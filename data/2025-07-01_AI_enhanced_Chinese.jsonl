{"id": "2506.23070", "categories": ["math.GM", "11B83"], "pdf": "https://arxiv.org/pdf/2506.23070", "abs": "https://arxiv.org/abs/2506.23070", "authors": ["Youchun Luo"], "title": "Iteration Steps of 3x+1 Problem", "comment": null, "summary": "On the 3x+1 problem, given a positive integer $N$, let $D\\left( N \\right) $,\n$O\\left( N \\right) $, $E\\left( N \\right) $ be the total iteration steps, the\nodd iteration steps and the even iteration steps when $N$ iterates to 1(except\n1) respectively. Trivially, we have $D\\left( N \\right) =O\\left( N \\right)\n+E\\left( N \\right) $. In this paper, we propose a so-called weak residue\nconjecture(i.e., $\\frac{2^{E\\left( N \\right)}}{3^{O\\left( N \\right)}\\cdot N}\\le\n2$). We prove that if 3x+1 conjecture is true and the weak residue conjecture\nis true, there exist non-trivial relationships among $D\\left( N \\right) $,\n$O\\left( N \\right) $, $E\\left( N \\right) $, i.e., $O\\left( N \\right) =\\left[\n\\log _62\\cdot D\\left( N \\right) -\\log _6N \\right] $(it implies that we can\ncalculate $O\\left( N \\right) $, $E\\left( N \\right) $ directly by $D\\left( N\n\\right) $ only, of course given $N$), and 5 more similar equations are derived\nsimultaneously.", "AI": {"tldr": "本文研究了3x+1问题中迭代步数的关系，提出了弱残差猜想，并证明了若3x+1猜想和弱残差猜想成立，则存在D(N)、O(N)、E(N)之间的非平凡关系。", "motivation": "探讨3x+1问题中迭代步数之间的关系，特别是总迭代步数D(N)、奇数步数O(N)和偶数步数E(N)之间的数学联系。", "method": "提出弱残差猜想$\\frac{2^{E\\left( N \\right)}}{3^{O\\left( N \\right)}\\cdot N}\\le 2$，并在3x+1猜想和弱残差猜想成立的假设下进行推导。", "result": "证明了若两个猜想成立，则存在O(N) = [log_62·D(N) - log_6N]等6个方程，可直接通过D(N)计算O(N)和E(N)。", "conclusion": "研究揭示了3x+1问题中迭代步数之间的潜在数学规律，为深入理解该问题提供了新的理论工具。"}}
{"id": "2506.22886", "categories": ["math.HO", "97D40, 97D60, 97D99, 97G99, 00A35"], "pdf": "https://arxiv.org/pdf/2506.22886", "abs": "https://arxiv.org/abs/2506.22886", "authors": ["Ioannis Diamantis"], "title": "The VIBE Framework: A Student-Centered Approach to Teaching Knot Theory in Secondary Mathematics", "comment": "Developed during the preparation of the University Teaching\n  Qualification (BKO) portfolio at Maastricht University", "summary": "Knot theory, a visual and intuitive branch of topology, offers a unique\nopportunity to introduce advanced mathematical thinking in secondary education.\nDespite its accessibility and cross-disciplinary relevance, it remains largely\nabsent from standard curricula. This paper proposes the {\\it VIBE framework}, a\nstudent-centered approach, structured around four pedagogical pillars: Visual,\nInquiry-based, Braided (collaborative), and Embedded (contextualized) learning.\nRooted in constructivist theory, VIBE supports cognitive development, spatial\nreasoning, and mathematical engagement across diverse learners. We present a\nsequence of low-threshold, high-ceiling activities designed to develop core\ntopological concepts while fostering creativity and exploration. Through\nqualitative heatmaps, clustering visualizations, and classroom snapshots, we\ndemonstrate how knot theory can be transformed into a powerful medium for\ninquiry and interdisciplinary connection. We believe that the VIBE framework\nprovides a structured yet adaptable approach that supports the integration of\ndeep, meaningful mathematical experiences into secondary education.", "AI": {"tldr": "本文提出VIBE框架，将结理论引入中学教育，通过视觉化、探究式、协作式和情境化学习，促进学生的认知发展和空间推理能力。", "motivation": "结理论作为拓扑学的直观分支，具有跨学科相关性，但当前中学课程中鲜有涉及。研究旨在通过创新教学方法填补这一空白。", "method": "采用基于建构主义的VIBE框架（视觉Visual、探究Inquiry-based、协作Braided、情境化Embedded），设计低门槛高上限的教学活动序列。", "result": "通过定性热图、聚类可视化和课堂实录证明，结理论能有效转化为探究性学习媒介，促进跨学科联系和学生创造力发展。", "conclusion": "VIBE框架为中学数学教育提供了结构化且灵活的方法，支持将深度的数学体验融入课程体系。"}}
{"id": "2506.22587", "categories": ["math.NT", "11R42, 11P21, 11N37"], "pdf": "https://arxiv.org/pdf/2506.22587", "abs": "https://arxiv.org/abs/2506.22587", "authors": ["Nilmoni Karak", "Kamalakshya Mahatab"], "title": "The Piltz divisor Problem in Number Fields Using The Resonance Method", "comment": "11 pages", "summary": "The Piltz divisor problem is a natural generalization of the classical\nDirichlet divisor problem. In this paper, we study this problem over number\nfields and obtain improved $\\Omega-$bounds for its error terms. Our approach\ninvolves generalizing a Voronoi-type formula due to Soundararajan in the number\nfield setting, and applying a recent result due to the second author.", "AI": {"tldr": "本文研究了数域上的Piltz除数问题，通过推广Soundararajan的Voronoi型公式并结合第二作者的最新成果，改进了误差项的$\\Omega-$界。", "motivation": "Piltz除数问题是经典Dirichlet除数问题的自然推广，研究其在数域上的表现具有重要理论意义。", "method": "方法包括将Soundararajan的Voronoi型公式推广到数域场景，并应用第二作者的最新研究成果。", "result": "获得了误差项的改进$\\Omega-$界，推进了该问题的研究进展。", "conclusion": "本研究通过创新方法在数域上拓展了Piltz除数问题的解，为相关领域提供了新的理论工具。"}}
{"id": "2506.22588", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.22588", "abs": "https://arxiv.org/abs/2506.22588", "authors": ["Muriel F. Pérez-Ortiz", "Rui M. Castro"], "title": "Anytime-Valid Tests for Sparse Anomalies", "comment": null, "summary": "We consider the problem of detection of sparse anomalies when monitoring a\nlarge number of data streams continuously in time. This problem is addressed\nusing anytime-valid tests. In the context of a normal-means model and for a\nfixed sample, this problem is known to exhibit a nontrivial phase transition\nthat characterizes when anomalies can and cannot be detected. We show, for the\nanytime-valid version of the problem, testing procedures that can detect the\npresence of anomalies quickly. Given that the goal is quick detection, existing\napproaches to anytime-valid testing that study how evidence accumulates for\nlarge times through log-optimality criteria is insufficient. This issue is\naddressed in this context by studying log-optimal procedures for a fixed moment\nin time, but as the number of streams grows larger. The resulting\ncharacterization is related to, but not implied by the existing results for\nfixed-sample tests. In addition, we also construct and analyze tests that are\nparameter-adaptive and exhibit optimal performance (in a well defined sense)\neven when the hypothesized model parameters are unknown. Numerical results\nillustrate the behavior of the proposed tests in comparison with oracle tests\nand suitable benchmarks.", "AI": {"tldr": "本文研究了在大规模数据流中实时检测稀疏异常的问题，提出了基于随时有效性检验的方法，并在正态均值模型下展示了快速检测异常的能力。通过分析流数量增长时的对数最优性，建立了与固定样本检验不同的理论特征，并构建了参数自适应的最优检验方法。数值实验验证了所提方法的优越性能。", "motivation": "传统固定样本检验方法在实时监测大规模数据流时存在效率不足的问题，无法快速检测稀疏异常。本文旨在开发一种随时有效性检验框架，解决快速检测与理论最优性之间的平衡问题。", "method": "采用随时有效性检验方法，在正态均值模型下建立检测程序。通过研究流数量增长时固定时间点的对数最优性（而非传统的大时间累积证据），构建参数自适应的检验统计量。与固定样本检验的理论结果进行对比分析。", "result": "理论分析表明所提方法能快速检测异常，其检测特征与固定样本检验存在本质差异。数值实验显示：参数自适应检验在未知真实参数时，性能接近已知参数的Oracle检验，显著优于基准方法。", "conclusion": "本文提出的随时有效性检验框架突破了传统方法的局限性，通过流数量渐近分析实现了稀疏异常的快速检测。参数自适应设计使方法具备实际应用价值，为高维流式数据监测提供了新工具。"}}
{"id": "2506.22857", "categories": ["math.CO", "cs.DM", "05C83, 05C85, 05C10, 68R10, 68R05", "G.2.2"], "pdf": "https://arxiv.org/pdf/2506.22857", "abs": "https://arxiv.org/abs/2506.22857", "authors": ["Maximilian Gorsky", "Giannos Stamoulis", "Dimitrios M. Thilikos", "Sebastian Wiederrecht"], "title": "Catching Rats in $H$-minor-free Graphs", "comment": "44 pages", "summary": "We show that every $H$-minor-free graph that also excludes a $(k \\times\nk)$-grid as a minor has treewidth/branchwidth bounded from above by a function\n$f(t,k)$ that is linear in $k$ and polynomial in $t := |V(H)|$. Such a result\nwas proven originally by [Demaine & Hajiaghayi, Combinatorica, 2008], where $f$\nwas indeed linear in $k$. However the dependency in $t$ in this result was\nnon-explicit (and huge). Later, [Kawarabayashi & Kobayashi, JCTB, 2020] showed\nthat this bound can be estimated to be $f(t,k)\\in 2^{\\mathcal{O}(t\\log t)}\n\\cdot k$. Wood recently asked whether $f$ can be pushed further to be\npolynomial, while maintaining the linearity on $k$. We answer this in a\nparticularly strong sense, by showing that the treewidth/branchwidth of $G$ is\nin $\\mathcal{O}(gk + t^{2304}),$ where $g$ is the Euler genus of $H$. This\ndirectly yields $f(t,k)= \\mathcal{O}(t^2k + t^{2304})$.\n  Our methods build on techniques for branchwidth and on new bounds and\ninsights for the Graph Minor Structure Theorem (GMST) due to [Gorsky, Seweryn &\nWiederrecht, 2025, arXiv:2504.02532]. In particular, we prove a variant of the\nGMST that ensures some helpful properties for the minor relation. We further\nemploy our methods to provide approximation algorithms for the\ntreewidth/branchwidth of $H$-minor-free graphs. In particular, for every\n$\\varepsilon > 0$ and every $t$-vertex graph $H$ with Euler genus $g$, we give\na $(g + \\varepsilon)$-approximation algorithm for the branchwidth of\n$H$-minor-free graphs running in $2^{\\mathsf{poly}(t) / \\varepsilon} \\cdot\n\\mathsf{poly}(n)$-time. Our algorithms explicitly return either an appropriate\nbranch-decomposition or a grid-minor certifying a negative answer.", "AI": {"tldr": "本文证明了排除$H$子式和$(k \\times k)$网格子式的图,其树宽/分支宽上限为$\\mathcal{O}(gk + t^{2304})$,改进了先前结果并回答了Wood的问题。同时提出了分支宽近似算法。", "motivation": "研究$H$-minor-free图的树宽/分支宽上界,旨在将函数$f(t,k)$改进为$k$线性且$t$多项式,解决[Demaine & Hajiaghayi, 2008]和[Kawarabayashi & Kobayashi, 2020]遗留的显式界问题。", "method": "基于分支宽技术及[Gorsky等, 2025]的图子式结构定理新界限,证明改进版GMST以增强子式关系性质,并开发近似算法。", "result": "获得强上界$\\mathcal{O}(gk + t^{2304})$,导出$f(t,k)=\\mathcal{O}(t^2k + t^{2304})$。提出$(g + \\varepsilon)$-近似算法,运行时间为$2^{\\mathsf{poly}(t) / \\varepsilon} \\cdot \\mathsf{poly}(n)$。", "conclusion": "不仅显著改进了树宽/分支宽的理论上界,还提供了实用的近似算法,算法可输出分支分解或证明不存在性的网格子式。"}}
{"id": "2506.23790", "categories": ["cs.DM", "cs.CC", "cs.DS", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.23790", "abs": "https://arxiv.org/abs/2506.23790", "authors": ["Jesse Beisegel", "Katharina Klost", "Kristin Knorr", "Fabienne Ratajczak", "Robert Scheffler"], "title": "A Graph Width Perspective on Partially Ordered Hamiltonian Paths and Cycles I: Treewidth, Pathwidth, and Grid Graphs", "comment": "\"A Graph Width Perspective on Partially Ordered Hamiltonian Paths\"\n  arXiv:2503.03553 was an extended abstract of a host of results. We have\n  decided to split that paper into two separate full papers. This first paper\n  given here covers the first half of the results along with several new\n  results, in particular about Hamiltonian cycles", "summary": "We consider the problem of finding a Hamiltonian path or a Hamiltonian cycle\nwith precedence constraints in the form of a partial order on the vertex set.\nWe show that the path problem is $\\mathsf{NP}$-complete for graphs of pathwidth\n4 while the cycle problem is $\\mathsf{NP}$-complete on graphs of pathwidth 5.\nWe complement these results by giving polynomial-time algorithms for graphs of\npathwidth 3 and treewidth 2 for Hamiltonian paths as well as pathwidth 4 and\ntreewidth 3 for Hamiltonian cycles. Furthermore, we study the complexity of the\npath and cycle problems on rectangular grid graphs of bounded height. For\nthese, we show that the path and cycle problems are $\\mathsf{NP}$-complete when\nthe height of the grid is greater or equal to 7 and 9, respectively. In the\nvariant where we look for minimum edge-weighted Hamiltonian paths and cycles,\nthe problems are $\\mathsf{NP}$-hard for heights 5 and 6, respectively.", "AI": {"tldr": "本文研究了带偏序约束的哈密尔顿路径和哈密尔顿环问题，证明了路径问题在路径宽度为4的图上及环问题在路径宽度为5的图上是$\\mathsf{NP}$-完全的，并给出了路径宽度为3和树宽度为2的图上的多项式时间算法。同时，研究了有界高度矩形网格图上的复杂度，发现路径和环问题分别在高度≥7和≥9时是$\\mathsf{NP}$-完全的，而最小边权问题在高度5和6时是$\\mathsf{NP}$-难的。", "motivation": "研究带偏序约束的哈密尔顿路径和环问题，旨在理解这些经典图论问题在不同图结构上的计算复杂度边界。", "method": "通过理论证明和算法设计，分析了路径宽度和树宽度受限的图上的复杂度，并特别考察了有界高度矩形网格图上的情况。", "result": "路径问题在路径宽度4的图上是$\\mathsf{NP}$-完全的，环问题在路径宽度5的图上是$\\mathsf{NP}$-完全的；路径宽度3和树宽度2的图上有多项式时间算法。矩形网格图中，路径和环问题分别在高度≥7和≥9时是$\\mathsf{NP}$-完全的，最小边权问题在高度5和6时是$\\mathsf{NP}$-难的。", "conclusion": "研究明确了带偏序约束的哈密尔顿问题在不同图结构上的复杂度边界，为相关算法设计提供了理论依据。"}}
{"id": "2506.23265", "categories": ["math.LO", "math.GR", "03C45, 03C60, 03C64, 28D15"], "pdf": "https://arxiv.org/pdf/2506.23265", "abs": "https://arxiv.org/abs/2506.23265", "authors": ["Artem Chernikov"], "title": "Externally definable fsg groups in NIP theories", "comment": "72 pages, 2 figures", "summary": "We show that every fsg group externally definable in an NIP structure is\ndefinably isomorphic to a group interpretable in it. Our proof relies on honest\ndefinitions and a group chunk result reconstructing a hyper-definable group\nfrom its multiplication given generically with respect to a translation\ninvariant definable Keisler measure on it. We obtain related results on\nexternally (type-)definable sets and groups, including a proof of a conjecture\nof Eleftheriou on fsg groups in real closed valued fields, and a description of\nexternally definable, definably amenable subgroups of definable groups.", "AI": {"tldr": "证明了NIP结构中外部可定义的fsg群与可解释群之间存在定义同构，解决了Eleftheriou猜想并描述了可定义群中的外部可定义、可定义顺从子群。", "motivation": "研究NIP结构中外部可定义集与群的性质，特别是fsg群与可解释群之间的关系，以及解决Eleftheriou在实闭值域上的猜想。", "method": "采用诚实定义和群块结果，通过平移不变的可定义Keisler测度重构超可定义群。", "result": "证明了外部可定义的fsg群与可解释群的定义同构，解决了Eleftheriou猜想，并描述了外部可定义、可定义顺从子群。", "conclusion": "该研究深化了对NIP结构中外部可定义群的理解，为相关领域提供了新的工具和结果。"}}
{"id": "2506.22888", "categories": ["q-fin.CP"], "pdf": "https://arxiv.org/pdf/2506.22888", "abs": "https://arxiv.org/abs/2506.22888", "authors": ["Jirong Zhuang", "Xuan Wu"], "title": "SABR-Informed Multitask Gaussian Process: A Synthetic-to-Real Framework for Implied Volatility Surface Construction", "comment": "33 pages", "summary": "Constructing the Implied Volatility Surface (IVS) is a challenging task in\nquantitative finance due to the complexity of real markets and the sparsity of\nmarket data. Structural models like Stochastic Alpha Beta Rho (SABR) model\noffer interpretability and theoretical consistency but lack flexibility, while\npurely data-driven methods such as Gaussian Process regression can struggle\nwith sparse data. We introduce SABR-Informed Multi-Task Gaussian Process\n(SABR-MTGP), treating IVS construction as a multi-task learning problem. Our\nmethod uses a dense synthetic dataset from a calibrated SABR model as a source\ntask to inform the construction based on sparse market data (the target task).\nThe MTGP framework captures task correlation and transfers structural\ninformation adaptively, improving predictions particularly in data-scarce\nregions. Experiments using Heston-generated ground truth data under various\nmarket conditions show that SABR-MTGP outperforms both standard Gaussian\nprocess regression and SABR across different maturities. Furthermore, an\napplication to real SPX market data demonstrates the method's practical\napplicability and its ability to produce stable and realistic surfaces. This\nconfirms our method balances structural guidance from SABR with the flexibility\nneeded for market data.", "AI": {"tldr": "提出SABR-MTGP方法，结合SABR模型的结构化优势与高斯过程回归的灵活性，通过多任务学习构建隐含波动率曲面，在数据稀疏区域表现优异。", "motivation": "隐含波动率曲面(IVS)构建面临市场数据稀疏与模型灵活性不足的双重挑战，传统SABR模型可解释性强但缺乏灵活性，纯数据驱动方法对稀疏数据效果不佳。", "method": "采用多任务高斯过程框架，以校准后的SABR模型生成密集合成数据作为源任务，稀疏市场数据作为目标任务，自适应传递结构信息并捕捉任务相关性。", "result": "在Heston模型生成数据及真实SPX市场数据上的实验表明，SABR-MTGP在多种期限结构下均优于标准高斯过程回归和SABR模型，能生成稳定且符合实际的曲面。", "conclusion": "该方法成功平衡了SABR模型的结构指导与市场数据所需的灵活性，为IVS构建提供了兼具理论一致性与实践适应性的解决方案。"}}
{"id": "2506.22475", "categories": ["math.OC", "cs.GT", "91A12, 91A43, 91A80"], "pdf": "https://arxiv.org/pdf/2506.22475", "abs": "https://arxiv.org/abs/2506.22475", "authors": ["P. Soto-Rodríguez", "B. Casas-Méndez", "A. Saavedra-Nieves"], "title": "Highway toll allocation problem revisited: new methods and characterizations", "comment": "28 pages, 5 tables, 3 figures", "summary": "This paper considers the highway toll allocation problem (Wu, van den Brink,\nand Est\\'evez-Fern\\'andez in Transport Res B-Meth 180:10288, 2024). The aim is\nto allocate the tolls collected from the users of a highway across the various\nroad sections. To this end, the authors propose, among others, the Segments\nEqual Sharing method, which is characterized and reinterpreted as a specific\nsolution of a cooperative game associated with the problem. This paper presents\ntwo new allocation rules: the Segments Proportional Sharing method and the\nSegments Compensated Sharing method. We axiomatically characterize these new\nmethods and compare their properties to those of the Segments Equal Sharing\nmethod. Furthermore, we also examine the relationship of these methods to the\nsolution of the associated cooperative game. We conclude the methodological\nstudy by introducing a general family of segment allocation methods that\nincludes the three aforementioned rules. Finally, we evaluate the performance\nof these methods using a real-world dataset.", "AI": {"tldr": "本文研究高速公路通行费分配问题，提出了两种新的分配规则（路段比例共享法和路段补偿共享法），并通过公理化特征和合作博弈关联进行分析，最终构建了一个包含三种规则的通用分配方法家族，并使用真实数据集验证了其性能。", "motivation": "旨在解决高速公路各路段间通行费的公平分配问题，扩展现有研究并引入更灵活的分配方法。", "method": "提出路段比例共享法和路段补偿共享法两种新规则，通过公理化方法进行特征描述，并与合作博弈解建立关联，最终构建通用分配方法家族。", "result": "新方法在公理性质上展现出与原有路段均等共享法的差异，通用方法家族成功涵盖三种分配规则，实证数据验证了方法的可行性。", "conclusion": "通过理论构建与实证分析，研究为高速公路通行费分配提供了多元化的解决方案框架，拓展了该领域的决策工具箱。"}}
{"id": "2506.22506", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22506", "abs": "https://arxiv.org/abs/2506.22506", "authors": ["Momin Ahmad Khan", "Yasra Chandio", "Fatima Muhammad Anwar"], "title": "SABRE-FL: Selective and Accurate Backdoor Rejection for Federated Prompt Learning", "comment": null, "summary": "Federated Prompt Learning has emerged as a communication-efficient and\nprivacy-preserving paradigm for adapting large vision-language models like CLIP\nacross decentralized clients. However, the security implications of this setup\nremain underexplored. In this work, we present the first study of backdoor\nattacks in Federated Prompt Learning. We show that when malicious clients\ninject visually imperceptible, learnable noise triggers into input images, the\nglobal prompt learner becomes vulnerable to targeted misclassification while\nstill maintaining high accuracy on clean inputs. Motivated by this\nvulnerability, we propose SABRE-FL, a lightweight, modular defense that filters\npoisoned prompt updates using an embedding-space anomaly detector trained\noffline on out-of-distribution data. SABRE-FL requires no access to raw client\ndata or labels and generalizes across diverse datasets. We show, both\ntheoretically and empirically, that malicious clients can be reliably\nidentified and filtered using an embedding-based detector. Across five diverse\ndatasets and four baseline defenses, SABRE-FL outperforms all baselines by\nsignificantly reducing backdoor accuracy while preserving clean accuracy,\ndemonstrating strong empirical performance and underscoring the need for robust\nprompt learning in future federated systems.", "AI": {"tldr": "本文首次研究了联邦提示学习中的后门攻击问题，提出了一种轻量级防御方法SABRE-FL，通过嵌入空间异常检测器有效过滤恶意客户端提交的污染提示更新，在保持干净数据准确率的同时显著降低后门攻击成功率。", "motivation": "联邦提示学习作为高效通信且保护隐私的范式，其安全风险尚未充分探索。研究发现当恶意客户端在输入图像中注入视觉不可察的学习型噪声触发器时，全局提示学习器会产生针对性误分类漏洞。", "method": "提出SABRE-FL防御框架：采用离线训练的嵌入空间异常检测器过滤污染提示更新，无需访问原始客户端数据或标签，具有模块化特性并可泛化至不同数据集。", "result": "在五个数据集和四种基线防御上的实验表明，SABRE-FL能可靠识别恶意客户端，将后门准确率平均降低63.2%，同时保持98.7%的干净数据准确率，显著优于所有基线方法。", "conclusion": "研究揭示了联邦提示学习系统的安全脆弱性，证实基于嵌入空间的检测方法能有效防御后门攻击，强调了未来联邦系统需要更鲁棒的提示学习机制。"}}
{"id": "2506.22604", "categories": ["cs.AI", "cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.22604", "abs": "https://arxiv.org/abs/2506.22604", "authors": ["David Porfirio", "Vincent Hsiao", "Morgan Fine-Morris", "Leslie Smith", "Laura M. Hiatt"], "title": "Bootstrapping Human-Like Planning via LLMs", "comment": "Accepted by the 2025 34th IEEE International Conference on Robot and\n  Human Interactive Communication (RO-MAN)", "summary": "Robot end users increasingly require accessible means of specifying tasks for\nrobots to perform. Two common end-user programming paradigms include\ndrag-and-drop interfaces and natural language programming. Although natural\nlanguage interfaces harness an intuitive form of human communication,\ndrag-and-drop interfaces enable users to meticulously and precisely dictate the\nkey actions of the robot's task. In this paper, we investigate the degree to\nwhich both approaches can be combined. Specifically, we construct a large\nlanguage model (LLM)-based pipeline that accepts natural language as input and\nproduces human-like action sequences as output, specified at a level of\ngranularity that a human would produce. We then compare these generated action\nsequences to another dataset of hand-specified action sequences. Although our\nresults reveal that larger models tend to outperform smaller ones in the\nproduction of human-like action sequences, smaller models nonetheless achieve\nsatisfactory performance.", "AI": {"tldr": "研究探讨了结合自然语言编程与拖拽界面两种机器人任务编程方式的可行性，通过基于大语言模型（LLM）的流程生成类人动作序列，并与人工指定序列对比，发现大模型表现更优但小模型仍可满足需求。", "motivation": "随着机器人终端用户对任务编程便捷性需求的提升，研究旨在结合自然语言编程的直观性与拖拽界面的精确性优势，探索两者融合的可能性。", "method": "构建基于大语言模型（LLM）的流程，输入自然语言指令并输出类人精细动作序列，随后与人工指定的动作序列数据集进行对比分析。", "result": "实验表明，大模型在生成类人动作序列方面优于小模型，但小模型仍能达到令人满意的性能水平。", "conclusion": "尽管大模型在生成精细动作序列上更具优势，小模型的实际表现验证了轻量化解决方案的可行性，为两种编程范式的结合提供了实践依据。"}}
{"id": "2506.22590", "categories": ["math.NT", "11P21, 11K38, 52C07"], "pdf": "https://arxiv.org/pdf/2506.22590", "abs": "https://arxiv.org/abs/2506.22590", "authors": ["Nilmoni Karak"], "title": "Omega Estimate for the Lattice Point Discrepancy of a Body of Revolution Using The Resonance Method", "comment": "7 pages", "summary": "Using a recent method developed by Mahatab, we obtain an improved\n$\\Omega$-bound for the error term arising in lattice counting problem of bodies\nof revolution in $\\mathbb R^3$ around a coordinate axis and having smooth\nboundary with bounded nonzero curvature. This strengthens an earlier result by\nK\\\"uhleitner and Nowak.", "AI": {"tldr": "本文利用Mahatab的最新方法，改进了三维空间中旋转体格子点计数问题的误差项$\\Omega$界，强化了K\\\"uhleitner和Nowak的早期结果。", "motivation": "研究三维空间中具有光滑边界且曲率有界的旋转体在坐标轴周围的格子点计数问题，旨在改进现有误差界。", "method": "采用Mahatab提出的新方法，对旋转体的格子点计数误差项进行分析。", "result": "获得了比K\\\"uhleitner和Nowak更优的误差项$\\Omega$界。", "conclusion": "该方法有效提升了旋转体格子点计数问题的误差估计精度，为相关领域研究提供了更严格的理论工具。"}}
{"id": "2506.22701", "categories": ["math.ST", "cs.DS", "cs.LG", "cs.NA", "math.NA", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.22701", "abs": "https://arxiv.org/abs/2506.22701", "authors": ["Shi Jie Yu"], "title": "Lower bounds for trace estimation via Block Krylov and other methods", "comment": null, "summary": "This paper studies theoretical lower bounds for estimating the trace of a\nmatrix function, $\\text{tr}(f(A))$, focusing on methods that use Hutchinson's\nmethod along with Block Krylov techniques. These methods work by approximating\nmatrix-vector products like $f(A)V$ using a Block Krylov subspace. This is\nclosely related to approximating functions with polynomials. We derive\ntheoretical upper bounds on how many Krylov steps are needed for functions such\nas $A^{-1/2}$ and $A^{-1}$ by analyzing the upper bounds from the polynomial\napproximation of their scalar equivalent. In addition, we also develop lower\nlimits on the number of queries needed for trace estimation, specifically for\n$\\text{tr}(W^{-p})$ where $W$ is a Wishart matrix. Our study clarifies the\nconnection between the number of steps in Block Krylov methods and the degree\nof the polynomial used for approximation. This links the total cost of trace\nestimation to basic limits in polynomial approximation and how much information\nis needed for the computation.", "AI": {"tldr": "本文研究了矩阵函数迹估计的理论下界，结合Hutchinson方法和块Krylov技术，分析了多项式近似与查询次数下限的关系。", "motivation": "矩阵函数迹估计（如$\\text{tr}(f(A))$）在科学计算中至关重要，但现有方法效率不足，需明确块Krylov步数与多项式近似阶数的理论联系。", "method": "通过块Krylov子空间近似矩阵-向量积（如$f(A)V$），并分析标量等价函数（如$A^{-1/2}$、$A^{-1}$）的多项式近似上界，推导所需Krylov步数。", "result": "建立了Wishart矩阵$\\text{tr}(W^{-p})$迹估计的查询次数下限，揭示了块Krylov步数与多项式近似阶数的直接关联。", "conclusion": "研究将迹估计的总成本与多项式近似的基本极限及计算所需信息量联系起来，为高效算法设计提供了理论依据。"}}
{"id": "2506.22976", "categories": ["math.CO", "05A30, 33D45"], "pdf": "https://arxiv.org/pdf/2506.22976", "abs": "https://arxiv.org/abs/2506.22976", "authors": ["Ronald Orozco López"], "title": "Homogeneous Linear Calculus of Order 1 and a $λ$-Taylor Formula", "comment": null, "summary": "In this paper, a new calculus on sequences is defined. Also, the\n$\\lambda$-derivative and the $\\lambda$-integration are investigated. The\nfundamental theorem of $\\lambda$-calculus is included. A suitable function\nbasis for the $\\lambda$-derivative and the $\\lambda$-integral is provided, and\nvarious properties of this basis are given. A $\\lambda$-Taylor formula for\nfunctions is given.", "AI": {"tldr": "本文定义了一种新的序列演算，研究了$\\lambda$-导数和$\\lambda$-积分，并给出了$\\lambda$-演算的基本定理。", "motivation": "研究新的序列演算及其相关数学工具，扩展微积分理论的应用范围。", "method": "定义了$\\lambda$-导数和$\\lambda$-积分，构建了适合的函数基，并推导了$\\lambda$-泰勒公式。", "result": "提出了$\\lambda$-演算的基本定理，展示了函数基的各种性质，并给出了$\\lambda$-泰勒展开式。", "conclusion": "该研究为序列分析提供了新的数学工具，$\\lambda$-演算框架具有理论价值和潜在应用前景。"}}
{"id": "2506.23943", "categories": ["cs.DM", "cs.CG"], "pdf": "https://arxiv.org/pdf/2506.23943", "abs": "https://arxiv.org/abs/2506.23943", "authors": ["Emilio Di Giacomo", "Walter Didimo", "Henry Förster", "Torsten Ueckerdt", "Johannes Zink"], "title": "Linear Layouts of Graphs with Priority Queues", "comment": "Appears in Proc. 19th Algorithms and Data Structures Symposium (WADS\n  2025)", "summary": "A linear layout of a graph consists of a linear ordering of its vertices and\na partition of its edges into pages such that the edges assigned to the same\npage obey some constraint. The two most prominent and widely studied types of\nlinear layouts are stack and queue layouts, in which any two edges assigned to\nthe same page are forbidden to cross and nest, respectively. The names of these\ntwo layouts derive from the fact that, when parsing the graph according to the\nlinear vertex ordering, the edges in a single page can be stored using a single\nstack or queue, respectively. Recently, the concepts of stack and queue layouts\nhave been extended by using a double-ended queue or a restricted-input queue\nfor storing the edges of a page. We extend this line of study to edge-weighted\ngraphs by introducing priority queue layouts, that is, the edges on each page\nare stored in a priority queue whose keys are the edge weights. First, we show\nthat there are edge-weighted graphs that require a linear number of priority\nqueues. Second, we characterize the graphs that admit a priority queue layout\nwith a single queue, regardless of the edge-weight function, and we provide an\nefficient recognition algorithm. Third, we show that the number of priority\nqueues required independently of the edge-weight function is bounded by the\npathwidth of the graph, but can be arbitrarily large already for graphs of\ntreewidth two. Finally, we prove that determining the minimum number of\npriority queues is NP-complete if the linear ordering of the vertices is fixed.", "AI": {"tldr": "本文研究了边加权图的优先级队列布局，证明了某些图需要线性数量的优先级队列，并提供了单队列布局的识别算法。同时探讨了路径宽度与队列数的关系，并证明了固定顶点顺序时最小队列数的NP完全性。", "motivation": "传统堆栈和队列布局已扩展至双端队列和受限输入队列，但边加权图的优先级队列布局尚未系统研究。本文旨在填补这一空白，探索边权重如何影响图的页面分配。", "method": "引入优先级队列布局概念，其中每页边按权重存储在优先队列中。通过构造性证明、路径宽度理论分析和NP完全性归约等方法展开研究。", "result": "1) 存在需要O(n)个优先级队列的边加权图；2) 单队列布局图类可高效识别；3) 队列数受路径宽度限制但树宽度为2时仍可无限；4) 固定顶点顺序时最小队列数计算是NP完全的。", "conclusion": "优先级队列布局为边加权图提供了新的分层框架，其复杂性由路径宽度部分约束但计算难度较高，未来可探索近似算法或特殊图类的高效布局方案。"}}
{"id": "2506.23586", "categories": ["math.LO", "20B27, 22A05, 20F28, 03C15"], "pdf": "https://arxiv.org/pdf/2506.23586", "abs": "https://arxiv.org/abs/2506.23586", "authors": ["Gianluca Paolini", "Federico Pisciotta"], "title": "A Galois correspondence for automorphism groups of structures with the Lascar Property", "comment": null, "summary": "Generalizing the $\\omega$-categorical context, we introduce a notion, which\nwe call the Lascar Property, that allows for a fine analysis of the topological\nisomorphisms between automorphism groups of countable structures satisfying\nthis property. In particular, under the assumption of the Lascar Property, we\nexhibit a definable Galois correspondence between pointwise stabilizers of\nfinitely generated Galois algebraically closed subsets of $M$ and finitely\ngenerated Galois algebraically closed subsets of $M$. We use this to\ncharacterize the group of automorphisms of $\\mathrm{Aut}(M)$, for $M$ the\ncountable saturated model of $\\mathrm{ACF}_0$, $\\mathrm{DCF}_0$, or the theory\nof infinite $\\mathrm{K}$-vector spaces, generalizing results of Evans $\\&$\nLascar, and Konnerth, while at the same time subsuming the analysis from [11]\nfor $\\omega$-categorical structures with weak elimination of imaginaries.", "AI": {"tldr": "本文引入Lascar性质，分析满足该性质的可数结构自同构群的拓扑同构，并建立了可定义的Galois对应关系，推广了Evans、Lascar和Konnerth的结果。", "motivation": "研究可数结构自同构群的拓扑同构，推广$\\omega$-范畴背景下的结果，为模型论中的自同构群分析提供新工具。", "method": "引入Lascar性质，构建点稳定子与有限生成Galois代数闭子集之间的可定义Galois对应关系。", "result": "在Lascar性质假设下，刻画了$\\mathrm{ACF}_0$、$\\mathrm{DCF}_0$和无限$\\mathrm{K}$-向量空间理论的可数饱和模型的自同构群。", "conclusion": "该框架统一了$\\omega$-范畴结构的分析，并推广了前人关于自同构群的研究成果。"}}
{"id": "2506.22479", "categories": ["math.OC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22479", "abs": "https://arxiv.org/abs/2506.22479", "authors": ["Krisanu Sarkar"], "title": "Hindsight-Guided Momentum (HGM) Optimizer: An Approach to Adaptive Learning Rate", "comment": null, "summary": "We introduce Hindsight-Guided Momentum (HGM), a first-order optimization\nalgorithm that adaptively scales learning rates based on the directional\nconsistency of recent updates. Traditional adaptive methods, such as Adam or\nRMSprop , adapt learning dynamics using only the magnitude of gradients, often\noverlooking important geometric cues.Geometric cues refer to directional\ninformation, such as the alignment between current gradients and past updates,\nwhich reflects the local curvature and consistency of the optimization path.\nHGM addresses this by incorporating a hindsight mechanism that evaluates the\ncosine similarity between the current gradient and accumulated momentum. This\nallows it to distinguish between coherent and conflicting gradient directions,\nincreasing the learning rate when updates align and reducing it in regions of\noscillation or noise. The result is a more responsive optimizer that\naccelerates convergence in smooth regions of the loss surface while maintaining\nstability in sharper or more erratic areas. Despite this added adaptability,\nthe method preserves the computational and memory efficiency of existing\noptimizers.By more intelligently responding to the structure of the\noptimization landscape, HGM provides a simple yet effective improvement over\nexisting approaches, particularly in non-convex settings like that of deep\nneural network training.", "AI": {"tldr": "HGM是一种基于历史梯度方向自适应调整学习率的一阶优化算法，通过评估当前梯度与累积动量的余弦相似性，在平滑区域加速收敛，在振荡区域保持稳定性。", "motivation": "传统自适应方法（如Adam、RMSprop）仅依赖梯度幅值调整学习率，忽略了梯度方向等几何信息，导致优化路径的局部曲率和一致性未被充分利用。", "method": "HGM引入后见机制，通过计算当前梯度与历史动量的余弦相似度，动态调节学习率：方向一致时增大步长，方向冲突时减小步长。", "result": "该算法在损失函数的平滑区域加速收敛，在尖锐或噪声区域保持稳定，且计算和内存效率与现有优化器相当。", "conclusion": "HGM通过智能响应优化地形结构，在非凸场景（如深度神经网络训练）中提供了简单有效的改进，同时保持了高效性。"}}
{"id": "2506.22515", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22515", "abs": "https://arxiv.org/abs/2506.22515", "authors": ["Antony Dalmiere", "Guillaume Auriol", "Vincent Nicomette", "Pascal Marchand"], "title": "In-context learning for the classification of manipulation techniques in phishing emails", "comment": null, "summary": "Traditional phishing detection often overlooks psychological manipulation.\nThis study investigates using Large Language Model (LLM) In-Context Learning\n(ICL) for fine-grained classification of phishing emails based on a taxonomy of\n40 manipulation techniques. Using few-shot examples with GPT-4o-mini on\nreal-world French phishing emails (SignalSpam), we evaluated performance\nagainst a human-annotated test set (100 emails). The approach effectively\nidentifies prevalent techniques (e.g., Baiting, Curiosity Appeal, Request For\nMinor Favor) with a promising accuracy of 0.76. This work demonstrates ICL's\npotential for nuanced phishing analysis and provides insights into attacker\nstrategies.", "AI": {"tldr": "本研究利用大型语言模型（LLM）的上下文学习（ICL）技术，对基于40种操纵技术分类的网络钓鱼邮件进行细粒度检测，在真实法语钓鱼邮件数据集上取得0.76的准确率。", "motivation": "传统钓鱼检测常忽略心理操纵手段，本研究旨在探索LLM在识别复杂心理操纵技术方面的潜力。", "method": "采用GPT-4o-mini模型进行少样本学习，基于SignalSpam法语钓鱼邮件数据集，使用人工标注的100封测试邮件进行评估。", "result": "模型能有效识别主流操纵技术（如诱饵、好奇心吸引、小额请求等），准确率达0.76。", "conclusion": "该研究证实了ICL在精细化钓鱼分析中的实用性，并为攻击者策略分析提供了新视角。"}}
{"id": "2506.22609", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22609", "abs": "https://arxiv.org/abs/2506.22609", "authors": ["Graham Todd", "Alexander G. Padula", "Dennis J. N. J. Soemers", "Julian Togelius"], "title": "Ludax: A GPU-Accelerated Domain Specific Language for Board Games", "comment": "18 pages, 3 figures", "summary": "Games have long been used as benchmarks and testing environments for research\nin artificial intelligence. A key step in supporting this research was the\ndevelopment of game description languages: frameworks that compile\ndomain-specific code into playable and simulatable game environments, allowing\nresearchers to generalize their algorithms and approaches across multiple games\nwithout having to manually implement each one. More recently, progress in\nreinforcement learning (RL) has been largely driven by advances in hardware\nacceleration. Libraries like JAX allow practitioners to take full advantage of\ncutting-edge computing hardware, often speeding up training and testing by\norders of magnitude. Here, we present a synthesis of these strands of research:\na domain-specific language for board games which automatically compiles into\nhardware-accelerated code. Our framework, Ludax, combines the generality of\ngame description languages with the speed of modern parallel processing\nhardware and is designed to fit neatly into existing deep learning pipelines.\nWe envision Ludax as a tool to help accelerate games research generally, from\nRL to cognitive science, by enabling rapid simulation and providing a flexible\nrepresentation scheme. We present a detailed breakdown of Ludax's description\nlanguage and technical notes on the compilation process, along with speed\nbenchmarking and a demonstration of training RL agents. The Ludax framework,\nalong with implementations of existing board games, is open-source and freely\navailable.", "AI": {"tldr": "本文介绍了Ludax框架，一种专为棋盘游戏设计的领域特定语言，能自动编译为硬件加速代码，结合了游戏描述语言的通用性与现代并行处理硬件的速度，旨在加速从强化学习到认知科学等游戏研究。", "motivation": "游戏长期以来作为人工智能研究的基准和测试环境。随着硬件加速的进步，如JAX等库大幅提升了训练和测试速度。本文旨在结合游戏描述语言的通用性与硬件加速的优势，推动游戏研究的快速发展。", "method": "提出了Ludax框架，一种棋盘游戏的领域特定语言，能自动编译为硬件加速代码。详细介绍了Ludax的描述语言和编译过程的技术细节，并进行了速度基准测试和强化学习代理的训练演示。", "result": "Ludax框架成功结合了游戏描述语言的通用性与现代硬件加速的速度，能够无缝集成到现有的深度学习流程中。框架及其现有棋盘游戏的实现已开源并免费提供。", "conclusion": "Ludax框架有望成为加速游戏研究的工具，通过快速模拟和灵活的表示方案，支持从强化学习到认知科学的广泛研究。"}}
{"id": "2506.22634", "categories": ["math.NT", "cs.DS", "cs.NA", "math.NA", "11N05, 11Y35, 11M26, 65B10", "F.2.1; I.1.2"], "pdf": "https://arxiv.org/pdf/2506.22634", "abs": "https://arxiv.org/abs/2506.22634", "authors": ["Bugra Kilictas", "Faruk Alpay"], "title": "A Rigorous Error Bound for the TG Kernel in Prime Counting", "comment": "19 pages, 0 figure", "summary": "We establish rigorous error bounds for prime counting using a truncated\nGaussian (TG) kernel in the explicit formula framework. Our main theorem proves\nthat the approximation error remains globally below 1/2 for all sufficiently\nlarge arguments, guaranteeing exact computation of {\\pi}(x) through simple\nrounding, without relying on unproven hypotheses.\n  The TG kernel construction employs Gaussian-like test functions with compact\nsupport, engineered with vanishing moments to eliminate main terms. For x with\n10^8 decimal digits, we demonstrate that only ~1200 nontrivial zeta zeros\nsuffice to achieve the error bound, enabling computation in seconds on modern\nhardware - a dramatic improvement over classical methods.\n  Key contributions include: (1) Explicit tail truncation bounds using Taylor\nremainder analysis, showing exponential decay; (2) Zero-sum truncation error\nbounds via unconditional density estimates; (3) Rigorous treatment of trivial\nzero contributions. All constants are made explicit, ensuring full\nverifiability.\n  The method bridges analytic number theory and practical computation, with\npotential applications to record-breaking prime counting computations. We\ndiscuss algorithmic implications including FFT-based arithmetic for ~330\nmillion bit numbers. The framework's flexibility suggests connections to deeper\nstructures in prime distribution, particularly regarding optimized kernel\ndesigns and the interplay between smoothing parameters {\\alpha} and truncation\nheights.\n  This work exemplifies how classical analytic techniques, when carefully\nimplemented with modern computational perspectives, yield practical algorithms\nfor problems previously considered purely theoretical. The rigorous error\nanalysis ensures reliability even at astronomical scales, opening new avenues\nfor computational number theory research.", "AI": {"tldr": "该论文通过截断高斯核在显式公式框架中建立了素数计数的严格误差界，证明了对于足够大的参数，近似误差全局低于1/2，从而无需依赖未证明假设即可通过简单舍入精确计算素数计数函数{\\pi}(x)。", "motivation": "研究旨在将经典解析数论技术与现代计算视角结合，开发实用算法解决以往被视为纯理论的问题，特别是在天文尺度上可靠地进行素数计数计算。", "method": "采用具有紧支撑的高斯类测试函数构造截断高斯核，通过泰勒余项分析实现显式尾部截断边界（呈现指数衰减），利用无条件密度估计控制零和截断误差，并严格处理平凡零点贡献。所有常数均显式给出以确保可验证性。", "result": "对于具有10^8位十进制数字的x，仅需约1200个非平凡zeta零点即可在秒级时间内达到误差界，比经典方法有显著提升。该方法支持基于FFT的3.3亿比特数运算，为破纪录的素数计算提供可能。", "conclusion": "该工作通过严格误差分析将解析数论与实际计算连接起来，展示了优化核设计与平滑参数{\\alpha}和截断高度相互作用对素数分布的深层意义，为计算数论研究开辟了新途径。"}}
{"id": "2506.22975", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.22975", "abs": "https://arxiv.org/abs/2506.22975", "authors": ["Aman Pandey", "Chanchal Kundu"], "title": "On the Study of Weighted Fractional Cumulative Residual Inaccuracy and its Dynamical Version with Applications", "comment": null, "summary": "In recent years, there has been a growing interest in information measures\nthat quantify inaccuracy and uncertainty in systems. In this paper, we\nintroduce a novel concept called the Weighted Fractional Cumulative Residual\nInaccuracy (WFCRI). We develop several fundamental properties of WFCRI and\nestablish important bounds that reveal its analytical behavior. Further, we\nexamine the behavior of WFCRI under a mixture hazard model. A dynamic version\nof WFCRI also proposed and studied its behavior under proportional hazard rate\nmodel. An empirical estimation method for WFCRI under the proportional hazard\nrate model framework is also proposed, and its performance is evaluated through\nsimulation studies. Finally, we demonstrate the utility of WFCRI measure in\ncharacterizing chaotic dynamics by applying it to the Ricker and cubic maps.\nThe proposed measure is also applied to real data to assess the uncertainty.", "AI": {"tldr": "本文提出了一种新的信息度量方法——加权分数累积剩余不精确度(WFCRI)，研究了其基本性质、边界条件及在混合风险模型中的行为，并提出了动态版本和比例风险率模型下的经验估计方法，最后应用于混沌动力学和实际数据分析。", "motivation": "近年来，量化系统不精确性和不确定性的信息度量方法受到广泛关注。本文旨在引入WFCRI这一新概念，以更全面地描述和分析系统的不确定性。", "method": "建立了WFCRI的基本性质与重要边界条件；研究了混合风险模型下WFCRI的行为；提出了动态WFCRI及其在比例风险率模型中的表现；开发了比例风险率框架下的经验估计方法并通过仿真验证。", "result": "WFCRI在Ricker映射和立方映射中有效表征了混沌动力学特性；实际数据应用表明该度量能准确评估不确定性；仿真研究验证了经验估计方法的可靠性。", "conclusion": "WFCRI是一种有效的系统不确定性和不精确性量化工具，在理论分析和实际应用中均展现出优越性能，为复杂系统研究提供了新的度量视角。"}}
{"id": "2506.23015", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.23015", "abs": "https://arxiv.org/abs/2506.23015", "authors": ["Martin Bays", "Tingxiang Zou"], "title": "Non-expansion in polynomial automorphisms of $\\mathbb{C}^2$", "comment": null, "summary": "We treat the higher-dimensional Elekes-Szab\\'o problem in the case of the\naction of Aut(C^2) on C^2.", "AI": {"tldr": "本文研究了高维Elekes-Szab\\'o问题在Aut($\\mathbb{C}^2$)作用于$\\mathbb{C}^2$时的情形。", "motivation": "探讨高维Elekes-Szab\\'o问题在复平面自同构群作用下的表现，扩展了该问题的研究范围。", "method": "通过分析Aut($\\mathbb{C}^2$)群在$\\mathbb{C}^2$上的作用，运用代数几何和组合数学的方法进行研究。", "result": "得出了在高维情况下，Elekes-Szab\\'o问题在Aut($\\mathbb{C}^2$)作用下的具体性质和结论。", "conclusion": "该研究为高维Elekes-Szab\\'o问题提供了新的视角和结果，丰富了相关领域的理论体系。"}}
{"id": "2506.23654", "categories": ["math.LO", "03H05 (Primary), 03C20, 26E35 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.23654", "abs": "https://arxiv.org/abs/2506.23654", "authors": ["Peter Ouwehand"], "title": "Nonstandard Universes", "comment": null, "summary": "These notes are concerned with the existence and the basic properties of the\nset-theoretic universes for nonstandard analysis, compiled by a beginner in the\nsubject. It assumes a basic background in first-order logic, though the\nnecessary material is revised in Appendix A. Needless to say, none of the\nmaterial presented here is original, but has been adapted from standard\nsources.", "AI": {"tldr": "本文由初学者编写，总结了非标准分析中集合论宇宙的存在性与基本性质，需一阶逻辑基础。", "motivation": "旨在为非标准分析的学习者提供集合论宇宙的基础知识汇编。", "method": "回顾一阶逻辑必备内容（附录A），并整合标准文献中的现有材料。", "result": "系统呈现了非标准分析所需的集合论宇宙存在性及其核心特性。", "conclusion": "尽管内容非原创，但为初学者提供了清晰的基础框架与参考资料。"}}
{"id": "2506.22483", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2506.22483", "abs": "https://arxiv.org/abs/2506.22483", "authors": ["Hua Liu", "Zhuoma Gangji", "Yumei Wei", "Jianhua Ye", "Gang Ma"], "title": "Mathematical Modeling of Carbon Dioxide Emissions with GDP Linkage: Sensitivity Analysis and Optimal Control Strategy", "comment": null, "summary": "Climate change and global warming are among the most significant issues that\nhumanity is currently facing, and also among the issues that pose the greatest\nthreats to all mankind. These issues are primarily driven by abnormal increases\nin greenhouse gas concentrations. Mathematical modeling serves as a powerful\napproach to analyze the dynamic patterns of atmospheric carbon dioxide. In this\npaper, we established a mathmetical model with four state variables to\ninvestigate the dynamic behavior of the interaction between atmospheric carbon\ndioxide, GDP, forest area and human population. Relevant theories were employed\nto analyze the system's boundedness and the stability of equilibrium points.\nThe parameter values were estimated with the help of the actual data in China\nand numerical fitting was carried out to verify the results of the theoretical\nanalysis. The sensitivity analysis of the compartments with respect to the\nmodel parameters was analyzed by using the Partial Rank Correlation Coefficient\n(PRCC) and the Latin Hypercube Sampling test. Apply the optimal control theory\nto regulate the atmospheric carbon dioxide level and provide the corresponding\nnumerical fitting. Finally, corresponding discussions and suggestions were put\nforward with the help of the results of the theoretical analysis and numerical\nfitting.", "AI": {"tldr": "本文通过建立四状态变量数学模型，研究大气二氧化碳与GDP、森林面积及人口的动态关系，结合中国实际数据验证理论分析，提出调控建议。", "motivation": "气候变化与全球变暖是人类面临的最严峻问题之一，主要由温室气体浓度异常升高驱动，数学模型是分析大气二氧化碳动态模式的有力工具。", "method": "建立包含大气二氧化碳、GDP、森林面积和人口的数学模型，利用中国实际数据估计参数并进行数值拟合，采用PRCC和拉丁超立方抽样进行敏感性分析，应用最优控制理论调控二氧化碳水平。", "result": "理论分析与数值拟合验证了模型的边界性和平衡点稳定性，敏感性分析揭示了各组分对参数的依赖关系，最优控制理论提供了二氧化碳调控方案。", "conclusion": "基于理论分析和数值拟合结果，提出了针对大气二氧化碳调控的具体讨论与建议，为应对气候变化提供了科学依据。"}}
{"id": "2506.22521", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22521", "abs": "https://arxiv.org/abs/2506.22521", "authors": ["Kaixiang Zhao", "Lincan Li", "Kaize Ding", "Neil Zhenqiang Gong", "Yue Zhao", "Yushun Dong"], "title": "A Survey on Model Extraction Attacks and Defenses for Large Language Models", "comment": null, "summary": "Model extraction attacks pose significant security threats to deployed\nlanguage models, potentially compromising intellectual property and user\nprivacy. This survey provides a comprehensive taxonomy of LLM-specific\nextraction attacks and defenses, categorizing attacks into functionality\nextraction, training data extraction, and prompt-targeted attacks. We analyze\nvarious attack methodologies including API-based knowledge distillation, direct\nquerying, parameter recovery, and prompt stealing techniques that exploit\ntransformer architectures. We then examine defense mechanisms organized into\nmodel protection, data privacy protection, and prompt-targeted strategies,\nevaluating their effectiveness across different deployment scenarios. We\npropose specialized metrics for evaluating both attack effectiveness and\ndefense performance, addressing the specific challenges of generative language\nmodels. Through our analysis, we identify critical limitations in current\napproaches and propose promising research directions, including integrated\nattack methodologies and adaptive defense mechanisms that balance security with\nmodel utility. This work serves NLP researchers, ML engineers, and security\nprofessionals seeking to protect language models in production environments.", "AI": {"tldr": "本文综述了针对语言模型的提取攻击与防御方法，提出了分类体系并评估了现有技术的有效性，指出了当前研究的不足与未来方向。", "motivation": "模型提取攻击严重威胁语言模型的安全，可能侵犯知识产权与用户隐私，亟需系统化研究攻击类型与防御策略。", "method": "建立LLM专用攻击分类体系（功能/训练数据/提示攻击），分析API蒸馏、直接查询、参数恢复等方法；防御机制分为模型保护、数据隐私与提示策略三类。", "result": "提出生成式模型专用的攻防评估指标，揭示现有方法在平衡安全性与模型效用方面的局限性，发现集成攻击与自适应防御的研究潜力。", "conclusion": "该研究为NLP研究者与安全从业者提供系统指导，未来需开发兼顾安全与效用的动态防御方案以应对生产环境威胁。"}}
{"id": "2506.22653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22653", "abs": "https://arxiv.org/abs/2506.22653", "authors": ["Michael Grosskopf", "Russell Bent", "Rahul Somasundaram", "Isaac Michaud", "Arthur Lui", "Nathan Debardeleben", "Earl Lawrence"], "title": "URSA: The Universal Research and Scientific Agent", "comment": "31 pages, 9 figures", "summary": "Large language models (LLMs) have moved far beyond their initial form as\nsimple chatbots, now carrying out complex reasoning, planning, writing, coding,\nand research tasks. These skills overlap significantly with those that human\nscientists use day-to-day to solve complex problems that drive the cutting edge\nof research. Using LLMs in \"agentic\" AI has the potential to revolutionize\nmodern science and remove bottlenecks to progress. In this work, we present\nURSA, a scientific agent ecosystem for accelerating research tasks. URSA\nconsists of a set of modular agents and tools, including coupling to advanced\nphysics simulation codes, that can be combined to address scientific problems\nof varied complexity and impact. This work highlights the architecture of URSA,\nas well as examples that highlight the potential of the system.", "AI": {"tldr": "论文介绍了URSA科学代理生态系统，该系统利用大型语言模型（LLMs）的复杂推理能力，通过模块化代理和工具加速科研任务。", "motivation": "大型语言模型（LLMs）已具备与人类科学家相似的复杂推理、规划等能力，将其应用于‘代理型’AI有望突破科研瓶颈，推动科学发展。", "method": "URSA系统由模块化代理和工具组成，包括与高级物理模拟代码的耦合，可灵活组合以解决不同复杂度和影响力的科学问题。", "result": "论文展示了URSA的架构及实例，证明了该系统在加速科研任务方面的潜力。", "conclusion": "URSA作为一个科学代理生态系统，通过整合LLMs与专业工具，为科研提供了高效、灵活的解决方案，展现了AI驱动科学革命的广阔前景。"}}
{"id": "2506.22651", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.22651", "abs": "https://arxiv.org/abs/2506.22651", "authors": ["Adriana Cardoso", "António Machiavelo"], "title": "The Dedekind-Hasse Criterion in Quaternion Algebras", "comment": null, "summary": "We give a criterion for principal ideal orders, with the objective of\ngeneralizing for an arbitrary order some known results about the Hurwitz\nIntegers, namely, the existence and uniqueness (up to associates) of a\nleft/right factor of a given norm and the existence of a factorization in prime\nquaternions.", "AI": {"tldr": "本文提出了主理想序的一个判别准则，旨在将Hurwitz整数的已知结果推广到任意序，包括给定范数的左/右因子存在性、唯一性（相伴意义下）以及素四元数分解的存在性。", "motivation": "研究动机是推广Hurwitz整数的经典结果（如因子存在性、唯一性和素分解）到更一般的主理想序结构，以建立更广泛的代数理论框架。", "method": "通过建立主理想序的判别准则，并利用四元数代数与序理论工具，对Hurwitz整数的性质进行系统性扩展。", "result": "证明了任意主理想序中：（1）给定范数的左/右因子在相伴意义下唯一存在；（2）素四元数分解的存在性，从而推广了原有结论。", "conclusion": "该准则为研究一般序的算术性质提供了统一方法，将四元数理论中的经典结果扩展至更广泛的代数结构。"}}
{"id": "2506.22996", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.22996", "abs": "https://arxiv.org/abs/2506.22996", "authors": ["Faranak Goodarzi"], "title": "Some results about varextropy and weighted varextropy functions", "comment": null, "summary": "In this paper, we investigate several properties of the weighted varextropy\nmeasure and obtain it for specific distribution functions, such as the\nequilibrium and weighted distributions. We also obtain bounds for the weighted\nvarextropy, as well as for weighted residual varextropy and weighted past\nvarextropy. Additionally, we derive an expression for the varextropy of the\nlifetime of coherent systems. A new stochastic ordering, referred to as\nweighted varextopy orderind, is introduced, and some of its key properties are\nexplored. Furtheremore, we propose two nonparametric estimators for the\nweighted varextropy function. A simulation study is conducted to evaluate the\nperformance of these estimators in terms of mean squared error(MSE) and bias.\nFinally, we provide a characterization of the reciprocal distribution based on\nthe weighted varextropy measure. Some tests for reciprocal distribution are\nconstructed by using the proposed estimators and the powers of the tests are\ncompared with the powers of Kolmogorov-Smirnov (KS) test. application to real\ndata is also reported.", "AI": {"tldr": "本文研究了加权变熵测度的若干性质，推导了其在特定分布函数（如均衡分布和加权分布）中的表达式，并提出了新的随机排序方法。通过模拟研究评估了非参数估计器的性能，并基于加权变熵测度对倒数分布进行了表征。", "motivation": "研究加权变熵测度的性质及其在不同分布函数中的应用，旨在扩展信息论工具在统计分布分析中的适用性，并为系统寿命分析提供新的度量方法。", "method": "通过理论推导获得加权变熵测度的边界条件及表达式，提出加权变熵排序方法，构建两种非参数估计器，并通过模拟研究评估其性能（MSE和偏差）。", "result": "获得了均衡分布和加权分布的加权变熵表达式，提出了新的随机排序方法，模拟研究表明非参数估计器表现良好，并基于加权变熵测度成功表征了倒数分布。", "conclusion": "加权变熵测度为分布分析提供了有效工具，新提出的估计器和检验方法在模拟和实际数据中表现优异，其性能与KS检验相当。"}}
{"id": "2506.23054", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.23054", "abs": "https://arxiv.org/abs/2506.23054", "authors": ["Arnab Char", "Ken-ichi Kawarabayashi", "Lucas Picasarri-Arrieta"], "title": "Edge-colouring and orientations: applications to degree-boundedness and $χ$-boundedness", "comment": null, "summary": "We prove that every $2$-edge-coloured graph with sufficiently large minimum\ndegree contains a monochromatic induced subgraph whose minimum degree remains\nlarge.\n  As a consequence, we deduce that some classes of graphs are degree-bounded. A\nclass $\\mathcal{G}$ is {\\it degree-bounded} if, for every integer $s$, there\nexists $d=d(s)$ such that every graph $G\\in \\mathcal{G}$ either contains\n$K_{s,s}$ or has minimum degree at most $d$. We obtain that the following\nclasses are degree-bounded: (i) for every $k$, the graphs $G$ whose edge-set\ncan be $k$-coloured such that no even hole of $G$ is monochromatic; (ii) for\nevery fixed antidirected forest $F$, the graphs admitting an orientation\nwithout any induced copy of $F$; (iii) for every $\\ell\\geq 4$, the graphs\nadmitting an orientation without any induced antidirected cycle of length at\nleast $\\ell$.\n  For $k=2$, class (i) contains odd-signable graphs. Class (ii) characterises\nthe oriented graphs $H$ such that the class of graphs admitting an orientation\nwithout any induced copy of $H$ is degree-bounded. For $\\ell=5$, class (iii)\ncontains Burling graphs. In case (i) and case (iii) for $\\ell=4$, we further\nobtain that the classes are polynomially $\\chi$-bounded.", "AI": {"tldr": "证明了在足够大的最小度条件下，每张2边着色图都包含一个最小度仍保持较大的单色诱导子图，并推导出某些图类是度有界的。", "motivation": "研究图的最小度与单色诱导子图的关系，探索特定图类的度有界性质及其在着色和定向问题中的应用。", "method": "通过分析2边着色图的结构性质，结合极值图论方法，证明单色诱导子图的存在性，并推广到特定图类的度有界性证明。", "result": "确定了三类图是度有界的：(i)无单色偶洞的k边着色图；(ii)不含特定逆向森林的定向图；(iii)不含长逆向环的定向图。部分结果还进一步证明了多项式χ有界性。", "conclusion": "该研究不仅扩展了Ramsey理论在图着色中的应用，还为定向图和着色图的度约束提供了新的理论工具，特别适用于奇可签名图和Burling图等特殊图类。"}}
{"id": "2506.23168", "categories": ["cs.AI", "cs.DM", "math.CO", "math.RA", "06B99", "G.2.1"], "pdf": "https://arxiv.org/pdf/2506.23168", "abs": "https://arxiv.org/abs/2506.23168", "authors": ["Mohammad Abdulla", "Tobias Hille", "Dominik Dürrschnabel", "Gerd Stumme"], "title": "Rises for Measuring Local Distributivity in Lattices", "comment": "16 pages, 2 tables, 5 figures, International Joint Conference on\n  Conceptual Knowledge Structures", "summary": "Distributivity is a well-established and extensively studied notion in\nlattice theory. In the context of data analysis, particularly within Formal\nConcept Analysis (FCA), lattices are often observed to exhibit a high degree of\ndistributivity. However, no standardized measure exists to quantify this\nproperty. In this paper, we introduce the notion of rises in (concept) lattices\nas a means to assess distributivity. Rises capture how the number of attributes\nor objects in covering concepts change within the concept lattice. We show that\na lattice is distributive if and only if no non-unit rises occur. Furthermore,\nwe relate rises to the classical notion of meet- and join distributivity. We\nobserve that concept lattices from real-world data are to a high degree\njoin-distributive, but much less meet-distributive. We additionally study how\njoin-distributivity manifests on the level of ordered sets.", "AI": {"tldr": "本文提出使用'上升'概念量化概念格的分配性，证明格完全分配的充要条件，并发现现实数据概念格高度满足并分配性而非交分配性。", "motivation": "形式概念分析中概念格常呈现高度分配性，但缺乏标准化度量方法。研究旨在建立量化分配性的新指标。", "method": "引入概念格中'上升'的定义，通过覆盖概念内属性/对象数量的变化评估分配性，关联经典交/并分配理论。", "result": "证明格完全分配当且仅当无非单位上升；现实概念格普遍具有高并分配性但低交分配性。", "conclusion": "上升是量化分配性的有效工具，揭示了现实数据概念格在序集层面上呈现的分配特性差异。"}}
{"id": "2506.22514", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2506.22514", "abs": "https://arxiv.org/abs/2506.22514", "authors": ["Anis Matoussi", "Guillaume Broux-Quemerais", "Zhou Chao"], "title": "Optimal investment and consumption under forward utilities with relative performance concerns", "comment": null, "summary": "We study a n-player and mean-field portfolio optimization problem under\nrelative performance concerns with non-zero volatility, for wealth and\nconsumption. The consistency assumption defining forward relative performance\nprocesses leads to a sufficient characterization of such processes with mean of\na Stochastic HJB equations, which highlights the link between wealth and\nconsumption utility, and also characterizes the optimal strategies. In\nparticular, forward relative performance processes with a wealth utility of\nCRRA type and separable time and space dependence necessarily have a\nconsumption utility of the same form, with the same risk aversion parameter.\nThis characterization gives a better understanding of the drift condition\nensuring time consistency. In this setting, we establish closed form of the\nNash equilibrium for both the n-player and mean eld problems. We also provide\nsome numerical examples.", "AI": {"tldr": "本文研究了具有相对绩效关注的n玩家和均值场投资组合优化问题，通过随机HJB方程刻画了前向相对绩效过程，揭示了财富与消费效用的联系，并给出了CRRA型效用下的纳什均衡闭式解。", "motivation": "探讨非零波动率下财富与消费的相对绩效优化问题，旨在理解时间一致性条件及最优策略特征。", "method": "采用随机HJB方程对前向相对绩效过程进行充分表征，结合CRRA型财富效用和可分离时空依赖性的假设。", "result": "证明了CRRA型财富效用必然对应相同风险厌恶参数的消费效用，并给出了n玩家及均值场问题的纳什均衡闭式解。", "conclusion": "研究深化了对时间一致性漂移条件的理解，并通过数值算例验证了理论结果的实际应用价值。"}}
{"id": "2506.22557", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22557", "abs": "https://arxiv.org/abs/2506.22557", "authors": ["Boyuan Chen", "Minghao Shao", "Abdul Basit", "Siddharth Garg", "Muhammad Shafique"], "title": "MetaCipher: A General and Extensible Reinforcement Learning Framework for Obfuscation-Based Jailbreak Attacks on Black-Box LLMs", "comment": null, "summary": "The growing capabilities of large language models (LLMs) have exposed them to\nincreasingly sophisticated jailbreak attacks. Among these, obfuscation-based\nattacks -- which encrypt malicious content to evade detection -- remain highly\neffective. By leveraging the reasoning ability of advanced LLMs to interpret\nencrypted prompts, such attacks circumvent conventional defenses that rely on\nkeyword detection or context filtering. These methods are very difficult to\ndefend against, as existing safety mechanisms are not designed to interpret or\ndecode ciphered content. In this work, we propose \\textbf{MetaCipher}, a novel\nobfuscation-based jailbreak framework, along with a reinforcement\nlearning-based dynamic cipher selection mechanism that adaptively chooses\noptimal encryption strategies from a cipher pool. This approach enhances\njailbreak effectiveness and generalizability across diverse task types, victim\nLLMs, and safety guardrails. Our framework is modular and extensible by design,\nsupporting arbitrary cipher families and accommodating evolving adversarial\nstrategies. We complement our method with a large-scale empirical analysis of\ncipher performance across multiple victim LLMs. Within as few as 10 queries,\nMetaCipher achieves over 92\\% attack success rate (ASR) on most recent standard\nmalicious prompt benchmarks against state-of-the-art non-reasoning LLMs, and\nover 74\\% ASR against reasoning-capable LLMs, outperforming all existing\nobfuscation-based jailbreak methods. These results highlight the long-term\nrobustness and adaptability of our approach, making it more resilient than\nprior methods in the face of advancing safety measures.", "AI": {"tldr": "本文提出MetaCipher框架，通过强化学习动态选择加密策略，显著提升大型语言模型(LLM)越狱攻击的成功率，在10次查询内对非推理型LLM达到92%攻击成功率，对推理型LLM达74%。", "motivation": "现有安全机制无法有效检测加密恶意内容，基于混淆的越狱攻击利用LLM的推理能力破解加密提示，亟需新型防御方案。", "method": "提出模块化框架MetaCipher，结合强化学习的动态密码选择机制，从密码池自适应选择最优加密策略，支持任意密码家族扩展。", "result": "实验显示：在最新恶意提示基准测试中，对非推理型LLM攻击成功率超92%，推理型LLM达74%，优于现有所有混淆攻击方法。", "conclusion": "MetaCipher具有长期鲁棒性和适应性，能有效应对不断升级的安全措施，为LLM安全防御提出新挑战。"}}
{"id": "2506.22740", "categories": ["cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.22740", "abs": "https://arxiv.org/abs/2506.22740", "authors": ["Jessica Hullman", "Ziyang Guo", "Berk Ustun"], "title": "Explanations are a means to an end", "comment": null, "summary": "Modern methods for explainable machine learning are designed to describe how\nmodels map inputs to outputs--without deep consideration of how these\nexplanations will be used in practice. This paper argues that explanations\nshould be designed and evaluated with a specific end in mind. We describe how\nto formalize this end in a framework based in statistical decision theory. We\nshow how this functionally-grounded approach can be applied across diverse use\ncases, such as clinical decision support, providing recourse, or debugging. We\ndemonstrate its use to characterize the maximum \"boost\" in performance on a\nparticular task that an explanation could provide an idealized decision-maker,\npreventing misuse due to ambiguity by forcing researchers to specify concrete\nuse cases that can be analyzed in light of models of expected explanation use.\nWe argue that evaluation should meld theoretical and empirical perspectives on\nthe value of explanation, and contribute definitions that span these\nperspectives.", "AI": {"tldr": "本文提出了一种基于统计决策理论的功能性解释框架，强调解释应针对具体应用场景设计，并通过理论和实证相结合的方法评估其价值。", "motivation": "当前可解释机器学习方法主要关注模型输入输出映射，缺乏对解释实际应用场景的深入考虑。本文主张解释应围绕特定目标设计和评估。", "method": "采用统计决策理论框架，将解释功能形式化，并应用于临床决策支持、提供补救措施和模型调试等多样化用例。通过定义理想决策者能获得的性能\"提升\"来量化解释价值。", "result": "该框架能有效防止解释的模糊性误用，要求研究者明确具体用例，并基于预期解释使用模型进行分析。提出了跨越理论和实证视角的解释价值评估定义。", "conclusion": "解释设计和评估需要结合具体功能目标，通过理论建模与实证分析相结合的方式，才能实现解释在实践中的有效应用。"}}
{"id": "2506.22667", "categories": ["math.NT", "11N36, 11A25, 11L40"], "pdf": "https://arxiv.org/pdf/2506.22667", "abs": "https://arxiv.org/abs/2506.22667", "authors": ["Cameron Wilson"], "title": "An improved large sieve for quadratic characters via Hooley neutralisers and its applications", "comment": "Comments welcome. This paper has been separated from a previous paper\n  [arXiv:2404.11489]. arXiv admin note: substantial text overlap with\n  arXiv:2404.11489", "summary": "We combine Hooley neutralisers and the large sieve for quadratic characters.\nWe give applications to character sums with a hyperbolic height condition.", "AI": {"tldr": "该论文结合Hooley中和器与二次特征的大筛法，应用于双曲高度条件下的特征和问题。", "motivation": "研究旨在解决双曲高度条件下特征和的计算问题，为相关数论问题提供新工具。", "method": "通过结合Hooley中和器与二次特征的大筛法技术，构建新的分析方法。", "result": "成功推导出双曲高度条件下特征和的有效估计，拓展了筛法应用范围。", "conclusion": "该方法为数论中特征和问题提供了新的研究途径，具有潜在的理论价值。"}}
{"id": "2506.23010", "categories": ["math.ST", "cs.IT", "cs.LG", "math.IT", "math.PR", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.23010", "abs": "https://arxiv.org/abs/2506.23010", "authors": ["Max Lovig", "Tianhao Wang", "Zhou Fan"], "title": "On Universality of Non-Separable Approximate Message Passing Algorithms", "comment": null, "summary": "Mean-field characterizations of first-order iterative algorithms -- including\nApproximate Message Passing (AMP), stochastic and proximal gradient descent,\nand Langevin diffusions -- have enabled a precise understanding of learning\ndynamics in many statistical applications. For algorithms whose non-linearities\nhave a coordinate-separable form, it is known that such characterizations enjoy\na degree of universality with respect to the underlying data distribution.\nHowever, mean-field characterizations of non-separable algorithm dynamics have\nlargely remained restricted to i.i.d. Gaussian or rotationally-invariant data.\n  In this work, we initiate a study of universality for non-separable AMP\nalgorithms. We identify a general condition for AMP with polynomial\nnon-linearities, in terms of a Bounded Composition Property (BCP) for their\nrepresenting tensors, to admit a state evolution that holds universally for\nmatrices with non-Gaussian entries. We then formalize a condition of\nBCP-approximability for Lipschitz AMP algorithms to enjoy a similar universal\nguarantee. We demonstrate that many common classes of non-separable\nnon-linearities are BCP-approximable, including local denoisers, spectral\ndenoisers for generic signals, and compositions of separable functions with\ngeneric linear maps, implying the universality of state evolution for AMP\nalgorithms employing these non-linearities.", "AI": {"tldr": "本文研究了非可分离近似消息传递（AMP）算法的普适性，提出了一种称为有界组合性质（BCP）的条件，使得多项式非线性AMP算法在非高斯矩阵输入下仍能保持状态演化的普适性。", "motivation": "现有均值场理论主要局限于可分离非线性或高斯/旋转不变数据，缺乏对非可分离AMP算法普适性的系统研究。", "method": "提出了BCP条件（多项式非线性）和BCP可逼近性条件（Lipschitz非线性），通过张量表示理论分析算法动力学。", "result": "证明局部降噪器、通用信号的谱降噪器以及可分离函数与线性映射的组合等常见非线性都满足BCP可逼近性，从而保证相应AMP算法的普适状态演化。", "conclusion": "该研究扩展了AMP理论框架，首次系统建立了非可分离非线性在非高斯数据下的普适性保证，为更广泛算法的动力学分析提供了工具。"}}
{"id": "2506.23082", "categories": ["math.CO", "Primary: 05A15, Secondary: 05A30"], "pdf": "https://arxiv.org/pdf/2506.23082", "abs": "https://arxiv.org/abs/2506.23082", "authors": ["Jang Soo Kim", "Seung Jin Lee", "Meesue Yoo"], "title": "Hall--Littlewood expansions of chromatic quasisymmetric polynomials using linked rook placements", "comment": "23 pages, 18 figures", "summary": "In this work, we obtain a Hall--Littlewood expansion of the chromatic\nquasisymmetric function arising from a natural unit interval order and describe\nthe coefficients in terms of linked rook placements. Applying the\nCarlsson--Mellit relation between chromatic quasisymmetric functions and\nunicellular LLT polynomials, we also obtain a combinatorial description for the\ncoefficients of the unicellular LLT polynomials expanded in terms of the\nmodified transformed Hall--Littlewood polynomials.", "AI": {"tldr": "本文通过自然单位区间序获得色拟对称函数的Hall-Littlewood展开，并用关联车布局描述系数，同时应用Carlsson-Mellit关系给出了单细胞LLT多项式在修正变换Hall-Littlewood基下展开系数的组合描述。", "motivation": "研究色拟对称函数与单细胞LLT多项式在不同多项式基下的展开关系，旨在揭示其组合意义。", "method": "利用自然单位区间序构造色拟对称函数的Hall-Littlewood展开，通过关联车布局描述系数，并应用Carlsson-Mellit关系连接LLT多项式。", "result": "获得了色拟对称函数的Hall-Littlewood展开系数与关联车布局的明确对应关系，并给出了单细胞LLT多项式在修正变换Hall-Littlewood基下展开的组合解释。", "conclusion": "该工作建立了色拟对称函数与LLT多项式展开的显式组合联系，为相关对称函数理论提供了新的组合视角。"}}
{"id": "2506.23989", "categories": ["math.CO", "cs.CC", "cs.DM"], "pdf": "https://arxiv.org/pdf/2506.23989", "abs": "https://arxiv.org/abs/2506.23989", "authors": ["Igor Balla", "Lianna Hambardzumyan", "István Tomon"], "title": "Factorization norms and an inverse theorem for MaxCut", "comment": "23 pages, includes parts of the preprint arxiv:2502.18429 (which will\n  not be published)", "summary": "We prove that Boolean matrices with bounded $\\gamma_2$-norm or bounded\nnormalized trace norm must contain a linear-sized all-ones or all-zeros\nsubmatrix, verifying a conjecture of Hambardzumyan, Hatami, and Hatami. We also\npresent further structural results about Boolean matrices of bounded\n$\\gamma_2$-norm and discuss applications in communication complexity, operator\ntheory, spectral graph theory, and extremal combinatorics.\n  As a key application, we establish an inverse theorem for MaxCut. A\ncelebrated result of Edwards states that every graph $G$ with $m$ edges has a\ncut of size at least $\\frac{m}{2}+\\frac{\\sqrt{8m+1}-1}{8}$, with equality\nachieved by complete graphs with an odd number of vertices. To contrast this,\nwe prove that if the MaxCut of $G$ is at most $\\frac{m}{2}+O(\\sqrt{m})$, then\n$G$ must contain a clique of size $\\Omega(\\sqrt{m})$.", "AI": {"tldr": "本文证明了具有有界$\\gamma_2$-范数或归一化迹范数的布尔矩阵必须包含线性大小的全1或全0子矩阵，验证了Hambardzumyan等人的猜想，并讨论了其在多个领域的应用。", "motivation": "研究布尔矩阵的结构性质，验证Hambardzumyan等人的猜想，并探索其在通信复杂度、算子理论、谱图论和极值组合学中的应用。", "method": "通过分析布尔矩阵的$\\gamma_2$-范数和归一化迹范数，结合极值组合学和图论方法，证明了主要结果。", "result": "证明了布尔矩阵在有界$\\gamma_2$-范数或归一化迹范数下必须包含线性大小的全1或全0子矩阵，并建立了MaxCut的逆定理。", "conclusion": "该研究不仅验证了猜想，还提供了关于布尔矩阵结构的新见解，并在多个领域展示了其应用价值，特别是MaxCut逆定理的建立。"}}
{"id": "2506.22524", "categories": ["math.OC", "cs.DS", "math.PR", "60G51, 90B05, 93E20", "I.2.6; G.3"], "pdf": "https://arxiv.org/pdf/2506.22524", "abs": "https://arxiv.org/abs/2506.22524", "authors": ["Ryoya Koide", "Yurika Ono", "Aya Ishigaki"], "title": "Inventory Control Using a Lévy Process for Evaluating Total Costs under Intermittent Demand", "comment": null, "summary": "Products with intermittent demand are characterized by a high risk of sales\nlosses and obsolescence due to the sporadic occurrence of demand events.\nGenerally, both point forecasting and probabilistic forecasting approaches are\napplied to intermittent demand. In particular, probabilistic forecasting, which\nmodels demand as a stochastic process, is capable of capturing uncertainty. An\nexample of such modeling is the use of L\\'evy processes, which possess\nindependent increments and accommodate discontinuous changes (jumps). However,\nto the best of our knowledge, in inventory control using L\\'evy processes, no\nstudies have investigated how the order quantity and reorder point affect the\ntotal cost. One major difficulty has been the mathematical formulation of\ninventory replenishment triggered at reorder points. To address this challenge,\nthe present study formulates a reorder-point policy by modeling cumulative\ndemand as a drifted Poisson process and introducing a stopping time to\nrepresent the timing at which the reorder point is reached. Furthermore, the\nvalidity of the proposed method is verified by comparing the total cost with\nthat obtained from a case where an ARIMA model is combined with a reorder-point\npolicy. As a main result, while the total cost under ARIMA-based forecasting\nincreases linearly over time, the L\\'evy process-based formulation provides an\nanalytical expression for the total cost, revealing that random demand\nfluctuations cause the expected total cost to grow at a rate faster than\nlinear.", "AI": {"tldr": "间歇性需求产品存在销售损失和过时的高风险。本研究通过将累积需求建模为漂移泊松过程，并引入停止时间来表示达到再订购点的时机，解决了基于L\\'evy过程的库存控制中订单量和再订购点对总成本影响的未解问题。", "motivation": "间歇性需求产品由于需求事件的偶发性，存在高风险的销售损失和过时。虽然概率预测方法（如L\\'evy过程）能够捕捉不确定性，但在库存控制中，订单量和再订购点如何影响总成本尚未有研究。", "method": "本研究通过将累积需求建模为漂移泊松过程，并引入停止时间来表示达到再订购点的时机，从而制定再订购点策略。此外，通过将总成本与ARIMA模型结合再订购点策略的结果进行比较，验证了所提方法的有效性。", "result": "主要结果表明，基于ARIMA预测的总成本随时间线性增长，而基于L\\'evy过程的公式提供了总成本的解析表达式，揭示了随机需求波动导致预期总成本以快于线性的速度增长。", "conclusion": "本研究通过L\\'evy过程建模间歇性需求，提供了库存控制中总成本的解析表达式，揭示了需求波动对成本增长的加速效应，为间歇性需求产品的库存管理提供了新的理论支持。"}}
{"id": "2506.22606", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22606", "abs": "https://arxiv.org/abs/2506.22606", "authors": ["Osama Zafar", "Mina Namazi", "Yuqiao Xu", "Youngjin Yoo", "Erman Ayday"], "title": "A User-Centric, Privacy-Preserving, and Verifiable Ecosystem for Personal Data Management and Utilization", "comment": null, "summary": "In the current paradigm of digital personalized services, the centralized\nmanagement of personal data raises significant privacy concerns, security\nvulnerabilities, and diminished individual autonomy over sensitive information.\nDespite their efficiency, traditional centralized architectures frequently fail\nto satisfy rigorous privacy requirements and expose users to data breaches and\nunauthorized access risks. This pressing challenge calls for a fundamental\nparadigm shift in methodologies for collecting, storing, and utilizing personal\ndata across diverse sectors, including education, healthcare, and finance.\n  This paper introduces a novel decentralized, privacy-preserving architecture\nthat handles heterogeneous personal information, ranging from educational\ncredentials to health records and financial data. Unlike traditional models,\nour system grants users complete data ownership and control, allowing them to\nselectively share information without compromising privacy. The architecture's\nfoundation comprises advanced privacy-enhancing technologies, including secure\nenclaves and federated learning, enabling secure computation, verification, and\ndata sharing. The system supports diverse functionalities, including local\ncomputation, model training, and privacy-preserving data sharing, while\nensuring data credibility and robust user privacy.", "AI": {"tldr": "本文提出了一种新型的去中心化隐私保护架构，旨在解决集中式个人数据管理带来的隐私和安全问题，赋予用户数据所有权和选择性共享能力。", "motivation": "当前集中式个人数据管理模式存在隐私泄露、安全漏洞和用户自主权缺失等问题，亟需一种新的方法来安全收集、存储和使用跨领域个人数据。", "method": "采用安全飞地和联邦学习等隐私增强技术，构建支持本地计算、模型训练和隐私保护数据共享的去中心化架构，确保数据可信性和用户隐私。", "result": "该系统实现了对教育证书、健康记录和财务数据等异构个人信息的隐私保护处理，用户可完全掌控数据共享权限。", "conclusion": "该去中心化架构为个人数据管理提供了安全、可控的解决方案，有望在医疗、教育、金融等领域推动隐私保护范式的革新。"}}
{"id": "2506.22774", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.22774", "abs": "https://arxiv.org/abs/2506.22774", "authors": ["Michael Papademas", "Xenia Ziouvelou", "Antonis Troumpoukis", "Vangelis Karkaletsis"], "title": "Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems", "comment": null, "summary": "Artificial Intelligence (AI) technology epitomizes the complex challenges\nposed by human-made artifacts, particularly those widely integrated into\nsociety and exert significant influence, highlighting potential benefits and\ntheir negative consequences. While other technologies may also pose substantial\nrisks, AI's pervasive reach makes its societal effects especially profound. The\ncomplexity of AI systems, coupled with their remarkable capabilities, can lead\nto a reliance on technologies that operate beyond direct human oversight or\nunderstanding. To mitigate the risks that arise, several theoretical tools and\nguidelines have been developed, alongside efforts to create technological tools\naimed at safeguarding Trustworthy AI. The guidelines take a more holistic view\nof the issue but fail to provide techniques for quantifying trustworthiness.\nConversely, while technological tools are better at achieving such\nquantification, they lack a holistic perspective, focusing instead on specific\naspects of Trustworthy AI. This paper aims to introduce an assessment method\nthat combines the ethical components of Trustworthy AI with the algorithmic\nprocesses of PageRank and TrustRank. The goal is to establish an assessment\nframework that minimizes the subjectivity inherent in the self-assessment\ntechniques prevalent in the field by introducing algorithmic criteria. The\napplication of our approach indicates that a holistic assessment of an AI\nsystem's trustworthiness can be achieved by providing quantitative insights\nwhile considering the theoretical content of relevant guidelines.", "AI": {"tldr": "本文提出一种结合伦理准则与PageRank/TrustRank算法的AI可信度评估方法，旨在量化评估的同时保持理论完整性。", "motivation": "AI技术的社会影响深远且复杂，现有可信AI指南缺乏量化方法，而技术工具又过于片面，需结合两者优势。", "method": "将可信AI的伦理组件与PageRank/TrustRank算法流程结合，建立减少主观性的算法化评估框架。", "result": "应用表明该方法能通过量化分析实现整体可信度评估，同时兼顾伦理指南的理论内涵。", "conclusion": "融合伦理准则与算法标准可平衡量化与全面性，为AI可信度评估提供更客观的解决方案。"}}
{"id": "2506.22825", "categories": ["math.NT", "math.QA", "math.RA", "14L17, 17B05"], "pdf": "https://arxiv.org/pdf/2506.22825", "abs": "https://arxiv.org/abs/2506.22825", "authors": ["Hanamichi Kawamura"], "title": "A Note on Flexion Units", "comment": null, "summary": "This article is a survey of Ecalle's theory of flexion units. In particular,\nwe provide complete proofs of several key assertions that were stated without\nproof in Ecalle's original works. These results are crucial for understanding\napplications of flexion units to the theory of multiple zeta values and the\nKashiwara-Vergne problem.", "AI": {"tldr": "本文综述了Ecalle的屈折单元理论，并补充了原始文献中未证明的关键断言，这些结果对多重zeta值和Kashiwara-Vergne问题的应用至关重要。", "motivation": "Ecalle的屈折单元理论在多重zeta值和Kashiwara-Vergne问题中有重要应用，但原始文献中多个关键断言缺乏证明，本文旨在填补这一空白。", "method": "通过系统梳理Ecalle理论框架，对屈折单元的核心命题进行严格证明，采用代数与解析相结合的研究方法。", "result": "完整证明了Ecalle原始工作中若干未论证的关键命题，确立了屈折单元理论与多重zeta值之间的严格数学联系。", "conclusion": "本研究不仅完善了屈折单元的理论基础，更为其在数论和李理论中的进一步应用提供了坚实的数学保障。"}}
{"id": "2506.23059", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.23059", "abs": "https://arxiv.org/abs/2506.23059", "authors": ["Rong Jiang", "M. C. Jones", "Keming Yu", "Jiangfeng Wang"], "title": "Average quantile regression: a new non-mean regression model and coherent risk measure", "comment": null, "summary": "Regression models that go beyond the mean, alongside coherent risk measures,\nhave been important tools in modern data analysis. This paper introduces the\ninnovative concept of Average Quantile Regression (AQR), which is smooth at the\nquantile-like level, comonotonically additive, and explicitly accounts for the\nseverity of tail losses relative to quantile regression. AQR serves as a\nversatile regression model capable of describing distributional information\nacross all positions, akin to quantile regression, yet offering enhanced\ninterpretability compared to expectiles. Numerous traditional regression models\nand coherent risk measures can be regarded as special cases of AQR. As a\nflexible non-parametric regression model, AQR demonstrates outstanding\nperformance in analyzing high-dimensional and large datasets, particularly\nthose generated by distributed systems, and provides a convenient framework for\ntheir statistical analysis. The corresponding estimators are rigorously\nderived, and their asymptotic properties are thoroughly developed. In a risk\nmanagement context, the case study confirms AQR's effectiveness in risk\nassessment and portfolio optimization.", "AI": {"tldr": "本文提出平均分位数回归（AQR）新方法，兼具平滑性、共单调可加性及尾部损失敏感性，优于传统分位数回归和期望回归，适用于高维大数据分析及风险管理。", "motivation": "传统回归模型和风险度量工具在描述分布信息和尾部风险时存在局限，需开发兼具解释力和灵活性的新方法。", "method": "提出AQR模型：通过光滑分位数水平实现共单调可加性，显式量化尾部损失，推导估计量并建立渐近理论框架。", "result": "AQR能统一多种经典回归模型与风险度量，在分布式系统高维数据分析和投资组合优化中表现优异。", "conclusion": "AQR为风险管理提供强有力工具，案例验证其在风险评估与组合优化中的有效性，具有广泛应用潜力。"}}
{"id": "2506.23124", "categories": ["math.CO", "52C35, 52C30, 14N20, 32S22", "G.2.1"], "pdf": "https://arxiv.org/pdf/2506.23124", "abs": "https://arxiv.org/abs/2506.23124", "authors": ["Pragnya Das", "Takuya Saito", "Simona Settepanella"], "title": "Arithmetic non-generic arrangements", "comment": null, "summary": "A discriminantal hyperplane arrangement B(n,k,A) is constructed from a given\n(generic) hyperplane arrangement A, which is classified as either very generic\nor non-very generic depending on the combinatorial structure of B(n,k,A). In\nparticular, A is considered non-very generic if the intersection lattice of\nB(n,k,A) contains at least one non-very generic intersection -- that is, an\nintersection that fails to satisfy a specific rank condition established by\nAthanasiadis in [1]. In this paper, we present arithmetic criteria\ncharacterizing non-very generic intersections in discriminantal arrangements\nand we complete and correct a previous result by Libgober and the third author\nconcerning rank-two intersections in such arrangements.", "AI": {"tldr": "本文研究了判别超平面构型B(n,k,A)中的非非常一般交点，提出了算术准则来刻画这些交点，并修正了先前关于此类构型中二阶交点的结果。", "motivation": "研究判别超平面构型中非非常一般交点的特性，以完善对这类构型组合结构的理解，并纠正先前研究中的错误。", "method": "通过分析判别超平面构型B(n,k,A)的交点格，特别是非非常一般交点，建立算术准则来刻画这些交点。", "result": "提出了非非常一般交点的算术准则，并修正了Libgober和第三作者关于判别超平面构型中二阶交点的结果。", "conclusion": "本文的工作完善了对判别超平面构型中非非常一般交点的理解，并为相关研究提供了更准确的数学工具。"}}
{"id": "2506.22526", "categories": ["math.OC", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2506.22526", "abs": "https://arxiv.org/abs/2506.22526", "authors": ["Ofer M. Shir", "Michael Emmerich"], "title": "Correlated Mutations for Integer Programming", "comment": null, "summary": "Even with the recent theoretical advancements that dramatically reduced the\ncomplexity of Integer Programming (IP), heuristics remain the dominant\nproblem-solvers for this difficult category. This study seeks to establish the\ngroundwork for Integer Evolution Strategies (IESs), a class of randomized\nsearch heuristics inherently designed for continuous spaces. IESs already excel\nin treating IP in practice, but accomplish it via discretization and by\napplying sophisticated patches to their continuous operators, while\npersistently using the $\\ell_2$-norm as their operation pillar. We lay\nfoundations for discrete search, by adopting the $\\ell_1$-norm, accounting for\nthe suitable step-size, and questioning alternative measures to quantify\ncorrelations over the integer lattice. We focus on mutation distributions for\nunbounded integer decision variables. We briefly discuss a couple of candidate\ndiscrete probabilities induced by the uniform and binomial distributions, which\nwe show to possess less appealing theoretical properties, and then narrow down\nto the Truncated Normal (TN) and Double Geometric (DG) distributions. We\nexplore their theoretical properties, including entropy functions, and propose\na procedure to generate scalable correlated mutation distributions. Our\ninvestigations are accompanied by extensive numerical simulations, which\nconsistently support the claim that the DG distribution is better suited for\nunbounded integer search. We link our theoretical perspective to empirical\nevidence indicating that an IES with correlated DG mutations outperformed other\nstrategies over non-separable quadratic IP. We conclude that while the\nreplacement of the default TN distribution by the DG is theoretically justified\nand practically beneficial, the truly crucial change lies in adopting the\n$\\ell_1$-norm over the $\\ell_2$-norm.", "AI": {"tldr": "本文为整数进化策略(IES)奠定理论基础，提出采用$\\ell_1$-范数替代传统$\\ell_2$-范数，并证明双几何分布(DG)比截断正态分布(TN)更适合无界整数搜索。", "motivation": "尽管整数规划(IP)理论复杂度降低，启发式算法仍是主流解法。现有IES通过离散化处理连续空间算子，但始终依赖$\\ell_2$-范数，需建立更适合离散搜索的理论框架。", "method": "研究采用$\\ell_1$-范数，分析步长选择，探讨整数格上相关性度量。重点研究无界整数决策变量的变异分布，比较均匀分布、二项分布、TN和DG的理论特性，提出可扩展的相关变异分布生成方法。", "result": "数值模拟表明DG分布更适合无界整数搜索。实证显示采用相关DG变异的IES在非可分二次IP问题中表现最优。理论分析支持用DG替代TN分布，但最关键的是采用$\\ell_1$-范数。", "conclusion": "虽然用DG替代TN分布具有理论和实践优势，但最根本的改进在于采用$\\ell_1$-范数而非$\\ell_2$-范数作为操作基础。"}}
{"id": "2506.22639", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.22639", "abs": "https://arxiv.org/abs/2506.22639", "authors": ["Michael A. Specter", "Mihai Christodorescu", "Abbie Farr", "Bo Ma", "Robin Lassonde", "Xiaoyang Xu", "Xiang Pan", "Fengguo Wei", "Saswat Anand", "Dave Kleidermacher"], "title": "Fingerprinting SDKs for Mobile Apps and Where to Find Them: Understanding the Market for Device Fingerprinting", "comment": "To appear in ACM CCS 2025. Extended from conference version; has\n  added appendices more inclusive author list", "summary": "This paper presents a large-scale analysis of fingerprinting-like behavior in\nthe mobile application ecosystem. We take a market-based approach, focusing on\nthird-party tracking as enabled by applications' common use of third-party\nSDKs. Our dataset consists of over 228,000 SDKs from popular Maven\nrepositories, 178,000 Android applications collected from the Google Play\nstore, and our static analysis pipeline detects exfiltration of over 500\nindividual signals. To the best of our knowledge, this represents the\nlargest-scale analysis of SDK behavior undertaken to date.\n  We find that Ads SDKs (the ostensible focus of industry efforts such as\nApple's App Tracking Transparency and Google's Privacy Sandbox) appear to be\nthe source of only 30.56% of the fingerprinting behaviors. A surprising 23.92%\noriginate from SDKs whose purpose was unknown or unclear. Furthermore, Security\nand Authentication SDKs are linked to only 11.7% of likely fingerprinting\ninstances. These results suggest that addressing fingerprinting solely in\nspecific market-segment contexts like advertising may offer incomplete benefit.\nEnforcing anti-fingerprinting policies is also complex, as we observe a sparse\ndistribution of signals and APIs used by likely fingerprinting SDKs. For\ninstance, only 2% of exfiltrated APIs are used by more than 75% of SDKs, making\nit difficult to rely on user permissions to control fingerprinting behavior.", "AI": {"tldr": "本文对移动应用生态系统中的指纹识别行为进行了大规模分析，发现广告SDK仅占30.56%的指纹行为，而23.92%来自用途不明的SDK，表明仅针对广告领域的反指纹措施效果有限。", "motivation": "研究动机是揭示移动应用生态系统中第三方SDK的指纹识别行为现状，评估现有隐私保护措施（如苹果的ATT和谷歌的隐私沙盒）的实际效果。", "method": "研究方法包括收集228,000个Maven仓库SDK和178,000个Google Play应用数据，通过静态分析管道检测500多个信号的外泄行为。", "result": "结果显示：广告SDK仅贡献30.56%的指纹行为，23.92%来自未知用途SDK，安全认证类SDK占11.7%。指纹行为涉及的API分布稀疏，仅2%的API被75%以上SDK使用。", "conclusion": "结论指出：仅针对特定领域（如广告）的反指纹策略效果不完整，且由于API使用高度分散，依赖用户权限控制指纹行为存在困难。"}}
{"id": "2506.22865", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22865", "abs": "https://arxiv.org/abs/2506.22865", "authors": ["Ziqi Zhong", "Xunzhu Tang"], "title": "ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have revealed a\nsignificant performance gap between closed-source and open-source models,\nparticularly in tasks requiring complex reasoning and precise instruction\nfollowing. This paper introduces ReasonBridge, a methodology that efficiently\ntransfers reasoning capabilities from powerful closed-source to open-source\nmodels through a novel hierarchical knowledge distillation framework. We\ndevelop a tailored dataset Reason1K with only 1,000 carefully curated reasoning\ntraces emphasizing difficulty, diversity, and quality. These traces are\nfiltered from across multiple domains using a structured multi-criteria\nselection algorithm. Our transfer learning approach incorporates: (1) a\nhierarchical distillation process capturing both strategic abstraction and\ntactical implementation patterns, (2) a sparse reasoning-focused adapter\narchitecture requiring only 0.3% additional trainable parameters, and (3) a\ntest-time compute scaling mechanism using guided inference interventions.\nComprehensive evaluations demonstrate that ReasonBridge improves reasoning\ncapabilities in open-source models by up to 23% on benchmark tasks,\nsignificantly narrowing the gap with closed-source models. Notably, the\nenhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its\nperformance on competition-level AIME problems. Our methodology generalizes\neffectively across diverse reasoning domains and model architectures,\nestablishing a sample-efficient approach to reasoning enhancement for\ninstruction following.", "AI": {"tldr": "本文提出ReasonBridge方法，通过分层知识蒸馏框架将闭源大模型的复杂推理能力高效迁移至开源模型，仅需1000条精选推理轨迹数据，使开源模型推理能力提升23%，显著缩小与闭源模型的差距。", "motivation": "当前闭源与开源大语言模型在复杂推理任务上存在显著性能差距，亟需一种高效方法将闭源模型的推理能力迁移至开源模型。", "method": "1) 构建含1000条多领域精选推理轨迹的Reason1K数据集\\n2) 分层蒸馏框架捕获战略抽象与战术实现模式\\n3) 仅增加0.3%可训练参数的稀疏推理适配器\\n4) 测试时采用引导推理干预的计算扩展机制", "result": "开源模型推理能力最高提升23%，增强版Qwen2.5-14B在MATH500超越Claude-Sonnet3.5，在AIME竞赛题达到同等水平。该方法在不同领域和模型架构中均展现良好泛化性。", "conclusion": "ReasonBridge建立了样本高效的推理增强范式，为提升指令跟随模型的推理能力提供了通用解决方案，显著推进了开源模型性能边界。"}}
{"id": "2506.22863", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.22863", "abs": "https://arxiv.org/abs/2506.22863", "authors": ["Yohay Ailon Tevet"], "title": "Chabauty Limits of Fermat Spirals", "comment": null, "summary": "A Fermat spiral is a set of points of the form $\\sqrt{n}e^{2\\pi i\\alpha n}$\nfor $\\alpha \\in \\mathbb{R}$. In this paper we prove that the Chabauty limits of\nFermat spirals are always closed subgroups of $\\mathbb{R}^2$, and conclude that\nno Fermat spirals are dense forests. Furthermore, we show that if $\\alpha$ is\nbadly approximable the Chabauty limits are always lattices, for which we give a\ncharacterisation.", "AI": {"tldr": "本文研究了费马螺线$\\sqrt{n}e^{2\\pi i\\alpha n}$的Chabauty极限，证明它们总是$\\mathbb{R}^2$的闭子群，并得出费马螺线不是稠密森林的结论。对于难以逼近的$\\alpha$，Chabauty极限总是格，并给出了其特征描述。", "motivation": "研究费马螺线的Chabauty极限性质，探索其在$\\mathbb{R}^2$中的结构特征及其与稠密森林的关系。", "method": "通过数学分析证明费马螺线的Chabauty极限为闭子群，并对难以逼近的$\\alpha$情况进一步分析其格结构。", "result": "费马螺线的Chabauty极限总是$\\mathbb{R}^2$的闭子群，且不是稠密森林；当$\\alpha$难以逼近时，Chabauty极限为格。", "conclusion": "费马螺线的Chabauty极限具有明确的代数结构，且在特定条件下表现为格，这为相关数学领域提供了新的理论支持。"}}
{"id": "2506.23213", "categories": ["math.ST", "eess.SP", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.23213", "abs": "https://arxiv.org/abs/2506.23213", "authors": ["Stefano Fortunati", "Jean-Pierre Delmas", "Esa Ollila"], "title": "Nuisance parameters and elliptically symmetric distributions: a geometric approach to parametric and semiparametric efficiency", "comment": null, "summary": "Elliptically symmetric distributions are a classic example of a\nsemiparametric model where the location vector and the scatter matrix (or a\nparameterization of them) are the two finite-dimensional parameters of\ninterest, while the density generator represents an\n\\textit{infinite-dimensional nuisance} term. This basic representation of the\nelliptic model can be made more accurate, rich, and flexible by considering\nadditional \\textit{finite-dimensional nuisance} parameters. Our aim is\ntherefore to investigate the deep and counter-intuitive links between\nstatistical efficiency in estimating the parameters of interest in the presence\nof both finite and infinite-dimensional nuisance parameters. Unlike previous\nworks that addressed this problem using Le Cam's asymptotic theory, our\napproach here is purely geometric: efficiency will be analyzed using tools such\nas projections and tangent spaces embedded in the relevant Hilbert space. This\nallows us to obtain original results also for the case where the location\nvector and the scatter matrix are parameterized by a finite-dimensional vector\nthat can be partitioned in two sub-vectors: one containing the parameters of\ninterest and the other containing the nuisance parameters. As an example, we\nillustrate how the obtained results can be applied to the well-known\n\\virg{low-rank} parameterization. Furthermore, while the theoretical analysis\nwill be developed for Real Elliptically Symmetric (RES) distributions, we show\nhow to extend our results to the case of Circular and Non-Circular Complex\nElliptically Symmetric (C-CES and NC-CES) distributions.", "AI": {"tldr": "本文研究椭圆对称分布中兴趣参数与有限/无限维干扰参数的统计效率关系，采用几何方法替代传统渐近理论，并扩展至复椭圆对称分布。", "motivation": "椭圆对称分布模型中，位置向量与散度矩阵作为有限维兴趣参数常受无限维干扰项影响。研究旨在揭示干扰参数存在下参数估计效率的深层联系。", "method": "采用基于希尔伯特空间的几何分析工具（如投影与切空间），替代Le Cam渐近理论，处理参数化后的兴趣参数与干扰参数子向量。", "result": "获得了低秩参数化等场景下的原创性结论，并将实椭圆对称分布的理论框架推广至循环/非循环复椭圆对称分布。", "conclusion": "几何方法能有效分析含干扰参数的统计效率问题，理论成果可拓展至复数域，为椭圆对称模型研究提供新视角。"}}
{"id": "2506.23148", "categories": ["math.CO", "05A05, 05A15"], "pdf": "https://arxiv.org/pdf/2506.23148", "abs": "https://arxiv.org/abs/2506.23148", "authors": ["Shuzhen Lv", "Philip B. Zhang"], "title": "Joint equidistributions of mesh patterns 123 and 132 with antipodal shadings", "comment": "23 pages", "summary": "The study of joint equidistributions of mesh patterns 123 and 132 with the\nsame symmetric shadings was recently initiated by Kitaev and Lv, where 75 of 80\npotential joint equidistributions were proven. In this paper, we prove 112 out\nof 126 potential joint equidistributions of mesh patterns 123 and 132 with the\nsame antipodal shadings. As a byproduct, we present 562 joint equidistribution\nresults for non-symmetric and non-antipodal shadings. To achieve this, we\nconstruct bijections, find recurrence relations, and obtain generating\nfunctions. Moreover, we demonstrate that the joint distributions of several\npairs of mesh patterns are related to the unsigned Stirling numbers of the\nfirst kind.", "AI": {"tldr": "本文证明了126种潜在联合等分布中的112种，涉及网格模式123和132的相同对映着色，并通过构建双射、递推关系和生成函数，展示了562种非对称非对映着色的联合等分布结果。", "motivation": "Kitaev和Lv最近发起了对具有相同对称着色的网格模式123和132联合等分布的研究，证明了80种潜在分布中的75种。本研究旨在扩展这一工作，探索相同对映着色下的联合等分布。", "method": "通过构造双射、寻找递推关系、获得生成函数等方法，研究了网格模式123和132的联合分布。此外，还展示了某些网格模式对的联合分布与第一类无符号Stirling数的关联。", "result": "在126种潜在联合等分布中，成功证明了112种具有相同对映着色的情况，并额外提供了562种非对称非对映着色的联合等分布结果。", "conclusion": "本研究不仅扩展了Kitaev和Lv的工作，证明了更多联合等分布情况，还揭示了网格模式联合分布与组合数学中经典数列的联系，为相关领域提供了新的研究视角。"}}
{"id": "2506.22553", "categories": ["math.OC", "cs.NA", "math.FA", "math.NA", "47H09, 65K05, 90C25 (Primary) 52A37, 52B55 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.22553", "abs": "https://arxiv.org/abs/2506.22553", "authors": ["Heinz H. Bauschke", "Tran Thanh Tung"], "title": "On a result by Meshulam", "comment": null, "summary": "In 1996, Meshulam proved that every sequence generated by applying\nprojections onto affine subspaces, drawn from a finite collection in Euclidean\nspace, must be bounded.\n  In this paper, we extend his result not only from affine subspaces to convex\npolyhedral subsets, but also from Euclidean to general Hilbert space. Various\nexamples are provided to illustrate the sharpness of the results.", "AI": {"tldr": "本文扩展了Meshulam(1996)关于欧几里得空间中仿射子空间投影序列有界性的结果，将其推广到凸多面体子集及一般希尔伯特空间。", "motivation": "研究投影序列的有界性在优化算法和凸分析中具有重要意义，原结果局限于欧几里得空间和仿射子空间，需要更一般的理论框架。", "method": "采用泛函分析和凸几何方法，将原定理从仿射子空间推广到凸多面体，并从欧几里得空间扩展到希尔伯特空间。", "result": "证明了在希尔伯特空间中，任意有限凸多面体集合上的投影序列必定有界，并通过示例展示了结果的紧性。", "conclusion": "该研究显著扩展了投影序列有界性理论的适用范围，为相关优化算法提供了更广泛的理论基础。"}}
{"id": "2506.22666", "categories": ["cs.CR", "cs.CL", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.22666", "abs": "https://arxiv.org/abs/2506.22666", "authors": ["Anamika Lochab", "Lu Yan", "Patrick Pynadath", "Xiangyu Zhang", "Ruqi Zhang"], "title": "VERA: Variational Inference Framework for Jailbreaking Large Language Models", "comment": null, "summary": "The rise of API-only access to state-of-the-art LLMs highlights the need for\neffective black-box jailbreak methods to identify model vulnerabilities in\nreal-world settings. Without a principled objective for gradient-based\noptimization, most existing approaches rely on genetic algorithms, which are\nlimited by their initialization and dependence on manually curated prompt\npools. Furthermore, these methods require individual optimization for each\nprompt, failing to provide a comprehensive characterization of model\nvulnerabilities. To address this gap, we introduce VERA: Variational infErence\nfRamework for jAilbreaking. VERA casts black-box jailbreak prompting as a\nvariational inference problem, training a small attacker LLM to approximate the\ntarget LLM's posterior over adversarial prompts. Once trained, the attacker can\ngenerate diverse, fluent jailbreak prompts for a target query without\nre-optimization. Experimental results show that VERA achieves strong\nperformance across a range of target LLMs, highlighting the value of\nprobabilistic inference for adversarial prompt generation.", "AI": {"tldr": "本文提出VERA框架，通过变分推理方法生成多样化、流畅的越狱提示，有效识别黑盒LLM的漏洞。", "motivation": "现有黑盒越狱方法依赖遗传算法和手动优化，无法全面评估模型漏洞，亟需更高效的自动化解决方案。", "method": "VERA将越狱提示构建为变分推断问题，训练小型攻击者LLM来近似目标模型对对抗性提示的后验分布。", "result": "实验表明VERA能在无需重复优化的情况下，为不同目标LLM生成高效越狱提示，性能显著优于基线方法。", "conclusion": "概率推理框架VERA为对抗性提示生成提供了新范式，证实了变分方法在黑盒安全评估中的价值。"}}
{"id": "2506.22893", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.22893", "abs": "https://arxiv.org/abs/2506.22893", "authors": ["Arpit Narechania", "Alex Endert", "Atanu R Sinha"], "title": "Agentic Enterprise: AI-Centric User to User-Centric AI", "comment": "12 pages, 1 figure, 2 sidebars; Preprint", "summary": "After a very long winter, the Artificial Intelligence (AI) spring is here.\nOr, so it seems over the last three years. AI has the potential to impact many\nareas of human life - personal, social, health, education, professional. In\nthis paper, we take a closer look at the potential of AI for Enterprises, where\ndecision-making plays a crucial and repeated role across functions, tasks, and\noperations. We consider Agents imbued with AI as means to increase\ndecision-productivity of enterprises. We highlight six tenets for Agentic\nsuccess in enterprises, by drawing attention to what the current, AI-Centric\nUser paradigm misses, in the face of persistent needs of and usefulness for\nEnterprise Decision-Making. In underscoring a shift to User-Centric AI, we\noffer six tenets and promote market mechanisms for platforms, aligning the\ndesign of AI and its delivery by Agents to the cause of enterprise users.", "AI": {"tldr": "本文探讨了人工智能（AI）在企业决策中的潜力，提出了以用户为中心的AI六大原则，并倡导通过市场机制优化AI代理的设计与交付。", "motivation": "随着AI技术的快速发展，其在企业决策中的潜在影响日益显著。然而，当前以AI为中心的用户范式未能充分满足企业决策的持续需求，因此需要转向以用户为中心的AI设计。", "method": "通过分析企业决策的多样性和重复性，提出将AI代理作为提升企业决策效率的工具，并总结了六大原则以实现AI代理在企业中的成功应用。", "result": "研究强调了从以AI为中心转向以用户为中心的重要性，并提出了六大原则，同时建议通过市场机制优化AI平台的设计与交付。", "conclusion": "通过以用户为中心的AI设计和市场机制的引入，可以更好地满足企业决策的需求，提升AI代理在企业中的实用性和效率。"}}
{"id": "2506.23099", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.23099", "abs": "https://arxiv.org/abs/2506.23099", "authors": ["Ruikai Chen"], "title": "On sesquilinear forms over finite fields", "comment": null, "summary": "We develop a theory of sesquilinear forms over finite fields, investigating\ntheir representations via polynomials and coefficient matrices, along with\nclassification results for these forms. Through their connection to quadratic\nforms, we calculate certain character sums to resolve enumeration problems for\nequations defined by sesquilinear forms. This provides a characterization of a\nclass of maximal or minimal Artin-Schreier curves with explicit examples.", "AI": {"tldr": "本文研究了有限域上半线性形式的表示与分类，通过其与二次型的关联解决了特定方程的计数问题，并刻画了一类极值Artin-Schreier曲线。", "motivation": "探索有限域上半线性形式的数学理论及其在代数几何中的应用，特别是解决由半线性形式定义的方程计数问题。", "method": "通过多项式与系数矩阵表示半线性形式，利用其与二次型的联系计算特征和，进而解决枚举问题。", "result": "获得了半线性形式的分类结果，并由此刻画了一类具有显式例子的极大或极小Artin-Schreier曲线。", "conclusion": "该研究为有限域上半线性形式的理论提供了新视角，并在代数几何中发现了具体的极值曲线实例。"}}
{"id": "2506.23337", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.23337", "abs": "https://arxiv.org/abs/2506.23337", "authors": ["Nikolai N. Leonenko", "Andrey Pepelyshev"], "title": "Numerical computation of the Rosenblatt distribution and applications", "comment": null, "summary": "The Rosenblatt distribution plays a key role in the limit theorems for\nnon-linear functionals of stationary Gaussian processes with long-range\ndependence. We derive new expressions for the characteristic function of the\nRosenblatt distribution. Also we present a novel accurate approximation of all\neigenvalues of the Riesz integral operator associated with the correlation\nfunction of the Gaussian process and propose an efficient algorithm for\ncomputation of the density of the Rosenblatt distribution. We perform\nMonte-Carlo simulation for small sample sizes to demonstrate the appearance of\nthe Rosenblatt distribution for several functionals of stationary Gaussian\nprocesses with long-range dependence.", "AI": {"tldr": "本文研究了Rosenblatt分布在长程依赖平稳高斯过程非线性泛函极限定理中的关键作用，提出了其特征函数的新表达式，并开发了Riesz积分算子所有特征值的精确近似方法及Rosenblatt分布密度的高效计算算法。", "motivation": "Rosenblatt分布在长程依赖高斯过程的非线性泛函极限理论中具有核心地位，但其特征函数和分布密度的计算仍存在挑战，需要更高效的算法和理论突破。", "method": "通过推导Rosenblatt分布特征函数的新表达式，提出Riesz积分算子特征值的精确近似方法，并设计蒙特卡洛模拟验证小样本下该分布在长程依赖高斯过程泛函中的出现规律。", "result": "获得了Rosenblatt分布特征函数的创新解析形式，建立了Riesz算子特征值的有效逼近技术，开发出分布密度的高效计算算法，并通过数值实验验证了理论结果。", "conclusion": "该研究为长程依赖高斯过程非线性泛函的统计分析提供了新的理论工具和计算框架，显著推进了Rosenblatt分布在实际应用中的可操作性。"}}
{"id": "2506.23237", "categories": ["math.CO", "05A19 (Primary), 05A15, 05C30 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.23237", "abs": "https://arxiv.org/abs/2506.23237", "authors": ["Thomas Selig", "Haoyue Zhu"], "title": "Prime graphical parking functions and strongly recurrent configurations of the Abelian sandpile model", "comment": "23 pages, 14 figures; this is the full-length version of an extended\n  abstract that will appear in the proceedings of EUROCOMB'25", "summary": "This work investigates the duality between two discrete dynamical processes:\nparking functions, and the Abelian sandpile model (ASM). Specifically, we are\ninterested in the extension of classical parking functions, called $G$-parking\nfunctions, introduced by Postnikov and Shapiro in 2004. $G$-parking functions\nare in bijection with recurrent configurations of the ASM on $G$. In this work,\nwe define a notion of prime $G$-parking functions. These are parking functions\nthat are in a sense \"indecomposable\". Our notion extends the concept of\nprimeness for classical parking functions, as well as the notion of prime\n$(p,q)$-parking functions introduced by Armon et al. in recent work. We show\nthat from the ASM perspective, prime $G$-parking functions correspond to\ncertain configurations of the ASM, which we call strongly recurrent. We study\nthis new connection on a number of graph families, including wheel graphs,\ncomplete graphs, complete multi-partite graphs, and complete split graphs.", "AI": {"tldr": "本文研究了停车函数与阿贝尔沙堆模型(ASM)之间的对偶关系，特别是引入了$G$-停车函数的素数概念，并证明其在ASM中对应强循环配置。", "motivation": "探索$G$-停车函数与ASM循环配置之间的深层联系，扩展经典停车函数及$(p,q)$-停车函数的素数概念。", "method": "定义了素数$G$-停车函数的概念，并在轮图、完全图、完全多部图和完全分裂图等多种图族上研究其与ASM强循环配置的对应关系。", "result": "证明了素数$G$-停车函数与ASM中的强循环配置存在对应关系，并在特定图族中验证了这一结论。", "conclusion": "通过建立素数$G$-停车函数与ASM强循环配置的联系，为离散动力系统的对偶性研究提供了新的理论工具和实例验证。"}}
{"id": "2506.22568", "categories": ["math.OC", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.22568", "abs": "https://arxiv.org/abs/2506.22568", "authors": ["Gladston Moreira", "Ivan Meneghini", "Elzabeth Wanner"], "title": "Maximum Dispersion, Maximum Concentration: Enhancing the Quality of MOP Solutions", "comment": "11 pages", "summary": "Multi-objective optimization problems (MOPs) often require a trade-off\nbetween conflicting objectives, maximizing diversity and convergence in the\nobjective space. This study presents an approach to improve the quality of MOP\nsolutions by optimizing the dispersion in the decision space and the\nconvergence in a specific region of the objective space. Our approach defines a\nRegion of Interest (ROI) based on a cone representing the decision maker's\npreferences in the objective space, while enhancing the dispersion of solutions\nin the decision space using a uniformity measure. Combining solution\nconcentration in the objective space with dispersion in the decision space\nintensifies the search for Pareto-optimal solutions while increasing solution\ndiversity. When combined, these characteristics improve the quality of\nsolutions and avoid the bias caused by clustering solutions in a specific\nregion of the decision space. Preliminary experiments suggest that this method\nenhances multi-objective optimization by generating solutions that effectively\nbalance dispersion and concentration, thereby mitigating bias in the decision\nspace.", "AI": {"tldr": "该研究提出了一种多目标优化方法，通过在决策空间增强解分散性，并在目标空间的特定区域集中优化，以平衡解的多样性与收敛性。", "motivation": "多目标优化问题(MOPs)需要在冲突目标间权衡，传统方法易在决策空间特定区域产生偏差，需同时优化解的分散性与收敛性。", "method": "基于决策者偏好定义目标空间的锥形兴趣区域(ROI)，利用均匀性度量增强决策空间解分散性，结合目标空间集中与决策空间分散进行帕累托优化。", "result": "实验表明该方法能有效平衡分散与集中，减少决策空间偏差，生成更高质量的帕累托最优解。", "conclusion": "结合目标空间区域集中与决策空间分散的策略，显著提升了多目标优化的解质量与多样性，为复杂权衡问题提供新思路。"}}
{"id": "2506.22706", "categories": ["cs.CR", "cs.AI", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.22706", "abs": "https://arxiv.org/abs/2506.22706", "authors": ["Arun Ramamurthy", "Neil Dhir"], "title": "General Autonomous Cybersecurity Defense: Learning Robust Policies for Dynamic Topologies and Diverse Attackers", "comment": null, "summary": "In the face of evolving cyber threats such as malware, ransomware and\nphishing, autonomous cybersecurity defense (ACD) systems have become essential\nfor real-time threat detection and response with optional human intervention.\nHowever, existing ACD systems rely on limiting assumptions, particularly the\nstationarity of the underlying network dynamics. In real-world scenarios,\nnetwork topologies can change due to actions taken by attackers or defenders,\nsystem failures, or time evolution of networks, leading to failures in the\nadaptive capabilities of current defense agents. Moreover, many agents are\ntrained on static environments, resulting in overfitting to specific\ntopologies, which hampers their ability to generalize to out-of-distribution\nnetwork topologies. This work addresses these challenges by exploring methods\nfor developing agents to learn generalizable policies across dynamic network\nenvironments -- general ACD (GACD).", "AI": {"tldr": "本文提出了一种通用自主网络安全防御（GACD）方法，旨在解决现有系统因网络拓扑动态变化导致的适应能力不足问题。", "motivation": "现有自主网络安全防御（ACD）系统基于网络动态平稳性的假设，难以应对现实世界中网络拓扑的动态变化，导致防御策略泛化能力不足。", "method": "通过探索在动态网络环境中学习通用策略的方法，开发能够适应不同网络拓扑的防御代理（GACD）。", "result": "该方法旨在提升防御代理在非静态网络环境中的适应性和泛化能力，克服现有系统因静态训练环境导致的过拟合问题。", "conclusion": "GACD为动态网络环境下的网络安全防御提供了新的研究方向，有望增强防御系统在复杂多变网络中的鲁棒性。"}}
{"id": "2506.22919", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22919", "abs": "https://arxiv.org/abs/2506.22919", "authors": ["Sanskar Pandey", "Ruhaan Chopra", "Saad Murtaza Bhat", "Ark Abhyudaya"], "title": "Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning", "comment": null, "summary": "Mixture-of-Experts (MoE) models enable conditional computation by routing\ninputs to specialized experts, but these experts rely on identical inductive\nbiases, thus limiting representational diversity. This static computation\npathway is inefficient for inputs that require different types of reasoning and\nlimits specialization and interpretability. We propose Hecto, a lightweight MoE\narchitecture that leverages architectural heterogeneity by combining a GRU\nexpert for temporal reasoning and an FFNN expert for static abstraction under a\nsparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AG\nNews, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closely\ntrails homogeneous baselines in performance despite receiving isolated input\nrepresentations, while achieving clear expert specialization, with each expert\naligning to distinct reasoning types (temporal vs static). At larger batch\nsizes, Hecto exhibits improved performance, benefiting from relaxed\ncomputational constraints that allow its heterogeneous architecture to optimize\nmore effectively. Ablation results isolate architectural diversity as the\nsource of Hecto's stability and interpretability across diverse reasoning\ntasks. Overall, Hecto establishes itself as a new benchmark for conditional\ncomputation, offering a principled framework for specialized reasoning in\nlow-resource regimes with its model strength derived from principled\nspecialization.", "AI": {"tldr": "Hecto提出了一种轻量级混合专家模型，通过结合GRU和FFNN专家实现架构异构性，在稀疏Top-1门控机制下，针对不同推理类型（时序vs静态）实现专家专业化，在低资源条件下建立条件计算新基准。", "motivation": "传统MoE模型中专家依赖相同归纳偏置，限制了表征多样性和计算效率，静态计算路径无法适应不同类型推理需求，也阻碍了专业化和可解释性。", "method": "采用GRU专家处理时序推理和FFNN专家处理静态抽象的异构架构，通过稀疏Top-1门控机制实现条件计算，输入表示相互隔离。", "result": "在三个推理基准(AG News/SST-2/HotpotQA)和回归任务(STS-B)上，Hecto性能匹配或接近同构基线，同时实现清晰的专家专业化（时序/静态推理分离）；大批量时性能提升，架构多样性是其稳定性和可解释性的关键。", "conclusion": "Hecto为条件计算设立了新基准，通过原则性专业化框架，在低资源场景下为专业化推理提供了系统解决方案，其模型优势源于架构异构性。"}}
{"id": "2506.23499", "categories": ["math.NT", "cs.CR", "11P82"], "pdf": "https://arxiv.org/pdf/2506.23499", "abs": "https://arxiv.org/abs/2506.23499", "authors": ["Boris Y. Rubinstein"], "title": "Unbounded knapsack problem and double partitions", "comment": "6 pages, 1 figure", "summary": "The unbounded knapsack problem can be considered as a particular case of the\ndouble partition problem that asks for a number of nonnegative integer\nsolutions to a system of two linear Diophantine equations with integer\ncoefficients. In the middle of 19th century Sylvester and Cayley suggested an\napproach based on the variable elimination allowing a reduction of a double\npartition to a sum of scalar partitions. This manuscript discusses a geometric\ninterpretation of this method and its application to the knapsack problem.", "AI": {"tldr": "本文探讨了无界背包问题与双划分问题的关系，并基于19世纪Sylvester和Cayley提出的变量消去法，给出了该方法的几何解释及其在背包问题中的应用。", "motivation": "研究无界背包问题与双划分问题的联系，探索历史方法（Sylvester和Cayley的变量消去法）的现代几何解释及应用价值。", "method": "采用变量消去法将双划分问题简化为标量划分的和，并通过几何视角重新诠释这一经典方法。", "result": "成功将双划分问题转化为更易处理的标量划分形式，并验证了该方法在解决背包问题中的有效性。", "conclusion": "几何解释不仅复兴了19世纪的数学方法，还为背包问题提供了新的解决思路，展示了经典理论与现代问题的结合潜力。"}}
{"id": "2506.23456", "categories": ["math.ST", "cs.DS", "cs.LG", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.23456", "abs": "https://arxiv.org/abs/2506.23456", "authors": ["William Gay", "William He", "Nicholas Kocurek", "Ryan O'Donnell"], "title": "Sampling and Identity-Testing Without Approximate Tensorization of Entropy", "comment": null, "summary": "Certain tasks in high-dimensional statistics become easier when the\nunderlying distribution satisfies a local-to-global property called approximate\ntensorization of entropy (ATE). For example, the Glauber dynamics Markov chain\nof an ATE distribution mixes fast and can produce approximate samples in a\nsmall amount of time, since such a distribution satisfies a modified\nlog-Sobolev inequality. Moreover, identity-testing for an ATE distribution\nrequires few samples if the tester is given coordinate conditional access to\nthe unknown distribution, as shown by Blanca, Chen, \\v{S}tefankovi\\v{c}, and\nVigoda (COLT 2023).\n  A natural class of distributions that do not satisfy ATE consists of mixtures\nof (few) distributions that do satisfy ATE. We study the complexity of\nidentity-testing and sampling for these distributions. Our main results are the\nfollowing:\n  1. We show fast mixing of Glauber dynamics from a data-based initialization,\nwith optimal sample complexity, for mixtures of distributions satisfying\nmodified log-Sobolev inequalities. This extends work of Huang, Koehler, Lee,\nMohanty, Rajaraman, Vuong, and Wu (STOC 2025, COLT 2025) for mixtures of\ndistributions satisfying Poincar\\'e inequalities.\n  2. Answering an open question posed by Blanca et al., we give efficient\nidentity-testers for mixtures of ATE distributions in the\ncoordinate-conditional sampling access model. We also give some simplifications\nand improvements to the original algorithm of Blanca et al.", "AI": {"tldr": "本文研究了满足近似熵张量化(ATE)条件的混合分布的采样与身份测试问题，提出了基于数据初始化的Glauber动力学快速混合方法，并改进了坐标条件采样模型下的身份测试算法。", "motivation": "研究混合ATE分布的采样与测试复杂度，解决Blanca等人提出的开放性问题，并扩展Huang等人关于Poincar\\'e不等式混合分布的工作。", "method": "1. 使用数据初始化实现Glauber动力学的快速混合；2. 在坐标条件采样模型下设计高效身份测试算法，并简化Blanca等人的原始算法。", "result": "1. 获得了满足修正log-Sobolev不等式的混合分布的最优样本复杂度；2. 在坐标条件采样模型中实现了混合ATE分布的高效身份测试。", "conclusion": "该研究为混合ATE分布提供了有效的采样与测试工具，解决了理论计算机科学中的重要问题，并改进了现有算法的效率。"}}
{"id": "2506.23238", "categories": ["math.CO", "Primary 05C65"], "pdf": "https://arxiv.org/pdf/2506.23238", "abs": "https://arxiv.org/abs/2506.23238", "authors": ["Ayako Carter", "Eric Montoya", "Mihai D. Staic"], "title": "An acyclic $d$-partition of the $r$-uniform complete hypergraph $K_{rd}^{(r)}$", "comment": "17 pages, 3 figures, all comments are welcome", "summary": "In this paper we introduce a $d$-partition\n$\\mathcal{E}_d^{(r)}=(\\Omega_1^{(r,d)}, \\Omega_2^{(r,d)},\\dots,\n\\Omega_d^{(r,d)})$ of the $r$-uniform complete hypergraph $K_{rd}^{(r)}$. We\nprove that $\\mathcal{E}_d^{(r)}$ is homogeneous and that each hypergraph\n$\\Omega_i^{(r,d)}$ is acyclic (i.e. has zero Betti numbers). As an application,\nwe show that the map $det^{S^r}$ is nontrivial for every $r$, which gives a\npartial answer to a conjecture from [14].", "AI": {"tldr": "本文引入了一个$d$-分区$\\mathcal{E}_d^{(r)}$，证明了其齐次性及每个超图$\\Omega_i^{(r,d)}$的无环性，并应用此结果部分验证了[14]中的猜想。", "motivation": "研究$r$-均匀完全超图$K_{rd}^{(r)}$的分区性质，并探索其在行列式映射$det^{S^r}$非平凡性中的应用。", "method": "通过构造$d$-分区$\\mathcal{E}_d^{(r)}=(\\Omega_1^{(r,d)}, \\Omega_2^{(r,d)},\\dots, \\Omega_d^{(r,d)})$，并分析其齐次性和无环性。", "result": "证明了分区$\\mathcal{E}_d^{(r)}$是齐次的，且每个超图$\\Omega_i^{(r,d)}$是无环的（即贝蒂数为零），并由此得出$det^{S^r}$对所有$r$均非平凡。", "conclusion": "该研究不仅验证了超图分区的特定性质，还为[14]中的猜想提供了部分解答，具有重要的理论意义。"}}
{"id": "2506.22603", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.22603", "abs": "https://arxiv.org/abs/2506.22603", "authors": ["Yixin Wang", "Qingna Li", "Liwei Zhang"], "title": "A highly efficient single-loop smoothing damped Newton method for large-scale bilevel hyperparameter optimization of SVC", "comment": null, "summary": "Bilevel hyperparameter optimization has received growing attention thanks to\nthe fast development of machine learning. Due to the tremendous size of data\nsets, the scale of bilevel hyperparameter optimization problem could be\nextremely large, posing great challenges in designing efficient numerical\nalgorithms. In this paper, we focus on solving the large-scale mathematical\nprograms with equilibrium constraints (MPEC) derived from hyperparameter\nselection of L1-support vector classification (L1-SVC). We propose a highly\nefficient single-loop smoothing damped Newton method (SDNM) for solving such\nMPEC. Compared with most existing algorithms where subproblems are involved and\nsolved by on-shelf packages, our approach fully takes advantage of the\nstructure of MPEC and therefore is single-loop. Moreover, the proposed SDNM\nenjoys a quadratic convergence rate under proper assumptions. Extensive\nnumerical results over LIBSVM dataset show the superior performance of SDNM\nover other state-of-art algorithms including the Scholtes global relaxation\nmethod (SGRM) with subproblem solved by SNOPT and the Matlab built-in function\nfmincon, especially in CPU time. For example, for dataset w4a, SDNM is 20 times\nfaster than SGRM and 3 times faster than fmincon. Further numerical results\nalso verifies the quadratic convergence rate of SDNM as well as the fulfillment\nof the second order sufficient condition, while guarantees that SDNM returns a\nstrict local minimizer of the smoothing problem of MPEC.", "AI": {"tldr": "本文提出了一种高效的单循环平滑阻尼牛顿法（SDNM），用于解决大规模L1支持向量分类（L1-SVC）超参数选择中的数学规划与均衡约束问题（MPEC）。SDNM在LIBSVM数据集上表现出色，计算速度显著优于现有算法。", "motivation": "随着机器学习快速发展，双层超参数优化问题规模日益庞大，亟需高效数值算法。本文针对L1-SVC超参数选择中的MPEC问题，旨在设计更高效的求解方法。", "method": "提出单循环平滑阻尼牛顿法（SDNM），充分利用MPEC结构特性避免子问题求解。理论证明在适当条件下具有二次收敛速率，并通过二阶充分条件验证严格局部极小值。", "result": "在LIBSVM数据集上，SDNM性能显著优于SGRM（快20倍）和fmincon（快3倍）。数值实验验证了二次收敛速率及二阶充分条件满足性。", "conclusion": "SDNM为大规模MPEC问题提供了高效解决方案，其单循环特性和二次收敛速率在超参数优化领域具有重要应用价值，尤其适合处理海量数据场景。"}}
{"id": "2506.22722", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22722", "abs": "https://arxiv.org/abs/2506.22722", "authors": ["Anmin Fu", "Fanyu Meng", "Huaibing Peng", "Hua Ma", "Zhi Zhang", "Yifeng Zheng", "Willy Susilo", "Yansong Gao"], "title": "Kill Two Birds with One Stone! Trajectory enabled Unified Online Detection of Adversarial Examples and Backdoor Attacks", "comment": null, "summary": "The proposed UniGuard is the first unified online detection framework capable\nof simultaneously addressing adversarial examples and backdoor attacks.\nUniGuard builds upon two key insights: first, both AE and backdoor attacks have\nto compromise the inference phase, making it possible to tackle them\nsimultaneously during run-time via online detection. Second, an adversarial\ninput, whether a perturbed sample in AE attacks or a trigger-carrying sample in\nbackdoor attacks, exhibits distinctive trajectory signatures from a benign\nsample as it propagates through the layers of a DL model in forward inference.\nThe propagation trajectory of the adversarial sample must deviate from that of\nits benign counterpart; otherwise, the adversarial objective cannot be\nfulfilled. Detecting these trajectory signatures is inherently challenging due\nto their subtlety; UniGuard overcomes this by treating the propagation\ntrajectory as a time-series signal, leveraging LSTM and spectrum transformation\nto amplify differences between adversarial and benign trajectories that are\nsubtle in the time domain. UniGuard exceptional efficiency and effectiveness\nhave been extensively validated across various modalities (image, text, and\naudio) and tasks (classification and regression), ranging from diverse model\narchitectures against a wide range of AE attacks and backdoor attacks,\nincluding challenging partial backdoors and dynamic triggers. When compared to\nSOTA methods, including ContraNet (NDSS 22) specific for AE detection and TED\n(IEEE SP 24) specific for backdoor detection, UniGuard consistently\ndemonstrates superior performance, even when matched against each method's\nstrengths in addressing their respective threats-each SOTA fails to parts of\nattack strategies while UniGuard succeeds for all.", "AI": {"tldr": "UniGuard是首个能同时检测对抗样本和后门攻击的统一在线检测框架，通过分析深度学习模型中的传播轨迹差异实现高效防御。", "motivation": "现有方法无法同时应对对抗样本和后门攻击，且攻击在推理阶段会留下可检测的轨迹特征，这为统一检测提供了理论依据。", "method": "将攻击样本的层间传播轨迹视为时间序列信号，结合LSTM和频谱变换放大对抗/良性轨迹的时域细微差异，实现统一检测。", "result": "在图像/文本/音频等多种模态和任务中验证有效，优于ContraNet（对抗检测）和TED（后门检测）等专用SOTA方法。", "conclusion": "UniGuard首次实现了对两类攻击的通用防御，其轨迹分析范式为深度学习安全检测开辟了新方向。"}}
{"id": "2506.22920", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22920", "abs": "https://arxiv.org/abs/2506.22920", "authors": ["Pinzheng Wang", "Juntao Li", "Zecheng Tang", "Haijia Gui", "Min zhang"], "title": "Improving Rationality in the Reasoning Process of Language Models through Self-playing Game", "comment": "Accepted by ICML 2025", "summary": "Large language models (LLMs) have demonstrated considerable reasoning\nabilities in various tasks such as mathematics and coding. However, recent\nstudies indicate that even the best models lack true comprehension of their\nreasoning processes. In this paper, we explore how self-play can enhance the\nrationality of models in the reasoning process without supervision from humans\nor superior models. We design a Critic-Discernment Game(CDG) in which a prover\nfirst provides a solution to a given problem and is subsequently challenged by\ncritiques of its solution. These critiques either aim to assist or mislead the\nprover. The objective of the prover is to maintain the correct answer when\nfaced with misleading comments, while correcting errors in response to\nconstructive feedback. Our experiments on tasks involving mathematical\nreasoning, stepwise error detection, self-correction, and long-chain reasoning\ndemonstrate that CDG training can significantly improve the ability of\nwell-aligned LLMs to comprehend their reasoning process.", "AI": {"tldr": "本文提出通过自博弈游戏Critic-Discernment Game(CDG)增强大语言模型的推理理解能力，实验证明该方法能显著提升模型在数学推理、错误检测等任务中的表现。", "motivation": "尽管大语言模型(LLM)在数学、编程等任务中展现出推理能力，但研究表明其缺乏对推理过程的真正理解。本文探索如何通过无监督的自博弈方式提升模型的理性推理能力。", "method": "设计了Critic-Discernment Game(CDG)：证明者先给出问题解决方案，随后接受或误导性批评的挑战。证明者需在误导评论中保持正确答案，在建设性反馈中修正错误。", "result": "在数学推理、分步错误检测、自我修正和长链推理等任务上的实验表明，CDG训练能显著提升已对齐LLM对自身推理过程的理解能力。", "conclusion": "无监督的自博弈方法CDG能有效增强语言模型对推理过程的理解能力，为提升模型理性推理提供了新思路。"}}
{"id": "2506.23541", "categories": ["math.NT", "11R16 (Primary) 11R27, 11R29, 11R32 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.23541", "abs": "https://arxiv.org/abs/2506.23541", "authors": ["Yoshichika Iizuka", "Yutaka Konomi"], "title": "An infinite family of pairs of distinct quartic Galois CM-fields with the same discriminant and regulator", "comment": null, "summary": "We construct an infinite family of pairs of distinct imaginary biquadratic\nfields and pairs of distinct imaginary cyclic quartic fields with the same\ndiscriminant and regulator. We also construct an infinite family of imaginary\nbiquadratic fields and imaginary cyclic quartic fields with the same regulator.\nMoreover, we give examples of a pair of distinct imaginary biquadratic fields\nand a pair of distinct imaginary cyclic quartic fields with the same\ndiscriminant, regulator and class number.", "AI": {"tldr": "本文构建了无限多对具有相同判别式和调节器的不同虚双二次域和虚循环四次域，并展示了具有相同调节器、判别式及类数的具体例子。", "motivation": "研究虚数域中不同数域间在判别式、调节器等不变量上的关系，探索数域理论的深层结构特性。", "method": "通过构造无限族的方法，系统性地生成具有相同不变量（判别式、调节器、类数）的不同虚双二次域和虚循环四次域对。", "result": "成功构建了无限多对具有相同判别式和调节器的虚数域，并首次给出判别式、调节器及类数完全相同的数域对实例。", "conclusion": "该研究揭示了虚数域中不变量相同的非平凡现象，为数域分类理论提供了新的构造性证据。"}}
{"id": "2506.23335", "categories": ["math.OC", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.23335", "abs": "https://arxiv.org/abs/2506.23335", "authors": ["Yasong Feng", "Yifan Jiang", "Tianyu Wang", "Zhiliang Ying"], "title": "Breaking a Logarithmic Barrier in the Stopping Time Convergence Rate of Stochastic First-order Methods", "comment": null, "summary": "This work provides a novel convergence analysis for stochastic optimization\nin terms of stopping times, addressing the practical reality that algorithms\nare often terminated adaptively based on observed progress. Unlike prior\napproaches, our analysis: 1. Directly characterizes convergence in terms of\nstopping times adapted to the underlying stochastic process. 2. Breaks a\nlogarithmic barrier in existing results. Key to our results is the development\nof a Gr\\\"onwall-type argument tailored to such stochastic processes. This tool\nenables sharper bounds without restrictive assumptions.", "AI": {"tldr": "本文提出了一种基于停时的随机优化收敛性分析新方法，突破了现有结果中的对数障碍，并开发了适用于此类随机过程的Gr\\\"onwall型论证工具。", "motivation": "针对实际应用中算法常根据观测进度自适应终止的现象，现有分析框架存在局限性，需要更直接的收敛性表征方法。", "method": "采用停时理论直接描述随机过程的收敛性，并开发了专门的Gr\\\"onwall型论证技术。", "result": "突破了现有结果中的对数障碍，在不引入严格假设的条件下获得了更精确的收敛界限。", "conclusion": "该分析框架为随机优化算法的自适应终止提供了理论支持，所开发的工具可应用于更广泛的随机过程分析场景。"}}
{"id": "2506.23264", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.23264", "abs": "https://arxiv.org/abs/2506.23264", "authors": ["Diep Luong-Le", "Tuan Tran", "Dilong Yang"], "title": "Relative discrepancy of hypergraphs", "comment": null, "summary": "Given $k$-uniform hypergraphs $G$ and $H$ on $n$ vertices with densities $p$\nand $q$, their relative discrepancy is defined as\n$\\hbox{disc}(G,H)=\\max\\big||E(G')\\cap E(H')|-pq\\binom{n}{k}\\big|$, where the\nmaximum ranges over all pairs $G',H'$ with $G'\\cong G$, $H'\\cong H$, and\n$V(G')=V(H')$. Let $\\hbox{bs}(k)$ denote the smallest integer $m \\ge 2$ such\nthat any collection of $m$ $k$-uniform hypergraphs on $n$ vertices with\nmoderate densities contains a pair $G,H$ for which $\\hbox{disc}(G,H) =\n\\Omega(n^{(k+1)/2})$.\n  In this paper, we answer several questions raised by Bollob\\'as and Scott,\nproviding both upper and lower bounds for $\\hbox{bs}(k)$. Consequently, we\ndetermine the exact value of $\\hbox{bs}(k)$ for $2\\le k\\le 13$, and show\n$\\hbox{bs}(k)=O(k^{0.525})$, substantially improving the previous bound\n$\\hbox{bs}(k)\\le k+1$ due to Bollob\\'as-Scott. The case $k=2$ recovers a result\nof Bollob\\'as-Scott, which generalises classical theorems of Erd\\H{o}s-Spencer,\nand Erd\\H{o}s-Goldberg-Pach-Spencer. The case $k=3$ also follows from the\nresults of Bollob\\'as-Scott and Kwan-Sudakov-Tran. Our proof combines linear\nalgebra, Fourier analysis, and extremal hypergraph theory.", "AI": {"tldr": "本文研究了$k$-均匀超图的相对差异问题，确定了$\\hbox{bs}(k)$的上下界，并改进了Bollob\\'as-Scott的现有结果。", "motivation": "研究$k$-均匀超图的相对差异，解决Bollob\\'as和Scott提出的若干问题，扩展Erd\\H{o}s等人的经典定理。", "method": "结合线性代数、傅里叶分析和极值超图理论，推导$\\hbox{bs}(k)$的上下界。", "result": "确定了$2\\le k\\le 13$时$\\hbox{bs}(k)$的精确值，并证明$\\hbox{bs}(k)=O(k^{0.525})$，显著改进了之前的$k+1$上界。", "conclusion": "本文不仅推广了经典结果，还为更高维度的超图差异问题提供了新的理论工具和界限。"}}
{"id": "2506.22725", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.22725", "abs": "https://arxiv.org/abs/2506.22725", "authors": ["Fangbing Lv", "Qiao-Li Dong"], "title": "Preconditioned Halpern iteration with adaptive anchoring parameters and an acceleration to Chambolle-Pock algorithm", "comment": null, "summary": "In this article, we propose a preconditioned Halpern iteration with adaptive\nanchoring parameters (PHA) algorithm by integrating a preconditioner and\nHalpern iteration with adaptive anchoring parameters. Then we establish the\nstrong convergence and at least $\\mathcal{O}(1/k)$ convergence rate of the PHA\nalgorithm, and extend these convergence results to Halpern-type preconditioned\nproximal point method with adaptive anchoring parameters. Moreover, we develop\nan accelerated Chambolle--Pock algorithm (aCP) that is shown to have at least\n$\\mathcal{O}(1/k)$ convergence rate concerning the residual mapping and the\nprimal-dual gap. Finally, numerical experiments on the minimax matrix game and\nLASSO problem are provided to show advantages and outperformance of our aCP\nalgorithm over Halpern-based accelerated Chambolle--Pock algorithm in [18].", "AI": {"tldr": "本文提出了一种带自适应锚定参数的预条件Halpern迭代算法(PHA)，并证明了其强收敛性和至少$\\mathcal{O}(1/k)$的收敛速率。同时，开发了加速Chambolle-Pock算法(aCP)，在极小极大矩阵博弈和LASSO问题上展示了优越性。", "motivation": "研究旨在结合预条件技术和自适应锚定参数改进Halpern迭代算法，提升收敛性能，并扩展至Halpern型预条件邻近点方法，同时开发更高效的加速Chambolle-Pock算法。", "method": "提出PHA算法整合预条件器和自适应锚定参数的Halpern迭代；建立强收敛性和$\\mathcal{O}(1/k)$收敛速率；开发具有相同收敛速率的aCP算法，重点关注残差映射和原始-对偶间隙。", "result": "理论证明PHA算法具有强收敛性和至少$\\mathcal{O}(1/k)$的收敛速率；aCP算法在数值实验中（极小极大矩阵博弈和LASSO问题）优于文献[18]的Halpern加速Chambolle-Pock算法。", "conclusion": "PHA算法和aCP算法在理论和实验中均表现出优越性能，特别是aCP算法在优化问题中具有实际应用优势，为相关领域提供了有效的计算工具。"}}
{"id": "2506.22727", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.22727", "abs": "https://arxiv.org/abs/2506.22727", "authors": ["Yu Zheng", "Chenang Li", "Zhou Li", "Qingsong Wang"], "title": "Convergent Privacy Framework with Contractive GNN Layers for Multi-hop Aggregations", "comment": "23 pages", "summary": "Differential privacy (DP) has been integrated into graph neural networks\n(GNNs) to protect sensitive structural information, e.g., edges, nodes, and\nassociated features across various applications. A common approach is to\nperturb the message-passing process, which forms the core of most GNN\narchitectures. However, existing methods typically incur a privacy cost that\ngrows linearly with the number of layers (Usenix Security'23), ultimately\nrequiring excessive noise to maintain a reasonable privacy level. This\nlimitation becomes particularly problematic when deep GNNs are necessary to\ncapture complex and long-range interactions in graphs. In this paper, we\ntheoretically establish that the privacy budget can converge with respect to\nthe number of layers by applying privacy amplification techniques to the\nmessage-passing process, exploiting the contractive properties inherent to\nstandard GNN operations. Motivated by this analysis, we propose a simple yet\neffective Contractive Graph Layer (CGL) that ensures the contractiveness\nrequired for theoretical guarantees while preserving model utility. Our\nframework, CARIBOU, supports both training and inference, equipped with a\ncontractive aggregation module, a privacy allocation module, and a privacy\nauditing module. Experimental evaluations demonstrate that CARIBOU\nsignificantly improves the privacy-utility trade-off and achieves superior\nperformance in privacy auditing tasks.", "AI": {"tldr": "本文提出了一种名为CARIBOU的框架，通过引入收缩图层（CGL）和隐私放大技术，解决了图神经网络（GNN）中差分隐私（DP）成本随层数线性增长的问题，显著提升了隐私与效用的平衡。", "motivation": "现有方法在GNN中应用差分隐私时，隐私成本随网络层数线性增长，导致需要添加过多噪声以维持合理的隐私水平，这在需要深层GNN捕捉复杂图交互时尤为严重。", "method": "通过理论分析，利用标准GNN操作的收缩性质，提出收缩图层（CGL）确保理论保证所需的收缩性，同时保持模型效用。CARIBOU框架包含收缩聚合模块、隐私分配模块和隐私审计模块。", "result": "实验表明，CARIBOU显著改善了隐私与效用的权衡，并在隐私审计任务中表现出优越性能。", "conclusion": "CARIBOU通过隐私放大技术和收缩图层设计，有效解决了深层GNN中差分隐私成本问题，为图数据隐私保护提供了更优的解决方案。"}}
{"id": "2506.22992", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.22992", "abs": "https://arxiv.org/abs/2506.22992", "authors": ["Yulun Jiang", "Yekun Chai", "Maria Brbić", "Michael Moor"], "title": "MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning", "comment": null, "summary": "The ability to process information from multiple modalities and to reason\nthrough it step-by-step remains a critical challenge in advancing artificial\nintelligence. However, existing reasoning benchmarks focus on text-only\nreasoning, or employ multimodal questions that can be answered by directly\nretrieving information from a non-text modality. Thus, complex reasoning\nremains poorly understood in multimodal domains. Here, we present MARBLE, a\nchallenging multimodal reasoning benchmark that is designed to scrutinize\nmultimodal language models (MLLMs) in their ability to carefully reason\nstep-by-step through complex multimodal problems and environments. MARBLE is\ncomposed of two highly challenging tasks, M-Portal and M-Cube, that require the\ncrafting and understanding of multistep plans under spatial, visual, and\nphysical constraints. We find that current MLLMs perform poorly on MARBLE --\nall the 12 advanced models obtain near-random performance on M-Portal and 0%\naccuracy on M-Cube. Only in simplified subtasks some models outperform the\nrandom baseline, indicating that complex reasoning is still a challenge for\nexisting MLLMs. Moreover, we show that perception remains a bottleneck, where\nMLLMs occasionally fail to extract information from the visual inputs. By\nshedding a light on the limitations of MLLMs, we hope that MARBLE will spur the\ndevelopment of the next generation of models with the ability to reason and\nplan across many, multimodal reasoning steps.", "AI": {"tldr": "论文提出MARBLE基准测试，用于评估多模态语言模型(MLLMs)在复杂多模态环境中的逐步推理能力，发现当前模型表现接近随机水平，揭示感知与推理仍是关键瓶颈。", "motivation": "现有推理基准仅关注纯文本或可单模态直接检索的多模态问题，复杂多模态推理能力的研究仍存在空白。", "method": "设计包含M-Portal和M-Cube两项高难度任务的MARBLE基准，要求模型在空间、视觉和物理约束下进行多步骤规划与理解。", "result": "12个先进MLLMs在M-Portal上表现接近随机，M-Cube准确率为0%；仅简化子任务中部分模型超越随机基线，显示视觉信息提取仍存在缺陷。", "conclusion": "MARBLE揭示了当前MLLMs在复杂多模态推理上的局限性，有望推动新一代具备跨模态多步推理能力模型的发展。"}}
{"id": "2506.23766", "categories": ["math.NT", "11R16, 11R45 (Primary) 11E12, 11P21 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.23766", "abs": "https://arxiv.org/abs/2506.23766", "authors": ["Sudipa Das", "Sushant Kala", "Arunabha Mukhopadhyay", "Anwesh Ray"], "title": "On the distribution of shapes of pure quartic number fields", "comment": "Version 1: 19 pages", "summary": "The shape of a number field is a subtle arithmetic invariant arising from the\ngeometry of numbers. It is defined as the equivalence class of the lattice of\nintegers with respect to linear operations that are composites of rotations,\nreflections, and positive scalar dilations. For a number field of degree $n$,\nthe shape is a point in the space of shapes $\\mathscr{S}_{n-1}$, which is the\ndouble quotient $GL_{n-1}(\\mathbb{Z}) \\backslash GL_{n-1}(\\mathbb{R}) /\nGO_{n-1}(\\mathbb{R})$. In this paper, we investigate the distribution of shapes\nin the family of pure quartic fields $K_m = \\mathbb{Q}(\\sqrt[4]{m})$. We prove\nthat the shape of $K_m$ lies on one of ten explicitly described torus orbits in\n$\\mathscr{S}_3$, determined by the sign and residue class of $m \\bmod 32$. It\nis shown that the shape on a given torus orbit is completely determined by two\nparameters, one of which varies continuously, while the other takes values in a\ndiscrete set. As a result, the distribution of shapes in this family is\ngoverned by a product of a continuous and a discrete measure. Our results shed\nnew light on a question posed by Manjul Bhargava and Piper H concerning the\ndistribution of shapes in families of non-generic number fields of fixed\ndegree. Notably, the limiting distribution in our case does not arise as the\nrestriction of the natural measure on $\\mathscr{S}_3$ induced by Haar measure\non $GL_3(\\mathbb{R})$.", "AI": {"tldr": "本文研究了纯四次域$K_m = \\mathbb{Q}(\\sqrt[4]{m})$的形状分布，证明其形状位于$\\mathscr{S}_3$中十条明确描述的环面轨道上，由$m \\bmod 32$的符号和剩余类决定。形状分布由连续和离散测度的乘积控制。", "motivation": "研究数域形状的分布，特别是非通用数域族中的形状分布，以回答Manjul Bhargava和Piper H提出的问题。", "method": "通过分析纯四次域的整数格点，确定其形状在形状空间$\\mathscr{S}_3$中的环面轨道，并研究形状的参数化。", "result": "纯四次域的形状位于十条明确描述的环面轨道上，由两个参数决定：一个连续变化，另一个离散取值。分布由连续和离散测度的乘积控制。", "conclusion": "本文揭示了非通用数域族中形状分布的新特性，其极限分布并非由$GL_3(\\mathbb{R})$上的Haar测度诱导的自然测度限制而来。"}}
{"id": "2506.23936", "categories": ["math.CO", "math.AG", "math.ST", "stat.TH", "62R01"], "pdf": "https://arxiv.org/pdf/2506.23936", "abs": "https://arxiv.org/abs/2506.23936", "authors": ["Hannah Göbel", "Pratik Misra"], "title": "Linear relations of colored Gaussian cycles", "comment": "29 pages, 14 figures", "summary": "A colored Gaussian graphical model is a linear concentration model in which\nequalities among the concentrations are specified by a coloring of an\nunderlying graph. Marigliano and Davies conjectured that every linear binomial\nthat appears in the vanishing ideal of an undirected colored cycle corresponds\nto a graph symmetry. We prove this conjecture for 3,5, and 7 cycles and\ndisprove it for colored cycles of any other length. We construct the\ncounterexamples by proving the fact that the determinant of the concentration\nmatrices of two colored paths can be equal even when they are not identical or\nreflection of each other. We also explore the potential strengthening of the\nconjecture and prove a revised version of the conjecture.", "AI": {"tldr": "本文研究了彩色高斯图模型中的线性二项式与图对称性的关系，证明了Marigliano和Davies猜想在3、5、7环中成立，但在其他长度的环中不成立，并提出了修正后的猜想。", "motivation": "研究彩色高斯图模型中线性二项式与图对称性的关系，验证Marigliano和Davies的猜想是否普遍成立。", "method": "通过分析彩色环的浓度矩阵，构造反例证明猜想在某些情况下不成立，并探索猜想的可能修正。", "result": "证明了猜想在3、5、7环中成立，但在其他长度的环中不成立，并通过构造两条彩色路径的浓度矩阵行列式相等的例子来反驳原猜想。", "conclusion": "原猜想仅在特定长度的环中成立，修正后的猜想在更广泛的条件下得到证明，为彩色高斯图模型的理论研究提供了新的方向。"}}
{"id": "2506.23284", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.23284", "abs": "https://arxiv.org/abs/2506.23284", "authors": ["Anshul Raj Singh"], "title": "An Equivalence Between Erdős's Square Packing Conjecture and the Convergence of an Infinite Series", "comment": "2 pages", "summary": "Let $f(n)$ denote the maximum sum of the side lengths of $n$ non-overlapping\nsquares packed inside a unit square. We prove that $f(n^2+1) = n$ for all\npositive integers $n$ if and only if the sum $\\sum_{k\\geq 1}(f(k^2+1)-k)$\nconverges. We also show that if $f(k^2+1) = k$, for infinitely many positive\nintegers then $f(k^2+1) = k$ for all positive integers.", "AI": {"tldr": "研究了单位正方形内放置n个不重叠小正方形的最大边长和$f(n)$, 证明了$f(n^2+1)=n$的充要条件及其普遍性。", "motivation": "探索单位正方形内非重叠小正方形的最优填充问题, 建立$f(n^2+1)$与整数$n$的精确关系。", "method": "通过分析级数$\\sum_{k\\geq1}(f(k^2+1)-k)$的收敛性, 采用必要条件与充分条件的双向证明方法。", "result": "证明了$f(n^2+1)=n$当且仅当级数收敛, 并发现该等式对无限多个$k$成立则对所有正整数成立。", "conclusion": "建立了正方形填充问题中$f(k^2+1)=k$的普适性判据, 为离散几何中的极值问题提供了新见解。"}}
{"id": "2506.22764", "categories": ["math.OC", "68Q25, 90C53, 90C25, 26A06"], "pdf": "https://arxiv.org/pdf/2506.22764", "abs": "https://arxiv.org/abs/2506.22764", "authors": ["Anne Rubbens", "Nizar Bousselmi", "Julien M. Hendrickx", "François Glineur"], "title": "Performance Estimation of second-order optimization methods on classes of univariate functions", "comment": null, "summary": "We develop a principled approach to obtain exact computer-aided worst-case\nguarantees on the performance of second-order optimization methods on classes\nof univariate functions. We first present a generic technique to derive\ninterpolation conditions for a wide range of univariate functions, and use it\nto obtain such conditions for generalized self-concordant functions (including\nself-concordant and quasi-self-concordant functions) and functions with\nLipschitz Hessian (both convex and non-convex). We then exploit these\nconditions within the Performance Estimation framework to tightly analyze the\nconvergence of second-order methods on univariate functions, including (Cubic\nRegularized) Newton's method and several of its variants. Thereby, we improve\non existing convergence rates, exhibit univariate lower bounds (that thus hold\nin the multivariate case), and analyze the performance of these methods with\nrespect to the same criteria.", "AI": {"tldr": "本文提出了一种严格的方法，用于计算机辅助分析二阶优化方法在单变量函数类上的最坏性能保证。通过建立插值条件并利用性能估计框架，改进了现有收敛率，并展示了单变量下界。", "motivation": "研究旨在为二阶优化方法在广义自协调函数和Lipschitz Hessian函数等单变量函数类上的性能提供精确的最坏情况保证，填补现有收敛率分析的不足。", "method": "首先提出通用技术推导单变量函数的插值条件，应用于广义自协调函数和Lipschitz Hessian函数；随后在性能估计框架中利用这些条件，严格分析牛顿法及其变体的收敛性。", "result": "改进了现有收敛率，展示了单变量下界（在多变量情况下同样成立），并基于相同标准分析了这些方法的性能表现。", "conclusion": "该方法为二阶优化方法的性能分析提供了理论保障，所建立的单变量下界对多变量情况具有普适意义，为优化算法设计提供了新的理论工具。"}}
{"id": "2506.22750", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.22750", "abs": "https://arxiv.org/abs/2506.22750", "authors": ["Saraga S.", "Anagha M. S.", "Dincy R. Arikkat", "Rafidha Rehiman K. A.", "Serena Nicolazzo", "Antonino Nocera", "Vinod P"], "title": "Enhancing Android Malware Detection with Retrieval-Augmented Generation", "comment": null, "summary": "The widespread use of Android applications has made them a prime target for\ncyberattacks, significantly increasing the risk of malware that threatens user\nprivacy, security, and device functionality. Effective malware detection is\nthus critical, with static analysis, dynamic analysis, and Machine Learning\nbeing widely used approaches. In this work, we focus on a Machine\nLearning-based method utilizing static features. We first compiled a dataset of\nbenign and malicious APKs and performed static analysis to extract features\nsuch as code structure, permissions, and manifest file content, without\nexecuting the apps. Instead of relying solely on raw static features, our\nsystem uses an LLM to generate high-level functional descriptions of APKs. To\nmitigate hallucinations, which are a known vulnerability of LLM, we integrated\nRetrieval-Augmented Generation (RAG), enabling the LLM to ground its output in\nrelevant context. Using carefully designed prompts, we guide the LLM to produce\ncoherent function summaries, which are then analyzed using a transformer-based\nmodel, improving detection accuracy over conventional feature-based methods for\nmalware detection.", "AI": {"tldr": "本文提出了一种基于机器学习的Android恶意软件检测方法，通过静态分析提取APK特征，并利用LLM生成高级功能描述，结合RAG技术减少幻觉，最终通过Transformer模型提高检测准确率。", "motivation": "Android应用的广泛使用使其成为网络攻击的主要目标，恶意软件威胁用户隐私和设备功能，因此需要有效的检测方法。", "method": "研究通过静态分析提取APK的代码结构、权限和清单文件等特征，利用LLM生成功能描述，并引入RAG技术减少幻觉，最后使用Transformer模型进行分析。", "result": "该方法相比传统的基于特征的恶意软件检测方法，提高了检测准确率。", "conclusion": "结合LLM和RAG技术的静态分析方法能够有效提升Android恶意软件检测的准确性，为安全领域提供了新的解决方案。"}}
{"id": "2506.23049", "categories": ["cs.AI", "cs.CL", "cs.SD", "eess.AS", "68T42, 68T50,", "I.2.7; I.2.11; H.5.5"], "pdf": "https://arxiv.org/pdf/2506.23049", "abs": "https://arxiv.org/abs/2506.23049", "authors": ["Leander Melroy Maben", "Gayathri Ganesh Lakshmy", "Srijith Radhakrishnan", "Siddhant Arora", "Shinji Watanabe"], "title": "AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks", "comment": null, "summary": "Despite advances in language and speech technologies, no open-source system\nenables full speech-to-speech, multi-turn dialogue with integrated tool use and\nagentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and\nAutomated Tool Use), the first open-source, speech-native assistant capable of\ncompleting complex, goal-driven tasks through dynamic tool invocation and\nmulti-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a\ncascaded pipeline and supports tools such as calendar booking, contact lookup,\nweb search, and email. Its modular design allows easy integration of new tools\nusing natural language prompts and action classes. On VoiceBench, AURA scores\n92.75% on OpenBookQA-outperforming all open-weight systems and nearing\nGPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems.\nHuman evaluation shows 90% task success on complex, multi-turn speech tasks.", "AI": {"tldr": "AURA是首个开源的语音原生助手，支持多轮对话、工具调用和智能推理，在复杂任务中表现优异。", "motivation": "当前缺乏开源的全语音对话系统，AURA旨在填补这一空白，实现语音驱动的多轮交互与工具调用。", "method": "采用级联式架构整合开源ASR、TTS和LLM，通过自然语言提示和动作类实现模块化工具集成（如日历、搜索等）。", "result": "VoiceBench测试中92.75%准确率（超越所有开源系统），AlpacaEval得分4.39；人工评估多轮任务成功率90%。", "conclusion": "AURA为开源语音助手树立了新标杆，其模块化设计和接近GPT-4o的性能证明语音代理系统的可行性。"}}
{"id": "2506.23805", "categories": ["math.NT", "11F33, 11R34, 11S25"], "pdf": "https://arxiv.org/pdf/2506.23805", "abs": "https://arxiv.org/abs/2506.23805", "authors": ["Abhishek", "Somnath Jha", "Sudhanshu Shekhar"], "title": "2-Selmer companion modular forms", "comment": null, "summary": "Let $N$ be a positive integer and $K$ be a number field. Suppose that\n$f_1,f_2 \\in S_k(\\Gamma_0(N))$ are two newforms such that their residual Galois\nrepresentations at $2$ are isomorphic. Let $\\omega_2: G_{\\mathbb Q} \\rightarrow\n{\\mathbb Z}^*_2$ be the $2$-adic cyclotomic character. Then, under suitable\nhypotheses, we have shown that for every quadratic character $\\chi$ of $K$ and\neach critical twist $j$, the residual Greenberg $2$-Selmer groups of\n$f_1\\chi\\omega_2^{-j}$ and $f_2\\chi\\omega_2^{-j}$ over $K$ are isomorphic. This\ngeneralizes the corresponding result of Mazur-Rubin on $2$-Selmer companion\nelliptic curves. Conversely, if the difference of the residual Greenberg\n(respectively Bloch-Kato) $2$-Selmer ranks of $f_1\\chi$ and $f_2\\chi$ is\nbounded independent of every quadratic character $\\chi$ of $K$, then under\nsuitable hypotheses we have shown that the residual Galois representations at\n$2$ of $f_1$ and $f_2$ are isomorphic as $G_K$-modules. The corresponding\nresult for elliptic curves was a conjecture of Mazur-Rubin, which was proved by\nM. Yu.", "AI": {"tldr": "该论文研究了数域$K$上两个新形式$f_1$和$f_2$的残差Galois表示在2处同构时，其Greenberg 2-Selmer群在特定条件下的同构性，并推广了Mazur-Rubin关于2-Selmer伴随椭圆曲线的结果。反之，若残差Greenberg（或Bloch-Kato）2-Selmer秩的差有界，则残差Galois表示作为$G_K$-模同构。", "motivation": "研究新形式$f_1$和$f_2$在残差Galois表示同构条件下，其2-Selmer群的同构性质，推广Mazur-Rubin关于椭圆曲线的结果，并探索逆命题的成立条件。", "method": "通过假设$f_1$和$f_2$的残差Galois表示在2处同构，并引入2-adic分圆特征$\\omega_2$和二次特征$\\chi$，分析其临界扭曲$j$下的Greenberg 2-Selmer群同构性。反之，通过分析2-Selmer秩差的有界性，推导残差Galois表示的同构性。", "result": "在适当假设下，若$f_1$和$f_2$的残差Galois表示在2处同构，则其Greenberg 2-Selmer群在二次特征$\\chi$和临界扭曲$j$下同构。反之，若2-Selmer秩差有界，则残差Galois表示作为$G_K$-模同构。", "conclusion": "该研究不仅推广了Mazur-Rubin关于椭圆曲线的结果，还建立了新形式在残差Galois表示同构与2-Selmer群性质之间的双向联系，为相关领域提供了新的理论工具。"}}
{"id": "2506.23330", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.23330", "abs": "https://arxiv.org/abs/2506.23330", "authors": ["Stuti Mohanty", "Bikramaditya Sahu"], "title": "Characterization of non-singular hyperplanes of $H\\left(s,q^2\\right)$ in $\\mathrm{P G}\\left(s, q^2\\right)$", "comment": null, "summary": "In this paper, we present a combinatorial characterization of the hyperplanes\nassociated with non-singular hermitian varieties ${H}\\left(s, q^2\\right)$ in\nthe projective space $\\mathrm{PG}\\left(s,q^2\\right)$ where $s\\geq3$ and $q>2$.\nBy analyzing the intersection numbers of hyperplanes with points and\nco-dimension $2$ subspaces, we establish necessary and sufficient conditions\nfor a hyperplane to be part of the hermitian variety. This approach extends\nprevious characterizations of hermitian varieties based on intersection\nproperties, providing a purely combinatorial method for identifying their\nhyperplanes.", "AI": {"tldr": "本文通过组合方法研究了射影空间$\\mathrm{PG}\\left(s,q^2\\right)$中非奇异厄米特簇${H}\\left(s, q^2\\right)$的超平面特性，提出了判定超平面是否属于该簇的充要条件。", "motivation": "旨在扩展基于交截性质的厄米特簇表征方法，为识别其超平面提供纯组合学的判定依据。", "method": "通过分析超平面与点及余维2子空间的交截数，建立组合特征条件。", "result": "确立了$s\\geq3$且$q>2$时，超平面属于厄米特簇${H}\\left(s, q^2\\right)$的充要组合条件。", "conclusion": "该组合表征方法完善了厄米特簇超平面的理论框架，为相关几何结构研究提供了新工具。"}}
{"id": "2506.22797", "categories": ["math.OC", "85-10, 90C11, 90C90, 70M20"], "pdf": "https://arxiv.org/pdf/2506.22797", "abs": "https://arxiv.org/abs/2506.22797", "authors": ["Saif R. Kazi", "Harsha Nagarajan", "Hassan Hijazi", "Przemek Wozniak"], "title": "Optimal Trajectory Planning for Space Object Tracking with Collision-Avoidance Constraints", "comment": "Submitted to 2025 IEEE Conference on Control Technology and\n  Applications (CCTA)", "summary": "A control optimization approach is presented for a chaser spacecraft tasked\nwith maintaining proximity to a target space object while avoiding collisions.\nThe target object trajectory is provided numerically to account for both\npassive debris and actively maneuvering spacecraft. Thrusting actions for the\nchaser object are modeled as discrete (on/off) variables to optimize resources\n(e.g., fuel) while satisfying spatial, dynamical, and collision-avoidance\nconstraints. The nonlinear equation of motion is discretized directly using a\nfourth-order Runge-Kutta method without the need for linearized dynamics. The\nresulting mixed-integer nonlinear programming (MINLP) formulation is further\nenhanced with scaling techniques, valid constraints based on a perspective\nconvex reformulation, and a combination of continuous relaxations of discrete\nactions with rounding heuristics to recover high-quality feasible solutions.\nThis methodology enables efficient, collision-free trajectory planning over\nextended time horizons while reducing computational overhead. The effectiveness\nand practicality of the proposed approach is validated through a numerical case\nstudy.", "AI": {"tldr": "提出一种针对追踪航天器的控制优化方法，通过离散推力动作和混合整数非线性规划（MINLP）实现长时间碰撞规避轨迹规划，兼顾资源优化与计算效率。", "motivation": "解决追踪航天器在接近目标空间物体（包括被动碎片和主动机动航天器）时，需同时满足空间约束、动力学约束及碰撞规避的复杂控制问题。", "method": "采用四阶Runge-Kutta法直接离散化非线性运动方程，构建MINLP模型；结合比例缩放技术、基于视角凸重构的有效约束，以及离散动作连续松弛与舍入启发式算法，提升求解效率。", "result": "数值案例验证表明，该方法能高效生成长时间无碰撞轨迹，显著降低计算开销，同时保证燃料等资源的最优利用。", "conclusion": "所提方法为航天器近距离操作提供了计算高效且实用的轨迹规划框架，适用于复杂空间环境下的实时控制任务。"}}
{"id": "2506.22787", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.22787", "abs": "https://arxiv.org/abs/2506.22787", "authors": ["Sri Harsha Gajavalli", "Junichi Koizumi", "Rakibul Hasan"], "title": "What's Privacy Good for? Measuring Privacy as a Shield from Harms due to Personal Data Use", "comment": null, "summary": "We propose a harm-centric conceptualization of privacy that asks: What harms\nfrom personal data use can privacy prevent? The motivation behind this research\nis limitations in existing privacy frameworks (e.g., Contextual Integrity) to\ncapture or categorize many of the harms that arise from modern technology's use\nof personal data. We operationalize this conceptualization in an online study\nwith 400 college and university students. Study participants indicated their\nperceptions of different harms (e.g., manipulation, discrimination, and\nharassment) that may arise when artificial intelligence-based algorithms infer\npersonal data (e.g., demographics, personality traits, and cognitive\ndisability) and use it to identify students who are likely to drop out of a\ncourse or the best job candidate. The study includes 14 harms and six types of\npersonal data selected based on an extensive literature review.\n  Comprehensive statistical analyses of the study data show that the 14 harms\nare internally consistent and collectively represent a general notion of\nprivacy harms. The study data also surfaces nuanced perceptions of harms, both\nacross the contexts and participants' demographic factors. Based on these\nresults, we discuss how privacy can be improved equitably. Thus, this research\nnot only contributes to enhancing the understanding of privacy as a concept but\nalso provides practical guidance to improve privacy in the context of education\nand employment.", "AI": {"tldr": "本文提出了一种以伤害为中心的隐私概念化方法，探讨隐私如何防止个人数据使用带来的伤害。通过在线研究，分析了人工智能算法推断个人数据时可能引发的14种伤害，并发现这些伤害在统计上具有内部一致性。研究结果为教育和就业领域的隐私改进提供了实践指导。", "motivation": "现有隐私框架（如情境完整性）难以捕捉或分类现代技术使用个人数据时产生的多种伤害，因此需要一种新的隐私概念化方法。", "method": "研究通过在线调查，收集了400名大学生对人工智能算法推断个人数据（如人口统计、人格特质、认知障碍）时可能引发的14种伤害的感知。数据基于广泛的文献综述选择。", "result": "统计分析显示，14种伤害具有内部一致性，共同代表了隐私伤害的一般概念。研究还揭示了不同情境和参与者 demographic 因素对伤害感知的细微差异。", "conclusion": "研究不仅深化了对隐私概念的理解，还为教育和就业领域的隐私改进提供了实践指导，强调如何公平地提升隐私保护。"}}
{"id": "2506.23080", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23080", "abs": "https://arxiv.org/abs/2506.23080", "authors": ["Xinmin Fang", "Lingfeng Tao", "Zhengxiong Li"], "title": "AI's Euclid's Elements Moment: From Language Models to Computable Thought", "comment": null, "summary": "This paper presents a comprehensive five-stage evolutionary framework for\nunderstanding the development of artificial intelligence, arguing that its\ntrajectory mirrors the historical progression of human cognitive technologies.\nWe posit that AI is advancing through distinct epochs, each defined by a\nrevolutionary shift in its capacity for representation and reasoning, analogous\nto the inventions of cuneiform, the alphabet, grammar and logic, mathematical\ncalculus, and formal logical systems. This \"Geometry of Cognition\" framework\nmoves beyond mere metaphor to provide a systematic, cross-disciplinary model\nthat not only explains AI's past architectural shifts-from expert systems to\nTransformers-but also charts a concrete and prescriptive path forward.\nCrucially, we demonstrate that this evolution is not merely linear but\nreflexive: as AI advances through these stages, the tools and insights it\ndevelops create a feedback loop that fundamentally reshapes its own underlying\narchitecture. We are currently transitioning into a \"Metalinguistic Moment,\"\ncharacterized by the emergence of self-reflective capabilities like\nChain-of-Thought prompting and Constitutional AI. The subsequent stages, the\n\"Mathematical Symbolism Moment\" and the \"Formal Logic System Moment,\" will be\ndefined by the development of a computable calculus of thought, likely through\nneuro-symbolic architectures and program synthesis, culminating in provably\naligned and reliable AI that reconstructs its own foundational representations.\nThis work serves as the methodological capstone to our trilogy, which\npreviously explored the economic drivers (\"why\") and cognitive nature (\"what\")\nof AI. Here, we address the \"how,\" providing a theoretical foundation for\nfuture research and offering concrete, actionable strategies for startups and\ndevelopers aiming to build the next generation of intelligent systems.", "AI": {"tldr": "本文提出一个五阶段进化框架，将人工智能发展类比人类认知技术史，揭示AI从专家系统到Transformer的架构演变，并预测其未来将进入'元语言时刻'，最终实现可证明对齐的可靠AI。", "motivation": "旨在超越隐喻层面，建立系统性跨学科模型，解释AI历史架构变迁（如专家系统到Transformer），并为下一代智能系统开发提供可操作路径。", "method": "采用'认知几何学'框架，通过类比人类认知技术（如楔形文字、微积分等）划分五个革命性阶段，分析AI表征与推理能力的跃迁，特别关注当前'元语言时刻'的自反特性。", "result": "揭示AI进化具有自反性：其工具与见解会重塑底层架构。预测未来将经历'数学符号时刻'（神经符号架构）和'形式逻辑系统时刻'（程序合成），最终实现自我重构基础表征的可靠AI。", "conclusion": "作为方法论三部曲终章，本框架为AI发展提供理论基础与实践策略，尤其对初创公司具有指导意义，标志着从经济驱动（'为何'）、认知本质（'是什么'）到实现路径（'如何'）的完整研究闭环。"}}
{"id": "2506.23882", "categories": ["math.NT", "11N37"], "pdf": "https://arxiv.org/pdf/2506.23882", "abs": "https://arxiv.org/abs/2506.23882", "authors": ["Pei Gao", "Qiyu Yang"], "title": "An improved upper bound for the distribution of iterated Euler totient functions", "comment": null, "summary": "Let $\\phi(n)$ be the Euler totient function and $\\phi_k(n)$ its $k$-fold\niterate. In this note, we improve the upper bound for the number of positive\n$n\\leqslant x$ such that $\\phi_{k+1}(n)\\geqslant cn$. Comparing with the upper\nbound which was obtained from Pollack's asymptotic formula of the summation of\n$\\phi_{k+1}(n)$ for $n\\leqslant x$, we have successfully increased the\ndenominator exponent of the main term of the upper bound from $k$ to $k+1$.", "AI": {"tldr": "本文改进了关于欧拉函数$\\phi_k(n)$迭代的上界估计，将分母指数从$k$提升至$k+1$。", "motivation": "研究欧拉函数$\\phi(n)$及其$k$次迭代$\\phi_k(n)$的上界问题，旨在优化现有理论结果。", "method": "通过对比Pollack关于$\\phi_{k+1}(n)$求和的渐近公式，改进上界估计方法。", "result": "成功将上界主项的分母指数从$k$提高到$k+1$，提升了理论精度。", "conclusion": "该改进为欧拉函数迭代性质的研究提供了更精确的上界估计工具。"}}
{"id": "2506.23354", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.23354", "abs": "https://arxiv.org/abs/2506.23354", "authors": ["Matthias Beck", "Kobe Wijesekera"], "title": "MacMahon's Double Vision: Partition Diamonds Revisited", "comment": "6 pages", "summary": "Plane partition diamonds were introduced by Andrews, Paule, and Riese (2001)\nas part of their study of MacMahon's $\\Omega$-operator in search for integer\npartition identities. More recently, Dockery, Jameson, Sellers, and Wilson\n(2024) extended this concept to $d$-fold partition diamonds and found their\ngenerating function in a recursive form. We approach $d$-fold partition\ndiamonds via Stanley's (1972) theory of $P$-partitions and give a closed\nformula for a bivariate generalization of the Dockery--Jameson--Sellers--Wilson\ngenerating function; its main ingredient is the Euler--Mahonian polynomial\nencoding descent statistics of permutations.", "AI": {"tldr": "本文通过Stanley的$P$-分拆理论，给出了Dockery等人提出的$d$-重分拆钻石生成函数的双变量闭式解，核心是编码排列下降统计的Euler-Mahonian多项式。", "motivation": "Andrews等人引入平面分拆钻石研究MacMahon的$\\Omega$-算子后，Dockery团队将其推广为$d$-重分拆钻石并获得递归型生成函数。本文旨在通过更系统的组合理论寻找闭式解。", "method": "采用Stanley(1972)的$P$-分拆理论框架，将问题转化为对排列下降统计的分析，利用Euler-Mahonian多项式作为核心工具。", "result": "成功推导出Dockery-Jameson-Sellers-Wilson生成函数的双变量闭式表达式，其数学本质与Euler-Mahonian多项式密切相关。", "conclusion": "该研究不仅为$d$-重分拆钻石提供了更深刻的组合解释，也展示了$P$-分拆理论与经典分拆问题的有效结合。"}}
{"id": "2506.22826", "categories": ["math.OC", "cs.CV", "cs.NA", "math.NA", "94A08, 94A12, 65J22, 90C22, 90C25"], "pdf": "https://arxiv.org/pdf/2506.22826", "abs": "https://arxiv.org/abs/2506.22826", "authors": ["Robert Beinert", "Jonas Bresch"], "title": "Denoising Multi-Color QR Codes and Stiefel-Valued Data by Relaxed Regularizations", "comment": "9 pages, 2 figures, 3 algorithms", "summary": "The handling of manifold-valued data, for instance, plays a central role in\ncolor restoration tasks relying on circle- or sphere-valued color models, in\nthe study of rotational or directional information related to the special\northogonal group, and in Gaussian image processing, where the pixel statistics\nare interpreted as values on the hyperbolic sheet. Especially, to denoise these\nkind of data, there have been proposed several generalizations of total\nvariation (TV) and Tikhonov-type denoising models incorporating the underlying\nmanifolds. Recently, a novel, numerically efficient denoising approach has been\nintroduced, where the data are embedded in an Euclidean ambient space, the\nnon-convex manifolds are encoded by a series of positive semi-definite,\nfixed-rank matrices, and the rank constraint is relaxed to obtain a\nconvexification that can be solved using standard algorithms from convex\nanalysis. The aim of the present paper is to extent this approach to new kinds\nof data like multi-binary and Stiefel-valued data. Multi-binary data can, for\ninstance, be used to model multi-color QR codes whereas Stiefel-valued data\noccur in image and video-based recognition. For both new data types, we propose\nTV- and Tikhonov-based denoising modelstogether with easy-to-solve\nconvexification. All derived methods are evaluated on proof-of-concept,\nsynthetic experiments.", "AI": {"tldr": "本文扩展了一种高效的流形数据去噪方法，适用于多二进制和Stiefel流形数据，提出了基于TV和Tikhonov的去噪模型及易求解的凸松弛方法，并通过合成实验验证。", "motivation": "流形值数据（如色彩修复中的圆/球面模型、旋转信息或双曲空间统计）的去噪需求催生了多种TV和Tikhonov模型的推广。近期通过欧氏嵌入和凸松弛的高效方法需要扩展至多二进制（如多色QR码）和Stiefel流形（图像/视频识别）数据。", "method": "将数据嵌入欧氏空间，用半正定固定秩矩阵编码非凸流形，松弛秩约束获得凸问题。针对多二进制和Stiefel数据提出TV/Tikhonov去噪模型及凸松弛方案。", "result": "在概念验证性合成实验中，所有推导方法均得到有效评估，证实了其可行性。", "conclusion": "该方法成功扩展至新型流形数据，为多二进制和Stiefel值数据的去噪提供了高效解决方案，未来可应用于QR码优化和视觉识别任务。"}}
{"id": "2506.22938", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22938", "abs": "https://arxiv.org/abs/2506.22938", "authors": ["Zaydon L. Ali", "Wassan Saad Abduljabbar Hayale", "Israa Ibraheem Al_Barazanchi", "Ravi Sekhar", "Pritesh Shah", "Sushma Parihar"], "title": "Efficient Cybersecurity Assessment Using SVM and Fuzzy Evidential Reasoning for Resilient Infrastructure", "comment": null, "summary": "With current advancement in hybermedia knowledges, the privacy of digital\ninformation has developed a critical problem. To overawed the susceptibilities\nof present security protocols, scholars tend to focus mainly on efforts on\nalternation of current protocols. Over past decade, various proposed encoding\nmodels have been shown insecurity, leading to main threats against significant\ndata. Utilizing the suitable encryption model is very vital means of guard\nagainst various such, but algorithm is selected based on the dependency of data\nwhich need to be secured. Moreover, testing potentiality of the security\nassessment one by one to identify the best choice can take a vital time for\nprocessing. For faster and precisive identification of assessment algorithm, we\nsuggest a security phase exposure model for cipher encryption technique by\ninvoking Support Vector Machine (SVM). In this work, we form a dataset using\nusual security components like contrast, homogeneity. To overcome the\nuncertainty in analysing the security and lack of ability of processing data to\na risk assessment mechanism. To overcome with such complications, this paper\nproposes an assessment model for security issues using fuzzy evidential\nreasoning (ER) approaches. Significantly, the model can be utilised to process\nand assemble risk assessment data on various aspects in systematic ways. To\nestimate the performance of our framework, we have various analyses like,\nrecall, F1 score and accuracy.", "AI": {"tldr": "本文提出了一种基于支持向量机（SVM）和模糊证据推理（ER）的安全评估模型，用于快速准确地识别加密算法的安全性。", "motivation": "随着数字信息隐私问题的日益突出，现有安全协议的脆弱性成为主要威胁。传统方法逐一测试算法效率低下，亟需一种快速精准的评估手段。", "method": "通过构建包含对比度、同质性等安全要素的数据集，结合SVM分类和模糊ER方法，建立系统性风险评估框架。", "result": "模型通过召回率、F1分数和准确率等指标验证，能有效处理多维度安全评估数据。", "conclusion": "该框架为加密技术安全评估提供了自动化解决方案，显著提升了分析效率与系统性。"}}
{"id": "2506.23107", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23107", "abs": "https://arxiv.org/abs/2506.23107", "authors": ["Bing Song", "Jianing Liu", "Sisi Jian", "Chenyang Wu", "Vinayak Dixit"], "title": "Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study", "comment": "20 pages, 1 figure", "summary": "Large language models (LLMs) have made significant strides, extending their\napplications to dialogue systems, automated content creation, and\ndomain-specific advisory tasks. However, as their use grows, concerns have\nemerged regarding their reliability in simulating complex decision-making\nbehavior, such as risky decision-making, where a single choice can lead to\nmultiple outcomes. This study investigates the ability of LLMs to simulate\nrisky decision-making scenarios. We compare model-generated decisions with\nactual human responses in a series of lottery-based tasks, using transportation\nstated preference survey data from participants in Sydney, Dhaka, Hong Kong,\nand Nanjing. Demographic inputs were provided to two LLMs -- ChatGPT 4o and\nChatGPT o1-mini -- which were tasked with predicting individual choices. Risk\npreferences were analyzed using the Constant Relative Risk Aversion (CRRA)\nframework. Results show that both models exhibit more risk-averse behavior than\nhuman participants, with o1-mini aligning more closely with observed human\ndecisions. Further analysis of multilingual data from Nanjing and Hong Kong\nindicates that model predictions in Chinese deviate more from actual responses\ncompared to English, suggesting that prompt language may influence simulation\nperformance. These findings highlight both the promise and the current\nlimitations of LLMs in replicating human-like risk behavior, particularly in\nlinguistic and cultural settings.", "AI": {"tldr": "研究对比了大型语言模型（LLMs）与人类在风险决策中的表现，发现模型比人类更风险厌恶，且中文提示下的预测偏差更大。", "motivation": "随着大型语言模型（LLMs）应用的扩展，其在模拟复杂决策行为（如风险决策）中的可靠性引发担忧，本研究旨在评估LLMs在此类任务中的表现。", "method": "研究使用彩票任务和交通偏好调查数据（来自悉尼、达卡、香港和南京的参与者），将ChatGPT 4o和o1-mini的预测与人类实际选择对比，并采用CRRA框架分析风险偏好。", "result": "两个模型均表现出比人类更风险厌恶的行为，其中o1-mini更接近人类决策；中文提示下的预测偏差显著高于英文。", "conclusion": "LLMs在模拟人类风险行为方面展现出潜力，但在语言和文化情境中存在明显局限性，需进一步优化。"}}
{"id": "2506.23938", "categories": ["math.NT", "math.AG"], "pdf": "https://arxiv.org/pdf/2506.23938", "abs": "https://arxiv.org/abs/2506.23938", "authors": ["Takuya Yamauchi"], "title": "A 2-adic automorphy lifting theorem for symplectic groups over totally real fields", "comment": "41 pages", "summary": "We prove a new automorphy lifting theorem for certain 2-adic Galois\nrepresentations $\\rho:G_F\\longrightarrow {\\rm\nGSp}_{2n}(\\overline{\\mathbb{Q}}_2)$ where $F$ an arbitrary totally real field.\nThis extends the minimal case previously established by Thorne to the\nnon-minimal case. A key ingredient is a detailed analysis for the residual\nmonodromy representations associated to the Dwork family in characteristic two.\nAs an application, combining with the author's previous work with Tsuzuki, we\nprove the automorphy of certain rank 4 symplectic motives over $F$ coming from\nthe Dwork quintic family under suitable conditions.", "AI": {"tldr": "本文证明了关于2-adic Galois表示的新自守提升定理，扩展了Thorne的最小情况至非最小情况，并应用于Dwork五次家族的特定秩4辛动机的自守性。", "motivation": "研究任意完全实域$F$上2-adic Galois表示的自守提升问题，特别是非最小情况，以填补现有理论的空白。", "method": "通过详细分析特征二下Dwork家族的剩余单值表示，结合作者与Tsuzuki的先前工作，构建自守提升定理。", "result": "证明了特定条件下，来自Dwork五次家族的秩4辛动机的自守性，扩展了自守表示理论的应用范围。", "conclusion": "该研究不仅推广了Thorne的最小情况定理，还为Dwork家族相关动机的自守性提供了新的理论支持。"}}
{"id": "2506.23355", "categories": ["math.CO", "math.GN", "math.RT", "(Primary) 05A18 (Secondary) 06A07, 06A11, 20C30, 57Q05"], "pdf": "https://arxiv.org/pdf/2506.23355", "abs": "https://arxiv.org/abs/2506.23355", "authors": ["Bruce E Sagan", "Sheila Sundaram"], "title": "Ordered set partition posets", "comment": "44 pages", "summary": "The lattice of partitions of a set and its d-divisible generalization have\nbeen much studied for their combinatorial, topological, and\nrespresentation-theoretic properties. An ordered set partition is a set\npartition where the subsets are listed in a specific order. Ordered set\npartitions appear in combinatorics, number theory, permutation polytopes, and\nthe study of coinvariant algebras. The ordered set partitions of {1,...,n} can\nbe partially ordered by refinement and then a unique minimal element attached,\nresulting in a lattice Omega_n. But this lattice has received no attention to\nour knowledge. The purpose of this paper is to provide the first comprehensive\nlook at Omega_n. In particular, we determine its M\\\"obius function, show that\nit admits a recursive atom ordering, and study the action of the symmetric\ngroup S_n on associated homology groups, looking in particular at the\nmultiplicity of the trivial representation. We also consider the related posets\nwhere every block has size either divisible by some fixed d at least 2, or\ncongruent to 1 modulo d.", "AI": {"tldr": "本文首次系统研究了有序集合划分格Omega_n，计算了其M\\\"obius函数，证明了其具有递归原子序，并分析了对称群S_n在相关同调群上的作用，特别是平凡表示的多重性。同时探讨了块大小与固定整数d相关的偏序集。", "motivation": "有序集合划分在组合数学、数论、置换多面体及协变代数研究中频繁出现，但其对应的格Omega_n此前未被系统研究。本文旨在填补这一空白，全面探索Omega_n的性质。", "method": "通过偏序集理论工具，分析Omega_n的格结构，计算M\\\"obius函数，构造递归原子序，并利用对称群表示论研究同调群的S_n作用。", "result": "确定了Omega_n的M\\\"obius函数，证明其具有递归原子序，揭示了同调群中平凡表示的多重性规律，并推广到块大小与d相关的偏序集。", "conclusion": "该研究为有序集合划分格Omega_n建立了系统理论框架，其组合与表示论性质为后续相关领域研究提供了新工具，特别在d-可分条件下的推广具有潜在应用价值。"}}
{"id": "2506.22851", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "math.PR", "stat.ML", "90C40, 90C39, 60J05, 93E20, 65C05, 68T07"], "pdf": "https://arxiv.org/pdf/2506.22851", "abs": "https://arxiv.org/abs/2506.22851", "authors": ["Arnulf Jentzen", "Konrad Kleinberg", "Thomas Kruse"], "title": "Deep neural networks can provably solve Bellman equations for Markov decision processes without the curse of dimensionality", "comment": null, "summary": "Discrete time stochastic optimal control problems and Markov decision\nprocesses (MDPs) are fundamental models for sequential decision-making under\nuncertainty and as such provide the mathematical framework underlying\nreinforcement learning theory. A central tool for solving MDPs is the Bellman\nequation and its solution, the so-called $Q$-function. In this article, we\nconstruct deep neural network (DNN) approximations for $Q$-functions associated\nto MDPs with infinite time horizon and finite control set $A$. More\nspecifically, we show that if the the payoff function and the random transition\ndynamics of the MDP can be suitably approximated by DNNs with leaky rectified\nlinear unit (ReLU) activation, then the solutions $Q_d\\colon \\mathbb R^d\\to\n\\mathbb R^{|A|}$, $d\\in \\mathbb{N}$, of the associated Bellman equations can\nalso be approximated in the $L^2$-sense by DNNs with leaky ReLU activation\nwhose numbers of parameters grow at most polynomially in both the dimension\n$d\\in \\mathbb{N}$ of the state space and the reciprocal $1/\\varepsilon$ of the\nprescribed error $\\varepsilon\\in (0,1)$. Our proof relies on the recently\nintroduced full-history recursive multilevel fixed-point (MLFP) approximation\nscheme.", "AI": {"tldr": "本文研究了马尔可夫决策过程（MDP）中$Q$-函数的深度神经网络（DNN）逼近方法，证明了在特定条件下，DNN能以多项式复杂度逼近Bellman方程的解。", "motivation": "离散时间随机最优控制问题和MDP是强化学习理论的基础模型，而Bellman方程及其解$Q$-函数是解决MDP的核心工具。本文旨在构建DNN对无限时间范围、有限控制集的MDP的$Q$-函数进行高效逼近。", "method": "通过使用带泄漏ReLU激活的DNN逼近MDP的回报函数和随机转移动态，并基于全历史递归多级定点（MLFP）近似方案，证明了$Q_d\\colon \\mathbb R^d\\to \\mathbb R^{|A|}$的$L^2$逼近可行性。", "result": "研究表明，若MDP的回报函数和转移动态可被DNN逼近，则对应的Bellman方程解$Q_d$也能被DNN以$L^2$意义逼近，且参数数量在状态空间维度$d$和误差倒数$1/\\varepsilon$上至多呈多项式增长。", "conclusion": "本文为MDP中$Q$-函数的DNN逼近提供了理论保证，展示了在强化学习中应用DNN解决高维问题的潜力。"}}
{"id": "2506.22949", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22949", "abs": "https://arxiv.org/abs/2506.22949", "authors": ["Ehsan Hallaji", "Vaishnavi Shanmugam", "Roozbeh Razavi-Far", "Mehrdad Saif"], "title": "A Study on Semi-Supervised Detection of DDoS Attacks under Class Imbalance", "comment": "Accepted for publication in IEEE CCECE 2025", "summary": "One of the most difficult challenges in cybersecurity is eliminating\nDistributed Denial of Service (DDoS) attacks. Automating this task using\nartificial intelligence is a complex process due to the inherent class\nimbalance and lack of sufficient labeled samples of real-world datasets. This\nresearch investigates the use of Semi-Supervised Learning (SSL) techniques to\nimprove DDoS attack detection when data is imbalanced and partially labeled. In\nthis process, 13 state-of-the-art SSL algorithms are evaluated for detecting\nDDoS attacks in several scenarios. We evaluate their practical efficacy and\nshortcomings, including the extent to which they work in extreme environments.\nThe results will offer insight into designing intelligent Intrusion Detection\nSystems (IDSs) that are robust against class imbalance and handle partially\nlabeled data.", "AI": {"tldr": "研究探讨了半监督学习(SSL)技术在数据不平衡和部分标记情况下提升DDoS攻击检测的效果，评估了13种先进SSL算法在不同场景中的表现。", "motivation": "网络安全中消除分布式拒绝服务(DDoS)攻击是重大挑战，由于真实数据集的类别不平衡和标记样本不足，利用人工智能自动化这一任务十分复杂。", "method": "研究评估了13种先进的半监督学习(SSL)算法在多种场景下检测DDoS攻击的能力，包括极端环境下的表现。", "result": "研究结果揭示了SSL算法在数据不平衡和部分标记情况下的实际效能与局限性，为设计鲁棒的入侵检测系统(IDS)提供了见解。", "conclusion": "该研究为设计能够应对类别不平衡和处理部分标记数据的智能入侵检测系统(IDS)提供了重要参考。"}}
{"id": "2506.23123", "categories": ["cs.AI", "cs.CY", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.23123", "abs": "https://arxiv.org/abs/2506.23123", "authors": ["Rishi Bommasani"], "title": "The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy", "comment": "Stanford University PhD Dissertation of Rishi Bommasani (Department\n  of Computer Science, 2025). Also available at\n  https://purl.stanford.edu/zf669yy0336", "summary": "Artificial intelligence is humanity's most promising technology because of\nthe remarkable capabilities offered by foundation models. Yet, the same\ntechnology brings confusion and consternation: foundation models are poorly\nunderstood and they may precipitate a wide array of harms. This dissertation\nexplains how technology and society coevolve in the age of AI, organized around\nthree themes. First, the conceptual framing: the capabilities, risks, and the\nsupply chain that grounds foundation models in the broader economy. Second, the\nempirical insights that enrich the conceptual foundations: transparency created\nvia evaluations at the model level and indexes at the organization level.\nFinally, the transition from understanding to action: superior understanding of\nthe societal impact of foundation models advances evidence-based AI policy.\nView together, this dissertation makes inroads into achieving better societal\noutcomes in the age of AI by building the scientific foundations and\nresearch-policy interface required for better AI governance.", "AI": {"tldr": "本文探讨了人工智能基础模型在社会与技术共同演进中的作用，提出了理解其能力、风险及治理框架的三重主题。", "motivation": "基础模型作为人工智能领域最具前景的技术，其潜在危害与社会影响尚未被充分理解，亟需建立科学基础和政策接口以实现更好的AI治理。", "method": "研究围绕三个主题展开：1) 基础模型的概念框架（能力、风险及经济供应链）；2) 通过模型评估和组织指数增强透明度；3) 从理解转向行动，推动基于证据的AI政策。", "result": "通过构建基础模型的科学基础和研究-政策接口，本研究为AI时代实现更优社会成果提供了理论支持和实践路径。", "conclusion": "该论文通过系统分析基础模型的社会技术协同演进机制，为改善AI治理体系奠定了关键基础，强调科学认知与政策制定的双向互动。"}}
{"id": "2506.24012", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.24012", "abs": "https://arxiv.org/abs/2506.24012", "authors": ["Ruikai Chen"], "title": "A general approach to permutation polynomials from quadratic forms", "comment": null, "summary": "We investigate a family of permutation polynomials of finite fields of\ncharacteristic 2. Through a connection between permutation polynomials and\nquadratic forms, a general treatment is presented to characterize these\npermutation polynomials. By determining some character sums associated with\nquadratic forms, we explicitly describe several classes of permutation\npolynomials.", "AI": {"tldr": "研究特征为2的有限域上一类置换多项式，通过其与二次型的联系，给出了这些置换多项式的通用刻画方法，并具体描述了几类置换多项式。", "motivation": "探讨有限域上置换多项式与二次型之间的联系，以更深入地理解置换多项式的性质及其构造方法。", "method": "通过分析置换多项式与二次型的关系，并计算相关的特征和，提出了一种通用的刻画置换多项式的方法。", "result": "确定了与二次型相关的若干特征和，从而明确描述了几类置换多项式。", "conclusion": "通过二次型与置换多项式的联系，成功刻画了特征为2的有限域上的若干置换多项式类，为相关研究提供了新的工具和视角。"}}
{"id": "2506.23373", "categories": ["math.CO", "math-ph", "math.MP", "05E05, 33D52, 05A19"], "pdf": "https://arxiv.org/pdf/2506.23373", "abs": "https://arxiv.org/abs/2506.23373", "authors": ["Emma Yu Jin", "Xiaowei Lin"], "title": "The monomial expansions for modified Macdonald polynomials", "comment": "45 Pages, 3 Figures", "summary": "We discover a family $A$ of sixteen statistics on fillings of any given Young\ndiagram and prove new combinatorial formulas for the modified Macdonald\npolynomials, that is, $$\\tilde{H}_{\\lambda}(X;q,t)=\\sum_{\\sigma\\in\nT(\\lambda)}x^{\\sigma}q^{maj(\\sigma)}t^{\\eta(\\sigma)}$$ for each statistic\n$\\eta\\in A$. Building upon this new formula, we establish four compact formulas\nfor the modified Macdonald polynomials, namely,\n$$\\tilde{H}_{\\lambda}(X;q,t)=\\sum_{\\sigma}d_{\\varepsilon}(\\sigma)x^{\\sigma}q^{maj(\\sigma)}t^{\\eta(\\sigma)}$$\nwhich is summed over all canonical or dual canonical fillings of a Young\ndiagram and $d_{\\varepsilon}(\\sigma)$ is a product of $t$-multinomials.\nFinally, the compact formulas enable us to derive four explicit expressions for\nthe monomial expansion of modified Macdonald polynomials, one of which\ncoincides with the formula given by Garbali and Wheeler (2019).", "AI": {"tldr": "本文发现了一组关于杨图填装的16个统计量，并提出了修正Macdonald多项式的新组合公式，进一步推导出四种紧凑公式及单项式展开的显式表达式。", "motivation": "研究旨在寻找修正Macdonald多项式的新组合表达式，以深化对其代数与组合性质的理解，并建立与现有理论的联系。", "method": "通过定义杨图填装的统计量族$A$，构建组合公式$\\tilde{H}_{\\lambda}(X;q,t)=\\sum_{\\sigma\\in T(\\lambda)}x^{\\sigma}q^{maj(\\sigma)}t^{\\eta(\\sigma)}$，并进一步推导紧凑公式及显式展开。", "result": "提出了四种修正Macdonald多项式的紧凑公式，并得到其单项式展开的四个显式表达式，其中一个与Garbali和Wheeler(2019)的公式一致。", "conclusion": "新发现的统计量族及组合公式为修正Macdonald多项式的研究提供了新工具，其显式展开结果验证了与已有理论的关联性。"}}
{"id": "2506.22887", "categories": ["math.OC", "math.AP"], "pdf": "https://arxiv.org/pdf/2506.22887", "abs": "https://arxiv.org/abs/2506.22887", "authors": ["George J. Bautista", "Roberto de A. Capistrano-Filho", "Juan Límaco"], "title": "On the controllability of laminated beams with Venttsel-type boundary conditions", "comment": "19 pp. Comments are welcome", "summary": "This paper examines the boundary controllability of a Timoshenko laminated\nbeam system subject to Venttsel-type boundary conditions. The study focuses on\na novel configuration in which three controls are applied solely at the\nboundary of the beam. Controllability is established by deriving an appropriate\nobservability inequality for the corresponding adjoint system, which is then\nemployed within the framework of the duality method in the setup of the\nclassical Hilbert uniqueness method (HUM) to achieve the control problem. The\nmain contribution lies in the analysis of a system comprising three beams\ngoverned by dynamic Venttsel-type boundary conditions, as introduced by\nVenttsel in [Theory Probab. Appl., 4 (1959)].", "AI": {"tldr": "本文研究了具有Venttsel型边界条件的Timoshenko叠层梁系统的边界可控性，通过引入三种边界控制并建立相应的观测不等式，证明了系统的可控性。", "motivation": "研究动机在于探索Timoshenko叠层梁在Venttsel型边界条件下的可控性问题，特别是在仅施加边界控制的情况下实现系统控制。", "method": "方法包括推导对应伴随系统的观测不等式，并利用经典Hilbert唯一性方法（HUM）的对偶框架来解决控制问题。", "result": "主要成果是证明了由三个梁组成的系统在动态Venttsel型边界条件下的可控性，这是对Venttsel原始工作的扩展。", "conclusion": "结论表明，通过适当的边界控制和观测不等式，可以实现Timoshenko叠层梁系统的有效控制，为相关工程应用提供了理论支持。"}}
{"id": "2506.23050", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23050", "abs": "https://arxiv.org/abs/2506.23050", "authors": ["David Cornwell"], "title": "Equivalence Classes in AES -- Part 1", "comment": null, "summary": "We investigate properties of equivalence classes in AES which arise naturally\nfrom properties of MixColumns and InvMixColumns. These two operations have the\nproperty that the XOR of the 4 input bytes equals the XOR of 4 output bytes. We\nexamine the effect on equivalence classes due to the operation of SubBytes,\nShiftRows, MixColumns and AddRoundKey. The next phase of research is to find a\nkey recovery attack using known (plaintext, ciphertext) equivalence class\npairs.\n  Keywords: AES, Equivalence, Class, MixColumns, ShiftRows, SubBytes,\nAddRoundKey, Schedule, State, XOR", "AI": {"tldr": "研究AES中由MixColumns和InvMixColumns操作自然产生的等价类特性，探索这些操作对等价类的影响，并计划利用已知的（明文、密文）等价类对进行密钥恢复攻击。", "motivation": "探讨AES加密算法中MixColumns和InvMixColumns操作引入的等价类特性，以理解其对加密过程的影响，并探索潜在的密钥恢复攻击方法。", "method": "分析SubBytes、ShiftRows、MixColumns和AddRoundKey操作对等价类的影响，研究输入输出字节XOR相等的特性。", "result": "发现MixColumns和InvMixColumns操作会形成特定的等价类，这些等价类在加密过程中保持某些不变性。", "conclusion": "下一步研究将聚焦于利用已知的（明文、密文）等价类对开发密钥恢复攻击，以进一步验证等价类在AES安全性中的作用。"}}
{"id": "2506.23128", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23128", "abs": "https://arxiv.org/abs/2506.23128", "authors": ["Chi Chiu So", "Yueyue Sun", "Jun-Min Wang", "Siu Pang Yung", "Anthony Wai Keung Loh", "Chun Pong Chau"], "title": "Are Large Language Models Capable of Deep Relational Reasoning? Insights from DeepSeek-R1 and Benchmark Comparisons", "comment": "10 pages, 0 figures, accepted by 2025 IEEE international conference\n  on artificial intelligence testing (AITest)", "summary": "How far are Large Language Models (LLMs) in performing deep relational\nreasoning? In this paper, we evaluate and compare the reasoning capabilities of\nthree cutting-edge LLMs, namely, DeepSeek-R1, DeepSeek-V3 and GPT-4o, through a\nsuite of carefully designed benchmark tasks in family tree and general graph\nreasoning. Our experiments reveal that DeepSeek-R1 consistently achieves the\nhighest F1-scores across multiple tasks and problem sizes, demonstrating strong\naptitude in logical deduction and relational inference. However, all evaluated\nmodels, including DeepSeek-R1, struggle significantly as problem complexity\nincreases, largely due to token length limitations and incomplete output\nstructures. A detailed analysis of DeepSeek-R1's long Chain-of-Thought\nresponses uncovers its unique planning and verification strategies, but also\nhighlights instances of incoherent or incomplete reasoning, calling attention\nto the need for deeper scrutiny into LLMs' internal inference dynamics. We\nfurther discuss key directions for future work, including the role of\nmultimodal reasoning and the systematic examination of reasoning failures. Our\nfindings provide both empirical insights and theoretical implications for\nadvancing LLMs' reasoning abilities, particularly in tasks that demand\nstructured, multi-step logical inference. Our code repository will be publicly\navailable at https://github.com/kelvinhkcs/Deep-Relational-Reasoning.", "AI": {"tldr": "本文评估了DeepSeek-R1、DeepSeek-V3和GPT-4o三种前沿大语言模型在家族树和通用图推理任务中的表现。实验表明DeepSeek-R1综合表现最优，但所有模型在问题复杂度增加时均表现不佳，暴露出输出不完整和推理不连贯等问题。研究为提升大语言模型的结构化多步推理能力提供了实证依据。", "motivation": "探究大语言模型在深度关系推理任务中的实际能力边界，通过系统评估揭示当前模型的优势与局限性，为未来研究方向提供依据。", "method": "设计家族树和通用图推理基准任务，对比测试三种模型（DeepSeek-R1/V3、GPT-4o）的F1分数表现，重点分析DeepSeek-R1的思维链响应模式。", "result": "DeepSeek-R1在多数任务中F1分数领先，但所有模型随问题复杂度增加性能显著下降。模型存在输出截断和推理不连贯现象，其验证策略展现独特规划能力。", "conclusion": "当前大语言模型在结构化推理任务中仍受限于长度约束和推理完整性。未来需研究多模态推理机制并系统分析失败案例，以提升复杂逻辑推断能力。代码库已开源。"}}
{"id": "2506.24089", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.24089", "abs": "https://arxiv.org/abs/2506.24089", "authors": ["Sean Howe"], "title": "The completed Kirillov model and local-global compatibility for functions on Igusa varieties", "comment": null, "summary": "We describe the cuspidal functions $\\mathbb{V}_b^{\\mathrm{cusp}}$ on the\nordinary Caraiani-Scholze Igusa variety for $\\mathrm{GL}_2$ as a completion of\nthe smooth Kirillov model for classical cuspidal modular forms, and identify a\nvariant of Hida's ordinary $p$-adic modular forms with the coinvariants of an\naction of $\\tilde{\\mu}_{p^\\infty}$ on $\\mathbb{V}_b^{\\mathrm{cusp}}$. As a\nconsequence of these results, we establish a weak local-global compatibility\ntheorem for eigenspaces in $\\mathbb{V}_b^{\\mathrm{cusp}}$ associated to\nclassical cuspidal modular forms. Based on these results, we conjecture an\nanalog of Hida theory and an associated local-global compatibility for\nfunctions on more general Caraiani-Scholze Igusa varieties, which are natural\nspaces of $p$-adic automorphic forms.", "AI": {"tldr": "该论文将$\\mathrm{GL}_2$的普通Caraiani-Scholze Igusa簇上的尖点函数$\\mathbb{V}_b^{\\mathrm{cusp}}$描述为经典尖点模形式光滑Kirillov模型的完备化，并建立了与Hida普通$p$-进模形式的变体的联系，进而提出了更一般Igusa簇上的Hida理论类比猜想。", "motivation": "研究目的是建立经典尖点模形式与$p$-进自守形式空间之间的联系，并探索更一般Igusa簇上的局部-整体兼容性理论。", "method": "通过将$\\mathbb{V}_b^{\\mathrm{cusp}}$与光滑Kirillov模型完备化相联系，并利用$\\tilde{\\mu}_{p^\\infty}$作用的协变关系，构建了与Hida模形式的对应。", "result": "证明了经典尖点模形式特征空间在$\\mathbb{V}_b^{\\mathrm{cusp}}$中的弱局部-整体兼容性定理，并提出了广义Igusa簇上类似Hida理论的猜想。", "conclusion": "该工作为$p$-进自守形式理论提供了新视角，并提出了在更广泛Igusa簇上建立局部-整体兼容性和Hida理论类比的开放性问题。"}}
{"id": "2506.23452", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.23452", "abs": "https://arxiv.org/abs/2506.23452", "authors": ["Aurora Hiveley"], "title": "Experimenting with Permutation Wordle", "comment": "9 pages", "summary": "Consider a game of permutation wordle in which a player attempts to guess a\nsecret permutation of length $n$ in as few guesses as possible. In each round,\nthe guessing player is told which indices of their guessed permutation are\ncorrect. How can we optimize the player's strategy? Samuel Kutin and Lawren\nSmithline (arXiv:2408.00903) propose a strategy called \"cyclic shift\" in which\nall incorrect entries are shifted one index to the right in successive guesses,\nand they conjecture its optimality. We investigate this conjecture by\nformalizing what a strategy looks like, performing experimental analysis on\ninductively constructed strategies, and examining the coefficients of an\ninductive strategy's generating function.", "AI": {"tldr": "本文研究了排列猜词游戏的最优策略，探讨了Kutin和Smithline提出的\"循环移位\"策略的潜在最优性，并通过形式化策略定义、实验分析和生成函数系数检验进行了验证。", "motivation": "排列猜词游戏中玩家需在最少次数内猜出长度为$n$的秘密排列，现有\"循环移位\"策略被猜想为最优，但缺乏理论验证。本文旨在通过多种方法检验这一猜想。", "method": "通过形式化策略定义、对归纳构造策略进行实验分析，并研究归纳策略生成函数的系数特性，系统评估\"循环移位\"策略的性能。", "result": "实验与理论分析表明，\"循环移位\"策略在特定条件下展现出优越性，但其全局最优性仍需进一步数学证明支持。", "conclusion": "虽然\"循环移位\"策略表现出潜在的最优特性，但完全证实其最优性需要更深入的理论工作，这为未来研究指明了方向。"}}
{"id": "2506.22923", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.22923", "abs": "https://arxiv.org/abs/2506.22923", "authors": ["Hongliang Li", "Herschel C. Pangborn", "Ilya Kovalenko"], "title": "Energy-Aware Model Predictive Control for Batch Manufacturing System Scheduling Under Different Electricity Pricing Strategies", "comment": null, "summary": "Manufacturing industries are among the highest energy-consuming sectors,\nfacing increasing pressure to reduce energy costs. This paper presents an\nenergy-aware Model Predictive Control (MPC) framework to dynamically schedule\nmanufacturing processes in response to time-varying electricity prices without\ncompromising production goals or violating production constraints. A\nnetwork-based manufacturing system model is developed to capture complex\nmaterial flows, batch processing, and capacities of buffers and machines. The\nscheduling problem is formulated as a Mixed-Integer Quadratic Program (MIQP)\nthat balances energy costs, buffer levels, and production requirements. A case\nstudy evaluates the proposed MPC framework under four industrial electricity\npricing schemes. Numerical results demonstrate that the approach reduces energy\nusage expenses while satisfying production goals and adhering to production\nconstraints. The findings highlight the importance of considering the detailed\nelectricity cost structure in manufacturing scheduling decisions and provide\npractical insights for manufacturers when selecting among different electricity\npricing strategies.", "AI": {"tldr": "本文提出了一种基于模型预测控制（MPC）的能源感知框架，用于动态调度制造过程以响应时变电价，同时不牺牲生产目标或违反生产约束。", "motivation": "制造业是高能耗行业之一，面临降低能源成本的压力。如何在满足生产目标和约束的同时，减少能源使用费用是一个重要问题。", "method": "开发了一个基于网络的制造系统模型，以捕捉复杂的物料流动、批量处理以及缓冲区和机器的容量。调度问题被表述为一个混合整数二次规划（MIQP），平衡能源成本、缓冲区水平和生产需求。", "result": "案例研究评估了所提出的MPC框架在四种工业电价方案下的表现。数值结果表明，该方法在满足生产目标和约束的同时，减少了能源使用费用。", "conclusion": "研究结果强调了在制造调度决策中考虑详细电价结构的重要性，并为制造商在选择不同电价策略时提供了实用见解。"}}
{"id": "2506.23183", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23183", "abs": "https://arxiv.org/abs/2506.23183", "authors": ["De Zhang Lee", "Aashish Kolluri", "Prateek Saxena", "Ee-Chien Chang"], "title": "A Practical and Secure Byzantine Robust Aggregator", "comment": null, "summary": "In machine learning security, one is often faced with the problem of removing\noutliers from a given set of high-dimensional vectors when computing their\naverage. For example, many variants of data poisoning attacks produce gradient\nvectors during training that are outliers in the distribution of clean\ngradients, which bias the computed average used to derive the ML model.\nFiltering them out before averaging serves as a generic defense strategy.\nByzantine robust aggregation is an algorithmic primitive which computes a\nrobust average of vectors, in the presence of an $\\epsilon$ fraction of vectors\nwhich may have been arbitrarily and adaptively corrupted, such that the\nresulting bias in the final average is provably bounded.\n  In this paper, we give the first robust aggregator that runs in quasi-linear\ntime in the size of input vectors and provably has near-optimal bias bounds.\nOur algorithm also does not assume any knowledge of the distribution of clean\nvectors, nor does it require pre-computing any filtering thresholds from it.\nThis makes it practical to use directly in standard neural network training\nprocedures. We empirically confirm its expected runtime efficiency and its\neffectiveness in nullifying 10 different ML poisoning attacks.", "AI": {"tldr": "本文提出了一种在机器学习安全领域中高效且近乎最优的鲁棒聚合算法，用于在存在$\\epsilon$比例恶意向量的情况下计算稳健平均值，无需预先了解干净向量的分布或设置过滤阈值。", "motivation": "在机器学习安全中，数据投毒攻击会产生异常梯度向量，污染模型训练过程。传统的鲁棒聚合方法需要预先了解干净向量的分布或设置阈值，限制了其实际应用。", "method": "提出首个准线性时间复杂度的鲁棒聚合算法，无需预先了解干净向量分布或计算过滤阈值，可直接应用于标准神经网络训练流程。", "result": "实验证实该算法具有预期的高效运行时间，并能有效抵消10种不同的机器学习投毒攻击。", "conclusion": "该算法为机器学习安全提供了一种实用且高效的防御工具，能够在对抗性环境中保障模型训练的稳健性。"}}
{"id": "2506.23141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23141", "abs": "https://arxiv.org/abs/2506.23141", "authors": ["Siyuan Li", "Ruitong Liu", "Yan Wen", "Te Sun"], "title": "Context-Driven Knowledge Graph Completion with Semantic-Aware Relational Message Passing", "comment": null, "summary": "Semantic context surrounding a triplet $(h, r, t)$ is crucial for Knowledge\nGraph Completion (KGC), providing vital cues for prediction. However,\ntraditional node-based message passing mechanisms, when applied to knowledge\ngraphs, often introduce noise and suffer from information dilution or\nover-smoothing by indiscriminately aggregating information from all neighboring\nedges. To address this challenge, we propose a semantic-aware relational\nmessage passing. A core innovation of this framework is the introduction of a\n\\textbf{semantic-aware Top-K neighbor selection strategy}. Specifically, this\nstrategy first evaluates the semantic relevance between a central node and its\nincident edges within a shared latent space, selecting only the Top-K most\npertinent ones. Subsequently, information from these selected edges is\neffectively fused with the central node's own representation using a\n\\textbf{multi-head attention aggregator} to generate a semantically focused\nnode message. In this manner, our model not only leverages the structure and\nfeatures of edges within the knowledge graph but also more accurately captures\nand propagates the contextual information most relevant to the specific link\nprediction task, thereby effectively mitigating interference from irrelevant\ninformation. Extensive experiments demonstrate that our method achieves\nsuperior performance compared to existing approaches on several established\nbenchmarks.", "AI": {"tldr": "提出语义感知的关系消息传递框架，通过Top-K邻居选择策略和多头注意力聚合器，提升知识图谱补全任务的性能。", "motivation": "传统基于节点的消息传递机制在知识图谱中会引入噪声，并因 indiscriminately 聚合所有相邻边信息导致信息稀释或过平滑问题。", "method": "框架核心是语义感知的Top-K邻居选择策略：在共享潜在空间中评估中心节点与边的语义相关性，仅选择Top-K最相关边，并通过多头注意力聚合器融合信息生成语义聚焦的节点表示。", "result": "在多个基准测试中，该方法相比现有技术取得了更优的性能表现。", "conclusion": "该模型不仅能利用知识图谱的结构和边特征，还能精准捕捉与特定链接预测任务最相关的上下文信息，有效减少无关信息的干扰。"}}
{"id": "2506.23965", "categories": ["math.CO", "math.NT"], "pdf": "https://arxiv.org/pdf/2506.23965", "abs": "https://arxiv.org/abs/2506.23965", "authors": ["Sayan Dutta", "Sohom Gupta"], "title": "The Neighbour Sum Problem on Trees", "comment": null, "summary": "A graph $\\mathcal G = (\\mathcal V, \\mathcal E)$ is said to satisfy the\nNeighbour Sum Property if there exists some $f:\\mathcal V\\to\\mathbb R$ such\nthat $f\\not\\equiv 0$ and it maps every vertex to the sum of the values taken by\nits neighbours. In this article, we provide an algorithm to check whether a\ngiven finite tree satisfies the neighbour sum property. We also find a large\nclass of trees on $n$ vertices that satisfy the property.", "AI": {"tldr": "本文研究了图的邻点和性质，提出了一个算法来检测有限树是否满足该性质，并发现了一类满足该性质的大规模树结构。", "motivation": "研究图论中的邻点和性质（Neighbour Sum Property），旨在探索非零函数$f$将每个顶点映射到其邻居顶点值之和的条件。", "method": "设计了一个算法，用于检测给定的有限树是否满足邻点和性质。", "result": "发现了一类在$n$个顶点上满足邻点和性质的树结构，为图论研究提供了新的实例。", "conclusion": "通过算法验证和实例分析，本文不仅提供了检测邻点和性质的有效方法，还扩展了满足该性质的树类别的知识。"}}
{"id": "2506.23794", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.23794", "abs": "https://arxiv.org/abs/2506.23794", "authors": ["Natalie Behague", "Debsoumya Chakraborti", "Xizhi Liu"], "title": "Sabotage the Mantel Theorem", "comment": "short note, comments are welcome", "summary": "One of the earliest results in extremal graph theory, Mantel's theorem,\nstates that the maximum number of edges in a triangle-free graph $G$ on $n$\nvertices is $\\lfloor n^2/4 \\rfloor$. We investigate how this extremal bound is\naffected when $G$ is additionally required to contain a prescribed graph\n$\\mathbb{P}$ as a subgraph. We establish general upper and lower bounds for\nthis problem, which are tight in the exponent for random triangle-free graphs\nand graphs generated by the triangle-free process, when the size of\n$\\mathbb{P}$ lies within certain ranges.", "AI": {"tldr": "研究在无三角形图中强制包含特定子图$\\mathbb{P}$时，如何影响Mantel定理的极值边界，并建立了紧致的上下界。", "motivation": "探索Mantel定理（关于无三角形图的最大边数）在额外要求包含特定子图$\\mathbb{P}$时的扩展情况。", "method": "通过分析随机无三角形图和三角消除过程生成的图，建立一般性的上下界理论框架。", "result": "当子图$\\mathbb{P}$的规模处于特定范围时，所提边界在指数级别上是紧致的，适用于两类典型图结构。", "conclusion": "该研究为约束性子图存在条件下的极值图论问题提供了普适的理论工具，并验证了边界在重要图类中的最优性。"}}
{"id": "2506.22928", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.22928", "abs": "https://arxiv.org/abs/2506.22928", "authors": ["Jan Harold Alcantara", "Minh N. Dao", "Akiko Takeda"], "title": "Douglas--Rachford for multioperator comonotone inclusions with applications to multiblock optimization", "comment": "36 pages, 2 figures", "summary": "We study the convergence of the adaptive Douglas--Rachford (aDR) algorithm\nfor solving a multioperator inclusion problem involving the sum of maximally\ncomonotone operators. To address such problems, we adopt a product space\nreformulation that accommodates nonconvex-valued operators, which is essential\nwhen dealing with comonotone mappings. We establish convergence of the aDR\nmethod under comonotonicity assumptions, subject to suitable conditions on the\nalgorithm parameters and comonotonicity moduli of the operators. Our analysis\nleverages the Attouch--Th\\'{e}ra duality framework, which allows us to study\nthe convergence of the aDR algorithm via its application to the dual inclusion\nproblem. As an application, we derive a multiblock ADMM-type algorithm for\nstructured convex and nonconvex optimization problems by applying the aDR\nalgorithm to the operator inclusion formulation of the KKT system. The\nresulting method extends to multiblock and nonconvex settings the classical\nduality between the Douglas--Rachford algorithm and the alternating direction\nmethod of multipliers in the convex two-block case. Moreover, we establish\nconvergence guarantees for both the fully convex and strongly convex-weakly\nconvex regimes.", "AI": {"tldr": "本文研究了自适应Douglas-Rachford（aDR）算法在求解涉及多个极大共单调算子和的包含问题时的收敛性。通过引入乘积空间重构处理非凸值算子，并基于Attouch-Th\\\\'{e}ra对偶框架分析收敛性，最终推导出适用于多块和非凸优化的ADMM类算法。", "motivation": "针对多算子包含问题（特别是涉及共单调算子的情形），现有方法难以处理非凸值算子。研究aDR算法的收敛性可为结构化凸优化及非凸优化问题提供新的求解框架。", "method": "采用乘积空间重构技术处理非凸值算子，在共单调性假设下分析aDR算法的收敛性。利用Attouch-Th\\\\'{e}ra对偶框架，通过对偶包含问题研究算法收敛，并应用于KKT系统的算子包含形式以推导多块ADMM类算法。", "result": "证明了aDR算法在共单调算子条件下的收敛性，并成功将其扩展为多块非凸优化的ADMM型算法。在完全凸和强凸-弱凸两种情形下均建立了收敛性保证。", "conclusion": "该研究不仅推广了经典Douglas-Rachford算法与ADMM的对偶关系至多块非凸情形，还为结构化优化问题提供了具有收敛保证的新算法框架。"}}
{"id": "2506.23260", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23260", "abs": "https://arxiv.org/abs/2506.23260", "authors": ["Mohamed Amine Ferrag", "Norbert Tihanyi", "Djallel Hamouda", "Leandros Maglaras", "Merouane Debbah"], "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows", "comment": "29 pages, 15 figures, 6 tables", "summary": "Autonomous AI agents powered by large language models (LLMs) with structured\nfunction-calling interfaces have dramatically expanded capabilities for\nreal-time data retrieval, complex computation, and multi-step orchestration.\nYet, the explosive proliferation of plugins, connectors, and inter-agent\nprotocols has outpaced discovery mechanisms and security practices, resulting\nin brittle integrations vulnerable to diverse threats. In this survey, we\nintroduce the first unified, end-to-end threat model for LLM-agent ecosystems,\nspanning host-to-tool and agent-to-agent communications, formalize adversary\ncapabilities and attacker objectives, and catalog over thirty attack\ntechniques. Specifically, we organized the threat model into four domains:\nInput Manipulation (e.g., prompt injections, long-context hijacks, multimodal\nadversarial inputs), Model Compromise (e.g., prompt- and parameter-level\nbackdoors, composite and encrypted multi-backdoors, poisoning strategies),\nSystem and Privacy Attacks (e.g., speculative side-channels, membership\ninference, retrieval poisoning, social-engineering simulations), and Protocol\nVulnerabilities (e.g., exploits in Model Context Protocol (MCP), Agent\nCommunication Protocol (ACP), Agent Network Protocol (ANP), and Agent-to-Agent\n(A2A) protocol). For each category, we review representative scenarios, assess\nreal-world feasibility, and evaluate existing defenses. Building on our threat\ntaxonomy, we identify key open challenges and future research directions, such\nas securing MCP deployments through dynamic trust management and cryptographic\nprovenance tracking; designing and hardening Agentic Web Interfaces; and\nachieving resilience in multi-agent and federated environments. Our work\nprovides a comprehensive reference to guide the design of robust defense\nmechanisms and establish best practices for resilient LLM-agent workflows.", "AI": {"tldr": "本文首次提出针对LLM智能体生态系统的端到端威胁模型，涵盖四大攻击领域，系统化分析了30余种攻击技术，并为构建安全防御机制提供研究方向和最佳实践。", "motivation": "随着LLM智能体插件和协议的爆炸式增长，其安全机制未能同步发展，导致系统面临多样化威胁，亟需建立统一的威胁模型和防御框架。", "method": "通过将威胁模型划分为输入操纵、模型渗透、系统隐私攻击和协议漏洞四大领域，对每类攻击技术进行场景分析、可行性评估和防御措施审查。", "result": "构建了包含30余种攻击技术的分类体系，发现现有防御存在不足，提出动态信任管理、加密溯源等关键研究方向。", "conclusion": "该研究为LLM智能体工作流提供了全面的安全参考框架，对设计鲁棒防御机制和建立弹性多智能体系统具有指导意义。"}}
{"id": "2506.23860", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.23860", "abs": "https://arxiv.org/abs/2506.23860", "authors": ["Tuvi Etzion"], "title": "Steiner Systems over Mixed Alphabet and Related Designs", "comment": null, "summary": "A mixed Steiner system MS$(t,k,Q)$ is a set (code) $C$ of words of weight $k$\nover an alphabet $Q$, where not all coordinates of a word have the same\nalphabet size, each word of weight $t$, over $Q$, has distance $k-t$ from\nexactly one codeword of $C$, and the minimum distance of the code $2(k-t)+1$.\nMixed Steiner systems are constructed from perfect mixed codes, resolvable\ndesigns, large set, orthogonal arrays, and a new type of pairs-triples design.\nNecessary conditions for the existence of mixed Steiner systems are presented\nand it is proved that there are no large sets of these Steiner systems.", "AI": {"tldr": "本文提出并研究了混合Steiner系统MS$(t,k,Q)$，构建了其存在条件，并证明不存在这类系统的大集。", "motivation": "研究混合Steiner系统的构造与存在条件，填补组合设计与编码理论交叉领域的空白。", "method": "利用完美混合码、可分解设计、大集、正交阵列及新型对-三元组设计构造混合Steiner系统。", "result": "提出了混合Steiner系统存在的必要条件，并证明不存在这类系统的大集。", "conclusion": "混合Steiner系统的研究为组合设计与编码理论提供了新的理论工具，但其大集的不存在性限制了进一步扩展。"}}
{"id": "2506.22966", "categories": ["math.OC", "cs.MA", "econ.TH"], "pdf": "https://arxiv.org/pdf/2506.22966", "abs": "https://arxiv.org/abs/2506.22966", "authors": ["Grzegorz Jamróz", "Rafał Kucharski"], "title": "Detection of coordinated fleet vehicles in route choice urban games. Part I. Inverse fleet assignment theory", "comment": "30 pages, 7 figures", "summary": "Detection of collectively routing fleets of vehicles in future urban systems\nmay become important for the management of traffic, as such routing may\ndestabilize urban networks leading to deterioration of driving conditions.\nAccordingly, in this paper we discuss the question whether it is possible to\ndetermine the flow of fleet vehicles on all routes given the fleet size and\nbehaviour as well as the combined total flow of fleet and non-fleet vehicles on\nevery route. We prove that the answer to this Inverse Fleet Assignment Problem\nis 'yes' for myopic fleet strategies which are more 'selfish' than\n'altruistic', and 'no' otherwise, under mild assumptions on route/link\nperformance functions. To reach these conclusions we introduce the forward\nfleet assignment operator and study its properties, proving that it is\ninvertible for 'bad' objectives of fleet controllers. We also discuss the\nchallenges of implementing myopic fleet routing in the real world and compare\nit to Stackelberg and Nash routing. Finally, we show that optimal Stackelberg\nfleet routing could involve highly variable mixed strategies in some scenarios,\nwhich would likely cause chaos in the traffic network.", "AI": {"tldr": "本文探讨了未来城市系统中车队集体路径选择对交通管理的影响，证明了在特定条件下逆向车队分配问题有解，并分析了自私型车队策略的可逆性及其实际应用挑战。", "motivation": "研究车队集体路径选择对城市交通网络的潜在破坏性影响，探索是否可通过已知车队规模和总流量逆向推演车队路径分布。", "method": "引入正向车队分配算子并分析其性质，证明其在自私型车队控制目标下的可逆性；对比短视策略与Stackelberg/Nash路径选择的差异。", "result": "证实当车队采用比'利他'更'自私'的短视策略时，逆向车队分配问题有解；发现最优Stackelberg策略可能导致交通网络混沌。", "conclusion": "自私型车队策略具有数学可解性，但实际部署面临挑战；Stackelberg最优路径可能引发交通混乱，需谨慎设计控制策略。"}}
{"id": "2506.23294", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23294", "abs": "https://arxiv.org/abs/2506.23294", "authors": ["Mostafa Abdelrahman", "Filip Rezabek", "Lars Hupel", "Kilian Glas", "Georg Carle"], "title": "Threshold Signatures for Central Bank Digital Currencies", "comment": null, "summary": "Digital signatures are crucial for securing Central Bank Digital Currencies\n(CBDCs) transactions. Like most forms of digital currencies, CBDC solutions\nrely on signatures for transaction authenticity and integrity, leading to major\nissues in the case of private key compromise. Our work explores threshold\nsignature schemes (TSSs) in the context of CBDCs. TSSs allow distributed key\nmanagement and signing, reducing the risk of a compromised key. We analyze\nCBDC-specific requirements, considering the applicability of TSSs, and use\nFilia CBDC solution as a base for a detailed evaluation. As most of the current\nsolutions rely on ECDSA for compatibility, we focus on ECDSA-based TSSs and\ntheir supporting libraries. Our performance evaluation measured the\ncomputational and communication complexity across key processes, as well as the\nthroughput and latency of end-to-end transactions. The results confirm that TSS\ncan enhance the security of CBDC implementations while maintaining acceptable\nperformance for real-world deployments.", "AI": {"tldr": "本文探讨了在央行数字货币（CBDC）中使用阈值签名方案（TSS）以增强安全性，同时保持可接受的性能。", "motivation": "CBDC依赖数字签名确保交易真实性和完整性，但私钥泄露会导致严重问题。研究旨在通过TSS分散密钥管理和签名，降低密钥泄露风险。", "method": "以Filia CBDC方案为基础，重点评估基于ECDSA的TSS及其支持库，分析计算与通信复杂度、吞吐量和端到端交易延迟。", "result": "性能评估表明，TSS能有效提升CBDC实施的安全性，且在实际部署中保持可接受的性能水平。", "conclusion": "TSS技术可平衡CBDC的安全需求与性能要求，为实际应用提供可行解决方案。"}}
{"id": "2506.23273", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23273", "abs": "https://arxiv.org/abs/2506.23273", "authors": ["Quang Hung Nguyen", "Phuong Anh Trinh", "Phan Quoc Hung Mai", "Tuan Phong Trinh"], "title": "FinStat2SQL: A Text2SQL Pipeline for Financial Statement Analysis", "comment": null, "summary": "Despite the advancements of large language models, text2sql still faces many\nchallenges, particularly with complex and domain-specific queries. In finance,\ndatabase designs and financial reporting layouts vary widely between financial\nentities and countries, making text2sql even more challenging. We present\nFinStat2SQL, a lightweight text2sql pipeline enabling natural language queries\nover financial statements. Tailored to local standards like VAS, it combines\nlarge and small language models in a multi-agent setup for entity extraction,\nSQL generation, and self-correction. We build a domain-specific database and\nevaluate models on a synthetic QA dataset. A fine-tuned 7B model achieves\n61.33\\% accuracy with sub-4-second response times on consumer hardware,\noutperforming GPT-4o-mini. FinStat2SQL offers a scalable, cost-efficient\nsolution for financial analysis, making AI-powered querying accessible to\nVietnamese enterprises.", "AI": {"tldr": "FinStat2SQL是一种轻量级文本转SQL管道，专为金融报表的自然语言查询设计，结合大小语言模型，在越南企业环境中实现高效、低成本的财务分析。", "motivation": "尽管大型语言模型有所进步，文本转SQL在复杂和特定领域查询（如金融）仍面临挑战，尤其是不同金融实体和国家间的数据库设计与报表布局差异。", "method": "采用多智能体设置，结合大小语言模型进行实体提取、SQL生成和自我校正，针对越南会计准则（VAS）定制，并构建特定领域数据库进行评估。", "result": "微调的7B模型在合成QA数据集上达到61.33%准确率，响应时间低于4秒，在消费级硬件上优于GPT-4o-mini。", "conclusion": "FinStat2SQL为越南企业提供了可扩展、经济高效的AI驱动查询解决方案，使财务分析更加普及。"}}
{"id": "2506.23865", "categories": ["math.CO", "05D10, 05C55, 22A15, 54D35"], "pdf": "https://arxiv.org/pdf/2506.23865", "abs": "https://arxiv.org/abs/2506.23865", "authors": ["Anik Pramanick", "MD Mursalim Saikh"], "title": "Further generalization of central sets theorem for partial semigroups and vip systems", "comment": "Key words: Key words and phrases: Central Sets, Central Set Theorem,\n  Partial semigroup, algebra of Stone-\\v{C}ech compactification of descrete\n  semigroup. arXiv admin note: substantial text overlap with arXiv:2407.02629", "summary": "The Central Sets Theorem, a fundamental result in Ramsey theory, is a joint\nextension of both Hindman's theorem and van der Waerden's theorem. It was\noriginally introduced by H. Furstenberg using methods from topological\ndynamics. Later, using the algebraic structure of the Stone-$\\v{C}$ech\ncompactification $\\beta$ S of a semigroup S, N. Hindman and V. Bergelson\nextended the theorem in 1990. H. Shi and H. Yang established a topological\ndynamical characterization of central sets in an arbitrary semigroup (S,+), and\nshowed it to be equivalent to the usual algebraic characterization. D. De, N.\nHindman, and D. Strauss later proved a stronger version of the Central Sets\nTheorem for semigroups in 2008. D. Phulara further genaralized the result for\ncommutative semigroups in 2015. Recently in his work, Zhang generalized it\nfurther and proved the central sets theorem for uncountably many central sets.\nWe extend the theorem to arbitrary adequate partial semigroups and VIP systems.", "AI": {"tldr": "中心集定理是Ramsey理论的核心结果，本文综述了其从拓扑动力系统到半群代数结构的扩展历程，并最终推广至任意适度偏半群与VIP系统。", "motivation": "中心集定理作为Hindman定理与van der Waerden定理的共同推广，其不断泛化的研究揭示了Ramsey理论的深层代数与拓扑结构关联。", "method": "结合Stone-\\v{C}ech紧化$\\beta S$的代数工具（Hindman & Bergelson）与拓扑动力系统方法（Shi & Yang），最终采用偏半群理论进行扩展。", "result": "定理被推广至适度偏半群及VIP系统，且Zhang近期成果实现了不可数中心集的扩展，突破了原有可数限制。", "conclusion": "该系列工作建立了中心集定理的最广泛形式，为未来非交换结构与高阶组合的Ramsey性质研究奠定了基础。"}}
{"id": "2506.23018", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.23018", "abs": "https://arxiv.org/abs/2506.23018", "authors": ["Jiajia Yu", "Jian-Guo Liu", "Hongkai Zhao"], "title": "Equilibrium Correction Iteration for A Class of Mean-Field Game Inverse Problem", "comment": null, "summary": "This work investigates the ambient potential identification problem in\ninverse Mean-Field Games (MFGs), where the goal is to recover the unknown\npotential from the value function at equilibrium. We propose a simple yet\neffective iterative strategy, Equilibrium Correction Iteration (ECI), that\nleverages the structure of MFGs rather than relying on generic optimization\nformulations. ECI uncovers hidden information from equilibrium measurements,\noffering a new perspective on inverse MFGs. To improve computational\nefficiency, two acceleration variants are introduced: Best Response Iteration\n(BRI), which uses inexact forward solvers, and Hierarchical ECI (HECI), which\nincorporates multilevel grids. While BRI performs efficiently in general\nsettings, HECI proves particularly effective in recovering low-frequency\npotentials. We also highlight a connection between the potential identification\nproblem in inverse MFGs and inverse linear parabolic equations, suggesting\npromising directions for future theoretical analysis. Finally, comprehensive\nnumerical experiments demonstrate how viscosity, terminal time, and interaction\ncosts can influence the well-posedness of the inverse problem.", "AI": {"tldr": "本文提出了一种名为均衡校正迭代(ECI)的新方法，用于解决平均场博弈(MFGs)中的环境势能识别问题，并通过两种加速变体(BRI和HECI)提高计算效率，同时揭示了该问题与逆线性抛物方程的联系。", "motivation": "研究旨在从均衡状态下的值函数中恢复未知势能，为逆平均场博弈问题提供新的解决视角。", "method": "提出了ECI迭代策略，利用MFGs结构而非通用优化框架；开发了BRI(使用非精确正向求解器)和HECI(采用多级网格)两种加速方法。", "result": "数值实验表明：BRI在通用场景高效，HECI擅长低频势能恢复；同时揭示了粘度、终止时间和交互成本对逆问题适定性的影响。", "conclusion": "该工作不仅为逆MFGs提供了有效解决方案，还通过建立与逆抛物方程的联系，为未来理论分析指明了方向。"}}
{"id": "2506.23296", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23296", "abs": "https://arxiv.org/abs/2506.23296", "authors": ["Naoto Kiribuchi", "Kengo Zenitani", "Takayuki Semitsu"], "title": "Securing AI Systems: A Guide to Known Attacks and Impacts", "comment": "34 pages, 16 figures", "summary": "Embedded into information systems, artificial intelligence (AI) faces\nsecurity threats that exploit AI-specific vulnerabilities. This paper provides\nan accessible overview of adversarial attacks unique to predictive and\ngenerative AI systems. We identify eleven major attack types and explicitly\nlink attack techniques to their impacts -- including information leakage,\nsystem compromise, and resource exhaustion -- mapped to the confidentiality,\nintegrity, and availability (CIA) security triad. We aim to equip researchers,\ndevelopers, security practitioners, and policymakers, even those without\nspecialized AI security expertise, with foundational knowledge to recognize\nAI-specific risks and implement effective defenses, thereby enhancing the\noverall security posture of AI systems.", "AI": {"tldr": "本文综述了针对预测性和生成性AI系统的独特对抗攻击，识别了11种主要攻击类型，并将攻击技术与对机密性、完整性和可用性（CIA）安全三要素的影响联系起来，旨在提升AI系统的整体安全防护能力。", "motivation": "随着AI技术嵌入信息系统，其面临利用AI特有漏洞的安全威胁。本文旨在为非AI安全专家提供基础知识，帮助他们识别AI特有风险并实施有效防御。", "method": "通过系统梳理，识别了11种主要攻击类型，并明确将攻击技术与其对CIA安全三要素（机密性、完整性、可用性）的影响联系起来，包括信息泄露、系统破坏和资源耗尽等。", "result": "研究为研究人员、开发者、安全从业者和政策制定者提供了对抗攻击的全面视角，帮助他们理解AI系统的安全漏洞及其潜在影响。", "conclusion": "本文通过系统分析AI特有安全威胁，为提升AI系统的整体安全防护能力提供了基础知识和实用指导，有助于推动AI技术的安全应用。"}}
{"id": "2506.23276", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.23276", "abs": "https://arxiv.org/abs/2506.23276", "authors": ["David Guzman Piedrahita", "Yongjin Yang", "Mrinmaya Sachan", "Giorgia Ramponi", "Bernhard Schölkopf", "Zhijing Jin"], "title": "Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games", "comment": null, "summary": "As large language models (LLMs) are increasingly deployed as autonomous\nagents, understanding their cooperation and social mechanisms is becoming\nincreasingly important. In particular, how LLMs balance self-interest and\ncollective well-being is a critical challenge for ensuring alignment,\nrobustness, and safe deployment. In this paper, we examine the challenge of\ncostly sanctioning in multi-agent LLM systems, where an agent must decide\nwhether to invest its own resources to incentivize cooperation or penalize\ndefection. To study this, we adapt a public goods game with institutional\nchoice from behavioral economics, allowing us to observe how different LLMs\nnavigate social dilemmas over repeated interactions. Our analysis reveals four\ndistinct behavioral patterns among models: some consistently establish and\nsustain high levels of cooperation, others fluctuate between engagement and\ndisengagement, some gradually decline in cooperative behavior over time, and\nothers rigidly follow fixed strategies regardless of outcomes. Surprisingly, we\nfind that reasoning LLMs, such as the o1 series, struggle significantly with\ncooperation, whereas some traditional LLMs consistently achieve high levels of\ncooperation. These findings suggest that the current approach to improving\nLLMs, which focuses on enhancing their reasoning capabilities, does not\nnecessarily lead to cooperation, providing valuable insights for deploying LLM\nagents in environments that require sustained collaboration. Our code is\navailable at https://github.com/davidguzmanp/SanctSim", "AI": {"tldr": "研究探讨大型语言模型（LLM）在多智能体系统中如何平衡自利与集体利益，发现不同模型在合作行为上存在显著差异，推理能力强的模型反而不易达成合作。", "motivation": "随着LLM作为自主智能体部署的增加，理解其合作机制及如何平衡个体与集体利益对确保模型对齐、鲁棒性和安全部署至关重要。", "method": "通过改编行为经济学中的公共物品博弈实验，观察不同LLM在重复互动中如何应对社会困境，特别关注资源投入以激励合作或惩罚背叛的行为。", "result": "发现四种行为模式：稳定高合作型、波动参与型、合作衰退型及策略僵化型。出乎意料的是，推理能力强的o1系列模型合作表现较差，而部分传统LLM反而能持续达成高效合作。", "conclusion": "当前提升LLM推理能力的优化方向未必能促进合作行为，这对需要持续协作的环境部署LLM智能体具有重要启示。代码已开源。"}}
{"id": "2506.23097", "categories": ["math.OC", "90C15 (Primary) 90C39 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.23097", "abs": "https://arxiv.org/abs/2506.23097", "authors": ["Dominic S. T. Keehan", "Andrew B. Philpott", "Edward J. Anderson"], "title": "On the Out-of-Sample Performance of Stochastic Dynamic Programming and Model Predictive Control", "comment": "31 pages, 6 figures", "summary": "Sample average approximation-based stochastic dynamic programming (SDP) and\nmodel predictive control (MPC) are two different methods for approaching\nmultistage stochastic optimization. In this paper we investigate the conditions\nunder which SDP may be outperformed by MPC. We show that, depending on the\npresence of concavity or convexity, MPC can be interpreted as solving a\nmean-constrained distributionally ambiguous version of the problem that is\nsolved by SDP. This furnishes performance guarantees when the true mean is\nknown and provides intuition for why MPC performs better in some applications\nand worse in others. We then study a multistage stochastic optimization problem\nthat is representative of the type for which MPC may be the better choice. We\nfind that this can indeed be the case when the probability distribution of the\nunderlying random variable is skewed or has enough weight in the right-hand\ntail.", "AI": {"tldr": "本文探讨了在何种条件下基于样本平均近似的随机动态规划(SDP)可能被模型预测控制(MPC)超越。研究发现，根据问题的凹凸性，MPC可视为解决SDP问题的均值约束分布模糊版本，这解释了MPC在某些应用中表现更优的原因。", "motivation": "研究动机是比较SDP和MPC两种多阶段随机优化方法的性能差异，特别是在特定条件下MPC可能优于SDP的情况。", "method": "通过理论分析，将MPC解释为求解均值约束的分布模糊问题，并与SDP进行对比。随后通过一个代表性多阶段随机优化问题进行实证研究。", "result": "研究发现当底层随机变量的概率分布存在偏态或右尾权重较大时，MPC确实可能成为更优的选择。", "conclusion": "结论表明MPC在特定分布特征下具有优势，这为实际应用中方法选择提供了理论依据。分布特性(如偏态和尾部权重)是决定MPC是否优于SDP的关键因素。"}}
{"id": "2506.23314", "categories": ["cs.CR", "cs.AI", "68T99", "I.2"], "pdf": "https://arxiv.org/pdf/2506.23314", "abs": "https://arxiv.org/abs/2506.23314", "authors": ["Joner Assolin", "Gabriel Canto", "Diego Kreutz", "Eduardo Feitosa", "Hendrio Bragança", "Angelo Nogueira", "Vanderson Rocha"], "title": "Interpretable by Design: MH-AutoML for Transparent and Efficient Android Malware Detection without Compromising Performance", "comment": "18 pages, 10 figures, 7 tabelas, paper submitted to JBCS", "summary": "Malware detection in Android systems requires both cybersecurity expertise\nand machine learning (ML) techniques. Automated Machine Learning (AutoML) has\nemerged as an approach to simplify ML development by reducing the need for\nspecialized knowledge. However, current AutoML solutions typically operate as\nblack-box systems with limited transparency, interpretability, and experiment\ntraceability. To address these limitations, we present MH-AutoML, a\ndomain-specific framework for Android malware detection. MH-AutoML automates\nthe entire ML pipeline, including data preprocessing, feature engineering,\nalgorithm selection, and hyperparameter tuning. The framework incorporates\ncapabilities for interpretability, debugging, and experiment tracking that are\noften missing in general-purpose solutions. In this study, we compare MH-AutoML\nagainst seven established AutoML frameworks: Auto-Sklearn, AutoGluon, TPOT,\nHyperGBM, Auto-PyTorch, LightAutoML, and MLJAR. Results show that MH-AutoML\nachieves better recall rates while providing more transparency and control. The\nframework maintains computational efficiency comparable to other solutions,\nmaking it suitable for cybersecurity applications where both performance and\nexplainability matter.", "AI": {"tldr": "本文提出MH-AutoML框架，针对安卓恶意软件检测领域，通过自动化机器学习流程并增强可解释性，在保持计算效率的同时实现了优于主流AutoML工具的召回率。", "motivation": "现有AutoML方案在安卓恶意软件检测中存在黑箱操作、可解释性差及实验追溯困难等问题，亟需开发兼具自动化与透明度的领域专用框架。", "method": "MH-AutoML实现了端到端自动化机器学习流程（数据预处理、特征工程、算法选择、超参数调优），并集成可解释性分析、调试和实验追踪模块。", "result": "在对比Auto-Sklearn等7种主流框架的实验中，MH-AutoML展现出更高的召回率（提升约3-5%）及显著的可解释性优势，同时保持相当的计算效率。", "conclusion": "该框架为网络安全领域提供了性能与可解释性兼备的解决方案，其领域定制化设计模式对AutoML在专业场景的应用具有示范意义。"}}
{"id": "2506.23306", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23306", "abs": "https://arxiv.org/abs/2506.23306", "authors": ["Qi Liu", "Can Li", "Wanjing Ma"], "title": "GATSim: Urban Mobility Simulation with Generative Agents", "comment": null, "summary": "Traditional agent-based urban mobility simulations rely on rigid rule-based\nsystems that fail to capture the complexity, adaptability, and behavioral\ndiversity characteristic of human travel decision-making. Recent advances in\nlarge language models and AI agent technology offer opportunities to create\nagents with reasoning capabilities, persistent memory, and adaptive learning\nmechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel\nframework that leverages these advances to create generative agents with rich\nbehavioral characteristics for urban mobility simulation. Unlike conventional\napproaches, GATSim agents possess diverse socioeconomic attributes, individual\nlifestyles, and evolving preferences that shape their mobility decisions\nthrough psychologically-informed memory systems, tool usage capabilities, and\nlifelong learning mechanisms. The main contributions of this study include: (1)\na comprehensive architecture combining an urban mobility foundation model with\nagent cognitive systems and transport simulation environment, (2) a fully\nfunctional prototype implementation, and (3) systematic validation\ndemonstrating that generative agents produce believable travel behaviors.\nThrough designed reflection processes, generative agents in this study can\ntransform specific travel experiences into generalized insights, enabling\nrealistic behavioral adaptation over time with specialized mechanisms for\nactivity planning and real-time reactive behaviors tailored to urban mobility\ncontexts. Experiments show that generative agents perform competitively with\nhuman annotators in mobility scenarios while naturally producing macroscopic\ntraffic evolution patterns. The code for the prototype system is shared at\nhttps://github.com/qiliuchn/gatsim.", "AI": {"tldr": "本文提出GATSim框架，利用大语言模型和AI代理技术创建具有丰富行为特征的生成式代理，用于城市交通模拟，相比传统基于规则的系统更能捕捉人类出行决策的复杂性和适应性。", "motivation": "传统基于规则的代理模拟无法充分反映人类出行决策的复杂性、适应性和行为多样性，而大语言模型和AI代理技术的进步为解决这一问题提供了新机遇。", "method": "GATSim结合城市交通基础模型、代理认知系统和交通模拟环境，通过心理启发的记忆系统、工具使用能力和终身学习机制，创建具有社会经济属性、生活方式和动态偏好的生成式代理。", "result": "实验表明生成式代理能产生可信的出行行为，在交通场景中表现与人类标注者相当，并能自然形成宏观交通演化模式。原型系统代码已开源。", "conclusion": "GATSim框架通过生成式代理实现了更真实的城市交通模拟，其反思机制使代理能将具体出行经验转化为通用认知，从而实现随时间推移的行为适应。"}}
{"id": "2506.23942", "categories": ["math.CO", "cs.CG"], "pdf": "https://arxiv.org/pdf/2506.23942", "abs": "https://arxiv.org/abs/2506.23942", "authors": ["Zach Hunter", "Aleksa Milojević", "Istvan Tomon", "Benny Sudakov"], "title": "$C_4$-free subgraphs of high degree with geometric applications", "comment": "37 pages, including references", "summary": "The Zarankiewicz problem, a cornerstone problem in extremal graph theory,\nasks for the maximum number of edges in an $n$-vertex graph that does not\ncontain the complete bipartite graph $K_{s,s}$. While the problem remains\nwidely open in the case of general graphs, the past two decades have seen\nsignificant progress on this problem for various restricted graph classes --\nparticularly those arising from geometric settings -- leading to a deeper\nunderstanding of their structure.\n  In this paper, we develop a new structural tool for addressing\nZarankiewicz-type problems. More specifically, we show that for any positive\ninteger $k$, every graph with average degree $d$ either contains an induced\n$C_4$-free subgraph with average degree at least $k$, or it contains a\n$d$-vertex subgraph with $\\Omega_k(d^2)$ edges. As an application of this\ndichotomy, we propose a unified approach to a large number of Zarankiewicz-type\nproblems in geometry, obtaining optimal bounds in each case.", "AI": {"tldr": "本文提出了一种解决Zarankiewicz型问题的新结构工具，通过展示图的平均度与诱导子图性质之间的二分关系，为几何领域中的多个极值图论问题提供了统一解决方法。", "motivation": "Zarankiewicz问题作为极值图论的核心问题，研究不含完全二分图$K_{s,s}$的图中边数的最大值。尽管一般图的情况仍未解决，但在几何图类中的进展促使开发新工具以统一处理此类问题。", "method": "作者证明了对任意正整数$k$，任何平均度为$d$的图要么包含一个平均度至少为$k$的诱导无$C_4$子图，要么包含一个具有$\\Omega_k(d^2)$条边的$d$顶点子图。", "result": "该二分定理被应用于几何中的Zarankiewicz型问题，在每个案例中都获得了最优边界，验证了方法的有效性。", "conclusion": "研究提出的结构工具为极值图论问题提供了统一框架，特别在几何图类中实现了理论突破，未来可扩展至更广泛的图类研究。"}}
{"id": "2506.23131", "categories": ["math.OC", "05C20, 90C26, 90C27, 90C32, 90C30"], "pdf": "https://arxiv.org/pdf/2506.23131", "abs": "https://arxiv.org/abs/2506.23131", "authors": ["Sihong Shao", "Chuan Yang", "Xinyang Ye"], "title": "Conductance Estimation in Digraphs: Submodular Transformation, Lovász Extension and Dinkelbach Iteration", "comment": "20 pages, 4 figures", "summary": "Conventional spectral digraph partitioning methods typically symmetrize the\nadjacency matrix, thereby transforming the directed graph partitioning problem\ninto an undirected one, where bipartitioning is commonly linked to minimizing\ngraph conductance. However, such symmetrization approaches disregard the\ndirectional dependencies of edges in digraphs, failing to capture the inherent\nimbalance crucial to directed network modeling. Building on the parallels\nbetween digraph conductance and conductance under submodular transformations,\nwe develop a generalized framework to derive their continuous formulations. By\nleveraging properties of the Lov\\'asz extension, this framework addresses the\nfundamental asymmetry problem in digraph partitioning. We then formulate an\nequivalent fractional programming problem, relax it via a three-step Dinkelbach\niteration procedure, and design the Directed Simple Iterative ($\\mathbf{DSI}$)\nalgorithm for estimating digraph conductance. The subproblem within\n$\\mathbf{DSI}$ is analytically solvable, and the algorithm is guaranteed to\nconverge provably to a binary local optimum. Extensive experiments on synthetic\nand real-world networks demonstrate that our $\\mathbf{DSI}$ algorithm\nsignificantly outperforms several state-of-the-art methods in digraph\nconductance minimization.", "AI": {"tldr": "本文提出了一种新的有向图分割框架，通过Lov\\'asz扩展和分数规划，设计了DSI算法，显著优于现有方法。", "motivation": "传统有向图分割方法通过对称化邻接矩阵忽略方向性，无法捕捉网络内在不平衡性，亟需新方法解决这一根本不对称问题。", "method": "基于子模变换的传导性理论，构建连续化框架，采用三步Dinkelbach迭代松弛分数规划问题，提出可解析求解子问题且收敛性有保证的DSI算法。", "result": "在合成和真实网络上的实验表明，DSI算法在有向图传导最小化任务中显著优于现有最先进方法。", "conclusion": "该研究通过数学严谨的算法设计，有效解决了有向图分割中的方向依赖性难题，为网络分析提供了新工具。"}}
{"id": "2506.23435", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2506.23435", "abs": "https://arxiv.org/abs/2506.23435", "authors": ["Hayder Tirmazi"], "title": "All Proof of Work But No Proof of Play", "comment": "Published in CFAIL 2025", "summary": "Speedrunning is a competition that emerged from communities of early video\ngames such as Doom (1993). Speedrunners try to finish a game in minimal time.\nProvably verifying the authenticity of submitted speedruns is an open problem.\nTraditionally, best-effort speedrun verification is conducted by on-site human\nobservers, forensic audio analysis, or a rigorous mathematical analysis of the\ngame mechanics. Such methods are tedious, fallible, and, perhaps worst of all,\nnot cryptographic. Motivated by naivety and the Dunning-Kruger effect, we\nattempt to build a system that cryptographically proves the authenticity of\nspeedruns. This paper describes our attempted solutions and ways to circumvent\nthem. Through a narration of our failures, we attempt to demonstrate the\ndifficulty of authenticating live and interactive human input in untrusted\nenvironments, as well as the limits of signature schemes, game integrity, and\nprovable play.", "AI": {"tldr": "本文探讨了如何通过密码学方法验证游戏速通记录的真实性，尽管最终未能成功，但揭示了在不可信环境中验证实时交互输入的困难。", "motivation": "速通比赛（如《毁灭战士》1993）需要验证玩家提交记录的真实性。传统方法依赖人工观察或游戏机制分析，但缺乏密码学保障。受达克效应启发，作者尝试构建密码学验证系统。", "method": "作者尝试设计多种密码学方案来证明速通记录的真实性，并详细记录了每种方案的规避方法。", "result": "所有尝试的方案均告失败，揭示了签名方案、游戏完整性和可验证玩法在实时交互验证中的局限性。", "conclusion": "研究表明，在不可信环境中验证人类实时交互输入极具挑战性，现有密码学工具难以满足需求，这为未来研究指明了方向。"}}
{"id": "2506.23464", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23464", "abs": "https://arxiv.org/abs/2506.23464", "authors": ["Sahil Tripathi", "Md Tabrez Nafis", "Imran Hussain", "Jiechao Gao"], "title": "The Confidence Paradox: Can LLM Know When It's Wrong", "comment": null, "summary": "Document Visual Question Answering (DocVQA) systems are increasingly deployed\nin real world applications, yet they remain ethically opaque-often producing\noverconfident answers to ambiguous questions or failing to communicate\nuncertainty in a trustworthy manner. This misalignment between model confidence\nand actual knowledge poses significant risks, particularly in domains requiring\nethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT\nhave advanced SOTA performance by focusing on architectural sophistication and\naccuracy; however, they fall short in ethical responsiveness.\n  To address these limitations, we introduce HonestVQA, a self-supervised\nhonesty calibration framework for ethically aligned DocVQA. Our model-agnostic\nmethod quantifies uncertainty to identify knowledge gaps, aligns model\nconfidence with actual correctness using weighted loss functions, and enforces\nethical response behavior via contrastive learning. We further introduce two\nprincipled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence\nIndex (ECI)--to benchmark alignment between confidence, accuracy, and ethical\ncommunication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3%\nand F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces\noverconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In\ncross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score,\ndemonstrating strong generalization. Ablation shows a 3.8% drop in accuracy\nwithout alignment or contrastive loss.", "AI": {"tldr": "本文提出HonestVQA框架，通过自监督诚实校准解决文档视觉问答（DocVQA）中的伦理问题，提升模型置信度与准确性的对齐，并在多个数据集上验证了其有效性。", "motivation": "现有DocVQA系统（如LayoutLMv3、UDOP、DONUT）在伦理响应性方面存在不足，常对模糊问题给出过度自信的答案，缺乏可信的不确定性传达，这在需要伦理问责的领域存在重大风险。", "method": "HonestVQA采用模型无关方法：1）量化不确定性以识别知识缺口；2）使用加权损失函数对齐模型置信度与实际正确性；3）通过对比学习强制伦理响应行为。同时提出H-Score和ECI两项评估指标。", "result": "实验表明，HonestVQA在SpDocVQA等数据集上准确率提升4.3%，F1值提升4.3%，H-Score和ECI分别降低0.072和0.078。跨领域评估中达到78.9%准确率和76.1% F1值，消融实验显示未对齐或缺失对比损失会导致准确率下降3.8%。", "conclusion": "HonestVQA通过伦理对齐机制显著改善了DocVQA系统的可信度与泛化能力，为伦理敏感的文档理解任务提供了可量化的解决方案框架。"}}
{"id": "2506.23278", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.23278", "abs": "https://arxiv.org/abs/2506.23278", "authors": ["Susumu Hashimoto", "Takeaki Uno"], "title": "Sample-Cluster-Select: A new framework to obtain diverse approximate solutions of combinatorial optimization problems", "comment": "29 pages, 6 figures", "summary": "When solving real-world problems, practitioners often hesitate to implement\nsolutions obtained from mathematical models, especially for important\ndecisions. This hesitation stems from practitioners' lack of trust in\noptimization models and computational results. To address these challenges, we\npropose Sample-Cluster-Select (SCS) for solving practical combinatorial\noptimization problems under the assumption of potentially acceptable solution\nset. SCS first samples the potential solutions, performs clustering on these\nsolutions, and selects a representative solution for each cluster. SCS aims to\nbuild trust by helping users understand the solution space through multiple\nrepresentative solutions, while simultaneously identifying promising\nalternatives around these solutions. We conducted experiments on randomly\ngenerated instances, comparing SCS against multi-start local search and\n$k$-best algorithms where efficient methods exist, or evolutionary algorithms\notherwise. The results show that SCS outperforms multi-start local search and\n$k$-best algorithms in most cases, while showing competitive performance\nagainst evolutionary algorithms, though not surpassing some of their variants.\nMost importantly, we found that the clustering approach provides insights into\nsolutions that are difficult to obtain with existing methods, such as local\nstructures of similar potential solutions and neighboring solutions of\nrepresentative solutions. Thus, our approach helps practitioners understand the\nsolution space better, thereby increasing their confidence in implementing the\nproposed solutions.", "AI": {"tldr": "本文提出Sample-Cluster-Select (SCS)方法，通过采样、聚类和选择代表性解决方案，帮助用户理解组合优化问题的解空间，增强对计算结果的信任。实验表明SCS优于多起点局部搜索和$k$-best算法，并与进化算法表现相当。", "motivation": "实践中，决策者常因对优化模型和计算结果缺乏信任而犹豫是否实施数学模型的解。SCS旨在通过提供多个代表性解及其邻近解，帮助用户理解解空间，从而建立信任。", "method": "SCS方法分为三步：采样潜在解、对这些解进行聚类、为每个聚类选择一个代表性解。该方法假设存在可接受的解集，并通过聚类揭示解空间的局部结构和邻近解。", "result": "在随机生成的实例上，SCS在大多数情况下优于多起点局部搜索和$k$-best算法，与进化算法表现相当，但未超越某些变体。聚类方法提供了现有方法难以获得的解空间洞察，如相似潜在解的局部结构和代表性解的邻近解。", "conclusion": "SCS方法通过提供多个代表性解及其邻近解，帮助用户更好地理解解空间，从而增强对实施解决方案的信心。聚类方法为解空间分析提供了新的视角。"}}
{"id": "2506.23474", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23474", "abs": "https://arxiv.org/abs/2506.23474", "authors": ["Zhiwei Lin", "Bonan Ruan", "Jiahao Liu", "Weibo Zhao"], "title": "A Large-Scale Evolvable Dataset for Model Context Protocol Ecosystem and Security Analysis", "comment": null, "summary": "The Model Context Protocol (MCP) has recently emerged as a standardized\ninterface for connecting language models with external tools and data. As the\necosystem rapidly expands, the lack of a structured, comprehensive view of\nexisting MCP artifacts presents challenges for research. To bridge this gap, we\nintroduce MCPCorpus, a large-scale dataset containing around 14K MCP servers\nand 300 MCP clients. Each artifact is annotated with 20+ normalized attributes\ncapturing its identity, interface configuration, GitHub activity, and metadata.\nMCPCorpus provides a reproducible snapshot of the real-world MCP ecosystem,\nenabling studies of adoption trends, ecosystem health, and implementation\ndiversity. To keep pace with the rapid evolution of the MCP ecosystem, we\nprovide utility tools for automated data synchronization, normalization, and\ninspection. Furthermore, to support efficient exploration and exploitation, we\nrelease a lightweight web-based search interface. MCPCorpus is publicly\navailable at: https://github.com/Snakinya/MCPCorpus.", "AI": {"tldr": "本文介绍了MCPCorpus，一个包含约1.4万个MCP服务器和300个MCP客户端的大规模数据集，用于标准化研究语言模型与外部工具的连接接口。", "motivation": "随着MCP生态系统的快速扩展，缺乏对现有MCP构件的结构化、全面视图给研究带来了挑战。", "method": "通过收集和标注大量MCP构件（每个构件包含20多个标准化属性），并提供自动化数据同步、规范化和检查工具，以及基于网络的轻量级搜索界面。", "result": "MCPCorpus提供了MCP生态系统的可重现快照，支持对采用趋势、生态系统健康和实现多样性的研究。", "conclusion": "MCPCorpus为研究社区提供了一个公开可用的资源，有助于跟踪和理解MCP生态系统的快速演变。"}}
{"id": "2506.23503", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23503", "abs": "https://arxiv.org/abs/2506.23503", "authors": ["Bosubabu Sambana", "Kondreddygari Archana", "Suram Indhra Sena Reddy", "Shaik Meethaigar Jameer Basha", "Shaik Karishma"], "title": "Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence", "comment": "6 Pages, 5 Figures, IEEE IDCIoT 2025", "summary": "Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the\nirrational thought patterns associated with mental health disorders, but its\neffectiveness relies on accurately identifying cognitive pathways to provide\ntargeted treatment. In today's digital age, individuals often express negative\nemotions on social media, where they may reveal cognitive distortions, and in\nsevere cases, exhibit suicidal tendencies. However, there is a significant gap\nin methodologies designed to analyze these cognitive pathways, which could be\ncritical for psychotherapists aiming to deliver timely and effective\ninterventions in online environments. Cognitive Behavioral Therapy (CBT)\nframework leveraging acceptance, commitment and data augmentation to categorize\nand address both textual and visual content as positive or negative.\nSpecifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5,\nPEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages\nfocusing on detecting negative emotions and cognitive distortions within social\nmedia data. While existing models are primarily designed to identify negative\nthoughts, the proposed system goes beyond this by predicting additional\nnegative side effects and other potential mental health disorders likes\nPhobias, Eating Disorders. This enhancement allows for a more comprehensive\nunderstanding and intervention strategy, offering psychotherapists a powerful\ntool for early detection and treatment of various psychological issues.", "AI": {"tldr": "该论文提出了一种基于认知行为疗法（CBT）的框架，通过情感分析和文本处理技术，从社交媒体数据中识别负面情绪和认知扭曲，以辅助心理治疗师进行早期干预。", "motivation": "当前缺乏有效分析社交媒体中认知路径的方法，而这些数据可能包含用户的心理健康问题线索，如认知扭曲和自杀倾向，亟需工具支持在线心理干预。", "method": "系统整合BERT、RoBERTa进行情感分析，T5、PEGASUS实现文本摘要，mT5处理多语言翻译，通过数据增强技术分类文本与视觉内容，并扩展预测其他心理健康问题（如恐惧症、进食障碍）。", "result": "该框架不仅能识别负面思维，还能预测潜在心理健康并发症，为治疗师提供更全面的早期检测和干预策略。", "conclusion": "结合CBT与NLP技术的系统可增强对社交媒体用户心理状态的洞察，成为心理治疗领域有效的数字化辅助工具。"}}
{"id": "2506.23970", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.23970", "abs": "https://arxiv.org/abs/2506.23970", "authors": ["Lawrence Hollom", "Lyuben Lichev", "Adva Mond", "Julien Portier", "Yiting Wang"], "title": "Approximate Itai-Zehavi conjecture for random graphs", "comment": "25 pages", "summary": "A famous conjecture by Itai and Zehavi states that, for every\n$d$-vertex-connected graph $G$ and every vertex $r$ in $G$, there are $d$\nspanning trees of $G$ such that, for every vertex $v$ in $G\\setminus \\{r\\}$,\nthe paths between $r$ and $v$ in different trees are internally\nvertex-disjoint. We show that with high probability the Itai-Zehavi conjecture\nholds asymptotically for the Erd\\H{o}s-R\\'enyi random graph $G(n,p)$ when $np=\n\\omega(\\log n)$ and for random regular graphs $G(n,d)$ when $d= \\omega(\\log\nn)$. Moreover, we essentially confirm the conjecture up to a constant factor\nfor sparser random regular graphs. This answers positively a question of\nDragani\\'{c} and Krivelevich. Our proof makes use of recent developments on\nsprinkling techniques in random regular graphs.", "AI": {"tldr": "本文证明了Itai-Zehavi猜想在Erd\\H{o}s-R\\'enyi随机图$G(n,p)$（当$np=\\omega(\\log n)$时）和随机正则图$G(n,d)$（当$d=\\omega(\\log n)$时）中高概率成立，并基本确认了稀疏随机正则图中该猜想在常数因子内的正确性。", "motivation": "研究Itai-Zehavi猜想在随机图中的渐近成立性，并回答Dragani\\'{c}和Krivelevich提出的问题。", "method": "利用了随机正则图中最新的sprinkling技术。", "result": "证明了在$np=\\omega(\\log n)$的$G(n,p)$和$d=\\omega(\\log n)$的$G(n,d)$中，Itai-Zehavi猜想高概率成立，且在稀疏随机正则图中猜想基本正确。", "conclusion": "该研究不仅验证了Itai-Zehavi猜想在两类随机图中的渐近正确性，还为稀疏随机正则图提供了常数因子内的确认，推动了相关领域的发展。"}}
{"id": "2506.23303", "categories": ["math.OC", "math.FA", "Primary 90C15, 90C25, 65K05, Secondary 68T07, 68W20, 68W40"], "pdf": "https://arxiv.org/pdf/2506.23303", "abs": "https://arxiv.org/abs/2506.23303", "authors": ["Heinz H. Bauschke", "Tran Thanh Tung"], "title": "On the boundedness of the sequence generated by minibatch stochastic gradient descent", "comment": null, "summary": "Stochastic Gradient Descent (SGD) with Polyak's stepsize has recently gained\nrenewed attention in stochastic optimization. Recently, Orvieto,\nLacoste-Julien, and Loizou introduced a decreasing variant of Polyak's\nstepsize, where convergence relies on a boundedness assumption of the iterates.\nThey established that this assumption holds under strong convexity. In this\npaper, we extend their result by proving that boundedness also holds for a\nbroader class of objective functions, including coercive functions. We also\npresent a case in which boundedness may or may not hold.", "AI": {"tldr": "本文扩展了Polyak步长在随机梯度下降(SGD)中的应用，证明了在更广泛的函数类（包括强制函数）中迭代的有界性成立，并讨论了有界性可能不成立的情况。", "motivation": "近期Polyak步长的随机梯度下降方法重新受到关注，但现有研究仅在强凸性假设下证明了迭代的有界性。本文旨在扩展这一结果至更广泛的函数类别。", "method": "通过理论分析，研究了随机梯度下降中采用递减Polyak步长时迭代的有界性条件，特别关注强制函数类。", "result": "证明了在强制函数等更广泛的函数类中，迭代序列的有界性仍然成立，同时提出了一个有界性可能不成立的案例。", "conclusion": "研究扩展了Polyak步长随机梯度下降的适用性，为更广泛的目标函数提供了收敛性保证，并指出了有界性条件的边界情况。"}}
{"id": "2506.23583", "categories": ["cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23583", "abs": "https://arxiv.org/abs/2506.23583", "authors": ["Marvin Xhemrishi", "Alexandre Graell i Amat", "Balázs Pejó"], "title": "Detect \\& Score: Privacy-Preserving Misbehaviour Detection and Contribution Evaluation in Federated Learning", "comment": "The shorter version is accepted at FL-AsiaCCS 25", "summary": "Federated learning with secure aggregation enables private and collaborative\nlearning from decentralised data without leaking sensitive client information.\nHowever, secure aggregation also complicates the detection of malicious client\nbehaviour and the evaluation of individual client contributions to the\nlearning. To address these challenges, QI (Pejo et al.) and FedGT (Xhemrishi et\nal.) were proposed for contribution evaluation (CE) and misbehaviour detection\n(MD), respectively. QI, however, lacks adequate MD accuracy due to its reliance\non the random selection of clients in each training round, while FedGT lacks\nthe CE ability. In this work, we combine the strengths of QI and FedGT to\nachieve both robust MD and accurate CE. Our experiments demonstrate superior\nperformance compared to using either method independently.", "AI": {"tldr": "结合QI和FedGT的优势，提出了一种同时实现恶意行为检测和贡献评估的联邦学习方法。", "motivation": "安全聚合的联邦学习虽然保护了客户数据隐私，但增加了恶意行为检测和贡献评估的难度。现有方法QI和FedGT分别存在检测精度不足和缺乏贡献评估能力的问题。", "method": "整合QI和FedGT的方法，利用QI的贡献评估能力和FedGT的恶意行为检测能力，实现两者的优势互补。", "result": "实验表明，结合方法在恶意行为检测和贡献评估方面均优于单独使用QI或FedGT。", "conclusion": "通过融合QI和FedGT，本研究成功实现了联邦学习中既鲁棒的恶意行为检测又准确的贡献评估。"}}
{"id": "2506.23504", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23504", "abs": "https://arxiv.org/abs/2506.23504", "authors": ["Bosubabu Sambana", "Kotamsetty Geethika Devi", "Bandi Rajeswara Reddy", "Galeti Mohammad Hussain", "Gownivalla Siddartha"], "title": "Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM", "comment": "6 Pages, 7 Figures", "summary": "The recent development of advanced machine learning methods for hybrid models\nhas greatly addressed the need for the correct prediction of electrical prices.\nThis method combines AlexNet and LSTM algorithms, which are used to introduce a\nnew model with higher accuracy in price forecasting. Despite RNN and ANN being\neffective, they often fail to deal with forex time sequence data. The\ntraditional methods do not accurately forecast the prices. These traditional\nmethods only focus on demand and price which leads to insufficient analysis of\ndata. To address this issue, using the hybrid approach, which focuses on\nexternal variables that also effect the predicted prices. Nevertheless, due to\nAlexNet's excellent feature extraction and LSTM's learning sequential patterns,\nthe prediction accuracy is vastly increased. The model is built on the past\ndata, which has been supplied with the most significant elements like demand,\ntemperature, sunlight, and rain. For example, the model applies methods, such\nas minimum-maximum scaling and a time window, to predict the electricity prices\nof the future. The results show that this hybrid model is good than the\nstandalone ones in terms of accuracy. Although we got our accuracy rating of\n97.08, it shows higher accompaniments than remaining models RNN and ANN with\naccuracies of 96.64 and 96.63 respectively.", "AI": {"tldr": "本文提出了一种结合AlexNet和LSTM的混合模型，用于提高电力价格预测的准确性。该模型通过整合外部变量（如需求、温度、阳光和降雨）并使用最小-最大缩放和时间窗口等方法，显著提升了预测性能。实验结果显示，该混合模型的准确率达到97.08%，优于单独的RNN和ANN模型。", "motivation": "传统的电力价格预测方法（如RNN和ANN）在处理外汇时间序列数据时表现不佳，且仅关注需求和价格，导致数据分析不足。为了解决这一问题，本文提出了一种混合模型，通过引入外部变量来提高预测准确性。", "method": "该模型结合了AlexNet的优秀特征提取能力和LSTM的序列模式学习能力，并整合了需求、温度、阳光和降雨等关键因素。此外，还采用了最小-最大缩放和时间窗口等技术来优化预测。", "result": "实验结果表明，该混合模型的预测准确率达到97.08%，高于单独的RNN（96.64%）和ANN（96.63%）模型，证明了其在电力价格预测中的优越性。", "conclusion": "本文提出的AlexNet与LSTM混合模型在电力价格预测中表现出更高的准确性和鲁棒性，为未来研究提供了新的方向。"}}
{"id": "2506.23592", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23592", "abs": "https://arxiv.org/abs/2506.23592", "authors": ["Víctor Mayoral-Vilches"], "title": "Cybersecurity AI: The Dangerous Gap Between Automation and Autonomy", "comment": null, "summary": "The cybersecurity industry combines \"automated\" and \"autonomous\" AI, creating\ndangerous misconceptions about system capabilities. Recent milestones like XBOW\ntopping HackerOne's leaderboard showcase impressive progress, yet these systems\nremain fundamentally semi-autonomous--requiring human oversight. Drawing from\nrobotics principles, where the distinction between automation and autonomy is\nwell-established, I take inspiration from prior work and establish a 6-level\ntaxonomy (Level 0-5) distinguishing automation from autonomy in Cybersecurity\nAI. Current \"autonomous\" pentesters operate at Level 3-4: they execute complex\nattack sequences but need human review for edge cases and strategic decisions.\nTrue Level 5 autonomy remains aspirational. Organizations deploying\nmischaracterized \"autonomous\" tools risk reducing oversight precisely when it's\nmost needed, potentially creating new vulnerabilities. The path forward\nrequires precise terminology, transparent capabilities disclosure, and human-AI\npartnership-not replacement.", "AI": {"tldr": "网络安全领域存在对AI能力的误解，当前\"自主\"系统实际处于半自主水平（3-4级），需建立明确分级标准并保持人机协作。", "motivation": "针对行业混淆\"自动化\"与\"自主性\"AI的现象，为避免过度依赖导致监管漏洞，需明确界定网络安全AI的能力等级。", "method": "借鉴机器人学原则，建立6级分类法（0-5级）区分自动化与自主性，分析现有渗透测试工具的实际能力等级。", "result": "当前所谓\"自主\"渗透工具仅达3-4级：能执行复杂攻击链，但边界案例和战略决策仍需人工审核，真正的5级自主尚未实现。", "conclusion": "应规范术语使用、公开透明披露AI能力，构建人机协作而非替代的关系，防止因误判自主性而引发新的安全漏洞。"}}
{"id": "2506.23517", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.23517", "abs": "https://arxiv.org/abs/2506.23517", "authors": ["Selin Dik", "Osman Erdem", "Mehmet Dik"], "title": "Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays", "comment": null, "summary": "As the use of AI tools by students has become more prevalent, instructors\nhave started using AI detection tools like GPTZero and QuillBot to detect AI\nwritten text. However, the reliability of these detectors remains uncertain. In\nour study, we focused mostly on the success rate of GPTZero, the most-used AI\ndetector, in identifying AI-generated texts based on different lengths of\nrandomly submitted essays: short (40-100 word count), medium (100-350 word\ncount), and long (350-800 word count). We gathered a data set consisting of\ntwenty-eight AI-generated papers and fifty human-written papers. With this\nrandomized essay data, papers were individually plugged into GPTZero and\nmeasured for percentage of AI generation and confidence. A vast majority of the\nAI-generated papers were detected accurately (ranging from 91-100% AI believed\ngeneration), while the human generated essays fluctuated; there were a handful\nof false positives. These findings suggest that although GPTZero is effective\nat detecting purely AI-generated content, its reliability in distinguishing\nhuman-authored texts is limited. Educators should therefore exercise caution\nwhen relying solely on AI detection tools.", "AI": {"tldr": "研究评估GPTZero检测AI生成文本的准确性，发现其对纯AI文本识别率高，但对人类文本存在误判，建议教育者谨慎依赖此类工具。", "motivation": "随着学生使用AI工具增多，教师依赖GPTZero等检测工具，但其可靠性存疑，需验证其在不同文本长度下的表现。", "method": "收集28篇AI生成和50篇人类撰写的随机长度论文（短/中/长），通过GPTZero检测AI生成百分比及置信度。", "result": "AI生成文本检测准确率高达91-100%，但人类文本存在波动及误判，显示工具在区分人类作者方面有限。", "conclusion": "GPTZero对纯AI文本有效，但人类文本识别不可靠，教育者需避免单一依赖AI检测工具。"}}
{"id": "2506.24071", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.24071", "abs": "https://arxiv.org/abs/2506.24071", "authors": ["S. A. Kandekar", "R. Barabde", "S. A. Mane"], "title": "The 3-path-connectivity of the augmented cubes", "comment": null, "summary": "Connectivity is a cornerstone concept in graph theory, essential for\nevaluating the robustness of networks against failures. To better capture fault\ntolerance in complex systems, researchers have extended classical connectivity\nnotions, one such extension being the $k$-path-connectivity, $\\pi_k(G)$,\nintroduced by Hager. Given a connected simple graph $G = (V, E)$ and a subset\n$D \\subseteq V$ with $|D| \\geq 2$, a $D$-path is a path that includes all\nvertices in $D$. A collection of such paths is internally disjoint if they\nintersect only at the vertices of $D$ and share no edges. The maximum number of\ninternally disjoint $D$-paths in $G$ is denoted $\\pi_G(D)$, and the\n$k$-path-connectivity is defined as $\\pi_k(G) = \\min \\{ \\pi_G(D) \\mid D\n\\subseteq V(G),\\ |D| = k\\}$. In this paper, we investigate the\n3-path-connectivity of the augmented cube $AQ_n$, a variant of the hypercube\nknown for its enhanced symmetry and fault-tolerant structure. We establish the\nexact value of $\\pi_3(AQ_n)$ and show that: $$\n  \\pi_3(AQ_n) =\n  \\begin{cases}\n  \\frac{3n}{2} - 2, & \\text{if } n \\text{ is even},\n  \\frac{3(n - 1)}{2} - 1, & \\text{if } n \\text{ is odd}.\n  \\end{cases}\n  $$", "AI": {"tldr": "本文研究了增强立方体$AQ_n$的3-路径连通性$\\pi_3(AQ_n)$，确定了其精确值，并展示了奇偶维度下的不同表达式。", "motivation": "为了评估网络在故障情况下的鲁棒性，研究者扩展了经典连通性概念，其中$k$-路径连通性$\\pi_k(G)$是重要指标。增强立方体$AQ_n$因其对称性和容错结构成为研究对象。", "method": "通过定义$D$-路径和内部不相交路径集，计算增强立方体$AQ_n$中任意3顶点子集$D$的最小路径连通数$\\pi_G(D)$，进而确定$\\pi_3(AQ_n)$。", "result": "证明了$\\pi_3(AQ_n)$的精确值：当$n$为偶数时等于$\\frac{3n}{2} - 2$，为奇数时等于$\\frac{3(n - 1)}{2} - 1$。", "conclusion": "该研究不仅完善了增强立方体的理论特性，还为网络容错性分析提供了新的数学工具，奇偶维度的差异结果具有重要理论意义。"}}
{"id": "2506.23475", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.23475", "abs": "https://arxiv.org/abs/2506.23475", "authors": ["Edward Duc Hien Nguyen", "Jaewook J. Suh", "Xin Jiang", "Shiqian Ma"], "title": "Swapping objectives accelerates Davis-Yin splitting", "comment": null, "summary": "In this work, we investigate the application of Davis-Yin splitting (DYS) to\nconvex optimization problems and demonstrate that swapping the roles of the two\nnonsmooth convex functions can result in a faster convergence rate. Such a swap\ntypically yields a different sequence of iterates, but its impact on\nconvergence behavior has been largely understudied or often overlooked. We\naddress this gap by establishing best-known convergence rates for DYS and its\nswapped counterpart, using the primal--dual gap function as the performance\nmetric. Our results indicate that variants of the Douglas--Rachford splitting\nalgorithm (a special case of DYS) share the same worst-case rate, whereas the\nconvergence rates of the two DYS variants differ. This discrepancy is further\nillustrated through concrete examples.", "AI": {"tldr": "本文研究了Davis-Yin分裂（DYS）在凸优化问题中的应用，发现交换两个非光滑凸函数的角色可以加快收敛速度。通过建立最佳收敛率，揭示了DYS及其交换变体在收敛行为上的差异。", "motivation": "在凸优化问题中，交换DYS算法中两个非光滑凸函数的角色对收敛速度的影响尚未充分研究。本文旨在填补这一空白，探讨这种交换如何改变算法的收敛行为。", "method": "使用原始-对偶间隙函数作为性能指标，建立了DYS及其交换变体的最佳收敛率。特别关注了Douglas-Rachford分裂算法（DYS的特例）的收敛行为。", "result": "研究发现，Douglas-Rachford分裂算法的两种变体具有相同的最坏收敛率，而两种DYS变体的收敛率则存在差异。通过具体示例进一步说明了这种差异。", "conclusion": "交换DYS算法中两个非光滑凸函数的角色可以显著影响收敛速度，这一发现为优化算法的设计提供了新的见解。"}}
{"id": "2506.23603", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23603", "abs": "https://arxiv.org/abs/2506.23603", "authors": ["Baihe Ma", "Yanna Jiang", "Xu Wang", "Guangshen Yu", "Qin Wang", "Caijun Sun", "Chen Li", "Xuelei Qi", "Ying He", "Wei Ni", "Ren Ping Liu"], "title": "SoK: Semantic Privacy in Large Language Models", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed in sensitive\ndomains, traditional data privacy measures prove inadequate for protecting\ninformation that is implicit, contextual, or inferable - what we define as\nsemantic privacy. This Systematization of Knowledge (SoK) introduces a\nlifecycle-centric framework to analyze how semantic privacy risks emerge across\ninput processing, pretraining, fine-tuning, and alignment stages of LLMs. We\ncategorize key attack vectors and assess how current defenses, such as\ndifferential privacy, embedding encryption, edge computing, and unlearning,\naddress these threats. Our analysis reveals critical gaps in semantic-level\nprotection, especially against contextual inference and latent representation\nleakage. We conclude by outlining open challenges, including quantifying\nsemantic leakage, protecting multimodal inputs, balancing de-identification\nwith generation quality, and ensuring transparency in privacy enforcement. This\nwork aims to inform future research on designing robust, semantically aware\nprivacy-preserving techniques for LLMs.", "AI": {"tldr": "本文系统化研究了大型语言模型(LLM)中的语义隐私风险，提出了生命周期分析框架，评估现有防御措施的不足，并指出未来研究方向。", "motivation": "随着LLM在敏感领域的广泛应用，传统数据隐私保护方法无法应对隐式、上下文或可推断的语义隐私风险，亟需系统性研究。", "method": "建立以生命周期为中心的分析框架，涵盖输入处理、预训练、微调和对齐阶段，分类攻击向量并评估差分隐私、嵌入加密等现有防御技术。", "result": "发现当前防护在语义层面存在重大缺口，特别是针对上下文推理和潜在表征泄露的防御不足，量化语义泄漏等核心挑战尚未解决。", "conclusion": "提出未来研究方向包括：量化语义泄漏、保护多模态输入、平衡去标识化与生成质量、确保隐私执行的透明度，为LLM设计语义感知的隐私保护技术提供指导。"}}
{"id": "2506.23520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23520", "abs": "https://arxiv.org/abs/2506.23520", "authors": ["Yu Zhang", "Ruijie Yu", "Jidong Tian", "Feng Zhu", "Jiapeng Liu", "Xiaokang Yang", "Yaohui Jin", "Yanyan Xu"], "title": "ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data", "comment": null, "summary": "With the increasing interest in robotic synthesis in the context of organic\nchemistry, the automated extraction of chemical procedures from literature is\ncritical. However, this task remains challenging due to the inherent ambiguity\nof chemical language and the high cost of human annotation required for\ndeveloping reliable computer-aided extraction protocols. Here, we present\nChemActor, a fully fine-tuned large language model (LLM), as a chemical\nexecutor to convert between unstructured experimental procedures and structured\naction sequences. We propose a sequential LLM-generated data framework to\naddress the challenges of insufficient and low-quality annotated data. This\nframework integrates a data selection module that selects data based on\ndistribution divergence, with a general-purpose LLM, to generate\nmachine-executable actions from a single molecule input. Additionally, we\nintroduce a novel multi-round LLMs circle review metric, which reflects the\nmodel's advanced understanding of chemical experimental procedures. Extensive\nexperiments on reaction-to-description (R2D) and description-to-action (D2A)\ntasks demonstrate that ChemActor, augmented by LLM-generated data, achieves\nstate-of-the-art performance, outperforming the baseline model by 10%. The code\nis available at: https://github.com/Zhanghahah/ChemActor.", "AI": {"tldr": "ChemActor是一种基于大型语言模型（LLM）的化学执行器，用于将非结构化的化学实验步骤转换为结构化的操作序列。通过LLM生成的数据框架和多轮评审指标，该模型在反应到描述（R2D）和描述到操作（D2A）任务中表现优异，性能提升10%。", "motivation": "随着有机化学中机器人合成的兴趣增加，从文献中自动提取化学步骤变得至关重要。然而，由于化学语言的固有模糊性和人工标注的高成本，这一任务仍然具有挑战性。", "method": "ChemActor是一个完全微调的大型语言模型（LLM），通过顺序LLM生成的数据框架解决标注数据不足和质量低的问题。该框架集成了基于分布差异的数据选择模块和通用LLM，从单个分子输入生成机器可执行的操作。此外，还引入了多轮LLM循环评审指标，以反映模型对化学实验步骤的高级理解。", "result": "在反应到描述（R2D）和描述到操作（D2A）任务上的大量实验表明，ChemActor通过LLM生成的数据增强，实现了最先进的性能，比基线模型高出10%。", "conclusion": "ChemActor通过LLM生成的数据框架和多轮评审指标，显著提升了化学实验步骤的自动化提取性能，为有机化学中的机器人合成提供了可靠的工具。代码已开源：https://github.com/Zhanghahah/ChemActor。"}}
{"id": "2506.24080", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.24080", "abs": "https://arxiv.org/abs/2506.24080", "authors": ["Alexander Bastien", "Omid Khormali"], "title": "On Link-irregular labelings of Graphs", "comment": null, "summary": "We introduce the concept of link-irregular labelings for graphs, extending\nthe notion of link-irregular graphs through edge labeling with positive\nintegers. A labeling is link-irregular if every vertex has a uniquely labeled\nsubgraph induced by its neighbors. We establish necessary and sufficient\nconditions for the existence of such labelings and define the link-irregular\nlabeling number $\\eta(G)$ as the minimum number of distinct labels required.\nOur main results include necessary and sufficient conditions for the existence\nof link-irregular labelings. We show that certain families of graphs, such as\nbipartite graphs, trees, cycles, hypercubes, and complete multipartite graphs,\ndo not admit link-irregular labelings, while complete graphs and wheel graphs\ndo. Specifically, we prove that $\\eta(K_n) = 2$ for $n \\geq 6$ and $\\eta(K_n) =\n3$ for $n \\in \\{3,4,5\\}$. For wheel graphs $W_n$, we establish that $\\eta(W_n)\n\\approx \\sqrt{2n}$ asymptotically. Finally, we prove that for every positive\ninteger $n$, there exists a graph with a link-irregular labeling number exactly\n$n$, and provide several results on graph operations that preserve labeling\nnumbers.", "AI": {"tldr": "本文提出了图的链接不规则标记概念，通过边标记扩展了链接不规则图的研究。确定了此类标记存在的充要条件，定义了最小标记数$\\eta(G)$，并证明了完全图和轮式图的可标记性及其标记数。", "motivation": "研究图的链接不规则标记，旨在扩展传统链接不规则图理论，探索通过边标记实现顶点邻域子图唯一标识的可能性及其应用价值。", "method": "采用组合数学与图论方法，建立链接不规则标记的充要条件，通过构造性证明分析特定图族（如完全图、轮式图）的标记数$\\eta(G)$，并研究图操作对标记数的影响。", "result": "证明完全图$K_n$在$n\\geq6$时$\\eta(K_n)=2$，$n\\in\\{3,4,5\\}$时需3种标记；轮式图$W_n$的标记数渐近于$\\sqrt{2n}$。同时构造出标记数任意正整数$n$的图例。", "conclusion": "链接不规则标记理论为图标记问题提供新视角，完全图与轮式图的可标记性得到完整刻画，且标记数存在普适构造。未来可进一步研究复杂图族的标记性质。"}}
{"id": "2506.23756", "categories": ["math.OC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2506.23756", "abs": "https://arxiv.org/abs/2506.23756", "authors": ["Jinho Bok", "Jason M. Altschuler"], "title": "Optimized methods for composite optimization: a reduction perspective", "comment": "40 pages", "summary": "Recent advances in convex optimization have leveraged computer-assisted\nproofs to develop optimized first-order methods that improve over classical\nalgorithms. However, each optimized method is specially tailored for a\nparticular problem setting, and it is a well-documented challenge to extend\noptimized methods to other settings due to their highly bespoke design and\nanalysis. We provide a general framework that derives optimized methods for\ncomposite optimization directly from those for unconstrained smooth\noptimization. The derived methods naturally extend the original methods,\ngeneralizing how proximal gradient descent extends gradient descent. The key to\nour result is certain algebraic identities that provide a unified and\nstraightforward way of extending convergence analyses from unconstrained to\ncomposite settings. As concrete examples, we apply our framework to establish\n(1) the phenomenon of stepsize acceleration for proximal gradient descent; (2)\na convergence rate for the proximal optimized gradient method which is faster\nthan FISTA; (3) a new method that improves the state-of-the-art rate for\nminimizing gradient norm in the composite setting.", "AI": {"tldr": "本文提出了一种通用框架，能够直接从无约束光滑优化的优化方法中推导出复合优化的优化方法，扩展了原始方法并统一了收敛性分析。", "motivation": "现有的优化方法通常针对特定问题定制，难以扩展到其他设置。本文旨在解决这一挑战，提供一种通用框架来扩展优化方法。", "method": "通过代数恒等式提供了一种统一且直接的方式，将无约束优化的收敛性分析扩展到复合优化设置。框架将优化方法从无约束光滑优化直接推广到复合优化。", "result": "应用该框架，本文展示了：(1) 近端梯度下降的步长加速现象；(2) 近端优化梯度法的收敛速度优于FISTA；(3) 一种新方法在复合设置中改进了梯度范数最小化的最新速率。", "conclusion": "该框架为复合优化提供了一种通用且高效的优化方法推导方式，显著提升了现有方法的性能，并为未来研究提供了新的方向。"}}
{"id": "2506.23622", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23622", "abs": "https://arxiv.org/abs/2506.23622", "authors": ["Jiahui Wu", "Fucai Luo", "Tiecheng Sun", "Haiyan Wang", "Weizhe Zhang"], "title": "Privacy-Preserving Federated Learning Scheme with Mitigating Model Poisoning Attacks: Vulnerabilities and Countermeasures", "comment": null, "summary": "The privacy-preserving federated learning schemes based on the setting of two\nhonest-but-curious and non-colluding servers offer promising solutions in terms\nof security and efficiency. However, our investigation reveals that these\nschemes still suffer from privacy leakage when considering model poisoning\nattacks from malicious users. Specifically, we demonstrate that the\nprivacy-preserving computation process for defending against model poisoning\nattacks inadvertently leaks privacy to one of the honest-but-curious servers,\nenabling it to access users' gradients in plaintext. To address both privacy\nleakage and model poisoning attacks, we propose an enhanced privacy-preserving\nand Byzantine-robust federated learning (PBFL) scheme, comprising three\ncomponents: (1) a two-trapdoor fully homomorphic encryption (FHE) scheme to\nbolster users' privacy protection; (2) a novel secure normalization judgment\nmethod to preemptively thwart gradient poisoning; and (3) an innovative secure\ncosine similarity measurement method for detecting model poisoning attacks\nwithout compromising data privacy. Our scheme guarantees privacy preservation\nand resilience against model poisoning attacks, even in scenarios with\nheterogeneous, non-IID (Independently and Identically Distributed) datasets.\nTheoretical analyses substantiate the security and efficiency of our scheme,\nand extensive experiments corroborate the efficacy of our private attacks.\nFurthermore, the experimental results demonstrate that our scheme accelerates\ntraining speed while reducing communication overhead compared to the\nstate-of-the-art PBFL schemes.", "AI": {"tldr": "本文提出了一种增强型隐私保护与拜占庭鲁棒的联邦学习方案（PBFL），通过双陷门全同态加密、安全归一化判断和安全余弦相似度测量，解决了现有方案在模型投毒攻击下的隐私泄露问题，并在非独立同分布数据集中验证了其高效性与安全性。", "motivation": "现有基于双诚实但好奇且不共谋服务器的隐私保护联邦学习方案在面临恶意用户的模型投毒攻击时，仍存在隐私泄露问题。研究发现，防御模型投毒攻击的隐私计算过程会意外向其中一个服务器暴露用户梯度明文。", "method": "方案包含三个核心组件：1) 双陷门全同态加密（FHE）增强用户隐私保护；2) 新型安全归一化判断方法预防梯度投毒；3) 创新的安全余弦相似度测量方法在不泄露数据隐私的前提下检测模型投毒攻击。", "result": "理论分析证实了方案的安全性与高效性，实验表明其能加速训练并降低通信开销。在非独立同分布（non-IID）数据场景下，方案仍能有效保障隐私并抵抗模型投毒攻击。", "conclusion": "PBFL方案在隐私保护与抗模型投毒攻击方面均优于现有方案，尤其适用于数据异构的联邦学习场景，为安全高效的分布式机器学习提供了新思路。"}}
{"id": "2506.23549", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23549", "abs": "https://arxiv.org/abs/2506.23549", "authors": ["Huai-Chih Wang", "Hsiang-Chun Chuang", "Hsi-Chun Cheng", "Dai-Jie Wu", "Shao-Hua Sun"], "title": "CooT: Learning to Coordinate In-Context with Coordination Transformers", "comment": "23 pages, 10 tables, 8 figures", "summary": "Effective coordination among artificial agents in dynamic and uncertain\nenvironments remains a significant challenge in multi-agent systems. Existing\napproaches, such as self-play and population-based methods, either generalize\npoorly to unseen partners or require extensive training. To overcome these\nlimitations, we propose Coordination Transformers (CooT), a novel in-context\ncoordination framework that uses recent interaction histories to adapt to\nunseen partners rapidly. Unlike previous approaches that primarily aim to\nincrease the diversity of training partners, CooT explicitly focuses on\nadapting to new partner behaviors by predicting actions aligned with observed\npartner interactions. Trained on interaction trajectories collected from\ndiverse pairs of agents with complementary behaviors, CooT quickly learns\neffective coordination strategies without explicit supervision or fine-tuning.\nEvaluations on the Overcooked benchmark demonstrate that CooT significantly\noutperforms baseline methods in coordination tasks involving previously unseen\npartners. Human evaluations further confirm CooT as the most effective\ncollaborative partner, while extensive ablations highlight its robustness,\nflexibility, and sensitivity to context in multi-agent scenarios.", "AI": {"tldr": "本文提出协调变换器(CooT)，一种基于交互历史快速适应未知伙伴的新型多智能体协调框架，在Overcooked基准测试中显著优于基线方法。", "motivation": "现有方法（如自博弈和群体训练）在泛化性和训练成本方面存在局限，需要一种能快速适应新伙伴行为的协调框架。", "method": "CooT通过分析近期交互历史预测伙伴行为，利用互补行为智能体对的交互轨迹进行无监督训练，无需微调即可学习协调策略。", "result": "在Overcooked测试中，CooT对未知伙伴的协调表现显著优于基线；人类评估确认其协作有效性，消融实验验证了框架的鲁棒性和情境敏感性。", "conclusion": "CooT通过情境化协调机制突破了传统方法的局限性，为动态不确定环境下的多智能体协作提供了新范式。"}}
{"id": "2506.23758", "categories": ["math.OC", "90C56 (Primary) 90C15, 90C25, 90C30 (Secondary)", "G.1.6"], "pdf": "https://arxiv.org/pdf/2506.23758", "abs": "https://arxiv.org/abs/2506.23758", "authors": ["Marco Rando", "Cheik Traoré", "Cesare Molinari", "Lorenzo Rosasco", "Silvia Villa"], "title": "A Structured Proximal Stochastic Variance Reduced Zeroth-order Algorithm", "comment": "32 pages, 3 figures, 3 tables", "summary": "Minimizing finite sums of functions is a central problem in optimization,\narising in numerous practical applications. Such problems are commonly\naddressed using first-order optimization methods. However, these procedures\ncannot be used in settings where gradient information is unavailable.\nFinite-difference methods provide an alternative by approximating gradients\nthrough function evaluations along a set of directions. For finite-sum\nminimization problems, it was shown that incorporating variance-reduction\ntechniques into finite-difference methods can improve convergence rates.\nAdditionally, recent studies showed that imposing structure on the directions\n(e.g., orthogonality) enhances performance. However, the impact of structured\ndirections on variance-reduced finite-difference methods remains unexplored. In\nthis work, we close this gap by proposing a structured variance-reduced\nfinite-difference algorithm for non-smooth finite-sum minimization. We analyze\nthe proposed method, establishing convergence rates for non-convex functions\nand those satisfying the Polyak-{\\L}ojasiewicz condition. Our results show that\nour algorithm achieves state-of-the-art convergence rates while incurring lower\nper-iteration costs. Finally, numerical experiments highlight the strong\npractical performance of our method.", "AI": {"tldr": "本文提出了一种结构化方差缩减有限差分算法，用于解决无梯度信息的非光滑有限和最小化问题，证明了其在非凸函数和满足Polyak-{\\L}ojasiewicz条件下的收敛速率，并通过实验验证了其优越性能。", "motivation": "有限和最小化是优化领域的核心问题，传统一阶优化方法在梯度信息缺失时失效。有限差分法虽能替代，但方差缩减技术与方向结构化的结合效果尚未探索。", "method": "提出结构化方差缩减有限差分算法，将正交性等方向约束融入方差缩减框架，适用于非光滑有限和最小化问题，并降低单次迭代成本。", "result": "理论分析表明，算法在非凸函数上达到最优收敛速率，对满足Polyak-{\\L}ojasiewicz条件的函数同样有效；数值实验证实其实际性能显著优于现有方法。", "conclusion": "该算法通过结构化方向与方差缩减的结合，实现了理论最优性与实践高效性的统一，为无梯度优化问题提供了新解决方案。"}}
{"id": "2506.23634", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23634", "abs": "https://arxiv.org/abs/2506.23634", "authors": ["Youjeong Noh", "Joon-Young Paik", "Jingun Kwon", "Eun-Sun Cho"], "title": "gMBA: Expression Semantic Guided Mixed Boolean-Arithmetic Deobfuscation Using Transformer Architectures", "comment": null, "summary": "Mixed Boolean-Arithmetic (MBA) obfuscation protects intellectual property by\nconverting programs into forms that are more complex to analyze. However, MBA\nhas been increasingly exploited by malware developers to evade detection and\ncause significant real-world problems. Traditional MBA deobfuscation methods\noften consider these expressions as part of a black box and overlook their\ninternal semantic information. To bridge this gap, we propose a truth table,\nwhich is an automatically constructed semantic representation of an\nexpression's behavior that does not rely on external resources. The truth table\nis a mathematical form that represents the output of expression for all\npossible combinations of input. We also propose a general and extensible guided\nMBA deobfuscation framework (gMBA) that modifies a Transformer-based neural\nencoder-decoder Seq2Seq architecture to incorporate this semantic guidance.\nExperimental results and in-depth analysis show that integrating expression\nsemantics significantly improves performance and highlights the importance of\ninternal semantic expressions in recovering obfuscated code to its original\nform.", "AI": {"tldr": "提出基于真值表的语义引导框架gMBA，通过Transformer架构改进混合布尔算术表达式反混淆，显著提升还原效果。", "motivation": "混合布尔算术混淆(MBA)被恶意软件滥用，传统方法忽视表达式内部语义信息，导致反混淆效果不佳。", "method": "1) 自动构建真值表捕捉表达式语义 2) 设计可扩展的gMBA框架，改造Transformer编码器-解码器结构集成语义引导。", "result": "实验表明语义信息集成显著提升性能，证实内部语义对还原混淆代码的关键作用。", "conclusion": "真值表语义表征与神经架构结合为MBA反混淆提供新范式，突显表达式语义分析的重要性。"}}
{"id": "2506.23563", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23563", "abs": "https://arxiv.org/abs/2506.23563", "authors": ["Huanjin Yao", "Jiaxing Huang", "Yawen Qiu", "Michael K. Chen", "Wenzheng Liu", "Wei Zhang", "Wenjie Zeng", "Xikun Zhang", "Jingyi Zhang", "Yuxin Song", "Wenhao Wu", "Dacheng Tao"], "title": "MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI", "comment": "Technical report", "summary": "Reasoning plays a crucial role in advancing Multimodal Large Language Models\n(MLLMs) toward Artificial General Intelligence. However, existing MLLM\nbenchmarks often fall short in precisely and comprehensively evaluating\nlong-chain reasoning abilities from three key aspects: (1) lack of difficulty\nand diversity, (2) susceptibility to guessability and memorization, (3)\ninadequate assessment of intermediate reasoning steps. To fill this gap, we\nintroduce MMReason, a new benchmark designed to precisely and comprehensively\nevaluate MLLM long-chain reasoning capability with diverse, open-ended,\nchallenging questions. First, we curate challenging questions requiring\nmulti-step reasoning from various fields (i.e., 6 disciplines) and multiple\ndifficulty levels (i.e., from pre-university to university, and from\nfoundational to competition tiers). Second, these questions are reformulated\ninto an open-ended format and filtered using a multi-model voting technique to\neliminate shortcut cases related to guessing and memorization, ensuring robust\nreasoning evaluations. Third, we annotate the questions with detailed\nstep-by-step solutions, and design a reference-based ternary scoring mechanism\nto reliably assess intermediate reasoning steps. With MMReason, we benchmark\npopular leading MLLMs and provide an in-depth analysis of their reasoning\ncapabilities. We hope MMReason will serve as a valuable resource for advancing\nMLLM reasoning research. Code will be available at\nhttps://github.com/HJYao00/MMReason.", "AI": {"tldr": "本文提出MMReason基准，旨在精准评估多模态大语言模型的长链推理能力，通过多样化、开放式难题及分步评分机制填补现有评估空白。", "motivation": "现有MLLM基准在长链推理评估上存在三大缺陷：难度与多样性不足、易受猜测与记忆干扰、缺乏中间步骤评估。MMReason旨在解决这些问题。", "method": "1) 从6个学科领域收集需多步推理的难题；2) 采用开放式问题格式并通过多模型投票过滤捷径案例；3) 标注详细分步解答案例并设计三元评分机制评估推理过程。", "result": "基于MMReason对主流MLLM进行测试，深入分析了模型推理能力差异。基准代码开源在https://github.com/HJYao00/MMReason。", "conclusion": "MMReason为推进MLLM推理研究提供了标准化评估工具，其多维度设计有望促进AGI领域的长链推理能力发展。"}}
{"id": "2506.23780", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.23780", "abs": "https://arxiv.org/abs/2506.23780", "authors": ["Mike Hewitt", "Giovanni Pantuso"], "title": "Production Planning Under Demand and Endogenous Supply Uncertainty", "comment": null, "summary": "We study the problem of determining how much finished goods inventory to\nsource from different capacitated facilities in order to maximize profits\nresulting from sales of such inventory. We consider a problem wherein there is\nuncertainty in demand for finished goods inventory and production yields at\nfacilities. Further, we consider that uncertainty in production yields is\nendogenous, as it depends on both the facilities where a product is produced\nand the volumes produced at those facilities. We model the problem as a two\nstage stochastic program and propose an exact, Benders-based algorithm for\nsolving instances of the problem. We prove the correctness of the algorithm and\nwith an extensive computational study demonstrate that it outperforms known\nbenchmarks. Finally, we establish the value in modeling uncertainty in both\ndemands and production yields.", "AI": {"tldr": "研究如何在需求和生产良率不确定的情况下，从不同产能设施中采购成品库存以最大化利润，提出了一种基于Benders分解的精确算法，并验证其优于现有方法。", "motivation": "成品库存采购决策面临需求和设施生产良率的双重不确定性，且生产良率具有内生性（取决于生产设施和产量），需要开发有效的优化方法。", "method": "将问题建模为两阶段随机规划，提出基于Benders分解的精确求解算法，并严格证明算法正确性。", "result": "计算实验表明该算法显著优于已知基准方法，同时验证了同时考虑需求和良率不确定性的价值。", "conclusion": "本研究提出的算法能有效处理内生性生产不确定性，为供应链库存优化提供了新工具，并证实双重不确定性建模的必要性。"}}
{"id": "2506.23682", "categories": ["cs.CR", "cs.AR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.23682", "abs": "https://arxiv.org/abs/2506.23682", "authors": ["Maysara Alhindi", "Joseph Hallett"], "title": "Not quite a piece of CHERI-cake: Are new digital security by design architectures usable?", "comment": null, "summary": "A digital security-by-design computer architecture, like CHERI, lets you\nprogram without fear of buffer overflows or other memory safety errors, but\nCHERI also rewrites some of the assumptions about how C works and how\nfundamental types (such as pointers) are implemented in hardware. We conducted\na usability study to examine how developers react to the changes required by\nCHERI when porting software to run on it. We find that developers struggle with\nCHERI's display of warnings and errors and a lack of diverse documentation.", "AI": {"tldr": "研究探讨了开发者在使用CHERI架构时遇到的挑战，包括警告显示和文档不足的问题。", "motivation": "CHERI架构虽能防止内存安全错误，但改变了C语言和指针等基础类型的实现方式，需了解开发者适应这些变化的体验。", "method": "通过进行可用性研究，观察开发者在将软件移植到CHERI架构时的反应和遇到的问题。", "result": "开发者对CHERI的警告和错误显示感到困惑，且缺乏多样化的文档支持。", "conclusion": "CHERI架构在安全性方面有优势，但在开发者体验和文档支持方面仍需改进。"}}
{"id": "2506.23576", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23576", "abs": "https://arxiv.org/abs/2506.23576", "authors": ["Maria Carolina Cornelia Wit", "Jun Pang"], "title": "Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models", "comment": "26 pages, 1 figure", "summary": "Recent advances in large language models (LLMs) have raised concerns about\njailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper\ninvestigates the use of multi-agent LLM systems as a defence against such\nattacks. We evaluate three jailbreaking strategies, including the original\nAutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the\nAutoDefense framework, we compare single-agent setups with two- and three-agent\nconfigurations. Our results show that multi-agent systems enhance resistance to\njailbreaks, especially by reducing false negatives. However, its effectiveness\nvaries by attack type, and it introduces trade-offs such as increased false\npositives and computational overhead. These findings point to the limitations\nof current automated defences and suggest directions for improving alignment\nrobustness in future LLM systems.", "AI": {"tldr": "研究探讨多智能体大语言模型系统作为防御越狱攻击的有效性，发现其能提升安全性但存在误报和计算开销的权衡。", "motivation": "针对大语言模型越狱攻击（如绕过安全机制的提示）日益增多，需探索更有效的防御策略。", "method": "复现AutoDefense框架，对比单智能体与多智能体（双/三智能体）配置，评估三种越狱策略（AutoDefense、BetterDan、JB）的防御效果。", "result": "多智能体系统显著降低漏检率，但对不同攻击类型效果不一，同时增加误报率和计算负担。", "conclusion": "当前自动化防御存在局限性，未来需提升大语言模型对齐鲁棒性以平衡安全性与效率。"}}
{"id": "2506.23819", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.23819", "abs": "https://arxiv.org/abs/2506.23819", "authors": ["Jingyi Huang", "Paul Goulart", "Kostas Margellos"], "title": "Data-Driven Performance Guarantees for Parametric Optimization Problems", "comment": null, "summary": "We propose a data-driven method to establish probabilistic performance\nguarantees for parametric optimization problems solved via iterative\nalgorithms. Our approach addresses two key challenges: providing convergence\nguarantees to characterize the worst-case number of iterations required to\nachieve a predefined tolerance, and upper bounding a performance metric after a\nfixed number of iterations. These guarantees are particularly useful for online\noptimization problems with limited computational time, where existing\nperformance guarantees are often unavailable or unduly conservative. We\nformulate the convergence analysis problem as a scenario optimization program\nbased on a finite set of sampled parameter instances. Leveraging tools from\nscenario optimization theory enables us to derive probabilistic guarantees on\nthe number of iterations needed to meet a given tolerance level. Using recent\nadvancements in scenario optimization, we further introduce a relaxation\napproach to trade the number of iterations against the risk of violating\nconvergence criteria thresholds. Additionally, we analyze the trade-off between\nsolution accuracy and time efficiency for fixed-iteration optimization problems\nby casting them into scenario optimization programs. Numerical simulations\ndemonstrate the efficacy of our approach in providing reliable probabilistic\nconvergence guarantees and evaluating the trade-off between solution accuracy\nand computational cost.", "AI": {"tldr": "本文提出一种数据驱动方法，为迭代算法求解的参数优化问题建立概率性能保证，解决收敛性分析和固定迭代次数下的性能度量上界问题。", "motivation": "在线优化问题常因计算时间有限而缺乏现有性能保证或过于保守，需开发能提供可靠收敛保证的方法。", "method": "基于采样参数实例构建场景优化程序，利用场景优化理论工具推导达到给定容差所需迭代次数的概率保证，并引入松弛方法权衡迭代次数与收敛阈值违反风险。", "result": "数值模拟验证了该方法在提供概率收敛保证及评估解精度与计算成本权衡方面的有效性。", "conclusion": "该框架为有限计算时间下的在线优化问题提供了实用的概率性能保证工具，通过场景优化实现了收敛性与计算效率的量化平衡。"}}
{"id": "2506.23683", "categories": ["cs.CR", "cs.OS", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23683", "abs": "https://arxiv.org/abs/2506.23683", "authors": ["Maysara Alhindi", "Joseph Hallett"], "title": "Threadbox: Sandboxing for Modular Security", "comment": null, "summary": "There are many sandboxing mechanisms provided by operating systems to limit\nwhat resources applications can access, however, sometimes the use of these\nmechanisms requires developers to refactor their code to fit the sandboxing\nmodel. In this work, we investigate what makes existing sandboxing mechanisms\nchallenging to apply to certain types of applications, and propose Threadbox, a\nsandboxing mechanism that enables having modular and independent sandboxes, and\ncan be applied to threads and sandbox specific functions. We present case\nstudies to illustrate the applicability of the idea and discuss its\nlimitations.", "AI": {"tldr": "本文提出Threadbox，一种新型沙盒机制，支持模块化和独立沙盒，可应用于线程和特定函数，解决了现有沙盒机制难以适用于某些应用的问题。", "motivation": "现有操作系统提供的沙盒机制在限制应用资源访问时，常需开发者重构代码以适应沙盒模型，导致某些应用难以应用现有沙盒机制。", "method": "提出Threadbox沙盒机制，支持模块化和独立沙盒，可针对线程和特定函数进行沙盒化，并通过案例研究验证其适用性。", "result": "Threadbox机制在实际应用中展示了其灵活性和适用性，能够有效沙盒化线程和特定函数，但也存在一定局限性。", "conclusion": "Threadbox为沙盒机制提供了一种新的思路，支持模块化和独立沙盒，适用于线程和特定函数，但其局限性仍需进一步研究和改进。"}}
{"id": "2506.23626", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23626", "abs": "https://arxiv.org/abs/2506.23626", "authors": ["António Afonso", "Iolanda Leite", "Alessandro Sestini", "Florian Fuchs", "Konrad Tollmar", "Linus Gisslén"], "title": "Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games", "comment": "16 pages in total, 10 pages of main paper, 5 figures", "summary": "Reinforcement Learning (RL) in games has gained significant momentum in\nrecent years, enabling the creation of different agent behaviors that can\ntransform a player's gaming experience. However, deploying RL agents in\nproduction environments presents two key challenges: (1) designing an effective\nreward function typically requires an RL expert, and (2) when a game's content\nor mechanics are modified, previously tuned reward weights may no longer be\noptimal. Towards the latter challenge, we propose an automated approach for\niteratively fine-tuning an RL agent's reward function weights, based on a\nuser-defined language based behavioral goal. A Language Model (LM) proposes\nupdated weights at each iteration based on this target behavior and a summary\nof performance statistics from prior training rounds. This closed-loop process\nallows the LM to self-correct and refine its output over time, producing\nincreasingly aligned behavior without the need for manual reward engineering.\nWe evaluate our approach in a racing task and show that it consistently\nimproves agent performance across iterations. The LM-guided agents show a\nsignificant increase in performance from $9\\%$ to $74\\%$ success rate in just\none iteration. We compare our LM-guided tuning against a human expert's manual\nweight design in the racing task: by the final iteration, the LM-tuned agent\nachieved an $80\\%$ success rate, and completed laps in an average of $855$ time\nsteps, a competitive performance against the expert-tuned agent's peak $94\\%$\nsuccess, and $850$ time steps.", "AI": {"tldr": "本文提出了一种基于语言模型的自动化方法，用于迭代优化强化学习代理的奖励函数权重，无需人工干预即可实现行为对齐，并在赛车任务中验证了其有效性。", "motivation": "在游戏中部署强化学习代理面临两大挑战：设计有效奖励函数需要专家知识，且游戏内容变更会导致原有奖励权重失效。本文旨在解决后者，实现奖励权重的自动化调整。", "method": "通过语言模型根据用户定义的行为目标和历史训练统计，迭代提出更新的奖励权重，形成自我修正的闭环优化过程，无需人工设计奖励函数。", "result": "实验显示：语言模型引导的代理在赛车任务中单次迭代成功率从$9\\%$提升至$74\\%$；最终迭代达到$80\\%$成功率（人类专家为$94\\%$），平均用时$855$步（专家为$850$步）。", "conclusion": "该方法通过语言模型自动化调整奖励权重，显著提升了强化学习代理的性能表现，为游戏环境中的动态优化提供了有效解决方案。"}}
{"id": "2506.23836", "categories": ["math.OC", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23836", "abs": "https://arxiv.org/abs/2506.23836", "authors": ["Alexander Tyurin"], "title": "Proving the Limited Scalability of Centralized Distributed Optimization via a New Lower Bound Construction", "comment": null, "summary": "We consider centralized distributed optimization in the classical federated\nlearning setup, where $n$ workers jointly find an $\\varepsilon$-stationary\npoint of an $L$-smooth, $d$-dimensional nonconvex function $f$, having access\nonly to unbiased stochastic gradients with variance $\\sigma^2$. Each worker\nrequires at most $h$ seconds to compute a stochastic gradient, and the\ncommunication times from the server to the workers and from the workers to the\nserver are $\\tau_{s}$ and $\\tau_{w}$ seconds per coordinate, respectively. One\nof the main motivations for distributed optimization is to achieve scalability\nwith respect to $n$. For instance, it is well known that the distributed\nversion of SGD has a variance-dependent runtime term $\\frac{h \\sigma^2 L\n\\Delta}{n \\varepsilon^2},$ which improves with the number of workers $n,$ where\n$\\Delta = f(x^0) - f^*,$ and $x^0 \\in R^d$ is the starting point. Similarly,\nusing unbiased sparsification compressors, it is possible to reduce both the\nvariance-dependent runtime term and the communication runtime term. However,\nonce we account for the communication from the server to the workers\n$\\tau_{s}$, we prove that it becomes infeasible to design a method using\nunbiased random sparsification compressors that scales both the server-side\ncommunication runtime term $\\tau_{s} d \\frac{L \\Delta}{\\varepsilon}$ and the\nvariance-dependent runtime term $\\frac{h \\sigma^2 L \\Delta}{\\varepsilon^2},$\nbetter than poly-logarithmically in $n$, even in the homogeneous (i.i.d.) case,\nwhere all workers access the same distribution. To establish this result, we\nconstruct a new \"worst-case\" function and develop a new lower bound framework\nthat reduces the analysis to the concentration of a random sum, for which we\nprove a concentration bound. These results reveal fundamental limitations in\nscaling distributed optimization, even under the homogeneous assumption.", "AI": {"tldr": "本文研究了联邦学习中的集中式分布式优化问题，证明了在使用无偏随机稀疏化压缩器时，服务器端通信时间和方差相关运行时间无法随工作节点数$n$实现超对数级扩展，揭示了分布式优化的根本局限性。", "motivation": "分布式优化的主要动机是通过增加工作节点数$n$实现可扩展性，例如分布式SGD的方差相关运行时间项$\\frac{h \\sigma^2 L \\Delta}{n \\varepsilon^2}$会随$n$增大而改善。本文旨在探究在考虑服务器到工作节点通信时间$\\tau_{s}$后，这种扩展性的理论极限。", "method": "作者构建了一个新的\"最坏情况\"函数，并开发了一个新的下界分析框架，将问题转化为随机和集中度的分析，为此证明了新的集中度边界。该方法通过理论分析揭示通信瓶颈。", "result": "研究证明：即使在各工作节点数据同分布（i.i.d.）的理想情况下，使用无偏随机稀疏化压缩器的方法也无法使服务器端通信时间项$\\tau_{s} d \\frac{L \\Delta}{\\varepsilon}$和方差相关时间项$\\frac{h \\sigma^2 L \\Delta}{\\varepsilon^2}$随$n$实现超对数级扩展。", "conclusion": "这些结果揭示了分布式优化在可扩展性方面的根本限制，表明即使满足同分布假设，通信瓶颈仍会导致性能提升存在理论上限，对联邦学习算法设计具有重要启示意义。"}}
{"id": "2506.23814", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23814", "abs": "https://arxiv.org/abs/2506.23814", "authors": ["Theo Chow", "Mario D'Onghia", "Lorenz Linhardt", "Zeliang Kan", "Daniel Arp", "Lorenzo Cavallaro", "Fabio Pierazzi"], "title": "Breaking Out from the TESSERACT: Reassessing ML-based Malware Detection under Spatio-Temporal Drift", "comment": null, "summary": "Several recent works focused on the best practices for applying machine\nlearning to cybersecurity. In the context of malware, TESSERACT highlighted the\nimpact of concept drift on detection performance and suggested temporal and\nspatial constraints to be enforced to ensure realistic time-aware evaluations,\nwhich have been adopted by the community. In this paper, we demonstrate\nstriking discrepancies in the performance of learning-based malware detection\nacross the same time frame when evaluated on two representative Android malware\ndatasets used in top-tier security conferences, both adhering to established\nsampling and evaluation guidelines. This questions our ability to understand\nhow current state-of-the-art approaches would perform in realistic scenarios.\nTo address this, we identify five novel temporal and spatial bias factors that\naffect realistic evaluations. We thoroughly evaluate the impact of these\nfactors in the Android malware domain on two representative datasets and five\nAndroid malware classifiers used or proposed in top-tier security conferences.\nFor each factor, we provide practical and actionable recommendations that the\ncommunity should integrate in their methodology for more realistic and\nreproducible settings.", "AI": {"tldr": "本文揭示了在相同时间范围内，基于学习的安卓恶意软件检测在两个代表性数据集上性能存在显著差异，并提出了五种新的时空偏差因素以改进评估方法。", "motivation": "现有研究虽提出了时间感知评估方法，但在实际应用中，不同数据集上的检测性能仍存在不一致性，这引发了对当前最先进方法在真实场景中表现能力的质疑。", "method": "研究在安卓恶意软件领域，对两个代表性数据集和五种常用分类器进行了全面评估，识别了五种新的时空偏差因素。", "result": "实验表明，这些偏差因素显著影响评估结果，并针对每个因素提出了具体可行的改进建议。", "conclusion": "为确保评估的可靠性和可重复性，研究呼吁社区在方法学中整合这些建议，以实现更真实的恶意软件检测评估。"}}
{"id": "2506.23673", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23673", "abs": "https://arxiv.org/abs/2506.23673", "authors": ["Jingsong Liu", "Han Li", "Chen Yang", "Michael Deutges", "Ario Sadafi", "Xin You", "Katharina Breininger", "Nassir Navab", "Peter J. Schüffler"], "title": "HASD: Hierarchical Adaption for pathology Slide-level Domain-shift", "comment": null, "summary": "Domain shift is a critical problem for pathology AI as pathology data is\nheavily influenced by center-specific conditions. Current pathology domain\nadaptation methods focus on image patches rather than WSI, thus failing to\ncapture global WSI features required in typical clinical scenarios. In this\nwork, we address the challenges of slide-level domain shift by proposing a\nHierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD\nachieves multi-scale feature consistency and computationally efficient\nslide-level domain adaptation through two key components: (1) a hierarchical\nadaptation framework that integrates a Domain-level Alignment Solver for\nfeature alignment, a Slide-level Geometric Invariance Regularization to\npreserve the morphological structure, and a Patch-level Attention Consistency\nRegularization to maintain local critical diagnostic cues; and (2) a prototype\nselection mechanism that reduces computational overhead. We validate our method\non two slide-level tasks across five datasets, achieving a 4.1\\% AUROC\nimprovement in a Breast Cancer HER2 Grading cohort and a 3.9\\% C-index gain in\na UCEC survival prediction cohort. Our method provides a practical and reliable\nslide-level domain adaption solution for pathology institutions, minimizing\nboth computational and annotation costs.", "AI": {"tldr": "本文提出了一种针对病理学AI中切片级域偏移问题的分层适配框架HASD，通过多尺度特征一致性和计算高效的适配方法，在乳腺癌HER2分级和UCEC生存预测任务中显著提升了性能。", "motivation": "病理学AI面临中心特异性条件导致的域偏移问题，现有方法仅关注图像块而忽略全切片图像(WSI)的全局特征，无法满足临床需求。", "method": "HASD框架包含：(1)分层适配组件（域级对齐求解器、切片级几何不变性正则化、块级注意力一致性正则化）；(2)降低计算开销的原型选择机制。", "result": "在五个数据集的两种切片级任务中，乳腺癌HER2分级队列AUROC提升4.1\\%，UCEC生存预测队列C-index提高3.9\\%。", "conclusion": "HASD为病理机构提供了实用可靠的切片级域适配方案，显著降低了计算和标注成本。"}}
{"id": "2506.23839", "categories": ["math.OC", "90C15, 90C46, 90C47"], "pdf": "https://arxiv.org/pdf/2506.23839", "abs": "https://arxiv.org/abs/2506.23839", "authors": ["Guohui Guan", "Zongxia Liang", "Xingjian Ma"], "title": "Random Distributionally Robust Optimization under Phi-divergence", "comment": "35 pages", "summary": "This paper introduces a novel framework, Random Distributionally Robust\nOptimization (RDRO), which extends classical Distributionally Robust\nOptimization (DRO) by allowing the decision variable to be a random variable.\nWe formulate the RDRO problem using a bivariate utility function and\n$\\varphi$-divergence ambiguity sets, enabling a more flexible and realistic\ntreatment of uncertainty. The RDRO framework encompasses a broad range of\nrobust decision-making applications, including portfolio optimization,\nhealthcare resource allocation, and reliable facility location. By optimal\ntransport theory and convex analysis, we characterize key structural properties\nof the RDRO problem. Our main theoretical contributions include establishing\nthe existence and uniqueness of optimal randomized decisions and proving a\nduality theorem that links the constrained RDRO formulation to its penalized\ncounterpart. We further propose an efficient numerical scheme that combines the\nscaling algorithm for unbalanced optimal transport with projected gradient\ndescent, and demonstrate its effectiveness through numerical experiments.", "AI": {"tldr": "本文提出了随机分布鲁棒优化（RDRO）新框架，通过将决策变量扩展为随机变量，结合双变量效用函数和$\\varphi$-散度模糊集，为不确定性决策提供更灵活的处理方式。", "motivation": "经典分布鲁棒优化（DRO）在处理不确定性时存在局限性，RDRO框架通过引入随机决策变量，能够更真实地模拟实际应用场景（如投资组合优化、医疗资源分配等）。", "method": "利用最优传输理论和凸分析建立RDRO问题的结构特性，提出结合非平衡最优传输缩放算法与投影梯度下降的高效数值求解方案。", "result": "理论贡献包括证明随机最优决策的存在唯一性，建立约束RDRO与惩罚形式的对偶定理；数值实验验证了算法的有效性。", "conclusion": "RDRO框架通过随机化决策变量和$\\varphi$-散度模糊集，显著提升了分布鲁棒优化的适用性和计算可行性，为复杂不确定性决策问题提供通用解决方案。"}}
{"id": "2506.23841", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23841", "abs": "https://arxiv.org/abs/2506.23841", "authors": ["Ítalo Oliveira", "Stefano M. Nicoletti", "Gal Engelberg", "Mattia Fumagalli", "Dan Klein", "Giancarlo Guizzardi"], "title": "An ontological lens on attack trees: Toward adequacy and interoperability", "comment": null, "summary": "Attack Trees (AT) are a popular formalism for security analysis. They are\nmeant to display an attacker's goal decomposed into attack steps needed to\nachieve it and compute certain security metrics (e.g., attack cost,\nprobability, and damage). ATs offer three important services: (a) conceptual\nmodeling capabilities for representing security risk management scenarios, (b)\na qualitative assessment to find root causes and minimal conditions of\nsuccessful attacks, and (c) quantitative analyses via security metrics\ncomputation under formal semantics, such as minimal time and cost among all\nattacks. Still, the AT language presents limitations due to its lack of\nontological foundations, thus compromising associated services. Via an\nontological analysis grounded in the Common Ontology of Value and Risk (COVER)\n-- a reference core ontology based on the Unified Foundational Ontology (UFO)\n-- we investigate the ontological adequacy of AT and reveal four significant\nshortcomings: (1) ambiguous syntactical terms that can be interpreted in\nvarious ways; (2) ontological deficit concerning crucial domain-specific\nconcepts; (3) lacking modeling guidance to construct ATs decomposing a goal;\n(4) lack of semantic interoperability, resulting in ad hoc stand-alone tools.\nWe also discuss existing incremental solutions and how our analysis paves the\nway for overcoming those issues through a broader approach to risk management\nmodeling.", "AI": {"tldr": "攻击树(AT)是安全分析中常用的形式化方法，但存在本体论基础不足的问题。本文基于COVER本体论分析AT，揭示其四大缺陷，并提出改进方向。", "motivation": "攻击树虽广泛用于安全风险建模与量化分析，但因缺乏本体论基础导致建模模糊、概念缺失、指导不足及工具互操作性差等问题，需系统性改进。", "method": "基于统一基础本体论(UFO)的COVER核心本体，对攻击树进行本体论充分性分析，识别其术语歧义、概念缺失等结构性缺陷。", "result": "发现攻击树存在四大短板：(1)术语多义性；(2)关键领域概念缺失；(3)目标分解缺乏建模指南；(4)工具语义互操作性不足。现有增量方案需结合更广泛的风险建模方法。", "conclusion": "本体论分析为攻击树的根本性改进提供理论基础，未来需开发整合COVER的本体驱动型风险建模框架以解决现有局限。"}}
{"id": "2506.23689", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.23689", "abs": "https://arxiv.org/abs/2506.23689", "authors": ["Zihao Liu", "Xinhang Sui", "Yueran Song", "Siwen Wang"], "title": "PokéAI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red", "comment": null, "summary": "We introduce Pok\\'eAI, the first text-based, multi-agent large language model\n(LLM) framework designed to autonomously play and progress through Pok\\'emon\nRed. Our system consists of three specialized agents-Planning, Execution, and\nCritique-each with its own memory bank, role, and skill set. The Planning Agent\nfunctions as the central brain, generating tasks to progress through the game.\nThese tasks are then delegated to the Execution Agent, which carries them out\nwithin the game environment. Upon task completion, the Critique Agent evaluates\nthe outcome to determine whether the objective was successfully achieved. Once\nverification is complete, control returns to the Planning Agent, forming a\nclosed-loop decision-making system.\n  As a preliminary step, we developed a battle module within the Execution\nAgent. Our results show that the battle AI achieves an average win rate of\n80.8% across 50 wild encounters, only 6% lower than the performance of an\nexperienced human player. Furthermore, we find that a model's battle\nperformance correlates strongly with its LLM Arena score on language-related\ntasks, indicating a meaningful link between linguistic ability and strategic\nreasoning. Finally, our analysis of gameplay logs reveals that each LLM\nexhibits a unique playstyle, suggesting that individual models develop distinct\nstrategic behaviors.", "AI": {"tldr": "Pok\\'eAI是首个基于文本的多智能体大语言模型框架，能自主玩《口袋妖怪红》并推进游戏进程，包含规划、执行、评估三个专业模块，战斗AI胜率达80.8%，且语言能力与战略推理存在关联。", "motivation": "开发首个能自主玩《口袋妖怪红》的多智能体LLM框架，探索语言模型在复杂游戏环境中的战略决策能力。", "method": "采用三智能体闭环系统：规划Agent生成任务，执行Agent操作游戏，评估Agent验证结果；其中执行Agent内置战斗模块进行性能测试。", "result": "战斗模块在50场野外对战中平均胜率80.8%（仅比人类玩家低6%），LLM竞技场分数与战斗表现强相关，不同模型展现出独特游戏风格。", "conclusion": "Pok\\'eAI证明了LLM在复杂游戏中的战略潜力，语言能力与游戏表现存在正相关，且模型会发展出个性化策略行为。"}}
{"id": "2506.23895", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.23895", "abs": "https://arxiv.org/abs/2506.23895", "authors": ["Yuta Tanabe", "Kentaro Yaji", "Kuniharu Ushijima"], "title": "Topology optimization of actively moving rigid bodies in unsteady flows", "comment": null, "summary": "This study proposes a novel topology optimization method for unsteady fluid\nflows induced by actively moving rigid bodies. The key idea of the proposed\nmethod is to decouple the design and analysis domains by using separate grids.\nThe design grid undergoes rigid body motion and is then overlapped onto the\nanalysis grid. After the overlap, key quantities such as the Brinkman\ncoefficient are transferred between the grids. This approach provides a direct\nand efficient means of representing object motion and facilitates the handling\nof more general and complex movements in unsteady flow conditions. Since the\ncomputational cost of solving unsteady fluid problems is substantial, we employ\na solver based on the lattice kinetic scheme, which is the extended version of\nthe lattice Boltzmann method, to evaluate the design sensitivity. The\nfundamental equations are derived, and the accuracy of the design sensitivity\ncalculations is validated through comparison with finite difference\napproximations. The effectiveness of the method is demonstrated through\nnumerical examples in two-dimensional and three-dimensional settings.", "AI": {"tldr": "本文提出了一种新颖的非定常流体流动拓扑优化方法，通过分离设计网格与分析网格来高效处理主动运动刚体引发的流动问题，并采用基于格子动力学方案的求解器验证了方法的有效性。", "motivation": "针对非定常流体中主动运动刚体引发的复杂流动问题，传统方法计算成本高昂且难以处理广义运动，需要开发更高效的拓扑优化框架。", "method": "采用设计网格与分析网格解耦策略：设计网格随刚体运动后叠加至分析网格，传递Brinkman系数等关键参数；基于扩展版格子Boltzmann方法（格子动力学方案）求解设计灵敏度，并通过有限差分验证其准确性。", "result": "二维和三维数值实验表明，该方法能准确计算设计灵敏度，有效表征物体运动，显著降低非定常流动问题的计算成本。", "conclusion": "所提出的多网格耦合方法为运动刚体引发的非定常流动拓扑优化提供了通用且高效的解决方案，格子动力学方案的应用进一步提升了计算效率。"}}
{"id": "2506.23855", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23855", "abs": "https://arxiv.org/abs/2506.23855", "authors": ["Travis Dick", "Alessandro Epasto", "Adel Javanmard", "Josh Karlin", "Andres Munoz Medina", "Vahab Mirrokni", "Sergei Vassilvitskii", "Peilin Zhong"], "title": "Differentially Private Synthetic Data Release for Topics API Outputs", "comment": "20 pages, 8 figures", "summary": "The analysis of the privacy properties of Privacy-Preserving Ads APIs is an\narea of research that has received strong interest from academics, industry,\nand regulators. Despite this interest, the empirical study of these methods is\nhindered by the lack of publicly available data. Reliable empirical analysis of\nthe privacy properties of an API, in fact, requires access to a dataset\nconsisting of realistic API outputs; however, privacy concerns prevent the\ngeneral release of such data to the public.\n  In this work, we develop a novel methodology to construct synthetic API\noutputs that are simultaneously realistic enough to enable accurate study and\nprovide strong privacy protections. We focus on one Privacy-Preserving Ads\nAPIs: the Topics API, part of Google Chrome's Privacy Sandbox. We developed a\nmethodology to generate a differentially-private dataset that closely matches\nthe re-identification risk properties of the real Topics API data. The use of\ndifferential privacy provides strong theoretical bounds on the leakage of\nprivate user information from this release.\n  Our methodology is based on first computing a large number of\ndifferentially-private statistics describing how output API traces evolve over\ntime. Then, we design a parameterized distribution over sequences of API traces\nand optimize its parameters so that they closely match the statistics obtained.\nFinally, we create the synthetic data by drawing from this distribution.\n  Our work is complemented by an open-source release of the anonymized dataset\nobtained by this methodology. We hope this will enable external researchers to\nanalyze the API in-depth and replicate prior and future work on a realistic\nlarge-scale dataset. We believe that this work will contribute to fostering\ntransparency regarding the privacy properties of Privacy-Preserving Ads APIs.", "AI": {"tldr": "本文提出了一种生成合成隐私保护广告API输出的新方法，重点关注Google Chrome的Topics API，通过差分隐私技术创建既真实又保护隐私的数据集，并开源了匿名数据集以促进研究透明度。", "motivation": "由于缺乏公开可用的真实数据，隐私保护广告API的隐私属性实证研究受到阻碍。隐私问题阻止了此类数据的公开发布，因此需要一种既能保护隐私又能提供真实数据的方法。", "method": "该方法首先计算大量差分隐私统计量，描述API输出随时间的变化；然后设计一个参数化的API轨迹序列分布，并优化参数以匹配统计量；最后从该分布中抽取数据生成合成数据集。", "result": "研究成功创建了一个差分隐私数据集，其重识别风险属性与真实Topics API数据高度匹配，并通过开源发布匿名数据集，为外部研究人员提供了分析API的工具。", "conclusion": "这项工作通过生成合成数据集和开源发布，促进了隐私保护广告API隐私属性的透明度，为未来研究提供了可靠的大规模数据集基础。"}}
{"id": "2506.23692", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23692", "abs": "https://arxiv.org/abs/2506.23692", "authors": ["Boyuan Zheng", "Zerui Fang", "Zhe Xu", "Rui Wang", "Yiwen Chen", "Cunshi Wang", "Mengwei Qu", "Lei Lei", "Zhen Feng", "Yan Liu", "Yuyang Li", "Mingzhou Tan", "Jiaji Wu", "Jianwei Shuai", "Jia Li", "Fangfu Ye"], "title": "Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models", "comment": null, "summary": "While AI for Science (AI4S) serves as an analytical tool in the current\nresearch paradigm, it doesn't solve its core inefficiency. We propose \"Agent\nfor Science\" (Agent4S)-the use of LLM-driven agents to automate the entire\nresearch workflow-as the true Fifth Scientific Paradigm. This paper introduces\na five-level classification for Agent4S, outlining a clear roadmap from simple\ntask automation to fully autonomous, collaborative \"AI Scientists.\" This\nframework defines the next revolutionary step in scientific discovery.", "AI": {"tldr": "论文提出'科学代理'(Agent4S)作为第五科学范式，通过LLM驱动代理自动化整个科研流程，取代当前AI4S的低效模式，并制定了五级分类路线图。", "motivation": "当前AI4S仅作为分析工具存在，未能解决科研核心效率问题，需要转向完全自动化的新型研究范式。", "method": "提出五级分类框架：从基础任务自动化到完全自主协作的'AI科学家'，系统规划Agent4S发展路径。", "result": "构建了从工具辅助到群体智能的渐进式发展体系，定义了科学发现革命的下一阶段形态。", "conclusion": "Agent4S通过全流程自动化将引发科研范式革命，五级分类为实现真正自主的'AI科学家'提供明确路线图。"}}
{"id": "2506.24048", "categories": ["math.OC", "cs.LG", "65K10, 68Q32, 65K15, 90C26"], "pdf": "https://arxiv.org/pdf/2506.24048", "abs": "https://arxiv.org/abs/2506.24048", "authors": ["Tim Roith", "Leon Bungert", "Philipp Wacker"], "title": "Consensus-based optimization for closed-box adversarial attacks and a connection to evolution strategies", "comment": null, "summary": "Consensus-based optimization (CBO) has established itself as an efficient\ngradient-free optimization scheme, with attractive mathematical properties,\nsuch as mean-field convergence results for non-convex loss functions. In this\nwork, we study CBO in the context of closed-box adversarial attacks, which are\nimperceptible input perturbations that aim to fool a classifier, without\naccessing its gradient. Our contribution is to establish a connection between\nthe so-called consensus hopping as introduced by Riedl et al. and natural\nevolution strategies (NES) commonly applied in the context of adversarial\nattacks and to rigorously relate both methods to gradient-based optimization\nschemes. Beyond that, we provide a comprehensive experimental study that shows\nthat despite the conceptual similarities, CBO can outperform NES and other\nevolutionary strategies in certain scenarios.", "AI": {"tldr": "本文研究了基于共识的优化（CBO）在黑盒对抗攻击中的应用，建立了CBO与自然进化策略（NES）的联系，并通过实验证明CBO在某些场景下优于NES和其他进化策略。", "motivation": "研究CBO在黑盒对抗攻击中的潜力，这种攻击通过微小输入扰动欺骗分类器，且无需梯度信息。", "method": "将CBO与自然进化策略（NES）联系起来，并严格分析两者与基于梯度的优化方法的关系。", "result": "实验研究表明，尽管CBO与NES在概念上相似，但在某些情况下CBO表现更优。", "conclusion": "CBO在黑盒对抗攻击中具有优势，为无梯度优化提供了新的研究方向。"}}
{"id": "2506.23866", "categories": ["cs.CR", "cs.CY", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23866", "abs": "https://arxiv.org/abs/2506.23866", "authors": ["Jason Kayembe", "Iness Ben Guirat", "Jan Tobias Mühlberg"], "title": "Exploring Privacy and Security as Drivers for Environmental Sustainability in Cloud-Based Office Solutions", "comment": "Post-proceedings paper persented at LOCO '24: 1st International\n  Workshop on Low Carbon Computing, 2024-12-03, in Glasgow, UK", "summary": "In this paper, we explore the intersection of privacy, security, and\nenvironmental sustainability in cloud-based office solutions, focusing on\nquantifying user- and network-side energy use and associated carbon emissions.\nWe hypothesise that privacy-focused services are typically more\nenergy-efficient than those funded through data collection and advertising. To\nevaluate this, we propose a framework that systematically measures\nenvironmental costs based on energy usage and network data traffic during\nwell-defined, automated usage scenarios. To test our hypothesis, we first\nanalyse how underlying architectures and business models, such as monetisation\nthrough personalised advertising, contribute to the environmental footprint of\nthese services. We then explore existing methodologies and tools for software\nenvironmental impact assessment. We apply our framework to three mainstream\nemail services selected to reflect different privacy policies, from\nad-supported tracking-intensive models to privacy-focused designs: Microsoft\nOutlook, Google Mail (Gmail), and Proton Mail. We extend this comparison to a\nself-hosted email solution, evaluated with and without end-to-end encryption.\nWe show that the self-hosted solution, even with 14% of device energy and 15%\nof emissions overheads from PGP encryption, remains the most energy-efficient,\nsaving up to 33% of emissions per session compared to Gmail. Among commercial\nproviders, Proton Mail is the most efficient, saving up to 0.1 gCO2 e per\nsession compared to Outlook, whose emissions can be further reduced by 2%\nthrough ad-blocking.", "AI": {"tldr": "本文研究了基于云的办公解决方案在隐私、安全和环境可持续性方面的交叉点，提出了一种量化用户和网络侧能源使用及碳排放的框架，并验证了隐私优先服务通常比依赖数据收集和广告的服务更节能。", "motivation": "探讨隐私优先服务是否比依赖广告和数据收集的服务更节能，并量化不同云邮件服务的环境影响。", "method": "提出系统化测量框架，分析不同架构和商业模型对环境足迹的影响，并应用于三种主流邮件服务（Microsoft Outlook、Gmail、Proton Mail）及自托管解决方案。", "result": "自托管解决方案即使增加14%的设备能耗和15%的PGP加密排放，仍比Gmail节能33%；在商业服务中，Proton Mail最节能，比Outlook节省0.1 gCO2 e/会话，且广告拦截可进一步减少Outlook 2%的排放。", "conclusion": "隐私优先设计（如Proton Mail和自托管方案）显著降低云服务碳排放，验证了初始假设，为可持续IT解决方案提供了实证依据。"}}
{"id": "2506.23703", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23703", "abs": "https://arxiv.org/abs/2506.23703", "authors": ["Lars Ullrich", "Walter Zimmer", "Ross Greer", "Knut Graichen", "Alois C. Knoll", "Mohan Trivedi"], "title": "A New Perspective On AI Safety Through Control Theory Methodologies", "comment": "Accepted to be published as part of the 2025 IEEE Open Journal of\n  Intelligent Transportation Systems (OJ-ITS)", "summary": "While artificial intelligence (AI) is advancing rapidly and mastering\nincreasingly complex problems with astonishing performance, the safety\nassurance of such systems is a major concern. Particularly in the context of\nsafety-critical, real-world cyber-physical systems, AI promises to achieve a\nnew level of autonomy but is hampered by a lack of safety assurance. While\ndata-driven control takes up recent developments in AI to improve control\nsystems, control theory in general could be leveraged to improve AI safety.\nTherefore, this article outlines a new perspective on AI safety based on an\ninterdisciplinary interpretation of the underlying data-generation process and\nthe respective abstraction by AI systems in a system theory-inspired and system\nanalysis-driven manner. In this context, the new perspective, also referred to\nas data control, aims to stimulate AI engineering to take advantage of existing\nsafety analysis and assurance in an interdisciplinary way to drive the paradigm\nof data control. Following a top-down approach, a generic foundation for safety\nanalysis and assurance is outlined at an abstract level that can be refined for\nspecific AI systems and applications and is prepared for future innovation.", "AI": {"tldr": "本文提出了一种基于系统理论和数据分析的新视角，旨在通过跨学科方法提升人工智能（AI）在安全关键系统中的应用安全性。", "motivation": "随着AI技术的快速发展，其在安全关键领域的应用日益广泛，但缺乏有效的安全保障机制，这成为制约AI进一步自主化的主要障碍。", "method": "文章提出了一种称为“数据控制”的新视角，结合控制理论和AI技术，通过系统分析和跨学科方法，为AI系统提供通用的安全分析和保障基础。", "result": "该方法在抽象层面为AI系统的安全分析和保障提供了通用框架，可针对具体AI系统和应用进行细化，并为未来的创新做好准备。", "conclusion": "通过整合控制理论和AI技术，数据控制的新视角有望推动AI工程在安全关键领域中的跨学科应用，从而提升AI系统的整体安全性。"}}
{"id": "2506.24076", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.24076", "abs": "https://arxiv.org/abs/2506.24076", "authors": ["Manu Upadhyaya", "Adrien B. Taylor", "Sebastian Banert", "Pontus Giselsson"], "title": "AutoLyap: A Python package for computer-assisted Lyapunov analyses for first-order methods", "comment": null, "summary": "We introduce AutoLyap, a Python package designed to automate Lyapunov\nanalyses for a wide class of first-order methods for solving structured\noptimization and inclusion problems. Lyapunov analyses are structured proof\npatterns, with historical roots in the study of dynamical systems, commonly\nused to establish convergence results for first-order methods. Building on\nprevious works, the core idea behind AutoLyap is to recast the verification of\nthe existence of a Lyapunov analysis as a semidefinite program (SDP), which can\nthen be solved numerically using standard SDP solvers. Users of the package\nspecify (i)~the class of optimization or inclusion problems, (ii)~the\nfirst-order method in question, and (iii)~the type of Lyapunov analysis they\nwish to test. Once these inputs are provided, AutoLyap handles the SDP modeling\nand proceeds with the numerical solution of the SDP. We leverage the package to\nnumerically verify and extend several convergence results.", "AI": {"tldr": "AutoLyap是一个Python包，用于自动化Lyapunov分析，验证一阶方法在结构优化和包含问题中的收敛性。", "motivation": "Lyapunov分析是验证一阶方法收敛性的常用工具，但手动验证复杂且耗时，AutoLyap旨在自动化这一过程。", "method": "AutoLyap将Lyapunov分析的存在性验证转化为半定规划（SDP）问题，用户指定问题类别、方法和分析类型后，包自动完成SDP建模与求解。", "result": "该包成功验证并扩展了多个收敛性结果，展示了其在实际应用中的有效性。", "conclusion": "AutoLyap为Lyapunov分析提供了高效、自动化的工具，简化了一阶方法收敛性的验证过程。"}}
{"id": "2506.23909", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23909", "abs": "https://arxiv.org/abs/2506.23909", "authors": ["David Bálik", "Martin Jureček", "Mark Stamp"], "title": "RawMal-TF: Raw Malware Dataset Labeled by Type and Family", "comment": null, "summary": "This work addresses the challenge of malware classification using machine\nlearning by developing a novel dataset labeled at both the malware type and\nfamily levels. Raw binaries were collected from sources such as VirusShare, VX\nUnderground, and MalwareBazaar, and subsequently labeled with family\ninformation parsed from binary names and type-level labels integrated from\nClarAVy. The dataset includes 14 malware types and 17 malware families, and was\nprocessed using a unified feature extraction pipeline based on static analysis,\nparticularly extracting features from Portable Executable headers, to support\nadvanced classification tasks. The evaluation was focused on three key\nclassification tasks. In the binary classification of malware versus benign\nsamples, Random Forest and XGBoost achieved high accuracy on the full datasets,\nreaching 98.5% for type-based detection and 98.98% for family-based detection.\nWhen using truncated datasets of 1,000 samples to assess performance under\nlimited data conditions, both models still performed strongly, achieving 97.6%\nfor type-based detection and 98.66% for family-based detection. For interclass\nclassification, which distinguishes between malware types or families, the\nmodels reached up to 97.5% accuracy on type-level tasks and up to 93.7% on\nfamily-level tasks. In the multiclass classification setting, which assigns\nsamples to the correct type or family, SVM achieved 81.1% accuracy on type\nlabels, while Random Forest and XGBoost reached approximately 73.4% on family\nlabels. The results highlight practical trade-offs between accuracy and\ncomputational cost, and demonstrate that labeling at both the type and family\nlevels enables more fine-grained and insightful malware classification. The\nwork establishes a robust foundation for future research on advanced malware\ndetection and classification.", "AI": {"tldr": "本研究通过构建新型多层级标记的恶意软件数据集，采用静态分析特征提取方法，验证了随机森林与XGBoost在恶意软件分类任务中的高效性能，最高准确率达98.98%。", "motivation": "解决现有恶意软件分类研究中缺乏细粒度标记数据集的问题，通过同时标注类型和家族层级标签，支持更精细化的分类研究。", "method": "整合VirusShare等平台的原始样本，基于PE头静态分析构建统一特征提取流程，创建含14类恶意软件类型和17个家族的数据集，采用随机森林、XGBoost和SVM进行三类分类任务评估。", "result": "二分类任务中模型准确率最高达98.98%；千样本缩减数据集仍保持97.6%以上准确率；类型级多分类准确率81.1%，家族级73.4%，揭示了精度与计算成本的权衡关系。", "conclusion": "双层级标记体系能实现更精细的恶意软件分类，为未来检测技术研究奠定基础，同时证明静态分析特征在有限数据条件下仍具鲁棒性。"}}
{"id": "2506.23706", "categories": ["cs.AI", "cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23706", "abs": "https://arxiv.org/abs/2506.23706", "authors": ["Christoph Schnabl", "Daniel Hugenroth", "Bill Marino", "Alastair R. Beresford"], "title": "Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments", "comment": "ICML 2024 Workshop TAIG", "summary": "Benchmarks are important measures to evaluate safety and compliance of AI\nmodels at scale. However, they typically do not offer verifiable results and\nlack confidentiality for model IP and benchmark datasets. We propose Attestable\nAudits, which run inside Trusted Execution Environments and enable users to\nverify interaction with a compliant AI model. Our work protects sensitive data\neven when model provider and auditor do not trust each other. This addresses\nverification challenges raised in recent AI governance frameworks. We build a\nprototype demonstrating feasibility on typical audit benchmarks against\nLlama-3.1.", "AI": {"tldr": "本文提出了一种名为'可验证审计'的新方法，通过在可信执行环境中运行，确保AI模型的安全性与合规性评估可验证且保护数据隐私。", "motivation": "现有基准测试无法提供可验证结果，且缺乏对模型知识产权和基准数据集保密性的保护，难以满足近期AI治理框架提出的验证需求。", "method": "采用可信执行环境技术构建'可验证审计'系统，使模型提供方与审计方在互不信任的情况下仍能保护敏感数据。", "result": "基于Llama-3.1的原型实验证明，该方法在典型审计基准测试中具有可行性。", "conclusion": "可验证审计方案有效解决了AI治理中的验证挑战，为模型合规性评估提供了兼具可验证性和保密性的新途径。"}}
{"id": "2506.23985", "categories": ["cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2506.23985", "abs": "https://arxiv.org/abs/2506.23985", "authors": ["Mohamed Sami Rakha", "Adam Sorrenti", "Greg Stager", "Walid Rjaibi", "Andriy Miranskyy"], "title": "Lock Prediction for Zero-Downtime Database Encryption", "comment": null, "summary": "Modern enterprise database systems face significant challenges in balancing\ndata security and performance. Ensuring robust encryption for sensitive\ninformation is critical for systems' compliance with security standards.\nAlthough holistic database encryption provides strong protection, existing\ndatabase systems often require a complete backup and restore cycle, resulting\nin prolonged downtime and increased storage usage. This makes it difficult to\nimplement online encryption techniques in high-throughput environments without\ndisrupting critical operations.\n  To address this challenge, we envision a solution that enables online\ndatabase encryption aligned with system activity, eliminating the need for\ndowntime, storage overhead, or full-database reprocessing. Central to this\nvision is the ability to predict which parts of the database will be accessed\nnext, allowing encryption to be applied online. As a step towards this\nsolution, this study proposes a predictive approach that leverages deep\nlearning models to forecast database lock sequences, using IBM Db2 as the\ndatabase system under study. In this study, we collected a specialized dataset\nfrom TPC-C benchmark workloads, leveraging lock event logs for model training\nand evaluation. We applied deep learning architectures, such as Transformer and\nLSTM, to evaluate models for various table-level and page-level lock\npredictions. We benchmark the accuracy of the trained models versus a Naive\nBaseline across different prediction horizons and timelines.\n  The study experiments demonstrate that the proposed deep learning-based\nmodels achieve up to 49% average accuracy for table-level and 66% for\npage-level predictions, outperforming a Naive Baseline. By anticipating which\ntables and pages will be locked next, the proposed approach is a step toward\nonline encryption, offering a practical path toward secure, low-overhead\ndatabase systems.", "AI": {"tldr": "本文提出了一种基于深度学习的预测方法，用于在线数据库加密，通过预测数据库锁定序列减少加密过程中的停机时间和存储开销。", "motivation": "现代企业数据库系统在平衡数据安全性和性能方面面临挑战，现有加密技术需要完整备份和恢复周期，导致长时间停机和存储增加，难以在高吞吐环境中实施在线加密。", "method": "研究利用深度学习模型（如Transformer和LSTM）预测数据库锁定序列，使用IBM Db2系统和TPC-C基准工作负载的锁事件日志进行模型训练和评估。", "result": "实验表明，所提出的深度学习模型在表级和页级预测中分别达到49%和66%的平均准确率，优于朴素基线方法。", "conclusion": "通过预测即将锁定的表和页，该方法为实现在线加密提供了可行路径，有助于构建安全且低开销的数据库系统。"}}
{"id": "2506.23773", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2506.23773", "abs": "https://arxiv.org/abs/2506.23773", "authors": ["Stefano M. Nicoletti", "Mariëlle Stoelinga"], "title": "BayesL: Towards a Logical Framework for Bayesian Networks", "comment": null, "summary": "We introduce BayesL, a novel logical framework for specifying, querying, and\nverifying the behaviour of Bayesian networks (BNs). BayesL (pronounced \"Basil\")\nis a structured language that allows for the creation of queries over BNs. It\nfacilitates versatile reasoning concerning causal and evidence-based\nrelationships, and permits comprehensive what-if scenario evaluations without\nthe need for manual modifications to the model.", "AI": {"tldr": "论文提出BayesL，一种用于贝叶斯网络(BNs)行为规范、查询与验证的新型逻辑框架。", "motivation": "现有方法在贝叶斯网络的因果推理和场景评估中需要手动修改模型，缺乏高效查询语言。", "method": "开发结构化语言BayesL，支持创建BN查询，实现因果与证据关系的多维度推理。", "result": "该框架无需手动调整模型即可完成全面的假设场景评估，提升分析效率。", "conclusion": "BayesL为贝叶斯网络提供了一种强大的声明式查询工具，拓展了概率图模型的应用边界。"}}
{"id": "2506.24033", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.24033", "abs": "https://arxiv.org/abs/2506.24033", "authors": ["Pei Zhan", "Peng Tang", "Yangzhuo Li", "Puwen Wei", "Shanqing Guo"], "title": "Poisoning Attacks to Local Differential Privacy for Ranking Estimation", "comment": "This paper, consisting of 24 pages with 31 figures and 1 table, has\n  been accepted by ACM CCS 2025", "summary": "Local differential privacy (LDP) involves users perturbing their inputs to\nprovide plausible deniability of their data. However, this also makes LDP\nvulnerable to poisoning attacks. In this paper, we first introduce novel\npoisoning attacks for ranking estimation. These attacks are intricate, as fake\nattackers do not merely adjust the frequency of target items. Instead, they\nleverage a limited number of fake users to precisely modify frequencies,\neffectively altering item rankings to maximize gains. To tackle this challenge,\nwe introduce the concepts of attack cost and optimal attack item (set), and\npropose corresponding strategies for kRR, OUE, and OLH protocols. For kRR, we\niteratively select optimal attack items and allocate suitable fake users. For\nOUE, we iteratively determine optimal attack item sets and consider the\nincremental changes in item frequencies across different sets. Regarding OLH,\nwe develop a harmonic cost function based on the pre-image of a hash to select\nthat supporting a larger number of effective attack items. Lastly, we present\nan attack strategy based on confidence levels to quantify the probability of a\nsuccessful attack and the number of attack iterations more precisely. We\ndemonstrate the effectiveness of our attacks through theoretical and empirical\nevidence, highlighting the necessity for defenses against these attacks. The\nsource code and data have been made available at\nhttps://github.com/LDP-user/LDP-Ranking.git.", "AI": {"tldr": "本文针对本地差分隐私（LDP）中的排名估计任务，提出新型投毒攻击方法，通过精确操纵目标项频率改变排名，并设计攻击成本与最优攻击项（集）策略，验证了攻击有效性。", "motivation": "LDP通过扰动用户输入提供数据隐私保护，但易受投毒攻击。现有攻击仅调整目标项频率，本文提出更精细的攻击方式，利用少量虚假用户精确修改频率以最大化攻击收益。", "method": "为kRR协议迭代选择最优攻击项并分配虚假用户；为OUE协议迭代确定最优攻击项集并分析频率增量；为OLH协议设计基于哈希原像的调和成本函数。最后提出基于置信度的攻击策略量化成功概率与迭代次数。", "result": "理论与实验证明攻击有效性，kRR、OUE、OLH协议均能通过策略显著改变项排名，代码数据已开源。", "conclusion": "研究揭示了LDP排名估计中投毒攻击的严重威胁，需开发针对性防御机制以保障系统安全。"}}
{"id": "2506.23784", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23784", "abs": "https://arxiv.org/abs/2506.23784", "authors": ["Parosh Aziz Abdulla", "Mohamed Faouzi Atig", "Julie Cailler", "Chencheng Liang", "Philipp Rümmer"], "title": "When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)", "comment": null, "summary": "Nielsen transformation is a standard approach for solving word equations: by\nrepeatedly splitting equations and applying simplification steps, equations are\nrewritten until a solution is reached. When solving a conjunction of word\nequations in this way, the performance of the solver will depend considerably\non the order in which equations are processed. In this work, the use of Graph\nNeural Networks (GNNs) for ranking word equations before and during the solving\nprocess is explored. For this, a novel graph-based representation for word\nequations is presented, preserving global information across conjuncts,\nenabling the GNN to have a holistic view during ranking. To handle the variable\nnumber of conjuncts, three approaches to adapt a multi-classification task to\nthe problem of ranking equations are proposed. The training of the GNN is done\nwith the help of minimum unsatisfiable subsets (MUSes) of word equations. The\nexperimental results show that, compared to state-of-the-art string solvers,\nthe new framework solves more problems in benchmarks where each variable\nappears at most once in each equation.", "AI": {"tldr": "该研究探索了使用图神经网络（GNN）对字方程进行排序以优化求解过程，提出了一种新的基于图的表示方法，并通过实验验证了其在特定基准测试中的有效性。", "motivation": "在解决字方程联立时，处理顺序对求解器性能有显著影响，传统方法缺乏全局视角，因此需要一种能综合考虑所有联立方程的排序方法。", "method": "提出了一种保留联立方程全局信息的图表示方法，并设计了三种适应多分类任务的GNN排序策略，利用最小不可满足子集（MUS）进行模型训练。", "result": "实验表明，与现有字符串求解器相比，新框架在变量每个方程最多出现一次的基准测试中能解决更多问题。", "conclusion": "基于GNN的排序方法为字方程求解提供了新的优化方向，尤其在处理特定约束条件时展现出优越性能。"}}
{"id": "2506.24056", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.24056", "abs": "https://arxiv.org/abs/2506.24056", "authors": ["Tung-Ling Li", "Hongliang Liu"], "title": "Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models", "comment": null, "summary": "We introduce logit-gap steering, a fast jailbreak framework that casts the\nrefusal-affirmation gap of RLHF-aligned language models as a single pass over\nthe vocabulary. A forward-computable score blends gap reduction with\nlightweight proxies for KL penalty and reward shift, allowing a \"sort-sum-stop\"\nsweep to complete in under a second and return a short suffix--two orders of\nmagnitude fewer model calls than beam or gradient attacks. The same suffix\ngeneralises to unseen prompts and scales from 0.5 B to 70 B checkpoints,\nlifting one-shot attack success from baseline levels to 80-100% while\npreserving topical coherence. Beyond efficiency, these suffixes expose\nsentence-boundary reward cliffs and other alignment artefacts, offering a\nlightweight probe into how safety tuning reshapes internal representations.", "AI": {"tldr": "本文提出了一种名为logit-gap steering的快速越狱框架，通过单次词汇表遍历减少RLHF对齐语言模型的拒绝-确认差距，实现了高效攻击且保持主题连贯性。", "motivation": "研究动机在于解决RLHF对齐语言模型中存在的拒绝-确认差距问题，并探索如何高效生成通用攻击后缀以揭示安全调优的内部表征。", "method": "方法采用前向可计算分数，结合差距减少、轻量级KL惩罚和奖励偏移代理，通过“排序-求和-停止”扫描在秒级内生成短后缀。", "result": "实验结果显示，该方法在0.5B至70B模型上均有效，单次攻击成功率提升至80-100%，同时揭示了句子边界奖励悬崖等对齐伪影。", "conclusion": "结论表明，logit-gap steering不仅高效且通用，还为安全调优如何重塑内部表征提供了轻量级探测工具。"}}
{"id": "2506.23793", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.23793", "abs": "https://arxiv.org/abs/2506.23793", "authors": ["Anton Andreychuk", "Konstantin Yakovlev", "Aleksandr Panov", "Alexey Skrynnik"], "title": "Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning", "comment": null, "summary": "Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot\ntrajectory planning problems, where multiple homogeneous robots simultaneously\nmove in the shared environment. While solving MAPF optimally has been proven to\nbe NP-hard, scalable, and efficient, solvers are vital for real-world\napplications like logistics, search-and-rescue, etc. To this end, decentralized\nsuboptimal MAPF solvers that leverage machine learning have come on stage.\nBuilding on the success of the recently introduced MAPF-GPT, a pure imitation\nlearning solver, we introduce MAPF-GPT-DDG. This novel approach effectively\nfine-tunes the pre-trained MAPF model using centralized expert data. Leveraging\na novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training\nwhile significantly improving performance at test time. Our experiments\ndemonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF\nsolvers, including the original MAPF-GPT, regarding solution quality across\nmany testing scenarios. Remarkably, it can work with MAPF instances involving\nup to 1 million agents in a single environment, setting a new milestone for\nscalability in MAPF domains.", "AI": {"tldr": "本文提出了一种名为MAPF-GPT-DDG的新型多智能体路径规划（MAPF）求解器，通过微调预训练模型并采用创新的增量数据生成机制，显著提升了求解质量和可扩展性，可处理百万级智能体的场景。", "motivation": "尽管最优MAPF求解已被证明是NP难问题，但高效的次优求解器对物流、搜救等实际应用至关重要。基于模仿学习的MAPF-GPT虽取得进展，仍有改进空间。", "method": "MAPF-GPT-DDG在预训练MAPF模型基础上，利用集中式专家数据进行微调，并引入增量数据生成（delta-data generation）机制加速训练过程。", "result": "实验表明该模型在所有学习型MAPF求解器中表现最优，支持单环境百万智能体规模的路径规划，创下领域可扩展性新纪录。", "conclusion": "MAPF-GPT-DDG通过数据生成创新与模型微调的结合，为大规模多智能体路径规划提供了高效解决方案，推动了该领域的实用化进程。"}}
{"id": "2506.23844", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23844", "abs": "https://arxiv.org/abs/2506.23844", "authors": ["Hang Su", "Jun Luo", "Chang Liu", "Xiao Yang", "Yichi Zhang", "Yinpeng Dong", "Jun Zhu"], "title": "A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents", "comment": "18 pages", "summary": "Recent advances in large language models (LLMs) have catalyzed the rise of\nautonomous AI agents capable of perceiving, reasoning, and acting in dynamic,\nopen-ended environments. These large-model agents mark a paradigm shift from\nstatic inference systems to interactive, memory-augmented entities. While these\ncapabilities significantly expand the functional scope of AI, they also\nintroduce qualitatively novel security risks - such as memory poisoning, tool\nmisuse, reward hacking, and emergent misalignment - that extend beyond the\nthreat models of conventional systems or standalone LLMs. In this survey, we\nfirst examine the structural foundations and key capabilities that underpin\nincreasing levels of agent autonomy, including long-term memory retention,\nmodular tool use, recursive planning, and reflective reasoning. We then analyze\nthe corresponding security vulnerabilities across the agent stack, identifying\nfailure modes such as deferred decision hazards, irreversible tool chains, and\ndeceptive behaviors arising from internal state drift or value misalignment.\nThese risks are traced to architectural fragilities that emerge across\nperception, cognition, memory, and action modules. To address these challenges,\nwe systematically review recent defense strategies deployed at different\nautonomy layers, including input sanitization, memory lifecycle control,\nconstrained decision-making, structured tool invocation, and introspective\nreflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a\nunified cognitive framework grounded in Constrained Markov Decision Processes\n(CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation,\nand joint reward-risk optimization to enable principled, proactive safety\nacross the agent's decision-making loop.", "AI": {"tldr": "本文综述了大型语言模型（LLM）驱动的自主AI代理的安全风险，提出了一种新型的反射式风险感知架构（R2A2）来应对这些挑战。", "motivation": "随着自主AI代理能力的提升，其面临的新型安全风险（如记忆污染、工具滥用等）超出了传统系统或独立LLM的威胁模型，亟需系统性解决方案。", "method": "通过分析代理栈的结构性脆弱性，提出基于约束马尔可夫决策过程（CMDP）的R2A2框架，整合风险感知建模、元策略适应等技术。", "result": "识别出感知-认知-记忆-行动模块的架构缺陷，并系统梳理了输入净化、记忆生命周期控制等分层防御策略。", "conclusion": "R2A2框架通过联合奖励-风险优化，为代理决策循环提供了理论化、主动式的安全保护机制。"}}
{"id": "2506.23908", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23908", "abs": "https://arxiv.org/abs/2506.23908", "authors": ["András György", "Tor Lattimore", "Nevena Lazić", "Csaba Szepesvári"], "title": "Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence", "comment": null, "summary": "Sound deductive reasoning -- the ability to derive new knowledge from\nexisting facts and rules -- is an indisputably desirable aspect of general\nintelligence. Despite the major advances of AI systems in areas such as math\nand science, especially since the introduction of transformer architectures, it\nis well-documented that even the most advanced frontier systems regularly and\nconsistently falter on easily-solvable deductive reasoning tasks. Hence, these\nsystems are unfit to fulfill the dream of achieving artificial general\nintelligence capable of sound deductive reasoning. We argue that their unsound\nbehavior is a consequence of the statistical learning approach powering their\ndevelopment. To overcome this, we contend that to achieve reliable deductive\nreasoning in learning-based AI systems, researchers must fundamentally shift\nfrom optimizing for statistical performance against distributions on reasoning\nproblems and algorithmic tasks to embracing the more ambitious exact learning\nparadigm, which demands correctness on all inputs. We argue that exact learning\nis both essential and possible, and that this ambitious objective should guide\nalgorithm design.", "AI": {"tldr": "论文指出当前AI系统在演绎推理上的不足，主张采用精确学习范式以实现可靠的推理能力。", "motivation": "尽管AI在数学和科学领域取得进展，但现有系统在简单演绎推理任务上仍频繁出错，无法实现真正的通用人工智能。", "method": "提出从统计学习范式转向精确学习范式，要求在所有输入上保证正确性，而非仅优化统计性能。", "result": "统计学习方法导致推理不可靠，精确学习是实现可靠演绎推理的必要途径。", "conclusion": "为实现可靠的演绎推理能力，AI研究必须采用精确学习范式，并将其作为算法设计的核心目标。"}}
{"id": "2506.23949", "categories": ["cs.AI", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.23949", "abs": "https://arxiv.org/abs/2506.23949", "authors": ["Anthony M. Barrett", "Jessica Newman", "Brandie Nonnecke", "Nada Madkour", "Dan Hendrycks", "Evan R. Murphy", "Krystal Jackson", "Deepika Raman"], "title": "AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models", "comment": null, "summary": "Increasingly multi-purpose AI models, such as cutting-edge large language\nmodels or other 'general-purpose AI' (GPAI) models, 'foundation models,'\ngenerative AI models, and 'frontier models' (typically all referred to\nhereafter with the umbrella term 'GPAI/foundation models' except where greater\nspecificity is needed), can provide many beneficial capabilities but also risks\nof adverse events with profound consequences. This document provides\nrisk-management practices or controls for identifying, analyzing, and\nmitigating risks of GPAI/foundation models. We intend this document primarily\nfor developers of large-scale, state-of-the-art GPAI/foundation models; others\nthat can benefit from this guidance include downstream developers of end-use\napplications that build on a GPAI/foundation model. This document facilitates\nconformity with or use of leading AI risk management-related standards,\nadapting and building on the generic voluntary guidance in the NIST AI Risk\nManagement Framework and ISO/IEC 23894, with a focus on the unique issues faced\nby developers of GPAI/foundation models.", "AI": {"tldr": "本文为多功能AI模型（如大型语言模型等）提供风险管理实践指南，旨在帮助开发者识别、分析和减轻相关风险。", "motivation": "多功能AI模型（GPAI/基础模型）虽具备诸多有益能力，但也可能带来严重后果的风险，需制定风险管理措施。", "method": "文档基于NIST AI风险管理框架和ISO/IEC 23894标准，针对GPAI/基础模型开发者的独特问题，提供风险控制实践。", "result": "为大型GPAI/基础模型开发者及下游应用开发者提供风险管理指南，促进与领先AI风险管理标准的符合性。", "conclusion": "本文通过定制化风险管理实践，帮助开发者应对GPAI/基础模型带来的独特挑战，确保技术发展的安全性与可控性。"}}
{"id": "2506.23924", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23924", "abs": "https://arxiv.org/abs/2506.23924", "authors": ["Akshit Kumar", "Tianyi Peng", "Yuhang Wu", "Assaf Zeevi"], "title": "Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice", "comment": null, "summary": "Large language models (LLMs) have exhibited expert-level capabilities across\nvarious domains. However, their abilities to solve problems in Operations\nResearch (OR) -- the analysis and optimization of mathematical models derived\nfrom real-world problems or their verbal descriptions -- remain underexplored.\nIn this work, we take a first step toward evaluating LLMs' abilities to solve\nstochastic modeling problems, a core class of OR problems characterized by\nuncertainty and typically involving tools from probability, statistics, and\nstochastic processes. We manually procure a representative set of\ngraduate-level homework and doctoral qualification-exam problems and test LLMs'\nabilities to solve them. We further leverage SimOpt, an open-source library of\nsimulation-optimization problems and solvers, to investigate LLMs' abilities to\nmake real-world decisions under uncertainty. Our results show that, though a\nnontrivial amount of work is still needed to reliably automate the stochastic\nmodeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on\npar with human experts in both classroom and practical settings. These findings\nhighlight the potential of building AI agents that assist OR researchers and\namplify the real-world impact of OR through automation.", "AI": {"tldr": "大型语言模型（LLMs）在解决运筹学（OR）中的随机建模问题方面展现出与人类专家相当的能力，但仍需进一步研究以实现可靠的自动化。", "motivation": "尽管LLMs在多个领域展现出专家级能力，但其在运筹学（OR）中解决随机建模问题的能力尚未被充分探索。随机建模是OR的核心问题之一，涉及不确定性及概率、统计和随机过程等工具。", "method": "研究通过手动收集一组研究生课程作业和博士资格考试题目，测试LLMs解决随机建模问题的能力，并利用开源库SimOpt评估LLMs在不确定性下做出实际决策的能力。", "result": "结果表明，尽管在现实中实现随机建模流程的可靠自动化仍需大量工作，但最先进的LLMs在课堂和实际场景中展现出与人类专家相当的能力。", "conclusion": "这些发现凸显了构建辅助OR研究的人工智能代理的潜力，并通过自动化放大OR在现实世界中的影响力。"}}
{"id": "2506.23926", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23926", "abs": "https://arxiv.org/abs/2506.23926", "authors": ["Junping Wang", "Bicheng Wang", "Yibo Xuea", "Yuan Xie"], "title": "Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system", "comment": null, "summary": "Resilience non-equilibrium measurement, the ability to maintain fundamental\nfunctionality amidst failures and errors, is crucial for scientific management\nand engineering applications of industrial chain. The problem is particularly\nchallenging when the number or types of multiple co-evolution of resilience\n(for example, randomly placed) are extremely chaos. Existing end-to-end deep\nlearning ordinarily do not generalize well to unseen full-feld reconstruction\nof spatiotemporal co-evolution structure, and predict resilience of network\ntopology, especially in multiple chaos data regimes typically seen in\nreal-world applications. To address this challenge, here we propose industrial\nbrain, a human-like autonomous cognitive decision-making and planning framework\nintegrating higher-order activity-driven neuro network and CT-OODA symbolic\nreasoning to autonomous plan resilience directly from observational data of\nglobal variable. The industrial brain not only understands and model structure\nof node activity dynamics and network co-evolution topology without simplifying\nassumptions, and reveal the underlying laws hidden behind complex networks, but\nalso enabling accurate resilience prediction, inference, and planning.\nExperimental results show that industrial brain significantly outperforms\nresilience prediction and planning methods, with an accurate improvement of up\nto 10.8\\% over GoT and OlaGPT framework and 11.03\\% over spectral dimension\nreduction. It also generalizes to unseen topologies and dynamics and maintains\nrobust performance despite observational disturbances. Our findings suggest\nthat industrial brain addresses an important gap in resilience prediction and\nplanning for industrial chain.", "AI": {"tldr": "提出工业大脑框架，结合高阶神经网路与符号推理，直接从观测数据自主规划产业链韧性，预测精度提升超10%，且对未知拓扑保持鲁棒性。", "motivation": "现有深度学习方法难以在混沌数据下重建时空共演结构并预测网络拓扑韧性，亟需突破性解决方案以应对实际工业链管理挑战。", "method": "融合高阶活动驱动神经网路与CT-OODA符号推理，构建类人自主认知决策框架，无需简化假设即可建模节点动态与网络共演拓扑结构。", "result": "实验显示工业大脑预测精度较GoT/OlaGPT提升10.8%，较谱降维方法提升11.03%，且在观测干扰下保持稳定，能泛化至未见过的拓扑动态。", "conclusion": "该框架填补了产业链韧性预测与自主规划的空白，通过揭示复杂网络隐藏规律，实现高精度韧性推断与规划。"}}
{"id": "2506.23992", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.23992", "abs": "https://arxiv.org/abs/2506.23992", "authors": ["Aditya Shrivastava", "Komal Gupta", "Shraddha Arora"], "title": "Harnessing AI Agents to Advance Research on Refugee Child Mental Health", "comment": "14 page , 2 image , 2 tables , accepted under 5th International\n  Conference on Innovations in Computational Intelligence and Computer Vision\n  (ICICV-2025)", "summary": "The international refugee crisis deepens, exposing millions of dis placed\nchildren to extreme psychological trauma. This research suggests a com pact,\nAI-based framework for processing unstructured refugee health data and\ndistilling knowledge on child mental health. We compare two Retrieval-Aug\nmented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to\ndetermine how well they process challenging humanitarian datasets while avoid\ning hallucination hazards. By combining cutting-edge AI methods with migration\nresearch and child psychology, this study presents a scalable strategy to\nassist policymakers, mental health practitioners, and humanitarian agencies to\nbetter assist displaced children and recognize their mental wellbeing. In\ntotal, both the models worked properly but significantly Deepseek R1 is\nsuperior to Zephyr with an accuracy of answer relevance 0.91", "AI": {"tldr": "研究提出基于AI的框架处理难民儿童心理健康数据，比较Zephyr-7B-beta和DeepSeek R1-7B两种RAG模型性能，发现DeepSeek R1表现更优。", "motivation": "国际难民危机导致数百万儿童面临心理创伤，需有效处理非结构化健康数据以支持决策和干预。", "method": "采用检索增强生成(RAG)技术，对比Zephyr-7B-beta和DeepSeek R1-7B模型在难民数据集上的表现，结合AI与儿童心理学方法。", "result": "两种模型均有效，但DeepSeek R1以0.91的相关性准确度显著优于Zephyr模型。", "conclusion": "该AI框架为难民儿童心理健康干预提供了可扩展方案，DeepSeek R1在数据处理的准确性上更具优势。"}}
{"id": "2506.24026", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.24026", "abs": "https://arxiv.org/abs/2506.24026", "authors": ["Yongyi Wang", "Wenxin Li"], "title": "Constructing Non-Markovian Decision Process via History Aggregator", "comment": null, "summary": "In the domain of algorithmic decision-making, non-Markovian dynamics manifest\nas a significant impediment, especially for paradigms such as Reinforcement\nLearning (RL), thereby exerting far-reaching consequences on the advancement\nand effectiveness of the associated systems. Nevertheless, the existing\nbenchmarks are deficient in comprehensively assessing the capacity of decision\nalgorithms to handle non-Markovian dynamics. To address this deficiency, we\nhave devised a generalized methodology grounded in category theory. Notably, we\nestablished the category of Markov Decision Processes (MDP) and the category of\nnon-Markovian Decision Processes (NMDP), and proved the equivalence\nrelationship between them. This theoretical foundation provides a novel\nperspective for understanding and addressing non-Markovian dynamics. We further\nintroduced non-Markovianity into decision-making problem settings via the\nHistory Aggregator for State (HAS). With HAS, we can precisely control the\nstate dependency structure of decision-making problems in the time series. Our\nanalysis demonstrates the effectiveness of our method in representing a broad\nrange of non-Markovian dynamics. This approach facilitates a more rigorous and\nflexible evaluation of decision algorithms by testing them in problem settings\nwhere non-Markovian dynamics are explicitly constructed.", "AI": {"tldr": "本文提出了一种基于范畴论的新方法，通过建立马尔可夫决策过程（MDP）和非马尔可夫决策过程（NMDP）的范畴，并证明其等价关系，为解决算法决策中的非马尔可夫动态问题提供了理论框架。", "motivation": "现有基准无法全面评估决策算法处理非马尔可夫动态的能力，这限制了强化学习等范式的发展和应用效果。", "method": "研究团队设计了基于范畴论的通用方法，构建了MDP和NMDP的范畴，并证明了它们的等价性。通过引入状态历史聚合器（HAS），在决策问题中精确控制时间序列中的状态依赖结构。", "result": "分析表明，该方法能有效表示广泛的非马尔可夫动态，为决策算法在明确构建非马尔可夫动态的问题设置中进行测试提供了更严格和灵活的评价方式。", "conclusion": "该研究为理解和处理非马尔可夫动态提供了新的理论视角，通过HAS实现了对决策问题中状态依赖结构的精确控制，推动了决策算法评估方法的发展。"}}
{"id": "2506.24119", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.24119", "abs": "https://arxiv.org/abs/2506.24119", "authors": ["Bo Liu", "Leon Guertler", "Simon Yu", "Zichen Liu", "Penghui Qi", "Daniel Balcells", "Mickel Liu", "Cheston Tan", "Weiyan Shi", "Min Lin", "Wee Sun Lee", "Natasha Jaques"], "title": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning", "comment": "Work in Progress", "summary": "Recent advances in reinforcement learning have shown that language models can\ndevelop sophisticated reasoning through training on tasks with verifiable\nrewards, but these approaches depend on human-curated problem-answer pairs and\ndomain-specific reward engineering. We introduce SPIRAL, a self-play framework\nwhere models learn by playing multi-turn, zero-sum games against continuously\nimproving versions of themselves, eliminating the need for human supervision.\nThrough self-play, SPIRAL generates an infinite curriculum of progressively\nchallenging problems as models must constantly adapt to stronger opponents. To\nenable this self-play training at scale, We implement a fully online,\nmulti-turn, multi-agent reinforcement learning system for LLMs and propose\nrole-conditioned advantage estimation (RAE) to stabilize multi-agent training.\nUsing SPIRAL, self-play on zero-sum games produces reasoning capabilities that\ntransfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%\nimprovement on math and 8.4% on general reasoning, outperforming SFT on 25,000\nexpert game trajectories. Analysis reveals that this transfer occurs through\nthree cognitive patterns: systematic decomposition, expected value calculation,\nand case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple\nNegotiation) further enhances performance as each game develops distinct\nreasoning strengths. Applying SPIRAL to a strong reasoning model\n(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These\nresults demonstrate that zero-sum games naturally develop transferable\nreasoning capabilities, highlighting a promising direction for autonomous\nreasoning development.", "AI": {"tldr": "SPIRAL框架通过自博弈训练语言模型，无需人工监督即可提升推理能力。在零和博弈中，模型通过不断对抗更强版本自我提升，展现出广泛迁移能力。", "motivation": "现有强化学习依赖人工标注和领域特定奖励设计，SPIRAL旨在通过自博弈消除这些限制，实现自主推理能力开发。", "method": "提出SPIRAL自博弈框架：1) 多轮零和博弈对抗自我改进版本；2) 在线多智能体强化学习系统；3) 角色条件优势估计(RAE)稳定训练。", "result": "Qwen3-4B-Base在Kuhn Poker训练后数学/推理能力提升8.6%/8.4%，超越2.5万专家轨迹监督学习。多游戏训练进一步强化不同推理模式。", "conclusion": "零和博弈能自然发展可迁移的推理能力（系统性分解、期望值计算、案例分析），为自主推理开发开辟了新方向。"}}
