<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 3]
- [math.OC](#math.OC) [Total: 16]
- [math.NT](#math.NT) [Total: 11]
- [math.LO](#math.LO) [Total: 4]
- [math.CO](#math.CO) [Total: 12]
- [cs.CR](#cs.CR) [Total: 24]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.DM](#cs.DM) [Total: 1]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Identifiability by common backdoor in summary causal graphs of time series](https://arxiv.org/abs/2506.14862)
*Clément Yvernes,Charles K. Assaad,Emilie Devijver,Eric Gaussier*

Main category: math.ST

TL;DR: 本文研究了时间序列中干预的可识别性问题，探讨了在仅能获得摘要因果图的情况下，如何通过共同后门集判断多干预多效应的可识别性，并提出了相应的判定算法。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决时间序列数据中干预效应的可识别性问题，特别是在真实因果图仅能以摘要形式呈现时，如何利用观测数据计算干预的总效应。

Method: 方法聚焦于通过共同后门集进行识别，针对时间序列（包括时间一致性与非一致性两种情况），建立了存在此类集合的条件，并设计了复杂度有限的判定算法。

Result: 研究结果为时间序列中的干预可识别性提供了理论条件，证明了特定场景下共同后门集的存在性，并给出了可判定性的算法实现。

Conclusion: 结论表明，在给定条件下，时间序列的干预效应可通过共同后门集实现可识别性，所提算法为实际应用提供了可行性保障。

Abstract: The identifiability problem for interventions aims at assessing whether the
total effect of some given interventions can be written with a do-free formula,
and thus be computed from observational data only. We study this problem,
considering multiple interventions and multiple effects, in the context of time
series when only abstractions of the true causal graph in the form of summary
causal graphs are available. We focus in this study on identifiability by a
common backdoor set, and establish, for time series with and without
consistency throughout time, conditions under which such a set exists. We also
provide algorithms of limited complexity to decide whether the problem is
identifiable or not.

</details>


### [2] [Probabilistic closed-form formulas for pricing nonlinear payoff variance and volatility derivatives under Schwartz model with time-varying log-return volatility](https://arxiv.org/abs/2506.15386)
*Nontawat Bunchak,Udomsak Rakwongwan,Phiraphat Sutthimat*

Main category: math.ST

TL;DR: 本文提出了离散时间观测下非线性收益波动率和方差衍生品的闭式解析定价公式，基于Schwartz单因子模型，解决了时变对数收益波动率下的定价难题，并通过蒙特卡洛模拟验证了方法的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决时变对数收益波动率假设下波动率和方差衍生品的定价问题，特别是当已实现方差服从加权参数的非中心卡方随机变量线性组合时的解析解难题。

Method: 采用概率密度函数方法，解析计算已实现方差平方根的期望，推导波动率互换和波动率看涨期权的定价公式，并对常数对数收益波动率情况简化公式，分析波动率敏感性（vega）。

Result: 提出了Schwartz单因子模型下波动率互换的简单闭式近似定价方法，蒙特卡洛模拟验证了方法的准确性，并探讨了价格波动率和交易日数量对波动率与方差互换公平执行价的影响。

Conclusion: 研究成功解决了时变波动率下的衍生品定价问题，提出的解析公式和近似方法在实际应用中表现出高效性和准确性，为相关金融产品定价提供了理论支持。

Abstract: This paper presents closed-form analytical formulas for pricing volatility
and variance derivatives with nonlinear payoffs under discrete-time
observations. The analysis is based on a probabilistic approach assuming that
the underlying asset price follows the Schwartz one-factor model, where the
volatility of log-returns is time-varying. A difficult challenge in this
pricing problem is to solve an analytical formula under the assumption of
time-varying log-return volatility, resulting in the realized variance being
distributed according to a linear combination of independent noncentral
chi-square random variables with weighted parameters. By utilizing the
probability density function, we analytically compute the expectation of the
square root of the realized variance and derive pricing formulas for volatility
swaps. Additionally, we derive analytical pricing formulas for volatility call
options. For the payoff function without the square root, we also derive
corresponding formulas for variance swaps and variance call options.
Additionally, we study the case of constant log-return volatility; simplified
pricing formulas are derived and sensitivity with respect to volatility (vega)
is analytically studied. Furthermore,we propose simple closed-form
approximations for pricing volatility swaps under the Schwartz one-factor
model. The accuracy and efficiency of the proposed methods are demonstrated
through Monte Carlo simulations, and the impact of price volatility and the
number of trading days on fair strike prices of volatility and variance swaps
is investigated across various numerical experiments.

</details>


### [3] [Density estimation via periodic scaled Korobov kernel method with exponential decay condition](https://arxiv.org/abs/2506.15419)
*Ziyang Ye,Haoyuan Tan,Xiaoqun Wang,Zhijian He*

Main category: math.ST

TL;DR: 本文提出了一种周期性缩放Korobov核（PSKK）方法，用于在$\mathbb{R}^d$上进行非参数密度估计，通过模运算将目标密度转换为周期性版本，并在缩放Korobov空间中应用核岭回归，从而扩展了先前方法的应用范围。


<details>
  <summary>Details</summary>
Motivation: 现有核方法要求密度函数具有固有周期性，限制了其在无界域上的应用。本文旨在消除这一限制，实现对更广泛非周期分布的有效估计。

Method: 通过模运算将目标密度包装为周期性版本，随后在缩放Korobov空间中使用核岭回归进行估计，扩展了Kazashi和Nobile（2023）提出的核方法。

Result: 理论证明，对于具有$\alpha$阶光滑性和指数衰减的密度，该方法实现了$\mathcal{O}(M^{-1/(1+1/(2\alpha)+\epsilon)})$的MISE收敛速率，且适用于更广泛的非周期分布。数值实验验证了理论结果。

Conclusion: PSKK方法不仅匹配了先前核方法的收敛速率，还显著扩展了其适用范围，在大样本场景下优于传统核密度估计方法。

Abstract: We propose the periodic scaled Korobov kernel (PSKK) method for nonparametric
density estimation on $\mathbb{R}^d$. By first wrapping the target density into
a periodic version through modulo operation and subsequently applying kernel
ridge regression in scaled Korobov spaces, we extend the kernel approach
proposed by Kazashi and Nobile (SIAM J. Numer. Anal., 2023) and eliminate its
requirement for inherent periodicity of the density function. This key
modification enables effective estimation of densities defined on unbounded
domains. We establish rigorous mean integrated squared error (MISE) bounds,
proving that for densities with smoothness of order $\alpha$ and exponential
decay, our method achieves the $\mathcal{O}(M^{-1/(1+1/(2\alpha)+\epsilon)})$
MISE convergence rate with an arbitrarily small $\epsilon>0$. While matching
the convergence rate of the previous kernel approach, our approach applies to a
broader class of non-periodic distributions. Numerical experiments confirm the
theoretical results and demonstrate significant improvement over traditional
kernel density estimation in large-sample regimes.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [4] [On λ-Cent-Dians and Generalized-Center for Network Design: Formulations and Algorithms](https://arxiv.org/abs/2506.14839)
*Víctor Bucarey,Natividad González-Blanco,Martine Labbé,Juan A. Mesa*

Main category: math.OC

TL;DR: 本文研究了网络设计中的$\lambda$-中心问题，提出了一种在预算约束下设计子网络的方法，并扩展了现有工作，提供了广义$\lambda$-中心问题的算法视角。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于设计一个高效服务于多个起点/终点需求对的子网络，同时满足预算约束，扩展了现有关于$\lambda$-中心问题的研究。

Method: 方法包括为$\lambda\geq 0$提供数学公式，讨论$\lambda>1$时的双层结构问题，并引入最大$\lambda$-中心概念，通过混合整数线性规划求解帕累托最优集。

Result: 结果展示了不同解决方案的质量评估，并针对$\lambda\in[0,1]$实现了Benders分解方法以大规模求解问题。

Conclusion: 结论表明，所提出的方法能够有效解决广义$\lambda$-中心问题，并通过不等式度量验证了解决方案的优越性。

Abstract: In this paper, we study the $\lambda$-centdian problem in the domain of
Network Design. The focus is on designing a sub-network within a given
underlying network while adhering to a budget constraint. This sub-network is
intended to efficiently serve a collection of origin/destination demand pairs.
We extend the work presented in \cite{bucarey2024on}, providing an algorithmic
perspective on the generalized $\lambda$-centdian problem. In particular, we
provide a mathematical formulation for $\lambda\geq 0$ and discuss the bilevel
structure of this problem for $\lambda>1$. Furthermore, we describe a procedure
to obtain a complete parametrization of the Pareto-optimality set based on
solving two mixed integer linear formulations by introducing the concept of
maximum $\lambda$-cent-dian. We evaluate the quality of the different solution
concepts using some inequality measures. Finally, for $\lambda\in[0,1]$, we
study the implementation of a Benders decomposition method to solve it at
scale.

</details>


### [5] [An efficient co-simulation and control approach to tackle complex multi-domain energetic systems: concepts and applications of the PEGASE platform](https://arxiv.org/abs/2506.15195)
*Mathieu Vallee,Roland Baviere,Valérie Seguin,Valéry Vuillerme,Nicolas Lamaison,Michael Nikhil Descamps,Antoine Aurousseau*

Main category: math.OC

TL;DR: 本文介绍了一款名为PEGASE的新型研究软件，专为复杂多领域能源系统的先进控制策略设计、验证和部署而设计。该软件具备高效的协同仿真引擎，支持基于规则的控制策略和模型预测控制（MPC）。


<details>
  <summary>Details</summary>
Motivation: 针对多领域大规模能源系统的复杂性，传统的整体解决方案效率低下。PEGASE通过分而治之的方法，将问题分解为多个子问题，以解耦的方式进行仿真，从而提高效率。

Method: PEGASE基于两个主要组件：一个用于集成仿真模型的框架（支持FMI标准或API接口），以及一个多线程排序器，支持不同时间步长的仿真序列。此外，PEGASE还配备了MPC框架，用于管理预测数据和建模混合整数线性规划问题。

Result: PEGASE通过C++实现，提供了快速的建模和求解时间，并支持通过标准工业协议连接硬件，实现对真实能源系统的控制。四个应用示例展示了其在太阳能热电厂和区域供热网络等领域的适用性。

Conclusion: PEGASE通过其协同仿真和先进控制功能，能够有效应对各类复杂能源系统的挑战。多样化的应用示例证明了该方法的稳健性和通用性。

Abstract: In this paper, we present a novel research software, called PEGASE, suitable
for the design, validation and deployment of advanced control strategies for
complex multi-domain energy systems. PEGASE especially features a highly
efficient cosimulation engine, together with integrated solutions for defining
both rule-based control strategies and Model-Predictive Control (MPC). The main
principle behind the PEGASE platform is divide-and-conquer. Indeed, rather than
trying to solve a problem as a monolithic entity, which can be highly complex
for multi-domain large-scale systems, it is often more efficient to decompose
it into several domains or sub-problems, and to simulate them in a decoupled
way. To provide its cosimulation capabilities, we based PEGASE on two main
components. The first one is a framework for integrating simulation models,
which can be either compatible with the FMI standard or interfaced through an
Application Programming Interface (API). The second one is a multi-threaded
sequencer enabling several simulation sequences with different time steps. To
provide advanced control capabilities, we also equipped PEGASE with a framework
for MPC combining a comprehensive management of predictions data and a modeler
dedicated to the formulation of Mixed Integer Linear Programs. We implemented
this framework in C++ providing low formulation and resolution times for
typical applications. Connection to hardware is also available via standard
industry protocols thereby allowing PEGASE to control real energy systems. In
this paper, we show how these basic functionalities, combined with dedicated
modeling tools, enable setting up simulation and control applications suitable
for tackling the complexity of various kinds of energy systems. To illustrate
this, we present four application examples from our recent research work. These
examples cover several domains, from concentrated solar thermal plants to
optimal control of district heating networks. The variety of examples
demonstrates the robustness and genericity of the approach.

</details>


### [6] [Operational Control of a Multi-energy District Heating System: Comparison of Model-Predictive Control and Rule-Based Control](https://arxiv.org/abs/2506.15197)
*Michael Nikhil Descamps,Nicolas Lamaison,Mathieu Vallee,Roland Baviere*

Main category: math.OC

TL;DR: 本研究比较了区域供热网络（DHN）的两种运行控制策略：基于规则的响应式控制（RBC）和模型预测控制（MPC）。通过Modelica建模和小规模区域供热网络仿真，结合热泵、燃气锅炉和太阳能热场的混合能源系统，MPC在降低运营成本和应对能源价格波动方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索多能源区域供热网络的高效运行控制策略，比较RBC和MPC在满足用户需求、技术约束及成本优化方面的性能差异，特别是在电力价格波动和太阳能间歇性条件下的表现。

Method: 采用Modelica建立小规模区域供热网络模型，整合热泵、燃气锅炉、太阳能热场及储热罐。通过自研的Pegase协同仿真平台实施RBC和MPC策略，考虑不同场景（如设备规模配置和预测误差）对策略效果的影响。

Result: MPC策略相比RBC显著降低运营成本，尤其在处理可变电价、间歇性太阳能和储热能力时效率更高。仿真工具支持快速耦合Modelica模型与复杂控制策略，全年仿真可在20分钟内完成。

Conclusion: MPC在多能源区域供热网络中展现出更优的经济性和灵活性，研究验证了仿真工具在高效实施和验证复杂控制策略方面的实用性，为实际工程应用提供了技术支撑。

Abstract: This study focuses on operational control strategies for a multi-energy
District Heating Network (DHN). Two control strategies are investigated and
compared: (i) a reactive rule-based control (RBC) and (ii) a model predictive
control (MPC). For the purpose of the study a small scale district heating
network is modelled using Modelica. The production plant combines a heat pump,
a gas boiler and a thermal solar field on the production side with a storage
tank for flexibility purposes. On the consumption side, the virtual buildings
are aggregated into a single consumer. We use our co-simulation and control
platform, called Pegase, to implement the studied strategies. For both
strategies the goal is to meet the consumers' demand while satisfying technical
constraints. In addition MPC has the objective to minimize the operational
costs, taking into account variable electricity prices and availability of
solar thermal resource. Different scenarios are also defined and compared to
study the effect of the heat plant sizing and forecasting error. The
operational cost is reduced when switching from RBC to a MPC. As can be
expected, MPC is more efficient when dealing with variable energy costs,
intermittent solar energy and storage capabilities. This study also
demonstrates how our tools enable an easy coupling of Modelica-based simulation
with various control strategies. It especially supports the implementation and
validation of complex MPC strategies in an efficient way, and yearly
simulations are performed within 20 minutes.

</details>


### [7] [On the Effectiveness of Classical Regression Methods for Optimal Switching Problems](https://arxiv.org/abs/2506.15436)
*Martin Andersson,Benny Avelin,Marcus Olofsson*

Main category: math.OC

TL;DR: 简单回归方法在1至50维的最优切换问题中展现出稳健且接近最优的性能，无需复杂调参即可超越神经网络。


<details>
  <summary>Details</summary>
Motivation: 研究旨在验证简单回归方法（如$k$-NN）在处理复杂PDE系统衍生的最优切换问题时，是否能在高维环境下保持稳定性能。

Method: 采用Longstaff-Schwartz算法与八种回归方法（包括$k$-NN和神经网络），在四个基准问题上测试，分析PCA对$k$-NN高维扩展的作用，并建立跳跃扩散动力学下的$k$-NN浓度边界。

Result: 简单回归方法在含近似偏差和蒙特卡洛噪声的逆向归纳训练目标中表现优异，其稳定性优于复杂方法；PCA显著提升了$k$-NN的高维适应性。

Conclusion: 实践建议：对于计算密集型切换问题，简单、低调参的回归方法（如$k$-NN）能提供可靠解，且性能优于过度优化的神经网络。

Abstract: Simple regression methods provide robust, near-optimal solutions for optimal
switching problems in dimensions ranging from 1 to 50. While the theory
requires solving intractable PDE systems, the Longstaff-Schwartz algorithm with
classical approaches like $k$-NN achieves excellent switching decisions without
extensive hyperparameter tuning. Testing eight regression approaches on four
benchmark problems, we find that simple methods maintain stable performance
across diverse problem characteristics, even after extensive neural network
optimization. The contaminated training targets inherent to backward
induction-where each target contains both approximation bias and Monte Carlo
noise-actually favor these robust approaches over more complex alternatives
such as neural networks. Further, we establish concentration bounds for $k$-NN
regression under jump-diffusion dynamics and show that PCA enables $k$-NN to
scale to high dimensions. For practitioners: simple, minimally-tuned regression
methods offer reliable performance for computationally demanding switching
problems.

</details>


### [8] [Contribution of expert aggregation to temperature prediction part II: Second order bounds with sleeping experts](https://arxiv.org/abs/2506.15216)
*Léo Pfitzner,Olivier Wintenberger,Olivier Mestre*

Main category: math.OC

TL;DR: 本文通过引入睡眠专家框架(SEF)和梯度提升回归树改进了在线专家聚合(EA)的温度预测方法，提高了反应性并减少了误差，同时保持了均方根误差水平。


<details>
  <summary>Details</summary>
Motivation: 在保持均方根误差不增加的前提下，提高专家聚合方法的反应性并减少大误差的数量，特别是在不确定何时使用有偏专家的情况下。

Method: 采用睡眠专家框架(SEF)更有效地利用有偏专家，结合梯度提升回归树处理专家使用时机的不确定性，并在BOA自适应聚合方法中在线应用。

Result: 改进后的方法在保持原有误差水平的同时提高了预测的反应性，并通过元聚合策略限制了SEF可能引入的噪声。

Conclusion: 通过SEF和梯度提升回归树的结合，成功提升了专家聚合方法的性能，为不确定环境下的在线预测提供了有效解决方案。

Abstract: In this paper we improve on the temperature predictions made with (online)
Expert Aggregation (EA) [Cesa-Bianchi and Lugosi, 2006] in Part I. In
particular, we make the aggregation more reactive, whilst maintaining at least
the same root mean squared error and reducing the number of large errors. We
have achieved this by using the Sleeping Expert Framework (SEF) [Freund et al.,
1997, Devaine et al., 2013], which allows the more efficient use of biased
experts (bad on average but which may be good at some point). To deal with the
fact that, unlike in Devaine et al. [2013], we do not know in advance when to
use these biased experts, we resorted to gradient boosted regression trees
[Chen and Guestrin, 2016] and provide regret bounds against sequences of
experts [Mourtada and Maillard, 2017] which take into account this uncertainty.
We applied this in a fully online way on BOA [Wintenberger, 2024], an adaptive
aggregation with second order regret bounds, which had the best results in Part
I. Finally, we made a meta-aggregation with the EA follow the leader. This
chooses whether or not to use the SEF in order to limit the possible noise
added by the SEF.

</details>


### [9] [Contribution of expert aggregation to temperature prediction part I](https://arxiv.org/abs/2506.15217)
*Léo Pfitzner,Olivier Wintenberger,Olivier Mestre,Marion Riverain*

Main category: math.OC

TL;DR: 本文提出使用专家聚合（EA）策略优化数值天气预报（NWP）模型的温度预测，通过在线自适应方法提升预测精度，并比较了不同EA策略的效果与局限性。


<details>
  <summary>Details</summary>
Motivation: 现有多种数值天气预报模型及其统计后处理方法（MOS），但如何最优整合这些预测结果仍具挑战性。专家聚合（EA）因其在线性、模型变化适应性和理论保障等优势成为解决方案。

Method: 采用专家聚合（EA）策略进行确定性温度预测，具体方法包括动态权重分配和模型后处理优化，并对比了不同EA策略在不同场景下的表现。

Result: 研究表明，EA策略能有效提升温度预测精度，甚至优于经过后处理的NWP模型。不同EA策略在不同设置下表现各异，部分策略存在局限性。

Conclusion: 专家聚合（EA）为整合多源天气预报提供了有效框架，显著改善了温度预测性能，但需根据实际需求选择合适策略并注意其适用边界。

Abstract: Many Numerical Weather Prediction (NWP) models and their associated Model
Output Statistics (MOS) are available. Combining all of these predictions in an
optimal way is however not straightforward. This can be achieved thanks to
Expert Aggregation (EA) [Cesa-Bianchi and Lugosi, 2006, Gaillard et al., 2014,
Wintenberger, 2024] which has many advantages, such as being online, being
adaptive to model changes and having theoretical guarantees. Hence, in this
paper, we propose a method for making deterministic temperature predictions
with EA strategies and show how this can improve temperature predictions, even
those of post processed NWP models. We also compare different EA strategies in
various settings and discuss certain limitations.

</details>


### [10] [Polynomial Eigenfunctions and Matrix Lyapunov Equations from Energy Balance Integrals](https://arxiv.org/abs/2506.15288)
*Netzer Moriya*

Main category: math.OC

TL;DR: 该论文建立了一个统一的理论框架，将经典正交多项式系统与矩阵Lyapunov方程通过随机动力系统中的能量耗散物理联系起来，揭示了二者在能量耗散结构上的对偶性。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于将无限维希尔伯特空间中的能量平衡原理与经典正交多项式及矩阵Lyapunov方程的理论联系，以揭示它们背后的统一物理机制。

Method: 方法上，从无限维希尔伯特空间的能量平衡原理出发，推导出一个主积分表示，涵盖谱几何和协方差动力学，并通过有限维投影重现经典矩阵方程。

Result: 结果表明，经典正交多项式（如Zernike、Hermite、球谐函数）与矩阵Lyapunov方程是同一能量耗散结构的对偶表现，且均匀耗散的加入保持了多项式特征函数结构。

Conclusion: 结论指出，该框架为经典微分算子的多项式特征函数结构提供了严格的数学基础，同时确保了物理一致性所需的能量平衡条件。

Abstract: We establish a unified theoretical framework that connects classical
orthogonal polynomial systems to matrix Lyapunov equations through the
fundamental physics of energy dissipation in stochastic dynamical systems.
Starting from the energy balance principle in infinite-dimensional Hilbert
spaces, we derive a master integral representation that naturally encompasses
both spectral geometry and covariance dynamics. The theory reveals that
established orthogonal polynomials (Zernike, Hermite, spherical harmonics) and
matrix Lyapunov equations are dual manifestations of the same underlying energy
dissipation structure. We provide rigorous mathematical foundations showing how
finite-dimensional projections of infinite-dimensional energy integrals
reproduce classical matrix equations, with specific structure determined by the
symmetries of noise processes. The framework demonstrates that adding uniform
dissipation to classical differential operators preserves their polynomial
eigenfunction structure while ensuring the energy balance conditions required
for physical consistency.

</details>


### [11] [Proximal Operators of Sorted Nonconvex Penalties](https://arxiv.org/abs/2506.15315)
*Anne Gagneux,Mathurin Massias,Emmanuel Soubies*

Main category: math.OC

TL;DR: 本文研究了稀疏信号恢复中的变量自动分组问题，提出了一类排序非凸惩罚方法，用于广义线性模型的正则化。该方法通过排序特性促进变量聚类，并通过非凸性减少系数收缩。针对弱凸和非凸两种情况，分别提出了高效计算近端算子的方法，并在实验中验证了其实际价值。


<details>
  <summary>Details</summary>
Motivation: 稀疏信号恢复中的变量自动分组是一个重要问题。现有方法如SLOPE虽能促进变量聚类，但存在系数过度收缩的缺点。本文旨在通过排序非凸惩罚方法，在保持聚类效果的同时减少系数偏差。

Method: 提出了一类推广SLOPE的排序非凸惩罚族。对于弱凸情况（如排序MCP和SCAD），使用PAV算法精确计算近端算子；对于非凸情况（如排序Lq，q∈]0,1[），提出了PAV算法的改进版本。

Result: 理论分析表明改进的PAV算法能有效解决非凸近端算子计算问题。实验证明排序非凸惩罚在保持变量聚类效果的同时，显著减少了系数收缩偏差。

Conclusion: 排序非凸惩罚方法在稀疏信号恢复中具有显著优势，其提出的近端算子计算方法为相关优化问题提供了高效解决方案。该方法在理论和实践中均展现出良好性能。

Abstract: This work studies the problem of sparse signal recovery with automatic
grouping of variables. To this end, we investigate sorted nonsmooth penalties
as a regularization approach for generalized linear models. We focus on a
family of sorted nonconvex penalties which generalizes the Sorted L1 Norm
(SLOPE). These penalties are designed to promote clustering of variables due to
their sorted nature, while the nonconvexity reduces the shrinkage of
coefficients. Our goal is to provide efficient ways to compute their proximal
operator, enabling the use of popular proximal algorithms to solve composite
optimization problems with this choice of sorted penalties. We distinguish
between two classes of problems: the weakly convex case where computing the
proximal operator remains a convex problem, and the nonconvex case where
computing the proximal operator becomes a challenging nonconvex combinatorial
problem. For the weakly convex case (e.g. sorted MCP and SCAD), we explain how
the Pool Adjacent Violators (PAV) algorithm can exactly compute the proximal
operator. For the nonconvex case (e.g. sorted Lq with q in ]0,1[), we show that
a slight modification of this algorithm turns out to be remarkably efficient to
tackle the computation of the proximal operator. We also present new
theoretical insights on the minimizers of the nonconvex proximal problem. We
demonstrate the practical interest of using such penalties on several
experiments.

</details>


### [12] [Optimal Control of Thin-Film Flow on a Flexible Topography](https://arxiv.org/abs/2506.15340)
*S. Alrashidy,A. Kalogirou,D. Kalise,K. G. van der Zee*

Main category: math.OC

TL;DR: 本文提出了一种数学模型，用于优化控制受外力影响的柔性地形上的薄膜流动，包括薄膜破裂和气泡合并现象。通过非线性润滑方程和能量耗散定律，推导了最优控制条件，并采用数值方法验证了控制策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过外部力控制柔性地形上的薄膜流动，以最小化实际与理想薄膜轮廓的差异，解决薄膜破裂和气泡合并等复杂流体动力学问题。

Method: 建立了非线性润滑方程描述流体动力学，推导了全局能量耗散定律和最优控制条件，采用IMEX时间步进法和降维梯度下降算法进行数值求解。

Result: 数值结果表明，控制策略能精确调控薄膜轮廓，加速稳态收敛，减少不稳定性，稳定去湿过程，并满足预设轮廓要求。

Conclusion: 该模型为柔性地形上薄膜流动的控制提供了有效方法，尤其在处理薄膜破裂和气泡合并时表现出优越性能，具有重要的理论和应用价值。

Abstract: This work presents a mathematical model for the optimal control of thin-film
flows over a flexible topography influenced by an external force. Our thin-film
model allows for the rupture of films as well as the coalescence of bubbles.
The objective is to find the optimal distributed force acting on the topography
that minimises the differences between actual and desired thin-film profiles. A
nonlinear lubrication equation governing the fluid dynamics and appropriate
functional settings for this model are presented. It is also shown that this
system satisfies a global energy-dissipation law for a suitable energy
functional. Optimality conditions are derived for the solution of the
minimisation problem of a specified cost function across a time horizon. These
conditions are formulated at a continuous level as a system of coupled,
forward-backward PDEs, which are subsequently discretised for numerical
investigation. To ensure computational efficiency and stability, first-order
Implicit-Explicit (IMEX) time-stepping schemes are employed to handle the
nonlinearities in the model, and a reduced gradient descent algorithm is
applied to obtain a numerical approximation of the optimal control signal.
Numerical results illustrate that controlling the thin film, even during
rupture, achieves a precise film profile. This control strategy accelerates
convergence towards a steady state, reduces instabilities, stabilises dewetting
processes, and meets the desired profile specifications.

</details>


### [13] [Multi-Timescale Gradient Sliding for Distributed Optimization](https://arxiv.org/abs/2506.15387)
*Junhui Zhang,Patrick Jaillet*

Main category: math.OC

TL;DR: 本文提出了两种一阶方法MT-GS和AMT-GS，用于解决非光滑分布式凸优化问题，通过多时间尺度策略减少通信轮数，并实现最优的$\epsilon$依赖性。


<details>
  <summary>Details</summary>
Motivation: 分布式优化中，减少通信轮数并保持算法效率是一个关键挑战。本文旨在通过多时间尺度梯度滑动方法，利用目标函数的相似性降低通信开销。

Method: 采用块可分解的原始-对偶公式和多时间尺度滑动方法，不同对偶块以不同速率更新，从而灵活适应不同代理的通信需求。

Result: MT-GS需要$O(\overline{r}A/\epsilon)$通信轮数和$O(\overline{r}/\epsilon^2)$次梯度步数；AMT-GS在强凸情况下需要$O(\overline{r}A/\sqrt{\epsilon\mu})$通信轮数和$O(\overline{r}/(\epsilon\mu))$次梯度步数。通信轮数对$A$的线性依赖是最优的。

Conclusion: MT-GS和AMT-GS在非光滑分布式优化中实现了通信效率的最优性，解决了Arjevani和Shamir（2015）提出的开放性问题。

Abstract: We propose two first-order methods for convex, non-smooth, distributed
optimization problems, hereafter called Multi-Timescale Gradient Sliding
(MT-GS) and its accelerated variant (AMT-GS). Our MT-GS and AMT-GS can take
advantage of similarities between (local) objectives to reduce the
communication rounds, are flexible so that different subsets (of agents) can
communicate at different, user-picked rates, and are fully deterministic. These
three desirable features are achieved through a block-decomposable primal-dual
formulation, and a multi-timescale variant of the sliding method introduced in
Lan et al. (2020), Lan (2016), where different dual blocks are updated at
potentially different rates.
  To find an $\epsilon$-suboptimal solution, the complexities of our algorithms
achieve optimal dependency on $\epsilon$: MT-GS needs
$O(\overline{r}A/\epsilon)$ communication rounds and
$O(\overline{r}/\epsilon^2)$ subgradient steps for Lipchitz objectives, and
AMT-GS needs $O(\overline{r}A/\sqrt{\epsilon\mu})$ communication rounds and
$O(\overline{r}/(\epsilon\mu))$ subgradient steps if the objectives are also
$\mu$-strongly convex. Here, $\overline{r}$ measures the ``average rate of
updates'' for dual blocks, and $A$ measures similarities between (subgradients
of) local functions. In addition, the linear dependency of communication rounds
on $A$ is optimal (Arjevani and Shamir 2015), thereby providing a positive
answer to the open question whether such dependency is achievable for
non-smooth objectives (Arjevani and Shamir 2015).

</details>


### [14] [Efficient Online Mirror Descent Stochastic Approximation for Multi-Stage Stochastic Programming](https://arxiv.org/abs/2506.15392)
*Junhui Zhang,Patrick Jaillet*

Main category: math.OC

TL;DR: 本文研究了多阶段随机规划问题的无约束和极小极大鞍点变体，提出了一种新的随机条件梯度预言机方法，并证明了镜像下降随机逼近算法的收敛性。通过半在线视角和异步实现，显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究多阶段随机规划问题中决策通过目标函数耦合的情况，旨在解决传统方法在约束耦合下的局限性，并降低计算复杂度。

Method: 基于确定性镜像下降算法与不精确梯度分析，引入随机条件梯度预言机，采用半在线视角和异步实现策略，减少计算负担。

Result: 证明了（加速）镜像下降随机逼近算法的期望和高概率收敛性，并通过延迟决策将复杂度从指数级降至线性级。

Conclusion: 提出的随机条件梯度预言机和半在线策略有效解决了多阶段随机规划问题，显著提升了计算效率，为实际应用提供了新思路。

Abstract: We study the unconstrained and the minimax saddle point variants of the
convex multi-stage stochastic programming problem, where consecutive decisions
are coupled through the objective functions, rather than through the
constraints. Based on the analysis of deterministic mirror descent algorithms
with inexact gradients, we introduce the idea of \textit{stochastic conditional
gradient oracles}, a multi-stage analog of the stochastic gradient oracles used
in (classical) stochastic programming. We show one approach to construct such
oracles and prove the convergence of the (accelerated) mirror descent
stochastic approximation, both in expectation and with high probability. To
further reduce the oracle complexity, we view the problem from a
\textit{semi-online} perspective, where the stage $t$ decision variables are
constructed $s$ stages in advance, instead of before stage $1$. We show that
the delay in decision making allows an asynchronous implementation of the
mirror descent stochastic approximation algorithms. By avoiding computing
solutions for scenarios that are inconsistent with information available during
stage $t$, the complexity is reduced from exponential to linear in the number
of stages.

</details>


### [15] [A polynomial projective algorithm for convex feasibility problems with positive-definite constraints](https://arxiv.org/abs/2506.15484)
*Sergei Chubanov*

Main category: math.OC

TL;DR: 本文研究了一类与自对偶锥相关的谱面投影变换，并提出了一种多项式时间算法来解决具有正定约束的凸可行性问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于改进现有凸可行性问题的求解效率，特别是在涉及正定矩阵约束的情况下，通过投影变换和势函数测量来优化算法性能。

Method: 方法包括在每次迭代中寻找可行解或生成有效不等式，通过投影变换将解集拉近关联谱面的中心，并使用势函数测量接近程度。

Result: 结果表明，该算法在方程数不小于正半定锥秩和的情况下，能够更精确地界定现有复杂度范围。

Conclusion: 结论指出，所提出的算法在特定条件下显著提升了凸可行性问题的求解效率，为相关优化问题提供了新的理论工具。

Abstract: We study a class of projective transformations of spectraplexes associated
with self-dual cones and, on this basis, propose a polynomial-time algorithm
for convex feasibility problems with positive definite constraints. At each
iteration of the algorithm, either a feasible solution is found or a suitable
valid inequality inducing a projective transformation allowing to bring the
solution set closer to the center of an associated spectraplex. The closeness
to the center is measured in terms of a potential function. The running time of
our algorithm makes the existing complexity bounds more precise for the case
when the number of equations linking the positive definite variable matrices is
not less than the sum of the ranks of the respective positive-semidefinite
cones.

</details>


### [16] [On Exact Solutions to the Linear Bellman Equation](https://arxiv.org/abs/2506.15527)
*David Ohlin,Richard Pates,Murat Arcak*

Main category: math.OC

TL;DR: 本文提出了线性算子动态系统最优控制的充分条件，推导出可分布式计算的Bellman方程显式解，并将线性可解MDP重构为连续状态最优控制问题。


<details>
  <summary>Details</summary>
Motivation: 研究旨在扩展线性可解MDP理论至半线性动态系统，以处理输入非线性问题，并为随机最短路径和线性二次调节器问题提供适用条件。

Method: 通过建立线性算子动态系统的充分条件，将Bellman方程显式解与分布式计算结合，并重新形式化线性可解MDP为连续状态控制问题。

Result: 证明了线性可解MDP类天然满足Bellman方程显式解条件，成功将理论推广至半线性动态系统，并在线性/二次成本场景中得到验证。

Conclusion: 所提条件适用于处理输入非线性的扩展场景，为随机最短路径和LQR问题提供了新的分布式求解框架。

Abstract: This paper presents sufficient conditions for optimal control of systems with
dynamics given by a linear operator, in order to obtain an explicit solution to
the Bellman equation that can be calculated in a distributed fashion. Further,
the class of Linearly Solvable MDP is reformulated as a continuous-state
optimal control problem. It is shown that this class naturally satisfies the
conditions for explicit solution of the Bellman equation, motivating the
extension of previous results to semilinear dynamics to account for input
nonlinearities. The applicability of the given conditions is illustrated in
scenarios with linear and quadratic cost, corresponding to the Stochastic
Shortest Path and Linear-Quadratic Regulator problems.

</details>


### [17] [Long run control of nonhomogeneous Markov processes](https://arxiv.org/abs/2506.15542)
*Łukasz Stettner*

Main category: math.OC

TL;DR: 论文研究了非齐次马尔可夫过程的平均奖励和风险敏感奖励泛函，证明了贝尔曼方程解的存在性、值函数对风险参数的连续性，以及控制收敛下的泛函稳定性。


<details>
  <summary>Details</summary>
Motivation: 探讨非齐次马尔可夫控制过程中平均单位时间奖励和风险敏感奖励泛函的数学特性，为随机控制理论提供理论基础。

Method: 通过构建合适的贝尔曼方程，分析其解的存在性；采用参数连续性证明和点态收敛方法研究泛函稳定性。

Result: 证明了贝尔曼方程解的存在性、值函数对风险敏感参数的连续依赖性，以及马尔可夫控制点态收敛时的泛函稳定性。

Conclusion: 该研究为风险敏感型随机控制问题建立了理论框架，其连续性及稳定性结论对实际应用具有指导意义。

Abstract: In the paper average reward per unit time and average risk sensitive reward
functionals are considered for controlled nonhomogeneous Markov processes.
Existence of solutions to suitable Bellman equations is shown. Continuity of
the value functions with respect to risk parameter is also proved. Finally
stability of functionals with respect to pointwise convergence of Markov
controls is studied.

</details>


### [18] [Primal-Dual Coordinate Descent for Nonconvex-Nonconcave Saddle Point Problems Under the Weak MVI Assumption](https://arxiv.org/abs/2506.15597)
*Iyad Walwil,Olivier Fercoq*

Main category: math.OC

TL;DR: 本文提出了两种新的原始-对偶算法（NC-PDHG和NC-SPDHG），用于解决非凸、非凹且非光滑的鞍点问题，并通过弱Minty变分不等式（MVI）条件证明其收敛性。数值实验验证了算法在逻辑回归和感知机回归等问题上的高效性。


<details>
  <summary>Details</summary>
Motivation: 设计针对非凸非凹鞍点问题的坐标下降算法具有挑战性，为此作者利用PEPit工具和自动化Lyapunov函数技术，成功推导出NC-SPDHG算法，填补了该领域的空白。

Method: NC-PDHG扩展了经典的原始-对偶混合梯度法（PDHG），而NC-SPDHG则结合随机外推坐标下降技术。两种方法在弱MVI参数满足温和条件下，采用自适应问题结构的恒定步长实现收敛。

Result: 数值实验表明，新算法在平方损失逻辑回归和感知机回归问题上具有线性收敛速度，性能优于现有最优算法。NC-SPDHG在凸凹最小二乘实验中与SAGA算法表现相当。

Conclusion: 所提算法为非凸非凹鞍点问题提供了有效解决方案，理论分析和实验验证均表明其优越性，尤其在弱MVI条件下展现出稳定收敛特性。

Abstract: We introduce two novel primal-dual algorithms for addressing nonconvex,
nonconcave, and nonsmooth saddle point problems characterized by the weak Minty
Variational Inequality (MVI). The first algorithm, Nonconvex-Nonconcave
Primal-Dual Hybrid Gradient (NC-PDHG), extends the well-known Primal-Dual
Hybrid Gradient (PDHG) method to this challenging problem class. The second
algorithm, Nonconvex-Nonconcave Stochastic Primal-Dual Hybrid Gradient
(NC-SPDHG), incorporates a randomly extrapolated primal-dual coordinate descent
approach, extending the Stochastic Primal-Dual Hybrid Gradient (SPDHG)
algorithm.
  To our knowledge, designing a coordinate-based algorithm to solve
nonconvex-nonconcave saddle point problems is unprecedented, and proving its
convergence posed significant difficulties. This challenge motivated us to
utilize PEPit, a Python-based tool for computer-assisted worst-case analysis of
first-order optimization methods. By integrating PEPit with automated Lyapunov
function techniques, we successfully derived the NC-SPDHG algorithm.
  Both methods are effective under a mild condition on the weak MVI parameter,
achieving convergence with constant step sizes that adapt to the structure of
the problem. Numerical experiments on logistic regression with squared loss and
perceptron-regression problems validate our theoretical findings and show their
efficiency compared to existing state-of-the-art algorithms, where linear
convergence is observed. Additionally, we conduct a convex-concave
least-squares experiment to show that NC-SPDHG performs competitively with
SAGA, a leading algorithm in the smooth convex setting.

</details>


### [19] [Heavy Ball and Nesterov Accelerations with Hessian-driven Damping for Nonconvex Optimization](https://arxiv.org/abs/2506.15632)
*N. Hadjisavvas,F. Lara,R. T. Marcavillaca,P. T. Vuong*

Main category: math.OC

TL;DR: 本文研究了针对强拟凸函数的二阶动力系统，提出了两种离散时间梯度算法，均实现了线性收敛。


<details>
  <summary>Details</summary>
Motivation: 旨在解决经典动量方法中常见的振荡问题，提升非凸优化中的稳定性和收敛性能。

Method: 基于连续时间模型，推导出带Hessian修正的重球法和自适应动量Nesterov加速法两种离散算法。

Result: 理论证明两种算法在迭代值和函数值上均能线性收敛至最优解，数值实验验证了结果。

Conclusion: 研究揭示了连续时间动力学与离散优化算法在强拟凸目标下的深刻联系，提出的方法有效抑制了振荡。

Abstract: In this work, we investigate a second-order dynamical system with
Hessian-driven damping tailored for a class of nonconvex functions called
strongly quasiconvex. Buil\-ding upon this continuous-time model, we derive two
discrete-time gra\-dient-based algorithms through time discretizations. The
first is a Heavy Ball method with Hessian correction, incorporating
cur\-va\-tu\-re-dependent terms that arise from discretizing the Hessian
damping component. The second is a Nesterov-type accelerated method with
adaptive momentum, fea\-tu\-ring correction terms that account for local
curvature. Both algorithms aim to enhance stability and convergence
performance, particularly by mi\-ti\-ga\-ting oscillations commonly observed in
cla\-ssi\-cal momentum me\-thods. Furthermore, in both cases we establish
li\-near convergence to the optimal solution for the iterates and functions
values. Our approach highlights the rich interplay between continuous-time
dynamics and discrete optimization algorithms in the se\-tting of strongly
quasiconvex objectives. Numerical experiments are presented to support obtained
results.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [20] [Special Cases of the Shafarevich Conjecture for Complete Intersections in Abelian Varieties](https://arxiv.org/abs/2506.14935)
*Frank Lu*

Main category: math.NT

TL;DR: 本文利用Lawrence-Venkatesh方法，证明了数域$K$上阿贝尔簇中某些完全交超曲面的Shafarevich猜想，关键创新在于计算欧拉示性数及证明Hodge结构变体的单值群大定理。


<details>
  <summary>Details</summary>
Motivation: 研究数域上阿贝尔簇完全交超曲面的Shafarevich猜想，旨在扩展对算术几何中丢番图可解性问题的理解。

Method: 结合Lawrence-Venkatesh方法，通过计算特定欧拉示性数，并将Hodge结构变体的单值群问题转化为Tannaka群组合陈述。

Result: 成功证明了目标完全交超曲面的Shafarevich猜想，并建立了单值群大定理与组合问题的联系。

Conclusion: 该方法为算术几何中类似问题提供了新工具，且单值群与Tannaka群的关联具有潜在推广价值。

Abstract: In this paper, we prove the Shafarevich conjecture for certain complete
intersections of hypersurfaces in abelian varieties defined over a number field
$K$ using the Lawrence-Venkatesh method. The main new inputs we need are
computation of certain Euler characteristics of these complete intersections
and a big monodromy statement for the variation of Hodge structure arising from
the middle cohomology of a family of such complete intersections. Following
\cite{ls25}, we prove the latter by relating this monodromy statement to a
statement about Tannaka groups, which we then convert into a combinatorial
statement.

</details>


### [21] [Triangular and tetrahedral number differences of sumset sizes in additive number theory](https://arxiv.org/abs/2506.15015)
*Melvyn B. Nathanson*

Main category: math.NT

TL;DR: 本文研究了整数有限集合的和集大小分布，发现四元素集合的流行和集大小呈现与三角数和四面体数相关的意外模式。


<details>
  <summary>Details</summary>
Motivation: 以往研究主要关注极小和集（Freiman定理）或极大和集（Sidon集与$B_h$集），本文旨在探索整数有限集合和集大小的完整分布范围。

Method: 通过系统分析不同大小整数集合的和集分布，特别聚焦于四元素集合的统计规律。

Result: 发现四元素集合的流行和集大小分布存在与三角数($\frac{n(n+1)}{2}$)及四面体数相关的数学模式。

Conclusion: 该研究揭示了整数集合和集大小分布中未被发现的数学结构，为加性组合学开辟了新研究方向。

Abstract: The study of sums of finite sets of integers has mostly concentrated on sets
with very small sumsets (Freiman's theorem and related work) and on sets with
very large sumsets (Sidon sets and $B_h$-sets). This paper considers the full
range of sumset sizes of finite sets of integers and an unexpected pattern
(related to the triangular and tetrahedral numbers) that appears in the
distribution of popular sumset sizes of sets of size 4.

</details>


### [22] [On the Modern Structure of the Gauss-Landau Theorem](https://arxiv.org/abs/2506.15101)
*Manuel M. Aguilera*

Main category: math.NT

TL;DR: 该研究对高斯-兰道定理进行了形式化，提出了一种统一的质因数分解方法来计算有限非零整数集的最大公约数（GCD）和最小公倍数（LCM）。


<details>
  <summary>Details</summary>
Motivation: 尽管这些定理在初等数论教学中常被用作启发式方法或技巧，但文献中尚未对其进行明确的形式化或命名。此形式化旨在增强理解并促进其在数学教学和研究中的应用。

Method: 通过统一的质因数分解方法，对有限非零整数集的GCD和LCM进行计算。

Result: 研究成功形式化了高斯-兰道定理，并提供了计算GCD和LCM的统一方法。

Conclusion: 该形式化不仅填补了文献中的空白，还为数学教学和研究提供了更清晰和系统的工具。

Abstract: We formalize the Gauss-Landau theorem, providing a unified prime
factorization approach to computing the GCD and LCM of finite nonzero integer
sets. Although commonly used as a heuristic or technique in elementary number
theory education, these theorems have not been explicitly formalized or named
in the literature. This formalization aims to enhance understanding and
facilitate adoption in mathematical instruction and research.

</details>


### [23] [Characterizing infinite torsion subgroups of the circle through arithmetic-type sequences](https://arxiv.org/abs/2506.15257)
*Ayan Ghosh,Pratulananda Das*

Main category: math.NT

TL;DR: 本文扩展了Das等人的工作，证明了算术型序列对应的特征子群可数当且仅当它是挠子群，且任何无限挠子群可由有界比的算术型序列表征，同时指出Eggleston定理的二分类不适用于一般算术型序列。


<details>
  <summary>Details</summary>
Motivation: 基于Das等人对算术型序列特征子群结构的研究，进一步探索这类子群的计数性质与挠性关系，并验证Eggleston定理在更广泛序列类中的适用性。

Method: 通过分析算术型序列与特征子群的关联性，结合挠子群的代数性质，采用构造性证明展示有界比序列对无限挠子群的表征能力。

Result: 发现特征子群可数性与挠性等价，且圆周上的无限挠子群均可用有界比算术型序列表征；同时揭示Eggleston二分类现象在广义算术型序列中不成立。

Conclusion: 研究深化了对算术型序列特征子群的理解，明确了挠性与可数性的等价关系，并指出经典定理的局限性，为后续非标准序列研究提供了新方向。

Abstract: In a recent work [Das et al., Bull. Sci. Math. 199 (2025), 103580], the
structure of characterized subgroups corresponding to arithmetic-type sequences
was investigated. Building upon this work, we further show that a characterized
subgroup associated with an arithmetic-type sequence is countable if and only
if it is torsion. Further we prove that any infinite torsion subgroup of the
circle can be characterized by an arithmetic-type sequence with bounded ratio.
Moreover, our findings demonstrate that the dichotomy observed in Eggleston's
theorem [Theorem 16, Eggleston, Proc. Lond. Math. Soc. 54(2) (1952), 42--93]
for arithmetic sequences does not extend, in general, to the broader class of
arithmetic-type sequences.

</details>


### [24] [Metric Poissonian pair correlationa and additive energy](https://arxiv.org/abs/2506.15274)
*Tanmoy Bera,E. Malavika*

Main category: math.NT

TL;DR: 本文证明了当自然数严格递增序列$(a_n)$的加性能量小于$N^3/(\log N)^C$（其中$C\geq13.155$）时，对于几乎所有实数$\alpha\in\mathbb{R}$，序列$(\{a_n\alpha\})$具有泊松对相关性。这为Bloom和Walker[3]建立的加性能量界中的指数$C$提供了下界。


<details>
  <summary>Details</summary>
Motivation: 研究严格递增自然数序列的加性能量与泊松对相关性之间的关系，为已有理论提供更精确的指数下界。

Method: 通过分析序列的加性能量上界，结合数学推导，证明在特定条件下序列的模1分布具有泊松对相关性。

Result: 当加性能量小于$N^3/(\log N)^C$且$C\geq13.155$时，序列$(\{a_n\alpha\})$对几乎所有实数$\alpha$具有泊松对相关性。

Conclusion: 该结果为加性能量界中的指数$C$提供了明确的下界（$C\geq13.155$），完善了Bloom和Walker[3]的理论成果。

Abstract: In this article we prove that if the additive energy of a strictly increasing
sequence $(a_n)$ of natural numbers is less than $N^3/(\log N)^C$ for some
$C\geq13.155$, then $(\{a_n\alpha\})$ has Poissonian pair correlation for
almost all $\alpha\in\mathbb{R}.$ This provides a lower bound for the exponent
$C$ in the additive energy bound established by Bloom and Walker[3].

</details>


### [25] [Singular intersections on families of abelian varieties](https://arxiv.org/abs/2506.15344)
*Nicola Ottolini*

Main category: math.NT

TL;DR: 在代数几何中，本文证明了在阿贝尔概形中，曲线与真平坦子群概形相切的点集是有限的，这是关于不可能交问题的一个结果。


<details>
  <summary>Details</summary>
Motivation: 研究阿贝尔概形中曲线与子群概形的切点有限性，属于不可能交问题的范畴，是对相对Pink猜想的变体研究。

Method: 通过代数几何和算术几何的方法，分析曲线$\mathcal{C}$在阿贝尔概形$\mathcal{A}$中与真平坦子群概形的切点性质。

Result: 证明了曲线$\mathcal{C}$与$\mathcal{A}$的真平坦子群概形相切的点集是有限的。

Conclusion: 这一结果为不可能交问题提供了新的理论支持，拓展了相对Pink猜想在阿贝尔簇中的应用范围。

Abstract: Let $S$ be a smooth irreducible curve defined over $\overline{\mathbb{Q}}$,
let $\mathcal{A}$ be an abelian scheme over $S$ and $\mathcal{C}$ a curve
inside $\mathcal{A}$, both defined over $\overline{\mathbb{Q}}$. In this paper
we prove that the set of points in which $\mathcal{C}$ intersects proper flat
subgroup schemes of $\mathcal{A}$ tangentially is finite. This fits in the
framework of the so-called problems of unlikely intersections, and can be seen
as a variation of the relative Pink conjecture for abelian varieties.

</details>


### [26] [A categorical formulation of the Deligne-Terasoma approach to double shuffle theory](https://arxiv.org/abs/2506.15348)
*Benjamin Enriquez,Khalef Yaddaden*

Main category: math.NT

TL;DR: 本文引入具有分解结构的双模(BFS)概念，证明其可诱导代数态射，并为双洗理论中的Betti与de Rham谐波余积提供几何解释框架。


<details>
  <summary>Details</summary>
Motivation: 旨在通过BFS结构统一理解双洗理论中Betti与de Rham谐波余积背后的几何构造。

Method: 提出具有分解结构的双模(BFS)新概念，建立其与代数态射的关联，并关联至双洗理论中的谐波余积。

Result: 证明BFS结构能自然诱导代数态射，且该框架可解释$\\cite{DeT, EF1, EF2, EF3}$中谐波余积的几何构造。

Conclusion: BFS结构为双洗理论的几何机制提供了普适性解释，统一了Betti与de Rham谐波余积的数学本质。

Abstract: In this paper, we introduce the notion of a bimodule with a factorization
structure (BFS) and show that such a structure gives rise to an algebra
morphism. We then prove that this framework offers an interpretation of the
geometric construction underlying both the Betti and de Rham harmonic
coproducts of the double shuffle theory developed in \cite{DeT, EF1, EF2, EF3}.

</details>


### [27] [Patterns in Growth and Distribution of Unbounded Prime Number Walks](https://arxiv.org/abs/2506.15357)
*Alberto Fraile,Daniel Fernández,Roberto Martínez,Theophanes E. Raptis*

Main category: math.NT

TL;DR: 本文证明了素数行走(PW)覆盖的面积无界的猜想，并深入探讨了其性质及衍生问题。


<details>
  <summary>Details</summary>
Motivation: 基于前期工作中素数行走在方格上的定义及数值结果，验证其面积无界性的核心猜想。

Method: 通过理论分析与数值验证相结合，详细考察素数行走的几何特性。

Result: 证实了素数行走覆盖区域无界的猜想，并揭示了新的相关数学问题。

Conclusion: 该研究不仅验证了关键猜想，还为素数行走的深入探索开辟了新方向。

Abstract: In our previous work, we defined a prime walk (PW) on a square grid and
presented several intriguing numerical results. Here, we demonstrate the main
conjecture presented there, namely, that the area covered by the prime walk is
unbounded. Taking this fact into account, we examine in further detail the
properties of the PW and explore new questions that arise naturally in this
analysis.

</details>


### [28] [No Nowhere Continuous Function Maps all Non-Normal Numbers to Normal Numbers](https://arxiv.org/abs/2506.15422)
*Chokri Manai*

Main category: math.NT

TL;DR: 本文证明了不存在一个非空开区间$I$和一个非常数连续函数$\phi$，能将所有非正规数映射为正规数。相反，正规数集$\mathcal{N}$具有相反性质，并构造了一个具体的Cantor型非常数连续函数$\hat{C}$将所有正规数映射为非正规数。


<details>
  <summary>Details</summary>
Motivation: 研究非正规数集$\mathcal{N}^c$的性质，探讨是否存在连续函数能将其映射为正规数集$\mathcal{N}$，以揭示$\mathcal{N}^c$的丰富性。

Method: 通过数学反证法证明不存在满足条件的函数$\phi$，并采用Cantor型构造法显式构建函数$\hat{C}$实现正规数到非正规数的映射。

Result: 否定了存在性命题，同时成功构造了$\hat{C}$函数，表明正规数集$\mathcal{N}$不具有$\mathcal{N}^c$的对应性质。

Conclusion: 非正规数集$\mathcal{N}^c$的拓扑性质比正规数集更复杂，该结果进一步揭示了实数集中正规/非正规数分布的深刻差异。

Abstract: In this work, we consider the set of non-normal numbers $\mathcal{N}^c$ and
ask if there is a non-empty open interval $I$ and a nowhere constant continuous
function $\phi: I \to \rr$ which maps all non-normal numbers to normal numbers,
i.e., $\varphi(I \cap \mathcal{N}^c) \subset \mathcal{N}.$ We answer this
question negatively. This result can be seen as a further manifestation of the
richness of the null set $\mathcal{N}^c$. Surprisingly, the "bigger" set of
normal numbers $\mathcal{N}$ does not share this property and we will give an
explicit Cantor-type construction of a nowhere constant continuous function
$\hat{C}$, which maps all normal numbers to non-normal numbers.

</details>


### [29] [Evaluation of Modular Polynomials from Supersingular Elliptic Curves](https://arxiv.org/abs/2506.15429)
*Maria Corte-Real Santos,Jonathan Komada Eriksen,Antonin Leroux,Michael Meyer,Lorenz Panny*

Main category: math.NT

TL;DR: 本文提出了两种基于CRT方法和超奇异曲线的新算法，用于计算模素数$p$下级别$\ell$的模多项式，具有最优内存需求和不同时间复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有算法在计算模多项式时内存需求较高，本文旨在开发内存需求最优且时间复杂度具有竞争力的新算法。

Method: 第一种算法结合了Sutherland的混合算法和Leroux的超奇异曲线方法；第二种算法通过子算法高效计算超奇异$j$-不变量上的模多项式。两种算法均基于CRT和Deuring对应关系。

Result: 第一种算法时间复杂度为$\Tilde{O}(\ell^3 \log^{3} \ell + \ell \log p)$，内存最优；第二种算法首次实现$\ell$的二次复杂度，且内存最优。算法还可扩展至其他类型模多项式计算。

Conclusion: 新算法在内存效率和时间复杂度上均有突破，并提供了优化实现。相关代码模块具有更广泛的潜在应用价值。

Abstract: We present several new algorithms to evaluate modular polynomials of level
$\ell$ modulo a prime $p$ on an input $j$.
  More precisely, we introduce two new generic algorithms, sharing the
following similarities: they are based on a CRT approach; they make use of
supersingular curves and the Deuring correspondence; and, their memory
requirements are optimal.
  The first algorithm combines the ideas behind a hybrid algorithm of
Sutherland in 2013 with a recent algorithm to compute modular polynomials using
supersingular curves introduced in 2023 by Leroux. The complexity (holding
around several plausible heuristic assumptions) of the resulting algorithm
matches the $\Tilde{O}(\ell^3 \log^{3} \ell + \ell \log p)$ time complexity of
the best known algorithm by Sutherland, but has an optimal memory requirement.
  Our second algorithm is based on a sub-algorithm that can evaluate modular
polynomials efficiently on supersingular $j$-invariants defined over $\Fp$, and
achieves heuristic complexity quadratic in both $\ell$ and $\log j$, and linear
in $\log p$. In particular, it is the first generic algorithm with optimal
memory requirement to obtain a quadratic complexity in~$\ell$.
  Additionally, we show how to adapt our method to the computation of other
types of modular polynomials such as the one stemming from Weber's function.
  Finally, we provide an optimised implementation of the two algorithms
detailed in this paper, though we emphasise that various modules in our
codebase
  may find applications outside their use in this paper.

</details>


### [30] [Long strings of composite values of polynomials and a basis of order 2](https://arxiv.org/abs/2506.15641)
*Artyom Radomskii*

Main category: math.NT

TL;DR: 该论文证明了对于任何具有正首项且在$\mathbb{Q}$上不可约的多项式$f: \mathbb{Z}\to \mathbb{Z}$，当$N$足够大时，存在两个连续正整数串$I_{1}$和$I_{2}$，使得$I_{1}\cup I_{2} \subset [1, N]$，且$f(n)$在$I_{1}\cup I_{2}$上均为合数。这一结果推广了[5]中关于$f(n)=n$的结论。


<details>
  <summary>Details</summary>
Motivation: 研究多项式在连续整数区间上取值均为合数的现象，推广已有关于线性多项式的结论至更一般的多项式情形。

Method: 通过构造两个连续正整数串$I_{1}$和$I_{2}$，并利用数论方法证明在这些区间上多项式$f(n)$均为合数。

Result: 对于足够大的$N$，存在两个长度与$\log N$相关的连续整数串，使得多项式$f(n)$在这些串上的取值均为合数。

Conclusion: 该研究成功将线性多项式的合数区间结果推广至更一般的不可约多项式，扩展了数论中关于多项式取值性质的理论。

Abstract: We show that for any polynomial $f: \mathbb{Z}\to \mathbb{Z}$ with positive
leading coefficient and irreducible over $\mathbb{Q}$, if $N$ is large enough
then there are two strings of consecutive positive integers
$I_{1}=\{n_1-m,\ldots, n_1+m\}$ and $I_{2}=\{n_2-m, \ldots, n_2+m\}$, where $m
= [(\log N) (\log \log N)^{1/325525}]$, such that $I_{1}\cup I_{2} \subset [1,
N]$, $N = n_1 + n_2$, and $f(n)$ is composite for any $n\in I_{1}\cup I_{2}$.
This extends the result in [5] which showed the same result but with $f(n)=n$.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [31] [Class of extensions of real field and their topological properties](https://arxiv.org/abs/2506.14838)
*E. V. Alexandrov*

Main category: math.LO

TL;DR: 本文定义了实数域的适当扩展类，并研究了这些扩展的拓扑性质。这些扩展可以是连通的（此时集合对二元运算不封闭）或非连通的（此时构成线性有序域），未来可应用于构建能感知零测集的测度。


<details>
  <summary>Details</summary>
Motivation: 研究实数域扩展类的拓扑性质，旨在为构建新型测度理论提供数学基础，特别是针对零勒贝格测度集的感知问题。

Method: 通过定义实数域的特定扩展类，分析其连通性与代数封闭性，并考察线性有序域的结构特性。

Result: 发现连通扩展对加法乘法不封闭，非连通扩展可形成线性有序域，揭示了拓扑性质与代数结构的关联性。

Conclusion: 该扩展理论为后续构造特殊测度提供了数学工具，尤其在处理零测集敏感性问题方面具有潜在应用价值。

Abstract: Proper classes of extensions of real field was defined and topological
properties of these extensions were studied. These extensions can be connected,
in this case such set is not closed under binary operations (addition and
multiplication), and not connected, in this case this extension is linearly
ordered field. In the future these constructions can be applied to building
measure that "feels" set of zero Lebesgue measure.

</details>


### [32] [Definability of complex functions in o-minimal structures](https://arxiv.org/abs/2506.15119)
*Adele Padgett,Patrick Speissegger*

Main category: math.LO

TL;DR: 证明了$\mathbf{an}^*$和$\mathcal{G}$类函数的全纯延拓在o-极小结构$\mathbb{R}_{\mathrm{an}^*}$和$\mathbb{R}_{\mathcal{G}}$中可定义，并给出了最优复域。应用包括描述黎曼$\zeta$函数和$\Gamma$函数在相应o-极小扩张中的最优可定义域。


<details>
  <summary>Details</summary>
Motivation: 研究特定函数类在全纯延拓下的可定义性，为复分析中的函数在o-极小结构中的行为提供理论基础。

Method: 通过构造复域并证明其最优性，验证$\mathbf{an}^*$和$\mathcal{G}$类函数的全纯延拓在对应o-极小结构中的可定义性。

Result: 确定了$\mathbf{an}^*$和$\mathcal{G}$类函数全纯延拓的最优可定义复域，并应用于黎曼$\zeta$函数和$\Gamma$函数。

Conclusion: 该研究为复变函数在o-极小结构中的可定义性提供了具体实例和理论支持，扩展了相关领域的研究工具。

Abstract: We prove that some holomorphic continuations of functions in the classes
$\mathbf{an}^*$ and $\mathcal{G}$ are definable in the o-minimal structures
$\mathbb{R}_{\mathrm{an}^*}$ and $\mathbb{R}_{\mathcal{G}}$ respectively. More
specifically, we give complex domains on which the holomorphic continuations
are definable, and show they are optimal. As an application, we describe
optimal domains on which the Riemann $\zeta$ function is definable in o-minimal
expansions of $\mathbb{R}_{\mathrm{an}^*,\exp}$ and on which the $\Gamma$
function is definable in o-minimal expansions of
$\mathbb{R}_{\mathcal{G},\exp}$.

</details>


### [33] [$Σ^1_3$ sets in the Sacks model](https://arxiv.org/abs/2506.15308)
*Jonathan Schilhan*

Main category: math.LO

TL;DR: 在可构造宇宙的迭代Sacks模型中，证明了$\Sigma^1_3$集的Mansfield-Solovay定理成立，并确定了Bernstein集的最优复杂度为$\Delta^1_4$。


<details>
  <summary>Details</summary>
Motivation: 研究迭代Sacks模型中Mansfield-Solovay定理的适用范围，以及Bernstein集在投影层次中的最优复杂度问题。

Method: 基于可构造宇宙的迭代Sacks模型，结合Kanovei的结果，分析$\Sigma^1_3$集的Marczewski可测性及Bernstein集的复杂度。

Result: 证明了在迭代Sacks模型中，所有$\mathbf{\Sigma}^1_3$集都是Marczewski可测的，且Bernstein集的最优复杂度为$\Delta^1_4$。

Conclusion: 该研究扩展了Mansfield-Solovay定理在投影层次中的应用，并明确了Bernstein集的复杂度界限。

Abstract: We show that in the iterated Sacks model over the constructible universe the
Mansfield-Solovay Theorem holds for $\Sigma^1_3$ sets. In particular, every
$\mathbf{\Sigma}^1_3$ set is Marczewski measurable and the optimal complexity
for a Bernstein set is $\Delta^1_4$. Based on a result by Kanovei, we also
briefly show how to separate the Mansfield-Solovay Theorem at non-trivial
levels of the projective hierarchy.

</details>


### [34] [Strongly First Order Disjunctive Embedded Dependencies in Team Semantics](https://arxiv.org/abs/2506.15367)
*Pietro Galliani*

Main category: math.LO

TL;DR: 本文研究了团队语义中一阶逻辑的表达能力扩展问题，特别关注了与数据库理论相关的析取嵌入式依赖关系，并给出了不增加一阶团队语义表达能力的（域独立）析取嵌入式依赖的特征。


<details>
  <summary>Details</summary>
Motivation: 团队语义是一阶逻辑的扩展，允许通过新型原子描述变量间的依赖关系。这些扩展中，部分能增强表达能力，部分则不能。研究旨在识别那些不增强表达能力的析取嵌入式依赖。

Method: 作者对团队语义中的析取嵌入式依赖进行了系统分析，特别关注了与数据库理论相关的依赖类型，并探讨了这些依赖在一阶团队语义中的表达能力。

Result: 研究得出了一类（域独立）析取嵌入式依赖的特征，这些依赖在添加到一阶团队语义时不会增加其表达能力。

Conclusion: 该工作为团队语义中依赖关系的表达能力提供了新的理论见解，特别是指出了那些无法增强一阶团队语义表达能力的析取嵌入式依赖的具体特征。

Abstract: First Order Team Semantics is a generalization of Tarskian Semantics in which
formulas are satisfied with respect to sets of assignments. In Team Semantics,
it is possible to extend First Order Logic via new types of atoms that describe
dependencies between variables; some of these extensions are strictly more
expressive than First Order Logic, while others are reducible to it.
  Many of the atoms studied in Team Semantics are inspired by Database Theory
and belong in particular to the class of Disjunctive Embedded Dependencies, a
very general family of dependencies that contains most of the dependencies of
practical interest in the study of databases.
  In this work, I provide a characterization for the (domain-independent)
Disjunctive Embedded Dependencies that fail to increase the expressive power of
First-Order Team Semantics when added to it.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [35] [Hamiltonian connectivity of some base-cobase graphs](https://arxiv.org/abs/2506.15049)
*Leonardo Martínez-Sandoval,Kolja Knauer*

Main category: math.CO

TL;DR: 该论文研究了拟阵的基-对偶基图的哈密顿连通性，通过多面体方法证明了特定类拟阵的哈密顿连通性，并发现R_{10}正则拟阵给出了Farber等人问题的反例。


<details>
  <summary>Details</summary>
Motivation: 探讨拟阵基图的性质是否可推广到基-对偶基图，回应Farber、Richter和Shank在1985年提出的开放性问题。

Method: 采用多面体方法分析系列-并联扩展的格路径拟阵，并研究轮形拟阵、涡旋拟阵及正则拟阵R_{10}的特殊性质。

Result: 证明了格路径拟阵扩展类及轮形/涡旋拟阵的基-对偶基图具有哈密顿连通性，但R_{10}拟阵构成反例。

Conclusion: 基-对偶基图的哈密顿连通性仅在特定拟阵类中成立，R_{10}的存在否定了该性质的普遍性。

Abstract: There has been wide interest in understanding which properties of base graphs
of matroids extend to base-cobase graphs of matroids. A significant result of
Naddef and Pulleyblank (1984) shows that the $1$-skeleton of any
$(0,1)$-polytope is either a hypercube, or Hamiltonian-connected, i.e. there is
a Hamiltonian path connecting any two vertices. In particular, this is true for
base graphs of matroids. A natural question raised by Farber, Richter, and
Shank (1985) is whether this extends to base-cobase graphs.
  First, we use the polytopal approach to show Hamiltonian connectivity of
base-cobase graphs of series-parallel extensions of lattice path matroids. On
the other hand, we show that this method extends to only very special classes
related to identically self-dual matroids. Second, we show that base-cobase
graphs of wheels and whirls are Hamiltonian connected. Last, we show that the
regular matroid $R_{10}$ yields a negative answer to the question of Farber,
Richter, and Shank.

</details>


### [36] [Factorizations in Geometric Lattices](https://arxiv.org/abs/2506.14892)
*Alex Aguila,Elvis Cabrera,Jyrko Correa-Morris*

Main category: math.CO

TL;DR: 本文研究几何格中与有限集$X$的分区格$\Pi(X)$同构的原子分解，探讨原子性在这些格中的作用，并推导了关于红色原子集合$\mathcal{R}$的递归公式。


<details>
  <summary>Details</summary>
Motivation: 研究几何格中的原子分解，特别是与分区格$\Pi(X)$同构的格，以深化对格理论和组合数学中基本结构的理解。

Method: 首先分析函数$\mathfrak{N}\colon \Pi(X) \rightarrow \mathbb{N}$的特性，然后引入红色原子集合$\mathcal{R}$，并推导枚举特定秩分区的递归公式。

Result: 得出了关于红色原子集合$\mathcal{R}$的递归公式$\pmb{\pi}(X, j, s, \mathcal{R})$，用于计算可表示为$s$个红色原子连接的秩-$j$分区数量。

Conclusion: 通过研究几何格中的原子分解，特别是红色原子的作用，为格理论和组合数学提供了新的工具和见解。

Abstract: This article investigates atomic decompositions in geometric lattices
isomorphic to the partition lattice $\Pi(X)$ of a finite set $X$, a fundamental
structure in lattice theory and combinatorics. We explore the role of atomicity
in these lattices, building on concepts introduced by D.D. Anderson, D.F.
Anderson, and M. Zafrullah within the context of factorization theory in
commutative algebra. As part of the study, we first examine the main
characteristics of the function $\mathfrak{N}\colon \Pi(X) \rightarrow
\mathbb{N}$, which assigns to each partition $\pi$ the number of minimal atomic
decompositions of $\pi$. We then consider a distinguished subset of atoms,
$\mathcal{R}$, referred to as the set of red atoms, and derive a recursive
formula for $\pmb{\pi}(X, j, s, \mathcal{R})$, which enumerates the rank-$j$
partitions expressible as the join of exactly $s$ red atoms.

</details>


### [37] [Short monochromatic odd cycles](https://arxiv.org/abs/2506.14910)
*Oliver Janzer,Fredy Yip*

Main category: math.CO

TL;DR: 本文证明了在完全图$K_{2^k+1}$的任意$k$-边着色中，存在长度至多为$O(k^{3/2}2^{k/2})$的单色奇环，显著改进了先前的结果。


<details>
  <summary>Details</summary>
Motivation: Erd\H{o}s和Graham在1973年提出估计$L(k)$的最小值，使得任意$k$-边着色的$K_{2^k+1}$包含长度不超过$L(k)$的单色奇环。

Method: 结合代数组合学和逼近理论的工具，改进了Gir\~ao和Hunter的多项式因子改进方法。

Result: 证明了$L(k)=O(k^{3/2}2^{k/2})$，实现了指数级的改进。

Conclusion: 该研究在单色奇环长度上取得了突破性进展，为相关极值问题提供了新的理论工具。

Abstract: It is easy to see that every $k$-edge-colouring of the complete graph on
$2^k+1$ vertices contains a monochromatic odd cycle. In 1973, Erd\H{o}s and
Graham asked to estimate the smallest $L(k)$ such that every $k$-edge-colouring
of $K_{2^k+1}$ contains a monochromatic odd cycle of length at most $L(k)$.
Recently, Gir\~ao and Hunter obtained the first nontrivial upper bound by
showing that $L(k)=O(\frac{2^k}{k^{1-o(1)}})$, which improves the trivial bound
by a polynomial factor. We obtain an exponential improvement by proving that
$L(k)=O(k^{3/2}2^{k/2})$. Our proof combines tools from algebraic combinatorics
and approximation theory.

</details>


### [38] [Some remarks on Folkman graphs for triangles](https://arxiv.org/abs/2506.14942)
*Eion Mulrenin*

Main category: math.CO

TL;DR: 本文研究了基于Hermitian单位几何图的Folkman类性质，证明了对于所有素数幂$q \geq 4$，存在一个具有"准Folkman"性质的图$H_q$，其中$q=4$时对应208个顶点的图。


<details>
  <summary>Details</summary>
Motivation: Folkman定理关于$K_4$-free但任何二边着色都包含单色三角形的图的存在性，其最小顶点数$f(2,3,4)$的计算极具挑战性。本文旨在探索类似Folkman性质的几何图结构。

Method: 利用射影平面上Hermitian单位构造的有限几何图序列$H_q$，通过分析其三角形子集$\mathcal{T}_q$的性质，并研究随机破坏$K_4$后保持Ramsey性质的概率。

Result: 证明对所有素数幂$q \geq 4$，$H_q$存在三角形子集$\mathcal{T}_q$满足：1) 不包含$K_4$；2) 任何二边着色都产生$\mathcal{T}_q$中的单色三角形。$q=4$时得到208个顶点的具体构造。

Conclusion: Hermitian单位几何图提供了新的"准Folkman"图范例，其随机破坏$K_4$后仍大概率保持Ramsey性质，为相关极值问题研究开辟了新途径。

Abstract: Folkman's theorem asserts the existence of graphs $G$ which are $K_4$-free,
but which have the property that every two-coloring of $E(G)$ contains a
monochromatic triangle. The quantitative aspects of $f(2,3,4)$, the least $n$
such that there exists an $n$-vertex graph with both properties above, are
notoriously difficult; a series of improvements over the span of two decades
witnessed the solution to two \$100 Erd\H{o}s problems, and the current record
due to Lange, Radziszowski, and Xu now stands at $f(2,3,4) \leq 786$, the proof
of which is computer-assisted.
  In this paper, we study Folkman-like properties of a sequence $H_q$ of finite
geometric graphs constructed using Hermitian unitals over projective planes
which were instrumental in the recent Mattheus-Verstra\"ete breakthrough on
off-diagonal Ramsey numbers. We show that for all prime powers $q \geq 4$,
there exists a subset $\mathcal{T}_q$ of triangles in $H_q$ such that no four
span a $K_4$ in $H_q$, but every two-coloring of $E(H_q)$ induces a
monochromatic triangle in $\mathcal{T}_q$. For $q=4$, this gives a graph on
$208$ vertices with this "quasi-Folkman" property. Moreover, we show that a
certain random alteration of $H_q$ which destroys all of its $K_4$'s will, for
large $q$, maintain the Ramsey property with high probability.

</details>


### [39] [Positive $m$-divisible non-crossing partitions and their Kreweras maps](https://arxiv.org/abs/2506.14996)
*Christian Krattenthaler,Christian Stump*

Main category: math.CO

TL;DR: 本文研究了正$m$-可分非交叉划分及其正Kreweras映射，在经典类型中给出了组合实现，并证明了其与圆环/环面上的伪旋转对应。通过建立一般类型的组合模型，验证了循环筛选现象。


<details>
  <summary>Details</summary>
Motivation: 探索正$m$-可分非交叉划分的组合性质及其在正Kreweras映射下的不变性，以建立更普适的数学理论框架。

Method: 在经典类型中使用非交叉集合划分实现组合结构，通过圆环/环面伪旋转建立几何对应；对例外类型开发新的组合模型。

Result: 成功枚举了经典类型中正Kreweras映射幂次下的不变正$m$-可分非交叉划分，并建立了一般类型的统一组合模型。

Conclusion: 研究结果系统建立了正$m$-可分非交叉划分的循环筛选现象，为相关代数组合理论提供了新工具。

Abstract: We study positive $m$-divisible non-crossing partitions and their positive
Kreweras maps. In classical types, we describe their combinatorial realisations
as certain non-crossing set partitions. We also realise these positive Kreweras
maps as pseudo-rotations on a circle, respectively on an annulus. We enumerate
positive $m$-divisible non-crossing partitions in classical types that are
invariant under powers of the positive Kreweras maps with respect to several
parameters. In order to cope with the exceptional types, we develop a different
combinatorial model in general type describing positive $m$-divisible
non-crossing partitions that are invariant under powers of the positive
Kreweras maps. We finally show that altogether these results establish several
cyclic sieving phenomena.

</details>


### [40] [Matroid complexes and Orlik-Solomon algebras](https://arxiv.org/abs/2506.15048)
*Basile Coron*

Main category: math.CO

TL;DR: 本文为超可解拟阵的Orlik-Solomon代数构建了一个组合拟自由微分分次模型，推广了Kontsevich的容许图cdga结构，并证明其具有合作结构，最终用该模型新证明了超可解拟阵的Orlik-Solomon代数是Koszul代数。


<details>
  <summary>Details</summary>
Motivation: 研究旨在将Kontsevich为辫子排列引入的容许图微分分次交换代数（cdga）推广到拟阵理论框架中，特别是针对超可解拟阵的Orlik-Solomon代数，以探索其组合与代数性质。

Method: 利用拟阵理论中的模性、单元素扩张和广义平行连接等概念，构建了组合拟自由微分分次模型，并证明该模型在广义意义上具有合作结构。

Result: 成功构造了超可解拟阵Orlik-Solomon代数的微分分次模型，并验证其合作结构，进而应用该模型给出了超可解拟阵Orlik-Solomon代数为Koszul代数的新证明。

Conclusion: 通过拟阵理论与微分分次代数的结合，不仅扩展了Kontsevich的容许图cdga框架，还为超可解拟阵的代数性质提供了新的研究工具与证明路径。

Abstract: In this article we construct a combinatorial quasi-free differential graded
model for the Orlik-Solomon algebra of supersolvable matroids, which
generalizes in a matroidal setting the cdga of admissible graphs introduced by
M. Kontsevich for the braid arrangements. Our construction draws on well-known
concepts from matroid theory, including modularity, single-element extensions,
and generalized parallel connections. We also show that this model carries a
cooperadic structure in a suitably generalized sense. As an application, we use
this model to give a new proof that the Orlik-Solomon algebras of supersolvable
matroids are Koszul.

</details>


### [41] [Higher diameters of Cayley digraphs](https://arxiv.org/abs/2506.15137)
*G. C. Magda,J. Rubin,S. Streipert,C. Watt,A. Kumar,G. P. Constantine*

Main category: math.CO

TL;DR: 本文定义并研究了凯莱有向图的高阶直径。


<details>
  <summary>Details</summary>
Motivation: 研究凯莱有向图的高阶直径，以扩展对图论中直径概念的理解。

Method: 通过定义凯莱有向图的高阶直径，并进行理论分析。

Result: 提出了凯莱有向图高阶直径的概念，并探讨了其性质。

Conclusion: 该研究为凯莱有向图的高阶直径提供了理论基础，有助于进一步探索图论中的相关性质。

Abstract: Higher diameters of Cayley digraphs are defined and studied.

</details>


### [42] [Antimagic labelings of a complete graph](https://arxiv.org/abs/2506.15221)
*Dr A. N. Bhavale*

Main category: math.CO

TL;DR: 本文证明了完全图$K_n$（$n \geq 3$）具有超反魔幻和全反魔幻性质，并存在反魔幻定向。


<details>
  <summary>Details</summary>
Motivation: 受Hartsfield和Ringel的反魔幻图猜想及Hefetz等人的问题启发，研究完全图的反魔幻性质及其定向问题。

Method: 利用Bhavale提出的边标记方法，对完全图$K_n$进行标记分析。

Result: 证明了$K_n$（$n \geq 3$）既是超反魔幻图也是全反魔幻图，并存在反魔幻定向。

Conclusion: 完全图$K_n$（$n \geq 3$）满足多种反魔幻性质，扩展了反魔幻图理论的研究成果。

Abstract: In $1990$, Hartsfield and Ringel introduced antimagic graphs. Hartsfield and
Ringel conjectured that every connected graph (and in particular, a tree)
except $K_2$ is antimagic. In $2010$, Hefetz et al.\ raised two questions: Is
every orientation of any simple connected undirected graph antimagic? and Given
any undirected graph $G$, does there exist an orientation of $G$ which is
antimagic? They call such an orientation an {\it antimagic orientation} of $G$.
Recently, Bhavale provided an edge labeling for a given graph on $n$ vertices
without isolated vertices. In this paper, using the labeling of Bhavale, we
prove that a complete graph $K_n$ for $n \geq 3$ is super antimagic as well as
totally antimagic total graph. We also prove that there exists an antimagic
orientation of $K_n$ for $n \geq 3$.

</details>


### [43] [Structured and Punctured Nullstellensätze](https://arxiv.org/abs/2506.15281)
*Erhard Aichinger,John R. Schmitt,Henry Zhan*

Main category: math.CO

TL;DR: 本文对组合Nullstellensatz定理进行了多方向推广，特别是统一了Schauz和Nica的结果，并通过多元多项式除法中的特定单项式不变性，进一步将Alon和F\"uredi的非零计数定理推广至穿孔网格。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于对Hilbert和Alon的Nullstellensatz定理的深入探索，旨在扩展多项式方法在组合学中的应用，特别是针对具有对称性的网格和穿孔网格。

Method: 方法上，作者通过分析多元多项式除法过程中特定单项式的行为，建立了一般性理论框架，从而能够统一处理不同学者的推广结果。

Result: 主要成果包括：1) 给出了Schauz和Nica结果的共同推广；2) 将Alon-F\"uredi非零计数定理扩展至穿孔网格$X \setminus Y$。

Conclusion: 该研究不仅深化了对多项式消去理论的理解，还为组合数学中的多项式方法提供了更强大的工具，特别是在处理对称网格和穿孔网格问题时展现出优越性。

Abstract: A Nullstellensatz is a theorem providing information on polynomials that
vanish on a certain set: David Hilbert's Nullstellensatz (1893) is a
cornerstone of algebraic geometry, and Noga Alon's Combinatorial
Nullstellensatz (1999) is a powerful tool in the "Polynomial Method", a
technique used in combinatorics. Alon's Theorem excludes that a polynomial
vanishing on a grid contains a monomial with certain properties. This theorem
has been generalized in several directions, two of which we will consider in
detail: Terence Tao and Van H. Vu (2006), Uwe Schauz (2008) and Micha\l{}
Laso\'n (2010) exclude more monomials, and recently, Bogdan Nica (2023)
improved the result for grids with additional symmetries in their side edges.
Simeon Ball and Oriol Serra (2009) incorporated the multiplicity of zeros and
gave Nullstellens\"atze for punctured grids, which are sets of the form $X
\setminus Y$ with both $X,Y$ grids.
  We generalize some of these results; in particular, we provide a common
generalization to the results of Schauz and Nica. To this end, we establish
that during multivariate polynomial division, certain monomials are unaffected.
This also allows us to generalize Pete L. Clark's proof of the nonzero counting
theorem by Alon and F\"uredi to punctured grids.

</details>


### [44] [Posets for Specht ideals of essential real reflection groups](https://arxiv.org/abs/2506.15335)
*Sebastian Debus,Kurt Klement Gottwald*

Main category: math.CO

TL;DR: 本文扩展了Specht理想理论至D型反射群和二面体群，完成了所有无限族本质实反射群的组合研究。


<details>
  <summary>Details</summary>
Motivation: Specht理想作为由群表示相关的Specht多项式生成的多项式环对称理想，此前仅在A型和B型反射群中被研究。为全面理解其组合结构，需扩展至其他反射群类型。

Method: 通过将Specht理想理论推广到D型反射群和二面体群，分析其包含关系及簇结构。

Result: 研究揭示了D型和二面体群中Specht理想的组合性质，填补了无限族本质实反射群研究的空白。

Conclusion: 该工作完善了所有无限族本质实反射群的Specht理想组合理论，为相关数学领域提供了完整框架。

Abstract: Specht ideals are symmetric ideals in the polynomial ring generated by Specht
polynomials associated with group representations. These ideals were previously
studied for reflection groups of types $A$ and $B$, where their inclusion
relations and their varieties reflect rich combinatorial structures. In this
paper, we extend this theory to type $D$ and the dihedral groups. Our results
complete the combinatorial study of Specht ideals across all infinite families
of essential real reflection groups.

</details>


### [45] [Inverse eigenvalue problem for discrete Schrödinger operators of a graph](https://arxiv.org/abs/2506.15430)
*Anzila Laikhuram,Jephian C. -H. Lin*

Main category: math.CO

TL;DR: 该论文研究了图的离散薛定谔算子的逆特征值问题，通过图结构的强性质，建立了超图引理、解放引理和分岔引理的类似版本，并解决了最多5个顶点的图的逆特征值问题。


<details>
  <summary>Details</summary>
Motivation: 离散薛定谔算子用于研究振动理论和Colin de Verdière参数，其逆特征值问题旨在刻画图的离散薛定谔算子的可能谱。

Method: 利用图结构的强性质，建立了超图引理、解放引理和分岔引理的类似版本，并应用于解决逆特征值问题。

Result: 解决了最多5个顶点的图的离散薛定谔算子的逆特征值问题，并给出了基于图结构的若干限制。

Conclusion: 通过强性质和建立的引理，成功解决了小规模图的离散薛定谔算子的逆特征值问题，为更大规模图的研究奠定了基础。

Abstract: A discrete Schr\"odinger operator of a graph $G$ is a real symmetric matrix
whose $i,j$-entry, $i \neq j$, is negative if $\{i,j\}$ is an edge and zero if
it is not an edge, while diagonal entries can be any real numbers. The discrete
Schr\"odinger operators have been used to study vibration theory and the Colin
de Verdi\`ere parameter. The inverse eigenvalue problem for discrete
Schr\"odinger operators of a graph aims to characterize the possible spectra
among discrete Schr\"odinger operators of a graph. Comparing to the inverse
eigenvalue problem of a graph, the answers turn out to be more limited, and
several restrictions based on graph structure are given. Using the strong
properties, analogous versions of the supergraph lemma, the liberation lemma,
and the bifurcation lemma are established. Using these results, the inverse
eigenvalue problem for discrete Schr\"odinger operators is resolved for each
graph with at most $5$ vertices.

</details>


### [46] [Is it easy to regularize a hypergraph with easy links?](https://arxiv.org/abs/2506.15582)
*Lior Gishboliner,Asaf Shapira,Yuval Wigderson*

Main category: math.CO

TL;DR: 本文研究了超图的$\varepsilon$-同质划分问题，推翻了Terry的猜想，证明了3-图存在最佳可能的单指数界同质划分，并推广到所有$k\geq 3$的k-图。同时发现顶点链接具有多项式大小$\varepsilon$-正则划分时，3-图仍可能仅具有塔型大小的正则划分。


<details>
  <summary>Details</summary>
Motivation: 研究超图在何种条件下存在小的$\varepsilon$-同质或正则划分，这一问题在图中已有较好理解，但对3-图及以上情况更为复杂。本文旨在探索顶点链接具有小同质划分时，整个超图是否也存在小同质划分。

Method: 通过分析3-图顶点链接的$\varepsilon$-同质划分性质，构建反例推翻原有猜想，并采用组合数学方法证明改进的单指数界。进一步推广到k-图，并研究顶点链接具有多项式大小正则划分时的全局性质。

Result: 1) 推翻了Terry关于双指数界紧性的猜想，给出最佳可能的单指数界同质划分；2) 将结果推广到所有$k\geq 3$的k-图；3) 证明即使顶点链接具有多项式大小$\varepsilon$-正则划分，3-图仍可能仅具有塔型大小的正则划分。

Conclusion: 本文彻底解决了3-图同质划分的界问题，并揭示了局部正则性不能保证全局正则性的反直觉现象，为超图正则性理论提供了重要突破。

Abstract: A partition of a (hyper)graph is $\varepsilon$-homogenous if the edge
densities between almost all clusters are either at most $\varepsilon$ or at
least $1-\varepsilon$. Suppose a $3$-graph has the property that the link of
every vertex has an $\varepsilon$-homogenous partition of size
$\text{poly}(1/\varepsilon)$. Does this guarantee that the $3$-graph also has a
small homogenous partition? Terry and Wolf proved that such a $3$-graph has an
$\varepsilon$-homogenous partition of size given by a wowzer-type function.
Terry recently improved this to a double exponential bound, and conjectured
that this bound is tight. Our first result in this paper disproves this
conjecture by giving an improved (single) exponential bound, which is best
possible. We further obtain an analogous result for $k$-graphs of all
uniformities $k \geq 3$.
  The above problem is part of a much broader programme which seeks to
understand the conditions under which a (hyper)graph has small
$\varepsilon$-regular partitions. While this problem is fairly well understood
for graphs, the situation is (as always) much more involved already for
$3$-graphs. For example, it is natural to ask if one can strengthen our first
result by only requiring each link to have $\varepsilon$-regular partitions of
size $\text{poly}(1/\varepsilon)$. Our second result shows that surprisingly
the answer is `no', namely, a $3$-graph might only have regular partitions of
tower-type size, even though the link of every vertex has an
$\varepsilon$-regular partition of polynomial size.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [47] [Winter Soldier: Backdooring Language Models at Pre-Training with Indirect Data Poisoning](https://arxiv.org/abs/2506.14913)
*Wassim Bouaziz,Mathurin Videau,Nicolas Usunier,El-Mahdi El-Mhamdi*

Main category: cs.CR

TL;DR: 研究提出了一种间接数据投毒方法，通过梯度优化提示调校使语言模型学习训练数据中不存在的秘密序列，实现数据集保护和使用追踪，且不影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据追踪方法依赖训练数据记忆，而语言模型提供者试图限制这种记忆。本研究探索不依赖记忆的间接数据投毒方法，以更隐蔽地保护数据集。

Method: 采用基于梯度优化的提示调校技术，使模型学习训练语料中不存在的秘密提示-响应对，投毒比例仅需0.005%的标记。

Result: 实验证明该方法能极高置信度检测秘密序列（$p < 10^{-55}$），且不影响语言模型基准性能，秘密从未出现在训练集中。

Conclusion: 间接数据投毒是可行且高效的数据集保护方案，可理论认证地追踪模型数据使用，为数据版权保护提供了新思路。

Abstract: The pre-training of large language models (LLMs) relies on massive text
datasets sourced from diverse and difficult-to-curate origins. Although
membership inference attacks and hidden canaries have been explored to trace
data usage, such methods rely on memorization of training data, which LM
providers try to limit. In this work, we demonstrate that indirect data
poisoning (where the targeted behavior is absent from training data) is not
only feasible but also allow to effectively protect a dataset and trace its
use. Using gradient-based optimization prompt-tuning, we make a model learn
arbitrary secret sequences: secret responses to secret prompts that are absent
from the training corpus. We validate our approach on language models
pre-trained from scratch and show that less than 0.005% of poisoned tokens are
sufficient to covertly make a LM learn a secret and detect it with extremely
high confidence ($p < 10^{-55}$) with a theoretically certifiable scheme.
Crucially, this occurs without performance degradation (on LM benchmarks) and
despite secrets never appearing in the training set.

</details>


### [48] [Fair Data Exchange with Constant-Time Proofs](https://arxiv.org/abs/2506.14944)
*Majid Khabbazian*

Main category: cs.CR

TL;DR: 本文提出了一种改进的公平数据交换协议，通过将文件视为Reed-Solomon编码字并扩展为低速率编码，实现了证明和验证时间的常数级开销，同时保持了完全的公平性。


<details>
  <summary>Details</summary>
Motivation: 现有的公平数据交换协议虽然在CCS 2024中提出了原子按文件付费的传输方案，但其证明和验证时间仍与文件长度线性相关，需要进一步优化。

Method: 通过将文件视为速率1的Reed-Solomon编码字，扩展为低速率编码并加密，仅对少量随机密文子集进行正确性证明，利用RS解码修复损坏符号。

Result: 改进后的协议将证明和验证开销降至常数级，保持了客户端和服务器的完全公平性，仅增加了可调的通信冗余开销。

Conclusion: 该协议通过优化编码和证明机制显著提升了效率，并在比特币实例中修复了椭圆曲线不匹配问题，支持链下运行和仅需两笔链上交易的备用方案。

Abstract: The Fair Data Exchange (FDE) protocol introduced at CCS 2024 offers atomic
pay-per-file transfers with constant-size proofs, but its prover and verifier
runtimes still scale linearly with the file length n. We collapse these costs
to essentially constant by viewing the file as a rate-1 Reed-Solomon (RS)
codeword, extending it to a lower-rate RS code with constant redundancy,
encrypting this extended vector, and then proving correctness for only a small
random subset of the resulting ciphertexts; RS decoding repairs any corrupted
symbols with negligible failure probability. Our protocol preserves full
client- and server-fairness, and adds only a tunable communication redundancy
overhead.
  Finally, we patch the elliptic-curve mismatch in the Bitcoin instantiation of
FDE with a compact zk-SNARK, enabling the entire exchange to run off-chain and
falling back to just two on-chain transactions when channels are unavailable.

</details>


### [49] [Narrowing the Gap between TEEs Threat Model and Deployment Strategies](https://arxiv.org/abs/2506.14964)
*Filip Rezabek,Jonathan Passerat-Palmbach,Moe Mahhouk,Frieder Erdmann,Andrew Miller*

Main category: cs.CR

TL;DR: 机密虚拟机(CVMs)虽提供数据使用隔离，但缺乏物理层面防护与侧信道攻击防御，需依赖可信云提供商。当前TEE认证未绑定运营商信息，导致用户无法评估物理攻击风险。论文提出通过PPID等方案扩展认证机制以解决这一关键限制。


<details>
  <summary>Details</summary>
Motivation: 现有CVMs的威胁模型未涵盖物理攻击防护，且TEE认证未包含运营商信息，用户无法验证TEE是否运行在可信基础设施内，导致终端用户无法获得端到端安全保障。

Method: 提出利用受保护平台标识符(PPID)等方案将CVM与云服务商绑定，并探讨TEE认证机制的强化与扩展方案。

Result: 分析表明不同TEE厂商、认证流程及提供商的实现差异，使得认证验证、迁移便捷性和去信任化应用构建面临挑战，凸显CVMs推广前必须解决的关键限制。

Conclusion: 需扩展TEE认证机制以包含运营商绑定信息，通过PPID等方案增强CVMs的物理攻击防护能力，这是实现CVMs广泛采用的重要前提。

Abstract: Confidential Virtual Machines (CVMs) provide isolation guarantees for data in
use, but their threat model does not include physical level protection and
side-channel attacks. Therefore, current deployments rely on trusted cloud
providers to host the CVMs' underlying infrastructure. However, TEE
attestations do not provide information about the operator hosting a CVM.
Without knowing whether a Trusted Execution Environment (TEE) runs within a
provider's infrastructure, a user cannot accurately assess the risks of
physical attacks. We observe a misalignment in the threat model where the
workloads are protected against other tenants but do not offer end-to-end
security assurances to external users without relying on cloud providers. The
attestation should be extended to bind the CVM with the provider. A possible
solution can rely on the Protected Platform Identifier (PPID), a unique CPU
identifier. However, the implementation details of various TEE manufacturers,
attestation flows, and providers vary. This makes verification of attestations,
ease of migration, and building applications without relying on a trusted party
challenging, highlighting a key limitation that must be addressed for the
adoption of CVMs. We discuss two points focusing on hardening and extensions of
TEEs' attestation.

</details>


### [50] [Private Continual Counting of Unbounded Streams](https://arxiv.org/abs/2506.15018)
*Ben Jacobsen,Kassem Fawaz*

Main category: cs.CR

TL;DR: 本文提出了一种新颖的差分隐私连续计数算法，适用于输入规模未知的无界场景，通过引入基于对数扰动的矩阵分解方法，实现了平滑误差和高效的空间时间复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有基于矩阵机制的最优算法需要预先知道输入规模$n$，而常见的'倍增技巧'会导致次优且非平滑的误差。如何在无界设置下实现差分隐私连续计数成为研究动机。

Method: 通过创新性地引入基于函数$\frac{1}{\sqrt{1-z}}$对数扰动的矩阵分解方法，该方法可能具有独立研究价值。算法在每轮仅需$O(t)$空间和分摊$O(\log t)$时间。

Result: 对于任意$\alpha > 0$和$t\leq n$，算法能以$O(\log^{2+2\alpha}(t))$方差私有估计前$t$个数据点的和。实证显示在$t$高达$2^{24}$时，方差仍低于Henzinger等算法的1.5倍。

Conclusion: 该研究提出了首个适用于无界设置的差分隐私连续计数算法，在误差平滑性、空间和时间效率方面均显著优于现有方案，且实证性能接近已知最优有界输入算法。

Abstract: We study the problem of differentially private continual counting in the
unbounded setting where the input size $n$ is not known in advance. Current
state-of-the-art algorithms based on optimal instantiations of the matrix
mechanism cannot be directly applied here because their privacy guarantees only
hold when key parameters are tuned to $n$. Using the common `doubling trick'
avoids knowledge of $n$ but leads to suboptimal and non-smooth error. We solve
this problem by introducing novel matrix factorizations based on logarithmic
perturbations of the function $\frac{1}{\sqrt{1-z}}$ studied in prior works,
which may be of independent interest. The resulting algorithm has smooth error,
and for any $\alpha > 0$ and $t\leq n$ it is able to privately estimate the sum
of the first $t$ data points with $O(\log^{2+2\alpha}(t))$ variance. It
requires $O(t)$ space and amortized $O(\log t)$ time per round, compared to
$O(\log(n)\log(t))$ variance, $O(n)$ space and $O(n \log n)$ pre-processing
time for the nearly-optimal bounded-input algorithm of Henzinger et al. (SODA
2023). Empirically, we find that our algorithm's performance is also comparable
to theirs in absolute terms: our variance is less than $1.5\times$ theirs for
$t$ as large as $2^{24}$.

</details>


### [51] [Systems-Theoretic and Data-Driven Security Analysis in ML-enabled Medical Devices](https://arxiv.org/abs/2506.15028)
*Gargi Mitra,Mohammadreza Hallajiyan,Inji Kim,Athish Pranav Dharmalingam,Mohammed Elnawawy,Shahrear Iqbal,Karthik Pattabiraman,Homa Alemzadeh*

Main category: cs.CR

TL;DR: AI/ML在医疗设备中的集成虽提升了诊疗能力，但也带来了严重的网络安全风险。本文强调在上市前阶段解决这些挑战的紧迫性，并提出了一套工具帮助安全分析师进行风险评估，以确保患者安全。


<details>
  <summary>Details</summary>
Motivation: AI/ML医疗设备的复杂性和互联性使其面临广泛的网络攻击面，可能导致模型误预测，对患者安全构成重大威胁，因此需在设计阶段就确保其安全性。

Method: 通过分析公开的设备召回、不良事件和已知漏洞数据，了解AI/ML医疗设备的威胁态势及其对患者安全的影响，并设计了一套工具帮助进行上市前风险评估。

Result: 提出了一套工具和技术，帮助安全分析师全面评估AI/ML医疗设备的网络安全风险，使制造商能够将网络安全作为核心设计原则。

Conclusion: 在AI/ML医疗设备的设计阶段嵌入网络安全原则至关重要，本文的工具和方法有助于提升设备安全性，保障患者安全。

Abstract: The integration of AI/ML into medical devices is rapidly transforming
healthcare by enhancing diagnostic and treatment facilities. However, this
advancement also introduces serious cybersecurity risks due to the use of
complex and often opaque models, extensive interconnectivity, interoperability
with third-party peripheral devices, Internet connectivity, and vulnerabilities
in the underlying technologies. These factors contribute to a broad attack
surface and make threat prevention, detection, and mitigation challenging.
Given the highly safety-critical nature of these devices, a cyberattack on
these devices can cause the ML models to mispredict, thereby posing significant
safety risks to patients. Therefore, ensuring the security of these devices
from the time of design is essential. This paper underscores the urgency of
addressing the cybersecurity challenges in ML-enabled medical devices at the
pre-market phase. We begin by analyzing publicly available data on device
recalls and adverse events, and known vulnerabilities, to understand the threat
landscape of AI/ML-enabled medical devices and their repercussions on patient
safety. Building on this analysis, we introduce a suite of tools and techniques
designed by us to assist security analysts in conducting comprehensive
premarket risk assessments. Our work aims to empower manufacturers to embed
cybersecurity as a core design principle in AI/ML-enabled medical devices,
thereby making them safe for patients.

</details>


### [52] [MECHA: Multithreaded and Efficient Cryptographic Hardware Access](https://arxiv.org/abs/2506.15034)
*Pratama Derry,Laksmono Agus Mahardika Ari,Iqbal Muhammad,Howon Kim*

Main category: cs.CR

TL;DR: 本文提出了一种多线程高效加密硬件访问(MECHA)架构，通过UNIX域套接字消除上下文切换需求，显著提升并发加密请求处理速度。


<details>
  <summary>Details</summary>
Motivation: 传统加密接口设计存在上下文切换开销，无法高效处理多应用并发请求，亟需一种更高效的解决方案。

Method: 采用Server线程、Client线程、Transceiver线程及收发队列结构，基于UNIX域套接字实现多请求并行处理，兼容各类通信协议。

Result: 实验表明MECHA架构使并发加密请求速度提升83%，显著优于传统接口设计。

Conclusion: 该架构在云计算至物联网等安全通信领域具有重大应用潜力，为并发加密操作提供了高效解决方案。

Abstract: This paper presents a multithread and efficient cryptographic hardware access
(MECHA) for efficient and fast cryptographic operations that eliminates the
need for context switching. Utilizing a UNIX domain socket, MECHA manages
multiple requests from multiple applications simultaneously, resulting in
faster processing and improved efficiency. We comprise several key components,
including the Server thread, Client thread, Transceiver thread, and a pair of
Sender and Receiver queues. MECHA design is portable and can be used with any
communication protocol, with experimental results demonstrating a 83% increase
in the speed of concurrent cryptographic requests compared to conventional
interface design. MECHA architecture has significant potential in the field of
secure communication applications ranging from cloud computing to the IoT,
offering a faster and more efficient solution for managing multiple
cryptographic operation requests concurrently.

</details>


### [53] [Advanced Prediction of Hypersonic Missile Trajectories with CNN-LSTM-GRU Architectures](https://arxiv.org/abs/2506.15043)
*Amir Hossein Baradaran*

Main category: cs.CR

TL;DR: 本文提出了一种结合CNN、LSTM和GRU的混合深度学习模型，用于高精度预测高超音速导弹的复杂轨迹，显著提升了防御系统的预测能力。


<details>
  <summary>Details</summary>
Motivation: 高超音速导弹因其极速和高机动性对国家安全构成重大威胁，准确预测其轨迹是实施有效拦截的关键。

Method: 采用卷积神经网络（CNN）、长短期记忆网络（LSTM）和门控循环单元（GRU）的混合深度学习架构，整合各模型的优势以捕捉轨迹的动态特征。

Result: 所提方法能够高精度预测高超音速导弹的复杂轨迹，为防御策略和拦截技术提供了重要支持。

Conclusion: 研究表明，先进的机器学习技术可显著增强防御系统的预测能力，为应对高超音速导弹威胁提供了有效解决方案。

Abstract: Advancements in the defense industry are paramount for ensuring the safety
and security of nations, providing robust protection against emerging threats.
Among these threats, hypersonic missiles pose a significant challenge due to
their extreme speeds and maneuverability, making accurate trajectory prediction
a critical necessity for effective countermeasures. This paper addresses this
challenge by employing a novel hybrid deep learning approach, integrating
Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM) networks,
and Gated Recurrent Units (GRUs). By leveraging the strengths of these
architectures, the proposed method successfully predicts the complex
trajectories of hypersonic missiles with high accuracy, offering a significant
contribution to defense strategies and missile interception technologies. This
research demonstrates the potential of advanced machine learning techniques in
enhancing the predictive capabilities of defense systems.

</details>


### [54] [Toward a Lightweight, Scalable, and Parallel Secure Encryption Engine](https://arxiv.org/abs/2506.15070)
*Rasha Karakchi,Rye Stahle-Smith,Nishant Chinnasami,Tiffany Yu*

Main category: cs.CR

TL;DR: 本文提出SPiME，一种轻量级、可扩展且兼容FPGA的安全内存处理器加密架构，将AES-128直接集成到内存处理框架中，显著提升边缘计算中的加密效率。


<details>
  <summary>Details</summary>
Motivation: 物联网（IoT）应用的指数增长加剧了对高效、高吞吐量和节能的边缘数据处理的迫切需求。传统以CPU为中心的加密方法存在性能瓶颈和过多的数据传输问题，特别是在对延迟敏感和资源受限的环境中。

Method: SPiME架构采用模块化的并行内存处理单元阵列，每个单元将AES核心与最小控制单元结合，实现分布式就地加密，并通过Verilog实现并在AMD UltraScale和UltraScale+ FPGA上进行测试。

Result: 评估结果表明，SPiME可扩展至超过4000个并行单元，同时在高性能设备上保持关键FPGA资源利用率低于5%，持续加密吞吐量超过25 Gbps，且具有可预测的低延迟性能。

Conclusion: SPiME设计具有可移植性、可配置性和资源高效性，是安全边缘计算、嵌入式加密系统和可定制硬件加速器的理想解决方案。

Abstract: The exponential growth of Internet of Things (IoT) applications has
intensified the demand for efficient, high-throughput, and energy-efficient
data processing at the edge. Conventional CPU-centric encryption methods suffer
from performance bottlenecks and excessive data movement, especially in
latency-sensitive and resource-constrained environments. In this paper, we
present SPiME, a lightweight, scalable, and FPGA-compatible Secure
Processor-in-Memory Encryption architecture that integrates the Advanced
Encryption Standard (AES-128) directly into a Processing-in-Memory (PiM)
framework. SPiME is designed as a modular array of parallel PiM units, each
combining an AES core with a minimal control unit to enable distributed
in-place encryption with minimal overhead. The architecture is fully
implemented in Verilog and tested on multiple AMD UltraScale and UltraScale+
FPGAs. Evaluation results show that SPiME can scale beyond 4,000 parallel units
while maintaining less than 5\% utilization of key FPGA resources on high-end
devices. It delivers over 25~Gbps in sustained encryption throughput with
predictable, low-latency performance. The design's portability,
configurability, and resource efficiency make it a compelling solution for
secure edge computing, embedded cryptographic systems, and customizable
hardware accelerators.

</details>


### [55] [CWGAN-GP Augmented CAE for Jamming Detection in 5G-NR in Non-IID Datasets](https://arxiv.org/abs/2506.15075)
*Samhita Kuili,Mohammadreza Amini,Burak Kantarci*

Main category: cs.CR

TL;DR: 本文提出了一种基于卷积自编码器(CAE)的5G-NR无线网络干扰检测方法，通过生成对抗网络增强数据平衡性，在复杂异构数据集上实现了优于基准模型的检测性能。


<details>
  <summary>Details</summary>
Motivation: 5G-NR网络中空中干扰攻击普遍存在，会严重影响接收信号质量。现有方法在异构I/Q数据集、同步信号块(SSB)特征提取及数据不平衡场景下的检测效果有待提升。

Method: 采用加性高斯白噪声(AWGN)模拟干扰环境，利用卷积自编码器(CAE)进行干扰检测。针对数据不平衡问题，使用Conv1D条件Wasserstein生成对抗网络梯度惩罚(CWGAN-GP)增强数据。并与去噪自编码器(CDAE)和稀疏自编码器(CSAE)进行对比。

Result: CAE模型在增强数据集上表现出色，平均精确率97.33%、召回率91.33%、F1分数94.08%、准确率94.35%，显著优于CDAE和CSAE基准模型。

Conclusion: 研究表明CAE模型能有效应对5G-NR网络中的复杂干扰场景，在异构数据条件下保持稳健的检测性能，为无线网络安全提供了可靠解决方案。

Abstract: In the ever-expanding domain of 5G-NR wireless cellular networks,
over-the-air jamming attacks are prevalent as security attacks, compromising
the quality of the received signal. We simulate a jamming environment by
incorporating additive white Gaussian noise (AWGN) into the real-world In-phase
and Quadrature (I/Q) OFDM datasets. A Convolutional Autoencoder (CAE) is
exploited to implement a jamming detection over various characteristics such as
heterogenous I/Q datasets; extracting relevant information on Synchronization
Signal Blocks (SSBs), and fewer SSB observations with notable class imbalance.
Given the characteristics of datasets, balanced datasets are acquired by
employing a Conv1D conditional Wasserstein Generative Adversarial
Network-Gradient Penalty(CWGAN-GP) on both majority and minority SSB
observations. Additionally, we compare the performance and detection ability of
the proposed CAE model on augmented datasets with benchmark models:
Convolutional Denoising Autoencoder (CDAE) and Convolutional Sparse Autoencoder
(CSAE). Despite the complexity of data heterogeneity involved across all
datasets, CAE depicts the robustness in detection performance of jammed signal
by achieving average values of 97.33% precision, 91.33% recall, 94.08%
F1-score, and 94.35% accuracy over CDAE and CSAE.

</details>


### [56] [Flexible Hardware-Enabled Guarantees for AI Compute](https://arxiv.org/abs/2506.15093)
*James Petrie,Onni Aarne,Nora Ammann,David Dalrymple*

Main category: cs.CR

TL;DR: 本文提出了一种名为flexHEGs的硬件保障系统，旨在通过开源、可更新的验证能力解决AI发展中的国际安全与治理挑战。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统日益强大，其对国际安全的威胁加剧，现有治理方法难以在不泄露敏感信息或危害国家安全的前提下有效协调。

Method: flexHEGs系统由可审计的保障处理器和提供物理防篡改的安全外壳组成，支持隐私保护的模型评估、受控部署、训练计算限制及自动安全协议执行。

Result: flexHEGs为前沿AI开发中的监管与国际安全挑战提供了一种技术解决方案，尽管实施仍面临技术难题。

Conclusion: 尽管技术挑战存在，flexHEGs代表了一种有前景的途径，以应对AI发展中的新兴治理与安全需求。

Abstract: As artificial intelligence systems become increasingly powerful, they pose
growing risks to international security, creating urgent coordination
challenges that current governance approaches struggle to address without
compromising sensitive information or national security. We propose flexible
hardware-enabled guarantees (flexHEGs), that could be integrated with AI
accelerators to enable trustworthy, privacy-preserving verification and
enforcement of claims about AI development. FlexHEGs consist of an auditable
guarantee processor that monitors accelerator usage and a secure enclosure
providing physical tamper protection. The system would be fully open source
with flexible, updateable verification capabilities. FlexHEGs could enable
diverse governance mechanisms including privacy-preserving model evaluations,
controlled deployment, compute limits for training, and automated safety
protocol enforcement. In this first part of a three part series, we provide a
comprehensive introduction of the flexHEG system, including an overview of the
governance and security capabilities it offers, its potential development and
adoption paths, and the remaining challenges and limitations it faces. While
technically challenging, flexHEGs offer an approach to address emerging
regulatory and international security challenges in frontier AI development.

</details>


### [57] [International Security Applications of Flexible Hardware-Enabled Guarantees](https://arxiv.org/abs/2506.15100)
*Onni Aarne,James Petrie*

Main category: cs.CR

TL;DR: 本文探讨了灵活硬件保障技术（flexHEGs）如何通过标准化设计、生态系统防御和明确操作参数，为国际可信AI治理提供技术基础，以应对恶意使用、失控风险、军事AI系统及战略稳定等安全挑战。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术快速发展，flexHEGs为解决国际安全挑战提供了新途径，需建立全面治理框架来应对AI相关芯片的潜在风险。

Method: 研究分析了两种治理模型：基于验证的协议（透明合规监控）和基于规则集的协议（通过加密签名更新自动执行国际规则），并通过博弈论验证其稳定性。

Result: 研究表明，在合理假设国家偏好和灾难性风险的前提下，全面的flexHEG协议可保持稳定，但需解决技术门槛、现有硬件管理及治理权力滥用等挑战。

Conclusion: 尽管需要大规模国际协调，flexHEGs可为管理AI风险提供技术基础，以应对国际安全与稳定面临的新兴威胁。

Abstract: As AI capabilities advance rapidly, flexible hardware-enabled guarantees
(flexHEGs) offer opportunities to address international security challenges
through comprehensive governance frameworks. This report examines how flexHEGs
could enable internationally trustworthy AI governance by establishing
standardized designs, robust ecosystem defenses, and clear operational
parameters for AI-relevant chips. We analyze four critical international
security applications: limiting proliferation to address malicious use,
implementing safety norms to prevent loss of control, managing risks from
military AI systems, and supporting strategic stability through
balance-of-power mechanisms while respecting national sovereignty. The report
explores both targeted deployments for specific high-risk facilities and
comprehensive deployments covering all AI-relevant compute. We examine two
primary governance models: verification-based agreements that enable
transparent compliance monitoring, and ruleset-based agreements that
automatically enforce international rules through cryptographically-signed
updates. Through game-theoretic analysis, we demonstrate that comprehensive
flexHEG agreements could remain stable under reasonable assumptions about state
preferences and catastrophic risks. The report addresses critical
implementation challenges including technical thresholds for AI-relevant chips,
management of existing non-flexHEG hardware, and safeguards against abuse of
governance power. While requiring significant international coordination,
flexHEGs could provide a technical foundation for managing AI risks at the
scale and speed necessary to address emerging threats to international security
and stability.

</details>


### [58] [EVA-S2PMLP: Secure and Scalable Two-Party MLP via Spatial Transformation](https://arxiv.org/abs/2506.15102)
*Shizhao Peng,Shoumo Li,Tianle Tao*

Main category: cs.CR

TL;DR: 本文提出EVA-S2PMLP框架，一种高效、可验证且精确的安全两方多层感知器方案，通过空间尺度优化提升隐私保护与性能，在垂直分区场景下实现隐私保护的神经网络训练。


<details>
  <summary>Details</summary>
Motivation: 垂直分区场景下的隐私保护神经网络训练对跨机构安全协作建模至关重要，需解决实数域可靠计算与数据保密性问题。

Method: 提出安全转换管道将标量输入映射至向量/矩阵空间，包含线性/非线性安全计算的原子协议模块（安全激活、矩阵向量运算、损失评估），理论验证协议可靠性、安全性及渐进复杂度。

Result: 实验表明框架推理精度高且通信开销显著降低（较基线提升12.3倍），基准数据集验证其在严格数据保密下保持模型效用。

Conclusion: 该框架为金融、医疗及跨组织AI应用中隐私保护神经网络训练提供实用解决方案，平衡性能与安全性。

Abstract: Privacy-preserving neural network training in vertically partitioned
scenarios is vital for secure collaborative modeling across institutions. This
paper presents \textbf{EVA-S2PMLP}, an Efficient, Verifiable, and Accurate
Secure Two-Party Multi-Layer Perceptron framework that introduces spatial-scale
optimization for enhanced privacy and performance. To enable reliable
computation under real-number domain, EVA-S2PMLP proposes a secure
transformation pipeline that maps scalar inputs to vector and matrix spaces
while preserving correctness. The framework includes a suite of atomic
protocols for linear and non-linear secure computations, with modular support
for secure activation, matrix-vector operations, and loss evaluation.
Theoretical analysis confirms the reliability, security, and asymptotic
complexity of each protocol. Extensive experiments show that EVA-S2PMLP
achieves high inference accuracy and significantly reduced communication
overhead, with up to $12.3\times$ improvement over baselines. Evaluation on
benchmark datasets demonstrates that the framework maintains model utility
while ensuring strict data confidentiality, making it a practical solution for
privacy-preserving neural network training in finance, healthcare, and
cross-organizational AI applications.

</details>


### [59] [PDLRecover: Privacy-preserving Decentralized Model Recovery with Machine Unlearning](https://arxiv.org/abs/2506.15112)
*Xiangman Li,Xiaodong Wu,Jianbing Ni,Mohamed Mahmoud,Maazen Alsabaan*

Main category: cs.CR

TL;DR: 本文提出PDLRecover方法，通过利用历史模型信息高效恢复被恶意客户端毒化的全局模型，同时保护隐私。该方法避免了重训练的高成本，并通过秘密共享技术确保本地模型参数不泄露。实验表明，恢复后的模型性能接近完全重训练模型，且计算和时间成本显著降低。


<details>
  <summary>Details</summary>
Motivation: 去中心化学习易受毒化攻击，现有防御方法主要检测并过滤恶意模型，但难以恢复已受损的全局模型。直接移除恶意客户端并重训练模型成本高且可能影响模型一致性和隐私。因此，需要一种高效且隐私保护的恢复方法。

Method: PDLRecover利用历史模型信息恢复被毒化的全局模型，通过近似Hessian矩阵计算的线性特性应用秘密共享技术保护历史更新。方法包括客户端准备、周期性恢复更新和最终精确更新，以确保恢复模型的鲁棒性和收敛性。

Result: 实验结果显示，恢复后的全局模型性能与完全重训练模型相当，但计算和时间成本显著降低。PDLRecover有效防止了本地模型参数的泄露，确保了恢复过程的准确性和隐私性。

Conclusion: PDLRecover提供了一种高效且隐私保护的全局模型恢复方法，避免了重训练的高成本，同时确保了模型的性能和安全性。该方法在去中心化学习中具有重要的应用价值。

Abstract: Decentralized learning is vulnerable to poison attacks, where malicious
clients manipulate local updates to degrade global model performance. Existing
defenses mainly detect and filter malicious models, aiming to prevent a limited
number of attackers from corrupting the global model. However, restoring an
already compromised global model remains a challenge. A direct approach is to
remove malicious clients and retrain the model using only the benign clients.
Yet, retraining is time-consuming, computationally expensive, and may
compromise model consistency and privacy.
  We propose PDLRecover, a novel method to recover a poisoned global model
efficiently by leveraging historical model information while preserving
privacy. The main challenge lies in protecting shared historical models while
enabling parameter estimation for model recovery. By exploiting the linearity
of approximate Hessian matrix computation, we apply secret sharing to protect
historical updates, ensuring local models are not leaked during transmission or
reconstruction. PDLRecover introduces client-side preparation, periodic
recovery updates, and a final exact update to ensure robustness and convergence
of the recovered model. Periodic updates maintain accurate curvature
information, and the final step ensures high-quality convergence. Experiments
show that the recovered global model achieves performance comparable to a fully
retrained model but with significantly reduced computation and time cost.
Moreover, PDLRecover effectively prevents leakage of local model parameters,
ensuring both accuracy and privacy in recovery.

</details>


### [60] [CipherMind: The Longest Codebook in the World](https://arxiv.org/abs/2506.15117)
*Ming Nie,Zhixiong Yang,Bingsheng Wei*

Main category: cs.CR

TL;DR: 本文提出CipherMind，利用大语言模型推理的确定性微调中间结果作为传输内容，实现通信加密。该方法适用于网关内传输等场景，理论上可基于任何大模型实现。


<details>
  <summary>Details</summary>
Motivation: 受大语言模型广泛应用的启发，作者探索利用其推理过程的不透明性和弱可解释性特性，开发新型通信加密方法。

Method: 通过确定性微调大模型获取推理中间结果作为加密传输内容，利用模型参数的语义特性实现数据加密。

Result: 提出的CipherMind框架能够有效利用大模型特性实现加密传输，适用于多种通信场景。

Conclusion: 基于大语言模型的加密通信范式具有普适性，任何大模型均可作为其实现基础，为安全通信提供了新思路。

Abstract: In recent years, the widespread application of large language models has
inspired us to consider using inference for communication encryption. We
therefore propose CipherMind, which utilizes intermediate results from
deterministic fine-tuning of large model inferences as transmission content.
The semantic parameters of large models exhibit characteristics like opaque
underlying implementations and weak interpretability, thus enabling their use
as an encryption method for data transmission. This communication paradigm can
be applied in scenarios like intra-gateway transmission, and theoretically, it
can be implemented using any large model as its foundation.

</details>


### [61] [From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem](https://arxiv.org/abs/2506.15170)
*Yanxu Mao,Tiehan Cui,Peipei Liu,Datao You,Hongsong Zhu*

Main category: cs.CR

TL;DR: 本文系统综述了大型语言模型(LLM)生态系统中越狱攻击与防御机制的发展，分析了多模态LLM和智能代理带来的安全挑战，并对现有技术进行了分类与评估，提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLM向多模态和智能代理演进，其安全风险日益严峻，需系统梳理越狱攻击与防御的最新进展，以促进更健壮的安全策略发展。

Method: 从攻击影响和可见性角度对越狱技术分类，分析代表性方法、数据集和评估指标；按响应时机和技术路线组织防御策略，并指出现有研究的四大局限性。

Result: 建立了越狱攻击的分类体系，整合了防御策略框架，更新了最新研究成果，揭示了数据集构建、评估框架优化等未来关键方向。

Conclusion: 研究深化了对越狱机制的理解，为LLM生态的安全防御提供了系统化参考，强调需发展适应快速演进模型的动态防御策略。

Abstract: Large language models (LLMs) are rapidly evolving from single-modal systems
to multimodal LLMs and intelligent agents, significantly expanding their
capabilities while introducing increasingly severe security risks. This paper
presents a systematic survey of the growing complexity of jailbreak attacks and
corresponding defense mechanisms within the expanding LLM ecosystem. We first
trace the developmental trajectory from LLMs to MLLMs and Agents, highlighting
the core security challenges emerging at each stage. Next, we categorize
mainstream jailbreak techniques from both the attack impact and visibility
perspectives, and provide a comprehensive analysis of representative attack
methods, related datasets, and evaluation metrics. On the defense side, we
organize existing strategies based on response timing and technical approach,
offering a structured understanding of their applicability and implementation.
Furthermore, we identify key limitations in existing surveys, such as
insufficient attention to agent-specific security issues, the absence of a
clear taxonomy for hybrid jailbreak methods, a lack of detailed analysis of
experimental setups, and outdated coverage of recent advancements. To address
these limitations, we provide an updated synthesis of recent work and outline
future research directions in areas such as dataset construction, evaluation
framework optimization, and strategy generalization. Our study seeks to enhance
the understanding of jailbreak mechanisms and facilitate the advancement of
more resilient and adaptive defense strategies in the context of ever more
capable LLMs.

</details>


### [62] [LLM vs. SAST: A Technical Analysis on Detecting Coding Bugs of GPT4-Advanced Data Analysis](https://arxiv.org/abs/2506.15212)
*Madjid G. Tehrani,Eldar Sultanow,William J. Buchanan,Mahkame Houmani,Christel H. Djaha Fodja*

Main category: cs.CR

TL;DR: 研究探讨GPT-4在软件漏洞扫描中的效能，发现其准确率高达94%，优于传统静态应用安全测试工具。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理技术的快速发展，大型语言模型如GPT-4在安全漏洞扫描等多样化应用中展现出潜力，本研究旨在评估其与传统工具的比较优势。

Method: 通过分析一系列安全错误，比较GPT-4（高级数据分析功能）与传统静态应用安全测试工具在检测32种可利用漏洞中的表现。

Result: GPT-4在漏洞检测中的准确率达到94%，显著优于传统静态应用安全测试工具。

Conclusion: 研究强调了GPT-4在漏洞扫描中的高效性，同时指出需关注大型语言模型的安全问题，提倡通过设计和默认安全等最佳实践来保障AI安全。

Abstract: With the rapid advancements in Natural Language Processing (NLP), large
language models (LLMs) like GPT-4 have gained significant traction in diverse
applications, including security vulnerability scanning. This paper
investigates the efficacy of GPT-4 in identifying software vulnerabilities
compared to traditional Static Application Security Testing (SAST) tools.
Drawing from an array of security mistakes, our analysis underscores the potent
capabilities of GPT-4 in LLM-enhanced vulnerability scanning. We unveiled that
GPT-4 (Advanced Data Analysis) outperforms SAST by an accuracy of 94% in
detecting 32 types of exploitable vulnerabilities. This study also addresses
the potential security concerns surrounding LLMs, emphasising the imperative of
security by design/default and other security best practices for AI.

</details>


### [63] [RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments](https://arxiv.org/abs/2506.15253)
*Yuchuan Fu,Xiaohan Yuan,Dongxia Wang*

Main category: cs.CR

TL;DR: 本文提出了RAS-Eval安全基准，用于评估大型语言模型(LLM)代理在动态环境中的安全漏洞。通过80个测试案例和3,802个攻击任务，研究发现攻击平均降低任务完成率36.78%，在学术环境中成功率高达85.65%。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理在医疗和金融等关键领域的快速部署，亟需建立标准化安全评估基准来应对动态环境中的安全威胁。

Method: 研究团队开发了RAS-Eval基准，包含80个测试案例和3,802个攻击任务，覆盖11个CWE类别。工具采用JSON、LangGraph和MCP格式实现，并评估了6个先进LLM模型。

Result: 实验显示：攻击平均降低代理任务完成率36.78%，学术环境攻击成功率85.65%。安全能力遵循规模定律，大模型表现优于小模型。

Conclusion: 研究揭示了现实世界LLM代理部署的重大安全风险，为未来安全研究提供了基础框架。代码和数据已开源。

Abstract: The rapid deployment of Large language model (LLM) agents in critical domains
like healthcare and finance necessitates robust security frameworks. To address
the absence of standardized evaluation benchmarks for these agents in dynamic
environments, we introduce RAS-Eval, a comprehensive security benchmark
supporting both simulated and real-world tool execution. RAS-Eval comprises 80
test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration
(CWE) categories, with tools implemented in JSON, LangGraph, and Model Context
Protocol (MCP) formats. We evaluate 6 state-of-the-art LLMs across diverse
scenarios, revealing significant vulnerabilities: attacks reduced agent task
completion rates (TCR) by 36.78% on average and achieved an 85.65% success rate
in academic settings. Notably, scaling laws held for security capabilities,
with larger models outperforming smaller counterparts. Our findings expose
critical risks in real-world agent deployments and provide a foundational
framework for future security research. Code and data are available at
https://github.com/lanzer-tree/RAS-Eval.

</details>


### [64] [Facility Location Problem under Local Differential Privacy without Super-set Assumption](https://arxiv.org/abs/2506.15224)
*Kevin Pfisterer,Quentin Hillebrand,Vorapong Suppakitpaisarn*

Main category: cs.CR

TL;DR: 本文在本地差分隐私（LDP）框架下提出了一种改进的设施选址问题模型，并设计了一种算法，该算法在保持用户隐私的同时，实现了常数近似比和较小的加性误差。实验表明，该算法在合成和真实数据集上均优于直接方法。


<details>
  <summary>Details</summary>
Motivation: 传统差分隐私算法在设施选址问题中存在$\Omega(\sqrt{n})$的近似比下界，且现有工作采用的超集假设可能损害用户隐私。本文旨在突破这一限制，提出一种在LDP模型下更高效的解决方案。

Method: 通过改进设施选址问题模型，设计了一种LDP算法，该算法不依赖超集假设，直接处理用户位置数据，同时保证隐私性。算法核心在于平衡隐私保护与近似比的优化。

Result: 提出的LDP算法实现了常数近似比和较小的加性误差，突破了$\Omega(\sqrt{n})$的下界限制。实验验证了算法在合成和真实数据集上的优越性能。

Conclusion: 本文证明了传统下界不适用于改进的设施选址模型，并通过LDP算法实现了高效的隐私保护解决方案，为实际应用提供了新的理论和技术支持。

Abstract: In this paper, we introduce an adaptation of the facility location problem
and analyze it within the framework of local differential privacy (LDP). Under
this model, we ensure the privacy of client presence at specific locations.
When n is the number of points, Gupta et al. established a lower bound of
$\Omega(\sqrt{n})$ on the approximation ratio for any differentially private
algorithm applied to the original facility location problem. As a result,
subsequent works have adopted the super-set assumption, which may, however,
compromise user privacy. We show that this lower bound does not apply to our
adaptation by presenting an LDP algorithm that achieves a constant
approximation ratio with a relatively small additive factor. Additionally, we
provide experimental results demonstrating that our algorithm outperforms the
straightforward approach on both synthetically generated and real-world
datasets.

</details>


### [65] [Evaluation Pipeline for systematically searching for Anomaly Detection Systems](https://arxiv.org/abs/2506.15388)
*Florian Rokohl,Alexander Lehnert,Marc Reichenbach*

Main category: cs.CR

TL;DR: 提出基于FPGA的实时异常检测系统，用于医疗数字化环境中的恶意客户端识别。


<details>
  <summary>Details</summary>
Motivation: 医疗数字化带来便利的同时也面临网络安全威胁，需实时检测恶意入侵者。

Method: 利用FPGA硬件满足实时性与功耗限制，通过整体系统评估实现高性能检测。

Result: 系统成功在硬件层面实现实时异常检测，符合医疗场景的严苛要求。

Conclusion: FPGA硬件方案有效解决了医疗网络安全中的实时检测与能效平衡问题。

Abstract: Digitalization in the medical world provides major benefits while making it a
target for attackers and thus hard to secure. To deal with network intruders we
propose an anomaly detection system on hardware to detect malicious clients in
real-time. We meet real-time and power restrictions using FPGAs. Overall system
performance is achieved via the presented holistic system evaluation.

</details>


### [66] [Detecting Hardware Trojans in Microprocessors via Hardware Error Correction Code-based Modules](https://arxiv.org/abs/2506.15417)
*Alessandro Palumbo,Ruben Salvador*

Main category: cs.CR

TL;DR: 本文提出了一种基于硬件的方法，利用RISC-V微处理器上的纠错码（ECC）检测运行时硬件木马（HT）激活，特别是针对注入恶意指令的HT。通过硬件安全检查器（HSC）和汉明单纠错（HSEC）架构，实现了100%的检测率且无额外开销。


<details>
  <summary>Details</summary>
Motivation: 软件可利用的硬件木马（HT）使攻击者能够执行未授权软件或获取特权操作权限，威胁系统安全。因此，需要一种高效且低开销的检测方法。

Method: 采用基于硬件的检测方法，利用汉明单纠错（HSEC）架构设计硬件安全检查器（HSC），用于检测运行时HT激活，特别是针对恶意指令注入的HT。

Result: 实验结果表明，该方法对潜在HT激活的检测率达到100%，且无误报或漏报。实现仅需72个LUT、24个FF和0.5个BRAM，不影响微处理器原始工作频率且无额外时延。

Conclusion: 所提出的硬件安全检查器（HSC）是一种高效、低开销的HT检测方案，适用于RISC-V微处理器，能够有效防御恶意指令注入攻击。

Abstract: Software-exploitable Hardware Trojans (HTs) enable attackers to execute
unauthorized software or gain illicit access to privileged operations. This
manuscript introduces a hardware-based methodology for detecting runtime HT
activations using Error Correction Codes (ECCs) on a RISC-V microprocessor.
Specifically, it focuses on HTs that inject malicious instructions, disrupting
the normal execution flow by triggering unauthorized programs. To counter this
threat, the manuscript introduces a Hardware Security Checker (HSC) leveraging
Hamming Single Error Correction (HSEC) architectures for effective HT
detection. Experimental results demonstrate that the proposed solution achieves
a 100% detection rate for potential HT activations, with no false positives or
undetected attacks. The implementation incurs minimal overhead, requiring only
72 #LUTs, 24 #FFs, and 0.5 #BRAM while maintaining the microprocessor's
original operating frequency and introducing no additional time delay.

</details>


### [67] [Side-Channel Extraction of Dataflow AI Accelerator Hardware Parameters](https://arxiv.org/abs/2506.15432)
*Guillaume Lomet,Ruben Salvador,Brice Colombier,Vincent Grosso,Olivier Sentieys,Cedric Killian*

Main category: cs.CR

TL;DR: 本文提出了一种针对FINN框架生成的数据流神经网络加速器的侧信道攻击方法，通过无监督降维和轻量级分类器，高效恢复硬件配置参数，攻击时间短且准确率高。


<details>
  <summary>Details</summary>
Motivation: 数据流神经网络加速器虽简化了AI任务部署，但其便利性使其易受侧信道攻击，导致知识产权被逆向工程。现有方法计算开销大，需更高效的攻击方案。

Method: 采用无监督降维技术降低计算开销，结合随机森林分类器从侧信道痕迹中恢复折叠和量化参数，攻击阶段仅需337毫秒。

Result: 攻击方法在95%准确率下仅需337毫秒恢复硬件参数，421毫秒完全恢复（平均4次痕迹）。相比现有方法，准备和攻击时间分别减少940倍和110倍。

Conclusion: 该方法在完全加载加速器数据流的情况下仍能高效攻击，提供了比现有技术更现实的攻击场景，且无需痕迹平均即可获得更好结果。

Abstract: Dataflow neural network accelerators efficiently process AI tasks on FPGAs,
with deployment simplified by ready-to-use frameworks and pre-trained models.
However, this convenience makes them vulnerable to malicious actors seeking to
reverse engineer valuable Intellectual Property (IP) through Side-Channel
Attacks (SCA). This paper proposes a methodology to recover the hardware
configuration of dataflow accelerators generated with the FINN framework.
Through unsupervised dimensionality reduction, we reduce the computational
overhead compared to the state-of-the-art, enabling lightweight classifiers to
recover both folding and quantization parameters. We demonstrate an attack
phase requiring only 337 ms to recover the hardware parameters with an accuracy
of more than 95% and 421 ms to fully recover these parameters with an averaging
of 4 traces for a FINN-based accelerator running a CNN, both using a random
forest classifier on side-channel traces, even with the accelerator dataflow
fully loaded. This approach offers a more realistic attack scenario than
existing methods, and compared to SoA attacks based on tsfresh, our method
requires 940x and 110x less time for preparation and attack phases,
respectively, and gives better results even without averaging traces.

</details>


### [68] [An efficient construction of Raz's two-source randomness extractor with improved parameters](https://arxiv.org/abs/2506.15547)
*Cameron Foreman,Lewis Wooltorton,Kevin Milner,Florian J. Curchod*

Main category: cs.CR

TL;DR: 本文改进了Raz的随机性提取器，提出了一种计算时间为准线性的新版本，并降低了熵需求。同时提供了开源实现和数值参数计算模块。


<details>
  <summary>Details</summary>
Motivation: Raz的原始提取器虽能在线性最小熵和对数最小熵的双源设置下工作，但其计算时间高达多项式阶（至少四次方），缺乏实用性。

Method: 通过优化Raz提取器的构造，实现了准线性计算时间；提出新的分析定理以减少熵需求；开发了开源代码实现及参数计算工具。

Result: 改进后的提取器在计算效率上显著提升，支持强量子证明版本，并通过全面的分析和数值对比验证了其优越性。

Conclusion: 该研究为弱随机源的实用化提取提供了高效解决方案，其开源工具进一步降低了应用门槛。

Abstract: Randomness extractors are algorithms that distill weak random sources into
near-perfect random numbers. Two-source extractors enable this distillation
process by combining two independent weak random sources. Raz's extractor (STOC
'05) was the first to achieve this in a setting where one source has linear
min-entropy (i.e., proportional to its length), while the other has only
logarithmic min-entropy in its length. However, Raz's original construction is
impractical due to a polynomial computation time of at least degree 4. Our work
solves this problem by presenting an improved version of Raz's extractor with
quasi-linear computation time, as well as a new analytic theorem with reduced
entropy requirements. We provide comprehensive analytical and numerical
comparisons of our construction with others in the literature, and we derive
strong and quantum-proof versions of our efficient Raz extractor. Additionally,
we offer an easy-to-use, open-source code implementation of the extractor and a
numerical parameter calculation module.

</details>


### [69] [deepSURF: Detecting Memory Safety Vulnerabilities in Rust Through Fuzzing LLM-Augmented Harnesses](https://arxiv.org/abs/2506.15648)
*Georgios Androutsopoulos,Antonio Bianchi*

Main category: cs.CR

TL;DR: 本文介绍了deepSURF工具，它结合静态分析与基于大语言模型（LLM）的模糊测试生成技术，有效检测Rust库中的内存安全漏洞，特别是在不安全代码中。


<details>
  <summary>Details</summary>
Motivation: 尽管Rust默认保证内存安全，但不安全代码的使用仍可能导致漏洞。现有工具在检测能力、处理Rust特有类型或减少人工干预方面存在不足。

Method: deepSURF通过替换泛型为自定义类型并生成特质实现来处理泛型，同时利用LLM动态增强模糊测试工具链，以探索复杂API交互。

Result: 在27个真实Rust库的评估中，deepSURF成功复现了20个已知内存安全漏洞，并发现了6个新漏洞，表现优于现有工具。

Conclusion: deepSURF通过创新的泛型处理和LLM增强的模糊测试，显著提升了Rust内存安全漏洞的检测能力，为相关领域提供了有效工具。

Abstract: Although Rust ensures memory safety by default, it also permits the use of
unsafe code, which can introduce memory safety vulnerabilities if misused.
Unfortunately, existing tools for detecting memory bugs in Rust typically
exhibit limited detection capabilities, inadequately handle Rust-specific
types, or rely heavily on manual intervention.
  To address these limitations, we present deepSURF, a tool that integrates
static analysis with Large Language Model (LLM)-guided fuzzing harness
generation to effectively identify memory safety vulnerabilities in Rust
libraries, specifically targeting unsafe code. deepSURF introduces a novel
approach for handling generics by substituting them with custom types and
generating tailored implementations for the required traits, enabling the
fuzzer to simulate user-defined behaviors within the fuzzed library.
Additionally, deepSURF employs LLMs to augment fuzzing harnesses dynamically,
facilitating exploration of complex API interactions and significantly
increasing the likelihood of exposing memory safety vulnerabilities. We
evaluated deepSURF on 27 real-world Rust crates, successfully rediscovering 20
known memory safety bugs and uncovering 6 previously unknown vulnerabilities,
demonstrating clear improvements over state-of-the-art tools.

</details>


### [70] [PhishDebate: An LLM-Based Multi-Agent Framework for Phishing Website Detection](https://arxiv.org/abs/2506.15656)
*Wenhao Li,Selvakumar Manickam,Yung-wey Chong,Shankar Karuppayah*

Main category: cs.CR

TL;DR: 本文提出PhishDebate框架，通过多智能体辩论机制提升钓鱼网站检测的准确性与可解释性，实验显示其性能优于单智能体及思维链基线。


<details>
  <summary>Details</summary>
Motivation: 钓鱼网站利用欺骗性结构和社交工程逃避检测，现有单智能体分类方法存在幻觉风险且缺乏可解释性，亟需更鲁棒的解决方案。

Method: 采用模块化多智能体辩论框架（PhishDebate），由四个专项智能体分别分析URL结构、HTML组成、语义内容及品牌仿冒，经协调员与法官进行结构化辩论。

Result: 在真实钓鱼数据集上实现98.2%召回率与真阳性率，显著优于单智能体和思维链基线，模块化设计支持智能体级配置以适应不同需求。

Conclusion: PhishDebate通过多角度辩论机制有效提升检测性能，其可解释决策和灵活架构为钓鱼防御提供了新范式。

Abstract: Phishing websites continue to pose a significant cybersecurity threat, often
leveraging deceptive structures, brand impersonation, and social engineering
tactics to evade detection. While recent advances in large language models
(LLMs) have enabled improved phishing detection through contextual
understanding, most existing approaches rely on single-agent classification
facing the risks of hallucination and lack interpretability or robustness. To
address these limitations, we propose PhishDebate, a modular multi-agent
LLM-based debate framework for phishing website detection. PhishDebate employs
four specialized agents to independently analyze different textual aspects of a
webpage--URL structure, HTML composition, semantic content, and brand
impersonation--under the coordination of a Moderator and a final Judge. Through
structured debate and divergent thinking, the framework delivers more accurate
and interpretable decisions. Extensive evaluations on commercial LLMs
demonstrate that PhishDebate achieves 98.2% recall and 98.2% True Positive Rate
(TPR) on a real-world phishing dataset, and outperforms single-agent and Chain
of Thought (CoT) baselines. Additionally, its modular design allows agent-level
configurability, enabling adaptation to varying resource and application
requirements.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [71] [CALM: Contextual Analog Logic with Multimodality](https://arxiv.org/abs/2506.14936)
*Maxwell J. Jacobson,Corey J. Maley,Yexiang Xue*

Main category: cs.AI

TL;DR: 本文提出了一种结合符号推理与神经生成的上下文模拟逻辑（CALM），通过多模态数据实现情境敏感决策，在物体摆放任务中准确率达92.2%，超越传统逻辑与LLM基线。


<details>
  <summary>Details</summary>
Motivation: 经典二值逻辑系统无法捕捉人类决策的细微差别，且在多模态环境中依赖人工标注，显得僵化脆弱；神经网络虽擅长多模态信息提取，但缺乏可解释的推理结构。CALM旨在弥合逻辑与神经感知的鸿沟。

Method: CALM使用领域树表示谓词，通过神经网络迭代优化模拟真值，并经过符号推理模块约束过滤。神经网络负责捕捉多模态信息，符号模块确保逻辑约束满足。

Result: 在填空式物体摆放任务中，CALM以92.2%准确率显著优于传统逻辑（86.3%）和LLM（59.4%），其生成的空间热图既符合逻辑约束又与人类偏好一致。

Conclusion: CALM展示了在多模态环境中兼顾逻辑结构与偏好对齐的潜力，为需要逻辑精确性、可解释性及神经多模态处理能力的下一代AI系统奠定基础。

Abstract: In this work, we introduce Contextual Analog Logic with Multimodality (CALM).
CALM unites symbolic reasoning with neural generation, enabling systems to make
context-sensitive decisions grounded in real-world multi-modal data.
  Background: Classic bivalent logic systems cannot capture the nuance of human
decision-making. They also require human grounding in multi-modal environments,
which can be ad-hoc, rigid, and brittle. Neural networks are good at extracting
rich contextual information from multi-modal data, but lack interpretable
structures for reasoning.
  Objectives: CALM aims to bridge the gap between logic and neural perception,
creating an analog logic that can reason over multi-modal inputs. Without this
integration, AI systems remain either brittle or unstructured, unable to
generalize robustly to real-world tasks. In CALM, symbolic predicates evaluate
to analog truth values computed by neural networks and constrained search.
  Methods: CALM represents each predicate using a domain tree, which
iteratively refines its analog truth value when the contextual groundings of
its entities are determined. The iterative refinement is predicted by neural
networks capable of capturing multi-modal information and is filtered through a
symbolic reasoning module to ensure constraint satisfaction.
  Results: In fill-in-the-blank object placement tasks, CALM achieved 92.2%
accuracy, outperforming classical logic (86.3%) and LLM (59.4%) baselines. It
also demonstrated spatial heatmap generation aligned with logical constraints
and delicate human preferences, as shown by a human study.
  Conclusions: CALM demonstrates the potential to reason with logic structure
while aligning with preferences in multi-modal environments. It lays the
foundation for next-gen AI systems that require the precision and
interpretation of logic and the multimodal information processing of neural
networks.

</details>


### [72] [MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2506.14990)
*Tristan Tomilin,Luka van den Boogaard,Samuel Garcin,Bram Grooten,Meng Fang,Mykola Pechenizkiy*

Main category: cs.AI

TL;DR: 论文提出了首个面向持续多智能体强化学习(CMARL)的基准测试MEAL，利用JAX实现GPU加速，解决了现有基准测试在CPU上运行导致的算力瓶颈问题，并通过实验揭示了当前CL与MARL方法结合在复杂场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习基准测试在持续学习(CL)与多智能体协作(MARL)交叉领域的研究不足，且CPU计算限制了任务序列长度。MEAL旨在填补这一空白并提供高效评估平台。

Method: 采用JAX框架实现GPU加速，构建包含100个连续任务的基准测试MEAL，支持在普通台式机上数小时内完成训练。通过消融实验分析架构与算法特征。

Result: 实验表明：简单环境中CL与MARL方法组合表现良好，但在需要持续协调的复杂环境中失效；GPU加速使任务序列长度提升两个数量级。

Conclusion: MEAL为CMARL研究提供了关键工具，揭示了当前方法的可扩展性缺陷，其GPU加速架构为未来长序列持续学习研究树立了新标准。

Abstract: Benchmarks play a crucial role in the development and analysis of
reinforcement learning (RL) algorithms, with environment availability strongly
impacting research. One particularly underexplored intersection is continual
learning (CL) in cooperative multi-agent settings. To remedy this, we introduce
MEAL (Multi-agent Environments for Adaptive Learning), the first benchmark
tailored for continual multi-agent reinforcement learning (CMARL). Existing CL
benchmarks run environments on the CPU, leading to computational bottlenecks
and limiting the length of task sequences. MEAL leverages JAX for GPU
acceleration, enabling continual learning across sequences of 100 tasks on a
standard desktop PC in a few hours. We show that naively combining popular CL
and MARL methods yields strong performance on simple environments, but fails to
scale to more complex settings requiring sustained coordination and adaptation.
Our ablation study identifies architectural and algorithmic features critical
for CMARL on MEAL.

</details>


### [73] [Truncated Proximal Policy Optimization](https://arxiv.org/abs/2506.15050)
*Tiantian Fan,Lingjun Liu,Yu Yue,Jiaze Chen,Chengyi Wang,Qiying Yu,Chi Zhang,Zhiqi Lin,Ruofei Zhu,Yufeng Yuan,Xiaochen Zuo,Bole Ma,Mofan Zhang,Gaohong Liu,Ru Zhang,Haotian Zhou,Cong Xie,Ruidong Zhu,Zhi Zhang,Xin Liu,Mingxuan Wang,Lin Yan,Yonghui Wu*

Main category: cs.AI

TL;DR: 本文提出了一种名为截断近端策略优化（T-PPO）的新方法，旨在提高大型语言模型（LLM）在推理任务中的训练效率。通过优化策略更新和限制响应长度，T-PPO显著减少了训练时间，同时保持了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的近端策略优化（PPO）方法在训练大型语言模型时，由于同步生成长响应导致硬件利用率低，训练效率低下。本文旨在解决这一问题，提高训练效率。

Method: 提出了截断近端策略优化（T-PPO），包括扩展广义优势估计（EGAE）和一种计算优化机制。EGAE从不完整响应中估计优势，而优化机制通过选择性过滤提示和截断标记来减少冗余计算。

Result: 实验结果表明，T-PPO在AIME 2024的32B基础模型上，将推理LLM的训练效率提高了2.5倍，并且优于现有竞争对手。

Conclusion: T-PPO通过优化策略更新和响应生成过程，显著提高了大型语言模型的训练效率，同时保持了模型的性能，为未来的推理模型开发提供了有效工具。

Abstract: Recently, test-time scaling Large Language Models (LLMs) have demonstrated
exceptional reasoning capabilities across scientific and professional tasks by
generating long chains-of-thought (CoT). As a crucial component for developing
these reasoning models, reinforcement learning (RL), exemplified by Proximal
Policy Optimization (PPO) and its variants, allows models to learn through
trial and error. However, PPO can be time-consuming due to its inherent
on-policy nature, which is further exacerbated by increasing response lengths.
In this work, we propose Truncated Proximal Policy Optimization (T-PPO), a
novel extension to PPO that improves training efficiency by streamlining policy
update and length-restricted response generation. T-PPO mitigates the issue of
low hardware utilization, an inherent drawback of fully synchronized
long-generation procedures, where resources often sit idle during the waiting
periods for complete rollouts. Our contributions are two-folds. First, we
propose Extended Generalized Advantage Estimation (EGAE) for advantage
estimation derived from incomplete responses while maintaining the integrity of
policy learning. Second, we devise a computationally optimized mechanism that
allows for the independent optimization of the policy and value models. By
selectively filtering prompt and truncated tokens, this mechanism reduces
redundant computations and accelerates the training process without sacrificing
convergence performance. We demonstrate the effectiveness and efficacy of T-PPO
on AIME 2024 with a 32B base model. The experimental results show that T-PPO
improves the training efficiency of reasoning LLMs by up to 2.5x and
outperforms its existing competitors.

</details>


### [74] [HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges](https://arxiv.org/abs/2506.15196)
*Xianliang Yang,Ling Zhang,Haolong Qian,Lei Song,Jiang Bian*

Main category: cs.AI

TL;DR: HeurAgenix是一种基于大语言模型的两阶段超启发式框架，通过进化启发式算法并自动选择最优解，显著提升组合优化问题的求解性能。


<details>
  <summary>Details</summary>
Motivation: 传统启发式算法设计依赖专家经验且难以泛化，HeurAgenix旨在利用大语言模型的感知能力实现自动化、通用化的启发式生成与选择。

Method: 框架分为启发式进化（LLM对比种子解提取策略）和动态选择（LLM或轻量模型指导）两阶段，采用双奖励机制微调选择器以应对组合优化的标注噪声。

Result: 在经典基准测试中，HeurAgenix不仅超越现有基于LLM的超启发式方法，还能媲美或优于专业求解器。

Conclusion: 该研究证明了LLM驱动框架在组合优化领域的潜力，其代码开源为后续研究提供了重要工具。

Abstract: Heuristic algorithms play a vital role in solving combinatorial optimization
(CO) problems, yet traditional designs depend heavily on manual expertise and
struggle to generalize across diverse instances. We introduce
\textbf{HeurAgenix}, a two-stage hyper-heuristic framework powered by large
language models (LLMs) that first evolves heuristics and then selects among
them automatically. In the heuristic evolution phase, HeurAgenix leverages an
LLM to compare seed heuristic solutions with higher-quality solutions and
extract reusable evolution strategies. During problem solving, it dynamically
picks the most promising heuristic for each problem state, guided by the LLM's
perception ability. For flexibility, this selector can be either a
state-of-the-art LLM or a fine-tuned lightweight model with lower inference
cost. To mitigate the scarcity of reliable supervision caused by CO complexity,
we fine-tune the lightweight heuristic selector with a dual-reward mechanism
that jointly exploits singals from selection preferences and state perception,
enabling robust selection under noisy annotations. Extensive experiments on
canonical benchmarks show that HeurAgenix not only outperforms existing
LLM-based hyper-heuristics but also matches or exceeds specialized solvers.
Code is available at https://github.com/microsoft/HeurAgenix.

</details>


### [75] [Multi-Agent Reinforcement Learning for Autonomous Multi-Satellite Earth Observation: A Realistic Case Study](https://arxiv.org/abs/2506.15207)
*Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Jimmy Cao,Ryszard Kowalczyk*

Main category: cs.AI

TL;DR: 本文研究了基于强化学习（RL）和多智能体强化学习（MARL）的低地球轨道（LEO）卫星自主地球观测（EO）任务规划，解决了多卫星系统中的实时决策、资源管理和分散协调等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道卫星数量的指数增长，传统优化方法难以满足动态地球观测任务的实时决策需求，因此需要探索RL和MARL在自主卫星任务规划中的应用。

Method: 研究通过单卫星操作建模扩展到多卫星星座的MARL框架，解决了能源和数据存储限制、观测不确定性以及部分可观测下的分散协调复杂性，并利用近真实卫星仿真环境评估了PPO、IPPO、MAPPO和HAPPO等先进MARL算法的训练稳定性和性能。

Result: 结果表明，MARL能有效平衡成像与资源管理，并解决多卫星协调中的非平稳性和奖励相互依赖问题。

Conclusion: 本研究为自主卫星操作提供了基础，并为改进分散式地球观测任务中的策略学习提供了实用指南。

Abstract: The exponential growth of Low Earth Orbit (LEO) satellites has revolutionised
Earth Observation (EO) missions, addressing challenges in climate monitoring,
disaster management, and more. However, autonomous coordination in
multi-satellite systems remains a fundamental challenge. Traditional
optimisation approaches struggle to handle the real-time decision-making
demands of dynamic EO missions, necessitating the use of Reinforcement Learning
(RL) and Multi-Agent Reinforcement Learning (MARL). In this paper, we
investigate RL-based autonomous EO mission planning by modelling
single-satellite operations and extending to multi-satellite constellations
using MARL frameworks. We address key challenges, including energy and data
storage limitations, uncertainties in satellite observations, and the
complexities of decentralised coordination under partial observability. By
leveraging a near-realistic satellite simulation environment, we evaluate the
training stability and performance of state-of-the-art MARL algorithms,
including PPO, IPPO, MAPPO, and HAPPO. Our results demonstrate that MARL can
effectively balance imaging and resource management while addressing
non-stationarity and reward interdependency in multi-satellite coordination.
The insights gained from this study provide a foundation for autonomous
satellite operations, offering practical guidelines for improving policy
learning in decentralised EO missions.

</details>


### [76] [Joint Computation Offloading and Resource Allocation for Uncertain Maritime MEC via Cooperation of UAVs and Vessels](https://arxiv.org/abs/2506.15225)
*Jiahao You,Ziye Jia,Chao Dong,Qihui Wu,Zhu Han*

Main category: cs.AI

TL;DR: 本文提出了一种基于无人机和船舶协作的海事边缘计算框架，通过李雅普诺夫优化和异构智能体软演员-评论家算法，有效解决了海事物联网任务卸载和资源分配的不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 海事物联网(MIoT)计算需求快速增长，但不确定的海事任务导致计算卸载和资源分配效率低下，亟需无人机(UAV)与船舶协作的多接入边缘计算(MEC)解决方案。

Method: 1) 建立无人机-船舶协作的MEC框架 2) 使用李雅普诺夫优化处理任务不确定性 3) 将问题转化为马尔可夫博弈 4) 提出异构智能体软演员-评论家算法求解。

Result: 仿真实验验证了所提方法在优化任务执行时间和资源分配方面的有效性，显著提升了海事边缘计算系统的性能。

Conclusion: 该研究为不确定环境下的海事计算卸载和资源分配提供了创新解决方案，通过智能体协作和强化学习实现了系统性能优化。

Abstract: The computation demands from the maritime Internet of Things (MIoT) increase
rapidly in recent years, and the unmanned aerial vehicles (UAVs) and vessels
based multi-access edge computing (MEC) can fulfill these MIoT requirements.
However, the uncertain maritime tasks present significant challenges of
inefficient computation offloading and resource allocation. In this paper, we
focus on the maritime computation offloading and resource allocation through
the cooperation of UAVs and vessels, with consideration of uncertain tasks.
Specifically, we propose a cooperative MEC framework for computation offloading
and resource allocation, including MIoT devices, UAVs and vessels. Then, we
formulate the optimization problem to minimize the total execution time. As for
the uncertain MIoT tasks, we leverage Lyapunov optimization to tackle the
unpredictable task arrivals and varying computational resource availability. By
converting the long-term constraints into short-term constraints, we obtain a
set of small-scale optimization problems. Further, considering the
heterogeneity of actions and resources of UAVs and vessels, we reformulate the
small-scale optimization problem into a Markov game (MG). Moreover, a
heterogeneous-agent soft actor-critic is proposed to sequentially update
various neural networks and effectively solve the MG problem. Finally,
simulations are conducted to verify the effectiveness in addressing
computational offloading and resource allocation.

</details>


### [77] [Efficient and Generalizable Environmental Understanding for Visual Navigation](https://arxiv.org/abs/2506.15377)
*Ruoyu Wang,Xinshu Li,Chen Wang,Lina Yao*

Main category: cs.AI

TL;DR: 本文提出了一种基于因果关系的视觉导航方法（CAN），通过引入因果理解模块提升智能体对环境的结构化理解能力，实验证明该方法在多种任务和仿真环境中均优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉导航方法通常同时处理所有历史观测数据，忽略了数据内部的关联结构，可能限制任务性能的进一步提升。本文从因果关系的角度分析导航任务的特性，旨在解决这一局限性。

Method: 提出了因果关系感知导航（CAN）框架，其核心是因果理解模块（Causal Understanding Module），该模块通过建模历史观测数据中的因果关系来增强智能体的环境理解能力。

Result: 实验表明，CAN在多种导航任务和仿真环境中均显著优于基线方法。消融研究证实因果理解模块是性能提升的关键，且该方法在强化学习和监督学习场景中均能有效泛化，无需额外计算开销。

Conclusion: 通过因果视角重构导航任务的数据建模方式，CAN框架实现了性能突破。因果理解模块的通用性表明，因果关系建模可广泛应用于具身智能的序列决策任务中。

Abstract: Visual Navigation is a core task in Embodied AI, enabling agents to navigate
complex environments toward given objectives. Across diverse settings within
Navigation tasks, many necessitate the modelling of sequential data accumulated
from preceding time steps. While existing methods perform well, they typically
process all historical observations simultaneously, overlooking the internal
association structure within the data, which may limit the potential for
further improvements in task performance. We address this by examining the
unique characteristics of Navigation tasks through the lens of causality,
introducing a causal framework to highlight the limitations of conventional
sequential methods. Leveraging this insight, we propose Causality-Aware
Navigation (CAN), which incorporates a Causal Understanding Module to enhance
the agent's environmental understanding capability. Empirical evaluations show
that our approach consistently outperforms baselines across various tasks and
simulation environments. Extensive ablations studies attribute these gains to
the Causal Understanding Module, which generalizes effectively in both
Reinforcement and Supervised Learning settings without computational overhead.

</details>


### [78] [Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents](https://arxiv.org/abs/2506.15567)
*Aline Dobrovsky,Konstantin Schekotihin,Christian Burmer*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型（LLM）的规划代理（LPA），用于辅助故障分析（FA）工程师处理复杂案例，通过整合LLM与外部工具实现自主查询处理和报告生成。


<details>
  <summary>Details</summary>
Motivation: 故障分析（FA）过程复杂且知识密集，随着AI模型数量的增加，如何协调这些组件以构建高效工作流成为挑战。

Method: 设计并实现了一种基于LLM的规划代理（LPA），结合高级规划能力和外部工具使用，支持自主处理复杂查询、检索外部数据并生成可读响应。

Result: 评估结果表明，LPA在支持FA任务方面具有操作有效性和可靠性。

Conclusion: LPA能够有效整合AI组件，提升FA工程师的工作效率，为故障分析流程提供智能化支持。

Abstract: Failure Analysis (FA) is a highly intricate and knowledge-intensive process.
The integration of AI components within the computational infrastructure of FA
labs has the potential to automate a variety of tasks, including the detection
of non-conformities in images, the retrieval of analogous cases from diverse
data sources, and the generation of reports from annotated images. However, as
the number of deployed AI models increases, the challenge lies in orchestrating
these components into cohesive and efficient workflows that seamlessly
integrate with the FA process.
  This paper investigates the design and implementation of a Large Language
Model (LLM)-based Planning Agent (LPA) to assist FA engineers in solving their
analysis cases. The LPA integrates LLMs with advanced planning capabilities and
external tool utilization, enabling autonomous processing of complex queries,
retrieval of relevant data from external systems, and generation of
human-readable responses. Evaluation results demonstrate the agent's
operational effectiveness and reliability in supporting FA tasks.

</details>


### [79] [The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games](https://arxiv.org/abs/2506.15624)
*Lyle Goodyear,Rachel Guo,Ramesh Johari*

Main category: cs.AI

TL;DR: 本文提出了一个系统化构建自然语言状态表示的框架，用于在重复多智能体游戏中提示LLM代理，并通过实验验证了不同状态表示对代理行为的影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLM代理在游戏中的历史编码采取临时方法，不仅模糊了状态表示对行为的影响，还限制了研究间的可比性。

Method: 框架通过三个维度（动作信息性、奖励信息性和提示风格）来表征状态表示方法，并应用于动态自私路由游戏进行验证。

Result: 实验发现，提供（1）历史摘要而非完整记录、（2）后悔信息而非原始收益、（3）有限他人动作信息的状态表示，能使代理行为更接近博弈论均衡预测且游戏更稳定。

Conclusion: 自然语言状态表示的选择显著影响LLM代理的行为，特定表示方式能有效提升代理行为的均衡性和稳定性。

Abstract: Large Language Models (LLMs) have shown promise as decision-makers in dynamic
settings, but their stateless nature necessitates creating a natural language
representation of history. We present a unifying framework for systematically
constructing natural language "state" representations for prompting LLM agents
in repeated multi-agent games. Previous work on games with LLM agents has taken
an ad hoc approach to encoding game history, which not only obscures the impact
of state representation on agents' behavior, but also limits comparability
between studies. Our framework addresses these gaps by characterizing methods
of state representation along three axes: action informativeness (i.e., the
extent to which the state representation captures actions played); reward
informativeness (i.e., the extent to which the state representation describes
rewards obtained); and prompting style (or natural language compression, i.e.,
the extent to which the full text history is summarized).
  We apply this framework to a dynamic selfish routing game, chosen because it
admits a simple equilibrium both in theory and in human subject experiments
\cite{rapoport_choice_2009}. Despite the game's relative simplicity, we find
that there are key dependencies of LLM agent behavior on the natural language
state representation. In particular, we observe that representations which
provide agents with (1) summarized, rather than complete, natural language
representations of past history; (2) information about regrets, rather than raw
payoffs; and (3) limited information about others' actions lead to behavior
that more closely matches game theoretic equilibrium predictions, and with more
stable game play by the agents. By contrast, other representations can exhibit
either large deviations from equilibrium, higher variation in dynamic game play
over time, or both.

</details>


### [80] [The AI Policy Module: Developing Computer Science Student Competency in AI Ethics and Policy](https://arxiv.org/abs/2506.15639)
*James Weichert,Daniel Dunlap,Mohammed Farghally,Hoda Eldardiry*

Main category: cs.AI

TL;DR: 本文介绍了一个AI政策模块的开发与实施，旨在将AI政策讨论引入计算机科学课程，帮助学生将伦理原则转化为实践，并提升他们对AI伦理与政策的关注与能力。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术在个人和专业领域的广泛应用，AI伦理和政策治理的重要性日益凸显。然而，当前的高等教育计算机课程未能充分培养学生将抽象伦理原则和政策偏好融入AI系统设计与开发的能力。

Method: 研究团队开发了AI政策模块2.0，并在2024年秋季进行了试点。模块包括一个关于“AI监管”的技术作业，并通过课前课后调查评估学生对AI伦理与政策的态度变化。

Result: 模块实施后，学生对AI技术伦理影响的关注度提升，同时对参与AI监管讨论的能力信心增强。AI监管作业被证明是探索AI对齐限度和强调政策在解决伦理挑战中作用的有效工具。

Conclusion: AI政策模块成功地将政策讨论引入计算机科学课程，帮助学生更好地理解AI伦理与政策，并为其未来作为AI工程师的责任做好准备。

Abstract: As artificial intelligence (AI) further embeds itself into many settings
across personal and professional contexts, increasing attention must be paid
not only to AI ethics, but also to the governance and regulation of AI
technologies through AI policy. However, the prevailing post-secondary
computing curriculum is currently ill-equipped to prepare future AI
practitioners to confront increasing demands to implement abstract ethical
principles and normative policy preferences into the design and development of
AI systems. We believe that familiarity with the 'AI policy landscape' and the
ability to translate ethical principles to practices will in the future
constitute an important responsibility for even the most technically-focused AI
engineers.
  Toward preparing current computer science (CS) students for these new
expectations, we developed an AI Policy Module to introduce discussions of AI
policy into the CS curriculum. Building on a successful pilot in fall 2024, in
this innovative practice full paper we present an updated and expanded version
of the module, including a technical assignment on "AI regulation". We present
the findings from our pilot of the AI Policy Module 2.0, evaluating student
attitudes towards AI ethics and policy through pre- and post-module surveys.
Following the module, students reported increased concern about the ethical
impacts of AI technologies while also expressing greater confidence in their
abilities to engage in discussions about AI regulation. Finally, we highlight
the AI Regulation Assignment as an effective and engaging tool for exploring
the limits of AI alignment and emphasizing the role of 'policy' in addressing
ethical challenges.

</details>


### [81] [Exploring and Exploiting the Inherent Efficiency within Large Reasoning Models for Self-Guided Efficiency Enhancement](https://arxiv.org/abs/2506.15647)
*Weixiang Zhao,Jiahe Guo,Yang Deng,Xingyu Sui,Yulin Hu,Yanyan Zhao,Wanxiang Che,Bing Qin,Tat-Seng Chua,Ting Liu*

Main category: cs.AI

TL;DR: 大型推理模型（LRMs）存在过度思考问题，导致冗余内容生成。研究发现LRMs具备简洁推理潜力，并提出两种轻量级方法提升效率：效率导向激活技术和自我奖励效率强化学习框架。实验证明这些方法显著缩短推理长度且保持或提升任务性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂问题解决中展现出类人思考能力，但过度思考现象导致效率低下和推理成本增加。研究旨在探索LRMs效率低下的表征和行为根源，并开发方法挖掘其潜在简洁推理能力。

Method: 提出两种方法：1) 效率导向（Efficiency Steering），一种无需训练的激活导向技术，通过模型表征空间中的单一方向调节推理行为；2) 自我奖励效率强化学习（Self-Rewarded Efficiency RL），通过奖励简洁正确答案动态平衡任务准确性与简洁性。

Result: 在七个LRM主干模型和多个数学推理基准测试中，所提方法显著减少推理长度（平均降低30%），同时保持或提升任务准确率（部分任务提升2-5%）。最短正确路径通常足以解决问题，验证了效率提升潜力。

Conclusion: 研究表明通过引导模型内在能力，可自监督地提升推理效率。未来工作可探索更精细的效率-准确性权衡机制，并将方法扩展到其他复杂推理任务。

Abstract: Recent advancements in large reasoning models (LRMs) have significantly
enhanced language models' capabilities in complex problem-solving by emulating
human-like deliberative thinking. However, these models often exhibit
overthinking (i.e., the generation of unnecessarily verbose and redundant
content), which hinders efficiency and inflates inference cost. In this work,
we explore the representational and behavioral origins of this inefficiency,
revealing that LRMs inherently possess the capacity for more concise reasoning.
Empirical analyses show that correct reasoning paths vary significantly in
length, and the shortest correct responses often suffice, indicating untapped
efficiency potential. Exploiting these findings, we propose two lightweight
methods to enhance LRM efficiency. First, we introduce Efficiency Steering, a
training-free activation steering technique that modulates reasoning behavior
via a single direction in the model's representation space. Second, we develop
Self-Rewarded Efficiency RL, a reinforcement learning framework that
dynamically balances task accuracy and brevity by rewarding concise correct
solutions. Extensive experiments on seven LRM backbones across multiple
mathematical reasoning benchmarks demonstrate that our methods significantly
reduce reasoning length while preserving or improving task performance. Our
results highlight that reasoning efficiency can be improved by leveraging and
guiding the intrinsic capabilities of existing models in a self-guided manner.

</details>


### [82] [SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence](https://arxiv.org/abs/2506.15672)
*Yao Zhang,Chenyang Lin,Shijie Tang,Haokun Chen,Shijie Zhou,Yunpu Ma,Volker Tresp*

Main category: cs.AI

TL;DR: SwarmAgentic是一个全自动代理系统生成框架，通过语言驱动探索和群体智能优化，实现了从零开始的代理生成与协作优化，在开放任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统生成框架缺乏完全自主性，无法实现从零生成、自优化功能与协作，限制了适应性和扩展性。

Method: 受粒子群优化(PSO)启发，框架维护候选系统种群并通过反馈引导更新，联合优化代理功能与协作这两个相互依赖的组件。

Result: 在6个开放任务(如旅行规划)中仅凭任务描述和目标函数即实现261.8%的相对性能提升，显著优于ADAS等基线。

Conclusion: 该框架将群体智能与全自动多代理生成相结合，为可扩展的自主代理系统设计迈出重要一步。代码已开源。

Abstract: The rapid progress of Large Language Models has advanced agentic systems in
decision-making, coordination, and task execution. Yet, existing agentic system
generation frameworks lack full autonomy, missing from-scratch agent
generation, self-optimizing agent functionality, and collaboration, limiting
adaptability and scalability. We propose SwarmAgentic, a framework for fully
automated agentic system generation that constructs agentic systems from
scratch and jointly optimizes agent functionality and collaboration as
interdependent components through language-driven exploration. To enable
efficient search over system-level structures, SwarmAgentic maintains a
population of candidate systems and evolves them via feedback-guided updates,
drawing inspiration from Particle Swarm Optimization (PSO). We evaluate our
method on six real-world, open-ended, and exploratory tasks involving
high-level planning, system-level coordination, and creative reasoning. Given
only a task description and an objective function, SwarmAgentic outperforms all
baselines, achieving a +261.8% relative improvement over ADAS on the
TravelPlanner benchmark, highlighting the effectiveness of full automation in
structurally unconstrained tasks. This framework marks a significant step
toward scalable and autonomous agentic system design, bridging swarm
intelligence with fully automated system multi-agent generation. Our code is
publicly released at https://yaoz720.github.io/SwarmAgentic/.

</details>


### [83] [Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence](https://arxiv.org/abs/2506.15677)
*Yining Hong,Rui Sun,Bingxuan Li,Xingcheng Yao,Maxine Wu,Alexander Chien,Da Yin,Ying Nian Wu,Zhecan James Wang,Kai-Wei Chang*

Main category: cs.AI

TL;DR: 本文提出了一种新型AI代理范式——具身网络代理（Embodied Web Agents），旨在整合物理世界交互与网络规模推理能力，并发布了统一的仿真平台与基准测试集。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理存在物理交互与数字推理割裂的问题，无法有效完成需要跨领域协同的任务（如在线食谱烹饪、动态地图导航等）。研究旨在突破这一局限。

Method: 开发了集成3D物理环境与功能性网页接口的仿真平台，构建包含烹饪、导航、购物等任务的基准测试集（Embodied Web Agents Benchmark）。

Result: 实验表明：现有AI系统与人类能力存在显著差距，揭示了具身认知与网络知识融合领域的挑战与机遇。

Conclusion: 该研究为跨领域智能评估提供了系统性框架，所有数据集与代码均已开源（https://embodied-web-agent.github.io/）。

Abstract: AI agents today are mostly siloed - they either retrieve and reason over vast
amount of digital information and knowledge obtained online; or interact with
the physical world through embodied perception, planning and action - but
rarely both. This separation limits their ability to solve tasks that require
integrated physical and digital intelligence, such as cooking from online
recipes, navigating with dynamic map data, or interpreting real-world landmarks
using web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI
agents that fluidly bridge embodiment and web-scale reasoning. To
operationalize this concept, we first develop the Embodied Web Agents task
environments, a unified simulation platform that tightly integrates realistic
3D indoor and outdoor environments with functional web interfaces. Building
upon this platform, we construct and release the Embodied Web Agents Benchmark,
which encompasses a diverse suite of tasks including cooking, navigation,
shopping, tourism, and geolocation - all requiring coordinated reasoning across
physical and digital realms for systematic assessment of cross-domain
intelligence. Experimental results reveal significant performance gaps between
state-of-the-art AI systems and human capabilities, establishing both
challenges and opportunities at the intersection of embodied cognition and
web-scale knowledge access. All datasets, codes and websites are publicly
available at our project page https://embodied-web-agent.github.io/.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [84] [A survey of Chernoff and Hoeffding bounds](https://arxiv.org/abs/2506.15612)
*Alexandros V. Gerbessiotis*

Main category: cs.DM

TL;DR: 本文是一篇综述论文，讨论了Chernoff和Hoeffding经典论文中的原始界限，并涵盖了多种形式的衍生界限。


<details>
  <summary>Details</summary>
Motivation: 旨在为感兴趣的研究者提供一个参考界限的存储库。

Method: 根据需要提供了完整的证明过程。

Result: 论文汇总了多种形式的界限，包括原始界限及其衍生形式。

Conclusion: 该综述为研究者提供了全面的参考界限及其证明，有助于相关领域的研究。

Abstract: This is a survey paper that discusses the original bounds of the seminal
papers by Chernoff and Hoeffding. Moreover, it includes a variety of derivative
bounds in a variety of forms. Complete proofs are provided as needed. The
intent is to provide a repository of reference bounds for the interested
researcher.

</details>
