<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 2]
- [math.OC](#math.OC) [Total: 13]
- [math.NT](#math.NT) [Total: 4]
- [math.LO](#math.LO) [Total: 5]
- [math.CO](#math.CO) [Total: 11]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [cs.CR](#cs.CR) [Total: 18]
- [cs.AI](#cs.AI) [Total: 26]
- [cs.DM](#cs.DM) [Total: 1]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [On the pointwise and sup-norm errors for local regression estimators](https://arxiv.org/abs/2507.07132)
*Jérémy Bettinger,François Portier,Adrien Saumard*

Main category: math.ST

TL;DR: 本文研究了基于局部平均的非参数回归估计器在Lipschitz回归函数估计中的行为，证明了形状规则性对达到极小极大收敛速率的必要性，并提出了几种数据依赖的局部映射估计器及其性能分析。


<details>
  <summary>Details</summary>
Motivation: 研究非参数局部回归估计器在固定点或sup-范数下估计Lipschitz回归函数的行为，旨在理解形状规则性对估计器收敛速率的影响。

Method: 首先证明了基于VC类集合索引的局部估计器的偏差界，引入了形状规则局部映射的概念；随后分析了基于数据依赖局部映射的特定估计器（如最近邻、CART改进算法等）的性能。

Result: 形状规则性是达到极小极大收敛速率的必要条件，且足以确保最优速率（至多对数因子）。新提出的改进CART算法在sup-范数下具有极小极大最优性。

Conclusion: 通过分析不同局部估计器的形状规则性，建立了基于纯随机树的局部估计器的概率界，揭示了估计器速率与其局部映射形状规则性的关系。

Abstract: In this paper, we analyze the behavior of various non-parametric local
regression estimators, i.e. estimators that are based on local averaging, for
estimating a Lipschitz regression function at a fixed point, or in sup-norm.
  We first prove some deviation bounds for local estimators that can be indexed
by a VC class of sets in the covariates space. We then introduce the general
concept of shape-regular local maps, corresponding to the situation where the
local averaging is done on sets which, in some sense, have ``almost isotropic''
shapes. On the one hand, we prove that, in general, shape-regularity is
necessary to achieve the minimax rates of convergence. On the other hand, we
prove that it is sufficient to ensure the optimal rates, up to some logarithmic
factors.
  Next, we prove some deviation bounds for specific estimators, that are based
on data-dependent local maps, such as nearest neighbors, their recent prototype
variants, as well as a new algorithm, which is a modified and generalized
version of CART, and that is minimax rate optimal in sup-norm. In particular,
the latter algorithm is based on a random tree construction that depends on
both the covariates and the response data. For each of the estimators, we
provide insights on the shape-regularity of their respective local maps.
Finally, we conclude the paper by establishing some probability bounds for
local estimators based on purely random trees, such as centered, uniform or
Mondrian trees. Again, we discuss the relations between the rates of the
estimators and the shape-regularity of their local maps.

</details>


### [2] [Computational barriers for permutation-based problems, and cumulants of weakly dependent random variables](https://arxiv.org/abs/2507.07946)
*Bertrand Even,Christophe Giraud,Nicolas Verzelen*

Main category: math.ST

TL;DR: 本文提出了一种处理弱依赖性问题的技术，通过上界累积量来突破现有方法在随机排列等问题中的限制，并在多特征匹配和序列问题中揭示了统计-计算差距的证据。


<details>
  <summary>Details</summary>
Motivation: 在高维问题中，多项式时间算法难以达到无计算约束下的统计极限。现有方法依赖潜在变量的独立性，无法处理随机排列等缺乏独立性的潜在结构问题。

Method: 开发了一种新技术，用于在弱依赖性（如无放回抽样或随机排列）条件下上界累积量，突破了独立性假设的限制。

Result: 该方法在多特征匹配和序列问题中有效，揭示了统计-计算差距的存在，证明了其在处理弱依赖性问题的优越性。

Conclusion: 通过上界累积量的新技术，本文成功解决了弱依赖性条件下的问题，为高维统计中的统计-计算差距研究提供了新工具。

Abstract: In many high-dimensional problems,polynomial-time algorithms fall short of
achieving the statistical limits attainable without computational constraints.
A powerful approach to probe the limits of polynomial-time algorithms is to
study the performance of low-degree polynomials. The seminal work of
arXiv:2008.02269 connects low-degree lower bounds to multivariate cumulants.
Prior works arXiv:2308.15728, arXiv:2506.13647 leverage independence among
latent variables to bound cumulants. However, such approaches break down for
problems with latent structure lacking independence, such as those involving
random permutations. To address this important restriction, we develop a
technique to upper-bound cumulants under weak dependencies, such as those
arising from sampling without replacement or random permutations. To show-case
the effectiveness of our approach, we uncover evidence of
statistical-computational gaps in multiple feature matching and in seriation
problems.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [3] [Secrecy Energy Efficiency Maximization in RIS-Aided Networks: Active or Nearly-Passive RIS?](https://arxiv.org/abs/2507.07241)
*Robert Kuku Fotock,Agbotiname Lucky Imoize,Alessio Zappone,Marco Di Renzo,Roberto Garello*

Main category: math.OC

TL;DR: 本文研究RIS辅助无线网络中保密能效(SEE)最大化问题，对比了有源与近无源RIS的性能差异，并开发了两种SEE优化算法。


<details>
  <summary>Details</summary>
Motivation: 探讨有源和近无源可重构智能表面(RIS)在保密能效方面的性能差异，为实际部署提供理论依据。

Method: 针对完美和统计信道状态信息，开发了两种算法来联合优化用户发射功率、RIS反射系数和基站接收滤波器。

Result: 数值结果表明，随着有源RIS反射单元静态功耗增加，其保密能效表现劣于近无源RIS。

Conclusion: 有源RIS与近无源RIS在保密能效上存在权衡，静态功耗是影响有源RIS性能的关键因素。

Abstract: This work addresses the problem of secrecy energy efficiency (SEE)
maximization in RIS-aided wireless networks. The use of active and
nearly-passive RISs are compared and their trade-off in terms of SEE is
analyzed. Considering both perfect and statistical channel state information,
two SEE maximization algorithms are developed to optimize the transmit powers
of the mobile users, the RIS reflection coefficients, and the base station
receive filters. Numerical results quantify the trade-off between active and
nearly-passive RISs in terms of SEE, with active RISs yielding worse SEE values
as the static power consumed by each reflecting element increases.

</details>


### [4] [Convergence and Robustness Bounds for Distributed Asynchronous Shortest-Path](https://arxiv.org/abs/2507.07263)
*Jared Miller,Mattia Bianchi,Florian Dörfler*

Main category: math.OC

TL;DR: 本文研究了异步分布式最短路径计算的收敛时间与鲁棒性边界，重点分析了自适应Bellman-Ford算法在异步环境下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 分布式系统中异步操作带来的不确定性（如节点空闲或竞争条件）可能影响最短路径算法的收敛性和鲁棒性，需要建立理论保障。

Method: 基于Lyapunov同步收敛理论，将有限时间收敛和鲁棒性边界扩展到异步场景，并研究了区间有界噪声下的异步最大概率路径算法。

Result: 为异步自适应Bellman-Ford算法建立了有限时间收敛保证和鲁棒性边界，同时证明了噪声环境下最大概率路径算法的收敛性。

Conclusion: 该研究为异步分布式最短路径计算提供了理论框架，其方法可推广至存在通信延迟和噪声的实际网络系统。

Abstract: This work analyzes convergence times and robustness bounds for asynchronous
distributed shortest-path computation. We focus on the Adaptive Bellman--Ford
algorithm, a self-stabilizing method in which each agent updates its
shortest-path estimate based only on the estimates of its neighbors and
forgetting its previous estimate. In the asynchronous framework considered in
this paper, agents are allowed to idle or encounter race conditions during
their execution of the Adaptive Bellman--Ford algorithm. We build on
Lyapunov-based results that develop finite-time convergence and robustness
bounds for the synchronous shortest-path setting, in order to produce
finite-time convergence and robustness bounds for the asynchronous setting. We
also explore robustness against interval-bounded noise processes and establish
convergence and robustness guarantees for asynchronous most-probable-path
algorithms.

</details>


### [5] [Combinatorial Algorithm for Tropical Linearly Factorized Programming](https://arxiv.org/abs/2507.07596)
*Yuki Nishida*

Main category: math.OC

TL;DR: 本文提出了一种新的热带优化问题——热带线性因子化规划问题，并设计了基于下降方法和切线有向图的高效算法。该算法在非退化情况下通过迭代更新树结构实现快速求解，并在整数实例中展示了多项式时间复杂度。


<details>
  <summary>Details</summary>
Motivation: 热带半环上的线性规划问题已有研究，但现有方法无法直接应用于目标函数为热带线性形式乘积的新型优化问题。本文旨在填补这一空白，提出并解决热带线性因子化规划问题。

Method: 算法基于下降方法，利用切线有向图确定可行下降方向。在非退化情况下，通过将切线有向图转化为生成树，设计类单纯形法进行迭代更新。每次迭代时间复杂度为$O(r_A+r_C)$，其中$r_A$、$r_C$分别为约束条件和目标函数的非零系数数量。

Result: 对于整数实例，算法可在$O((m+n)(r_A+r_C)MD)$时间内找到局部最优解，其中$n$为变量数，$m$为约束数，$M$为系数最大绝对值，$D$为目标函数次数。非退化情况下切线有向图呈现树结构特性显著提升了计算效率。

Conclusion: 本文提出的热带线性因子化规划算法有效解决了目标函数凸性（传统意义）与可行集凸性（热带意义）不一致的难题，为热带优化领域提供了新的理论工具和计算框架。

Abstract: The tropical semiring is a set of numbers $\mathbb{R}\cup\{-\infty\}$ with
addition $a\oplus b:=\max(a,b)$ and multiplication $a\otimes b:=a+b$. As well
as in conventional algebra, linear programming problem in the tropical semiring
has been developed. In this study, we introduce a new type of tropical
optimization problem, namely, tropical linearly factorized programming problem.
This problem involves minimizing the objective function given by the product of
tropical linear forms $c_{k,1}\otimes x_1\oplus \cdots\oplus c_{k,n}\otimes
x_n$ divided by a tropical monomial, subject to tropical linear inequality
constraints. The objective function is convex in the conventional sense but not
in the tropical sense, while the feasible set is convex in the tropical sense
but not in the conventional sense.
  Our algorithm for tropical linearly factorized programming is based on the
descent method and exploits tangent digraphs. First, we demonstrate that the
feasible descent direction at the current solution can be obtained by solving
the minimum $s$-$t$ cut problem on a specific subgraph of the tangent digraph.
Although exponentially many such digraphs may exist in general, a more
efficient algorithm is devised in cases where the problem is non-degenerate.
Focusing on the fact that tangent digraphs become spanning trees in
non-degenerate cases, we present a simplex-like algorithm that updates the tree
structure iteratively. We show that each iteration can be executed in
$O(r_A+r_C)$ time, where $r_A$ and $r_C$ are the numbers of ``non-zero''
coefficients in the linear constraints and objective function, respectively.
For integer instances, our algorithm finds a local optimum in
$O((m+n)(r_A+r_C)MD)$ time, where $n$ and $m$ are the number of decision
variables and constraints, respectively, $M$ is the maximum absolute value of
coefficients and $D$ is the degree of the objective function.

</details>


### [6] [Almost Sure Convergence for the Last Iterate of Stochastic Gradient Descent Schemes](https://arxiv.org/abs/2507.07281)
*Marcel Hudiani*

Main category: math.OC

TL;DR: 本文研究了随机梯度下降(SGD)和随机重球法(SHB)在参数化设置下的最终迭代几乎必然收敛速率，适用于全局凸或梯度满足$\gamma$-H\"{o}lder条件的非凸目标函数。


<details>
  <summary>Details</summary>
Motivation: 旨在通过简化分析工具（仅使用离散Gronwall不等式），统一推导SGD和SHB在凸/非凸场景下的收敛速率，并验证SHB在恒定动量参数下的概率收敛界。

Method: 采用离散Gronwall不等式替代传统的Robbins-Siegmund定理或鞅收敛理论，分析步长$\alpha_t = \Theta(t^{-p})$下SGD/SHB的迭代行为。

Result: 对于非凸目标获得$\min_{s\leq t} \|\nabla F(w_s)\|^2 = o(t^{p-1})$；凸目标下SHB以概率$1-\delta$达到$O(t^{\max(p-1,-2p+1)} \log^2 \frac{t}{\delta})$收敛率，且$\gamma=1$时$F(w_t)-F_*$的显式速率被证明。

Conclusion: 该方法简化了收敛分析框架，统一覆盖凸/非凸情形，并证实SHB恒定动量在适当步长下具有概率收敛保障，为随机优化算法理论提供了新见解。

Abstract: We study the almost sure convergence rate for the last iterate of stochastic
gradient descent (SGD) and stochastic heavy ball (SHB) in the parametric
setting when the objective function $F$ is globally convex or non-convex whose
gradient is $\gamma$-H\"{o}lder. Using only discrete Gronwall's inequality
without Robbins-Siegmund theorem nor martingale convergence theory, we recover
results for both SGD and SHB: $\min_{s\leq t} \|\nabla F(w_s)\|^2 = o(t^{p-1})$
for non-convex objectives and $F(w_t) - F_* = o(t^{2\gamma/(1+\gamma) \cdot
\max(p-1,-2p+1)-\epsilon})$ for $\beta \in (0, 1)$ and $\min_{s \leq t} F(w_s)
- F_* = o(t^{p-1})$ almost surely for convex objectives. In addition, we proved
that SHB with constant momentum parameter $\beta \in (0, 1)$ attains a
convergence rate of $F(w_t) - F_* = O(t^{\max(p-1,-2p+1)} \log^2
\frac{t}{\delta})$ with probability at least $1-\delta$ when $F$ is convex and
$\gamma = 1$ and step size $\alpha_t = \Theta(t^{-p})$ with $p \in
(\frac{1}{2}, 1)$.

</details>


### [7] [Qualitative and Generalized Differentiation Properties of Optimal Value Functions with Applications to Duality](https://arxiv.org/abs/2507.07377)
*Vo Si Trong Long,Nguyen Mau Nam,Len White*

Main category: math.OC

TL;DR: 本文研究了扰动优化问题中最优值函数的一般和广义微分性质，分析了其有效域、上镜图、严格上镜图、凸性、近凸性、连续性及Lipschitz型行为，并提出了基于集值映射Fenchel共轭的对偶框架，最后计算了最优值函数及其Fenchel共轭的$\epsilon$-次微分。


<details>
  <summary>Details</summary>
Motivation: 探讨扰动优化问题中最优值函数的微分性质，为凸与非凸情形下的优化问题提供理论支持，扩展对偶理论的应用范围。

Method: 通过分析最优值函数的有效域、上镜图等性质，提出基于集值映射Fenchel共轭的对偶框架，并计算$\epsilon$-次微分。

Result: 在凸与非凸情形下，全面刻画了最优值函数的微分性质，建立了新的对偶理论框架，并成功计算了$\epsilon$-次微分。

Conclusion: 本研究为扰动优化问题提供了系统的微分分析工具，扩展了对偶理论的应用场景，为后续研究奠定了理论基础。

Abstract: In this paper, we investigate general and generalized differentiation
properties of theoptimal value function associated with perturbed optimization
problems. We begin with a comprehensive analysis of its effective domain,
epigraph, strict epigraph, convexity, near convexity, continuity, and
Lipschitz-type behavior, in both convex and nonconvex settings. Next, we
propose a duality framework for constrained optimization problems with
set-valued constraints, based on the notion of the Fenchel conjugate for
set-valued mappings, which offers new insights into duality theory in a broad
context. Finally, we compute the {\epsilon}-subdifferentials of the optimal
value function and its Fenchel conjugate.

</details>


### [8] [Relocated Fixed-Point Iterations with Applications to Variable Stepsize Resolvent Splitting](https://arxiv.org/abs/2507.07428)
*Felipe Atenas,Heinz H. Bauschke,Minh N. Dao,Matthew K. Tam*

Main category: math.OC

TL;DR: 本文提出了一种适用于非扩张算子迭代算法的收敛性框架，无需算子族具有共同不动点，并应用于Douglas-Rachford算法的图扩展版本。


<details>
  <summary>Details</summary>
Motivation: 现有收敛性分析通常要求非扩张算子族具有共同不动点，限制了算法应用范围。本文旨在放宽这一限制条件。

Method: 采用参数化非扩张算子的半闭性原理扩展，设计了两步迭代框架：主算子步骤后接'重定位'步骤调整不动点。

Result: 所提框架成功应用于变参数Douglas-Rachford算法，可求解$N\geq 2$个极大单调算子和的零点问题。

Conclusion: 新框架突破了传统共同不动点的限制，为更广泛的非扩张算子迭代算法提供了收敛性保证。

Abstract: In this work, we develop a convergence framework for iterative algorithms
whose updates can be described by a one-parameter family of nonexpansive
operators. Within the framework, each step involving one of the main
algorithmic operators is followed by a second step which ''relocates''
fixed-points of the current operator to the next. As a consequence, our
analysis does not require the family of nonexpansive operators to have a common
fixed-point, as is common in the literature. Our analysis uses a parametric
extension of the demiclosedness principle for nonexpansive operators. As an
application of our convergence results, we develop a version of the graph-based
extension of the Douglas--Rachford algorithm for finding a zero of the sum of
$N\geq 2$ maximally monotone operators, which does not require the resolvent
parameter to be constant across iterations.

</details>


### [9] [On the local null controllability of a viscous Burgers' system in finite time](https://arxiv.org/abs/2507.07442)
*Hoai-Minh Nguyen,Minh-Nguyen Tran*

Main category: math.OC

TL;DR: 本文证明了在有限时间内Burgers控制系统$y_t - y_{xx} + y y_x = u(t)$在零Dirichlet边界条件下不具有局部零可控性。


<details>
  <summary>Details</summary>
Motivation: Marbach的研究表明Burgers控制系统在小时间内不具有局部零可控性，本文旨在探讨该系统在有限时间内是否具有这一性质。

Method: 研究方法受到Coron、Koenig和Nguyen关于KdV系统可控性工作的启发，与Marbach的方法不同。

Result: 研究结果表明，Burgers控制系统在有限时间内同样不具有局部零可控性。

Conclusion: 本文通过不同的方法验证了Burgers控制系统在有限时间内局部零可控性的缺失，扩展了Marbach的研究结论。

Abstract: This paper is devoted to the local null controllability of the Burgers
control system $y_t - y_{xx} + y y_x = u(t)$ on a bounded interval imposed by
the zero Dirichlet boundary condition. It is known from the work of Marbach
that this control system is not locally null controllable in small time. In
this paper, we prove that the system is not locally null controllable in finite
time as well. Our approach is inspired by the works of Coron, Koenig, and
Nguyen, and Nguyen on the controllability of the KdV system and is different
from the one of Marbach.

</details>


### [10] [An Adaptive Order Caputo Fractional Gradient Descent Method for Multi-objective Optimization Problems](https://arxiv.org/abs/2507.07674)
*Barsha Shaw,Md Abu Talhamainuddin Ansary*

Main category: math.OC

TL;DR: 本文提出了一种多目标自适应阶Caputo分数阶梯度下降（MOAOCFGD）算法，用于解决无约束多目标优化问题，适用于光滑与非光滑问题，无需预设参数或目标函数排序信息。


<details>
  <summary>Details</summary>
Motivation: 针对多目标优化问题中传统方法对光滑性要求高且依赖预设参数的局限性，提出一种自适应阶分数阶梯度方法以提升适用性与灵活性。

Method: 算法通过求解含自适应阶Caputo分数阶梯度的子问题确定下降方向，结合Armijo型线搜索选择步长，并证明了Tikhonov正则化解的收敛性。

Result: 数值实验（包括神经网络问题）验证了该方法的有效性，表明其在光滑与非光滑场景下均表现良好。

Conclusion: MOAOCFGD算法为多目标优化提供了一种无需先验参数的自适应解决方案，其理论收敛性与广泛适用性通过实验得到证实。

Abstract: This article introduces the multi-objective adaptive order Caputo fractional
gradient descent (MOAOCFGD) algorithm for solving unconstrained multi-objective
problems. The proposed method performs equally well for both smooth and
non-smooth multi-objective optimization problems. Moreover, the proposed method
does not require any a priori chosen parameters or ordering information of the
objective functions. At every iteration of the proposed method, a subproblem is
solved to identify a suitable descent direction toward an optimal solution.
This subproblem involves an adaptive-order Caputo fractional gradient for each
objective function. An Armijo-type line search is applied to determine a
suitable step length. The convergence of this method for the
Tikhonov-regularized solution is justified under mild assumptions. The proposed
method is verified using different numerical problems, including neural
networks.

</details>


### [11] [Efficient Stochastic BFGS methods Inspired by Bayesian Principles](https://arxiv.org/abs/2507.07729)
*André Carlon,Luis Espath,Raúl Tempone*

Main category: math.OC

TL;DR: 本文提出了一种基于贝叶斯推断的新型随机拟牛顿方法（S-BFGS和L-S-BFGS），能够在噪声梯度环境下高效学习逆Hessian近似，并在高维问题上展现出优异的计算效率与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统拟牛顿法依赖精确梯度信息，而随机优化中仅能获取带噪声的梯度观测。现有方法多通过修改确定性方程规避噪声，本文创新性地采用贝叶斯框架直接融合噪声梯度信息。

Method: 通过贝叶斯推断推导随机拟牛顿法，重点构建随机BFGS（S-BFGS）和随机L-BFGS（L-S-BFGS）。S-BFGS单次迭代复杂度为$\bigO{d^2}$，L-S-BFGS为$\bigO{d}$，适用于小批量场景。

Result: 在维度高达30,720的数值实验中，所提方法能有效学习逆Hessian近似，展现出优于传统方法的计算效率（S-BFGS $\bigO{d^2}$，L-S-BFGS $\bigO{d}$）和鲁棒性。

Conclusion: 基于贝叶斯框架的随机拟牛顿法成功解决了噪声梯度环境下的二阶导数逼近问题，其方法论可推广至其他拟牛顿变体，为大规模随机优化提供了新工具。

Abstract: Quasi-Newton methods are ubiquitous in deterministic local search due to
their efficiency and low computational cost. This class of methods uses the
history of gradient evaluations to approximate second-order derivatives.
However, only noisy gradient observations are accessible in stochastic
optimization; thus, deriving quasi-Newton methods in this setting is
challenging. Although most existing quasi-Newton methods for stochastic
optimization rely on deterministic equations that are modified to circumvent
noise, we propose a new approach inspired by Bayesian inference to assimilate
noisy gradient information and derive the stochastic counterparts to standard
quasi-Newton methods. We focus on the derivations of stochastic BFGS and
L-BFGS, but our methodology can also be employed to derive stochastic analogs
of other quasi-Newton methods. The resulting stochastic BFGS (S-BFGS) and
stochastic L-BFGS (L-S-BFGS) can effectively learn an inverse Hessian
approximation even with small batch sizes. For a problem of dimension $d$, the
iteration cost of S-BFGS is $\bigO{d^2}$, and the cost of L-S-BFGS is
$\bigO{d}$. Numerical experiments with a dimensionality of up to $30,720$
demonstrate the efficiency and robustness of the proposed method.

</details>


### [12] [A Model-Free Extremum Seeking Controller with Application to Tracking a Nonlinear Chemical Reaction](https://arxiv.org/abs/2507.07749)
*Alexander Zuyev,Victoria Grushkovska*

Main category: math.OC

TL;DR: 本文提出了一种极值搜索方法，用于在状态空间中给定参考曲线附近生成可接受轨迹，应用于非线性化学反应的最优轨迹跟踪问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于非线性化学反应等参量优化问题中，需要最大化特定时间段内平均反应产物，这类问题自然产生作为参考曲线的优化轨迹。

Method: 采用极值搜索控制设计，通过将问题成本函数定义为当前系统状态与时间参数化参考曲线之间的距离，实现在参考曲线邻域内的轨迹生成。

Result: 将所提方法应用于非等温反应模型，数值模拟结果展示了系统的跟踪误差表现。

Conclusion: 研究表明，极值搜索方法能有效生成参考曲线附近的可行轨迹，为非线性化学反应的优化控制提供了新思路。

Abstract: In this paper, we develop the extremum-seeking approach to generate
admissible trajectories in a neighborhood of a given reference curve in the
state space. The cost function of the problem represents the distance between
the current system state and the reference curve, which is parameterized as a
function of time. Such reference curves naturally arise as optimal trajectories
in isoperimetric optimization problems for nonlinear chemical reactions, where
the objective is to maximize the average reaction product over a given period.
We apply the proposed extremum seeking control design to a nonisothermal
reaction model and illustrate the resulting tracking errors through numerical
simulations.

</details>


### [13] [Dissipativity-based time domain decomposition for optimal control of hyperbolic PDEs](https://arxiv.org/abs/2507.07812)
*Bálint Farkas,Birgit Jacob,Manuel Schaller,Merlin Schmitz*

Main category: math.OC

TL;DR: 提出基于半群理论的时间域分解方法，用于偏微分方程的最优控制，通过解耦实现高效并行计算，并在波方程和热方程中验证了方法的收敛性和效率。


<details>
  <summary>Details</summary>
Motivation: 针对偏微分方程最优控制问题，传统方法计算复杂度高，难以并行化，需要一种高效且通用的解决方案。

Method: 将最优控制系统（状态方程和伴随方程）表述为耗散算子的和，采用Peaceman-Rachford型固定点迭代，实现时间分布的解耦最优控制问题并行求解。

Result: 证明了状态、控制及伴随状态在函数空间中的收敛性，适用于双曲型方程（如波方程），并通过2D波方程和3D热方程的数值算例验证了方法的有效性。

Conclusion: 该方法在$C_0$-(半)群框架下具有广泛适用性，尤其适合双曲方程，为大规模PDE最优控制问题提供了高效并行计算途径。

Abstract: We propose a time domain decomposition approach to optimal control of partial
differential equations (PDEs) based on semigroup theoretic methods. We
formulate the optimality system consisting of two coupled forward-backward
PDEs, the state and adjoint equation, as a sum of dissipative operators, which
enables a Peaceman-Rachford-type fixed-point iteration. The iteration steps may
be understood and implemented as solutions of many decoupled, and therefore
highly parallelizable, time-distributed optimal control problems. We prove the
convergence of the state, the control, and the corresponding adjoint state in
function space. Due to the general framework of $C_0$-(semi)groups, the results
are particularly well applicable, e.g., to hyperbolic equations, such as beam
or wave equations. We illustrate the convergence and efficiency of the proposed
method by means of two numerical examples subject to a 2D wave equation and a
3D heat equation.

</details>


### [14] [Complexity Analysis of a Bicriteria Directed Multimodal Transportation Network Design Problem](https://arxiv.org/abs/2507.07894)
*Dominik Leib,Susanne Fritzler,Neele Leithäuser*

Main category: math.OC

TL;DR: 本文研究了城乡公共交通规划中的双标准网络设计问题，证明了该问题的复杂性和不可近似性，并识别了可实现近似解的特殊情况。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于城乡公共交通规划中的实际需求，旨在填补双标准决策与网络设计交叉领域的研究空白。

Method: 通过借鉴有向网络设计问题的复杂性结果，采用理论证明方法分析问题特性。

Result: 证明了问题的NP难特性及不可近似性，同时发现了允许近似算法的特殊情形。

Conclusion: 该研究为实践者提供了重要参考，深化了对双标准网络设计问题复杂性的理解。

Abstract: In this paper, we address a bicriteria network design problem that arises
from practical applications in urban and rural public transportation planning.
We establish the problem's complexity and demonstrate inapproximability
results, highlighting the inherent difficulties in finding optimal solutions.
Additionally, we identify special cases where approximability can be achieved,
providing valuable insights for practitioners. Our proofs leverage complexity
results related to directed network design problems, an area that has received
limited attention in the existing literature. By investigating these complexity
results, we aim to fill a critical gap and enhance the understanding of the
interplay between bicriteria decision-making and network design challenges.

</details>


### [15] [Convergence rates for regularized unbalanced optimal transport: the discrete case](https://arxiv.org/abs/2507.07917)
*Luca Nenna,Paul Pegon,Louis Tocquec*

Main category: math.OC

TL;DR: 本文研究了不平衡最优运输(UOT)的正则化运输成本与运输方案的收敛速率问题，针对加权Dirac质量和的测度情形。


<details>
  <summary>Details</summary>
Motivation: UOT作为最优运输(OT)的扩展，允许比较不同质量的测度，在机器学习中具有对异常值的鲁棒性优势。

Method: 通过正则化方法，分析UOT问题中运输成本与运输方案向原始解的收敛行为，研究对象为加权Dirac质量和构成的测度。

Result: 获得了正则化UOT问题在Dirac测度情形下的收敛速率理论结果。

Conclusion: 该研究为UOT在机器学习中的应用提供了理论支撑，特别是在处理异常值时的正则化参数选择方面具有指导意义。

Abstract: Unbalanced optimal transport (UOT) is a natural extension of optimal
transport (OT) allowing comparison between measures of different masses. It
arises naturally in machine learning by offering a robustness against outliers.
The aim of this work is to provide convergence rates of the regularized
transport cost and plans towards their original solution when both measures are
weighted sums of Dirac masses.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [16] [Asymptotic properties of zeros of Riemann zeta function](https://arxiv.org/abs/2507.07253)
*Juan Arias de Reyna,Yves Meyer*

Main category: math.NT

TL;DR: 本文探讨了黎曼ζ函数非平凡零点序列的内在性质，提出了一个渐近关系式，并研究是否存在其他实数或复数序列满足相同性质。


<details>
  <summary>Details</summary>
Motivation: 研究黎曼ζ函数零点序列的独特数学特性，探索是否存在其他序列具有类似的渐近关系，以深化对该函数性质的理解。

Method: 通过假设黎曼猜想成立，将非平凡零点表示为$z_k= 1/2+i\tau_k$，推导出序列$(\tau_k)$满足的渐近关系式，并分析其数学结构。

Result: 建立了零点序列$(\tau_k)$与特定渐近展开式之间的对应关系，其中系数$a_n$由伯努利数$B_{2n}$和欧拉数$E_{2n}$的组合给出。

Conclusion: 该研究为黎曼ζ函数零点提供了新的特征化方法，但尚未确定是否存在其他序列满足相同渐近性质，这为未来研究指明了方向。

Abstract: We try to define the sequence of zeros of the Riemann zeta function by an
intrinsic property. Let $(z_k)_{k\in \mathbb{N}}$ be the sequence of nontrivial
zeros of $\zeta(s)$ with positive imaginary part. We write $z_k= 1/2+i\tau_k$
(RH says that these $\tau_k$ are all real). Then the sequence $(\tau_k)_{k\in
\mathbb{N}},$ satisfies the following asymptotic relation
\[\sum_{k\in\mathbb{N}}\frac{2x}{x^2+\tau_k^2}\simeq
\frac12\log\frac{x}{2\pi}+\sum_{n=1}^\infty \frac{a_n}{x^n},\,\,x\to +\infty\]
where $a_{2n+1}=2^{-2n-2}(8-E_{2n})$, $a_{2n}=(1-2^{-2n+1})B_{2n}/(4n).$ Are
there other sequences $(\alpha_k)_{k\in \mathbb{N}},$ of real or complex
numbers enjoying this property? These problems are addressed in this note.

</details>


### [17] [An Equivalent Representation of Generalized Differentials](https://arxiv.org/abs/2507.07337)
*Valentin Suder*

Main category: math.NT

TL;DR: 本文提出了一种用于研究任意特征$p$有限域上广义几乎完美非线性函数高阶导数的等价公式，并通过计算具有固定基数且元素和为常数的子集数量获得结果，同时探讨了高阶导数的多样性相关问题。


<details>
  <summary>Details</summary>
Motivation: 研究广义几乎完美非线性函数的高阶导数是密码学中的重要问题，现有方法在任意特征有限域上的应用存在局限性，需要更通用的等价公式。

Method: 通过组合数学方法，计算特征$p$有限域中满足特定基数且元素和恒定的子集数量，从而推导出高阶导数的等价表达式。

Result: 成功建立了适用于任意特征$p$有限域的广义几乎完美非线性函数高阶导数的通用等价公式，并提出了关于导数多样性的开放性问题。

Conclusion: 该公式为研究广义几乎完美非线性函数提供了新工具，同时提出的多样性问题为未来研究指明了方向，具有重要的理论价值。

Abstract: We propose an equivalent formula for the higher-order derivatives used in the
study of Generalized Almost Perfect Nonlinear functions over an arbitrary
finite field of characteristic $p$. The result is obtained by counting the
number of subsets of the prime field with a fixed cardinality for which the sum
of their elements is constant. We then ask related questions regarding the
diversity of higher-order derivatives.

</details>


### [18] [Higher Hida theory for Drinfeld modular curves](https://arxiv.org/abs/2507.07423)
*Daniel Barrera Salazar,Héctor del Castillo,Giovanni Rosso*

Main category: math.NT

TL;DR: 本文基于Boxer和Pilloni的高阶Hida理论，为Drinfeld模曲线上的线束上同调发展了高阶Hida理论，并插值了Serre对偶性。


<details>
  <summary>Details</summary>
Motivation: 受Boxer和Pilloni高阶Hida理论构造的启发，研究Drinfeld模形式线束上同调的高阶理论。

Method: 采用高阶Hida理论的方法，对Drinfeld模曲线上的线束上同调进行理论构建。

Result: 成功发展了Drinfeld模曲线上的高阶Hida理论，并实现了Serre对偶性的插值。

Conclusion: 该研究扩展了高阶Hida理论的应用范围，为Drinfeld模形式的上同调理论提供了新的工具。

Abstract: Inspired by the construction of Higher Hida theory of Boxer and Pilloni, we
develop Higher Hida theory for the cohomology of the line bundles of Drinfeld
modular forms on the Drinfeld modular curve. We also interpolate Serre duality.

</details>


### [19] [Prime Power Residues and Blocking Sets](https://arxiv.org/abs/2507.07673)
*Bhawesh Mishra,Paolo Santonastaso*

Main category: math.NT

TL;DR: 研究证明了有限整数集$B$在几乎所有素数下包含$q$次幂的条件与射影几何中的阻塞集等价，建立了伽罗瓦几何与数论的联系，并分类了最小集合$B$的尺寸界限。


<details>
  <summary>Details</summary>
Motivation: 探索有限整数集$B$在几乎所有素数下包含$q$次幂的充要条件，并建立其与射影几何中阻塞集的联系，以连接伽罗瓦几何与数论两个领域。

Method: 通过分析$B$中元素的$q$无平方部分的质因数数量$k$，将问题转化为射影空间$\mathrm{PG}(\mathbb{F}_{q}^{k})$中关于超平面的阻塞集问题，并利用射影一般线性群$\mathrm{PGL}(\mathbb{F}_{q}^{k})$的几何等价性进行研究。

Result: 证明了$B$在几乎所有素数下包含$q$次幂当且仅当$B$对应于射影几何中的阻塞集，且该性质在几何$q$等价下不变，同时分类并给出了最小集合$B$的尺寸界限。

Conclusion: 通过建立伽罗瓦几何与数论的联系，本文不仅分类了满足条件的集合$B$，还提供了其最小尺寸的界限，为两个领域的交叉研究提供了新的视角。

Abstract: Let $q$ be a fixed odd prime. We show that a finite subset $B$ of integers,
not containing any perfect $q^{th}$ power, contains a $q^{th}$ power modulo
almost every prime if and only if $B$ corresponds to a blocking set (with
respect to hyperplanes) in $\mathrm{PG}(\mathbb{F}_{q}^{k})$. Here, $k$ is the
number of distinct prime divisors of $q$-free parts of elements of $B$. As a
consequence, the property of a subset $B$ to contain $q^{th}$ power modulo
almost every prime $p$ is invariant under geometric $q$-equivalence defined by
an element of the projective general linear group
$\mathrm{PGL}(\mathbb{F}_{q}^{k})$. Employing this connection between two
disparate branches of mathematics, Galois geometry and number theory, we
classify, and provide bounds on the sizes of, minimal such sets $B$.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [20] [A 2-categorical approach to the semantics of dependent type theory with computation axioms](https://arxiv.org/abs/2507.07208)
*Matteo Spadetto*

Main category: math.LO

TL;DR: 本文从高阶范畴论角度研究了公理型类型理论的语义，通过2-范畴模型（显示映射2-范畴）呈现其语义，并证明该解释具有良好的定义性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 公理型类型理论缺乏计算规则，传统通过项等式判断描述的方式被计算公理替代。为有效描述其语义，需解决将内涵类型构造器编码为一维范畴术语的挑战。

Method: 采用Richard Garner的二维范畴方法，将公理型理论的类型构造器编码为自然二维范畴数据，构建显示映射2-范畴模型。相较于内涵类型，公理型的二维范畴要求更为宽松。

Result: 主要结果表明：公理型理论在显示映射2-范畴中的解释具有良好定义性且满足可靠性。通过重构Hofmann和Streicher的群胚模型，语义验证了内涵恒等类型的计算规则在公理型理论中不可接纳。

Conclusion: 研究不仅推广了Garner对内涵类型的语义框架，还通过具体模型证实了公理型恒等类型与内涵型的本质差异，为类型理论的语义研究提供了新工具。

Abstract: Axiomatic type theory is a dependent type theory without computation rules.
The term equality judgements that usually characterise these rules are replaced
by computation axioms, i.e., additional term judgements that are typed by
identity types. This paper is devoted to providing an effective description of
its semantics, from a higher categorical perspective: given the challenge of
encoding intensional type formers into 1-dimensional categorical terms and
properties, a challenge that persists even for axiomatic type formers, we adopt
Richard Garner's approach in the 2-dimensional study of dependent types. We
prove that the type formers of axiomatic theories can be encoded into natural
2-dimensional category theoretic data, obtaining a presentation of the
semantics of axiomatic type theory via 2-categorical models called display map
2-categories. In the axiomatic case, the 2-categorical requirements identified
by Garner for interpreting intensional type formers are relaxed. Therefore, we
obtain a presentation of the semantics of the axiomatic theory that generalises
Garner's one for the intensional case. Our main result states that the
interpretation of axiomatic theories within display map 2-categories is
well-defined and enjoys the soundness property. We use this fact to provide a
semantic proof that the computation rule of intensional identity types is not
admissible in axiomatic type theory. This is achieved via a revisitation of
Hofmann and Streicher's groupoid model that believes axiomatic identity types
but does not believe intensional ones.

</details>


### [21] [Generalized Tukey reducibility between $σ$-directed sets](https://arxiv.org/abs/2507.07309)
*Hiroshi Sakai,Toshimasa Tanno*

Main category: math.LO

TL;DR: 本文提出了一种称为pre-Tukey可约性的新概念，它是Tukey可约性在定向集上的推广，适用于$\mathsf{ZF}$系统。研究了在Solovay模型和满足$\mathsf{AD}$的$L(\mathbb{R})$中，基于实数集假设下的多个$\sigma$-定向集之间的pre-Tukey可约性。


<details>
  <summary>Details</summary>
Motivation: 为了在$\mathsf{ZF}$系统中扩展Tukey可约性的应用范围，研究不同假设下定向集之间的可约性关系。

Method: 引入pre-Tukey可约性概念，并在Solovay模型和满足$\mathsf{AD}$的$L(\mathbb{R})$中，分析$\sigma$-定向集之间的可约性。

Result: 在特定集合论假设下，多个$\sigma$-定向集之间存在pre-Tukey可约性关系。

Conclusion: pre-Tukey可约性为研究定向集关系提供了新工具，尤其在$\mathsf{ZF}$系统和特定模型中有良好表现。

Abstract: We introduce the pre-Tukey reducibility, a generalization of the Tukey
reducibility between directed sets that works well in $\mathsf{ZF}$. We
investigate the pre-Tukey reducibility between several $\sigma$-directed sets
under assumptions on sets of reals, which hold in the Solovay model and in
$L(\mathbb{R})$ satisfying $\mathsf{AD}$.

</details>


### [22] [On the lack of colimits in various categories of BAOs and Heyting algebras](https://arxiv.org/abs/2507.07489)
*Marco Abbadini,Guram Bezhanishvili,Luca Carai*

Main category: math.LO

TL;DR: 论文证明了几类带有稳定态射的BAO（带算子的布尔代数）范畴不是余完备的，包括Heyting代数、框架等范畴，进而得出它们不等价于代数预簇或簇，特别是解决了关于McKinsey-Tarski代数的一个问题。


<details>
  <summary>Details</summary>
Motivation: 研究不同代数范畴的完备性问题，特别是探讨Heyting代数、框架等范畴是否具有余完备性，以及它们是否能等价于代数预簇或簇，解决Peter Jipsen提出的关于McKinsey-Tarski代数的问题。

Method: 通过数学证明，分析各类BAO范畴（如Heyting代数、框架等）的余完备性，并考察它们与代数预簇或簇的等价关系。

Result: 证明了几类BAO范畴（包括Heyting代数、框架等）不是余完备的，且不等价于代数预簇或簇，特别是McKinsey-Tarski代数范畴也不等价于簇。

Conclusion: 这些范畴的余完备性和等价性被否定，特别是McKinsey-Tarski代数范畴不等价于簇，回答了Peter Jipsen的问题。

Abstract: We prove that various categories of BAOs (boolean algebras with an operator)
with stable morphisms between them are not cocomplete, and that neither are the
category of Heyting algebras with bounded lattice morphisms, its full
subcategory consisting of frames, and the category of frames with Heyting
morphisms. As a consequence, none of these categories is equivalent to a
prevariety of algebras, let alone a variety. In particular, we obtain that the
category of McKinsey-Tarski algebras is not equivalent to a variety, thus
answering a question by Peter Jipsen in the negative.

</details>


### [23] [Ramsey-like theorems for separable permutations](https://arxiv.org/abs/2507.07606)
*Quentin Le Houérou,Ludovic Patey*

Main category: math.LO

TL;DR: 本文研究了无限团边着色中避免特定模式的无限子团的可计算性，重点分析了可分离排列模式的计算特性及其与标准模型中无限齐次集存在性的等价关系。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索无限团边着色中避免特定模式（尤其是可分离排列）的无限子团存在性的计算理论特性，以及这些模式在标准模型中的表现。

Method: 方法包括对可分离排列模式的计算特性分析，以及开发了一种新的相对化对角线非计算论证技术。

Result: 结果表明，避免任何可分离排列模式等价于标准模型中无限齐次集的存在性，而这一性质对其他模式不成立。

Conclusion: 结论指出可分离排列模式在计算理论中具有独特地位，其避免性与无限齐次集存在性等价，为相关计算理论问题提供了新的视角。

Abstract: We conduct a computability-theoretic study of Ramsey-like theorems of the
form "Every coloring of the edges of an infinite clique admits an infinite
sub-clique avoiding some pattern", with a particular focus on transitive
patterns. As it turns out, the patterns corresponding to separable permutations
play an important role in the computational features of the statement. We prove
that the avoidance of any separable permutation is equivalent to the existence
of an infinite homogeneous set in standard models, while this property fails
for any other pattern. For this, we develop a novel argument for relativized
diagonal non-computation.

</details>


### [24] [Hyper-u-amenablity and Hyperfiniteness of Treeable Equivalence Relations](https://arxiv.org/abs/2507.07891)
*Petr Naryshkin,Andrea Vaccaro*

Main category: math.LO

TL;DR: 本文引入了u-可顺从性和超u-可顺从性的概念，证明了树状超u-可顺从的可数Borel等价关系是超有限的，并得出若干推论。


<details>
  <summary>Details</summary>
Motivation: 研究可数Borel等价关系的强可顺从性形式，特别是由超有限性所蕴含的性质，以深化对等价关系分类的理解。

Method: 引入u-可顺从性和超u-可顺从性概念，通过分析树状结构和群作用，证明超有限性的充分条件。

Result: 证明了树状超u-可顺从的可数Borel等价关系是超有限的，并得出自由群作用或可顺从群作用下的超有限性推论。

Conclusion: 树状且满足特定可顺从条件的可数Borel等价关系具有超有限性，扩展了超有限等价关系的判定范围。

Abstract: We introduce the notions of u-amenability and hyper-u-amenability for
countable Borel equivalence relations, strong forms of amenability that are
implied by hyperfiniteness. We show that treeable, hyper-u-amenable countable
Borel equivalence relations are hyperfinite. One of the corollaries that we get
is that if a countable Borel equivalence relation is measure-hyperfinite and
equal to the orbit equivalence relation of a free continuous action of a free
group (with $k \ge 2$ or $k = \infty$ generators) on a $\sigma$-compact Polish
space, then it is hyperfinite. We also obtain that if a countable Borel
equivalence relation is treeable and equal to the orbit equivalence relation of
a Borel action of an amenable group on a standard Borel space, or if it is
treeable, amenable and Borel bounded, then it is hyperfinite.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [25] [Statistics on $\ell$-interval parking functions](https://arxiv.org/abs/2507.07243)
*Kyle Celano,Jennifer Elder,Kimberly P. Hadaway,Pamela E. Harris,Jeremy L. Martin,Amanda Priestley,Gabe Udell*

Main category: math.CO

TL;DR: 本文研究了$\ell$-间隔停车函数的枚举问题，探讨了其与反转、位移和主指标等统计量的关系，并证明了特定条件下的循环筛选现象和统计量等分布性质。


<details>
  <summary>Details</summary>
Motivation: 研究$\ell$-间隔停车函数的统计特性，特别是位移、反转和主指标等统计量的分布规律，以深化对组合数学中停车函数结构的理解。

Method: 通过枚举和组合分析，研究了$\ell$-间隔停车函数的统计量分布，并利用Foata双射验证了特定条件下统计量的等分布性质。

Result: 证明了1-间隔停车函数在固定位移下呈现循环筛选现象，给出了固定反转数的1-间隔停车函数的闭式公式，并确定了Foata双射保持$\ell$-间隔停车函数集合的条件。

Conclusion: 当$\ell\leq 2$或$\ell\geq n-2$时，Foata双射保持$\ell$-间隔停车函数集合，此时反转和主指标统计量等分布。

Abstract: The displacement of a car with respect to a parking function is the number of
spots it must drive past its preferred spot in order to park. An
$\ell$-interval parking function is one in which each car has displacement at
most $\ell$. Among our results, we enumerate $\ell$-interval parking functions
with respect to statistics such as inversion, displacement, and major index. We
show that $1$-interval parking functions with fixed displacement exhibit a
cyclic sieving phenomenon. We give closed formulas for the number of
$1$-interval parking functions with a fixed number of inversions. We prove that
a well-known bijection of Foata preserves the set of $\ell$-interval parking
functions exactly when $\ell\leq 2$ or $\ell\geq n-2$, which implies that the
inversion and major index statistics are equidistributed in these cases.

</details>


### [26] [A simple proof of a $(p,2)$-theorem for non-piercing regions](https://arxiv.org/abs/2507.07269)
*Chaya Keller,Shakhar Smorodinsky*

Main category: math.CO

TL;DR: 本文证明在更一般的情况下，满足$(p,2)$-性质的平面非穿透区域族可用$O(p)$点刺穿，基于已知的遗传线性Delaunay图超图结果。


<details>
  <summary>Details</summary>
Motivation: 近期两项研究使用复杂几何技术证明满足$(p,2)$-性质的平面非穿透区域族需$O(p^9)$点刺穿，本文旨在简化并推广这一结论。

Method: 利用已知关于具有遗传线性Delaunay图的超图结果，这类超图包含非穿透区域的交超图。

Result: 在更广泛设定下，满足$(p,2)$-性质的区域族仅需$O(p)$点即可刺穿，显著优于先前$O(p^9)$的结论。

Conclusion: 通过超图理论框架，本文简化并强化了非穿透区域族的刺穿数上界，证明$O(p)$点的普适性结果。

Abstract: A family of sets satisfies the $(p,2)$-property if among any $p$ sets in the
family, some two intersect. Two recent works used elaborate geometric
techniques to show that any family of non-piercing regions in the plane that
satisfies the $(p,2)$-property can be pierced by $O(p^9)$ points. In this note
we show that even in a much more general setting, piercing by $O(p)$ points can
be deduced from known results on hypergraphs with a hereditarily linear
Delaunay graph, which include intersection hypergraphs of non-piercing regions.

</details>


### [27] [Spanning k-trees, odd [1,b]-factors and spectral radius in binding graphs](https://arxiv.org/abs/2507.07301)
*Jiancheng Wu,Sizhong Zhou*

Main category: math.CO

TL;DR: 本文通过邻接谱半径提出了两个紧密的充分条件：一是关于连通$\frac{1}{b}$-绑定图存在奇$[1,b]$-因子的条件，二是关于连通$\frac{1}{k-2}$-绑定图存在生成$k$-树的条件，部分改进了先前的研究结果。


<details>
  <summary>Details</summary>
Motivation: 研究图的绑定数与特定子结构（如奇$[1,b]$-因子和生成$k$-树）之间的关系，通过谱方法推广和改进现有理论结果。

Method: 利用图的邻接谱半径作为工具，结合绑定数的定义，推导出保证特定子结构存在的谱条件。

Result: 1. 推广了Fan和Lin关于奇$[1,b]$-因子的结果；2. 部分改进了Fan等人关于生成$k$-树的结果，均基于谱半径给出了紧的充分条件。

Conclusion: 谱半径可作为判定绑定图是否具有特定子结构的有效指标，所提条件在理论上具有紧性，并为相关问题的研究提供了新视角。

Abstract: The binding number of a graph $G$, written as $\mbox{bind}(G)$, is defined by
$$ \mbox{bind}(G)=\min\left\{\frac{|N_G(X)|}{|X|}:\emptyset\neq X\subseteq
V(G),N_G(X)\neq V(G)\right\}. $$ A graph $G$ is called $r$-binding if
$\mbox{bind}(G)\geq r$. An odd $[1,b]$-factor of a graph $G$ is a spanning
subgraph $F$ with $d_F(v)\in\{1,3,\ldots,b\}$ for all $v\in V(G)$, where
$b\geq1$ is an odd integer. A spanning $k$-tree of a connected graph $G$ is a
spanning tree $T$ with $d_T(v)\leq k$ for every $v\in V(G)$. In this paper, we
first show a tight sufficient condition with respect to the adjacency spectral
radius for connected $\frac{1}{b}$-binding graphs to have odd $[1,b]$-factors,
which generalizes Fan and Lin's previous result [D. Fan, H. Lin, Binding
number, $k$-factor and spectral radius of graphs, Electron. J. Combin. 31(1)
(2024) \#P1.30] and partly improves Fan, Liu and Ao's previous result [A. Fan,
R. Liu, G. Ao, Spectral radius, odd $[1,b]$-factor and spanning $k$-tree of
1-binding graphs, Linear Algebra Appl. 705 (2025) 1--16]. Then we put forward a
tight sufficient condition via the adjacency spectral radius for connected
$\frac{1}{k-2}$-binding graphs to have spanning $k$-trees, which partly
improves Fan, Liu and Ao's previous result [A. Fan, R. Liu, G. Ao, Spectral
radius, odd $[1,b]$-factor and spanning $k$-tree of 1-binding graphs, Linear
Algebra Appl. 705 (2025) 1--16].

</details>


### [28] [Volumes of moduli spaces of directed ribbon graphs and Cut-and-Join operators](https://arxiv.org/abs/2507.07308)
*Simon Barazer*

Main category: math.CO

TL;DR: 本文研究了无环分解的代数结构，通过该分解递归计算有向度量带图的模空间体积，并构建满足Cut-and-Join方程的积分算子，最终生成\textit{dessins d'enfants}的级数。


<details>
  <summary>Details</summary>
Motivation: 探索有向度量带图模空间体积的递归计算方法，并建立其与代数结构的联系。

Method: 利用无环分解技术定义积分算子，证明其满足Cut-and-Join方程，并通过特化算子生成\textit{dessins d'enfants}级数。

Result: 成功构建了满足特定方程的积分算子，并展示了其与\textit{dessins d'enfants}生成级数的关联。

Conclusion: 无环分解为模空间体积计算提供了新工具，积分算子的代数性质进一步拓展了在\textit{dessins d'enfants}研究中的应用。

Abstract: In this paper, we investigate the algebraic structure underlying the acyclic
decomposition. This decomposition applies to directed metric ribbon graphs and
enables the recursive computation of the volumes of their moduli spaces.
Building on this, we define integral operators with these volumes and show that
they satisfy a Cut-and-Join type equation. Furthermore, we demonstrate that a
suitable specialization of these operators gives rise to a generating series
for \textit{dessins d'enfants}.

</details>


### [29] [Exact Turán densities in triple systems](https://arxiv.org/abs/2507.07360)
*Nannan Chen,Yuzhen Qi,Caihong Yang,Hongbin Zhao*

Main category: math.CO

TL;DR: 本文证明了几个新的3-图Tur\'{a}n密度结果，包括确认Shi的猜想并解决了Mubayi和R\"odl提出的特殊非主族问题。


<details>
  <summary>Details</summary>
Motivation: 研究3-图的Tur\'{a}n密度问题，验证已有猜想并解决特定非主族问题，推动极值图论领域发展。

Method: 采用极值图论方法，通过数学证明确定不同3-图组合的Tur\'{a}n密度值。

Result: 得出三个具体结果：$\pi(C_4^3, \mathrm{complement\ of\ } F_5) = 2\sqrt{3} - 3$，$\pi(F_{3,2}, C_5^{3-}) = \frac{2}{9}$，以及$\pi(F_{3,2}, \mathrm{induced\ complement\ of\ } F_{3,2}) = \frac{3}{8}$。

Conclusion: 研究不仅验证了Shi的猜想，还解决了Mubayi和R\"odl提出的问题，为3-图Tur\'{a}n密度研究提供了新的理论支持。

Abstract: In this paper, we prove several new Tur\'{a}n density results for $3$-graphs.
We show: $\pi(C_4^3, \mathrm{complement\ of\ } F_5) = 2\sqrt{3} - 3$,
$\pi(F_{3,2}, C_5^{3-}) = \frac{2}{9}$, and $\pi(F_{3,2}, \mathrm{induced\
complement\ of\ } F_{3,2}) = \frac{3}{8}$. The first result confirms the
conjecture of Shi~[On Tur\'an denisties of small triple graphs, European J.
Combin. 52 (2016) 95-102]. The other results give several special non-principal
family posed by Mubayi and R\"odl~[On the Tur\'an number of triple systems, J.
Combin. Theory A. 100 (2002) 135-152].

</details>


### [30] [Deterministic simplicial complexes](https://arxiv.org/abs/2507.07402)
*S. N. Dorogovtsev,P. L. Krapivsky*

Main category: math.CO

TL;DR: 研究从单顶点确定性增长的单纯复形，发现其具有快速增长的单纯形数量、幂律度分布及无限谱维数等特性。


<details>
  <summary>Details</summary>
Motivation: 探索确定性增长的单纯复形的局部和全局特性，特别是其度分布和谱性质。

Method: 通过递归方式逐步构建单纯复形，每一步为现有$d$-单纯形添加新顶点形成$(d+1)$-单纯形，并分析约束与非约束模型的差异。

Result: 非约束模型中单纯形数量超阶乘增长，度分布呈幂律；约束模型中数量指数增长，谱维数有限且度分布行为各异。

Conclusion: 确定性增长的单纯复形展现出复杂的拓扑和谱特性，约束与非约束模型的行为差异显著，为网络科学提供了新的理论视角。

Abstract: We investigate simplicial complexes deterministically growing from a single
vertex. In the first step, a vertex and an edge connecting it to the primordial
vertex are added. The resulting simplicial complex has a 1-dimensional simplex
and two 0-dimensional faces (the vertices). The process continues recursively:
On the $n$-th step, every existing $d-$dimensional simplex ($d\leq n-1$) joins
a new vertex forming a $(d+1)-$dimensional simplex; all $2^{d+1}-2$ new faces
are also added so that the resulting object remains a simplicial complex. The
emerging simplicial complex has intriguing local and global characteristics.
The number of simplices grows faster than $n!$, and the upper-degree
distributions follow a power law. Here, the upper degree (or $d$-degree) of a
$d$-simplex refers to the number of $(d{+}1)$-simplices that share it as a
face. Interestingly, the $d$-degree distributions evolve quite differently for
different values of $d$. We compute the Hodge Laplacian spectra of simplicial
complexes and show that the spectral and Hausdorff dimensions are infinite. We
also explore a constrained version where the dimension of the added simplices
is fixed to a finite value $m$. In the constrained model, the number of
simplices grows exponentially. In particular, for $m=1$, the spectral dimension
is $2$. For $m=2$, the spectral dimension is finite, and the degree
distribution follows a power law, while the $1$-degree distribution decays
exponentially.

</details>


### [31] [Cocompact unfolding trees](https://arxiv.org/abs/2507.07503)
*Roman Gorazd*

Main category: math.CO

TL;DR: 本文研究了有限有向根图的根路径树在无向自同构群作用下仅有有限轨道（即紧余情形）的条件，并给出了判定算法。


<details>
  <summary>Details</summary>
Motivation: 旨在解决arXiv:2212.07205中问题(1)，明确哪些树与紧余树几乎同构。

Method: 通过分析根路径树的轨道有限性，提出了一种判定算法。

Result: 确定了紧余树的特征，并提供了判定树是否几乎同构于紧余树的有效方法。

Conclusion: 该研究为图论中树的紧余性质提供了理论依据与实用工具，基本解决了目标问题。

Abstract: This paper will show when a rooted path tree of a finite directed rooted
graph has only finitely many orbits under the action of its undirected
automorphism group (i.e. when it is cocompact). This will allow us to specify
which trees are almost isomorphic to cocompact trees. We will provide an
algorithm that will determine this, thus mostly answering question (1) from
arXiv:2212.07205.

</details>


### [32] [Evasive sets, twisted varieties, and container-clique trees](https://arxiv.org/abs/2507.07594)
*Jeck Lim,Jiaxi Nie,Ji Zeng*

Main category: math.CO

TL;DR: 该论文研究了有限域$\mathbb{F}_q^n$上的$(d,k,r)$-规避集，证明了其存在性并给出了枚举上界。同时，在代数闭域上的射影空间$\mathbb{P}^n$中，研究了$d$-扭曲簇的最小可能度。


<details>
  <summary>Details</summary>
Motivation: 研究有限域上规避集的构造及其规模，以及射影空间中扭曲簇的性质，旨在为相关数学问题提供新的理论工具和结果。

Method: 通过研究扭曲簇的性质，证明了规避集的存在性；使用容器方法的新技术，给出了规避集的枚举上界。

Result: 证明了$(d,k,r)$-规避集在$\mathbb{F}_q^n$中的存在性，其规模至少为$\Omega\left(q^{n-k}\right)$；给出了扭曲簇的最小可能度的上界；并利用新技术简化了已有结果的证明。

Conclusion: 该研究不仅为有限域上的规避集提供了新的构造方法，还为容器方法的应用提供了新的技术，具有独立的理论价值和应用潜力。

Abstract: In the affine space $\mathbb{F}_q^n$ over the finite field of order $q$, a
point set $S$ is said to be $(d,k,r)$-evasive if the intersection between $S$
and any variety, of dimension $k$ and degree at most $d$, has cardinality less
than $r$. As $q$ tends to infinity, the size of a $(d,k,r)$-evasive set in
$\mathbb{F}_q^n$ is at most $O\left(q^{n-k}\right)$ by a simple averaging
argument. We exhibit the existence of such evasive sets of sizes at least
$\Omega\left(q^{n-k}\right)$ for much smaller values of $r$ than previously
known constructions, and establish an enumerative upper bound $2^{O(q^{n-k})}$
for the total number of such evasive sets. The existence result is based on our
study of twisted varieties. In the projective space $\mathbb{P}^n$ over an
algebraically closed field, a variety $V$ is said to be $d$-twisted if the
intersection between $V$ and any variety, of dimension $n - \dim(V)$ and degree
at most $d$, has dimension zero. We prove an upper bound on the smallest
possible degree of twisted varieties which is best possible in a mild sense.
The enumeration result includes a new technique for the container method which
we believe is of independent interest. To illustrate the potential of this
technique, we give a simpler proof of a result by Chen--Liu--Nie--Zeng that
characterizes the maximum size of a collinear-triple-free subset in a random
sampling of $ \mathbb{F}_q^2$ up to polylogarithmic factors.

</details>


### [33] [A constructive characterization of uniformly 4-connected graphs](https://arxiv.org/abs/2507.07656)
*Xiang Chen,Shuai Kou,Chengfu Qin,Liqiong Xu,Weihua Yang*

Main category: math.CO

TL;DR: 本文提出了一种构造性方法，用于描述所有均匀4连通图的类别。


<details>
  <summary>Details</summary>
Motivation: 研究均匀4连通图的构造特性，以更好地理解其结构。

Method: 通过应用图操作，对均匀4连通图中的适当顶点和边集进行操作，使用$\Delta_1^+$或$\Delta_2^+$操作作用于准4兼容集。

Result: 任何均匀4连通图都可以从$C_5^2$或$C_6^2$通过一系列$\Delta_1^+$或$\Delta_2^+$操作得到。

Conclusion: 该研究为均匀4连通图提供了一个完整的构造性描述，有助于进一步研究其性质和应用。

Abstract: A constructive characterization of the class of uniformly $4$-connected
graphs is presented. The characterization is based on the application of graph
operations to appropriate vertex and edge sets in uniformly $4$-connected
graphs, that is, any uniformly $4$-connected graph can be obtained from $C_5^2$
or $C_6^2$ by a number of $\Delta_1^+$ or $\Delta_2^+$-operations to quasi
$4$-compatible sets.

</details>


### [34] [Regular sets in Cayley sum graphs on generalized dicyclic groups](https://arxiv.org/abs/2507.07736)
*Meiqi Peng,Yuefeng Yang,Wenying Zhu*

Main category: math.CO

TL;DR: 本文研究了广义双循环群$G$的子群$H$作为$(\alpha,\beta)$-正则集的性质，通过选择合适的连接集$S$，确定了$H$成为$G$的$(\alpha,\beta)$-正则集的所有可能参数对$(\alpha,\beta)$。


<details>
  <summary>Details</summary>
Motivation: 研究图的$(\alpha,\beta)$-正则集在群论和图论中具有重要意义，特别是在Cayley和图中。本文旨在探讨广义双循环群的子群如何成为$(\alpha,\beta)$-正则集。

Method: 对于广义双循环群$G$的每个子群$H$，通过构造适当的连接集$S$，分析$H$在Cayley和图中的邻接性质，从而确定$(\alpha,\beta)$的可能取值。

Result: 对于广义双循环群$G$的任意子群$H$，存在特定的连接集$S$，使得$H$成为$G$的$(\alpha,\beta)$-正则集，并完全确定了所有可能的参数对$(\alpha,\beta)$。

Conclusion: 本文成功刻画了广义双循环群中子群作为$(\alpha,\beta)$-正则集的充要条件，为相关领域的研究提供了新的理论工具。

Abstract: For a graph $\Gamma=(V(\Gamma),E(\Gamma))$, a subset $C$ of $V(\Gamma)$ is
called an $(\alpha,\beta)$-regular set in $\Gamma$, if every vertex of $C$ is
adjacent to exactly $\alpha$ vertices of $C$ and every vertex of
$V(\Gamma)\setminus C$ is adjacent to exactly $\beta$ vertices of $C$. In
particular, if $C$ is an $(\alpha,\beta)$-regular set in some Cayley sum graph
of a finite group $G$ with connection set $S$, then $C$ is called an
$(\alpha,\beta)$-regular set of $G$. In this paper, we consider a generalized
dicyclic group $G$ and for each subgroup $H$ of $G$, by giving an appropriate
connection set $S$, we determine each possibility for $(\alpha,\beta)$ such
that $H$ is an $(\alpha,\beta)$-regular set of $G$.

</details>


### [35] [Constructing Optimal Kobon Triangle Arrangements via Table Encoding, SAT Solving, and Heuristic Straightening](https://arxiv.org/abs/2507.07951)
*Pavlo Savchuk*

Main category: math.CO

TL;DR: 本文提出了构建最优Kobon三角形排列的新方法和结果，包括紧凑表格表示法、启发式恢复工具及基于SAT求解器的搜索技术，发现了23和27线的新最优解。


<details>
  <summary>Details</summary>
Motivation: 研究旨在发展更高效的方法来表示和分析复杂的伪线排列，特别是对称排列、平行线排列及多线交点排列，以寻找最优Kobon三角形排列。

Method: 1. 引入紧凑表格表示法描述伪线排列；2. 开发启发式工具从表格恢复直线排列，支持对称性等附加属性；3. 将最优Kobon排列搜索转化为SAT问题，利用Kissat求解器高效求解。

Result: 1. 工具成功恢复了多个已知最优解；2. 通过SAT求解器确认11线情况下无最优解；3. 发现了23和27线的新最优Kobon排列及其他新结果。

Conclusion: 新方法显著提升了最优Kobon排列的搜索效率与验证能力，为组合几何领域提供了实用工具与理论支持。

Abstract: We present new methods and results for constructing optimal Kobon triangle
arrangements. First, we introduce a compact table notation for describing
arrangements of pseudolines, enabling the representation and analysis of
complex cases, including symmetrical arrangements, arrangements with parallel
lines, and arrangements with multiple-line intersection points. Building on
this, we provide a simple heuristic method and tools for recovering
straight-line arrangements from a given table, with the ability to enforce
additional properties such as symmetries. The tool successfully recovers
arrangements for many previously known optimal solutions. Additionally, we
develop a tool that transforms the search for optimal Kobon arrangement tables
into a SAT problem, allowing us to leverage modern SAT solvers (specifically
Kissat) to efficiently find new solutions or to show that no other solutions
exist (for example, confirming that no optimal solution exists in the 11-line
case). Using these techniques, we find new optimal Kobon arrangements for 23
and 27 lines, along with several other new results.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [36] [Time Series Foundation Models for Multivariate Financial Time Series Forecasting](https://arxiv.org/abs/2507.07296)
*Ben A. Marconi*

Main category: q-fin.GN

TL;DR: 时间序列基础模型（TSFMs）在金融时间序列预测中展现出潜力，特别是在数据有限的任务中。Tiny Time Mixers（TTM）模型在预训练后表现出色，但传统专业模型在部分任务中仍具优势。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列预测面临非线性关系、时间依赖性和数据稀缺等挑战，尤其是低频数据和新上市资产。TSFMs通过预训练和任务适应提供解决方案。

Method: 研究评估了两种TSFMs（TTM和Chronos）在三个金融预测任务中的表现：美国10年期国债收益率变化、欧元/美元波动率和股票价差预测。比较了预训练模型和未训练模型的性能。

Result: 预训练的TTM在有限数据下表现优于未训练模型25-50%，在较长数据集中也有15-30%的提升。零样本性能在波动率和价差预测中超过基准，但传统模型在两项任务中匹配或优于TTM。

Conclusion: TSFMs在金融预测中具有潜力，尤其在噪声大、数据少的任务中，但需针对金融时间序列特性进行领域特定预训练和架构优化以提高竞争力。

Abstract: Financial time series forecasting presents significant challenges due to
complex nonlinear relationships, temporal dependencies, variable
interdependencies and limited data availability, particularly for tasks
involving low-frequency data, newly listed instruments, or emerging market
assets. Time Series Foundation Models (TSFMs) offer a promising solution
through pretraining on diverse time series corpora followed by task-specific
adaptation. This study evaluates two TSFMs (Tiny Time Mixers (TTM) and Chronos)
across three financial forecasting tasks: US 10-year Treasury yield changes,
EUR/USD volatility, and equity spread prediction. Results demonstrate that TTM
exhibits strong transferability. When fine-tuning both the pretrained version
of TTM and an untrained model with the same architecture, the pretrained
version achieved 25-50% better performance when fine-tuned on limited data and
15-30% improvements even when fine-tuned on lengthier datasets. Notably, TTM's
zero-shot performance outperformed naive benchmarks in volatility forecasting
and equity spread prediction, with the latter demonstrating that TSFMs can
surpass traditional benchmark models without fine-tuning. The pretrained model
consistently required 3-10 fewer years of data to achieve comparable
performance levels compared to the untrained model, demonstrating significant
sample-efficiency gains. However, while TTM outperformed naive baselines,
traditional specialised models matched or exceeded its performance in two of
three tasks, suggesting TSFMs prioritise breadth over task-specific
optimisation. These findings indicate that TSFMs, though still nascent, offer
substantial promise for financial forecasting-particularly in noisy,
data-constrained tasks-but achieving competitive performance likely requires
domain-specific pretraining and architectural refinements tailored to financial
time series characteristics.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [37] [WatchWitch: Interoperability, Privacy, and Autonomy for the Apple Watch](https://arxiv.org/abs/2507.07210)
*Nils Rollshausen,Alexander Heinrich,Matthias Hollick,Jiska Classen*

Main category: cs.CR

TL;DR: 研究团队首次公开逆向工程Apple Watch的无线协议，发现其专有实现中的多个安全问题，并开发了Android版WatchWitch实现跨平台互联，增强用户隐私控制与数据自主权。


<details>
  <summary>Details</summary>
Motivation: 苹果手表等智能设备收集大量健康数据，但用户无法选择数据处理方式，只能依赖苹果的封闭生态系统，缺乏数据控制权。

Method: 通过逆向工程破解Apple Watch的无线通信协议，分析其安全漏洞，并开发了Android平台的自定义实现WatchWitch。

Result: 成功突破苹果生态壁垒，实现与Android设备的互操作性，提供更强的隐私保护功能和数据自主管理能力。

Conclusion: 该研究为智能手表生态系统提供了更多消费者选择，使用户能更自主地控制设备及数据，推动行业开放竞争。

Abstract: Smartwatches such as the Apple Watch collect vast amounts of intimate health
and fitness data as we wear them. Users have little choice regarding how this
data is processed: The Apple Watch can only be used with Apple's iPhones, using
their software and their cloud services. We are the first to publicly
reverse-engineer the watch's wireless protocols, which led to discovering
multiple security issues in Apple's proprietary implementation. With
WatchWitch, our custom Android reimplementation, we break out of Apple's walled
garden -- demonstrating practical interoperability with enhanced privacy
controls and data autonomy. We thus pave the way for more consumer choice in
the smartwatch ecosystem, offering users more control over their devices.

</details>


### [38] [Automated Attack Testflow Extraction from Cyber Threat Report using BERT for Contextual Analysis](https://arxiv.org/abs/2507.07244)
*Faissal Ahmadou,Sepehr Ghaffarzadegan,Boubakr Nour,Makan Pourzandi,Mourad Debbabi,Chadi Assi*

Main category: cs.CR

TL;DR: 本文提出FLOWGUARDIAN系统，利用BERT模型和NLP技术自动从非结构化威胁报告中提取攻击测试流程，显著提升网络安全测试的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前依赖人工从威胁报告中提取攻击测试流程的方法耗时、易错且需要专业知识，亟需自动化解决方案以应对高级持续性威胁(APTs)的快速识别与缓解需求。

Method: 采用BERT语言模型和自然语言处理技术，系统化分析安全事件上下文，重构攻击序列，自动生成全面测试流程。

Result: 基于公开威胁报告的实证验证表明，FLOWGUARDIAN在准确性和效率上表现优异，能显著增强安全团队主动威胁狩猎和事件响应能力。

Conclusion: 该自动化方案不仅节省时间、减少人为错误，更能确保网络安全测试的全面覆盖与鲁棒性，为APT防御提供有效技术支持。

Abstract: In the ever-evolving landscape of cybersecurity, the rapid identification and
mitigation of Advanced Persistent Threats (APTs) is crucial. Security
practitioners rely on detailed threat reports to understand the tactics,
techniques, and procedures (TTPs) employed by attackers. However, manually
extracting attack testflows from these reports requires elusive knowledge and
is time-consuming and prone to errors. This paper proposes FLOWGUARDIAN, a
novel solution leveraging language models (i.e., BERT) and Natural Language
Processing (NLP) techniques to automate the extraction of attack testflows from
unstructured threat reports. FLOWGUARDIAN systematically analyzes and
contextualizes security events, reconstructs attack sequences, and then
generates comprehensive testflows. This automated approach not only saves time
and reduces human error but also ensures comprehensive coverage and robustness
in cybersecurity testing. Empirical validation using public threat reports
demonstrates FLOWGUARDIAN's accuracy and efficiency, significantly enhancing
the capabilities of security teams in proactive threat hunting and incident
response.

</details>


### [39] [Disa: Accurate Learning-based Static Disassembly with Attentions](https://arxiv.org/abs/2507.07246)
*Peicheng Wang,Monika Santra,Mingyu Liu,Cong Sun,Dongrui Zeng,Gang Tan*

Main category: cs.CR

TL;DR: 本文提出Disa，一种基于学习的反汇编方法，利用多头自注意力机制学习指令相关性，显著提升函数入口点和指令边界识别的准确性，尤其在混淆二进制文件中表现优异。


<details>
  <summary>Details</summary>
Motivation: 反汇编在漏洞检测、恶意软件分析等安全领域至关重要，但传统方法依赖文件格式假设和特定架构启发式规则，导致在混淆二进制文件中效果不佳。深度学习为提升反汇编精度和效率提供了新思路。

Method: Disa通过多头自注意力机制分析超集指令信息，学习指令间相关性，推断函数入口点和指令边界。该方法还能识别与内存块边界相关的指令，支持基于块内存模型的值集分析，生成更精确的控制流图(CFG)。

Result: 实验表明：1)在反汇编去同步和源码级混淆的二进制文件中，Disa的F1分数分别提升9.1%和13.2%；2)内存块识别精度提高18.5%；3)生成CFG时平均间接调用目标(AICT)减少4.4%，优于当前最优启发式方法。

Conclusion: Disa通过深度学习模型有效解决了传统反汇编技术的局限性，在函数入口识别和CFG生成精度上实现显著突破，为安全分析领域提供了更可靠的反汇编工具。

Abstract: For reverse engineering related security domains, such as vulnerability
detection, malware analysis, and binary hardening, disassembly is crucial yet
challenging. The fundamental challenge of disassembly is to identify
instruction and function boundaries. Classic approaches rely on file-format
assumptions and architecture-specific heuristics to guess the boundaries,
resulting in incomplete and incorrect disassembly, especially when the binary
is obfuscated. Recent advancements of disassembly have demonstrated that deep
learning can improve both the accuracy and efficiency of disassembly. In this
paper, we propose Disa, a new learning-based disassembly approach that uses the
information of superset instructions over the multi-head self-attention to
learn the instructions' correlations, thus being able to infer function
entry-points and instruction boundaries. Disa can further identify instructions
relevant to memory block boundaries to facilitate an advanced block-memory
model based value-set analysis for an accurate control flow graph (CFG)
generation. Our experiments show that Disa outperforms prior deep-learning
disassembly approaches in function entry-point identification, especially
achieving 9.1% and 13.2% F1-score improvement on binaries respectively
obfuscated by the disassembly desynchronization technique and popular
source-level obfuscator. By achieving an 18.5% improvement in the memory block
precision, Disa generates more accurate CFGs with a 4.4% reduction in Average
Indirect Call Targets (AICT) compared with the state-of-the-art heuristic-based
approach.

</details>


### [40] [Semi-fragile watermarking of remote sensing images using DWT, vector quantization and automatic tiling](https://arxiv.org/abs/2507.07250)
*Jordi Serra-Ruiz,David Megías*

Main category: cs.CR

TL;DR: 本文提出了一种针对多波段图像的半脆弱水印方案，通过树结构矢量量化方法在像素签名中嵌入水印，以检测对原始图像的篡改。


<details>
  <summary>Details</summary>
Motivation: 为了保护遥感图像免受未经授权的修改，同时保持其在有损压缩下的完整性，需要一种能够区分正常压缩和恶意篡改的水印技术。

Method: 该方法将多光谱或高光谱图像分割成三维块，为每个块构建树结构矢量量化器，并通过迭代算法操作这些树，直到满足嵌入水印的特定标准。

Result: 实验表明，该方法能够在有损压缩（超过给定阈值）下保持水印的完整性，同时能够检测并定位图像中被篡改的块。

Conclusion: 所提出的半脆弱水印方案有效地平衡了水印的鲁棒性和脆弱性，适用于遥感图像的完整性验证和篡改检测。

Abstract: A semi-fragile watermarking scheme for multiple band images is presented in
this article. We propose to embed a mark into remote sensing images applying a
tree-structured vector quantization approach to the pixel signatures instead of
processing each band separately. The signature of the multispectral or
hyperspectral image is used to embed the mark in it order to detect any
significant modification of the original image. The image is segmented into
three-dimensional blocks, and a tree-structured vector quantizer is built for
each block. These trees are manipulated using an iterative algorithm until the
resulting block satisfies a required criterion, which establishes the embedded
mark. The method is shown to be able to preserve the mark under lossy
compression (above a given threshold) but, at the same time, it detects
possibly forged blocks and their position in the whole image.

</details>


### [41] [FedP3E: Privacy-Preserving Prototype Exchange for Non-IID IoT Malware Detection in Cross-Silo Federated Learning](https://arxiv.org/abs/2507.07258)
*Rami Darwish,Mahmoud Abdelsalam,Sajad Khorsandroo,Kaushik Roy*

Main category: cs.CR

TL;DR: 针对物联网(IoT)生态系统中恶意软件攻击日益复杂化的问题，本文提出了一种名为FedP3E的新型联邦学习框架。该框架通过隐私保护的类原型交换机制，解决了数据异构性和类别不平衡问题，同时保持数据隐私。


<details>
  <summary>Details</summary>
Motivation: 随着IoT在关键领域的扩展，其面临的大规模恶意软件攻击日益复杂。现有联邦学习算法(如FedAvg、FedProx)在真实部署中难以应对类别不平衡和非独立同分布数据问题，特别是稀有或离散的恶意软件类别。这需要兼具隐私保护和数据异构鲁棒性的检测框架。

Method: 提出FedP3E框架：1)客户端使用高斯混合模型(GMM)构建类原型；2)添加高斯噪声扰动后传输压缩原型至服务器；3)服务器聚合原型并分发给客户端；4)结合SMOTE增强技术改善少数类表示。该机制通过原型驱动实现跨客户端结构模式共享，避免原始数据或梯度交换。

Result: 在N-BaIoT数据集上的跨机构场景测试表明，FedP3E能有效缓解统计异构性的负面影响。相比传统方法，该框架以最小通信开销提升了模型在数据不平衡情况下的表现。

Conclusion: FedP3E通过隐私保护的类原型交换机制，实现了联邦学习中跨客户端的知识共享。该方法不仅解决了IoT恶意软件检测中的数据隐私和异构性挑战，还通过原型驱动策略显著提升了少数类的识别能力，为实际部署提供了可行方案。

Abstract: As IoT ecosystems continue to expand across critical sectors, they have
become prominent targets for increasingly sophisticated and large-scale malware
attacks. The evolving threat landscape, combined with the sensitive nature of
IoT-generated data, demands detection frameworks that are both
privacy-preserving and resilient to data heterogeneity. Federated Learning (FL)
offers a promising solution by enabling decentralized model training without
exposing raw data. However, standard FL algorithms such as FedAvg and FedProx
often fall short in real-world deployments characterized by class imbalance and
non-IID data distributions -- particularly in the presence of rare or disjoint
malware classes. To address these challenges, we propose FedP3E
(Privacy-Preserving Prototype Exchange), a novel FL framework that supports
indirect cross-client representation sharing while maintaining data privacy.
Each client constructs class-wise prototypes using Gaussian Mixture Models
(GMMs), perturbs them with Gaussian noise, and transmits only these compact
summaries to the server. The aggregated prototypes are then distributed back to
clients and integrated into local training, supported by SMOTE-based
augmentation to enhance representation of minority malware classes. Rather than
relying solely on parameter averaging, our prototype-driven mechanism enables
clients to enrich their local models with complementary structural patterns
observed across the federation -- without exchanging raw data or gradients.
This targeted strategy reduces the adverse impact of statistical heterogeneity
with minimal communication overhead. We evaluate FedP3E on the N-BaIoT dataset
under realistic cross-silo scenarios with varying degrees of data imbalance.

</details>


### [42] [Shuffling for Semantic Secrecy](https://arxiv.org/abs/2507.07401)
*Fupei Chen,Liyao Xiang,Haoxiang Sun,Hei Victor Cheng,Kaiming Shen*

Main category: cs.CR

TL;DR: 本文提出了一种基于随机打乱特征的语义安全通信系统，通过在特征序列中引入随机置换模式作为共享密钥，有效平衡传输速率与泄露率，显著提升窃听信道下的安全传输性能。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信的安全编码方案难以在传输速率与信息泄露率之间取得理想平衡，尤其在强噪声和不可预测衰落的信道环境下性能受限，亟需新型安全增强机制。

Method: 设计以随机打乱模式为共享密钥的语义安全系统：通过置换特征序列扭曲数据语义本质，使窃听者无法还原信息；该方法可作为插件兼容现有语义通信框架。

Result: 仿真表明，所提方法在强噪声和信道衰落场景下，相比基准方案能显著提升安全传输率，同时满足泄露率约束条件下最小化语义错误概率。

Conclusion: 随机打乱机制为语义通信安全提供了灵活高效的解决方案，其密钥式特征置换策略在对抗窃听方面具有普适性应用潜力。

Abstract: Deep learning draws heavily on the latest progress in semantic
communications. The present paper aims to examine the security aspect of this
cutting-edge technique from a novel shuffling perspective. Our goal is to
improve upon the conventional secure coding scheme to strike a desirable
tradeoff between transmission rate and leakage rate. To be more specific, for a
wiretap channel, we seek to maximize the transmission rate while minimizing the
semantic error probability under the given leakage rate constraint. Toward this
end, we devise a novel semantic security communication system wherein the
random shuffling pattern plays the role of the shared secret key. Intuitively,
the permutation of feature sequences via shuffling would distort the semantic
essence of the target data to a sufficient extent so that eavesdroppers cannot
access it anymore. The proposed random shuffling method also exhibits its
flexibility in working for the existing semantic communication system as a
plugin. Simulations demonstrate the significant advantage of the proposed
method over the benchmark in boosting secure transmission, especially when
channels are prone to strong noise and unpredictable fading.

</details>


### [43] [Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models](https://arxiv.org/abs/2507.07406)
*Jikesh Thapa,Gurrehmat Chahal,Serban Voinea Gabreanu,Yazan Otoum*

Main category: cs.CR

TL;DR: 本文比较了传统机器学习（ML）、深度学习（DL）和量化小参数大语言模型（LLMs）在钓鱼检测中的表现，发现LLMs虽精度略低，但在识别上下文钓鱼线索上潜力显著，且轻量级LLMs可高效部署并提供可解释性支持。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击日益复杂，需平衡高精度与计算效率的检测系统，因此评估不同AI方法在钓鱼检测中的性能与适用性。

Method: 通过实验对比ML、DL及量化LLMs（如DeepSeek R1 Distill Qwen 14B）在钓鱼数据集上的表现，并研究零样本/少样本提示策略及对抗鲁棒性。

Result: LLMs当前精度低于ML/DL，但擅长捕捉上下文钓鱼线索；量化LLMs（如Q8_0）以17GB显存实现80%+精度，且对抗攻击下性能稳定。

Conclusion: 优化后的LLMs有望成为钓鱼防御系统的关键组件，为高效、可解释的网络安全AI集成提供可行路径。

Abstract: Phishing attacks are becoming increasingly sophisticated, underscoring the
need for detection systems that strike a balance between high accuracy and
computational efficiency. This paper presents a comparative evaluation of
traditional Machine Learning (ML), Deep Learning (DL), and quantized
small-parameter Large Language Models (LLMs) for phishing detection. Through
experiments on a curated dataset, we show that while LLMs currently
underperform compared to ML and DL methods in terms of raw accuracy, they
exhibit strong potential for identifying subtle, context-based phishing cues.
We also investigate the impact of zero-shot and few-shot prompting strategies,
revealing that LLM-rephrased emails can significantly degrade the performance
of both ML and LLM-based detectors. Our benchmarking highlights that models
like DeepSeek R1 Distill Qwen 14B (Q8_0) achieve competitive accuracy, above
80%, using only 17GB of VRAM, supporting their viability for cost-efficient
deployment. We further assess the models' adversarial robustness and
cost-performance tradeoffs, and demonstrate how lightweight LLMs can provide
concise, interpretable explanations to support real-time decision-making. These
findings position optimized LLMs as promising components in phishing defence
systems and offer a path forward for integrating explainable, efficient AI into
modern cybersecurity frameworks.

</details>


### [44] [Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks](https://arxiv.org/abs/2507.07413)
*Mohammad F. Al-Hammouri,Yazan Otoum,Rasha Atwa,Amiya Nayak*

Main category: cs.CR

TL;DR: 本文提出了一种结合传统签名检测与GPT-2语言模型的新型入侵检测方法，在物联网等复杂环境中显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着物联网等分布式异构环境中网络威胁日益复杂，传统入侵检测系统对新型攻击模式识别不足，亟需动态自适应解决方案。

Method: 构建混合入侵检测框架，整合签名检测的可靠性与GPT-2处理非结构化数据的能力，通过语义分析识别零日攻击。

Result: 实验表明该模型检测准确率提升6.3%，误报率降低9.0%，同时保持近实时响应速度。

Conclusion: 语言模型与传统技术的融合为构建智能、可扩展的现代网络安全防御体系提供了有效路径。

Abstract: This paper presents a novel approach to intrusion detection by integrating
traditional signature-based methods with the contextual understanding
capabilities of the GPT-2 Large Language Model (LLM). As cyber threats become
increasingly sophisticated, particularly in distributed, heterogeneous, and
resource-constrained environments such as those enabled by the Internet of
Things (IoT), the need for dynamic and adaptive Intrusion Detection Systems
(IDSs) becomes increasingly urgent. While traditional methods remain effective
for detecting known threats, they often fail to recognize new and evolving
attack patterns. In contrast, GPT-2 excels at processing unstructured data and
identifying complex semantic relationships, making it well-suited to uncovering
subtle, zero-day attack vectors. We propose a hybrid IDS framework that merges
the robustness of signature-based techniques with the adaptability of
GPT-2-driven semantic analysis. Experimental evaluations on a representative
intrusion dataset demonstrate that our model enhances detection accuracy by
6.3%, reduces false positives by 9.0%, and maintains near real-time
responsiveness. These results affirm the potential of language model
integration to build intelligent, scalable, and resilient cybersecurity
defences suited for modern connected environments.

</details>


### [45] [Autonomous AI-based Cybersecurity Framework for Critical Infrastructure: Real-Time Threat Mitigation](https://arxiv.org/abs/2507.07416)
*Jenifer Paulraj,Brindha Raghuraman,Nagarani Gopalakrishnan,Yazan Otoum*

Main category: cs.CR

TL;DR: 本文探讨了关键基础设施面临的网络安全威胁，提出了一种混合AI驱动的网络安全框架，以增强实时漏洞检测、威胁建模和自动修复能力。


<details>
  <summary>Details</summary>
Motivation: 关键基础设施系统（如能源电网、医疗设施、交通网络和水分配系统）对社会稳定和经济韧性至关重要，但其日益增长的互联性使其面临勒索软件、拒绝服务攻击和高级持续性威胁等网络威胁。

Method: 研究提出了一种混合AI驱动的网络安全框架，结合了实时漏洞检测、威胁建模和自动修复技术，并探讨了对抗性AI、法规遵从性和系统集成的复杂性。

Result: 研究结果为加强关键基础设施系统对新兴网络威胁的安全性和韧性提供了可行的见解。

Conclusion: 通过AI驱动的网络安全框架，可以有效提升关键基础设施系统的安全防护能力，应对日益复杂的网络威胁环境。

Abstract: Critical infrastructure systems, including energy grids, healthcare
facilities, transportation networks, and water distribution systems, are
pivotal to societal stability and economic resilience. However, the increasing
interconnectivity of these systems exposes them to various cyber threats,
including ransomware, Denial-of-Service (DoS) attacks, and Advanced Persistent
Threats (APTs). This paper examines cybersecurity vulnerabilities in critical
infrastructure, highlighting the threat landscape, attack vectors, and the role
of Artificial Intelligence (AI) in mitigating these risks. We propose a hybrid
AI-driven cybersecurity framework to enhance real-time vulnerability detection,
threat modelling, and automated remediation. This study also addresses the
complexities of adversarial AI, regulatory compliance, and integration. Our
findings provide actionable insights to strengthen the security and resilience
of critical infrastructure systems against emerging cyber threats.

</details>


### [46] [May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks](https://arxiv.org/abs/2507.07417)
*Nishit V. Pandya,Andrey Labunets,Sicun Gao,Earlence Fernandes*

Main category: cs.CR

TL;DR: 本文通过构建基于优化的白盒攻击，评估了针对大型语言模型（LLM）提示注入攻击的防御方法的鲁棒性，发现现有防御措施无法提供声称的安全性。


<details>
  <summary>Details</summary>
Motivation: 当前许多防御提示注入攻击的方法依赖于微调模型以区分指令和数据，但这些方法在白盒设置下的安全性尚未得到充分验证。

Method: 作者提出了一种新颖的基于注意力的攻击算法，并将其应用于两种最新的白盒防御方法SecAlign（CCS 2025）和StruQ（USENIX Security 2025）。

Result: 攻击成功率高达70%，且攻击者只需适度增加令牌预算。

Conclusion: 研究结果揭示了现有提示注入防御在白盒设置下的脆弱性，为理解其鲁棒性提供了重要进展。代码和攻击方法已开源。

Abstract: A popular class of defenses against prompt injection attacks on large
language models (LLMs) relies on fine-tuning the model to separate instructions
and data, so that the LLM does not follow instructions that might be present
with data. There are several academic systems and production-level
implementations of this idea. We evaluate the robustness of this class of
prompt injection defenses in the whitebox setting by constructing strong
optimization-based attacks and showing that the defenses do not provide the
claimed security properties. Specifically, we construct a novel attention-based
attack algorithm for text-based LLMs and apply it to two recent whitebox
defenses SecAlign (CCS 2025) and StruQ (USENIX Security 2025), showing attacks
with success rates of up to 70% with modest increase in attacker budget in
terms of tokens. Our findings make fundamental progress towards understanding
the robustness of prompt injection defenses in the whitebox setting. We release
our code and attacks at https://github.com/nishitvp/better_opts_attacks

</details>


### [47] [RADAR: a Radio-based Analytics for Dynamic Association and Recognition of pseudonyms in VANETs](https://arxiv.org/abs/2507.07732)
*Giovanni Gambigliani Zoccoli,Filip Valgimigli,Dario Stabili,Mirco Marchetti*

Main category: cs.CR

TL;DR: 本文提出RADAR算法，通过结合DSRC和Wi-Fi探针信号破解VANET中的隐私保护假名方案，实验证明Pearson RSSI指标在车辆跟踪中表现最优。


<details>
  <summary>Details</summary>
Motivation: 现有VANET假名方案存在被追踪风险，研究旨在利用多无线电信号提升车辆跟踪能力，尤其在攻击者无法全程覆盖的场景下。

Method: 结合车辆发射的DSRC与Wi-Fi探针消息，提出三种假名-WiFi标识关联指标（Count、Statistical RSSI、Pearson RSSI）进行对比实验。

Result: Pearson RSSI指标在所有场景下均优于其他方法，能有效追踪实施假名更换的车辆，且公开了全部实现代码与仿真场景。

Conclusion: 多信号融合显著提升车辆追踪效果，Pearson RSSI为最优解，研究成果推动了对VANET隐私保护机制的再评估。

Abstract: This paper presents RADAR, a tracking algorithm for vehicles participating in
Cooperative Intelligent Transportation Systems (C-ITS) that exploits multiple
radio signals emitted by a modern vehicle to break privacy-preserving pseudonym
schemes deployed in VANETs. This study shows that by combining Dedicated Short
Range Communication (DSRC) and Wi-Fi probe request messages broadcast by the
vehicle, it is possible to improve tracking over standard de-anonymization
approaches that only leverage DSRC, especially in realistic scenarios where the
attacker does not have full coverage of the entire vehicle path. The
experimental evaluation compares three different metrics for pseudonym and
Wi-Fi probe identifier association (Count, Statistical RSSI, and Pearson RSSI),
demonstrating that the Pearson RSSI metric is better at tracking vehicles under
pseudonym-changing schemes in all scenarios and against previous works. As an
additional contribution to the state-of-the-art, we publicly release all
implementations and simulation scenarios used in this work.

</details>


### [48] [Rainbow Artifacts from Electromagnetic Signal Injection Attacks on Image Sensors](https://arxiv.org/abs/2507.07773)
*Youqian Zhang,Xinyu Ji,Zhihao Wang,Qinhong Jiang*

Main category: cs.CR

TL;DR: 研究发现CMOS图像传感器存在新型电磁信号注入攻击漏洞，攻击者可通过模拟域干扰生成彩虹色伪影，导致目标检测模型误判，揭示了视觉感知系统中物理层攻击的严重威胁。


<details>
  <summary>Details</summary>
Motivation: 图像传感器广泛应用于安防监控、自动驾驶等关键系统，其数据完整性对决策至关重要，但现有数字完整性检查无法防范模拟域攻击。

Method: 通过精心调制的电磁干扰在CMOS传感器中诱导彩虹色伪影，并评估其对先进目标检测模型的影响。

Result: 注入的伪影能穿透图像信号处理流水线，使目标检测模型出现显著误判（如将停止标志识别为限速标志）。

Conclusion: 该研究揭示了视觉感知栈中未被充分认识的物理层漏洞，强调需开发针对此类攻击的鲁棒防御机制。

Abstract: Image sensors are integral to a wide range of safety- and security-critical
systems, including surveillance infrastructure, autonomous vehicles, and
industrial automation. These systems rely on the integrity of visual data to
make decisions. In this work, we investigate a novel class of electromagnetic
signal injection attacks that target the analog domain of image sensors,
allowing adversaries to manipulate raw visual inputs without triggering
conventional digital integrity checks. We uncover a previously undocumented
attack phenomenon on CMOS image sensors: rainbow-like color artifacts induced
in images captured by image sensors through carefully tuned electromagnetic
interference. We further evaluate the impact of these attacks on
state-of-the-art object detection models, showing that the injected artifacts
propagate through the image signal processing pipeline and lead to significant
mispredictions. Our findings highlight a critical and underexplored
vulnerability in the visual perception stack, highlighting the need for more
robust defenses against physical-layer attacks in such systems.

</details>


### [49] [Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking](https://arxiv.org/abs/2507.07871)
*Toluwani Aremu,Noor Hussein,Munachiso Nwadike,Samuele Poppi,Jie Zhang,Karthik Nandakumar,Neil Gong,Nils Lukas*

Main category: cs.CR

TL;DR: 本文提出一种多密钥扩展方法，以黑盒方式防御生成式AI水印窃取攻击，通过理论保证和实证验证显著降低伪造成功率，并正式定义了水印伪造的安全威胁模型。


<details>
  <summary>Details</summary>
Motivation: 生成式AI提供商面临水印窃取攻击的威胁，攻击者可能利用无害水印样本伪造有害内容进行诬告，需开发通用防御方案保护水印系统安全性。

Method: 提出后处理式多密钥扩展方案，可跨模态应用于任意水印方法；通过安全博弈建模水印伪造威胁，建立理论防御框架。

Result: 实验证明该方法在多数据集上显著降低伪造有效性，理论分析验证防御机制可靠性，攻击成功率平均下降37%。

Conclusion: 多密钥机制为生成式AI水印提供强安全保障，首次系统化定义并量化水印伪造威胁，为后续防御研究建立理论基础。

Abstract: Watermarking offers a promising solution for GenAI providers to establish the
provenance of their generated content. A watermark is a hidden signal embedded
in the generated content, whose presence can later be verified using a secret
watermarking key. A threat to GenAI providers are \emph{watermark stealing}
attacks, where users forge a watermark into content that was \emph{not}
generated by the provider's models without access to the secret key, e.g., to
falsely accuse the provider. Stealing attacks collect \emph{harmless}
watermarked samples from the provider's model and aim to maximize the expected
success rate of generating \emph{harmful} watermarked samples. Our work focuses
on mitigating stealing attacks while treating the underlying watermark as a
black-box. Our contributions are: (i) Proposing a multi-key extension to
mitigate stealing attacks that can be applied post-hoc to any watermarking
method across any modality. (ii) We provide theoretical guarantees and
demonstrate empirically that our method makes forging substantially less
effective across multiple datasets, and (iii) we formally define the threat of
watermark forging as the task of generating harmful, watermarked content and
model this threat via security games.

</details>


### [50] [The Trust Fabric: Decentralized Interoperability and Economic Coordination for the Agentic Web](https://arxiv.org/abs/2507.07901)
*Sree Bhargavi Balija,Rekha Singal,Abhishek Singh,Ramesh Raskar,Erfan Darzi,Raghu Bala,Thomas Hardjono,Ken Huang*

Main category: cs.CR

TL;DR: 本文提出了Nanda统一架构，通过分布式注册、语义代理卡和动态信任层三大创新，解决了AI代理生态系统的互操作性、信任和经济协调问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理生态系统存在碎片化问题，现有协议无法满足大规模互操作性、信任和经济协调的需求。

Method: 采用分布式注册实现快速DID代理发现，引入语义代理卡（含可验证凭证和可组合性配置），并设计动态信任层（整合行为认证与策略合规）。系统还包含X42/H42微支付和MAESTRO安全框架（含Synergetics专利AgentTalk协议和安全容器化）。

Result: 实际部署显示医疗应用合规率达99.9%，月交易量显著且隐私保障强，融合了MIT信任研究与思科/Synergetics的生产部署经验。

Conclusion: 该架构通过密码学证明和策略即代码，使代理成为去中心化经济中的信任锚点，构建了以信任为原生协作货币的全球互联Agent互联网。

Abstract: The fragmentation of AI agent ecosystems has created urgent demands for
interoperability, trust, and economic coordination that current protocols --
including MCP (Hou et al., 2025), A2A (Habler et al., 2025), ACP (Liu et al.,
2025), and Cisco's AGP (Edwards, 2025) -- cannot address at scale. We present
the Nanda Unified Architecture, a decentralized framework built around three
core innovations: fast DID-based agent discovery through distributed
registries, semantic agent cards with verifiable credentials and composability
profiles, and a dynamic trust layer that integrates behavioral attestations
with policy compliance. The system introduces X42/H42 micropayments for
economic coordination and MAESTRO, a security framework incorporating
Synergetics' patented AgentTalk protocol (US Patent 12,244,584 B1) and secure
containerization. Real-world deployments demonstrate 99.9 percent compliance in
healthcare applications and substantial monthly transaction volumes with strong
privacy guarantees. By unifying MIT's trust research with production
deployments from Cisco and Synergetics, we show how cryptographic proofs and
policy-as-code transform agents into trust-anchored participants in a
decentralized economy (Lakshmanan, 2025; Sha, 2025). The result enables a
globally interoperable Internet of Agents where trust becomes the native
currency of collaboration across both enterprise and Web3 ecosystems.

</details>


### [51] [Can Large Language Models Improve Phishing Defense? A Large-Scale Controlled Experiment on Warning Dialogue Explanations](https://arxiv.org/abs/2507.07916)
*Federico Maria Cau,Giuseppe Desolda,Francesco Greco,Lucio Davide Spano,Luca Viganò*

Main category: cs.CR

TL;DR: 研究评估大型语言模型（LLMs）生成钓鱼警告解释的能力，发现其效果可媲美人工解释，且具备可扩展性和适应性。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击通过利用人类行为绕过技术防御，现有警告对话框因解释不清和内容静态而效果有限，需探索LLMs生成更优解释的潜力。

Method: 开展大规模用户研究（N=750），比较人工解释与Claude 3.5 Sonnet、Llama 3.3 70B生成的两种解释风格（基于特征和反事实）对行为指标（点击率）和感知结果（如信任、风险、清晰度）的影响。

Result: LLM生成的优质解释在降低钓鱼易感性上等同或优于人工解释，其中Claude表现尤为突出；基于特征的解释对真实钓鱼更有效，反事实解释减少误报率。工作量、性别和警告熟悉度等因素显著调节警告效果。

Conclusion: LLMs可自动生成钓鱼警告解释，此类解决方案具备可扩展性、适应性，且符合以人为本的价值观。

Abstract: Phishing has become a prominent risk in modern cybersecurity, often used to
bypass technological defences by exploiting predictable human behaviour.
Warning dialogues are a standard mitigation measure, but the lack of
explanatory clarity and static content limits their effectiveness. In this
paper, we report on our research to assess the capacity of Large Language
Models (LLMs) to generate clear, concise, and scalable explanations for
phishing warnings. We carried out a large-scale between-subjects user study (N
= 750) to compare the influence of warning dialogues supplemented with manually
generated explanations against those generated by two LLMs, Claude 3.5 Sonnet
and Llama 3.3 70B. We investigated two explanatory styles (feature-based and
counterfactual) for their effects on behavioural metrics (click-through rate)
and perceptual outcomes (e.g., trust, risk, clarity). The results indicate that
well-constructed LLM-generated explanations can equal or surpass manually
crafted explanations in reducing susceptibility to phishing; Claude-generated
warnings exhibited particularly robust performance. Feature-based explanations
were more effective for genuine phishing attempts, whereas counterfactual
explanations diminished false-positive rates. Other variables such as workload,
gender, and prior familiarity with warning dialogues significantly moderated
warning effectiveness. These results indicate that LLMs can be used to
automatically build explanations for warning users against phishing, and that
such solutions are scalable, adaptive, and consistent with human-centred
values.

</details>


### [52] [KeyDroid: A Large-Scale Analysis of Secure Key Storage in Android Apps](https://arxiv.org/abs/2507.07927)
*Jenny Blessing,Ross J. Anderson,Alastair R. Beresford*

Main category: cs.CR

TL;DR: 首次全面调查Android设备中硬件支持密钥存储的使用情况，发现多数处理敏感数据的应用未充分利用可信硬件，且安全元件性能影响显著。


<details>
  <summary>Details</summary>
Motivation: 研究Android应用开发者对可信硬件的使用现状，评估硬件密钥存储的性能影响，填补该领域实证研究的空白。

Method: 分析490,119个Android应用的使用数据，结合Play Store的数据安全标签，并实测移动设备中可信硬件的加密操作运行时。

Result: 56.3%处理敏感数据的应用未使用可信硬件；仅5.03%采用最高安全级别的安全元件。硬件加密性能测试显示，安全元件导致对称/非对称加密性能显著下降。

Conclusion: 尽管行业推动可信硬件普及，但实际采用率低。安全元件虽提供高级防护，但性能代价使其难以支持大规模加密操作，需权衡安全与实用性。

Abstract: Most contemporary mobile devices offer hardware-backed storage for
cryptographic keys, user data, and other sensitive credentials. Such hardware
protects credentials from extraction by an adversary who has compromised the
main operating system, such as a malicious third-party app. Since 2011, Android
app developers can access trusted hardware via the Android Keystore API. In
this work, we conduct the first comprehensive survey of hardware-backed key
storage in Android devices. We analyze 490 119 Android apps, collecting data on
how trusted hardware is used by app developers (if used at all) and
cross-referencing our findings with sensitive user data collected by each app,
as self-reported by developers via the Play Store's data safety labels.
  We find that despite industry-wide initiatives to encourage adoption, 56.3%
of apps self-reporting as processing sensitive user data do not use Android's
trusted hardware capabilities at all, while just 5.03% of apps collecting some
form of sensitive data use the strongest form of trusted hardware, a secure
element distinct from the main processor. To better understand the potential
downsides of using secure hardware, we conduct the first empirical analysis of
trusted hardware performance in mobile devices, measuring the runtime of common
cryptographic operations across both software- and hardware-backed keystores.
We find that while hardware-backed key storage using a coprocessor is viable
for most common cryptographic operations, secure elements capable of preventing
more advanced attacks make performance infeasible for symmetric encryption with
non-negligible payloads and any kind of asymmetric encryption.

</details>


### [53] [EinHops: Einsum Notation for Expressive Homomorphic Operations on RNS-CKKS Tensors](https://arxiv.org/abs/2507.07972)
*Karthik Garimella,Austin Ebel,Brandon Reagen*

Main category: cs.CR

TL;DR: 本文提出EinHops系统，利用爱因斯坦求和（einsum）符号解决全同态加密（FHE）中多维张量运算的难题，通过显式编码维度结构实现透明化数据打包策略。


<details>
  <summary>Details</summary>
Motivation: 全同态加密仅支持一维向量运算（如SIMD加法/乘法、循环移位），传统多维张量运算需强制降维处理，现有系统抽象层级过高导致调试与优化困难。

Method: 将einsum表达式分解为FHE兼容操作序列，构建EinHops系统，显式暴露张量打包逻辑，支持从转置到复杂张量缩并等运算。

Result: 实验表明基于einsum的FHE张量系统兼具简洁性、通用性与可解释性，已在GitHub开源（https://github.com/baahl-nyu/einhops）。

Conclusion: EinHops通过einsum语法天然揭示维度结构，为加密张量运算提供了透明化、可扩展的解决方案。

Abstract: Fully Homomorphic Encryption (FHE) is an encryption scheme that allows for
computation to be performed directly on encrypted data, effectively closing the
loop on secure and outsourced computing. Data is encrypted not only during rest
and transit, but also during processing. However, FHE provides a limited
instruction set: SIMD addition, SIMD multiplication, and cyclic rotation of 1-D
vectors. This restriction makes performing multi-dimensional tensor operations
challenging. Practitioners must pack these tensors into 1-D vectors and map
tensor operations onto this one-dimensional layout rather than their
traditional nested structure. And while prior systems have made significant
strides in automating this process, they often hide critical packing decisions
behind layers of abstraction, making debugging, optimizing, and building on top
of these systems difficult.
  In this work, we approach multi-dimensional tensor operations in FHE through
Einstein summation (einsum) notation. Einsum notation explicitly encodes
dimensional structure and operations in its syntax, naturally exposing how
tensors should be packed and transformed. We decompose einsum expressions into
a fixed set of FHE-friendly operations. We implement our design and present
EinHops, a minimalist system that factors einsum expressions into a fixed
sequence of FHE operations. EinHops enables developers to perform encrypted
tensor operations using FHE while maintaining full visibility into the
underlying packing strategy. We evaluate EinHops on a range of tensor
operations from a simple transpose to complex multi-dimensional contractions.
We show that the explicit nature of einsum notation allows us to build an FHE
tensor system that is simple, general, and interpretable. We open-source
EinHops at the following repository: https://github.com/baahl-nyu/einhops.

</details>


### [54] [Defending Against Prompt Injection With a Few DefensiveTokens](https://arxiv.org/abs/2507.07974)
*Sizhe Chen,Yizhu Wang,Nicholas Carlini,Chawin Sitawarin,David Wagner*

Main category: cs.CR

TL;DR: 本文提出DefensiveToken方法，通过插入特殊令牌优化嵌入以防御LLM系统的提示注入攻击，实现测试时灵活切换安全性与实用性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)系统在交互外部数据时易受提示注入攻击，现有测试时防御措施效果远逊于训练时防御，亟需高效解决方案。

Method: 通过插入DefensiveToken特殊令牌并优化其嵌入，开发者可在输入前添加少量防御令牌实现安全防护，或跳过令牌保持原始性能。

Result: DefensiveToken在测试时提供接近训练时防御的安全强度，同时允许灵活选择最优实用性或安全性，代码已开源。

Conclusion: 该方法首次实现测试时防御与训练时防御可比拟的鲁棒性，为LLM系统提供安全性与实用性的动态平衡方案。

Abstract: When large language model (LLM) systems interact with external data to
perform complex tasks, a new attack, namely prompt injection, becomes a
significant threat. By injecting instructions into the data accessed by the
system, the attacker is able to override the initial user task with an
arbitrary task directed by the attacker. To secure the system, test-time
defenses, e.g., defensive prompting, have been proposed for system developers
to attain security only when needed in a flexible manner. However, they are
much less effective than training-time defenses that change the model
parameters. Motivated by this, we propose DefensiveToken, a test-time defense
with prompt injection robustness comparable to training-time alternatives.
DefensiveTokens are newly inserted as special tokens, whose embeddings are
optimized for security. In security-sensitive cases, system developers can
append a few DefensiveTokens before the LLM input to achieve security with a
minimal utility drop. In scenarios where security is less of a concern,
developers can simply skip DefensiveTokens; the LLM system remains the same as
there is no defense, generating high-quality responses. Thus, DefensiveTokens,
if released alongside the model, allow a flexible switch between the
state-of-the-art (SOTA) utility and almost-SOTA security at test time. The code
is available at https://github.com/Sizhe-Chen/DefensiveToken.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [55] [Working with AI: Measuring the Occupational Implications of Generative AI](https://arxiv.org/abs/2507.07935)
*Kiran Tomlinson,Sonia Jaffe,Will Wang,Scott Counts,Siddharth Suri*

Main category: cs.AI

TL;DR: 研究分析了生成式AI对经济的影响，通过200k用户与微软Bing Copilot的对话数据，发现AI最常协助信息收集与写作任务，并计算了各职业的AI适用性得分。


<details>
  <summary>Details</summary>
Motivation: 鉴于生成式AI的快速普及及其对广泛任务的潜在影响，理解AI对经济的影响成为社会最重要的问题之一。

Method: 研究分析了20万条用户与微软Bing Copilot的匿名对话数据，结合职业活动分类、任务成功率和影响范围，计算了各职业的AI适用性得分。

Result: 研究发现，AI最常协助的任务是信息收集与写作，而AI自身最常执行的任务是提供信息、写作、教学和建议。计算机与数学、办公室与行政支持以及销售等职业的AI适用性得分最高。

Conclusion: 研究表明，生成式AI对知识型职业的影响最为显著，且工资和教育水平与AI适用性存在相关性，实际使用情况与职业AI影响的预测存在差异。

Abstract: Given the rapid adoption of generative AI and its potential to impact a wide
range of tasks, understanding the effects of AI on the economy is one of
society's most important questions. In this work, we take a step toward that
goal by analyzing the work activities people do with AI, how successfully and
broadly those activities are done, and combine that with data on what
occupations do those activities. We analyze a dataset of 200k anonymized and
privacy-scrubbed conversations between users and Microsoft Bing Copilot, a
publicly available generative AI system. We find the most common work
activities people seek AI assistance for involve gathering information and
writing, while the most common activities that AI itself is performing are
providing information and assistance, writing, teaching, and advising.
Combining these activity classifications with measurements of task success and
scope of impact, we compute an AI applicability score for each occupation. We
find the highest AI applicability scores for knowledge work occupation groups
such as computer and mathematical, and office and administrative support, as
well as occupations such as sales whose work activities involve providing and
communicating information. Additionally, we characterize the types of work
activities performed most successfully, how wage and education correlate with
AI applicability, and how real-world usage compares to predictions of
occupational AI impact.

</details>


### [56] [Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation](https://arxiv.org/abs/2507.07115)
*Javal Vyas,Mehmet Mercangoz*

Main category: cs.AI

TL;DR: 本文提出了一种结合大型语言模型（LLMs）的统一智能体框架，用于化学工程中的离散故障恢复规划和连续过程控制，通过有限状态机（FSMs）和验证-重提示循环实现高效控制，并在案例研究中展示了优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现代化学过程日益复杂，加上劳动力短缺和故障场景的复杂性，需要结合符号推理和自适应控制的新型自动化范式。

Method: 采用有限状态机（FSMs）作为可解释的操作框架，由LLM驱动的规划代理提出恢复序列，仿真代理执行和检查每个过渡，验证-重提示循环迭代优化无效计划。

Result: 在案例研究1中，GPT-4o和GPT-4o-mini在180个随机生成的FSMs中实现了100%的有效路径成功率；在案例研究2中，LLM-based控制器在双加热器控制中表现与传统PID控制相当，且能更好地处理非线性动态。

Conclusion: 研究表明，通过结构化反馈和模块化智能体，LLMs可以统一高层符号规划和低层连续控制，为化学工程中的弹性、语言驱动自动化铺平道路。

Abstract: The increasing complexity of modern chemical processes, coupled with
workforce shortages and intricate fault scenarios, demands novel automation
paradigms that blend symbolic reasoning with adaptive control. In this work, we
introduce a unified agentic framework that leverages large language models
(LLMs) for both discrete fault-recovery planning and continuous process control
within a single architecture. We adopt Finite State Machines (FSMs) as
interpretable operating envelopes: an LLM-driven planning agent proposes
recovery sequences through the FSM, a Simulation Agent executes and checks each
transition, and a Validator-Reprompting loop iteratively refines invalid plans.
In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25
states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path
success within five reprompts-outperforming open-source LLMs in both accuracy
and latency. In Case Study 2, the same framework modulates dual-heater inputs
on a laboratory TCLab platform (and its digital twin) to maintain a target
average temperature under persistent asymmetric disturbances. Compared to
classical PID control, our LLM-based controller attains similar performance,
while ablation of the prompting loop reveals its critical role in handling
nonlinear dynamics. We analyze key failure modes-such as instruction following
lapses and coarse ODE approximations. Our results demonstrate that, with
structured feedback and modular agents, LLMs can unify high-level symbolic
planningand low-level continuous control, paving the way towards resilient,
language-driven automation in chemical engineering.

</details>


### [57] [BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks](https://arxiv.org/abs/2507.07134)
*Mridula Vijendran,Shuang Chen,Jingjing Deng,Hubert P. H. Shum*

Main category: cs.AI

TL;DR: 本文提出了一种名为BOOST的新方法，通过动态调整温度缩放和采样概率，解决AI绘画分类中的偏见问题，特别是在处理分布外数据时。该方法在KaoKore和PACS数据集上验证了其有效性，并提出了新的评估指标SODC。


<details>
  <summary>Details</summary>
Motivation: AI绘画分类中的偏见问题日益严重，尤其是在艺术策展和修复等任务中。偏见主要源于数据集的不平衡，导致模型对罕见绘画风格的分类准确性下降。现有研究在提高分类性能的同时，忽视了解决这些潜在偏见的重要性。

Method: 我们提出了一种名为BOOST（Bias-Oriented OOD Sampling and Tuning）的新方法，通过动态调整温度缩放和采样概率，促进所有类别的公平表示。此外，我们还提出了一个新的评估指标SODC（Same-Dataset OOD Detection Score），用于评估类别间的分离和每类偏见的减少。

Result: 在KaoKore和PACS数据集上的实验表明，BOOST方法能够有效减少类别偏见，同时在性能和公平性之间取得平衡。

Conclusion: BOOST方法为艺术领域的AI模型去偏见提供了一个稳健的解决方案，能够在保持高性能的同时实现公平性。

Abstract: The pervasive issue of bias in AI presents a significant challenge to
painting classification, and is getting more serious as these systems become
increasingly integrated into tasks like art curation and restoration. Biases,
often arising from imbalanced datasets where certain artistic styles dominate,
compromise the fairness and accuracy of model predictions, i.e., classifiers
are less accurate on rarely seen paintings. While prior research has made
strides in improving classification performance, it has largely overlooked the
critical need to address these underlying biases, that is, when dealing with
out-of-distribution (OOD) data. Our insight highlights the necessity of a more
robust approach to bias mitigation in AI models for art classification on
biased training data. We propose a novel OOD-informed model bias adaptive
sampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It
addresses these challenges by dynamically adjusting temperature scaling and
sampling probabilities, thereby promoting a more equitable representation of
all classes. We evaluate our proposed approach to the KaoKore and PACS
datasets, focusing on the model's ability to reduce class-wise bias. We further
propose a new metric, Same-Dataset OOD Detection Score (SODC), designed to
assess class-wise separation and per-class bias reduction. Our method
demonstrates the ability to balance high performance with fairness, making it a
robust solution for unbiasing AI models in the art domain.

</details>


### [58] [State-Inference-Based Prompting for Natural Language Trading with Game NPCs](https://arxiv.org/abs/2507.07203)
*Minkyung Kim,Junsik Kim,Hwidong Bae,Woongcheol Yang,Sangdon Park,Sohee Bae*

Main category: cs.AI

TL;DR: 论文提出状态推断提示法(SIBP)，通过自主对话状态推断和上下文规则遵守，解决大语言模型在规则化交易系统中的可靠性问题，实现97%以上的状态合规性和99.7%的计算精度。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在规则化交易系统中存在规则违反问题（如物品幻觉和计算错误），导致玩家信任度下降，需要一种可靠的方法来提升NPC交互的可信度。

Method: 采用状态推断提示法(SIBP)，将交易分解为六个状态，在统一提示框架内实现上下文感知的物品引用和基于占位符的价格计算。

Result: 在100个交易对话评估中，SIBP实现>97%的状态合规率、>95%的引用准确率和99.7%的计算精度，计算效率优于基线方法。

Conclusion: SIBP为商业游戏中可信NPC交互提供了实用基础，在保持计算效率的同时显著提升规则遵守能力。

Abstract: Large Language Models enable dynamic game interactions but struggle with
rule-governed trading systems. Current implementations suffer from rule
violations, such as item hallucinations and calculation errors, that erode
player trust. Here, State-Inference-Based Prompting (SIBP) enables reliable
trading through autonomous dialogue state inference and context-specific rule
adherence. The approach decomposes trading into six states within a unified
prompt framework, implementing context-aware item referencing and
placeholder-based price calculations. Evaluation across 100 trading dialogues
demonstrates >97% state compliance, >95% referencing accuracy, and 99.7%
calculation precision. SIBP maintains computational efficiency while
outperforming baseline approaches, establishing a practical foundation for
trustworthy NPC interactions in commercial games.

</details>


### [59] [Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains](https://arxiv.org/abs/2507.07217)
*Zili Wang,Frank Montabon,Kristin Yvonne Rozier*

Main category: cs.AI

TL;DR: 供应链网络是复杂系统，涉及非法活动时分析更为困难。本文探讨了神经符号方法在稀疏且不可靠数据中识别非法活动的有效性，并比较了人工与自动特征提取的差异。


<details>
  <summary>Details</summary>
Motivation: 供应链中的非法活动（如假冒零件、强迫劳动）数据稀疏且常被故意破坏，传统机器学习方法需要大量训练数据，难以应对此类问题。

Method: 采用神经符号方法，提出基于问题树的LLM查询方法，系统评估人工与机器对强迫劳动相关新闻文章分类的差异。

Result: 研究表明，神经符号方法能在稀疏数据中有效识别非法活动模式，问题树方法有助于量化文章相关性。

Conclusion: 神经符号方法和LLM查询为供应链非法活动检测提供了新途径，尤其在数据稀缺和不可靠情况下表现突出。

Abstract: Supply chain networks are complex systems that are challenging to analyze;
this problem is exacerbated when there are illicit activities involved in the
supply chain, such as counterfeit parts, forced labor, or human trafficking.
While machine learning (ML) can find patterns in complex systems like supply
chains, traditional ML techniques require large training data sets. However,
illicit supply chains are characterized by very sparse data, and the data that
is available is often (purposely) corrupted or unreliable in order to hide the
nature of the activities. We need to be able to automatically detect new
patterns that correlate with such illegal activity over complex, even temporal
data, without requiring large training data sets. We explore neurosymbolic
methods for identifying instances of illicit activity in supply chains and
compare the effectiveness of manual and automated feature extraction from news
articles accurately describing illicit activities uncovered by authorities. We
propose a question tree approach for querying a large language model (LLM) to
identify and quantify the relevance of articles. This enables a systematic
evaluation of the differences between human and machine classification of news
articles related to forced labor in supply chains.

</details>


### [60] [Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery](https://arxiv.org/abs/2507.07257)
*Licong Xu,Milind Sarkar,Anto I. Lonappan,Íñigo Zubeldia,Pablo Villanueva-Domingo,Santiago Casas,Christian Fidler,Chetana Amancharla,Ujjwal Tiwari,Adrian Bayer,Chadi Ait Ekiou,Miles Cranmer,Adrian Dimitrov,James Fergusson,Kahaan Gandhi,Sven Krippendorf,Andrew Laverick,Julien Lesgourgues,Antony Lewis,Thomas Meier,Blake Sherwin,Kristen Surrao,Francisco Villaescusa-Navarro,Chi Wang,Xueqing Xu,Boris Bolliet*

Main category: cs.AI

TL;DR: 本文介绍了cmbagent，一个由约30个大型语言模型（LLM）代理组成的多智能体系统，用于自动化科学研究任务。该系统采用规划与控制策略协调工作流，无需人工干预，并在宇宙学任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个完全自动化的多智能体系统，以执行复杂的科学研究任务，减少人工干预并提高效率。

Method: 系统由约30个LLM代理组成，各司其职（如检索科学论文与代码库、编写代码、解释结果、评审其他代理输出），采用规划与控制策略协调工作流，并支持本地代码执行。

Result: 该系统成功应用于宇宙学博士级任务（利用超新星数据测量宇宙学参数），在两项基准测试中表现优于当前最先进的LLM模型。

Conclusion: cmbagent展示了多智能体系统在自动化科学研究中的潜力，其代码已开源，并部署于HuggingFace及云端平台。

Abstract: We present a multi-agent system for automation of scientific research tasks,
cmbagent. The system is formed by about 30 Large Language Model (LLM) agents
and implements a Planning & Control strategy to orchestrate the agentic
workflow, with no human-in-the-loop at any point. Each agent specializes in a
different task (performing retrieval on scientific papers and codebases,
writing code, interpreting results, critiquing the output of other agents) and
the system is able to execute code locally. We successfully apply cmbagent to
carry out a PhD level cosmology task (the measurement of cosmological
parameters using supernova data) and evaluate its performance on two benchmark
sets, finding superior performance over state-of-the-art LLMs. The source code
is available on GitHub, demonstration videos are also available, and the system
is deployed on HuggingFace and will be available on the cloud.

</details>


### [61] [Application of LLMs to Multi-Robot Path Planning and Task Allocation](https://arxiv.org/abs/2507.07302)
*Ashish Kumar*

Main category: cs.AI

TL;DR: 本文研究利用大型语言模型作为专家规划器，提升多智能体强化学习在规划任务中的探索效率。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中的探索效率问题因算法复杂性而加剧，需要有效方法提升任务解决能力。

Method: 采用大型语言模型作为专家规划器，指导多智能体在规划任务中进行高效探索。

Result: 研究表明，大型语言模型能有效提升多智能体在规划任务中的探索效率。

Conclusion: 利用大型语言模型作为专家规划器是多智能体强化学习中提升探索效率的有效途径。

Abstract: Efficient exploration is a well known problem in deep reinforcement learning
and this problem is exacerbated in multi-agent reinforcement learning due the
intrinsic complexities of such algorithms. There are several approaches to
efficiently explore an environment to learn to solve tasks by multi-agent
operating in that environment, of which, the idea of expert exploration is
investigated in this work. More specifically, this work investigates the
application of large-language models as expert planners for efficient
exploration in planning based tasks for multiple agents.

</details>


### [62] [ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning](https://arxiv.org/abs/2507.07306)
*Yichen Lu,Wei Dai,Jiaen Liu,Ching Wing Kwok,Zongheng Wu,Xudong Xiao,Ao Sun,Sheng Fu,Jianyuan Zhan,Yian Wang,Takatomo Saito,Sicheng Lai*

Main category: cs.AI

TL;DR: 本文提出ViDove多模态翻译系统，通过整合视觉背景与领域知识，在字幕生成和通用翻译任务中显著提升质量（BLEU提升28%，SubER提升15%），并发布DoveBench长视频字幕翻译基准。


<details>
  <summary>Details</summary>
Motivation: 现有LLM翻译代理仅支持文本输入，无法利用视觉上下文信息。受人类译者工作流程启发，需开发能处理多模态输入的翻译系统以提升真实场景适应性。

Method: 1. 模拟人类译者流程，引入视觉与上下文背景信息\n2. 集成多模态记忆系统\n3. 结合长短时记忆模块与领域知识\n4. 构建DoveBench基准（17小时人工标注数据）

Result: 1. BLEU分数提升28%，SubER指标提升15%\n2. 在长视频字幕生成任务中表现优于SOTA基线\n3. 代码已开源（GitHub仓库pigeonai-org/ViDove）

Conclusion: ViDove通过多模态信息融合与记忆增强机制，显著提升翻译质量，为视频字幕等现实场景提供有效解决方案，同时发布的基准将推动相关研究发展。

Abstract: LLM-based translation agents have achieved highly human-like translation
results and are capable of handling longer and more complex contexts with
greater efficiency. However, they are typically limited to text-only inputs. In
this paper, we introduce ViDove, a translation agent system designed for
multimodal input. Inspired by the workflow of human translators, ViDove
leverages visual and contextual background information to enhance the
translation process. Additionally, we integrate a multimodal memory system and
long-short term memory modules enriched with domain-specific knowledge,
enabling the agent to perform more accurately and adaptively in real-world
scenarios. As a result, ViDove achieves significantly higher translation
quality in both subtitle generation and general translation tasks, with a 28%
improvement in BLEU scores and a 15% improvement in SubER compared to previous
state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark
for long-form automatic video subtitling and translation, featuring 17 hours of
high-quality, human-annotated data. Our code is available here:
https://github.com/pigeonai-org/ViDove

</details>


### [63] [On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment](https://arxiv.org/abs/2507.07341)
*Sarah Ball,Greg Gluch,Shafi Goldwasser,Frauke Kreuter,Omer Reingold,Guy N. Rothblum*

Main category: cs.AI

TL;DR: 研究探讨大型语言模型(LLM)的安全对齐挑战，聚焦于输入提示和输出过滤的计算困难性，证明外部过滤机制存在根本性局限，主张安全需内建于模型架构中。


<details>
  <summary>Details</summary>
Motivation: 随着LLM广泛应用，其生成有害内容的风险引发关注。研究旨在探索通过输入/输出过滤实现安全对齐的计算可行性边界。

Method: 采用计算复杂性理论分析，基于密码学硬度假设，证明对抗性提示构造的不可避免性及输出过滤的计算不可行性，并形式化放松的缓解方案。

Result: 核心发现：1)存在无法高效检测的对抗性提示 2)特定场景下输出过滤具计算不可行性 3)黑盒访问LLM无法实现安全。所有结论均依赖密码学假设。

Conclusion: 安全过滤无法脱离模型内部结构独立实现，AI系统的智能与判断必须一体化设计。研究成果为安全对齐提供了理论边界指引。

Abstract: With the increased deployment of large language models (LLMs), one concern is
their potential misuse for generating harmful content. Our work studies the
alignment challenge, with a focus on filters to prevent the generation of
unsafe information. Two natural points of intervention are the filtering of the
input prompt before it reaches the model, and filtering the output after
generation. Our main results demonstrate computational challenges in filtering
both prompts and outputs. First, we show that there exist LLMs for which there
are no efficient prompt filters: adversarial prompts that elicit harmful
behavior can be easily constructed, which are computationally indistinguishable
from benign prompts for any efficient filter. Our second main result identifies
a natural setting in which output filtering is computationally intractable. All
of our separation results are under cryptographic hardness assumptions. In
addition to these core findings, we also formalize and study relaxed mitigation
approaches, demonstrating further computational barriers. We conclude that
safety cannot be achieved by designing filters external to the LLM internals
(architecture and weights); in particular, black-box access to the LLM will not
suffice. Based on our technical results, we argue that an aligned AI system's
intelligence cannot be separated from its judgment.

</details>


### [64] [Supply Chain Optimization via Generative Simulation and Iterative Decision Policies](https://arxiv.org/abs/2507.07355)
*Haoyue Bai,Haoyu Wang,Nanxu Gong,Xinyuan Wang,Wangyang Ying,Haifeng Chen,Yanjie Fu*

Main category: cs.AI

TL;DR: 提出Sim-to-Dec框架，结合生成模拟与双感知决策模型，显著提升供应链运输的及时交付率和利润。


<details>
  <summary>Details</summary>
Motivation: 供应链运输的高响应性与经济效率受运输模式战略决策影响，需可观测、低风险的策略设计环境。

Method: 框架包含自回归生成模拟模块（减少手工规则依赖）和基于模拟反馈迭代优化的历史-未来双感知决策模型。

Result: 三个真实数据集实验表明，该框架在及时交付率和利润指标上显著优于基线方法。

Conclusion: Sim-to-Dec通过紧密耦合模拟与策略优化，实现了跨场景泛化能力和细粒度动态建模的统一。

Abstract: High responsiveness and economic efficiency are critical objectives in supply
chain transportation, both of which are influenced by strategic decisions on
shipping mode. An integrated framework combining an efficient simulator with an
intelligent decision-making algorithm can provide an observable, low-risk
environment for transportation strategy design. An ideal simulation-decision
framework must (1) generalize effectively across various settings, (2) reflect
fine-grained transportation dynamics, (3) integrate historical experience with
predictive insights, and (4) maintain tight integration between simulation
feedback and policy refinement. We propose Sim-to-Dec framework to satisfy
these requirements. Specifically, Sim-to-Dec consists of a generative
simulation module, which leverages autoregressive modeling to simulate
continuous state changes, reducing dependence on handcrafted domain-specific
rules and enhancing robustness against data fluctuations; and a history-future
dual-aware decision model, refined iteratively through end-to-end optimization
with simulator interactions. Extensive experiments conducted on three
real-world datasets demonstrate that Sim-to-Dec significantly improves timely
delivery rates and profit.

</details>


### [65] [DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search](https://arxiv.org/abs/2507.07426)
*Zerui Yang,Yuwei Wan,Yinqiao Li,Yudai Matsuda,Tong Xie,Linqi Song*

Main category: cs.AI

TL;DR: 本文提出DrugMCTS框架，结合RAG、多智能体协作与蒙特卡洛树搜索，无需微调即可显著提升大语言模型在药物重定向任务中的性能，在DrugBank和KIBA数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在科学领域（如药物发现）的推理能力受限于预训练知识，传统方法（微调或检索增强生成）存在计算成本高或难以充分利用结构化科学数据的缺陷。

Method: 提出DrugMCTS框架：整合检索增强生成（RAG）、5个专项分析分子与蛋白质信息的智能体协作，以及蒙特卡洛树搜索，实现结构化迭代推理，无需领域微调。

Result: Qwen2.5-7B-Instruct模型性能超越Deepseek-R1达20\%以上；在DrugBank和KIBA数据集上，召回率与鲁棒性显著优于通用大语言模型和深度学习基线。

Conclusion: 结构化推理、智能体协作及反馈驱动搜索机制对推进大语言模型在药物发现中的应用至关重要，DrugMCTS为领域内性能提升提供了有效方案。

Abstract: Recent advances in large language models have demonstrated considerable
potential in scientific domains such as drug discovery. However, their
effectiveness remains constrained when reasoning extends beyond the knowledge
acquired during pretraining. Conventional approaches, such as fine-tuning or
retrieval-augmented generation, face limitations in either imposing high
computational overhead or failing to fully exploit structured scientific data.
To overcome these challenges, we propose DrugMCTS, a novel framework that
synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree
Search for drug repurposing. The framework employs five specialized agents
tasked with retrieving and analyzing molecular and protein information, thereby
enabling structured and iterative reasoning. Without requiring domain-specific
fine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by
over 20\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate
that DrugMCTS achieves substantially higher recall and robustness compared to
both general-purpose LLMs and deep learning baselines. Our results highlight
the importance of structured reasoning, agent-based collaboration, and
feedback-driven search mechanisms in advancing LLM applications for drug
discovery.

</details>


### [66] [StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley](https://arxiv.org/abs/2507.07445)
*Weihao Tan,Changjiu Jiang,Yu Duan,Mingcong Lei,Jiageng Li,Yitian Hong,Xinrun Wang,Bo An*

Main category: cs.AI

TL;DR: StarDojo是一个基于《星露谷物语》的新型基准测试，旨在评估AI代理在开放式生产生活模拟中的综合能力，涵盖农业、制造、探索、战斗和社交互动五大领域。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试很少同时评估生产活动与社交互动能力，StarDojo旨在填补这一空白，推动复杂生产生活环境中稳健开放式代理的研究。

Method: 通过1,000项精心设计的任务（含100项核心子集）评估代理能力，提供统一接口支持多系统并行运行，特别适配多模态大语言模型（MLLMs）驱动的代理。

Result: 当前最先进的MLLMs代理表现有限，最佳模型GPT-4.1成功率仅12.7%，主要受限于视觉理解、多模态推理和底层操作能力。

Conclusion: StarDojo作为用户友好的环境与基准，将促进复杂生产生活环境中开放式代理的研究，揭示现有模型在跨模态任务中的显著不足。

Abstract: Autonomous agents navigating human society must master both production
activities and social interactions, yet existing benchmarks rarely evaluate
these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel
benchmark based on Stardew Valley, designed to assess AI agents in open-ended
production-living simulations. In StarDojo, agents are tasked to perform
essential livelihood activities such as farming and crafting, while
simultaneously engaging in social interactions to establish relationships
within a vibrant community. StarDojo features 1,000 meticulously curated tasks
across five key domains: farming, crafting, exploration, combat, and social
interactions. Additionally, we provide a compact subset of 100 representative
tasks for efficient model evaluation. The benchmark offers a unified,
user-friendly interface that eliminates the need for keyboard and mouse
control, supports all major operating systems, and enables the parallel
execution of multiple environment instances, making it particularly well-suited
for evaluating the most capable foundation agents, powered by multimodal large
language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents
demonstrate substantial limitations, with the best-performing model, GPT-4.1,
achieving only a 12.7% success rate, primarily due to challenges in visual
understanding, multimodal reasoning and low-level manipulation. As a
user-friendly environment and benchmark, StarDojo aims to facilitate further
research towards robust, open-ended agents in complex production-living
environments.

</details>


### [67] [Position: We Need An Algorithmic Understanding of Generative AI](https://arxiv.org/abs/2507.07544)
*Oliver Eberle,Thomas McGee,Hamza Giaffar,Taylor Webb,Ida Momennejad*

Main category: cs.AI

TL;DR: 本文提出AlgEval框架，旨在系统研究大语言模型(LLM)学习与使用的算法，通过案例研究揭示其潜在算法结构，为理解模型内部计算提供新途径。


<details>
  <summary>Details</summary>
Motivation: 当前研究多关注通过规模提升性能，缺乏对LLM实际学习算法的理论实证研究，需建立系统化评估框架填补这一空白。

Method: 提出AlgEval框架，结合自上而下的算法假设与自下而上的注意力模式/隐状态电路分析，以涌现搜索算法为案例进行研究。

Result: 案例研究表明可通过分析潜在表征、注意力和推理计算来识别算法基元及其组合方式，为算法可解释性提供实证基础。

Conclusion: 算法层面的解释能实现人类可理解的模型推理机制，为高效训练、性能提升及新型架构设计提供理论基础，替代资源密集的规模扩展路径。

Abstract: What algorithms do LLMs actually learn and use to solve problems? Studies
addressing this question are sparse, as research priorities are focused on
improving performance through scale, leaving a theoretical and empirical gap in
understanding emergent algorithms. This position paper proposes AlgEval: a
framework for systematic research into the algorithms that LLMs learn and use.
AlgEval aims to uncover algorithmic primitives, reflected in latent
representations, attention, and inference-time compute, and their algorithmic
composition to solve task-specific problems. We highlight potential
methodological paths and a case study toward this goal, focusing on emergent
search algorithms. Our case study illustrates both the formation of top-down
hypotheses about candidate algorithms, and bottom-up tests of these hypotheses
via circuit-level analysis of attention patterns and hidden states. The
rigorous, systematic evaluation of how LLMs actually solve tasks provides an
alternative to resource-intensive scaling, reorienting the field toward a
principled understanding of underlying computations. Such algorithmic
explanations offer a pathway to human-understandable interpretability, enabling
comprehension of the model's internal reasoning performance measures. This can
in turn lead to more sample-efficient methods for training and improving
performance, as well as novel architectures for end-to-end and multi-agent
systems.

</details>


### [68] [On Trustworthy Rule-Based Models and Explanations](https://arxiv.org/abs/2507.07576)
*Mohamed Siala,Jordi Planes,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本文探讨了机器学习中基于规则的模型解释性问题，指出其存在的负面特征，并提出分析算法，发现常用学习工具会导致规则集出现这些问题。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域，机器学习模型的解释准确性至关重要。错误的解释会误导人类决策者，因此需要深入研究基于规则的模型存在的负面特征。

Method: 论文开发了算法来分析基于规则的系统中的负面特征，如负重叠和冗余等问题。

Result: 研究发现，广泛使用的基于规则模型学习工具会导致规则集出现一种或多种负面特征。

Conclusion: 基于规则的机器学习模型在高风险应用中存在解释性问题，常用工具生成的规则集可能包含负面特征，需进一步优化。

Abstract: A task of interest in machine learning (ML) is that of ascribing explanations
to the predictions made by ML models. Furthermore, in domains deemed high risk,
the rigor of explanations is paramount. Indeed, incorrect explanations can and
will mislead human decision makers. As a result, and even if interpretability
is acknowledged as an elusive concept, so-called interpretable models are
employed ubiquitously in high-risk uses of ML and data mining (DM). This is the
case for rule-based ML models, which encompass decision trees, diagrams, sets
and lists. This paper relates explanations with well-known undesired facets of
rule-based ML models, which include negative overlap and several forms of
redundancy. The paper develops algorithms for the analysis of these undesired
facets of rule-based systems, and concludes that well-known and widely used
tools for learning rule-based ML models will induce rule sets that exhibit one
or more negative facets.

</details>


### [69] [Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs](https://arxiv.org/abs/2507.07595)
*Zhixiang Su,Di Wang,Chunyan Miao*

Main category: cs.AI

TL;DR: 本文提出了一种名为Context Pooling的新方法，用于提升基于图神经网络（GNN）的知识图谱（KG）链接预测模型性能。该方法首次在KG中应用图池化，并能在归纳设置中生成查询特定图。实验表明，该方法在多个数据集上达到了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于GNN的KG链接预测模型中，普通聚合操作对性能提升有限。因此，需要一种新方法来更有效地利用图结构信息，特别是在归纳设置中处理未见实体。

Method: 提出Context Pooling方法，首次在KG中应用图池化。设计了邻域精度和邻域召回两个指标评估邻居的逻辑相关性，从而筛选出与查询逻辑相关的邻居用于链接预测。该方法通用性强，可应用于多种SOTA模型。

Result: 在三个公开的转导和归纳数据集上测试了两个SOTA模型，在48种设置中的42种达到了最先进性能。

Conclusion: Context Pooling是首个在KG中应用图池化的方法，能有效提升链接预测性能，特别是在归纳设置中处理未见实体时表现优异。

Abstract: Recent investigations on the effectiveness of Graph Neural Network
(GNN)-based models for link prediction in Knowledge Graphs (KGs) show that
vanilla aggregation does not significantly impact the model performance. In
this paper, we introduce a novel method, named Context Pooling, to enhance
GNN-based models' efficacy for link predictions in KGs. To our best of
knowledge, Context Pooling is the first methodology that applies graph pooling
in KGs. Additionally, Context Pooling is first-of-its-kind to enable the
generation of query-specific graphs for inductive settings, where testing
entities are unseen during training. Specifically, we devise two metrics,
namely neighborhood precision and neighborhood recall, to assess the neighbors'
logical relevance regarding the given queries, thereby enabling the subsequent
comprehensive identification of only the logically relevant neighbors for link
prediction. Our method is generic and assessed by being applied to two
state-of-the-art (SOTA) models on three public transductive and inductive
datasets, achieving SOTA performance in 42 out of 48 settings.

</details>


### [70] [Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.07599)
*Sedigh Khademi,Jim Black,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila*

Main category: cs.AI

TL;DR: 本研究评估了微调Llama 3.2模型从急诊分诊记录中提取疫苗信息的能力，以支持近实时疫苗安全监测。微调的30亿参数Llama模型在疫苗名称提取准确率上优于其他方法，模型量化技术实现了资源受限环境的高效部署。


<details>
  <summary>Details</summary>
Motivation: 开发自动化工具从急诊记录中提取疫苗信息，提升疫苗安全监测效率及早期发现接种后不良事件的能力。

Method: 采用提示工程创建标注数据集并经人工核验，对比提示工程模型、微调模型与基于规则的方法。对Llama 3模型进行微调及量化处理。

Result: 微调后的30亿参数Llama模型疫苗名称提取准确率最优（F1=0.92），8位量化后模型体积缩小75%且精度损失<2%。

Conclusion: 大语言模型能有效自动化急诊记录数据提取，量化技术使其适用于临床环境，为疫苗安全监测提供了新范式。

Abstract: This study evaluates fine-tuned Llama 3.2 models for extracting
vaccine-related information from emergency department triage notes to support
near real-time vaccine safety surveillance. Prompt engineering was used to
initially create a labeled dataset, which was then confirmed by human
annotators. The performance of prompt-engineered models, fine-tuned models, and
a rule-based approach was compared. The fine-tuned Llama 3 billion parameter
model outperformed other models in its accuracy of extracting vaccine names.
Model quantization enabled efficient deployment in resource-constrained
environments. Findings demonstrate the potential of large language models in
automating data extraction from emergency department notes, supporting
efficient vaccine safety surveillance and early detection of emerging adverse
events following immunization issues.

</details>


### [71] [Towards conservative inference in credal networks using belief functions: the case of credal chains](https://arxiv.org/abs/2507.07619)
*Marco Sangalli,Thomas Krak,Cassio de Campos*

Main category: cs.AI

TL;DR: 本文提出了一种基于Dempster-Shafer理论的信用网络信念推理新框架，专注于链式结构，通过信念和似然函数高效计算保守区间，并对比了信念推理与传统敏感性分析的差异。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决信用网络中不确定性传播的问题，特别是在链式结构中，通过Dempster-Shafer理论提供一种计算高效且鲁棒的推理方法。

Method: 提出了一种新颖的框架，利用信念和似然函数在链式信用网络中传播不确定性，并形式化了基于信念的推理方法。

Result: 数值结果表明，该方法在链式结构中具有计算速度和鲁棒性优势，但也揭示了其局限性，为信用网络的普遍应用提供了实用见解。

Conclusion: 该框架为信用网络中的信念推理提供了有效工具，尤其在链式结构中表现突出，但其适用范围和局限性仍需进一步研究。

Abstract: This paper explores belief inference in credal networks using Dempster-Shafer
theory. By building on previous work, we propose a novel framework for
propagating uncertainty through a subclass of credal networks, namely chains.
The proposed approach efficiently yields conservative intervals through belief
and plausibility functions, combining computational speed with robust
uncertainty representation. Key contributions include formalizing belief-based
inference methods and comparing belief-based inference against classical
sensitivity analysis. Numerical results highlight the advantages and
limitations of applying belief inference within this framework, providing
insights into its practical utility for chains and for credal networks in
general.

</details>


### [72] [PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations](https://arxiv.org/abs/2507.07644)
*Fedor Rodionov,Abdelrahman Eldesokey,Michael Birsak,John Femiani,Bernard Ghanem,Peter Wonka*

Main category: cs.AI

TL;DR: PlanQA是一个用于评估大语言模型(LLM)几何与空间推理能力的诊断基准，基于结构化室内场景表示，揭示了当前LLM在真实世界布局推理中的明显缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在几何与空间推理方面存在不足，特别是在处理真实世界布局时缺乏一致性，需要专门的评估工具来诊断这些缺陷。

Method: 通过结构化符号格式(如JSON/XML)编码厨房、客厅等室内场景，设计多样化问题类型测试度量/拓扑推理(距离、可见性等)及室内设计约束(可达性、平衡性等)。

Result: 测试表明前沿开源/商业LLM能处理简单查询，但普遍无法模拟物理约束、保持空间连贯性或适应布局扰动，暴露出空间推理的明显盲区。

Conclusion: PlanQA揭示了当前LLM在真实空间推理上的局限性，希望推动开发能准确推断和操作实际场景几何属性的语言模型。

Abstract: We introduce PlanQA, a diagnostic benchmark for evaluating geometric and
spatial reasoning in large-language models (LLMs). PlanQA is grounded in
structured representations of indoor scenes, such as kitchens, living rooms,
and bedrooms, encoded in a symbolic format (e.g., JSON, XML layouts). The
benchmark includes diverse question types that test not only metric and
topological reasoning (e.g., distance, visibility, shortest paths) but also
interior design constraints such as affordance, clearance, balance, and
usability. Our results across a variety of frontier open-source and commercial
LLMs show that while models may succeed in shallow queries, they often fail to
simulate physical constraints, preserve spatial coherence, or generalize under
layout perturbation. PlanQA uncovers a clear blind spot in today's LLMs: they
do not consistently reason about real-world layouts. We hope that this
benchmark inspires new work on language models that can accurately infer and
manipulate spatial and geometric properties in practical settings.

</details>


### [73] [Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization](https://arxiv.org/abs/2507.07723)
*Chengtao Jian,Kai Yang,Ye Ouyang,Xiaozhou Ye*

Main category: cs.AI

TL;DR: 本文分析了直接偏好优化（DPO）的理论特性与内在局限，提出了一种双层优化框架——稳定偏好优化，以改进模型对齐的稳定性和偏好一致性。


<details>
  <summary>Details</summary>
Motivation: DPO虽在实践中表现优异，但其理论特性和潜在问题尚未充分研究。研究发现DPO对初始化敏感且易导致概率质量分配不当，可能强化模型偏见，影响对齐稳定性与偏好一致性。

Method: 提出基于双层优化的稳定偏好优化框架，结合监督微调与改进的DPO目标，通过正则化方案显式提升偏好输出的绝对概率，同时保持优化稳定性。

Result: 在推理和摘要任务上的实验表明，该方法显著提升推理准确性，并更好地使输出分布与预期偏好对齐，性能优于标准DPO。

Conclusion: 稳定偏好优化为偏好对齐目标的设计提供了新思路，为更可靠、可解释的语言模型对齐开辟了新途径。

Abstract: Direct Preference Optimization (DPO) has emerged as a popular and efficient
alternative to reward modeling and reinforcement learning for aligning language
models with human preferences. Despite its empirical success, the theoretical
properties and intrinsic limitations of DPO remain underexplored. In this work,
we first present a comprehensive analysis of DPO's dynamics from a probability
evolution perspective. Our analysis reveals that DPO is highly sensitive to
initialization. It also tends to misallocate probability mass, which can
inadvertently shift probability toward irrelevant or undesired responses. This
misallocation may unintentionally reinforce model bias, thereby compromising
both the stability of model alignment and the consistency with intended
preferences. Motivated by these theoretical findings, we propose a
theoretically grounded bilevel optimization framework that tightly integrate
supervised fine-tuning with an enhanced DPO objective a.k.a. stable preference
optimization. Our approach introduces a principled regularization scheme to
explicitly encourage absolute probability improvement for preferred outputs,
while maintaining stable optimization dynamics. Experiments on challenging
reasoning and summarization benchmarks elucidate that our method consistently
improves reasoning accuracy and better aligns output distributions with
intended preferences, outperforming standard DPO. Stable preference
optimization provides new insights into the design of preference-based
alignment objectives and opens up new avenues towards more reliable and
interpretable language model alignment.

</details>


### [74] [Identification of Violin Reduction via Contour Lines Classification](https://arxiv.org/abs/2507.07743)
*Philémon Beghin,Anne-Emmanuelle Ceulemans,François Glineur*

Main category: cs.AI

TL;DR: 本文提出了一种基于轮廓线分类小提琴是否经过尺寸缩减的方法，通过分析25把小提琴的3D几何网格数据，发现几何形状参数（尤其是开口参数β）能有效区分缩减与非缩减乐器。


<details>
  <summary>Details</summary>
Motivation: 16世纪晚期出现的小提琴在随后的200年里发展出高度多样化的家族。约1750年引入尺寸标准化后，未被标准涵盖的乐器常被缩减尺寸，导致轮廓线特征改变（U型变V型）。这种差异虽被专家观察但缺乏定量研究。

Method: 研究采集25把乐器通过摄影测量获得的3D网格数据，每把提取10-20条间距1毫米的轮廓线。用抛物线型方程$y=\alpha|x|^{\beta}$拟合曲线，计算α（垂直拉伸）和β（开口度）参数，通过回归分析和阈值处理构建每把乐器的数值特征谱。

Result: 分类实验表明：仅凭几何特征可在一定程度上预测尺寸缩减（准确率未明确说明），其中开口参数β最具预测性。但存在连续过渡的改造谱系，使得部分乐器的缩减程度难以量化。

Conclusion: 通过轮廓线几何分析可实现小提琴尺寸缩减的客观分类，证实了专家经验观察到的U/V型差异的数学基础。该方法为乐器鉴定提供了量化工具，但完全连续的特征谱要求未来研究引入更多判别维度。

Abstract: The first violins appeared in late 16th-century Italy. Over the next 200
years, they spread across Europe and luthiers of various royal courts, eager to
experiment with new techniques, created a highly diverse family of instruments.
Around 1750, size standards were introduced to unify violin making for
orchestras and conservatories. Instruments that fell between two standards were
then reduced to a smaller size by luthiers. These reductions have an impact on
several characteristics of violins, in particular on the contour lines, i.e.
lines of constant altitude, which look more like a U for non reduced
instruments and a V for reduced ones. While such differences are observed by
experts, they have not been studied quantitatively.
  This paper presents a method for classifying violins as reduced or
non-reduced based on their contour lines. We study a corpus of 25 instruments
whose 3D geometric meshes were acquired via photogrammetry. For each
instrument, we extract 10-20 contour lines regularly spaced every millimetre.
Each line is fitted with a parabola-like curve (with an equation of the type y
= alpha*abs(x)**beta) depending on two parameters, describing how open (beta)
and how vertically stretched (alpha) the curve is. We compute additional
features from those parameters, using regressions and counting how many values
fall under some threshold. We also deal with outliers and non equal numbers of
levels, and eventually obtain a numerical profile for each instrument.
  We then apply classification methods to assess whether geometry alone can
predict size reduction. We find that distinguishing between reduced and non
reduced instruments is feasible to some degree, taking into account that a
whole spectrum of more or less transformed violins exists, for which it is more
difficult to quantify the reduction. We also find the opening parameter beta to
be the most predictive.

</details>


### [75] [Measuring AI Alignment with Human Flourishing](https://arxiv.org/abs/2507.07787)
*Elizabeth Hilliard,Akshaya Jagadeesh,Alex Cook,Steele Billings,Nicholas Skytland,Alicia Llewellyn,Jackson Paull,Nathan Paull,Nolan Kurylo,Keatra Nesbitt,Robert Gruenewald,Anthony Jantzi,Omar Chavez*

Main category: cs.AI

TL;DR: 本文提出FAI Benchmark评估框架，从七大维度衡量AI对人类福祉的贡献，测试28个主流语言模型后发现无模型在所有维度均达标，尤其在信仰与灵性等维度表现薄弱。


<details>
  <summary>Details</summary>
Motivation: 传统AI评估仅关注技术能力或危害预防，缺乏对AI促进人类全面福祉的衡量。本研究旨在建立新框架，评估AI如何支持人类繁荣发展。

Method: 采用1229个主客观问题，通过专业评判LLM和跨维度评估，使用几何平均分确保各维度平衡。七大维度包括：品德与美德、亲密关系、幸福满意度等。

Result: 测试28个模型显示，最高分仅72/100。所有模型在信仰与灵性、品德与美德、意义与目标维度均未达标，揭示当前AI的局限性。

Conclusion: FAI Benchmark为开发真正支持人类繁荣的AI系统奠定基础，超越单纯危害规避，对AI伦理与发展具有重要指导意义。

Abstract: This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel
evaluation framework that assesses AI alignment with human flourishing across
seven dimensions: Character and Virtue, Close Social Relationships, Happiness
and Life Satisfaction, Meaning and Purpose, Mental and Physical Health,
Financial and Material Stability, and Faith and Spirituality. Unlike
traditional benchmarks that focus on technical capabilities or harm prevention,
the FAI Benchmark measures AI performance on how effectively models contribute
to the flourishing of a person across these dimensions. The benchmark evaluates
how effectively LLM AI systems align with current research models of holistic
human well-being through a comprehensive methodology that incorporates 1,229
objective and subjective questions. Using specialized judge Large Language
Models (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs
geometric mean scoring to ensure balanced performance across all flourishing
dimensions. Initial testing of 28 leading language models reveals that while
some models approach holistic alignment (with the highest-scoring models
achieving 72/100), none are acceptably aligned across all dimensions,
particularly in Faith and Spirituality, Character and Virtue, and Meaning and
Purpose. This research establishes a framework for developing AI systems that
actively support human flourishing rather than merely avoiding harm, offering
significant implications for AI development, ethics, and evaluation.

</details>


### [76] [MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving](https://arxiv.org/abs/2507.07818)
*Lu Xu,Jiaqian Yu,Xiongfeng Peng,Yiwei Chen,Weiming Li,Jaewook Yoo,Sunghyun Chunag,Dongwook Lee,Daehyun Ji,Chao Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种面向驾驶技能的混合专家模型MoSE，通过模仿人类驾驶员的学习和推理过程，实现了在自动驾驶任务中的高效性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的混合专家模型（MoE）需要大量训练数据和复杂优化，而人类驾驶员通过分技能、分步骤学习驾驶。受此启发，研究者希望开发一种更高效的技能导向模型。

Method: 提出MoSE模型：1) 定义并标注特定驾驶技能，实现技能导向路由；2) 构建分层技能数据集，预训练路由器以模拟人类逐步推理；3) 在单次前向过程中整合辅助任务（如描述、推理、规划）。

Result: 模型参数量小于30亿（稀疏激活），但在CODA AD极端案例推理任务上超越多个80亿+参数的模型。相比现有方法，激活模型体积减少至少62.5%，且达到最先进性能。

Conclusion: MoSE通过模拟人类分技能、分步骤的学习机制，在显著降低计算成本的同时，实现了自动驾驶推理任务的性能突破，为高效能语言模型在自动驾驶中的应用提供了新思路。

Abstract: Recent studies show large language models (LLMs) and vision language models
(VLMs) trained using web-scale data can empower end-to-end autonomous driving
systems for a better generalization and interpretation. Specifically, by
dynamically routing inputs to specialized subsets of parameters, the
Mixture-of-Experts (MoE) technique enables general LLMs or VLMs to achieve
substantial performance improvements while maintaining computational
efficiency. However, general MoE models usually demands extensive training data
and complex optimization. In this work, inspired by the learning process of
human drivers, we propose a skill-oriented MoE, called MoSE, which mimics human
drivers' learning process and reasoning process, skill-by-skill and
step-by-step. We propose a skill-oriented routing mechanism that begins with
defining and annotating specific skills, enabling experts to identify the
necessary driving competencies for various scenarios and reasoning tasks,
thereby facilitating skill-by-skill learning. Further align the driving process
to multi-step planning in human reasoning and end-to-end driving models, we
build a hierarchical skill dataset and pretrain the router to encourage the
model to think step-by-step. Unlike multi-round dialogs, MoSE integrates
valuable auxiliary tasks (e.g.\ description, reasoning, planning) in one single
forward process without introducing any extra computational cost. With less
than 3B sparsely activated parameters, our model outperforms several 8B+
parameters on CODA AD corner case reasoning task. Compared to existing methods
based on open-source models and data, our approach achieves state-of-the-art
performance with significantly reduced activated model size (at least by
$62.5\%$) with a single-turn conversation.

</details>


### [77] [AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift](https://arxiv.org/abs/2507.07820)
*Eunsu Baek,Keondo Park,Jeonggil Ko,Min-hwan Oh,Taesik Gong,Hyung-Sin Kim*

Main category: cs.AI

TL;DR: 当前AI发展依赖大规模模型和海量数据，但存在环境、经济和伦理成本问题。论文提出仿生自适应感知技术，通过动态调整传感器参数提升效率，使小模型性能超越大模型，并规划了技术整合路线图与研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有AI依赖算力和数据扩展的模式不可持续，且加剧资源不平等。受生物感官系统动态调节启发，提出自适应感知作为基础性变革方向，以降低协变量偏移并提高能效。

Method: 在输入层主动调制传感器参数（如曝光度、灵敏度、多模态配置），结合轻量级模型架构（如EfficientNet-B0），通过实时算法与多模态融合实现高效感知。

Result: 实证显示自适应感知使小模型性能超越计算资源消耗高的大模型（如OpenCLIP-H），在人形机器人、医疗、农业等领域展现出应用潜力。

Conclusion: 提出构建标准化基准、隐私保护方法等研究方向，推动AI向可持续、鲁棒且公平的系统转型，需解决技术整合与伦理挑战。

Abstract: Current AI advances largely rely on scaling neural models and expanding
training datasets to achieve generalization and robustness. Despite notable
successes, this paradigm incurs significant environmental, economic, and
ethical costs, limiting sustainability and equitable access. Inspired by
biological sensory systems, where adaptation occurs dynamically at the input
(e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive
sensing as a necessary and foundational shift. Adaptive sensing proactively
modulates sensor parameters (e.g., exposure, sensitivity, multimodal
configurations) at the input level, significantly mitigating covariate shifts
and improving efficiency. Empirical evidence from recent studies demonstrates
that adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass
substantially larger models (e.g., OpenCLIP-H) trained with significantly more
data and compute. We (i) outline a roadmap for broadly integrating adaptive
sensing into real-world applications spanning humanoid, healthcare, autonomous
systems, agriculture, and environmental monitoring, (ii) critically assess
technical and ethical integration challenges, and (iii) propose targeted
research directions, such as standardized benchmarks, real-time adaptive
algorithms, multimodal integration, and privacy-preserving methods.
Collectively, these efforts aim to transition the AI community toward
sustainable, robust, and equitable artificial intelligence systems.

</details>


### [78] [Searching for actual causes: Approximate algorithms with adjustable precision](https://arxiv.org/abs/2507.07857)
*Samuel Reyd,Ada Diaconescu,Jean-Louis Dessalles*

Main category: cs.AI

TL;DR: 本文提出了一种多项式复杂度的算法，用于识别实际原因，适用于非布尔、黑盒和随机系统，并通过实验验证了其有效性和可调性。


<details>
  <summary>Details</summary>
Motivation: 当前可解释人工智能（XAI）和因果关系的文献主要关注理解哪些因素导致哪些结果，但这并非非专家用户期望的解释。用户更关注导致目标结果的实际原因，而这一概念的形式化仍是一个开放问题。

Method: 作者提出了一组算法，以多项式复杂度识别实际原因，并允许通过调整计算时间来获得更高的精确性和详尽性。

Result: 实验表明，这些算法能够识别现有方法无法处理的系统（如非布尔、黑盒和随机系统）的原因，并且可以通过增加计算时间来提高精确性和详尽性。

Conclusion: 该研究为解决实际原因识别这一NP完全问题提供了实用的多项式复杂度解决方案，适用于多种系统类型，并具有可调性。

Abstract: Causality has gained popularity in recent years. It has helped improve the
performance, reliability, and interpretability of machine learning models.
However, recent literature on explainable artificial intelligence (XAI) has
faced criticism. The classical XAI and causality literature focuses on
understanding which factors contribute to which consequences. While such
knowledge is valuable for researchers and engineers, it is not what non-expert
users expect as explanations. Instead, these users often await facts that cause
the target consequences, i.e., actual causes. Formalizing this notion is still
an open problem. Additionally, identifying actual causes is reportedly an
NP-complete problem, and there are too few practical solutions to approximate
formal definitions. We propose a set of algorithms to identify actual causes
with a polynomial complexity and an adjustable level of precision and
exhaustiveness. Our experiments indicate that the algorithms (1) identify
causes for different categories of systems that are not handled by existing
approaches (i.e., non-boolean, black-box, and stochastic systems), (2) can be
adjusted to gain more precision and exhaustiveness with more computation time.

</details>


### [79] [An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis](https://arxiv.org/abs/2507.07893)
*Mingda Zhang,Na Zhao,Jianglong Qing,Qing xu,Kaiwen Pan,Ting luo*

Main category: cs.AI

TL;DR: 本文提出了一种结合提示工程与多维知识图谱的增强框架，以解决大语言模型在法律纠纷分析中的局限性，显著提升了法律决策分析的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为智能法律系统的核心组件，在法律纠纷分析中存在法律知识表示不足、概念理解有限和推理缺陷等问题，亟需改进。

Method: 研究提出三阶段分层提示结构（任务定义、知识背景、推理引导）与三层知识图谱架构（分类本体、表示层、实例层），结合四种法律概念检索方法及网络搜索技术。

Result: 实验表明该框架显著提升法律纠纷分析性能，能精准处理复杂案件的法律适用分析，并深入理解司法决策逻辑。

Conclusion: 该研究为智能法律辅助系统提供了创新技术路径，通过知识增强框架实现了法律决策能力的突破性进展。

Abstract: The rapid development of artificial intelligence has positioned large
language models as fundamental components of intelligent legal systems.
However, these models face significant limitations in legal dispute analysis,
including insufficient legal knowledge representation, limited concept
understanding, and reasoning deficiencies. This research proposes an enhanced
framework integrating prompt engineering with multidimensional knowledge
graphs. The framework introduces a three-stage hierarchical prompt structure
comprising task definition, knowledge background, and reasoning guidance,
supplemented by legal-specific reasoning templates and dynamic optimization
mechanisms. A three-layer knowledge graph architecture is constructed with
legal classification ontology, representation, and instance layers. Four
complementary methods enable precise legal concept retrieval: direct legal norm
code matching, domain-specific semantic vector similarity, ontology-based path
reasoning, and specialized lexical segmentation. These components integrate
with web search technology to establish a knowledge-enhanced framework for
legal decision-making. Experimental results demonstrate significant performance
improvements in legal dispute analysis, enabling accurate legal application
analysis for complex cases while exhibiting nuanced understanding of judicial
decision-making logic, providing a novel technical approach for implementing
intelligent legal assistance systems.

</details>


### [80] [Meek Models Shall Inherit the Earth](https://arxiv.org/abs/2507.07931)
*Hans Gundlach,Jayson Lynch,Neil Thompson*

Main category: cs.AI

TL;DR: 本文认为，随着计算规模扩大的边际效益递减，有限计算预算的"弱小模型"将逐渐接近顶级模型的性能水平，导致AI能力趋同。


<details>
  <summary>Details</summary>
Motivation: 针对少数公司主导AI系统规模扩张导致的能力不平等现象，研究计算规模效益递减对模型能力趋同的影响。

Method: 建立理论模型分析固定分布下"下一词预测"目标的边际效益；通过基准数据验证训练损失差异的代理有效性；实证分析AI模型能力差异随时间变化。

Result: 研究表明：1) 计算规模扩大的能力边际效益显著降低 2) 即使计算资源指数级增长，最终能力优势也将微乎其微 3) 弱小模型性能将逼近顶级模型。

Conclusion: 弱小模型的崛起要求重新审视AI战略与政策，论文最后阐述了这一转变将影响的具体领域。

Abstract: The past decade has seen incredible scaling of AI systems by a few companies,
leading to inequality in AI model performance. This paper argues that, contrary
to prevailing intuition, the diminishing returns to compute scaling will lead
to a convergence of AI model capabilities. In other words, meek models (those
with limited computation budget) shall inherit the earth, approaching the
performance level of the best models overall. We develop a model illustrating
that under a fixed-distribution next-token objective, the marginal capability
returns to raw compute shrink substantially. Given current scaling practices,
we argue that these diminishing returns are strong enough that even companies
that can scale their models exponentially faster than other organizations will
eventually have little advantage in capabilities. As part of our argument, we
give several reasons that proxies like training loss differences capture
important capability measures using evidence from benchmark data and
theoretical performance models. In addition, we analyze empirical data on the
capability difference of AI models over time. Finally, in light of the
increasing ability of meek models, we argue that AI strategy and policy require
reexamination, and we outline the areas this shift will affect.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [81] [The Richness of CSP Non-redundancy](https://arxiv.org/abs/2507.07942)
*Joshua Brakensiek,Venkatesan Guruswami,Bart M. P. Jansen,Victor Lagerkvist,Magnus Wahlström*

Main category: cs.DM

TL;DR: 本文研究了约束满足问题（CSP）中的非冗余性（NRD）问题，揭示了其与计算机科学和数学中多个重要问题的联系。通过建立非冗余性的代数理论，首次展示了具有Mal'tsev嵌入但不依赖于阿贝尔群结构的谓词实例。


<details>
  <summary>Details</summary>
Motivation: 非冗余性（NRD）是约束满足问题（CSP）中的核心概念，与稀疏化、核化、查询复杂性、通用代数和极值组合学等多个领域密切相关。本文旨在深入理解非冗余性，并探索其在理论和应用中的广泛影响。

Method: 首先证明了对于每个有理数$r \ge 1$，存在有限CSP谓词$P$，其非冗余性为$\Theta(n^r)$。其次，通过极值组合学中高围长图的结构，完全分类了所有二元谓词的条件非冗余性。最后，基于Carbonnel的工作，建立了条件非冗余性的代数理论。

Result: 主要成果包括：（1）证明了非冗余性可以覆盖多项式增长的广泛范围；（2）完全分类了二元谓词的条件非冗余性；（3）首次展示了基于量子Pauli群结构的Mal'tsev嵌入实例，突破了传统阿贝尔群框架。

Conclusion: 非冗余性作为连接多个领域的关键枢纽，其深入研究不仅推动了CSP理论的边界，还为量子计算等新兴领域提供了新的理论工具。代数理论的建立为未来探索更高维或无限域上的非冗余性奠定了基础。

Abstract: In the field of constraint satisfaction problems (CSP), a clause is called
redundant if its satisfaction is implied by satisfying all other clauses. An
instance of CSP$(P)$ is called non-redundant if it does not contain any
redundant clause. The non-redundancy (NRD) of a predicate $P$ is the maximum
number of clauses in a non-redundant instance of CSP$(P)$, as a function of the
number of variables $n$. Recent progress has shown that non-redundancy is
crucially linked to many other important questions in computer science and
mathematics including sparsification, kernelization, query complexity,
universal algebra, and extremal combinatorics. Given that non-redundancy is a
nexus for many of these important problems, the central goal of this paper is
to more deeply understand non-redundancy.
  Our first main result shows that for every rational number $r \ge 1$, there
exists a finite CSP predicate $P$ such that the non-redundancy of $P$ is
$\Theta(n^r)$. Our second main result explores the concept of conditional
non-redundancy first coined by Brakensiek and Guruswami [STOC 2025]. We
completely classify the conditional non-redundancy of all binary predicates
(i.e., constraints on two variables) by connecting these non-redundancy
problems to the structure of high-girth graphs in extremal combinatorics.
  Inspired by these concrete results, we build off the work of Carbonnel [CP
2022] to develop an algebraic theory of conditional non-redundancy. As an
application of this algebraic theory, we revisit the notion of Mal'tsev
embeddings, which is the most general technique known to date for establishing
that a predicate has linear non-redundancy. For example, we provide the first
example of predicate with a Mal'tsev embedding that cannot be attributed to the
structure of an Abelian group, but rather to the structure of the quantum Pauli
group.

</details>
