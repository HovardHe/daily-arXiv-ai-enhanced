<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 3]
- [math.OC](#math.OC) [Total: 9]
- [math.NT](#math.NT) [Total: 9]
- [math.LO](#math.LO) [Total: 1]
- [math.GM](#math.GM) [Total: 1]
- [math.CO](#math.CO) [Total: 17]
- [q-fin.MF](#q-fin.MF) [Total: 1]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [cs.CR](#cs.CR) [Total: 4]
- [cs.AI](#cs.AI) [Total: 23]
- [stat.TH](#stat.TH) [Total: 1]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Learning Smooth Populations of Parameters with Trial Heterogeneity](https://arxiv.org/abs/2507.23140)
*JungHo Lee,Valerio Baćak,Edward H. Kennedy*

Main category: math.ST

TL;DR: 本文研究了在试验异质性和平滑性条件下二项混合分布的混合分布估计问题，提出了基于核密度估计器的快速误差率，并在刑事司法应用中比较了不同辩护类型的定罪率。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于刑事司法领域的实际需求，特别是比较宾夕法尼亚州贫困辩护中指定律师（法院指定的私人律师）和公设辩护人的定罪率差异，并探讨可能的混杂因素。

Method: 在假设密度为s-平滑的条件下，我们推导了在试验异质性下核密度估计器的快速误差率，该速率依赖于试验的调和平均数。同时研究了在i.i.d.和二项混合设置下两个密度之间差异的非参数估计。

Result: 结果表明，即使在同质情况下，我们的结果也优于Ye和Bickel（2021）的最新速率。在刑事司法应用中，发现指定律师的估计定罪率通常高于公设辩护人，可能是由于指定律师更可能接手严重案件这一混杂因素。

Conclusion: 本研究不仅提高了二项混合分布估计的理论性能，还为刑事司法系统中的辩护效果差异提供了实证依据，强调了考虑案件严重性等混杂因素的重要性。

Abstract: We consider the classical problem of estimating the mixing distribution of
binomial mixtures, but under trial heterogeneity and smoothness. This problem
has been studied extensively when the trial parameter is homogeneous, but not
under the more general scenario of heterogeneous trials, and only within a low
smoothness regime, where the resulting rates are slow. Under the assumption
that the density is s-smooth, we derive fast error rates for the kernel density
estimator under trial heterogeneity that depend on the harmonic mean of the
trials. Importantly, even when reduced to the homogeneous case, our result
improves on the state-of-the-art rate of Ye and Bickel (2021). We also study
nonparametric estimation of the difference between two densities, which can be
smoother than the individual densities, in both i.i.d. and binomial-mixture
settings. Our work is motivated by an application in criminal justice:
comparing conviction rates of indigent representation in Pennsylvania. We find
that the estimated conviction rates for appointed counsel (court-appointed
private attorneys) are generally higher than those for public defenders,
potentially due to a confounding factor: appointed counsel are more likely to
take on severe cases.

</details>


### [2] [CLT in high-dimensional Bayesian linear regression with low SNR](https://arxiv.org/abs/2507.23285)
*Seunghyun Lee,Nabarun Deb,Sumit Mukherjee*

Main category: math.ST

TL;DR: 本文研究了高维贝叶斯线性回归中线性统计量的中心极限定理，重点探讨了非收缩机制下的后验分布一维投影及后验均值的极限分布。结果表明极限分布为高斯分布，且围绕后验的平均场近似。通过白噪声设计和错误指定贝叶斯模型两个具体案例进行了验证，并构建了可信区间。


<details>
  <summary>Details</summary>
Motivation: 现代高维数据集通常具有有限的信噪比，传统文献关注后验收缩，而本研究在非收缩机制下探索后验分布的极限行为，填补了这一研究空白。

Method: 结合随机场伊辛模型的Berry-Esseen型界限和一阶、二阶Poincar\'{e}不等式，无需对先验施加稀疏性假设。

Result: 极限分布为高斯分布，且依赖于所选先验，中心位于后验的平均场近似。通过白噪声设计和错误指定贝叶斯模型验证了这一现象。

Conclusion: 在非收缩机制下，高维贝叶斯线性回归的线性统计量呈现高斯极限分布，且与先验选择密切相关。研究成果为构建可信区间提供了理论基础。

Abstract: We study central limit theorems for linear statistics in high-dimensional
Bayesian linear regression with product priors. Unlike the existing literature
where the focus is on posterior contraction, we work under a non-contracting
regime where neither the likelihood nor the prior dominates the other. This is
motivated by modern high-dimensional datasets characterized by a bounded
signal-to-noise ratio. This work takes a first step towards understanding limit
distributions for one-dimensional projections of the posterior, as well as the
posterior mean, in such regimes. Analogous to contractive settings, the
resulting limiting distributions are Gaussian, but they heavily depend on the
chosen prior and center around the Mean-Field approximation of the posterior.
We study two concrete models of interest to illustrate this phenomenon -- the
white noise design, and the (misspecified) Bayesian model. As an application,
we construct credible intervals and compute their coverage probability under
any misspecified prior. Our proofs rely on a combination of recent developments
in Berry-Esseen type bounds for Random Field Ising models and both first and
second order Poincar\'{e} inequalities. Notably, our results do not require any
sparsity assumptions on the prior.

</details>


### [3] [Optimal-Transport Based Multivariate Goodness-of-Fit Tests](https://arxiv.org/abs/2507.23490)
*Zdeněk Hlávka,Šárka Hudecová,Simos G. Meintanis*

Main category: math.ST

TL;DR: 本文提出基于特征函数的多元观测拟合优度检验，通过最优传输理论构建多元秩，实现简单原假设的分布无关性检验。


<details>
  <summary>Details</summary>
Motivation: 现有多元正态性检验方法在有限样本中表现不佳，需开发计算简便且性能优越的新检验方法。

Method: 采用两样本准则衡量原始观测与参考分布生成样本的多元秩差异，利用最优传输理论构造秩统计量，对复合假设使用bootstrap近似。

Result: 仿真研究表明，该方法在有限样本中表现优于现有多元正态性检验，且具有渐进理论支持。

Conclusion: 基于特征函数和最优传输的检验方法为多元分布拟合优度检验提供了高效且分布无关的新工具。

Abstract: Characteristic-function based goodness-of-fit tests are suggested for
multivariate observations. The test statistics, which are straightforward to
compute, are defined as two-sample criteria measuring discrepancy between
multivariate ranks of the original observations and the corresponding ranks
obtained from an artificial sample generated from the reference distribution
under test. Multivariate ranks are constructed using the theory of the optimal
measure transport, thus rendering the tests of a simple null hypothesis
distribution-free, while bootstrap approximations are still necessary for
testing composite null hypotheses. Asymptotic theory is developed and a
simulation study, concentrating on comparisons with previously proposed tests
of multivariate normality, demonstrates that the method performs well in finite
samples.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [4] [Adaptive direct search algorithms for constrained optimization](https://arxiv.org/abs/2507.23054)
*Charles Audet,Théo Denorme,Youssef Diouane,Sébastien Le Digabel,Christophe Tribes*

Main category: math.OC

TL;DR: 本文提出了一种新的自适应直接搜索方法（ADS），结合了MADS和SDDS的优点，避免了网格限制和充分下降条件，在理论和计算上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有无导数和黑箱优化方法（MADS和SDDS）各有局限：MADS受限于网格点，SDDS可能丢弃改进点。需要一种更灵活且高效的新方法。

Method: ADS采用基于“穿孔空间”的新接受规则，无需网格或充分下降条件，保留了方向性直接搜索的理论基础。

Result: 计算实验表明，ADS在约束和无约束问题中均优于MADS和SDDS，展现了更高的灵活性和性能。

Conclusion: ADS成功融合了MADS和SDDS的优势，为无导数优化提供了更高效的解决方案，具有理论和实际应用价值。

Abstract: Two families of directional direct search methods have emerged in
derivative-free and blackbox optimization (DFO and BBO), each based on distinct
principles: Mesh Adaptive Direct Search (MADS) and Sufficient Decrease Direct
Search (SDDS). MADS restricts trial points to a mesh and accepts any
improvement, ensuring none are missed, but at the cost of restraining the
placement of trial points. SDDS allows greater freedom by evaluating points
anywhere in the space, but accepts only those yielding a sufficient decrease in
the objective function value, which may lead to discarding improving points.
  This work introduces a new class of methods, Adaptive Direct Search (ADS),
which uses a novel acceptance rule based on the so-called punctured space,
avoiding both meshes and sufficient decrease conditions. ADS enables flexible
search while addressing the limitations of MADS and SDDS, and retains the
theoretical foundations of directional direct search. Computational results in
constrained and unconstrained settings highlight its performance compared to
both MADS and SDDS.

</details>


### [5] [Stability-Constrained AC Optimal Power Flow -- A Gaussian Process-Based Approach](https://arxiv.org/abs/2507.23094)
*Vincenzo Di Vito,Kaarthik Sundar,Ferdinando Fioretto,Deepjyoti Deka*

Main category: math.OC

TL;DR: 本文提出了一种数据驱动的方法，将发电机动态特性纳入交流最优潮流（ACOPF）问题中，通过高斯过程（GP）模型学习发电机稳定性，确保运行点既经济又稳定。


<details>
  <summary>Details</summary>
Motivation: 传统ACOPF依赖稳态模型，忽略发电机动态行为，可能导致经济最优但动态不稳定的运行点。本文旨在解决这一问题。

Method: 使用高斯过程回归学习同步发电机动态微分方程解的稳定性指数，并通过指数代理函数表征稳定性，将概率稳定性评估直接集成到优化过程中。

Result: 在IEEE 39、57和118节点系统上的数值实验表明，该方法能高效捕获发电机动态特性，使用有限训练数据即可实现可靠且鲁棒的决策。

Conclusion: 所提出的动态感知ACOPF框架能同时满足运行安全和动态稳定性标准，为电力系统运行提供了更可靠的解决方案。

Abstract: The Alternating Current Optimal Power Flow (ACOPF) problem is a core task in
power system operations, aimed at determining cost-effective generation
dispatch while satisfying physical and operational constraints. However,
conventional ACOPF formulations rely on steady-state models and neglect the
dynamic behavior of generators, which can lead to operating points that are
economically optimal but dynamically unstable. This paper proposes a novel,
data-driven approach to incorporate generator dynamics into the ACOPF using
Gaussian Process (GP) models. Specifically, it introduces an exponential
surrogate function to characterize the stability of solutions to the
differential equations governing synchronous generator dynamics. The exponent,
which indicates whether system trajectories decay (stable) or grow (unstable),
is learned as a function of the bus voltage using GP regression. Crucially, the
framework enables probabilistic stability assessment to be integrated directly
into the optimization process. The resulting dynamics-aware ACOPF formulation
identifies operating points that satisfy both operational safety and dynamic
stability criteria. Numerical experiments on the IEEE 39-bus, 57-bus, and
118-bus systems demonstrate that the proposed method efficiently captures
generator dynamics using limited training data, leading to more reliable and
robust decisions across a wide range of operating conditions.

</details>


### [6] [On the Complexity of Finding Stationary Points in Nonconvex Simple Bilevel Optimization](https://arxiv.org/abs/2507.23155)
*Jincheng Cao,Ruichen Jiang,Erfan Yazdandoost Hamedani,Aryan Mokhtari*

Main category: math.OC

TL;DR: 本文研究非凸双层优化问题，提出一种新的平稳性概念，并设计了一种动态屏障梯度下降算法，首次在多项式时间内实现双层联合平稳性。


<details>
  <summary>Details</summary>
Motivation: 在缺乏凸性或PL条件等结构假设时，传统方法难以保证双层优化问题的全局最优性。因此需要定义新的平稳性概念并设计高效算法。

Method: 采用动态屏障梯度下降(DBGD)框架的改进版本，通过控制上下层目标的平衡参数$p\geq0$，实现$\epsilon_f$和$\epsilon_g$精度的联合平稳点搜索。

Result: 算法达到$(\epsilon_f, \epsilon_g)$-平稳点的复杂度为$\mathcal{O}\left(\max\left(\epsilon_f^{-\frac{3+p}{1+p}}, \epsilon_g^{-\frac{3+p}{2}}\right)\right)$，这是首个非凸双层问题的离散时间算法复杂度保证。

Conclusion: 该工作首次为一般非凸双层问题提供了具有理论保证的求解框架，动态屏障方法能有效平衡上下层目标的优化需求。

Abstract: In this paper, we study the problem of solving a simple bilevel optimization
problem, where the upper-level objective is minimized over the solution set of
the lower-level problem. We focus on the general setting in which both the
upper- and lower-level objectives are smooth but potentially nonconvex. Due to
the absence of additional structural assumptions for the lower-level
objective-such as convexity or the Polyak-{\L}ojasiewicz (PL)
condition-guaranteeing global optimality is generally intractable. Instead, we
introduce a suitable notion of stationarity for this class of problems and aim
to design a first-order algorithm that finds such stationary points in
polynomial time. Intuitively, stationarity in this setting means the
upper-level objective cannot be substantially improved locally without causing
a larger deterioration in the lower-level objective. To this end, we show that
a simple and implementable variant of the dynamic barrier gradient descent
(DBGD) framework can effectively solve the considered nonconvex simple bilevel
problems up to stationarity. Specifically, to reach an $(\epsilon_f,
\epsilon_g)$-stationary point-where $\epsilon_f$ and $\epsilon_g$ denote the
target stationarity accuracies for the upper- and lower-level objectives,
respectively-the considered method achieves a complexity of
$\mathcal{O}\left(\max\left(\epsilon_f^{-\frac{3+p}{1+p}},
\epsilon_g^{-\frac{3+p}{2}}\right)\right)$, where $p \geq 0$ is an arbitrary
constant balancing the terms. To the best of our knowledge, this is the first
complexity result for a discrete-time algorithm that guarantees joint
stationarity for both levels in general nonconvex simple bilevel problems.

</details>


### [7] [FMIP: Multimodal Flow Matching for Mixed Integer Linear Programming](https://arxiv.org/abs/2507.23390)
*Hongpei Li,Hui Yuan,Han Zhang,Dongdong Ge,Mengdi Wang,Yinyu Ye*

Main category: math.OC

TL;DR: 本文提出FMIP框架，通过多模态流匹配建模混合整数规划中整数与连续变量的联合分布，结合引导机制提升求解质量，实验显示其性能超越现有基于GNN的基准方法50.04%。


<details>
  <summary>Details</summary>
Motivation: 现有基于图神经网络的启发式方法仅预测整数变量解，难以捕捉混合变量间复杂交互且表征能力不足，亟需新方法解决混合整数规划的NP难问题。

Method: FMIP框架创新性地采用多模态流匹配技术，在混合解空间中联合建模变量分布，并引入目标函数优化和约束满足的双重引导机制指导采样。

Result: 在7个标准MILP基准测试中，FMIP将求解质量平均提升50.04%，显著优于现有基于GNN的预测方法。

Conclusion: FMIP通过流匹配和联合分布建模展现了作为学习型MILP求解策略的潜力，为复杂决策问题提供了新范式。

Abstract: Mixed-Integer Linear Programming (MILP) is a cornerstone of mathematical
optimization, enabling the modeling of complex decision-making problems
involving both integer and continuous variables. Despite its versatility, most
MILP problems are NP-complete, making them challenging to solve in practice.
Existing graph neural network (GNN)-based heuristics aim to reduce problem
scale by predicting only the solutions on integer variables for a given
instance, struggling to capture the intricate interplay between continuous and
integer variables and lack sufficient representational power. To address these
limitations, we propose FMIP, a novel multimodal flow-matching framework that
models the joint distribution over integer and continuous variables in the
mixed solution space of MILP. To enable more accurate and scalable heuristics,
FMIP integrates a guidance mechanism to guide solution sampling under both
objective function optimization and constraint satisfaction. We evaluate FMIP
on seven standard MILP benchmarks. Our experiments show that FMIP improves
solution quality by 50.04% on average over existing GNN-based predictive
baselines. These results highlight FMIP's potential as a powerful new approach
for developing learning based MILP solution strategy.

</details>


### [8] [Popov Mirror-Prox Method for Variational Inequalities](https://arxiv.org/abs/2507.23395)
*Abhishek Chakraborty,Angelia Nedić*

Main category: math.OC

TL;DR: 本文提出了Popov镜像近端算法在多项式增长条件下的收敛性，针对随机和确定性变分不等式（VIs）提出了无需问题参数先验知识的步长方案，并验证了其在矩阵博弈、分段二次函数及ResNet-18图像分类任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要问题特定参数的先验知识，限制了算法的通用性。本文旨在开发无需参数先验的步长方案，扩展镜像近端技术至具有任意多项式增长的映射，填补文献空白。

Method: 提出参数自由的恒定和递减步长方案，针对单调VI在约束集上建立对偶间隙函数的最优收敛速率，对H\"older连续映射的确定性VI证明残差函数的收敛性，无需有界集或单调性假设。

Result: 在随机和确定性单调VI中实现最优收敛速率，对非单调VI的特定类也有效，但需已知H\"older指数以获得最佳速率。实验验证了理论结果。

Conclusion: 通过扩展镜像近端技术至多项式增长映射，本文为随机和确定性VI提供了参数自由的解决方案，并在理论和实证上验证了其有效性，尤其适用于非单调VI的特定场景。

Abstract: This paper establishes the convergence properties of the Popov mirror-prox
algorithm for solving stochastic and deterministic variational inequalities
(VIs) under a polynomial growth condition on the mapping variation. Unlike
existing methods that require prior knowledge of problem-specific parameters,
we propose step-size schemes that are entirely parameter-free in both constant
and diminishing forms. For stochastic and deterministic monotone VIs, we
establish optimal convergence rates in terms of the dual gap function over a
bounded constraint set. Additionally, for deterministic VIs with H\"older
continuous mapping, we prove convergence in terms of the residual function
without requiring a bounded set or a monotone mapping, provided a Minty
solution exists. This allows our method to address certain classes of
non-monotone VIs. However, knowledge of the H\"older exponent is necessary to
achieve the best convergence rates in this case. By extending mirror-prox
techniques to mappings with arbitrary polynomial growth, our work bridges an
existing gap in the literature. We validate our theoretical findings with
empirical results on matrix games, piecewise quadratic functions, and image
classification tasks using ResNet-18.

</details>


### [9] [Biobjective optimization with M-convex functions](https://arxiv.org/abs/2507.23423)
*Ellen H. Fukuda,Satoru Iwata,Itsuki Nakagawa*

Main category: math.OC

TL;DR: 本文首次将多目标优化与离散凸分析结合，针对双目标优化问题提出了多项式时间算法，特别适用于包含M$^\natural$-凸函数和二元系数线性函数的场景，并在M-凸函数特例中实现了更高效率。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索多目标优化与离散凸分析这一未充分结合的领域，旨在解决双目标优化问题中Pareto最优值集的高效计算问题。

Method: 方法包括：1) 对含M$^\natural$-凸函数和二元线性函数的双目标问题设计多项式时间算法；2) 在M-凸函数特例中优化算法效率；3) 结合M$^\natural$-凸函数最小化与字典序优化的多项式时间方法。

Result: 结果表明：1) 特定双目标问题的Pareto最优值集可在多项式时间内求解；2) M-凸函数特例的算法效率更高；3) 字典序优化组合问题同样具备多项式时间解法。

Conclusion: 结论指出，离散凸分析与多目标优化的结合为高效求解双目标问题提供了新途径，尤其适用于M$^\natural$-凸函数相关场景，且算法复杂度可控。

Abstract: In this paper, we deal with two ingredients that, as far as we know, have not
been combined until now: multiobjective optimization and discrete convex
analysis. First, we show that the entire Pareto optimal value set can be
obtained in polynomial time for biobjective optimization problems with discrete
convex functions, in particular, involving an M$^\natural$-convex function and
a linear function with binary coefficients. We also observe that a more
efficient algorithm can be obtained in the special case where the
M$^\natural$-convex function is M-convex. Additionally, we present a
polynomial-time method for biobjective optimization problems that combine
M$^\natural$-convex function minimization with lexicographic optimization.

</details>


### [10] [Convergence rates of Newton's method for strongly self-concordant minimization](https://arxiv.org/abs/2507.23558)
*Nick Tsipinakis,Panos Parpas*

Main category: math.OC

TL;DR: 本文研究了牛顿法在强自协调函数（自协调函数的一个子类）上的局部收敛性，证明了其二次收敛速率优于一般自协调函数，并具有更大的局部收敛区域。


<details>
  <summary>Details</summary>
Motivation: 尽管牛顿法在自协调函数上的性质已被充分研究，但针对强自协调函数这一子类的局部分析尚未在文献中探讨，本文旨在填补这一理论空白。

Method: 通过理论分析，比较了牛顿法在强自协调函数与一般自协调函数上的局部收敛行为。

Result: 研究发现，强自协调函数的牛顿法不仅具有更快的二次收敛速率，而且局部收敛区域更大，这一性质在广泛的优化目标函数中均成立。

Conclusion: 本文成果完善了牛顿法应用于强自协调函数的理论体系，揭示了其优于一般自协调函数的收敛特性。

Abstract: Newton's method has been thoroughly studied for the class of self-concordant
functions. However, a local analysis specific to strongly self-concordant
functions (a subclass of the former) is missing from the literature. The local
quadratic rate of strongly self-concordant functions follows, of course, from
the known results for self-concordant functions. However, it is not known
whether strongly self-concordant functions enjoy better theoretical properties.
In this paper, we study the local convergence of Newton's method for this
subclass. We show that its quadratic convergence rate differs from that of
general self-concordant functions. In particular, it is provably faster for a
wide range of objective functions and benefits from a larger region of local
convergence. Thus, the results of this paper close the gap in the theoretical
understanding of Newton's method applied to strongly self-concordant functions.

</details>


### [11] [Combinatorial Approaches for Embedded Feature Selection in Nonlinear SVMs](https://arxiv.org/abs/2507.23711)
*Federico D'Onofrio,Yuri Faenza,Laura Palagi*

Main category: math.OC

TL;DR: 本文提出了一种基于硬基数约束的非线性SVM双对偶嵌入特征选择方法，通过混合整数非线性规划（MINLP）模型和交替优化框架，显著提升了特征选择效果。


<details>
  <summary>Details</summary>
Motivation: 现有硬约束方法仅适用于线性SVM的原始形式，无法处理非线性核。本研究旨在将硬基数约束直接嵌入非线性SVM的对偶问题，实现特征数量的严格控制并保持核方法优势。

Method: 1) 提出适用于通用非线性核的局部搜索元启发式算法；2) 设计分解框架交替优化连续变量和二元变量子问题，对于多项式核证明二元子问题可转化为基数约束下的子模函数最大化问题。

Result: 数值实验表明，所提算法显著优于标准MINLP求解方法，在特征选择问题上提供了更有效的解决方案。

Conclusion: 该研究首次实现了对偶非线性SVM的硬基数约束特征选择，通过子模优化框架提升了计算效率，为可解释机器学习提供了新工具。

Abstract: Embedded Feature Selection (FS) is a classical approach for interpretable
machine learning, aiming to identify the most relevant features of a dataset
while simultaneously training the model. We consider an approach based on a
hard cardinality constraint for nonlinear SVMs. To the best of our knowledge,
hard-constraint approaches have been proposed only for the primal formulation
of linear SVMs. In contrast, we embed a hard cardinality constraint directly
into the dual of a nonlinear SVM, guaranteeing strict control over the number
of selected features while still leveraging kernelization. We formulate the
problem as a Mixed-Integer Nonlinear Programming (MINLP) model. As a first
contribution, we propose a local search metaheuristic applicable to general
nonlinear kernels. Our second and main contribution is a decomposition
framework that alternates optimization between two subproblems: one involving
only continuous variables and the other involving only binary variables. For
polynomial kernels, we show that the binary subproblem reduces to a submodular
function maximization under a cardinality constraint, enabling the use of
scalable submodular maximization algorithms within the alternating optimization
process. Numerical experiments demonstrate that our algorithms significantly
outperform standard methods for solving the proposed MINLPs, providing more
effective solutions to the addressed feature selection problem.

</details>


### [12] [Adaptive Stepsize Selection in Decentralized Convex Optimization](https://arxiv.org/abs/2507.23725)
*Ilya Kuruzov,Xiaokai Chen,Gesualdo Scutari,Alexander Gasnikov*

Main category: math.OC

TL;DR: 本文提出了一种完全自适应的去中心化优化算法，无需全局信息即可自动调整步长，适用于强凸和平滑损失函数，并在两种情况下分别实现线性和次线性收敛速率。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化方法的收敛性依赖于预先设定的步长，这需要全局信息且难以调整，导致实际应用中收敛速度缓慢。本文旨在解决这一局限性。

Method: 算法通过仅使用邻居间通信实现完全自适应的步长选择，无需任何全局信息（如图形连通性或局部平滑性常数），且不要求代理知道问题是否强凸。

Result: 算法在强凸损失下以线性速率收敛，在非强凸情况下以次线性速率收敛，与非自适应方法的最佳已知速率相匹配。

Conclusion: 该研究提供了一种高效且实用的去中心化优化方法，克服了传统方法对步长调参的依赖，同时保持了理论上的最优收敛性能。

Abstract: We study decentralized optimization where multiple agents minimize the
average of their (strongly) convex, smooth losses over a communication graph.
Convergence of the existing decentralized methods generally hinges on an
apriori, proper selection of the stepsize. Choosing this value is notoriously
delicate: (i) it demands global knowledge from all the agents of the graph's
connectivity and every local smoothness/strong-convexity constants--information
they rarely have; (ii) even with perfect information, the worst-case tuning
forces an overly small stepsize, slowing convergence in practice; and (iii)
large-scale trial-and-error tuning is prohibitive. This work introduces a
decentralized algorithm that is fully adaptive in the choice of the agents'
stepsizes, without any global information and using only neighbor-to-neighbor
communications--agents need not even know whether the problem is strongly
convex. The algorithm retains strong guarantees: it converges at \emph{linear}
rate when the losses are strongly convex and at \emph{sublinear} rate
otherwise, matching the best-known rates of (nonadaptive) parameter-dependent
methods.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [13] [On the densities of covering numbers and abundant numbers](https://arxiv.org/abs/2507.23041)
*Nathan McNew,Jai Setty*

Main category: math.NT

TL;DR: 研究了覆盖数集$\mathcal{C}$和丰数集$\mathcal{A}$的密度，证明了$\mathcal{C}$存在自然密度$d(\mathcal{C})$并给出精确范围，同时改进了$d(\mathcal{A})$的边界。方法上引入了测量函数$c(n)$，并推导了原始覆盖数的计数上界。


<details>
  <summary>Details</summary>
Motivation: 探究覆盖数集和丰数集的密度性质，解决覆盖数密度计算精度不足的问题，并改进丰数密度的现有边界。

Method: 借鉴Behrend和Del\'eglise的丰数密度估计方法，引入函数$c(n)\leq h(n)=\sigma(n)/n$衡量整数接近覆盖数的程度，通过新思路简化计算以实现三位小数精度。

Result: 覆盖数密度确认为$0.103230 < d(\mathcal{C}) < 0.103398$；丰数密度边界大幅提升至$0.247619608 < d(\mathcal{A}) < 0.247619658$；原始覆盖数计数上界为$O\left(x\exp\left(-\frac{1}{2\sqrt{\log 2}}\sqrt{\log x}\log\log x\right)\right)$。

Conclusion: 覆盖数集具有严格定义的密度，其精确计算需要创新方法；丰数密度边界得到显著优化；原始覆盖数的稀疏性远超原始丰数。

Abstract: We investigate the densities of the sets of abundant numbers and of covering
numbers, integers $n$ for which there exists a distinct covering system where
every modulus divides $n$. We establish that the set $\mathcal{C}$ of covering
numbers possesses a natural density $d(\mathcal{C})$ and prove that $0.103230 <
d(\mathcal{C}) < 0.103398.$ Our approach adapts methods developed by Behrend
and Del\'eglise for bounding the density of abundant numbers, by introducing a
function $c(n)$ that measures how close an integer $n$ is to being a covering
number with the property that $c(n) \leq h(n) = \sigma(n)/n$. However,
computing $d(\mathcal{C})$ to three decimal digits requires some new ideas to
simplify the computations. As a byproduct of our methods, we obtain
significantly improved bounds for $d(\mathcal{A})$, the density of abundant
numbers, namely $0.247619608 < d(\mathcal{A}) < 0.247619658$. We also show the
count of primitive covering numbers up to $x$ is $O\left(
x\exp\left(\left(-\tfrac{1}{2\sqrt{\log 2}} + \epsilon\right)\sqrt{\log x} \log
\log x\right)\right)$, which is substantially smaller than the corresponding
bound for primitive abundant numbers.

</details>


### [14] [Nonzero $\mathfrak{n}$ cohomology of Totally Degenerate Limit of Discrete Series representations](https://arxiv.org/abs/2507.23102)
*Jin Kunwoo Lee*

Main category: math.NT

TL;DR: 证明了完全退化离散级数表示的n上同调群在特定度上非零，并发现Soergel的组合复形满足Serre对偶性，揭示了U(n+1)和U(n)的TDLDS在相同度上存在非零上同调群，暗示了酉群任意秩的Gan-Gross-Prasad型分支法则。


<details>
  <summary>Details</summary>
Motivation: 研究完全退化离散级数表示（TDLDS）的上同调性质，探索其在酉群表示论中的潜在分支法则。

Method: 通过分析Soergel的组合复形结构，证明其满足Serre对偶性，并计算特定度的上同调群。

Result: 发现U(n+1)和U(n)的TDLDS在相同度上存在非零n上同调群，且其组合复形具有对偶性。

Conclusion: 该结果暗示了酉群任意秩的TDLDS可能存在类似Gan-Gross-Prasad的分支法则，为后续表示论研究提供了新方向。

Abstract: We show that a totally degenerate limit of discrete series representation
admits a choice of n cohomology group that is nonvanishing at a canonically
defined degree. We then show that the combinatorial complexes used by Soergel
to compute these cohomology groups satisfies Serre duality. We conclude that
this produces two n cohomology groups, each for a totally degenerate limit of
discrete series of U(n+1) and U(n), which are nonvanishing at the same degree.
This suggests Gan Gross Prasad type branching laws for the TDLDS of unitary
groups of any rank.

</details>


### [15] [Cyclotomy, cyclotomic cosets and arimetic propeties of some families in $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$](https://arxiv.org/abs/2507.23179)
*Juncheng Zhou,Hongfeng Wu*

Main category: math.NT

TL;DR: 该论文研究了在环$\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$中，利用二阶分圆类获得算术性质，并推广了已有结果，同时给出了该环中极小理想的本原幂等元的显式表达式。


<details>
  <summary>Details</summary>
Motivation: 研究特定环结构中的算术性质，推广已有结果，并探索极小理想的本原幂等元表达式。

Method: 使用二阶分圆类（$n=p^sq^t$，$p\equiv3 \mathrm{mod} 4$，$\gcd(\phi(p^s),\phi(q^t))=2$），结合$l$是模$q^t$的原根且$\mathrm{ord}_{p^s}(l)=\phi(p^s)/2$的条件。

Result: 获得了环$\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$的算术性质，并推广了文献中的结果；同时给出了该环中极小理想的本原幂等元的显式表达式。

Conclusion: 通过分圆类方法，成功推广了已有结果，并揭示了特定环结构中极小理想的本原幂等元形式，为相关领域的研究提供了新工具。

Abstract: Arithmetic properties of some families in $\frac{\mathbb{F}_l[x]}{\langle
x^{p^sq^t}-1\rangle}$ are obtained by using the cyclotomic classes of order 2
with respect to $n=p^sq^t$, where $p\equiv3 \mathrm{mod} 4$,
$\gcd(\phi(p^s),\phi(q^t))=2$, $l$ is a primitive root modulo $q^t$ and
$\mathrm{ord}_{p^s}(l)=\phi(p^s)/2$. The form of these cyclotomic classes
enables us to further generalize the results obtained in \cite{ref1}. The
explicit expressions of primitive idempotents of minimal ideals in
$\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ are also obtained.

</details>


### [16] [Extending bounds on minimal ranks of universal quadratic lattices to larger number fields](https://arxiv.org/abs/2507.23338)
*Matěj Doležálek*

Main category: math.NT

TL;DR: 本文改进了Kala的技术，通过研究数域复合体中的子域结构，利用基本伽罗瓦理论将其转化为群论问题，证明了若在度数为d的全实数域中存在通用格的最小秩$\geq r$，则在所有$k\geq3$的度数kd中也存在此类域。


<details>
  <summary>Details</summary>
Motivation: 已有大量文献证明在某些全实数域族中，通用二次格的最小秩可以任意大。Kala提出了一种技术，在特定条件下将此类结果扩展到更大的域（如从二次域到任意偶数度的域）。本文旨在改进这一技术。

Method: 通过研究数域复合体中的子域结构，利用基本伽罗瓦理论将其转化为群论问题，从而改进Kala的技术。

Result: 证明了若在度数为d的全实数域中存在通用格的最小秩$\geq r$，则在所有$k\geq3$的度数kd中也存在此类域。

Conclusion: 本文通过改进Kala的技术，扩展了关于全实数域中通用格最小秩的结果，证明了其在更高度数域中的存在性。

Abstract: There exist numerous results in the literature proving that within certain
families of totally real number fields, the minimal rank of a universal
quadratic lattice over such a field can be arbitrarily large. Kala introduced a
technique of extending such results to larger fields -- e.g. from quadratic
fields to fields of arbitrary even degree -- under some conditions. We present
improvements to this technique by investigating the structure of subfields
within composita of number fields, using basic Galois theory to translate this
into a group-theoretic problem. In particular, we show that if totally real
number fields with minimal rank of a universal lattice $\geq r$ exist in degree
$d$, then they also exist in degree $kd$ for all $k\geq3$.

</details>


### [17] [Discrete restrictions from Laurent monomial systems for multiple Dirichlet series](https://arxiv.org/abs/2507.23477)
*Shenghao Hua*

Main category: math.NT

TL;DR: 本文介绍了一类特殊的多元Dirichlet级数，其项支持在一个簇上并具有欧拉积结构，这些级数自然来源于Dirichlet扭曲的自守\( L \)-函数的扭曲矩。


<details>
  <summary>Details</summary>
Motivation: 研究多元Dirichlet级数的动机在于它们与自守\( L \)-函数的扭曲矩之间的自然联系，以及它们在数论中的潜在应用。

Method: 通过分析Dirichlet扭曲的自守\( L \)-函数的扭曲矩，构建并研究了一类具有欧拉积结构的多元Dirichlet级数。

Result: 结果表明，这类多元Dirichlet级数不仅具有欧拉积结构，而且与自守\( L \)-函数的扭曲矩密切相关。

Conclusion: 本文提出了关于这些级数解析性质的若干猜想，为进一步研究多元Dirichlet级数及其在数论中的应用奠定了基础。

Abstract: We introduce a special class of multiple Dirichlet series whose terms are
supported on a variety and which admit an Euler product structure. We show that
these series arise naturally from twisted moments of automorphic \( L
\)-functions associated with Dirichlet twists. We proposed several conjectures
on the analytic properties of these series.

</details>


### [18] [Picturesque convolution-like recurrences and partial sums' generation](https://arxiv.org/abs/2507.23619)
*Ignas Gasparavičius,Andrius Grigutis,Juozas Petkelis*

Main category: math.NT

TL;DR: 本文提出了一种方法，通过已知序列${\pmb b}$构造相关序列${\pmb a}$，并探讨了其极限与初始项的关系，展示了该方法在生成著名序列（如黎曼zeta函数部分和）中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究如何从已知序列${\pmb b}$生成具有特定关系的序列${\pmb a}$，并探索其数学性质与应用价值。

Method: 通过递推关系$a_n=a_0 b_{n+m}+\ldots +a_{n+m}b_0$构造序列${\pmb a}$，分析$\lim_{n\to\infty}a_n$与初始项$a_0,\ldots,a_{m-1}$的关联。

Result: 证明了序列${\pmb a}$的极限与初始项的显式关系，展示了该方法可生成平面/空间中的优美模式，并能导出黎曼zeta函数部分和等著名序列。

Conclusion: 该序列构造方法具有普适性，不仅能揭示数学内在联系，还能通过特定${\pmb b}$生成经典数列，为序列分析提供了新工具。

Abstract: Let ${\pmb b}=\{b_0,\,b_1,\,\ldots\}$ be the known sequence of numbers such
that $b_0\neq0$. In this work, we develop methods to find another sequence
${\pmb a}=\{a_0,\,a_1,\,\ldots\}$ that is related to ${\pmb b}$ as follows:
$a_n=a_0\,b_{n+m}+a_1\,b_{n+m-1}+\ldots+a_{n+m}\,b_0$,
$n\in\mathbb{N}\cup\{0\}$, $m\in\mathbb{N}$. We show the connection of
$\lim_{n\to\infty}a_n$ with $a_0,\,a_1,\,\ldots,\,a_{m-1}$ and provide varied
examples of finding the sequence ${\pmb a}$ when ${\pmb b}$ is given. We
demonstrate that the sequences ${\pmb a}$ may exhibit pretty patterns in the
plane or space. Also, we show that the properly chosen sequence ${\pmb b}$ may
define ${\pmb a}$ as some famous sequences, such as the partial sums of the
Riemann zeta function, etc.

</details>


### [19] [An evident corollary arising from Newton--Thorne](https://arxiv.org/abs/2507.23656)
*Shenghao Hua*

Main category: math.NT

TL;DR: 本文提出了一类特殊的自守提升例子，涉及多个自守表示的张量积，其动机源于Schur多项式的组合恒等式以及Newton和Thorne的著名结果。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于Schur多项式的组合恒等式以及Newton和Thorne的著名结果，旨在探索自守表示张量积的$L$-函数匹配问题。

Method: 通过构建一类特殊的自守提升例子，结合Schur多项式的组合恒等式，研究了多个自守表示张量积的$L$-函数匹配问题。

Result: 研究结果表明，存在一类特殊的自守提升例子，能够实现多个自守表示张量积的$L$-函数匹配。

Conclusion: 本文通过Schur多项式的组合恒等式和Newton-Thorne结果，成功构建了一类特殊的自守提升例子，为自守表示张量积的$L$-函数匹配问题提供了新的视角。

Abstract: We present a special class of examples of automorphic lifts of multiple
tensor products of automorphic representations in the sense of matching
$L$-functions, motivated by combinatorial identities for Schur polynomials and
a celebrated result of Newton and Thorne.

</details>


### [20] [A Central Limit Theorem for the Winding Number of Low-Lying Closed Geodesics](https://arxiv.org/abs/2507.23706)
*Elias Dubno*

Main category: math.NT

TL;DR: 证明了模曲面上低洼闭合测地线的缠绕在任意自然长度归一化下具有高斯极限分布。


<details>
  <summary>Details</summary>
Motivation: 研究模曲面上闭合测地线的统计特性，探索其缠绕行为的极限分布规律。

Method: 通过数学分析与概率论方法，对闭合测地线的缠绕进行归一化处理并建立统计模型。

Result: 发现归一化后的缠绕行为服从高斯分布，揭示了其普遍统计特性。

Conclusion: 该结果为模曲面几何与概率论的交叉研究提供了新的理论支持，表明高斯分布在此类问题中的普适性。

Abstract: We show that the winding of low-lying closed geodesics on the modular surface
has a Gaussian limiting distribution when normalized by any natural notion of
length.

</details>


### [21] [Bost-Connes systems and periodic Witt vectors](https://arxiv.org/abs/2507.23759)
*Bora Yalkinoglu*

Main category: math.NT

TL;DR: 利用Borger的周期Witt向量理论，构建了一般数域Bost-Connes系统算术子代数的积分细化。


<details>
  <summary>Details</summary>
Motivation: 研究Bost-Connes系统在一般数域上的算术子代数结构，寻求其积分层面的理论扩展。

Method: 采用Borger的周期Witt向量理论作为核心工具，进行代数构造与理论推导。

Result: 成功建立了适用于任意数域的Bost-Connes系统算术子代数的积分细化版本。

Conclusion: 该成果为Bost-Connes系统的算术结构提供了更深刻的积分理论框架，拓展了非交换几何在数论中的应用。

Abstract: In this note, using Borger's theory of periodic Witt vectors, we construct
integral refinements of the arithmetic subalgebras associated with Bost-Connes
systems for general number fields.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [22] [Convolution semigroups for automorphism dynamics](https://arxiv.org/abs/2507.23503)
*Kyle Gannon,Daniel Max Hoffmann,Krzysztof Krupiński*

Main category: math.LO

TL;DR: 该研究从Hrushovski关于可定义模式的论文出发，构建了第一阶结构自同构群自然作用相关的Ellis半群与类型及Keisler测度集合间的同胚映射，进而将半群运算推广为任意一阶理论中不变类型与测度的新型卷积运算，并建立了幂等测度与自同构群闭子群间的对应关系。


<details>
  <summary>Details</summary>
Motivation: 研究最初受Hrushovski关于可定义模式的论文启发，旨在探索第一阶结构自同构群作用下的Ellis半群与类型、Keisler测度集合之间的深层联系。

Method: 通过建立Ellis半群与类型及Keisler测度集合的同胚映射，将半群运算转移至后者，并推广为不变类型与测度的卷积运算；利用仿射类构造证明该卷积可编码可定义群上的标准可定义卷积运算。

Result: 成功构建新型卷积运算的普适理论，证明了幂等测度与自同构群闭子群在相对可定义拓扑下的对应定理，并通过仿射类验证了新卷积对标准可定义卷积的编码能力。

Conclusion: 该研究不仅扩展了不变类型与测度的卷积理论框架，还通过对应定理揭示了幂等测度与模型论自同构群结构的深刻联系，为后续研究提供了新的工具与视角。

Abstract: Initially motivated by Hrushovski's paper on definability patterns, we obtain
homeomorphisms between Ellis semigroups related to natural actions of the
automorphism groups of first order structures and certain collections of types
and Keisler measures. Thus, we can transfer the semigroup operation from these
Ellis semigroups to the corresponding collections of types and Keisler
measures. By generalizing this transferred product, we obtain a new convolution
operation for invariant types and measures in arbitrary first-order theories.
We develop its general theory and prove several correspondence theorems between
idempotent measures and closed subgroups of the automorphism group of a
sufficiently large (so-called monster) model with respect to the relatively
definable topology. Via the affine sort construction, we demonstrate that this
new notion of convolution encodes the standard definable convolution operation
over definable groups.

</details>


<div id='math.GM'></div>

# math.GM [[Back]](#toc)

### [23] [On the Explicit Expression of an Extended Version of Riemann Zeta Function](https://arxiv.org/abs/2507.22961)
*Yushi Huang*

Main category: math.GM

TL;DR: 本文通过Mellin反演公式和柯西留数定理，研究了扩展版Riemann zeta函数的显式表达，并探讨了其在特殊函数积分及Barnes zeta函数中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究扩展版Riemann zeta函数的显式表达，以深化对特殊函数积分及其应用的理解。

Method: 使用Mellin反演公式和柯西留数定理计算Mellin-Barnes型积分，并通过改变积分路径和应用Riemann zeta函数的功能方程、欧拉反射公式及Legendre倍增公式进行积分评估。

Result: 成功推导出扩展版Riemann zeta函数$\sum_{m=1}^{\infty}\sum_{n=1}^{\infty}{(m+n)^{-s}}$的显式表达式，并展示了其与双曲函数等特殊函数积分的联系。

Conclusion: 该研究不仅提供了扩展版Riemann zeta函数的显式表达，还为Barnes zeta函数的显式表达推导提供了新的途径，展示了其在特殊函数积分中的广泛应用潜力。

Abstract: In this paper, we focus on the explicit expression of an extended version of
Riemann zeta function. We use two different methods, Mellin inversion formula
and Cauchy's residue theorem, to calculate a Mellin-Barnes type integral of the
analytic function regarding $z$: $\Gamma(z)\Gamma(s-z)u^{-z}$ ($u\in (0,1)$,
$s\in \mathbb{C}$). We provide the necessary background on the analytic
properties of Gamma and Riemann zeta function to confirm the absolute
convergence of this Mellin-Barnes integral. Next, we represent the extended
version of Riemann zeta function
$\sum_{m=1}^{\infty}\sum_{n=1}^{\infty}{(m+n)^{-s}}$ using the following
complex integral where the real part of $s$ is larger than 2 and $c>1$ is
chosen to make $\Re(s)-c$ larger than 1.
$$\Gamma(s)\sum_{m=1}^{\infty}\sum_{n=1}^{\infty}{(m+n)^{-s}}=\frac{1}{2\pi i}
\int_{c - i\infty}^{c + i\infty} \zeta(z) \zeta(s - z) \Gamma(z) \Gamma(s - z)
\, dz$$ We provide the evaluation of this integral by changing the integration
path from straight line $\Re(z)=c$ into a rectangular contour whose left side
is positioned at negative infinity. We apply the functional equation of Riemann
zeta function, Euler's reflection formula, and Legendre's duplication formula
to evaluate the integral segment through $\Re(z)=-\infty$. After introducing
Hurwitz zeta function and properly calculating the difference between the sum
of residues in two analogous rectangular contours, we finalize the evaluation.
Lastly, we demonstrate the connection of this result with other intricate
integrals involving special functions, such as the hyperbolic function.
Additionally, we discuss its applications in deriving explicit expressions for
the Barnes zeta function.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [24] [Domination, matching and transversal numbers for Berge-$G$ hypergraphs](https://arxiv.org/abs/2507.22957)
*María José Chávez de Diego,Pablo Montero Moreno,María Trinidad Villar-Liñán*

Main category: math.CO

TL;DR: 本文研究了Berge-G超图的扩张，探讨了支配数、匹配数和横截数及其关系，推广了广义幂超图的相关结果。


<details>
  <summary>Details</summary>
Motivation: 研究Berge-G超图的扩张家族，旨在扩展对广义幂超图的理解，并探索超图中支配、匹配和横截参数之间的关系。

Method: 通过定义图$G$的扩张作为Berge-$G$超图的一个特定子族，分析其支配数、匹配数和横截数，并与已有结果进行比较。

Result: 在Berge-G超图的扩张家族中，获得了支配数、匹配数和横截数的新关系，推广了广义幂超图的先前研究成果。

Conclusion: 该工作为Berge-G超图的扩张家族提供了理论框架，揭示了支配、匹配和横截参数之间的新联系，对超图理论有重要贡献。

Abstract: Let $G=(V(G),E(G))$ be a graph and $H=(V(H),E(H))$ be a hypergraph. The
hypergraph $H$ is a {\it Berge-G} if there is a bijection $f : E(G) \mapsto
E(H)$ such that for each $e \in E(G)$ we have $e \subseteq f(e)$. We define
{\it dilations of $G$} as a particular subfamily of not necessarily uniform
Berge-$G$ hypergraphs. We examine domination, matching and transversal numbers
and some relation between these parameters in that family of hypergraphs.
  Our work generalizes previous results concerning generalized power
hypergraphs.

</details>


### [25] [Character theoretic techniques for nonabelian partial difference sets](https://arxiv.org/abs/2507.23039)
*Seth R. Nelson,Eric Swartz*

Main category: math.CO

TL;DR: 本文研究了非阿贝尔群中的部分差集（PDS），扩展了特征理论技术，证明了Ott关于广义四边形结果的类似结论，并构造了新的非阿贝尔PDS实例。


<details>
  <summary>Details</summary>
Motivation: 近年来，非阿贝尔群中的PDS研究受到广泛关注，本文旨在开发适用于非阿贝尔环境的特征理论技术。

Method: 通过特征理论技术，分析了PDS与父群共轭类的交集，并在许多情况下计算了这些交集。

Result: 证明了PDS在多种情况下的不存在性，并提供了存在时的严格限制。此外，构造了文献中未提及的非阿贝尔PDS实例，包括与Clapham研究的块正则Steiner三重系统相关的无限族。

Conclusion: 本文成功将特征理论技术应用于非阿贝尔群中的PDS研究，不仅限制了PDS的存在条件，还构造了新的非阿贝尔PDS实例，扩展了该领域的研究范围。

Abstract: A $(v,k,\lambda, \mu)$-partial difference set (PDS) is a subset $D$ of size
$k$ of a group $G$ of order $v$ such that every nonidentity element $g$ of $G$
can be expressed in either $\lambda$ or $\mu$ different ways as a product
$xy^{-1}$, $x, y \in D$, depending on whether or not $g$ is in $D$. If $D$ is
inverse closed and $1 \notin D$, then the Cayley graph ${\rm Cay}(G,D)$ is a
$(v,k,\lambda, \mu)$-strongly regular graph (SRG). PDSs have been studied
extensively over the years, especially in abelian groups, where techniques from
character theory have proven to be particularly effective. Recently, there has
been considerable interest in studying PDSs in nonabelian groups, and the
purpose of this paper is develop character theoretic techniques that apply in
the nonabelian setting. We prove that analogues of character theoretic results
of Ott about generalized quadrangles of order $s$ also hold in the general PDS
setting, and we are able to use these techniques to compute the intersection of
a putative PDS with the conjugacy classes of the parent group in many
instances. With these techniques, we are able to prove the nonexistence of PDSs
in numerous instances and provide severe restrictions in cases when such PDSs
may still exist. Furthermore, we are able to use these techniques
constructively, computing several examples of PDSs in nonabelian groups not
previously recognized in the literature, including an infinite family of
genuinely nonabelian PDSs associated to the block-regular Steiner triple
systems originally studied by Clapham and related infinite families of
genuinely nonabelian PDSs associated to the block-regular Steiner $2$-designs
first studied by Wilson.

</details>


### [26] [Binary matroids and degree-boundedness for pivot-minors](https://arxiv.org/abs/2507.23182)
*Rutger Campbell,James Davies,Robert Hickingbotham*

Main category: math.CO

TL;DR: 证明了对于每个二分图$H$和正整数$s$，排除$H$作为pivot-minor且不含$K_{s,s}$子图的图类具有有界平均度。同时证明了$K_{s,t}$-free二分圆图存在度数上限顶点。


<details>
  <summary>Details</summary>
Motivation: 研究特定图类（如排除特定子图或pivot-minor的图）的图论性质，特别是平均度的界限问题。

Method: 利用Geelen等人宣布的二元拟阵结构定理，并结合对$K_{s,t}$-free二分圆图的顶点度数分析。

Result: 证明了排除$H$作为pivot-minor且不含$K_{s,s}$子图的图类具有有界平均度；并给出$K_{s,t}$-free二分圆图顶点度数的紧上界$\max\{2s-2, t-1\}$。

Conclusion: 该研究为特定图类的结构性质提供了理论保证，并通过示例验证了度数界限的紧性。

Abstract: We prove that for every bipartite graph $H$ and positive integer $s$, the
class of $K_{s,s}$-subgraph-free graphs excluding $H$ as a pivot-minor has
bounded average degree. Our proof relies on the announced binary matroid
structure theorem of Geelen, Gerards, and Whittle.
  Along the way, we also prove that every $K_{s,t}$-free bipartite circle graph
with $s\le t$ has a vertex of degree at most $\max\{2s-2, t-1\}$ and provide
examples showing that this is tight.

</details>


### [27] [Weighted $K$-$k$-Schur functions and their application to the $K$-$k$-Schur alternating conjecture](https://arxiv.org/abs/2507.23222)
*Yaozhou Fan,Xing Gao*

Main category: math.CO

TL;DR: 本文引入加权$K$-$k$-Schur函数的新概念，统一并扩展了$K$-$k$-Schur函数和闭$k$-Schur Katalan函数，解决了Blasiak等人提出的$K$-$k$-Schur交替猜想。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于统一和扩展现有的$K$-$k$-Schur函数理论，并解决2022年提出的$K$-$k$-Schur交替猜想，以深化对$K$-理论对称函数组合结构的理解。

Method: 通过引入加权$K$-$k$-Schur函数的新概念，并研究其在特定$k$-有界分区下的交替性质，从而扩展了Katalan函数的范畴。

Result: 研究结果证实了$K$-$k$-Schur交替猜想对于广泛类别的$k$-有界分区（包括所有严格递减的$k$-有界分区）成立。

Conclusion: 该研究不仅解决了重要的数学猜想，而且为$K$-理论对称函数的组合结构提供了新的见解。

Abstract: We introduce the new concept of weighted $K$-$k$-Schur functions -- a novel
family within the broader class of Katalan functions -- that unifies and
extends both $K$-$k$-Schur functions and closed $k$-Schur Katalan functions.
This new notion exhibits a fundamental alternating property under certain
conditions on the indexed $k$-bounded partitions. As a central application, we
resolve the $K$-$k$-Schur alternating conjecture -- posed by Blasiak, Morse,
and Seelinger in 2022 -- for a wide class of $k$-bounded partitions, including
all strictly decreasing $k$-bounded partitions. Our results shed new light on
the combinatorial structure of $K$-theoretic symmetric functions.

</details>


### [28] [Perfecting the Line Graph](https://arxiv.org/abs/2507.23231)
*Hartosh Singh Bal*

Main category: math.CO

TL;DR: 本文介绍了两种将任意有限图转化为完美图的规范构造：对称提升$\mathrm{HL}'_2(G)$和有序提升$\mathrm{HL}_2(G)$，它们均源自二分双覆盖的线图且具有盒完美性。对称提升作为线图的规范2-覆盖，可分解为对称与反对称部分，保留基图的光谱特性并提升组合扩展性。该构造可推广至基于汉明距离约束的参数化提升。


<details>
  <summary>Details</summary>
Motivation: 研究目标是通过规范构造将任意有限图转化为具有完美图性质的图结构，特别是保留光谱特性同时增强组合扩展性，并为正则图（如Paley图）构建稀疏、高结构性的盒完美扩展图族。

Method: 提出两种构造方法：1) 结构无关的对称提升$\mathrm{HL}'_2(G)$，通过二分双覆盖的线图实现；2) 依赖顶点标记的有序提升$\mathrm{HL}_2(G)$。对称提升可分解为恢复原线图的对称部分和编码边重叠符号的反对称线图$L^-(G)$。进一步推广至参数化提升$\mathrm{HL}_{r,d}(G)$。

Result: 对称提升完整保留了基图$L(G)$的邻接与拉普拉斯特征值（含重数），且对正则图能生成稀疏、高结构性的盒完美扩展图族。随机正则基图也表现出类似性质，为盒完美随机正则图研究提供可能。参数化提升成功将构造推广至汉明距离约束的有序元组。

Conclusion: 两种提升构造为完美图生成提供了通用框架，其中对称提升在保留光谱特性的同时优化了组合扩展性。该工作不仅为结构化扩展图族构建开辟了新途径，其参数化推广更展现了在更复杂图类中的应用潜力。

Abstract: This paper introduces two canonical constructions that transform arbitrary
finite graphs into perfect graphs: the symmetric lift $\mathrm{HL}'_2(G)$,
which is purely structural and label-invariant, and the ordered lift
$\mathrm{HL}_2(G)$, which depends explicitly on vertex labeling and encodes
directional information. Both lifts arise as line graphs of bipartite double
covers and are box-perfect.
  The symmetric lift $\mathrm{HL}'_2(G)$ forms a canonical 2-cover of the line
graph $L(G)$. This involution decomposes $\mathrm{HL}'_2(G)$ into symmetric and
antisymmetric components: the symmetric part recovers $L(G)$, while the
antisymmetric part yields a signed graph $L^-(G)$, the antisymmetric line
graph, with +1/-1 edges encoding consistent vs. crossed overlaps. Thus, all
adjacency and Laplacian eigenvalues of $L(G)$, with multiplicities, appear
within those of $\mathrm{HL}'_2(G)$, despite $L(G)$ typically not being a
subgraph.
  For regular graphs such as Paley graphs, this yields infinite families of
sparse, highly structured regular and box-perfect expanders that also retain
large cliques. The lift retains much of the spectral expansion of the base
while improving the combinatorial expansion. Much the same behavior is observed
with random regular base graphs, allowing for the possibility of the study of
box-perfect random regular graphs.
  Finally, we generalize these constructions to parameterized lifts
$\mathrm{HL}_{r,d}(G)$ and $\mathrm{HL}_{r,d}'(G)$ defined on ordered
$r$-tuples connected by Hamming distance constraints, which structurally encode
the base graph and remain box-perfect.

</details>


### [29] [Recent advances in arrow relations and traces of sets](https://arxiv.org/abs/2507.23375)
*Mingze Li,Jie Ma,Mingyuan Rong*

Main category: math.CO

TL;DR: 本文综述了极值集理论中的箭头关系$(n, m) \rightarrow (a, b)$，探讨了集合族与其迹之间的定量关系，并总结了该领域的最新研究进展。


<details>
  <summary>Details</summary>
Motivation: 箭头关系是极值集理论的核心概念，用于量化集合族与其迹之间的关系，理解这种关系有助于解决极值组合学中的一系列问题。

Method: 通过综述近期关于箭头关系的研究成果，从不同的极值视角对相关问题和结果进行分类和探讨。

Result: 文章总结了多种与箭头关系相关的问题和结果，提供了该领域的统一概述，展示了不同极值视角下的研究进展。

Conclusion: 本文为极值集理论中的箭头关系研究提供了全面的综述，突出了该领域的多样性和进展，为未来研究指明了方向。

Abstract: The arrow relation, a central concept in extremal set theory, captures
quantitative relationships between families of sets and their traces. Formally,
the arrow relation $(n, m) \rightarrow (a, b)$ signifies that for any family
$\mathcal{F} \subseteq 2^{[n]}$ with $|\mathcal{F}| \geqslant m$, there exists
an $a$-element subset $T \subseteq [n]$ such that the trace $\mathcal{F}_{|T} =
\{ F \cap T : F \in \mathcal{F} \}$ contains at least $b$ distinct sets. This
survey highlights recent progress on a variety of problems and results
connected to arrow relations. We explore diverse topics, broadly categorized by
different extremal perspectives on these relations, offering a cohesive
overview of the field.

</details>


### [30] [Combinatorial solutions to the Social Golfer Problem and Social Golfer Problem with Adjacent Group Sizes](https://arxiv.org/abs/2507.23376)
*Alice Miller,Ivaylo Valkov,R. Julian R. Abel*

Main category: math.CO

TL;DR: 论文利用可分解组合设计（如可分解平衡不完全区组设计等）构建了社交高尔夫球手问题（SGP）及其变种（SGA）的最优解，并提出通用算法及150人内的完整解集。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过组合数学方法解决社交高尔夫球手问题及其相邻组规模变种，寻求最优分组方案。

Method: 采用可分解组合设计（RBIBD、RGDD等）理论框架，开发通用算法系统化求解问题。

Result: 提供了适用于150名玩家以内的完整最优解集合，验证了组合设计在SGP/SGA中的有效性。

Conclusion: 组合设计理论为社交高尔夫问题提供了系统化解决方案，算法可实现规模扩展，未来可探索更大玩家群体的应用。

Abstract: Resolvable combinatorial designs including Resolvable Balanced Incomplete
Block Designs, Resolvable Group Divisible Designs, Uniformly Resolvable Designs
and Mutually Orthogonal Latin Squares and Rectangles are used to construct
optimal solutions to the Social Golfer problem (SGP) and the Social Golfer
problem with adjacent group sizes (SGA). An algorithm is presented to find an
optimal solution in general, and a complete set of solutions is provided for up
to 150 players.

</details>


### [31] [Towards the classification of maximum scattered linear sets of $\mathrm{PG}(1,q^5)$](https://arxiv.org/abs/2507.23409)
*Stefano Lia,Giovanni Longobardi,Corrado Zanella*

Main category: math.CO

TL;DR: 本文研究了$\mathrm{PG}(1,q^5)$中的最大散射线性集，证明了其投影配置的几何特性，并推导出新类型线性集必须满足的多项式形式。通过计算机验证，发现$q\leq 25$时不存在新类型的最大散射线性集。


<details>
  <summary>Details</summary>
Motivation: 研究$\mathrm{PG}(1,q^5)$中最大散射线性集的投影配置特性，以确定是否存在新类型的线性集，并验证其在小阶数下的存在性。

Method: 通过分析投影配置的几何性质，特别是点$A$和$B$的秩，推导出新类型线性集的多项式形式，并通过计算机对$q\leq 25$的情况进行穷举验证。

Result: 若点$A$或$B$的秩为5，则对应的最大散射线性集必为LP型；若存在新类型线性集，则必须满足$\mathrm{rk} A=\mathrm{rk} B=4$。计算机验证显示$q\leq 25$时无新类型存在。

Conclusion: 本文证明了最大散射线性集的分类与其投影配置的几何特性密切相关，并为新类型的存在性提供了理论依据和计算验证。

Abstract: Every maximum scattered linear set in $\mathrm{PG}(1,q^5)$ is the projection
of an $\mathbb{F}_q$-subgeometry $\Sigma$ of $\mathrm{PG}(4,q^5)$ from a plane
$\Gamma$ external to the secant variety to $\Sigma$. The pair $(\Gamma,\Sigma)$
will be called a projecting configuration for the linear set. The projecting
configurations for the only known maximum scattered linear sets in
$\mathrm{PG}(1,q^5)$, namely those of pseudoregulus and LP type, have been
characterized in the literature by B. Csajb\'{o}k, C. Zanella in 2016 and by C.
Zanella, F. Zullo in 2020. Let $(\Gamma,\Sigma)$ be a projecting configuration
for a maximum scattered linear set in $\mathrm{PG}(1,q^5)$, let $\sigma$ be a
generator of $\mathbb{G}=\mathrm{P}\Gamma \mathrm{L}(5,q^5)_\Sigma$, and
$A=\Gamma\cap\Gamma^{\sigma^4}$, $B=\Gamma\cap\Gamma^{\sigma^3}$. If $A$ and
$B$ are not both points, then the projected linear set is of pseudoregulus
type. Then, suppose that they are points. The rank of a point $X$ is the
vectorial dimension of the span of the orbit of $X$ under the action of
$\mathbb{G}$. In this paper, by investigating the geometric properties of
projecting configurations, it is proved that if at least one of the points $A$
and $B$ has rank 5, the associated maximum scattered linear set must be of LP
type. Then, if a maximum scattered linear set of a new type exists, it must be
such that $\mathrm{rk} A=\mathrm{rk} B=4$. In this paper we derive two possible
polynomial forms that such a linear set must have. An exhaustive analysis by
computer shows that for $q\leq 25$, no new maximum scattered linear set exists.

</details>


### [32] [The net-regular strongly regular signed graphs with degree 5](https://arxiv.org/abs/2507.23420)
*Qian Yu,Yaoping Hou*

Main category: math.CO

TL;DR: 本文确定了所有具有5度的连通净正则强正则符号图，发现净度为3和1的强正则符号图分别有5个和2个。


<details>
  <summary>Details</summary>
Motivation: 研究连通净正则强正则符号图的分类，特别是针对度数为5的情况，以填补该领域的知识空白。

Method: 通过数学分析和图论方法，系统地分类和验证所有可能的连通净正则强正则符号图。

Result: 确定了5个净度为3和2个净度为1的强正则符号图。

Conclusion: 该研究为符号图理论提供了新的分类结果，为进一步研究高维符号图奠定了基础。

Abstract: In this paper, we determine all connected net-regular strongly regular signed
graphs with degree 5. There are five and two strongly regular signed graphs
with net-degree 3 and 1, respectively.

</details>


### [33] [Fuss--Catalan algebras on generalized Dyck paths via non-crossing partitions](https://arxiv.org/abs/2507.23460)
*Keiichi Shigechi*

Main category: math.CO

TL;DR: 本文研究了Fuss--Catalan代数，作为Temperley--Lieb代数的推广，通过非交叉分割作用于广义Dyck路径。首先建立了Dyck路径与非交叉分割的双射关系，证明了Kreweras自同态等价于弦图的旋转。其次通过非交叉分割格中的递增$r$-链定义了Fuss--Catalan代数，并推广至单/双边界情形。最后讨论了代数的可积性，在$r=2$时获得了反射方程的新解。


<details>
  <summary>Details</summary>
Motivation: 研究Fuss--Catalan代数的动机在于推广Temperley--Lieb代数与Dyck路径的作用关系，探索非交叉分割与广义Dyck路径的对应性，并建立边界情形下的代数结构及其可积性质。

Method: 1) 通过非交叉分割定义Temperley--Lieb代数并建立与Dyck路径的双射；2) 利用非交叉分割格中的递增$r$-链构造Fuss--Catalan代数；3) 通过对称非交叉分割链引入边界Fuss--Catalan代数；4) 使用广义弦图验证表示兼容性；5) 分析代数可积性并求解反射方程。

Result: 1) 证明Kreweras自同态对应弦图旋转；2) 建立递增$r$-链与广义Dyck路径的双射；3) 构造单/双边界Fuss--Catalan代数；4) 在$r=2$时获得反射方程新解。

Conclusion: 通过非交叉分割框架系统推广了Temperley--Lieb代数，建立的Fuss--Catalan代数及其边界变形不仅兼容广义Dyck路径表示，还具有可积性特征，为$r=2$情形提供了反射方程的新解。

Abstract: We study the Fuss--Catalan algebras, which are generalizations of the
Temperley--Lieb algebra and act on generalized Dyck paths, through non-crossing
partitions. First, the Temperley--Lieb algebra is defined on non-crossing
partitions, and a bijection between a Dyck path and a non-crossing partition is
shown to be compatible with the Temperley--Lieb algebra on Dyck paths, or
equivalently chord diagrams. We show that the Kreweras endomorphism on
non-crossing partitions is equivalent to the rotation of chord diagrams under
the bijection. Secondly, by considering an increasing $r$-chain in the graded
lattice of non-crossing partitions, we define the Fuss--Catalan algebras on
increasing $r$-chains. Through a bijection between an increasing $r$-chain and
a generalized Dyck path, one naturally obtains the Fuss--Catalan algebra on
generalized Dyck paths. As generalizations of the Fuss--Catalan algebra, we
introduce the one- and two-boundary Fuss--Catalan algebras. Increasing
$r$-chains of symmetric non-crossing partitions give symmetric generalized Dyck
paths by the bijection, and the boundary Fuss--Catalan algebras naturally act
on them. We show that these representations are compatible with the
diagrammatic representations of the algebras by use of generalized chord
diagrams. Thirdly, we discuss the integrability of the Fuss--Catalan algebras.
For the Fuss--Catalan algebras with boundaries, we obtain a new solution of the
reflection equation in the case of $r=2$.

</details>


### [34] [Improved bounds on the postage stamp problem for large numbers of stamps](https://arxiv.org/abs/2507.23627)
*Eric James Faust,Michael Tait*

Main category: math.CO

TL;DR: 本文研究了$h$重加性基$F_h(n)$的最小基数问题，改进了现有上下界，特别是对于较大的$h$值。


<details>
  <summary>Details</summary>
Motivation: 虽然$h$重加性基的平凡上下界$h!n \lesssim F_h(n)^h \lesssim h^h n$已被熟知，但对于$h>2$的情况研究较少。本文旨在改进这一领域的最佳已知边界。

Method: 对于下界，作者采用了概率方法并结合Berry-Esseen定理；对于上界，则利用了Jia和Shen提出的有限循环群加性基构造。

Result: 证明了对于任意$\epsilon>0$，当$h$足够大时，有$\left(\frac{1}{2}-\epsilon\right)h!\sqrt{2\pi e} n\; \leq \; F_h(n)^h \; \leq \; \left(\left(\frac{\sqrt{3}}{2}+\epsilon\right)h\right)^h n$。

Conclusion: 本文显著改进了$h$重加性基$F_h(n)$的上下界，为这一领域的进一步研究提供了新的理论基础。

Abstract: Let $F_h(n)$ denote the minimum cardinality of an additive {\em $h$-fold
basis} of $\{1,2,\cdots,n\}$: a set $S$ such that any integer in $\{1,2,\cdots,
n\}$ can be written as a sum of at most $h$ elements from $S$. While the
trivial bounds $h!n \; \lesssim \; F_h(n)^h \; \lesssim \; h^h n$ are
well-known, comparatively little has been established for $h>2$. In this paper,
we make significant improvements to both of the best-known bounds on $F_h(n)$
for sufficiently large $h$. For the lower bound, we use a probabilistic
approach along with the Berry-Esseen Theorem to improve upon the best-known
asymptotic result due to Yu. We also establish the first nontrivial asymptotic
upper bound on $F_h(n)$ by leveraging a construction for additive bases of
finite cyclic groups due to Jia and Shen. In particular, we show that given any
$\epsilon>0$, for sufficiently large $h$, we have \[
\left(\frac{1}{2}-\epsilon\right)h!\sqrt{2\pi e} n\; \leq \; F_h(n)^h \; \leq
\; \left(\left(\frac{\sqrt{3}}{2}+\epsilon\right)h\right)^h n. \]

</details>


### [35] [Oriented diameter of graphs with diameter $4$ and given maximum edge girth](https://arxiv.org/abs/2507.23517)
*Jifu Lin,Lihua You*

Main category: math.CO

TL;DR: 本文研究了无桥图的最大边围长及其强定向直径的上界，特别针对直径4的图给出了$F(4,A^*)$的范围。


<details>
  <summary>Details</summary>
Motivation: 研究无桥图的最大边围长$g^*(G)$及其强定向直径的上界$F(d,A)$，旨在扩展Chv\'atal和Thomassen等人的工作，解决直径4图的定向问题。

Method: 通过定义最大边围长$g^*(G)$并分析其与图直径的关系，结合已有理论框架，推导$F(4,A^*)$的上下界。

Result: 证明了对于直径4的无桥图，$F(4,A^*)$的范围为$12\leq F(4,A^*)\leq 13$，其中$A^*=\{2,3,6,7,8,9\}$。

Conclusion: 本文进一步明确了直径4无桥图的强定向直径上界，为相关图论问题提供了新的理论支持。

Abstract: Let $G$ be a bridgeless graph. We introduce the maximum edge girth of $G$,
denoted by $g^*(G)=\max\{l_G(e)\mid e\in E(G)\}$, where $l_G(e)$ is the edge
girth of $e$, defined as the length of the shortest cycle containing $e$. Let
$F(d,A)$ be the smallest value for which every bridgeless graph $G$ with
diameter $d$ and $g^*(G)\in A$ admits a strong orientation $\overrightarrow{G}$
such that the diameter of $\overrightarrow{G}$ is at most $F(d,A)$. Let
$f(d)=F(d,A)$, where $A=\{a\in \mathbb{N}\mid 2\leq a\leq 2d+1\}$. Chv\'atal
and Thomassen (JCT-B, 1978) obtained general bounds for $f(d)$ and showed that
$f(2)=6$. Kwok et al. (JCT-B, 2010) proved that $9\leq f(3)\leq 11$. Wang and
Chen (JCT-B, 2022) determined $f(3)=9$. In this paper, we give that $12\leq
F(4,A^*)\leq 13$, where $A^*=\{2,3,6,7,8,9\}$.

</details>


### [36] [Tree-indexed sums of Catalan numbers](https://arxiv.org/abs/2507.23557)
*Alin Bostan,Valentin Féray,Paul Thévenin*

Main category: math.CO

TL;DR: 研究基于树索引的卡特兰数无限乘积和，证明其为$1/\pi$的有理系数多项式，并给出有效计算算法。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于大型蜿蜒系统（平面非交叉环构型）的分析需求。

Method: 引入参数化提升方法，证明和式可表示为第一类和第二类完全椭圆积分的多项式。

Result: 发现这些和式是$1/\pi$的有理系数多项式，且多项式次数不超过树顶点数的一半。

Conclusion: 建立了树索引和式与椭圆积分的显式联系，为相关组合问题提供了有效计算工具。

Abstract: We consider a family of infinite sums of products of Catalan numbers, indexed
by trees. We show that these sums are polynomials in $1/\pi$ with rational
coefficients; the proof is effective and provides an algorithm to explicitly
compute these sums. Along the way we introduce parametric liftings of our sums,
and show that they are polynomials in the complete elliptic integrals of the
first and second kind. Moreover, the degrees of these polynomials are at most
half of the number of vertices of the tree. The computation of these
tree-indexed sums is motivated by the study of large meandric systems, which
are non-crossing configurations of loops in the plane.

</details>


### [37] [Ramsey numbers for 1-degenerate 3-graphs](https://arxiv.org/abs/2507.23623)
*Peter Allen,Simona Boyadzhiyska,Matías Pavez-Signé*

Main category: math.CO

TL;DR: 本文构建了一个3-均匀1-退化的超图，其2色Ramsey数为$\Omega\big(n^{3/2}/\log n\big)$，否定了超图Burr-Erd\H{o}s猜想的所有剩余开放情况，并证明了广义刺猬图的Ramsey数上界为$O\big(n^{3/2}\big)$。


<details>
  <summary>Details</summary>
Motivation: 研究超图Burr-Erd\H{o}s猜想的剩余开放情况，通过构建特定超图验证其不成立，并探索广义刺猬图的Ramsey数上界。

Method: 构建了一个3-均匀1-退化的超图，该图是著名刺猬图的变体，并分析了其2色Ramsey数的下界和广义刺猬图的上界。

Result: 证明了所构建超图的2色Ramsey数为$\Omega\big(n^{3/2}/\log n\big)$，且所有3-均匀广义刺猬图的Ramsey数上界为$O\big(n^{3/2}\big)$。

Conclusion: 超图Burr-Erd\H{o}s猜想的剩余开放情况均不成立，广义刺猬图的Ramsey数上界接近最优。

Abstract: We construct a 3-uniform 1-degenerate hypergraph on $n$ vertices whose
2-colour Ramsey number is $\Omega\big(n^{3/2}/\log n\big)$. This shows that all
remaining open cases of the hypergraph Burr-Erd\H{o}s conjecture are false. Our
graph is a variant of the celebrated hedgehog graph. We additionally show
near-sharp upper bounds, proving that all 3-uniform generalised hedgehogs have
2-colour Ramsey number $O\big(n^{3/2}\big)$.

</details>


### [38] [Erdős meets Nash-Williams](https://arxiv.org/abs/2507.23624)
*Michelle Delcourt,Cicely,Henderson,Thomas Lesgourgues,Luke Postle*

Main category: math.CO

TL;DR: 该论文将Erdős与Nash-Williams的猜想统一为“Erdős meets Nash-Williams猜想”，并通过分数松弛方法将最小度数要求降至0.82733n，同时采用精炼吸收法提供了新证明。


<details>
  <summary>Details</summary>
Motivation: 1847年Kirkman证明了满足$n\equiv 1,3 \mod 6$的完全图$K_n$存在Steiner三元系。1970年Nash-Williams猜想高最小度数的图存在三角形分解，1973年Erdős猜想存在任意大围长的Steiner三元系。2021年Glock等人提出统一猜想。

Method: 通过将统一猜想转化为Nash-Williams猜想的分数松弛形式，结合Delcourt与Postle的最佳分数界，采用新型精炼吸收法（而非传统迭代吸收法）进行证明。

Result: 当图$G$的最小度数至少为0.82733n时，统一猜想成立。该结果推广了Barber等人对Nash-Williams猜想的证明，以及Kwan等人对Erdős猜想的解决。

Conclusion: 研究不仅验证了“Erdős meets Nash-Williams猜想”在0.82733n条件下的正确性，还通过精炼吸收法为两个经典问题提供了独立的新证明，展示了该方法在组合数学中的潜力。

Abstract: In 1847, Kirkman proved that there exists a Steiner triple system on $n$
vertices (equivalently a triangle decomposition of the edges of $K_n$) whenever
$n$ satisfies the necessary divisibility conditions (namely $n\equiv 1,3 \mod
6$). In 1970, Nash-Williams conjectured that every graph $G$ on $n$ vertices
with minimum degree at least $3n/4$ (for $n$ large enough and satisfying the
necessary divisibility conditions) has a triangle decomposition. In 1973,
Erd\H{o}s conjectured that for each integer $g$, there exists a Steiner triple
system on $n$ vertices with girth at least $g$ (provided that $n\equiv 1,3 \mod
6$ is large enough compared to the fixed $g$). In 2021, Glock, K\"uhn, and
Osthus conjectured the common generalization of these two conjectures, dubbing
it the ``Erd\H{o}s meets Nash-Williams' Conjecture''.
  In this paper, we reduce the combined conjecture to the fractional relaxation
of the Nash-Williams' Conjecture. Combined with the best known fractional bound
of Delcourt and Postle, this proves the combined conjecture above when $G$ has
minimum degree at least $0.82733n$. We note that our result generalizes the
seminal work of Barber, K\"uhn, Lo, and Osthus on Nash-Williams' Conjecture and
the resolution of Erd\H{o}s' Conjecture by Kwan, Sah, Sawhney, and Simkin. Both
previous proofs of those results used the method of iterative absorption. Our
proof instead proceeds via the newly developed method of refined absorption
(and hence provides new independent proofs of both results).

</details>


### [39] [Which maximal subgroups are perfect codes?](https://arxiv.org/abs/2507.23635)
*Shouhong Qiao,Ning Su,Binzhou Xia,Zhishuo Zhang,Sanming Zhou*

Main category: math.CO

TL;DR: 本文系统研究了群的最大子群何时能成为完美码，提出了子群完美码的局部补集特征。


<details>
  <summary>Details</summary>
Motivation: 研究群$G$的最大子群$H$在何种Cayley图中能成为完美码，拓展完美码在群论中的应用。

Method: 通过分析子群在Cayley图中的邻域特性，建立子群完美码与局部补集之间的等价刻画。

Result: 证明了最大子群成为完美码的充要条件与其局部补集结构密切相关。

Conclusion: 该研究为群论与编码理论的交叉领域提供了新的理论工具，揭示了子群完美码的几何本质。

Abstract: A perfect code in a graph $\Gamma=(V, E)$ is a subset $C$ of $V$ such that no
two vertices in $C$ are adjacent and every vertex in $V \setminus C$ is
adjacent to exactly one vertex in $C$. A subgroup $H$ of a group $G$ is called
a subgroup perfect code of $G$ if it is a perfect code in some Cayley graph of
$G$. In this paper, we undertake a systematic study of which maximal subgroups
of a group can be perfect codes. Our approach highlights a characterization of
subgroup perfect codes in terms of their ``local'' complements.

</details>


### [40] [Horofunctions of infinite Sierpinski polygon graphs](https://arxiv.org/abs/2507.23681)
*Daniele D'Angeli,Francesco Matucci,Davide Perego,Emanuele Rodaro*

Main category: math.CO

TL;DR: 该论文推广了D'Angeli和Donno的工作，通过无限字母序列构造有限点图序列，研究其Gromov-Hausdorff极限图，并基于二面体群描述同构类，探讨horofunction边界中Busemann与非Busemann点的性质。


<details>
  <summary>Details</summary>
Motivation: 研究从无限序列构造的有限点图序列的极限行为，特别是其同构分类及horofunction边界性质，以深化对几何群论中极限结构的理解。

Method: 从$r \neq 4i$（$i \in \mathbb{N}$）字母的无限序列出发，构造一系列有限点图，分析其Gromov-Hausdorff极限，并利用二面体群描述同构类。

Result: 极限图的同构类可由二面体群刻画，并揭示了horofunction边界中Busemann点与非Busemann点的结构特征。

Conclusion: 该工作为无限序列生成的图极限提供了新的分类框架，并拓展了对horofunction边界几何性质的认识，尤其在非Busemann点的描述上具有理论意义。

Abstract: Generalizing works of D'Angeli and Donno, we describe, starting from an
infinite sequence over $r$ letters with $r \neq 4i$ and $i \in \mathbb{N}$, a
sequence of pointed finite graphs. We study the pointed Gromov-Hausdorff limit
graphs giving a description of isomorphim classes in terms of dihedral groups
and providing insights on the horofunction boundaries in terms of Busemann and
non-Busemann points.

</details>


<div id='q-fin.MF'></div>

# q-fin.MF [[Back]](#toc)

### [41] [Volatility Modeling with Rough Paths: A Signature-Based Alternative to Classical Expansions](https://arxiv.org/abs/2507.23392)
*Elisa Alòs,Òscar Burés,Rafael de Santiago,Josep Vives*

Main category: q-fin.MF

TL;DR: 比较两种隐含波动率曲面校准方法：基于Malliavin微积分的二阶渐近展开法和基于粗糙路径理论的路径签名数据驱动法。签名法在Heston模型和粗糙Bergomi模型下均表现优异，展现了模型无关性和适应性。


<details>
  <summary>Details</summary>
Motivation: 探讨不同波动率校准方法在参数化（Heston模型）和非参数化（粗糙路径）场景下的表现，验证签名方法在复杂波动率特征（如粗糙性/非马尔可夫性）中的普适优势。

Method: 1. 渐近展开法：基于Malliavin微积分推导Heston型模型的二阶近似公式；\n2. 签名法：将波动率建模为原生过程签名的线性泛函，无需预设参数形式。

Result: 数值实验表明：\n1. 在Heston模型下，签名法与渐近法精度相当；\n2. 在粗糙Bergomi模型（渐近法失效）中，签名法仍保持高精度校准能力。

Conclusion: 基于路径签名的校准方法具有模型无关性、鲁棒性和适应性，特别适用于波动率呈现粗糙路径或非马尔可夫特征的复杂场景。

Abstract: We compare two methodologies for calibrating implied volatility surfaces: a
second-order asymptotic expansion method derived via Malliavin calculus, and a
data-driven approach based on path signatures from rough path theory. The
former, developed in Al\`os et al. (2015), yields efficient and accurate
calibration formulas under the assumption that the asset price follows a
Heston-type stochastic volatility model. The latter models volatility as a
linear functional of the signature of a primary stochastic process, enabling a
flexible approximation without requiring a specific parametric form.
  Our numerical experiments show that the signature-based method achieves
calibration accuracy comparable to the asymptotic approach when the true
dynamics are Heston. We then test the model in a more general setting where the
asset follows a rough Bergomi volatility process-a regime beyond the scope of
the asymptotic expansion-and show that the signature approach continues to
deliver accurate results. These findings highlight the model-independence,
robustness and adaptability of signature-based calibration methods in settings
where volatility exhibits rough or non-Markovian features.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [42] [A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection](https://arxiv.org/abs/2507.22908)
*Abhishek Sawaika,Swetang Krishna,Tushar Tomar,Durga Pritam Suggisetti,Aditi Lal,Tanmaya Shrivastav,Nouhaila Innan,Muhammad Shafique*

Main category: q-fin.CP

TL;DR: 本文提出了一种结合量子增强LSTM和隐私保护技术的联邦学习框架，用于提升金融欺诈检测的准确性和数据安全性。


<details>
  <summary>Details</summary>
Motivation: 随着数字交易的快速增长，传统欺诈检测方法面临挑战，需要更高效且安全的解决方案。

Method: 采用量子增强LSTM模型捕捉复杂交易模式，并引入新型防御方法'FedRansel'抵御投毒和推理攻击。

Result: 相比传统模型，关键评估指标性能提升约5%，模型退化与推理准确率降低4-8%。

Conclusion: 该框架显著提升了欺诈检测精度，同时强化了敏感金融数据的安全性和保密性。

Abstract: Rapid growth of digital transactions has led to a surge in fraudulent
activities, challenging traditional detection methods in the financial sector.
To tackle this problem, we introduce a specialised federated learning framework
that uniquely combines a quantum-enhanced Long Short-Term Memory (LSTM) model
with advanced privacy preserving techniques. By integrating quantum layers into
the LSTM architecture, our approach adeptly captures complex
cross-transactional patters, resulting in an approximate 5% performance
improvement across key evaluation metrics compared to conventional models.
Central to our framework is "FedRansel", a novel method designed to defend
against poisoning and inference attacks, thereby reducing model degradation and
inference accuracy by 4-8%, compared to standard differential privacy
mechanisms. This pseudo-centralised setup with a Quantum LSTM model, enhances
fraud detection accuracy and reinforces the security and confidentiality of
sensitive financial data.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [43] [Fine-Grained Privacy Extraction from Retrieval-Augmented Generation Systems via Knowledge Asymmetry Exploitation](https://arxiv.org/abs/2507.23229)
*Yufei Chen,Yao Wang,Haibin Zhang,Tao Gu*

Main category: cs.CR

TL;DR: 本文提出一种新型黑盒攻击框架，通过知识不对称性实现跨领域细粒度隐私提取，在RAG系统中精准识别敏感信息，同时为自适应防御提供基础。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统的隐私攻击方法存在两大缺陷：无法准确分离知识库来源的句子，且跨领域鲁棒性不足。本文旨在解决这些问题，实现精准隐私提取与防御。

Method: 1) 利用思维链推理构建自适应提示词规避敏感内容 2) 分解对抗性查询以最大化信息差 3) 语义关系评分解决词法/句法歧义 4) 基于特征分数训练神经网络识别隐私句子

Result: 实验显示：单领域隐私提取率达91%，多领域达83%；案例研究中敏感句子暴露减少65%以上，显著优于现有方法。

Conclusion: 该框架填补了RAG系统攻防间的技术空白，首次实现无需预定义知识的跨领域隐私精准提取，同时为动态防御机制奠定理论基础。

Abstract: Retrieval-augmented generation (RAG) systems enhance large language models
(LLMs) by integrating external knowledge bases, but this advancement introduces
significant privacy risks. Existing privacy attacks on RAG systems can trigger
data leakage but often fail to accurately isolate knowledge-base-derived
sentences within mixed responses. They also lack robustness when applied across
multiple domains. This paper addresses these challenges by presenting a novel
black-box attack framework that exploits knowledge asymmetry between RAG and
standard LLMs to achieve fine-grained privacy extraction across heterogeneous
knowledge landscapes. We propose a chain-of-thought reasoning strategy that
creates adaptive prompts to steer RAG systems away from sensitive content.
Specifically, we first decompose adversarial queries to maximize information
disparity and then apply a semantic relationship scoring to resolve lexical and
syntactic ambiguities. We finally train a neural network on these feature
scores to precisely identify sentences containing private information. Unlike
prior work, our framework generalizes to unseen domains through iterative
refinement without pre-defined knowledge. Experimental results show that we
achieve over 91% privacy extraction rate in single-domain and 83% in
multi-domain scenarios, reducing sensitive sentence exposure by over 65% in
case studies. This work bridges the gap between attack and defense in RAG
systems, enabling precise extraction of private information while providing a
foundation for adaptive mitigation.

</details>


### [44] [Counterfactual Evaluation for Blind Attack Detection in LLM-based Evaluation Systems](https://arxiv.org/abs/2507.23453)
*Lijia Liu,Takumi Kondo,Kyohei Atarashi,Koh Takeuchi,Jiyi Li,Shigeru Saito,Hisashi Kashima*

Main category: cs.CR

TL;DR: 本文研究了针对LLM评估系统的提示注入防御方法，提出了一种结合标准评估(SE)与反事实评估(CFE)的框架，有效提升了系统对盲攻击的检测能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)评估系统容易受到独立于真实答案的盲攻击，需要开发有效的防御机制来保障评估可靠性。

Method: 提出SE+CFE框架：在标准评估基础上增加反事实评估，通过验证提交答案在真实和虚构答案下的反应来检测攻击。

Result: 实验表明标准评估极易受攻击，而SE+CFE框架显著提升了攻击检测率(提升幅度未具体说明)，且性能损失最小。

Conclusion: SE+CFE框架通过双重验证机制有效增强了LLM评估系统安全性，为防御提示注入攻击提供了实用解决方案。

Abstract: This paper investigates defenses for LLM-based evaluation systems against
prompt injection. We formalize a class of threats called blind attacks, where a
candidate answer is crafted independently of the true answer to deceive the
evaluator. To counter such attacks, we propose a framework that augments
Standard Evaluation (SE) with Counterfactual Evaluation (CFE), which
re-evaluates the submission against a deliberately false ground-truth answer.
An attack is detected if the system validates an answer under both standard and
counterfactual conditions. Experiments show that while standard evaluation is
highly vulnerable, our SE+CFE framework significantly improves security by
boosting attack detection with minimal performance trade-offs.

</details>


### [45] [LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora](https://arxiv.org/abs/2507.23611)
*Estelle Ruellan,Eric Clay,Nicholas Ascoli*

Main category: cs.CR

TL;DR: 本文提出利用LLMs（如gpt-4o-mini）分析感染截图以提取IoC、追踪攻击活动的新方法，通过Aurora窃密木马案例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前针对窃密日志的被动分析研究存在空白，尤其是感染截图这类关键证据被忽视，亟需自动化工具实现大规模分析。

Method: 采用LLM模型解析1000张Aurora窃密木马感染截图，从中提取URL、文件等IoC，并通过关联分析映射攻击向量和活动。

Result: 从截图中提取出337个可行动URL和246个相关文件，识别出3个独立恶意软件活动，揭示了分发手段和社会工程策略。

Conclusion: 基于感染截图的LLM驱动分析方法为威胁情报提供了可扩展的新范式，实现了从传统日志检测到主动干预的转变。

Abstract: Infostealers exfiltrate credentials, session cookies, and sensitive data from
infected systems. With over 29 million stealer logs reported in 2024, manual
analysis and mitigation at scale are virtually unfeasible/unpractical. While
most research focuses on proactive malware detection, a significant gap remains
in leveraging reactive analysis of stealer logs and their associated artifacts.
Specifically, infection artifacts such as screenshots, image captured at the
point of compromise, are largely overlooked by the current literature. This
paper introduces a novel approach leveraging Large Language Models (LLMs), more
specifically gpt-4o-mini, to analyze infection screenshots to extract potential
Indicators of Compromise (IoCs), map infection vectors, and track campaigns.
Focusing on the Aurora infostealer, we demonstrate how LLMs can process
screenshots to identify infection vectors, such as malicious URLs, installer
files, and exploited software themes. Our method extracted 337 actionable URLs
and 246 relevant files from 1000 screenshots, revealing key malware
distribution methods and social engineering tactics. By correlating extracted
filenames, URLs, and infection themes, we identified three distinct malware
campaigns, demonstrating the potential of LLM-driven analysis for uncovering
infection workflows and enhancing threat intelligence. By shifting malware
analysis from traditional log-based detection methods to a reactive,
artifact-driven approach that leverages infection screenshots, this research
presents a scalable method for identifying infection vectors and enabling early
intervention.

</details>


### [46] [Polynomial Lattices for the BIKE Cryptosystem](https://arxiv.org/abs/2507.23641)
*Michael Schaller*

Main category: cs.CR

TL;DR: 本文研究了BIKE密码系统中基于多项式环的秩2格，提出了一种弱密钥恢复方法，并展示了如何通过求解最短向量问题获得格的一个约化基。


<details>
  <summary>Details</summary>
Motivation: 研究BIKE密码系统中由公钥生成的秩2格的性质，并扩展了现有弱密钥恢复方法，以发现更多潜在的安全漏洞。

Method: 构建了一个多项式环上的秩2格，分析了其结构，并推广了BardetDLO16中的弱密钥恢复方法，通过求解最短向量问题获得格的约化基。

Result: 证明了BardetDLO16的方法隐含解决了所构建格的最短向量问题，并通过约化基进一步检测了更多弱密钥的可能性。

Conclusion: 该方法不仅能够恢复最短向量，还能生成格的约化基，从而更全面地评估BIKE密码系统的密钥安全性。

Abstract: In this paper we introduce a rank $2$ lattice over a polynomial ring arising
from the public key of the BIKE cryptosystem \cite{aragon2022bike}. The secret
key is a sparse vector in this lattice. We study properties of this lattice and
generalize the recovery of weak keys from \cite{BardetDLO16}. In particular, we
show that they implicitly solved a shortest vector problem in the lattice we
constructed. Rather than finding only a shortest vector, we obtain a reduced
basis of the lattice which makes it possible to check for more weak keys.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [47] [Unifying Post-hoc Explanations of Knowledge Graph Completions](https://arxiv.org/abs/2507.22951)
*Alessandro Lonardi,Samy Badreddine,Tarek R. Besold,Pablo Sanchez Martin*

Main category: cs.AI

TL;DR: 本文提出了一种统一的知识图谱补全（KGC）事后解释性方法框架，通过多目标优化平衡解释的有效性与简洁性，并改进了评估协议，强调以终端用户可理解的查询为导向的解释性。


<details>
  <summary>Details</summary>
Motivation: 当前KGC事后解释性研究缺乏形式化定义和一致评估标准，导致可复现性和跨研究比较困难。本文旨在统一方法并改进评估标准，提升该领域研究的可复现性和影响力。

Method: 1. 提出通过多目标优化统一现有KGC事后解释算法的通用框架；2. 使用Mean Reciprocal Rank和Hits@$k$等指标改进评估协议；3. 强调解释应能回答终端用户的实际查询。

Result: 实证研究表明，所提出的框架能有效统一现有解释方法，改进的评估协议（如MRR和Hits@$k$）能更准确衡量解释质量，且用户导向的解释性标准更具实用性。

Conclusion: 通过统一KGC事后解释性方法和完善评估标准，本研究为提升该领域研究的可复现性和实际应用价值提供了系统化解决方案。

Abstract: Post-hoc explainability for Knowledge Graph Completion (KGC) lacks
formalization and consistent evaluations, hindering reproducibility and
cross-study comparisons. This paper argues for a unified approach to post-hoc
explainability in KGC. First, we propose a general framework to characterize
post-hoc explanations via multi-objective optimization, balancing their
effectiveness and conciseness. This unifies existing post-hoc explainability
algorithms in KGC and the explanations they produce. Next, we suggest and
empirically support improved evaluation protocols using popular metrics like
Mean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of
interpretability as the ability of explanations to address queries meaningful
to end-users. By unifying methods and refining evaluation standards, this work
aims to make research in KGC explainability more reproducible and impactful.

</details>


### [48] [Data Readiness for Scientific AI at Scale](https://arxiv.org/abs/2507.23018)
*Wesley Brewer,Patrick Widener,Valentine Anantharaj,Feiyi Wang,Tom Beck,Arjun Shankar,Sarp Oral*

Main category: cs.AI

TL;DR: 本文探讨了AI数据准备(DRAI)原则在领导级科学数据集上的应用，提出了一个针对高性能计算(HPC)环境的两维准备框架，用于指导科学数据向可扩展AI训练的转化。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于分析科学数据在训练基础模型时的准备状态，特别是在气候、核聚变、生物/健康和材料等代表性领域，以识别通用的预处理模式和领域特定约束。

Method: 方法包括引入一个两维准备框架，由数据准备级别(从原始到AI就绪)和数据处理阶段(从接收到分片)组成，两者均针对HPC环境定制，特别关注基于Transformer的生成模型。

Result: 结果是一个概念成熟度矩阵，能够描述科学数据的准备状态，并指导基础设施开发，以实现跨领域的标准化、可扩展和可复现的科学AI支持。

Conclusion: 结论是该框架为科学数据的AI应用提供了清晰的路径，强调了在HPC环境中实现标准化和跨领域支持的重要性，以促进科学AI的可扩展性和复现性。

Abstract: This paper examines how Data Readiness for AI (DRAI) principles apply to
leadership-scale scientific datasets used to train foundation models. We
analyze archetypal workflows across four representative domains - climate,
nuclear fusion, bio/health, and materials - to identify common preprocessing
patterns and domain-specific constraints. We introduce a two-dimensional
readiness framework composed of Data Readiness Levels (raw to AI-ready) and
Data Processing Stages (ingest to shard), both tailored to high performance
computing (HPC) environments. This framework outlines key challenges in
transforming scientific data for scalable AI training, emphasizing
transformer-based generative models. Together, these dimensions form a
conceptual maturity matrix that characterizes scientific data readiness and
guides infrastructure development toward standardized, cross-domain support for
scalable and reproducible AI for science.

</details>


### [49] [FairReason: Balancing Reasoning and Social Bias in MLLMs](https://arxiv.org/abs/2507.23067)
*Zhenyu Pan,Yutong Zhang,Jianshu Zhang,Haoran Lu,Haozheng Luo,Yuwei Han,Philip S. Yu,Manling Li,Han Liu*

Main category: cs.AI

TL;DR: 多模态大语言模型（MLLMs）在提升推理能力的同时，其输出常伴随明显的社会偏见。本研究通过对比三种去偏策略，发现强化学习结合1:4的去偏与推理样本比例能在保留88%推理准确率的同时降低10%的刻板印象分数。


<details>
  <summary>Details</summary>
Motivation: 尽管现有技术提升了MLLMs的逻辑准确性，但模型输出仍存在显著的社会偏见。研究旨在揭示推理能力提升与偏见缓解之间的相互作用，并探索两者是否存在固有权衡。

Method: 研究首先在相同条件下评估了三种去偏策略：监督微调（SFT）、知识蒸馏（KD）和基于规则的强化学习（RL）。随后调整各策略中去偏样本与推理样本的比例，绘制推理与偏见的权衡曲线。

Result: 实验发现强化学习结合1:4的去偏与推理样本比例是最佳平衡点，能降低10%的刻板印象分数，同时保留模型原始推理准确率的88%。

Conclusion: 研究为平衡MLLMs的公平性与能力提供了具体指导，表明通过适当比例的样本混合和强化学习训练，可有效兼顾推理性能与偏见缓解。

Abstract: Multimodal Large Language Models (MLLMs) already achieve state-of-the-art
results across a wide range of tasks and modalities. To push their reasoning
ability further, recent studies explore advanced prompting schemes and
post-training fine-tuning. Although these techniques improve logical accuracy,
they frequently leave the models' outputs burdened with pronounced social
biases. Clarifying how reasoning gains interact with bias mitigation-and
whether the two objectives inherently trade off-therefore remains an open and
pressing research problem. Our study begins by benchmarking three
bias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation
(KD), and rule-based reinforcement learning (RL)-under identical conditions,
establishing their baseline strengths and weaknesses. Building on these
results, we vary the proportion of debias-focused and reasoning-centric samples
within each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps
reveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement
learning cuts stereotype scores by 10% while retaining 88% of the model's
original reasoning accuracy, offering concrete guidance for balancing fairness
and capability in MLLMs.

</details>


### [50] [Moravec's Paradox: Towards an Auditory Turing Test](https://arxiv.org/abs/2507.23091)
*David Noever,Forrest McKee*

Main category: cs.AI

TL;DR: 当前AI系统在人类轻松完成的听觉任务上表现糟糕，失败率超过93%。研究通过917项听觉挑战测试，揭示AI在选择性注意力、噪声鲁棒性和上下文适应方面的缺陷，呼吁整合选择性注意力、基于物理的音频理解和情境感知的新方法。


<details>
  <summary>Details</summary>
Motivation: 受Moravec悖论启发（即人类简单的任务对机器困难，反之亦然），研究旨在量化AI与人类在听觉任务上的差距，并探究失败原因。

Method: 设计了包含7类（如重叠语音、噪声中语音等）917项挑战的听觉图灵测试，评估了GPT-4音频能力和Whisper等先进模型。

Result: 最佳模型准确率仅6.9%，远低于人类的52%（7.5倍差距），暴露了AI在复杂听觉场景处理中的选择性注意力、噪声鲁棒性和上下文适应缺陷。

Conclusion: 研究建立了衡量机器听觉进步的诊断框架，指出需整合选择性注意力、物理音频理解和情境感知的新架构，以缩小人机听觉差距。

Abstract: This research work demonstrates that current AI systems fail catastrophically
on auditory tasks that humans perform effortlessly. Drawing inspiration from
Moravec's paradox (i.e., tasks simple for humans often prove difficult for
machines, and vice versa), we introduce an auditory Turing test comprising 917
challenges across seven categories: overlapping speech, speech in noise,
temporal distortion, spatial audio, coffee-shop noise, phone distortion, and
perceptual illusions. Our evaluation of state-of-the-art audio models including
GPT-4's audio capabilities and OpenAI's Whisper reveals a striking failure rate
exceeding 93%, with even the best-performing model achieving only 6.9% accuracy
on tasks that humans solved at 7.5 times higher success (52%). These results
expose focusing failures in how AI systems process complex auditory scenes,
particularly in selective attention, noise robustness, and contextual
adaptation. Our benchmark not only quantifies the human-machine auditory gap
but also provides insights into why these failures occur, suggesting that
current architectures lack fundamental mechanisms for human-like auditory scene
analysis. The traditional design of audio CAPTCHAs highlights common filters
that humans evolved but machines fail to select in multimodal language models.
This work establishes a diagnostic framework for measuring progress toward
human-level machine listening and highlights the need for novel approaches
integrating selective attention, physics-based audio understanding, and
context-aware perception into multimodal AI systems.

</details>


### [51] [Argumentatively Coherent Judgmental Forecasting](https://arxiv.org/abs/2507.23163)
*Deniz Gorur,Antonio Rago,Francesca Toni*

Main category: cs.AI

TL;DR: 本文提出并形式化定义了判断性预测中的\"论证一致性\"属性，通过三项评估验证其价值：过滤不一致预测可提升人类及LLM预测准确率，但用户实验显示人们普遍未遵循该属性，表明需在群体预测前整合过滤机制。


<details>
  <summary>Details</summary>
Motivation: 研究论证结构对判断性预测的影响，提出\"论证一致性\"概念，旨在确保预测者的推理与预测结果逻辑自洽，弥补传统定量预测的局限性。

Method: 1. 形式化定义论证一致性；2. 评估强制一致性对人类和LLM预测准确率的影响；3. 通过众包实验检验用户对该属性的实际遵循程度。

Result: 过滤不一致预测使人类和LLM准确率均提升（LLM表现媲美人类），但用户实验揭示多数人未自然遵循一致性，凸显群体预测中主动过滤机制的必要性。

Conclusion: 论证一致性是提升判断性预测质量的有效标准，需将其作为前置过滤条件整合至基于论证的群体预测框架中。

Abstract: Judgmental forecasting employs human opinions to make predictions about
future events, rather than exclusively historical data as in quantitative
forecasting. When these opinions form an argumentative structure around
forecasts, it is useful to study the properties of the forecasts from an
argumentative perspective. In this paper, we advocate and formally define a
property of argumentative coherence, which, in essence, requires that a
forecaster's reasoning is coherent with their forecast. We then conduct three
evaluations with our notion of coherence. First, we assess the impact of
enforcing coherence on human forecasters as well as on Large Language Model
(LLM)-based forecasters, given that they have recently shown to be competitive
with human forecasters. In both cases, we show that filtering out incoherent
predictions improves forecasting accuracy consistently, supporting the
practical value of coherence in both human and LLM-based forecasting. Then, via
crowd-sourced user experiments, we show that, despite its apparent
intuitiveness and usefulness, users do not generally align with this coherence
property. This points to the need to integrate, within argumentation-based
judgmental forecasting, mechanisms to filter out incoherent opinions before
obtaining group forecasting predictions.

</details>


### [52] [Tractable Responsibility Measures for Ontology-Mediated Query Answering](https://arxiv.org/abs/2507.23191)
*Meghyn Bienvenu,Diego Figueira,Pierre Lafourcade*

Main category: cs.AI

TL;DR: 本文研究了基于Shapley值的责任度量WSMS在ontology-mediated查询回答中的计算复杂度，揭示了其在特定查询类别下的可处理性边界。


<details>
  <summary>Details</summary>
Motivation: 量化查询答案中各事实的责任贡献是解释性数据分析的关键问题，但现有方法在ontology-mediated查询场景下的复杂度尚不明确。

Method: 通过借鉴数据库领域的成果，分析WSMS度量在可一阶重写查询类别中的计算复杂度，并探索本体语言表达能力对复杂度的影响。

Result: 证明对于可一阶重写查询，WSMS具有多项式数据复杂度；但当本体语言支持$\exists R.A \sqsubseteq A$等公理时，问题变为shP-难。同时发现即使无本体，特定结构受限的联合查询仍保持可处理性。

Conclusion: 研究确定了DL-Lite方言中结构受限的联合查询类可实现高效WSMS计算，为实际应用提供了理论指导。

Abstract: Recent work on quantitative approaches to explaining query answers employs
responsibility measures to assign scores to facts in order to quantify their
respective contributions to obtaining a given answer. In this paper, we study
the complexity of computing such responsibility scores in the setting of
ontology-mediated query answering, focusing on a very recently introduced
family of Shapley-value-based responsibility measures defined in terms of
weighted sums of minimal supports (WSMS). By exploiting results from the
database setting, we can show that such measures enjoy polynomial data
complexity for classes of ontology-mediated queries that are
first-order-rewritable, whereas the problem becomes "shP"-hard when the
ontology language can encode reachability queries (via axioms like $\exists R.
A \sqsubseteq A$). To better understand the tractability frontier, we next
explore the combined complexity of WSMS computation. We prove that
intractability applies already to atomic queries if the ontology language
supports conjunction, as well as to unions of `well-behaved' conjunctive
queries, even in the absence of an ontology. By contrast, our study yields
positive results for common DL-Lite dialects: by means of careful analysis, we
identify classes of structurally restricted conjunctive queries (which
intuitively disallow undesirable interactions between query atoms) that admit
tractable WSMS computation.

</details>


### [53] [Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification](https://arxiv.org/abs/2507.23197)
*Yuke Liao,Blaise Genest,Kuldeep Meel,Shaan Aryaman*

Main category: cs.AI

TL;DR: 论文提出了一种新型的解决方案感知ReLU评分方法（SAS），通过分而治之策略优化混合MILP验证器，显著减少二进制变量数量并保持高准确率。


<details>
  <summary>Details</summary>
Motivation: 针对复杂实例验证效率低下的问题，研究旨在通过优化ReLU变量选择策略，减少计算成本并提升验证效率。

Method: 采用分而治之策略，结合解决方案感知ReLU评分（SAS）及改进的BaB-SR/BaB-FSB分支函数，优先处理关键ReLU变量；并设计混合MILP流程，先调用$\alpha,\beta$-CROWN快速解决简单实例，再使用部分MILP处理剩余问题。

Result: SAS方法将二进制变量数量减少约6倍，准确率不变；混合验证器将未决实例比例降至8-15%，平均单实例运行时间为46-417秒，适用于200万参数的大型CNN。

Conclusion: SAS评分与混合MILP框架显著提升了验证效率，在保持精度的同时大幅降低计算资源消耗，为大规模神经网络验证提供了实用解决方案。

Abstract: To handle complex instances, we revisit a divide-and-conquer approach to
break down the complexity: instead of few complex BaB calls, we rely on many
small {\em partial} MILP calls. The crucial step is to select very few but very
important ReLUs to treat using (costly) binary variables. The previous attempts
were suboptimal in that respect. To select these important ReLU variables, we
propose a novel {\em solution-aware} ReLU scoring ({\sf SAS}), as well as adapt
the BaB-SR and BaB-FSB branching functions as {\em global} ReLU scoring ({\sf
GS}) functions. We compare them theoretically as well as experimentally, and
{\sf SAS} is more efficient at selecting a set of variables to open using
binary variables. Compared with previous attempts, SAS reduces the number of
binary variables by around 6 times, while maintaining the same level of
accuracy. Implemented in {\em Hybrid MILP}, calling first $\alpha,\beta$-CROWN
with a short time-out to solve easier instances, and then partial MILP,
produces a very accurate yet efficient verifier, reducing by up to $40\%$ the
number of undecided instances to low levels ($8-15\%$), while keeping a
reasonable runtime ($46s-417s$ on average per instance), even for fairly large
CNNs with 2 million parameters.

</details>


### [54] [How Far Are AI Scientists from Changing the World?](https://arxiv.org/abs/2507.23276)
*Qiujie Xie,Yixuan Weng,Minjun Zhu,Fuchen Shen,Shulin Huang,Zhen Lin,Jiahui Zhou,Zilan Mao,Zijie Yang,Linyi Yang,Jian Wu,Yue Zhang*

Main category: cs.AI

TL;DR: 本文综述了基于大语言模型(LLM)的AI科学家系统如何推动自动化科学发现，探讨其当前成就、关键瓶颈及未来发展目标。


<details>
  <summary>Details</summary>
Motivation: 随着LLM推动AI科学家系统在科研领域取得突破性进展（如ICLR 2025接受AI生成论文），亟需评估该系统重塑科研范式的潜力与现存差距。

Method: 采用前瞻性综述方法，系统分析现有AI科学家系统的核心组件、关键瓶颈及实现突破性发现所需的要素。

Result: 当前系统已能生成人类未知现象的研究成果，但解决重大科学挑战仍需突破代理能力、知识整合等核心瓶颈。

Conclusion: 本综述明晰了AI科学家系统的局限与发展路径，为构建能解决重大科学问题的终极科学AI指明方向。

Abstract: The emergence of large language models (LLMs) is propelling automated
scientific discovery to the next level, with LLM-based Artificial Intelligence
(AI) Scientist systems now taking the lead in scientific research. Several
influential works have already appeared in the field of AI Scientist systems,
with AI-generated research papers having been accepted at the ICLR 2025
workshop, suggesting that a human-level AI Scientist capable of uncovering
phenomena previously unknown to humans, may soon become a reality. In this
survey, we focus on the central question: How far are AI scientists from
changing the world and reshaping the scientific research paradigm? To answer
this question, we provide a prospect-driven review that comprehensively
analyzes the current achievements of AI Scientist systems, identifying key
bottlenecks and the critical components required for the emergence of a
scientific agent capable of producing ground-breaking discoveries that solve
grand challenges. We hope this survey will contribute to a clearer
understanding of limitations of current AI Scientist systems, showing where we
are, what is missing, and what the ultimate goals for scientific AI should be.

</details>


### [55] [AI Must not be Fully Autonomous](https://arxiv.org/abs/2507.23330)
*Tosin Adewumi,Lama Alkhaled,Florent Imbert,Hui Han,Nudrat Habib,Karl Löwenmark*

Main category: cs.AI

TL;DR: 本文探讨了自主人工智能（AI）的三个等级，主张AI不应完全自主以避免风险，特别是在人工超级智能（ASI）可能几十年内出现的背景下。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于识别自主AI的风险，并强调在ASI可能快速发展的背景下，人类监督的重要性。

Method: 方法包括讨论自主性、AI和代理理论，提出12个论点、6个反驳及反驳的回应，并在附录中提供15个AI价值错位及其他风险的证据。

Result: 研究结果表明，完全自主的AI（第三等级）若无人类监督将带来重大风险，而负责任的监督是减轻这些风险的关键。

Conclusion: 结论强调AI不应完全自主，特别是在ASI可能出现的未来，人类监督对于确保AI的安全和道德使用至关重要。

Abstract: Autonomous Artificial Intelligence (AI) has many benefits. It also has many
risks. In this work, we identify the 3 levels of autonomous AI. We are of the
position that AI must not be fully autonomous because of the many risks,
especially as artificial superintelligence (ASI) is speculated to be just
decades away. Fully autonomous AI, which can develop its own objectives, is at
level 3 and without responsible human oversight. However, responsible human
oversight is crucial for mitigating the risks. To ague for our position, we
discuss theories of autonomy, AI and agents. Then, we offer 12 distinct
arguments and 6 counterarguments with rebuttals to the counterarguments. We
also present 15 pieces of recent evidence of AI misaligned values and other
risks in the appendix.

</details>


### [56] [DSBC : Data Science task Benchmarking with Context engineering](https://arxiv.org/abs/2507.23336)
*Ram Mohan Rao Kadiyala,Siddhant Gupta,Jebish Purbey,Giulio Martini,Suman Debnath,Hamza Farooq*

Main category: cs.AI

TL;DR: 本文提出一个针对数据科学代理的综合性基准测试，评估了三种大型语言模型在不同方法下的表现，揭示了模型间的性能差异及影响实际部署的关键因素。


<details>
  <summary>Details</summary>
Motivation: 尽管数据科学代理在自动化分析任务中迅速普及，但缺乏系统性评估其效能与局限的基准测试。本研究旨在填补这一空白，通过真实用户交互数据构建评估框架。

Method: 研究评估了Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini三种模型，采用零样本上下文工程、多步上下文工程及SmolAgent三种方法，覆盖八类数据科学任务，并测试模型对数据泄漏和模糊指令等常见提示问题的敏感性。

Result: 结果显示不同模型与方法间存在显著性能差异，温度参数对整体及特定任务结果具有影响，为实际部署提供了关键参考依据。

Conclusion: 本研究提出的基准数据集与评估框架为未来开发更鲁棒高效的数据科学代理奠定了基础，强调了模型选择与方法优化在实际应用中的重要性。

Abstract: Recent advances in large language models (LLMs) have significantly impacted
data science workflows, giving rise to specialized data science agents designed
to automate analytical tasks. Despite rapid adoption, systematic benchmarks
evaluating the efficacy and limitations of these agents remain scarce. In this
paper, we introduce a comprehensive benchmark specifically crafted to reflect
real-world user interactions with data science agents by observing usage of our
commercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,
Gemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with
context engineering, multi-step with context engineering, and with SmolAgent.
Our benchmark assesses performance across a diverse set of eight data science
task categories, additionally exploring the sensitivity of models to common
prompting issues, such as data leakage and slightly ambiguous instructions. We
further investigate the influence of temperature parameters on overall and
task-specific outcomes for each model and approach. Our findings reveal
distinct performance disparities among the evaluated models and methodologies,
highlighting critical factors that affect practical deployment. The benchmark
dataset and evaluation framework introduced herein aim to provide a foundation
for future research of more robust and effective data science agents.

</details>


### [57] [LLM4Rail: An LLM-Augmented Railway Service Consulting Platform](https://arxiv.org/abs/2507.23377)
*Zhuo Li,Xianghuai Deng,Chiwei Feng,Hanmeng Li,Shenjie Wang,Haichao Zhang,Teng Jia,Conlin Chen,Louis Linchun Wu,Jia Wang*

Main category: cs.AI

TL;DR: 本文提出了LLM4Rail平台，这是一个基于大语言模型（LLM）的铁路服务咨询系统，通过创新的QTAO提示框架和CRFD-25数据集，提供个性化铁路餐饮推荐等服务。


<details>
  <summary>Details</summary>
Motivation: 为满足日益增长的个性化铁路服务需求，开发了LLM4Rail平台，旨在利用LLM技术提升铁路服务的智能化与个性化水平。

Method: 采用迭代的“问题-思考-行动-观察（QTAO）”提示框架，结合语言推理与任务导向行动；构建了CRFD-25铁路餐饮数据集，并引入基于特征相似度的后处理步骤以确保推荐准确性。

Result: LLM4Rail能够提供定制化的票务、餐饮推荐、天气信息及闲聊服务；CRFD-25数据集覆盖多维度分类的餐饮数据，零样本对话推荐系统有效解决了开放推荐中的约束问题。

Conclusion: LLM4Rail通过QTAO框架和CRFD-25数据集，显著提升了铁路服务的个性化和智能化水平，为未来铁路服务创新提供了可行方案。

Abstract: Large language models (LLMs) have significantly reshaped different walks of
business. To meet the increasing demands for individualized railway service, we
develop LLM4Rail - a novel LLM-augmented railway service consulting platform.
Empowered by LLM, LLM4Rail can provide custom modules for ticketing, railway
food & drink recommendations, weather information, and chitchat. In LLM4Rail,
we propose the iterative "Question-Thought-Action-Observation (QTAO)" prompting
framework. It meticulously integrates verbal reasoning with task-oriented
actions, that is, reasoning to guide action selection, to effectively retrieve
external observations relevant to railway operation and service to generate
accurate responses. To provide personalized onboard dining services, we first
construct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible
takeout dataset tailored for railway services. CRFD-25 covers a wide range of
signature dishes categorized by cities, cuisines, age groups, and spiciness
levels. We further introduce an LLM-based zero-shot conversational recommender
for railway catering. To address the unconstrained nature of open
recommendations, the feature similarity-based post-processing step is
introduced to ensure all the recommended items are aligned with CRFD-25
dataset.

</details>


### [58] [Chatting with your ERP: A Recipe](https://arxiv.org/abs/2507.23429)
*Jorge Ruiz Gómez,Lidia Andrés Susinos,Jorge Alamo Olivé,Sonia Rey Osorno,Manuel Luis Gonzalez Hernández*

Main category: cs.AI

TL;DR: 本文介绍了一种基于大型语言模型（LLM）的智能代理，能够通过自然语言查询与工业级ERP系统交互，并生成可执行的SQL语句。


<details>
  <summary>Details</summary>
Motivation: 旨在解决工业ERP系统中自然语言查询的自动化处理问题，提升人机交互效率。

Method: 采用双代理架构（推理+校验阶段），利用开源权重LLM实现自然语言到SQL的可靠转换。

Result: 提出的新型架构显著提高了查询生成的准确性，验证了方法的可行性。

Conclusion: 该LLM代理为工业ERP系统提供了高效的自然语言接口，双代理设计是提升可靠性的有效方案。

Abstract: This paper presents the design, implementation, and evaluation behind a Large
Language Model (LLM) agent that chats with an industrial production-grade ERP
system. The agent is capable of interpreting natural language queries and
translating them into executable SQL statements, leveraging open-weight LLMs. A
novel dual-agent architecture combining reasoning and critique stages was
proposed to improve query generation reliability.

</details>


### [59] [Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation](https://arxiv.org/abs/2507.23440)
*Mingzhe Li,Xin Lu,Yanyan Zhao*

Main category: cs.AI

TL;DR: 提出Self-Foveate方法，通过多级聚焦技术增强LLM从无监督文本中合成指令的多样性与难度。


<details>
  <summary>Details</summary>
Motivation: 现有自动化指令合成方法在数据多样性与难度控制上存在不足，需减少人工标注依赖并提升合成质量。

Method: 采用"微观-散射-宏观"多级聚焦方法，引导LLM深度挖掘无监督文本中的细粒度信息。

Result: 跨多无监督语料库与模型架构的实验验证了该方法在提升指令多样性与难度上的有效性。

Conclusion: Self-Foveate为LLM指令合成提供了创新解决方案，相关数据与代码已开源。

Abstract: Large language models (LLMs) with instruction following capabilities have
demonstrated impressive problem-solving abilities. While synthesizing
instructional data from unsupervised text has become a common approach for
training such models, conventional methods rely heavily on human effort for
data annotation. Although existing automated synthesis paradigms have
alleviated this constraint, they still exhibit significant limitations in
ensuring adequate diversity and difficulty of synthesized instructions. To
address these challenges, we propose Self-Foveate, an innovative LLM-driven
method for instruction synthesis. This approach introduces a
"Micro-Scatter-Macro" multi-level foveation methodology that effectively guides
the LLM to deeply excavate fine-grained information embedded in unsupervised
text, thereby enhancing both the diversity and difficulty of synthesized
instructions. Comprehensive experiments across multiple unsupervised corpora
and diverse model architectures validate the effectiveness and superiority of
our proposed method. We publicly release our data and codes:
https://github.com/Mubuky/Self-Foveate

</details>


### [60] [Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery](https://arxiv.org/abs/2507.23488)
*Kacper Kadziolka,Saber Salehkaleybar*

Main category: cs.AI

TL;DR: 研究发现，采用推理优先架构的大语言模型在因果发现任务上表现显著优于传统方法，结合模块化上下文管道可进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 因果推断是大语言模型面临的核心挑战，传统模型在数据扰动下易过拟合且表现接近随机水平，因此探索推理优先模型在因果发现中的潜力。

Method: 基于Corr2Cause基准测试，采用OpenAI的o系列和DeepSeek-R模型家族，并设计受思维树和思维链启发的模块化上下文管道。

Result: 推理优先架构模型展现出显著优势，结合新管道后性能提升近三倍；通过分析推理链长度和复杂度，验证了该框架的有效性。

Conclusion: 先进推理模型代表重大突破，但需结合结构化上下文框架才能最大化其潜力，该研究为跨领域因果发现提供了通用蓝图。

Abstract: Causal inference remains a fundamental challenge for large language models.
Recent advances in internal reasoning with large language models have sparked
interest in whether state-of-the-art reasoning models can robustly perform
causal discovery-a task where conventional models often suffer from severe
overfitting and near-random performance under data perturbations. We study
causal discovery on the Corr2Cause benchmark using the emergent OpenAI's
o-series and DeepSeek-R model families and find that these reasoning-first
architectures achieve significantly greater native gains than prior approaches.
To capitalize on these strengths, we introduce a modular in-context pipeline
inspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding
nearly three-fold improvements over conventional baselines. We further probe
the pipeline's impact by analyzing reasoning chain length, complexity, and
conducting qualitative and quantitative comparisons between conventional and
reasoning models. Our findings suggest that while advanced reasoning models
represent a substantial leap forward, carefully structured in-context
frameworks are essential to maximize their capabilities and offer a
generalizable blueprint for causal discovery across diverse domains.

</details>


### [61] [Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification](https://arxiv.org/abs/2507.23497)
*David A Kelly,Hana Chockler*

Main category: cs.AI

TL;DR: 本文提出了一种基于因果关系的图像分类器解释方法，具有形式化严谨性，适用于黑盒算法，并通过实验验证了其高效性和普适性。


<details>
  <summary>Details</summary>
Motivation: 现有图像分类器解释方法缺乏形式化严谨性，而基于逻辑的解释方法虽严谨但假设条件过于严格。本文旨在提出一种兼具严谨性和实用性的解释方法。

Method: 引入因果解释和对比性因果解释，增强解释的可信度意识，并提出完全因果解释。方法无需模型内部信息，完全黑盒操作。

Result: 实验表明，不同模型在充分性、对比性和完整性方面表现各异。算法平均每张图像仅需6秒，高效且普适。

Conclusion: 因果解释方法在保持形式化严谨的同时，适用于图像分类器，且计算高效，为黑盒模型解释提供了新思路。

Abstract: Existing algorithms for explaining the outputs of image classifiers are based
on a variety of approaches and produce explanations that lack formal rigor. On
the other hand, logic-based explanations are formally and rigorously defined
but their computability relies on strict assumptions about the model that do
not hold on image classifiers.
  In this paper, we show that causal explanations, in addition to being
formally and rigorously defined, enjoy the same formal properties as
logic-based ones, while still lending themselves to black-box algorithms and
being a natural fit for image classifiers. We prove formal properties of causal
explanations and introduce contrastive causal explanations for image
classifiers. Moreover, we augment the definition of explanation with confidence
awareness and introduce complete causal explanations: explanations that are
classified with exactly the same confidence as the original image.
  We implement our definitions, and our experimental results demonstrate that
different models have different patterns of sufficiency, contrastiveness, and
completeness. Our algorithms are efficiently computable, taking on average 6s
per image on a ResNet50 model to compute all types of explanations, and are
totally black-box, needing no knowledge of the model, no access to model
internals, no access to gradient, nor requiring any properties, such as
monotonicity, of the model.

</details>


### [62] [DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer](https://arxiv.org/abs/2507.23554)
*Ruoyu Wang,Junda Wu,Yu Xia,Tong Yu,Ryan A. Rossi,Julian McAuley,Lina Yao*

Main category: cs.AI

TL;DR: 本文提出DICE框架，通过动态选择上下文示例提升大语言模型代理在推理任务中的性能，解决了现有方法依赖启发式规则且缺乏理论依据的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于上下文学习的代理模型对示例选择极为敏感，次优示例会导致性能不稳定或下降，而现有方法缺乏普适且理论化的示例选择标准。

Method: DICE框架通过因果视角将示例知识分解为可迁移和不可迁移成分，提出具有性能提升理论保证的逐步选择标准，可作为即插即用模块集成到现有代理框架。

Result: 跨领域实验表明DICE能显著提升代理模型的鲁棒性和效率，验证了基于理论的上下文感知示例选择的重要性。

Conclusion: 该研究为代理系统的示例选择提供了理论化、通用化的解决方案，动态上下文示例选择是实现高效稳健大语言模型代理的关键机制。

Abstract: Large language model-based agents, empowered by in-context learning (ICL),
have demonstrated strong capabilities in complex reasoning and tool-use tasks.
However, existing works have shown that the effectiveness of ICL is highly
sensitive to the choice of demonstrations, with suboptimal examples often
leading to unstable or degraded performance. While prior work has explored
example selection, including in some agentic or multi-step settings, existing
approaches typically rely on heuristics or task-specific designs and lack a
general, theoretically grounded criterion for what constitutes an effective
demonstration across reasoning steps. Therefore, it is non-trivial to develop a
principled, general-purpose method for selecting demonstrations that
consistently benefit agent performance. In this paper, we address this
challenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a
theoretically grounded ICL framework for agentic tasks that selects the most
relevant demonstrations at each step of reasoning. Our approach decomposes
demonstration knowledge into transferable and non-transferable components
through a causal lens, showing how the latter can introduce spurious
dependencies that impair generalization. We further propose a stepwise
selection criterion with a formal guarantee of improved agent performance.
Importantly, DICE is a general, framework-agnostic solution that can be
integrated as a plug-in module into existing agentic frameworks without any
additional training cost. Extensive experiments across diverse domains
demonstrate our method's effectiveness and generality, highlighting the
importance of principled, context-aware demo selection for robust and efficient
LLM agents.

</details>


### [63] [Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI](https://arxiv.org/abs/2507.23565)
*Botao Zhu,Xianbin Wang,Dusit Niyato*

Main category: cs.AI

TL;DR: 本文提出一种基于语义信任链的自主信任编排方法，利用智能代理与超图技术，在设备空闲期进行高效信任评估，实现分布式资源优化利用。


<details>
  <summary>Details</summary>
Motivation: 分布式协作系统中，任务复杂性、设备资源动态性及评估开销导致信任评估效率低下，影响协作任务执行。

Method: 采用智能代理感知设备状态，结合历史数据在空闲期进行信任评估；通过超图嵌入信任语义实现分层管理，并构建多设备信任链支持大规模协作。

Result: 实验表明该方法显著降低资源消耗，实现高效信任评估。

Conclusion: 语义信任链与智能代理的结合有效平衡评估开销与准确性，为大规模分布式协作提供新范式。

Abstract: In collaborative systems, the effective completion of tasks hinges on
task-specific trust evaluations of potential devices for distributed
collaboration. However, the complexity of tasks, the spatiotemporal dynamism of
distributed device resources, and the inevitable assessment overhead
dramatically increase the complexity and resource consumption of the trust
evaluation process. As a result, ill-timed or overly frequent trust evaluations
can reduce utilization rate of constrained resources, negatively affecting
collaborative task execution. To address this challenge, this paper proposes an
autonomous trust orchestration method based on a new concept of semantic
chain-of-trust. Our technique employs agentic AI and hypergraph to establish
and maintain trust relationships among devices. By leveraging its strengths in
autonomous perception, task decomposition, and semantic reasoning, we propose
agentic AI to perceive device states and autonomously perform trust evaluations
of collaborators based on historical performance data only during device idle
periods, thereby enabling efficient utilization of distributed resources. In
addition, agentic AI performs task-specific trust evaluations on collaborator
resources by analyzing the alignment between resource capabilities and task
requirements. Moreover, by maintaining a trust hypergraph embedded with trust
semantics for each device, agentic AI enables hierarchical management of
collaborators and identifies collaborators requiring trust evaluation based on
trust semantics, thereby achieving a balance between overhead and trust
accuracy. Furthermore, local trust hypergraphs from multiple devices can be
chained together to support multi-hop collaboration, enabling efficient
coordination in large-scale systems. Experimental results demonstrate that the
proposed method achieves resource-efficient trust evaluation.

</details>


### [64] [MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying](https://arxiv.org/abs/2507.23633)
*Qian Zhao,Zhuo Sun,Bin Guo,Zhiwen Yu*

Main category: cs.AI

TL;DR: 本文提出了一种策略引导的智能体辅助记忆回忆方法，通过设计5W回忆地图和分层回忆树优化策略选择，开发出MemoCue智能体，在三个数据集上表现优于现有方法17.74%。


<details>
  <summary>Details</summary>
Motivation: 传统智能体辅助记忆回忆受限于内存模块容量，无法获取完整记忆。受记忆理论启发，作者提出通过有效线索主动激活相关记忆，提升回忆效果。

Method: 提出Recall Router框架：1) 设计5W回忆地图将查询分类到5种典型场景；2) 构建分层回忆树结合蒙特卡洛树搜索优化策略选择；3) 微调开源大语言模型开发MemoCue智能体。

Result: 在三个代表性数据集上，MemoCue在回忆启发方面超越基于LLM的方法17.74%。人工评估进一步验证了其在记忆回忆应用中的优势。

Conclusion: 策略引导的智能体辅助记忆回忆方法通过系统化策略设计和响应生成优化，显著提升了记忆回忆效果，为人类记忆辅助提供了新思路。

Abstract: Agent-assisted memory recall is one critical research problem in the field of
human-computer interaction. In conventional methods, the agent can retrieve
information from its equipped memory module to help the person recall
incomplete or vague memories. The limited size of memory module hinders the
acquisition of complete memories and impacts the memory recall performance in
practice. Memory theories suggest that the person's relevant memory can be
proactively activated through some effective cues. Inspired by this, we propose
a novel strategy-guided agent-assisted memory recall method, allowing the agent
to transform an original query into a cue-rich one via the judiciously designed
strategy to help the person recall memories. To this end, there are two key
challenges. (1) How to choose the appropriate recall strategy for diverse
forgetting scenarios with distinct memory-recall characteristics? (2) How to
obtain the high-quality responses leveraging recall strategies, given only
abstract and sparsely annotated strategy patterns? To address the challenges,
we propose a Recall Router framework. Specifically, we design a 5W Recall Map
to classify memory queries into five typical scenarios and define fifteen
recall strategy patterns across the corresponding scenarios. We then propose a
hierarchical recall tree combined with the Monte Carlo Tree Search algorithm to
optimize the selection of strategy and the generation of strategy responses. We
construct an instruction tuning dataset and fine-tune multiple open-source
large language models (LLMs) to develop MemoCue, an agent that excels in
providing memory-inspired responses. Experiments on three representative
datasets show that MemoCue surpasses LLM-based methods by 17.74% in recall
inspiration. Further human evaluation highlights its advantages in
memory-recall applications.

</details>


### [65] [Personalized Education with Ranking Alignment Recommendation](https://arxiv.org/abs/2507.23664)
*Haipeng Liu,Yuxuan Liu,Ting Long*

Main category: cs.AI

TL;DR: 本文提出了一种名为RAR的个性化问题推荐方法，通过将协作思想融入探索机制，有效提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化问题推荐方法大多采用强化学习，但在训练过程中难以高效探索，无法为每位学生找到最佳问题。

Method: 提出了Ranking Alignment Recommendation (RAR)方法，将协作思想整合到探索机制中，从而在有限的训练周期内实现更高效的探索。

Result: 实验表明，RAR显著提高了推荐性能，且该框架可应用于任何基于强化学习的问题推荐系统。

Conclusion: RAR通过改进探索机制，有效提升了个性化问题推荐的性能，具有广泛的适用性。代码已开源：https://github.com/wuming29/RAR.git。

Abstract: Personalized question recommendation aims to guide individual students
through questions to enhance their mastery of learning targets. Most previous
methods model this task as a Markov Decision Process and use reinforcement
learning to solve, but they struggle with efficient exploration, failing to
identify the best questions for each student during training. To address this,
we propose Ranking Alignment Recommendation (RAR), which incorporates
collaborative ideas into the exploration mechanism, enabling more efficient
exploration within limited training episodes. Experiments show that RAR
effectively improves recommendation performance, and our framework can be
applied to any RL-based question recommender. Our code is available in
https://github.com/wuming29/RAR.git.

</details>


### [66] [TextQuests: How Good are LLMs at Text-Based Video Games?](https://arxiv.org/abs/2507.23701)
*Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks*

Main category: cs.AI

TL;DR: 论文提出TextQuests基准，基于Infocom互动小说游戏，用于评估AI代理在探索性环境中长期自主推理的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能充分评估AI代理在需要长期自主推理的探索性环境中的表现，因此需要新基准来促进更鲁棒的内在推理能力发展。

Method: 采用Infocom文本冒险游戏作为基准，禁止使用外部工具，专注于评估代理在单次交互会话中的长期上下文推理和试错学习能力。

Result: 发布TextQuests基准（https://textquests.ai），该基准能有效评估AI代理在状态化任务中的自主问题解决能力。

Conclusion: TextQuests为评估AI代理在复杂探索环境中的长期自主推理能力提供了有效工具，填补了现有基准的不足。

Abstract: Evaluating AI agents within complex, interactive environments that mirror
real-world challenges is critical for understanding their practical
capabilities. While existing agent benchmarks effectively assess skills like
tool use or performance on structured tasks, they often do not fully capture an
agent's ability to operate autonomously in exploratory environments that demand
sustained, self-directed reasoning over a long and growing context. To spur the
development of agents capable of more robust intrinsic reasoning over long
horizons, we introduce TextQuests, a benchmark based on the Infocom suite of
interactive fiction games. These text-based adventures, which can take human
players over 30 hours and require hundreds of precise actions to solve, serve
as an effective proxy for evaluating AI agents on focused, stateful tasks. The
benchmark is specifically designed to assess an LLM agent's capacity for
self-contained problem-solving by precluding the use of external tools, thereby
focusing on intrinsic long-context reasoning capabilities in an exploratory
environment characterized by the need for trial-and-error learning and
sustained problem-solving within a single interactive session. We release
TextQuests at https://textquests.ai.

</details>


### [67] [Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving](https://arxiv.org/abs/2507.23726)
*Luoxin Chen,Jinming Gu,Liankai Huang,Wenhao Huang,Zhicheng Jiang,Allan Jie,Xiaoran Jin,Xing Jin,Chenggang Li,Kaijing Ma,Cheng Ren,Jiawei Shen,Wenlei Shi,Tong Sun,He Sun,Jiahui Wang,Siran Wang,Zhihong Wang,Chenrui Wei,Shufa Wei,Yonghui Wu,Yuchen Wu,Yihang Xia,Huajian Xin,Fan Yang,Huaiyuan Ying,Hongyi Yuan,Zheng Yuan,Tianyang Zhan,Chi Zhang,Yue Zhang,Ge Zhang,Tianyun Zhao,Jianqiu Zhao,Yichi Zhou,Thomas Hanwen Zhu*

Main category: cs.AI

TL;DR: Seed-Prover是一种基于强化学习和形式化验证的定理证明模型，通过迭代优化证明过程，显著提升了IMO级数学问题的解决能力，并在几何推理方面取得突破。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在数学推理中因缺乏明确的监督信号而难以有效进行定理证明，形式化验证语言如Lean能提供清晰反馈，但需解决几何支持不足的问题。

Method: 提出Seed-Prover模型，结合Lean的反馈、已证引理和自总结进行迭代证明优化；设计三种推理策略实现深度与广度推理；开发几何推理引擎Seed-Geometry弥补Lean的不足。

Result: 模型在形式化IMO历史题中达到78.1\%的证明率，MiniF2F上饱和，PutnamBench超过50\%；IMO 2025中成功证明5/6题目，几何引擎性能超越前人。

Conclusion: 该工作通过形式化验证与长链推理的结合，实现了自动数学推理的重大进展，为复杂定理证明提供了有效解决方案。

Abstract: LLMs have demonstrated strong mathematical reasoning abilities by leveraging
reinforcement learning with long chain-of-thought, yet they continue to
struggle with theorem proving due to the lack of clear supervision signals when
solely using natural language. Dedicated domain-specific languages like Lean
provide clear supervision via formal verification of proofs, enabling effective
training through reinforcement learning. In this work, we propose
\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover
can iteratively refine its proof based on Lean feedback, proved lemmas, and
self-summarization. To solve IMO-level contest problems, we design three
test-time inference strategies that enable both deep and broad reasoning.
Seed-Prover proves $78.1\%$ of formalized past IMO problems, saturates MiniF2F,
and achieves over 50\% on PutnamBench, outperforming the previous
state-of-the-art by a large margin. To address the lack of geometry support in
Lean, we introduce a geometry reasoning engine \textbf{Seed-Geometry}, which
outperforms previous formal geometry engines. We use these two systems to
participate in IMO 2025 and fully prove 5 out of 6 problems. This work
represents a significant advancement in automated mathematical reasoning,
demonstrating the effectiveness of formal verification with long
chain-of-thought reasoning.

</details>


### [68] [CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks](https://arxiv.org/abs/2507.23751)
*Ping Yu,Jack Lanchantin,Tianlu Wang,Weizhe Yuan,Olga Golovneva,Ilia Kulikov,Sainbayar Sukhbaatar,Jason Weston,Jing Xu*

Main category: cs.AI

TL;DR: 提出CoT-Self-Instruct方法，通过链式思考生成高质量合成数据，显著提升大语言模型在可验证推理与非可验证指令任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有训练数据集在复杂推理任务上表现不足，需要一种能自动生成高质量合成数据的方法来提升模型性能。

Method: 基于种子任务引导大模型进行链式思考（CoT）规划，生成质量与复杂度相当的合成提示，并通过自动指标过滤高质量数据。

Result: 在MATH500等可验证推理任务中超越s1k等数据集；在AlpacaEval 2.0等非可验证任务上优于人类或标准自指令提示。

Conclusion: CoT-Self-Instruct能有效生成优质训练数据，为复杂推理与指令跟随任务提供新的数据增强方案。

Abstract: We propose CoT-Self-Instruct, a synthetic data generation method that
instructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the
given seed tasks, and then to generate a new synthetic prompt of similar
quality and complexity for use in LLM training, followed by filtering for
high-quality data with automatic metrics. In verifiable reasoning, our
synthetic data significantly outperforms existing training datasets, such as
s1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For
non-verifiable instruction-following tasks, our method surpasses the
performance of human or standard self-instruct prompts on both AlpacaEval 2.0
and Arena-Hard.

</details>


### [69] [SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model](https://arxiv.org/abs/2507.23773)
*Mingkai Deng,Jinyu Hou,Yilin Shen,Hongxia Jin,Graham Neubig,Zhiting Hu,Eric Xing*

Main category: cs.AI

TL;DR: 本文提出SimuRA架构，通过世界模型模拟克服自回归LLM的局限性，在网页浏览任务中实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的AI代理采用单任务单代理模式，缺乏可扩展性和通用性，且受限于自回归推理的固有缺陷。人类通过心理模拟进行推理的通用性启发我们开发更强大的通用代理架构。

Method: 提出SimuRA目标导向架构，基于最优代理理论框架，利用LLM实现通用世界模型，通过自然语言潜在空间进行跨环境规划模拟。

Result: 在航班搜索任务中成功率从0%提升至32.2%，基于世界模型的规划相比自回归规划最高可获得124%的性能优势。

Conclusion: SimuRA证明了世界模型模拟作为推理范式的优越性，为训练基于LLM的通用超级智能代理奠定了基础，已开放网页浏览代理演示版供测试。

Abstract: AI agents built on large language models (LLMs) hold enormous promise, but
current practice focuses on a one-task-one-agent approach, which not only falls
short of scalability and generality, but also suffers from the fundamental
limitations of autoregressive LLMs. On the other hand, humans are general
agents who reason by mentally simulating the outcomes of their actions and
plans. Moving towards a more general and powerful AI agent, we introduce
SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based
on a principled formulation of optimal agent in any environment, \modelname
overcomes the limitations of autoregressive reasoning by introducing a world
model for planning via simulation. The generalized world model is implemented
using LLM, which can flexibly plan in a wide range of environments using the
concept-rich latent space of natural language. Experiments on difficult web
browsing tasks show that \modelname improves the success of flight search from
0\% to 32.2\%. World-model-based planning, in particular, shows consistent
advantage of up to 124\% over autoregressive planning, demonstrating the
advantage of world model simulation as a reasoning paradigm. We are excited
about the possibility for training a single, general agent model based on LLMs
that can act superintelligently in all environments. To start, we make SimuRA,
a web-browsing agent built on \modelname with pretrained LLMs, available as a
research demo for public testing.

</details>


<div id='stat.TH'></div>

# stat.TH [[Back]](#toc)

### [70] [Information geometry of Lévy processes and financial models](https://arxiv.org/abs/2507.23646)
*Jaehyung Choi*

Main category: stat.TH

TL;DR: 本文研究了L\'evy过程的信息几何，推导了$\alpha$-散度、Fisher信息矩阵和$\alpha$-连接，并探讨了在金融建模中的应用。


<details>
  <summary>Details</summary>
Motivation: 探索L\'evy过程的信息几何结构，为金融建模中的相关过程提供几何视角和统计工具。

Method: 从L\'evy过程的$\alpha$-散度出发，计算Fisher信息矩阵和$\alpha$-连接，并分析其统计应用。

Result: 成功推导了L\'evy过程的几何结构，包括经调整稳定过程、CGMY模型和方差伽玛过程等金融相关案例。

Conclusion: 该研究为L\'evy过程建立了信息几何框架，在金融建模等领域具有潜在应用价值。

Abstract: We explore the information geometry of L\'evy processes. As a starting point,
we derive the $\alpha$-divergence between two L\'evy processes. Subsequently,
the Fisher information matrix and the $\alpha$-connection associated with the
geometry of L\'evy processes are computed from the $\alpha$-divergence. In
addition, we discuss statistical applications of this information geometry. As
illustrative examples, we investigate the differential-geometric structures of
various L\'evy processes relevant to financial modeling, including tempered
stable processes, the CGMY model, and variance gamma processes.

</details>
