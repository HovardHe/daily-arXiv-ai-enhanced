{"id": "2507.07935", "categories": ["cs.AI", "cs.CY", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2507.07935", "abs": "https://arxiv.org/abs/2507.07935", "authors": ["Kiran Tomlinson", "Sonia Jaffe", "Will Wang", "Scott Counts", "Siddharth Suri"], "title": "Working with AI: Measuring the Occupational Implications of Generative AI", "comment": "40 pages", "summary": "Given the rapid adoption of generative AI and its potential to impact a wide\nrange of tasks, understanding the effects of AI on the economy is one of\nsociety's most important questions. In this work, we take a step toward that\ngoal by analyzing the work activities people do with AI, how successfully and\nbroadly those activities are done, and combine that with data on what\noccupations do those activities. We analyze a dataset of 200k anonymized and\nprivacy-scrubbed conversations between users and Microsoft Bing Copilot, a\npublicly available generative AI system. We find the most common work\nactivities people seek AI assistance for involve gathering information and\nwriting, while the most common activities that AI itself is performing are\nproviding information and assistance, writing, teaching, and advising.\nCombining these activity classifications with measurements of task success and\nscope of impact, we compute an AI applicability score for each occupation. We\nfind the highest AI applicability scores for knowledge work occupation groups\nsuch as computer and mathematical, and office and administrative support, as\nwell as occupations such as sales whose work activities involve providing and\ncommunicating information. Additionally, we characterize the types of work\nactivities performed most successfully, how wage and education correlate with\nAI applicability, and how real-world usage compares to predictions of\noccupational AI impact."}
{"id": "2507.07210", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07210", "abs": "https://arxiv.org/abs/2507.07210", "authors": ["Nils Rollshausen", "Alexander Heinrich", "Matthias Hollick", "Jiska Classen"], "title": "WatchWitch: Interoperability, Privacy, and Autonomy for the Apple Watch", "comment": "To appear in \"Proceedings on Privacy Enhancing Technologies\"", "summary": "Smartwatches such as the Apple Watch collect vast amounts of intimate health\nand fitness data as we wear them. Users have little choice regarding how this\ndata is processed: The Apple Watch can only be used with Apple's iPhones, using\ntheir software and their cloud services. We are the first to publicly\nreverse-engineer the watch's wireless protocols, which led to discovering\nmultiple security issues in Apple's proprietary implementation. With\nWatchWitch, our custom Android reimplementation, we break out of Apple's walled\ngarden -- demonstrating practical interoperability with enhanced privacy\ncontrols and data autonomy. We thus pave the way for more consumer choice in\nthe smartwatch ecosystem, offering users more control over their devices."}
{"id": "2507.07208", "categories": ["math.LO", "cs.LO", "math.CT", "03F50, 03G30, 18C10, 03B38, 03B70, 18N45, 18D30, 55U35, 55U40"], "pdf": "https://arxiv.org/pdf/2507.07208", "abs": "https://arxiv.org/abs/2507.07208", "authors": ["Matteo Spadetto"], "title": "A 2-categorical approach to the semantics of dependent type theory with computation axioms", "comment": "64 pages, comments welcome", "summary": "Axiomatic type theory is a dependent type theory without computation rules.\nThe term equality judgements that usually characterise these rules are replaced\nby computation axioms, i.e., additional term judgements that are typed by\nidentity types. This paper is devoted to providing an effective description of\nits semantics, from a higher categorical perspective: given the challenge of\nencoding intensional type formers into 1-dimensional categorical terms and\nproperties, a challenge that persists even for axiomatic type formers, we adopt\nRichard Garner's approach in the 2-dimensional study of dependent types. We\nprove that the type formers of axiomatic theories can be encoded into natural\n2-dimensional category theoretic data, obtaining a presentation of the\nsemantics of axiomatic type theory via 2-categorical models called display map\n2-categories. In the axiomatic case, the 2-categorical requirements identified\nby Garner for interpreting intensional type formers are relaxed. Therefore, we\nobtain a presentation of the semantics of the axiomatic theory that generalises\nGarner's one for the intensional case. Our main result states that the\ninterpretation of axiomatic theories within display map 2-categories is\nwell-defined and enjoys the soundness property. We use this fact to provide a\nsemantic proof that the computation rule of intensional identity types is not\nadmissible in axiomatic type theory. This is achieved via a revisitation of\nHofmann and Streicher's groupoid model that believes axiomatic identity types\nbut does not believe intensional ones."}
{"id": "2507.07243", "categories": ["math.CO", "Primary 05A05, Secondary 05A15, 05A19"], "pdf": "https://arxiv.org/pdf/2507.07243", "abs": "https://arxiv.org/abs/2507.07243", "authors": ["Kyle Celano", "Jennifer Elder", "Kimberly P. Hadaway", "Pamela E. Harris", "Jeremy L. Martin", "Amanda Priestley", "Gabe Udell"], "title": "Statistics on $\\ell$-interval parking functions", "comment": "25 pages", "summary": "The displacement of a car with respect to a parking function is the number of\nspots it must drive past its preferred spot in order to park. An\n$\\ell$-interval parking function is one in which each car has displacement at\nmost $\\ell$. Among our results, we enumerate $\\ell$-interval parking functions\nwith respect to statistics such as inversion, displacement, and major index. We\nshow that $1$-interval parking functions with fixed displacement exhibit a\ncyclic sieving phenomenon. We give closed formulas for the number of\n$1$-interval parking functions with a fixed number of inversions. We prove that\na well-known bijection of Foata preserves the set of $\\ell$-interval parking\nfunctions exactly when $\\ell\\leq 2$ or $\\ell\\geq n-2$, which implies that the\ninversion and major index statistics are equidistributed in these cases."}
{"id": "2507.07241", "categories": ["math.OC", "cs.IT", "eess.SP", "math.IT", "49M20 (Primary) 49M05, 94A05 (Secondary)", "F.2.1; F.2.3; I.6.8; G.1.6"], "pdf": "https://arxiv.org/pdf/2507.07241", "abs": "https://arxiv.org/abs/2507.07241", "authors": ["Robert Kuku Fotock", "Agbotiname Lucky Imoize", "Alessio Zappone", "Marco Di Renzo", "Roberto Garello"], "title": "Secrecy Energy Efficiency Maximization in RIS-Aided Networks: Active or Nearly-Passive RIS?", "comment": "16 pages, 11 figures, IEEE TRANSACTIONS ON INFORMATION FORENSICS AND\n  SECURITY", "summary": "This work addresses the problem of secrecy energy efficiency (SEE)\nmaximization in RIS-aided wireless networks. The use of active and\nnearly-passive RISs are compared and their trade-off in terms of SEE is\nanalyzed. Considering both perfect and statistical channel state information,\ntwo SEE maximization algorithms are developed to optimize the transmit powers\nof the mobile users, the RIS reflection coefficients, and the base station\nreceive filters. Numerical results quantify the trade-off between active and\nnearly-passive RISs in terms of SEE, with active RISs yielding worse SEE values\nas the static power consumed by each reflecting element increases."}
{"id": "2507.07253", "categories": ["math.NT", "Primary 11M06, Secondary 52C23, 30D99"], "pdf": "https://arxiv.org/pdf/2507.07253", "abs": "https://arxiv.org/abs/2507.07253", "authors": ["Juan Arias de Reyna", "Yves Meyer"], "title": "Asymptotic properties of zeros of Riemann zeta function", "comment": "22 pages, 1 figure", "summary": "We try to define the sequence of zeros of the Riemann zeta function by an\nintrinsic property. Let $(z_k)_{k\\in \\mathbb{N}}$ be the sequence of nontrivial\nzeros of $\\zeta(s)$ with positive imaginary part. We write $z_k= 1/2+i\\tau_k$\n(RH says that these $\\tau_k$ are all real). Then the sequence $(\\tau_k)_{k\\in\n\\mathbb{N}},$ satisfies the following asymptotic relation\n\\[\\sum_{k\\in\\mathbb{N}}\\frac{2x}{x^2+\\tau_k^2}\\simeq\n\\frac12\\log\\frac{x}{2\\pi}+\\sum_{n=1}^\\infty \\frac{a_n}{x^n},\\,\\,x\\to +\\infty\\]\nwhere $a_{2n+1}=2^{-2n-2}(8-E_{2n})$, $a_{2n}=(1-2^{-2n+1})B_{2n}/(4n).$ Are\nthere other sequences $(\\alpha_k)_{k\\in \\mathbb{N}},$ of real or complex\nnumbers enjoying this property? These problems are addressed in this note."}
{"id": "2507.07296", "categories": ["q-fin.GN", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07296", "abs": "https://arxiv.org/abs/2507.07296", "authors": ["Ben A. Marconi"], "title": "Time Series Foundation Models for Multivariate Financial Time Series Forecasting", "comment": "66 pages", "summary": "Financial time series forecasting presents significant challenges due to\ncomplex nonlinear relationships, temporal dependencies, variable\ninterdependencies and limited data availability, particularly for tasks\ninvolving low-frequency data, newly listed instruments, or emerging market\nassets. Time Series Foundation Models (TSFMs) offer a promising solution\nthrough pretraining on diverse time series corpora followed by task-specific\nadaptation. This study evaluates two TSFMs (Tiny Time Mixers (TTM) and Chronos)\nacross three financial forecasting tasks: US 10-year Treasury yield changes,\nEUR/USD volatility, and equity spread prediction. Results demonstrate that TTM\nexhibits strong transferability. When fine-tuning both the pretrained version\nof TTM and an untrained model with the same architecture, the pretrained\nversion achieved 25-50% better performance when fine-tuned on limited data and\n15-30% improvements even when fine-tuned on lengthier datasets. Notably, TTM's\nzero-shot performance outperformed naive benchmarks in volatility forecasting\nand equity spread prediction, with the latter demonstrating that TSFMs can\nsurpass traditional benchmark models without fine-tuning. The pretrained model\nconsistently required 3-10 fewer years of data to achieve comparable\nperformance levels compared to the untrained model, demonstrating significant\nsample-efficiency gains. However, while TTM outperformed naive baselines,\ntraditional specialised models matched or exceeded its performance in two of\nthree tasks, suggesting TSFMs prioritise breadth over task-specific\noptimisation. These findings indicate that TSFMs, though still nascent, offer\nsubstantial promise for financial forecasting-particularly in noisy,\ndata-constrained tasks-but achieving competitive performance likely requires\ndomain-specific pretraining and architectural refinements tailored to financial\ntime series characteristics."}
{"id": "2507.07942", "categories": ["cs.DM", "cs.CC", "cs.LO", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.07942", "abs": "https://arxiv.org/abs/2507.07942", "authors": ["Joshua Brakensiek", "Venkatesan Guruswami", "Bart M. P. Jansen", "Victor Lagerkvist", "Magnus Wahlström"], "title": "The Richness of CSP Non-redundancy", "comment": "82 pages, 5 figures", "summary": "In the field of constraint satisfaction problems (CSP), a clause is called\nredundant if its satisfaction is implied by satisfying all other clauses. An\ninstance of CSP$(P)$ is called non-redundant if it does not contain any\nredundant clause. The non-redundancy (NRD) of a predicate $P$ is the maximum\nnumber of clauses in a non-redundant instance of CSP$(P)$, as a function of the\nnumber of variables $n$. Recent progress has shown that non-redundancy is\ncrucially linked to many other important questions in computer science and\nmathematics including sparsification, kernelization, query complexity,\nuniversal algebra, and extremal combinatorics. Given that non-redundancy is a\nnexus for many of these important problems, the central goal of this paper is\nto more deeply understand non-redundancy.\n  Our first main result shows that for every rational number $r \\ge 1$, there\nexists a finite CSP predicate $P$ such that the non-redundancy of $P$ is\n$\\Theta(n^r)$. Our second main result explores the concept of conditional\nnon-redundancy first coined by Brakensiek and Guruswami [STOC 2025]. We\ncompletely classify the conditional non-redundancy of all binary predicates\n(i.e., constraints on two variables) by connecting these non-redundancy\nproblems to the structure of high-girth graphs in extremal combinatorics.\n  Inspired by these concrete results, we build off the work of Carbonnel [CP\n2022] to develop an algebraic theory of conditional non-redundancy. As an\napplication of this algebraic theory, we revisit the notion of Mal'tsev\nembeddings, which is the most general technique known to date for establishing\nthat a predicate has linear non-redundancy. For example, we provide the first\nexample of predicate with a Mal'tsev embedding that cannot be attributed to the\nstructure of an Abelian group, but rather to the structure of the quantum Pauli\ngroup."}
{"id": "2507.07115", "categories": ["cs.AI", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.07115", "abs": "https://arxiv.org/abs/2507.07115", "authors": ["Javal Vyas", "Mehmet Mercangoz"], "title": "Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation", "comment": null, "summary": "The increasing complexity of modern chemical processes, coupled with\nworkforce shortages and intricate fault scenarios, demands novel automation\nparadigms that blend symbolic reasoning with adaptive control. In this work, we\nintroduce a unified agentic framework that leverages large language models\n(LLMs) for both discrete fault-recovery planning and continuous process control\nwithin a single architecture. We adopt Finite State Machines (FSMs) as\ninterpretable operating envelopes: an LLM-driven planning agent proposes\nrecovery sequences through the FSM, a Simulation Agent executes and checks each\ntransition, and a Validator-Reprompting loop iteratively refines invalid plans.\nIn Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25\nstates, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path\nsuccess within five reprompts-outperforming open-source LLMs in both accuracy\nand latency. In Case Study 2, the same framework modulates dual-heater inputs\non a laboratory TCLab platform (and its digital twin) to maintain a target\naverage temperature under persistent asymmetric disturbances. Compared to\nclassical PID control, our LLM-based controller attains similar performance,\nwhile ablation of the prompting loop reveals its critical role in handling\nnonlinear dynamics. We analyze key failure modes-such as instruction following\nlapses and coarse ODE approximations. Our results demonstrate that, with\nstructured feedback and modular agents, LLMs can unify high-level symbolic\nplanningand low-level continuous control, paving the way towards resilient,\nlanguage-driven automation in chemical engineering."}
{"id": "2507.07132", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.07132", "abs": "https://arxiv.org/abs/2507.07132", "authors": ["Jérémy Bettinger", "François Portier", "Adrien Saumard"], "title": "On the pointwise and sup-norm errors for local regression estimators", "comment": "arXiv admin note: substantial text overlap with arXiv:2501.18204", "summary": "In this paper, we analyze the behavior of various non-parametric local\nregression estimators, i.e. estimators that are based on local averaging, for\nestimating a Lipschitz regression function at a fixed point, or in sup-norm.\n  We first prove some deviation bounds for local estimators that can be indexed\nby a VC class of sets in the covariates space. We then introduce the general\nconcept of shape-regular local maps, corresponding to the situation where the\nlocal averaging is done on sets which, in some sense, have ``almost isotropic''\nshapes. On the one hand, we prove that, in general, shape-regularity is\nnecessary to achieve the minimax rates of convergence. On the other hand, we\nprove that it is sufficient to ensure the optimal rates, up to some logarithmic\nfactors.\n  Next, we prove some deviation bounds for specific estimators, that are based\non data-dependent local maps, such as nearest neighbors, their recent prototype\nvariants, as well as a new algorithm, which is a modified and generalized\nversion of CART, and that is minimax rate optimal in sup-norm. In particular,\nthe latter algorithm is based on a random tree construction that depends on\nboth the covariates and the response data. For each of the estimators, we\nprovide insights on the shape-regularity of their respective local maps.\nFinally, we conclude the paper by establishing some probability bounds for\nlocal estimators based on purely random trees, such as centered, uniform or\nMondrian trees. Again, we discuss the relations between the rates of the\nestimators and the shape-regularity of their local maps."}
{"id": "2507.07244", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07244", "abs": "https://arxiv.org/abs/2507.07244", "authors": ["Faissal Ahmadou", "Sepehr Ghaffarzadegan", "Boubakr Nour", "Makan Pourzandi", "Mourad Debbabi", "Chadi Assi"], "title": "Automated Attack Testflow Extraction from Cyber Threat Report using BERT for Contextual Analysis", "comment": null, "summary": "In the ever-evolving landscape of cybersecurity, the rapid identification and\nmitigation of Advanced Persistent Threats (APTs) is crucial. Security\npractitioners rely on detailed threat reports to understand the tactics,\ntechniques, and procedures (TTPs) employed by attackers. However, manually\nextracting attack testflows from these reports requires elusive knowledge and\nis time-consuming and prone to errors. This paper proposes FLOWGUARDIAN, a\nnovel solution leveraging language models (i.e., BERT) and Natural Language\nProcessing (NLP) techniques to automate the extraction of attack testflows from\nunstructured threat reports. FLOWGUARDIAN systematically analyzes and\ncontextualizes security events, reconstructs attack sequences, and then\ngenerates comprehensive testflows. This automated approach not only saves time\nand reduces human error but also ensures comprehensive coverage and robustness\nin cybersecurity testing. Empirical validation using public threat reports\ndemonstrates FLOWGUARDIAN's accuracy and efficiency, significantly enhancing\nthe capabilities of security teams in proactive threat hunting and incident\nresponse."}
{"id": "2507.07309", "categories": ["math.LO"], "pdf": "https://arxiv.org/pdf/2507.07309", "abs": "https://arxiv.org/abs/2507.07309", "authors": ["Hiroshi Sakai", "Toshimasa Tanno"], "title": "Generalized Tukey reducibility between $σ$-directed sets", "comment": "19 pages", "summary": "We introduce the pre-Tukey reducibility, a generalization of the Tukey\nreducibility between directed sets that works well in $\\mathsf{ZF}$. We\ninvestigate the pre-Tukey reducibility between several $\\sigma$-directed sets\nunder assumptions on sets of reals, which hold in the Solovay model and in\n$L(\\mathbb{R})$ satisfying $\\mathsf{AD}$."}
{"id": "2507.07269", "categories": ["math.CO", "cs.CG", "52A37"], "pdf": "https://arxiv.org/pdf/2507.07269", "abs": "https://arxiv.org/abs/2507.07269", "authors": ["Chaya Keller", "Shakhar Smorodinsky"], "title": "A simple proof of a $(p,2)$-theorem for non-piercing regions", "comment": null, "summary": "A family of sets satisfies the $(p,2)$-property if among any $p$ sets in the\nfamily, some two intersect. Two recent works used elaborate geometric\ntechniques to show that any family of non-piercing regions in the plane that\nsatisfies the $(p,2)$-property can be pierced by $O(p^9)$ points. In this note\nwe show that even in a much more general setting, piercing by $O(p)$ points can\nbe deduced from known results on hypergraphs with a hereditarily linear\nDelaunay graph, which include intersection hypergraphs of non-piercing regions."}
{"id": "2507.07263", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.07263", "abs": "https://arxiv.org/abs/2507.07263", "authors": ["Jared Miller", "Mattia Bianchi", "Florian Dörfler"], "title": "Convergence and Robustness Bounds for Distributed Asynchronous Shortest-Path", "comment": "12 pages, 6 figures", "summary": "This work analyzes convergence times and robustness bounds for asynchronous\ndistributed shortest-path computation. We focus on the Adaptive Bellman--Ford\nalgorithm, a self-stabilizing method in which each agent updates its\nshortest-path estimate based only on the estimates of its neighbors and\nforgetting its previous estimate. In the asynchronous framework considered in\nthis paper, agents are allowed to idle or encounter race conditions during\ntheir execution of the Adaptive Bellman--Ford algorithm. We build on\nLyapunov-based results that develop finite-time convergence and robustness\nbounds for the synchronous shortest-path setting, in order to produce\nfinite-time convergence and robustness bounds for the asynchronous setting. We\nalso explore robustness against interval-bounded noise processes and establish\nconvergence and robustness guarantees for asynchronous most-probable-path\nalgorithms."}
{"id": "2507.07337", "categories": ["math.NT", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.07337", "abs": "https://arxiv.org/abs/2507.07337", "authors": ["Valentin Suder"], "title": "An Equivalent Representation of Generalized Differentials", "comment": null, "summary": "We propose an equivalent formula for the higher-order derivatives used in the\nstudy of Generalized Almost Perfect Nonlinear functions over an arbitrary\nfinite field of characteristic $p$. The result is obtained by counting the\nnumber of subsets of the prime field with a fixed cardinality for which the sum\nof their elements is constant. We then ask related questions regarding the\ndiversity of higher-order derivatives."}
{"id": "2507.07337", "categories": ["math.NT", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.07337", "abs": "https://arxiv.org/abs/2507.07337", "authors": ["Valentin Suder"], "title": "An Equivalent Representation of Generalized Differentials", "comment": null, "summary": "We propose an equivalent formula for the higher-order derivatives used in the\nstudy of Generalized Almost Perfect Nonlinear functions over an arbitrary\nfinite field of characteristic $p$. The result is obtained by counting the\nnumber of subsets of the prime field with a fixed cardinality for which the sum\nof their elements is constant. We then ask related questions regarding the\ndiversity of higher-order derivatives."}
{"id": "2507.07134", "categories": ["cs.AI", "cs.LG", "I.2.10"], "pdf": "https://arxiv.org/pdf/2507.07134", "abs": "https://arxiv.org/abs/2507.07134", "authors": ["Mridula Vijendran", "Shuang Chen", "Jingjing Deng", "Hubert P. H. Shum"], "title": "BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks", "comment": "18 pages, 7 figures, 3 tables", "summary": "The pervasive issue of bias in AI presents a significant challenge to\npainting classification, and is getting more serious as these systems become\nincreasingly integrated into tasks like art curation and restoration. Biases,\noften arising from imbalanced datasets where certain artistic styles dominate,\ncompromise the fairness and accuracy of model predictions, i.e., classifiers\nare less accurate on rarely seen paintings. While prior research has made\nstrides in improving classification performance, it has largely overlooked the\ncritical need to address these underlying biases, that is, when dealing with\nout-of-distribution (OOD) data. Our insight highlights the necessity of a more\nrobust approach to bias mitigation in AI models for art classification on\nbiased training data. We propose a novel OOD-informed model bias adaptive\nsampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It\naddresses these challenges by dynamically adjusting temperature scaling and\nsampling probabilities, thereby promoting a more equitable representation of\nall classes. We evaluate our proposed approach to the KaoKore and PACS\ndatasets, focusing on the model's ability to reduce class-wise bias. We further\npropose a new metric, Same-Dataset OOD Detection Score (SODC), designed to\nassess class-wise separation and per-class bias reduction. Our method\ndemonstrates the ability to balance high performance with fairness, making it a\nrobust solution for unbiasing AI models in the art domain."}
{"id": "2507.07946", "categories": ["math.ST", "stat.TH", "68Q17"], "pdf": "https://arxiv.org/pdf/2507.07946", "abs": "https://arxiv.org/abs/2507.07946", "authors": ["Bertrand Even", "Christophe Giraud", "Nicolas Verzelen"], "title": "Computational barriers for permutation-based problems, and cumulants of weakly dependent random variables", "comment": null, "summary": "In many high-dimensional problems,polynomial-time algorithms fall short of\nachieving the statistical limits attainable without computational constraints.\nA powerful approach to probe the limits of polynomial-time algorithms is to\nstudy the performance of low-degree polynomials. The seminal work of\narXiv:2008.02269 connects low-degree lower bounds to multivariate cumulants.\nPrior works arXiv:2308.15728, arXiv:2506.13647 leverage independence among\nlatent variables to bound cumulants. However, such approaches break down for\nproblems with latent structure lacking independence, such as those involving\nrandom permutations. To address this important restriction, we develop a\ntechnique to upper-bound cumulants under weak dependencies, such as those\narising from sampling without replacement or random permutations. To show-case\nthe effectiveness of our approach, we uncover evidence of\nstatistical-computational gaps in multiple feature matching and in seriation\nproblems."}
{"id": "2507.07246", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07246", "abs": "https://arxiv.org/abs/2507.07246", "authors": ["Peicheng Wang", "Monika Santra", "Mingyu Liu", "Cong Sun", "Dongrui Zeng", "Gang Tan"], "title": "Disa: Accurate Learning-based Static Disassembly with Attentions", "comment": "To appear at ACM CCS 2025", "summary": "For reverse engineering related security domains, such as vulnerability\ndetection, malware analysis, and binary hardening, disassembly is crucial yet\nchallenging. The fundamental challenge of disassembly is to identify\ninstruction and function boundaries. Classic approaches rely on file-format\nassumptions and architecture-specific heuristics to guess the boundaries,\nresulting in incomplete and incorrect disassembly, especially when the binary\nis obfuscated. Recent advancements of disassembly have demonstrated that deep\nlearning can improve both the accuracy and efficiency of disassembly. In this\npaper, we propose Disa, a new learning-based disassembly approach that uses the\ninformation of superset instructions over the multi-head self-attention to\nlearn the instructions' correlations, thus being able to infer function\nentry-points and instruction boundaries. Disa can further identify instructions\nrelevant to memory block boundaries to facilitate an advanced block-memory\nmodel based value-set analysis for an accurate control flow graph (CFG)\ngeneration. Our experiments show that Disa outperforms prior deep-learning\ndisassembly approaches in function entry-point identification, especially\nachieving 9.1% and 13.2% F1-score improvement on binaries respectively\nobfuscated by the disassembly desynchronization technique and popular\nsource-level obfuscator. By achieving an 18.5% improvement in the memory block\nprecision, Disa generates more accurate CFGs with a 4.4% reduction in Average\nIndirect Call Targets (AICT) compared with the state-of-the-art heuristic-based\napproach."}
{"id": "2507.07489", "categories": ["math.LO", "math.CT", "18C05, 08C05, 18F70, 06E25, 06D20, 06D22, 18F60"], "pdf": "https://arxiv.org/pdf/2507.07489", "abs": "https://arxiv.org/abs/2507.07489", "authors": ["Marco Abbadini", "Guram Bezhanishvili", "Luca Carai"], "title": "On the lack of colimits in various categories of BAOs and Heyting algebras", "comment": null, "summary": "We prove that various categories of BAOs (boolean algebras with an operator)\nwith stable morphisms between them are not cocomplete, and that neither are the\ncategory of Heyting algebras with bounded lattice morphisms, its full\nsubcategory consisting of frames, and the category of frames with Heyting\nmorphisms. As a consequence, none of these categories is equivalent to a\nprevariety of algebras, let alone a variety. In particular, we obtain that the\ncategory of McKinsey-Tarski algebras is not equivalent to a variety, thus\nanswering a question by Peter Jipsen in the negative."}
{"id": "2507.07301", "categories": ["math.CO", "05C50, 05C05, 05C70"], "pdf": "https://arxiv.org/pdf/2507.07301", "abs": "https://arxiv.org/abs/2507.07301", "authors": ["Jiancheng Wu", "Sizhong Zhou"], "title": "Spanning k-trees, odd [1,b]-factors and spectral radius in binding graphs", "comment": "11 pages", "summary": "The binding number of a graph $G$, written as $\\mbox{bind}(G)$, is defined by\n$$ \\mbox{bind}(G)=\\min\\left\\{\\frac{|N_G(X)|}{|X|}:\\emptyset\\neq X\\subseteq\nV(G),N_G(X)\\neq V(G)\\right\\}. $$ A graph $G$ is called $r$-binding if\n$\\mbox{bind}(G)\\geq r$. An odd $[1,b]$-factor of a graph $G$ is a spanning\nsubgraph $F$ with $d_F(v)\\in\\{1,3,\\ldots,b\\}$ for all $v\\in V(G)$, where\n$b\\geq1$ is an odd integer. A spanning $k$-tree of a connected graph $G$ is a\nspanning tree $T$ with $d_T(v)\\leq k$ for every $v\\in V(G)$. In this paper, we\nfirst show a tight sufficient condition with respect to the adjacency spectral\nradius for connected $\\frac{1}{b}$-binding graphs to have odd $[1,b]$-factors,\nwhich generalizes Fan and Lin's previous result [D. Fan, H. Lin, Binding\nnumber, $k$-factor and spectral radius of graphs, Electron. J. Combin. 31(1)\n(2024) \\#P1.30] and partly improves Fan, Liu and Ao's previous result [A. Fan,\nR. Liu, G. Ao, Spectral radius, odd $[1,b]$-factor and spanning $k$-tree of\n1-binding graphs, Linear Algebra Appl. 705 (2025) 1--16]. Then we put forward a\ntight sufficient condition via the adjacency spectral radius for connected\n$\\frac{1}{k-2}$-binding graphs to have spanning $k$-trees, which partly\nimproves Fan, Liu and Ao's previous result [A. Fan, R. Liu, G. Ao, Spectral\nradius, odd $[1,b]$-factor and spanning $k$-tree of 1-binding graphs, Linear\nAlgebra Appl. 705 (2025) 1--16]."}
{"id": "2507.07281", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07281", "abs": "https://arxiv.org/abs/2507.07281", "authors": ["Marcel Hudiani"], "title": "Almost Sure Convergence for the Last Iterate of Stochastic Gradient Descent Schemes", "comment": null, "summary": "We study the almost sure convergence rate for the last iterate of stochastic\ngradient descent (SGD) and stochastic heavy ball (SHB) in the parametric\nsetting when the objective function $F$ is globally convex or non-convex whose\ngradient is $\\gamma$-H\\\"{o}lder. Using only discrete Gronwall's inequality\nwithout Robbins-Siegmund theorem nor martingale convergence theory, we recover\nresults for both SGD and SHB: $\\min_{s\\leq t} \\|\\nabla F(w_s)\\|^2 = o(t^{p-1})$\nfor non-convex objectives and $F(w_t) - F_* = o(t^{2\\gamma/(1+\\gamma) \\cdot\n\\max(p-1,-2p+1)-\\epsilon})$ for $\\beta \\in (0, 1)$ and $\\min_{s \\leq t} F(w_s)\n- F_* = o(t^{p-1})$ almost surely for convex objectives. In addition, we proved\nthat SHB with constant momentum parameter $\\beta \\in (0, 1)$ attains a\nconvergence rate of $F(w_t) - F_* = O(t^{\\max(p-1,-2p+1)} \\log^2\n\\frac{t}{\\delta})$ with probability at least $1-\\delta$ when $F$ is convex and\n$\\gamma = 1$ and step size $\\alpha_t = \\Theta(t^{-p})$ with $p \\in\n(\\frac{1}{2}, 1)$."}
{"id": "2507.07423", "categories": ["math.NT", "math.AG"], "pdf": "https://arxiv.org/pdf/2507.07423", "abs": "https://arxiv.org/abs/2507.07423", "authors": ["Daniel Barrera Salazar", "Héctor del Castillo", "Giovanni Rosso"], "title": "Higher Hida theory for Drinfeld modular curves", "comment": null, "summary": "Inspired by the construction of Higher Hida theory of Boxer and Pilloni, we\ndevelop Higher Hida theory for the cohomology of the line bundles of Drinfeld\nmodular forms on the Drinfeld modular curve. We also interpolate Serre duality."}
{"id": "2507.07596", "categories": ["math.OC", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.07596", "abs": "https://arxiv.org/abs/2507.07596", "authors": ["Yuki Nishida"], "title": "Combinatorial Algorithm for Tropical Linearly Factorized Programming", "comment": null, "summary": "The tropical semiring is a set of numbers $\\mathbb{R}\\cup\\{-\\infty\\}$ with\naddition $a\\oplus b:=\\max(a,b)$ and multiplication $a\\otimes b:=a+b$. As well\nas in conventional algebra, linear programming problem in the tropical semiring\nhas been developed. In this study, we introduce a new type of tropical\noptimization problem, namely, tropical linearly factorized programming problem.\nThis problem involves minimizing the objective function given by the product of\ntropical linear forms $c_{k,1}\\otimes x_1\\oplus \\cdots\\oplus c_{k,n}\\otimes\nx_n$ divided by a tropical monomial, subject to tropical linear inequality\nconstraints. The objective function is convex in the conventional sense but not\nin the tropical sense, while the feasible set is convex in the tropical sense\nbut not in the conventional sense.\n  Our algorithm for tropical linearly factorized programming is based on the\ndescent method and exploits tangent digraphs. First, we demonstrate that the\nfeasible descent direction at the current solution can be obtained by solving\nthe minimum $s$-$t$ cut problem on a specific subgraph of the tangent digraph.\nAlthough exponentially many such digraphs may exist in general, a more\nefficient algorithm is devised in cases where the problem is non-degenerate.\nFocusing on the fact that tangent digraphs become spanning trees in\nnon-degenerate cases, we present a simplex-like algorithm that updates the tree\nstructure iteratively. We show that each iteration can be executed in\n$O(r_A+r_C)$ time, where $r_A$ and $r_C$ are the numbers of ``non-zero''\ncoefficients in the linear constraints and objective function, respectively.\nFor integer instances, our algorithm finds a local optimum in\n$O((m+n)(r_A+r_C)MD)$ time, where $n$ and $m$ are the number of decision\nvariables and constraints, respectively, $M$ is the maximum absolute value of\ncoefficients and $D$ is the degree of the objective function."}
{"id": "2507.07203", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07203", "abs": "https://arxiv.org/abs/2507.07203", "authors": ["Minkyung Kim", "Junsik Kim", "Hwidong Bae", "Woongcheol Yang", "Sangdon Park", "Sohee Bae"], "title": "State-Inference-Based Prompting for Natural Language Trading with Game NPCs", "comment": "9 pages main content, 4 pages appendix, 3 figures. Accepted to the\n  KDD 2025 Workshop on Prompt Optimization", "summary": "Large Language Models enable dynamic game interactions but struggle with\nrule-governed trading systems. Current implementations suffer from rule\nviolations, such as item hallucinations and calculation errors, that erode\nplayer trust. Here, State-Inference-Based Prompting (SIBP) enables reliable\ntrading through autonomous dialogue state inference and context-specific rule\nadherence. The approach decomposes trading into six states within a unified\nprompt framework, implementing context-aware item referencing and\nplaceholder-based price calculations. Evaluation across 100 trading dialogues\ndemonstrates >97% state compliance, >95% referencing accuracy, and 99.7%\ncalculation precision. SIBP maintains computational efficiency while\noutperforming baseline approaches, establishing a practical foundation for\ntrustworthy NPC interactions in commercial games."}
{"id": "2507.07250", "categories": ["cs.CR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.07250", "abs": "https://arxiv.org/abs/2507.07250", "authors": ["Jordi Serra-Ruiz", "David Megías"], "title": "Semi-fragile watermarking of remote sensing images using DWT, vector quantization and automatic tiling", "comment": null, "summary": "A semi-fragile watermarking scheme for multiple band images is presented in\nthis article. We propose to embed a mark into remote sensing images applying a\ntree-structured vector quantization approach to the pixel signatures instead of\nprocessing each band separately. The signature of the multispectral or\nhyperspectral image is used to embed the mark in it order to detect any\nsignificant modification of the original image. The image is segmented into\nthree-dimensional blocks, and a tree-structured vector quantizer is built for\neach block. These trees are manipulated using an iterative algorithm until the\nresulting block satisfies a required criterion, which establishes the embedded\nmark. The method is shown to be able to preserve the mark under lossy\ncompression (above a given threshold) but, at the same time, it detects\npossibly forged blocks and their position in the whole image."}
{"id": "2507.07606", "categories": ["math.LO", "math.CO", "03D32, 03B30 (Primary) 05D10, 03F30 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.07606", "abs": "https://arxiv.org/abs/2507.07606", "authors": ["Quentin Le Houérou", "Ludovic Patey"], "title": "Ramsey-like theorems for separable permutations", "comment": "47 pages", "summary": "We conduct a computability-theoretic study of Ramsey-like theorems of the\nform \"Every coloring of the edges of an infinite clique admits an infinite\nsub-clique avoiding some pattern\", with a particular focus on transitive\npatterns. As it turns out, the patterns corresponding to separable permutations\nplay an important role in the computational features of the statement. We prove\nthat the avoidance of any separable permutation is equivalent to the existence\nof an infinite homogeneous set in standard models, while this property fails\nfor any other pattern. For this, we develop a novel argument for relativized\ndiagonal non-computation."}
{"id": "2507.07308", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.07308", "abs": "https://arxiv.org/abs/2507.07308", "authors": ["Simon Barazer"], "title": "Volumes of moduli spaces of directed ribbon graphs and Cut-and-Join operators", "comment": null, "summary": "In this paper, we investigate the algebraic structure underlying the acyclic\ndecomposition. This decomposition applies to directed metric ribbon graphs and\nenables the recursive computation of the volumes of their moduli spaces.\nBuilding on this, we define integral operators with these volumes and show that\nthey satisfy a Cut-and-Join type equation. Furthermore, we demonstrate that a\nsuitable specialization of these operators gives rise to a generating series\nfor \\textit{dessins d'enfants}."}
{"id": "2507.07377", "categories": ["math.OC", "49J52, 46N10, 90C25, 90C31"], "pdf": "https://arxiv.org/pdf/2507.07377", "abs": "https://arxiv.org/abs/2507.07377", "authors": ["Vo Si Trong Long", "Nguyen Mau Nam", "Len White"], "title": "Qualitative and Generalized Differentiation Properties of Optimal Value Functions with Applications to Duality", "comment": null, "summary": "In this paper, we investigate general and generalized differentiation\nproperties of theoptimal value function associated with perturbed optimization\nproblems. We begin with a comprehensive analysis of its effective domain,\nepigraph, strict epigraph, convexity, near convexity, continuity, and\nLipschitz-type behavior, in both convex and nonconvex settings. Next, we\npropose a duality framework for constrained optimization problems with\nset-valued constraints, based on the notion of the Fenchel conjugate for\nset-valued mappings, which offers new insights into duality theory in a broad\ncontext. Finally, we compute the {\\epsilon}-subdifferentials of the optimal\nvalue function and its Fenchel conjugate."}
{"id": "2507.07673", "categories": ["math.NT", "math.CO", "51E21, 05B25, 11A15"], "pdf": "https://arxiv.org/pdf/2507.07673", "abs": "https://arxiv.org/abs/2507.07673", "authors": ["Bhawesh Mishra", "Paolo Santonastaso"], "title": "Prime Power Residues and Blocking Sets", "comment": "Accepted for publication in Journal de Th\\'eorie des Nombres de\n  Bordeaux", "summary": "Let $q$ be a fixed odd prime. We show that a finite subset $B$ of integers,\nnot containing any perfect $q^{th}$ power, contains a $q^{th}$ power modulo\nalmost every prime if and only if $B$ corresponds to a blocking set (with\nrespect to hyperplanes) in $\\mathrm{PG}(\\mathbb{F}_{q}^{k})$. Here, $k$ is the\nnumber of distinct prime divisors of $q$-free parts of elements of $B$. As a\nconsequence, the property of a subset $B$ to contain $q^{th}$ power modulo\nalmost every prime $p$ is invariant under geometric $q$-equivalence defined by\nan element of the projective general linear group\n$\\mathrm{PGL}(\\mathbb{F}_{q}^{k})$. Employing this connection between two\ndisparate branches of mathematics, Galois geometry and number theory, we\nclassify, and provide bounds on the sizes of, minimal such sets $B$."}
{"id": "2507.07217", "categories": ["cs.AI", "cs.LG", "cs.LO", "I.2.4; I.2.7; J.4"], "pdf": "https://arxiv.org/pdf/2507.07217", "abs": "https://arxiv.org/abs/2507.07217", "authors": ["Zili Wang", "Frank Montabon", "Kristin Yvonne Rozier"], "title": "Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains", "comment": null, "summary": "Supply chain networks are complex systems that are challenging to analyze;\nthis problem is exacerbated when there are illicit activities involved in the\nsupply chain, such as counterfeit parts, forced labor, or human trafficking.\nWhile machine learning (ML) can find patterns in complex systems like supply\nchains, traditional ML techniques require large training data sets. However,\nillicit supply chains are characterized by very sparse data, and the data that\nis available is often (purposely) corrupted or unreliable in order to hide the\nnature of the activities. We need to be able to automatically detect new\npatterns that correlate with such illegal activity over complex, even temporal\ndata, without requiring large training data sets. We explore neurosymbolic\nmethods for identifying instances of illicit activity in supply chains and\ncompare the effectiveness of manual and automated feature extraction from news\narticles accurately describing illicit activities uncovered by authorities. We\npropose a question tree approach for querying a large language model (LLM) to\nidentify and quantify the relevance of articles. This enables a systematic\nevaluation of the differences between human and machine classification of news\narticles related to forced labor in supply chains."}
{"id": "2507.07258", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07258", "abs": "https://arxiv.org/abs/2507.07258", "authors": ["Rami Darwish", "Mahmoud Abdelsalam", "Sajad Khorsandroo", "Kaushik Roy"], "title": "FedP3E: Privacy-Preserving Prototype Exchange for Non-IID IoT Malware Detection in Cross-Silo Federated Learning", "comment": null, "summary": "As IoT ecosystems continue to expand across critical sectors, they have\nbecome prominent targets for increasingly sophisticated and large-scale malware\nattacks. The evolving threat landscape, combined with the sensitive nature of\nIoT-generated data, demands detection frameworks that are both\nprivacy-preserving and resilient to data heterogeneity. Federated Learning (FL)\noffers a promising solution by enabling decentralized model training without\nexposing raw data. However, standard FL algorithms such as FedAvg and FedProx\noften fall short in real-world deployments characterized by class imbalance and\nnon-IID data distributions -- particularly in the presence of rare or disjoint\nmalware classes. To address these challenges, we propose FedP3E\n(Privacy-Preserving Prototype Exchange), a novel FL framework that supports\nindirect cross-client representation sharing while maintaining data privacy.\nEach client constructs class-wise prototypes using Gaussian Mixture Models\n(GMMs), perturbs them with Gaussian noise, and transmits only these compact\nsummaries to the server. The aggregated prototypes are then distributed back to\nclients and integrated into local training, supported by SMOTE-based\naugmentation to enhance representation of minority malware classes. Rather than\nrelying solely on parameter averaging, our prototype-driven mechanism enables\nclients to enrich their local models with complementary structural patterns\nobserved across the federation -- without exchanging raw data or gradients.\nThis targeted strategy reduces the adverse impact of statistical heterogeneity\nwith minimal communication overhead. We evaluate FedP3E on the N-BaIoT dataset\nunder realistic cross-silo scenarios with varying degrees of data imbalance."}
{"id": "2507.07891", "categories": ["math.LO", "math.DS", "math.GR"], "pdf": "https://arxiv.org/pdf/2507.07891", "abs": "https://arxiv.org/abs/2507.07891", "authors": ["Petr Naryshkin", "Andrea Vaccaro"], "title": "Hyper-u-amenablity and Hyperfiniteness of Treeable Equivalence Relations", "comment": "19 pages, 2 figures", "summary": "We introduce the notions of u-amenability and hyper-u-amenability for\ncountable Borel equivalence relations, strong forms of amenability that are\nimplied by hyperfiniteness. We show that treeable, hyper-u-amenable countable\nBorel equivalence relations are hyperfinite. One of the corollaries that we get\nis that if a countable Borel equivalence relation is measure-hyperfinite and\nequal to the orbit equivalence relation of a free continuous action of a free\ngroup (with $k \\ge 2$ or $k = \\infty$ generators) on a $\\sigma$-compact Polish\nspace, then it is hyperfinite. We also obtain that if a countable Borel\nequivalence relation is treeable and equal to the orbit equivalence relation of\na Borel action of an amenable group on a standard Borel space, or if it is\ntreeable, amenable and Borel bounded, then it is hyperfinite."}
{"id": "2507.07360", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.07360", "abs": "https://arxiv.org/abs/2507.07360", "authors": ["Nannan Chen", "Yuzhen Qi", "Caihong Yang", "Hongbin Zhao"], "title": "Exact Turán densities in triple systems", "comment": "9 pages, 1 figure", "summary": "In this paper, we prove several new Tur\\'{a}n density results for $3$-graphs.\nWe show: $\\pi(C_4^3, \\mathrm{complement\\ of\\ } F_5) = 2\\sqrt{3} - 3$,\n$\\pi(F_{3,2}, C_5^{3-}) = \\frac{2}{9}$, and $\\pi(F_{3,2}, \\mathrm{induced\\\ncomplement\\ of\\ } F_{3,2}) = \\frac{3}{8}$. The first result confirms the\nconjecture of Shi~[On Tur\\'an denisties of small triple graphs, European J.\nCombin. 52 (2016) 95-102]. The other results give several special non-principal\nfamily posed by Mubayi and R\\\"odl~[On the Tur\\'an number of triple systems, J.\nCombin. Theory A. 100 (2002) 135-152]."}
{"id": "2507.07428", "categories": ["math.OC", "47H05, 47H09, 47N10, 65K05, 47H04"], "pdf": "https://arxiv.org/pdf/2507.07428", "abs": "https://arxiv.org/abs/2507.07428", "authors": ["Felipe Atenas", "Heinz H. Bauschke", "Minh N. Dao", "Matthew K. Tam"], "title": "Relocated Fixed-Point Iterations with Applications to Variable Stepsize Resolvent Splitting", "comment": "27 pages", "summary": "In this work, we develop a convergence framework for iterative algorithms\nwhose updates can be described by a one-parameter family of nonexpansive\noperators. Within the framework, each step involving one of the main\nalgorithmic operators is followed by a second step which ''relocates''\nfixed-points of the current operator to the next. As a consequence, our\nanalysis does not require the family of nonexpansive operators to have a common\nfixed-point, as is common in the literature. Our analysis uses a parametric\nextension of the demiclosedness principle for nonexpansive operators. As an\napplication of our convergence results, we develop a version of the graph-based\nextension of the Douglas--Rachford algorithm for finding a zero of the sum of\n$N\\geq 2$ maximally monotone operators, which does not require the resolvent\nparameter to be constant across iterations."}
{"id": "2507.07257", "categories": ["cs.AI", "astro-ph.IM", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.07257", "abs": "https://arxiv.org/abs/2507.07257", "authors": ["Licong Xu", "Milind Sarkar", "Anto I. Lonappan", "Íñigo Zubeldia", "Pablo Villanueva-Domingo", "Santiago Casas", "Christian Fidler", "Chetana Amancharla", "Ujjwal Tiwari", "Adrian Bayer", "Chadi Ait Ekiou", "Miles Cranmer", "Adrian Dimitrov", "James Fergusson", "Kahaan Gandhi", "Sven Krippendorf", "Andrew Laverick", "Julien Lesgourgues", "Antony Lewis", "Thomas Meier", "Blake Sherwin", "Kristen Surrao", "Francisco Villaescusa-Navarro", "Chi Wang", "Xueqing Xu", "Boris Bolliet"], "title": "Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery", "comment": "Accepted contribution to the ICML 2025 Workshop on Machine Learning\n  for Astrophysics. Code: https://github.com/CMBAgents/cmbagent; Videos:\n  https://www.youtube.com/@cmbagent; HuggingFace:\n  https://huggingface.co/spaces/astropilot-ai/cmbagent; Cloud:\n  https://cmbagent.cloud", "summary": "We present a multi-agent system for automation of scientific research tasks,\ncmbagent. The system is formed by about 30 Large Language Model (LLM) agents\nand implements a Planning & Control strategy to orchestrate the agentic\nworkflow, with no human-in-the-loop at any point. Each agent specializes in a\ndifferent task (performing retrieval on scientific papers and codebases,\nwriting code, interpreting results, critiquing the output of other agents) and\nthe system is able to execute code locally. We successfully apply cmbagent to\ncarry out a PhD level cosmology task (the measurement of cosmological\nparameters using supernova data) and evaluate its performance on two benchmark\nsets, finding superior performance over state-of-the-art LLMs. The source code\nis available on GitHub, demonstration videos are also available, and the system\nis deployed on HuggingFace and will be available on the cloud."}
{"id": "2507.07401", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07401", "abs": "https://arxiv.org/abs/2507.07401", "authors": ["Fupei Chen", "Liyao Xiang", "Haoxiang Sun", "Hei Victor Cheng", "Kaiming Shen"], "title": "Shuffling for Semantic Secrecy", "comment": null, "summary": "Deep learning draws heavily on the latest progress in semantic\ncommunications. The present paper aims to examine the security aspect of this\ncutting-edge technique from a novel shuffling perspective. Our goal is to\nimprove upon the conventional secure coding scheme to strike a desirable\ntradeoff between transmission rate and leakage rate. To be more specific, for a\nwiretap channel, we seek to maximize the transmission rate while minimizing the\nsemantic error probability under the given leakage rate constraint. Toward this\nend, we devise a novel semantic security communication system wherein the\nrandom shuffling pattern plays the role of the shared secret key. Intuitively,\nthe permutation of feature sequences via shuffling would distort the semantic\nessence of the target data to a sufficient extent so that eavesdroppers cannot\naccess it anymore. The proposed random shuffling method also exhibits its\nflexibility in working for the existing semantic communication system as a\nplugin. Simulations demonstrate the significant advantage of the proposed\nmethod over the benchmark in boosting secure transmission, especially when\nchannels are prone to strong noise and unpredictable fading."}
{"id": "2507.07402", "categories": ["math.CO", "cond-mat.dis-nn", "cond-mat.stat-mech", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2507.07402", "abs": "https://arxiv.org/abs/2507.07402", "authors": ["S. N. Dorogovtsev", "P. L. Krapivsky"], "title": "Deterministic simplicial complexes", "comment": "20 pages, 13 figures", "summary": "We investigate simplicial complexes deterministically growing from a single\nvertex. In the first step, a vertex and an edge connecting it to the primordial\nvertex are added. The resulting simplicial complex has a 1-dimensional simplex\nand two 0-dimensional faces (the vertices). The process continues recursively:\nOn the $n$-th step, every existing $d-$dimensional simplex ($d\\leq n-1$) joins\na new vertex forming a $(d+1)-$dimensional simplex; all $2^{d+1}-2$ new faces\nare also added so that the resulting object remains a simplicial complex. The\nemerging simplicial complex has intriguing local and global characteristics.\nThe number of simplices grows faster than $n!$, and the upper-degree\ndistributions follow a power law. Here, the upper degree (or $d$-degree) of a\n$d$-simplex refers to the number of $(d{+}1)$-simplices that share it as a\nface. Interestingly, the $d$-degree distributions evolve quite differently for\ndifferent values of $d$. We compute the Hodge Laplacian spectra of simplicial\ncomplexes and show that the spectral and Hausdorff dimensions are infinite. We\nalso explore a constrained version where the dimension of the added simplices\nis fixed to a finite value $m$. In the constrained model, the number of\nsimplices grows exponentially. In particular, for $m=1$, the spectral dimension\nis $2$. For $m=2$, the spectral dimension is finite, and the degree\ndistribution follows a power law, while the $1$-degree distribution decays\nexponentially."}
{"id": "2507.07442", "categories": ["math.OC", "math.AP"], "pdf": "https://arxiv.org/pdf/2507.07442", "abs": "https://arxiv.org/abs/2507.07442", "authors": ["Hoai-Minh Nguyen", "Minh-Nguyen Tran"], "title": "On the local null controllability of a viscous Burgers' system in finite time", "comment": null, "summary": "This paper is devoted to the local null controllability of the Burgers\ncontrol system $y_t - y_{xx} + y y_x = u(t)$ on a bounded interval imposed by\nthe zero Dirichlet boundary condition. It is known from the work of Marbach\nthat this control system is not locally null controllable in small time. In\nthis paper, we prove that the system is not locally null controllable in finite\ntime as well. Our approach is inspired by the works of Coron, Koenig, and\nNguyen, and Nguyen on the controllability of the KdV system and is different\nfrom the one of Marbach."}
{"id": "2507.07302", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07302", "abs": "https://arxiv.org/abs/2507.07302", "authors": ["Ashish Kumar"], "title": "Application of LLMs to Multi-Robot Path Planning and Task Allocation", "comment": null, "summary": "Efficient exploration is a well known problem in deep reinforcement learning\nand this problem is exacerbated in multi-agent reinforcement learning due the\nintrinsic complexities of such algorithms. There are several approaches to\nefficiently explore an environment to learn to solve tasks by multi-agent\noperating in that environment, of which, the idea of expert exploration is\ninvestigated in this work. More specifically, this work investigates the\napplication of large-language models as expert planners for efficient\nexploration in planning based tasks for multiple agents."}
{"id": "2507.07406", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07406", "abs": "https://arxiv.org/abs/2507.07406", "authors": ["Jikesh Thapa", "Gurrehmat Chahal", "Serban Voinea Gabreanu", "Yazan Otoum"], "title": "Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models", "comment": "8 Pages, IEEE Conference", "summary": "Phishing attacks are becoming increasingly sophisticated, underscoring the\nneed for detection systems that strike a balance between high accuracy and\ncomputational efficiency. This paper presents a comparative evaluation of\ntraditional Machine Learning (ML), Deep Learning (DL), and quantized\nsmall-parameter Large Language Models (LLMs) for phishing detection. Through\nexperiments on a curated dataset, we show that while LLMs currently\nunderperform compared to ML and DL methods in terms of raw accuracy, they\nexhibit strong potential for identifying subtle, context-based phishing cues.\nWe also investigate the impact of zero-shot and few-shot prompting strategies,\nrevealing that LLM-rephrased emails can significantly degrade the performance\nof both ML and LLM-based detectors. Our benchmarking highlights that models\nlike DeepSeek R1 Distill Qwen 14B (Q8_0) achieve competitive accuracy, above\n80%, using only 17GB of VRAM, supporting their viability for cost-efficient\ndeployment. We further assess the models' adversarial robustness and\ncost-performance tradeoffs, and demonstrate how lightweight LLMs can provide\nconcise, interpretable explanations to support real-time decision-making. These\nfindings position optimized LLMs as promising components in phishing defence\nsystems and offer a path forward for integrating explainable, efficient AI into\nmodern cybersecurity frameworks."}
{"id": "2507.07503", "categories": ["math.CO", "math.GR", "05E16, 05E18"], "pdf": "https://arxiv.org/pdf/2507.07503", "abs": "https://arxiv.org/abs/2507.07503", "authors": ["Roman Gorazd"], "title": "Cocompact unfolding trees", "comment": "Adapted from Thesis chapter, 30 pages, 6 figures", "summary": "This paper will show when a rooted path tree of a finite directed rooted\ngraph has only finitely many orbits under the action of its undirected\nautomorphism group (i.e. when it is cocompact). This will allow us to specify\nwhich trees are almost isomorphic to cocompact trees. We will provide an\nalgorithm that will determine this, thus mostly answering question (1) from\narXiv:2212.07205."}
{"id": "2507.07596", "categories": ["math.OC", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.07596", "abs": "https://arxiv.org/abs/2507.07596", "authors": ["Yuki Nishida"], "title": "Combinatorial Algorithm for Tropical Linearly Factorized Programming", "comment": null, "summary": "The tropical semiring is a set of numbers $\\mathbb{R}\\cup\\{-\\infty\\}$ with\naddition $a\\oplus b:=\\max(a,b)$ and multiplication $a\\otimes b:=a+b$. As well\nas in conventional algebra, linear programming problem in the tropical semiring\nhas been developed. In this study, we introduce a new type of tropical\noptimization problem, namely, tropical linearly factorized programming problem.\nThis problem involves minimizing the objective function given by the product of\ntropical linear forms $c_{k,1}\\otimes x_1\\oplus \\cdots\\oplus c_{k,n}\\otimes\nx_n$ divided by a tropical monomial, subject to tropical linear inequality\nconstraints. The objective function is convex in the conventional sense but not\nin the tropical sense, while the feasible set is convex in the tropical sense\nbut not in the conventional sense.\n  Our algorithm for tropical linearly factorized programming is based on the\ndescent method and exploits tangent digraphs. First, we demonstrate that the\nfeasible descent direction at the current solution can be obtained by solving\nthe minimum $s$-$t$ cut problem on a specific subgraph of the tangent digraph.\nAlthough exponentially many such digraphs may exist in general, a more\nefficient algorithm is devised in cases where the problem is non-degenerate.\nFocusing on the fact that tangent digraphs become spanning trees in\nnon-degenerate cases, we present a simplex-like algorithm that updates the tree\nstructure iteratively. We show that each iteration can be executed in\n$O(r_A+r_C)$ time, where $r_A$ and $r_C$ are the numbers of ``non-zero''\ncoefficients in the linear constraints and objective function, respectively.\nFor integer instances, our algorithm finds a local optimum in\n$O((m+n)(r_A+r_C)MD)$ time, where $n$ and $m$ are the number of decision\nvariables and constraints, respectively, $M$ is the maximum absolute value of\ncoefficients and $D$ is the degree of the objective function."}
{"id": "2507.07306", "categories": ["cs.AI", "cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.07306", "abs": "https://arxiv.org/abs/2507.07306", "authors": ["Yichen Lu", "Wei Dai", "Jiaen Liu", "Ching Wing Kwok", "Zongheng Wu", "Xudong Xiao", "Ao Sun", "Sheng Fu", "Jianyuan Zhan", "Yian Wang", "Takatomo Saito", "Sicheng Lai"], "title": "ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning", "comment": null, "summary": "LLM-based translation agents have achieved highly human-like translation\nresults and are capable of handling longer and more complex contexts with\ngreater efficiency. However, they are typically limited to text-only inputs. In\nthis paper, we introduce ViDove, a translation agent system designed for\nmultimodal input. Inspired by the workflow of human translators, ViDove\nleverages visual and contextual background information to enhance the\ntranslation process. Additionally, we integrate a multimodal memory system and\nlong-short term memory modules enriched with domain-specific knowledge,\nenabling the agent to perform more accurately and adaptively in real-world\nscenarios. As a result, ViDove achieves significantly higher translation\nquality in both subtitle generation and general translation tasks, with a 28%\nimprovement in BLEU scores and a 15% improvement in SubER compared to previous\nstate-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark\nfor long-form automatic video subtitling and translation, featuring 17 hours of\nhigh-quality, human-annotated data. Our code is available here:\nhttps://github.com/pigeonai-org/ViDove"}
{"id": "2507.07413", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07413", "abs": "https://arxiv.org/abs/2507.07413", "authors": ["Mohammad F. Al-Hammouri", "Yazan Otoum", "Rasha Atwa", "Amiya Nayak"], "title": "Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks", "comment": "6 pages, IEEE conference", "summary": "This paper presents a novel approach to intrusion detection by integrating\ntraditional signature-based methods with the contextual understanding\ncapabilities of the GPT-2 Large Language Model (LLM). As cyber threats become\nincreasingly sophisticated, particularly in distributed, heterogeneous, and\nresource-constrained environments such as those enabled by the Internet of\nThings (IoT), the need for dynamic and adaptive Intrusion Detection Systems\n(IDSs) becomes increasingly urgent. While traditional methods remain effective\nfor detecting known threats, they often fail to recognize new and evolving\nattack patterns. In contrast, GPT-2 excels at processing unstructured data and\nidentifying complex semantic relationships, making it well-suited to uncovering\nsubtle, zero-day attack vectors. We propose a hybrid IDS framework that merges\nthe robustness of signature-based techniques with the adaptability of\nGPT-2-driven semantic analysis. Experimental evaluations on a representative\nintrusion dataset demonstrate that our model enhances detection accuracy by\n6.3%, reduces false positives by 9.0%, and maintains near real-time\nresponsiveness. These results affirm the potential of language model\nintegration to build intelligent, scalable, and resilient cybersecurity\ndefences suited for modern connected environments."}
{"id": "2507.07594", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.07594", "abs": "https://arxiv.org/abs/2507.07594", "authors": ["Jeck Lim", "Jiaxi Nie", "Ji Zeng"], "title": "Evasive sets, twisted varieties, and container-clique trees", "comment": null, "summary": "In the affine space $\\mathbb{F}_q^n$ over the finite field of order $q$, a\npoint set $S$ is said to be $(d,k,r)$-evasive if the intersection between $S$\nand any variety, of dimension $k$ and degree at most $d$, has cardinality less\nthan $r$. As $q$ tends to infinity, the size of a $(d,k,r)$-evasive set in\n$\\mathbb{F}_q^n$ is at most $O\\left(q^{n-k}\\right)$ by a simple averaging\nargument. We exhibit the existence of such evasive sets of sizes at least\n$\\Omega\\left(q^{n-k}\\right)$ for much smaller values of $r$ than previously\nknown constructions, and establish an enumerative upper bound $2^{O(q^{n-k})}$\nfor the total number of such evasive sets. The existence result is based on our\nstudy of twisted varieties. In the projective space $\\mathbb{P}^n$ over an\nalgebraically closed field, a variety $V$ is said to be $d$-twisted if the\nintersection between $V$ and any variety, of dimension $n - \\dim(V)$ and degree\nat most $d$, has dimension zero. We prove an upper bound on the smallest\npossible degree of twisted varieties which is best possible in a mild sense.\nThe enumeration result includes a new technique for the container method which\nwe believe is of independent interest. To illustrate the potential of this\ntechnique, we give a simpler proof of a result by Chen--Liu--Nie--Zeng that\ncharacterizes the maximum size of a collinear-triple-free subset in a random\nsampling of $ \\mathbb{F}_q^2$ up to polylogarithmic factors."}
{"id": "2507.07674", "categories": ["math.OC", "26A33, 90C29, 90C25, 65K99, 49M05"], "pdf": "https://arxiv.org/pdf/2507.07674", "abs": "https://arxiv.org/abs/2507.07674", "authors": ["Barsha Shaw", "Md Abu Talhamainuddin Ansary"], "title": "An Adaptive Order Caputo Fractional Gradient Descent Method for Multi-objective Optimization Problems", "comment": "23 Pages; 5 Figures (10 subfigures); 3 Tables", "summary": "This article introduces the multi-objective adaptive order Caputo fractional\ngradient descent (MOAOCFGD) algorithm for solving unconstrained multi-objective\nproblems. The proposed method performs equally well for both smooth and\nnon-smooth multi-objective optimization problems. Moreover, the proposed method\ndoes not require any a priori chosen parameters or ordering information of the\nobjective functions. At every iteration of the proposed method, a subproblem is\nsolved to identify a suitable descent direction toward an optimal solution.\nThis subproblem involves an adaptive-order Caputo fractional gradient for each\nobjective function. An Armijo-type line search is applied to determine a\nsuitable step length. The convergence of this method for the\nTikhonov-regularized solution is justified under mild assumptions. The proposed\nmethod is verified using different numerical problems, including neural\nnetworks."}
{"id": "2507.07341", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07341", "abs": "https://arxiv.org/abs/2507.07341", "authors": ["Sarah Ball", "Greg Gluch", "Shafi Goldwasser", "Frauke Kreuter", "Omer Reingold", "Guy N. Rothblum"], "title": "On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment", "comment": null, "summary": "With the increased deployment of large language models (LLMs), one concern is\ntheir potential misuse for generating harmful content. Our work studies the\nalignment challenge, with a focus on filters to prevent the generation of\nunsafe information. Two natural points of intervention are the filtering of the\ninput prompt before it reaches the model, and filtering the output after\ngeneration. Our main results demonstrate computational challenges in filtering\nboth prompts and outputs. First, we show that there exist LLMs for which there\nare no efficient prompt filters: adversarial prompts that elicit harmful\nbehavior can be easily constructed, which are computationally indistinguishable\nfrom benign prompts for any efficient filter. Our second main result identifies\na natural setting in which output filtering is computationally intractable. All\nof our separation results are under cryptographic hardness assumptions. In\naddition to these core findings, we also formalize and study relaxed mitigation\napproaches, demonstrating further computational barriers. We conclude that\nsafety cannot be achieved by designing filters external to the LLM internals\n(architecture and weights); in particular, black-box access to the LLM will not\nsuffice. Based on our technical results, we argue that an aligned AI system's\nintelligence cannot be separated from its judgment."}
{"id": "2507.07416", "categories": ["cs.CR", "cs.AI", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07416", "abs": "https://arxiv.org/abs/2507.07416", "authors": ["Jenifer Paulraj", "Brindha Raghuraman", "Nagarani Gopalakrishnan", "Yazan Otoum"], "title": "Autonomous AI-based Cybersecurity Framework for Critical Infrastructure: Real-Time Threat Mitigation", "comment": "7 pages, IEEE conference", "summary": "Critical infrastructure systems, including energy grids, healthcare\nfacilities, transportation networks, and water distribution systems, are\npivotal to societal stability and economic resilience. However, the increasing\ninterconnectivity of these systems exposes them to various cyber threats,\nincluding ransomware, Denial-of-Service (DoS) attacks, and Advanced Persistent\nThreats (APTs). This paper examines cybersecurity vulnerabilities in critical\ninfrastructure, highlighting the threat landscape, attack vectors, and the role\nof Artificial Intelligence (AI) in mitigating these risks. We propose a hybrid\nAI-driven cybersecurity framework to enhance real-time vulnerability detection,\nthreat modelling, and automated remediation. This study also addresses the\ncomplexities of adversarial AI, regulatory compliance, and integration. Our\nfindings provide actionable insights to strengthen the security and resilience\nof critical infrastructure systems against emerging cyber threats."}
{"id": "2507.07656", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.07656", "abs": "https://arxiv.org/abs/2507.07656", "authors": ["Xiang Chen", "Shuai Kou", "Chengfu Qin", "Liqiong Xu", "Weihua Yang"], "title": "A constructive characterization of uniformly 4-connected graphs", "comment": null, "summary": "A constructive characterization of the class of uniformly $4$-connected\ngraphs is presented. The characterization is based on the application of graph\noperations to appropriate vertex and edge sets in uniformly $4$-connected\ngraphs, that is, any uniformly $4$-connected graph can be obtained from $C_5^2$\nor $C_6^2$ by a number of $\\Delta_1^+$ or $\\Delta_2^+$-operations to quasi\n$4$-compatible sets."}
{"id": "2507.07729", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.07729", "abs": "https://arxiv.org/abs/2507.07729", "authors": ["André Carlon", "Luis Espath", "Raúl Tempone"], "title": "Efficient Stochastic BFGS methods Inspired by Bayesian Principles", "comment": "18 pages, 4 figures", "summary": "Quasi-Newton methods are ubiquitous in deterministic local search due to\ntheir efficiency and low computational cost. This class of methods uses the\nhistory of gradient evaluations to approximate second-order derivatives.\nHowever, only noisy gradient observations are accessible in stochastic\noptimization; thus, deriving quasi-Newton methods in this setting is\nchallenging. Although most existing quasi-Newton methods for stochastic\noptimization rely on deterministic equations that are modified to circumvent\nnoise, we propose a new approach inspired by Bayesian inference to assimilate\nnoisy gradient information and derive the stochastic counterparts to standard\nquasi-Newton methods. We focus on the derivations of stochastic BFGS and\nL-BFGS, but our methodology can also be employed to derive stochastic analogs\nof other quasi-Newton methods. The resulting stochastic BFGS (S-BFGS) and\nstochastic L-BFGS (L-S-BFGS) can effectively learn an inverse Hessian\napproximation even with small batch sizes. For a problem of dimension $d$, the\niteration cost of S-BFGS is $\\bigO{d^2}$, and the cost of L-S-BFGS is\n$\\bigO{d}$. Numerical experiments with a dimensionality of up to $30,720$\ndemonstrate the efficiency and robustness of the proposed method."}
{"id": "2507.07355", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07355", "abs": "https://arxiv.org/abs/2507.07355", "authors": ["Haoyue Bai", "Haoyu Wang", "Nanxu Gong", "Xinyuan Wang", "Wangyang Ying", "Haifeng Chen", "Yanjie Fu"], "title": "Supply Chain Optimization via Generative Simulation and Iterative Decision Policies", "comment": null, "summary": "High responsiveness and economic efficiency are critical objectives in supply\nchain transportation, both of which are influenced by strategic decisions on\nshipping mode. An integrated framework combining an efficient simulator with an\nintelligent decision-making algorithm can provide an observable, low-risk\nenvironment for transportation strategy design. An ideal simulation-decision\nframework must (1) generalize effectively across various settings, (2) reflect\nfine-grained transportation dynamics, (3) integrate historical experience with\npredictive insights, and (4) maintain tight integration between simulation\nfeedback and policy refinement. We propose Sim-to-Dec framework to satisfy\nthese requirements. Specifically, Sim-to-Dec consists of a generative\nsimulation module, which leverages autoregressive modeling to simulate\ncontinuous state changes, reducing dependence on handcrafted domain-specific\nrules and enhancing robustness against data fluctuations; and a history-future\ndual-aware decision model, refined iteratively through end-to-end optimization\nwith simulator interactions. Extensive experiments conducted on three\nreal-world datasets demonstrate that Sim-to-Dec significantly improves timely\ndelivery rates and profit."}
{"id": "2507.07417", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.07417", "abs": "https://arxiv.org/abs/2507.07417", "authors": ["Nishit V. Pandya", "Andrey Labunets", "Sicun Gao", "Earlence Fernandes"], "title": "May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks", "comment": null, "summary": "A popular class of defenses against prompt injection attacks on large\nlanguage models (LLMs) relies on fine-tuning the model to separate instructions\nand data, so that the LLM does not follow instructions that might be present\nwith data. There are several academic systems and production-level\nimplementations of this idea. We evaluate the robustness of this class of\nprompt injection defenses in the whitebox setting by constructing strong\noptimization-based attacks and showing that the defenses do not provide the\nclaimed security properties. Specifically, we construct a novel attention-based\nattack algorithm for text-based LLMs and apply it to two recent whitebox\ndefenses SecAlign (CCS 2025) and StruQ (USENIX Security 2025), showing attacks\nwith success rates of up to 70% with modest increase in attacker budget in\nterms of tokens. Our findings make fundamental progress towards understanding\nthe robustness of prompt injection defenses in the whitebox setting. We release\nour code and attacks at https://github.com/nishitvp/better_opts_attacks"}
{"id": "2507.07736", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.07736", "abs": "https://arxiv.org/abs/2507.07736", "authors": ["Meiqi Peng", "Yuefeng Yang", "Wenying Zhu"], "title": "Regular sets in Cayley sum graphs on generalized dicyclic groups", "comment": null, "summary": "For a graph $\\Gamma=(V(\\Gamma),E(\\Gamma))$, a subset $C$ of $V(\\Gamma)$ is\ncalled an $(\\alpha,\\beta)$-regular set in $\\Gamma$, if every vertex of $C$ is\nadjacent to exactly $\\alpha$ vertices of $C$ and every vertex of\n$V(\\Gamma)\\setminus C$ is adjacent to exactly $\\beta$ vertices of $C$. In\nparticular, if $C$ is an $(\\alpha,\\beta)$-regular set in some Cayley sum graph\nof a finite group $G$ with connection set $S$, then $C$ is called an\n$(\\alpha,\\beta)$-regular set of $G$. In this paper, we consider a generalized\ndicyclic group $G$ and for each subgroup $H$ of $G$, by giving an appropriate\nconnection set $S$, we determine each possibility for $(\\alpha,\\beta)$ such\nthat $H$ is an $(\\alpha,\\beta)$-regular set of $G$."}
{"id": "2507.07749", "categories": ["math.OC", "93C40, 49N30, 93D21, 93C95"], "pdf": "https://arxiv.org/pdf/2507.07749", "abs": "https://arxiv.org/abs/2507.07749", "authors": ["Alexander Zuyev", "Victoria Grushkovska"], "title": "A Model-Free Extremum Seeking Controller with Application to Tracking a Nonlinear Chemical Reaction", "comment": "Submitted to the 11th International Conference on Control, Decision\n  and Information Technologies (CoDIT 2025)", "summary": "In this paper, we develop the extremum-seeking approach to generate\nadmissible trajectories in a neighborhood of a given reference curve in the\nstate space. The cost function of the problem represents the distance between\nthe current system state and the reference curve, which is parameterized as a\nfunction of time. Such reference curves naturally arise as optimal trajectories\nin isoperimetric optimization problems for nonlinear chemical reactions, where\nthe objective is to maximize the average reaction product over a given period.\nWe apply the proposed extremum seeking control design to a nonisothermal\nreaction model and illustrate the resulting tracking errors through numerical\nsimulations."}
{"id": "2507.07426", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07426", "abs": "https://arxiv.org/abs/2507.07426", "authors": ["Zerui Yang", "Yuwei Wan", "Yinqiao Li", "Yudai Matsuda", "Tong Xie", "Linqi Song"], "title": "DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search", "comment": null, "summary": "Recent advances in large language models have demonstrated considerable\npotential in scientific domains such as drug discovery. However, their\neffectiveness remains constrained when reasoning extends beyond the knowledge\nacquired during pretraining. Conventional approaches, such as fine-tuning or\nretrieval-augmented generation, face limitations in either imposing high\ncomputational overhead or failing to fully exploit structured scientific data.\nTo overcome these challenges, we propose DrugMCTS, a novel framework that\nsynergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree\nSearch for drug repurposing. The framework employs five specialized agents\ntasked with retrieving and analyzing molecular and protein information, thereby\nenabling structured and iterative reasoning. Without requiring domain-specific\nfine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by\nover 20\\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate\nthat DrugMCTS achieves substantially higher recall and robustness compared to\nboth general-purpose LLMs and deep learning baselines. Our results highlight\nthe importance of structured reasoning, agent-based collaboration, and\nfeedback-driven search mechanisms in advancing LLM applications for drug\ndiscovery."}
{"id": "2507.07732", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07732", "abs": "https://arxiv.org/abs/2507.07732", "authors": ["Giovanni Gambigliani Zoccoli", "Filip Valgimigli", "Dario Stabili", "Mirco Marchetti"], "title": "RADAR: a Radio-based Analytics for Dynamic Association and Recognition of pseudonyms in VANETs", "comment": "7 pages, 4 figures, accepted for publication at the 2025 IEEE 102nd\n  Vehicular Technology Conference: VTC2025-Fall", "summary": "This paper presents RADAR, a tracking algorithm for vehicles participating in\nCooperative Intelligent Transportation Systems (C-ITS) that exploits multiple\nradio signals emitted by a modern vehicle to break privacy-preserving pseudonym\nschemes deployed in VANETs. This study shows that by combining Dedicated Short\nRange Communication (DSRC) and Wi-Fi probe request messages broadcast by the\nvehicle, it is possible to improve tracking over standard de-anonymization\napproaches that only leverage DSRC, especially in realistic scenarios where the\nattacker does not have full coverage of the entire vehicle path. The\nexperimental evaluation compares three different metrics for pseudonym and\nWi-Fi probe identifier association (Count, Statistical RSSI, and Pearson RSSI),\ndemonstrating that the Pearson RSSI metric is better at tracking vehicles under\npseudonym-changing schemes in all scenarios and against previous works. As an\nadditional contribution to the state-of-the-art, we publicly release all\nimplementations and simulation scenarios used in this work."}
{"id": "2507.07951", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.07951", "abs": "https://arxiv.org/abs/2507.07951", "authors": ["Pavlo Savchuk"], "title": "Constructing Optimal Kobon Triangle Arrangements via Table Encoding, SAT Solving, and Heuristic Straightening", "comment": "21 pages, 15 figures", "summary": "We present new methods and results for constructing optimal Kobon triangle\narrangements. First, we introduce a compact table notation for describing\narrangements of pseudolines, enabling the representation and analysis of\ncomplex cases, including symmetrical arrangements, arrangements with parallel\nlines, and arrangements with multiple-line intersection points. Building on\nthis, we provide a simple heuristic method and tools for recovering\nstraight-line arrangements from a given table, with the ability to enforce\nadditional properties such as symmetries. The tool successfully recovers\narrangements for many previously known optimal solutions. Additionally, we\ndevelop a tool that transforms the search for optimal Kobon arrangement tables\ninto a SAT problem, allowing us to leverage modern SAT solvers (specifically\nKissat) to efficiently find new solutions or to show that no other solutions\nexist (for example, confirming that no optimal solution exists in the 11-line\ncase). Using these techniques, we find new optimal Kobon arrangements for 23\nand 27 lines, along with several other new results."}
{"id": "2507.07812", "categories": ["math.OC", "math.FA", "46N10, 49M27, 49N10, 65M55, 65Y05"], "pdf": "https://arxiv.org/pdf/2507.07812", "abs": "https://arxiv.org/abs/2507.07812", "authors": ["Bálint Farkas", "Birgit Jacob", "Manuel Schaller", "Merlin Schmitz"], "title": "Dissipativity-based time domain decomposition for optimal control of hyperbolic PDEs", "comment": "24 pages, 4 figures", "summary": "We propose a time domain decomposition approach to optimal control of partial\ndifferential equations (PDEs) based on semigroup theoretic methods. We\nformulate the optimality system consisting of two coupled forward-backward\nPDEs, the state and adjoint equation, as a sum of dissipative operators, which\nenables a Peaceman-Rachford-type fixed-point iteration. The iteration steps may\nbe understood and implemented as solutions of many decoupled, and therefore\nhighly parallelizable, time-distributed optimal control problems. We prove the\nconvergence of the state, the control, and the corresponding adjoint state in\nfunction space. Due to the general framework of $C_0$-(semi)groups, the results\nare particularly well applicable, e.g., to hyperbolic equations, such as beam\nor wave equations. We illustrate the convergence and efficiency of the proposed\nmethod by means of two numerical examples subject to a 2D wave equation and a\n3D heat equation."}
{"id": "2507.07445", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07445", "abs": "https://arxiv.org/abs/2507.07445", "authors": ["Weihao Tan", "Changjiu Jiang", "Yu Duan", "Mingcong Lei", "Jiageng Li", "Yitian Hong", "Xinrun Wang", "Bo An"], "title": "StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley", "comment": "Project website: https://weihaotan.github.io/StarDojo", "summary": "Autonomous agents navigating human society must master both production\nactivities and social interactions, yet existing benchmarks rarely evaluate\nthese skills simultaneously. To bridge this gap, we introduce StarDojo, a novel\nbenchmark based on Stardew Valley, designed to assess AI agents in open-ended\nproduction-living simulations. In StarDojo, agents are tasked to perform\nessential livelihood activities such as farming and crafting, while\nsimultaneously engaging in social interactions to establish relationships\nwithin a vibrant community. StarDojo features 1,000 meticulously curated tasks\nacross five key domains: farming, crafting, exploration, combat, and social\ninteractions. Additionally, we provide a compact subset of 100 representative\ntasks for efficient model evaluation. The benchmark offers a unified,\nuser-friendly interface that eliminates the need for keyboard and mouse\ncontrol, supports all major operating systems, and enables the parallel\nexecution of multiple environment instances, making it particularly well-suited\nfor evaluating the most capable foundation agents, powered by multimodal large\nlanguage models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents\ndemonstrate substantial limitations, with the best-performing model, GPT-4.1,\nachieving only a 12.7% success rate, primarily due to challenges in visual\nunderstanding, multimodal reasoning and low-level manipulation. As a\nuser-friendly environment and benchmark, StarDojo aims to facilitate further\nresearch towards robust, open-ended agents in complex production-living\nenvironments."}
{"id": "2507.07773", "categories": ["cs.CR", "cs.CV", "B.8; I.4"], "pdf": "https://arxiv.org/pdf/2507.07773", "abs": "https://arxiv.org/abs/2507.07773", "authors": ["Youqian Zhang", "Xinyu Ji", "Zhihao Wang", "Qinhong Jiang"], "title": "Rainbow Artifacts from Electromagnetic Signal Injection Attacks on Image Sensors", "comment": "5 pages, 4 figures", "summary": "Image sensors are integral to a wide range of safety- and security-critical\nsystems, including surveillance infrastructure, autonomous vehicles, and\nindustrial automation. These systems rely on the integrity of visual data to\nmake decisions. In this work, we investigate a novel class of electromagnetic\nsignal injection attacks that target the analog domain of image sensors,\nallowing adversaries to manipulate raw visual inputs without triggering\nconventional digital integrity checks. We uncover a previously undocumented\nattack phenomenon on CMOS image sensors: rainbow-like color artifacts induced\nin images captured by image sensors through carefully tuned electromagnetic\ninterference. We further evaluate the impact of these attacks on\nstate-of-the-art object detection models, showing that the injected artifacts\npropagate through the image signal processing pipeline and lead to significant\nmispredictions. Our findings highlight a critical and underexplored\nvulnerability in the visual perception stack, highlighting the need for more\nrobust defenses against physical-layer attacks in such systems."}
{"id": "2507.07673", "categories": ["math.NT", "math.CO", "51E21, 05B25, 11A15"], "pdf": "https://arxiv.org/pdf/2507.07673", "abs": "https://arxiv.org/abs/2507.07673", "authors": ["Bhawesh Mishra", "Paolo Santonastaso"], "title": "Prime Power Residues and Blocking Sets", "comment": "Accepted for publication in Journal de Th\\'eorie des Nombres de\n  Bordeaux", "summary": "Let $q$ be a fixed odd prime. We show that a finite subset $B$ of integers,\nnot containing any perfect $q^{th}$ power, contains a $q^{th}$ power modulo\nalmost every prime if and only if $B$ corresponds to a blocking set (with\nrespect to hyperplanes) in $\\mathrm{PG}(\\mathbb{F}_{q}^{k})$. Here, $k$ is the\nnumber of distinct prime divisors of $q$-free parts of elements of $B$. As a\nconsequence, the property of a subset $B$ to contain $q^{th}$ power modulo\nalmost every prime $p$ is invariant under geometric $q$-equivalence defined by\nan element of the projective general linear group\n$\\mathrm{PGL}(\\mathbb{F}_{q}^{k})$. Employing this connection between two\ndisparate branches of mathematics, Galois geometry and number theory, we\nclassify, and provide bounds on the sizes of, minimal such sets $B$."}
{"id": "2507.07894", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.07894", "abs": "https://arxiv.org/abs/2507.07894", "authors": ["Dominik Leib", "Susanne Fritzler", "Neele Leithäuser"], "title": "Complexity Analysis of a Bicriteria Directed Multimodal Transportation Network Design Problem", "comment": null, "summary": "In this paper, we address a bicriteria network design problem that arises\nfrom practical applications in urban and rural public transportation planning.\nWe establish the problem's complexity and demonstrate inapproximability\nresults, highlighting the inherent difficulties in finding optimal solutions.\nAdditionally, we identify special cases where approximability can be achieved,\nproviding valuable insights for practitioners. Our proofs leverage complexity\nresults related to directed network design problems, an area that has received\nlimited attention in the existing literature. By investigating these complexity\nresults, we aim to fill a critical gap and enhance the understanding of the\ninterplay between bicriteria decision-making and network design challenges."}
{"id": "2507.07544", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07544", "abs": "https://arxiv.org/abs/2507.07544", "authors": ["Oliver Eberle", "Thomas McGee", "Hamza Giaffar", "Taylor Webb", "Ida Momennejad"], "title": "Position: We Need An Algorithmic Understanding of Generative AI", "comment": "Accepted at ICML 2025 as a Spotlight Position Paper", "summary": "What algorithms do LLMs actually learn and use to solve problems? Studies\naddressing this question are sparse, as research priorities are focused on\nimproving performance through scale, leaving a theoretical and empirical gap in\nunderstanding emergent algorithms. This position paper proposes AlgEval: a\nframework for systematic research into the algorithms that LLMs learn and use.\nAlgEval aims to uncover algorithmic primitives, reflected in latent\nrepresentations, attention, and inference-time compute, and their algorithmic\ncomposition to solve task-specific problems. We highlight potential\nmethodological paths and a case study toward this goal, focusing on emergent\nsearch algorithms. Our case study illustrates both the formation of top-down\nhypotheses about candidate algorithms, and bottom-up tests of these hypotheses\nvia circuit-level analysis of attention patterns and hidden states. The\nrigorous, systematic evaluation of how LLMs actually solve tasks provides an\nalternative to resource-intensive scaling, reorienting the field toward a\nprincipled understanding of underlying computations. Such algorithmic\nexplanations offer a pathway to human-understandable interpretability, enabling\ncomprehension of the model's internal reasoning performance measures. This can\nin turn lead to more sample-efficient methods for training and improving\nperformance, as well as novel architectures for end-to-end and multi-agent\nsystems."}
{"id": "2507.07871", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07871", "abs": "https://arxiv.org/abs/2507.07871", "authors": ["Toluwani Aremu", "Noor Hussein", "Munachiso Nwadike", "Samuele Poppi", "Jie Zhang", "Karthik Nandakumar", "Neil Gong", "Nils Lukas"], "title": "Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking", "comment": null, "summary": "Watermarking offers a promising solution for GenAI providers to establish the\nprovenance of their generated content. A watermark is a hidden signal embedded\nin the generated content, whose presence can later be verified using a secret\nwatermarking key. A threat to GenAI providers are \\emph{watermark stealing}\nattacks, where users forge a watermark into content that was \\emph{not}\ngenerated by the provider's models without access to the secret key, e.g., to\nfalsely accuse the provider. Stealing attacks collect \\emph{harmless}\nwatermarked samples from the provider's model and aim to maximize the expected\nsuccess rate of generating \\emph{harmful} watermarked samples. Our work focuses\non mitigating stealing attacks while treating the underlying watermark as a\nblack-box. Our contributions are: (i) Proposing a multi-key extension to\nmitigate stealing attacks that can be applied post-hoc to any watermarking\nmethod across any modality. (ii) We provide theoretical guarantees and\ndemonstrate empirically that our method makes forging substantially less\neffective across multiple datasets, and (iii) we formally define the threat of\nwatermark forging as the task of generating harmful, watermarked content and\nmodel this threat via security games."}
{"id": "2507.07942", "categories": ["cs.DM", "cs.CC", "cs.LO", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.07942", "abs": "https://arxiv.org/abs/2507.07942", "authors": ["Joshua Brakensiek", "Venkatesan Guruswami", "Bart M. P. Jansen", "Victor Lagerkvist", "Magnus Wahlström"], "title": "The Richness of CSP Non-redundancy", "comment": "82 pages, 5 figures", "summary": "In the field of constraint satisfaction problems (CSP), a clause is called\nredundant if its satisfaction is implied by satisfying all other clauses. An\ninstance of CSP$(P)$ is called non-redundant if it does not contain any\nredundant clause. The non-redundancy (NRD) of a predicate $P$ is the maximum\nnumber of clauses in a non-redundant instance of CSP$(P)$, as a function of the\nnumber of variables $n$. Recent progress has shown that non-redundancy is\ncrucially linked to many other important questions in computer science and\nmathematics including sparsification, kernelization, query complexity,\nuniversal algebra, and extremal combinatorics. Given that non-redundancy is a\nnexus for many of these important problems, the central goal of this paper is\nto more deeply understand non-redundancy.\n  Our first main result shows that for every rational number $r \\ge 1$, there\nexists a finite CSP predicate $P$ such that the non-redundancy of $P$ is\n$\\Theta(n^r)$. Our second main result explores the concept of conditional\nnon-redundancy first coined by Brakensiek and Guruswami [STOC 2025]. We\ncompletely classify the conditional non-redundancy of all binary predicates\n(i.e., constraints on two variables) by connecting these non-redundancy\nproblems to the structure of high-girth graphs in extremal combinatorics.\n  Inspired by these concrete results, we build off the work of Carbonnel [CP\n2022] to develop an algebraic theory of conditional non-redundancy. As an\napplication of this algebraic theory, we revisit the notion of Mal'tsev\nembeddings, which is the most general technique known to date for establishing\nthat a predicate has linear non-redundancy. For example, we provide the first\nexample of predicate with a Mal'tsev embedding that cannot be attributed to the\nstructure of an Abelian group, but rather to the structure of the quantum Pauli\ngroup."}
{"id": "2507.07917", "categories": ["math.OC", "cs.NA", "math.NA", "Primary: 49Q22, Secondary: 49N15, 94A17"], "pdf": "https://arxiv.org/pdf/2507.07917", "abs": "https://arxiv.org/abs/2507.07917", "authors": ["Luca Nenna", "Paul Pegon", "Louis Tocquec"], "title": "Convergence rates for regularized unbalanced optimal transport: the discrete case", "comment": "27 pages, 10 figures", "summary": "Unbalanced optimal transport (UOT) is a natural extension of optimal\ntransport (OT) allowing comparison between measures of different masses. It\narises naturally in machine learning by offering a robustness against outliers.\nThe aim of this work is to provide convergence rates of the regularized\ntransport cost and plans towards their original solution when both measures are\nweighted sums of Dirac masses."}
{"id": "2507.07576", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.07576", "abs": "https://arxiv.org/abs/2507.07576", "authors": ["Mohamed Siala", "Jordi Planes", "Joao Marques-Silva"], "title": "On Trustworthy Rule-Based Models and Explanations", "comment": null, "summary": "A task of interest in machine learning (ML) is that of ascribing explanations\nto the predictions made by ML models. Furthermore, in domains deemed high risk,\nthe rigor of explanations is paramount. Indeed, incorrect explanations can and\nwill mislead human decision makers. As a result, and even if interpretability\nis acknowledged as an elusive concept, so-called interpretable models are\nemployed ubiquitously in high-risk uses of ML and data mining (DM). This is the\ncase for rule-based ML models, which encompass decision trees, diagrams, sets\nand lists. This paper relates explanations with well-known undesired facets of\nrule-based ML models, which include negative overlap and several forms of\nredundancy. The paper develops algorithms for the analysis of these undesired\nfacets of rule-based systems, and concludes that well-known and widely used\ntools for learning rule-based ML models will induce rule sets that exhibit one\nor more negative facets."}
{"id": "2507.07901", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07901", "abs": "https://arxiv.org/abs/2507.07901", "authors": ["Sree Bhargavi Balija", "Rekha Singal", "Abhishek Singh", "Ramesh Raskar", "Erfan Darzi", "Raghu Bala", "Thomas Hardjono", "Ken Huang"], "title": "The Trust Fabric: Decentralized Interoperability and Economic Coordination for the Agentic Web", "comment": null, "summary": "The fragmentation of AI agent ecosystems has created urgent demands for\ninteroperability, trust, and economic coordination that current protocols --\nincluding MCP (Hou et al., 2025), A2A (Habler et al., 2025), ACP (Liu et al.,\n2025), and Cisco's AGP (Edwards, 2025) -- cannot address at scale. We present\nthe Nanda Unified Architecture, a decentralized framework built around three\ncore innovations: fast DID-based agent discovery through distributed\nregistries, semantic agent cards with verifiable credentials and composability\nprofiles, and a dynamic trust layer that integrates behavioral attestations\nwith policy compliance. The system introduces X42/H42 micropayments for\neconomic coordination and MAESTRO, a security framework incorporating\nSynergetics' patented AgentTalk protocol (US Patent 12,244,584 B1) and secure\ncontainerization. Real-world deployments demonstrate 99.9 percent compliance in\nhealthcare applications and substantial monthly transaction volumes with strong\nprivacy guarantees. By unifying MIT's trust research with production\ndeployments from Cisco and Synergetics, we show how cryptographic proofs and\npolicy-as-code transform agents into trust-anchored participants in a\ndecentralized economy (Lakshmanan, 2025; Sha, 2025). The result enables a\nglobally interoperable Internet of Agents where trust becomes the native\ncurrency of collaboration across both enterprise and Web3 ecosystems."}
{"id": "2507.07595", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07595", "abs": "https://arxiv.org/abs/2507.07595", "authors": ["Zhixiang Su", "Di Wang", "Chunyan Miao"], "title": "Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs", "comment": null, "summary": "Recent investigations on the effectiveness of Graph Neural Network\n(GNN)-based models for link prediction in Knowledge Graphs (KGs) show that\nvanilla aggregation does not significantly impact the model performance. In\nthis paper, we introduce a novel method, named Context Pooling, to enhance\nGNN-based models' efficacy for link predictions in KGs. To our best of\nknowledge, Context Pooling is the first methodology that applies graph pooling\nin KGs. Additionally, Context Pooling is first-of-its-kind to enable the\ngeneration of query-specific graphs for inductive settings, where testing\nentities are unseen during training. Specifically, we devise two metrics,\nnamely neighborhood precision and neighborhood recall, to assess the neighbors'\nlogical relevance regarding the given queries, thereby enabling the subsequent\ncomprehensive identification of only the logically relevant neighbors for link\nprediction. Our method is generic and assessed by being applied to two\nstate-of-the-art (SOTA) models on three public transductive and inductive\ndatasets, achieving SOTA performance in 42 out of 48 settings."}
{"id": "2507.07916", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.07916", "abs": "https://arxiv.org/abs/2507.07916", "authors": ["Federico Maria Cau", "Giuseppe Desolda", "Francesco Greco", "Lucio Davide Spano", "Luca Viganò"], "title": "Can Large Language Models Improve Phishing Defense? A Large-Scale Controlled Experiment on Warning Dialogue Explanations", "comment": null, "summary": "Phishing has become a prominent risk in modern cybersecurity, often used to\nbypass technological defences by exploiting predictable human behaviour.\nWarning dialogues are a standard mitigation measure, but the lack of\nexplanatory clarity and static content limits their effectiveness. In this\npaper, we report on our research to assess the capacity of Large Language\nModels (LLMs) to generate clear, concise, and scalable explanations for\nphishing warnings. We carried out a large-scale between-subjects user study (N\n= 750) to compare the influence of warning dialogues supplemented with manually\ngenerated explanations against those generated by two LLMs, Claude 3.5 Sonnet\nand Llama 3.3 70B. We investigated two explanatory styles (feature-based and\ncounterfactual) for their effects on behavioural metrics (click-through rate)\nand perceptual outcomes (e.g., trust, risk, clarity). The results indicate that\nwell-constructed LLM-generated explanations can equal or surpass manually\ncrafted explanations in reducing susceptibility to phishing; Claude-generated\nwarnings exhibited particularly robust performance. Feature-based explanations\nwere more effective for genuine phishing attempts, whereas counterfactual\nexplanations diminished false-positive rates. Other variables such as workload,\ngender, and prior familiarity with warning dialogues significantly moderated\nwarning effectiveness. These results indicate that LLMs can be used to\nautomatically build explanations for warning users against phishing, and that\nsuch solutions are scalable, adaptive, and consistent with human-centred\nvalues."}
{"id": "2507.07599", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.07599", "abs": "https://arxiv.org/abs/2507.07599", "authors": ["Sedigh Khademi", "Jim Black", "Christopher Palmer", "Muhammad Javed", "Hazel Clothier", "Jim Buttery", "Gerardo Luis Dimaguila"], "title": "Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models", "comment": "5 pages", "summary": "This study evaluates fine-tuned Llama 3.2 models for extracting\nvaccine-related information from emergency department triage notes to support\nnear real-time vaccine safety surveillance. Prompt engineering was used to\ninitially create a labeled dataset, which was then confirmed by human\nannotators. The performance of prompt-engineered models, fine-tuned models, and\na rule-based approach was compared. The fine-tuned Llama 3 billion parameter\nmodel outperformed other models in its accuracy of extracting vaccine names.\nModel quantization enabled efficient deployment in resource-constrained\nenvironments. Findings demonstrate the potential of large language models in\nautomating data extraction from emergency department notes, supporting\nefficient vaccine safety surveillance and early detection of emerging adverse\nevents following immunization issues."}
{"id": "2507.07927", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07927", "abs": "https://arxiv.org/abs/2507.07927", "authors": ["Jenny Blessing", "Ross J. Anderson", "Alastair R. Beresford"], "title": "KeyDroid: A Large-Scale Analysis of Secure Key Storage in Android Apps", "comment": null, "summary": "Most contemporary mobile devices offer hardware-backed storage for\ncryptographic keys, user data, and other sensitive credentials. Such hardware\nprotects credentials from extraction by an adversary who has compromised the\nmain operating system, such as a malicious third-party app. Since 2011, Android\napp developers can access trusted hardware via the Android Keystore API. In\nthis work, we conduct the first comprehensive survey of hardware-backed key\nstorage in Android devices. We analyze 490 119 Android apps, collecting data on\nhow trusted hardware is used by app developers (if used at all) and\ncross-referencing our findings with sensitive user data collected by each app,\nas self-reported by developers via the Play Store's data safety labels.\n  We find that despite industry-wide initiatives to encourage adoption, 56.3%\nof apps self-reporting as processing sensitive user data do not use Android's\ntrusted hardware capabilities at all, while just 5.03% of apps collecting some\nform of sensitive data use the strongest form of trusted hardware, a secure\nelement distinct from the main processor. To better understand the potential\ndownsides of using secure hardware, we conduct the first empirical analysis of\ntrusted hardware performance in mobile devices, measuring the runtime of common\ncryptographic operations across both software- and hardware-backed keystores.\nWe find that while hardware-backed key storage using a coprocessor is viable\nfor most common cryptographic operations, secure elements capable of preventing\nmore advanced attacks make performance infeasible for symmetric encryption with\nnon-negligible payloads and any kind of asymmetric encryption."}
{"id": "2507.07619", "categories": ["cs.AI", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.07619", "abs": "https://arxiv.org/abs/2507.07619", "authors": ["Marco Sangalli", "Thomas Krak", "Cassio de Campos"], "title": "Towards conservative inference in credal networks using belief functions: the case of credal chains", "comment": null, "summary": "This paper explores belief inference in credal networks using Dempster-Shafer\ntheory. By building on previous work, we propose a novel framework for\npropagating uncertainty through a subclass of credal networks, namely chains.\nThe proposed approach efficiently yields conservative intervals through belief\nand plausibility functions, combining computational speed with robust\nuncertainty representation. Key contributions include formalizing belief-based\ninference methods and comparing belief-based inference against classical\nsensitivity analysis. Numerical results highlight the advantages and\nlimitations of applying belief inference within this framework, providing\ninsights into its practical utility for chains and for credal networks in\ngeneral."}
{"id": "2507.07972", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07972", "abs": "https://arxiv.org/abs/2507.07972", "authors": ["Karthik Garimella", "Austin Ebel", "Brandon Reagen"], "title": "EinHops: Einsum Notation for Expressive Homomorphic Operations on RNS-CKKS Tensors", "comment": "11 pages, 7 figures, 1 table", "summary": "Fully Homomorphic Encryption (FHE) is an encryption scheme that allows for\ncomputation to be performed directly on encrypted data, effectively closing the\nloop on secure and outsourced computing. Data is encrypted not only during rest\nand transit, but also during processing. However, FHE provides a limited\ninstruction set: SIMD addition, SIMD multiplication, and cyclic rotation of 1-D\nvectors. This restriction makes performing multi-dimensional tensor operations\nchallenging. Practitioners must pack these tensors into 1-D vectors and map\ntensor operations onto this one-dimensional layout rather than their\ntraditional nested structure. And while prior systems have made significant\nstrides in automating this process, they often hide critical packing decisions\nbehind layers of abstraction, making debugging, optimizing, and building on top\nof these systems difficult.\n  In this work, we approach multi-dimensional tensor operations in FHE through\nEinstein summation (einsum) notation. Einsum notation explicitly encodes\ndimensional structure and operations in its syntax, naturally exposing how\ntensors should be packed and transformed. We decompose einsum expressions into\na fixed set of FHE-friendly operations. We implement our design and present\nEinHops, a minimalist system that factors einsum expressions into a fixed\nsequence of FHE operations. EinHops enables developers to perform encrypted\ntensor operations using FHE while maintaining full visibility into the\nunderlying packing strategy. We evaluate EinHops on a range of tensor\noperations from a simple transpose to complex multi-dimensional contractions.\nWe show that the explicit nature of einsum notation allows us to build an FHE\ntensor system that is simple, general, and interpretable. We open-source\nEinHops at the following repository: https://github.com/baahl-nyu/einhops."}
{"id": "2507.07644", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07644", "abs": "https://arxiv.org/abs/2507.07644", "authors": ["Fedor Rodionov", "Abdelrahman Eldesokey", "Michael Birsak", "John Femiani", "Bernard Ghanem", "Peter Wonka"], "title": "PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations", "comment": "25 pages, 18 figures. Diagnostic benchmark for spatial reasoning in\n  LLMs. Project page: https://OldDelorean.github.io/PlanQA/", "summary": "We introduce PlanQA, a diagnostic benchmark for evaluating geometric and\nspatial reasoning in large-language models (LLMs). PlanQA is grounded in\nstructured representations of indoor scenes, such as kitchens, living rooms,\nand bedrooms, encoded in a symbolic format (e.g., JSON, XML layouts). The\nbenchmark includes diverse question types that test not only metric and\ntopological reasoning (e.g., distance, visibility, shortest paths) but also\ninterior design constraints such as affordance, clearance, balance, and\nusability. Our results across a variety of frontier open-source and commercial\nLLMs show that while models may succeed in shallow queries, they often fail to\nsimulate physical constraints, preserve spatial coherence, or generalize under\nlayout perturbation. PlanQA uncovers a clear blind spot in today's LLMs: they\ndo not consistently reason about real-world layouts. We hope that this\nbenchmark inspires new work on language models that can accurately infer and\nmanipulate spatial and geometric properties in practical settings."}
{"id": "2507.07974", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07974", "abs": "https://arxiv.org/abs/2507.07974", "authors": ["Sizhe Chen", "Yizhu Wang", "Nicholas Carlini", "Chawin Sitawarin", "David Wagner"], "title": "Defending Against Prompt Injection With a Few DefensiveTokens", "comment": null, "summary": "When large language model (LLM) systems interact with external data to\nperform complex tasks, a new attack, namely prompt injection, becomes a\nsignificant threat. By injecting instructions into the data accessed by the\nsystem, the attacker is able to override the initial user task with an\narbitrary task directed by the attacker. To secure the system, test-time\ndefenses, e.g., defensive prompting, have been proposed for system developers\nto attain security only when needed in a flexible manner. However, they are\nmuch less effective than training-time defenses that change the model\nparameters. Motivated by this, we propose DefensiveToken, a test-time defense\nwith prompt injection robustness comparable to training-time alternatives.\nDefensiveTokens are newly inserted as special tokens, whose embeddings are\noptimized for security. In security-sensitive cases, system developers can\nappend a few DefensiveTokens before the LLM input to achieve security with a\nminimal utility drop. In scenarios where security is less of a concern,\ndevelopers can simply skip DefensiveTokens; the LLM system remains the same as\nthere is no defense, generating high-quality responses. Thus, DefensiveTokens,\nif released alongside the model, allow a flexible switch between the\nstate-of-the-art (SOTA) utility and almost-SOTA security at test time. The code\nis available at https://github.com/Sizhe-Chen/DefensiveToken."}
{"id": "2507.07723", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07723", "abs": "https://arxiv.org/abs/2507.07723", "authors": ["Chengtao Jian", "Kai Yang", "Ye Ouyang", "Xiaozhou Ye"], "title": "Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization", "comment": null, "summary": "Direct Preference Optimization (DPO) has emerged as a popular and efficient\nalternative to reward modeling and reinforcement learning for aligning language\nmodels with human preferences. Despite its empirical success, the theoretical\nproperties and intrinsic limitations of DPO remain underexplored. In this work,\nwe first present a comprehensive analysis of DPO's dynamics from a probability\nevolution perspective. Our analysis reveals that DPO is highly sensitive to\ninitialization. It also tends to misallocate probability mass, which can\ninadvertently shift probability toward irrelevant or undesired responses. This\nmisallocation may unintentionally reinforce model bias, thereby compromising\nboth the stability of model alignment and the consistency with intended\npreferences. Motivated by these theoretical findings, we propose a\ntheoretically grounded bilevel optimization framework that tightly integrate\nsupervised fine-tuning with an enhanced DPO objective a.k.a. stable preference\noptimization. Our approach introduces a principled regularization scheme to\nexplicitly encourage absolute probability improvement for preferred outputs,\nwhile maintaining stable optimization dynamics. Experiments on challenging\nreasoning and summarization benchmarks elucidate that our method consistently\nimproves reasoning accuracy and better aligns output distributions with\nintended preferences, outperforming standard DPO. Stable preference\noptimization provides new insights into the design of preference-based\nalignment objectives and opens up new avenues towards more reliable and\ninterpretable language model alignment."}
{"id": "2507.07341", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07341", "abs": "https://arxiv.org/abs/2507.07341", "authors": ["Sarah Ball", "Greg Gluch", "Shafi Goldwasser", "Frauke Kreuter", "Omer Reingold", "Guy N. Rothblum"], "title": "On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment", "comment": null, "summary": "With the increased deployment of large language models (LLMs), one concern is\ntheir potential misuse for generating harmful content. Our work studies the\nalignment challenge, with a focus on filters to prevent the generation of\nunsafe information. Two natural points of intervention are the filtering of the\ninput prompt before it reaches the model, and filtering the output after\ngeneration. Our main results demonstrate computational challenges in filtering\nboth prompts and outputs. First, we show that there exist LLMs for which there\nare no efficient prompt filters: adversarial prompts that elicit harmful\nbehavior can be easily constructed, which are computationally indistinguishable\nfrom benign prompts for any efficient filter. Our second main result identifies\na natural setting in which output filtering is computationally intractable. All\nof our separation results are under cryptographic hardness assumptions. In\naddition to these core findings, we also formalize and study relaxed mitigation\napproaches, demonstrating further computational barriers. We conclude that\nsafety cannot be achieved by designing filters external to the LLM internals\n(architecture and weights); in particular, black-box access to the LLM will not\nsuffice. Based on our technical results, we argue that an aligned AI system's\nintelligence cannot be separated from its judgment."}
{"id": "2507.07743", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07743", "abs": "https://arxiv.org/abs/2507.07743", "authors": ["Philémon Beghin", "Anne-Emmanuelle Ceulemans", "François Glineur"], "title": "Identification of Violin Reduction via Contour Lines Classification", "comment": null, "summary": "The first violins appeared in late 16th-century Italy. Over the next 200\nyears, they spread across Europe and luthiers of various royal courts, eager to\nexperiment with new techniques, created a highly diverse family of instruments.\nAround 1750, size standards were introduced to unify violin making for\norchestras and conservatories. Instruments that fell between two standards were\nthen reduced to a smaller size by luthiers. These reductions have an impact on\nseveral characteristics of violins, in particular on the contour lines, i.e.\nlines of constant altitude, which look more like a U for non reduced\ninstruments and a V for reduced ones. While such differences are observed by\nexperts, they have not been studied quantitatively.\n  This paper presents a method for classifying violins as reduced or\nnon-reduced based on their contour lines. We study a corpus of 25 instruments\nwhose 3D geometric meshes were acquired via photogrammetry. For each\ninstrument, we extract 10-20 contour lines regularly spaced every millimetre.\nEach line is fitted with a parabola-like curve (with an equation of the type y\n= alpha*abs(x)**beta) depending on two parameters, describing how open (beta)\nand how vertically stretched (alpha) the curve is. We compute additional\nfeatures from those parameters, using regressions and counting how many values\nfall under some threshold. We also deal with outliers and non equal numbers of\nlevels, and eventually obtain a numerical profile for each instrument.\n  We then apply classification methods to assess whether geometry alone can\npredict size reduction. We find that distinguishing between reduced and non\nreduced instruments is feasible to some degree, taking into account that a\nwhole spectrum of more or less transformed violins exists, for which it is more\ndifficult to quantify the reduction. We also find the opening parameter beta to\nbe the most predictive."}
{"id": "2507.07787", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07787", "abs": "https://arxiv.org/abs/2507.07787", "authors": ["Elizabeth Hilliard", "Akshaya Jagadeesh", "Alex Cook", "Steele Billings", "Nicholas Skytland", "Alicia Llewellyn", "Jackson Paull", "Nathan Paull", "Nolan Kurylo", "Keatra Nesbitt", "Robert Gruenewald", "Anthony Jantzi", "Omar Chavez"], "title": "Measuring AI Alignment with Human Flourishing", "comment": null, "summary": "This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel\nevaluation framework that assesses AI alignment with human flourishing across\nseven dimensions: Character and Virtue, Close Social Relationships, Happiness\nand Life Satisfaction, Meaning and Purpose, Mental and Physical Health,\nFinancial and Material Stability, and Faith and Spirituality. Unlike\ntraditional benchmarks that focus on technical capabilities or harm prevention,\nthe FAI Benchmark measures AI performance on how effectively models contribute\nto the flourishing of a person across these dimensions. The benchmark evaluates\nhow effectively LLM AI systems align with current research models of holistic\nhuman well-being through a comprehensive methodology that incorporates 1,229\nobjective and subjective questions. Using specialized judge Large Language\nModels (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs\ngeometric mean scoring to ensure balanced performance across all flourishing\ndimensions. Initial testing of 28 leading language models reveals that while\nsome models approach holistic alignment (with the highest-scoring models\nachieving 72/100), none are acceptably aligned across all dimensions,\nparticularly in Faith and Spirituality, Character and Virtue, and Meaning and\nPurpose. This research establishes a framework for developing AI systems that\nactively support human flourishing rather than merely avoiding harm, offering\nsignificant implications for AI development, ethics, and evaluation."}
{"id": "2507.07818", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07818", "abs": "https://arxiv.org/abs/2507.07818", "authors": ["Lu Xu", "Jiaqian Yu", "Xiongfeng Peng", "Yiwei Chen", "Weiming Li", "Jaewook Yoo", "Sunghyun Chunag", "Dongwook Lee", "Daehyun Ji", "Chao Zhang"], "title": "MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving", "comment": null, "summary": "Recent studies show large language models (LLMs) and vision language models\n(VLMs) trained using web-scale data can empower end-to-end autonomous driving\nsystems for a better generalization and interpretation. Specifically, by\ndynamically routing inputs to specialized subsets of parameters, the\nMixture-of-Experts (MoE) technique enables general LLMs or VLMs to achieve\nsubstantial performance improvements while maintaining computational\nefficiency. However, general MoE models usually demands extensive training data\nand complex optimization. In this work, inspired by the learning process of\nhuman drivers, we propose a skill-oriented MoE, called MoSE, which mimics human\ndrivers' learning process and reasoning process, skill-by-skill and\nstep-by-step. We propose a skill-oriented routing mechanism that begins with\ndefining and annotating specific skills, enabling experts to identify the\nnecessary driving competencies for various scenarios and reasoning tasks,\nthereby facilitating skill-by-skill learning. Further align the driving process\nto multi-step planning in human reasoning and end-to-end driving models, we\nbuild a hierarchical skill dataset and pretrain the router to encourage the\nmodel to think step-by-step. Unlike multi-round dialogs, MoSE integrates\nvaluable auxiliary tasks (e.g.\\ description, reasoning, planning) in one single\nforward process without introducing any extra computational cost. With less\nthan 3B sparsely activated parameters, our model outperforms several 8B+\nparameters on CODA AD corner case reasoning task. Compared to existing methods\nbased on open-source models and data, our approach achieves state-of-the-art\nperformance with significantly reduced activated model size (at least by\n$62.5\\%$) with a single-turn conversation."}
{"id": "2507.07820", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07820", "abs": "https://arxiv.org/abs/2507.07820", "authors": ["Eunsu Baek", "Keondo Park", "Jeonggil Ko", "Min-hwan Oh", "Taesik Gong", "Hyung-Sin Kim"], "title": "AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift", "comment": null, "summary": "Current AI advances largely rely on scaling neural models and expanding\ntraining datasets to achieve generalization and robustness. Despite notable\nsuccesses, this paradigm incurs significant environmental, economic, and\nethical costs, limiting sustainability and equitable access. Inspired by\nbiological sensory systems, where adaptation occurs dynamically at the input\n(e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive\nsensing as a necessary and foundational shift. Adaptive sensing proactively\nmodulates sensor parameters (e.g., exposure, sensitivity, multimodal\nconfigurations) at the input level, significantly mitigating covariate shifts\nand improving efficiency. Empirical evidence from recent studies demonstrates\nthat adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass\nsubstantially larger models (e.g., OpenCLIP-H) trained with significantly more\ndata and compute. We (i) outline a roadmap for broadly integrating adaptive\nsensing into real-world applications spanning humanoid, healthcare, autonomous\nsystems, agriculture, and environmental monitoring, (ii) critically assess\ntechnical and ethical integration challenges, and (iii) propose targeted\nresearch directions, such as standardized benchmarks, real-time adaptive\nalgorithms, multimodal integration, and privacy-preserving methods.\nCollectively, these efforts aim to transition the AI community toward\nsustainable, robust, and equitable artificial intelligence systems."}
{"id": "2507.07857", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07857", "abs": "https://arxiv.org/abs/2507.07857", "authors": ["Samuel Reyd", "Ada Diaconescu", "Jean-Louis Dessalles"], "title": "Searching for actual causes: Approximate algorithms with adjustable precision", "comment": null, "summary": "Causality has gained popularity in recent years. It has helped improve the\nperformance, reliability, and interpretability of machine learning models.\nHowever, recent literature on explainable artificial intelligence (XAI) has\nfaced criticism. The classical XAI and causality literature focuses on\nunderstanding which factors contribute to which consequences. While such\nknowledge is valuable for researchers and engineers, it is not what non-expert\nusers expect as explanations. Instead, these users often await facts that cause\nthe target consequences, i.e., actual causes. Formalizing this notion is still\nan open problem. Additionally, identifying actual causes is reportedly an\nNP-complete problem, and there are too few practical solutions to approximate\nformal definitions. We propose a set of algorithms to identify actual causes\nwith a polynomial complexity and an adjustable level of precision and\nexhaustiveness. Our experiments indicate that the algorithms (1) identify\ncauses for different categories of systems that are not handled by existing\napproaches (i.e., non-boolean, black-box, and stochastic systems), (2) can be\nadjusted to gain more precision and exhaustiveness with more computation time."}
{"id": "2507.07893", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07893", "abs": "https://arxiv.org/abs/2507.07893", "authors": ["Mingda Zhang", "Na Zhao", "Jianglong Qing", "Qing xu", "Kaiwen Pan", "Ting luo"], "title": "An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis", "comment": "15 pages,3 figures", "summary": "The rapid development of artificial intelligence has positioned large\nlanguage models as fundamental components of intelligent legal systems.\nHowever, these models face significant limitations in legal dispute analysis,\nincluding insufficient legal knowledge representation, limited concept\nunderstanding, and reasoning deficiencies. This research proposes an enhanced\nframework integrating prompt engineering with multidimensional knowledge\ngraphs. The framework introduces a three-stage hierarchical prompt structure\ncomprising task definition, knowledge background, and reasoning guidance,\nsupplemented by legal-specific reasoning templates and dynamic optimization\nmechanisms. A three-layer knowledge graph architecture is constructed with\nlegal classification ontology, representation, and instance layers. Four\ncomplementary methods enable precise legal concept retrieval: direct legal norm\ncode matching, domain-specific semantic vector similarity, ontology-based path\nreasoning, and specialized lexical segmentation. These components integrate\nwith web search technology to establish a knowledge-enhanced framework for\nlegal decision-making. Experimental results demonstrate significant performance\nimprovements in legal dispute analysis, enabling accurate legal application\nanalysis for complex cases while exhibiting nuanced understanding of judicial\ndecision-making logic, providing a novel technical approach for implementing\nintelligent legal assistance systems."}
{"id": "2507.07931", "categories": ["cs.AI", "cs.CY", "I.2.0; K.4.1"], "pdf": "https://arxiv.org/pdf/2507.07931", "abs": "https://arxiv.org/abs/2507.07931", "authors": ["Hans Gundlach", "Jayson Lynch", "Neil Thompson"], "title": "Meek Models Shall Inherit the Earth", "comment": "13 pages, 9 figures, longer version of the paper presented at TAIG\n  ICML 2025", "summary": "The past decade has seen incredible scaling of AI systems by a few companies,\nleading to inequality in AI model performance. This paper argues that, contrary\nto prevailing intuition, the diminishing returns to compute scaling will lead\nto a convergence of AI model capabilities. In other words, meek models (those\nwith limited computation budget) shall inherit the earth, approaching the\nperformance level of the best models overall. We develop a model illustrating\nthat under a fixed-distribution next-token objective, the marginal capability\nreturns to raw compute shrink substantially. Given current scaling practices,\nwe argue that these diminishing returns are strong enough that even companies\nthat can scale their models exponentially faster than other organizations will\neventually have little advantage in capabilities. As part of our argument, we\ngive several reasons that proxies like training loss differences capture\nimportant capability measures using evidence from benchmark data and\ntheoretical performance models. In addition, we analyze empirical data on the\ncapability difference of AI models over time. Finally, in light of the\nincreasing ability of meek models, we argue that AI strategy and policy require\nreexamination, and we outline the areas this shift will affect."}
{"id": "2507.07935", "categories": ["cs.AI", "cs.CY", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2507.07935", "abs": "https://arxiv.org/abs/2507.07935", "authors": ["Kiran Tomlinson", "Sonia Jaffe", "Will Wang", "Scott Counts", "Siddharth Suri"], "title": "Working with AI: Measuring the Occupational Implications of Generative AI", "comment": "40 pages", "summary": "Given the rapid adoption of generative AI and its potential to impact a wide\nrange of tasks, understanding the effects of AI on the economy is one of\nsociety's most important questions. In this work, we take a step toward that\ngoal by analyzing the work activities people do with AI, how successfully and\nbroadly those activities are done, and combine that with data on what\noccupations do those activities. We analyze a dataset of 200k anonymized and\nprivacy-scrubbed conversations between users and Microsoft Bing Copilot, a\npublicly available generative AI system. We find the most common work\nactivities people seek AI assistance for involve gathering information and\nwriting, while the most common activities that AI itself is performing are\nproviding information and assistance, writing, teaching, and advising.\nCombining these activity classifications with measurements of task success and\nscope of impact, we compute an AI applicability score for each occupation. We\nfind the highest AI applicability scores for knowledge work occupation groups\nsuch as computer and mathematical, and office and administrative support, as\nwell as occupations such as sales whose work activities involve providing and\ncommunicating information. Additionally, we characterize the types of work\nactivities performed most successfully, how wage and education correlate with\nAI applicability, and how real-world usage compares to predictions of\noccupational AI impact."}
{"id": "2507.07258", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07258", "abs": "https://arxiv.org/abs/2507.07258", "authors": ["Rami Darwish", "Mahmoud Abdelsalam", "Sajad Khorsandroo", "Kaushik Roy"], "title": "FedP3E: Privacy-Preserving Prototype Exchange for Non-IID IoT Malware Detection in Cross-Silo Federated Learning", "comment": null, "summary": "As IoT ecosystems continue to expand across critical sectors, they have\nbecome prominent targets for increasingly sophisticated and large-scale malware\nattacks. The evolving threat landscape, combined with the sensitive nature of\nIoT-generated data, demands detection frameworks that are both\nprivacy-preserving and resilient to data heterogeneity. Federated Learning (FL)\noffers a promising solution by enabling decentralized model training without\nexposing raw data. However, standard FL algorithms such as FedAvg and FedProx\noften fall short in real-world deployments characterized by class imbalance and\nnon-IID data distributions -- particularly in the presence of rare or disjoint\nmalware classes. To address these challenges, we propose FedP3E\n(Privacy-Preserving Prototype Exchange), a novel FL framework that supports\nindirect cross-client representation sharing while maintaining data privacy.\nEach client constructs class-wise prototypes using Gaussian Mixture Models\n(GMMs), perturbs them with Gaussian noise, and transmits only these compact\nsummaries to the server. The aggregated prototypes are then distributed back to\nclients and integrated into local training, supported by SMOTE-based\naugmentation to enhance representation of minority malware classes. Rather than\nrelying solely on parameter averaging, our prototype-driven mechanism enables\nclients to enrich their local models with complementary structural patterns\nobserved across the federation -- without exchanging raw data or gradients.\nThis targeted strategy reduces the adverse impact of statistical heterogeneity\nwith minimal communication overhead. We evaluate FedP3E on the N-BaIoT dataset\nunder realistic cross-silo scenarios with varying degrees of data imbalance."}
{"id": "2507.07406", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07406", "abs": "https://arxiv.org/abs/2507.07406", "authors": ["Jikesh Thapa", "Gurrehmat Chahal", "Serban Voinea Gabreanu", "Yazan Otoum"], "title": "Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models", "comment": "8 Pages, IEEE Conference", "summary": "Phishing attacks are becoming increasingly sophisticated, underscoring the\nneed for detection systems that strike a balance between high accuracy and\ncomputational efficiency. This paper presents a comparative evaluation of\ntraditional Machine Learning (ML), Deep Learning (DL), and quantized\nsmall-parameter Large Language Models (LLMs) for phishing detection. Through\nexperiments on a curated dataset, we show that while LLMs currently\nunderperform compared to ML and DL methods in terms of raw accuracy, they\nexhibit strong potential for identifying subtle, context-based phishing cues.\nWe also investigate the impact of zero-shot and few-shot prompting strategies,\nrevealing that LLM-rephrased emails can significantly degrade the performance\nof both ML and LLM-based detectors. Our benchmarking highlights that models\nlike DeepSeek R1 Distill Qwen 14B (Q8_0) achieve competitive accuracy, above\n80%, using only 17GB of VRAM, supporting their viability for cost-efficient\ndeployment. We further assess the models' adversarial robustness and\ncost-performance tradeoffs, and demonstrate how lightweight LLMs can provide\nconcise, interpretable explanations to support real-time decision-making. These\nfindings position optimized LLMs as promising components in phishing defence\nsystems and offer a path forward for integrating explainable, efficient AI into\nmodern cybersecurity frameworks."}
{"id": "2507.07413", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07413", "abs": "https://arxiv.org/abs/2507.07413", "authors": ["Mohammad F. Al-Hammouri", "Yazan Otoum", "Rasha Atwa", "Amiya Nayak"], "title": "Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks", "comment": "6 pages, IEEE conference", "summary": "This paper presents a novel approach to intrusion detection by integrating\ntraditional signature-based methods with the contextual understanding\ncapabilities of the GPT-2 Large Language Model (LLM). As cyber threats become\nincreasingly sophisticated, particularly in distributed, heterogeneous, and\nresource-constrained environments such as those enabled by the Internet of\nThings (IoT), the need for dynamic and adaptive Intrusion Detection Systems\n(IDSs) becomes increasingly urgent. While traditional methods remain effective\nfor detecting known threats, they often fail to recognize new and evolving\nattack patterns. In contrast, GPT-2 excels at processing unstructured data and\nidentifying complex semantic relationships, making it well-suited to uncovering\nsubtle, zero-day attack vectors. We propose a hybrid IDS framework that merges\nthe robustness of signature-based techniques with the adaptability of\nGPT-2-driven semantic analysis. Experimental evaluations on a representative\nintrusion dataset demonstrate that our model enhances detection accuracy by\n6.3%, reduces false positives by 9.0%, and maintains near real-time\nresponsiveness. These results affirm the potential of language model\nintegration to build intelligent, scalable, and resilient cybersecurity\ndefences suited for modern connected environments."}
{"id": "2507.07416", "categories": ["cs.CR", "cs.AI", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07416", "abs": "https://arxiv.org/abs/2507.07416", "authors": ["Jenifer Paulraj", "Brindha Raghuraman", "Nagarani Gopalakrishnan", "Yazan Otoum"], "title": "Autonomous AI-based Cybersecurity Framework for Critical Infrastructure: Real-Time Threat Mitigation", "comment": "7 pages, IEEE conference", "summary": "Critical infrastructure systems, including energy grids, healthcare\nfacilities, transportation networks, and water distribution systems, are\npivotal to societal stability and economic resilience. However, the increasing\ninterconnectivity of these systems exposes them to various cyber threats,\nincluding ransomware, Denial-of-Service (DoS) attacks, and Advanced Persistent\nThreats (APTs). This paper examines cybersecurity vulnerabilities in critical\ninfrastructure, highlighting the threat landscape, attack vectors, and the role\nof Artificial Intelligence (AI) in mitigating these risks. We propose a hybrid\nAI-driven cybersecurity framework to enhance real-time vulnerability detection,\nthreat modelling, and automated remediation. This study also addresses the\ncomplexities of adversarial AI, regulatory compliance, and integration. Our\nfindings provide actionable insights to strengthen the security and resilience\nof critical infrastructure systems against emerging cyber threats."}
{"id": "2507.07417", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.07417", "abs": "https://arxiv.org/abs/2507.07417", "authors": ["Nishit V. Pandya", "Andrey Labunets", "Sicun Gao", "Earlence Fernandes"], "title": "May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks", "comment": null, "summary": "A popular class of defenses against prompt injection attacks on large\nlanguage models (LLMs) relies on fine-tuning the model to separate instructions\nand data, so that the LLM does not follow instructions that might be present\nwith data. There are several academic systems and production-level\nimplementations of this idea. We evaluate the robustness of this class of\nprompt injection defenses in the whitebox setting by constructing strong\noptimization-based attacks and showing that the defenses do not provide the\nclaimed security properties. Specifically, we construct a novel attention-based\nattack algorithm for text-based LLMs and apply it to two recent whitebox\ndefenses SecAlign (CCS 2025) and StruQ (USENIX Security 2025), showing attacks\nwith success rates of up to 70% with modest increase in attacker budget in\nterms of tokens. Our findings make fundamental progress towards understanding\nthe robustness of prompt injection defenses in the whitebox setting. We release\nour code and attacks at https://github.com/nishitvp/better_opts_attacks"}
{"id": "2507.07871", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07871", "abs": "https://arxiv.org/abs/2507.07871", "authors": ["Toluwani Aremu", "Noor Hussein", "Munachiso Nwadike", "Samuele Poppi", "Jie Zhang", "Karthik Nandakumar", "Neil Gong", "Nils Lukas"], "title": "Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking", "comment": null, "summary": "Watermarking offers a promising solution for GenAI providers to establish the\nprovenance of their generated content. A watermark is a hidden signal embedded\nin the generated content, whose presence can later be verified using a secret\nwatermarking key. A threat to GenAI providers are \\emph{watermark stealing}\nattacks, where users forge a watermark into content that was \\emph{not}\ngenerated by the provider's models without access to the secret key, e.g., to\nfalsely accuse the provider. Stealing attacks collect \\emph{harmless}\nwatermarked samples from the provider's model and aim to maximize the expected\nsuccess rate of generating \\emph{harmful} watermarked samples. Our work focuses\non mitigating stealing attacks while treating the underlying watermark as a\nblack-box. Our contributions are: (i) Proposing a multi-key extension to\nmitigate stealing attacks that can be applied post-hoc to any watermarking\nmethod across any modality. (ii) We provide theoretical guarantees and\ndemonstrate empirically that our method makes forging substantially less\neffective across multiple datasets, and (iii) we formally define the threat of\nwatermark forging as the task of generating harmful, watermarked content and\nmodel this threat via security games."}
