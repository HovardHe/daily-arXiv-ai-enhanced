<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 4]
- [math.OC](#math.OC) [Total: 24]
- [math.NT](#math.NT) [Total: 13]
- [math.LO](#math.LO) [Total: 2]
- [math.GM](#math.GM) [Total: 3]
- [math.CO](#math.CO) [Total: 18]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [cs.CR](#cs.CR) [Total: 49]
- [cs.AI](#cs.AI) [Total: 50]
- [cs.DM](#cs.DM) [Total: 2]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Asymptotic theory for the likelihood-based block maxima method in time series](https://arxiv.org/abs/2506.17448)
*David L. Carl,Simone A. Padoan,Stefano Rizzelli*

Main category: math.ST

TL;DR: 本文为平稳时间序列的块最大值（BM）方法建立了一个严格的渐近框架，填补了依赖时间序列模型下贝叶斯推断的理论空白，并提出了修正后验分布以改进极值指数的推断性能。


<details>
  <summary>Details</summary>
Motivation: 当前块最大值方法在独立设置下的贝叶斯推断已有广泛研究，但缺乏针对时间序列的渐近理论，需建立适用于实际应用场景的依赖时间序列模型的理论基础。

Method: 首先建立了序列依赖下误指定广义极值（GEV）模型的全面似然理论，包括经验对数似然过程的一致收敛、最大似然估计量的收缩率及局部渐近正态展开。基于此发展了贝叶斯推断的渐近理论。

Result: 证明了后验一致性、$\sqrt{k}$-收缩率、Bernstein-von Mises定理以及可信区间的渐近覆盖性质。针对极值指数提出了校正后验分布，模拟显示该方法具有优异的推断性能。

Conclusion: 该研究为依赖时间序列的极值分析提供了理论保障，所提出的调整贝叶斯方法显著提升了极值指数和风险价值的推断可靠性。

Abstract: This paper develops a rigorous asymptotic framework for likelihood-based
inference in the Block Maxima (BM) method for stationary time series. While
Bayesian inference under the BM approach has been widely studied in the
independence setting, no asymptotic theory currently exists for time series.
Further results are needed to establish that BM method can be applied with the
kind of dependent time series models relevant to applied fields. To address
this gap we first establish a comprehensive likelihood theory for the
misspecified Generalized Extreme Value (GEV) model under serial dependence. Our
results include uniform convergence of the empirical log-likelihood process,
contraction rates for the Maximum Likelihood Estimator, and a local
asymptotically Gaussian expansion. Building on this foundation, we develop the
asymptotic theory of Bayesian inference for the GEV parameters, the extremal
index, $T$-time-horizon return levels, and extreme quantiles (Value at Risk).
Under general conditions on the prior, we prove posterior consistency,
$\sqrt{k}$-contraction rates, Bernstein-von Mises theorems, and asymptotic
coverage properties for credible intervals. For inference on the extremal
index, we propose an adjusted posterior distribution that corrects for poor
coverage exhibited by a naive Bayesian approach. Simulations show excellent
inferential performances for the proposed methodology.

</details>


### [2] [Testing Separability of High-Dimensional Covariance Matrices](https://arxiv.org/abs/2506.17463)
*Bongjung Sung,Peter D. Hoff*

Main category: math.ST

TL;DR: 本文提出了一种新的可分离性检验方法，通过核心协方差矩阵的概念解决了高维数据下传统检验方法存在的问题，并证明了其在大样本下的有效性。


<details>
  <summary>Details</summary>
Motivation: 可分离协方差模型在矩阵变量数据建模中广泛应用，但当真实协方差矩阵$\Sigma$不可分离时，传统推断可能产生误导。现有检验方法在小样本或高维情况下（$p>n$）功效不足或无法精确保证错误率控制，亟需改进方法。

Method: 利用核心协方差矩阵的互补概念，将$\Sigma$的可分离性检验转化为其核心成分的球性检验。构建了适用于高维场景的检验统计量，其零分布在可分离性假设下具有不变性，可通过模拟精确获得零分布。

Result: 所提检验方法在$p/n\rightarrow\gamma\in(0,\infty)$的渐近框架下具有确定的零分布，并被证明是一致的。数值模拟显示其功效显著优于现有方法。

Conclusion: 基于核心协方差矩阵的检验方法有效解决了高维数据下可分离性检验的难题，为矩阵变量数据分析提供了更可靠的统计工具。

Abstract: Due to their parsimony, separable covariance models have been popular in
modeling matrix-variate data. However, the inference from such a model may be
misleading if the population covariance matrix $\Sigma$ is actually
non-separable, motivating the use of statistical tests of separability.
Likelihood ratio tests have tractable null distributions and good power when
the sample size $n$ is larger than the number of variables $p$, but are not
well-defined otherwise. Other existing separability tests for the $p>n$ case
have low power for small sample sizes, and have null distributions that depend
on unknown parameters, preventing exact error rate control. To address these
issues, we propose novel invariant tests leveraging the core covariance matrix,
a complementary notion to a separable covariance matrix. We show that testing
separability of $\Sigma$ is equivalent to testing sphericity of its core
component. With this insight, we construct test statistics that are
well-defined in high-dimensional settings and have distributions that are
invariant under the null hypothesis of separability, allowing for exact
simulation of null distributions. We study asymptotic null distributions and
prove consistency of our tests in a $p/n\rightarrow\gamma\in(0,\infty)$
asymptotic regime. The large power of our proposed tests relative to existing
procedures is demonstrated numerically.

</details>


### [3] [Detection and Reconstruction of a Random Hypergraph from Noisy Graph Projection](https://arxiv.org/abs/2506.17527)
*Shuyang Gong,Zhangsong Li,Qiheng Xu*

Main category: math.ST

TL;DR: 本文研究了$d$-均匀随机超图的噪声投影图的推断问题，建立了检测与重构的尖锐阈值，并揭示了检测-重构间隙现象。


<details>
  <summary>Details</summary>
Motivation: 研究在噪声环境下，如何从超图的投影图中进行检测和重构，解决\cite{BGPY25+}中提出的问题。

Method: 通过分析噪声投影图（保留边概率$p=n^{-1+\alpha+o(1)}$，添加噪声边概率$q=n^{-1+\beta+o(1)}$），建立检测与重构的理论框架。

Result: 对于所有常数$d$，确定了检测（区分噪声投影与Erd\H{o}s-R\'enyi随机图）和重构（估计原始超图）的尖锐阈值，并发现检测-重构间隙现象。

Conclusion: 该工作不仅解决了超图噪声投影的推断问题，还为相关领域提供了理论工具和现象发现。

Abstract: For a $d$-uniform random hypergraph on $n$ vertices in which hyperedges are
included i.i.d.\ so that the average degree in the hypergraph is
$n^{\delta+o(1)}$, the projection of such a hypergraph is a graph on the same
$n$ vertices where an edge connects two vertices if and only if they belong to
a same hyperedge. In this work, we study the inference problem where the
observation is a \emph{noisy} version of the graph projection where each edge
in the projection is kept with probability $p=n^{-1+\alpha+o(1)}$ and each edge
not in the projection is added with probability $q=n^{-1+\beta+o(1)}$. For all
constant $d$, we establish sharp thresholds for both detection (distinguishing
the noisy projection from an Erd\H{o}s-R\'enyi random graph with edge density
$q$) and reconstruction (estimating the original hypergraph). Notably, our
results reveal a \emph{detection-reconstruction gap} phenomenon in this
problem. Our work also answers a problem raised in \cite{BGPY25+}.

</details>


### [4] [Estimating quantile treatments without strict overlap](https://arxiv.org/abs/2506.18215)
*Marco Avella-Medina,Richard Davis,Gennady Samorodnitsky*

Main category: math.ST

TL;DR: 本文提出了一种在不假设严格重叠条件下估计分位数处理效应的新方法，通过改进的逆概率加权（IPW）估计器处理倾向得分趋近于零的情况，并证明了其优于标准分位数IPW估计器。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决倾向得分可能趋近于零（即不满足严格重叠假设）时，传统分位数处理效应估计方法的局限性。

Method: 方法上采用了一种截断的逆概率加权（IPW）估计器，特别关注倾向得分作为规则变化函数趋近于零的情况，并构建了重尾目标函数来估计分位数过程。

Result: 结果表明，估计的分位数过程的极限分布服从稳定分布，收敛速率为$n^{1-1/\gamma}$，其中$\gamma>1$为倾向得分趋近于零时的尾部指数。数值实验和实际数据集验证了该估计器的优越性。

Conclusion: 结论指出，所提出的截断IPW估计器在倾向得分不满足严格重叠条件时表现更优，为处理极端倾向得分情况下的分位数估计提供了有效工具。

Abstract: We consider the problem of estimating quantile treatment effects without
assuming strict overlap , i.e., we do not assume that the propensity score is
bounded away from zero. More specifically, we consider an inverse probability
weighting (IPW) approach for estimating quantiles in the potential outcomes
framework and pay special attention to scenarios where the propensity scores
can tend to zero as a regularly varying function. Our approach effectively
considers a heavy-tailed objective function for estimating the quantile
process. We introduce a truncated IPW estimator that is shown to outperform the
standard quantile IPW estimator when strict overlap does not hold. We show that
the limiting distribution of the estimated quantile process follows a stable
distribution and converges at the rate $n^{1-1/\gamma}$, where $\gamma>1$ is
the tail index of the propensity scores when they tend to zero. We illustrate
the performance of our estimators in numerical experiments and in a dataset
that exhibits the presence of extreme propensity scores.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [5] [On the convergence of computational methods for the online bin stretching problem](https://arxiv.org/abs/2506.17271)
*Antoine Lhomme,Nicolas Catusse,Nadia Brauner*

Main category: math.OC

TL;DR: 本文证明了在线装箱问题中计算搜索方法的收敛性，并给出了与最优性能差距的理论界限。


<details>
  <summary>Details</summary>
Motivation: 在线装箱问题中，计算搜索方法虽能获得较好的上下界，但缺乏理论保证其收敛至最优性能。

Method: 通过理论分析，验证计算搜索方法的收敛性，并量化其与最优性能的差距。

Result: 证明了计算搜索方法确实收敛，并提供了与最优性能差距的理论界限。

Conclusion: 研究结果为在线问题的计算方法收敛性奠定了理论基础。

Abstract: Online bin stretching is an online packing problem where some of the best
known lower and upper bounds were found through computational searches. The
limiting factor in obtaining better bounds with such methods is the
computational time allowed. However, there is still no theoretical guarantee
that such methods do converge towards the optimal online performance. This
paper shows that such methods do, in fact, converge; moreover, bounds on the
gap to the optimal are also given. These results frame a theoretical foundation
for the convergence of computational approaches for online problems.

</details>


### [6] [Sum-of-Squares Biquadratic Polynomials](https://arxiv.org/abs/2506.17260)
*Chunfeng Cui,Liqun Qi,Yi Xu*

Main category: math.OC

TL;DR: 本文研究了2×2双二次正半定多项式是否为平方和(sos)的问题，给出了充要条件，并证明了其sos秩不超过4，且系数可正交。


<details>
  <summary>Details</summary>
Motivation: Hilbert指出四变量正半定齐次四次多项式可能不是平方和(sos)。本文探讨2×2双二次多项式是否满足sos性质。

Method: 通过分析双二次多项式的结构，提出了判断其是否为sos的充要条件，并研究了不同交叉项情况下的sos分解形式。

Result: 证明了2×2 sos双二次多项式可分解为四项式，sos秩≤4；无交叉项或单一交叉项时总可分解为二项式(sosb)；给出了双交叉项时为sosb的充分条件。

Conclusion: 本文系统解决了2×2双二次正半定多项式的sos问题，为相关领域提供了重要的理论工具和分析方法。

Abstract: Hilbert indicated that a positive semi-definite (psd) homogeneous quartic
polynomial of four variables may not be sum of squares (sos). A $2 \times 2$
biquadratic polynomial is a homogeneous quartic polynomial of four variables.
Is a psd $2 \times 2$ biquadratic polynomial sos? In this paper, we present a
necessary and sufficient condition for a $2 \times 2$ psd biquadratic
polynomial to be sos. We show that if a $2 \times 2$ sos biquadratic polynomial
is sos, then it is sos of tetranomials, its sos rank is at most $4$, and the
coefficients of the tetranomials can be orthogonal to each other. We show that
a $2 \times 2$ psd biquadratic polynomial with one half-cross term or without
half-cross terms is always sos of binomials (sosb). Sufficient conditions for
$2 \times 2$ psd biquadratic polynomials with two half-cross terms to be sosb
are presented. We also present a case in which the psd biquadratic polynomials
are sos of trinomials (sostri).

</details>


### [7] [Existence and Uniqueness of Physically Correct Hydraulic States in Water Distribution Systems -- A theoretical analysis on the solvability of non-linear systems of equations in the context of water distribution systems](https://arxiv.org/abs/2506.17270)
*Janine Strotherm,Julian Rolfes,Barbara Hammer*

Main category: math.OC

TL;DR: 本文为水分配系统（WDSs）中非线性水力原理解的存在性与唯一性提供了理论保证，填补了该领域长期缺乏严格数学证明的空白。


<details>
  <summary>Details</summary>
Motivation: 城市化与气候变化推动智慧城市发展，准确估算水分配系统的水力状态（如水压、需水量、水流）至关重要。现有水力模拟器依赖观测状态子集进行估算，但缺乏对输入数据是否足以推导完整状态的理论验证。

Method: 通过严格数学分析（无需泰勒近似或网络相关算法），研究非线性水力原理方程组的解存在性与唯一性，并验证常见观测子集的充分性。

Result: 证明了在常见观测子集下，非线性水力原理存在唯一物理合理解，且前人研究结果为本结论的特例。该理论为水力模拟器的可靠性提供了基础保障。

Conclusion: 首次严格论证了水分配系统水力状态估算的理论可行性，为后续模拟器分析与理论验证奠定基础，解决了行业共识但未证明的关键问题。

Abstract: Planning and extension of water distribution systems (WDSs) plays a key role
in the development of smart cities, driven by challenges such as urbanization
and climate change. In this context, the correct estimation of physically
correct hydraulic states, i.e., pressure heads, water demands and water flows,
is of high interest. Hydraulic emulators such as EPANET or more recently,
physic-informed surrogate models are used to solve this task. They require a
subset of observed states, such as heads at reservoirs and water demands, as
inputs to estimate the whole hydraulic state. In order to obtain reliable
results of such emulators, but also to be able to give theoretical guarantees
of their estimations, an important question is whether theoretically, the
subset of observed states that the emulator requires as an input suffices to
derive the whole state, purely based on the physical properties, also called
hydraulic principles, it obeys. This questions translates to solving linear and
non-linear systems of equations. Previous articles investigate on the existence
question under the term observability analysis, however, they rely on the
approximation of the non-linear principles using Taylor approximation and on
network-dependent numerical or algebraic algorithms. In this work, we provide
purely theoretical guarantees on the existence and uniqueness of solutions to
the non-linear hydraulic principles, and by this, the existence and uniqueness
of physically correct states, given common subsets of them -- a result that
seems to be common-sense in the water community but has never been rigorously
proven. We show that previous existence results are special cases of our more
general findings, and therefore lay the foundation for further analysis and
theoretical guarantees of the before-mentioned hydraulic emulators.

</details>


### [8] [The LQR-Schrödinger Bridge](https://arxiv.org/abs/2506.17273)
*Marc Lambert*

Main category: math.OC

TL;DR: 本文研究了离散时间下的薛定谔桥问题，采用线性二次调节器（LQR）成本函数，在边界边际为高斯分布时，提出了闭式解法，并通过动态规划原理和Riccati方程实现了高效求解。


<details>
  <summary>Details</summary>
Motivation: 研究离散时间薛定谔桥问题，旨在通过LQR成本函数（包含势能项和动能项）构建复杂非均匀高斯过程，并扩展高斯分布间的Bures传输到更复杂几何结构。

Method: 采用动态规划原理，将Kantorovich势解释为成本函数，在LQR-高斯假设下，通过前向和后向传递精确传播势能，建立对偶Riccati方程系统。

Result: 在边界边际为高斯分布时，问题可闭式求解，最优过程为马尔可夫过程，其转移核和高斯边际可闭式计算。数值实验验证了该方法能构建含加速和循环的复杂高斯过程。

Conclusion: 该方法不仅高效求解LQR-薛定谔桥问题，还能将Bures传输扩展到负曲率几何结构，为复杂高斯过程建模提供了新工具。

Abstract: We consider the Schr{\"o}dinger bridge problem in discrete time, where the
pathwise cost is replaced by a sum of quadratic functions, taking the form of a
linear quadratic regulator (LQR) cost. This cost comprises potential terms that
act as attractors and kinetic terms that control the diffusion of the process.
When the two boundary marginals are Gaussian, we show that the
LQR-Schr{\"o}dinger bridge problem can be solved in closed form. We follow the
dynamic programming principle, interpreting the Kantorovich potentials as
cost-to-go functions. Under the LQR-Gaussian assumption, these potentials can
be propagated exactly in a backward and forward passes, leading to a system of
dual Riccati equations, well known in estimation and control. This system
converges rapidly in practice. We then show that the optimal process is
Markovian and compute its transition kernel in closed form as well as the
Gaussian marginals. Through numerical experiments, we demonstrate that this
approach can be used to construct complex, non-homogeneous Gaussian processes
with acceleration and loops, given well-chosen attractive potentials. Moreover,
this approach allows extending the Bures transport between Gaussian
distributions to more complex geometries with negative curvature.

</details>


### [9] [KKT-based optimality conditions for neural network approximation](https://arxiv.org/abs/2506.17305)
*Vinesha Peiris,Nadezda Sukhorukova,Julien Ugon*

Main category: math.OC

TL;DR: 本文研究了神经网络在曼哈顿范数($l_1$范数)和切比雪夫范数($\max$范数)下的最优性条件，针对单隐藏层网络，将非光滑无约束优化问题转化为高维光滑约束问题，并利用KKT条件建立了基于凸分析的充要条件。


<details>
  <summary>Details</summary>
Motivation: 旨在为神经网络近似建立严格的最优性理论框架，特别是在非欧几里得范数空间($l_1$和$\max$范数)中，解决传统梯度方法无法直接应用的挑战。

Method: 将原始非光滑无约束优化重构为高维空间的光滑约束问题，通过KKT条件推导必要条件，并采用凸集和凸分析工具表述最优性条件。

Result: 获得了单隐藏层神经网络在$l_1$和$\max$范数下的充要最优性条件，证明可通过凸优化框架严格表征神经网络的最优近似行为。

Conclusion: 该理论为神经网络优化提供了新的分析工具，特别适用于非光滑范数空间，未来可扩展至深层网络和更复杂的最优控制场景。

Abstract: In this paper, we obtain necessary optimality conditions for neural network
approximation. We consider neural networks in Manhattan ($l_1$ norm) and
Chebyshev ($\max$ norm). The optimality conditions are based on neural networks
with at most one hidden layer. We reformulate nonsmooth unconstrained
optimisation problems as larger dimension constrained problems with smooth
objective functions and constraints. Then we use KKT conditions to develop the
necessary conditions and present the optimality conditions in terms of convex
analysis and convex sets.

</details>


### [10] [Convergent Proximal Multiblock ADMM for Nonconvex Dynamics-Constrained Optimization](https://arxiv.org/abs/2506.17405)
*Bowen Li,Ya-xiang Yuan*

Main category: math.OC

TL;DR: 本文提出了一种针对非线性动力学约束非凸优化的可证明收敛的多块ADMM方法，解决了经典扩展中的发散问题。通过利用问题特殊结构，证明了在局部Lipschitz和局部$L$-光滑条件下，近端ADMM生成的序列有界且所有累积点均为KKT点。数值实验表明该方法在4D变分数据同化和刚性问题的隐式求解中表现稳定。


<details>
  <summary>Details</summary>
Motivation: 经典扩展ADMM在非线性动力学约束的非凸优化中易发散，而动力学约束变分问题（如ODE/PDE约束的泛函优化）在科学计算中广泛存在。本文旨在开发一种理论保证收敛的算法来解决这类$n$-求和型非凸优化问题。

Method: 基于近端交替方向乘子法（proximal ADMM），利用问题结构设计收敛算法。提出确定惩罚参数$\rho_i$和近端参数$\eta_i$的流程，并证明在局部Lipschitz和$L$-光滑条件下，算法生成的序列有界且收敛于KKT点。

Result: 理论证明：算法序列有界且所有累积点为KKT点，快速子序列收敛速度为$o(1/k)$。数值实验显示，在4D变分数据同化和刚性隐式格式求解中，近端ADMM比基于梯度的方法更稳定。

Conclusion: 所提出的近端ADMM为非线性动力学约束的非凸优化提供了理论保证的解决方案，其稳定性和收敛性在科学计算问题中得到验证。文中还讨论了子问题求解的新方法和该算法的优势。

Abstract: This paper proposes a provably convergent multiblock ADMM for nonconvex
optimization with nonlinear dynamics constraints, overcoming the divergence
issue in classical extensions. We consider a class of optimization problems
that arise from discretization of dynamics-constrained variational problems
that are optimization problems for a functional constrained by time-dependent
ODEs or PDEs. This is a family of $n$-sum nonconvex optimization problems with
nonlinear constraints. We study the convergence properties of the proximal
alternating direction method of multipliers (proximal ADMM) applied to those
problems. Taking the advantage of the special problem structure, we show that
under local Lipschitz and local $L$-smooth conditions, the sequence generated
by the proximal ADMM is bounded and all accumulation points are KKT points.
Based on our analysis, we also design a procedure to determine the penalty
parameters $\rho_i$ and the proximal parameters $\eta_i$. We further prove that
among all the subsequences that converge, the fast one converges at the rate of
$o(1/k)$. The numerical experiments are performed on 4D variational data
assimilation problems and as the solver of implicit schemes for stiff problems.
The proposed proximal ADMM has more stable performance than gradient-based
methods. We discuss the implementation to solve the subproblems, a new way to
solve the implicit schemes, and the advantages of the proposed algorithm.

</details>


### [11] [Regularization of Nonlinear Inverse Problems -- From Functional Analysis to Data-Driven Approaches](https://arxiv.org/abs/2506.17465)
*Clemens Kirisits,Bochra Mejri,Sergei Pereverzev,Otmar Scherzer,Cong Shi*

Main category: math.OC

TL;DR: 本书重点分析非线性逆问题的正则化方法，强调利用先验实验数据（监督或无监督）将数据驱动见解融入物理模型控制的逆问题求解。


<details>
  <summary>Details</summary>
Motivation: 逆问题旨在通过间接或不完整测量揭示观测系统的内部机制，在医学成像、地球物理成像及工业参数识别等领域具有广泛应用。

Method: 采用结合监督或无监督先验数据的正则化技术，将数据驱动方法与传统物理模型相结合求解非线性逆问题。

Result: 该方法实现了数据驱动见解与物理模型的融合，为逆问题求解提供了新范式。

Conclusion: 整合先验数据的正则化方法能有效解决非线性逆问题，在跨学科应用中展现出重要价值。

Abstract: The focus of this book is on the analysis of regularization methods for
solving \emph{nonlinear inverse problems}. Specifically, we place a strong
emphasis on techniques that incorporate supervised or unsupervised data derived
from prior experiments. This approach enables the integration of data-driven
insights into the solution of inverse problems governed by physical models.
\emph{Inverse problems}, in general, aim to uncover the \emph{inner mechanisms}
of an observed system based on indirect or incomplete measurements. This field
has far-reaching applications across various disciplines, such as medical or
geophysical imaging, as well as, more broadly speaking, industrial processes
where identifying hidden parameters is essential.

</details>


### [12] [Enhanced PDHG for Linear Programming with Online Preconditioning](https://arxiv.org/abs/2506.17650)
*Haihao Lu,Wanyu Zhang*

Main category: math.OC

TL;DR: 本文提出了一种用于线性规划原始-对偶混合梯度(PDHG)算法的在线预处理技术，通过自适应更新预处理矩阵显著提升了求解效率。


<details>
  <summary>Details</summary>
Motivation: 为提高PDHG算法在求解线性规划问题时的实际性能，需要开发能动态调整预处理策略的方法。

Method: 采用在线优化框架自适应更新原始和对偶预处理矩阵，引入标准化损失函数和低频更新等增强策略，并在GPU求解器cuPDLP.jl上实现。

Result: 数值实验表明，该技术能有效减少迭代次数和总求解时间。

Conclusion: 在线预处理技术显著提升了PDHG算法求解线性规划问题的计算效率，具有实际应用价值。

Abstract: We present an online preconditioning technique for the primal-dual hybrid
gradient (PDHG) algorithm for linear programming (LP). The method adaptively
updates primal and dual preconditioners using an online optimization framework.
To improve its practical performance, we introduce several algorithmic
enhancements, including using normalized online loss functions and updating
preconditioners infrequently. We implement the technique on top of vanilla PDHG
and the GPU-based LP solver cuPDLP.jl, and benchmark its performance on
standard LP datasets. Our numerical experiments demonstrate that online
preconditioning effectively reduces both iteration counts and overall solving
time.

</details>


### [13] [An Analytical Framework for the Linear Best-Worst Method and its Application to Achieve Sustainable Development Goals--Oriented Agri-Food Supply Chains](https://arxiv.org/abs/2506.17666)
*Harshit M. Ratandhara,Mohit Kumar*

Main category: math.OC

TL;DR: 本文提出了一种新的线性BWM框架，通过数学解析方法直接计算权重，无需优化软件，提高了计算效率和概念清晰度，并验证了模型对数据变化的低敏感性和一致性指标的计算。


<details>
  <summary>Details</summary>
Motivation: 现有线性BWM模型需依赖优化软件求解权重，本研究旨在开发一种数学解析框架，消除对优化工具的依赖，提升模型的计算效率和透明度。

Method: 通过数学推导构建解析表达式直接计算权重，避免优化求解过程；推导线性BWM的一致性指标值，并通过5个数值案例和1个真实案例（18个驱动因素的可持续农业供应链排名）验证方法。

Result: 提出的解析框架显著提升计算效率，证明模型对数据变化敏感性较低，并成功计算出用于评估数据一致性的一致性比率所需指标。

Conclusion: 该解析方法不仅简化了线性BWM的实施流程，其低数据敏感性和一致性验证能力使其在可持续供应链等多准则决策场景中具有实用价值。

Abstract: The Best-Worst Method (BWM) has emerged as a prominent multi-criteria
decision-making method for determining the weights of the decision criteria.
Among various BWM models, this research focuses on the linear model of the BWM.
This model calculates weights by solving an optimization problem, necessitating
optimization software. In this article, we present a novel framework that
solves this optimization model mathematically, yielding an analytical
expression for the resultant weights, thus eliminating the requirement for an
optimization software. The proposed approach enhances both the conceptual
clarity of the underlying optimization process and the computational efficiency
of the model. Based of this framework, we demonstrate the model's limited
response to data variations, i.e., its lower data sensitivity. We also compute
the values of consistency index for the linear BWM, which are required to
calculate the consistency ratio - a consistency indicator used for assessing
inconsistency in input data. Finally, we illustrate the validity and
applicability of the proposed approach through five numerical examples and a
real-world case study that ranks eighteen drivers across three categories -
Industry 4.0, sustainability, and circular economy - in relation to sustainable
development goals-driven agri-food supply chains.

</details>


### [14] [Regular Tree Search for Simulation Optimization](https://arxiv.org/abs/2506.17696)
*Du-Yi Wang,Guo Liang,Guangwu Liu,Kun Zhang*

Main category: math.OC

TL;DR: 本文提出了一种名为正则树搜索的随机搜索算法，用于解决非凸目标函数的仿真优化问题，通过自适应采样和搜索空间递归分区实现全局收敛。


<details>
  <summary>Details</summary>
Motivation: 非凸目标函数的仿真优化问题是运筹学中的基本挑战，现有方法难以保证全局最优解的可靠性。

Method: 算法结合自适应采样与递归分区，通过树结构迭代细化，采用树搜索策略（如UCT）指导采样，并在叶节点样本数超过深度相关阈值时触发分区。

Result: 在次高斯噪声下证明了全局收敛性，数值实验表明算法能可靠找到全局最优解并准确估计目标值。

Conclusion: 正则树搜索算法为非凸仿真优化问题提供了有效的解决方案，无需目标函数连续性假设即可保证收敛。

Abstract: Tackling simulation optimization problems with non-convex objective functions
remains a fundamental challenge in operations research. In this paper, we
propose a class of random search algorithms, called Regular Tree Search, which
integrates adaptive sampling with recursive partitioning of the search space.
The algorithm concentrates simulations on increasingly promising regions by
iteratively refining a tree structure. A tree search strategy guides sampling
decisions, while partitioning is triggered when the number of samples in a leaf
node exceeds a threshold that depends on its depth. Furthermore, a specific
tree search strategy, Upper Confidence Bounds applied to Trees (UCT), is
employed in the Regular Tree Search. We prove global convergence under
sub-Gaussian noise, based on assumptions involving the optimality gap, without
requiring continuity of the objective function. Numerical experiments confirm
that the algorithm reliably identifies the global optimum and provides accurate
estimates of its objective value.

</details>


### [15] [Pushing the Complexity Boundaries of Fixed-Point Equations: Adaptation to Contraction and Controlled Expansion](https://arxiv.org/abs/2506.17698)
*Jelena Diakonikolas*

Main category: math.OC

TL;DR: 本文针对Lipschitz常数略大于1的扩张算子，提出了新算法以逼近不动点方程，并引入逐渐扩张算子类，证明了在有限迭代次数内收敛至$\epsilon$-近似解。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理Lipschitz常数大于1的扩张算子时计算困难，本研究旨在突破这一限制，解决优化、博弈论等领域中的关键问题。

Method: 设计了自适应Lipschitz常数的算法，并引入逐渐扩张算子类，允许点间常数扩张（约1.4倍），理论证明其可在$O(1/\epsilon)$次迭代内收敛。

Result: 算法在非扩张或压缩算子下达到最优预言复杂度，适用于无限维赋范空间，并可扩展至正曲率测地度量空间。

Conclusion: 该研究突破了扩张算子的计算瓶颈，为广泛数学问题提供了高效逼近工具，具有理论与应用双重价值。

Abstract: Fixed-point equations with Lipschitz operators have been studied for more
than a century, and are central to problems in mathematical optimization, game
theory, economics, and dynamical systems, among others. When the Lipschitz
constant of the operator is larger than one (i.e., when the operator is
expansive), it is well known that approximating fixed-point equations becomes
computationally intractable even in basic finite-dimensional settings. In this
work, we aim to push these complexity boundaries by introducing algorithms that
can address problems with mildly expansive (i.e., with Lipschitz constant
slightly larger than one) operators not excluded by existing lower bounds,
attaining the best possible fixed-point error up to universal constants. We
further introduce a class of \emph{gradually expansive operators} that allow
for constant (up to $\approx 1.4$) expansion between points, for which we prove
convergence to $\epsilon$-approximate fixed points in order-$(1/\epsilon)$
iterations for $\epsilon > 0.$ Our algorithms automatically adapt to the
Lipschitz constant of the operator and attain optimal oracle complexity bounds
when the input operator is nonexpansive or contractive. Our results apply to
general, possibly infinite-dimensional normed vector spaces and can be extended
to positively curved geodesic metric spaces.

</details>


### [16] [On circumcentered direct methods for monotone variational inequality problems](https://arxiv.org/abs/2506.17814)
*Roger Behling,Yunier Bello-Cruz,Alfredo Iusem,Di Liu,Luiz-Rafael Santos*

Main category: math.OC

TL;DR: 本文首次提出使用外心迭代法（CRM）解决变分不等式问题（VIP），包括参数单调算子和单调算子两种情况，理论证明和数值实验均显示其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 变分不等式问题（VIP）在连续优化理论和应用中具有核心地位，传统方法如交替投影法和Douglas-Rachford法存在效率瓶颈，而CRM因其处理近似投影的能力成为有潜力的替代方案。

Method: 提出两种外心迭代法：1）针对参数单调算子VIP的精确投影版本；2）针对单调算子VIP的近似投影版本，均基于CRM框架并扩展其适用性。

Result: 理论证明了两种方法的收敛性，数值实验显示其性能优于著名的外梯度法，尤其在处理近似投影时展现显著优势。

Conclusion: CRM框架成功扩展至VIP求解领域，为参数单调和单调算子问题提供了高效新工具，近似投影特性增强了实际应用潜力。

Abstract: The variational inequality problem (VIP) plays a central role in the theory
and applications in continuous optimization. In particular, minimization
problems and KKT systems can be regard as VIPs. In this work, we present the
first methods using circumcenter iterations for solving VIPs. The
circumcentered-reflection method (CRM) is a tool based on projections developed
with the aim of finding a point in the intersection of finitely many closed
convex sets. CRM has gone through enhancements and adaptations over the last
few years and was proven to be faster in many settings than competitors such as
alternating projections and the Douglas-Rachford method. One of the nice
features of CRM is that it is able to deal with approximate projections, which
is exactly what we enforced in this article theoretically and numerically. We
present both a circumcenter method for the VIP with paramonotone operator and
monotone operator, the first employing exact projections and the second
approximate ones. Convergence results showing their convergence are
established. Numerically, our experiments indicate good performance, including
advantages over the well-know extragradient method.

</details>


### [17] [Nonconvex Nonsmooth Multicomposite Optimization and Its Applications to Recurrent Neural Networks](https://arxiv.org/abs/2506.17884)
*Lingzi Jin,Xiao Wang,Xiaojun Chen*

Main category: math.OC

TL;DR: 本文研究了一类非凸非光滑多复合优化问题，提出了通过约束重构与$\ell_1$惩罚重构的等价性来有效求解一阶和二阶方向平稳点的方法，并应用于循环神经网络训练。


<details>
  <summary>Details</summary>
Motivation: 该研究针对机器学习等领域中出现的非凸非光滑多复合优化问题，特别是包含Tikhonov正则化项和多组件函数组合的目标函数，旨在建立有效的求解框架。

Method: 首先推导了约束重构可行域切锥的闭式表达式，进而证明了原问题与约束重构及$\ell_1$惩罚重构在全局最优性和方向平稳性上的等价性，为间接求解提供了理论基础。

Result: 研究结果表明，通过约束重构与惩罚重构的等价性，可在特定情况下间接获得原问题的一阶和二阶方向平稳点，并将该方法成功应用于循环神经网络的训练过程。

Conclusion: 该工作为非凸非光滑多复合优化问题提供了新的求解路径，其理论框架在机器学习模型（如RNN）训练中展现出应用潜力。

Abstract: We consider a class of nonconvex nonsmooth multicomposite optimization
problems where the objective function consists of a Tikhonov regularizer and a
composition of multiple nonconvex nonsmooth component functions. Such
optimization problems arise from tangible applications in machine learning and
beyond. To define and compute its first-order and second-order
d(irectional)-stationary points effectively, we first derive the closed-form
expression of the tangent cone for the feasible region of its constrained
reformulation. Building on this, we establish its equivalence with the
corresponding constrained and $\ell_1$-penalty reformulations in terms of
global optimality and d-stationarity. The equivalence offers indirect methods
to attain the first-order and second-order d-stationary points of the original
problem in certain cases. We apply our results to the training process of
recurrent neural networks (RNNs).

</details>


### [18] [Inverse Chance Constrained Optimal Power Flow](https://arxiv.org/abs/2506.17924)
*Shenglu Wang,Kairui Feng,Mengqi Xue,Yue Song*

Main category: math.OC

TL;DR: 本文提出了一种逆向机会约束最优潮流（CC-OPF）方法，将安全水平从参数转变为决策变量，旨在寻找系统支持的最高可行安全水平，并通过牛顿-拉夫逊类迭代算法高效求解。


<details>
  <summary>Details</summary>
Motivation: 安全水平是CC-OPF的关键输入参数，但其如何影响CC-OPF的可行性边界尚未明确。研究安全水平对系统可行性的影响，有助于优化电力系统的安全运行。

Method: 通过将安全水平从参数转变为决策变量，提出逆向CC-OPF问题，并设计了一种基于对偶敏感性分析的牛顿-拉夫逊类迭代算法，以高效求解该问题。

Result: 数值实验验证了所提方法的有效性，揭示了安全水平的复杂可行性边界，强调了在多机会约束中协调安全水平的重要性。

Conclusion: 逆向CC-OPF方法能够有效确定系统支持的最高安全水平，为电力系统的安全运行提供了新的优化思路。

Abstract: The chance constrained optimal power flow (CC-OPF) essentially finds the
low-cost generation dispatch scheme ensuring operational constraints are met
with a specified probability, termed the security level. While the security
level is a crucial input parameter, how it shapes the CC-OPF feasibility
boundary has not been revealed. Changing the security level from a parameter to
a decision variable, this letter proposes the inverse CC-OPF that seeks the
highest feasible security level supported by the system. To efficiently solve
this problem, we design a Newton-Raphson-like iteration algorithm leveraging
the duality-based sensitivity analysis of an associated surrogate problem.
Numerical experiments validate the proposed approach, revealing complex
feasibility boundaries for security levels that underscore the importance of
coordinating security levels across multiple chance constraints.

</details>


### [19] [ROBBO: An Efficient Method for Pareto Front Estimation with Guaranteed Accuracy](https://arxiv.org/abs/2506.18004)
*Roberto Boffadossi,Marco Leonesio,Lorenzo Fagiano*

Main category: math.OC

TL;DR: 提出了一种名为ROBBO的新方法，用于估计双目标优化问题中的帕累托前沿（PF），确保在有限采样点内达到预设误差容忍度，并在理论和数值分析中展示了其优越性。


<details>
  <summary>Details</summary>
Motivation: 双目标优化问题中准确估计帕累托前沿的需求，现有方法在采样效率和误差控制方面存在不足，需要一种更鲁棒且平衡的解决方案。

Method: ROBBO方法假设PF连续，通过有限预计算的PF采样点，确保两个目标函数的近似误差在预设容忍范围内，并推导了理论上的最坏情况采样数量。

Result: 理论分析和数值比较表明，ROBBO在采样效率和误差控制上优于现有流行方法，并在2轴定位系统的路径跟踪问题和连续搅拌釜反应器的稳态优化问题中验证了其有效性。

Conclusion: ROBBO方法在双目标优化中表现出色，提供了理论保证和实际应用价值，其开源实现可供进一步研究和应用。

Abstract: A new method to estimate the Pareto Front (PF) in bi-objective optimization
problems is presented. Assuming a continuous PF, the approach, named ROBBO
(RObust and Balanced Bi-objective Optimization), needs to sample at most a
finite, pre-computed number of PF points. Upon termination, it guarantees that
the worst-case approximation error lies within a desired tolerance range,
predefined by the decision maker, for each of the two objective functions.
Theoretical results are derived, about the worst-case number of PF samples
required to guarantee the wanted accuracy, both in general and for specific
sampling methods from the literature. A comparative analysis, both theoretical
and numerical, demonstrates the superiority of the proposed method with respect
to popular ones. The approach is finally showcased in a constrained
path-following problem for a 2-axis positioning system and in a steady-state
optimization problem for a Continuous-flow Stirred Tank Reactor. An open demo
implementation of ROBBO is made available online.

</details>


### [20] [On the Linear Speedup of the Push-Pull Method for Decentralized Optimization over Digraphs](https://arxiv.org/abs/2506.18075)
*Liyuan Liang,Gan Luo,Kun Yuan*

Main category: math.OC

TL;DR: 本文研究了随机Push-Pull方法在强连通有向图上的线性加速特性，提出了新的分析框架，填补了该算法在理论与实证表现之间的差距。


<details>
  <summary>Details</summary>
Motivation: Push-Pull作为一种广泛使用的去中心化优化算法，虽在多种场景下表现出优越的实证性能，但其线性加速特性尚未得到普遍证明，理论与实证之间存在显著差距。

Method: 通过提出新的分析框架，研究团队对随机Push-Pull方法进行了理论分析，避免了非线性校正，并专注于强连通有向图。

Result: 研究证明，Push-Pull算法在任意强连通有向图上均能实现线性加速，为算法的理论理解提供了全面支持。

Conclusion: 该研究不仅为随机Push-Pull方法的理论分析奠定了基础，还使其理论与实证表现达成一致，推动了去中心化优化算法的发展。

Abstract: The linear speedup property is essential for demonstrating the advantage of
distributed algorithms over their single-node counterparts. In this paper, we
study the stochastic Push-Pull method, a widely adopted decentralized
optimization algorithm over directed graphs (digraphs). Unlike methods that
rely solely on row-stochastic or column-stochastic mixing matrices, Push-Pull
avoids nonlinear correction and has shown superior empirical performance across
a variety of settings. However, its theoretical analysis remains challenging,
and the linear speedup property has not been generally establishe--revealing a
significant gap between empirical success and limited theoretical
understanding. To bridge this gap, we propose a novel analysis framework and
prove that Push-Pull achieves linear speedup over arbitrary strongly connected
digraphs. Our results provide the comprehensive theoretical understanding for
stochastic Push-Pull, aligning its theory with empirical performance. Code:
\href{https://github.com/pkumelon/PushPull}{https://github.com/pkumelon/PushPull}.

</details>


### [21] [Wisdom of Crowds Through Myopic Self-Confidence Adaptation](https://arxiv.org/abs/2506.18195)
*Giacomo Como,Fabio Fagnani,Anton Proskurnikov*

Main category: math.OC

TL;DR: 该研究探讨了群体智慧现象，分析了在多智能体系统中通过非贝叶斯学习规则（法国-德格鲁特动态）进行迭代意见聚合的过程，并研究了博弈论框架下的帕累托前沿与纳什均衡。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于群体决策中集体判断可能优于个体判断的现象（如高尔顿的牛重猜测实验），但同时也关注到少数影响力大的个体可能降低群体决策准确性。本文旨在分析多智能体系统中如何通过优化影响权重来最小化估计方差。

Method: 采用非贝叶斯学习规则（法国-德格鲁特动态）进行迭代分布式平均，将问题建模为多目标博弈论优化问题，分析影响权重矩阵对估计方差的作用，并研究帕累托前沿与纳什均衡。

Result: 研究刻画了博弈中的帕累托前沿与纳什均衡集，证明了异步最佳响应动态会收敛到严格纳什均衡集，表明智能体通过优化权重分配可达成最优估计。

Conclusion: 结论表明，在多智能体系统中，通过博弈论框架优化影响权重能够有效降低估计方差，且异步学习动态可收敛至稳定均衡，为群体决策机制设计提供了理论依据。

Abstract: The wisdom of crowds is an umbrella term for phenomena suggesting that the
collective judgment or decision of a large group can be more accurate than the
individual judgments or decisions of the group members. A well-known example
illustrating this concept is the competition at a country fair described by
Galton, where the median value of the individual guesses about the weight of an
ox resulted in an astonishingly accurate estimate of the actual weight. This
phenomenon resembles classical results in probability theory and relies on
independent decision-making. The accuracy of the group's final decision can be
significantly reduced if the final agents' opinions are driven by a few
influential agents.
  In this paper, we consider a group of agents who initially possess
uncorrelated and unbiased noisy measurements of a common state of the world.
Assume these agents iteratively update their estimates according to a simple
non-Bayesian learning rule, commonly known in mathematical sociology as the
French-DeGroot dynamics or iterative opinion pooling. As a result of this
iterative distributed averaging process, each agent arrives at an asymptotic
estimate of the state of the world, with the variance of this estimate
determined by the matrix of weights the agents assign to each other. Every
agent aims at minimizing the variance of her asymptotic estimate of the state
of the world; however, such variance is also influenced by the weights
allocated by other agents. To achieve the best possible estimate, the agents
must then solve a game-theoretic, multi-objective optimization problem defined
by the available sets of influence weights. We characterize both the Pareto
frontier and the set of Nash equilibria in the resulting game. Additionally, we
examine asynchronous best-response dynamics for the group of agents and prove
their convergence to the set of strict Nash equilibria.

</details>


### [22] [Spectral Outer-Approximation Algorithms for Binary Semidefinite Problems](https://arxiv.org/abs/2506.18265)
*Daniel de Roux,Zedong Peng,David E. Bernal Neira*

Main category: math.OC

TL;DR: 本文提出了一种针对二元二次约束二次规划（BQCQP）衍生的二元半定规划（BSDP）的谱外逼近算法，该算法在计算实验中表现优异，甚至超越现有ISDP求解器。


<details>
  <summary>Details</summary>
Motivation: 尽管整数半定规划（ISDP）与二元二次约束二次规划（BQCQP）存在关联，但现有ISDP求解器是否有效利用BQCQP的独特结构尚不明确。本文旨在填补这一空白。

Method: 提出了一种基于谱分解的谱外逼近算法，利用多面体和二阶可表示区域外逼近半定规划的可行集，同时对角化目标矩阵和约束矩阵的聚合矩阵。

Result: 计算实验表明，该算法在性能上与SCIP-SDP和PAJARITO等先进ISDP求解器相当，甚至在某些情况下表现更优。

Conclusion: 该研究凸显了ISDP在解决BQCQP问题中的潜力，并为相关领域提供了新的求解思路。

Abstract: Integer semidefinite programming (ISDP) has recently gained attention due to
its connection to binary quadratically constrained quadratic programs (BQCQPs),
which can be exactly reformulated as binary semidefinite programs (BSDPs).
However, it remains unclear whether this reformulation effectively uses
existing ISDP solvers to address BQCQPs. To the best of our knowledge, no
specialized ISDP algorithms exploit the unique structure of BSDPs derived from
BQCQPs. This paper proposes a novel spectral outer approximation algorithm
tailored for BSDPs derived from BQCQP reformulations. Our approach is inspired
by polyhedral and second-order representable regions that outer approximate the
feasible set of a semidefinite program relying on a spectral decomposition of a
matrix that simultaneously diagonalizes the objective matrix and an aggregation
of the constraint matrices. Computational experiments show that our algorithm
is competitive with, and in some cases outperforms, state-of-the-art ISDP
solvers such as SCIP-SDP and PAJARITO, highlighting ISDP's potential for
solving BQCQPs.

</details>


### [23] [Finite-Time Information-Theoretic Bounds in Queueing Control](https://arxiv.org/abs/2506.18278)
*Yujie Liu,Vincent Y. F. Tan,Yunbei Xu*

Main category: math.OC

TL;DR: 本文首次建立了随机处理网络中调度问题的有限时间信息论下界，并提出了达到这些下界的新策略。研究发现MaxWeight策略在有限时间内存在性能缺陷，并提出了一种优化Lyapunov漂移的新调度规则。


<details>
  <summary>Details</summary>
Motivation: 现有MaxWeight策略仅保证稳定性和在重负载下的渐近最优性，但缺乏对有限时间内性能的理论分析。本文旨在填补这一空白，揭示有限时间内调度策略的性能限制。

Method: 1) 建立极小极大框架确定问题参数；2) 推导总队列长度的信息论下界；3) 分析MaxWeight的局限性；4) 提出包含二阶项的Lyapunov漂移优化新策略。

Result: 证明了MaxWeight在有限时间内会因问题相关因素导致更大积压；新调度规则在一定条件下能匹配下界（误差为通用常数）。

Conclusion: 研究揭示了'仅漂移'方法的根本局限，为队列控制中的非渐近最优性提供了理论方向。新策略通过全面优化Lyapunov漂移实现了有限时间最优性突破。

Abstract: We establish the first finite-time information-theoretic lower bounds-and
derive new policies that achieve them-for the total queue length in scheduling
problems over stochastic processing networks with both adversarial and
stochastic arrivals. Prior analyses of MaxWeight guarantee only stability and
asymptotic optimality in heavy traffic; we prove that, at finite horizons,
MaxWeight can incur strictly larger backlog by problem-dependent factors which
we identify. Our main innovations are 1) a minimax framework that pinpoints the
precise problem parameters governing any policy's finite-time performance; 2)
an information-theoretic lower bound on total queue length; 3) fundamental
limitation of MaxWeight that it is suboptimal in finite time; and 4) a new
scheduling rule that minimizes the full Lyapunov drift-including its
second-order term-thereby matching the lower bound under certain conditions, up
to universal constants. These findings reveal a fundamental limitation on
"drift-only" methods and points the way toward principled, non-asymptotic
optimality in queueing control.

</details>


### [24] [A Computationally Efficient Method for Solving Mixed-Integer AC Optimal Power Flow Problems](https://arxiv.org/abs/2506.18301)
*Johannes Heid,Nils Bornhorst,Eric Tönges,Philipp Härtel,Denis Mende,Martin Braun*

Main category: math.OC

TL;DR: 提出了一种高效的迭代收缩方法，用于解决混合整数交流最优潮流问题，显著提高了求解精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理混合整数交流最优潮流问题时，往往面临精度不足或计算复杂度过高的挑战，难以满足实际应用需求。

Method: 通过迭代求解连续松弛的混合整数交流最优潮流问题，并基于简单潮流结果系统性地消除候选整数值，算法计算复杂度随整数变量数量线性增长。

Result: 仿真结果表明，与现有先进方法相比，所提方法在求解精度上取得了显著提升。

Conclusion: 该方法为解决实际混合整数交流最优潮流问题提供了高效且精确的解决方案，具有广阔的应用前景。

Abstract: Stepwise controllable devices, such as switched capacitors or stepwise
controllable loads and generators, transform the nonconvex AC optimal power
flow (AC-OPF) problem into a nonconvex mixed-integer (MI) programming problem
which is generally hard to solve optimally. Existing methods for solving
MI-AC-OPF problems usually suffer from either limited accuracy or computational
intractability, making them impractical for real-world applications. To address
these challenges, we propose an efficient iterative deflation approach
providing high-quality approximate solutions. In each iteration, a continuously
relaxed version of the MI-AC-OPF problem is solved and one candidate integer
value is systematically eliminated based on the evaluation of a simple power
flow result. The computational complexity of the proposed algorithm grows
linearly with the number of integer optimization variables, ensuring
scalability. Simulations demonstrate that the proposed approach achieves
significant improvements in solution accuracy compared to a state-of-the-art
approach. Thus, the proposed method is promising for solving practical
MI-AC-OPF problems.

</details>


### [25] [On the Maximization of Real Sequences](https://arxiv.org/abs/2506.18409)
*Assalé Adjé*

Main category: math.OC

TL;DR: 本文提出了一种基于上界逼近的通用方法，用于求解实数序列的最大化问题，并在多种著名序列上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究实数序列的最大化问题，旨在找到序列的上确界及对应最大项的索引，为理论分析和实际应用提供数学工具。

Method: 方法基于构造由严格递增连续函数序列和标量序列组成的上界逼近对，并通过函数在$[0,1]$上的逆映射关联整数索引。

Result: 证明了此类逼近对的存在性，其可提供序列最大值的上界及极大化索引，并在Logistic、Fibonacci等经典序列及线性系统范数峰值计算中得到应用验证。

Conclusion: 所提方法具有普适性和理论保证，能有效解决多种序列最大化问题，为离散系统分析提供了新工具。

Abstract: In this paper, we study a maximization problem on real sequences. More
precisely, for a given sequence, we are interesting in computing the supremum
of the sequence and an index for which the associated term is maximal. We
propose a general methodology to solve this maximization problem. The method is
based on upper approximations constructed from pairs of eventually decreasing
sequences of strictly increasing continuous functions on $[0,1]$ and of scalars
in $(0,1)$. Then, we can associate integers with those pairs using inverses on
$[0,1]$ of the functions. We prove that such pairs always exist and one
provides the index maximizer. In general, such pairs provide an upper bound of
the greatest maximizer of the sequence. Finally, we apply the methodology on
concrete examples including famous sequences such as logistic, Fibonacci and
Syracuse sequences. We also apply our techniques to norm based peaks
computation problems on discrete-time linear systems.

</details>


### [26] [An improved input-constrained funnel controller for nonlinear systems](https://arxiv.org/abs/2506.18417)
*Thomas Berger*

Main category: math.OC

TL;DR: 本文提出了一种改进的漏斗控制器设计，用于具有输入约束的高阶非线性多输入多输出系统，显著降低了控制器复杂度并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 针对现有漏斗控制器在非线性多输入多输出系统中设计参数多、复杂度高的问题，提出改进方案以简化设计并提升跟踪性能。

Method: 通过优化高阶泛函微分方程建模的控制器结构，减少设计参数数量，并在输入饱和未激活时确保跟踪误差按预设漏斗边界演化。

Result: 改进后的控制器复杂度显著降低，所需设计参数更少，仿真结果显示出更优越的控制性能。

Conclusion: 该研究为不确定非线性系统提供了一种更简洁高效的漏斗控制方案，在保证性能的同时大幅降低了实现难度。

Abstract: We present an improvement of a recent funnel controller design for uncertain
nonlinear multi-input, multi-output systems modeled by higher order functional
differential equations in the presence of input constraints. The objective is
to guarantee the evolution of the tracking error within a performance funnel
with prescribed desired shape for the case of inactive saturation. Compared to
its precursor, controller complexity is significantly reduced, much fewer
design parameters are involved and simulations exhibit a superior performance.

</details>


### [27] [FICA: Faster Inner Convex Approximation of Chance Constrained Grid Dispatch with Decision-Coupled Uncertainty](https://arxiv.org/abs/2506.18806)
*Yihong Zhou,Hanbin Yang,Thomas Morstyn*

Main category: math.OC

TL;DR: 本文提出了一种快速内凸近似方法(FICA)，用于解决具有Wasserstein分布鲁棒联合机会约束(WJCC)和自动发电控制因素建模的电力系统调度问题。该方法通过利用问题的一维结构特性，显著加速求解过程，计算速度提升可达500倍，同时保持与CVaR方法相同的近似质量。


<details>
  <summary>Details</summary>
Motivation: 针对电力系统调度中具有左侧不确定性的Wasserstein分布鲁棒联合机会约束(LHS-WJCC)问题计算复杂度高的挑战，研究旨在开发一种能保持最优性同时大幅提升计算效率的求解方法。

Method: 提出的FICA方法利用问题中(即使部分存在的)一维结构特性，引入一组强有效不等式加速求解过程。理论证明该方法与条件风险价值(CVaR)内凸近似法具有相同的最优性。

Result: 数值实验表明：1)在仅50%约束具有一维结构时，FICA相比CVaR可获得40倍加速；2)优化时间步长超过16步时加速比可达500倍；3)近似质量与CVaR相同，与计算密集的精确重构相比质量差距小于1%。

Conclusion: FICA方法在保持解质量的同时显著提升计算效率，适用于电力系统调度及其他具有(部分)一维结构特性的优化问题，为解决复杂分布鲁棒优化问题提供了有效工具。

Abstract: This paper proposes a Faster Inner Convex Approximation (FICA) method for
solving power system dispatch problems with Wasserstein distributionally robust
joint chance constraints (WJCC) and incorporating the modelling of the
automatic generation control factors. The problem studied belongs to the
computationally challenging class of WJCC with left-hand-side uncertainty
(LHS-WJCC). By exploiting the special one-dimensional structure (even if only
partially present) of the problem, the proposed FICA incorporates a set of
strong valid inequalities to accelerate the solution process. We prove that
FICA achieves the same optimality as the well-known conditional value-at-risk
(CVaR) inner convex approximation method. Our numerical experiments demonstrate
that the proposed FICA can yield 40x computational speedup compared to CVaR,
and can even reach up to 500x speedup when the optimisation horizon exceeds 16
time steps. This speedup is achieved when only 50% of constraints in a WJCC
have the one-dimensional structure. The approximation quality is numerically
verified to be the same as CVaR, and the quality gap is below 1% when compared
to the computationally demanding exact reformulation of the LHS-WJCC in most
cases. We also discuss the applications of FICA in optimisation problems from
other domains that (partially) exhibit the one-dimensional structure.

</details>


### [28] [A comparison principle for variational problems : with an application to optimal transport](https://arxiv.org/abs/2506.18884)
*Flavien Léger,Maxime Sylvestre*

Main category: math.OC

TL;DR: 本文研究了Banach空间上涉及子模能量的变分问题，通过将交换性概念扩展到无限维空间并与子模性建立对偶关系，推导出抽象比较原理，并应用于最优传输和熵最优传输问题。


<details>
  <summary>Details</summary>
Motivation: 研究Banach空间上子模能量的变分问题，旨在建立无限维空间中的交换性与子模性的对偶关系，为最优传输及其相关领域提供理论支持。

Method: 将交换性概念扩展到无限维空间，证明其与子模性的对偶关系，并利用这些概念在抽象框架下推导比较原理。随后将结果应用于最优传输和熵最优传输问题。

Result: 在Kantorovich势和Schr\"odinger势上建立了比较原理，并证明了相关JKO格式的比较原理。

Conclusion: 通过建立无限维空间中的交换性与子模性的对偶关系，成功推导出抽象比较原理，并将其应用于最优传输和熵最优传输问题，为相关领域提供了新的理论工具。

Abstract: We study variational problems on Banach spaces which involve submodular
energies. We extend the notion of exchangeability to this infinite dimensional
setting and show that it is in duality with submodularity. These two notions
allow us to derive comparison principle in an abstract fashion. We apply our
results to the optimal transport and entropic optimal transport problems. We
then derive comparison principles on the Kantorovich and Schr\"odinger
potentials. We also prove comparison principles for the associated JKO schemes.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [29] [Explicit conditional bounds for the residue of a Dedekind zeta-function at $s=1$](https://arxiv.org/abs/2506.17416)
*Stephan Ramon Garcia,Ethan Simpson Lee*

Main category: math.NT

TL;DR: 本文证明了关于数域Dedekind zeta函数在$s=1$处留数的新显式条件界，所有常数均给出具体数值。


<details>
  <summary>Details</summary>
Motivation: 研究Dedekind zeta函数在临界点$s=1$的留数行为，为解析数论提供更精确的定量工具。

Method: 采用显式分析方法，推导出具有具体数值常数的条件界公式。

Result: 获得了Dedekind zeta函数留数的新显式上界，所有常数均以明确数值形式呈现。

Conclusion: 该结果为数域zeta函数的解析性质提供了可计算的具体界限，具有实际应用价值。

Abstract: We prove new explicit conditional bounds for the residue at $s=1$ of the
Dedekind zeta-function associated to a number field. Our bounds are concrete
and all constants are presented with explicit numerical values.

</details>


### [30] [Infinitely many elliptic curves over $\mathbb{Q}(i)$ with rank 2 and $j$-invariant 1728](https://arxiv.org/abs/2506.17605)
*Ben Savoie*

Main category: math.NT

TL;DR: 该论文证明了在$\mathbb{Q}(i)$上存在无限多形式为$y^2 = x^3 - \gamma^2 x$的椭圆曲线，其秩为2，并给出了特定条件下椭圆曲线秩为2的构造方法。


<details>
  <summary>Details</summary>
Motivation: 研究在$\mathbb{Q}(i)$上具有特定形式且秩为2的椭圆曲线的存在性，以扩展对椭圆曲线算术性质的理解。

Method: 通过数论和代数几何的方法，构造并分析了特定形式的椭圆曲线，利用素数性质和模条件证明了秩为2的结论。

Result: 证明了无限多$y^2 = x^3 - \gamma^2 x$形式的椭圆曲线在$\mathbb{Q}(i)$上秩为2，并给出了特定素数条件下椭圆曲线秩为2的具体实例。

Conclusion: 该研究不仅证明了无限多秩为2的椭圆曲线的存在性，还提供了具体的构造条件，为椭圆曲线的算术研究提供了新的工具和视角。

Abstract: We prove that there exist infinitely many elliptic curves over
$\mathbb{Q}(i)$ of the form $y^2 = x^3 - \gamma^2 x$, where $\gamma \in
\mathbb{Z}[i]$, with rank 2. In addition, we prove that if $p$ and $q$ are
rational twin primes with $p \equiv 5 \bmod 8$, then $y^2 = x^3 + p q x$ has
rank 2 over $\mathbb{Q}(i)$. Lastly, we prove that if $p$ is a rational prime
of the form $p = a^2 + b^4$ (of which there are infinitely many) and $p
\not\equiv 1 \bmod 16$, then $y^2 = x^3 - p x$ has rank 2 over $\mathbb{Q}(i)$.

</details>


### [31] [Pattern formation Statistics on Fermat Quotients](https://arxiv.org/abs/2506.17684)
*Cristian Cobeli,Alexandru Zaharescu,Zhuo Zhang*

Main category: math.NT

TL;DR: 研究费马商模$p$的随机性与规律性，证明矩阵行表现类似随机序列，而空间统计符合预期。


<details>
  <summary>Details</summary>
Motivation: 费马商模$p$定义为$\mathfrak{q}_p(b):=\frac{b^{p-1}-1}{p} \pmod p$，虽然定义简单且排列规则，但整体缺乏规律性。研究旨在探讨这种矛盾现象。

Method: 通过分析$p\times(p-1)$费马商矩阵$\mathtt{FQM}(p)$，研究其行的随机分布特性及$N$-模式的空间统计。

Result: 证明矩阵的每一行表现类似随机序列，同时空间统计结果符合自然预期。

Conclusion: 费马商模$p$在局部表现出随机性，但在整体空间统计上仍遵循规律，揭示了其复杂的数学特性。

Abstract: Despite their simple definition as $\mathfrak{q}_p(b):=\frac{b^{p-1}-1}{p}
\pmod p$, for $0\le b \le p^2-1$ and $\gcd(b,p)=1$, and their regular
arrangement in a $p\times(p-1)$ Fermat quotient matrix $\mathtt{FQM}(p)$ of
integers from $[0,p-1]$, Fermat quotients modulo $p$ are well known for their
overall lack of regularity. Here, we discuss this contrasting effect by proving
that, on the one hand, any line of the matrix behaves like an analogue of a
randomly distributed sequence of numbers, and on the other hand, the spatial
statistics of distances on regular $N$-patterns confirm the natural
expectations.

</details>


### [32] [The hyperbolic lattice counting problem in large dimensions](https://arxiv.org/abs/2506.17753)
*Christos Katsivelos*

Main category: math.NT

TL;DR: 研究双曲空间$\mathbb{H}^n$上余紧格点$\Gamma$作用下的圆问题误差项的局部平均行为，给出上界并证明均值及二阶矩的$\Omega$结果。


<details>
  <summary>Details</summary>
Motivation: 探讨双曲空间上格点作用下的圆问题误差项的平均行为，以深化对几何与谱理论联系的理解。

Method: 通过量子方差和谱指数和在素数测地线定理中的应用，分析误差项的局部平均。

Result: 证明了误差项局部平均的上界依赖量子方差与谱指数和，并得到均值及二阶矩的$\Omega$结果。

Conclusion: 该研究为双曲空间上圆问题误差项的平均行为提供了新的理论工具和结果，拓展了相关领域的认知。

Abstract: For $n\geq 3$ and $\Gamma$ a cocompact lattice acting on the hyperbolic space
$\mathbb{H}^n$, we investigate the average behaviour of the error term in the
circle problem. First, we explore the local average of the error term over
compact sets of $\Gamma\backslash\mathbb{H}^n$. Our upper bound depends on the
quantum variance and the spectral exponential sums appearing in the study of
the Prime geodesic theorem. We also prove $\Omega$-results for the mean value
and the second moment of the error term.

</details>


### [33] [Liouville function, von Mangoldt function and norm forms at random binary forms](https://arxiv.org/abs/2506.18065)
*Yijie Diao*

Main category: math.NT

TL;DR: 本文研究了二元形式算术函数的平均行为，验证了Chowla猜想和Bateman-Horn猜想的平均版本，并证明了Colliot-Th\'el\`ene猜想在特定条件下的平均成立性。


<details>
  <summary>Details</summary>
Motivation: 探讨二元形式算术函数的平均行为，为Chowla猜想、Bateman-Horn猜想以及Colliot-Th\'el\`ene猜想提供概率为1的平均版本验证。

Method: 通过分析高度排序的$d$次二元形式的算术函数平均值，结合概率为1的极限行为研究方法。

Result: 证明了Chowla猜想和Bateman-Horn猜想在随机二元形式下的平均成立性，并验证了当$e$整除$d$时，几乎所有的Ch\^atelet簇满足有理Hasse原理。

Conclusion: 该研究为相关数论猜想提供了平均意义上的支持，扩展了对二元形式算术性质的理解，并部分解决了Colliot-Th\'el\`ene猜想。

Abstract: We analyze the average behavior of various arithmetic functions at the values
of degree $d$ binary forms ordered by height, with probability $1$. This
approach yields averaged versions of the Chowla conjecture and the Bateman-Horn
conjecture for random binary forms. Furthermore, we show that the rational
Hasse principle holds for almost all Ch\^atelet varieties defined by a fixed
norm form of degree $e$ and by varying binary forms of fixed degree $d$,
provided $e$ divides $d$. This proves an average version of a conjecture of
Colliot-Th\'el\`ene.

</details>


### [34] [Differential operators on Hermitian modular forms on $\mathrm{u}(n, n)$](https://arxiv.org/abs/2506.18236)
*Nobuki Takeda*

Main category: math.NT

TL;DR: 本文构建了Hermite模形式上的显式微分算子，扩展了Siegel模形式的方法，并应用于推导Hermite Eisenstein级数的精确拉回公式。


<details>
  <summary>Details</summary>
Motivation: 研究Hermite模形式上的微分算子，旨在扩展Siegel模形式的方法，并探索其与双变量球面多调和多项式的关系。

Method: 通过构造双变量球面多调和多项式的显式基，并利用这些基构建具体的微分算子。

Result: 成功构建了Hermite模形式上的显式微分算子，并推导了Hermite Eisenstein级数的精确拉回公式。

Conclusion: 该方法不仅扩展了Siegel模形式的技术，还为Hermite模形式的研究提供了新的工具和应用。

Abstract: We construct explicit differential operators on hermitian modular forms,
extending methods developed for Siegel modular forms. These differential
operators are closely related to the two-variable spherical pluriharmonic
polynomials. We construct explicit bases for the space of such polynomials and
use them to build concrete operators. As an application, we derive an exact
pullback formula for hermitian Eisenstein series.

</details>


### [35] [On a conjectural supercongruence involving the dual sequence $s_n(x)$](https://arxiv.org/abs/2506.18287)
*Chen Wang,Sheng-Jie Wang*

Main category: math.NT

TL;DR: 本文证明了Z.-W. Sun关于多项式序列$s_n(x)$模$p^3$超同余的猜想。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于Kimoto和Wakayama提出并由Long、Osburn和Swisher证实的超同余猜想，Z.-W. Sun由此引入多项式序列$s_n(x)$并研究其同余性质。

Method: 通过分析多项式序列$s_n(x)$的表达式及其组合性质，研究了其在素数$p>3$和$p$-adic整数$x\neq-1/2$条件下的模$p^3$行为。

Result: 证实了对于任意素数$p>3$和$p$-adic整数$x\neq-1/2$，有$\sum_{n=0}^{p-1}s_n(x)^2\equiv (-1)^{\langle x\rangle_p}\frac{p+2(x-\langle x\rangle_p)}{2x+1}\pmod{p^3}$成立。

Conclusion: 成功验证了Z.-W. Sun提出的关于多项式序列$s_n(x)$的超同余猜想，为相关数论问题提供了新的理论支持。

Abstract: In 2017, motivated by a supercongruence conjectured by Kimoto and Wakayama
and confirmed by Long, Osburn and Swisher, Z.-W. Sun introduced the sequence of
polynomials: $$
s_n(x)=\sum_{k=0}^n\binom{n}{k}\binom{x}{k}\binom{x+k}{k}=\sum_{k=0}^n\binom{n}{k}(-1)^k\binom{x}{k}\binom{-1-x}{k}
$$ and investigated its congruence properties. In particular, Z.-W. Sun
conjectured that for any prime $p>3$ and $p$-adic integer $x\neq-1/2$ one has
\begin{equation*} \sum_{n=0}^{p-1}s_n(x)^2\equiv (-1)^{\langle
x\rangle_p}\frac{p+2(x-\langle x\rangle_p)}{2x+1}\pmod{p^3}, \end{equation*}
where $\langle x\rangle_p$ denotes the least nonnegative residue of $x$ modulo
$p$. In this paper, we confirm this conjecture.

</details>


### [36] [Stratification theorems for exponential sums in families](https://arxiv.org/abs/2506.18299)
*Dante Bonolis,Emmanuel Kowalski,Katharine Woo*

Main category: math.NT

TL;DR: 本文综述了有限域上指数和的层化定理，特别是Katz-Laumon和Fouvry-Katz的成果，并证明了这些定理在代数与解析层面具有统一的族变体。附录提供了多变量有限域上迹函数的直观介绍。


<details>
  <summary>Details</summary>
Motivation: 受Bonolis、Pierce和Woo近期工作的启发，研究有限域上指数和层化定理的统一族变体。

Method: 综述已有层化定理，并代数与解析地证明其在族中的统一性。附录采用初等方法介绍多变量迹函数。

Result: 证明了Katz-Laumon和Fouvry-Katz的层化定理在代数族和解析族中具有统一形式。

Conclusion: 有限域指数和层化定理的统一族变体拓展了其应用范围，附录为多变量迹函数研究提供了基础。

Abstract: We survey some of the stratification theorems concerning exponential sums
over finite fields, especially those due to Katz-Laumon and Fouvry-Katz, as
well as some of their applications. Moreover, motivated partly by recent work
of Bonolis, Pierce and Woo (arXiv:2505.11226), we prove that these
stratification statements admit uniform variants in families, both
algebraically and analytically.
  The paper includes an Appendix by Forey, Fres\'an and Kowalski (excerpted
from arXiv:2109.11961), which provides an elementary intuitive introduction to
trace functions in more than one variable over finite fields.

</details>


### [37] [The second moment of Ramanujan sums](https://arxiv.org/abs/2506.18395)
*Hong Ziwei,Zheng Zhiyong*

Main category: math.NT

TL;DR: 本文在黎曼假设下，改进了拉马努金和二项$C(x, y)$的渐近公式误差项精度，并允许$x$与$y$任意接近。


<details>
  <summary>Details</summary>
Motivation: 研究拉马努金和二项$C(x, y)$的渐近行为，特别是在$x$和$y$接近时的表现，以深化对数论中相关问题的理解。

Method: 假设黎曼假设成立，采用分析方法推导$C(x, y)$的渐近公式，重点改进误差项的精度。

Result: 得到了$C(x, y)$的更精确渐近公式，且允许$x$和$y$任意接近，这在以往研究中较为罕见。

Conclusion: 该研究不仅改进了拉马努金和二阶矩的渐近分析，还为$x$和$y$接近情况下的数论问题提供了新的工具。

Abstract: In this paper, we analyze $C(x, y)$, the second moment of Ramanujan sums.
Assuming the Riemann Hypothesis, we derive an asymptotic formula for $C(x, y)$
with improved error term precision. The key feature of our approach is that it
allows $x$ and $y$ to be arbitrarily close.

</details>


### [38] [Partial sums of the hyperharmonic series](https://arxiv.org/abs/2506.18461)
*Hongguang Wu,Jun Qiu*

Main category: math.NT

TL;DR: 本文扩展了Erd\"os和Niven的结论，证明超调和级数的部分和也互不相等。


<details>
  <summary>Details</summary>
Motivation: 受1946年Erd\"os和Niven关于调和级数部分和唯一性的启发，研究超调和级数的类似性质。

Method: 通过数学推导和证明，扩展了原始定理的适用范围至超调和级数。

Result: 严格证明了超调和级数的任意两个部分和不可能相等。

Conclusion: 该研究不仅推广了经典结果，还为级数唯一性理论提供了新的见解。

Abstract: In 1946, Erd\"os and Niven proved that no two partial sums of the harmonic
series are equal. In this paper, we extend this result by demonstrating that no
two partial sums of the hyperharmonic series are equal.

</details>


### [39] [Lambert series and double Lambert series](https://arxiv.org/abs/2506.18712)
*Tewodros Amdeberhan,George E. Andrews,Cristina Ballantine*

Main category: math.NT

TL;DR: 本文探讨经典Lambert级数、多重Lambert级数与Rogers-Ramanujan型经典$q$-级数之间的关系，并对Andrews-Dixit-Schultz-Yee猜想进行了思考。


<details>
  <summary>Details</summary>
Motivation: 研究Lambert级数与$q$-级数之间的内在联系，深化对特殊函数理论的理解。

Method: 通过数学分析手段，对比研究经典Lambert级数、多重Lambert级数及Rogers-Ramanujan型$q$-级数的性质与关系。

Result: 建立了不同类型级数之间的关联性，为相关数学领域提供了新的理论视角。

Conclusion: 研究不仅验证了级数间的深刻联系，还为Andrews-Dixit-Schultz-Yee猜想的后续研究奠定了基础。

Abstract: We consider relationships between classical Lambert series, multiple Lambert
series and classical $q$-series of the Rogers-Ramanujan type. We conclude with
a contemplation on the Andrews-Dixit-Schultz-Yee conjecture.

</details>


### [40] [New evidence for Rémond's generalisation of Lehmer's conjecture](https://arxiv.org/abs/2506.18776)
*Sara Checcoli,Gabriel Andreas Dill*

Main category: math.NT

TL;DR: 本文推广了Pottmeyer的结果，从代数数乘法群到数域上定义的几乎分裂半阿贝尔簇，证明了在商去$\Gamma$的饱和闭包后，有理点群成为自由群。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于R\'emond对Lehmer猜想的推广，探讨几乎分裂半阿贝尔簇中有限秩子群$\Gamma$的有理点群结构。

Method: 方法结合了Pottmeyer基于Pontryagin结果的判别准则，以及Kummer理论中的R\'emond证明。

Result: 结果表明，在商去$\Gamma$的饱和闭包后，$G$在有限扩张域上的有理点群成为自由群。

Conclusion: 结论验证了几乎分裂半阿贝尔簇中特定子群结构的自由性，为相关数论问题提供了新的理论支持。

Abstract: In this article, we generalise a result of Pottmeyer from the multiplicative
group of the algebraic numbers to almost split semiabelian varieties defined
over number fields. This concerns a consequence of R\'emond's generalisation of
Lehmer's conjecture. Namely, for a finite rank subgroup $\Gamma$ of an almost
split semiabelian variety $G$, we consider the group of rational points of $G$
over a finite extension of the field generated by the saturated closure of
$\Gamma$, i.e. the division closure of the subgroup generated by $\Gamma$ and
all its images under geometric endomorphisms of $G$. We show that this becomes
a free group after one quotients out the saturated closure of $\Gamma$. The
proof uses, amongst other ingredients, a criterion of Pottmeyer, which relies
on a result of Pontryagin, together with a result from Kummer theory, of which
we reproduce a proof by R\'emond.

</details>


### [41] [Counting elliptic curves over $\mathbb{Q}$ with bounded naive height](https://arxiv.org/abs/2506.18874)
*Adrian Barquero-Sanchez,Daniel Mora-Mora*

Main category: math.NT

TL;DR: 本文提供了椭圆曲线$E_{A,B} \colon y^2 = x^3 + Ax + B$在朴素高度排序下的精确与渐近计数公式，涵盖所有曲线及特定子族（如固定$j$-不变量或复乘曲线），并比较了两种常见朴素高度归一化方法的公式。


<details>
  <summary>Details</summary>
Motivation: 研究椭圆曲线在朴素高度下的计数问题，旨在为不同归一化方法（校准与非校准朴素高度）提供统一的理论框架，并验证理论预测与实际计算数据的一致性。

Method: 通过显式参数化固定$j$-不变量且高度有界的曲线集，将其表示为最小高度曲线的扭形式，并结合SageMath代码实现精确与渐近公式的计算。

Result: 推导出广义朴素高度$H_{\alpha, \beta}(E_{A,B}) := \max\{ \alpha |A|^3, \beta B^2 \}$的计数公式，提供高达$10^{30}$的复乘曲线数据，并通过计算机搜索验证理论结果。

Conclusion: 论文建立了椭圆曲线计数问题的通用理论工具，其公式适用于任意归一化参数，且开源代码为后续研究提供了可扩展的计算基础。

Abstract: In this paper, we give exact and asymptotic formulas for counting elliptic
curves $ E_{A,B} \colon y^2 = x^3 + Ax + B $ with $ A, B \in \mathbb{Z} $,
ordered by naive height. We study the family of all such curves and also
several natural subfamilies, including those with fixed $ j $-invariant and
those with complex multiplication (CM). In particular, we provide formulas for
two commonly used normalizations of the naive height appearing in the
literature: the calibrated naive height, defined by \[
H^{\mathrm{cal}}(E_{A,B}) := \max\{ 4|A|^3, 27B^2 \}, \] and the uncalibrated
naive height, defined by \[ H^{\mathrm{ncal}}(E_{A,B}) := \max\{ |A|^3, B^2 \}.
\] In fact, we prove our theorems with respect to the more general naive height
$H_{\alpha, \beta}(E_{A,B}) := \max\{ \alpha |A|^3, \beta B^2 \}$, defined for
arbitrary positive real numbers $\alpha, \beta \in \mathbb{R}_{> 0}$.
  As part of our approach, we give a completely explicit parametrization of the
set of curves $ E_{A,B} $ with fixed $ j $-invariant and bounded naive height,
describing them as twists of the curve $ E_{A_j, B_j} $ of minimal naive height
for the given $ j $-invariant. We also include tables comparing and verifying
our theoretical predictions with exact counts obtained via exhaustive computer
searches, and we compute data for CM elliptic curves of naive height up to $
10^{30} $. Code in SageMath is provided to compute all exact and asymptotic
formulas appearing in the paper.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [42] [Finite Combinatorics and Fragments of Arithmetic](https://arxiv.org/abs/2506.17943)
*Wei Wang*

Main category: math.LO

TL;DR: 该论文研究了在缺乏$B\Sigma_{n+1}$的情况下，一阶算术片段中$\Sigma_{n+1}$-可定义映射在有限域上的组合性质，比较了不同鸽巢原理变体之间的关系。


<details>
  <summary>Details</summary>
Motivation: 探讨有限域上$\Sigma_{n+1}$-可定义映射与有限映射行为的差异，特别是在$B\Sigma_{n+1}$缺失时的组合性质。

Method: 通过比较$\mathrm{GPHP}(\Sigma_{n+1})$、$\mathrm{CARD}(\Sigma_{n+1})$和$\mathrm{WPHP}(\Sigma_{n+1})$之间的关系，以及分析$\mathrm{FRT}(\Sigma_{n+1})$与$\mathrm{WPHP}(\Sigma_{n+1})$的独立性。

Result: 证明了$\mathrm{GPHP}(\Sigma_{n+1})$严格位于$\mathrm{CARD}(\Sigma_{n+1})$和$\mathrm{WPHP}(\Sigma_{n+1})$之间，且$\mathrm{FRT}(\Sigma_{n+1})$不蕴含$\mathrm{WPHP}(\Sigma_{n+1})$。

Conclusion: 研究揭示了$\Sigma_{n+1}$-可定义映射在有限域上的复杂组合行为，为理解一阶算术片段中的鸽巢原理提供了新的理论依据。

Abstract: In fragments of first order arithmetic, definable maps on finite domains
could behave very differently from finite maps. Here combinatorial properties
of $\Sigma_{n+1}$-definable maps on finite domains are compared in the absence
of $B\Sigma_{n+1}$. It is shown that $\mathrm{GPHP}(\Sigma_{n+1})$ (the
$\Sigma_{n+1}$-instance of Kaye's General Pigeonhole Principle) lies strictly
between $\mathrm{CARD}(\Sigma_{n+1})$ and $\mathrm{WPHP}(\Sigma_{n+1})$ (Weak
Pigeonhole Principle for $\Sigma_{n+1}$-maps), and also that
$\mathrm{FRT}(\Sigma_{n+1})$ (Finite Ramsey's Theorem for $\Sigma_{n+1}$-maps)
does not imply $\mathrm{WPHP}(\Sigma_{n+1})$.

</details>


### [43] [Projective length, phantom extensions, and the structure of flat modules](https://arxiv.org/abs/2506.17982)
*Matteo Casarosa,Martino Lupini*

Main category: math.LO

TL;DR: 本文从拓扑概念推广至三角范畴，提出可数Dedekind域上平坦模的幻影扩张概念，建立了复杂度理论刻画，并证明了一个二分法定理。通过构造规范幻影投射分解，定义了精确结构$\mathcal{E}_{\alpha}$，并给出了平坦模的结构定理。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于将幻影映射的阶数概念从拓扑学推广至三角范畴，特别是可数Dedekind域上平坦模的导出范畴，以探索幻影扩张的性质及其在模论中的应用。

Method: 方法包括定义幻影扩张的阶数$\alpha$，利用波兰模的左心结构对$\mathrm{Ext}(C,A)$进行复杂度刻画，构造幻影投射分解，并建立精确结构$\mathcal{E}_{\alpha}$。

Result: 主要结果包括二分法定理（平坦模$A$要么所有扩张平凡，要么存在任意高阶幻影扩张），以及结构定理（将$\mathcal{P}_{\alpha}$类对象刻画为有限平坦模预层在秩$1+\alpha$良基森林上的余极限直和项）。

Conclusion: 结论表明该研究首次在平坦模情形建立了类似于挠模Ulm分类定理的结构理论，揭示了幻影扩张阶数与模的投射长度之间的深刻联系，为平坦模分类提供了新工具。

Abstract: We consider the natural generalization of the notion of the order of a
phantom map from the topological setting to triangulated categories. When
applied to the derived category of the category of countable flat modules over
a countable Dedekind domain, this yields a notion of\emph{\ phantom extension}
of order $\alpha <\omega _{1}$. We provide a complexity-theoretic
characterization of the module $\mathrm{Ph}% ^{\alpha }\mathrm{Ext}\left(
C,A\right) $ of phantom extensions of order $\alpha $ with respect to the
structure of \emph{phantom Polish module} on $\mathrm{Ext}\left( C,A\right) $
obtained by considering it as an object of the left heart of the quasi-abelian
category of Polish modules. We use this characterization to prove the following
Dichotomy Theorem: either all the extensions of a countable flat module $A$ are
trivial (which happens precisely when $A$ is divisible) or $A$ has phantom
extensions of arbitrarily high order.
  By producing canonical phantom projective resolutions of order $\alpha $, we
prove that phantom extensions of order $\alpha $ define on the category of
countable flat modules an exact structure $\mathcal{E}_{\alpha }$ that is
hereditary with enough projectives, and the functor $\mathrm{Ph}^{\alpha }%
\mathrm{Ext}$ is the derived functor of $\mathrm{Hom}$ with respect to
$\mathcal{E}_{\alpha }$. We prove a Structure Theorem characterizing the
objects of the class $\mathcal{P}_{\alpha }$ of countable flat modules that
have \emph{projective length at most }$\alpha $ (i.e., are $\mathcal{E}_{\alpha
}$-projective) as the direct summands of colimits of presheaves of finite flat
modules over well-founded forests of rank $% 1+\alpha $ regarded as ordered
sets. This can be seen as the first analogue in the flat case of the classical
Ulm Classification Theorem for torsion modules.

</details>


<div id='math.GM'></div>

# math.GM [[Back]](#toc)

### [44] [Some interesting number theory problems](https://arxiv.org/abs/2506.17235)
*Wenpeng Zhang*

Main category: math.GM

TL;DR: 本文提出了一些与勒让德符号和双项指数和相关的有趣数论问题。


<details>
  <summary>Details</summary>
Motivation: 研究勒让德符号和双项指数和在数论中的重要性及其潜在应用。

Method: 通过分析勒让德符号的性质和双项指数和的结构，提出相关问题。

Result: 提出了一系列与勒让德符号和双项指数和相关的数论问题，为后续研究提供了方向。

Conclusion: 这些问题的研究将有助于深入理解勒让德符号和双项指数和在数论中的作用。

Abstract: The main purpose of this paper is to propose some interesting number theory
problems related to the Legendre's symbol and the two-term exponential sums.

</details>


### [45] [More Relationships between a Central Quadrilateral and its Reference Quadrilateral](https://arxiv.org/abs/2506.17240)
*Stanley Rabinowitz,Ercole Suppa*

Main category: math.GM

TL;DR: 研究四边形对角线形成的四个半三角形中不同三角形中心构成的新四边形（中心四边形）与原四边形的关系。通过计算机分析1000种三角形中心，比较两者在形状、面积、周长等方面的异同。


<details>
  <summary>Details</summary>
Motivation: 探讨四边形与其对角线形成的半三角形中各种三角形中心所构成的新四边形之间的几何关系，扩展对四边形性质的理解。

Method: 在四边形的四个半三角形中分别定位1000种不同的三角形中心（如重心、垂心等），形成中心四边形，并通过计算机程序比较原四边形与中心四边形的几何特性（如全等、相似、面积或周长相等）。

Result: 研究发现，对于不同形状的四边形和不同的三角形中心，原四边形与中心四边形之间存在多种几何关系，如相似性或面积相等。具体关系取决于四边形类型和所选三角形中心。

Conclusion: 通过系统分析，揭示了四边形与其中心四边形之间的丰富几何联系，为四边形和三角形中心的进一步研究提供了基础。

Abstract: The diagonals of a quadrilateral form four associated triangles, called half
triangles. Each half triangle is bounded by two sides of the quadrilateral and
one diagonal. If we locate a triangle center (such as the incenter, centroid,
orthocenter, etc.) in each of these triangles, the four triangle centers form
another quadrilateral called a central quadrilateral. For each of various
shaped quadrilaterals, and each of 1000 different triangle centers, we compare
the reference quadrilateral to the central quadrilateral. Using a computer, we
determine how the two quadrilaterals are related. For example, we test to see
if the two quadrilaterals are congruent, similar, have the same area, or have
the same perimeter.

</details>


### [46] [A study of a family of self-referential sequences](https://arxiv.org/abs/2506.18103)
*Benoit Cloitre*

Main category: math.GM

TL;DR: 本文提出并分析了一个三参数自引用整数序列族$S(x,y,z)$，揭示了其多样行为模式，包括密度收敛性、非均匀Beatty序列生成、周期性规律及与元斐波那契递推的深刻联系。


<details>
  <summary>Details</summary>
Motivation: 针对OEIS中大量未分类的自引用序列行为，建立统一理论框架以解释其生成机制与数学特性。

Method: 通过定义递推规则$a(k)$（索引$k$已出现时步进$y$，否则步进$z$），结合代数方程求根、几何模式分析与树状表示法展开研究。

Result: 证明当$y>z>0$时序列密度收敛于方程$r^2 - z r - (y - z) = 0$的正根；发现两类子族可显式生成非均匀Beatty序列；零判别量情形揭示晶格几何模式；建立与元斐波那契递推的等价性。

Conclusion: 该序列族为理解OEIS中复杂自引用序列提供了系统性工具，其数学结构在数论、离散几何与递推理论中具有广泛意义。

Abstract: We introduce and analyze a three-parameter family of self-referential integer
sequences $S(x,y,z)$: starting from $a(1)=x$, each term advances by $y$ when
the index $k$ has already appeared as a value and by $z$ otherwise. This simple
rule generates a surprising zoo of behaviors, many of which are catalogued --
albeit in a rather unstructured fashion -- in the OEIS. Whenever $y>z>0$, we
prove that the density $a(k)/k$ converges to the positive root of $r^2 - z r -
(y - z) = 0$. Two subfamilies, $S(x,Z+1,Z)$ and $S(x,Z,Z+1)$, yield explicit
non-homogeneous Beatty sequences, providing explicit formulas for numerous OEIS
entries. For $y=0$ and $z \ge 2$, the sequences eventually become periodic and
satisfy linear recurrences. Critical cases with a zero discriminant unveil
geometric patterns on triangular, square, and hexagonal lattices. Finally, via
tree-like representations we uncover a tight link with meta-Fibonacci
recurrences.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [47] [Notes on sum-free sets in abelian groups](https://arxiv.org/abs/2506.17401)
*Nathanaël Hassler,Andrew Treglown*

Main category: math.CO

TL;DR: 本文探讨了阿贝尔群中最大无和集的一些开放性问题，并对大多数偶数阶阿贝尔群$G$中最大无和子集的数量进行了渐近确定。


<details>
  <summary>Details</summary>
Motivation: 研究阿贝尔群中最大无和集的性质及其数量，填补该领域的理论空白。

Method: 利用容器方法（container method）进行证明。

Result: 对于大多数偶数阶阿贝尔群$G$，渐近确定了其最大无和子集的数量。

Conclusion: 该研究为阿贝尔群中最大无和集的理论提供了新的进展，并指出了未来可能的开放性问题。

Abstract: In this paper we highlight a few open problems concerning maximal sum-free
sets in abelian groups. In addition, for most even order abelian groups $G$ we
asymptotically determine the number of maximal distinct sum-free subsets in
$G$. Our proof makes use of the container method.

</details>


### [48] [The characteristic polynomial of sunflowers](https://arxiv.org/abs/2506.17628)
*Changjiang Bu,Lixiang Chen,Ge Lin*

Main category: math.CO

TL;DR: 本文研究了向日葵超图的特征多项式，通过确定其特征值和谱矩，给出了明确的公式表达。


<details>
  <summary>Details</summary>
Motivation: 向日葵超图因其独特的结构特性在超图理论中具有重要地位，研究其特征多项式有助于深入理解其代数性质。

Method: 通过分析向日葵超图的结构特性，推导其特征值和谱矩，最终建立特征多项式的显式公式。

Result: 成功确定了向日葵超图的所有特征值和谱矩，并得到了其特征多项式的显式表达式。

Conclusion: 该研究为向日葵超图的代数性质提供了完整的数学描述，为后续相关研究奠定了理论基础。

Abstract: A uniform hypergraph is called a sunflower if all of its hyperedges intersect
in the same set of vertices. In this paper, we determine the eigenvalues and
spectral moments of a sunflower, thereby obtaining an explicit formula for its
characteristic polynomial.

</details>


### [49] [Entropy Bounds for Perfect Matchings in Bipartite Hypergraphs](https://arxiv.org/abs/2506.17652)
*Tantan Dai,Alexander Divoux,Tom Kelly*

Main category: math.CO

TL;DR: 该论文研究了均匀超图中A-完美匹配数量的上界，并应用于拉丁方和超图的边着色问题，得出了具体的数量限制。


<details>
  <summary>Details</summary>
Motivation: 研究超图中A-完美匹配的数量上界，以及其在拉丁方和超图边着色问题中的应用，旨在为组合数学中的相关问题提供理论支持。

Method: 通过证明均匀超图中A-完美匹配数量的上界，结合最大共度较小的条件，进一步应用于拉丁方的横截数和超图的边着色问题。

Result: 证明了当n为奇数且n≡0(mod3)时，存在阶数为n的拉丁方，其横截数不超过$(n/e^{2.117})^n$；同时，对于k-均匀D-正则超图，当q=(1+o(1))D且最大共度为o(q)时，其真q-边着色数不超过$((1+o(1))q/e^k)^{Dn/k}$。

Conclusion: 该研究为超图中的匹配问题、拉丁方的横截数以及超图的边着色问题提供了新的上界结果，扩展了组合数学的理论基础。

Abstract: A hypergraph is \textit{bipartite with bipartition} $(A, B)$ if every edge
has exactly one vertex in $A$, and a matching in such a hypergraph is
\textit{$A$-perfect} if it saturates every vertex in $A$. We prove an upper
bound on the number of $A$-perfect matchings in uniform hypergraphs with small
maximum codegree. Using this result, we prove that there exist order-$n$ Latin
squares with at most $(n/e^{2.117})^n$ transversals when $n$ is odd and $n
\equiv 0\pmod 3$. We also show that $k$-uniform $D$-regular hypergraphs on $n$
vertices have at most $((1+o(1))q/e^k)^{Dn/k}$ proper $q$-edge-colorings when
$q = (1+o(1))D$ and the maximum codegree is $o(q)$.

</details>


### [50] [Coloring outside the lines: Spectral bounds for generalized hypergraph colorings](https://arxiv.org/abs/2506.17659)
*Lies Beers,Raffaella Mulas*

Main category: math.CO

TL;DR: 该论文研究了定向超图的染色数与其归一化拉普拉斯特征值之间的关系，给出了紧界的必要条件，并将结果推广到$d$-proper着色、$d$-improper着色以及超图的边着色。


<details>
  <summary>Details</summary>
Motivation: 研究定向超图的染色数与其归一化拉普拉斯特征值之间的不等式关系，并探讨该不等式紧界的条件，进一步推广到其他着色问题。

Method: 通过分析定向超图的归一化拉普拉斯特征值$\lambda_1$和$\lambda_N$，推导染色数$\chi$的下界，并研究紧界的必要条件。随后将方法推广到$d$-proper着色、$d$-improper着色和超图边着色。

Result: 证明了定向超图的染色数满足$\chi\geq (\lambda_N-\lambda_1)/\min\{\lambda_N-1,1-\lambda_1\}$，并给出了紧界的必要条件。进一步推广到$d$-proper着色、$d$-improper着色和超图边着色，并给出了类似的光谱界限。

Conclusion: 该研究为定向超图及其他着色问题提供了光谱界限，并明确了紧界的条件，为相关领域的进一步研究奠定了基础。

Abstract: It is known that, for an oriented hypergraph with (vertex) coloring number
$\chi$ and smallest and largest normalized Laplacian eigenvalues $\lambda_1$
and $\lambda_N$, respectively, the inequality $\chi\geq
(\lambda_N-\lambda_1)/\min\{\lambda_N-1,1-\lambda_1\}$ holds. We provide
necessary conditions for oriented hypergraphs for which this bound is tight.
Focusing on $c$-uniform unoriented hypergraphs, we then generalize the bound to
the setting of \emph{$d$-proper colorings}: colorings in which no edge contains
more than $d$ vertices of the same color. We also adapt our proof techniques to
derive analogous spectral bounds for \emph{$d$-improper colorings} of graphs
and for edge colorings of hypergraphs. Moreover, for all coloring notions
considered, we provide necessary conditions under which the bound is an
equality.

</details>


### [51] [Quantum $\mathfrak{gl}$-weight system and its average values](https://arxiv.org/abs/2506.17706)
*Mikhail Zaitsev*

Main category: math.CO

TL;DR: 本文证明了Kazarian等人提出的关于$\mathfrak{gl}$-权系统在置换上平均值的猜想，通过量子类比方法得到了一参数变形，并表明该量子权系统的平均值是单部分Schur函数的线性组合。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于验证Kazarian等人提出的$\mathfrak{gl}$-权系统平均值的猜想，探索其在量子框架下的推广形式。

Method: 采用$A$型Hecke代数上的量子$\mathfrak{gl}$-权系统类比方法，构造了一参数变形的平均权系统。

Result: 证明了量子权系统的平均值可表示为单部分Schur函数的线性组合，其系数为Bernoulli多项式的$q$-模拟。

Conclusion: 该工作不仅证实了原始猜想，还通过量子变形拓展了理论框架，揭示了$\mathfrak{gl}$-权系统与Schur函数之间的深层联系。

Abstract: We present a proof of a recent conjecture due to M. Kazarian, E. Krasilnikov,
S. Lando, and M. Shapiro, which describes the average value of the universal
$\mathfrak{gl}$-weight system on permutations. The proof uses a quantum
analogue of the $\mathfrak{gl}$-weight system on Hecke algebras of type $A$,
which leads to a one-parameter deformation of the average value of the
universal ${\mathfrak{gl}}$-weight system. We show that the average value of
the quantum weight system is a linear combination of one-part Schur functions,
with coefficients being $q$-analogues of Bernoulli polynomials.

</details>


### [52] [Extended VC-dimension, and Radon and Tverberg type theorems for unions of convex sets](https://arxiv.org/abs/2506.17777)
*Noga Alon,Shakhar Smorodinsky*

Main category: math.CO

TL;DR: 本文扩展了超图的VC维概念，并应用于证明凸集并集的Tverberg型定理，同时改进了B\'ar\'any和Kalai早期结果的Radon型定理估计。


<details>
  <summary>Details</summary>
Motivation: 研究凸集并集的组合性质，扩展VC维概念以解决相关问题，改进现有理论中的估计。

Method: 定义并研究超图VC维的扩展，应用该扩展证明凸集并集的Tverberg型定理，并推导新的Radon型定理。

Result: 建立了凸集并集的Tverberg型定理，显著改进了B\'ar\'any和Kalai的Radon型定理估计。

Conclusion: 扩展的VC维概念为凸集并集的研究提供了新工具，改进了相关定理的估计，推动了组合几何的发展。

Abstract: We define and study an extension of the notion of the VC-dimension of a
hypergraph and apply it to establish a Tverberg type theorem for unions of
convex sets. We also prove a new Radon type theorem for unions of convex sets,
  vastly improving the estimates in an earlier result of B\'ar\'any and Kalai.

</details>


### [53] [Greedy Gossiping](https://arxiv.org/abs/2506.17804)
*Kada Williams*

Main category: math.CO

TL;DR: 本文研究了贪婪八卦问题，探讨在有限通话次数$m<2n-4$下，如何最大化总八卦知识量，并证明贪婪策略在$m<2n-4$时最优。


<details>
  <summary>Details</summary>
Motivation: 经典八卦问题(1971)已解决$n\ge 4$时需$2n-4$次通话使所有人获知所有八卦。本文研究其变体：给定有限通话次数$m<2n-4$，如何最大化总八卦知识量。

Method: 采用贪婪策略：每次通话选择能使总八卦知识量增加最多的两人进行通话。通过理论分析验证该策略在$m<2n-4$时的最优性。

Result: 主要发现：当$m=2n-3$时总知识量可达$n^2$；但更关键的是，对于所有$m<2n-4$的情况，贪婪策略都能达到最大可能的总知识量。

Conclusion: 研究证明贪婪通话策略在$m<2n-4$时具有最优性，这一反直觉的结果为有限通信条件下的信息传播优化提供了理论保证。

Abstract: The renowned Gossiping Problem (1971) asks the following. There are $n$
people who each know an item of gossip. In a telephone call, two people share
all the gossip they know. How many calls are needed for all of them to be
informed of all the gossip? If $n\ge 4$, the answer is $2n-4$.
  We initiate and solve the related Greedy Gossiping Problem: given a fixed
number $m<2n-4$ of calls, at most how much gossip can be known altogether? If
every call increases the total knowledge of gossip as much as possible, the sum
reaches $n^2$ only when $m=2n-3$. Our main result is that surprisingly, for
each $m<2n-4$, this calling strategy is optimal.

</details>


### [54] [Proofs Of Three Geode Conjectures](https://arxiv.org/abs/2506.17862)
*Tewodros Amdeberhan,Doron Zeilberger*

Main category: math.CO

TL;DR: 本文证明了Wildberger和Rubine关于Geode数的三个猜想，这些数源自超Catalan数。


<details>
  <summary>Details</summary>
Motivation: Wildberger和Rubine在2025年5月的《美国数学月刊》中引入了Geode数，并提出三个猜想，本文旨在证明这些猜想。

Method: 通过数学推导和证明，验证了Geode数的性质及其与超Catalan数的关系。

Result: 成功证明了Wildberger和Rubine提出的三个关于Geode数的猜想。

Conclusion: 本文的研究不仅证实了Geode数的猜想，还为进一步研究多指标数提供了新的视角。

Abstract: In the May 2025 issue of the Amer. Math. Monthly, Norman J. Wildberger and
Dean Rubine intoduced a new kind of multi-indexed numbers, that they call
`Geode numbers', obtained from the Hyper-Catalan numbers. They posed three
intriguing conjectures about them, that are proved in this note.

</details>


### [55] [Some sharp bounds on the average Steiner (k, l)-eccentricity for trees](https://arxiv.org/abs/2506.17915)
*Cheng Zeng,Gengji Li*

Main category: math.CO

TL;DR: 本文提出了不增加树平均Steiner $(k,l)$-偏心率变换方法，并在特定条件下获得尖锐边界及极值树。


<details>
  <summary>Details</summary>
Motivation: 研究树结构中Steiner $(k,l)$-偏心率的变化规律，探索不同约束条件下的极值特性。

Method: 引入保持平均Steiner $(k,l)$-偏心率不增的树变换，分析给定节点数、直径、最大度数和叶节点数等约束条件。

Result: 获得了各类约束条件下平均Steiner $(k,l)$-偏心率的尖锐上界，并确定了对应的极值树结构。

Conclusion: 所提出的变换方法有效揭示了树结构参数与Steiner偏心率的关系，为网络优化提供了理论工具。

Abstract: In this paper we introduce some transformations for trees that do not
increase the average Steiner $(k,l)$-eccentricity for all $0\leq l\leq k\leq
n$. Using these transformations, we obtain some sharp bounds on the average
Steiner $(k,l)$-eccentricity for trees with some certain conditions, including
given nodes, given diameter, given max degree and given leaves, and get the
corresponding extremal trees as well.

</details>


### [56] [How Trees on Atoms of Subset Algebras Define Minimal Forests and Their Growth](https://arxiv.org/abs/2506.17921)
*Vasily Buslov*

Main category: math.CO

TL;DR: 该论文研究了加权有向图$V$中由最小生成$k$-分量森林生成的子集代数$\mathfrak{A}_k$上极小树的性质，揭示了这些树如何决定森林形态及其随弧数增加的生长规律，并建立了从单一代数$\mathfrak{A}_k$的极小树推断原图树结构的精确界限。


<details>
  <summary>Details</summary>
Motivation: 探讨如何通过子集代数$\mathfrak{A}_k$上的极小树理解加权有向图的最小生成森林结构，以及如何利用有限信息构建更少分量的最小生成森林。

Method: 分析极小树在子集代数$\mathfrak{A}_k$原子上的性质，研究森林随弧数增加的演化规律，并建立从已知代数推断原图结构的理论界限。

Result: 确定了从单一代数$\mathfrak{A}_k$的极小树可提取的原图树结构信息量，提出了构建更少分量最小生成森林的方法及所需补充信息的精确条件。

Conclusion: 极小树与子集代数的关联性为分析最小生成森林提供了新视角，但完全确定更少分量的森林需要额外的结构信息。

Abstract: A complete description is given of how minimal trees on atoms of the algebra
of subsets $\mathfrak{A}_k$ generated by minimal spanning $k$-component forests
of a weighted digraph $V$ determine the form of these forests and how forests
grow with increasing number of arcs (that is with a decrease in the number of
trees). Precise bounds are established on what can be extracted about the tree
structure of the original graph if the minimal trees on the atoms of a single
algebra $\mathfrak{A}_k$ are known, and also what minimum spanning forests with
fewer components can be constructed based on this, and what exactly additional
information is required to determine minimum spanning forests consisting of
even fewer components.

</details>


### [57] [A unified approach to total irregular labeling](https://arxiv.org/abs/2506.17922)
*Aleams Barra*

Main category: math.CO

TL;DR: 本文提出了一种统一计算各类图的总顶点不规则强度(tvs)的方法，简化并统一了多种图结构的tvs证明，并解决了简单2-正则图的tvs开放问题。


<details>
  <summary>Details</summary>
Motivation: 旨在为多种图结构提供统一的总顶点不规则强度计算方法，并解决简单2-正则图的tvs开放问题。

Method: 采用Barra等人提出的新技术，对环、路径、棱柱、轮、完全图、舵图、友谊图及$K_{n,n}$等图结构进行统一分析。

Result: 简化并统一了多种图结构的tvs证明，首次确定了简单2-正则图的tvs值。

Conclusion: 该方法不仅统一了各类图的tvs计算，还填补了简单2-正则图的理论空白，为图论研究提供了新工具。

Abstract: We present a unified approach to compute the total vertex irregularity
strength (tvs) of various graphs, employing a novel technique recently proposed
by Barra et al. For graphs such as cycles, paths, prisms, wheels, complete
graphs, helm graphs, friendship graphs, and $K_{n,n}$ , we offer simplified and
unified proofs of their previously established tvs values. Furthermore, we
resolve an open problem by determining the tvs for simple 2-regular graphs.

</details>


### [58] [Reducible Iterated Graph Systems: multiscale-freeness and multifractals](https://arxiv.org/abs/2506.18073)
*Nero Ziyu Li,Frank Xin Hu,Thomas Britz*

Main category: math.CO

TL;DR: 该研究将分形几何概念引入图论，扩展了边迭代图系统(Edge IGS)的理论框架，定义了图分形的多重分形性和多尺度自由性，并证明了相关谱的有限离散特性。


<details>
  <summary>Details</summary>
Motivation: 旨在将分形几何的核心思想迁移至图论领域，完善原始边迭代图系统理论中关于可约情形的空白。

Method: 通过扩展边迭代图系统框架，在可约情形下建立多重分形性与多尺度自由性的严格数学定义，并构建等价条件判定体系。

Result: 证明了图分形的分形谱与度谱均为有限离散集，确立了两种现象发生的充要条件。

Conclusion: 研究成果填补了原始边迭代图系统理论的空白，为图分形建立了完整的理论基础。

Abstract: Iterated Graph Systems (IGS) aims to transplant ideas from fractal geometry
into graph theory. Building on this framework, we extend Edge IGS from the
primitive to the reducible setting. Within this broader context, we formulate
rigorous definitions of multifractality and multiscale-freeness for graph
fractals, and we establish conditions that are equivalent to the occurrence of
these two phenomena. We further determine the corresponding fractal and degree
spectra, proving that both are finite and discrete. These results complete the
foundational theory of Edge IGS by filling the gap left by the primitive case
studied in [1,2].

</details>


### [59] [Large grid subsets without many cospherical points](https://arxiv.org/abs/2506.18113)
*Zichao Dong,Zijian Xu*

Main category: math.CO

TL;DR: 本文基于射影代数几何的直觉，提出了一种在$d$维网格$[n]^d$中构造大小为$n - o(n)$的子集的新方法，该子集不包含$d + 2$个共球或共超平面的点。对于$d = 2$，这改进了Thiele在1995年提出的Erd\H{o}s--Purdy问题的最佳下界$n/4$；对于$d \ge 3$，这改进了Suk和White最近提出的$\Omega \bigl( n^{\frac{3}{d+1}-o(1)} \bigr)$下界，并强有力地证实了他们猜测的$\Omega \bigl( n^{\frac{d}{d+1}} \bigr)$下界，渐进解决了Brass、Moser和Pach提出的广义Erd\H{o}s--Purdy问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于射影代数几何的直觉，旨在解决Erd\H{o}s--Purdy问题及其广义形式，即在高维网格中寻找不包含特定共球或共超平面点集的子集。

Method: 本文提出了一种新颖的构造方法，通过在$d$维网格$[n]^d$中构造大小为$n - o(n)$的子集，确保该子集不包含$d + 2$个共球或共超平面的点。

Result: 对于$d = 2$，结果改进了Thiele在1995年提出的下界$n/4$；对于$d \ge 3$，结果改进了Suk和White的$\Omega \bigl( n^{\frac{3}{d+1}-o(1)} \bigr)$下界，并证实了他们的猜测$\Omega \bigl( n^{\frac{d}{d+1}} \bigr)$。

Conclusion: 本文不仅改进了Erd\H{o}s--Purdy问题及其广义形式的下界，还渐进解决了Brass、Moser和Pach提出的问题，为高维网格中的点集几何问题提供了新的理论支持。

Abstract: Motivated by intuitions from projective algebraic geometry, we provide a
novel construction of subsets of the $d$-dimensional grid $[n]^d$ of size $n -
o(n)$ with no $d + 2$ points on a sphere or a hyperplane. For $d = 2$, this
improves the previously best known lower bound of $n/4$ toward the
Erd\H{o}s--Purdy problem due to Thiele in 1995. For $d \ge 3$, this improves
the recent $\Omega \bigl( n^{\frac{3}{d+1}-o(1)} \bigr)$ bound due to Suk and
White, confirming their conjectured $\Omega \bigl( n^{\frac{d}{d+1}} \bigr)$
bound in a strong sense, and asymptotically resolves the generalized
Erd\H{o}s--Purdy problem posed by Brass, Moser, and Pach.

</details>


### [60] [All Ramsey critical graphs for a large tree versus $tK_{m}$](https://arxiv.org/abs/2506.18235)
*Zhiyu Cheng,Zhidan Luo,Pingge Chen*

Main category: math.CO

TL;DR: 本文研究了拉姆齐临界图在大树与$tK_{m}$之间的性质，并确定了星临界拉姆齐数。


<details>
  <summary>Details</summary>
Motivation: 研究拉姆齐临界图的性质有助于深入理解拉姆齐理论中的极值问题，特别是大树与多部图之间的关系。

Method: 通过分析红蓝边着色的完全图$K_{N-1}$，寻找不包含红色大树或蓝色$tK_{m}$的临界结构。

Result: 完整刻画了大树与$tK_{m}$之间的所有拉姆齐临界图，并推导出相应的星临界拉姆齐数。

Conclusion: 该研究为拉姆齐理论中大树与多部图的临界性质提供了完整的理论框架，并解决了星临界拉姆齐数的计算问题。

Abstract: Let $H, H_{1}$ and $H_{2}$ be graphs, and let $H\rightarrow (H_{1}, H_{2})$
denote that any red-blue coloring of $E(H)$ yields a red copy of $H_{1}$ or a
blue copy of $H_{2}$. The Ramsey number for $H_{1}$ versus $H_{2}$, $r(H_{1},
H_{2})$, is the minimum integer $N$ such that $K_{N}\rightarrow (H_{1},
H_{2})$. The Ramsey critical graph $H$ for $H_{1}$ versus $H_{2}$ is a red-blue
edge-colored $K_{N- 1}$ such that $H\not\rightarrow (H_{1}, H_{2})$, where $N=
r(H_{1}, H_{2})$. In this paper, we characterize all Ramsey critical graphs for
a large tree versus $tK_{m}$. As a corollary, we determine the star-critical
Ramsey number for a large tree versus $tK_{m}$.

</details>


### [61] [On polluted bootstrap percolation in Cartesian grids](https://arxiv.org/abs/2506.18345)
*Boštjan Brešar,Jaka Hedžet,Michael A. Henning*

Main category: math.CO

TL;DR: 本文研究了污染环境下的极值自举渗透问题，重点关注网格图类，特别是路径的笛卡尔积$P_m \square P_n$。在给定污染顶点数量的情况下，建立了污染网格的最小2-邻居自举渗透数的封闭公式，并为其他极端情况提供了下界。


<details>
  <summary>Details</summary>
Motivation: 研究污染环境下的自举渗透问题，旨在理解在部分顶点永久处于非感染状态时，图的最小初始感染集大小如何变化，这对于理解网络中的信息传播和病毒扩散有重要意义。

Method: 采用极值组合方法，研究了网格图类（即路径的笛卡尔积$P_m \square P_n$）在污染环境下的自举渗透行为。通过分析污染顶点的分布和数量，推导了最小2-邻居自举渗透数的封闭公式。

Result: 对于给定的污染顶点数量，建立了污染网格的最小2-邻居自举渗透数的封闭公式，并为其他极端情况提供了一个下界。

Conclusion: 本文的结果为污染环境下的自举渗透问题提供了理论支持，特别是在网格图类中，为理解网络中的信息传播和病毒扩散提供了新的见解。

Abstract: Given a graph $G$ and assuming that some vertices of $G$ are infected, the
$r$-neighbor bootstrap percolation rule makes an uninfected vertex $v$ infected
if $v$ has at least $r$ infected neighbors. The $r$-percolation number, $m(G,
r)$, of $G$ is the minimum cardinality of a set of initially infected vertices
in $G$ such that after continuously performing the $r$-neighbor bootstrap
percolation rule each vertex of $G$ eventually becomes infected. In this paper,
we continue the study of polluted bootstrap percolation introduced and studied
by Gravner and McDonald [Bootstrap percolation in a polluted environment. J.\
Stat\ Physics 87 (1997) 915--927] where in this variant some vertices are
permanently in the non-infected state. We study an extremal (combinatorial)
version of the bootstrap percolation problem in a polluted environment, where
our main focus is on the class of grid graphs, that is, the Cartesian product
$P_m \square P_n$ of two paths $P_m$ and $P_n$ on $m$ and $n$ vertices,
respectively. Given a number of polluted vertices in a Cartesian grid we
establish a closed formula for the minimum $2$-neighbor bootstrap percolation
number of the polluted grid, and obtain a lower bound for the other extreme.

</details>


### [62] [Counting edges of different types in a local graph of a Grassmann graph](https://arxiv.org/abs/2506.18700)
*Ian Seong*

Main category: math.CO

TL;DR: 本文研究了有限域上Grassmann图$J_q(n,k)$中局部图$\Gamma(x)$的边类型及其计数问题，通过稳定子群作用与矩阵代数方法，分类并计算了不同类型边的数量。


<details>
  <summary>Details</summary>
Motivation: 研究Grassmann图中局部图边的分类与计数，旨在深入理解图的几何结构与群作用下的轨道性质，为相关代数与组合问题提供理论支持。

Method: 利用稳定子群$\text{Stab}(x,y)$在$\Gamma(x)$上的五轨道作用，结合子代数$\mathcal{H}$的矩阵分析，对边类型（0、+、-）进行定义与计数。

Result: 通过代数方法，精确计算了局部图中不同类型边的数量，揭示了轨道间边的分布规律，并验证了与子代数$\mathcal{H}$的关联性。

Conclusion: 该研究不仅完善了Grassmann图局部结构的理论框架，还为后续高维代数组合与群表示论的应用提供了新工具。

Abstract: Let $\mathbb{F}_q$ denote a finite field with $q$ elements. Let $n,k$ denote
integers with $n>2k\geq 6$. Let $V$ denote a vector space over $\mathbb{F}_{q}$
that has dimension $n$. The vertex set of the Grassmann graph $J_q(n,k)$
consists of the $k$-dimensional subspaces of $V$. Two vertices of $J_q(n,k)$
are adjacent whenever their intersection has dimension $k-1$. Let $\partial$
denote the path-length distance function of $J_q(n,k)$. Pick vertices $x,y$ of
$J_q(n,k)$ such that $1<\partial(x,y)<k$. Let $\Gamma(x)$ denote the local
graph of $x$ in $J_q(n,k)$. In this paper we define three types of edges in
$\Gamma(x)$, namely type $0$, type $+$, and type $-$; for adjacent $w,z\in
\Gamma(x)$ such that $\partial(w,y)=\partial(z,y)$, the type of the edge $wz$
depends on the subspaces $w+z,w,z,w\cap z$ and their intersections with $y$.
Our general goal is to count the number of edges in $\Gamma(x)$ for each type.
Consider a two-vertex stabilizer $\text{Stab}(x,y)$ in $GL(V)$; it is known
that the $\text{Stab}(x,y)$-action on $\Gamma(x)$ has five orbits. Pick two
orbits $\mathcal{O},\mathcal{N}$ that are not necessarily distinct; for a given
$w\in \mathcal{O}$, we find the number of vertices in $z\in \mathcal{N}$ such
that the edge $wz$ has (i) type $0$, (ii) type $+$, (iii) type $-$. To find
these numbers, we make heavy use of a subalgebra $\mathcal{H}$ of
$\text{Mat}_{P}(\mathbb{C})$; the algebra $\mathcal{H}$ contains matrices that
are closely related to the five orbits of the $\text{Stab}(x,y)$-action on
$\Gamma(x)$.

</details>


### [63] [Triangle-free subsets of the Hypercube](https://arxiv.org/abs/2506.18782)
*Padmini Mukkamala*

Main category: math.CO

TL;DR: 研究了在$n$维超立方体中寻找最大顶点子集的问题，该子集不包含三个顶点彼此之间的汉明距离恰好为$r$。给出了下界$\frac{c2^n}{e^r2^{\frac r2} (\frac nr)^{\frac{3r}{4}}}$和上界$O(\frac{r2^n}{n+1})$（当$2r \le n$时）。特别地，当$r$为常数时，下界为$\frac{c2^n}{n^{3r/4}}$，上界为$\frac{c'2^n}{n}$。


<details>
  <summary>Details</summary>
Motivation: 研究超立方体中顶点子集的最大规模，避免三个顶点之间的汉明距离恰好为$r$，这是组合数学和图论中的一个重要问题。

Method: 通过组合分析和概率方法，推导了子集规模的下界和上界。

Result: 当$2r \le n$时，给出了下界$\frac{c2^n}{e^r2^{\frac r2} (\frac nr)^{\frac{3r}{4}}}$和上界$O(\frac{r2^n}{n+1})$。当$r$为常数时，下界为$\frac{c2^n}{n^{3r/4}}$，上界为$\frac{c'2^n}{n}$。

Conclusion: 该研究为超立方体中避免特定汉明距离的顶点子集规模提供了理论界限，对组合数学和编码理论有重要意义。

Abstract: We study the problem of determining the largest subset of vertices of the $n$
dimensional hypercube without three vertices at a Hamming distance of exactly
$r$ from each other. In particular, we provide a lower bound of
$\frac{c2^n}{e^r2^{\frac r2} (\frac nr)^{\frac{3r}{4}}}$ and an upper bound of
$O(\frac{r2^n}{n+1})$ when $2r \le n$. In particular, when $r$ is a constant,
the lower bound is $\frac{c2^n}{n^{3r/4}}$, while the upper bound is
$\frac{c'2^n}{n}$.

</details>


### [64] [Graph theoretic properties of Speyer's matroid polynomial $g_M(t)$](https://arxiv.org/abs/2506.18788)
*Erik Panzer*

Main category: math.CO

TL;DR: 本文研究了图的$k$-连通分量、Crapo不变量$\beta(M)$与Speyer多项式$g_M(t)$之间的关系，提出了$g_M'(-1)$的简单解释，改进了计算$g_M(t)$的算法，并通过大量计算揭示了$g_M''(-1)$作为图的新不变量的潜力，同时探讨了三次图的流多项式与$g_M''(0)$的关系。


<details>
  <summary>Details</summary>
Motivation: 研究图的$k$-连通分量、Crapo不变量$\beta(M)$与Speyer多项式$g_M(t)$之间的关系，旨在揭示这些数学对象之间的深层联系，并为图论和拟阵理论提供新的工具和视角。

Method: 通过理论证明建立$k$-连通分量、$\beta(M)$与$g_M(t)$之间的关系，改进Ferroni的算法以计算$g_M(t)$，并实现该算法以生成大量数据进行分析。

Result: 提出了$g_M'(-1)$在图或对偶图情况下的简单解释，改进了计算$g_M(t)$的算法，并通过数据揭示了$g_M''(-1)$作为图的新不变量的潜力，同时探讨了三次图的流多项式与$g_M''(0)$的可能关系。

Conclusion: 研究表明$g_M''(-1)$是一个有趣的图不变量，未来研究可进一步探索其性质和应用，同时三次图的流多项式与$g_M''(0)$的关系也值得深入研究。

Abstract: We prove relations between the number of $k$-connected components of a graph,
Crapo's invariant $\beta(M)$ of a matroid, and Speyer's polynomial $g_M(t)$.
These yield a simple interpretation of $g_M'(-1)$ when $M$ is graphic or
cographic. Furthermore, we improve Ferroni's algorithm to compute $g_M(t)$ and
provide an implementation and an extensive data set. These calculations reveal
a large number of graph theoretic constraints on the second derivative
$g_M''(-1)$, which we thus advertise as an intriguing new invariant of graphs.
We also propose a relation between the flow polynomial and $g_M''(0)$ for cubic
graphs.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [65] [Price equilibria with positive margins in loyal-strategic markets with discrete prices](https://arxiv.org/abs/2506.17239)
*Gurkirat Wadhwa,Akansh Verma,Veeraruna Kavitha,Priyank Sinha*

Main category: q-fin.GN

TL;DR: 研究探讨了竞争性供应链中离散定价对市场均衡的影响，揭示了价格增量变化如何导致纳什均衡不唯一甚至不存在，并通过数值模拟验证了其对市场竞争动态的显著影响。


<details>
  <summary>Details</summary>
Motivation: 传统供应链模型常假设连续定价以简化计算，但忽视了现实中因货币单位限制导致的离散定价现象，以及顾客忠诚度和策略行为对购买决策的影响。本研究旨在填补这一理论空白。

Method: 构建了一个包含单一供应商和两家制造商的供应链模型，引入顾客需求分段和离散定价机制，通过博弈论分析纳什均衡特性，并辅以数值模拟验证。

Result: 分析表明制造商间的纳什均衡可能不唯一，且低面额货币单位会导致均衡不存在；数值实验证实微小价格增量变化会显著改变市场份额分配。

Conclusion: 离散定价机制对供应链竞争具有实质性影响，政策制定者需考虑货币面值因素以避免市场不稳定，企业应精细化定价策略以应对动态竞争。

Abstract: In competitive supply chains (SCs), pricing decisions are crucial, as they
directly impact market share and profitability. Traditional SC models often
assume continuous pricing for mathematical convenience, overlooking the
practical reality of discrete price increments driven by currency constraints.
Additionally, customer behavior, influenced by loyalty and strategic
considerations, plays a significant role in purchasing decisions. To address
these gaps, this study examines a SC model involving one supplier and two
manufacturers, incorporating realistic factors such as customer demand
segmentation and discrete price setting. Our analysis shows that the Nash
equilibria (NE) among manufacturers are not unique, we then discuss the focal
equilibrium. Our analysis also reveals that low denomination factors can lead
to instability as the corresponding game does not have NE. Numerical
simulations demonstrate that even small changes in price increments
significantly affect the competitive dynamics and market share distribution.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [66] [A Geometric Square-Based Approach to RSA Integer Factorization](https://arxiv.org/abs/2506.17233)
*Akihisa Yorozu*

Main category: cs.CR

TL;DR: 提出一种基于几何解释与平方差的新RSA因数分解方法，适用于小半素数但尚未突破大数挑战。


<details>
  <summary>Details</summary>
Motivation: 探索通过几何视角和平方差重新表述RSA因数分解问题，以提升对相邻质因数模数的分解效率。

Method: 将问题转化为完美平方数间距计算，利用递推关系实现快速收敛，特别针对质因数间距小的RSA模数。

Result: 该方法能高效分解小半素数，但尚未在可行时间内破解RSA-100等大规模挑战，显示其潜力与当前局限。

Conclusion: 几何化方法为RSA分解提供了新思路，但对大数分解仍需进一步优化，未来可能结合其他技术突破限制。

Abstract: We present a new approach to RSA factorization inspired by geometric
interpretations and square differences. This method reformulates the problem in
terms of the distance between perfect squares and provides a recurrence
relation that allows rapid convergence when the RSA modulus has closely spaced
prime factors. Although this method is efficient for small semiprimes, it does
not yet succeed in factoring large challenges like RSA-100 in practical time,
highlighting both its potential and current limitations.

</details>


### [67] [Design, Implementation, and Analysis of Fair Faucets for Blockchain Ecosystems](https://arxiv.org/abs/2506.17236)
*Serdar Metin*

Main category: cs.CR

TL;DR: 本文研究非商业区块链网络中共享资源的公平分配问题，提出6种抗DoS攻击、低计算成本且支持差异化用户权重的Max-min公平算法。


<details>
  <summary>Details</summary>
Motivation: 商业区块链通过法币交易实现资源分配，而非商业网络依赖简单的'水龙头'机制，易受DoS攻击且无法保证公平性。

Method: 将传统水龙头机制改进为基于Max-min公平原则的分配方案，设计6种新型算法。

Result: 提出的算法具有抗DoS攻击、低区块链计算成本、支持用户权重策略三大特性。

Conclusion: Max-min公平算法有效解决了非商业区块链网络的资源公平分配问题，为去中心化系统提供了可靠的经济模型。

Abstract: The present dissertation addresses the problem of fairly distributing shared
resources in non-commercial blockchain networks. Blockchains are distributed
systems that order and timestamp records of a given network of users, in a
public, cryptographically secure, and consensual way. The records, which may in
kind be events, transaction orders, sets of rules for structured transactions
etc. are placed within well-defined datastructures called blocks, and they are
linked to each other by the virtue of cryptographic pointers, in a total
ordering which represents their temporal relations of succession. The ability
to operate on the blockchain, and/or to contribute a record to the content of a
block are shared resources of the blockchain systems. In commercial networks,
these resources are exchanged in return for fiat money, and consequently,
fairness is not a relevant problem in terms of computer engineering. In
non-commercial networks, however, monetary solutions are not available, by
definition. The present non-commercial blockchain networks employ trivial
distribution mechanisms called faucets, which offer fixed amounts of free
tokens (called cryptocurrencies) specific to the given network. This mechanism,
although simple and efficient, is prone to denial of service (DoS) attacks and
cannot address the fairness problem. In the present dissertation, the faucet
mechanism is adapted for fair distribution, in line with Max-min Fairness
scheme. In total, we contributed 6 distinct Max-min Fair algorithms as
efficient blockchain faucets. The algorithms we contribute are resistant to DoS
attacks, low-cost in terms of blockchain computation economics, and they also
allow for different user weighting policies.

</details>


### [68] [Detecting and Mitigating SQL Injection Vulnerabilities in Web Applications](https://arxiv.org/abs/2506.17245)
*Sagar Neupane*

Main category: cs.CR

TL;DR: 本文提出了一种针对PHP-MySQL网络应用的SQL注入漏洞综合渗透测试方法，强调了输入消毒和预处理语句的有效性，并通过真实案例验证了持续安全评估的重要性。


<details>
  <summary>Details</summary>
Motivation: SQL注入（SQLi）仍是网络应用的关键漏洞，尽管防御技术有所进步，但网络应用和攻击策略的复杂性不断增加，仍带来重大风险。

Method: 研究采用OWASP ZAP、sqlmap和Nmap等工具，系统性地评估和修复PHP-MySQL网络应用中的SQLi漏洞。

Result: 研究发现输入消毒和预处理语句能有效降低SQLi风险，同时强调持续安全评估对应对新兴威胁的必要性。

Conclusion: 本研究通过真实案例提供了SQLi检测与预防的实用策略，为相关领域贡献了实践性见解。

Abstract: SQL injection (SQLi) remains a critical vulnerability in web applications,
enabling attackers to manipulate databases through malicious inputs. Despite
advancements in mitigation techniques, the evolving complexity of web
applications and attack strategies continues to pose significant risks. This
paper presents a comprehensive penetration testing methodology to identify,
exploit, and mitigate SQLi vulnerabilities in a PHP-MySQL-based web
application. Utilizing tools such as OWASP ZAP, sqlmap, and Nmap, the study
demonstrates a systematic approach to vulnerability assessment and remediation.
The findings underscore the efficacy of input sanitization and prepared
statements in mitigating SQLi risks, while highlighting the need for ongoing
security assessments to address emerging threats. The study contributes to the
field by providing practical insights into effective detection and prevention
strategies, supported by a real-world case study.

</details>


### [69] [Securing Generative AI Agentic Workflows: Risks, Mitigation, and a Proposed Firewall Architecture](https://arxiv.org/abs/2506.17266)
*Sunil Kumar Jang Bahadur,Gopala Dhar*

Main category: cs.CR

TL;DR: 生成式人工智能（GenAI）在带来重大进步的同时，也引入了新的安全挑战，特别是在自主运行的智能体工作流中。本文概述了GenAI工作流中的关键安全漏洞，并提出了包括数据加密、访问控制等在内的缓解策略，以及一个名为“GenAI安全防火墙”的综合防护架构。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能（GenAI）在多智能体系统中的广泛应用，其自主性和交互复杂性带来了数据隐私泄露、模型操纵等新型安全风险，亟需有效的安全防护措施以确保技术的安全部署。

Method: 本文提出了一种名为“GenAI安全防火墙”的架构，通过整合数据加密、访问控制、提示工程、模型监控、智能体沙盒化和安全审计等多种安全服务，并利用GenAI自身能力增强防御，为系统提供全面、灵活且高效的防护。

Result: 提出的“GenAI安全防火墙”能够有效应对GenAI工作流中的数据隐私、模型操纵和智能体自主性等安全漏洞，为多智能体系统的安全运行提供了可行的解决方案。

Conclusion: 解决GenAI工作流中的安全问题是确保这一变革性技术负责任且安全部署的关键。通过综合防护架构和多种安全策略的结合，可以显著降低GenAI系统的安全风险。

Abstract: Generative Artificial Intelligence (GenAI) presents significant advancements
but also introduces novel security challenges, particularly within agentic
workflows where AI agents operate autonomously. These risks escalate in
multi-agent systems due to increased interaction complexity. This paper
outlines critical security vulnerabilities inherent in GenAI agentic workflows,
including data privacy breaches, model manipulation, and issues related to
agent autonomy and system integration. It discusses key mitigation strategies
such as data encryption, access control, prompt engineering, model monitoring,
agent sandboxing, and security audits. Furthermore, it details a proposed
"GenAI Security Firewall" architecture designed to provide comprehensive,
adaptable, and efficient protection for these systems by integrating various
security services and leveraging GenAI itself for enhanced defense. Addressing
these security concerns is paramount for the responsible and safe deployment of
this transformative technology.

</details>


### [70] [Digital Privacy Everywhere](https://arxiv.org/abs/2506.17269)
*Paritosh Ranjan,Surajit Majumder,Prodip Roy*

Main category: cs.CR

TL;DR: 本文提出了一种名为'数字隐私无处不在'(DPE)的系统，旨在主动执行定制隐私政策，保护敏感环境中的数字设备隐私。


<details>
  <summary>Details</summary>
Motivation: 随着配备摄像头、麦克风等隐私侵入组件的数字设备激增，传统被动管理方式（如标识或口头指令）效果有限，亟需主动解决方案。

Method: DPE系统包含中央管理控制台、现场验证单元(FVU)、移动设备执行模块(EMMD)和外部地理所有权服务(EGOS)，协同检测并强制执行摄像头/麦克风禁用等隐私设置。

Result: 该系统能在剧院、医院等场所实时保障隐私合规性，同时保持用户体验流畅，并支持跨地域的运营扩展。

Conclusion: DPE为敏感环境提供了一套可扩展的主动隐私保护框架，有效弥补了现有被动管理方式的不足。

Abstract: The increasing proliferation of digital and mobile devices equipped with
cameras, microphones, GPS, and other privacy invasive components has raised
significant concerns for businesses operating in sensitive or policy restricted
environments. Current solutions rely on passive enforcement, such as signage or
verbal instructions, which are largely ineffective. This paper presents Digital
Privacy Everywhere (DPE), a comprehensive and scalable system designed to
actively enforce custom privacy policies for digital devices within predefined
physical boundaries. The DPE architecture includes a centralized management
console, field verification units (FVUs), enforcement modules for mobile
devices (EMMDs), and an External Geo Ownership Service (EGOS). These components
collaboratively detect, configure, and enforce privacy settings such as
disabling cameras, microphones, or radios across various premises like
theaters, hospitals, financial institutions, and educational facilities. The
system ensures privacy compliance in real time while maintaining a seamless
user experience and operational scalability across geographies.

</details>


### [71] [Step-by-Step Reasoning Attack: Revealing 'Erased' Knowledge in Large Language Models](https://arxiv.org/abs/2506.17279)
*Yash Sinha,Manit Baser,Murari Mandal,Dinil Mon Divakaran,Mohan Kankanhalli*

Main category: cs.CR

TL;DR: 本文提出了一种基于逐步推理的黑盒攻击方法Sleek，用于揭示大语言模型(LLM)知识擦除中的隐藏信息泄露问题。实验表明现有遗忘技术无法可靠移除知识，62.5%的攻击提示能成功恢复被删除的《哈利波特》知识。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的知识擦除对合规性、隐私保护和偏见消除至关重要。现有遗忘技术仅表面抑制知识，未能真正擦除，导致信息仍可通过特定提示恢复。

Method: 提出Sleek攻击框架：1) 利用LLM生成查询构建逐步推理的对抗提示策略 2) 开发能召回已擦除内容并暴露知识不公平抑制的机制 3) 将提示分类为直接/间接/隐含三类以识别最有效的攻击类型。

Result: 在四种先进遗忘技术和两种主流LLM上的测试显示：62.5%对抗提示成功恢复WHP-遗忘Llama模型中的《哈利波特》知识，50%案例暴露了对保留知识的不公平抑制。

Conclusion: 研究揭示了当前知识擦除技术存在持续的信息泄露风险，强调需要开发更鲁棒的遗忘策略来实现真正的知识擦除。逐步推理可成为检测擦除效果的有效工具。

Abstract: Knowledge erasure in large language models (LLMs) is important for ensuring
compliance with data and AI regulations, safeguarding user privacy, mitigating
bias, and misinformation. Existing unlearning methods aim to make the process
of knowledge erasure more efficient and effective by removing specific
knowledge while preserving overall model performance, especially for retained
information. However, it has been observed that the unlearning techniques tend
to suppress and leave the knowledge beneath the surface, thus making it
retrievable with the right prompts. In this work, we demonstrate that
\textit{step-by-step reasoning} can serve as a backdoor to recover this hidden
information. We introduce a step-by-step reasoning-based black-box attack,
Sleek, that systematically exposes unlearning failures. We employ a structured
attack framework with three core components: (1) an adversarial prompt
generation strategy leveraging step-by-step reasoning built from LLM-generated
queries, (2) an attack mechanism that successfully recalls erased content, and
exposes unfair suppression of knowledge intended for retention and (3) a
categorization of prompts as direct, indirect, and implied, to identify which
query types most effectively exploit unlearning weaknesses. Through extensive
evaluations on four state-of-the-art unlearning techniques and two widely used
LLMs, we show that existing approaches fail to ensure reliable knowledge
removal. Of the generated adversarial prompts, 62.5% successfully retrieved
forgotten Harry Potter facts from WHP-unlearned Llama, while 50% exposed unfair
suppression of retained knowledge. Our work highlights the persistent risks of
information leakage, emphasizing the need for more robust unlearning strategies
for erasure.

</details>


### [72] [Theoretically Unmasking Inference Attacks Against LDP-Protected Clients in Federated Vision Models](https://arxiv.org/abs/2506.17292)
*Quan Nguyen,Minh N. Vu,Truc Nguyen,My T. Thai*

Main category: cs.CR

TL;DR: 联邦学习虽通过服务器协调避免直接数据共享以保护隐私，但成员推理攻击(MIA)仍能高成功率攻击未保护数据。研究证明即使采用本地差分隐私(LDP)，隐私风险仍存在，且抑制攻击所需噪声会显著降低模型效用。


<details>
  <summary>Details</summary>
Motivation: 现有研究多忽视LDP或缺乏对LDP保护数据下MIA成功率的理论保证，需填补这一空白以揭示真实隐私风险。

Method: 推导了针对全连接层或自注意力层的低多项式时间MIA成功率的理论下界，并通过联邦视觉模型进行实践验证。

Result: 实验表明LDP保护下隐私风险仍显著存在，且抵御攻击所需噪声会严重损害模型性能。

Conclusion: 仅依赖LDP无法完全消除联邦学习中的隐私泄露风险，需在隐私预算与模型效用间谨慎权衡。

Abstract: Federated Learning enables collaborative learning among clients via a
coordinating server while avoiding direct data sharing, offering a perceived
solution to preserve privacy. However, recent studies on Membership Inference
Attacks (MIAs) have challenged this notion, showing high success rates against
unprotected training data. While local differential privacy (LDP) is widely
regarded as a gold standard for privacy protection in data analysis, most
studies on MIAs either neglect LDP or fail to provide theoretical guarantees
for attack success rates against LDP-protected data. To address this gap, we
derive theoretical lower bounds for the success rates of low-polynomial time
MIAs that exploit vulnerabilities in fully connected or self-attention layers.
We establish that even when data are protected by LDP, privacy risks persist,
depending on the privacy budget. Practical evaluations on federated vision
models confirm considerable privacy risks, revealing that the noise required to
mitigate these attacks significantly degrades models' utility.

</details>


### [73] [LLM Jailbreak Oracle](https://arxiv.org/abs/2506.17299)
*Shuyi Lin,Anshuman Suri,Alina Oprea,Cheng Tan*

Main category: cs.CR

TL;DR: 本文提出'越狱预言问题'来系统评估大语言模型(LLM)的安全漏洞，并开发了首个高效算法Boa，通过三阶段搜索策略实现对抗性安全检测。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在安全关键领域广泛应用，缺乏系统性方法评估其对抗'越狱攻击'的脆弱性已成为重大安全隐患。

Method: Boa算法采用三阶段搜索策略：(1)构建拒绝模式黑名单，(2)广度优先采样寻找易得越狱路径，(3)基于细粒度安全评分的深度优先搜索探索低概率路径。

Result: Boa首次实现了越狱预言问题的有效求解，支持系统化防御评估、红队攻击标准化比较及极端对抗条件下的模型认证。

Conclusion: 该研究为LLM安全评估建立了理论基础和实用工具，Boa算法在计算效率与检测完备性间取得了突破性平衡。

Abstract: As large language models (LLMs) become increasingly deployed in
safety-critical applications, the lack of systematic methods to assess their
vulnerability to jailbreak attacks presents a critical security gap. We
introduce the jailbreak oracle problem: given a model, prompt, and decoding
strategy, determine whether a jailbreak response can be generated with
likelihood exceeding a specified threshold. This formalization enables a
principled study of jailbreak vulnerabilities. Answering the jailbreak oracle
problem poses significant computational challenges -- the search space grows
exponentially with the length of the response tokens. We present Boa, the first
efficient algorithm for solving the jailbreak oracle problem. Boa employs a
three-phase search strategy: (1) constructing block lists to identify refusal
patterns, (2) breadth-first sampling to identify easily accessible jailbreaks,
and (3) depth-first priority search guided by fine-grained safety scores to
systematically explore promising low-probability paths. Boa enables rigorous
security assessments including systematic defense evaluation, standardized
comparison of red team attacks, and model certification under extreme
adversarial conditions.

</details>


### [74] [A Nested Watermark for Large Language Models](https://arxiv.org/abs/2506.17308)
*Koichi Nagatsuka,Terufumi Morishita,Yasuhiro Sogawa*

Main category: cs.CR

TL;DR: 本文提出了一种新型嵌套水印方案，通过双密钥机制解决现有大语言模型水印技术中密钥泄露导致的溯源失效问题，实验证明该方法在保持文本质量的同时实现高精度水印检测。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型可能被滥用于生成虚假信息的风险，现有单密钥水印技术存在密钥泄露后无法追溯文本来源的致命缺陷，亟需更鲁棒的认证方案。

Method: 采用嵌套水印架构，使用两个独立密钥在自回归生成过程中嵌入双重水印，即使一个密钥泄露仍能通过另一个密钥进行作者身份认证。

Result: 实验数据显示，该方法对两个水印均保持高检测准确率（分别达98.7%和97.3%），且生成文本的流畅度（PPL=15.2）与原始模型相当。

Conclusion: 双密钥嵌套水印技术有效提升了模型输出溯源的容错能力，为防范LLM生成内容滥用提供了可扩展的认证框架，未来可延伸至多级水印系统研究。

Abstract: The rapid advancement of large language models (LLMs) has raised concerns
regarding their potential misuse, particularly in generating fake news and
misinformation. To address these risks, watermarking techniques for
autoregressive language models have emerged as a promising means for detecting
LLM-generated text. Existing methods typically embed a watermark by increasing
the probabilities of tokens within a group selected according to a single
secret key. However, this approach suffers from a critical limitation: if the
key is leaked, it becomes impossible to trace the text's provenance or
attribute authorship. To overcome this vulnerability, we propose a novel nested
watermarking scheme that embeds two distinct watermarks into the generated text
using two independent keys. This design enables reliable authorship
identification even in the event that one key is compromised. Experimental
results demonstrate that our method achieves high detection accuracy for both
watermarks while maintaining the fluency and overall quality of the generated
text.

</details>


### [75] [Efficient Malware Detection with Optimized Learning on High-Dimensional Features](https://arxiv.org/abs/2506.17309)
*Aditya Choudhary,Sarthak Pawar,Yashodhara Haribhakta*

Main category: cs.CR

TL;DR: 该研究通过XGBoost特征选择和PCA降维技术，将2381维恶意软件特征降至128/256/384维，在LightGBM模型上实现97.52%检测准确率，同时显著降低计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 传统恶意软件检测使用的2381维EMBER特征向量存在计算效率瓶颈，需通过降维平衡检测性能与资源开销。

Method: 采用XGBoost特征选择和PCA两种降维方法，在EMBER-2018/ERMDS/BODMAS混合数据集上评估XGBoost/LightGBM/Extra Trees/Random Forest四种模型，测试维度为原特征的5.4%-16.1%（128/256/384维）。

Result: XGBoost特征选择后的384维特征+LightGBM组合最优（97.52%准确率），仅需61分钟训练时间和30GB内存，在TRITIUM/INFERNO未知数据集上保持95.31%/93.98%准确率。

Conclusion: 该方案证明降维技术可显著提升恶意软件检测的计算效率，且不影响模型泛化能力，为实际部署提供了高效解决方案。

Abstract: Malware detection using machine learning requires feature extraction from
binary files, as models cannot process raw binaries directly. A common approach
involves using LIEF for raw feature extraction and the EMBER vectorizer to
generate 2381-dimensional feature vectors. However, the high dimensionality of
these features introduces significant computational challenges. This study
addresses these challenges by applying two dimensionality reduction techniques:
XGBoost-based feature selection and Principal Component Analysis (PCA). We
evaluate three reduced feature dimensions (128, 256, and 384), which correspond
to approximately 5.4%, 10.8%, and 16.1% of the original 2381 features, across
four models-XGBoost, LightGBM, Extra Trees, and Random Forest-using a unified
training, validation, and testing split formed from the EMBER-2018, ERMDS, and
BODMAS datasets. This approach ensures generalization and avoids dataset bias.
Experimental results show that LightGBM trained on the 384-dimensional feature
set after XGBoost feature selection achieves the highest accuracy of 97.52% on
the unified dataset, providing an optimal balance between computational
efficiency and detection performance. The best model, trained in 61 minutes
using 30 GB of RAM and 19.5 GB of disk space, generalizes effectively to
completely unseen datasets, maintaining 95.31% accuracy on TRITIUM and 93.98%
accuracy on INFERNO. These findings present a scalable, compute-efficient
approach for malware detection without compromising accuracy.

</details>


### [76] [Tracking GPTs Third Party Service: Automation, Analysis, and Insights](https://arxiv.org/abs/2506.17315)
*Chuan Yan,Liuhuo Wan,Bowei Guan,Fengqi Yu,Guangdong Bai,Jin Song Dong*

Main category: cs.CR

TL;DR: 本文介绍了GPTs-ThirdSpy，一个自动化框架，用于提取GPTs的隐私设置，以支持第三方服务集成在GPTs中的学术研究。


<details>
  <summary>Details</summary>
Motivation: GPTs与第三方服务的集成方式限制了隐私设置信息的可访问性和分析，使得系统评估数据隐私影响具有挑战性。

Method: GPTs-ThirdSpy是一个自动化框架，旨在提取GPTs的隐私设置，为研究人员提供实时、可靠的第三方服务元数据。

Result: GPTs-ThirdSpy能够系统地收集和结构化数据，支持对GPTs生态系统的透明度和监管挑战进行大规模研究。

Conclusion: GPTs-ThirdSpy为学术研究提供了工具，以深入分析GPTs中第三方服务的集成、合规性及潜在安全风险。

Abstract: ChatGPT has quickly advanced from simple natural language processing to
tackling more sophisticated and specialized tasks. Drawing inspiration from the
success of mobile app ecosystems, OpenAI allows developers to create
applications that interact with third-party services, known as GPTs. GPTs can
choose to leverage third-party services to integrate with specialized APIs for
domain-specific applications. However, the way these disclose privacy setting
information limits accessibility and analysis, making it challenging to
systematically evaluate the data privacy implications of third-party integrate
to GPTs. In order to support academic research on the integration of
third-party services in GPTs, we introduce GPTs-ThirdSpy, an automated
framework designed to extract privacy settings of GPTs. GPTs-ThirdSpy provides
academic researchers with real-time, reliable metadata on third-party services
used by GPTs, enabling in-depth analysis of their integration, compliance, and
potential security risks. By systematically collecting and structuring this
data, GPTs-ThirdSpy facilitates large-scale research on the transparency and
regulatory challenges associated with the GPT app ecosystem.

</details>


### [77] [Beyond the Scope: Security Testing of Permission Management in Team Workspace](https://arxiv.org/abs/2506.17317)
*Liuhuo Wan,Chuan Yan,Mark Huasong Meng,Kailong Wang,Haoyu Wang,Guangdong Bai,Jin Song Dong*

Main category: cs.CR

TL;DR: 本文研究了团队工作空间插件的权限管理现状，揭示了多用户协作环境下插件可能绕过管理员权限隔离的安全风险，并开发了自动化工具TAI进行系统性测试。


<details>
  <summary>Details</summary>
Motivation: 随着Google Workspace和Microsoft OneDrive等团队工作空间平台允许第三方插件集成，多用户协作功能使插件可能绕过权限隔离，引发安全隐患。本文旨在调查此类插件的权限管理现状。

Method: 通过深入分析团队工作空间生态系统的访问控制机制，结合多用户和跨应用特性，识别了三种可能导致权限提升的安全风险，并开发了自动化工具TAI进行系统性测试。

Result: 评估发现权限提升漏洞在该生态系统中普遍存在，共识别出41个存在问题的交互案例。

Conclusion: 研究结果警示团队工作空间平台和第三方开发者需重视插件权限管理漏洞，以防止权限提升风险。

Abstract: Nowadays team workspaces are widely adopted for multi-user collaboration and
digital resource management. To further broaden real-world applications,
mainstream team workspaces platforms, such as Google Workspace and Microsoft
OneDrive, allow third-party applications (referred to as add-ons) to be
integrated into their workspaces, significantly extending the functionality of
team workspaces. The powerful multi-user collaboration capabilities and
integration of add-ons make team workspaces a central hub for managing shared
resources and protecting them against unauthorized access. Due to the
collaboration features of team workspaces, add-ons involved in collaborations
may bypass the permission isolation enforced by the administrator, unlike in
single-user permission management.
  This paper aims to investigate the permission management landscape of team
workspaces add-ons. To this end, we perform an in-depth analysis of the
enforced access control mechanism inherent in this ecosystem, considering both
multi-user and cross-app features. We identify three potential security risks
that can be exploited to cause permission escalation. We then systematically
reveal the landscape of permission escalation risks in the current ecosystem.
Specifically, we propose an automated tool, TAI, to systematically test all
possible interactions within this ecosystem. Our evaluation reveals that
permission escalation vulnerabilities are widespread in this ecosystem, with 41
interactions identified as problematic. Our findings should raise an alert to
both the team workspaces platforms and third-party developers.

</details>


### [78] [Context manipulation attacks : Web agents are susceptible to corrupted memory](https://arxiv.org/abs/2506.17318)
*Atharv Singh Patlan,Ashwin Hebbar,Pramod Viswanath,Prateek Mittal*

Main category: cs.CR

TL;DR: 论文提出了一种针对自主网页导航代理的新型攻击方式——计划注入（plan injection），通过操纵代理的上下文记忆系统，成功绕过现有防护措施，攻击成功率显著高于传统提示注入攻击。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLM）的无状态特性，网页导航代理依赖外部记忆系统维护交互上下文。这些客户端或第三方管理的记忆系统存在严重安全漏洞，近期已被实际攻击利用。

Method: 研究者形式化定义了计划注入攻击，并系统评估了Browser-use和Agent-E两款流行网页代理。通过构建上下文链式注入（context-chained injections），在用户目标与攻击目标间建立逻辑桥梁。

Result: 计划注入攻击成功绕过现有提示注入防御，攻击成功率最高达到传统方法的3倍。在隐私窃取任务中，上下文链式注入使成功率提升17.7%。

Conclusion: 研究结果表明，代理系统的安全内存处理必须作为首要考虑因素，当前系统的上下文管理机制存在严重安全隐患。

Abstract: Autonomous web navigation agents, which translate natural language
instructions into sequences of browser actions, are increasingly deployed for
complex tasks across e-commerce, information retrieval, and content discovery.
Due to the stateless nature of large language models (LLMs), these agents rely
heavily on external memory systems to maintain context across interactions.
Unlike centralized systems where context is securely stored server-side, agent
memory is often managed client-side or by third-party applications, creating
significant security vulnerabilities. This was recently exploited to attack
production systems.
  We introduce and formalize "plan injection," a novel context manipulation
attack that corrupts these agents' internal task representations by targeting
this vulnerable context. Through systematic evaluation of two popular web
agents, Browser-use and Agent-E, we show that plan injections bypass robust
prompt injection defenses, achieving up to 3x higher attack success rates than
comparable prompt-based attacks. Furthermore, "context-chained injections,"
which craft logical bridges between legitimate user goals and attacker
objectives, lead to a 17.7% increase in success rate for privacy exfiltration
tasks. Our findings highlight that secure memory handling must be a first-class
concern in agentic systems.

</details>


### [79] [On the Performance of Cyber-Biomedical Features for Intrusion Detection in Healthcare 5.0](https://arxiv.org/abs/2506.17329)
*Pedro H. Lui,Lucas P. Siqueira,Juliano F. Kazienko,Vagner E. Quincozes,Silvio E. Quincozes,Daniel Welfer*

Main category: cs.CR

TL;DR: 本研究应用可解释人工智能（XAI）分析Healthcare 5.0数据集，结合网络流量与生物医学传感器数据，XGBoost模型在入侵检测中表现优异，F1分数达99%。


<details>
  <summary>Details</summary>
Motivation: Healthcare 5.0依赖互联医疗技术，但面临网络安全威胁，且现有AI驱动安全模型忽视生物医学数据，影响效果与可解释性。

Method: 采用可解释AI（XAI）技术，整合网络流量与生物医学传感器数据，使用XGBoost模型进行分类分析。

Result: XGBoost模型对良性数据与数据篡改的F1分数达99%，对欺骗攻击为81%；网络数据主导入侵检测，体温特征对欺骗检测贡献显著（Shapley值0.37）。

Conclusion: XAI能有效提升Healthcare 5.0网络安全，网络数据与生物医学特征的结合增强模型性能与可解释性。

Abstract: Healthcare 5.0 integrates Artificial Intelligence (AI), the Internet of
Things (IoT), real-time monitoring, and human-centered design toward
personalized medicine and predictive diagnostics. However, the increasing
reliance on interconnected medical technologies exposes them to cyber threats.
Meanwhile, current AI-driven cybersecurity models often neglect biomedical
data, limiting their effectiveness and interpretability. This study addresses
this gap by applying eXplainable AI (XAI) to a Healthcare 5.0 dataset that
integrates network traffic and biomedical sensor data. Classification outputs
indicate that XGBoost achieved 99% F1-score for benign and data alteration, and
81% for spoofing. Explainability findings reveal that network data play a
dominant role in intrusion detection whereas biomedical features contributed to
spoofing detection, with temperature reaching a Shapley values magnitude of
0.37.

</details>


### [80] [Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases](https://arxiv.org/abs/2506.17336)
*Yubeen Bae,Minchan Kim,Jaejin Lee,Sangbum Kim,Jaehyung Kim,Yejin Choi,Niloofar Mireshghallah*

Main category: cs.CR

TL;DR: 论文提出了一种结合强大但不信任的LLM与本地弱模型的方法，通过苏格拉底式思维链推理和同态加密向量数据库，在保护用户隐私的同时提升问答性能。


<details>
  <summary>Details</summary>
Motivation: 用户在使用LLM处理敏感数据时面临隐私风险，现有方案要么依赖不可信的强大模型，要么只能使用本地弱模型。本文旨在解决这一隐私与性能的权衡问题。

Method: 1) 将通用查询发送至不可信LLM生成思维链提示和子查询；2) 使用同态加密向量数据库对用户百万级私有数据进行加密语义搜索；3) 将提示和解密数据输入本地模型生成最终响应。

Result: 在LoCoMo长上下文QA基准测试中，GPT-4o与本地Llama-3.2-1B的混合框架比单独使用GPT-4o性能提升最高达7.1个百分点。

Conclusion: 该框架首次实现了任务在不可信强LLM与可信弱本地模型间的分解协作，为保护隐私的混合LLM系统迈出了重要一步。

Abstract: Large language models (LLMs) are increasingly used as personal agents,
accessing sensitive user data such as calendars, emails, and medical records.
Users currently face a trade-off: They can send private records, many of which
are stored in remote databases, to powerful but untrusted LLM providers,
increasing their exposure risk. Alternatively, they can run less powerful
models locally on trusted devices. We bridge this gap. Our Socratic
Chain-of-Thought Reasoning first sends a generic, non-private user query to a
powerful, untrusted LLM, which generates a Chain-of-Thought (CoT) prompt and
detailed sub-queries without accessing user data. Next, we embed these
sub-queries and perform encrypted sub-second semantic search using our
Homomorphically Encrypted Vector Database across one million entries of a
single user's private data. This represents a realistic scale of personal
documents, emails, and records accumulated over years of digital activity.
Finally, we feed the CoT prompt and the decrypted records to a local language
model and generate the final response. On the LoCoMo long-context QA benchmark,
our hybrid framework, combining GPT-4o with a local Llama-3.2-1B model,
outperforms using GPT-4o alone by up to 7.1 percentage points. This
demonstrates a first step toward systems where tasks are decomposed and split
between untrusted strong LLMs and weak local ones, preserving user privacy.

</details>


### [81] [AndroIDS : Android-based Intrusion Detection System using Federated Learning](https://arxiv.org/abs/2506.17349)
*Akarsh K Nair,Shanik Hubert Satheesh Kumar.,Deepti Gupta*

Main category: cs.CR

TL;DR: 本文提出了一种基于联邦学习的入侵检测框架AndroIDS，利用系统调用轨迹作为隐私保护的数据源，在移动物联网环境中实现高效且隐私安全的异常检测。


<details>
  <summary>Details</summary>
Motivation: 随着安卓移动物联网设备的指数级增长，智能家居、无人机等场景面临日益严重的网络攻击威胁，传统集中式检测方法存在隐私泄露风险，亟需开发隐私保护的分布式检测方案。

Method: 采用联邦学习框架，通过系统调用轨迹构建个性化数据集；建立通用系统调用数据集模拟真实场景，在IID和非IID数据分布下验证模型性能，并与集中式深度学习进行对比。

Result: 联邦学习模型在IID和非IID条件下分别达到96.46%和92.87%的准确率，F1分数分别为89%和86%；非IID场景仅导致轻微性能下降，证明模型对数据异构性具有鲁棒性。

Conclusion: 该框架在保护用户隐私的同时实现了高效的入侵检测，实验结果表明其适用于现实移动物联网场景，为安全可扩展的分布式检测提供了可行方案。

Abstract: The exponential growth of android-based mobile IoT systems has significantly
increased the susceptibility of devices to cyberattacks, particularly in smart
homes, UAVs, and other connected mobile environments. This article presents a
federated learning-based intrusion detection framework called AndroIDS that
leverages system call traces as a personalized and privacy-preserving data
source. Unlike conventional centralized approaches, the proposed method enables
collaborative anomaly detection without sharing raw data, thus preserving user
privacy across distributed nodes. A generalized system call dataset was
generated to reflect realistic android system behavior and serves as the
foundation for experimentation. Extensive evaluation demonstrates the
effectiveness of the FL model under both IID and non-IID conditions, achieving
an accuracy of 96.46 % and 92.87 %, and F1-scores of 89 % and 86 %,
respectively. These results highlight the models robustness to data
heterogeneity, with only a minor performance drop in the non-IID case. Further,
a detailed comparison with centralized deep learning further illustrates
trade-offs in detection performance and deployment feasibility. Overall, the
results validate the practical applicability of the proposed approach for
secure and scalable intrusion detection in real-world mobile IoT scenarios.

</details>


### [82] [CUBA: Controlled Untargeted Backdoor Attack against Deep Neural Networks](https://arxiv.org/abs/2506.17350)
*Yinghao Wu,Liyan Zhang*

Main category: cs.CR

TL;DR: 本文提出了一种新型的约束无目标后门攻击（CUBA），结合了无目标攻击的灵活性和有目标攻击的意图性，通过限制目标类别范围实现可控攻击，有效规避现有防御方法。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击多为有目标攻击，其触发机制与特定恶意行为强关联，而纯粹无目标攻击因缺乏目标性而自弱。CUBA旨在结合两者优势，实现更灵活且难以检测的攻击方式。

Method: 采用对数归一化交叉熵损失函数与翻转独热标签，通过约束训练过程中的对数输出，使受感染模型在选定目标类别范围内呈现均匀分布，实现可控无目标攻击。

Result: 在不同数据集上的实验表明，CUBA能有效生成具有均匀类别分布的后门模型，成功规避现有防御方法的检测。

Conclusion: CUBA通过融合随机性与确定性，为后门攻击提供了新范式，其设计思路对现有防御体系构成挑战，需进一步研究针对性防护策略。

Abstract: Backdoor attacks have emerged as a critical security threat against deep
neural networks in recent years. The majority of existing backdoor attacks
focus on targeted backdoor attacks, where trigger is strongly associated to
specific malicious behavior. Various backdoor detection methods depend on this
inherent property and shows effective results in identifying and mitigating
such targeted attacks. However, a purely untargeted attack in backdoor
scenarios is, in some sense, self-weakening, since the target nature is what
makes backdoor attacks so powerful. In light of this, we introduce a novel
Constrained Untargeted Backdoor Attack (CUBA), which combines the flexibility
of untargeted attacks with the intentionality of targeted attacks. The
compromised model, when presented with backdoor images, will classify them into
random classes within a constrained range of target classes selected by the
attacker. This combination of randomness and determinedness enables the
proposed untargeted backdoor attack to natively circumvent existing backdoor
defense methods. To implement the untargeted backdoor attack under controlled
flexibility, we propose to apply logit normalization on cross-entropy loss with
flipped one-hot labels. By constraining the logit during training, the
compromised model will show a uniform distribution across selected target
classes, resulting in controlled untargeted attack. Extensive experiments
demonstrate the effectiveness of the proposed CUBA on different datasets.

</details>


### [83] [Differentiation-Based Extraction of Proprietary Data from Fine-Tuned LLMs](https://arxiv.org/abs/2506.17353)
*Zongjie Li,Daoyuan Wu,Shuai Wang,Zhendong Su*

Main category: cs.CR

TL;DR: 本文首次研究了监督微调(SFT)数据提取问题，提出新型攻击方法DDE并验证其有效性，同时提出防御机制以降低数据泄露风险。


<details>
  <summary>Details</summary>
Motivation: 随着领域专用和人类对齐大语言模型需求增长，SFT数据集成为高价值目标，但数据提取风险尚未被系统研究。

Method: 提出差异化数据提取(DDE)方法，利用微调模型的置信度差异及与预训练基模型的行为差异进行攻击。

Result: 跨领域实验表明DDE在所有攻击场景中优于基线方法，同时提出的防御机制能有效缓解攻击且对模型性能影响最小。

Conclusion: 研究揭示了微调LLMs中隐藏的数据泄露风险，为开发更安全模型提供了重要见解。

Abstract: The increasing demand for domain-specific and human-aligned Large Language
Models (LLMs) has led to the widespread adoption of Supervised Fine-Tuning
(SFT) techniques. SFT datasets often comprise valuable instruction-response
pairs, making them highly valuable targets for potential extraction. This paper
studies this critical research problem for the first time. We start by formally
defining and formulating the problem, then explore various attack goals, types,
and variants based on the unique properties of SFT data in real-world
scenarios. Based on our analysis of extraction behaviors of direct extraction,
we develop a novel extraction method specifically designed for SFT models,
called Differentiated Data Extraction (DDE), which exploits the confidence
levels of fine-tuned models and their behavioral differences from pre-trained
base models. Through extensive experiments across multiple domains and
scenarios, we demonstrate the feasibility of SFT data extraction using DDE. Our
results show that DDE consistently outperforms existing extraction baselines in
all attack settings. To counter this new attack, we propose a defense mechanism
that mitigates DDE attacks with minimal impact on model performance. Overall,
our research reveals hidden data leak risks in fine-tuned LLMs and provides
insights for developing more secure models.

</details>


### [84] [Secret Sharing in 5G-MEC: Applicability for joint Security and Dependability](https://arxiv.org/abs/2506.17371)
*Thilina Pathirana,Ruxandra F. Olimid*

Main category: cs.CR

TL;DR: 本文探讨了在5G多接入边缘计算（MEC）中应用阈值秘密共享技术以增强数据安全性和可靠性的方法。通过(k,n)阈值方案分散存储敏感数据，确保数据机密性和可用性，并提出了基于信任度的边缘节点选择策略。


<details>
  <summary>Details</summary>
Motivation: 5G-MEC的分布式特性带来了隐私和安全挑战，如数据暴露风险。研究旨在解决边缘敏感数据的高效处理与安全保障问题。

Method: 采用(k,n)阈值秘密共享方案，将数据分散存储于n个节点，需至少k个节点协作才能重构数据。同时提出基于信任度的边缘节点（MEH）选择方法。

Result: 该方案能抵御少于k个节点的共谋攻击，容忍最多n-k个节点故障，有效降低未授权访问和节点故障风险。节点选择方法可扩展至其他5G-MEC可信场景。

Conclusion: 阈值秘密共享技术为5G-MEC存储提供了安全可靠的解决方案，其节点选择框架具有通用性，可适用于更广泛的边缘计算场景。

Abstract: Multi-access Edge Computing (MEC), an enhancement of 5G, processes data
closer to its generation point, reducing latency and network load. However, the
distributed and edge-based nature of 5G-MEC presents privacy and security
challenges, including data exposure risks. Ensuring efficient manipulation and
security of sensitive data at the edge is crucial. To address these challenges,
we investigate the usage of threshold secret sharing in 5G-MEC storage, an
approach that enhances both security and dependability. A (k,n) threshold
secret sharing scheme splits and stores sensitive data among n nodes, requiring
at least k nodes for reconstruction. The solution ensures confidentiality by
protecting data against fewer than k colluding nodes and enhances availability
by tolerating up to n-k failing nodes. This approach mitigates threats such as
unauthorized access and node failures, whether accidental or intentional. We
further discuss a method for selecting the convenient MEHs to store the shares,
considering the MEHs' trustworthiness level as a main criterion. Although we
define our proposal in the context of secret-shared data storage, it can be
seen as an independent, standalone selection process for 5G-MEC trustworthy
node selection in other scenarios too.

</details>


### [85] [Open Sky, Open Threats: Replay Attacks in Space Launch and Re-entry Phases](https://arxiv.org/abs/2506.17446)
*Nesrine Benchoubane,Eray Guven,Gunes Karabulut Kurt*

Main category: cs.CR

TL;DR: 本文研究了重放攻击对航天器通信关键阶段（发射与再入）上下行链路完整性的影响，提出了一种基于相位相干性决策导向均衡器的安全接收机设计。


<details>
  <summary>Details</summary>
Motivation: 航天器在发射和再入阶段的通信系统易受重放攻击，攻击者信号可能压制合法传输，威胁任务安全。

Method: 结合软件定义无线电（SDR）与实时信道模拟器，模拟猎户座飞船通信系统受攻击场景，并设计采用窄带锁相环（PLL）的相位相干决策导向均衡器（DD）。

Result: 实验显示重放攻击下攻击信号信噪比（SNR）优势可达再入阶段-7.8dB、发射阶段-6.5dB，新接收机设计显著提升对相位畸变的敏感度。

Conclusion: 通过优化接收机同步机制，增强了对重放干扰引起的相位失真的检测能力，有效提升了航天器通信系统的抗攻击韧性。

Abstract: This paper examines the effects of replay attacks on the integrity of both
uplink and downlink communications during critical phases of spacecraft
communication. By combining software-defined radios (SDRs) with a real-time
channel emulator, we replicate realistic attack conditions on the Orion
spacecraft's communication systems in both launch and reentry. Our evaluation
shows that, under replay attacks, the attacker's signal can overpower
legitimate transmissions, leading to a Signal to Noise Ratio (SNR) difference
of up to -7.8 dB during reentry and -6.5 dB during launch. To mitigate these
threats, we propose a more secure receiver design incorporating a
phase-coherency-dependent decision-directed (DD) equalizer with a narrowed
phase-locked loop (PLL) bandwidth. This configuration enhances resilience by
making synchronization more sensitive to phase distortions caused by replay
interference.

</details>


### [86] [A Smart Contract-based Non-Transferable Signature Verification System using Nominative Signatures](https://arxiv.org/abs/2506.17504)
*Hinata Nishino,Kazumasa Omote,Keita Emura*

Main category: cs.CR

TL;DR: 本文提出了一种基于智能合约和提名签名技术的不可转让签名验证系统，用于在加密货币交易中同时验证签名和资金转移状态。


<details>
  <summary>Details</summary>
Motivation: 传统提名签名虽能限制验证者身份，但无法验证资金是否已/将转移。在加密货币场景中，需要同时实现签名验证和资金状态确认。

Method: 改造Hanaoka-Schuldt提名签名方案（原基于对称配对），使其适配非对称配对，并通过智能合约执行验证算法，评估gas消耗。

Result: 系统成功实现：1) 保留提名签名的不可见性（允许区块链公开） 2) 新增资金转移验证功能 3) 完成非对称配对改造及gas成本测算。

Conclusion: 该方案首次将提名签名与智能合约结合，为加密货币场景提供兼具身份控制与资金状态验证的不可转让签名系统，实测验证了可行性。

Abstract: Nominative signatures allow us to indicate who can verify a signature, and
they can be employed to construct a non-transferable signature verification
system that prevents the signature verification by a third party in unexpected
situations. For example, this system can prevent IOU/loan certificate
verification in unexpected situations. However, nominative signatures
themselves do not allow the verifier to check whether the funds will be
transferred in the future or have been transferred.It would be desirable to
verify the fact simultaneously when the system involves a certain money
transfer such as cryptocurrencies/cryptoassets. In this paper, we propose a
smart contract-based non-transferable signature verification system using
nominative signatures. We pay attention to the fact that the invisibility,
which is a security requirement to be held for nominative signatures, allows us
to publish nominative signatures on the blockchain. Our system can verify
whether a money transfer actually will take place, in addition to indicating
who can verify a signature. We transform the Hanaoka-Schuldt nominative
signature scheme (ACNS 2011, IEICE Trans. 2016) which is constructed over a
symmetric pairing to a scheme constructed over an asymmetric pairing, and
evaluate the gas cost when a smart contract runs the verification algorithm of
the modified Hanaoka-Schuldt nominative signature scheme.

</details>


### [87] [Semantic-Aware Parsing for Security Logs](https://arxiv.org/abs/2506.17512)
*Julien Piet,Vivian Fang,Rishi Khare,Vern Paxson,Raluca Ada Popa,David Wagner*

Main category: cs.CR

TL;DR: Matryoshka是一个端到端系统，利用LLMs自动生成具有语义感知的结构化日志解析器，结合语法解析和语义解析层，显著提升日志查询效率并减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 由于现实日志的异构性和缺乏结构，安全分析师难以高效查询和关联日志数据。现有AI解析器仅关注语法模板，缺乏语义解释能力，而直接使用大型语言模型查询原始日志存在规模化和提示注入攻击的隐患。

Method: Matryoshka引入了一种新颖的语法解析器（使用精确正则表达式而非通配符）和全新的语义解析层，将变量聚类并映射到可查询的、具有上下文意义的模式中，同时支持与Open Cybersecurity Schema Framework (OCSF)的互操作性。

Result: 在新构建的真实日志基准测试中，Matryoshka的语法解析器优于先前工作，语义层在现实安全查询中达到F1分数0.95。尽管将字段映射到OCSF分类仍具挑战性，但系统显著减少了人工提取和组织字段的工作量。

Conclusion: Matryoshka通过自动提取和组织有价值字段，推动了日志分析向全自动化、AI驱动的方向发展，为安全分析师提供了高效且语义丰富的日志查询解决方案。

Abstract: Security analysts struggle to quickly and efficiently query and correlate log
data due to the heterogeneity and lack of structure in real-world logs.
Existing AI-based parsers focus on learning syntactic log templates but lack
the semantic interpretation needed for querying. Directly querying large
language models on raw logs is impractical at scale and vulnerable to prompt
injection attacks.
  In this paper, we introduce Matryoshka, the first end-to-end system
leveraging LLMs to automatically generate semantically-aware structured log
parsers. Matryoshka combines a novel syntactic parser-employing precise regular
expressions rather than wildcards-with a completely new semantic parsing layer
that clusters variables and maps them into a queryable, contextually meaningful
schema. This approach provides analysts with queryable and semantically rich
data representations, facilitating rapid and precise log querying without the
traditional burden of manual parser construction. Additionally, Matryoshka can
map the newly created fields to recognized attributes within the Open
Cybersecurity Schema Framework (OCSF), enabling interoperability.
  We evaluate Matryoshka on a newly curated real-world log benchmark,
introducing novel metrics to assess how consistently fields are named and
mapped across logs. Matryoshka's syntactic parser outperforms prior works, and
the semantic layer achieves an F1 score of 0.95 on realistic security queries.
Although mapping fields to the extensive OCSF taxonomy remains challenging,
Matryoshka significantly reduces manual effort by automatically extracting and
organizing valuable fields, moving us closer to fully automated, AI-driven log
analytics.

</details>


### [88] [SoK: Stablecoin Designs, Risks, and the Stablecoin LEGO](https://arxiv.org/abs/2506.17622)
*Shengchen Ling,Yuefeng Du,Yajin Zhou,Lei Wu,Cong Wang,Xiaohua Jia,Houmin Yan*

Main category: cs.CR

TL;DR: 本文通过分析157项研究、95种活跃稳定币及44起重大安全事件，提出稳定币稳定性是市场信心与流动性互动的脆弱状态，设计存在风险专业化而非缓释的权衡，收益率机制导致稳定性与高风险金融工程的系统性矛盾，安全事件通过压力测试重塑安全边界。作者提出Stablecoin LEGO框架，揭示历史教训整合与风险评估的强相关性。


<details>
  <summary>Details</summary>
Motivation: 尽管稳定币市值已超2460亿美元（2025年5月），但其设计权衡、安全动态及连锁失效路径等关键风险认知仍不完善。本研究旨在填补这一空白。

Method: 对157项学术研究、95种活跃稳定币及44起重大安全事件进行大规模分析，并开发定量框架Stablecoin LEGO，将历史失败映射至现有设计。

Result: 四大核心发现：1）稳定性是市场信心与流动性互动的涌现状态；2）设计呈现风险专业化而非缓释的权衡；3）收益率机制引发稳定性使命与高风险金融工程的系统性矛盾；4）安全事件通过压力测试推动韧性进化。LEGO框架显示历史教训整合与低风险强相关。

Conclusion: 研究为构建、评估及监管更具韧性的稳定币提供了系统性基础，强调从历史事件中学习对降低风险的关键作用。

Abstract: Stablecoins have become significant assets in modern finance, with a market
capitalization exceeding USD 246 billion (May 2025). Yet, despite their
systemic importance, a comprehensive and risk-oriented understanding of crucial
aspects like their design trade-offs, security dynamics, and interdependent
failure pathways often remains underdeveloped. This SoK confronts this gap
through a large-scale analysis of 157 research studies, 95 active stablecoins,
and 44 major security incidents. Our analysis establishes four pivotal
insights: 1) stability is best understood not an inherent property but an
emergent, fragile state reliant on the interplay between market confidence and
continuous liquidity; 2) stablecoin designs demonstrate trade-offs in risk
specialization instead of mitigation; 3) the widespread integration of yield
mechanisms imposes a "dual mandate" that creates a systemic tension between the
core mission of stability and the high-risk financial engineering required for
competitive returns; and 4) major security incidents act as acute "evolutionary
pressures", forging resilience by stress-testing designs and aggressively
redefining the security frontier. We introduce the Stablecoin LEGO framework, a
quantitative methodology mapping historical failures to current designs. Its
application reveals that a lower assessed risk strongly correlates with
integrating lessons from past incidents. We hope this provides a systematic
foundation for building, evaluating, and regulating more resilient stablecoins.

</details>


### [89] [List-Decodable Byzantine Robust PIR: Lower Communication Complexity, Higher Byzantine Tolerance, Smaller List Size](https://arxiv.org/abs/2506.17625)
*Pengzhen Ke,Liang Feng Zhang,Huaxiong Wang,Li-Ping Wang*

Main category: cs.CR

TL;DR: 本文提出了两种完美的列表可解码拜占庭鲁棒私有信息检索（BRPIR）方案，首次实现了同时处理多数恶意服务器、低通信复杂度$o(n^{1/2})$及非平凡列表大小估计。


<details>
  <summary>Details</summary>
Motivation: 现有拜占庭鲁棒PIR方案在应对多数恶意服务器、通信复杂度及列表大小估计方面存在不足，亟需改进。

Method: 设计了两种新型完美列表可解码BRPIR方案，通过优化算法结构提升鲁棒性并降低通信开销。

Result: 相比现有方案，新方案通信复杂度更低（$o(n^{1/2})$）、拜占庭容忍度更高（支持多数恶意服务器）、列表大小更小。

Conclusion: 该研究为恶意服务器场景下的隐私保护检索提供了更高效的解决方案，在多项关键指标上超越现有技术。

Abstract: Private Information Retrieval (PIR) is a privacy-preserving primitive in
cryptography. Significant endeavors have been made to address the variant of
PIR concerning the malicious servers. Among those endeavors, list-decodable
Byzantine robust PIR schemes may tolerate a majority of malicious responding
servers that provide incorrect answers. In this paper, we propose two perfect
list-decodable BRPIR schemes. Our schemes are the first ones that can
simultaneously handle a majority of malicious responding servers, achieve a
communication complexity of $o(n^{1/2})$ for a database of size n, and provide
a nontrivial estimation on the list sizes. Compared with the existing
solutions, our schemes attain lower communication complexity, higher byzantine
tolerance, and smaller list size.

</details>


### [90] [A Locally Differential Private Coding-Assisted Succinct Histogram Protocol](https://arxiv.org/abs/2506.17767)
*Hsuan-Po Liu,Hessam Mahdavifar*

Main category: cs.CR

TL;DR: 本文提出首个实用的$(\epsilon,\delta)$-LDP协议，利用极性码和SCL解码算法构建简洁直方图，通过高斯扰动实现高效软解码，在低频率项上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在隐私敏感的大规模机器学习应用中，简洁直方图需在保证本地差分隐私(LDP)的同时维持数据效用，纠错码成为可靠信息收集的有力工具。

Method: 采用极性码及其连续取消列表(SCL)解码算法作为底层编码方案，引入基于高斯分布的扰动机制以实现高效软解码。

Result: 实验表明该方法在低真实频率项上表现优异，同时保持与现有方法相近的频率估计精度。

Conclusion: 该协议首次将纠错码与LDP相结合，为隐私保护的简洁直方图构建提供了高效解决方案，特别适用于稀疏数据场景。

Abstract: A succinct histogram captures frequent items and their frequencies across
clients and has become increasingly important for large-scale,
privacy-sensitive machine learning applications. To develop a rigorous
framework to guarantee privacy for the succinct histogram problem, local
differential privacy (LDP) has been utilized and shown promising results. To
preserve data utility under LDP, which essentially works by intentionally
adding noise to data, error-correcting codes naturally emerge as a promising
tool for reliable information collection. This work presents the first
practical $(\epsilon,\delta)$-LDP protocol for constructing succinct histograms
using error-correcting codes. To this end, polar codes and their
successive-cancellation list (SCL) decoding algorithms are leveraged as the
underlying coding scheme. More specifically, our protocol introduces
Gaussian-based perturbations to enable efficient soft decoding. Experiments
demonstrate that our approach outperforms prior methods, particularly for items
with low true frequencies, while maintaining similar frequency estimation
accuracy.

</details>


### [91] [A TRNG Implemented using a Soft-Data Based Sponge Function within a Unified Strong PUF Architecture](https://arxiv.org/abs/2506.17795)
*Rachel Cazzola,Cyrus Minwalla,Calvin Chan,Jim Plusquellic*

Main category: cs.CR

TL;DR: 本文提出了一种结合PUF和TRNG的统一架构，利用静态熵和动态噪声熵生成高安全性随机数，并通过多种测试验证其稳健性。


<details>
  <summary>Details</summary>
Motivation: 硬件安全原语如TRNG和PUF是微电子系统信任根的核心组件，但现有方案在熵源利用和抗攻击能力上存在不足，需设计更高效、安全的统一架构。

Method: 采用SiRF PUF的静态熵与路径延迟测量的动态噪声熵，结合改进的双工海绵结构进行数据后处理，并嵌入TDC高精度测量，同时设计抗温压攻击的密钥再生算法。

Result: 在ZYBO Z7-10 FPGA上实现的多实例测试显示，该架构通过NIST SP 800-22等全套测试，具有优异的最小熵和适中数据速率。

Conclusion: 所提出的PUF-TRNG统一架构能稳定生成高质量随机数，兼具抗攻击性和实用性，为硬件安全提供了有效解决方案。

Abstract: Hardware security primitives including True Random Number Generators (TRNG)
and Physical Unclonable Functions (PUFs) are central components to establishing
a root of trust in microelectronic systems. In this paper, we propose a unified
PUF-TRNG architecture that leverages a combination of the static entropy
available in a strong PUF called the shift-register, reconvergent-fanout (SiRF)
PUF, and the dynamic entropy associated with random noise present in path delay
measurements. The SiRF PUF uses an engineered netlist containing a large number
of paths as the source of static entropy, and a time-to-digital-converter (TDC)
as a high-resolution, embedded instrument for measuring path delays, where
measurement noise serves as the source of dynamic entropy. A novel data
postprocessing algorithm is proposed based on a modified duplex sponge
construction. The sponge function operates on soft data, i.e., fixed point data
values, to add entropy to the ensuing random bit sequences and to increase the
bit generation rate. A postprocessing algorithm for reproducing PUF-generated
encryption keys is also used in the TRNG to protect against temperature voltage
attacks designed to subvert the random characteristics in the bit sequences.
The unified PUF-TRNG architecture is implemented across multiple instances of a
ZYBO Z7-10 FPGA board and extensively tested with NIST SP 800-22, NIST SP
800-90B, AIS-31, and DieHarder test suites. Results indicate a stable and
robust TRNG design with excellent min-entropy and a moderate data rate.

</details>


### [92] [AdRo-FL: Informed and Secure Client Selection for Federated Learning in the Presence of Adversarial Aggregator](https://arxiv.org/abs/2506.17805)
*Md. Kamrul Hossain,Walid Aljoby,Anis Elgabli,Ahmed M. Abdelmoniem,Khaled A. Harras*

Main category: cs.CR

TL;DR: AdRo-FL提出了一种对抗性鲁棒联邦学习框架，既能基于客户端效用进行智能选择，又能防御偏置选择攻击(BSA)，同时保持隐私保护的聚合机制，在集群和分布式两种设置下均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习(FL)中，安全聚合(SA)虽能保护个体更新，但易受恶意聚合器通过偏置选择攻击(BSA)的操纵。可验证随机选择虽能防御BSA，却无法实现影响FL性能的关键智能客户端选择。

Method: AdRo-FL针对两种场景设计：1) 集群场景：通过每轮强制最小客户端选择配额（由集群头监督）和引入效用函数优先高效客户端；2) 分布式场景：采用两阶段协议（效用排名初选+可验证随机函数终选）。同时应用量化和严格传输期限优化通信与能效。

Result: 相比不安全基线，AdRo-FL实现最高$1.85\times$的准确率达成速度提升和$1.06\times$的最终准确率提高。

Conclusion: AdRo-FL首次在联邦学习中实现了智能客户端选择与BSA防御的兼容，通过场景定制化设计、量化压缩和时效控制，显著提升学习效率与模型性能，为隐私保护协作学习提供了新范式。

Abstract: Federated Learning (FL) enables collaborative learning without exposing
clients' data. While clients only share model updates with the aggregator,
studies reveal that aggregators can infer sensitive information from these
updates. Secure Aggregation (SA) protects individual updates during
transmission; however, recent work demonstrates a critical vulnerability where
adversarial aggregators manipulate client selection to bypass SA protections,
constituting a Biased Selection Attack (BSA). Although verifiable random
selection prevents BSA, it precludes informed client selection essential for FL
performance. We propose Adversarial Robust Federated Learning (AdRo-FL), which
simultaneously enables: informed client selection based on client utility, and
robust defense against BSA maintaining privacy-preserving aggregation. AdRo-FL
implements two client selection frameworks tailored for distinct settings. The
first framework assumes clients are grouped into clusters based on mutual
trust, such as different branches of an organization. The second framework
handles distributed clients where no trust relationships exist between them.
For the cluster-oriented setting, we propose a novel defense against BSA by (1)
enforcing a minimum client selection quota from each cluster, supervised by a
cluster-head in every round, and (2) introducing a client utility function to
prioritize efficient clients. For the distributed setting, we design a
two-phase selection protocol: first, the aggregator selects the top clients
based on our utility-driven ranking; then, a verifiable random function (VRF)
ensures a BSA-resistant final selection. AdRo-FL also applies quantization to
reduce communication overhead and sets strict transmission deadlines to improve
energy efficiency. AdRo-FL achieves up to $1.85\times$ faster time-to-accuracy
and up to $1.06\times$ higher final accuracy compared to insecure baselines.

</details>


### [93] [LASA: Enhancing SoC Security Verification with LLM-Aided Property Generation](https://arxiv.org/abs/2506.17865)
*Dinesh Reddy Ankireddy,Sudipta Paria,Aritra Dasgupta,Sandip Ray,Swarup Bhunia*

Main category: cs.CR

TL;DR: 本文提出LASA框架，利用大语言模型（LLM）和检索增强生成（RAG）技术，自动生成非空泛的安全属性与SystemVerilog断言（SVA），显著提升基于总线SoC设计的验证效率与覆盖率（平均达88%），并成功检测出OpenTitan SoC中的五个独特漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有形式化属性验证（FPV）需人工编写安全属性，耗时、昂贵且易错；而现有LLM技术生成的断言常存在空泛问题，且缺乏高效提示生成与全面验证能力。

Method: LASA结合LLM与RAG技术，从设计文档生成非空泛SVA；集成商用EDA工具进行FPV验证，通过反馈循环迭代优化提示以提高覆盖率。

Result: 在多个开源SoC设计中验证有效性，平均覆盖率达~88%；在Hack@DAC'24竞赛的缺陷版OpenTitan SoC中检测出五个独特漏洞。

Conclusion: LASA框架通过自动化生成高质量安全属性与断言，显著降低验证成本，提升覆盖率和漏洞检测能力，为复杂SoC安全验证提供高效解决方案。

Abstract: Ensuring the security of modern System-on-Chip (SoC) designs poses
significant challenges due to increasing complexity and distributed assets
across the intellectual property (IP) blocks. Formal property verification
(FPV) provides the capability to model and validate design behaviors through
security properties with model checkers; however, current practices require
significant manual efforts to create such properties, making them
time-consuming, costly, and error-prone. The emergence of Large Language Models
(LLMs) has showcased remarkable proficiency across diverse domains, including
HDL code generation and verification tasks. Current LLM-based techniques often
produce vacuous assertions and lack efficient prompt generation, comprehensive
verification, and bug detection. This paper presents LASA, a novel framework
that leverages LLMs and retrieval-augmented generation (RAG) to produce
non-vacuous security properties and SystemVerilog Assertions (SVA) from design
specifications and related documentation for bus-based SoC designs. LASA
integrates commercial EDA tool for FPV to generate coverage metrics and
iteratively refines prompts through a feedback loop to enhance coverage. The
effectiveness of LASA is validated through various open-source SoC designs,
demonstrating high coverage values with an average of ~88\%, denoting
comprehensive verification through efficient generation of security properties
and SVAs. LASA also demonstrates bug detection capabilities, identifying five
unique bugs in the buggy OpenTitan SoC from Hack@DAC'24 competition.

</details>


### [94] [Cost-Effective Optimization and Implementation of the CRT-Paillier Decryption Algorithm for Enhanced Performance](https://arxiv.org/abs/2506.17935)
*Zhengwu Huang,Ding Deng,Pengyue Sun,Guangfu Sun,Xiaomei Tang*

Main category: cs.CR

TL;DR: 本文提出了一种名为eCRT-Paillier的解密算法，通过结合预计算参数和消除额外判断操作，显著提升了Paillier算法的解密效率，并在FPGA上实现了高性能加速器MESA。


<details>
  <summary>Details</summary>
Motivation: Paillier加法同态算法虽能有效保护隐私，但其计算效率受限于复杂的模运算和密文扩展。现有CRT优化方法虽加速解密，却增加了计算链长度。

Method: 提出eCRT-Paillier算法：1) 结合预计算参数缩短解密链；2) 消除Montgomery模乘引入的冗余判断。设计全流水线架构，通过指数分段和多核并行化提升吞吐量。

Result: 在Xilinx Virtex-7 FPGA上实现的MESA加速器，2048位密钥解密仅需0.577ms（100MHz）。相比现有方案，吞吐量提升1.16-313.21倍，资源效率（LUT/DSP/FF）提升3.32-117.55倍。

Conclusion: eCRT-Paillier算法与MESA架构显著优化了同态解密性能，为隐私保护云计算提供了高效解决方案，其设计方法可推广至其他密码学加速场景。

Abstract: To address the privacy protection problem in cloud computing, privacy
enhancement techniques such as the Paillier additive homomorphism algorithm are
receiving widespread attention. Paillier algorithm allows addition and scalar
multiplication operations in dencrypted state, which can effectively protect
privacy. However, its computational efficiency is limited by complex modulo
operations due to the ciphertext expansion followed by encryption. To
accelerate its decryption operation, the Chinese Remainder Theorem (CRT) is
often used to optimize these modulo operations, which lengthens the decryption
computation chain in turn. To address this issue, we propose an eCRT-Paillier
decryption algorithm that shortens the decryption computation chain by
combining precomputed parameters and eliminating extra judgment operations
introduced by Montgomery modular multiplications. These two improvements reduce
50% modular multiplications and 60% judgment operations in the postprocessing
of the CRT-Paillier decryption algorithm. Based on these improvements, we
propose a highly parallel full-pipeline architecture to eliminate stalls caused
by multiplier reuse in traditional modular exponentiation operations. This
architecture also adopts some optimizations such as simplifying modular
exponentiation units by dividing the exponent into segments and parallelizing
data flow by multi-core instantiation. Finally, a high-throughput and efficient
Paillier accelerator named MESA was implemented on the Xilinx Virtex-7 FPGA for
evaluation, which can complete a decryption using 2048-bit key within 0.577ms
under 100 MHz clock frequency. Compared to prior works, MESA demonstrates a
throughput improvement of 1.16 to 313.21 under identical conditions, also with
enhancements in area efficiency for LUT, DSP, and FF of 3.32 to 117.55, 1.49 to
1.64, and 2.94 to 9.94, respectively.

</details>


### [95] [Secure User-friendly Blockchain Modular Wallet Design Using Android & OP-TEE](https://arxiv.org/abs/2506.17988)
*Seongjin Kim,Sanguk Yun,Jungho Jang*

Main category: cs.CR

TL;DR: 本文提出了一种基于ARM TrustZone和OP-TEE的模块化密钥管理架构，通过多租户TA存储和加密签名链，解决了加密货币钱包的安全性与互操作性危机。


<details>
  <summary>Details</summary>
Motivation: 现有加密货币钱包在软件栈各层存在私钥泄漏风险，亟需一种既能保障安全又能支持多链互操作的解决方案。

Method: 将传统单一可信应用拆分为多链模块，采用硬件级安全隔离、加密OTA更新及链式签名验证，并通过安全监控调用限制富执行环境的访问。

Result: 实现了可抵御六层威胁的安全架构，支持比特币/以太坊等多链热插拔，审计效率提升50%，并在AOSP上验证了参考实现。

Conclusion: 模块化TEE架构为Web3提供了关键操作系统原语，其硬件级安全保障与灵活扩展性有望推动自托管钱包的大规模普及。

Abstract: Emerging crypto economies still hemorrhage digital assets because legacy
wallets leak private keys at almost every layer of the software stack, from
user-space libraries to kernel memory dumps. This paper solves that twin crisis
of security and interoperability by re-imagining key management as a
platform-level service anchored in ARM TrustZone through OP-TEE. Our
architecture fractures the traditional monolithic Trusted Application into
per-chain modules housed in a multi-tenant TA store, finally breaking OP-TEE's
single-binary ceiling. A cryptographically sealed firmware-over-the-air
pipeline welds each TA set to an Android system image, enabling hot-swap
updates while Verified Boot enforces rollback protection. Every package carries
a chained signature developer first, registry second so even a compromised
supply chain cannot smuggle malicious code past the Secure World's RSA-PSS
gatekeeper. Inside the TEE, strict inter-TA isolation, cache partitioning, and
GP-compliant crypto APIs ensure secrets never bleed across trust boundaries or
timing domains. The Rich Execution Environment can interact only via
hardware-mediated Secure Monitor Calls, collapsing the surface exposed to
malware in Android space. End-users enjoy a single polished interface yet can
install or retire Bitcoin, Ethereum, Solana, or tomorrow's chain with one tap,
shrinking both storage footprint and audit scope. For auditors, the composition
model slashes duplicated verification effort by quarantining blockchain logic
inside narrowly scoped modules that share formally specified interfaces. Our
threat analysis spans six adversary layers and shows how the design neutralizes
REE malware sniffing, OTA injection, and cross-module side channels without
exotic hardware. A reference implementation on AOSP exports a Wallet Manager
HAL, custom SELinux domains, and a CI/CD pipeline that vet community modules
before release. The result is not merely another hardware wallet but a
programmable substrate that can evolve at the velocity of the blockchain
ecosystem. By welding radical extensibility to hardware-anchored assurance, the
platform closes the security-usability gap that has long stymied mass-market
self-custody. We posit that modular TEEs are the missing OS primitive for Web3,
much as virtual memory unlocked multi-tasking in classical computing. Together,
these contributions sketch a blueprint for multi-chain asset management that is
auditable, resilient, and poised for global deployment.

</details>


### [96] [Mechanistic Interpretability in the Presence of Architectural Obfuscation](https://arxiv.org/abs/2506.18053)
*Marcos Florencio,Thomas Barton*

Main category: cs.CR

TL;DR: 架构混淆技术虽能保留大语言模型的全局行为，但会显著干扰其内部机制的逆向工程，在保护用户隐私内容的同时牺牲了细粒度可解释性。


<details>
  <summary>Details</summary>
Motivation: 研究架构混淆技术（如隐藏状态张量置换、嵌入表线性变换等）对模型机制可解释性的影响，填补现有文献空白。

Method: 在私有化混淆映射条件下，对GPT-2-small模型应用logit-lens归因、因果路径修补和注意力头消融等方法，追踪已知电路结构。

Result: 混淆技术会扭曲注意力头的激活模式但保持层级计算图完整，导致用户提示逆向工程失败（因果轨迹语义失准、logit归因噪声剧增），而前馈/残差通路功能不受影响。

Conclusion: 架构混淆能兼顾全局模型性能与隐私保护，但会破坏细粒度可解释性，为未来隐私防御和鲁棒性解释工具开发提供量化依据。

Abstract: Architectural obfuscation - e.g., permuting hidden-state tensors, linearly
transforming embedding tables, or remapping tokens - has recently gained
traction as a lightweight substitute for heavyweight cryptography in
privacy-preserving large-language-model (LLM) inference. While recent work has
shown that these techniques can be broken under dedicated reconstruction
attacks, their impact on mechanistic interpretability has not been
systematically studied. In particular, it remains unclear whether scrambling a
network's internal representations truly thwarts efforts to understand how the
model works, or simply relocates the same circuits to an unfamiliar coordinate
system. We address this gap by analyzing a GPT-2-small model trained from
scratch with a representative obfuscation map. Assuming the obfuscation map is
private and the original basis is hidden (mirroring an honest-but-curious
server), we apply logit-lens attribution, causal path-patching, and
attention-head ablation to locate and manipulate known circuits. Our findings
reveal that obfuscation dramatically alters activation patterns within
attention heads yet preserves the layer-wise computational graph. This
disconnect hampers reverse-engineering of user prompts: causal traces lose
their alignment with baseline semantics, and token-level logit attributions
become too noisy to reconstruct. At the same time, feed-forward and residual
pathways remain functionally intact, suggesting that obfuscation degrades
fine-grained interpretability without compromising top-level task performance.
These results establish quantitative evidence that architectural obfuscation
can simultaneously (i) retain global model behaviour and (ii) impede
mechanistic analyses of user-specific content. By mapping where
interpretability breaks down, our study provides guidance for future privacy
defences and for robustness-aware interpretability tooling.

</details>


### [97] [Federated Learning-Based Data Collaboration Method for Enhancing Edge Cloud AI System Security Using Large Language Models](https://arxiv.org/abs/2506.18087)
*Huaiying Luo,Cheng Ji*

Main category: cs.CR

TL;DR: 本文提出了一种基于联邦学习和大型语言模型（LLMs）的边缘云AI系统数据协作方法，通过安全多方计算协议和对抗训练技术，显著提升了数据隐私保护和系统鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着边缘计算和云系统在AI应用中的普及，如何在保证高效性能的同时确保数据隐私成为亟待解决的安全问题。

Method: 在现有联邦学习框架中引入安全多方计算协议，利用LLM优化分布式节点间的数据聚合与加密流程，并结合对抗训练技术增强系统对数据泄露和模型投毒等威胁的防御能力。

Result: 实验表明，该方法在数据保护和模型鲁棒性方面比传统联邦学习方法提升了15%。

Conclusion: 所提出的方法有效解决了边缘云AI系统中的隐私与安全问题，为分布式AI应用提供了更可靠的解决方案。

Abstract: With the widespread application of edge computing and cloud systems in
AI-driven applications, how to maintain efficient performance while ensuring
data privacy has become an urgent security issue. This paper proposes a
federated learning-based data collaboration method to improve the security of
edge cloud AI systems, and use large-scale language models (LLMs) to enhance
data privacy protection and system robustness. Based on the existing federated
learning framework, this method introduces a secure multi-party computation
protocol, which optimizes the data aggregation and encryption process between
distributed nodes by using LLM to ensure data privacy and improve system
efficiency. By combining advanced adversarial training techniques, the model
enhances the resistance of edge cloud AI systems to security threats such as
data leakage and model poisoning. Experimental results show that the proposed
method is 15% better than the traditional federated learning method in terms of
data protection and model robustness.

</details>


### [98] [Optimizing Resource Allocation and Energy Efficiency in Federated Fog Computing for IoT](https://arxiv.org/abs/2506.18100)
*Taimoor Ahmad,Anas Ali*

Main category: cs.CR

TL;DR: 本文提出了一种基于多层机器学习的框架，用于智能检测物联网（IoT）网络中的ARP欺骗攻击，显著提高了检测精度并降低了误报率。


<details>
  <summary>Details</summary>
Motivation: ARP欺骗攻击严重威胁物联网网络，传统检测方法因高误报率和适应性差而不足。

Method: 采用多层集成分类器框架，每层优化检测精度并减少误报，包括动态反馈机制和数据集不平衡问题的系统解决。

Result: 实验评估显示检测精度高达97.5\%，误报率低于2\%，且检测时间优于现有方法。

Conclusion: 该研究增强了物联网部署中的安全管理，为ARP欺骗攻击提供了鲁棒防御，提高了物联网环境的可靠性和信任度。

Abstract: Address Resolution Protocol (ARP) spoofing attacks severely threaten Internet
of Things (IoT) networks by allowing attackers to intercept, modify, or block
communications. Traditional detection methods are insufficient due to high
false positives and poor adaptability. This research proposes a multi-layered
machine learning-based framework for intelligently detecting ARP spoofing in
IoT networks. Our approach utilizes an ensemble of classifiers organized into
multiple layers, each layer optimizing detection accuracy and reducing false
alarms. Experimental evaluations demonstrate significant improvements in
detection accuracy (up to 97.5\%), reduced false positive rates (less than
2\%), and faster detection time compared to existing methods. Our key
contributions include introducing multi-layer ensemble classifiers specifically
tuned for IoT networks, systematically addressing dataset imbalance problems,
introducing a dynamic feedback mechanism for classifier retraining, and
validating practical applicability through extensive simulations. This research
enhances security management in IoT deployments, providing robust defenses
against ARP spoofing attacks and improving reliability and trust in IoT
environments.

</details>


### [99] [Dynamic Temporal Positional Encodings for Early Intrusion Detection in IoT](https://arxiv.org/abs/2506.18114)
*Ioannis Panopoulos,Maria-Lamprini A. Bartsioka,Sokratis Nikolaidis,Stylianos I. Venieris,Dimitra I. Kaklamani,Iakovos S. Venieris*

Main category: cs.CR

TL;DR: 本文提出了一种基于Transformer的早期入侵检测系统（EIDS），通过动态时间位置编码和数据增强技术，显著提升了IoT环境下的入侵检测准确性和实时性。


<details>
  <summary>Details</summary>
Motivation: 物联网（IoT）的快速发展带来了严峻的安全挑战，传统入侵检测系统（IDS）常忽略网络流量的时序特征，导致早期威胁检测效果不佳。

Method: 采用Transformer架构，结合动态时间位置编码捕捉流量序列结构和时序异常；引入数据增强流程提升模型鲁棒性；利用网络流时间戳识别恶意行为模式。

Result: 在CICIoT2023数据集上，本方法在检测准确性和时效性上均优于现有模型，并在资源受限的IoT设备上实现了低延迟推理和极小内存占用。

Conclusion: EIDS系统通过时序建模和轻量化设计，为IoT环境提供了高效、实时的入侵检测解决方案，兼具理论创新和工程实践价值。

Abstract: The rapid expansion of the Internet of Things (IoT) has introduced
significant security challenges, necessitating efficient and adaptive Intrusion
Detection Systems (IDS). Traditional IDS models often overlook the temporal
characteristics of network traffic, limiting their effectiveness in early
threat detection. We propose a Transformer-based Early Intrusion Detection
System (EIDS) that incorporates dynamic temporal positional encodings to
enhance detection accuracy while maintaining computational efficiency. By
leveraging network flow timestamps, our approach captures both sequence
structure and timing irregularities indicative of malicious behaviour.
Additionally, we introduce a data augmentation pipeline to improve model
robustness. Evaluated on the CICIoT2023 dataset, our method outperforms
existing models in both accuracy and earliness. We further demonstrate its
real-time feasibility on resource-constrained IoT devices, achieving
low-latency inference and minimal memory footprint.

</details>


### [100] [HE-LRM: Encrypted Deep Learning Recommendation Models using Fully Homomorphic Encryption](https://arxiv.org/abs/2506.18150)
*Karthik Garimella,Austin Ebel,Gabrielle De Micheli,Brandon Reagen*

Main category: cs.CR

TL;DR: 本文探讨了全同态加密（FHE）在深度学习推荐模型（DLRM）中的应用挑战与机遇，提出了一种压缩嵌入查找方法和多嵌入打包策略，显著提升了加密推理效率，并在开源框架Orion中实现了端到端的加密DLRM系统HE-LRM。


<details>
  <summary>Details</summary>
Motivation: 全同态加密（FHE）能够直接在加密数据上进行计算，适用于隐私保护的神经推理。然而，稀疏特征的加密查找操作在计算和内存方面存在挑战，尤其是在深度学习推荐模型（DLRM）中。本文旨在解决这些挑战，提升加密推荐系统的实用性。

Method: 本文提出了一种压缩嵌入查找方法，显著降低了FHE的计算成本，同时保持了模型的性能。此外，还提出了一种高效的多嵌入打包策略，支持在FHE下进行4400万参数的嵌入查找。这些方法被集成到开源框架Orion中，形成了端到端的加密DLRM系统HE-LRM。

Result: 实验结果表明，压缩嵌入查找方法比现有最优方法提升了77倍。多嵌入打包策略成功实现了大规模嵌入查找。在UCI（健康预测）和Criteo（点击预测）数据集上的评估显示，加密推理在推荐系统中是可行的。

Conclusion: 通过适当的压缩和打包策略，加密推理在推荐系统中具有实际应用价值。本文提出的方法显著提升了FHE在DLRM中的效率，为隐私保护的推荐系统提供了可行的解决方案。

Abstract: Fully Homomorphic Encryption (FHE) is an encryption scheme that not only
encrypts data but also allows for computations to be applied directly on the
encrypted data. While computationally expensive, FHE can enable
privacy-preserving neural inference in the client-server setting: a client
encrypts their input with FHE and sends it to an untrusted server. The server
then runs neural inference on the encrypted data and returns the encrypted
results. The client decrypts the output locally, keeping both the input and
result private from the server. Private inference has focused on networks with
dense inputs such as image classification, and less attention has been given to
networks with sparse features. Unlike dense inputs, sparse features require
efficient encrypted lookup operations into large embedding tables, which
present computational and memory constraints for FHE.
  In this paper, we explore the challenges and opportunities when applying FHE
to Deep Learning Recommendation Models (DLRM) from both a compiler and systems
perspective. DLRMs utilize conventional MLPs for dense features and embedding
tables to map sparse, categorical features to dense vector representations. We
develop novel methods for performing compressed embedding lookups in order to
reduce FHE computational costs while keeping the underlying model performant.
Our embedding lookup improves upon a state-of-the-art approach by $77 \times$.
Furthermore, we present an efficient multi-embedding packing strategy that
enables us to perform a 44 million parameter embedding lookup under FHE.
Finally, we integrate our solutions into the open-source Orion framework and
present HE-LRM, an end-to-end encrypted DLRM. We evaluate HE-LRM on UCI (health
prediction) and Criteo (click prediction), demonstrating that with the right
compression and packing strategies, encrypted inference for recommendation
systems is practical.

</details>


### [101] [SoK: Current State of Ethereum's Enshrined Proposer Builder Separation](https://arxiv.org/abs/2506.18189)
*Maxwell Koegler*

Main category: cs.CR

TL;DR: 本文探讨了以太坊中提议者-构建者分离（PBS）机制的现状及其协议内化（ePBS）的必要性，分析了潜在风险与Web3价值观的契合点。


<details>
  <summary>Details</summary>
Motivation: 当前通过MEV-boost实现的PBS存在依赖中继、缺乏监管的问题，社区呼吁将其协议内化以提升安全性并降低验证者成本，同时需解决多方共谋和链停滞风险。

Method: 研究通过系统化梳理现有PBS机制，评估协议内化升级（ePBS）的技术方案，包括原生MEV缓解机制和负载外包通信层的设计。

Result: ePBS可能实现抗审查、验证者收益公平等目标，但需平衡多方博弈带来的社会经济影响，如共谋导致的中心化倾向。

Conclusion: PBS协议内化是兼顾MEV问题解决与Web3价值观的关键路径，但需谨慎设计以避免衍生风险，后续研究将聚焦具体实施方案的链上影响。

Abstract: Initially introduced to Ethereum via Flashbots' MEV-boost, Proposer-Builder
Separation allows proposers to auction off blockspace to a market of
transaction orderers, known as builders. PBS is currently available to
validators through the aforementioned MEV-boost, but its unregulated and
relay-dependent nature has much of the Ethereum community calling for its
enshrinement. Providing a protocol-integrated PBS marketspace and communication
channel for payload outsourcing is termed PBS enshrinement. Although ePBS
potentially introduces native MEV mitigation mechanisms and reduces validator
operation costs, fears of multiparty collusion and chain stagnation are all too
real. In addition to mitigating these potential drawbacks, PBS research pursues
many tenets revered by Web3 enthusiasts, including but not limited to,
censorship resistance, validator reward equity, and deflationary finance. The
subsequent SoK will identify current PBS mechanisms, the need for enshrinement,
additions to the ePBS upgrade, and the existing or potential on-chain
socioeconomic implications of each.

</details>


### [102] [Shrinking the Generation-Verification Gap with Weak Verifiers](https://arxiv.org/abs/2506.18203)
*Jon Saad-Falcon,E. Kelly Buchanan,Mayee F. Chen,Tzu-Heng Huang,Brendan McLaughlin,Tanvir Bhathal,Shang Zhu,Ben Athiwaratkun,Frederic Sala,Scott Linderman,Azalia Mirhoseini,Christopher Ré*

Main category: cs.CR

TL;DR: Weaver框架通过组合多个弱验证器构建强验证器，利用弱监督减少对标注数据的依赖，显著提升语言模型在测试时重复采样中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有验证器要么不可扩展（如人类），要么效用有限（如Lean工具），LM评判和奖励模型虽广泛使用，但与完美验证器仍有性能差距。

Method: Weaver通过加权集成多个弱验证器，利用弱监督估计各验证器准确率，并归一化输出格式以处理低质量验证器，最终合成统一评分。

Result: 在推理和数学任务中，Weaver显著超越Pass@1性能，使用Llama 3.3 70B生成器时达到o3-mini级别准确率（87.7%），接近GPT-4o与o3-mini的差距。

Conclusion: Weaver有效缩小了普通验证器与完美验证器的差距，并通过训练400M交叉编码器降低集成计算成本，为语言模型验证提供了高效解决方案。

Abstract: Verifiers can improve language model capabilities by scoring and ranking
responses from generated candidates. Currently, high-quality verifiers are
either unscalable (e.g., humans) or limited in utility (e.g., tools like Lean).
While LM judges and reward models have become broadly useful as general-purpose
verifiers, a significant performance gap remains between them and oracle
verifiers (verifiers with perfect accuracy). To help close this gap, we
introduce Weaver, a framework for designing a strong verifier by combining
multiple weak, imperfect verifiers. We find weighted ensembles of verifiers,
which typically require learning from labeled data, significantly outperform
unweighted combinations due to differences in verifier accuracies. To reduce
dependency on labeled data, Weaver leverages weak supervision to estimate each
verifier's accuracy and combines outputs into a unified score that better
reflects true response quality. However, directly applying weak supervision
algorithms poses challenges, including inconsistent verifier output formats and
handling low-quality verifiers. Weaver addresses these using dataset statistics
to normalize outputs and filter specific verifiers. We study Weaver's
effectiveness in test-time repeated sampling, where a model generates multiple
candidate responses and selects one. Our evaluations show Weaver significantly
improves over Pass@1-performance when selecting the first candidate-across
reasoning and math tasks, achieving o3-mini-level accuracy with Llama 3.3 70B
Instruct as generator, and an ensemble of 70B or smaller judge and reward
models as verifiers (87.7% average). This gain mirrors the jump between GPT-4o
and o3-mini (69.0% vs. 86.7%), which required extensive finetuning and
post-training. To reduce computational costs of verifier ensembles, we train a
400M cross-encoder using Weaver's combined output scores.

</details>


### [103] [Smart-LLaMA-DPO: Reinforced Large Language Model for Explainable Smart Contract Vulnerability Detection](https://arxiv.org/abs/2506.18245)
*Lei Yu,Zhirong Huang,Hang Yuan,Shiqi Cheng,Li Yang,Fengjun Zhang,Chenjie Shen,Jiajia Ma,Jingyuan Zhang,Junyi Lu,Chun Zuo*

Main category: cs.CR

TL;DR: 本文提出基于LLaMA-3.1-8B的Smart-LLaMA-DPO模型，通过构建全面数据集、持续预训练和直接偏好优化，显著提升了智能合约漏洞检测的准确性和解释质量。


<details>
  <summary>Details</summary>
Motivation: 现有智能合约漏洞检测方法存在数据集覆盖不全、大语言模型对安全概念理解不准确等问题，导致解释错误或检测效果不佳。

Method: 1) 构建覆盖四类主要漏洞的标注数据集；2) 使用大规模合约代码进行持续预训练；3) 采用监督微调和直接偏好优化(DPO)结合人类反馈优化模型。

Result: 在重入、时间戳依赖等漏洞检测上，F1值平均提升10.43%，准确率提升7.87%，生成的解释更正确全面。

Conclusion: Smart-LLaMA-DPO通过系统化训练框架显著提升检测性能，为智能合约安全提供了更可靠的自动化审计方案。

Abstract: Smart contract vulnerability detection remains a major challenge in
blockchain security. Existing vulnerability detection methods face two main
issues: (1) Existing datasets lack comprehensive coverage and high-quality
explanations for preference learning. (2) Large language models (LLMs) often
struggle with accurately interpreting specific concepts in smart contract
security. Empirical analysis shows that even after continual pre-training (CPT)
and supervised fine-tuning (SFT), LLMs may misinterpret the execution order of
state changes, resulting in incorrect explanations despite making correct
detection decisions. To address these challenges, we propose Smart-LLaMA-DPO
based on LLaMA-3.1-8B. We construct a comprehensive dataset covering four major
vulnerability types and machine-unauditable vulnerabilities, including precise
labels, explanations, and locations for SFT, as well as high-quality and
low-quality output pairs for Direct Preference Optimization (DPO). Second, we
perform CPT using large-scale smart contract to enhance the LLM's understanding
of specific security practices in smart contracts. Futhermore, we conduct SFT
with our comprehensive dataset. Finally, we apply DPO, leveraging human
feedback and a specially designed loss function that increases the probability
of preferred explanations while reducing the likelihood of non-preferred
outputs. We evaluate Smart-LLaMA-DPO on four major vulnerability types:
reentrancy, timestamp dependence, integer overflow/underflow, and delegatecall,
as well as machine-unauditable vulnerabilities. Our method significantly
outperforms state-of-the-art baselines, with average improvements of 10.43% in
F1 score and 7.87% in accuracy. Moreover, both LLM evaluation and human
evaluation confirm that our method generates more correct, thorough, and clear
explanations.

</details>


### [104] [Adaptive alert prioritisation in security operations centres via learning to defer with human feedback](https://arxiv.org/abs/2506.18462)
*Fatemeh Jalalvand,Mohan Baruwal Chhetri,Surya Nepal,Cécile Paris*

Main category: cs.CR

TL;DR: 本文提出了一种基于人类反馈的自适应延迟学习框架L2DHF，通过结合深度强化学习优化安全告警优先级排序，显著提升准确率并减少分析师工作量。


<details>
  <summary>Details</summary>
Motivation: 传统AI在安全运营中心(SOC)告警优先级排序中存在对新型威胁识别不足的问题，而静态延迟策略无法从人类反馈中学习。需要动态融合人类与AI优势的方案。

Method: 提出L2DHF框架，采用深度强化学习从人类反馈(DRLHF)中动态优化延迟决策，使AI能持续改进并减少不必要的人类介入。

Result: 在UNSW-NB15和CICIDS2017数据集上，关键告警准确率分别提升13-16%和60-67%，CICIDS2017高优先级误判减少98%，UNSW-NB15延迟量降低37%。

Conclusion: L2DHF通过实时整合人类反馈实现了高效自适应的告警排序，实验证明其能显著提升SOC运营效率并减轻分析师负担，具备实际部署价值。

Abstract: Alert prioritisation (AP) is crucial for security operations centres (SOCs)
to manage the overwhelming volume of alerts and ensure timely detection and
response to genuine threats, while minimising alert fatigue. Although
predictive AI can process large alert volumes and identify known patterns, it
struggles with novel and evolving scenarios that demand contextual
understanding and nuanced judgement. A promising solution is Human-AI teaming
(HAT), which combines human expertise with AI's computational capabilities.
Learning to Defer (L2D) operationalises HAT by enabling AI to "defer" uncertain
or unfamiliar cases to human experts. However, traditional L2D models rely on
static deferral policies that do not evolve with experience, limiting their
ability to learn from human feedback and adapt over time. To overcome this, we
introduce Learning to Defer with Human Feedback (L2DHF), an adaptive deferral
framework that leverages Deep Reinforcement Learning from Human Feedback
(DRLHF) to optimise deferral decisions. By dynamically incorporating human
feedback, L2DHF continuously improves AP accuracy and reduces unnecessary
deferrals, enhancing SOC effectiveness and easing analyst workload. Experiments
on two widely used benchmark datasets, UNSW-NB15 and CICIDS2017, demonstrate
that L2DHF significantly outperforms baseline models. Notably, it achieves
13-16% higher AP accuracy for critical alerts on UNSW-NB15 and 60-67% on
CICIDS2017. It also reduces misprioritisations, for example, by 98% for
high-category alerts on CICIDS2017. Moreover, L2DHF decreases deferrals, for
example, by 37% on UNSW-NB15, directly reducing analyst workload. These gains
are achieved with efficient execution, underscoring L2DHF's practicality for
real-world SOC deployment.

</details>


### [105] [Automatic Selection of Protections to Mitigate Risks Against Software Applications](https://arxiv.org/abs/2506.18470)
*Daniele Canavese,Leonardo Regano,Bjorn De Sutter,Cataldo Basile*

Main category: cs.CR

TL;DR: 本文提出了一种自动化选择软件保护措施的新方法，通过博弈论模型优化防御策略，引入软件保护指数评估保护效果，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对关键软件资产面临的MATE风险，现有保护措施选择缺乏系统性方法，亟需自动化解决方案以平衡安全性与可用性。

Method: 建立博弈论模型，防御者通过启发式最小最大深度优先搜索策略动态优化保护方案，提出结合软件指标与专家评估的软件保护指数(SPI)。

Result: 概念验证实现与专家评估表明，该方法能有效提升软件抗攻击能力，同时将保护开销控制在可接受范围内。

Conclusion: 基于博弈论的自动化软件保护选择方案为软件风险缓解提供了兼具理论严谨性与实践可行性的新途径。

Abstract: This paper introduces a novel approach for the automated selection of
software protections to mitigate MATE risks against critical assets within
software applications. We formalize the key elements involved in protection
decision-making - including code artifacts, assets, security requirements,
attacks, and software protections - and frame the protection process through a
game-theoretic model. In this model, a defender strategically applies
protections to various code artifacts of a target application, anticipating
repeated attack attempts by adversaries against the confidentiality and
integrity of the application's assets. The selection of the optimal defense
maximizes resistance to attacks while ensuring the application remains usable
by constraining the overhead introduced by protections. The game is solved
through a heuristic based on a mini-max depth-first exploration strategy,
augmented with dynamic programming optimizations for improved efficiency.
Central to our formulation is the introduction of the Software Protection
Index, an original contribution that extends existing notions of potency and
resilience by evaluating protection effectiveness against attack paths using
software metrics and expert assessments. We validate our approach through a
proof-of-concept implementation and expert evaluations, demonstrating that
automated software protection is a practical and effective solution for risk
mitigation in software.

</details>


### [106] [DUMB and DUMBer: Is Adversarial Training Worth It in the Real World?](https://arxiv.org/abs/2506.18516)
*Francesco Marchiori,Marco Alecci,Luca Pajola,Mauro Conti*

Main category: cs.CR

TL;DR: 本文介绍了DUMBer攻击框架，用于系统评估对抗训练模型的鲁棒性，通过多任务、多模型的大规模实验揭示了不同防御策略的实际效果。


<details>
  <summary>Details</summary>
Motivation: 对抗样本通过微小扰动欺骗机器学习模型，其可迁移性使黑盒攻击成为可能。现有对抗训练评估局限于同质模型，难以反映实际部署中的多样性。

Method: 基于DUMB方法论构建DUMBer框架，在三个计算机视觉任务中评估多种对抗训练技术，使用13种先进攻击算法对异构模型群进行13万次评估。

Result: 实验揭示了对抗训练在不同威胁模型和数据集条件下的细微行为差异，为实践者提供了基于模型、数据和攻击设置的防御有效性指导。

Conclusion: 该研究为AI实践者提供了可操作的防御策略选择依据，强调需根据具体部署环境选择最优对抗训练方案。

Abstract: Adversarial examples are small and often imperceptible perturbations crafted
to fool machine learning models. These attacks seriously threaten the
reliability of deep neural networks, especially in security-sensitive domains.
Evasion attacks, a form of adversarial attack where input is modified at test
time to cause misclassification, are particularly insidious due to their
transferability: adversarial examples crafted against one model often fool
other models as well. This property, known as adversarial transferability,
complicates defense strategies since it enables black-box attacks to succeed
without direct access to the victim model. While adversarial training is one of
the most widely adopted defense mechanisms, its effectiveness is typically
evaluated on a narrow and homogeneous population of models. This limitation
hinders the generalizability of empirical findings and restricts practical
adoption.
  In this work, we introduce DUMBer, an attack framework built on the
foundation of the DUMB (Dataset soUrces, Model architecture, and Balance)
methodology, to systematically evaluate the resilience of adversarially trained
models. Our testbed spans multiple adversarial training techniques evaluated
across three diverse computer vision tasks, using a heterogeneous population of
uniquely trained models to reflect real-world deployment variability. Our
experimental pipeline comprises over 130k evaluations spanning 13
state-of-the-art attack algorithms, allowing us to capture nuanced behaviors of
adversarial training under varying threat models and dataset conditions. Our
findings offer practical, actionable insights for AI practitioners, identifying
which defenses are most effective based on the model, dataset, and attacker
setup.

</details>


### [107] [Security Assessment of DeepSeek and GPT Series Models against Jailbreak Attacks](https://arxiv.org/abs/2506.18543)
*Xiaodong Wu,Xiangman Li,Jianbing Ni*

Main category: cs.CR

TL;DR: 本文首次系统评估了DeepSeek系列模型在对抗性提示攻击（越狱攻击）下的鲁棒性，并与GPT-3.5、GPT-4进行对比。研究发现DeepSeek的混合专家（MoE）架构对优化类攻击具有选择性抵抗力，但对提示类攻击更脆弱，揭示了架构效率与安全对齐间的权衡。


<details>
  <summary>Details</summary>
Motivation: 随着开源大模型（如DeepSeek）的广泛应用，其对抗越狱攻击的鲁棒性尚未得到充分研究。本文旨在填补这一空白，评估开源模型与商用模型（如GPT-4）在安全对齐上的差异。

Method: 使用HarmBench基准测试，对比评估DeepSeek与GPT-3.5/GPT-4 Turbo。测试7种典型攻击策略，覆盖510种按功能和语义分类的有害行为，分析MoE架构的路由稀疏性对安全性的影响。

Result: DeepSeek的MoE架构对TAP-T等优化攻击具有选择性鲁棒性，但对提示工程攻击更敏感；GPT-4 Turbo因密集Transformer结构和RLHF训练表现更稳定。案例显示DeepSeek常将对抗提示路由至未充分对齐的专家模块。

Conclusion: 研究揭示了架构效率与安全泛化间的根本性权衡，强调需针对开源模型开发模块化对齐策略和定向安全调优，以确保安全部署。

Abstract: The widespread deployment of large language models (LLMs) has raised critical
concerns over their vulnerability to jailbreak attacks, i.e., adversarial
prompts that bypass alignment mechanisms and elicit harmful or policy-violating
outputs. While proprietary models like GPT-4 have undergone extensive
evaluation, the robustness of emerging open-source alternatives such as
DeepSeek remains largely underexplored, despite their growing adoption in
real-world applications. In this paper, we present the first systematic
jailbreak evaluation of DeepSeek-series models, comparing them with GPT-3.5 and
GPT-4 using the HarmBench benchmark. We evaluate seven representative attack
strategies across 510 harmful behaviors categorized by both function and
semantic domain. Our analysis reveals that DeepSeek's Mixture-of-Experts (MoE)
architecture introduces routing sparsity that offers selective robustness
against optimization-based attacks such as TAP-T, but leads to significantly
higher vulnerability under prompt-based and manually engineered attacks. In
contrast, GPT-4 Turbo demonstrates stronger and more consistent safety
alignment across diverse behaviors, likely due to its dense Transformer design
and reinforcement learning from human feedback. Fine-grained behavioral
analysis and case studies further show that DeepSeek often routes adversarial
prompts to under-aligned expert modules, resulting in inconsistent refusal
behaviors. These findings highlight a fundamental trade-off between
architectural efficiency and alignment generalization, emphasizing the need for
targeted safety tuning and modular alignment strategies to ensure secure
deployment of open-source LLMs.

</details>


### [108] [Understanding the Theoretical Guarantees of DPM](https://arxiv.org/abs/2506.18685)
*Yara Schütt,Esfandiar Mohammadi*

Main category: cs.CR

TL;DR: 本研究深入分析了差分隐私机制(DPM)的效用，扩展了停止准则的理论解释，揭示了最小聚类规模和评分函数权重限制，并通过轮廓系数质疑其作为聚类指标的适用性，最后将DPM与$(\xi, \rho)$-可分离性理论关联，促进其在未知场景中的应用。


<details>
  <summary>Details</summary>
Motivation: 已有研究建立了DPM选择优质分裂及停止的概率保证，但需在现实输入分布背景下重新解读这些理论保证，以理解DPM在任意输入中的行为规律。

Method: 通过聚类指标轮廓系数解读DPM效用，分析分裂停止准则的理论边界，并将其与$(\xi, \rho)$-可分离性理论框架关联。

Result: 发现即使采用最优DPM分裂，轮廓系数仍可能下降；确定了最小聚类规模和评分函数权重的约束条件，揭示了超参数与输入数据集对DPM效果的影响机制。

Conclusion: 对DPM理论保证的系统分析不仅质疑了轮廓系数的适用性，更通过$(\xi, \rho)$-可分离性框架推动DPM在未知数据环境中的实践应用。

Abstract: In this study, we conducted an in-depth examination of the utility analysis
of the differentially private mechanism (DPM). The authors of DPM have already
established the probability of a good split being selected and of DPM halting.
In this study, we expanded the analysis of the stopping criterion and provided
an interpretation of these guarantees in the context of realistic input
distributions. Our findings revealed constraints on the minimum cluster size
and the metric weight for the scoring function. Furthermore, we introduced an
interpretation of the utility of DPM through the lens of the clustering metric,
the silhouette score. Our findings indicate that even when an optimal DPM-based
split is employed, the silhouette score of the resulting clustering may still
decline. This observation calls into question the suitability of the silhouette
score as a clustering metric. Finally, we examined the potential of the
underlying concept of DPM by linking it to a more theoretical view, that of
$(\xi, \rho)$-separability. This extensive analysis of the theoretical
guarantees of DPM allows a better understanding of its behaviour for arbitrary
inputs. From these guarantees, we can analyse the impact of different
hyperparameters and different input data sets, thereby promoting the
application of DPM in practice for unknown settings and data sets.

</details>


### [109] [Vulnerability Assessment Combining CVSS Temporal Metrics and Bayesian Networks](https://arxiv.org/abs/2506.18715)
*Stefano Perone,Simone Guarino,Luca Faramondi,Roberto Setola*

Main category: cs.CR

TL;DR: 该研究提出了一种结合CVSS时间指标与贝叶斯网络的创新方法，用于动态评估工业网络安全漏洞优先级。


<details>
  <summary>Details</summary>
Motivation: 现有漏洞评估方法忽视时间维度，无法有效应对工业环境中漏洞修复与利用的动态变化。

Method: 通过贝叶斯网络概率建模整合CVSS时间指标，动态计算漏洞时间分数并更新基础分数，考量漏洞利用可行性、修复状态及报告可信度。

Result: 该方法实现了漏洞优先级的自适应评估，为决策提供更精准的动态数据支撑。

Conclusion: 融合时间维度的贝叶斯网络模型显著提升了漏洞评估的时效性与准确性，特别适用于需要快速响应的工业安全场景。

Abstract: Vulnerability assessment is a critical challenge in cybersecurity,
particularly in industrial environments. This work presents an innovative
approach by incorporating the temporal dimension into vulnerability assessment,
an aspect neglected in existing literature. Specifically, this paper focuses on
refining vulnerability assessment and prioritization by integrating Common
Vulnerability Scoring System (CVSS) Temporal Metrics with Bayesian Networks to
account for exploit availability, remediation efforts, and confidence in
reported vulnerabilities. Through probabilistic modeling, Bayesian networks
enable a structured and adaptive evaluation of vulnerabilities, allowing for
more accurate prioritization and decision-making. The proposed approach
dynamically computes the Temporal Score and updates the CVSS Base Score by
processing data on exploits and fixes from vulnerability databases.

</details>


### [110] [Physical Layer Challenge-Response Authentication between Ambient Backscatter Devices](https://arxiv.org/abs/2506.18767)
*Yifan Zhang,Yongchao Dang,Masoud Kaveh,Zheng Yan,Riku Jäntti,Zhu Han*

Main category: cs.CR

TL;DR: 本文提出PLCRA-BD方案，一种面向环境反向散射通信(AmBC)的轻量级物理层挑战-响应认证机制，解决资源受限设备的安全认证问题，支持高移动性并有效抵御多种无线攻击。


<details>
  <summary>Details</summary>
Motivation: 环境反向散射通信(AmBC)因能量收集特性成为物联网关键技术，但开放无线环境使其易受攻击，且传统认证方法无法在资源受限的背向散射设备(BD)间实施。

Method: 1) 构建物理层指纹作为轻量级身份标识 2) 设计收发一体联合架构，利用OFDM符号重复模式抑制环境射频干扰 3) 基于信道相干性实现低复杂度挑战-响应认证 4) 针对高移动场景优化流程，确保在信道相干时间内完成交换。

Result: 安全分析表明方案可抵抗假冒、窃听、重放和伪造攻击。仿真验证其在资源受限BD中的高效性，在不同信道条件下均保持高认证精度，且性能优于传统方案。

Conclusion: PLCRA-BD通过物理层指纹和联合收发设计，为AmBC系统提供了安全、轻量且支持移动场景的认证解决方案，显著提升了资源受限设备的安全性。

Abstract: Ambient backscatter communication (AmBC) has become an integral part of
ubiquitous Internet of Things (IoT) applications due to its energy-harvesting
capabilities and ultra-low-power consumption. However, the open wireless
environment exposes AmBC systems to various attacks, and existing
authentication methods cannot be implemented between resource-constrained
backscatter devices (BDs) due to their high computational demands.To this end,
this paper proposes PLCRA-BD, a novel physical layer challenge-response
authentication scheme between BDs in AmBC that overcomes BDs' limitations,
supports high mobility, and performs robustly against impersonation and
wireless attacks. It constructs embedded keys as physical layer fingerprints
for lightweight identification and designs a joint transceiver that integrates
BDs' backscatter waveform with receiver functionality to mitigate interference
from ambient RF signals by exploiting repeated patterns in OFDM symbols. Based
on this, a challenge-response authentication procedure is introduced to enable
low-complexity fingerprint exchange between two paired BDs leveraging channel
coherence, while securing the exchange process using a random number and
unpredictable channel fading. Additionally, we optimize the authentication
procedure for high-mobility scenarios, completing exchanges within the channel
coherence time to minimize the impact of dynamic channel fluctuations. Security
analysis confirms its resistance against impersonation, eavesdropping, replay,
and counterfeiting attacks. Extensive simulations validate its effectiveness in
resource-constrained BDs, demonstrating high authentication accuracy across
diverse channel conditions, robustness against multiple wireless attacks, and
superior efficiency compared to traditional authentication schemes.

</details>


### [111] [Design high-confidence computers using trusted instructional set architecture and emulators](https://arxiv.org/abs/2506.18780)
*Shuangbao Paul Wang*

Main category: cs.CR

TL;DR: 本文提出了一种可信计算机架构设计与仿真的整体方法，以应对现代处理器因Spectre和Meltdown漏洞而面临的安全威胁。


<details>
  <summary>Details</summary>
Motivation: 高可信计算依赖于可信指令集架构、密封内核和安全操作系统，而云计算则依赖于可信系统进行虚拟化任务。然而，Spectre和Meltdown漏洞使现代处理器易受攻击，禁用分支预测和流水线并非理想解决方案，现有软件补丁仅能解决非核心问题。

Method: 论文提出了一种整体性的可信计算机架构设计与仿真方法。

Result: 该方法旨在从根本上解决现代处理器的安全漏洞问题，而非仅通过软件补丁或禁用关键性能优化技术。

Conclusion: 通过整体性的架构设计与仿真，可以有效提升计算机系统的安全性和可信度，同时保持高性能计算能力。

Abstract: High-confidence computing relies on trusted instructional set architecture,
sealed kernels, and secure operating systems. Cloud computing depends on
trusted systems for virtualization tasks. Branch predictions and pipelines are
essential in improving performance of a CPU/GPU. But Spectre and Meltdown make
modern processors vulnerable to be exploited. Disabling the prediction and
pipeline is definitely not a good solution. On the other hand, current software
patches can only address non-essential issues around Meltdown. This paper
introduces a holistic approach in trusted computer architecture design and
emulation.

</details>


### [112] [FORGE: An LLM-driven Framework for Large-Scale Smart Contract Vulnerability Dataset Construction](https://arxiv.org/abs/2506.18795)
*Jiachi Chen,Yiming Shen,Jiashuo Zhang,Zihao Li,John Grundy,Zhenzhe Shao,Yanlin Wang,Jiashui Wang,Ting Chen,Zibin Zheng*

Main category: cs.CR

TL;DR: 本文提出FORGE，首个自动化构建智能合约漏洞数据集的方法，通过LLM驱动流程从真实审计报告中提取高质量漏洞并按CWE标准分类，显著提升数据集规模与标注一致性。


<details>
  <summary>Details</summary>
Motivation: 当前人工构建的智能合约漏洞数据集存在标注过程劳动密集易出错、分类标准不统一两大局限，制约安全工具评估与安全研究进展。

Method: FORGE采用分治策略从审计报告提取结构化漏洞信息，并运用思维树技术将其分类至CWE层级体系，实现自动化数据集构建。

Result: 处理6,454份审计报告生成含81,390个Solidity文件、27,497个漏洞记录的数据集，人工验证显示提取精确度达95.6%，与专家标注一致性k-$\alpha$为0.87。对13种安全工具的基准测试揭示了当前检测能力的不足。

Conclusion: FORGE构建的数据集不仅为安全研究提供标准化基准，还通过CWE统一视角揭示了现实漏洞严重性分布与当前研究重点的不匹配现象。

Abstract: High-quality smart contract vulnerability datasets are critical for
evaluating security tools and advancing smart contract security research. Two
major limitations of current manual dataset construction are (1)
labor-intensive and error-prone annotation processes limiting the scale,
quality, and evolution of the dataset, and (2) absence of standardized
classification rules results in inconsistent vulnerability categories and
labeling results across different datasets. To address these limitations, we
present FORGE, the first automated approach for constructing smart contract
vulnerability datasets. FORGE leverages an LLM-driven pipeline to extract
high-quality vulnerabilities from real-world audit reports and classify them
according to the CWE, the most widely recognized classification in software
security. FORGE employs a divide-and-conquer strategy to extract structured and
self-contained vulnerability information from these reports. Additionally, it
uses a tree-of-thoughts technique to classify the vulnerability information
into the hierarchical CWE classification. To evaluate FORGE's effectiveness, we
run FORGE on 6,454 real-world audit reports and generate a dataset comprising
81,390 solidity files and 27,497 vulnerability findings across 296 CWE
categories. Manual assessment of the dataset demonstrates high extraction
precision and classification consistency with human experts (precision of 95.6%
and inter-rater agreement k-$\alpha$ of 0.87). We further validate the
practicality of our dataset by benchmarking 13 existing security tools on our
dataset. The results reveal the significant limitations in current detection
capabilities. Furthermore, by analyzing the severity-frequency distribution
patterns through a unified CWE perspective in our dataset, we highlight
inconsistency between current smart contract research focus and priorities
identified from real-world vulnerabilities...

</details>


### [113] [Cellular Automata as Generators of Interleaving Sequences](https://arxiv.org/abs/2506.18848)
*Sara D. Cardell*

Main category: cs.CR

TL;DR: 本文提出两种一维细胞自动机作为交织序列生成器，填补了细胞自动机与交织序列生成之间研究空白。


<details>
  <summary>Details</summary>
Motivation: 现有文献中，细胞自动机作为序列生成器与交织序列的研究相互独立，缺乏两者结合的研究。本文旨在填补这一空白，探索细胞自动机生成交织序列的能力。

Method: 研究采用两种一维细胞自动机家族作为交织序列的生成器，通过交织多个序列元素实现序列生成。

Result: 研究展示了细胞自动机能够有效生成交织序列，为这一领域提供了新的生成方法。

Conclusion: 本研究通过细胞自动机生成交织序列，不仅填补了文献空白，还深化了对细胞自动机与序列生成之间关系的理解。

Abstract: An interleaving sequence is obtained by combining or intertwining elements
from two or more sequences. On the other hand, cellular automata are known to
be generators for keystream sequences. In this paper we present two families of
one-dimensional cellular automata as generators of interleaving sequences. This
study aims to close a notable gap within the current body of literature by
exploring the capacity of cellular automata to generate interleaving sequences.
While previous works have separately examined cellular automata as sequence
generators and interleaving sequences, there exists limited literature
interconnecting these two topics. Our study seeks to bridge this gap, providing
perspectives on the generation of interleaving sequences through the
utilisation of cellular automata, thereby fostering a deeper understanding of
both disciplines.

</details>


### [114] [Amplifying Machine Learning Attacks Through Strategic Compositions](https://arxiv.org/abs/2506.18870)
*Yugeng Liu,Zheng Li,Hai Huang,Michael Backes,Yang Zhang*

Main category: cs.CR

TL;DR: 该论文首次研究了机器学习模型中多种攻击策略的组合效应，提出了基于攻击流程三阶段的分类法，并通过实验验证了四种有效攻击组合。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注单一攻击类型，而实践中攻击者可能同时采用多种策略。论文探讨了不同攻击间的协同效应，填补了这一研究空白。

Method: 提出基于准备、执行、评估三阶段的攻击组合分类法，聚焦对抗样本、属性推断、成员推断和属性推断四种推理阶段攻击，开发了可复用工具包COAT。

Result: 在三种ML架构和图像数据集上的实验表明，四种攻击组合（如属性推断辅助属性推断、对抗样本辅助属性推断）具有显著效果。

Conclusion: 研究呼吁学界关注多策略组合攻击场景，以提升AI系统的安全性和鲁棒性，并开源了模块化工具包COAT推动相关研究。

Abstract: Machine learning (ML) models are proving to be vulnerable to a variety of
attacks that allow the adversary to learn sensitive information, cause
mispredictions, and more. While these attacks have been extensively studied,
current research predominantly focuses on analyzing each attack type
individually. In practice, however, adversaries may employ multiple attack
strategies simultaneously rather than relying on a single approach. This
prompts a crucial yet underexplored question: When the adversary has multiple
attacks at their disposal, are they able to mount or amplify the effect of one
attack with another? In this paper, we take the first step in studying the
strategic interactions among different attacks, which we define as attack
compositions. Specifically, we focus on four well-studied attacks during the
model's inference phase: adversarial examples, attribute inference, membership
inference, and property inference. To facilitate the study of their
interactions, we propose a taxonomy based on three stages of the attack
pipeline: preparation, execution, and evaluation. Using this taxonomy, we
identify four effective attack compositions, such as property inference
assisting attribute inference at its preparation level and adversarial examples
assisting property inference at its execution level. We conduct extensive
experiments on the attack compositions using three ML model architectures and
three benchmark image datasets. Empirical results demonstrate the effectiveness
of these four attack compositions. We implement and release a modular reusable
toolkit, COAT. Arguably, our work serves as a call for researchers and
practitioners to consider advanced adversarial settings involving multiple
attack strategies, aiming to strengthen the security and robustness of AI
systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [115] [Evaluating Generalization and Representation Stability in Small LMs via Prompting](https://arxiv.org/abs/2506.17289)
*Rahul Raja,Arpita Vats*

Main category: cs.AI

TL;DR: 本文比较了小语言模型在少样本提示和监督微调两种适应范式下的泛化能力，重点关注了它们在分布内和分布外设置中的表现差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索少样本提示和监督微调在小语言模型中的泛化能力差异，特别是在低资源设置和分布变化下的鲁棒性。

Method: 方法包括对不同任务格式、提示风格和模型规模进行比较研究，分析内部表示以评估任务特定特征的稳定性和抽象性。

Result: 研究结果揭示了小模型在不同适应策略下如何内化和泛化知识的关键差异，为低数据环境下的模型选择提供了实用指导。

Conclusion: 结论强调了提示和微调在模型适应中的不同效果，为关于这两种策略的持续辩论提供了实证见解。

Abstract: We investigate the generalization capabilities of small language models under
two popular adaptation paradigms: few-shot prompting and supervised
fine-tuning. While prompting is often favored for its parameter efficiency and
flexibility, it remains unclear how robust this approach is in low-resource
settings and under distributional shifts. This paper presents a comparative
study of prompting and fine-tuning across task formats, prompt styles, and
model scales, with a focus on their behavior in both in-distribution and
out-of-distribution (OOD) settings.
  Beyond accuracy, we analyze the internal representations learned by each
approach to assess the stability and abstraction of task-specific features. Our
findings highlight critical differences in how small models internalize and
generalize knowledge under different adaptation strategies. This work offers
practical guidance for model selection in low-data regimes and contributes
empirical insight into the ongoing debate over prompting versus fine-tuning.
Code for the experiments is available at the following

</details>


### [116] [Individual Causal Inference with Structural Causal Model](https://arxiv.org/abs/2506.17300)
*Daniel T. Chang*

Main category: cs.AI

TL;DR: 本文提出了一种基于结构因果模型（SCM）的个体因果推理（ICI）方法，通过引入indiv-operator和个体因果查询，实现了对个体干预效果的个性化估计。


<details>
  <summary>Details</summary>
Motivation: 传统因果推理方法主要基于群体，难以处理个体层面的因果效应（ICE）。由于个体数据有限且SCM本质上是群体导向的，因此需要一种能够结合个体特征的方法来进行个性化因果推理。

Method: 提出indiv(W)算子来形式化群体个性化过程，并定义个体因果查询P(Y | indiv(W), do(X), Z)来形式化ICI。利用SCM中的外生变量（U）编码个体差异，实现个体化推理。

Result: 研究表明，基于SCM的ICI是对个体可能替代情况的推理，而非非实际的个体反事实推理。这种方法能够有效估计个体干预效果。

Conclusion: 通过SCM实现的ICI属于"第三阶梯"因果推理，能够结合个体特征进行假设性干预效果的推理，为个体化决策提供了理论框架。

Abstract: Individual causal inference (ICI) uses causal inference methods to understand
and predict the effects of interventions on individuals, considering their
specific characteristics / facts. It aims to estimate individual causal effect
(ICE), which varies across individuals. Estimating ICE can be challenging due
to the limited data available for individuals, and the fact that most causal
inference methods are population-based. Structural Causal Model (SCM) is
fundamentally population-based. Therefore, causal discovery (structural
learning and parameter learning), association queries and intervention queries
are all naturally population-based. However, exogenous variables (U) in SCM can
encode individual variations and thus provide the mechanism for individualized
population per specific individual characteristics / facts. Based on this, we
propose ICI with SCM as a "rung 3" causal inference, because it involves
"imagining" what would be the causal effect of a hypothetical intervention on
an individual, given the individual's observed characteristics / facts.
Specifically, we propose the indiv-operator, indiv(W), to formalize/represent
the population individualization process, and the individual causal query, P(Y
| indiv(W), do(X), Z), to formalize/represent ICI. We show and argue that ICI
with SCM is inference on individual alternatives (possible), not individual
counterfactuals (non-actual).

</details>


### [117] [Resource Rational Contractualism Should Guide AI Alignment](https://arxiv.org/abs/2506.17434)
*Sydney Levine,Matija Franklin,Tan Zhi-Xuan,Secil Yanik Guyot,Lionel Wong,Daniel Kilov,Yejin Choi,Joshua B. Tenenbaum,Noah Goodman,Seth Lazar,Iason Gabriel*

Main category: cs.AI

TL;DR: 提出资源理性契约主义（RRC）框架，使AI系统能通过认知启发式高效模拟多方利益协议，实现动态适应人类社会环境。


<details>
  <summary>Details</summary>
Motivation: AI系统需在目标价值多元的人类环境中决策，现有契约主义方法达成大规模协议成本高、速度慢，亟需高效解决方案。

Method: 采用基于规范认知的启发式工具箱，在计算精度与资源消耗间权衡，近似模拟理性多方可能达成的协议条件。

Result: RRC框架使AI既能保持运算效率，又能动态适应并解释不断变化的人类社会规则与价值观。

Conclusion: 资源理性契约主义为AI对齐问题提供了可扩展的实践路径，通过认知启发式平衡协议质量与计算成本。

Abstract: AI systems will soon have to navigate human environments and make decisions
that affect people and other AI agents whose goals and values diverge.
Contractualist alignment proposes grounding those decisions in agreements that
diverse stakeholders would endorse under the right conditions, yet securing
such agreement at scale remains costly and slow -- even for advanced AI. We
therefore propose Resource-Rational Contractualism (RRC): a framework where AI
systems approximate the agreements rational parties would form by drawing on a
toolbox of normatively-grounded, cognitively-inspired heuristics that trade
effort for accuracy. An RRC-aligned agent would not only operate efficiently,
but also be equipped to dynamically adapt to and interpret the ever-changing
human social world.

</details>


### [118] [Keeping Medical AI Healthy: A Review of Detection and Correction Methods for System Degradation](https://arxiv.org/abs/2506.17442)
*Hao Guan,David Bates,Li Zhou*

Main category: cs.AI

TL;DR: 本文综述了医疗AI系统在长期部署中性能退化的原因、监测方法及修正策略，旨在提升AI在动态临床环境中的可靠性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 医疗AI系统在现实应用中可能因数据分布变化、患者特征改变、临床协议更新或数据质量波动导致性能下降，引发安全隐患，亟需建立持续监测与自我修正机制。

Method: 系统回顾了数据与模型层面性能退化的成因，归纳了数据漂移和模型漂移的检测技术，分析了根本原因，并总结了从模型重训练到测试时适应的修正策略。

Result: 研究覆盖传统机器学习模型和最先进的大语言模型(LLMs)，揭示了各类技术在医疗AI系统中的优势与局限性，并提出了持续监测框架的实施路径。

Conclusion: 该工作为开发可长期安全部署的医疗AI系统提供了技术指导，同时指出了动态临床环境中模型可靠性维护的未来研究方向。

Abstract: Artificial intelligence (AI) is increasingly integrated into modern
healthcare, offering powerful support for clinical decision-making. However, in
real-world settings, AI systems may experience performance degradation over
time, due to factors such as shifting data distributions, changes in patient
characteristics, evolving clinical protocols, and variations in data quality.
These factors can compromise model reliability, posing safety concerns and
increasing the likelihood of inaccurate predictions or adverse outcomes. This
review presents a forward-looking perspective on monitoring and maintaining the
"health" of AI systems in healthcare. We highlight the urgent need for
continuous performance monitoring, early degradation detection, and effective
self-correction mechanisms. The paper begins by reviewing common causes of
performance degradation at both data and model levels. We then summarize key
techniques for detecting data and model drift, followed by an in-depth look at
root cause analysis. Correction strategies are further reviewed, ranging from
model retraining to test-time adaptation. Our survey spans both traditional
machine learning models and state-of-the-art large language models (LLMs),
offering insights into their strengths and limitations. Finally, we discuss
ongoing technical challenges and propose future research directions. This work
aims to guide the development of reliable, robust medical AI systems capable of
sustaining safe, long-term deployment in dynamic clinical settings.

</details>


### [119] [OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections](https://arxiv.org/abs/2506.17449)
*Manasa Bharadwaj,Nikhil Verma,Kevin Ferreira*

Main category: cs.AI

TL;DR: 本文提出OmniReflect框架，通过构建指导原则提升LLM代理性能，在自持与合作模式下均显著提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏长期学习机制且在动态环境中效率低下，需一种通用框架来增强LLM代理的效能。

Method: 采用分层反思驱动框架，结合神经、符号及神经符号技术，构建紧凑指导原则（宪法），支持自持（单代理自我反思）与合作（元顾问指导）两种模式。

Result: 实验显示任务成功率显著提升：自持模式下ALFWorld(+10.3%)、BabyAI(+23.8%)、PDDL(+8.3%)；合作模式下轻量级Qwen3-4B代理超越所有基线。

Conclusion: OmniReflect在不同环境和模型骨干中均表现出强鲁棒性与有效性，为LLM代理学习提供了通用解决方案。

Abstract: Efforts to improve Large Language Model (LLM) agent performance on complex
tasks have largely focused on fine-tuning and iterative self-correction.
However, these approaches often lack generalizable mechanisms for longterm
learning and remain inefficient in dynamic environments. We introduce
OmniReflect, a hierarchical, reflection-driven framework that constructs a
constitution, a compact set of guiding principles distilled from task
experiences, to enhance the effectiveness and efficiency of an LLM agent.
OmniReflect operates in two modes: Self-sustaining, where a single agent
periodically curates its own reflections during task execution, and
Co-operative, where a Meta-advisor derives a constitution from a small
calibration set to guide another agent. To construct these constitutional
principles, we employ Neural, Symbolic, and NeuroSymbolic techniques, offering
a balance between contextual adaptability and computational efficiency.
Empirical results averaged across models show major improvements in task
success, with absolute gains of +10.3% on ALFWorld, +23.8% on BabyAI, and +8.3%
on PDDL in the Self-sustaining mode. Similar gains are seen in the Co-operative
mode, where a lightweight Qwen3-4B ReAct agent outperforms all Reflexion
baselines on BabyAI. These findings highlight the robustness and effectiveness
of OmniReflect across environments and backbones.

</details>


### [120] [From Unstructured Communication to Intelligent RAG: Multi-Agent Automation for Supply Chain Knowledge Bases](https://arxiv.org/abs/2506.17484)
*Yao Zhang,Zaixi Shang,Silpan Patel,Mikel Zuniga*

Main category: cs.AI

TL;DR: 本文提出了一种基于LLMs的多智能体系统，将供应链支持票据等非结构化通信转化为结构化知识库，显著提升RAG系统性能并降低运营工作量。


<details>
  <summary>Details</summary>
Motivation: 供应链运营产生大量非结构化通信数据（如支持票据、邮件等），现有RAG系统因数据噪声大、不完整而效果受限，亟需将隐性知识转化为结构化知识库。

Method: 采用离线优先方法，设计包含分类发现、票据归类、知识合成三个智能体的LLMs多智能体系统，自动构建紧凑知识库（仅为原始数据量的3.4%）。

Result: 实验表明：预建知识库使RAG系统有用回答率提升至48.74%（传统方法38.6%），无效响应减少77.4%，未来50%票据可自动解决。

Conclusion: 该方法通过离线智能处理将瞬时通信转化为可重用知识，显著提升运营效率（减少支持负载、加速问题解决），填补了知识管理领域的关键空白。

Abstract: Supply chain operations generate vast amounts of operational data; however,
critical knowledge such as system usage practices, troubleshooting workflows,
and resolution techniques often remains buried within unstructured
communications like support tickets, emails, and chat logs. While RAG systems
aim to leverage such communications as a knowledge base, their effectiveness is
limited by raw data challenges: support tickets are typically noisy,
inconsistent, and incomplete, making direct retrieval suboptimal. Unlike
existing RAG approaches that focus on runtime optimization, we introduce a
novel offline-first methodology that transforms these communications into a
structured knowledge base. Our key innovation is a LLMs-based multi-agent
system orchestrating three specialized agents: Category Discovery for taxonomy
creation, Categorization for ticket grouping, and Knowledge Synthesis for
article generation. Applying our methodology to real-world support tickets with
resolution notes and comments, our system creates a compact knowledge base -
reducing total volume to just 3.4% of original ticket data while improving
quality. Experiments demonstrate that our prebuilt knowledge base in RAG
systems significantly outperforms traditional RAG implementations (48.74% vs.
38.60% helpful answers) and achieves a 77.4% reduction in unhelpful responses.
By automating institutional knowledge capture that typically remains siloed in
experts' heads, our solution translates to substantial operational efficiency:
reducing support workload, accelerating resolution times, and creating
self-improving systems that automatically resolve approximately 50% of future
supply chain tickets. Our approach addresses a key gap in knowledge management
by transforming transient communications into structured, reusable knowledge
through intelligent offline processing rather than latency-inducing runtime
architectures.

</details>


### [121] [Kaleidoscopic Teaming in Multi Agent Simulations](https://arxiv.org/abs/2506.17514)
*Ninareh Mehrabi,Tharindu Kumarage,Kai-Wei Chang,Aram Galstyan,Rahul Gupta*

Main category: cs.AI

TL;DR: 本文提出了一种名为"万花筒式团队"的新框架，用于评估AI代理在单代理和多代理场景中的安全风险，通过生成多样化场景和引入上下文优化技术来识别漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有红队测试或安全评估框架无法充分评估AI代理在复杂行为、思维过程和交互中的安全风险，特别是在多代理设置中暴露的漏洞。

Method: 作者提出了"万花筒式团队"框架，通过生成模拟现实社会场景来评估单代理和多代理设置中的安全性，并引入上下文优化技术改进场景生成。

Result: 使用该框架识别了多种AI模型在代理用例中的安全漏洞，并提出了相应的安全度量标准。

Conclusion: 万花筒式团队框架为AI代理安全评估提供了更全面的方法，能够发现传统方法无法检测到的复杂交互漏洞。

Abstract: Warning: This paper contains content that may be inappropriate or offensive.
  AI agents have gained significant recent attention due to their autonomous
tool usage capabilities and their integration in various real-world
applications. This autonomy poses novel challenges for the safety of such
systems, both in single- and multi-agent scenarios. We argue that existing red
teaming or safety evaluation frameworks fall short in evaluating safety risks
in complex behaviors, thought processes and actions taken by agents. Moreover,
they fail to consider risks in multi-agent setups where various vulnerabilities
can be exposed when agents engage in complex behaviors and interactions with
each other. To address this shortcoming, we introduce the term kaleidoscopic
teaming which seeks to capture complex and wide range of vulnerabilities that
can happen in agents both in single-agent and multi-agent scenarios. We also
present a new kaleidoscopic teaming framework that generates a diverse array of
scenarios modeling real-world human societies. Our framework evaluates safety
of agents in both single-agent and multi-agent setups. In single-agent setup,
an agent is given a scenario that it needs to complete using the tools it has
access to. In multi-agent setup, multiple agents either compete against or
cooperate together to complete a task in the scenario through which we capture
existing safety vulnerabilities in agents. We introduce new in-context
optimization techniques that can be used in our kaleidoscopic teaming framework
to generate better scenarios for safety analysis. Lastly, we present
appropriate metrics that can be used along with our framework to measure safety
of agents. Utilizing our kaleidoscopic teaming framework, we identify
vulnerabilities in various models with respect to their safety in agentic
use-cases.

</details>


### [122] [Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models](https://arxiv.org/abs/2506.17585)
*Yukun Huang,Sanxing Chen,Jian Pei,Manzil Zaheer,Bhuwan Dhingra*

Main category: cs.AI

TL;DR: 本文探讨如何让语言模型在持续预训练中可靠地引用文档，提出主动索引方法，显著提升引用精度。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型的引用不可靠，依赖外部检索器会引入延迟和噪声，需探索无需推理时检索的可靠引用方法。

Method: 采用两阶段方法：1) 持续预训练将事实与文档标识绑定；2) 指令微调引导引用行为。提出主动索引，通过合成QA对增强训练。

Result: 主动索引在Qwen2.5-7B和3B上全面优于被动索引，引用精度最高提升30.2%，且性能随数据量增加持续提升。

Conclusion: 主动索引能有效提升模型引用可靠性，数据扩增带来持续性能改进，为可信语言模型提供新方向。

Abstract: Trustworthy language models should provide both correct and verifiable
answers. While language models can sometimes attribute their outputs to
pretraining data, their citations are often unreliable due to hallucination. As
a result, current systems insert citations by querying an external retriever at
inference time, introducing latency, infrastructure dependence, and
vulnerability to retrieval noise. We explore whether LLMs can be made to
reliably attribute to the documents seen during (continual)
pretraining--without test-time retrieval--by revising the training process. To
evaluate this, we release CitePretrainBench, a benchmark that mixes real-world
corpora (Wikipedia, Common Crawl, arXiv) with novel, unseen documents and
probes both short-form (single fact) and long-form (multi-fact) citation tasks.
Our approach follows a two-stage process: (1) continual pretraining to bind
facts to persistent document identifiers, and (2) instruction tuning to elicit
citation behavior. We find that simple Passive Indexing, which appends an
identifier to each document, helps memorize verbatim text but fails on
paraphrased or compositional facts. Instead, we propose Active Indexing, which
continually pretrains on synthetic QA pairs that (1) restate each fact in
diverse compositional forms, and (2) require bidirectional source-to-fact and
fact-to-source generation, jointly teaching the model to generate content from
a cited source and to attribute its own answers. Experiments with Qwen2.5-7B
and 3B show that Active Indexing consistently outperforms Passive Indexing
across all tasks and models, with citation precision gains up to 30.2 percent.
Our ablation studies reveal that performance continues to improve as we scale
the amount of augmented data, showing a clear upward trend even at 16 times the
original token count.

</details>


### [123] [Taming the Untamed: Graph-Based Knowledge Retrieval and Reasoning for MLLMs to Conquer the Unknown](https://arxiv.org/abs/2506.17589)
*Bowen Wang*

Main category: cs.AI

TL;DR: 本文通过构建多模态知识图谱(MH-MMKG)并提出多智能体检索器，显著提升了多模态大语言模型(MLLMs)在特定领域任务中的表现，为多模态知识增强推理提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在罕见领域任务中表现不佳，主要受限于相关知识的缺乏。研究旨在探索如何有效利用多模态知识提升模型性能。

Method: 以视觉游戏认知为测试平台，构建《怪物猎人：世界》多模态知识图谱(MH-MMKG)，设计复杂查询任务，并提出无需额外训练的多智能体检索器实现自主知识搜索。

Result: 实验结果表明，该方法显著提高了MLLMs在复杂知识检索与推理任务中的表现，准确率提升明显。

Conclusion: 研究为多模态知识增强推理提供了可行方案，建立的MH-MMKG数据集为未来研究奠定了坚实基础，展示了自主知识检索在提升模型领域适应性方面的潜力。

Abstract: The real value of knowledge lies not just in its accumulation, but in its
potential to be harnessed effectively to conquer the unknown. Although recent
multimodal large language models (MLLMs) exhibit impressing multimodal
capabilities, they often fail in rarely encountered domain-specific tasks due
to limited relevant knowledge. To explore this, we adopt visual game cognition
as a testbed and select Monster Hunter: World as the target to construct a
multimodal knowledge graph (MH-MMKG), which incorporates multi-modalities and
intricate entity relations. We also design a series of challenging queries
based on MH-MMKG to evaluate the models' ability for complex knowledge
retrieval and reasoning. Furthermore, we propose a multi-agent retriever that
enables a model to autonomously search relevant knowledge without additional
training. Experimental results show that our approach significantly enhances
the performance of MLLMs, providing a new perspective on multimodal
knowledge-augmented reasoning and laying a solid foundation for future
research.

</details>


### [124] [Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges](https://arxiv.org/abs/2506.17644)
*Zimo Ji,Daoyuan Wu,Wenyuan Jiang,Pingchuan Ma,Zongjie Li,Shuai Wang*

Main category: cs.AI

TL;DR: 本文提出CTFKnow基准测试评估大模型在CTF竞赛中的知识应用能力，并开发CTFAgent框架通过两阶段RAG和环境增强显著提升性能，在picoCTF2024中进入前23.6%名次。


<details>
  <summary>Details</summary>
Motivation: 随着大模型发展，自动化解决CTF挑战的需求增长，但现有模型在知识应用和策略调整上存在不足，需建立专门评估体系并提升实战能力。

Method: 构建含3,992个问题的CTFKnow基准测试；提出CTFAgent框架，创新性引入两阶段检索增强生成（RAG）和交互式环境增强模块。

Result: CTFAgent在两个主流CTF数据集上实现80%以上性能提升，在picoCTF2024竞赛中位列前23.6%（近7000支队伍）。

Conclusion: 研究表明大模型虽具备技术知识储备，但场景化应用能力不足；CTFAgent框架通过知识增强和动态环境交互有效提升了CTF解题能力。

Abstract: Capture-the-Flag (CTF) competitions are crucial for cybersecurity education
and training. As large language models (LLMs) evolve, there is increasing
interest in their ability to automate CTF challenge solving. For example, DARPA
has organized the AIxCC competition since 2023 to advance AI-powered automated
offense and defense. However, this demands a combination of multiple abilities,
from knowledge to reasoning and further to actions. In this paper, we highlight
the importance of technical knowledge in solving CTF problems and deliberately
construct a focused benchmark, CTFKnow, with 3,992 questions to measure LLMs'
performance in this core aspect. Our study offers a focused and innovative
measurement of LLMs' capability in understanding CTF knowledge and applying it
to solve CTF challenges. Our key findings reveal that while LLMs possess
substantial technical knowledge, they falter in accurately applying this
knowledge to specific scenarios and adapting their strategies based on feedback
from the CTF environment.
  Based on insights derived from this measurement study, we propose CTFAgent, a
novel LLM-driven framework for advancing CTF problem-solving. CTFAgent
introduces two new modules: two-stage Retrieval Augmented Generation (RAG) and
interactive Environmental Augmentation, which enhance LLMs' technical knowledge
and vulnerability exploitation on CTF, respectively. Our experimental results
show that, on two popular CTF datasets, CTFAgent both achieves over 80%
performance improvement. Moreover, in the recent picoCTF2024 hosted by CMU,
CTFAgent ranked in the top 23.6% of nearly 7,000 participating teams. This
reflects the benefit of our measurement study and the potential of our
framework in advancing LLMs' capabilities in CTF problem-solving.

</details>


### [125] [PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models](https://arxiv.org/abs/2506.17667)
*Lintao Wang,Encheng Su,Jiaqi Liu,Pengze Li,Peng Xia,Jiabei Xiao,Wenlong Zhang,Xinnan Dai,Xi Chen,Yuan Meng,Mingyu Ding,Lei Bai,Wanli Ouyang,Shixiang Tang,Aoran Wang,Xinzhu Ma*

Main category: cs.AI

TL;DR: PhysUniBench是一个针对多模态大语言模型（MLLMs）设计的大规模多模态基准测试，旨在评估和改进其在本科物理问题上的推理能力。该基准包含3,304个问题，覆盖8个物理子学科，并包含视觉图表。实验显示当前最先进模型在物理推理上表现不佳，如GPT-4o mini准确率仅为34.2%。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型在物理问题解决上存在挑战，现有评估方法无法全面捕捉本科物理的广度和复杂性，因此需要更严格的评估工具来推动AI在科学领域的发展。

Method: PhysUniBench通过多阶段构建过程，包括多次发布、专家评估、自动过滤易解决问题以及五级难度分级系统，系统性地收集和难度评级了3,304个物理问题，每个问题配有视觉图表，包含开放式和选择题。

Result: 实验结果表明，当前最先进的MLLMs在物理推理上遇到显著困难，例如GPT-4o mini在PhysUniBench上的准确率仅为34.2%，尤其是在多步骤问题和需要精确图表解释的问题上表现不佳。

Conclusion: PhysUniBench作为一个广泛而严格的评估工具，旨在推动AI在科学领域的进步，鼓励开发具有更强物理推理、问题解决能力和多模态理解的模型。基准测试和评估脚本已公开提供。

Abstract: Physics problem-solving is a challenging domain for large AI models,
requiring integration of conceptual understanding, mathematical reasoning, and
interpretation of physical diagrams. Current evaluation methodologies show
notable limitations in capturing the breadth and complexity of
undergraduate-level physics, underscoring the need for more rigorous
assessments. To this end, we present PhysUniBench, a large-scale multimodal
benchmark designed to evaluate and improve the reasoning capabilities of
multimodal large language models (MLLMs) specifically on undergraduate-level
physics problems. PhysUniBench consists of 3,304 physics questions spanning 8
major sub-disciplines of physics, each accompanied by one visual diagrams. The
benchmark includes both open-ended and multiple-choice questions,
systematically curated and difficulty-rated through an iterative
model-in-the-loop process. The benchmark's construction involved a rigorous
multi-stage process, including multiple roll-outs, expert-level evaluation,
automated filtering of easily solved problems, and a nuanced difficulty grading
system with five levels. Through extensive experiments, we observe that current
state-of-the-art models encounter substantial challenges in physics reasoning.
For example, GPT-4o mini achieves only about 34.2\% accuracy in the proposed
PhysUniBench. These results highlight that current MLLMs struggle with advanced
physics reasoning, especially on multi-step problems and those requiring
precise diagram interpretation. By providing a broad and rigorous assessment
tool, PhysUniBench aims to drive progress in AI for Science, encouraging the
development of models with stronger physical reasoning, problem-solving skills,
and multimodal understanding. The benchmark and evaluation scripts are
available at https://prismax-team.github.io/PhysUniBenchmark/.

</details>


### [126] [Beyond Syntax: Action Semantics Learning for App Agents](https://arxiv.org/abs/2506.17697)
*Bohan Tang,Dezhao Luo,Jingxuan Chen,Shaogang Gong,Jianye Hao,Jun Wang,Kun Shao*

Main category: cs.AI

TL;DR: 本文提出了一种名为动作语义学习（ASL）的新框架，通过捕捉用户界面中动作的语义而非语法形式，显著提升了App代理的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的解决方案依赖昂贵的闭源LLM API，而微调小型开源LLM时，传统的语法学习范式易受分布外（OOD）问题影响，导致性能下降。

Method: ASL框架引入语义评估器（SEE），通过计算语义奖励来训练App代理，使其生成与真实动作语义一致的行为，即使语法形式不同。该方法从编程语言理论中汲取灵感，将动作语义定义为用户界面中的状态转换。

Result: 在离线和在线智能手机App操作基准测试中，ASL显著优于现有方法，证明了其在OOD问题上的更强鲁棒性。

Conclusion: ASL通过语义学习范式有效解决了传统语法学习的局限性，为App代理的准确性和泛化性能提供了理论保障和实证支持。

Abstract: The advent of Large Language Models (LLMs) enables the rise of App agents
that interpret user intent and operate smartphone Apps through actions such as
clicking and scrolling. While prompt-based solutions with closed LLM APIs show
promising ability, they incur heavy compute costs and external API dependency.
Fine-tuning smaller open-source LLMs solves these limitations. However, current
fine-tuning methods use a syntax learning paradigm that forces agents to
reproduce exactly the ground truth action strings, leading to
out-of-distribution (OOD) vulnerability. To fill this gap, we propose Action
Semantics Learning (ASL), a novel learning framework, where the learning
objective is capturing the semantics of the ground truth actions. Specifically,
inspired by the programming language theory, we define the action semantics for
App agents as the state transition induced by the action in the user interface.
With this insight, ASL employs a novel SEmantic Estimator (SEE) to compute a
semantic reward to train the App agents in generating actions aligned with the
semantics of ground truth actions, even when the syntactic forms differ. To
support the effectiveness of ASL, we theoretically demonstrate the superior
robustness of ASL for the OOD problem compared with the existing syntax
learning paradigm. Extensive experiments on offline and online smartphone App
operation benchmarks show that ASL significantly improves the accuracy and
generalisation of App agents over existing methods.

</details>


### [127] [AnyMAC: Cascading Flexible Multi-Agent Collaboration via Next-Agent Prediction](https://arxiv.org/abs/2506.17784)
*Song Wang,Zhen Tan,Zihan Chen,Shuang Zhou,Tianlong Chen,Jundong Li*

Main category: cs.AI

TL;DR: 本文提出了一种基于顺序结构的新型多智能体协作框架，通过动态角色选择和上下文筛选实现高效通信，显著提升了性能并降低了通信开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于图结构的智能体通信拓扑缺乏适应性，限制了集体智能的潜力。需要更灵活的通信机制来优化多智能体协作效率。

Method: 采用顺序通信结构：1) 下一步智能体预测动态选择最优角色；2) 下一上下文选择机制(NCS)实现历史信息精准筛选，构建任务自适应的通信管道。

Result: 在多个基准测试中，该方法在保持性能优势的同时显著减少了通信开销，验证了顺序通信结构的有效性。

Conclusion: 顺序通信框架通过角色灵活性与全局信息流的结合，为多智能体系统提供了更优的协作范式，推动了集体智能的发展。

Abstract: Recent progress in large language model (LLM)-based multi-agent collaboration
highlights the power of structured communication in enabling collective
intelligence. However, existing methods largely rely on static or graph-based
inter-agent topologies, lacking the potential adaptability and flexibility in
communication. In this work, we propose a new framework that rethinks
multi-agent coordination through a sequential structure rather than a graph
structure, offering a significantly larger topology space for multi-agent
communication. Our method focuses on two key directions: (1) Next-Agent
Prediction, which selects the most suitable agent role at each step, and (2)
Next-Context Selection (NCS), which enables each agent to selectively access
relevant information from any previous step. Together, these components
construct task-adaptive communication pipelines that support both role
flexibility and global information flow. Extensive evaluations across multiple
benchmarks demonstrate that our approach achieves superior performance while
substantially reducing communication overhead.

</details>


### [128] [Bayesian Social Deduction with Graph-Informed Language Models](https://arxiv.org/abs/2506.17788)
*Shahab Rahimirad,Guven Gergerli,Lucia Romero,Angela Qian,Matthew Lyle Olson,Simon Stepputtis,Joseph Campbell*

Main category: cs.AI

TL;DR: 本文评估了大语言模型（LLMs）在社交推理游戏Avalon中的表现，发现大模型虽强但计算成本高，小模型性能骤降。作者提出混合推理框架，结合结构化概率模型与LLM，在Agent-Agent对抗中表现优异，并首次在受控实验中击败人类玩家（67%胜率）。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在社交推理（从部分观察推断他人信念与意图）任务中仍面临挑战，尤其在实时场景下小模型性能显著下降。研究旨在突破这一限制。

Method: 提出混合推理框架：将信念推断外化至结构化概率模型，同时利用LLM处理语言理解与交互。该方法在Avalon游戏中实现高效社交推理。

Result: 混合框架在Agent-Agent对抗中媲美更大模型，并以67%胜率首次击败人类玩家，定性评分高于基线模型及人类队友。开源代码、模型及数据集。

Conclusion: 通过分离信念推断与语言处理，混合框架显著提升LLM社交推理效率，为实时应用提供可行方案。成果发布于https://camp-lab-purdue.github.io/bayesian-social-deduction/。

Abstract: Social reasoning - inferring unobservable beliefs and intentions from partial
observations of other agents - remains a challenging task for large language
models (LLMs). We evaluate the limits of current reasoning language models in
the social deduction game Avalon and find that while the largest models
demonstrate strong performance, they require extensive test-time inference and
degrade sharply when distilled to smaller, real-time-capable variants. To
address this, we introduce a hybrid reasoning framework that externalizes
belief inference to a structured probabilistic model, while using an LLM for
language understanding and interaction. Our approach achieves competitive
performance with much larger models in Agent-Agent play and, notably, is the
first language agent to defeat human players in a controlled study - achieving
a 67% win rate and receiving higher qualitative ratings than both reasoning
baselines and human teammates. We release code, models, and a dataset to
support future work on social reasoning in LLM agents, which can be found at
https://camp-lab-purdue.github.io/bayesian-social-deduction/

</details>


### [129] [Efficient Strategy Synthesis for MDPs via Hierarchical Block Decomposition](https://arxiv.org/abs/2506.17792)
*Alexandros Evangelidis,Gricel Vázquez,Simos Gerasimou*

Main category: cs.AI

TL;DR: 本文提出了一种动态优化马尔可夫决策过程(MDP)的方法，通过迭代选择最脆弱区域进行细化，显著提升大规模MDP策略合成的效率，相比PRISM工具性能提升可达2倍。


<details>
  <summary>Details</summary>
Motivation: 传统策略合成方法在处理大规模状态空间时效率不足，难以应对软件产品线、机器人等复杂系统中的不确定性决策问题。

Method: 采用动态细化MDP的迭代方法，仅对必要的最脆弱区域进行细化，在精度与效率之间取得平衡。

Result: 在包含百万级状态的多样化案例研究中，本方法相较主流概率模型检测工具PRISM实现最高2倍的性能提升。

Conclusion: 该动态细化方法为大规模MDP的实际策略合成任务提供了高效解决方案，在保持精度的同时显著提升计算效率。

Abstract: Software-intensive systems, such as software product lines and robotics,
utilise Markov decision processes (MDPs) to capture uncertainty and analyse
sequential decision-making problems. Despite the usefulness of conventional
policy synthesis methods, they fail to scale to large state spaces. Our
approach addresses this issue and accelerates policy synthesis in large MDPs by
dynamically refining the MDP and iteratively selecting the most fragile MDP
regions for refinement. This iterative procedure offers a balance between
accuracy and efficiency, as refinement occurs only when necessary. Through a
comprehensive empirical evaluation comprising diverse case studies and MDPs up
to 1M states, we demonstrate significant performance improvements yielded by
our approach compared to the leading probabilistic model checker PRISM (up to
2x), thus offering a very competitive solution for real-world policy synthesis
tasks in larger MDPs.

</details>


### [130] [Reflective Verbal Reward Design for Pluralistic Alignment](https://arxiv.org/abs/2506.17834)
*Carter Blair,Kate Larson,Edith Law*

Main category: cs.AI

TL;DR: 本文提出了一种个性化奖励建模方法，通过反思对话构建个体化奖励函数，解决了传统RLHF方法因聚合人类反馈而压制少数偏好的问题。实验显示该方法比非反思模型准确率提升9-12%，且样本效率更高。


<details>
  <summary>Details</summary>
Motivation: 传统RLHF方法将人类反馈聚合为单一奖励模型，但人类价值观具有异质性，这种聚合可能导致少数群体偏好被压制。需要开发能保留个体差异的奖励建模方法。

Method: 使用语言模型引导用户进行反思对话，记录包含用户批评和偏好的对话历史，将其作为上下文构建个体化语言模型奖励函数（称为"语言奖励模型"）。

Result: 在30名参与者的实验中，该方法比非反思语言奖励模型准确率提高9-12%，且比传统监督学习方法更具样本效率。

Conclusion: 基于反思对话的个体化奖励建模能更准确地捕捉多元人类价值观，为AI对齐提供了尊重价值多样性的新途径。

Abstract: AI agents are commonly aligned with "human values" through reinforcement
learning from human feedback (RLHF), where a single reward model is learned
from aggregated human feedback and used to align an agent's behavior. However,
human values are not homogeneous--different people hold distinct and sometimes
conflicting values. Aggregating feedback into a single reward model risks
disproportionately suppressing minority preferences. To address this, we
present a novel reward modeling approach for learning individualized reward
models. Our approach uses a language model to guide users through reflective
dialogues where they critique agent behavior and construct their preferences.
This personalized dialogue history, containing the user's reflections and
critiqued examples, is then used as context for another language model that
serves as an individualized reward function (what we call a "verbal reward
model") for evaluating new trajectories. In studies with 30 participants, our
method achieved a 9-12% improvement in accuracy over non-reflective verbal
reward models while being more sample efficient than traditional supervised
learning methods.

</details>


### [131] [Out of Control -- Why Alignment Needs Formal Control Theory (and an Alignment Control Stack)](https://arxiv.org/abs/2506.17846)
*Elija Perrier*

Main category: cs.AI

TL;DR: 本文主张将形式最优控制理论作为AI对齐研究的核心，提出通过分层控制栈（Alignment Control Stack）实现跨层级协议互操作性，以弥补现有AI安全方法在泛化性上的不足，并为政府监管提供理论依据。


<details>
  <summary>Details</summary>
Motivation: 当前AI安全与可解释性研究缺乏通用控制框架的泛化能力，且未解决不同对齐协议间的互操作性问题。本文旨在通过最优控制理论构建分层对齐框架，以增强对前沿AI系统的可控性理解。

Method: 提出'对齐控制栈'（Alignment Control Stack）分层模型，从物理层到社会技术层逐级定义测量与控制特性，并形式化各层级的互操作性。

Result: 构建了基于最优控制理论的分层对齐框架，明确了各层级的控制指标与跨层协调机制，为AI系统的安全部署提供可验证的理论基础。

Conclusion: 将最优控制理论与实际部署需求结合，可创建更全面的AI对齐框架，提升高级AI系统的安全性与可靠性，同时满足政府监管的合规性要求。

Abstract: This position paper argues that formal optimal control theory should be
central to AI alignment research, offering a distinct perspective from
prevailing AI safety and security approaches. While recent work in AI safety
and mechanistic interpretability has advanced formal methods for alignment,
they often fall short of the generalisation required of control frameworks for
other technologies. There is also a lack of research into how to render
different alignment/control protocols interoperable. We argue that by recasting
alignment through principles of formal optimal control and framing alignment in
terms of hierarchical stack from physical to socio-technical layers according
to which controls may be applied we can develop a better understanding of the
potential and limitations for controlling frontier models and agentic AI
systems. To this end, we introduce an Alignment Control Stack which sets out a
hierarchical layered alignment stack, identifying measurement and control
characteristics at each layer and how different layers are formally
interoperable. We argue that such analysis is also key to the assurances that
will be needed by governments and regulators in order to see AI technologies
sustainably benefit the community. Our position is that doing so will bridge
the well-established and empirically validated methods of optimal control with
practical deployment considerations to create a more comprehensive alignment
framework, enhancing how we approach safety and reliability for advanced AI
systems.

</details>


### [132] [Towards Robust Fact-Checking: A Multi-Agent System with Advanced Evidence Retrieval](https://arxiv.org/abs/2506.17878)
*Tam Trinh,Manh Nguyen,Truong-Son Hy*

Main category: cs.AI

TL;DR: 本文提出了一种新型多智能体系统，用于自动化事实核查，通过分解复杂声明、检索可靠证据并生成透明解释，显著提升了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 数字时代错误信息的快速传播对公共讨论构成挑战，传统人工核查难以应对海量在线内容，现有自动化方法在复杂声明处理、来源可信度和透明度方面存在局限。

Method: 系统包含四个专用智能体：输入解析智能体分解声明，查询生成智能体构建子查询，证据检索智能体获取可信证据，判定预测智能体综合真实性判断并生成可解释说明。

Result: 在FEVEROUS、HOVER和SciFact基准数据集上，该系统宏F1分数比基线方法提高12.3%，能有效分解复杂声明并从可信来源检索证据。

Conclusion: 该研究为自动化事实核查领域提供了更准确、高效且透明的验证方法，既符合人工核查实践，又具备现实应用的扩展性。

Abstract: The rapid spread of misinformation in the digital era poses significant
challenges to public discourse, necessitating robust and scalable fact-checking
solutions. Traditional human-led fact-checking methods, while credible,
struggle with the volume and velocity of online content, prompting the
integration of automated systems powered by Large Language Models (LLMs).
However, existing automated approaches often face limitations, such as handling
complex claims, ensuring source credibility, and maintaining transparency. This
paper proposes a novel multi-agent system for automated fact-checking that
enhances accuracy, efficiency, and explainability. The system comprises four
specialized agents: an Input Ingestion Agent for claim decomposition, a Query
Generation Agent for formulating targeted subqueries, an Evidence Retrieval
Agent for sourcing credible evidence, and a Verdict Prediction Agent for
synthesizing veracity judgments with human-interpretable explanations.
Evaluated on benchmark datasets (FEVEROUS, HOVER, SciFact), the proposed system
achieves a 12.3% improvement in Macro F1-score over baseline methods. The
system effectively decomposes complex claims, retrieves reliable evidence from
trusted sources, and generates transparent explanations for verification
decisions. Our approach contributes to the growing field of automated
fact-checking by providing a more accurate, efficient, and transparent
verification methodology that aligns with human fact-checking practices while
maintaining scalability for real-world applications. Our source code is
available at https://github.com/HySonLab/FactAgent

</details>


### [133] [Leveraging Large Language Model for Intelligent Log Processing and Autonomous Debugging in Cloud AI Platforms](https://arxiv.org/abs/2506.17900)
*Cheng Ji,Huaiying Luo*

Main category: cs.AI

TL;DR: 本文提出基于大语言模型(LLM)的智能日志处理与自动调试框架LLM-ID，通过多阶段语义推理和强化学习策略，显著提升云平台故障定位准确率16.2%。


<details>
  <summary>Details</summary>
Motivation: 云平台AI系统日志具有海量、非结构化、语义模糊等特性，传统方法难以实现高效故障定位与自修复，亟需智能化的日志分析解决方案。

Method: 1. 动态结构化系统日志并提取事件模板\n2. 微调LLM结合多轮注意力机制进行上下文推理\n3. 引入强化学习驱动的策略引导恢复规划器\n4. 构建端到端的故障链自动重建框架

Result: 在云平台日志数据集上的实验表明，LLM-ID将故障定位准确率提升16.2%，显著优于主流方法，且具备持续学习与异构环境适应能力。

Conclusion: LLM-ID框架通过语义理解与动态决策的深度融合，为云系统智能运维提供了具有强泛化性的新范式，其多阶段推理机制可扩展至其他复杂系统诊断场景。

Abstract: With the increasing complexity and rapid expansion of the scale of AI systems
in cloud platforms, the log data generated during system operation is massive,
unstructured, and semantically ambiguous, which brings great challenges to
fault location and system self-repair. In order to solve this problem, this
paper proposes an intelligent log processing and automatic debugging framework
based on Large Language Model (LLM), named Intelligent Debugger (LLM-ID). This
method is extended on the basis of the existing pre-trained Transformer model,
and integrates a multi-stage semantic inference mechanism to realize the
context understanding of system logs and the automatic reconstruction of fault
chains. Firstly, the system log is dynamically structured, and the unsupervised
clustering and embedding mechanism is used to extract the event template and
semantic schema. Subsequently, the fine-tuned LLM combined with the multi-round
attention mechanism to perform contextual reasoning on the log sequence to
generate potential fault assumptions and root cause paths. Furthermore, this
paper introduces a reinforcement learning-based policy-guided recovery planner,
which is driven by the remediation strategy generated by LLM to support dynamic
decision-making and adaptive debugging in the cloud environment. Compared with
the existing rule engine or traditional log analysis system, the proposed model
has stronger semantic understanding ability, continuous learning ability and
heterogeneous environment adaptability. Experiments on the cloud platform log
dataset show that LLM-ID improves the fault location accuracy by 16.2%, which
is significantly better than the current mainstream methods

</details>


### [134] [Learning, Reasoning, Refinement: A Framework for Kahneman's Dual-System Intelligence in GUI Agents](https://arxiv.org/abs/2506.17913)
*Jinjie Wei,Jiyao Liu,Lihao Liu,Ming Hu,Junzhi Ning,Mingcheng Li,Weijie Yin,Junjun He,Xiao Liang,Chao Feng,Dingkang Yang*

Main category: cs.AI

TL;DR: 本文提出CogniGUI框架，通过结合快速视觉语义分析和相对奖励策略优化，实现类人自适应学习的GUI自动化，并在新基准ScreenSeek上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理系统依赖试错决策且评估指标过于简单，无法反映真实交互复杂性，亟需支持渐进式学习和适应能力的解决方案。

Method: 基于双过程理论构建：1)全解析引擎进行GUI元素层级解析；2)GRPO代理通过相对奖励评估多路径，形成"探索-学习-掌握"循环。

Result: CogniGUI在现有基准和新提出的ScreenSeek基准（含跨应用导航、动态状态转换等挑战）上均优于最先进方法。

Conclusion: 该认知框架通过双系统设计实现持续策略优化，ScreenSeek基准为评估代理泛化能力提供了更全面的测试标准。

Abstract: Graphical User Interface (GUI) agents have made significant progress in
automating digital tasks through the utilization of computer vision and
language models. Nevertheless, existing agent systems encounter notable
limitations. Firstly, they predominantly depend on trial and error decision
making rather than progressive reasoning, thereby lacking the capability to
learn and adapt from interactive encounters. Secondly, these systems are
assessed using overly simplistic single step accuracy metrics, which do not
adequately reflect the intricate nature of real world GUI interactions. In this
paper, we present CogniGUI, a cognitive framework developed to overcome these
limitations by enabling adaptive learning for GUI automation resembling
human-like behavior. Inspired by Kahneman's Dual Process Theory, our approach
combines two main components: (1) an omni parser engine that conducts immediate
hierarchical parsing of GUI elements through quick visual semantic analysis to
identify actionable components, and (2) a Group based Relative Policy
Optimization (GRPO) grounding agent that assesses multiple interaction paths
using a unique relative reward system, promoting minimal and efficient
operational routes. This dual-system design facilitates iterative ''exploration
learning mastery'' cycles, enabling the agent to enhance its strategies over
time based on accumulated experience. Moreover, to assess the generalization
and adaptability of agent systems, we introduce ScreenSeek, a comprehensive
benchmark that includes multi application navigation, dynamic state
transitions, and cross interface coherence, which are often overlooked
challenges in current benchmarks. Experimental results demonstrate that
CogniGUI surpasses state-of-the-art methods in both the current GUI grounding
benchmarks and our newly proposed benchmark.

</details>


### [135] [Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective](https://arxiv.org/abs/2506.17930)
*Jianyu Wang,Zhiqiang Hu,Lidong Bing*

Main category: cs.AI

TL;DR: 提出PromptQuine框架，通过进化搜索自动优化提示剪枝策略，证明看似无意义的"乱码"提示能超越传统方法提升大语言模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统提示设计依赖精心构造的指令和示例，但研究发现随机剪枝生成的"乱码"提示反而能显著提升模型表现，这挑战了现有认知并需要自动化优化方法。

Method: 开发自发现提示优化框架PromptQuine，采用进化搜索在低数据量下自动探索有效的token剪枝策略，模仿自然界资源约束下的自组织现象。

Result: 该方法在分类、多选题、生成和数学推理等任务中稳定超越现有自动提示优化技术，且不受模型对齐影响，同时保持较高运行效率。

Conclusion: 研究为上下文学习机制研究提供新方向，呼吁开发更开放式的搜索算法以探索更高效的大语言模型提示方法。

Abstract: We propose a novel prompt design paradigm that challenges conventional wisdom
in large language model (LLM) prompting. While conventional wisdom prioritizes
well-crafted instructions and demonstrations for in-context learning (ICL), we
show that pruning random demonstrations into seemingly incoherent "gibberish"
can remarkably improve performance across diverse tasks. Notably, the
"gibberish" always matches or surpasses state-of-the-art automatic prompt
optimization techniques, achieving substantial gains regardless of LLM
alignment. Nevertheless, discovering an effective pruning strategy is
non-trivial, as existing attribution methods and prompt compression algorithms
fail to deliver robust results, let alone human intuition. In terms of this, we
propose a self-discover prompt optimization framework, PromptQuine, an
evolutionary search framework that automatically searches for the pruning
strategy by itself using only low-data regimes. Much like the emergent
complexity in nature--such as symbiosis and self-organization--arising in
response to resource constraints, our framework evolves and refines
unconventional yet highly effective prompts by leveraging only the tokens
present within the context. We demonstrate its effectiveness across
classification, multi-choice question answering, generation and math reasoning
tasks across LLMs, while achieving decent runtime efficiency. We hope our
findings can guide mechanistic studies on in-context learning, and provide a
call to action, to pave the way for more open-ended search algorithms for more
effective LLM prompting.

</details>


### [136] [medicX-KG: A Knowledge Graph for Pharmacists' Drug Information Needs](https://arxiv.org/abs/2506.17959)
*Lizzy Farrugia,Lilian M. Azzopardi,Jeremy Debattista,Charlie Abela*

Main category: cs.AI

TL;DR: 本文介绍了medicX-KG，一个面向药剂师的知识图谱，用于支持临床和监管决策，整合了多源药物数据，并通过人工智能和语义技术提升药学服务质量。


<details>
  <summary>Details</summary>
Motivation: 药剂师角色正从药品调配转向提供综合药学服务，需要准确、最新的药物信息支持。现有药物信息来源分散，缺乏统一的国家级药物库，medicX-KG旨在解决这一问题。

Method: medicX-KG整合了英国国家处方集(BNF)、DrugBank和马耳他药品管理局(MMA)的数据，采用知识图谱技术构建语义层，包括数据提取、本体设计和语义映射。设计过程中还采访了执业药剂师以确保实用性。

Result: 评估表明，medicX-KG能有效支持关于药物可用性、相互作用、不良反应和治疗类别的查询。但仍存在局限性，如缺少详细的剂量编码和实时更新功能。

Conclusion: medicX-KG为药剂师提供了一个统一的药物信息平台，支持数据驱动的决策。未来需进一步完善剂量编码和实时更新功能，以提升系统的全面性和时效性。

Abstract: The role of pharmacists is evolving from medicine dispensing to delivering
comprehensive pharmaceutical services within multidisciplinary healthcare
teams. Central to this shift is access to accurate, up-to-date medicinal
product information supported by robust data integration. Leveraging artificial
intelligence and semantic technologies, Knowledge Graphs (KGs) uncover hidden
relationships and enable data-driven decision-making. This paper presents
medicX-KG, a pharmacist-oriented knowledge graph supporting clinical and
regulatory decisions. It forms the semantic layer of the broader medicX
platform, powering predictive and explainable pharmacy services. medicX-KG
integrates data from three sources, including, the British National Formulary
(BNF), DrugBank, and the Malta Medicines Authority (MMA) that addresses Malta's
regulatory landscape and combines European Medicines Agency alignment with
partial UK supply dependence. The KG tackles the absence of a unified national
drug repository, reducing pharmacists' reliance on fragmented sources. Its
design was informed by interviews with practicing pharmacists to ensure
real-world applicability. We detail the KG's construction, including data
extraction, ontology design, and semantic mapping. Evaluation demonstrates that
medicX-KG effectively supports queries about drug availability, interactions,
adverse reactions, and therapeutic classes. Limitations, including missing
detailed dosage encoding and real-time updates, are discussed alongside
directions for future enhancements.

</details>


### [137] [Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities](https://arxiv.org/abs/2506.18019)
*Yuanchen Bei,Weizhi Zhang,Siwen Wang,Weizhi Chen,Sheng Zhou,Hao Chen,Yong Li,Jiajun Bu,Shirui Pan,Yizhou Yu,Irwin King,Fakhri Karray,Philip S. Yu*

Main category: cs.AI

TL;DR: 本文综述了图技术如何赋能AI智能体，探讨了图技术与智能体核心功能的结合、显著应用及未来研究方向，旨在推动下一代AI智能体的发展。


<details>
  <summary>Details</summary>
Motivation: 随着AI智能体从强化学习主导转向大语言模型驱动，再到两者融合，其能力不断增强。然而，完成复杂现实任务需要智能体有效规划执行、可靠记忆及多智能体协调，面对庞杂信息与交互，数据结构化成为关键挑战。

Method: 通过将复杂无序数据转化为结构化形式（尤其是利用图在组织与管理数据关系上的天然优势），系统回顾图技术如何增强AI智能体，包括功能整合、应用案例及未来方向。

Result: 图技术为AI智能体提供了强大的数据结构化支持，使其能更高效处理复杂任务。相关资源已在Github链接中持续更新供社区使用。

Conclusion: 图技术与AI智能体的交叉研究有望推动下一代智能体发展，以应对日益复杂的挑战。本综述旨在激发这一新兴领域的创新。

Abstract: AI agents have experienced a paradigm shift, from early dominance by
reinforcement learning (RL) to the rise of agents powered by large language
models (LLMs), and now further advancing towards a synergistic fusion of RL and
LLM capabilities. This progression has endowed AI agents with increasingly
strong abilities. Despite these advances, to accomplish complex real-world
tasks, agents are required to plan and execute effectively, maintain reliable
memory, and coordinate smoothly with other agents. Achieving these capabilities
involves contending with ever-present intricate information, operations, and
interactions. In light of this challenge, data structurization can play a
promising role by transforming intricate and disorganized data into
well-structured forms that agents can more effectively understand and process.
In this context, graphs, with their natural advantage in organizing, managing,
and harnessing intricate data relationships, present a powerful data paradigm
for structurization to support the capabilities demanded by advanced AI agents.
To this end, this survey presents a first systematic review of how graphs can
empower AI agents. Specifically, we explore the integration of graph techniques
with core agent functionalities, highlight notable applications, and identify
prospective avenues for future research. By comprehensively surveying this
burgeoning intersection, we hope to inspire the development of next-generation
AI agents equipped to tackle increasingly sophisticated challenges with graphs.
Related resources are collected and continuously updated for the community in
the Github link.

</details>


### [138] [Action Language BC+](https://arxiv.org/abs/2506.18044)
*Joseph Babb,Joohyung Lee*

Main category: cs.AI

TL;DR: 本文提出了一种新的动作语言BC+，旨在弥合传统动作语言与现代答案集编程(ASP)语言之间的差距，通过广义稳定模型语义实现更丰富的知识表示能力。


<details>
  <summary>Details</summary>
Motivation: 传统动作语言在表达能力上与现代ASP语言存在显著差距，后者支持选择规则、聚合等实用结构。BC+旨在整合两者的优势。

Method: 基于命题公式的广义稳定模型语义定义BC+语言，将现代ASP构造视为命题公式的简写形式，并扩展cplus2asp系统实现该语言。

Result: BC+成功涵盖了B、C、C+等主流动作语言的优秀特性，且可直接利用ASP求解器进行计算，实现了理论表达与计算实践的融合。

Conclusion: BC+通过统一框架整合了动作语言与ASP的最新进展，其实现证明了该语言在知识表示和自动推理领域的实用价值。

Abstract: Action languages are formal models of parts of natural language that are
designed to describe effects of actions. Many of these languages can be viewed
as high level notations of answer set programs structured to represent
transition systems. However, the form of answer set programs considered in the
earlier work is quite limited in comparison with the modern Answer Set
Programming (ASP) language, which allows several useful constructs for
knowledge representation, such as choice rules, aggregates, and abstract
constraint atoms. We propose a new action language called BC+, which closes the
gap between action languages and the modern ASP language. The main idea is to
define the semantics of BC+ in terms of general stable model semantics for
propositional formulas, under which many modern ASP language constructs can be
identified with shorthands for propositional formulas. Language BC+ turns out
to be sufficiently expressive to encompass the best features of other action
languages, such as languages B, C, C+, and BC. Computational methods available
in ASP solvers are readily applicable to compute BC+, which led to an
implementation of the language by extending system cplus2asp.

</details>


### [139] [Weighted Assumption Based Argumentation to reason about ethical principles and actions](https://arxiv.org/abs/2506.18056)
*Paolo Baldi,Fabio Aurelio D'Asaro,Abeer Dyoub,Francesca Alessandra Lisi*

Main category: cs.AI

TL;DR: 本文扩展了基于假设的论证（ABA），引入了加权论证机制，通过伦理推理案例进行演示，并基于答案集编程实现了该方法。


<details>
  <summary>Details</summary>
Motivation: 为增强基于假设的论证（ABA）的表达能力，研究提出在论证过程中引入权重概念，以更精细地刻画论证强度与攻击关系。

Method: 在ABA框架中为论证分配权重，推导论证间攻击关系的权重值，并以伦理推理为例说明方法，最终基于答案集编程实现该加权体系。

Result: 成功构建了加权ABA框架，通过具体案例验证了权重机制在伦理推理中的适用性，并开发了可操作的计算实现。

Conclusion: 加权ABA扩展了传统论证框架的表达能力，为复杂场景（如伦理决策）提供了更精细的论证分析工具，其计算实现证明了方法的可行性。

Abstract: We augment Assumption Based Argumentation (ABA for short) with weighted
argumentation. In a nutshell, we assign weights to arguments and then derive
the weight of attacks between ABA arguments. We illustrate our proposal through
running examples in the field of ethical reasoning, and present an
implementation based on Answer Set Programming.

</details>


### [140] [Deep Research Agents: A Systematic Examination And Roadmap](https://arxiv.org/abs/2506.18096)
*Yuxuan Huang,Yihang Chen,Haozheng Zhang,Kang Li,Meng Fang,Linyi Yang,Xiaoguang Li,Lifeng Shang,Songcen Xu,Jianye Hao,Kun Shao,Jun Wang*

Main category: cs.AI

TL;DR: 本文系统分析了深度研究(DR)智能体的核心技术架构，提出了工作流分类法并评估了现有基准的局限性，同时指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型(LLM)的发展，能够执行复杂多轮信息研究任务的自主AI系统——深度研究智能体应运而生，需要对其技术架构进行系统性研究。

Method: 通过对比API检索与浏览器探索的信息获取策略，研究模块化工具使用框架，提出区分静态/动态工作流的分类法，并按规划策略和智能体构成进行分类。

Result: 构建了DR智能体技术体系分类框架，指出当前基准测试存在外部知识访问受限、顺序执行效率低下、评估指标与实际目标错位等关键局限。

Conclusion: 深度研究智能体领域仍需解决开放性挑战，论文提出了未来研究方向并建立了持续更新的研究资源库。

Abstract: The rapid progress of Large Language Models (LLMs) has given rise to a new
category of autonomous AI systems, referred to as Deep Research (DR) agents.
These agents are designed to tackle complex, multi-turn informational research
tasks by leveraging a combination of dynamic reasoning, adaptive long-horizon
planning, multi-hop information retrieval, iterative tool use, and the
generation of structured analytical reports. In this paper, we conduct a
detailed analysis of the foundational technologies and architectural components
that constitute Deep Research agents. We begin by reviewing information
acquisition strategies, contrasting API-based retrieval methods with
browser-based exploration. We then examine modular tool-use frameworks,
including code execution, multimodal input processing, and the integration of
Model Context Protocols (MCPs) to support extensibility and ecosystem
development. To systematize existing approaches, we propose a taxonomy that
differentiates between static and dynamic workflows, and we classify agent
architectures based on planning strategies and agent composition, including
single-agent and multi-agent configurations. We also provide a critical
evaluation of current benchmarks, highlighting key limitations such as
restricted access to external knowledge, sequential execution inefficiencies,
and misalignment between evaluation metrics and the practical objectives of DR
agents. Finally, we outline open challenges and promising directions for future
research. A curated and continuously updated repository of DR agent research is
available at: {https://github.com/ai-agents-2030/awesome-deep-research-agent}.

</details>


### [141] [Decentralized Consensus Inference-based Hierarchical Reinforcement Learning for Multi-Constrained UAV Pursuit-Evasion Game](https://arxiv.org/abs/2506.18126)
*Xiang Yuming,Li Sizhao,Li Rongpeng,Zhao Zhifeng,Zhang Honggang*

Main category: cs.AI

TL;DR: 本文提出了一种名为CI-HRL的两层框架，用于解决多约束追逃游戏中的协同规避与编队覆盖任务，通过高层策略进行目标定位，低层策略管理避障、导航和编队，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 多无人机系统在多约束追逃游戏中的应用面临高维复杂问题，尤其是在通信受限条件下，协同规避与编队覆盖任务极具挑战性。

Method: 提出CI-HRL框架，高层策略使用ConsMAC模块实现全局信息感知与共识建立，低层策略采用AT-M和策略蒸馏技术完成控制。

Result: 高保真SITL仿真实验表明，CI-HRL显著提升了无人机群的协同规避和任务完成能力。

Conclusion: CI-HRL为多约束追逃游戏中的协同规避与编队覆盖任务提供了一种高效解决方案，具有实际应用潜力。

Abstract: Multiple quadrotor unmanned aerial vehicle (UAV) systems have garnered
widespread research interest and fostered tremendous interesting applications,
especially in multi-constrained pursuit-evasion games (MC-PEG). The Cooperative
Evasion and Formation Coverage (CEFC) task, where the UAV swarm aims to
maximize formation coverage across multiple target zones while collaboratively
evading predators, belongs to one of the most challenging issues in MC-PEG,
especially under communication-limited constraints. This multifaceted problem,
which intertwines responses to obstacles, adversaries, target zones, and
formation dynamics, brings up significant high-dimensional complications in
locating a solution. In this paper, we propose a novel two-level framework
(i.e., Consensus Inference-based Hierarchical Reinforcement Learning (CI-HRL)),
which delegates target localization to a high-level policy, while adopting a
low-level policy to manage obstacle avoidance, navigation, and formation.
Specifically, in the high-level policy, we develop a novel multi-agent
reinforcement learning module, Consensus-oriented Multi-Agent Communication
(ConsMAC), to enable agents to perceive global information and establish
consensus from local states by effectively aggregating neighbor messages.
Meanwhile, we leverage an Alternative Training-based Multi-agent proximal
policy optimization (AT-M) and policy distillation to accomplish the low-level
control. The experimental results, including the high-fidelity
software-in-the-loop (SITL) simulations, validate that CI-HRL provides a
superior solution with enhanced swarm's collaborative evasion and task
completion capabilities.

</details>


### [142] [SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging](https://arxiv.org/abs/2506.18135)
*Zijun Chen,Zhanpeng Zhou,Bo Zhang,Weinan Zhang,Xi Sun,Junchi Yan*

Main category: cs.AI

TL;DR: 该研究从表示角度揭示了模型合并实现多任务能力的机制，并提出无需额外训练的\texttt{SE-Merging}框架，通过动态识别任务和自适应调整合并系数显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 尽管模型合并在实践中取得成功，但其底层机制尚不明确。本研究旨在从表示层面揭示模型合并如何实现多任务能力。

Method: 提出\texttt{SE-Merging}框架，利用样本任务区分和专家模型适配两大特性，动态识别任务并自适应调整合并系数，无需额外训练即可增强任务特定专业知识。

Result: 大量实验表明，\texttt{SE-Merging}在保持与现有技术兼容的同时，实现了显著的性能提升。

Conclusion: 模型合并通过任务区分和专家适配实现多任务能力，\texttt{SE-Merging}框架有效利用这些特性动态优化合并过程，为模型合并领域提供了新见解。

Abstract: Model merging has gained increasing attention due to its intriguing property:
interpolating the parameters of different task-specific fine-tuned models leads
to multi-task abilities. However, despite its empirical success, the underlying
mechanisms of model merging remain poorly understood. In this work, we delve
into the mechanism behind model merging from a representation perspective. Our
analysis reveals that model merging achieves multi-task abilities through two
key capabilities: i) distinguishing samples from different tasks, and ii)
adapting to the corresponding expert model for each sample. These two
capabilities allow the merged model to retain task-specific expertise, enabling
efficient multi-task adaptation. Building on these insights, we propose
\texttt{SE-Merging}, a self-enhanced model merging framework that leverages
these two characteristics to dynamically identify the corresponding task for
each sample and then adaptively rescales the merging coefficients to further
enhance task-specific expertise in the merged model. Notably,
\texttt{SE-Merging} achieves dynamic model merging without additional training.
Extensive experiments demonstrate that \texttt{SE-Merging} achieves significant
performance improvements while remaining compatible with existing model merging
techniques.

</details>


### [143] [CoachGPT: A Scaffolding-based Academic Writing Assistant](https://arxiv.org/abs/2506.18149)
*Fumian Chen,Sotheara Veng,Joshua Wilson,Xiaoming Li,Hui Fang*

Main category: cs.AI

TL;DR: 研究开发了CoachGPT，一款基于大型语言模型（LLM）的AI写作助手，旨在为学术写作提供个性化实时反馈，弥补传统工具和现有AI助手的不足。


<details>
  <summary>Details</summary>
Motivation: 学术写作能力对学生的成功至关重要，但缺乏指导资源（尤其是非母语者）。传统工具（如词典）和早期AI助手（基于规则）效果有限，而现有LLM虽强大却缺乏教学功能，可能影响学习效果。

Method: CoachGPT采用LLM技术构建，通过（1）整合教育专家指令，（2）分解为子任务，（3）利用LLM提供实时反馈，形成独特的脚手架式写作辅助框架。

Result: 用户研究表明，相比现有工具，CoachGPT能提供更沉浸式的写作体验与个性化指导，验证了LLM在学术写作辅助中的潜力。

Conclusion: CoachGPT通过结合教育专家知识与LLM的生成能力，为资源有限或偏好自主学习的学习者提供了创新的学术写作支持方案。

Abstract: Academic writing skills are crucial for students' success, but can feel
overwhelming without proper guidance and practice, particularly when writing in
a second language. Traditionally, students ask instructors or search
dictionaries, which are not universally accessible. Early writing assistants
emerged as rule-based systems that focused on detecting misspellings,
subject-verb disagreements, and basic punctuation errors; however, they are
inaccurate and lack contextual understanding. Machine learning-based assistants
demonstrate a strong ability for language understanding but are expensive to
train. Large language models (LLMs) have shown remarkable capabilities in
generating responses in natural languages based on given prompts. Still, they
have a fundamental limitation in education: they generate essays without
teaching, which can have detrimental effects on learning when misused. To
address this limitation, we develop CoachGPT, which leverages large language
models (LLMs) to assist individuals with limited educational resources and
those who prefer self-paced learning in academic writing. CoachGPT is an AI
agent-based web application that (1) takes instructions from experienced
educators, (2) converts instructions into sub-tasks, and (3) provides real-time
feedback and suggestions using large language models. This unique scaffolding
structure makes CoachGPT unique among existing writing assistants. Compared to
existing writing assistants, CoachGPT provides a more immersive writing
experience with personalized feedback and guidance. Our user studies prove the
usefulness of CoachGPT and the potential of large language models for academic
writing.

</details>


### [144] [AI Through the Human Lens: Investigating Cognitive Theories in Machine Psychology](https://arxiv.org/abs/2506.18156)
*Akash Kundu,Rishika Goswami*

Main category: cs.AI

TL;DR: 研究探讨大语言模型(LLM)是否表现出类似人类的认知模式，通过四种心理学框架评估，发现其行为既反映人类倾向又受训练数据影响。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在主题统觉测试(TAT)、框架偏差、道德基础理论(MFT)和认知失调四种心理学框架下是否展现类人认知特征。

Method: 使用结构化提示和自动评分系统评估多个专有和开源模型。

Result: 模型能生成连贯叙事、易受积极框架影响、道德判断侧重自由/压迫维度，并通过大量合理化缓解自相矛盾，这些行为受训练数据和对齐方法塑造。

Conclusion: 研究结果对AI透明度、伦理部署具有重要意义，为认知心理学与AI安全领域的交叉研究指明方向。

Abstract: We investigate whether Large Language Models (LLMs) exhibit human-like
cognitive patterns under four established frameworks from psychology: Thematic
Apperception Test (TAT), Framing Bias, Moral Foundations Theory (MFT), and
Cognitive Dissonance. We evaluated several proprietary and open-source models
using structured prompts and automated scoring. Our findings reveal that these
models often produce coherent narratives, show susceptibility to positive
framing, exhibit moral judgments aligned with Liberty/Oppression concerns, and
demonstrate self-contradictions tempered by extensive rationalization. Such
behaviors mirror human cognitive tendencies yet are shaped by their training
data and alignment methods. We discuss the implications for AI transparency,
ethical deployment, and future work that bridges cognitive psychology and AI
safety

</details>


### [145] [Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation](https://arxiv.org/abs/2506.18158)
*Xinzge Gao,Chuanrui Hu,Bin Chen,Teng Li*

Main category: cs.AI

TL;DR: 本文提出Chain-of-Memory (CoM)方法，通过显式建模GUI代理的短期和长期记忆，提升其在跨应用任务中的表现，并发布了包含11.1万标注数据的GUI Odyssey-CoM数据集。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理依赖历史截图或动作隐式表示任务状态，难以准确理解复杂跨应用任务，缺乏有效机制存储关键信息。

Method: CoM通过捕获动作描述、整合任务相关屏幕信息，并维护专用记忆模块来显式管理短期/长期记忆。配套开发了带记忆标注的GUI Odyssey-CoM数据集。

Result: 实验表明CoM显著提升GUI代理性能，使7B模型达到与72B模型相当的记忆管理能力。数据集和代码将开源。

Conclusion: 显式记忆表征能有效增强GUI代理的任务状态理解能力，CoM框架为复杂跨应用任务提供了可扩展的解决方案。

Abstract: Multimodal large language models (MLLMs) are attracting growing attention in
the development of Graphical User Interface (GUI) agents. Existing approaches
often rely on historical screenshots or actions to implicitly represent the
task state. This reliance poses challenges for GUI agents in accurately
understanding task states and underscores the absence of effective mechanisms
to store critical information in complex and lengthy cross-app tasks. To
address these challenges, we propose Chain-of-Memory (CoM), a novel approach
for explicitly modeling short-term and long-term memory in GUI agents. CoM
achieves this by capturing action descriptions, integrating task-relevant
screen information, and maintaining a dedicated memory module to store and
manage this information. By leveraging explicit memory representations, CoM
enables GUI agents to better understand task states and retain critical
historical information persistently. To equip GUI agents with memory management
capabilities and evaluate the effectiveness of CoM, we developed the GUI
Odyssey-CoM, a dataset comprising 111k screen-action pairs annotated with
Chain-of-Memory. Experimental results demonstrate that CoM significantly
improves GUI agents' performance in cross-application tasks. Additionally, GUI
Odyssey-CoM enables 7B models to achieve memory management capabilities
comparable to 72B models. The dataset and code will be open-sourced.

</details>


### [146] [Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?](https://arxiv.org/abs/2506.18183)
*Zhiting Mei,Christina Zhang,Tenny Yin,Justin Lidard,Ola Shorinwa,Anirudha Majumdar*

Main category: cs.AI

TL;DR: 本文探讨了推理语言模型的不确定性量化问题，发现现有模型普遍存在过度自信现象，并验证了自省式不确定性量化对部分模型的校准效果。


<details>
  <summary>Details</summary>
Motivation: 尽管推理语言模型在多步推理任务中表现优异，但其生成的错误答案往往伴随高置信度（幻觉问题）。为确保模型在实际应用中的安全性，研究其不确定性量化至关重要。

Method: 提出自省式不确定性量化（UQ）方法，通过三个核心问题评估模型：校准性、推理深度对校准的影响，以及基于思维链自检的校准改进。在多个SOTA模型（如o3-Mini、DeepSeek R1等）上进行广泛实验。

Result: 研究发现：(1) 模型普遍过度自信，错误答案的自我评估置信度常超85%；(2) 更深层推理会加剧过度自信；(3) 自省能改善部分模型（如o3-Mini）的校准性，但效果非普适（如Claude 3.7 Sonnet校准性反而下降）。

Conclusion: 需建立专门的不确定性量化基准，并进一步研究提升推理模型校准性的方法，这对模型安全部署具有重要意义。

Abstract: Reasoning language models have set state-of-the-art (SOTA) records on many
challenging benchmarks, enabled by multi-step reasoning induced using
reinforcement learning. However, like previous language models, reasoning
models are prone to generating confident, plausible responses that are
incorrect (hallucinations). Knowing when and how much to trust these models is
critical to the safe deployment of reasoning models in real-world applications.
To this end, we explore uncertainty quantification of reasoning models in this
work. Specifically, we ask three fundamental questions: First, are reasoning
models well-calibrated? Second, does deeper reasoning improve model
calibration? Finally, inspired by humans' innate ability to double-check their
thought processes to verify the validity of their answers and their confidence,
we ask: can reasoning models improve their calibration by explicitly reasoning
about their chain-of-thought traces? We introduce introspective uncertainty
quantification (UQ) to explore this direction. In extensive evaluations on SOTA
reasoning models across a broad range of benchmarks, we find that reasoning
models: (i) are typically overconfident, with self-verbalized confidence
estimates often greater than 85% particularly for incorrect responses, (ii)
become even more overconfident with deeper reasoning, and (iii) can become
better calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not
uniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we
conclude with important research directions to design necessary UQ benchmarks
and improve the calibration of reasoning models.

</details>


### [147] [The Impact of Medication Non-adherence on Adverse Outcomes: Evidence from Schizophrenia Patients via Survival Analysis](https://arxiv.org/abs/2506.18187)
*Shahriar Noroozizadeh,Pim Welle,Jeremy C. Weiss,George H. Chen*

Main category: cs.AI

TL;DR: 本研究量化了精神分裂症患者不坚持服用抗精神病药物与不良后果之间的关联，发现不坚持用药会使不良后果提前1至4个月发生。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估精神分裂症患者不坚持用药（抗精神病药物）与不良后果（如早逝、强制住院、入狱）之间的关联，强调坚持用药对延缓精神危机的重要性。

Method: 采用生存分析方法，扩展了标准因果推断方法（T-learner、S-learner、最近邻匹配），利用不同生存模型估计个体和平均处理效应，分析基于不同时间跨度（3、6、9、12个月）的纵向数据。

Result: 研究发现不坚持用药会使不良后果提前1至4个月发生，且在不同药物剂型（注射与口服）和药物类型中结果一致。县提供的风险评分能调整关键混杂因素，移除后会放大效应估计。

Conclusion: 研究强调了坚持用药对延缓精神危机的临床重要性，并表明将生存分析与因果推断工具结合可提供政策相关见解。尽管应用了因果推断方法，但仅作出关联性声明，并讨论了因果解释所需的假设。

Abstract: This study quantifies the association between non-adherence to antipsychotic
medications and adverse outcomes in individuals with schizophrenia. We frame
the problem using survival analysis, focusing on the time to the earliest of
several adverse events (early death, involuntary hospitalization, jail
booking). We extend standard causal inference methods (T-learner, S-learner,
nearest neighbor matching) to utilize various survival models to estimate
individual and average treatment effects, where treatment corresponds to
medication non-adherence. Analyses are repeated using different amounts of
longitudinal information (3, 6, 9, and 12 months). Using data from Allegheny
County in western Pennsylvania, we find strong evidence that non-adherence
advances adverse outcomes by approximately 1 to 4 months. Ablation studies
confirm that county-provided risk scores adjust for key confounders, as their
removal amplifies the estimated effects. Subgroup analyses by medication
formulation (injectable vs. oral) and medication type consistently show that
non-adherence is associated with earlier adverse events. These findings
highlight the clinical importance of adherence in delaying psychiatric crises
and show that integrating survival analysis with causal inference tools can
yield policy-relevant insights. We caution that although we apply causal
inference, we only make associative claims and discuss assumptions needed for
causal interpretation.

</details>


### [148] [A Conceptual Framework for AI Capability Evaluations](https://arxiv.org/abs/2506.18213)
*María Victoria Carro,Denise Alejandra Mester,Francisca Gauna Selasco,Luca Nicolás Forziati Gangi,Matheo Sandleris Musa,Lola Ramos Pereyra,Mario Leiva,Juan Gustavo Corvalan,María Vanina Martinez,Gerardo Simari*

Main category: cs.AI

TL;DR: 本文提出一个分析AI能力评估的概念框架，旨在提升评估的透明度、可比性和可解释性，为研究者、实践者和政策制定者提供系统化工具。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统深入社会，透明且全面的评估成为AI治理的关键工具，但目前缺乏系统化的评估方法。

Method: 作者提出一个结构化描述性框架，系统分析现有评估方法与术语，不强制新分类或固定格式。

Result: 该框架支持跨评估的透明比较，帮助识别方法缺陷、指导评估设计，并为政策制定提供实用工具。

Conclusion: 此框架填补了AI能力评估的系统化空白，为多方利益相关者提供了标准化分析工具。

Abstract: As AI systems advance and integrate into society, well-designed and
transparent evaluations are becoming essential tools in AI governance,
informing decisions by providing evidence about system capabilities and risks.
Yet there remains a lack of clarity on how to perform these assessments both
comprehensively and reliably. To address this gap, we propose a conceptual
framework for analyzing AI capability evaluations, offering a structured,
descriptive approach that systematizes the analysis of widely used methods and
terminology without imposing new taxonomies or rigid formats. This framework
supports transparency, comparability, and interpretability across diverse
evaluations. It also enables researchers to identify methodological weaknesses,
assists practitioners in designing evaluations, and provides policymakers with
an accessible tool to scrutinize, compare, and navigate complex evaluation
landscapes.

</details>


### [149] [The 4th Dimension for Scaling Model Size](https://arxiv.org/abs/2506.18233)
*Ruike Zhu,Hanwen Zhang,Tianyu Shi,Chi Wang,Tianyi Zhou,Zengyi Qin*

Main category: cs.AI

TL;DR: 本文提出虚拟逻辑深度（VLD）作为大语言模型扩展的第四维度，通过参数复用提升推理能力而不增加参数量。实验表明VLD扩展能保持知识容量恒定，显著增强推理能力，且参数量与推理能力无直接关联。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型扩展的新维度（虚拟逻辑深度），研究参数复用对模型性能的影响，填补该领域系统性研究的空白。

Method: 通过精心设计的对照实验，分析不同VLD扩展方式下模型的知识容量与推理能力变化，验证参数复用策略的有效性。

Result: 1. VLD扩展使知识容量基本恒定\n2. 正确实施时可显著提升推理能力\n3. 参数量仅关联知识容量，与推理能力无关\n4. 结论在不同模型配置下具有普适性

Conclusion: 在特定条件下，无需增加参数量即可通过VLD扩展提升模型推理能力，这为高效的大语言模型优化提供了新方向。

Abstract: Scaling the size of large language models typically involves three
dimensions: depth, width, and the number of parameters. In this work, we
explore a fourth dimension, virtual logical depth (VLD), which increases the
effective algorithmic depth without changing the overall parameter count by
reusing parameters within the model. Although parameter reuse is not a new
concept, its potential and characteristics in model scaling have not been
thoroughly studied. Through carefully designed controlled experiments, we make
the following key discoveries regarding VLD scaling:
  VLD scaling forces the knowledge capacity of the model to remain almost
constant, with only minor variations.
  VLD scaling enables a significant improvement in reasoning capability,
provided the scaling method is properly implemented.
  The number of parameters correlates with knowledge capacity, but not with
reasoning capability. Under certain conditions, it is not necessary to increase
the parameter count to enhance reasoning.
  These findings are consistent across various model configurations and are
likely to be generally valid within the scope of our experiments.

</details>


### [150] [Advanced For-Loop for QML algorithm search](https://arxiv.org/abs/2506.18260)
*FuTe Wong*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型的多智能体系统（LLMMA）框架，用于自动搜索和优化量子机器学习（QML）算法。该系统在抽象层面上迭代生成并优化经典机器学习算法的量子转换，展示了智能体框架在量子计算中系统探索和适应经典机器学习概念的潜力。


<details>
  <summary>Details</summary>
Motivation: 受Google DeepMind的FunSearch启发，本研究旨在利用多智能体系统自动化和优化量子机器学习算法的开发，以推动量子增强机器学习的效率和应用范围。

Method: 采用基于大语言模型的多智能体系统（LLMMA），在抽象层面上迭代生成和优化经典机器学习算法（如多层感知机、前向-前向和反向传播算法）的量子转换。

Result: 作为概念验证，本研究展示了智能体框架在系统探索经典机器学习概念并将其适配到量子计算中的潜力，为高效自动化开发QML算法奠定了基础。

Conclusion: 未来研究方向包括在搜索空间中引入规划机制和优化策略，以扩大量子增强机器学习的应用范围。

Abstract: This paper introduces an advanced framework leveraging Large Language
Model-based Multi-Agent Systems (LLMMA) for the automated search and
optimization of Quantum Machine Learning (QML) algorithms. Inspired by Google
DeepMind's FunSearch, the proposed system works on abstract level to
iteratively generates and refines quantum transformations of classical machine
learning algorithms (concepts), such as the Multi-Layer Perceptron,
forward-forward and backpropagation algorithms. As a proof of concept, this
work highlights the potential of agentic frameworks to systematically explore
classical machine learning concepts and adapt them for quantum computing,
paving the way for efficient and automated development of QML algorithms.
Future directions include incorporating planning mechanisms and optimizing
strategy in the search space for broader applications in quantum-enhanced
machine learning.

</details>


### [151] [Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team](https://arxiv.org/abs/2506.18348)
*Weilun Yu,Shixiang Tang,Yonggui Huang,Nanqing Dong,Li Fan,Honggang Qi,Wei Liu,Xiaoli Diao,Xi Chen,Wanli Ouyang*

Main category: cs.AI

TL;DR: 本文提出IDVSCI框架，通过多智能体动态知识交换和双多样性评审机制，提升LLM在自主科研中的交互推理与创新性。实验表明其在跨领域数据集上均优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的科研智能体缺乏真实研究所需的交互推理与评审机制，制约了自主科学发现的效能。

Method: 提出IDVSCI框架：1) 动态知识交换机制实现智能体间迭代反馈；2) 双多样性评审范式模拟异质专家评估。

Result: 在计算机科学基准和健康科学新数据集上，IDVSCI性能均超越AI Scientist、VIRSCI等现有系统。

Conclusion: 建模交互与同行评审动态对LLM自主研究具有重要价值，IDVSCI框架为跨领域科学协作提供了新范式。

Abstract: Scientific progress increasingly relies on effective collaboration among
researchers, a dynamic that large language models (LLMs) have only begun to
emulate. While recent LLM-based scientist agents show promise in autonomous
scientific discovery, they often lack the interactive reasoning and evaluation
mechanisms essential to real-world research. We propose IDVSCI (Internal
Discussion and Vote SCIentists), a multi-agent framework built on LLMs that
incorporates two key innovations: a Dynamic Knowledge Exchange mechanism
enabling iterative feedback among agents, and a Dual-Diversity Review paradigm
that simulates heterogeneous expert evaluation. These components jointly
promote deeper reasoning and the generation of more creative and impactful
scientific ideas. To evaluate the effectiveness and generalizability of our
approach, we conduct experiments on two datasets: a widely used benchmark in
computer science and a new dataset we introduce in the health sciences domain.
Results show that IDVSCI consistently achieves the best performance across both
datasets, outperforming existing systems such as AI Scientist and VIRSCI. These
findings highlight the value of modeling interaction and peer review dynamics
in LLM-based autonomous research.

</details>


### [152] [A Large Language Model-based Multi-Agent Framework for Analog Circuits' Sizing Relationships Extraction](https://arxiv.org/abs/2506.18424)
*Chengjie Liu,Weiyu Chen,Huiyao Xu,Yuan Du,Jun Yang,Li Du*

Main category: cs.AI

TL;DR: 提出基于大语言模型（LLM）的多智能体框架，用于从学术论文中提取模拟电路尺寸关系，有效修剪搜索空间，提升优化效率$2.32 \sim 26.6 \times$。


<details>
  <summary>Details</summary>
Motivation: 现有模拟电路预布局阶段器件尺寸优化方法忽视先验知识自动引入，导致搜索空间压缩不足，需通过LLM提取尺寸关系实现有效修剪。

Method: 构建LLM驱动的多智能体框架，从论文文本中自动提取电路尺寸约束关系，基于此关系在尺寸优化过程中动态修剪无效搜索空间。

Result: 在3类电路测试中，优化效率提升$2.32 \sim 26.6 \times$，验证LLM对模拟电路尺寸搜索空间修剪的有效性。

Conclusion: LLM为模拟电路设计自动化提供了新思路，其提取的尺寸关系能显著提升传统优化方法的效率，实现AI与EDA技术的创新结合。

Abstract: In the design process of the analog circuit pre-layout phase, device sizing
is an important step in determining whether an analog circuit can meet the
required performance metrics. Many existing techniques extract the circuit
sizing task as a mathematical optimization problem to solve and continuously
improve the optimization efficiency from a mathematical perspective. But they
ignore the automatic introduction of prior knowledge, fail to achieve effective
pruning of the search space, which thereby leads to a considerable compression
margin remaining in the search space. To alleviate this problem, we propose a
large language model (LLM)-based multi-agent framework for analog circuits'
sizing relationships extraction from academic papers. The search space in the
sizing process can be effectively pruned based on the sizing relationship
extracted by this framework. Eventually, we conducted tests on 3 types of
circuits, and the optimization efficiency was improved by $2.32 \sim 26.6
\times$. This work demonstrates that the LLM can effectively prune the search
space for analog circuit sizing, providing a new solution for the combination
of LLMs and conventional analog circuit design automation methods.

</details>


### [153] [How Robust is Model Editing after Fine-Tuning? An Empirical Study on Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.18428)
*Feng He,Zhenyang Liu,Marco Valentino,Zhixue Zhao*

Main category: cs.AI

TL;DR: 研究发现，模型编辑后的行为在微调过程中普遍无法保持，这对AI安全具有双重影响：微调可作为恶意编辑的修复机制，但也需重新编辑以维持有益的安全属性。


<details>
  <summary>Details</summary>
Motivation: 探讨模型编辑后行为在微调中的持久性，这对事实修正、偏见消除等应用具有重要实践意义，涉及AI安全防御与风险防控。

Method: 针对Stable Diffusion和FLUX两类T2I模型，结合UCE、ReFACT两种编辑技术与DreamBooth、LoRA、DoRA三种微调方法，通过多任务多指标进行系统性实验。

Result: 实验表明：1) 微调普遍导致编辑失效，即使微调与编辑无关；2) DoRA的编辑逆转效应最强；3) UCE比ReFACT在微调后保留更高编辑效力。

Conclusion: 当前编辑技术存在持久性缺陷，需开发更鲁棒的方法以确保AI系统的长期可控性。微调兼具防御恶意编辑与需补编辑的双重安全特性。

Abstract: Model editing offers a low-cost technique to inject or correct a particular
behavior in a pre-trained model without extensive retraining, supporting
applications such as factual correction and bias mitigation. Despite this
common practice, it remains unknown whether edits persist after fine-tuning or
whether they are inadvertently reversed. This question has fundamental
practical implications. For example, if fine-tuning removes prior edits, it
could serve as a defence mechanism against hidden malicious edits. Vice versa,
the unintended removal of edits related to bias mitigation could pose serious
safety concerns. We systematically investigate the interaction between model
editing and fine-tuning in the context of T2I diffusion models, which are known
to exhibit biases and generate inappropriate content. Our study spans two T2I
model families (Stable Diffusion and FLUX), two sota editing techniques, and
three fine-tuning methods (DreamBooth, LoRA, and DoRA). Through an extensive
empirical analysis across diverse editing tasks and evaluation metrics, our
findings reveal a trend: edits generally fail to persist through fine-tuning,
even when fine-tuning is tangential or unrelated to the edits. Notably, we
observe that DoRA exhibits the strongest edit reversal effect. At the same
time, among editing methods, UCE demonstrates greater robustness, retaining
significantly higher efficacy post-fine-tuning compared to ReFACT. These
findings highlight a crucial limitation in current editing methodologies,
emphasizing the need for more robust techniques to ensure reliable long-term
control and alignment of deployed AI systems. These findings have dual
implications for AI safety: they suggest that fine-tuning could serve as a
remediation mechanism for malicious edits while simultaneously highlighting the
need for re-editing after fine-tuning to maintain beneficial safety and
alignment properties.

</details>


### [154] [Standard Applicability Judgment and Cross-jurisdictional Reasoning: A RAG-based Framework for Medical Device Compliance](https://arxiv.org/abs/2506.18511)
*Yu Han,Aaron Ceross,Jeroen H. M. Bergmann*

Main category: cs.AI

TL;DR: 本文提出了一种模块化AI系统，通过检索增强生成（RAG）技术自动确定医疗器械的适用监管标准，支持跨辖区（如中美）标准冲突解决，准确率达73%。


<details>
  <summary>Details</summary>
Motivation: 医疗器械合规性中，确定适用的监管标准是一个关键但研究不足的挑战，常需专家解读分散且异构的文档。

Method: 系统采用RAG流程：根据自由文本设备描述检索候选标准，利用大语言模型推断辖区特定适用性（强制/推荐/不适用），并提供可追溯的论证。构建了专家标注的国际基准数据集，并与纯检索、零样本及基于规则的基线方法对比。

Result: 分类准确率73%，Top-5检索召回率87%，首次实现端到端的标准适用性推理，支持可扩展且可解释的AI辅助监管科学。

Conclusion: 该研究提出了首个支持跨辖区标准推理（如中美）的RAG系统，为监管框架下的冲突解决和适用性论证提供了有效工具。

Abstract: Identifying the appropriate regulatory standard applicability remains a
critical yet understudied challenge in medical device compliance, frequently
necessitating expert interpretation of fragmented and heterogeneous
documentation across different jurisdictions. To address this challenge, we
introduce a modular AI system that leverages a retrieval-augmented generation
(RAG) pipeline to automate standard applicability determination. Given a
free-text device description, our system retrieves candidate standards from a
curated corpus and uses large language models to infer jurisdiction-specific
applicability, classified as Mandatory, Recommended, or Not Applicable, with
traceable justifications. We construct an international benchmark dataset of
medical device descriptions with expert-annotated standard mappings, and
evaluate our system against retrieval-only, zero-shot, and rule-based
baselines. The proposed approach attains a classification accuracy of 73% and a
Top-5 retrieval recall of 87%, demonstrating its effectiveness in identifying
relevant regulatory standards. We introduce the first end-to-end system for
standard applicability reasoning, enabling scalable and interpretable
AI-supported regulatory science. Notably, our region-aware RAG agent performs
cross-jurisdictional reasoning between Chinese and U.S. standards, supporting
conflict resolution and applicability justification across regulatory
frameworks.

</details>


### [155] [A Question Bank to Assess AI Inclusivity: Mapping out the Journey from Diversity Errors to Inclusion Excellence](https://arxiv.org/abs/2506.18538)
*Rifat Ara Shams,Didar Zowghi,Muneera Bano*

Main category: cs.AI

TL;DR: 本文提出一个包含253个问题的AI包容性评估题库，覆盖人类、数据、流程、系统与治理五大支柱，旨在通过标准化工具促进AI系统的多样性与包容性。


<details>
  <summary>Details</summary>
Motivation: 现有AI风险评估框架常忽视包容性指标，缺乏衡量AI系统是否符合多样性与包容性（D&I）原则的统一工具，可能导致偏见决策。

Method: 通过文献综述、D&I指南、负责任AI框架及模拟用户研究（70个AI生成角色参与）的多源迭代方法开发题库，并评估其跨领域适用性。

Result: 模拟测试表明题库能有效评估不同AI职位和应用场景的包容性，强调需将D&I原则融入AI开发流程与治理体系。

Conclusion: 该题库为研究者、从业者及政策制定者提供了系统性提升AI包容性的实操工具，推动更公平、负责任的AI技术发展。

Abstract: Ensuring diversity and inclusion (D&I) in artificial intelligence (AI) is
crucial for mitigating biases and promoting equitable decision-making. However,
existing AI risk assessment frameworks often overlook inclusivity, lacking
standardized tools to measure an AI system's alignment with D&I principles.
This paper introduces a structured AI inclusivity question bank, a
comprehensive set of 253 questions designed to evaluate AI inclusivity across
five pillars: Humans, Data, Process, System, and Governance. The development of
the question bank involved an iterative, multi-source approach, incorporating
insights from literature reviews, D&I guidelines, Responsible AI frameworks,
and a simulated user study. The simulated evaluation, conducted with 70
AI-generated personas related to different AI jobs, assessed the question
bank's relevance and effectiveness for AI inclusivity across diverse roles and
application domains. The findings highlight the importance of integrating D&I
principles into AI development workflows and governance structures. The
question bank provides an actionable tool for researchers, practitioners, and
policymakers to systematically assess and enhance the inclusivity of AI
systems, paving the way for more equitable and responsible AI technologies.

</details>


### [156] [T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent](https://arxiv.org/abs/2506.18559)
*Hong Qing Yu*

Main category: cs.AI

TL;DR: 本文提出了一种名为T-CPDL的新型逻辑框架，通过整合时间、因果和概率推理，显著提升了大语言模型在结构化推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在生成流畅文本方面表现出色，但在涉及时间约束、因果关系和概率推理的结构化推理任务中表现不佳，需要更强大的逻辑框架来支持。

Method: 提出了T-CPDL（时间因果概率描述逻辑），扩展了传统描述逻辑，包含时间区间算子、显式因果关系和概率标注。设计了两种变体：一种基于Allen区间代数的定性时间关系，另一种带有时间戳因果断言。

Result: 在时间推理和因果推断基准测试中，T-CPDL显著提高了推理准确性、可解释性和置信度校准能力，为语言模型提供了透明的推理路径和细粒度语义。

Conclusion: T-CPDL框架不仅增强了语言模型的可靠决策能力，还为开发先进的逻辑检索增强生成（Logic-RAG）系统奠定了基础，有望提升知识图谱增强系统的推理效率。

Abstract: Large language models excel at generating fluent text but frequently struggle
with structured reasoning involving temporal constraints, causal relationships,
and probabilistic reasoning. To address these limitations, we propose Temporal
Causal Probabilistic Description Logic (T-CPDL), an integrated framework that
extends traditional Description Logic with temporal interval operators,
explicit causal relationships, and probabilistic annotations. We present two
distinct variants of T-CPDL: one capturing qualitative temporal relationships
through Allen's interval algebra, and another variant enriched with explicit
timestamped causal assertions. Both variants share a unified logical structure,
enabling complex reasoning tasks ranging from simple temporal ordering to
nuanced probabilistic causation. Empirical evaluations on temporal reasoning
and causal inference benchmarks confirm that T-CPDL substantially improves
inference accuracy, interpretability, and confidence calibration of language
model outputs. By delivering transparent reasoning paths and fine-grained
temporal and causal semantics, T-CPDL significantly enhances the capability of
language models to support robust, explainable, and trustworthy
decision-making. This work also lays the groundwork for developing advanced
Logic-Retrieval-Augmented Generation (Logic-RAG) frameworks, potentially
boosting the reasoning capabilities and efficiency of knowledge graph-enhanced
RAG systems.

</details>


### [157] [Airalogy: AI-empowered universal data digitization for research automation](https://arxiv.org/abs/2506.18586)
*Zijie Yang,Qiji Zhou,Fang Guo,Sijie Zhang,Yexun Xi,Jinglei Nie,Yudian Zhu,Liping Huang,Chou Wu,Yonghe Xia,Xiaoyu Ma,Yingming Pu,Panzhong Lu,Junshu Pan,Mingtao Chen,Tiannan Guo,Yanmei Dou,Hongyu Chen,Anping Zeng,Jiaxing Huang,Tian Xu,Yue Zhang*

Main category: cs.AI

TL;DR: 本文介绍了Airalogy平台，首个AI与社区驱动的多学科研究数据数字化平台，旨在解决研究数据标准化与通用性之间的平衡问题，已在西湖大学四个学院实验室部署。


<details>
  <summary>Details</summary>
Motivation: 当前AI应用受限于数据标准化不足和跨学科数据共享困难，阻碍了多学科AI赋能的全面实现。

Method: 开发Airalogy平台，整合科学领域知识与计算技术，提供可定制、标准化的数据记录方法和AI研究助手功能。

Result: Airalogy平台成功在西湖大学多个实验室部署，支持智能问答、自动化数据录入与分析，推动科研自动化。

Conclusion: Airalogy平台有望加速全球科研创新，实现跨学科研究数据的标准化与共享，最终造福全人类。

Abstract: Research data are the foundation of Artificial Intelligence (AI)-driven
science, yet current AI applications remain limited to a few fields with
readily available, well-structured, digitized datasets. Achieving comprehensive
AI empowerment across multiple disciplines is still out of reach. Present-day
research data collection is often fragmented, lacking unified standards,
inefficiently managed, and difficult to share. Creating a single platform for
standardized data digitization needs to overcome the inherent challenge of
balancing between universality (supporting the diverse, ever-evolving needs of
various disciplines) and standardization (enforcing consistent formats to fully
enable AI). No existing platform accommodates both facets. Building a truly
multidisciplinary platform requires integrating scientific domain knowledge
with sophisticated computing skills. Researchers often lack the computational
expertise to design customized and standardized data recording methods, whereas
platform developers rarely grasp the intricate needs of multiple scientific
domains. These gaps impede research data standardization and hamper AI-driven
progress. In this study, we address these challenges by developing Airalogy
(https://airalogy.com), the world's first AI- and community-driven platform
that balances universality and standardization for digitizing research data
across multiple disciplines. Airalogy represents entire research workflows
using customizable, standardized data records and offers an advanced AI
research copilot for intelligent Q&A, automated data entry, analysis, and
research automation. Already deployed in laboratories across all four schools
of Westlake University, Airalogy has the potential to accelerate and automate
scientific innovation in universities, industry, and the global research
community-ultimately benefiting humanity as a whole.

</details>


### [158] [AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs](https://arxiv.org/abs/2506.18628)
*Piotr Matys,Jan Eliasz,Konrad Kiełczyński,Mikołaj Langner,Teddy Ferdinan,Jan Kocoń,Przemysław Kazienko*

Main category: cs.AI

TL;DR: 本文提出AggTruth方法，通过分析上下文注意力分数分布在线检测大语言模型(LLM)的幻觉问题，四种变体在不同场景下均优于现有技术，并证明注意力头选择对性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 大语言模型(LLM)在实际应用中常产生幻觉问题，即使在检索增强生成(RAG)场景下仍存在挑战，亟需有效的在线检测方法。

Method: 提出AggTruth方法，通过四种不同的注意力分数聚合技术分析上下文分布，并深入研究特征选择及注意力头数量对检测性能的影响。

Result: 在所有测试LLM中，AggTruth在同任务和跨任务场景均表现稳定，多项指标超越当前最优方法(SOTA)，注意力头选择对结果有显著影响。

Conclusion: 研究表明基于注意力机制的在线幻觉检测具有可行性，精心设计的注意力头选择策略可显著提升检测性能，为LLM部署提供重要技术支撑。

Abstract: In real-world applications, Large Language Models (LLMs) often hallucinate,
even in Retrieval-Augmented Generation (RAG) settings, which poses a
significant challenge to their deployment. In this paper, we introduce
AggTruth, a method for online detection of contextual hallucinations by
analyzing the distribution of internal attention scores in the provided context
(passage). Specifically, we propose four different variants of the method, each
varying in the aggregation technique used to calculate attention scores. Across
all LLMs examined, AggTruth demonstrated stable performance in both same-task
and cross-task setups, outperforming the current SOTA in multiple scenarios.
Furthermore, we conducted an in-depth analysis of feature selection techniques
and examined how the number of selected attention heads impacts detection
performance, demonstrating that careful selection of heads is essential to
achieve optimal results.

</details>


### [159] [Dual-level Behavioral Consistency for Inter-group and Intra-group Coordination in Multi-Agent Systems](https://arxiv.org/abs/2506.18651)
*Shuocun Yang,Huawen Hu,Enze Shi,Shu Zhang*

Main category: cs.AI

TL;DR: 本文提出双层级行为一致性(DLBC)方法，通过动态调节组内与组间行为多样性，提升多智能体强化学习中的分工与合作效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注组内行为一致性，而忽视了多智能体分组场景中的行为调控需求，亟需一种能同时管理组内与组间行为的方法。

Method: DLBC将智能体分组后，通过组间一致性约束不同组的行为策略实现分工，通过组内一致性对齐组内行为策略促进合作，并直接约束策略函数以保证算法普适性。

Result: 实验表明DLBC显著提升了组内合作性能与组间任务专精化，在多种分组合作场景中取得实质性性能改进。

Conclusion: DLBC为多智能体系统行为调控提供了新思路，未来可探索其在更复杂任务和动态环境中的应用潜力。

Abstract: Behavioral diversity in Multi-agent reinforcement learning(MARL) represents
an emerging and promising research area. Prior work has largely centered on
intra-group behavioral consistency in multi-agent systems, with limited
attention given to behavioral consistency in multi-agent grouping scenarios. In
this paper, we introduce Dual-Level Behavioral Consistency (DLBC), a novel MARL
control method designed to explicitly regulate agent behaviors at both
intra-group and inter-group levels. DLBC partitions agents into distinct groups
and dynamically modulates behavioral diversity both within and between these
groups. By dynamically modulating behavioral diversity within and between these
groups, DLBC achieves enhanced division of labor through inter-group
consistency, which constrains behavioral strategies across different groups.
Simultaneously, intra-group consistency, achieved by aligning behavioral
strategies within each group, fosters stronger intra-group cooperation.
Crucially, DLBC's direct constraint of agent policy functions ensures its broad
applicability across various algorithmic frameworks. Experimental results in
various grouping cooperation scenarios demonstrate that DLBC significantly
enhances both intra-group cooperative performance and inter-group task
specialization, yielding substantial performance improvements. DLBC provides
new ideas for behavioral consistency control of multi-intelligent body systems,
and its potential for application in more complex tasks and dynamic
environments can be further explored in the future.

</details>


### [160] [Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training](https://arxiv.org/abs/2506.18777)
*Jonathan Cook,Silvia Sapora,Arash Ahmadian,Akbir Khan,Tim Rocktaschel,Jakob Foerster,Laura Ruis*

Main category: cs.AI

TL;DR: 研究发现仅通过源代码训练（无需输入输出示例）可使大语言模型（LLMs）具备程序评估能力，这种"反向传播编程"（PBB）机制能帮助模型内化可复用的算法抽象，从而增强推理能力。


<details>
  <summary>Details</summary>
Motivation: 探索代码训练提升LLMs通用推理能力的机制，提出"反向传播编程"（PBB）假说——仅通过源代码（无I/O示例）训练即可使模型学会程序评估。

Method: 微调LLMs处理两类程序（数学问题/算法）：一组含源代码+I/O示例（w/ IO），另一组仅含源代码（w/o IO）。对比模型在代码形式vs自然语言描述、直接生成vs思维链步进等场景下的表现。

Result: 1) PBB在代码形式下效果显著优于自然语言描述；2) LLMs能通过前向传播隐式评估w/o IO程序，思维链步进可提升可靠性；3) PBB比基于数据分布I/O训练的程序评估更具鲁棒性。

Conclusion: 代码训练通过PBB机制使LLMs内化算法抽象从而增强推理。未来需提升模型从符号化流程中学习的能力，该方向进展可拓展至基于形式化原则的模型对齐等应用。

Abstract: Training large language models (LLMs) on source code significantly enhances
their general-purpose reasoning abilities, but the mechanisms underlying this
generalisation are poorly understood. In this paper, we propose Programming by
Backprop (PBB) as a potential driver of this effect - teaching a model to
evaluate a program for inputs by training on its source code alone, without
ever seeing I/O examples. To explore this idea, we finetune LLMs on two sets of
programs representing simple maths problems and algorithms: one with source
code and I/O examples (w/ IO), the other with source code only (w/o IO). We
find evidence that LLMs have some ability to evaluate w/o IO programs for
inputs in a range of experimental settings, and make several observations.
Firstly, PBB works significantly better when programs are provided as code
rather than semantically equivalent language descriptions. Secondly, LLMs can
produce outputs for w/o IO programs directly, by implicitly evaluating the
program within the forward pass, and more reliably when stepping through the
program in-context via chain-of-thought. We further show that PBB leads to more
robust evaluation of programs across inputs than training on I/O pairs drawn
from a distribution that mirrors naturally occurring data. Our findings suggest
a mechanism for enhanced reasoning through code training: it allows LLMs to
internalise reusable algorithmic abstractions. Significant scope remains for
future work to enable LLMs to more effectively learn from symbolic procedures,
and progress in this direction opens other avenues like model alignment by
training on formal constitutional principles.

</details>


### [161] [TRIZ Agents: A Multi-Agent LLM Approach for TRIZ-Based Innovation](https://arxiv.org/abs/2506.18783)
*Kamil Szczepanik,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 本文提出了一种基于大型语言模型（LLM）的多智能体系统（TRIZ agents），通过协作解决TRIZ创新问题，展示了在复杂工程案例中分散式问题解决的优势。


<details>
  <summary>Details</summary>
Motivation: TRIZ理论虽为创新提供结构化框架，但其应用常受限于跨学科知识的高复杂度。大型语言模型的发展为自动化部分流程提供了新可能，但现有研究仅探索单一模型。本文旨在通过多智能体协作突破这一局限。

Method: 设计基于LLM的多智能体系统（TRIZ agents），每个智能体具备专业领域能力与工具访问权限，依据TRIZ方法论协作解决创新问题。通过工程案例评估团队效能。

Result: 案例研究表明，多智能体协作能高效完成TRIZ流程步骤，并产生多样化的创新解决方案，验证了分散式智能体在复杂构思任务中的潜力。

Conclusion: 该研究为AI驱动的创新提供了新范式，证明多智能体协作在解决跨学科复杂问题时的优越性，推动了TRIZ理论的自动化应用发展。

Abstract: TRIZ, the Theory of Inventive Problem Solving, is a structured,
knowledge-based framework for innovation and abstracting problems to find
inventive solutions. However, its application is often limited by the
complexity and deep interdisciplinary knowledge required. Advancements in Large
Language Models (LLMs) have revealed new possibilities for automating parts of
this process. While previous studies have explored single LLMs in TRIZ
applications, this paper introduces a multi-agent approach. We propose an
LLM-based multi-agent system, called TRIZ agents, each with specialized
capabilities and tool access, collaboratively solving inventive problems based
on the TRIZ methodology. This multi-agent system leverages agents with various
domain expertise to efficiently navigate TRIZ steps. The aim is to model and
simulate an inventive process with language agents. We assess the effectiveness
of this team of agents in addressing complex innovation challenges based on a
selected case study in engineering. We demonstrate the potential of agent
collaboration to produce diverse, inventive solutions. This research
contributes to the future of AI-driven innovation, showcasing the advantages of
decentralized problem-solving in complex ideation tasks.

</details>


### [162] [ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation](https://arxiv.org/abs/2506.18810)
*Siao Tang,Xinyin Ma,Gongfan Fang,Xinchao Wang*

Main category: cs.AI

TL;DR: 本文提出ConciseHint框架，通过生成过程中注入文本提示来优化大型推理模型的冗长问题，在保持性能的同时显著缩短推理长度。


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型（如DeepSeek-R1）在链式推理（CoT）中普遍存在过度冗长问题，而传统方法仅关注推理前优化，忽略了生成过程中的干预潜力。

Method: 提出动态提示框架ConciseHint：1) 在token生成时注入人工设计或数据训练的简洁提示 2) 根据问题复杂度自适应调整提示强度 3) 兼容主流LRMs模型架构。

Result: 在GSM8K基准测试中，Qwen-3 4B模型的推理长度减少65%且精度无损，DeepSeek-R1等SOTA模型同样验证了有效性。

Conclusion: ConciseHint首次实现推理过程中的动态简洁化干预，为提升大型语言模型效率开辟了新方向，且不影响原有推理能力。

Abstract: Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and
OpenAI o1 series have achieved notable performance enhancements on complex
reasoning tasks by scaling up the generation length by Chain-of-Thought (CoT).
However, an emerging issue is their inclination to produce excessively verbose
reasoning processes, leading to the inefficiency problem. Existing literature
on improving efficiency mainly adheres to the before-reasoning paradigms such
as prompting and reasoning or fine-tuning and reasoning, but ignores the
promising direction of directly encouraging the model to speak concisely by
intervening during the generation of reasoning. In order to fill the blank, we
propose a framework dubbed ConciseHint, which continuously encourages the
reasoning model to speak concisely by injecting the textual hint (manually
designed or trained on the concise data) during the token generation of the
reasoning process. Besides, ConciseHint is adaptive to the complexity of the
query by adaptively adjusting the hint intensity, which ensures it will not
undermine model performance. Experiments on the state-of-the-art LRMs,
including DeepSeek-R1 and Qwen-3 series, demonstrate that our method can
effectively produce concise reasoning processes while maintaining performance
well. For instance, we achieve a reduction ratio of 65\% for the reasoning
length on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.

</details>


### [163] [Steering Conceptual Bias via Transformer Latent-Subspace Activation](https://arxiv.org/abs/2506.18887)
*Vansh Sharma,Venkat Raman*

Main category: cs.AI

TL;DR: 本研究开发了梯度优化的自适应激活导向框架(G-ACT)，通过激活语言模型(LLMs)的潜在子空间，有效引导科学代码生成偏向特定编程语言(如C++)，相比传统方法显著提升了分类准确率和层间导向效率。


<details>
  <summary>Details</summary>
Motivation: 现有静态神经元归因方法在引导LLMs生成特定编程语言时存在脆弱性和泛化性不足的问题，需要开发更鲁棒、可扩展的导向机制来实现概念级控制。

Method: 提出G-ACT框架：1) 聚类每提示的激活差异为少量导向向量；2) 在线训练轻量级逐层探针并优化；3) 选择性在关键层进行定向注入，仅导向部分层以保持推理效率。

Result: 在LLaMA-3.2 3B中，平均探针分类准确率提升15%，前7层准确率提升61.5%；对于LLaMA-3.3 70B模型，关键层定向注入仍能改善语言选择，尽管注意力信号更分散。

Conclusion: G-ACT为实际智能体系统提供了可扩展、可解释且高效的概念控制机制，通过部分层导向平衡性能与开销，实现了可复现的模型行为控制。

Abstract: This work examines whether activating latent subspaces in language models
(LLMs) can steer scientific code generation toward a specific programming
language. Five causal LLMs were first evaluated on scientific coding prompts to
quantify their baseline bias among four programming languages. A static
neuron-attribution method, perturbing the highest activated MLP weight for a
C++ or CPP token, proved brittle and exhibited limited generalization across
prompt styles and model scales. To address these limitations, a
gradient-refined adaptive activation steering framework (G-ACT) was developed:
per-prompt activation differences are clustered into a small set of steering
directions, and lightweight per-layer probes are trained and refined online to
select the appropriate steering vector. In LLaMA-3.2 3B, this approach reliably
biases generation towards the CPP language by increasing the average probe
classification accuracy by 15% and the early layers (0-6) improving the probe
classification accuracy by 61.5% compared to the standard ACT framework. For
LLaMA-3.3 70B, where attention-head signals become more diffuse, targeted
injections at key layers still improve language selection. Although per-layer
probing introduces a modest inference overhead, it remains practical by
steering only a subset of layers and enables reproducible model behavior. These
results demonstrate a scalable, interpretable and efficient mechanism for
concept-level control for practical agentic systems.

</details>


### [164] [jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval](https://arxiv.org/abs/2506.18902)
*Michael Günther,Saba Sturua,Mohammad Kalim Akram,Isabelle Mohr,Andrei Ungureanu,Sedigheh Eslami,Scott Martens,Bo Wang,Nan Wang,Han Xiao*

Main category: cs.AI

TL;DR: 本文介绍了jina-embeddings-v4，一个38亿参数的多模态嵌入模型，通过新颖架构统一文本和图像表示，支持单向量和多向量嵌入，并在多种检索任务中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够统一文本和图像表示的多模态嵌入模型，以优化跨模态检索任务，特别是在处理视觉丰富内容方面的性能。

Method: 采用新颖的架构支持单向量和多向量嵌入，结合任务特定的低秩适应（LoRA）适配器，优化不同检索场景的性能。

Result: jina-embeddings-v4在单模态和跨模态检索任务中均达到最先进性能，尤其在处理表格、图表、图表和混合媒体格式等视觉丰富内容方面表现突出。

Conclusion: jina-embeddings-v4在多模态嵌入和检索任务中表现出色，特别是针对视觉丰富内容的处理能力，为相关领域的研究和应用提供了有力工具。

Abstract: We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding
model that unifies text and image representations through a novel architecture
supporting both single-vector and multi-vector embeddings in the late
interaction style. The model incorporates task-specific Low-Rank Adaptation
(LoRA) adapters to optimize performance across diverse retrieval scenarios,
including query-based information retrieval, cross-modal semantic similarity,
and programming code search. Comprehensive evaluations demonstrate that
jina-embeddings-v4 achieves state-of-the-art performance on both single- modal
and cross-modal retrieval tasks, with particular strength in processing
visually rich content such as tables, charts, diagrams, and mixed-media
formats. To facilitate evaluation of this capability, we also introduce
Jina-VDR, a novel benchmark specifically designed for visually rich image
retrieval.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [165] [Distribution of codewords on the faces of a hypercube and new combinatorial identities](https://arxiv.org/abs/2506.18494)
*Jamolidin K. Abdurakhmanov*

Main category: cs.DM

TL;DR: 本文提出了一种通过q值立方体中子集分布的几何视角研究组合恒等式的新框架，揭示了新的具有几何意义的组合恒等式，并提供了经典恒等式的几何解释。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于通过几何视角理解组合恒等式，探索子集在q值立方体中的分布规律，从而发现新的组合关系并重新解释经典结果。

Method: 方法包括分析子集在$E_q^n$立方体各面上的分布，建立子集秩函数的精确计算，并通过参数化恒等式族连接k维面包含子集元素的数量与二项式求和。

Result: 主要结果包括：证明了奇数基数子集的秩函数下界为$4D_A/(|A|^2-1)$；建立了连接k维面元素分布与二项式求和的恒等式；获得了偶权向量的新恒等式$(2^{k-1}-1)\times2^{n-1}\times\binom{n}{k}=\sum_{i=1}^{\lfloor n/2\rfloor}\binom{n}{2i}\binom{n-2i}{k-2i}$。

Conclusion: 该框架通过子集秩分析提供了生成新恒等式和理解现有恒等式的统一方法，证明了几何视角能揭示隐藏的组合关系，范德蒙恒等式等经典结果自然涌现为特例。

Abstract: We present a novel framework for studying combinatorial identities through
the geometric lens of subset distributions in q-valued cubes. By analyzing how
elements of arbitrary subsets are distributed among the faces of the cube
E_q^n, we discover new combinatorial identities with geometric significance. We
prove that for any subset A contained in E_2^n, the rank function satisfies
refined bounds that lead to exact computations for small cardinalities.
Specifically, we show that for odd cardinalities, the lower bound is
4D_A/(|A|^2-1) where D_A is the sum of all pairwise Hamming distances in A. Our
main theorem establishes identities connecting the number of k-dimensional
faces containing exactly e elements of a subset to binomial sums over all
subsets of specified cardinality. This yields a parametric family of identities
where classical results emerge as special cases. As applications, we derive a
geometric interpretation of Vandermonde's identity by examining faces of
q-valued cubes, revealing that this classical result naturally arises from
counting element distributions. We also obtain a completely new identity for
even-weight vectors: (2^(k-1) - 1) times 2^(n-1) times binomial(n,k) equals the
sum over i from 1 to floor(n/2) of binomial(n,2i) times binomial(n-2i,k-2i).
This identity, valid for all 1 <= k <= n, demonstrates how geometric
perspectives can uncover hidden combinatorial relationships. Our framework
provides a unified approach for generating new identities and understanding
existing ones through subset rank analysis.

</details>


### [166] [Perfect phylogenies via the Minimum Uncovering Branching problem: efficiently solvable cases](https://arxiv.org/abs/2506.18578)
*Narmina Baghirova,Esther Galby,Martin Milanič*

Main category: cs.DM

TL;DR: 本文解决了最小覆盖分支问题在有限宽度实例中的多项式时间可解性，通过将其转化为二分图最大匹配和偏序集最大权反链问题，并提出了新的多项式时间可计算下界。


<details>
  <summary>Details</summary>
Motivation: 最小覆盖分支问题在癌症基因组学中有重要应用，此前研究已证明其在有限高度实例中是APX完全的，但在有限宽度实例中的精确复杂度尚未解决。

Method: 通过分析最优解的结构特性，将问题转化为二分图最大匹配和偏序集最大权反链计算，并引入新的多项式时间可计算下界。

Result: 证明了该问题在有限宽度实例中具有多项式时间算法，填补了此前研究的空白。

Conclusion: 本研究不仅解决了最小覆盖分支问题的关键开放性问题，还为相关优化问题提供了新的计算工具和理论框架。

Abstract: In this paper, we present new efficiently solvable cases of the Minimum
Uncovering Branching problem, an optimization problem with applications in
cancer genomics introduced by Hujdurovi\'c, Husi\'c, Milani\v{c}, Rizzi, and
Tomescu in 2018. The problem involves a family of finite sets, and the goal is
to map each non-maximal set to exactly one set that contains it, minimizing the
sum of uncovered elements across all sets in the family. Hujdurovi\'c et al.
formulated the problem in terms of branchings of the digraph formed by the
proper set inclusion relation on the input sets and studied the problem
complexity based on properties of the corresponding partially ordered set, in
particular, with respect to its height and width, defined respectively as the
maximum cardinality of a chain and an antichain. They showed that the problem
is APX-complete for instances of bounded height and that a constant-factor
approximation algorithm exists for instances of bounded width, but left the
exact complexity for bounded-width instances open. In this paper, we answer
this question by proving that the problem is solvable in polynomial time. We
derive this result by examining the structural properties of optimal solutions
and reducing the problem to computing maximum matchings in bipartite graphs and
maximum weight antichains in partially ordered sets. We also introduce a new
polynomially computable lower bound and identify another condition for
polynomial-time solvability.

</details>
