{"id": "2507.17541", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.17541", "abs": "https://arxiv.org/abs/2507.17541", "authors": ["Vilhelm Agdur", "Jessica Enright", "Laura Larios-Jones", "Kitty Meeks", "Fiona Skerman", "Ella Yates"], "title": "Approximating temporal modularity on graphs of small underlying treewidth", "comment": null, "summary": "Modularity is a very widely used measure of the level of clustering or\ncommunity structure in networks. Here we consider a recent generalisation of\nthe definition of modularity to temporal graphs, whose edge-sets change over\ndiscrete timesteps; such graphs offer a more realistic model of many real-world\nnetworks in which connections between entities (for example, between\nindividuals in a social network) evolve over time. Computing modularity is\nnotoriously difficult: it is NP-hard even to approximate in general, and only\nadmits efficient exact algorithms in very restricted special cases. Our main\nresult is that a multiplicative approximation to temporal modularity can be\ncomputed efficiently when the underlying graph has small treewidth. This\ngeneralises a similar approximation algorithm for the static case, but requires\nsome substantially new ideas to overcome technical challenges associated with\nthe temporal nature of the problem."}
{"id": "2507.17162", "categories": ["q-fin.CP", "q-fin.MF", "q-fin.PM", "q-fin.TR", "91G10 (Primary), 93E20, 60H10 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.17162", "abs": "https://arxiv.org/abs/2507.17162", "authors": ["Patrick Chan", "Ronnie Sircar", "Iosif Zimbidis"], "title": "Optimal Trading under Instantaneous and Persistent Price Impact, Predictable Returns and Multiscale Stochastic Volatility", "comment": null, "summary": "We consider a dynamic portfolio optimization problem that incorporates\npredictable returns, instantaneous transaction costs, price impact, and\nstochastic volatility, extending the classical results of Garleanu and Pedersen\n(2013), which assume constant volatility. Constructing the optimal portfolio\nstrategy in this general setting is challenging due to the nonlinear nature of\nthe resulting Hamilton-Jacobi-Bellman (HJB) equations. To address this, we\npropose a multi-scale volatility expansion that captures stochastic volatility\ndynamics across different time scales. Specifically, the analysis involves a\nsingular perturbation for the fast mean-reverting volatility factor and a\nregular perturbation for the slow-moving factor. We also introduce an\napproximation for small price impact and demonstrate its numerical accuracy. We\nformally derive asymptotic approximations up to second order and use Monte\nCarlo simulations to show how incorporating these corrections improves the\nProfit and Loss (PnL) of the resulting portfolio strategy."}
{"id": "2507.16823", "categories": ["math.HO", "68T20", "I.2.1"], "pdf": "https://arxiv.org/pdf/2507.16823", "abs": "https://arxiv.org/abs/2507.16823", "authors": ["Michael Young"], "title": "Collapsi is strongly solved", "comment": "3 pages, 4 figures", "summary": "Collapsi is a two-player game of complete information released in June 2025\nby Mark S. Ball of Riffle Shuffle & Roll. Played with two pawns on a toroidal\nboard of 16 randomly mixed playing cards, players take it in turns to move\nbased on the value of the card they sit on, with the game ending when a player\nhas no legal moves. The number of possible deals after symmetry breaking is low\nenough, and the game tree shallow enough, to make an exhaustive analysis of the\ngame feasible. A solver was written that can find an optimal move for a given\nboard position in around 20 milliseconds. A search was applied revealing that\nthe first player can force a win in 37.5% of deals, with the second player able\nto force a win in all others. In 6.4% of deals the losing player can prolong\nthe game to the maximum length of 14 plies; a win can never be forced in fewer\nthan 7 plies."}
{"id": "2507.16985", "categories": ["math.LO", "math.GR", "03C52 20B27 20B10"], "pdf": "https://arxiv.org/pdf/2507.16985", "abs": "https://arxiv.org/abs/2507.16985", "authors": ["Bertalan Bodor"], "title": "Structures with not too fast unlabelled growth", "comment": null, "summary": "Let $\\mathscr{S}$ be the class of all structures whose growth rate on orbits\nof subsets of size $n$ is not faster than $\\frac{2^n}{p(n)}$ for any polynomial\n$p$. In this article we give a complete classification of all structures in\n$\\mathscr{S}$ in terms of their automorphism groups. As a consequence of our\nclassification we show that $\\mathscr{S}$ has only countably many structures up\nto bidefinability, all these structures are first-order interpretable in\n$(\\mathbb{Q};<)$ and they are interdefinable with a finitely bounded\nhomogeneous structure. Furthermore, we also show that all structures in\n$\\mathscr{S}$ have finitely many first-order reduct up to interdefinability,\nthereby confirming Thomas' conjecture for the class $\\mathscr{S}$."}
{"id": "2507.16827", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.16827", "abs": "https://arxiv.org/abs/2507.16827", "authors": ["Bijay Raj Bhatta"], "title": "Parameter Height bounds for the Zilber Pink conjecture for PEL types III and IV", "comment": null, "summary": "We prove the Zilber-Pink conjecture to the intersection of an irreducible\nHodge generic algebraic subvariety $ V \\subset \\mathcal{A}_g$ with special\nsubvarieties of all simple PEL types other than $\\mathbb{Z}$, under the\nassumption of the Large Galois Orbits conjecture. In particular, we establish\nparameter height bounds for the arithmetic ingredients of the Pila-Zannier\nstrategy in the case of Albert types III and IV. This paper is a sequel to Daw\nand Orr's paper \"Lattices with skew-Hermitian forms over division algebras and\nunlikely intersections\" 2023."}
{"id": "2507.16998", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.16998", "abs": "https://arxiv.org/abs/2507.16998", "authors": ["Claudio Agostinelli", "Ayanendranath Basu", "Giulia Bertagnolli", "Arun Kumar Kuchibhotla"], "title": "A Weighted Likelihood Approach Based on Statistical Data Depths", "comment": null, "summary": "We propose a general approach to construct weighted likelihood estimating\nequations with the aim of obtaining robust parameter estimates. We modify the\nstandard likelihood equations by incorporating a weight that reflects the\nstatistical depth of each data point relative to the model, as opposed to the\nsample. An observation is considered regular when the corresponding difference\nof these two depths is close to zero. When this difference is large the\nobservation score contribution is downweighted. We study the asymptotic\nproperties of the proposed estimator, including consistency and asymptotic\nnormality, for a broad class of weight functions. In particular, we establish\nasymptotic normality under the standard regularity conditions typically assumed\nfor the maximum likelihood estimator (MLE). Our weighted likelihood estimator\nachieves the same asymptotic efficiency as the MLE in the absence of\ncontamination, while maintaining a high degree of robustness in contaminated\nsettings. In stark contrast to the traditional minimum divergence/disparity\nestimators, our results hold even if the dimension of the data diverges with\nthe sample size, without requiring additional assumptions on the existence or\nsmoothness of the underlying densities. We also derive the finite sample\nbreakdown point of our estimator for both location and scatter matrix in the\nelliptically symmetric model. Detailed results and examples are presented for\nrobust parameter estimation in the multivariate normal model. Robustness is\nfurther illustrated using two real data sets and a Monte Carlo simulation\nstudy."}
{"id": "2507.17012", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2507.17012", "abs": "https://arxiv.org/abs/2507.17012", "authors": ["Zhihan Zhang", "Alexander Metzger", "Yuxuan Mei", "Felix Hähnlein", "Zachary Englhardt", "Tingyu Cheng", "Gregory D. Abowd", "Shwetak Patel", "Adriana Schulz", "Vikram Iyer"], "title": "Towards Autonomous Sustainability Assessment via Multimodal AI Agents", "comment": null, "summary": "Interest in sustainability information has surged in recent years. However,\nthe data required for a life cycle assessment (LCA) that maps the materials and\nprocesses from product manufacturing to disposal into environmental impacts\n(EI) are often unavailable. Here we reimagine conventional LCA by introducing\nmultimodal AI agents that emulate interactions between LCA experts and\nstakeholders like product managers and engineers to calculate the\ncradle-to-gate (production) carbon emissions of electronic devices. The AI\nagents iteratively generate a detailed life-cycle inventory leveraging a custom\ndata abstraction and software tools that extract information from online text\nand images from repair communities and government certifications. This approach\nreduces weeks or months of expert time to under one minute and closes data\navailability gaps while yielding carbon footprint estimates within 19% of\nexpert LCAs with zero proprietary data. Additionally, we develop a method to\ndirectly estimate EI by comparing an input to a cluster of products with\nsimilar descriptions and known carbon footprints. This runs in 3 ms on a laptop\nwith a MAPE of 12.28% on electronic products. Further, we develop a data-driven\nmethod to generate emission factors. We use the properties of an unknown\nmaterial to represent it as a weighted sum of emission factors for similar\nmaterials. Compared to human experts picking the closest LCA database entry,\nthis improves MAPE by 120.26%. We analyze the data and compute scaling of this\napproach and discuss its implications for future LCA workflows."}
{"id": "2507.16825", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.16825", "abs": "https://arxiv.org/abs/2507.16825", "authors": ["Wei-Wei Qi"], "title": "A q-Supercongruence Motivated by Higher-Order Generalized Lehmer-Euler Numbers", "comment": null, "summary": "Certain generalization of Euler numbers was defined in 1935 by Lehmer using\ncubic roots of unity, as a natural generalization of Bernoulli and Euler\nnumbers. In this paper, we define a new polynomial related to the higher-order\ngeneralized Lehmer-Euler numbers and determine its a q-supercongruence."}
{"id": "2507.16840", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16840", "abs": "https://arxiv.org/abs/2507.16840", "authors": ["Weijia Yang", "Tian Lan", "Leyuan Liu", "Wei Chen", "Tianqing Zhu", "Sheng Wen", "Xiaosong Zhang"], "title": "CASPER: Contrastive Approach for Smart Ponzi Scheme Detecter with More Negative Samples", "comment": null, "summary": "The rapid evolution of digital currency trading, fueled by the integration of\nblockchain technology, has led to both innovation and the emergence of smart\nPonzi schemes. A smart Ponzi scheme is a fraudulent investment operation in\nsmart contract that uses funds from new investors to pay returns to earlier\ninvestors. Traditional Ponzi scheme detection methods based on deep learning\ntypically rely on fully supervised models, which require large amounts of\nlabeled data. However, such data is often scarce, hindering effective model\ntraining. To address this challenge, we propose a novel contrastive learning\nframework, CASPER (Contrastive Approach for Smart Ponzi detectER with more\nnegative samples), designed to enhance smart Ponzi scheme detection in\nblockchain transactions. By leveraging contrastive learning techniques, CASPER\ncan learn more effective representations of smart contract source code using\nunlabeled datasets, significantly reducing both operational costs and system\ncomplexity. We evaluate CASPER on the XBlock dataset, where it outperforms the\nbaseline by 2.3% in F1 score when trained with 100% labeled data. More\nimpressively, with only 25% labeled data, CASPER achieves an F1 score nearly\n20% higher than the baseline under identical experimental conditions. These\nresults highlight CASPER's potential for effective and cost-efficient detection\nof smart Ponzi schemes, paving the way for scalable fraud detection solutions\nin the future."}
{"id": "2507.17162", "categories": ["q-fin.CP", "q-fin.MF", "q-fin.PM", "q-fin.TR", "91G10 (Primary), 93E20, 60H10 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.17162", "abs": "https://arxiv.org/abs/2507.17162", "authors": ["Patrick Chan", "Ronnie Sircar", "Iosif Zimbidis"], "title": "Optimal Trading under Instantaneous and Persistent Price Impact, Predictable Returns and Multiscale Stochastic Volatility", "comment": null, "summary": "We consider a dynamic portfolio optimization problem that incorporates\npredictable returns, instantaneous transaction costs, price impact, and\nstochastic volatility, extending the classical results of Garleanu and Pedersen\n(2013), which assume constant volatility. Constructing the optimal portfolio\nstrategy in this general setting is challenging due to the nonlinear nature of\nthe resulting Hamilton-Jacobi-Bellman (HJB) equations. To address this, we\npropose a multi-scale volatility expansion that captures stochastic volatility\ndynamics across different time scales. Specifically, the analysis involves a\nsingular perturbation for the fast mean-reverting volatility factor and a\nregular perturbation for the slow-moving factor. We also introduce an\napproximation for small price impact and demonstrate its numerical accuracy. We\nformally derive asymptotic approximations up to second order and use Monte\nCarlo simulations to show how incorporating these corrections improves the\nProfit and Loss (PnL) of the resulting portfolio strategy."}
{"id": "2507.16821", "categories": ["math.GM", "11N36, 11N05", "F.2.1"], "pdf": "https://arxiv.org/pdf/2507.16821", "abs": "https://arxiv.org/abs/2507.16821", "authors": ["Paul Alexander Bilokon"], "title": "Imbalance Prime Sieving: Every Prime Gap Is a Result of a Möbius Imbalance Obstruction", "comment": "10 pages, code in public domain on GitHub", "summary": "We introduce a novel sieve for prime numbers based on detecting topological\nobstructions in a M\\\"obius-transformed rational metric space. Unlike\ntraditional sieves which rely on divisibility, our method identifies primes as\nthose numbers which contribute new, non-colliding imbalance conjugates. This\nprovides both an exact algorithm for prime enumeration and a new geometric\ninterpretation of prime gaps. This sieve constructs a topological obstruction\ntheory over rational pairs (p, q), from which we observe that every prime gap\nis a consequence of a collision in this transformed imbalance space. Our\nempirical results demonstrate that this method precisely filters the prime\nnumbers up to a specified bound, with potential implications for new\nnumber-theoretic models and sieving algorithms."}
{"id": "2507.17606", "categories": ["q-fin.CP", "cs.LG", "math.PR", "q-fin.MF", "91G20, 91G60, 68T07"], "pdf": "https://arxiv.org/pdf/2507.17606", "abs": "https://arxiv.org/abs/2507.17606", "authors": ["Jasper Rou"], "title": "Time Deep Gradient Flow Method for pricing American options", "comment": "13 pages, 6 figures", "summary": "In this research, we explore neural network-based methods for pricing\nmultidimensional American put options under the BlackScholes and Heston model,\nextending up to five dimensions. We focus on two approaches: the Time Deep\nGradient Flow (TDGF) method and the Deep Galerkin Method (DGM). We extend the\nTDGF method to handle the free-boundary partial differential equation inherent\nin American options. We carefully design the sampling strategy during training\nto enhance performance. Both TDGF and DGM achieve high accuracy while\noutperforming conventional Monte Carlo methods in terms of computational speed.\nIn particular, TDGF tends to be faster during training than DGM."}
{"id": "2507.17090", "categories": ["math.LO", "math.CA", "34M15, 12H05, 03C69"], "pdf": "https://arxiv.org/pdf/2507.17090", "abs": "https://arxiv.org/abs/2507.17090", "authors": ["Yutong Duan", "Christine Eagles", "Léo Jimenez"], "title": "Algebraic independence of solutions to multiple Lotka-Volterra systems", "comment": "23 pages", "summary": "Consider some non-zero complex numbers $a_i, b_i, c_i, d_i$ with $1 \\leq i\n\\leq n$ and the associated classical Lotka-Volterra systems\n  \\[\n  \\begin{cases}\n  x' = a_i xy + b_i y \\newline\n  y' = c_i xy + d_i y \\text{ .}\n  \\end{cases}\n  \\] We show that as long as $b_i \\neq d_i$ for all $i$ and $\\{ b_i, d_i\\} \\neq\n\\{ b_j, d_j\\}$ for $i \\neq j$, any tuples $(x_1,y_1) , \\cdots , (x_m,y_m)$ of\npairwise distinct, non-degenerate solutions of these systems are algebraically\nindependent over $\\mathbb{C}$, meaning $\\mathrm{trdeg}((x_1,y_1) , \\cdots ,\n(x_m,y_m)/\\mathbb{C}) = 2m$. Our proof relies on extending recent work of Duan\nand Nagloo by showing strong minimality of these systems, as long as $b_i \\neq\nd_i$. We also generalize a theorem of Brestovski which allows us to control\nalgebraic relations using invariant volume forms. Finally, we completely\nclassify all invariant algebraic curves in the non-strongly minimal, $b_i =\nd_i$ case by using machinery from geometric stability theory."}
{"id": "2507.16828", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.16828", "abs": "https://arxiv.org/abs/2507.16828", "authors": ["Jialai She"], "title": "Nonexistence of Consecutive Powerful Triplets Around Cubes with Prime-Square Factors", "comment": null, "summary": "The Erd\\H{o}s-Mollin-Walsh conjecture, asserting the nonexistence of three\nconsecutive powerful integers, remains a celebrated open problem in number\ntheory. A natural line of inquiry, following recent work by Chan (2025), is to\ninvestigate potential counterexamples centered around perfect cubes, which are\nthemselves powerful. This paper establishes a new non-existence result for a\nfamily of such integer triplets with distinct structural constraints, combining\ntechniques from modular arithmetic, $p$-adic valuation, and the theory of\nelliptic curves."}
{"id": "2507.17073", "categories": ["math.ST", "math.PR", "stat.TH", "62F10, 82B20, 60F05, 91B12"], "pdf": "https://arxiv.org/pdf/2507.17073", "abs": "https://arxiv.org/abs/2507.17073", "authors": ["Miguel Ballesteros", "Ivan Naumkin", "Gabor Toth"], "title": "Approximation Techniques for the Reconstruction of the Probability Measure and the Coupling Parameters in a Curie-Weiss Model for Large Populations", "comment": null, "summary": "The Curie-Weiss model, originally used to study phase transitions in\nstatistical mechanics, has been adapted to model phenomena in social sciences\nwhere many agents interact with each other. Reconstructing the probability\nmeasure of a Curie-Weiss model via the maximum likelihood method runs into the\nproblem of computing the partition function which scales exponentially with the\npopulation. We study the estimation of the coupling parameters of a multi-group\nCurie-Weiss model using large population asymptotic approximations for the\nrelevant moments of the probability distribution in the case that there are no\ninteractions between groups. As a result, we obtain an estimator which can be\ncalculated at a low and constant computational cost for any size of the\npopulation. The estimator is consistent (under the added assumption that the\npopulation is large enough), asymptotically normal, and satisfies large\ndeviation principles. The estimator is potentially useful in political science,\nsociology, automated voting, and in any application where the degree of social\ncohesion in a population has to be identified. The Curie-Weiss model's coupling\nparameters provide a natural measure of social cohesion. We discuss the problem\nof estimating the optimal weights in two-tier voting systems."}
{"id": "2507.17054", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17054", "abs": "https://arxiv.org/abs/2507.17054", "authors": ["Shao-Hung Chan", "Thomy Phan", "Jiaoyang Li", "Sven Koenig"], "title": "New Mechanisms in Flex Distribution for Bounded Suboptimal Multi-Agent Path Finding", "comment": "9 pages, 10 figures, International Symposium on Combinatorial Search,\n  2025", "summary": "Multi-Agent Path Finding (MAPF) is the problem of finding a set of\ncollision-free paths, one for each agent in a shared environment. Its objective\nis to minimize the sum of path costs (SOC), where the path cost of each agent\nis defined as the travel time from its start location to its target location.\nExplicit Estimation Conflict-Based Search (EECBS) is the leading algorithm for\nbounded-suboptimal MAPF, with the SOC of the solution being at most a\nuser-specified factor $w$ away from optimal. EECBS maintains sets of paths and\na lower bound $LB$ on the optimal SOC. Then, it iteratively selects a set of\npaths whose SOC is at most $w \\cdot LB$ and introduces constraints to resolve\ncollisions. For each path in a set, EECBS maintains a lower bound on its\noptimal path that satisfies constraints. By finding an individually\nbounded-suboptimal path with cost at most a threshold of $w$ times its lower\nbound, EECBS guarantees to find a bounded-suboptimal solution. To speed up\nEECBS, previous work uses flex distribution to increase the threshold. Though\nEECBS with flex distribution guarantees to find a bounded-suboptimal solution,\nincreasing the thresholds may push the SOC beyond $w \\cdot LB$, forcing EECBS\nto switch among different sets of paths instead of resolving collisions on a\nparticular set of paths, and thus reducing efficiency. To address this issue,\nwe propose Conflict-Based Flex Distribution that distributes flex in proportion\nto the number of collisions. We also estimate the delays needed to satisfy\nconstraints and propose Delay-Based Flex Distribution. On top of that, we\npropose Mixed-Strategy Flex Distribution, combining both in a hierarchical\nframework. We prove that EECBS with our new flex distribution mechanisms is\ncomplete and bounded-suboptimal. Our experiments show that our approaches\noutperform the original (greedy) flex distribution."}
{"id": "2507.16956", "categories": ["math.CO", "math.NT", "11B85"], "pdf": "https://arxiv.org/pdf/2507.16956", "abs": "https://arxiv.org/abs/2507.16956", "authors": ["Robbert Fokkink", "Gandhar Joshi"], "title": "On Cloitre's hiccup sequences", "comment": null, "summary": "In 2003, Benoit Cloitre entered a bunch of sequences in the OEIS that we call\n\\emph{hiccup} sequences. We collect the various claims, observations, and\nproofs of properties of these sequences that have been entered in the OEIS over\nthe years, and present a unified approach, guided by a remarkable theorem of\nBosma, Dekking, and Steiner."}
{"id": "2507.16852", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16852", "abs": "https://arxiv.org/abs/2507.16852", "authors": ["Álvaro Ruiz-Ródenas", "Jaime Pujante Sáez", "Daniel García-Algora", "Mario Rodríguez Béjar", "Jorge Blasco", "José Luis Hernández-Ramos"], "title": "SynthCTI: LLM-Driven Synthetic CTI Generation to enhance MITRE Technique Mapping", "comment": "17 pages, 13 figures", "summary": "Cyber Threat Intelligence (CTI) mining involves extracting structured\ninsights from unstructured threat data, enabling organizations to understand\nand respond to evolving adversarial behavior. A key task in CTI mining is\nmapping threat descriptions to MITRE ATT\\&CK techniques. However, this process\nis often performed manually, requiring expert knowledge and substantial effort.\nAutomated approaches face two major challenges: the scarcity of high-quality\nlabeled CTI data and class imbalance, where many techniques have very few\nexamples. While domain-specific Large Language Models (LLMs) such as SecureBERT\nhave shown improved performance, most recent work focuses on model architecture\nrather than addressing the data limitations. In this work, we present SynthCTI,\na data augmentation framework designed to generate high-quality synthetic CTI\nsentences for underrepresented MITRE ATT\\&CK techniques. Our method uses a\nclustering-based strategy to extract semantic context from training data and\nguide an LLM in producing synthetic CTI sentences that are lexically diverse\nand semantically faithful. We evaluate SynthCTI on two publicly available CTI\ndatasets, CTI-to-MITRE and TRAM, using LLMs with different capacity.\nIncorporating synthetic data leads to consistent macro-F1 improvements: for\nexample, ALBERT improves from 0.35 to 0.52 (a relative gain of 48.6\\%), and\nSecureBERT reaches 0.6558 (up from 0.4412). Notably, smaller models augmented\nwith SynthCTI outperform larger models trained without augmentation,\ndemonstrating the value of data generation methods for building efficient and\neffective CTI classification systems."}
{"id": "2507.17606", "categories": ["q-fin.CP", "cs.LG", "math.PR", "q-fin.MF", "91G20, 91G60, 68T07"], "pdf": "https://arxiv.org/pdf/2507.17606", "abs": "https://arxiv.org/abs/2507.17606", "authors": ["Jasper Rou"], "title": "Time Deep Gradient Flow Method for pricing American options", "comment": "13 pages, 6 figures", "summary": "In this research, we explore neural network-based methods for pricing\nmultidimensional American put options under the BlackScholes and Heston model,\nextending up to five dimensions. We focus on two approaches: the Time Deep\nGradient Flow (TDGF) method and the Deep Galerkin Method (DGM). We extend the\nTDGF method to handle the free-boundary partial differential equation inherent\nin American options. We carefully design the sampling strategy during training\nto enhance performance. Both TDGF and DGM achieve high accuracy while\noutperforming conventional Monte Carlo methods in terms of computational speed.\nIn particular, TDGF tends to be faster during training than DGM."}
{"id": "2507.16822", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2507.16822", "abs": "https://arxiv.org/abs/2507.16822", "authors": ["Ilona Iglewska-Nowak"], "title": "On the Green function to the Poisson and the Helmholtz equations on the $n$-dimensional unit sphere", "comment": null, "summary": "A new method is presented to obtain a closed form of the generalized Green\nfunction to the Poisson and the Helmholtz equations on the $n$-dimensional unit\nsphere."}
{"id": "2507.17124", "categories": ["math.LO", "03E17, 03E10, 03E35, 03E05, 03E20"], "pdf": "https://arxiv.org/pdf/2507.17124", "abs": "https://arxiv.org/abs/2507.17124", "authors": ["Jorge Antonio Cruz Chapital"], "title": "$κ$-barely independent families and Tukey types of ultrafilters", "comment": "14 pages", "summary": "Given two infinite cardinals $\\kappa$ and $\\lambda$, we introduce and study\nthe notion of a $\\kappa$-barely independent family over $\\lambda.$ We provide\nsome conditions under which these types of families exist. In particular, we\nrelate the existence of large $\\kappa$-barely independent families with the\ngeneralized reaping numbers $\\mathfrak{r}(\\kappa,\\lambda)$ and use these\nrelations to give conditions under which every uniform ultrafilter over a given\ncardinal $\\lambda$ is both Tukey top and has maximal character. Finally, we\nshow that $\\mathfrak{p}>\\omega_1$ the non-existence of barely independent\nfamilies over $\\omega_1.$"}
{"id": "2507.16883", "categories": ["math.NT", "11D41, 11F80, 11R32"], "pdf": "https://arxiv.org/pdf/2507.16883", "abs": "https://arxiv.org/abs/2507.16883", "authors": ["Luis Dieulefait", "Franco Golfieri Madriaga"], "title": "On Fermat's Last Theorem over the $\\mathbb{Z}_3$-extension of $\\mathbb{Q}$ and other fields", "comment": "12 pages", "summary": "The main result of the present article is a proof of Fermat's Last Theorem\nfor sufficiently large prime exponents $p$ with $p \\equiv 2 \\pmod{3}$ over\ncertain number fields. A particular case of these fields are the maximal real\nsubfields of the cyclotomic extensions $\\mathbb{Q}(\\zeta_{3^n})$ for every $n$.\nOur strategy consists in combining the modular method with a generalization of\nan arithmetic result of Pomey to these fields."}
{"id": "2507.17625", "categories": ["math.ST", "math.PR", "stat.TH", "62M10, 37A35, 60F05, 37M10"], "pdf": "https://arxiv.org/pdf/2507.17625", "abs": "https://arxiv.org/abs/2507.17625", "authors": ["Angelika Silbernagel", "Christian Weiß"], "title": "The Joint Asymptotic Distribution of Entropy and Complexity", "comment": "39 pages, 6 figures, 5 tables", "summary": "We derive the asymptotic distribution of ordinal-pattern frequencies under\nweak dependence conditions and investigate the long-run covariance matrix not\nonly analytically for moving-average, Gaussian, and the novel generalized\ncoin-tossing processes, but also approximately by a simulation-based approach.\nThen, we deduce the asymptotic distribution of the entropy-complexity pair,\nwhich emerged as a popular tool for summarizing the time-series dynamics. Here,\nwe make the necessary distinction between a uniform and a non-uniform ordinal\npattern distribution and, thus, obtain two different limit theorems. On this\nbasis, we consider a test for serial dependence and check its finite-sample\nperformance. Moreover, we use our asymptotic results to approximate the\nestimation uncertainty of entropy-complexity pairs."}
{"id": "2507.17075", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17075", "abs": "https://arxiv.org/abs/2507.17075", "authors": ["Yihao Xue", "Baharan Mirzasoleiman"], "title": "LoRA is All You Need for Safety Alignment of Reasoning LLMs", "comment": null, "summary": "Reasoning LLMs have demonstrated remarkable breakthroughs in solving complex\nproblems that were previously out of reach. To ensure LLMs do not assist with\nharmful requests, safety alignment fine-tuning is necessary in the\npost-training phase. However, safety alignment fine-tuning has recently been\nshown to significantly degrade reasoning abilities, a phenomenon known as the\n\"Safety Tax\". In this work, we show that using LoRA for SFT on refusal datasets\neffectively aligns the model for safety without harming its reasoning\ncapabilities. This is because restricting the safety weight updates to a\nlow-rank space minimizes the interference with the reasoning weights. Our\nextensive experiments across four benchmarks covering math, science, and coding\nshow that this approach produces highly safe LLMs -- with safety levels\ncomparable to full-model fine-tuning -- without compromising their reasoning\nabilities. Additionally, we observe that LoRA induces weight updates with\nsmaller overlap with the initial weights compared to full-model fine-tuning. We\nalso explore methods that further reduce such overlap -- via regularization or\nduring weight merging -- and observe some improvement on certain tasks. We hope\nthis result motivates designing approaches that yield more consistent\nimprovements in the reasoning-safety trade-off."}
{"id": "2507.17084", "categories": ["math.CO", "05C10"], "pdf": "https://arxiv.org/pdf/2507.17084", "abs": "https://arxiv.org/abs/2507.17084", "authors": ["Allan Bickle", "Russell Campbell"], "title": "Planar-Toroidal Decomposition of $K_{12}$", "comment": "9 pages", "summary": "In 1978, Anderson and White asked whether there is a decomposition of\n$K_{12}$ into two graphs, one planar and one toroidal. Using theoretical\narguments and a computer search of all maximal planar graphs of order 12, we\nshow that no such decomposition exists. We further show that if $G$ is planar\nof order 12 and $H\\subseteq\\overline{G}$ is toroidal, then $H$ has at least two\nfewer edges than $\\overline{G}$. A computer search found all 123 unique pairs\n$\\left(G,H\\right)$ that make this an equality."}
{"id": "2507.16870", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16870", "abs": "https://arxiv.org/abs/2507.16870", "authors": ["Senthilkumar Gopal"], "title": "Building a robust OAuth token based API Security: A High level Overview", "comment": "11 pages, 5 figures, IEEE Transactions on Dependable and Secure\n  Computing", "summary": "APIs (Application Programming Interfaces) or Web Services are the\nfoundational building blocks that enable interconnected systems. However this\nproliferation of APIs has also introduced security challenges that require\nsystematic and scalable solutions for secure authentication and authorization.\nThis paper presents the fundamentals necessary for building a such a\ntoken-based API security system. It discusses the components necessary, the\nintegration of OAuth 2.0, extensibility of the token architectures, necessary\ncryptographic foundations, and persistence strategies to ensure secure and\nresilient operations. In addition to architectural concerns, the paper explores\nbest practices for token lifecycle management, scope definition, expiration\npolicies, and revocation mechanisms, all framed within a real-world scenario.\nBy adhering to these principles, developers can establish a robust baseline\nwhile maintaining the flexibility to customize their domain-specific\nrequirements. The approach does not claim to cover all variations necessary for\ndiverse architectures but instead focuses on key principles essential for any\nstandard API token authentication system. Throughout, the paper emphasizes\nbalancing practical considerations with security imperatives and uses key\nconcepts such as the CIA triad, OAuth standards, secure token life cycle, and\npractices for protecting sensitive user and application data. The intent is to\nequip developers with the foundational knowledge necessary to build secure,\nscalable token-based API security systems ready to handle the evolving threat\nlandscape."}
{"id": "2507.17503", "categories": ["math.LO", "math.CO", "03E05 (Primary) 03E50, 03E15, 06A05 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.17503", "abs": "https://arxiv.org/abs/2507.17503", "authors": ["Raphaël Carroy", "Maxwell Levine", "Lorenzo Notaro"], "title": "Some questions on entangled linear orders", "comment": "26 pages", "summary": "Entangled linear orders were first introduced by Abraham and Shelah.\nTodor\\v{c}evi\\'c showed that these linear orders exist under $\\mathsf{CH}$. We\nprove the following results: (1) If $\\mathsf{CH}$ holds, then, for every $n >\n0$, there is an $n$-entangled linear order which is not $(n+1)$-entangled. (2)\nIf $\\mathsf{CH}$ holds, then there are two homeomorphic sets of reals $A, B\n\\subseteq \\mathbb{R}$ such that $A$ is entangled but $B$ is not $2$-entangled.\n(3) If $\\mathbb{R}\\subseteq \\mathrm{L}$, then there is an entangled $\\Pi_1^1$\nset of reals. (4) If $\\diamondsuit$ holds, then there is a $2$-entangled\nnon-separable linear order."}
{"id": "2507.17002", "categories": ["math.NT", "11F46, 11F30 (Primary) 11F50 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.17002", "abs": "https://arxiv.org/abs/2507.17002", "authors": ["Sidney Washburn"], "title": "Certain Genus 3 Siegel Cusp Forms with Level are Determined by their Fundamental Fourier Coefficients", "comment": "20 pages", "summary": "We prove that vector-valued genus 3 Siegel cusp forms for $\\Gamma_0^3(N)$\nwith certain nebentypus are determined by their fundamental Fourier\ncoefficients, assuming $N$ is odd and square-free. A key step in our proof\ninvolves strengthening the known corresponding genus 2 result. More precisely,\nwe show that genus 2 Siegel cusp forms for $\\Gamma_0^2(N)$ with certain\nnebentypus are determined by their fundamental Fourier coefficients whose\ndiscriminants are coprime to $N$. We also prove that Jacobi forms of\nfundamental index with discriminant coprime to the odd level $N$ are determined\nby their primitive theta components."}
{"id": "2507.17697", "categories": ["math.ST", "q-bio.QM", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.17697", "abs": "https://arxiv.org/abs/2507.17697", "authors": ["Janis Keck"], "title": "Frequentist Asymptotics of Variational Laplace", "comment": "30 pages, 3 figures, originally submitted as a master's thesis", "summary": "Variational inference is a general framework to obtain approximations to the\nposterior distribution in a Bayesian context. In essence, variational inference\nentails an optimization over a given family of probability distributions to\nchoose the member of this family best approximating the posterior. Variational\nLaplace, an iterative update scheme motivated by this objective, is widely used\nin different contexts in the cognitive neuroscience community. However, until\nnow, the theoretical properties of this scheme have not been systematically\ninvestigated. Here, we study variational Laplace in the light of frequentist\nasymptotic statistics. Asymptotical frequentist theory enables one to judge the\nquality of point estimates by their limit behaviour. We apply this framework to\nfind that point estimates generated by variational Laplace enjoy the desirable\nproperties of asymptotic consistency and efficiency in two toy examples.\nFurthermore, we derive conditions that are sufficient to establish these\nproperties in a general setting. Besides of point estimates, we also study the\nfrequentist convergence of distributions in the sense of total variation\ndistance, which may be useful to relate variational Laplace both to recent\nfindings regarding variational inference as well as to classical frequentist\nconsiderations on the Bayesian posterior. Finally, to illustrate the validity\nof our theoretical considerations, we conduct simulation experiments in our\nstudy examples."}
{"id": "2507.17118", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17118", "abs": "https://arxiv.org/abs/2507.17118", "authors": ["Mandar Pitale", "Jelena Frtunikj", "Abhinaw Priyadershi", "Vasu Singh", "Maria Spence"], "title": "HySafe-AI: Hybrid Safety Architectural Analysis Framework for AI Systems: A Case Study", "comment": "7 pages", "summary": "AI has become integral to safety-critical areas like autonomous driving\nsystems (ADS) and robotics. The architecture of recent autonomous systems are\ntrending toward end-to-end (E2E) monolithic architectures such as large\nlanguage models (LLMs) and vision language models (VLMs). In this paper, we\nreview different architectural solutions and then evaluate the efficacy of\ncommon safety analyses such as failure modes and effect analysis (FMEA) and\nfault tree analysis (FTA). We show how these techniques can be improved for the\nintricate nature of the foundational models, particularly in how they form and\nutilize latent representations. We introduce HySAFE-AI, Hybrid Safety\nArchitectural Analysis Framework for AI Systems, a hybrid framework that adapts\ntraditional methods to evaluate the safety of AI systems. Lastly, we offer\nhints of future work and suggestions to guide the evolution of future AI safety\nstandards."}
{"id": "2507.17246", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.17246", "abs": "https://arxiv.org/abs/2507.17246", "authors": ["Kinkar Chandra Das", "Jayanta Bera"], "title": "Resolving Open Problems on the Euler Sombor Index", "comment": null, "summary": "Recently, the Euler Sombor index $(EUS)$ was introduced as a novel\ndegree-based topological index. For a graph $G$, the Euler Sombor index is\ndefined as $$EUS(G) = \\sum_{v_i v_j \\in E(G)} \\sqrt{d_i^2 + d_j^2 + d_i d_j},$$\nwhere $d_i$ and $d_j$ denote the degrees of the vertices $v_i$ and $v_j$,\nrespectively. Very recently, Khanra and Das \\textbf{\\bf [Euler Sombor index of\ntrees, unicyclic and chemical graphs, \\emph{MATCH Commun. Math. Comput. Chem.}\n\\textbf{94} (2025) 525--548]} proposed several open problems concerning the\nEuler Sombor index. This paper completely resolves two of the most challenging\nproblems posed therein. First, we determine the minimum value of the $EUS$\nindex among all unicyclic graphs of a fixed order and prescribed girth, and we\ncharacterize the extremal graphs that attain this minimum. Building on this\nresult, we further establish the minimum $EUS$ index within the broader class\nof connected graphs of the same order and girth, and identify the corresponding\nextremal structures. In addition, we classify all connected graphs that attain\nthe maximum Euler Sombor index $(EUS)$ when both the order and the number of\nleaves are fixed."}
{"id": "2507.16872", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16872", "abs": "https://arxiv.org/abs/2507.16872", "authors": ["Na Li", "Yansong Gao", "Hongsheng Hu", "Boyu Kuang", "Anmin Fu"], "title": "CompLeak: Deep Learning Model Compression Exacerbates Privacy Leakage", "comment": null, "summary": "Model compression is crucial for minimizing memory storage and accelerating\ninference in deep learning (DL) models, including recent foundation models like\nlarge language models (LLMs). Users can access different compressed model\nversions according to their resources and budget. However, while existing\ncompression operations primarily focus on optimizing the trade-off between\nresource efficiency and model performance, the privacy risks introduced by\ncompression remain overlooked and insufficiently understood.\n  In this work, through the lens of membership inference attack (MIA), we\npropose CompLeak, the first privacy risk evaluation framework examining three\nwidely used compression configurations that are pruning, quantization, and\nweight clustering supported by the commercial model compression framework of\nGoogle's TensorFlow-Lite (TF-Lite) and Facebook's PyTorch Mobile. CompLeak has\nthree variants, given available access to the number of compressed models and\noriginal model. CompLeakNR starts by adopting existing MIA methods to attack a\nsingle compressed model, and identifies that different compressed models\ninfluence members and non-members differently. When the original model and one\ncompressed model are available, CompLeakSR leverages the compressed model as a\nreference to the original model and uncovers more privacy by combining meta\ninformation (e.g., confidence vector) from both models. When multiple\ncompressed models are available with/without accessing the original model,\nCompLeakMR innovatively exploits privacy leakage info from multiple compressed\nversions to substantially signify the overall privacy leakage. We conduct\nextensive experiments on seven diverse model architectures (from ResNet to\nfoundation models of BERT and GPT-2), and six image and textual benchmark\ndatasets."}
{"id": "2507.17069", "categories": ["math.OC", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2507.17069", "abs": "https://arxiv.org/abs/2507.17069", "authors": ["Xuemei Chen", "Owen Deen"], "title": "The Generalized Matrix Separation Problem: Algorithms", "comment": "24 pages", "summary": "When given a generalized matrix separation problem, which aims to recover a\nlow rank matrix $L_0$ and a sparse matrix $S_0$ from $M_0=L_0+HS_0$, the work\n\\cite{CW25} proposes a novel convex optimization problem whose objective\nfunction is the sum of the $\\ell_1$-norm and nuclear norm. In this paper we\ndetail the iterative algorithms and its associated computations for solving\nthis convex optimization problem. We present various efficient implementation\nstrategies, with attention to practical cases where $H$ is circulant,\nseparable, or block structured. Notably, we propose a preconditioning technique\nthat drastically improved the performance of our algorithms in terms of\nefficiency, accuracy, and robustness. While this paper serves as an\nillustrative algorithm implementation manual, we also provide theoretical\nguarantee for our preconditioning strategy. Numerical results illustrate the\neffectiveness of the proposed approach."}
{"id": "2507.17517", "categories": ["math.LO", "math.GR", "03E25, 20E05, 28A05"], "pdf": "https://arxiv.org/pdf/2507.17517", "abs": "https://arxiv.org/abs/2507.17517", "authors": ["Cesare Straffelini", "Kilian Zambanini"], "title": "Minimal Banach-Tarski Decompositions", "comment": "18 pages", "summary": "We investigate the problem of finding the minimum number of pieces necessary\nfor dividing a three-dimensional sphere or a ball and reassembling it to form\n$n$ congruent copies of the original object, generalising a known result by\nRaphael Robinson."}
{"id": "2507.17021", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.17021", "abs": "https://arxiv.org/abs/2507.17021", "authors": ["Joshua Harrington", "Lenny Jones"], "title": "Monogenic sextic trinomials $x^6+Ax^3+B$ and their Galois groups", "comment": null, "summary": "Let $f(x)=x^6+Ax^3+B\\in {\\mathbb Z}[x]$, with $A\\ne 0$, and suppose that\n$f(x)$ is irreducible over ${\\mathbb Q}$. We define $f(x)$ to be {\\em\nmonogenic} if $\\{1,\\theta,\\theta^2,\\theta^3,\\theta^4,\\theta^{5}\\}$ is a basis\nfor the ring of integers of ${\\mathbb Q}(\\theta)$, where $f(\\theta)=0$.\n  For each possible Galois group $G$ of $f(x)$ over ${\\mathbb Q}$, we use a\ntheorem of Jakhar, Khanduja and Sangwan to give explicit descriptions of all\nmonogenic trinomials $f(x)$ having Galois group $G$. We also investigate when\nthese trinomials generate distinct sextic fields."}
{"id": "2507.17168", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17168", "abs": "https://arxiv.org/abs/2507.17168", "authors": ["Qifan Zhang", "Nuo Chen", "Zehua Li", "Miao Peng", "Jing Tang", "Jia Li"], "title": "Improving LLMs' Generalized Reasoning Abilities by Graph Problems", "comment": "COLM2025", "summary": "Large Language Models (LLMs) have made remarkable strides in reasoning tasks,\nyet their performance often falters on novel and complex problems.\nDomain-specific continued pretraining (CPT) methods, such as those tailored for\nmathematical reasoning, have shown promise but lack transferability to broader\nreasoning tasks. In this work, we pioneer the use of Graph Problem Reasoning\n(GPR) to enhance the general reasoning capabilities of LLMs. GPR tasks,\nspanning pathfinding, network analysis, numerical computation, and topological\nreasoning, require sophisticated logical and relational reasoning, making them\nideal for teaching diverse reasoning patterns. To achieve this, we introduce\nGraphPile, the first large-scale corpus specifically designed for CPT using GPR\ndata. Spanning 10.9 billion tokens across 23 graph tasks, the dataset includes\nchain-of-thought, program-of-thought, trace of execution, and real-world graph\ndata. Using GraphPile, we train GraphMind on popular base models Llama 3 and\n3.1, as well as Gemma 2, achieving up to 4.9 percent higher accuracy in\nmathematical reasoning and up to 21.2 percent improvement in non-mathematical\nreasoning tasks such as logical and commonsense reasoning. By being the first\nto harness GPR for enhancing reasoning patterns and introducing the first\ndataset of its kind, our work bridges the gap between domain-specific\npretraining and universal reasoning capabilities, advancing the adaptability\nand robustness of LLMs."}
{"id": "2507.17302", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.17302", "abs": "https://arxiv.org/abs/2507.17302", "authors": ["Kecai Deng"], "title": "Bipartite graphs with minimum degree at least 15 are antimagic", "comment": null, "summary": "An antimagic {labeling} of a graph $G=(V,E)$ is a one-to-one mapping $f:\nE\\rightarrow\\{1,2,\\ldots,|E|\\}$, ensuring that the vertex sums in $V$ are\npairwise distinct, where a vertex sum of a vertex $v$ is defined as the sum of\nthe labels of the edges incident to $v$. A graph is called antimagic if it\nadmits an antimagic labeling. The Antimagic Labeling Conjecture, proposed by\nHartsfield and Ringel in 1990, posits that every connected graph other than\n$K_2$ is antimagic. The conjecture was confirmed for graphs of average degree\nat least 4,182 in 2016 by Eccles, where it was stated that a similar approach\ncould not reduce the bound below 1,000 from 4,182.\n  This paper shows that every bipartite graph with minimum degree at least 15\nis antimagic. Our approach relies on three tools: a consequence of K\\\"{o}nig's\nTheorem, the existence of a subgraph of a specific size that avoids Eulerian\ncomponents, and a labeling lemma that ensures some vertex sums are divisible by\nthree while others are not."}
{"id": "2507.16887", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16887", "abs": "https://arxiv.org/abs/2507.16887", "authors": ["Youpeng Li", "Weiliang Qi", "Xuyu Wang", "Fuxun Yu", "Xinda Wang"], "title": "Revisiting Pre-trained Language Models for Vulnerability Detection", "comment": null, "summary": "The rapid advancement of pre-trained language models (PLMs) has demonstrated\npromising results for various code-related tasks. However, their effectiveness\nin detecting real-world vulnerabilities remains a critical challenge. % for the\nsecurity community. While existing empirical studies evaluate PLMs for\nvulnerability detection (VD), their inadequate consideration in data\npreparation, evaluation setups, and experimental settings undermines the\naccuracy and comprehensiveness of evaluations. This paper introduces RevisitVD,\nan extensive evaluation of 17 PLMs spanning smaller code-specific PLMs and\nlarge-scale PLMs using newly constructed datasets. Specifically, we compare the\nperformance of PLMs under both fine-tuning and prompt engineering, assess their\neffectiveness and generalizability across various training and testing\nsettings, and analyze their robustness against code normalization, abstraction,\nand semantic-preserving transformations.\n  Our findings reveal that, for VD tasks, PLMs incorporating pre-training tasks\ndesigned to capture the syntactic and semantic patterns of code outperform both\ngeneral-purpose PLMs and those solely pre-trained or fine-tuned on large code\ncorpora. However, these models face notable challenges in real-world scenarios,\nsuch as difficulties in detecting vulnerabilities with complex dependencies,\nhandling perturbations introduced by code normalization and abstraction, and\nidentifying semantic-preserving vulnerable code transformations. Also, the\ntruncation caused by the limited context windows of PLMs can lead to a\nnon-negligible amount of labeling errors. This study underscores the importance\nof thorough evaluations of model performance in practical scenarios and\noutlines future directions to help enhance the effectiveness of PLMs for\nrealistic VD applications."}
{"id": "2507.17115", "categories": ["math.OC", "cs.SY", "econ.TH", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.17115", "abs": "https://arxiv.org/abs/2507.17115", "authors": ["Lendy Banegas", "Fredy Vides"], "title": "Stochastically Structured Reservoir Computers for Financial and Economic System Identification", "comment": null, "summary": "This paper introduces a methodology for identifying and simulating financial\nand economic systems using stochastically structured reservoir computers\n(SSRCs). The proposed framework leverages structure-preserving embeddings and\ngraph-informed coupling matrices to model inter-agent dynamics with enhanced\ninterpretability. A constrained optimization scheme ensures that the learned\nmodels satisfy both stochastic and structural constraints. Two empirical case\nstudies, a dynamic behavioral model of resource competition among agents, and\nregional inflation network dynamics, illustrate the effectiveness of the\napproach in capturing and anticipating complex nonlinear patterns and enabling\ninterpretable predictive analysis under uncertainty."}
{"id": "2507.17715", "categories": ["math.LO"], "pdf": "https://arxiv.org/pdf/2507.17715", "abs": "https://arxiv.org/abs/2507.17715", "authors": ["Joseph McDonald"], "title": "Canonical completion and duality for cylindric ortholattices and cylindric Boolean algebras", "comment": null, "summary": "In this note, we investigate the algebraic and topological representation\ntheory of cylindric ortholattices and cylindric Boolean algebras. The first\ncontribution demonstrates that cylindric ortholattices are closed under\ncanonical completions. By equipping a spectral topology to the dual space\nassociated with the canonical completion, we then establish a dual equivalence\nbetween the category of cylindric ortholattices and a certain subcategory of\nthe category of spectral spaces. This work builds on the completion and duality\nresults obtained by Harding, McDonald, and Peinado in the setting of monadic\northolattices combined with the duality results obtained by McDonald and\nYamamoto in the setting of general ortholattices. By working with the duality\ntheory for Boolean algebras established by Bezhanishvili and Holliday, we then\nobtain completion and duality results for cylindric Boolean algebras. A key\naspect of our duality results is that they are constructive in the sense that\nthey obtain in Zermelo-Fraenkel set theory independently of the Axiom of\nChoice."}
{"id": "2507.17041", "categories": ["math.NT", "11F11, 11F67"], "pdf": "https://arxiv.org/pdf/2507.17041", "abs": "https://arxiv.org/abs/2507.17041", "authors": ["Tianyu Ni", "Hui Xue"], "title": "Twisted periods of modular forms", "comment": null, "summary": "Let $S_k$ denote the space of cusp forms of weight $k$ and level one. For\n$0\\leq t\\leq k-2$ and primitive Dirichlet character $\\chi$ mod $D$, we\nintroduce twisted periods $r_{t,\\chi}$ on $S_k$. We show that for a fixed\nnatural number $n$, if $k$ is sufficiently large relative to $n$ and $D$, then\nany $n$ periods with the same twist but different indices are linearly\nindependent. We also prove that if $k$ is sufficiently large relative to $D$\nthen any $n$ periods with the same index but different twists mod $D$ are\nlinearly independent. These results are achieved by studying the trace of the\nproducts and Rankin-Cohen brackets of Eisenstein series of level $D$ with\nnebentypus. Moreover, we give two applications of our method. First, we prove\ncertain identities that evaluate convolution sums of twisted divisor functions.\nSecond, we show that Maeda's conjecture implies a non-vanishing result on\ntwisted central $L$-values of normalized Hecke eigenforms."}
{"id": "2507.17214", "categories": ["cs.AI", "cs.CY", "cs.NI", "cs.SY", "eess.SY", "I.2; B.8; C.2; I.5; J.7"], "pdf": "https://arxiv.org/pdf/2507.17214", "abs": "https://arxiv.org/abs/2507.17214", "authors": ["Amod Kant Agrawal"], "title": "Our Cars Can Talk: How IoT Brings AI to Vehicles", "comment": "3 pages, 1 figure; To appear in IEEE Computer (Nov 2025)", "summary": "Bringing AI to vehicles and enabling them as sensing platforms is key to\ntransforming maintenance from reactive to proactive. Now is the time to\nintegrate AI copilots that speak both languages: machine and driver. This\narticle offers a conceptual and technical perspective intended to spark\ninterdisciplinary dialogue and guide future research and development in\nintelligent vehicle systems, predictive maintenance, and AI-powered user\ninteraction."}
{"id": "2507.17341", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.17341", "abs": "https://arxiv.org/abs/2507.17341", "authors": ["Athira Divakaran", "Tijo James", "Sandi Klavžar", "Latha S Nair"], "title": "Maker-Breaker total domination number", "comment": null, "summary": "The Maker-Breaker total domination number, $\\gamma_{\\rm MBT}(G)$, of a graph\n$G$ is introduced as the minimum number of moves of Dominator to win the\nMaker-Breaker total domination game, provided that he has a winning strategy\nand is the first to play. The Staller-start Maker-Breaker total domination\nnumber, $\\gamma_{\\rm MBT}'(G)$, is defined analogously for the game in which\nStaller starts. Upper and lower bounds on $\\gamma_{\\rm MBT}(G)$ and on\n$\\gamma_{\\rm MBT}'(G)$ are provided and demonstrated to be sharp. It is proved\nthat for any pair of integers $(k,\\ell)$ with $2\\leq k\\leq \\ell$, (i) there\nexists a connected graph $G$ with $\\gamma_{\\rm MB}(G)=k$ and $\\gamma_{\\rm\nMBT}(G)=\\ell$, (ii) there exists a connected graph $G'$ with $\\gamma_{\\rm\nMB}'(G')=k$ and $\\gamma_{\\rm MBT}'(G')=\\ell$, and (iii) there there exists a\nconnected graph $G''$ with $\\gamma_{\\rm MBT}(G'')=k$ and $\\gamma_{\\rm\nMBT}'(G'')=\\ell$. Here, $\\gamma_{\\rm MB}$ and $\\gamma_{\\rm MB}'$ are\ncorresponding invariants for the Maker-Breaker domination game."}
{"id": "2507.16952", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16952", "abs": "https://arxiv.org/abs/2507.16952", "authors": ["Md Min-Ha-Zul Abedin", "Tazqia Mehrub"], "title": "Evaluating Ensemble and Deep Learning Models for Static Malware Detection with Dimensionality Reduction Using the EMBER Dataset", "comment": null, "summary": "This study investigates the effectiveness of several machine learning\nalgorithms for static malware detection using the EMBER dataset, which contains\nfeature representations of Portable Executable (PE) files. We evaluate eight\nclassification models: LightGBM, XGBoost, CatBoost, Random Forest, Extra Trees,\nHistGradientBoosting, k-Nearest Neighbors (KNN), and TabNet, under three\npreprocessing settings: original feature space, Principal Component Analysis\n(PCA), and Linear Discriminant Analysis (LDA). The models are assessed on\naccuracy, precision, recall, F1 score, and AUC to examine both predictive\nperformance and robustness. Ensemble methods, especially LightGBM and XGBoost,\nshow the best overall performance across all configurations, with minimal\nsensitivity to PCA and consistent generalization. LDA improves KNN performance\nbut significantly reduces accuracy for boosting models. TabNet, while promising\nin theory, underperformed under feature reduction, likely due to architectural\nsensitivity to input structure. The analysis is supported by detailed\nexploratory data analysis (EDA), including mutual information ranking, PCA or\nt-SNE visualizations, and outlier detection using Isolation Forest and Local\nOutlier Factor (LOF), which confirm the discriminatory capacity of key features\nin the EMBER dataset. The results suggest that boosting models remain the most\nreliable choice for high-dimensional static malware detection, and that\ndimensionality reduction should be applied selectively based on model type.\nThis work provides a benchmark for comparing classification models and\npreprocessing strategies in malware detection tasks and contributes insights\nthat can guide future system development and real-world deployment."}
{"id": "2507.17272", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.17272", "abs": "https://arxiv.org/abs/2507.17272", "authors": ["R. Diaz Millan", "Orizon Pereira Ferreira", "Julien Ugon"], "title": "Frank-Wolfe algorithm for star-convex functions", "comment": "12 pages", "summary": "We study the Frank-Wolfe algorithm for minimizing a differentiable function\nwith Lipschitz continuous gradient over a compact convex set. To extend\nclassical complexity bounds to certain non-convex functions, we focus on the\nclass of \\emph{star-convex functions}, which retain essential geometric\nproperties despite the lack of convexity. We establish iteration-complexity\nbounds of $\\mathcal{O}(1/k)$ for both the objective values and the duality gap\nunder star-convexity, using diminishing, Armijo-type, and Lipschitz-based\nstepsize rules. Notably, the diminishing and Armijo strategies do not require\nprior knowledge of Lipschitz or curvature constants. These results demonstrate\nthat the Frank-Wolfe method preserves optimal complexity guarantees beyond the\nconvex setting."}
{"id": "2507.17724", "categories": ["math.LO"], "pdf": "https://arxiv.org/pdf/2507.17724", "abs": "https://arxiv.org/abs/2507.17724", "authors": ["Joseph McDonald"], "title": "Orthogonality relations and operators on bounded quasi-implication algebras", "comment": null, "summary": "In this note, we study various relational and algebraic aspects of the\nbounded quasi-implication algebras introduced by Hardegree. By generalizing the\nconstructions given by MacLaren and Goldblatt within the setting of\northolattices, we construct various orthogonality relations from bounded\nquasi-implication algebras.\n  We then introduce certain bounded quasi-implication algebras with an\nadditional operator, which we call monadic quasi-implication algebras, and\nstudy them within the setting of quantum monadic algebras. A quantum monadic\nalgebra is an orthomodular lattice equipped with a closure operator, known as a\nquantifier, whose closed elements form an orthomodular sub-lattice. It is shown\nthat every quantum monadic algebra can be converted into a monadic\nquasi-implication algebra with the underlying magma structure being determined\nby the operation of Sasaki implication on the underlying orthomodular lattice.\nIt is then conversely demonstrated that every monadic quasi-implication algebra\ncan be converted into a quantum monadic algebra. These constructions are shown\nto induce an isomorphism between the category of quantum monadic algebras and\nthe category of monadic quasi-implication algebras.\n  Finally, by generalizing the constructions given by Harding as well as\nHarding, McDonald, and Peinado in the setting of monadic ortholattices, we\nconstruct various monadic orthoframes from monadic quasi-implication algebras."}
{"id": "2507.17167", "categories": ["math.NT", "math.DS"], "pdf": "https://arxiv.org/pdf/2507.17167", "abs": "https://arxiv.org/abs/2507.17167", "authors": ["Gerardo González Robert", "Mumtaz Hussain", "Benjamin Ward", "Lauren White"], "title": "Continued fractions with large prime partial quotients", "comment": "24 pages, comments welcome", "summary": "We determine the Lebesgue measure and Hausdorff dimension of various sets of\nreal numbers with infinitely many partial quotients that are both large and\nprime, thus extending the well-known theorems by {\\L}uczak (1997) and\nHuang-Wu-Xu (2020). To this end, we obtain new asymptotics on the tail end of\nthe almost prime zeta function. Our results include some recent work by\nSchindler-Zweim{\\\"u}ller (2023)."}
{"id": "2507.17257", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.17257", "abs": "https://arxiv.org/abs/2507.17257", "authors": ["Elija Perrier", "Michael Timothy Bennett"], "title": "Agent Identity Evals: Measuring Agentic Identity", "comment": null, "summary": "Central to agentic capability and trustworthiness of language model agents\n(LMAs) is the extent they maintain stable, reliable, identity over time.\nHowever, LMAs inherit pathologies from large language models (LLMs)\n(statelessness, stochasticity, sensitivity to prompts and\nlinguistically-intermediation) which can undermine their identifiability,\ncontinuity, persistence and consistency. This attrition of identity can erode\ntheir reliability, trustworthiness and utility by interfering with their\nagentic capabilities such as reasoning, planning and action. To address these\nchallenges, we introduce \\textit{agent identity evals} (AIE), a rigorous,\nstatistically-driven, empirical framework for measuring the degree to which an\nLMA system exhibit and maintain their agentic identity over time, including\ntheir capabilities, properties and ability to recover from state perturbations.\nAIE comprises a set of novel metrics which can integrate with other measures of\nperformance, capability and agentic robustness to assist in the design of\noptimal LMA infrastructure and scaffolding such as memory and tools. We set out\nformal definitions and methods that can be applied at each stage of the LMA\nlife-cycle, and worked examples of how to apply them."}
{"id": "2507.17370", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.17370", "abs": "https://arxiv.org/abs/2507.17370", "authors": ["Sébastien Ferenczi", "Luca Q. Zamboni"], "title": "Clustering, order conditions, and languages of interval exchanges", "comment": null, "summary": "For any interval exchange transformation $T$ (standard or generalized), if we\ndefine a morphism $\\phi$ from the set of letters to the\n  set of the return words of a word in the natural coding, respecting the\nlexicographical order, the word $\\phi v$ clusters (for the Burrows-Wheeler\ntransform) for the permutation of $T$ if and only if the word $v$ clusters for\nthe permutation of the induced map of $T$\n  on the cylinder $[w]$. When $T$ is symmetrical, all such natural codings are\nrich languages, and this implies that the two orders above are the same if $w$\nis a palindrome. Finally, we generalize the result, proved by using the\nclustering of a word $w$,\n  that $ww$ is produced by a generalized interval exchange transformation if\nand only if $ww$ is produced by a standard interval exchange transformation, to\nnon-clustering $w$: in the symmetric case, $w$ is produced by a\n  generalized interval exchange transformation if and only if $w$ is produced\nby a standard interval exchange transformation."}
{"id": "2507.16996", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16996", "abs": "https://arxiv.org/abs/2507.16996", "authors": ["Iman Vakilinia"], "title": "From Cracks to Crooks: YouTube as a Vector for Malware Distribution", "comment": null, "summary": "With billions of users and an immense volume of daily uploads, YouTube has\nbecome an attractive target for cybercriminals aiming to leverage its vast\naudience. The platform's openness and trustworthiness provide an ideal\nenvironment for deceptive campaigns that can operate under the radar of\nconventional security tools. This paper explores how cybercriminals exploit\nYouTube to disseminate malware, focusing on campaigns that promote free\nsoftware or game cheats. It discusses deceptive video demonstrations and the\ntechniques behind malware delivery. Additionally, the paper presents a new\nevasion technique that abuses YouTube's multilingual metadata capabilities to\ncircumvent automated detection systems. Findings indicate that this method is\nincreasingly being used in recent malicious videos to avoid detection and\nremoval."}
{"id": "2507.17277", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.17277", "abs": "https://arxiv.org/abs/2507.17277", "authors": ["Jinhao Li", "Arlena Chew", "Hao Wang"], "title": "Investigating State-of-the-Art Planning Strategies for Electric Vehicle Charging Infrastructures in Coupled Transport and Power Networks: A Comprehensive Review", "comment": "26 pages", "summary": "Electric vehicles (EVs) have emerged as a pivotal solution to reduce\ngreenhouse gas emissions paving a pathway to net zero. As the adoption of EVs\ncontinues to grow, countries are proactively formulating systematic plans for\nnationwide electric vehicle charging infrastructure (EVCI) to keep pace with\nthe accelerating shift towards EVs. This comprehensive review aims to\nthoroughly examine current global practices in EVCI planning and explore\nstate-of-the-art methodologies for designing EVCI planning strategies. Despite\nremarkable efforts by influential players in the global EV market, such as\nChina, the United States, and the European Union, the progress in EVCI rollout\nhas been notably slower than anticipated in the rest of the world. This delay\ncan be attributable to three major impediments: inadequate EVCI charging\nservices, low utilization rates of public EVCI facilities, and the non-trivial\nintegration of EVCI into the electric grid. This review dissects the interests\nof these stakeholders, clarifying their respective roles and expectations in\nthe context of EVCI planning. This review also provides insights into level 1,\n2, and 3 chargers with explorations of their applications in different\ngeographical locations for diverse EV charging patterns. Finally, a thorough\nreview of node-based and flow-based approaches to EV planning is presented. The\nmodeling of placing charging stations is broadly categorized into set coverage,\nmaximum coverage, flow-capturing, and flow-refueling location models. In\nconclusion, this review identifies several research gaps, including the dynamic\nmodeling of EV charging demand and the coordination of vehicle electrification\nwith grid decarbonization. This paper calls for further contributions to bridge\nthese gaps and drive the advancement of EVCI planning."}
{"id": "2507.17608", "categories": ["math.NT", "11F11, 11F67"], "pdf": "https://arxiv.org/pdf/2507.17608", "abs": "https://arxiv.org/abs/2507.17608", "authors": ["Tianyu Ni", "Hui Xue"], "title": "Linear independence of periods for the symmetric square $L$-functions", "comment": "to appear in Ann. Math. Qu\\'e", "summary": "For $S_k$, the space of cusp forms of weight $k$ for the full modular group,\nwe first introduce periods on $S_k$ associated to symmetric square\n$L$-functions. We then prove that for a fixed natural number $n$, if $k$ is\nsufficiently large relative to $n$, then any $n$ such periods are linearly\nindependent. With some extra assumption, we also prove that for $k\\geq e^{12}$,\nwe can always pick up to $\\frac{\\log k}{4}$ arbitrary linearly independent\nperiods."}
{"id": "2507.17258", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17258", "abs": "https://arxiv.org/abs/2507.17258", "authors": ["Andreas Scholl", "Natalie Kiesler"], "title": "Students' Feedback Requests and Interactions with the SCRIPT Chatbot: Do They Get What They Ask For?", "comment": "Accepted at PPIG 2025", "summary": "Building on prior research on Generative AI (GenAI) and related tools for\nprogramming education, we developed SCRIPT, a chatbot based on ChatGPT-4o-mini,\nto support novice learners. SCRIPT allows for open-ended interactions and\nstructured guidance through predefined prompts. We evaluated the tool via an\nexperiment with 136 students from an introductory programming course at a large\nGerman university and analyzed how students interacted with SCRIPT while\nsolving programming tasks with a focus on their feedback preferences. The\nresults reveal that students' feedback requests seem to follow a specific\nsequence. Moreover, the chatbot responses aligned well with students' requested\nfeedback types (in 75%), and it adhered to the system prompt constraints. These\ninsights inform the design of GenAI-based learning support systems and\nhighlight challenges in balancing guidance and flexibility in AI-assisted\ntools."}
{"id": "2507.17407", "categories": ["math.CO", "05E18, 05C25, 05C30"], "pdf": "https://arxiv.org/pdf/2507.17407", "abs": "https://arxiv.org/abs/2507.17407", "authors": ["Sauvik Poddar", "Angsuman Das"], "title": "Non-isomorphic $d$-integral circulant graphs", "comment": "19 pages, 1 table", "summary": "The algebraic degree $Deg(G)$ of a graph $G$ is the dimension of the\nsplitting field of the adjacency polynomial of $G$ over the field $\\mathbb{Q}$.\nIt can be shown that for every positive integer $d$, there exists a circulant\ngraph with algebraic degree $d$. Let $C(d)$ be the least positive integer such\nthat there exists a circulant graph of order $C(d)$ having algebraic degree\n$d$. A graph $G$ is called $d$-integral if $Deg(G)=d$. We call a $d$-integral\ncirculant graph \\textit{minimal} if order of that graph equals $C(d)$. Let\n$\\mathcal{F}_{n,d}$ denote the collection of isomorphism classes of connected,\n$d$-integral circulant graphs of some given possible order $n$. In this paper\nwe compute the exact value of $C(d)$ and provide some bounds on\n$|\\mathcal{F}_{n,d}|$, thereby showing that the minimal $d$-integral circulant\ngraph is not unique. Moreover, we find the exact value of $|\\mathcal{F}_{p,d}|$\nwhere both $p$ and $d$ are prime."}
{"id": "2507.17007", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17007", "abs": "https://arxiv.org/abs/2507.17007", "authors": ["Gabriele Costa"], "title": "The Postman: A Journey of Ethical Hacking in PosteID/SPID Borderland", "comment": null, "summary": "This paper presents a vulnerability assessment activity that we carried out\non PosteID, the implementation of the Italian Public Digital Identity System\n(SPID) by Poste Italiane. The activity led to the discovery of a critical\nprivilege escalation vulnerability, which was eventually patched. The overall\nanalysis and disclosure process represents a valuable case study for the\ncommunity of ethical hackers. In this work, we present both the technical steps\nand the details of the disclosure process."}
{"id": "2507.17545", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17545", "abs": "https://arxiv.org/abs/2507.17545", "authors": ["Sebastian Pokutta"], "title": "Scalable DC Optimization via Adaptive Frank-Wolfe Algorithms", "comment": null, "summary": "We consider the problem of minimizing a difference of (smooth) convex\nfunctions over a compact convex feasible region $P$, i.e., $\\min_{x \\in P} f(x)\n- g(x)$, with smooth $f$ and Lipschitz continuous $g$. This computational study\nbuilds upon and complements the framework of Maskan et al. [2025] by\nintegrating advanced Frank-Wolfe variants to reduce computational overhead. We\nempirically show that constrained DC problems can be efficiently solved using a\ncombination of the Blended Pairwise Conditional Gradients (BPCG) algorithm\n[Tsuji et al., 2022] with warm-starting and the adaptive error bound from\nMaskan et al. [2025]. The result is a highly efficient and scalable\nprojection-free algorithm for constrained DC optimization."}
{"id": "2507.17631", "categories": ["math.NT", "math.AG", "14F30, 14F40"], "pdf": "https://arxiv.org/pdf/2507.17631", "abs": "https://arxiv.org/abs/2507.17631", "authors": ["Abhinandan", "Alex Youcis"], "title": "An integral comparison of crystalline and de Rham cohomology", "comment": "33 pages. Comments welcome!", "summary": "Let $\\mathcal{O}_K$ be a mixed characteristic complete DVR with perfect\nresidue field $k$ and fraction field $K$. It is a celebrated result of\nBerthelot and Ogus that for a smooth proper formal scheme $X/\\mathcal{O}_K$\nthere exists a comparison between the de Rham cohomology groups\n$\\mathrm{H}^i_\\mathrm{dR}(X/\\mathcal{O}_K)$ and the crystalline cohomology\ngroups $\\mathrm{H}^i_\\mathrm{crys}(X_k/W(k))$ of the special fibre, after\ntensoring with $K$. In this article, we use the stacky perspective on prismatic\ncohomology, due to Drinfeld and Bhatt--Lurie, to give a version of this\ncomparison result with coefficients in a perfect complex of prismatic\n$F$-crystals on $X$. Our method is of an integral nature and suggests new tools\nto understand the relationship between torsion in de Rham and crystalline\ncohomology."}
{"id": "2507.17289", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17289", "abs": "https://arxiv.org/abs/2507.17289", "authors": ["Shitong Zhu", "Chenhao Fang", "Derek Larson", "Neel Reddy Pochareddy", "Rajeev Rao", "Sophie Zeng", "Yanqing Peng", "Wendy Summer", "Alex Goncalves", "Arya Pudota", "Herve Robert"], "title": "Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments", "comment": null, "summary": "This paper presents Compliance Brain Assistant (CBA), a conversational,\nagentic AI assistant designed to boost the efficiency of daily compliance tasks\nfor personnel in enterprise environments. To strike a good balance between\nresponse quality and latency, we design a user query router that can\nintelligently choose between (i) FastTrack mode: to handle simple requests that\nonly need additional relevant context retrieved from knowledge corpora; and\n(ii) FullAgentic mode: to handle complicated requests that need composite\nactions and tool invocations to proactively discover context across various\ncompliance artifacts, and/or involving other APIs/models for accommodating\nrequests. A typical example would be to start with a user query, use its\ndescription to find a specific entity and then use the entity's information to\nquery other APIs for curating and enriching the final AI response.\n  Our experimental evaluations compared CBA against an out-of-the-box LLM on\nvarious real-world privacy/compliance-related queries targeting various\npersonas. We found that CBA substantially improved upon the vanilla LLM's\nperformance on metrics such as average keyword match rate (83.7% vs. 41.7%) and\nLLM-judge pass rate (82.0% vs. 20.0%). We also compared metrics for the full\nrouting-based design against the `fast-track only` and `full-agentic` modes and\nfound that it had a better average match-rate and pass-rate while keeping the\nrun-time approximately the same. This finding validated our hypothesis that the\nrouting mechanism leads to a good trade-off between the two worlds."}
{"id": "2507.17492", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.17492", "abs": "https://arxiv.org/abs/2507.17492", "authors": ["Aida Abiad", "Vladislav Taranchuk", "Thijs van Veluw"], "title": "On the sum of the largest and smallest eigenvalues of odd-cycle free graphs", "comment": null, "summary": "Let $G$ be a graph with adjacency eigenvalues $\\lambda_1 \\geq \\cdots \\geq\n\\lambda_n$. Both $\\lambda_1 + \\lambda_n$ and the odd girth of $G$ can be seen\nas measures of the bipartiteness of $G$. Csikv\\'ari proved in 2022 that for odd\ngirth 5 graphs (triangle-free) it holds that $(\\lambda_1+\\lambda_n)/n \\le\n(3-2\\sqrt 2) < 0.1716$. In this paper we extend Csikv\\'ari's result to general\nodd girth $k$ proving that $(\\lambda_1+\\lambda_n)/n = O(k^{-1})$. In the case\nof odd girth 7, we prove a stronger upper bound of $(\\lambda_1+\\lambda_n)/n <\n0.0396$."}
{"id": "2507.17010", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17010", "abs": "https://arxiv.org/abs/2507.17010", "authors": ["H M Mohaimanul Islam", "Huynh Q. N. Vo", "Aditya Rane"], "title": "Towards Trustworthy AI: Secure Deepfake Detection using CNNs and Zero-Knowledge Proofs", "comment": "Submitted for peer-review in TrustXR - 2025", "summary": "In the era of synthetic media, deepfake manipulations pose a significant\nthreat to information integrity. To address this challenge, we propose\nTrustDefender, a two-stage framework comprising (i) a lightweight convolutional\nneural network (CNN) that detects deepfake imagery in real-time extended\nreality (XR) streams, and (ii) an integrated succinct zero-knowledge proof\n(ZKP) protocol that validates detection results without disclosing raw user\ndata. Our design addresses both the computational constraints of XR platforms\nwhile adhering to the stringent privacy requirements in sensitive settings.\nExperimental evaluations on multiple benchmark deepfake datasets demonstrate\nthat TrustDefender achieves 95.3% detection accuracy, coupled with efficient\nproof generation underpinned by rigorous cryptography, ensuring seamless\nintegration with high-performance artificial intelligence (AI) systems. By\nfusing advanced computer vision models with provable security mechanisms, our\nwork establishes a foundation for reliable AI in immersive and\nprivacy-sensitive applications."}
{"id": "2507.17556", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.17556", "abs": "https://arxiv.org/abs/2507.17556", "authors": ["Max L. N. Goncalves", "Geovani N. Grapiglia"], "title": "Sub-sampled Trust-Region Methods with Deterministic Worst-Case Complexity Guarantees", "comment": null, "summary": "In this paper, we develop and analyze sub-sampled trust-region methods for\nsolving finite-sum optimization problems. These methods employ subsampling\nstrategies to approximate the gradient and Hessian of the objective function,\nsignificantly reducing the overall computational cost. We propose a novel\nadaptive procedure for deterministically adjusting the sample size used for\ngradient (or gradient and Hessian) approximations. Furthermore, we establish\nworst-case iteration complexity bounds for obtaining approximate stationary\npoints. More specifically, for a given $\\varepsilon_g, \\varepsilon_H\\in (0,1)$,\nit is shown that an $\\varepsilon_g$-approximate first-order stationary point is\nreached in at most $\\mathcal{O}({\\varepsilon_g}^{-2} )$ iterations, whereas an\n$(\\varepsilon_g,\\varepsilon_H)$-approximate second-order stationary point is\nreached in at most\n$\\mathcal{O}(\\max\\{\\varepsilon_{g}^{-2}\\varepsilon_{H}^{-1},\\varepsilon_{H}^{-3}\\})$\niterations. Finally, numerical experiments illustrate the effectiveness of our\nnew subsampling technique."}
{"id": "2507.16956", "categories": ["math.CO", "math.NT", "11B85"], "pdf": "https://arxiv.org/pdf/2507.16956", "abs": "https://arxiv.org/abs/2507.16956", "authors": ["Robbert Fokkink", "Gandhar Joshi"], "title": "On Cloitre's hiccup sequences", "comment": null, "summary": "In 2003, Benoit Cloitre entered a bunch of sequences in the OEIS that we call\n\\emph{hiccup} sequences. We collect the various claims, observations, and\nproofs of properties of these sequences that have been entered in the OEIS over\nthe years, and present a unified approach, guided by a remarkable theorem of\nBosma, Dekking, and Steiner."}
{"id": "2507.17418", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17418", "abs": "https://arxiv.org/abs/2507.17418", "authors": ["Joobin Jin", "Seokjun Hong", "Gyeongseon Baek", "Yeeun Kim", "Byeongjoon Noh"], "title": "Ctx2TrajGen: Traffic Context-Aware Microscale Vehicle Trajectories using Generative Adversarial Imitation Learning", "comment": null, "summary": "Precise modeling of microscopic vehicle trajectories is critical for traffic\nbehavior analysis and autonomous driving systems. We propose Ctx2TrajGen, a\ncontext-aware trajectory generation framework that synthesizes realistic urban\ndriving behaviors using GAIL. Leveraging PPO and WGAN-GP, our model addresses\nnonlinear interdependencies and training instability inherent in microscopic\nsettings. By explicitly conditioning on surrounding vehicles and road geometry,\nCtx2TrajGen generates interaction-aware trajectories aligned with real-world\ncontext. Experiments on the drone-captured DRIFT dataset demonstrate superior\nperformance over existing methods in terms of realism, behavioral diversity,\nand contextual fidelity, offering a robust solution to data scarcity and domain\nshift without simulation."}
{"id": "2507.17541", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.17541", "abs": "https://arxiv.org/abs/2507.17541", "authors": ["Vilhelm Agdur", "Jessica Enright", "Laura Larios-Jones", "Kitty Meeks", "Fiona Skerman", "Ella Yates"], "title": "Approximating temporal modularity on graphs of small underlying treewidth", "comment": null, "summary": "Modularity is a very widely used measure of the level of clustering or\ncommunity structure in networks. Here we consider a recent generalisation of\nthe definition of modularity to temporal graphs, whose edge-sets change over\ndiscrete timesteps; such graphs offer a more realistic model of many real-world\nnetworks in which connections between entities (for example, between\nindividuals in a social network) evolve over time. Computing modularity is\nnotoriously difficult: it is NP-hard even to approximate in general, and only\nadmits efficient exact algorithms in very restricted special cases. Our main\nresult is that a multiplicative approximation to temporal modularity can be\ncomputed efficiently when the underlying graph has small treewidth. This\ngeneralises a similar approximation algorithm for the static case, but requires\nsome substantially new ideas to overcome technical challenges associated with\nthe temporal nature of the problem."}
{"id": "2507.17033", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17033", "abs": "https://arxiv.org/abs/2507.17033", "authors": ["Joshua Kalyanapu", "Farshad Dizani", "Darsh Asher", "Azam Ghanbari", "Rosario Cammarota", "Aydin Aysu", "Samira Mirbagher Ajorpaz"], "title": "GATEBLEED: Exploiting On-Core Accelerator Power Gating for High Performance & Stealthy Attacks on AI", "comment": "Accepted at MICRO 2025", "summary": "As power consumption from AI training and inference continues to increase, AI\naccelerators are being integrated directly into the CPU. Intel's Advanced\nMatrix Extensions (AMX) is one such example, debuting on the 4th generation\nIntel Xeon Scalable CPU. We discover a timing side and covert channel,\nGATEBLEED, caused by the aggressive power gating utilized to keep the CPU\nwithin operating limits. We show that the GATEBLEED side channel is a threat to\nAI privacy as many ML models such as transformers and CNNs make critical\ncomputationally-heavy decisions based on private values like confidence\nthresholds and routing logits. Timing delays from selective powering down of\nAMX components mean that each matrix multiplication is a potential leakage\npoint when executed on the AMX accelerator. Our research identifies over a\ndozen potential gadgets across popular ML libraries (HuggingFace, PyTorch,\nTensorFlow, etc.), revealing that they can leak sensitive and private\ninformation. GATEBLEED poses a risk for local and remote timing inference, even\nunder previous protective measures. GATEBLEED can be used as a high\nperformance, stealthy remote covert channel and a generic magnifier for timing\ntransmission channels, capable of bypassing traditional cache defenses to leak\narbitrary memory addresses and evading state of the art microarchitectural\nattack detectors under realistic network conditions and system configurations\nin which previous attacks fail. We implement an end-to-end microarchitectural\ninference attack on a transformer model optimized with Intel AMX, achieving a\nmembership inference accuracy of 81% and a precision of 0.89. In a CNN-based or\ntransformer-based mixture-of-experts model optimized with Intel AMX, we leak\nexpert choice with 100% accuracy."}
{"id": "2507.17566", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.17566", "abs": "https://arxiv.org/abs/2507.17566", "authors": ["Rolf Nelson van Lieshout", "Niels Lindner"], "title": "A Compact Cycle Formulation for the Multiperiodic Event Scheduling Problem", "comment": null, "summary": "The Periodic Event Scheduling Problem (PESP) is a fundamental model in\nperiodic timetabling for public transport systems, assuming a common period\nacross all events. However, real-world networks often feature heterogeneous\nservice frequencies. This paper studies the Multiperiodic Event Scheduling\nProblem (MPESP), a generalization of PESP that allows each event to recur at\nits own individual period. While more expressive, MPESP presents new modeling\nchallenges due to the loss of a global period. We present a cycle-based\nformulation for MPESP that extends the strongest known formulation for PESP\nand, in contrast to existing approaches, is valid for any MPESP instance.\nCrucially, the formulation requires a cycle basis derived from a spanning tree\nsatisfying specific structural properties, which we formalize and\nalgorithmically construct, extending the concept of sharp spanning trees to\nrooted instances. We further prove a multiperiodic analogue of the cycle\nperiodicity property. Our new formulation solves nearly all tested instances,\nincluding several large-scale real-world public transport networks, to\noptimality or with small optimality gaps, dramatically outperforming existing\narc-based models. The results demonstrate the practical potential of MPESP in\ncapturing heterogeneous frequencies without resorting to artificial event\nduplication."}
{"id": "2507.17477", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17477", "abs": "https://arxiv.org/abs/2507.17477", "authors": ["Haoran Sun", "Zekun Zhang", "Shaoning Zeng"], "title": "An Uncertainty-Driven Adaptive Self-Alignment Framework for Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable progress in\ninstruction following and general-purpose reasoning. However, achieving\nhigh-quality alignment with human intent and safety norms without human\nannotations remains a fundamental challenge. In this work, we propose an\nUncertainty-Driven Adaptive Self-Alignment (UDASA) framework designed to\nimprove LLM alignment in a fully automated manner. UDASA first generates\nmultiple responses for each input and quantifies output uncertainty across\nthree dimensions: semantics, factuality, and value alignment. Based on these\nuncertainty scores, the framework constructs preference pairs and categorizes\ntraining samples into three stages, conservative, moderate, and exploratory,\naccording to their uncertainty difference. The model is then optimized\nprogressively across these stages. In addition, we conduct a series of\npreliminary studies to validate the core design assumptions and provide strong\nempirical motivation for the proposed framework. Experimental results show that\nUDASA outperforms existing alignment methods across multiple tasks, including\nharmlessness, helpfulness, truthfulness, and controlled sentiment generation,\nsignificantly improving model performance."}
{"id": "2507.17620", "categories": ["math.CO", "math-ph", "math.MP", "52B40 (primary), 52B12 (secondary)"], "pdf": "https://arxiv.org/pdf/2507.17620", "abs": "https://arxiv.org/abs/2507.17620", "authors": ["Elia Mazzucchelli", "Elizabeth Pratt"], "title": "Exterior Cyclic Polytopes and Convexity of Amplituhedra", "comment": "30 pages, 10 figures, 1 table; comments welcome", "summary": "The amplituhedron is a semialgebraic set in the Grassmannian. We study\nconvexity and duality of amplituhedra. We introduce a notion of convexity,\ncalled \\textit{extendable convexity}, for real semialgebraic sets in any\nembedded projective variety. We show that the $k=m=2$ amplituhedron is\nextendably convex in the Grassmannian of lines in projective three-space. In\nthe process we introduce a new polytope called the \\emph{exterior cyclic\npolytope}, generalizing the cyclic polytope. It is equal to the convex hull of\nthe amplituhedron in the Pl\\\"ucker embedding. We undertake a combinatorial\nanalysis of the exterior cyclic polytope, its facets, and its dual. Finally, we\nintroduce the \\textit{(extendable) dual amplituhedron}, which is closely\nrelated to the dual of the exterior cyclic polytope. We show that the dual\namplituhedron for $k=m=2$ is again an amplituhedron, where the external matrix\ndata is changed by the twist map."}
{"id": "2507.17064", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.17064", "abs": "https://arxiv.org/abs/2507.17064", "authors": ["Nafisa Anjum", "Tasnuva Farheen"], "title": "SoK: Securing the Final Frontier for Cybersecurity in Space-Based Infrastructure", "comment": null, "summary": "With the advent of modern technology, critical infrastructure,\ncommunications, and national security depend increasingly on space-based\nassets. These assets, along with associated assets like data relay systems and\nground stations, are, therefore, in serious danger of cyberattacks. Strong\nsecurity defenses are essential to ensure data integrity, maintain secure\noperations, and protect assets in space and on the ground against various\nthreats. Previous research has found discrete vulnerabilities in space systems\nand suggested specific solutions to address them. Such research has yielded\nvaluable insights, but lacks a thorough examination of space cyberattack\nvectors and a rigorous assessment of the efficacy of mitigation techniques.\nThis study tackles this issue by taking a comprehensive approach to analyze the\nrange of possible space cyber-attack vectors, which include ground, space,\nsatellite, and satellite constellations. In order to address the particular\nthreats, the study also assesses the efficacy of mitigation measures that are\nlinked with space infrastructures and proposes a Risk Scoring Framework. Based\non the analysis, this paper identifies potential research challenges for\ndeveloping and testing cutting-edge technology solutions, encouraging robust\ncybersecurity measures needed in space."}
{"id": "2507.17482", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17482", "abs": "https://arxiv.org/abs/2507.17482", "authors": ["Luca Salvatore Lorello", "Nikolaos Manginas", "Marco Lippi", "Stefano Melacci"], "title": "LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning", "comment": null, "summary": "Neuro-symbolic artificial intelligence aims to combine neural architectures\nwith symbolic approaches that can represent knowledge in a human-interpretable\nformalism. Continual learning concerns with agents that expand their knowledge\nover time, improving their skills while avoiding to forget previously learned\nconcepts. Most of the existing approaches for neuro-symbolic artificial\nintelligence are applied to static scenarios only, and the challenging setting\nwhere reasoning along the temporal dimension is necessary has been seldom\nexplored. In this work we introduce LTLZinc, a benchmarking framework that can\nbe used to generate datasets covering a variety of different problems, against\nwhich neuro-symbolic and continual learning methods can be evaluated along the\ntemporal and constraint-driven dimensions. Our framework generates expressive\ntemporal reasoning and continual learning tasks from a linear temporal logic\nspecification over MiniZinc constraints, and arbitrary image classification\ndatasets. Fine-grained annotations allow multiple neural and neuro-symbolic\ntraining settings on the same generated datasets. Experiments on six\nneuro-symbolic sequence classification and four class-continual learning tasks\ngenerated by LTLZinc, demonstrate the challenging nature of temporal learning\nand reasoning, and highlight limitations of current state-of-the-art methods.\nWe release the LTLZinc generator and ten ready-to-use tasks to the\nneuro-symbolic and continual learning communities, in the hope of fostering\nresearch towards unified temporal learning and reasoning frameworks."}
{"id": "2507.17646", "categories": ["math.CO", "05C57, 05C69"], "pdf": "https://arxiv.org/pdf/2507.17646", "abs": "https://arxiv.org/abs/2507.17646", "authors": ["Boštjan Brešar", "Tanja Dravec", "Kirsti Kuenzel", "Douglas F. Rall"], "title": "On Maker-Breaker domination game critical graphs", "comment": "18 pages, 3 figures", "summary": "The Maker-Breaker domination game is played on a graph $G$ by Dominator and\nStaller who alternate turns selecting an unplayed vertex of $G$. The goal of\nDominator is that the vertices he selected during the game form a dominating\nset while Staller's goal is to prevent this from happening. The graph invariant\n$\\gamma_{\\rm MB}'(G)$ is the number of Dominator's moves in the game played on\n$G$ in which he can achieve his goal when Staller makes the first move and both\nplayers play optimally. In this paper, we continue the investigation of\n$2$-$\\gamma_{\\rm MB}'$-critical graphs, initiated in [Divarakan et al.,\nMaker--Breaker domination game critical graphs, Discrete Appl.\\ Math. 368\n(2025) 126--134], which are defined as the graphs $G$ with $\\gamma_{\\rm\nMB}'(G)=2$ and $\\gamma_{\\rm MB}'(G-e)>2$ for every edge $e$ in $G$. The authors\ncharacterized bipartite $2$-$\\gamma_{\\rm MB}'$-critical graphs, and found an\nexample of a non-bipartite $2$-$\\gamma_{\\rm MB}'$-critical graph. In this\npaper, we characterize the $2$-$\\gamma_{\\rm MB}'$-critical graphs that have a\ncut-vertex, which are represented by two infinite families. In addition, we\nprove that $C_5$ is the only non-bipartite, triangle-free $2$-$\\gamma_{\\rm\nMB}'$-critical graph."}
{"id": "2507.17074", "categories": ["cs.CR", "cs.NI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2507.17074", "abs": "https://arxiv.org/abs/2507.17074", "authors": ["Sanzida Hoque", "Abdullah Aydeger", "Engin Zeydan", "Madhusanka Liyanage"], "title": "Analysis of Post-Quantum Cryptography in User Equipment in 5G and Beyond", "comment": "Table 5, Figures 7, This paper has been accepted as a regular paper\n  at LCN 2025 and will appear in the conference proceedings. The final version\n  will be published by IEEE and the copyright will belong to IEEE", "summary": "The advent of quantum computing threatens the security of classical\npublic-key cryptographic systems, prompting the transition to post-quantum\ncryptography (PQC). While PQC has been analyzed in theory, its performance in\npractical wireless communication environments remains underexplored. This paper\npresents a detailed implementation and performance evaluation of NIST-selected\nPQC algorithms in user equipment (UE) to UE communications over 5G networks.\nUsing a full 5G emulation stack (Open5GS and UERANSIM) and PQC-enabled TLS 1.3\nvia BoringSSL and liboqs, we examine key encapsulation mechanisms and digital\nsignature schemes across realistic network conditions. We evaluate performance\nbased on handshake latency, CPU and memory usage, bandwidth, and retransmission\nrates, under varying cryptographic configurations and client loads. Our\nfindings show that ML-KEM with ML-DSA offers the best efficiency for\nlatency-sensitive applications, while SPHINCS+ and HQC combinations incur\nhigher computational and transmission overheads, making them unsuitable for\nsecurity-critical but time-sensitive 5G scenarios."}
{"id": "2507.17487", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2507.17487", "abs": "https://arxiv.org/abs/2507.17487", "authors": ["Lorenzo Marconi", "Flavia Ricci", "Riccardo Rosati"], "title": "CQE under Epistemic Dependencies: Algorithms and Experiments (extended version)", "comment": "Extended version of paper accepted at the 24th International Semantic\n  Web Conference (ISWC 2025)", "summary": "We investigate Controlled Query Evaluation (CQE) over ontologies, where\ninformation disclosure is regulated by epistemic dependencies (EDs), a family\nof logical rules recently proposed for the CQE framework. In particular, we\ncombine EDs with the notion of optimal GA censors, i.e. maximal sets of ground\natoms that are entailed by the ontology and can be safely revealed. We focus on\nanswering Boolean unions of conjunctive queries (BUCQs) with respect to the\nintersection of all optimal GA censors - an approach that has been shown in\nother contexts to ensure strong security guarantees with favorable\ncomputational behavior. First, we characterize the security of this\nintersection-based approach and identify a class of EDs (namely, full EDs) for\nwhich it remains safe. Then, for a subclass of EDs and for DL-Lite_R\nontologies, we show that answering BUCQs in the above CQE semantics is in AC^0\nin data complexity by presenting a suitable, detailed first-order rewriting\nalgorithm. Finally, we report on experiments conducted in two different\nevaluation scenarios, showing the practical feasibility of our rewriting\nfunction."}
{"id": "2507.17666", "categories": ["math.CO", "90C35"], "pdf": "https://arxiv.org/pdf/2507.17666", "abs": "https://arxiv.org/abs/2507.17666", "authors": ["Veronica Phan"], "title": "A simple proof that the edge density of Fon-der-Flaass $(3,4)$-graph is $\\geq\\frac{7}{16}(1-o(1))$", "comment": null, "summary": "In 2018, Alexander A. Razborov proved that the edge density of Fon-der-Flaass\n$(3,4)$-graph is $\\geq\\frac{7}{16}(1-o(1))$, using flag algebras. In this\npaper, we give an elementary proof of this result."}
{"id": "2507.17180", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17180", "abs": "https://arxiv.org/abs/2507.17180", "authors": ["Hao Jiang", "Quan Zhou", "Dongdong Zhao", "Shangshang Yang", "Wenjian Luo", "Xingyi Zhang"], "title": "A Privacy-Preserving Data Collection Method for Diversified Statistical Analysis", "comment": null, "summary": "Data perturbation-based privacy-preserving methods have been widely adopted\nin various scenarios due to their efficiency and the elimination of the need\nfor a trusted third party. However, these methods primarily focus on individual\nstatistical indicators, neglecting the overall quality of the collected data\nfrom a distributional perspective. Consequently, they often fall short of\nmeeting the diverse statistical analysis requirements encountered in practical\ndata analysis. As a promising sensitive data perturbation method, negative\nsurvey methods is able to complete the task of collecting sensitive information\ndistribution while protecting personal privacy. Yet, existing negative survey\nmethods are primarily designed for discrete sensitive information and are\ninadequate for real-valued data distributions. To bridge this gap, this paper\nproposes a novel real-value negative survey model, termed RVNS, for the first\ntime in the field of real-value sensitive information collection. The RVNS\nmodel exempts users from the necessity of discretizing their data and only\nrequires them to sample a set of data from a range that deviates from their\nactual sensitive details, thereby preserving the privacy of their genuine\ninformation. Moreover, to accurately capture the distribution of sensitive\ninformation, an optimization problem is formulated, and a novel approach is\nemployed to solve it. Rigorous theoretical analysis demonstrates that the RVNS\nmodel conforms to the differential privacy model, ensuring robust privacy\npreservation. Comprehensive experiments conducted on both synthetic and\nreal-world datasets further validate the efficacy of the proposed method."}
{"id": "2507.17493", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.17493", "abs": "https://arxiv.org/abs/2507.17493", "authors": ["Alexander Beiser", "Markus Hecher", "Stefan Woltran"], "title": "Automated Hybrid Grounding Using Structural and Data-Driven Heuristics", "comment": null, "summary": "The grounding bottleneck poses one of the key challenges that hinders the\nwidespread adoption of Answer Set Programming in industry. Hybrid Grounding is\na step in alleviating the bottleneck by combining the strength of standard\nbottom-up grounding with recently proposed techniques where rule bodies are\ndecoupled during grounding. However, it has remained unclear when hybrid\ngrounding shall use body-decoupled grounding and when to use standard bottom-up\ngrounding. In this paper, we address this issue by developing automated hybrid\ngrounding: we introduce a splitting algorithm based on data-structural\nheuristics that detects when to use body-decoupled grounding and when standard\ngrounding is beneficial. We base our heuristics on the structure of rules and\nan estimation procedure that incorporates the data of the instance. The\nexperiments conducted on our prototypical implementation demonstrate promising\nresults, which show an improvement on hard-to-ground scenarios, whereas on\nhard-to-solve instances we approach state-of-the-art performance."}
{"id": "2507.17667", "categories": ["math.CO", "05A19, 05E05"], "pdf": "https://arxiv.org/pdf/2507.17667", "abs": "https://arxiv.org/abs/2507.17667", "authors": ["Shi-Mei Ma", "Jianfeng Wang", "Guiying Yan", "Jean Yeh", "Yeong-Nan Yeh"], "title": "Symmetric decompositions and Euler-Stirling statistics on Stirling permutations", "comment": "21 pages", "summary": "The Stirling permutations introduced by Gessel-Stanley have recently received\nconsiderable attention. Motivated by Ji's recent work on Euler-Stirling\nstatistics of permutations (Sci China Math., 2025), we present several\nsymmetric decompositions of the enumerators related to Euler-Stirling\nstatistics of Stirling permutations. Firstly, we provide a partial symmetric\ndecomposition for the $1/k$-Eulerian polynomial. Secondly, we give several\nunexpected applications of the $(p,q)$-Eulerian polynomials, where $p$ marks\nthe number of fixed points and $q$ marks that of cycles. Using the change of\ngrammars, we show that the $(\\alpha,\\beta)$-Eulerian polynomials introduced by\nCarlitz-Scoville can be deduced from the $(p,q)$-Eulerian polynomials by\nspecial parametrizations. We then introduce proper and improper ascent-plateau\nstatistics on Stirling permutations. Moreover, we introduce proper ascent,\nimproper ascent, proper descent and improper descent statistics on\npermutations. Furthermore, we consider the joint distributions of\nEuler-Stirling statistics on permutations, including the numbers of improper\nascents, proper ascents, left-to-right minima and right-to-left minina. In the\nfinal part, we first give a symmetric decomposition of the joint distribution\nof the ascent-plateau and left ascent-plateau statistics, and then we show that\nthe $q$-ascent-plateau polynomials are bi-$\\gamma$-positive, where $q$ marks\nthe number of left-to-right minima."}
{"id": "2507.17199", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17199", "abs": "https://arxiv.org/abs/2507.17199", "authors": ["Ruoyang Rykie Guo"], "title": "Threshold-Protected Searchable Sharing: Privacy Preserving Aggregated-ANN Search for Collaborative RAG", "comment": null, "summary": "LLM-powered search services have driven data integration as a significant\ntrend. However, this trend's progress is fundamentally hindered, despite the\nfact that combining individual knowledge can significantly improve the\nrelevance and quality of responses in specialized queries and make AI more\nprofessional at providing services. Two key bottlenecks are private data\nrepositories' locality constraints and the need to maintain compatibility with\nmainstream search techniques, particularly Hierarchical Navigable Small World\n(HNSW) indexing for high-dimensional vector spaces. In this work, we develop a\nsecure and privacy-preserving aggregated approximate nearest neighbor search\n(SP-A$^2$NN) with HNSW compatibility under a threshold-based searchable sharing\nprimitive. A sharable bitgraph structure is constructed and extended to support\nsearches and dynamical insertions over shared data without compromising the\nunderlying graph topology. The approach reduces the complexity of a search from\n$O(n^2)$ to $O(n)$ compared to naive (undirected) graph-sharing approach when\norganizing graphs in the identical HNSW manner.\n  On the theoretical front, we explore a novel security analytical framework\nthat incorporates privacy analysis via reductions. The proposed\nleakage-guessing proof system is built upon an entirely different interactive\ngame that is independent of existing coin-toss game design. Rather than being\npurely theoretical, this system is rooted in existing proof systems but goes\nbeyond them to specifically address leakage concerns and standardize leakage\nanalysis -- one of the most critical security challenges with AI's rapid\ndevelopment."}
{"id": "2507.17512", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17512", "abs": "https://arxiv.org/abs/2507.17512", "authors": ["Yu Li", "Zhuoshi Pan", "Honglin Lin", "Mengyuan Sun", "Conghui He", "Lijun Wu"], "title": "Can One Domain Help Others? A Data-Centric Study on Multi-Domain Reasoning via Reinforcement Learning", "comment": "27 pages, 24 figures", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a\npowerful paradigm for enhancing the reasoning capabilities of LLMs. Existing\nresearch has predominantly concentrated on isolated reasoning domains such as\nmathematical problem-solving, coding tasks, or logical reasoning. However, real\nworld reasoning scenarios inherently demand an integrated application of\nmultiple cognitive skills. Despite this, the interplay among these reasoning\nskills under reinforcement learning remains poorly understood. To bridge this\ngap, we present a systematic investigation of multi-domain reasoning within the\nRLVR framework, explicitly focusing on three primary domains: mathematical\nreasoning, code generation, and logical puzzle solving. We conduct a\ncomprehensive study comprising four key components: (1) Leveraging the GRPO\nalgorithm and the Qwen-2.5-7B model family, our study thoroughly evaluates the\nmodels' in-domain improvements and cross-domain generalization capabilities\nwhen trained on single-domain datasets. (2) Additionally, we examine the\nintricate interactions including mutual enhancements and conflicts that emerge\nduring combined cross-domain training. (3) To further understand the influence\nof SFT on RL, we also analyze and compare performance differences between base\nand instruct models under identical RL configurations. (4) Furthermore, we\ndelve into critical RL training details, systematically exploring the impacts\nof curriculum learning strategies, variations in reward design, and\nlanguage-specific factors. Through extensive experiments, our results offer\nsignificant insights into the dynamics governing domain interactions, revealing\nkey factors influencing both specialized and generalizable reasoning\nperformance. These findings provide valuable guidance for optimizing RL\nmethodologies to foster comprehensive, multi-domain reasoning capabilities in\nLLMs."}
{"id": "2507.17739", "categories": ["math.CO", "05C45, 05C15, 05C45"], "pdf": "https://arxiv.org/pdf/2507.17739", "abs": "https://arxiv.org/abs/2507.17739", "authors": ["Wenchong Chen", "Mingyuan Rong", "Zixiang Xu"], "title": "Optimal stability results on color-biased Hamilton cycles", "comment": "14 pages, 3 figures", "summary": "We investigate Hamilton cycles in edge-colored graphs with \\( r \\) colors,\nfocusing on the notion of color-bias (discrepancy), the maximum deviation from\nuniform color frequencies along a cycle. Foundational work by Balogh, Csaba,\nJing, and Pluh\\'{a}r, and the later generalization by Freschi, Hyde, Lada, and\nTreglown, as well as an independent work by Gishboliner, Krivelevich, and\nMichaeli, established that any \\(n\\)-vertex graph with minimum degree exceeding\n\\( \\frac{(r+1)n}{2r} + \\frac{m}{2}\\) contains a Hamilton cycle with color-bias\nat least \\(m\\), and characterized the extremal graphs with minimum degree\n\\(\\frac{(r+1)n}{2r}\\) in which all Hamilton cycles are perfectly balanced.\n  We prove the optimal stability results: for any positive integers \\(r\\ge 2\\)\nand \\( m < 2^{-6} r^{2} n,\\) if every Hamilton cycle in an \\( n \\)-vertex graph\nwith minimum degree exceeding \\( \\frac{n}{2} + 6r^{2}m \\) has color-bias less\nthan \\( m \\), then the graph must closely resemble the extremal constructions\nof Freschi, Hyde, Lada, and Treglown. The leading term \\( \\frac{n}{2} \\) in the\ndegree condition is optimal, as it is the sharp threshold for guaranteeing\nHamiltonicity. Moreover, we show the additive error term \\(\\Theta(m)\\) is also\nbest possible when \\(m\\) is large and \\(r=2\\), since weaker condition\n$\\frac{n}{2}+o(m)$ allow for a counterexample. Notably, the structural\nstability threshold \\( \\frac{1}{2} \\) lies strictly below the extremal\nthreshold \\( \\frac{1}{2} + \\frac{1}{2r} \\) required to force color imbalance.\nOur proof leverages local configurations to deduce global structure, revealing\na rigid combinatorial dichotomy."}
{"id": "2507.17259", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.17259", "abs": "https://arxiv.org/abs/2507.17259", "authors": ["Eyal German", "Sagiv Antebi", "Daniel Samira", "Asaf Shabtai", "Yuval Elovici"], "title": "Tab-MIA: A Benchmark Dataset for Membership Inference Attacks on Tabular Data in LLMs", "comment": null, "summary": "Large language models (LLMs) are increasingly trained on tabular data, which,\nunlike unstructured text, often contains personally identifiable information\n(PII) in a highly structured and explicit format. As a result, privacy risks\narise, since sensitive records can be inadvertently retained by the model and\nexposed through data extraction or membership inference attacks (MIAs). While\nexisting MIA methods primarily target textual content, their efficacy and\nthreat implications may differ when applied to structured data, due to its\nlimited content, diverse data types, unique value distributions, and\ncolumn-level semantics. In this paper, we present Tab-MIA, a benchmark dataset\nfor evaluating MIAs on tabular data in LLMs and demonstrate how it can be used.\nTab-MIA comprises five data collections, each represented in six different\nencoding formats. Using our Tab-MIA benchmark, we conduct the first evaluation\nof state-of-the-art MIA methods on LLMs finetuned with tabular data across\nmultiple encoding formats. In the evaluation, we analyze the memorization\nbehavior of pretrained LLMs on structured data derived from Wikipedia tables.\nOur findings show that LLMs memorize tabular data in ways that vary across\nencoding formats, making them susceptible to extraction via MIAs. Even when\nfine-tuned for as few as three epochs, models exhibit high vulnerability, with\nAUROC scores approaching 90% in most cases. Tab-MIA enables systematic\nevaluation of these risks and provides a foundation for developing\nprivacy-preserving methods for tabular data in LLMs."}
{"id": "2507.17514", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17514", "abs": "https://arxiv.org/abs/2507.17514", "authors": ["Athanasios Davvetas", "Xenia Ziouvelou", "Ypatia Dami", "Alexis Kaponis", "Konstantina Giouvanopoulou", "Michael Papademas"], "title": "TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment", "comment": "9 pages, 1 figure, 4 tables", "summary": "This paper introduces the TAI Scan Tool, a RAG-based TAI self-assessment tool\nwith minimalistic input. The current version of the tool supports the legal TAI\nassessment, with a particular emphasis on facilitating compliance with the AI\nAct. It involves a two-step approach with a pre-screening and an assessment\nphase. The assessment output of the system includes insight regarding the\nrisk-level of the AI system according to the AI Act, while at the same time\nretrieving relevant articles to aid with compliance and notify on their\nobligations. Our qualitative evaluation using use-case scenarios yields\npromising results, correctly predicting risk levels while retrieving relevant\narticles across three distinct semantic groups. Furthermore, interpretation of\nresults shows that the tool's reasoning relies on comparison with the setting\nof high-risk systems, a behaviour attributed to their deployment requiring\ncareful consideration, and therefore frequently presented within the AI Act."}
{"id": "2507.17503", "categories": ["math.LO", "math.CO", "03E05 (Primary) 03E50, 03E15, 06A05 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.17503", "abs": "https://arxiv.org/abs/2507.17503", "authors": ["Raphaël Carroy", "Maxwell Levine", "Lorenzo Notaro"], "title": "Some questions on entangled linear orders", "comment": "26 pages", "summary": "Entangled linear orders were first introduced by Abraham and Shelah.\nTodor\\v{c}evi\\'c showed that these linear orders exist under $\\mathsf{CH}$. We\nprove the following results: (1) If $\\mathsf{CH}$ holds, then, for every $n >\n0$, there is an $n$-entangled linear order which is not $(n+1)$-entangled. (2)\nIf $\\mathsf{CH}$ holds, then there are two homeomorphic sets of reals $A, B\n\\subseteq \\mathbb{R}$ such that $A$ is entangled but $B$ is not $2$-entangled.\n(3) If $\\mathbb{R}\\subseteq \\mathrm{L}$, then there is an entangled $\\Pi_1^1$\nset of reals. (4) If $\\diamondsuit$ holds, then there is a $2$-entangled\nnon-separable linear order."}
{"id": "2507.17324", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17324", "abs": "https://arxiv.org/abs/2507.17324", "authors": ["Yifan Xu", "Jinfu Chen", "Zhenyu Qi", "Huashan Chen", "Junyi Wang", "Pengfei Hu", "Feng Liu", "Sen He"], "title": "An Empirical Study on Virtual Reality Software Security Weaknesses", "comment": null, "summary": "Virtual Reality (VR) has emerged as a transformative technology across\nindustries, yet its security weaknesses, including vulnerabilities, are\nunderinvestigated. This study investigates 334 VR projects hosted on GitHub,\nexamining 1,681 software security weaknesses to understand: what types of\nweaknesses are prevalent in VR software; {\\em when} and {\\em how} weaknesses\nare introduced; how long they have survived; and how they have been removed.\nDue to the limited availability of VR software security weaknesses in public\ndatabases (e.g., the National Vulnerability Database or NVD), we prepare the\n{first systematic} dataset of VR software security weaknesses by introducing a\nnovel framework to collect such weaknesses from GitHub commit data. Our\nempirical study on the dataset leads to useful insights, including: (i) VR\nweaknesses are heavily skewed toward user interface weaknesses, followed by\nresource-related weaknesses; (ii) VR development tools pose higher security\nrisks than VR applications; (iii) VR security weaknesses are often introduced\nat the VR software birth time."}
{"id": "2507.17539", "categories": ["cs.AI", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.17539", "abs": "https://arxiv.org/abs/2507.17539", "authors": ["Xinyao Liu", "Diping Song"], "title": "Constructing Ophthalmic MLLM for Positioning-diagnosis Collaboration Through Clinical Cognitive Chain Reasoning", "comment": null, "summary": "Multimodal large language models (MLLMs) demonstrate significant potential in\nthe field of medical diagnosis. However, they face critical challenges in\nspecialized domains such as ophthalmology, particularly the fragmentation of\nannotation granularity and inconsistencies in clinical reasoning logic, which\nhinder precise cross-modal understanding. This paper introduces FundusExpert,\nan ophthalmology-specific MLLM with integrated positioning-diagnosis reasoning\ncapabilities, along with FundusGen, a dataset constructed through the\nintelligent Fundus-Engine system. Fundus-Engine automates localization and\nleverages MLLM-based semantic expansion to integrate global disease\nclassification, local object detection, and fine-grained feature analysis\nwithin a single fundus image. Additionally, by constructing a clinically\naligned cognitive chain, it guides the model to generate interpretable\nreasoning paths. FundusExpert, fine-tuned with instruction data from FundusGen,\nachieves the best performance in ophthalmic question-answering tasks,\nsurpassing the average accuracy of the 40B MedRegA by 26.6%. It also excels in\nzero-shot report generation tasks, achieving a clinical consistency of 77.0%,\nsignificantly outperforming GPT-4o's 47.6%. Furthermore, we reveal a scaling\nlaw between data quality and model capability ($L \\propto N^{0.068}$),\ndemonstrating that the cognitive alignment annotations in FundusGen enhance\ndata utilization efficiency. By integrating region-level localization with\ndiagnostic reasoning chains, our work develops a scalable, clinically-aligned\nMLLM and explores a pathway toward bridging the visual-language gap in specific\nMLLMs. Our project can be found at https://github.com/MeteorElf/FundusExpert."}
{"id": "2507.17385", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17385", "abs": "https://arxiv.org/abs/2507.17385", "authors": ["Mohammad Eslami", "Ashira Johara", "Kyungbin Park", "Samuel Pagliarini"], "title": "A Zero-overhead Flow for Security Closure", "comment": null, "summary": "In the traditional Application-Specific Integrated Circuit (ASIC) design\nflow, the concept of timing closure implies to reach convergence during\nphysical synthesis such that, under a given area and power budget, the design\nworks at the targeted frequency. However, security has been largely neglected\nwhen evaluating the Quality of Results (QoR) from physical synthesis. In\ngeneral, commercial place & route tools do not understand security goals. In\nthis work, we propose a modified ASIC design flow that is security-aware and,\ndifferently from prior research, does not degrade QoR for the sake of security\nimprovement. Therefore, we propose a first-of-its-kind zero-overhead flow for\nsecurity closure. Our flow is concerned with two distinct threat models: (i)\ninsertion of Hardware Trojans (HTs) and (ii) physical probing/fault injection.\nImportantly, the flow is entirely executed within a commercial place & route\nengine and is scalable. In several metrics, our security-aware flow achieves\nthe best-known results for the ISPD`22 set of benchmark circuits while\nincurring negligible design overheads due to security-related strategies.\nFinally, we open source the entire methodology (as a set of scripts) and also\nshare the protected circuits (as design databases) for the benefit of the\nhardware security community."}
{"id": "2507.17680", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.17680", "abs": "https://arxiv.org/abs/2507.17680", "authors": ["Yongchao Zeng", "Calum Brown", "Ioannis Kyriakou", "Ronja Hotz", "Mark Rounsevell"], "title": "Simulating multiple human perspectives in socio-ecological systems using large language models", "comment": null, "summary": "Understanding socio-ecological systems requires insights from diverse\nstakeholder perspectives, which are often hard to access. To enable\nalternative, simulation-based exploration of different stakeholder\nperspectives, we develop the HoPeS (Human-Oriented Perspective Shifting)\nmodelling framework. HoPeS employs agents powered by large language models\n(LLMs) to represent various stakeholders; users can step into the agent roles\nto experience perspectival differences. A simulation protocol serves as a\n\"scaffold\" to streamline multiple perspective-taking simulations, supporting\nusers in reflecting on, transitioning between, and integrating across\nperspectives. A prototype system is developed to demonstrate HoPeS in the\ncontext of institutional dynamics and land use change, enabling both\nnarrative-driven and numerical experiments. In an illustrative experiment, a\nuser successively adopts the perspectives of a system observer and a researcher\n- a role that analyses data from the embedded land use model to inform\nevidence-based decision-making for other LLM agents representing various\ninstitutions. Despite the user's effort to recommend technically sound\npolicies, discrepancies persist between the policy recommendation and\nimplementation due to stakeholders' competing advocacies, mirroring real-world\nmisalignment between researcher and policymaker perspectives. The user's\nreflection highlights the subjective feelings of frustration and disappointment\nas a researcher, especially due to the challenge of maintaining political\nneutrality while attempting to gain political influence. Despite this, the user\nexhibits high motivation to experiment with alternative narrative framing\nstrategies, suggesting the system's potential in exploring different\nperspectives. Further system and protocol refinement are likely to enable new\nforms of interdisciplinary collaboration in socio-ecological simulations."}
{"id": "2507.17491", "categories": ["cs.CR", "cs.NI", "68M25", "C.2.2"], "pdf": "https://arxiv.org/pdf/2507.17491", "abs": "https://arxiv.org/abs/2507.17491", "authors": ["Nazatul H. Sultan", "Xinlong Guan", "Josef Pieprzyk", "Wei Ni", "Sharif Abuadbba", "Hajime Suzuki"], "title": "Active Attack Resilience in 5G: A New Take on Authentication and Key Agreement", "comment": "Accepted at RAID 2025", "summary": "As 5G networks expand into critical infrastructure, secure and efficient user\nauthentication is more important than ever. The 5G-AKA protocol, standardized\nby 3GPP in TS 33.501, is central to authentication in current 5G deployments.\nIt provides mutual authentication, user privacy, and key secrecy. However,\ndespite its adoption, 5G-AKA has known limitations in both security and\nperformance. While it focuses on protecting privacy against passive attackers,\nrecent studies show its vulnerabilities to active attacks. It also relies on a\nsequence number mechanism to prevent replay attacks, requiring perfect\nsynchronization between the device and the core network. This stateful design\nadds complexity, causes desynchronization, and incurs extra communication\noverhead. More critically, 5G-AKA lacks Perfect Forward Secrecy (PFS), exposing\npast communications if long-term keys are compromised-an increasing concern\namid sophisticated threats. This paper proposes an enhanced authentication\nprotocol that builds on 5G-AKA's design while addressing its shortcomings.\nFirst, we introduce a stateless version that removes sequence number reliance,\nreducing complexity while staying compatible with existing SIM cards and\ninfrastructure. We then extend this design to add PFS with minimal\ncryptographic overhead. Both protocols are rigorously analyzed using ProVerif,\nconfirming their compliance with all major security requirements, including\nresistance to passive and active attacks, as well as those defined by 3GPP and\nacademic studies. We also prototype both protocols and evaluate their\nperformance against 5G-AKA and 5G-AKA' (USENIX'21). Our results show the\nproposed protocols offer stronger security with only minor computational\noverhead, making them practical, future-ready solutions for 5G and beyond."}
{"id": "2507.17695", "categories": ["cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.17695", "abs": "https://arxiv.org/abs/2507.17695", "authors": ["Ilias Chatzistefanidis", "Navid Nikaein"], "title": "Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks", "comment": "Submitted to Computer Networks AI for 6G", "summary": "Large Language Model (LLM)-based autonomous agents are expected to play a\nvital role in the evolution of 6G networks, by empowering real-time\ndecision-making related to management and service provisioning to end-users.\nThis shift facilitates the transition from a specialized intelligence approach,\nwhere artificial intelligence (AI) algorithms handle isolated tasks, to\nartificial general intelligence (AGI)-driven networks, where agents possess\nbroader reasoning capabilities and can manage diverse network functions. In\nthis paper, we introduce a novel agentic paradigm that combines LLMs with\nreal-time optimization algorithms towards Trustworthy AI, defined as symbiotic\nagents. Optimizers at the LLM's input-level provide bounded uncertainty\nsteering for numerically precise tasks, whereas output-level optimizers\nsupervised by the LLM enable adaptive real-time control. We design and\nimplement two novel agent types including: (i) Radio Access Network optimizers,\nand (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We\nfurther propose an end-to-end architecture for AGI networks and evaluate it on\na 5G testbed capturing channel fluctuations from moving vehicles. Results show\nthat symbiotic agents reduce decision errors fivefold compared to standalone\nLLM-based agents, while smaller language models (SLM) achieve similar accuracy\nwith a 99.9% reduction in GPU resource overhead and in near-real-time loops of\n82 ms. A multi-agent demonstration for collaborative RAN on the real-world\ntestbed highlights significant flexibility in service-level agreement and\nresource allocation, reducing RAN over-utilization by approximately 44%.\nDrawing on our findings and open-source implementations, we introduce the\nsymbiotic paradigm as the foundation for next-generation, AGI-driven\nnetworks-systems designed to remain adaptable, efficient, and trustworthy even\nas LLMs advance."}
{"id": "2507.17516", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17516", "abs": "https://arxiv.org/abs/2507.17516", "authors": ["Shafizur Rahman Seeam", "Ye Zheng", "Yidan Hu"], "title": "Frequency Estimation of Correlated Multi-attribute Data under Local Differential Privacy", "comment": null, "summary": "Large-scale data collection, from national censuses to IoT-enabled smart\nhomes, routinely gathers dozens of attributes per individual. These\nmulti-attribute datasets are vital for analytics but pose significant privacy\nrisks. Local Differential Privacy (LDP) is a powerful tool to protect user data\nprivacy by allowing users to locally perturb their records before releasing to\nan untrusted data aggregator. However, existing LDP mechanisms either split the\nprivacy budget across all attributes or treat each attribute independently,\nignoring natural inter-attribute correlations. This leads to excessive noise or\nfragmented budgets, resulting in significant utility loss, particularly in\nhigh-dimensional settings.\n  To overcome these limitations, we propose Correlated Randomized Response\n(Corr-RR), a novel LDP mechanism that leverages correlations among attributes\nto substantially improve utility while maintaining rigorous LDP guarantees.\nCorr-RR allocates the full privacy budget to perturb a single, randomly\nselected attribute and reconstructs the remaining attributes using estimated\ninterattribute dependencies, without incurring additional privacy cost. To\nenable this, Corr-RR operates in two phases: (1) a subset of users apply\nstandard LDP mechanisms to estimate correlations, and (2) each remaining user\nperturbs one attribute and infers the others using the learned correlations. We\ntheoretically prove that Corr-RR satisfies $\\epsilon$-LDP, and extensive\nexperiments on synthetic and real-world datasets demonstrate that Corr-RR\nconsistently outperforms state-of-the-art LDP mechanisms, particularly in\nscenarios with many attributes and strong inter-attribute correlations."}
{"id": "2507.17699", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17699", "abs": "https://arxiv.org/abs/2507.17699", "authors": ["Zhao Song", "Song Yue", "Jiahao Zhang"], "title": "Thinking Isn't an Illusion: Overcoming the Limitations of Reasoning Models via Tool Augmentations", "comment": null, "summary": "Large Reasoning Models (LRMs) have become a central focus in today's large\nlanguage model (LLM) research, where models are designed to output a\nstep-by-step thinking process before arriving at a final answer to handle\ncomplex reasoning tasks. Despite their promise, recent empirical studies (e.g.,\n[Shojaee et al., 2025] from Apple) suggest that this thinking process may not\nactually enhance reasoning ability, where LLMs without explicit reasoning\nactually outperform LRMs on tasks with low or high complexity. In this work, we\nrevisit these findings and investigate whether the limitations of LRMs persist\nwhen tool augmentations are introduced. We incorporate two types of tools,\nPython interpreters and scratchpads, and evaluate three representative LLMs and\ntheir LRM counterparts on Apple's benchmark reasoning puzzles. Our results show\nthat, with proper tool use, LRMs consistently outperform their non-reasoning\ncounterparts across all levels of task complexity. These findings challenge the\nrecent narrative that reasoning is an illusion and highlight the potential of\ntool-augmented LRMs for solving complex problems."}
{"id": "2507.17518", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.17518", "abs": "https://arxiv.org/abs/2507.17518", "authors": ["Vita Santa Barletta", "Vito Bavaro", "Miriana Calvano", "Antonio Curci", "Antonio Piccinno", "Davide Pio Posa"], "title": "Enabling Cyber Security Education through Digital Twins and Generative AI", "comment": null, "summary": "Digital Twins (DTs) are gaining prominence in cybersecurity for their ability\nto replicate complex IT (Information Technology), OT (Operational Technology),\nand IoT (Internet of Things) infrastructures, allowing for real time\nmonitoring, threat analysis, and system simulation. This study investigates how\nintegrating DTs with penetration testing tools and Large Language Models (LLMs)\ncan enhance cybersecurity education and operational readiness. By simulating\nrealistic cyber environments, this approach offers a practical, interactive\nframework for exploring vulnerabilities and defensive strategies. At the core\nof this research is the Red Team Knife (RTK), a custom penetration testing\ntoolkit aligned with the Cyber Kill Chain model. RTK is designed to guide\nlearners through key phases of cyberattacks, including reconnaissance,\nexploitation, and response within a DT powered ecosystem. The incorporation of\nLarge Language Models (LLMs) further enriches the experience by providing\nintelligent, real-time feedback, natural language threat explanations, and\nadaptive learning support during training exercises. This combined DT LLM\nframework is currently being piloted in academic settings to develop hands on\nskills in vulnerability assessment, threat detection, and security operations.\nInitial findings suggest that the integration significantly improves the\neffectiveness and relevance of cybersecurity training, bridging the gap between\ntheoretical knowledge and real-world application. Ultimately, the research\ndemonstrates how DTs and LLMs together can transform cybersecurity education to\nmeet evolving industry demands."}
{"id": "2507.17730", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17730", "abs": "https://arxiv.org/abs/2507.17730", "authors": ["Zhe Chen", "Daniel Harabor", "Ryan Hechnenberger", "Nathan R. Sturtevant"], "title": "Online Submission and Evaluation System Design for Competition Operations", "comment": "This work was presented at the Workshop on the International Planning\n  Competition (WIPC 2024)", "summary": "Research communities have developed benchmark datasets across domains to\ncompare the performance of algorithms and techniques However, tracking the\nprogress in these research areas is not easy, as publications appear in\ndifferent venues at the same time, and many of them claim to represent the\nstate-of-the-art. To address this, research communities often organise periodic\ncompetitions to evaluate the performance of various algorithms and techniques,\nthereby tracking advancements in the field. However, these competitions pose a\nsignificant operational burden. The organisers must manage and evaluate a large\nvolume of submissions. Furthermore, participants typically develop their\nsolutions in diverse environments, leading to compatibility issues during the\nevaluation of their submissions. This paper presents an online competition\nsystem that automates the submission and evaluation process for a competition.\nThe competition system allows organisers to manage large numbers of submissions\nefficiently, utilising isolated environments to evaluate submissions. This\nsystem has already been used successfully for several competitions, including\nthe Grid-Based Pathfinding Competition and the League of Robot Runners\ncompetition."}
{"id": "2507.17628", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17628", "abs": "https://arxiv.org/abs/2507.17628", "authors": ["Matteo Strada"], "title": "Quantifying the ROI of Cyber Threat Intelligence: A Data-Driven Approach", "comment": "14 pages", "summary": "The valuation of Cyber Threat Intelligence (CTI) remains a persistent\nchallenge due to the problem of negative evidence: successful threat prevention\nresults in non-events that generate minimal observable financial impact, making\nCTI expenditures difficult to justify within traditional cost-benefit\nframeworks. This study introduces a data-driven methodology for quantifying the\nreturn on investment (ROI) of CTI, thereby reframing it as a measurable\ncontributor to risk mitigation. The proposed framework extends established\nmodels in security economics, including the Gordon-Loeb and FAIR models, to\naccount for CTI's complex influence on both the probability of security\nbreaches and the severity of associated losses. The framework is\noperationalized through empirically grounded performance indicators, such as\nreductions in mean time to detect (MTTD), mean time to respond (MTTR), and\nadversary dwell time, supported by three sector-specific case studies in\nfinance, healthcare, and retail. To address limitations in conventional linear\nassessment methodologies, the Threat Intelligence Effectiveness Index (TIEI) is\nintroduced as a composite metric based on a weighted geometric mean. TIEI\npenalizes underperformance across critical dimensions: quality, enrichment,\nintegration, and operational impact; thereby capturing bottleneck effect where\nthe least effective component limits overall performance. By integrating\nfinancial quantification, adversarial coverage, and qualitative assessments of\nbusiness enablement, the proposed hybrid model converts negative evidence into\na justifiable ROI explanation. This approach offers a replicable means of\nrepositioning CTI from an expense to a strategic investment, enabling informed\ndecision-making and continuous optimization across diverse organizational\ncontexts."}
{"id": "2507.16540", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16540", "abs": "https://arxiv.org/abs/2507.16540", "authors": ["Radowanul Haque", "Aftab Ali", "Sally McClean", "Naveed Khan"], "title": "Explainable Vulnerability Detection in C/C++ Using Edge-Aware Graph Attention Networks", "comment": null, "summary": "Detecting security vulnerabilities in source code remains challenging,\nparticularly due to class imbalance in real-world datasets where vulnerable\nfunctions are under-represented. Existing learning-based methods often optimise\nfor recall, leading to high false positive rates and reduced usability in\ndevelopment workflows. Furthermore, many approaches lack explainability,\nlimiting their integration into security workflows. This paper presents\nExplainVulD, a graph-based framework for vulnerability detection in C/C++ code.\nThe method constructs Code Property Graphs and represents nodes using\ndual-channel embeddings that capture both semantic and structural information.\nThese are processed by an edge-aware attention mechanism that incorporates\nedge-type embeddings to distinguish among program relations. To address class\nimbalance, the model is trained using class-weighted cross-entropy loss.\nExplainVulD achieves a mean accuracy of 88.25 percent and an F1 score of 48.23\npercent across 30 independent runs on the ReVeal dataset. These results\nrepresent relative improvements of 4.6 percent in accuracy and 16.9 percent in\nF1 score compared to the ReVeal model, a prior learning-based method. The\nframework also outperforms static analysis tools, with relative gains of 14.0\nto 14.1 percent in accuracy and 132.2 to 201.2 percent in F1 score. Beyond\nimproved detection performance, ExplainVulD produces explainable outputs by\nidentifying the most influential code regions within each function, supporting\ntransparency and trust in security triage."}
{"id": "2507.17655", "categories": ["cs.CR", "cs.NI", "cs.SE", "C.2.4; D.4.6; E.3; E.5; K.6.5"], "pdf": "https://arxiv.org/pdf/2507.17655", "abs": "https://arxiv.org/abs/2507.17655", "authors": ["Shams Shaikh", "Trima P. Fernandes e Fizardo"], "title": "Rethinking HSM and TPM Security in the Cloud: Real-World Attacks and Next-Gen Defenses", "comment": "9 pages, 2 Flowcharts, 2 Tables", "summary": "As organizations rapidly migrate to the cloud, the security of cryptographic\nkey management has become a growing concern. Hardware Security Modules (HSMs)\nand Trusted Platform Modules (TPMs), traditionally seen as the gold standard\nfor securing encryption keys and digital trust, are increasingly challenged by\ncloud-native threats. Real-world breaches have exposed weaknesses in cloud\ndeployments, including misconfigurations, API abuse, and privilege escalations,\nallowing attackers to access sensitive key material and bypass protections.\nThese incidents reveal that while the hardware remains secure, the surrounding\ncloud ecosystem introduces systemic vulnerabilities. This paper analyzes\nnotable security failures involving HSMs and TPMs, identifies common attack\nvectors, and questions longstanding assumptions about their effectiveness in\ndistributed environments. We explore alternative approaches such as\nconfidential computing, post-quantum cryptography, and decentralized key\nmanagement. Our findings highlight that while HSMs and TPMs still play a role,\nmodern cloud security requires more adaptive, layered architectures. By\nevaluating both current weaknesses and emerging models, this research equips\ncloud architects and security engineers with strategies to reinforce\ncryptographic trust in the evolving threat landscape."}
{"id": "2507.16840", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16840", "abs": "https://arxiv.org/abs/2507.16840", "authors": ["Weijia Yang", "Tian Lan", "Leyuan Liu", "Wei Chen", "Tianqing Zhu", "Sheng Wen", "Xiaosong Zhang"], "title": "CASPER: Contrastive Approach for Smart Ponzi Scheme Detecter with More Negative Samples", "comment": null, "summary": "The rapid evolution of digital currency trading, fueled by the integration of\nblockchain technology, has led to both innovation and the emergence of smart\nPonzi schemes. A smart Ponzi scheme is a fraudulent investment operation in\nsmart contract that uses funds from new investors to pay returns to earlier\ninvestors. Traditional Ponzi scheme detection methods based on deep learning\ntypically rely on fully supervised models, which require large amounts of\nlabeled data. However, such data is often scarce, hindering effective model\ntraining. To address this challenge, we propose a novel contrastive learning\nframework, CASPER (Contrastive Approach for Smart Ponzi detectER with more\nnegative samples), designed to enhance smart Ponzi scheme detection in\nblockchain transactions. By leveraging contrastive learning techniques, CASPER\ncan learn more effective representations of smart contract source code using\nunlabeled datasets, significantly reducing both operational costs and system\ncomplexity. We evaluate CASPER on the XBlock dataset, where it outperforms the\nbaseline by 2.3% in F1 score when trained with 100% labeled data. More\nimpressively, with only 25% labeled data, CASPER achieves an F1 score nearly\n20% higher than the baseline under identical experimental conditions. These\nresults highlight CASPER's potential for effective and cost-efficient detection\nof smart Ponzi schemes, paving the way for scalable fraud detection solutions\nin the future."}
{"id": "2507.16852", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16852", "abs": "https://arxiv.org/abs/2507.16852", "authors": ["Álvaro Ruiz-Ródenas", "Jaime Pujante Sáez", "Daniel García-Algora", "Mario Rodríguez Béjar", "Jorge Blasco", "José Luis Hernández-Ramos"], "title": "SynthCTI: LLM-Driven Synthetic CTI Generation to enhance MITRE Technique Mapping", "comment": "17 pages, 13 figures", "summary": "Cyber Threat Intelligence (CTI) mining involves extracting structured\ninsights from unstructured threat data, enabling organizations to understand\nand respond to evolving adversarial behavior. A key task in CTI mining is\nmapping threat descriptions to MITRE ATT\\&CK techniques. However, this process\nis often performed manually, requiring expert knowledge and substantial effort.\nAutomated approaches face two major challenges: the scarcity of high-quality\nlabeled CTI data and class imbalance, where many techniques have very few\nexamples. While domain-specific Large Language Models (LLMs) such as SecureBERT\nhave shown improved performance, most recent work focuses on model architecture\nrather than addressing the data limitations. In this work, we present SynthCTI,\na data augmentation framework designed to generate high-quality synthetic CTI\nsentences for underrepresented MITRE ATT\\&CK techniques. Our method uses a\nclustering-based strategy to extract semantic context from training data and\nguide an LLM in producing synthetic CTI sentences that are lexically diverse\nand semantically faithful. We evaluate SynthCTI on two publicly available CTI\ndatasets, CTI-to-MITRE and TRAM, using LLMs with different capacity.\nIncorporating synthetic data leads to consistent macro-F1 improvements: for\nexample, ALBERT improves from 0.35 to 0.52 (a relative gain of 48.6\\%), and\nSecureBERT reaches 0.6558 (up from 0.4412). Notably, smaller models augmented\nwith SynthCTI outperform larger models trained without augmentation,\ndemonstrating the value of data generation methods for building efficient and\neffective CTI classification systems."}
{"id": "2507.16872", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16872", "abs": "https://arxiv.org/abs/2507.16872", "authors": ["Na Li", "Yansong Gao", "Hongsheng Hu", "Boyu Kuang", "Anmin Fu"], "title": "CompLeak: Deep Learning Model Compression Exacerbates Privacy Leakage", "comment": null, "summary": "Model compression is crucial for minimizing memory storage and accelerating\ninference in deep learning (DL) models, including recent foundation models like\nlarge language models (LLMs). Users can access different compressed model\nversions according to their resources and budget. However, while existing\ncompression operations primarily focus on optimizing the trade-off between\nresource efficiency and model performance, the privacy risks introduced by\ncompression remain overlooked and insufficiently understood.\n  In this work, through the lens of membership inference attack (MIA), we\npropose CompLeak, the first privacy risk evaluation framework examining three\nwidely used compression configurations that are pruning, quantization, and\nweight clustering supported by the commercial model compression framework of\nGoogle's TensorFlow-Lite (TF-Lite) and Facebook's PyTorch Mobile. CompLeak has\nthree variants, given available access to the number of compressed models and\noriginal model. CompLeakNR starts by adopting existing MIA methods to attack a\nsingle compressed model, and identifies that different compressed models\ninfluence members and non-members differently. When the original model and one\ncompressed model are available, CompLeakSR leverages the compressed model as a\nreference to the original model and uncovers more privacy by combining meta\ninformation (e.g., confidence vector) from both models. When multiple\ncompressed models are available with/without accessing the original model,\nCompLeakMR innovatively exploits privacy leakage info from multiple compressed\nversions to substantially signify the overall privacy leakage. We conduct\nextensive experiments on seven diverse model architectures (from ResNet to\nfoundation models of BERT and GPT-2), and six image and textual benchmark\ndatasets."}
{"id": "2507.16887", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16887", "abs": "https://arxiv.org/abs/2507.16887", "authors": ["Youpeng Li", "Weiliang Qi", "Xuyu Wang", "Fuxun Yu", "Xinda Wang"], "title": "Revisiting Pre-trained Language Models for Vulnerability Detection", "comment": null, "summary": "The rapid advancement of pre-trained language models (PLMs) has demonstrated\npromising results for various code-related tasks. However, their effectiveness\nin detecting real-world vulnerabilities remains a critical challenge. % for the\nsecurity community. While existing empirical studies evaluate PLMs for\nvulnerability detection (VD), their inadequate consideration in data\npreparation, evaluation setups, and experimental settings undermines the\naccuracy and comprehensiveness of evaluations. This paper introduces RevisitVD,\nan extensive evaluation of 17 PLMs spanning smaller code-specific PLMs and\nlarge-scale PLMs using newly constructed datasets. Specifically, we compare the\nperformance of PLMs under both fine-tuning and prompt engineering, assess their\neffectiveness and generalizability across various training and testing\nsettings, and analyze their robustness against code normalization, abstraction,\nand semantic-preserving transformations.\n  Our findings reveal that, for VD tasks, PLMs incorporating pre-training tasks\ndesigned to capture the syntactic and semantic patterns of code outperform both\ngeneral-purpose PLMs and those solely pre-trained or fine-tuned on large code\ncorpora. However, these models face notable challenges in real-world scenarios,\nsuch as difficulties in detecting vulnerabilities with complex dependencies,\nhandling perturbations introduced by code normalization and abstraction, and\nidentifying semantic-preserving vulnerable code transformations. Also, the\ntruncation caused by the limited context windows of PLMs can lead to a\nnon-negligible amount of labeling errors. This study underscores the importance\nof thorough evaluations of model performance in practical scenarios and\noutlines future directions to help enhance the effectiveness of PLMs for\nrealistic VD applications."}
{"id": "2507.16952", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16952", "abs": "https://arxiv.org/abs/2507.16952", "authors": ["Md Min-Ha-Zul Abedin", "Tazqia Mehrub"], "title": "Evaluating Ensemble and Deep Learning Models for Static Malware Detection with Dimensionality Reduction Using the EMBER Dataset", "comment": null, "summary": "This study investigates the effectiveness of several machine learning\nalgorithms for static malware detection using the EMBER dataset, which contains\nfeature representations of Portable Executable (PE) files. We evaluate eight\nclassification models: LightGBM, XGBoost, CatBoost, Random Forest, Extra Trees,\nHistGradientBoosting, k-Nearest Neighbors (KNN), and TabNet, under three\npreprocessing settings: original feature space, Principal Component Analysis\n(PCA), and Linear Discriminant Analysis (LDA). The models are assessed on\naccuracy, precision, recall, F1 score, and AUC to examine both predictive\nperformance and robustness. Ensemble methods, especially LightGBM and XGBoost,\nshow the best overall performance across all configurations, with minimal\nsensitivity to PCA and consistent generalization. LDA improves KNN performance\nbut significantly reduces accuracy for boosting models. TabNet, while promising\nin theory, underperformed under feature reduction, likely due to architectural\nsensitivity to input structure. The analysis is supported by detailed\nexploratory data analysis (EDA), including mutual information ranking, PCA or\nt-SNE visualizations, and outlier detection using Isolation Forest and Local\nOutlier Factor (LOF), which confirm the discriminatory capacity of key features\nin the EMBER dataset. The results suggest that boosting models remain the most\nreliable choice for high-dimensional static malware detection, and that\ndimensionality reduction should be applied selectively based on model type.\nThis work provides a benchmark for comparing classification models and\npreprocessing strategies in malware detection tasks and contributes insights\nthat can guide future system development and real-world deployment."}
{"id": "2507.17010", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17010", "abs": "https://arxiv.org/abs/2507.17010", "authors": ["H M Mohaimanul Islam", "Huynh Q. N. Vo", "Aditya Rane"], "title": "Towards Trustworthy AI: Secure Deepfake Detection using CNNs and Zero-Knowledge Proofs", "comment": "Submitted for peer-review in TrustXR - 2025", "summary": "In the era of synthetic media, deepfake manipulations pose a significant\nthreat to information integrity. To address this challenge, we propose\nTrustDefender, a two-stage framework comprising (i) a lightweight convolutional\nneural network (CNN) that detects deepfake imagery in real-time extended\nreality (XR) streams, and (ii) an integrated succinct zero-knowledge proof\n(ZKP) protocol that validates detection results without disclosing raw user\ndata. Our design addresses both the computational constraints of XR platforms\nwhile adhering to the stringent privacy requirements in sensitive settings.\nExperimental evaluations on multiple benchmark deepfake datasets demonstrate\nthat TrustDefender achieves 95.3% detection accuracy, coupled with efficient\nproof generation underpinned by rigorous cryptography, ensuring seamless\nintegration with high-performance artificial intelligence (AI) systems. By\nfusing advanced computer vision models with provable security mechanisms, our\nwork establishes a foundation for reliable AI in immersive and\nprivacy-sensitive applications."}
{"id": "2507.17518", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.17518", "abs": "https://arxiv.org/abs/2507.17518", "authors": ["Vita Santa Barletta", "Vito Bavaro", "Miriana Calvano", "Antonio Curci", "Antonio Piccinno", "Davide Pio Posa"], "title": "Enabling Cyber Security Education through Digital Twins and Generative AI", "comment": null, "summary": "Digital Twins (DTs) are gaining prominence in cybersecurity for their ability\nto replicate complex IT (Information Technology), OT (Operational Technology),\nand IoT (Internet of Things) infrastructures, allowing for real time\nmonitoring, threat analysis, and system simulation. This study investigates how\nintegrating DTs with penetration testing tools and Large Language Models (LLMs)\ncan enhance cybersecurity education and operational readiness. By simulating\nrealistic cyber environments, this approach offers a practical, interactive\nframework for exploring vulnerabilities and defensive strategies. At the core\nof this research is the Red Team Knife (RTK), a custom penetration testing\ntoolkit aligned with the Cyber Kill Chain model. RTK is designed to guide\nlearners through key phases of cyberattacks, including reconnaissance,\nexploitation, and response within a DT powered ecosystem. The incorporation of\nLarge Language Models (LLMs) further enriches the experience by providing\nintelligent, real-time feedback, natural language threat explanations, and\nadaptive learning support during training exercises. This combined DT LLM\nframework is currently being piloted in academic settings to develop hands on\nskills in vulnerability assessment, threat detection, and security operations.\nInitial findings suggest that the integration significantly improves the\neffectiveness and relevance of cybersecurity training, bridging the gap between\ntheoretical knowledge and real-world application. Ultimately, the research\ndemonstrates how DTs and LLMs together can transform cybersecurity education to\nmeet evolving industry demands."}
