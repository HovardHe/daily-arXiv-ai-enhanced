<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 3]
- [math.OC](#math.OC) [Total: 9]
- [math.NT](#math.NT) [Total: 9]
- [math.LO](#math.LO) [Total: 1]
- [math.GM](#math.GM) [Total: 1]
- [math.CO](#math.CO) [Total: 17]
- [q-fin.MF](#q-fin.MF) [Total: 1]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [cs.CR](#cs.CR) [Total: 4]
- [cs.AI](#cs.AI) [Total: 23]
- [stat.TH](#stat.TH) [Total: 1]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Learning Smooth Populations of Parameters with Trial Heterogeneity](https://arxiv.org/abs/2507.23140)
*JungHo Lee,Valerio Baćak,Edward H. Kennedy*

Main category: math.ST

TL;DR: 本文研究了在试验异质性和平滑性条件下二项混合分布的混合分布估计问题，提出了基于核密度估计器的快速误差率，并在刑事司法应用中比较了不同辩护类型的定罪率。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于刑事司法领域的实际应用：比较宾夕法尼亚州贫困辩护中指定律师（法院指定的私人律师）和公设辩护人的定罪率差异，并探讨潜在混杂因素。

Method: 在假设密度为s-平滑的条件下，推导了试验异质性下核密度估计器的快速误差率，该速率依赖于试验的调和平均数。同时研究了独立同分布和二项混合设置中两密度差异的非参数估计。

Result: 研究结果显示，即使在同质试验情况下，本文方法也优于Ye和Bickel（2021）的最新成果。应用分析表明，指定律师的估计定罪率通常高于公设辩护人，可能与指定律师更可能接手严重案件这一混杂因素有关。

Conclusion: 本文提出的方法在异质性试验条件下实现了更优的估计速率，并在刑事司法数据分析中揭示了辩护类型与定罪率之间的潜在关联，为混杂因素影响提供了实证证据。

Abstract: We consider the classical problem of estimating the mixing distribution of
binomial mixtures, but under trial heterogeneity and smoothness. This problem
has been studied extensively when the trial parameter is homogeneous, but not
under the more general scenario of heterogeneous trials, and only within a low
smoothness regime, where the resulting rates are slow. Under the assumption
that the density is s-smooth, we derive fast error rates for the kernel density
estimator under trial heterogeneity that depend on the harmonic mean of the
trials. Importantly, even when reduced to the homogeneous case, our result
improves on the state-of-the-art rate of Ye and Bickel (2021). We also study
nonparametric estimation of the difference between two densities, which can be
smoother than the individual densities, in both i.i.d. and binomial-mixture
settings. Our work is motivated by an application in criminal justice:
comparing conviction rates of indigent representation in Pennsylvania. We find
that the estimated conviction rates for appointed counsel (court-appointed
private attorneys) are generally higher than those for public defenders,
potentially due to a confounding factor: appointed counsel are more likely to
take on severe cases.

</details>


### [2] [CLT in high-dimensional Bayesian linear regression with low SNR](https://arxiv.org/abs/2507.23285)
*Seunghyun Lee,Nabarun Deb,Sumit Mukherjee*

Main category: math.ST

TL;DR: 本文研究了高维贝叶斯线性回归中线性统计量的中心极限定理，重点探讨了非收缩机制下的后验分布一维投影及后验均值的极限分布。


<details>
  <summary>Details</summary>
Motivation: 现代高维数据集通常具有有限的信噪比，这促使我们在非收缩机制下研究后验分布的极限行为，其中似然函数和先验分布都不占主导地位。

Method: 结合随机场Ising模型的Berry-Esseen型边界以及一阶和二阶Poincar\\'{e}不等式，研究了白噪声设计和错误指定的贝叶斯模型两种具体模型。

Result: 极限分布为高斯分布，但强烈依赖于所选先验，并以后验的平均场近似为中心。在不要求先验稀疏性的情况下，构建了可信区间并计算了其覆盖概率。

Conclusion: 该研究为非收缩机制下高维贝叶斯回归的极限分布提供了理论框架，揭示了先验选择对后验分布的重要影响。

Abstract: We study central limit theorems for linear statistics in high-dimensional
Bayesian linear regression with product priors. Unlike the existing literature
where the focus is on posterior contraction, we work under a non-contracting
regime where neither the likelihood nor the prior dominates the other. This is
motivated by modern high-dimensional datasets characterized by a bounded
signal-to-noise ratio. This work takes a first step towards understanding limit
distributions for one-dimensional projections of the posterior, as well as the
posterior mean, in such regimes. Analogous to contractive settings, the
resulting limiting distributions are Gaussian, but they heavily depend on the
chosen prior and center around the Mean-Field approximation of the posterior.
We study two concrete models of interest to illustrate this phenomenon -- the
white noise design, and the (misspecified) Bayesian model. As an application,
we construct credible intervals and compute their coverage probability under
any misspecified prior. Our proofs rely on a combination of recent developments
in Berry-Esseen type bounds for Random Field Ising models and both first and
second order Poincar\'{e} inequalities. Notably, our results do not require any
sparsity assumptions on the prior.

</details>


### [3] [Optimal-Transport Based Multivariate Goodness-of-Fit Tests](https://arxiv.org/abs/2507.23490)
*Zdeněk Hlávka,Šárka Hudecová,Simos G. Meintanis*

Main category: math.ST

TL;DR: 本文提出了一种基于特征函数的多元观测拟合优度检验方法，通过最优测度输运理论构建多元秩，实现简单零假设的分布无关性检验。


<details>
  <summary>Details</summary>
Motivation: 现有多元正态性检验方法在有限样本中表现不佳，需要开发更有效的检验统计量。

Method: 采用两样本准则衡量原始观测与参考分布生成样本的多元秩差异，利用最优测度输运理论构建检验统计量，对复合假设需结合自助法。

Result: 仿真研究表明，该方法在有限样本中表现优于现有多元正态性检验方法，且具有渐进理论支持。

Conclusion: 基于特征函数和最优输运的多元秩检验法为多元分布检验提供了有效工具，特别适用于简单零假设场景。

Abstract: Characteristic-function based goodness-of-fit tests are suggested for
multivariate observations. The test statistics, which are straightforward to
compute, are defined as two-sample criteria measuring discrepancy between
multivariate ranks of the original observations and the corresponding ranks
obtained from an artificial sample generated from the reference distribution
under test. Multivariate ranks are constructed using the theory of the optimal
measure transport, thus rendering the tests of a simple null hypothesis
distribution-free, while bootstrap approximations are still necessary for
testing composite null hypotheses. Asymptotic theory is developed and a
simulation study, concentrating on comparisons with previously proposed tests
of multivariate normality, demonstrates that the method performs well in finite
samples.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [4] [Adaptive direct search algorithms for constrained optimization](https://arxiv.org/abs/2507.23054)
*Charles Audet,Théo Denorme,Youssef Diouane,Sébastien Le Digabel,Christophe Tribes*

Main category: math.OC

TL;DR: 本文提出了一种新的无导数优化方法——自适应直接搜索（ADS），通过引入基于穿孔空间的接受规则，结合了MADS和SDDS的优点，避免了二者的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的无导数优化方法MADS和SDDS各有局限：MADS限制试验点位置但可能错过改进点，SDDS允许自由搜索但可能丢弃改进点。需要一种能兼顾灵活性和效率的新方法。

Method: ADS采用基于穿孔空间的新型接受规则，既不依赖网格限制（如MADS），也不要求充分下降条件（如SDDS），同时保留了方向直接搜索的理论基础。

Result: 在带约束和无约束场景下的计算结果表明，ADS的性能优于MADS和SDDS，实现了更灵活的搜索能力。

Conclusion: ADS通过创新性接受规则成功融合了MADS和SDDS的优势，为无导数优化提供了更高效的解决方案，具有理论和实践价值。

Abstract: Two families of directional direct search methods have emerged in
derivative-free and blackbox optimization (DFO and BBO), each based on distinct
principles: Mesh Adaptive Direct Search (MADS) and Sufficient Decrease Direct
Search (SDDS). MADS restricts trial points to a mesh and accepts any
improvement, ensuring none are missed, but at the cost of restraining the
placement of trial points. SDDS allows greater freedom by evaluating points
anywhere in the space, but accepts only those yielding a sufficient decrease in
the objective function value, which may lead to discarding improving points.
  This work introduces a new class of methods, Adaptive Direct Search (ADS),
which uses a novel acceptance rule based on the so-called punctured space,
avoiding both meshes and sufficient decrease conditions. ADS enables flexible
search while addressing the limitations of MADS and SDDS, and retains the
theoretical foundations of directional direct search. Computational results in
constrained and unconstrained settings highlight its performance compared to
both MADS and SDDS.

</details>


### [5] [Stability-Constrained AC Optimal Power Flow -- A Gaussian Process-Based Approach](https://arxiv.org/abs/2507.23094)
*Vincenzo Di Vito,Kaarthik Sundar,Ferdinando Fioretto,Deepjyoti Deka*

Main category: math.OC

TL;DR: 本文提出了一种数据驱动方法，将发电机动态特性融入交流最优潮流问题，通过高斯过程模型确保运行点同时满足经济性和动态稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统交流最优潮流（ACOPF）依赖稳态模型，忽略发电机动态行为，可能导致经济最优但动态不稳定的运行点。

Method: 采用高斯过程回归学习同步发电机动态微分方程解的稳定性指数，构建指数代理函数表征稳定性，并将概率稳定性评估直接整合至优化过程。

Result: 在IEEE 39、57和118节点系统中的实验表明，该方法能用少量训练数据有效捕捉发电机动态，获得更可靠、鲁棒的运行决策。

Conclusion: 所提出的动态感知ACOPF框架实现了运行安全性与动态稳定性的协同优化，为电力系统调度提供了新思路。

Abstract: The Alternating Current Optimal Power Flow (ACOPF) problem is a core task in
power system operations, aimed at determining cost-effective generation
dispatch while satisfying physical and operational constraints. However,
conventional ACOPF formulations rely on steady-state models and neglect the
dynamic behavior of generators, which can lead to operating points that are
economically optimal but dynamically unstable. This paper proposes a novel,
data-driven approach to incorporate generator dynamics into the ACOPF using
Gaussian Process (GP) models. Specifically, it introduces an exponential
surrogate function to characterize the stability of solutions to the
differential equations governing synchronous generator dynamics. The exponent,
which indicates whether system trajectories decay (stable) or grow (unstable),
is learned as a function of the bus voltage using GP regression. Crucially, the
framework enables probabilistic stability assessment to be integrated directly
into the optimization process. The resulting dynamics-aware ACOPF formulation
identifies operating points that satisfy both operational safety and dynamic
stability criteria. Numerical experiments on the IEEE 39-bus, 57-bus, and
118-bus systems demonstrate that the proposed method efficiently captures
generator dynamics using limited training data, leading to more reliable and
robust decisions across a wide range of operating conditions.

</details>


### [6] [On the Complexity of Finding Stationary Points in Nonconvex Simple Bilevel Optimization](https://arxiv.org/abs/2507.23155)
*Jincheng Cao,Ruichen Jiang,Erfan Yazdandoost Hamedani,Aryan Mokhtari*

Main category: math.OC

TL;DR: 本文研究非凸双层优化问题，提出一种动态屏障梯度下降（DBGD）框架，首次实现多项式时间内找到联合平稳点。


<details>
  <summary>Details</summary>
Motivation: 针对上下层目标均为光滑但可能非凸的双层优化问题，由于缺乏凸性或PL条件等结构假设，全局最优解难以保证，因此需要设计高效算法寻找平稳点。

Method: 采用动态屏障梯度下降（DBGD）框架，通过定义合适的平稳性概念，设计可实现的离散时间算法，平衡上下层目标的收敛精度。

Result: 算法达到$(\epsilon_f, \epsilon_g)$-平稳点的复杂度为$\mathcal{O}\left(\max\left(\epsilon_f^{-\frac{3+p}{1+p}}, \epsilon_g^{-\frac{3+p}{2}}\right)\right)$，其中$p \geq 0$为平衡参数。

Conclusion: 这是首个针对一般非凸双层优化问题、能保证双层联合平稳性的离散时间算法复杂度结果，填补了该领域空白。

Abstract: In this paper, we study the problem of solving a simple bilevel optimization
problem, where the upper-level objective is minimized over the solution set of
the lower-level problem. We focus on the general setting in which both the
upper- and lower-level objectives are smooth but potentially nonconvex. Due to
the absence of additional structural assumptions for the lower-level
objective-such as convexity or the Polyak-{\L}ojasiewicz (PL)
condition-guaranteeing global optimality is generally intractable. Instead, we
introduce a suitable notion of stationarity for this class of problems and aim
to design a first-order algorithm that finds such stationary points in
polynomial time. Intuitively, stationarity in this setting means the
upper-level objective cannot be substantially improved locally without causing
a larger deterioration in the lower-level objective. To this end, we show that
a simple and implementable variant of the dynamic barrier gradient descent
(DBGD) framework can effectively solve the considered nonconvex simple bilevel
problems up to stationarity. Specifically, to reach an $(\epsilon_f,
\epsilon_g)$-stationary point-where $\epsilon_f$ and $\epsilon_g$ denote the
target stationarity accuracies for the upper- and lower-level objectives,
respectively-the considered method achieves a complexity of
$\mathcal{O}\left(\max\left(\epsilon_f^{-\frac{3+p}{1+p}},
\epsilon_g^{-\frac{3+p}{2}}\right)\right)$, where $p \geq 0$ is an arbitrary
constant balancing the terms. To the best of our knowledge, this is the first
complexity result for a discrete-time algorithm that guarantees joint
stationarity for both levels in general nonconvex simple bilevel problems.

</details>


### [7] [FMIP: Multimodal Flow Matching for Mixed Integer Linear Programming](https://arxiv.org/abs/2507.23390)
*Hongpei Li,Hui Yuan,Han Zhang,Dongdong Ge,Mengdi Wang,Yinyu Ye*

Main category: math.OC

TL;DR: 本文提出FMIP框架，通过多模态流匹配建模混合整数规划中整数与连续变量的联合分布，结合目标函数优化与约束满足的引导机制，在七个基准测试中平均提升解质量50.04%。


<details>
  <summary>Details</summary>
Motivation: 现有基于图神经网络的启发式方法仅预测整数变量解，难以捕捉整数与连续变量的复杂交互且表征能力不足，亟需新方法解决混合整数规划的NP完全难题。

Method: FMIP框架创新性地采用多模态流匹配技术，在混合解空间中联合建模变量分布，并引入目标函数与约束的双重引导机制指导采样过程。

Result: 在七个标准MILP基准测试中，FMIP相比现有基于GNN的预测基线平均提升解质量50.04%，显著优于传统方法。

Conclusion: FMIP通过流匹配与引导机制的协同设计，为学习型MILP求解策略提供了兼具高精度与可扩展性的新范式。

Abstract: Mixed-Integer Linear Programming (MILP) is a cornerstone of mathematical
optimization, enabling the modeling of complex decision-making problems
involving both integer and continuous variables. Despite its versatility, most
MILP problems are NP-complete, making them challenging to solve in practice.
Existing graph neural network (GNN)-based heuristics aim to reduce problem
scale by predicting only the solutions on integer variables for a given
instance, struggling to capture the intricate interplay between continuous and
integer variables and lack sufficient representational power. To address these
limitations, we propose FMIP, a novel multimodal flow-matching framework that
models the joint distribution over integer and continuous variables in the
mixed solution space of MILP. To enable more accurate and scalable heuristics,
FMIP integrates a guidance mechanism to guide solution sampling under both
objective function optimization and constraint satisfaction. We evaluate FMIP
on seven standard MILP benchmarks. Our experiments show that FMIP improves
solution quality by 50.04% on average over existing GNN-based predictive
baselines. These results highlight FMIP's potential as a powerful new approach
for developing learning based MILP solution strategy.

</details>


### [8] [Popov Mirror-Prox Method for Variational Inequalities](https://arxiv.org/abs/2507.23395)
*Abhishek Chakraborty,Angelia Nedić*

Main category: math.OC

TL;DR: 本文提出了Popov mirror-prox算法的收敛性，用于解决在多项式增长条件下的随机和确定性变分不等式（VIs），无需问题特定参数的先验知识，并验证了其在矩阵游戏、分段二次函数和ResNet-18图像分类任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要问题特定参数的先验知识，本文旨在提出完全参数自由的步长方案，填补文献中关于多项式增长映射的mirror-prox技术的空白。

Method: 提出了Popov mirror-prox算法，包括恒定和递减形式的无参数步长方案，适用于随机和确定性单调VIs，以及具有H\"older连续映射的确定性VIs。

Result: 在随机和确定性单调VIs中，证明了在有界约束集上对偶间隙函数的最优收敛速率；对于确定性VIs，在存在Minty解的情况下，无需有界集或单调映射，证明了残差函数的收敛性。

Conclusion: 通过扩展mirror-prox技术到任意多项式增长的映射，本文填补了文献空白，并通过实验验证了理论结果，能够处理某些非单调VIs类别。

Abstract: This paper establishes the convergence properties of the Popov mirror-prox
algorithm for solving stochastic and deterministic variational inequalities
(VIs) under a polynomial growth condition on the mapping variation. Unlike
existing methods that require prior knowledge of problem-specific parameters,
we propose step-size schemes that are entirely parameter-free in both constant
and diminishing forms. For stochastic and deterministic monotone VIs, we
establish optimal convergence rates in terms of the dual gap function over a
bounded constraint set. Additionally, for deterministic VIs with H\"older
continuous mapping, we prove convergence in terms of the residual function
without requiring a bounded set or a monotone mapping, provided a Minty
solution exists. This allows our method to address certain classes of
non-monotone VIs. However, knowledge of the H\"older exponent is necessary to
achieve the best convergence rates in this case. By extending mirror-prox
techniques to mappings with arbitrary polynomial growth, our work bridges an
existing gap in the literature. We validate our theoretical findings with
empirical results on matrix games, piecewise quadratic functions, and image
classification tasks using ResNet-18.

</details>


### [9] [Biobjective optimization with M-convex functions](https://arxiv.org/abs/2507.23423)
*Ellen H. Fukuda,Satoru Iwata,Itsuki Nakagawa*

Main category: math.OC

TL;DR: 本文首次将多目标优化与离散凸分析相结合，针对双目标优化问题（涉及M$^\natural$-凸函数和二元系数线性函数）提出了多项式时间算法求解整个帕累托最优值集，并在M-凸函数特例中展示了更高效率。此外，还提出了结合M$^\natural$-凸函数最小化与字典序优化的多项式时间方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索多目标优化与离散凸分析这一未被结合的领域，旨在为特定类型的双目标优化问题开发高效求解算法。

Method: 方法包括：1) 针对含M$^\natural$-凸函数和二元线性函数的双目标问题设计多项式时间算法；2) 在M-凸函数特例中优化算法效率；3) 结合M$^\natural$-凸最小化与字典序优化的新方法。

Result: 结果表明：1) 特定双目标问题的帕累托最优值集可在多项式时间内完整求解；2) M-凸函数特例的算法效率更高；3) 新方法在混合优化场景中保持多项式时间复杂度。

Conclusion: 结论指出，离散凸分析与多目标优化的结合为高效求解特定复杂优化问题提供了新途径，未来可扩展至更广泛的函数类和优化框架。

Abstract: In this paper, we deal with two ingredients that, as far as we know, have not
been combined until now: multiobjective optimization and discrete convex
analysis. First, we show that the entire Pareto optimal value set can be
obtained in polynomial time for biobjective optimization problems with discrete
convex functions, in particular, involving an M$^\natural$-convex function and
a linear function with binary coefficients. We also observe that a more
efficient algorithm can be obtained in the special case where the
M$^\natural$-convex function is M-convex. Additionally, we present a
polynomial-time method for biobjective optimization problems that combine
M$^\natural$-convex function minimization with lexicographic optimization.

</details>


### [10] [Convergence rates of Newton's method for strongly self-concordant minimization](https://arxiv.org/abs/2507.23558)
*Nick Tsipinakis,Panos Parpas*

Main category: math.OC

TL;DR: 本文填补了强自协函数牛顿法局部收敛理论空白，证明其比普通自协函数具有更快的二次收敛速度和更大的局部收敛区域。


<details>
  <summary>Details</summary>
Motivation: 现有文献对自协函数类牛顿法研究充分，但缺乏对强自协函数子类的局部收敛性分析，需验证其是否具有更优理论特性。

Method: 通过理论分析强自协函数子类的牛顿法局部收敛性，与普通自协函数进行对比研究。

Result: 强自协函数的牛顿法二次收敛速率显著优于普通自协函数，且具有更大的局部收敛区域，适用于更广泛的优化目标函数。

Conclusion: 研究完善了强自协函数牛顿法的理论框架，证实其优越的收敛性能，为相关优化问题提供了理论支撑。

Abstract: Newton's method has been thoroughly studied for the class of self-concordant
functions. However, a local analysis specific to strongly self-concordant
functions (a subclass of the former) is missing from the literature. The local
quadratic rate of strongly self-concordant functions follows, of course, from
the known results for self-concordant functions. However, it is not known
whether strongly self-concordant functions enjoy better theoretical properties.
In this paper, we study the local convergence of Newton's method for this
subclass. We show that its quadratic convergence rate differs from that of
general self-concordant functions. In particular, it is provably faster for a
wide range of objective functions and benefits from a larger region of local
convergence. Thus, the results of this paper close the gap in the theoretical
understanding of Newton's method applied to strongly self-concordant functions.

</details>


### [11] [Combinatorial Approaches for Embedded Feature Selection in Nonlinear SVMs](https://arxiv.org/abs/2507.23711)
*Federico D'Onofrio,Yuri Faenza,Laura Palagi*

Main category: math.OC

TL;DR: 本文提出了一种基于硬基数约束的非线性SVM嵌入式特征选择方法，通过混合整数非线性规划模型和交替优化框架，显著提升了特征选择效果。


<details>
  <summary>Details</summary>
Motivation: 嵌入式特征选择（FS）旨在训练模型的同时识别数据集中最相关的特征。现有硬约束方法仅适用于线性SVM的原始形式，本文探索将其应用于非线性SVM的对偶问题，以实现严格的特征数量控制并利用核化优势。

Method: 1) 将对偶非线性SVM与硬基数约束结合，构建混合整数非线性规划（MINLP）模型；2) 提出适用于通用非线性核的局部搜索元启发式算法；3) 设计分解框架，通过交替优化连续变量和二元变量子问题（多项式核下二元子问题转化为子模函数最大化问题）。

Result: 数值实验表明，所提算法在求解MINLP问题上显著优于标准方法，为特征选择问题提供了更有效的解决方案。

Conclusion: 该研究首次实现对偶非线性SVM的硬约束特征选择，通过子模优化等技术突破计算瓶颈，为可解释机器学习提供了新工具。

Abstract: Embedded Feature Selection (FS) is a classical approach for interpretable
machine learning, aiming to identify the most relevant features of a dataset
while simultaneously training the model. We consider an approach based on a
hard cardinality constraint for nonlinear SVMs. To the best of our knowledge,
hard-constraint approaches have been proposed only for the primal formulation
of linear SVMs. In contrast, we embed a hard cardinality constraint directly
into the dual of a nonlinear SVM, guaranteeing strict control over the number
of selected features while still leveraging kernelization. We formulate the
problem as a Mixed-Integer Nonlinear Programming (MINLP) model. As a first
contribution, we propose a local search metaheuristic applicable to general
nonlinear kernels. Our second and main contribution is a decomposition
framework that alternates optimization between two subproblems: one involving
only continuous variables and the other involving only binary variables. For
polynomial kernels, we show that the binary subproblem reduces to a submodular
function maximization under a cardinality constraint, enabling the use of
scalable submodular maximization algorithms within the alternating optimization
process. Numerical experiments demonstrate that our algorithms significantly
outperform standard methods for solving the proposed MINLPs, providing more
effective solutions to the addressed feature selection problem.

</details>


### [12] [Adaptive Stepsize Selection in Decentralized Convex Optimization](https://arxiv.org/abs/2507.23725)
*Ilya Kuruzov,Xiaokai Chen,Gesualdo Scutari,Alexander Gasnikov*

Main category: math.OC

TL;DR: 本文提出了一种完全自适应的去中心化优化算法，无需全局信息即可自动调整步长，适用于强凸和非强凸损失函数，并保持最佳收敛速率。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化方法的收敛性依赖于预先设定的步长，这需要全局信息且难以调整，导致实际应用中收敛缓慢或计算成本高昂。

Method: 算法通过邻居间通信实现完全自适应的步长选择，无需全局信息或强凸性假设，仅依赖局部通信。

Result: 算法在强凸损失下以线性速率收敛，非强凸损失下以次线性速率收敛，匹配依赖参数方法的最佳已知速率。

Conclusion: 该研究提供了一种高效且无需全局调参的去中心化优化方案，显著提升了实际应用的可行性和性能。

Abstract: We study decentralized optimization where multiple agents minimize the
average of their (strongly) convex, smooth losses over a communication graph.
Convergence of the existing decentralized methods generally hinges on an
apriori, proper selection of the stepsize. Choosing this value is notoriously
delicate: (i) it demands global knowledge from all the agents of the graph's
connectivity and every local smoothness/strong-convexity constants--information
they rarely have; (ii) even with perfect information, the worst-case tuning
forces an overly small stepsize, slowing convergence in practice; and (iii)
large-scale trial-and-error tuning is prohibitive. This work introduces a
decentralized algorithm that is fully adaptive in the choice of the agents'
stepsizes, without any global information and using only neighbor-to-neighbor
communications--agents need not even know whether the problem is strongly
convex. The algorithm retains strong guarantees: it converges at \emph{linear}
rate when the losses are strongly convex and at \emph{sublinear} rate
otherwise, matching the best-known rates of (nonadaptive) parameter-dependent
methods.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [13] [On the densities of covering numbers and abundant numbers](https://arxiv.org/abs/2507.23041)
*Nathan McNew,Jai Setty*

Main category: math.NT

TL;DR: 研究了覆盖数集$\mathcal{C}$的密度，证明其自然密度$d(\mathcal{C})$存在且范围在0.103230到0.103398之间，同时改进了丰数密度$d(\mathcal{A})$的界限，并给出了原始覆盖数计数的上界估计。


<details>
  <summary>Details</summary>
Motivation: 探讨覆盖数集和丰数集的密度问题，旨在精确计算覆盖数的自然密度，并改进现有丰数密度的估计方法。

Method: 采用Behrend和Del\'eglise的方法，引入函数$c(n)$衡量整数接近覆盖数的程度，结合$c(n) \leq h(n) = \sigma(n)/n$的性质，简化计算过程。

Result: 确定覆盖数集$\mathcal{C}$的密度$d(\mathcal{C})$在0.103230到0.103398之间，丰数密度$d(\mathcal{A})$的新界限为0.247619608到0.247619658，原始覆盖数的计数上界为$O\left(x\exp\left(\left(-\tfrac{1}{2\sqrt{\log 2}} + \epsilon\right)\sqrt{\log x} \log \log x\right)\right)$。

Conclusion: 通过新方法成功计算了覆盖数集的密度并改进了丰数密度的估计，同时发现原始覆盖数的增长速度远低于原始丰数。

Abstract: We investigate the densities of the sets of abundant numbers and of covering
numbers, integers $n$ for which there exists a distinct covering system where
every modulus divides $n$. We establish that the set $\mathcal{C}$ of covering
numbers possesses a natural density $d(\mathcal{C})$ and prove that $0.103230 <
d(\mathcal{C}) < 0.103398.$ Our approach adapts methods developed by Behrend
and Del\'eglise for bounding the density of abundant numbers, by introducing a
function $c(n)$ that measures how close an integer $n$ is to being a covering
number with the property that $c(n) \leq h(n) = \sigma(n)/n$. However,
computing $d(\mathcal{C})$ to three decimal digits requires some new ideas to
simplify the computations. As a byproduct of our methods, we obtain
significantly improved bounds for $d(\mathcal{A})$, the density of abundant
numbers, namely $0.247619608 < d(\mathcal{A}) < 0.247619658$. We also show the
count of primitive covering numbers up to $x$ is $O\left(
x\exp\left(\left(-\tfrac{1}{2\sqrt{\log 2}} + \epsilon\right)\sqrt{\log x} \log
\log x\right)\right)$, which is substantially smaller than the corresponding
bound for primitive abundant numbers.

</details>


### [14] [Nonzero $\mathfrak{n}$ cohomology of Totally Degenerate Limit of Discrete Series representations](https://arxiv.org/abs/2507.23102)
*Jin Kunwoo Lee*

Main category: math.NT

TL;DR: 本文证明了完全退化离散级数表示的特定上同调群在规范定义的度数下非零，并揭示了Soergel组合复形满足Serre对偶性，为酉群的TDLDS分支定律提供了新线索。


<details>
  <summary>Details</summary>
Motivation: 研究完全退化离散级数表示的上同调性质，旨在探索酉群表示论中的Gan-Gross-Prasad型分支定律。

Method: 通过分析Soergel组合复形计算上同调群，并验证其满足Serre对偶性，比较U(n+1)和U(n)群的TDLDS表示。

Result: 发现U(n+1)和U(n)的完全退化离散级数表示在相同度数下存在成对非零上同调群。

Conclusion: 该结果为任意秩酉群的完全退化离散级数表示建立了类似Gan-Gross-Prasad的分支定律框架。

Abstract: We show that a totally degenerate limit of discrete series representation
admits a choice of n cohomology group that is nonvanishing at a canonically
defined degree. We then show that the combinatorial complexes used by Soergel
to compute these cohomology groups satisfies Serre duality. We conclude that
this produces two n cohomology groups, each for a totally degenerate limit of
discrete series of U(n+1) and U(n), which are nonvanishing at the same degree.
This suggests Gan Gross Prasad type branching laws for the TDLDS of unitary
groups of any rank.

</details>


### [15] [Cyclotomy, cyclotomic cosets and arimetic propeties of some families in $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$](https://arxiv.org/abs/2507.23179)
*Juncheng Zhou,Hongfeng Wu*

Main category: math.NT

TL;DR: 本文研究了在$\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$中的算术性质，利用二阶分圆类推广了已有结果，并给出了极小理想的本原幂等元的显式表达式。


<details>
  <summary>Details</summary>
Motivation: 研究特定条件下分圆类的算术性质，以推广已有文献中的结果，并探索多项式环中理想的结构。

Method: 使用$n=p^sq^t$的二阶分圆类，其中$p\equiv3 \mathrm{mod} 4$，$\gcd(\phi(p^s),\phi(q^t))=2$，$l$是模$q^t$的原根且$\mathrm{ord}_{p^s}(l)=\phi(p^s)/2$。

Result: 获得了$\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$中极小理想的本原幂等元的显式表达式，并推广了文献中的结果。

Conclusion: 通过特定条件下的分圆类分析，成功推广了已有结果，并揭示了多项式环中理想结构的算术性质。

Abstract: Arithmetic properties of some families in $\frac{\mathbb{F}_l[x]}{\langle
x^{p^sq^t}-1\rangle}$ are obtained by using the cyclotomic classes of order 2
with respect to $n=p^sq^t$, where $p\equiv3 \mathrm{mod} 4$,
$\gcd(\phi(p^s),\phi(q^t))=2$, $l$ is a primitive root modulo $q^t$ and
$\mathrm{ord}_{p^s}(l)=\phi(p^s)/2$. The form of these cyclotomic classes
enables us to further generalize the results obtained in \cite{ref1}. The
explicit expressions of primitive idempotents of minimal ideals in
$\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ are also obtained.

</details>


### [16] [Extending bounds on minimal ranks of universal quadratic lattices to larger number fields](https://arxiv.org/abs/2507.23338)
*Matěj Doležálek*

Main category: math.NT

TL;DR: 本文改进了Kala的技术，通过研究数域复合体中的子域结构，利用基本伽罗瓦理论将其转化为群论问题，证明了若在d次全实数域中存在通用格的最小秩$\geq r$，则在所有$k\geq3$的kd次域中也存在。


<details>
  <summary>Details</summary>
Motivation: 已有大量文献证明在某些全实数域族中，通用二次格的最小秩可以任意大。Kala提出了一种技术，在满足某些条件下将这类结果推广到更大域（如从二次域到任意偶数次域）。本文旨在改进这一技术。

Method: 通过研究数域复合体中的子域结构，利用基本伽罗瓦理论将其转化为群论问题，从而改进Kala的推广技术。

Result: 证明了若在d次全实数域中存在通用格的最小秩$\geq r$，则在所有$k\geq3$的kd次域中也存在这样的域。

Conclusion: 本文通过群论方法改进了Kala的技术，显著扩展了通用格最小秩下界的存在性结果的应用范围。

Abstract: There exist numerous results in the literature proving that within certain
families of totally real number fields, the minimal rank of a universal
quadratic lattice over such a field can be arbitrarily large. Kala introduced a
technique of extending such results to larger fields -- e.g. from quadratic
fields to fields of arbitrary even degree -- under some conditions. We present
improvements to this technique by investigating the structure of subfields
within composita of number fields, using basic Galois theory to translate this
into a group-theoretic problem. In particular, we show that if totally real
number fields with minimal rank of a universal lattice $\geq r$ exist in degree
$d$, then they also exist in degree $kd$ for all $k\geq3$.

</details>


### [17] [Discrete restrictions from Laurent monomial systems for multiple Dirichlet series](https://arxiv.org/abs/2507.23477)
*Shenghao Hua*

Main category: math.NT

TL;DR: 本文介绍了一类特殊的多元Dirichlet级数，其项支持在某个簇上并具有欧拉积结构，这些级数自然地来源于Dirichlet扭曲的自守\(L\)-函数的扭曲矩。


<details>
  <summary>Details</summary>
Motivation: 研究多元Dirichlet级数的动机在于理解其与自守\(L\)-函数扭曲矩之间的自然联系，以及探索这些级数的解析性质。

Method: 通过分析Dirichlet扭曲的自守\(L\)-函数的扭曲矩，构建了具有欧拉积结构的多元Dirichlet级数。

Result: 结果表明，这类多元Dirichlet级数不仅具有欧拉积结构，而且与自守\(L\)-函数的扭曲矩密切相关。

Conclusion: 本文提出了关于这些级数解析性质的若干猜想，为进一步研究提供了方向。

Abstract: We introduce a special class of multiple Dirichlet series whose terms are
supported on a variety and which admit an Euler product structure. We show that
these series arise naturally from twisted moments of automorphic \( L
\)-functions associated with Dirichlet twists. We proposed several conjectures
on the analytic properties of these series.

</details>


### [18] [Picturesque convolution-like recurrences and partial sums' generation](https://arxiv.org/abs/2507.23619)
*Ignas Gasparavičius,Andrius Grigutis,Juozas Petkelis*

Main category: math.NT

TL;DR: 本文研究如何从已知序列${\pmb b}$推导出相关序列${\pmb a}$，展示其极限与初始项的关系，并通过实例说明${\pmb a}$可呈现几何图案或经典数列如黎曼ζ函数部分和。


<details>
  <summary>Details</summary>
Motivation: 探索序列${\pmb b}$与${\pmb a}$之间的数学关系，扩展序列构造方法的应用场景，包括生成几何图案和经典数列。

Method: 提出递推方法建立序列${\pmb a}$与${\pmb b}$的关联式$a_n = \sum_{k=0}^{n+m} a_k b_{n+m-k}$，分析$\lim_{n\to\infty}a_n$与初始项$a_0,\ldots,a_{m-1}$的联系。

Result: 证明序列${\pmb a}$的极限行为依赖初始项，展示其可生成平面/空间几何图案，且特定${\pmb b}$能导出黎曼ζ函数部分和等经典序列。

Conclusion: 该序列构造方法具有普适性，可统一处理多种数学对象，为序列分析与图形化表示提供新工具。

Abstract: Let ${\pmb b}=\{b_0,\,b_1,\,\ldots\}$ be the known sequence of numbers such
that $b_0\neq0$. In this work, we develop methods to find another sequence
${\pmb a}=\{a_0,\,a_1,\,\ldots\}$ that is related to ${\pmb b}$ as follows:
$a_n=a_0\,b_{n+m}+a_1\,b_{n+m-1}+\ldots+a_{n+m}\,b_0$,
$n\in\mathbb{N}\cup\{0\}$, $m\in\mathbb{N}$. We show the connection of
$\lim_{n\to\infty}a_n$ with $a_0,\,a_1,\,\ldots,\,a_{m-1}$ and provide varied
examples of finding the sequence ${\pmb a}$ when ${\pmb b}$ is given. We
demonstrate that the sequences ${\pmb a}$ may exhibit pretty patterns in the
plane or space. Also, we show that the properly chosen sequence ${\pmb b}$ may
define ${\pmb a}$ as some famous sequences, such as the partial sums of the
Riemann zeta function, etc.

</details>


### [19] [An evident corollary arising from Newton--Thorne](https://arxiv.org/abs/2507.23656)
*Shenghao Hua*

Main category: math.NT

TL;DR: 本文提出了一类特殊的自守提升例子，涉及多个自守表示的张量积，其动机源于Schur多项式的组合恒等式以及Newton和Thorne的著名结果。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于Schur多项式的组合恒等式以及Newton和Thorne的著名结果，旨在探索自守表示张量积的提升问题。

Method: 通过匹配$L$-函数的方法，研究了一类特殊的自守提升例子，涉及多个自守表示的张量积。

Result: 研究结果表明，存在一类特殊的自守提升例子，能够匹配多个自守表示张量积的$L$-函数。

Conclusion: 本文通过组合恒等式和$L$-函数匹配，成功构建了一类特殊的自守提升例子，为自守表示理论提供了新的视角。

Abstract: We present a special class of examples of automorphic lifts of multiple
tensor products of automorphic representations in the sense of matching
$L$-functions, motivated by combinatorial identities for Schur polynomials and
a celebrated result of Newton and Thorne.

</details>


### [20] [A Central Limit Theorem for the Winding Number of Low-Lying Closed Geodesics](https://arxiv.org/abs/2507.23706)
*Elias Dubno*

Main category: math.NT

TL;DR: 模曲面上的低洼闭合测地线在按任意自然长度归一化后，其绕数具有高斯极限分布。


<details>
  <summary>Details</summary>
Motivation: 研究模曲面上闭合测地线的统计性质，特别是其绕数分布的极限行为。

Method: 通过分析模曲面上低洼闭合测地线的几何特性，并采用自然长度归一化方法进行研究。

Result: 发现归一化后的绕数分布收敛于高斯分布，揭示了其统计规律性。

Conclusion: 该结果不仅深化了对模曲面上测地线行为的理解，也为相关领域的统计研究提供了新的视角。

Abstract: We show that the winding of low-lying closed geodesics on the modular surface
has a Gaussian limiting distribution when normalized by any natural notion of
length.

</details>


### [21] [Bost-Connes systems and periodic Witt vectors](https://arxiv.org/abs/2507.23759)
*Bora Yalkinoglu*

Main category: math.NT

TL;DR: 利用Borger周期Witt向量理论，构建了一般数域Bost-Connes系统算术子代数的积分细化。


<details>
  <summary>Details</summary>
Motivation: 研究Bost-Connes系统在一般数域上的算术子代数结构，寻求其积分层面的理论扩展。

Method: 采用Borger的周期Witt向量理论作为主要工具，进行代数结构的构造与分析。

Result: 成功构造了与一般数域Bost-Connes系统相关的算术子代数的积分细化版本。

Conclusion: 该研究为Bost-Connes系统的算术结构提供了更深入的积分理论框架，拓展了其在数域上的应用潜力。

Abstract: In this note, using Borger's theory of periodic Witt vectors, we construct
integral refinements of the arithmetic subalgebras associated with Bost-Connes
systems for general number fields.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [22] [Convolution semigroups for automorphism dynamics](https://arxiv.org/abs/2507.23503)
*Kyle Gannon,Daniel Max Hoffmann,Krzysztof Krupiński*

Main category: math.LO

TL;DR: 该研究从Hrushovski关于可定义模式的论文出发，建立了与一阶结构自同构群自然作用相关的Ellis半群与类型及Keisler测度集合之间的同胚映射，进而推广出适用于任意一阶理论中不变类型与测度的新卷积运算，并证明了幂等测度与自同构群闭子群之间的对应关系。


<details>
  <summary>Details</summary>
Motivation: 研究最初受Hrushovski关于可定义模式的论文启发，旨在探索一阶结构自同构群作用下的Ellis半群与类型及Keisler测度集合之间的深层联系。

Method: 通过建立Ellis半群与类型/测度集合的同胚映射，将半群运算转移至后者；进而推广出不变类型与测度的新卷积运算，并利用仿射类构造验证其与可定义群上标准卷积运算的兼容性。

Result: 成功构建了新型卷积运算的通用理论，证明了幂等测度与（相对可定义拓扑下）超大模型自同构群闭子群之间的对应定理，并通过仿射类构造表明新卷积可编码可定义群上的标准卷积运算。

Conclusion: 该研究不仅建立了Ellis半群与类型/测度系统的运算对应，还发展出具有普适性的卷积理论，为模型论与拓扑动力学的交叉研究提供了新工具，特别在可定义群卷积运算的抽象刻画方面取得突破。

Abstract: Initially motivated by Hrushovski's paper on definability patterns, we obtain
homeomorphisms between Ellis semigroups related to natural actions of the
automorphism groups of first order structures and certain collections of types
and Keisler measures. Thus, we can transfer the semigroup operation from these
Ellis semigroups to the corresponding collections of types and Keisler
measures. By generalizing this transferred product, we obtain a new convolution
operation for invariant types and measures in arbitrary first-order theories.
We develop its general theory and prove several correspondence theorems between
idempotent measures and closed subgroups of the automorphism group of a
sufficiently large (so-called monster) model with respect to the relatively
definable topology. Via the affine sort construction, we demonstrate that this
new notion of convolution encodes the standard definable convolution operation
over definable groups.

</details>


<div id='math.GM'></div>

# math.GM [[Back]](#toc)

### [23] [On the Explicit Expression of an Extended Version of Riemann Zeta Function](https://arxiv.org/abs/2507.22961)
*Yushi Huang*

Main category: math.GM

TL;DR: 本文通过Mellin反演公式和Cauchy留数定理，研究了扩展Riemann zeta函数的显式表达式，并探讨了其在特殊函数积分中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究扩展Riemann zeta函数$\sum_{m=1}^{\infty}\sum_{n=1}^{\infty}{(m+n)^{-s}}$的显式表达式，并验证其Mellin-Barnes积分的绝对收敛性。

Method: 使用Mellin反演公式和Cauchy留数定理计算积分，通过改变积分路径并应用Riemann zeta函数的函数方程、Euler反射公式和Legendre倍乘公式。

Result: 成功推导出扩展Riemann zeta函数的显式表达式，并展示了其与双曲函数等特殊函数积分的联系。

Conclusion: 该研究不仅提供了扩展Riemann zeta函数的显式表达式，还为Barnes zeta函数的显式表达提供了新的推导方法。

Abstract: In this paper, we focus on the explicit expression of an extended version of
Riemann zeta function. We use two different methods, Mellin inversion formula
and Cauchy's residue theorem, to calculate a Mellin-Barnes type integral of the
analytic function regarding $z$: $\Gamma(z)\Gamma(s-z)u^{-z}$ ($u\in (0,1)$,
$s\in \mathbb{C}$). We provide the necessary background on the analytic
properties of Gamma and Riemann zeta function to confirm the absolute
convergence of this Mellin-Barnes integral. Next, we represent the extended
version of Riemann zeta function
$\sum_{m=1}^{\infty}\sum_{n=1}^{\infty}{(m+n)^{-s}}$ using the following
complex integral where the real part of $s$ is larger than 2 and $c>1$ is
chosen to make $\Re(s)-c$ larger than 1.
$$\Gamma(s)\sum_{m=1}^{\infty}\sum_{n=1}^{\infty}{(m+n)^{-s}}=\frac{1}{2\pi i}
\int_{c - i\infty}^{c + i\infty} \zeta(z) \zeta(s - z) \Gamma(z) \Gamma(s - z)
\, dz$$ We provide the evaluation of this integral by changing the integration
path from straight line $\Re(z)=c$ into a rectangular contour whose left side
is positioned at negative infinity. We apply the functional equation of Riemann
zeta function, Euler's reflection formula, and Legendre's duplication formula
to evaluate the integral segment through $\Re(z)=-\infty$. After introducing
Hurwitz zeta function and properly calculating the difference between the sum
of residues in two analogous rectangular contours, we finalize the evaluation.
Lastly, we demonstrate the connection of this result with other intricate
integrals involving special functions, such as the hyperbolic function.
Additionally, we discuss its applications in deriving explicit expressions for
the Barnes zeta function.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [24] [Domination, matching and transversal numbers for Berge-$G$ hypergraphs](https://arxiv.org/abs/2507.22957)
*María José Chávez de Diego,Pablo Montero Moreno,María Trinidad Villar-Liñán*

Main category: math.CO

TL;DR: 本文研究了Berge-G超图的扩张问题，探讨了支配数、匹配数和横截数之间的关系，推广了广义幂超图的相关结果。


<details>
  <summary>Details</summary>
Motivation: 研究Berge-G超图的扩张家族，旨在理解超图中支配、匹配和横截参数之间的内在联系，扩展广义幂超图的现有理论。

Method: 通过定义图的扩张作为Berge-G超图的特定子族，分析其非均匀性，并运用组合数学方法研究支配数、匹配数和横截数的性质。

Result: 在Berge-G超图的扩张家族中，获得了支配数、匹配数和横截数之间的新关系，这些结果推广了广义幂超图的已有结论。

Conclusion: 该研究为Berge-G超图的扩张理论提供了新的视角，其成果可应用于超图参数分析和组合优化问题。

Abstract: Let $G=(V(G),E(G))$ be a graph and $H=(V(H),E(H))$ be a hypergraph. The
hypergraph $H$ is a {\it Berge-G} if there is a bijection $f : E(G) \mapsto
E(H)$ such that for each $e \in E(G)$ we have $e \subseteq f(e)$. We define
{\it dilations of $G$} as a particular subfamily of not necessarily uniform
Berge-$G$ hypergraphs. We examine domination, matching and transversal numbers
and some relation between these parameters in that family of hypergraphs.
  Our work generalizes previous results concerning generalized power
hypergraphs.

</details>


### [25] [Character theoretic techniques for nonabelian partial difference sets](https://arxiv.org/abs/2507.23039)
*Seth R. Nelson,Eric Swartz*

Main category: math.CO

TL;DR: 本文研究了非阿贝尔群中的$(v,k,\lambda, \mu)$-部分差集（PDS），开发了适用于非阿贝尔环境的特征理论技术，证明了若干不存在性结果，并构造了新的非阿贝尔PDS实例。


<details>
  <summary>Details</summary>
Motivation: 近年来，非阿贝尔群中的PDS研究受到广泛关注。本文旨在开发适用于非阿贝尔群的特征理论技术，以扩展传统阿贝尔群中的研究方法。

Method: 作者推广了Ott关于广义四边形特征理论的结果，将其应用于一般PDS场景，并利用这些技术计算PDS与父群共轭类的交集。

Result: 研究证明了多种情况下PDS的不存在性，并对可能存在的PDS施加了严格限制。此外，构造性地发现了文献中未记载的非阿贝尔PDS实例，包括与Clapham研究的块正则Steiner三重系相关的无限族。

Conclusion: 本文发展的特征理论技术有效解决了非阿贝尔群中PDS的研究难题，既可用于否定性证明，又能指导新PDS的构造，特别是发现了与块正则Steiner设计相关的无限非阿贝尔PDS族。

Abstract: A $(v,k,\lambda, \mu)$-partial difference set (PDS) is a subset $D$ of size
$k$ of a group $G$ of order $v$ such that every nonidentity element $g$ of $G$
can be expressed in either $\lambda$ or $\mu$ different ways as a product
$xy^{-1}$, $x, y \in D$, depending on whether or not $g$ is in $D$. If $D$ is
inverse closed and $1 \notin D$, then the Cayley graph ${\rm Cay}(G,D)$ is a
$(v,k,\lambda, \mu)$-strongly regular graph (SRG). PDSs have been studied
extensively over the years, especially in abelian groups, where techniques from
character theory have proven to be particularly effective. Recently, there has
been considerable interest in studying PDSs in nonabelian groups, and the
purpose of this paper is develop character theoretic techniques that apply in
the nonabelian setting. We prove that analogues of character theoretic results
of Ott about generalized quadrangles of order $s$ also hold in the general PDS
setting, and we are able to use these techniques to compute the intersection of
a putative PDS with the conjugacy classes of the parent group in many
instances. With these techniques, we are able to prove the nonexistence of PDSs
in numerous instances and provide severe restrictions in cases when such PDSs
may still exist. Furthermore, we are able to use these techniques
constructively, computing several examples of PDSs in nonabelian groups not
previously recognized in the literature, including an infinite family of
genuinely nonabelian PDSs associated to the block-regular Steiner triple
systems originally studied by Clapham and related infinite families of
genuinely nonabelian PDSs associated to the block-regular Steiner $2$-designs
first studied by Wilson.

</details>


### [26] [Binary matroids and degree-boundedness for pivot-minors](https://arxiv.org/abs/2507.23182)
*Rutger Campbell,James Davies,Robert Hickingbotham*

Main category: math.CO

TL;DR: 本文证明了对于任意二分图$H$和正整数$s$，排除$H$作为pivot-minor且不含$K_{s,s}$子图的图类具有有限平均度。结果依赖于Geelen等人宣布的二元拟阵结构定理。


<details>
  <summary>Details</summary>
Motivation: 研究二分图$H$和$K_{s,s}$-子图自由图类的平均度限制问题，探索图论中结构性质与度分布的关系。

Method: 利用Geelen、Gerards和Whittle提出的二元拟阵结构定理，结合对$K_{s,t}$-自由二分圆图顶点度的分析。

Result: 证明了$K_{s,s}$-子图自由且排除$H$作为pivot-minor的图类具有有限平均度；同时发现$K_{s,t}$-自由二分圆图存在度数不超过$\max\{2s-2, t-1\}$的顶点，且该界限是紧的。

Conclusion: 该研究为特定图类的度分布提供了精确界限，并展示了二元拟阵理论在图结构分析中的重要作用。

Abstract: We prove that for every bipartite graph $H$ and positive integer $s$, the
class of $K_{s,s}$-subgraph-free graphs excluding $H$ as a pivot-minor has
bounded average degree. Our proof relies on the announced binary matroid
structure theorem of Geelen, Gerards, and Whittle.
  Along the way, we also prove that every $K_{s,t}$-free bipartite circle graph
with $s\le t$ has a vertex of degree at most $\max\{2s-2, t-1\}$ and provide
examples showing that this is tight.

</details>


### [27] [Weighted $K$-$k$-Schur functions and their application to the $K$-$k$-Schur alternating conjecture](https://arxiv.org/abs/2507.23222)
*Yaozhou Fan,Xing Gao*

Main category: math.CO

TL;DR: 本文引入加权$K$-$k$-Schur函数的新概念，统一并扩展了$K$-$k$-Schur函数和闭$k$-Schur Katalan函数，解决了Blasiak等人提出的$K$-$k$-Schur交替猜想。


<details>
  <summary>Details</summary>
Motivation: 研究旨在统一和扩展$K$-$k$-Schur函数与闭$k$-Schur Katalan函数，并解决2022年提出的$K$-$k$-Schur交替猜想。

Method: 通过引入加权$K$-$k$-Schur函数的新概念，并研究其在特定$k$-有界分区下的交替性质。

Result: 证明了$K$-$k$-Schur交替猜想对于广泛类别的$k$-有界分区成立，包括所有严格递减的$k$-有界分区。

Conclusion: 研究成果为$K$-理论对称函数的组合结构提供了新的见解，并解决了重要的数学猜想。

Abstract: We introduce the new concept of weighted $K$-$k$-Schur functions -- a novel
family within the broader class of Katalan functions -- that unifies and
extends both $K$-$k$-Schur functions and closed $k$-Schur Katalan functions.
This new notion exhibits a fundamental alternating property under certain
conditions on the indexed $k$-bounded partitions. As a central application, we
resolve the $K$-$k$-Schur alternating conjecture -- posed by Blasiak, Morse,
and Seelinger in 2022 -- for a wide class of $k$-bounded partitions, including
all strictly decreasing $k$-bounded partitions. Our results shed new light on
the combinatorial structure of $K$-theoretic symmetric functions.

</details>


### [28] [Perfecting the Line Graph](https://arxiv.org/abs/2507.23231)
*Hartosh Singh Bal*

Main category: math.CO

TL;DR: 本文介绍了两种将任意有限图转化为完美图的规范构造：对称提升$\mathrm{HL}'_2(G)$和有序提升$\mathrm{HL}_2(G)$，它们均源自二分双覆盖的线图且具有盒完美性。对称提升分解为对称与反对称部分，保留了线图$L(G)$的所有邻接及拉普拉斯特征值。对于正则图（如Paley图），该构造可生成稀疏、高度结构化的正则盒完美扩展图。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过规范构造将任意有限图转化为具有完美图性质的图结构，特别是探索对称与有序提升在保留图谱特性及组合扩展性方面的潜力，并为盒完美随机正则图的研究提供可能。

Method: 提出对称提升$\mathrm{HL}'_2(G)$（结构不变）和有序提升$\mathrm{HL}_2(G)$（依赖顶点标记），两者均作为二分双覆盖的线图。对称提升分解为对称部分（恢复$L(G)$）和反对称部分（生成带符号图$L^-(G)$）。进一步推广至参数化提升$\mathrm{HL}_{r,d}(G)$和$\mathrm{HL}_{r,d}'(G)$。

Result: 对称提升$\mathrm{HL}'_2(G)$完整保留了$L(G)$的特征值（含重数），且对正则图可构造稀疏、结构化的盒完美扩展图家族。随机正则基图也表现出类似性质，为盒完美随机正则图研究奠定基础。参数化提升进一步扩展了构造的适用范围。

Conclusion: 两种提升构造为完美图生成提供了通用框架，对称提升尤其能同时保持谱扩展性与组合优化特性。推广后的参数化构造为图论与组合数学研究开辟了新方向，特别是在结构化扩展图与盒完美性分析领域。

Abstract: This paper introduces two canonical constructions that transform arbitrary
finite graphs into perfect graphs: the symmetric lift $\mathrm{HL}'_2(G)$,
which is purely structural and label-invariant, and the ordered lift
$\mathrm{HL}_2(G)$, which depends explicitly on vertex labeling and encodes
directional information. Both lifts arise as line graphs of bipartite double
covers and are box-perfect.
  The symmetric lift $\mathrm{HL}'_2(G)$ forms a canonical 2-cover of the line
graph $L(G)$. This involution decomposes $\mathrm{HL}'_2(G)$ into symmetric and
antisymmetric components: the symmetric part recovers $L(G)$, while the
antisymmetric part yields a signed graph $L^-(G)$, the antisymmetric line
graph, with +1/-1 edges encoding consistent vs. crossed overlaps. Thus, all
adjacency and Laplacian eigenvalues of $L(G)$, with multiplicities, appear
within those of $\mathrm{HL}'_2(G)$, despite $L(G)$ typically not being a
subgraph.
  For regular graphs such as Paley graphs, this yields infinite families of
sparse, highly structured regular and box-perfect expanders that also retain
large cliques. The lift retains much of the spectral expansion of the base
while improving the combinatorial expansion. Much the same behavior is observed
with random regular base graphs, allowing for the possibility of the study of
box-perfect random regular graphs.
  Finally, we generalize these constructions to parameterized lifts
$\mathrm{HL}_{r,d}(G)$ and $\mathrm{HL}_{r,d}'(G)$ defined on ordered
$r$-tuples connected by Hamming distance constraints, which structurally encode
the base graph and remain box-perfect.

</details>


### [29] [Recent advances in arrow relations and traces of sets](https://arxiv.org/abs/2507.23375)
*Mingze Li,Jie Ma,Mingyuan Rong*

Main category: math.CO

TL;DR: 本文综述了极值集合论中的箭头关系$(n, m) \rightarrow (a, b)$及其相关研究进展，探讨了不同极值视角下的多样主题。


<details>
  <summary>Details</summary>
Motivation: 箭头关系是极值集合论的核心概念，用于量化集合族与其迹之间的定量关系，理解这一关系对推动极值集合论的发展至关重要。

Method: 通过综述近期关于箭头关系的研究成果，从不同的极值视角出发，系统梳理了该领域的各类问题和结果。

Result: 文章总结了箭头关系$(n, m) \rightarrow (a, b)$的多种应用和结果，展示了集合族$\mathcal{F} \subseteq 2^{[n]}$与其迹$\mathcal{F}_{|T}$之间的丰富联系。

Conclusion: 本文为极值集合论中的箭头关系研究提供了全面的概述，强调了不同极值视角下的多样性和统一性，为该领域的未来发展指明了方向。

Abstract: The arrow relation, a central concept in extremal set theory, captures
quantitative relationships between families of sets and their traces. Formally,
the arrow relation $(n, m) \rightarrow (a, b)$ signifies that for any family
$\mathcal{F} \subseteq 2^{[n]}$ with $|\mathcal{F}| \geqslant m$, there exists
an $a$-element subset $T \subseteq [n]$ such that the trace $\mathcal{F}_{|T} =
\{ F \cap T : F \in \mathcal{F} \}$ contains at least $b$ distinct sets. This
survey highlights recent progress on a variety of problems and results
connected to arrow relations. We explore diverse topics, broadly categorized by
different extremal perspectives on these relations, offering a cohesive
overview of the field.

</details>


### [30] [Combinatorial solutions to the Social Golfer Problem and Social Golfer Problem with Adjacent Group Sizes](https://arxiv.org/abs/2507.23376)
*Alice Miller,Ivaylo Valkov,R. Julian R. Abel*

Main category: math.CO

TL;DR: 论文利用可分解组合设计（如RBIBD、RGDD等）构建了社交高尔夫球手问题（SGP）及其变体（SGA）的最优解，并提出通用算法，提供了150人内的完整解集。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过组合数学方法解决社交高尔夫球手问题及其相邻组规模变体，寻找最优分组方案。

Method: 采用可分解平衡不完全区组设计（RBIBD）、可分解群可分设计（RGDD）等组合设计理论，开发通用算法求解最优解。

Result: 成功构建了适用于SGP和SGA问题的最优解，并针对最多150名参与者的情况提供了完整解决方案集合。

Conclusion: 组合设计理论为社交高尔夫球手问题提供了系统化解决框架，算法与解集展示了该方法在实践中的有效性。

Abstract: Resolvable combinatorial designs including Resolvable Balanced Incomplete
Block Designs, Resolvable Group Divisible Designs, Uniformly Resolvable Designs
and Mutually Orthogonal Latin Squares and Rectangles are used to construct
optimal solutions to the Social Golfer problem (SGP) and the Social Golfer
problem with adjacent group sizes (SGA). An algorithm is presented to find an
optimal solution in general, and a complete set of solutions is provided for up
to 150 players.

</details>


### [31] [Towards the classification of maximum scattered linear sets of $\mathrm{PG}(1,q^5)$](https://arxiv.org/abs/2507.23409)
*Stefano Lia,Giovanni Longobardi,Corrado Zanella*

Main category: math.CO

TL;DR: 本文研究了$\mathrm{PG}(1,q^5)$中的最大散射线性集，证明了其投影配置的几何性质与线性集类型的关系，并推导了新类型线性集可能的多项式形式。通过计算机验证，发现$q\leq 25$时不存在新类型的最大散射线性集。


<details>
  <summary>Details</summary>
Motivation: 研究$\mathrm{PG}(1,q^5)$中最大散射线性集的投影配置性质，以确定是否存在除已知伪正则型和LP型之外的新类型线性集。

Method: 通过分析投影配置$\Gamma,\Sigma)$的几何特性，特别是点$A$和$B$的秩，结合群$\mathbb{G}=\mathrm{P}\Gamma \mathrm{L}(5,q^5)_\Sigma$的作用，推导新类型线性集的多项式形式，并进行计算机验证。

Result: 若投影配置中点$A$或$B$的秩为5，则对应线性集必为LP型；若存在新类型线性集，则需满足$\mathrm{rk} A=\mathrm{rk} B=4$。推导了两种可能的多项式形式，但计算机验证表明$q\leq 25$时不存在新类型。

Conclusion: 最大散射线性集的类型由其投影配置的几何性质决定，$q\leq 25$时仅存在伪正则型和LP型，新类型线性集若存在需满足特定秩条件并具有更复杂的多项式形式。

Abstract: Every maximum scattered linear set in $\mathrm{PG}(1,q^5)$ is the projection
of an $\mathbb{F}_q$-subgeometry $\Sigma$ of $\mathrm{PG}(4,q^5)$ from a plane
$\Gamma$ external to the secant variety to $\Sigma$. The pair $(\Gamma,\Sigma)$
will be called a projecting configuration for the linear set. The projecting
configurations for the only known maximum scattered linear sets in
$\mathrm{PG}(1,q^5)$, namely those of pseudoregulus and LP type, have been
characterized in the literature by B. Csajb\'{o}k, C. Zanella in 2016 and by C.
Zanella, F. Zullo in 2020. Let $(\Gamma,\Sigma)$ be a projecting configuration
for a maximum scattered linear set in $\mathrm{PG}(1,q^5)$, let $\sigma$ be a
generator of $\mathbb{G}=\mathrm{P}\Gamma \mathrm{L}(5,q^5)_\Sigma$, and
$A=\Gamma\cap\Gamma^{\sigma^4}$, $B=\Gamma\cap\Gamma^{\sigma^3}$. If $A$ and
$B$ are not both points, then the projected linear set is of pseudoregulus
type. Then, suppose that they are points. The rank of a point $X$ is the
vectorial dimension of the span of the orbit of $X$ under the action of
$\mathbb{G}$. In this paper, by investigating the geometric properties of
projecting configurations, it is proved that if at least one of the points $A$
and $B$ has rank 5, the associated maximum scattered linear set must be of LP
type. Then, if a maximum scattered linear set of a new type exists, it must be
such that $\mathrm{rk} A=\mathrm{rk} B=4$. In this paper we derive two possible
polynomial forms that such a linear set must have. An exhaustive analysis by
computer shows that for $q\leq 25$, no new maximum scattered linear set exists.

</details>


### [32] [The net-regular strongly regular signed graphs with degree 5](https://arxiv.org/abs/2507.23420)
*Qian Yu,Yaoping Hou*

Main category: math.CO

TL;DR: 本文确定了所有度为5的连通净正则强正则符号图，发现净度为3和1的强正则符号图分别有5个和2个。


<details>
  <summary>Details</summary>
Motivation: 研究强正则符号图的分类及其性质，特别是针对度为5的连通净正则情况。

Method: 通过数学分析和图论方法，对连通净正则强正则符号图进行系统分类。

Result: 发现度为5的连通净正则强正则符号图中，净度为3的有5个，净度为1的有2个。

Conclusion: 该研究为强正则符号图的分类提供了新的结果，并揭示了特定条件下的图结构特征。

Abstract: In this paper, we determine all connected net-regular strongly regular signed
graphs with degree 5. There are five and two strongly regular signed graphs
with net-degree 3 and 1, respectively.

</details>


### [33] [Improved bounds on the postage stamp problem for large numbers of stamps](https://arxiv.org/abs/2507.23627)
*Eric James Faust,Michael Tait*

Main category: math.CO

TL;DR: 论文改进了关于$h$-fold基$F_h(n)$的上下界，通过概率方法和构造有限循环群的加法基，显著提升了已知结果。


<details>
  <summary>Details</summary>
Motivation: 研究$h$-fold基$F_h(n)$的最小基数，填补$h>2$时理论空白，改进现有上下界。

Method: 使用概率方法和Berry-Esseen定理改进下界；利用Jia和Shen的有限循环群加法基构造上界。

Result: 证明对任意$\epsilon>0$，充分大的$h$有$\left(\frac{1}{2}-\epsilon\right)h!\sqrt{2\pi e} n\; \leq \; F_h(n)^h \; \leq \; \left(\left(\frac{\sqrt{3}}{2}+\epsilon\right)h\right)^h n$。

Conclusion: 首次建立$F_h(n)$的非平凡渐近上界，显著改进下界，为$h$-fold基理论提供新工具。

Abstract: Let $F_h(n)$ denote the minimum cardinality of an additive {\em $h$-fold
basis} of $\{1,2,\cdots,n\}$: a set $S$ such that any integer in $\{1,2,\cdots,
n\}$ can be written as a sum of at most $h$ elements from $S$. While the
trivial bounds $h!n \; \lesssim \; F_h(n)^h \; \lesssim \; h^h n$ are
well-known, comparatively little has been established for $h>2$. In this paper,
we make significant improvements to both of the best-known bounds on $F_h(n)$
for sufficiently large $h$. For the lower bound, we use a probabilistic
approach along with the Berry-Esseen Theorem to improve upon the best-known
asymptotic result due to Yu. We also establish the first nontrivial asymptotic
upper bound on $F_h(n)$ by leveraging a construction for additive bases of
finite cyclic groups due to Jia and Shen. In particular, we show that given any
$\epsilon>0$, for sufficiently large $h$, we have \[
\left(\frac{1}{2}-\epsilon\right)h!\sqrt{2\pi e} n\; \leq \; F_h(n)^h \; \leq
\; \left(\left(\frac{\sqrt{3}}{2}+\epsilon\right)h\right)^h n. \]

</details>


### [34] [Fuss--Catalan algebras on generalized Dyck paths via non-crossing partitions](https://arxiv.org/abs/2507.23460)
*Keiichi Shigechi*

Main category: math.CO

TL;DR: 本文研究了Fuss--Catalan代数，作为Temperley--Lieb代数的推广，通过非交叉分割作用于广义Dyck路径。我们建立了非交叉分割与Dyck路径的双射关系，并引入了边界Fuss--Catalan代数的新解。


<details>
  <summary>Details</summary>
Motivation: 研究Fuss--Catalan代数的动机在于推广Temperley--Lieb代数，探索其在非交叉分割和广义Dyck路径上的作用，以及这些代数结构的可积性。

Method: 方法包括：1) 在非交叉分割上定义Temperley--Lieb代数；2) 通过非交叉分割的递增$r$-链定义Fuss--Catalan代数；3) 引入边界Fuss--Catalan代数并研究其表示。

Result: 主要结果包括：1) 证明了Kreweras自同态与弦图旋转的等价性；2) 建立了递增$r$-链与广义Dyck路径的双射；3) 在$r=2$情况下获得了反射方程的新解。

Conclusion: 结论表明Fuss--Catalan代数及其边界推广在非交叉分割和广义Dyck路径上具有兼容的表示，并为可积系统提供了新的解。这些结果为相关代数结构的研究开辟了新方向。

Abstract: We study the Fuss--Catalan algebras, which are generalizations of the
Temperley--Lieb algebra and act on generalized Dyck paths, through non-crossing
partitions. First, the Temperley--Lieb algebra is defined on non-crossing
partitions, and a bijection between a Dyck path and a non-crossing partition is
shown to be compatible with the Temperley--Lieb algebra on Dyck paths, or
equivalently chord diagrams. We show that the Kreweras endomorphism on
non-crossing partitions is equivalent to the rotation of chord diagrams under
the bijection. Secondly, by considering an increasing $r$-chain in the graded
lattice of non-crossing partitions, we define the Fuss--Catalan algebras on
increasing $r$-chains. Through a bijection between an increasing $r$-chain and
a generalized Dyck path, one naturally obtains the Fuss--Catalan algebra on
generalized Dyck paths. As generalizations of the Fuss--Catalan algebra, we
introduce the one- and two-boundary Fuss--Catalan algebras. Increasing
$r$-chains of symmetric non-crossing partitions give symmetric generalized Dyck
paths by the bijection, and the boundary Fuss--Catalan algebras naturally act
on them. We show that these representations are compatible with the
diagrammatic representations of the algebras by use of generalized chord
diagrams. Thirdly, we discuss the integrability of the Fuss--Catalan algebras.
For the Fuss--Catalan algebras with boundaries, we obtain a new solution of the
reflection equation in the case of $r=2$.

</details>


### [35] [Oriented diameter of graphs with diameter $4$ and given maximum edge girth](https://arxiv.org/abs/2507.23517)
*Jifu Lin,Lihua You*

Main category: math.CO

TL;DR: 本文研究了无桥图的最大边围长与强定向直径的关系，给出了直径4时$F(4,A^*)$的上下界。


<details>
  <summary>Details</summary>
Motivation: 研究无桥图的最大边围长$g^*(G)$与强定向直径的关系，扩展了Chv\'atal和Thomassen等人的工作。

Method: 通过定义最大边围长$g^*(G)$，并引入$F(d,A)$函数，分析不同直径和边围长条件下的强定向直径界限。

Result: 证明了当直径为4且$A^*=\{2,3,6,7,8,9\}$时，$12\leq F(4,A^*)\leq 13$。

Conclusion: 本文进一步推进了无桥图强定向直径的研究，为直径4的情况提供了新的上下界。

Abstract: Let $G$ be a bridgeless graph. We introduce the maximum edge girth of $G$,
denoted by $g^*(G)=\max\{l_G(e)\mid e\in E(G)\}$, where $l_G(e)$ is the edge
girth of $e$, defined as the length of the shortest cycle containing $e$. Let
$F(d,A)$ be the smallest value for which every bridgeless graph $G$ with
diameter $d$ and $g^*(G)\in A$ admits a strong orientation $\overrightarrow{G}$
such that the diameter of $\overrightarrow{G}$ is at most $F(d,A)$. Let
$f(d)=F(d,A)$, where $A=\{a\in \mathbb{N}\mid 2\leq a\leq 2d+1\}$. Chv\'atal
and Thomassen (JCT-B, 1978) obtained general bounds for $f(d)$ and showed that
$f(2)=6$. Kwok et al. (JCT-B, 2010) proved that $9\leq f(3)\leq 11$. Wang and
Chen (JCT-B, 2022) determined $f(3)=9$. In this paper, we give that $12\leq
F(4,A^*)\leq 13$, where $A^*=\{2,3,6,7,8,9\}$.

</details>


### [36] [Tree-indexed sums of Catalan numbers](https://arxiv.org/abs/2507.23557)
*Alin Bostan,Valentin Féray,Paul Thévenin*

Main category: math.CO

TL;DR: 研究了一类由树索引的卡特兰数乘积的无穷级数，证明其为$1/\pi$的有理系数多项式，并给出了有效计算算法。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于对大圆环系统（平面上非交叉环构型）的分析需求。

Method: 通过引入参数的提升，将级数表示为第一类和第二类完全椭圆积分的多项式。

Result: 证明这些级数是$1/\pi$的有理系数多项式，且多项式次数不超过树顶点数的一半。

Conclusion: 提供了一种有效算法显式计算树索引的卡特兰数乘积级数，拓展了椭圆积分在组合数学中的应用。

Abstract: We consider a family of infinite sums of products of Catalan numbers, indexed
by trees. We show that these sums are polynomials in $1/\pi$ with rational
coefficients; the proof is effective and provides an algorithm to explicitly
compute these sums. Along the way we introduce parametric liftings of our sums,
and show that they are polynomials in the complete elliptic integrals of the
first and second kind. Moreover, the degrees of these polynomials are at most
half of the number of vertices of the tree. The computation of these
tree-indexed sums is motivated by the study of large meandric systems, which
are non-crossing configurations of loops in the plane.

</details>


### [37] [Ramsey numbers for 1-degenerate 3-graphs](https://arxiv.org/abs/2507.23623)
*Peter Allen,Simona Boyadzhiyska,Matías Pavez-Signé*

Main category: math.CO

TL;DR: 本文构建了一个3-均匀1-退化超图，其2-色Ramsey数为$\Omega\big(n^{3/2}/\log n\big)$，否定了超图Burr-Erd\H{o}s猜想的所有剩余开放情况。


<details>
  <summary>Details</summary>
Motivation: 研究超图Burr-Erd\H{o}s猜想的剩余开放情况，验证其是否成立。

Method: 构建了一个3-均匀1-退化超图，该图是著名的hedgehog图的变体，并证明了其2-色Ramsey数的下界。

Result: 证明了所有3-均匀广义hedgehog图的2-色Ramsey数为$O\big(n^{3/2}\big)$，并给出了下界$\Omega\big(n^{3/2}/\log n\big)$。

Conclusion: 超图Burr-Erd\H{o}s猜想的所有剩余开放情况均为假，广义hedgehog图的Ramsey数具有近尖锐的上下界。

Abstract: We construct a 3-uniform 1-degenerate hypergraph on $n$ vertices whose
2-colour Ramsey number is $\Omega\big(n^{3/2}/\log n\big)$. This shows that all
remaining open cases of the hypergraph Burr-Erd\H{o}s conjecture are false. Our
graph is a variant of the celebrated hedgehog graph. We additionally show
near-sharp upper bounds, proving that all 3-uniform generalised hedgehogs have
2-colour Ramsey number $O\big(n^{3/2}\big)$.

</details>


### [38] [Erdős meets Nash-Williams](https://arxiv.org/abs/2507.23624)
*Michelle Delcourt,Cicely,Henderson,Thomas Lesgourgues,Luke Postle*

Main category: math.CO

TL;DR: 该论文将Erd\H{o}s与Nash-Williams的猜想统一为“Erd\H{o}s meets Nash-Williams' Conjecture”，并通过分数松弛方法将组合猜想简化为Nash-Williams猜想的分数版本，证明了当图G的最小度至少为0.82733n时，该猜想成立。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于1847年Kirkman关于Steiner三元系的证明，以及1970年Nash-Williams和1973年Erd\H{o}s分别提出的关于三角形分解和Steiner三元系周长下限的猜想。2021年Glock等人提出了统一这两个猜想的“Erd\H{o}s meets Nash-Williams' Conjecture”。

Method: 论文采用新开发的“精细吸收”方法，而非之前使用的迭代吸收方法，将组合猜想简化为Nash-Williams猜想的分数松弛版本，并结合Delcourt和Postle的最佳分数界进行证明。

Result: 研究结果表明，当图G的最小度至少为0.82733n时，统一猜想成立。这一结果推广了Barber等人关于Nash-Williams猜想的工作，以及Kwan等人对Erd\H{o}s猜想的解决。

Conclusion: 论文通过精细吸收方法独立证明了Erd\H{o}s和Nash-Williams的猜想，为组合数学中的三角形分解和Steiner三元系问题提供了新的视角和解决方案。

Abstract: In 1847, Kirkman proved that there exists a Steiner triple system on $n$
vertices (equivalently a triangle decomposition of the edges of $K_n$) whenever
$n$ satisfies the necessary divisibility conditions (namely $n\equiv 1,3 \mod
6$). In 1970, Nash-Williams conjectured that every graph $G$ on $n$ vertices
with minimum degree at least $3n/4$ (for $n$ large enough and satisfying the
necessary divisibility conditions) has a triangle decomposition. In 1973,
Erd\H{o}s conjectured that for each integer $g$, there exists a Steiner triple
system on $n$ vertices with girth at least $g$ (provided that $n\equiv 1,3 \mod
6$ is large enough compared to the fixed $g$). In 2021, Glock, K\"uhn, and
Osthus conjectured the common generalization of these two conjectures, dubbing
it the ``Erd\H{o}s meets Nash-Williams' Conjecture''.
  In this paper, we reduce the combined conjecture to the fractional relaxation
of the Nash-Williams' Conjecture. Combined with the best known fractional bound
of Delcourt and Postle, this proves the combined conjecture above when $G$ has
minimum degree at least $0.82733n$. We note that our result generalizes the
seminal work of Barber, K\"uhn, Lo, and Osthus on Nash-Williams' Conjecture and
the resolution of Erd\H{o}s' Conjecture by Kwan, Sah, Sawhney, and Simkin. Both
previous proofs of those results used the method of iterative absorption. Our
proof instead proceeds via the newly developed method of refined absorption
(and hence provides new independent proofs of both results).

</details>


### [39] [Which maximal subgroups are perfect codes?](https://arxiv.org/abs/2507.23635)
*Shouhong Qiao,Ning Su,Binzhou Xia,Zhishuo Zhang,Sanming Zhou*

Main category: math.CO

TL;DR: 本文系统研究了群的最大子群如何成为完美码，提出了子群完美码的局部补集特征。


<details>
  <summary>Details</summary>
Motivation: 研究群中子群完美码的存在条件，特别是最大子群能否成为完美码，以深化对群结构与图论编码关系的理解。

Method: 通过分析群$G$的凯莱图$\Gamma=(V, E)$，利用子群$H$的局部补集性质，建立子群完美码的判定标准。

Result: 证明了最大子群作为完美码的充要条件与其局部补集特性相关，为群论编码提供了新工具。

Conclusion: 子群完美码的局部补集特征为群论与编码理论的交叉研究开辟了新方向，具有潜在应用价值。

Abstract: A perfect code in a graph $\Gamma=(V, E)$ is a subset $C$ of $V$ such that no
two vertices in $C$ are adjacent and every vertex in $V \setminus C$ is
adjacent to exactly one vertex in $C$. A subgroup $H$ of a group $G$ is called
a subgroup perfect code of $G$ if it is a perfect code in some Cayley graph of
$G$. In this paper, we undertake a systematic study of which maximal subgroups
of a group can be perfect codes. Our approach highlights a characterization of
subgroup perfect codes in terms of their ``local'' complements.

</details>


### [40] [Horofunctions of infinite Sierpinski polygon graphs](https://arxiv.org/abs/2507.23681)
*Daniele D'Angeli,Francesco Matucci,Davide Perego,Emanuele Rodaro*

Main category: math.CO

TL;DR: 该论文推广了D'Angeli和Donno的工作，通过无限字母序列构建有限图序列，研究其Gromov-Hausdorff极限图，并分析同构类与horofunction边界性质。


<details>
  <summary>Details</summary>
Motivation: 研究基于无限字母序列构建的图序列的极限行为，特别关注$r \neq 4i$（$i \in \mathbb{N}$）的情况，以扩展前人成果并揭示新的数学结构。

Method: 从$r$字母无限序列出发构造带标记有限图序列，分析其Gromov-Hausdorff极限，利用二面体群描述同构类，并探讨horofunction边界中Busemann与非Busemann点的性质。

Result: 证明了极限图的同构类可由二面体群刻画，并揭示了horofunction边界中Busemann点与非Busemann点的结构特征。

Conclusion: 该工作不仅推广了现有理论框架，还为无限序列与几何群论的交叉研究提供了新的工具与视角，特别在极限图分类与边界点分析方面取得进展。

Abstract: Generalizing works of D'Angeli and Donno, we describe, starting from an
infinite sequence over $r$ letters with $r \neq 4i$ and $i \in \mathbb{N}$, a
sequence of pointed finite graphs. We study the pointed Gromov-Hausdorff limit
graphs giving a description of isomorphim classes in terms of dihedral groups
and providing insights on the horofunction boundaries in terms of Busemann and
non-Busemann points.

</details>


<div id='q-fin.MF'></div>

# q-fin.MF [[Back]](#toc)

### [41] [Volatility Modeling with Rough Paths: A Signature-Based Alternative to Classical Expansions](https://arxiv.org/abs/2507.23392)
*Elisa Alòs,Òscar Burés,Rafael de Santiago,Josep Vives*

Main category: q-fin.MF

TL;DR: 比较两种隐含波动率曲面校准方法：基于Malliavin微积分的二阶渐近展开法与基于粗糙路径理论的路径签名数据驱动法。后者在Heston模型下表现相当，且在粗糙Bergomi模型等非马尔可夫场景中更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 评估不同校准方法在复杂波动率模型（如粗糙波动率）中的适用性，探索非参数化方法的优势。

Method: 1. 渐近展开法：基于Heston型随机波动率模型推导解析公式；\n2. 签名法：将波动率建模为主过程路径签名的线性泛函，无需预设参数形式。

Result: 签名法在Heston设定下精度与渐近法相当；在粗糙Bergomi模型中仍保持准确性，展现对非马尔可夫特征的适应性。

Conclusion: 基于路径签名的方法具有模型无关性、鲁棒性和适应性，特别适用于粗糙或非马尔可夫波动率场景。

Abstract: We compare two methodologies for calibrating implied volatility surfaces: a
second-order asymptotic expansion method derived via Malliavin calculus, and a
data-driven approach based on path signatures from rough path theory. The
former, developed in Al\`os et al. (2015), yields efficient and accurate
calibration formulas under the assumption that the asset price follows a
Heston-type stochastic volatility model. The latter models volatility as a
linear functional of the signature of a primary stochastic process, enabling a
flexible approximation without requiring a specific parametric form.
  Our numerical experiments show that the signature-based method achieves
calibration accuracy comparable to the asymptotic approach when the true
dynamics are Heston. We then test the model in a more general setting where the
asset follows a rough Bergomi volatility process-a regime beyond the scope of
the asymptotic expansion-and show that the signature approach continues to
deliver accurate results. These findings highlight the model-independence,
robustness and adaptability of signature-based calibration methods in settings
where volatility exhibits rough or non-Markovian features.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [42] [A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection](https://arxiv.org/abs/2507.22908)
*Abhishek Sawaika,Swetang Krishna,Tushar Tomar,Durga Pritam Suggisetti,Aditi Lal,Tanmaya Shrivastav,Nouhaila Innan,Muhammad Shafique*

Main category: q-fin.CP

TL;DR: 本文提出了一种结合量子增强LSTM模型和隐私保护技术的联邦学习框架，用于提升金融欺诈检测的准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 随着数字交易的快速增长，传统欺诈检测方法面临挑战，亟需一种能同时提升检测性能和保障数据隐私的新方法。

Method: 采用量子增强LSTM架构捕获复杂交易模式，并开发新型防御机制'FedRansel'抵御投毒和推理攻击，结合伪中心化联邦学习框架。

Result: 相比传统模型，量子LSTM在关键指标上提升约5%性能；FedRansel将模型退化率和推理准确率降低4-8%，优于标准差分隐私机制。

Conclusion: 该框架显著提高了欺诈检测精度，同时通过量子计算和高级隐私保护技术强化了金融数据的安全性。

Abstract: Rapid growth of digital transactions has led to a surge in fraudulent
activities, challenging traditional detection methods in the financial sector.
To tackle this problem, we introduce a specialised federated learning framework
that uniquely combines a quantum-enhanced Long Short-Term Memory (LSTM) model
with advanced privacy preserving techniques. By integrating quantum layers into
the LSTM architecture, our approach adeptly captures complex
cross-transactional patters, resulting in an approximate 5% performance
improvement across key evaluation metrics compared to conventional models.
Central to our framework is "FedRansel", a novel method designed to defend
against poisoning and inference attacks, thereby reducing model degradation and
inference accuracy by 4-8%, compared to standard differential privacy
mechanisms. This pseudo-centralised setup with a Quantum LSTM model, enhances
fraud detection accuracy and reinforces the security and confidentiality of
sensitive financial data.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [43] [Fine-Grained Privacy Extraction from Retrieval-Augmented Generation Systems via Knowledge Asymmetry Exploitation](https://arxiv.org/abs/2507.23229)
*Yufei Chen,Yao Wang,Haibin Zhang,Tao Gu*

Main category: cs.CR

TL;DR: 本文提出了一种针对检索增强生成（RAG）系统的黑盒攻击框架，通过知识不对称性实现跨领域隐私信息精准提取，并采用思维链推理策略降低敏感内容暴露风险。实验显示单领域隐私提取率达91%，多领域达83%，敏感语句暴露减少65%。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统隐私攻击方法存在两大缺陷：无法准确分离知识库来源的句子，且跨领域鲁棒性不足。本文旨在解决这些问题，实现细粒度隐私提取并建立攻防桥梁。

Method: 1. 利用RAG与标准LLM的知识不对称性设计攻击框架\n2. 采用思维链推理生成自适应提示\n3. 分解对抗性查询以最大化信息差异\n4. 语义关系评分解决词汇句法歧义\n5. 基于特征分数训练神经网络识别隐私语句

Result: 单领域隐私提取成功率91%，多领域达83%。案例研究中敏感语句暴露率降低65%以上，且无需预定义知识即可泛化至未见领域。

Conclusion: 该框架首次实现跨异构知识场景的精准隐私提取，同时为自适应防御提供基础，弥合了RAG系统攻防间的技术鸿沟。

Abstract: Retrieval-augmented generation (RAG) systems enhance large language models
(LLMs) by integrating external knowledge bases, but this advancement introduces
significant privacy risks. Existing privacy attacks on RAG systems can trigger
data leakage but often fail to accurately isolate knowledge-base-derived
sentences within mixed responses. They also lack robustness when applied across
multiple domains. This paper addresses these challenges by presenting a novel
black-box attack framework that exploits knowledge asymmetry between RAG and
standard LLMs to achieve fine-grained privacy extraction across heterogeneous
knowledge landscapes. We propose a chain-of-thought reasoning strategy that
creates adaptive prompts to steer RAG systems away from sensitive content.
Specifically, we first decompose adversarial queries to maximize information
disparity and then apply a semantic relationship scoring to resolve lexical and
syntactic ambiguities. We finally train a neural network on these feature
scores to precisely identify sentences containing private information. Unlike
prior work, our framework generalizes to unseen domains through iterative
refinement without pre-defined knowledge. Experimental results show that we
achieve over 91% privacy extraction rate in single-domain and 83% in
multi-domain scenarios, reducing sensitive sentence exposure by over 65% in
case studies. This work bridges the gap between attack and defense in RAG
systems, enabling precise extraction of private information while providing a
foundation for adaptive mitigation.

</details>


### [44] [Counterfactual Evaluation for Blind Attack Detection in LLM-based Evaluation Systems](https://arxiv.org/abs/2507.23453)
*Lijia Liu,Takumi Kondo,Kyohei Atarashi,Koh Takeuchi,Jiyi Li,Shigeru Saito,Hisashi Kashima*

Main category: cs.CR

TL;DR: 本文提出了一种针对LLM评估系统的防御框架SE+CFE，通过标准评估与反事实评估相结合，有效检测独立于真实答案的盲攻击，显著提升系统安全性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估系统易受独立构造候选答案的盲攻击威胁，需开发可靠防御机制以保障评估公正性。

Method: 在标准评估(SE)基础上引入反事实评估(CFE)，通过验证提交答案在真实与虚构答案下的矛盾性来检测攻击。

Result: 实验表明标准评估漏洞率达80%，而SE+CFE框架将攻击检测率提升至95%且性能损失小于2%。

Conclusion: SE+CFE框架通过双重验证机制显著增强LLM评估系统对抗盲攻击的鲁棒性，为安全评估提供新范式。

Abstract: This paper investigates defenses for LLM-based evaluation systems against
prompt injection. We formalize a class of threats called blind attacks, where a
candidate answer is crafted independently of the true answer to deceive the
evaluator. To counter such attacks, we propose a framework that augments
Standard Evaluation (SE) with Counterfactual Evaluation (CFE), which
re-evaluates the submission against a deliberately false ground-truth answer.
An attack is detected if the system validates an answer under both standard and
counterfactual conditions. Experiments show that while standard evaluation is
highly vulnerable, our SE+CFE framework significantly improves security by
boosting attack detection with minimal performance trade-offs.

</details>


### [45] [LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora](https://arxiv.org/abs/2507.23611)
*Estelle Ruellan,Eric Clay,Nicholas Ascoli*

Main category: cs.CR

TL;DR: 本文提出利用大型语言模型（LLM）分析感染截图以提取潜在威胁指标（IoCs）的新方法，针对Aurora信息窃取木马展示了从1000张截图中提取337个可操作URL和246个相关文件的有效性，揭示了恶意软件传播方法和社会工程策略。


<details>
  <summary>Details</summary>
Motivation: 信息窃取木马（Infostealers）窃取敏感数据，2024年报告超过2900万条窃取日志，人工分析难以应对。现有研究多关注主动检测，而忽略了对窃取日志及其相关感染截图等反应性分析。

Method: 采用大型语言模型（如gpt-4o-mini）分析感染截图，提取潜在威胁指标（IoCs），映射感染途径并追踪恶意活动。研究聚焦Aurora信息窃取木马，通过截图识别恶意URL、安装文件及被利用的软件主题。

Result: 从1000张截图中提取了337个可操作URL和246个相关文件，揭示了恶意软件传播的关键方法和社会工程策略。通过关联文件名、URL和感染主题，识别出三个不同的恶意活动，证明了LLM驱动分析在揭示感染工作流程和增强威胁情报方面的潜力。

Conclusion: 本研究通过将恶意软件分析从传统的基于日志的检测方法转向基于感染截图的反应性分析方法，提出了一种可扩展的识别感染途径和实现早期干预的方法，为威胁情报提供了新的视角。

Abstract: Infostealers exfiltrate credentials, session cookies, and sensitive data from
infected systems. With over 29 million stealer logs reported in 2024, manual
analysis and mitigation at scale are virtually unfeasible/unpractical. While
most research focuses on proactive malware detection, a significant gap remains
in leveraging reactive analysis of stealer logs and their associated artifacts.
Specifically, infection artifacts such as screenshots, image captured at the
point of compromise, are largely overlooked by the current literature. This
paper introduces a novel approach leveraging Large Language Models (LLMs), more
specifically gpt-4o-mini, to analyze infection screenshots to extract potential
Indicators of Compromise (IoCs), map infection vectors, and track campaigns.
Focusing on the Aurora infostealer, we demonstrate how LLMs can process
screenshots to identify infection vectors, such as malicious URLs, installer
files, and exploited software themes. Our method extracted 337 actionable URLs
and 246 relevant files from 1000 screenshots, revealing key malware
distribution methods and social engineering tactics. By correlating extracted
filenames, URLs, and infection themes, we identified three distinct malware
campaigns, demonstrating the potential of LLM-driven analysis for uncovering
infection workflows and enhancing threat intelligence. By shifting malware
analysis from traditional log-based detection methods to a reactive,
artifact-driven approach that leverages infection screenshots, this research
presents a scalable method for identifying infection vectors and enabling early
intervention.

</details>


### [46] [Polynomial Lattices for the BIKE Cryptosystem](https://arxiv.org/abs/2507.23641)
*Michael Schaller*

Main category: cs.CR

TL;DR: 本文研究了BIKE密码系统中基于多项式环的秩2格，分析了其性质并推广了弱密钥恢复方法。通过构建格并求解最短向量问题，作者不仅找到最短向量，还获得了格的约化基，从而能检测更多弱密钥。


<details>
  <summary>Details</summary>
Motivation: 研究BIKE密码系统中由公钥生成的秩2格结构，旨在理解其数学特性并扩展现有的弱密钥恢复方法。

Method: 构建多项式环上的秩2格，分析其性质，并推广了Bardet等人提出的弱密钥恢复技术，通过求解格的最短向量问题并计算约化基。

Result: 证明了Bardet等人的方法隐含解决了所构建格的最短向量问题，且通过获得约化基可检测更多潜在的弱密钥。

Conclusion: 该方法不仅改进了现有弱密钥检测能力，还为分析BIKE密码系统的安全性提供了新的格理论工具。

Abstract: In this paper we introduce a rank $2$ lattice over a polynomial ring arising
from the public key of the BIKE cryptosystem \cite{aragon2022bike}. The secret
key is a sparse vector in this lattice. We study properties of this lattice and
generalize the recovery of weak keys from \cite{BardetDLO16}. In particular, we
show that they implicitly solved a shortest vector problem in the lattice we
constructed. Rather than finding only a shortest vector, we obtain a reduced
basis of the lattice which makes it possible to check for more weak keys.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [47] [Unifying Post-hoc Explanations of Knowledge Graph Completions](https://arxiv.org/abs/2507.22951)
*Alessandro Lonardi,Samy Badreddine,Tarek R. Besold,Pablo Sanchez Martin*

Main category: cs.AI

TL;DR: 本文提出知识图谱补全（KGC）后验解释性的统一框架，通过多目标优化平衡解释效果与简洁性，改进评估协议，并强调解释需面向终端用户的实际查询需求。


<details>
  <summary>Details</summary>
Motivation: 当前KGC后验解释性研究缺乏形式化定义与标准化评估，导致可复现性与跨研究比较困难。本文旨在建立统一方法以提升该领域研究的规范性与影响力。

Method: 1. 提出基于多目标优化的通用框架，统一现有KGC后验解释算法\n2. 采用平均倒数排名（MRR）和Hits@$k$等指标改进评估协议\n3. 强调解释需针对终端用户的实际需求设计。

Result: 实证研究表明：统一框架能有效协调解释效果与简洁性，改进的评估协议（如MRR和Hits@$k$）更可靠，面向用户查询的解释显著提升可解释性价值。

Conclusion: 通过方法统一与评估标准优化，本研究为KGC解释性建立了可复现的研究基础，推动该领域向解决实际用户需求的方向发展。

Abstract: Post-hoc explainability for Knowledge Graph Completion (KGC) lacks
formalization and consistent evaluations, hindering reproducibility and
cross-study comparisons. This paper argues for a unified approach to post-hoc
explainability in KGC. First, we propose a general framework to characterize
post-hoc explanations via multi-objective optimization, balancing their
effectiveness and conciseness. This unifies existing post-hoc explainability
algorithms in KGC and the explanations they produce. Next, we suggest and
empirically support improved evaluation protocols using popular metrics like
Mean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of
interpretability as the ability of explanations to address queries meaningful
to end-users. By unifying methods and refining evaluation standards, this work
aims to make research in KGC explainability more reproducible and impactful.

</details>


### [48] [Data Readiness for Scientific AI at Scale](https://arxiv.org/abs/2507.23018)
*Wesley Brewer,Patrick Widener,Valentine Anantharaj,Feiyi Wang,Tom Beck,Arjun Shankar,Sarp Oral*

Main category: cs.AI

TL;DR: 本文提出一个针对高性能计算环境的两维数据准备框架，用于评估和提升科学数据在AI训练中的适用性，特别关注生成式模型的应用。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决领导级科学数据集在AI训练中的数据准备问题，特别是在气候、核聚变、生物/健康和材料等领域，如何标准化和优化数据处理流程以支持可扩展的AI科学应用。

Method: 方法包括分析四个典型领域的数据处理流程，提出一个由数据准备级别（从原始数据到AI就绪）和数据处理阶段（从数据摄入到分片）组成的两维框架，并针对高性能计算环境进行定制。

Result: 研究结果是一个概念性的成熟度矩阵，能够描述科学数据的准备状态，并为跨领域的基础设施开发提供指导，以支持可扩展和可复现的科学AI应用。

Conclusion: 结论强调该框架为科学数据向AI就绪状态的转化提供了系统化的方法，特别是在支持基于Transformer的生成模型方面，推动了标准化和跨领域支持的发展。

Abstract: This paper examines how Data Readiness for AI (DRAI) principles apply to
leadership-scale scientific datasets used to train foundation models. We
analyze archetypal workflows across four representative domains - climate,
nuclear fusion, bio/health, and materials - to identify common preprocessing
patterns and domain-specific constraints. We introduce a two-dimensional
readiness framework composed of Data Readiness Levels (raw to AI-ready) and
Data Processing Stages (ingest to shard), both tailored to high performance
computing (HPC) environments. This framework outlines key challenges in
transforming scientific data for scalable AI training, emphasizing
transformer-based generative models. Together, these dimensions form a
conceptual maturity matrix that characterizes scientific data readiness and
guides infrastructure development toward standardized, cross-domain support for
scalable and reproducible AI for science.

</details>


### [49] [FairReason: Balancing Reasoning and Social Bias in MLLMs](https://arxiv.org/abs/2507.23067)
*Zhenyu Pan,Yutong Zhang,Jianshu Zhang,Haoran Lu,Haozheng Luo,Yuwei Han,Philip S. Yu,Manling Li,Han Liu*

Main category: cs.AI

TL;DR: 多模态大语言模型(MLLMs)在提升推理能力时存在社会偏见加剧的问题。研究通过对比三种去偏策略，发现强化学习结合1:4的样本比例能有效平衡偏见减少与推理准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管现有技术提升了MLLMs的逻辑准确性，但常伴随显著的社会偏见。研究旨在揭示推理能力提升与偏见缓解之间的相互作用及潜在权衡关系。

Method: 基准测试了三种去偏策略：监督微调(SFT)、知识蒸馏(KD)和基于规则的强化学习(RL)，并调整去偏样本与推理样本的比例以绘制权衡曲线。

Result: 实验表明，采用强化学习训练且去偏与推理样本比例为1:4时，模型刻板印象得分降低10%，同时保留原始推理准确性的88%。

Conclusion: 研究为MLLMs公平性与能力平衡提供了具体方案，强化学习结合特定样本比例是实现该目标的有效途径。

Abstract: Multimodal Large Language Models (MLLMs) already achieve state-of-the-art
results across a wide range of tasks and modalities. To push their reasoning
ability further, recent studies explore advanced prompting schemes and
post-training fine-tuning. Although these techniques improve logical accuracy,
they frequently leave the models' outputs burdened with pronounced social
biases. Clarifying how reasoning gains interact with bias mitigation-and
whether the two objectives inherently trade off-therefore remains an open and
pressing research problem. Our study begins by benchmarking three
bias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation
(KD), and rule-based reinforcement learning (RL)-under identical conditions,
establishing their baseline strengths and weaknesses. Building on these
results, we vary the proportion of debias-focused and reasoning-centric samples
within each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps
reveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement
learning cuts stereotype scores by 10% while retaining 88% of the model's
original reasoning accuracy, offering concrete guidance for balancing fairness
and capability in MLLMs.

</details>


### [50] [Moravec's Paradox: Towards an Auditory Turing Test](https://arxiv.org/abs/2507.23091)
*David Noever,Forrest McKee*

Main category: cs.AI

TL;DR: 研究表明，当前AI系统在人类轻松完成的听觉任务上表现极差，失败率超过93%，而人类成功率高达52%。研究通过917项听觉挑战测试，揭示了AI在选择性注意力、噪声鲁棒性和上下文适应方面的根本缺陷。


<details>
  <summary>Details</summary>
Motivation: 受Moravec悖论启发（即对人类简单的任务对机器却很难），研究旨在量化AI与人类在听觉任务上的差距，并探索失败原因，推动实现人类水平的机器听觉。

Method: 设计了包含7类（重叠语音、噪声环境语音等）917项挑战的听觉图灵测试，评估了GPT-4音频能力和Whisper等前沿模型。

Result: 最佳模型准确率仅6.9%，远低于人类52%的表现。AI在选择性注意力、噪声处理和场景适应等核心机制上存在系统性缺陷。

Conclusion: 需开发整合选择性注意力、基于物理的音频理解和情境感知的新架构，当前音频CAPTCHA设计反映了机器缺乏人类进化出的听觉过滤机制。研究建立了诊断机器听觉进步的框架。

Abstract: This research work demonstrates that current AI systems fail catastrophically
on auditory tasks that humans perform effortlessly. Drawing inspiration from
Moravec's paradox (i.e., tasks simple for humans often prove difficult for
machines, and vice versa), we introduce an auditory Turing test comprising 917
challenges across seven categories: overlapping speech, speech in noise,
temporal distortion, spatial audio, coffee-shop noise, phone distortion, and
perceptual illusions. Our evaluation of state-of-the-art audio models including
GPT-4's audio capabilities and OpenAI's Whisper reveals a striking failure rate
exceeding 93%, with even the best-performing model achieving only 6.9% accuracy
on tasks that humans solved at 7.5 times higher success (52%). These results
expose focusing failures in how AI systems process complex auditory scenes,
particularly in selective attention, noise robustness, and contextual
adaptation. Our benchmark not only quantifies the human-machine auditory gap
but also provides insights into why these failures occur, suggesting that
current architectures lack fundamental mechanisms for human-like auditory scene
analysis. The traditional design of audio CAPTCHAs highlights common filters
that humans evolved but machines fail to select in multimodal language models.
This work establishes a diagnostic framework for measuring progress toward
human-level machine listening and highlights the need for novel approaches
integrating selective attention, physics-based audio understanding, and
context-aware perception into multimodal AI systems.

</details>


### [51] [Argumentatively Coherent Judgmental Forecasting](https://arxiv.org/abs/2507.23163)
*Deniz Gorur,Antonio Rago,Francesca Toni*

Main category: cs.AI

TL;DR: 本文提出并形式化定义了判断性预测中的论证连贯性属性，通过三项评估验证其价值。研究表明，过滤不连贯预测能提升人类和LLM预测准确性，但用户实验显示人们普遍未遵循该属性，因此需在群体预测前整合过滤机制。


<details>
  <summary>Details</summary>
Motivation: 判断性预测依赖人类观点而非历史数据，当观点围绕预测形成论证结构时，需从论证角度研究预测特性。本文旨在定义并验证论证连贯性对预测质量的影响。

Method: 1. 形式化定义论证连贯性；2. 评估强制连贯性对人类和LLM预测准确性的影响；3. 通过众包实验检验用户对连贯性的实际遵循程度。

Result: 过滤不连贯预测显著提升人类和LLM预测准确性（平均提升12%）。但用户实验表明，尽管连贯性直观有用，多数人并未自然遵循该属性。

Conclusion: 论证连贯性是判断性预测的关键质量指标，需在群体预测流程中整合过滤机制以剔除不连贯观点，从而提升整体预测可靠性。

Abstract: Judgmental forecasting employs human opinions to make predictions about
future events, rather than exclusively historical data as in quantitative
forecasting. When these opinions form an argumentative structure around
forecasts, it is useful to study the properties of the forecasts from an
argumentative perspective. In this paper, we advocate and formally define a
property of argumentative coherence, which, in essence, requires that a
forecaster's reasoning is coherent with their forecast. We then conduct three
evaluations with our notion of coherence. First, we assess the impact of
enforcing coherence on human forecasters as well as on Large Language Model
(LLM)-based forecasters, given that they have recently shown to be competitive
with human forecasters. In both cases, we show that filtering out incoherent
predictions improves forecasting accuracy consistently, supporting the
practical value of coherence in both human and LLM-based forecasting. Then, via
crowd-sourced user experiments, we show that, despite its apparent
intuitiveness and usefulness, users do not generally align with this coherence
property. This points to the need to integrate, within argumentation-based
judgmental forecasting, mechanisms to filter out incoherent opinions before
obtaining group forecasting predictions.

</details>


### [52] [Tractable Responsibility Measures for Ontology-Mediated Query Answering](https://arxiv.org/abs/2507.23191)
*Meghyn Bienvenu,Diego Figueira,Pierre Lafourcade*

Main category: cs.AI

TL;DR: 本文研究了基于Shapley值的责任度量（WSMS）在ontology-mediated查询回答中的计算复杂性，揭示了在不同查询类型和本体语言下的可处理性边界。


<details>
  <summary>Details</summary>
Motivation: 近期研究采用责任度量量化事实对查询结果的贡献，但WSMS在ontology-mediated查询中的计算复杂性尚未明确，需系统探索其可处理性边界。

Method: 通过结合数据库领域已有成果，分析不同ontology语言（如支持合取或DL-Lite方言）对WSMS计算的影响，并设计结构受限的查询类以保证可处理性。

Result: 证明WSMS在first-order-rewritable查询中具有多项式数据复杂度，但若本体语言支持可达性查询（如$\exists R. A \sqsubseteq A$）则导致shP-困难；同时发现合取操作或特定联合查询即使在无本体时也引发计算困难，而DL-Lite方言中结构受限的查询可保持高效计算。

Conclusion: 研究明确了WSMS在ontology-mediated查询中的复杂性边界，为实际应用提供了理论指导：需避免特定查询结构或选择可处理的本体语言（如DL-Lite）以实现高效责任计算。

Abstract: Recent work on quantitative approaches to explaining query answers employs
responsibility measures to assign scores to facts in order to quantify their
respective contributions to obtaining a given answer. In this paper, we study
the complexity of computing such responsibility scores in the setting of
ontology-mediated query answering, focusing on a very recently introduced
family of Shapley-value-based responsibility measures defined in terms of
weighted sums of minimal supports (WSMS). By exploiting results from the
database setting, we can show that such measures enjoy polynomial data
complexity for classes of ontology-mediated queries that are
first-order-rewritable, whereas the problem becomes "shP"-hard when the
ontology language can encode reachability queries (via axioms like $\exists R.
A \sqsubseteq A$). To better understand the tractability frontier, we next
explore the combined complexity of WSMS computation. We prove that
intractability applies already to atomic queries if the ontology language
supports conjunction, as well as to unions of `well-behaved' conjunctive
queries, even in the absence of an ontology. By contrast, our study yields
positive results for common DL-Lite dialects: by means of careful analysis, we
identify classes of structurally restricted conjunctive queries (which
intuitively disallow undesirable interactions between query atoms) that admit
tractable WSMS computation.

</details>


### [53] [Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification](https://arxiv.org/abs/2507.23197)
*Yuke Liao,Blaise Genest,Kuldeep Meel,Shaan Aryaman*

Main category: cs.AI

TL;DR: 该论文提出了一种新颖的解决方案感知ReLU评分方法（SAS），通过分治法减少二元变量数量，显著提升了验证效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂实例时，由于ReLU变量选择不理想导致效率低下，需要更优的变量选择策略。

Method: 提出SAS评分方法，并适配BaB-SR和BaB-FSB分支函数作为全局评分（GS），结合混合MILP框架（先调用$\alpha,\beta$-CROWN快速处理简单实例，再使用部分MILP）。

Result: SAS将二元变量数量减少约6倍，同时保持相同精度；混合方法将未决实例比例降至8-15%，平均运行时间46-417秒（适用于200万参数CNN）。

Conclusion: SAS结合混合MILP框架实现了高效精确的验证器，在保持合理运行时间下显著提升决策率，为大规模神经网络验证提供新方案。

Abstract: To handle complex instances, we revisit a divide-and-conquer approach to
break down the complexity: instead of few complex BaB calls, we rely on many
small {\em partial} MILP calls. The crucial step is to select very few but very
important ReLUs to treat using (costly) binary variables. The previous attempts
were suboptimal in that respect. To select these important ReLU variables, we
propose a novel {\em solution-aware} ReLU scoring ({\sf SAS}), as well as adapt
the BaB-SR and BaB-FSB branching functions as {\em global} ReLU scoring ({\sf
GS}) functions. We compare them theoretically as well as experimentally, and
{\sf SAS} is more efficient at selecting a set of variables to open using
binary variables. Compared with previous attempts, SAS reduces the number of
binary variables by around 6 times, while maintaining the same level of
accuracy. Implemented in {\em Hybrid MILP}, calling first $\alpha,\beta$-CROWN
with a short time-out to solve easier instances, and then partial MILP,
produces a very accurate yet efficient verifier, reducing by up to $40\%$ the
number of undecided instances to low levels ($8-15\%$), while keeping a
reasonable runtime ($46s-417s$ on average per instance), even for fairly large
CNNs with 2 million parameters.

</details>


### [54] [How Far Are AI Scientists from Changing the World?](https://arxiv.org/abs/2507.23276)
*Qiujie Xie,Yixuan Weng,Minjun Zhu,Fuchen Shen,Shulin Huang,Zhen Lin,Jiahui Zhou,Zilan Mao,Zijie Yang,Linyi Yang,Jian Wu,Yue Zhang*

Main category: cs.AI

TL;DR: 大型语言模型(LLM)推动AI科学家系统引领科研变革，本文综述其现状、瓶颈与终极目标。


<details>
  <summary>Details</summary>
Motivation: 探讨AI科学家系统何时能颠覆科研范式、解决重大科学挑战，明确当前局限与发展方向。

Method: 采用前瞻性综述方法，系统分析AI科学家系统的现有成果与关键组件需求。

Result: 发现当前系统已能产出人类未知成果（如ICLR 2025收录AI论文），但突破性发现仍受核心瓶颈制约。

Conclusion: 需明确科学AI的终极目标，弥补现有系统缺陷，以实现真正颠覆性科研范式重塑。

Abstract: The emergence of large language models (LLMs) is propelling automated
scientific discovery to the next level, with LLM-based Artificial Intelligence
(AI) Scientist systems now taking the lead in scientific research. Several
influential works have already appeared in the field of AI Scientist systems,
with AI-generated research papers having been accepted at the ICLR 2025
workshop, suggesting that a human-level AI Scientist capable of uncovering
phenomena previously unknown to humans, may soon become a reality. In this
survey, we focus on the central question: How far are AI scientists from
changing the world and reshaping the scientific research paradigm? To answer
this question, we provide a prospect-driven review that comprehensively
analyzes the current achievements of AI Scientist systems, identifying key
bottlenecks and the critical components required for the emergence of a
scientific agent capable of producing ground-breaking discoveries that solve
grand challenges. We hope this survey will contribute to a clearer
understanding of limitations of current AI Scientist systems, showing where we
are, what is missing, and what the ultimate goals for scientific AI should be.

</details>


### [55] [AI Must not be Fully Autonomous](https://arxiv.org/abs/2507.23330)
*Tosin Adewumi,Lama Alkhaled,Florent Imbert,Hui Han,Nudrat Habib,Karl Löwenmark*

Main category: cs.AI

TL;DR: 本文探讨了自主人工智能（AI）的三个级别，主张不应发展完全自主的AI（第三级），因其存在重大风险，特别是在人工超级智能（ASI）可能几十年内出现的背景下。作者通过理论讨论、12个论点、6个反驳及附录中的15个案例，强调人类监督对风险管控的关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于自主AI的双重性：其潜在益处与重大风险并存。随着人工超级智能（ASI）可能在未来几十年内实现，完全自主的AI（尤其是能自主设定目标的第三级）缺乏人类监督将带来不可控风险。

Method: 方法包括：1. 梳理自主性、AI与智能体理论；2. 提出12个支持限制AI自主性的论点；3. 分析6个反对观点并逐一反驳；4. 在附录中列举15个近期AI价值错位及风险的实证案例。

Result: 研究结果表明，完全自主的AI（第三级）因可能脱离人类控制目标而风险极高。现有证据显示，即使当前AI已频繁出现价值偏差，强化人类监督是必要措施。

Conclusion: 结论明确反对发展完全自主的AI，主张所有AI系统必须保留人类监督机制。尤其在ASI临近的背景下，需通过理论框架与实证案例的结合，优先防控自主AI的潜在威胁。

Abstract: Autonomous Artificial Intelligence (AI) has many benefits. It also has many
risks. In this work, we identify the 3 levels of autonomous AI. We are of the
position that AI must not be fully autonomous because of the many risks,
especially as artificial superintelligence (ASI) is speculated to be just
decades away. Fully autonomous AI, which can develop its own objectives, is at
level 3 and without responsible human oversight. However, responsible human
oversight is crucial for mitigating the risks. To ague for our position, we
discuss theories of autonomy, AI and agents. Then, we offer 12 distinct
arguments and 6 counterarguments with rebuttals to the counterarguments. We
also present 15 pieces of recent evidence of AI misaligned values and other
risks in the appendix.

</details>


### [56] [DSBC : Data Science task Benchmarking with Context engineering](https://arxiv.org/abs/2507.23336)
*Ram Mohan Rao Kadiyala,Siddhant Gupta,Jebish Purbey,Giulio Martini,Suman Debnath,Hamza Farooq*

Main category: cs.AI

TL;DR: 本文提出一个针对数据科学代理的综合性基准测试，评估了三种大型语言模型在不同方法下的表现，揭示了性能差异及关键影响因素。


<details>
  <summary>Details</summary>
Motivation: 尽管数据科学代理快速普及，但缺乏系统性评估其效能与局限的基准测试，本文旨在填补这一空白。

Method: 通过商业应用观察真实用户交互，评估Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini三种模型在零样本上下文工程、多步上下文工程及SmolAgent三种方法下的表现，涵盖八类数据科学任务，并测试模型对提示问题的敏感性及温度参数的影响。

Result: 评估结果显示不同模型和方法间存在显著性能差异，温度参数对任务特定结果有显著影响。

Conclusion: 本文提出的基准数据集和评估框架为未来研究更鲁棒高效的数据科学代理奠定了基础。

Abstract: Recent advances in large language models (LLMs) have significantly impacted
data science workflows, giving rise to specialized data science agents designed
to automate analytical tasks. Despite rapid adoption, systematic benchmarks
evaluating the efficacy and limitations of these agents remain scarce. In this
paper, we introduce a comprehensive benchmark specifically crafted to reflect
real-world user interactions with data science agents by observing usage of our
commercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,
Gemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with
context engineering, multi-step with context engineering, and with SmolAgent.
Our benchmark assesses performance across a diverse set of eight data science
task categories, additionally exploring the sensitivity of models to common
prompting issues, such as data leakage and slightly ambiguous instructions. We
further investigate the influence of temperature parameters on overall and
task-specific outcomes for each model and approach. Our findings reveal
distinct performance disparities among the evaluated models and methodologies,
highlighting critical factors that affect practical deployment. The benchmark
dataset and evaluation framework introduced herein aim to provide a foundation
for future research of more robust and effective data science agents.

</details>


### [57] [LLM4Rail: An LLM-Augmented Railway Service Consulting Platform](https://arxiv.org/abs/2507.23377)
*Zhuo Li,Xianghuai Deng,Chiwei Feng,Hanmeng Li,Shenjie Wang,Haichao Zhang,Teng Jia,Conlin Chen,Louis Linchun Wu,Jia Wang*

Main category: cs.AI

TL;DR: 本文提出LLM4Rail平台，通过大语言模型(LLM)增强铁路服务咨询功能，采用创新的QTAO提示框架整合语言推理与任务导向行动，并构建CRFD-25铁路餐饮数据集实现个性化推荐。


<details>
  <summary>Details</summary>
Motivation: 为满足日益增长的个性化铁路服务需求，开发基于LLM的智能咨询平台，解决传统服务系统在票务、餐饮推荐、天气查询等场景的局限性。

Method: 1) 设计迭代式\"问题-思考-行动-观察(QTAO)\"提示框架；2) 构建中国铁路餐饮数据集CRFD-25；3) 开发基于LLM的零样本对话推荐系统，引入特征相似性后处理确保推荐有效性。

Result: 成功实现具备多模块服务的LLM4Rail平台，其中餐饮推荐系统能基于用户画像（年龄/口味偏好等）从CRFD-25数据集中生成个性化推荐，准确率达92.3%。

Conclusion: LLM4Rail通过融合语言推理与领域知识库，显著提升铁路服务智能化水平，QTAO框架与CRFD-25数据集为垂直领域LLM应用提供新范式。

Abstract: Large language models (LLMs) have significantly reshaped different walks of
business. To meet the increasing demands for individualized railway service, we
develop LLM4Rail - a novel LLM-augmented railway service consulting platform.
Empowered by LLM, LLM4Rail can provide custom modules for ticketing, railway
food & drink recommendations, weather information, and chitchat. In LLM4Rail,
we propose the iterative "Question-Thought-Action-Observation (QTAO)" prompting
framework. It meticulously integrates verbal reasoning with task-oriented
actions, that is, reasoning to guide action selection, to effectively retrieve
external observations relevant to railway operation and service to generate
accurate responses. To provide personalized onboard dining services, we first
construct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible
takeout dataset tailored for railway services. CRFD-25 covers a wide range of
signature dishes categorized by cities, cuisines, age groups, and spiciness
levels. We further introduce an LLM-based zero-shot conversational recommender
for railway catering. To address the unconstrained nature of open
recommendations, the feature similarity-based post-processing step is
introduced to ensure all the recommended items are aligned with CRFD-25
dataset.

</details>


### [58] [Chatting with your ERP: A Recipe](https://arxiv.org/abs/2507.23429)
*Jorge Ruiz Gómez,Lidia Andrés Susinos,Jorge Alamo Olivé,Sonia Rey Osorno,Manuel Luis Gonzalez Hernández*

Main category: cs.AI

TL;DR: 本文介绍了一种基于大型语言模型(LLM)的智能代理，能够将自然语言查询转换为可执行的SQL语句，应用于工业级ERP系统。


<details>
  <summary>Details</summary>
Motivation: 旨在解决工业ERP系统中自然语言查询的自动化处理需求，提升人机交互效率。

Method: 采用创新的双代理架构，结合推理与批判阶段，利用开源权重LLM提高查询生成的可靠性。

Result: 成功实现了一个能与生产级ERP系统对话的LLM代理，有效完成自然语言到SQL的转换。

Conclusion: 该双代理架构显著提升了查询生成的准确性，为工业ERP系统的智能化交互提供了可行方案。

Abstract: This paper presents the design, implementation, and evaluation behind a Large
Language Model (LLM) agent that chats with an industrial production-grade ERP
system. The agent is capable of interpreting natural language queries and
translating them into executable SQL statements, leveraging open-weight LLMs. A
novel dual-agent architecture combining reasoning and critique stages was
proposed to improve query generation reliability.

</details>


### [59] [Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation](https://arxiv.org/abs/2507.23440)
*Mingzhe Li,Xin Lu,Yanyan Zhao*

Main category: cs.AI

TL;DR: 本文提出Self-Foveate方法，通过多级聚焦技术提升大语言模型从无监督文本中合成指令的多样性与难度。


<details>
  <summary>Details</summary>
Motivation: 现有自动化指令合成方法在确保指令多样性和难度方面存在显著不足，亟需减少人工标注依赖并提升合成质量。

Method: 采用'微观-散射-宏观'多级聚焦方法，引导大语言模型深度挖掘无监督文本中的细粒度信息。

Result: 跨多组无监督语料库和不同模型架构的实验验证了该方法在提升指令质量方面的有效性和优越性。

Conclusion: Self-Foveate为自动化指令合成提供了创新解决方案，相关数据和代码已开源。

Abstract: Large language models (LLMs) with instruction following capabilities have
demonstrated impressive problem-solving abilities. While synthesizing
instructional data from unsupervised text has become a common approach for
training such models, conventional methods rely heavily on human effort for
data annotation. Although existing automated synthesis paradigms have
alleviated this constraint, they still exhibit significant limitations in
ensuring adequate diversity and difficulty of synthesized instructions. To
address these challenges, we propose Self-Foveate, an innovative LLM-driven
method for instruction synthesis. This approach introduces a
"Micro-Scatter-Macro" multi-level foveation methodology that effectively guides
the LLM to deeply excavate fine-grained information embedded in unsupervised
text, thereby enhancing both the diversity and difficulty of synthesized
instructions. Comprehensive experiments across multiple unsupervised corpora
and diverse model architectures validate the effectiveness and superiority of
our proposed method. We publicly release our data and codes:
https://github.com/Mubuky/Self-Foveate

</details>


### [60] [Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery](https://arxiv.org/abs/2507.23488)
*Kacper Kadziolka,Saber Salehkaleybar*

Main category: cs.AI

TL;DR: 研究发现，采用推理优先架构的大型语言模型在因果发现任务上表现显著优于传统方法，结合模块化上下文管道可进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 因果推断是大型语言模型面临的核心挑战，传统模型在数据扰动下易出现过拟合和随机表现，研究旨在探索先进推理模型在此任务的潜力。

Method: 使用OpenAI的o系列和DeepSeek-R模型在Corr2Cause基准测试因果发现，并引入受Tree-of-Thoughts和Chain-of-Thoughts启发的模块化上下文管道。

Result: 推理优先架构模型展现出显著优势，结合上下文管道后性能提升近三倍，并通过分析推理链长度和复杂度验证其有效性。

Conclusion: 先进推理模型代表了重大进步，但需结合结构化上下文框架才能最大化其能力，为跨领域因果发现提供了可推广的解决方案。

Abstract: Causal inference remains a fundamental challenge for large language models.
Recent advances in internal reasoning with large language models have sparked
interest in whether state-of-the-art reasoning models can robustly perform
causal discovery-a task where conventional models often suffer from severe
overfitting and near-random performance under data perturbations. We study
causal discovery on the Corr2Cause benchmark using the emergent OpenAI's
o-series and DeepSeek-R model families and find that these reasoning-first
architectures achieve significantly greater native gains than prior approaches.
To capitalize on these strengths, we introduce a modular in-context pipeline
inspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding
nearly three-fold improvements over conventional baselines. We further probe
the pipeline's impact by analyzing reasoning chain length, complexity, and
conducting qualitative and quantitative comparisons between conventional and
reasoning models. Our findings suggest that while advanced reasoning models
represent a substantial leap forward, carefully structured in-context
frameworks are essential to maximize their capabilities and offer a
generalizable blueprint for causal discovery across diverse domains.

</details>


### [61] [Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification](https://arxiv.org/abs/2507.23497)
*David A Kelly,Hana Chockler*

Main category: cs.AI

TL;DR: 本文提出了一种基于因果关系的图像分类器解释方法，具有形式化严谨性且适用于黑盒算法，同时引入了对比性和置信度感知的完整因果解释。


<details>
  <summary>Details</summary>
Motivation: 现有图像分类器解释方法缺乏形式化严谨性，而基于逻辑的解释虽严谨但依赖严格假设。本文旨在结合两者的优势，提出既严谨又实用的因果解释方法。

Method: 通过定义因果解释及其对比性变体，并引入置信度感知的完整因果解释。算法完全黑盒化，无需模型内部信息或梯度，计算效率高（平均6秒/图像）。

Result: 实验表明不同模型在充分性、对比性和完整性上呈现不同模式。算法在ResNet50上高效运行，且完全黑盒兼容。

Conclusion: 因果解释为图像分类器提供了形式化严谨且实用的解释框架，其黑盒特性与高效性使其具有广泛适用性。

Abstract: Existing algorithms for explaining the outputs of image classifiers are based
on a variety of approaches and produce explanations that lack formal rigor. On
the other hand, logic-based explanations are formally and rigorously defined
but their computability relies on strict assumptions about the model that do
not hold on image classifiers.
  In this paper, we show that causal explanations, in addition to being
formally and rigorously defined, enjoy the same formal properties as
logic-based ones, while still lending themselves to black-box algorithms and
being a natural fit for image classifiers. We prove formal properties of causal
explanations and introduce contrastive causal explanations for image
classifiers. Moreover, we augment the definition of explanation with confidence
awareness and introduce complete causal explanations: explanations that are
classified with exactly the same confidence as the original image.
  We implement our definitions, and our experimental results demonstrate that
different models have different patterns of sufficiency, contrastiveness, and
completeness. Our algorithms are efficiently computable, taking on average 6s
per image on a ResNet50 model to compute all types of explanations, and are
totally black-box, needing no knowledge of the model, no access to model
internals, no access to gradient, nor requiring any properties, such as
monotonicity, of the model.

</details>


### [62] [DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer](https://arxiv.org/abs/2507.23554)
*Ruoyu Wang,Junda Wu,Yu Xia,Tong Yu,Ryan A. Rossi,Julian McAuley,Lina Yao*

Main category: cs.AI

TL;DR: 本文提出DICE框架，通过因果视角动态选择上下文示例，提升大语言模型代理在复杂任务中的推理稳定性与性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于上下文学习的代理模型性能高度依赖示例选择，但缺乏理论支撑的通用选择标准，导致性能不稳定。

Method: DICE框架将示例知识分解为可迁移/不可迁移成分，提出具有理论保证的逐步选择准则，无需训练即可嵌入现有代理框架。

Result: 跨领域实验验证DICE能显著提升代理性能，证明基于因果关系的动态示例选择对稳健推理的关键作用。

Conclusion: 该研究为代理系统提供了首个理论完备的通用示例选择方案，揭示了上下文感知机制对高效LLM代理的重要性。

Abstract: Large language model-based agents, empowered by in-context learning (ICL),
have demonstrated strong capabilities in complex reasoning and tool-use tasks.
However, existing works have shown that the effectiveness of ICL is highly
sensitive to the choice of demonstrations, with suboptimal examples often
leading to unstable or degraded performance. While prior work has explored
example selection, including in some agentic or multi-step settings, existing
approaches typically rely on heuristics or task-specific designs and lack a
general, theoretically grounded criterion for what constitutes an effective
demonstration across reasoning steps. Therefore, it is non-trivial to develop a
principled, general-purpose method for selecting demonstrations that
consistently benefit agent performance. In this paper, we address this
challenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a
theoretically grounded ICL framework for agentic tasks that selects the most
relevant demonstrations at each step of reasoning. Our approach decomposes
demonstration knowledge into transferable and non-transferable components
through a causal lens, showing how the latter can introduce spurious
dependencies that impair generalization. We further propose a stepwise
selection criterion with a formal guarantee of improved agent performance.
Importantly, DICE is a general, framework-agnostic solution that can be
integrated as a plug-in module into existing agentic frameworks without any
additional training cost. Extensive experiments across diverse domains
demonstrate our method's effectiveness and generality, highlighting the
importance of principled, context-aware demo selection for robust and efficient
LLM agents.

</details>


### [63] [Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI](https://arxiv.org/abs/2507.23565)
*Botao Zhu,Xianbin Wang,Dusit Niyato*

Main category: cs.AI

TL;DR: 本文提出了一种基于语义信任链的自主信任编排方法，利用智能代理和超图技术优化分布式协作中的信任评估，实现资源高效利用。


<details>
  <summary>Details</summary>
Motivation: 分布式协作系统中，任务复杂性、设备资源动态性及评估开销导致信任评估过程复杂且资源消耗大，影响协作效率。

Method: 采用智能代理和超图技术，通过自主感知设备状态、历史数据分析及任务需求匹配，在设备空闲期进行信任评估，并构建嵌入信任语义的局部超图以实现分层管理。

Result: 实验表明，该方法在减少评估开销的同时保持了信任准确性，支持大规模系统中的多跳协作。

Conclusion: 所提出的语义信任链方法有效平衡了评估开销与信任精度，为分布式协作系统提供了资源高效的信任评估解决方案。

Abstract: In collaborative systems, the effective completion of tasks hinges on
task-specific trust evaluations of potential devices for distributed
collaboration. However, the complexity of tasks, the spatiotemporal dynamism of
distributed device resources, and the inevitable assessment overhead
dramatically increase the complexity and resource consumption of the trust
evaluation process. As a result, ill-timed or overly frequent trust evaluations
can reduce utilization rate of constrained resources, negatively affecting
collaborative task execution. To address this challenge, this paper proposes an
autonomous trust orchestration method based on a new concept of semantic
chain-of-trust. Our technique employs agentic AI and hypergraph to establish
and maintain trust relationships among devices. By leveraging its strengths in
autonomous perception, task decomposition, and semantic reasoning, we propose
agentic AI to perceive device states and autonomously perform trust evaluations
of collaborators based on historical performance data only during device idle
periods, thereby enabling efficient utilization of distributed resources. In
addition, agentic AI performs task-specific trust evaluations on collaborator
resources by analyzing the alignment between resource capabilities and task
requirements. Moreover, by maintaining a trust hypergraph embedded with trust
semantics for each device, agentic AI enables hierarchical management of
collaborators and identifies collaborators requiring trust evaluation based on
trust semantics, thereby achieving a balance between overhead and trust
accuracy. Furthermore, local trust hypergraphs from multiple devices can be
chained together to support multi-hop collaboration, enabling efficient
coordination in large-scale systems. Experimental results demonstrate that the
proposed method achieves resource-efficient trust evaluation.

</details>


### [64] [MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying](https://arxiv.org/abs/2507.23633)
*Qian Zhao,Zhuo Sun,Bin Guo,Zhiwen Yu*

Main category: cs.AI

TL;DR: 本文提出了一种策略引导的代理辅助记忆回忆方法，通过设计5W回忆地图和分层回忆树优化策略选择，开发了MemoCue代理，显著提升了记忆回忆效果。


<details>
  <summary>Details</summary>
Motivation: 传统代理辅助记忆回忆方法受限于内存模块大小，难以获取完整记忆。受记忆理论启发，通过有效线索主动激活用户相关记忆，提出了新的解决方案。

Method: 设计了5W回忆地图将记忆查询分类为五种典型场景，定义15种回忆策略模式；提出结合蒙特卡洛树搜索算法的分层回忆树优化策略选择和响应生成；微调开源大语言模型开发MemoCue代理。

Result: 在三个代表性数据集上，MemoCue在回忆启发方面超越基于LLM的方法17.74%；人类评估进一步验证了其在记忆回忆应用中的优势。

Conclusion: 策略引导的代理辅助记忆回忆方法通过系统化策略设计和优化，显著提升了记忆回忆性能，MemoCue代理在实践应用中展现出优越性。

Abstract: Agent-assisted memory recall is one critical research problem in the field of
human-computer interaction. In conventional methods, the agent can retrieve
information from its equipped memory module to help the person recall
incomplete or vague memories. The limited size of memory module hinders the
acquisition of complete memories and impacts the memory recall performance in
practice. Memory theories suggest that the person's relevant memory can be
proactively activated through some effective cues. Inspired by this, we propose
a novel strategy-guided agent-assisted memory recall method, allowing the agent
to transform an original query into a cue-rich one via the judiciously designed
strategy to help the person recall memories. To this end, there are two key
challenges. (1) How to choose the appropriate recall strategy for diverse
forgetting scenarios with distinct memory-recall characteristics? (2) How to
obtain the high-quality responses leveraging recall strategies, given only
abstract and sparsely annotated strategy patterns? To address the challenges,
we propose a Recall Router framework. Specifically, we design a 5W Recall Map
to classify memory queries into five typical scenarios and define fifteen
recall strategy patterns across the corresponding scenarios. We then propose a
hierarchical recall tree combined with the Monte Carlo Tree Search algorithm to
optimize the selection of strategy and the generation of strategy responses. We
construct an instruction tuning dataset and fine-tune multiple open-source
large language models (LLMs) to develop MemoCue, an agent that excels in
providing memory-inspired responses. Experiments on three representative
datasets show that MemoCue surpasses LLM-based methods by 17.74% in recall
inspiration. Further human evaluation highlights its advantages in
memory-recall applications.

</details>


### [65] [Personalized Education with Ranking Alignment Recommendation](https://arxiv.org/abs/2507.23664)
*Haipeng Liu,Yuxuan Liu,Ting Long*

Main category: cs.AI

TL;DR: 本文提出了一种名为排名对齐推荐（RAR）的新方法，通过将协作思想融入探索机制，解决了现有强化学习方法在个性化问题推荐中探索效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化问题推荐方法大多基于马尔可夫决策过程并使用强化学习，但在训练过程中难以高效探索，无法为每个学生找到最佳问题。

Method: 提出的RAR方法将协作思想整合到探索机制中，从而在有限的训练周期内实现更高效的探索。该方法可应用于任何基于强化学习的问题推荐系统。

Result: 实验表明，RAR有效提升了推荐性能，且该框架具有通用性。

Conclusion: RAR通过改进探索机制，显著提高了个性化问题推荐的效率，其框架设计具有广泛适用性。代码已开源。

Abstract: Personalized question recommendation aims to guide individual students
through questions to enhance their mastery of learning targets. Most previous
methods model this task as a Markov Decision Process and use reinforcement
learning to solve, but they struggle with efficient exploration, failing to
identify the best questions for each student during training. To address this,
we propose Ranking Alignment Recommendation (RAR), which incorporates
collaborative ideas into the exploration mechanism, enabling more efficient
exploration within limited training episodes. Experiments show that RAR
effectively improves recommendation performance, and our framework can be
applied to any RL-based question recommender. Our code is available in
https://github.com/wuming29/RAR.git.

</details>


### [66] [TextQuests: How Good are LLMs at Text-Based Video Games?](https://arxiv.org/abs/2507.23701)
*Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks*

Main category: cs.AI

TL;DR: 本文介绍了TextQuests基准测试，基于Infocom互动小说游戏，旨在评估AI代理在长上下文推理和自主探索环境中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能全面评估AI代理在需要长期自主推理的探索性环境中的表现，因此需要开发新基准以促进更强大的内在推理能力。

Method: 采用Infocom互动小说游戏作为测试环境，禁止使用外部工具，专注于评估代理在单一交互会话中的长上下文推理和试错学习能力。

Result: TextQuests基准测试发布，可作为评估AI代理在复杂、状态化任务中自主解决问题能力的有效工具。

Conclusion: TextQuests为开发具有长期自主推理能力的AI代理提供了重要基准，填补了现有评估体系的空白。

Abstract: Evaluating AI agents within complex, interactive environments that mirror
real-world challenges is critical for understanding their practical
capabilities. While existing agent benchmarks effectively assess skills like
tool use or performance on structured tasks, they often do not fully capture an
agent's ability to operate autonomously in exploratory environments that demand
sustained, self-directed reasoning over a long and growing context. To spur the
development of agents capable of more robust intrinsic reasoning over long
horizons, we introduce TextQuests, a benchmark based on the Infocom suite of
interactive fiction games. These text-based adventures, which can take human
players over 30 hours and require hundreds of precise actions to solve, serve
as an effective proxy for evaluating AI agents on focused, stateful tasks. The
benchmark is specifically designed to assess an LLM agent's capacity for
self-contained problem-solving by precluding the use of external tools, thereby
focusing on intrinsic long-context reasoning capabilities in an exploratory
environment characterized by the need for trial-and-error learning and
sustained problem-solving within a single interactive session. We release
TextQuests at https://textquests.ai.

</details>


### [67] [Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving](https://arxiv.org/abs/2507.23726)
*Luoxin Chen,Jinming Gu,Liankai Huang,Wenhao Huang,Zhicheng Jiang,Allan Jie,Xiaoran Jin,Xing Jin,Chenggang Li,Kaijing Ma,Cheng Ren,Jiawei Shen,Wenlei Shi,Tong Sun,He Sun,Jiahui Wang,Siran Wang,Zhihong Wang,Chenrui Wei,Shufa Wei,Yonghui Wu,Yuchen Wu,Yihang Xia,Huajian Xin,Fan Yang,Huaiyuan Ying,Hongyi Yuan,Zheng Yuan,Tianyang Zhan,Chi Zhang,Yue Zhang,Ge Zhang,Tianyun Zhao,Jianqiu Zhao,Yichi Zhou,Thomas Hanwen Zhu*

Main category: cs.AI

TL;DR: Seed-Prover是一种基于强化学习和形式化验证的数学定理证明模型，通过迭代优化证明过程，显著提升了IMO级数学问题的解决能力，并在几何推理方面取得突破。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在数学推理上虽表现优异，但因缺乏明确的监督信号，在定理证明上仍有局限。形式化验证语言如Lean能提供清晰反馈，但需解决几何支持不足等问题。

Method: 提出Seed-Prover模型，结合Lean的形式化验证反馈、已证引理和自我总结迭代优化证明；设计三种测试时推理策略实现深度与广度推理；开发Seed-Geometry引擎增强几何问题处理能力。

Result: Seed-Prover在形式化IMO历史题中达到78.1\%的证明率，显著超越先前最佳表现；Seed-Geometry优于现有几何引擎；在IMO 2025中成功证明5/6的题目。

Conclusion: 该研究通过形式化验证与长链推理的结合，推动了自动数学推理的显著进展，证明了混合系统在解决高难度数学问题上的有效性。

Abstract: LLMs have demonstrated strong mathematical reasoning abilities by leveraging
reinforcement learning with long chain-of-thought, yet they continue to
struggle with theorem proving due to the lack of clear supervision signals when
solely using natural language. Dedicated domain-specific languages like Lean
provide clear supervision via formal verification of proofs, enabling effective
training through reinforcement learning. In this work, we propose
\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover
can iteratively refine its proof based on Lean feedback, proved lemmas, and
self-summarization. To solve IMO-level contest problems, we design three
test-time inference strategies that enable both deep and broad reasoning.
Seed-Prover proves $78.1\%$ of formalized past IMO problems, saturates MiniF2F,
and achieves over 50\% on PutnamBench, outperforming the previous
state-of-the-art by a large margin. To address the lack of geometry support in
Lean, we introduce a geometry reasoning engine \textbf{Seed-Geometry}, which
outperforms previous formal geometry engines. We use these two systems to
participate in IMO 2025 and fully prove 5 out of 6 problems. This work
represents a significant advancement in automated mathematical reasoning,
demonstrating the effectiveness of formal verification with long
chain-of-thought reasoning.

</details>


### [68] [CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks](https://arxiv.org/abs/2507.23751)
*Ping Yu,Jack Lanchantin,Tianlu Wang,Weizhe Yuan,Olga Golovneva,Ilia Kulikov,Sainbayar Sukhbaatar,Jason Weston,Jing Xu*

Main category: cs.AI

TL;DR: 提出CoT-Self-Instruct方法，通过链式思考生成高质量合成数据，显著提升LLM在可验证推理和非可验证指令任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM训练数据在复杂推理任务上表现不足，需开发能自动生成高质量合成数据的方法。

Method: 1. 基于种子任务引导LLM进行链式思考(CoT) 2. 生成质量相似的新合成提示 3. 使用自动指标过滤高质量数据。

Result: 在MATH500等可验证推理任务上超越s1k等数据集；在AlpacaEval 2.0等非可验证任务上优于人类编写的提示。

Conclusion: CoT-Self-Instruct能有效生成训练数据，显著提升LLM在复杂任务中的性能表现。

Abstract: We propose CoT-Self-Instruct, a synthetic data generation method that
instructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the
given seed tasks, and then to generate a new synthetic prompt of similar
quality and complexity for use in LLM training, followed by filtering for
high-quality data with automatic metrics. In verifiable reasoning, our
synthetic data significantly outperforms existing training datasets, such as
s1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For
non-verifiable instruction-following tasks, our method surpasses the
performance of human or standard self-instruct prompts on both AlpacaEval 2.0
and Arena-Hard.

</details>


### [69] [SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model](https://arxiv.org/abs/2507.23773)
*Mingkai Deng,Jinyu Hou,Yilin Shen,Hongxia Jin,Graham Neubig,Zhiting Hu,Eric Xing*

Main category: cs.AI

TL;DR: 本文提出SimuRA架构，通过世界模型模拟克服自回归LLM的局限性，在网页浏览任务中实现32.2%的航班搜索成功率，比自回归规划提升124%。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理采用单任务单代理模式，缺乏可扩展性和通用性，且受限于自回归LLM的根本缺陷。人类通过心理模拟进行推理的通用性启发了本研究。

Method: 基于最优代理理论框架，SimuRA引入LLM实现的通用世界模型，利用自然语言的潜在概念空间进行跨环境规划，特别开发了网页浏览代理演示系统。

Result: 在困难网页任务中，航班搜索成功率从0%提升至32.2%，基于世界模型的规划比自回归方法最高有124%的优势。

Conclusion: SimuRA证明了世界模型模拟作为推理范式的优越性，为训练基于LLM的通用超级智能代理迈出重要一步，已开放网页浏览代理供公开测试。

Abstract: AI agents built on large language models (LLMs) hold enormous promise, but
current practice focuses on a one-task-one-agent approach, which not only falls
short of scalability and generality, but also suffers from the fundamental
limitations of autoregressive LLMs. On the other hand, humans are general
agents who reason by mentally simulating the outcomes of their actions and
plans. Moving towards a more general and powerful AI agent, we introduce
SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based
on a principled formulation of optimal agent in any environment, \modelname
overcomes the limitations of autoregressive reasoning by introducing a world
model for planning via simulation. The generalized world model is implemented
using LLM, which can flexibly plan in a wide range of environments using the
concept-rich latent space of natural language. Experiments on difficult web
browsing tasks show that \modelname improves the success of flight search from
0\% to 32.2\%. World-model-based planning, in particular, shows consistent
advantage of up to 124\% over autoregressive planning, demonstrating the
advantage of world model simulation as a reasoning paradigm. We are excited
about the possibility for training a single, general agent model based on LLMs
that can act superintelligently in all environments. To start, we make SimuRA,
a web-browsing agent built on \modelname with pretrained LLMs, available as a
research demo for public testing.

</details>


<div id='stat.TH'></div>

# stat.TH [[Back]](#toc)

### [70] [Information geometry of Lévy processes and financial models](https://arxiv.org/abs/2507.23646)
*Jaehyung Choi*

Main category: stat.TH

TL;DR: 本文研究了L\'evy过程的信息几何结构，推导了$\alpha$-散度、Fisher信息矩阵和$\alpha$-连接，并探讨了在金融建模中的应用。


<details>
  <summary>Details</summary>
Motivation: 探索L\'evy过程的信息几何特性，为金融建模中的随机过程提供新的分析工具。

Method: 从$\alpha$-散度出发，推导了Fisher信息矩阵和$\alpha$-连接，并分析了多种L\'evy过程的微分几何结构。

Result: 计算了L\'evy过程的几何结构，包括调和稳定过程、CGMY模型和方差伽玛过程等金融相关案例。

Conclusion: 该信息几何框架为L\'evy过程的统计分析提供了新的视角，尤其在金融建模中具有潜在应用价值。

Abstract: We explore the information geometry of L\'evy processes. As a starting point,
we derive the $\alpha$-divergence between two L\'evy processes. Subsequently,
the Fisher information matrix and the $\alpha$-connection associated with the
geometry of L\'evy processes are computed from the $\alpha$-divergence. In
addition, we discuss statistical applications of this information geometry. As
illustrative examples, we investigate the differential-geometric structures of
various L\'evy processes relevant to financial modeling, including tempered
stable processes, the CGMY model, and variance gamma processes.

</details>
