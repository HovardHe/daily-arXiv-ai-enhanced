{"id": "2506.19857", "categories": ["math.HO", "cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.19857", "abs": "https://arxiv.org/abs/2506.19857", "authors": ["Inés García-Redondo", "Claudia Landi", "Sarah Percival", "Anda Skeja", "Bei Wang", "Ling Zhou"], "title": "Finding the Cores of Higher Graphs Using Geometric and Topological Means: A Survey", "comment": "54 pages", "summary": "In this survey, we explore recent literature on finding the cores of higher\ngraphs using geometric and topological means. We study graphs, hypergraphs, and\nsimplicial complexes, all of which are models of higher graphs. We study the\nnotion of a core, which is a minimalist representation of a higher graph that\nretains its geometric or topological information. We focus on geometric and\ntopological methods based on discrete curvatures, effective resistance, and\npersistent homology. We aim to connect tools from graph theory, discrete\ngeometry, and computational topology to inspire new research on the\nsimplification of higher graphs.", "AI": {"tldr": "本文综述了利用几何与拓扑方法寻找高阶图核心的最新研究，涵盖图、超图和单纯复形等模型，重点探讨了基于离散曲率、有效电阻和持续同调的核心提取技术。", "motivation": "高阶图的核心提取能保留其几何或拓扑信息的最小表示，有助于简化复杂结构并促进图论、离散几何与计算拓扑的跨学科研究。", "method": "采用离散曲率、有效电阻和持续同调等几何拓扑工具，对图、超图及单纯复形进行核心特征分析。", "result": "建立了高阶图核心提取的统一框架，验证了几何拓扑方法在简化复杂结构中的有效性。", "conclusion": "该研究为高阶图简化提供了新思路，推动了图论与拓扑方法的交叉融合，具有潜在的理论与应用价值。"}}
{"id": "2506.19868", "categories": ["math.NT", "15A36"], "pdf": "https://arxiv.org/pdf/2506.19868", "abs": "https://arxiv.org/abs/2506.19868", "authors": ["Abraham Berman", "Eliyahu Levy"], "title": "11 can be reduced to 10", "comment": null, "summary": "Laffey and Smigoc proved that for every 2x2 doubly nonnegative integer matrix\nA, icpr(A) is less than or equal to 11. We prove that 11 can be replaced by 10,\nand show that for many small matrices, even by 9.15", "AI": {"tldr": "Laffey和Smigoc证明所有2x2双非负整数矩阵A的icpr(A)≤11，本文将其改进为≤10，并对许多小矩阵进一步降至9.15。", "motivation": "研究2x2双非负整数矩阵的icpr上界优化问题，改进现有理论结果。", "method": "通过数学证明与数值分析相结合的方法，对矩阵性质进行深入探讨。", "result": "成功将icpr(A)的上界从11降至10，并证明对小矩阵可达9.15。", "conclusion": "该研究显著改进了2x2双非负整数矩阵的icpr上界，为相关领域提供了更精确的理论工具。"}}
{"id": "2506.20118", "categories": ["math.NT", "cs.IT", "math.IT", "11T06, 37P25"], "pdf": "https://arxiv.org/pdf/2506.20118", "abs": "https://arxiv.org/abs/2506.20118", "authors": ["Kai Tan", "Chengqing Li"], "title": "The Graph Structure of a Class of Permutation Maps over Ring $\\mathbb{Z}_{p^k}$", "comment": "11 pages, 1 figure", "summary": "Understanding the periodic and structural properties of permutation maps over\nresidue rings such as $\\mathbb{Z}_{p^k}$ is a foundational challenge in\nalgebraic dynamics and pseudorandom sequence analysis. Despite notable progress\nin characterizing global periods, a critical bottleneck remains: the lack of\nexplicit tools to analyze local cycle structures and their evolution with\nincreasing arithmetic precision. In this work, we propose a unified analytical\nframework to systematically derive the distribution of cycle lengths for a\nclass of permutation maps over $\\mathbb{Z}_{p^k}$. The approach combines\ntechniques from generating functions, minimal polynomials, and lifting theory\nto track how the cycle structure adapts as the modulus $p^k$ changes. To\nvalidate the generality and effectiveness of our method, we apply it to the\nwell-known Cat map as a canonical example, revealing the exact patterns\ngoverning its cycle formation and transition. This analysis not only provides\nrigorous explanations for experimentally observed regularities in fixed-point\nimplementations of such maps but also lays a theoretical foundation for\nevaluating the randomness and dynamical behavior of pseudorandom number\nsequences generated by other nonlinear maps. The results have broad\nimplications for secure system design, computational number theory, and\nsymbolic dynamics.", "AI": {"tldr": "该研究提出了一个统一的分析框架，用于系统地推导$\\mathbb{Z}_{p^k}$上一类置换映射的周期长度分布，结合生成函数、极小多项式和提升理论，揭示了循环结构的演化规律，并以Cat映射为例验证了方法的有效性。", "motivation": "尽管在刻画全局周期方面取得了进展，但缺乏分析局部循环结构及其随算术精度增加的演化工具，这成为代数动力学和伪随机序列分析中的一个关键瓶颈。", "method": "结合生成函数、极小多项式和提升理论的技术，提出统一的分析框架，追踪模数$p^k$变化时循环结构的适应性变化。", "result": "以Cat映射为例，揭示了其循环形成和过渡的精确模式，为实验观察到的固定点实现中的规律性提供了严格解释。", "conclusion": "该分析不仅为评估其他非线性映射生成的伪随机数序列的随机性和动态行为奠定了理论基础，还对安全系统设计、计算数论和符号动力学具有广泛意义。"}}
{"id": "2506.20150", "categories": ["math.NT", "11M32, 11M41"], "pdf": "https://arxiv.org/pdf/2506.20150", "abs": "https://arxiv.org/abs/2506.20150", "authors": ["Driss Essouabri", "Kohji Matsumoto", "Simon Rutard"], "title": "Values at non-positive integers of partially twisted multiple zeta-functions II", "comment": null, "summary": "We study the values at non-positive integer points of multi-variable twisted\nmultiple zeta-functions, whose each factor of the denominator is given by\npolynomials. The fully twisted case was already answered by de Crisenoy. On the\npartially twisted case, in one of our former article we studied the case when\neach factor of the denominator is given by linear forms or power-sum forms. In\nthe present paper we treat the case of general polynomial denominators, and\nobtain explicit forms of the values at non-positive integer points. Our\nstrategy is to reduce to the theorem of de Crisenoy for the fully twisted case,\nvia the multiple Mellin-Barnes integral formula. We observe that in some cases\nthe obtained values are transcendental.", "AI": {"tldr": "本文研究了多变量扭曲多重zeta函数在非正整数点的取值问题，特别是分母为一般多项式的情况，通过多重Mellin-Barnes积分公式将问题转化为完全扭曲情形，并发现某些情况下所得到的值是超越数。", "motivation": "研究多变量扭曲多重zeta函数在非正整数点的取值，特别是分母为一般多项式的情况，以扩展对这类函数性质的理解。", "method": "通过多重Mellin-Barnes积分公式，将部分扭曲情形转化为完全扭曲情形，利用de Crisenoy的定理进行求解。", "result": "获得了分母为一般多项式的多变量扭曲多重zeta函数在非正整数点的显式表达式，并发现某些情况下这些值是超越数。", "conclusion": "本文成功地将部分扭曲情形的多变量扭曲多重zeta函数的非正整数点取值问题转化为完全扭曲情形，并揭示了某些情况下取值的超越性质。"}}
{"id": "2506.20175", "categories": ["math.NT", "11G05, 11G40"], "pdf": "https://arxiv.org/pdf/2506.20175", "abs": "https://arxiv.org/abs/2506.20175", "authors": ["K. Lakshmanan"], "title": "On the Minimality of the Conductor in Rank Bounds for Elliptic Curves", "comment": "8 pages", "summary": "We show that no arithmetic invariant strictly smaller than the conductor of\nan elliptic curve over \\( \\mathbb{Q} \\) can appear in a functional equation\ngoverning the analytic continuation of an associated \\( L \\)-function of degree\ntwo. In particular, any attempt to define a modified \\( L \\)-function for an\nelliptic curve with a smaller invariant in place of the conductor leads to a\ncontradiction with the Modularity Theorem. As a consequence, the classical\nupper bound \\( \\operatorname{rank}(E) \\ll \\log N_E \\) is analytically optimal:\nno refinement replacing the conductor \\( N_E \\) with a smaller arithmetic\nquantity is possible. We further derive a conditional corollary: if a\nsub-conductor invariant were to govern the rank in an unbounded family of\nelliptic curves, the ranks must be unbounded - placing our results in\nconnection with deep open questions concerning the distribution of ranks over\n\\( \\mathbb{Q} \\).", "AI": {"tldr": "本文证明了椭圆曲线的算术不变量中，没有比其导子更小的量能在二阶L函数的解析延拓函数方程中出现。任何尝试用更小的不变量替代导子来定义修正L函数都会与模性定理矛盾。由此得出经典秩上界$\\log N_E$在解析意义下是最优的，且若子导子不变量控制无界椭圆曲线族的秩，则秩必须无界。", "motivation": "研究椭圆曲线L函数解析性质与算术不变量之间的关系，特别是探讨是否存在比导子更小的不变量能控制L函数的解析行为，从而优化经典的秩上界。", "method": "通过分析椭圆曲线L函数的函数方程结构，结合模性定理的刚性约束，采用反证法证明不存在严格小于导子的算术不变量满足函数方程要求。", "result": "1) 导子是L函数函数方程中最小可能的算术不变量；2) 经典秩上界$\\operatorname{rank}(E) \\ll \\log N_E$无法通过替换更小的量来改进；3) 若子导子控制无界曲线族的秩，则秩必然无界。", "conclusion": "该研究确立了导子在椭圆曲线L函数理论中的极小性地位，揭示了秩上界的最优性，并将结果与秩分布的核心未解决问题联系起来，为后续研究提供了严格的理论边界。"}}
{"id": "2506.19870", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19870", "abs": "https://arxiv.org/abs/2506.19870", "authors": ["Md Asif Ul Hoq Khan", "MD Zahedul Islam", "Istiaq Ahmed", "Md Masud Karim Rabbi", "Farhana Rahman Anonna", "MD Abdul Fahim Zeeshan", "Mehedi Hasan Ridoy", "Bivash Ranjan Chowdhury", "Md Nazmul Shakir Rabbi", "GM Alamin Sadnan"], "title": "Secure Energy Transactions Using Blockchain Leveraging AI for Fraud Detection and Energy Market Stability", "comment": null, "summary": "Peer-to-peer trading and the move to decentralized grids have reshaped the\nenergy markets in the United States. Notwithstanding, such developments lead to\nnew challenges, mainly regarding the safety and authenticity of energy trade.\nThis study aimed to develop and build a secure, intelligent, and efficient\nenergy transaction system for the decentralized US energy market. This research\ninterlinks the technological prowess of blockchain and artificial intelligence\n(AI) in a novel way to solve long-standing challenges in the distributed energy\nmarket, specifically those of security, fraudulent behavior detection, and\nmarket reliability. The dataset for this research is comprised of more than 1.2\nmillion anonymized energy transaction records from a simulated peer-to-peer\n(P2P) energy exchange network emulating real-life blockchain-based American\nmicrogrids, including those tested by LO3 Energy and Grid+ Labs. Each record\ncontains detailed fields of transaction identifier, timestamp, energy volume\n(kWh), transaction type (buy/sell), unit price, prosumer/consumer identifier\n(hashed for privacy), smart meter readings, geolocation regions, and settlement\nconfirmation status. The dataset also includes system-calculated behavior\nmetrics of transaction rate, variability of energy production, and historical\npricing patterns. The system architecture proposed involves the integration of\ntwo layers, namely a blockchain layer and artificial intelligence (AI) layer,\neach playing a unique but complementary function in energy transaction securing\nand market intelligence improvement. The machine learning models used in this\nresearch were specifically chosen for their established high performance in\nclassification tasks, specifically in the identification of energy transaction\nfraud in decentralized markets.", "AI": {"tldr": "本研究开发了一个结合区块链与人工智能的安全、智能、高效的去中心化能源交易系统，旨在解决美国分布式能源市场中安全性与欺诈检测等长期挑战。", "motivation": "随着点对点交易与去中心化电网的发展，美国能源市场面临安全性与交易真实性等新挑战，亟需构建可靠的新型交易系统。", "method": "整合区块链层与AI层双架构，采用120万条模拟P2P能源交易数据，运用高性能机器学习模型识别欺诈行为。", "result": "系统成功实现基于区块链的安全交易验证，并通过AI模型有效检测分布式市场中的异常交易模式。", "conclusion": "区块链与人工智能的协同应用为去中心化能源市场提供了安全可靠的解决方案，显著提升交易安全性与市场可信度。"}}
{"id": "2506.20120", "categories": ["math.LO", "math.AG", "03C66, 14G40,"], "pdf": "https://arxiv.org/pdf/2506.20120", "abs": "https://arxiv.org/abs/2506.20120", "authors": ["Antoine Chambert-Loir"], "title": "La logique continue des corps globalement valués", "comment": "S\\'eminaire Bourbaki, 77e ann\\'ee, 2024/25. In French", "summary": "The continuous logic of globally valued fields -- A globally valued field is\na field endowed with a family of absolute values that satisfy a product\nformula. Number fields and function fields in one variable give classical and\nfundamental examples; Nevanlinna theory also gives rise to such structures on\nthe field of meromorphic functions on $\\mathbf C$. These globally valued fields\ncan be studied in the context of continuous logic (for which the predicates are\nreal valued), and such a study has been undertaken some 10 years ago by Ben\nYaacov and Hrushovski, thus providing a model-theoretic framework for the\ndiophantine theory of heights. One of the first fundamental results in the\ntehory states the the field of algebraic numbers, with its essentially unique\nstructure of a globally valued field, is existentially closed: every system\ninvolving polynomial equalities and inequalities, as well as strict\ninequalities in heights, possesses a solution in algebraic numbers as soon as\nit possesses some solution in a globally valued extension. The proof, due to\nSzachniewicz, is inspired by the proof proposed by Ben Yaacov and Hrushovski in\nthe case of function fields: the latter used in a crucial way the description\nby Boucksom, Demailly, P\\u aun and Peternell of the cone of mobile curves in a\ncomplex projective variety, the case of number fields relies on recent results\nin Arakelov geometry.", "AI": {"tldr": "Error processing this paper.", "motivation": "Error processing this paper.", "method": "Error processing this paper.", "result": "Error processing this paper.", "conclusion": "Error processing this paper."}}
{"id": "2506.19888", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.19888", "abs": "https://arxiv.org/abs/2506.19888", "authors": ["Huye Chen", "Jingjian Li", "Hao Yu"], "title": "Hamilton Cycles In Vertex-Transitive Graphs of Order 10p", "comment": null, "summary": "After a long term efforts, the Hamiltonian problem of connected\nvertex-transitive graphs of order $pq$ (where $p$ and $q$ are primes) was\nfinally finshed in 2021, see [10]. Fifteen years ago, mathematicians began to\nchallenge this problem for graphs of order $2pq$. Among of them, it was proved\nin 2012 (see [21]) that every connected vertex-transitive graph of order $10p$\n(where $p\\neq7$ is a prime) contains a Hamilton path, with the exception of a\nfamily of graphs which was recently confirmed in [11]. In this paper, a further\nconclusion will be achieved: every connected vertex-transitive graph of order\n$10p$ (where $p$ is a prime) contains a Hamilton cycle, except for the\ntruncation of the Petersen graph.", "AI": {"tldr": "本文证明了除Petersen图的截断外，所有阶数为$10p$（$p$为素数）的连通顶点传递图都包含哈密顿圈。", "motivation": "继阶数为$pq$（$p$和$q$为素数）的连通顶点传递图的哈密顿问题在2021年解决后，数学家们开始挑战阶数为$2pq$的图。本文进一步研究阶数为$10p$的图。", "method": "基于前人关于阶数为$10p$（$p\\neq7$为素数）的连通顶点传递图包含哈密顿路径的研究，本文通过理论证明扩展了这一结论。", "result": "证明了除Petersen图的截断外，所有阶数为$10p$（$p$为素数）的连通顶点传递图都包含哈密顿圈。", "conclusion": "本文完善了阶数为$10p$的连通顶点传递图的哈密顿性问题，为相关图论研究提供了重要结论。"}}
{"id": "2506.20196", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2506.20196", "abs": "https://arxiv.org/abs/2506.20196", "authors": ["José-Miguel Díaz-Bañez", "José-Manuel Higes-López", "Miguel-Angel Pérez-Cutiño", "Tom Todtenhaupt"], "title": "Modeling energy collection with shortest paths in rectangular grids: an efficient algorithm for energy harvesting", "comment": null, "summary": "Parabolic Trough solar fields are among the most prominent methods for\nharnessing solar energy. However, continuous sun-tracking movements leads to\nwear and degradation of the tracking system, raising the question of whether\nthe rotations can be minimized without compromising energy capture. In this\npaper, we address this question by exploring two problems: (1) minimizing the\nnumber of SCA rotational movements while maintaining energy production within a\nspecified range, and (2) maximizing energy capture when the number of rotations\nis limited. Unlike prior work, we develop a general framework that considers\nvariable conditions. By transforming the problem into grid-based path\noptimization, we design polynomial-time algorithms that can operate\nindependently of the weather throughout the day. Through realistic simulations\nand experiments using real-world data, our methods show that rotational\nmovements of solar trackers can be reduced by at least 10% while maintaining\nover 95% energy collection efficiency. These results offer a scalable solution\nfor improving the operational lifespan of the solar field. Furthermore, our\nmethods can be integrated with solar irradiance forecasting, enhancing their\nrobustness and suitability for real-world deployment.", "AI": {"tldr": "本文提出了一种减少槽式太阳能场旋转次数的方法，在保持能量收集效率的同时延长系统寿命。", "motivation": "槽式太阳能场的连续太阳跟踪运动导致跟踪系统磨损和退化，因此需要研究在不影响能量捕获的情况下最小化旋转次数。", "method": "通过将问题转化为基于网格的路径优化，设计了多项式时间算法，该算法不受全天天气变化的影响。", "result": "真实数据模拟和实验表明，太阳能跟踪器的旋转运动可以减少至少10%，同时保持95%以上的能量收集效率。", "conclusion": "该方法为延长太阳能场的使用寿命提供了可扩展的解决方案，并且可以与太阳辐照度预测结合，增强其在实际部署中的鲁棒性。"}}
{"id": "2506.20006", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.20006", "abs": "https://arxiv.org/abs/2506.20006", "authors": ["Saroj Prasad Chhatoi", "Victor Magron"], "title": "Approximating the order 2 quantum Wasserstein distance using the moment-SOS hierarchy", "comment": "13 pages", "summary": "Optimal transport theory has recently been extended to quantum settings,\nwhere the density matrices generalize the probability measures. In this paper,\nwe study the computational aspects of the order 2 quantum Wasserstein distance,\nformulating it as an infinite dimensional linear program in the space of\npositive Borel measures supported on products of two unit spheres. This\nformulation is recognized as an instance of the Generalized Moment Problem,\nwhich enables us to use the moment-sums of squares hierarchy to provide a\nsequence of lower bounds converging to the distance. We illustrate our approach\nwith numerical experiments.", "AI": {"tldr": "本文研究了二阶量子Wasserstein距离的计算问题，将其表述为无限维线性规划，并利用广义矩问题和矩-平方和层次结构提供收敛的下界序列。", "motivation": "最优传输理论近期被扩展到量子领域，其中密度矩阵推广了概率测度。本文旨在解决二阶量子Wasserstein距离的计算问题。", "method": "将量子Wasserstein距离表述为两个单位球面乘积上正Borel测度空间的无限维线性规划，并利用广义矩问题和矩-平方和层次结构进行计算。", "result": "通过数值实验验证了方法的有效性，展示了一序列收敛于真实距离的下界。", "conclusion": "提出的方法为量子最优传输问题的计算提供了有效工具，并通过数值实验验证了其可行性。"}}
{"id": "2506.20005", "categories": ["math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.20005", "abs": "https://arxiv.org/abs/2506.20005", "authors": ["Roberto Vila", "Eduardo Yoshio Nakano"], "title": "On unbiased estimators for functions of the rate parameter of the exponential distribution", "comment": "15 pages", "summary": "In this paper, we explicitly derive unbiased estimators for various functions\nof the rate parameter of the exponential distribution, including powers of the\nrate parameter, the $q$th quantile, the $p$th moment, the survival function,\nthe maximum, minimum, probability density function, mean past lifetime, moment\ngenerating function, and others. It is also noteworthy that this work corrects\na general formula originally proposed by Tate, R. F. (Ann. Math. Statist.,\n30(2): 341-366, 1959) for constructing unbiased estimators of functions of the\nexponential distribution's rate parameter in the absence of a location\nparameter. Additionally, we establish a result demonstrating the asymptotic\nnormality of the proposed unbiased estimators.", "AI": {"tldr": "本文显式推导了指数分布率参数多种函数的无偏估计量，包括率参数的幂、分位数、矩等，并修正了Tate提出的通用公式，同时证明了所提估计量的渐近正态性。", "motivation": "针对指数分布率参数相关函数的无偏估计问题，修正历史公式错误并扩展估计范围，为统计推断提供更可靠的工具。", "method": "通过数学推导显式构造无偏估计量，涵盖率参数的幂、分位数、生存函数等，并采用渐近理论分析估计量性质。", "result": "成功推导出包括$q$分位数、$p$阶矩等在内的无偏估计量，修正了Tate(1959)的通用公式，并证明估计量具有渐近正态性。", "conclusion": "本研究系统解决了指数分布率参数函数的无偏估计问题，理论结果对统计实践具有重要指导意义。"}}
{"id": "2506.19923", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19923", "abs": "https://arxiv.org/abs/2506.19923", "authors": ["Kaito Baba", "Chaoran Liu", "Shuhei Kurita", "Akiyoshi Sannai"], "title": "Prover Agent: An Agent-based Framework for Formal Mathematical Proofs", "comment": "22 pages, 2 figures", "summary": "We present Prover Agent, a novel AI agent for automated theorem proving that\nintegrates large language models (LLMs) with a formal proof assistant, Lean.\nProver Agent coordinates an informal reasoning LLM, a formal prover model, and\nfeedback from Lean while also generating auxiliary lemmas to assist in\ndiscovering the overall proof strategy. It achieves an 86.1% success rate on\nthe MiniF2F benchmark, establishing a new state-of-the-art among methods using\nsmall language models (SLMs) with a much lower sample budget than previous\napproaches. We also present case studies illustrating how these generated\nlemmas contribute to solving challenging problems.", "AI": {"tldr": "提出Prover Agent智能体，通过结合大语言模型与Lean证明助手，实现86.1%的MiniF2F基准成功率，创下小语言模型方法的新纪录。", "motivation": "为解决自动定理证明中形式化与非形式化推理的协同问题，开发能高效生成辅助引理并降低计算成本的智能体。", "method": "整合非形式化推理LLM、形式化证明模型及Lean反馈机制，通过生成辅助引理协同探索整体证明策略。", "result": "在MiniF2F基准测试中达到86.1%成功率，以远低于先前方法的样本预算实现小语言模型领域最优性能。", "conclusion": "案例研究表明生成引理对解决复杂问题具有关键作用，该方法为自动定理证明提供了高效新范式。"}}
{"id": "2506.20456", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.20456", "abs": "https://arxiv.org/abs/2506.20456", "authors": ["L. De Carli", "A. Echezabal", "I. Morell"], "title": "On the Sierpinski triangle and its generalizations", "comment": null, "summary": "By examining arithmetic operations between decimal numbers in a given base m\nwe uncover fractal structures that generalize the Sierpinski triangle", "AI": {"tldr": "通过研究m进制下十进制数间的算术运算，发现了可推广谢尔宾斯基三角形的分形结构。", "motivation": "探索不同进制下算术运算中隐藏的几何模式，扩展分形几何的理论框架。", "method": "分析m进制系统中十进制数之间的加减乘除运算，观察其生成的数字模式。", "result": "发现了具有自相似特性的分形结构，这些结构是谢尔宾斯基三角形的高维推广。", "conclusion": "算术运算在不同数制下会产生复杂的分形模式，这为分形几何提供了新的研究方向。"}}
{"id": "2506.19871", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19871", "abs": "https://arxiv.org/abs/2506.19871", "authors": ["Yining Pang", "Chenghan Li"], "title": "An Attack Method for Medical Insurance Claim Fraud Detection based on Generative Adversarial Network", "comment": "arXiv admin note: text overlap with arXiv:2405.12076 by other authors", "summary": "Insurance fraud detection represents a pivotal advancement in modern\ninsurance service, providing intelligent and digitalized monitoring to enhance\nmanagement and prevent fraud. It is crucial for ensuring the security and\nefficiency of insurance systems. Although AI and machine learning algorithms\nhave demonstrated strong performance in detecting fraudulent claims, the\nabsence of standardized defense mechanisms renders current systems vulnerable\nto emerging adversarial threats. In this paper, we propose a GAN-based approach\nto conduct adversarial attacks on fraud detection systems. Our results indicate\nthat an attacker, without knowledge of the training data or internal model\ndetails, can generate fraudulent cases that are classified as legitimate with a\n99\\% attack success rate (ASR). By subtly modifying real insurance records and\nclaims, adversaries can significantly increase the fraud risk, potentially\nbypassing compromised detection systems. These findings underscore the urgent\nneed to enhance the robustness of insurance fraud detection models against\nadversarial manipulation, thereby ensuring the stability and reliability of\ndifferent insurance systems.", "AI": {"tldr": "本文提出一种基于GAN的方法对保险欺诈检测系统进行对抗攻击，实验显示攻击者无需了解训练数据或模型细节即可生成被误判为合法的欺诈案例，成功率高达99\\%，凸显了增强模型鲁棒性的紧迫性。", "motivation": "保险欺诈检测对保障系统安全至关重要，但现有AI模型缺乏标准化防御机制，易受对抗性威胁。本文旨在揭示这一漏洞，推动检测系统的稳健性提升。", "method": "采用生成对抗网络（GAN）生成对抗样本，通过微调真实保险记录和索赔数据，构造可欺骗检测系统的欺诈案例。", "result": "攻击者在未知训练数据及模型细节的情况下，实现99\\%的攻击成功率（ASR），证明当前系统易被对抗性操作绕过。", "conclusion": "研究结果警示保险欺诈检测模型亟需强化对抗鲁棒性，以确保保险系统的稳定性和可靠性。"}}
{"id": "2506.20620", "categories": ["math.LO", "03B30 (Primary), 03D80 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.20620", "abs": "https://arxiv.org/abs/2506.20620", "authors": ["Gavin Dooley"], "title": "Iterated jump noncomputability and compactness", "comment": "14 pages, 2 figures. Feedback welcome", "summary": "We use reverse mathematics to analyze \"iterated jump\" versions of the\nfollowing four principles: the atomic model theorem with subenumerable types\n(AST), the diagonally noncomputable principle (DNR), weak weak K\\H{o}nig's\nlemma (WWKL), and weak K\\H{o}nig's lemma (WKL). The logical relationships\nbetween these principles are summarized in Figure 1 and include, among other\nthings, an infinite chain and an infinite antichain, the latter of which\nrepresents a strong form of non-linearity in terms of provability strength\namong \"natural\" combinatorial principles.", "AI": {"tldr": "使用逆向数学分析四种原则的'迭代跳跃'版本，揭示了它们之间的逻辑关系，包括无限链和无限反链，展示了自然组合原则在可证明性强度上的非线性特征。", "motivation": "研究'迭代跳跃'版本的组合原则（AST、DNR、WWKL、WKL），以理解它们在逆向数学框架下的逻辑关系和结构复杂性。", "method": "采用逆向数学方法，分析四种原则的'迭代跳跃'版本，并通过逻辑关系图（图1）总结它们的相互依赖性。", "result": "发现了无限链和无限反链的存在，后者特别展示了自然组合原则在可证明性强度上的强非线性特征。", "conclusion": "研究揭示了'迭代跳跃'版本组合原则之间的复杂逻辑结构，为逆向数学中的非线性现象提供了新的例证。"}}
{"id": "2506.20003", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.20003", "abs": "https://arxiv.org/abs/2506.20003", "authors": ["Gabriela Araujo-Pardo", "Lydia Mirabel Mendoza-Cadena"], "title": "New upper bounds on the order of mixed cages of girth 6", "comment": "arXiv admin note: text overlap with arXiv:2503.17152", "summary": "A $[z,r;g]$-mixed cage is a mixed graph of minimum order such that each\nvertex has $z$ in-arcs, $z$ out-arcs, $r$ edges, and it has girth $g$, and the\nminimum order for $[z,r;g]$-mixed graphs is denoted by $n[z,r;g]$. In this\npaper, we present an infinite family of mixed graphs with girth $6$, that\nimproves, in some cases, the families that we give in G. Araujo-Pardo and L.\nMendoza-Cadena. \\textit{On Mixed Cages of girth 6}, arXiv:2401.14768v2. In\nparticular, if $q$ is an even prime power we construct a family of graphs that\nsatisfies $n[\\frac{q}{4},q;6]\\leq 4q^2-4$, and if $q$ is an odd prime power,\nand $\\frac{q-3}{2}$ is odd then our family satisfies that\n$n[\\frac{q-1}{4},q;6]\\leq 4q^2-4$, otherwise $n[\\frac{q-3}{4},q;6]\\leq 4q^2-4$.", "AI": {"tldr": "本文提出了一种新的混合图无限族，其围长为6，在某些情况下改进了现有结果。特别地，对于偶数素数幂q，构造的图族满足$n[\\frac{q}{4},q;6]\\leq 4q^2-4$；对于奇数素数幂q，根据条件不同，分别满足$n[\\frac{q-1}{4},q;6]\\leq 4q^2-4$或$n[\\frac{q-3}{4},q;6]\\leq 4q^2-4$。", "motivation": "研究混合笼图的最小阶数问题，特别是围长为6的情况，旨在改进现有结果并扩展混合图族的构造方法。", "method": "通过构造无限族的混合图，利用素数幂的性质，对不同情况的q进行分类讨论，并给出相应的阶数上界。", "result": "对于偶数素数幂q，证明了$n[\\frac{q}{4},q;6]\\leq 4q^2-4$；对于奇数素数幂q，根据$\\frac{q-3}{2}$的奇偶性，分别证明了$n[\\frac{q-1}{4},q;6]\\leq 4q^2-4$或$n[\\frac{q-3}{4},q;6]\\leq 4q^2-4$。", "conclusion": "本文提出的混合图族在某些情况下改进了现有结果，为混合笼图的研究提供了新的构造方法和理论支持。"}}
{"id": "2506.20172", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.20172", "abs": "https://arxiv.org/abs/2506.20172", "authors": ["Jeffrey Christiansen", "Kate Smith-Miles"], "title": "Instance Space Analysis for the Quadratic Assignment Problem", "comment": "Number of pages: 46 (35 pages in main body, 11 pages in appendices);\n  Number of figures: 15; For associated data, see\n  https://matilda.unimelb.edu.au/matilda/problems/opt/qap#qap", "summary": "For any optimisation problem where diverse algorithmic approaches are\navailable, the task of predicting algorithm performance and selecting the\nalgorithm most likely to perform well on a given instance holds great practical\ninterest. However, if our test instances do not adequately represent the\npotential problem space, we may be misled about the strengths and weaknesses of\nan algorithm. In this paper we consider algorithm prediction and selection for\nthe Quadratic Assignment Problem (QAP). We identify and eliminate superficial\ndifferences between QAP instances which do not affect problem difficulty and\npropose several new features for quantifying the characteristics of a\nparticular instance. We then apply Instance Space Analysis to compare the\nperformance of evolutionary and ant colony-based algorithms. Using this\nanalysis, we identify limitations of the existing instance libraries and\ngenerators which obscure the true performance profile of these algorithms.\nFinally, we propose new instance classes which expand the instance space and\nsupport new insights into the properties of the problem and algorithms.", "AI": {"tldr": "本文针对二次分配问题(QAP)，提出消除实例间非本质差异的方法，设计新特征量化实例特性，并通过实例空间分析比较进化算法与蚁群算法性能，揭示现有实例库的局限性，提出扩展实例空间的新类别。", "motivation": "在优化问题中，算法性能预测与选择具有重要实践意义，但测试实例若不能充分代表问题空间，可能导致对算法优缺点的误判。本文旨在解决QAP领域的这一问题。", "method": "1) 识别并消除QAP实例间不影响问题难度的表面差异 2) 提出多个新特征量化实例特性 3) 应用实例空间分析法比较进化算法与蚁群算法 4) 分析现有实例库与生成器的局限性", "result": "研究发现现有实例库存在明显局限，掩盖了算法的真实性能特征。通过提出的新实例类别，扩展了实例空间并获得了对问题及算法特性的新认知。", "conclusion": "通过系统化分析QAP实例空间，本研究不仅改进了算法性能评估方法，还提出了更具代表性的实例生成方案，为未来算法比较研究提供了新范式。"}}
{"id": "2506.20124", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.20124", "abs": "https://arxiv.org/abs/2506.20124", "authors": ["Hien Duy Nguyen", "TrungTin Nguyen"], "title": "Modifications of the BIC for order selection in finite mixture models", "comment": null, "summary": "Finite mixture models are ubiquitous tools in modern statistical modeling,\nand a frequently encountered problem that arises in their implementation is the\nchoice of model order. In Kerebin (2000, Sankhya: The Indian Journal of\nStatistics, Series A, 62, pp. 49-66), the frequently used Bayesian information\ncriterion (BIC) was proved to provide consistent order estimation in the\nmixture model setting. However, the result requires particularly strong model\nregularity, including the existence of higher moments and higher derivatives of\nthe component density function. We introduce the $\\nu$-BIC and $\\epsilon$-BIC,\nwhich modifies the BIC by weighting the penalty by a negligibly small\nlogarithmic factors that are immaterial in practice. We prove that the minor\nmodification enables consistency guarantees under weaker conditions,\nparticularly without differentiability and with minimal moment assumptions. We\ndemonstrate how our theory apply to obtaining order selection consistency for\nGaussian mixtures, non-differentiable Laplace mixtures, and mixtures of\nregression models.", "AI": {"tldr": "本文提出了改进的$\\nu$-BIC和$\\epsilon$-BIC准则，通过引入对数加权因子，在更弱的模型正则性条件下实现了混合模型阶数选择的一致性。", "motivation": "传统BIC准则在混合模型阶数选择中需要强正则性假设（如高阶矩和密度函数可导性），限制了其应用范围。研究旨在放宽这些约束条件。", "method": "通过给BIC惩罚项添加极小对数权重因子（$\\nu$-BIC和$\\epsilon$-BIC），在保持实用效果的同时降低理论要求。", "result": "改进后的准则在无需可导性和最小矩假设下仍能保证一致性，适用于高斯混合、拉普拉斯混合及回归混合模型。", "conclusion": "微调后的BIC显著扩展了混合模型阶数选择的适用场景，为复杂数据建模提供了更灵活的理论工具。"}}
{"id": "2506.19977", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19977", "abs": "https://arxiv.org/abs/2506.19977", "authors": ["Deng Pan", "Keerthiram Murugesan", "Nuno Moniz", "Nitesh Chawla"], "title": "Context Attribution with Multi-Armed Bandit Optimization", "comment": null, "summary": "Understanding which parts of the retrieved context contribute to a large\nlanguage model's generated answer is essential for building interpretable and\ntrustworthy generative QA systems. We propose a novel framework that formulates\ncontext attribution as a combinatorial multi-armed bandit (CMAB) problem. Each\ncontext segment is treated as a bandit arm, and we employ Combinatorial\nThompson Sampling (CTS) to efficiently explore the exponentially large space of\ncontext subsets under a limited query budget. Our method defines a reward\nfunction based on normalized token likelihoods, capturing how well a subset of\nsegments supports the original model response. Unlike traditional\nperturbation-based attribution methods such as SHAP, which sample subsets\nuniformly and incur high computational costs, our approach adaptively balances\nexploration and exploitation by leveraging posterior estimates of segment\nrelevance. This leads to substantially improved query efficiency while\nmaintaining high attribution fidelity. Extensive experiments on diverse\ndatasets and LLMs demonstrate that our method achieves competitive attribution\nquality with fewer model queries.", "AI": {"tldr": "提出一种基于组合多臂老虎机(CMAB)的上下文归因框架，通过组合汤普森采样(CTS)高效探索上下文子集，显著提升查询效率并保持高归因保真度。", "motivation": "理解检索上下文中哪些部分影响大语言模型的生成答案，对构建可解释且可信的生成式QA系统至关重要。传统扰动归因方法(如SHAP)计算成本高且采样效率低。", "method": "将上下文片段视为老虎机臂，采用组合汤普森采样(CTS)在有限查询预算下探索指数级上下文子集空间。基于归一化token似然的奖励函数评估子集对原始响应的支持程度。", "result": "在多样化数据集和LLMs上的实验表明，该方法以更少模型查询达到竞争性归因质量，计算效率显著优于传统扰动方法。", "conclusion": "该框架通过自适应平衡探索与利用，为生成式QA系统提供高效可扩展的归因方案，增强了模型决策的可解释性。"}}
{"id": "2506.20562", "categories": ["math.NT", "11G07, 11F80"], "pdf": "https://arxiv.org/pdf/2506.20562", "abs": "https://arxiv.org/abs/2506.20562", "authors": ["Nirvana Coppola"], "title": "Wild Galois representations: elliptic curves with wild cyclic reduction", "comment": "Based on my PhD thesis. Comments are welcome!", "summary": "In 1990, Kraus classified all possible inertia images of the $\\ell$-adic\nGalois representation attached to an elliptic curve over a non-archimedean\nlocal field. In previous work, the author computed explicitly the Galois\nrepresentation of elliptic curves having non-abelian inertia image, a\nphenomenon which only occurs when the residue characteristic of the field of\ndefinition is $2$ or $3$ and the curve attains good reduction over some\nnon-abelian ramified extension. In this work, the computation of the Galois\nrepresentation in all the remaining wild cases, i.e. when the residue\ncharacteristic is $p=2$ or $3$ and the curve attains good reduction over an\nextension whose ramification degree is divisible by $p$ (without assuming the\ncondition on the image of inertia being non-abelian), is completed. This is\nbased on Chapter V of the author's PhD thesis.", "AI": {"tldr": "本文完成了剩余所有野性情况（即剩余特征为$p=2$或$3$时）下椭圆曲线$\\ell$-adic Galois表示的计算，扩展了Kraus 1990年的分类工作。", "motivation": "Kraus在1990年分类了非阿基米德局部域上椭圆曲线的$\\ell$-adic Galois表示的所有可能惯性像。此前作者已计算了具有非阿贝尔惯性像的椭圆曲线的Galois表示，但剩余野性情况尚未完全解决。", "method": "基于作者博士论文第五章的方法，本文重点处理剩余特征$p=2$或$3$时，椭圆曲线在可分度被$p$整除的扩张上获得良好约化的Galois表示计算问题。", "result": "完整计算了剩余特征为$p=2$或$3$时，椭圆曲线在野性扩张（不要求惯性像非阿贝尔）下的Galois表示，填补了此前工作的空白。", "conclusion": "该研究完善了局部域上椭圆曲线Galois表示的理论框架，特别解决了$p=2,3$的野性情况，为后续相关数论问题提供了工具。"}}
{"id": "2506.19874", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19874", "abs": "https://arxiv.org/abs/2506.19874", "authors": ["Xing Yang", "Bingtao Wang", "Yuhao Wang", "Zimo Ji", "Terry Jingchen Zhang", "Wenyuan Jiang"], "title": "Towards Provable (In)Secure Model Weight Release Schemes", "comment": "8 pages, 2 figures", "summary": "Recent secure weight release schemes claim to enable open-source model\ndistribution while protecting model ownership and preventing misuse. However,\nthese approaches lack rigorous security foundations and provide only informal\nsecurity guarantees. Inspired by established works in cryptography, we\nformalize the security of weight release schemes by introducing several\nconcrete security definitions. We then demonstrate our definition's utility\nthrough a case study of TaylorMLP, a prominent secure weight release scheme.\nOur analysis reveals vulnerabilities that allow parameter extraction thus\nshowing that TaylorMLP fails to achieve its informal security goals. We hope\nthis work will advocate for rigorous research at the intersection of machine\nlearning and security communities and provide a blueprint for how future weight\nrelease schemes should be designed and evaluated.", "AI": {"tldr": "本文通过引入严格的安全定义，对现有安全权重发布方案进行形式化分析，并以TaylorMLP为例揭示其未能实现安全目标的漏洞。", "motivation": "当前安全权重发布方案缺乏严格的安全理论基础，仅提供非正式的安全保证，需要建立形式化的安全评估框架。", "method": "借鉴密码学成果提出多项具体安全定义，并以主流方案TaylorMLP为案例进行安全性分析。", "result": "分析发现TaylorMLP存在参数提取漏洞，证明其无法达成宣称的非正式安全目标。", "conclusion": "研究呼吁机器学习与安全领域的交叉研究需采用严格方法，并为未来权重发布方案的设计评估提供范式。"}}
{"id": "2506.20038", "categories": ["math.CO", "math.AC", "math.RT", "13F60 (Primary) 05E99, 13A50, 14M15, 15A72, 15A75 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.20038", "abs": "https://arxiv.org/abs/2506.20038", "authors": ["Zenan Fu"], "title": "Cluster structures in mixed Grassmanianns", "comment": "113 pages, 54 figures", "summary": "Generalizing the results by Fomin-Pylyavskyy and Carde, we construct a family\nof natural cluster structures in the coordinate ring of a mixed Grassmannian,\nthe configuration space of tuples of several vectors and covectors in a\nfinite-dimensional complex vector space. We describe and explore these cluster\nstructures using the machinery of weaves introduced by Casals and Zaslow.", "AI": {"tldr": "本文推广了Fomin-Pylyavskyy和Carde的结果，构建了混合格拉斯曼量坐标环中的一族自然簇结构，并利用Casals和Zaslow引入的编织工具进行描述和探索。", "motivation": "研究混合格拉斯曼量（包含向量和余向量的多元组构型空间）的坐标环中的簇结构，以推广前人工作并深化对该空间代数结构的理解。", "method": "通过编织（weaves）这一由Casals和Zaslow提出的工具，系统地构造和分析混合格拉斯曼量中的簇结构。", "result": "成功构建了一族自然的簇结构，并详细描述了这些结构在混合格拉斯曼量坐标环中的表现和性质。", "conclusion": "该研究不仅推广了现有理论，还为混合格拉斯曼量的簇代数结构提供了新的研究框架和工具。"}}
{"id": "2506.20191", "categories": ["math.OC", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2506.20191", "abs": "https://arxiv.org/abs/2506.20191", "authors": ["Michael Lindsey", "Yunpeng Shi"], "title": "Fast entropy-regularized SDP relaxations for permutation synchronization", "comment": null, "summary": "We introduce fast randomized algorithms for solving semidefinite programming\n(SDP) relaxations of the partial permutation synchronization (PPS) problem, a\ncore task in multi-image matching with significant relevance to 3D\nreconstruction. Our methods build on recent advances in entropy-regularized\nsemidefinite programming and are tailored to the unique structure of PPS, in\nwhich the unknowns are partial permutation matrices aligning sparse and noisy\npairwise correspondences across images. We prove that entropy regularization\nresolves optimizer non-uniqueness in standard relaxations, and we develop a\nrandomized solver with nearly optimal scaling in the number of observed\ncorrespondences. We also develop several rounding procedures for recovering\ncombinatorial solutions from the implicitly represented primal solution\nvariable, maintaining cycle consistency if desired without harming\ncomputational scaling. We demonstrate that our approach achieves\nstate-of-the-art performance on synthetic and real-world datasets in terms of\nspeed and accuracy. Our results highlight PPS as a paradigmatic setting in\nwhich entropy-regularized SDP admits both theoretical and practical advantages\nover traditional low-rank or spectral techniques.", "AI": {"tldr": "本文提出了一种快速随机算法，用于解决部分排列同步（PPS）问题的半定规划（SDP）松弛，该方法在熵正则化的基础上优化了计算效率和解的唯一性。", "motivation": "部分排列同步（PPS）是多图像匹配中的核心任务，对3D重建具有重要意义。传统方法在解的唯一性和计算效率上存在不足，因此需要一种更高效且理论完备的解决方案。", "method": "基于熵正则化的半定规划（SDP）方法，针对PPS问题的特殊结构设计随机化求解器，并开发了从隐式表示的原始解变量中恢复组合解的舍入程序。", "result": "实验表明，该方法在合成和真实数据集上均实现了速度和精度的最优表现，优于传统的低秩或谱技术。", "conclusion": "熵正则化的SDP在PPS问题中展现出理论和实践上的双重优势，为多图像匹配提供了高效且可靠的解决方案。"}}
{"id": "2506.20185", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.20185", "abs": "https://arxiv.org/abs/2506.20185", "authors": ["Jason Beh", "Jérôme Morio", "Florian Simatos", "Simon Weissmann"], "title": "Affine invariant interacting Langevin dynamics in Markov chain importance sampling for rare event estimation", "comment": null, "summary": "This work considers the framework of Markov chain importance sampling~(MCIS),\nin which one employs a Markov chain Monte Carlo~(MCMC) scheme to sample\nparticles approaching the optimal distribution for importance sampling, prior\nto estimating the quantity of interest through importance sampling. In rare\nevent estimation, the optimal distribution admits a non-differentiable\nlog-density, thus gradient-based MCMC can only target a smooth approximation of\nthe optimal density. We propose a new gradient-based MCIS scheme for rare event\nestimation, called affine invariant interacting Langevin dynamics for\nimportance sampling~(ALDI-IS), in which the affine invariant interacting\nLangevin dynamics~(ALDI) is used to sample particles according to the smoothed\nzero-variance density. We establish a non-asymptotic error bound when\nimportance sampling is used in conjunction with samples independently and\nidentically distributed according to the smoothed optiaml density to estimate a\nrare event probability, and an error bound on the sampling bias when a\nsimplified version of ALDI, the unadjusted Langevin algorithm, is used to\nsample from the smoothed optimal density. We show that the smoothing parameter\nof the optimal density has a strong influence and exhibits a trade-off between\na low importance sampling error and the ease of sampling using ALDI. We perform\na numerical study of ALDI-IS and illustrate this trade-off phenomenon on\nstandard rare event estimation test cases.", "AI": {"tldr": "本文提出了一种名为ALDI-IS的基于梯度的马尔可夫链重要性采样方法，用于稀有事件估计，通过平滑最优密度解决了非可微性问题，并分析了平滑参数对采样误差与采样难度的影响。", "motivation": "在稀有事件估计中，最优分布的对数密度非可微，导致基于梯度的MCMC方法只能逼近平滑后的最优密度，因此需要开发新的采样方案以平衡采样精度与效率。", "method": "提出ALDI-IS方法，利用仿射不变交互Langevin动力学（ALDI）从平滑后的零方差密度中采样，并分析了独立同分布采样及简化版ALDI（非调整Langevin算法）的误差界限。", "result": "研究表明，平滑参数对重要性采样误差和ALDI采样效率具有显著影响，二者之间存在权衡关系，数值实验验证了这一现象。", "conclusion": "ALDI-IS为稀有事件估计提供了一种有效框架，平滑参数的选择需在低采样误差与易采样性之间取得平衡，标准测试案例验证了其可行性。"}}
{"id": "2506.20008", "categories": ["cs.AI", "cs.PL", "cs.SE", "68T50, 81P68, 68T07, 68T20", "I.2.7; I.2.2"], "pdf": "https://arxiv.org/pdf/2506.20008", "abs": "https://arxiv.org/abs/2506.20008", "authors": ["Abdul Basit", "Minghao Shao", "Haider Asif", "Nouhaila Innan", "Muhammad Kashif", "Alberto Marchisio", "Muhammad Shafique"], "title": "QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges", "comment": "8 pages, 6 figures, 3 tables, submitted to QAI 2025", "summary": "Recent advances in Large Language Models (LLMs) have demonstrated strong\npotential in code generation, yet their effectiveness in quantum computing\nremains underexplored. This paper benchmarks LLMs for PennyLane-based quantum\ncode generation using real-world challenges from the Quantum Hackathon (QHack).\nWe introduce QHackBench, a novel benchmark dataset derived from QHack\ncompetitions, and evaluate model performance under vanilla prompting and\nRetrieval-Augmented Generation (RAG). Our structured evaluation framework\nassesses functional correctness, syntactic validity, and execution success\nacross varying challenge difficulties. Results indicate that RAG-enhanced\nmodels, supplemented with an augmented PennyLane dataset, approximately\ngenerate similar results as the standard prompting, particularly in complex\nquantum algorithms. Additionally, we introduce a multi-agent evaluation\npipeline that iteratively refines incorrect solutions, further enhancing\nexecution success rates. To foster further research, we commit to publicly\nreleasing QHackBench, along with our evaluation framework and experimental\nresults, enabling continued advancements in AI-assisted quantum programming.", "AI": {"tldr": "本文评估了大语言模型（LLMs）在基于PennyLane的量子代码生成中的表现，引入QHackBench基准数据集，并比较了标准提示与检索增强生成（RAG）的效果。结果表明RAG增强模型在复杂量子算法中表现接近标准提示，同时提出了多智能体评估流程以提升执行成功率。", "motivation": "尽管大语言模型在代码生成方面展现出强大潜力，但其在量子计算领域的应用尚未充分探索。本文旨在填补这一空白，通过实际量子编程挑战评估LLMs的性能。", "method": "研究使用QHack竞赛的真实挑战构建了QHackBench数据集，采用标准提示和RAG两种方法评估模型。评估框架从功能正确性、语法有效性和执行成功率三个维度衡量模型表现，并引入多智能体流程迭代修正错误解决方案。", "result": "实验结果显示，在增强PennyLane数据集的支持下，RAG增强模型的表现与标准提示相近，尤其在复杂量子算法中。多智能体评估流程进一步提高了代码执行的成功率。", "conclusion": "本研究为AI辅助量子编程提供了新的基准数据集和评估框架，公开了QHackBench及相关资源以促进后续研究。结果表明LLMs在量子代码生成中具有潜力，而RAG和多智能体方法能有效提升性能。"}}
{"id": "2506.20581", "categories": ["math.NT", "11T55 (Primary) 11L07, 11P55 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.20581", "abs": "https://arxiv.org/abs/2506.20581", "authors": ["Ben Doyle"], "title": "On the Moments of Exponential Sums over r-Free Polynomials", "comment": "20 pages", "summary": "Let $\\mathbb{F}_q[t]$ denote the ring of polynomials over the finite field\n$\\mathbb{F}_q$. Building off of techniques of Balog and Ruzsa and of Keil in\nthe integer setting, we determine the precise order of magnitude of $k$th\nmoments of exponential sums over $r$-free polynomials in $\\mathbb{F}_q[t]$ for\nall $k>0$. In the supercritical case $k>1+1/r$, we acquire an asymptotic\nformula using a function field analogue of the Hardy-Littlewood circle method.", "AI": {"tldr": "本文研究了有限域$\\mathbb{F}_q[t]$上$r$-自由多项式的指数和的$k$阶矩的精确量级，并在超临界情况$k>1+1/r$下，利用函数域版本的Hardy-Littlewood圆法得到了渐近公式。", "motivation": "研究有限域$\\mathbb{F}_q[t]$上$r$-自由多项式的指数和的矩问题，扩展了Balog、Ruzsa和Keil在整数情况下的技术，旨在确定其精确量级。", "method": "采用了函数域版本的Hardy-Littlewood圆法，结合Balog、Ruzsa和Keil在整数情况下的技术，对$k$阶矩进行分析。", "result": "对于所有$k>0$，确定了$r$-自由多项式指数和的$k$阶矩的精确量级；在超临界情况$k>1+1/r$下，得到了渐近公式。", "conclusion": "本文成功地将整数情况下的技术推广到函数域，为有限域上$r$-自由多项式的指数和矩问题提供了完整的解决方案。"}}
{"id": "2506.19877", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19877", "abs": "https://arxiv.org/abs/2506.19877", "authors": ["Zhaoyang Xu", "Yunbo Liu"], "title": "Robust Anomaly Detection in Network Traffic: Evaluating Machine Learning Models on CICIDS2017", "comment": "submitted to IEEE CNS 2025", "summary": "Identifying suitable machine learning paradigms for intrusion detection\nremains critical for building effective and generalizable security solutions.\nIn this study, we present a controlled comparison of four representative models\n- Multi-Layer Perceptron (MLP), 1D Convolutional Neural Network (CNN),\nOne-Class Support Vector Machine (OCSVM) and Local Outlier Factor (LOF) - on\nthe CICIDS2017 dataset under two scenarios: detecting known attack types and\ngeneralizing to previously unseen threats. Our results show that supervised MLP\nand CNN achieve near-perfect accuracy on familiar attacks but suffer drastic\nrecall drops on novel attacks. Unsupervised LOF attains moderate overall\naccuracy and high recall on unknown threats at the cost of elevated false\nalarms, while boundary-based OCSVM balances precision and recall best,\ndemonstrating robust detection across both scenarios. These findings offer\npractical guidance for selecting IDS models in dynamic network environments.", "AI": {"tldr": "本文比较了四种机器学习模型在入侵检测中的表现，发现监督学习模型在已知攻击上表现优异但在未知攻击上表现不佳，而无监督模型在未知攻击上更具鲁棒性。", "motivation": "寻找适合入侵检测的机器学习范式对于构建有效且泛化的安全解决方案至关重要。", "method": "研究在CICIDS2017数据集上对比了四种模型：多层感知机(MLP)、一维卷积神经网络(CNN)、单类支持向量机(OCSVM)和局部离群因子(LOF)，分别在已知攻击和未知攻击场景下的表现。", "result": "监督学习的MLP和CNN在已知攻击上准确率接近完美，但在未知攻击上召回率大幅下降；无监督的LOF在未知攻击上召回率高但误报率也高；边界检测的OCSVM在精度和召回率上表现最平衡。", "conclusion": "研究结果为动态网络环境中选择入侵检测系统模型提供了实用指导，OCSVM在两种场景下均表现出稳健的检测能力。"}}
{"id": "2506.20072", "categories": ["math.CO", "05C30"], "pdf": "https://arxiv.org/pdf/2506.20072", "abs": "https://arxiv.org/abs/2506.20072", "authors": ["Aaron Abrams", "Rod Canfield", "Andrew Granville"], "title": "The number of possibilities for random dating", "comment": "This is the fifth of eleven old articles being uploaded to arxiv\n  after publication", "summary": "Let $G$ be a regular graph and $H$ a subgraph on the same vertex set. We give\nsurprisingly compact formulas for the number of copies of $H$ one expects to\nfind in a random subgraph of $G$.", "AI": {"tldr": "本文提出了在正则图$G$及其同顶点子图$H$中，随机子图内$H$出现次数的简洁计算公式。", "motivation": "研究正则图与其子图之间的统计关系，为图论中的随机子图计数问题提供理论工具。", "method": "通过建立正则图$G$与子图$H$的数学关系，推导随机子图内$H$出现次数的概率公式。", "result": "获得了形式异常简洁的$H$出现次数期望值计算公式，适用于任意正则图结构。", "conclusion": "该公式为分析正则图随机子图模式提供了高效的计算框架，具有广泛的理论应用价值。"}}
{"id": "2506.20216", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.20216", "abs": "https://arxiv.org/abs/2506.20216", "authors": ["Ugo Rosolia", "Marc Bataillou Almagro", "George Iosifidis", "Martin Gross", "Georgios Paschos"], "title": "Speed-Aware Network Design: A Parametric Optimization Approach", "comment": null, "summary": "Network design problems have been studied from the 1950s, as they can be used\nin a wide range of real-world applications, e.g., design of communication and\ntransportation networks. In classical network design problems, the objective is\nto minimize the cost of routing the demand flow through a graph. In this paper,\nwe introduce a generalized version of such a problem, where the objective is to\ntradeoff routing costs and delivery speed; we introduce the concept of\nspeed-coverage, which is defined as the number of unique items that can be sent\nto destinations in less than 1-day. Speed-coverage is a function of both the\nnetwork design and the inventory stored at origin nodes, e.g., an item can be\ndelivered in 1-day if it is in-stock at an origin that can reach a destination\nwithin 24 hours. Modeling inventory is inherently complex, since inventory\ncoverage is described by an integer function with a large number of points\n(exponential to the number of origin sites), each one to be evaluated using\nhistorical data. To bypass this complexity, we first leverage a parametric\noptimization approach, which converts the non-linear joint routing and\nspeed-coverage optimization problem into an equivalent mixed-integer linear\nprogram. Then, we propose a sampling strategy to avoid evaluating all the\npoints of the speed-coverage function. The proposed method is evaluated on a\nseries of numerical tests with representative scenarios and network sizes. We\nshow that when considering the routing costs and monetary gains resulting from\nspeed-coverage, our approach outperforms the baseline by 8.36% on average.", "AI": {"tldr": "本文提出了一种广义网络设计问题，通过引入速度覆盖概念，权衡路由成本与交付速度，并采用参数优化和采样策略解决库存建模的复杂性。", "motivation": "经典网络设计问题仅关注最小化路由成本，而实际应用中需同时考虑交付速度。速度覆盖（24小时内可送达的唯一物品数量）的引入填补了这一空白。", "method": "1. 将非线性联合路由与速度覆盖优化转化为混合整数线性规划；2. 提出采样策略避免评估速度覆盖函数的所有点。", "result": "在代表性场景和网络规模的数值测试中，该方法在综合考虑路由成本与速度覆盖收益时，平均优于基线8.36%。", "conclusion": "通过参数化建模和高效采样，该方法有效解决了库存-路由联合优化问题，为网络设计提供了新的权衡维度。"}}
{"id": "2506.20239", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.20239", "abs": "https://arxiv.org/abs/2506.20239", "authors": ["Guillaume Maillard"], "title": "A model-based approach to density estimation in sup-norm", "comment": null, "summary": "We define a general method for finding a quasi-best approximant in sup-norm\nto a target density belonging to a given model, based on independent samples\ndrawn from distributions which average to the target (which does not\nnecessarily belong to the model). We also provide a general method for\nselecting among a countable family of such models. These estimators satisfy\noracle inequalities in the general setting. The quality of the bounds depends\non the volume of sets on which $|p-q|$ is close to its maximum, where $p,q$\nbelong to the model (or possibly to two different models, in the case of model\nselection). This leads to optimal results in a number of settings, including\npiecewise polynomials on a given partition and anisotropic smoothness classes.\nParticularly interesting is the case of the single index model with fixed\nsmoothness $\\beta$, where we recover the one-dimensional rate: this was an open\nproblem.", "AI": {"tldr": "提出了一种基于独立样本寻找目标密度准最佳逼近的通用方法，并解决了单指标模型中固定光滑度$\\beta$情况下的开放性问题。", "motivation": "研究如何在给定模型中，基于独立样本找到目标密度的准最佳逼近，即使目标密度本身不属于该模型。", "method": "定义了一种通用方法，用于在给定模型中找到目标密度的准最佳逼近，并提供了在可数模型族中进行选择的方法。这些估计器满足一般情况下的oracle不等式。", "result": "方法的性能取决于$|p-q|$接近其最大值的集合体积，其中$p,q$属于模型（或在模型选择情况下属于两个不同模型）。在多种设置下（如给定分割上的分段多项式和各向异性光滑类）得到了最优结果。特别是在固定光滑度$\\beta$的单指标模型中，恢复了一维速率，解决了开放性问题。", "conclusion": "所提出的方法在多种设置下表现优异，特别是在单指标模型中解决了开放性问题，为密度逼近和模型选择提供了有效的通用框架。"}}
{"id": "2506.20009", "categories": ["cs.AI", "cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2506.20009", "abs": "https://arxiv.org/abs/2506.20009", "authors": ["Konstantinos Vrettos", "Michail E. Klontzas"], "title": "Accurate and Energy Efficient: Local Retrieval-Augmented Generation Models Outperform Commercial Large Language Models in Medical Tasks", "comment": "18 pages, 3 Figures", "summary": "Background The increasing adoption of Artificial Intelligence (AI) in\nhealthcare has sparked growing concerns about its environmental and ethical\nimplications. Commercial Large Language Models (LLMs), such as ChatGPT and\nDeepSeek, require substantial resources, while the utilization of these systems\nfor medical purposes raises critical issues regarding patient privacy and\nsafety. Methods We developed a customizable Retrieval-Augmented Generation\n(RAG) framework for medical tasks, which monitors its energy usage and CO2\nemissions. This system was then used to create RAGs based on various\nopen-source LLMs. The tested models included both general purpose models like\nllama3.1:8b and medgemma-4b-it, which is medical-domain specific. The best RAGs\nperformance and energy consumption was compared to DeepSeekV3-R1 and OpenAIs\no4-mini model. A dataset of medical questions was used for the evaluation.\nResults Custom RAG models outperformed commercial models in accuracy and energy\nconsumption. The RAG model built on llama3.1:8B achieved the highest accuracy\n(58.5%) and was significantly better than other models, including o4-mini and\nDeepSeekV3-R1. The llama3.1-RAG also exhibited the lowest energy consumption\nand CO2 footprint among all models, with a Performance per kWh of 0.52 and a\ntotal CO2 emission of 473g. Compared to o4-mini, the llama3.1-RAG achieved 2.7x\ntimes more accuracy points per kWh and 172% less electricity usage while\nmaintaining higher accuracy. Conclusion Our study demonstrates that local LLMs\ncan be leveraged to develop RAGs that outperform commercial, online LLMs in\nmedical tasks, while having a smaller environmental impact. Our modular\nframework promotes sustainable AI development, reducing electricity usage and\naligning with the UNs Sustainable Development Goals.", "AI": {"tldr": "研究表明，基于开源LLM的自定义RAG框架在医疗任务中表现优于商业模型，同时显著降低能耗和碳排放。", "motivation": "人工智能在医疗领域的广泛应用引发了对环境与伦理问题的担忧，特别是商业大语言模型的高资源消耗及患者隐私安全问题。", "method": "开发了可监控能耗的RAG框架，测试了包括llama3.1:8b和medgemma-4b-it在内的开源模型，并与DeepSeekV3-R1等商业模型进行对比评估。", "result": "llama3.1-RAG模型以58.5%准确率优于所有对比模型，单位能耗性能达0.52，总碳排放仅473克，比o4-mini节能172%且准确率更高。", "conclusion": "本地化LLM开发的RAG系统在医疗领域兼具性能与环保优势，模块化框架符合联合国可持续发展目标。"}}
{"id": "2506.19881", "categories": ["cs.CR", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19881", "abs": "https://arxiv.org/abs/2506.19881", "authors": ["Aloni Cohen"], "title": "Blameless Users in a Clean Room: Defining Copyright Protection for Generative Models", "comment": null, "summary": "Are there any conditions under which a generative model's outputs are\nguaranteed not to infringe the copyrights of its training data? This is the\nquestion of \"provable copyright protection\" first posed by Vyas, Kakade, and\nBarak (ICML 2023). They define near access-freeness (NAF) and propose it as\nsufficient for protection. This paper revisits the question and establishes new\nfoundations for provable copyright protection -- foundations that are firmer\nboth technically and legally. First, we show that NAF alone does not prevent\ninfringement. In fact, NAF models can enable verbatim copying, a blatant\nfailure of copy protection that we dub being tainted. Then, we introduce our\nblameless copy protection framework for defining meaningful guarantees, and\ninstantiate it with clean-room copy protection. Clean-room copy protection\nallows a user to control their risk of copying by behaving in a way that is\nunlikely to copy in a counterfactual clean-room setting. Finally, we formalize\na common intuition about differential privacy and copyright by proving that DP\nimplies clean-room copy protection when the dataset is golden, a copyright\ndeduplication requirement.", "AI": {"tldr": "本文重新审视了生成模型输出是否侵犯训练数据版权的可证明保护问题，指出原有NAF标准的不足，提出了新的无责复制保护框架和清洁室复制保护机制，并证明了差分隐私在满足特定条件时可实现版权保护。", "motivation": "研究生成模型输出在何种条件下能确保不侵犯训练数据版权，批判性评估现有NAF标准的有效性，并寻求更坚实的技术和法律基础。", "method": "1) 揭示NAF标准存在允许逐字复制的缺陷；2) 提出无责复制保护框架及其实例化方案——清洁室复制保护；3) 形式化差分隐私与版权的关系，证明其在数据集满足去重要求时的保护性。", "result": "1) 证明NAF单独使用无法防止侵权；2) 提出清洁室机制使用户能通过反事实行为控制复制风险；3) 建立差分隐私在黄金数据集下隐含清洁室保护的数学证明。", "conclusion": "通过构建新的理论框架和形式化证明，为生成模型的版权保护提供了更严谨的基础，特别是指出差分隐私在满足版权去重要求时的保护作用。"}}
{"id": "2506.20086", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.20086", "abs": "https://arxiv.org/abs/2506.20086", "authors": ["On-Hei Solomon Lo", "Kenta Ozeki"], "title": "Minors of non-hamiltonian polyhedra and the Herschel family", "comment": null, "summary": "We show that every non-hamiltonian polyhedron contains the Herschel graph as\na minor. As an application, we provide a characterization of non-hamiltonian\npolyhedra without $K_{2,6}$ minors, thereby resolving a conjecture by\nEllingham, Marshall, Ozeki, Royle, and Tsuchiya.", "AI": {"tldr": "证明所有非哈密顿多面体都包含Herschel图作为子图，并解决了关于不含$K_{2,6}$子图的非哈密顿多面体的猜想。", "motivation": "解决Ellingham等人提出的关于非哈密顿多面体的猜想，特别是针对不含$K_{2,6}$子图的情况。", "method": "通过分析非哈密顿多面体的图论性质，证明其必然包含Herschel图作为子图。", "result": "所有非哈密顿多面体都包含Herschel图作为子图，并完全刻画了不含$K_{2,6}$子图的非哈密顿多面体。", "conclusion": "该研究不仅验证了猜想，还为非哈密顿多面体的结构提供了更深入的理解。"}}
{"id": "2506.20335", "categories": ["math.OC", "90C56, 65K05, 90C06"], "pdf": "https://arxiv.org/pdf/2506.20335", "abs": "https://arxiv.org/abs/2506.20335", "authors": ["Yiwen Chen", "Warren Hare", "Amy Wiebe"], "title": "CLARSTA: A random subspace trust-region algorithm for convex-constrained derivative-free optimization", "comment": null, "summary": "This paper proposes a random subspace trust-region algorithm for general\nconvex-constrained derivative-free optimization (DFO) problems. Similar to\nprevious random subspace DFO methods, the convergence of our algorithm requires\na certain accuracy of models and a certain quality of subspaces. For model\naccuracy, we define a new class of models that is only required to provide\nreasonable accuracy on the projection of the constraint set onto the subspace.\nWe provide a new geometry measure to make these models easy to analyze,\nconstruct, and manage. For subspace quality, we use the concentration on the\nGrassmann manifold to provide a method to sample subspaces that preserve the\nfirst-order criticality measure by a certain percentage with a certain\nprobability lower bound. Based on all these new theoretical results, we present\nan almost-sure global convergence and a worst-case complexity analysis of our\nalgorithm. Numerical experiments on problems with dimensions up to 10000\ndemonstrate the reliable performance of our algorithm in high dimensions.", "AI": {"tldr": "本文提出了一种用于凸约束无导数优化问题的随机子空间信赖域算法，通过新的模型精度定义和子空间采样方法，实现了高维问题的可靠求解。", "motivation": "针对高维凸约束无导数优化问题，现有方法在模型精度和子空间质量方面存在局限性，需要新的理论框架和算法设计。", "method": "提出仅需在约束集投影上保持精度的模型类，并引入Grassmann流形上的集中性理论来保证子空间质量，构建了随机子空间信赖域算法。", "result": "理论证明了算法的全局收敛性和最坏情况复杂度，在维度高达10000的问题上验证了算法的可靠性。", "conclusion": "该算法通过创新的模型定义和子空间采样技术，为高维凸约束无导数优化提供了有效的解决方案，具有理论和实践价值。"}}
{"id": "2506.20325", "categories": ["math.ST", "math.PR", "stat.TH", "62M05, 60J10, 60F10"], "pdf": "https://arxiv.org/pdf/2506.20325", "abs": "https://arxiv.org/abs/2506.20325", "authors": ["Lasse Leskelä", "Maximilien Dreveton"], "title": "Robust estimation of a Markov chain transition matrix from multiple sample paths", "comment": "22 pages", "summary": "Markov chains are fundamental models for stochastic dynamics, with\napplications in a wide range of areas such as population dynamics, queueing\nsystems, reinforcement learning, and Monte Carlo methods. Estimating the\ntransition matrix and stationary distribution from observed sample paths is a\ncore statistical challenge, particularly when multiple independent trajectories\nare available. While classical theory typically assumes identical chains with\nknown stationary distributions, real-world data often arise from heterogeneous\nchains whose transition kernels and stationary measures might differ from a\ncommon target. We analyse empirical estimators for such parallel Markov\nprocesses and establish sharp concentration inequalities that generalise\nBernstein-type bounds from standard time averages to ensemble-time averages.\nOur results provide nonasymptotic error bounds and consistency guarantees in\nhigh-dimensional regimes, accommodating sparse or weakly mixing chains, model\nmismatch, nonstationary initialisations, and partially corrupted data. These\nfindings offer rigorous foundations for statistical inference in heterogeneous\nMarkov chain settings common in modern computational applications.", "AI": {"tldr": "本文研究了异构马尔可夫链的转移矩阵与稳态分布估计问题，提出了适用于并行样本路径的统计推断方法，并建立了非渐近误差界与一致性保证。", "motivation": "经典马尔可夫链理论假设同质链且稳态分布已知，但实际数据常来自具有不同转移核与稳态测度的异构链。需要发展适用于此类场景的统计推断理论。", "method": "通过分析并行马尔可夫过程的经验估计量，将伯恩斯坦型界限从传统时间平均推广到集合-时间平均框架。", "result": "建立了高维场景下的非渐近误差界，适用于稀疏链、弱混合链、模型失配、非平稳初始及部分污染数据，为统计推断提供严格理论基础。", "conclusion": "该研究为现代计算应用中常见的异构马尔可夫链场景提供了统计推断的 rigorous 理论基础，扩展了传统方法的适用边界。"}}
{"id": "2506.20018", "categories": ["cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2506.20018", "abs": "https://arxiv.org/abs/2506.20018", "authors": ["Zechun Deng", "Ziwei Liu", "Ziqian Bi", "Junhao Song", "Chia Xin Liang", "Joe Yeong", "Junfeng Hao"], "title": "Achieving Trustworthy Real-Time Decision Support Systems with Low-Latency Interpretable AI Models", "comment": null, "summary": "This paper investigates real-time decision support systems that leverage\nlow-latency AI models, bringing together recent progress in holistic AI-driven\ndecision tools, integration with Edge-IoT technologies, and approaches for\neffective human-AI teamwork. It looks into how large language models can assist\ndecision-making, especially when resources are limited. The research also\nexamines the effects of technical developments such as DeLLMa, methods for\ncompressing models, and improvements for analytics on edge devices, while also\naddressing issues like limited resources and the need for adaptable frameworks.\nThrough a detailed review, the paper offers practical perspectives on\ndevelopment strategies and areas of application, adding to the field by\npointing out opportunities for more efficient and flexible AI-supported\nsystems. The conclusions set the stage for future breakthroughs in this\nfast-changing area, highlighting how AI can reshape real-time decision support.", "AI": {"tldr": "本文探讨了利用低延迟AI模型的实时决策支持系统，结合了整体AI驱动决策工具、边缘物联网技术集成以及有效人机协作方法的最新进展。", "motivation": "研究旨在解决资源有限情况下的决策支持问题，探索如何通过大型语言模型等技术提升决策效率。", "method": "通过详细综述，分析了DeLLMa等技术发展、模型压缩方法及边缘设备分析改进，并讨论了资源限制和适应性框架需求。", "result": "研究提供了开发策略和应用领域的实用视角，指出了构建更高效灵活AI支持系统的机会。", "conclusion": "结论为这一快速变化领域的未来突破奠定了基础，强调了AI如何重塑实时决策支持。"}}
{"id": "2506.19886", "categories": ["cs.CR", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2506.19886", "abs": "https://arxiv.org/abs/2506.19886", "authors": ["Xuesong Wang", "Mo Li", "Xingyan Shi", "Zhaoqian Liu", "Shenghao Yang"], "title": "Diffusion-based Task-oriented Semantic Communications with Model Inversion Attack", "comment": null, "summary": "Semantic communication has emerged as a promising neural network-based system\ndesign for 6G networks. Task-oriented semantic communication is a novel\nparadigm whose core goal is to efficiently complete specific tasks by\ntransmitting semantic information, optimizing communication efficiency and task\nperformance. The key challenge lies in preserving privacy while maintaining\ntask accuracy, as this scenario is susceptible to model inversion attacks. In\nsuch attacks, adversaries can restore or even reconstruct input data by\nanalyzing and processing model outputs, owing to the neural network-based\nnature of the systems. In addition, traditional systems use image quality\nindicators (such as PSNR or SSIM) to assess attack severity, which may be\ninadequate for task-oriented semantic communication, since visual differences\ndo not necessarily ensure semantic divergence. In this paper, we propose a\ndiffusion-based semantic communication framework, named DiffSem, that optimizes\nsemantic information reconstruction through a diffusion mechanism with\nself-referential label embedding to significantly improve task performance. Our\nmodel also compensates channel noise and adopt semantic information distortion\nto ensure the robustness of the system in various signal-to-noise ratio\nenvironments. To evaluate the attacker's effectiveness, we propose a new metric\nthat better quantifies the semantic fidelity of estimations from the adversary.\nExperimental results based on this criterion show that on the MNIST dataset,\nDiffSem improves the classification accuracy by 10.03%, and maintain stable\nperformance under dynamic channels. Our results further demonstrate that\nsignificant deviation exists between traditional image quality indicators and\nthe leakage of task-relevant semantic information.", "AI": {"tldr": "本文提出了一种基于扩散机制的语义通信框架DiffSem，通过自参考标签嵌入优化语义信息重建，显著提升任务性能，并在动态信道中保持稳定表现。同时提出新指标量化攻击者语义保真度，实验证明DiffSem在MNIST数据集上分类准确率提升10.03%，且传统图像质量指标与任务相关语义信息泄露存在显著偏差。", "motivation": "面向任务的语义通信是6G网络中的新兴范式，其核心挑战在于平衡隐私保护与任务准确性。传统系统易受模型逆向攻击，且依赖图像质量指标（如PSNR/SSIM）评估攻击严重性，但这些指标无法充分反映语义差异。因此需设计新型框架及评估标准。", "method": "提出DiffSem框架：1) 采用扩散机制与自参考标签嵌入优化语义重建；2) 补偿信道噪声并引入语义信息失真以增强鲁棒性；3) 设计新指标量化攻击者语义保真度，替代传统图像质量评估。", "result": "在MNIST数据集上，DiffSem使分类准确率提升10.03%，且在动态信道环境下性能稳定。实验证实传统图像质量指标（如PSNR/SSIM）与任务相关语义泄露程度存在显著偏差。", "conclusion": "DiffSem通过扩散机制有效提升语义通信的任务性能与抗干扰能力，同时提出的新评估指标更精准反映语义安全性。该研究为6G网络中隐私保护与效能平衡提供了新思路。"}}
{"id": "2506.20087", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.20087", "abs": "https://arxiv.org/abs/2506.20087", "authors": ["On-Hei Solomon Lo"], "title": "On minors of non-hamiltonian graphs", "comment": null, "summary": "A theorem of Tutte states that every 4-connected non-hamiltonian graph\ncontains $K_{3,3}$ as a minor. We strengthen this result by proving that such a\ngraph must contain $K_{3,4}$ as a minor, thereby confirming a special case of a\nconjecture posed by Chen, Yu, and Zang in a strong form. This result may be\nviewed as a step toward characterizing the minor-minimal 4-connected\nnon-hamiltonian graphs. As a 3-connected analog, Ding and Marshall conjectured\nthat every 3-connected non-hamiltonian graph has a minor of $K_{3,4}$,\n$\\mathfrak{Q}^+$, or the Herschel graph, where $\\mathfrak{Q}^+$ is obtained\nfrom the cube by adding a new vertex adjacent to three independent vertices. We\nconfirm this conjecture.", "AI": {"tldr": "论文强化了Tutte定理，证明了4连通非哈密尔顿图必须包含$K_{3,4}$作为子图，并验证了Ding和Marshall关于3连通非哈密尔顿图的猜想。", "motivation": "研究旨在进一步刻画4连通非哈密尔顿图的极小子图结构，并验证相关猜想以推动图论领域的发展。", "method": "通过理论证明和数学推导，强化了Tutte定理，并验证了Ding和Marshall的猜想。", "result": "证明了4连通非哈密尔顿图必须包含$K_{3,4}$作为子图，并确认了3连通非哈密尔顿图包含$K_{3,4}$、$\\mathfrak{Q}^+$或Herschel图作为子图的猜想。", "conclusion": "该结果为刻画极小4连通非哈密尔顿图提供了重要进展，并验证了3连通情况下的猜想，对图论研究具有深远意义。"}}
{"id": "2506.20344", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20344", "abs": "https://arxiv.org/abs/2506.20344", "authors": ["Po Chen", "Rujun Jiang", "Peng Wang"], "title": "A Complete Loss Landscape Analysis of Regularized Deep Matrix Factorization", "comment": "35 pages, 3 figures", "summary": "Despite its wide range of applications across various domains, the\noptimization foundations of deep matrix factorization (DMF) remain largely\nopen. In this work, we aim to fill this gap by conducting a comprehensive study\nof the loss landscape of the regularized DMF problem. Toward this goal, we\nfirst provide a closed-form expression of all critical points. Building on\nthis, we establish precise conditions under which a critical point is a local\nminimizer, a global minimizer, a strict saddle point, or a non-strict saddle\npoint. Leveraging these results, we derive a necessary and sufficient condition\nunder which each critical point is either a local minimizer or a strict saddle\npoint. This provides insights into why gradient-based methods almost always\nconverge to a local minimizer of the regularized DMF problem. Finally, we\nconduct numerical experiments to visualize its loss landscape under different\nsettings to support our theory.", "AI": {"tldr": "本文对正则化深度矩阵分解（DMF）的损失景观进行了全面研究，给出了临界点的闭式表达式，并建立了临界点性质（局部极小值、全局极小值、严格鞍点等）的精确条件，揭示了梯度法几乎总能收敛到局部极小值的原因。", "motivation": "尽管深度矩阵分解（DMF）在多个领域应用广泛，但其优化基础仍缺乏系统研究。本文旨在填补这一空白，深入分析正则化DMF问题的损失景观特性。", "method": "首先推导了所有临界点的闭式表达式，在此基础上建立了临界点性质的数学条件（如局部极小值、严格鞍点的判别准则），并通过数值实验可视化不同参数下的损失景观。", "result": "提出了临界点分类的充要条件，证明每个临界点要么是局部极小值，要么是严格鞍点，这解释了梯度法的高效收敛性。数值实验验证了理论结果。", "conclusion": "该研究为理解DMF的优化行为提供了理论框架，揭示了梯度法在正则化DMF问题中几乎必然收敛到局部最优解的内在机制，对实际应用具有指导意义。"}}
{"id": "2506.20458", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.20458", "abs": "https://arxiv.org/abs/2506.20458", "authors": ["Kayvan Sadeghi"], "title": "On Exponential Random Graph Models with Dyadic Independence", "comment": "13 pages", "summary": "We show that the only exponential random graph model with n nodal parameters,\ndyads being independent, and the natural assumption of permutation-equivariant\nnodal parametrization is the \\b{eta} model. In addition, we show that an\nexponential random graph model with similar assumptions but with fewer than n\nblock parameters is the additive stochastic block model. We also provide\nsimilar results for directed networks", "AI": {"tldr": "论文证明了在节点参数独立且具有置换等变性的自然假设下，唯一具有n个节点参数的指数随机图模型是\\b{eta}模型，并指出类似假设但参数少于n的模型为加性随机分块模型。", "motivation": "研究在特定假设条件下，指数随机图模型和随机分块模型的唯一性，以深化对网络统计模型的理解。", "method": "通过数学证明和理论分析，验证了在节点参数独立和置换等变性的假设下，\\b{eta}模型和加性随机分块模型的唯一性。", "result": "证明了\\b{eta}模型是指数随机图模型中唯一满足条件的模型，加性随机分块模型是参数少于n时的唯一模型，并推广到有向网络。", "conclusion": "研究结果为网络统计分析提供了理论支持，明确了特定条件下模型的唯一性，为后续研究奠定了基础。"}}
{"id": "2506.20020", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.20020", "abs": "https://arxiv.org/abs/2506.20020", "authors": ["Saloni Dash", "Amélie Reymond", "Emma S. Spiro", "Aylin Caliskan"], "title": "Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning", "comment": null, "summary": "Reasoning in humans is prone to biases due to underlying motivations like\nidentity protection, that undermine rational decision-making and judgment. This\nmotivated reasoning at a collective level can be detrimental to society when\ndebating critical issues such as human-driven climate change or vaccine safety,\nand can further aggravate political polarization. Prior studies have reported\nthat large language models (LLMs) are also susceptible to human-like cognitive\nbiases, however, the extent to which LLMs selectively reason toward\nidentity-congruent conclusions remains largely unexplored. Here, we investigate\nwhether assigning 8 personas across 4 political and socio-demographic\nattributes induces motivated reasoning in LLMs. Testing 8 LLMs (open source and\nproprietary) across two reasoning tasks from human-subject studies -- veracity\ndiscernment of misinformation headlines and evaluation of numeric scientific\nevidence -- we find that persona-assigned LLMs have up to 9% reduced veracity\ndiscernment relative to models without personas. Political personas\nspecifically, are up to 90% more likely to correctly evaluate scientific\nevidence on gun control when the ground truth is congruent with their induced\npolitical identity. Prompt-based debiasing methods are largely ineffective at\nmitigating these effects. Taken together, our empirical findings are the first\nto suggest that persona-assigned LLMs exhibit human-like motivated reasoning\nthat is hard to mitigate through conventional debiasing prompts -- raising\nconcerns of exacerbating identity-congruent reasoning in both LLMs and humans.", "AI": {"tldr": "研究发现，大型语言模型（LLMs）在赋予特定政治和社会人口属性的人设后，会表现出类似人类的动机性推理偏差，这种偏差难以通过常规提示方法消除。", "motivation": "人类推理常因身份保护等动机产生偏见，影响理性决策。集体层面的动机性推理在讨论气候变化或疫苗安全等关键问题时可能加剧社会分裂。此前研究表明LLMs也存在类似认知偏差，但其是否因身份认同选择性推理尚不明确。", "method": "研究为8个LLMs（开源和商业模型）赋予4类政治/社会属性的8种人设，测试其在两项人类研究任务中的表现：错误信息标题真实性判断和数字科学证据评估。", "result": "带人设的LLMs真实性判断准确率下降达9%。政治人设模型在枪控证据评估中，当事实与其政治身份一致时正确率提升90%。现有提示去偏方法基本无效。", "conclusion": "首次证实LLMs会表现出顽固的类人动机性推理，常规去偏方法难以缓解，可能加剧LLMs和人类身份认同驱动的非理性推理。"}}
{"id": "2506.19889", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19889", "abs": "https://arxiv.org/abs/2506.19889", "authors": ["Wanli Peng", "Xin Chen", "Hang Fu", "XinYu He", "Xue Yiming", "Juan Wen"], "title": "Retrieval-Confused Generation is a Good Defender for Privacy Violation Attack of Large Language Models", "comment": null, "summary": "Recent advances in large language models (LLMs) have made a profound impact\non our society and also raised new security concerns. Particularly, due to the\nremarkable inference ability of LLMs, the privacy violation attack (PVA),\nrevealed by Staab et al., introduces serious personal privacy issues. Existing\ndefense methods mainly leverage LLMs to anonymize the input query, which\nrequires costly inference time and cannot gain satisfactory defense\nperformance. Moreover, directly rejecting the PVA query seems like an effective\ndefense method, while the defense method is exposed, promoting the evolution of\nPVA. In this paper, we propose a novel defense paradigm based on\nretrieval-confused generation (RCG) of LLMs, which can efficiently and covertly\ndefend the PVA. We first design a paraphrasing prompt to induce the LLM to\nrewrite the \"user comments\" of the attack query to construct a disturbed\ndatabase. Then, we propose the most irrelevant retrieval strategy to retrieve\nthe desired user data from the disturbed database. Finally, the \"data comments\"\nare replaced with the retrieved user data to form a defended query, leading to\nresponding to the adversary with some wrong personal attributes, i.e., the\nattack fails. Extensive experiments are conducted on two datasets and eight\npopular LLMs to comprehensively evaluate the feasibility and the superiority of\nthe proposed defense method.", "AI": {"tldr": "本文提出了一种基于检索混淆生成(RCG)的新型防御范式，用于高效隐蔽地防御大型语言模型(LLM)的隐私侵犯攻击(PVA)。该方法通过改写攻击查询、构建干扰数据库和无关检索策略，使攻击者获得错误个人信息，从而有效抵御PVA。", "motivation": "现有防御方法依赖LLM匿名化输入查询，计算成本高且效果不佳；直接拒绝PVA查询会暴露防御方法，促使攻击进化。因此需要开发更高效隐蔽的防御机制。", "method": "1) 设计改写提示诱导LLM重构攻击查询的\"用户评论\"以构建干扰数据库；2) 采用最不相关检索策略从干扰库中检索目标数据；3) 用检索数据替换原始\"数据评论\"生成防御性查询。", "result": "在两个数据集和八个主流LLM上的实验表明，该方法能有效使攻击者获取错误个人属性，显著提升防御性能。", "conclusion": "RCG防御范式通过主动干扰攻击查询的语义关联性，实现了对PVA的高效隐蔽防御，为LLM隐私保护提供了新思路。"}}
{"id": "2506.20099", "categories": ["math.CO", "math.RT", "05E10, 20C08"], "pdf": "https://arxiv.org/pdf/2506.20099", "abs": "https://arxiv.org/abs/2506.20099", "authors": ["Gavin Hobbs", "Tommy Parisi", "Mark Skandera", "Jiayuan Wang"], "title": "A generalization of Deodhar's defect statistic for Iwahori--Hecke algebras of type $BC$", "comment": "18 pages, 6 figures (some best viewed in color). Extended abstract\n  accepted for poster presentation at FPSAC 2025", "summary": "Let $H$ be the Iwahori--Hecke algebra corresponding to any Coxeter group.\nDeodhar's defect statistic [Geom. Dedicata 36, (1990) pp.95--119] allows one to\nexpand products of simple Kazhdan--Lusztig basis elements of $H$ in the natural\nbasis of $H$. Clearwater and the third author gave a type-$A$ extension [Ann.\nComb. 25, no. 3 (2021) pp.757--787] of this formula which combinatorially\ndescribes the natural expansion of products of Kazhdan--Lusztig basis elements\nindexed by smooth elements of the symmetric group. We similarly give a\ntype-$BC$ extension of Deodhar's result which combinatorially describes the\nnatural expansion of Kazhdan--Lusztig basis elements indexed by hyperoctahedral\ngroup elements which are simultaneously smooth in types $B$ and $C$.", "AI": {"tldr": "本文扩展了Deodhar的缺陷统计方法，为类型$BC$的Kazhdan--Lusztig基元素乘积在自然基中的展开提供了组合描述。", "motivation": "Deodhar的缺陷统计方法已成功应用于Iwahori--Hecke代数中简单Kazhdan--Lusztig基元素乘积的展开，但在类型$A$之外的扩展尚未充分研究。本文旨在填补这一空白。", "method": "借鉴Clearwater等人在类型$A$中的工作，作者将Deodhar的方法推广到类型$BC$，特别关注同时在类型$B$和$C$中光滑的超八面体群元素。", "result": "成功推导出类型$BC$中Kazhdan--Lusztig基元素乘积在自然基中的组合展开公式，扩展了Deodhar的原始结果。", "conclusion": "该研究不仅完善了类型$BC$的Kazhdan--Lusztig理论，还为相关组合结构提供了新的计算工具。"}}
{"id": "2506.20492", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.20492", "abs": "https://arxiv.org/abs/2506.20492", "authors": ["Kamal Fenza", "Moussa Labbadi", "Mohamed Ouzahra"], "title": "A Decomposition Method for Finite-Time Stabilization of Bilinear Systems with Applications to Parabolic and Hyperbolic Equations", "comment": null, "summary": "In this work, we address the problem of finite-time stabilization for a class\nof bilinear system. We propose a decomposition-based approach in which the\nnominal system is split into two subsystems, one of which is inherently\nfinite-time stable without control. This allows the stabilization analysis to\nfocus solely on the remaining subsystem. To ensure the well-posedness of the\nclosed-loop system, we establish sufficient conditions on the system and\ncontrol operators. The stabilization results are then derived using a suitable\nLyapunov function and an observation condition. The effectiveness of the\nproposed approach is demonstrated through examples involving both parabolic and\nhyperbolic infinite-dimensional systems.", "AI": {"tldr": "本文针对一类双线性系统的有限时间稳定问题，提出了一种基于分解的方法，通过将系统分解为两个子系统来简化稳定分析，并建立了闭环系统适定性的充分条件。", "motivation": "解决一类双线性系统的有限时间稳定问题，通过分解方法简化分析过程，提高控制效率。", "method": "采用分解方法，将名义系统分为两个子系统，其中一个子系统无需控制即具有有限时间稳定性，从而集中分析剩余子系统。通过建立系统和控制算子的充分条件，确保闭环系统的适定性，并利用合适的Lyapunov函数和观测条件推导稳定结果。", "result": "所提出的方法在抛物型和双曲型无限维系统示例中证明了其有效性，成功实现了有限时间稳定。", "conclusion": "通过分解方法和Lyapunov函数，本文有效解决了一类双线性系统的有限时间稳定问题，为无限维系统的控制提供了新思路。"}}
{"id": "2506.20659", "categories": ["math.ST", "math.OC", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.20659", "abs": "https://arxiv.org/abs/2506.20659", "authors": ["Joshua Agterberg", "René Vidal"], "title": "A High-Dimensional Statistical Theory for Convex and Nonconvex Matrix Sensing", "comment": null, "summary": "The problem of matrix sensing, or trace regression, is a problem wherein one\nwishes to estimate a low-rank matrix from linear measurements perturbed with\nnoise. A number of existing works have studied both convex and nonconvex\napproaches to this problem, establishing minimax error rates when the number of\nmeasurements is sufficiently large relative to the rank and dimension of the\nlow-rank matrix, though a precise comparison of these procedures still remains\nunexplored. In this work we provide a high-dimensional statistical analysis for\nsymmetric low-rank matrix sensing observed under Gaussian measurements and\nnoise. Our main result describes a novel phenomenon: in this statistical model\nand in an appropriate asymptotic regime, the behavior of any local minimum of\nthe nonconvex factorized approach (with known rank) is approximately equivalent\nto that of the matrix hard-thresholding of a corresponding matrix denoising\nproblem, and the behavior of the convex nuclear-norm regularized least squares\napproach is approximately equivalent to that of matrix soft-thresholding of the\nsame matrix denoising problem. Here \"approximately equivalent\" is understood in\nthe sense of concentration of Lipchitz functions. As a consequence, the\nnonconvex procedure uniformly dominates the convex approach in mean squared\nerror. Our arguments are based on a matrix operator generalization of the\nConvex Gaussian Min-Max Theorem (CGMT) together with studying the interplay\nbetween local minima of the convex and nonconvex formulations and their\n\"debiased\" counterparts, and several of these results may be of independent\ninterest.", "AI": {"tldr": "本文研究了高斯测量和噪声下对称低秩矩阵感知问题，发现非凸因子化方法在均方误差上一致优于凸核范数正则化方法。", "motivation": "现有工作对矩阵感知问题的凸和非凸方法进行了研究，但在高维统计模型下这些方法的精确比较仍未探索。本文旨在填补这一空白。", "method": "采用高维统计分析方法，基于矩阵算子的凸高斯极小极大定理（CGMT），研究凸和非凸公式的局部极小值及其去偏对应关系。", "result": "在适当渐近条件下，非凸因子化方法的任何局部极小值行为近似等价于矩阵去噪问题的硬阈值处理，而凸方法则近似等价于软阈值处理。非凸方法在均方误差上一致优于凸方法。", "conclusion": "本文揭示了非凸方法在高斯测量和噪声下的统计优势，相关结果可能具有独立的理论价值。"}}
{"id": "2506.20059", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20059", "abs": "https://arxiv.org/abs/2506.20059", "authors": ["Weijieying Ren", "Tianxiang Zhao", "Lei Wang", "Tianchun Wang", "Vasant Honavar"], "title": "DiaLLMs: EHR Enhanced Clinical Conversational System for Clinical Test Recommendation and Diagnosis Prediction", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have led to remarkable\nprogresses in medical consultation. However, existing medical LLMs overlook the\nessential role of Electronic Health Records (EHR) and focus primarily on\ndiagnosis recommendation, limiting their clinical applicability. We propose\nDiaLLM, the first medical LLM that integrates heterogeneous EHR data into\nclinically grounded dialogues, enabling clinical test recommendation, result\ninterpretation, and diagnosis prediction to better align with real-world\nmedical practice. To construct clinically grounded dialogues from EHR, we\ndesign a Clinical Test Reference (CTR) strategy that maps each clinical code to\nits corresponding description and classifies test results as \"normal\" or\n\"abnormal\". Additionally, DiaLLM employs a reinforcement learning framework for\nevidence acquisition and automated diagnosis. To handle the large action space,\nwe introduce a reject sampling strategy to reduce redundancy and improve\nexploration efficiency. Furthermore, a confirmation reward and a\nclass-sensitive diagnosis reward are designed to guide accurate diagnosis\nprediction. Extensive experimental results demonstrate that DiaLLM outperforms\nbaselines in clinical test recommendation and diagnosis prediction.", "AI": {"tldr": "提出首个整合电子健康记录(EHR)的医疗大语言模型DiaLLM，通过临床测试参考策略和强化学习框架，实现临床检查推荐、结果解读和诊断预测，显著提升临床适用性。", "motivation": "现有医疗大语言模型忽视电子健康记录(EHR)的核心作用且仅关注诊断推荐，限制了临床实用性。需开发能整合EHR数据并支持全流程临床决策的模型。", "method": "1) 设计临床测试参考(CTR)策略将临床代码映射为可读描述并分类检测结果\\n2) 采用强化学习框架进行证据收集和自动诊断\\n3) 引入拒绝采样策略缩减动作空间\\n4) 设计确认奖励和类别敏感诊断奖励机制", "result": "实验表明DiaLLM在临床检查推荐和诊断预测任务上全面超越基线模型，验证了EHR整合与强化学习框架的有效性。", "conclusion": "DiaLLM通过创新性地融合EHR数据与对话系统，建立了更符合真实医疗场景的决策支持范式，为医疗AI的临床落地提供了新方向。"}}
{"id": "2506.19892", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2506.19892", "abs": "https://arxiv.org/abs/2506.19892", "authors": ["Isaac Marroqui Penalva", "Enrique Tomás Martínez Beltrán", "Manuel Gil Pérez", "Alberto Huertas Celdrán"], "title": "RepuNet: A Reputation System for Mitigating Malicious Clients in DFL", "comment": null, "summary": "Decentralized Federated Learning (DFL) enables nodes to collaboratively train\nmodels without a central server, introducing new vulnerabilities since each\nnode independently selects peers for model aggregation. Malicious nodes may\nexploit this autonomy by sending corrupted models (model poisoning), delaying\nmodel submissions (delay attack), or flooding the network with excessive\nmessages, negatively affecting system performance. Existing solutions often\ndepend on rigid configurations or additional infrastructures such as\nblockchain, leading to computational overhead, scalability issues, or limited\nadaptability. To overcome these limitations, this paper proposes RepuNet, a\ndecentralized reputation system that categorizes threats in DFL and dynamically\nevaluates node behavior using metrics like model similarity, parameter changes,\nmessage latency, and communication volume. Nodes' influence in model\naggregation is adjusted based on their reputation scores. RepuNet was\nintegrated into the Nebula DFL platform and experimentally evaluated with MNIST\nand CIFAR-10 datasets under non-IID distributions, using federations of up to\n25 nodes in both fully connected and random topologies. Different attack\nintensities, frequencies, and activation intervals were tested. Results\ndemonstrated that RepuNet effectively detects and mitigates malicious behavior,\nachieving F1 scores above 95% for MNIST scenarios and approximately 76% for\nCIFAR-10 cases. These outcomes highlight RepuNet's adaptability, robustness,\nand practical potential for mitigating threats in decentralized federated\nlearning environments.", "AI": {"tldr": "本文提出RepuNet，一种去中心化信誉系统，用于检测和缓解去中心化联邦学习（DFL）中的恶意行为，通过动态评估节点行为并调整其在模型聚合中的影响力，实验证明其在MNIST和CIFAR-10数据集上具有高效性和鲁棒性。", "motivation": "去中心化联邦学习（DFL）中节点自主选择聚合对等节点，易受模型投毒、延迟攻击和消息洪泛等恶意行为影响，现有解决方案存在配置僵化、计算开销大或适应性有限等问题。", "method": "RepuNet通过模型相似性、参数变化、消息延迟和通信量等指标动态评估节点行为，并基于信誉分数调整节点在模型聚合中的影响力，集成至Nebula DFL平台进行实验验证。", "result": "在MNIST和CIFAR-10非独立同分布数据集上，RepuNet对恶意行为的检测F1分数分别超过95%和约76%，展现了良好的适应性和鲁棒性。", "conclusion": "RepuNet能有效应对DFL中的多种威胁，具有实际应用潜力，为去中心化联邦学习环境提供了可靠的安全保障。"}}
{"id": "2506.20153", "categories": ["math.CO", "05E14 (Primary), 05E40 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.20153", "abs": "https://arxiv.org/abs/2506.20153", "authors": ["Adhip Ganguly", "Shyamashree Upadhyay"], "title": "On the homogeneity problem of the Kazhdan-Lusztig ideals", "comment": "26 pages", "summary": "In this paper, we identify some sufficient conditions for a Kazhdan-Lusztig\nideal to be inhomogeneous. Also, we attempt to approach the problem of giving\nsome necessary and sufficient conditions for a Kazhdan-Lusztig ideal to be\n\"standard homogeneous\".", "AI": {"tldr": "本文研究了Kazhdan-Lusztig理想的不齐次性充分条件，并探讨了其标准齐次性的充要条件。", "motivation": "旨在为Kazhdan-Lusztig理想的不齐次性提供理论支持，并探索其标准齐次性的判定条件。", "method": "通过数学推导和条件分析，识别不齐次性的充分条件，并尝试构建标准齐次性的充要条件框架。", "result": "确定了Kazhdan-Lusztig理想不齐次性的若干充分条件，为标准齐次性问题的研究奠定了基础。", "conclusion": "该研究推进了对Kazhdan-Lusztig理想齐次性问题的理解，为后续相关理论工作提供了重要参考。"}}
{"id": "2506.20546", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.20546", "abs": "https://arxiv.org/abs/2506.20546", "authors": ["Yuke Zhou", "Ruiyang Jin", "Siyang Gao", "Jianxiao Wang", "Jie Song"], "title": "A Zeroth-Order Extra-Gradient Method For Black-Box Constrained Optimization", "comment": null, "summary": "Non-analytical objectives and constraints often arise in control systems,\nparticularly in problems with complex dynamics, which are challenging yet lack\nefficient solution methods. In this work, we consider general constrained\noptimization problems involving black-box objectives and constraints. To solve\nit, we reformulate it as a min-max problem and propose a zeroth-order extra\ngradient (ZOEG) algorithm that combines the extra gradient method with a\nfeedback-based stochastic zeroth-order gradient estimator. Then, we apply\nanother coordinate gradient estimator to design the zeroth-order coordinate\nextra gradient algorithm (ZOCEG) to further improve efficiency. The theoretical\nanalysis shows that ZOEG can achieve the best-known oracle complexity of\n$\\mathcal{O}(d\\epsilon^{-2})$ to get an $\\epsilon$-optimal solution ($d$ is the\ndimension of decision space), and ZOCEG can improve it to\n$\\mathcal{O}(d\\epsilon^{-1})$. Furthermore, we develop a variant of ZOCEG,\nwhich applies block coordinate updates to enhance the efficiency of single-step\ngradient estimation. Finally, numerical experiments on a load tracking problem\nvalidate our theoretical results and the effectiveness of the proposed\nalgorithms.", "AI": {"tldr": "本文提出两种零阶优化算法ZOEG和ZOCEG，用于解决黑箱目标与约束的优化问题，理论证明其达到最优复杂度，并通过负载跟踪实验验证有效性。", "motivation": "控制系统中非解析目标与约束问题普遍存在但缺乏高效解法，需开发适用于黑箱场景的优化方法。", "method": "将原问题重构为极小极大问题，结合额外梯度法与零阶梯度估计器设计ZOEG；进一步引入坐标梯度估计器开发ZOCEG，并提出分块坐标更新变种提升效率。", "result": "ZOEG达到$\\mathcal{O}(d\\epsilon^{-2})$的已知最优复杂度，ZOCEG改进至$\\mathcal{O}(d\\epsilon^{-1})$，负载跟踪实验验证算法有效性。", "conclusion": "所提算法在理论和实验上均展现优越性，为黑箱约束优化问题提供了高效解决方案。"}}
{"id": "2506.20130", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20130", "abs": "https://arxiv.org/abs/2506.20130", "authors": ["Adrien Bibal", "Steven N. Minton", "Deborah Khider", "Yolanda Gil"], "title": "AI Copilots for Reproducibility in Science: A Case Study", "comment": null, "summary": "Open science initiatives seek to make research outputs more transparent,\naccessible, and reusable, but ensuring that published findings can be\nindependently reproduced remains a persistent challenge. This paper introduces\nOpenPub, an AI-powered platform that supports researchers, reviewers, and\nreaders through a suite of modular copilots focused on key open science tasks.\nIn this work, we present the Reproducibility Copilot, which analyzes\nmanuscripts, code, and supplementary materials to generate structured Jupyter\nNotebooks and recommendations aimed at facilitating computational, or \"rote\",\nreproducibility. We conducted feasibility tests using previously studied\nresearch papers with known reproducibility benchmarks. Results indicate that\nOpenPub can substantially reduce reproduction time - from over 30 hours to\nabout 1 hour - while achieving high coverage of figures, tables, and results\nsuitable for computational reproduction. The system systematically detects\nbarriers to reproducibility, including missing hyperparameters, undocumented\npreprocessing steps, and incomplete or inaccessible datasets. These findings\nsuggest that AI-driven tools can meaningfully reduce the burden of\nreproducibility efforts and contribute to more transparent and verifiable\nscientific communication. The modular copilot architecture also provides a\nfoundation for extending AI assistance to additional open science objectives\nbeyond reproducibility.", "AI": {"tldr": "本文介绍OpenPub平台及其AI驱动的可复现性助手，该工具通过分析论文材料生成结构化Jupyter Notebook，将复现时间从30小时缩短至1小时，显著提升计算复现效率。", "motivation": "开放科学倡议虽推动研究透明化，但成果独立复现仍具挑战性。本研究旨在通过AI工具降低复现负担，促进可验证的科学交流。", "method": "开发模块化OpenPub平台，其核心'可复现性助手'能解析稿件、代码及补充材料，自动生成带修复建议的Jupyter Notebook，并系统性检测复现障碍如缺失超参数、未记录预处理步骤等。", "result": "在已知复现基准的论文测试中，系统将复现时间从30+小时压缩至约1小时，对图表和结果的计算复现覆盖率高，并能准确识别各类复现壁垒。", "conclusion": "AI工具可有效减轻复现工作负担，模块化架构为拓展其他开放科学目标奠定基础，有助于提升科研透明度和可验证性。"}}
{"id": "2506.19899", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.19899", "abs": "https://arxiv.org/abs/2506.19899", "authors": ["Andrew T. Rozema", "James C. Davis"], "title": "Anti-Phishing Training Does Not Work: A Large-Scale Empirical Assessment of Multi-Modal Training Grounded in the NIST Phish Scale", "comment": "13 pages, 5 apdx", "summary": "Social engineering attacks using email, commonly known as phishing, are a\ncritical cybersecurity threat. Phishing attacks often lead to operational\nincidents and data breaches. As a result, many organizations allocate a\nsubstantial portion of their cybersecurity budgets to phishing awareness\ntraining, driven in part by compliance requirements. However, the effectiveness\nof this training remains in dispute. Empirical evidence of training\n(in)effectiveness is essential for evidence-based cybersecurity investment and\npolicy development. Despite recent measurement studies, two critical gaps\nremain in the literature:\n  (1) we lack a validated measure of phishing lure difficulty, and\n  (2) there are few comparisons of different types of training in real-world\nbusiness settings.\n  To fill these gaps, we conducted a large-scale study ($N = 12{,}511$) of\nphishing effectiveness at a US-based financial technology (``fintech'') firm.\nOur two-factor design compared the effect of treatments (lecture-based,\ninteractive, and control groups) on subjects' susceptibility to phishing lures\nof varying complexity (using the NIST Phish Scale). The NIST Phish Scale\nsuccessfully predicted behavior (click rates: 7.0\\% easy to 15.0\\% hard emails,\np $<$ 0.001), but training showed no significant main effects on clicks (p =\n0.450) or reporting (p = 0.417). Effect sizes remained below 0.01, indicating\nlittle practical value in any of the phishing trainings we deployed. Our\nresults add to the growing evidence that phishing training is ineffective,\nreinforcing the importance of phishing defense-in-depth and the merit of\nchanges to processes and technology to reduce reliance on humans, as well as\nrebuking the training costs necessitated by regulatory requirements.", "AI": {"tldr": "钓鱼邮件是重大网络安全威胁，但现有钓鱼意识培训效果存疑。本研究通过大规模实验发现NIST钓鱼难度量表能有效预测点击率（7.0\\%简单邮件至15.0\\%复杂邮件），但三种培训方式（讲座式、互动式、对照组）均未显著降低点击率（p=0.450）或提高举报率（p=0.417），效应量均小于0.01。", "motivation": "现有研究存在两个关键空白：(1)缺乏验证的钓鱼诱饵难度评估工具，(2)缺少真实商业环境中不同培训方式的对比。鉴于合规要求下企业投入大量预算进行钓鱼培训，需实证评估其效果以指导网络安全投资决策。", "method": "在美国金融科技公司开展大规模实验（N=12,511），采用双因素设计：比较三种培训方式（讲座式/互动式/对照组）对员工应对不同难度钓鱼邮件（使用NIST Phish Scale分级）的影响，统计点击率和举报率差异。", "result": "NIST钓鱼量表显著预测行为（简单邮件点击率7.0\\% vs复杂邮件15.0\\%，p<0.001），但培训组间无显著差异（点击率p=0.450，举报率p=0.417），所有培训效应量η²<0.01。", "conclusion": "结果证实钓鱼培训效果微乎其微，支持采用深度防御策略：应通过流程优化和技术升级减少对人因素的依赖，同时质疑合规驱动的培训投入合理性。"}}
{"id": "2506.20273", "categories": ["math.CO", "05C50, 05C70"], "pdf": "https://arxiv.org/pdf/2506.20273", "abs": "https://arxiv.org/abs/2506.20273", "authors": ["Sizhong Zhou", "Tao Zhang", "Zhiren Sun"], "title": "Adjacency spectral radius and H-factors in 1-binding graphs", "comment": "9 pages", "summary": "Let $G$ be a graph, and let $H:V(G)\\longrightarrow\\{\\{1\\},\\{0,2\\}\\}$ be a\nset-valued function. Hence, $H(v)$ equals $\\{1\\}$ or $\\{0,2\\}$ for any $v\\in\nV(G)$. We let $$ H^{-1}(1)=\\{v: v\\in V(G) \\ \\mbox{and} \\ H(v)=1\\}. $$ An\n$H$-factor of $G$ is a spanning subgraph $F$ of $G$ such that $d_F(v)\\in H(v)$\nfor each $v\\in V(G)$. Lu and Kano showed a characterization for the existence\nof an $H$-factor in a graph [Characterization of 1-tough graphs using factors,\nDiscrete Math. 343 (2020) 111901]. Let $A(G)$ and $\\rho(G)$ denote the\nadjacency matrix and the adjacency spectral radius of $G$, respectively. By\nusing Lu and Kano's result, we pose a sufficient condition with respect to the\nadjacency spectral radius to guarantee the existence of an $H$-factor in a\n1-binding graph. In this paper, we prove that if a connected 1-binding graph\n$G$ of order $n\\geq11$ satisfies $\\rho(G)\\geq\\rho(K_1\\vee(K_{n-4}\\cup K_2\\cup\nK_1))$, then $G$ has an $H$-factor for each\n$H:V(G)\\longrightarrow\\{\\{1\\},\\{0,2\\}\\}$ with $H^{-1}(1)$ even, unless\n$G=K_1\\vee(K_{n-4}\\cup K_2\\cup K_1)$.", "AI": {"tldr": "本文通过Lu和Kano的H-因子存在性定理，为1-绑定图提出了一个基于邻接谱半径的充分条件，确保在满足特定条件下存在H-因子。", "motivation": "研究图的H-因子存在性问题，特别是通过邻接谱半径这一图论工具，为1-绑定图提供一个新的判定条件。", "method": "利用Lu和Kano的H-因子存在性定理，结合图的邻接矩阵和邻接谱半径$\\rho(G)$，分析1-绑定图的结构特性。", "result": "证明当连通1-绑定图$G$的阶数$n\\geq11$且$\\rho(G)\\geq\\rho(K_1\\vee(K_{n-4}\\cup K_2\\cup K_1))$时，除非$G$为特定图结构，否则对任意满足$H^{-1}(1)$为偶数的集合函数$H$，$G$都存在H-因子。", "conclusion": "通过邻接谱半径这一工具，为1-绑定图的H-因子存在性提供了一个有效的充分条件，扩展了相关图因子的理论结果。"}}
{"id": "2506.20630", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2506.20630", "abs": "https://arxiv.org/abs/2506.20630", "authors": ["Zhaosong Lu", "Yifeng Xiao"], "title": "First-order methods for stochastic and finite-sum convex optimization with deterministic constraints", "comment": "41 pages", "summary": "In this paper, we study a class of stochastic and finite-sum convex\noptimization problems with deterministic constraints. Existing methods\ntypically aim to find an $\\epsilon$-$expectedly\\ feasible\\ stochastic\\ optimal$\nsolution, in which the expected constraint violation and expected optimality\ngap are both within a prescribed tolerance $\\epsilon$. However, in many\npractical applications, constraints must be nearly satisfied with certainty,\nrendering such solutions potentially unsuitable due to the risk of substantial\nviolations. To address this issue, we propose stochastic first-order methods\nfor finding an $\\epsilon$-$surely\\ feasible\\ stochastic\\ optimal$\n($\\epsilon$-SFSO) solution, where the constraint violation is deterministically\nbounded by $\\epsilon$ and the expected optimality gap is at most $\\epsilon$.\nOur methods apply an accelerated stochastic gradient (ASG) scheme or a modified\nvariance-reduced ASG scheme $only\\ once$ to a sequence of quadratic penalty\nsubproblems with appropriately chosen penalty parameters. We establish\nfirst-order oracle complexity bounds for the proposed methods in computing an\n$\\epsilon$-SFSO solution. As a byproduct, we also derive first-order oracle\ncomplexity results for sample average approximation method in computing an\n$\\epsilon$-SFSO solution of the stochastic optimization problem using our\nproposed methods to solve the sample average problem.", "AI": {"tldr": "本文提出了一种新的随机一阶方法，用于求解具有确定性约束的随机凸优化问题，确保解在确定性约束下几乎必然可行，且期望最优性差距在允许范围内。", "motivation": "现有方法通常寻找期望可行的随机最优解，但在实际应用中，约束必须几乎必然满足，因此需要一种确保确定性约束不显著违反的解决方案。", "method": "提出了两种随机一阶方法：加速随机梯度（ASG）方案和修正的方差缩减ASG方案，通过一次应用于适当选择的二次惩罚子问题序列，确保解的确定性可行性和期望最优性。", "result": "建立了计算$\\epsilon$-SFSO解的一阶预言复杂度界限，并作为副产品，推导了样本平均逼近方法在求解随机优化问题时的复杂度结果。", "conclusion": "所提出的方法不仅解决了确定性约束下的随机优化问题，还为样本平均逼近方法提供了有效的求解工具，具有实际应用价值。"}}
{"id": "2506.20249", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.20249", "abs": "https://arxiv.org/abs/2506.20249", "authors": ["Junyan Cheng", "Peter Clark", "Kyle Richardson"], "title": "Language Modeling by Language Models", "comment": null, "summary": "Can we leverage LLMs to model the process of discovering novel language model\n(LM) architectures? Inspired by real research, we propose a multi-agent LLM\napproach that simulates the conventional stages of research, from ideation and\nliterature search (proposal stage) to design implementation (code generation),\ngenerative pre-training, and downstream evaluation (verification). Using ideas\nfrom scaling laws, our system, Genesys, employs a Ladder of Scales approach;\nnew designs are proposed, adversarially reviewed, implemented, and selectively\nverified at increasingly larger model scales (14M$\\sim$350M parameters) with a\nnarrowing budget (the number of models we can train at each scale). To help\nmake discovery efficient and factorizable, Genesys uses a novel genetic\nprogramming backbone, which we show has empirical advantages over commonly used\ndirect prompt generation workflows (e.g., $\\sim$86\\% percentage point\nimprovement in successful design generation, a key bottleneck). We report\nexperiments involving 1,162 newly discovered designs (1,062 fully verified\nthrough pre-training) and find the best designs to be highly competitive with\nknown architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common\nbenchmarks). We couple these results with comprehensive system-level ablations\nand formal results, which give broader insights into the design of effective\nautonomous discovery systems.", "AI": {"tldr": "提出多智能体LLM系统Genesys，通过模拟研究流程（提案、实现、验证）自动发现新型语言模型架构，采用遗传编程框架提升效率，实验验证1062个新设计，部分性能超越现有架构。", "motivation": "探索利用LLM自动化发现新型语言模型架构的可能性，解决人工设计效率低下的问题。", "method": "1) 多智能体模拟研究全流程（提案→代码生成→预训练→评估） 2) 采用阶梯式规模验证（14M~350M参数） 3) 创新遗传编程框架替代直接提示生成", "result": "1) 生成1162个新架构，1062个完成全流程验证 2) 最佳设计在6/9基准测试中超越GPT2、Mamba2 3) 遗传编程使成功生成率提升约86%", "conclusion": "Genesys系统证明LLM可有效自动化架构探索，遗传编程框架显著提升效率，为自主发现系统设计提供新见解。"}}
{"id": "2506.19934", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.19934", "abs": "https://arxiv.org/abs/2506.19934", "authors": ["Maryam Mahdi Al-Husseini"], "title": "A Hybrid Intrusion Detection System with a New Approach to Protect the Cybersecurity of Cloud Computing", "comment": "1. Acknowledgment for: Supervisor: Prof. Dr. Alireza Rouhi Advisor:\n  Prof. Dr. Einollah Pira 2. Thesis of MSc. degree for Azarbaijan Shahid Madani\n  University Faculty of Information Technology and Computer Engineering 3.\n  Number of pages: 103 4. Number of Figures: 66", "summary": "Cybersecurity is one of the foremost challenges facing the world of cloud\ncomputing. Recently, the widespread adoption of smart devices in cloud\ncomputing environments that provide Internet-based services has become\nprevalent. Therefore, it is essential to consider the security threats in these\nenvironments. The use of intrusion detection systems can mitigate the\nvulnerabilities of these systems. Furthermore, hybrid intrusion detection\nsystems can provide better protection compared to conventional intrusion\ndetection systems. These systems manage issues related to complexity,\ndimensionality, and performance. This research aims to propose a Hybrid\nIntrusion Detection System (HyIDS) that identifies and mitigates initial\nthreats. The main innovation of this research is the introduction of a new\nmethod for hybrid intrusion detection systems (HyIDS). For this purpose, an\nEnergy-Valley Optimizer (EVO) is used to select an optimal feature set, which\nis then classified using supervised machine learning models. The proposed\napproach is evaluated using the CIC_DDoS2019, CSE_CIC_DDoS2018, and NSL-KDD\ndatasets. For evaluation and testing, the proposed system has been run for a\ntotal of 32 times. The results of the proposed approach are compared with the\nGrey Wolf Optimizer (GWO). With the CIC_DDoS2019 dataset, the D_TreeEVO model\nachieves an accuracy of 99.13% and a detection rate of 98.941%. Furthermore,\nthis result reaches 99.78% for the CSE_CIC_DDoS2018 dataset. In comparison to\nNSL-KDD, it has an accuracy of 99.50% and a detection rate (DT) of 99.48%. For\nfeature selection, EVO outperforms GWO. The results of this research indicate\nthat EVO yields better results as an optimizer for HyIDS performance.", "AI": {"tldr": "本文提出了一种混合入侵检测系统（HyIDS），采用能量谷优化器（EVO）进行特征选择，并结合监督机器学习模型，显著提高了检测准确率和性能。", "motivation": "云计算环境中智能设备的广泛使用带来了严重的安全威胁，传统入侵检测系统存在局限性，需要更高效的混合入侵检测系统来应对复杂性和性能问题。", "method": "研究提出了一种新的HyIDS方法，使用EVO进行最优特征选择，并采用监督机器学习模型进行分类，通过CIC_DDoS2019、CSE_CIC_DDoS2018和NSL-KDD数据集进行验证。", "result": "实验结果表明，D_TreeEVO模型在CIC_DDoS2019数据集上准确率达99.13%，检测率为98.941%；在CSE_CIC_DDoS2018数据集上准确率达99.78%；在NSL-KDD数据集上准确率为99.50%，检测率为99.48%。EVO在特征选择上优于GWO。", "conclusion": "EVO作为HyIDS的优化器表现优异，能够显著提升入侵检测系统的性能，为云计算环境中的网络安全提供了更有效的解决方案。"}}
{"id": "2506.20296", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.20296", "abs": "https://arxiv.org/abs/2506.20296", "authors": ["Xu Wang", "Jiayi Zhu"], "title": "On Base, Normal and Near-normal Sequences", "comment": "11 pages", "summary": "The base sequences BS(n+1,n) are four sequences of $\\pm1$ and lengths\nn+1,n+1,n,n with zero auto correlation. The base sequence conjecture states\nthat BS(n+1,n) exists for all integers $n>0$ and has been verified for\n$n\\le40$. We present our algorithm and gives construction of BS(n+1,n) for\n$n=41,42,43$.\n  The Normal sequences NS (n) and the Near-normal sequences NNS (n) are\nsubclasses of BS(n+1,n). Yang conjecture asserts that there is a NNS(n) for\neach even integer n and has been verified for $n\\le40$. We found that there is\nno NNS(n) for n=42 and 44 by exhaustive search, which gives the first counter\ncase of Yang conjecture. We also show that there is no NS(n) for\nn=41,42,43,44,45 by exhaustive search and proves that no NS(n) exist for\n$n=8k-2,k \\in Z_+$.", "AI": {"tldr": "该论文研究了基序列BS(n+1,n)的存在性，验证了基序列猜想在n=41,42,43时成立，并首次发现了Yang猜想的反例n=42和44。同时，证明了对于n=8k-2（k为正整数）不存在正规序列NS(n)。", "motivation": "研究基序列BS(n+1,n)的存在性及其子类（正规序列NS(n)和近正规序列NNS(n)）的性质，验证相关猜想并探索其适用范围。", "method": "通过算法构造BS(n+1,n)序列，并对NS(n)和NNS(n)进行穷举搜索，验证其存在性。", "result": "成功构造了n=41,42,43的BS(n+1,n)序列，发现n=42和44不存在NNS(n)，并证明n=41,42,43,44,45不存在NS(n)，且对于n=8k-2（k为正整数）不存在NS(n)。", "conclusion": "基序列猜想在n≤43时成立，但Yang猜想在n=42和44时不成立。此外，正规序列NS(n)在特定条件下不存在，为相关理论研究提供了新的反例和限制条件。"}}
{"id": "2506.20541", "categories": ["math.CO", "math.OC"], "pdf": "https://arxiv.org/pdf/2506.20541", "abs": "https://arxiv.org/abs/2506.20541", "authors": ["João Gouveia", "Stefan Steinerberger", "Rekha R. Thomas"], "title": "Conformal Rigidity and Spectral Embeddings of Graphs", "comment": null, "summary": "We investigate the structure of conformally rigid graphs. Graphs are\nconformally rigid if introducing edge weights cannot increase (decrease) the\nsecond (last) eigenvalue of the Graph Laplacian. Edge-transitive graphs and\ndistance-regular graphs are known to be conformally rigid. We establish new\nresults using the connection between conformal rigidity and edge-isometric\nspectral embeddings of the graph. All $1$-walk regular graphs are conformally\nrigid, a consequence of a stronger property of their embeddings. Using\nsymmetries of the graph, we establish two related characterizations of when a\nvertex-transitive graph is conformally rigid. This provides a necessary and\nsufficient condition for a Cayley graph on an abelian group to be conformally\nrigid. As an application we exhibit an infinite family of conformally rigid\ncirculants. Our symmetry technique can be interpreted in the language of\nsemidefinite programming which provides another criterion for conformal\nrigidity in terms of edge orbits. The paper also describes a number of explicit\nconformally rigid graphs whose conformal rigidity is not yet explained by the\nexisting theory.", "AI": {"tldr": "研究了共形刚性图的结构，证明了所有1-行走正则图都具有共形刚性，并利用对称性给出了顶点传递图共形刚性的充要条件。", "motivation": "探索共形刚性图的结构特性，特别是通过图拉普拉斯算子的特征值变化来定义刚性，并扩展已知的刚性图类别。", "method": "利用边等距谱嵌入与共形刚性的联系，结合图的对称性分析，并应用半定规划技术。", "result": "证明了1-行走正则图具有共形刚性，给出了阿贝尔群上凯莱图刚性的充要条件，并展示了一类无限共形刚性循环图族。", "conclusion": "现有理论尚未完全解释某些显式共形刚性图的性质，对称性分析和半定规划为刚性判定提供了新工具。"}}
{"id": "2506.20274", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20274", "abs": "https://arxiv.org/abs/2506.20274", "authors": ["Liya Wang", "David Yi", "Damien Jose", "John Passarelli", "James Gao", "Jordan Leventis", "Kang Li"], "title": "Enterprise Large Language Model Evaluation Benchmark", "comment": "Submitted to MLNLP 2025 at https://csity2025.org/mlnlp/index", "summary": "Large Language Models (LLMs) ) have demonstrated promise in boosting\nproductivity across AI-powered tools, yet existing benchmarks like Massive\nMultitask Language Understanding (MMLU) inadequately assess enterprise-specific\ntask complexities. We propose a 14-task framework grounded in Bloom's Taxonomy\nto holistically evaluate LLM capabilities in enterprise contexts. To address\nchallenges of noisy data and costly annotation, we develop a scalable pipeline\ncombining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented\ngeneration (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six\nleading models shows open-source contenders like DeepSeek R1 rival proprietary\nmodels in reasoning tasks but lag in judgment-based scenarios, likely due to\noverthinking. Our benchmark reveals critical enterprise performance gaps and\noffers actionable insights for model optimization. This work provides\nenterprises a blueprint for tailored evaluations and advances practical LLM\ndeployment.", "AI": {"tldr": "本文提出一个基于布鲁姆分类法的14任务框架，用于全面评估大语言模型(LLM)在企业场景中的能力，并构建了包含9700个样本的基准测试。研究发现开源模型在推理任务上可媲美商业模型，但在判断类任务中存在过度思考问题。", "motivation": "现有基准测试(如MMLU)无法充分评估LLM在企业特定任务中的复杂表现，亟需开发更贴合企业需求的评估体系。", "method": "开发可扩展的标注流程，结合LLM作为标注员、LLM作为评判员以及纠错检索增强生成(CRAG)技术，构建了包含9700个样本的鲁棒基准数据集。", "result": "评估6个主流模型显示：开源模型(如DeepSeek R1)在推理任务上表现接近商业模型，但在判断类场景中因过度思考而落后；基准测试揭示了企业应用中的关键性能差距。", "conclusion": "本研究为企业提供了定制化评估蓝图，推动LLM的实际部署应用，并为模型优化提供了可操作的改进方向。"}}
{"id": "2506.19943", "categories": ["cs.CR", "cs.NI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2506.19943", "abs": "https://arxiv.org/abs/2506.19943", "authors": ["Juyoul Lee", "Sanzida Hoque", "Abdullah Aydeger", "Engin Zeydan"], "title": "Quantum-Resistant Domain Name System: A Comprehensive System-Level Study", "comment": "Manuscript submitted to ACM, 29 pages, 8 Figures, 15 Tables", "summary": "The Domain Name System (DNS) plays a foundational role in Internet\ninfrastructure, yet its core protocols remain vulnerable to compromise by\nquantum adversaries. As cryptographically relevant quantum computers become a\nrealistic threat, ensuring DNS confidentiality, authenticity, and integrity in\nthe post-quantum era is imperative. In this paper, we present a comprehensive\nsystem-level study of post-quantum DNS security across three widely deployed\nmechanisms: DNSSEC, DNS-over-TLS (DoT), and DNS-over-HTTPS (DoH). We propose\nPost-Quantum Cryptographic (PQC)-DNS, a unified framework for benchmarking DNS\nsecurity under legacy, post-quantum, and hybrid cryptographic configurations.\nOur implementation leverages the Open Quantum Safe (OQS) libraries and\nintegrates lattice- and hash-based primitives into BIND9 and TLS 1.3 stacks. We\nformalize performance and threat models and analyze the impact of post-quantum\nkey encapsulation and digital signatures on end-to-end DNS resolution.\nExperimental results on a containerized testbed reveal that lattice-based\nprimitives such as Module-Lattice-Based Key-Encapsulation Mechanism (MLKEM) and\nFalcon offer practical latency and resource profiles, while hash-based schemes\nlike SPHINCS+ significantly increase message sizes and processing overhead. We\nalso examine security implications including downgrade risks, fragmentation\nvulnerabilities, and susceptibility to denial-of-service amplification. Our\nfindings inform practical guidance for deploying quantum-resilient DNS and\ncontribute to the broader effort of securing core Internet protocols for the\npost-quantum future.", "AI": {"tldr": "该论文提出了一种名为PQC-DNS的统一框架，用于评估DNS在后量子时代的加密安全性，通过实验验证了多种后量子密码方案的性能与安全性。", "motivation": "随着量子计算机的发展，传统DNS协议在量子攻击面前显得脆弱，亟需研究如何保障DNS在后量子时代的机密性、真实性和完整性。", "method": "研究团队开发了PQC-DNS框架，整合了Open Quantum Safe库，在BIND9和TLS 1.3中实现了基于格和哈希的后量子密码方案，并通过容器化测试平台评估了性能与安全影响。", "result": "实验表明，基于格的MLKEM和Falcon方案具有实用的延迟和资源占用，而基于哈希的SPHINCS+则显著增加了消息大小和处理开销。研究还揭示了降级风险、分片漏洞等安全问题。", "conclusion": "该研究为部署抗量子DNS提供了实践指导，并为保障核心互联网协议在后量子时代的安全性做出了贡献。"}}
{"id": "2506.20351", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.20351", "abs": "https://arxiv.org/abs/2506.20351", "authors": ["Nithish Kumar R", "Vadiraja Bhatta G. R.", "Prasanna Poojary"], "title": "Enumeration of subsets with closedness in finite fields of characteristic 2", "comment": null, "summary": "The additive closedness in the subset of an additive group is termed as\nr-value. The nature of closedness in different subsets of fixed size is\nobserved as a spectrum of r-values. We enumerate r-values of subsets in finite\nfields of characteristic 2 and represent them as the spectrum of values. Based\non these values the subsets can be further studied as partial Steiner triple\nsystems, sum-free sets, Sidon sets, and Schure triples.", "AI": {"tldr": "本文研究了加法群子集中的加法封闭性（称为r值），在特征为2的有限域中枚举子集的r值并表示为值谱，进而分析其作为部分Steiner三元系、无和集、Sidon集及Schure三元组的性质。", "motivation": "探索加法群子集中不同大小子集的封闭性特征，通过r值谱揭示其内在结构特性，为组合数学中的特殊集合类型研究提供新视角。", "method": "在特征为2的有限域中系统枚举子集的r值，将封闭性量化为离散值谱，并关联至部分Steiner三元系等组合结构进行分析。", "result": "成功建立了有限域子集r值的计算框架，验证了r值谱与多种组合结构（如无和集、Sidon集）之间的对应关系。", "conclusion": "r值谱为理解加法封闭性提供了统一工具，未来可扩展至其他域特征及更复杂的组合系统研究。"}}
{"id": "2506.20332", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20332", "abs": "https://arxiv.org/abs/2506.20332", "authors": ["Jihao Gu", "Qihang Ai", "Yingyao Wang", "Pi Bu", "Jingxuan Xing", "Zekun Zhu", "Wei Jiang", "Ziming Wang", "Yingxiu Zhao", "Ming-Liang Zhang", "Jun Song", "Yuning Jiang", "Bo Zheng"], "title": "Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards", "comment": "14 pages, 12 figures", "summary": "Vision-language model-based mobile agents have gained the ability to not only\nunderstand complex instructions and mobile screenshots, but also optimize their\naction outputs via thinking and reasoning, benefiting from reinforcement\nlearning, such as Group Relative Policy Optimization (GRPO). However, existing\nresearch centers on offline reinforcement learning training or online\noptimization using action-level rewards, which limits the agent's dynamic\ninteraction with the environment. This often results in agents settling into\nlocal optima, thereby weakening their ability for exploration and error action\ncorrection. To address these challenges, we introduce an approach called\nMobile-R1, which employs interactive multi-turn reinforcement learning with\ntask-level rewards for mobile agents. Our training framework consists of three\nstages: initial format finetuning, single-step online training via action-level\nreward, followed by online training via task-level reward based on multi-turn\ntrajectories. This strategy is designed to enhance the exploration and error\ncorrection capabilities of Mobile-R1, leading to significant performance\nimprovements. Moreover, we have collected a dataset covering 28 Chinese\napplications with 24,521 high-quality manual annotations and established a new\nbenchmark with 500 trajectories. We will open source all resources, including\nthe dataset, benchmark, model weight, and codes:\nhttps://mobile-r1.github.io/Mobile-R1/.", "AI": {"tldr": "本文提出Mobile-R1方法，通过任务级奖励的多轮交互强化学习提升移动代理的探索与纠错能力，并开源了包含数据集、基准测试及模型权重的资源。", "motivation": "现有基于视觉语言模型的移动代理虽能理解复杂指令并优化动作输出，但因依赖离线强化学习或动作级奖励，导致环境交互受限，易陷入局部最优，探索与纠错能力不足。", "method": "提出三阶段训练框架：1)初始格式微调；2)基于动作级奖励的单步在线训练；3)基于多轮轨迹的任务级奖励在线训练，以增强代理的动态交互能力。", "result": "构建了覆盖28个中文应用的24,521条标注数据集及500条轨迹的基准测试，Mobile-R1性能显著提升，所有资源将开源。", "conclusion": "Mobile-R1通过任务级多轮强化学习有效解决了移动代理的局部最优问题，其开源资源将推动相关领域研究。"}}
{"id": "2506.20000", "categories": ["cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20000", "abs": "https://arxiv.org/abs/2506.20000", "authors": ["Narasimha Raghavan Veeraragavan", "Jan Franz Nygård"], "title": "Can One Safety Loop Guard Them All? Agentic Guard Rails for Federated Computing", "comment": "Accepted at ICML 2025 Workshop on Collaborative and Federated Agentic\n  Workflows (CFAgentic@ICML'25)", "summary": "We propose Guardian-FC, a novel two-layer framework for privacy preserving\nfederated computing that unifies safety enforcement across diverse privacy\npreserving mechanisms, including cryptographic back-ends like fully homomorphic\nencryption (FHE) and multiparty computation (MPC), as well as statistical\ntechniques such as differential privacy (DP). Guardian-FC decouples guard-rails\nfrom privacy mechanisms by executing plug-ins (modular computation units),\nwritten in a backend-neutral, domain-specific language (DSL) designed\nspecifically for federated computing workflows and interchangeable Execution\nProviders (EPs), which implement DSL operations for various privacy back-ends.\nAn Agentic-AI control plane enforces a finite-state safety loop through signed\ntelemetry and commands, ensuring consistent risk management and auditability.\nThe manifest-centric design supports fail-fast job admission and seamless\nextensibility to new privacy back-ends. We present qualitative scenarios\nillustrating backend-agnostic safety and a formal model foundation for\nverification. Finally, we outline a research agenda inviting the community to\nadvance adaptive guard-rail tuning, multi-backend composition, DSL\nspecification development, implementation, and compiler extensibility alongside\nhuman-override usability.", "AI": {"tldr": "Guardian-FC是一个新颖的双层框架，用于隐私保护的联邦计算，统一了多种隐私保护机制的安全执行，包括加密后端和统计技术。", "motivation": "为了解决联邦计算中隐私保护机制多样化和安全执行不一致的问题，提出了一个统一的安全框架。", "method": "框架采用两层设计，通过后端中立的领域特定语言（DSL）和执行提供者（EPs）解耦安全护栏与隐私机制，并由Agentic-AI控制平面强制执行安全循环。", "result": "Guardian-FC支持快速失败的任务准入和无缝扩展到新的隐私后端，并提供了形式化模型基础进行验证。", "conclusion": "论文提出了一个研究议程，邀请社区共同推进自适应护栏调优、多后端组合、DSL规范开发以及编译器可扩展性。"}}
{"id": "2506.20357", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20357", "abs": "https://arxiv.org/abs/2506.20357", "authors": ["Sungwon Han", "Sungkyu Park", "Seungeon Lee"], "title": "Tabular Feature Discovery With Reasoning Type Exploration", "comment": null, "summary": "Feature engineering for tabular data remains a critical yet challenging step\nin machine learning. Recently, large language models (LLMs) have been used to\nautomatically generate new features by leveraging their vast knowledge.\nHowever, existing LLM-based approaches often produce overly simple or\nrepetitive features, partly due to inherent biases in the transformations the\nLLM chooses and the lack of structured reasoning guidance during generation. In\nthis paper, we propose a novel method REFeat, which guides an LLM to discover\ndiverse and informative features by leveraging multiple types of reasoning to\nsteer the feature generation process. Experiments on 59 benchmark datasets\ndemonstrate that our approach not only achieves higher predictive accuracy on\naverage, but also discovers more diverse and meaningful features. These results\nhighlight the promise of incorporating rich reasoning paradigms and adaptive\nstrategy selection into LLM-driven feature discovery for tabular data.", "AI": {"tldr": "本文提出了一种名为REFeat的新方法，通过引导大型语言模型（LLM）利用多种推理类型生成多样且信息丰富的特征，解决了现有LLM方法在表格数据特征工程中生成特征过于简单或重复的问题。", "motivation": "当前基于LLM的表格数据特征生成方法存在生成特征过于简单或重复的问题，部分原因是LLM选择的转换存在固有偏差以及生成过程中缺乏结构化推理指导。", "method": "REFeat方法通过引导LLM利用多种推理类型（如因果推理、类比推理等）来指导特征生成过程，从而生成多样且信息丰富的特征。", "result": "在59个基准数据集上的实验表明，REFeat不仅平均预测准确率更高，而且能够发现更多样且更有意义的特征。", "conclusion": "这些结果凸显了将丰富的推理模式和自适应策略选择融入LLM驱动的表格数据特征发现中的潜力。"}}
{"id": "2506.20082", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20082", "abs": "https://arxiv.org/abs/2506.20082", "authors": ["Yali Yuan", "Weiyi Zou", "Guang Cheng"], "title": "Attack Smarter: Attention-Driven Fine-Grained Webpage Fingerprinting Attacks", "comment": null, "summary": "Website Fingerprinting (WF) attacks aim to infer which websites a user is\nvisiting by analyzing traffic patterns, thereby compromising user anonymity.\nAlthough this technique has been demonstrated to be effective in controlled\nexperimental environments, it remains largely limited to small-scale scenarios,\ntypically restricted to recognizing website homepages. In practical settings,\nhowever, users frequently access multiple subpages in rapid succession, often\nbefore previous content fully loads. WebPage Fingerprinting (WPF) generalizes\nthe WF framework to large-scale environments by modeling subpages of the same\nsite as distinct classes. These pages often share similar page elements,\nresulting in lower inter-class variance in traffic features. Furthermore, we\nconsider multi-tab browsing scenarios, in which a single trace encompasses\nmultiple categories of webpages. This leads to overlapping traffic segments,\nand similar features may appear in different positions within the traffic,\nthereby increasing the difficulty of classification. To address these\nchallenges, we propose an attention-driven fine-grained WPF attack, named\nADWPF. Specifically, during the training phase, we apply targeted augmentation\nto salient regions of the traffic based on attention maps, including attention\ncropping and attention masking. ADWPF then extracts low-dimensional features\nfrom both the original and augmented traffic and applies self-attention modules\nto capture the global contextual patterns of the trace. Finally, to handle the\nmulti-tab scenario, we employ the residual attention to generate class-specific\nrepresentations of webpages occurring at different temporal positions.\nExtensive experiments demonstrate that the proposed method consistently\nsurpasses state-of-the-art baselines across datasets of different scales.", "AI": {"tldr": "本文提出了一种名为ADWPF的注意力驱动细粒度网页指纹攻击方法，通过建模网站子页面为独立类别并处理多标签浏览场景，显著提升了大规模环境下的识别性能。", "motivation": "传统网站指纹攻击(WF)在实验环境中有效，但仅局限于识别主页，难以应对实际场景中用户快速访问多个子页面及多标签浏览的复杂情况。网页指纹(WPF)通过将子页面建模为独立类别扩展了WF框架，但面临类间差异小、流量段重叠等挑战。", "method": "ADWPF方法在训练阶段基于注意力图对流量显著区域进行针对性增强（注意力裁剪和掩蔽），从原始和增强流量中提取低维特征，并通过自注意力模块捕捉全局上下文模式。针对多标签场景，采用残差注意力生成不同时间位置网页的类别特定表示。", "result": "大量实验表明，ADWPF在不同规模的数据集上持续超越现有最先进基线方法，验证了其在大规模环境中的有效性。", "conclusion": "该研究通过注意力机制和针对性数据增强解决了网页指纹攻击中的关键挑战，为大规模实际场景中的用户匿名性保护提出了新的攻防研究方向。"}}
{"id": "2506.20556", "categories": ["math.CO", "05C69, 05D05, 05C35"], "pdf": "https://arxiv.org/pdf/2506.20556", "abs": "https://arxiv.org/abs/2506.20556", "authors": ["Philipp Heering"], "title": "On the Erdős-Ko-Rado problem of flags with type $\\{1, n-3 \\}$ of finite sets", "comment": null, "summary": "A flag of a finite set $S$ is a set $f$ of non-empty, proper subsets of $S$,\nsuch that $X\\subseteq Y$ or $Y\\subseteq X$ for all $X,Y\\in f$. Two flags $f_1$\nand $f_2$ of $S$ are opposite if $X_1\\cap X_2=\\emptyset$, or $X_1\\cup X_2=S$\nfor all $X_1\\in f_1$ and $X_2\\in f_2$. The set $\\{|X| \\mid X\\in f \\}$ is the\ntype of a flag $f$. A set of pairwise non-opposite flags is an\nErd\\H{o}s-Ko-Rado set. In 2022 Metsch posed the problem of determining the\nmaximum size of all Erd\\H{o}s-Ko-Rado sets of flags of type $T$ with $|T|=2$.\nWe contribute towards this by determining the maximum size for flags of type\n$\\{ 1,n-3\\}$ for finite sets with $n$ elements. Furthermore we answer an open\nquestions of Metsch regarding a small case.", "AI": {"tldr": "本文研究了有限集合上特定类型标志的最大非对立Erd\\H{o}s-Ko-Rado集的大小，解决了Metsch提出的关于类型$\\{1,n-3\\}$标志的一个开放问题。", "motivation": "Metsch在2022年提出了确定类型$T$且$|T|=2$的标志的最大非对立Erd\\H{o}s-Ko-Rado集大小的问题，本文旨在为此问题做出贡献。", "method": "通过分析有限集合上类型为$\\{1,n-3\\}$的标志的性质，研究了非对立标志集的最大可能大小。", "result": "确定了具有$n$个元素的有限集合上类型为$\\{1,n-3\\}$的标志的最大非对立Erd\\H{o}s-Ko-Rado集的大小，并回答了Metsch提出的一个小规模案例的开放问题。", "conclusion": "本研究为理解标志的非对立Erd\\H{o}s-Ko-Rado集的最大规模提供了新的见解，特别是对于类型$\\{1,n-3\\}$的标志，解决了相关开放问题。"}}
{"id": "2506.20384", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20384", "abs": "https://arxiv.org/abs/2506.20384", "authors": ["Dror Ivry", "Oran Nahum"], "title": "Paladin-mini: A Compact and Efficient Grounding Model Excelling in Real-World Scenarios", "comment": "6 pages, 2 figures", "summary": "This paper introduces two significant contributions to address the issue of\ngrounding claims in a given context. Grounding means that given a context\n(document) and a claim, there's at least one supportive evidence for the claim\nin the document. We will introduce Paladin-mini, a compact (3.8B parameters)\nopen-source classifier model (used for labeling data as grounded or ungrounded)\nengineered for robust performance in real-world scenarios, and the\ngrounding-benchmark, a new evaluation dataset designed to assess performance on\ncritical reasoning tasks. We'll also demonstrate the results of Paladin-mini\nwith benchmarks against the current State-of-the-art and share clear and\nreproducible results.", "AI": {"tldr": "本文提出了Paladin-mini（3.8B参数的开源分类模型）和grounding-benchmark评估数据集，用于解决上下文中的声明验证问题，并展示了其与当前最先进技术的对比结果。", "motivation": "研究动机是解决在给定上下文中验证声明是否有支持证据的问题（即声明接地问题），这对现实场景中的关键推理任务至关重要。", "method": "方法包括：1) 开发紧凑型开源分类模型Paladin-mini（3.8B参数）；2) 构建新的评估数据集grounding-benchmark；3) 与现有最优模型进行基准测试对比。", "result": "实验结果表明Paladin-mini在真实场景中表现稳健，论文提供了清晰可复现的基准测试结果。", "conclusion": "Paladin-mini和grounding-benchmark为声明接地问题提供了有效的解决方案和评估标准，其紧凑模型设计尤其适合实际应用部署。"}}
{"id": "2506.20101", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.20101", "abs": "https://arxiv.org/abs/2506.20101", "authors": ["Jiahui Wu", "Tiecheng Sun", "Fucai Luo", "Haiyan Wang", "Weizhe Zhang"], "title": "Secure Multi-Key Homomorphic Encryption with Application to Privacy-Preserving Federated Learning", "comment": null, "summary": "Multi-Key Homomorphic Encryption (MKHE), proposed by Lopez-Alt et al. (STOC\n2012), allows for performing arithmetic computations directly on ciphertexts\nencrypted under distinct keys. Subsequent works by Chen and Dai et al. (CCS\n2019) and Kim and Song et al. (CCS 2023) extended this concept by proposing\nmulti-key BFV/CKKS variants, referred to as the CDKS scheme. These variants\nincorporate asymptotically optimal techniques to facilitate secure computation\nacross multiple data providers. In this paper, we identify a critical security\nvulnerability in the CDKS scheme when applied to multiparty secure computation\ntasks, such as privacy-preserving federated learning (PPFL). In particular, we\nshow that CDKS may inadvertently leak plaintext information from one party to\nothers. To mitigate this issue, we propose a new scheme, SMHE (Secure Multi-Key\nHomomorphic Encryption), which incorporates a novel masking mechanism into the\nmulti-key BFV and CKKS frameworks to ensure that plaintexts remain confidential\nthroughout the computation. We implement a PPFL application using SMHE and\ndemonstrate that it provides significantly improved security with only a modest\noverhead in homomorphic evaluation. For instance, our PPFL model based on\nmulti-key CKKS incurs less than a 2\\times runtime and communication traffic\nincrease compared to the CDKS-based PPFL model. The code is publicly available\nat https://github.com/JiahuiWu2022/SMHE.git.", "AI": {"tldr": "本文发现多密钥同态加密方案CDKS在多方安全计算中存在安全漏洞，可能导致明文信息泄露。作者提出新型安全方案SMHE，通过引入掩蔽机制增强保密性，并在隐私保护联邦学习中验证其高效性。", "motivation": "CDKS方案在隐私保护联邦学习等场景中意外泄露参与者明文数据，亟需设计能保障跨方计算机密性的新型多密钥同态加密框架。", "method": "在BFV/CKKS多密钥框架中嵌入创新性掩蔽机制，构建SMHE方案。基于该方案实现隐私保护联邦学习应用，并量化评估性能开销。", "result": "实验表明：基于多密钥CKKS的SMHE方案仅带来不足2倍的运行时与通信开销增长，较CDKS方案显著提升安全性。代码已开源。", "conclusion": "SMHE方案成功解决了CDKS的明文泄露缺陷，以可接受性能代价为多方安全计算提供更强保密保障，具有实际部署价值。"}}
{"id": "2506.20613", "categories": ["math.CO", "05A05, 05A15, 05A16, 05C05, 06B05, 05C80, 05D40, 60C05"], "pdf": "https://arxiv.org/pdf/2506.20613", "abs": "https://arxiv.org/abs/2506.20613", "authors": ["Boris Pittel"], "title": "On likelihood of a Condorcet winner for uniformly random and independent voter preferences", "comment": null, "summary": "We study a mathematical model of voting contest with $m$ voters and $n$\ncandidates, with each voter ranking the candidates in order of preference,\nwithout ties. A Condorcet winner is a candidate who gets more than $m/2$ votes\nin pairwise contest with every other candidate. An ``impartial culture''\nsetting is the case when each voter chooses his/her candidate preference list\nuniformly at random from all $n!$ preferences, and does it independently of all\nother voters. For impartial culture case, Robert May and Lisa Sauermann showed\nthat when $m=2k-1$ is fixed ($k=2$ and $k>2$ respectively), and $n$ grows\nindefinitely, the probability of a Condorcet winner is small, of order\n$n^{-(k-1)/k}$. We show that when $m$ grows indefinitely and $m\\gg n^4$, the\nprobability of a Condercet winner is $1-O(n^2/m^{1/2})\\to 1$.", "AI": {"tldr": "研究投票竞赛模型，证明当选民数$m$远大于候选人数$n$的四次方时，存在Condorcet赢家的概率趋近于1。", "motivation": "探讨在选民偏好随机且独立的情况下，Condorcet赢家出现的概率，扩展了Robert May和Lisa Sauermann关于固定选民数$m$的研究。", "method": "使用数学建模分析投票竞赛，假设选民偏好服从\"公正文化\"（impartial culture）分布，即每个选民独立且均匀随机地从所有$n!$种偏好中选择。", "result": "当选民数$m$无限增长且$m\\gg n^4$时，存在Condorcet赢家的概率为$1-O(n^2/m^{1/2})\\to 1$。", "conclusion": "在选民数远大于候选人数四次方的条件下，几乎必然存在Condorcet赢家，这与固定选民数时的低概率形成鲜明对比。"}}
{"id": "2506.20401", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20401", "abs": "https://arxiv.org/abs/2506.20401", "authors": ["Jinchun Du", "Bojie Shen", "Muhammad Aamir Cheema", "Adel N. Toosi"], "title": "Smart Ride and Delivery Services with Electric Vehicles: Leveraging Bidirectional Charging for Profit Optimisation", "comment": null, "summary": "With the rising popularity of electric vehicles (EVs), modern service\nsystems, such as ride-hailing delivery services, are increasingly integrating\nEVs into their operations. Unlike conventional vehicles, EVs often have a\nshorter driving range, necessitating careful consideration of charging when\nfulfilling requests. With recent advances in Vehicle-to-Grid (V2G) technology -\nallowing EVs to also discharge energy back to the grid - new opportunities and\ncomplexities emerge. We introduce the Electric Vehicle Orienteering Problem\nwith V2G (EVOP-V2G): a profit-maximization problem where EV drivers must select\ncustomer requests or orders while managing when and where to charge or\ndischarge. This involves navigating dynamic electricity prices, charging\nstation selection, and route constraints. We formulate the problem as a Mixed\nInteger Programming (MIP) model and propose two near-optimal metaheuristic\nalgorithms: one evolutionary (EA) and the other based on large neighborhood\nsearch (LNS). Experiments on real-world data show our methods can double driver\nprofits compared to baselines, while maintaining near-optimal performance on\nsmall instances and excellent scalability on larger ones. Our work highlights a\npromising path toward smarter, more profitable EV-based mobility systems that\nactively support the energy grid.", "AI": {"tldr": "本文提出电动汽车定向问题与车网互动（EVOP-V2G）模型，通过混合整数规划和元启发式算法优化电动车司机的利润，实验显示该方法可显著提升收益并支持电网。", "motivation": "随着电动车在共享出行中的普及，其续航短和充电管理问题日益突出。车网互动（V2G）技术带来新机遇，但也增加了运营复杂性，需开发智能调度方案以最大化司机利润。", "method": "建立混合整数规划（MIP）模型，提出两种近优元启发式算法：进化算法（EA）和大邻域搜索（LNS），以动态电价、充电站选择和路径约束为变量进行优化。", "result": "真实数据实验表明，相比基线方法，该算法可使司机利润翻倍，在小规模实例中接近最优解，且在大规模实例中展现出色扩展性。", "conclusion": "研究为电动车智能调度系统提供了高效解决方案，既能提升司机收益，又能通过V2G技术主动支持电网，推动可持续交通发展。"}}
{"id": "2506.20102", "categories": ["cs.CR", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.20102", "abs": "https://arxiv.org/abs/2506.20102", "authors": ["Malikussaid", "Sutiyo"], "title": "Autonomous Cyber Resilience via a Co-Evolutionary Arms Race within a Fortified Digital Twin Sandbox", "comment": "17 pages, 2 figures, 4 equations, 2 algorithms, 4 tables, to be\n  published in ISPACS Conference 2025, unabridged version", "summary": "The convergence of IT and OT has created hyper-connected ICS, exposing\ncritical infrastructure to a new class of adaptive, intelligent adversaries\nthat render static defenses obsolete. Existing security paradigms often fail to\naddress a foundational \"Trinity of Trust,\" comprising the fidelity of the\nsystem model, the integrity of synchronizing data, and the resilience of the\nanalytical engine against sophisticated evasion. This paper introduces the ARC\nframework, a method for achieving analytical resilience through an autonomous,\nclosed-loop hardening process. ARC establishes a perpetual co-evolutionary arms\nrace within the high-fidelity sandbox of a F-SCDT. A DRL agent, the \"Red\nAgent,\" is formalized and incentivized to autonomously discover stealthy,\nphysically-plausible attack paths that maximize process disruption while\nevading detection. Concurrently, an ensemble-based \"Blue Agent\" defender is\ncontinuously hardened via adversarial training against the evolving threats\ndiscovered by its adversary. This co-evolutionary dynamic forces both agents to\nbecome progressively more sophisticated, enabling the system to autonomously\nprobe and patch its own vulnerabilities. Experimental validation on both the\nTEP and the SWaT testbeds demonstrates the framework's superior performance. A\ncomprehensive ablation study, supported by extensive visualizations including\nROC curves and SHAP plots, reveals that the co-evolutionary process itself is\nresponsible for a significant performance increase in detecting novel attacks.\nBy integrating XAI to ensure operator trust and proposing a scalable F-ARC\narchitecture, this work presents ARC not merely as an improvement, but as a\nnecessary paradigm shift toward dynamic, self-improving security for the future\nof critical infrastructure.", "AI": {"tldr": "论文提出ARC框架，通过红蓝代理的协同进化机制实现工业控制系统动态安全防御，实验证明其能有效检测新型攻击并自主修补漏洞。", "motivation": "IT与OT融合导致关键基础设施面临新型自适应攻击，传统静态防御失效，需建立涵盖系统模型、数据同步和分析引擎弹性的'信任三位一体'新范式。", "method": "采用深度强化学习(DRL)训练'红代理'自主发现隐蔽攻击路径，同时通过对抗训练强化'蓝代理'防御能力，在F-SCDT沙箱中形成持续进化的攻防体系。", "result": "在TEP和SWaT测试平台验证中，协同进化机制使攻击检测性能显著提升（ROC曲线和SHAP图佐证），F-ARC架构兼具可解释性(XAI)与可扩展性。", "conclusion": "ARC框架代表从静态防御到动态自主安全范式的根本转变，为关键基础设施提供持续自我强化的安全保障机制。"}}
{"id": "2506.20656", "categories": ["math.CO", "05C57, 05C63, 05A05"], "pdf": "https://arxiv.org/pdf/2506.20656", "abs": "https://arxiv.org/abs/2506.20656", "authors": ["Ryota Inagaki", "Tanya Khovanova", "Austin Luo"], "title": "Labeled Chip-Firing on Directed $k$-ary Trees and Where Chips Land", "comment": "24 pages, 4 figures, 2 tables", "summary": "Chip-firing is a combinatorial game played on a graph, in which chips are\nplaced and dispersed on the vertices until a stable configuration is achieved.\nWe study a chip-firing variant on an infinite, rooted directed $k$-ary tree,\nwhere we place $k^n$ chips labeled $1,2,3,\\dots, k^n$ on the root for some\nnonnegative integer $n$. A vertex $v$ can fire if it has at least $k$ chips;\nwhen it fires, $k$ chips are selected, and the chip with the $i$th smallest\nlabel is sent to the $i$th leftmost child of $v$. A stable configuration is\nreached when no vertices can fire. In this paper, we prove numerous properties\nof the stable configuration, such as that chips land on vertices in ranges and\nthe lengths of those ranges. We also describe where each chip can land. This\nhelps us describe possible stable configurations of the game.", "AI": {"tldr": "研究无限有根k叉树上的筹码博弈变体，分析稳定配置中筹码分布规律及范围长度特性。", "motivation": "探索无限有根k叉树上特定筹码分配规则下的稳定状态性质，扩展组合博弈理论的应用场景。", "method": "在根节点放置$k^n$个标记筹码，定义顶点触发规则（选择第i小筹码发送至第i左子树），直至达到稳定状态。", "result": "证明了稳定配置中筹码呈区间分布的特性，精确描述了各筹码的可能落点范围及其长度关系。", "conclusion": "该研究为无限树结构上的组合博弈提供了稳定状态分析框架，揭示了筹码传递的规律性模式。"}}
{"id": "2506.20404", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20404", "abs": "https://arxiv.org/abs/2506.20404", "authors": ["Riccardo Lo Bianco", "Willem van Jaarsveld", "Remco Dijkman"], "title": "GymPN: A Library for Decision-Making in Process Management Systems", "comment": null, "summary": "Process management systems support key decisions about the way work is\nallocated in organizations. This includes decisions on which task to perform\nnext, when to execute the task, and who to assign the task to. Suitable\nsoftware tools are required to support these decisions in a way that is optimal\nfor the organization. This paper presents a software library, called GymPN,\nthat supports optimal decision-making in business processes using Deep\nReinforcement Learning. GymPN builds on previous work that supports task\nassignment in business processes, introducing two key novelties: support for\npartial process observability and the ability to model multiple decisions in a\nbusiness process. These novel elements address fundamental limitations of\nprevious work and thus enable the representation of more realistic process\ndecisions. We evaluate the library on eight typical business process\ndecision-making problem patterns, showing that GymPN allows for easy modeling\nof the desired problems, as well as learning optimal decision policies.", "AI": {"tldr": "本文介绍了一个名为GymPN的软件库，利用深度强化学习优化业务流程中的决策制定，解决了部分流程可观察性和多决策建模的关键问题。", "motivation": "业务流程管理系统需要优化任务分配、执行时机和人员指派等关键决策，现有工具在支持这些决策时存在局限性。", "method": "GymPN基于深度强化学习，新增了对部分流程可观察性和多决策建模的支持，突破了以往工作的限制。", "result": "在八种典型业务流程决策问题模式上的评估表明，GymPN能轻松建模目标问题并学习最优决策策略。", "conclusion": "GymPN通过创新性地解决部分可观察性和多决策问题，为业务流程提供了更贴近现实的决策支持工具。"}}
{"id": "2506.20109", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.20109", "abs": "https://arxiv.org/abs/2506.20109", "authors": ["Lambang Akbar Wijayadi", "Yuancheng Jiang", "Roland H. C. Yap", "Zhenkai Liang", "Zhuohao Liu"], "title": "Evaluating Disassembly Errors With Only Binaries", "comment": null, "summary": "Disassemblers are crucial in the analysis and modification of binaries.\nExisting works showing disassembler errors largely rely on practical\nimplementation without specific guarantees and assume source code and compiler\ntoolchains to evaluate ground truth. However, the assumption of source code is\ncontrary to typical binary scenarios where only the binary is available. In\nthis work, we investigate an approach with minimal assumptions and a sound\napproach to disassembly error evaluation that does not require source code. Any\nsource code does not address the fundamental problem of binary disassembly and\nfails when only the binary exists. As far as we know, this is the first work to\nevaluate disassembly errors using only the binary. We propose TraceBin, which\nuses dynamic execution to find disassembly errors. TraceBin targets the use\ncase where the disassembly is used in an automated fashion for security tasks\non a target binary, such as static binary instrumentation, binary hardening,\nautomated code repair, and so on, which may be affected by disassembly errors.\nDiscovering disassembly errors in the target binary aids in reducing problems\ncaused by such errors. Furthermore, we are not aware of existing approaches\nthat can evaluate errors given only a target binary, as they require source\ncode. Our evaluation shows TraceBin finds: (i) errors consistent with existing\nstudies even without source; (ii) disassembly errors due to control flow; (iii)\nnew interesting errors; (iv) errors in non-C/C++ binaries; (v) errors in\nclosed-source binaries; and (vi) show that disassembly errors can have\nsignificant security implications. Overall, our experimental results show that\nTraceBin finds many errors in existing popular disassemblers. It is also\nhelpful in automated security tasks on (closed source) binaries relying on\ndisassemblers.", "AI": {"tldr": "本文提出了TraceBin，一种仅需二进制文件即可评估反汇编错误的新方法，无需源代码假设，通过动态执行发现错误，显著提升自动化安全任务的可靠性。", "motivation": "现有反汇编错误研究依赖源代码和编译器工具链，与仅有二进制文件的现实场景矛盾。TraceBin旨在解决这一根本问题，首次实现无源码条件下的反汇编错误评估。", "method": "TraceBin采用动态执行技术定位反汇编错误，专注于自动化安全任务（如静态插桩、二进制加固）中的错误检测，通过目标二进制自身揭示潜在问题。", "result": "实验表明TraceBin能发现：(i)与现有研究一致的无源码错误；(ii)控制流导致的反汇编错误；(iii)新型错误；(iv)非C/C++二进制错误；(v)闭源二进制错误；(vi)证明错误可能导致重大安全隐患。", "conclusion": "TraceBin在主流反汇编器中检出大量错误，尤其适用于依赖反汇编的（闭源）二进制文件自动化安全任务，填补了无源码评估的技术空白。"}}
{"id": "2506.20669", "categories": ["math.CO", "91A46 (Primary) 05C57, 05C75, 05C60 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.20669", "abs": "https://arxiv.org/abs/2506.20669", "authors": ["Rylo Ashmore", "Beth Ann Austin", "Alfie M. Davies", "Danny Dyer", "William Kellough"], "title": "On graph automorphisms related to Snort", "comment": "30 pages, 9 figures", "summary": "We study the outcomes of various positions of the game Snort. When played on\ngraphs admitting an automorphism of order two that maps vertices outside of\ntheir closed neighbourhoods (called opposable graphs), the second player has a\nwinning strategy. We give a necessary and sufficient condition for a graph to\nbe opposable, and prove that the property of being opposable is preserved by\nseveral graph products. We show examples that a graph being second-player win\ndoes not imply that the graph is opposable, which answers Kakihara's\nconjecture. We give an analogous definition to opposability, which gives a\nfirst-player winning strategy; we prove a necessary condition for this property\nto be preserved by the Cartesian and strong products. As an application of our\nresults, we determine the outcome of Snort when played on various $n\\times m$\nchess graphs.", "AI": {"tldr": "研究了Snort游戏中不同图位置的胜负结果，提出了可反对图的概念并给出了其充要条件，证明了该性质在多种图积下的保持性，回答了Kakihara猜想，并应用结果确定了多种$n\\times m$棋盘图的Snort游戏胜负。", "motivation": "探讨Snort游戏中图的性质与胜负策略之间的关系，特别是通过图的自同构性质来研究第二玩家的必胜策略。", "method": "定义了可反对图的概念，给出了其充要条件，并研究了该性质在图积操作下的保持性；同时提出了类似定义以研究第一玩家的必胜策略。", "result": "证明了可反对性在多种图积下保持，给出了第二玩家必胜但图不可反对的反例（回答了Kakihara猜想），并确定了多种棋盘图上的Snort游戏结果。", "conclusion": "通过图的自同构性质可以有效分析Snort游戏的胜负策略，可反对性及其推广定义为此类组合游戏研究提供了新工具，棋盘图的应用展示了理论的实际价值。"}}
{"id": "2506.20486", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20486", "abs": "https://arxiv.org/abs/2506.20486", "authors": ["Salvatore Milite", "Giulio Caravagna", "Andrea Sottoriva"], "title": "Mixtures of Neural Cellular Automata: A Stochastic Framework for Growth Modelling and Self-Organization", "comment": null, "summary": "Neural Cellular Automata (NCAs) are a promising new approach to model\nself-organizing processes, with potential applications in life science.\nHowever, their deterministic nature limits their ability to capture the\nstochasticity of real-world biological and physical systems.\n  We propose the Mixture of Neural Cellular Automata (MNCA), a novel framework\nincorporating the idea of mixture models into the NCA paradigm. By combining\nprobabilistic rule assignments with intrinsic noise, MNCAs can model diverse\nlocal behaviors and reproduce the stochastic dynamics observed in biological\nprocesses.\n  We evaluate the effectiveness of MNCAs in three key domains: (1) synthetic\nsimulations of tissue growth and differentiation, (2) image morphogenesis\nrobustness, and (3) microscopy image segmentation. Results show that MNCAs\nachieve superior robustness to perturbations, better recapitulate real\nbiological growth patterns, and provide interpretable rule segmentation. These\nfindings position MNCAs as a promising tool for modeling stochastic dynamical\nsystems and studying self-growth processes.", "AI": {"tldr": "本文提出混合神经细胞自动机（MNCA），通过引入概率规则和固有噪声，增强了对生物系统随机性的建模能力，在组织生长、图像形态生成和显微镜图像分割中表现出优越性能。", "motivation": "传统神经细胞自动机（NCA）的确定性限制了其对真实生物物理系统随机性的建模能力，需要开发能捕捉随机动态的新框架。", "method": "将混合模型思想融入NCA范式，结合概率规则分配和固有噪声，构建MNCA框架以模拟多样化局部行为和生物随机过程。", "result": "MNCA在组织生长模拟、图像形态生成鲁棒性和显微镜图像分割中展现出更强的抗干扰能力、更真实的生物生长模式复现及可解释的规则分割。", "conclusion": "MNCA作为建模随机动力系统的有力工具，为自生长过程研究提供了新途径，在生命科学领域具有应用潜力。"}}
{"id": "2506.20170", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.20170", "abs": "https://arxiv.org/abs/2506.20170", "authors": ["Guoqiang Chen", "Xin Jin", "Zhiqiang Lin"], "title": "JsDeObsBench: Measuring and Benchmarking LLMs for JavaScript Deobfuscation", "comment": "Accepted by ACM CCS 2025", "summary": "Deobfuscating JavaScript (JS) code poses a significant challenge in web\nsecurity, particularly as obfuscation techniques are frequently used to conceal\nmalicious activities within scripts. While Large Language Models (LLMs) have\nrecently shown promise in automating the deobfuscation process, transforming\ndetection and mitigation strategies against these obfuscated threats, a\nsystematic benchmark to quantify their effectiveness and limitations has been\nnotably absent. To address this gap, we present JsDeObsBench, a dedicated\nbenchmark designed to rigorously evaluate the effectiveness of LLMs in the\ncontext of JS deobfuscation. We detail our benchmarking methodology, which\nincludes a wide range of obfuscation techniques ranging from basic variable\nrenaming to sophisticated structure transformations, providing a robust\nframework for assessing LLM performance in real-world scenarios. Our extensive\nexperimental analysis investigates the proficiency of cutting-edge LLMs, e.g.,\nGPT-4o, Mixtral, Llama, and DeepSeek-Coder, revealing superior performance in\ncode simplification despite challenges in maintaining syntax accuracy and\nexecution reliability compared to baseline methods. We further evaluate the\ndeobfuscation of JS malware to exhibit the potential of LLMs in security\nscenarios. The findings highlight the utility of LLMs in deobfuscation\napplications and pinpoint crucial areas for further improvement.", "AI": {"tldr": "本文介绍了JsDeObsBench基准测试，用于系统评估大型语言模型（LLM）在JavaScript反混淆任务中的表现，揭示了LLM在代码简化方面的优势及在语法准确性和执行可靠性上的挑战。", "motivation": "JavaScript混淆技术常被用于隐藏恶意代码，而现有研究缺乏对LLM反混淆能力的系统评估。本文旨在填补这一空白，量化LLM在反混淆任务中的效果与局限。", "method": "研究团队构建了JsDeObsBench基准，涵盖从基础变量重命名到复杂结构变换的多种混淆技术，并测试了GPT-4o、Mixtral、Llama和DeepSeek-Coder等前沿LLM模型。", "result": "实验表明LLM在代码简化方面表现优异，但在保持语法准确性和执行可靠性上仍存在挑战。在JS恶意软件反混淆任务中，LLM展现出安全应用潜力。", "conclusion": "研究证实了LLM在反混淆应用中的实用性，同时指出了关键改进方向，为后续研究提供了重要基准。"}}
{"id": "2506.20504", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2506.20504", "abs": "https://arxiv.org/abs/2506.20504", "authors": ["Konstantin Demin", "Taylor Webb", "Eric Elmoznino", "Hakwan Lau"], "title": "Engineering Sentience", "comment": null, "summary": "We spell out a definition of sentience that may be useful for designing and\nbuilding it in machines. We propose that for sentience to be meaningful for AI,\nit must be fleshed out in functional, computational terms, in enough detail to\nallow for implementation. Yet, this notion of sentience must also reflect\nsomething essentially 'subjective', beyond just having the general capacity to\nencode perceptual content. For this specific functional notion of sentience to\noccur, we propose that certain sensory signals need to be both assertoric\n(persistent) and qualitative. To illustrate the definition in more concrete\nterms, we sketch out some ways for potential implementation, given current\ntechnology. Understanding what it takes for artificial agents to be\nfunctionally sentient can also help us avoid creating them inadvertently, or at\nleast, realize that we have created them in a timely manner.", "AI": {"tldr": "本文提出了一个适用于机器设计的感知定义，强调功能性计算实现与主观体验的结合，并探讨了潜在实现方法。", "motivation": "研究旨在为AI设计有意义的感知能力，避免无意中创造具有感知的人工智能，并及时识别其存在。", "method": "提出感知需具备断言性（持久性）与质性特征，并结合当前技术勾勒可能的实现路径。", "result": "构建了功能性感知的理论框架，说明特定感官信号需满足双重特性才能实现人工感知。", "conclusion": "明确人工代理功能性感知的实现条件，既有助于定向开发，也能预警非预期感知体的产生。"}}
{"id": "2506.20228", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.20228", "abs": "https://arxiv.org/abs/2506.20228", "authors": ["Antony Dalmiere", "Zheng Zhou", "Guillaume Auriol", "Vincent Nicomette", "Pascal Marchand"], "title": "Measuring Modern Phishing Tactics: A Quantitative Study of Body Obfuscation Prevalence, Co-occurrence, and Filter Impact", "comment": null, "summary": "Phishing attacks frequently use email body obfuscation to bypass detection\nfilters, but quantitative insights into how techniques are combined and their\nimpact on filter scores remain limited. This paper addresses this gap by\nempirically investigating the prevalence, co-occurrence patterns, and spam\nscore associations of body obfuscation techniques. Analysing 386 verified\nphishing emails, we quantified ten techniques, identified significant pairwise\nco-occurrences revealing strategic layering like the presence of text in images\nwith multipart abuse, and assessed associations with antispam scores using\nmultilinear regression. Text in Image (47.0%), Base64 Encoding (31.2%), and\nInvalid HTML (28.8%) were highly prevalent. Regression (R${}^2$=0.486, p<0.001)\nlinked Base64 Encoding and Text in Image with significant antispam evasion\n(p<0.05) in this configuration, suggesting potential bypass capabilities, while\nInvalid HTML correlated with higher scores. These findings establish a\nquantitative baseline for complex evasion strategies, underscoring the need for\nmulti-modal defences against combined obfuscation tactics.", "AI": {"tldr": "研究通过分析386封钓鱼邮件，量化了十种邮件正文混淆技术，发现Base64编码和图片藏文显著关联反垃圾邮件规避能力，为复合混淆策略提供了量化基准。", "motivation": "钓鱼攻击常使用邮件正文混淆技术绕过检测，但缺乏对这些技术组合方式及其对过滤器评分影响的定量研究。", "method": "实证分析386封已验证钓鱼邮件，统计十种混淆技术流行度与共现模式，并采用多元线性回归评估其与反垃圾邮件评分的关联性。", "result": "图片藏文(47.0%)、Base64编码(31.2%)和无效HTML(28.8%)最普遍；回归模型(R${}^2$=0.486, p<0.001)显示Base64编码和图片藏文组合显著降低反垃圾评分(p<0.05)，而无效HTML则与更高评分相关。", "conclusion": "研究确立了复合混淆策略的量化基准，表明需要针对组合式混淆技术开发多模态防御方案。"}}
{"id": "2506.20531", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.20531", "abs": "https://arxiv.org/abs/2506.20531", "authors": ["Wenbin Gan", "Minh-Son Dao", "Koji Zettsu"], "title": "Case-based Reasoning Augmented Large Language Model Framework for Decision Making in Realistic Safety-Critical Driving Scenarios", "comment": "12 pages, 10 figures, under-review conference", "summary": "Driving in safety-critical scenarios requires quick, context-aware\ndecision-making grounded in both situational understanding and experiential\nreasoning. Large Language Models (LLMs), with their powerful general-purpose\nreasoning capabilities, offer a promising foundation for such decision-making.\nHowever, their direct application to autonomous driving remains limited due to\nchallenges in domain adaptation, contextual grounding, and the lack of\nexperiential knowledge needed to make reliable and interpretable decisions in\ndynamic, high-risk environments. To address this gap, this paper presents a\nCase-Based Reasoning Augmented Large Language Model (CBR-LLM) framework for\nevasive maneuver decision-making in complex risk scenarios. Our approach\nintegrates semantic scene understanding from dashcam video inputs with the\nretrieval of relevant past driving cases, enabling LLMs to generate maneuver\nrecommendations that are both context-sensitive and human-aligned. Experiments\nacross multiple open-source LLMs show that our framework improves decision\naccuracy, justification quality, and alignment with human expert behavior.\nRisk-aware prompting strategies further enhance performance across diverse risk\ntypes, while similarity-based case retrieval consistently outperforms random\nsampling in guiding in-context learning. Case studies further demonstrate the\nframework's robustness in challenging real-world conditions, underscoring its\npotential as an adaptive and trustworthy decision-support tool for intelligent\ndriving systems.", "AI": {"tldr": "本文提出了一种基于案例推理增强的大型语言模型（CBR-LLM）框架，用于复杂风险场景下的紧急避障决策，通过结合语义场景理解和历史驾驶案例检索，提升决策准确性和可解释性。", "motivation": "安全关键场景下的驾驶需要快速、基于情境的决策，但现有大型语言模型（LLM）在领域适应、情境接地和缺乏经验知识方面存在局限，难以在动态高风险环境中做出可靠决策。", "method": "提出CBR-LLM框架，整合行车记录仪视频的语义场景理解与历史驾驶案例检索，利用风险感知提示策略和相似性案例检索增强LLM的上下文学习能力。", "result": "实验表明，该框架显著提高了决策准确性、理由质量以及与人类专家行为的一致性，相似性案例检索在上下文学习中优于随机采样。", "conclusion": "案例研究验证了框架在真实复杂场景中的鲁棒性，表明其可作为智能驾驶系统的自适应、可信赖决策支持工具。"}}
{"id": "2506.20234", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.20234", "abs": "https://arxiv.org/abs/2506.20234", "authors": ["Quentin Hillebrand", "Vorapong Suppakitpaisarn", "Tetsuo Shibuya"], "title": "Communication-Efficient Publication of Sparse Vectors under Differential Privacy", "comment": null, "summary": "In this work, we propose a differentially private algorithm for publishing\nmatrices aggregated from sparse vectors. These matrices include social network\nadjacency matrices, user-item interaction matrices in recommendation systems,\nand single nucleotide polymorphisms (SNPs) in DNA data. Traditionally,\ndifferential privacy in vector collection relies on randomized response, but\nthis approach incurs high communication costs. Specifically, for a matrix with\n$N$ users, $n$ columns, and $m$ nonzero elements, conventional methods require\n$\\Omega(n \\times N)$ communication, making them impractical for large-scale\ndata. Our algorithm significantly reduces this cost to $O(\\varepsilon m)$,\nwhere $\\varepsilon$ is the privacy budget. Notably, this is even lower than the\nnon-private case, which requires $\\Omega(m \\log n)$ communication. Moreover, as\nthe privacy budget decreases, communication cost further reduces, enabling\nbetter privacy with improved efficiency. We theoretically prove that our method\nyields results identical to those of randomized response, and experimental\nevaluations confirm its effectiveness in terms of accuracy, communication\nefficiency, and computational complexity.", "AI": {"tldr": "本文提出一种差分隐私算法，用于发布稀疏向量聚合矩阵，显著降低通信成本至$O(\\varepsilon m)$，优于传统随机响应方法的$\\Omega(n \\times N)$，且在隐私预算$\\varepsilon$降低时效率更高。", "motivation": "传统差分隐私方法（如随机响应）在处理稀疏向量聚合矩阵（如社交网络邻接矩阵、推荐系统用户-物品交互矩阵）时通信成本过高（$\\Omega(n \\times N)$），难以适用于大规模数据。", "method": "设计了一种新型差分隐私算法，通过优化通信机制将成本降至$O(\\varepsilon m)$，并证明其输出结果与随机响应方法等效。", "result": "理论分析与实验验证表明，该算法在精度、通信效率（成本低于非隐私场景的$\\Omega(m \\log n)$）和计算复杂度方面均表现优异，且隐私预算降低时效率进一步提升。", "conclusion": "该算法实现了隐私保护与效率的平衡，为稀疏矩阵的差分隐私发布提供了实用解决方案，尤其适用于大规模数据场景。"}}
{"id": "2506.20598", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.20598", "abs": "https://arxiv.org/abs/2506.20598", "authors": ["Alexander D. Kalian", "Jaewook Lee", "Stefan P. Johannesson", "Lennart Otte", "Christer Hogstrand", "Miao Guo"], "title": "Fine-Tuning and Prompt Engineering of LLMs, for the Creation of Multi-Agent AI for Addressing Sustainable Protein Production Challenges", "comment": null, "summary": "The global demand for sustainable protein sources has accelerated the need\nfor intelligent tools that can rapidly process and synthesise domain-specific\nscientific knowledge. In this study, we present a proof-of-concept multi-agent\nArtificial Intelligence (AI) framework designed to support sustainable protein\nproduction research, with an initial focus on microbial protein sources. Our\nRetrieval-Augmented Generation (RAG)-oriented system consists of two GPT-based\nLLM agents: (1) a literature search agent that retrieves relevant scientific\nliterature on microbial protein production for a specified microbial strain,\nand (2) an information extraction agent that processes the retrieved content to\nextract relevant biological and chemical information. Two parallel\nmethodologies, fine-tuning and prompt engineering, were explored for agent\noptimisation. Both methods demonstrated effectiveness at improving the\nperformance of the information extraction agent in terms of transformer-based\ncosine similarity scores between obtained and ideal outputs. Mean cosine\nsimilarity scores were increased by up to 25%, while universally reaching mean\nscores of $\\geq 0.89$ against ideal output text. Fine-tuning overall improved\nthe mean scores to a greater extent (consistently of $\\geq 0.94$) compared to\nprompt engineering, although lower statistical uncertainties were observed with\nthe latter approach. A user interface was developed and published for enabling\nthe use of the multi-agent AI system, alongside preliminary exploration of\nadditional chemical safety-based search capabilities", "AI": {"tldr": "研究提出了一种多智能体AI框架，用于支持可持续蛋白质生产研究，重点关注微生物蛋白质来源，通过检索增强生成（RAG）系统优化文献搜索和信息提取，并开发了用户界面。", "motivation": "全球对可持续蛋白质来源的需求加速了开发智能工具的需求，以快速处理和合成特定领域的科学知识。", "method": "研究采用了基于GPT的大型语言模型（LLM）构建了两个智能体：一个用于检索微生物蛋白质生产相关文献，另一个用于提取生物和化学信息。通过微调和提示工程两种方法优化智能体性能。", "result": "两种优化方法均有效提升了信息提取智能体的性能，基于变换器的余弦相似度得分最高提升了25%，平均得分达到$\\geq 0.89$。微调方法平均得分更高（$\\geq 0.94$），而提示工程方法的统计不确定性较低。", "conclusion": "多智能体AI框架在可持续蛋白质生产研究中表现出潜力，微调方法在性能提升上更为显著，同时开发了用户界面以支持系统使用。"}}
{"id": "2506.20290", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.20290", "abs": "https://arxiv.org/abs/2506.20290", "authors": ["Berkay Kemal Balioglu", "Alireza Khodaie", "Mehmet Emre Gursoy"], "title": "Don't Hash Me Like That: Exposing and Mitigating Hash-Induced Unfairness in Local Differential Privacy", "comment": null, "summary": "Local differential privacy (LDP) has become a widely accepted framework for\nprivacy-preserving data collection. In LDP, many protocols rely on hash\nfunctions to implement user-side encoding and perturbation. However, the\nsecurity and privacy implications of hash function selection have not been\npreviously investigated. In this paper, we expose that the hash functions may\nact as a source of unfairness in LDP protocols. We show that although users\noperate under the same protocol and privacy budget, differences in hash\nfunctions can lead to significant disparities in vulnerability to inference and\npoisoning attacks. To mitigate hash-induced unfairness, we propose Fair-OLH\n(F-OLH), a variant of OLH that enforces an entropy-based fairness constraint on\nhash function selection. Experiments show that F-OLH is effective in mitigating\nhash-induced unfairness under acceptable time overheads.", "AI": {"tldr": "本文揭示了局部差分隐私（LDP）协议中哈希函数选择可能导致的不公平问题，并提出了一种基于熵的公平约束方法Fair-OLH（F-OLH）来缓解这一问题。", "motivation": "在LDP框架下，哈希函数常用于用户端编码和扰动，但其安全性和隐私影响尚未被充分研究。研究发现，不同哈希函数可能导致用户在面对推理和投毒攻击时存在显著差异，即使协议和隐私预算相同。", "method": "提出了Fair-OLH（F-OLH），这是OLH（Optimal Local Hashing）的一种变体，通过在哈希函数选择中引入基于熵的公平约束，确保用户间的公平性。", "result": "实验表明，F-OLH在可接受的时间开销下，能够有效缓解由哈希函数引起的不公平问题。", "conclusion": "哈希函数的选择在LDP协议中是一个潜在的不公平来源，而F-OLH通过公平约束显著改善了这一问题，为隐私保护数据收集提供了更公平的解决方案。"}}
{"id": "2506.20600", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20600", "abs": "https://arxiv.org/abs/2506.20600", "authors": ["Wengxi Li", "Roy Pea", "Nick Haber", "Hari Subramonyam"], "title": "CogGen: A Learner-Centered Generative AI Architecture for Intelligent Tutoring with Programming Video", "comment": null, "summary": "We introduce CogGen, a learner-centered AI architecture that transforms\nprogramming videos into interactive, adaptive learning experiences by\nintegrating student modeling with generative AI tutoring based on the Cognitive\nApprenticeship framework. The architecture consists of three components: (1)\nvideo segmentation by learning goals, (2) a conversational tutoring engine\napplying Cognitive Apprenticeship strategies, and (3) a student model using\nBayesian Knowledge Tracing to adapt instruction. Our technical evaluation\ndemonstrates effective video segmentation accuracy and strong pedagogical\nalignment across knowledge, method, action, and interaction layers. Ablation\nstudies confirm the necessity of each component in generating effective\nguidance. This work advances AI-powered tutoring by bridging structured student\nmodeling with interactive AI conversations, offering a scalable approach to\nenhancing video-based programming education.", "AI": {"tldr": "CogGen是一种以学习者为中心的AI架构，通过将学生建模与基于认知学徒框架的生成式AI辅导相结合，将编程视频转化为互动、自适应的学习体验。", "motivation": "当前视频编程教育缺乏互动性和个性化，CogGen旨在通过AI技术弥补这一缺陷，提升学习效果。", "method": "架构包含三个核心组件：(1)按学习目标分割视频，(2)应用认知学徒策略的对话式辅导引擎，(3)基于贝叶斯知识追踪（Bayesian Knowledge Tracing）的自适应学生模型。", "result": "技术评估显示视频分割准确率高，且在教学的知识、方法、行动和互动层面均表现出强教育一致性。消融实验证实各组件对生成有效指导均不可或缺。", "conclusion": "该研究通过结合结构化学生建模与交互式AI对话，推动了AI辅助教学的发展，为规模化提升视频编程教育提供了可行方案。"}}
{"id": "2506.20415", "categories": ["cs.CR", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.20415", "abs": "https://arxiv.org/abs/2506.20415", "authors": ["Dipayan Saha", "Shams Tarek", "Hasan Al Shaikh", "Khan Thamid Hasan", "Pavan Sai Nalluri", "Md. Ajoad Hasan", "Nashmin Alam", "Jingbo Zhou", "Sujan Kumar Saha", "Mark Tehranipoor", "Farimah Farahmandi"], "title": "SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models", "comment": null, "summary": "Ensuring the security of complex system-on-chips (SoCs) designs is a critical\nimperative, yet traditional verification techniques struggle to keep pace due\nto significant challenges in automation, scalability, comprehensiveness, and\nadaptability. The advent of large language models (LLMs), with their remarkable\ncapabilities in natural language understanding, code generation, and advanced\nreasoning, presents a new paradigm for tackling these issues. Moving beyond\nmonolithic models, an agentic approach allows for the creation of multi-agent\nsystems where specialized LLMs collaborate to solve complex problems more\neffectively. Recognizing this opportunity, we introduce SV-LLM, a novel\nmulti-agent assistant system designed to automate and enhance SoC security\nverification. By integrating specialized agents for tasks like verification\nquestion answering, security asset identification, threat modeling, test plan\nand property generation, vulnerability detection, and simulation-based bug\nvalidation, SV-LLM streamlines the workflow. To optimize their performance in\nthese diverse tasks, agents leverage different learning paradigms, such as\nin-context learning, fine-tuning, and retrieval-augmented generation (RAG). The\nsystem aims to reduce manual intervention, improve accuracy, and accelerate\nsecurity analysis, supporting proactive identification and mitigation of risks\nearly in the design cycle. We demonstrate its potential to transform hardware\nsecurity practices through illustrative case studies and experiments that\nshowcase its applicability and efficacy.", "AI": {"tldr": "本文提出SV-LLM系统，利用多智能体协作的大语言模型（LLM）自动化提升SoC安全验证，解决传统方法在自动化、扩展性等方面的不足。", "motivation": "传统SoC安全验证技术面临自动化不足、扩展性差等挑战，而大语言模型（LLM）的自然语言理解和代码生成能力为解决这些问题提供了新思路。", "method": "SV-LLM采用多智能体系统，集成专门代理执行问答、资产识别、威胁建模等任务，结合上下文学习、微调和检索增强生成（RAG）优化性能。", "result": "案例研究和实验表明，SV-LLM能减少人工干预、提高准确性并加速安全分析，支持在设计周期早期主动识别和缓解风险。", "conclusion": "SV-LLM展现了通过多智能体LLM协作变革硬件安全实践的潜力，为SoC安全验证提供了高效、自动化的解决方案。"}}
{"id": "2506.20608", "categories": ["cs.AI", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2506.20608", "abs": "https://arxiv.org/abs/2506.20608", "authors": ["Barry Smith", "Junchao Zhang", "Hong Zhang", "Lois Curfman McInnes", "Murat Keceli", "Archit Vasan", "Satish Balay", "Toby Isaac", "Le Chen", "Venkatram Vishwanath"], "title": "AI Assistants to Enhance and Exploit the PETSc Knowledge Base", "comment": null, "summary": "Generative AI, especially through large language models (LLMs), is\ntransforming how technical knowledge can be accessed, reused, and extended.\nPETSc, a widely used numerical library for high-performance scientific\ncomputing, has accumulated a rich but fragmented knowledge base over its three\ndecades of development, spanning source code, documentation, mailing lists,\nGitLab issues, Discord conversations, technical papers, and more. Much of this\nknowledge remains informal and inaccessible to users and new developers. To\nactivate and utilize this knowledge base more effectively, the PETSc team has\nbegun building an LLM-powered system that combines PETSc content with custom\nLLM tools -- including retrieval-augmented generation (RAG), reranking\nalgorithms, and chatbots -- to assist users, support developers, and propose\nupdates to formal documentation. This paper presents initial experiences\ndesigning and evaluating these tools, focusing on system architecture, using\nRAG and reranking for PETSc-specific information, evaluation methodologies for\nvarious LLMs and embedding models, and user interface design. Leveraging the\nArgonne Leadership Computing Facility resources, we analyze how LLM responses\ncan enhance the development and use of numerical software, with an initial\nfocus on scalable Krylov solvers. Our goal is to establish an extensible\nframework for knowledge-centered AI in scientific software, enabling scalable\nsupport, enriched documentation, and enhanced workflows for research and\ndevelopment. We conclude by outlining directions for expanding this system into\na robust, evolving platform that advances software ecosystems to accelerate\nscientific discovery.", "AI": {"tldr": "PETSc团队利用大型语言模型（LLM）构建知识管理系统，整合分散的技术知识，通过RAG、重排序算法和聊天机器人等工具提升用户支持与开发效率，重点关注可扩展Krylov求解器，旨在建立科学软件中知识中心AI的扩展框架。", "motivation": "PETSc作为高性能科学计算库，30年积累的知识分散且非结构化，难以被用户和开发者有效利用，需通过AI技术激活这些知识资源。", "method": "结合检索增强生成（RAG）、重排序算法和定制聊天机器人，利用Argonne领导计算设施资源，评估不同LLM和嵌入模型，设计用户界面。", "result": "初步构建了面向PETSc的LLM工具系统，验证了其在增强数值软件开发和使用中的潜力，特别是对可扩展Krylov求解器的支持。", "conclusion": "提出扩展该系统为动态演进平台的愿景，通过知识中心AI推动科学软件生态发展，加速科研发现进程。"}}
{"id": "2506.20488", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2506.20488", "abs": "https://arxiv.org/abs/2506.20488", "authors": ["Shuo Yang", "Xinran Zheng", "Jinfeng Xu", "Jinze Li", "Danyang Song", "Zheyu Chen", "Edith C. H. Ngai"], "title": "Generative AI for Vulnerability Detection in 6G Wireless Networks: Advances, Case Study, and Future Directions", "comment": null, "summary": "The rapid advancement of 6G wireless networks, IoT, and edge computing has\nsignificantly expanded the cyberattack surface, necessitating more intelligent\nand adaptive vulnerability detection mechanisms. Traditional security methods,\nwhile foundational, struggle with zero-day exploits, adversarial threats, and\ncontext-dependent vulnerabilities in highly dynamic network environments.\nGenerative AI (GAI) emerges as a transformative solution, leveraging synthetic\ndata generation, multimodal reasoning, and adaptive learning to enhance\nsecurity frameworks. This paper explores the integration of GAI-powered\nvulnerability detection in 6G wireless networks, focusing on code auditing,\nprotocol security, cloud-edge defenses, and hardware protection. We introduce a\nthree-layer framework comprising the Technology Layer, Capability Layer, and\nApplication Layer to systematically analyze the role of VAEs, GANs, LLMs, and\nGDMs in securing next-generation wireless ecosystems. To demonstrate practical\nimplementation, we present a case study on LLM-driven code vulnerability\ndetection, highlighting its effectiveness, performance, and challenges.\nFinally, we outline future research directions, including lightweight models,\nhigh-authenticity data generation, external knowledge integration, and\nprivacy-preserving technologies. By synthesizing current advancements and open\nchallenges, this work provides a roadmap for researchers and practitioners to\nharness GAI for building resilient and adaptive security solutions in 6G\nnetworks.", "AI": {"tldr": "本文探讨了生成式AI（GAI）在6G无线网络漏洞检测中的应用，提出了一个三层框架，并通过案例研究展示了其有效性，同时指出了未来研究方向。", "motivation": "随着6G、物联网和边缘计算的快速发展，网络攻击面扩大，传统安全方法难以应对零日漏洞和动态网络环境中的威胁，需要更智能的漏洞检测机制。", "method": "提出了一个包含技术层、能力层和应用层的三层框架，系统分析了VAEs、GANs、LLMs和GDMs在安全防护中的作用，并通过LLM驱动的代码漏洞检测案例进行实践验证。", "result": "案例研究表明，GAI在漏洞检测中表现出高效性和适应性，但也面临轻量化模型、高真实性数据生成等挑战。", "conclusion": "本文为研究人员和实践者提供了利用GAI构建6G网络弹性安全解决方案的路线图，并指出了未来在轻量化模型、隐私保护技术等方面的研究方向。"}}
{"id": "2506.20640", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20640", "abs": "https://arxiv.org/abs/2506.20640", "authors": ["Sijie Li", "Weiwei Sun", "Shanda Li", "Ameet Talwalkar", "Yiming Yang"], "title": "Towards Community-Driven Agents for Machine Learning Engineering", "comment": null, "summary": "Large language model-based machine learning (ML) agents have shown great\npromise in automating ML research. However, existing agents typically operate\nin isolation on a given research problem, without engaging with the broader\nresearch community, where human researchers often gain insights and contribute\nby sharing knowledge. To bridge this gap, we introduce MLE-Live, a live\nevaluation framework designed to assess an agent's ability to communicate with\nand leverage collective knowledge from a simulated Kaggle research community.\nBuilding on this framework, we propose CoMind, a novel agent that excels at\nexchanging insights and developing novel solutions within a community context.\nCoMind achieves state-of-the-art performance on MLE-Live and outperforms 79.2%\nhuman competitors on average across four ongoing Kaggle competitions. Our code\nis released at https://github.com/comind-ml/CoMind.", "AI": {"tldr": "本文介绍了MLE-Live评估框架及CoMind智能体，该智能体能在模拟Kaggle社区中交流知识并开发新方案，性能超越79.2%人类选手。", "motivation": "现有基于大语言模型的ML智能体通常孤立运作，无法像人类研究者那样通过社区交流获取洞见。为弥补这一差距，研究团队开发了支持知识共享的评估框架。", "method": "提出MLE-Live实时评估框架，用于测试智能体在模拟Kaggle社区中的协作能力；并在此基础上开发了CoMind智能体，擅长在群体环境中交换见解和创新解决方案。", "result": "CoMind在MLE-Live框架下达到最先进性能，在四项Kaggle竞赛中平均超越79.2%的人类参赛者。代码已开源。", "conclusion": "研究表明，具备社区协作能力的ML智能体（如CoMind）能显著提升研究效率，为自动化机器学习开辟了新方向。"}}
{"id": "2506.20576", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20576", "abs": "https://arxiv.org/abs/2506.20576", "authors": ["Sabrine Ennaji", "Elhadj Benkhelifa", "Luigi V. Mancini"], "title": "Vulnerability Disclosure through Adaptive Black-Box Adversarial Attacks on NIDS", "comment": null, "summary": "Adversarial attacks, wherein slight inputs are carefully crafted to mislead\nintelligent models, have attracted increasing attention. However, a critical\ngap persists between theoretical advancements and practical application,\nparticularly in structured data like network traffic, where interdependent\nfeatures complicate effective adversarial manipulations. Moreover, ambiguity in\ncurrent approaches restricts reproducibility and limits progress in this field.\nHence, existing defenses often fail to handle evolving adversarial attacks.\nThis paper proposes a novel approach for black-box adversarial attacks, that\naddresses these limitations. Unlike prior work, which often assumes system\naccess or relies on repeated probing, our method strictly respect black-box\nconstraints, reducing interaction to avoid detection and better reflect\nreal-world scenarios. We present an adaptive feature selection strategy using\nchange-point detection and causality analysis to identify and target sensitive\nfeatures to perturbations. This lightweight design ensures low computational\ncost and high deployability. Our comprehensive experiments show the attack's\neffectiveness in evading detection with minimal interaction, enhancing its\nadaptability and applicability in real-world scenarios. By advancing the\nunderstanding of adversarial attacks in network traffic, this work lays a\nfoundation for developing robust defenses.", "AI": {"tldr": "本文提出了一种针对网络流量结构化数据的黑盒对抗攻击新方法，通过自适应特征选择和因果分析实现高效攻击，实验证明其在最小交互下能有效规避检测。", "motivation": "现有对抗攻击理论在实际结构化数据（如网络流量）应用中存在差距，特征间依赖关系导致有效攻击困难，且现有方法模糊性限制了可复现性，防御措施难以应对持续演变的攻击。", "method": "提出严格遵循黑盒约束的轻量级攻击方法：采用变点检测和因果分析的自适应特征选择策略，仅针对敏感特征进行扰动，最大限度减少交互以避免被发现。", "result": "实验表明该方法能以极低计算成本和最少交互次数有效规避检测系统，显著提升现实场景中的适应性和适用性。", "conclusion": "该研究推进了网络流量对抗攻击的理解，为开发鲁棒防御机制奠定基础，其轻量级设计确保高可部署性。"}}
{"id": "2506.20664", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.20664", "abs": "https://arxiv.org/abs/2506.20664", "authors": ["Andrei Lupu", "Timon Willi", "Jakob Foerster"], "title": "The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind", "comment": "41 pages, 19 figures", "summary": "As Large Language Models (LLMs) gain agentic abilities, they will have to\nnavigate complex multi-agent scenarios, interacting with human users and other\nagents in cooperative and competitive settings. This will require new reasoning\nskills, chief amongst them being theory of mind (ToM), or the ability to reason\nabout the \"mental\" states of other agents. However, ToM and other multi-agent\nabilities in LLMs are poorly understood, since existing benchmarks suffer from\nnarrow scope, data leakage, saturation, and lack of interactivity. We thus\npropose Decrypto, a game-based benchmark for multi-agent reasoning and ToM\ndrawing inspiration from cognitive science, computational pragmatics and\nmulti-agent reinforcement learning. It is designed to be as easy as possible in\nall other dimensions, eliminating confounding factors commonly found in other\nbenchmarks. To our knowledge, it is also the first platform for designing\ninteractive ToM experiments.\n  We validate the benchmark design through comprehensive empirical evaluations\nof frontier LLMs, robustness studies, and human-AI cross-play experiments. We\nfind that LLM game-playing abilities lag behind humans and simple\nword-embedding baselines. We then create variants of two classic cognitive\nscience experiments within Decrypto to evaluate three key ToM abilities.\nSurprisingly, we find that state-of-the-art reasoning models are significantly\nworse at those tasks than their older counterparts. This demonstrates that\nDecrypto addresses a crucial gap in current reasoning and ToM evaluations, and\npaves the path towards better artificial agents.", "AI": {"tldr": "本文提出Decrypto，一个基于游戏的多智能体推理与心理理论（ToM）基准测试平台，旨在解决现有基准测试的局限性，并通过实验验证了当前大型语言模型（LLM）在多智能体推理和ToM任务上的表现不及人类和简单基线模型。", "motivation": "随着大型语言模型（LLM）获得代理能力，它们需要在复杂的多智能体场景中导航，与人类用户和其他智能体在合作与竞争环境中互动。然而，LLM在多智能体能力和心理理论（ToM）方面的表现尚不明确，现有基准测试存在范围狭窄、数据泄漏、饱和和缺乏交互性等问题。", "method": "作者提出Decrypto，一个基于游戏的基准测试平台，灵感来自认知科学、计算语用学和多智能体强化学习。该平台旨在消除其他基准测试中常见的混杂因素，并通过全面的实证评估、鲁棒性研究和人机交叉实验验证其设计。", "result": "实验发现，LLM在游戏中的表现落后于人类和简单的词嵌入基线模型。此外，在Decrypto中设计的经典认知科学实验变体中，最先进的推理模型在ToM任务上的表现显著不如旧版模型。", "conclusion": "Decrypto填补了当前推理和ToM评估的关键空白，为开发更优的人工智能代理铺平了道路。研究结果表明，现有LLM在多智能体推理和ToM任务上仍有显著提升空间。"}}
{"id": "2506.20585", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.20585", "abs": "https://arxiv.org/abs/2506.20585", "authors": ["Alexander Söderhäll", "Zahra Alimadadi", "Panos Papadimitratos"], "title": "On the Impact of Sybil-based Attacks on Mobile Crowdsensing for Transportation", "comment": "7 pages, 5 figures, 2 tables, TrustSense workshop of PerCom 2025", "summary": "Mobile Crowd-Sensing (MCS) enables users with personal mobile devices (PMDs)\nto gain information on their surroundings. Users collect and contribute data on\ndifferent phenomena using their PMD sensors, and the MCS system processes this\ndata to extract valuable information for end users. Navigation MCS-based\napplications (N-MCS) are prevalent and important for transportation: users\nshare their location and speed while driving and, in return, find efficient\nroutes to their destinations. However, N-MCS are currently vulnerable to\nmalicious contributors, often termed Sybils: submitting falsified data,\nseemingly from many devices that are not truly present on target roads, falsely\nreporting congestion when there is none, thus changing the road status the\nN-MCS infers. The attack effect is that the N-MCS returns suboptimal routes to\nusers, causing late arrival and, overall, deteriorating road traffic flow. We\ninvestigate exactly the impact of Sybil-based attacks on N-MCS: we design an\nN-MCS system that offers efficient routing on top of the vehicular simulator\nSUMO, using the InTAS road network as our scenario. We design experiments\nattacking an individual N-MCS user as well as a larger population of users,\nselecting the adversary targets based on graph-theoretical arguments. Our\nexperiments show that the resources required for a successful attack depend on\nthe location of the attack (i.e., the surrounding road network and traffic) and\nthe extent of Sybil contributed data for the targeted road(s). We demonstrate\nthat Sybil attacks can alter the route of N-MCS users, increasing average\ntravel time by 20% with Sybils 3% of the N-MCS user population.", "AI": {"tldr": "移动群智感知（MCS）在导航应用中易受虚假数据攻击（Sybil攻击），导致路线规划失效。本文通过实验证明，仅需3%的虚假用户即可使平均行程时间增加20%。", "motivation": "导航类移动群智感知（N-MCS）系统易受虚假数据攻击，攻击者通过伪造多设备数据谎报路况，导致系统推荐低效路线，影响整体交通流。研究旨在量化此类攻击的实际影响。", "method": "基于SUMO交通模拟器和InTAS路网构建N-MCS系统，设计针对个体及群体用户的攻击实验，结合图论选择攻击目标，分析攻击资源与路网位置、虚假数据量的关系。", "result": "实验表明，攻击成功率取决于目标路段的路网结构及虚假数据占比。当虚假用户占3%时，用户平均行程时间增加20%，路线被恶意篡改。", "conclusion": "Sybil攻击对N-MCS系统具有显著破坏性，需设计防御机制以应对虚假数据注入，确保交通导航服务的可靠性。"}}
