<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 9]
- [math.OC](#math.OC) [Total: 34]
- [math.NT](#math.NT) [Total: 16]
- [math.LO](#math.LO) [Total: 3]
- [math.HO](#math.HO) [Total: 1]
- [math.GM](#math.GM) [Total: 1]
- [math.CO](#math.CO) [Total: 26]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [cs.CR](#cs.CR) [Total: 37]
- [cs.AI](#cs.AI) [Total: 45]
- [cs.DM](#cs.DM) [Total: 2]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Anytime-Valid Tests for Sparse Anomalies](https://arxiv.org/abs/2506.22588)
*Muriel F. Pérez-Ortiz,Rui M. Castro*

Main category: math.ST

TL;DR: 本文研究了在大规模数据流中实时检测稀疏异常的问题，提出了基于随时有效性检验的方法，并在正态均值模型下展示了快速检测异常的能力。通过分析流数量增长时的对数最优性，建立了与固定样本检验不同的理论特征，并构建了参数自适应的最优检验方法。数值实验验证了所提方法的优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统固定样本检验方法在实时监测大规模数据流时存在效率不足的问题，无法快速检测稀疏异常。本文旨在开发一种随时有效性检验框架，解决快速检测与理论最优性之间的平衡问题。

Method: 采用随时有效性检验方法，在正态均值模型下建立检测程序。通过研究流数量增长时固定时间点的对数最优性（而非传统的大时间累积证据），构建参数自适应的检验统计量。与固定样本检验的理论结果进行对比分析。

Result: 理论分析表明所提方法能快速检测异常，其检测特征与固定样本检验存在本质差异。数值实验显示：参数自适应检验在未知真实参数时，性能接近已知参数的Oracle检验，显著优于基准方法。

Conclusion: 本文提出的随时有效性检验框架突破了传统方法的局限性，通过流数量渐近分析实现了稀疏异常的快速检测。参数自适应设计使方法具备实际应用价值，为高维流式数据监测提供了新工具。

Abstract: We consider the problem of detection of sparse anomalies when monitoring a
large number of data streams continuously in time. This problem is addressed
using anytime-valid tests. In the context of a normal-means model and for a
fixed sample, this problem is known to exhibit a nontrivial phase transition
that characterizes when anomalies can and cannot be detected. We show, for the
anytime-valid version of the problem, testing procedures that can detect the
presence of anomalies quickly. Given that the goal is quick detection, existing
approaches to anytime-valid testing that study how evidence accumulates for
large times through log-optimality criteria is insufficient. This issue is
addressed in this context by studying log-optimal procedures for a fixed moment
in time, but as the number of streams grows larger. The resulting
characterization is related to, but not implied by the existing results for
fixed-sample tests. In addition, we also construct and analyze tests that are
parameter-adaptive and exhibit optimal performance (in a well defined sense)
even when the hypothesized model parameters are unknown. Numerical results
illustrate the behavior of the proposed tests in comparison with oracle tests
and suitable benchmarks.

</details>


### [2] [Lower bounds for trace estimation via Block Krylov and other methods](https://arxiv.org/abs/2506.22701)
*Shi Jie Yu*

Main category: math.ST

TL;DR: 本文研究了矩阵函数迹估计的理论下界，结合Hutchinson方法和块Krylov技术，分析了多项式近似与查询次数下限的关系。


<details>
  <summary>Details</summary>
Motivation: 矩阵函数迹估计（如$\text{tr}(f(A))$）在科学计算中至关重要，但现有方法效率不足，需明确块Krylov步数与多项式近似阶数的理论联系。

Method: 通过块Krylov子空间近似矩阵-向量积（如$f(A)V$），并分析标量等价函数（如$A^{-1/2}$、$A^{-1}$）的多项式近似上界，推导所需Krylov步数。

Result: 建立了Wishart矩阵$\text{tr}(W^{-p})$迹估计的查询次数下限，揭示了块Krylov步数与多项式近似阶数的直接关联。

Conclusion: 研究将迹估计的总成本与多项式近似的基本极限及计算所需信息量联系起来，为高效算法设计提供了理论依据。

Abstract: This paper studies theoretical lower bounds for estimating the trace of a
matrix function, $\text{tr}(f(A))$, focusing on methods that use Hutchinson's
method along with Block Krylov techniques. These methods work by approximating
matrix-vector products like $f(A)V$ using a Block Krylov subspace. This is
closely related to approximating functions with polynomials. We derive
theoretical upper bounds on how many Krylov steps are needed for functions such
as $A^{-1/2}$ and $A^{-1}$ by analyzing the upper bounds from the polynomial
approximation of their scalar equivalent. In addition, we also develop lower
limits on the number of queries needed for trace estimation, specifically for
$\text{tr}(W^{-p})$ where $W$ is a Wishart matrix. Our study clarifies the
connection between the number of steps in Block Krylov methods and the degree
of the polynomial used for approximation. This links the total cost of trace
estimation to basic limits in polynomial approximation and how much information
is needed for the computation.

</details>


### [3] [On the Study of Weighted Fractional Cumulative Residual Inaccuracy and its Dynamical Version with Applications](https://arxiv.org/abs/2506.22975)
*Aman Pandey,Chanchal Kundu*

Main category: math.ST

TL;DR: 本文提出了一种新的信息度量方法——加权分数累积剩余不精确度(WFCRI)，研究了其基本性质、边界条件及在混合风险模型中的行为，并提出了动态版本和比例风险率模型下的经验估计方法，最后应用于混沌动力学和实际数据分析。


<details>
  <summary>Details</summary>
Motivation: 近年来，量化系统不精确性和不确定性的信息度量方法受到广泛关注。本文旨在引入WFCRI这一新概念，以更全面地描述和分析系统的不确定性。

Method: 建立了WFCRI的基本性质与重要边界条件；研究了混合风险模型下WFCRI的行为；提出了动态WFCRI及其在比例风险率模型中的表现；开发了比例风险率框架下的经验估计方法并通过仿真验证。

Result: WFCRI在Ricker映射和立方映射中有效表征了混沌动力学特性；实际数据应用表明该度量能准确评估不确定性；仿真研究验证了经验估计方法的可靠性。

Conclusion: WFCRI是一种有效的系统不确定性和不精确性量化工具，在理论分析和实际应用中均展现出优越性能，为复杂系统研究提供了新的度量视角。

Abstract: In recent years, there has been a growing interest in information measures
that quantify inaccuracy and uncertainty in systems. In this paper, we
introduce a novel concept called the Weighted Fractional Cumulative Residual
Inaccuracy (WFCRI). We develop several fundamental properties of WFCRI and
establish important bounds that reveal its analytical behavior. Further, we
examine the behavior of WFCRI under a mixture hazard model. A dynamic version
of WFCRI also proposed and studied its behavior under proportional hazard rate
model. An empirical estimation method for WFCRI under the proportional hazard
rate model framework is also proposed, and its performance is evaluated through
simulation studies. Finally, we demonstrate the utility of WFCRI measure in
characterizing chaotic dynamics by applying it to the Ricker and cubic maps.
The proposed measure is also applied to real data to assess the uncertainty.

</details>


### [4] [Some results about varextropy and weighted varextropy functions](https://arxiv.org/abs/2506.22996)
*Faranak Goodarzi*

Main category: math.ST

TL;DR: 本文研究了加权变熵测度的若干性质，推导了其在特定分布函数（如均衡分布和加权分布）中的表达式，并提出了新的随机排序方法。通过模拟研究评估了非参数估计器的性能，并基于加权变熵测度对倒数分布进行了表征。


<details>
  <summary>Details</summary>
Motivation: 研究加权变熵测度的性质及其在不同分布函数中的应用，旨在扩展信息论工具在统计分布分析中的适用性，并为系统寿命分析提供新的度量方法。

Method: 通过理论推导获得加权变熵测度的边界条件及表达式，提出加权变熵排序方法，构建两种非参数估计器，并通过模拟研究评估其性能（MSE和偏差）。

Result: 获得了均衡分布和加权分布的加权变熵表达式，提出了新的随机排序方法，模拟研究表明非参数估计器表现良好，并基于加权变熵测度成功表征了倒数分布。

Conclusion: 加权变熵测度为分布分析提供了有效工具，新提出的估计器和检验方法在模拟和实际数据中表现优异，其性能与KS检验相当。

Abstract: In this paper, we investigate several properties of the weighted varextropy
measure and obtain it for specific distribution functions, such as the
equilibrium and weighted distributions. We also obtain bounds for the weighted
varextropy, as well as for weighted residual varextropy and weighted past
varextropy. Additionally, we derive an expression for the varextropy of the
lifetime of coherent systems. A new stochastic ordering, referred to as
weighted varextopy orderind, is introduced, and some of its key properties are
explored. Furtheremore, we propose two nonparametric estimators for the
weighted varextropy function. A simulation study is conducted to evaluate the
performance of these estimators in terms of mean squared error(MSE) and bias.
Finally, we provide a characterization of the reciprocal distribution based on
the weighted varextropy measure. Some tests for reciprocal distribution are
constructed by using the proposed estimators and the powers of the tests are
compared with the powers of Kolmogorov-Smirnov (KS) test. application to real
data is also reported.

</details>


### [5] [On Universality of Non-Separable Approximate Message Passing Algorithms](https://arxiv.org/abs/2506.23010)
*Max Lovig,Tianhao Wang,Zhou Fan*

Main category: math.ST

TL;DR: 本文研究了非可分离近似消息传递（AMP）算法的普适性，提出了一种称为有界组合性质（BCP）的条件，使得多项式非线性AMP算法在非高斯矩阵输入下仍能保持状态演化的普适性。


<details>
  <summary>Details</summary>
Motivation: 现有均值场理论主要局限于可分离非线性或高斯/旋转不变数据，缺乏对非可分离AMP算法普适性的系统研究。

Method: 提出了BCP条件（多项式非线性）和BCP可逼近性条件（Lipschitz非线性），通过张量表示理论分析算法动力学。

Result: 证明局部降噪器、通用信号的谱降噪器以及可分离函数与线性映射的组合等常见非线性都满足BCP可逼近性，从而保证相应AMP算法的普适状态演化。

Conclusion: 该研究扩展了AMP理论框架，首次系统建立了非可分离非线性在非高斯数据下的普适性保证，为更广泛算法的动力学分析提供了工具。

Abstract: Mean-field characterizations of first-order iterative algorithms -- including
Approximate Message Passing (AMP), stochastic and proximal gradient descent,
and Langevin diffusions -- have enabled a precise understanding of learning
dynamics in many statistical applications. For algorithms whose non-linearities
have a coordinate-separable form, it is known that such characterizations enjoy
a degree of universality with respect to the underlying data distribution.
However, mean-field characterizations of non-separable algorithm dynamics have
largely remained restricted to i.i.d. Gaussian or rotationally-invariant data.
  In this work, we initiate a study of universality for non-separable AMP
algorithms. We identify a general condition for AMP with polynomial
non-linearities, in terms of a Bounded Composition Property (BCP) for their
representing tensors, to admit a state evolution that holds universally for
matrices with non-Gaussian entries. We then formalize a condition of
BCP-approximability for Lipschitz AMP algorithms to enjoy a similar universal
guarantee. We demonstrate that many common classes of non-separable
non-linearities are BCP-approximable, including local denoisers, spectral
denoisers for generic signals, and compositions of separable functions with
generic linear maps, implying the universality of state evolution for AMP
algorithms employing these non-linearities.

</details>


### [6] [Average quantile regression: a new non-mean regression model and coherent risk measure](https://arxiv.org/abs/2506.23059)
*Rong Jiang,M. C. Jones,Keming Yu,Jiangfeng Wang*

Main category: math.ST

TL;DR: 本文提出平均分位数回归（AQR）新方法，兼具平滑性、共单调可加性及尾部损失敏感性，优于传统分位数回归和期望回归，适用于高维大数据分析及风险管理。


<details>
  <summary>Details</summary>
Motivation: 传统回归模型和风险度量工具在描述分布信息和尾部风险时存在局限，需开发兼具解释力和灵活性的新方法。

Method: 提出AQR模型：通过光滑分位数水平实现共单调可加性，显式量化尾部损失，推导估计量并建立渐近理论框架。

Result: AQR能统一多种经典回归模型与风险度量，在分布式系统高维数据分析和投资组合优化中表现优异。

Conclusion: AQR为风险管理提供强有力工具，案例验证其在风险评估与组合优化中的有效性，具有广泛应用潜力。

Abstract: Regression models that go beyond the mean, alongside coherent risk measures,
have been important tools in modern data analysis. This paper introduces the
innovative concept of Average Quantile Regression (AQR), which is smooth at the
quantile-like level, comonotonically additive, and explicitly accounts for the
severity of tail losses relative to quantile regression. AQR serves as a
versatile regression model capable of describing distributional information
across all positions, akin to quantile regression, yet offering enhanced
interpretability compared to expectiles. Numerous traditional regression models
and coherent risk measures can be regarded as special cases of AQR. As a
flexible non-parametric regression model, AQR demonstrates outstanding
performance in analyzing high-dimensional and large datasets, particularly
those generated by distributed systems, and provides a convenient framework for
their statistical analysis. The corresponding estimators are rigorously
derived, and their asymptotic properties are thoroughly developed. In a risk
management context, the case study confirms AQR's effectiveness in risk
assessment and portfolio optimization.

</details>


### [7] [Nuisance parameters and elliptically symmetric distributions: a geometric approach to parametric and semiparametric efficiency](https://arxiv.org/abs/2506.23213)
*Stefano Fortunati,Jean-Pierre Delmas,Esa Ollila*

Main category: math.ST

TL;DR: 本文研究椭圆对称分布中兴趣参数与有限/无限维干扰参数的统计效率关系，采用几何方法替代传统渐近理论，并扩展至复椭圆对称分布。


<details>
  <summary>Details</summary>
Motivation: 椭圆对称分布模型中，位置向量与散度矩阵作为有限维兴趣参数常受无限维干扰项影响。研究旨在揭示干扰参数存在下参数估计效率的深层联系。

Method: 采用基于希尔伯特空间的几何分析工具（如投影与切空间），替代Le Cam渐近理论，处理参数化后的兴趣参数与干扰参数子向量。

Result: 获得了低秩参数化等场景下的原创性结论，并将实椭圆对称分布的理论框架推广至循环/非循环复椭圆对称分布。

Conclusion: 几何方法能有效分析含干扰参数的统计效率问题，理论成果可拓展至复数域，为椭圆对称模型研究提供新视角。

Abstract: Elliptically symmetric distributions are a classic example of a
semiparametric model where the location vector and the scatter matrix (or a
parameterization of them) are the two finite-dimensional parameters of
interest, while the density generator represents an
\textit{infinite-dimensional nuisance} term. This basic representation of the
elliptic model can be made more accurate, rich, and flexible by considering
additional \textit{finite-dimensional nuisance} parameters. Our aim is
therefore to investigate the deep and counter-intuitive links between
statistical efficiency in estimating the parameters of interest in the presence
of both finite and infinite-dimensional nuisance parameters. Unlike previous
works that addressed this problem using Le Cam's asymptotic theory, our
approach here is purely geometric: efficiency will be analyzed using tools such
as projections and tangent spaces embedded in the relevant Hilbert space. This
allows us to obtain original results also for the case where the location
vector and the scatter matrix are parameterized by a finite-dimensional vector
that can be partitioned in two sub-vectors: one containing the parameters of
interest and the other containing the nuisance parameters. As an example, we
illustrate how the obtained results can be applied to the well-known
\virg{low-rank} parameterization. Furthermore, while the theoretical analysis
will be developed for Real Elliptically Symmetric (RES) distributions, we show
how to extend our results to the case of Circular and Non-Circular Complex
Elliptically Symmetric (C-CES and NC-CES) distributions.

</details>


### [8] [Numerical computation of the Rosenblatt distribution and applications](https://arxiv.org/abs/2506.23337)
*Nikolai N. Leonenko,Andrey Pepelyshev*

Main category: math.ST

TL;DR: 本文研究了Rosenblatt分布在长程依赖平稳高斯过程非线性泛函极限定理中的关键作用，提出了其特征函数的新表达式，并开发了Riesz积分算子所有特征值的精确近似方法及Rosenblatt分布密度的高效计算算法。


<details>
  <summary>Details</summary>
Motivation: Rosenblatt分布在长程依赖高斯过程的非线性泛函极限理论中具有核心地位，但其特征函数和分布密度的计算仍存在挑战，需要更高效的算法和理论突破。

Method: 通过推导Rosenblatt分布特征函数的新表达式，提出Riesz积分算子特征值的精确近似方法，并设计蒙特卡洛模拟验证小样本下该分布在长程依赖高斯过程泛函中的出现规律。

Result: 获得了Rosenblatt分布特征函数的创新解析形式，建立了Riesz算子特征值的有效逼近技术，开发出分布密度的高效计算算法，并通过数值实验验证了理论结果。

Conclusion: 该研究为长程依赖高斯过程非线性泛函的统计分析提供了新的理论工具和计算框架，显著推进了Rosenblatt分布在实际应用中的可操作性。

Abstract: The Rosenblatt distribution plays a key role in the limit theorems for
non-linear functionals of stationary Gaussian processes with long-range
dependence. We derive new expressions for the characteristic function of the
Rosenblatt distribution. Also we present a novel accurate approximation of all
eigenvalues of the Riesz integral operator associated with the correlation
function of the Gaussian process and propose an efficient algorithm for
computation of the density of the Rosenblatt distribution. We perform
Monte-Carlo simulation for small sample sizes to demonstrate the appearance of
the Rosenblatt distribution for several functionals of stationary Gaussian
processes with long-range dependence.

</details>


### [9] [Sampling and Identity-Testing Without Approximate Tensorization of Entropy](https://arxiv.org/abs/2506.23456)
*William Gay,William He,Nicholas Kocurek,Ryan O'Donnell*

Main category: math.ST

TL;DR: 本文研究了满足近似熵张量化(ATE)条件的混合分布的采样与身份测试问题，提出了基于数据初始化的Glauber动力学快速混合方法，并改进了坐标条件采样模型下的身份测试算法。


<details>
  <summary>Details</summary>
Motivation: 研究混合ATE分布的采样与测试复杂度，解决Blanca等人提出的开放性问题，并扩展Huang等人关于Poincar\'e不等式混合分布的工作。

Method: 1. 使用数据初始化实现Glauber动力学的快速混合；2. 在坐标条件采样模型下设计高效身份测试算法，并简化Blanca等人的原始算法。

Result: 1. 获得了满足修正log-Sobolev不等式的混合分布的最优样本复杂度；2. 在坐标条件采样模型中实现了混合ATE分布的高效身份测试。

Conclusion: 该研究为混合ATE分布提供了有效的采样与测试工具，解决了理论计算机科学中的重要问题，并改进了现有算法的效率。

Abstract: Certain tasks in high-dimensional statistics become easier when the
underlying distribution satisfies a local-to-global property called approximate
tensorization of entropy (ATE). For example, the Glauber dynamics Markov chain
of an ATE distribution mixes fast and can produce approximate samples in a
small amount of time, since such a distribution satisfies a modified
log-Sobolev inequality. Moreover, identity-testing for an ATE distribution
requires few samples if the tester is given coordinate conditional access to
the unknown distribution, as shown by Blanca, Chen, \v{S}tefankovi\v{c}, and
Vigoda (COLT 2023).
  A natural class of distributions that do not satisfy ATE consists of mixtures
of (few) distributions that do satisfy ATE. We study the complexity of
identity-testing and sampling for these distributions. Our main results are the
following:
  1. We show fast mixing of Glauber dynamics from a data-based initialization,
with optimal sample complexity, for mixtures of distributions satisfying
modified log-Sobolev inequalities. This extends work of Huang, Koehler, Lee,
Mohanty, Rajaraman, Vuong, and Wu (STOC 2025, COLT 2025) for mixtures of
distributions satisfying Poincar\'e inequalities.
  2. Answering an open question posed by Blanca et al., we give efficient
identity-testers for mixtures of ATE distributions in the
coordinate-conditional sampling access model. We also give some simplifications
and improvements to the original algorithm of Blanca et al.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [10] [Highway toll allocation problem revisited: new methods and characterizations](https://arxiv.org/abs/2506.22475)
*P. Soto-Rodríguez,B. Casas-Méndez,A. Saavedra-Nieves*

Main category: math.OC

TL;DR: 本文研究高速公路通行费分配问题，提出了两种新的分配规则（路段比例共享法和路段补偿共享法），并通过公理化特征和合作博弈关联进行分析，最终构建了一个包含三种规则的通用分配方法家族，并使用真实数据集验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 旨在解决高速公路各路段间通行费的公平分配问题，扩展现有研究并引入更灵活的分配方法。

Method: 提出路段比例共享法和路段补偿共享法两种新规则，通过公理化方法进行特征描述，并与合作博弈解建立关联，最终构建通用分配方法家族。

Result: 新方法在公理性质上展现出与原有路段均等共享法的差异，通用方法家族成功涵盖三种分配规则，实证数据验证了方法的可行性。

Conclusion: 通过理论构建与实证分析，研究为高速公路通行费分配提供了多元化的解决方案框架，拓展了该领域的决策工具箱。

Abstract: This paper considers the highway toll allocation problem (Wu, van den Brink,
and Est\'evez-Fern\'andez in Transport Res B-Meth 180:10288, 2024). The aim is
to allocate the tolls collected from the users of a highway across the various
road sections. To this end, the authors propose, among others, the Segments
Equal Sharing method, which is characterized and reinterpreted as a specific
solution of a cooperative game associated with the problem. This paper presents
two new allocation rules: the Segments Proportional Sharing method and the
Segments Compensated Sharing method. We axiomatically characterize these new
methods and compare their properties to those of the Segments Equal Sharing
method. Furthermore, we also examine the relationship of these methods to the
solution of the associated cooperative game. We conclude the methodological
study by introducing a general family of segment allocation methods that
includes the three aforementioned rules. Finally, we evaluate the performance
of these methods using a real-world dataset.

</details>


### [11] [Hindsight-Guided Momentum (HGM) Optimizer: An Approach to Adaptive Learning Rate](https://arxiv.org/abs/2506.22479)
*Krisanu Sarkar*

Main category: math.OC

TL;DR: HGM是一种基于历史梯度方向自适应调整学习率的一阶优化算法，通过评估当前梯度与累积动量的余弦相似性，在平滑区域加速收敛，在振荡区域保持稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统自适应方法（如Adam、RMSprop）仅依赖梯度幅值调整学习率，忽略了梯度方向等几何信息，导致优化路径的局部曲率和一致性未被充分利用。

Method: HGM引入后见机制，通过计算当前梯度与历史动量的余弦相似度，动态调节学习率：方向一致时增大步长，方向冲突时减小步长。

Result: 该算法在损失函数的平滑区域加速收敛，在尖锐或噪声区域保持稳定，且计算和内存效率与现有优化器相当。

Conclusion: HGM通过智能响应优化地形结构，在非凸场景（如深度神经网络训练）中提供了简单有效的改进，同时保持了高效性。

Abstract: We introduce Hindsight-Guided Momentum (HGM), a first-order optimization
algorithm that adaptively scales learning rates based on the directional
consistency of recent updates. Traditional adaptive methods, such as Adam or
RMSprop , adapt learning dynamics using only the magnitude of gradients, often
overlooking important geometric cues.Geometric cues refer to directional
information, such as the alignment between current gradients and past updates,
which reflects the local curvature and consistency of the optimization path.
HGM addresses this by incorporating a hindsight mechanism that evaluates the
cosine similarity between the current gradient and accumulated momentum. This
allows it to distinguish between coherent and conflicting gradient directions,
increasing the learning rate when updates align and reducing it in regions of
oscillation or noise. The result is a more responsive optimizer that
accelerates convergence in smooth regions of the loss surface while maintaining
stability in sharper or more erratic areas. Despite this added adaptability,
the method preserves the computational and memory efficiency of existing
optimizers.By more intelligently responding to the structure of the
optimization landscape, HGM provides a simple yet effective improvement over
existing approaches, particularly in non-convex settings like that of deep
neural network training.

</details>


### [12] [Mathematical Modeling of Carbon Dioxide Emissions with GDP Linkage: Sensitivity Analysis and Optimal Control Strategy](https://arxiv.org/abs/2506.22483)
*Hua Liu,Zhuoma Gangji,Yumei Wei,Jianhua Ye,Gang Ma*

Main category: math.OC

TL;DR: 本文通过建立四状态变量数学模型，研究大气二氧化碳与GDP、森林面积及人口的动态关系，结合中国实际数据验证理论分析，提出调控建议。


<details>
  <summary>Details</summary>
Motivation: 气候变化与全球变暖是人类面临的最严峻问题之一，主要由温室气体浓度异常升高驱动，数学模型是分析大气二氧化碳动态模式的有力工具。

Method: 建立包含大气二氧化碳、GDP、森林面积和人口的数学模型，利用中国实际数据估计参数并进行数值拟合，采用PRCC和拉丁超立方抽样进行敏感性分析，应用最优控制理论调控二氧化碳水平。

Result: 理论分析与数值拟合验证了模型的边界性和平衡点稳定性，敏感性分析揭示了各组分对参数的依赖关系，最优控制理论提供了二氧化碳调控方案。

Conclusion: 基于理论分析和数值拟合结果，提出了针对大气二氧化碳调控的具体讨论与建议，为应对气候变化提供了科学依据。

Abstract: Climate change and global warming are among the most significant issues that
humanity is currently facing, and also among the issues that pose the greatest
threats to all mankind. These issues are primarily driven by abnormal increases
in greenhouse gas concentrations. Mathematical modeling serves as a powerful
approach to analyze the dynamic patterns of atmospheric carbon dioxide. In this
paper, we established a mathmetical model with four state variables to
investigate the dynamic behavior of the interaction between atmospheric carbon
dioxide, GDP, forest area and human population. Relevant theories were employed
to analyze the system's boundedness and the stability of equilibrium points.
The parameter values were estimated with the help of the actual data in China
and numerical fitting was carried out to verify the results of the theoretical
analysis. The sensitivity analysis of the compartments with respect to the
model parameters was analyzed by using the Partial Rank Correlation Coefficient
(PRCC) and the Latin Hypercube Sampling test. Apply the optimal control theory
to regulate the atmospheric carbon dioxide level and provide the corresponding
numerical fitting. Finally, corresponding discussions and suggestions were put
forward with the help of the results of the theoretical analysis and numerical
fitting.

</details>


### [13] [Optimal investment and consumption under forward utilities with relative performance concerns](https://arxiv.org/abs/2506.22514)
*Anis Matoussi,Guillaume Broux-Quemerais,Zhou Chao*

Main category: math.OC

TL;DR: 本文研究了具有相对绩效关注的n玩家和均值场投资组合优化问题，通过随机HJB方程刻画了前向相对绩效过程，揭示了财富与消费效用的联系，并给出了CRRA型效用下的纳什均衡闭式解。


<details>
  <summary>Details</summary>
Motivation: 探讨非零波动率下财富与消费的相对绩效优化问题，旨在理解时间一致性条件及最优策略特征。

Method: 采用随机HJB方程对前向相对绩效过程进行充分表征，结合CRRA型财富效用和可分离时空依赖性的假设。

Result: 证明了CRRA型财富效用必然对应相同风险厌恶参数的消费效用，并给出了n玩家及均值场问题的纳什均衡闭式解。

Conclusion: 研究深化了对时间一致性漂移条件的理解，并通过数值算例验证了理论结果的实际应用价值。

Abstract: We study a n-player and mean-field portfolio optimization problem under
relative performance concerns with non-zero volatility, for wealth and
consumption. The consistency assumption defining forward relative performance
processes leads to a sufficient characterization of such processes with mean of
a Stochastic HJB equations, which highlights the link between wealth and
consumption utility, and also characterizes the optimal strategies. In
particular, forward relative performance processes with a wealth utility of
CRRA type and separable time and space dependence necessarily have a
consumption utility of the same form, with the same risk aversion parameter.
This characterization gives a better understanding of the drift condition
ensuring time consistency. In this setting, we establish closed form of the
Nash equilibrium for both the n-player and mean eld problems. We also provide
some numerical examples.

</details>


### [14] [Inventory Control Using a Lévy Process for Evaluating Total Costs under Intermittent Demand](https://arxiv.org/abs/2506.22524)
*Ryoya Koide,Yurika Ono,Aya Ishigaki*

Main category: math.OC

TL;DR: 间歇性需求产品存在销售损失和过时的高风险。本研究通过将累积需求建模为漂移泊松过程，并引入停止时间来表示达到再订购点的时机，解决了基于L\'evy过程的库存控制中订单量和再订购点对总成本影响的未解问题。


<details>
  <summary>Details</summary>
Motivation: 间歇性需求产品由于需求事件的偶发性，存在高风险的销售损失和过时。虽然概率预测方法（如L\'evy过程）能够捕捉不确定性，但在库存控制中，订单量和再订购点如何影响总成本尚未有研究。

Method: 本研究通过将累积需求建模为漂移泊松过程，并引入停止时间来表示达到再订购点的时机，从而制定再订购点策略。此外，通过将总成本与ARIMA模型结合再订购点策略的结果进行比较，验证了所提方法的有效性。

Result: 主要结果表明，基于ARIMA预测的总成本随时间线性增长，而基于L\'evy过程的公式提供了总成本的解析表达式，揭示了随机需求波动导致预期总成本以快于线性的速度增长。

Conclusion: 本研究通过L\'evy过程建模间歇性需求，提供了库存控制中总成本的解析表达式，揭示了需求波动对成本增长的加速效应，为间歇性需求产品的库存管理提供了新的理论支持。

Abstract: Products with intermittent demand are characterized by a high risk of sales
losses and obsolescence due to the sporadic occurrence of demand events.
Generally, both point forecasting and probabilistic forecasting approaches are
applied to intermittent demand. In particular, probabilistic forecasting, which
models demand as a stochastic process, is capable of capturing uncertainty. An
example of such modeling is the use of L\'evy processes, which possess
independent increments and accommodate discontinuous changes (jumps). However,
to the best of our knowledge, in inventory control using L\'evy processes, no
studies have investigated how the order quantity and reorder point affect the
total cost. One major difficulty has been the mathematical formulation of
inventory replenishment triggered at reorder points. To address this challenge,
the present study formulates a reorder-point policy by modeling cumulative
demand as a drifted Poisson process and introducing a stopping time to
represent the timing at which the reorder point is reached. Furthermore, the
validity of the proposed method is verified by comparing the total cost with
that obtained from a case where an ARIMA model is combined with a reorder-point
policy. As a main result, while the total cost under ARIMA-based forecasting
increases linearly over time, the L\'evy process-based formulation provides an
analytical expression for the total cost, revealing that random demand
fluctuations cause the expected total cost to grow at a rate faster than
linear.

</details>


### [15] [Correlated Mutations for Integer Programming](https://arxiv.org/abs/2506.22526)
*Ofer M. Shir,Michael Emmerich*

Main category: math.OC

TL;DR: 本文为整数进化策略(IES)奠定理论基础，提出采用$\ell_1$-范数替代传统$\ell_2$-范数，并证明双几何分布(DG)比截断正态分布(TN)更适合无界整数搜索。


<details>
  <summary>Details</summary>
Motivation: 尽管整数规划(IP)理论复杂度降低，启发式算法仍是主流解法。现有IES通过离散化处理连续空间算子，但始终依赖$\ell_2$-范数，需建立更适合离散搜索的理论框架。

Method: 研究采用$\ell_1$-范数，分析步长选择，探讨整数格上相关性度量。重点研究无界整数决策变量的变异分布，比较均匀分布、二项分布、TN和DG的理论特性，提出可扩展的相关变异分布生成方法。

Result: 数值模拟表明DG分布更适合无界整数搜索。实证显示采用相关DG变异的IES在非可分二次IP问题中表现最优。理论分析支持用DG替代TN分布，但最关键的是采用$\ell_1$-范数。

Conclusion: 虽然用DG替代TN分布具有理论和实践优势，但最根本的改进在于采用$\ell_1$-范数而非$\ell_2$-范数作为操作基础。

Abstract: Even with the recent theoretical advancements that dramatically reduced the
complexity of Integer Programming (IP), heuristics remain the dominant
problem-solvers for this difficult category. This study seeks to establish the
groundwork for Integer Evolution Strategies (IESs), a class of randomized
search heuristics inherently designed for continuous spaces. IESs already excel
in treating IP in practice, but accomplish it via discretization and by
applying sophisticated patches to their continuous operators, while
persistently using the $\ell_2$-norm as their operation pillar. We lay
foundations for discrete search, by adopting the $\ell_1$-norm, accounting for
the suitable step-size, and questioning alternative measures to quantify
correlations over the integer lattice. We focus on mutation distributions for
unbounded integer decision variables. We briefly discuss a couple of candidate
discrete probabilities induced by the uniform and binomial distributions, which
we show to possess less appealing theoretical properties, and then narrow down
to the Truncated Normal (TN) and Double Geometric (DG) distributions. We
explore their theoretical properties, including entropy functions, and propose
a procedure to generate scalable correlated mutation distributions. Our
investigations are accompanied by extensive numerical simulations, which
consistently support the claim that the DG distribution is better suited for
unbounded integer search. We link our theoretical perspective to empirical
evidence indicating that an IES with correlated DG mutations outperformed other
strategies over non-separable quadratic IP. We conclude that while the
replacement of the default TN distribution by the DG is theoretically justified
and practically beneficial, the truly crucial change lies in adopting the
$\ell_1$-norm over the $\ell_2$-norm.

</details>


### [16] [On a result by Meshulam](https://arxiv.org/abs/2506.22553)
*Heinz H. Bauschke,Tran Thanh Tung*

Main category: math.OC

TL;DR: 本文扩展了Meshulam(1996)关于欧几里得空间中仿射子空间投影序列有界性的结果，将其推广到凸多面体子集及一般希尔伯特空间。


<details>
  <summary>Details</summary>
Motivation: 研究投影序列的有界性在优化算法和凸分析中具有重要意义，原结果局限于欧几里得空间和仿射子空间，需要更一般的理论框架。

Method: 采用泛函分析和凸几何方法，将原定理从仿射子空间推广到凸多面体，并从欧几里得空间扩展到希尔伯特空间。

Result: 证明了在希尔伯特空间中，任意有限凸多面体集合上的投影序列必定有界，并通过示例展示了结果的紧性。

Conclusion: 该研究显著扩展了投影序列有界性理论的适用范围，为相关优化算法提供了更广泛的理论基础。

Abstract: In 1996, Meshulam proved that every sequence generated by applying
projections onto affine subspaces, drawn from a finite collection in Euclidean
space, must be bounded.
  In this paper, we extend his result not only from affine subspaces to convex
polyhedral subsets, but also from Euclidean to general Hilbert space. Various
examples are provided to illustrate the sharpness of the results.

</details>


### [17] [Maximum Dispersion, Maximum Concentration: Enhancing the Quality of MOP Solutions](https://arxiv.org/abs/2506.22568)
*Gladston Moreira,Ivan Meneghini,Elzabeth Wanner*

Main category: math.OC

TL;DR: 该研究提出了一种多目标优化方法，通过在决策空间增强解分散性，并在目标空间的特定区域集中优化，以平衡解的多样性与收敛性。


<details>
  <summary>Details</summary>
Motivation: 多目标优化问题(MOPs)需要在冲突目标间权衡，传统方法易在决策空间特定区域产生偏差，需同时优化解的分散性与收敛性。

Method: 基于决策者偏好定义目标空间的锥形兴趣区域(ROI)，利用均匀性度量增强决策空间解分散性，结合目标空间集中与决策空间分散进行帕累托优化。

Result: 实验表明该方法能有效平衡分散与集中，减少决策空间偏差，生成更高质量的帕累托最优解。

Conclusion: 结合目标空间区域集中与决策空间分散的策略，显著提升了多目标优化的解质量与多样性，为复杂权衡问题提供新思路。

Abstract: Multi-objective optimization problems (MOPs) often require a trade-off
between conflicting objectives, maximizing diversity and convergence in the
objective space. This study presents an approach to improve the quality of MOP
solutions by optimizing the dispersion in the decision space and the
convergence in a specific region of the objective space. Our approach defines a
Region of Interest (ROI) based on a cone representing the decision maker's
preferences in the objective space, while enhancing the dispersion of solutions
in the decision space using a uniformity measure. Combining solution
concentration in the objective space with dispersion in the decision space
intensifies the search for Pareto-optimal solutions while increasing solution
diversity. When combined, these characteristics improve the quality of
solutions and avoid the bias caused by clustering solutions in a specific
region of the decision space. Preliminary experiments suggest that this method
enhances multi-objective optimization by generating solutions that effectively
balance dispersion and concentration, thereby mitigating bias in the decision
space.

</details>


### [18] [A highly efficient single-loop smoothing damped Newton method for large-scale bilevel hyperparameter optimization of SVC](https://arxiv.org/abs/2506.22603)
*Yixin Wang,Qingna Li,Liwei Zhang*

Main category: math.OC

TL;DR: 本文提出了一种高效的单循环平滑阻尼牛顿法（SDNM），用于解决大规模L1支持向量分类（L1-SVC）超参数选择中的数学规划与均衡约束问题（MPEC）。SDNM在LIBSVM数据集上表现出色，计算速度显著优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习快速发展，双层超参数优化问题规模日益庞大，亟需高效数值算法。本文针对L1-SVC超参数选择中的MPEC问题，旨在设计更高效的求解方法。

Method: 提出单循环平滑阻尼牛顿法（SDNM），充分利用MPEC结构特性避免子问题求解。理论证明在适当条件下具有二次收敛速率，并通过二阶充分条件验证严格局部极小值。

Result: 在LIBSVM数据集上，SDNM性能显著优于SGRM（快20倍）和fmincon（快3倍）。数值实验验证了二次收敛速率及二阶充分条件满足性。

Conclusion: SDNM为大规模MPEC问题提供了高效解决方案，其单循环特性和二次收敛速率在超参数优化领域具有重要应用价值，尤其适合处理海量数据场景。

Abstract: Bilevel hyperparameter optimization has received growing attention thanks to
the fast development of machine learning. Due to the tremendous size of data
sets, the scale of bilevel hyperparameter optimization problem could be
extremely large, posing great challenges in designing efficient numerical
algorithms. In this paper, we focus on solving the large-scale mathematical
programs with equilibrium constraints (MPEC) derived from hyperparameter
selection of L1-support vector classification (L1-SVC). We propose a highly
efficient single-loop smoothing damped Newton method (SDNM) for solving such
MPEC. Compared with most existing algorithms where subproblems are involved and
solved by on-shelf packages, our approach fully takes advantage of the
structure of MPEC and therefore is single-loop. Moreover, the proposed SDNM
enjoys a quadratic convergence rate under proper assumptions. Extensive
numerical results over LIBSVM dataset show the superior performance of SDNM
over other state-of-art algorithms including the Scholtes global relaxation
method (SGRM) with subproblem solved by SNOPT and the Matlab built-in function
fmincon, especially in CPU time. For example, for dataset w4a, SDNM is 20 times
faster than SGRM and 3 times faster than fmincon. Further numerical results
also verifies the quadratic convergence rate of SDNM as well as the fulfillment
of the second order sufficient condition, while guarantees that SDNM returns a
strict local minimizer of the smoothing problem of MPEC.

</details>


### [19] [Breaking a Logarithmic Barrier in the Stopping Time Convergence Rate of Stochastic First-order Methods](https://arxiv.org/abs/2506.23335)
*Yasong Feng,Yifan Jiang,Tianyu Wang,Zhiliang Ying*

Main category: math.OC

TL;DR: 本文提出了一种基于停时的随机优化收敛性分析新方法，突破了现有结果中的对数障碍，并开发了适用于此类随机过程的Gr\"onwall型论证工具。


<details>
  <summary>Details</summary>
Motivation: 针对实际应用中算法常根据观测进度自适应终止的现象，现有分析框架存在局限性，需要更直接的收敛性表征方法。

Method: 采用停时理论直接描述随机过程的收敛性，并开发了专门的Gr\"onwall型论证技术。

Result: 突破了现有结果中的对数障碍，在不引入严格假设的条件下获得了更精确的收敛界限。

Conclusion: 该分析框架为随机优化算法的自适应终止提供了理论支持，所开发的工具可应用于更广泛的随机过程分析场景。

Abstract: This work provides a novel convergence analysis for stochastic optimization
in terms of stopping times, addressing the practical reality that algorithms
are often terminated adaptively based on observed progress. Unlike prior
approaches, our analysis: 1. Directly characterizes convergence in terms of
stopping times adapted to the underlying stochastic process. 2. Breaks a
logarithmic barrier in existing results. Key to our results is the development
of a Gr\"onwall-type argument tailored to such stochastic processes. This tool
enables sharper bounds without restrictive assumptions.

</details>


### [20] [Preconditioned Halpern iteration with adaptive anchoring parameters and an acceleration to Chambolle-Pock algorithm](https://arxiv.org/abs/2506.22725)
*Fangbing Lv,Qiao-Li Dong*

Main category: math.OC

TL;DR: 本文提出了一种带自适应锚定参数的预条件Halpern迭代算法(PHA)，并证明了其强收敛性和至少$\mathcal{O}(1/k)$的收敛速率。同时，开发了加速Chambolle-Pock算法(aCP)，在极小极大矩阵博弈和LASSO问题上展示了优越性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在结合预条件技术和自适应锚定参数改进Halpern迭代算法，提升收敛性能，并扩展至Halpern型预条件邻近点方法，同时开发更高效的加速Chambolle-Pock算法。

Method: 提出PHA算法整合预条件器和自适应锚定参数的Halpern迭代；建立强收敛性和$\mathcal{O}(1/k)$收敛速率；开发具有相同收敛速率的aCP算法，重点关注残差映射和原始-对偶间隙。

Result: 理论证明PHA算法具有强收敛性和至少$\mathcal{O}(1/k)$的收敛速率；aCP算法在数值实验中（极小极大矩阵博弈和LASSO问题）优于文献[18]的Halpern加速Chambolle-Pock算法。

Conclusion: PHA算法和aCP算法在理论和实验中均表现出优越性能，特别是aCP算法在优化问题中具有实际应用优势，为相关领域提供了有效的计算工具。

Abstract: In this article, we propose a preconditioned Halpern iteration with adaptive
anchoring parameters (PHA) algorithm by integrating a preconditioner and
Halpern iteration with adaptive anchoring parameters. Then we establish the
strong convergence and at least $\mathcal{O}(1/k)$ convergence rate of the PHA
algorithm, and extend these convergence results to Halpern-type preconditioned
proximal point method with adaptive anchoring parameters. Moreover, we develop
an accelerated Chambolle--Pock algorithm (aCP) that is shown to have at least
$\mathcal{O}(1/k)$ convergence rate concerning the residual mapping and the
primal-dual gap. Finally, numerical experiments on the minimax matrix game and
LASSO problem are provided to show advantages and outperformance of our aCP
algorithm over Halpern-based accelerated Chambolle--Pock algorithm in [18].

</details>


### [21] [Performance Estimation of second-order optimization methods on classes of univariate functions](https://arxiv.org/abs/2506.22764)
*Anne Rubbens,Nizar Bousselmi,Julien M. Hendrickx,François Glineur*

Main category: math.OC

TL;DR: 本文提出了一种严格的方法，用于计算机辅助分析二阶优化方法在单变量函数类上的最坏性能保证。通过建立插值条件并利用性能估计框架，改进了现有收敛率，并展示了单变量下界。


<details>
  <summary>Details</summary>
Motivation: 研究旨在为二阶优化方法在广义自协调函数和Lipschitz Hessian函数等单变量函数类上的性能提供精确的最坏情况保证，填补现有收敛率分析的不足。

Method: 首先提出通用技术推导单变量函数的插值条件，应用于广义自协调函数和Lipschitz Hessian函数；随后在性能估计框架中利用这些条件，严格分析牛顿法及其变体的收敛性。

Result: 改进了现有收敛率，展示了单变量下界（在多变量情况下同样成立），并基于相同标准分析了这些方法的性能表现。

Conclusion: 该方法为二阶优化方法的性能分析提供了理论保障，所建立的单变量下界对多变量情况具有普适意义，为优化算法设计提供了新的理论工具。

Abstract: We develop a principled approach to obtain exact computer-aided worst-case
guarantees on the performance of second-order optimization methods on classes
of univariate functions. We first present a generic technique to derive
interpolation conditions for a wide range of univariate functions, and use it
to obtain such conditions for generalized self-concordant functions (including
self-concordant and quasi-self-concordant functions) and functions with
Lipschitz Hessian (both convex and non-convex). We then exploit these
conditions within the Performance Estimation framework to tightly analyze the
convergence of second-order methods on univariate functions, including (Cubic
Regularized) Newton's method and several of its variants. Thereby, we improve
on existing convergence rates, exhibit univariate lower bounds (that thus hold
in the multivariate case), and analyze the performance of these methods with
respect to the same criteria.

</details>


### [22] [Optimal Trajectory Planning for Space Object Tracking with Collision-Avoidance Constraints](https://arxiv.org/abs/2506.22797)
*Saif R. Kazi,Harsha Nagarajan,Hassan Hijazi,Przemek Wozniak*

Main category: math.OC

TL;DR: 提出一种针对追踪航天器的控制优化方法，通过离散推力动作和混合整数非线性规划（MINLP）实现长时间碰撞规避轨迹规划，兼顾资源优化与计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决追踪航天器在接近目标空间物体（包括被动碎片和主动机动航天器）时，需同时满足空间约束、动力学约束及碰撞规避的复杂控制问题。

Method: 采用四阶Runge-Kutta法直接离散化非线性运动方程，构建MINLP模型；结合比例缩放技术、基于视角凸重构的有效约束，以及离散动作连续松弛与舍入启发式算法，提升求解效率。

Result: 数值案例验证表明，该方法能高效生成长时间无碰撞轨迹，显著降低计算开销，同时保证燃料等资源的最优利用。

Conclusion: 所提方法为航天器近距离操作提供了计算高效且实用的轨迹规划框架，适用于复杂空间环境下的实时控制任务。

Abstract: A control optimization approach is presented for a chaser spacecraft tasked
with maintaining proximity to a target space object while avoiding collisions.
The target object trajectory is provided numerically to account for both
passive debris and actively maneuvering spacecraft. Thrusting actions for the
chaser object are modeled as discrete (on/off) variables to optimize resources
(e.g., fuel) while satisfying spatial, dynamical, and collision-avoidance
constraints. The nonlinear equation of motion is discretized directly using a
fourth-order Runge-Kutta method without the need for linearized dynamics. The
resulting mixed-integer nonlinear programming (MINLP) formulation is further
enhanced with scaling techniques, valid constraints based on a perspective
convex reformulation, and a combination of continuous relaxations of discrete
actions with rounding heuristics to recover high-quality feasible solutions.
This methodology enables efficient, collision-free trajectory planning over
extended time horizons while reducing computational overhead. The effectiveness
and practicality of the proposed approach is validated through a numerical case
study.

</details>


### [23] [Denoising Multi-Color QR Codes and Stiefel-Valued Data by Relaxed Regularizations](https://arxiv.org/abs/2506.22826)
*Robert Beinert,Jonas Bresch*

Main category: math.OC

TL;DR: 本文扩展了一种高效的流形数据去噪方法，适用于多二进制和Stiefel流形数据，提出了基于TV和Tikhonov的去噪模型及易求解的凸松弛方法，并通过合成实验验证。


<details>
  <summary>Details</summary>
Motivation: 流形值数据（如色彩修复中的圆/球面模型、旋转信息或双曲空间统计）的去噪需求催生了多种TV和Tikhonov模型的推广。近期通过欧氏嵌入和凸松弛的高效方法需要扩展至多二进制（如多色QR码）和Stiefel流形（图像/视频识别）数据。

Method: 将数据嵌入欧氏空间，用半正定固定秩矩阵编码非凸流形，松弛秩约束获得凸问题。针对多二进制和Stiefel数据提出TV/Tikhonov去噪模型及凸松弛方案。

Result: 在概念验证性合成实验中，所有推导方法均得到有效评估，证实了其可行性。

Conclusion: 该方法成功扩展至新型流形数据，为多二进制和Stiefel值数据的去噪提供了高效解决方案，未来可应用于QR码优化和视觉识别任务。

Abstract: The handling of manifold-valued data, for instance, plays a central role in
color restoration tasks relying on circle- or sphere-valued color models, in
the study of rotational or directional information related to the special
orthogonal group, and in Gaussian image processing, where the pixel statistics
are interpreted as values on the hyperbolic sheet. Especially, to denoise these
kind of data, there have been proposed several generalizations of total
variation (TV) and Tikhonov-type denoising models incorporating the underlying
manifolds. Recently, a novel, numerically efficient denoising approach has been
introduced, where the data are embedded in an Euclidean ambient space, the
non-convex manifolds are encoded by a series of positive semi-definite,
fixed-rank matrices, and the rank constraint is relaxed to obtain a
convexification that can be solved using standard algorithms from convex
analysis. The aim of the present paper is to extent this approach to new kinds
of data like multi-binary and Stiefel-valued data. Multi-binary data can, for
instance, be used to model multi-color QR codes whereas Stiefel-valued data
occur in image and video-based recognition. For both new data types, we propose
TV- and Tikhonov-based denoising modelstogether with easy-to-solve
convexification. All derived methods are evaluated on proof-of-concept,
synthetic experiments.

</details>


### [24] [Deep neural networks can provably solve Bellman equations for Markov decision processes without the curse of dimensionality](https://arxiv.org/abs/2506.22851)
*Arnulf Jentzen,Konrad Kleinberg,Thomas Kruse*

Main category: math.OC

TL;DR: 本文研究了马尔可夫决策过程（MDP）中$Q$-函数的深度神经网络（DNN）逼近方法，证明了在特定条件下，DNN能以多项式复杂度逼近Bellman方程的解。


<details>
  <summary>Details</summary>
Motivation: 离散时间随机最优控制问题和MDP是强化学习理论的基础模型，而Bellman方程及其解$Q$-函数是解决MDP的核心工具。本文旨在构建DNN对无限时间范围、有限控制集的MDP的$Q$-函数进行高效逼近。

Method: 通过使用带泄漏ReLU激活的DNN逼近MDP的回报函数和随机转移动态，并基于全历史递归多级定点（MLFP）近似方案，证明了$Q_d\colon \mathbb R^d\to \mathbb R^{|A|}$的$L^2$逼近可行性。

Result: 研究表明，若MDP的回报函数和转移动态可被DNN逼近，则对应的Bellman方程解$Q_d$也能被DNN以$L^2$意义逼近，且参数数量在状态空间维度$d$和误差倒数$1/\varepsilon$上至多呈多项式增长。

Conclusion: 本文为MDP中$Q$-函数的DNN逼近提供了理论保证，展示了在强化学习中应用DNN解决高维问题的潜力。

Abstract: Discrete time stochastic optimal control problems and Markov decision
processes (MDPs) are fundamental models for sequential decision-making under
uncertainty and as such provide the mathematical framework underlying
reinforcement learning theory. A central tool for solving MDPs is the Bellman
equation and its solution, the so-called $Q$-function. In this article, we
construct deep neural network (DNN) approximations for $Q$-functions associated
to MDPs with infinite time horizon and finite control set $A$. More
specifically, we show that if the the payoff function and the random transition
dynamics of the MDP can be suitably approximated by DNNs with leaky rectified
linear unit (ReLU) activation, then the solutions $Q_d\colon \mathbb R^d\to
\mathbb R^{|A|}$, $d\in \mathbb{N}$, of the associated Bellman equations can
also be approximated in the $L^2$-sense by DNNs with leaky ReLU activation
whose numbers of parameters grow at most polynomially in both the dimension
$d\in \mathbb{N}$ of the state space and the reciprocal $1/\varepsilon$ of the
prescribed error $\varepsilon\in (0,1)$. Our proof relies on the recently
introduced full-history recursive multilevel fixed-point (MLFP) approximation
scheme.

</details>


### [25] [On the controllability of laminated beams with Venttsel-type boundary conditions](https://arxiv.org/abs/2506.22887)
*George J. Bautista,Roberto de A. Capistrano-Filho,Juan Límaco*

Main category: math.OC

TL;DR: 本文研究了具有Venttsel型边界条件的Timoshenko叠层梁系统的边界可控性，通过引入三种边界控制并建立相应的观测不等式，证明了系统的可控性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索Timoshenko叠层梁在Venttsel型边界条件下的可控性问题，特别是在仅施加边界控制的情况下实现系统控制。

Method: 方法包括推导对应伴随系统的观测不等式，并利用经典Hilbert唯一性方法（HUM）的对偶框架来解决控制问题。

Result: 主要成果是证明了由三个梁组成的系统在动态Venttsel型边界条件下的可控性，这是对Venttsel原始工作的扩展。

Conclusion: 结论表明，通过适当的边界控制和观测不等式，可以实现Timoshenko叠层梁系统的有效控制，为相关工程应用提供了理论支持。

Abstract: This paper examines the boundary controllability of a Timoshenko laminated
beam system subject to Venttsel-type boundary conditions. The study focuses on
a novel configuration in which three controls are applied solely at the
boundary of the beam. Controllability is established by deriving an appropriate
observability inequality for the corresponding adjoint system, which is then
employed within the framework of the duality method in the setup of the
classical Hilbert uniqueness method (HUM) to achieve the control problem. The
main contribution lies in the analysis of a system comprising three beams
governed by dynamic Venttsel-type boundary conditions, as introduced by
Venttsel in [Theory Probab. Appl., 4 (1959)].

</details>


### [26] [Energy-Aware Model Predictive Control for Batch Manufacturing System Scheduling Under Different Electricity Pricing Strategies](https://arxiv.org/abs/2506.22923)
*Hongliang Li,Herschel C. Pangborn,Ilya Kovalenko*

Main category: math.OC

TL;DR: 本文提出了一种基于模型预测控制（MPC）的能源感知框架，用于动态调度制造过程以响应时变电价，同时不牺牲生产目标或违反生产约束。


<details>
  <summary>Details</summary>
Motivation: 制造业是高能耗行业之一，面临降低能源成本的压力。如何在满足生产目标和约束的同时，减少能源使用费用是一个重要问题。

Method: 开发了一个基于网络的制造系统模型，以捕捉复杂的物料流动、批量处理以及缓冲区和机器的容量。调度问题被表述为一个混合整数二次规划（MIQP），平衡能源成本、缓冲区水平和生产需求。

Result: 案例研究评估了所提出的MPC框架在四种工业电价方案下的表现。数值结果表明，该方法在满足生产目标和约束的同时，减少了能源使用费用。

Conclusion: 研究结果强调了在制造调度决策中考虑详细电价结构的重要性，并为制造商在选择不同电价策略时提供了实用见解。

Abstract: Manufacturing industries are among the highest energy-consuming sectors,
facing increasing pressure to reduce energy costs. This paper presents an
energy-aware Model Predictive Control (MPC) framework to dynamically schedule
manufacturing processes in response to time-varying electricity prices without
compromising production goals or violating production constraints. A
network-based manufacturing system model is developed to capture complex
material flows, batch processing, and capacities of buffers and machines. The
scheduling problem is formulated as a Mixed-Integer Quadratic Program (MIQP)
that balances energy costs, buffer levels, and production requirements. A case
study evaluates the proposed MPC framework under four industrial electricity
pricing schemes. Numerical results demonstrate that the approach reduces energy
usage expenses while satisfying production goals and adhering to production
constraints. The findings highlight the importance of considering the detailed
electricity cost structure in manufacturing scheduling decisions and provide
practical insights for manufacturers when selecting among different electricity
pricing strategies.

</details>


### [27] [Douglas--Rachford for multioperator comonotone inclusions with applications to multiblock optimization](https://arxiv.org/abs/2506.22928)
*Jan Harold Alcantara,Minh N. Dao,Akiko Takeda*

Main category: math.OC

TL;DR: 本文研究了自适应Douglas-Rachford（aDR）算法在求解涉及多个极大共单调算子和的包含问题时的收敛性。通过引入乘积空间重构处理非凸值算子，并基于Attouch-Th\\'{e}ra对偶框架分析收敛性，最终推导出适用于多块和非凸优化的ADMM类算法。


<details>
  <summary>Details</summary>
Motivation: 针对多算子包含问题（特别是涉及共单调算子的情形），现有方法难以处理非凸值算子。研究aDR算法的收敛性可为结构化凸优化及非凸优化问题提供新的求解框架。

Method: 采用乘积空间重构技术处理非凸值算子，在共单调性假设下分析aDR算法的收敛性。利用Attouch-Th\\'{e}ra对偶框架，通过对偶包含问题研究算法收敛，并应用于KKT系统的算子包含形式以推导多块ADMM类算法。

Result: 证明了aDR算法在共单调算子条件下的收敛性，并成功将其扩展为多块非凸优化的ADMM型算法。在完全凸和强凸-弱凸两种情形下均建立了收敛性保证。

Conclusion: 该研究不仅推广了经典Douglas-Rachford算法与ADMM的对偶关系至多块非凸情形，还为结构化优化问题提供了具有收敛保证的新算法框架。

Abstract: We study the convergence of the adaptive Douglas--Rachford (aDR) algorithm
for solving a multioperator inclusion problem involving the sum of maximally
comonotone operators. To address such problems, we adopt a product space
reformulation that accommodates nonconvex-valued operators, which is essential
when dealing with comonotone mappings. We establish convergence of the aDR
method under comonotonicity assumptions, subject to suitable conditions on the
algorithm parameters and comonotonicity moduli of the operators. Our analysis
leverages the Attouch--Th\'{e}ra duality framework, which allows us to study
the convergence of the aDR algorithm via its application to the dual inclusion
problem. As an application, we derive a multiblock ADMM-type algorithm for
structured convex and nonconvex optimization problems by applying the aDR
algorithm to the operator inclusion formulation of the KKT system. The
resulting method extends to multiblock and nonconvex settings the classical
duality between the Douglas--Rachford algorithm and the alternating direction
method of multipliers in the convex two-block case. Moreover, we establish
convergence guarantees for both the fully convex and strongly convex-weakly
convex regimes.

</details>


### [28] [Detection of coordinated fleet vehicles in route choice urban games. Part I. Inverse fleet assignment theory](https://arxiv.org/abs/2506.22966)
*Grzegorz Jamróz,Rafał Kucharski*

Main category: math.OC

TL;DR: 本文探讨了未来城市系统中车队集体路径选择对交通管理的影响，证明了在特定条件下逆向车队分配问题有解，并分析了自私型车队策略的可逆性及其实际应用挑战。


<details>
  <summary>Details</summary>
Motivation: 研究车队集体路径选择对城市交通网络的潜在破坏性影响，探索是否可通过已知车队规模和总流量逆向推演车队路径分布。

Method: 引入正向车队分配算子并分析其性质，证明其在自私型车队控制目标下的可逆性；对比短视策略与Stackelberg/Nash路径选择的差异。

Result: 证实当车队采用比'利他'更'自私'的短视策略时，逆向车队分配问题有解；发现最优Stackelberg策略可能导致交通网络混沌。

Conclusion: 自私型车队策略具有数学可解性，但实际部署面临挑战；Stackelberg最优路径可能引发交通混乱，需谨慎设计控制策略。

Abstract: Detection of collectively routing fleets of vehicles in future urban systems
may become important for the management of traffic, as such routing may
destabilize urban networks leading to deterioration of driving conditions.
Accordingly, in this paper we discuss the question whether it is possible to
determine the flow of fleet vehicles on all routes given the fleet size and
behaviour as well as the combined total flow of fleet and non-fleet vehicles on
every route. We prove that the answer to this Inverse Fleet Assignment Problem
is 'yes' for myopic fleet strategies which are more 'selfish' than
'altruistic', and 'no' otherwise, under mild assumptions on route/link
performance functions. To reach these conclusions we introduce the forward
fleet assignment operator and study its properties, proving that it is
invertible for 'bad' objectives of fleet controllers. We also discuss the
challenges of implementing myopic fleet routing in the real world and compare
it to Stackelberg and Nash routing. Finally, we show that optimal Stackelberg
fleet routing could involve highly variable mixed strategies in some scenarios,
which would likely cause chaos in the traffic network.

</details>


### [29] [Equilibrium Correction Iteration for A Class of Mean-Field Game Inverse Problem](https://arxiv.org/abs/2506.23018)
*Jiajia Yu,Jian-Guo Liu,Hongkai Zhao*

Main category: math.OC

TL;DR: 本文提出了一种名为均衡校正迭代(ECI)的新方法，用于解决平均场博弈(MFGs)中的环境势能识别问题，并通过两种加速变体(BRI和HECI)提高计算效率，同时揭示了该问题与逆线性抛物方程的联系。


<details>
  <summary>Details</summary>
Motivation: 研究旨在从均衡状态下的值函数中恢复未知势能，为逆平均场博弈问题提供新的解决视角。

Method: 提出了ECI迭代策略，利用MFGs结构而非通用优化框架；开发了BRI(使用非精确正向求解器)和HECI(采用多级网格)两种加速方法。

Result: 数值实验表明：BRI在通用场景高效，HECI擅长低频势能恢复；同时揭示了粘度、终止时间和交互成本对逆问题适定性的影响。

Conclusion: 该工作不仅为逆MFGs提供了有效解决方案，还通过建立与逆抛物方程的联系，为未来理论分析指明了方向。

Abstract: This work investigates the ambient potential identification problem in
inverse Mean-Field Games (MFGs), where the goal is to recover the unknown
potential from the value function at equilibrium. We propose a simple yet
effective iterative strategy, Equilibrium Correction Iteration (ECI), that
leverages the structure of MFGs rather than relying on generic optimization
formulations. ECI uncovers hidden information from equilibrium measurements,
offering a new perspective on inverse MFGs. To improve computational
efficiency, two acceleration variants are introduced: Best Response Iteration
(BRI), which uses inexact forward solvers, and Hierarchical ECI (HECI), which
incorporates multilevel grids. While BRI performs efficiently in general
settings, HECI proves particularly effective in recovering low-frequency
potentials. We also highlight a connection between the potential identification
problem in inverse MFGs and inverse linear parabolic equations, suggesting
promising directions for future theoretical analysis. Finally, comprehensive
numerical experiments demonstrate how viscosity, terminal time, and interaction
costs can influence the well-posedness of the inverse problem.

</details>


### [30] [On the Out-of-Sample Performance of Stochastic Dynamic Programming and Model Predictive Control](https://arxiv.org/abs/2506.23097)
*Dominic S. T. Keehan,Andrew B. Philpott,Edward J. Anderson*

Main category: math.OC

TL;DR: 本文探讨了在何种条件下基于样本平均近似的随机动态规划(SDP)可能被模型预测控制(MPC)超越。研究发现，根据问题的凹凸性，MPC可视为解决SDP问题的均值约束分布模糊版本，这解释了MPC在某些应用中表现更优的原因。


<details>
  <summary>Details</summary>
Motivation: 研究动机是比较SDP和MPC两种多阶段随机优化方法的性能差异，特别是在特定条件下MPC可能优于SDP的情况。

Method: 通过理论分析，将MPC解释为求解均值约束的分布模糊问题，并与SDP进行对比。随后通过一个代表性多阶段随机优化问题进行实证研究。

Result: 研究发现当底层随机变量的概率分布存在偏态或右尾权重较大时，MPC确实可能成为更优的选择。

Conclusion: 结论表明MPC在特定分布特征下具有优势，这为实际应用中方法选择提供了理论依据。分布特性(如偏态和尾部权重)是决定MPC是否优于SDP的关键因素。

Abstract: Sample average approximation-based stochastic dynamic programming (SDP) and
model predictive control (MPC) are two different methods for approaching
multistage stochastic optimization. In this paper we investigate the conditions
under which SDP may be outperformed by MPC. We show that, depending on the
presence of concavity or convexity, MPC can be interpreted as solving a
mean-constrained distributionally ambiguous version of the problem that is
solved by SDP. This furnishes performance guarantees when the true mean is
known and provides intuition for why MPC performs better in some applications
and worse in others. We then study a multistage stochastic optimization problem
that is representative of the type for which MPC may be the better choice. We
find that this can indeed be the case when the probability distribution of the
underlying random variable is skewed or has enough weight in the right-hand
tail.

</details>


### [31] [Conductance Estimation in Digraphs: Submodular Transformation, Lovász Extension and Dinkelbach Iteration](https://arxiv.org/abs/2506.23131)
*Sihong Shao,Chuan Yang,Xinyang Ye*

Main category: math.OC

TL;DR: 本文提出了一种新的有向图分割框架，通过Lov\'asz扩展和分数规划，设计了DSI算法，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统有向图分割方法通过对称化邻接矩阵忽略方向性，无法捕捉网络内在不平衡性，亟需新方法解决这一根本不对称问题。

Method: 基于子模变换的传导性理论，构建连续化框架，采用三步Dinkelbach迭代松弛分数规划问题，提出可解析求解子问题且收敛性有保证的DSI算法。

Result: 在合成和真实网络上的实验表明，DSI算法在有向图传导最小化任务中显著优于现有最先进方法。

Conclusion: 该研究通过数学严谨的算法设计，有效解决了有向图分割中的方向依赖性难题，为网络分析提供了新工具。

Abstract: Conventional spectral digraph partitioning methods typically symmetrize the
adjacency matrix, thereby transforming the directed graph partitioning problem
into an undirected one, where bipartitioning is commonly linked to minimizing
graph conductance. However, such symmetrization approaches disregard the
directional dependencies of edges in digraphs, failing to capture the inherent
imbalance crucial to directed network modeling. Building on the parallels
between digraph conductance and conductance under submodular transformations,
we develop a generalized framework to derive their continuous formulations. By
leveraging properties of the Lov\'asz extension, this framework addresses the
fundamental asymmetry problem in digraph partitioning. We then formulate an
equivalent fractional programming problem, relax it via a three-step Dinkelbach
iteration procedure, and design the Directed Simple Iterative ($\mathbf{DSI}$)
algorithm for estimating digraph conductance. The subproblem within
$\mathbf{DSI}$ is analytically solvable, and the algorithm is guaranteed to
converge provably to a binary local optimum. Extensive experiments on synthetic
and real-world networks demonstrate that our $\mathbf{DSI}$ algorithm
significantly outperforms several state-of-the-art methods in digraph
conductance minimization.

</details>


### [32] [Sample-Cluster-Select: A new framework to obtain diverse approximate solutions of combinatorial optimization problems](https://arxiv.org/abs/2506.23278)
*Susumu Hashimoto,Takeaki Uno*

Main category: math.OC

TL;DR: 本文提出Sample-Cluster-Select (SCS)方法，通过采样、聚类和选择代表性解决方案，帮助用户理解组合优化问题的解空间，增强对计算结果的信任。实验表明SCS优于多起点局部搜索和$k$-best算法，并与进化算法表现相当。


<details>
  <summary>Details</summary>
Motivation: 实践中，决策者常因对优化模型和计算结果缺乏信任而犹豫是否实施数学模型的解。SCS旨在通过提供多个代表性解及其邻近解，帮助用户理解解空间，从而建立信任。

Method: SCS方法分为三步：采样潜在解、对这些解进行聚类、为每个聚类选择一个代表性解。该方法假设存在可接受的解集，并通过聚类揭示解空间的局部结构和邻近解。

Result: 在随机生成的实例上，SCS在大多数情况下优于多起点局部搜索和$k$-best算法，与进化算法表现相当，但未超越某些变体。聚类方法提供了现有方法难以获得的解空间洞察，如相似潜在解的局部结构和代表性解的邻近解。

Conclusion: SCS方法通过提供多个代表性解及其邻近解，帮助用户更好地理解解空间，从而增强对实施解决方案的信心。聚类方法为解空间分析提供了新的视角。

Abstract: When solving real-world problems, practitioners often hesitate to implement
solutions obtained from mathematical models, especially for important
decisions. This hesitation stems from practitioners' lack of trust in
optimization models and computational results. To address these challenges, we
propose Sample-Cluster-Select (SCS) for solving practical combinatorial
optimization problems under the assumption of potentially acceptable solution
set. SCS first samples the potential solutions, performs clustering on these
solutions, and selects a representative solution for each cluster. SCS aims to
build trust by helping users understand the solution space through multiple
representative solutions, while simultaneously identifying promising
alternatives around these solutions. We conducted experiments on randomly
generated instances, comparing SCS against multi-start local search and
$k$-best algorithms where efficient methods exist, or evolutionary algorithms
otherwise. The results show that SCS outperforms multi-start local search and
$k$-best algorithms in most cases, while showing competitive performance
against evolutionary algorithms, though not surpassing some of their variants.
Most importantly, we found that the clustering approach provides insights into
solutions that are difficult to obtain with existing methods, such as local
structures of similar potential solutions and neighboring solutions of
representative solutions. Thus, our approach helps practitioners understand the
solution space better, thereby increasing their confidence in implementing the
proposed solutions.

</details>


### [33] [On the boundedness of the sequence generated by minibatch stochastic gradient descent](https://arxiv.org/abs/2506.23303)
*Heinz H. Bauschke,Tran Thanh Tung*

Main category: math.OC

TL;DR: 本文扩展了Polyak步长在随机梯度下降(SGD)中的应用，证明了在更广泛的函数类（包括强制函数）中迭代的有界性成立，并讨论了有界性可能不成立的情况。


<details>
  <summary>Details</summary>
Motivation: 近期Polyak步长的随机梯度下降方法重新受到关注，但现有研究仅在强凸性假设下证明了迭代的有界性。本文旨在扩展这一结果至更广泛的函数类别。

Method: 通过理论分析，研究了随机梯度下降中采用递减Polyak步长时迭代的有界性条件，特别关注强制函数类。

Result: 证明了在强制函数等更广泛的函数类中，迭代序列的有界性仍然成立，同时提出了一个有界性可能不成立的案例。

Conclusion: 研究扩展了Polyak步长随机梯度下降的适用性，为更广泛的目标函数提供了收敛性保证，并指出了有界性条件的边界情况。

Abstract: Stochastic Gradient Descent (SGD) with Polyak's stepsize has recently gained
renewed attention in stochastic optimization. Recently, Orvieto,
Lacoste-Julien, and Loizou introduced a decreasing variant of Polyak's
stepsize, where convergence relies on a boundedness assumption of the iterates.
They established that this assumption holds under strong convexity. In this
paper, we extend their result by proving that boundedness also holds for a
broader class of objective functions, including coercive functions. We also
present a case in which boundedness may or may not hold.

</details>


### [34] [Swapping objectives accelerates Davis-Yin splitting](https://arxiv.org/abs/2506.23475)
*Edward Duc Hien Nguyen,Jaewook J. Suh,Xin Jiang,Shiqian Ma*

Main category: math.OC

TL;DR: 本文研究了Davis-Yin分裂（DYS）在凸优化问题中的应用，发现交换两个非光滑凸函数的角色可以加快收敛速度。通过建立最佳收敛率，揭示了DYS及其交换变体在收敛行为上的差异。


<details>
  <summary>Details</summary>
Motivation: 在凸优化问题中，交换DYS算法中两个非光滑凸函数的角色对收敛速度的影响尚未充分研究。本文旨在填补这一空白，探讨这种交换如何改变算法的收敛行为。

Method: 使用原始-对偶间隙函数作为性能指标，建立了DYS及其交换变体的最佳收敛率。特别关注了Douglas-Rachford分裂算法（DYS的特例）的收敛行为。

Result: 研究发现，Douglas-Rachford分裂算法的两种变体具有相同的最坏收敛率，而两种DYS变体的收敛率则存在差异。通过具体示例进一步说明了这种差异。

Conclusion: 交换DYS算法中两个非光滑凸函数的角色可以显著影响收敛速度，这一发现为优化算法的设计提供了新的见解。

Abstract: In this work, we investigate the application of Davis-Yin splitting (DYS) to
convex optimization problems and demonstrate that swapping the roles of the two
nonsmooth convex functions can result in a faster convergence rate. Such a swap
typically yields a different sequence of iterates, but its impact on
convergence behavior has been largely understudied or often overlooked. We
address this gap by establishing best-known convergence rates for DYS and its
swapped counterpart, using the primal--dual gap function as the performance
metric. Our results indicate that variants of the Douglas--Rachford splitting
algorithm (a special case of DYS) share the same worst-case rate, whereas the
convergence rates of the two DYS variants differ. This discrepancy is further
illustrated through concrete examples.

</details>


### [35] [Optimized methods for composite optimization: a reduction perspective](https://arxiv.org/abs/2506.23756)
*Jinho Bok,Jason M. Altschuler*

Main category: math.OC

TL;DR: 本文提出了一种通用框架，能够直接从无约束光滑优化的优化方法中推导出复合优化的优化方法，扩展了原始方法并统一了收敛性分析。


<details>
  <summary>Details</summary>
Motivation: 现有的优化方法通常针对特定问题定制，难以扩展到其他设置。本文旨在解决这一挑战，提供一种通用框架来扩展优化方法。

Method: 通过代数恒等式提供了一种统一且直接的方式，将无约束优化的收敛性分析扩展到复合优化设置。框架将优化方法从无约束光滑优化直接推广到复合优化。

Result: 应用该框架，本文展示了：(1) 近端梯度下降的步长加速现象；(2) 近端优化梯度法的收敛速度优于FISTA；(3) 一种新方法在复合设置中改进了梯度范数最小化的最新速率。

Conclusion: 该框架为复合优化提供了一种通用且高效的优化方法推导方式，显著提升了现有方法的性能，并为未来研究提供了新的方向。

Abstract: Recent advances in convex optimization have leveraged computer-assisted
proofs to develop optimized first-order methods that improve over classical
algorithms. However, each optimized method is specially tailored for a
particular problem setting, and it is a well-documented challenge to extend
optimized methods to other settings due to their highly bespoke design and
analysis. We provide a general framework that derives optimized methods for
composite optimization directly from those for unconstrained smooth
optimization. The derived methods naturally extend the original methods,
generalizing how proximal gradient descent extends gradient descent. The key to
our result is certain algebraic identities that provide a unified and
straightforward way of extending convergence analyses from unconstrained to
composite settings. As concrete examples, we apply our framework to establish
(1) the phenomenon of stepsize acceleration for proximal gradient descent; (2)
a convergence rate for the proximal optimized gradient method which is faster
than FISTA; (3) a new method that improves the state-of-the-art rate for
minimizing gradient norm in the composite setting.

</details>


### [36] [A Structured Proximal Stochastic Variance Reduced Zeroth-order Algorithm](https://arxiv.org/abs/2506.23758)
*Marco Rando,Cheik Traoré,Cesare Molinari,Lorenzo Rosasco,Silvia Villa*

Main category: math.OC

TL;DR: 本文提出了一种结构化方差缩减有限差分算法，用于解决无梯度信息的非光滑有限和最小化问题，证明了其在非凸函数和满足Polyak-{\L}ojasiewicz条件下的收敛速率，并通过实验验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 有限和最小化是优化领域的核心问题，传统一阶优化方法在梯度信息缺失时失效。有限差分法虽能替代，但方差缩减技术与方向结构化的结合效果尚未探索。

Method: 提出结构化方差缩减有限差分算法，将正交性等方向约束融入方差缩减框架，适用于非光滑有限和最小化问题，并降低单次迭代成本。

Result: 理论分析表明，算法在非凸函数上达到最优收敛速率，对满足Polyak-{\L}ojasiewicz条件的函数同样有效；数值实验证实其实际性能显著优于现有方法。

Conclusion: 该算法通过结构化方向与方差缩减的结合，实现了理论最优性与实践高效性的统一，为无梯度优化问题提供了新解决方案。

Abstract: Minimizing finite sums of functions is a central problem in optimization,
arising in numerous practical applications. Such problems are commonly
addressed using first-order optimization methods. However, these procedures
cannot be used in settings where gradient information is unavailable.
Finite-difference methods provide an alternative by approximating gradients
through function evaluations along a set of directions. For finite-sum
minimization problems, it was shown that incorporating variance-reduction
techniques into finite-difference methods can improve convergence rates.
Additionally, recent studies showed that imposing structure on the directions
(e.g., orthogonality) enhances performance. However, the impact of structured
directions on variance-reduced finite-difference methods remains unexplored. In
this work, we close this gap by proposing a structured variance-reduced
finite-difference algorithm for non-smooth finite-sum minimization. We analyze
the proposed method, establishing convergence rates for non-convex functions
and those satisfying the Polyak-{\L}ojasiewicz condition. Our results show that
our algorithm achieves state-of-the-art convergence rates while incurring lower
per-iteration costs. Finally, numerical experiments highlight the strong
practical performance of our method.

</details>


### [37] [Production Planning Under Demand and Endogenous Supply Uncertainty](https://arxiv.org/abs/2506.23780)
*Mike Hewitt,Giovanni Pantuso*

Main category: math.OC

TL;DR: 研究如何在需求和生产良率不确定的情况下，从不同产能设施中采购成品库存以最大化利润，提出了一种基于Benders分解的精确算法，并验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 成品库存采购决策面临需求和设施生产良率的双重不确定性，且生产良率具有内生性（取决于生产设施和产量），需要开发有效的优化方法。

Method: 将问题建模为两阶段随机规划，提出基于Benders分解的精确求解算法，并严格证明算法正确性。

Result: 计算实验表明该算法显著优于已知基准方法，同时验证了同时考虑需求和良率不确定性的价值。

Conclusion: 本研究提出的算法能有效处理内生性生产不确定性，为供应链库存优化提供了新工具，并证实双重不确定性建模的必要性。

Abstract: We study the problem of determining how much finished goods inventory to
source from different capacitated facilities in order to maximize profits
resulting from sales of such inventory. We consider a problem wherein there is
uncertainty in demand for finished goods inventory and production yields at
facilities. Further, we consider that uncertainty in production yields is
endogenous, as it depends on both the facilities where a product is produced
and the volumes produced at those facilities. We model the problem as a two
stage stochastic program and propose an exact, Benders-based algorithm for
solving instances of the problem. We prove the correctness of the algorithm and
with an extensive computational study demonstrate that it outperforms known
benchmarks. Finally, we establish the value in modeling uncertainty in both
demands and production yields.

</details>


### [38] [Data-Driven Performance Guarantees for Parametric Optimization Problems](https://arxiv.org/abs/2506.23819)
*Jingyi Huang,Paul Goulart,Kostas Margellos*

Main category: math.OC

TL;DR: 本文提出一种数据驱动方法，为迭代算法求解的参数优化问题建立概率性能保证，解决收敛性分析和固定迭代次数下的性能度量上界问题。


<details>
  <summary>Details</summary>
Motivation: 在线优化问题常因计算时间有限而缺乏现有性能保证或过于保守，需开发能提供可靠收敛保证的方法。

Method: 基于采样参数实例构建场景优化程序，利用场景优化理论工具推导达到给定容差所需迭代次数的概率保证，并引入松弛方法权衡迭代次数与收敛阈值违反风险。

Result: 数值模拟验证了该方法在提供概率收敛保证及评估解精度与计算成本权衡方面的有效性。

Conclusion: 该框架为有限计算时间下的在线优化问题提供了实用的概率性能保证工具，通过场景优化实现了收敛性与计算效率的量化平衡。

Abstract: We propose a data-driven method to establish probabilistic performance
guarantees for parametric optimization problems solved via iterative
algorithms. Our approach addresses two key challenges: providing convergence
guarantees to characterize the worst-case number of iterations required to
achieve a predefined tolerance, and upper bounding a performance metric after a
fixed number of iterations. These guarantees are particularly useful for online
optimization problems with limited computational time, where existing
performance guarantees are often unavailable or unduly conservative. We
formulate the convergence analysis problem as a scenario optimization program
based on a finite set of sampled parameter instances. Leveraging tools from
scenario optimization theory enables us to derive probabilistic guarantees on
the number of iterations needed to meet a given tolerance level. Using recent
advancements in scenario optimization, we further introduce a relaxation
approach to trade the number of iterations against the risk of violating
convergence criteria thresholds. Additionally, we analyze the trade-off between
solution accuracy and time efficiency for fixed-iteration optimization problems
by casting them into scenario optimization programs. Numerical simulations
demonstrate the efficacy of our approach in providing reliable probabilistic
convergence guarantees and evaluating the trade-off between solution accuracy
and computational cost.

</details>


### [39] [Proving the Limited Scalability of Centralized Distributed Optimization via a New Lower Bound Construction](https://arxiv.org/abs/2506.23836)
*Alexander Tyurin*

Main category: math.OC

TL;DR: 本文研究了联邦学习中的集中式分布式优化问题，证明了在使用无偏随机稀疏化压缩器时，服务器端通信时间和方差相关运行时间无法随工作节点数$n$实现超对数级扩展，揭示了分布式优化的根本局限性。


<details>
  <summary>Details</summary>
Motivation: 分布式优化的主要动机是通过增加工作节点数$n$实现可扩展性，例如分布式SGD的方差相关运行时间项$\frac{h \sigma^2 L \Delta}{n \varepsilon^2}$会随$n$增大而改善。本文旨在探究在考虑服务器到工作节点通信时间$\tau_{s}$后，这种扩展性的理论极限。

Method: 作者构建了一个新的"最坏情况"函数，并开发了一个新的下界分析框架，将问题转化为随机和集中度的分析，为此证明了新的集中度边界。该方法通过理论分析揭示通信瓶颈。

Result: 研究证明：即使在各工作节点数据同分布（i.i.d.）的理想情况下，使用无偏随机稀疏化压缩器的方法也无法使服务器端通信时间项$\tau_{s} d \frac{L \Delta}{\varepsilon}$和方差相关时间项$\frac{h \sigma^2 L \Delta}{\varepsilon^2}$随$n$实现超对数级扩展。

Conclusion: 这些结果揭示了分布式优化在可扩展性方面的根本限制，表明即使满足同分布假设，通信瓶颈仍会导致性能提升存在理论上限，对联邦学习算法设计具有重要启示意义。

Abstract: We consider centralized distributed optimization in the classical federated
learning setup, where $n$ workers jointly find an $\varepsilon$-stationary
point of an $L$-smooth, $d$-dimensional nonconvex function $f$, having access
only to unbiased stochastic gradients with variance $\sigma^2$. Each worker
requires at most $h$ seconds to compute a stochastic gradient, and the
communication times from the server to the workers and from the workers to the
server are $\tau_{s}$ and $\tau_{w}$ seconds per coordinate, respectively. One
of the main motivations for distributed optimization is to achieve scalability
with respect to $n$. For instance, it is well known that the distributed
version of SGD has a variance-dependent runtime term $\frac{h \sigma^2 L
\Delta}{n \varepsilon^2},$ which improves with the number of workers $n,$ where
$\Delta = f(x^0) - f^*,$ and $x^0 \in R^d$ is the starting point. Similarly,
using unbiased sparsification compressors, it is possible to reduce both the
variance-dependent runtime term and the communication runtime term. However,
once we account for the communication from the server to the workers
$\tau_{s}$, we prove that it becomes infeasible to design a method using
unbiased random sparsification compressors that scales both the server-side
communication runtime term $\tau_{s} d \frac{L \Delta}{\varepsilon}$ and the
variance-dependent runtime term $\frac{h \sigma^2 L \Delta}{\varepsilon^2},$
better than poly-logarithmically in $n$, even in the homogeneous (i.i.d.) case,
where all workers access the same distribution. To establish this result, we
construct a new "worst-case" function and develop a new lower bound framework
that reduces the analysis to the concentration of a random sum, for which we
prove a concentration bound. These results reveal fundamental limitations in
scaling distributed optimization, even under the homogeneous assumption.

</details>


### [40] [Random Distributionally Robust Optimization under Phi-divergence](https://arxiv.org/abs/2506.23839)
*Guohui Guan,Zongxia Liang,Xingjian Ma*

Main category: math.OC

TL;DR: 本文提出了随机分布鲁棒优化（RDRO）新框架，通过将决策变量扩展为随机变量，结合双变量效用函数和$\varphi$-散度模糊集，为不确定性决策提供更灵活的处理方式。


<details>
  <summary>Details</summary>
Motivation: 经典分布鲁棒优化（DRO）在处理不确定性时存在局限性，RDRO框架通过引入随机决策变量，能够更真实地模拟实际应用场景（如投资组合优化、医疗资源分配等）。

Method: 利用最优传输理论和凸分析建立RDRO问题的结构特性，提出结合非平衡最优传输缩放算法与投影梯度下降的高效数值求解方案。

Result: 理论贡献包括证明随机最优决策的存在唯一性，建立约束RDRO与惩罚形式的对偶定理；数值实验验证了算法的有效性。

Conclusion: RDRO框架通过随机化决策变量和$\varphi$-散度模糊集，显著提升了分布鲁棒优化的适用性和计算可行性，为复杂不确定性决策问题提供通用解决方案。

Abstract: This paper introduces a novel framework, Random Distributionally Robust
Optimization (RDRO), which extends classical Distributionally Robust
Optimization (DRO) by allowing the decision variable to be a random variable.
We formulate the RDRO problem using a bivariate utility function and
$\varphi$-divergence ambiguity sets, enabling a more flexible and realistic
treatment of uncertainty. The RDRO framework encompasses a broad range of
robust decision-making applications, including portfolio optimization,
healthcare resource allocation, and reliable facility location. By optimal
transport theory and convex analysis, we characterize key structural properties
of the RDRO problem. Our main theoretical contributions include establishing
the existence and uniqueness of optimal randomized decisions and proving a
duality theorem that links the constrained RDRO formulation to its penalized
counterpart. We further propose an efficient numerical scheme that combines the
scaling algorithm for unbalanced optimal transport with projected gradient
descent, and demonstrate its effectiveness through numerical experiments.

</details>


### [41] [Topology optimization of actively moving rigid bodies in unsteady flows](https://arxiv.org/abs/2506.23895)
*Yuta Tanabe,Kentaro Yaji,Kuniharu Ushijima*

Main category: math.OC

TL;DR: 本文提出了一种新颖的非定常流体流动拓扑优化方法，通过分离设计网格与分析网格来高效处理主动运动刚体引发的流动问题，并采用基于格子动力学方案的求解器验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 针对非定常流体中主动运动刚体引发的复杂流动问题，传统方法计算成本高昂且难以处理广义运动，需要开发更高效的拓扑优化框架。

Method: 采用设计网格与分析网格解耦策略：设计网格随刚体运动后叠加至分析网格，传递Brinkman系数等关键参数；基于扩展版格子Boltzmann方法（格子动力学方案）求解设计灵敏度，并通过有限差分验证其准确性。

Result: 二维和三维数值实验表明，该方法能准确计算设计灵敏度，有效表征物体运动，显著降低非定常流动问题的计算成本。

Conclusion: 所提出的多网格耦合方法为运动刚体引发的非定常流动拓扑优化提供了通用且高效的解决方案，格子动力学方案的应用进一步提升了计算效率。

Abstract: This study proposes a novel topology optimization method for unsteady fluid
flows induced by actively moving rigid bodies. The key idea of the proposed
method is to decouple the design and analysis domains by using separate grids.
The design grid undergoes rigid body motion and is then overlapped onto the
analysis grid. After the overlap, key quantities such as the Brinkman
coefficient are transferred between the grids. This approach provides a direct
and efficient means of representing object motion and facilitates the handling
of more general and complex movements in unsteady flow conditions. Since the
computational cost of solving unsteady fluid problems is substantial, we employ
a solver based on the lattice kinetic scheme, which is the extended version of
the lattice Boltzmann method, to evaluate the design sensitivity. The
fundamental equations are derived, and the accuracy of the design sensitivity
calculations is validated through comparison with finite difference
approximations. The effectiveness of the method is demonstrated through
numerical examples in two-dimensional and three-dimensional settings.

</details>


### [42] [Consensus-based optimization for closed-box adversarial attacks and a connection to evolution strategies](https://arxiv.org/abs/2506.24048)
*Tim Roith,Leon Bungert,Philipp Wacker*

Main category: math.OC

TL;DR: 本文研究了基于共识的优化（CBO）在黑盒对抗攻击中的应用，建立了CBO与自然进化策略（NES）的联系，并通过实验证明CBO在某些场景下优于NES和其他进化策略。


<details>
  <summary>Details</summary>
Motivation: 研究CBO在黑盒对抗攻击中的潜力，这种攻击通过微小输入扰动欺骗分类器，且无需梯度信息。

Method: 将CBO与自然进化策略（NES）联系起来，并严格分析两者与基于梯度的优化方法的关系。

Result: 实验研究表明，尽管CBO与NES在概念上相似，但在某些情况下CBO表现更优。

Conclusion: CBO在黑盒对抗攻击中具有优势，为无梯度优化提供了新的研究方向。

Abstract: Consensus-based optimization (CBO) has established itself as an efficient
gradient-free optimization scheme, with attractive mathematical properties,
such as mean-field convergence results for non-convex loss functions. In this
work, we study CBO in the context of closed-box adversarial attacks, which are
imperceptible input perturbations that aim to fool a classifier, without
accessing its gradient. Our contribution is to establish a connection between
the so-called consensus hopping as introduced by Riedl et al. and natural
evolution strategies (NES) commonly applied in the context of adversarial
attacks and to rigorously relate both methods to gradient-based optimization
schemes. Beyond that, we provide a comprehensive experimental study that shows
that despite the conceptual similarities, CBO can outperform NES and other
evolutionary strategies in certain scenarios.

</details>


### [43] [AutoLyap: A Python package for computer-assisted Lyapunov analyses for first-order methods](https://arxiv.org/abs/2506.24076)
*Manu Upadhyaya,Adrien B. Taylor,Sebastian Banert,Pontus Giselsson*

Main category: math.OC

TL;DR: AutoLyap是一个Python包，用于自动化Lyapunov分析，验证一阶方法在结构优化和包含问题中的收敛性。


<details>
  <summary>Details</summary>
Motivation: Lyapunov分析是验证一阶方法收敛性的常用工具，但手动验证复杂且耗时，AutoLyap旨在自动化这一过程。

Method: AutoLyap将Lyapunov分析的存在性验证转化为半定规划（SDP）问题，用户指定问题类别、方法和分析类型后，包自动完成SDP建模与求解。

Result: 该包成功验证并扩展了多个收敛性结果，展示了其在实际应用中的有效性。

Conclusion: AutoLyap为Lyapunov分析提供了高效、自动化的工具，简化了一阶方法收敛性的验证过程。

Abstract: We introduce AutoLyap, a Python package designed to automate Lyapunov
analyses for a wide class of first-order methods for solving structured
optimization and inclusion problems. Lyapunov analyses are structured proof
patterns, with historical roots in the study of dynamical systems, commonly
used to establish convergence results for first-order methods. Building on
previous works, the core idea behind AutoLyap is to recast the verification of
the existence of a Lyapunov analysis as a semidefinite program (SDP), which can
then be solved numerically using standard SDP solvers. Users of the package
specify (i)~the class of optimization or inclusion problems, (ii)~the
first-order method in question, and (iii)~the type of Lyapunov analysis they
wish to test. Once these inputs are provided, AutoLyap handles the SDP modeling
and proceeds with the numerical solution of the SDP. We leverage the package to
numerically verify and extend several convergence results.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [44] [The Piltz divisor Problem in Number Fields Using The Resonance Method](https://arxiv.org/abs/2506.22587)
*Nilmoni Karak,Kamalakshya Mahatab*

Main category: math.NT

TL;DR: 本文研究了数域上的Piltz除数问题，通过推广Soundararajan的Voronoi型公式并结合第二作者的最新成果，改进了误差项的$\Omega-$界。


<details>
  <summary>Details</summary>
Motivation: Piltz除数问题是经典Dirichlet除数问题的自然推广，研究其在数域上的表现具有重要理论意义。

Method: 方法包括将Soundararajan的Voronoi型公式推广到数域场景，并应用第二作者的最新研究成果。

Result: 获得了误差项的改进$\Omega-$界，推进了该问题的研究进展。

Conclusion: 本研究通过创新方法在数域上拓展了Piltz除数问题的解，为相关领域提供了新的理论工具。

Abstract: The Piltz divisor problem is a natural generalization of the classical
Dirichlet divisor problem. In this paper, we study this problem over number
fields and obtain improved $\Omega-$bounds for its error terms. Our approach
involves generalizing a Voronoi-type formula due to Soundararajan in the number
field setting, and applying a recent result due to the second author.

</details>


### [45] [Omega Estimate for the Lattice Point Discrepancy of a Body of Revolution Using The Resonance Method](https://arxiv.org/abs/2506.22590)
*Nilmoni Karak*

Main category: math.NT

TL;DR: 本文利用Mahatab的最新方法，改进了三维空间中旋转体格子点计数问题的误差项$\Omega$界，强化了K\"uhleitner和Nowak的早期结果。


<details>
  <summary>Details</summary>
Motivation: 研究三维空间中具有光滑边界且曲率有界的旋转体在坐标轴周围的格子点计数问题，旨在改进现有误差界。

Method: 采用Mahatab提出的新方法，对旋转体的格子点计数误差项进行分析。

Result: 获得了比K\"uhleitner和Nowak更优的误差项$\Omega$界。

Conclusion: 该方法有效提升了旋转体格子点计数问题的误差估计精度，为相关领域研究提供了更严格的理论工具。

Abstract: Using a recent method developed by Mahatab, we obtain an improved
$\Omega$-bound for the error term arising in lattice counting problem of bodies
of revolution in $\mathbb R^3$ around a coordinate axis and having smooth
boundary with bounded nonzero curvature. This strengthens an earlier result by
K\"uhleitner and Nowak.

</details>


### [46] [A Rigorous Error Bound for the TG Kernel in Prime Counting](https://arxiv.org/abs/2506.22634)
*Bugra Kilictas,Faruk Alpay*

Main category: math.NT

TL;DR: 该论文通过截断高斯核在显式公式框架中建立了素数计数的严格误差界，证明了对于足够大的参数，近似误差全局低于1/2，从而无需依赖未证明假设即可通过简单舍入精确计算素数计数函数{\pi}(x)。


<details>
  <summary>Details</summary>
Motivation: 研究旨在将经典解析数论技术与现代计算视角结合，开发实用算法解决以往被视为纯理论的问题，特别是在天文尺度上可靠地进行素数计数计算。

Method: 采用具有紧支撑的高斯类测试函数构造截断高斯核，通过泰勒余项分析实现显式尾部截断边界（呈现指数衰减），利用无条件密度估计控制零和截断误差，并严格处理平凡零点贡献。所有常数均显式给出以确保可验证性。

Result: 对于具有10^8位十进制数字的x，仅需约1200个非平凡zeta零点即可在秒级时间内达到误差界，比经典方法有显著提升。该方法支持基于FFT的3.3亿比特数运算，为破纪录的素数计算提供可能。

Conclusion: 该工作通过严格误差分析将解析数论与实际计算连接起来，展示了优化核设计与平滑参数{\alpha}和截断高度相互作用对素数分布的深层意义，为计算数论研究开辟了新途径。

Abstract: We establish rigorous error bounds for prime counting using a truncated
Gaussian (TG) kernel in the explicit formula framework. Our main theorem proves
that the approximation error remains globally below 1/2 for all sufficiently
large arguments, guaranteeing exact computation of {\pi}(x) through simple
rounding, without relying on unproven hypotheses.
  The TG kernel construction employs Gaussian-like test functions with compact
support, engineered with vanishing moments to eliminate main terms. For x with
10^8 decimal digits, we demonstrate that only ~1200 nontrivial zeta zeros
suffice to achieve the error bound, enabling computation in seconds on modern
hardware - a dramatic improvement over classical methods.
  Key contributions include: (1) Explicit tail truncation bounds using Taylor
remainder analysis, showing exponential decay; (2) Zero-sum truncation error
bounds via unconditional density estimates; (3) Rigorous treatment of trivial
zero contributions. All constants are made explicit, ensuring full
verifiability.
  The method bridges analytic number theory and practical computation, with
potential applications to record-breaking prime counting computations. We
discuss algorithmic implications including FFT-based arithmetic for ~330
million bit numbers. The framework's flexibility suggests connections to deeper
structures in prime distribution, particularly regarding optimized kernel
designs and the interplay between smoothing parameters {\alpha} and truncation
heights.
  This work exemplifies how classical analytic techniques, when carefully
implemented with modern computational perspectives, yield practical algorithms
for problems previously considered purely theoretical. The rigorous error
analysis ensures reliability even at astronomical scales, opening new avenues
for computational number theory research.

</details>


### [47] [The Dedekind-Hasse Criterion in Quaternion Algebras](https://arxiv.org/abs/2506.22651)
*Adriana Cardoso,António Machiavelo*

Main category: math.NT

TL;DR: 本文提出了主理想序的一个判别准则，旨在将Hurwitz整数的已知结果推广到任意序，包括给定范数的左/右因子存在性、唯一性（相伴意义下）以及素四元数分解的存在性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是推广Hurwitz整数的经典结果（如因子存在性、唯一性和素分解）到更一般的主理想序结构，以建立更广泛的代数理论框架。

Method: 通过建立主理想序的判别准则，并利用四元数代数与序理论工具，对Hurwitz整数的性质进行系统性扩展。

Result: 证明了任意主理想序中：（1）给定范数的左/右因子在相伴意义下唯一存在；（2）素四元数分解的存在性，从而推广了原有结论。

Conclusion: 该准则为研究一般序的算术性质提供了统一方法，将四元数理论中的经典结果扩展至更广泛的代数结构。

Abstract: We give a criterion for principal ideal orders, with the objective of
generalizing for an arbitrary order some known results about the Hurwitz
Integers, namely, the existence and uniqueness (up to associates) of a
left/right factor of a given norm and the existence of a factorization in prime
quaternions.

</details>


### [48] [An improved large sieve for quadratic characters via Hooley neutralisers and its applications](https://arxiv.org/abs/2506.22667)
*Cameron Wilson*

Main category: math.NT

TL;DR: 该论文结合Hooley中和器与二次特征的大筛法，应用于双曲高度条件下的特征和问题。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决双曲高度条件下特征和的计算问题，为相关数论问题提供新工具。

Method: 通过结合Hooley中和器与二次特征的大筛法技术，构建新的分析方法。

Result: 成功推导出双曲高度条件下特征和的有效估计，拓展了筛法应用范围。

Conclusion: 该方法为数论中特征和问题提供了新的研究途径，具有潜在的理论价值。

Abstract: We combine Hooley neutralisers and the large sieve for quadratic characters.
We give applications to character sums with a hyperbolic height condition.

</details>


### [49] [A Note on Flexion Units](https://arxiv.org/abs/2506.22825)
*Hanamichi Kawamura*

Main category: math.NT

TL;DR: 本文综述了Ecalle的屈折单元理论，并补充了原始文献中未证明的关键断言，这些结果对多重zeta值和Kashiwara-Vergne问题的应用至关重要。


<details>
  <summary>Details</summary>
Motivation: Ecalle的屈折单元理论在多重zeta值和Kashiwara-Vergne问题中有重要应用，但原始文献中多个关键断言缺乏证明，本文旨在填补这一空白。

Method: 通过系统梳理Ecalle理论框架，对屈折单元的核心命题进行严格证明，采用代数与解析相结合的研究方法。

Result: 完整证明了Ecalle原始工作中若干未论证的关键命题，确立了屈折单元理论与多重zeta值之间的严格数学联系。

Conclusion: 本研究不仅完善了屈折单元的理论基础，更为其在数论和李理论中的进一步应用提供了坚实的数学保障。

Abstract: This article is a survey of Ecalle's theory of flexion units. In particular,
we provide complete proofs of several key assertions that were stated without
proof in Ecalle's original works. These results are crucial for understanding
applications of flexion units to the theory of multiple zeta values and the
Kashiwara-Vergne problem.

</details>


### [50] [Chabauty Limits of Fermat Spirals](https://arxiv.org/abs/2506.22863)
*Yohay Ailon Tevet*

Main category: math.NT

TL;DR: 本文研究了费马螺线$\sqrt{n}e^{2\pi i\alpha n}$的Chabauty极限，证明它们总是$\mathbb{R}^2$的闭子群，并得出费马螺线不是稠密森林的结论。对于难以逼近的$\alpha$，Chabauty极限总是格，并给出了其特征描述。


<details>
  <summary>Details</summary>
Motivation: 研究费马螺线的Chabauty极限性质，探索其在$\mathbb{R}^2$中的结构特征及其与稠密森林的关系。

Method: 通过数学分析证明费马螺线的Chabauty极限为闭子群，并对难以逼近的$\alpha$情况进一步分析其格结构。

Result: 费马螺线的Chabauty极限总是$\mathbb{R}^2$的闭子群，且不是稠密森林；当$\alpha$难以逼近时，Chabauty极限为格。

Conclusion: 费马螺线的Chabauty极限具有明确的代数结构，且在特定条件下表现为格，这为相关数学领域提供了新的理论支持。

Abstract: A Fermat spiral is a set of points of the form $\sqrt{n}e^{2\pi i\alpha n}$
for $\alpha \in \mathbb{R}$. In this paper we prove that the Chabauty limits of
Fermat spirals are always closed subgroups of $\mathbb{R}^2$, and conclude that
no Fermat spirals are dense forests. Furthermore, we show that if $\alpha$ is
badly approximable the Chabauty limits are always lattices, for which we give a
characterisation.

</details>


### [51] [On sesquilinear forms over finite fields](https://arxiv.org/abs/2506.23099)
*Ruikai Chen*

Main category: math.NT

TL;DR: 本文研究了有限域上半线性形式的表示与分类，通过其与二次型的关联解决了特定方程的计数问题，并刻画了一类极值Artin-Schreier曲线。


<details>
  <summary>Details</summary>
Motivation: 探索有限域上半线性形式的数学理论及其在代数几何中的应用，特别是解决由半线性形式定义的方程计数问题。

Method: 通过多项式与系数矩阵表示半线性形式，利用其与二次型的联系计算特征和，进而解决枚举问题。

Result: 获得了半线性形式的分类结果，并由此刻画了一类具有显式例子的极大或极小Artin-Schreier曲线。

Conclusion: 该研究为有限域上半线性形式的理论提供了新视角，并在代数几何中发现了具体的极值曲线实例。

Abstract: We develop a theory of sesquilinear forms over finite fields, investigating
their representations via polynomials and coefficient matrices, along with
classification results for these forms. Through their connection to quadratic
forms, we calculate certain character sums to resolve enumeration problems for
equations defined by sesquilinear forms. This provides a characterization of a
class of maximal or minimal Artin-Schreier curves with explicit examples.

</details>


### [52] [Unbounded knapsack problem and double partitions](https://arxiv.org/abs/2506.23499)
*Boris Y. Rubinstein*

Main category: math.NT

TL;DR: 本文探讨了无界背包问题与双划分问题的关系，并基于19世纪Sylvester和Cayley提出的变量消去法，给出了该方法的几何解释及其在背包问题中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究无界背包问题与双划分问题的联系，探索历史方法（Sylvester和Cayley的变量消去法）的现代几何解释及应用价值。

Method: 采用变量消去法将双划分问题简化为标量划分的和，并通过几何视角重新诠释这一经典方法。

Result: 成功将双划分问题转化为更易处理的标量划分形式，并验证了该方法在解决背包问题中的有效性。

Conclusion: 几何解释不仅复兴了19世纪的数学方法，还为背包问题提供了新的解决思路，展示了经典理论与现代问题的结合潜力。

Abstract: The unbounded knapsack problem can be considered as a particular case of the
double partition problem that asks for a number of nonnegative integer
solutions to a system of two linear Diophantine equations with integer
coefficients. In the middle of 19th century Sylvester and Cayley suggested an
approach based on the variable elimination allowing a reduction of a double
partition to a sum of scalar partitions. This manuscript discusses a geometric
interpretation of this method and its application to the knapsack problem.

</details>


### [53] [An infinite family of pairs of distinct quartic Galois CM-fields with the same discriminant and regulator](https://arxiv.org/abs/2506.23541)
*Yoshichika Iizuka,Yutaka Konomi*

Main category: math.NT

TL;DR: 本文构建了无限多对具有相同判别式和调节器的不同虚双二次域和虚循环四次域，并展示了具有相同调节器、判别式及类数的具体例子。


<details>
  <summary>Details</summary>
Motivation: 研究虚数域中不同数域间在判别式、调节器等不变量上的关系，探索数域理论的深层结构特性。

Method: 通过构造无限族的方法，系统性地生成具有相同不变量（判别式、调节器、类数）的不同虚双二次域和虚循环四次域对。

Result: 成功构建了无限多对具有相同判别式和调节器的虚数域，并首次给出判别式、调节器及类数完全相同的数域对实例。

Conclusion: 该研究揭示了虚数域中不变量相同的非平凡现象，为数域分类理论提供了新的构造性证据。

Abstract: We construct an infinite family of pairs of distinct imaginary biquadratic
fields and pairs of distinct imaginary cyclic quartic fields with the same
discriminant and regulator. We also construct an infinite family of imaginary
biquadratic fields and imaginary cyclic quartic fields with the same regulator.
Moreover, we give examples of a pair of distinct imaginary biquadratic fields
and a pair of distinct imaginary cyclic quartic fields with the same
discriminant, regulator and class number.

</details>


### [54] [On the distribution of shapes of pure quartic number fields](https://arxiv.org/abs/2506.23766)
*Sudipa Das,Sushant Kala,Arunabha Mukhopadhyay,Anwesh Ray*

Main category: math.NT

TL;DR: 本文研究了纯四次域$K_m = \mathbb{Q}(\sqrt[4]{m})$的形状分布，证明其形状位于$\mathscr{S}_3$中十条明确描述的环面轨道上，由$m \bmod 32$的符号和剩余类决定。形状分布由连续和离散测度的乘积控制。


<details>
  <summary>Details</summary>
Motivation: 研究数域形状的分布，特别是非通用数域族中的形状分布，以回答Manjul Bhargava和Piper H提出的问题。

Method: 通过分析纯四次域的整数格点，确定其形状在形状空间$\mathscr{S}_3$中的环面轨道，并研究形状的参数化。

Result: 纯四次域的形状位于十条明确描述的环面轨道上，由两个参数决定：一个连续变化，另一个离散取值。分布由连续和离散测度的乘积控制。

Conclusion: 本文揭示了非通用数域族中形状分布的新特性，其极限分布并非由$GL_3(\mathbb{R})$上的Haar测度诱导的自然测度限制而来。

Abstract: The shape of a number field is a subtle arithmetic invariant arising from the
geometry of numbers. It is defined as the equivalence class of the lattice of
integers with respect to linear operations that are composites of rotations,
reflections, and positive scalar dilations. For a number field of degree $n$,
the shape is a point in the space of shapes $\mathscr{S}_{n-1}$, which is the
double quotient $GL_{n-1}(\mathbb{Z}) \backslash GL_{n-1}(\mathbb{R}) /
GO_{n-1}(\mathbb{R})$. In this paper, we investigate the distribution of shapes
in the family of pure quartic fields $K_m = \mathbb{Q}(\sqrt[4]{m})$. We prove
that the shape of $K_m$ lies on one of ten explicitly described torus orbits in
$\mathscr{S}_3$, determined by the sign and residue class of $m \bmod 32$. It
is shown that the shape on a given torus orbit is completely determined by two
parameters, one of which varies continuously, while the other takes values in a
discrete set. As a result, the distribution of shapes in this family is
governed by a product of a continuous and a discrete measure. Our results shed
new light on a question posed by Manjul Bhargava and Piper H concerning the
distribution of shapes in families of non-generic number fields of fixed
degree. Notably, the limiting distribution in our case does not arise as the
restriction of the natural measure on $\mathscr{S}_3$ induced by Haar measure
on $GL_3(\mathbb{R})$.

</details>


### [55] [2-Selmer companion modular forms](https://arxiv.org/abs/2506.23805)
*Abhishek,Somnath Jha,Sudhanshu Shekhar*

Main category: math.NT

TL;DR: 该论文研究了数域$K$上两个新形式$f_1$和$f_2$的残差Galois表示在2处同构时，其Greenberg 2-Selmer群在特定条件下的同构性，并推广了Mazur-Rubin关于2-Selmer伴随椭圆曲线的结果。反之，若残差Greenberg（或Bloch-Kato）2-Selmer秩的差有界，则残差Galois表示作为$G_K$-模同构。


<details>
  <summary>Details</summary>
Motivation: 研究新形式$f_1$和$f_2$在残差Galois表示同构条件下，其2-Selmer群的同构性质，推广Mazur-Rubin关于椭圆曲线的结果，并探索逆命题的成立条件。

Method: 通过假设$f_1$和$f_2$的残差Galois表示在2处同构，并引入2-adic分圆特征$\omega_2$和二次特征$\chi$，分析其临界扭曲$j$下的Greenberg 2-Selmer群同构性。反之，通过分析2-Selmer秩差的有界性，推导残差Galois表示的同构性。

Result: 在适当假设下，若$f_1$和$f_2$的残差Galois表示在2处同构，则其Greenberg 2-Selmer群在二次特征$\chi$和临界扭曲$j$下同构。反之，若2-Selmer秩差有界，则残差Galois表示作为$G_K$-模同构。

Conclusion: 该研究不仅推广了Mazur-Rubin关于椭圆曲线的结果，还建立了新形式在残差Galois表示同构与2-Selmer群性质之间的双向联系，为相关领域提供了新的理论工具。

Abstract: Let $N$ be a positive integer and $K$ be a number field. Suppose that
$f_1,f_2 \in S_k(\Gamma_0(N))$ are two newforms such that their residual Galois
representations at $2$ are isomorphic. Let $\omega_2: G_{\mathbb Q} \rightarrow
{\mathbb Z}^*_2$ be the $2$-adic cyclotomic character. Then, under suitable
hypotheses, we have shown that for every quadratic character $\chi$ of $K$ and
each critical twist $j$, the residual Greenberg $2$-Selmer groups of
$f_1\chi\omega_2^{-j}$ and $f_2\chi\omega_2^{-j}$ over $K$ are isomorphic. This
generalizes the corresponding result of Mazur-Rubin on $2$-Selmer companion
elliptic curves. Conversely, if the difference of the residual Greenberg
(respectively Bloch-Kato) $2$-Selmer ranks of $f_1\chi$ and $f_2\chi$ is
bounded independent of every quadratic character $\chi$ of $K$, then under
suitable hypotheses we have shown that the residual Galois representations at
$2$ of $f_1$ and $f_2$ are isomorphic as $G_K$-modules. The corresponding
result for elliptic curves was a conjecture of Mazur-Rubin, which was proved by
M. Yu.

</details>


### [56] [An improved upper bound for the distribution of iterated Euler totient functions](https://arxiv.org/abs/2506.23882)
*Pei Gao,Qiyu Yang*

Main category: math.NT

TL;DR: 本文改进了关于欧拉函数$\phi_k(n)$迭代的上界估计，将分母指数从$k$提升至$k+1$。


<details>
  <summary>Details</summary>
Motivation: 研究欧拉函数$\phi(n)$及其$k$次迭代$\phi_k(n)$的上界问题，旨在优化现有理论结果。

Method: 通过对比Pollack关于$\phi_{k+1}(n)$求和的渐近公式，改进上界估计方法。

Result: 成功将上界主项的分母指数从$k$提高到$k+1$，提升了理论精度。

Conclusion: 该改进为欧拉函数迭代性质的研究提供了更精确的上界估计工具。

Abstract: Let $\phi(n)$ be the Euler totient function and $\phi_k(n)$ its $k$-fold
iterate. In this note, we improve the upper bound for the number of positive
$n\leqslant x$ such that $\phi_{k+1}(n)\geqslant cn$. Comparing with the upper
bound which was obtained from Pollack's asymptotic formula of the summation of
$\phi_{k+1}(n)$ for $n\leqslant x$, we have successfully increased the
denominator exponent of the main term of the upper bound from $k$ to $k+1$.

</details>


### [57] [A 2-adic automorphy lifting theorem for symplectic groups over totally real fields](https://arxiv.org/abs/2506.23938)
*Takuya Yamauchi*

Main category: math.NT

TL;DR: 本文证明了关于2-adic Galois表示的新自守提升定理，扩展了Thorne的最小情况至非最小情况，并应用于Dwork五次家族的特定秩4辛动机的自守性。


<details>
  <summary>Details</summary>
Motivation: 研究任意完全实域$F$上2-adic Galois表示的自守提升问题，特别是非最小情况，以填补现有理论的空白。

Method: 通过详细分析特征二下Dwork家族的剩余单值表示，结合作者与Tsuzuki的先前工作，构建自守提升定理。

Result: 证明了特定条件下，来自Dwork五次家族的秩4辛动机的自守性，扩展了自守表示理论的应用范围。

Conclusion: 该研究不仅推广了Thorne的最小情况定理，还为Dwork家族相关动机的自守性提供了新的理论支持。

Abstract: We prove a new automorphy lifting theorem for certain 2-adic Galois
representations $\rho:G_F\longrightarrow {\rm
GSp}_{2n}(\overline{\mathbb{Q}}_2)$ where $F$ an arbitrary totally real field.
This extends the minimal case previously established by Thorne to the
non-minimal case. A key ingredient is a detailed analysis for the residual
monodromy representations associated to the Dwork family in characteristic two.
As an application, combining with the author's previous work with Tsuzuki, we
prove the automorphy of certain rank 4 symplectic motives over $F$ coming from
the Dwork quintic family under suitable conditions.

</details>


### [58] [A general approach to permutation polynomials from quadratic forms](https://arxiv.org/abs/2506.24012)
*Ruikai Chen*

Main category: math.NT

TL;DR: 研究特征为2的有限域上一类置换多项式，通过其与二次型的联系，给出了这些置换多项式的通用刻画方法，并具体描述了几类置换多项式。


<details>
  <summary>Details</summary>
Motivation: 探讨有限域上置换多项式与二次型之间的联系，以更深入地理解置换多项式的性质及其构造方法。

Method: 通过分析置换多项式与二次型的关系，并计算相关的特征和，提出了一种通用的刻画置换多项式的方法。

Result: 确定了与二次型相关的若干特征和，从而明确描述了几类置换多项式。

Conclusion: 通过二次型与置换多项式的联系，成功刻画了特征为2的有限域上的若干置换多项式类，为相关研究提供了新的工具和视角。

Abstract: We investigate a family of permutation polynomials of finite fields of
characteristic 2. Through a connection between permutation polynomials and
quadratic forms, a general treatment is presented to characterize these
permutation polynomials. By determining some character sums associated with
quadratic forms, we explicitly describe several classes of permutation
polynomials.

</details>


### [59] [The completed Kirillov model and local-global compatibility for functions on Igusa varieties](https://arxiv.org/abs/2506.24089)
*Sean Howe*

Main category: math.NT

TL;DR: 该论文将$\mathrm{GL}_2$的普通Caraiani-Scholze Igusa簇上的尖点函数$\mathbb{V}_b^{\mathrm{cusp}}$描述为经典尖点模形式光滑Kirillov模型的完备化，并建立了与Hida普通$p$-进模形式的变体的联系，进而提出了更一般Igusa簇上的Hida理论类比猜想。


<details>
  <summary>Details</summary>
Motivation: 研究目的是建立经典尖点模形式与$p$-进自守形式空间之间的联系，并探索更一般Igusa簇上的局部-整体兼容性理论。

Method: 通过将$\mathbb{V}_b^{\mathrm{cusp}}$与光滑Kirillov模型完备化相联系，并利用$\tilde{\mu}_{p^\infty}$作用的协变关系，构建了与Hida模形式的对应。

Result: 证明了经典尖点模形式特征空间在$\mathbb{V}_b^{\mathrm{cusp}}$中的弱局部-整体兼容性定理，并提出了广义Igusa簇上类似Hida理论的猜想。

Conclusion: 该工作为$p$-进自守形式理论提供了新视角，并提出了在更广泛Igusa簇上建立局部-整体兼容性和Hida理论类比的开放性问题。

Abstract: We describe the cuspidal functions $\mathbb{V}_b^{\mathrm{cusp}}$ on the
ordinary Caraiani-Scholze Igusa variety for $\mathrm{GL}_2$ as a completion of
the smooth Kirillov model for classical cuspidal modular forms, and identify a
variant of Hida's ordinary $p$-adic modular forms with the coinvariants of an
action of $\tilde{\mu}_{p^\infty}$ on $\mathbb{V}_b^{\mathrm{cusp}}$. As a
consequence of these results, we establish a weak local-global compatibility
theorem for eigenspaces in $\mathbb{V}_b^{\mathrm{cusp}}$ associated to
classical cuspidal modular forms. Based on these results, we conjecture an
analog of Hida theory and an associated local-global compatibility for
functions on more general Caraiani-Scholze Igusa varieties, which are natural
spaces of $p$-adic automorphic forms.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [60] [Externally definable fsg groups in NIP theories](https://arxiv.org/abs/2506.23265)
*Artem Chernikov*

Main category: math.LO

TL;DR: 证明了NIP结构中外部可定义的fsg群与可解释群之间存在定义同构，解决了Eleftheriou猜想并描述了可定义群中的外部可定义、可定义顺从子群。


<details>
  <summary>Details</summary>
Motivation: 研究NIP结构中外部可定义集与群的性质，特别是fsg群与可解释群之间的关系，以及解决Eleftheriou在实闭值域上的猜想。

Method: 采用诚实定义和群块结果，通过平移不变的可定义Keisler测度重构超可定义群。

Result: 证明了外部可定义的fsg群与可解释群的定义同构，解决了Eleftheriou猜想，并描述了外部可定义、可定义顺从子群。

Conclusion: 该研究深化了对NIP结构中外部可定义群的理解，为相关领域提供了新的工具和结果。

Abstract: We show that every fsg group externally definable in an NIP structure is
definably isomorphic to a group interpretable in it. Our proof relies on honest
definitions and a group chunk result reconstructing a hyper-definable group
from its multiplication given generically with respect to a translation
invariant definable Keisler measure on it. We obtain related results on
externally (type-)definable sets and groups, including a proof of a conjecture
of Eleftheriou on fsg groups in real closed valued fields, and a description of
externally definable, definably amenable subgroups of definable groups.

</details>


### [61] [A Galois correspondence for automorphism groups of structures with the Lascar Property](https://arxiv.org/abs/2506.23586)
*Gianluca Paolini,Federico Pisciotta*

Main category: math.LO

TL;DR: 本文引入Lascar性质，分析满足该性质的可数结构自同构群的拓扑同构，并建立了可定义的Galois对应关系，推广了Evans、Lascar和Konnerth的结果。


<details>
  <summary>Details</summary>
Motivation: 研究可数结构自同构群的拓扑同构，推广$\omega$-范畴背景下的结果，为模型论中的自同构群分析提供新工具。

Method: 引入Lascar性质，构建点稳定子与有限生成Galois代数闭子集之间的可定义Galois对应关系。

Result: 在Lascar性质假设下，刻画了$\mathrm{ACF}_0$、$\mathrm{DCF}_0$和无限$\mathrm{K}$-向量空间理论的可数饱和模型的自同构群。

Conclusion: 该框架统一了$\omega$-范畴结构的分析，并推广了前人关于自同构群的研究成果。

Abstract: Generalizing the $\omega$-categorical context, we introduce a notion, which
we call the Lascar Property, that allows for a fine analysis of the topological
isomorphisms between automorphism groups of countable structures satisfying
this property. In particular, under the assumption of the Lascar Property, we
exhibit a definable Galois correspondence between pointwise stabilizers of
finitely generated Galois algebraically closed subsets of $M$ and finitely
generated Galois algebraically closed subsets of $M$. We use this to
characterize the group of automorphisms of $\mathrm{Aut}(M)$, for $M$ the
countable saturated model of $\mathrm{ACF}_0$, $\mathrm{DCF}_0$, or the theory
of infinite $\mathrm{K}$-vector spaces, generalizing results of Evans $\&$
Lascar, and Konnerth, while at the same time subsuming the analysis from [11]
for $\omega$-categorical structures with weak elimination of imaginaries.

</details>


### [62] [Nonstandard Universes](https://arxiv.org/abs/2506.23654)
*Peter Ouwehand*

Main category: math.LO

TL;DR: 本文由初学者编写，总结了非标准分析中集合论宇宙的存在性与基本性质，需一阶逻辑基础。


<details>
  <summary>Details</summary>
Motivation: 旨在为非标准分析的学习者提供集合论宇宙的基础知识汇编。

Method: 回顾一阶逻辑必备内容（附录A），并整合标准文献中的现有材料。

Result: 系统呈现了非标准分析所需的集合论宇宙存在性及其核心特性。

Conclusion: 尽管内容非原创，但为初学者提供了清晰的基础框架与参考资料。

Abstract: These notes are concerned with the existence and the basic properties of the
set-theoretic universes for nonstandard analysis, compiled by a beginner in the
subject. It assumes a basic background in first-order logic, though the
necessary material is revised in Appendix A. Needless to say, none of the
material presented here is original, but has been adapted from standard
sources.

</details>


<div id='math.HO'></div>

# math.HO [[Back]](#toc)

### [63] [The VIBE Framework: A Student-Centered Approach to Teaching Knot Theory in Secondary Mathematics](https://arxiv.org/abs/2506.22886)
*Ioannis Diamantis*

Main category: math.HO

TL;DR: 本文提出VIBE框架，将结理论引入中学教育，通过视觉化、探究式、协作式和情境化学习，促进学生的认知发展和空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 结理论作为拓扑学的直观分支，具有跨学科相关性，但当前中学课程中鲜有涉及。研究旨在通过创新教学方法填补这一空白。

Method: 采用基于建构主义的VIBE框架（视觉Visual、探究Inquiry-based、协作Braided、情境化Embedded），设计低门槛高上限的教学活动序列。

Result: 通过定性热图、聚类可视化和课堂实录证明，结理论能有效转化为探究性学习媒介，促进跨学科联系和学生创造力发展。

Conclusion: VIBE框架为中学数学教育提供了结构化且灵活的方法，支持将深度的数学体验融入课程体系。

Abstract: Knot theory, a visual and intuitive branch of topology, offers a unique
opportunity to introduce advanced mathematical thinking in secondary education.
Despite its accessibility and cross-disciplinary relevance, it remains largely
absent from standard curricula. This paper proposes the {\it VIBE framework}, a
student-centered approach, structured around four pedagogical pillars: Visual,
Inquiry-based, Braided (collaborative), and Embedded (contextualized) learning.
Rooted in constructivist theory, VIBE supports cognitive development, spatial
reasoning, and mathematical engagement across diverse learners. We present a
sequence of low-threshold, high-ceiling activities designed to develop core
topological concepts while fostering creativity and exploration. Through
qualitative heatmaps, clustering visualizations, and classroom snapshots, we
demonstrate how knot theory can be transformed into a powerful medium for
inquiry and interdisciplinary connection. We believe that the VIBE framework
provides a structured yet adaptable approach that supports the integration of
deep, meaningful mathematical experiences into secondary education.

</details>


<div id='math.GM'></div>

# math.GM [[Back]](#toc)

### [64] [Iteration Steps of 3x+1 Problem](https://arxiv.org/abs/2506.23070)
*Youchun Luo*

Main category: math.GM

TL;DR: 本文研究了3x+1问题中迭代步数的关系，提出了弱残差猜想，并证明了若3x+1猜想和弱残差猜想成立，则存在D(N)、O(N)、E(N)之间的非平凡关系。


<details>
  <summary>Details</summary>
Motivation: 探讨3x+1问题中迭代步数之间的关系，特别是总迭代步数D(N)、奇数步数O(N)和偶数步数E(N)之间的数学联系。

Method: 提出弱残差猜想$\frac{2^{E\left( N \right)}}{3^{O\left( N \right)}\cdot N}\le 2$，并在3x+1猜想和弱残差猜想成立的假设下进行推导。

Result: 证明了若两个猜想成立，则存在O(N) = [log_62·D(N) - log_6N]等6个方程，可直接通过D(N)计算O(N)和E(N)。

Conclusion: 研究揭示了3x+1问题中迭代步数之间的潜在数学规律，为深入理解该问题提供了新的理论工具。

Abstract: On the 3x+1 problem, given a positive integer $N$, let $D\left( N \right) $,
$O\left( N \right) $, $E\left( N \right) $ be the total iteration steps, the
odd iteration steps and the even iteration steps when $N$ iterates to 1(except
1) respectively. Trivially, we have $D\left( N \right) =O\left( N \right)
+E\left( N \right) $. In this paper, we propose a so-called weak residue
conjecture(i.e., $\frac{2^{E\left( N \right)}}{3^{O\left( N \right)}\cdot N}\le
2$). We prove that if 3x+1 conjecture is true and the weak residue conjecture
is true, there exist non-trivial relationships among $D\left( N \right) $,
$O\left( N \right) $, $E\left( N \right) $, i.e., $O\left( N \right) =\left[
\log _62\cdot D\left( N \right) -\log _6N \right] $(it implies that we can
calculate $O\left( N \right) $, $E\left( N \right) $ directly by $D\left( N
\right) $ only, of course given $N$), and 5 more similar equations are derived
simultaneously.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [65] [Catching Rats in $H$-minor-free Graphs](https://arxiv.org/abs/2506.22857)
*Maximilian Gorsky,Giannos Stamoulis,Dimitrios M. Thilikos,Sebastian Wiederrecht*

Main category: math.CO

TL;DR: 本文证明了排除$H$子式和$(k \times k)$网格子式的图,其树宽/分支宽上限为$\mathcal{O}(gk + t^{2304})$,改进了先前结果并回答了Wood的问题。同时提出了分支宽近似算法。


<details>
  <summary>Details</summary>
Motivation: 研究$H$-minor-free图的树宽/分支宽上界,旨在将函数$f(t,k)$改进为$k$线性且$t$多项式,解决[Demaine & Hajiaghayi, 2008]和[Kawarabayashi & Kobayashi, 2020]遗留的显式界问题。

Method: 基于分支宽技术及[Gorsky等, 2025]的图子式结构定理新界限,证明改进版GMST以增强子式关系性质,并开发近似算法。

Result: 获得强上界$\mathcal{O}(gk + t^{2304})$,导出$f(t,k)=\mathcal{O}(t^2k + t^{2304})$。提出$(g + \varepsilon)$-近似算法,运行时间为$2^{\mathsf{poly}(t) / \varepsilon} \cdot \mathsf{poly}(n)$。

Conclusion: 不仅显著改进了树宽/分支宽的理论上界,还提供了实用的近似算法,算法可输出分支分解或证明不存在性的网格子式。

Abstract: We show that every $H$-minor-free graph that also excludes a $(k \times
k)$-grid as a minor has treewidth/branchwidth bounded from above by a function
$f(t,k)$ that is linear in $k$ and polynomial in $t := |V(H)|$. Such a result
was proven originally by [Demaine & Hajiaghayi, Combinatorica, 2008], where $f$
was indeed linear in $k$. However the dependency in $t$ in this result was
non-explicit (and huge). Later, [Kawarabayashi & Kobayashi, JCTB, 2020] showed
that this bound can be estimated to be $f(t,k)\in 2^{\mathcal{O}(t\log t)}
\cdot k$. Wood recently asked whether $f$ can be pushed further to be
polynomial, while maintaining the linearity on $k$. We answer this in a
particularly strong sense, by showing that the treewidth/branchwidth of $G$ is
in $\mathcal{O}(gk + t^{2304}),$ where $g$ is the Euler genus of $H$. This
directly yields $f(t,k)= \mathcal{O}(t^2k + t^{2304})$.
  Our methods build on techniques for branchwidth and on new bounds and
insights for the Graph Minor Structure Theorem (GMST) due to [Gorsky, Seweryn &
Wiederrecht, 2025, arXiv:2504.02532]. In particular, we prove a variant of the
GMST that ensures some helpful properties for the minor relation. We further
employ our methods to provide approximation algorithms for the
treewidth/branchwidth of $H$-minor-free graphs. In particular, for every
$\varepsilon > 0$ and every $t$-vertex graph $H$ with Euler genus $g$, we give
a $(g + \varepsilon)$-approximation algorithm for the branchwidth of
$H$-minor-free graphs running in $2^{\mathsf{poly}(t) / \varepsilon} \cdot
\mathsf{poly}(n)$-time. Our algorithms explicitly return either an appropriate
branch-decomposition or a grid-minor certifying a negative answer.

</details>


### [66] [Homogeneous Linear Calculus of Order 1 and a $λ$-Taylor Formula](https://arxiv.org/abs/2506.22976)
*Ronald Orozco López*

Main category: math.CO

TL;DR: 本文定义了一种新的序列演算，研究了$\lambda$-导数和$\lambda$-积分，并给出了$\lambda$-演算的基本定理。


<details>
  <summary>Details</summary>
Motivation: 研究新的序列演算及其相关数学工具，扩展微积分理论的应用范围。

Method: 定义了$\lambda$-导数和$\lambda$-积分，构建了适合的函数基，并推导了$\lambda$-泰勒公式。

Result: 提出了$\lambda$-演算的基本定理，展示了函数基的各种性质，并给出了$\lambda$-泰勒展开式。

Conclusion: 该研究为序列分析提供了新的数学工具，$\lambda$-演算框架具有理论价值和潜在应用前景。

Abstract: In this paper, a new calculus on sequences is defined. Also, the
$\lambda$-derivative and the $\lambda$-integration are investigated. The
fundamental theorem of $\lambda$-calculus is included. A suitable function
basis for the $\lambda$-derivative and the $\lambda$-integral is provided, and
various properties of this basis are given. A $\lambda$-Taylor formula for
functions is given.

</details>


### [67] [Non-expansion in polynomial automorphisms of $\mathbb{C}^2$](https://arxiv.org/abs/2506.23015)
*Martin Bays,Tingxiang Zou*

Main category: math.CO

TL;DR: 本文研究了高维Elekes-Szab\'o问题在Aut($\mathbb{C}^2$)作用于$\mathbb{C}^2$时的情形。


<details>
  <summary>Details</summary>
Motivation: 探讨高维Elekes-Szab\'o问题在复平面自同构群作用下的表现，扩展了该问题的研究范围。

Method: 通过分析Aut($\mathbb{C}^2$)群在$\mathbb{C}^2$上的作用，运用代数几何和组合数学的方法进行研究。

Result: 得出了在高维情况下，Elekes-Szab\'o问题在Aut($\mathbb{C}^2$)作用下的具体性质和结论。

Conclusion: 该研究为高维Elekes-Szab\'o问题提供了新的视角和结果，丰富了相关领域的理论体系。

Abstract: We treat the higher-dimensional Elekes-Szab\'o problem in the case of the
action of Aut(C^2) on C^2.

</details>


### [68] [Edge-colouring and orientations: applications to degree-boundedness and $χ$-boundedness](https://arxiv.org/abs/2506.23054)
*Arnab Char,Ken-ichi Kawarabayashi,Lucas Picasarri-Arrieta*

Main category: math.CO

TL;DR: 证明了在足够大的最小度条件下，每张2边着色图都包含一个最小度仍保持较大的单色诱导子图，并推导出某些图类是度有界的。


<details>
  <summary>Details</summary>
Motivation: 研究图的最小度与单色诱导子图的关系，探索特定图类的度有界性质及其在着色和定向问题中的应用。

Method: 通过分析2边着色图的结构性质，结合极值图论方法，证明单色诱导子图的存在性，并推广到特定图类的度有界性证明。

Result: 确定了三类图是度有界的：(i)无单色偶洞的k边着色图；(ii)不含特定逆向森林的定向图；(iii)不含长逆向环的定向图。部分结果还进一步证明了多项式χ有界性。

Conclusion: 该研究不仅扩展了Ramsey理论在图着色中的应用，还为定向图和着色图的度约束提供了新的理论工具，特别适用于奇可签名图和Burling图等特殊图类。

Abstract: We prove that every $2$-edge-coloured graph with sufficiently large minimum
degree contains a monochromatic induced subgraph whose minimum degree remains
large.
  As a consequence, we deduce that some classes of graphs are degree-bounded. A
class $\mathcal{G}$ is {\it degree-bounded} if, for every integer $s$, there
exists $d=d(s)$ such that every graph $G\in \mathcal{G}$ either contains
$K_{s,s}$ or has minimum degree at most $d$. We obtain that the following
classes are degree-bounded: (i) for every $k$, the graphs $G$ whose edge-set
can be $k$-coloured such that no even hole of $G$ is monochromatic; (ii) for
every fixed antidirected forest $F$, the graphs admitting an orientation
without any induced copy of $F$; (iii) for every $\ell\geq 4$, the graphs
admitting an orientation without any induced antidirected cycle of length at
least $\ell$.
  For $k=2$, class (i) contains odd-signable graphs. Class (ii) characterises
the oriented graphs $H$ such that the class of graphs admitting an orientation
without any induced copy of $H$ is degree-bounded. For $\ell=5$, class (iii)
contains Burling graphs. In case (i) and case (iii) for $\ell=4$, we further
obtain that the classes are polynomially $\chi$-bounded.

</details>


### [69] [Hall--Littlewood expansions of chromatic quasisymmetric polynomials using linked rook placements](https://arxiv.org/abs/2506.23082)
*Jang Soo Kim,Seung Jin Lee,Meesue Yoo*

Main category: math.CO

TL;DR: 本文通过自然单位区间序获得色拟对称函数的Hall-Littlewood展开，并用关联车布局描述系数，同时应用Carlsson-Mellit关系给出了单细胞LLT多项式在修正变换Hall-Littlewood基下展开系数的组合描述。


<details>
  <summary>Details</summary>
Motivation: 研究色拟对称函数与单细胞LLT多项式在不同多项式基下的展开关系，旨在揭示其组合意义。

Method: 利用自然单位区间序构造色拟对称函数的Hall-Littlewood展开，通过关联车布局描述系数，并应用Carlsson-Mellit关系连接LLT多项式。

Result: 获得了色拟对称函数的Hall-Littlewood展开系数与关联车布局的明确对应关系，并给出了单细胞LLT多项式在修正变换Hall-Littlewood基下展开的组合解释。

Conclusion: 该工作建立了色拟对称函数与LLT多项式展开的显式组合联系，为相关对称函数理论提供了新的组合视角。

Abstract: In this work, we obtain a Hall--Littlewood expansion of the chromatic
quasisymmetric function arising from a natural unit interval order and describe
the coefficients in terms of linked rook placements. Applying the
Carlsson--Mellit relation between chromatic quasisymmetric functions and
unicellular LLT polynomials, we also obtain a combinatorial description for the
coefficients of the unicellular LLT polynomials expanded in terms of the
modified transformed Hall--Littlewood polynomials.

</details>


### [70] [Factorization norms and an inverse theorem for MaxCut](https://arxiv.org/abs/2506.23989)
*Igor Balla,Lianna Hambardzumyan,István Tomon*

Main category: math.CO

TL;DR: 本文证明了具有有界$\gamma_2$-范数或归一化迹范数的布尔矩阵必须包含线性大小的全1或全0子矩阵，验证了Hambardzumyan等人的猜想，并讨论了其在多个领域的应用。


<details>
  <summary>Details</summary>
Motivation: 研究布尔矩阵的结构性质，验证Hambardzumyan等人的猜想，并探索其在通信复杂度、算子理论、谱图论和极值组合学中的应用。

Method: 通过分析布尔矩阵的$\gamma_2$-范数和归一化迹范数，结合极值组合学和图论方法，证明了主要结果。

Result: 证明了布尔矩阵在有界$\gamma_2$-范数或归一化迹范数下必须包含线性大小的全1或全0子矩阵，并建立了MaxCut的逆定理。

Conclusion: 该研究不仅验证了猜想，还提供了关于布尔矩阵结构的新见解，并在多个领域展示了其应用价值，特别是MaxCut逆定理的建立。

Abstract: We prove that Boolean matrices with bounded $\gamma_2$-norm or bounded
normalized trace norm must contain a linear-sized all-ones or all-zeros
submatrix, verifying a conjecture of Hambardzumyan, Hatami, and Hatami. We also
present further structural results about Boolean matrices of bounded
$\gamma_2$-norm and discuss applications in communication complexity, operator
theory, spectral graph theory, and extremal combinatorics.
  As a key application, we establish an inverse theorem for MaxCut. A
celebrated result of Edwards states that every graph $G$ with $m$ edges has a
cut of size at least $\frac{m}{2}+\frac{\sqrt{8m+1}-1}{8}$, with equality
achieved by complete graphs with an odd number of vertices. To contrast this,
we prove that if the MaxCut of $G$ is at most $\frac{m}{2}+O(\sqrt{m})$, then
$G$ must contain a clique of size $\Omega(\sqrt{m})$.

</details>


### [71] [Arithmetic non-generic arrangements](https://arxiv.org/abs/2506.23124)
*Pragnya Das,Takuya Saito,Simona Settepanella*

Main category: math.CO

TL;DR: 本文研究了判别超平面构型B(n,k,A)中的非非常一般交点，提出了算术准则来刻画这些交点，并修正了先前关于此类构型中二阶交点的结果。


<details>
  <summary>Details</summary>
Motivation: 研究判别超平面构型中非非常一般交点的特性，以完善对这类构型组合结构的理解，并纠正先前研究中的错误。

Method: 通过分析判别超平面构型B(n,k,A)的交点格，特别是非非常一般交点，建立算术准则来刻画这些交点。

Result: 提出了非非常一般交点的算术准则，并修正了Libgober和第三作者关于判别超平面构型中二阶交点的结果。

Conclusion: 本文的工作完善了对判别超平面构型中非非常一般交点的理解，并为相关研究提供了更准确的数学工具。

Abstract: A discriminantal hyperplane arrangement B(n,k,A) is constructed from a given
(generic) hyperplane arrangement A, which is classified as either very generic
or non-very generic depending on the combinatorial structure of B(n,k,A). In
particular, A is considered non-very generic if the intersection lattice of
B(n,k,A) contains at least one non-very generic intersection -- that is, an
intersection that fails to satisfy a specific rank condition established by
Athanasiadis in [1]. In this paper, we present arithmetic criteria
characterizing non-very generic intersections in discriminantal arrangements
and we complete and correct a previous result by Libgober and the third author
concerning rank-two intersections in such arrangements.

</details>


### [72] [Joint equidistributions of mesh patterns 123 and 132 with antipodal shadings](https://arxiv.org/abs/2506.23148)
*Shuzhen Lv,Philip B. Zhang*

Main category: math.CO

TL;DR: 本文证明了126种潜在联合等分布中的112种，涉及网格模式123和132的相同对映着色，并通过构建双射、递推关系和生成函数，展示了562种非对称非对映着色的联合等分布结果。


<details>
  <summary>Details</summary>
Motivation: Kitaev和Lv最近发起了对具有相同对称着色的网格模式123和132联合等分布的研究，证明了80种潜在分布中的75种。本研究旨在扩展这一工作，探索相同对映着色下的联合等分布。

Method: 通过构造双射、寻找递推关系、获得生成函数等方法，研究了网格模式123和132的联合分布。此外，还展示了某些网格模式对的联合分布与第一类无符号Stirling数的关联。

Result: 在126种潜在联合等分布中，成功证明了112种具有相同对映着色的情况，并额外提供了562种非对称非对映着色的联合等分布结果。

Conclusion: 本研究不仅扩展了Kitaev和Lv的工作，证明了更多联合等分布情况，还揭示了网格模式联合分布与组合数学中经典数列的联系，为相关领域提供了新的研究视角。

Abstract: The study of joint equidistributions of mesh patterns 123 and 132 with the
same symmetric shadings was recently initiated by Kitaev and Lv, where 75 of 80
potential joint equidistributions were proven. In this paper, we prove 112 out
of 126 potential joint equidistributions of mesh patterns 123 and 132 with the
same antipodal shadings. As a byproduct, we present 562 joint equidistribution
results for non-symmetric and non-antipodal shadings. To achieve this, we
construct bijections, find recurrence relations, and obtain generating
functions. Moreover, we demonstrate that the joint distributions of several
pairs of mesh patterns are related to the unsigned Stirling numbers of the
first kind.

</details>


### [73] [Prime graphical parking functions and strongly recurrent configurations of the Abelian sandpile model](https://arxiv.org/abs/2506.23237)
*Thomas Selig,Haoyue Zhu*

Main category: math.CO

TL;DR: 本文研究了停车函数与阿贝尔沙堆模型(ASM)之间的对偶关系，特别是引入了$G$-停车函数的素数概念，并证明其在ASM中对应强循环配置。


<details>
  <summary>Details</summary>
Motivation: 探索$G$-停车函数与ASM循环配置之间的深层联系，扩展经典停车函数及$(p,q)$-停车函数的素数概念。

Method: 定义了素数$G$-停车函数的概念，并在轮图、完全图、完全多部图和完全分裂图等多种图族上研究其与ASM强循环配置的对应关系。

Result: 证明了素数$G$-停车函数与ASM中的强循环配置存在对应关系，并在特定图族中验证了这一结论。

Conclusion: 通过建立素数$G$-停车函数与ASM强循环配置的联系，为离散动力系统的对偶性研究提供了新的理论工具和实例验证。

Abstract: This work investigates the duality between two discrete dynamical processes:
parking functions, and the Abelian sandpile model (ASM). Specifically, we are
interested in the extension of classical parking functions, called $G$-parking
functions, introduced by Postnikov and Shapiro in 2004. $G$-parking functions
are in bijection with recurrent configurations of the ASM on $G$. In this work,
we define a notion of prime $G$-parking functions. These are parking functions
that are in a sense "indecomposable". Our notion extends the concept of
primeness for classical parking functions, as well as the notion of prime
$(p,q)$-parking functions introduced by Armon et al. in recent work. We show
that from the ASM perspective, prime $G$-parking functions correspond to
certain configurations of the ASM, which we call strongly recurrent. We study
this new connection on a number of graph families, including wheel graphs,
complete graphs, complete multi-partite graphs, and complete split graphs.

</details>


### [74] [An acyclic $d$-partition of the $r$-uniform complete hypergraph $K_{rd}^{(r)}$](https://arxiv.org/abs/2506.23238)
*Ayako Carter,Eric Montoya,Mihai D. Staic*

Main category: math.CO

TL;DR: 本文引入了一个$d$-分区$\mathcal{E}_d^{(r)}$，证明了其齐次性及每个超图$\Omega_i^{(r,d)}$的无环性，并应用此结果部分验证了[14]中的猜想。


<details>
  <summary>Details</summary>
Motivation: 研究$r$-均匀完全超图$K_{rd}^{(r)}$的分区性质，并探索其在行列式映射$det^{S^r}$非平凡性中的应用。

Method: 通过构造$d$-分区$\mathcal{E}_d^{(r)}=(\Omega_1^{(r,d)}, \Omega_2^{(r,d)},\dots, \Omega_d^{(r,d)})$，并分析其齐次性和无环性。

Result: 证明了分区$\mathcal{E}_d^{(r)}$是齐次的，且每个超图$\Omega_i^{(r,d)}$是无环的（即贝蒂数为零），并由此得出$det^{S^r}$对所有$r$均非平凡。

Conclusion: 该研究不仅验证了超图分区的特定性质，还为[14]中的猜想提供了部分解答，具有重要的理论意义。

Abstract: In this paper we introduce a $d$-partition
$\mathcal{E}_d^{(r)}=(\Omega_1^{(r,d)}, \Omega_2^{(r,d)},\dots,
\Omega_d^{(r,d)})$ of the $r$-uniform complete hypergraph $K_{rd}^{(r)}$. We
prove that $\mathcal{E}_d^{(r)}$ is homogeneous and that each hypergraph
$\Omega_i^{(r,d)}$ is acyclic (i.e. has zero Betti numbers). As an application,
we show that the map $det^{S^r}$ is nontrivial for every $r$, which gives a
partial answer to a conjecture from [14].

</details>


### [75] [Relative discrepancy of hypergraphs](https://arxiv.org/abs/2506.23264)
*Diep Luong-Le,Tuan Tran,Dilong Yang*

Main category: math.CO

TL;DR: 本文研究了$k$-均匀超图的相对差异问题，确定了$\hbox{bs}(k)$的上下界，并改进了Bollob\'as-Scott的现有结果。


<details>
  <summary>Details</summary>
Motivation: 研究$k$-均匀超图的相对差异，解决Bollob\'as和Scott提出的若干问题，扩展Erd\H{o}s等人的经典定理。

Method: 结合线性代数、傅里叶分析和极值超图理论，推导$\hbox{bs}(k)$的上下界。

Result: 确定了$2\le k\le 13$时$\hbox{bs}(k)$的精确值，并证明$\hbox{bs}(k)=O(k^{0.525})$，显著改进了之前的$k+1$上界。

Conclusion: 本文不仅推广了经典结果，还为更高维度的超图差异问题提供了新的理论工具和界限。

Abstract: Given $k$-uniform hypergraphs $G$ and $H$ on $n$ vertices with densities $p$
and $q$, their relative discrepancy is defined as
$\hbox{disc}(G,H)=\max\big||E(G')\cap E(H')|-pq\binom{n}{k}\big|$, where the
maximum ranges over all pairs $G',H'$ with $G'\cong G$, $H'\cong H$, and
$V(G')=V(H')$. Let $\hbox{bs}(k)$ denote the smallest integer $m \ge 2$ such
that any collection of $m$ $k$-uniform hypergraphs on $n$ vertices with
moderate densities contains a pair $G,H$ for which $\hbox{disc}(G,H) =
\Omega(n^{(k+1)/2})$.
  In this paper, we answer several questions raised by Bollob\'as and Scott,
providing both upper and lower bounds for $\hbox{bs}(k)$. Consequently, we
determine the exact value of $\hbox{bs}(k)$ for $2\le k\le 13$, and show
$\hbox{bs}(k)=O(k^{0.525})$, substantially improving the previous bound
$\hbox{bs}(k)\le k+1$ due to Bollob\'as-Scott. The case $k=2$ recovers a result
of Bollob\'as-Scott, which generalises classical theorems of Erd\H{o}s-Spencer,
and Erd\H{o}s-Goldberg-Pach-Spencer. The case $k=3$ also follows from the
results of Bollob\'as-Scott and Kwan-Sudakov-Tran. Our proof combines linear
algebra, Fourier analysis, and extremal hypergraph theory.

</details>


### [76] [Linear relations of colored Gaussian cycles](https://arxiv.org/abs/2506.23936)
*Hannah Göbel,Pratik Misra*

Main category: math.CO

TL;DR: 本文研究了彩色高斯图模型中的线性二项式与图对称性的关系，证明了Marigliano和Davies猜想在3、5、7环中成立，但在其他长度的环中不成立，并提出了修正后的猜想。


<details>
  <summary>Details</summary>
Motivation: 研究彩色高斯图模型中线性二项式与图对称性的关系，验证Marigliano和Davies的猜想是否普遍成立。

Method: 通过分析彩色环的浓度矩阵，构造反例证明猜想在某些情况下不成立，并探索猜想的可能修正。

Result: 证明了猜想在3、5、7环中成立，但在其他长度的环中不成立，并通过构造两条彩色路径的浓度矩阵行列式相等的例子来反驳原猜想。

Conclusion: 原猜想仅在特定长度的环中成立，修正后的猜想在更广泛的条件下得到证明，为彩色高斯图模型的理论研究提供了新的方向。

Abstract: A colored Gaussian graphical model is a linear concentration model in which
equalities among the concentrations are specified by a coloring of an
underlying graph. Marigliano and Davies conjectured that every linear binomial
that appears in the vanishing ideal of an undirected colored cycle corresponds
to a graph symmetry. We prove this conjecture for 3,5, and 7 cycles and
disprove it for colored cycles of any other length. We construct the
counterexamples by proving the fact that the determinant of the concentration
matrices of two colored paths can be equal even when they are not identical or
reflection of each other. We also explore the potential strengthening of the
conjecture and prove a revised version of the conjecture.

</details>


### [77] [An Equivalence Between Erdős's Square Packing Conjecture and the Convergence of an Infinite Series](https://arxiv.org/abs/2506.23284)
*Anshul Raj Singh*

Main category: math.CO

TL;DR: 研究了单位正方形内放置n个不重叠小正方形的最大边长和$f(n)$, 证明了$f(n^2+1)=n$的充要条件及其普遍性。


<details>
  <summary>Details</summary>
Motivation: 探索单位正方形内非重叠小正方形的最优填充问题, 建立$f(n^2+1)$与整数$n$的精确关系。

Method: 通过分析级数$\sum_{k\geq1}(f(k^2+1)-k)$的收敛性, 采用必要条件与充分条件的双向证明方法。

Result: 证明了$f(n^2+1)=n$当且仅当级数收敛, 并发现该等式对无限多个$k$成立则对所有正整数成立。

Conclusion: 建立了正方形填充问题中$f(k^2+1)=k$的普适性判据, 为离散几何中的极值问题提供了新见解。

Abstract: Let $f(n)$ denote the maximum sum of the side lengths of $n$ non-overlapping
squares packed inside a unit square. We prove that $f(n^2+1) = n$ for all
positive integers $n$ if and only if the sum $\sum_{k\geq 1}(f(k^2+1)-k)$
converges. We also show that if $f(k^2+1) = k$, for infinitely many positive
integers then $f(k^2+1) = k$ for all positive integers.

</details>


### [78] [Characterization of non-singular hyperplanes of $H\left(s,q^2\right)$ in $\mathrm{P G}\left(s, q^2\right)$](https://arxiv.org/abs/2506.23330)
*Stuti Mohanty,Bikramaditya Sahu*

Main category: math.CO

TL;DR: 本文通过组合方法研究了射影空间$\mathrm{PG}\left(s,q^2\right)$中非奇异厄米特簇${H}\left(s, q^2\right)$的超平面特性，提出了判定超平面是否属于该簇的充要条件。


<details>
  <summary>Details</summary>
Motivation: 旨在扩展基于交截性质的厄米特簇表征方法，为识别其超平面提供纯组合学的判定依据。

Method: 通过分析超平面与点及余维2子空间的交截数，建立组合特征条件。

Result: 确立了$s\geq3$且$q>2$时，超平面属于厄米特簇${H}\left(s, q^2\right)$的充要组合条件。

Conclusion: 该组合表征方法完善了厄米特簇超平面的理论框架，为相关几何结构研究提供了新工具。

Abstract: In this paper, we present a combinatorial characterization of the hyperplanes
associated with non-singular hermitian varieties ${H}\left(s, q^2\right)$ in
the projective space $\mathrm{PG}\left(s,q^2\right)$ where $s\geq3$ and $q>2$.
By analyzing the intersection numbers of hyperplanes with points and
co-dimension $2$ subspaces, we establish necessary and sufficient conditions
for a hyperplane to be part of the hermitian variety. This approach extends
previous characterizations of hermitian varieties based on intersection
properties, providing a purely combinatorial method for identifying their
hyperplanes.

</details>


### [79] [MacMahon's Double Vision: Partition Diamonds Revisited](https://arxiv.org/abs/2506.23354)
*Matthias Beck,Kobe Wijesekera*

Main category: math.CO

TL;DR: 本文通过Stanley的$P$-分拆理论，给出了Dockery等人提出的$d$-重分拆钻石生成函数的双变量闭式解，核心是编码排列下降统计的Euler-Mahonian多项式。


<details>
  <summary>Details</summary>
Motivation: Andrews等人引入平面分拆钻石研究MacMahon的$\Omega$-算子后，Dockery团队将其推广为$d$-重分拆钻石并获得递归型生成函数。本文旨在通过更系统的组合理论寻找闭式解。

Method: 采用Stanley(1972)的$P$-分拆理论框架，将问题转化为对排列下降统计的分析，利用Euler-Mahonian多项式作为核心工具。

Result: 成功推导出Dockery-Jameson-Sellers-Wilson生成函数的双变量闭式表达式，其数学本质与Euler-Mahonian多项式密切相关。

Conclusion: 该研究不仅为$d$-重分拆钻石提供了更深刻的组合解释，也展示了$P$-分拆理论与经典分拆问题的有效结合。

Abstract: Plane partition diamonds were introduced by Andrews, Paule, and Riese (2001)
as part of their study of MacMahon's $\Omega$-operator in search for integer
partition identities. More recently, Dockery, Jameson, Sellers, and Wilson
(2024) extended this concept to $d$-fold partition diamonds and found their
generating function in a recursive form. We approach $d$-fold partition
diamonds via Stanley's (1972) theory of $P$-partitions and give a closed
formula for a bivariate generalization of the Dockery--Jameson--Sellers--Wilson
generating function; its main ingredient is the Euler--Mahonian polynomial
encoding descent statistics of permutations.

</details>


### [80] [Ordered set partition posets](https://arxiv.org/abs/2506.23355)
*Bruce E Sagan,Sheila Sundaram*

Main category: math.CO

TL;DR: 本文首次系统研究了有序集合划分格Omega_n，计算了其M\"obius函数，证明了其具有递归原子序，并分析了对称群S_n在相关同调群上的作用，特别是平凡表示的多重性。同时探讨了块大小与固定整数d相关的偏序集。


<details>
  <summary>Details</summary>
Motivation: 有序集合划分在组合数学、数论、置换多面体及协变代数研究中频繁出现，但其对应的格Omega_n此前未被系统研究。本文旨在填补这一空白，全面探索Omega_n的性质。

Method: 通过偏序集理论工具，分析Omega_n的格结构，计算M\"obius函数，构造递归原子序，并利用对称群表示论研究同调群的S_n作用。

Result: 确定了Omega_n的M\"obius函数，证明其具有递归原子序，揭示了同调群中平凡表示的多重性规律，并推广到块大小与d相关的偏序集。

Conclusion: 该研究为有序集合划分格Omega_n建立了系统理论框架，其组合与表示论性质为后续相关领域研究提供了新工具，特别在d-可分条件下的推广具有潜在应用价值。

Abstract: The lattice of partitions of a set and its d-divisible generalization have
been much studied for their combinatorial, topological, and
respresentation-theoretic properties. An ordered set partition is a set
partition where the subsets are listed in a specific order. Ordered set
partitions appear in combinatorics, number theory, permutation polytopes, and
the study of coinvariant algebras. The ordered set partitions of {1,...,n} can
be partially ordered by refinement and then a unique minimal element attached,
resulting in a lattice Omega_n. But this lattice has received no attention to
our knowledge. The purpose of this paper is to provide the first comprehensive
look at Omega_n. In particular, we determine its M\"obius function, show that
it admits a recursive atom ordering, and study the action of the symmetric
group S_n on associated homology groups, looking in particular at the
multiplicity of the trivial representation. We also consider the related posets
where every block has size either divisible by some fixed d at least 2, or
congruent to 1 modulo d.

</details>


### [81] [The monomial expansions for modified Macdonald polynomials](https://arxiv.org/abs/2506.23373)
*Emma Yu Jin,Xiaowei Lin*

Main category: math.CO

TL;DR: 本文发现了一组关于杨图填装的16个统计量，并提出了修正Macdonald多项式的新组合公式，进一步推导出四种紧凑公式及单项式展开的显式表达式。


<details>
  <summary>Details</summary>
Motivation: 研究旨在寻找修正Macdonald多项式的新组合表达式，以深化对其代数与组合性质的理解，并建立与现有理论的联系。

Method: 通过定义杨图填装的统计量族$A$，构建组合公式$\tilde{H}_{\lambda}(X;q,t)=\sum_{\sigma\in T(\lambda)}x^{\sigma}q^{maj(\sigma)}t^{\eta(\sigma)}$，并进一步推导紧凑公式及显式展开。

Result: 提出了四种修正Macdonald多项式的紧凑公式，并得到其单项式展开的四个显式表达式，其中一个与Garbali和Wheeler(2019)的公式一致。

Conclusion: 新发现的统计量族及组合公式为修正Macdonald多项式的研究提供了新工具，其显式展开结果验证了与已有理论的关联性。

Abstract: We discover a family $A$ of sixteen statistics on fillings of any given Young
diagram and prove new combinatorial formulas for the modified Macdonald
polynomials, that is, $$\tilde{H}_{\lambda}(X;q,t)=\sum_{\sigma\in
T(\lambda)}x^{\sigma}q^{maj(\sigma)}t^{\eta(\sigma)}$$ for each statistic
$\eta\in A$. Building upon this new formula, we establish four compact formulas
for the modified Macdonald polynomials, namely,
$$\tilde{H}_{\lambda}(X;q,t)=\sum_{\sigma}d_{\varepsilon}(\sigma)x^{\sigma}q^{maj(\sigma)}t^{\eta(\sigma)}$$
which is summed over all canonical or dual canonical fillings of a Young
diagram and $d_{\varepsilon}(\sigma)$ is a product of $t$-multinomials.
Finally, the compact formulas enable us to derive four explicit expressions for
the monomial expansion of modified Macdonald polynomials, one of which
coincides with the formula given by Garbali and Wheeler (2019).

</details>


### [82] [Experimenting with Permutation Wordle](https://arxiv.org/abs/2506.23452)
*Aurora Hiveley*

Main category: math.CO

TL;DR: 本文研究了排列猜词游戏的最优策略，探讨了Kutin和Smithline提出的"循环移位"策略的潜在最优性，并通过形式化策略定义、实验分析和生成函数系数检验进行了验证。


<details>
  <summary>Details</summary>
Motivation: 排列猜词游戏中玩家需在最少次数内猜出长度为$n$的秘密排列，现有"循环移位"策略被猜想为最优，但缺乏理论验证。本文旨在通过多种方法检验这一猜想。

Method: 通过形式化策略定义、对归纳构造策略进行实验分析，并研究归纳策略生成函数的系数特性，系统评估"循环移位"策略的性能。

Result: 实验与理论分析表明，"循环移位"策略在特定条件下展现出优越性，但其全局最优性仍需进一步数学证明支持。

Conclusion: 虽然"循环移位"策略表现出潜在的最优特性，但完全证实其最优性需要更深入的理论工作，这为未来研究指明了方向。

Abstract: Consider a game of permutation wordle in which a player attempts to guess a
secret permutation of length $n$ in as few guesses as possible. In each round,
the guessing player is told which indices of their guessed permutation are
correct. How can we optimize the player's strategy? Samuel Kutin and Lawren
Smithline (arXiv:2408.00903) propose a strategy called "cyclic shift" in which
all incorrect entries are shifted one index to the right in successive guesses,
and they conjecture its optimality. We investigate this conjecture by
formalizing what a strategy looks like, performing experimental analysis on
inductively constructed strategies, and examining the coefficients of an
inductive strategy's generating function.

</details>


### [83] [The Neighbour Sum Problem on Trees](https://arxiv.org/abs/2506.23965)
*Sayan Dutta,Sohom Gupta*

Main category: math.CO

TL;DR: 本文研究了图的邻点和性质，提出了一个算法来检测有限树是否满足该性质，并发现了一类满足该性质的大规模树结构。


<details>
  <summary>Details</summary>
Motivation: 研究图论中的邻点和性质（Neighbour Sum Property），旨在探索非零函数$f$将每个顶点映射到其邻居顶点值之和的条件。

Method: 设计了一个算法，用于检测给定的有限树是否满足邻点和性质。

Result: 发现了一类在$n$个顶点上满足邻点和性质的树结构，为图论研究提供了新的实例。

Conclusion: 通过算法验证和实例分析，本文不仅提供了检测邻点和性质的有效方法，还扩展了满足该性质的树类别的知识。

Abstract: A graph $\mathcal G = (\mathcal V, \mathcal E)$ is said to satisfy the
Neighbour Sum Property if there exists some $f:\mathcal V\to\mathbb R$ such
that $f\not\equiv 0$ and it maps every vertex to the sum of the values taken by
its neighbours. In this article, we provide an algorithm to check whether a
given finite tree satisfies the neighbour sum property. We also find a large
class of trees on $n$ vertices that satisfy the property.

</details>


### [84] [Sabotage the Mantel Theorem](https://arxiv.org/abs/2506.23794)
*Natalie Behague,Debsoumya Chakraborti,Xizhi Liu*

Main category: math.CO

TL;DR: 研究在无三角形图中强制包含特定子图$\mathbb{P}$时，如何影响Mantel定理的极值边界，并建立了紧致的上下界。


<details>
  <summary>Details</summary>
Motivation: 探索Mantel定理（关于无三角形图的最大边数）在额外要求包含特定子图$\mathbb{P}$时的扩展情况。

Method: 通过分析随机无三角形图和三角消除过程生成的图，建立一般性的上下界理论框架。

Result: 当子图$\mathbb{P}$的规模处于特定范围时，所提边界在指数级别上是紧致的，适用于两类典型图结构。

Conclusion: 该研究为约束性子图存在条件下的极值图论问题提供了普适的理论工具，并验证了边界在重要图类中的最优性。

Abstract: One of the earliest results in extremal graph theory, Mantel's theorem,
states that the maximum number of edges in a triangle-free graph $G$ on $n$
vertices is $\lfloor n^2/4 \rfloor$. We investigate how this extremal bound is
affected when $G$ is additionally required to contain a prescribed graph
$\mathbb{P}$ as a subgraph. We establish general upper and lower bounds for
this problem, which are tight in the exponent for random triangle-free graphs
and graphs generated by the triangle-free process, when the size of
$\mathbb{P}$ lies within certain ranges.

</details>


### [85] [Steiner Systems over Mixed Alphabet and Related Designs](https://arxiv.org/abs/2506.23860)
*Tuvi Etzion*

Main category: math.CO

TL;DR: 本文提出并研究了混合Steiner系统MS$(t,k,Q)$，构建了其存在条件，并证明不存在这类系统的大集。


<details>
  <summary>Details</summary>
Motivation: 研究混合Steiner系统的构造与存在条件，填补组合设计与编码理论交叉领域的空白。

Method: 利用完美混合码、可分解设计、大集、正交阵列及新型对-三元组设计构造混合Steiner系统。

Result: 提出了混合Steiner系统存在的必要条件，并证明不存在这类系统的大集。

Conclusion: 混合Steiner系统的研究为组合设计与编码理论提供了新的理论工具，但其大集的不存在性限制了进一步扩展。

Abstract: A mixed Steiner system MS$(t,k,Q)$ is a set (code) $C$ of words of weight $k$
over an alphabet $Q$, where not all coordinates of a word have the same
alphabet size, each word of weight $t$, over $Q$, has distance $k-t$ from
exactly one codeword of $C$, and the minimum distance of the code $2(k-t)+1$.
Mixed Steiner systems are constructed from perfect mixed codes, resolvable
designs, large set, orthogonal arrays, and a new type of pairs-triples design.
Necessary conditions for the existence of mixed Steiner systems are presented
and it is proved that there are no large sets of these Steiner systems.

</details>


### [86] [Further generalization of central sets theorem for partial semigroups and vip systems](https://arxiv.org/abs/2506.23865)
*Anik Pramanick,MD Mursalim Saikh*

Main category: math.CO

TL;DR: 中心集定理是Ramsey理论的核心结果，本文综述了其从拓扑动力系统到半群代数结构的扩展历程，并最终推广至任意适度偏半群与VIP系统。


<details>
  <summary>Details</summary>
Motivation: 中心集定理作为Hindman定理与van der Waerden定理的共同推广，其不断泛化的研究揭示了Ramsey理论的深层代数与拓扑结构关联。

Method: 结合Stone-\v{C}ech紧化$\beta S$的代数工具（Hindman & Bergelson）与拓扑动力系统方法（Shi & Yang），最终采用偏半群理论进行扩展。

Result: 定理被推广至适度偏半群及VIP系统，且Zhang近期成果实现了不可数中心集的扩展，突破了原有可数限制。

Conclusion: 该系列工作建立了中心集定理的最广泛形式，为未来非交换结构与高阶组合的Ramsey性质研究奠定了基础。

Abstract: The Central Sets Theorem, a fundamental result in Ramsey theory, is a joint
extension of both Hindman's theorem and van der Waerden's theorem. It was
originally introduced by H. Furstenberg using methods from topological
dynamics. Later, using the algebraic structure of the Stone-$\v{C}$ech
compactification $\beta$ S of a semigroup S, N. Hindman and V. Bergelson
extended the theorem in 1990. H. Shi and H. Yang established a topological
dynamical characterization of central sets in an arbitrary semigroup (S,+), and
showed it to be equivalent to the usual algebraic characterization. D. De, N.
Hindman, and D. Strauss later proved a stronger version of the Central Sets
Theorem for semigroups in 2008. D. Phulara further genaralized the result for
commutative semigroups in 2015. Recently in his work, Zhang generalized it
further and proved the central sets theorem for uncountably many central sets.
We extend the theorem to arbitrary adequate partial semigroups and VIP systems.

</details>


### [87] [$C_4$-free subgraphs of high degree with geometric applications](https://arxiv.org/abs/2506.23942)
*Zach Hunter,Aleksa Milojević,Istvan Tomon,Benny Sudakov*

Main category: math.CO

TL;DR: 本文提出了一种解决Zarankiewicz型问题的新结构工具，通过展示图的平均度与诱导子图性质之间的二分关系，为几何领域中的多个极值图论问题提供了统一解决方法。


<details>
  <summary>Details</summary>
Motivation: Zarankiewicz问题作为极值图论的核心问题，研究不含完全二分图$K_{s,s}$的图中边数的最大值。尽管一般图的情况仍未解决，但在几何图类中的进展促使开发新工具以统一处理此类问题。

Method: 作者证明了对任意正整数$k$，任何平均度为$d$的图要么包含一个平均度至少为$k$的诱导无$C_4$子图，要么包含一个具有$\Omega_k(d^2)$条边的$d$顶点子图。

Result: 该二分定理被应用于几何中的Zarankiewicz型问题，在每个案例中都获得了最优边界，验证了方法的有效性。

Conclusion: 研究提出的结构工具为极值图论问题提供了统一框架，特别在几何图类中实现了理论突破，未来可扩展至更广泛的图类研究。

Abstract: The Zarankiewicz problem, a cornerstone problem in extremal graph theory,
asks for the maximum number of edges in an $n$-vertex graph that does not
contain the complete bipartite graph $K_{s,s}$. While the problem remains
widely open in the case of general graphs, the past two decades have seen
significant progress on this problem for various restricted graph classes --
particularly those arising from geometric settings -- leading to a deeper
understanding of their structure.
  In this paper, we develop a new structural tool for addressing
Zarankiewicz-type problems. More specifically, we show that for any positive
integer $k$, every graph with average degree $d$ either contains an induced
$C_4$-free subgraph with average degree at least $k$, or it contains a
$d$-vertex subgraph with $\Omega_k(d^2)$ edges. As an application of this
dichotomy, we propose a unified approach to a large number of Zarankiewicz-type
problems in geometry, obtaining optimal bounds in each case.

</details>


### [88] [Approximate Itai-Zehavi conjecture for random graphs](https://arxiv.org/abs/2506.23970)
*Lawrence Hollom,Lyuben Lichev,Adva Mond,Julien Portier,Yiting Wang*

Main category: math.CO

TL;DR: 本文证明了Itai-Zehavi猜想在Erd\H{o}s-R\'enyi随机图$G(n,p)$（当$np=\omega(\log n)$时）和随机正则图$G(n,d)$（当$d=\omega(\log n)$时）中高概率成立，并基本确认了稀疏随机正则图中该猜想在常数因子内的正确性。


<details>
  <summary>Details</summary>
Motivation: 研究Itai-Zehavi猜想在随机图中的渐近成立性，并回答Dragani\'{c}和Krivelevich提出的问题。

Method: 利用了随机正则图中最新的sprinkling技术。

Result: 证明了在$np=\omega(\log n)$的$G(n,p)$和$d=\omega(\log n)$的$G(n,d)$中，Itai-Zehavi猜想高概率成立，且在稀疏随机正则图中猜想基本正确。

Conclusion: 该研究不仅验证了Itai-Zehavi猜想在两类随机图中的渐近正确性，还为稀疏随机正则图提供了常数因子内的确认，推动了相关领域的发展。

Abstract: A famous conjecture by Itai and Zehavi states that, for every
$d$-vertex-connected graph $G$ and every vertex $r$ in $G$, there are $d$
spanning trees of $G$ such that, for every vertex $v$ in $G\setminus \{r\}$,
the paths between $r$ and $v$ in different trees are internally
vertex-disjoint. We show that with high probability the Itai-Zehavi conjecture
holds asymptotically for the Erd\H{o}s-R\'enyi random graph $G(n,p)$ when $np=
\omega(\log n)$ and for random regular graphs $G(n,d)$ when $d= \omega(\log
n)$. Moreover, we essentially confirm the conjecture up to a constant factor
for sparser random regular graphs. This answers positively a question of
Dragani\'{c} and Krivelevich. Our proof makes use of recent developments on
sprinkling techniques in random regular graphs.

</details>


### [89] [The 3-path-connectivity of the augmented cubes](https://arxiv.org/abs/2506.24071)
*S. A. Kandekar,R. Barabde,S. A. Mane*

Main category: math.CO

TL;DR: 本文研究了增强立方体$AQ_n$的3-路径连通性$\pi_3(AQ_n)$，确定了其精确值，并展示了奇偶维度下的不同表达式。


<details>
  <summary>Details</summary>
Motivation: 为了评估网络在故障情况下的鲁棒性，研究者扩展了经典连通性概念，其中$k$-路径连通性$\pi_k(G)$是重要指标。增强立方体$AQ_n$因其对称性和容错结构成为研究对象。

Method: 通过定义$D$-路径和内部不相交路径集，计算增强立方体$AQ_n$中任意3顶点子集$D$的最小路径连通数$\pi_G(D)$，进而确定$\pi_3(AQ_n)$。

Result: 证明了$\pi_3(AQ_n)$的精确值：当$n$为偶数时等于$\frac{3n}{2} - 2$，为奇数时等于$\frac{3(n - 1)}{2} - 1$。

Conclusion: 该研究不仅完善了增强立方体的理论特性，还为网络容错性分析提供了新的数学工具，奇偶维度的差异结果具有重要理论意义。

Abstract: Connectivity is a cornerstone concept in graph theory, essential for
evaluating the robustness of networks against failures. To better capture fault
tolerance in complex systems, researchers have extended classical connectivity
notions, one such extension being the $k$-path-connectivity, $\pi_k(G)$,
introduced by Hager. Given a connected simple graph $G = (V, E)$ and a subset
$D \subseteq V$ with $|D| \geq 2$, a $D$-path is a path that includes all
vertices in $D$. A collection of such paths is internally disjoint if they
intersect only at the vertices of $D$ and share no edges. The maximum number of
internally disjoint $D$-paths in $G$ is denoted $\pi_G(D)$, and the
$k$-path-connectivity is defined as $\pi_k(G) = \min \{ \pi_G(D) \mid D
\subseteq V(G),\ |D| = k\}$. In this paper, we investigate the
3-path-connectivity of the augmented cube $AQ_n$, a variant of the hypercube
known for its enhanced symmetry and fault-tolerant structure. We establish the
exact value of $\pi_3(AQ_n)$ and show that: $$
  \pi_3(AQ_n) =
  \begin{cases}
  \frac{3n}{2} - 2, & \text{if } n \text{ is even},
  \frac{3(n - 1)}{2} - 1, & \text{if } n \text{ is odd}.
  \end{cases}
  $$

</details>


### [90] [On Link-irregular labelings of Graphs](https://arxiv.org/abs/2506.24080)
*Alexander Bastien,Omid Khormali*

Main category: math.CO

TL;DR: 本文提出了图的链接不规则标记概念，通过边标记扩展了链接不规则图的研究。确定了此类标记存在的充要条件，定义了最小标记数$\eta(G)$，并证明了完全图和轮式图的可标记性及其标记数。


<details>
  <summary>Details</summary>
Motivation: 研究图的链接不规则标记，旨在扩展传统链接不规则图理论，探索通过边标记实现顶点邻域子图唯一标识的可能性及其应用价值。

Method: 采用组合数学与图论方法，建立链接不规则标记的充要条件，通过构造性证明分析特定图族（如完全图、轮式图）的标记数$\eta(G)$，并研究图操作对标记数的影响。

Result: 证明完全图$K_n$在$n\geq6$时$\eta(K_n)=2$，$n\in\{3,4,5\}$时需3种标记；轮式图$W_n$的标记数渐近于$\sqrt{2n}$。同时构造出标记数任意正整数$n$的图例。

Conclusion: 链接不规则标记理论为图标记问题提供新视角，完全图与轮式图的可标记性得到完整刻画，且标记数存在普适构造。未来可进一步研究复杂图族的标记性质。

Abstract: We introduce the concept of link-irregular labelings for graphs, extending
the notion of link-irregular graphs through edge labeling with positive
integers. A labeling is link-irregular if every vertex has a uniquely labeled
subgraph induced by its neighbors. We establish necessary and sufficient
conditions for the existence of such labelings and define the link-irregular
labeling number $\eta(G)$ as the minimum number of distinct labels required.
Our main results include necessary and sufficient conditions for the existence
of link-irregular labelings. We show that certain families of graphs, such as
bipartite graphs, trees, cycles, hypercubes, and complete multipartite graphs,
do not admit link-irregular labelings, while complete graphs and wheel graphs
do. Specifically, we prove that $\eta(K_n) = 2$ for $n \geq 6$ and $\eta(K_n) =
3$ for $n \in \{3,4,5\}$. For wheel graphs $W_n$, we establish that $\eta(W_n)
\approx \sqrt{2n}$ asymptotically. Finally, we prove that for every positive
integer $n$, there exists a graph with a link-irregular labeling number exactly
$n$, and provide several results on graph operations that preserve labeling
numbers.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [91] [SABR-Informed Multitask Gaussian Process: A Synthetic-to-Real Framework for Implied Volatility Surface Construction](https://arxiv.org/abs/2506.22888)
*Jirong Zhuang,Xuan Wu*

Main category: q-fin.CP

TL;DR: 提出SABR-MTGP方法，结合SABR模型的结构化优势与高斯过程回归的灵活性，通过多任务学习构建隐含波动率曲面，在数据稀疏区域表现优异。


<details>
  <summary>Details</summary>
Motivation: 隐含波动率曲面(IVS)构建面临市场数据稀疏与模型灵活性不足的双重挑战，传统SABR模型可解释性强但缺乏灵活性，纯数据驱动方法对稀疏数据效果不佳。

Method: 采用多任务高斯过程框架，以校准后的SABR模型生成密集合成数据作为源任务，稀疏市场数据作为目标任务，自适应传递结构信息并捕捉任务相关性。

Result: 在Heston模型生成数据及真实SPX市场数据上的实验表明，SABR-MTGP在多种期限结构下均优于标准高斯过程回归和SABR模型，能生成稳定且符合实际的曲面。

Conclusion: 该方法成功平衡了SABR模型的结构指导与市场数据所需的灵活性，为IVS构建提供了兼具理论一致性与实践适应性的解决方案。

Abstract: Constructing the Implied Volatility Surface (IVS) is a challenging task in
quantitative finance due to the complexity of real markets and the sparsity of
market data. Structural models like Stochastic Alpha Beta Rho (SABR) model
offer interpretability and theoretical consistency but lack flexibility, while
purely data-driven methods such as Gaussian Process regression can struggle
with sparse data. We introduce SABR-Informed Multi-Task Gaussian Process
(SABR-MTGP), treating IVS construction as a multi-task learning problem. Our
method uses a dense synthetic dataset from a calibrated SABR model as a source
task to inform the construction based on sparse market data (the target task).
The MTGP framework captures task correlation and transfers structural
information adaptively, improving predictions particularly in data-scarce
regions. Experiments using Heston-generated ground truth data under various
market conditions show that SABR-MTGP outperforms both standard Gaussian
process regression and SABR across different maturities. Furthermore, an
application to real SPX market data demonstrates the method's practical
applicability and its ability to produce stable and realistic surfaces. This
confirms our method balances structural guidance from SABR with the flexibility
needed for market data.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [92] [SABRE-FL: Selective and Accurate Backdoor Rejection for Federated Prompt Learning](https://arxiv.org/abs/2506.22506)
*Momin Ahmad Khan,Yasra Chandio,Fatima Muhammad Anwar*

Main category: cs.CR

TL;DR: 本文首次研究了联邦提示学习中的后门攻击问题，提出了一种轻量级防御方法SABRE-FL，通过嵌入空间异常检测器有效过滤恶意客户端提交的污染提示更新，在保持干净数据准确率的同时显著降低后门攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 联邦提示学习作为高效通信且保护隐私的范式，其安全风险尚未充分探索。研究发现当恶意客户端在输入图像中注入视觉不可察的学习型噪声触发器时，全局提示学习器会产生针对性误分类漏洞。

Method: 提出SABRE-FL防御框架：采用离线训练的嵌入空间异常检测器过滤污染提示更新，无需访问原始客户端数据或标签，具有模块化特性并可泛化至不同数据集。

Result: 在五个数据集和四种基线防御上的实验表明，SABRE-FL能可靠识别恶意客户端，将后门准确率平均降低63.2%，同时保持98.7%的干净数据准确率，显著优于所有基线方法。

Conclusion: 研究揭示了联邦提示学习系统的安全脆弱性，证实基于嵌入空间的检测方法能有效防御后门攻击，强调了未来联邦系统需要更鲁棒的提示学习机制。

Abstract: Federated Prompt Learning has emerged as a communication-efficient and
privacy-preserving paradigm for adapting large vision-language models like CLIP
across decentralized clients. However, the security implications of this setup
remain underexplored. In this work, we present the first study of backdoor
attacks in Federated Prompt Learning. We show that when malicious clients
inject visually imperceptible, learnable noise triggers into input images, the
global prompt learner becomes vulnerable to targeted misclassification while
still maintaining high accuracy on clean inputs. Motivated by this
vulnerability, we propose SABRE-FL, a lightweight, modular defense that filters
poisoned prompt updates using an embedding-space anomaly detector trained
offline on out-of-distribution data. SABRE-FL requires no access to raw client
data or labels and generalizes across diverse datasets. We show, both
theoretically and empirically, that malicious clients can be reliably
identified and filtered using an embedding-based detector. Across five diverse
datasets and four baseline defenses, SABRE-FL outperforms all baselines by
significantly reducing backdoor accuracy while preserving clean accuracy,
demonstrating strong empirical performance and underscoring the need for robust
prompt learning in future federated systems.

</details>


### [93] [In-context learning for the classification of manipulation techniques in phishing emails](https://arxiv.org/abs/2506.22515)
*Antony Dalmiere,Guillaume Auriol,Vincent Nicomette,Pascal Marchand*

Main category: cs.CR

TL;DR: 本研究利用大型语言模型（LLM）的上下文学习（ICL）技术，对基于40种操纵技术分类的网络钓鱼邮件进行细粒度检测，在真实法语钓鱼邮件数据集上取得0.76的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统钓鱼检测常忽略心理操纵手段，本研究旨在探索LLM在识别复杂心理操纵技术方面的潜力。

Method: 采用GPT-4o-mini模型进行少样本学习，基于SignalSpam法语钓鱼邮件数据集，使用人工标注的100封测试邮件进行评估。

Result: 模型能有效识别主流操纵技术（如诱饵、好奇心吸引、小额请求等），准确率达0.76。

Conclusion: 该研究证实了ICL在精细化钓鱼分析中的实用性，并为攻击者策略分析提供了新视角。

Abstract: Traditional phishing detection often overlooks psychological manipulation.
This study investigates using Large Language Model (LLM) In-Context Learning
(ICL) for fine-grained classification of phishing emails based on a taxonomy of
40 manipulation techniques. Using few-shot examples with GPT-4o-mini on
real-world French phishing emails (SignalSpam), we evaluated performance
against a human-annotated test set (100 emails). The approach effectively
identifies prevalent techniques (e.g., Baiting, Curiosity Appeal, Request For
Minor Favor) with a promising accuracy of 0.76. This work demonstrates ICL's
potential for nuanced phishing analysis and provides insights into attacker
strategies.

</details>


### [94] [A Survey on Model Extraction Attacks and Defenses for Large Language Models](https://arxiv.org/abs/2506.22521)
*Kaixiang Zhao,Lincan Li,Kaize Ding,Neil Zhenqiang Gong,Yue Zhao,Yushun Dong*

Main category: cs.CR

TL;DR: 本文综述了针对语言模型的提取攻击与防御方法，提出了分类体系并评估了现有技术的有效性，指出了当前研究的不足与未来方向。


<details>
  <summary>Details</summary>
Motivation: 模型提取攻击严重威胁语言模型的安全，可能侵犯知识产权与用户隐私，亟需系统化研究攻击类型与防御策略。

Method: 建立LLM专用攻击分类体系（功能/训练数据/提示攻击），分析API蒸馏、直接查询、参数恢复等方法；防御机制分为模型保护、数据隐私与提示策略三类。

Result: 提出生成式模型专用的攻防评估指标，揭示现有方法在平衡安全性与模型效用方面的局限性，发现集成攻击与自适应防御的研究潜力。

Conclusion: 该研究为NLP研究者与安全从业者提供系统指导，未来需开发兼顾安全与效用的动态防御方案以应对生产环境威胁。

Abstract: Model extraction attacks pose significant security threats to deployed
language models, potentially compromising intellectual property and user
privacy. This survey provides a comprehensive taxonomy of LLM-specific
extraction attacks and defenses, categorizing attacks into functionality
extraction, training data extraction, and prompt-targeted attacks. We analyze
various attack methodologies including API-based knowledge distillation, direct
querying, parameter recovery, and prompt stealing techniques that exploit
transformer architectures. We then examine defense mechanisms organized into
model protection, data privacy protection, and prompt-targeted strategies,
evaluating their effectiveness across different deployment scenarios. We
propose specialized metrics for evaluating both attack effectiveness and
defense performance, addressing the specific challenges of generative language
models. Through our analysis, we identify critical limitations in current
approaches and propose promising research directions, including integrated
attack methodologies and adaptive defense mechanisms that balance security with
model utility. This work serves NLP researchers, ML engineers, and security
professionals seeking to protect language models in production environments.

</details>


### [95] [MetaCipher: A General and Extensible Reinforcement Learning Framework for Obfuscation-Based Jailbreak Attacks on Black-Box LLMs](https://arxiv.org/abs/2506.22557)
*Boyuan Chen,Minghao Shao,Abdul Basit,Siddharth Garg,Muhammad Shafique*

Main category: cs.CR

TL;DR: 本文提出MetaCipher框架，通过强化学习动态选择加密策略，显著提升大型语言模型(LLM)越狱攻击的成功率，在10次查询内对非推理型LLM达到92%攻击成功率，对推理型LLM达74%。


<details>
  <summary>Details</summary>
Motivation: 现有安全机制无法有效检测加密恶意内容，基于混淆的越狱攻击利用LLM的推理能力破解加密提示，亟需新型防御方案。

Method: 提出模块化框架MetaCipher，结合强化学习的动态密码选择机制，从密码池自适应选择最优加密策略，支持任意密码家族扩展。

Result: 实验显示：在最新恶意提示基准测试中，对非推理型LLM攻击成功率超92%，推理型LLM达74%，优于现有所有混淆攻击方法。

Conclusion: MetaCipher具有长期鲁棒性和适应性，能有效应对不断升级的安全措施，为LLM安全防御提出新挑战。

Abstract: The growing capabilities of large language models (LLMs) have exposed them to
increasingly sophisticated jailbreak attacks. Among these, obfuscation-based
attacks -- which encrypt malicious content to evade detection -- remain highly
effective. By leveraging the reasoning ability of advanced LLMs to interpret
encrypted prompts, such attacks circumvent conventional defenses that rely on
keyword detection or context filtering. These methods are very difficult to
defend against, as existing safety mechanisms are not designed to interpret or
decode ciphered content. In this work, we propose \textbf{MetaCipher}, a novel
obfuscation-based jailbreak framework, along with a reinforcement
learning-based dynamic cipher selection mechanism that adaptively chooses
optimal encryption strategies from a cipher pool. This approach enhances
jailbreak effectiveness and generalizability across diverse task types, victim
LLMs, and safety guardrails. Our framework is modular and extensible by design,
supporting arbitrary cipher families and accommodating evolving adversarial
strategies. We complement our method with a large-scale empirical analysis of
cipher performance across multiple victim LLMs. Within as few as 10 queries,
MetaCipher achieves over 92\% attack success rate (ASR) on most recent standard
malicious prompt benchmarks against state-of-the-art non-reasoning LLMs, and
over 74\% ASR against reasoning-capable LLMs, outperforming all existing
obfuscation-based jailbreak methods. These results highlight the long-term
robustness and adaptability of our approach, making it more resilient than
prior methods in the face of advancing safety measures.

</details>


### [96] [A User-Centric, Privacy-Preserving, and Verifiable Ecosystem for Personal Data Management and Utilization](https://arxiv.org/abs/2506.22606)
*Osama Zafar,Mina Namazi,Yuqiao Xu,Youngjin Yoo,Erman Ayday*

Main category: cs.CR

TL;DR: 本文提出了一种新型的去中心化隐私保护架构，旨在解决集中式个人数据管理带来的隐私和安全问题，赋予用户数据所有权和选择性共享能力。


<details>
  <summary>Details</summary>
Motivation: 当前集中式个人数据管理模式存在隐私泄露、安全漏洞和用户自主权缺失等问题，亟需一种新的方法来安全收集、存储和使用跨领域个人数据。

Method: 采用安全飞地和联邦学习等隐私增强技术，构建支持本地计算、模型训练和隐私保护数据共享的去中心化架构，确保数据可信性和用户隐私。

Result: 该系统实现了对教育证书、健康记录和财务数据等异构个人信息的隐私保护处理，用户可完全掌控数据共享权限。

Conclusion: 该去中心化架构为个人数据管理提供了安全、可控的解决方案，有望在医疗、教育、金融等领域推动隐私保护范式的革新。

Abstract: In the current paradigm of digital personalized services, the centralized
management of personal data raises significant privacy concerns, security
vulnerabilities, and diminished individual autonomy over sensitive information.
Despite their efficiency, traditional centralized architectures frequently fail
to satisfy rigorous privacy requirements and expose users to data breaches and
unauthorized access risks. This pressing challenge calls for a fundamental
paradigm shift in methodologies for collecting, storing, and utilizing personal
data across diverse sectors, including education, healthcare, and finance.
  This paper introduces a novel decentralized, privacy-preserving architecture
that handles heterogeneous personal information, ranging from educational
credentials to health records and financial data. Unlike traditional models,
our system grants users complete data ownership and control, allowing them to
selectively share information without compromising privacy. The architecture's
foundation comprises advanced privacy-enhancing technologies, including secure
enclaves and federated learning, enabling secure computation, verification, and
data sharing. The system supports diverse functionalities, including local
computation, model training, and privacy-preserving data sharing, while
ensuring data credibility and robust user privacy.

</details>


### [97] [Fingerprinting SDKs for Mobile Apps and Where to Find Them: Understanding the Market for Device Fingerprinting](https://arxiv.org/abs/2506.22639)
*Michael A. Specter,Mihai Christodorescu,Abbie Farr,Bo Ma,Robin Lassonde,Xiaoyang Xu,Xiang Pan,Fengguo Wei,Saswat Anand,Dave Kleidermacher*

Main category: cs.CR

TL;DR: 本文对移动应用生态系统中的指纹识别行为进行了大规模分析，发现广告SDK仅占30.56%的指纹行为，而23.92%来自用途不明的SDK，表明仅针对广告领域的反指纹措施效果有限。


<details>
  <summary>Details</summary>
Motivation: 研究动机是揭示移动应用生态系统中第三方SDK的指纹识别行为现状，评估现有隐私保护措施（如苹果的ATT和谷歌的隐私沙盒）的实际效果。

Method: 研究方法包括收集228,000个Maven仓库SDK和178,000个Google Play应用数据，通过静态分析管道检测500多个信号的外泄行为。

Result: 结果显示：广告SDK仅贡献30.56%的指纹行为，23.92%来自未知用途SDK，安全认证类SDK占11.7%。指纹行为涉及的API分布稀疏，仅2%的API被75%以上SDK使用。

Conclusion: 结论指出：仅针对特定领域（如广告）的反指纹策略效果不完整，且由于API使用高度分散，依赖用户权限控制指纹行为存在困难。

Abstract: This paper presents a large-scale analysis of fingerprinting-like behavior in
the mobile application ecosystem. We take a market-based approach, focusing on
third-party tracking as enabled by applications' common use of third-party
SDKs. Our dataset consists of over 228,000 SDKs from popular Maven
repositories, 178,000 Android applications collected from the Google Play
store, and our static analysis pipeline detects exfiltration of over 500
individual signals. To the best of our knowledge, this represents the
largest-scale analysis of SDK behavior undertaken to date.
  We find that Ads SDKs (the ostensible focus of industry efforts such as
Apple's App Tracking Transparency and Google's Privacy Sandbox) appear to be
the source of only 30.56% of the fingerprinting behaviors. A surprising 23.92%
originate from SDKs whose purpose was unknown or unclear. Furthermore, Security
and Authentication SDKs are linked to only 11.7% of likely fingerprinting
instances. These results suggest that addressing fingerprinting solely in
specific market-segment contexts like advertising may offer incomplete benefit.
Enforcing anti-fingerprinting policies is also complex, as we observe a sparse
distribution of signals and APIs used by likely fingerprinting SDKs. For
instance, only 2% of exfiltrated APIs are used by more than 75% of SDKs, making
it difficult to rely on user permissions to control fingerprinting behavior.

</details>


### [98] [VERA: Variational Inference Framework for Jailbreaking Large Language Models](https://arxiv.org/abs/2506.22666)
*Anamika Lochab,Lu Yan,Patrick Pynadath,Xiangyu Zhang,Ruqi Zhang*

Main category: cs.CR

TL;DR: 本文提出VERA框架，通过变分推理方法生成多样化、流畅的越狱提示，有效识别黑盒LLM的漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有黑盒越狱方法依赖遗传算法和手动优化，无法全面评估模型漏洞，亟需更高效的自动化解决方案。

Method: VERA将越狱提示构建为变分推断问题，训练小型攻击者LLM来近似目标模型对对抗性提示的后验分布。

Result: 实验表明VERA能在无需重复优化的情况下，为不同目标LLM生成高效越狱提示，性能显著优于基线方法。

Conclusion: 概率推理框架VERA为对抗性提示生成提供了新范式，证实了变分方法在黑盒安全评估中的价值。

Abstract: The rise of API-only access to state-of-the-art LLMs highlights the need for
effective black-box jailbreak methods to identify model vulnerabilities in
real-world settings. Without a principled objective for gradient-based
optimization, most existing approaches rely on genetic algorithms, which are
limited by their initialization and dependence on manually curated prompt
pools. Furthermore, these methods require individual optimization for each
prompt, failing to provide a comprehensive characterization of model
vulnerabilities. To address this gap, we introduce VERA: Variational infErence
fRamework for jAilbreaking. VERA casts black-box jailbreak prompting as a
variational inference problem, training a small attacker LLM to approximate the
target LLM's posterior over adversarial prompts. Once trained, the attacker can
generate diverse, fluent jailbreak prompts for a target query without
re-optimization. Experimental results show that VERA achieves strong
performance across a range of target LLMs, highlighting the value of
probabilistic inference for adversarial prompt generation.

</details>


### [99] [General Autonomous Cybersecurity Defense: Learning Robust Policies for Dynamic Topologies and Diverse Attackers](https://arxiv.org/abs/2506.22706)
*Arun Ramamurthy,Neil Dhir*

Main category: cs.CR

TL;DR: 本文提出了一种通用自主网络安全防御（GACD）方法，旨在解决现有系统因网络拓扑动态变化导致的适应能力不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有自主网络安全防御（ACD）系统基于网络动态平稳性的假设，难以应对现实世界中网络拓扑的动态变化，导致防御策略泛化能力不足。

Method: 通过探索在动态网络环境中学习通用策略的方法，开发能够适应不同网络拓扑的防御代理（GACD）。

Result: 该方法旨在提升防御代理在非静态网络环境中的适应性和泛化能力，克服现有系统因静态训练环境导致的过拟合问题。

Conclusion: GACD为动态网络环境下的网络安全防御提供了新的研究方向，有望增强防御系统在复杂多变网络中的鲁棒性。

Abstract: In the face of evolving cyber threats such as malware, ransomware and
phishing, autonomous cybersecurity defense (ACD) systems have become essential
for real-time threat detection and response with optional human intervention.
However, existing ACD systems rely on limiting assumptions, particularly the
stationarity of the underlying network dynamics. In real-world scenarios,
network topologies can change due to actions taken by attackers or defenders,
system failures, or time evolution of networks, leading to failures in the
adaptive capabilities of current defense agents. Moreover, many agents are
trained on static environments, resulting in overfitting to specific
topologies, which hampers their ability to generalize to out-of-distribution
network topologies. This work addresses these challenges by exploring methods
for developing agents to learn generalizable policies across dynamic network
environments -- general ACD (GACD).

</details>


### [100] [Kill Two Birds with One Stone! Trajectory enabled Unified Online Detection of Adversarial Examples and Backdoor Attacks](https://arxiv.org/abs/2506.22722)
*Anmin Fu,Fanyu Meng,Huaibing Peng,Hua Ma,Zhi Zhang,Yifeng Zheng,Willy Susilo,Yansong Gao*

Main category: cs.CR

TL;DR: UniGuard是首个能同时检测对抗样本和后门攻击的统一在线检测框架，通过分析深度学习模型中的传播轨迹差异实现高效防御。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法同时应对对抗样本和后门攻击，且攻击在推理阶段会留下可检测的轨迹特征，这为统一检测提供了理论依据。

Method: 将攻击样本的层间传播轨迹视为时间序列信号，结合LSTM和频谱变换放大对抗/良性轨迹的时域细微差异，实现统一检测。

Result: 在图像/文本/音频等多种模态和任务中验证有效，优于ContraNet（对抗检测）和TED（后门检测）等专用SOTA方法。

Conclusion: UniGuard首次实现了对两类攻击的通用防御，其轨迹分析范式为深度学习安全检测开辟了新方向。

Abstract: The proposed UniGuard is the first unified online detection framework capable
of simultaneously addressing adversarial examples and backdoor attacks.
UniGuard builds upon two key insights: first, both AE and backdoor attacks have
to compromise the inference phase, making it possible to tackle them
simultaneously during run-time via online detection. Second, an adversarial
input, whether a perturbed sample in AE attacks or a trigger-carrying sample in
backdoor attacks, exhibits distinctive trajectory signatures from a benign
sample as it propagates through the layers of a DL model in forward inference.
The propagation trajectory of the adversarial sample must deviate from that of
its benign counterpart; otherwise, the adversarial objective cannot be
fulfilled. Detecting these trajectory signatures is inherently challenging due
to their subtlety; UniGuard overcomes this by treating the propagation
trajectory as a time-series signal, leveraging LSTM and spectrum transformation
to amplify differences between adversarial and benign trajectories that are
subtle in the time domain. UniGuard exceptional efficiency and effectiveness
have been extensively validated across various modalities (image, text, and
audio) and tasks (classification and regression), ranging from diverse model
architectures against a wide range of AE attacks and backdoor attacks,
including challenging partial backdoors and dynamic triggers. When compared to
SOTA methods, including ContraNet (NDSS 22) specific for AE detection and TED
(IEEE SP 24) specific for backdoor detection, UniGuard consistently
demonstrates superior performance, even when matched against each method's
strengths in addressing their respective threats-each SOTA fails to parts of
attack strategies while UniGuard succeeds for all.

</details>


### [101] [Convergent Privacy Framework with Contractive GNN Layers for Multi-hop Aggregations](https://arxiv.org/abs/2506.22727)
*Yu Zheng,Chenang Li,Zhou Li,Qingsong Wang*

Main category: cs.CR

TL;DR: 本文提出了一种名为CARIBOU的框架，通过引入收缩图层（CGL）和隐私放大技术，解决了图神经网络（GNN）中差分隐私（DP）成本随层数线性增长的问题，显著提升了隐私与效用的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法在GNN中应用差分隐私时，隐私成本随网络层数线性增长，导致需要添加过多噪声以维持合理的隐私水平，这在需要深层GNN捕捉复杂图交互时尤为严重。

Method: 通过理论分析，利用标准GNN操作的收缩性质，提出收缩图层（CGL）确保理论保证所需的收缩性，同时保持模型效用。CARIBOU框架包含收缩聚合模块、隐私分配模块和隐私审计模块。

Result: 实验表明，CARIBOU显著改善了隐私与效用的权衡，并在隐私审计任务中表现出优越性能。

Conclusion: CARIBOU通过隐私放大技术和收缩图层设计，有效解决了深层GNN中差分隐私成本问题，为图数据隐私保护提供了更优的解决方案。

Abstract: Differential privacy (DP) has been integrated into graph neural networks
(GNNs) to protect sensitive structural information, e.g., edges, nodes, and
associated features across various applications. A common approach is to
perturb the message-passing process, which forms the core of most GNN
architectures. However, existing methods typically incur a privacy cost that
grows linearly with the number of layers (Usenix Security'23), ultimately
requiring excessive noise to maintain a reasonable privacy level. This
limitation becomes particularly problematic when deep GNNs are necessary to
capture complex and long-range interactions in graphs. In this paper, we
theoretically establish that the privacy budget can converge with respect to
the number of layers by applying privacy amplification techniques to the
message-passing process, exploiting the contractive properties inherent to
standard GNN operations. Motivated by this analysis, we propose a simple yet
effective Contractive Graph Layer (CGL) that ensures the contractiveness
required for theoretical guarantees while preserving model utility. Our
framework, CARIBOU, supports both training and inference, equipped with a
contractive aggregation module, a privacy allocation module, and a privacy
auditing module. Experimental evaluations demonstrate that CARIBOU
significantly improves the privacy-utility trade-off and achieves superior
performance in privacy auditing tasks.

</details>


### [102] [Enhancing Android Malware Detection with Retrieval-Augmented Generation](https://arxiv.org/abs/2506.22750)
*Saraga S.,Anagha M. S.,Dincy R. Arikkat,Rafidha Rehiman K. A.,Serena Nicolazzo,Antonino Nocera,Vinod P*

Main category: cs.CR

TL;DR: 本文提出了一种基于机器学习的Android恶意软件检测方法，通过静态分析提取APK特征，并利用LLM生成高级功能描述，结合RAG技术减少幻觉，最终通过Transformer模型提高检测准确率。


<details>
  <summary>Details</summary>
Motivation: Android应用的广泛使用使其成为网络攻击的主要目标，恶意软件威胁用户隐私和设备功能，因此需要有效的检测方法。

Method: 研究通过静态分析提取APK的代码结构、权限和清单文件等特征，利用LLM生成功能描述，并引入RAG技术减少幻觉，最后使用Transformer模型进行分析。

Result: 该方法相比传统的基于特征的恶意软件检测方法，提高了检测准确率。

Conclusion: 结合LLM和RAG技术的静态分析方法能够有效提升Android恶意软件检测的准确性，为安全领域提供了新的解决方案。

Abstract: The widespread use of Android applications has made them a prime target for
cyberattacks, significantly increasing the risk of malware that threatens user
privacy, security, and device functionality. Effective malware detection is
thus critical, with static analysis, dynamic analysis, and Machine Learning
being widely used approaches. In this work, we focus on a Machine
Learning-based method utilizing static features. We first compiled a dataset of
benign and malicious APKs and performed static analysis to extract features
such as code structure, permissions, and manifest file content, without
executing the apps. Instead of relying solely on raw static features, our
system uses an LLM to generate high-level functional descriptions of APKs. To
mitigate hallucinations, which are a known vulnerability of LLM, we integrated
Retrieval-Augmented Generation (RAG), enabling the LLM to ground its output in
relevant context. Using carefully designed prompts, we guide the LLM to produce
coherent function summaries, which are then analyzed using a transformer-based
model, improving detection accuracy over conventional feature-based methods for
malware detection.

</details>


### [103] [What's Privacy Good for? Measuring Privacy as a Shield from Harms due to Personal Data Use](https://arxiv.org/abs/2506.22787)
*Sri Harsha Gajavalli,Junichi Koizumi,Rakibul Hasan*

Main category: cs.CR

TL;DR: 本文提出了一种以伤害为中心的隐私概念化方法，探讨隐私如何防止个人数据使用带来的伤害。通过在线研究，分析了人工智能算法推断个人数据时可能引发的14种伤害，并发现这些伤害在统计上具有内部一致性。研究结果为教育和就业领域的隐私改进提供了实践指导。


<details>
  <summary>Details</summary>
Motivation: 现有隐私框架（如情境完整性）难以捕捉或分类现代技术使用个人数据时产生的多种伤害，因此需要一种新的隐私概念化方法。

Method: 研究通过在线调查，收集了400名大学生对人工智能算法推断个人数据（如人口统计、人格特质、认知障碍）时可能引发的14种伤害的感知。数据基于广泛的文献综述选择。

Result: 统计分析显示，14种伤害具有内部一致性，共同代表了隐私伤害的一般概念。研究还揭示了不同情境和参与者 demographic 因素对伤害感知的细微差异。

Conclusion: 研究不仅深化了对隐私概念的理解，还为教育和就业领域的隐私改进提供了实践指导，强调如何公平地提升隐私保护。

Abstract: We propose a harm-centric conceptualization of privacy that asks: What harms
from personal data use can privacy prevent? The motivation behind this research
is limitations in existing privacy frameworks (e.g., Contextual Integrity) to
capture or categorize many of the harms that arise from modern technology's use
of personal data. We operationalize this conceptualization in an online study
with 400 college and university students. Study participants indicated their
perceptions of different harms (e.g., manipulation, discrimination, and
harassment) that may arise when artificial intelligence-based algorithms infer
personal data (e.g., demographics, personality traits, and cognitive
disability) and use it to identify students who are likely to drop out of a
course or the best job candidate. The study includes 14 harms and six types of
personal data selected based on an extensive literature review.
  Comprehensive statistical analyses of the study data show that the 14 harms
are internally consistent and collectively represent a general notion of
privacy harms. The study data also surfaces nuanced perceptions of harms, both
across the contexts and participants' demographic factors. Based on these
results, we discuss how privacy can be improved equitably. Thus, this research
not only contributes to enhancing the understanding of privacy as a concept but
also provides practical guidance to improve privacy in the context of education
and employment.

</details>


### [104] [Efficient Cybersecurity Assessment Using SVM and Fuzzy Evidential Reasoning for Resilient Infrastructure](https://arxiv.org/abs/2506.22938)
*Zaydon L. Ali,Wassan Saad Abduljabbar Hayale,Israa Ibraheem Al_Barazanchi,Ravi Sekhar,Pritesh Shah,Sushma Parihar*

Main category: cs.CR

TL;DR: 本文提出了一种基于支持向量机（SVM）和模糊证据推理（ER）的安全评估模型，用于快速准确地识别加密算法的安全性。


<details>
  <summary>Details</summary>
Motivation: 随着数字信息隐私问题的日益突出，现有安全协议的脆弱性成为主要威胁。传统方法逐一测试算法效率低下，亟需一种快速精准的评估手段。

Method: 通过构建包含对比度、同质性等安全要素的数据集，结合SVM分类和模糊ER方法，建立系统性风险评估框架。

Result: 模型通过召回率、F1分数和准确率等指标验证，能有效处理多维度安全评估数据。

Conclusion: 该框架为加密技术安全评估提供了自动化解决方案，显著提升了分析效率与系统性。

Abstract: With current advancement in hybermedia knowledges, the privacy of digital
information has developed a critical problem. To overawed the susceptibilities
of present security protocols, scholars tend to focus mainly on efforts on
alternation of current protocols. Over past decade, various proposed encoding
models have been shown insecurity, leading to main threats against significant
data. Utilizing the suitable encryption model is very vital means of guard
against various such, but algorithm is selected based on the dependency of data
which need to be secured. Moreover, testing potentiality of the security
assessment one by one to identify the best choice can take a vital time for
processing. For faster and precisive identification of assessment algorithm, we
suggest a security phase exposure model for cipher encryption technique by
invoking Support Vector Machine (SVM). In this work, we form a dataset using
usual security components like contrast, homogeneity. To overcome the
uncertainty in analysing the security and lack of ability of processing data to
a risk assessment mechanism. To overcome with such complications, this paper
proposes an assessment model for security issues using fuzzy evidential
reasoning (ER) approaches. Significantly, the model can be utilised to process
and assemble risk assessment data on various aspects in systematic ways. To
estimate the performance of our framework, we have various analyses like,
recall, F1 score and accuracy.

</details>


### [105] [A Study on Semi-Supervised Detection of DDoS Attacks under Class Imbalance](https://arxiv.org/abs/2506.22949)
*Ehsan Hallaji,Vaishnavi Shanmugam,Roozbeh Razavi-Far,Mehrdad Saif*

Main category: cs.CR

TL;DR: 研究探讨了半监督学习(SSL)技术在数据不平衡和部分标记情况下提升DDoS攻击检测的效果，评估了13种先进SSL算法在不同场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 网络安全中消除分布式拒绝服务(DDoS)攻击是重大挑战，由于真实数据集的类别不平衡和标记样本不足，利用人工智能自动化这一任务十分复杂。

Method: 研究评估了13种先进的半监督学习(SSL)算法在多种场景下检测DDoS攻击的能力，包括极端环境下的表现。

Result: 研究结果揭示了SSL算法在数据不平衡和部分标记情况下的实际效能与局限性，为设计鲁棒的入侵检测系统(IDS)提供了见解。

Conclusion: 该研究为设计能够应对类别不平衡和处理部分标记数据的智能入侵检测系统(IDS)提供了重要参考。

Abstract: One of the most difficult challenges in cybersecurity is eliminating
Distributed Denial of Service (DDoS) attacks. Automating this task using
artificial intelligence is a complex process due to the inherent class
imbalance and lack of sufficient labeled samples of real-world datasets. This
research investigates the use of Semi-Supervised Learning (SSL) techniques to
improve DDoS attack detection when data is imbalanced and partially labeled. In
this process, 13 state-of-the-art SSL algorithms are evaluated for detecting
DDoS attacks in several scenarios. We evaluate their practical efficacy and
shortcomings, including the extent to which they work in extreme environments.
The results will offer insight into designing intelligent Intrusion Detection
Systems (IDSs) that are robust against class imbalance and handle partially
labeled data.

</details>


### [106] [Equivalence Classes in AES -- Part 1](https://arxiv.org/abs/2506.23050)
*David Cornwell*

Main category: cs.CR

TL;DR: 研究AES中由MixColumns和InvMixColumns操作自然产生的等价类特性，探索这些操作对等价类的影响，并计划利用已知的（明文、密文）等价类对进行密钥恢复攻击。


<details>
  <summary>Details</summary>
Motivation: 探讨AES加密算法中MixColumns和InvMixColumns操作引入的等价类特性，以理解其对加密过程的影响，并探索潜在的密钥恢复攻击方法。

Method: 分析SubBytes、ShiftRows、MixColumns和AddRoundKey操作对等价类的影响，研究输入输出字节XOR相等的特性。

Result: 发现MixColumns和InvMixColumns操作会形成特定的等价类，这些等价类在加密过程中保持某些不变性。

Conclusion: 下一步研究将聚焦于利用已知的（明文、密文）等价类对开发密钥恢复攻击，以进一步验证等价类在AES安全性中的作用。

Abstract: We investigate properties of equivalence classes in AES which arise naturally
from properties of MixColumns and InvMixColumns. These two operations have the
property that the XOR of the 4 input bytes equals the XOR of 4 output bytes. We
examine the effect on equivalence classes due to the operation of SubBytes,
ShiftRows, MixColumns and AddRoundKey. The next phase of research is to find a
key recovery attack using known (plaintext, ciphertext) equivalence class
pairs.
  Keywords: AES, Equivalence, Class, MixColumns, ShiftRows, SubBytes,
AddRoundKey, Schedule, State, XOR

</details>


### [107] [A Practical and Secure Byzantine Robust Aggregator](https://arxiv.org/abs/2506.23183)
*De Zhang Lee,Aashish Kolluri,Prateek Saxena,Ee-Chien Chang*

Main category: cs.CR

TL;DR: 本文提出了一种在机器学习安全领域中高效且近乎最优的鲁棒聚合算法，用于在存在$\epsilon$比例恶意向量的情况下计算稳健平均值，无需预先了解干净向量的分布或设置过滤阈值。


<details>
  <summary>Details</summary>
Motivation: 在机器学习安全中，数据投毒攻击会产生异常梯度向量，污染模型训练过程。传统的鲁棒聚合方法需要预先了解干净向量的分布或设置阈值，限制了其实际应用。

Method: 提出首个准线性时间复杂度的鲁棒聚合算法，无需预先了解干净向量分布或计算过滤阈值，可直接应用于标准神经网络训练流程。

Result: 实验证实该算法具有预期的高效运行时间，并能有效抵消10种不同的机器学习投毒攻击。

Conclusion: 该算法为机器学习安全提供了一种实用且高效的防御工具，能够在对抗性环境中保障模型训练的稳健性。

Abstract: In machine learning security, one is often faced with the problem of removing
outliers from a given set of high-dimensional vectors when computing their
average. For example, many variants of data poisoning attacks produce gradient
vectors during training that are outliers in the distribution of clean
gradients, which bias the computed average used to derive the ML model.
Filtering them out before averaging serves as a generic defense strategy.
Byzantine robust aggregation is an algorithmic primitive which computes a
robust average of vectors, in the presence of an $\epsilon$ fraction of vectors
which may have been arbitrarily and adaptively corrupted, such that the
resulting bias in the final average is provably bounded.
  In this paper, we give the first robust aggregator that runs in quasi-linear
time in the size of input vectors and provably has near-optimal bias bounds.
Our algorithm also does not assume any knowledge of the distribution of clean
vectors, nor does it require pre-computing any filtering thresholds from it.
This makes it practical to use directly in standard neural network training
procedures. We empirically confirm its expected runtime efficiency and its
effectiveness in nullifying 10 different ML poisoning attacks.

</details>


### [108] [From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows](https://arxiv.org/abs/2506.23260)
*Mohamed Amine Ferrag,Norbert Tihanyi,Djallel Hamouda,Leandros Maglaras,Merouane Debbah*

Main category: cs.CR

TL;DR: 本文首次提出针对LLM智能体生态系统的端到端威胁模型，涵盖四大攻击领域，系统化分析了30余种攻击技术，并为构建安全防御机制提供研究方向和最佳实践。


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能体插件和协议的爆炸式增长，其安全机制未能同步发展，导致系统面临多样化威胁，亟需建立统一的威胁模型和防御框架。

Method: 通过将威胁模型划分为输入操纵、模型渗透、系统隐私攻击和协议漏洞四大领域，对每类攻击技术进行场景分析、可行性评估和防御措施审查。

Result: 构建了包含30余种攻击技术的分类体系，发现现有防御存在不足，提出动态信任管理、加密溯源等关键研究方向。

Conclusion: 该研究为LLM智能体工作流提供了全面的安全参考框架，对设计鲁棒防御机制和建立弹性多智能体系统具有指导意义。

Abstract: Autonomous AI agents powered by large language models (LLMs) with structured
function-calling interfaces have dramatically expanded capabilities for
real-time data retrieval, complex computation, and multi-step orchestration.
Yet, the explosive proliferation of plugins, connectors, and inter-agent
protocols has outpaced discovery mechanisms and security practices, resulting
in brittle integrations vulnerable to diverse threats. In this survey, we
introduce the first unified, end-to-end threat model for LLM-agent ecosystems,
spanning host-to-tool and agent-to-agent communications, formalize adversary
capabilities and attacker objectives, and catalog over thirty attack
techniques. Specifically, we organized the threat model into four domains:
Input Manipulation (e.g., prompt injections, long-context hijacks, multimodal
adversarial inputs), Model Compromise (e.g., prompt- and parameter-level
backdoors, composite and encrypted multi-backdoors, poisoning strategies),
System and Privacy Attacks (e.g., speculative side-channels, membership
inference, retrieval poisoning, social-engineering simulations), and Protocol
Vulnerabilities (e.g., exploits in Model Context Protocol (MCP), Agent
Communication Protocol (ACP), Agent Network Protocol (ANP), and Agent-to-Agent
(A2A) protocol). For each category, we review representative scenarios, assess
real-world feasibility, and evaluate existing defenses. Building on our threat
taxonomy, we identify key open challenges and future research directions, such
as securing MCP deployments through dynamic trust management and cryptographic
provenance tracking; designing and hardening Agentic Web Interfaces; and
achieving resilience in multi-agent and federated environments. Our work
provides a comprehensive reference to guide the design of robust defense
mechanisms and establish best practices for resilient LLM-agent workflows.

</details>


### [109] [Threshold Signatures for Central Bank Digital Currencies](https://arxiv.org/abs/2506.23294)
*Mostafa Abdelrahman,Filip Rezabek,Lars Hupel,Kilian Glas,Georg Carle*

Main category: cs.CR

TL;DR: 本文探讨了在央行数字货币（CBDC）中使用阈值签名方案（TSS）以增强安全性，同时保持可接受的性能。


<details>
  <summary>Details</summary>
Motivation: CBDC依赖数字签名确保交易真实性和完整性，但私钥泄露会导致严重问题。研究旨在通过TSS分散密钥管理和签名，降低密钥泄露风险。

Method: 以Filia CBDC方案为基础，重点评估基于ECDSA的TSS及其支持库，分析计算与通信复杂度、吞吐量和端到端交易延迟。

Result: 性能评估表明，TSS能有效提升CBDC实施的安全性，且在实际部署中保持可接受的性能水平。

Conclusion: TSS技术可平衡CBDC的安全需求与性能要求，为实际应用提供可行解决方案。

Abstract: Digital signatures are crucial for securing Central Bank Digital Currencies
(CBDCs) transactions. Like most forms of digital currencies, CBDC solutions
rely on signatures for transaction authenticity and integrity, leading to major
issues in the case of private key compromise. Our work explores threshold
signature schemes (TSSs) in the context of CBDCs. TSSs allow distributed key
management and signing, reducing the risk of a compromised key. We analyze
CBDC-specific requirements, considering the applicability of TSSs, and use
Filia CBDC solution as a base for a detailed evaluation. As most of the current
solutions rely on ECDSA for compatibility, we focus on ECDSA-based TSSs and
their supporting libraries. Our performance evaluation measured the
computational and communication complexity across key processes, as well as the
throughput and latency of end-to-end transactions. The results confirm that TSS
can enhance the security of CBDC implementations while maintaining acceptable
performance for real-world deployments.

</details>


### [110] [Securing AI Systems: A Guide to Known Attacks and Impacts](https://arxiv.org/abs/2506.23296)
*Naoto Kiribuchi,Kengo Zenitani,Takayuki Semitsu*

Main category: cs.CR

TL;DR: 本文综述了针对预测性和生成性AI系统的独特对抗攻击，识别了11种主要攻击类型，并将攻击技术与对机密性、完整性和可用性（CIA）安全三要素的影响联系起来，旨在提升AI系统的整体安全防护能力。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术嵌入信息系统，其面临利用AI特有漏洞的安全威胁。本文旨在为非AI安全专家提供基础知识，帮助他们识别AI特有风险并实施有效防御。

Method: 通过系统梳理，识别了11种主要攻击类型，并明确将攻击技术与其对CIA安全三要素（机密性、完整性、可用性）的影响联系起来，包括信息泄露、系统破坏和资源耗尽等。

Result: 研究为研究人员、开发者、安全从业者和政策制定者提供了对抗攻击的全面视角，帮助他们理解AI系统的安全漏洞及其潜在影响。

Conclusion: 本文通过系统分析AI特有安全威胁，为提升AI系统的整体安全防护能力提供了基础知识和实用指导，有助于推动AI技术的安全应用。

Abstract: Embedded into information systems, artificial intelligence (AI) faces
security threats that exploit AI-specific vulnerabilities. This paper provides
an accessible overview of adversarial attacks unique to predictive and
generative AI systems. We identify eleven major attack types and explicitly
link attack techniques to their impacts -- including information leakage,
system compromise, and resource exhaustion -- mapped to the confidentiality,
integrity, and availability (CIA) security triad. We aim to equip researchers,
developers, security practitioners, and policymakers, even those without
specialized AI security expertise, with foundational knowledge to recognize
AI-specific risks and implement effective defenses, thereby enhancing the
overall security posture of AI systems.

</details>


### [111] [Interpretable by Design: MH-AutoML for Transparent and Efficient Android Malware Detection without Compromising Performance](https://arxiv.org/abs/2506.23314)
*Joner Assolin,Gabriel Canto,Diego Kreutz,Eduardo Feitosa,Hendrio Bragança,Angelo Nogueira,Vanderson Rocha*

Main category: cs.CR

TL;DR: 本文提出MH-AutoML框架，针对安卓恶意软件检测领域，通过自动化机器学习流程并增强可解释性，在保持计算效率的同时实现了优于主流AutoML工具的召回率。


<details>
  <summary>Details</summary>
Motivation: 现有AutoML方案在安卓恶意软件检测中存在黑箱操作、可解释性差及实验追溯困难等问题，亟需开发兼具自动化与透明度的领域专用框架。

Method: MH-AutoML实现了端到端自动化机器学习流程（数据预处理、特征工程、算法选择、超参数调优），并集成可解释性分析、调试和实验追踪模块。

Result: 在对比Auto-Sklearn等7种主流框架的实验中，MH-AutoML展现出更高的召回率（提升约3-5%）及显著的可解释性优势，同时保持相当的计算效率。

Conclusion: 该框架为网络安全领域提供了性能与可解释性兼备的解决方案，其领域定制化设计模式对AutoML在专业场景的应用具有示范意义。

Abstract: Malware detection in Android systems requires both cybersecurity expertise
and machine learning (ML) techniques. Automated Machine Learning (AutoML) has
emerged as an approach to simplify ML development by reducing the need for
specialized knowledge. However, current AutoML solutions typically operate as
black-box systems with limited transparency, interpretability, and experiment
traceability. To address these limitations, we present MH-AutoML, a
domain-specific framework for Android malware detection. MH-AutoML automates
the entire ML pipeline, including data preprocessing, feature engineering,
algorithm selection, and hyperparameter tuning. The framework incorporates
capabilities for interpretability, debugging, and experiment tracking that are
often missing in general-purpose solutions. In this study, we compare MH-AutoML
against seven established AutoML frameworks: Auto-Sklearn, AutoGluon, TPOT,
HyperGBM, Auto-PyTorch, LightAutoML, and MLJAR. Results show that MH-AutoML
achieves better recall rates while providing more transparency and control. The
framework maintains computational efficiency comparable to other solutions,
making it suitable for cybersecurity applications where both performance and
explainability matter.

</details>


### [112] [All Proof of Work But No Proof of Play](https://arxiv.org/abs/2506.23435)
*Hayder Tirmazi*

Main category: cs.CR

TL;DR: 本文探讨了如何通过密码学方法验证游戏速通记录的真实性，尽管最终未能成功，但揭示了在不可信环境中验证实时交互输入的困难。


<details>
  <summary>Details</summary>
Motivation: 速通比赛（如《毁灭战士》1993）需要验证玩家提交记录的真实性。传统方法依赖人工观察或游戏机制分析，但缺乏密码学保障。受达克效应启发，作者尝试构建密码学验证系统。

Method: 作者尝试设计多种密码学方案来证明速通记录的真实性，并详细记录了每种方案的规避方法。

Result: 所有尝试的方案均告失败，揭示了签名方案、游戏完整性和可验证玩法在实时交互验证中的局限性。

Conclusion: 研究表明，在不可信环境中验证人类实时交互输入极具挑战性，现有密码学工具难以满足需求，这为未来研究指明了方向。

Abstract: Speedrunning is a competition that emerged from communities of early video
games such as Doom (1993). Speedrunners try to finish a game in minimal time.
Provably verifying the authenticity of submitted speedruns is an open problem.
Traditionally, best-effort speedrun verification is conducted by on-site human
observers, forensic audio analysis, or a rigorous mathematical analysis of the
game mechanics. Such methods are tedious, fallible, and, perhaps worst of all,
not cryptographic. Motivated by naivety and the Dunning-Kruger effect, we
attempt to build a system that cryptographically proves the authenticity of
speedruns. This paper describes our attempted solutions and ways to circumvent
them. Through a narration of our failures, we attempt to demonstrate the
difficulty of authenticating live and interactive human input in untrusted
environments, as well as the limits of signature schemes, game integrity, and
provable play.

</details>


### [113] [A Large-Scale Evolvable Dataset for Model Context Protocol Ecosystem and Security Analysis](https://arxiv.org/abs/2506.23474)
*Zhiwei Lin,Bonan Ruan,Jiahao Liu,Weibo Zhao*

Main category: cs.CR

TL;DR: 本文介绍了MCPCorpus，一个包含约1.4万个MCP服务器和300个MCP客户端的大规模数据集，用于标准化研究语言模型与外部工具的连接接口。


<details>
  <summary>Details</summary>
Motivation: 随着MCP生态系统的快速扩展，缺乏对现有MCP构件的结构化、全面视图给研究带来了挑战。

Method: 通过收集和标注大量MCP构件（每个构件包含20多个标准化属性），并提供自动化数据同步、规范化和检查工具，以及基于网络的轻量级搜索界面。

Result: MCPCorpus提供了MCP生态系统的可重现快照，支持对采用趋势、生态系统健康和实现多样性的研究。

Conclusion: MCPCorpus为研究社区提供了一个公开可用的资源，有助于跟踪和理解MCP生态系统的快速演变。

Abstract: The Model Context Protocol (MCP) has recently emerged as a standardized
interface for connecting language models with external tools and data. As the
ecosystem rapidly expands, the lack of a structured, comprehensive view of
existing MCP artifacts presents challenges for research. To bridge this gap, we
introduce MCPCorpus, a large-scale dataset containing around 14K MCP servers
and 300 MCP clients. Each artifact is annotated with 20+ normalized attributes
capturing its identity, interface configuration, GitHub activity, and metadata.
MCPCorpus provides a reproducible snapshot of the real-world MCP ecosystem,
enabling studies of adoption trends, ecosystem health, and implementation
diversity. To keep pace with the rapid evolution of the MCP ecosystem, we
provide utility tools for automated data synchronization, normalization, and
inspection. Furthermore, to support efficient exploration and exploitation, we
release a lightweight web-based search interface. MCPCorpus is publicly
available at: https://github.com/Snakinya/MCPCorpus.

</details>


### [114] [Detect \& Score: Privacy-Preserving Misbehaviour Detection and Contribution Evaluation in Federated Learning](https://arxiv.org/abs/2506.23583)
*Marvin Xhemrishi,Alexandre Graell i Amat,Balázs Pejó*

Main category: cs.CR

TL;DR: 结合QI和FedGT的优势，提出了一种同时实现恶意行为检测和贡献评估的联邦学习方法。


<details>
  <summary>Details</summary>
Motivation: 安全聚合的联邦学习虽然保护了客户数据隐私，但增加了恶意行为检测和贡献评估的难度。现有方法QI和FedGT分别存在检测精度不足和缺乏贡献评估能力的问题。

Method: 整合QI和FedGT的方法，利用QI的贡献评估能力和FedGT的恶意行为检测能力，实现两者的优势互补。

Result: 实验表明，结合方法在恶意行为检测和贡献评估方面均优于单独使用QI或FedGT。

Conclusion: 通过融合QI和FedGT，本研究成功实现了联邦学习中既鲁棒的恶意行为检测又准确的贡献评估。

Abstract: Federated learning with secure aggregation enables private and collaborative
learning from decentralised data without leaking sensitive client information.
However, secure aggregation also complicates the detection of malicious client
behaviour and the evaluation of individual client contributions to the
learning. To address these challenges, QI (Pejo et al.) and FedGT (Xhemrishi et
al.) were proposed for contribution evaluation (CE) and misbehaviour detection
(MD), respectively. QI, however, lacks adequate MD accuracy due to its reliance
on the random selection of clients in each training round, while FedGT lacks
the CE ability. In this work, we combine the strengths of QI and FedGT to
achieve both robust MD and accurate CE. Our experiments demonstrate superior
performance compared to using either method independently.

</details>


### [115] [Cybersecurity AI: The Dangerous Gap Between Automation and Autonomy](https://arxiv.org/abs/2506.23592)
*Víctor Mayoral-Vilches*

Main category: cs.CR

TL;DR: 网络安全领域存在对AI能力的误解，当前"自主"系统实际处于半自主水平（3-4级），需建立明确分级标准并保持人机协作。


<details>
  <summary>Details</summary>
Motivation: 针对行业混淆"自动化"与"自主性"AI的现象，为避免过度依赖导致监管漏洞，需明确界定网络安全AI的能力等级。

Method: 借鉴机器人学原则，建立6级分类法（0-5级）区分自动化与自主性，分析现有渗透测试工具的实际能力等级。

Result: 当前所谓"自主"渗透工具仅达3-4级：能执行复杂攻击链，但边界案例和战略决策仍需人工审核，真正的5级自主尚未实现。

Conclusion: 应规范术语使用、公开透明披露AI能力，构建人机协作而非替代的关系，防止因误判自主性而引发新的安全漏洞。

Abstract: The cybersecurity industry combines "automated" and "autonomous" AI, creating
dangerous misconceptions about system capabilities. Recent milestones like XBOW
topping HackerOne's leaderboard showcase impressive progress, yet these systems
remain fundamentally semi-autonomous--requiring human oversight. Drawing from
robotics principles, where the distinction between automation and autonomy is
well-established, I take inspiration from prior work and establish a 6-level
taxonomy (Level 0-5) distinguishing automation from autonomy in Cybersecurity
AI. Current "autonomous" pentesters operate at Level 3-4: they execute complex
attack sequences but need human review for edge cases and strategic decisions.
True Level 5 autonomy remains aspirational. Organizations deploying
mischaracterized "autonomous" tools risk reducing oversight precisely when it's
most needed, potentially creating new vulnerabilities. The path forward
requires precise terminology, transparent capabilities disclosure, and human-AI
partnership-not replacement.

</details>


### [116] [SoK: Semantic Privacy in Large Language Models](https://arxiv.org/abs/2506.23603)
*Baihe Ma,Yanna Jiang,Xu Wang,Guangshen Yu,Qin Wang,Caijun Sun,Chen Li,Xuelei Qi,Ying He,Wei Ni,Ren Ping Liu*

Main category: cs.CR

TL;DR: 本文系统化研究了大型语言模型(LLM)中的语义隐私风险，提出了生命周期分析框架，评估现有防御措施的不足，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在敏感领域的广泛应用，传统数据隐私保护方法无法应对隐式、上下文或可推断的语义隐私风险，亟需系统性研究。

Method: 建立以生命周期为中心的分析框架，涵盖输入处理、预训练、微调和对齐阶段，分类攻击向量并评估差分隐私、嵌入加密等现有防御技术。

Result: 发现当前防护在语义层面存在重大缺口，特别是针对上下文推理和潜在表征泄露的防御不足，量化语义泄漏等核心挑战尚未解决。

Conclusion: 提出未来研究方向包括：量化语义泄漏、保护多模态输入、平衡去标识化与生成质量、确保隐私执行的透明度，为LLM设计语义感知的隐私保护技术提供指导。

Abstract: As Large Language Models (LLMs) are increasingly deployed in sensitive
domains, traditional data privacy measures prove inadequate for protecting
information that is implicit, contextual, or inferable - what we define as
semantic privacy. This Systematization of Knowledge (SoK) introduces a
lifecycle-centric framework to analyze how semantic privacy risks emerge across
input processing, pretraining, fine-tuning, and alignment stages of LLMs. We
categorize key attack vectors and assess how current defenses, such as
differential privacy, embedding encryption, edge computing, and unlearning,
address these threats. Our analysis reveals critical gaps in semantic-level
protection, especially against contextual inference and latent representation
leakage. We conclude by outlining open challenges, including quantifying
semantic leakage, protecting multimodal inputs, balancing de-identification
with generation quality, and ensuring transparency in privacy enforcement. This
work aims to inform future research on designing robust, semantically aware
privacy-preserving techniques for LLMs.

</details>


### [117] [Privacy-Preserving Federated Learning Scheme with Mitigating Model Poisoning Attacks: Vulnerabilities and Countermeasures](https://arxiv.org/abs/2506.23622)
*Jiahui Wu,Fucai Luo,Tiecheng Sun,Haiyan Wang,Weizhe Zhang*

Main category: cs.CR

TL;DR: 本文提出了一种增强型隐私保护与拜占庭鲁棒的联邦学习方案（PBFL），通过双陷门全同态加密、安全归一化判断和安全余弦相似度测量，解决了现有方案在模型投毒攻击下的隐私泄露问题，并在非独立同分布数据集中验证了其高效性与安全性。


<details>
  <summary>Details</summary>
Motivation: 现有基于双诚实但好奇且不共谋服务器的隐私保护联邦学习方案在面临恶意用户的模型投毒攻击时，仍存在隐私泄露问题。研究发现，防御模型投毒攻击的隐私计算过程会意外向其中一个服务器暴露用户梯度明文。

Method: 方案包含三个核心组件：1) 双陷门全同态加密（FHE）增强用户隐私保护；2) 新型安全归一化判断方法预防梯度投毒；3) 创新的安全余弦相似度测量方法在不泄露数据隐私的前提下检测模型投毒攻击。

Result: 理论分析证实了方案的安全性与高效性，实验表明其能加速训练并降低通信开销。在非独立同分布（non-IID）数据场景下，方案仍能有效保障隐私并抵抗模型投毒攻击。

Conclusion: PBFL方案在隐私保护与抗模型投毒攻击方面均优于现有方案，尤其适用于数据异构的联邦学习场景，为安全高效的分布式机器学习提供了新思路。

Abstract: The privacy-preserving federated learning schemes based on the setting of two
honest-but-curious and non-colluding servers offer promising solutions in terms
of security and efficiency. However, our investigation reveals that these
schemes still suffer from privacy leakage when considering model poisoning
attacks from malicious users. Specifically, we demonstrate that the
privacy-preserving computation process for defending against model poisoning
attacks inadvertently leaks privacy to one of the honest-but-curious servers,
enabling it to access users' gradients in plaintext. To address both privacy
leakage and model poisoning attacks, we propose an enhanced privacy-preserving
and Byzantine-robust federated learning (PBFL) scheme, comprising three
components: (1) a two-trapdoor fully homomorphic encryption (FHE) scheme to
bolster users' privacy protection; (2) a novel secure normalization judgment
method to preemptively thwart gradient poisoning; and (3) an innovative secure
cosine similarity measurement method for detecting model poisoning attacks
without compromising data privacy. Our scheme guarantees privacy preservation
and resilience against model poisoning attacks, even in scenarios with
heterogeneous, non-IID (Independently and Identically Distributed) datasets.
Theoretical analyses substantiate the security and efficiency of our scheme,
and extensive experiments corroborate the efficacy of our private attacks.
Furthermore, the experimental results demonstrate that our scheme accelerates
training speed while reducing communication overhead compared to the
state-of-the-art PBFL schemes.

</details>


### [118] [gMBA: Expression Semantic Guided Mixed Boolean-Arithmetic Deobfuscation Using Transformer Architectures](https://arxiv.org/abs/2506.23634)
*Youjeong Noh,Joon-Young Paik,Jingun Kwon,Eun-Sun Cho*

Main category: cs.CR

TL;DR: 提出基于真值表的语义引导框架gMBA，通过Transformer架构改进混合布尔算术表达式反混淆，显著提升还原效果。


<details>
  <summary>Details</summary>
Motivation: 混合布尔算术混淆(MBA)被恶意软件滥用，传统方法忽视表达式内部语义信息，导致反混淆效果不佳。

Method: 1) 自动构建真值表捕捉表达式语义 2) 设计可扩展的gMBA框架，改造Transformer编码器-解码器结构集成语义引导。

Result: 实验表明语义信息集成显著提升性能，证实内部语义对还原混淆代码的关键作用。

Conclusion: 真值表语义表征与神经架构结合为MBA反混淆提供新范式，突显表达式语义分析的重要性。

Abstract: Mixed Boolean-Arithmetic (MBA) obfuscation protects intellectual property by
converting programs into forms that are more complex to analyze. However, MBA
has been increasingly exploited by malware developers to evade detection and
cause significant real-world problems. Traditional MBA deobfuscation methods
often consider these expressions as part of a black box and overlook their
internal semantic information. To bridge this gap, we propose a truth table,
which is an automatically constructed semantic representation of an
expression's behavior that does not rely on external resources. The truth table
is a mathematical form that represents the output of expression for all
possible combinations of input. We also propose a general and extensible guided
MBA deobfuscation framework (gMBA) that modifies a Transformer-based neural
encoder-decoder Seq2Seq architecture to incorporate this semantic guidance.
Experimental results and in-depth analysis show that integrating expression
semantics significantly improves performance and highlights the importance of
internal semantic expressions in recovering obfuscated code to its original
form.

</details>


### [119] [Not quite a piece of CHERI-cake: Are new digital security by design architectures usable?](https://arxiv.org/abs/2506.23682)
*Maysara Alhindi,Joseph Hallett*

Main category: cs.CR

TL;DR: 研究探讨了开发者在使用CHERI架构时遇到的挑战，包括警告显示和文档不足的问题。


<details>
  <summary>Details</summary>
Motivation: CHERI架构虽能防止内存安全错误，但改变了C语言和指针等基础类型的实现方式，需了解开发者适应这些变化的体验。

Method: 通过进行可用性研究，观察开发者在将软件移植到CHERI架构时的反应和遇到的问题。

Result: 开发者对CHERI的警告和错误显示感到困惑，且缺乏多样化的文档支持。

Conclusion: CHERI架构在安全性方面有优势，但在开发者体验和文档支持方面仍需改进。

Abstract: A digital security-by-design computer architecture, like CHERI, lets you
program without fear of buffer overflows or other memory safety errors, but
CHERI also rewrites some of the assumptions about how C works and how
fundamental types (such as pointers) are implemented in hardware. We conducted
a usability study to examine how developers react to the changes required by
CHERI when porting software to run on it. We find that developers struggle with
CHERI's display of warnings and errors and a lack of diverse documentation.

</details>


### [120] [Threadbox: Sandboxing for Modular Security](https://arxiv.org/abs/2506.23683)
*Maysara Alhindi,Joseph Hallett*

Main category: cs.CR

TL;DR: 本文提出Threadbox，一种新型沙盒机制，支持模块化和独立沙盒，可应用于线程和特定函数，解决了现有沙盒机制难以适用于某些应用的问题。


<details>
  <summary>Details</summary>
Motivation: 现有操作系统提供的沙盒机制在限制应用资源访问时，常需开发者重构代码以适应沙盒模型，导致某些应用难以应用现有沙盒机制。

Method: 提出Threadbox沙盒机制，支持模块化和独立沙盒，可针对线程和特定函数进行沙盒化，并通过案例研究验证其适用性。

Result: Threadbox机制在实际应用中展示了其灵活性和适用性，能够有效沙盒化线程和特定函数，但也存在一定局限性。

Conclusion: Threadbox为沙盒机制提供了一种新的思路，支持模块化和独立沙盒，适用于线程和特定函数，但其局限性仍需进一步研究和改进。

Abstract: There are many sandboxing mechanisms provided by operating systems to limit
what resources applications can access, however, sometimes the use of these
mechanisms requires developers to refactor their code to fit the sandboxing
model. In this work, we investigate what makes existing sandboxing mechanisms
challenging to apply to certain types of applications, and propose Threadbox, a
sandboxing mechanism that enables having modular and independent sandboxes, and
can be applied to threads and sandbox specific functions. We present case
studies to illustrate the applicability of the idea and discuss its
limitations.

</details>


### [121] [Breaking Out from the TESSERACT: Reassessing ML-based Malware Detection under Spatio-Temporal Drift](https://arxiv.org/abs/2506.23814)
*Theo Chow,Mario D'Onghia,Lorenz Linhardt,Zeliang Kan,Daniel Arp,Lorenzo Cavallaro,Fabio Pierazzi*

Main category: cs.CR

TL;DR: 本文揭示了在相同时间范围内，基于学习的安卓恶意软件检测在两个代表性数据集上性能存在显著差异，并提出了五种新的时空偏差因素以改进评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽提出了时间感知评估方法，但在实际应用中，不同数据集上的检测性能仍存在不一致性，这引发了对当前最先进方法在真实场景中表现能力的质疑。

Method: 研究在安卓恶意软件领域，对两个代表性数据集和五种常用分类器进行了全面评估，识别了五种新的时空偏差因素。

Result: 实验表明，这些偏差因素显著影响评估结果，并针对每个因素提出了具体可行的改进建议。

Conclusion: 为确保评估的可靠性和可重复性，研究呼吁社区在方法学中整合这些建议，以实现更真实的恶意软件检测评估。

Abstract: Several recent works focused on the best practices for applying machine
learning to cybersecurity. In the context of malware, TESSERACT highlighted the
impact of concept drift on detection performance and suggested temporal and
spatial constraints to be enforced to ensure realistic time-aware evaluations,
which have been adopted by the community. In this paper, we demonstrate
striking discrepancies in the performance of learning-based malware detection
across the same time frame when evaluated on two representative Android malware
datasets used in top-tier security conferences, both adhering to established
sampling and evaluation guidelines. This questions our ability to understand
how current state-of-the-art approaches would perform in realistic scenarios.
To address this, we identify five novel temporal and spatial bias factors that
affect realistic evaluations. We thoroughly evaluate the impact of these
factors in the Android malware domain on two representative datasets and five
Android malware classifiers used or proposed in top-tier security conferences.
For each factor, we provide practical and actionable recommendations that the
community should integrate in their methodology for more realistic and
reproducible settings.

</details>


### [122] [An ontological lens on attack trees: Toward adequacy and interoperability](https://arxiv.org/abs/2506.23841)
*Ítalo Oliveira,Stefano M. Nicoletti,Gal Engelberg,Mattia Fumagalli,Dan Klein,Giancarlo Guizzardi*

Main category: cs.CR

TL;DR: 攻击树(AT)是安全分析中常用的形式化方法，但存在本体论基础不足的问题。本文基于COVER本体论分析AT，揭示其四大缺陷，并提出改进方向。


<details>
  <summary>Details</summary>
Motivation: 攻击树虽广泛用于安全风险建模与量化分析，但因缺乏本体论基础导致建模模糊、概念缺失、指导不足及工具互操作性差等问题，需系统性改进。

Method: 基于统一基础本体论(UFO)的COVER核心本体，对攻击树进行本体论充分性分析，识别其术语歧义、概念缺失等结构性缺陷。

Result: 发现攻击树存在四大短板：(1)术语多义性；(2)关键领域概念缺失；(3)目标分解缺乏建模指南；(4)工具语义互操作性不足。现有增量方案需结合更广泛的风险建模方法。

Conclusion: 本体论分析为攻击树的根本性改进提供理论基础，未来需开发整合COVER的本体驱动型风险建模框架以解决现有局限。

Abstract: Attack Trees (AT) are a popular formalism for security analysis. They are
meant to display an attacker's goal decomposed into attack steps needed to
achieve it and compute certain security metrics (e.g., attack cost,
probability, and damage). ATs offer three important services: (a) conceptual
modeling capabilities for representing security risk management scenarios, (b)
a qualitative assessment to find root causes and minimal conditions of
successful attacks, and (c) quantitative analyses via security metrics
computation under formal semantics, such as minimal time and cost among all
attacks. Still, the AT language presents limitations due to its lack of
ontological foundations, thus compromising associated services. Via an
ontological analysis grounded in the Common Ontology of Value and Risk (COVER)
-- a reference core ontology based on the Unified Foundational Ontology (UFO)
-- we investigate the ontological adequacy of AT and reveal four significant
shortcomings: (1) ambiguous syntactical terms that can be interpreted in
various ways; (2) ontological deficit concerning crucial domain-specific
concepts; (3) lacking modeling guidance to construct ATs decomposing a goal;
(4) lack of semantic interoperability, resulting in ad hoc stand-alone tools.
We also discuss existing incremental solutions and how our analysis paves the
way for overcoming those issues through a broader approach to risk management
modeling.

</details>


### [123] [Differentially Private Synthetic Data Release for Topics API Outputs](https://arxiv.org/abs/2506.23855)
*Travis Dick,Alessandro Epasto,Adel Javanmard,Josh Karlin,Andres Munoz Medina,Vahab Mirrokni,Sergei Vassilvitskii,Peilin Zhong*

Main category: cs.CR

TL;DR: 本文提出了一种生成合成隐私保护广告API输出的新方法，重点关注Google Chrome的Topics API，通过差分隐私技术创建既真实又保护隐私的数据集，并开源了匿名数据集以促进研究透明度。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏公开可用的真实数据，隐私保护广告API的隐私属性实证研究受到阻碍。隐私问题阻止了此类数据的公开发布，因此需要一种既能保护隐私又能提供真实数据的方法。

Method: 该方法首先计算大量差分隐私统计量，描述API输出随时间的变化；然后设计一个参数化的API轨迹序列分布，并优化参数以匹配统计量；最后从该分布中抽取数据生成合成数据集。

Result: 研究成功创建了一个差分隐私数据集，其重识别风险属性与真实Topics API数据高度匹配，并通过开源发布匿名数据集，为外部研究人员提供了分析API的工具。

Conclusion: 这项工作通过生成合成数据集和开源发布，促进了隐私保护广告API隐私属性的透明度，为未来研究提供了可靠的大规模数据集基础。

Abstract: The analysis of the privacy properties of Privacy-Preserving Ads APIs is an
area of research that has received strong interest from academics, industry,
and regulators. Despite this interest, the empirical study of these methods is
hindered by the lack of publicly available data. Reliable empirical analysis of
the privacy properties of an API, in fact, requires access to a dataset
consisting of realistic API outputs; however, privacy concerns prevent the
general release of such data to the public.
  In this work, we develop a novel methodology to construct synthetic API
outputs that are simultaneously realistic enough to enable accurate study and
provide strong privacy protections. We focus on one Privacy-Preserving Ads
APIs: the Topics API, part of Google Chrome's Privacy Sandbox. We developed a
methodology to generate a differentially-private dataset that closely matches
the re-identification risk properties of the real Topics API data. The use of
differential privacy provides strong theoretical bounds on the leakage of
private user information from this release.
  Our methodology is based on first computing a large number of
differentially-private statistics describing how output API traces evolve over
time. Then, we design a parameterized distribution over sequences of API traces
and optimize its parameters so that they closely match the statistics obtained.
Finally, we create the synthetic data by drawing from this distribution.
  Our work is complemented by an open-source release of the anonymized dataset
obtained by this methodology. We hope this will enable external researchers to
analyze the API in-depth and replicate prior and future work on a realistic
large-scale dataset. We believe that this work will contribute to fostering
transparency regarding the privacy properties of Privacy-Preserving Ads APIs.

</details>


### [124] [Exploring Privacy and Security as Drivers for Environmental Sustainability in Cloud-Based Office Solutions](https://arxiv.org/abs/2506.23866)
*Jason Kayembe,Iness Ben Guirat,Jan Tobias Mühlberg*

Main category: cs.CR

TL;DR: 本文研究了基于云的办公解决方案在隐私、安全和环境可持续性方面的交叉点，提出了一种量化用户和网络侧能源使用及碳排放的框架，并验证了隐私优先服务通常比依赖数据收集和广告的服务更节能。


<details>
  <summary>Details</summary>
Motivation: 探讨隐私优先服务是否比依赖广告和数据收集的服务更节能，并量化不同云邮件服务的环境影响。

Method: 提出系统化测量框架，分析不同架构和商业模型对环境足迹的影响，并应用于三种主流邮件服务（Microsoft Outlook、Gmail、Proton Mail）及自托管解决方案。

Result: 自托管解决方案即使增加14%的设备能耗和15%的PGP加密排放，仍比Gmail节能33%；在商业服务中，Proton Mail最节能，比Outlook节省0.1 gCO2 e/会话，且广告拦截可进一步减少Outlook 2%的排放。

Conclusion: 隐私优先设计（如Proton Mail和自托管方案）显著降低云服务碳排放，验证了初始假设，为可持续IT解决方案提供了实证依据。

Abstract: In this paper, we explore the intersection of privacy, security, and
environmental sustainability in cloud-based office solutions, focusing on
quantifying user- and network-side energy use and associated carbon emissions.
We hypothesise that privacy-focused services are typically more
energy-efficient than those funded through data collection and advertising. To
evaluate this, we propose a framework that systematically measures
environmental costs based on energy usage and network data traffic during
well-defined, automated usage scenarios. To test our hypothesis, we first
analyse how underlying architectures and business models, such as monetisation
through personalised advertising, contribute to the environmental footprint of
these services. We then explore existing methodologies and tools for software
environmental impact assessment. We apply our framework to three mainstream
email services selected to reflect different privacy policies, from
ad-supported tracking-intensive models to privacy-focused designs: Microsoft
Outlook, Google Mail (Gmail), and Proton Mail. We extend this comparison to a
self-hosted email solution, evaluated with and without end-to-end encryption.
We show that the self-hosted solution, even with 14% of device energy and 15%
of emissions overheads from PGP encryption, remains the most energy-efficient,
saving up to 33% of emissions per session compared to Gmail. Among commercial
providers, Proton Mail is the most efficient, saving up to 0.1 gCO2 e per
session compared to Outlook, whose emissions can be further reduced by 2%
through ad-blocking.

</details>


### [125] [RawMal-TF: Raw Malware Dataset Labeled by Type and Family](https://arxiv.org/abs/2506.23909)
*David Bálik,Martin Jureček,Mark Stamp*

Main category: cs.CR

TL;DR: 本研究通过构建新型多层级标记的恶意软件数据集，采用静态分析特征提取方法，验证了随机森林与XGBoost在恶意软件分类任务中的高效性能，最高准确率达98.98%。


<details>
  <summary>Details</summary>
Motivation: 解决现有恶意软件分类研究中缺乏细粒度标记数据集的问题，通过同时标注类型和家族层级标签，支持更精细化的分类研究。

Method: 整合VirusShare等平台的原始样本，基于PE头静态分析构建统一特征提取流程，创建含14类恶意软件类型和17个家族的数据集，采用随机森林、XGBoost和SVM进行三类分类任务评估。

Result: 二分类任务中模型准确率最高达98.98%；千样本缩减数据集仍保持97.6%以上准确率；类型级多分类准确率81.1%，家族级73.4%，揭示了精度与计算成本的权衡关系。

Conclusion: 双层级标记体系能实现更精细的恶意软件分类，为未来检测技术研究奠定基础，同时证明静态分析特征在有限数据条件下仍具鲁棒性。

Abstract: This work addresses the challenge of malware classification using machine
learning by developing a novel dataset labeled at both the malware type and
family levels. Raw binaries were collected from sources such as VirusShare, VX
Underground, and MalwareBazaar, and subsequently labeled with family
information parsed from binary names and type-level labels integrated from
ClarAVy. The dataset includes 14 malware types and 17 malware families, and was
processed using a unified feature extraction pipeline based on static analysis,
particularly extracting features from Portable Executable headers, to support
advanced classification tasks. The evaluation was focused on three key
classification tasks. In the binary classification of malware versus benign
samples, Random Forest and XGBoost achieved high accuracy on the full datasets,
reaching 98.5% for type-based detection and 98.98% for family-based detection.
When using truncated datasets of 1,000 samples to assess performance under
limited data conditions, both models still performed strongly, achieving 97.6%
for type-based detection and 98.66% for family-based detection. For interclass
classification, which distinguishes between malware types or families, the
models reached up to 97.5% accuracy on type-level tasks and up to 93.7% on
family-level tasks. In the multiclass classification setting, which assigns
samples to the correct type or family, SVM achieved 81.1% accuracy on type
labels, while Random Forest and XGBoost reached approximately 73.4% on family
labels. The results highlight practical trade-offs between accuracy and
computational cost, and demonstrate that labeling at both the type and family
levels enables more fine-grained and insightful malware classification. The
work establishes a robust foundation for future research on advanced malware
detection and classification.

</details>


### [126] [Lock Prediction for Zero-Downtime Database Encryption](https://arxiv.org/abs/2506.23985)
*Mohamed Sami Rakha,Adam Sorrenti,Greg Stager,Walid Rjaibi,Andriy Miranskyy*

Main category: cs.CR

TL;DR: 本文提出了一种基于深度学习的预测方法，用于在线数据库加密，通过预测数据库锁定序列减少加密过程中的停机时间和存储开销。


<details>
  <summary>Details</summary>
Motivation: 现代企业数据库系统在平衡数据安全性和性能方面面临挑战，现有加密技术需要完整备份和恢复周期，导致长时间停机和存储增加，难以在高吞吐环境中实施在线加密。

Method: 研究利用深度学习模型（如Transformer和LSTM）预测数据库锁定序列，使用IBM Db2系统和TPC-C基准工作负载的锁事件日志进行模型训练和评估。

Result: 实验表明，所提出的深度学习模型在表级和页级预测中分别达到49%和66%的平均准确率，优于朴素基线方法。

Conclusion: 通过预测即将锁定的表和页，该方法为实现在线加密提供了可行路径，有助于构建安全且低开销的数据库系统。

Abstract: Modern enterprise database systems face significant challenges in balancing
data security and performance. Ensuring robust encryption for sensitive
information is critical for systems' compliance with security standards.
Although holistic database encryption provides strong protection, existing
database systems often require a complete backup and restore cycle, resulting
in prolonged downtime and increased storage usage. This makes it difficult to
implement online encryption techniques in high-throughput environments without
disrupting critical operations.
  To address this challenge, we envision a solution that enables online
database encryption aligned with system activity, eliminating the need for
downtime, storage overhead, or full-database reprocessing. Central to this
vision is the ability to predict which parts of the database will be accessed
next, allowing encryption to be applied online. As a step towards this
solution, this study proposes a predictive approach that leverages deep
learning models to forecast database lock sequences, using IBM Db2 as the
database system under study. In this study, we collected a specialized dataset
from TPC-C benchmark workloads, leveraging lock event logs for model training
and evaluation. We applied deep learning architectures, such as Transformer and
LSTM, to evaluate models for various table-level and page-level lock
predictions. We benchmark the accuracy of the trained models versus a Naive
Baseline across different prediction horizons and timelines.
  The study experiments demonstrate that the proposed deep learning-based
models achieve up to 49% average accuracy for table-level and 66% for
page-level predictions, outperforming a Naive Baseline. By anticipating which
tables and pages will be locked next, the proposed approach is a step toward
online encryption, offering a practical path toward secure, low-overhead
database systems.

</details>


### [127] [Poisoning Attacks to Local Differential Privacy for Ranking Estimation](https://arxiv.org/abs/2506.24033)
*Pei Zhan,Peng Tang,Yangzhuo Li,Puwen Wei,Shanqing Guo*

Main category: cs.CR

TL;DR: 本文针对本地差分隐私（LDP）中的排名估计任务，提出新型投毒攻击方法，通过精确操纵目标项频率改变排名，并设计攻击成本与最优攻击项（集）策略，验证了攻击有效性。


<details>
  <summary>Details</summary>
Motivation: LDP通过扰动用户输入提供数据隐私保护，但易受投毒攻击。现有攻击仅调整目标项频率，本文提出更精细的攻击方式，利用少量虚假用户精确修改频率以最大化攻击收益。

Method: 为kRR协议迭代选择最优攻击项并分配虚假用户；为OUE协议迭代确定最优攻击项集并分析频率增量；为OLH协议设计基于哈希原像的调和成本函数。最后提出基于置信度的攻击策略量化成功概率与迭代次数。

Result: 理论与实验证明攻击有效性，kRR、OUE、OLH协议均能通过策略显著改变项排名，代码数据已开源。

Conclusion: 研究揭示了LDP排名估计中投毒攻击的严重威胁，需开发针对性防御机制以保障系统安全。

Abstract: Local differential privacy (LDP) involves users perturbing their inputs to
provide plausible deniability of their data. However, this also makes LDP
vulnerable to poisoning attacks. In this paper, we first introduce novel
poisoning attacks for ranking estimation. These attacks are intricate, as fake
attackers do not merely adjust the frequency of target items. Instead, they
leverage a limited number of fake users to precisely modify frequencies,
effectively altering item rankings to maximize gains. To tackle this challenge,
we introduce the concepts of attack cost and optimal attack item (set), and
propose corresponding strategies for kRR, OUE, and OLH protocols. For kRR, we
iteratively select optimal attack items and allocate suitable fake users. For
OUE, we iteratively determine optimal attack item sets and consider the
incremental changes in item frequencies across different sets. Regarding OLH,
we develop a harmonic cost function based on the pre-image of a hash to select
that supporting a larger number of effective attack items. Lastly, we present
an attack strategy based on confidence levels to quantify the probability of a
successful attack and the number of attack iterations more precisely. We
demonstrate the effectiveness of our attacks through theoretical and empirical
evidence, highlighting the necessity for defenses against these attacks. The
source code and data have been made available at
https://github.com/LDP-user/LDP-Ranking.git.

</details>


### [128] [Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models](https://arxiv.org/abs/2506.24056)
*Tung-Ling Li,Hongliang Liu*

Main category: cs.CR

TL;DR: 本文提出了一种名为logit-gap steering的快速越狱框架，通过单次词汇表遍历减少RLHF对齐语言模型的拒绝-确认差距，实现了高效攻击且保持主题连贯性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决RLHF对齐语言模型中存在的拒绝-确认差距问题，并探索如何高效生成通用攻击后缀以揭示安全调优的内部表征。

Method: 方法采用前向可计算分数，结合差距减少、轻量级KL惩罚和奖励偏移代理，通过“排序-求和-停止”扫描在秒级内生成短后缀。

Result: 实验结果显示，该方法在0.5B至70B模型上均有效，单次攻击成功率提升至80-100%，同时揭示了句子边界奖励悬崖等对齐伪影。

Conclusion: 结论表明，logit-gap steering不仅高效且通用，还为安全调优如何重塑内部表征提供了轻量级探测工具。

Abstract: We introduce logit-gap steering, a fast jailbreak framework that casts the
refusal-affirmation gap of RLHF-aligned language models as a single pass over
the vocabulary. A forward-computable score blends gap reduction with
lightweight proxies for KL penalty and reward shift, allowing a "sort-sum-stop"
sweep to complete in under a second and return a short suffix--two orders of
magnitude fewer model calls than beam or gradient attacks. The same suffix
generalises to unseen prompts and scales from 0.5 B to 70 B checkpoints,
lifting one-shot attack success from baseline levels to 80-100% while
preserving topical coherence. Beyond efficiency, these suffixes expose
sentence-boundary reward cliffs and other alignment artefacts, offering a
lightweight probe into how safety tuning reshapes internal representations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [129] [Bootstrapping Human-Like Planning via LLMs](https://arxiv.org/abs/2506.22604)
*David Porfirio,Vincent Hsiao,Morgan Fine-Morris,Leslie Smith,Laura M. Hiatt*

Main category: cs.AI

TL;DR: 研究探讨了结合自然语言编程与拖拽界面两种机器人任务编程方式的可行性，通过基于大语言模型（LLM）的流程生成类人动作序列，并与人工指定序列对比，发现大模型表现更优但小模型仍可满足需求。


<details>
  <summary>Details</summary>
Motivation: 随着机器人终端用户对任务编程便捷性需求的提升，研究旨在结合自然语言编程的直观性与拖拽界面的精确性优势，探索两者融合的可能性。

Method: 构建基于大语言模型（LLM）的流程，输入自然语言指令并输出类人精细动作序列，随后与人工指定的动作序列数据集进行对比分析。

Result: 实验表明，大模型在生成类人动作序列方面优于小模型，但小模型仍能达到令人满意的性能水平。

Conclusion: 尽管大模型在生成精细动作序列上更具优势，小模型的实际表现验证了轻量化解决方案的可行性，为两种编程范式的结合提供了实践依据。

Abstract: Robot end users increasingly require accessible means of specifying tasks for
robots to perform. Two common end-user programming paradigms include
drag-and-drop interfaces and natural language programming. Although natural
language interfaces harness an intuitive form of human communication,
drag-and-drop interfaces enable users to meticulously and precisely dictate the
key actions of the robot's task. In this paper, we investigate the degree to
which both approaches can be combined. Specifically, we construct a large
language model (LLM)-based pipeline that accepts natural language as input and
produces human-like action sequences as output, specified at a level of
granularity that a human would produce. We then compare these generated action
sequences to another dataset of hand-specified action sequences. Although our
results reveal that larger models tend to outperform smaller ones in the
production of human-like action sequences, smaller models nonetheless achieve
satisfactory performance.

</details>


### [130] [Ludax: A GPU-Accelerated Domain Specific Language for Board Games](https://arxiv.org/abs/2506.22609)
*Graham Todd,Alexander G. Padula,Dennis J. N. J. Soemers,Julian Togelius*

Main category: cs.AI

TL;DR: 本文介绍了Ludax框架，一种专为棋盘游戏设计的领域特定语言，能自动编译为硬件加速代码，结合了游戏描述语言的通用性与现代并行处理硬件的速度，旨在加速从强化学习到认知科学等游戏研究。


<details>
  <summary>Details</summary>
Motivation: 游戏长期以来作为人工智能研究的基准和测试环境。随着硬件加速的进步，如JAX等库大幅提升了训练和测试速度。本文旨在结合游戏描述语言的通用性与硬件加速的优势，推动游戏研究的快速发展。

Method: 提出了Ludax框架，一种棋盘游戏的领域特定语言，能自动编译为硬件加速代码。详细介绍了Ludax的描述语言和编译过程的技术细节，并进行了速度基准测试和强化学习代理的训练演示。

Result: Ludax框架成功结合了游戏描述语言的通用性与现代硬件加速的速度，能够无缝集成到现有的深度学习流程中。框架及其现有棋盘游戏的实现已开源并免费提供。

Conclusion: Ludax框架有望成为加速游戏研究的工具，通过快速模拟和灵活的表示方案，支持从强化学习到认知科学的广泛研究。

Abstract: Games have long been used as benchmarks and testing environments for research
in artificial intelligence. A key step in supporting this research was the
development of game description languages: frameworks that compile
domain-specific code into playable and simulatable game environments, allowing
researchers to generalize their algorithms and approaches across multiple games
without having to manually implement each one. More recently, progress in
reinforcement learning (RL) has been largely driven by advances in hardware
acceleration. Libraries like JAX allow practitioners to take full advantage of
cutting-edge computing hardware, often speeding up training and testing by
orders of magnitude. Here, we present a synthesis of these strands of research:
a domain-specific language for board games which automatically compiles into
hardware-accelerated code. Our framework, Ludax, combines the generality of
game description languages with the speed of modern parallel processing
hardware and is designed to fit neatly into existing deep learning pipelines.
We envision Ludax as a tool to help accelerate games research generally, from
RL to cognitive science, by enabling rapid simulation and providing a flexible
representation scheme. We present a detailed breakdown of Ludax's description
language and technical notes on the compilation process, along with speed
benchmarking and a demonstration of training RL agents. The Ludax framework,
along with implementations of existing board games, is open-source and freely
available.

</details>


### [131] [URSA: The Universal Research and Scientific Agent](https://arxiv.org/abs/2506.22653)
*Michael Grosskopf,Russell Bent,Rahul Somasundaram,Isaac Michaud,Arthur Lui,Nathan Debardeleben,Earl Lawrence*

Main category: cs.AI

TL;DR: 论文介绍了URSA科学代理生态系统，该系统利用大型语言模型（LLMs）的复杂推理能力，通过模块化代理和工具加速科研任务。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）已具备与人类科学家相似的复杂推理、规划等能力，将其应用于‘代理型’AI有望突破科研瓶颈，推动科学发展。

Method: URSA系统由模块化代理和工具组成，包括与高级物理模拟代码的耦合，可灵活组合以解决不同复杂度和影响力的科学问题。

Result: 论文展示了URSA的架构及实例，证明了该系统在加速科研任务方面的潜力。

Conclusion: URSA作为一个科学代理生态系统，通过整合LLMs与专业工具，为科研提供了高效、灵活的解决方案，展现了AI驱动科学革命的广阔前景。

Abstract: Large language models (LLMs) have moved far beyond their initial form as
simple chatbots, now carrying out complex reasoning, planning, writing, coding,
and research tasks. These skills overlap significantly with those that human
scientists use day-to-day to solve complex problems that drive the cutting edge
of research. Using LLMs in "agentic" AI has the potential to revolutionize
modern science and remove bottlenecks to progress. In this work, we present
URSA, a scientific agent ecosystem for accelerating research tasks. URSA
consists of a set of modular agents and tools, including coupling to advanced
physics simulation codes, that can be combined to address scientific problems
of varied complexity and impact. This work highlights the architecture of URSA,
as well as examples that highlight the potential of the system.

</details>


### [132] [Rises for Measuring Local Distributivity in Lattices](https://arxiv.org/abs/2506.23168)
*Mohammad Abdulla,Tobias Hille,Dominik Dürrschnabel,Gerd Stumme*

Main category: cs.AI

TL;DR: 本文提出使用'上升'概念量化概念格的分配性，证明格完全分配的充要条件，并发现现实数据概念格高度满足并分配性而非交分配性。


<details>
  <summary>Details</summary>
Motivation: 形式概念分析中概念格常呈现高度分配性，但缺乏标准化度量方法。研究旨在建立量化分配性的新指标。

Method: 引入概念格中'上升'的定义，通过覆盖概念内属性/对象数量的变化评估分配性，关联经典交/并分配理论。

Result: 证明格完全分配当且仅当无非单位上升；现实概念格普遍具有高并分配性但低交分配性。

Conclusion: 上升是量化分配性的有效工具，揭示了现实数据概念格在序集层面上呈现的分配特性差异。

Abstract: Distributivity is a well-established and extensively studied notion in
lattice theory. In the context of data analysis, particularly within Formal
Concept Analysis (FCA), lattices are often observed to exhibit a high degree of
distributivity. However, no standardized measure exists to quantify this
property. In this paper, we introduce the notion of rises in (concept) lattices
as a means to assess distributivity. Rises capture how the number of attributes
or objects in covering concepts change within the concept lattice. We show that
a lattice is distributive if and only if no non-unit rises occur. Furthermore,
we relate rises to the classical notion of meet- and join distributivity. We
observe that concept lattices from real-world data are to a high degree
join-distributive, but much less meet-distributive. We additionally study how
join-distributivity manifests on the level of ordered sets.

</details>


### [133] [Explanations are a means to an end](https://arxiv.org/abs/2506.22740)
*Jessica Hullman,Ziyang Guo,Berk Ustun*

Main category: cs.AI

TL;DR: 本文提出了一种基于统计决策理论的功能性解释框架，强调解释应针对具体应用场景设计，并通过理论和实证相结合的方法评估其价值。


<details>
  <summary>Details</summary>
Motivation: 当前可解释机器学习方法主要关注模型输入输出映射，缺乏对解释实际应用场景的深入考虑。本文主张解释应围绕特定目标设计和评估。

Method: 采用统计决策理论框架，将解释功能形式化，并应用于临床决策支持、提供补救措施和模型调试等多样化用例。通过定义理想决策者能获得的性能"提升"来量化解释价值。

Result: 该框架能有效防止解释的模糊性误用，要求研究者明确具体用例，并基于预期解释使用模型进行分析。提出了跨越理论和实证视角的解释价值评估定义。

Conclusion: 解释设计和评估需要结合具体功能目标，通过理论建模与实证分析相结合的方式，才能实现解释在实践中的有效应用。

Abstract: Modern methods for explainable machine learning are designed to describe how
models map inputs to outputs--without deep consideration of how these
explanations will be used in practice. This paper argues that explanations
should be designed and evaluated with a specific end in mind. We describe how
to formalize this end in a framework based in statistical decision theory. We
show how this functionally-grounded approach can be applied across diverse use
cases, such as clinical decision support, providing recourse, or debugging. We
demonstrate its use to characterize the maximum "boost" in performance on a
particular task that an explanation could provide an idealized decision-maker,
preventing misuse due to ambiguity by forcing researchers to specify concrete
use cases that can be analyzed in light of models of expected explanation use.
We argue that evaluation should meld theoretical and empirical perspectives on
the value of explanation, and contribute definitions that span these
perspectives.

</details>


### [134] [Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems](https://arxiv.org/abs/2506.22774)
*Michael Papademas,Xenia Ziouvelou,Antonis Troumpoukis,Vangelis Karkaletsis*

Main category: cs.AI

TL;DR: 本文提出一种结合伦理准则与PageRank/TrustRank算法的AI可信度评估方法，旨在量化评估的同时保持理论完整性。


<details>
  <summary>Details</summary>
Motivation: AI技术的社会影响深远且复杂，现有可信AI指南缺乏量化方法，而技术工具又过于片面，需结合两者优势。

Method: 将可信AI的伦理组件与PageRank/TrustRank算法流程结合，建立减少主观性的算法化评估框架。

Result: 应用表明该方法能通过量化分析实现整体可信度评估，同时兼顾伦理指南的理论内涵。

Conclusion: 融合伦理准则与算法标准可平衡量化与全面性，为AI可信度评估提供更客观的解决方案。

Abstract: Artificial Intelligence (AI) technology epitomizes the complex challenges
posed by human-made artifacts, particularly those widely integrated into
society and exert significant influence, highlighting potential benefits and
their negative consequences. While other technologies may also pose substantial
risks, AI's pervasive reach makes its societal effects especially profound. The
complexity of AI systems, coupled with their remarkable capabilities, can lead
to a reliance on technologies that operate beyond direct human oversight or
understanding. To mitigate the risks that arise, several theoretical tools and
guidelines have been developed, alongside efforts to create technological tools
aimed at safeguarding Trustworthy AI. The guidelines take a more holistic view
of the issue but fail to provide techniques for quantifying trustworthiness.
Conversely, while technological tools are better at achieving such
quantification, they lack a holistic perspective, focusing instead on specific
aspects of Trustworthy AI. This paper aims to introduce an assessment method
that combines the ethical components of Trustworthy AI with the algorithmic
processes of PageRank and TrustRank. The goal is to establish an assessment
framework that minimizes the subjectivity inherent in the self-assessment
techniques prevalent in the field by introducing algorithmic criteria. The
application of our approach indicates that a holistic assessment of an AI
system's trustworthiness can be achieved by providing quantitative insights
while considering the theoretical content of relevant guidelines.

</details>


### [135] [ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models](https://arxiv.org/abs/2506.22865)
*Ziqi Zhong,Xunzhu Tang*

Main category: cs.AI

TL;DR: 本文提出ReasonBridge方法，通过分层知识蒸馏框架将闭源大模型的复杂推理能力高效迁移至开源模型，仅需1000条精选推理轨迹数据，使开源模型推理能力提升23%，显著缩小与闭源模型的差距。


<details>
  <summary>Details</summary>
Motivation: 当前闭源与开源大语言模型在复杂推理任务上存在显著性能差距，亟需一种高效方法将闭源模型的推理能力迁移至开源模型。

Method: 1) 构建含1000条多领域精选推理轨迹的Reason1K数据集\n2) 分层蒸馏框架捕获战略抽象与战术实现模式\n3) 仅增加0.3%可训练参数的稀疏推理适配器\n4) 测试时采用引导推理干预的计算扩展机制

Result: 开源模型推理能力最高提升23%，增强版Qwen2.5-14B在MATH500超越Claude-Sonnet3.5，在AIME竞赛题达到同等水平。该方法在不同领域和模型架构中均展现良好泛化性。

Conclusion: ReasonBridge建立了样本高效的推理增强范式，为提升指令跟随模型的推理能力提供了通用解决方案，显著推进了开源模型性能边界。

Abstract: Recent advancements in Large Language Models (LLMs) have revealed a
significant performance gap between closed-source and open-source models,
particularly in tasks requiring complex reasoning and precise instruction
following. This paper introduces ReasonBridge, a methodology that efficiently
transfers reasoning capabilities from powerful closed-source to open-source
models through a novel hierarchical knowledge distillation framework. We
develop a tailored dataset Reason1K with only 1,000 carefully curated reasoning
traces emphasizing difficulty, diversity, and quality. These traces are
filtered from across multiple domains using a structured multi-criteria
selection algorithm. Our transfer learning approach incorporates: (1) a
hierarchical distillation process capturing both strategic abstraction and
tactical implementation patterns, (2) a sparse reasoning-focused adapter
architecture requiring only 0.3% additional trainable parameters, and (3) a
test-time compute scaling mechanism using guided inference interventions.
Comprehensive evaluations demonstrate that ReasonBridge improves reasoning
capabilities in open-source models by up to 23% on benchmark tasks,
significantly narrowing the gap with closed-source models. Notably, the
enhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its
performance on competition-level AIME problems. Our methodology generalizes
effectively across diverse reasoning domains and model architectures,
establishing a sample-efficient approach to reasoning enhancement for
instruction following.

</details>


### [136] [Agentic Enterprise: AI-Centric User to User-Centric AI](https://arxiv.org/abs/2506.22893)
*Arpit Narechania,Alex Endert,Atanu R Sinha*

Main category: cs.AI

TL;DR: 本文探讨了人工智能（AI）在企业决策中的潜力，提出了以用户为中心的AI六大原则，并倡导通过市场机制优化AI代理的设计与交付。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的快速发展，其在企业决策中的潜在影响日益显著。然而，当前以AI为中心的用户范式未能充分满足企业决策的持续需求，因此需要转向以用户为中心的AI设计。

Method: 通过分析企业决策的多样性和重复性，提出将AI代理作为提升企业决策效率的工具，并总结了六大原则以实现AI代理在企业中的成功应用。

Result: 研究强调了从以AI为中心转向以用户为中心的重要性，并提出了六大原则，同时建议通过市场机制优化AI平台的设计与交付。

Conclusion: 通过以用户为中心的AI设计和市场机制的引入，可以更好地满足企业决策的需求，提升AI代理在企业中的实用性和效率。

Abstract: After a very long winter, the Artificial Intelligence (AI) spring is here.
Or, so it seems over the last three years. AI has the potential to impact many
areas of human life - personal, social, health, education, professional. In
this paper, we take a closer look at the potential of AI for Enterprises, where
decision-making plays a crucial and repeated role across functions, tasks, and
operations. We consider Agents imbued with AI as means to increase
decision-productivity of enterprises. We highlight six tenets for Agentic
success in enterprises, by drawing attention to what the current, AI-Centric
User paradigm misses, in the face of persistent needs of and usefulness for
Enterprise Decision-Making. In underscoring a shift to User-Centric AI, we
offer six tenets and promote market mechanisms for platforms, aligning the
design of AI and its delivery by Agents to the cause of enterprise users.

</details>


### [137] [Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning](https://arxiv.org/abs/2506.22919)
*Sanskar Pandey,Ruhaan Chopra,Saad Murtaza Bhat,Ark Abhyudaya*

Main category: cs.AI

TL;DR: Hecto提出了一种轻量级混合专家模型，通过结合GRU和FFNN专家实现架构异构性，在稀疏Top-1门控机制下，针对不同推理类型（时序vs静态）实现专家专业化，在低资源条件下建立条件计算新基准。


<details>
  <summary>Details</summary>
Motivation: 传统MoE模型中专家依赖相同归纳偏置，限制了表征多样性和计算效率，静态计算路径无法适应不同类型推理需求，也阻碍了专业化和可解释性。

Method: 采用GRU专家处理时序推理和FFNN专家处理静态抽象的异构架构，通过稀疏Top-1门控机制实现条件计算，输入表示相互隔离。

Result: 在三个推理基准(AG News/SST-2/HotpotQA)和回归任务(STS-B)上，Hecto性能匹配或接近同构基线，同时实现清晰的专家专业化（时序/静态推理分离）；大批量时性能提升，架构多样性是其稳定性和可解释性的关键。

Conclusion: Hecto为条件计算设立了新基准，通过原则性专业化框架，在低资源场景下为专业化推理提供了系统解决方案，其模型优势源于架构异构性。

Abstract: Mixture-of-Experts (MoE) models enable conditional computation by routing
inputs to specialized experts, but these experts rely on identical inductive
biases, thus limiting representational diversity. This static computation
pathway is inefficient for inputs that require different types of reasoning and
limits specialization and interpretability. We propose Hecto, a lightweight MoE
architecture that leverages architectural heterogeneity by combining a GRU
expert for temporal reasoning and an FFNN expert for static abstraction under a
sparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AG
News, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closely
trails homogeneous baselines in performance despite receiving isolated input
representations, while achieving clear expert specialization, with each expert
aligning to distinct reasoning types (temporal vs static). At larger batch
sizes, Hecto exhibits improved performance, benefiting from relaxed
computational constraints that allow its heterogeneous architecture to optimize
more effectively. Ablation results isolate architectural diversity as the
source of Hecto's stability and interpretability across diverse reasoning
tasks. Overall, Hecto establishes itself as a new benchmark for conditional
computation, offering a principled framework for specialized reasoning in
low-resource regimes with its model strength derived from principled
specialization.

</details>


### [138] [Improving Rationality in the Reasoning Process of Language Models through Self-playing Game](https://arxiv.org/abs/2506.22920)
*Pinzheng Wang,Juntao Li,Zecheng Tang,Haijia Gui,Min zhang*

Main category: cs.AI

TL;DR: 本文提出通过自博弈游戏Critic-Discernment Game(CDG)增强大语言模型的推理理解能力，实验证明该方法能显著提升模型在数学推理、错误检测等任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型(LLM)在数学、编程等任务中展现出推理能力，但研究表明其缺乏对推理过程的真正理解。本文探索如何通过无监督的自博弈方式提升模型的理性推理能力。

Method: 设计了Critic-Discernment Game(CDG)：证明者先给出问题解决方案，随后接受或误导性批评的挑战。证明者需在误导评论中保持正确答案，在建设性反馈中修正错误。

Result: 在数学推理、分步错误检测、自我修正和长链推理等任务上的实验表明，CDG训练能显著提升已对齐LLM对自身推理过程的理解能力。

Conclusion: 无监督的自博弈方法CDG能有效增强语言模型对推理过程的理解能力，为提升模型理性推理提供了新思路。

Abstract: Large language models (LLMs) have demonstrated considerable reasoning
abilities in various tasks such as mathematics and coding. However, recent
studies indicate that even the best models lack true comprehension of their
reasoning processes. In this paper, we explore how self-play can enhance the
rationality of models in the reasoning process without supervision from humans
or superior models. We design a Critic-Discernment Game(CDG) in which a prover
first provides a solution to a given problem and is subsequently challenged by
critiques of its solution. These critiques either aim to assist or mislead the
prover. The objective of the prover is to maintain the correct answer when
faced with misleading comments, while correcting errors in response to
constructive feedback. Our experiments on tasks involving mathematical
reasoning, stepwise error detection, self-correction, and long-chain reasoning
demonstrate that CDG training can significantly improve the ability of
well-aligned LLMs to comprehend their reasoning process.

</details>


### [139] [MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning](https://arxiv.org/abs/2506.22992)
*Yulun Jiang,Yekun Chai,Maria Brbić,Michael Moor*

Main category: cs.AI

TL;DR: 论文提出MARBLE基准测试，用于评估多模态语言模型(MLLMs)在复杂多模态环境中的逐步推理能力，发现当前模型表现接近随机水平，揭示感知与推理仍是关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有推理基准仅关注纯文本或可单模态直接检索的多模态问题，复杂多模态推理能力的研究仍存在空白。

Method: 设计包含M-Portal和M-Cube两项高难度任务的MARBLE基准，要求模型在空间、视觉和物理约束下进行多步骤规划与理解。

Result: 12个先进MLLMs在M-Portal上表现接近随机，M-Cube准确率为0%；仅简化子任务中部分模型超越随机基线，显示视觉信息提取仍存在缺陷。

Conclusion: MARBLE揭示了当前MLLMs在复杂多模态推理上的局限性，有望推动新一代具备跨模态多步推理能力模型的发展。

Abstract: The ability to process information from multiple modalities and to reason
through it step-by-step remains a critical challenge in advancing artificial
intelligence. However, existing reasoning benchmarks focus on text-only
reasoning, or employ multimodal questions that can be answered by directly
retrieving information from a non-text modality. Thus, complex reasoning
remains poorly understood in multimodal domains. Here, we present MARBLE, a
challenging multimodal reasoning benchmark that is designed to scrutinize
multimodal language models (MLLMs) in their ability to carefully reason
step-by-step through complex multimodal problems and environments. MARBLE is
composed of two highly challenging tasks, M-Portal and M-Cube, that require the
crafting and understanding of multistep plans under spatial, visual, and
physical constraints. We find that current MLLMs perform poorly on MARBLE --
all the 12 advanced models obtain near-random performance on M-Portal and 0%
accuracy on M-Cube. Only in simplified subtasks some models outperform the
random baseline, indicating that complex reasoning is still a challenge for
existing MLLMs. Moreover, we show that perception remains a bottleneck, where
MLLMs occasionally fail to extract information from the visual inputs. By
shedding a light on the limitations of MLLMs, we hope that MARBLE will spur the
development of the next generation of models with the ability to reason and
plan across many, multimodal reasoning steps.

</details>


### [140] [AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks](https://arxiv.org/abs/2506.23049)
*Leander Melroy Maben,Gayathri Ganesh Lakshmy,Srijith Radhakrishnan,Siddhant Arora,Shinji Watanabe*

Main category: cs.AI

TL;DR: AURA是首个开源的语音原生助手，支持多轮对话、工具调用和智能推理，在复杂任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏开源的全语音对话系统，AURA旨在填补这一空白，实现语音驱动的多轮交互与工具调用。

Method: 采用级联式架构整合开源ASR、TTS和LLM，通过自然语言提示和动作类实现模块化工具集成（如日历、搜索等）。

Result: VoiceBench测试中92.75%准确率（超越所有开源系统），AlpacaEval得分4.39；人工评估多轮任务成功率90%。

Conclusion: AURA为开源语音助手树立了新标杆，其模块化设计和接近GPT-4o的性能证明语音代理系统的可行性。

Abstract: Despite advances in language and speech technologies, no open-source system
enables full speech-to-speech, multi-turn dialogue with integrated tool use and
agentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and
Automated Tool Use), the first open-source, speech-native assistant capable of
completing complex, goal-driven tasks through dynamic tool invocation and
multi-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a
cascaded pipeline and supports tools such as calendar booking, contact lookup,
web search, and email. Its modular design allows easy integration of new tools
using natural language prompts and action classes. On VoiceBench, AURA scores
92.75% on OpenBookQA-outperforming all open-weight systems and nearing
GPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems.
Human evaluation shows 90% task success on complex, multi-turn speech tasks.

</details>


### [141] [AI's Euclid's Elements Moment: From Language Models to Computable Thought](https://arxiv.org/abs/2506.23080)
*Xinmin Fang,Lingfeng Tao,Zhengxiong Li*

Main category: cs.AI

TL;DR: 本文提出一个五阶段进化框架，将人工智能发展类比人类认知技术史，揭示AI从专家系统到Transformer的架构演变，并预测其未来将进入'元语言时刻'，最终实现可证明对齐的可靠AI。


<details>
  <summary>Details</summary>
Motivation: 旨在超越隐喻层面，建立系统性跨学科模型，解释AI历史架构变迁（如专家系统到Transformer），并为下一代智能系统开发提供可操作路径。

Method: 采用'认知几何学'框架，通过类比人类认知技术（如楔形文字、微积分等）划分五个革命性阶段，分析AI表征与推理能力的跃迁，特别关注当前'元语言时刻'的自反特性。

Result: 揭示AI进化具有自反性：其工具与见解会重塑底层架构。预测未来将经历'数学符号时刻'（神经符号架构）和'形式逻辑系统时刻'（程序合成），最终实现自我重构基础表征的可靠AI。

Conclusion: 作为方法论三部曲终章，本框架为AI发展提供理论基础与实践策略，尤其对初创公司具有指导意义，标志着从经济驱动（'为何'）、认知本质（'是什么'）到实现路径（'如何'）的完整研究闭环。

Abstract: This paper presents a comprehensive five-stage evolutionary framework for
understanding the development of artificial intelligence, arguing that its
trajectory mirrors the historical progression of human cognitive technologies.
We posit that AI is advancing through distinct epochs, each defined by a
revolutionary shift in its capacity for representation and reasoning, analogous
to the inventions of cuneiform, the alphabet, grammar and logic, mathematical
calculus, and formal logical systems. This "Geometry of Cognition" framework
moves beyond mere metaphor to provide a systematic, cross-disciplinary model
that not only explains AI's past architectural shifts-from expert systems to
Transformers-but also charts a concrete and prescriptive path forward.
Crucially, we demonstrate that this evolution is not merely linear but
reflexive: as AI advances through these stages, the tools and insights it
develops create a feedback loop that fundamentally reshapes its own underlying
architecture. We are currently transitioning into a "Metalinguistic Moment,"
characterized by the emergence of self-reflective capabilities like
Chain-of-Thought prompting and Constitutional AI. The subsequent stages, the
"Mathematical Symbolism Moment" and the "Formal Logic System Moment," will be
defined by the development of a computable calculus of thought, likely through
neuro-symbolic architectures and program synthesis, culminating in provably
aligned and reliable AI that reconstructs its own foundational representations.
This work serves as the methodological capstone to our trilogy, which
previously explored the economic drivers ("why") and cognitive nature ("what")
of AI. Here, we address the "how," providing a theoretical foundation for
future research and offering concrete, actionable strategies for startups and
developers aiming to build the next generation of intelligent systems.

</details>


### [142] [Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study](https://arxiv.org/abs/2506.23107)
*Bing Song,Jianing Liu,Sisi Jian,Chenyang Wu,Vinayak Dixit*

Main category: cs.AI

TL;DR: 研究对比了大型语言模型（LLMs）与人类在风险决策中的表现，发现模型比人类更风险厌恶，且中文提示下的预测偏差更大。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）应用的扩展，其在模拟复杂决策行为（如风险决策）中的可靠性引发担忧，本研究旨在评估LLMs在此类任务中的表现。

Method: 研究使用彩票任务和交通偏好调查数据（来自悉尼、达卡、香港和南京的参与者），将ChatGPT 4o和o1-mini的预测与人类实际选择对比，并采用CRRA框架分析风险偏好。

Result: 两个模型均表现出比人类更风险厌恶的行为，其中o1-mini更接近人类决策；中文提示下的预测偏差显著高于英文。

Conclusion: LLMs在模拟人类风险行为方面展现出潜力，但在语言和文化情境中存在明显局限性，需进一步优化。

Abstract: Large language models (LLMs) have made significant strides, extending their
applications to dialogue systems, automated content creation, and
domain-specific advisory tasks. However, as their use grows, concerns have
emerged regarding their reliability in simulating complex decision-making
behavior, such as risky decision-making, where a single choice can lead to
multiple outcomes. This study investigates the ability of LLMs to simulate
risky decision-making scenarios. We compare model-generated decisions with
actual human responses in a series of lottery-based tasks, using transportation
stated preference survey data from participants in Sydney, Dhaka, Hong Kong,
and Nanjing. Demographic inputs were provided to two LLMs -- ChatGPT 4o and
ChatGPT o1-mini -- which were tasked with predicting individual choices. Risk
preferences were analyzed using the Constant Relative Risk Aversion (CRRA)
framework. Results show that both models exhibit more risk-averse behavior than
human participants, with o1-mini aligning more closely with observed human
decisions. Further analysis of multilingual data from Nanjing and Hong Kong
indicates that model predictions in Chinese deviate more from actual responses
compared to English, suggesting that prompt language may influence simulation
performance. These findings highlight both the promise and the current
limitations of LLMs in replicating human-like risk behavior, particularly in
linguistic and cultural settings.

</details>


### [143] [The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy](https://arxiv.org/abs/2506.23123)
*Rishi Bommasani*

Main category: cs.AI

TL;DR: 本文探讨了人工智能基础模型在社会与技术共同演进中的作用，提出了理解其能力、风险及治理框架的三重主题。


<details>
  <summary>Details</summary>
Motivation: 基础模型作为人工智能领域最具前景的技术，其潜在危害与社会影响尚未被充分理解，亟需建立科学基础和政策接口以实现更好的AI治理。

Method: 研究围绕三个主题展开：1) 基础模型的概念框架（能力、风险及经济供应链）；2) 通过模型评估和组织指数增强透明度；3) 从理解转向行动，推动基于证据的AI政策。

Result: 通过构建基础模型的科学基础和研究-政策接口，本研究为AI时代实现更优社会成果提供了理论支持和实践路径。

Conclusion: 该论文通过系统分析基础模型的社会技术协同演进机制，为改善AI治理体系奠定了关键基础，强调科学认知与政策制定的双向互动。

Abstract: Artificial intelligence is humanity's most promising technology because of
the remarkable capabilities offered by foundation models. Yet, the same
technology brings confusion and consternation: foundation models are poorly
understood and they may precipitate a wide array of harms. This dissertation
explains how technology and society coevolve in the age of AI, organized around
three themes. First, the conceptual framing: the capabilities, risks, and the
supply chain that grounds foundation models in the broader economy. Second, the
empirical insights that enrich the conceptual foundations: transparency created
via evaluations at the model level and indexes at the organization level.
Finally, the transition from understanding to action: superior understanding of
the societal impact of foundation models advances evidence-based AI policy.
View together, this dissertation makes inroads into achieving better societal
outcomes in the age of AI by building the scientific foundations and
research-policy interface required for better AI governance.

</details>


### [144] [Are Large Language Models Capable of Deep Relational Reasoning? Insights from DeepSeek-R1 and Benchmark Comparisons](https://arxiv.org/abs/2506.23128)
*Chi Chiu So,Yueyue Sun,Jun-Min Wang,Siu Pang Yung,Anthony Wai Keung Loh,Chun Pong Chau*

Main category: cs.AI

TL;DR: 本文评估了DeepSeek-R1、DeepSeek-V3和GPT-4o三种前沿大语言模型在家族树和通用图推理任务中的表现。实验表明DeepSeek-R1综合表现最优，但所有模型在问题复杂度增加时均表现不佳，暴露出输出不完整和推理不连贯等问题。研究为提升大语言模型的结构化多步推理能力提供了实证依据。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在深度关系推理任务中的实际能力边界，通过系统评估揭示当前模型的优势与局限性，为未来研究方向提供依据。

Method: 设计家族树和通用图推理基准任务，对比测试三种模型（DeepSeek-R1/V3、GPT-4o）的F1分数表现，重点分析DeepSeek-R1的思维链响应模式。

Result: DeepSeek-R1在多数任务中F1分数领先，但所有模型随问题复杂度增加性能显著下降。模型存在输出截断和推理不连贯现象，其验证策略展现独特规划能力。

Conclusion: 当前大语言模型在结构化推理任务中仍受限于长度约束和推理完整性。未来需研究多模态推理机制并系统分析失败案例，以提升复杂逻辑推断能力。代码库已开源。

Abstract: How far are Large Language Models (LLMs) in performing deep relational
reasoning? In this paper, we evaluate and compare the reasoning capabilities of
three cutting-edge LLMs, namely, DeepSeek-R1, DeepSeek-V3 and GPT-4o, through a
suite of carefully designed benchmark tasks in family tree and general graph
reasoning. Our experiments reveal that DeepSeek-R1 consistently achieves the
highest F1-scores across multiple tasks and problem sizes, demonstrating strong
aptitude in logical deduction and relational inference. However, all evaluated
models, including DeepSeek-R1, struggle significantly as problem complexity
increases, largely due to token length limitations and incomplete output
structures. A detailed analysis of DeepSeek-R1's long Chain-of-Thought
responses uncovers its unique planning and verification strategies, but also
highlights instances of incoherent or incomplete reasoning, calling attention
to the need for deeper scrutiny into LLMs' internal inference dynamics. We
further discuss key directions for future work, including the role of
multimodal reasoning and the systematic examination of reasoning failures. Our
findings provide both empirical insights and theoretical implications for
advancing LLMs' reasoning abilities, particularly in tasks that demand
structured, multi-step logical inference. Our code repository will be publicly
available at https://github.com/kelvinhkcs/Deep-Relational-Reasoning.

</details>


### [145] [Context-Driven Knowledge Graph Completion with Semantic-Aware Relational Message Passing](https://arxiv.org/abs/2506.23141)
*Siyuan Li,Ruitong Liu,Yan Wen,Te Sun*

Main category: cs.AI

TL;DR: 提出语义感知的关系消息传递框架，通过Top-K邻居选择策略和多头注意力聚合器，提升知识图谱补全任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于节点的消息传递机制在知识图谱中会引入噪声，并因 indiscriminately 聚合所有相邻边信息导致信息稀释或过平滑问题。

Method: 框架核心是语义感知的Top-K邻居选择策略：在共享潜在空间中评估中心节点与边的语义相关性，仅选择Top-K最相关边，并通过多头注意力聚合器融合信息生成语义聚焦的节点表示。

Result: 在多个基准测试中，该方法相比现有技术取得了更优的性能表现。

Conclusion: 该模型不仅能利用知识图谱的结构和边特征，还能精准捕捉与特定链接预测任务最相关的上下文信息，有效减少无关信息的干扰。

Abstract: Semantic context surrounding a triplet $(h, r, t)$ is crucial for Knowledge
Graph Completion (KGC), providing vital cues for prediction. However,
traditional node-based message passing mechanisms, when applied to knowledge
graphs, often introduce noise and suffer from information dilution or
over-smoothing by indiscriminately aggregating information from all neighboring
edges. To address this challenge, we propose a semantic-aware relational
message passing. A core innovation of this framework is the introduction of a
\textbf{semantic-aware Top-K neighbor selection strategy}. Specifically, this
strategy first evaluates the semantic relevance between a central node and its
incident edges within a shared latent space, selecting only the Top-K most
pertinent ones. Subsequently, information from these selected edges is
effectively fused with the central node's own representation using a
\textbf{multi-head attention aggregator} to generate a semantically focused
node message. In this manner, our model not only leverages the structure and
features of edges within the knowledge graph but also more accurately captures
and propagates the contextual information most relevant to the specific link
prediction task, thereby effectively mitigating interference from irrelevant
information. Extensive experiments demonstrate that our method achieves
superior performance compared to existing approaches on several established
benchmarks.

</details>


### [146] [FinStat2SQL: A Text2SQL Pipeline for Financial Statement Analysis](https://arxiv.org/abs/2506.23273)
*Quang Hung Nguyen,Phuong Anh Trinh,Phan Quoc Hung Mai,Tuan Phong Trinh*

Main category: cs.AI

TL;DR: FinStat2SQL是一种轻量级文本转SQL管道，专为金融报表的自然语言查询设计，结合大小语言模型，在越南企业环境中实现高效、低成本的财务分析。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型有所进步，文本转SQL在复杂和特定领域查询（如金融）仍面临挑战，尤其是不同金融实体和国家间的数据库设计与报表布局差异。

Method: 采用多智能体设置，结合大小语言模型进行实体提取、SQL生成和自我校正，针对越南会计准则（VAS）定制，并构建特定领域数据库进行评估。

Result: 微调的7B模型在合成QA数据集上达到61.33%准确率，响应时间低于4秒，在消费级硬件上优于GPT-4o-mini。

Conclusion: FinStat2SQL为越南企业提供了可扩展、经济高效的AI驱动查询解决方案，使财务分析更加普及。

Abstract: Despite the advancements of large language models, text2sql still faces many
challenges, particularly with complex and domain-specific queries. In finance,
database designs and financial reporting layouts vary widely between financial
entities and countries, making text2sql even more challenging. We present
FinStat2SQL, a lightweight text2sql pipeline enabling natural language queries
over financial statements. Tailored to local standards like VAS, it combines
large and small language models in a multi-agent setup for entity extraction,
SQL generation, and self-correction. We build a domain-specific database and
evaluate models on a synthetic QA dataset. A fine-tuned 7B model achieves
61.33\% accuracy with sub-4-second response times on consumer hardware,
outperforming GPT-4o-mini. FinStat2SQL offers a scalable, cost-efficient
solution for financial analysis, making AI-powered querying accessible to
Vietnamese enterprises.

</details>


### [147] [Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games](https://arxiv.org/abs/2506.23276)
*David Guzman Piedrahita,Yongjin Yang,Mrinmaya Sachan,Giorgia Ramponi,Bernhard Schölkopf,Zhijing Jin*

Main category: cs.AI

TL;DR: 研究探讨大型语言模型（LLM）在多智能体系统中如何平衡自利与集体利益，发现不同模型在合作行为上存在显著差异，推理能力强的模型反而不易达成合作。


<details>
  <summary>Details</summary>
Motivation: 随着LLM作为自主智能体部署的增加，理解其合作机制及如何平衡个体与集体利益对确保模型对齐、鲁棒性和安全部署至关重要。

Method: 通过改编行为经济学中的公共物品博弈实验，观察不同LLM在重复互动中如何应对社会困境，特别关注资源投入以激励合作或惩罚背叛的行为。

Result: 发现四种行为模式：稳定高合作型、波动参与型、合作衰退型及策略僵化型。出乎意料的是，推理能力强的o1系列模型合作表现较差，而部分传统LLM反而能持续达成高效合作。

Conclusion: 当前提升LLM推理能力的优化方向未必能促进合作行为，这对需要持续协作的环境部署LLM智能体具有重要启示。代码已开源。

Abstract: As large language models (LLMs) are increasingly deployed as autonomous
agents, understanding their cooperation and social mechanisms is becoming
increasingly important. In particular, how LLMs balance self-interest and
collective well-being is a critical challenge for ensuring alignment,
robustness, and safe deployment. In this paper, we examine the challenge of
costly sanctioning in multi-agent LLM systems, where an agent must decide
whether to invest its own resources to incentivize cooperation or penalize
defection. To study this, we adapt a public goods game with institutional
choice from behavioral economics, allowing us to observe how different LLMs
navigate social dilemmas over repeated interactions. Our analysis reveals four
distinct behavioral patterns among models: some consistently establish and
sustain high levels of cooperation, others fluctuate between engagement and
disengagement, some gradually decline in cooperative behavior over time, and
others rigidly follow fixed strategies regardless of outcomes. Surprisingly, we
find that reasoning LLMs, such as the o1 series, struggle significantly with
cooperation, whereas some traditional LLMs consistently achieve high levels of
cooperation. These findings suggest that the current approach to improving
LLMs, which focuses on enhancing their reasoning capabilities, does not
necessarily lead to cooperation, providing valuable insights for deploying LLM
agents in environments that require sustained collaboration. Our code is
available at https://github.com/davidguzmanp/SanctSim

</details>


### [148] [GATSim: Urban Mobility Simulation with Generative Agents](https://arxiv.org/abs/2506.23306)
*Qi Liu,Can Li,Wanjing Ma*

Main category: cs.AI

TL;DR: 本文提出GATSim框架，利用大语言模型和AI代理技术创建具有丰富行为特征的生成式代理，用于城市交通模拟，相比传统基于规则的系统更能捕捉人类出行决策的复杂性和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的代理模拟无法充分反映人类出行决策的复杂性、适应性和行为多样性，而大语言模型和AI代理技术的进步为解决这一问题提供了新机遇。

Method: GATSim结合城市交通基础模型、代理认知系统和交通模拟环境，通过心理启发的记忆系统、工具使用能力和终身学习机制，创建具有社会经济属性、生活方式和动态偏好的生成式代理。

Result: 实验表明生成式代理能产生可信的出行行为，在交通场景中表现与人类标注者相当，并能自然形成宏观交通演化模式。原型系统代码已开源。

Conclusion: GATSim框架通过生成式代理实现了更真实的城市交通模拟，其反思机制使代理能将具体出行经验转化为通用认知，从而实现随时间推移的行为适应。

Abstract: Traditional agent-based urban mobility simulations rely on rigid rule-based
systems that fail to capture the complexity, adaptability, and behavioral
diversity characteristic of human travel decision-making. Recent advances in
large language models and AI agent technology offer opportunities to create
agents with reasoning capabilities, persistent memory, and adaptive learning
mechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel
framework that leverages these advances to create generative agents with rich
behavioral characteristics for urban mobility simulation. Unlike conventional
approaches, GATSim agents possess diverse socioeconomic attributes, individual
lifestyles, and evolving preferences that shape their mobility decisions
through psychologically-informed memory systems, tool usage capabilities, and
lifelong learning mechanisms. The main contributions of this study include: (1)
a comprehensive architecture combining an urban mobility foundation model with
agent cognitive systems and transport simulation environment, (2) a fully
functional prototype implementation, and (3) systematic validation
demonstrating that generative agents produce believable travel behaviors.
Through designed reflection processes, generative agents in this study can
transform specific travel experiences into generalized insights, enabling
realistic behavioral adaptation over time with specialized mechanisms for
activity planning and real-time reactive behaviors tailored to urban mobility
contexts. Experiments show that generative agents perform competitively with
human annotators in mobility scenarios while naturally producing macroscopic
traffic evolution patterns. The code for the prototype system is shared at
https://github.com/qiliuchn/gatsim.

</details>


### [149] [The Confidence Paradox: Can LLM Know When It's Wrong](https://arxiv.org/abs/2506.23464)
*Sahil Tripathi,Md Tabrez Nafis,Imran Hussain,Jiechao Gao*

Main category: cs.AI

TL;DR: 本文提出HonestVQA框架，通过自监督诚实校准解决文档视觉问答（DocVQA）中的伦理问题，提升模型置信度与准确性的对齐，并在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有DocVQA系统（如LayoutLMv3、UDOP、DONUT）在伦理响应性方面存在不足，常对模糊问题给出过度自信的答案，缺乏可信的不确定性传达，这在需要伦理问责的领域存在重大风险。

Method: HonestVQA采用模型无关方法：1）量化不确定性以识别知识缺口；2）使用加权损失函数对齐模型置信度与实际正确性；3）通过对比学习强制伦理响应行为。同时提出H-Score和ECI两项评估指标。

Result: 实验表明，HonestVQA在SpDocVQA等数据集上准确率提升4.3%，F1值提升4.3%，H-Score和ECI分别降低0.072和0.078。跨领域评估中达到78.9%准确率和76.1% F1值，消融实验显示未对齐或缺失对比损失会导致准确率下降3.8%。

Conclusion: HonestVQA通过伦理对齐机制显著改善了DocVQA系统的可信度与泛化能力，为伦理敏感的文档理解任务提供了可量化的解决方案框架。

Abstract: Document Visual Question Answering (DocVQA) systems are increasingly deployed
in real world applications, yet they remain ethically opaque-often producing
overconfident answers to ambiguous questions or failing to communicate
uncertainty in a trustworthy manner. This misalignment between model confidence
and actual knowledge poses significant risks, particularly in domains requiring
ethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT
have advanced SOTA performance by focusing on architectural sophistication and
accuracy; however, they fall short in ethical responsiveness.
  To address these limitations, we introduce HonestVQA, a self-supervised
honesty calibration framework for ethically aligned DocVQA. Our model-agnostic
method quantifies uncertainty to identify knowledge gaps, aligns model
confidence with actual correctness using weighted loss functions, and enforces
ethical response behavior via contrastive learning. We further introduce two
principled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence
Index (ECI)--to benchmark alignment between confidence, accuracy, and ethical
communication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3%
and F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces
overconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In
cross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score,
demonstrating strong generalization. Ablation shows a 3.8% drop in accuracy
without alignment or contrastive loss.

</details>


### [150] [Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence](https://arxiv.org/abs/2506.23503)
*Bosubabu Sambana,Kondreddygari Archana,Suram Indhra Sena Reddy,Shaik Meethaigar Jameer Basha,Shaik Karishma*

Main category: cs.AI

TL;DR: 该论文提出了一种基于认知行为疗法（CBT）的框架，通过情感分析和文本处理技术，从社交媒体数据中识别负面情绪和认知扭曲，以辅助心理治疗师进行早期干预。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏有效分析社交媒体中认知路径的方法，而这些数据可能包含用户的心理健康问题线索，如认知扭曲和自杀倾向，亟需工具支持在线心理干预。

Method: 系统整合BERT、RoBERTa进行情感分析，T5、PEGASUS实现文本摘要，mT5处理多语言翻译，通过数据增强技术分类文本与视觉内容，并扩展预测其他心理健康问题（如恐惧症、进食障碍）。

Result: 该框架不仅能识别负面思维，还能预测潜在心理健康并发症，为治疗师提供更全面的早期检测和干预策略。

Conclusion: 结合CBT与NLP技术的系统可增强对社交媒体用户心理状态的洞察，成为心理治疗领域有效的数字化辅助工具。

Abstract: Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the
irrational thought patterns associated with mental health disorders, but its
effectiveness relies on accurately identifying cognitive pathways to provide
targeted treatment. In today's digital age, individuals often express negative
emotions on social media, where they may reveal cognitive distortions, and in
severe cases, exhibit suicidal tendencies. However, there is a significant gap
in methodologies designed to analyze these cognitive pathways, which could be
critical for psychotherapists aiming to deliver timely and effective
interventions in online environments. Cognitive Behavioral Therapy (CBT)
framework leveraging acceptance, commitment and data augmentation to categorize
and address both textual and visual content as positive or negative.
Specifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5,
PEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages
focusing on detecting negative emotions and cognitive distortions within social
media data. While existing models are primarily designed to identify negative
thoughts, the proposed system goes beyond this by predicting additional
negative side effects and other potential mental health disorders likes
Phobias, Eating Disorders. This enhancement allows for a more comprehensive
understanding and intervention strategy, offering psychotherapists a powerful
tool for early detection and treatment of various psychological issues.

</details>


### [151] [Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM](https://arxiv.org/abs/2506.23504)
*Bosubabu Sambana,Kotamsetty Geethika Devi,Bandi Rajeswara Reddy,Galeti Mohammad Hussain,Gownivalla Siddartha*

Main category: cs.AI

TL;DR: 本文提出了一种结合AlexNet和LSTM的混合模型，用于提高电力价格预测的准确性。该模型通过整合外部变量（如需求、温度、阳光和降雨）并使用最小-最大缩放和时间窗口等方法，显著提升了预测性能。实验结果显示，该混合模型的准确率达到97.08%，优于单独的RNN和ANN模型。


<details>
  <summary>Details</summary>
Motivation: 传统的电力价格预测方法（如RNN和ANN）在处理外汇时间序列数据时表现不佳，且仅关注需求和价格，导致数据分析不足。为了解决这一问题，本文提出了一种混合模型，通过引入外部变量来提高预测准确性。

Method: 该模型结合了AlexNet的优秀特征提取能力和LSTM的序列模式学习能力，并整合了需求、温度、阳光和降雨等关键因素。此外，还采用了最小-最大缩放和时间窗口等技术来优化预测。

Result: 实验结果表明，该混合模型的预测准确率达到97.08%，高于单独的RNN（96.64%）和ANN（96.63%）模型，证明了其在电力价格预测中的优越性。

Conclusion: 本文提出的AlexNet与LSTM混合模型在电力价格预测中表现出更高的准确性和鲁棒性，为未来研究提供了新的方向。

Abstract: The recent development of advanced machine learning methods for hybrid models
has greatly addressed the need for the correct prediction of electrical prices.
This method combines AlexNet and LSTM algorithms, which are used to introduce a
new model with higher accuracy in price forecasting. Despite RNN and ANN being
effective, they often fail to deal with forex time sequence data. The
traditional methods do not accurately forecast the prices. These traditional
methods only focus on demand and price which leads to insufficient analysis of
data. To address this issue, using the hybrid approach, which focuses on
external variables that also effect the predicted prices. Nevertheless, due to
AlexNet's excellent feature extraction and LSTM's learning sequential patterns,
the prediction accuracy is vastly increased. The model is built on the past
data, which has been supplied with the most significant elements like demand,
temperature, sunlight, and rain. For example, the model applies methods, such
as minimum-maximum scaling and a time window, to predict the electricity prices
of the future. The results show that this hybrid model is good than the
standalone ones in terms of accuracy. Although we got our accuracy rating of
97.08, it shows higher accompaniments than remaining models RNN and ANN with
accuracies of 96.64 and 96.63 respectively.

</details>


### [152] [Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays](https://arxiv.org/abs/2506.23517)
*Selin Dik,Osman Erdem,Mehmet Dik*

Main category: cs.AI

TL;DR: 研究评估GPTZero检测AI生成文本的准确性，发现其对纯AI文本识别率高，但对人类文本存在误判，建议教育者谨慎依赖此类工具。


<details>
  <summary>Details</summary>
Motivation: 随着学生使用AI工具增多，教师依赖GPTZero等检测工具，但其可靠性存疑，需验证其在不同文本长度下的表现。

Method: 收集28篇AI生成和50篇人类撰写的随机长度论文（短/中/长），通过GPTZero检测AI生成百分比及置信度。

Result: AI生成文本检测准确率高达91-100%，但人类文本存在波动及误判，显示工具在区分人类作者方面有限。

Conclusion: GPTZero对纯AI文本有效，但人类文本识别不可靠，教育者需避免单一依赖AI检测工具。

Abstract: As the use of AI tools by students has become more prevalent, instructors
have started using AI detection tools like GPTZero and QuillBot to detect AI
written text. However, the reliability of these detectors remains uncertain. In
our study, we focused mostly on the success rate of GPTZero, the most-used AI
detector, in identifying AI-generated texts based on different lengths of
randomly submitted essays: short (40-100 word count), medium (100-350 word
count), and long (350-800 word count). We gathered a data set consisting of
twenty-eight AI-generated papers and fifty human-written papers. With this
randomized essay data, papers were individually plugged into GPTZero and
measured for percentage of AI generation and confidence. A vast majority of the
AI-generated papers were detected accurately (ranging from 91-100% AI believed
generation), while the human generated essays fluctuated; there were a handful
of false positives. These findings suggest that although GPTZero is effective
at detecting purely AI-generated content, its reliability in distinguishing
human-authored texts is limited. Educators should therefore exercise caution
when relying solely on AI detection tools.

</details>


### [153] [ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data](https://arxiv.org/abs/2506.23520)
*Yu Zhang,Ruijie Yu,Jidong Tian,Feng Zhu,Jiapeng Liu,Xiaokang Yang,Yaohui Jin,Yanyan Xu*

Main category: cs.AI

TL;DR: ChemActor是一种基于大型语言模型（LLM）的化学执行器，用于将非结构化的化学实验步骤转换为结构化的操作序列。通过LLM生成的数据框架和多轮评审指标，该模型在反应到描述（R2D）和描述到操作（D2A）任务中表现优异，性能提升10%。


<details>
  <summary>Details</summary>
Motivation: 随着有机化学中机器人合成的兴趣增加，从文献中自动提取化学步骤变得至关重要。然而，由于化学语言的固有模糊性和人工标注的高成本，这一任务仍然具有挑战性。

Method: ChemActor是一个完全微调的大型语言模型（LLM），通过顺序LLM生成的数据框架解决标注数据不足和质量低的问题。该框架集成了基于分布差异的数据选择模块和通用LLM，从单个分子输入生成机器可执行的操作。此外，还引入了多轮LLM循环评审指标，以反映模型对化学实验步骤的高级理解。

Result: 在反应到描述（R2D）和描述到操作（D2A）任务上的大量实验表明，ChemActor通过LLM生成的数据增强，实现了最先进的性能，比基线模型高出10%。

Conclusion: ChemActor通过LLM生成的数据框架和多轮评审指标，显著提升了化学实验步骤的自动化提取性能，为有机化学中的机器人合成提供了可靠的工具。代码已开源：https://github.com/Zhanghahah/ChemActor。

Abstract: With the increasing interest in robotic synthesis in the context of organic
chemistry, the automated extraction of chemical procedures from literature is
critical. However, this task remains challenging due to the inherent ambiguity
of chemical language and the high cost of human annotation required for
developing reliable computer-aided extraction protocols. Here, we present
ChemActor, a fully fine-tuned large language model (LLM), as a chemical
executor to convert between unstructured experimental procedures and structured
action sequences. We propose a sequential LLM-generated data framework to
address the challenges of insufficient and low-quality annotated data. This
framework integrates a data selection module that selects data based on
distribution divergence, with a general-purpose LLM, to generate
machine-executable actions from a single molecule input. Additionally, we
introduce a novel multi-round LLMs circle review metric, which reflects the
model's advanced understanding of chemical experimental procedures. Extensive
experiments on reaction-to-description (R2D) and description-to-action (D2A)
tasks demonstrate that ChemActor, augmented by LLM-generated data, achieves
state-of-the-art performance, outperforming the baseline model by 10%. The code
is available at: https://github.com/Zhanghahah/ChemActor.

</details>


### [154] [CooT: Learning to Coordinate In-Context with Coordination Transformers](https://arxiv.org/abs/2506.23549)
*Huai-Chih Wang,Hsiang-Chun Chuang,Hsi-Chun Cheng,Dai-Jie Wu,Shao-Hua Sun*

Main category: cs.AI

TL;DR: 本文提出协调变换器(CooT)，一种基于交互历史快速适应未知伙伴的新型多智能体协调框架，在Overcooked基准测试中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如自博弈和群体训练）在泛化性和训练成本方面存在局限，需要一种能快速适应新伙伴行为的协调框架。

Method: CooT通过分析近期交互历史预测伙伴行为，利用互补行为智能体对的交互轨迹进行无监督训练，无需微调即可学习协调策略。

Result: 在Overcooked测试中，CooT对未知伙伴的协调表现显著优于基线；人类评估确认其协作有效性，消融实验验证了框架的鲁棒性和情境敏感性。

Conclusion: CooT通过情境化协调机制突破了传统方法的局限性，为动态不确定环境下的多智能体协作提供了新范式。

Abstract: Effective coordination among artificial agents in dynamic and uncertain
environments remains a significant challenge in multi-agent systems. Existing
approaches, such as self-play and population-based methods, either generalize
poorly to unseen partners or require extensive training. To overcome these
limitations, we propose Coordination Transformers (CooT), a novel in-context
coordination framework that uses recent interaction histories to adapt to
unseen partners rapidly. Unlike previous approaches that primarily aim to
increase the diversity of training partners, CooT explicitly focuses on
adapting to new partner behaviors by predicting actions aligned with observed
partner interactions. Trained on interaction trajectories collected from
diverse pairs of agents with complementary behaviors, CooT quickly learns
effective coordination strategies without explicit supervision or fine-tuning.
Evaluations on the Overcooked benchmark demonstrate that CooT significantly
outperforms baseline methods in coordination tasks involving previously unseen
partners. Human evaluations further confirm CooT as the most effective
collaborative partner, while extensive ablations highlight its robustness,
flexibility, and sensitivity to context in multi-agent scenarios.

</details>


### [155] [MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI](https://arxiv.org/abs/2506.23563)
*Huanjin Yao,Jiaxing Huang,Yawen Qiu,Michael K. Chen,Wenzheng Liu,Wei Zhang,Wenjie Zeng,Xikun Zhang,Jingyi Zhang,Yuxin Song,Wenhao Wu,Dacheng Tao*

Main category: cs.AI

TL;DR: 本文提出MMReason基准，旨在精准评估多模态大语言模型的长链推理能力，通过多样化、开放式难题及分步评分机制填补现有评估空白。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM基准在长链推理评估上存在三大缺陷：难度与多样性不足、易受猜测与记忆干扰、缺乏中间步骤评估。MMReason旨在解决这些问题。

Method: 1) 从6个学科领域收集需多步推理的难题；2) 采用开放式问题格式并通过多模型投票过滤捷径案例；3) 标注详细分步解答案例并设计三元评分机制评估推理过程。

Result: 基于MMReason对主流MLLM进行测试，深入分析了模型推理能力差异。基准代码开源在https://github.com/HJYao00/MMReason。

Conclusion: MMReason为推进MLLM推理研究提供了标准化评估工具，其多维度设计有望促进AGI领域的长链推理能力发展。

Abstract: Reasoning plays a crucial role in advancing Multimodal Large Language Models
(MLLMs) toward Artificial General Intelligence. However, existing MLLM
benchmarks often fall short in precisely and comprehensively evaluating
long-chain reasoning abilities from three key aspects: (1) lack of difficulty
and diversity, (2) susceptibility to guessability and memorization, (3)
inadequate assessment of intermediate reasoning steps. To fill this gap, we
introduce MMReason, a new benchmark designed to precisely and comprehensively
evaluate MLLM long-chain reasoning capability with diverse, open-ended,
challenging questions. First, we curate challenging questions requiring
multi-step reasoning from various fields (i.e., 6 disciplines) and multiple
difficulty levels (i.e., from pre-university to university, and from
foundational to competition tiers). Second, these questions are reformulated
into an open-ended format and filtered using a multi-model voting technique to
eliminate shortcut cases related to guessing and memorization, ensuring robust
reasoning evaluations. Third, we annotate the questions with detailed
step-by-step solutions, and design a reference-based ternary scoring mechanism
to reliably assess intermediate reasoning steps. With MMReason, we benchmark
popular leading MLLMs and provide an in-depth analysis of their reasoning
capabilities. We hope MMReason will serve as a valuable resource for advancing
MLLM reasoning research. Code will be available at
https://github.com/HJYao00/MMReason.

</details>


### [156] [Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models](https://arxiv.org/abs/2506.23576)
*Maria Carolina Cornelia Wit,Jun Pang*

Main category: cs.AI

TL;DR: 研究探讨多智能体大语言模型系统作为防御越狱攻击的有效性，发现其能提升安全性但存在误报和计算开销的权衡。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型越狱攻击（如绕过安全机制的提示）日益增多，需探索更有效的防御策略。

Method: 复现AutoDefense框架，对比单智能体与多智能体（双/三智能体）配置，评估三种越狱策略（AutoDefense、BetterDan、JB）的防御效果。

Result: 多智能体系统显著降低漏检率，但对不同攻击类型效果不一，同时增加误报率和计算负担。

Conclusion: 当前自动化防御存在局限性，未来需提升大语言模型对齐鲁棒性以平衡安全性与效率。

Abstract: Recent advances in large language models (LLMs) have raised concerns about
jailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper
investigates the use of multi-agent LLM systems as a defence against such
attacks. We evaluate three jailbreaking strategies, including the original
AutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the
AutoDefense framework, we compare single-agent setups with two- and three-agent
configurations. Our results show that multi-agent systems enhance resistance to
jailbreaks, especially by reducing false negatives. However, its effectiveness
varies by attack type, and it introduces trade-offs such as increased false
positives and computational overhead. These findings point to the limitations
of current automated defences and suggest directions for improving alignment
robustness in future LLM systems.

</details>


### [157] [Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games](https://arxiv.org/abs/2506.23626)
*António Afonso,Iolanda Leite,Alessandro Sestini,Florian Fuchs,Konrad Tollmar,Linus Gisslén*

Main category: cs.AI

TL;DR: 本文提出了一种基于语言模型的自动化方法，用于迭代优化强化学习代理的奖励函数权重，无需人工干预即可实现行为对齐，并在赛车任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在游戏中部署强化学习代理面临两大挑战：设计有效奖励函数需要专家知识，且游戏内容变更会导致原有奖励权重失效。本文旨在解决后者，实现奖励权重的自动化调整。

Method: 通过语言模型根据用户定义的行为目标和历史训练统计，迭代提出更新的奖励权重，形成自我修正的闭环优化过程，无需人工设计奖励函数。

Result: 实验显示：语言模型引导的代理在赛车任务中单次迭代成功率从$9\%$提升至$74\%$；最终迭代达到$80\%$成功率（人类专家为$94\%$），平均用时$855$步（专家为$850$步）。

Conclusion: 该方法通过语言模型自动化调整奖励权重，显著提升了强化学习代理的性能表现，为游戏环境中的动态优化提供了有效解决方案。

Abstract: Reinforcement Learning (RL) in games has gained significant momentum in
recent years, enabling the creation of different agent behaviors that can
transform a player's gaming experience. However, deploying RL agents in
production environments presents two key challenges: (1) designing an effective
reward function typically requires an RL expert, and (2) when a game's content
or mechanics are modified, previously tuned reward weights may no longer be
optimal. Towards the latter challenge, we propose an automated approach for
iteratively fine-tuning an RL agent's reward function weights, based on a
user-defined language based behavioral goal. A Language Model (LM) proposes
updated weights at each iteration based on this target behavior and a summary
of performance statistics from prior training rounds. This closed-loop process
allows the LM to self-correct and refine its output over time, producing
increasingly aligned behavior without the need for manual reward engineering.
We evaluate our approach in a racing task and show that it consistently
improves agent performance across iterations. The LM-guided agents show a
significant increase in performance from $9\%$ to $74\%$ success rate in just
one iteration. We compare our LM-guided tuning against a human expert's manual
weight design in the racing task: by the final iteration, the LM-tuned agent
achieved an $80\%$ success rate, and completed laps in an average of $855$ time
steps, a competitive performance against the expert-tuned agent's peak $94\%$
success, and $850$ time steps.

</details>


### [158] [HASD: Hierarchical Adaption for pathology Slide-level Domain-shift](https://arxiv.org/abs/2506.23673)
*Jingsong Liu,Han Li,Chen Yang,Michael Deutges,Ario Sadafi,Xin You,Katharina Breininger,Nassir Navab,Peter J. Schüffler*

Main category: cs.AI

TL;DR: 本文提出了一种针对病理学AI中切片级域偏移问题的分层适配框架HASD，通过多尺度特征一致性和计算高效的适配方法，在乳腺癌HER2分级和UCEC生存预测任务中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 病理学AI面临中心特异性条件导致的域偏移问题，现有方法仅关注图像块而忽略全切片图像(WSI)的全局特征，无法满足临床需求。

Method: HASD框架包含：(1)分层适配组件（域级对齐求解器、切片级几何不变性正则化、块级注意力一致性正则化）；(2)降低计算开销的原型选择机制。

Result: 在五个数据集的两种切片级任务中，乳腺癌HER2分级队列AUROC提升4.1\%，UCEC生存预测队列C-index提高3.9\%。

Conclusion: HASD为病理机构提供了实用可靠的切片级域适配方案，显著降低了计算和标注成本。

Abstract: Domain shift is a critical problem for pathology AI as pathology data is
heavily influenced by center-specific conditions. Current pathology domain
adaptation methods focus on image patches rather than WSI, thus failing to
capture global WSI features required in typical clinical scenarios. In this
work, we address the challenges of slide-level domain shift by proposing a
Hierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD
achieves multi-scale feature consistency and computationally efficient
slide-level domain adaptation through two key components: (1) a hierarchical
adaptation framework that integrates a Domain-level Alignment Solver for
feature alignment, a Slide-level Geometric Invariance Regularization to
preserve the morphological structure, and a Patch-level Attention Consistency
Regularization to maintain local critical diagnostic cues; and (2) a prototype
selection mechanism that reduces computational overhead. We validate our method
on two slide-level tasks across five datasets, achieving a 4.1\% AUROC
improvement in a Breast Cancer HER2 Grading cohort and a 3.9\% C-index gain in
a UCEC survival prediction cohort. Our method provides a practical and reliable
slide-level domain adaption solution for pathology institutions, minimizing
both computational and annotation costs.

</details>


### [159] [PokéAI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red](https://arxiv.org/abs/2506.23689)
*Zihao Liu,Xinhang Sui,Yueran Song,Siwen Wang*

Main category: cs.AI

TL;DR: Pok\'eAI是首个基于文本的多智能体大语言模型框架，能自主玩《口袋妖怪红》并推进游戏进程，包含规划、执行、评估三个专业模块，战斗AI胜率达80.8%，且语言能力与战略推理存在关联。


<details>
  <summary>Details</summary>
Motivation: 开发首个能自主玩《口袋妖怪红》的多智能体LLM框架，探索语言模型在复杂游戏环境中的战略决策能力。

Method: 采用三智能体闭环系统：规划Agent生成任务，执行Agent操作游戏，评估Agent验证结果；其中执行Agent内置战斗模块进行性能测试。

Result: 战斗模块在50场野外对战中平均胜率80.8%（仅比人类玩家低6%），LLM竞技场分数与战斗表现强相关，不同模型展现出独特游戏风格。

Conclusion: Pok\'eAI证明了LLM在复杂游戏中的战略潜力，语言能力与游戏表现存在正相关，且模型会发展出个性化策略行为。

Abstract: We introduce Pok\'eAI, the first text-based, multi-agent large language model
(LLM) framework designed to autonomously play and progress through Pok\'emon
Red. Our system consists of three specialized agents-Planning, Execution, and
Critique-each with its own memory bank, role, and skill set. The Planning Agent
functions as the central brain, generating tasks to progress through the game.
These tasks are then delegated to the Execution Agent, which carries them out
within the game environment. Upon task completion, the Critique Agent evaluates
the outcome to determine whether the objective was successfully achieved. Once
verification is complete, control returns to the Planning Agent, forming a
closed-loop decision-making system.
  As a preliminary step, we developed a battle module within the Execution
Agent. Our results show that the battle AI achieves an average win rate of
80.8% across 50 wild encounters, only 6% lower than the performance of an
experienced human player. Furthermore, we find that a model's battle
performance correlates strongly with its LLM Arena score on language-related
tasks, indicating a meaningful link between linguistic ability and strategic
reasoning. Finally, our analysis of gameplay logs reveals that each LLM
exhibits a unique playstyle, suggesting that individual models develop distinct
strategic behaviors.

</details>


### [160] [Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models](https://arxiv.org/abs/2506.23692)
*Boyuan Zheng,Zerui Fang,Zhe Xu,Rui Wang,Yiwen Chen,Cunshi Wang,Mengwei Qu,Lei Lei,Zhen Feng,Yan Liu,Yuyang Li,Mingzhou Tan,Jiaji Wu,Jianwei Shuai,Jia Li,Fangfu Ye*

Main category: cs.AI

TL;DR: 论文提出'科学代理'(Agent4S)作为第五科学范式，通过LLM驱动代理自动化整个科研流程，取代当前AI4S的低效模式，并制定了五级分类路线图。


<details>
  <summary>Details</summary>
Motivation: 当前AI4S仅作为分析工具存在，未能解决科研核心效率问题，需要转向完全自动化的新型研究范式。

Method: 提出五级分类框架：从基础任务自动化到完全自主协作的'AI科学家'，系统规划Agent4S发展路径。

Result: 构建了从工具辅助到群体智能的渐进式发展体系，定义了科学发现革命的下一阶段形态。

Conclusion: Agent4S通过全流程自动化将引发科研范式革命，五级分类为实现真正自主的'AI科学家'提供明确路线图。

Abstract: While AI for Science (AI4S) serves as an analytical tool in the current
research paradigm, it doesn't solve its core inefficiency. We propose "Agent
for Science" (Agent4S)-the use of LLM-driven agents to automate the entire
research workflow-as the true Fifth Scientific Paradigm. This paper introduces
a five-level classification for Agent4S, outlining a clear roadmap from simple
task automation to fully autonomous, collaborative "AI Scientists." This
framework defines the next revolutionary step in scientific discovery.

</details>


### [161] [A New Perspective On AI Safety Through Control Theory Methodologies](https://arxiv.org/abs/2506.23703)
*Lars Ullrich,Walter Zimmer,Ross Greer,Knut Graichen,Alois C. Knoll,Mohan Trivedi*

Main category: cs.AI

TL;DR: 本文提出了一种基于系统理论和数据分析的新视角，旨在通过跨学科方法提升人工智能（AI）在安全关键系统中的应用安全性。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的快速发展，其在安全关键领域的应用日益广泛，但缺乏有效的安全保障机制，这成为制约AI进一步自主化的主要障碍。

Method: 文章提出了一种称为“数据控制”的新视角，结合控制理论和AI技术，通过系统分析和跨学科方法，为AI系统提供通用的安全分析和保障基础。

Result: 该方法在抽象层面为AI系统的安全分析和保障提供了通用框架，可针对具体AI系统和应用进行细化，并为未来的创新做好准备。

Conclusion: 通过整合控制理论和AI技术，数据控制的新视角有望推动AI工程在安全关键领域中的跨学科应用，从而提升AI系统的整体安全性。

Abstract: While artificial intelligence (AI) is advancing rapidly and mastering
increasingly complex problems with astonishing performance, the safety
assurance of such systems is a major concern. Particularly in the context of
safety-critical, real-world cyber-physical systems, AI promises to achieve a
new level of autonomy but is hampered by a lack of safety assurance. While
data-driven control takes up recent developments in AI to improve control
systems, control theory in general could be leveraged to improve AI safety.
Therefore, this article outlines a new perspective on AI safety based on an
interdisciplinary interpretation of the underlying data-generation process and
the respective abstraction by AI systems in a system theory-inspired and system
analysis-driven manner. In this context, the new perspective, also referred to
as data control, aims to stimulate AI engineering to take advantage of existing
safety analysis and assurance in an interdisciplinary way to drive the paradigm
of data control. Following a top-down approach, a generic foundation for safety
analysis and assurance is outlined at an abstract level that can be refined for
specific AI systems and applications and is prepared for future innovation.

</details>


### [162] [Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments](https://arxiv.org/abs/2506.23706)
*Christoph Schnabl,Daniel Hugenroth,Bill Marino,Alastair R. Beresford*

Main category: cs.AI

TL;DR: 本文提出了一种名为'可验证审计'的新方法，通过在可信执行环境中运行，确保AI模型的安全性与合规性评估可验证且保护数据隐私。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法提供可验证结果，且缺乏对模型知识产权和基准数据集保密性的保护，难以满足近期AI治理框架提出的验证需求。

Method: 采用可信执行环境技术构建'可验证审计'系统，使模型提供方与审计方在互不信任的情况下仍能保护敏感数据。

Result: 基于Llama-3.1的原型实验证明，该方法在典型审计基准测试中具有可行性。

Conclusion: 可验证审计方案有效解决了AI治理中的验证挑战，为模型合规性评估提供了兼具可验证性和保密性的新途径。

Abstract: Benchmarks are important measures to evaluate safety and compliance of AI
models at scale. However, they typically do not offer verifiable results and
lack confidentiality for model IP and benchmark datasets. We propose Attestable
Audits, which run inside Trusted Execution Environments and enable users to
verify interaction with a compliant AI model. Our work protects sensitive data
even when model provider and auditor do not trust each other. This addresses
verification challenges raised in recent AI governance frameworks. We build a
prototype demonstrating feasibility on typical audit benchmarks against
Llama-3.1.

</details>


### [163] [BayesL: Towards a Logical Framework for Bayesian Networks](https://arxiv.org/abs/2506.23773)
*Stefano M. Nicoletti,Mariëlle Stoelinga*

Main category: cs.AI

TL;DR: 论文提出BayesL，一种用于贝叶斯网络(BNs)行为规范、查询与验证的新型逻辑框架。


<details>
  <summary>Details</summary>
Motivation: 现有方法在贝叶斯网络的因果推理和场景评估中需要手动修改模型，缺乏高效查询语言。

Method: 开发结构化语言BayesL，支持创建BN查询，实现因果与证据关系的多维度推理。

Result: 该框架无需手动调整模型即可完成全面的假设场景评估，提升分析效率。

Conclusion: BayesL为贝叶斯网络提供了一种强大的声明式查询工具，拓展了概率图模型的应用边界。

Abstract: We introduce BayesL, a novel logical framework for specifying, querying, and
verifying the behaviour of Bayesian networks (BNs). BayesL (pronounced "Basil")
is a structured language that allows for the creation of queries over BNs. It
facilitates versatile reasoning concerning causal and evidence-based
relationships, and permits comprehensive what-if scenario evaluations without
the need for manual modifications to the model.

</details>


### [164] [When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)](https://arxiv.org/abs/2506.23784)
*Parosh Aziz Abdulla,Mohamed Faouzi Atig,Julie Cailler,Chencheng Liang,Philipp Rümmer*

Main category: cs.AI

TL;DR: 该研究探索了使用图神经网络（GNN）对字方程进行排序以优化求解过程，提出了一种新的基于图的表示方法，并通过实验验证了其在特定基准测试中的有效性。


<details>
  <summary>Details</summary>
Motivation: 在解决字方程联立时，处理顺序对求解器性能有显著影响，传统方法缺乏全局视角，因此需要一种能综合考虑所有联立方程的排序方法。

Method: 提出了一种保留联立方程全局信息的图表示方法，并设计了三种适应多分类任务的GNN排序策略，利用最小不可满足子集（MUS）进行模型训练。

Result: 实验表明，与现有字符串求解器相比，新框架在变量每个方程最多出现一次的基准测试中能解决更多问题。

Conclusion: 基于GNN的排序方法为字方程求解提供了新的优化方向，尤其在处理特定约束条件时展现出优越性能。

Abstract: Nielsen transformation is a standard approach for solving word equations: by
repeatedly splitting equations and applying simplification steps, equations are
rewritten until a solution is reached. When solving a conjunction of word
equations in this way, the performance of the solver will depend considerably
on the order in which equations are processed. In this work, the use of Graph
Neural Networks (GNNs) for ranking word equations before and during the solving
process is explored. For this, a novel graph-based representation for word
equations is presented, preserving global information across conjuncts,
enabling the GNN to have a holistic view during ranking. To handle the variable
number of conjuncts, three approaches to adapt a multi-classification task to
the problem of ranking equations are proposed. The training of the GNN is done
with the help of minimum unsatisfiable subsets (MUSes) of word equations. The
experimental results show that, compared to state-of-the-art string solvers,
the new framework solves more problems in benchmarks where each variable
appears at most once in each equation.

</details>


### [165] [Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning](https://arxiv.org/abs/2506.23793)
*Anton Andreychuk,Konstantin Yakovlev,Aleksandr Panov,Alexey Skrynnik*

Main category: cs.AI

TL;DR: 本文提出了一种名为MAPF-GPT-DDG的新型多智能体路径规划（MAPF）求解器，通过微调预训练模型并采用创新的增量数据生成机制，显著提升了求解质量和可扩展性，可处理百万级智能体的场景。


<details>
  <summary>Details</summary>
Motivation: 尽管最优MAPF求解已被证明是NP难问题，但高效的次优求解器对物流、搜救等实际应用至关重要。基于模仿学习的MAPF-GPT虽取得进展，仍有改进空间。

Method: MAPF-GPT-DDG在预训练MAPF模型基础上，利用集中式专家数据进行微调，并引入增量数据生成（delta-data generation）机制加速训练过程。

Result: 实验表明该模型在所有学习型MAPF求解器中表现最优，支持单环境百万智能体规模的路径规划，创下领域可扩展性新纪录。

Conclusion: MAPF-GPT-DDG通过数据生成创新与模型微调的结合，为大规模多智能体路径规划提供了高效解决方案，推动了该领域的实用化进程。

Abstract: Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot
trajectory planning problems, where multiple homogeneous robots simultaneously
move in the shared environment. While solving MAPF optimally has been proven to
be NP-hard, scalable, and efficient, solvers are vital for real-world
applications like logistics, search-and-rescue, etc. To this end, decentralized
suboptimal MAPF solvers that leverage machine learning have come on stage.
Building on the success of the recently introduced MAPF-GPT, a pure imitation
learning solver, we introduce MAPF-GPT-DDG. This novel approach effectively
fine-tunes the pre-trained MAPF model using centralized expert data. Leveraging
a novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training
while significantly improving performance at test time. Our experiments
demonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF
solvers, including the original MAPF-GPT, regarding solution quality across
many testing scenarios. Remarkably, it can work with MAPF instances involving
up to 1 million agents in a single environment, setting a new milestone for
scalability in MAPF domains.

</details>


### [166] [A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents](https://arxiv.org/abs/2506.23844)
*Hang Su,Jun Luo,Chang Liu,Xiao Yang,Yichi Zhang,Yinpeng Dong,Jun Zhu*

Main category: cs.AI

TL;DR: 本文综述了大型语言模型（LLM）驱动的自主AI代理的安全风险，提出了一种新型的反射式风险感知架构（R2A2）来应对这些挑战。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理能力的提升，其面临的新型安全风险（如记忆污染、工具滥用等）超出了传统系统或独立LLM的威胁模型，亟需系统性解决方案。

Method: 通过分析代理栈的结构性脆弱性，提出基于约束马尔可夫决策过程（CMDP）的R2A2框架，整合风险感知建模、元策略适应等技术。

Result: 识别出感知-认知-记忆-行动模块的架构缺陷，并系统梳理了输入净化、记忆生命周期控制等分层防御策略。

Conclusion: R2A2框架通过联合奖励-风险优化，为代理决策循环提供了理论化、主动式的安全保护机制。

Abstract: Recent advances in large language models (LLMs) have catalyzed the rise of
autonomous AI agents capable of perceiving, reasoning, and acting in dynamic,
open-ended environments. These large-model agents mark a paradigm shift from
static inference systems to interactive, memory-augmented entities. While these
capabilities significantly expand the functional scope of AI, they also
introduce qualitatively novel security risks - such as memory poisoning, tool
misuse, reward hacking, and emergent misalignment - that extend beyond the
threat models of conventional systems or standalone LLMs. In this survey, we
first examine the structural foundations and key capabilities that underpin
increasing levels of agent autonomy, including long-term memory retention,
modular tool use, recursive planning, and reflective reasoning. We then analyze
the corresponding security vulnerabilities across the agent stack, identifying
failure modes such as deferred decision hazards, irreversible tool chains, and
deceptive behaviors arising from internal state drift or value misalignment.
These risks are traced to architectural fragilities that emerge across
perception, cognition, memory, and action modules. To address these challenges,
we systematically review recent defense strategies deployed at different
autonomy layers, including input sanitization, memory lifecycle control,
constrained decision-making, structured tool invocation, and introspective
reflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a
unified cognitive framework grounded in Constrained Markov Decision Processes
(CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation,
and joint reward-risk optimization to enable principled, proactive safety
across the agent's decision-making loop.

</details>


### [167] [Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence](https://arxiv.org/abs/2506.23908)
*András György,Tor Lattimore,Nevena Lazić,Csaba Szepesvári*

Main category: cs.AI

TL;DR: 论文指出当前AI系统在演绎推理上的不足，主张采用精确学习范式以实现可靠的推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在数学和科学领域取得进展，但现有系统在简单演绎推理任务上仍频繁出错，无法实现真正的通用人工智能。

Method: 提出从统计学习范式转向精确学习范式，要求在所有输入上保证正确性，而非仅优化统计性能。

Result: 统计学习方法导致推理不可靠，精确学习是实现可靠演绎推理的必要途径。

Conclusion: 为实现可靠的演绎推理能力，AI研究必须采用精确学习范式，并将其作为算法设计的核心目标。

Abstract: Sound deductive reasoning -- the ability to derive new knowledge from
existing facts and rules -- is an indisputably desirable aspect of general
intelligence. Despite the major advances of AI systems in areas such as math
and science, especially since the introduction of transformer architectures, it
is well-documented that even the most advanced frontier systems regularly and
consistently falter on easily-solvable deductive reasoning tasks. Hence, these
systems are unfit to fulfill the dream of achieving artificial general
intelligence capable of sound deductive reasoning. We argue that their unsound
behavior is a consequence of the statistical learning approach powering their
development. To overcome this, we contend that to achieve reliable deductive
reasoning in learning-based AI systems, researchers must fundamentally shift
from optimizing for statistical performance against distributions on reasoning
problems and algorithmic tasks to embracing the more ambitious exact learning
paradigm, which demands correctness on all inputs. We argue that exact learning
is both essential and possible, and that this ambitious objective should guide
algorithm design.

</details>


### [168] [AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models](https://arxiv.org/abs/2506.23949)
*Anthony M. Barrett,Jessica Newman,Brandie Nonnecke,Nada Madkour,Dan Hendrycks,Evan R. Murphy,Krystal Jackson,Deepika Raman*

Main category: cs.AI

TL;DR: 本文为多功能AI模型（如大型语言模型等）提供风险管理实践指南，旨在帮助开发者识别、分析和减轻相关风险。


<details>
  <summary>Details</summary>
Motivation: 多功能AI模型（GPAI/基础模型）虽具备诸多有益能力，但也可能带来严重后果的风险，需制定风险管理措施。

Method: 文档基于NIST AI风险管理框架和ISO/IEC 23894标准，针对GPAI/基础模型开发者的独特问题，提供风险控制实践。

Result: 为大型GPAI/基础模型开发者及下游应用开发者提供风险管理指南，促进与领先AI风险管理标准的符合性。

Conclusion: 本文通过定制化风险管理实践，帮助开发者应对GPAI/基础模型带来的独特挑战，确保技术发展的安全性与可控性。

Abstract: Increasingly multi-purpose AI models, such as cutting-edge large language
models or other 'general-purpose AI' (GPAI) models, 'foundation models,'
generative AI models, and 'frontier models' (typically all referred to
hereafter with the umbrella term 'GPAI/foundation models' except where greater
specificity is needed), can provide many beneficial capabilities but also risks
of adverse events with profound consequences. This document provides
risk-management practices or controls for identifying, analyzing, and
mitigating risks of GPAI/foundation models. We intend this document primarily
for developers of large-scale, state-of-the-art GPAI/foundation models; others
that can benefit from this guidance include downstream developers of end-use
applications that build on a GPAI/foundation model. This document facilitates
conformity with or use of leading AI risk management-related standards,
adapting and building on the generic voluntary guidance in the NIST AI Risk
Management Framework and ISO/IEC 23894, with a focus on the unique issues faced
by developers of GPAI/foundation models.

</details>


### [169] [Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice](https://arxiv.org/abs/2506.23924)
*Akshit Kumar,Tianyi Peng,Yuhang Wu,Assaf Zeevi*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在解决运筹学（OR）中的随机建模问题方面展现出与人类专家相当的能力，但仍需进一步研究以实现可靠的自动化。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在多个领域展现出专家级能力，但其在运筹学（OR）中解决随机建模问题的能力尚未被充分探索。随机建模是OR的核心问题之一，涉及不确定性及概率、统计和随机过程等工具。

Method: 研究通过手动收集一组研究生课程作业和博士资格考试题目，测试LLMs解决随机建模问题的能力，并利用开源库SimOpt评估LLMs在不确定性下做出实际决策的能力。

Result: 结果表明，尽管在现实中实现随机建模流程的可靠自动化仍需大量工作，但最先进的LLMs在课堂和实际场景中展现出与人类专家相当的能力。

Conclusion: 这些发现凸显了构建辅助OR研究的人工智能代理的潜力，并通过自动化放大OR在现实世界中的影响力。

Abstract: Large language models (LLMs) have exhibited expert-level capabilities across
various domains. However, their abilities to solve problems in Operations
Research (OR) -- the analysis and optimization of mathematical models derived
from real-world problems or their verbal descriptions -- remain underexplored.
In this work, we take a first step toward evaluating LLMs' abilities to solve
stochastic modeling problems, a core class of OR problems characterized by
uncertainty and typically involving tools from probability, statistics, and
stochastic processes. We manually procure a representative set of
graduate-level homework and doctoral qualification-exam problems and test LLMs'
abilities to solve them. We further leverage SimOpt, an open-source library of
simulation-optimization problems and solvers, to investigate LLMs' abilities to
make real-world decisions under uncertainty. Our results show that, though a
nontrivial amount of work is still needed to reliably automate the stochastic
modeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on
par with human experts in both classroom and practical settings. These findings
highlight the potential of building AI agents that assist OR researchers and
amplify the real-world impact of OR through automation.

</details>


### [170] [Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system](https://arxiv.org/abs/2506.23926)
*Junping Wang,Bicheng Wang,Yibo Xuea,Yuan Xie*

Main category: cs.AI

TL;DR: 提出工业大脑框架，结合高阶神经网路与符号推理，直接从观测数据自主规划产业链韧性，预测精度提升超10%，且对未知拓扑保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法难以在混沌数据下重建时空共演结构并预测网络拓扑韧性，亟需突破性解决方案以应对实际工业链管理挑战。

Method: 融合高阶活动驱动神经网路与CT-OODA符号推理，构建类人自主认知决策框架，无需简化假设即可建模节点动态与网络共演拓扑结构。

Result: 实验显示工业大脑预测精度较GoT/OlaGPT提升10.8%，较谱降维方法提升11.03%，且在观测干扰下保持稳定，能泛化至未见过的拓扑动态。

Conclusion: 该框架填补了产业链韧性预测与自主规划的空白，通过揭示复杂网络隐藏规律，实现高精度韧性推断与规划。

Abstract: Resilience non-equilibrium measurement, the ability to maintain fundamental
functionality amidst failures and errors, is crucial for scientific management
and engineering applications of industrial chain. The problem is particularly
challenging when the number or types of multiple co-evolution of resilience
(for example, randomly placed) are extremely chaos. Existing end-to-end deep
learning ordinarily do not generalize well to unseen full-feld reconstruction
of spatiotemporal co-evolution structure, and predict resilience of network
topology, especially in multiple chaos data regimes typically seen in
real-world applications. To address this challenge, here we propose industrial
brain, a human-like autonomous cognitive decision-making and planning framework
integrating higher-order activity-driven neuro network and CT-OODA symbolic
reasoning to autonomous plan resilience directly from observational data of
global variable. The industrial brain not only understands and model structure
of node activity dynamics and network co-evolution topology without simplifying
assumptions, and reveal the underlying laws hidden behind complex networks, but
also enabling accurate resilience prediction, inference, and planning.
Experimental results show that industrial brain significantly outperforms
resilience prediction and planning methods, with an accurate improvement of up
to 10.8\% over GoT and OlaGPT framework and 11.03\% over spectral dimension
reduction. It also generalizes to unseen topologies and dynamics and maintains
robust performance despite observational disturbances. Our findings suggest
that industrial brain addresses an important gap in resilience prediction and
planning for industrial chain.

</details>


### [171] [Harnessing AI Agents to Advance Research on Refugee Child Mental Health](https://arxiv.org/abs/2506.23992)
*Aditya Shrivastava,Komal Gupta,Shraddha Arora*

Main category: cs.AI

TL;DR: 研究提出基于AI的框架处理难民儿童心理健康数据，比较Zephyr-7B-beta和DeepSeek R1-7B两种RAG模型性能，发现DeepSeek R1表现更优。


<details>
  <summary>Details</summary>
Motivation: 国际难民危机导致数百万儿童面临心理创伤，需有效处理非结构化健康数据以支持决策和干预。

Method: 采用检索增强生成(RAG)技术，对比Zephyr-7B-beta和DeepSeek R1-7B模型在难民数据集上的表现，结合AI与儿童心理学方法。

Result: 两种模型均有效，但DeepSeek R1以0.91的相关性准确度显著优于Zephyr模型。

Conclusion: 该AI框架为难民儿童心理健康干预提供了可扩展方案，DeepSeek R1在数据处理的准确性上更具优势。

Abstract: The international refugee crisis deepens, exposing millions of dis placed
children to extreme psychological trauma. This research suggests a com pact,
AI-based framework for processing unstructured refugee health data and
distilling knowledge on child mental health. We compare two Retrieval-Aug
mented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to
determine how well they process challenging humanitarian datasets while avoid
ing hallucination hazards. By combining cutting-edge AI methods with migration
research and child psychology, this study presents a scalable strategy to
assist policymakers, mental health practitioners, and humanitarian agencies to
better assist displaced children and recognize their mental wellbeing. In
total, both the models worked properly but significantly Deepseek R1 is
superior to Zephyr with an accuracy of answer relevance 0.91

</details>


### [172] [Constructing Non-Markovian Decision Process via History Aggregator](https://arxiv.org/abs/2506.24026)
*Yongyi Wang,Wenxin Li*

Main category: cs.AI

TL;DR: 本文提出了一种基于范畴论的新方法，通过建立马尔可夫决策过程（MDP）和非马尔可夫决策过程（NMDP）的范畴，并证明其等价关系，为解决算法决策中的非马尔可夫动态问题提供了理论框架。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法全面评估决策算法处理非马尔可夫动态的能力，这限制了强化学习等范式的发展和应用效果。

Method: 研究团队设计了基于范畴论的通用方法，构建了MDP和NMDP的范畴，并证明了它们的等价性。通过引入状态历史聚合器（HAS），在决策问题中精确控制时间序列中的状态依赖结构。

Result: 分析表明，该方法能有效表示广泛的非马尔可夫动态，为决策算法在明确构建非马尔可夫动态的问题设置中进行测试提供了更严格和灵活的评价方式。

Conclusion: 该研究为理解和处理非马尔可夫动态提供了新的理论视角，通过HAS实现了对决策问题中状态依赖结构的精确控制，推动了决策算法评估方法的发展。

Abstract: In the domain of algorithmic decision-making, non-Markovian dynamics manifest
as a significant impediment, especially for paradigms such as Reinforcement
Learning (RL), thereby exerting far-reaching consequences on the advancement
and effectiveness of the associated systems. Nevertheless, the existing
benchmarks are deficient in comprehensively assessing the capacity of decision
algorithms to handle non-Markovian dynamics. To address this deficiency, we
have devised a generalized methodology grounded in category theory. Notably, we
established the category of Markov Decision Processes (MDP) and the category of
non-Markovian Decision Processes (NMDP), and proved the equivalence
relationship between them. This theoretical foundation provides a novel
perspective for understanding and addressing non-Markovian dynamics. We further
introduced non-Markovianity into decision-making problem settings via the
History Aggregator for State (HAS). With HAS, we can precisely control the
state dependency structure of decision-making problems in the time series. Our
analysis demonstrates the effectiveness of our method in representing a broad
range of non-Markovian dynamics. This approach facilitates a more rigorous and
flexible evaluation of decision algorithms by testing them in problem settings
where non-Markovian dynamics are explicitly constructed.

</details>


### [173] [SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2506.24119)
*Bo Liu,Leon Guertler,Simon Yu,Zichen Liu,Penghui Qi,Daniel Balcells,Mickel Liu,Cheston Tan,Weiyan Shi,Min Lin,Wee Sun Lee,Natasha Jaques*

Main category: cs.AI

TL;DR: SPIRAL框架通过自博弈训练语言模型，无需人工监督即可提升推理能力。在零和博弈中，模型通过不断对抗更强版本自我提升，展现出广泛迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习依赖人工标注和领域特定奖励设计，SPIRAL旨在通过自博弈消除这些限制，实现自主推理能力开发。

Method: 提出SPIRAL自博弈框架：1) 多轮零和博弈对抗自我改进版本；2) 在线多智能体强化学习系统；3) 角色条件优势估计(RAE)稳定训练。

Result: Qwen3-4B-Base在Kuhn Poker训练后数学/推理能力提升8.6%/8.4%，超越2.5万专家轨迹监督学习。多游戏训练进一步强化不同推理模式。

Conclusion: 零和博弈能自然发展可迁移的推理能力（系统性分解、期望值计算、案例分析），为自主推理开发开辟了新方向。

Abstract: Recent advances in reinforcement learning have shown that language models can
develop sophisticated reasoning through training on tasks with verifiable
rewards, but these approaches depend on human-curated problem-answer pairs and
domain-specific reward engineering. We introduce SPIRAL, a self-play framework
where models learn by playing multi-turn, zero-sum games against continuously
improving versions of themselves, eliminating the need for human supervision.
Through self-play, SPIRAL generates an infinite curriculum of progressively
challenging problems as models must constantly adapt to stronger opponents. To
enable this self-play training at scale, We implement a fully online,
multi-turn, multi-agent reinforcement learning system for LLMs and propose
role-conditioned advantage estimation (RAE) to stabilize multi-agent training.
Using SPIRAL, self-play on zero-sum games produces reasoning capabilities that
transfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%
improvement on math and 8.4% on general reasoning, outperforming SFT on 25,000
expert game trajectories. Analysis reveals that this transfer occurs through
three cognitive patterns: systematic decomposition, expected value calculation,
and case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple
Negotiation) further enhances performance as each game develops distinct
reasoning strengths. Applying SPIRAL to a strong reasoning model
(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These
results demonstrate that zero-sum games naturally develop transferable
reasoning capabilities, highlighting a promising direction for autonomous
reasoning development.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [174] [A Graph Width Perspective on Partially Ordered Hamiltonian Paths and Cycles I: Treewidth, Pathwidth, and Grid Graphs](https://arxiv.org/abs/2506.23790)
*Jesse Beisegel,Katharina Klost,Kristin Knorr,Fabienne Ratajczak,Robert Scheffler*

Main category: cs.DM

TL;DR: 本文研究了带偏序约束的哈密尔顿路径和哈密尔顿环问题，证明了路径问题在路径宽度为4的图上及环问题在路径宽度为5的图上是$\mathsf{NP}$-完全的，并给出了路径宽度为3和树宽度为2的图上的多项式时间算法。同时，研究了有界高度矩形网格图上的复杂度，发现路径和环问题分别在高度≥7和≥9时是$\mathsf{NP}$-完全的，而最小边权问题在高度5和6时是$\mathsf{NP}$-难的。


<details>
  <summary>Details</summary>
Motivation: 研究带偏序约束的哈密尔顿路径和环问题，旨在理解这些经典图论问题在不同图结构上的计算复杂度边界。

Method: 通过理论证明和算法设计，分析了路径宽度和树宽度受限的图上的复杂度，并特别考察了有界高度矩形网格图上的情况。

Result: 路径问题在路径宽度4的图上是$\mathsf{NP}$-完全的，环问题在路径宽度5的图上是$\mathsf{NP}$-完全的；路径宽度3和树宽度2的图上有多项式时间算法。矩形网格图中，路径和环问题分别在高度≥7和≥9时是$\mathsf{NP}$-完全的，最小边权问题在高度5和6时是$\mathsf{NP}$-难的。

Conclusion: 研究明确了带偏序约束的哈密尔顿问题在不同图结构上的复杂度边界，为相关算法设计提供了理论依据。

Abstract: We consider the problem of finding a Hamiltonian path or a Hamiltonian cycle
with precedence constraints in the form of a partial order on the vertex set.
We show that the path problem is $\mathsf{NP}$-complete for graphs of pathwidth
4 while the cycle problem is $\mathsf{NP}$-complete on graphs of pathwidth 5.
We complement these results by giving polynomial-time algorithms for graphs of
pathwidth 3 and treewidth 2 for Hamiltonian paths as well as pathwidth 4 and
treewidth 3 for Hamiltonian cycles. Furthermore, we study the complexity of the
path and cycle problems on rectangular grid graphs of bounded height. For
these, we show that the path and cycle problems are $\mathsf{NP}$-complete when
the height of the grid is greater or equal to 7 and 9, respectively. In the
variant where we look for minimum edge-weighted Hamiltonian paths and cycles,
the problems are $\mathsf{NP}$-hard for heights 5 and 6, respectively.

</details>


### [175] [Linear Layouts of Graphs with Priority Queues](https://arxiv.org/abs/2506.23943)
*Emilio Di Giacomo,Walter Didimo,Henry Förster,Torsten Ueckerdt,Johannes Zink*

Main category: cs.DM

TL;DR: 本文研究了边加权图的优先级队列布局，证明了某些图需要线性数量的优先级队列，并提供了单队列布局的识别算法。同时探讨了路径宽度与队列数的关系，并证明了固定顶点顺序时最小队列数的NP完全性。


<details>
  <summary>Details</summary>
Motivation: 传统堆栈和队列布局已扩展至双端队列和受限输入队列，但边加权图的优先级队列布局尚未系统研究。本文旨在填补这一空白，探索边权重如何影响图的页面分配。

Method: 引入优先级队列布局概念，其中每页边按权重存储在优先队列中。通过构造性证明、路径宽度理论分析和NP完全性归约等方法展开研究。

Result: 1) 存在需要O(n)个优先级队列的边加权图；2) 单队列布局图类可高效识别；3) 队列数受路径宽度限制但树宽度为2时仍可无限；4) 固定顶点顺序时最小队列数计算是NP完全的。

Conclusion: 优先级队列布局为边加权图提供了新的分层框架，其复杂性由路径宽度部分约束但计算难度较高，未来可探索近似算法或特殊图类的高效布局方案。

Abstract: A linear layout of a graph consists of a linear ordering of its vertices and
a partition of its edges into pages such that the edges assigned to the same
page obey some constraint. The two most prominent and widely studied types of
linear layouts are stack and queue layouts, in which any two edges assigned to
the same page are forbidden to cross and nest, respectively. The names of these
two layouts derive from the fact that, when parsing the graph according to the
linear vertex ordering, the edges in a single page can be stored using a single
stack or queue, respectively. Recently, the concepts of stack and queue layouts
have been extended by using a double-ended queue or a restricted-input queue
for storing the edges of a page. We extend this line of study to edge-weighted
graphs by introducing priority queue layouts, that is, the edges on each page
are stored in a priority queue whose keys are the edge weights. First, we show
that there are edge-weighted graphs that require a linear number of priority
queues. Second, we characterize the graphs that admit a priority queue layout
with a single queue, regardless of the edge-weight function, and we provide an
efficient recognition algorithm. Third, we show that the number of priority
queues required independently of the edge-weight function is bounded by the
pathwidth of the graph, but can be arbitrarily large already for graphs of
treewidth two. Finally, we prove that determining the minimum number of
priority queues is NP-complete if the linear ordering of the vertices is fixed.

</details>
