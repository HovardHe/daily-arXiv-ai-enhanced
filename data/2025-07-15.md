<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 7]
- [math.OC](#math.OC) [Total: 25]
- [math.NT](#math.NT) [Total: 17]
- [math.LO](#math.LO) [Total: 4]
- [math.HO](#math.HO) [Total: 2]
- [math.GM](#math.GM) [Total: 1]
- [math.CO](#math.CO) [Total: 28]
- [q-fin.CP](#q-fin.CP) [Total: 4]
- [cs.CR](#cs.CR) [Total: 33]
- [cs.AI](#cs.AI) [Total: 44]
- [cs.DM](#cs.DM) [Total: 2]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Optimal estimators for threshold-based quality measures](https://arxiv.org/abs/2507.08811)
*Aaron Abrams,Sandy Ganzell,Henry Landau,Zeph Landau,James Pommersheim,Eric Zaslow*

Main category: math.ST

TL;DR: 本文研究参数估计问题，针对给定单参数分布族，提出在最坏情况下以指定容错概率评估估计量的方法，证明了紧致空间分布存在平移不变的最优估计量，并给出无限树上分布的反例。


<details>
  <summary>Details</summary>
Motivation: 解决从未知分布采样后，如何从给定单参数分布族中选择最优估计量的问题，扩展Schulman和Vazirani的最坏情况容错评估框架。

Method: 采用概率分析框架，对$\mathbb{R}$上多类分布构造最优估计量，证明紧致空间分布的平移不变性，并通过无限树反例验证结论边界。

Result: 证实在紧致空间上总存在平移不变最优估计量，提出该性质可推广至$\mathbb{R}$的猜想，但构造无限树分布的反例表明结论不普适。

Conclusion: 紧致性对估计量的平移不变性起关键作用，而无限结构可能破坏该性质，为参数估计理论提供新的理论边界。

Abstract: We consider a problem in parametric estimation: given $n$ samples from an
unknown distribution, we want to estimate which distribution, from a given
one-parameter family, produced the data. Following Schulman and Vazirani, we
evaluate an estimator in terms of the chance of being within a specified
tolerance of the correct answer, in the worst case. We provide optimal
estimators for several families of distributions on $\mathbb{R}$. We prove that
for distributions on a compact space, there is always an optimal estimator that
is translation-invariant, and we conjecture that this conclusion also holds for
any distribution on $\mathbb{R}$. By contrast, we give an example showing it
does not hold for a certain distribution on an infinite tree.

</details>


### [2] [Possibilistic inferential models: a review](https://arxiv.org/abs/2507.09007)
*Ryan Martin*

Main category: math.ST

TL;DR: 本文综述了推断模型（IM）的最新进展，特别是基于可能性理论的IM，其在保持频率派可靠性的同时，提供了类似贝叶斯的条件推理能力。


<details>
  <summary>Details</summary>
Motivation: 推断模型（IM）旨在提供可靠的数据驱动不确定性量化，与Fisher的基准论证目标相似，但IM不要求不确定性量化必须是概率性的，从而提供了更大的灵活性。

Method: 研究重点是基于可能性理论的IM构建方法，这些方法简单易行，具有强大的频率派可靠性，并能进行类似贝叶斯的条件推理。

Result: 论文展示了IM的新理论、方法和计算工具，并提出了一种基本可能性IM的推广，与现代统计和机器学习中的bootstrap和共形预测等方法建立了新的联系。

Conclusion: 可能性IM不仅易于构建，而且具有强大的可靠性和灵活性，为不确定性量化提供了新的视角，并与现代统计和机器学习方法产生了意想不到的联系。

Abstract: An inferential model (IM) is a model describing the construction of provably
reliable, data-driven uncertainty quantification and inference about relevant
unknowns. IMs and Fisher's fiducial argument have similar objectives, but a
fundamental distinction between the two is that the former doesn't require that
uncertainty quantification be probabilistic, offering greater flexibility and
allowing for a proof of its reliability. Important recent developments have
been made thanks in part to newfound connections with the imprecise probability
literature, in particular, possibility theory. The brand of possibilistic IMs
studied here are straightforward to construct, have very strong
frequentist-like reliability properties, and offer fully conditional,
Bayesian-like (imprecise) probabilistic reasoning. This paper reviews these key
recent developments, describing the new theory, methods, and computational
tools. A generalization of the basic possibilistic IM is also presented, making
new and unexpected connections with ideas in modern statistics and machine
learning, e.g., bootstrap and conformal prediction.

</details>


### [3] [Optimal Differentially Private Ranking from Pairwise Comparisons](https://arxiv.org/abs/2507.09388)
*T. Tony Cai,Abhinav Chakraborty,Yichen Wang*

Main category: math.ST

TL;DR: 本文提出两种差分隐私算法（边差分隐私和个体差分隐私）来处理不完整且含噪声的成对比较排序问题，通过扰动最大似然估计和噪声计数方法实现最优收敛率，并在模拟和真实数据中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 在推荐系统、教育评估和敏感话题调查等应用中，基于成对比较的排序面临数据隐私保护的核心问题。

Method: 开发了基于边差分隐私（保护单个比较结果）和个体差分隐私（保护个体贡献的多个比较）的算法，包括扰动最大似然估计器和噪声计数方法。

Result: 算法在相应隐私约束下达到极小极大最优收敛率，模拟和真实数据实验验证了其实际有效性。

Conclusion: 所提出的差分隐私排序方法在理论性能和实际应用上均表现出色，为隐私敏感的排序场景提供了可靠解决方案。

Abstract: Data privacy is a central concern in many applications involving ranking from
incomplete and noisy pairwise comparisons, such as recommendation systems,
educational assessments, and opinion surveys on sensitive topics. In this work,
we propose differentially private algorithms for ranking based on pairwise
comparisons. Specifically, we develop and analyze ranking methods under two
privacy notions: edge differential privacy, which protects the confidentiality
of individual comparison outcomes, and individual differential privacy, which
safeguards potentially many comparisons contributed by a single individual. Our
algorithms--including a perturbed maximum likelihood estimator and a noisy
count-based method--are shown to achieve minimax optimal rates of convergence
under the respective privacy constraints. We further demonstrate the practical
effectiveness of our methods through experiments on both simulated and
real-world data.

</details>


### [4] [Edgeworth corrections for the spiked eigenvalues of non-Gaussian sample covariance matrices with applications](https://arxiv.org/abs/2507.09584)
*Yashi Wei,Jiang Hu,Zhidong Bai*

Main category: math.ST

TL;DR: 本文扩展了非高斯数据下单峰和多峰场景的Edgeworth展开，构建了更精确的置信区间并提出了新的峰值数量估计方法，仿真显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: Yang和Johnstone (2018)在高斯假设下建立了尖峰协方差模型中最大样本特征值的Edgeworth修正，但非高斯情况下的扩展尚未解决。

Method: 通过建立非高斯数据下单峰和多峰场景的一阶Edgeworth展开，构建更精确的置信区间并提出新的峰值数量估计器。

Result: 仿真研究表明，所提方法在各种设置下（尤其是低维情况）的鲁棒性和准确性均优于现有方法。

Conclusion: 本文提出的方法显著提升了非高斯数据下尖峰特征值的统计推断精度，为峰值数量估计提供了新工具。

Abstract: Yang and Johnstone (2018) established an Edgeworth correction for the largest
sample eigenvalue in a spiked covariance model under the assumption of Gaussian
observations, leaving the extension to non-Gaussian settings as an open
problem. In this paper, we address this issue by establishing first-order
Edgeworth expansions for spiked eigenvalues in both single-spike and
multi-spike scenarios with non-Gaussian data. Leveraging these expansions, we
construct more accurate confidence intervals for the population spiked
eigenvalues and propose a novel estimator for the number of spikes. Simulation
studies demonstrate that our proposed methodology outperforms existing
approaches in both robustness and accuracy across a wide range of settings,
particularly in low-dimensional cases.

</details>


### [5] [Fixed-Point Estimation of the Drift Parameter in Stochastic Differential Equations Driven by Rough Multiplicative Fractional Noise](https://arxiv.org/abs/2507.09787)
*Chiara Amorino,Laure Coutin,Nicolas Marie*

Main category: math.ST

TL;DR: 本文研究了从$N$个独立样本中估计由乘性分数布朗噪声驱动的随机微分方程的漂移参数问题，提出了基于Skorokhod积分的固定点估计器，并分析了其误差控制和性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决乘性分数布朗噪声（Hurst参数$H\in (1/3,1)$）驱动的随机微分方程中漂移参数的估计问题，特别是在不可观测的Skorokhod积分近似中面临的挑战。

Method: 方法包括构建基于最小二乘的Skorokhod积分对象，通过固定点估计器近似不可观测量，并利用Malliavin导数的重构控制乘性设置中的近似误差。对于$H\in (1/3,1/2]$，进一步利用二维Young积分处理更复杂的修正项。

Result: 结果表明，对于任意$H\in (1/3,1)$，固定点估计器具有良好的适定性，同时提供了渐近置信区间和非渐近风险界。数值实验验证了估计器的优异性能。

Conclusion: 结论指出，所提出的固定点估计器在理论和实践中均表现良好，为乘性分数布朗噪声驱动的随机微分方程漂移参数估计提供了有效解决方案。

Abstract: We investigate the problem of estimating the drift parameter from $N$
independent copies of the solution of a stochastic differential equation driven
by a multiplicative fractional Brownian noise with Hurst parameter $H\in
(1/3,1)$. Building on a least-squares-type object involving the Skorokhod
integral, a key challenge consists in approximating this unobservable quantity
with a computable fixed-point estimator, which requires addressing the
correction induced by replacing the Skorokhod integral with its pathwise
counterpart. To this end, a crucial technical contribution of this work is the
reformulation of the Malliavin derivative of the process in a way that does not
depend explicitly on the driving noise, enabling control of the approximation
error in the multiplicative setting. For the case $H\in (1/3,1/2]$, we further
exploit results on two-dimensional Young integrals to manage the more intricate
correction term that appears. As a result, we establish the well-posedness of a
fixed-point estimator for any $H\in (1/3,1)$, together with both an asymptotic
confidence interval and a non-asymptotic risk bound. Finally, a numerical study
illustrates the good practical performance of the proposed estimator.

</details>


### [6] [Low-Dose Tomography of Random Fields and the Problem of Continuous Heterogeneity](https://arxiv.org/abs/2507.10220)
*Ho Yun,Alessia Caponera,Victor M. Panaretos*

Main category: math.ST

TL;DR: 本文提出了一种基于低剂量断层扫描数据的非参数估计方法，用于分析结构异质性生物大分子的构象变化，证明了仅需每个个体两个投影即可实现一致估计，并开发了高效的张量Krylov方法进行计算实现。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于冷冻电镜技术中结构异质性生物大分子的构象变化分析需求，旨在通过低剂量断层扫描数据估计群体结构的变异模式。

Method: 方法将群体建模为随机场，均值表示典型结构，协方差反映异质性；在再生核希尔伯特空间中建立特定问题的表示定理和Mercer定理，并采用函数数据分析中的池化估计策略。

Result: 结果表明，即使每个个体仅有两个投影数据也能实现一致估计，推导了反映参数影响的均匀收敛速率，并通过张量化Krylov方法实现了高效计算。

Conclusion: 该研究为冷冻电镜中的结构异质性分析提供了新方法，展示了函数数据分析策略在新颖场景中的适用性，仿真实验验证了方法的有效性。

Abstract: We consider the problem of nonparametric estimation of the conformational
variability in a population of related structures, based on low-dose tomography
of a random sample of representative individuals. In this context, each
individual represents a random perturbation of a common template and is imaged
noisily and discretely at but a few projection angles. Such problems arise in
the cryo Electron Microscopy of structurally heterogeneous biological
macromolecules. We model the population as a random field, whose mean captures
the typical structure, and whose covariance reflects the heterogeneity. We show
that consistent estimation is achievable with as few as two projections per
individual, and derive uniform convergence rates reflecting how the various
parameters of the problem affect statistical efficiency, and their trade-offs.
Our analysis formulates the domain of the forward operator to be a reproducing
kernel Hilbert space, where we establish representer and Mercer theorems
tailored to question at hand. This allows us to exploit pooling estimation
strategies central to functional data analysis, illustrating their versatility
in a novel context. We provide an efficient computational implementation using
tensorized Krylov methods and demonstrate the performance of our methodology by
way of simulation.

</details>


### [7] [Post-reduction inference for confidence sets of models](https://arxiv.org/abs/2507.10373)
*Heather Battey,Daniel Garcia Rasines,Yanbo Tang*

Main category: math.ST

TL;DR: 本文提出利用Fisherian条件推断中的充分/共充分分离与辅助/共辅助分离方法，解决高维回归模型（如基因组学）中变量筛选与模型评估的难题，避免数据重复使用问题，并在正态线性回归模型中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在高维回归问题（如基因组学）中，变量筛选与模型评估需分步进行，但传统方法存在数据重复使用导致的偏差问题。本文旨在通过Fisherian条件推断的分离方法解决这一核心矛盾。

Method: 采用充分/共充分分离与辅助/共辅助分离的Fisherian条件推断框架，避免预设模型偏离方向。在正态线性回归模型中详细分析 nuisance 参数估计对信息提取的影响，并扩展至对数正态加速失效模型。

Result: 理想情况下（无nuisance参数），分离方法可无损失地提取数据信息。通过改进Fan等（2012）的交叉验证估计量，在条件推断框架下获得精确分布理论。分析了样本分割与分离方法的性能对比条件。

Conclusion: Fisherian分离方法为高维回归提供了理论严谨的变量筛选与评估框架，其条件推断特性优于传统数据复用方法。正态模型的详细分析为推广至指数族及广义回归模型奠定了基础。

Abstract: Sparsity in a regression context makes the model itself an object of
interest, pointing to a confidence set of models as the appropriate
presentation of evidence. A difficulty in areas such as genomics, where the
number of candidate variables is vast, arises from the need for preliminary
reduction prior to the assessment of models. The present paper considers a
resolution using inferential separations fundamental to the Fisherian approach
to conditional inference, namely, the sufficiency/co-sufficiency separation,
and the ancillary/co-ancillary separation. The advantage of these separations
is that no direction for departure from any hypothesised model is needed,
avoiding issues that would otherwise arise from using the same data for
reduction and for model assessment. In idealised cases with no nuisance
parameters, the separations extract all the information in the data, solely for
the purpose for which it is useful, without loss or redundancy. The extent to
which estimation of nuisance parameters affects the idealised information
extraction is illustrated in detail for the normal-theory linear regression
model, extending immediately to a log-normal accelerated-life model for
time-to-event outcomes. This idealised analysis provides insight into when
sample-splitting is likely to perform as well as, or better than, the
co-sufficient or ancillary tests, and when it may be unreliable. The
considerations involved in extending the detailed implementation to canonical
exponential-family and more general regression models are briefly discussed. As
part of the analysis for the Gaussian model, we introduce a modified version of
the refitted cross-validation estimator of Fan et al. (2012), whose
distribution theory is exact in an appropriate conditional sense.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [8] [From Controllability to Information: A Unified Analysis via Gramian, Minimum Energy, Fisher Information Matrix and Entropy](https://arxiv.org/abs/2507.08847)
*Gabriel R. de Andrade Silva*

Main category: math.OC

TL;DR: 本文以阻尼谐振荡器为例，探讨了线性动力系统中可控性、控制能量、信息与熵的关系，揭示了能量控制与信息估计精度之间的对偶性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示动力系统控制中的基本物理原理，通过整合能量与信息视角，深化对可控性、控制能量与信息熵之间联系的理解。

Method: 通过解析推导不同阻尼状态下的可控性格拉姆矩阵（Wc）及其行列式（det(Wc)），并结合费舍尔信息矩阵（I）、香农熵（H）和热力学熵（S）进行概念与形式关联分析。

Result: 发现系统参数（阻尼$\zeta$和固有频率$\omega_n$）对最小控制能量的影响，并建立了格拉姆矩阵与信息/热力学熵之间的联系，表明控制难易程度与信息熵存在关联。

Conclusion: 研究提出了能量控制与信息估计精度的对偶性框架，为动力系统控制提供了统一的能量-信息分析视角，揭示了控制过程中的基本物理规律。

Abstract: This article explores the connections between controllability, control
energy, information, and entropy in the context of linear dynamical systems,
using the damped harmonic oscillator as a case study. We analytically derive
the Controllability Gramian Matrix (Wc) and its determinant (det(Wc)) for
different damping regimes. We analyze the physical interpretation of det(Wc) in
terms of minimum control energy, highlighting the influence of system
parameters (damping {\zeta} and natural frequency {\omega}n). We investigate
the conceptual and formal relationships between the Gramian, the Fisher
Information Matrix (I), and Shannon (H) and thermodynamic (S) entropies,
suggesting a duality between energetic control and estimation precision, as
well as a link between ease of control and informational/thermodynamic entropy.
The unified analysis offers insights into the fundamental principles governing
the control of dynamical systems, integrating energy and information
perspectives.

</details>


### [9] [Mathematical Modeling of a pH Swing Precipitation Process and its Optimal Design](https://arxiv.org/abs/2507.08891)
*Sandesh Athni Hiremath,Chinmay Hegde,Andreas Voigt*

Main category: math.OC

TL;DR: 本文提出了一种半线性平流方程与随机微分方程耦合的系统，用于描述碳酸钙沉淀过程中颗粒尺寸分布和化学动力学的动态行为，并通过实验数据验证了模型的适用性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过建立数学模型，解释和预测在调整pH值条件下碳酸钙沉淀过程中关键组分的动态行为，包括颗粒尺寸分布和溶液化学动力学。

Method: 提出了一个耦合的半线性平流方程和随机微分方程系统，用于描述颗粒尺寸分布和化学动力学。通过实验数据验证模型，并采用三种方法（手动调参、经典FBSDE方法和DNN方法）进行模型拟合。

Result: 数学上证明了温和解的存在性及系统的长期行为。实验验证表明，DNN方法在误差和计算资源消耗方面表现最优。

Conclusion: 所提出的模型能够有效描述碳酸钙沉淀过程的动态行为，且DNN方法在模型拟合中表现最佳，具有最低的误差和最优的计算经济性。

Abstract: In this work we consider the semi-batch process of precipitation of calcium
carbonate solids from a solution containing calcium ions by adjusting the pH of
the solution. The change in pH is induced either by the addition of alkaline
solution such as sodium hydroxide (NaOH) or by the addition of a carbon dioxide
gas (CO$_2$) to the given ionic solution. Under this setup we propose a system
of degenerate stochastic partial differential equations that is able to explain
the dynamical behavior of the key components of precipitation process. In
particular, we propose a semi-linear advection equation for the dynamics of
particle size distribution (PSD) of the precipitated particles. This is in turn
coupled with a system of stochastic differential equations (SDEs) that is able
to explain the chemical kinetics between calcium ions (Ca$^{+2}$), calcium
carbonate (CaCO$_3$) in aqueous state and pH of the solution. The resulting
coupled system is first mathematically studied, in particular conditions for
the existence of a mild-solution is established and also the long time behavior
of the system is established. Following this we consider the validation of the
model for which we consider experimentally obtained lab-scale data. Using this
data we propose three methods to fit the model with the data which then also
validates the suitability of the proposed model. The three methods include
manual intuitive tuning, classical forward backward SDE (FBSDE) method and
finally a DNN based method. The FBSDE method is based on the stochastic optimal
control formulation for which we provide the necessary and sufficient condition
for the existence of an optimal solution. Lastly, we compare the three methods
and show that DNN method is the best in terms of lowest error and as the most
economical in terms of the compute resources necessary during online use.

</details>


### [10] [A Mathematical and Optimal Control Model for Rabies Transmission Dynamics Among Humans and Dogs with Environmental Effects](https://arxiv.org/abs/2507.08895)
*Mfano Charles,Sayoki G. Mfinanga,G. A. Lyakurwa,Delfim F. M. Torres,Verdiana G. Masanja*

Main category: math.OC

TL;DR: 本研究通过确定性模型分析狂犬病传播动态，结合环境因素与最优控制理论，发现综合干预措施可有效降低传播，疫苗接种和治疗是五年内消除狂犬病的关键。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索狂犬病传播机制及控制策略效果，通过模型量化环境因素与干预措施对疾病传播的影响，为公共卫生决策提供理论依据。

Method: 采用确定性模型结合最优控制理论，定性定量分析疾病传播平衡点稳定性（$\mathcal{R}_e < 1$时稳定），并通过网格图和等高线图展示控制策略（如犬只接种、健康宣传、暴露后治疗）与$\mathcal{R}_e$的负相关关系。

Result: 数值模拟表明：干预强度增加可降低传播率，而犬只接触率升高会提升$\mathcal{R}_e$；最优控制验证了综合策略的有效性，尤其疫苗接种和治疗对实现五年内消除目标至关重要。

Conclusion: 研究证实当$\mathcal{R}_e < 1$时无病平衡点稳定，综合控制策略能显著抑制狂犬病传播，为制定消除计划提供了关键干预方向。

Abstract: This study presents a deterministic model to investigate rabies transmission
dynamics, incorporating environmental effects and control strategies using
optimal control theory. Qualitative and quantitative analyses reveal that the
disease-free equilibrium is stable when the effective reproduction number
$\mathcal{R}_e < 1$, and unstable when $\mathcal{R}_e > 1$. Mesh and contour
plots illustrate an inverse relationship between $\mathcal{R}_e$ and control
strategies, including dog vaccination, health promotion, and post-exposure
treatment. Increased intervention reduces transmission, while higher contact
rates among dogs raise $\mathcal{R}_e$. Numerical simulations with optimal
control confirm the effectiveness of integrated strategies. Vaccination and
treatment are identified as key interventions for achieving rabies elimination
within five years.

</details>


### [11] [Stochastic Approximation with Block Coordinate Optimal Stepsizes](https://arxiv.org/abs/2507.08963)
*Tao Jiang,Lin Xiao*

Main category: math.OC

TL;DR: 本文提出了一种基于块坐标步长的随机逼近方法，通过在线估计搜索方向的二阶矩，推导出新的自适应步长规则，其性能与Adam相当但内存和超参数需求更少。


<details>
  <summary>Details</summary>
Motivation: 旨在最小化下一次迭代到最优点的期望距离，通过改进步长规则来提升随机逼近方法的效率和适用性。

Method: 采用块坐标步长和在线二阶矩估计，提出一种条件估计器，减少内存和超参数需求，适用于非凸非光滑场景。

Result: 证明该方法几乎必然收敛到最优点的一个小邻域，邻域半径取决于二阶矩估计的偏差和方差。

Conclusion: 该方法在广泛适用性下实现了高效收敛，为随机优化提供了新的理论支持和实用工具。

Abstract: We consider stochastic approximation with block-coordinate stepsizes and
propose adaptive stepsize rules that aim to minimize the expected distance from
the next iterate to an optimal point. These stepsize rules employ online
estimates of the second moment of the search direction along each block
coordinate. The popular Adam algorithm can be interpreted as a particular
heuristic for such estimation. By leveraging a simple conditional estimator, we
derive a new method that obtains comparable performance as Adam but requires
less memory and fewer hyper-parameters. We prove that this family of methods
converges almost surely to a small neighborhood of the optimal point, and the
radius of the neighborhood depends on the bias and variance of the
second-moment estimator. Our analysis relies on a simple aiming condition that
assumes neither convexity nor smoothness, thus has broad applicability.

</details>


### [12] [On the Gradient Domination of the LQG Problem](https://arxiv.org/abs/2507.09026)
*Kasra Fallah,Leonardo F. Toso,James Anderson*

Main category: math.OC

TL;DR: 本文研究了在线性二次高斯（LQG）调节器问题中通过策略梯度（PG）方法寻找解决方案。尽管PG方法在解决线性二次调节器（LQR）问题中表现出强大的理论保证，但在LQG设置中的理论理解仍然有限。通过采用一种替代的参数化方法，即历史表示，作者证明了梯度优势和近似平滑性，并提供了全局收敛和每次迭代稳定性的保证。


<details>
  <summary>Details</summary>
Motivation: 尽管PG方法在LQR问题中表现出色，但在LQG问题中缺乏梯度优势，阻碍了全局收敛保证。因此，需要一种新的参数化方法来克服这一限制。

Method: 作者采用了一种替代的参数化方法，即历史表示，通过过去p个时间步的输入和输出数据来参数化控制输入。这种方法使得能够建立LQG成本的梯度优势和近似平滑性。

Result: 作者证明了在基于模型和无模型设置中，策略梯度LQG具有全局收敛和每次迭代稳定性的保证。数值实验在一个开环不稳定系统上支持了全局收敛保证，并展示了在不同历史长度下的收敛性。

Conclusion: 通过历史表示参数化方法，本文成功解决了LQG问题中PG方法的梯度优势缺失问题，并提供了全局收敛和稳定性的理论保证，为实际应用提供了有力支持。

Abstract: We consider solutions to the linear quadratic Gaussian (LQG) regulator
problem via policy gradient (PG) methods. Although PG methods have demonstrated
strong theoretical guarantees in solving the linear quadratic regulator (LQR)
problem, despite its nonconvex landscape, their theoretical understanding in
the LQG setting remains limited. Notably, the LQG problem lacks gradient
dominance in the classical parameterization, i.e., with a dynamic controller,
which hinders global convergence guarantees. In this work, we study PG for the
LQG problem by adopting an alternative parameterization of the set of
stabilizing controllers and employing a lifting argument. We refer to this
parameterization as a history representation of the control input as it is
parameterized by past input and output data from the previous p time-steps.
This representation enables us to establish gradient dominance and approximate
smoothness for the LQG cost. We prove global convergence and per-iteration
stability guarantees for policy gradient LQG in model-based and model-free
settings. Numerical experiments on an open-loop unstable system are provided to
support the global convergence guarantees and to illustrate convergence under
different history lengths of the history representation.

</details>


### [13] [A Method for Learning to Solve Parametric Bilevel Optimization with Coupling Constraints](https://arxiv.org/abs/2507.09050)
*James Kotary,Himanshu Sharma,Ethan King,Draguna Vrabie,Ferdinando Fioretto,Jan Drgona*

Main category: math.OC

TL;DR: 本文提出了一种利用现代优化问题微分技术学习解决双层优化问题的框架，展示了神经网络如何作为参数化双层优化的高效近似器。


<details>
  <summary>Details</summary>
Motivation: 现有学习优化（L2O）方法主要关注单层规划问题，而双层规划问题因其约束本身也是优化子问题而难以解决，尤其在时间紧迫的情况下。

Method: 通过现代优化问题微分技术，构建了一个学习解决广泛挑战性双层优化问题的框架，并在合成双层程序和控制系统协同设计问题上进行了验证。

Result: 实验表明，该框架能够有效训练神经网络，使其成为参数化双层优化问题的高效近似求解器。

Conclusion: 该研究为双层优化问题的快速近似求解提供了新思路，展示了神经网络在复杂优化问题中的潜力。

Abstract: Learning to Optimize (L2O) is a subfield of machine learning (ML) in which ML
models are trained to solve parametric optimization problems. The general goal
is to learn a fast approximator of solutions to constrained optimization
problems, as a function of their defining parameters. Prior L2O methods focus
almost entirely on single-level programs, in contrast to the bilevel programs,
whose constraints are themselves expressed in terms of optimization
subproblems. Bilevel programs have numerous important use cases but are
notoriously difficult to solve, particularly under stringent time demands. This
paper proposes a framework for learning to solve a broad class of challenging
bilevel optimization problems, by leveraging modern techniques for
differentiation through optimization problems. The framework is illustrated on
an array of synthetic bilevel programs, as well as challenging control system
co-design problems, showing how neural networks can be trained as efficient
approximators of parametric bilevel optimization.

</details>


### [14] [Factorization-free Orthogonal Projection onto the Positive Semidefinite Cone with Composite Polynomial Filtering](https://arxiv.org/abs/2507.09165)
*Shucheng Kang,Haoyu Han,Antoine Groudiev,Heng Yang*

Main category: math.OC

TL;DR: 提出一种无需分解的正交投影方法，通过复合多项式滤波实现半正定锥投影，在GPU上高效运行并显著超越传统特征值分解方法。


<details>
  <summary>Details</summary>
Motivation: 受同态加密技术启发，旨在开发一种高效低精度的半正定锥投影方法，以替代计算昂贵的特征值分解。

Method: 采用复合多项式滤波逼近投影算子，仅需矩阵乘法运算，优化后支持GPU低精度计算（半精度/单精度）。

Result: 半精度下仅22次矩阵乘法即达$10^{-3}$相对误差，比cuSOLVER快10倍；单精度在B200 GPU上仍保持2倍加速。万阶稠密矩阵投影耗时半精度55ms/单精度400ms。

Conclusion: 集成至一阶半定规划求解器验证：低精度投影可稳定获得中等精度解，为大规模优化问题提供高效计算方案。

Abstract: We propose a factorization-free method for orthogonal projection onto the
positive semidefinite (PSD) cone, leveraging composite polynomial filtering.
Inspired by recent advances in homomorphic encryption, our approach
approximates the PSD cone projection operator using a carefully optimized
composite polynomial evaluated exclusively via matrix-matrix multiplications.
This approach enables efficient GPU implementations with low-precision
arithmetic, significantly outperforming the classical PSD cone projection using
state-of-the-art GPU-based eigenvalue decomposition solvers. Specifically, our
method achieves a consistent relative error of $10^{-3}$ in half-precision
arithmetic with only 22 matrix-matrix multiplications, providing roughly a
$10\times$ speed-up over NVIDIA's cuSOLVER routines on various large-scale
matrices. In single-precision arithmetic with emulation on B200 GPUs, our
approach maintains competitive accuracy while achieving up to a $2\times$
speed-up. Consequently, for a $10,000 \times 10,000$ dense symmetric matrix,
our method requires approximately $55$ ms in half-precision and $400$ ms in
single-precision arithmetic on B200 GPUs. Integration into a first-order
semidefinite programming solver confirms that our low-precision projections
reliably yield solutions of moderate accuracy.

</details>


### [15] [A deep learning approach to multi-marginal optimal transport via Hilbert space embeddings of probability measures](https://arxiv.org/abs/2507.09206)
*Yumiharu Nakano,Takafumi Saito*

Main category: math.OC

TL;DR: 提出一种解决多边际Monge问题的数值方法，基于概率测度的希尔伯特空间嵌入，采用最大均值差异惩罚技术，适用于大规模计算。


<details>
  <summary>Details</summary>
Motivation: 将经典Monge问题扩展到多目标分布场景，解决传统方法在多边际情况下的局限性。

Method: 利用希尔伯特空间嵌入概率测度，通过最大均值差异（MMD）惩罚技术强制边际约束，支持GPU加速的大规模计算。

Result: 数值实验验证了该方法在合成数据上的有效性，展示了计算效率与精度。

Conclusion: 所提方法为多边际Monge问题提供了高效数值解决方案，适用于实际大规模问题。

Abstract: We propose a numerical method for solving the multi-marginal Monge problem,
which extends the classical Monge formulation to settings involving multiple
target distributions. Our approach is based on the Hilbert space embedding of
probability measures and employs a penalization technique using the maximum
mean discrepancy to enforce marginal constraints. The method is designed to be
computationally efficient, enabling GPU-based implementation suitable for
large-scale problems. We confirm the effectiveness of the proposed method
through numerical experiments using synthetic data.

</details>


### [16] [Coordinated Communication and Inventory Optimization in Multi-Retailer Supply Chains](https://arxiv.org/abs/2507.09223)
*Sagar Sudhakara,Yuchong Zhang*

Main category: math.OC

TL;DR: 研究多零售商供应链中动态信息共享与库存控制的联合优化问题，提出基于POMDP的集中式决策模型，通过有限数据摘要减少通信频率而不影响性能。


<details>
  <summary>Details</summary>
Motivation: 传统固定信息共享协议（如始终共享或从不共享）无法平衡通信成本与运营绩效，需探索灵活的信息交换机制以优化供应链协同。

Method: 采用公共信息框架建立集中式POMDP模型，结合动态规划求解最优策略；引入近似点基POMDP方法（PBVI/SARSOP）处理计算复杂度，并考虑通信频率的实际约束。

Result: 数值实验表明，相比静态共享策略，该方法显著改善成本与服务水平的权衡，零售商仅需共享有限数据摘要即可实现近最优性能。

Conclusion: 动态信息共享策略能有效优化供应链协同库存控制，在降低通信开销的同时维持运营效率，为实际系统提供了可扩展的解决方案。

Abstract: We consider a multi-retailer supply chain where each retailer can dynamically
choose when to share information (e.g., local inventory levels or demand
observations) with other retailers, incurring a communication cost for each
sharing event. This flexible information exchange mechanism contrasts with
fixed protocols such as always sharing or never sharing. We formulate a joint
optimization of inventory control and communication strategies, aiming to
balance the trade-off between communication overhead and operational
performance (service levels, holding, and stockout costs). We adopt a common
information framework and derive a centralized Partially Observable Markov
Decision Process (POMDP) model for a supply chain coordinator. Solving this
coordinator's POMDP via dynamic programming characterizes the structure of
optimal policies, determining when retailers should communicate and how they
should adjust orders based on available information. We show that, in this
setting, retailers can often act optimally by sharing only limited summaries of
their private data, reducing communication frequency without compromising
performance. We also incorporate practical constraints on communication
frequency and propose an approximate point-based POMDP solution method
(PBVI/SARSOP) to address computational complexity. Numerical experiments on
multi-retailer inventory scenarios demonstrate that our approach significantly
improves the cost-service trade-off compared to static information sharing
policies, effectively optimizing the schedule of information exchange for
cooperative inventory control.

</details>


### [17] [A Rockafellar Theorem for cyclically quasi-monotone maps: the regular non-vanishing case](https://arxiv.org/abs/2507.09437)
*Luigi De Pascale,Paul Pegon*

Main category: math.OC

TL;DR: 研究了循环拟单调性与拟凸性之间的联系，证明了在特定条件下循环拟单调映射可包含于拟凸函数的法锥算子中，并探讨了经济学与最优运输中的应用。


<details>
  <summary>Details</summary>
Motivation: 探索循环拟单调映射是否总能包含于拟凸函数的法锥算子中，类比于Rockafellar关于凸函数的定理，以扩展数学理论在经济学和最优运输中的应用。

Method: 针对$\mathscr{C}^1$-正则且非零的映射及一维多值映射，提供了理论证明，并通过显式构造和示例说明一般情况下的主要挑战。

Result: 在任意维度下对$\mathscr{C}^1$-正则非零映射及一维多值映射，证明了循环拟单调映射可包含于拟凸函数的法锥算子中。

Conclusion: 研究为循环拟单调性与拟凸性关系提供了部分解答，揭示了在经济学与$L^\infty$最优运输中的潜在应用，但一般情况仍存在挑战。

Abstract: We study the connection between cyclic quasi-monotonicity and
quasi-convexity, focusing on whether every cyclically quasi-monotone (possibly
multivalued) map is included in the normal cone operator of a quasi-convex
function, in analogy with Rockafellar's theorem for convex functions. We
provide a positive answer for $\mathscr{C}^1$-regular, non-vanishing maps in
any dimension, as well as for general multi-maps in dimension $1$. We further
discuss connections to revealed preference theory in economics and to
$L^\infty$ optimal transport. Finally, we present explicit constructions and
examples, highlighting the main challenges that arise in the general case.

</details>


### [18] [Improving Full Strong Branching Decisions by Incorporating Additional Information](https://arxiv.org/abs/2507.09455)
*Prachi Shah,Santanu S. Dey*

Main category: math.OC

TL;DR: 本文改进了全强分支规则(FSB)，通过调整LP增益评估和引入全局不对称趋势检测，显著减少了分支定界树的大小和未解决问题间隙。


<details>
  <summary>Details</summary>
Motivation: 全强分支规则(FSB)虽能生成极小分支定界树，但其依赖局部LP增益的决策存在两个缺陷：可能高估全局对偶界改进，且无法预见分支决策对后续可行性和整数性的影响。

Method: 1. 结合原始界调整LP增益权重；2. 检测0/1赋值导致的全局不对称趋势并整合到FSB评分函数；3. 将方法扩展到可靠性分支(RB)并优化评分。

Result: 在MIPLIB 2017测试中：已解决案例的树规模平均减少22-35\%，未解决案例间隙降低3.6-5.6\%；改进的RB评分使已解决案例树规模减少5-13\%，未解决案例间隙降低2.6-4.3\%。

Conclusion: 通过修正FSB的局部性缺陷并引入全局趋势分析，新方法能生成更平衡的分支定界树，显著提升求解效率，且改进策略可推广至其他分支规则。

Abstract: The full strong branching (FSB) rule is well known to produce extremely small
branch-and-bound trees. This rule guides branching decisions based exclusively
on the information regarding local gains in the linear programming (LP) bounds.
We identify and correct two key shortcomings in FSB. First, the LP gains may be
overestimations of the improvement in global dual bounds whenever pruning is
possible. We propose a modification to address this issue, that incorporates
primal bounds and readjusts the relative importance of the larger and smaller
LP gains. Second, FSB decisions may be myopic as they consider only local LP
gains and cannot foresee the impact of branching decisions on feasibility or
integrality beyond immediate children. To address this weakness, we present an
approach that detects global asymmetry trends in infeasibility and integrality
due to 0 and 1 assignments and incorporates them into the FSB score function.
We further extend this approach to achieve more balanced trees even when the
branch-and-bound tree prunes primarily by bounds.
  Using randomly generated problem instances with known structures, we derive
insights and fine-tune our modified scores. Evaluation on MIPLIB 2017 Benchmark
instances shows a 22-35\% reduction in mean tree sizes for solved cases and a
3.6-5.6\% decrease in the remaining gap for unsolved ones. Our approach extends
to reliability branching (RB), where improved scores reduce mean tree sizes by
5-13\% on solved instances and lower the mean gap by 2.6-4.3\% on unsolved
instances, depending on primal bound quality.

</details>


### [19] [A Mixed-Integer Bi-level Model for Joint Optimal Edge Resource Pricing and Provisioning](https://arxiv.org/abs/2507.09498)
*Duong Thuy Anh Nguyen,Tarannum Nisha,Ni Trieu,Duong Tung Nguyen*

Main category: math.OC

TL;DR: 本文研究了边缘计算中边缘节点激活与资源定价的联合优化问题，提出了一种基于双层规划的分解迭代算法，以实现平台净收益最大化并满足服务的成本优化需求。


<details>
  <summary>Details</summary>
Motivation: 边缘计算平台需为多样化服务提供异构资源，而传统方法难以处理包含整数变量的非凸双层规划问题，因此需要开发新的优化技术。

Method: 受鲁棒优化中列约束生成方法的启发，设计了一种分解式迭代算法，精确求解包含整数变量的非凸双层规划问题。

Result: 大量数值实验验证了所提模型与算法的有效性，能够同时优化平台利润和服务成本。

Conclusion: 该研究为边缘计算资源管理提供了理论框架与实用工具，通过协同优化定价与节点激活策略实现多方共赢。

Abstract: This paper studies the joint optimization of edge node activation and
resource pricing in edge computing, where an edge computing platform provides
heterogeneous resources to accommodate multiple services with diverse
preferences. We cast this problem as a bi-level program, with the platform
acting as the leader and the services as the followers. The platform aims to
maximize net profit by optimizing edge resource prices and edge node
activation, with the services' optimization problems acting as constraints.
Based on the platform's decisions, each service aims to minimize its costs and
enhance user experience through optimal service placement and resource
procurement decisions. The presence of integer variables in both the upper and
lower-level problems renders this problem particularly challenging. Traditional
techniques for transforming bi-level problems into single-level formulations
are inappropriate owing to the non-convex nature of the follower problems.
Drawing inspiration from the column-and-constraint generation method in robust
optimization, we develop an efficient decomposition-based iterative algorithm
to compute an exact optimal solution to the formulated bi-level problem.
Extensive numerical results are presented to demonstrate the efficacy of the
proposed model and technique.

</details>


### [20] [Characterizations of Strong Variational Sufficiency in General Models of Composite Optimization](https://arxiv.org/abs/2507.09522)
*Boris S. Mordukhovich,Peipei Tang,Chengjing Wang*

Main category: math.OC

TL;DR: 本文研究了优化问题中的强变分充分性概念，针对复合优化问题建立了局部极小点的强变分充分性完整刻画，通过广义强二阶充分条件(SSOSC)和增广拉格朗日函数的广义Hessian矩阵正定性实现。


<details>
  <summary>Details</summary>
Motivation: 强变分充分性在优化理论、数值方法和应用中具有重要意义，但现有研究尚未完全覆盖非凸复合优化问题。本文旨在填补这一空白，特别是在涉及核范数和半正定锥指示函数等非多面体问题时。

Method: 采用广义强二阶充分条件(SSOSC)和新型二阶变分函数来刻画局部极小点的强变分充分性，该方法适用于无约束条件的非多面体复合优化问题。

Result: 成功建立了复合优化问题局部极小点强变分充分性的完整特征，证明了其与广义SSOSC和增广拉格朗日函数广义Hessian矩阵正定性的等价关系。

Conclusion: 该研究为复合优化问题提供了新的理论工具，特别是在处理核范数和半正定锥等非多面体问题时具有显著优势，且不需要任何约束规范条件。

Abstract: This paper investigates a recently introduced notion of strong variational
sufficiency in optimization problems whose importance has been highly
recognized in optimization theory, numerical methods, and applications. We
address a general class of composite optimization problems and establish
complete characterizations of strong variational sufficiency for their local
minimizers in terms of a generalized version of the strong second-order
sufficient condition (SSOSC) and the positive-definiteness of an appropriate
generalized Hessian of the augmented Lagrangian calculated at the point in
question. The generalized SSOSC is expressed via a novel second-order
variational function, which reflects specific features of nonconvex composite
models. The imposed assumptions describe the spectrum of composite optimization
problems covered by our approach while being constructively implemented for
nonpolyhedral problems that involve the nuclear norm function and the indicator
function of the positive-semidefinite cone without any constraint
qualifications.

</details>


### [21] [Frank-Wolfe Recursions for the Emergency Response Problem on Measure Spaces](https://arxiv.org/abs/2507.09808)
*Di Yu,Shane G. Henderson,Raghu Pasupathy*

Main category: math.OC

TL;DR: 本文提出了一种针对院外心脏骤停（OHCA）应急响应的无限维优化方法，通过志愿者资源空间分配最小化死亡概率，并开发了无需离散化的全校正Frank-Wolfe算法。


<details>
  <summary>Details</summary>
Motivation: 解决院外心脏骤停应急响应中志愿者资源空间分配的最优化问题，该问题具有无限维特性且存在分析与计算挑战。

Method: 建立目标函数的凸性、可行集紧性等结构特性，推导影响函数作为一阶变分对象，并采用直接处理无限维问题的全校正Frank-Wolfe算法。当志愿者移动采用$L_1$范数建模时，影响函数呈现分段严格凹性。

Result: 算法在离散案例中展现复杂解结构，在连续案例中揭示非平凡分配方案，并能基于奥克兰市OHCA数据扩展到实际城市场景。即使子问题未达全局最优仍具有收敛性。

Conclusion: 该框架可自然扩展到广义$P$-均值问题类别，当采用$L_1$范数时支持快速计算，为空间资源分配问题提供了理论保障与实用工具。

Abstract: We consider an optimization problem over measures for emergency response to
out-of-hospital cardiac arrest (OHCA), where the goal is to allocate volunteer
resources across a spatial region to minimize the probability of death. The
problem is infinite-dimensional and poses challenges for analysis and
computation. We first establish structural properties, including convexity of
the objective functional, compactness of the feasible set, and existence of
optimal solutions. We also derive the influence function, which serves as the
first-order variational object in our optimization framework. We then adapt and
analyze a fully-corrective Frank-Wolfe (fc-FW) algorithm that operates directly
on the infinite-dimensional problem without discretization or parametric
approximation. We show a form of convergence even when subproblems are not
solved to global optimality. Our full implementation of fc-FW demonstrates
complex solution structure even in simple discrete cases, reveals nontrivial
volunteer allocations in continuous cases, and scales to realistic urban
scenarios using OHCA data from the city of Auckland, New Zealand. Finally, we
show that when volunteer travel is modeled through the $L_1$ norm, the
influence function is piecewise strictly concave, enabling fast computation via
support reduction. The proposed framework and analysis extend naturally to a
broad class of $P$-means problems.

</details>


### [22] [Nesterov Finds GRAAL: Optimal and Adaptive Gradient Method for Convex Optimization](https://arxiv.org/abs/2507.09823)
*Ekaterina Borodich,Dmitry Kovalev*

Main category: math.OC

TL;DR: 本文提出了一种结合Nesterov加速的自适应梯度方法GRAAL，用于最小化连续可微凸函数$f(x)$，实现了$\mathcal{O}(1/k^2)$的最优收敛速率，且无需线搜索或超参数调优。


<details>
  <summary>Details</summary>
Motivation: 现有自适应梯度方法（如GRAAL）虽能避免超参数调优并达到$\mathcal{O}(1/k)$收敛，但无法匹配Nesterov加速的$\mathcal{O}(1/k^2)$最优速率。本文旨在解决这一局限性。

Method: 将Nesterov加速机制融入GRAAL框架，提出新算法。该算法通过估计目标函数局部曲率自适应计算步长，且允许任意小的初始步长（仅增加对数级迭代复杂度）。

Result: 理论证明新算法对Lipschitz光滑函数达到$\mathcal{O}(1/k^2)$最优收敛率，其自适应能力显著优于现有加速方法（如Li和Lan 2023年的尝试）。

Conclusion: GRAAL结合Nesterov加速后，首次实现自适应梯度方法在保持超参数鲁棒性的同时达到最优收敛速率，为凸优化提供了更高效的解决方案。

Abstract: In this paper, we focus on the problem of minimizing a continuously
differentiable convex objective function $\min_x f(x)$. Recently, several
adaptive gradient methods, including GRAAL (Malitsky, 2020), have been
developed. These methods estimate the local curvature of the objective function
to compute stepsizes, attain the standard convergence rate $\mathcal{O}(1/k)$
of fixed-stepsize gradient descent for Lipschitz-smooth functions, and do not
require any line search procedures or hyperparameter tuning. However, a natural
question arises: is it possible to accelerate the convergence of these
algorithms to match the optimal rate $\mathcal{O}(1/k^2)$ of the accelerated
gradient descent of Nesterov (1983)? Although some attempts have been made (Li
and Lan, 2023), the capabilities of the existing accelerated algorithms to
adapt to the curvature of the objective function are highly limited.
Consequently, we provide a positive answer to this question and develop GRAAL
with Nesterov acceleration. We prove that our algorithm achieves the desired
optimal convergence rate for Lipschitz smooth functions. Moreover, in contrast
to existing methods, it does so with an arbitrary, even excessively small,
initial stepsize at the cost of a logarithmic additive term in the iteration
complexity.

</details>


### [23] [Optimal Design of Satellite Constellation Configurations with Mixed Integer Linear Programming](https://arxiv.org/abs/2507.09855)
*David O. Williams Rogers,Dongshik Won,Dongwook Koh,Kyungwoo Hong,Hang Woon Lee*

Main category: math.OC

TL;DR: 本文提出了一种统一的卫星星座配置设计框架，通过五种混合整数线性规划模型解决不同任务场景下的覆盖优化问题，支持多种指标和复杂任务需求。


<details>
  <summary>Details</summary>
Motivation: 卫星星座设计中覆盖性能是系统成本和性能的关键因素，现有方法针对不同场景需单独处理，缺乏统一框架。本文旨在解决这一局限性。

Method: 提出包含五种混合整数线性规划模型的统一框架，可扩展复杂任务约束，支持覆盖百分比、重访时间、卫星数量等多种指标，适用于静态/动态目标。

Result: 案例研究和对比分析表明，该框架能获得数学可证明的最优星座配置，并灵活适应地面/航空/太空等不同任务场景的时空变化需求。

Conclusion: 该统一框架突破了传统问题导向方法的局限性，为多任务场景下的星座配置权衡研究提供了通用且可扩展的解决方案。

Abstract: Designing satellite constellation systems involves complex multidisciplinary
optimization in which coverage serves as a primary driver of overall system
cost and performance. Among the various design considerations, constellation
configuration -- how satellites are placed and distributed in space relative to
each other -- predominantly determines the resulting coverage. In constellation
configuration design, coverage can be considered either as an objective or a
constraint, driven by mission objectives. State-of-the-art literature addresses
each situation on a case-by-case basis, applying a unique set of assumptions,
modeling, and solution methods. Although such a problem-based methodology is
valuable, users often face implementation challenges when performing trade-off
studies across different mission scenarios, as each scenario must be handled
distinctly. In response, we propose a unifying framework consisting of five
mixed-integer linear program formulations that are of practical significance,
extensible to more complex mission narratives using additional constraints, and
capable of obtaining provably optimal constellation configurations. It can
handle various metrics and mission scenarios, such as percent coverage, average
or maximum revisit times, fixed number of satellites, spatiotemporally varying
coverage requirements, and ground-, aerial-, or space-based, static or mobile
targets. The paper presents several add-ons, case studies, and comparative
analyses to demonstrate the versatility of the proposed framework.

</details>


### [24] [Gromov-Wasserstein Barycenters: The Analysis Problem](https://arxiv.org/abs/2507.09865)
*Rocío Díaz Martín,Ivan V. Medri,James M. Murphy*

Main category: math.OC

TL;DR: 本文提出基于Gromov-Wasserstein(GW)距离的质心编码模型(BCM)，用于估计有限度量空间中的成对距离矩阵或网络边权矩阵，并开发了两种求解GW质心坐标的计算方法。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过GW距离下的质心坐标来表征未知目标矩阵，假设该矩阵属于已知模板集的GW质心组合，这相当于调和分析中的逆问题求解。

Method: 提出两种方法：1)基于不动点迭代的GW质心计算；2)采用微分方法与blow-up技术相结合的GW结构分析方法。

Result: 通过数值实验和机器学习应用验证了所提GW分析框架的有效性，展示了其在矩阵估计任务中的实用性。

Conclusion: 该工作建立了GW距离下的分析-综合对偶框架，为网络数据与度量空间的矩阵表示提供了新的计算工具。

Abstract: This paper considers the problem of estimating a matrix that encodes pairwise
distances in a finite metric space (or, more generally, the edge weight matrix
of a network) under the barycentric coding model (BCM) with respect to the
Gromov-Wasserstein (GW) distance function. We frame this task as estimating the
unknown barycentric coordinates with respect to the GW distance, assuming that
the target matrix (or kernel) belongs to the set of GW barycenters of a finite
collection of known templates. In the language of harmonic analysis, if
computing GW barycenters can be viewed as a synthesis problem, this paper aims
to solve the corresponding analysis problem. We propose two methods: one
utilizing fixed-point iteration for computing GW barycenters, and another
employing a differentiation-based approach to the GW structure using a blow-up
technique. Finally, we demonstrate the application of the proposed GW analysis
approach in a series of numerical experiments and applications to machine
learning.

</details>


### [25] [On the Convergence of the Policy Iteration for Infinite-Horizon Nonlinear Optimal Control Problems](https://arxiv.org/abs/2507.09994)
*Tobias Ehring,Behzad Azmi,Bernard Haasdonk*

Main category: math.OC

TL;DR: 本文研究了策略迭代（PI）在无限时域、非线性、自治最优控制问题中的理论挑战，特别是计算状态空间受限时的可行性，提出了保证计算域前向不变性的构造性方法，并建立了广义Hamilton-Jacobi-Bellman（GHJB）方程解的存在性、唯一性和正则性条件。


<details>
  <summary>Details</summary>
Motivation: 策略迭代在工程和科学领域广泛应用，但在无限时域非线性自治最优控制问题中，特别是计算状态空间受限时，存在理论挑战，尤其是GHJB方程解的存在性、唯一性和正则性，以及计算域的前向不变性，这些在以往研究中被忽视。

Method: 通过引入构造性程序保证整个PI序列中计算域的前向不变性，并建立GHJB方程解在每个迭代步骤中具有足够正则性的充分条件。

Result: 理论分析表明，所提方法能确保计算域的前向不变性，并在每个迭代步骤中存在足够正则的GHJB解。数值结果支持了理论发现。

Conclusion: 本文填补了策略迭代在无限时域非线性最优控制问题中的理论空白，通过构造性方法和正则性条件，确保了PI算法的可行性，为实际应用提供了理论保障。

Abstract: Policy iteration (PI) is a widely used algorithm for synthesizing optimal
feedback control policies across many engineering and scientific applications.
When PI is deployed on infinite-horizon, nonlinear, autonomous optimal-control
problems, however, a number of significant theoretical challenges emerge -
particularly when the computational state space is restricted to a bounded
domain. In this paper, we investigate these challenges and show that the
viability of PI in this setting hinges on the existence, uniqueness, and
regularity of solutions to the Generalized Hamilton-Jacobi-Bellman (GHJB)
equation solved at each iteration. To ensure a well-posed iterative scheme, the
GHJB solution must possess sufficient smoothness, and the domain on which the
GHJB equation is solved must remain forward-invariant under the closed-loop
dynamics induced by the current policy. Although fundamental to the method's
convergence, previous studies have largely overlooked these aspects. This paper
closes that gap by introducing a constructive procedure that guarantees forward
invariance of the computational domain throughout the entire PI sequence and by
establishing sufficient conditions under which a suitably regular GHJB solution
exists at every iteration. Numerical results are presented for a grid-based
implementation of PI to support the theoretical findings.

</details>


### [26] [On the structure of optimal solutions of conservation laws at a junction with one incoming and one outgoing arc](https://arxiv.org/abs/2507.10090)
*Fabio Ancona,Annalisa Cesaroni,Giuseppe Maria Coclite,Mauro Garavello*

Main category: math.OC

TL;DR: 研究1-1网络上严格凹守恒律的极小极大问题，通过节点流入控制优化解的总变差与通量时间积分的最大化。


<details>
  <summary>Details</summary>
Motivation: 探讨在节点处通过流入控制优化守恒律解的总变差与通量积分最大化的方法，以解决初始数据非单调时的最优控制问题。

Method: 建立初始边界值问题解的总变差受初始数据和边界通量总变差控制的规律性结果，分析单调初始数据下熵弱解通量的最优性。

Result: 证明在初始数据单调时，熵弱解在节点处的通量提供最优流入控制；非单调初始数据时，熵弱解通量不再最优，并通过两个原型示例验证。

Conclusion: 熵弱解通量在初始数据单调时为极小极大问题提供最优控制，但在非单调情况下需寻找其他优化策略。

Abstract: We consider a min-max problem for strictly concave conservation laws on a 1-1
network, with inflow controls acting at the junction. We investigate the
minimization problem for a functional measuring the total variation of the flow
of the solutions at the node, among those solutions that maximize the time
integral of the flux. To formulate this problem we establish a regularity
result showing that the total variation of the boundary-flux of the solution of
an initial-boundary value problem is controlled by the total variation of the
initial datum and of the flux of the boundary datum. In the case the initial
datum is monotone, we show that the flux of the entropy weak solution at the
node provides an optimal inflow control for this min-max problem. We also
exhibit two prototype examples showing that, in the case where the initial
datum is not monotone, the flux of the entropy weak solution is no more
optimal.

</details>


### [27] [Simultaneous Design of Microbe and Bioreactor](https://arxiv.org/abs/2507.10128)
*Anita L. Ziegler,Marc-Daniel Stumm,Tim Prömper,Thomas Steimann,Jørgen Magnus,Alexander Mitsos*

Main category: math.OC

TL;DR: 本文提出SimulKnockReactor双层优化方法，将生物反应器设计与微生物菌株设计结合，相比传统分步方法降低成本并提升效率。


<details>
  <summary>Details</summary>
Motivation: 传统生物技术工艺开发采用分步方法（代谢工程→实验室优化→生物反应器放大），存在成本高、耗时长且结果次优的问题。

Method: 上层（生物反应器级）通过连续搅拌釜反应器优化搅拌/通气/pH控制的投资与运行成本；下层（细胞级）基于通量平衡分析实现上层预测的最优反应敲除。

Result: 使用大肠杆菌核心和基因组尺度代谢模型验证表明：1）底物是最大成本因素；2）本方法比OptKnock顺序方法更能保证生产能力，且年成本相同或更低。

Conclusion: SimulKnockReactor通过整合细胞与生物反应器层级优化，向全集成生物工艺设计迈出重要一步。

Abstract: When developing a biotechnological process, the microorganism is first
designed, e.g., using metabolic engineering. Then, the optimum fermentation
parameters are determined on a laboratory scale, and lastly, they are
transferred to the bioreactor scale. However, this step-by-step approach is
costly and time-consuming and may result in suboptimal configurations. Herein,
we present the bilevel optimization formulation SimulKnockReactor, which
connects bioreactor design with microbial strain design, an extension of our
previous formulation, SimulKnock (Ziegler et al., 2024, AIChE J.). At the upper
(bioreactor) level, we minimize investment and operation costs for agitation,
aeration, and pH control by determining the size and operating conditions of a
continuous stirred-tank reactor - without selecting specific devices like the
stirrer type. The lower (cellular) level is based on flux balance analysis and
implements optimal reaction knockouts predicted by the upper level. Our results
with a core and a genome-scale metabolic model of Escherichia coli show that
the substrate is the largest cost factor. Our simultaneous approach outperforms
a sequential approach using OptKnock. Namely, the knockouts proposed by
OptKnock cannot guarantee the required production capacity in all cases
considered. In the case that both approaches deliver feasible results, the
total annual costs are the same or lower with SimulKnockReactor, highlighting
the advantage of combining cellular and bioreactor levels. This work is a
further step towards a fully integrated bioprocess design.

</details>


### [28] [System Realizations by Mammillary Models with an Application to Propofol Pharmacokinetics](https://arxiv.org/abs/2507.10138)
*Veronica Beltrami,Luca Consolini,Mattia Laurini,Marco Milanesi,Michele Schiavo,Antonio Visioli*

Main category: math.OC

TL;DR: 本研究提出了线性系统通过乳腺模型实现的条件，为临床药理学中生理可解释的模型提供了数学基础，并以丙泊酚输注模型为例进行了验证。


<details>
  <summary>Details</summary>
Motivation: 标准识别技术获得的传递函数常缺乏与生理过程的明确关联，而乳腺模型能反映分布与消除的生理动态，这对临床药理学中模型参数的可解释性、个性化及安全给药至关重要。

Method: 研究提供了传递函数可表示为乳腺模型的充分必要条件，建立了数学模型与生理过程的对应关系。

Result: 通过丙泊酚输注模型的应用实例，证明了乳腺模型实现能支持具有生理可解释性的系统表示。

Conclusion: 乳腺模型实现为临床药理学（如全静脉麻醉）提供了兼具数学严谨性与生理可解释性的建模工具。

Abstract: This work addresses the problem of linear system realizations by mammillary
models, offering necessary and sufficient conditions under which a given
transfer function can be represented in this form. While standard identifi
cation techniques may yield transfer functions without an explicit connection
to underlying physiological processes, com partmental models, particularly
mammillary ones, reflect the physiological dynamics of distribution and
elimination. This feature is especially relevant in clinical pharmacology,
where model parameters must correspond to meaningful biological processes to
support interpretability, personalization, and safe drug delivery, such as in
total intravenous anesthesia. To conclude, an application to a propofol
infusion model illustrates how mammillary realizations can support
physiologically inter pretable system representations.

</details>


### [29] [Recursive Feasibility without Terminal Constraints via Parent-Child MPC Architecture](https://arxiv.org/abs/2507.10166)
*Filip Surmaa,Anahita Jamshidnejad*

Main category: math.OC

TL;DR: 本文提出了一种新颖的分层模型预测控制（MPC）框架——Parent-Child MPC架构，用于在不确定性下引导非线性系统朝向目标集，平衡计算复杂度并保证递归可行性和稳定性，而无需依赖保守的终端约束。


<details>
  <summary>Details</summary>
Motivation: 传统MPC方法在处理非线性系统时存在计算复杂度高、保守性强等问题，需要一种既能保证性能又能提高计算效率的新方法。

Method: 通过将短时域的Child MPC层与一个或多个长时域的Parent MPC层耦合，利用基于管控制的阶段约束确保递归可行性和稳定性。

Result: 案例研究表明，与传统MPC方法相比，Parent-Child MPC架构提高了性能和计算效率，减少了保守性，并实现了对某些非线性系统的可扩展规划。

Conclusion: Parent-Child MPC架构为非线性系统的控制提供了一种高效且可扩展的解决方案，显著提升了传统MPC方法的性能。

Abstract: This paper proposes a novel hierarchical model predictive control (MPC)
framework, called the Parent-Child MPC architecture, to steer nonlinear systems
under uncertainty towards a target set, balancing computational complexity and
guaranteeing recursive feasibility and stability without relying on
conservative terminal constraints in online decision-making. By coupling a
small-horizon Child MPC layer with one or more large-horizon Parent MPC layers,
the architecture ensures recursive feasibility and stability through adjustable
stage-wise constraints derived from tube-based control. As is demonstrated in
our case studies, compared to traditional MPC methods, the proposed
Parent-Child MPC architecture enhances performance and computational
efficiency, reduces conservativeness, and enables scalable planning for certain
nonlinear systems.

</details>


### [30] [Well-posedness of an optical flow based optimal control formulation for image registration](https://arxiv.org/abs/2507.10188)
*Johannes Haubner,Christian Clason*

Main category: math.OC

TL;DR: 本文提出了一种基于最优控制的光流图像配准方法，通过引入松弛优化和Orlicz空间处理非自反Banach空间问题，并建立了线性双曲输运方程的新存在唯一性结果。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于将图像配准问题转化为最优控制问题，通过光流公式处理线性双曲输运方程，解决非自反Banach空间中的优化挑战。

Method: 方法包括引入平滑的最大最小值函数松弛优化问题，利用Orlicz空间理论，并对线性双曲输运方程进行新的存在性和唯一性分析。

Result: 结果表明，松弛后的优化问题具有良好的适定性，同时关于松弛参数和离散化的极限考虑也得到了有效讨论。

Conclusion: 结论指出，所提出的方法为图像配准提供了一种新的理论框架，通过松弛优化和Orlicz空间的应用，解决了非自反Banach空间中的优化难题。

Abstract: We consider image registration as an optimal control problem using an optical
flow formulation, i.e., we discuss an optimization problem that is governed by
a linear hyperbolic transport equation. Requiring Lipschitz continuity of the
vector fields that parametrize the transformation leads to an optimization
problem in a non-reflexive Banach space. We introduce relaxations of the
optimization problem involving smoothed maximum and minimum functions and
appropriate Orlicz spaces. To derive well-posedness results for the relaxed
optimization problem, we revisit and establish new existence and uniqueness
results for the linear hyperbolic transport equations. We further discuss limit
considerations with respect to the relaxation parameter and discretizations.

</details>


### [31] [The Reconfigurable Earth Observation Satellite Scheduling Problem](https://arxiv.org/abs/2507.10394)
*Brycen D. Pearl,Joseph M. Miller,Hang Woon Lee*

Main category: math.OC

TL;DR: 本文提出了一种可重构地球观测卫星调度问题（REOSSP），通过卫星机动性优化星座配置，并开发了混合整数线性规划模型及滚动时域算法（RHP）以提升大规模问题的计算效率。实验表明REOSSP在性能上优于传统EOSSP，RHP显著减少了计算时间。


<details>
  <summary>Details</summary>
Motivation: 传统地球观测卫星调度问题（EOSSP）局限于固定星座配置，限制了观测效率。本文利用卫星机动性提出REOSSP，旨在通过动态重构星座提升观测效能。

Method: 开发了REOSSP的混合整数线性规划模型，并针对大规模问题设计了滚动时域算法（RHP）。通过随机实例和飓风桑迪案例验证模型性能。

Result: 实验表明，REOSSP相比传统EOSSP显著提升了观测性能，RHP有效缩短了大规模问题的计算时间。

Conclusion: 星座可重构性为地球观测卫星调度带来显著改进，REOSSP模型及RHP算法在理论与实践上均具有重要价值。

Abstract: Earth observation satellites (EOS) play a pivotal role in capturing and
analyzing planetary phenomena, ranging from natural disasters to societal
development. The EOS scheduling problem (EOSSP), which optimizes the schedule
of EOS, is often solved with respect to nadir-directional EOS systems, thus
restricting the observation time of targets and, consequently, the
effectiveness of each EOS. This paper leverages state-of-the-art constellation
reconfigurability to develop the reconfigurable EOS scheduling problem
(REOSSP), wherein EOS are assumed to be maneuverable, forming a more optimal
constellation configuration at multiple opportunities during a schedule. This
paper develops a novel mixed-integer linear programming formulation for the
REOSSP to optimally solve the scheduling problem for given parameters.
Additionally, since the REOSSP can be computationally expensive for large-scale
problems, a rolling horizon procedure (RHP) solution method is developed. The
performance of the REOSSP is benchmarked against the EOSSP, which serves as a
baseline, through a set of random instances where problem characteristics are
varied and a case study in which Hurricane Sandy is used to demonstrate
realistic performance. These experiments demonstrate the value of constellation
reconfigurability in its application to the EOSSP, yielding solutions that
improve performance, while the RHP enhances computational runtime for
large-scale REOSSP instances.

</details>


### [32] [Multiobjective Aerodynamic Design Optimization of the NASA Common Research Model](https://arxiv.org/abs/2507.10488)
*Kade Carlson,Ashwin Renganathan*

Main category: math.OC

TL;DR: 提出了一种名为$q\texttt{POTS}$的新型多目标贝叶斯优化方法，用于飞机气动设计优化，解决了传统多点优化方法的偏差问题，并在样本效率和准确性上优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 传统飞机气动设计优化采用多点加权平均方法，存在权重设定偏差导致的次优设计问题。多目标优化虽能避免此问题，但现有方法在样本效率、可扩展性和并行评估方面存在不足。

Method: 提出基于Thompson采样的多目标贝叶斯优化方法$q\texttt{POTS}$，利用高斯过程代理和贝叶斯决策理论，根据帕累托最优概率生成迭代序列，支持同步并行评估。

Result: 在合成实验和24维NASA通用研究模型的两目标气动设计优化中，$q\texttt{POTS}$表现出优于现有技术的样本效率和准确性，并提供了开源软件实现。

Conclusion: $q\texttt{POTS}$方法有效解决了多目标优化的关键挑战，为飞机气动设计提供了更高效、更准确的优化方案，具有实际应用价值。

Abstract: Aircraft aerodynamic design optimization must account for the varying
operating conditions along the cruise segment as opposed to designing at one
fixed operating condition, to arrive at more realistic designs. Conventional
approaches address this by performing a ``multi-point'' optimization that
assumes a weighted average of the objectives at a set of sub-segments along the
cruise segment. We argue that since such multi-point approaches are,
inevitably, biased by the specification of the weights, they can lead to
sub-optimal designs. Instead, we propose to optimize the aircraft design at
multiple sub-segments simultaneously -- that is, via multiobjective
optimization that leads to a set of Pareto optimal solutions. However, existing
work in multiobjective optimization suffers from (i) lack of sample efficiency
(that is, keeping the number of function evaluations to convergence minimal),
(ii) scalability with input dimensions and number of objectives, and (iii) the
ability to generate a batch of iterates for synchronous parallel evaluations.
To overcome these limitations, we propose a novel multiobjective Bayesian
optimization methodology that demonstrates improved sample efficiency and
accuracy compared to the state of the art. Inspired by Thompson sampling, our
approach leverages Gaussian process surrogates and Bayesian decision theory to
generate a sequence of iterates according to the probability that they are
Pareto optimal. Our approach, named batch Pareto optimal Thompson sampling
($q\texttt{POTS}$), demonstrates superior empirical performance on a variety of
synthetic experiments as well as a $24$ dimensional two-objective aerodynamic
design optimization of the NASA common research model. We also provide
open-source software of our methodology.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [33] [The modularity of an abelian variety](https://arxiv.org/abs/2507.08970)
*Jae-Hyun Yang*

Main category: math.NT

TL;DR: 本文扩展了椭圆曲线的模性概念，提出了有理数域上阿贝尔簇的模性，并猜想简单阿贝尔簇在有理数域上是模的。


<details>
  <summary>Details</summary>
Motivation: 研究有理数域上阿贝尔簇的模性，以扩展椭圆曲线模性理论的应用范围。

Method: 通过理论推导和数学猜想，探讨阿贝尔簇模性的定义及其在有理数域上的性质。

Result: 提出了有理数域上简单阿贝尔簇模性的猜想，为后续研究提供了方向。

Conclusion: 有理数域上的简单阿贝尔簇可能具有模性，这一猜想有待进一步验证。

Abstract: We introduce the concept of the modularity of an abelian variety defined over
the rational number field extending the modularity of an elliptic curve. We
discuss the modularity of an abelian variety over the rational number field. We
conjecture that a simple abelian variety over the rational number field is
modular.

</details>


### [34] [Explicit Bounds and Parallel Algorithms for Counting Multiply Gleeful Numbers](https://arxiv.org/abs/2507.09012)
*Sara Moore,Jonathan P. Sorenson*

Main category: math.NT

TL;DR: 本文研究了$k$-gleeful数的性质，即能表示为连续素数$k$次幂之和的正整数。通过扩展理论分析、提出高效并行算法以及研究多重gleeful数，提供了新的结果和猜想。


<details>
  <summary>Details</summary>
Motivation: 研究$k$-gleeful数的表示及其性质，填补$k>1$时的理论空白，并为计算和密度估计提供新方法。

Method: 1. 扩展理论分析，给出$x$和$k$下$k$-gleeful表示数量的上下界；2. 提出两种高效并行算法（理论算法和实用算法）生成所有$k$-gleeful表示；3. 研究多重gleeful数，提出启发式模型并验证。

Result: 1. 提供了$k$-gleeful表示数量的显式界；2. 设计了高效的并行算法；3. 通过启发式模型和实证数据支持多重gleeful数的密度估计，并提出新猜想。

Conclusion: 本文扩展了$k$-gleeful数的理论框架，提出了高效算法，并通过启发式模型和实证研究揭示了多重gleeful数的性质，为后续研究奠定了基础。

Abstract: Let $k\ge 1$ be an integer. A positive integer $n$ is $k$-\textit{gleeful} if
$n$ can be represented as the sum of $k$th powers of consecutive primes. For
example, $35=2^3+3^3$ is a $3$-gleeful number, and $195=5^2+7^2+11^2$ is
$2$-gleeful. In this paper, we present some new results on $k$-gleeful numbers
for $k>1$.
  First, we extend previous analytical work. For given values of $x$ and $k$,
we give explicit upper and lower bounds on the number of $k$-gleeful
representations of integers $n\le x$.
  Second, we describe and analyze two new, efficient parallel algorithms, one
theoretical and one practical, to generate all $k$-gleeful representations up
to a bound $x$.
  Third, we study integers that are multiply gleeful, that is, integers with
more than one representation as a sum of powers of consecutive primes,
including both the same or different values of $k$. We give a simple heuristic
model for estimating the density of multiply-gleeful numbers, we present
empirical data in support of our heuristics, and offer some new conjectures.

</details>


### [35] [On a Generalization of Motohashi's Formula: Non-archimedean Weight Functions](https://arxiv.org/abs/2507.09125)
*Han Wu*

Main category: math.NT

TL;DR: 本文延续了Kwan公式的adelic版本，在非阿基米德位置给出了混合矩侧权重函数的界限，揭示了Katz超几何和在先前与P.Xi合作工作中出现的结构原因。


<details>
  <summary>Details</summary>
Motivation: 研究目的是在$\mathrm{PGL}_3 \times \mathrm{PGL}_2$侧的权重函数接近短族特征函数时，对混合矩侧的权重函数进行界限估计。

Method: 方法适用于任何$\mathrm{PGL}_3$的调和表示$\Pi$，通过adelic版本的Kwan公式进行分析。

Result: 在非阿基米德位置获得了混合矩侧权重函数的界限，并揭示了Katz超几何和出现的结构原因。

Conclusion: 该研究不仅推广了Kwan公式的应用范围，还为理解Katz超几何和在相关工作中的出现提供了结构解释。

Abstract: This is a continuation of the adelic version of Kwan's formula. At
non-archimedean places we give a bound of the weight function on the mixed
moment side, when the weight function on the $\mathrm{PGL}_3 \times
\mathrm{PGL}_2$ side is nearly the characteristic function of a short family.
Our method works for any tempered representation $\Pi$ of $\mathrm{PGL}_3$, and
reveals the structural reason for the appearance of Katz's hypergeometric sums
in a previous joint work with P.Xi.

</details>


### [36] [On the correlations between character sums of division polynomials under shifts](https://arxiv.org/abs/2507.09271)
*Subham Bhakta,Igor E. Shparlinski*

Main category: math.NT

TL;DR: 本文研究了有限域$\mathbb{F}_p$上椭圆曲线$E$的有理点$P$的除法多项式$\psi_n(P)$与乘法特征$\chi$的双重和$S_{\chi,P}(N,h)$的均值估计，并给出了多维推广结果。


<details>
  <summary>Details</summary>
Motivation: 旨在分析椭圆曲线除法多项式与乘法特征的双重和在短区间$h \in [1, H]$上的平均行为，扩展数论中特征和的研究范畴。

Method: 通过数论与代数几何工具，对双重和$S_{\chi,P}(N,h)$进行均值估计，并采用多维推广方法扩展结论。

Result: 在短区间$h \in [1, H]$上获得了$S_{\chi,P}(N,h)$的均值估计，并成功推导出该结果的多维版本。

Conclusion: 研究为椭圆曲线与特征和的交叉领域提供了新的分析工具，其多维推广结果具有潜在的理论应用价值。

Abstract: Let $E$ be an elliptic curve over the finite field $\mathbb{F}_p$, and $P \in
E(\mathbb{F}_p)$ be an $\mathbb{F}_p$-rational point. We study the sums \[
S_{\chi,P}(N,h) = \sum_{n=1}^N \chi(\psi_n(P)) \chi(\psi_{n+h}(P)), \] where
$\psi_n(P)$ denotes the $n$-th division polynomial evaluated at $P$, and $\chi$
is a multiplicative character of $\mathbb{F}_p^{*}$. We estimate
$S_{\chi,P}(N,h)$ on average over $h$ over a rather short interval $h \in [1,
H]$. We also obtain a multidimensional generalisation of this result.

</details>


### [37] [Certain positive $q$-series and inequalities for two-color partitions](https://arxiv.org/abs/2507.09276)
*George E. Andrews,Mohamed El Bachraoui*

Main category: math.NT

TL;DR: 研究了依赖于正整数对$(k,m)$的$q$-级数，探讨其正性及与双色整数分拆的关联。


<details>
  <summary>Details</summary>
Motivation: 探索$q$-级数在不同$(k,m)$值下的正性，及其与加权双色整数分拆计数的联系。

Method: 通过分析$q$-级数生成函数，研究其对$(k,m)$的依赖性，并关联到带权重$(-1)^j$的双色整数分拆。

Result: 发现级数正性在初始$(k,m)$值成立，但其他情况尚不明确；生成函数正性可推导分拆不等式。

Conclusion: 该研究为$q$-级数正性与加权分拆不等式建立了联系，但更广泛的$(k,m)$值仍需进一步探索。

Abstract: We consider some $q$-series which depend on a pair of positive integers
$(k,m)$. While positivity of these series holds for the first few values of
$(k,m)$, the situation is quite unclear for other values of $(k,m)$. In
addition, our series generate the number of certain two-color integer
partitions weighted by $(-1)^j$ where $j$ is the number of even parts.
Therefore, inequalities involving these partitions will be deduced from the
positivity of their generating functions.

</details>


### [38] [The asymptotic Mahler measure of Gaussian periods](https://arxiv.org/abs/2507.09303)
*Gunther Cornelissen,David Hokken,Berend Ringeling*

Main category: math.NT

TL;DR: 该论文构建了一系列具有极小Mahler测度/高度的分圆整数（高斯周期），研究了其Mahler测度随导子的渐进行为，发现其增长率与高维log Calabi-Yau簇的多元Mahler测度相关。通过计算实验推测这些分圆整数在给定奇数阶循环伽罗瓦群的代数整数集中实现了最小非零对数Mahler测度，并提出了关于Mahler测度随阶数双对数增长的具体猜想。


<details>
  <summary>Details</summary>
Motivation: 研究分圆整数的Mahler测度极小值问题，探索其与高维几何对象（log Calabi-Yau簇）及代数动力系统的联系，旨在揭示数论与几何间的深层关系。

Method: 结合定量等分布理论、自反多面体与环簇理论、随机游走理论、贝塞尔函数、类域论及Linnik常数等工具，通过理论分析与计算实验相结合的方法展开研究。

Result: 发现分圆整数的Mahler测度增长率与高维log Calabi-Yau簇的多元Mahler测度一致，计算实验支持其在特定代数整数集中达到最小非零对数Mahler测度的猜想。

Conclusion: 提出Mahler测度随阶数双对数增长的精确猜想，揭示了分圆整数极小Mahler测度与高维几何、动力系统的深刻联系，为后续研究提供了新方向。

Abstract: We construct a sequence of cyclotomic integers (Gaussian periods) of
particularly small Mahler measure/height. We study the asymptotics of their
Mahler measure as a function of their conductor, to find that the growth rate
is the (multivariate) Mahler measure of a family of log Calabi-Yau varieties of
increasing dimension. In turn, we study the asymptotics of some of these Mahler
measures as the dimension increases, as well as properties of the associated
algebraic dynamical system. We describe computational experiments that suggest
that these cyclotomic integers realise the smallest non-zero logarithmic Mahler
measure in the set of algebraic integers with cyclic Galois group of a given
odd order. Finally, we discuss some precise conjectures that imply double
logarithmic growth for those Mahler measures as a function of that order. The
proofs use ideas from the theory of quantitative equidistribution, reflexive
polytopes and toric varieties, the theory of random walks, Bessel functions,
class field theory, and Linnik's constant.

</details>


### [39] [Beyond endoscopy for $\mathsf{GL}_2$ over $\mathbb{Q}$ with ramification 2: bounds towards the Ramanujan conjecture](https://arxiv.org/abs/2507.09655)
*Yuhao Cheng*

Main category: math.NT

TL;DR: 本文推广了Altuğ在非分歧情况下关于$\mathsf{GL}_2$的工作至分歧情形，特别是在$S=\{\infty,q_1,\dots,q_r\}$且$2\in S$的背景下，并给出了Ramanujan猜想中1/4界限的新证明。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于将Altuğ关于$\mathsf{GL}_2$在非分歧情况下的工作推广至分歧情形，特别是当分歧点集$S$包含$\infty$和某些素数时。

Method: 方法分为三步：首先估计迹公式中非椭圆部分的贡献；其次应用先前工作的主要结果分离椭圆部分中的1维表示；最后通过技术性解析估计控制椭圆部分的余项。

Result: 结果包括在分歧情况下为Ramanujan猜想中的1/4界限提供了新证明，并展示了如何通过Altuğ的原始方法适应分歧情形。

Conclusion: 结论表明，即使在分歧情况下，通过适当的技术调整，仍然可以推广Altuğ的工作并为Ramanujan猜想提供新的证明路径。

Abstract: We continue generalizing Altu\u{g}'s work on $\mathsf{GL}_2$ over
$\mathbb{Q}$ in the unramified setting for \emph{Beyond Endoscopy} to the
ramified case where ramification occurs at $S=\{\infty,q_1,\dots,q_r\}$ with
$2\in S$, after generalizing the first step. We establish a new proof of the
$1/4$ bound towards the Ramanujan conjecture for the trace of the cuspidal part
in the ramified case, which is also provided by adapting Altu\u{g}'s original
approach. The proof proceeds in three stages: First, we estimate the
contributions from the non-elliptic parts of the trace formula. Then, we apply
the main result from our the previous work to isolate the $1$-dimensional
representations within the elliptic part. Finally, we employ technical analytic
estimates to bound the remainder terms in the elliptic part.

</details>


### [40] [On pairs of consecutive sequences with the same radicals](https://arxiv.org/abs/2507.09899)
*Noah Lebowitz-Lockard*

Main category: math.NT

TL;DR: 本文利用abc猜想的结果，改进了Balasubramanian等人关于整数三元组$(m, n, k)$的研究，其中$m+i$和$n+i$具有相同根基。同时，对满足特定条件的整数对$(m, n)$的数量进行了上界估计。


<details>
  <summary>Details</summary>
Motivation: 研究整数三元组$(m, n, k)$的性质，其中$m+i$和$n+i$具有相同根基，旨在改进前人结果并探索相关数论问题的边界。

Method: 利用abc猜想的结果，结合数论方法，对整数三元组$(m, n, k)$的性质进行分析，并对满足条件的整数对$(m, n)$的数量进行上界估计。

Result: 改进了Balasubramanian等人的结果，给出了$k$的上界，并对满足特定条件的整数对$(m, n)$的数量进行了有效估计。

Conclusion: 通过abc猜想的应用，本文在整数三元组和整数对的研究中取得了新的进展，为数论中的相关问题提供了更精确的边界。

Abstract: Let $(m, n, k)$ be a tuple of integers with the property that if $i \leq k$,
then $m + i$ and $n + i$ have the same radical. Using a result on the abc
Conjecture, we bound $k$ from above, improving a result of Balasubramanian,
Shorey, and Waldschmidt. We also bound the number of pairs $(m, n)$ for which
$m < n \leq x$ and $m(m + 1) \cdots (m + k - 1))$ and $n(n + 1) \cdots (n +
\ell - 1)$ have the same radical and the number of pairs for which $m + i$ and
$n + i$ have the same radical for all $i < k$.

</details>


### [41] [On quadratic character sums over quartics](https://arxiv.org/abs/2507.09991)
*Bogdan Nica*

Main category: math.NT

TL;DR: 本文推导了四次和三次多项式参数的二次特征和变换公式。


<details>
  <summary>Details</summary>
Motivation: 研究多项式参数的二次特征和变换公式，以深化对特征和理论的理解。

Method: 通过数学推导和特征和理论，建立了四次和三次多项式参数的变换公式。

Result: 成功获得了四次和三次多项式参数的二次特征和变换公式。

Conclusion: 这些变换公式为特征和理论的研究提供了新的工具和视角。

Abstract: We obtain transformation formulas for quadratic character sums with quartic
and cubic polynomial arguments.

</details>


### [42] [Some New Congruences and Partition-Theoretic Interpretations for the Coefficients of Some Rogers-Ramanujan Type Identities](https://arxiv.org/abs/2507.10020)
*Sabi Biswas,Nipen Saikia*

Main category: math.NT

TL;DR: 该论文为拉马努金笔记本中的q级数恒等式提供了新的分拆解释，并证明了模2幂的无限同余族。


<details>
  <summary>Details</summary>
Motivation: 研究拉马努金笔记本中的q级数恒等式，特别是罗杰斯-拉马努金型恒等式，旨在通过分拆理论提供新的解释。

Method: 使用正整数上的超分拆和彩色分拆，对罗杰斯-拉马努金型恒等式进行分拆理论解释。

Result: 成功证明了模2幂的无限同余族，为相关恒等式提供了新的数学支持。

Conclusion: 通过分拆理论，论文不仅解释了罗杰斯-拉马努金型恒等式，还扩展了其在数论中的应用。

Abstract: Ramanujan listed several q-series identities in his lost notebook. The most
well
  known q-series identities are the Rogers-Ramanujan type identities which are
first discovered
  by Rogers and then rediscovered by Ramanujan. In this paper, we give
partition-theoretic
  interpretations of some of the Rogers-Ramanujan type identities using
overpartition and
  colour partition of positive integers, and prove infinite families of
congruences modulo powers
  of 2.

</details>


### [43] [Generalised height pairings and the Albanese kernel](https://arxiv.org/abs/2507.10111)
*Netan Dogra*

Main category: math.NT

TL;DR: 本文探讨了深度二的Chabauty--Coleman--Kim方法中广义高度配对的域定义与计算问题，通过Beilinson--Bloch猜想提出算法，并研究了非阿贝尔Chabauty中的'动机细化'。


<details>
  <summary>Details</summary>
Motivation: 研究Chabauty--Coleman--Kim方法中广义高度配对的域定义与计算问题，探索Beilinson--Bloch猜想对此的启示。

Method: 利用Beilinson--Bloch猜想，假设光滑射影曲线$X$的Albanese核为挠元，提出计算Jacobian上有理点对广义高度配对的算法。

Result: 证明了若$X\times X$的Albanese核为挠元，则存在算法计算Jacobian上有理点对的广义高度配对。

Conclusion: 研究揭示了非阿贝尔Chabauty中出现的非阿贝尔上同调簇的'动机细化'的重要性。

Abstract: The Chabauty--Coleman--Kim method in depth two describes the rational points
on a curve in terms of a generalisation of Nekov\'a\v{r}'s $p$-adic height
pairing which replaces $\mathbb{G}_m$ with a higher Chow group. It is unclear
both what the domain of definition of this pairing is, and how to compute it.
This paper explores the relavence of the Beilinson--Bloch conjectures to this
problem. In particular, it is shown that if $X$ is a smooth projective curve
and the Albanese kernel of $X\times X$ is torsion, then there is an algorithm
to compute the generalised height pairing on a pair of rational points on the
Jacobian. This leads to the consideration of certain `motivic refinements' of
the nonabelian cohomology varieties which arise in nonabelian Chabauty.

</details>


### [44] [Motives and Automorphic Representations](https://arxiv.org/abs/2507.10268)
*James Arthur*

Main category: math.NT

TL;DR: 本文探讨了代数几何与自守表示理论之间的深刻联系，提出了统一这两个领域的普适群构造猜想。


<details>
  <summary>Details</summary>
Motivation: 研究Alexander Grothendieck的代数几何与Robert Langlands的自守表示理论之间的关系，旨在揭示几何对象与谱对象之间的基本对偶性。

Method: 通过引入明确的猜想性构造，提出支配这些理论的普适群，并探索它们之间的关系。

Result: 提出了连接代数几何与自守表示理论的普适群构造猜想，为两者之间的深刻联系提供了新的视角。

Conclusion: 本文为理解代数几何与自守表示理论之间的对偶性提供了新的理论框架，未来研究可进一步验证这些猜想。

Abstract: This paper explores relations between two separate worlds. They are the
algebraic geometry of Alexander Grothendieck and the automorphic representation
theory of Robert Langlands. The relation between them would be a very broad
example of the fundamental duality between geometric objects and spectral
objects that permeates much of modern mathematics. Our goal is to introduce
explicit conjectural constructions of the universal groups that govern much of
these theories, and to explore the relations between them.

</details>


### [45] [Orthomorphism Polynomials of degree $7$ over finite fields](https://arxiv.org/abs/2507.10316)
*Bhitali Kousik,Dhiren Kumar Basnet*

Main category: math.NT

TL;DR: 本文基于Xiang Fan对有限域上7次置换多项式的分类，确定了特定阶数有限域上7次正交多项式，并在某些域上证明了其不存在性。


<details>
  <summary>Details</summary>
Motivation: 利用已有对7次置换多项式的分类结果，进一步研究有限域上7次正交多项式的存在性与具体形式。

Method: 基于Xiang Fan对奇特征有限域上7次置换多项式的分类，分析并列举了阶数为11、13、17、19、25、49的有限域上所有7次正交多项式。

Result: 确定了特定阶数有限域上7次正交多项式的完整列表，并在某些域上证明了这类多项式的不存在性。

Conclusion: 本研究不仅扩展了对有限域上正交多项式的理解，还为相关领域的进一步研究提供了具体案例和理论支持。

Abstract: In 2019, Xiang Fan \cite{xfan} classified all permutation polynomials of
degree $7$ over finite fields of odd characteristics. In this paper, we use
this classification to determine the complete list of degree $7$ orthomorphism
polynomials over finite fields of order $q\in\{11,~13,~17,~19,~25,~49\}.$ In
addition, the non-existence of these polynomials is established for certain
fields.

</details>


### [46] [Asymptotics of analytic torsion for congruence quotients of $\operatorname{SL}(n,\mathbb{R})/\operatorname{SO}(n)$](https://arxiv.org/abs/2507.10339)
*Tim Berland*

Main category: math.NT

TL;DR: 本文证明了$\operatorname{SL}(n,\mathbb{R})/\operatorname{SO}(n)$同余商解析挠率增长的渐近精确估计，基于热核迹的新界与误差项分析。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于算术群上同调挠率的潜在应用，尽管目前这种关联仍是猜想性的。

Method: 方法包括建立热核迹的新边界以控制特定轨道积分的大时间行为，并精细分析误差项。同时定义了$\lambda$-强非循环表示并证明其广泛存在性。

Result: 主要结果是在体积项约束下，获得了同余商解析挠率增长的尖锐渐近公式。

Conclusion: 结论表明该结果为算术群挠率研究提供了新工具，但需进一步验证其与同调挠率的理论联系。

Abstract: In this paper we prove a sharpened asymptotic for the growth of analytic
torsion of congruence quotients of
$\operatorname{SL}(n,\mathbb{R})/\operatorname{SO}(n)$ in terms of the volume.
The result is based on a new bound on the trace of the heat kernel in this
setting, allowing control of the large time behaviour of certain orbital
integrals, as well as a careful analysis of error terms. The result requires
the existence of $\lambda$-strongly acyclic representations, which we define
and show exists in plenitude for any $\lambda$. The motivation is possible
applications to torsion in the cohomology of arithmetic groups, although the
connection in this setting is as of yet conjectural.

</details>


### [47] [Effective equidistribution of norm one elements in CM-fields](https://arxiv.org/abs/2507.10387)
*Shabnam Akhtari,Jeffrey D. Vaaler,Martin Widmer*

Main category: math.NT

TL;DR: 本文研究了数域$K$中乘法群$K^\times$的最大子群$\mathcal{S}_K$，该子群在每个复数嵌入下都能嵌入单位圆。当$K=\mathbb{Q}(\mathcal{S}_K)$是CM域时，$\mathcal{S}_K/{\mathop{\rm Tor}\nolimits}(K^\times)$是一个无限秩的自由阿贝尔群；否则$\mathcal{S}_K=\{\pm 1\}$。


<details>
  <summary>Details</summary>
Motivation: 探讨数域$K$中乘法群$K^\times$的最大子群$\mathcal{S}_K$的结构，并将其视为单位群$\mathcal{O}_K^\times$的Archimedean对应物。

Method: 通过分析数域$K$的复数嵌入和子群$\mathcal{S}_K$的性质，特别是当$K=\mathbb{Q}(\mathcal{S}_K)$时，研究其是否为CM域。

Result: 当$K=\mathbb{Q}(\mathcal{S}_K)$是CM域时，$\mathcal{S}_K/{\mathop{\rm Tor}\nolimits}(K^\times)$是无限秩的自由阿贝尔群；否则$\mathcal{S}_K=\{\pm 1\}$。此外，$\mathcal{S}_K$是相对范数映射的核。

Conclusion: 研究揭示了$\mathcal{S}_K$的结构与数域$K$是否为CM域密切相关，并明确了其在相对范数映射中的作用。

Abstract: For a number field $K$ let $\mathcal{S}_K$ be the maximal subgroup of the
multiplicative group $K^\times$ that embeds into the unit circle under each
embedding of $K$ into the complex numbers. The group $\mathcal{S}_K$ can be
seen as an archimedean counterpart to the group of units $\mathcal{O}_K^\times$
of the ring of integers $\mathcal{O}_K$. If $K=\mathbb{Q}(\mathcal{S}_K)$ is a
CM-field then $\mathcal{S}_K/{\mathop{\rm Tor}\nolimits}(K^\times)$ is a free
abelian group of infinite rank. If $K=\mathbb{Q}(\mathcal{S}_K)$ is not a
CM-field then $\mathcal{S}_K=\{\pm 1\}$. In the former case $\mathcal{S}_K$ is
the kernel of the relative norm map from $K^\times$ to the multiplicative
subgroup $k^\times$ of the maximal totally real subfield $k$ of $K$.

</details>


### [48] [On effective mean-values of arithmetic functions](https://arxiv.org/abs/2507.10483)
*Gérald Tenenbaum*

Main category: math.NT

TL;DR: 本文研究了两个乘法函数$r$和$f$的均值比较问题，其中$r$非负且满足增长条件，$f$复值且受$r$控制。在特定条件下，通过有效均值估计，给出了$f$和$r$在整数集上的均值比较定理，并提供了加性函数加权矩和非负乘法函数筛法均值的有效估计。


<details>
  <summary>Details</summary>
Motivation: 研究乘法函数$r$和$f$的均值比较问题，旨在在特定条件下建立有效的比较定理，并推广到加性函数和非负乘法函数的均值估计，为数论中的均值问题提供新的工具和结果。

Method: 利用乘法函数的性质，结合素数集上的平均值条件，应用近期的有效均值估计技术，推导出$f$和$r$的均值比较定理，并进一步研究加性函数和非负乘法函数的均值问题。

Result: 得到了$f$和$r$在整数集上的有效均值比较定理，并提供了加性函数加权矩和非负乘法函数筛法均值的有效估计，为相关问题的研究提供了新的理论支持。

Conclusion: 本文通过有效均值估计技术，成功建立了乘法函数$f$和$r$的均值比较定理，并推广到加性函数和非负乘法函数的均值问题，为数论中的均值研究提供了重要的理论工具和结果。

Abstract: Let $r,\,f$ be multiplicative functions with $r\geqslant 0$, $f$ is complex
valued, $|f|\leqslant r$, and $r$ satisfies some standard growth hypotheses.
Let $x$ be large, and assume that, for some real number $\tau$, the quantities
$r(p)-\Re\{f(p)/p^{i\tau}\}$ are small in various appropriate average senses
over the set of prime numbers not exceeding $x$. We derive from recent
effective mean-value estimates an effective comparison theorem between the
mean-values of $f$ and of $r$ on the set of integers $\leqslant x$. We also
provide effective estimates for certain weighted moments of additive functions
and for sifted mean-values of non-negative multiplicative functions.

</details>


### [49] [Discrete sumsets with one large summand](https://arxiv.org/abs/2507.10512)
*John T. Griesmer*

Main category: math.NT

TL;DR: 本文研究了离散阿贝尔群中具有正上Banach密度的子集的求和集性质，改进了前人关于整数集求和集的结果，并建立了离散阿贝尔群与紧致阿贝尔群中求和集的强对应关系。


<details>
  <summary>Details</summary>
Motivation: 研究离散阿贝尔群中具有正上Banach密度的子集的求和集性质，旨在推广和完善已有的整数集求和集理论，特别是在piecewise syndetic和piecewise Bohr集方面的结论。

Method: 通过建立离散阿贝尔群、紧致阿贝尔群中卷积的level集以及紧致阿贝尔群中求和集之间的强对应关系，避免了使用测度保持动力学和非标准分析的方法。

Result: 证明了对于任意基数的离散阿贝尔群，若子集具有正上Banach密度，则其求和集具有piecewise Bohr性质，且这一结果是定性最优的。

Conclusion: 本文的结果不仅推广了先前关于整数集求和集的结论，还通过新的方法建立了更广泛的群论框架下的求和集理论，适用于任意基数的离散阿贝尔群。

Abstract: If $A$ and $B$ are subsets of an abelian group, their sumset is
$A+B:=\{a+b:a\in A, b\in B\}$. We study sumsets in discrete abelian groups,
where at least one summand has positive upper Banach density.
  Renling Jin proved that if $A$ and $B$ are sets of integers having positive
upper Banach density, then $A+B$ is piecewise syndetic. Bergelson, Furstenberg,
and Weiss improved the conclusion to "$A+B$ is piecewise Bohr." Beiglb\"ock,
Bergelson, and Fish showed this to be qualitatively optimal, in the sense that
if $C\subseteq \mathbb Z$ is piecewise Bohr, then there are $A, B\subseteq
\mathbb Z$ having positive upper Banach density such that $A+B\subseteq C$.
  We improve these results by establishing a strong correspondence between
sumsets in discrete abelian groups, level sets of convolutions in compact
abelian groups, and sumsets in compact abelian groups. Our proofs avoid measure
preserving dynamics and nonstandard analysis, and our results apply to discrete
abelian groups of any cardinality.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [50] [Complexity of the variable-free fragments of non-normal modal logics (extended version)](https://arxiv.org/abs/2507.09136)
*A. Kudinov,M. Rybakov*

Main category: math.LO

TL;DR: 本文证明了包含经典命题逻辑且包含于弱Grzegorczyk逻辑的模态逻辑的无变量片段的可满足性问题均为NP难问题，特别是非正规模态逻辑E、EM、EN和EMN的无变量片段是coNP完全的。


<details>
  <summary>Details</summary>
Motivation: 研究模态逻辑无变量片段的计算复杂性，特别是针对包含经典命题逻辑且位于弱Grzegorczyk逻辑范围内的模态逻辑。

Method: 通过理论分析和复杂性归约，证明了这些逻辑无变量片段的可满足性问题均为NP难问题。

Result: 确定了非正规模态逻辑E、EM、EN和EMN的无变量片段是coNP完全的。

Conclusion: 该研究为模态逻辑无变量片段的计算复杂性提供了新的理论结果，特别是揭示了非正规模态逻辑的复杂性特征。

Abstract: We show that the satisfiability problem for the variable-free fragment of
every modal logic containing classical propositional logic and contained in the
weak Grzegorczyk logic is NP-hard. In particular, the variable-free fragments
of the non-normal modal logics E, EM, EN, and EMN are coNP-complete.

</details>


### [51] [Fragments of Some Subintuitionistic Logics](https://arxiv.org/abs/2507.09348)
*Fatemeh Shirmohammadzadeh Maleki,Dick de Jongh*

Main category: math.LO

TL;DR: 本文确定了大多数已知子直觉逻辑的蕴涵片段。


<details>
  <summary>Details</summary>
Motivation: 研究子直觉逻辑的蕴涵片段，以深化对这些逻辑系统结构的理解。

Method: 通过逻辑分析和形式化方法，对多种子直觉逻辑的蕴涵关系进行系统研究。

Result: 成功确定了大多数已知子直觉逻辑的蕴涵片段，为相关领域提供了理论基础。

Conclusion: 该研究填补了子直觉逻辑研究中的空白，为进一步探索逻辑系统性质奠定了基础。

Abstract: In this article we determine the implicational fragments of most of the known
subintuitionistic logics.

</details>


### [52] [Definable coordinate geometries over fields, part 1: theory](https://arxiv.org/abs/2507.10279)
*Judit Madarász,Mike Stannett,Gergely Székely*

Main category: math.LO

TL;DR: 论文定义了域和有序域上的坐标几何概念，证明了通过自同构群可以确定几何结构，并建立了可定义关系与自同构之间的等价性。


<details>
  <summary>Details</summary>
Motivation: 研究坐标几何在域和有序域上的普遍性质，探索几何结构与自同构群之间的内在联系。

Method: 通过有限个可定义关系构建坐标几何，分析自同构群对几何结构的决定性作用，并利用仿射变换简化证明过程。

Result: 证明了几何结构可由自同构群唯一确定，且可定义关系与自同构封闭性等价，仿射变换的自同构足以刻画这些关系。

Conclusion: 坐标几何的可定义关系完全由其自同构群决定，这一结果为几何结构与代数对称性的关联提供了理论基础。

Abstract: We define general notions of coordinate geometries over fields and ordered
fields, and consider coordinate geometries that are given by finitely many
relations that are definable over those fields. We show that the automorphism
group of such a geometry determines the geometry up to definitional
equivalence; moreover, if we are given two such geometries $\mathcal{G}$ and
$\mathcal{G}'$, then the concepts (explicitly definable relations) of
$\mathcal{G}$ are concepts of $\mathcal{G}'$ exactly if the automorphisms of
$\mathcal{G}'$ are automorphisms of $\mathcal{G}$. We show this by first
proving that a relation is a concept of $\mathcal{G}$ exactly if it is closed
under the automorphisms of $\mathcal{G}$ and is definable over the field;
moreover, it is enough to consider automorphisms that are affine
transformations.

</details>


### [53] [Definable coordinate geometries over fields, part 2: applications](https://arxiv.org/abs/2507.10289)
*Judit Madarász,Mike Stannett,Gergely Székely*

Main category: math.LO

TL;DR: 本研究第二部分展示了如何利用自同构群关系快速判定多种几何与时空（如欧几里得、伽利略、牛顿、闵可夫斯基等）之间的关系与差异，并提出了若干未解决的中间几何存在问题。


<details>
  <summary>Details</summary>
Motivation: 基于第一部分证明的几何概念集关系完全由其自同构群关系决定，本部分旨在应用该结论分析不同几何与时空结构的关联性。

Method: 采用以介于关系$\mathsf{Bw}$为核心的塔斯基一阶语言定义各类几何与时空，通过自同构群比较其结构关系。

Result: 成功建立了有序仿射、欧几里得、伽利略等时空之间的明确关联与差异，验证了群论方法的有效性。

Conclusion: 提出了一系列关于中间几何存在性的开放问题，为后续研究提供了方向。

Abstract: In Part 1 of this study we showed, for a wide range of geometries, that the
relationships between their concept-sets are fully determined by those between
their (affine) automorphism groups. In this (self-contained) part, we show how
this result can be applied to quickly determine relationships and differences
between various geometries and spacetimes, including ordered affine, Euclidean,
Galilean, Newtonian, Late Classical, Relativistic and Minkowski spacetimes (we
first define these spacetimes and geometries using a Tarskian first-order
language centred on the ternary relation $\mathsf{Bw}$ of betweenness). We
conclude with a selection of open problems related to the existence of certain
intermediate geometries.

</details>


<div id='math.HO'></div>

# math.HO [[Back]](#toc)

### [54] [Remembering Igor R. Shafarevich: The Path to Freedom](https://arxiv.org/abs/2507.09700)
*Alexey Remizov*

Main category: math.HO

TL;DR: 纪念俄罗斯数学家Igor Shafarevich诞辰100周年，文章精选其关于数学与科学未来的论述并附简要评注。


<details>
  <summary>Details</summary>
Motivation: 2023年是俄罗斯著名数学家Igor Shafarevich诞辰100周年，文章旨在通过精选其著作中的论述来探讨数学与科学的未来。

Method: 文章从Shafarevich的多部著作中选取相关引文，并辅以简要的评论和解释。

Result: 呈现了Shafarevich对数学及科学发展的深刻见解，为读者提供了理解其思想的窗口。

Conclusion: 通过Shafarevich的论述，文章不仅纪念了他的贡献，也引发了对数学与科学未来发展的思考。

Abstract: 2023 year marks the hundredth birth anniversary of prominent Russian
mathematician and thinker Igor Rostislavovich Shafarevich (1923-2017). The
article presents a selection of quotations from various works of him, devoted
to the future of mathematics and science in general, with minor comments and
explanations.

</details>


### [55] [The Second Machine Turn: From Checking Proofs to Creating Concepts](https://arxiv.org/abs/2507.10179)
*Asvin G*

Main category: math.HO

TL;DR: 本文探讨了AI在数学发现中的第二次转折：从自动化证明检查转向自动化创造数学概念。讨论了当前技术、障碍与解决方案，并尝试将概念创造本身数学化。最后评估了这些能力对数学及人机协作的影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索AI如何超越证明检查，直接参与数学概念的创造，从而推动数学发现的新范式。

Method: 方法包括分析当前技术现状、识别关键障碍并提出解决方案，同时尝试将概念创造过程形式化为数学问题。

Result: 初步结果表明，AI在数学概念创造中具有潜力，但仍需解决形式化表达和创造性逻辑的挑战。

Conclusion: 结论指出，AI的数学概念创造能力可能重塑数学研究方式，未来可能出现多种人机协作的新模式。

Abstract: We identify a second machine turn in the process of mathematical discovery:
after automating proof-checking, AI is now poised to automate the *creation* of
mathematical concepts themselves. We discuss the current state of the art,
obstacles and potential solutions as well as a preliminary attempt at
mathematizing the creation of concepts itself. The paper ends with an
assessment of how these capabilities could reshape mathematics and
human-machine collaboration, and a few different futures we might find
ourselves in.

</details>


<div id='math.GM'></div>

# math.GM [[Back]](#toc)

### [56] [Point-to-ellipse Fourier series](https://arxiv.org/abs/2507.08807)
*John-Olof Nilsson*

Main category: math.GM

TL;DR: 本文首次推导了椭圆上点法线距离的傅里叶级数展开式，其系数为幂级数形式，为相关分析与计算提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 研究椭圆几何性质时，传统方法难以直接处理法线距离问题。通过建立傅里叶级数展开式，可开启新的解析与数值计算途径。

Method: 采用幂级数系数构造傅里叶级数，针对椭圆上点的法线距离进行级数展开推导。

Result: 成功获得首个具有幂级数系数的椭圆法线距离傅里叶展开式，公式形式为$\sum_{n=0}^{\infty}a_n e^{in\theta}$。

Conclusion: 该成果突破了椭圆几何分析的局限性，为后续动力学模拟、光学计算等应用提供了数学基础。

Abstract: Fourier series with power series coefficients for the normal and distance to
a point from an ellipse are derived. These expressions are the first of their
kind and opens up a range of analysis and computational possibilities.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [57] [Unavoidable Minors of Matroids with Minimum Cocircuit Size Four](https://arxiv.org/abs/2507.09015)
*Matthew Mizell,James Oxley*

Main category: math.CO

TL;DR: 该论文推广了Halin-Jung定理和Mills-Turner定理，证明了所有余圈至少包含四个元素的简单拟阵必定包含九个特定拟阵之一作为其子拟阵。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于Halin-Jung关于图论中最小度数的定理和Mills-Turner关于二元拟阵的类似定理，旨在将这些结果推广到更一般的简单拟阵上。

Method: 通过分析简单拟阵的结构特性，特别是余圈的大小限制，研究采用了组合数学和拟阵理论的方法进行推广证明。

Result: 研究结果表明，所有余圈至少包含四个元素的简单拟阵必定包含九个特定拟阵之一作为子拟阵，其中七个是已知拟阵，且这些拟阵的秩不超过五，元素数不超过十二。

Conclusion: 该研究成功推广了前人的定理，为拟阵理论中的子拟阵存在性问题提供了更一般的结论，并揭示了特定拟阵的结构特性。

Abstract: In 1963, Halin and Jung proved that every simple graph with minimum degree at
least four has $K_5$ or $K_{2,2,2}$ as a minor. Mills and Turner proved an
analog of this theorem by showing that every $3$-connected binary matroid in
which every cocircuit has size at least four has $F_7, M^*(K_{3,3}), M(K_5),$
or $ M(K_{2,2,2})$ as a minor. Generalizing these results, this paper proves
that every simple matroid in which all cocircuits have at least four elements
has as a minor one of nine matroids, seven of which are well known. All nine of
these special matroids have rank at most five and have at most twelve elements.

</details>


### [58] [On the Importance of Studying the Membership Problem for Pedigree Polytopes](https://arxiv.org/abs/2507.09069)
*Tiru Arthanari*

Main category: math.CO

TL;DR: 本文证明了谱系多面体的成员资格问题可在强多项式时间内解决，并由此推导出NP=P的结论。


<details>
  <summary>Details</summary>
Motivation: 研究谱系多面体的成员资格问题，旨在为对称旅行商问题（STSP）多面体的结构提供新见解，并探索计算复杂性的边界。

Method: 通过构建分层网络递归检验成员资格，利用谱系的茎属性按顺序处理各维度问题。

Result: 建立了强多项式时间框架解决成员资格问题，进而可高效求解谱系多面体上的线性优化问题，最终导致NP=P的证明。

Conclusion: 该成果不仅为STSP提供了新的解决方案，更对计算复杂性理论提出了重大挑战，相关证明已在作者专著《Pedigree Polytopes》中系统呈现。

Abstract: Given $n \geq 3$, a combinatorial object called a \textit{ pedigree } is
defined using $3$-element subsets from $[n]$ obeying certain conditions. The
convex hull of pedigrees is called the pedigree polytope for $n$. Pedigrees are
in $1-1$ correspondence with Hamiltonian cycles. Properties of pedigrees,
pedigree polytopes, adjacency structure of the graph of the pedigree polytope
and their implication on the adjacency structure of the Symmetric Travelling
Salesman problem (STSP) polytope have been studied earlier in the literature by
the author.
  The question: Given $X$, does it belong to the pedigree polytope for $n$? is
called the membership problem. This article provides proof that the membership
problem for pedigree polytopes can be solved efficiently. Due to the pedigree's
stem property, we can check the membership problem sequentially for $ k \in [4,
n]$. One constructs a layered network, recursively, to check membership in the
pedigree polytope. Proof of the proposed framework's validity is given. This
article's significant and far-reaching contribution is that the membership
problem has a strongly polynomial-time framework.
  Since the polynomial solvability of the membership problem implies that one
can solve efficiently any linear optimisation problem over the pedigree
polytope. And a specific linear optimisation over the pedigree polytope (the
multistage insertion formulation) solves the STSP.
  The consequence of this result is that we have proof of $NP = P$. A recent
book by the author entitled \textit{Pedigree Polytopes} brings together
published results on pedigrees and some new results, mainly in Chapters 5 and
6. The primary purpose of this article is to present the latest results from
that book in a self-contained fashion so that experts can vet the same. Some of
the proofs and presentation of concepts in this article are new.

</details>


### [59] [A bijection between $321$- and $213$-avoiding permutations preserving $t$-stack-sortability](https://arxiv.org/abs/2507.09187)
*Yang Li,Sergey Kitaev,Zhicong Lin,Jing Liu*

Main category: math.CO

TL;DR: 本文构建了$321$-和$213$-避免排列之间的双射，保持$t$-堆栈可排序性，并验证了Zhang和Kitaev提出的枚举猜想。


<details>
  <summary>Details</summary>
Motivation: 研究旨在推进长度3模式避免排列双射的长期研究，并验证Zhang和Kitaev的枚举猜想。

Method: 通过增加二叉树的构造方法，建立$321$-和$213$-避免排列间的双射。

Result: 双射不仅保持$t$-堆栈可排序性，还转化了两类排列间的自然统计量。

Conclusion: 该工作深化了对模式避免排列双射的理解，并为相关猜想提供了证明。

Abstract: We construct a bijection between $321$- and $213$-avoiding permutations that
preserves the property of $t$-stack-sortability. Our bijection transforms
natural statistics between these two classes of permutations and proves a
refinement of an enumerative conjecture posed by Zhang and Kitaev. This work
contributes further to the long-standing line of research on bijections between
length-3 pattern avoiding permutations. Increasing binary trees lie at the
heart of our approach.

</details>


### [60] [Explicit geometric construction of triangle-free Ramsey graphs](https://arxiv.org/abs/2507.09235)
*Matija Kocbek*

Main category: math.CO

TL;DR: 本文提出了一种显式几何构造方法，构建了大量不含$m$-团且具有有限独立数的图族，推广了Codenotti等人的无三角形Ramsey图。重点研究了无三角形图，描述了几类具有$n$个顶点且独立数为$O(n^{\frac{2}{3}})$的图族，匹配了已知最佳构造界。此外，还提出了基于欧几里得几何的另一类图族，并给出了一个线性$\frac{1}{2}$-近似算法用于寻找最大独立集。


<details>
  <summary>Details</summary>
Motivation: 研究无$m$-团且独立数有限的图族，特别是无三角形图，以推广和改进现有的Ramsey图构造，并探索其组合性质。

Method: 采用显式几何构造方法，构建了多类无三角形图族，并提供了组合证明。此外，设计了一个线性$\frac{1}{2}$-近似算法，适用于部分图族。

Result: 构造了多类无三角形图族，独立数达到$O(n^{\frac{2}{3}})$，匹配已知最佳构造界。另一类基于欧几里得几何的图族虽未达到最佳界，但仍具有较小的独立数。近似算法在部分图族中有效。

Conclusion: 本文通过几何构造和组合方法，扩展了无$m$-团图族的研究，特别是在无三角形图方面取得了与最佳构造界匹配的结果，并为部分图族提供了高效的近似算法。

Abstract: We describe an explicit geometric construction of a vast family of graphs
without $m$-cliques with bounded independence number generalizing triangle-free
Ramsey graphs described by Codenotti, Pudl\'ak and Resta and provide a
combinatorial proof for the upper bound on the independence number of the
latter. We focus on triangle-free graphs and describe some families of such
graphs with $n$ vertices and independence number $O(n^{\frac{2}{3}})$, matching
the best-known constructive bound. We describe an additional family of graphs
that don't match the best-known bound but still have a small independence
number and are based on Euclidean geometry. We also present a linear
$\frac{1}{2}$-approximation algorithm for finding the largest independent set
that works for a significant subset of our family of graphs.

</details>


### [61] [Breaking the Symmetries of Amenable Graphs](https://arxiv.org/abs/2507.09710)
*Christine T. Cheng*

Main category: math.CO

TL;DR: 本文研究了通过区分标记和固定集打破图的对称性的两种方法，提出了在可处理图上计算区分数和固定数的高效算法。


<details>
  <summary>Details</summary>
Motivation: 图的对称性破坏在理论和应用中具有重要意义，区分标记和固定集是两种常见方法。研究如何在特定图类上高效计算这些参数具有实际价值。

Method: 利用Arvind等人对可处理图的特征刻画，将区分标记和固定集的计算转化为基于颜色细化的算法，时间复杂度为$O((|V(G)|+|E(G)|) \log |V(G)|)$。

Result: 对于可处理图$G$，区分数$D(G)$和固定数$Fix(G)$均可在$O((|V(G)|+|E(G)|) \log |V(G)|)$时间内计算得出。

Conclusion: 该研究为可处理图的对称性破坏问题提供了高效解决方案，扩展了颜色细化方法在图论算法中的应用范围。

Abstract: In this paper, we consider two ways of breaking a graph's symmetry:
distinguishing labelings and fixing sets. A distinguishing labeling $\phi$ of
$G$ colors the vertices of $G$ so that the only automorphism of the labeled
graph $(G, \phi)$ is the identity map. The distinguishing number of $G$,
$D(G)$, is the fewest number of colors needed to create a distinguishing
labeling of $G$. A subset $S$ of vertices is a fixing set of $G$ if the only
automorphism of $G$ that fixes every element in $S$ is the identity map. The
fixing number of $G$, $Fix(G)$, is the size of a smallest fixing set. A fixing
set $S$ of $G$ can be translated into a distinguishing labeling $\phi_S$ by
assigning distinct colors to the vertices in $S$ and assigning another color
(e.g., the ``null" color) to the vertices not in $S$.
  Color refinement is a well-known efficient heuristic for graph isomorphism. A
graph $G$ is amenable if, for any graph $H$, color refinement correctly
determines whether $G$ and $H$ are isomorphic or not. Using the
characterization of amenable graphs by Arvind et al. as a starting point, we
show that both $D(G)$ and $Fix(G)$ can be computed in $O((|V(G)|+|E(G)|) \log
|V(G)|)$ time when $G$ is an amenable graph.

</details>


### [62] [Counting fixed-point-free Cayley permutations](https://arxiv.org/abs/2507.09304)
*Giulio Cerbai,Anders Claesson*

Main category: math.CO

TL;DR: 该论文通过双排序物种方法，研究了允许重复值的Cayley排列的递归结构，并推导了其功能有向图的微分方程，进而枚举了无固定点的Cayley排列。


<details>
  <summary>Details</summary>
Motivation: 研究Cayley排列的递归结构及其功能有向图的性质，以解决组合数学中的计数问题。

Method: 使用双排序物种理论推导微分方程，捕捉Cayley排列功能有向图的递归结构。

Result: 成功枚举了无固定点的Cayley排列，并给出了具有特定图论性质（如树、森林或连通性）的Cayley排列的组合恒等式和计数公式。

Conclusion: 该方法不仅解决了Cayley排列的计数问题，还为研究其他组合结构提供了新的工具和视角。

Abstract: Cayley permutations generalize permutations by allowing repeated values. We
use two-sort species to derive differential equations that capture the
recursive structure of their functional digraphs. These equations enable us to
enumerate fixed-point-free Cayley permutations. Our approach also yields
combinatorial identities and counting formulas for Cayley permutations whose
functional digraphs have specific graph-theoretical properties, such as being a
tree, being a forest, or being connected.

</details>


### [63] [$(Δ-1)$-dicolouring of digraphs](https://arxiv.org/abs/2507.10266)
*Ararat Harutyunyan,Ken-ichi Kawarabayashi,Lucas Picasarri-Arrieta,Gil Puig i Surroca*

Main category: math.CO

TL;DR: 本文提出了有向图中Borodin-Kostochka猜想的多个推广版本，并证明了当最大度数足够大时这些猜想成立，同时提出了新的分解引理作为关键工具。


<details>
  <summary>Details</summary>
Motivation: 研究有向图中色数与团数的关系，将无向图的Borodin-Kostochka猜想推广到有向图领域，探索二色数与双团数的对应理论。

Method: 采用密度分解引理（dense decomposition lemma）作为主要技术手段，该引理将有向图分解为特定结构，并推广了Molloy-Reed的无向图分解方法。

Result: 证明了当最大度数$\Delta$足够大时，有向图的二色数不超过$\Delta-1$（除非满足特定双团结构条件），将Reed的无向图结果推广到有向情形。

Conclusion: 该研究不仅推广了经典图论猜想，还提出了适用于有向图的新分解技术，为后续研究提供了有力工具，并给出了最优条件的硬度证明。

Abstract: In 1977, Borodin and Kostochka conjectured that every graph with maximum
degree $\Delta \geq 9$ is $(\Delta-1)$-colourable, unless it contains a clique
of size $\Delta$. In 1999, Reed confirmed the conjecture when $\Delta\geq
10^{14}$.
  We propose different generalisations of this conjecture for digraphs, and
prove the analogue of Reed's result for each of them. The chromatic number and
clique number are replaced respectively by the dichromatic number and the
biclique number of digraphs. If $D$ is a digraph such that
$\min(\tilde{\Delta}(D),\Delta^+(D)) = \Delta \geq 9$, we conjecture that $D$
has dichromatic number at most $\Delta-1$, unless either (i) $D$ contains a
biclique of size $\Delta$, or (ii) $D$ contains a biclique $K$ of size
$\Delta-2$, a directed $3$-cycle $\vec{C_3}$ disjoint from $K$, and all
possible arcs in both directions between $\vec{C_3}$ and $K$. If true, this
implies the conjecture of Borodin and Kostochka. We prove it when $\Delta$ is
large enough, thereby generalising the result of Reed.
  We finally give a sufficient condition for a digraph $D$ to have dichromatic
number at most $\Delta_{\min}(D)-1$, assuming that $\Delta_{\min}(D)$ is large
enough. In particular, this holds when the underlying graph of $D$ has no
clique of size $\Delta_{\min}(D)$, thus yielding a third independent
generalisation of Reed's result. We further give a hardness result witnessing
that our sufficient condition is best possible.
  To obtain these new upper bounds on the dichromatic number, we prove a dense
decomposition lemma for digraphs having large maximum degree, which generalises
to the directed setting the so-called dense decomposition of graphs due to
Molloy and Reed. We believe this may be of independent interest, especially as
a tool in various applications.

</details>


### [64] [Words with factor somplexity $2n+1$ and minimal critical exponent](https://arxiv.org/abs/2507.09387)
*James D. Currie*

Main category: math.CO

TL;DR: 证明了因子复杂度为2n+1的词语临界指数至少为$\mu=2+\frac{1}{\lambda^2-1}=2.4808726\cdots$，验证了Shallit和Shur的猜想。


<details>
  <summary>Details</summary>
Motivation: 验证Shallit和Shur关于因子复杂度为2n+1的词语临界指数的猜想。

Method: 通过数学分析和代数方程求解，确定临界指数的下限。

Result: 临界指数至少为$\mu=2+\frac{1}{\lambda^2-1}$，其中$\lambda=1.7548777$是方程$x^3-2x^2+x-1=0$的实根。

Conclusion: 研究结果证实了Shallit和Shur的猜想，为词语复杂度与临界指数的关系提供了理论支持。

Abstract: We show that words with factor complexity 2n+1 have critical exponent at
least $\mu$, where $\mu=2+\frac{1}{\lambda^2-1}= 2.4808726\cdots$, where
$\lambda=1.7548777$ is the real zero of $x^3-2x+x-1=0$. This confirms a
conjecture of Shallit and Shur.

</details>


### [65] [Colorful Minors](https://arxiv.org/abs/2507.10467)
*Evangelos Protopapas,Dimitrios M. Thilikos,Sebastian Wiederrecht*

Main category: math.CO

TL;DR: 本文提出了彩色子图（colorful minors）的新概念，扩展了传统根子图理论，建立了结构定理并开发了参数化算法，为带颜色标注的图问题提供了统一框架。


<details>
  <summary>Details</summary>
Motivation: 传统子图理论无法有效处理带颜色标注的顶点集问题，需要发展能同时考虑图结构和颜色分布的扩展理论。

Method: 1) 定义$q$-彩色图与彩色子图关系；2) 针对特定彩色图族$\mathcal{H}$建立结构定理；3) 基于结构性质设计固定参数算法；4) 推导两种与树宽扩展相关的算法元定理。

Result: 1) 完全分类具有Erd\H{o}s-P\'osa性质的彩色图；2) 证明彩色子图测试的FPT算法；3) 建立彩色子图的良拟序性质；4) 提出结合颜色分布的结构参数化元定理。

Conclusion: 彩色子图理论为带标注图问题提供了新范式，算法元定理表明同时考虑图结构与颜色分布能扩展经典结论，未来可应用于更复杂的标注系统。

Abstract: We introduce the notion of colorful minors, which generalizes the classical
concept of rooted minors in graphs. $q$-colorful graph is defined as a pair
$(G, \chi),$ where $G$ is a graph and $\chi$ assigns to each vertex a (possibly
empty) subset of at most $q$ colors. The colorful minor relation enhances the
classical minor relation by merging color sets at contracted edges and allowing
the removal of colors from vertices. This framework naturally models
algorithmic problems involving graphs with (possibly overlapping) annotated
vertex sets. We develop a structural theory for colorful minors by establishing
several theorems characterizing $\mathcal{H}$-colorful minor-free graphs, where
$\mathcal{H}$ consists either of a clique or a grid with all vertices assigned
all colors, or of grids with colors segregated and ordered on the outer face.
Leveraging our structural insights, we provide a complete classification -
parameterized by the number $q$ of colors - of all colorful graphs that exhibit
the Erd\H{o}s-P\'osa property with respect to colorful minors. On the
algorithmic side, we provide a fixed-parameter tractable algorithm for colorful
minor testing and a variant of the $k$-disjoint paths problem. Together with
the fact that the colorful minor relation forms a well-quasi-order, this
implies that every colorful minor-monotone parameter on colorful graphs admits
a fixed-parameter algorithm. Furthermore, we derive two algorithmic
meta-theorems (AMTs) whose structural conditions are linked to extensions of
treewidth and Hadwiger number on colorful graphs. Our results suggest how known
AMTs can be extended to incorporate not only the structure of the input graph
but also the way the colored vertices are distributed in it.

</details>


### [66] [Oriented Steiner Triple Systems, Steiner Products, and Dynamics](https://arxiv.org/abs/2507.09396)
*Jake Kettinger,Chris Peterson*

Main category: math.CO

TL;DR: 本文研究了7元和9元集上的定向Steiner三重系统及其关联的Steiner乘积动力学。


<details>
  <summary>Details</summary>
Motivation: 探讨定向Steiner三重系统及其诱导的反对称双线性运算（Steiner乘积）的代数与动力学特性。

Method: 通过为Steiner三重系统中的每个三元组赋予循环序，构造反对称双线性运算，并对7元和9元系统进行分类。

Result: 完整分类了7元和9元集上的定向Steiner三重系统，并分析了对应Steiner乘积的动态行为。

Conclusion: 定向Steiner三重系统可生成具有独特动力学性质的代数结构，小规模系统的分类为更一般理论奠定了基础。

Abstract: Let S denote a Steiner triple system on an n-element set. An orientation of S
is an assignment of a cyclic ordering to each of the triples in S. From an
oriented Steiner triple system, one can define an anticommutative bilinear
operation on Rn resembling the cross product. We call this bilinear operation a
Steiner product. We classify the oriented Steiner triple systems on sets of
size 7 and 9 and investigate the dynamics of their associated Steiner products.

</details>


### [67] [Lattice paths and the Geode](https://arxiv.org/abs/2507.09405)
*Ira M. Gessel*

Main category: math.CO

TL;DR: 本文研究了形式幂级数$S$及其相关级数$G$（Geode）和$H$的性质，给出了它们的显式表达式，并提供了基于格路径的组合解释。


<details>
  <summary>Details</summary>
Motivation: Wildberger和Rubine最近发现了一个形式幂级数$G$（称为Geode），满足$S=1+GS_1$。本文旨在探讨Geode及其相关级数$H=G/S$的性质及其组合意义。

Method: 通过分析形式幂级数$S$的定义方程$S=1+\sum_{i=1}^\infty t_n S^n$，推导出$G$和$H$的显式表达式，并利用格路径的组合结构解释其含义。

Result: 得到了$G$和$H$的显式表达式：$G=\biggl(1-\sum_{n=1}^\infty t_n (1+S+S^2+\cdots+S^{n-1})\biggr)^{-1}$，$H=\biggl( 1-\sum_{n=2}^\infty t_n (S+S^2+\cdots+S^{n-1})\biggr)^{-1}$，并给出了它们在格路径中的组合解释。

Conclusion: 本文成功揭示了Geode级数$G$及其相关级数$H$的数学结构和组合意义，为形式幂级数的研究提供了新的视角。

Abstract: Let $t_1,t_2,\dots$ be variables, and let $S$ be the formal power series in
the variables $t_1, t_2,\dots$ satisfying $S=1+\sum_{i=1}^\infty t_n S^n.$ Let
$S_1 =\sum_{n=1}^\infty t_n$. Wildberger and Rubine recently showed that there
is a formal power series $G$ in the $t_i$, which they called the Geode,
satisfying $S=1+GS_1$. In this paper we discuss some of the properties of the
Geode and of the related series $H=G/S$, which satisfies $S=1/(1-HS_1)$. We
show that \begin{equation*} G=\biggl(1-\sum_{n=1}^\infty t_n
(1+S+S^2+\cdots+S^{n-1})\biggr)^{-1}, \end{equation*} and \begin{equation*}
H=\biggl( 1-\sum_{n=2}^\infty t_n (S+S^2+\cdots+S^{n-1})\biggr)^{-1},
\end{equation*} and we give combinatorial interpretations of $G$ and $H$ in
terms of lattice paths.

</details>


### [68] [On the Range of the Permanent of $(\pm1)$-Matrices](https://arxiv.org/abs/2507.09433)
*DeVon Ingram,Alexander Razborov*

Main category: math.CO

TL;DR: 本文证明了在$n\times n$的$\pm1$矩阵上，永久函数的值域具有超多项式下界。


<details>
  <summary>Details</summary>
Motivation: 研究永久函数在特定矩阵集合上的值域范围，以深化对计算复杂性理论的理解。

Method: 通过数学分析和构造性证明，建立永久函数在$\pm1$矩阵上的下界。

Result: 证明了永久函数在$n\times n$的$\pm1$矩阵上的值域具有超多项式下界。

Conclusion: 该结果为永久函数的计算复杂性提供了新的理论支撑，对相关领域的研究具有重要意义。

Abstract: We establish a superpolynomial lower bound on the range of the permanent
function on the set of $n\times n$ matrices with $\pm1$ entries.

</details>


### [69] [Polynomial-to-exponential transition in 3-uniform Ramsey numbers](https://arxiv.org/abs/2507.09434)
*Ruben Ascoli,Xiaoyu He,Hung-Hsun Hans Yu*

Main category: math.CO

TL;DR: 本文解决了Erdős和Hajnal于1972年提出的关于$k$-一致超图拉姆齐数的猜想，特别是针对$k=3$和所有$s$的情况。通过研究一种新型Turán型问题，即所有紧密分量都是三部图的$n$顶点3-一致超图中的最大边数，证明了平衡迭代边膨胀是该问题的精确极值。


<details>
  <summary>Details</summary>
Motivation: Erdős和Hajnal在1972年提出了关于$k$-一致超图拉姆齐数$r_k(s, e; t)$的猜想，并悬赏500美元寻求证明。此前，Conlon、Fox和Sudakov证明了$k=3$且$s$为3-adic特殊值的情况，Mubayi和Razborov证明了$s > k \geq 4$的情况。本文旨在解决剩余的$k=3$和所有$s$的情况，完成该猜想的全面证明。

Method: 通过解决一个新型Turán型问题：在所有紧密分量都是三部图的$n$顶点3-一致超图中，最大边数是多少。作者证明了平衡迭代边膨胀是该问题的精确极值，从而为拉姆齐数猜想提供了关键工具。

Result: 本文证明了Erdős和Hajnal猜想对于$k=3$和所有$s$的情况成立，即存在一个明确定义的值$h_3(s)$，使得$r_3(s, h_3(s)-1; t)$是$t$的多项式，而$r_3(s, h_3(s); t)$是$t$的幂次指数。

Conclusion: 本文彻底解决了Erdős和Hajnal关于$k$-一致超图拉姆齐数的猜想，特别是针对$k=3$和所有$s$的情况。通过研究新型Turán型问题并证明平衡迭代边膨胀是其精确极值，为拉姆齐理论提供了重要进展。

Abstract: Let $r_k(s, e; t)$ denote the smallest $N$ such that any red/blue edge
coloring of the complete $k$-uniform hypergraph on $N$ vertices contains either
$e$ red edges among some $s$ vertices, or a blue clique of size $t$. Erd\H os
and Hajnal introduced the study of this Ramsey number in 1972 and conjectured
that for fixed $s>k\geq 3$, there is a well defined value $h_k(s)$ such that
$r_k(s, h_k(s)-1; t)$ is polynomial in $t$, while $r_k(s, h_k(s); t)$ is
exponential in a power of $t$. Erd\H os later offered \$500 for a proof.
Conlon, Fox, and Sudakov proved the conjecture for $k=3$ and $3$-adically
special values of $s$, and Mubayi and Razborov proved it for $s > k \geq 4$. We
prove the conjecture for $k=3$ and all $s$, settling all remaining cases of the
problem. We do this by solving a novel Tur\'an-type problem: what is the
maximum number of edges in an $n$-vertex $3$-uniform hypergraph in which all
tight components are tripartite? We show that the balanced iterated blowup of
an edge is an exact extremizer for this problem for all $n$.

</details>


### [70] [Riordan pattern's quest within simplicial complexes](https://arxiv.org/abs/2507.09504)
*Pedro J. Chocano,Ana Luzón,Manuel A. Morón,Luis Felipe Prieto-Martínez*

Main category: math.CO

TL;DR: 本文通过Riordan矩阵连接几何组合学中的$f$-向量、$h$-向量和$\gamma$-向量等概念，并研究了拓扑连接操作的组合性质及其迭代生成的Riordan矩阵特性。


<details>
  <summary>Details</summary>
Motivation: 旨在揭示Riordan矩阵在几何组合学概念间的桥梁作用，并探索拓扑连接操作在单纯复形和Alexandroff空间中的组合性质。

Method: 采用Riordan矩阵理论分析几何组合学概念的关联性，并通过拓扑连接操作的迭代生成Riordan矩阵，研究其数学特性。

Result: 成功建立了Riordan矩阵与$f$-向量、$h$-向量等概念的关联，并揭示了拓扑连接操作迭代生成的Riordan矩阵的独特性质。

Conclusion: Riordan矩阵为几何组合学提供了新的研究工具，拓扑连接操作的迭代矩阵展现出丰富的数学结构，值得进一步探索。

Abstract: The aim of this paper is twofold. First, we demonstrate how Riordan matrices
can be employed to connect well-known concepts in geometric combinatorics, such
as $f$-vectors, $h$-vectors $\gamma$-vectors, in a similar fashion to the
McMullen Correspondence, and the Dehn-Sommerville equations, among others.
Second, we investigate the combinatorial properties of the topological join
operation, both for simplicial complexes and for Alexandroff spaces. Finally,
we explore the Riordan matrices arising from the iteration of this topological
operation and analyze their properties.

</details>


### [71] [Equiangular lines via nodal domains](https://arxiv.org/abs/2507.09511)
*Chuanyuan Ge,Shiping Liu*

Main category: math.CO

TL;DR: 该论文证明了在给定$\Delta>0$和$0<\lambda<3/\sqrt{2}$时，连通图中第二特征值$\lambda$的最大重数为$O_{\Delta,\lambda}(1)$，解决了Jiang等人的问题，并改进了等角线相关结果。


<details>
  <summary>Details</summary>
Motivation: 研究受Jiang等人关于图中第二特征值重数问题的启发，旨在解决$0<\lambda<3/\sqrt{2}$情况下的未解问题，并推动等角线研究的进展。

Method: 基于特征函数节点域的概念，通过构造具有大量节点域的特征函数，建立了基于最大度和图圈数的重数估计方法。

Result: 证明了在给定条件下，第二特征值$\lambda$的最大重数为$O_{\Delta,\lambda}(1)$，从而改进了等角线的相关结果。

Conclusion: 该研究不仅解决了特定条件下的特征值重数问题，还通过创新的节点域构造方法为图论和谱理论提供了新的工具。

Abstract: For given $\Delta>0$ and $0<\lambda<3/\sqrt{2}$, we show that the maximum
multiplicity that $\lambda$ can appear as the second largest eigenvalue of a
connected graph with maximum degree at most $\Delta$ is
$O_{\Delta,\lambda}(1)$. This result answers a question due to Jiang, Tidor,
Yao, Zhang and Zhao [Question 6.4, Ann. of Math. (2) 194 (2021), no. 3,
729-743] in the case of $0<\lambda<3/\sqrt{2}$, and consequently leads to
improvements in their results on equiangular lines. Our proof is based on the
concept of nodal domains of eigenfunctions. Indeed, we establish a multiplicity
estimate in terms of maximum degree and cyclomatic number of the graph, via a
novel construction of eigenfunctions with large number of nodal domains.

</details>


### [72] [Correlations in random cluster model at $q=1$](https://arxiv.org/abs/2507.09520)
*Son Nguyen,Pavlo Pylyavskyy*

Main category: math.CO

TL;DR: 本文研究了有限集合上负相关和正相关测度的性质，针对随机簇模型在$q=1$时给出了组合公式，填补了$0 \leq q \leq 1$时负相关性猜想的空白。


<details>
  <summary>Details</summary>
Motivation: 随机簇模型中边之间的正相关性在$q \geq 1$时已由FKG不等式证明，但$0 \leq q \leq 1$时的负相关性仅为猜想。本文旨在解决这一理论缺口。

Method: 通过组合数学方法，推导了$q=1$时$\mu(\mathcal{A}_e \cap \mathcal{A}_f) - \mu(\mathcal{A}_e) \mu(\mathcal{A}_f)$的显式公式。

Result: 成功建立了$q=1$时的组合公式，此前该公式仅在均匀生成树情形（$q\to 0$的极限）中已知。

Conclusion: 该结果为随机簇模型的负相关性猜想提供了关键进展，为$0 \leq q \leq 1$的后续研究奠定了基础。

Abstract: Let $\mu$ be a measure that samples a subset of a finite ground set, and let
$\mathcal{A}_e$ be the event that element $e$ is sampled. The measure $\mu$ is
negatively correlated if for any pair of elements $e, f$ one has
$\mu(\mathcal{A}_e \cap \mathcal{A}_f) - \mu(\mathcal{A}_e) \mu(\mathcal{A}_f)
\leq 0$. A measure is positively correlated if the direction of the inequality
is reversed. For the random cluster model on graphs positive correlation
between edges is known for $q \geq 1$ due to the FKG inequality, while the
negative correlation is only conjectured for $0 \leq q \leq 1$. The main result
of this paper is to give a combinatorial formula for the difference in question
at $q=1$. Previously, such a formula was known in the uniform spanning tree
case, which is a limit of the random cluster model at $q=0$.

</details>


### [73] [Correlation Clustering for General Graphs](https://arxiv.org/abs/2507.09576)
*Leila Parsaei-Majd*

Main category: math.CO

TL;DR: 本文提出了一种适用于一般情况的关联聚类算法，并证明了在特定条件下，下界（最大边不相交弱负环数）等于最小不一致数。此外，算法在特定符号图子类中具有2-近似性能。


<details>
  <summary>Details</summary>
Motivation: 关联聚类能在不预先指定聚类数量的情况下，将符号图的顶点划分为最优数量的聚类，其核心目标是最小化不一致数（即聚类内负边与聚类间正边的总和）。

Method: 提出了一种通用关联聚类算法，并分析了使下界与最小不一致数相等的充要条件。进一步证明了该算法在特定符号图子类中的近似性能。

Result: 算法在一般符号图中有效，且在满足特定条件时，下界与最小不一致数相等。对于特定子类，算法具有$2$-近似保证（即$2\$-近似）。

Conclusion: 该研究为关联聚类提供了通用算法框架，并揭示了图结构与最优解间的理论联系，同时为特定图类提供了可证明的近似比。

Abstract: Correlation clustering provides a method for separating the vertices of a
signed graph into the optimum number of clusters without specifying that number
in advance. The main goal in this type of clustering is to minimize the number
of disagreements: the number of negative edges inside clusters plus the number
of positive edges between clusters. In this paper, we present an algorithm for
correlation clustering in general case. Also, we show that there is a necessary
and sufficient condition under which the lower bound, maximum number of edge
disjoint weakly negative cycles, is equal to minimum number of disagreements.
Finally, we prove that the presented algorithm gives a $2$-approximation for a
subclass of signed graphs.

</details>


### [74] [Fibonacci, Lucas, and Spread Polynomials](https://arxiv.org/abs/2507.09689)
*Johann Cigler*

Main category: math.CO

TL;DR: 本文通过斐波那契和卢卡斯多项式对扩展多项式的一种变体进行了基础阐述。


<details>
  <summary>Details</summary>
Motivation: 旨在以初等方式展示扩展多项式与经典多项式序列之间的关联性。

Method: 利用斐波那契多项式与卢卡斯多项式作为工具，推导扩展多项式的变体形式。

Result: 建立了扩展多项式变体与斐波那契/卢卡斯多项式之间的显式数学关系。

Conclusion: 该研究为扩展多项式提供了新的表达视角，并揭示了其与经典多项式序列的深层联系。

Abstract: This note gives an elementary exposition of a variant of the spread
polynomials in terms of Fibonacci and Lucas polynomials.

</details>


### [75] [A Family of Congruences Modulo 7 for Partitions with Monochromatic Even Parts and Multi--Colored Odd Parts](https://arxiv.org/abs/2507.09752)
*Michael D. Hirschhorn,James A. Sellers*

Main category: math.CO

TL;DR: 本文推广了Amdeberhan和Merca提出的整数分拆函数$a(n)$，构建了一个无限函数族，并利用生成函数和经典$q$级数恒等式，证明了该函数族满足无限多个模7同余式。


<details>
  <summary>Details</summary>
Motivation: 受Amdeberhan和Merca关于单色偶数部分和三色奇数部分的整数分拆函数$a(n)$研究的启发，特别是$a(7n+2) \equiv 0 \pmod{7}$的结论，作者希望将这一函数推广到一个无限函数族中。

Method: 通过初等的生成函数操作和经典的$q$级数恒等式，作者构建并分析了一个无限分拆函数族。

Result: 作者证明了该函数族的成员满足无限多个模7的同余关系，扩展了先前的研究结果。

Conclusion: 这项研究不仅推广了特定的分拆函数，还通过系统的方法揭示了更广泛的同余性质，为整数分拆理论提供了新的见解。

Abstract: In recent work, Amdeberhan and Merca considered the integer partition
function $a(n)$ which counts the number of integer partitions of weight $n$
wherein even parts come in only one color (i.e., they are monochromatic), while
the odd parts may appear in one of three colors. One of the results that they
proved was that, for all $n\geq 0$, $a(7n+2) \equiv 0 \pmod{7}$. In this work,
we generalize this function $a(n)$ by naturally placing it within an infinite
family of related partition functions. Using elementary generating function
manipulations and classical $q$--series identities, we then prove infinitely
many congruences modulo 7 which are satisfied by members of this family of
functions.

</details>


### [76] [The Fractional Haemers Bound of The Mycielski Construction](https://arxiv.org/abs/2507.09811)
*Bence Csonka*

Main category: math.CO

TL;DR: 研究了广义Mycielski构造$M_r(G)$对互补分数Haemers界$\bar{\mathcal{H}}_f(G; \mathbb{F})$的影响，证明了当$\bar{\mathcal{H}}_f(G; \mathbb{F})$等于$G$的团数时，Tardif关于分数色数的公式对$\bar{\mathcal{H}}_f$同样成立。


<details>
  <summary>Details</summary>
Motivation: 此前已研究了Mycielski构造对分数色数$\chi_f$和互补Lov\'asz theta数$\bar{\vartheta}$的影响，本文旨在探讨其对互补分数Haemers界的影响，填补这一研究空白。

Method: 通过推广Tardif关于分数色数的公式，并利用图$G$的团数与$\bar{\mathcal{H}}_f(G; \mathbb{F})$的关系，建立了一般上界。

Result: 证明了当$\bar{\mathcal{H}}_f(G; \mathbb{F})$等于$G$的团数时，所提出的上界是紧的，即公式成立。

Conclusion: 本文扩展了Mycielski构造对图参数影响的研究，为互补分数Haemers界提供了新的理论结果，特别是在其等于团数时的紧性条件。

Abstract: We investigate the effect of the generalized Mycielski construction $M_r(G)$
on the complementary fractional Haemers bound $\bar{\mathcal{H}}_f(G;
\mathbb{F})$, a parameter that depends on a graph $G$ and a field $\mathbb{F}$.
The effect of the Mycielski construction on graph parameters has already been
studied for the fractional chromatic number $\chi_f$ and the complementary
Lov\'asz theta number $\bar{\vartheta}$. Larsen, Propp, and Ullman provided a
formula for $ \chi_f(M_2(G)) $ in terms of $\chi_f(G)$. This was later
generalized by Tardif to $ \chi_f(M_r(G)) $ for any $r$, and Simonyi and the
author gave a similar expression for $ \bar{\vartheta}(M_2(G)) $ in terms of
$\bar{\vartheta}(G)$. In this paper, we show that Tardif's formula for the
fractional chromatic number remains valid for $ \bar{\mathcal{H}}_f $ whenever
$ \bar{\mathcal{H}}_f(G; \mathbb{F})$ equals the clique number of $G$. In
particular, we provide a general upper bound on $\bar{\mathcal{H}}_f(M_r(G);
\mathbb{F})$ in terms of $\bar{\mathcal{H}}_f(G;\mathbb{F})$ and we prove that
this bound is tight whenever $ \bar{\mathcal{H}}_f(G; \mathbb{F})$ equals the
clique number of $G$.

</details>


### [77] [Ramsey numbers of sparse graphs versus disjoint books](https://arxiv.org/abs/2507.09827)
*Ting Huang,Yanbo Zhang,Yaojun Chen*

Main category: math.CO

TL;DR: 论文证明了对于具有特定边数限制的连通图$G$，其与$t$个顶点不相交的$B_k$的Ramsey数为$2n+t-2$，条件是$n\ge 111t^3k^3$。


<details>
  <summary>Details</summary>
Motivation: 扩展Erd\H{o}s等人的工作，从树结构推广到更一般的连通图$G$，并考虑多个顶点不相交的$B_k$的情况。

Method: 通过分析连通图$G$的边数限制和顶点数条件，结合Ramsey理论，推导出Ramsey数的精确表达式。

Result: 证明了$r(G,tB_k)=2n+t-2$，其中$G$为满足$n(1+\epsilon)$边数限制的连通图，$n\ge 111t^3k^3$。

Conclusion: 该结果不仅推广了早期关于树的Ramsey数结果，还为更一般图结构的Ramsey理论提供了新的见解。

Abstract: Let $B_k$ denote a book on $k+2$ vertices and $tB_k$ be $t$ vertex-disjoint
$B_k$'s. Let $G$ be a connected graph with $n$ vertices and at most
$n(1+\epsilon)$ edges, where $\epsilon$ is a constant depending on $k$ and $t$.
In this paper, we show that the Ramsey number $$r(G,tB_k)=2n+t-2$$ provided
$n\ge 111t^3k^3$. Our result extends the work of Erd\H{o}s, Faudree, Rousseau,
and Schelp (1988), who established the corresponding result for $G$ being a
tree and $t=1$.

</details>


### [78] [Fan-goodness of sparse graphs](https://arxiv.org/abs/2507.09832)
*Ting Huang,Yanbo Zhang,Yaojun Chen*

Main category: math.CO

TL;DR: 本文研究了稀疏图的扇图优良性，证明了在一定边数限制下，拉姆齐数$r(G,F_k)=2n-1$和$r(G,tF_k)=2n+t-2$的成立条件，并回答了Brennan关于循环数阈值$c(n)$的问题。


<details>
  <summary>Details</summary>
Motivation: Brennan (2017)在研究单环图与扇图$F_k$的拉姆齐数时，提出了一个关于循环数阈值$c(n)$的问题，即当图$G$包含至少$c(n)$个循环且$n$足够大时，$r(G,F_k) \geq 2n$是否成立。本文旨在通过研究一般稀疏图的扇图优良性来回答这一问题。

Method: 通过分析图的边数限制，引入依赖于$k$和$t$的常数$\epsilon(k)$和$\epsilon(k,t)$，证明了在一定条件下，拉姆齐数$r(G,F_k)=2n-1$和$r(G,tF_k)=2n+t-2$的成立。

Result: 结果表明，如果图$G$的边数不超过$n(1+\epsilon(k))$，则$r(G,F_k)=2n-1$对$n\ge 36k^4$成立；如果边数不超过$n(1+\epsilon(k,t))$，则$r(G,tF_k)=2n+t-2$对$n\ge 161t^2k^4$成立。这进一步表明$c(n)$大于$\epsilon(k) n$。

Conclusion: 本文通过研究稀疏图的扇图优良性，不仅推广了Brennan的结果，还回答了关于循环数阈值$c(n)$的问题，为相关领域的研究提供了新的理论支持。

Abstract: Let $G$ be a connected graph of order $n$, $F_k$ be a fan consisting of $k$
triangles sharing a common vertex, and $tF_k$ be $t$ vertex-disjoint copies of
$F_k$. Brennan (2017) showed the Ramsey number $r(G,F_k)=2n-1$ for $G$ being a
unicyclic graph for $n \geq k^2-k+1$ and $k\ge 18$, and asked the threshold
$c(n)$ for which $r(G,F_k) \geq 2n$ holds for any $G$ containing at least
$c(n)$ cycles and $n$ being large. In this paper, we consider fan-goodness of
general sparse graphs and show that if $G$ has at most $n(1+\epsilon(k))$
edges, where $\epsilon(k)$ is a constant depending on $k$, then
$$r(G,F_k)=2n-1$$ for $n\ge 36k^4$, which implies that $c(n)$ is greater than
$\epsilon(k) n$. Moreover, if $G$ has at most $n(1+\epsilon(k,t))$ edges, where
$\epsilon(k,t)$ is a constant depending on $k,t$, then $$r(G,tF_k)=2n+t-2$$
provided $n\ge 161t^2k^4$.

</details>


### [79] [An Alon-Boppana--type bound for very dense graphs, with applications to max-cut](https://arxiv.org/abs/2507.10037)
*Shengtong Zhang*

Main category: math.CO

TL;DR: 该论文证明了对于任何$\epsilon > 0$，若正则图$G$与任何Tur\'{a}n图相差至少$\epsilon n^2$条边，则其第二特征值$\lambda_2$满足$\lambda_2 \geq n^{1/4 - \epsilon}$，且指数$1/4$是最优的。结果推广了先前仅适用于密度不超过$\frac{1}{2}$的图的类似界限，并部分验证了R\"{a}ty等人的猜想。此外，该谱方法在max-cut问题上也有重要应用。


<details>
  <summary>Details</summary>
Motivation: 研究正则图与Tur\'{a}n图的偏离程度与其第二特征值的关系，并探索谱方法在max-cut问题中的应用，以验证多个猜想并改进经典结果。

Method: 采用谱分析方法，通过分析图的第二特征值与结构性质的关系，推广了先前的结果，并应用于max-cut问题的研究。

Result: 证明了正则图的第二特征值下界$\lambda_2 \geq n^{1/4 - \epsilon}$，且该指数最优。在max-cut问题上，改进了Edwards的经典结果，并部分验证了多个猜想。

Conclusion: 该研究不仅推广了正则图的谱性质结果，还在max-cut问题上取得了重要进展，为相关猜想提供了部分解答，展示了谱方法在图论问题中的强大应用潜力。

Abstract: For any $\epsilon > 0$, we show that if $G$ is a regular graph on $n
\gg_\epsilon 1$ vertices that is $\epsilon$-far (differs by at least $\epsilon
n^2$ edges) from any Tur\'{a}n graph, then its second eigenvalue $\lambda_2$
satisfies $$\lambda_2 \geq n^{1/4 - \epsilon}.$$ The exponent $1/4$ is optimal.
Our result generalizes an analogous bound, independently obtained by Balla,
R\"{a}ty -- Sudakov-Tomon, and Ihringer, which only applies to graphs with
density at most $\frac{1}{2}$. Up to a lower-order factor, this confirms a
conjecture of R\"{a}ty, Sudakov and Tomon. Our spectral approach has
interesting applications to max-cut. First, we show that if a graph $G$, on $n
\gg_\epsilon 1$ vertices and $m$ edges, is $\epsilon$-far from a disjoint union
of cliques, then it has a max-cut of size at least $$\frac{m}{2} + n^{1.01}.$$
Our result improves upon a classical result of Edwards by a non-trivial
polynomial factor, making progress towards another conjecture of R\"{a}ty,
Sudakov and Tomon. As another application of our method, we show that if a
graph $G$ is $H$-free and has $m$ edges, then $G$ has a max-cut of size at
least $$\frac{m}{2} + c_H m^{0.5001}$$ where $c_H > 0$ is some constant
depending on $H$ only. This result makes progress towards a conjecture of Alon,
Bollob\'{a}s, Krivelevich and Sudakov, and answers recent questions by
Glock-Janzer-Sudakov and Balla-Janzer-Sudakov.

</details>


### [80] [Note on extremal problems about connected subgraph sums](https://arxiv.org/abs/2507.10114)
*Stijn Cambie,Carla Groenland*

Main category: math.CO

TL;DR: 该论文研究了图的连通子图和的集合$S(G,c)$，解决了Solomon Lo提出的问题，证明了对于每个$n$顶点图，存在顶点赋值$c$使得不同图的连通子图和集合不同。


<details>
  <summary>Details</summary>
Motivation: 研究图的连通子图和集合$S(G,c)$的性质，解决Solomon Lo提出的问题，探讨如何通过顶点赋值区分不同图。

Method: 通过构造顶点赋值$c:V(G)\to \{1,\dots,12n^2\}$，分析不同图的连通子图和集合的差异。

Result: 证明了对于每个$n$顶点图，存在顶点赋值$c$使得$S(G,c)\neq S(G',c')$，其中$G'\not\cong G$。

Conclusion: 该研究为图的连通子图和集合提供了新的理论结果，并探讨了顶点赋值的性质及其在图区分中的应用。

Abstract: For a graph $G$ with vertex assignment $c:V(G)\to \mathbb{Z}^+$, we define
$\sum_{v\in V(H)}c(v)$ for $H$ a connected subgraph of $G$ as a connected
subgraph sum of $G$. We study the set $S(G,c)$ of connected subgraph sums and,
in particular, resolve a problem posed by Solomon Lo in a strong form. We show
that for each $n$-vertex graph, there is a vertex assignment $c:V(G)\to
\{1,\dots,12n^2\}$ such that for every $n$-vertex graph $G'\not\cong G$ and
vertex assignment $c'$ for $G'$, the corresponding collections of connected
subgraph sums are different (i.e., $S(G,c)\neq S(G',c')$). We also provide some
remarks on vertex assignments of a graph $G$ for which all connected subgraph
sums are different.

</details>


### [81] [A lower bound for the Weisfeiler-Leman dimension of circulant graphs](https://arxiv.org/abs/2507.10116)
*Yulai Wu,Gang Chen,Qing Ren,Ilia Ponomarenko*

Main category: math.CO

TL;DR: 证明了对于无限多个正整数n，存在一个阶数为n的循环图，其Weisfeiler-Leman维度至少为c√(log n)，其中c是与n无关的正常数。


<details>
  <summary>Details</summary>
Motivation: 研究循环图的Weisfeiler-Leman维度，探索其在图同构问题中的计算复杂性。

Method: 通过数学构造和证明，分析循环图的Weisfeiler-Leman维度的下界。

Result: 发现无限多个循环图的Weisfeiler-Leman维度至少为c√(log n)，表明其维度可以随n的增长而增大。

Conclusion: 该结果为循环图的Weisfeiler-Leman维度提供了新的下界，对图同构算法的研究具有重要意义。

Abstract: It is proved that for infinitely many positive integers n, there exists a
circulant graph of order n whose Weisfeiler-Leman dimension is at least
c\sqrt{log n} for some positive constant c not depending on n.

</details>


### [82] [A new look at twin reduction](https://arxiv.org/abs/2507.10189)
*Peter J. Cameron*

Main category: math.CO

TL;DR: 论文研究了图中顶点间的孪生约简等价关系，并给出了该关系的特征描述，进而推导出图自同构群的结构定理。


<details>
  <summary>Details</summary>
Motivation: 探索图中顶点间的孪生约简等价关系及其对图自同构群结构的影响，为图论研究提供新的理论工具。

Method: 通过定义顶点间的孪生约简等价关系，并分析其性质，进而推导出图自同构群的结构特征。

Result: 给出了孪生约简等价关系的完整特征描述，并基于此提出了图自同构群的结构定理。

Conclusion: 该研究不仅深化了对图中顶点等价关系的理解，还为图自同构群的结构分析提供了新的理论框架。

Abstract: Twin reduction defines an equivalence relation on the vertex set of a graph.
I give a characterisation of this equivalence relation. A consequence is a
structure theorem for the automorphism group of the graph.

</details>


### [83] [Leaf to leaf path lengths in trees of given degree sequence](https://arxiv.org/abs/2507.10351)
*Dieter Rautenbach,Johannes Scherer,Florian Werner*

Main category: math.CO

TL;DR: 本文研究了树中不同叶到叶路径长度的下界，提出了无度数为2顶点的树的新不等式$lp(T)\geq {\rm rad}(s)-\log_2\left({\rm rad}(s)\right)$，并探讨了可能的改进方向。


<details>
  <summary>Details</summary>
Motivation: 受Di Braccio等人关于叶路径长度下界研究的启发，本文旨在进一步探索无度数为2顶点的树在给定度序列下的叶路径长度最小值问题。

Method: 通过分析树的度序列$s$和半径${\rm rad}(s)$，结合对数函数建立了新的下界关系式，并讨论了该不等式的优化空间。

Result: 证明了对于无度数为2顶点的树$T$，其不同叶路径数满足$lp(T)\geq {\rm rad}(s)-\log_2\left({\rm rad}(s)\right)$，其中$s$为$T$的度序列。

Conclusion: 该结果为树结构中的叶路径多样性研究提供了新的理论工具，文末指出可通过调整对数项系数等方式进一步优化下界公式。

Abstract: For a tree $T$, let $lp(T)$ be the number of different lengths of leaf to
leaf paths in $T$. For a degree sequence $s$ of a tree, let ${\rm rad}(s)$ be
the minimum radius of a tree with degree sequence $s$. Recently, Di Braccio,
Katsamaktsis, and Malekshahian provided a lower bound on $lp(T)$ in terms of
the number of leaves and the maximum degree of $T$, answering a related
question posed by Narins, Pokrovskiy, and Szab\'o. Here we show $lp(T)\geq {\rm
rad}(s)-\log_2\left({\rm rad}(s)\right)$ for a tree $T$ with no vertex of
degree $2$ and degree sequence $s$, and discuss possible improvements and
variants.

</details>


### [84] [Degree-truncated choosability of graphs](https://arxiv.org/abs/2507.10453)
*Huan Zhou,Jialu Zhu,Xuding Zhu*

Main category: math.CO

TL;DR: 本文否定了Richter关于3连通非完全平面图是否具有6-截断可选性的猜想，构造了反例证明其不成立，并证明了这类图具有16-截断DP可着色性。进一步研究了一般真子图闭族中s-连通图的截断可选性，并指出连通性和非完全性是必要条件。


<details>
  <summary>Details</summary>
Motivation: 研究图的截断可选性（degree-truncated choosability）问题，特别是针对3连通非完全平面图，验证Richter提出的猜想是否成立，并探索更广泛图类的截断可选性条件。

Method: 通过构造反例否定原猜想，采用DP着色（DP-colouring）技术证明16-截断可着色性，并推广到真子图闭族中的s-连通图，分析其截断可选性的通用条件。

Result: 1. 构造了3连通非完全平面图的反例，证明其非7-截断可选；2. 证明了所有3连通非完全平面图具有16-截断DP可着色性；3. 建立了真子图闭族中s-连通图的截断可选性通用理论，特别给出了曲面嵌入图的3连通情形结果。

Conclusion: 连通性和非完全性是截断可选性的关键条件：1. 反例否定了Richter猜想；2. 16-截断DP可着色性为平面图提供了新上界；3. 真子图闭族的结果具有普适性，但需满足s-连通和非完全性，否则存在反例（如$K_{s-1,k^{s-1}}$）。

Abstract: A graph $G$ is called degree-truncated $k$-choosable if for every list
assignment $L$ with $|L(v)| \ge \min\{d_G(v), k\}$ for each vertex $v$, $G$ is
$L$-colourable. Richter asked whether every 3-connected non-complete planar
graph is degree-truncated 6-choosable. We answer this question in negative by
constructing a 3-connected non-complete planar graph which is not
degree-truncated 7-choosable. Then we prove that every 3-connected non-complete
planar graph is degree-truncated 16-DP-colourable (and hence degree-truncated
$16$-choosable). We further prove that for an arbitrary proper minor closed
family ${\mathcal G}$ of graphs, let $s$ be the minimum integer such that
$K_{s,t} \notin \mathcal{G}$ for some $t$, then there is a constant $k$ such
that every $s$-connected graph $G \in {\mathcal G}$ other than a GDP tree is
degree-truncated DP-$k$-colourable (and hence degree-truncated $k$-choosable),
where a GDP-tree is a graph whose blocks are complete graphs or cycles. In
particular, for any surface $\Sigma$, there is a constant $k$ such that every
3-connected non-complete graph embeddable on $\Sigma$ is degree-truncated
DP-$k$-colourable (and hence degree-truncated $k$-choosable). The
$s$-connectedness for graphs in $\mathcal{G}$ (and 3-connectedness for graphs
embeddable on $\Sigma$) is necessary, as for any positive integer $k$,
$K_{s-1,k^{s-1}} \in \mathcal{G}$ ($K_{2,k^2}$ is planar) is not
degree-truncated $k$-choosable. Also, non-completeness is a necessary
condition, as complete graphs are not degree-choosable.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [85] [Function approximations for counterparty credit exposure calculations](https://arxiv.org/abs/2507.09004)
*Domagoj Demeterfi,Kathrin Glau,Linus Wunderlich*

Main category: q-fin.CP

TL;DR: 本文提出了一种通过函数近似替代频繁调用的衍生品定价器的方法，显著降低了计算负担，同时保持了对风险暴露度量的准确性。通过Chebyshev插值法实现了指数级收敛，并在数值实验中展示了高达230倍的加速效果。


<details>
  <summary>Details</summary>
Motivation: 金融机构在定期测量风险暴露时面临计算负担过重或风险过度简化的两难选择。本文旨在解决这一困境，通过系统研究函数近似方法来替代频繁的衍生品定价调用。

Method: 采用Chebyshev插值法进行函数近似，覆盖所有实际相关的风险暴露度量，包括分位数。证明了在$L^p$范数（$1 \leq p < \infty$）和均匀范数下的误差界限，并在温和条件下推导了概率性和有限样本误差界限。

Result: 数值实验显示，使用10,000次模拟时，在所有测试案例中均观察到显著的运行时间减少，加速因子最高达230倍，平均加速87倍。此外，还提出了插值次数的自适应选择方法。

Conclusion: 该方法不仅显著提高了计算效率，还通过希腊字母的近似展示了其理论之外的实用价值，为金融机构提供了一种高效且准确的风险暴露测量解决方案。

Abstract: The challenge to measure exposures regularly forces financial institutions
into a choice between an overwhelming computational burden or
oversimplification of risk. To resolve this unsettling dilemma, we
systematically investigate replacing frequently called derivative pricers by
function approximations covering all practically relevant exposure measures,
including quantiles. We prove error bounds for exposure measures in terms of
the $L^p$ norm, $1 \leq p < \infty$, and for the uniform norm. To fully exploit
these results, we employ the Chebyshev interpolation and show exponential
convergence of the resulting exposure calculations. As our main result we
derive probabilistic and finite sample error bounds under mild conditions
including the natural case of unbounded risk factors. We derive an asymptotic
efficiency gain scaling with $n^{1/2-\varepsilon}$ for any $\varepsilon>0$ with
$n$ the number of simulations. Our numerical experiments cover callable,
barrier, stochastic volatility and jump features. Using 10\,000 simulations, we
consistently observe significant run-time reductions in all cases with speed-up
factors up to 230, and an average speed-up of 87. We also present an adaptive
choice of the interpolation degree. Finally, numerical examples relying on the
approximation of Greeks highlight the merit of the method beyond the presented
theory.

</details>


### [86] [Joint deep calibration of the 4-factor PDV model](https://arxiv.org/abs/2507.09412)
*Fabio Baschetti,Giacomo Bormetti,Pietro Rossi*

Main category: q-fin.CP

TL;DR: 该论文提出了一种通过神经网络学习SPX隐含波动率、VIX期货和VIX看涨期权价格的方法，显著缩短了联合校准时间至几秒钟。


<details>
  <summary>Details</summary>
Motivation: 联合校准SPX和VIX市场数据需要复杂建模且计算成本高昂，尤其是当波动率衍生品定价依赖于嵌套蒙特卡洛模拟时。现有方法虽具现实性但外模拟效率低下。

Method: 通过神经网络学习VIX作为随机变量，并进一步学习SPX隐含波动率、VIX期货及期权价格，将定价函数简化为矩阵-向量乘积以实现实时计算。

Result: 该方法将联合校准时间从耗时缓慢缩短至仅需几秒，显著提升了计算效率。

Conclusion: 该研究通过神经网络学习关键定价函数，解决了联合校准中的计算瓶颈，为快速校准提供了可行方案。

Abstract: Joint calibration to SPX and VIX market data is a delicate task that requires
sophisticated modeling and incurs significant computational costs. The latter
is especially true when pricing of volatility derivatives hinges on nested
Monte Carlo simulation. One such example is the 4-factor Markov Path-Dependent
Volatility (PDV) model of Guyon and Lekeufack (2023). Nonetheless, its realism
has earned it considerable attention in recent years. Gazzani and Guyon (2025)
marked a relevant contribution by learning the VIX as a random variable, i.e.,
a measurable function of the model parameters and the Markovian factors. A
neural network replaces the inner simulation and makes the joint calibration
problem accessible. However, the minimization loop remains slow due to
expensive outer simulation. The present paper overcomes this limitation by
learning SPX implied volatilities, VIX futures, and VIX call option prices. The
pricing functions reduce to simple matrix-vector products that can be evaluated
on the fly, shrinking calibration times to just a few seconds.

</details>


### [87] [Enhancing Trading Performance Through Sentiment Analysis with Large Language Models: Evidence from the S&P 500](https://arxiv.org/abs/2507.09739)
*Haojie Liu,Zihan Lin,Randall R. Rojas*

Main category: q-fin.CP

TL;DR: 该研究结合金融新闻实时情感分析（GPT-2和FinBERT）与技术指标及时间序列模型（ARIMA和ETS），优化标普500交易策略，证明情感数据与传统模型结合可提升交易表现。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过整合实时情感分析与传统量化模型，在波动市场中开发更具适应性的股票交易策略。

Method: 融合GPT-2/FinBERT情感分析、动量指标、趋势指标（ARIMA/ETS），并与买入持有基准策略对比评估资产价值及收益。

Result: 实验表明，情感驱动指标与传统模型的结合显著提高了交易策略的动态适应能力和收益表现。

Conclusion: 情感分析与技术指标的协同作用为波动市场提供了更灵活的交易框架，验证了多模态数据融合在量化投资中的价值。

Abstract: This study integrates real-time sentiment analysis from financial news, GPT-2
and FinBERT, with technical indicators and time-series models like ARIMA and
ETS to optimize S&P 500 trading strategies. By merging sentiment data with
momentum and trend-based metrics, including a benchmark buy-and-hold and
sentiment-based approach, is evaluated through assets values and returns.
Results show that combining sentiment-driven insights with traditional models
improves trading performance, offering a more dynamic approach to stock trading
that adapts to market changes in volatile environments.

</details>


### [88] [Towards Realistic and Interpretable Market Simulations: Factorizing Financial Power Law using Optimal Transport](https://arxiv.org/abs/2507.09863)
*Ryuji Hashimoto,Kiyoshi Izumi*

Main category: q-fin.CP

TL;DR: 通过人工市场模拟研究股票收益率幂律分布的成因，发现价格信息效应起主导作用，且多因素协同放大该效应。


<details>
  <summary>Details</summary>
Motivation: 传统金融理论假设价格波动服从高斯分布，但实证研究显示收益率尾部呈幂律分布。现有研究对成因假设不一，但鲜有将投资者行为与制度需求失衡等因素共同建模分析。

Method: 构建人工市场进行控制实验，采用最优传输(OT)作为定量相似性度量，逐步在智能体模型中引入行为组件，通过OT距离比较模拟结果与实证数据。

Result: 价格的信息效应对重现幂律行为起主导作用，且多个组件通过协同交互放大该效应。

Conclusion: 研究证实了市场复杂行为中价格信息效应的核心地位，并为多因素协同作用机制提供了量化分析框架。

Abstract: We investigate the mechanisms behind the power-law distribution of stock
returns using artificial market simulations. While traditional financial theory
assumes Gaussian price fluctuations, empirical studies consistently show that
the tails of return distributions follow a power law. Previous research has
proposed hypotheses for this phenomenon -- some attributing it to investor
behavior, others to institutional demand imbalances. However, these factors
have rarely been modeled together to assess their individual and joint
contributions. The complexity of real financial markets complicates the
isolation of the contribution of a single component using existing data. To
address this, we construct artificial markets and conduct controlled
experiments using optimal transport (OT) as a quantitative similarity measure.
Our proposed framework incrementally introduces behavioral components into the
agent models, allowing us to compare each simulation output with empirical data
via OT distances. The results highlight that informational effect of prices
plays a dominant role in reproducing power-law behavior and that multiple
components interact synergistically to amplify this effect.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [89] [Immutability Does Not Guarantee Trust: A Formal and Logical Refutation](https://arxiv.org/abs/2507.08844)
*Craig S Wright*

Main category: cs.CR

TL;DR: 本文通过形式化方法驳斥了区块链不可变性保证信任的常见观点，证明不可变性仅确保数据持久性而非可信度。


<details>
  <summary>Details</summary>
Motivation: 针对区块链领域普遍认为不可变性等同于信任的错误认知，研究旨在通过严谨分析揭示两者本质区别。

Method: 采用谓词逻辑、自动机理论模型和认知博弈论分析，构建形式化反例（如预测欺诈方案和垃圾数据永久化现象）。

Result: 证明不可变性仅实现数据结构层面的持久存储，无法保证数据的正确性、公平性或可信度。

Conclusion: 不可变性与信任分属结构和认知领域，将二者混为一谈的论点经不起形式化验证。

Abstract: It is frequently claimed in blockchain discourse that immutability guarantees
trust. This paper rigorously refutes that assertion. We define immutability as
the cryptographic persistence of historical states in an append-only data
structure and contrast it with trust, understood as a rational epistemic
expectation under uncertainty. Employing predicate logic, automata-theoretic
models, and epistemic game-theoretic analysis, we demonstrate that immutability
neither entails nor implies correctness, fairness, or credibility. Through
formal constructions and counterexamples--including predictive fraud schemes
and the phenomenon of garbage permanence--we show that the belief conflates
structural and epistemic domains. Immutability preserves all data equally,
regardless of veracity. Therefore, the assertion that immutability guarantees
trust collapses under the weight of formal scrutiny.

</details>


### [90] [Clio-X: AWeb3 Solution for Privacy-Preserving AI Access to Digital Archives](https://arxiv.org/abs/2507.08853)
*Victoria L. Lemieux,Rosa Gil,Faith Molosiwa,Qihong Zhou,Binming Li,Roberto Garcia,Luis De La Torre Cubillo,Zehua Wang*

Main category: cs.CR

TL;DR: 本文探讨了隐私增强技术（PETs）和Web3架构如何帮助档案机构在保护敏感内容的同时支持AI驱动的访问，提出了去中心化解决方案Clio-X，并通过用户评估揭示了采用障碍及基于参与式设计和去中心化治理的改进路径。


<details>
  <summary>Details</summary>
Motivation: 随着档案机构转向人工智能管理日益增长的数字记录，当前AI数据实践中的隐私风险引发了关于数据主权和伦理责任的关键问题。

Method: 研究提出了Clio-X，一个去中心化、隐私优先的Web3数字解决方案，通过用户评估中等保真原型，结合Rogers的创新扩散理论分析采用障碍。

Result: 用户评估显示对解决方案潜力的兴趣，但也揭示了信任、系统不透明性、经济担忧和治理等显著采用障碍。

Conclusion: 通过整合技术保障和基于社区的监督，Clio-X为文化遗产领域伦理部署AI提供了新模式，强调参与式设计和去中心化自治组织（DAO）的治理路径。

Abstract: As archives turn to artificial intelligence to manage growing volumes of
digital records, privacy risks inherent in current AI data practices raise
critical concerns about data sovereignty and ethical accountability. This paper
explores how privacy-enhancing technologies (PETs) and Web3 architectures can
support archives to preserve control over sensitive content while still being
able to make it available for access by researchers. We present Clio-X, a
decentralized, privacy-first Web3 digital solution designed to embed PETs into
archival workflows and support AI-enabled reference and access. Drawing on a
user evaluation of a medium-fidelity prototype, the study reveals both interest
in the potential of the solution and significant barriers to adoption related
to trust, system opacity, economic concerns, and governance. Using Rogers'
Diffusion of Innovation theory, we analyze the sociotechnical dimensions of
these barriers and propose a path forward centered on participatory design and
decentralized governance through a Clio-X Decentralized Autonomous
Organization. By integrating technical safeguards with community-based
oversight, Clio-X offers a novel model to ethically deploy AI in cultural
heritage contexts.

</details>


### [91] [RAG Safety: Exploring Knowledge Poisoning Attacks to Retrieval-Augmented Generation](https://arxiv.org/abs/2507.08862)
*Tianzhe Zhao,Jiaoyan Chen,Yanchi Ru,Haiping Zhu,Nan Hu,Jun Liu,Qika Lin*

Main category: cs.CR

TL;DR: 本文首次系统研究了基于知识图谱的检索增强生成（KG-RAG）方法的数据投毒攻击安全问题，提出了一种隐蔽的攻击策略，通过扰动知识图谱中的三元组误导KG-RAG系统生成错误回答。实验证明该攻击策略在最小扰动下仍能显著降低系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅关注非结构化文本数据源的RAG系统安全风险，而知识图谱因其结构化、可编辑特性存在独特漏洞，但KG-RAG的安全威胁尚未被充分探索。

Method: 提出符合现实场景的隐蔽攻击框架：1)识别对抗性目标答案 2)插入扰动三元组构建误导性推理链，使KG-RAG在生成过程中更易检索并依赖这些扰动知识。

Result: 在两个基准数据集和四种最新KG-RAG方法上的实验表明，即使最小知识图谱扰动也能显著降低系统性能（具体指标未给出）。深入分析揭示了KG-RAG内部阶段的安全威胁及大语言模型对抗性知识的鲁棒性。

Conclusion: 研究揭示了KG-RAG系统面临严重的数据投毒安全风险，结构化知识图谱的编辑特性使其比非结构化数据更易受攻击，需开发针对性防御机制保障可靠性。

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
retrieving external data to mitigate hallucinations and outdated knowledge
issues. Benefiting from the strong ability in facilitating diverse data sources
and supporting faithful reasoning, knowledge graphs (KGs) have been
increasingly adopted in RAG systems, giving rise to KG-based RAG (KG-RAG)
methods. Though RAG systems are widely applied in various applications, recent
studies have also revealed its vulnerabilities to data poisoning attacks, where
malicious information injected into external knowledge sources can mislead the
system into producing incorrect or harmful responses. However, these studies
focus exclusively on RAG systems using unstructured textual data sources,
leaving the security risks of KG-RAG largely unexplored, despite the fact that
KGs present unique vulnerabilities due to their structured and editable nature.
In this work, we conduct the first systematic investigation of the security
issue of KG-RAG methods through data poisoning attacks. To this end, we
introduce a practical, stealthy attack setting that aligns with real-world
implementation. We propose an attack strategy that first identifies adversarial
target answers and then inserts perturbation triples to complete misleading
inference chains in the KG, increasing the likelihood that KG-RAG methods
retrieve and rely on these perturbations during generation. Through extensive
experiments on two benchmarks and four recent KG-RAG methods, our attack
strategy demonstrates strong effectiveness in degrading KG-RAG performance,
even with minimal KG perturbations. In-depth analyses are also conducted to
understand the safety threats within the internal stages of KG-RAG systems and
to explore the robustness of LLMs against adversarial knowledge.

</details>


### [92] [Privacy-Utility-Fairness: A Balanced Approach to Vehicular-Traffic Management System](https://arxiv.org/abs/2507.08864)
*Poushali Sengupta,Sabita Maharjan,frank Eliassen,Yan Zhang*

Main category: cs.CR

TL;DR: 本文提出一种新型算法，通过差分隐私技术平衡基于位置的车辆交通管理中的隐私、效用和公平性，确保敏感地理数据安全的同时维持交通管理效用和区域公平。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案在防止链接攻击和人口统计偏差方面不足，导致隐私泄露和数据分析不公。本文旨在解决这些问题，确保数据使用和决策中的公平性。

Method: 采用差分隐私技术，结合基于查询的数据访问、迭代混洗和校准噪声注入，实施拉普拉斯机制以确保$\epsilon$-差分隐私标准。

Result: 在挪威车辆位置数据上实现算法，证明其能维持交通管理和城市规划的数据效用，同时公平表示所有地理区域，并生成挪威交通状况的隐私保护热图。

Conclusion: 该算法有效保护车辆交通数据隐私，平衡效用与公平，为交通管理和城市规划提供可靠且公平的数据支持。

Abstract: Location-based vehicular traffic management faces significant challenges in
protecting sensitive geographical data while maintaining utility for traffic
management and fairness across regions. Existing state-of-the-art solutions
often fail to meet the required level of protection against linkage attacks and
demographic biases, leading to privacy leakage and inequity in data analysis.
In this paper, we propose a novel algorithm designed to address the challenges
regarding the balance of privacy, utility, and fairness in location-based
vehicular traffic management systems. In this context, utility means providing
reliable and meaningful traffic information, while fairness ensures that all
regions and individuals are treated equitably in data use and decision-making.
Employing differential privacy techniques, we enhance data security by
integrating query-based data access with iterative shuffling and calibrated
noise injection, ensuring that sensitive geographical data remains protected.
We ensure adherence to epsilon-differential privacy standards by implementing
the Laplace mechanism. We implemented our algorithm on vehicular location-based
data from Norway, demonstrating its ability to maintain data utility for
traffic management and urban planning while ensuring fair representation of all
geographical areas without being overrepresented or underrepresented.
Additionally, we have created a heatmap of Norway based on our model,
illustrating the privatized and fair representation of the traffic conditions
across various cities. Our algorithm provides privacy in vehicular traffic

</details>


### [93] [Towards Privacy-Preserving and Personalized Smart Homes via Tailored Small Language Models](https://arxiv.org/abs/2507.08878)
*Xinyu Huang,Leming Shen,Zijing Ma,Yuanqing Zheng*

Main category: cs.CR

TL;DR: 本文提出HomeLLaMA，一种基于本地小型语言模型（SLM）的隐私保护智能家居助手，通过云端大语言模型（LLM）学习提供个性化服务，并开发PrivShield支持选择性隐私保护远程查询。实验证明其能显著提升隐私保护同时保持服务质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能家居助手需将用户命令及隐私数据传输至远程服务器，引发隐私泄露担忧。为解决此问题，研究旨在开发本地化隐私保护解决方案。

Method: 1) 开发本地SLM框架HomeLLaMA，通过云端LLM知识蒸馏实现个性化响应；2) 设计PrivShield机制，允许用户选择性发送低敏感度查询至远程LLM；3) 构建评估基准DevFinder。

Result: 在100人用户研究中，HomeLLaMA在提供个性化服务的同时，隐私泄露风险显著降低。PrivShield进一步平衡了隐私保护与服务体验。

Conclusion: HomeLLaMA证明了本地化SLM在智能家居场景的可行性，其隐私保护架构与可选远程服务机制为未来人机交互系统设计提供了新范式。

Abstract: Large Language Models (LLMs) have showcased remarkable generalizability in
language comprehension and hold significant potential to revolutionize
human-computer interaction in smart homes. Existing LLM-based smart home
assistants typically transmit user commands, along with user profiles and home
configurations, to remote servers to obtain personalized services. However,
users are increasingly concerned about the potential privacy leaks to the
remote servers. To address this issue, we develop HomeLLaMA, an on-device
assistant for privacy-preserving and personalized smart home serving with a
tailored small language model (SLM). HomeLLaMA learns from cloud LLMs to
deliver satisfactory responses and enable user-friendly interactions. Once
deployed, HomeLLaMA facilitates proactive interactions by continuously updating
local SLMs and user profiles. To further enhance user experience while
protecting their privacy, we develop PrivShield to offer an optional
privacy-preserving LLM-based smart home serving for those users, who are
unsatisfied with local responses and willing to send less-sensitive queries to
remote servers. For evaluation, we build a comprehensive benchmark DevFinder to
assess the service quality. Extensive experiments and user studies (M=100)
demonstrate that HomeLLaMA can provide personalized services while
significantly enhancing user privacy.

</details>


### [94] [CovertAuth: Joint Covert Communication and Authentication in MmWave Systems](https://arxiv.org/abs/2507.08904)
*Yulin Teng,Keshuang Han,Pinchang Zhang,Xiaohong Jiang,Yulong Shen,Fu Xiao*

Main category: cs.CR

TL;DR: 本文提出了一种名为CovertAuth的新型安全框架，旨在增强毫米波通信中波束对准阶段的安全性，抵御窃听和身份冒充攻击。通过联合优化波束训练预算和传输功率，以及利用天线阵列缺陷的互耦效应进行物理层认证，显著提高了隐蔽通信率和认证准确性。


<details>
  <summary>Details</summary>
Motivation: 毫米波通信中的波束对准过程由于全向暴露和广播特性，极易受到窃听和身份冒充攻击。现有方法在安全性和效率上存在不足，亟需一种综合解决方案来保障波束对准阶段的安全。

Method: 首先推导了成功波束对准概率和隐蔽传输速率的闭式表达式，构建了联合优化波束训练预算和传输功率的隐蔽通信问题。采用交替优化算法结合逐次凸近似进行迭代求解。针对冒充攻击，利用天线阵列缺陷的互耦效应设计加权和能量检测器，并建立检测概率和虚警概率的理论模型进行性能分析。

Result: 仿真结果表明，在相同隐蔽性要求下，CovertAuth相比现有工作具有更高的检测准确率。优化后的权重值能最大化认证准确性，同时隐蔽通信速率得到显著提升。

Conclusion: CovertAuth框架通过双重安全机制有效解决了毫米波波束对准阶段的窃听和冒充威胁，其理论模型和优化算法为未来无线通信安全研究提供了重要参考。

Abstract: Beam alignment (BA) is a crucial process in millimeter-wave (mmWave)
communications, enabling precise directional transmission and efficient link
establishment. However, due to characteristics like omnidirectional exposure
and the broadcast nature of the BA phase, it is particularly vulnerable to
eavesdropping and identity impersonation attacks. To this end, this paper
proposes a novel secure framework named CovertAuth, designed to enhance the
security of the BA phase against such attacks. In particular, to combat
eavesdropping attacks, the closed-form expressions of successful BA probability
and covert transmission rate are first derived. Then, a covert communication
problem aimed at jointly optimizing beam training budget and transmission power
is formulated to maximize covert communication rate, subject to the covertness
requirement. An alternating optimization algorithm combined with successive
convex approximation is employed to iteratively achieve optimal results. To
combat impersonation attacks, the mutual coupling effect of antenna array
impairments is explored as a device feature to design a weighted-sum energy
detector based physical layer authentication scheme. Moreover, theoretical
models for authentication metrics like detection and false alarm probabilities
are also provided to conduct performance analysis. Based on these models, an
optimization problem is constructed to determine the optimal weight value that
maximizes authentication accuracy. Finally, simulation results demonstrate that
CovertAuth presents improved detection accuracy under the same covertness
requirement compared to existing works.

</details>


### [95] [Characterizing Security and Privacy Teaching Standards for Schools in the United States](https://arxiv.org/abs/2507.08978)
*Katherine Limes,Nathan Malkin,Kelsey R. Fulton*

Main category: cs.CR

TL;DR: 研究分析了美国K-12教育中安全与隐私教学标准与行业专家期望的匹配程度，发现标准虽涵盖广泛主题，但专家更强调威胁建模与安全思维。


<details>
  <summary>Details</summary>
Motivation: 随着安全与隐私教育在K-12阶段的普及，研究旨在评估现有教学标准是否与安全隐私社区的专业期望一致。

Method: 收集全美各州及8个国家组织的计算机科学教学标准，人工筛选11,954条标准并标记3,778条相关条目，分类为103个主题，随后访谈11位专业人士进行对比分析。

Result: 标准覆盖了加密、网络安全等技术主题及法律、伦理等社会主题，但专家更重视威胁建模（threat modeling）和安全思维（security mindset）等未被充分强调的内容。

Conclusion: 现行教学标准与行业需求存在部分脱节，未来需加强威胁建模与安全思维等核心能力的培养。

Abstract: Increasingly, students begin learning aspects of security and privacy during
their primary and secondary education (grades K-12 in the United States).
Individual U.S. states and some national organizations publish teaching
standards -- guidance that outlines expectations for what students should learn
-- which often form the basis for course curricula. However, research has not
yet examined what is covered by these standards and whether the topics align
with what the broader security and privacy community thinks students should
know. To shed light on these questions, we started by collecting computer
science teaching standards from all U.S. states and eight national
organizations. After manually examining a total of 11,954 standards, we labeled
3,778 of them as being related to security and privacy, further classifying
these into 103 topics. Topics ranged from technical subjects like encryption,
network security, and embedded systems to social subjects such as laws, ethics,
and appropriate online behavior. Subsequently, we interviewed 11 security and
privacy professionals to examine how the teaching standards align with their
expectations. We found that, while the specific topics they mentioned mostly
overlapped with those of existing standards, professionals placed a greater
emphasis on threat modeling and security mindset.

</details>


### [96] [SSH-Passkeys: Leveraging Web Authentication for Passwordless SSH](https://arxiv.org/abs/2507.09022)
*Moe Kayali,Jonas Schmitt,Franziska Roesner*

Main category: cs.CR

TL;DR: 提出一种利用Web认证API实现SSH无密码登录的方法，通过passkeys替代传统密码和SSH密钥，显著提升安全性和用户体验。


<details>
  <summary>Details</summary>
Motivation: 当前SSH认证主要依赖密码和自定义密钥，存在钓鱼、密钥泄露等安全隐患，且密钥管理复杂。WebAuthn作为现代认证标准能有效解决这些问题，但无法直接与SSH集成。

Method: 通过UNIX可插拔认证模块(PAM)将WebAuthn与SSH服务器集成，保持向后兼容性，无需客户端新软件，提供密钥静态保护、防钓鱼等特性。

Result: 原型测试显示：SSH-passkeys使关键安全错误减少90%，认证时间平均缩短4倍；用户研究中20%的参与者曾泄露私钥，证实传统SSH密钥的安全缺陷。

Conclusion: 该框架成功将WebAuthn优势引入SSH领域，在保持易用性的同时解决了密码和SSH密钥的核心安全问题，为SSH认证提供了更优方案。

Abstract: We propose a method for using Web Authentication APIs for SSH authentication,
enabling passwordless remote server login with passkeys. These are credentials
that are managed throughout the key lifecycle by an authenticator on behalf of
the user and offer strong security guarantees.
  Passwords remain the dominant mode of SSH authentication, despite their well
known flaws such as phishing and reuse. SSH's custom key-based authentication
protocol can alleviate these issues but remains vulnerable to key theft.
Additionally, it has poor usability, with even knowledgeable users leaking key
material and failing to verify fingerprints. Hence, effective key management
remains a critical open area in SSH security. In contrast, WebAuthn is a modern
authentication standard designed to replace passwords, managing keys on behalf
of the user. As a web API, this standard cannot integrate with SSH directly.
  We propose a framework to integrate WebAuthn with SSH servers, by using UNIX
pluggable authentication modules (PAM). Our approach is backwards-compatible,
supports stock SSH servers and requires no new software client-side. It offers
protection for cryptographic material at rest, resistance to key leaks,
phishing protection, privacy protection and attestation capability. None of
these properties are offered by passwords nor traditional SSH keys. We validate
these advantages with a structured, conceptual security analysis.
  We develop a prototype implementation and conduct a user study to quantify
the security advantages of our proposal, testing our prototype with 40 SSH
users. The study confirms the security problems of SSH-keys, including 20% of
the cohort leaking their private keys. Our SSH-passkeys effectively address
these problems: we find a 90% reduction in critical security errors, while
reducing authentication time by 4x on average.

</details>


### [97] [Favicon Trojans: Executable Steganography Via Ico Alpha Channel Exploitation](https://arxiv.org/abs/2507.09074)
*David Noever,Forrest McKee*

Main category: cs.CR

TL;DR: 本文提出了一种利用ICO图像文件的alpha透明层在网页浏览器中嵌入并传递自解压JavaScript负载的新型可执行隐写方法。该方法通过针对非透明alpha层图像值的最低有效位(LSB)，成功将压缩的JavaScript代码隐藏在favicon图像中而不影响视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 全球网络流量每天加载2940亿个favicon，消耗0.9PB的网络带宽。利用这一普遍存在的网络行为，研究者探索了一种隐蔽的攻击面，模糊了静态图像与可执行内容之间的传统界限。

Method: 该方法通过修改ICO文件alpha通道的LSB来嵌入压缩的JavaScript代码。在页面加载时，浏览器会按照标准行为获取favicon，使嵌入的加载脚本能够使用原生JavaScript API和画布像素访问在内存中提取并执行负载，无需额外的网络或用户请求。

Result: 概念验证表明，64x64的ICO图像可以嵌入最多512字节未压缩数据，或使用轻量级双重压缩时达到0.8KB。跨多个浏览器(桌面和移动环境)的测试证实了嵌入脚本的成功且静默执行。研究还分析了如何规避内容安全策略和杀毒扫描器。

Conclusion: 该研究展示了一种隐蔽且可重复利用的攻击面，利用了现代浏览器必须加载ICO文件的特性。现有的隐写分析和净化防御在检测或中和alpha通道漏洞方面存在局限性，这为基于favicon的多态钓鱼攻击提供了新的可能性。

Abstract: This paper presents a novel method of executable steganography using the
alpha transparency layer of ICO image files to embed and deliver
self-decompressing JavaScript payloads within web browsers. By targeting the
least significant bit (LSB) of non-transparent alpha layer image values, the
proposed method successfully conceals compressed JavaScript code inside a
favicon image without affecting visual fidelity. Global web traffic loads 294
billion favicons daily and consume 0.9 petabytes of network bandwidth. A
proof-of-concept implementation demonstrates that a 64x64 ICO image can embed
up to 512 bytes uncompressed, or 0.8 kilobyte when using lightweight two-fold
compression. On page load, a browser fetches the favicon as part of standard
behavior, allowing an embedded loader script to extract and execute the payload
entirely in memory using native JavaScript APIs and canvas pixel access. This
creates a two-stage covert channel requiring no additional network or user
requests. Testing across multiple browsers in both desktop and mobile
environments confirms successful and silent execution of the embedded script.
We evaluate the threat model, relate it to polymorphic phishing attacks that
evade favicon-based detection, and analyze evasion of content security policies
and antivirus scanners. We map nine example MITRE ATT&CK Framework objectives
to single line JavaScript to execute arbitrarily in ICO files. Existing
steganalysis and sanitization defenses are discussed, highlighting limitations
in detecting or neutralizing alpha-channel exploits. The results demonstrate a
stealthy and reusable attack surface that blurs traditional boundaries between
static images and executable content. Because modern browsers report silent
errors when developers specifically fail to load ICO files, this attack surface
offers an interesting example of required web behaviors that in turn compromise
security.

</details>


### [98] [CLIProv: A Contrastive Log-to-Intelligence Multimodal Approach for Threat Detection and Provenance Analysis](https://arxiv.org/abs/2507.09133)
*Jingwen Li,Ru Zhang,Jianyi Liu,Wanguo Zhao*

Main category: cs.CR

TL;DR: 本文提出CLIProv方法，通过对比学习弥合威胁情报与溯源日志的语义鸿沟，将威胁检测转化为语义搜索问题，显著提升攻击行为检测效率与精度。


<details>
  <summary>Details</summary>
Motivation: 当前高级威胁情报(TTP)与底层溯源日志间的语义差距，导致难以转化为可执行安全策略。需要新方法实现高效攻击行为检测与溯源分析。

Method: 采用多模态框架：1) 对比学习对齐日志与威胁情报语义 2) 将威胁检测建模为语义搜索问题 3) 基于攻击模式生成完整攻击场景。

Result: 实验表明：1) 有效识别系统溯源日志中的攻击行为 2) 检测精度超越现有方法 3) 显著提升检测效率。

Conclusion: CLIProv通过语义对齐与搜索机制，为复杂网络攻击检测提供高效解决方案，其方法论对威胁情报实践具有参考价值。

Abstract: With the increasing complexity of cyberattacks, the proactive and
forward-looking nature of threat intelligence has become more crucial for
threat detection and provenance analysis. However, translating high-level
attack patterns described in Tactics, Techniques, and Procedures (TTP)
intelligence into actionable security policies remains a significant challenge.
This challenge arises from the semantic gap between high-level threat
intelligence and low-level provenance log. To address this issue, this paper
introduces CLIProv, a novel approach for detecting threat behaviors in a host
system. CLIProv employs a multimodal framework that leverages contrastive
learning to align the semantics of provenance logs with threat intelligence,
effectively correlating system intrusion activities with attack patterns.
Furthermore, CLIProv formulates threat detection as a semantic search problem,
identifying attack behaviors by searching for threat intelligence that is most
semantically similar to the log sequence. By leveraging attack pattern
information in threat intelligence, CLIProv identifies TTPs and generates
complete and concise attack scenarios. Experimental evaluations on standard
datasets show that CLIProv effectively identifies attack behaviors in system
provenance logs, offering valuable references for potential techniques.
Compared to state-of-the-art methods, CLIProv achieves higher precision and
significantly improved detection efficiency.

</details>


### [99] [Confidential Wrapped Ethereum](https://arxiv.org/abs/2507.09231)
*Artem Chystiakov,Mariia Zhvanko*

Main category: cs.CR

TL;DR: 论文提出了一种在应用层实现隐私保护的封装以太坊（cWETH）方案，结合椭圆曲线加密与零知识证明技术，平衡区块链透明性与用户隐私需求。


<details>
  <summary>Details</summary>
Motivation: 公共区块链的透明性虽是其核心优势，但交易公开会威胁用户隐私。研究旨在不牺牲区块链开放性的前提下，解决用户机密性保护这一关键问题。

Method: 采用基于椭圆曲线扭曲ElGamal的承诺方案保障机密性，结合EC Diffie-Hellman协议实现受限访问，并利用zk-SNARKs验证承诺生成、加密及解密的正确性。

Result: 成功设计出完全在应用层运行的cWETH方案，通过密码学原语组合实现了交易数据的可验证隐私保护。

Conclusion: 该方案为区块链隐私保护提供了新思路，证明在不修改底层协议的情况下，通过应用层创新即可兼顾透明性与机密性需求。

Abstract: Transparency is one of the key benefits of public blockchains. However, the
public visibility of transactions potentially compromises users' privacy. The
fundamental challenge is to balance the intrinsic benefits of blockchain
openness with the vital need for individual confidentiality. The proposal
suggests creating a confidential version of wrapped Ethereum (cWETH) fully
within the application layer. The solution combines the Elliptic Curve (EC)
Twisted ElGamal-based commitment scheme to preserve confidentiality and the EC
Diffie-Hellman (DH) protocol to introduce accessibility limited by the
commitment scheme. To enforce the correct generation of commitments,
encryption, and decryption, zk-SNARKs are utilized.

</details>


### [100] [Hybrid Quantum Security for IPsec](https://arxiv.org/abs/2507.09288)
*Javier Blanco-Romero,Pedro Otero García,Daniel Sobral-Blanco,Florina Almenares Mendoza,Ana Fernández Vilas,Manuel Fernández-Veiga*

Main category: cs.CR

TL;DR: 本文首次系统比较了IPsec中顺序与并行混合QKD-PQC密钥建立策略，提出了两种将QKD整合到IKEv2协议的新方法，并通过实验证明并行混合方法在性能上显著优于顺序方法。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发(QKD)虽能提供信息论安全性，但其与传统安全协议的整合仍存在挑战，主要源于预分发量子密钥与计算密钥交换模式的不匹配。

Method: 提出两种新方法：(1)纯QKD方法，用基于标识符的量子密钥协调替代计算密钥派生；(2)统一的QKD-KEM抽象，允许在现有协议框架内并行组合量子与后量子密码方法。

Result: 基于Docker的测试框架与IDQuantique QKD硬件的性能评估显示，并行混合方法在网络延迟条件下显著优于顺序方法，而纯QKD通过标识符密钥协调实现了最小带宽开销。

Conclusion: 研究为关键基础设施部署提供了实用的量子增强IPsec解决方案，并行混合方法消除了RFC 9370规定的顺序方法固有延迟惩罚，实现了深度防御安全。

Abstract: Quantum Key Distribution (QKD) offers information-theoretic security against
quantum computing threats, but integrating QKD into existing security protocols
remains an unsolved challenge due to fundamental mismatches between
pre-distributed quantum keys and computational key exchange paradigms. This
paper presents the first systematic comparison of sequential versus parallel
hybrid QKD-PQC key establishment strategies for IPsec, revealing fundamental
protocol design principles that extend beyond specific implementations. We
introduce two novel approaches for incorporating QKD into Internet Key Exchange
version 2 (IKEv2) with support for both ETSI GS QKD 004 stateful and ETSI GS
QKD 014 stateless API specifications: (1) a pure QKD approach that replaces
computational key derivation with identifier-based quantum key coordination,
and (2) a unified QKD-KEM abstraction that enables parallel composition of
quantum and post-quantum cryptographic methods within existing protocol
frameworks. Our key insight is that parallel hybrid approaches eliminate the
multiplicative latency penalties inherent in sequential methods mandated by RFC
9370, achieving significant performance improvements under realistic network
conditions. Performance evaluation using a Docker-based testing framework with
IDQuantique QKD hardware demonstrates that the parallel hybrid approach
significantly outperforms sequential methods under network latency conditions,
while pure QKD achieves minimal bandwidth overhead through identifier-based key
coordination. Our implementations provide practical quantum-enhanced IPsec
solutions suitable for critical infrastructure deployments requiring
defense-in-depth security.

</details>


### [101] [Implementing and Evaluating Post-Quantum DNSSEC in CoreDNS](https://arxiv.org/abs/2507.09301)
*Julio Gento Suela,Javier Blanco-Romero,Florina Almenares Mendoza,Daniel Díaz-Sánchez*

Main category: cs.CR

TL;DR: 本文提出了一种将后量子密码（PQC）算法集成到CoreDNS中的方法，以实现抗量子攻击的DNSSEC功能。研究开发了一个支持五种PQC签名算法家族的插件，并评估了其性能与安全性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 量子计算机的出现对依赖RSA和ECDSA等算法的现有安全服务（如DNSSEC）构成威胁，因为这些基于数论问题的公钥密码易受量子攻击。

Method: 研究团队开发了一个CoreDNS插件，支持ML-DSA、FALCON、SPHINCS+、MAYO和SNOVA五种PQC签名算法家族，实现了兼容现有DNS解析流程的实时量子抗性签名功能。

Result: 性能评估显示，PQC算法虽引入操作开销，但部分候选方案在安全性与效率之间提供了可行的折衷方案，适用于DNSSEC向抗量子密码的过渡。

Conclusion: 研究表明，通过集成PQC算法，CoreDNS能够实现量子抗性的DNSSEC功能，尽管存在性能开销，但部分算法家族已具备实际部署的潜力。

Abstract: The emergence of quantum computers poses a significant threat to current
secure service, application and/or protocol implementations that rely on RSA
and ECDSA algorithms, for instance DNSSEC, because public-key cryptography
based on number factorization or discrete logarithm is vulnerable to quantum
attacks. This paper presents the integration of post-quantum cryptographic
(PQC) algorithms into CoreDNS to enable quantum-resistant DNSSEC functionality.
We have developed a plugin that extends CoreDNS with support for five PQC
signature algorithm families: ML-DSA, FALCON, SPHINCS+, MAYO, and SNOVA. Our
implementation maintains compatibility with existing DNS resolution flows while
providing on-the-fly signing using quantum-resistant signatures. A benchmark
has been performed and performance evaluation results reveal significant
trade-offs between security and efficiency. The results indicate that while PQC
algorithms introduce operational overhead, several candidates offer viable
compromises for transitioning DNSSEC to quantum-resistant cryptography.

</details>


### [102] [Backscatter Device-aided Integrated Sensing and Communication: A Pareto Optimization Framework](https://arxiv.org/abs/2507.09354)
*Yifan Zhang,Yu Bai,Riku Jantti,Zheng Yan,Christos Masouros,Zhu Han*

Main category: cs.CR

TL;DR: 本文提出了一种利用环境中的被动反向散射设备（BD）增强集成感知与通信（ISAC）系统性能的方法，通过联合优化资源分配、功率管理和BD调制决策，在密集遮挡场景中显著提升感知精度与通信可靠性。


<details>
  <summary>Details</summary>
Motivation: 密集遮挡的城市和非视距场景会导致ISAC系统性能显著下降，限制了其实际应用效果，因此需要利用环境中自然分布的被动BD设备来增强系统性能。

Method: 在OFDM框架下，通过定义感知互信息（SMI）与通信速率的帕累托边界，将问题分解为三个子问题，采用块坐标下降（BCD）算法迭代求解，分别使用连续凸逼近（SCA）、增广拉格朗日结合注水法以及半定松弛（SDR）方法处理资源分配、功率管理和BD调制问题。

Result: 仿真结果表明，所提系统在双静态ISAC场景和MIMO配置中均表现出优越性能，显著优于现有先进ISAC方案。

Conclusion: BD辅助的ISAC系统通过利用环境中的被动设备提供额外反射路径，有效解决了密集遮挡场景的性能瓶颈，为未来ISAC系统的实际部署提供了重要设计思路。

Abstract: Integrated sensing and communication (ISAC) systems potentially encounter
significant performance degradation in densely obstructed urban and
non-line-of-sight scenarios, thus limiting their effectiveness in practical
deployments. To deal with these challenges, this paper proposes a backscatter
device (BD)-assisted ISAC system, which leverages passive BDs naturally
distributed in underlying environments for performance enhancement. These
ambient devices can enhance sensing accuracy and communication reliability by
providing additional reflective signal paths. In this system, we define the
Pareto boundary characterizing the trade-off between sensing mutual information
(SMI) and communication rates to provide fundamental insights for its design.
To derive the boundary, we formulate a performance optimization problem within
an orthogonal frequency division multiplexing (OFDM) framework, by jointly
optimizing time-frequency resource element (RE) allocation, transmit power
management, and BD modulation decisions. To tackle the non-convexity of the
problem, we decompose it into three subproblems, solved iteratively through a
block coordinate descent (BCD) algorithm. Specifically, the RE subproblem is
addressed using the successive convex approximation (SCA) method, the power
subproblem is solved using an augmented Lagrangian combined water-filling
method, and the BD modulation subproblem is tackled using semidefinite
relaxation (SDR) methods. Additionally, we demonstrate the generality of the
proposed system by showing its adaptability to bistatic ISAC scenarios and MIMO
settings. Finally, extensive simulation results validate the effectiveness of
the proposed system and its superior performance compared to existing
state-of-the-art ISAC schemes.

</details>


### [103] [LLMalMorph: On The Feasibility of Generating Variant Malware using Large-Language-Models](https://arxiv.org/abs/2507.09411)
*Md Ajwad Akil,Adrian Shuai Li,Imtiaz Karim,Arun Iyengar,Ashish Kundu,Vinny Parla,Elisa Bertino*

Main category: cs.CR

TL;DR: 本文提出LLMalMorph框架，利用大语言模型（LLMs）半自动化生成恶意软件变体，通过语义和语法理解实现代码转换，实验表明能有效降低杀毒引擎检测率并保持功能。


<details>
  <summary>Details</summary>
Motivation: 受LLMs在代码生成领域的突破启发，研究探索其修改恶意软件源码生成变体的可行性，以评估当前LLMs在恶意软件变体生成中的能力边界。

Method: 开发LLMalMorph框架：从恶意软件源码提取函数级信息，结合定制化提示词与策略性代码变换，无需微调即可引导LLM生成功能保持的变体。实验使用10个不同复杂度/类型的Windows恶意样本生成618个变体。

Result: 成功降低传统杀毒引擎检测率（部分变体），且未针对ML检测器优化的变体仍对ML分类器表现出显著攻击成功率。同时揭示了LLMs在代码风格一致性、复杂逻辑保持等方面的生成局限。

Conclusion: LLMs可成为恶意软件变体生成的新兴工具，但当前技术仍存在局限性。研究为理解LLMs在网络安全威胁演化中的潜在影响提供了实证基础。

Abstract: Large Language Models (LLMs) have transformed software development and
automated code generation. Motivated by these advancements, this paper explores
the feasibility of LLMs in modifying malware source code to generate variants.
We introduce LLMalMorph, a semi-automated framework that leverages semantical
and syntactical code comprehension by LLMs to generate new malware variants.
LLMalMorph extracts function-level information from the malware source code and
employs custom-engineered prompts coupled with strategically defined code
transformations to guide the LLM in generating variants without
resource-intensive fine-tuning. To evaluate LLMalMorph, we collected 10 diverse
Windows malware samples of varying types, complexity and functionality and
generated 618 variants. Our thorough experiments demonstrate that it is
possible to reduce the detection rates of antivirus engines of these malware
variants to some extent while preserving malware functionalities. In addition,
despite not optimizing against any Machine Learning (ML)-based malware
detectors, several variants also achieved notable attack success rates against
an ML-based malware classifier. We also discuss the limitations of current LLM
capabilities in generating malware variants from source code and assess where
this emerging technology stands in the broader context of malware variant
generation.

</details>


### [104] [SmartphoneDemocracy: Privacy-Preserving E-Voting on Decentralized Infrastructure using Novel European Identity](https://arxiv.org/abs/2507.09453)
*Michał Jóźwik,Johan Pouwelse*

Main category: cs.CR

TL;DR: 本文提出了一种基于智能手机的安全、隐私保护的电子投票协议SmartphoneDemocracy，结合欧盟数字身份钱包、零知识证明和点对点区块链技术，实现了匿名可验证的投票。


<details>
  <summary>Details</summary>
Motivation: 现有电子投票系统依赖中心化架构，存在单点故障和过度信任问题，违背民主原则。研究旨在开发一种安全、隐私保护且信任依赖最小化的智能手机投票方案。

Method: 协议整合三项关键技术：欧盟数字身份钱包（防女巫攻击）、零知识证明（隐私保护验证）和点对点区块链TrustChain（无服务器公共公告板），支持匿名可验证的智能手机投票。

Result: 安全分析表明协议能抵御定义威胁模型，性能评估证实计算和网络开销适用于中大规模选举，原型系统验证了可行性。

Conclusion: SmartphoneDemocracy为公民提供了一条可信、易用且用户可控的数字投票路径，推动了民主进程的数字化发展。

Abstract: The digitization of democratic processes promises greater accessibility but
presents challenges in terms of security, privacy, and verifiability. Existing
electronic voting systems often rely on centralized architectures, creating
single points of failure and forcing too much trust in authorities, which
contradicts democratic principles. This research addresses the challenge of
creating a secure, private e-voting system with minimized trust dependencies
designed for the most versatile personal device: the smartphone. We introduce
SmartphoneDemocracy, a novel e-voting protocol that combines three key
technologies: the emerging European Digital Identity (EUDI) Wallet for
Sybil-resistant identity verification, Zero-Knowledge Proofs for
privacy-preserving validation, and a peer-to-peer blockchain (TrustChain) for a
resilient, serverless public bulletin board. Our protocol enables voters to
register and cast ballots anonymously and verifiably directly from their
smartphones. We provide a detailed protocol design, a security analysis against
a defined threat model, and a performance evaluation demonstrating that the
computational and network overhead is feasible for medium- to large-scale
elections. By developing and prototyping this system, we demonstrate a viable
path to empower citizens with a trustworthy, accessible, and user-controlled
digital voting experience.

</details>


### [105] [A Mixture of Linear Corrections Generates Secure Code](https://arxiv.org/abs/2507.09508)
*Weichen Yu,Ravi Mangal,Terry Zhuo,Matt Fredrikson,Corina S. Pasareanu*

Main category: cs.CR

TL;DR: 研究发现大语言模型(LLMs)内部已编码区分代码漏洞的精确表征，通过混合修正(MoC)技术可引导模型生成更安全的代码，在保持功能性的同时显著提升安全性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型擅长代码生成，但其在检测和避免代码漏洞方面表现不佳。研究旨在探究这种缺陷源于漏洞知识不足还是提示策略失效。

Method: 采用表征工程技术分析LLMs内部是否编码漏洞概念，并开发基于混合修正(MoC)的推理时引导技术，微调模型的token生成概率。

Result: MoC方法使Qwen2.5-Coder-7B的安全率提升8.9\%，同时HumanEval pass@1功能指标提高2.1\%，证明可在不影响功能性的前提下增强代码安全性。

Conclusion: LLMs已具备识别代码漏洞的内部表征能力，通过MoC技术可实现可控的漏洞管理，为生成代码的安全实践提供有效解决方案。

Abstract: Large language models (LLMs) have become proficient at sophisticated
code-generation tasks, yet remain ineffective at reliably detecting or avoiding
code vulnerabilities. Does this deficiency stem from insufficient learning
about code vulnerabilities, or is it merely a result of ineffective prompting?
Using representation engineering techniques, we investigate whether LLMs
internally encode the concepts necessary to identify code vulnerabilities. We
find that current LLMs encode precise internal representations that distinguish
vulnerable from secure code--achieving greater accuracy than standard prompting
approaches. Leveraging these vulnerability-sensitive representations, we
develop an inference-time steering technique that subtly modulates the model's
token-generation probabilities through a mixture of corrections (MoC). Our
method effectively guides LLMs to produce less vulnerable code without
compromising functionality, demonstrating a practical approach to controlled
vulnerability management in generated code. Notably, MoC enhances the security
ratio of Qwen2.5-Coder-7B by 8.9\%, while simultaneously improving
functionality on HumanEval pass@1 by 2.1\%.

</details>


### [106] [A Login Page Transparency and Visual Similarity Based Zero Day Phishing Defense Protocol](https://arxiv.org/abs/2507.09564)
*Gaurav Varshney,Akanksha Raj,Divya Sangwan,Sharif Abuadbba,Rina Mishra,Yansong Gao*

Main category: cs.CR

TL;DR: 本文提出了一种名为'页面透明度'(PT)的新概念，旨在通过公开记录登录页面并使用密码学证明进行验证，从而有效对抗网络钓鱼攻击。


<details>
  <summary>Details</summary>
Motivation: 网络钓鱼攻击通过仿冒网站欺骗用户泄露敏感信息，现有解决方案多为独立应用，缺乏全面且主动的协议级防护措施。

Method: 受证书透明性启发，PT要求将捕获用户敏感信息的登录页面通过PLS公开记录，并采用密码学证明和视觉页面匹配算法进行验证，所有实现均在客户端通过新HTTP PT头部完成。

Result: 该方法使得攻击者无法在PLS上注册仿冒页面并获得验证所需的密码学证明，从而有效阻止钓鱼攻击，且无需平台特定修改或第三方解决方案。

Conclusion: 页面透明度(PT)为网络钓鱼防护提供了一种协议级的全面解决方案，通过客户端实现的公开验证机制显著提升了防护效果。

Abstract: Phishing is a prevalent cyberattack that uses look-alike websites to deceive
users into revealing sensitive information. Numerous efforts have been made by
the Internet community and security organizations to detect, prevent, or train
users to avoid falling victim to phishing attacks. Most of this research over
the years has been highly diverse and application-oriented, often serving as
standalone solutions for HTTP clients, servers, or third parties. However,
limited work has been done to develop a comprehensive or proactive
protocol-oriented solution to effectively counter phishing attacks. Inspired by
the concept of certificate transparency, which allows certificates issued by
Certificate Authorities (CAs) to be publicly verified by clients, thereby
enhancing transparency, we propose a concept called Page Transparency (PT) for
the web. The proposed PT requires login pages that capture users' sensitive
information to be publicly logged via PLS and made available to web clients for
verification. The pages are verified to be logged using cryptographic proofs.
Since all pages are logged on a PLS and visually compared with existing pages
through a comprehensive visual page-matching algorithm, it becomes impossible
for an attacker to register a deceptive look-alike page on the PLS and receive
the cryptographic proof required for client verification. All implementations
occur on the client side, facilitated by the introduction of a new HTTP PT
header, eliminating the need for platform-specific changes or the installation
of third-party solutions for phishing prevention.

</details>


### [107] [PromptChain: A Decentralized Web3 Architecture for Managing AI Prompts as Digital Assets](https://arxiv.org/abs/2507.09579)
*Marc Bara*

Main category: cs.CR

TL;DR: PromptChain提出了一种去中心化的Web3架构，将AI提示作为具有可验证所有权、版本控制和货币化能力的一类数字资产。


<details>
  <summary>Details</summary>
Motivation: 当前的中心化平台缺乏适当的归属机制、质量保证或对提示创作者的公平补偿，PromptChain旨在解决这些限制。

Method: 通过整合IPFS进行不可变存储、智能合约进行治理以及代币激励社区策展，设计了包括跨模型兼容的元数据模式、权益加权验证机制和按贡献比例奖励的代币经济。

Result: 该架构展示了去中心化系统如何在效率上匹敌中心化替代方案，同时通过区块链锚定的来源追踪提供更优的所有权保证和抗审查性。

Conclusion: 通过将提示与特定AI模型或输出解耦，这项工作为Web3时代的人机协作开放生态系统奠定了基础，首次系统性地将提示视为具有专用去中心化基础设施的独立数字资产。

Abstract: We present PromptChain, a decentralized Web3 architecture that establishes AI
prompts as first-class digital assets with verifiable ownership, version
control, and monetization capabilities. Current centralized platforms lack
mechanisms for proper attribution, quality assurance, or fair compensation for
prompt creators. PromptChain addresses these limitations through a novel
integration of IPFS for immutable storage, smart contracts for governance, and
token incentives for community curation. Our design includes: (1) a
comprehensive metadata schema for cross-model compatibility, (2) a
stake-weighted validation mechanism to align incentives, and (3) a token
economy that rewards contributors proportionally to their impact. The proposed
architecture demonstrates how decentralized systems could potentially match
centralized alternatives in efficiency while providing superior ownership
guarantees and censorship resistance through blockchain-anchored provenance
tracking. By decoupling prompts from specific AI models or outputs, this work
establishes the foundation for an open ecosystem of human-AI collaboration in
the Web3 era, representing the first systematic treatment of prompts as
standalone digital assets with dedicated decentralized infrastructure.

</details>


### [108] [AICrypto: A Comprehensive Benchmark For Evaluating Cryptography Capabilities of Large Language Models](https://arxiv.org/abs/2507.09580)
*Yu Wang,Yijian Liu,Liheng Ji,Han Luo,Wenjie Li,Xiaofei Zhou,Chiyun Feng,Puji Wang,Yuhan Cao,Geyuan Zhang,Xiaojian Li,Rongwu Xu,Yilei Chen,Tianxing He*

Main category: cs.CR

TL;DR: 本文提出了首个全面评估大语言模型（LLMs）密码学能力的基准测试AICrypto，包含多种任务类型。评估17个主流LLMs后发现，顶尖模型在记忆密码学概念、利用常见漏洞和常规证明上接近或超越人类专家，但在抽象数学理解和多步推理上仍有不足。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在多个领域表现出色，但其在密码学（网络安全基石）中的应用尚未充分探索。为填补这一空白，研究者旨在系统评估LLMs的密码学能力。

Method: 构建包含135道选择题、150个夺旗挑战和18个证明问题的基准测试AICrypto，所有任务经密码学专家审核。设计基于智能体的自动化评估框架，并引入人类专家表现基线进行对比。

Result: 评估17个主流LLMs显示：顶尖模型在密码概念记忆、漏洞利用和常规证明上达到或超越人类水平，但在抽象数学理解（如$\lambda$演算）和多步动态分析任务上表现欠佳。

Conclusion: AICrypto基准揭示了LLMs当前密码学能力的优势与局限，为未来研究提供方向。代码与数据集已开源，助力LLMs在密码学应用的进一步发展。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
a variety of domains. However, their applications in cryptography, which serves
as a foundational pillar of cybersecurity, remain largely unexplored. To
address this gap, we propose \textbf{AICrypto}, the first comprehensive
benchmark designed to evaluate the cryptographic capabilities of LLMs. The
benchmark comprises 135 multiple-choice questions, 150 capture-the-flag (CTF)
challenges, and 18 proof problems, covering a broad range of skills from
factual memorization to vulnerability exploitation and formal reasoning. All
tasks are carefully reviewed or constructed by cryptography experts to ensure
correctness and rigor. To support automated evaluation of CTF challenges, we
design an agent-based framework. To gain deeper insight into the current state
of cryptographic proficiency in LLMs, we introduce human expert performance
baselines for comparison across all task types. Our evaluation of 17 leading
LLMs reveals that state-of-the-art models match or even surpass human experts
in memorizing cryptographic concepts, exploiting common vulnerabilities, and
routine proofs. However, they still lack a deep understanding of abstract
mathematical concepts and struggle with tasks that require multi-step reasoning
and dynamic analysis. We hope this work could provide insights for future
research on LLMs in cryptographic applications. Our code and dataset are
available at https://aicryptobench.github.io.

</details>


### [109] [Efficient Private Inference Based on Helper-Assisted Malicious Security Dishonest Majority MPC](https://arxiv.org/abs/2507.09607)
*Kaiwen Wang,Yuehan Dong,Junchao Fan,Xiaolin Chang*

Main category: cs.CR

TL;DR: 本文提出了一种基于辅助恶意安全非诚实多数模型（HA-MSDM）的高效隐私推理框架，通过五种定制MPC协议和协同优化策略，在保证安全性的同时显著提升计算效率，并在LeNet和AlexNet上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有MPC隐私推理框架多基于半诚实或诚实多数模型，威胁模型过于理想化；而恶意安全非诚实多数模型效率低下。需在安全与效率间取得平衡。

Method: 1) 设计五种MPC协议实现高效固定轮次乘法/指数/多项式运算；2) 采用多项式逼近非线性层提升效率；3) 构建六阶多项式逼近实现高精度激活函数拟合；4) 引入参数可调批量归一化层约束激活逃逸问题。

Result: 在LeNet和AlexNet上：LAN环境提速2.4-25.7倍，WAN环境加速1.3-9.5倍（对比IEEE S&P'25方案），相对误差仅0.04%-1.08%。

Conclusion: HA-MSDM框架通过协议创新与协同优化，首次在恶意安全非诚实多数模型下实现高效高精度的隐私推理，为MLaaS提供了实用化解决方案。

Abstract: Private inference based on Secure Multi-Party Computation (MPC) addresses
data privacy risks in Machine Learning as a Service (MLaaS). However, existing
MPC-based private inference frameworks focuses on semi-honest or honest
majority models, whose threat models are overly idealistic, while malicious
security dishonest majority models face the challenge of low efficiency. To
balance security and efficiency, we propose a private inference framework using
Helper-Assisted Malicious Security Dishonest Majority Model (HA-MSDM). This
framework includes our designed five MPC protocols and a co-optimized strategy.
These protocols achieve efficient fixed-round multiplication, exponentiation,
and polynomial operations, providing foundational primitives for private
inference. The co-optimized strategy balances inference efficiency and
accuracy. To enhance efficiency, we employ polynomial approximation for
nonlinear layers. For improved accuracy, we construct sixth-order polynomial
approximation within a fixed interval to achieve high-precision activation
function fitting and introduce parameter-adjusted batch normalization layers to
constrain the activation escape problem. Benchmark results on LeNet and AlexNet
show our framework achieves 2.4-25.7x speedup in LAN and 1.3-9.5x acceleration
in WAN compared to state-of-the-art frameworks (IEEE S&P'25), maintaining high
accuracy with only 0.04%-1.08% relative errors.

</details>


### [110] [CAN-Trace Attack: Exploit CAN Messages to Uncover Driving Trajectories](https://arxiv.org/abs/2507.09624)
*Xiaojie Lin,Baihe Ma,Xu Wang,Guangsheng Yu,Ying He,Wei Ni,Ren Ping Liu*

Main category: cs.CR

TL;DR: 本文提出CAN-Trace，一种利用CAN消息重构驾驶轨迹的新型隐私攻击方法，通过车速和油门踏板位置数据构建加权图并与路网匹配，攻击成功率最高达99.41%。


<details>
  <summary>Details</summary>
Motivation: 现有GPS轨迹检测方法易受信号中断影响，且驾驶轨迹隐私保护存在漏洞，需探索基于车载CAN消息的潜在攻击途径。

Method: 设计轨迹重构算法将CAN数据转换为加权图，采用图匹配算法与路网比对，并开发新指标评估匹配候选以容忍数据间隙和误差。

Result: 真实场景测试显示攻击成功率城区达90.59%、郊区达99.41%，验证了CAN-Trace对多车型和区域的普适有效性。

Conclusion: CAN-Trace揭示了车载总线数据的隐私风险，其高成功率表明传统防护措施不足，亟需新型防御机制应对此类攻击。

Abstract: Driving trajectory data remains vulnerable to privacy breaches despite
existing mitigation measures. Traditional methods for detecting driving
trajectories typically rely on map-matching the path using Global Positioning
System (GPS) data, which is susceptible to GPS data outage. This paper
introduces CAN-Trace, a novel privacy attack mechanism that leverages
Controller Area Network (CAN) messages to uncover driving trajectories, posing
a significant risk to drivers' long-term privacy. A new trajectory
reconstruction algorithm is proposed to transform the CAN messages,
specifically vehicle speed and accelerator pedal position, into weighted graphs
accommodating various driving statuses. CAN-Trace identifies driving
trajectories using graph-matching algorithms applied to the created graphs in
comparison to road networks. We also design a new metric to evaluate matched
candidates, which allows for potential data gaps and matching inaccuracies.
Empirical validation under various real-world conditions, encompassing
different vehicles and driving regions, demonstrates the efficacy of CAN-Trace:
it achieves an attack success rate of up to 90.59% in the urban region, and
99.41% in the suburban region.

</details>


### [111] [Interpreting Differential Privacy in Terms of Disclosure Risk](https://arxiv.org/abs/2507.09699)
*Zeki Kazan,Sagar Sharma,Wanrong Zhang,Bo Jiang,Qiang Yan*

Main category: cs.CR

TL;DR: 本文探讨了差分隐私（DP）与统计披露风险度量之间的新关系，为专家和非专家提供了解释DP保证、选择隐私参数的工具。


<details>
  <summary>Details</summary>
Motivation: 随着差分隐私（DP）的广泛应用，开发有效工具来理解其隐私保障变得至关重要。

Method: 通过建立DP与统计披露风险度量之间的新关系，提出了一种解释DP保证和隐私参数选择的方法。

Result: 研究结果表明，这些关系可以帮助解释DP组合定理，并为隐私参数的选择和合理性提供依据。

Conclusion: 该研究为理解和应用差分隐私提供了新的视角和工具，有助于更有效地实施隐私保护措施。

Abstract: As the use of differential privacy (DP) becomes widespread, the development
of effective tools for reasoning about the privacy guarantee becomes
increasingly critical. In pursuit of this goal, we demonstrate novel
relationships between DP and measures of statistical disclosure risk. We
suggest how experts and non-experts can use these results to explain the DP
guarantee, interpret DP composition theorems, select and justify privacy
parameters, and identify worst-case adversary prior probabilities.

</details>


### [112] [EventHunter: Dynamic Clustering and Ranking of Security Events from Hacker Forum Discussions](https://arxiv.org/abs/2507.09762)
*Yasir Ech-Chammakhy,Anas Motii,Anass Rabii,Jaafar Chbili*

Main category: cs.CR

TL;DR: 本文提出了一种无监督框架，通过Transformer嵌入和对比学习自动检测、聚类并优先处理黑客论坛中的安全事件，有效减少噪音并识别高优先级威胁。


<details>
  <summary>Details</summary>
Motivation: 黑客论坛是网络安全威胁的早期预警信号源，但其内容非结构化且噪音大，难以提取可操作情报。

Method: 采用基于Transformer的嵌入模型，通过对比学习微调，将相关讨论聚类为安全事件，并结合时间性、来源可信度、信息完整性和相关性等量化指标进行每日排名。

Result: 在真实黑客论坛数据上的实验表明，该方法能有效降噪并识别高优先级威胁，帮助安全分析师采取主动响应。

Conclusion: 该框架将分散的黑客论坛讨论转化为结构化、可操作的情报，解决了自动威胁检测与分析中的核心挑战。

Abstract: Hacker forums provide critical early warning signals for emerging
cybersecurity threats, but extracting actionable intelligence from their
unstructured and noisy content remains a significant challenge. This paper
presents an unsupervised framework that automatically detects, clusters, and
prioritizes security events discussed across hacker forum posts. Our approach
leverages Transformer-based embeddings fine-tuned with contrastive learning to
group related discussions into distinct security event clusters, identifying
incidents like zero-day disclosures or malware releases without relying on
predefined keywords. The framework incorporates a daily ranking mechanism that
prioritizes identified events using quantifiable metrics reflecting timeliness,
source credibility, information completeness, and relevance. Experimental
evaluation on real-world hacker forum data demonstrates that our method
effectively reduces noise and surfaces high-priority threats, enabling security
analysts to mount proactive responses. By transforming disparate hacker forum
discussions into structured, actionable intelligence, our work addresses
fundamental challenges in automated threat detection and analysis.

</details>


### [113] [Endorsement-Driven Blockchain SSI Framework for Dynamic IoT Ecosystems](https://arxiv.org/abs/2507.09859)
*Guntur Dharma Putra,Bagus Rakadyanto Oktavianto Putra*

Main category: cs.CR

TL;DR: 本文提出了一种基于区块链的自主权身份（SSI）框架，支持任何具有可验证信任关联的个体作为凭证颁发者，适用于动态物联网（IoT）环境。


<details>
  <summary>Details</summary>
Motivation: 现有的SSI框架通常仅允许受信任实体（如IoT制造商）颁发和撤销凭证，限制了动态IoT生态系统的灵活性。

Method: 采用分层架构，通过基于背书的动态信任计算和分层信任链机制维护信任关系，区块链作为可验证数据注册表确保透明性和不可篡改性，智能合约自动化凭证颁发、验证和撤销等关键流程。

Result: 概念验证表明，该框架可行且与基线相比开销极小，适合资源受限的动态IoT环境。

Conclusion: 提出的区块链SSI框架实现了去中心化、可扩展的身份管理，为动态IoT生态系统提供了灵活且高效的解决方案。

Abstract: Self-Sovereign Identity (SSI) offers significant potential for managing
identities in the Internet of Things (IoT), enabling decentralized
authentication and credential management without reliance on centralized
entities. However, existing SSI frameworks often limit credential issuance and
revocation to trusted entities, such as IoT manufacturers, which restricts
flexibility in dynamic IoT ecosystems. In this paper, we propose a
blockchain-based SSI framework that allows any individual with a verifiable
trust linkage to act as a credential issuer, ensuring decentralized and
scalable identity management. Our framework incorporates a layered
architecture, where trust is dynamically established through endorsement-based
calculations and maintained via a hierarchical chain-of-trust mechanism.
Blockchain serves as the Verifiable Data Registry, ensuring transparency and
immutability of identity operations, while smart contracts automate critical
processes such as credential issuance, verification, and revocation. A
proof-of-concept implementation demonstrates that the proposed framework is
feasible and incurs minimal overheads compared to the baseline, making it
well-suited for dynamic and resource-constrained IoT environments.

</details>


### [114] [Secure and Efficient UAV-Based Face Detection via Homomorphic Encryption and Edge Computing](https://arxiv.org/abs/2507.09860)
*Nguyen Van Duc,Bui Duc Manh,Quang-Trung Luu,Dinh Thai Hoang,Van-Linh Nguyen,Diep N. Nguyen*

Main category: cs.CR

TL;DR: 本文提出了一种结合同态加密（HE）的新型机器学习方法，用于解决无人机（UAV）人脸检测中的隐私问题。该方法通过CKKS方案在加密数据上直接计算，同时保持检测精度。


<details>
  <summary>Details</summary>
Motivation: 无人机的高分辨率图像和先进神经网络虽能实现动态环境下的人脸识别，但其广泛监控能力引发了隐私担忧。因此，需要一种既能保护隐私又不显著降低检测精度的方法。

Method: 提出了一种集成HE与神经网络的框架，采用CKKS方案对加密数据进行计算，并开发了有效的数据编码方法以SIMD方式预处理原始人脸数据，设计了无需解密的密文安全推理算法。

Result: 实验结果表明，该方法在保护数据隐私的同时，检测性能与未加密基准相比仅有不到1%的准确率损失，有效平衡了隐私保护与检测性能。

Conclusion: 该方法为无人机安全人脸检测提供了一种可行的解决方案，既确保了数据隐私，又优化了计算效率与安全性。

Abstract: This paper aims to propose a novel machine learning (ML) approach
incorporating Homomorphic Encryption (HE) to address privacy limitations in
Unmanned Aerial Vehicles (UAV)-based face detection. Due to challenges related
to distance, altitude, and face orientation, high-resolution imagery and
sophisticated neural networks enable accurate face recognition in dynamic
environments. However, privacy concerns arise from the extensive surveillance
capabilities of UAVs. To resolve this issue, we propose a novel framework that
integrates HE with advanced neural networks to secure facial data throughout
the inference phase. This method ensures that facial data remains secure with
minimal impact on detection accuracy. Specifically, the proposed system
leverages the Cheon-Kim-Kim-Song (CKKS) scheme to perform computations directly
on encrypted data, optimizing computational efficiency and security.
Furthermore, we develop an effective data encoding method specifically designed
to preprocess the raw facial data into CKKS form in a
Single-Instruction-Multiple-Data (SIMD) manner. Building on this, we design a
secure inference algorithm to compute on ciphertext without needing decryption.
This approach not only protects data privacy during the processing of facial
data but also enhances the efficiency of UAV-based face detection systems.
Experimental results demonstrate that our method effectively balances privacy
protection and detection performance, making it a viable solution for UAV-based
secure face detection. Significantly, our approach (while maintaining data
confidentially with HE encryption) can still achieve an accuracy of less than
1% compared to the benchmark without using encryption.

</details>


### [115] [Differentially Private Federated Low Rank Adaptation Beyond Fixed-Matrix](https://arxiv.org/abs/2507.09990)
*Ming Wen,Jiaqi Zhu,Yuedong Xu,Yipeng Zhou,Dingding Han*

Main category: cs.CR

TL;DR: 本文提出FedASK框架，通过双阶段草图技术实现联邦学习中低秩适配器的高效更新与差分隐私保护，解决了传统方法在隐私与学习效率间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中，即使仅传输本地适配器仍存在隐私泄露风险。传统差分隐私方法在保护隐私时会损害模型微调效果，亟需新方法平衡隐私与性能。

Method: 受随机SVD启发，FedASK采用两阶段草图流程：先聚合隐私保护的本地更新草图，再在服务端重构全局矩阵，实现双适配器的高效差分隐私更新。

Result: 理论证明FedASK具有精确聚合特性与差分隐私保障。实验表明其在多种隐私设置和数据分布下均优于基线方法。

Conclusion: FedASK通过创新性双草图设计，首次实现联邦低秩适配器中双矩阵的隐私保护协同更新，为隐私敏感的LLM联邦微调提供有效解决方案。

Abstract: Large language models (LLMs) typically require fine-tuning for
domain-specific tasks, and LoRA offers a computationally efficient approach by
training low-rank adapters. LoRA is also communication-efficient for federated
LLMs when multiple users collaboratively fine-tune a global LLM model without
sharing their proprietary raw data. However, even the transmission of local
adapters between a server and clients risks serious privacy leakage. Applying
differential privacy (DP) to federated LoRA encounters a dilemma: adding noise
to both adapters amplifies synthetic noise on the model, while fixing one
adapter impairs the learnability of fine-tuning. In this paper, we propose
FedASK (Differentially Private Federated Low Rank Adaptation with Double
Sketching) , a novel federated LoRA framework to enable effective updating of
both low-rank adapters with robust differential privacy. Inspired by randomized
SVD, our key idea is a two-stage sketching pipeline. This pipeline first
aggregates carefully sketched, privacy-preserving local updates, and then
reconstructs the global matrices on the server to facilitate effective updating
of both adapters. We theoretically prove FedASK's differential privacy
guarantee and its exact aggregation property. Comprehensive experiments
demonstrate that FedASK consistently outperforms baseline methods across a
variety of privacy settings and data distributions.

</details>


### [116] [The Man Behind the Sound: Demystifying Audio Private Attribute Profiling via Multimodal Large Language Model Agents](https://arxiv.org/abs/2507.10016)
*Lixu Wang,Kaixiang Yao,Xinfeng Li,Dong Yang,Haoyang Li,Xiaofeng Wang,Wei Dong*

Main category: cs.CR

TL;DR: 研究发现多模态大语言模型(MLLMs)存在通过音频推断敏感个人属性的新型隐私风险，提出AP^2音频基准数据集和Gifts混合多智能体框架以增强推断能力，并探讨防御策略。


<details>
  <summary>Details</summary>
Motivation: 音频数据因其隐蔽采集特性和独特声学特征（如音调）可能被用于更精细的个人属性推断，但现有研究缺乏标注数据集且MLLMs直接推断能力有限。

Method: 构建AP^2标注数据集；提出Gifts框架，结合音频语言模型(ALMs)和LLMs优势，通过LLM引导ALM推断并整合结果，解决ALMs长上下文幻觉问题。

Result: Gifts在敏感属性推断上显著优于基线方法；验证了基于MLLMs的音频隐私攻击可行性，需加强防御措施。

Conclusion: 研究揭示了音频隐私分析风险，提供数据集和框架支持未来研究，强调开发鲁棒防御机制的必要性。

Abstract: Our research uncovers a novel privacy risk associated with multimodal large
language models (MLLMs): the ability to infer sensitive personal attributes
from audio data -- a technique we term audio private attribute profiling. This
capability poses a significant threat, as audio can be covertly captured
without direct interaction or visibility. Moreover, compared to images and
text, audio carries unique characteristics, such as tone and pitch, which can
be exploited for more detailed profiling. However, two key challenges exist in
understanding MLLM-employed private attribute profiling from audio: (1) the
lack of audio benchmark datasets with sensitive attribute annotations and (2)
the limited ability of current MLLMs to infer such attributes directly from
audio. To address these challenges, we introduce AP^2, an audio benchmark
dataset that consists of two subsets collected and composed from real-world
data, and both are annotated with sensitive attribute labels. Additionally, we
propose Gifts, a hybrid multi-agent framework that leverages the complementary
strengths of audio-language models (ALMs) and large language models (LLMs) to
enhance inference capabilities. Gifts employs an LLM to guide the ALM in
inferring sensitive attributes, then forensically analyzes and consolidates the
ALM's inferences, overcoming severe hallucinations of existing ALMs in
generating long-context responses. Our evaluations demonstrate that Gifts
significantly outperforms baseline approaches in inferring sensitive
attributes. Finally, we investigate model-level and data-level defense
strategies to mitigate the risks of audio private attribute profiling. Our work
validates the feasibility of audio-based privacy attacks using MLLMs,
highlighting the need for robust defenses, and provides a dataset and framework
to facilitate future research.

</details>


### [117] [HASSLE: A Self-Supervised Learning Enhanced Hijacking Attack on Vertical Federated Learning](https://arxiv.org/abs/2507.10162)
*Weiyang He,Chip-Hong Chang*

Main category: cs.CR

TL;DR: 本文提出HASSLE攻击框架，通过梯度方向标签推断与自监督增强的对抗嵌入生成，实现对垂直联邦学习系统的高效攻击，攻击成功率高达99%，并评估了8种防御措施的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有垂直联邦学习(VFL)的隐私攻击存在标签推断精度低与后门注入条件次优的局限，需开发更严苛的安全评估方法以揭示系统脆弱性。

Method: HASSLE结合基于梯度方向的标签推断模块（仅需单目标标签样本）与自监督学习增强的对抗嵌入生成算法，实现高精度样本识别与攻击注入。

Result: 在两方场景下，HASSLE在4个数据集（含图像与表格数据）上攻击成功率超99%，CIFAR-100达85%；对8种防御的评估证实其显著威胁。

Conclusion: 该研究不仅揭示了VFL系统的新型安全风险，同时为构建可信赖的联邦学习体系提供了防御设计新视角。

Abstract: Vertical Federated Learning (VFL) enables an orchestrating active party to
perform a machine learning task by cooperating with passive parties that
provide additional task-related features for the same training data entities.
While prior research has leveraged the privacy vulnerability of VFL to
compromise its integrity through a combination of label inference and backdoor
attacks, their effectiveness is constrained by the low label inference
precision and suboptimal backdoor injection conditions. To facilitate a more
rigorous security evaluation on VFL without these limitations, we propose
HASSLE, a hijacking attack framework composed of a gradient-direction-based
label inference module and an adversarial embedding generation algorithm
enhanced by self-supervised learning. HASSLE accurately identifies private
samples associated with a targeted label using only a single known instance of
that label. In the two-party scenario, it demonstrates strong performance with
an attack success rate (ASR) of over 99% across four datasets, including both
image and tabular modalities, and achieves 85% ASR on the more complex
CIFAR-100 dataset. Evaluation of HASSLE against 8 potential defenses further
highlights its significant threat while providing new insights into building a
trustworthy VFL system.

</details>


### [118] [DNS Tunneling: Threat Landscape and Improved Detection Solutions](https://arxiv.org/abs/2507.10267)
*Novruz Amirov,Baran Isik,Bilal Ihsan Tuncer,Serif Bahtiyar*

Main category: cs.CR

TL;DR: 提出一种基于机器学习的新型DNS隧道检测方法，能有效识别隐蔽通信。


<details>
  <summary>Details</summary>
Motivation: DNS隧道可将恶意行为隐藏在看似正常的流量中，传统基于规则或特征匹配的方法检测效果不佳。

Method: 结合机器学习算法，通过提取DNS流量特征进行分析。

Result: 实验表明该方法能准确检测DNS隧道。

Conclusion: 该机器学习方案是DNS隧道检测的有效解决方案。

Abstract: Detecting Domain Name System (DNS) tunneling is a significant challenge in
security due to its capacity to hide harmful actions within DNS traffic that
appears to be normal and legitimate. Traditional detection methods are based on
rule-based approaches or signature matching methods that are often insufficient
to accurately identify such covert communication channels. This research is
about effectively detecting DNS tunneling. We propose a novel approach to
detect DNS tunneling with machine learning algorithms. We combine machine
learning algorithms to analyze the traffic by using features extracted from DNS
traffic. Analyses results show that the proposed approach is a good candidate
to detect DNS tunneling accurately.

</details>


### [119] [Logic layer Prompt Control Injection (LPCI): A Novel Security Vulnerability Class in Agentic Systems](https://arxiv.org/abs/2507.10457)
*Hammad Atta,Ken Huang,Manish Bhatt,Kamal Ahmed,Muhammad Aziz Ul Haq,Yasir Mehmood*

Main category: cs.CR

TL;DR: 论文提出了一种新型安全漏洞LPCI，通过内存、向量存储或工具输出嵌入编码、延迟和条件触发的攻击载荷，绕过传统输入过滤，在大型语言模型企业集成中引发跨会话未授权行为。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)与企业系统集成时，逻辑执行层和持久化内存环境存在新型隐蔽安全漏洞，传统防御机制难以检测。

Method: 提出逻辑层提示控制注入(LPCI)攻击方法，将编码化、延迟触发和条件触发的恶意载荷植入内存/向量数据库/工具输出流。

Result: 实验证明LPCI可绕过常规输入过滤系统，实现跨会话的持久化攻击，触发模型未授权行为。

Conclusion: 该研究揭示了LLM系统集成中逻辑层的新型威胁范式，需开发针对性防御机制应对记忆化攻击向量。

Abstract: The integration of large language models (LLMs) into enterprise systems has
created a new class of covert security vulnerabilities, particularly within
logic-execution layers and persistent-memory contexts. In this paper, we
introduce Logic-Layer Prompt Control Injection (LPCI), a novel attack category
in which encoded, delayed, and conditionally triggered payloads are embedded in
memory, vector stores, or tool outputs. These payloads can bypass conventional
input filters and trigger unauthorised behaviour across sessions.

</details>


### [120] [SynthGuard: Redefining Synthetic Data Generation with a Scalable and Privacy-Preserving Workflow Framework](https://arxiv.org/abs/2507.10489)
*Eduardo Brito,Mahmoud Shoush,Kristian Tamm,Paula Etti,Liina Kamm*

Main category: cs.CR

TL;DR: SynthGuard框架通过模块化、隐私保护的工作流程，解决了合成数据生成（SDG）中的数据主权和合规性问题，确保安全、可审计且可复现的执行。


<details>
  <summary>Details</summary>
Motivation: 随着医疗、金融和执法等领域对数据驱动应用的依赖增加，需要安全、隐私保护且可扩展的数据生成与共享机制。现有SDG方法常依赖集中式处理，引发数据主权和合规性担忧。

Method: 提出SynthGuard框架，支持模块化和隐私保护的工作流程，使数据所有者能控制SDG流程，确保跨环境的安全、可审计执行，并通过领域专家迭代开发验证。

Result: SynthGuard在实际用例中验证了其平衡安全性、隐私与可扩展性的能力，有效执行SDG工作流并整合隐私与效用评估。

Conclusion: SynthGuard通过满足数据主权和监管合规要求，解决了领域特定需求与可扩展SDG的复杂性问题，为安全数据生成提供了可行方案。

Abstract: The growing reliance on data-driven applications in sectors such as
healthcare, finance, and law enforcement underscores the need for secure,
privacy-preserving, and scalable mechanisms for data generation and sharing.
Synthetic data generation (SDG) has emerged as a promising approach but often
relies on centralized or external processing, raising concerns about data
sovereignty, domain ownership, and compliance with evolving regulatory
standards. To overcome these issues, we introduce SynthGuard, a framework
designed to ensure computational governance by enabling data owners to maintain
control over SDG workflows. SynthGuard supports modular and privacy-preserving
workflows, ensuring secure, auditable, and reproducible execution across
diverse environments. In this paper, we demonstrate how SynthGuard addresses
the complexities at the intersection of domain-specific needs and scalable SDG
by aligning with requirements for data sovereignty and regulatory compliance.
Developed iteratively with domain expert input, SynthGuard has been validated
through real-world use cases, demonstrating its ability to balance security,
privacy, and scalability while ensuring compliance. The evaluation confirms its
effectiveness in implementing and executing SDG workflows and integrating
privacy and utility assessments across various computational environments.

</details>


### [121] [BURN: Backdoor Unlearning via Adversarial Boundary Analysis](https://arxiv.org/abs/2507.10491)
*Yanghao Su,Jie Zhang,Yiming Li,Tianwei Zhang,Qing Guo,Weiming Zhang,Nenghai Yu,Nils Lukas,Wenbo Zhou*

Main category: cs.CR

TL;DR: 本文提出BURN框架，通过对抗边界分析实现后门遗忘，有效消除触发器与目标标签的虚假关联，同时保持模型原有性能。


<details>
  <summary>Details</summary>
Motivation: 现有后门遗忘方法仅关注恢复触发器模式，未能修正毒样本的语义标签，无法彻底消除触发器与目标标签的虚假关联。

Method: BURN框架分两阶段：1) 利用对抗边界距离异常检测毒样本并恢复其正确标签；2) 通过反馈机制追踪预测差异，指导数据精炼和模型净化。

Result: 在多种数据集、架构和七类后门攻击下的实验表明，BURN能有效移除后门威胁且保持模型原始准确率。

Conclusion: 基于对抗边界分析的BURN框架突破了现有后门遗忘的局限性，为防御后门攻击提供了新思路。

Abstract: Backdoor unlearning aims to remove backdoor-related information while
preserving the model's original functionality. However, existing unlearning
methods mainly focus on recovering trigger patterns but fail to restore the
correct semantic labels of poison samples. This limitation prevents them from
fully eliminating the false correlation between the trigger pattern and the
target label. To address this, we leverage boundary adversarial attack
techniques, revealing two key observations. First, poison samples exhibit
significantly greater distances from decision boundaries compared to clean
samples, indicating they require larger adversarial perturbations to change
their predictions. Second, while adversarial predicted labels for clean samples
are uniformly distributed, those for poison samples tend to revert to their
original correct labels. Moreover, the features of poison samples restore to
closely resemble those of corresponding clean samples after adding adversarial
perturbations. Building upon these insights, we propose Backdoor Unlearning via
adversaRial bouNdary analysis (BURN), a novel defense framework that integrates
false correlation decoupling, progressive data refinement, and model
purification. In the first phase, BURN employs adversarial boundary analysis to
detect poisoned samples based on their abnormal adversarial boundary distances,
then restores their correct semantic labels for fine-tuning. In the second
phase, it employs a feedback mechanism that tracks prediction discrepancies
between the original backdoored model and progressively sanitized models,
guiding both dataset refinement and model purification. Extensive evaluations
across multiple datasets, architectures, and seven diverse backdoor attack
types confirm that BURN effectively removes backdoor threats while maintaining
the model's original performance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [122] [Think Clearly: Improving Reasoning via Redundant Token Pruning](https://arxiv.org/abs/2507.08806)
*Daewon Choi,Jimin Lee,Jihoon Tack,Woomin Song,Saket Dingliwal,Sai Muralidhar Jayanthi,Bhavana Ganesh,Jinwoo Shin,Aram Galstyan,Sravan Babu Bodapati*

Main category: cs.AI

TL;DR: 本文提出一种通过识别并剪枝冗余推理步骤来提升大语言模型长链推理性能的方法，利用注意力机制检测冗余并在数学竞赛等任务中显著提升准确率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的长链推理存在注意力分散和冗余问题，尤其在错误答案中表现更明显，这影响了推理效率和准确性。

Method: 通过向中间推理步骤插入特殊指令标记，测量token级注意力分数以识别冗余，采用结构感知剪枝优先移除低贡献推理块，最后恢复原始推理生成。

Result: 该方法在AIME、AMC等数学竞赛基准上显著提升准确率，且无需额外训练即可有效减少推理冗余。

Conclusion: 系统性剔除冗余推理步骤能显著提升模型性能，尤其在复杂数学问题上，验证了注意力机制对优化长链推理的关键作用。

Abstract: Recent large language models have shown promising capabilities in long-form
reasoning, following structured chains of thought before arriving at a final
answer. However, we observe that these reasoning paths tend to include
substantial redundancy; analyzing attention patterns reveals that attention
scores are widely scattered, particularly incorrect answers exhibit greater
attention sparsity. In this paper, we demonstrate that deliberately removing
this redundancy in the reasoning process significantly improves performance
through clear thinking, i.e., removing distraction. Specifically, we
systematically identify reasoning redundancy by measuring token-level attention
scores to a special end-of-thinking token, which is appended to an explicit
instruction inserted to conclude each intermediate reasoning step. Furthermore,
we propose structure-aware pruning that prioritizes removing tokens in
low-contributing reasoning chunks over individual tokens. After evicting
redundant tokens, we remove the injected end-of-thinking instruction, then
resume the reasoning generation. We demonstrate that our method significantly
improves overall accuracy across reasoning-intensive benchmarks without any
training involved. In particular, our method shows strong performance on
challenging mathematical competition benchmarks such as AIME and AMC, where
reasoning redundancy is more prevalent.

</details>


### [123] [A New Approach for Multicriteria Assessment in the Ranking of Alternatives Using Cardinal and Ordinal Data](https://arxiv.org/abs/2507.08875)
*Fuh-Hwa Franklin Liu,Su-Chuan Shih*

Main category: cs.AI

TL;DR: 本文提出了一种结合两种虚拟间隙分析（VGA）模型的新型多标准评估（MCA）方法，旨在提高评估的效率和公平性，并通过数值示例验证了其准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 现有的多标准评估方法（如DEA、SFA和MCDM）依赖于假设和主观判断，且常采用同质性假设，影响了评估的全面性和可靠性。因此，需要一种更全面、适应性强的解决方案。

Method: 提出了一种基于线性规划的虚拟间隙分析（VGA）框架，结合两种VGA模型，以同时处理定量和定性标准，从而改进多标准评估。

Result: 通过两个数值示例验证了所提方法的准确性和透明度，表明其在效率和公平性方面具有显著优势。

Conclusion: 该方法为多标准评估提供了强大且自适应的解决方案，有望推动自动化决策系统和决策支持系统的进一步发展。

Abstract: Modern methods for multi-criteria assessment (MCA), such as Data Envelopment
Analysis (DEA), Stochastic Frontier Analysis (SFA), and Multiple Criteria
Decision-Making (MCDM), are utilized to appraise a collection of
Decision-Making Units (DMUs), also known as alternatives, based on several
criteria. These methodologies inherently rely on assumptions and can be
influenced by subjective judgment to effectively tackle the complex evaluation
challenges in various fields. In real-world scenarios, it is essential to
incorporate both quantitative and qualitative criteria as they consist of
cardinal and ordinal data. Despite the inherent variability in the criterion
values of different alternatives, the homogeneity assumption is often employed,
significantly affecting evaluations. To tackle these challenges and determine
the most appropriate alternative, we propose a novel MCA approach that combines
two Virtual Gap Analysis (VGA) models. The VGA framework, rooted in linear
programming, is pivotal in the MCA methodology. This approach improves
efficiency and fairness, ensuring that evaluations are both comprehensive and
dependable, thus offering a strong and adaptive solution. Two comprehensive
numerical examples demonstrate the accuracy and transparency of our proposed
method. The goal is to encourage continued advancement and stimulate progress
in automated decision systems and decision support systems.

</details>


### [124] [Multi-Actor Generative Artificial Intelligence as a Game Engine](https://arxiv.org/abs/2507.08892)
*Alexander Sasha Vezhnevets,Jayd Matyas,Logan Cross,Davide Paglieri,Minsuk Chang,William A. Cunningham,Simon Osindero,William S. Isaac,Joel Z. Leibo*

Main category: cs.AI

TL;DR: 本文提出了一种基于桌游角色扮演游戏（TTRPG）中游戏管理员（GM）概念的灵活场景定义框架，采用实体-组件架构模式，支持生成式AI在多参与者环境中的多样化应用。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在多参与者环境中有广泛用途，如社会科学建模、交互叙事和AI评估，但需要灵活的框架来支持不同用例（模拟主义、戏剧主义和评估主义）。

Method: 借鉴TTRPG中GM的角色，采用实体-组件架构模式，将GM设计为可配置的实体，由组件构成，实现工程师处理底层细节、设计师组合配置组件的分离。

Result: 通过Concordia库的持续演进，展示了该框架如何支持用户有效配置符合特定目标的场景，实现快速迭代、模块化和可扩展性。

Conclusion: 实体-组件架构和GM概念的结合为生成式AI在多参与者环境中的应用提供了灵活、可扩展的解决方案，支持多样化的用例需求。

Abstract: Generative AI can be used in multi-actor environments with purposes ranging
from social science modeling to interactive narrative and AI evaluation.
Supporting this diversity of use cases -- which we classify as Simulationist,
Dramatist, and Evaluationist -- demands a flexible scenario definition
framework. We argue here that a good approach is to take inspiration from
tabletop role-playing games (TTRPGs), where a Game Master (GM) is responsible
for the environment and generates all parts of the story not directly
determined by the voluntary actions of player characters. We argue that the
Entity-Component architectural pattern is useful here. In such a system, the GM
is not a hardcoded computer game but is itself a configurable entity, composed
of components just like any other actor. By design, the approach allows for a
separation between the underlying implementation details handled by an
engineer, the creation of reusable components, and their composition and
configuration managed by a designer who constructs entities from the
components. This separation of concerns is instrumental for achieving rapid
iteration, maintaining modularity, and ultimately to ensure scalability. We
describe the ongoing evolution of the Concordia library in terms of this
philosophy, demonstrating how it allows users to effectively configure
scenarios that align with their specific goals.

</details>


### [125] [BioAnalyst: A Foundation Model for Biodiversity](https://arxiv.org/abs/2507.09080)
*Athanasios Trantas,Martino Mensio,Stylianos Stasinos,Sebastian Gribincea,Taimur Khan,Damian Podareanu,Aliene van der Veen*

Main category: cs.AI

TL;DR: 本文介绍了BioAnalyst，首个专为生物多样性分析和保护规划设计的基础模型，利用AI技术提升生态预测准确性，尤其在数据稀缺场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 生物多样性加速丧失对生态研究和保护策略构成严峻挑战，亟需综合监测与预测工具。AI基础模型在科学领域展现出巨大潜力，为生物多样性保护提供了新思路。

Method: BioAnalyst采用基于Transformer的架构，预训练数据涵盖物种分布记录、遥感指标、气候及环境变量等多模态数据集，可微调适配物种分布建模、栖息地评估等下游任务。

Result: 模型在两个下游用例中验证了其普适性，尤其在数据稀缺情况下超越现有方法，为生态预测设立了新的准确度基准。

Conclusion: 通过开源BioAnalyst及其工作流，研究者旨在推动生物多样性建模的协作研究，推进AI技术解决紧迫生态问题。

Abstract: The accelerating loss of biodiversity presents critical challenges for
ecological research and conservation strategies. The preservation of
biodiversity is paramount for maintaining ecological balance and ensuring the
sustainability of ecosystems. However, biodiversity faces numerous threats,
including habitat loss, climate change, and the proliferation of invasive
species. Addressing these and other ecology-related challenges, both at local
and global scales, requires comprehensive monitoring, predictive and
conservation planning capabilities. Artificial Intelligence (AI) Foundation
Models (FMs) have gained significant momentum in numerous scientific domains by
leveraging vast datasets to learn general-purpose representations adaptable to
various downstream tasks. This paradigm holds immense promise for biodiversity
conservation. In response, we introduce BioAnalyst, the first Foundation Model
tailored for biodiversity analysis and conservation planning. BioAnalyst
employs a transformer-based architecture, pre-trained on extensive multi-modal
datasets encompassing species occurrence records, remote sensing indicators,
climate and environmental variables. BioAnalyst is designed for adaptability,
allowing for fine-tuning of a range of downstream tasks, such as species
distribution modelling, habitat suitability assessments, invasive species
detection, and population trend forecasting. We evaluate the model's
performance on two downstream use cases, demonstrating its generalisability
compared to existing methods, particularly in data-scarce scenarios for two
distinct use-cases, establishing a new accuracy baseline for ecological
forecasting. By openly releasing BioAnalyst and its fine-tuning workflows to
the scientific community, we aim to foster collaborative efforts in
biodiversity modelling and advance AI-driven solutions to pressing ecological
challenges.

</details>


### [126] [Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity](https://arxiv.org/abs/2507.09089)
*Joel Becker,Nate Rush,Elizabeth Barnes,David Rein*

Main category: cs.AI

TL;DR: 一项随机对照试验发现，2025年前沿AI工具（如Cursor Pro和Claude 3.5/3.7 Sonnet）反而使资深开源开发者的任务完成时间延长19%，与开发者预期（缩短20%）及经济学/机器学习专家预测（缩短38-39%）相矛盾。


<details>
  <summary>Details</summary>
Motivation: 尽管AI工具被广泛采用，但其对实际软件开发的影响仍缺乏深入研究。本研究旨在量化2025年前沿AI工具对有经验开源开发者生产力的真实影响。

Method: 采用随机对照试验设计，16名具有中等AI经验的开发者（平均5年项目经验）完成246个任务，随机分配是否允许使用2025年初的AI工具（主要使用Cursor Pro代码编辑器和Claude 3.5/3.7 Sonnet）。

Result: 与预期相反：开发者预估AI可缩短20%时间，但实际测量显示任务完成时间增加19%。该结果与经济学（预测缩短39%）和机器学习专家（预测缩短38%）的预测均相悖。通过20个维度的环境因素分析，排除实验设计主导该现象的可能性。

Conclusion: 当前AI工具在成熟开源项目中可能产生反生产力效应，这种减速现象具有稳健性，暗示AI工具集成到专业工作流时可能存在未被充分认识的适应成本。

Abstract: Despite widespread adoption, the impact of AI tools on software development
in the wild remains understudied. We conduct a randomized controlled trial
(RCT) to understand how AI tools at the February-June 2025 frontier affect the
productivity of experienced open-source developers. 16 developers with moderate
AI experience complete 246 tasks in mature projects on which they have an
average of 5 years of prior experience. Each task is randomly assigned to allow
or disallow usage of early 2025 AI tools. When AI tools are allowed, developers
primarily use Cursor Pro, a popular code editor, and Claude 3.5/3.7 Sonnet.
Before starting tasks, developers forecast that allowing AI will reduce
completion time by 24%. After completing the study, developers estimate that
allowing AI reduced completion time by 20%. Surprisingly, we find that allowing
AI actually increases completion time by 19%--AI tooling slowed developers
down. This slowdown also contradicts predictions from experts in economics (39%
shorter) and ML (38% shorter). To understand this result, we collect and
evaluate evidence for 20 properties of our setting that a priori could
contribute to the observed slowdown effect--for example, the size and quality
standards of projects, or prior developer experience with AI tooling. Although
the influence of experimental artifacts cannot be entirely ruled out, the
robustness of the slowdown effect across our analyses suggests it is unlikely
to primarily be a function of our experimental design.

</details>


### [127] [Hide-and-Shill: A Reinforcement Learning Framework for Market Manipulation Detection in Symphony-a Decentralized Multi-Agent System](https://arxiv.org/abs/2507.09179)
*Ronghua Shi,Yiou Liu,Xinyu Ying,Yang Tan,Yuchun Feng,Lynn Ai,Bill Shi,Xuhui Wang,Zhuang Liu*

Main category: cs.AI

TL;DR: 本文提出了一种基于多智能体强化学习（MARL）的去中心化市场操纵检测框架Symphony，通过对抗博弈建模操纵者与检测器的动态交互，整合语义特征、社交图谱和链上数据，实现了无需中心化监管的实时DeFi市场监控。


<details>
  <summary>Details</summary>
Motivation: 去中心化金融（DeFi）的无许可特性催生了前所未有的市场操纵行为（如拉盘砸盘），传统中心化监管失效，亟需新型去中心化检测范式。

Method: 1) 提出群体相对策略优化（GRPO）解决稀疏奖励与部分可观测问题；2) 基于理性预期理论设计奖励函数区分价格发现与操纵噪声；3) 构建多模态智能体管道，融合LLM语义特征、社交图谱信号与链上数据。

Result: 在10万真实对话数据训练后，Hide-and-Shill系统在对抗模拟中取得最优检测准确率与因果归因性能，检测延迟代币价格反应模式的F1值达92%。

Conclusion: 该研究开创了多智能体系统与金融监管的跨学科范式，通过Symphony架构实现对抗协同进化，为开放DeFi生态提供可验证的分布式市场情报基础设施。所有代码已开源。

Abstract: Decentralized finance (DeFi) has introduced a new era of permissionless
financial innovation but also led to unprecedented market manipulation. Without
centralized oversight, malicious actors coordinate shilling campaigns and
pump-and-dump schemes across various platforms. We propose a Multi-Agent
Reinforcement Learning (MARL) framework for decentralized manipulation
detection, modeling the interaction between manipulators and detectors as a
dynamic adversarial game. This framework identifies suspicious patterns using
delayed token price reactions as financial indicators.Our method introduces
three innovations: (1) Group Relative Policy Optimization (GRPO) to enhance
learning stability in sparse-reward and partially observable settings; (2) a
theory-based reward function inspired by rational expectations and information
asymmetry, differentiating price discovery from manipulation noise; and (3) a
multi-modal agent pipeline that integrates LLM-based semantic features, social
graph signals, and on-chain market data for informed decision-making.The
framework is integrated within the Symphony system, a decentralized multi-agent
architecture enabling peer-to-peer agent execution and trust-aware learning
through distributed logs, supporting chain-verifiable evaluation. Symphony
promotes adversarial co-evolution among strategic actors and maintains robust
manipulation detection without centralized oracles, enabling real-time
surveillance across global DeFi ecosystems.Trained on 100,000 real-world
discourse episodes and validated in adversarial simulations, Hide-and-Shill
achieves top performance in detection accuracy and causal attribution. This
work bridges multi-agent systems with financial surveillance, advancing a new
paradigm for decentralized market intelligence. All resources are available at
the Hide-and-Shill GitHub repository to promote open research and
reproducibility.

</details>


### [128] [When Developer Aid Becomes Security Debt: A Systematic Analysis of Insecure Behaviors in LLM Coding Agents](https://arxiv.org/abs/2507.09329)
*Matous Kozak,Roshanak Zilouchian Moghaddam,Siva Sivaraman*

Main category: cs.AI

TL;DR: 首个基于LLM的编程代理系统安全评估显示，21%的操作存在安全隐患，GPT-4.1以96.8%的缓解成功率表现最佳。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM编程代理能加速软件开发，但其安全影响尚未明确，研究旨在系统评估其安全隐患。

Method: 分析了5个前沿模型（GPT-4o/GPT-4.1/Claude变体）在93个真实软件任务中的12,000余项操作，开发了高精度漏洞检测系统。

Result: 发现21%的操作轨迹含安全隐患，信息泄露（CWE-200）最常见；不同模型安全表现差异显著，GPT-4.1安全缓解成功率高达96.8%。

Conclusion: 研究建立了首个编程代理安全评估框架，强调下一代LLM编程代理需具备安全感知设计。

Abstract: LLM-based coding agents are rapidly being deployed in software development,
yet their security implications remain poorly understood. These agents, while
capable of accelerating software development, may inadvertently introduce
insecure practices. We conducted the first systematic security evaluation of
autonomous coding agents, analyzing over 12,000 actions across five
state-of-the-art models (GPT-4o, GPT-4.1, Claude variants) on 93 real-world
software setup tasks. Our findings reveal significant security concerns: 21% of
agent trajectories contained insecure actions, with models showing substantial
variation in security behavior. We developed a high-precision detection system
that identified four major vulnerability categories, with information exposure
(CWE-200) being the most prevalent one. We also evaluated mitigation strategies
including feedback mechanisms and security reminders with various effectiveness
between models. GPT-4.1 demonstrated exceptional security awareness with 96.8%
mitigation success. Our work provides the first comprehensive framework for
evaluating coding agent security and highlights the need for security-aware
design of next generation LLM-based coding agents.

</details>


### [129] [A Taxonomy of Omnicidal Futures Involving Artificial Intelligence](https://arxiv.org/abs/2507.09369)
*Andrew Critch,Jacob Tsimerman*

Main category: cs.AI

TL;DR: 本文提出了一种关于AI可能导致人类灭绝的潜在事件分类及案例，旨在通过公开讨论推动预防措施。


<details>
  <summary>Details</summary>
Motivation: 通过公开讨论AI可能带来的灭绝性风险，以期获得公众支持并推动预防措施的制定。

Method: 提出分类法并列举AI可能导致人类灭绝的潜在场景案例。

Result: 展示了一系列并非不可避免但需警惕的AI相关灭绝性风险场景。

Conclusion: 公开讨论AI的潜在灭绝性风险有助于推动社会采取预防措施，降低灾难性风险。

Abstract: This report presents a taxonomy and examples of potential omnicidal events
resulting from AI: scenarios where all or almost all humans are killed. These
events are not presented as inevitable, but as possibilities that we can work
to avoid. Insofar as large institutions require a degree of public support in
order to take certain actions, we hope that by presenting these possibilities
in public, we can help to support preventive measures against catastrophic
risks from AI.

</details>


### [130] [EduFlow: Advancing MLLMs' Problem-Solving Proficiency through Multi-Stage, Multi-Perspective Critique](https://arxiv.org/abs/2507.09374)
*Chenglin Zhu,Tao Zhang,Chong Li,Mingan Lin,Zenan Zhou,Jian Xie*

Main category: cs.AI

TL;DR: 本文提出EduFlow框架，首个覆盖教育科学推理全流程的端到端解决方案，通过EduPRM奖励模型和EduMCTS搜索框架提升多模态大模型在科学任务中的多步推理能力与可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型(MLLMs)在需要多步可解释推理的科学任务中表现不佳，存在科学推理模式不足、多步推断缺乏全局连贯性、缺少反思性自我修正等问题，导致其在结构化科学场景中不可靠。

Method: 1) 核心组件EduPRM奖励模型通过课程学习整合三种监督源：MCTS引导的轨迹、错误注入的批判和师生对话\n2) 提出EduMCTS领域自适应搜索框架，引入自反思机制等教育专用推理动作\n3) 结合自洽性与拒绝采样构建EduMCTS-160K大规模教育推理轨迹数据集

Result: 实验表明EduFlow显著提升了推理的一致性与连贯性，代码、数据和模型将开源发布。

Conclusion: 该研究通过流程感知的奖励建模与领域适应的搜索策略，为教育科学推理提供了首个端到端解决方案，实现了动态多阶段问题求解与推理过程中的迭代优化。

Abstract: Multimodal large language models (MLLMs) still perform poorly on scientific
tasks, particularly those requiring multi-step and interpretable reasoning.
Their limitations include insufficient scientific reasoning patterns, lack of
global coherence in multi-step inference, and the absence of reflective
self-correction, making them unreliable in structured scientific contexts. We
introduce EduFlow, the first end-to-end framework that covers the full pipeline
of educational scientific reasoning, including data selection, MCTS-based
trajectory construction, model training, and output optimization. At its core
is EduPRM, a process-aware reward model that critiques reasoning steps with
tags and justifications. EduPRM is trained via curriculum learning on three
complementary supervision sources: MCTS-guided trajectories, error-injected
critiques, and teacher-student dialogues, enabling dynamic adaptation to
multi-stage problem solving and iterative refinement during inference. We
further propose EduMCTS, a domain-adapted search framework that introduces
bootstrapping actions specifically designed for educational reasoning, such as
a self-reflection mechanism that promotes reflective error correction. It
further leverages EduPRM's fine-grained feedback to guide the search toward
higher-quality reasoning trajectories. By applying self-consistency and
rejection sampling, we constructed EduMCTS-160K, a large-scale dataset of
educational reasoning trajectories. Extensive experiments demonstrate that
EduFlow enhances reasoning consistency and coherence. Code, data, and models
will be released.

</details>


### [131] [Knowledge Conceptualization Impacts RAG Efficacy](https://arxiv.org/abs/2507.09389)
*Chris Davis Jaldi,Anmol Saini,Elham Ghiasi,O. Divine Eziolise,Cogan Shimizu*

Main category: cs.AI

TL;DR: 本文探讨了可解释性与适应性在AI系统中的重要性，特别是针对大型语言模型（LLMs）和生成式AI，研究了可迁移且可解释的神经符号AI系统设计，重点评估了知识表示对AI代理查询三元组存储的影响。


<details>
  <summary>Details</summary>
Motivation: 可解释性和适应性是前沿及下一代AI系统的基石，尤其是在大型语言模型和生成式AI中。研究旨在结合这两种特性，设计可迁移且可解释的神经符号AI系统。

Method: 研究聚焦于一类称为"代理检索增强生成"的系统，该系统能主动选择、解释和查询知识源以响应自然语言提示。系统评估了知识表示的结构和复杂性对AI代理（如LLM）查询三元组存储的影响。

Result: 结果表明，不同的知识表示方法对AI代理的查询效果有显著影响，研究详细分析了这些影响及其潜在意义。

Conclusion: 研究强调了知识表示在AI系统中的关键作用，为设计更高效、可解释且适应性强的神经符号AI系统提供了重要见解。

Abstract: Explainability and interpretability are cornerstones of frontier and
next-generation artificial intelligence (AI) systems. This is especially true
in recent systems, such as large language models (LLMs), and more broadly,
generative AI. On the other hand, adaptability to new domains, contexts, or
scenarios is also an important aspect for a successful system. As such, we are
particularly interested in how we can merge these two efforts, that is,
investigating the design of transferable and interpretable neurosymbolic AI
systems. Specifically, we focus on a class of systems referred to as ''Agentic
Retrieval-Augmented Generation'' systems, which actively select, interpret, and
query knowledge sources in response to natural language prompts. In this paper,
we systematically evaluate how different conceptualizations and representations
of knowledge, particularly the structure and complexity, impact an AI agent (in
this case, an LLM) in effectively querying a triplestore. We report our
results, which show that there are impacts from both approaches, and we discuss
their impact and implications.

</details>


### [132] [LLM-Stackelberg Games: Conjectural Reasoning Equilibria and Their Applications to Spearphishing](https://arxiv.org/abs/2507.09407)
*Quanyan Zhu*

Main category: cs.AI

TL;DR: 本文提出了LLM-Stackelberg博弈框架，将大语言模型（LLMs）整合到领导者与追随者的策略互动中，突破了传统Stackelberg博弈的完全信息与理性主体假设。通过定义推理均衡与行为均衡等新概念，该框架能捕捉有限理性、信息不对称及元认知适应等复杂特征，并以钓鱼攻击案例验证了其在网络安全等领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 传统Stackelberg博弈基于完全信息与理性主体假设，难以刻画现实决策中的认知局限与信息不对称。本文旨在通过LLM的推理能力构建更贴近真实决策过程的博弈框架。

Method: 设计LLM-Stackelberg博弈框架：1) 主体通过结构化提示进行推理；2) 利用LLM生成概率化行为；3) 提出推理均衡（内部推理与行为一致）与猜想推理均衡（参数化对手响应模型）。以钓鱼攻击为案例验证框架有效性。

Result: 案例研究表明：1) LLM介导的互动能呈现丰富的认知策略；2) 框架可建模网络安全中的对抗行为；3) 新均衡概念成功捕捉有限理性与动态适应过程。

Conclusion: LLM-Stackelberg博弈为网络安全、错误信息识别等领域的策略决策建模提供了新范式，其分层均衡结构能有效处理现实决策中的认知复杂性与对抗动态。

Abstract: We introduce the framework of LLM-Stackelberg games, a class of sequential
decision-making models that integrate large language models (LLMs) into
strategic interactions between a leader and a follower. Departing from
classical Stackelberg assumptions of complete information and rational agents,
our formulation allows each agent to reason through structured prompts,
generate probabilistic behaviors via LLMs, and adapt their strategies through
internal cognition and belief updates. We define two equilibrium concepts:
reasoning and behavioral equilibrium, which aligns an agent's internal
prompt-based reasoning with observable behavior, and conjectural reasoning
equilibrium, which accounts for epistemic uncertainty through parameterized
models over an opponent's response. These layered constructs capture bounded
rationality, asymmetric information, and meta-cognitive adaptation. We
illustrate the framework through a spearphishing case study, where a sender and
a recipient engage in a deception game using structured reasoning prompts. This
example highlights the cognitive richness and adversarial potential of
LLM-mediated interactions. Our results show that LLM-Stackelberg games provide
a powerful paradigm for modeling decision-making in domains such as
cybersecurity, misinformation, and recommendation systems.

</details>


### [133] [GenAI-based Multi-Agent Reinforcement Learning towards Distributed Agent Intelligence: A Generative-RL Agent Perspective](https://arxiv.org/abs/2507.09495)
*Hang Wang,Junshan Zhang*

Main category: cs.AI

TL;DR: 本文提出从反应式转向生成式AI驱动的多智能体强化学习新范式，通过预测性建模实现前瞻性协作决策，解决传统方法在联合行动空间、非平稳环境和部分可观测性上的根本性挑战。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体强化学习方法面临联合行动空间指数增长、环境非平稳性及部分可观测性三大挑战，现有反应式机制难以应对新场景。需要转向基于生成式AI的主动决策范式。

Method: 将智能体重构为生成模型：通过预测环境演化与其他智能体行为，生成协调行动序列；利用生成式AI的模式识别与合成能力实现战略推理与动态适应。

Result: 该方法理论上能实现：1) 基于预测的主动决策 2) 通过增强通信的无缝协作 3) 对演化场景的动态适应，突破传统反应式框架的局限性。

Conclusion: 生成式强化学习范式将推动分布式智能从个体优化向涌现集体行为演进，在自主系统、机器人及人机协作领域解决传统方法无法处理的协调难题。

Abstract: Multi-agent reinforcement learning faces fundamental challenges that
conventional approaches have failed to overcome: exponentially growing joint
action spaces, non-stationary environments where simultaneous learning creates
moving targets, and partial observability that constrains coordination. Current
methods remain reactive, employing stimulus-response mechanisms that fail when
facing novel scenarios. We argue for a transformative paradigm shift from
reactive to proactive multi-agent intelligence through generative AI-based
reinforcement learning. This position advocates reconceptualizing agents not as
isolated policy optimizers, but as sophisticated generative models capable of
synthesizing complex multi-agent dynamics and making anticipatory decisions
based on predictive understanding of future interactions. Rather than
responding to immediate observations, generative-RL agents can model
environment evolution, predict other agents' behaviors, generate coordinated
action sequences, and engage in strategic reasoning accounting for long-term
dynamics. This approach leverages pattern recognition and generation
capabilities of generative AI to enable proactive decision-making, seamless
coordination through enhanced communication, and dynamic adaptation to evolving
scenarios. We envision this paradigm shift will unlock unprecedented
possibilities for distributed intelligence, moving beyond individual
optimization toward emergent collective behaviors representing genuine
collaborative intelligence. The implications extend across autonomous systems,
robotics, and human-AI collaboration, promising solutions to coordination
challenges intractable under traditional reactive frameworks.

</details>


### [134] [Consistency Trajectory Planning: High-Quality and Efficient Trajectory Optimization for Offline Model-Based Reinforcement Learning](https://arxiv.org/abs/2507.09534)
*Guanquan Wang,Takuya Hiraoka,Yoshimasa Tsuruoka*

Main category: cs.AI

TL;DR: 本文提出了一种名为一致性轨迹规划（CTP）的新型离线模型强化学习方法，利用一致性轨迹模型（CTM）实现高效轨迹优化，显著提升了计算效率与策略质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的规划方法虽性能优异，但因其迭代采样过程导致计算成本高昂，亟需一种高效且低延迟的替代方案。

Method: CTP通过一致性轨迹模型支持快速单步轨迹生成，避免了传统扩散模型的多步去噪过程，同时保持策略质量不显著下降。

Result: 在D4RL基准测试中，CTP在长周期目标导向任务中全面超越现有扩散规划方法，仅用极少的去噪步骤即可实现更高归一化收益，推理速度提升超120倍。

Conclusion: CTP以极低延迟实现高性能离线规划，其效率与实用性的平衡为强化学习部署提供了重要技术突破。

Abstract: This paper introduces Consistency Trajectory Planning (CTP), a novel offline
model-based reinforcement learning method that leverages the recently proposed
Consistency Trajectory Model (CTM) for efficient trajectory optimization. While
prior work applying diffusion models to planning has demonstrated strong
performance, it often suffers from high computational costs due to iterative
sampling procedures. CTP supports fast, single-step trajectory generation
without significant degradation in policy quality. We evaluate CTP on the D4RL
benchmark and show that it consistently outperforms existing diffusion-based
planning methods in long-horizon, goal-conditioned tasks. Notably, CTP achieves
higher normalized returns while using significantly fewer denoising steps. In
particular, CTP achieves comparable performance with over $120\times$ speedup
in inference time, demonstrating its practicality and effectiveness for
high-performance, low-latency offline planning.

</details>


### [135] [Learning to Control Dynamical Agents via Spiking Neural Networks and Metropolis-Hastings Sampling](https://arxiv.org/abs/2507.09540)
*Ali Safa,Farida Mohsen,Ali Al-Zawqari*

Main category: cs.AI

TL;DR: 本文提出了一种基于Metropolis-Hastings采样的新型框架，首次实现了无需梯度方法的脉冲神经网络强化学习训练，在控制任务中表现优于传统深度Q学习和现有SNN方法。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络(SNN)虽具有生物启发性和高能效优势，但其不可微的脉冲特性导致强化学习训练困难，亟需突破传统反向传播的限制。

Method: 采用Metropolis-Hastings贝叶斯采样技术，通过概率性接受参数更新提案，直接依据累积奖励信号进行优化，兼容神经形态硬件平台。

Result: 在AcroBot和CartPole控制基准测试中，该方法在累积奖励最大化、网络资源消耗和训练回合数方面均超越深度Q学习及现有SNN强化学习方法。

Conclusion: 该框架为脉冲神经网络强化学习提供了首个非梯度训练方案，证实了贝叶斯方法在神经形态控制任务中的有效性，开辟了新型高效训练范式。

Abstract: Spiking Neural Networks (SNNs) offer biologically inspired, energy-efficient
alternatives to traditional Deep Neural Networks (DNNs) for real-time control
systems. However, their training presents several challenges, particularly for
reinforcement learning (RL) tasks, due to the non-differentiable nature of
spike-based communication. In this work, we introduce what is, to our
knowledge, the first framework that employs Metropolis-Hastings (MH) sampling,
a Bayesian inference technique, to train SNNs for dynamical agent control in RL
environments without relying on gradient-based methods. Our approach
iteratively proposes and probabilistically accepts network parameter updates
based on accumulated reward signals, effectively circumventing the limitations
of backpropagation while enabling direct optimization on neuromorphic
platforms. We evaluated this framework on two standard control benchmarks:
AcroBot and CartPole. The results demonstrate that our MH-based approach
outperforms conventional Deep Q-Learning (DQL) baselines and prior SNN-based RL
approaches in terms of maximizing the accumulated reward while minimizing
network resources and training episodes.

</details>


### [136] [eSapiens: A Platform for Secure and Auditable Retrieval-Augmented Generation](https://arxiv.org/abs/2507.09588)
*Isaac Shi,Zeyuan Li,Fan Liu,Wenli Wang,Lewei He,Yang Yang,Tianyu Shi*

Main category: cs.AI

TL;DR: eSapiens是一个面向企业的AIaaS平台，整合专有数据、工作流程和主流LLM，提供数据安全与自动化洞察，实验显示其在法律和金融领域的高效性。


<details>
  <summary>Details</summary>
Motivation: 企业需要安全可控的AI解决方案以保留知识资产并自动化重复任务，eSapiens旨在满足这一需求。

Method: 平台结合结构化文档处理、混合向量检索和无代码编排（LangChain），支持多款LLM，核心THOR代理可处理SQL查询并生成数据库洞察。通过法律语料检索实验（512令牌分块）和TRACe指标生成质量测试验证性能。

Result: 法律检索Top-3准确率达91.3%；五款LLM中，eSapiens生成内容的事实一致性最高提升23%。

Conclusion: eSapiens为法律、金融等高要求领域提供了可信、可审计的AI工作流解决方案，实验数据验证其有效性。

Abstract: We present eSapiens, an AI-as-a-Service (AIaaS) platform engineered around a
business-oriented trifecta: proprietary data, operational workflows, and any
major agnostic Large Language Model (LLM). eSapiens gives businesses full
control over their AI assets, keeping everything in-house for AI knowledge
retention and data security. eSapiens AI Agents (Sapiens) empower your team by
providing valuable insights and automating repetitive tasks, enabling them to
focus on high-impact work and drive better business outcomes.
  The system integrates structured document ingestion, hybrid vector retrieval,
and no-code orchestration via LangChain, and supports top LLMs including
OpenAI, Claude, Gemini, and DeepSeek. A key component is the THOR Agent, which
handles structured SQL-style queries and generates actionable insights over
enterprise databases.
  To evaluate the system, we conduct two experiments. First, a retrieval
benchmark on legal corpora reveals that a chunk size of 512 tokens yields the
highest retrieval precision (Top-3 accuracy: 91.3%). Second, a generation
quality test using TRACe metrics across five LLMs shows that eSapiens delivers
more context-consistent outputs with up to a 23% improvement in factual
alignment.
  These results demonstrate the effectiveness of eSapiens in enabling
trustworthy, auditable AI workflows for high-stakes domains like legal and
finance.

</details>


### [137] [The Hidden Costs of AI: A Review of Energy, E-Waste, and Inequality in Model Development](https://arxiv.org/abs/2507.09611)
*Jenis Winsta*

Main category: cs.AI

TL;DR: 本文综述了人工智能快速发展中常被忽视的环境与伦理挑战，包括能耗、电子垃圾、算力不平等及网络安全能耗问题，呼吁负责任的AI发展需兼顾可持续性与公平性。


<details>
  <summary>Details</summary>
Motivation: 尽管AI技术突飞猛进，但其环境代价（如高碳排放）与社会影响（如算力资源分配不均）尚未得到充分重视，亟需系统性研究。

Method: 通过整合近期学术研究与机构报告数据，聚焦模型训练排放、硬件淘汰率、全球基础设施差异及网络安全能耗四大关键领域进行交叉分析。

Result: 揭示了AI产业链中存在的系统性矛盾：模型训练单次碳排放达284吨、硬件更新周期缩短导致电子垃圾激增、发展中国家算力资源匮乏，以及区块链等安全协议带来的隐性能源负担。

Conclusion: 主张将伦理责任与环境保护纳入AI发展核心框架，提出透明化能耗数据、优化算法能效、建立全球资源分配机制等可持续实践路径，以确保技术红利普惠化。

Abstract: Artificial intelligence (AI) has made remarkable progress in recent years,
yet its rapid expansion brings overlooked environmental and ethical challenges.
This review explores four critical areas where AI's impact extends beyond
performance: energy consumption, electronic waste (e-waste), inequality in
compute access, and the hidden energy burden of cybersecurity systems. Drawing
from recent studies and institutional reports, the paper highlights systemic
issues such as high emissions from model training, rising hardware turnover,
global infrastructure disparities, and the energy demands of securing AI. By
connecting these concerns, the review contributes to Responsible AI discourse
by identifying key research gaps and advocating for sustainable, transparent,
and equitable development practices. Ultimately, it argues that AI's progress
must align with ethical responsibility and environmental stewardship to ensure
a more inclusive and sustainable technological future.

</details>


### [138] [Bridging Bots: from Perception to Action via Multimodal-LMs and Knowledge Graphs](https://arxiv.org/abs/2507.09617)
*Margherita Martorana,Francesca Urgese,Mark Adamik,Ilaria Tiddi*

Main category: cs.AI

TL;DR: 本文提出了一种结合多模态语言模型与知识图谱的神经符号框架，旨在提升服务机器人的互操作性和情境适应能力。通过评估不同模型的性能，发现模型整合策略对生成符合本体论的知识图谱至关重要。


<details>
  <summary>Details</summary>
Motivation: 当前家用服务机器人依赖专有硬件和软件，导致系统孤立且难以扩展。知识图谱和本体论虽能促进系统互操作，但难以处理原始感知数据；而多模态语言模型擅长感知解释，却缺乏透明性和知识基础。

Method: 提出神经符号框架，整合机器人感知数据、本体论及五种多模态模型（3种LLaMA和2种GPT），采用不同神经符号交互模式生成平台无关的本体兼容知识图谱。

Result: 评估显示GPT-o1和LLaMA 4 Maverick模型表现最优，但新模型未必带来更好结果，凸显神经符号整合策略对生成合规知识图谱的关键作用。

Conclusion: 神经符号框架有效结合多模态感知与结构化知识表示，为机器人互操作提供解决方案，但需谨慎选择模型整合策略以确保知识图谱质量。

Abstract: Personal service robots are deployed to support daily living in domestic
environments, particularly for elderly and individuals requiring assistance.
These robots must perceive complex and dynamic surroundings, understand tasks,
and execute context-appropriate actions. However, current systems rely on
proprietary, hard-coded solutions tied to specific hardware and software,
resulting in siloed implementations that are difficult to adapt and scale
across platforms. Ontologies and Knowledge Graphs (KGs) offer a solution to
enable interoperability across systems, through structured and standardized
representations of knowledge and reasoning. However, symbolic systems such as
KGs and ontologies struggle with raw and noisy sensory input. In contrast,
multimodal language models are well suited for interpreting input such as
images and natural language, but often lack transparency, consistency, and
knowledge grounding. In this work, we propose a neurosymbolic framework that
combines the perceptual strengths of multimodal language models with the
structured representations provided by KGs and ontologies, with the aim of
supporting interoperability in robotic applications. Our approach generates
ontology-compliant KGs that can inform robot behavior in a platform-independent
manner. We evaluated this framework by integrating robot perception data,
ontologies, and five multimodal models (three LLaMA and two GPT models), using
different modes of neural-symbolic interaction. We assess the consistency and
effectiveness of the generated KGs across multiple runs and configurations, and
perform statistical analyzes to evaluate performance. Results show that GPT-o1
and LLaMA 4 Maverick consistently outperform other models. However, our
findings also indicate that newer models do not guarantee better results,
highlighting the critical role of the integration strategy in generating
ontology-compliant KGs.

</details>


### [139] [humancompatible.interconnect: Testing Properties of Repeated Uses of Interconnections of AI Systems](https://arxiv.org/abs/2507.09626)
*Rodion Nazarov,Anthony Quinn,Robert Shorten,Jakub Marecek*

Main category: cs.AI

TL;DR: 本文介绍了一个基于PyTorch的开源工具包，用于通过随机控制技术建模多智能体系统中AI系统的互连及其重复使用特性，提供公平性和鲁棒性的闭环保障。


<details>
  <summary>Details</summary>
Motivation: 多智能体AI系统需要满足公平性和鲁棒性的先验保证，但现有方法在随机系统建模方面存在复杂性挑战。

Method: 开发了基于PyTorch的工具包，采用随机控制技术对AI系统与智能体响应进行闭环建模，量化公平性和鲁棒性需求。

Result: 该工具包显著降低了多智能体闭环模型公平性保障的实现复杂度，并提供了可验证的先验保证。

Conclusion: PyTorch工具包为多智能体AI系统的公平鲁棒闭环控制提供了实用化解决方案，推动了可靠AI系统的发展。

Abstract: Artificial intelligence (AI) systems often interact with multiple agents. The
regulation of such AI systems often requires that {\em a priori\/} guarantees
of fairness and robustness be satisfied. With stochastic models of agents'
responses to the outputs of AI systems, such {\em a priori\/} guarantees
require non-trivial reasoning about the corresponding stochastic systems. Here,
we present an open-source PyTorch-based toolkit for the use of stochastic
control techniques in modelling interconnections of AI systems and properties
of their repeated uses. It models robustness and fairness desiderata in a
closed-loop fashion, and provides {\em a priori\/} guarantees for these
interconnections. The PyTorch-based toolkit removes much of the complexity
associated with the provision of fairness guarantees for closed-loop models of
multi-agent systems.

</details>


### [140] [Towards Concise and Adaptive Thinking in Large Reasoning Models: A Survey](https://arxiv.org/abs/2507.09662)
*Jason Zhu,Hongyu Li*

Main category: cs.AI

TL;DR: 大型推理模型（LRMs）在复杂任务上表现出色，但面临生成冗余推理链的问题。本文综述了简洁与自适应推理的最新进展，旨在提升LRMs的效率和实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型（如OpenAI o1和DeepSeek R1）在数学和编程等复杂推理任务中表现优异，但其生成的冗长推理链导致资源浪费和响应延迟，阻碍了实际应用。因此，需要研究如何缩短推理链并实现基于输入难度的自适应推理。

Method: 本文综述了近期关于简洁与自适应推理的研究进展，包括方法论、基准测试以及未来探索的挑战，旨在为研究者提供该领域的全面概览。

Result: 通过综述发现，简洁与自适应推理的研究为提升大型推理模型的效率提供了多种方法，但仍面临如何平衡推理深度与速度的挑战。

Conclusion: 本文希望帮助研究者快速了解简洁与自适应推理领域的现状，并启发新的自适应推理思路，以促进大型推理模型的更好应用。

Abstract: Large reasoning models (LRMs) like OpenAI o1 and DeepSeek R1 have
demonstrated impressive performance on complex reasoning tasks like mathematics
and programming with long Chain-of-Thought (CoT) reasoning sequences
(slow-thinking), compared with traditional large language models
(fast-thinking). However, these reasoning models also face a huge challenge
that generating unnecessarily lengthy and redundant reasoning chains even for
trivial questions. This phenomenon leads to a significant waste of inference
resources, increases the response time for simple queries, and hinders the
practical application of LRMs in real-world products. To this end, it is
crucial to shorten lengthy reasoning chains and learn adaptive reasoning
between fast and slow thinking based on input difficulty. In this survey, we
provide a comprehensive overview of recent progress in concise and adaptive
thinking for efficient reasoning of LRMs, including methodologies, benchmarks,
and challenges for future exploration. We hope this survey can help researchers
quickly understand the landscape of this field and inspire novel adaptive
thinking ideas to facilitate better usage of LRMs.

</details>


### [141] [Causality-informed Anomaly Detection in Partially Observable Sensor Networks: Moving beyond Correlations](https://arxiv.org/abs/2507.09742)
*Xiaofeng Xiao,Bo Shen,Xubo Yue*

Main category: cs.AI

TL;DR: 本文提出了一种基于因果关系的深度Q网络（Causal DQ）方法，用于部分可观测的传感器布局优化，以更快地检测异常。


<details>
  <summary>Details</summary>
Motivation: 随着AI驱动的制造业日益普及，实时监控数据流的需求激增。由于资源有限，无法在所有位置部署传感器，因此需要开发一种最优的传感器布局策略，以实现系统的部分可观测性并快速检测异常。现有方法大多仅考虑变量相关性，忽略了因果关系，而少数结合因果分析的方法依赖人工干预，既不实用又可能导致灾难性损失。

Method: 本文提出了一种因果信息深度Q网络（Causal DQ）方法，通过在Q网络训练的每个阶段整合因果信息，实现了更快的收敛和更严格的理论误差界限。

Result: 实验表明，经过训练的因果信息Q网络在各种设置下显著缩短了异常检测时间，证明了其在大规模实时数据流中传感器布局的有效性。

Conclusion: 本文的方法不仅适用于当前的实现，其基本见解还可应用于各种强化学习问题，为工程应用中的因果信息机器学习方法开辟了新的可能性。

Abstract: Nowadays, as AI-driven manufacturing becomes increasingly popular, the volume
of data streams requiring real-time monitoring continues to grow. However, due
to limited resources, it is impractical to place sensors at every location to
detect unexpected shifts. Therefore, it is necessary to develop an optimal
sensor placement strategy that enables partial observability of the system
while detecting anomalies as quickly as possible. Numerous approaches have been
proposed to address this challenge; however, most existing methods consider
only variable correlations and neglect a crucial factor: Causality. Moreover,
although a few techniques incorporate causal analysis, they rely on
interventions-artificially creating anomalies-to identify causal effects, which
is impractical and might lead to catastrophic losses. In this paper, we
introduce a causality-informed deep Q-network (Causal DQ) approach for
partially observable sensor placement in anomaly detection. By integrating
causal information at each stage of Q-network training, our method achieves
faster convergence and tighter theoretical error bounds. Furthermore, the
trained causal-informed Q-network significantly reduces the detection time for
anomalies under various settings, demonstrating its effectiveness for sensor
placement in large-scale, real-world data streams. Beyond the current
implementation, our technique's fundamental insights can be applied to various
reinforcement learning problems, opening up new possibilities for real-world
causality-informed machine learning methods in engineering applications.

</details>


### [142] [Sound and Complete Neuro-symbolic Reasoning with LLM-Grounded Interpretations](https://arxiv.org/abs/2507.09751)
*Bradley P. Allen,Prateek Chhikara,Thomas Macaulay Ferguson,Filip Ilievski,Paul Groth*

Main category: cs.AI

TL;DR: 提出一种将大语言模型（LLM）整合到次协调逻辑形式语义解释函数中的方法，以利用LLM的广泛参数知识同时保持逻辑系统的可靠性与完备性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在自然语言理解与生成方面表现优异，但其输出存在逻辑不一致性问题。研究旨在探索如何在形式推理中有效利用LLM的知识同时克服其不一致性缺陷。

Method: 通过将LLM直接嵌入次协调逻辑的形式语义解释函数，构建神经符号推理的理论框架。实验采用多个短文本事实性基准数据集验证方法的可行性。

Result: 实验证明该方法具有可行性，不同于先前研究，其能在保留底层逻辑可靠性与完备性的前提下利用LLM的知识进行推理。

Conclusion: 该研究为神经符号推理提供了理论框架，成功实现了LLM知识与形式逻辑系统的协同，为解决LLM逻辑不一致性问题提供了新思路。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities in
natural language understanding and generation, but they exhibit problems with
logical consistency in the output they generate. How can we harness LLMs'
broad-coverage parametric knowledge in formal reasoning despite their
inconsistency? We present a method for directly integrating an LLM into the
interpretation function of the formal semantics for a paraconsistent logic. We
provide experimental evidence for the feasibility of the method by evaluating
the function using datasets created from several short-form factuality
benchmarks. Unlike prior work, our method offers a theoretical framework for
neuro-symbolic reasoning that leverages an LLM's knowledge while preserving the
underlying logic's soundness and completeness properties.

</details>


### [143] [Technical Requirements for Halting Dangerous AI Activities](https://arxiv.org/abs/2507.09801)
*Peter Barnett,Aaron Scher,David Abecassis*

Main category: cs.AI

TL;DR: 本文探讨了AI快速发展带来的风险，并提出了通过技术干预实现危险AI活动协调暂停的方案，作为AI治理的技术基础。


<details>
  <summary>Details</summary>
Motivation: AI系统的快速发展带来了失控、滥用、地缘政治不稳定和权力集中等前所未有的风险，需要采取措施避免最坏结果。

Method: 提出了关键的技术干预措施，以实现对危险AI开发和部署的协调暂停，并讨论了这些措施如何限制各类危险AI活动。

Result: 这些技术干预措施能够有效限制危险AI活动，并为潜在的AI治理计划提供技术基础。

Conclusion: 通过协调暂停危险AI活动的技术干预，可以为应对AI风险提供可行的治理方案，避免最坏情况的发生。

Abstract: The rapid development of AI systems poses unprecedented risks, including loss
of control, misuse, geopolitical instability, and concentration of power. To
navigate these risks and avoid worst-case outcomes, governments may proactively
establish the capability for a coordinated halt on dangerous AI development and
deployment. In this paper, we outline key technical interventions that could
allow for a coordinated halt on dangerous AI activities. We discuss how these
interventions may contribute to restricting various dangerous AI activities,
and show how these interventions can form the technical foundation for
potential AI governance plans.

</details>


### [144] [Is Human-Written Data Enough? The Challenge of Teaching Reasoning to LLMs Without RL or Distillation](https://arxiv.org/abs/2507.09850)
*Wei Du,Branislav Kisacanin,George Armstrong,Shubham Toshniwal,Ivan Moshkov,Alexan Ayrapetyan,Sadegh Mahdavi,Dan Zhao,Shizhe Diao,Dragan Masulovic,Marius Stanean,Advaith Avadhanam,Max Wang,Ashmit Dutta,Shitij Govil,Sri Yanamandara,Mihir Tandon,Sriram Ananthakrishnan,Vedant Rathi,David Zhang,Joonseok Kang,Leon Luo,Titu Andreescu,Boris Ginsburg,Igor Gitman*

Main category: cs.AI

TL;DR: 研究表明，仅需少量高质量思维链（CoT）示例即可激活基础模型的推理能力，轻量微调的32B模型性能超越72B模型。专家CoT的潜在特质难以复制，但人工精心编写的少量CoT数据仍具潜力。


<details>
  <summary>Details</summary>
Motivation: 探索是否仅通过提示或最小化调优即可在基础模型中诱导长思维链推理，替代传统强化学习或大模型蒸馏方法。

Method: 使用20个来自\texttt{QwQ-32B-Preview}的长CoT示例轻量微调\texttt{Qwen2.5-32B}，并尝试非推理模型数据及人工标注数据（结合提示工程、多轮编辑和结构化引导）。

Result: 微调后的32B模型超越\texttt{Qwen2.5-Math-72B-Instruct}，但非专家CoT数据效果不佳。分析显示问题难度、多样性和答案长度是关键影响因素。

Conclusion: 专家CoT具有不可替代性，但精心设计的小规模人工CoT数据可有效激活模型推理能力。公开了人工标注数据集以促进相关研究。

Abstract: Reasoning-capable language models achieve state-of-the-art performance in
diverse complex tasks by generating long, explicit Chain-of-Thought (CoT)
traces. While recent works show that base models can acquire such reasoning
traces via reinforcement learning or distillation from stronger models like
DeepSeek-R1, previous works demonstrate that even short CoT prompting without
fine-tuning is able to improve reasoning. We ask whether long CoT can be
induced in a base model using only prompting or minimal tuning. Using just 20
long CoT examples from the reasoning model \texttt{QwQ-32B-Preview}, we lightly
fine-tune the base model \texttt{Qwen2.5-32B}. The resulting model outperforms
the much larger \texttt{Qwen2.5-Math-72B-Instruct}, showing that a handful of
high-quality examples can unlock strong reasoning capabilities. We further
explore using CoT data from non-reasoning models and human annotators, enhanced
with prompt engineering, multi-pass editing, and structural guidance. However,
neither matches the performance of reasoning model traces, suggesting that
certain latent qualities of expert CoT are difficult to replicate. We analyze
key properties of reasoning data, such as problem difficulty, diversity, and
answer length, that influence reasoning distillation. While challenges remain,
we are optimistic that carefully curated human-written CoT, even in small
quantities, can activate reasoning behaviors in base models. We release our
human-authored dataset across refinement stages and invite further
investigation into what makes small-scale reasoning supervision so effective.

</details>


### [145] [Model-Grounded Symbolic Artificial Intelligence Systems Learning and Reasoning with Model-Grounded Symbolic Artificial Intelligence Systems](https://arxiv.org/abs/2507.09854)
*Aniruddha Chattopadhyay,Raj Dandekar,Kaushik Roy*

Main category: cs.AI

TL;DR: 本文提出将指令调优的大型语言模型重新解释为基于模型的符号AI系统，其中自然语言作为符号层，通过模型的内部表示空间实现接地。研究开发了新颖的学习和推理方法，并在不同复杂度的公理演绎推理过程中进行了初步评估。


<details>
  <summary>Details</summary>
Motivation: 神经符号AI系统结合了神经网络和经典符号AI机制，以利用大规模、可泛化学习与稳健、可验证推理的互补优势。本研究旨在探索如何将大型语言模型重新解释为符号AI系统，以提升学习效率和推理可靠性。

Method: 研究提出将指令调优的大型语言模型视为基于模型的符号AI系统，自然语言作为符号层，模型的内部表示空间实现接地。在此基础上，开发了与传统学习和推理范式结构相似的新方法。

Result: 初步评估表明，该方法在不同复杂度的公理演绎推理过程中有效，为提升学习效率和推理可靠性提供了新的见解。

Conclusion: 通过将大型语言模型重新解释为符号AI系统，并结合新颖的学习和推理方法，本研究为神经符号AI的发展提供了新的思路，初步结果展示了其在提升推理可靠性方面的潜力。

Abstract: Neurosymbolic artificial intelligence (AI) systems combine neural network and
classical symbolic AI mechanisms to exploit the complementary strengths of
large scale, generalizable learning and robust, verifiable reasoning. Numerous
classifications of neurosymbolic AI illustrate how these two components can be
integrated in distinctly different ways. In this work, we propose
reinterpreting instruction tuned large language models as model grounded
symbolic AI systems where natural language serves as the symbolic layer and
grounding is achieved through the models internal representation space. Within
this framework, we investigate and develop novel learning and reasoning
approaches that preserve structural similarities to traditional learning and
reasoning paradigms. Preliminary evaluations across axiomatic deductive
reasoning procedures of varying complexity provide insights into the
effectiveness of our approach in improving learning efficiency and reasoning
reliability.

</details>


### [146] [VerifyBench: A Systematic Benchmark for Evaluating Reasoning Verifiers Across Domains](https://arxiv.org/abs/2507.09884)
*Xuzhao Li,Xuchen Li,Shiyu Hu,Yongzhen Guo,Wentao Zhang*

Main category: cs.AI

TL;DR: 本文提出VerifyBench基准，系统评估数学、物理、化学和生物领域的验证器性能，揭示专用验证器与通用大模型在准确率、召回率及跨领域泛化的根本性权衡。


<details>
  <summary>Details</summary>
Motivation: 现有验证器面临规则方法处理复杂答案困难、专用模型灵活性不足、通用模型判断不一致等问题，缺乏跨领域的系统性评估，阻碍强化学习与可验证奖励（RLVR）的可靠发展。

Method: 构建含4000个专家级问题的跨领域基准VerifyBench，配备参考答案和多样化响应；通过多学科专家团队严格标注确保可靠性，设计四维实验框架对比专用验证器与通用LLM在答案提取/完整响应、短/长输出组合条件下的性能边界。

Result: 专用验证器准确率领先但召回率不足，通用模型包容性强但精度不稳定；验证器对输入结构高度敏感且存在跨领域泛化的固有局限。

Conclusion: 研究揭示了当前验证器技术的瓶颈，为RLVR发展提供了关键见解：需平衡专用模型的精确性与通用模型的适应性，并解决跨领域迁移的核心挑战。

Abstract: Large language models (LLMs) increasingly rely on reinforcement learning (RL)
to enhance their reasoning capabilities through feedback. A critical challenge
is verifying the consistency of model-generated responses and reference
answers, since these responses are often lengthy, diverse, and nuanced.
Rule-based verifiers struggle with complexity, prompting the use of model-based
verifiers. However, specialized verifiers lack flexibility, while general LLM
judges can be inconsistent. Existing research primarily focuses on building
better verifiers, yet a systematic evaluation of different types of verifiers'
performance across domains remains lacking, severely constraining the reliable
development of Reinforcement Learning with Verifiable Reward (RLVR). To address
this, we propose VerifyBench--a cross-domain comprehensive benchmark for
systematically evaluating verifiers. We construct 4,000 expert-level questions
covering mathematics, physics, chemistry, and biology. Each question is
equipped with reference answers and diverse responses. The reliability of the
evaluation is ensured through a rigorous annotation process conducted by a
multidisciplinary expert team. We design a four-dimensional experimental
framework to comprehensively compare the performance boundaries of specialized
verifiers and general LLMs under combined conditions of extracted answers vs.
complete responses, and short vs. long outputs. Our evaluation uncovers
fundamental trade-offs in verifiers: while specialized verifiers achieve
leading accuracy, they exhibit deficiencies in recall; general models show
stronger inclusivity but unstable precision. More importantly, we discover
verifiers' high sensitivity to input structure and inherent limitations in
cross-domain generalization, providing critical insights into the bottlenecks
of current verifier technology.

</details>


### [147] [DeepSeek: Paradigm Shifts and Technical Evolution in Large AI Models](https://arxiv.org/abs/2507.09955)
*Luolin Xiong,Haofen Wang,Xi Chen,Lu Sheng,Yun Xiong,Jingping Liu,Yanghua Xiao,Huajun Chen,Qing-Long Han,Yang Tang*

Main category: cs.AI

TL;DR: DeepSeek发布V3和R1系列AI模型，以低成本、高性能和开源优势引发全球关注。论文回顾了大模型演进历程，介绍了MLA、MoE等创新算法，并探讨了其在工程实现与行业竞争中的影响。


<details>
  <summary>Details</summary>
Motivation: 研究DeepSeek模型的创新性及其对AI大模型技术发展的推动作用，分析其在算法、工程实现及行业竞争中的突破。

Method: 采用文献综述与技术创新分析相结合的方法，重点研究Multi-head Latent Attention (MLA)、Mixture-of-Experts (MoE)等新型算法，以及模型扩展、训练推理等系统级优化架构。

Result: DeepSeek模型在性能与成本效益上超越主流LLM，其创新算法和工程架构为AI大模型发展提供了新范式，显著影响了行业竞争格局。

Conclusion: DeepSeek的创新实践揭示了AI大模型在数据、训练与推理方面的未来发展趋势，为技术演进提供了重要参考。

Abstract: DeepSeek, a Chinese Artificial Intelligence (AI) startup, has released their
V3 and R1 series models, which attracted global attention due to their low
cost, high performance, and open-source advantages. This paper begins by
reviewing the evolution of large AI models focusing on paradigm shifts, the
mainstream Large Language Model (LLM) paradigm, and the DeepSeek paradigm.
Subsequently, the paper highlights novel algorithms introduced by DeepSeek,
including Multi-head Latent Attention (MLA), Mixture-of-Experts (MoE),
Multi-Token Prediction (MTP), and Group Relative Policy Optimization (GRPO).
The paper then explores DeepSeek engineering breakthroughs in LLM scaling,
training, inference, and system-level optimization architecture. Moreover, the
impact of DeepSeek models on the competitive AI landscape is analyzed,
comparing them to mainstream LLMs across various fields. Finally, the paper
reflects on the insights gained from DeepSeek innovations and discusses future
trends in the technical and engineering development of large AI models,
particularly in data, training, and reasoning.

</details>


### [148] [Improving monotonic optimization in heterogeneous multi-agent reinforcement learning with optimal marginal deterministic policy gradient](https://arxiv.org/abs/2507.09989)
*Xiaoyang Yu,Youfang Lin,Shuo Wang,Sheng Han*

Main category: cs.AI

TL;DR: 本文提出OMDPG算法，通过最优边际Q函数(OMQ)和广义Q评论家(GQC)解决异构多智能体强化学习(ParPS)与单调性能提升的冲突，在SMAC和MAMuJoCo环境中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 异构多智能体强化学习(HMARL)中，HAPPO算法的顺序更新方案需要独立学习(NoPS)，但实际需要基于分组的参数共享(ParPS)以实现高效协作。实验表明直接结合ParPS会导致策略更新基线漂移问题。

Method: 1) 用最优边际Q函数$\phi_{\psi}^*(s,a_{1:i})$替代顺序计算的$Q_{\psi}^s(s,a_{1:i})$；2) 引入悲观不确定性约束的广义Q评论家(GQC)；3) 采用集中评论家分组执行器(CCGA)架构实现ParPS。

Result: 在SMAC和MAMuJoCo环境中，OMDPG算法在保持单调改进的同时，性能优于多种最先进的MARL基线方法。

Conclusion: OMDPG通过OMQ函数和GQC机制有效解决了ParPS与单调改进的冲突，CCGA架构实现了局部策略网络参数共享与全局Q函数精确计算的统一。

Abstract: In heterogeneous multi-agent reinforcement learning (MARL), achieving
monotonic improvement plays a pivotal role in enhancing performance. The HAPPO
algorithm proposes a feasible solution by introducing a sequential update
scheme, which requires independent learning with No Parameter-sharing (NoPS).
However, heterogeneous MARL generally requires Partial Parameter-sharing
(ParPS) based on agent grouping to achieve high cooperative performance. Our
experiments prove that directly combining ParPS with the sequential update
scheme leads to the policy updating baseline drift problem, thereby failing to
achieve improvement. To solve the conflict between monotonic improvement and
ParPS, we propose the Optimal Marginal Deterministic Policy Gradient (OMDPG)
algorithm. First, we replace the sequentially computed $Q_{\psi}^s(s,a_{1:i})$
with the Optimal Marginal Q (OMQ) function $\phi_{\psi}^*(s,a_{1:i})$ derived
from Q-functions. This maintains MAAD's monotonic improvement while eliminating
the conflict through optimal joint action sequences instead of sequential
policy ratio calculations. Second, we introduce the Generalized Q Critic (GQC)
as the critic function, employing pessimistic uncertainty-constrained loss to
optimize different Q-value estimations. This provides the required Q-values for
OMQ computation and stable baselines for actor updates. Finally, we implement a
Centralized Critic Grouped Actor (CCGA) architecture that simultaneously
achieves ParPS in local policy networks and accurate global Q-function
computation. Experimental results in SMAC and MAMuJoCo environments demonstrate
that OMDPG outperforms various state-of-the-art MARL baselines.

</details>


### [149] [On The Role of Intentionality in Knowledge Representation: Analyzing Scene Context for Cognitive Agents with a Tiny Language Model](https://arxiv.org/abs/2507.10000)
*Mark Burgess*

Main category: cs.AI

TL;DR: 该论文提出了一种基于Promise理论和语义时空模型的低成本意图检测方法，通过多尺度异常分析区分内容与上下文，适用于基础生物体。


<details>
  <summary>Details</summary>
Motivation: 自Searle解构哲学领域的意图性以来，科学界对意图实际应用的研究较少。该研究旨在填补这一空白，探索无需复杂计算资源的意图性检测方法。

Method: 利用语义时空模型中的过程一致性作为指导，通过多尺度异常检测分离'意图内容'与'环境上下文'，以时空一致性作为衡量标准。

Result: 该方法能以极低计算成本实现潜在的意图性检测，无需大量训练或推理能力，其概念形成水平取决于代理的记忆容量。

Conclusion: 研究为基本生物体提供了一种实用的意图性解释框架，证明复杂的人工概率批处理并非意图检测的必要条件。

Abstract: Since Searle's work deconstructing intent and intentionality in the realm of
philosophy, the practical meaning of intent has received little attention in
science and technology. Intentionality and context are both central to the
scope of Promise Theory's model of Semantic Spacetime, used as an effective
Tiny Language Model. One can identify themes and concepts from a text, on a low
level (without knowledge of the specific language) by using process coherence
as a guide. Any agent process can assess superficially a degree of latent
`intentionality' in data by looking for anomalous multi-scale anomalies and
assessing the work done to form them. Scale separation can be used to sort
parts into `intended' content and `ambient context', using the spacetime
coherence as a measure. This offers an elementary but pragmatic interpretation
of latent intentionality for very low computational cost, and without reference
to extensive training or reasoning capabilities. The process is well within the
reach of basic organisms as it does not require large scale artificial
probabilistic batch processing. The level of concept formation depends,
however, on the memory capacity of the agent.

</details>


### [150] [Deep Hidden Cognition Facilitates Reliable Chain-of-Thought Reasoning](https://arxiv.org/abs/2507.10007)
*Zijun Chen,Wenbo Hu,Richang Hong*

Main category: cs.AI

TL;DR: 本文提出了一种通过模型内在真实性编码来校准思维链（CoT）推理准确性的新方法，显著提升了推理任务的可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 思维链推理在大型语言模型和多模态大型语言模型中展现出强大的深度推理能力，但其中间步骤的错误积累会降低其可靠性。

Method: 研究发现特定注意力头激活能可靠反映CoT推理步骤的真实性，基于此训练了一个置信度预测器，通过波束搜索动态选择最合理的推理路径。

Result: 实验结果表明，该方法在数学、符号和常识推理任务中显著优于现有基线方法（如Few-Shot CoT、Self-Consistency等），在单模态和多模态设置下均表现出更高的准确性和可靠性。

Conclusion: 这项工作为提升思维链推理的可靠性提供了一条新路径，并验证了其在专业推理模型中的适用性，同时探讨了模型自校正能力在CoT推理中的作用。

Abstract: Chain of Thought (CoT) reasoning has demonstrated remarkable deep reasoning
capabilities in both large language models (LLMs) and multimodal large language
models (MLLMs). However, its reliability is often undermined by the
accumulation of errors in intermediate steps. This paper introduces an novel
approach to calibrate the CoT reasoning accuracy by leveraging the model's
intrinsic veracity encoding. We discover that specific attention head
activations reliably reflect the truthfulness of reasoning steps in CoT. Based
on this insight, we train a confidence predictor to evaluate the correctness of
each reasoning step using these truthfulness-sensitive activations, dynamically
selecting the most plausible reasoning path via beam search. Experimental
results demonstrate that our method significantly outperforms the
state-of-the-art baselines (e.g., Few-Shot CoT, Self-Consistency, and
Self-Evaluation Guided Beam Search) across the mathematical, symbolic, and
commonsense reasoning tasks, exhibiting superior accuracy and reliability in
both unimodal and multimodal settings. We further validate the approach on
large reasoning models, confirming its applicability to specialized reasoning
models. Additionally, we explore the role of the model's self-correction
ability in CoT reasoning. This work provides a novel reliability improvement
path for CoT reasoning with broad application potential.

</details>


### [151] [Automating SPARQL Query Translations between DBpedia and Wikidata](https://arxiv.org/abs/2507.10045)
*Malte Christian Bartels,Debayan Banerjee,Ricardo Usbeck*

Main category: cs.AI

TL;DR: 本文研究最先进的大型语言模型（LLM）能否在不同知识图谱（KG）模式间自动转换SPARQL查询，重点关注DBpedia与Wikidata及DBLP与OpenAlex间的转换，并通过构建两个基准测试评估模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在填补知识图谱互操作性研究的空白，通过严格评估LLM在SPARQL到SPARQL转换任务中的表现，探索模型在不同KG模式间的翻译能力。

Method: 研究选取了Llama-3-8B、DeepSeek-R1-Distill-Llama-70B和Mistral-Large-Instruct-2407三种开源LLM，使用零样本、少样本及两种思维链变体进行测试，并构建了包含DBpedia-Wikidata和DBLP-OpenAlex查询对齐的两个基准数据集。

Result: 研究发现，不同模型和提示策略的性能差异显著，且Wikidata到DBpedia的转换效果明显优于DBpedia到Wikidata的转换。

Conclusion: 研究表明，LLM在SPARQL查询翻译任务中表现参差不齐，提示策略和模型选择对性能有显著影响，且不同知识图谱间的翻译效果存在明显差异。

Abstract: This paper investigates whether state-of-the-art Large Language Models (LLMs)
can automatically translate SPARQL between popular Knowledge Graph (KG)
schemas. We focus on translations between the DBpedia and Wikidata KG, and
later on DBLP and OpenAlex KG. This study addresses a notable gap in KG
interoperability research by rigorously evaluating LLM performance on
SPARQL-to-SPARQL translation. Two benchmarks are assembled, where the first
align 100 DBpedia-Wikidata queries from QALD-9-Plus; the second contains 100
DBLP queries aligned to OpenAlex, testing generalizability beyond encyclopaedic
KGs. Three open LLMs: Llama-3-8B, DeepSeek-R1-Distill-Llama-70B, and
Mistral-Large-Instruct-2407 are selected based on their sizes and architectures
and tested with zero-shot, few-shot, and two chain-of-thought variants. Outputs
were compared with gold answers, and resulting errors were categorized. We find
that the performance varies markedly across models and prompting strategies,
and that translations for Wikidata to DBpedia work far better than translations
for DBpedia to Wikidata.

</details>


### [152] [On Gradual Semantics for Assumption-Based Argumentation](https://arxiv.org/abs/2507.10076)
*Anna Rapberger,Fabrizio Russo,Antonio Rago,Francesca Toni*

Main category: cs.AI

TL;DR: 本文填补了假设基础论证（ABA）中渐进语义学的空白，提出了一种新的渐进语义学家族，用于为ABA框架中的核心组件（假设）赋予辩证强度。通过将双极集基础论证框架作为ABA框架的抽象，并推广最先进的模块化渐进语义学，研究展示了这些语义学满足平衡性和单调性等理想性质。


<details>
  <summary>Details</summary>
Motivation: 渐进语义学在计算论证中作为扩展和标记语义学的细粒度替代方案，能够为论证赋予可接受度。然而，尽管假设基础论证（ABA）是一种流行的结构化论证形式，渐进语义学在ABA中的应用尚未得到充分研究。本文旨在填补这一空白。

Method: 研究使用双极集基础论证框架作为（可能非平坦的）ABA框架的抽象，并推广了定量双极论证框架（QBAFs）中最先进的模块化渐进语义学。此外，还探索了一种基于论证的方法，直接利用已建立的QBAF模块化语义学作为基线。

Result: 提出的渐进ABA语义学满足渐进QBAF语义学的理想性质（如平衡性和单调性）的适当调整版本。通过合成ABA框架的实验，比较了渐进ABA语义学与其基于论证的对应方法，并评估了收敛性。

Conclusion: 本文成功地将渐进语义学引入ABA框架，提出并验证了一种新的渐进语义学家族，为ABA中的假设赋予了辩证强度。实验结果表明，这些语义学具有良好的性质，并在与基于论证的方法比较中展现出优势。

Abstract: In computational argumentation, gradual semantics are fine-grained
alternatives to extension-based and labelling-based semantics . They ascribe a
dialectical strength to (components of) arguments sanctioning their degree of
acceptability. Several gradual semantics have been studied for abstract,
bipolar and quantitative bipolar argumentation frameworks (QBAFs), as well as,
to a lesser extent, for some forms of structured argumentation. However, this
has not been the case for assumption-based argumentation (ABA), despite it
being a popular form of structured argumentation with several applications
where gradual semantics could be useful. In this paper, we fill this gap and
propose a family of novel gradual semantics for equipping assumptions, which
are the core components in ABA frameworks, with dialectical strengths. To do
so, we use bipolar set-based argumentation frameworks as an abstraction of
(potentially non-flat) ABA frameworks and generalise state-of-the-art modular
gradual semantics for QBAFs. We show that our gradual ABA semantics satisfy
suitable adaptations of desirable properties of gradual QBAF semantics, such as
balance and monotonicity. We also explore an argument-based approach that
leverages established QBAF modular semantics directly, and use it as baseline.
Finally, we conduct experiments with synthetic ABA frameworks to compare our
gradual ABA semantics with its argument-based counterpart and assess
convergence.

</details>


### [153] [BlueGlass: A Framework for Composite AI Safety](https://arxiv.org/abs/2507.10106)
*Harshal Nandigramwar,Syed Qutub,Kay-Ulrich Scholl*

Main category: cs.AI

TL;DR: 本文提出了BlueGlass框架，旨在通过统一基础设施整合多样化AI安全工具，提升AI系统的整体安全性，并以视觉语言模型为例展示了三种安全分析方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统能力与普及度的提升，现有安全工具各自为政无法提供全面保障，亟需集成化解决方案来确保AI系统安全。

Method: 开发BlueGlass框架实现安全工具的组合工作流，通过分布评估、层级动态探针分析和稀疏自编码器三种方法验证视觉语言模型的安全性。

Result: 实验揭示模型在不同数据分布下的性能权衡与失效模式，发现层级学习存在相位跃迁现象，并通过稀疏自编码器识别出可解释概念。

Conclusion: 该研究为构建更鲁棒的AI系统提供了基础性框架和实证发现，推动了复合式安全方法论的发展。

Abstract: As AI systems become increasingly capable and ubiquitous, ensuring the safety
of these systems is critical. However, existing safety tools often target
different aspects of model safety and cannot provide full assurance in
isolation, highlighting a need for integrated and composite methodologies. This
paper introduces BlueGlass, a framework designed to facilitate composite AI
safety workflows by providing a unified infrastructure enabling the integration
and composition of diverse safety tools that operate across model internals and
outputs. Furthermore, to demonstrate the utility of this framework, we present
three safety-oriented analyses on vision-language models for the task of object
detection: (1) distributional evaluation, revealing performance trade-offs and
potential failure modes across distributions; (2) probe-based analysis of layer
dynamics highlighting shared hierarchical learning via phase transition; and
(3) sparse autoencoders identifying interpretable concepts. More broadly, this
work contributes foundational infrastructure and findings for building more
robust and reliable AI systems.

</details>


### [154] [Analysis of AI Techniques for Orchestrating Edge-Cloud Application Migration](https://arxiv.org/abs/2507.10119)
*Sadig Gojayev,Ahmad Anaqreh,Carolina Fortuna*

Main category: cs.AI

TL;DR: 本文研究了边缘-云系统中应用迁移的自动编排问题，通过马尔可夫决策过程（MDP）分析比较了AI规划和强化学习（RL）方法，并基于状态空间定义提出了新分类。


<details>
  <summary>Details</summary>
Motivation: 边缘-云系统中的应用迁移能提升服务质量（QoS）并降低成本，但目前主要依赖启发式方法。本文旨在探索更高效的自动化编排技术。

Method: 从MDP出发，分析并比较了AI规划和RL方法，针对可建模为汉诺塔（ToH）问题的迁移问题，提出了基于状态空间定义的新分类框架。

Result: 研究梳理了现有技术的优缺点，并通过状态空间视角评估了不同模型的适用性，为计算连续环境中的迁移编排提供了技术参考。

Conclusion: 本文为边缘-云应用迁移的自动化编排提供了理论框架和方法比较，有助于未来计算连续环境中迁移技术的优化与发展。

Abstract: Application migration in edge-cloud system enables high QoS and cost
effective service delivery. However, automatically orchestrating such migration
is typically solved with heuristic approaches. Starting from the Markov
Decision Process (MDP), in this paper, we identify, analyze and compare
selected state-of-the-art Artificial Intelligence (AI) planning and
Reinforcement Learning (RL) approaches for solving the class of edge-cloud
application migration problems that can be modeled as Towers of Hanoi (ToH)
problems. We introduce a new classification based on state space definition and
analyze the compared models also through this lense. The aim is to understand
available techniques capable of orchestrating such application migration in
emerging computing continuum environments.

</details>


### [155] [Could you be wrong: Debiasing LLMs using a metacognitive prompt for improving human decision making](https://arxiv.org/abs/2507.10124)
*Thomas T. Hills*

Main category: cs.AI

TL;DR: 本文探讨了利用人类心理学中的元认知提示（如\"你可能错了吗？\"）来减少大型语言模型（LLM）中的偏见，展示了这种方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于LLM仍在发展中，当前的真实性可能在未来失效，因此需要一种通用的去偏见策略，能够超越当前模型的限制。人类决策中的去偏见策略为此提供了可能。

Method: 研究采用了人类决策文献中的元认知提示（如\"你可能错了吗？\"），在LLM生成初始回答后，通过该提示引导模型进一步揭示潜在偏见、错误和矛盾证据。

Result: 实验表明，元认知提示能有效引导LLM自我识别偏见，并生成深刻的元认知反思，揭示模型与用户在提示理解上的不一致性。

Conclusion: 人类心理学为提示工程提供了新途径，利用长期积累的有效提示改进人类决策的方法，可以显著提升LLM的去偏见能力。

Abstract: Identifying bias in LLMs is ongoing. Because they are still in development,
what is true today may be false tomorrow. We therefore need general strategies
for debiasing that will outlive current models. Strategies developed for
debiasing human decision making offer one promising approach as they
incorporate an LLM-style prompt intervention designed to bring latent knowledge
into awareness during decision making. LLMs trained on vast amounts of
information contain information about potential biases, counter-arguments, and
contradictory evidence, but that information may only be brought to bear if
prompted. Metacognitive prompts developed in the human decision making
literature are designed to achieve this, and as I demonstrate here, they show
promise with LLMs. The prompt I focus on here is "could you be wrong?"
Following an LLM response, this prompt leads LLMs to produce additional
information, including why they answered as they did, errors, biases,
contradictory evidence, and alternatives, none of which were apparent in their
initial response. Indeed, this metaknowledge often reveals that how LLMs and
users interpret prompts are not aligned. Here I demonstrate this prompt using a
set of questions taken from recent articles about LLM biases, including
implicit discriminatory biases and failures of metacognition. "Could you be
wrong" prompts the LLM to identify its own biases and produce cogent
metacognitive reflection. I also present another example involving convincing
but incomplete information, which is readily corrected by the metacognitive
prompt. In sum, this work argues that human psychology offers a new avenue for
prompt engineering, leveraging a long history of effective prompt-based
improvements to human decision making.

</details>


### [156] [FRSICL: LLM-Enabled In-Context Learning Flight Resource Allocation for Fresh Data Collection in UAV-Assisted Wildfire Monitoring](https://arxiv.org/abs/2507.10134)
*Yousef Emami,Hao Zhou,Miguel Gutierrez Gaitan,Kai Li,Luis Almeida*

Main category: cs.AI

TL;DR: 本文提出了一种基于LLM的在线飞行资源分配方案（FRSICL），用于无人机辅助的野火监测系统，通过联合优化飞行控制和数据收集调度，实时最小化地面传感器的平均信息年龄（AoI）。


<details>
  <summary>Details</summary>
Motivation: 无人机在野火监测中至关重要，但现有的深度强化学习方法存在采样效率低、仿真与现实的差距以及训练复杂等问题，不适用于时间敏感的应用场景。

Method: FRSICL利用自然语言任务描述和环境反馈，动态生成数据收集调度和速度控制策略，无需大量重新训练即可实现实时决策。

Result: 仿真结果表明，FRSICL在最小化平均AoI方面优于近端策略优化（PPO）和最近邻基线方法。

Conclusion: FRSICL提供了一种高效、实时的无人机资源分配方案，显著提升了野火监测系统的性能，适用于时间敏感的应用场景。

Abstract: Unmanned Aerial Vehicles (UAVs) are vital for public safety, particularly in
wildfire monitoring, where early detection minimizes environmental impact. In
UAV-Assisted Wildfire Monitoring (UAWM) systems, joint optimization of sensor
transmission scheduling and velocity is critical for minimizing Age of
Information (AoI) from stale sensor data. Deep Reinforcement Learning (DRL) has
been used for such optimization; however, its limitations such as low sampling
efficiency, simulation-to-reality gaps, and complex training render it
unsuitable for time-critical applications like wildfire monitoring. This paper
introduces a new online Flight Resource Allocation scheme based on LLM-Enabled
In-Context Learning (FRSICL) to jointly optimize the UAV's flight control and
data collection schedule along the trajectory in real time, thereby
asymptotically minimizing the average AoI across ground sensors. In contrast to
DRL, FRSICL generates data collection schedules and controls velocity using
natural language task descriptions and feedback from the environment, enabling
dynamic decision-making without extensive retraining. Simulation results
confirm the effectiveness of the proposed FRSICL compared to Proximal Policy
Optimization (PPO) and Nearest-Neighbor baselines.

</details>


### [157] [Adaptability in Multi-Agent Reinforcement Learning: A Framework and Unified Review](https://arxiv.org/abs/2507.10142)
*Siyi Hu,Mohamad A Hady,Jianglin Qiao,Jimmy Cao,Mahardhika Pratama,Ryszard Kowalczyk*

Main category: cs.AI

TL;DR: 多智能体强化学习（MARL）在模拟环境中表现优异，但在现实动态系统中的部署仍受限。本文提出以\textit{适应性}为核心的三维评估框架，旨在提升MARL算法在动态环境中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现实多智能体系统（MAS）的复杂动态性（如智能体数量波动、任务目标演变等）导致MARL部署困难，需建立系统性评估标准以衡量算法在变化条件下的稳定性。

Method: 提出基于\textit{适应性}概念的三维框架：学习适应性、策略适应性和场景驱动适应性，为动态环境中的MARL评估提供结构化方法。

Result: 该框架超越传统基准测试，支持对MARL算法在动态配置下的性能进行更原则性评估，推动算法向实际应用靠拢。

Conclusion: 通过适应性视角的系统化评估，本研究为开发适用于现实动态多智能体系统的MARL算法提供了理论基础和实践指导。

Abstract: Multi-Agent Reinforcement Learning (MARL) has shown clear effectiveness in
coordinating multiple agents across simulated benchmarks and constrained
scenarios. However, its deployment in real-world multi-agent systems (MAS)
remains limited, primarily due to the complex and dynamic nature of such
environments. These challenges arise from multiple interacting sources of
variability, including fluctuating agent populations, evolving task goals, and
inconsistent execution conditions. Together, these factors demand that MARL
algorithms remain effective under continuously changing system configurations
and operational demands. To better capture and assess this capacity for
adjustment, we introduce the concept of \textit{adaptability} as a unified and
practically grounded lens through which to evaluate the reliability of MARL
algorithms under shifting conditions, broadly referring to any changes in the
environment dynamics that may occur during learning or execution. Centred on
the notion of adaptability, we propose a structured framework comprising three
key dimensions: learning adaptability, policy adaptability, and scenario-driven
adaptability. By adopting this adaptability perspective, we aim to support more
principled assessments of MARL performance beyond narrowly defined benchmarks.
Ultimately, this survey contributes to the development of algorithms that are
better suited for deployment in dynamic, real-world multi-agent systems.

</details>


### [158] [Introducing the Swiss Food Knowledge Graph: AI for Context-Aware Nutrition Recommendation](https://arxiv.org/abs/2507.10156)
*Lubnaa Abdur Rahman,Ioannis Papathanail,Stavroula Mougiakakou*

Main category: cs.AI

TL;DR: 本文介绍了瑞士食品知识图谱（SwissFKG），首个整合食谱、成分、替代品、营养数据、饮食限制、过敏原信息及国家营养指南的资源，并通过LLM增强图谱内容，为下一代饮食评估工具奠定基础。


<details>
  <summary>Details</summary>
Motivation: 现有自动饮食评估系统常忽略非视觉因素（如成分替代对营养的影响）及个体饮食需求（如过敏、文化习惯）。瑞士虽提供食品信息，但分散且缺乏整合。

Method: 构建SwissFKG图谱，采用LLM驱动的增强流程填充数据，并首次对四个现成LLM（<70B参数）进行食品知识增强基准测试。开发Graph-RAG应用展示图谱如何辅助LLM回答营养查询。

Result: LLM能有效丰富图谱营养信息。SwissFKG不仅提供食谱推荐，还包含成分级信息（如过敏原、饮食限制）及营养指南。Graph-RAG验证了图谱增强LLM回答用户特定查询的能力。

Conclusion: SwissFKG融合视觉、情境与文化维度，为新一代饮食评估工具提供了基础，未来可支持更全面的个性化营养分析。

Abstract: AI has driven significant progress in the nutrition field, especially through
multimedia-based automatic dietary assessment. However, existing automatic
dietary assessment systems often overlook critical non-visual factors, such as
recipe-specific ingredient substitutions that can significantly alter
nutritional content, and rarely account for individual dietary needs, including
allergies, restrictions, cultural practices, and personal preferences. In
Switzerland, while food-related information is available, it remains
fragmented, and no centralized repository currently integrates all relevant
nutrition-related aspects within a Swiss context. To bridge this divide, we
introduce the Swiss Food Knowledge Graph (SwissFKG), the first resource, to our
best knowledge, to unite recipes, ingredients, and their substitutions with
nutrient data, dietary restrictions, allergen information, and national
nutrition guidelines under one graph. We establish a LLM-powered enrichment
pipeline for populating the graph, whereby we further present the first
benchmark of four off-the-shelf (<70 B parameter) LLMs for food knowledge
augmentation. Our results demonstrate that LLMs can effectively enrich the
graph with relevant nutritional information. Our SwissFKG goes beyond recipe
recommendations by offering ingredient-level information such as allergen and
dietary restriction information, and guidance aligned with nutritional
guidelines. Moreover, we implement a Graph-RAG application to showcase how the
SwissFKG's rich natural-language data structure can help LLM answer
user-specific nutrition queries, and we evaluate LLM-embedding pairings by
comparing user-query responses against predefined expected answers. As such,
our work lays the foundation for the next generation of dietary assessment
tools that blend visual, contextual, and cultural dimensions of eating.

</details>


### [159] [Should We Ever Prefer Decision Transformer for Offline Reinforcement Learning?](https://arxiv.org/abs/2507.10174)
*Yumi Omori,Zixuan Dong,Keith Ross*

Main category: cs.AI

TL;DR: 本文通过实验比较了基于Transformer的决策转换器(DT)与基于MLP的过滤行为克隆(FBC)在稀疏奖励环境中的表现，发现FBC不仅性能相当或更优，且更简单高效，质疑DT的适用性。


<details>
  <summary>Details</summary>
Motivation: 针对决策转换器(DT)在离线强化学习中的流行，研究旨在验证其在稀疏奖励环境下是否真正优于传统方法，特别是与过滤行为克隆(FBC)的对比。

Method: 在机器人操作任务(Robomimic)和运动基准(D4RL)上，对比DT与FBC的表现。FBC方法仅过滤低效轨迹后执行标准行为克隆，流程简单且计算高效。

Result: 实验表明FBC在稀疏奖励环境中表现与DT相当或更优，同时所需训练数据更少、计算成本更低。这与DT支持者的主张相矛盾。

Conclusion: 结合先前研究指出DT在密集奖励环境中亦无优势，作者质疑DT的适用性，提出\"DT是否真的有必要？\"的核心问题。

Abstract: In recent years, extensive work has explored the application of the
Transformer architecture to reinforcement learning problems. Among these,
Decision Transformer (DT) has gained particular attention in the context of
offline reinforcement learning due to its ability to frame return-conditioned
policy learning as a sequence modeling task. Most recently, Bhargava et al.
(2024) provided a systematic comparison of DT with more conventional MLP-based
offline RL algorithms, including Behavior Cloning (BC) and Conservative
Q-Learning (CQL), and claimed that DT exhibits superior performance in
sparse-reward and low-quality data settings.
  In this paper, through experimentation on robotic manipulation tasks
(Robomimic) and locomotion benchmarks (D4RL), we show that MLP-based Filtered
Behavior Cloning (FBC) achieves competitive or superior performance compared to
DT in sparse-reward environments. FBC simply filters out low-performing
trajectories from the dataset and then performs ordinary behavior cloning on
the filtered dataset. FBC is not only very straightforward, but it also
requires less training data and is computationally more efficient. The results
therefore suggest that DT is not preferable for sparse-reward environments.
From prior work, arguably, DT is also not preferable for dense-reward
environments. Thus, we pose the question: Is DT ever preferable?

</details>


### [160] [Survey for Categorising Explainable AI Studies Using Data Analysis Task Frameworks](https://arxiv.org/abs/2507.10208)
*Hamzah Ziadeh,Hendrik Knoche*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Research into explainable artificial intelligence (XAI) for data analysis
tasks suffer from a large number of contradictions and lack of concrete design
recommendations stemming from gaps in understanding the tasks that require AI
assistance. In this paper, we drew on multiple fields such as visual analytics,
cognition, and dashboard design to propose a method for categorising and
comparing XAI studies under three dimensions: what, why, and who. We identified
the main problems as: inadequate descriptions of tasks, context-free studies,
and insufficient testing with target users. We propose that studies should
specifically report on their users' domain, AI, and data analysis expertise to
illustrate the generalisability of their findings. We also propose study
guidelines for designing and reporting XAI tasks to improve the XAI community's
ability to parse the rapidly growing field. We hope that our contribution can
help researchers and designers better identify which studies are most relevant
to their work, what gaps exist in the research, and how to handle contradictory
results regarding XAI design.

</details>


### [161] [Toward Real-World Table Agents: Capabilities, Workflows, and Design Principles for LLM-based Table Intelligence](https://arxiv.org/abs/2507.10281)
*Jiaming Tian,Liyao Li,Wentao Ye,Haobo Wang,Lingxin Wang,Lihua Yu,Zujie Ren,Gang Chen,Junbo Zhao*

Main category: cs.AI

TL;DR: 本文综述了基于LLM的表格代理技术，针对现实场景中的噪声、结构异质性和语义复杂性，提出了五大核心能力评估框架，并揭示了开源模型在Text-to-SQL任务中的性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注洁净学术数据集，而现实表格任务常面临噪声、结构异质性和语义复杂性等挑战，亟需系统化解决方案。

Method: 定义五大核心能力（C1:表格结构理解，C2:表格与查询语义理解，C3:表格检索与压缩，C4:可追溯执行推理，C5:跨领域泛化），并以Text-to-SQL代理为例进行深度分析。

Result: 发现开源模型在真实场景Text-to-SQL任务中存在显著性能落差，需提升鲁棒性、泛化能力和效率。

Conclusion: 提出实用建议以增强LLM表格代理在真实场景的应用能力，强调需突破学术基准与工业落地的鸿沟。

Abstract: Tables are fundamental in domains such as finance, healthcare, and public
administration, yet real-world table tasks often involve noise, structural
heterogeneity, and semantic complexity--issues underexplored in existing
research that primarily targets clean academic datasets. This survey focuses on
LLM-based Table Agents, which aim to automate table-centric workflows by
integrating preprocessing, reasoning, and domain adaptation. We define five
core competencies--C1: Table Structure Understanding, C2: Table and Query
Semantic Understanding, C3: Table Retrieval and Compression, C4: Executable
Reasoning with Traceability, and C5: Cross-Domain Generalization--to analyze
and compare current approaches. In addition, a detailed examination of the
Text-to-SQL Agent reveals a performance gap between academic benchmarks and
real-world scenarios, especially for open-source models. Finally, we provide
actionable insights to improve the robustness, generalization, and efficiency
of LLM-based Table Agents in practical settings.

</details>


### [162] [Instance space analysis of the capacitated vehicle routing problem](https://arxiv.org/abs/2507.10397)
*Alessandra M. M. M. Gouvêa,Nuno Paulos,Eduardo Uchoa e Mariá C. V. Nascimento*

Main category: cs.AI

TL;DR: 本文通过实例空间分析（ISA）方法，结合DIMACS挑战赛数据集，揭示了CVRP问题实例特征与元启发式算法性能间的复杂关系，并提供了便于新实例分析的投影矩阵。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决CVRP领域中实例特征与元启发式算法（MH）性能间微妙关系理解的挑战，推动该领域研究进展。

Method: 采用实例空间分析（ISA）框架，结合DIMACS第12届车辆路径挑战赛数据集，通过PRELIM、SIFTED和PILOT三阶段（运用降维与机器学习方法）构建二维实例空间投影。

Result: 识别出23个关键实例特征，建立了反映实例结构与MH行为关系的二维投影空间，并提供了可扩展新实例分析的投影矩阵。

Conclusion: 该研究为CVRP领域提供了创新的实例分析方法，其投影矩阵工具显著提升了后续研究的可扩展性与可比性。

Abstract: This paper seeks to advance CVRP research by addressing the challenge of
understanding the nuanced relationships between instance characteristics and
metaheuristic (MH) performance. We present Instance Space Analysis (ISA) as a
valuable tool that allows for a new perspective on the field. By combining the
ISA methodology with a dataset from the DIMACS 12th Implementation Challenge on
Vehicle Routing, our research enabled the identification of 23 relevant
instance characteristics. Our use of the PRELIM, SIFTED, and PILOT stages,
which employ dimensionality reduction and machine learning methods, allowed us
to create a two-dimensional projection of the instance space to understand how
the structure of instances affect the behavior of MHs. A key contribution of
our work is that we provide a projection matrix, which makes it straightforward
to incorporate new instances into this analysis and allows for a new method for
instance analysis in the CVRP field.

</details>


### [163] [SentiDrop: A Multi Modal Machine Learning model for Predicting Dropout in Distance Learning](https://arxiv.org/abs/2507.10421)
*Meriem Zerkouk,Miloud Mihoubi,Belkacem Chikhaoui*

Main category: cs.AI

TL;DR: 本文提出了一种结合BERT情感分析和XGBoost多源数据建模的新方法，用于预测远程教育中的学生辍学风险，准确率达84\%，优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 远程教育中的辍学问题严重，早期预测对干预至关重要。现有研究强调需整合社会人口、行为数据和情感分析等多源信息以提高预测精度。

Method: 使用BERT模型对学生评论进行细粒度情感分析，结合XGBoost处理社会人口和行为数据，通过特征重要性选择关键特征进行融合建模。

Result: 模型在未见数据上达到84\%的准确率（基线82\%），且在精确率和F1分数等指标上表现更优。

Conclusion: 该模型可作为开发个性化防辍策略的重要工具，有效提升学生持续学习率。

Abstract: School dropout is a serious problem in distance learning, where early
detection is crucial for effective intervention and student perseverance.
Predicting student dropout using available educational data is a widely
researched topic in learning analytics. Our partner's distance learning
platform highlights the importance of integrating diverse data sources,
including socio-demographic data, behavioral data, and sentiment analysis, to
accurately predict dropout risks. In this paper, we introduce a novel model
that combines sentiment analysis of student comments using the Bidirectional
Encoder Representations from Transformers (BERT) model with socio-demographic
and behavioral data analyzed through Extreme Gradient Boosting (XGBoost). We
fine-tuned BERT on student comments to capture nuanced sentiments, which were
then merged with key features selected using feature importance techniques in
XGBoost. Our model was tested on unseen data from the next academic year,
achieving an accuracy of 84\%, compared to 82\% for the baseline model.
Additionally, the model demonstrated superior performance in other metrics,
such as precision and F1-score. The proposed method could be a vital tool in
developing personalized strategies to reduce dropout rates and encourage
student perseverance

</details>


### [164] [Acquiring and Adapting Priors for Novel Tasks via Neural Meta-Architectures](https://arxiv.org/abs/2507.10446)
*Sudarshan Babu*

Main category: cs.AI

TL;DR: 本文提出了一种在数据稀缺领域（如计算化学、计算免疫学和医学影像）中高效获取先验知识的架构设计，通过神经记忆和超网络技术实现少量样本下的快速适应，并在3D场景生成、分割及分子属性预测中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统迁移学习依赖大规模预训练模型，但在数据稀缺领域无法应用。本研究旨在解决这一挑战，探索在有限数据下高效获取和迁移先验知识的方法。

Method: 1. 使用神经记忆实现非平稳分布的少量样本适应；2. 设计超网络结合MAML获取更通用的先验；3. 将超网络应用于3D场景生成与分割；4. 改造分子生成方法作为预训练框架提升属性预测。

Result: 1. 超网络在少量3D场景训练下实现高效文本生成3D；2. 成功迁移先验完成有限数据的新场景分割；3. 分子预训练框架显著提升计算免疫学的属性预测精度。

Conclusion: 该研究为数据稀缺领域提供了可行的先验获取方案，通过神经记忆和超网络设计突破了传统迁移学习的限制，在多个跨领域任务中验证了其高效性与通用性。

Abstract: The ability to transfer knowledge from prior experiences to novel tasks
stands as a pivotal capability of intelligent agents, including both humans and
computational models. This principle forms the basis of transfer learning,
where large pre-trained neural networks are fine-tuned to adapt to downstream
tasks. Transfer learning has demonstrated tremendous success, both in terms of
task adaptation speed and performance. However there are several domains where,
due to lack of data, training such large pre-trained models or foundational
models is not a possibility - computational chemistry, computational
immunology, and medical imaging are examples. To address these challenges, our
work focuses on designing architectures to enable efficient acquisition of
priors when large amounts of data are unavailable. In particular, we
demonstrate that we can use neural memory to enable adaptation on
non-stationary distributions with only a few samples. Then we demonstrate that
our hypernetwork designs (a network that generates another network) can acquire
more generalizable priors than standard networks when trained with Model
Agnostic Meta-Learning (MAML). Subsequently, we apply hypernetworks to 3D scene
generation, demonstrating that they can acquire priors efficiently on just a
handful of training scenes, thereby leading to faster text-to-3D generation. We
then extend our hypernetwork framework to perform 3D segmentation on novel
scenes with limited data by efficiently transferring priors from earlier viewed
scenes. Finally, we repurpose an existing molecular generative method as a
pre-training framework that facilitates improved molecular property prediction,
addressing critical challenges in computational immunology

</details>


### [165] [DeepResearch$^{\text{Eco}}$: A Recursive Agentic Workflow for Complex Scientific Question Answering in Ecology](https://arxiv.org/abs/2507.10522)
*Jennifer D'Souza,Endres Keno Sander,Andrei Aioanei*

Main category: cs.AI

TL;DR: DeepResearch$^{\text{Eco}}$是一种基于LLM的新型自动化科研合成系统，通过递归、深度和广度可控的探索提升文献检索的多样性和精确性，在生态学研究中实现了显著更高的文献整合效率和分析深度。


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成流程缺乏用户可控性、透明推理和参数化配置能力，难以实现高通量的领域证据整合与分析严谨性的平衡。

Method: 开发支持递归探索的代理式LLM系统，通过参数驱动配置实现可调控的文献合成过程，保持分析严谨性的同时增强检索多样性。

Result: 在49个生态学问题的测试中，系统实现最高21倍的文献整合量提升，每千字整合文献量增加14.9倍；高参数设置下达到专家级分析深度和上下文多样性。

Conclusion: DeepResearch$^{\text{Eco}}$为科学文献合成提供了可配置、高透明度的解决方案，其参数化设计显著提升了研究效率和分析质量。

Abstract: We introduce DeepResearch$^{\text{Eco}}$, a novel agentic LLM-based system
for automated scientific synthesis that supports recursive, depth- and
breadth-controlled exploration of original research questions -- enhancing
search diversity and nuance in the retrieval of relevant scientific literature.
Unlike conventional retrieval-augmented generation pipelines, DeepResearch
enables user-controllable synthesis with transparent reasoning and
parameter-driven configurability, facilitating high-throughput integration of
domain-specific evidence while maintaining analytical rigor. Applied to 49
ecological research questions, DeepResearch achieves up to a 21-fold increase
in source integration and a 14.9-fold rise in sources integrated per 1,000
words. High-parameter settings yield expert-level analytical depth and
contextual diversity.
  Source code available at: https://github.com/sciknoworg/deep-research.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [166] [Multiplicative Modular Nim (MuM)](https://arxiv.org/abs/2507.08830)
*Satyam Tyagi*

Main category: cs.DM

TL;DR: 本文介绍了乘法模Nim游戏(MuM)，一种将传统Nim游戏的异或和替换为堆大小乘法模m的新变体。通过建立完整的游戏理论，包括素数模数的直接分析、类似Sprague-Grundy定理的mumber概念证明，以及复合模数的中国剩余定理分解，作者首次系统分析了这种非加法组合游戏代数。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于两个层面：一是构建新型非加法组合游戏理论体系；二是通过有限域扩展为AES加密算法中的S盒代数提供更直观的教学工具。

Method: 采用Bouton式分析方法处理素数模数；定义乘法mex递归的mumber值；通过中国剩余定理分解复合模数；引入规范堆模型解决有限域F(pn)中的多对一映射问题。

Result: 核心成果包括：1) 证明mumber等价于堆积模m；2) 展示游戏并集时mumber的模乘组合特性；3) 实现复合模数的质数幂因子子游戏分解；4) 建立有限域版本的游戏代数体系。

Conclusion: 该研究首次系统构建了乘法模Nim游戏的完整理论框架，其非加性的mumber代数特性与有限域扩展为组合数学和密码学教育提供了新的理论工具与实践范式。

Abstract: We introduce Multiplicative Modular Nim (MuM), a variant of Nim in which the
traditional nim-sum is replaced by heap-size multiplication modulo m. We
establish a complete theory for this game, beginning with a direct,
Bouton-style analysis for prime moduli. Our central result is an analogue of
the Sprague-Grundy theorem, where we define a game-theoretic value, the mumber,
for each position via a multiplicative mex recursion. We prove that these
mumbers are equivalent to the heap-product modulo m, and show that for
disjunctive sums of games, they combine via modular multiplication in contrast
to the XOR-sum of classical nimbers. For composite moduli, we show that MuM
decomposes via the Chinese Remainder Theorem into independent subgames
corresponding to its prime-power factors. We extend the game to finite fields
F(pn), motivated by the pedagogical need to make the algebra of the AES S-box
more accessible. We demonstrate that a sound game in this domain requires a
Canonical Heap Model to resolve the many-to-one mapping from integer heaps to
field elements. To our knowledge, this is the first systematic analysis of a
multiplicative modular variant of Nim and its extension into a complete,
non-additive combinatorial game algebra.

</details>


### [167] [m-Eternal Domination and Variants on Some Classes of Finite and Infinite Graphs](https://arxiv.org/abs/2507.09283)
*Tiziana Calamoneri,Federico Corò,Neeldhara Misra,Saraswati G. Nanoti,Giacomo Paesani*

Main category: cs.DM

TL;DR: 研究了m-永恒支配问题及其变体在特殊图类上的NP难解性，并在四种无限规则网格上建立了支配与m-永恒支配问题的紧致界。


<details>
  <summary>Details</summary>
Motivation: 探讨图论中m-永恒支配问题的计算复杂性及其在不同图结构上的表现，特别是无限规则网格中的精确解。

Method: 通过两方博弈模型（防御者与攻击者）定义问题，分析NP难解性，并在方形、八角形、六边形及三角形网格上进行结构性证明。

Result: 证明m-永恒支配问题及其变体在特殊图类上为NP难问题，并在四种无限网格中确定了m-永恒支配数的紧致上下界。

Conclusion: 该研究不仅深化了对m-永恒支配问题复杂性的理解，还为无限规则网格中的支配策略提供了理论保障。

Abstract: We study the m-Eternal Domination problem, which is the following two-player
game between a defender and an attacker on a graph: initially, the defender
positions k guards on vertices of the graph; the game then proceeds in turns
between the defender and the attacker, with the attacker selecting a vertex and
the defender responding to the attack by moving a guard to the attacked vertex.
The defender may move more than one guard on their turn, but guards can only
move to neighboring vertices. The defender wins a game on a graph G with k
guards if the defender has a strategy such that at every point of the game the
vertices occupied by guards form a dominating set of G and the attacker wins
otherwise. The m-eternal domination number of a graph G is the smallest value
of k for which (G,k) is a defender win.
  We show that m-Eternal Domination is NP-hard, as well as some of its
variants, even on special classes of graphs. We also show structural results
for the Domination and m-Eternal Domination problems in the context of four
types of infinite regular grids: square, octagonal, hexagonal, and triangular,
establishing tight bounds.

</details>
