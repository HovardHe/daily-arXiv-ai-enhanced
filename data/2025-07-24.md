<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 4]
- [math.OC](#math.OC) [Total: 7]
- [math.NT](#math.NT) [Total: 9]
- [math.LO](#math.LO) [Total: 7]
- [math.HO](#math.HO) [Total: 1]
- [math.GM](#math.GM) [Total: 2]
- [math.CO](#math.CO) [Total: 15]
- [q-fin.CP](#q-fin.CP) [Total: 2]
- [cs.CR](#cs.CR) [Total: 23]
- [cs.AI](#cs.AI) [Total: 21]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [A Weighted Likelihood Approach Based on Statistical Data Depths](https://arxiv.org/abs/2507.16998)
*Claudio Agostinelli,Ayanendranath Basu,Giulia Bertagnolli,Arun Kumar Kuchibhotla*

Main category: math.ST

TL;DR: 本文提出了一种基于统计深度的加权似然估计方法，旨在获得稳健的参数估计。该方法通过调整数据点的权重来平衡估计的效率和稳健性，适用于高维数据且无需额外假设。


<details>
  <summary>Details</summary>
Motivation: 传统最大似然估计（MLE）在数据污染时表现不佳，而现有稳健估计方法在高维数据中可能失效。本文旨在提出一种既高效又稳健的估计方法，适用于高维场景。

Method: 通过引入统计深度权重调整标准似然方程，根据数据点相对于模型和样本的深度差异动态调整权重。差异接近零时视为正常点，差异大时降低其得分贡献。

Result: 所提估计量在无污染时与MLE具有相同的渐近效率，在污染情况下保持高度稳健性。即使数据维度随样本量增长，仍能保持理论性质，且无需密度函数的额外光滑性假设。

Conclusion: 该方法在多元正态模型中展现了优异的稳健性，并通过实际数据和模拟实验验证了其有效性。相比传统最小散度估计，在高维场景中更具优势。

Abstract: We propose a general approach to construct weighted likelihood estimating
equations with the aim of obtaining robust parameter estimates. We modify the
standard likelihood equations by incorporating a weight that reflects the
statistical depth of each data point relative to the model, as opposed to the
sample. An observation is considered regular when the corresponding difference
of these two depths is close to zero. When this difference is large the
observation score contribution is downweighted. We study the asymptotic
properties of the proposed estimator, including consistency and asymptotic
normality, for a broad class of weight functions. In particular, we establish
asymptotic normality under the standard regularity conditions typically assumed
for the maximum likelihood estimator (MLE). Our weighted likelihood estimator
achieves the same asymptotic efficiency as the MLE in the absence of
contamination, while maintaining a high degree of robustness in contaminated
settings. In stark contrast to the traditional minimum divergence/disparity
estimators, our results hold even if the dimension of the data diverges with
the sample size, without requiring additional assumptions on the existence or
smoothness of the underlying densities. We also derive the finite sample
breakdown point of our estimator for both location and scatter matrix in the
elliptically symmetric model. Detailed results and examples are presented for
robust parameter estimation in the multivariate normal model. Robustness is
further illustrated using two real data sets and a Monte Carlo simulation
study.

</details>


### [2] [Approximation Techniques for the Reconstruction of the Probability Measure and the Coupling Parameters in a Curie-Weiss Model for Large Populations](https://arxiv.org/abs/2507.17073)
*Miguel Ballesteros,Ivan Naumkin,Gabor Toth*

Main category: math.ST

TL;DR: 该研究通过大群体渐近近似方法，提出了一种计算成本低且一致的耦合参数估计器，用于多群居里-韦斯模型，适用于无交互群体情况，并在社会学、政治学等领域具有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 居里-韦斯模型最初用于统计力学中的相变研究，后扩展至社会科学中多智能体交互现象的建模。传统最大似然法在重建模型概率测度时面临分区函数计算复杂度随群体规模指数增长的问题。

Method: 研究采用大群体渐近近似方法，针对无交互群体的多群居里-韦斯模型，推导了概率分布相关矩的近似表达式，从而构建耦合参数估计器。

Result: 所得估计器计算成本低且恒定（与群体规模无关），具有一致性（假设群体足够大）、渐近正态性，并满足大偏差原理。耦合参数为社会凝聚力提供了自然度量。

Conclusion: 该估计器可应用于政治学、社会学、自动化投票等领域，用于量化社会凝聚力。研究还探讨了两层投票系统中最优权重的估计问题。

Abstract: The Curie-Weiss model, originally used to study phase transitions in
statistical mechanics, has been adapted to model phenomena in social sciences
where many agents interact with each other. Reconstructing the probability
measure of a Curie-Weiss model via the maximum likelihood method runs into the
problem of computing the partition function which scales exponentially with the
population. We study the estimation of the coupling parameters of a multi-group
Curie-Weiss model using large population asymptotic approximations for the
relevant moments of the probability distribution in the case that there are no
interactions between groups. As a result, we obtain an estimator which can be
calculated at a low and constant computational cost for any size of the
population. The estimator is consistent (under the added assumption that the
population is large enough), asymptotically normal, and satisfies large
deviation principles. The estimator is potentially useful in political science,
sociology, automated voting, and in any application where the degree of social
cohesion in a population has to be identified. The Curie-Weiss model's coupling
parameters provide a natural measure of social cohesion. We discuss the problem
of estimating the optimal weights in two-tier voting systems.

</details>


### [3] [The Joint Asymptotic Distribution of Entropy and Complexity](https://arxiv.org/abs/2507.17625)
*Angelika Silbernagel,Christian Weiß*

Main category: math.ST

TL;DR: 本文推导了弱依赖条件下序数模式频率的渐近分布，研究了长程协方差矩阵，并通过分析和模拟方法探讨了熵-复杂度对的渐近分布，提出了序列依赖性检验并评估其性能。


<details>
  <summary>Details</summary>
Motivation: 研究序数模式频率的渐近分布及其在时间序列分析中的应用，特别是熵-复杂度对的分布特性，以提供更准确的统计工具。

Method: 通过分析移动平均、高斯和广义抛硬币过程，结合模拟方法研究长程协方差矩阵，推导熵-复杂度对的渐近分布，并区分均匀和非均匀序数模式分布。

Result: 得到了两种不同的极限定理，提出了序列依赖性检验并验证了其有限样本性能，利用渐近结果近似估计熵-复杂度对的不确定性。

Conclusion: 研究为时间序列分析提供了新的统计工具和方法，特别是在熵-复杂度对的应用和序列依赖性检验方面具有重要价值。

Abstract: We derive the asymptotic distribution of ordinal-pattern frequencies under
weak dependence conditions and investigate the long-run covariance matrix not
only analytically for moving-average, Gaussian, and the novel generalized
coin-tossing processes, but also approximately by a simulation-based approach.
Then, we deduce the asymptotic distribution of the entropy-complexity pair,
which emerged as a popular tool for summarizing the time-series dynamics. Here,
we make the necessary distinction between a uniform and a non-uniform ordinal
pattern distribution and, thus, obtain two different limit theorems. On this
basis, we consider a test for serial dependence and check its finite-sample
performance. Moreover, we use our asymptotic results to approximate the
estimation uncertainty of entropy-complexity pairs.

</details>


### [4] [Frequentist Asymptotics of Variational Laplace](https://arxiv.org/abs/2507.17697)
*Janis Keck*

Main category: math.ST

TL;DR: 本文研究了变分拉普拉斯方法在频率派渐近统计理论下的性质，证明其在两点估计中具有渐近一致性和有效性，并推导了保证这些性质的通用条件。


<details>
  <summary>Details</summary>
Motivation: 变分推断作为贝叶斯后验近似框架被广泛应用，但其迭代更新方案（变分拉普拉斯）的理论性质尚未系统研究。论文旨在通过频率派渐近理论评估该方法的统计特性。

Method: 采用频率派渐近统计框架，分析变分拉普拉斯生成的点估计的极限行为；通过全变差距离研究分布收敛性；在玩具模型中进行仿真实验验证。

Result: 两点估计场景下，变分拉普拉斯具有渐近一致性和有效性；推导出保证这些性质的充分条件；分布收敛性分析连接了变分推断与经典贝叶斯后验理论。

Conclusion: 理论分析与仿真实验表明，变分拉普拉斯在频率派框架下具有良好统计性质，为认知神经科学领域的应用提供了理论支撑。

Abstract: Variational inference is a general framework to obtain approximations to the
posterior distribution in a Bayesian context. In essence, variational inference
entails an optimization over a given family of probability distributions to
choose the member of this family best approximating the posterior. Variational
Laplace, an iterative update scheme motivated by this objective, is widely used
in different contexts in the cognitive neuroscience community. However, until
now, the theoretical properties of this scheme have not been systematically
investigated. Here, we study variational Laplace in the light of frequentist
asymptotic statistics. Asymptotical frequentist theory enables one to judge the
quality of point estimates by their limit behaviour. We apply this framework to
find that point estimates generated by variational Laplace enjoy the desirable
properties of asymptotic consistency and efficiency in two toy examples.
Furthermore, we derive conditions that are sufficient to establish these
properties in a general setting. Besides of point estimates, we also study the
frequentist convergence of distributions in the sense of total variation
distance, which may be useful to relate variational Laplace both to recent
findings regarding variational inference as well as to classical frequentist
considerations on the Bayesian posterior. Finally, to illustrate the validity
of our theoretical considerations, we conduct simulation experiments in our
study examples.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [5] [The Generalized Matrix Separation Problem: Algorithms](https://arxiv.org/abs/2507.17069)
*Xuemei Chen,Owen Deen*

Main category: math.OC

TL;DR: 本文详细阐述了解决广义矩阵分离问题的迭代算法，提出了一种结合$\ell_1$范数与核范数的凸优化方法，并针对不同结构的矩阵$H$提出了高效实现策略，特别是通过预条件技术显著提升了算法性能。


<details>
  <summary>Details</summary>
Motivation: 广义矩阵分离问题旨在从$M_0=L_0+HS_0$中恢复低秩矩阵$L_0$和稀疏矩阵$S_0$，本文旨在提供高效的算法实现及理论保证。

Method: 提出了一种基于$\ell_1$范数与核范数之和的凸优化问题，详细描述了迭代算法及计算过程，特别针对$H$为循环、可分或块结构的情况提出了高效实现策略，并引入了预条件技术。

Result: 数值实验表明，所提出的预条件技术显著提高了算法的效率、精度和鲁棒性，验证了方法的有效性。

Conclusion: 本文不仅提供了算法实现的详细手册，还为预条件策略提供了理论保证，数值结果证明了所提方法的高效性和实用性。

Abstract: When given a generalized matrix separation problem, which aims to recover a
low rank matrix $L_0$ and a sparse matrix $S_0$ from $M_0=L_0+HS_0$, the work
\cite{CW25} proposes a novel convex optimization problem whose objective
function is the sum of the $\ell_1$-norm and nuclear norm. In this paper we
detail the iterative algorithms and its associated computations for solving
this convex optimization problem. We present various efficient implementation
strategies, with attention to practical cases where $H$ is circulant,
separable, or block structured. Notably, we propose a preconditioning technique
that drastically improved the performance of our algorithms in terms of
efficiency, accuracy, and robustness. While this paper serves as an
illustrative algorithm implementation manual, we also provide theoretical
guarantee for our preconditioning strategy. Numerical results illustrate the
effectiveness of the proposed approach.

</details>


### [6] [Stochastically Structured Reservoir Computers for Financial and Economic System Identification](https://arxiv.org/abs/2507.17115)
*Lendy Banegas,Fredy Vides*

Main category: math.OC

TL;DR: 本文提出了一种基于随机结构储层计算机（SSRCs）的金融经济系统识别与模拟方法，通过结构保持嵌入和图信息耦合矩阵增强模型可解释性，并通过约束优化确保模型满足随机与结构约束。


<details>
  <summary>Details</summary>
Motivation: 现有金融经济系统模型在捕捉非线性动态和保持可解释性方面存在不足，需要一种能同时满足随机性与结构性约束的新方法。

Method: 采用随机结构储层计算机框架，结合结构保持嵌入和图信息耦合矩阵建模代理间动态，并通过约束优化算法确保模型合规性。

Result: 两个案例研究（资源竞争行为模型和区域通胀网络动态）表明，该方法能有效捕捉复杂非线性模式，并在不确定性下实现可解释预测分析。

Conclusion: SSRC框架为金融经济系统提供了兼具预测准确性和结构可解释性的建模工具，特别适用于多代理非线性动态场景。

Abstract: This paper introduces a methodology for identifying and simulating financial
and economic systems using stochastically structured reservoir computers
(SSRCs). The proposed framework leverages structure-preserving embeddings and
graph-informed coupling matrices to model inter-agent dynamics with enhanced
interpretability. A constrained optimization scheme ensures that the learned
models satisfy both stochastic and structural constraints. Two empirical case
studies, a dynamic behavioral model of resource competition among agents, and
regional inflation network dynamics, illustrate the effectiveness of the
approach in capturing and anticipating complex nonlinear patterns and enabling
interpretable predictive analysis under uncertainty.

</details>


### [7] [Frank-Wolfe algorithm for star-convex functions](https://arxiv.org/abs/2507.17272)
*R. Diaz Millan,Orizon Pereira Ferreira,Julien Ugon*

Main category: math.OC

TL;DR: 本文研究了Frank-Wolfe算法在星凸函数上的应用，证明了在多种步长规则下仍保持$\mathcal{O}(1/k)$的迭代复杂度，扩展了经典凸优化结果。


<details>
  <summary>Details</summary>
Motivation: 为了将经典凸优化复杂度结果推广到非凸函数，研究聚焦于具有Lipschitz连续梯度的星凸函数，这类函数虽非凸但保留了关键几何特性。

Method: 采用Frank-Wolfe算法，分析其在星凸函数上的表现，测试了递减步长、Armijo型步长和基于Lipschitz的步长规则，其中前两种无需预知Lipschitz或曲率常数。

Result: 在星凸性假设下，无论目标函数值还是对偶间隙均达到$\mathcal{O}(1/k)$的迭代复杂度界限，证明算法在非凸环境下仍保持最优复杂度保证。

Conclusion: 研究表明Frank-Wolfe方法能超越凸优化框架，在更广泛的星凸函数类中维持最优复杂度特性，为算法应用提供了理论扩展。

Abstract: We study the Frank-Wolfe algorithm for minimizing a differentiable function
with Lipschitz continuous gradient over a compact convex set. To extend
classical complexity bounds to certain non-convex functions, we focus on the
class of \emph{star-convex functions}, which retain essential geometric
properties despite the lack of convexity. We establish iteration-complexity
bounds of $\mathcal{O}(1/k)$ for both the objective values and the duality gap
under star-convexity, using diminishing, Armijo-type, and Lipschitz-based
stepsize rules. Notably, the diminishing and Armijo strategies do not require
prior knowledge of Lipschitz or curvature constants. These results demonstrate
that the Frank-Wolfe method preserves optimal complexity guarantees beyond the
convex setting.

</details>


### [8] [Investigating State-of-the-Art Planning Strategies for Electric Vehicle Charging Infrastructures in Coupled Transport and Power Networks: A Comprehensive Review](https://arxiv.org/abs/2507.17277)
*Jinhao Li,Arlena Chew,Hao Wang*

Main category: math.OC

TL;DR: 本文综述了全球电动汽车充电基础设施（EVCI）规划的现状与方法，指出推广中的三大障碍，并探讨了不同充电桩类型及规划模型的应用。


<details>
  <summary>Details</summary>
Motivation: 电动汽车（EVs）作为减少温室气体排放的关键解决方案，其充电基础设施（EVCI）的规划与建设需跟上EV普及速度。然而，全球范围内EVCI建设进度滞后，主要由于充电服务不足、公共设施利用率低及电网整合困难。

Method: 通过分析中国、美国和欧盟等主要EV市场的实践经验，探讨了1级、2级和3级充电桩的地理应用差异，并系统评估了基于节点和流量的EVCI规划模型（如集合覆盖、最大覆盖、流量捕获和流量补充模型）。

Result: 研究发现，全球EVCI建设滞后于预期，主要受限于充电服务不足、公共设施利用率低及电网整合挑战。不同充电桩类型和规划模型需因地制宜，以满足多样化的充电需求。

Conclusion: 本文指出EV充电需求动态建模及车辆电气化与电网脱碳协调等研究空白，呼吁进一步贡献以推动EVCI规划的进步。

Abstract: Electric vehicles (EVs) have emerged as a pivotal solution to reduce
greenhouse gas emissions paving a pathway to net zero. As the adoption of EVs
continues to grow, countries are proactively formulating systematic plans for
nationwide electric vehicle charging infrastructure (EVCI) to keep pace with
the accelerating shift towards EVs. This comprehensive review aims to
thoroughly examine current global practices in EVCI planning and explore
state-of-the-art methodologies for designing EVCI planning strategies. Despite
remarkable efforts by influential players in the global EV market, such as
China, the United States, and the European Union, the progress in EVCI rollout
has been notably slower than anticipated in the rest of the world. This delay
can be attributable to three major impediments: inadequate EVCI charging
services, low utilization rates of public EVCI facilities, and the non-trivial
integration of EVCI into the electric grid. This review dissects the interests
of these stakeholders, clarifying their respective roles and expectations in
the context of EVCI planning. This review also provides insights into level 1,
2, and 3 chargers with explorations of their applications in different
geographical locations for diverse EV charging patterns. Finally, a thorough
review of node-based and flow-based approaches to EV planning is presented. The
modeling of placing charging stations is broadly categorized into set coverage,
maximum coverage, flow-capturing, and flow-refueling location models. In
conclusion, this review identifies several research gaps, including the dynamic
modeling of EV charging demand and the coordination of vehicle electrification
with grid decarbonization. This paper calls for further contributions to bridge
these gaps and drive the advancement of EVCI planning.

</details>


### [9] [Scalable DC Optimization via Adaptive Frank-Wolfe Algorithms](https://arxiv.org/abs/2507.17545)
*Sebastian Pokutta*

Main category: math.OC

TL;DR: 本文提出了一种高效且可扩展的无投影算法，用于解决紧凑凸可行区域上的凸差函数最小化问题，结合了BPCG算法和自适应误差界技术。


<details>
  <summary>Details</summary>
Motivation: 研究如何在紧凑凸可行区域$P$上最小化光滑凸函数差$f(x) - g(x)$，其中$f$光滑且$g$满足Lipschitz连续，旨在降低计算开销并提升效率。

Method: 结合Blended Pairwise Conditional Gradients (BPCG)算法与热启动技术，并利用Maskan等人[2025]的自适应误差界，构建了一种无投影的约束DC优化框架。

Result: 实证表明，该方法能高效解决约束DC问题，具有较高的计算效率和可扩展性。

Conclusion: 通过整合先进Frank-Wolfe变体和自适应误差界，本文提出的算法在约束DC优化中实现了高效且可扩展的解决方案。

Abstract: We consider the problem of minimizing a difference of (smooth) convex
functions over a compact convex feasible region $P$, i.e., $\min_{x \in P} f(x)
- g(x)$, with smooth $f$ and Lipschitz continuous $g$. This computational study
builds upon and complements the framework of Maskan et al. [2025] by
integrating advanced Frank-Wolfe variants to reduce computational overhead. We
empirically show that constrained DC problems can be efficiently solved using a
combination of the Blended Pairwise Conditional Gradients (BPCG) algorithm
[Tsuji et al., 2022] with warm-starting and the adaptive error bound from
Maskan et al. [2025]. The result is a highly efficient and scalable
projection-free algorithm for constrained DC optimization.

</details>


### [10] [Sub-sampled Trust-Region Methods with Deterministic Worst-Case Complexity Guarantees](https://arxiv.org/abs/2507.17556)
*Max L. N. Goncalves,Geovani N. Grapiglia*

Main category: math.OC

TL;DR: 本文提出了一种用于解决有限和优化问题的子采样信赖域方法，通过自适应调整样本量降低计算成本，并建立了最坏情况下的迭代复杂度界限。


<details>
  <summary>Details</summary>
Motivation: 有限和优化问题在大规模计算中面临高昂的梯度与Hessian矩阵计算成本，需要开发高效的子采样策略以降低复杂度。

Method: 采用确定性自适应子采样策略近似目标函数的梯度与Hessian矩阵，结合信赖域框架设计新算法。

Result: 理论证明算法最多需$\mathcal{O}({\varepsilon_g}^{-2} )$次迭代获得一阶$\varepsilon_g$-近似稳定点，最多需$\mathcal{O}(\max\{\varepsilon_{g}^{-2}\varepsilon_{H}^{-1},\varepsilon_{H}^{-3}\})$次迭代获得二阶$(\varepsilon_g,\varepsilon_H)$-近似稳定点。数值实验验证了方法的有效性。

Conclusion: 所提出的自适应子采样技术显著降低了计算负担，同时保证了理论收敛性，为大规模有限和优化提供了实用解决方案。

Abstract: In this paper, we develop and analyze sub-sampled trust-region methods for
solving finite-sum optimization problems. These methods employ subsampling
strategies to approximate the gradient and Hessian of the objective function,
significantly reducing the overall computational cost. We propose a novel
adaptive procedure for deterministically adjusting the sample size used for
gradient (or gradient and Hessian) approximations. Furthermore, we establish
worst-case iteration complexity bounds for obtaining approximate stationary
points. More specifically, for a given $\varepsilon_g, \varepsilon_H\in (0,1)$,
it is shown that an $\varepsilon_g$-approximate first-order stationary point is
reached in at most $\mathcal{O}({\varepsilon_g}^{-2} )$ iterations, whereas an
$(\varepsilon_g,\varepsilon_H)$-approximate second-order stationary point is
reached in at most
$\mathcal{O}(\max\{\varepsilon_{g}^{-2}\varepsilon_{H}^{-1},\varepsilon_{H}^{-3}\})$
iterations. Finally, numerical experiments illustrate the effectiveness of our
new subsampling technique.

</details>


### [11] [A Compact Cycle Formulation for the Multiperiodic Event Scheduling Problem](https://arxiv.org/abs/2507.17566)
*Rolf Nelson van Lieshout,Niels Lindner*

Main category: math.OC

TL;DR: 本文研究了多周期事件调度问题（MPESP），这是对传统周期事件调度问题（PESP）的推广，允许每个事件以各自周期重复。通过基于循环的建模方法，解决了因缺乏全局周期带来的挑战，并在实际交通网络中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统PESP模型假设所有事件共享同一周期，而现实交通网络往往存在异构服务频率。MPESP通过允许事件拥有独立周期，更贴合实际需求，但缺乏全局周期带来了新的建模挑战。

Method: 提出了一种基于循环的MPESP建模框架，扩展了PESP的最强已知公式。该方法要求从满足特定结构属性的生成树中导出循环基，并将尖锐生成树概念推广到有根实例。同时证明了多周期类比下的循环周期性性质。

Result: 新模型在测试中表现优异，几乎所有实例（包括多个大规模现实交通网络）都能达到最优解或接近最优解，显著优于现有的基于弧的模型。

Conclusion: MPESP模型无需人工复制事件即可有效捕捉异构频率特性，展示了其在实践中的巨大潜力，为复杂交通网络调度提供了更灵活的解决方案。

Abstract: The Periodic Event Scheduling Problem (PESP) is a fundamental model in
periodic timetabling for public transport systems, assuming a common period
across all events. However, real-world networks often feature heterogeneous
service frequencies. This paper studies the Multiperiodic Event Scheduling
Problem (MPESP), a generalization of PESP that allows each event to recur at
its own individual period. While more expressive, MPESP presents new modeling
challenges due to the loss of a global period. We present a cycle-based
formulation for MPESP that extends the strongest known formulation for PESP
and, in contrast to existing approaches, is valid for any MPESP instance.
Crucially, the formulation requires a cycle basis derived from a spanning tree
satisfying specific structural properties, which we formalize and
algorithmically construct, extending the concept of sharp spanning trees to
rooted instances. We further prove a multiperiodic analogue of the cycle
periodicity property. Our new formulation solves nearly all tested instances,
including several large-scale real-world public transport networks, to
optimality or with small optimality gaps, dramatically outperforming existing
arc-based models. The results demonstrate the practical potential of MPESP in
capturing heterogeneous frequencies without resorting to artificial event
duplication.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [12] [Parameter Height bounds for the Zilber Pink conjecture for PEL types III and IV](https://arxiv.org/abs/2507.16827)
*Bijay Raj Bhatta*

Main category: math.NT

TL;DR: 本文在假设大Galois轨道猜想成立的前提下，证明了Zilber-Pink猜想对于不可约Hodge一般代数子簇$V \subset \mathcal{A}_g$与所有非$\mathbb{Z}$型简单PEL特殊子簇的交集成立，并针对Albert III型和IV型情形建立了参数高度界。


<details>
  <summary>Details</summary>
Motivation: 研究Zilber-Pink猜想在PEL型特殊子簇与Hodge一般子簇交集情形下的验证，特别是针对Albert III型和IV型情形发展Pila-Zannier方法的算术工具。

Method: 基于Daw和Orr 2023年关于带斜厄米形式格点的工作，采用大Galois轨道猜想作为前提条件，运用Pila-Zannier策略的算术化方法。

Result: 证明了非$\mathbb{Z}$型简单PEL特殊子簇与Hodge一般子簇交集的Zilber-Pink猜想，并首次建立了Albert III/IV型情形的参数高度界。

Conclusion: 该成果推进了 unlikely intersections 理论在PEL型情形下的研究，为后续处理更一般的特殊子簇情形提供了新的技术工具。

Abstract: We prove the Zilber-Pink conjecture to the intersection of an irreducible
Hodge generic algebraic subvariety $ V \subset \mathcal{A}_g$ with special
subvarieties of all simple PEL types other than $\mathbb{Z}$, under the
assumption of the Large Galois Orbits conjecture. In particular, we establish
parameter height bounds for the arithmetic ingredients of the Pila-Zannier
strategy in the case of Albert types III and IV. This paper is a sequel to Daw
and Orr's paper "Lattices with skew-Hermitian forms over division algebras and
unlikely intersections" 2023.

</details>


### [13] [Nonexistence of Consecutive Powerful Triplets Around Cubes with Prime-Square Factors](https://arxiv.org/abs/2507.16828)
*Jialai She*

Main category: math.NT

TL;DR: 本文针对Erd\H{o}s-Mollin-Walsh猜想，研究了围绕完全立方数的潜在反例，并利用多种数论方法证明了特定整数三元组的不存在性。


<details>
  <summary>Details</summary>
Motivation: 受Chan (2025)近期工作的启发，本研究旨在探索Erd\H{o}s-Mollin-Walsh猜想中围绕完全立方数的潜在反例，以推动这一著名数论问题的解决。

Method: 结合模运算、$p$-进赋值理论和椭圆曲线理论，对具有特定结构约束的整数三元组进行分析。

Result: 研究证明了一类结构独特的整数三元组不存在，为Erd\H{o}s-Mollin-Walsh猜想提供了新的非存在性结果。

Conclusion: 通过综合运用多种数论工具，本研究为Erd\H{o}s-Mollin-Walsh猜想的验证提供了新的理论支持，并展示了跨方法研究在数论问题中的有效性。

Abstract: The Erd\H{o}s-Mollin-Walsh conjecture, asserting the nonexistence of three
consecutive powerful integers, remains a celebrated open problem in number
theory. A natural line of inquiry, following recent work by Chan (2025), is to
investigate potential counterexamples centered around perfect cubes, which are
themselves powerful. This paper establishes a new non-existence result for a
family of such integer triplets with distinct structural constraints, combining
techniques from modular arithmetic, $p$-adic valuation, and the theory of
elliptic curves.

</details>


### [14] [On Fermat's Last Theorem over the $\mathbb{Z}_3$-extension of $\mathbb{Q}$ and other fields](https://arxiv.org/abs/2507.16883)
*Luis Dieulefait,Franco Golfieri Madriaga*

Main category: math.NT

TL;DR: 本文证明了对于满足$p \equiv 2 \pmod{3}$的足够大素数$p$，在某些数域上费马大定理成立。


<details>
  <summary>Details</summary>
Motivation: 研究费马大定理在特定数域上的推广，特别是针对满足特定条件的素数指数。

Method: 结合模方法和Pomey算术结果的推广，应用于这些特定数域。

Result: 证明了在最大实子域$\mathbb{Q}(\zeta_{3^n})$上，对于足够大的满足$p \equiv 2 \pmod{3}$的素数$p$，费马大定理成立。

Conclusion: 通过模方法和算术结果的推广，成功证明了费马大定理在特定数域和素数指数下的有效性。

Abstract: The main result of the present article is a proof of Fermat's Last Theorem
for sufficiently large prime exponents $p$ with $p \equiv 2 \pmod{3}$ over
certain number fields. A particular case of these fields are the maximal real
subfields of the cyclotomic extensions $\mathbb{Q}(\zeta_{3^n})$ for every $n$.
Our strategy consists in combining the modular method with a generalization of
an arithmetic result of Pomey to these fields.

</details>


### [15] [Certain Genus 3 Siegel Cusp Forms with Level are Determined by their Fundamental Fourier Coefficients](https://arxiv.org/abs/2507.17002)
*Sidney Washburn*

Main category: math.NT

TL;DR: 证明了在$N$为奇数且无平方因子的条件下，具有特定特征的$\Gamma_0^3(N)$上的向量值3亏格Siegel尖形式由其基本傅里叶系数唯一确定。


<details>
  <summary>Details</summary>
Motivation: 研究Siegel尖形式在特定条件下的唯一性，扩展了已知的2亏格结果，并探讨了Jacobi形式的唯一性问题。

Method: 通过加强已知的2亏格结果，证明$\Gamma_0^2(N)$上的尖形式在特定条件下由其基本傅里叶系数唯一确定，并研究了Jacobi形式的原始theta分量。

Result: 证明了3亏格Siegel尖形式在特定条件下由其基本傅里叶系数唯一确定，并扩展了2亏格结果的适用范围。同时，证明了Jacobi形式在特定条件下由其原始theta分量唯一确定。

Conclusion: 该研究为Siegel尖形式和Jacobi形式的唯一性提供了新的理论支持，特别是在高亏格和特定特征条件下的结果具有重要意义。

Abstract: We prove that vector-valued genus 3 Siegel cusp forms for $\Gamma_0^3(N)$
with certain nebentypus are determined by their fundamental Fourier
coefficients, assuming $N$ is odd and square-free. A key step in our proof
involves strengthening the known corresponding genus 2 result. More precisely,
we show that genus 2 Siegel cusp forms for $\Gamma_0^2(N)$ with certain
nebentypus are determined by their fundamental Fourier coefficients whose
discriminants are coprime to $N$. We also prove that Jacobi forms of
fundamental index with discriminant coprime to the odd level $N$ are determined
by their primitive theta components.

</details>


### [16] [Monogenic sextic trinomials $x^6+Ax^3+B$ and their Galois groups](https://arxiv.org/abs/2507.17021)
*Joshua Harrington,Lenny Jones*

Main category: math.NT

TL;DR: 本文研究了具有特定形式$x^6+Ax^3+B$的不可约六次三项式，给出了其在不同伽罗瓦群下成为单基多项式的显式描述，并探讨了生成不同六次数域的条件。


<details>
  <summary>Details</summary>
Motivation: 动机在于明确刻画具有形式$x^6+Ax^3+B$的不可约三项式在何种条件下成为单基多项式（即其根生成的整数环具有幂基），并分类其伽罗瓦群结构。

Method: 方法上采用Jakhar-Khanduja-Sangwan定理，针对该三项式所有可能的伽罗瓦群$G$，系统构造了满足单基性条件的显式参数化描述。

Result: 结果为每个可能的伽罗瓦群$G$给出了对应的单基三项式的完整参数化表达，并分析了这些多项式生成不同六次数域的条件。

Conclusion: 结论完整解决了该类六次单基三项式的分类问题，为代数数论中的幂基研究提供了新的具体范例。

Abstract: Let $f(x)=x^6+Ax^3+B\in {\mathbb Z}[x]$, with $A\ne 0$, and suppose that
$f(x)$ is irreducible over ${\mathbb Q}$. We define $f(x)$ to be {\em
monogenic} if $\{1,\theta,\theta^2,\theta^3,\theta^4,\theta^{5}\}$ is a basis
for the ring of integers of ${\mathbb Q}(\theta)$, where $f(\theta)=0$.
  For each possible Galois group $G$ of $f(x)$ over ${\mathbb Q}$, we use a
theorem of Jakhar, Khanduja and Sangwan to give explicit descriptions of all
monogenic trinomials $f(x)$ having Galois group $G$. We also investigate when
these trinomials generate distinct sextic fields.

</details>


### [17] [Twisted periods of modular forms](https://arxiv.org/abs/2507.17041)
*Tianyu Ni,Hui Xue*

Main category: math.NT

TL;DR: 本文研究了权为$k$、水平为1的尖点形式$S_k$上的扭曲周期$r_{t,\chi}$。证明了在$k$足够大时，具有相同扭曲但不同指数的周期或相同指数但不同扭曲的周期线性无关。方法涉及Eisenstein级数的迹与Rankin-Cohen括号，并应用于卷积和与$L$值非零性。


<details>
  <summary>Details</summary>
Motivation: 探索尖点形式$S_k$上扭曲周期的线性独立性，及其在数论中的应用，如卷积和与$L$值的非零性。

Method: 通过研究带nebentypus的水平$D$的Eisenstein级数的乘积与Rankin-Cohen括号的迹，分析扭曲周期的线性独立性。

Result: 证明了当$k$足够大时，相同扭曲不同指数或相同指数不同扭曲的$n$个周期线性无关。并应用该方法得到卷积和恒等式与$L$值非零性结果。

Conclusion: 本文建立了扭曲周期线性独立性的新结果，并展示了其在数论问题中的广泛应用，特别是与Maeda猜想相关的$L$值非零性。

Abstract: Let $S_k$ denote the space of cusp forms of weight $k$ and level one. For
$0\leq t\leq k-2$ and primitive Dirichlet character $\chi$ mod $D$, we
introduce twisted periods $r_{t,\chi}$ on $S_k$. We show that for a fixed
natural number $n$, if $k$ is sufficiently large relative to $n$ and $D$, then
any $n$ periods with the same twist but different indices are linearly
independent. We also prove that if $k$ is sufficiently large relative to $D$
then any $n$ periods with the same index but different twists mod $D$ are
linearly independent. These results are achieved by studying the trace of the
products and Rankin-Cohen brackets of Eisenstein series of level $D$ with
nebentypus. Moreover, we give two applications of our method. First, we prove
certain identities that evaluate convolution sums of twisted divisor functions.
Second, we show that Maeda's conjecture implies a non-vanishing result on
twisted central $L$-values of normalized Hecke eigenforms.

</details>


### [18] [Continued fractions with large prime partial quotients](https://arxiv.org/abs/2507.17167)
*Gerardo González Robert,Mumtaz Hussain,Benjamin Ward,Lauren White*

Main category: math.NT

TL;DR: 本文通过研究实数集中具有无限多个大且为素数的部分商的集合，扩展了{\L}uczak (1997)和Huang-Wu-Xu (2020)的定理，并给出了几乎素数zeta函数尾部的新渐近结果。


<details>
  <summary>Details</summary>
Motivation: 研究具有无限多个大且为素数的部分商的实数集的Lebesgue测度和Hausdorff维数，以扩展已有理论并填补相关领域的空白。

Method: 通过分析几乎素数zeta函数的尾部渐近行为，结合数论和分形几何的方法，推导出相关集合的测度和维数。

Result: 确定了这些实数集的Lebesgue测度和Hausdorff维数，并得到了几乎素数zeta函数尾部的新渐近公式，部分结果与Schindler-Zweim{\"u}ller (2023)的研究一致。

Conclusion: 本文不仅扩展了{\L}uczak和Huang-Wu-Xu的经典定理，还为相关领域提供了新的分析工具和结果，具有重要的理论意义。

Abstract: We determine the Lebesgue measure and Hausdorff dimension of various sets of
real numbers with infinitely many partial quotients that are both large and
prime, thus extending the well-known theorems by {\L}uczak (1997) and
Huang-Wu-Xu (2020). To this end, we obtain new asymptotics on the tail end of
the almost prime zeta function. Our results include some recent work by
Schindler-Zweim{\"u}ller (2023).

</details>


### [19] [Linear independence of periods for the symmetric square $L$-functions](https://arxiv.org/abs/2507.17608)
*Tianyu Ni,Hui Xue*

Main category: math.NT

TL;DR: 本文研究了全模群权$k$尖形式空间$S_k$上与对称平方$L$-函数相关的周期，证明了当$k$相对于固定自然数$n$足够大时，任意$n$个周期线性无关。进一步假设下，当$k\geq e^{12}$时可选取多达$\frac{\log k}{4}$个线性无关周期。


<details>
  <summary>Details</summary>
Motivation: 探索尖形式空间$S_k$上对称平方$L$-函数相关周期的线性独立性，为模形式的周期理论提供新见解。

Method: 首先在$S_k$上引入与对称平方$L$-函数关联的周期，然后通过分析权$k$与周期数量的关系，运用数论和代数方法证明线性独立性。

Result: 主要结果包括：1) 对固定$n$，当$k$足够大时任意$n$个周期线性无关；2) 在$k\geq e^{12}$条件下可构造$\frac{\log k}{4}$个线性无关周期。

Conclusion: 该研究揭示了高权尖形式周期空间的维数增长规律，为模形式周期理论的定量研究提供了重要工具。

Abstract: For $S_k$, the space of cusp forms of weight $k$ for the full modular group,
we first introduce periods on $S_k$ associated to symmetric square
$L$-functions. We then prove that for a fixed natural number $n$, if $k$ is
sufficiently large relative to $n$, then any $n$ such periods are linearly
independent. With some extra assumption, we also prove that for $k\geq e^{12}$,
we can always pick up to $\frac{\log k}{4}$ arbitrary linearly independent
periods.

</details>


### [20] [An integral comparison of crystalline and de Rham cohomology](https://arxiv.org/abs/2507.17631)
*Abhinandan,Alex Youcis*

Main category: math.NT

TL;DR: 本文利用棱镜上同调的堆叠视角，建立了带有棱镜$F$-晶体系数的de Rham上同调与晶体上同调之间的比较定理，方法具有积分性质。


<details>
  <summary>Details</summary>
Motivation: Berthelot和Ogus的经典结果表明，光滑真形式概形$X/\mathcal{O}_K$的de Rham上同调与特殊纤维的晶体上同调在张量$K$后存在比较。本文旨在推广这一结果至带有棱镜$F$-晶体系数的情形。

Method: 采用Drinfeld和Bhatt--Lurie提出的棱镜上同调的堆叠视角，开发了一种积分性质的方法，研究棱镜$F$-晶体系数的上同调比较。

Result: 证明了带有完美棱镜$F$-晶体复形系数的de Rham上同调与晶体上同调之间的比较定理，为理解两者间的挠关系提供了新工具。

Conclusion: 本文的积分方法不仅推广了经典比较定理，还为研究de Rham与晶体上同调中的挠问题开辟了新途径。

Abstract: Let $\mathcal{O}_K$ be a mixed characteristic complete DVR with perfect
residue field $k$ and fraction field $K$. It is a celebrated result of
Berthelot and Ogus that for a smooth proper formal scheme $X/\mathcal{O}_K$
there exists a comparison between the de Rham cohomology groups
$\mathrm{H}^i_\mathrm{dR}(X/\mathcal{O}_K)$ and the crystalline cohomology
groups $\mathrm{H}^i_\mathrm{crys}(X_k/W(k))$ of the special fibre, after
tensoring with $K$. In this article, we use the stacky perspective on prismatic
cohomology, due to Drinfeld and Bhatt--Lurie, to give a version of this
comparison result with coefficients in a perfect complex of prismatic
$F$-crystals on $X$. Our method is of an integral nature and suggests new tools
to understand the relationship between torsion in de Rham and crystalline
cohomology.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [21] [Structures with not too fast unlabelled growth](https://arxiv.org/abs/2507.16985)
*Bertalan Bodor*

Main category: math.LO

TL;DR: 该论文对轨道子集增长速率不超过$\frac{2^n}{p(n)}$的结构类$\mathscr{S}$进行了完全分类，证明了其可数性、一阶可解释性及有限有界同质性，并验证了Thomas猜想。


<details>
  <summary>Details</summary>
Motivation: 研究轨道子集增长速率受限的结构类$\mathscr{S}$的完整分类及其模型论性质，特别是验证Thomas猜想在该类结构中的适用性。

Method: 通过自同构群对$\mathscr{S}$中的结构进行系统分类，并分析其与$(\mathbb{Q};<)$的一阶解释关系及有限有界同质性。

Result: 证明$\mathscr{S}$中所有结构在双可定义性下仅有可数个，且均为一阶可解释于$(\mathbb{Q};<)$的有限有界同质结构，同时每个结构的一阶归约类在互可定义性下有限。

Conclusion: 该研究不仅完成了对$\mathscr{S}$的完整分类，还确立了其与有序有理数的深刻联系，并为Thomas猜想提供了新的证据。

Abstract: Let $\mathscr{S}$ be the class of all structures whose growth rate on orbits
of subsets of size $n$ is not faster than $\frac{2^n}{p(n)}$ for any polynomial
$p$. In this article we give a complete classification of all structures in
$\mathscr{S}$ in terms of their automorphism groups. As a consequence of our
classification we show that $\mathscr{S}$ has only countably many structures up
to bidefinability, all these structures are first-order interpretable in
$(\mathbb{Q};<)$ and they are interdefinable with a finitely bounded
homogeneous structure. Furthermore, we also show that all structures in
$\mathscr{S}$ have finitely many first-order reduct up to interdefinability,
thereby confirming Thomas' conjecture for the class $\mathscr{S}$.

</details>


### [22] [Algebraic independence of solutions to multiple Lotka-Volterra systems](https://arxiv.org/abs/2507.17090)
*Yutong Duan,Christine Eagles,Léo Jimenez*

Main category: math.LO

TL;DR: 研究非零复数$a_i, b_i, c_i, d_i$构成的Lotka-Volterra系统，证明在$b_i \neq d_i$且参数对唯一时，系统的非退化解具有代数独立性，并分类了$b_i = d_i$情形下的不变代数曲线。


<details>
  <summary>Details</summary>
Motivation: 探讨Lotka-Volterra系统的解的代数独立性，扩展Duan和Nagloo关于强极小性的工作，并完善Brestovski定理对代数关系的控制。

Method: 通过证明系统在$b_i \neq d_i$时的强极小性，结合Brestovski定理利用不变体积形式控制代数关系，并运用几何稳定性理论分类$b_i = d_i$情形的不变代数曲线。

Result: 在$b_i \neq d_i$且参数对唯一时，系统的任何非退化解组$(x_1,y_1), \cdots, (x_m,y_m)$在$\mathbb{C}$上代数独立，且完全分类了$b_i = d_i$情形的不变代数曲线。

Conclusion: 该研究不仅推广了强极小性理论在Lotka-Volterra系统中的应用，还通过几何稳定性理论解决了$b_i = d_i$情形的分类问题，为相关动力系统研究提供了新工具。

Abstract: Consider some non-zero complex numbers $a_i, b_i, c_i, d_i$ with $1 \leq i
\leq n$ and the associated classical Lotka-Volterra systems
  \[
  \begin{cases}
  x' = a_i xy + b_i y \newline
  y' = c_i xy + d_i y \text{ .}
  \end{cases}
  \] We show that as long as $b_i \neq d_i$ for all $i$ and $\{ b_i, d_i\} \neq
\{ b_j, d_j\}$ for $i \neq j$, any tuples $(x_1,y_1) , \cdots , (x_m,y_m)$ of
pairwise distinct, non-degenerate solutions of these systems are algebraically
independent over $\mathbb{C}$, meaning $\mathrm{trdeg}((x_1,y_1) , \cdots ,
(x_m,y_m)/\mathbb{C}) = 2m$. Our proof relies on extending recent work of Duan
and Nagloo by showing strong minimality of these systems, as long as $b_i \neq
d_i$. We also generalize a theorem of Brestovski which allows us to control
algebraic relations using invariant volume forms. Finally, we completely
classify all invariant algebraic curves in the non-strongly minimal, $b_i =
d_i$ case by using machinery from geometric stability theory.

</details>


### [23] [$κ$-barely independent families and Tukey types of ultrafilters](https://arxiv.org/abs/2507.17124)
*Jorge Antonio Cruz Chapital*

Main category: math.LO

TL;DR: 该论文引入了$\kappa$-barely独立族的概念，研究了其在无限基数$\kappa$和$\lambda$下的存在条件，并探讨了其与广义收割数$\mathfrak{r}(\kappa,\lambda)$的关系，最终得出$\mathfrak{p}>\omega_1$时在$\omega_1$上不存在barely独立族的结论。


<details>
  <summary>Details</summary>
Motivation: 研究$\kappa$-barely独立族的动机在于理解其在无限基数理论中的作用，特别是与广义收割数$\mathfrak{r}(\kappa,\lambda)$的关系，以及其对均匀超滤子性质的影响。

Method: 通过引入$\kappa$-barely独立族的概念，并分析其存在条件，论文将其与广义收割数$\mathfrak{r}(\kappa,\lambda)$联系起来，进而研究均匀超滤子的Tukey拓扑和最大特征。

Result: 论文证明了在某些条件下，$\kappa$-barely独立族的存在性，并利用这些条件得出均匀超滤子具有Tukey拓扑和最大特征的结论。此外，还证明了当$\mathfrak{p}>\omega_1$时，$\omega_1$上不存在barely独立族。

Conclusion: 论文的主要结论是$\kappa$-barely独立族的存在性与广义收割数密切相关，且在$\mathfrak{p}>\omega_1$时，$\omega_1$上不存在barely独立族。这些结果为无限基数理论提供了新的见解。

Abstract: Given two infinite cardinals $\kappa$ and $\lambda$, we introduce and study
the notion of a $\kappa$-barely independent family over $\lambda.$ We provide
some conditions under which these types of families exist. In particular, we
relate the existence of large $\kappa$-barely independent families with the
generalized reaping numbers $\mathfrak{r}(\kappa,\lambda)$ and use these
relations to give conditions under which every uniform ultrafilter over a given
cardinal $\lambda$ is both Tukey top and has maximal character. Finally, we
show that $\mathfrak{p}>\omega_1$ the non-existence of barely independent
families over $\omega_1.$

</details>


### [24] [Some questions on entangled linear orders](https://arxiv.org/abs/2507.17503)
*Raphaël Carroy,Maxwell Levine,Lorenzo Notaro*

Main category: math.LO

TL;DR: 该论文研究了纠缠线性序的存在性及其性质，在连续统假设（$\mathsf{CH}$）和其他集合论假设下，证明了不同维度的纠缠线性序的存在性及其区别。


<details>
  <summary>Details</summary>
Motivation: 研究纠缠线性序的存在性及其在不同集合论假设下的表现，以深化对线性序结构和实数集复杂性的理解。

Method: 通过集合论方法，利用连续统假设（$\mathsf{CH}$）、构造性宇宙（$\mathrm{L}$）和钻石原则（$\diamondsuit$）等假设，证明不同维度的纠缠线性序的存在性。

Result: 1) 在$\mathsf{CH}$下，存在$n$-纠缠但不$(n+1)$-纠缠的线性序；2) 在$\mathsf{CH}$下，存在同胚的实数集$A$和$B$，其中$A$纠缠但$B$不$2$-纠缠；3) 若$\mathbb{R}\subseteq \mathrm{L}$，则存在纠缠的$\Pi_1^1$实数集；4) 若$\diamondsuit$成立，则存在不可分的$2$-纠缠线性序。

Conclusion: 论文证明了纠缠线性序在多种集合论假设下的存在性及其性质差异，为线性序和实数集的结构研究提供了新的理论工具。

Abstract: Entangled linear orders were first introduced by Abraham and Shelah.
Todor\v{c}evi\'c showed that these linear orders exist under $\mathsf{CH}$. We
prove the following results: (1) If $\mathsf{CH}$ holds, then, for every $n >
0$, there is an $n$-entangled linear order which is not $(n+1)$-entangled. (2)
If $\mathsf{CH}$ holds, then there are two homeomorphic sets of reals $A, B
\subseteq \mathbb{R}$ such that $A$ is entangled but $B$ is not $2$-entangled.
(3) If $\mathbb{R}\subseteq \mathrm{L}$, then there is an entangled $\Pi_1^1$
set of reals. (4) If $\diamondsuit$ holds, then there is a $2$-entangled
non-separable linear order.

</details>


### [25] [Minimal Banach-Tarski Decompositions](https://arxiv.org/abs/2507.17517)
*Cesare Straffelini,Kilian Zambanini*

Main category: math.LO

TL;DR: 研究三维球体分割重组为n个全等副本所需的最少块数，推广了Raphael Robinson的已知结果。


<details>
  <summary>Details</summary>
Motivation: 探索三维空间中球体分割与重组的数学问题，扩展已有的一维和二维结果至三维情形。

Method: 通过几何分割与重组技术，分析球体或球体分割为全等副本的最小块数。

Result: 确定了将三维球体或球体分割重组为n个全等副本所需的最少块数。

Conclusion: 该研究为三维空间中的分割重组问题提供了新的理论结果，推广了Raphael Robinson的工作。

Abstract: We investigate the problem of finding the minimum number of pieces necessary
for dividing a three-dimensional sphere or a ball and reassembling it to form
$n$ congruent copies of the original object, generalising a known result by
Raphael Robinson.

</details>


### [26] [Canonical completion and duality for cylindric ortholattices and cylindric Boolean algebras](https://arxiv.org/abs/2507.17715)
*Joseph McDonald*

Main category: math.LO

TL;DR: 本文研究了柱形正交格和柱形布尔代数的代数与拓扑表示理论，证明了柱形正交格在规范完备化下封闭，并建立了其与谱空间子范畴的对偶等价关系。


<details>
  <summary>Details</summary>
Motivation: 研究柱形正交格和柱形布尔代数的表示理论，扩展Harding、McDonald和Peinado在单子正交格中的完备性与对偶性结果，结合McDonald和Yamamoto在一般正交格中的对偶性成果。

Method: 通过为规范完备化的对偶空间赋予谱拓扑，结合Bezhanishvili和Holliday的布尔代数对偶理论，采用构造性方法在Zermelo-Fraenkel集合论中独立于选择公理完成证明。

Result: 证明了柱形正交格在规范完备化下封闭，并建立了其与谱空间子范畴的构造性对偶等价关系；进一步获得了柱形布尔代数的完备性与对偶性结果。

Conclusion: 本文不仅推广了正交格与布尔代数的对偶理论，还通过构造性方法在基础集合论框架内实现了对偶性证明，为相关领域提供了新的理论工具。

Abstract: In this note, we investigate the algebraic and topological representation
theory of cylindric ortholattices and cylindric Boolean algebras. The first
contribution demonstrates that cylindric ortholattices are closed under
canonical completions. By equipping a spectral topology to the dual space
associated with the canonical completion, we then establish a dual equivalence
between the category of cylindric ortholattices and a certain subcategory of
the category of spectral spaces. This work builds on the completion and duality
results obtained by Harding, McDonald, and Peinado in the setting of monadic
ortholattices combined with the duality results obtained by McDonald and
Yamamoto in the setting of general ortholattices. By working with the duality
theory for Boolean algebras established by Bezhanishvili and Holliday, we then
obtain completion and duality results for cylindric Boolean algebras. A key
aspect of our duality results is that they are constructive in the sense that
they obtain in Zermelo-Fraenkel set theory independently of the Axiom of
Choice.

</details>


### [27] [Orthogonality relations and operators on bounded quasi-implication algebras](https://arxiv.org/abs/2507.17724)
*Joseph McDonald*

Main category: math.LO

TL;DR: 本文研究了Hardegree提出的有界拟蕴涵代数的关系与代数性质，通过推广MacLaren和Goldblatt在正交格中的构造，构建了多种正交关系。进一步引入了带算子的有界拟蕴涵代数（称为单子拟蕴涵代数），并在量子单子代数框架下进行研究。证明了量子单子代数与单子拟蕴涵代数之间的相互转换及范畴同构性，最后推广了Harding等人的构造，从单子拟蕴涵代数构建了多种单子正交框架。


<details>
  <summary>Details</summary>
Motivation: 研究有界拟蕴涵代数的关系与代数性质，探索其在量子单子代数中的应用，并建立与正交结构的联系。

Method: 推广MacLaren和Goldblatt的构造方法，构建正交关系；引入单子拟蕴涵代数并研究其与量子单子代数的关系；推广Harding等人的构造方法构建单子正交框架。

Result: 证明了量子单子代数与单子拟蕴涵代数之间的相互转换及范畴同构性；成功从单子拟蕴涵代数构建了多种单子正交框架。

Conclusion: 本文通过推广多种构造方法，建立了有界拟蕴涵代数与量子单子代数之间的深刻联系，为相关代数结构的研究提供了新的视角和工具。

Abstract: In this note, we study various relational and algebraic aspects of the
bounded quasi-implication algebras introduced by Hardegree. By generalizing the
constructions given by MacLaren and Goldblatt within the setting of
ortholattices, we construct various orthogonality relations from bounded
quasi-implication algebras.
  We then introduce certain bounded quasi-implication algebras with an
additional operator, which we call monadic quasi-implication algebras, and
study them within the setting of quantum monadic algebras. A quantum monadic
algebra is an orthomodular lattice equipped with a closure operator, known as a
quantifier, whose closed elements form an orthomodular sub-lattice. It is shown
that every quantum monadic algebra can be converted into a monadic
quasi-implication algebra with the underlying magma structure being determined
by the operation of Sasaki implication on the underlying orthomodular lattice.
It is then conversely demonstrated that every monadic quasi-implication algebra
can be converted into a quantum monadic algebra. These constructions are shown
to induce an isomorphism between the category of quantum monadic algebras and
the category of monadic quasi-implication algebras.
  Finally, by generalizing the constructions given by Harding as well as
Harding, McDonald, and Peinado in the setting of monadic ortholattices, we
construct various monadic orthoframes from monadic quasi-implication algebras.

</details>


<div id='math.HO'></div>

# math.HO [[Back]](#toc)

### [28] [Collapsi is strongly solved](https://arxiv.org/abs/2507.16823)
*Michael Young*

Main category: math.HO

TL;DR: Collapsi是一款由Mark S. Ball开发的两人完全信息游戏，在2025年6月发布。游戏在16张随机洗牌的环形棋盘上进行，玩家根据所在位置的牌值移动棋子。通过穷举分析发现，先手玩家在37.5%的情况下可以强制获胜，后手玩家在其余情况下获胜。


<details>
  <summary>Details</summary>
Motivation: 研究Collapsi游戏的完整信息特性及其对称性，探索其游戏树的可穷举性，以确定最优策略和胜负分布。

Method: 开发了一个求解器，能够在约20毫秒内找到给定棋盘位置的最优移动。通过对称性简化后，对游戏进行了穷举分析，统计了胜负分布和游戏长度。

Result: 先手玩家在37.5%的牌局中可以强制获胜，后手玩家在其余62.5%的牌局中获胜。6.4%的牌局中，败方可以将游戏延长至最大14步，而最短强制获胜步数为7步。

Conclusion: Collapsi游戏具有明确的胜负分布和策略深度，其对称性和浅游戏树使得穷举分析成为可能，为完全信息游戏的研究提供了新的案例。

Abstract: Collapsi is a two-player game of complete information released in June 2025
by Mark S. Ball of Riffle Shuffle & Roll. Played with two pawns on a toroidal
board of 16 randomly mixed playing cards, players take it in turns to move
based on the value of the card they sit on, with the game ending when a player
has no legal moves. The number of possible deals after symmetry breaking is low
enough, and the game tree shallow enough, to make an exhaustive analysis of the
game feasible. A solver was written that can find an optimal move for a given
board position in around 20 milliseconds. A search was applied revealing that
the first player can force a win in 37.5% of deals, with the second player able
to force a win in all others. In 6.4% of deals the losing player can prolong
the game to the maximum length of 14 plies; a win can never be forced in fewer
than 7 plies.

</details>


<div id='math.GM'></div>

# math.GM [[Back]](#toc)

### [29] [Imbalance Prime Sieving: Every Prime Gap Is a Result of a Möbius Imbalance Obstruction](https://arxiv.org/abs/2507.16821)
*Paul Alexander Bilokon*

Main category: math.GM

TL;DR: 提出了一种基于M\"obius变换有理度量空间中拓扑障碍检测的新型素数筛法，该方法通过识别不平衡共轭对来精确枚举素数，并给出了素数间隙的几何解释。


<details>
  <summary>Details</summary>
Motivation: 传统筛法依赖可除性，本文旨在通过拓扑方法重新理解素数的分布特性，探索素数间隙的几何本质。

Method: 在有理数对(p,q)上构建拓扑障碍理论，通过M\"obius变换后的不平衡空间中的碰撞现象识别素数，将素数间隙解释为该空间中的碰撞结果。

Result: 该方法能精确筛选出指定范围内的素数，实证结果验证了其有效性，并为数论模型和筛法算法提供了新的研究方向。

Conclusion: 该筛法不仅提供了素数枚举的精确算法，还揭示了素数间隙的拓扑成因，可能推动数论和计算数学领域的新发展。

Abstract: We introduce a novel sieve for prime numbers based on detecting topological
obstructions in a M\"obius-transformed rational metric space. Unlike
traditional sieves which rely on divisibility, our method identifies primes as
those numbers which contribute new, non-colliding imbalance conjugates. This
provides both an exact algorithm for prime enumeration and a new geometric
interpretation of prime gaps. This sieve constructs a topological obstruction
theory over rational pairs (p, q), from which we observe that every prime gap
is a consequence of a collision in this transformed imbalance space. Our
empirical results demonstrate that this method precisely filters the prime
numbers up to a specified bound, with potential implications for new
number-theoretic models and sieving algorithms.

</details>


### [30] [On the Green function to the Poisson and the Helmholtz equations on the $n$-dimensional unit sphere](https://arxiv.org/abs/2507.16822)
*Ilona Iglewska-Nowak*

Main category: math.GM

TL;DR: 提出了一种在$n$维单位球上求解泊松方程和亥姆霍兹方程广义格林函数闭合形式的新方法。


<details>
  <summary>Details</summary>
Motivation: 解决$n$维单位球上泊松方程和亥姆霍兹方程的广义格林函数闭合形式问题。

Method: 采用新的数学方法推导广义格林函数的闭合形式解。

Result: 成功获得了$n$维单位球上两类方程的广义格林函数闭合表达式。

Conclusion: 该方法为相关领域提供了有效的解析工具，具有理论价值和应用潜力。

Abstract: A new method is presented to obtain a closed form of the generalized Green
function to the Poisson and the Helmholtz equations on the $n$-dimensional unit
sphere.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [31] [Approximating temporal modularity on graphs of small underlying treewidth](https://arxiv.org/abs/2507.17541)
*Vilhelm Agdur,Jessica Enright,Laura Larios-Jones,Kitty Meeks,Fiona Skerman,Ella Yates*

Main category: math.CO

TL;DR: 本文提出了一种针对时序图模块度的有效近似算法，适用于树宽较小的图结构，扩展了静态图的现有方法。


<details>
  <summary>Details</summary>
Motivation: 模块度是衡量网络聚类或社区结构水平的常用指标。时序图能更真实地模拟现实世界网络的动态连接（如社交网络中个体关系的演变），但其模块度计算因NP难特性而极具挑战性。

Method: 通过将静态图的模块度近似算法推广至时序图，并引入新思路以克服时序性带来的技术难题，重点关注树宽较小的底层图结构。

Result: 证明当时序图的树宽较小时，可在多项式时间内高效计算其模块度的乘法近似值。

Conclusion: 该研究为时序图模块度计算提供了理论可行的解决方案，填补了动态网络分析领域的算法空白，但需依赖树宽较小的图结构假设。

Abstract: Modularity is a very widely used measure of the level of clustering or
community structure in networks. Here we consider a recent generalisation of
the definition of modularity to temporal graphs, whose edge-sets change over
discrete timesteps; such graphs offer a more realistic model of many real-world
networks in which connections between entities (for example, between
individuals in a social network) evolve over time. Computing modularity is
notoriously difficult: it is NP-hard even to approximate in general, and only
admits efficient exact algorithms in very restricted special cases. Our main
result is that a multiplicative approximation to temporal modularity can be
computed efficiently when the underlying graph has small treewidth. This
generalises a similar approximation algorithm for the static case, but requires
some substantially new ideas to overcome technical challenges associated with
the temporal nature of the problem.

</details>


### [32] [A q-Supercongruence Motivated by Higher-Order Generalized Lehmer-Euler Numbers](https://arxiv.org/abs/2507.16825)
*Wei-Wei Qi*

Main category: math.CO

TL;DR: 本文定义了一种与高阶广义Lehmer-Euler数相关的新多项式，并确定了其q-超同余关系。


<details>
  <summary>Details</summary>
Motivation: 1935年Lehmer利用三次单位根定义了Euler数的某种推广，作为Bernoulli数和Euler数的自然推广。本研究旨在进一步探索这一方向。

Method: 通过定义与高阶广义Lehmer-Euler数相关的新多项式，研究其数学性质。

Result: 成功确定了该新多项式的q-超同余关系。

Conclusion: 这项工作扩展了Lehmer对Euler数的推广研究，为相关数论问题提供了新的工具和视角。

Abstract: Certain generalization of Euler numbers was defined in 1935 by Lehmer using
cubic roots of unity, as a natural generalization of Bernoulli and Euler
numbers. In this paper, we define a new polynomial related to the higher-order
generalized Lehmer-Euler numbers and determine its a q-supercongruence.

</details>


### [33] [On Cloitre's hiccup sequences](https://arxiv.org/abs/2507.16956)
*Robbert Fokkink,Gandhar Joshi*

Main category: math.CO

TL;DR: 本文综述了Benoit Cloitre在2003年提交到OEIS的一系列\emph{hiccup}序列，整合了多年来对这些序列的各种声明、观察和性质证明，并基于Bosma、Dekking和Steiner的著名定理提出了一种统一的研究方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于整理和分析OEIS中关于\emph{hiccup}序列的分散信息，并通过统一的理论框架深化对这些序列的理解。

Method: 研究方法包括收集OEIS中关于\emph{hiccup}序列的已有成果，并运用Bosma、Dekking和Steiner的定理作为指导，进行系统化的分析和证明。

Result: 研究结果呈现了对\emph{hiccup}序列性质的全面总结，并通过统一的理论框架验证了这些序列的多种特性。

Conclusion: 结论表明，基于Bosma等人的定理，可以有效地统一理解和证明\emph{hiccup}序列的各种性质，为未来的研究提供了坚实的理论基础。

Abstract: In 2003, Benoit Cloitre entered a bunch of sequences in the OEIS that we call
\emph{hiccup} sequences. We collect the various claims, observations, and
proofs of properties of these sequences that have been entered in the OEIS over
the years, and present a unified approach, guided by a remarkable theorem of
Bosma, Dekking, and Steiner.

</details>


### [34] [Planar-Toroidal Decomposition of $K_{12}$](https://arxiv.org/abs/2507.17084)
*Allan Bickle,Russell Campbell*

Main category: math.CO

TL;DR: 通过理论论证和计算机搜索，证明$K_{12}$无法分解为一个平面图和一个环面图，并发现若$G$为12阶平面图且$H\subseteq\overline{G}$为环面图，则$H$的边数至少比$\overline{G}$少2。


<details>
  <summary>Details</summary>
Motivation: 解决Anderson和White在1978年提出的问题：是否存在将$K_{12}$分解为一个平面图和一个环面图的可能。

Method: 结合理论分析和计算机搜索，枚举所有12阶极大平面图，并验证其补图的环面子图性质。

Result: 发现$K_{12}$无法满足分解条件，且当$G$为12阶平面图时，其补图中的环面图$H$边数至少比补图少2；计算机搜索找到123组满足$H$边数仅少2的唯一对$(G,H)$。

Conclusion: 否定了$K_{12}$的平面-环面分解可能性，并量化了补图中环面子图的边数限制，为图分解问题提供了新的理论边界。

Abstract: In 1978, Anderson and White asked whether there is a decomposition of
$K_{12}$ into two graphs, one planar and one toroidal. Using theoretical
arguments and a computer search of all maximal planar graphs of order 12, we
show that no such decomposition exists. We further show that if $G$ is planar
of order 12 and $H\subseteq\overline{G}$ is toroidal, then $H$ has at least two
fewer edges than $\overline{G}$. A computer search found all 123 unique pairs
$\left(G,H\right)$ that make this an equality.

</details>


### [35] [Resolving Open Problems on the Euler Sombor Index](https://arxiv.org/abs/2507.17246)
*Kinkar Chandra Das,Jayanta Bera*

Main category: math.CO

TL;DR: 本文解决了关于Euler Sombor指数（$EUS$）的两个开放性问题：确定了固定阶数和围长的单圈图中$EUS$的最小值及其极值图，并进一步扩展到更广泛的连通图类；同时分类了在固定阶数和叶子数时达到最大$EUS$的所有连通图。


<details>
  <summary>Details</summary>
Motivation: Khanra和Das在关于Euler Sombor指数的研究中提出了若干开放性问题，本文旨在解决其中最具挑战性的两个问题，即极值图的确定与分类。

Method: 通过数学推导和图论分析，首先在单圈图中确定$EUS$的最小值及极值图，随后将结果推广到连通图类，并对固定阶数和叶子数的连通图进行最大$EUS$的分类。

Result: 确定了单圈图和连通图中$EUS$的最小值及对应的极值结构，并分类了在固定阶数和叶子数时达到最大$EUS$的所有连通图。

Conclusion: 本文完全解决了Khanra和Das提出的两个开放性问题，为Euler Sombor指数的极值研究提供了完整的理论框架和具体结果。

Abstract: Recently, the Euler Sombor index $(EUS)$ was introduced as a novel
degree-based topological index. For a graph $G$, the Euler Sombor index is
defined as $$EUS(G) = \sum_{v_i v_j \in E(G)} \sqrt{d_i^2 + d_j^2 + d_i d_j},$$
where $d_i$ and $d_j$ denote the degrees of the vertices $v_i$ and $v_j$,
respectively. Very recently, Khanra and Das \textbf{\bf [Euler Sombor index of
trees, unicyclic and chemical graphs, \emph{MATCH Commun. Math. Comput. Chem.}
\textbf{94} (2025) 525--548]} proposed several open problems concerning the
Euler Sombor index. This paper completely resolves two of the most challenging
problems posed therein. First, we determine the minimum value of the $EUS$
index among all unicyclic graphs of a fixed order and prescribed girth, and we
characterize the extremal graphs that attain this minimum. Building on this
result, we further establish the minimum $EUS$ index within the broader class
of connected graphs of the same order and girth, and identify the corresponding
extremal structures. In addition, we classify all connected graphs that attain
the maximum Euler Sombor index $(EUS)$ when both the order and the number of
leaves are fixed.

</details>


### [36] [Bipartite graphs with minimum degree at least 15 are antimagic](https://arxiv.org/abs/2507.17302)
*Kecai Deng*

Main category: math.CO

TL;DR: 本文证明了最小度数至少为15的二部图具有反魔术标号，推进了Hartsfield和Ringel于1990年提出的反魔术标号猜想的研究。


<details>
  <summary>Details</summary>
Motivation: 反魔术标号猜想认为除$K_2$外的所有连通图都存在反魔术标号。2016年Eccles证明了平均度数至少为4,182的图满足该猜想，但无法将下限降至1,000。本研究旨在探索更宽松条件下的证明。

Method: 采用三个关键工具：K\"{o}nig定理的推论、避免欧拉分量的特定大小子图的存在性，以及确保部分顶点和可被3整除而其他不可的标号引理。

Result: 证明了所有最小度数至少为15的二部图都具有反魔术标号，突破了先前对高平均度数图的研究限制。

Conclusion: 该研究通过创新方法将反魔术标号猜想在二部图上的证明条件显著放宽，为完全解决该猜想提供了新思路。

Abstract: An antimagic {labeling} of a graph $G=(V,E)$ is a one-to-one mapping $f:
E\rightarrow\{1,2,\ldots,|E|\}$, ensuring that the vertex sums in $V$ are
pairwise distinct, where a vertex sum of a vertex $v$ is defined as the sum of
the labels of the edges incident to $v$. A graph is called antimagic if it
admits an antimagic labeling. The Antimagic Labeling Conjecture, proposed by
Hartsfield and Ringel in 1990, posits that every connected graph other than
$K_2$ is antimagic. The conjecture was confirmed for graphs of average degree
at least 4,182 in 2016 by Eccles, where it was stated that a similar approach
could not reduce the bound below 1,000 from 4,182.
  This paper shows that every bipartite graph with minimum degree at least 15
is antimagic. Our approach relies on three tools: a consequence of K\"{o}nig's
Theorem, the existence of a subgraph of a specific size that avoids Eulerian
components, and a labeling lemma that ensures some vertex sums are divisible by
three while others are not.

</details>


### [37] [Maker-Breaker total domination number](https://arxiv.org/abs/2507.17341)
*Athira Divakaran,Tijo James,Sandi Klavžar,Latha S Nair*

Main category: math.CO

TL;DR: 本文引入了图的总支配Maker-Breaker数$\gamma_{\rm MBT}(G)$及其Staller起始版本$\gamma_{\rm MBT}'(G)$，证明了其上下界并构造了满足特定整数对的连通图。


<details>
  <summary>Details</summary>
Motivation: 研究图论中Maker-Breaker总支配游戏的最小步数问题，拓展了传统支配游戏的理论框架。

Method: 通过定义$\gamma_{\rm MBT}(G)$和$\gamma_{\rm MBT}'(G)$两个新参数，建立上下界并构造示例图验证紧性。

Result: 对于任意$2\leq k\leq \ell$的整数对，存在连通图分别满足：(i)$\gamma_{\rm MB}(G)=k$且$\gamma_{\rm MBT}(G)=\ell$；(ii)Staller起始的对应情形；(iii)混合参数情形。

Conclusion: 该研究完善了Maker-Breaker支配理论体系，所提出的总支配参数具有明确的图论意义和构造可行性。

Abstract: The Maker-Breaker total domination number, $\gamma_{\rm MBT}(G)$, of a graph
$G$ is introduced as the minimum number of moves of Dominator to win the
Maker-Breaker total domination game, provided that he has a winning strategy
and is the first to play. The Staller-start Maker-Breaker total domination
number, $\gamma_{\rm MBT}'(G)$, is defined analogously for the game in which
Staller starts. Upper and lower bounds on $\gamma_{\rm MBT}(G)$ and on
$\gamma_{\rm MBT}'(G)$ are provided and demonstrated to be sharp. It is proved
that for any pair of integers $(k,\ell)$ with $2\leq k\leq \ell$, (i) there
exists a connected graph $G$ with $\gamma_{\rm MB}(G)=k$ and $\gamma_{\rm
MBT}(G)=\ell$, (ii) there exists a connected graph $G'$ with $\gamma_{\rm
MB}'(G')=k$ and $\gamma_{\rm MBT}'(G')=\ell$, and (iii) there there exists a
connected graph $G''$ with $\gamma_{\rm MBT}(G'')=k$ and $\gamma_{\rm
MBT}'(G'')=\ell$. Here, $\gamma_{\rm MB}$ and $\gamma_{\rm MB}'$ are
corresponding invariants for the Maker-Breaker domination game.

</details>


### [38] [Clustering, order conditions, and languages of interval exchanges](https://arxiv.org/abs/2507.17370)
*Sébastien Ferenczi,Luca Q. Zamboni*

Main category: math.CO

TL;DR: 该研究探讨了区间交换变换（IET）及其广义形式下的词汇聚类特性，证明了在对称情况下，广义与标准IET生成的词汇等价性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解区间交换变换在自然编码中的词汇聚类行为，特别是广义与标准形式之间的关系，以扩展对词汇生成机制的理论认识。

Method: 通过定义字母集到返回词汇集的态射$\phi$，并利用Burrows-Wheeler变换的聚类性质，分析词汇$\phi v$与诱导映射下的词汇$v$的关联性。对称情况下，进一步验证回文词汇的序等价性。

Result: 发现对称区间交换变换中，广义IET生成的词汇当且仅当标准IET可生成时成立，且自然编码均为丰富语言。非聚类词汇的生成条件在对称情况下同样成立。

Conclusion: 研究统一了广义与标准区间交换变换在词汇生成上的等价性，尤其在对称情形下，为语言理论中的变换分类提供了新判据。

Abstract: For any interval exchange transformation $T$ (standard or generalized), if we
define a morphism $\phi$ from the set of letters to the
  set of the return words of a word in the natural coding, respecting the
lexicographical order, the word $\phi v$ clusters (for the Burrows-Wheeler
transform) for the permutation of $T$ if and only if the word $v$ clusters for
the permutation of the induced map of $T$
  on the cylinder $[w]$. When $T$ is symmetrical, all such natural codings are
rich languages, and this implies that the two orders above are the same if $w$
is a palindrome. Finally, we generalize the result, proved by using the
clustering of a word $w$,
  that $ww$ is produced by a generalized interval exchange transformation if
and only if $ww$ is produced by a standard interval exchange transformation, to
non-clustering $w$: in the symmetric case, $w$ is produced by a
  generalized interval exchange transformation if and only if $w$ is produced
by a standard interval exchange transformation.

</details>


### [39] [Non-isomorphic $d$-integral circulant graphs](https://arxiv.org/abs/2507.17407)
*Sauvik Poddar,Angsuman Das*

Main category: math.CO

TL;DR: 本文研究了循环图的代数度数$Deg(G)$，定义了最小$d$-积分循环图，并计算了$C(d)$的确切值，证明了最小$d$-积分循环图不唯一，同时给出了$|\mathcal{F}_{n,d}|$的界限及$|\mathcal{F}_{p,d}|$的精确值。


<details>
  <summary>Details</summary>
Motivation: 研究循环图的代数度数及其最小阶数$C(d)$，探索$d$-积分循环图的性质和唯一性问题，为图论中的代数结构提供新的理论支持。

Method: 通过定义$d$-积分循环图及最小$d$-积分循环图，利用代数图论和数论方法，计算$C(d)$的确切值，并分析$|\mathcal{F}_{n,d}|$的界限及$|\mathcal{F}_{p,d}|$的精确值。

Result: 证明了对于每个正整数$d$，存在阶数为$C(d)$的循环图，且最小$d$-积分循环图不唯一；给出了$|\mathcal{F}_{n,d}|$的界限，并在$p$和$d$均为素数时得到了$|\mathcal{F}_{p,d}|$的精确值。

Conclusion: 本文不仅计算了$C(d)$的确切值，还证明了最小$d$-积分循环图的不唯一性，为循环图的代数性质研究提供了重要结论。

Abstract: The algebraic degree $Deg(G)$ of a graph $G$ is the dimension of the
splitting field of the adjacency polynomial of $G$ over the field $\mathbb{Q}$.
It can be shown that for every positive integer $d$, there exists a circulant
graph with algebraic degree $d$. Let $C(d)$ be the least positive integer such
that there exists a circulant graph of order $C(d)$ having algebraic degree
$d$. A graph $G$ is called $d$-integral if $Deg(G)=d$. We call a $d$-integral
circulant graph \textit{minimal} if order of that graph equals $C(d)$. Let
$\mathcal{F}_{n,d}$ denote the collection of isomorphism classes of connected,
$d$-integral circulant graphs of some given possible order $n$. In this paper
we compute the exact value of $C(d)$ and provide some bounds on
$|\mathcal{F}_{n,d}|$, thereby showing that the minimal $d$-integral circulant
graph is not unique. Moreover, we find the exact value of $|\mathcal{F}_{p,d}|$
where both $p$ and $d$ are prime.

</details>


### [40] [On the sum of the largest and smallest eigenvalues of odd-cycle free graphs](https://arxiv.org/abs/2507.17492)
*Aida Abiad,Vladislav Taranchuk,Thijs van Veluw*

Main category: math.CO

TL;DR: 本文扩展了Csikv\'ari关于图二部性的结果，证明了对于一般奇数围长$k$的图，$(\lambda_1+\lambda_n)/n = O(k^{-1})$，并在奇数围长为7时给出了更强的上界0.0396。


<details>
  <summary>Details</summary>
Motivation: 研究图的二部性度量，特别是通过邻接特征值$\lambda_1 + \lambda_n$和奇数围长来量化图的二部性质，扩展Csikv\'ari关于奇数围长5的结果。

Method: 通过数学推导和分析，将Csikv\'ari的结果推广到一般奇数围长$k$的图，并针对奇数围长7的情况进行更精细的估计。

Result: 对于一般奇数围长$k$的图，证明了$(\lambda_1+\lambda_n)/n = O(k^{-1})$；特别地，奇数围长7时，$(\lambda_1+\lambda_n)/n < 0.0396$。

Conclusion: 本文成功将二部性度量的结果推广到更一般的奇数围长图，并给出了更精确的上界，为图论中二部性质的研究提供了新的理论工具。

Abstract: Let $G$ be a graph with adjacency eigenvalues $\lambda_1 \geq \cdots \geq
\lambda_n$. Both $\lambda_1 + \lambda_n$ and the odd girth of $G$ can be seen
as measures of the bipartiteness of $G$. Csikv\'ari proved in 2022 that for odd
girth 5 graphs (triangle-free) it holds that $(\lambda_1+\lambda_n)/n \le
(3-2\sqrt 2) < 0.1716$. In this paper we extend Csikv\'ari's result to general
odd girth $k$ proving that $(\lambda_1+\lambda_n)/n = O(k^{-1})$. In the case
of odd girth 7, we prove a stronger upper bound of $(\lambda_1+\lambda_n)/n <
0.0396$.

</details>


### [41] [Exterior Cyclic Polytopes and Convexity of Amplituhedra](https://arxiv.org/abs/2507.17620)
*Elia Mazzucchelli,Elizabeth Pratt*

Main category: math.CO

TL;DR: 本文研究了amplituhedron的凸性与对偶性，提出了一种称为“可扩展凸性”的新概念，并证明了在特定条件下amplituhedron具有该性质。通过引入“外部循环多面体”及其对偶，进一步分析了其组合结构，并定义了“对偶amplituhedron”，展示了其在特定参数下的对称性。


<details>
  <summary>Details</summary>
Motivation: 研究amplituhedron的几何性质，特别是凸性与对偶性，以深化对这一数学结构的理解，并探索其在物理和数学中的应用潜力。

Method: 引入“可扩展凸性”概念，分析其在Grassmannian中的表现；定义“外部循环多面体”作为工具，研究其组合性质；构造“对偶amplituhedron”并分析其与原始结构的关系。

Result: 证明了$k=m=2$的amplituhedron在Grassmannian中具有可扩展凸性；外部循环多面体与amplituhedron在Plücker嵌入下的凸包等价；对偶amplituhedron在特定参数下仍为amplituhedron，且外部矩阵数据通过扭转映射变换。

Conclusion: amplituhedron的凸性与对偶性可通过可扩展凸性和外部循环多面体等工具系统研究，对偶结构的存在进一步揭示了其内在对称性，为后续研究提供了新方向。

Abstract: The amplituhedron is a semialgebraic set in the Grassmannian. We study
convexity and duality of amplituhedra. We introduce a notion of convexity,
called \textit{extendable convexity}, for real semialgebraic sets in any
embedded projective variety. We show that the $k=m=2$ amplituhedron is
extendably convex in the Grassmannian of lines in projective three-space. In
the process we introduce a new polytope called the \emph{exterior cyclic
polytope}, generalizing the cyclic polytope. It is equal to the convex hull of
the amplituhedron in the Pl\"ucker embedding. We undertake a combinatorial
analysis of the exterior cyclic polytope, its facets, and its dual. Finally, we
introduce the \textit{(extendable) dual amplituhedron}, which is closely
related to the dual of the exterior cyclic polytope. We show that the dual
amplituhedron for $k=m=2$ is again an amplituhedron, where the external matrix
data is changed by the twist map.

</details>


### [42] [On Maker-Breaker domination game critical graphs](https://arxiv.org/abs/2507.17646)
*Boštjan Brešar,Tanja Dravec,Kirsti Kuenzel,Douglas F. Rall*

Main category: math.CO

TL;DR: 本文研究了2-$\gamma_{\rm MB}'$-临界图的性质，特别是具有割顶点的图和无非三角形的非二分图，并给出了两类无限族的特征描述。


<details>
  <summary>Details</summary>
Motivation: 研究2-$\gamma_{\rm MB}'$-临界图的特性，以扩展对Dominator-Breaker支配游戏的理解，特别是在临界条件下的图结构。

Method: 通过分析图的割顶点结构和非二分图的特性，结合已有的二分图临界图的研究成果，进行理论推导和证明。

Result: 特征化了具有割顶点的2-$\gamma_{\rm MB}'$-临界图，并证明$C_5$是唯一的非二分且无三角形的2-$\gamma_{\rm MB}'$-临界图。

Conclusion: 本文完善了2-$\gamma_{\rm MB}'$-临界图的分类，特别是对具有割顶点和非二分结构的图提供了明确的特征描述。

Abstract: The Maker-Breaker domination game is played on a graph $G$ by Dominator and
Staller who alternate turns selecting an unplayed vertex of $G$. The goal of
Dominator is that the vertices he selected during the game form a dominating
set while Staller's goal is to prevent this from happening. The graph invariant
$\gamma_{\rm MB}'(G)$ is the number of Dominator's moves in the game played on
$G$ in which he can achieve his goal when Staller makes the first move and both
players play optimally. In this paper, we continue the investigation of
$2$-$\gamma_{\rm MB}'$-critical graphs, initiated in [Divarakan et al.,
Maker--Breaker domination game critical graphs, Discrete Appl.\ Math. 368
(2025) 126--134], which are defined as the graphs $G$ with $\gamma_{\rm
MB}'(G)=2$ and $\gamma_{\rm MB}'(G-e)>2$ for every edge $e$ in $G$. The authors
characterized bipartite $2$-$\gamma_{\rm MB}'$-critical graphs, and found an
example of a non-bipartite $2$-$\gamma_{\rm MB}'$-critical graph. In this
paper, we characterize the $2$-$\gamma_{\rm MB}'$-critical graphs that have a
cut-vertex, which are represented by two infinite families. In addition, we
prove that $C_5$ is the only non-bipartite, triangle-free $2$-$\gamma_{\rm
MB}'$-critical graph.

</details>


### [43] [A simple proof that the edge density of Fon-der-Flaass $(3,4)$-graph is $\geq\frac{7}{16}(1-o(1))$](https://arxiv.org/abs/2507.17666)
*Veronica Phan*

Main category: math.CO

TL;DR: 本文给出了Fon-der-Flaass $(3,4)$-图边密度下界$\geq\frac{7}{16}(1-o(1))$的初等证明，简化了Razborov 2018年使用标志代数的证明方法。


<details>
  <summary>Details</summary>
Motivation: 2018年Razborov使用标志代数证明了Fon-der-Flaass $(3,4)$-图的边密度下界，但该方法较为复杂。本文旨在提供更简洁的初等证明。

Method: 采用初等组合数学方法，避免了标志代数等高级工具，直接推导边密度下界。

Result: 成功证明了Fon-der-Flaass $(3,4)$-图的边密度至少为$\frac{7}{16}(1-o(1))$，与Razborov的结果一致。

Conclusion: 通过初等方法验证了Razborov的结论，为相关极值图论问题提供了更简洁的证明路径。

Abstract: In 2018, Alexander A. Razborov proved that the edge density of Fon-der-Flaass
$(3,4)$-graph is $\geq\frac{7}{16}(1-o(1))$, using flag algebras. In this
paper, we give an elementary proof of this result.

</details>


### [44] [Symmetric decompositions and Euler-Stirling statistics on Stirling permutations](https://arxiv.org/abs/2507.17667)
*Shi-Mei Ma,Jianfeng Wang,Guiying Yan,Jean Yeh,Yeong-Nan Yeh*

Main category: math.CO

TL;DR: 本文研究了Stirling排列的Euler-Stirling统计量，提出了多个对称分解方法，并引入了新的统计量如proper/improper ascent-plateau，展示了多项式的双$\gamma$-正性。


<details>
  <summary>Details</summary>
Motivation: 受Ji关于排列的Euler-Stirling统计量研究的启发，本文旨在探索Stirling排列的相关统计量的对称分解及其应用。

Method: 通过语法变换和参数化方法，推导了$(p,q)$-Eulerian多项式与$(\alpha,\beta)$-Eulerian多项式的关系，并引入了新的统计量如proper/improper ascent-plateau。

Result: 给出了$1/k$-Eulerian多项式的部分对称分解，证明了$q$-ascent-plateau多项式的双$\gamma$-正性，并研究了Euler-Stirling统计量的联合分布。

Conclusion: 本文不仅扩展了Stirling排列的统计量研究，还通过对称分解和多项式性质的分析，为组合数学提供了新的工具和视角。

Abstract: The Stirling permutations introduced by Gessel-Stanley have recently received
considerable attention. Motivated by Ji's recent work on Euler-Stirling
statistics of permutations (Sci China Math., 2025), we present several
symmetric decompositions of the enumerators related to Euler-Stirling
statistics of Stirling permutations. Firstly, we provide a partial symmetric
decomposition for the $1/k$-Eulerian polynomial. Secondly, we give several
unexpected applications of the $(p,q)$-Eulerian polynomials, where $p$ marks
the number of fixed points and $q$ marks that of cycles. Using the change of
grammars, we show that the $(\alpha,\beta)$-Eulerian polynomials introduced by
Carlitz-Scoville can be deduced from the $(p,q)$-Eulerian polynomials by
special parametrizations. We then introduce proper and improper ascent-plateau
statistics on Stirling permutations. Moreover, we introduce proper ascent,
improper ascent, proper descent and improper descent statistics on
permutations. Furthermore, we consider the joint distributions of
Euler-Stirling statistics on permutations, including the numbers of improper
ascents, proper ascents, left-to-right minima and right-to-left minina. In the
final part, we first give a symmetric decomposition of the joint distribution
of the ascent-plateau and left ascent-plateau statistics, and then we show that
the $q$-ascent-plateau polynomials are bi-$\gamma$-positive, where $q$ marks
the number of left-to-right minima.

</details>


### [45] [Optimal stability results on color-biased Hamilton cycles](https://arxiv.org/abs/2507.17739)
*Wenchong Chen,Mingyuan Rong,Zixiang Xu*

Main category: math.CO

TL;DR: 本文研究了边着色图中哈密顿环的颜色偏差问题，证明了最优稳定性结果：当顶点数n的图最小度超过$\frac{n}{2} + 6r^{2}m$时，若所有哈密顿环颜色偏差小于m，则该图必须接近Freschi等人的极值构造。


<details>
  <summary>Details</summary>
Motivation: 研究边着色图中哈密顿环的颜色偏差（即颜色频率的最大偏离），旨在理解极值图的结构特性及其与最小度条件的关系。

Method: 通过局部构型推导全局结构，揭示了一种刚性的组合二分法，并利用极值图理论进行分析。

Result: 证明了最小度条件$\frac{n}{2} + 6r^{2}m$的最优性，且当m较大且r=2时，加法误差项$\Theta(m)$也是最优的。结构稳定性阈值$\frac{1}{2}$严格低于强制颜色不平衡所需的极值阈值$\frac{1}{2} + \frac{1}{2r}$。

Conclusion: 研究揭示了边着色图中哈密顿环颜色偏差与图结构之间的深刻联系，为极值图理论提供了新的稳定性结果。

Abstract: We investigate Hamilton cycles in edge-colored graphs with \( r \) colors,
focusing on the notion of color-bias (discrepancy), the maximum deviation from
uniform color frequencies along a cycle. Foundational work by Balogh, Csaba,
Jing, and Pluh\'{a}r, and the later generalization by Freschi, Hyde, Lada, and
Treglown, as well as an independent work by Gishboliner, Krivelevich, and
Michaeli, established that any \(n\)-vertex graph with minimum degree exceeding
\( \frac{(r+1)n}{2r} + \frac{m}{2}\) contains a Hamilton cycle with color-bias
at least \(m\), and characterized the extremal graphs with minimum degree
\(\frac{(r+1)n}{2r}\) in which all Hamilton cycles are perfectly balanced.
  We prove the optimal stability results: for any positive integers \(r\ge 2\)
and \( m < 2^{-6} r^{2} n,\) if every Hamilton cycle in an \( n \)-vertex graph
with minimum degree exceeding \( \frac{n}{2} + 6r^{2}m \) has color-bias less
than \( m \), then the graph must closely resemble the extremal constructions
of Freschi, Hyde, Lada, and Treglown. The leading term \( \frac{n}{2} \) in the
degree condition is optimal, as it is the sharp threshold for guaranteeing
Hamiltonicity. Moreover, we show the additive error term \(\Theta(m)\) is also
best possible when \(m\) is large and \(r=2\), since weaker condition
$\frac{n}{2}+o(m)$ allow for a counterexample. Notably, the structural
stability threshold \( \frac{1}{2} \) lies strictly below the extremal
threshold \( \frac{1}{2} + \frac{1}{2r} \) required to force color imbalance.
Our proof leverages local configurations to deduce global structure, revealing
a rigid combinatorial dichotomy.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [46] [Optimal Trading under Instantaneous and Persistent Price Impact, Predictable Returns and Multiscale Stochastic Volatility](https://arxiv.org/abs/2507.17162)
*Patrick Chan,Ronnie Sircar,Iosif Zimbidis*

Main category: q-fin.CP

TL;DR: 本文扩展了Garleanu和Pedersen(2013)的静态波动率假设，研究了包含可预测收益、即时交易成本、价格影响和随机波动的动态投资组合优化问题，提出了多尺度波动率展开方法，并通过蒙特卡洛模拟验证了策略改进效果。


<details>
  <summary>Details</summary>
Motivation: 经典投资组合优化理论假设波动率恒定，但实际市场中波动率具有随机性。本文旨在解决随机波动率、交易成本和价格影响等多因素耦合下的动态组合优化难题。

Method: 采用多尺度波动率展开技术：对快速均值回复的波动因子进行奇异摄动分析，对慢变因子进行正则摄动分析；同时引入小价格冲击近似，并通过蒙特卡洛模拟验证数值精度。

Result: 推导出二阶渐近近似解，数值实验表明该修正策略能有效提升组合损益(PnL)表现。随机波动率的多尺度特性被成功捕捉并量化。

Conclusion: 所提出的多尺度分析方法成功解决了随机波动率下非线性HJB方程的求解难题，为复杂市场环境下的动态资产配置提供了有效工具。

Abstract: We consider a dynamic portfolio optimization problem that incorporates
predictable returns, instantaneous transaction costs, price impact, and
stochastic volatility, extending the classical results of Garleanu and Pedersen
(2013), which assume constant volatility. Constructing the optimal portfolio
strategy in this general setting is challenging due to the nonlinear nature of
the resulting Hamilton-Jacobi-Bellman (HJB) equations. To address this, we
propose a multi-scale volatility expansion that captures stochastic volatility
dynamics across different time scales. Specifically, the analysis involves a
singular perturbation for the fast mean-reverting volatility factor and a
regular perturbation for the slow-moving factor. We also introduce an
approximation for small price impact and demonstrate its numerical accuracy. We
formally derive asymptotic approximations up to second order and use Monte
Carlo simulations to show how incorporating these corrections improves the
Profit and Loss (PnL) of the resulting portfolio strategy.

</details>


### [47] [Time Deep Gradient Flow Method for pricing American options](https://arxiv.org/abs/2507.17606)
*Jasper Rou*

Main category: q-fin.CP

TL;DR: 本研究探索了基于神经网络的多维美式看跌期权定价方法，比较了TDGF和DGM两种方法在BlackScholes和Heston模型下的表现，最高扩展到五维空间。两种方法在计算速度上均优于传统蒙特卡洛方法，其中TDGF训练速度更快。


<details>
  <summary>Details</summary>
Motivation: 针对多维美式期权定价的复杂性，研究旨在开发高效的神经网络方法，突破传统蒙特卡洛方法的计算瓶颈，特别是在高维场景下的应用。

Method: 扩展了TDGF方法以处理美式期权的自由边界偏微分方程问题，并优化了训练采样策略；同时对比了DGM方法。两种方法均采用神经网络架构，在BlackScholes和Heston模型下测试至五维。

Result: TDGF和DGM均实现高精度定价，计算速度显著快于蒙特卡洛方法。TDGF在训练效率上优于DGM，尤其在处理高维问题时表现更突出。

Conclusion: 神经网络方法（特别是TDGF）为高维美式期权定价提供了高效解决方案，其速度优势为实时定价和风险管理开辟了新途径。未来可进一步探索更高维度及其他衍生品类型的应用。

Abstract: In this research, we explore neural network-based methods for pricing
multidimensional American put options under the BlackScholes and Heston model,
extending up to five dimensions. We focus on two approaches: the Time Deep
Gradient Flow (TDGF) method and the Deep Galerkin Method (DGM). We extend the
TDGF method to handle the free-boundary partial differential equation inherent
in American options. We carefully design the sampling strategy during training
to enhance performance. Both TDGF and DGM achieve high accuracy while
outperforming conventional Monte Carlo methods in terms of computational speed.
In particular, TDGF tends to be faster during training than DGM.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [48] [CASPER: Contrastive Approach for Smart Ponzi Scheme Detecter with More Negative Samples](https://arxiv.org/abs/2507.16840)
*Weijia Yang,Tian Lan,Leyuan Liu,Wei Chen,Tianqing Zhu,Sheng Wen,Xiaosong Zhang*

Main category: cs.CR

TL;DR: 本文提出了一种名为CASPER的新型对比学习框架，用于检测区块链中的智能庞氏骗局，通过利用未标记数据集显著提高了检测效率并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 随着区块链技术的发展，智能庞氏骗局日益猖獗。传统基于深度学习的检测方法依赖大量标记数据，但此类数据稀缺，限制了模型训练效果。

Method: CASPER采用对比学习技术，通过增加负样本数量，从未标记数据中学习智能合约源代码的更有效表示，从而降低系统复杂性和操作成本。

Result: 在XBlock数据集上，CASPER在使用100%标记数据时F1分数比基线高2.3%；仅使用25%标记数据时，F1分数比基线高近20%。

Conclusion: CASPER展示了高效且经济地检测智能庞氏骗局的潜力，为未来可扩展的欺诈检测解决方案奠定了基础。

Abstract: The rapid evolution of digital currency trading, fueled by the integration of
blockchain technology, has led to both innovation and the emergence of smart
Ponzi schemes. A smart Ponzi scheme is a fraudulent investment operation in
smart contract that uses funds from new investors to pay returns to earlier
investors. Traditional Ponzi scheme detection methods based on deep learning
typically rely on fully supervised models, which require large amounts of
labeled data. However, such data is often scarce, hindering effective model
training. To address this challenge, we propose a novel contrastive learning
framework, CASPER (Contrastive Approach for Smart Ponzi detectER with more
negative samples), designed to enhance smart Ponzi scheme detection in
blockchain transactions. By leveraging contrastive learning techniques, CASPER
can learn more effective representations of smart contract source code using
unlabeled datasets, significantly reducing both operational costs and system
complexity. We evaluate CASPER on the XBlock dataset, where it outperforms the
baseline by 2.3% in F1 score when trained with 100% labeled data. More
impressively, with only 25% labeled data, CASPER achieves an F1 score nearly
20% higher than the baseline under identical experimental conditions. These
results highlight CASPER's potential for effective and cost-efficient detection
of smart Ponzi schemes, paving the way for scalable fraud detection solutions
in the future.

</details>


### [49] [SynthCTI: LLM-Driven Synthetic CTI Generation to enhance MITRE Technique Mapping](https://arxiv.org/abs/2507.16852)
*Álvaro Ruiz-Ródenas,Jaime Pujante Sáez,Daniel García-Algora,Mario Rodríguez Béjar,Jorge Blasco,José Luis Hernández-Ramos*

Main category: cs.CR

TL;DR: 本文提出SynthCTI框架，通过数据增强生成高质量合成网络威胁情报（CTI）句子，解决MITRE ATT\&CK技术分类中的数据稀缺和类别不平衡问题，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前CTI挖掘中，将威胁描述映射到MITRE ATT\&CK技术主要依赖人工，自动化方法面临高质量标注数据稀缺和类别不平衡的挑战，现有研究多关注模型架构而非数据限制。

Method: SynthCTI采用基于聚类的策略从训练数据中提取语义上下文，指导大语言模型（LLM）生成词汇多样且语义忠实于少数类别的合成CTI句子。

Result: 在两个公开CTI数据集上的实验表明，合成数据使ALBERT的macro-F1从0.35提升至0.52（相对增益48.6%），SecureBERT达到0.6558（原0.4412）。增强后的小模型性能超过未增强的大模型。

Conclusion: SynthCTI证明了数据生成方法对构建高效CTI分类系统的价值，通过解决数据限制显著提升模型效果，尤其对小模型性能改善明显。

Abstract: Cyber Threat Intelligence (CTI) mining involves extracting structured
insights from unstructured threat data, enabling organizations to understand
and respond to evolving adversarial behavior. A key task in CTI mining is
mapping threat descriptions to MITRE ATT\&CK techniques. However, this process
is often performed manually, requiring expert knowledge and substantial effort.
Automated approaches face two major challenges: the scarcity of high-quality
labeled CTI data and class imbalance, where many techniques have very few
examples. While domain-specific Large Language Models (LLMs) such as SecureBERT
have shown improved performance, most recent work focuses on model architecture
rather than addressing the data limitations. In this work, we present SynthCTI,
a data augmentation framework designed to generate high-quality synthetic CTI
sentences for underrepresented MITRE ATT\&CK techniques. Our method uses a
clustering-based strategy to extract semantic context from training data and
guide an LLM in producing synthetic CTI sentences that are lexically diverse
and semantically faithful. We evaluate SynthCTI on two publicly available CTI
datasets, CTI-to-MITRE and TRAM, using LLMs with different capacity.
Incorporating synthetic data leads to consistent macro-F1 improvements: for
example, ALBERT improves from 0.35 to 0.52 (a relative gain of 48.6\%), and
SecureBERT reaches 0.6558 (up from 0.4412). Notably, smaller models augmented
with SynthCTI outperform larger models trained without augmentation,
demonstrating the value of data generation methods for building efficient and
effective CTI classification systems.

</details>


### [50] [Building a robust OAuth token based API Security: A High level Overview](https://arxiv.org/abs/2507.16870)
*Senthilkumar Gopal*

Main category: cs.CR

TL;DR: 本文探讨了构建基于令牌的API安全系统的基础知识，包括OAuth 2.0集成、令牌架构扩展、加密基础及持久化策略，旨在为开发者提供构建安全、可扩展系统的关键原则。


<details>
  <summary>Details</summary>
Motivation: 随着API的普及，安全认证和授权面临系统性挑战，需要可扩展的解决方案来应对不断演变的威胁环境。

Method: 论文提出了构建令牌安全系统的必要组件，包括OAuth 2.0集成、令牌生命周期管理、范围定义及吊销机制，并结合实际场景分析最佳实践。

Result: 通过遵循这些原则，开发者能够建立灵活且安全的API认证系统，同时满足特定领域的需求。

Conclusion: 本文为开发者提供了构建安全、可扩展令牌系统的关键知识，强调在实践与安全需求间取得平衡，以应对不断变化的威胁。

Abstract: APIs (Application Programming Interfaces) or Web Services are the
foundational building blocks that enable interconnected systems. However this
proliferation of APIs has also introduced security challenges that require
systematic and scalable solutions for secure authentication and authorization.
This paper presents the fundamentals necessary for building a such a
token-based API security system. It discusses the components necessary, the
integration of OAuth 2.0, extensibility of the token architectures, necessary
cryptographic foundations, and persistence strategies to ensure secure and
resilient operations. In addition to architectural concerns, the paper explores
best practices for token lifecycle management, scope definition, expiration
policies, and revocation mechanisms, all framed within a real-world scenario.
By adhering to these principles, developers can establish a robust baseline
while maintaining the flexibility to customize their domain-specific
requirements. The approach does not claim to cover all variations necessary for
diverse architectures but instead focuses on key principles essential for any
standard API token authentication system. Throughout, the paper emphasizes
balancing practical considerations with security imperatives and uses key
concepts such as the CIA triad, OAuth standards, secure token life cycle, and
practices for protecting sensitive user and application data. The intent is to
equip developers with the foundational knowledge necessary to build secure,
scalable token-based API security systems ready to handle the evolving threat
landscape.

</details>


### [51] [CompLeak: Deep Learning Model Compression Exacerbates Privacy Leakage](https://arxiv.org/abs/2507.16872)
*Na Li,Yansong Gao,Hongsheng Hu,Boyu Kuang,Anmin Fu*

Main category: cs.CR

TL;DR: 本文提出CompLeak框架，首次系统评估了模型压缩（剪枝、量化和权重聚类）带来的隐私风险，通过成员推理攻击（MIA）揭示了不同压缩配置下的隐私泄露问题，并在多种模型架构和数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前模型压缩技术主要关注资源效率与性能的权衡，却忽视了压缩操作引入的隐私风险。本研究旨在填补这一空白，揭示压缩模型可能导致的隐私泄露问题。

Method: CompLeak框架包含三种变体：1) CompLeakNR（单压缩模型攻击）；2) CompLeakSR（原始模型+单压缩模型联合分析）；3) CompLeakMR（多压缩模型协同攻击）。实验覆盖TensorFlow-Lite和PyTorch Mobile支持的三种主流压缩方法，在7种模型架构（包括BERT和GPT-2）和6个数据集上进行验证。

Result: 实验表明：1) 不同压缩模型对成员/非成员数据表现出差异性敏感度；2) 结合原始模型元信息（如置信度向量）可显著增强攻击效果；3) 多压缩模型协同分析能进一步放大隐私泄露风险。

Conclusion: 模型压缩会引入新的隐私攻击面，现有压缩技术需重新审视其安全性。CompLeak为量化隐私风险提供了方法论基础，未来压缩算法设计应兼顾效率与隐私保护。

Abstract: Model compression is crucial for minimizing memory storage and accelerating
inference in deep learning (DL) models, including recent foundation models like
large language models (LLMs). Users can access different compressed model
versions according to their resources and budget. However, while existing
compression operations primarily focus on optimizing the trade-off between
resource efficiency and model performance, the privacy risks introduced by
compression remain overlooked and insufficiently understood.
  In this work, through the lens of membership inference attack (MIA), we
propose CompLeak, the first privacy risk evaluation framework examining three
widely used compression configurations that are pruning, quantization, and
weight clustering supported by the commercial model compression framework of
Google's TensorFlow-Lite (TF-Lite) and Facebook's PyTorch Mobile. CompLeak has
three variants, given available access to the number of compressed models and
original model. CompLeakNR starts by adopting existing MIA methods to attack a
single compressed model, and identifies that different compressed models
influence members and non-members differently. When the original model and one
compressed model are available, CompLeakSR leverages the compressed model as a
reference to the original model and uncovers more privacy by combining meta
information (e.g., confidence vector) from both models. When multiple
compressed models are available with/without accessing the original model,
CompLeakMR innovatively exploits privacy leakage info from multiple compressed
versions to substantially signify the overall privacy leakage. We conduct
extensive experiments on seven diverse model architectures (from ResNet to
foundation models of BERT and GPT-2), and six image and textual benchmark
datasets.

</details>


### [52] [Revisiting Pre-trained Language Models for Vulnerability Detection](https://arxiv.org/abs/2507.16887)
*Youpeng Li,Weiliang Qi,Xuyu Wang,Fuxun Yu,Xinda Wang*

Main category: cs.CR

TL;DR: 本文提出RevisitVD框架，对17种预训练语言模型(PLMs)在漏洞检测(VD)任务中的表现进行全面评估，发现专为代码设计的PLMs优于通用模型，但面对复杂依赖、代码规范化扰动等现实场景仍存在显著挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究对预训练语言模型在漏洞检测任务中的评估存在数据准备、实验设置等方面的不足，导致评估结果不够准确全面。本文旨在通过系统性实验填补这一空白。

Method: 构建新数据集，比较17种PLMs在微调和提示工程下的表现，评估模型在不同训练/测试设置中的有效性、泛化性及对抗代码规范化/抽象化/语义保持变换的鲁棒性。

Result: 专为代码语法语义模式设计的PLMs表现最优，但存在三大局限：1) 难检测复杂依赖漏洞 2) 抗代码规范化扰动能力弱 3) 受限于上下文窗口导致标注错误。

Conclusion: 研究强调需加强模型在实际场景中的性能评估，并为提升PLMs在真实漏洞检测应用中的有效性指明未来方向。

Abstract: The rapid advancement of pre-trained language models (PLMs) has demonstrated
promising results for various code-related tasks. However, their effectiveness
in detecting real-world vulnerabilities remains a critical challenge. % for the
security community. While existing empirical studies evaluate PLMs for
vulnerability detection (VD), their inadequate consideration in data
preparation, evaluation setups, and experimental settings undermines the
accuracy and comprehensiveness of evaluations. This paper introduces RevisitVD,
an extensive evaluation of 17 PLMs spanning smaller code-specific PLMs and
large-scale PLMs using newly constructed datasets. Specifically, we compare the
performance of PLMs under both fine-tuning and prompt engineering, assess their
effectiveness and generalizability across various training and testing
settings, and analyze their robustness against code normalization, abstraction,
and semantic-preserving transformations.
  Our findings reveal that, for VD tasks, PLMs incorporating pre-training tasks
designed to capture the syntactic and semantic patterns of code outperform both
general-purpose PLMs and those solely pre-trained or fine-tuned on large code
corpora. However, these models face notable challenges in real-world scenarios,
such as difficulties in detecting vulnerabilities with complex dependencies,
handling perturbations introduced by code normalization and abstraction, and
identifying semantic-preserving vulnerable code transformations. Also, the
truncation caused by the limited context windows of PLMs can lead to a
non-negligible amount of labeling errors. This study underscores the importance
of thorough evaluations of model performance in practical scenarios and
outlines future directions to help enhance the effectiveness of PLMs for
realistic VD applications.

</details>


### [53] [Evaluating Ensemble and Deep Learning Models for Static Malware Detection with Dimensionality Reduction Using the EMBER Dataset](https://arxiv.org/abs/2507.16952)
*Md Min-Ha-Zul Abedin,Tazqia Mehrub*

Main category: cs.CR

TL;DR: 本研究评估了八种机器学习算法在EMBER数据集上的静态恶意软件检测效果，发现集成方法（尤其是LightGBM和XGBoost）在所有配置中表现最佳，而特征降维需根据模型类型选择性应用。


<details>
  <summary>Details</summary>
Motivation: 探讨不同机器学习算法及预处理方法在高维静态恶意软件检测中的性能差异，为实际系统开发提供基准和指导。

Method: 使用EMBER数据集，评估LightGBM、XGBoost等八种分类模型在原始特征空间、PCA和LDA三种预处理设置下的表现，通过准确率、召回率等指标及EDA分析（包括互信息排序、t-SNE可视化等）验证特征判别能力。

Result: 集成方法（特别是LightGBM和XGBoost）在所有配置中表现最优且对PCA不敏感；LDA提升了KNN但显著降低了提升模型的准确率；TabNet在特征降维下表现不佳。EDA证实了EMBER数据集关键特征的判别能力。

Conclusion: 提升模型是高维静态恶意软件检测最可靠的选择，特征降维需根据模型类型谨慎应用。本研究为分类模型和预处理策略的比较提供了基准，对实际部署具有指导意义。

Abstract: This study investigates the effectiveness of several machine learning
algorithms for static malware detection using the EMBER dataset, which contains
feature representations of Portable Executable (PE) files. We evaluate eight
classification models: LightGBM, XGBoost, CatBoost, Random Forest, Extra Trees,
HistGradientBoosting, k-Nearest Neighbors (KNN), and TabNet, under three
preprocessing settings: original feature space, Principal Component Analysis
(PCA), and Linear Discriminant Analysis (LDA). The models are assessed on
accuracy, precision, recall, F1 score, and AUC to examine both predictive
performance and robustness. Ensemble methods, especially LightGBM and XGBoost,
show the best overall performance across all configurations, with minimal
sensitivity to PCA and consistent generalization. LDA improves KNN performance
but significantly reduces accuracy for boosting models. TabNet, while promising
in theory, underperformed under feature reduction, likely due to architectural
sensitivity to input structure. The analysis is supported by detailed
exploratory data analysis (EDA), including mutual information ranking, PCA or
t-SNE visualizations, and outlier detection using Isolation Forest and Local
Outlier Factor (LOF), which confirm the discriminatory capacity of key features
in the EMBER dataset. The results suggest that boosting models remain the most
reliable choice for high-dimensional static malware detection, and that
dimensionality reduction should be applied selectively based on model type.
This work provides a benchmark for comparing classification models and
preprocessing strategies in malware detection tasks and contributes insights
that can guide future system development and real-world deployment.

</details>


### [54] [From Cracks to Crooks: YouTube as a Vector for Malware Distribution](https://arxiv.org/abs/2507.16996)
*Iman Vakilinia*

Main category: cs.CR

TL;DR: 本文研究了网络犯罪分子如何利用YouTube平台传播恶意软件，特别关注了通过免费软件或游戏作弊工具进行欺骗性推广的活动，并提出了一种新的规避检测技术。


<details>
  <summary>Details</summary>
Motivation: YouTube拥有数十亿用户和每日海量上传内容，成为网络犯罪分子利用其庞大受众的理想目标。平台的开放性和可信度为欺骗性活动提供了隐蔽环境。

Method: 研究分析了通过视频演示传播恶意软件的技术，并提出了一种滥用YouTube多语言元数据功能的新型规避技术，以绕过自动化检测系统。

Result: 研究发现，这种新型规避技术在近期恶意视频中的使用频率增加，有效帮助恶意内容逃避检测和删除。

Conclusion: YouTube平台存在被恶意软件传播滥用的风险，新型多语言元数据规避技术加剧了这一威胁，需要更先进的检测手段应对。

Abstract: With billions of users and an immense volume of daily uploads, YouTube has
become an attractive target for cybercriminals aiming to leverage its vast
audience. The platform's openness and trustworthiness provide an ideal
environment for deceptive campaigns that can operate under the radar of
conventional security tools. This paper explores how cybercriminals exploit
YouTube to disseminate malware, focusing on campaigns that promote free
software or game cheats. It discusses deceptive video demonstrations and the
techniques behind malware delivery. Additionally, the paper presents a new
evasion technique that abuses YouTube's multilingual metadata capabilities to
circumvent automated detection systems. Findings indicate that this method is
increasingly being used in recent malicious videos to avoid detection and
removal.

</details>


### [55] [The Postman: A Journey of Ethical Hacking in PosteID/SPID Borderland](https://arxiv.org/abs/2507.17007)
*Gabriele Costa*

Main category: cs.CR

TL;DR: 本文对意大利邮政的公共数字身份系统PosteID进行了漏洞评估，发现并修补了一个关键权限提升漏洞，为道德黑客社区提供了有价值的案例研究。


<details>
  <summary>Details</summary>
Motivation: 评估PosteID系统的安全性，以发现潜在漏洞并提升公共数字身份系统的安全性。

Method: 通过技术分析步骤和漏洞披露流程，对PosteID系统进行了全面的漏洞评估。

Result: 发现了一个关键的权限提升漏洞，并最终成功修补。

Conclusion: 该研究不仅揭示了PosteID系统的安全漏洞，还为道德黑客社区提供了技术分析和漏洞披露的实践案例。

Abstract: This paper presents a vulnerability assessment activity that we carried out
on PosteID, the implementation of the Italian Public Digital Identity System
(SPID) by Poste Italiane. The activity led to the discovery of a critical
privilege escalation vulnerability, which was eventually patched. The overall
analysis and disclosure process represents a valuable case study for the
community of ethical hackers. In this work, we present both the technical steps
and the details of the disclosure process.

</details>


### [56] [Towards Trustworthy AI: Secure Deepfake Detection using CNNs and Zero-Knowledge Proofs](https://arxiv.org/abs/2507.17010)
*H M Mohaimanul Islam,Huynh Q. N. Vo,Aditya Rane*

Main category: cs.CR

TL;DR: 提出TrustDefender框架，结合轻量级CNN和零知识证明协议，实现XR流中深度伪造图像的实时检测与隐私保护验证。


<details>
  <summary>Details</summary>
Motivation: 合成媒体时代下，深度伪造技术对信息完整性构成威胁，需兼顾XR平台算力限制与隐私保护需求。

Method: 两阶段框架：1) 轻量级CNN实时检测XR流中的深度伪造图像；2) 集成零知识证明协议验证结果，避免原始数据泄露。

Result: 在多个基准数据集上达到95.3%检测准确率，密码学保障的高效证明生成，支持高性能AI系统无缝集成。

Conclusion: 通过计算机视觉与可证明安全机制的结合，为沉浸式隐私敏感应用中的可信AI奠定基础。

Abstract: In the era of synthetic media, deepfake manipulations pose a significant
threat to information integrity. To address this challenge, we propose
TrustDefender, a two-stage framework comprising (i) a lightweight convolutional
neural network (CNN) that detects deepfake imagery in real-time extended
reality (XR) streams, and (ii) an integrated succinct zero-knowledge proof
(ZKP) protocol that validates detection results without disclosing raw user
data. Our design addresses both the computational constraints of XR platforms
while adhering to the stringent privacy requirements in sensitive settings.
Experimental evaluations on multiple benchmark deepfake datasets demonstrate
that TrustDefender achieves 95.3% detection accuracy, coupled with efficient
proof generation underpinned by rigorous cryptography, ensuring seamless
integration with high-performance artificial intelligence (AI) systems. By
fusing advanced computer vision models with provable security mechanisms, our
work establishes a foundation for reliable AI in immersive and
privacy-sensitive applications.

</details>


### [57] [GATEBLEED: Exploiting On-Core Accelerator Power Gating for High Performance & Stealthy Attacks on AI](https://arxiv.org/abs/2507.17033)
*Joshua Kalyanapu,Farshad Dizani,Darsh Asher,Azam Ghanbari,Rosario Cammarota,Aydin Aysu,Samira Mirbagher Ajorpaz*

Main category: cs.CR

TL;DR: 研究发现Intel AMX加速器因激进电源门控导致GATEBLEED时序侧信道漏洞，可泄露AI模型隐私数据，威胁本地及远程安全。


<details>
  <summary>Details</summary>
Motivation: 随着AI训练与推理功耗激增，CPU集成加速器（如Intel AMX）成为常态，但其电源管理机制可能引发新型安全风险。

Method: 通过分析AMX电源门控导致的时序差异，在主流ML库（HuggingFace/PyTorch等）中定位十多个漏洞点，构建端到端微架构推理攻击。

Result: 针对AMX优化的Transformer模型实现81%成员推理准确率；在专家混合模型中100%泄露专家选择路径，突破现有防护措施。

Conclusion: GATEBLEED作为高性能隐蔽信道，可绕过缓存防御及检测系统，暴露AI隐私决策关键数据（如置信度阈值），需重新设计硬件安全方案。

Abstract: As power consumption from AI training and inference continues to increase, AI
accelerators are being integrated directly into the CPU. Intel's Advanced
Matrix Extensions (AMX) is one such example, debuting on the 4th generation
Intel Xeon Scalable CPU. We discover a timing side and covert channel,
GATEBLEED, caused by the aggressive power gating utilized to keep the CPU
within operating limits. We show that the GATEBLEED side channel is a threat to
AI privacy as many ML models such as transformers and CNNs make critical
computationally-heavy decisions based on private values like confidence
thresholds and routing logits. Timing delays from selective powering down of
AMX components mean that each matrix multiplication is a potential leakage
point when executed on the AMX accelerator. Our research identifies over a
dozen potential gadgets across popular ML libraries (HuggingFace, PyTorch,
TensorFlow, etc.), revealing that they can leak sensitive and private
information. GATEBLEED poses a risk for local and remote timing inference, even
under previous protective measures. GATEBLEED can be used as a high
performance, stealthy remote covert channel and a generic magnifier for timing
transmission channels, capable of bypassing traditional cache defenses to leak
arbitrary memory addresses and evading state of the art microarchitectural
attack detectors under realistic network conditions and system configurations
in which previous attacks fail. We implement an end-to-end microarchitectural
inference attack on a transformer model optimized with Intel AMX, achieving a
membership inference accuracy of 81% and a precision of 0.89. In a CNN-based or
transformer-based mixture-of-experts model optimized with Intel AMX, we leak
expert choice with 100% accuracy.

</details>


### [58] [SoK: Securing the Final Frontier for Cybersecurity in Space-Based Infrastructure](https://arxiv.org/abs/2507.17064)
*Nafisa Anjum,Tasnuva Farheen*

Main category: cs.CR

TL;DR: 随着现代技术的发展，关键基础设施、通信和国家安全日益依赖空间资产，这些资产面临严重的网络攻击威胁。本研究全面分析了空间网络攻击途径，评估了缓解措施的有效性，并提出了风险评分框架。


<details>
  <summary>Details</summary>
Motivation: 空间资产及其相关系统（如数据中继系统和地面站）面临严重的网络攻击威胁，需要强大的安全防御来确保数据完整性、维护安全操作并保护资产。以往研究虽发现了一些漏洞并提出了具体解决方案，但缺乏对空间网络攻击途径的全面分析和缓解措施效果的严格评估。

Method: 本研究采用综合方法，分析了可能的空间网络攻击途径，包括地面、空间、卫星和卫星星座。同时，评估了与空间基础设施相关的缓解措施的有效性，并提出了一个风险评分框架。

Result: 研究识别了空间网络攻击的多种途径，并评估了相关缓解措施的效果。基于分析，提出了一个风险评分框架，并指出了开发测试尖端技术解决方案的潜在研究挑战。

Conclusion: 本研究强调了空间网络安全的重要性，提出了风险评分框架，并呼吁开发更强大的网络安全措施以应对空间资产面临的威胁。

Abstract: With the advent of modern technology, critical infrastructure,
communications, and national security depend increasingly on space-based
assets. These assets, along with associated assets like data relay systems and
ground stations, are, therefore, in serious danger of cyberattacks. Strong
security defenses are essential to ensure data integrity, maintain secure
operations, and protect assets in space and on the ground against various
threats. Previous research has found discrete vulnerabilities in space systems
and suggested specific solutions to address them. Such research has yielded
valuable insights, but lacks a thorough examination of space cyberattack
vectors and a rigorous assessment of the efficacy of mitigation techniques.
This study tackles this issue by taking a comprehensive approach to analyze the
range of possible space cyber-attack vectors, which include ground, space,
satellite, and satellite constellations. In order to address the particular
threats, the study also assesses the efficacy of mitigation measures that are
linked with space infrastructures and proposes a Risk Scoring Framework. Based
on the analysis, this paper identifies potential research challenges for
developing and testing cutting-edge technology solutions, encouraging robust
cybersecurity measures needed in space.

</details>


### [59] [Analysis of Post-Quantum Cryptography in User Equipment in 5G and Beyond](https://arxiv.org/abs/2507.17074)
*Sanzida Hoque,Abdullah Aydeger,Engin Zeydan,Madhusanka Liyanage*

Main category: cs.CR

TL;DR: 本文评估了NIST选定的后量子密码（PQC）算法在5G网络用户设备间通信中的性能表现，发现ML-KEM与ML-DSA组合最适合时延敏感应用。


<details>
  <summary>Details</summary>
Motivation: 量子计算的兴起威胁传统公钥密码系统安全，需转向后量子密码（PQC）。现有研究多集中于理论分析，PQC在实际无线通信环境中的性能尚不明确。

Method: 研究使用5G全栈仿真平台（Open5GS和UERANSIM）及支持PQC的TLS 1.3（通过BoringSSL和liboqs实现），在真实网络条件下测试密钥封装机制和数字签名方案，评估握手延迟、CPU/内存占用、带宽及重传率等指标。

Result: 实验表明：ML-KEM+ML-DSA组合在时延敏感场景中效率最优；SPHINCS+与HQC组合因计算和传输开销较高，不适用于对安全性要求高且时间敏感的5G场景。

Conclusion: 后量子密码算法需根据具体场景选择——ML-KEM与ML-DSA适合5G时延敏感应用，而SPHINCS+和HQC因高开销需谨慎部署。

Abstract: The advent of quantum computing threatens the security of classical
public-key cryptographic systems, prompting the transition to post-quantum
cryptography (PQC). While PQC has been analyzed in theory, its performance in
practical wireless communication environments remains underexplored. This paper
presents a detailed implementation and performance evaluation of NIST-selected
PQC algorithms in user equipment (UE) to UE communications over 5G networks.
Using a full 5G emulation stack (Open5GS and UERANSIM) and PQC-enabled TLS 1.3
via BoringSSL and liboqs, we examine key encapsulation mechanisms and digital
signature schemes across realistic network conditions. We evaluate performance
based on handshake latency, CPU and memory usage, bandwidth, and retransmission
rates, under varying cryptographic configurations and client loads. Our
findings show that ML-KEM with ML-DSA offers the best efficiency for
latency-sensitive applications, while SPHINCS+ and HQC combinations incur
higher computational and transmission overheads, making them unsuitable for
security-critical but time-sensitive 5G scenarios.

</details>


### [60] [A Privacy-Preserving Data Collection Method for Diversified Statistical Analysis](https://arxiv.org/abs/2507.17180)
*Hao Jiang,Quan Zhou,Dongdong Zhao,Shangshang Yang,Wenjian Luo,Xingyi Zhang*

Main category: cs.CR

TL;DR: 本文提出了一种新型实值负调查模型RVNS，用于实值敏感信息收集，解决了现有方法仅适用于离散数据的局限性，并通过理论分析和实验验证了其隐私保护效果和数据分布还原能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于数据扰动的隐私保护方法主要关注个体统计指标，忽视了数据分布的整体质量，且现有负调查方法仅适用于离散敏感信息，无法满足实值数据分布的需求。

Method: 提出RVNS模型，用户无需离散化数据，仅需从偏离真实敏感数据的范围内采样，并通过优化问题准确还原敏感信息分布，同时理论证明其符合差分隐私模型。

Result: 理论分析表明RVNS模型符合差分隐私要求，综合实验在合成和真实数据集上验证了该方法的有效性。

Conclusion: RVNS模型首次实现了实值敏感信息的隐私保护收集，兼具高效性和分布还原能力，为实际数据分析中的多样化统计需求提供了解决方案。

Abstract: Data perturbation-based privacy-preserving methods have been widely adopted
in various scenarios due to their efficiency and the elimination of the need
for a trusted third party. However, these methods primarily focus on individual
statistical indicators, neglecting the overall quality of the collected data
from a distributional perspective. Consequently, they often fall short of
meeting the diverse statistical analysis requirements encountered in practical
data analysis. As a promising sensitive data perturbation method, negative
survey methods is able to complete the task of collecting sensitive information
distribution while protecting personal privacy. Yet, existing negative survey
methods are primarily designed for discrete sensitive information and are
inadequate for real-valued data distributions. To bridge this gap, this paper
proposes a novel real-value negative survey model, termed RVNS, for the first
time in the field of real-value sensitive information collection. The RVNS
model exempts users from the necessity of discretizing their data and only
requires them to sample a set of data from a range that deviates from their
actual sensitive details, thereby preserving the privacy of their genuine
information. Moreover, to accurately capture the distribution of sensitive
information, an optimization problem is formulated, and a novel approach is
employed to solve it. Rigorous theoretical analysis demonstrates that the RVNS
model conforms to the differential privacy model, ensuring robust privacy
preservation. Comprehensive experiments conducted on both synthetic and
real-world datasets further validate the efficacy of the proposed method.

</details>


### [61] [Threshold-Protected Searchable Sharing: Privacy Preserving Aggregated-ANN Search for Collaborative RAG](https://arxiv.org/abs/2507.17199)
*Ruoyang Rykie Guo*

Main category: cs.CR

TL;DR: 本文提出了一种兼容HNSW的安全隐私保护聚合近似最近邻搜索方法(SP-A$^2$NN)，通过可共享的bitgraph结构支持跨私有数据源的动态搜索与插入，将搜索复杂度从$O(n^2)$降至$O(n)$，并建立了针对AI数据泄漏的新型安全分析框架。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的搜索服务需要整合分散的私有知识库，但面临数据本地性限制与主流搜索技术(如HNSW索引)兼容性的双重瓶颈，亟需隐私保护的高效跨库搜索方案。

Method: 基于阈值可搜索共享原语构建可扩展的bitgraph结构，保持底层图拓扑不变；提出泄漏猜测证明系统，通过独立于现有硬币抛掷游戏的新型交互式博弈进行隐私分析。

Result: 相比原始无向图共享方法，在相同HNSW架构下将搜索复杂度从$O(n^2)$优化至$O(n)$，同时支持共享数据的动态插入与安全检索。

Conclusion: SP-A$^2$NN有效解决了跨私有知识库的兼容性搜索难题，其标准化泄漏分析框架为AI高速发展中的关键安全问题提供了理论支撑与实践方案。

Abstract: LLM-powered search services have driven data integration as a significant
trend. However, this trend's progress is fundamentally hindered, despite the
fact that combining individual knowledge can significantly improve the
relevance and quality of responses in specialized queries and make AI more
professional at providing services. Two key bottlenecks are private data
repositories' locality constraints and the need to maintain compatibility with
mainstream search techniques, particularly Hierarchical Navigable Small World
(HNSW) indexing for high-dimensional vector spaces. In this work, we develop a
secure and privacy-preserving aggregated approximate nearest neighbor search
(SP-A$^2$NN) with HNSW compatibility under a threshold-based searchable sharing
primitive. A sharable bitgraph structure is constructed and extended to support
searches and dynamical insertions over shared data without compromising the
underlying graph topology. The approach reduces the complexity of a search from
$O(n^2)$ to $O(n)$ compared to naive (undirected) graph-sharing approach when
organizing graphs in the identical HNSW manner.
  On the theoretical front, we explore a novel security analytical framework
that incorporates privacy analysis via reductions. The proposed
leakage-guessing proof system is built upon an entirely different interactive
game that is independent of existing coin-toss game design. Rather than being
purely theoretical, this system is rooted in existing proof systems but goes
beyond them to specifically address leakage concerns and standardize leakage
analysis -- one of the most critical security challenges with AI's rapid
development.

</details>


### [62] [Tab-MIA: A Benchmark Dataset for Membership Inference Attacks on Tabular Data in LLMs](https://arxiv.org/abs/2507.17259)
*Eyal German,Sagiv Antebi,Daniel Samira,Asaf Shabtai,Yuval Elovici*

Main category: cs.CR

TL;DR: 大型语言模型（LLMs）在处理表格数据时面临隐私风险，Tab-MIA基准数据集首次系统评估了表格数据在多种编码格式下的成员推理攻击（MIA）效果，揭示LLMs对结构化数据的记忆行为差异及高脆弱性。


<details>
  <summary>Details</summary>
Motivation: 由于表格数据常包含显式的个人身份信息（PII），而现有MIA方法主要针对文本数据，其在结构化数据上的效果和威胁尚未明确，需系统性评估LLMs对表格数据的隐私风险。

Method: 提出Tab-MIA基准数据集，包含五种数据集合和六种编码格式，首次对微调后的LLMs进行多编码格式下的MIA评估，并分析模型对维基百科表格数据的记忆行为。

Result: 实验表明，LLMs对不同编码格式的表格数据记忆方式各异，即使仅微调三个周期，模型AUROC分数仍接近90%，显示出极高的MIA攻击脆弱性。

Conclusion: Tab-MIA为系统评估表格数据隐私风险提供了基础，并助力开发LLMs的隐私保护方法，凸显当前模型在结构化数据上的严重安全隐患。

Abstract: Large language models (LLMs) are increasingly trained on tabular data, which,
unlike unstructured text, often contains personally identifiable information
(PII) in a highly structured and explicit format. As a result, privacy risks
arise, since sensitive records can be inadvertently retained by the model and
exposed through data extraction or membership inference attacks (MIAs). While
existing MIA methods primarily target textual content, their efficacy and
threat implications may differ when applied to structured data, due to its
limited content, diverse data types, unique value distributions, and
column-level semantics. In this paper, we present Tab-MIA, a benchmark dataset
for evaluating MIAs on tabular data in LLMs and demonstrate how it can be used.
Tab-MIA comprises five data collections, each represented in six different
encoding formats. Using our Tab-MIA benchmark, we conduct the first evaluation
of state-of-the-art MIA methods on LLMs finetuned with tabular data across
multiple encoding formats. In the evaluation, we analyze the memorization
behavior of pretrained LLMs on structured data derived from Wikipedia tables.
Our findings show that LLMs memorize tabular data in ways that vary across
encoding formats, making them susceptible to extraction via MIAs. Even when
fine-tuned for as few as three epochs, models exhibit high vulnerability, with
AUROC scores approaching 90% in most cases. Tab-MIA enables systematic
evaluation of these risks and provides a foundation for developing
privacy-preserving methods for tabular data in LLMs.

</details>


### [63] [An Empirical Study on Virtual Reality Software Security Weaknesses](https://arxiv.org/abs/2507.17324)
*Yifan Xu,Jinfu Chen,Zhenyu Qi,Huashan Chen,Junyi Wang,Pengfei Hu,Feng Liu,Sen He*

Main category: cs.CR

TL;DR: 本研究首次系统调查了334个GitHub上的VR项目，分析了1,681个安全弱点，发现VR软件安全研究不足，用户界面和资源相关弱点最为普遍，且开发工具风险高于应用本身。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实(VR)技术快速发展，但其安全弱点研究不足，公开数据库(如NVD)中VR安全弱点数据有限，亟需系统性调查。

Method: 通过构建新型框架从GitHub提交数据中提取VR安全弱点，建立了首个系统性VR软件安全弱点数据集，涵盖334个项目共1,681个弱点。

Result: 研究发现：(i)用户界面弱点占比最高，其次是资源相关弱点；(ii)VR开发工具比应用本身存在更高安全风险；(iii)多数弱点在VR软件诞生初期即被引入。

Conclusion: 该研究填补了VR安全领域的知识空白，揭示了VR弱点的分布特征与引入规律，为后续安全研究提供了首个系统性数据集。

Abstract: Virtual Reality (VR) has emerged as a transformative technology across
industries, yet its security weaknesses, including vulnerabilities, are
underinvestigated. This study investigates 334 VR projects hosted on GitHub,
examining 1,681 software security weaknesses to understand: what types of
weaknesses are prevalent in VR software; {\em when} and {\em how} weaknesses
are introduced; how long they have survived; and how they have been removed.
Due to the limited availability of VR software security weaknesses in public
databases (e.g., the National Vulnerability Database or NVD), we prepare the
{first systematic} dataset of VR software security weaknesses by introducing a
novel framework to collect such weaknesses from GitHub commit data. Our
empirical study on the dataset leads to useful insights, including: (i) VR
weaknesses are heavily skewed toward user interface weaknesses, followed by
resource-related weaknesses; (ii) VR development tools pose higher security
risks than VR applications; (iii) VR security weaknesses are often introduced
at the VR software birth time.

</details>


### [64] [A Zero-overhead Flow for Security Closure](https://arxiv.org/abs/2507.17385)
*Mohammad Eslami,Ashira Johara,Kyungbin Park,Samuel Pagliarini*

Main category: cs.CR

TL;DR: 本文提出了一种零开销的安全感知ASIC设计流程，在不降低传统QoR指标的前提下，有效应对硬件木马和物理探测/故障注入两大威胁模型，并在ISPD`22基准电路上实现了最佳安全性能。


<details>
  <summary>Details</summary>
Motivation: 传统ASIC设计流程在时序收敛时忽视安全性评估，商业布局布线工具缺乏安全目标考量，亟需开发不影响设计质量的安全增强方案。

Method: 在商用布局布线引擎内构建安全闭环节点，通过脚本化流程同时防御硬件木马植入和物理层攻击，保持设计流程的可扩展性。

Result: 在ISPD`22基准测试中取得最优安全指标，安全策略引入的设计开销可忽略不计，相关脚本和防护电路设计数据库已开源。

Conclusion: 该安全感知流程首次实现零开销的安全闭环，为硬件安全社区提供了可复用的方法论和实践资源。

Abstract: In the traditional Application-Specific Integrated Circuit (ASIC) design
flow, the concept of timing closure implies to reach convergence during
physical synthesis such that, under a given area and power budget, the design
works at the targeted frequency. However, security has been largely neglected
when evaluating the Quality of Results (QoR) from physical synthesis. In
general, commercial place & route tools do not understand security goals. In
this work, we propose a modified ASIC design flow that is security-aware and,
differently from prior research, does not degrade QoR for the sake of security
improvement. Therefore, we propose a first-of-its-kind zero-overhead flow for
security closure. Our flow is concerned with two distinct threat models: (i)
insertion of Hardware Trojans (HTs) and (ii) physical probing/fault injection.
Importantly, the flow is entirely executed within a commercial place & route
engine and is scalable. In several metrics, our security-aware flow achieves
the best-known results for the ISPD`22 set of benchmark circuits while
incurring negligible design overheads due to security-related strategies.
Finally, we open source the entire methodology (as a set of scripts) and also
share the protected circuits (as design databases) for the benefit of the
hardware security community.

</details>


### [65] [Active Attack Resilience in 5G: A New Take on Authentication and Key Agreement](https://arxiv.org/abs/2507.17491)
*Nazatul H. Sultan,Xinlong Guan,Josef Pieprzyk,Wei Ni,Sharif Abuadbba,Hajime Suzuki*

Main category: cs.CR

TL;DR: 本文提出了一种增强型5G-AKA认证协议，解决了现有5G-AKA协议在安全性和性能上的不足，包括无状态设计和完美前向保密性（PFS），并通过实验验证了其高效性和安全性。


<details>
  <summary>Details</summary>
Motivation: 5G-AKA协议虽被广泛采用，但仍存在安全漏洞（如缺乏PFS）和性能问题（如同步机制复杂）。随着5G网络扩展至关键基础设施，亟需更安全高效的认证方案。

Method: 首先提出无状态版本协议消除序列号依赖，保持与现有SIM卡兼容；随后扩展设计加入PFS功能。使用ProVerif进行形式化验证，并原型实现性能对比测试。

Result: 协议满足3GPP安全要求，可抵抗被动/主动攻击。性能测试显示其仅引入微小计算开销，较5G-AKA和5G-AKA'（USENIX'21）更具安全优势。

Conclusion: 所提协议在兼容现有设施前提下显著提升安全性，为5G及未来网络提供了实用解决方案。

Abstract: As 5G networks expand into critical infrastructure, secure and efficient user
authentication is more important than ever. The 5G-AKA protocol, standardized
by 3GPP in TS 33.501, is central to authentication in current 5G deployments.
It provides mutual authentication, user privacy, and key secrecy. However,
despite its adoption, 5G-AKA has known limitations in both security and
performance. While it focuses on protecting privacy against passive attackers,
recent studies show its vulnerabilities to active attacks. It also relies on a
sequence number mechanism to prevent replay attacks, requiring perfect
synchronization between the device and the core network. This stateful design
adds complexity, causes desynchronization, and incurs extra communication
overhead. More critically, 5G-AKA lacks Perfect Forward Secrecy (PFS), exposing
past communications if long-term keys are compromised-an increasing concern
amid sophisticated threats. This paper proposes an enhanced authentication
protocol that builds on 5G-AKA's design while addressing its shortcomings.
First, we introduce a stateless version that removes sequence number reliance,
reducing complexity while staying compatible with existing SIM cards and
infrastructure. We then extend this design to add PFS with minimal
cryptographic overhead. Both protocols are rigorously analyzed using ProVerif,
confirming their compliance with all major security requirements, including
resistance to passive and active attacks, as well as those defined by 3GPP and
academic studies. We also prototype both protocols and evaluate their
performance against 5G-AKA and 5G-AKA' (USENIX'21). Our results show the
proposed protocols offer stronger security with only minor computational
overhead, making them practical, future-ready solutions for 5G and beyond.

</details>


### [66] [Frequency Estimation of Correlated Multi-attribute Data under Local Differential Privacy](https://arxiv.org/abs/2507.17516)
*Shafizur Rahman Seeam,Ye Zheng,Yidan Hu*

Main category: cs.CR

TL;DR: 本文提出了一种名为Corr-RR的新型本地差分隐私机制，通过利用属性间的相关性显著提升数据效用，同时严格保证$\epsilon$-LDP隐私。该方法分两阶段操作：先由部分用户估计属性关联，再由其他用户扰动单一属性并推断其余属性，实验证明其在多属性强相关场景下优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有LDP机制要么平分隐私预算导致噪声过大，要么独立处理属性忽略相关性，造成高维数据下的严重效用损失。亟需一种能利用属性关联性提升效用的新方法。

Method: Corr-RR采用两阶段框架：1) 部分用户使用标准LDP机制估计属性间相关性；2) 其余用户随机选择一个属性施加全预算扰动，基于学习到的相关性推断其他属性，避免额外隐私开销。

Result: 理论证明满足$\epsilon$-LDP，在合成和真实数据集上的实验表明，Corr-RR在属性数量多、相关性强的场景下持续优于现有最优LDP机制。

Conclusion: Corr-RR通过创新性地利用属性相关性，在保持严格隐私保障的同时显著提高了高维数据收集场景下的数据效用，为LDP机制设计提供了新思路。

Abstract: Large-scale data collection, from national censuses to IoT-enabled smart
homes, routinely gathers dozens of attributes per individual. These
multi-attribute datasets are vital for analytics but pose significant privacy
risks. Local Differential Privacy (LDP) is a powerful tool to protect user data
privacy by allowing users to locally perturb their records before releasing to
an untrusted data aggregator. However, existing LDP mechanisms either split the
privacy budget across all attributes or treat each attribute independently,
ignoring natural inter-attribute correlations. This leads to excessive noise or
fragmented budgets, resulting in significant utility loss, particularly in
high-dimensional settings.
  To overcome these limitations, we propose Correlated Randomized Response
(Corr-RR), a novel LDP mechanism that leverages correlations among attributes
to substantially improve utility while maintaining rigorous LDP guarantees.
Corr-RR allocates the full privacy budget to perturb a single, randomly
selected attribute and reconstructs the remaining attributes using estimated
interattribute dependencies, without incurring additional privacy cost. To
enable this, Corr-RR operates in two phases: (1) a subset of users apply
standard LDP mechanisms to estimate correlations, and (2) each remaining user
perturbs one attribute and infers the others using the learned correlations. We
theoretically prove that Corr-RR satisfies $\epsilon$-LDP, and extensive
experiments on synthetic and real-world datasets demonstrate that Corr-RR
consistently outperforms state-of-the-art LDP mechanisms, particularly in
scenarios with many attributes and strong inter-attribute correlations.

</details>


### [67] [Enabling Cyber Security Education through Digital Twins and Generative AI](https://arxiv.org/abs/2507.17518)
*Vita Santa Barletta,Vito Bavaro,Miriana Calvano,Antonio Curci,Antonio Piccinno,Davide Pio Posa*

Main category: cs.CR

TL;DR: 数字孪生(DT)与渗透测试工具及大语言模型(LLM)的结合，显著提升了网络安全教育的实效性，通过模拟真实网络环境提供互动式漏洞探索与防御策略训练。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决网络安全教育中理论与实践脱节的问题，探索数字孪生与大语言模型如何协同增强培训效果，以满足行业动态需求。

Method: 开发了基于网络杀伤链模型的定制渗透测试工具包RTK，结合数字孪生环境模拟攻击全流程，并集成LLM提供实时智能反馈与自然语言威胁分析。

Result: 初步测试表明，该框架有效提升了漏洞评估、威胁检测等实操能力，使网络安全培训更具针对性和实用性。

Conclusion: 数字孪生与大语言模型的融合为网络安全教育提供了变革性解决方案，能够动态适应行业演进需求，弥合知识与应用间的鸿沟。

Abstract: Digital Twins (DTs) are gaining prominence in cybersecurity for their ability
to replicate complex IT (Information Technology), OT (Operational Technology),
and IoT (Internet of Things) infrastructures, allowing for real time
monitoring, threat analysis, and system simulation. This study investigates how
integrating DTs with penetration testing tools and Large Language Models (LLMs)
can enhance cybersecurity education and operational readiness. By simulating
realistic cyber environments, this approach offers a practical, interactive
framework for exploring vulnerabilities and defensive strategies. At the core
of this research is the Red Team Knife (RTK), a custom penetration testing
toolkit aligned with the Cyber Kill Chain model. RTK is designed to guide
learners through key phases of cyberattacks, including reconnaissance,
exploitation, and response within a DT powered ecosystem. The incorporation of
Large Language Models (LLMs) further enriches the experience by providing
intelligent, real-time feedback, natural language threat explanations, and
adaptive learning support during training exercises. This combined DT LLM
framework is currently being piloted in academic settings to develop hands on
skills in vulnerability assessment, threat detection, and security operations.
Initial findings suggest that the integration significantly improves the
effectiveness and relevance of cybersecurity training, bridging the gap between
theoretical knowledge and real-world application. Ultimately, the research
demonstrates how DTs and LLMs together can transform cybersecurity education to
meet evolving industry demands.

</details>


### [68] [Quantifying the ROI of Cyber Threat Intelligence: A Data-Driven Approach](https://arxiv.org/abs/2507.17628)
*Matteo Strada*

Main category: cs.CR

TL;DR: 本研究提出了一种量化网络威胁情报(CTI)投资回报率(ROI)的数据驱动方法，通过建立混合评估模型将CTI重新定义为可测量的风险缓解因素。


<details>
  <summary>Details</summary>
Motivation: 由于负面证据问题（成功的威胁预防导致无事件发生），CTI的价值评估长期面临挑战，难以在传统成本效益框架内证明其支出合理性。

Method: 扩展了Gordon-Loeb和FAIR等安全经济学模型，引入基于加权几何平均的威胁情报有效性指数(TIEI)，通过MTTD、MTTR等实证指标和金融、医疗、零售三个行业的案例研究进行操作化。

Result: 开发的混合模型整合了财务量化、对抗覆盖范围和业务赋能定性评估，将负面证据转化为合理的ROI解释，TIEI指标能捕捉关键维度的瓶颈效应。

Conclusion: 该方法提供了可复现的评估框架，将CTI从成本支出重新定位为战略投资，支持跨组织环境的持续优化和决策制定。

Abstract: The valuation of Cyber Threat Intelligence (CTI) remains a persistent
challenge due to the problem of negative evidence: successful threat prevention
results in non-events that generate minimal observable financial impact, making
CTI expenditures difficult to justify within traditional cost-benefit
frameworks. This study introduces a data-driven methodology for quantifying the
return on investment (ROI) of CTI, thereby reframing it as a measurable
contributor to risk mitigation. The proposed framework extends established
models in security economics, including the Gordon-Loeb and FAIR models, to
account for CTI's complex influence on both the probability of security
breaches and the severity of associated losses. The framework is
operationalized through empirically grounded performance indicators, such as
reductions in mean time to detect (MTTD), mean time to respond (MTTR), and
adversary dwell time, supported by three sector-specific case studies in
finance, healthcare, and retail. To address limitations in conventional linear
assessment methodologies, the Threat Intelligence Effectiveness Index (TIEI) is
introduced as a composite metric based on a weighted geometric mean. TIEI
penalizes underperformance across critical dimensions: quality, enrichment,
integration, and operational impact; thereby capturing bottleneck effect where
the least effective component limits overall performance. By integrating
financial quantification, adversarial coverage, and qualitative assessments of
business enablement, the proposed hybrid model converts negative evidence into
a justifiable ROI explanation. This approach offers a replicable means of
repositioning CTI from an expense to a strategic investment, enabling informed
decision-making and continuous optimization across diverse organizational
contexts.

</details>


### [69] [Explainable Vulnerability Detection in C/C++ Using Edge-Aware Graph Attention Networks](https://arxiv.org/abs/2507.16540)
*Radowanul Haque,Aftab Ali,Sally McClean,Naveed Khan*

Main category: cs.CR

TL;DR: 本文提出ExplainVulD框架，通过双通道嵌入和边缘感知注意力机制检测C/C++代码漏洞，解决类别不平衡问题，并在准确率和F1分数上显著超越现有方法，同时提供可解释性输出。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的漏洞检测方法因类别不平衡导致高误报率且缺乏可解释性，难以集成到安全流程中。ExplainVulD旨在提升检测性能并增强结果可解释性。

Method: 构建代码属性图，采用融合语义与结构的双通道节点嵌入，通过边缘感知注意力机制区分程序关系，并使用类别加权交叉熵损失解决类别不平衡问题。

Result: 在ReVeal数据集上30次独立运行平均达到88.25%准确率与48.23% F1分数，相对ReVeal模型提升4.6%准确率与16.9% F1分数，且显著优于静态分析工具。

Conclusion: ExplainVulD通过可解释的漏洞定位实现了检测性能与实用性的双重突破，为安全审计流程提供了透明可信的决策支持。

Abstract: Detecting security vulnerabilities in source code remains challenging,
particularly due to class imbalance in real-world datasets where vulnerable
functions are under-represented. Existing learning-based methods often optimise
for recall, leading to high false positive rates and reduced usability in
development workflows. Furthermore, many approaches lack explainability,
limiting their integration into security workflows. This paper presents
ExplainVulD, a graph-based framework for vulnerability detection in C/C++ code.
The method constructs Code Property Graphs and represents nodes using
dual-channel embeddings that capture both semantic and structural information.
These are processed by an edge-aware attention mechanism that incorporates
edge-type embeddings to distinguish among program relations. To address class
imbalance, the model is trained using class-weighted cross-entropy loss.
ExplainVulD achieves a mean accuracy of 88.25 percent and an F1 score of 48.23
percent across 30 independent runs on the ReVeal dataset. These results
represent relative improvements of 4.6 percent in accuracy and 16.9 percent in
F1 score compared to the ReVeal model, a prior learning-based method. The
framework also outperforms static analysis tools, with relative gains of 14.0
to 14.1 percent in accuracy and 132.2 to 201.2 percent in F1 score. Beyond
improved detection performance, ExplainVulD produces explainable outputs by
identifying the most influential code regions within each function, supporting
transparency and trust in security triage.

</details>


### [70] [Rethinking HSM and TPM Security in the Cloud: Real-World Attacks and Next-Gen Defenses](https://arxiv.org/abs/2507.17655)
*Shams Shaikh,Trima P. Fernandes e Fizardo*

Main category: cs.CR

TL;DR: 随着组织快速迁移至云端，加密密钥管理的安全性日益受到关注。传统硬件安全模块（HSM）和可信平台模块（TPM）在云原生威胁面前显现出局限性。本文分析了相关安全漏洞，探讨了替代方案，并提出了适应性更强的分层架构。


<details>
  <summary>Details</summary>
Motivation: 云计算的普及使得加密密钥管理面临新的安全挑战，传统的HSM和TPM在云环境中暴露出系统性漏洞，亟需研究更有效的保护方法。

Method: 通过分析涉及HSM和TPM的实际安全事件，识别常见攻击向量，并评估机密计算、后量子密码学和去中心化密钥管理等替代方案的可行性。

Result: 研究发现，尽管HSM和TPM仍有一定作用，但现代云安全需要更灵活的分层架构来应对不断变化的威胁环境。

Conclusion: 云安全架构师和安全工程师需结合现有弱点和新兴模型，采用适应性策略，以在演变的威胁环境中强化加密信任体系。

Abstract: As organizations rapidly migrate to the cloud, the security of cryptographic
key management has become a growing concern. Hardware Security Modules (HSMs)
and Trusted Platform Modules (TPMs), traditionally seen as the gold standard
for securing encryption keys and digital trust, are increasingly challenged by
cloud-native threats. Real-world breaches have exposed weaknesses in cloud
deployments, including misconfigurations, API abuse, and privilege escalations,
allowing attackers to access sensitive key material and bypass protections.
These incidents reveal that while the hardware remains secure, the surrounding
cloud ecosystem introduces systemic vulnerabilities. This paper analyzes
notable security failures involving HSMs and TPMs, identifies common attack
vectors, and questions longstanding assumptions about their effectiveness in
distributed environments. We explore alternative approaches such as
confidential computing, post-quantum cryptography, and decentralized key
management. Our findings highlight that while HSMs and TPMs still play a role,
modern cloud security requires more adaptive, layered architectures. By
evaluating both current weaknesses and emerging models, this research equips
cloud architects and security engineers with strategies to reinforce
cryptographic trust in the evolving threat landscape.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [71] [Towards Autonomous Sustainability Assessment via Multimodal AI Agents](https://arxiv.org/abs/2507.17012)
*Zhihan Zhang,Alexander Metzger,Yuxuan Mei,Felix Hähnlein,Zachary Englhardt,Tingyu Cheng,Gregory D. Abowd,Shwetak Patel,Adriana Schulz,Vikram Iyer*

Main category: cs.AI

TL;DR: 本文提出了一种基于多模态AI代理的创新方法，用于快速计算电子产品从生产到出厂（摇篮到大门）的碳排放量，显著缩短传统生命周期评估（LCA）所需时间，并填补数据空白。


<details>
  <summary>Details</summary>
Motivation: 尽管对可持续性信息的兴趣激增，但传统生命周期评估（LCA）所需的数据往往难以获取，导致计算产品从制造到处置的环境影响（EI）面临挑战。

Method: 引入多模态AI代理模拟LCA专家与利益相关者的互动，利用定制数据抽象和软件工具从在线文本和图像中提取信息，构建详细的生命周期清单。此外，开发了通过比较类似产品直接估算EI的方法，以及数据驱动的排放因子生成方法。

Result: 该方法将专家数周或数月的工作缩短至一分钟内，碳排放估算与专家LCA结果的误差在19%以内。直接估算EI的方法在笔记本电脑上仅需3毫秒，电子产品的平均绝对百分比误差（MAPE）为12.28%。数据驱动的排放因子生成方法比人工选择最接近的LCA数据库条目提高了120.26%的MAPE。

Conclusion: 该方法不仅显著提高了LCA的效率和准确性，还为未来LCA工作流程的改进提供了重要启示，尤其是在数据可用性和计算速度方面。

Abstract: Interest in sustainability information has surged in recent years. However,
the data required for a life cycle assessment (LCA) that maps the materials and
processes from product manufacturing to disposal into environmental impacts
(EI) are often unavailable. Here we reimagine conventional LCA by introducing
multimodal AI agents that emulate interactions between LCA experts and
stakeholders like product managers and engineers to calculate the
cradle-to-gate (production) carbon emissions of electronic devices. The AI
agents iteratively generate a detailed life-cycle inventory leveraging a custom
data abstraction and software tools that extract information from online text
and images from repair communities and government certifications. This approach
reduces weeks or months of expert time to under one minute and closes data
availability gaps while yielding carbon footprint estimates within 19% of
expert LCAs with zero proprietary data. Additionally, we develop a method to
directly estimate EI by comparing an input to a cluster of products with
similar descriptions and known carbon footprints. This runs in 3 ms on a laptop
with a MAPE of 12.28% on electronic products. Further, we develop a data-driven
method to generate emission factors. We use the properties of an unknown
material to represent it as a weighted sum of emission factors for similar
materials. Compared to human experts picking the closest LCA database entry,
this improves MAPE by 120.26%. We analyze the data and compute scaling of this
approach and discuss its implications for future LCA workflows.

</details>


### [72] [New Mechanisms in Flex Distribution for Bounded Suboptimal Multi-Agent Path Finding](https://arxiv.org/abs/2507.17054)
*Shao-Hung Chan,Thomy Phan,Jiaoyang Li,Sven Koenig*

Main category: cs.AI

TL;DR: 本文提出三种新的flex分配策略（基于冲突、基于延迟和混合策略），用于改进多智能体路径规划算法EECBS，通过动态调整路径成本阈值来提升求解效率，同时保证解的次优性和完备性。实验证明新方法优于原始贪婪分配策略。


<details>
  <summary>Details</summary>
Motivation: EECBS算法虽能保证求解的次优性，但现有flex分配策略可能因过度放宽阈值导致频繁切换路径集，反而降低效率。需开发更智能的flex分配机制以平衡求解质量与计算效率。

Method: 1) 基于冲突的flex分配：按碰撞次数比例分配flex值；2) 基于延迟的flex分配：根据约束满足所需延迟调整阈值；3) 混合策略：分层整合前两种方法。均保持算法完备性和$w\cdot LB$次优界。

Result: 实验表明，新flex分配策略显著提升EECBS效率：混合策略在85%测试案例中快于原方法，基于冲突的策略在稀疏场景中速度提升达47%，且所有方法均保持解质量。

Conclusion: 动态调整flex分配能有效避免EECBS陷入低效路径切换。三种新策略通过量化碰撞影响和约束延迟，实现了求解速度与次优性的平衡，为复杂环境下的多智能体路径规划提供实用解决方案。

Abstract: Multi-Agent Path Finding (MAPF) is the problem of finding a set of
collision-free paths, one for each agent in a shared environment. Its objective
is to minimize the sum of path costs (SOC), where the path cost of each agent
is defined as the travel time from its start location to its target location.
Explicit Estimation Conflict-Based Search (EECBS) is the leading algorithm for
bounded-suboptimal MAPF, with the SOC of the solution being at most a
user-specified factor $w$ away from optimal. EECBS maintains sets of paths and
a lower bound $LB$ on the optimal SOC. Then, it iteratively selects a set of
paths whose SOC is at most $w \cdot LB$ and introduces constraints to resolve
collisions. For each path in a set, EECBS maintains a lower bound on its
optimal path that satisfies constraints. By finding an individually
bounded-suboptimal path with cost at most a threshold of $w$ times its lower
bound, EECBS guarantees to find a bounded-suboptimal solution. To speed up
EECBS, previous work uses flex distribution to increase the threshold. Though
EECBS with flex distribution guarantees to find a bounded-suboptimal solution,
increasing the thresholds may push the SOC beyond $w \cdot LB$, forcing EECBS
to switch among different sets of paths instead of resolving collisions on a
particular set of paths, and thus reducing efficiency. To address this issue,
we propose Conflict-Based Flex Distribution that distributes flex in proportion
to the number of collisions. We also estimate the delays needed to satisfy
constraints and propose Delay-Based Flex Distribution. On top of that, we
propose Mixed-Strategy Flex Distribution, combining both in a hierarchical
framework. We prove that EECBS with our new flex distribution mechanisms is
complete and bounded-suboptimal. Our experiments show that our approaches
outperform the original (greedy) flex distribution.

</details>


### [73] [LoRA is All You Need for Safety Alignment of Reasoning LLMs](https://arxiv.org/abs/2507.17075)
*Yihao Xue,Baharan Mirzasoleiman*

Main category: cs.AI

TL;DR: 研究发现，使用LoRA进行安全对齐微调可在不损害大语言模型推理能力的情况下提升安全性，解决了"安全税"问题。


<details>
  <summary>Details</summary>
Motivation: 安全对齐微调虽能阻止大语言模型响应有害请求，但会显著降低其推理能力（即"安全税"现象），需要寻找两全其美的解决方案。

Method: 采用LoRA（低秩适应）方法在拒绝数据集上进行监督微调，将安全权重更新限制在低秩空间，减少对推理权重的干扰。同时探索通过正则化或权重合并进一步降低权重重叠的方法。

Result: 在数学、科学和编程四个基准测试中，该方法实现了与全参数微调相当的安全水平，且完全保留原始推理能力。LoRA产生的权重更新与初始权重重叠度小于全参数微调。

Conclusion: 该研究证明了通过限制参数更新空间可有效平衡安全性与推理能力，为未来设计更优的权衡方法提供了方向。

Abstract: Reasoning LLMs have demonstrated remarkable breakthroughs in solving complex
problems that were previously out of reach. To ensure LLMs do not assist with
harmful requests, safety alignment fine-tuning is necessary in the
post-training phase. However, safety alignment fine-tuning has recently been
shown to significantly degrade reasoning abilities, a phenomenon known as the
"Safety Tax". In this work, we show that using LoRA for SFT on refusal datasets
effectively aligns the model for safety without harming its reasoning
capabilities. This is because restricting the safety weight updates to a
low-rank space minimizes the interference with the reasoning weights. Our
extensive experiments across four benchmarks covering math, science, and coding
show that this approach produces highly safe LLMs -- with safety levels
comparable to full-model fine-tuning -- without compromising their reasoning
abilities. Additionally, we observe that LoRA induces weight updates with
smaller overlap with the initial weights compared to full-model fine-tuning. We
also explore methods that further reduce such overlap -- via regularization or
during weight merging -- and observe some improvement on certain tasks. We hope
this result motivates designing approaches that yield more consistent
improvements in the reasoning-safety trade-off.

</details>


### [74] [HySafe-AI: Hybrid Safety Architectural Analysis Framework for AI Systems: A Case Study](https://arxiv.org/abs/2507.17118)
*Mandar Pitale,Jelena Frtunikj,Abhinaw Priyadershi,Vasu Singh,Maria Spence*

Main category: cs.AI

TL;DR: 本文探讨了AI在安全关键领域（如自动驾驶系统和机器人技术）中的应用，提出了一种混合安全架构分析框架HySAFE-AI，用于评估AI系统的安全性，并改进了传统的安全分析方法以适应基础模型的复杂性。


<details>
  <summary>Details</summary>
Motivation: 随着AI在自动驾驶系统（ADS）和机器人技术等安全关键领域的广泛应用，端到端（E2E）整体架构（如大型语言模型LLMs和视觉语言模型VLMs）成为趋势，但传统安全分析方法（如FMEA和FTA）在处理这些复杂模型时存在局限性。

Method: 本文回顾了不同的架构解决方案，评估了常见安全分析方法（如FMEA和FTA）的有效性，并提出了HySAFE-AI框架，该框架结合传统方法，特别关注基础模型如何形成和利用潜在表示。

Result: 研究表明，HySAFE-AI框架能够有效改进传统安全分析方法，适应基础模型的复杂性，并为未来AI安全标准的制定提供了指导。

Conclusion: 本文提出的HySAFE-AI框架为评估AI系统的安全性提供了新思路，并指出了未来研究方向，以推动AI安全标准的进一步发展。

Abstract: AI has become integral to safety-critical areas like autonomous driving
systems (ADS) and robotics. The architecture of recent autonomous systems are
trending toward end-to-end (E2E) monolithic architectures such as large
language models (LLMs) and vision language models (VLMs). In this paper, we
review different architectural solutions and then evaluate the efficacy of
common safety analyses such as failure modes and effect analysis (FMEA) and
fault tree analysis (FTA). We show how these techniques can be improved for the
intricate nature of the foundational models, particularly in how they form and
utilize latent representations. We introduce HySAFE-AI, Hybrid Safety
Architectural Analysis Framework for AI Systems, a hybrid framework that adapts
traditional methods to evaluate the safety of AI systems. Lastly, we offer
hints of future work and suggestions to guide the evolution of future AI safety
standards.

</details>


### [75] [Improving LLMs' Generalized Reasoning Abilities by Graph Problems](https://arxiv.org/abs/2507.17168)
*Qifan Zhang,Nuo Chen,Zehua Li,Miao Peng,Jing Tang,Jia Li*

Main category: cs.AI

TL;DR: 本文提出GraphPile数据集和GraphMind模型，通过图问题推理（GPR）增强大语言模型（LLM）的通用推理能力，在数学与非数学推理任务中均取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有领域持续预训练（CPT）方法在数学推理等特定任务上表现良好，但缺乏向通用推理任务的迁移能力。图问题推理因其复杂的逻辑与关系推理特性，被视为提升LLM通用推理能力的理想途径。

Method: 构建首个大规模GPR数据集GraphPile（109亿token/23类图任务），包含思维链、程序思维、执行轨迹和真实图数据。基于Llama 3/3.1和Gemma 2训练GraphMind模型。

Result: GraphMind在数学推理任务中准确率提升4.9%，在逻辑推理和常识推理等非数学任务中提升达21.2%，显著优于领域特定预训练方法。

Conclusion: 该研究首次将GPR用于增强LLM推理模式，通过GraphPile数据集弥合领域预训练与通用推理能力的鸿沟，推动LLM适应性与鲁棒性的发展。

Abstract: Large Language Models (LLMs) have made remarkable strides in reasoning tasks,
yet their performance often falters on novel and complex problems.
Domain-specific continued pretraining (CPT) methods, such as those tailored for
mathematical reasoning, have shown promise but lack transferability to broader
reasoning tasks. In this work, we pioneer the use of Graph Problem Reasoning
(GPR) to enhance the general reasoning capabilities of LLMs. GPR tasks,
spanning pathfinding, network analysis, numerical computation, and topological
reasoning, require sophisticated logical and relational reasoning, making them
ideal for teaching diverse reasoning patterns. To achieve this, we introduce
GraphPile, the first large-scale corpus specifically designed for CPT using GPR
data. Spanning 10.9 billion tokens across 23 graph tasks, the dataset includes
chain-of-thought, program-of-thought, trace of execution, and real-world graph
data. Using GraphPile, we train GraphMind on popular base models Llama 3 and
3.1, as well as Gemma 2, achieving up to 4.9 percent higher accuracy in
mathematical reasoning and up to 21.2 percent improvement in non-mathematical
reasoning tasks such as logical and commonsense reasoning. By being the first
to harness GPR for enhancing reasoning patterns and introducing the first
dataset of its kind, our work bridges the gap between domain-specific
pretraining and universal reasoning capabilities, advancing the adaptability
and robustness of LLMs.

</details>


### [76] [Our Cars Can Talk: How IoT Brings AI to Vehicles](https://arxiv.org/abs/2507.17214)
*Amod Kant Agrawal*

Main category: cs.AI

TL;DR: 将AI引入车辆作为感知平台，实现从被动到主动的维护转变，并提出整合AI副驾驶的概念。


<details>
  <summary>Details</summary>
Motivation: 通过AI技术提升车辆智能化水平，改变传统被动维护模式，促进车辆系统与驾驶员的交互。

Method: 从概念和技术角度探讨AI副驾驶的整合，旨在推动跨学科对话。

Result: 为智能车辆系统、预测性维护和AI驱动的用户交互研究提供指导方向。

Conclusion: AI与车辆的融合是未来研究的关键领域，需进一步探索技术实现与跨学科合作。

Abstract: Bringing AI to vehicles and enabling them as sensing platforms is key to
transforming maintenance from reactive to proactive. Now is the time to
integrate AI copilots that speak both languages: machine and driver. This
article offers a conceptual and technical perspective intended to spark
interdisciplinary dialogue and guide future research and development in
intelligent vehicle systems, predictive maintenance, and AI-powered user
interaction.

</details>


### [77] [Agent Identity Evals: Measuring Agentic Identity](https://arxiv.org/abs/2507.17257)
*Elija Perrier,Michael Timothy Bennett*

Main category: cs.AI

TL;DR: 本文提出了一种名为\textit{agent identity evals} (AIE)的框架，用于评估语言模型代理(LMAs)在时间维度上维持稳定身份的能力，以解决其因继承大语言模型(LLMs)的病理特性而导致的身份稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 语言模型代理(LMAs)的身份稳定性对其代理能力和可信度至关重要，但其继承自大语言模型(LLMs)的无状态性、随机性等病理特性会削弱其身份的可识别性、连续性、持久性和一致性，从而影响其可靠性和实用性。

Method: 作者提出了AIE框架，这是一套严格的、基于统计的实证方法，用于量化LMA系统在时间维度上维持其代理身份的程度，包括其能力、属性及从状态扰动中恢复的能力。AIE包含一系列新指标，可与其他性能指标结合使用。

Result: AIE框架提供了可在LMA生命周期各阶段应用的正式定义和方法，并通过实例展示了如何应用这些方法来优化LMA的基础设施和支撑结构(如记忆和工具)。

Conclusion: AIE框架为评估和提升语言模型代理的身份稳定性提供了系统化的解决方案，有助于增强其代理能力、可信度和实用性，为LMA的设计和优化提供了重要工具。

Abstract: Central to agentic capability and trustworthiness of language model agents
(LMAs) is the extent they maintain stable, reliable, identity over time.
However, LMAs inherit pathologies from large language models (LLMs)
(statelessness, stochasticity, sensitivity to prompts and
linguistically-intermediation) which can undermine their identifiability,
continuity, persistence and consistency. This attrition of identity can erode
their reliability, trustworthiness and utility by interfering with their
agentic capabilities such as reasoning, planning and action. To address these
challenges, we introduce \textit{agent identity evals} (AIE), a rigorous,
statistically-driven, empirical framework for measuring the degree to which an
LMA system exhibit and maintain their agentic identity over time, including
their capabilities, properties and ability to recover from state perturbations.
AIE comprises a set of novel metrics which can integrate with other measures of
performance, capability and agentic robustness to assist in the design of
optimal LMA infrastructure and scaffolding such as memory and tools. We set out
formal definitions and methods that can be applied at each stage of the LMA
life-cycle, and worked examples of how to apply them.

</details>


### [78] [Students' Feedback Requests and Interactions with the SCRIPT Chatbot: Do They Get What They Ask For?](https://arxiv.org/abs/2507.17258)
*Andreas Scholl,Natalie Kiesler*

Main category: cs.AI

TL;DR: 研究开发了基于ChatGPT-4o-mini的聊天机器人SCRIPT，用于支持编程新手学习，并通过实验分析了学生的互动行为和反馈偏好。


<details>
  <summary>Details</summary>
Motivation: 基于生成式AI（GenAI）在编程教育中的应用研究，开发SCRIPT以帮助初学者通过开放式互动和结构化引导学习编程。

Method: 在德国一所大型大学的入门编程课程中，对136名学生进行实验，分析他们使用SCRIPT解决编程任务时的互动行为和反馈请求模式。

Result: 学生的反馈请求呈现特定序列，75%的聊天机器人回应与其请求的反馈类型一致，且系统提示约束得到遵守。

Conclusion: 研究结果为设计基于GenAI的学习支持系统提供了 insights，并凸显了在AI辅助工具中平衡引导与灵活性的挑战。

Abstract: Building on prior research on Generative AI (GenAI) and related tools for
programming education, we developed SCRIPT, a chatbot based on ChatGPT-4o-mini,
to support novice learners. SCRIPT allows for open-ended interactions and
structured guidance through predefined prompts. We evaluated the tool via an
experiment with 136 students from an introductory programming course at a large
German university and analyzed how students interacted with SCRIPT while
solving programming tasks with a focus on their feedback preferences. The
results reveal that students' feedback requests seem to follow a specific
sequence. Moreover, the chatbot responses aligned well with students' requested
feedback types (in 75%), and it adhered to the system prompt constraints. These
insights inform the design of GenAI-based learning support systems and
highlight challenges in balancing guidance and flexibility in AI-assisted
tools.

</details>


### [79] [Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments](https://arxiv.org/abs/2507.17289)
*Shitong Zhu,Chenhao Fang,Derek Larson,Neel Reddy Pochareddy,Rajeev Rao,Sophie Zeng,Yanqing Peng,Wendy Summer,Alex Goncalves,Arya Pudota,Herve Robert*

Main category: cs.AI

TL;DR: 本文介绍合规大脑助手(CBA)，一种提升企业合规任务效率的对话式AI助手，通过智能路由机制在响应质量与延迟间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 企业合规任务复杂多样，需兼顾响应速度与处理深度。现有方案难以同时满足简单查询与复合操作需求，亟需智能分流机制。

Method: 设计双模式路由系统：FastTrack模式处理仅需知识检索的简单请求；FullAgentic模式通过工具调用和API组合处理需主动探索上下文的复杂请求。

Result: 实验显示CBA在关键词匹配率(83.7% vs 41.7%)和LLM评判通过率(82.0% vs 20.0%)上显著优于基础LLM，混合路由设计在保持运行时相近的同时获得最优指标。

Conclusion: 路由机制有效平衡简单与复杂请求的处理效能，验证了混合架构在企业合规AI助手场景中的优越性。

Abstract: This paper presents Compliance Brain Assistant (CBA), a conversational,
agentic AI assistant designed to boost the efficiency of daily compliance tasks
for personnel in enterprise environments. To strike a good balance between
response quality and latency, we design a user query router that can
intelligently choose between (i) FastTrack mode: to handle simple requests that
only need additional relevant context retrieved from knowledge corpora; and
(ii) FullAgentic mode: to handle complicated requests that need composite
actions and tool invocations to proactively discover context across various
compliance artifacts, and/or involving other APIs/models for accommodating
requests. A typical example would be to start with a user query, use its
description to find a specific entity and then use the entity's information to
query other APIs for curating and enriching the final AI response.
  Our experimental evaluations compared CBA against an out-of-the-box LLM on
various real-world privacy/compliance-related queries targeting various
personas. We found that CBA substantially improved upon the vanilla LLM's
performance on metrics such as average keyword match rate (83.7% vs. 41.7%) and
LLM-judge pass rate (82.0% vs. 20.0%). We also compared metrics for the full
routing-based design against the `fast-track only` and `full-agentic` modes and
found that it had a better average match-rate and pass-rate while keeping the
run-time approximately the same. This finding validated our hypothesis that the
routing mechanism leads to a good trade-off between the two worlds.

</details>


### [80] [Ctx2TrajGen: Traffic Context-Aware Microscale Vehicle Trajectories using Generative Adversarial Imitation Learning](https://arxiv.org/abs/2507.17418)
*Joobin Jin,Seokjun Hong,Gyeongseon Baek,Yeeun Kim,Byeongjoon Noh*

Main category: cs.AI

TL;DR: 提出Ctx2TrajGen框架，通过GAIL结合PPO和WGAN-GP生成上下文感知的微观车辆轨迹，解决数据稀缺与领域偏移问题，在DRIFT数据集上验证了优越性。


<details>
  <summary>Details</summary>
Motivation: 精确建模微观车辆轨迹对交通行为分析和自动驾驶系统至关重要，但现有方法存在非线性依赖和训练不稳定性问题。

Method: 基于GAIL框架，整合PPO和WGAN-GP算法，显式建模周围车辆与道路几何的上下文条件，生成交互感知的轨迹。

Result: 在无人机采集的DRIFT数据集上，模型在真实性、行为多样性和上下文保真度方面超越现有方法，无需仿真即可缓解数据稀缺问题。

Conclusion: Ctx2TrajGen为微观交通建模提供了稳健解决方案，其上下文感知能力显著提升了轨迹生成的现实性和适应性。

Abstract: Precise modeling of microscopic vehicle trajectories is critical for traffic
behavior analysis and autonomous driving systems. We propose Ctx2TrajGen, a
context-aware trajectory generation framework that synthesizes realistic urban
driving behaviors using GAIL. Leveraging PPO and WGAN-GP, our model addresses
nonlinear interdependencies and training instability inherent in microscopic
settings. By explicitly conditioning on surrounding vehicles and road geometry,
Ctx2TrajGen generates interaction-aware trajectories aligned with real-world
context. Experiments on the drone-captured DRIFT dataset demonstrate superior
performance over existing methods in terms of realism, behavioral diversity,
and contextual fidelity, offering a robust solution to data scarcity and domain
shift without simulation.

</details>


### [81] [An Uncertainty-Driven Adaptive Self-Alignment Framework for Large Language Models](https://arxiv.org/abs/2507.17477)
*Haoran Sun,Zekun Zhang,Shaoning Zeng*

Main category: cs.AI

TL;DR: 本文提出了一种不确定性驱动的自适应自对齐（UDASA）框架，旨在无需人工标注的情况下提升大语言模型（LLM）与人类意图和安全规范的自动对齐能力。该方法通过多维度不确定性量化及分阶段优化，显著提升了模型在无害性、有用性、真实性等任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在指令遵循和通用推理方面取得显著进展，但如何在不依赖人工标注的情况下实现高质量的人类意图与安全规范对齐仍是一个核心挑战。

Method: UDASA框架首先生成每个输入的多个响应，并从语义、事实性和价值对齐三个维度量化输出不确定性。根据不确定性差异将训练样本分为保守、中等和探索三个阶段，并逐步优化模型。

Result: 实验结果表明，UDASA在无害性、有用性、真实性和受控情感生成等多个任务上优于现有对齐方法，显著提升了模型性能。

Conclusion: UDASA通过自动化不确定性驱动机制实现了LLM的高效自对齐，为无需人工干预的模型优化提供了可行方案，其分阶段训练策略和核心设计假设得到了实证支持。

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in
instruction following and general-purpose reasoning. However, achieving
high-quality alignment with human intent and safety norms without human
annotations remains a fundamental challenge. In this work, we propose an
Uncertainty-Driven Adaptive Self-Alignment (UDASA) framework designed to
improve LLM alignment in a fully automated manner. UDASA first generates
multiple responses for each input and quantifies output uncertainty across
three dimensions: semantics, factuality, and value alignment. Based on these
uncertainty scores, the framework constructs preference pairs and categorizes
training samples into three stages, conservative, moderate, and exploratory,
according to their uncertainty difference. The model is then optimized
progressively across these stages. In addition, we conduct a series of
preliminary studies to validate the core design assumptions and provide strong
empirical motivation for the proposed framework. Experimental results show that
UDASA outperforms existing alignment methods across multiple tasks, including
harmlessness, helpfulness, truthfulness, and controlled sentiment generation,
significantly improving model performance.

</details>


### [82] [LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning](https://arxiv.org/abs/2507.17482)
*Luca Salvatore Lorello,Nikolaos Manginas,Marco Lippi,Stefano Melacci*

Main category: cs.AI

TL;DR: 本文介绍了LTLZinc基准框架，用于生成涵盖多种问题的数据集，以评估神经符号和持续学习方法在时间和约束驱动维度上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号人工智能方法多应用于静态场景，缺乏对时间维度推理的探索。本文旨在填补这一空白，推动时间学习与推理框架的统一研究。

Method: LTLZinc框架基于MiniZinc约束的线性时序逻辑规范和任意图像分类数据集，生成表达性时序推理和持续学习任务，并提供细粒度注释支持多种训练设置。

Result: 在LTLZinc生成的6个神经符号序列分类和4个类持续学习任务上的实验表明，时序学习与推理具有挑战性，并揭示了当前最先进方法的局限性。

Conclusion: 作者开源了LTLZinc生成器和10个现成任务，希望促进神经符号和持续学习社区对统一时序学习与推理框架的研究。

Abstract: Neuro-symbolic artificial intelligence aims to combine neural architectures
with symbolic approaches that can represent knowledge in a human-interpretable
formalism. Continual learning concerns with agents that expand their knowledge
over time, improving their skills while avoiding to forget previously learned
concepts. Most of the existing approaches for neuro-symbolic artificial
intelligence are applied to static scenarios only, and the challenging setting
where reasoning along the temporal dimension is necessary has been seldom
explored. In this work we introduce LTLZinc, a benchmarking framework that can
be used to generate datasets covering a variety of different problems, against
which neuro-symbolic and continual learning methods can be evaluated along the
temporal and constraint-driven dimensions. Our framework generates expressive
temporal reasoning and continual learning tasks from a linear temporal logic
specification over MiniZinc constraints, and arbitrary image classification
datasets. Fine-grained annotations allow multiple neural and neuro-symbolic
training settings on the same generated datasets. Experiments on six
neuro-symbolic sequence classification and four class-continual learning tasks
generated by LTLZinc, demonstrate the challenging nature of temporal learning
and reasoning, and highlight limitations of current state-of-the-art methods.
We release the LTLZinc generator and ten ready-to-use tasks to the
neuro-symbolic and continual learning communities, in the hope of fostering
research towards unified temporal learning and reasoning frameworks.

</details>


### [83] [CQE under Epistemic Dependencies: Algorithms and Experiments (extended version)](https://arxiv.org/abs/2507.17487)
*Lorenzo Marconi,Flavia Ricci,Riccardo Rosati*

Main category: cs.AI

TL;DR: 本文研究了基于本体论的受控查询评估（CQE），结合认知依赖（EDs）和最优GA审查器，提出了一种确保安全性的布尔联合合取查询（BUCQs）应答方法，并在DL-Lite_R本体上实现了高效的数据复杂度处理。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于通过结合认知依赖（EDs）和最优GA审查器，开发一种既能保证信息安全又能高效处理查询的CQE框架，特别是在本体论背景下。

Method: 方法包括：1) 结合EDs与最优GA审查器，定义基于交集的安全应答语义；2) 针对DL-Lite_R本体和特定EDs子类，设计一种数据复杂度为AC^0的一阶重写算法。

Result: 结果表明：1) 在完整EDs下，交集方法仍能保证安全性；2) 所提重写算法在DL-Lite_R中可实现高效查询处理；3) 实验验证了该方法的实际可行性。

Conclusion: 结论指出，该CQE框架在理论安全性和计算效率之间取得了平衡，尤其适用于需要严格信息控制的场景，并通过实验证明了其实际应用价值。

Abstract: We investigate Controlled Query Evaluation (CQE) over ontologies, where
information disclosure is regulated by epistemic dependencies (EDs), a family
of logical rules recently proposed for the CQE framework. In particular, we
combine EDs with the notion of optimal GA censors, i.e. maximal sets of ground
atoms that are entailed by the ontology and can be safely revealed. We focus on
answering Boolean unions of conjunctive queries (BUCQs) with respect to the
intersection of all optimal GA censors - an approach that has been shown in
other contexts to ensure strong security guarantees with favorable
computational behavior. First, we characterize the security of this
intersection-based approach and identify a class of EDs (namely, full EDs) for
which it remains safe. Then, for a subclass of EDs and for DL-Lite_R
ontologies, we show that answering BUCQs in the above CQE semantics is in AC^0
in data complexity by presenting a suitable, detailed first-order rewriting
algorithm. Finally, we report on experiments conducted in two different
evaluation scenarios, showing the practical feasibility of our rewriting
function.

</details>


### [84] [Automated Hybrid Grounding Using Structural and Data-Driven Heuristics](https://arxiv.org/abs/2507.17493)
*Alexander Beiser,Markus Hecher,Stefan Woltran*

Main category: cs.AI

TL;DR: 本文提出了一种自动化混合基础方法，通过基于数据结构的启发式算法决定何时使用解耦规则体基础，何时使用标准自底向上基础，以缓解ASP在工业应用中的基础瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 基础瓶颈是阻碍答案集编程(ASP)在工业中广泛应用的关键挑战之一。混合基础通过结合标准自底向上基础和规则体解耦技术来缓解这一问题，但何时使用哪种方法尚不明确。

Method: 开发了自动化混合基础方法：引入基于数据结构的启发式分割算法，该算法根据规则结构和实例数据的估计程序，自动检测何时使用规则体解耦基础，何时使用标准基础更有利。

Result: 原型实现实验表明，该方法在难以基础的场景中表现优异，在难以求解的实例上接近最先进水平。

Conclusion: 提出的自动化混合基础方法有效缓解了ASP的基础瓶颈问题，特别是在处理复杂场景时展现出显著优势，为ASP的工业应用提供了实用解决方案。

Abstract: The grounding bottleneck poses one of the key challenges that hinders the
widespread adoption of Answer Set Programming in industry. Hybrid Grounding is
a step in alleviating the bottleneck by combining the strength of standard
bottom-up grounding with recently proposed techniques where rule bodies are
decoupled during grounding. However, it has remained unclear when hybrid
grounding shall use body-decoupled grounding and when to use standard bottom-up
grounding. In this paper, we address this issue by developing automated hybrid
grounding: we introduce a splitting algorithm based on data-structural
heuristics that detects when to use body-decoupled grounding and when standard
grounding is beneficial. We base our heuristics on the structure of rules and
an estimation procedure that incorporates the data of the instance. The
experiments conducted on our prototypical implementation demonstrate promising
results, which show an improvement on hard-to-ground scenarios, whereas on
hard-to-solve instances we approach state-of-the-art performance.

</details>


### [85] [Can One Domain Help Others? A Data-Centric Study on Multi-Domain Reasoning via Reinforcement Learning](https://arxiv.org/abs/2507.17512)
*Yu Li,Zhuoshi Pan,Honglin Lin,Mengyuan Sun,Conghui He,Lijun Wu*

Main category: cs.AI

TL;DR: 本文系统研究了强化学习可验证奖励（RLVR）框架下多领域推理能力，聚焦数学推理、代码生成与逻辑谜题三大领域，揭示了跨领域训练的相互作用机制与优化策略。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于单一推理领域（如数学、编程或逻辑），而现实场景需要综合认知能力。RLVR框架下多领域推理的交互机制尚不明确，亟需系统性探索。

Method: 1) 采用GRPO算法与Qwen-2.5-7B模型族评估单领域训练效果；2) 分析跨领域联合训练中的协同/冲突效应；3) 对比基础模型与指令模型在相同RL配置下的表现；4) 系统研究课程学习、奖励设计及语言因素影响。

Result: 实验揭示了领域间动态交互规律：跨领域训练存在显著协同效应（如代码生成提升数学推理），但也发现特定冲突；课程学习与分层奖励设计能有效提升综合推理性能达15-20%。

Conclusion: 研究为LLMs多领域推理能力优化提供了方法论指导：需针对性设计跨领域训练策略、分层奖励机制及渐进式课程，这对开发通用人工智能推理系统具有重要启示。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for enhancing the reasoning capabilities of LLMs. Existing
research has predominantly concentrated on isolated reasoning domains such as
mathematical problem-solving, coding tasks, or logical reasoning. However, real
world reasoning scenarios inherently demand an integrated application of
multiple cognitive skills. Despite this, the interplay among these reasoning
skills under reinforcement learning remains poorly understood. To bridge this
gap, we present a systematic investigation of multi-domain reasoning within the
RLVR framework, explicitly focusing on three primary domains: mathematical
reasoning, code generation, and logical puzzle solving. We conduct a
comprehensive study comprising four key components: (1) Leveraging the GRPO
algorithm and the Qwen-2.5-7B model family, our study thoroughly evaluates the
models' in-domain improvements and cross-domain generalization capabilities
when trained on single-domain datasets. (2) Additionally, we examine the
intricate interactions including mutual enhancements and conflicts that emerge
during combined cross-domain training. (3) To further understand the influence
of SFT on RL, we also analyze and compare performance differences between base
and instruct models under identical RL configurations. (4) Furthermore, we
delve into critical RL training details, systematically exploring the impacts
of curriculum learning strategies, variations in reward design, and
language-specific factors. Through extensive experiments, our results offer
significant insights into the dynamics governing domain interactions, revealing
key factors influencing both specialized and generalizable reasoning
performance. These findings provide valuable guidance for optimizing RL
methodologies to foster comprehensive, multi-domain reasoning capabilities in
LLMs.

</details>


### [86] [TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment](https://arxiv.org/abs/2507.17514)
*Athanasios Davvetas,Xenia Ziouvelou,Ypatia Dami,Alexis Kaponis,Konstantina Giouvanopoulou,Michael Papademas*

Main category: cs.AI

TL;DR: 本文介绍了TAI扫描工具，一个基于RAG的TAI自评估工具，支持法律TAI评估，重点帮助遵守AI法案。通过两阶段评估，系统能预测风险等级并检索相关条款，定性评估显示效果良好。


<details>
  <summary>Details</summary>
Motivation: 开发TAI扫描工具旨在通过最小化输入，帮助AI系统进行法律合规性自评估，特别是针对AI法案的要求，简化合规流程。

Method: 工具采用两步法：预筛选和评估阶段。评估阶段根据AI法案预测系统风险等级，同时检索相关法律条款以辅助合规。

Result: 定性评估显示，工具能准确预测风险等级，并在三个不同语义组中检索到相关条款。工具推理依赖于与高风险系统设置的比较。

Conclusion: TAI扫描工具在帮助AI系统遵守AI法案方面表现出色，其风险评估和条款检索功能为合规提供了有效支持。

Abstract: This paper introduces the TAI Scan Tool, a RAG-based TAI self-assessment tool
with minimalistic input. The current version of the tool supports the legal TAI
assessment, with a particular emphasis on facilitating compliance with the AI
Act. It involves a two-step approach with a pre-screening and an assessment
phase. The assessment output of the system includes insight regarding the
risk-level of the AI system according to the AI Act, while at the same time
retrieving relevant articles to aid with compliance and notify on their
obligations. Our qualitative evaluation using use-case scenarios yields
promising results, correctly predicting risk levels while retrieving relevant
articles across three distinct semantic groups. Furthermore, interpretation of
results shows that the tool's reasoning relies on comparison with the setting
of high-risk systems, a behaviour attributed to their deployment requiring
careful consideration, and therefore frequently presented within the AI Act.

</details>


### [87] [Constructing Ophthalmic MLLM for Positioning-diagnosis Collaboration Through Clinical Cognitive Chain Reasoning](https://arxiv.org/abs/2507.17539)
*Xinyao Liu,Diping Song*

Main category: cs.AI

TL;DR: 本文提出FundusExpert眼科专用多模态大模型及FundusGen数据集，通过智能Fundus-Engine系统整合定位-诊断推理链，显著提升眼科诊断精度与报告生成临床一致性，并揭示数据质量与模型能力的标度律关系。


<details>
  <summary>Details</summary>
Motivation: 现有医学多模态大模型在眼科等专科领域面临注释粒度碎片化与临床逻辑不一致的挑战，阻碍跨模态精准理解。

Method: 开发Fundus-Engine系统自动定位病灶，结合语义扩展构建FundusGen数据集；设计临床对齐认知链指导模型生成可解释推理路径；微调得到FundusExpert模型。

Result: FundusExpert在眼科问答任务中以26.6%优势超越40B MedRegA，零样本报告生成临床一致性达77.0%（GPT-4o为47.6%）；发现数据质量-能力标度律$L \propto N^{0.068}$。

Conclusion: 通过区域定位与诊断推理链的结合，构建了可扩展的临床对齐多模态大模型，为专科领域视觉-语言鸿沟的弥合提供新路径。

Abstract: Multimodal large language models (MLLMs) demonstrate significant potential in
the field of medical diagnosis. However, they face critical challenges in
specialized domains such as ophthalmology, particularly the fragmentation of
annotation granularity and inconsistencies in clinical reasoning logic, which
hinder precise cross-modal understanding. This paper introduces FundusExpert,
an ophthalmology-specific MLLM with integrated positioning-diagnosis reasoning
capabilities, along with FundusGen, a dataset constructed through the
intelligent Fundus-Engine system. Fundus-Engine automates localization and
leverages MLLM-based semantic expansion to integrate global disease
classification, local object detection, and fine-grained feature analysis
within a single fundus image. Additionally, by constructing a clinically
aligned cognitive chain, it guides the model to generate interpretable
reasoning paths. FundusExpert, fine-tuned with instruction data from FundusGen,
achieves the best performance in ophthalmic question-answering tasks,
surpassing the average accuracy of the 40B MedRegA by 26.6%. It also excels in
zero-shot report generation tasks, achieving a clinical consistency of 77.0%,
significantly outperforming GPT-4o's 47.6%. Furthermore, we reveal a scaling
law between data quality and model capability ($L \propto N^{0.068}$),
demonstrating that the cognitive alignment annotations in FundusGen enhance
data utilization efficiency. By integrating region-level localization with
diagnostic reasoning chains, our work develops a scalable, clinically-aligned
MLLM and explores a pathway toward bridging the visual-language gap in specific
MLLMs. Our project can be found at https://github.com/MeteorElf/FundusExpert.

</details>


### [88] [Simulating multiple human perspectives in socio-ecological systems using large language models](https://arxiv.org/abs/2507.17680)
*Yongchao Zeng,Calum Brown,Ioannis Kyriakou,Ronja Hotz,Mark Rounsevell*

Main category: cs.AI

TL;DR: 研究开发了HoPeS框架，利用LLM代理模拟不同利益相关者视角，通过角色扮演体验视角差异，并在土地用途变化案例中展示了研究者与政策制定者间的现实矛盾。


<details>
  <summary>Details</summary>
Motivation: 理解社会生态系统需要多元利益相关者视角，但传统方法难以获取这些视角，因此需要开发新的模拟工具来探索不同观点。

Method: 采用基于大语言模型（LLM）的代理代表不同利益相关者，设计模拟协议作为"支架"，支持用户进行多视角模拟、反思与整合，并开发原型系统进行叙事驱动和数值实验。

Result: 实验显示用户作为研究者推荐技术合理政策时，仍因利益相关者竞争性主张出现政策与实施的偏差，反映了现实世界中研究者与政策制定者的视角错位，但用户表现出尝试不同叙事框架的高动机。

Conclusion: HoPeS系统展现了探索多元视角的潜力，进一步优化系统和协议可能开启社会生态模拟中跨学科合作的新形式。

Abstract: Understanding socio-ecological systems requires insights from diverse
stakeholder perspectives, which are often hard to access. To enable
alternative, simulation-based exploration of different stakeholder
perspectives, we develop the HoPeS (Human-Oriented Perspective Shifting)
modelling framework. HoPeS employs agents powered by large language models
(LLMs) to represent various stakeholders; users can step into the agent roles
to experience perspectival differences. A simulation protocol serves as a
"scaffold" to streamline multiple perspective-taking simulations, supporting
users in reflecting on, transitioning between, and integrating across
perspectives. A prototype system is developed to demonstrate HoPeS in the
context of institutional dynamics and land use change, enabling both
narrative-driven and numerical experiments. In an illustrative experiment, a
user successively adopts the perspectives of a system observer and a researcher
- a role that analyses data from the embedded land use model to inform
evidence-based decision-making for other LLM agents representing various
institutions. Despite the user's effort to recommend technically sound
policies, discrepancies persist between the policy recommendation and
implementation due to stakeholders' competing advocacies, mirroring real-world
misalignment between researcher and policymaker perspectives. The user's
reflection highlights the subjective feelings of frustration and disappointment
as a researcher, especially due to the challenge of maintaining political
neutrality while attempting to gain political influence. Despite this, the user
exhibits high motivation to experiment with alternative narrative framing
strategies, suggesting the system's potential in exploring different
perspectives. Further system and protocol refinement are likely to enable new
forms of interdisciplinary collaboration in socio-ecological simulations.

</details>


### [89] [Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks](https://arxiv.org/abs/2507.17695)
*Ilias Chatzistefanidis,Navid Nikaein*

Main category: cs.AI

TL;DR: 本文提出了一种结合大语言模型（LLM）与实时优化算法的可信AI代理范式——共生代理，用于6G网络中的实时决策与管理。实验表明，该方法显著降低了决策错误并提升了资源效率。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的自主代理在6G网络中具有重要潜力，但需从专用智能向通用人工智能（AGI）驱动的网络转型，以提升网络功能的多样性和管理能力。

Method: 设计了输入级优化器提供数值精确任务的边界不确定性引导，输出级优化器实现自适应实时控制，并开发了两种新型代理：无线接入网优化器和多代理服务级别协议（SLA）协商器。

Result: 共生代理将决策错误减少五倍，较小语言模型（SLM）在GPU资源开销减少99.9%的情况下达到相似精度，实时循环延迟为82毫秒。多代理演示显示无线接入网资源过利用率降低约44%。

Conclusion: 共生范式为下一代AGI驱动网络奠定了基础，确保其适应性、高效性和可信性，即使在大语言模型不断进步的情况下。

Abstract: Large Language Model (LLM)-based autonomous agents are expected to play a
vital role in the evolution of 6G networks, by empowering real-time
decision-making related to management and service provisioning to end-users.
This shift facilitates the transition from a specialized intelligence approach,
where artificial intelligence (AI) algorithms handle isolated tasks, to
artificial general intelligence (AGI)-driven networks, where agents possess
broader reasoning capabilities and can manage diverse network functions. In
this paper, we introduce a novel agentic paradigm that combines LLMs with
real-time optimization algorithms towards Trustworthy AI, defined as symbiotic
agents. Optimizers at the LLM's input-level provide bounded uncertainty
steering for numerically precise tasks, whereas output-level optimizers
supervised by the LLM enable adaptive real-time control. We design and
implement two novel agent types including: (i) Radio Access Network optimizers,
and (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We
further propose an end-to-end architecture for AGI networks and evaluate it on
a 5G testbed capturing channel fluctuations from moving vehicles. Results show
that symbiotic agents reduce decision errors fivefold compared to standalone
LLM-based agents, while smaller language models (SLM) achieve similar accuracy
with a 99.9% reduction in GPU resource overhead and in near-real-time loops of
82 ms. A multi-agent demonstration for collaborative RAN on the real-world
testbed highlights significant flexibility in service-level agreement and
resource allocation, reducing RAN over-utilization by approximately 44%.
Drawing on our findings and open-source implementations, we introduce the
symbiotic paradigm as the foundation for next-generation, AGI-driven
networks-systems designed to remain adaptable, efficient, and trustworthy even
as LLMs advance.

</details>


### [90] [Thinking Isn't an Illusion: Overcoming the Limitations of Reasoning Models via Tool Augmentations](https://arxiv.org/abs/2507.17699)
*Zhao Song,Song Yue,Jiahao Zhang*

Main category: cs.AI

TL;DR: 研究表明，在引入工具增强后，大型推理模型（LRMs）在所有任务复杂度级别上均优于非推理模型，挑战了'推理是幻觉'的近期观点。


<details>
  <summary>Details</summary>
Motivation: 近期实证研究（如苹果公司的[Shojaee et al., 2025]）表明，显式推理过程可能并未提升模型能力，甚至非推理模型在高低复杂度任务中表现更优。本研究旨在探讨工具增强是否能突破LRMs的局限性。

Method: 研究整合了Python解释器和草稿纸两种工具，并在苹果的基准推理谜题上评估了三款代表性LLM及其LRM版本。

Result: 实验显示，正确使用工具时，LRMs在所有任务复杂度级别上持续超越非推理模型。

Conclusion: 工具增强的LRMs在解决复杂问题方面具有潜力，反驳了'推理无效'的论点，为LRMs的实际应用提供了新证据。

Abstract: Large Reasoning Models (LRMs) have become a central focus in today's large
language model (LLM) research, where models are designed to output a
step-by-step thinking process before arriving at a final answer to handle
complex reasoning tasks. Despite their promise, recent empirical studies (e.g.,
[Shojaee et al., 2025] from Apple) suggest that this thinking process may not
actually enhance reasoning ability, where LLMs without explicit reasoning
actually outperform LRMs on tasks with low or high complexity. In this work, we
revisit these findings and investigate whether the limitations of LRMs persist
when tool augmentations are introduced. We incorporate two types of tools,
Python interpreters and scratchpads, and evaluate three representative LLMs and
their LRM counterparts on Apple's benchmark reasoning puzzles. Our results show
that, with proper tool use, LRMs consistently outperform their non-reasoning
counterparts across all levels of task complexity. These findings challenge the
recent narrative that reasoning is an illusion and highlight the potential of
tool-augmented LRMs for solving complex problems.

</details>


### [91] [Online Submission and Evaluation System Design for Competition Operations](https://arxiv.org/abs/2507.17730)
*Zhe Chen,Daniel Harabor,Ryan Hechnenberger,Nathan R. Sturtevant*

Main category: cs.AI

TL;DR: 本文介绍了一种在线竞赛系统，用于自动化竞赛提交和评估过程，解决了研究社区在追踪算法进展和评估大量提交时面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 研究社区通过基准数据集和竞赛比较算法性能，但现有方法存在操作负担重和兼容性问题，需要一种更高效的解决方案。

Method: 开发了一个在线竞赛系统，利用隔离环境自动评估提交，支持组织者高效管理大量参赛作品。

Result: 该系统已成功应用于多个竞赛，如基于网格的路径规划竞赛和机器人跑步联盟竞赛，验证了其有效性。

Conclusion: 该在线竞赛系统为研究社区提供了一种高效、自动化的竞赛管理工具，有助于跟踪算法进展并减少操作负担。

Abstract: Research communities have developed benchmark datasets across domains to
compare the performance of algorithms and techniques However, tracking the
progress in these research areas is not easy, as publications appear in
different venues at the same time, and many of them claim to represent the
state-of-the-art. To address this, research communities often organise periodic
competitions to evaluate the performance of various algorithms and techniques,
thereby tracking advancements in the field. However, these competitions pose a
significant operational burden. The organisers must manage and evaluate a large
volume of submissions. Furthermore, participants typically develop their
solutions in diverse environments, leading to compatibility issues during the
evaluation of their submissions. This paper presents an online competition
system that automates the submission and evaluation process for a competition.
The competition system allows organisers to manage large numbers of submissions
efficiently, utilising isolated environments to evaluate submissions. This
system has already been used successfully for several competitions, including
the Grid-Based Pathfinding Competition and the League of Robot Runners
competition.

</details>
