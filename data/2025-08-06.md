<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 2]
- [math.OC](#math.OC) [Total: 9]
- [math.NT](#math.NT) [Total: 15]
- [math.LO](#math.LO) [Total: 3]
- [math.CO](#math.CO) [Total: 13]
- [q-fin.MF](#q-fin.MF) [Total: 1]
- [cs.CR](#cs.CR) [Total: 18]
- [cs.AI](#cs.AI) [Total: 52]
- [cs.DM](#cs.DM) [Total: 2]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Polynomial complexity sampling from multimodal distributions using Sequential Monte Carlo](https://arxiv.org/abs/2508.02763)
*Ruiyu Han,Gautam Iyer,Dejan Slepčev*

Main category: math.ST

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We study a sequential Monte Carlo algorithm to sample from the Gibbs measure
with a non-convex energy function at a low temperature. We use the practical
and popular geometric annealing schedule, and use a Langevin diffusion at each
temperature level. The Langevin diffusion only needs to run for a time that is
long enough to ensure local mixing within energy valleys, which is much shorter
than the time required for global mixing. Our main result shows convergence of
Monte Carlo estimators with time complexity that, approximately, scales like
the forth power of the inverse temperature, and the square of the inverse
allowed error. We also study this algorithm in an illustrative model scenario
where more explicit estimates can be given.

</details>


### [2] [Expanding the Standard Diffusion Process to Specified Non-Gaussian Marginal Distributions](https://arxiv.org/abs/2508.03617)
*Robert Richardson,H. Dennis Tolley,Kenneth Kuttler*

Main category: math.ST

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We develop a class of non-Gaussian translation processes that extend
classical stochastic differential equations (SDEs) by prescribing arbitrary
absolutely continuous marginal distributions. Our approach uses a copula-based
transformation to flexibly model skewness, heavy tails, and other non-Gaussian
features often observed in real data. We rigorously define the process,
establish key probabilistic properties, and construct a corresponding diffusion
model via stochastic calculus, including proofs of existence and uniqueness. A
simplified approximation is introduced and analyzed, with error bounds derived
from asymptotic expansions. Simulations demonstrate that both the full and
simplified models recover target marginals with high accuracy. Examples using
the Student's t, asymmetric Laplace, and Exponentialized Generalized Beta of
the Second Kind (EGB2) distributions illustrate the flexibility and
tractability of the framework.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [3] [Global Optimality in Multi-Flyby Asteroid Trajectory Optimization: Theory and Application Techniques](https://arxiv.org/abs/2508.02904)
*Zhong Zhang,Xiang Guo,Di Wu,Hexi Baoyin,Junfeng Li,Francesco Topputo*

Main category: math.OC

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Designing optimal trajectories for multi-flyby asteroid missions is
scientifically critical but technically challenging due to nonlinear dynamics,
intermediate constraints, and numerous local optima. This paper establishes a
method that approaches global optimality for multi-flyby trajectory
optimization under a given sequence. The original optimal control problem with
interior-point equality constraints is transformed into a multi-stage decision
formulation. This reformulation enables direct application of dynamic
programming in lower dimensions, and follows Bellman's principle of optimality.
Moreover, the method provides a quantifiable bound on global optima errors
introduced by discretization and approximation assumptions, thus ensuring a
measure of confidence in the obtained solution. The method accommodates both
impulsive and low-thrust maneuver schemes in rendezvous and flyby scenarios.
Several computational techniques are introduced to enhance efficiency,
including a specialized solution for bi-impulse cases and an adaptive step
refinement strategy. The proposed method is validated through three problems:
1) an impulsive variant of the fourth Global Trajectory Optimization
competition problem (GTOC4), 2) the GTOC11 problem, and 3) the original
low-thrust GTOC4 problem. Each case demonstrates improvements in fuel
consumption over the best-known trajectories. These results give evidence of
the generality and effectiveness of the proposed method in global trajectory
optimization.

</details>


### [4] [A Comparative Study of Optimal Control and Neural Networks in Asteroid Rendezvous Mission Analysis](https://arxiv.org/abs/2508.02920)
*Zhong Zhang,Niccolò Michelotti,Gonçalo Oliveira Pinho,Francesco Topputo*

Main category: math.OC

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: This paper presents a comparative study of the applicability and accuracy of
optimal control methods and neural network-based estimators in the context of
porkchop plots for preliminary asteroid rendezvous mission design. The scenario
considered involves a deep-space CubeSat equipped with a low-thrust engine,
departing from Earth and rendezvousing with a near-Earth asteroid within a
three-year launch window. A low-thrust trajectory optimization model is
formulated, incorporating variable specific impulse, maximum thrust, and path
constraints. The optimal control problem is efficiently solved using Sequential
Convex Programming (SCP) combined with a solution continuation strategy. The
neural network framework consists of two models: one predicts the minimum fuel
consumption ($\Delta v$), while the other estimates the minimum flight time
($\Delta t$) which is used to assess transfer feasibility. Case results
demonstrate that, in simplified scenarios without path constraints, the neural
network approach achieves low relative errors across most of the design space
and successfully captures the main structural features of the porkchop plots.
In cases where the SCP-based continuation method fails due to the presence of
multiple local optima, the neural network still provides smooth and globally
consistent predictions, significantly improving the efficiency of early-stage
asteroid candidate screening. However, the deformation of the feasible region
caused by path constraints leads to noticeable discrepancies in certain
boundary regions, thereby limiting the applicability of the network in detailed
mission design phases. Overall, the integration of neural networks with
porkchop plot analysis offers a effective decision-making tool for mission
designers and planetary scientists, with significant potential for engineering
applications.

</details>


### [5] [Quantum Hamiltonian Descent based Augmented Lagrangian Method for Constrained Nonconvex Nonlinear Optimization](https://arxiv.org/abs/2508.02969)
*Mingze Li,Lei Fan,Zhu Han*

Main category: math.OC

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Nonlinear programming (NLP) plays a critical role in domains such as power
energy systems, chemical engineering, communication networks, and financial
engineering. However, solving large-scale, nonconvex NLP problems remains a
significant challenge due to the complexity of the solution landscape and the
presence of nonlinear nonconvex constraints. In this paper, we develop a
Quantum Hamiltonian Descent based Augmented Lagrange Method (QHD-ALM) framework
to address largescale, constrained nonconvex NLP problems. The augmented
Lagrange method (ALM) can convert a constrained NLP to an unconstrained NLP,
which can be solved by using Quantum Hamiltonian Descent (QHD). To run the QHD
on a classical machine, we propose to use the Simulated Bifurcation algorithm
as the engine to simulate the dynamic process. We apply our algorithm to a
Power-to-Hydrogen System, and the simulation results verify the effectiveness
of our algorithm.

</details>


### [6] [On Relatively Smooth Optimization over Riemannian Manifolds](https://arxiv.org/abs/2508.03048)
*Chang He,Jiaxiang Li,Bo Jiang,Shiqian Ma,Shuzhong Zhang*

Main category: math.OC

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We study optimization over Riemannian embedded submanifolds, where the
objective function is relatively smooth in the ambient Euclidean space. Such
problems have broad applications but are still largely unexplored. We introduce
two Riemannian first-order methods, namely the retraction-based and
projection-based Riemannian Bregman gradient methods, by incorporating the
Bregman distance into the update steps. The retraction-based method can handle
nonsmooth optimization; at each iteration, the update direction is generated by
solving a convex optimization subproblem constrained to the tangent space. We
show that when the reference function is of the quartic form $h(x) =
\frac{1}{4}\|x\|^4 + \frac{1}{2}\|x\|^2$, the constraint subproblem admits a
closed-form solution. The projection-based approach can be applied to smooth
Riemannian optimization, which solves an unconstrained subproblem in the
ambient Euclidean space. Both methods are shown to achieve an iteration
complexity of $\mathcal{O}(1/\epsilon^2)$ for finding an $\epsilon$-approximate
Riemannian stationary point. When the manifold is compact, we further develop
stochastic variants and establish a sample complexity of
$\mathcal{O}(1/\epsilon^4)$. Numerical experiments on the nonlinear eigenvalue
problem and low-rank quadratic sensing problem demonstrate the advantages of
the proposed methods.

</details>


### [7] [Complete Integral of Primer-Vector Equations for Transfers in a Central Gravitational Field](https://arxiv.org/abs/2508.03075)
*Sergey Zaborsky*

Main category: math.OC

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: This paper demonstrates the existence of a complete integral for the system
of differential equations of Lawden's primer-vector, which is used in the
optimization of space transfers in a central gravitational field. The derived
complete integral has been shown to significantly reduce the order of the
differential system for the primer-vector from sixth to second, thereby
simplifying the optimization problem into a boundary value problem with four
parameters. The presence of a complete integral enables the exclusion of the
transversality conditions, which introduce significant complexity to the
boundary value problem. The problem of transfer optimization is considerably
simplified due to the existence of the full integral and generating solutions.
The analysis reveals that, depending on the given constraints, there are six
types of optimization problems, each corresponding to a specific boundary value
problem.

</details>


### [8] [Electricity Price-Aware Scheduling of Data Center Cooling](https://arxiv.org/abs/2508.03160)
*Arash Khojaste,Jonathan Pearce,Golbon Zakeri,Yuanrui Sang*

Main category: math.OC

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Data centers are becoming a major consumer of electricity on the grid, with
cooling accounting for about 40\% of that energy. As electricity prices vary
throughout the day and year, there is a need for cooling strategies that adapt
to these fluctuations to reduce data center cooling costs. In this paper, we
present a model for electricity price-aware cooling scheduling using a Markov
Decision Process(MDP) framework to reliably estimate the cooling system
operational costs and facilitate investment-phase decision-making. We utilize
Quantile Fourier Regression (QFR) fits to classify electricity prices into
different regimes while capturing both daily and seasonal patterns. We simulate
14 years of operation using historical electricity price and outdoor
temperature data, and compare our model against heuristic baselines. The
results demonstrate that our approach consistently achieves lower cooling
costs. This model is useful for grid operators interested in demand response
programs and data center investors looking to make investment decisions.

</details>


### [9] [Robust stabilization of hyperbolic PDE-ODE systems via Neural Operator-approximated gain kernels](https://arxiv.org/abs/2508.03242)
*Kaijing Lyu,Umberto Biccari,Junmin Wang*

Main category: math.OC

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: This paper investigates the mean square exponential stabilization problem for
a class of coupled PDE-ODE systems with Markov jump parameters. The considered
system consists of multiple coupled hyperbolic PDEs and a finite-dimensional
ODE, where all system parameters evolve according to a homogeneous
continuous-time Markov process. The control design is based on a backstepping
approach. To address the computational complexity of solving kernel equations,
a DeepONet framework is proposed to learn the mapping from system parameters to
the backstepping kernels. By employing Lyapunov-based analysis, we further
prove that the controller obtained from the neural operator ensures stability
of the closed-loop stochastic system. Numerical simulations demonstrate that
the proposed approach achieves more than two orders of magnitude speedup
compared to traditional numerical solvers, while maintaining high accuracy and
ensuring robust closed-loop stability under stochastic switching.

</details>


### [10] [Lazifying point insertion algorithms in spaces of measures](https://arxiv.org/abs/2508.03459)
*Arsen Hnatiuk,Daniel Walter*

Main category: math.OC

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Greedy point insertion algorithms have emerged as an attractive tool for the
solution of minimization problems over the space of Radon measures.
Conceptually, these methods can be split into two phases: first, the
computation of a new candidate point via maximizing a continuous function over
the spatial domain, and second, updating the weights and/or support points of
all Dirac-Deltas forming the iterate. Under additional structural assumptions
on the problem, full resolution of the subproblems in both steps guarantees an
asymptotic linear rate of convergence for pure coefficient updates, or finite
step convergence, if, in addition, the position of all Dirac-Deltas is
optimized. In the present paper, we lazify point insertion algorithms and allow
for the inexact solution of both subproblems based on computable error
measures, while provably retaining improved theoretical convergence guarantees.
As a specific example, we present a new method with a quadratic rate of
convergence based on Newton steps for the weight-position pairs, which we
globalize by point-insertion as well as clustering steps.

</details>


### [11] [Feedback Optimization of Dynamical Systems in Time-Varying Environments: An Internal Model Principle Approach](https://arxiv.org/abs/2508.03503)
*Gianluca Bianchin,Bryan Van Scoy*

Main category: math.OC

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Feedback optimization has emerged as a promising approach for regulating
dynamical systems to optimal steady states that are implicitly defined by
underlying optimization problems. Despite their effectiveness, existing methods
face two key limitations: (i) reliable performance is restricted to
time-invariant or slowly varying settings, and (ii) convergence rates are
limited by the need for the controller to operate orders of magnitude slower
than the plant. These limitations can be traced back to the reliance of
existing techniques on numerical optimization algorithms. In this paper, we
propose a novel perspective on the design of feedback optimization algorithms,
by framing these objectives as an output regulation problem. We place
particular emphasis on time-varying optimization problems, and show that an
algorithm can track time-varying optimizers if and only if it incorporates a
model of the temporal variability inherent to the optimization - a requirement
that we term the internal model principle of feedback optimization. Building on
this insight, we introduce a new design methodology that couples
output-feedback stabilization with a control component that drives the system
toward the critical points of the optimization problem. This framework enables
feedback optimization algorithms to overcome the classical limitations of slow
tracking and poor adaptability to time variations.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [12] [Narayana numbers that are products of two Fibonacci numbers](https://arxiv.org/abs/2508.02688)
*Japhet Odjoumani*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Let $\{N_m\}_{m\ge0}$ be the Narayana's cows sequence given by $N_0=0$,
$N_1=1=N_2=1$ and \[ N_{m+3}=N_{m+2}+N_m,\quad \text{ for }\; m\geq 0 \] and
let $\{F_n\}_{n\ge0}$ be the Fibonacci sequence. In this paper we solve
explicitely the Diophantine equation \[ N_m=F_nF_k, \] in positive unknowns
$m,\,n$ and $k$. That is, we find the non-zero narayana numbers that are
products of two Fibonacci numbers.

</details>


### [13] [An effective analytic recurrence for prime numbers: from asymptotics to explicit bounds](https://arxiv.org/abs/2508.02690)
*Benoit Cloitre*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We present an explicit and effective recurrence formula for prime numbers,
bridging arithmetic and analytic approaches. Building upon foundational work by
Gandhi (1971), Golomb (1976), and Keller (2007), we establish the effective
bound $s_n \le 2p_n$ for all $n \ge 1$ within the Golomb-Keller analytic
recurrence. This transforms their asymptotic formula into an explicit
recurrence using twice the n-th prime as the exponent: $$ p_{n+1} = \left\lceil
\left( -1 + \zeta(2p_n) \prod_{j=1}^{n} \left(1 - \frac{1}{p_j^{2p_n}}\right)
\right)^{-1/(2p_n)} \right\rceil $$ The proof is self-contained and relies on
Bertrand's postulate. We also present strong numerical and heuristic evidence
for a sharper conjecture: $s_n \le p_n$ for all $n \ge 1$, suggesting that the
formula works with the n-th prime as the exponent.

</details>


### [14] [On the sum-of-squares function](https://arxiv.org/abs/2508.02701)
*Vitalii V. Iudelevich*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: In this paper, we derive the following asymptotic formula $$
\mathop{{\sum}'}_{n\leqslant x}\dfrac{r(n)}{r(n+1)} = {x}{(\ln
x)^{-3/4}}(c+o(1)),\ \ x \to +\infty,$$ where $r(n)$ is the number of
representations of $n$ as a sum of two squares, $c$ is a positive constant, and
the prime indicates summation over those $n$ for which $r(n+1)\neq 0$.

</details>


### [15] [Divisibility criteria and coefficient formulas for cyclotomic polynomials](https://arxiv.org/abs/2508.02722)
*Laura De Carli,Maurizio Laporta*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We establish necessary and sufficient conditions for a polynomial to be
divisible by a cyclotomic polynomials and derive new formulas involving
Ramanujan sums as an application of our results. Additionally, we provide new
insights into the coefficients of cyclotomic polynomials and we propose a
recursive relation between the coefficients of two cyclotomic polynomials whose
indexes differ by a prime factor.

</details>


### [16] [Slopes of modular forms and the Ghost conjecture](https://arxiv.org/abs/2508.02761)
*Eunsu Hur*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We give an algorithm to compute the slope sequence of modular forms with
fixed Galois components from its first few entries, which is a refined version
of the conjecture of [Buz05]. We use the results of arXiv:2302.07697 on the
ghost conjecture from axXiv:1710.01572. These symmetries in slope sequences
have potential implication to unexplained symmetries in many Coleman-Mazur
eigencurves.

</details>


### [17] [Small gaps between Goldbach primes](https://arxiv.org/abs/2508.02769)
*Mizuki Akeno*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We study small gaps between Goldbach primes $\mathbb{P} \cap (N-\mathbb{P})$
using the Bombieri-Davenport method and the Maynard-Tao method, and compare the
two.
  We show that for almost all even integers $N$, the smallest gap in
$\mathbb{P} \cap (N-\mathbb{P})$ can be $0.765...$ times smaller than the
average gap using the Bombieri-Davenport method. This is an improvement on a
recent result of Tsuda. We also demonstrate that a straightforward application
of the Maynard-Tao method is insufficient to improve this bound. However, it
allows us to establish the existence of bounded gaps between Goldbach primes
with bounded error for almost all even integers $N$.

</details>


### [18] [Numbers with Four Close Factorizations](https://arxiv.org/abs/2508.02818)
*Tsz Ho Chan,Laura Holmes,Michael Liu,Jose Villarreal*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: In this paper, we study numbers $n$ that can be factored in four different
ways as $n = A B = (A + a_1) (B - b_1) = (A + a_2) (B - b_2) = (A + a_3) (B -
b_3)$ with $B \le A$, $1 \le a_1 < a_2 < a_3 \le C$ and $1 \le b_1 < b_2 < b_3
\le C$. We obtain the optimal upper bound $A \le 0.04742 \ldots \cdot C^3 +
O(C)$. The key idea is to transform the original question into generalized Pell
equations $a x^2 - b y^2 = c$ and study their solutions.

</details>


### [19] [Redefining Euler-Rabinowitsch Polynomials with Heegner Number Based Quadratic Formulation](https://arxiv.org/abs/2508.02821)
*Sudarshan Kumaresan,Shipra Kumari,Neha Mishra*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: This paper introduces a novel class of prime-generating quadratic polynomials
defined by $f_{Z,k,H}(n) = n^2 - (2Zk - 1)n + \frac{(2Zk - 1)^2 + H}{4}$, where
$Zk \in \mathbb{Z}_{\geq 0}$ and $H$ belongs to the set of Heegner numbers.
This form is closely related to the Euler-Rabinowitsch polynomials through
specific substitutions. The structure enables algebraic tuning for prime-rich
outputs and provides deeper insight into the impact of Heegner numbers on prime
distribution. Using tools such as the Bateman-Horn conjecture and
prime-counting functions, we demonstrate that this family can be optimized to
generate a high density of primes. This work offers new directions for research
in analytic number theory and potential applications in cryptography and signal
processing.

</details>


### [20] [On Turing's method for Artin $L$-functions and the Selberg class](https://arxiv.org/abs/2508.03023)
*Neea Palojärvi,Tianyu Zhao*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We derive explicit bounds for two general classes of $L$-functions, improving
and generalizing earlier known estimates. These bounds can be used, for
example, to apply Turing's method for determining the number of zeros up to a
given height.

</details>


### [21] [Explicit Hecke eigenform product identities for Hilbert modular forms](https://arxiv.org/abs/2508.03071)
*Zeping Hao,Chao Qin,Yang Zhou*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Let $F$ be a totally real number field, and $g,f,h$ be Hilbert modular forms
over $F$ that are Hecke eigenforms satisfying $g=f\cdot h$. We characterize
such product identities among all real quadratic fields of narrow class number
one, proving they occur only for $F=\mathbb Q(\sqrt{5})$, with precisely two
such identities. We also shed some light on the general totally real case by
showing that no such identity exists when both $f$ and $h$ are Eisenstein
series of distinct weights.

</details>


### [22] [Massey products and unipotent extensions with restricted ramification](https://arxiv.org/abs/2508.03233)
*Oussama Hamza,Donghyeok Lim,Christian Maire*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We fix a prime p and construct new cases of pro-p extensions of number fields
with restricted ramification and splitting, whose Galois groups decompose as
coproducts of pro-p absolute Galois groups of local fields. As a consequence,
these pro-p extensions satisfy the strong Massey vanishing property and thus
admit large unipotent quotients.

</details>


### [23] [Iterates of post-critically finite polynomials of the form $\boldsymbol{x^d+c}$](https://arxiv.org/abs/2508.03308)
*Vefa Goksel*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Fix a prime number $d$. The post-critically finite polynomials of the form
$f_{d,c} = x^d+c\in \mathbb{C}[x]$ play a fundamental role in polynomial
dynamics. While many results are known in the complex dynamical setting, much
less is understood about the arithmetic properties of these polynomials. In
this paper, we describe the factorization of the iterates of post-critically
finite polynomials $f_{d,c}$ over their fields of definition. As a consequence,
we prove new cases of a conjecture of Andrews and Petsche on abelian arboreal
Galois representations.

</details>


### [24] [A dimensional mass transference principle from balls to open sets and applications to dynamical Diophantine approximation](https://arxiv.org/abs/2508.03359)
*Yubin He*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: The mass transference principle of Beresnevich and Velani is a powerful
mechanism for determining the Hausdorff dimension/measure of $\limsup$ sets
that arise naturally in Diophantine approximation. However, in the setting of
dynamical Diophantine approximation, this principle often fails to apply
effectively, as the radii of the balls defining the dynamical $\limsup$ sets
generally depend on the orbit of the point $x$ itself.
  In this paper, we develop a dimensional mass transference principle that
enables us to recover and extend classical results on shrinking target
problems, particularly for the $\beta$-transformation and the Gauss map.
Moreover, our result shows that the corresponding $\limsup$ sets have large
intersection properties. A potentially interesting feature of our method is
that, in many cases, shrinking target problems are closely related to finding
an appropriate Gibbs measure, which may reveal new aspects of the link between
thermodynamic formalism and dynamical Diophantine approximation.

</details>


### [25] [Isogeny graphs of abelian varieties and singular ideals in orders](https://arxiv.org/abs/2508.03570)
*Sarah Arpin,Stefano Marseglia,Caleb Springer*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Famously, Kohel proved that isogeny graphs of ordinary elliptic curves are
beautifully structured objects, now called volcanos. We prove graph structural
theorems for abelian varieties of any dimension with commutative endomorphism
ring and containing a fixed locally Bass order, leveraging an ideal-theoretic
perspective on isogeny graphs. This generalizes previous results, which relied
on restrictive additional assumptions, such as maximal real multiplication,
ordinary, and absolutely simple (Brooks, Jetchev, Wesolowski 2017). In
particular, our work also applies to non-simple and non-ordinary isogeny
classes. To obtain our results, we first prove a structure theorem for the
lattice of inclusion of the overorders of a locally Bass order in an \'etale
algebra which is of independent interest. This analysis builds on a careful
study of local singularities of the orders. We include several examples of
volcanoes and isogeny graphs exhibiting unexpected properties ultimately due to
our more general setting.

</details>


### [26] [Notes and computations on forbidden differences](https://arxiv.org/abs/2508.03650)
*Christian Dean,Haley Havard,Elizabeth Hawkins,Patch Heard,Andrew Lott,Alex Rice*

Main category: math.NT

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We explore from several perspectives the following question: given
$X\subseteq \mathbb{Z}$ and $N\in \mathbb{N}$, what is the maximum size
$D(X,N)$ of $A\subseteq \{1,2,\dots,N\}$ before $A$ is forced to contain two
distinct elements that differ by an element of $X$? The set of forbidden
differences, $X$, is called \textit{intersective} if $D(X,N)=o(N)$, with the
most well-studied examples being $X=S=\{n^2: n\in \mathbb{N}\}$ and
$X=\mathcal{P}-1=\{p-1: p\text{ prime}\}$. In addition to some new results,
including exact formulas and estimates for $D(X,N)$ in some non-intersective
cases like $X=\mathcal{P}$ and $X=S+k$, $k\in \mathbb{N}$, we also provide a
comprehensive survey of known bounds and extensive computational data. In
particular, we utilize an existing algorithm for finding maximum cliques in
graphs to determine $D(S,N)$ for $N\leq 300$ and $D(\mathcal{P}-1,N)$ for
$N\leq 500$. None of these exact values appear previously in the literature.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [27] [Total Failure of Approachability at Successors of Singulars of Countable Cofinality](https://arxiv.org/abs/2508.02867)
*Hannes Jakob*

Main category: math.LO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Relative to class many supercompact cardinals, we construct a model of
$\ZFC+\GCH$ where for every singular cardinal $\delta$ of countable cofinality
and every regular uncountable $\mu<\delta$ there are stationarily many
non-approachable points of cofinality $\mu$ in $\delta^+$. This answers a
question of Mitchell and provides a decisive answer to a question of Foreman
and Shelah.

</details>


### [28] [Difference-restriction algebras with operators](https://arxiv.org/abs/2508.03432)
*Célia Borlido,Ganna Kudryavtseva,Brett McLean*

Main category: math.LO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We exhibit an adjunction between a category of abstract algebras of partial
functions that we call difference-restriction algebras and a category of
Hausdorff \'etale spaces. Difference-restriction algebras are those algebras
isomorphic to a collection of partial functions closed under relative
complement and domain restriction. Our adjunction generalises the adjunction
between the category of generalised Boolean algebras and the category of
Hausdorff spaces. We define the finitary compatible completion of a
difference-restriction algebra and show that the monad induced by our
adjunction yields the finitary compatible completion of any
difference-restriction algebra. As a corollary, the adjunction restricts to a
duality between the finitarily compatibly complete difference-restriction
algebras and the locally compact zero-dimensional Hausdorff \'etale spaces,
generalising the duality between generalised Boolean algebras and locally
compact zero-dimensional Hausdorff spaces. We then extend these adjunction,
duality, and completion results to difference-restriction algebras equipped
with arbitrary additional compatibility preserving operators.

</details>


### [29] [On the de Rham theorem in the globally subanalytic setting](https://arxiv.org/abs/2508.03499)
*Annette Huber,Tobias Kaiser,Abhishek Oswal*

Main category: math.LO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: For globally subanalytic manifolds we define de Rham complexes of globally
subanalytic differential forms and of constructible differential forms. Whereas
the de Rham theorem does not hold for the former in the non-compact case, it
does hold for the latter in full generality. We deduce that the constructible
de Rham cohomology groups are canonically isomorphic to the classical ones. We
stress that our results apply already in the $C^1$-setting.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [30] [Random Walks and the Meeting Time for Trees](https://arxiv.org/abs/2508.02804)
*Andrew Beveridge,Ben Bridenbaugh,Ari Holcombe Pomerance*

Main category: math.CO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Consider a random walk on a tree $G=(V,E)$. For $v,w \in V$, let the hitting
time $H(v,w)$ denote the expected number of steps required for the random walk
started at $v$ to reach $w$, and let $\pi_v = \mathrm{deg}(v)/2|E|$ denote the
stationary distribution for the random walk. We characterize the extremal tree
structures for the meeting time $T_{\mathrm{meet}}(G) = \max_{w \in V} \sum_{v
\in V} \pi_v H(v,w)$. For fixed order $n$ and diameter $d$, the meeting time is
maximized by the broom graph. The meeting time is minimized by the balanced
double broom graph, or a slight variant, depending on the relative parities of
$n$ and $d$.

</details>


### [31] [The asymptotic rank of adjacency matrices of weighted configuration models over arbitrary fields](https://arxiv.org/abs/2508.02813)
*Remco van der Hofstad,Noela Müller,Haodong Zhu*

Main category: math.CO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We study the asymptotic rank of adjacency matrices of a large class of
edge-weighted configuration models. Here, the weight of a (multi-)edge can be
any fixed non-zero element from an arbitrary field, as long as it is
independent of the (multi-)graph. Our main result demonstrates that the
asymptotic behavior of the normalized rank of the adjacency matrix neither
depends on the fixed edge-weights, nor on which field they are chosen from. Our
approach relies on a novel adaptation of the component exploration method of
\cite{janson2009new}, which enables the application of combinatorial techniques
from \cite{coja2022rank, HofMul25}.

</details>


### [32] [Plabic Tangles and Cluster Promotion Maps](https://arxiv.org/abs/2508.02891)
*Chaim Even-Zohar,Matteo Parisi,Melissa Sherman-Bennett,Ran Tessler,Lauren Williams*

Main category: math.CO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Inspired by the BCFW recurrence for tilings of the amplituhedron, we
introduce the general framework of `plabic tangles' that utilizes plabic graphs
to define rational maps between products of Grassmannians called `promotions'.
The central conjecture of the paper is that promotion maps are quasi-cluster
homomorphisms, which we prove for several classes of promotions. In order to
define promotion maps, we utilize $m$-vector-relation configurations ($m$-VRCs)
on plabic graphs. We relate $m$-VRCs to the degree (a.k.a `intersection
number') of the amplituhedron map on positroid varieties and characterize all
plabic trees with intersection number one and their VRCs. Finally, we show that
promotion maps admit an operad structure and, supported by the class of
`$4$-mass box' promotion, we point at new positivity properties for
non-rational maps beyond cluster algebras. Promotion maps have important
connections to the geometry and cluster structure of the amplituhedron and
singularities of scattering amplitudes in planar $\mathcal{N}=4$ super
Yang-Mills theory.

</details>


### [33] [Backbone colouring of chordal graphs](https://arxiv.org/abs/2508.02980)
*Júlio Araújo,Nicolas Nisse,Lucas Picasarri-Arrieta*

Main category: math.CO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: A proper $k$-colouring of a graph $G=(V,E)$ is a function $c: V(G)\to
\{1,\ldots,k\}$ such that $c(u)\neq c(v)$ for every edge $uv\in E(G)$. The
chromatic number $\chi(G)$ is the minimum $k$ such that there exists a proper
$k$-colouring of $G$. Given a spanning subgraph $H$ of $G$, a $q$-backbone
$k$-colouring of $(G,H)$ is a proper $k$-colouring $c$ of $G$ such that $\lvert
c(u)-c(v)\rvert \ge q$ for every edge $uv\in E(H)$. The $q$-backbone chromatic
number ${\rm BBC}_q(G,H)$ is the smallest $k$ for which there exists a
$q$-backbone $k$-colouring of $(G,H)$. In their seminal paper, Broersma et
al.~\cite{BFGW07} ask whether, for any chordal graph $G$ and any spanning
forest $H$ of $G$, we have that ${\rm BBC}_2(G,H)\leq \chi(G)+O(1)$.
  In this work, we first show that this is true as long as $H$ is bipartite and
$G$ is an interval graph in which each vertex belongs to at most two maximal
cliques. We then show that this does not extend to bipartite graphs as backbone
by exhibiting a family of chordal graphs $G$ with spanning bipartite subgraphs
$H$ satisfying ${\rm BBC}_2(G,H)\geq \frac{5\chi(G)}{3}$. Then, we show that if
$G$ is chordal and $H$ has bounded maximum average degree (in particular, if
$H$ is a forest), then ${\rm BBC}_2(G,H)\leq \chi(G)+O(\sqrt{\chi(G)})$. We
finally show that ${\rm BBC}_2(G,H)\leq \frac{3}{2}\chi(G)+O(1)$ holds whenever
$G$ is chordal and $H$ is $C_4$-free.

</details>


### [34] [Lorentzian polynomials and matroids over triangular hyperfields 1: Topological aspects](https://arxiv.org/abs/2508.02907)
*Matthew Baker,June Huh,Mario Kummer,Oliver Lorscheid*

Main category: math.CO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Lorentzian polynomials serve as a bridge between continuous and discrete
convexity, connecting analysis and combinatorics. In this article, we study the
topology of the space $\mathbb{P}\textrm{L}_J$ of Lorentzian polynomials on $J$
modulo $\mathbb{R}_{>0}$, which is nonempty if and only if $J$ is the set of
bases of a polymatroid. We prove that $\mathbb{P}\textrm{L}_J$ is a manifold
with boundary of dimension equal to the Tutte rank of $J$, and more precisely,
that it is homeomorphic to a closed Euclidean ball with the Dressian of $J$
removed from its boundary. Furthermore, we show that $\mathbb{P}\textrm{L}_J$
is homeomorphic to the thin Schubert cell $\textrm{Gr}_J(\mathbb{T}_q)$ of $J$
over the triangular hyperfield $\mathbb{T}_q$, introduced by Viro in the
context of tropical geometry and Maslov dequantization, for any $q>0$. This
identification enables us to apply the representation theory of polymatroids
developed in a companion paper, as well as earlier work by the first and fourth
authors on foundations of matroids, to give a simple explicit description of
$\mathbb{P}\textrm{L}_J$ up to homeomorphism in several key cases. Our results
show that $\mathbb{P}\textrm{L}_J$ always admits a compactification
homeomorphic to a closed Euclidean ball. They can also be used to answer a
question of Br\"and\'en in the negative by showing that the closure of
$\mathbb{P}\textrm{L}_J$ within the space of all polynomials modulo
$\mathbb{R}_{>0}$ is not homeomorphic to a closed Euclidean ball in general. In
addition, we introduce the Hausdorff compactification of the space of rescaling
classes of Lorentzian polynomials and show that the Chow quotient of a complex
Grassmannian maps naturally to this compactification. This provides a geometric
framework that connects the asymptotic structure of the space of Lorentzian
polynomials with classical constructions in algebraic geometry.

</details>


### [35] [Chromatic discrepancy of locally $s$-colourable graphs](https://arxiv.org/abs/2508.02985)
*Timothée Corsini,Lucas Picasarri-Arrieta,Théo Pierron,François Pirot,Eileen Robinson*

Main category: math.CO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: The chromatic discrepancy of a graph $G$, denoted $\phi(G)$, is the least
over all proper colourings $\sigma$ of $G$ of the greatest difference between
the number of colours $|\sigma(V(H))|$ spanned by an induced subgraph $H$ of
$G$ and its chromatic number $\chi(H)$. We prove that the chromatic discrepancy
of a triangle-free graph $G$ is at least $\chi(G)-2$. This is best possible and
positively answers a question raised by Aravind, Kalyanasundaram, Sandeep, and
Sivadasan.
  More generally, we say that a graph $G$ is locally $s$-colourable if the
closed neighbourhood of any vertex $v\in V(G)$ is properly $s$-colourable; in
particular, a triangle-free graph is locally $2$-colourable. We conjecture that
every locally $s$-colourable graph $G$ satisfies $\phi(G) \geq \chi(G)-s$, and
show that this would be almost best possible. We prove the conjecture when
$\chi(G) \le 11s/6$, and as a partial result towards the general case, we prove
that every locally $s$-colourable graph $G$ satisfies $\phi(G) \geq \chi(G) -
s\ln \chi(G)$.
  If the conjecture holds, it implies in particular, for every integer
$\ell\geq 2$, that any graph $G$ without any copy of $C_{\ell+1}$, the cycle of
length $\ell+1$, satisfies $\phi(G) \geq \chi(G) - \ell$. When $\ell \ge 3$ and
$G\neq K_\ell$, we conjecture that we actually have $\phi(G)\ge \chi(G) - \ell
+ 1$, and prove it in the special case $\ell = 3$ or $\chi(G) \le 5\ell/3$. In
general, we further obtain that every $C_{\ell+1}$-free graph $G$ satisfies
$\phi(G) \geq \chi(G) - O_{\ell}(\ln \ln \chi(G))$. We do so by determining an
almost tight bound on the chromatic number of balls of radius at most $\ell/2$
in $G$, which could be of independent interest.

</details>


### [36] [Cliques and High Odd Holes in Graphs with Chromatic Number Equal to Maximum Degree](https://arxiv.org/abs/2508.02939)
*Rachel Galindo,Jessica McDonald,Songling Shan*

Main category: math.CO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We prove that if $G$ is a connected graph with $\chi(G) = \Delta(G)$ and
$G\neq \overline{C_7}$, then $G$ contains either $K_{\Delta(G)}$ or an odd hole
where every vertex has degree at least $\Delta(G)-1$ in $G$. This extends
earlier work by Chen, Lan, Lin and Zhou, who proved the result for
$\Delta(G)\geq 7$.

</details>


### [37] [On universal graphs for trees and treewidth $k$ graphs](https://arxiv.org/abs/2508.03335)
*Neel Kaul,David R. Wood*

Main category: math.CO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Let $s(n)$ be the minimum number of edges in a graph that contains every
$n$-vertex tree as a subgraph. Chung and Graham [J. London Math. Soc. 1983]
claim to prove that $s(n)\leqslant O(n\log n)$. We point out a mistake in their
proof. The previously best known upper bound is $s(n)\leqslant O(n(\log
n)(\log\log n)^{2})$ by Chung, Graham and Pippenger [Proc. Hungarian Coll. on
Combinatorics 1976], the proof of which is missing many crucial details. We
give a fully self-contained proof of the new and improved upper bound
$s(n)\leqslant O(n(\log n)(\log\log n))$. The best known lower bound is
$s(n)\geqslant \Omega(n\log n)$.
  We generalise these results for graphs of treewidth $k$. For an integer
$k\geqslant 1$, let $s_k(n)$ be the minimum number of edges in a graph that
contains every $n$-vertex graph with treewidth $k$ as a subgraph. So
$s(n)=s_1(n)$. We show that $\Omega(k n\log n) \leqslant s_k(n) \leqslant
O(kn(\log n)(\log\log n))$.

</details>


### [38] [Quadratic relations for ninth variations of Schur functions and application to Schur multiple zeta functions](https://arxiv.org/abs/2508.03150)
*Wataru Takeda,Yoshinori Yamasaki*

Main category: math.CO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Macdonald's ninth variation of Schur functions is a broad generalization of
the classical Schur function and its variants, defined via the Jacobi-Trudi
determinant formula. In this paper, we establish various algebraic relations
for $S^{(r)}_{\lambda/\mu}(X)$, a class of the ninth variation introduced by
Nakagawa, Noumi, Shirakawa, and Yamada, by combining the Jacobi-Trudi formula
with determinant formulas such as the Desnanot-Jacobi adjoint matrix theorem
and the Pl\"ucker relations, which generalize the corresponding relations for
Schur functions. As an application, we investigate algebraic relations for
"diagonally constant" Schur multiple zeta functions and examine their specific
special values when the shape is rectangular.

</details>


### [39] [The Subgraphs of Order Six of the Family of Strongly Regular Graphs with Parameters $λ=1$ and $μ=2$](https://arxiv.org/abs/2508.03377)
*Reimbay Reimbayev*

Main category: math.CO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Strongly regular graphs are highly symmetrical and can be described fully
with just a few parameters yet the existence of many of them is still under the
question. Due to this uncertainty, it is of immense interest to study their
structure, in particular to obtain all the possible subgraphs of lower order.
In this paper we study the family of strongly regular graphs with parameters
$\lambda =1$ and $\mu =2$ and establish all their subgraphs of order six.

</details>


### [40] [Barnette Graphs with Faces up to Size 8 are Hamiltonian](https://arxiv.org/abs/2508.03531)
*Tobias Schnieders*

Main category: math.CO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Barnette's conjecture states that every cubic, bipartite, planar and
3-connected graph is Hamiltonian. Goodey verified Barnette's conjecture for all
graphs with faces of size up to 6.
  We substantially strengthen Goodey's result by proving Hamiltonicity for
cubic, bipartite, planar and (2-)connected graphs with faces of size up to 8.
Parts of the proof are computational, including a distinction of 339.068.624
cases.

</details>


### [41] [Computing plethysms via derivations](https://arxiv.org/abs/2508.03568)
*Alessandro D'Andrea,Enrico Fatighenti,Claudio Onorati*

Main category: math.CO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We consider a derivation D on the ring ${\Lambda}$ of symmetric functions and
investigate its combinatorial, algebraic and geometric properties. More
precisely, we show that D restricts to a quasi-isometry, with respect to the
Hall product, on the graded component of ${\Lambda}$ of each positive degree
and provide a chain-rule formula with respect to the plethysm operation.
Furthermore, we relate the geometric shape of D(f), where f $\in {\Lambda}$ is
an homogeneous symmetric function, to that of f. An application to the shape of
the partitions appearing in a given plethysms is proved.

</details>


### [42] [Cyclic subsets of tournaments](https://arxiv.org/abs/2508.03634)
*Zach Hunter,Teng Liu,Aleksa Milojević,Benny Sudakov*

Main category: math.CO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Let $G$ be a Dirac graph, and let $S$ be a vertex subset of $G$, chosen
uniformly at random. How likely is the induced subgraph $G[S]$ to be
Hamiltonian? This question, proposed by Erd\H{o}s and Faudree in 1996, was
recently resolved by Dragani\'c, Keevash and M\"uyesser, in the setting of
graphs. In this paper, we study a similar question for tournaments -- if $T$ is
a tournament of high minimum degree, how likely is it for a random induced
subtournament of $T$ to be Hamiltonian? We prove an optimal bound on this
probability, and extend the results to the regime where the subset is not
sampled uniformly at random, but according to a $p$-biased measure.

</details>


<div id='q-fin.MF'></div>

# q-fin.MF [[Back]](#toc)

### [43] [Modeling Loss-Versus-Rebalancing in Automated Market Makers via Continuous-Installment Options](https://arxiv.org/abs/2508.02971)
*Srisht Fateh Singh,Reina Ke Xin Li,Samuel Gaskin,Yuntao Wu,Jeffrey Klinck,Panagiotis Michalopoulos,Zissis Poulos,Andreas Veneris*

Main category: q-fin.MF

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: This paper mathematically models a constant-function automated market maker
(CFAMM) position as a portfolio of exotic options, known as perpetual American
continuous-installment (CI) options. This model replicates an AMM position's
delta at each point in time over an infinite time horizon, thus taking into
account the perpetual nature and optionality to withdraw of liquidity
provision. This framework yields two key theoretical results: (a) It proves
that the AMM's adverse-selection cost, loss-versus-rebalancing (LVR), is
analytically identical to the continuous funding fees (the time value decay or
theta) earned by the at-the-money CI option embedded in the replicating
portfolio. (b) A special case of this model derives an AMM liquidity position's
delta profile and boundaries that suffer approximately constant LVR, up to a
bounded residual error, over an arbitrarily long forward window. Finally, the
paper describes how the constant volatility parameter required by the perpetual
option can be calibrated from the term structure of implied volatilities and
estimates the errors for both implied volatility calibration and LVR residual
error. Thus, this work provides a practical framework enabling liquidity
providers to choose an AMM liquidity profile and price boundaries for an
arbitrarily long, forward-looking time window where they can expect an
approximately constant, price-independent LVR. The results establish a rigorous
option-theoretic interpretation of AMMs and their LVR, and provide actionable
guidance for liquidity providers in estimating future adverse-selection costs
and optimizing position parameters.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [44] [Real-World Evaluation of Protocol-Compliant Denial-of-Service Attacks on C-V2X-based Forward Collision Warning Systems](https://arxiv.org/abs/2508.02805)
*Jean Michel Tine,Mohammed Aldeen,Abyad Enan,M Sabbir Salek,Long Cheng,Mashrur Chowdhury*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Cellular Vehicle-to-Everything (C-V2X) technology enables low-latency,
reliable communications essential for safety applications such as a Forward
Collision Warning (FCW) system. C-V2X deployments operate under strict protocol
compliance with the 3rd Generation Partnership Project (3GPP) and the Society
of Automotive Engineers Standard (SAE) J2735 specifications to ensure
interoperability. This paper presents a real-world testbed evaluation of
protocol-compliant Denial-of-Service (DoS) attacks using User Datagram Protocol
(UDP) flooding and oversized Basic Safety Message (BSM) attacks that 7 exploit
transport- and application-layer vulnerabilities in C-V2X. The attacks
presented in this study transmit valid messages over standard PC5 sidelinks,
fully adhering to 3GPP and SAE J2735 specifications, but at abnormally high
rates and with oversized payloads that overload the receiver resources without
breaching any protocol rules such as IEEE 1609. Using a real-world connected
vehicle 11 testbed with commercially available On-Board Units (OBUs), we
demonstrate that high-rate UDP flooding and oversized payload of BSM flooding
can severely degrade FCW performance. Results show that UDP flooding alone
reduces packet delivery ratio by up to 87% and increases latency to over 400ms,
while oversized BSM floods overload receiver processing resources, delaying or
completely suppressing FCW alerts. When UDP and BSM attacks are executed
simultaneously, they cause near-total communication failure, preventing FCW
warnings entirely. These findings reveal that protocol-compliant communications
do not necessarily guarantee safe or reliable operation of C-V2X-based safety
applications.

</details>


### [45] [Thermal-Aware 3D Design for Side-Channel Information Leakage](https://arxiv.org/abs/2508.02816)
*Dylan Stow,Russell Barnes,Eren Kurshan,Yuan Xie*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Side-channel attacks are important security challenges as they reveal
sensitive information about on-chip activities. Among such attacks, the thermal
side-channel has been shown to disclose the activities of key functional blocks
and even encryption keys. This paper proposes a novel approach to proactively
conceal critical activities in the functional layers while minimizing the power
dissipation by (i) leveraging inherent characteristics of 3D integration to
protect from side-channel attacks and (ii) dynamically generating custom
activity patterns to match the activity to be concealed in the functional
layers. Experimental analysis shows that 3D technology combined with the
proposed run-time algorithm effectively reduces the Side channel vulnerability
Factor (SVF) below 0.05 and the Spatial Thermal Side-channel Factor (STSF)
below 0.59.

</details>


### [46] [Agentic Privacy-Preserving Machine Learning](https://arxiv.org/abs/2508.02836)
*Mengyu Zhang,Zhuotao Liu,Jingwen Huang,Xuanqi Liu*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Privacy-preserving machine learning (PPML) is critical to ensure data privacy
in AI. Over the past few years, the community has proposed a wide range of
provably secure PPML schemes that rely on various cryptography primitives.
However, when it comes to large language models (LLMs) with billions of
parameters, the efficiency of PPML is everything but acceptable. For instance,
the state-of-the-art solution for confidential LLM inference represents at
least 10,000-fold slower performance compared to plaintext inference. The
performance gap is even larger when the context length increases. In this
position paper, we propose a novel framework named Agentic-PPML to make PPML in
LLMs practical. Our key insight is to employ a general-purpose LLM for intent
understanding and delegate cryptographically secure inference to specialized
models trained on vertical domains. By modularly separating language intent
parsing - which typically involves little or no sensitive information - from
privacy-critical computation, Agentic-PPML completely eliminates the need for
the LLMs to process the encrypted prompts, enabling practical deployment of
privacy-preserving LLM-centric services.

</details>


### [47] [LMDG: Advancing Lateral Movement Detection Through High-Fidelity Dataset Generation](https://arxiv.org/abs/2508.02942)
*Anas Mabrouk,Mohamed Hatem,Mohammad Mamun,Sherif Saad*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Lateral Movement (LM) attacks continue to pose a significant threat to
enterprise security, enabling adversaries to stealthily compromise critical
assets. However, the development and evaluation of LM detection systems are
impeded by the absence of realistic, well-labeled datasets. To address this
gap, we propose LMDG, a reproducible and extensible framework for generating
high-fidelity LM datasets. LMDG automates benign activity generation,
multi-stage attack execution, and comprehensive labeling of system and network
logs, dramatically reducing manual effort and enabling scalable dataset
creation. A central contribution of LMDG is Process Tree Labeling, a novel
agent-based technique that traces all malicious activity back to its origin
with high precision. Unlike prior methods such as Injection Timing or
Behavioral Profiling, Process Tree Labeling enables accurate, step-wise
labeling of malicious log entries, correlating each with a specific attack step
and MITRE ATT\&CK TTPs. To our knowledge, this is the first approach to support
fine-grained labeling of multi-step attacks, providing critical context for
detection models such as attack path reconstruction. We used LMDG to generate a
25-day dataset within a 25-VM enterprise environment containing 22 user
accounts. The dataset includes 944 GB of host and network logs and embeds 35
multi-stage LM attacks, with malicious events comprising less than 1% of total
activity, reflecting a realistic benign-to-malicious ratio for evaluating
detection systems. LMDG-generated datasets improve upon existing ones by
offering diverse LM attacks, up-to-date attack patterns, longer attack
timeframes, comprehensive data sources, realistic network architectures, and
more accurate labeling.

</details>


### [48] [A Non-leveled and Reliable Approximate FHE Framework through Binarized Polynomial Rings](https://arxiv.org/abs/2508.02943)
*Baigang Chen,Dongfang Zhao*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Homomorphic encryption (HE) enables secure computation on encrypted data,
safeguarding user privacy in domains such as cloud computing, healthcare, and
finance. Among fully homomorphic encryption (FHE) schemes, CKKS is notable for
supporting approximate arithmetic over complex numbers, a key requirement for
machine-learning and numerical workloads. However, CKKS incurs rapid noise
growth, complex parameter tuning, and relies on costly modulus switching. We
propose a binary variant of CKKS that operates entirely over binary-coefficient
polynomial rings and replaces rescaling with a lightweight bootstrapping
mechanism. To mitigate additional bit-flip errors introduced by binary
encoding, we integrate BCH error-correcting codes for robust decryption. Our
open-source implementation, built on the HElib library, preserves the core
algebraic structure of CKKS while introducing binary-coefficient encoding,
enabling efficient evaluation in small ring dimensions and unbounded-depth
computation. Empirical evaluations demonstrate the framework's practicality and
scalability across a range of settings.

</details>


### [49] [Lightweight Fault Detection Architecture for NTT on FPGA](https://arxiv.org/abs/2508.03062)
*Rourab Paul,Paresh Baidya,Krishnendu Guha*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Post-Quantum Cryptographic (PQC) algorithms are mathematically secure and
resistant to quantum attacks but can still leak sensitive information in
hardware implementations due to natural faults or intentional fault injections.
The intent fault injection in side-channel attacks reduces the reliability of
crypto implementation in future generation network security procesors. In this
regard, this research proposes a lightweight, efficient, recomputation-based
fault detection module implemented on a Field Programmable Gate Array (FPGA)
for Number Theoretic Transform (NTT). The NTT is primarily composed of memory
units and the Cooley-Tukey Butterfly Unit (CT-BU), a critical and
computationally intensive hardware component essential for polynomial
multiplication. NTT and polynomial multiplication are fundamental building
blocks in many PQC algorithms, including Kyber, NTRU, Ring-LWE, and others. In
this paper, we present a fault detection method called : Recomputation with a
Modular Offset (REMO) for the logic blocks of the CT-BU using Montgomery
Reduction and another method called Memory Rule Checkers for the memory
components used within the NTT. The proposed fault detection framework sets a
new benchmark by achieving high efficiency with significant low implementation
cost. It occupies only 16 slices and a single DSP block, with a power
consumption of just 3mW in Artix-7 FPGA. The REMO-based detection mechanism
achieves a fault coverage of 87.2% to 100%, adaptable across various word
sizes, fault bit counts, and fault injection modes. Similarly, the Memory Rule
Checkers demonstrate robust performance, achieving 50.7% to 100% fault
detection depending on and the nature of injected faults.

</details>


### [50] [Untraceable DeepFakes via Traceable Fingerprint Elimination](https://arxiv.org/abs/2508.03067)
*Jiewei Lai,Lan Zhang,Chen Tang,Pengcheng Sun,Xinming Wang,Yunhao Wang*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Recent advancements in DeepFakes attribution technologies have significantly
enhanced forensic capabilities, enabling the extraction of traces left by
generative models (GMs) in images, making DeepFakes traceable back to their
source GMs. Meanwhile, several attacks have attempted to evade attribution
models (AMs) for exploring their limitations, calling for more robust AMs.
However, existing attacks fail to eliminate GMs' traces, thus can be mitigated
by defensive measures. In this paper, we identify that untraceable DeepFakes
can be achieved through a multiplicative attack, which can fundamentally
eliminate GMs' traces, thereby evading AMs even enhanced with defensive
measures. We design a universal and black-box attack method that trains an
adversarial model solely using real data, applicable for various GMs and
agnostic to AMs. Experimental results demonstrate the outstanding attack
capability and universal applicability of our method, achieving an average
attack success rate (ASR) of 97.08\% against 6 advanced AMs on DeepFakes
generated by 9 GMs. Even in the presence of defensive mechanisms, our method
maintains an ASR exceeding 72.39\%. Our work underscores the potential
challenges posed by multiplicative attacks and highlights the need for more
robust AMs.

</details>


### [51] [VFLAIR-LLM: A Comprehensive Framework and Benchmark for Split Learning of LLMs](https://arxiv.org/abs/2508.03097)
*Zixuan Gu,Qiufeng Fan,Long Sun,Yang Liu,Xiaojun Ye*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: With the advancement of Large Language Models (LLMs), LLM applications have
expanded into a growing number of fields. However, users with data privacy
concerns face limitations in directly utilizing LLM APIs, while private
deployments incur significant computational demands. This creates a substantial
challenge in achieving secure LLM adaptation under constrained local resources.
To address this issue, collaborative learning methods, such as Split Learning
(SL), offer a resource-efficient and privacy-preserving solution for adapting
LLMs to private domains. In this study, we introduce VFLAIR-LLM (available at
https://github.com/FLAIR-THU/VFLAIR-LLM), an extensible and lightweight split
learning framework for LLMs, enabling privacy-preserving LLM inference and
fine-tuning in resource-constrained environments. Our library provides two LLM
partition settings, supporting three task types and 18 datasets. In addition,
we provide standard modules for implementing and evaluating attacks and
defenses. We benchmark 5 attacks and 9 defenses under various Split Learning
for LLM(SL-LLM) settings, offering concrete insights and recommendations on the
choice of model partition configurations, defense strategies, and relevant
hyperparameters for real-world applications.

</details>


### [52] [Attack the Messages, Not the Agents: A Multi-round Adaptive Stealthy Tampering Framework for LLM-MAS](https://arxiv.org/abs/2508.03125)
*Bingyu Yan,Ziyi Zhou,Xiaoming Zhang,Chaozhuo Li,Ruilin Zeng,Yirui Qi,Tianbo Wang,Litian Zhang*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Large language model-based multi-agent systems (LLM-MAS) effectively
accomplish complex and dynamic tasks through inter-agent communication, but
this reliance introduces substantial safety vulnerabilities. Existing attack
methods targeting LLM-MAS either compromise agent internals or rely on direct
and overt persuasion, which limit their effectiveness, adaptability, and
stealthiness. In this paper, we propose MAST, a Multi-round Adaptive Stealthy
Tampering framework designed to exploit communication vulnerabilities within
the system. MAST integrates Monte Carlo Tree Search with Direct Preference
Optimization to train an attack policy model that adaptively generates
effective multi-round tampering strategies. Furthermore, to preserve
stealthiness, we impose dual semantic and embedding similarity constraints
during the tampering process. Comprehensive experiments across diverse tasks,
communication architectures, and LLMs demonstrate that MAST consistently
achieves high attack success rates while significantly enhancing stealthiness
compared to baselines. These findings highlight the effectiveness,
stealthiness, and adaptability of MAST, underscoring the need for robust
communication safeguards in LLM-MAS.

</details>


### [53] [Protecting Small Organizations from AI Bots with Logrip: Hierarchical IP Hashing](https://arxiv.org/abs/2508.03130)
*Rama Carl Hoetzlein*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Small organizations, start ups, and self-hosted servers face increasing
strain from automated web crawlers and AI bots, whose online presence has
increased dramatically in the past few years. Modern bots evade traditional
throttling and can degrade server performance through sheer volume even when
they are well-behaved. We introduce a novel security approach that leverages
data visualization and hierarchical IP hashing to analyze server event logs,
distinguishing human users from automated entities based on access patterns. By
aggregating IP activity across subnet classes and applying statistical
measures, our method detects coordinated bot activity and distributed crawling
attacks that conventional tools fail to identify. Using a real world example we
estimate that 80 to 95 percent of traffic originates from AI crawlers,
underscoring the need for improved filtering mechanisms. Our approach enables
small organizations to regulate automated traffic effectively, preserving
public access while mitigating performance degradation.

</details>


### [54] [WiFinger: Fingerprinting Noisy IoT Event Traffic Using Packet-level Sequence Matching](https://arxiv.org/abs/2508.03151)
*Ronghua Li,Shinan Liu,Haibo Hu,Qingqing Ye,Nick Feamster*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: IoT environments such as smart homes are susceptible to privacy inference
attacks, where attackers can analyze patterns of encrypted network traffic to
infer the state of devices and even the activities of people. While most
existing attacks exploit ML techniques for discovering such traffic patterns,
they underperform on wireless traffic, especially Wi-Fi, due to its heavy noise
and packet losses of wireless sniffing. In addition, these approaches commonly
target at distinguishing chunked IoT event traffic samples, and they failed at
effectively tracking multiple events simultaneously. In this work, we propose
WiFinger, a fine-grained multi-IoT event fingerprinting approach against noisy
traffic. WiFinger turns the traffic pattern classification task into a
subsequence matching problem and introduces novel techniques to account for the
high time complexity while maintaining high accuracy. Experiments demonstrate
that our method outperforms existing approaches on Wi-Fi traffic, achieving an
average recall of 85% (vs. 0.49% and 0.46%) for various IoT events while
maintaining almost zero false positives for most of them.

</details>


### [55] [BadBlocks: Low-Cost and Stealthy Backdoor Attacks Tailored for Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.03221)
*Yu Pan,Jiahao Chen,Lin Wang,Bingrong Dai,Yi Du*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: In recent years,Diffusion models have achieved remarkable progress in the
field of image generation.However,recent studies have shown that diffusion
models are susceptible to backdoor attacks,in which attackers can manipulate
the output by injecting covert triggers such as specific visual patterns or
textual phrases into the training dataset.Fortunately,with the continuous
advancement of defense techniques,defenders have become increasingly capable of
identifying and mitigating most backdoor attacks using visual inspection and
neural network-based detection methods.However,in this paper,we identify a
novel type of backdoor threat that is more lightweight and covert than existing
approaches,which we name BadBlocks,requires only about 30\% of the
computational resources and 20\% GPU time typically needed by previous backdoor
attacks,yet it successfully injects backdoors and evades the most advanced
defense frameworks.BadBlocks enables attackers to selectively contaminate
specific blocks within the UNet architecture of diffusion models while
maintaining normal functionality in the remaining components.Experimental
results demonstrate that BadBlocks achieves a high attack success rate (ASR)
and low perceptual quality loss (as measured by FID Score),even under extremely
constrained computational resources and GPU time.Moreover,BadBlocks is able to
bypass existing defense frameworks,especially the attention-based backdoor
detection method, highlighting it as a novel and noteworthy threat.Ablation
studies further demonstrate that effective backdoor injection does not require
fine-tuning the entire network and highlight the pivotal role of certain neural
network layers in backdoor mapping.Overall,BadBlocks significantly reduces the
barrier to conducting backdoor attacks in all aspects.It enables attackers to
inject backdoors into large-scale diffusion models even using consumer-grade
GPUs.

</details>


### [56] [BDFirewall: Towards Effective and Expeditiously Black-Box Backdoor Defense in MLaaS](https://arxiv.org/abs/2508.03307)
*Ye Li,Chengcheng Zhu,Yanchao Zhao,Jiale Zhang*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: In this paper, we endeavor to address the challenges of backdoor attacks
countermeasures in black-box scenarios, thereby fortifying the security of
inference under MLaaS. We first categorize backdoor triggers from a new
perspective, i.e., their impact on the patched area, and divide them into:
high-visibility triggers (HVT), semi-visibility triggers (SVT), and
low-visibility triggers (LVT). Based on this classification, we propose a
progressive defense framework, BDFirewall, that removes these triggers from the
most conspicuous to the most subtle, without requiring model access. First, for
HVTs, which create the most significant local semantic distortions, we identify
and eliminate them by detecting these salient differences. We then restore the
patched area to mitigate the adverse impact of such removal process. The
localized purification designed for HVTs is, however, ineffective against SVTs,
which globally perturb benign features. We therefore model an SVT-poisoned
input as a mixture of a trigger and benign features, where we unconventionally
treat the benign features as "noise". This formulation allows us to reconstruct
SVTs by applying a denoising process that removes these benign "noise"
features. The SVT-free input is then obtained by subtracting the reconstructed
trigger. Finally, to neutralize the nearly imperceptible but fragile LVTs, we
introduce lightweight noise to disrupt the trigger pattern and then apply DDPM
to restore any collateral impact on clean features. Comprehensive experiments
demonstrate that our method outperforms state-of-the-art defenses. Compared
with baselines, BDFirewall reduces the Attack Success Rate (ASR) by an average
of 33.25%, improving poisoned sample accuracy (PA) by 29.64%, and achieving up
to a 111x speedup in inference time. Code will be made publicly available upon
acceptance.

</details>


### [57] [From Legacy to Standard: LLM-Assisted Transformation of Cybersecurity Playbooks into CACAO Format](https://arxiv.org/abs/2508.03342)
*Mehdi Akbari Gurabi,Lasse Nitz,Radu-Mihai Castravet,Roman Matzutt,Avikarsha Mandal,Stefan Decker*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Existing cybersecurity playbooks are often written in heterogeneous,
non-machine-readable formats, which limits their automation and
interoperability across Security Orchestration, Automation, and Response
platforms. This paper explores the suitability of Large Language Models,
combined with Prompt Engineering, to automatically translate legacy incident
response playbooks into the standardized, machine-readable CACAO format. We
systematically examine various Prompt Engineering techniques and carefully
design prompts aimed at maximizing syntactic accuracy and semantic fidelity for
control flow preservation. Our modular transformation pipeline integrates a
syntax checker to ensure syntactic correctness and features an iterative
refinement mechanism that progressively reduces syntactic errors. We evaluate
the proposed approach on a custom-generated dataset comprising diverse legacy
playbooks paired with manually created CACAO references. The results
demonstrate that our method significantly improves the accuracy of playbook
transformation over baseline models, effectively captures complex workflow
structures, and substantially reduces errors. It highlights the potential for
practical deployment in automated cybersecurity playbook transformation tasks.

</details>


### [58] [Smart Car Privacy: Survey of Attacks and Privacy Issues](https://arxiv.org/abs/2508.03413)
*Akshay Madhav Deshmukh*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Automobiles are becoming increasingly important in our day to day life.
Modern automobiles are highly computerized and hence potentially vulnerable to
attack. Providing many wireless connectivity for vehicles enables a bridge
between vehicles and their external environments. Such a connected vehicle
solution is expected to be the next frontier for automotive revolution and the
key to the evolution to next generation intelligent transportation systems.
Vehicular Ad hoc Networks (VANETs) are emerging mobile ad hoc network
technologies incorporating mobile routing protocols for inter-vehicle data
communications to support intelligent transportation systems. Thus security and
privacy are the major concerns in VANETs due to the mobility of the vehicles.
Thus designing security mechanisms to remove adversaries from the network
remarkably important in VANETs.
  This paper provides an overview of various vehicular network architectures.
The evolution of security in modern vehicles. Various security and privacy
attacks in VANETs with their defending mechanisms with examples and classify
these mechanisms. It also provides an overview of various privacy implication
that a vehicular network possess.

</details>


### [59] [Unravelling the Probabilistic Forest: Arbitrage in Prediction Markets](https://arxiv.org/abs/2508.03474)
*Oriol Saguillo,Vahid Ghafouri,Lucianna Kiffer,Guillermo Suarez-Tangil*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Polymarket is a prediction market platform where users can speculate on
future events by trading shares tied to specific outcomes, known as conditions.
Each market is associated with a set of one or more such conditions. To ensure
proper market resolution, the condition set must be exhaustive -- collectively
accounting for all possible outcomes -- and mutually exclusive -- only one
condition may resolve as true. Thus, the collective prices of all related
outcomes should be \$1, representing a combined probability of 1 of any
outcome. Despite this design, Polymarket exhibits cases where dependent assets
are mispriced, allowing for purchasing (or selling) a certain outcome for less
than (or more than) \$1, guaranteeing profit. This phenomenon, known as
arbitrage, could enable sophisticated participants to exploit such
inconsistencies.
  In this paper, we conduct an empirical arbitrage analysis on Polymarket data
to answer three key questions: (Q1) What conditions give rise to arbitrage (Q2)
Does arbitrage actually occur on Polymarket and (Q3) Has anyone exploited these
opportunities. A major challenge in analyzing arbitrage between related markets
lies in the scalability of comparisons across a large number of markets and
conditions, with a naive analysis requiring $O(2^{n+m})$ comparisons. To
overcome this, we employ a heuristic-driven reduction strategy based on
timeliness, topical similarity, and combinatorial relationships, further
validated by expert input.
  Our study reveals two distinct forms of arbitrage on Polymarket: Market
Rebalancing Arbitrage, which occurs within a single market or condition, and
Combinatorial Arbitrage, which spans across multiple markets. We use on-chain
historical order book data to analyze when these types of arbitrage
opportunities have existed, and when they have been executed by users. We find
a realized estimate of 40 million USD of profit extracted.

</details>


### [60] [Intrusion Detection in Heterogeneous Networks with Domain-Adaptive Multi-Modal Learning](https://arxiv.org/abs/2508.03517)
*Mabin Umman Varghese,Zahra Taghiyarrenani*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Network Intrusion Detection Systems (NIDS) play a crucial role in
safeguarding network infrastructure against cyberattacks. As the prevalence and
sophistication of these attacks increase, machine learning and deep neural
network approaches have emerged as effective tools for enhancing NIDS
capabilities in detecting malicious activities. However, the effectiveness of
traditional deep neural models is often limited by the need for extensive
labelled datasets and the challenges posed by data and feature heterogeneity
across different network domains. To address these limitations, we developed a
deep neural model that integrates multi-modal learning with domain adaptation
techniques for classification. Our model processes data from diverse sources in
a sequential cyclic manner, allowing it to learn from multiple datasets and
adapt to varying feature spaces. Experimental results demonstrate that our
proposed model significantly outperforms baseline neural models in classifying
network intrusions, particularly under conditions of varying sample
availability and probability distributions. The model's performance highlights
its ability to generalize across heterogeneous datasets, making it an efficient
solution for real-world network intrusion detection.

</details>


### [61] [MalFlows: Context-aware Fusion of Heterogeneous Flow Semantics for Android Malware Detection](https://arxiv.org/abs/2508.03588)
*Zhaoyi Meng,Fenglei Xu,Wenxiang Zhao,Wansen Wang,Wenchao Huang,Jie Cui,Hong Zhong,Yan Xiong*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Static analysis, a fundamental technique in Android app examination, enables
the extraction of control flows, data flows, and inter-component communications
(ICCs), all of which are essential for malware detection. However, existing
methods struggle to leverage the semantic complementarity across different
types of flows for representing program behaviors, and their context-unaware
nature further hinders the accuracy of cross-flow semantic integration. We
propose and implement MalFlows, a novel technique that achieves context-aware
fusion of heterogeneous flow semantics for Android malware detection. Our goal
is to leverage complementary strengths of the three types of flow-related
information for precise app profiling. We adopt a heterogeneous information
network (HIN) to model the rich semantics across these program flows. We
further propose flow2vec, a context-aware HIN embedding technique that
distinguishes the semantics of HIN entities as needed based on contextual
constraints across different flows and learns accurate app representations
through the joint use of multiple meta-paths. The representations are finally
fed into a channel-attention-based deep neural network for malware
classification. To the best of our knowledge, this is the first study to
comprehensively aggregate the strengths of diverse flow-related information for
assessing maliciousness within apps. We evaluate MalFlows on a large-scale
dataset comprising over 20 million flow instances extracted from more than
31,000 real-world apps. Experimental results demonstrate that MalFlows
outperforms representative baselines in Android malware detection, and
meanwhile, validate the effectiveness of flow2vec in accurately learning app
representations from the HIN constructed over the heterogeneous flows.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [62] [Efficient Agents: Building Effective Agents While Reducing Cost](https://arxiv.org/abs/2508.02694)
*Ningning Wang,Xavier Hu,Pai Liu,He Zhu,Yue Hou,Heyuan Huang,Shengyu Zhang,Jian Yang,Jiaheng Liu,Ge Zhang,Changwang Zhang,Jun Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: The remarkable capabilities of Large Language Model (LLM)-driven agents have
enabled sophisticated systems to tackle complex, multi-step tasks, but their
escalating costs threaten scalability and accessibility. This work presents the
first systematic study of the efficiency-effectiveness trade-off in modern
agent systems, addressing the critical need for cost-effective designs without
sacrificing performance. We investigate three key questions: (1) How much
complexity do agentic tasks inherently require? (2) When do additional modules
yield diminishing returns? (3) How much efficiency can be gained through the
design of efficient agent frameworks? Through an empirical analysis on the GAIA
benchmark, we evaluate the impact of LLM backbone selection, agent framework
designs, and test-time scaling strategies. Using the cost-of-pass metric, we
quantify the efficiency-performance trade-off across these dimensions. Our
findings inform the development of Efficient Agents , a novel agent framework
that has an optimal complexity to task requirements. Efficient Agents retains
96.7% of the performance of OWL, one leading open-source agent framework, while
reducing operational costs from $0.398 to $0.228, resulting in a 28.4%
improvement in cost-of-pass. Our work provides actionable insights for
designing efficient, high-performing agent systems, advancing the accessibility
and sustainability of AI-driven solutions.

</details>


### [63] [Planning with Dynamically Changing Domains](https://arxiv.org/abs/2508.02697)
*Mikhail Soutchanski,Yongmei Liu*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: In classical planning and conformant planning, it is assumed that there are
finitely many named objects given in advance, and only they can participate in
actions and in fluents. This is the Domain Closure Assumption (DCA). However,
there are practical planning problems where the set of objects changes
dynamically as actions are performed; e.g., new objects can be created, old
objects can be destroyed. We formulate the planning problem in first-order
logic, assume an initial theory is a finite consistent set of fluent literals,
discuss when this guarantees that in every situation there are only finitely
many possible actions, impose a finite integer bound on the length of the plan,
and propose to organize search over sequences of actions that are grounded at
planning time. We show the soundness and completeness of our approach. It can
be used to solve the bounded planning problems without DCA that belong to the
intersection of sequential generalized planning (without sensing actions) and
conformant planning, restricted to the case without the disjunction over fluent
literals. We discuss a proof-of-the-concept implementation of our planner.

</details>


### [64] [Recovering Individual-Level Activity Sequences from Location-Based Service Data Using a Novel Transformer-Based Model](https://arxiv.org/abs/2508.02734)
*Weiyu Luo,Chenfeng Xiong*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Location-Based Service (LBS) data provides critical insights into human
mobility, yet its sparsity often yields incomplete trip and activity sequences,
making accurate inferences about trips and activities difficult. We raise a
research problem: Can we use activity sequences derived from high-quality LBS
data to recover incomplete activity sequences at the individual level? This
study proposes a new solution, the Variable Selection Network-fused Insertion
Transformer (VSNIT), integrating the Insertion Transformer's flexible sequence
construction with the Variable Selection Network's dynamic covariate handling
capability, to recover missing segments in incomplete activity sequences while
preserving existing data. The findings show that VSNIT inserts more diverse,
realistic activity patterns, more closely matching real-world variability, and
restores disrupted activity transitions more effectively aligning with the
target. It also performs significantly better than the baseline model across
all metrics. These results highlight VSNIT's superior accuracy and diversity in
activity sequence recovery tasks, demonstrating its potential to enhance LBS
data utility for mobility analysis. This approach offers a promising framework
for future location-based research and applications.

</details>


### [65] [Large Language Model-based Data Science Agent: A Survey](https://arxiv.org/abs/2508.02744)
*Peiran Wang,Yaoning Yu,Ke Chen,Xianyang Zhan,Haohan Wang*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: The rapid advancement of Large Language Models (LLMs) has driven novel
applications across diverse domains, with LLM-based agents emerging as a
crucial area of exploration. This survey presents a comprehensive analysis of
LLM-based agents designed for data science tasks, summarizing insights from
recent studies. From the agent perspective, we discuss the key design
principles, covering agent roles, execution, knowledge, and reflection methods.
From the data science perspective, we identify key processes for LLM-based
agents, including data preprocessing, model development, evaluation,
visualization, etc. Our work offers two key contributions: (1) a comprehensive
review of recent developments in applying LLMbased agents to data science
tasks; (2) a dual-perspective framework that connects general agent design
principles with the practical workflows in data science.

</details>


### [66] [Cognitive Loop via In-Situ Optimization: Self-Adaptive Reasoning for Science](https://arxiv.org/abs/2508.02789)
*Newman Cheng,Gordon Broadbent,William Chappell*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: The capacity for artificial intelligence (AI) to formulate, evolve, and test
altered thought patterns under dynamic conditions indicates advanced cognition
that is crucial for scientific discovery. The existing AI development landscape
falls into two categories: 1) frameworks over non-reasoning models that
natively incorporate opinions on how humans think, and 2) reasoning models that
abstract precise control of the reasoning intuition away from end users. While
powerful, for scientists to maximize utility of AI in scientific discovery,
they not only require accuracy and transparency in reasoning, but also
steerability. Hence, we introduce an alternative approach that enables deep and
precise control over the reasoning process called: a cognitive loop via in-situ
optimization (CLIO). CLIO enables large language models (LLMs) to
self-formulate ways of approaching a problem, adapt behavior when
self-confidence is low, and ultimately provide scientists with a final belief
or answer. Through CLIO's open design, scientists can observe uncertainty
levels, understand how final belief states are formulated using graph
structures, and interject corrections. Without any further post-training,
OpenAI's GPT-4.1 with CLIO yields an accuracy of 22.37\% in text-based biology
and medicine questions on Humanity's Last Exam (HLE). This yields a 13.82\% net
or 161.64\% relative increase when compared to the base GPT-4.1 model and
surpasses OpenAI's o3 performance in high and low reasoning effort modes. We
further discovered that oscillations within internal uncertainty measures are
key in determining the accuracy of CLIO's results, revealing how its open
design and internal mechanisms can provide insight and control into scientific
decision-making processes.

</details>


### [67] [A Multi-Agent System for Complex Reasoning in Radiology Visual Question Answering](https://arxiv.org/abs/2508.02841)
*Ziruo Yi,Jinyu Liu,Ting Xiao,Mark V. Albert*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Radiology visual question answering (RVQA) provides precise answers to
questions about chest X-ray images, alleviating radiologists' workload. While
recent methods based on multimodal large language models (MLLMs) and
retrieval-augmented generation (RAG) have shown promising progress in RVQA,
they still face challenges in factual accuracy, hallucinations, and cross-modal
misalignment. We introduce a multi-agent system (MAS) designed to support
complex reasoning in RVQA, with specialized agents for context understanding,
multimodal reasoning, and answer validation. We evaluate our system on a
challenging RVQA set curated via model disagreement filtering, comprising
consistently hard cases across multiple MLLMs. Extensive experiments
demonstrate the superiority and effectiveness of our system over strong MLLM
baselines, with a case study illustrating its reliability and interpretability.
This work highlights the potential of multi-agent approaches to support
explainable and trustworthy clinical AI applications that require complex
reasoning.

</details>


### [68] [Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game](https://arxiv.org/abs/2508.02900)
*Michael Katz,Harsha Kokel,Sarath Sreedharan*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: There is a broad consensus that the inability to form long-term plans is one
of the key limitations of current foundational models and agents. However, the
existing planning benchmarks remain woefully inadequate to truly measure their
planning capabilities. Most existing benchmarks either focus on loosely defined
tasks like travel planning or end up leveraging existing domains and problems
from international planning competitions. While the former tasks are hard to
formalize and verify, the latter were specifically designed to test and
challenge the weaknesses of existing automated planners. To address these
shortcomings, we propose a procedure for creating a planning benchmark centered
around the game called Countdown, where a player is expected to form a target
number from a list of input numbers through arithmetic operations. We discuss
how this problem meets many of the desiderata associated with an ideal
benchmark for planning capabilities evaluation. Specifically, the domain allows
for an intuitive, natural language description for each problem instance, it is
computationally challenging (NP-complete), and the instance space is rich
enough that we do not have to worry about memorization. We perform an extensive
theoretical analysis, establishing the computational complexity result and
demonstrate the advantage of our instance generation procedure over public
benchmarks. We evaluate a variety of existing LLM-assisted planning methods on
instances generated using our procedure. Our results show that, unlike other
domains like 24 Game (a special case of Countdown), our proposed dynamic
benchmark remains extremely challenging for existing LLM-based approaches.

</details>


### [69] [Enhancing Japanese Large Language Models with Reasoning Vectors](https://arxiv.org/abs/2508.02913)
*Carolina Minami Oguchi,Leo Wei,Koyo Kobayashi,Hsin-Tai Wu,Dipak Ghosal*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Post-training methods have improved the performance and enhanced the
reasoning capability for mainstream large language models (LLMs), but the same
is challenging for Japanese LLMs to achieve due to the amount of resources
required. Inspired by task vectors that extract the change of weights before
and after training, specifically for a certain task, we obtain reasoning
vectors from reasoning LLMs and apply them to Japanese LLMs to boost their
performance. While the resources available present a challenge to improve
Japanese LLMs, we present a simple and effective way to obtain high improvement
and hope to inspire for other languages.

</details>


### [70] [PentestJudge: Judging Agent Behavior Against Operational Requirements](https://arxiv.org/abs/2508.02921)
*Shane Caldwell,Max Harley,Michael Kouremetis,Vincent Abruzzo,Will Pearce*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We introduce PentestJudge, a system for evaluating the operations of
penetration testing agents. PentestJudge is a large language model
(LLM)-as-judge with access to tools that allow it to consume arbitrary
trajectories of agent states and tool call history to determine whether a
security agent's actions meet certain operating criteria that would be
impractical to evaluate programmatically. We develop rubrics that use a tree
structure to hierarchically collapse the penetration testing task for a
particular environment into smaller, simpler, and more manageable sub-tasks and
criteria until each leaf node represents simple yes-or-no criteria for
PentestJudge to evaluate. Task nodes are broken down into different categories
related to operational objectives, operational security, and tradecraft.
LLM-as-judge scores are compared to human domain experts as a ground-truth
reference, allowing us to compare their relative performance with standard
binary classification metrics, such as F1 scores. We evaluate several frontier
and open-source models acting as judge agents, with the best model reaching an
F1 score of 0.83. We find models that are better at tool-use perform more
closely to human experts. By stratifying the F1 scores by requirement type, we
find even models with similar overall scores struggle with different types of
questions, suggesting certain models may be better judges of particular
operating criteria. We find that weaker and cheaper models can judge the
trajectories of pentests performed by stronger and more expensive models,
suggesting verification may be easier than generation for the penetration
testing task. We share this methodology to facilitate future research in
understanding the ability of judges to holistically and scalably evaluate the
process quality of AI-based information security agents so that they may be
confidently used in sensitive production environments.

</details>


### [71] [AQUAH: Automatic Quantification and Unified Agent in Hydrology](https://arxiv.org/abs/2508.02936)
*Songkun Yan,Zhi Li,Siyu Zhu,Yixin Wen,Mofan Zhang,Mengye Chen,Jie Cao,Yang Hong*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We introduce AQUAH, the first end-to-end language-based agent designed
specifically for hydrologic modeling. Starting from a simple natural-language
prompt (e.g., 'simulate floods for the Little Bighorn basin from 2020 to
2022'), AQUAH autonomously retrieves the required terrain, forcing, and gauge
data; configures a hydrologic model; runs the simulation; and generates a
self-contained PDF report. The workflow is driven by vision-enabled large
language models, which interpret maps and rasters on the fly and steer key
decisions such as outlet selection, parameter initialization, and uncertainty
commentary. Initial experiments across a range of U.S. basins show that AQUAH
can complete cold-start simulations and produce analyst-ready documentation
without manual intervention. The results are judged by hydrologists as clear,
transparent, and physically plausible. While further calibration and validation
are still needed for operational deployment, these early outcomes highlight the
promise of LLM-centered, vision-grounded agents to streamline complex
environmental modeling and lower the barrier between Earth observation data,
physics-based tools, and decision makers.

</details>


### [72] [MedBLINK: Probing Basic Perception in Multimodal Language Models for Medicine](https://arxiv.org/abs/2508.02951)
*Mahtab Bigverdi,Wisdom Ikezogwo,Kevin Zhang,Hyewon Jeong,Mingyu Lu,Sungjae Cho,Linda Shapiro,Ranjay Krishna*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Multimodal language models (MLMs) show promise for clinical decision support
and diagnostic reasoning, raising the prospect of end-to-end automated medical
image interpretation. However, clinicians are highly selective in adopting AI
tools; a model that makes errors on seemingly simple perception tasks such as
determining image orientation or identifying whether a CT scan is
contrast-enhance are unlikely to be adopted for clinical tasks. We introduce
Medblink, a benchmark designed to probe these models for such perceptual
abilities. Medblink spans eight clinically meaningful tasks across multiple
imaging modalities and anatomical regions, totaling 1,429 multiple-choice
questions over 1,605 images. We evaluate 19 state-of-the-art MLMs, including
general purpose (GPT4o, Claude 3.5 Sonnet) and domain specific (Med Flamingo,
LLaVA Med, RadFM) models. While human annotators achieve 96.4% accuracy, the
best-performing model reaches only 65%. These results show that current MLMs
frequently fail at routine perceptual checks, suggesting the need to strengthen
their visual grounding to support clinical adoption. Data is available on our
project page.

</details>


### [73] [Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow](https://arxiv.org/abs/2508.02959)
*Chia-Tung Ho,Jing Gong,Xufeng Yao,Yunsheng Bai,Abhishek B Akkur,Haoxing Ren*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Large language models (LLMs) excel at solving complex tasks by executing
agentic workflows composed of detailed instructions and structured operations.
Yet, building general-purpose agents by manually embedding foundation models
into agentic systems such as Chain-of-Thought, Self-Reflection, and ReACT
through text interfaces limits scalability and efficiency. Recently, many
researchers have sought to automate the generation and optimization of these
workflows through code-based representations. However, existing methods often
rely on labeled datasets to train and optimize workflows, making them
ineffective and inflexible for solving real-world, dynamic problems where
labeled data is unavailable. To address this challenge, we introduce Polymath,
a self-optimizing agent with dynamic hierarchical workflow that leverages the
flexibility of task flow graphs and the expressiveness of code-represented
workflows to solve a wide range of real-world, dynamic problems. The proposed
optimization methodology integrates multi-grid-inspired graph optimization with
a self-reflection-guided evolutionary algorithm to refine workflows without
labeled data. Experimental results on six benchmark datasets across coding,
math, and multi-turn QA tasks show that Polymath achieves 8.1% average
improvement over state-of-the-art baselines.

</details>


### [74] [Defend LLMs Through Self-Consciousness](https://arxiv.org/abs/2508.02961)
*Boshi Huang,Fabio Nonato de Paula*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: This paper introduces a novel self-consciousness defense mechanism for Large
Language Models (LLMs) to combat prompt injection attacks. Unlike traditional
approaches that rely on external classifiers, our method leverages the LLM's
inherent reasoning capabilities to perform self-protection. We propose a
framework that incorporates Meta-Cognitive and Arbitration Modules, enabling
LLMs to evaluate and regulate their own outputs autonomously. Our approach is
evaluated on seven state-of-the-art LLMs using two datasets: AdvBench and
Prompt-Injection-Mixed-Techniques-2024. Experiment results demonstrate
significant improvements in defense success rates across models and datasets,
with some achieving perfect and near-perfect defense in Enhanced Mode. We also
analyze the trade-off between defense success rate improvement and
computational overhead. This self-consciousness method offers a lightweight,
cost-effective solution for enhancing LLM ethics, particularly beneficial for
GenAI use cases across various platforms.

</details>


### [75] [Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling](https://arxiv.org/abs/2508.02979)
*Peng Ding,Rick Stevens*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: The proliferation of tool-augmented Large Language Models (LLMs) has created
a fragmented ecosystem where developers must navigate multiple protocols,
manual schema definitions, and complex execution workflows. We address this
challenge by proposing a unified approach to tool integration that abstracts
protocol differences while optimizing execution performance. Our solution
demonstrates how protocol-agnostic design principles can significantly reduce
development overhead through automated schema generation, dual-mode concurrent
execution, and seamless multi-source tool management. Experimental results show
60-80% code reduction across integration scenarios, performance improvements up
to 3.1x through optimized concurrency, and full compatibility with existing
function calling standards. This work contributes both theoretical insights
into tool integration architecture and practical solutions for real-world LLM
application development.

</details>


### [76] [When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs](https://arxiv.org/abs/2508.02994)
*Fangyi Yu*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: As large language models (LLMs) grow in capability and autonomy, evaluating
their outputs-especially in open-ended and complex tasks-has become a critical
bottleneck. A new paradigm is emerging: using AI agents as the evaluators
themselves. This "agent-as-a-judge" approach leverages the reasoning and
perspective-taking abilities of LLMs to assess the quality and safety of other
models, promising calable and nuanced alternatives to human evaluation. In this
review, we define the agent-as-a-judge concept, trace its evolution from
single-model judges to dynamic multi-agent debate frameworks, and critically
examine their strengths and shortcomings. We compare these approaches across
reliability, cost, and human alignment, and survey real-world deployments in
domains such as medicine, law, finance, and education. Finally, we highlight
pressing challenges-including bias, robustness, and meta evaluation-and outline
future research directions. By bringing together these strands, our review
demonstrates how agent-based judging can complement (but not replace) human
oversight, marking a step toward trustworthy, scalable evaluation for
next-generation LLMs.

</details>


### [77] [AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots](https://arxiv.org/abs/2508.02999)
*Xinjie Zhao,Moritz Blum,Fan Gao,Yingjian Chen,Boming Yang,Luis Marquez-Carpintero,Mónica Pina-Navarro,Yanran Fu,So Morikawa,Yusuke Iwasawa,Yutaka Matsuo,Chanjun Park,Irene Li*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: AGENTiGraph is a user-friendly, agent-driven system that enables intuitive
interaction and management of domain-specific data through the manipulation of
knowledge graphs in natural language. It gives non-technical users a complete,
visual solution to incrementally build and refine their knowledge bases,
allowing multi-round dialogues and dynamic updates without specialized query
languages. The flexible design of AGENTiGraph, including intent classification,
task planning, and automatic knowledge integration, ensures seamless reasoning
between diverse tasks. Evaluated on a 3,500-query benchmark within an
educational scenario, the system outperforms strong zero-shot baselines
(achieving 95.12% classification accuracy, 90.45% execution success),
indicating potential scalability to compliance-critical or multi-step queries
in legal and medical domains, e.g., incorporating new statutes or research on
the fly. Our open-source demo offers a powerful new paradigm for multi-turn
enterprise knowledge management that bridges LLMs and structured graphs.

</details>


### [78] [Beyond Policy Optimization: A Data Curation Flywheel for Sparse-Reward Long-Horizon Planning](https://arxiv.org/abs/2508.03018)
*Yutong Wang,Pengliang Ji,Kaixin Li,Baolong Bi,Tao Feng,Guillaume Sartoretti*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Large Language Reasoning Models have demonstrated remarkable success on
static tasks, yet their application to multi-round agentic planning in
interactive environments faces two fundamental challenges. First, the
intractable credit assignment problem renders conventional reinforcement
learning ineffective in sparse-reward settings. Second, the computational
overhead of verbose, step-by-step reasoning histories is prohibitive. To
address these challenges, we propose BPO, a three-stage framework
(bootstrapping, extrapolation, and refinement) that establishes a
self-improving data flywheel to develop robust reasoning models for
long-horizon, sparse-reward environments. Our framework first bootstraps
efficient reasoning using the proposed planning quaternions with long-short
chain-of-thought fusion. It then extrapolates to out-of-distribution tasks
through complexity-stratified curriculum learning. Finally, the model
iteratively refines itself by learning exclusively on experiences selected via
reward-gated rejection sampling. Experiments on ALFWorld, ScienceWorld, and
WebShop demonstrate that our approach achieves state-of-the-art with
significant token efficiency, providing a new recipe for reasoning models in
agentic planning.

</details>


### [79] [Collab-Solver: Collaborative Solving Policy Learning for Mixed-Integer Linear Programming](https://arxiv.org/abs/2508.03030)
*Siyuan Li,Yifan Yu,Yanchen Deng,Zhihao Zhang,Mengjing Chen,Fangzhou Zhu,Tao Zhong,Jianye Hao,Peng Liu,Bo An*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Mixed-integer linear programming (MILP) has been a fundamental problem in
combinatorial optimization. Previous works have designed a plethora of
hard-coded heuristics to accomplish challenging MILP solving with domain
knowledge. Driven by the high capability of neural networks, recent research is
devoted to replacing manually designed heuristics with learned policies.
Although learning-based MILP methods have shown great promise, existing
worksindependentlytreatthepolicylearningineachmoduleofMILPsolvers without
considering their interdependence, severely hurting the solving speed and
quality. To address this issue, we propose a novel multi-agent-based policy
learning framework for MILP (Collab-Solver), which can collaboratively optimize
the policies for multiple modules. Specifically, we formulate the collaboration
of cut selection and branching in MILP solving as a Stackelberg game. Under
this formulation, we develop a two-phase learning paradigm to stabilize the
collaborative policy learning, where the first phase achieves the
data-communicated policy pretraining and the second phase further orchestrates
the policy learning for various modules. The jointly learned policy
significantly improves the solving performance on both synthetic and
large-scale real-world MILP datasets. Moreover, the policies learned by
Collab-Solver have also demonstrated excellent generalization abilities across
different instance sets.

</details>


### [80] [From Text to Trajectories: GPT-2 as an ODE Solver via In-Context](https://arxiv.org/abs/2508.03031)
*Ziyang Ma,Baojian Zhou,Deqing Yang,Yanghua Xiao*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: In-Context Learning (ICL) has emerged as a new paradigm in large language
models (LLMs), enabling them to perform novel tasks by conditioning on a few
examples embedded in the prompt. Yet, the highly nonlinear behavior of ICL for
NLP tasks remains poorly understood. To shed light on its underlying
mechanisms, this paper investigates whether LLMs can solve ordinary
differential equations (ODEs) under the ICL setting. We formulate standard ODE
problems and their solutions as sequential prompts and evaluate GPT-2 models on
these tasks. Experiments on two types of ODEs show that GPT-2 can effectively
learn a meta-ODE algorithm, with convergence behavior comparable to, or better
than, the Euler method, and achieve exponential accuracy gains with increasing
numbers of demonstrations. Moreover, the model generalizes to
out-of-distribution (OOD) problems, demonstrating robust extrapolation
capabilities. These empirical findings provide new insights into the mechanisms
of ICL in NLP and its potential for solving nonlinear numerical problems.

</details>


### [81] [Tree-of-Reasoning: Towards Complex Medical Diagnosis via Multi-Agent Reasoning with Evidence Tree](https://arxiv.org/abs/2508.03038)
*Qi Peng,Jialin Cui,Jiayuan Xie,Yi Cai,Qing Li*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Large language models (LLMs) have shown great potential in the medical
domain. However, existing models still fall short when faced with complex
medical diagnosis task in the real world. This is mainly because they lack
sufficient reasoning depth, which leads to information loss or logical jumps
when processing a large amount of specialized medical data, leading to
diagnostic errors. To address these challenges, we propose Tree-of-Reasoning
(ToR), a novel multi-agent framework designed to handle complex scenarios.
Specifically, ToR introduces a tree structure that can clearly record the
reasoning path of LLMs and the corresponding clinical evidence. At the same
time, we propose a cross-validation mechanism to ensure the consistency of
multi-agent decision-making, thereby improving the clinical reasoning ability
of multi-agents in complex medical scenarios. Experimental results on
real-world medical data show that our framework can achieve better performance
than existing baseline methods.

</details>


### [82] [T2UE: Generating Unlearnable Examples from Text Descriptions](https://arxiv.org/abs/2508.03091)
*Xingjun Ma,Hanxun Huang,Tianwei Song,Ye Sun,Yifeng Gao,Yu-Gang Jiang*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Large-scale pre-training frameworks like CLIP have revolutionized multimodal
learning, but their reliance on web-scraped datasets, frequently containing
private user data, raises serious concerns about misuse. Unlearnable Examples
(UEs) have emerged as a promising countermeasure against unauthorized model
training, employing carefully crafted unlearnable noise to disrupt the learning
of meaningful representations from protected data. Current approaches typically
generate UEs by jointly optimizing unlearnable noise for both images and their
associated text descriptions (or labels). However, this optimization process is
often computationally prohibitive for on-device execution, forcing reliance on
external third-party services. This creates a fundamental privacy paradox:
users must initially expose their data to these very services to achieve
protection, thereby compromising privacy in the process. Such a contradiction
has severely hindered the development of practical, scalable data protection
solutions. To resolve this paradox, we introduce \textbf{Text-to-Unlearnable
Example (T2UE)}, a novel framework that enables users to generate UEs using
only text descriptions. T2UE circumvents the need for original image data by
employing a text-to-image (T2I) model to map text descriptions into the image
(noise) space, combined with an error-minimization framework to produce
effective unlearnable noise. Extensive experiments show that T2UE-protected
data substantially degrades performance in downstream tasks (e.g., cross-modal
retrieval) for state-of-the-art models. Notably, the protective effect
generalizes across diverse architectures and even to supervised learning
settings. Our work demonstrates the feasibility of "zero-contact data
protection", where personal data can be safeguarded based solely on their
textual descriptions, eliminating the need for direct data exposure.

</details>


### [83] [Beyond Surface-Level Detection: Towards Cognitive-Driven Defense Against Jailbreak Attacks via Meta-Operations Reasoning](https://arxiv.org/abs/2508.03054)
*Rui Pu,Chaozhuo Li,Rui Ha,Litian Zhang,Lirong Qiu,Xi Zhang*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Defending large language models (LLMs) against jailbreak attacks is essential
for their safe and reliable deployment. Existing defenses often rely on shallow
pattern matching, which struggles to generalize to novel and unseen attack
strategies. To address this challenge, we propose the Cognitive-Driven Defense
(CDD) framework, which targets the underlying structure of jailbreak prompts by
applying meta-operations, defined as basic manipulations that conceal harmful
intent.CDD emulates human cognitive reasoning through a structured reasoning
chain. It begins with a global perception of the prompt and follows with a
localized analysis to uncover hidden manipulations. By applying supervised
fine-tuning on this structured chain, the model learns to identify and reason
about known manipulation patterns. To enhance generalization to unseen threats,
an entropy-guided reinforcement learning algorithm (EG-GRPO) is introduced to
encourage exploration of new types and variants of meta-operations. Experiments
demonstrate that CDD can achieve state-of-the-art defense performance and
exhibit strong generalization to unseen jailbreak attacks.

</details>


### [84] [ContractEval: Benchmarking LLMs for Clause-Level Legal Risk Identification in Commercial Contracts](https://arxiv.org/abs/2508.03080)
*Shuang Liu,Zelong Li,Ruoyun Ma,Haiyan Zhao,Mengnan Du*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: The potential of large language models (LLMs) in specialized domains such as
legal risk analysis remains underexplored. In response to growing interest in
locally deploying open-source LLMs for legal tasks while preserving data
confidentiality, this paper introduces ContractEval, the first benchmark to
thoroughly evaluate whether open-source LLMs could match proprietary LLMs in
identifying clause-level legal risks in commercial contracts. Using the
Contract Understanding Atticus Dataset (CUAD), we assess 4 proprietary and 15
open-source LLMs. Our results highlight five key findings: (1) Proprietary
models outperform open-source models in both correctness and output
effectiveness, though some open-source models are competitive in certain
specific dimensions. (2) Larger open-source models generally perform better,
though the improvement slows down as models get bigger. (3) Reasoning
("thinking") mode improves output effectiveness but reduces correctness, likely
due to over-complicating simpler tasks. (4) Open-source models generate "no
related clause" responses more frequently even when relevant clauses are
present. This suggests "laziness" in thinking or low confidence in extracting
relevant content. (5) Model quantization speeds up inference but at the cost of
performance drop, showing the tradeoff between efficiency and accuracy. These
findings suggest that while most LLMs perform at a level comparable to junior
legal assistants, open-source models require targeted fine-tuning to ensure
correctness and effectiveness in high-stakes legal settings. ContractEval
offers a solid benchmark to guide future development of legal-domain LLMs.

</details>


### [85] [EoH-S: Evolution of Heuristic Set using LLMs for Automated Heuristic Design](https://arxiv.org/abs/2508.03082)
*Fei Liu,Yilu Liu,Qingfu Zhang,Xialiang Tong,Mingxuan Yuan*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Automated Heuristic Design (AHD) using Large Language Models (LLMs) has
achieved notable success in recent years. Despite the effectiveness of existing
approaches, they only design a single heuristic to serve all problem instances,
often inducing poor generalization across different distributions or settings.
To address this issue, we propose Automated Heuristic Set Design (AHSD), a new
formulation for LLM-driven AHD. The aim of AHSD is to automatically generate a
small-sized complementary heuristic set to serve diverse problem instances,
such that each problem instance could be optimized by at least one heuristic in
this set. We show that the objective function of AHSD is monotone and
supermodular. Then, we propose Evolution of Heuristic Set (EoH-S) to apply the
AHSD formulation for LLM-driven AHD. With two novel mechanisms of complementary
population management and complementary-aware memetic search, EoH-S could
effectively generate a set of high-quality and complementary heuristics.
Comprehensive experimental results on three AHD tasks with diverse instances
spanning various sizes and distributions demonstrate that EoH-S consistently
outperforms existing state-of-the-art AHD methods and achieves up to 60\%
performance improvements.

</details>


### [86] [MissDDIM: Deterministic and Efficient Conditional Diffusion for Tabular Data Imputation](https://arxiv.org/abs/2508.03083)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Diffusion models have recently emerged as powerful tools for missing data
imputation by modeling the joint distribution of observed and unobserved
variables. However, existing methods, typically based on stochastic denoising
diffusion probabilistic models (DDPMs), suffer from high inference latency and
variable outputs, limiting their applicability in real-world tabular settings.
To address these deficiencies, we present in this paper MissDDIM, a conditional
diffusion framework that adapts Denoising Diffusion Implicit Models (DDIM) for
tabular imputation. While stochastic sampling enables diverse completions, it
also introduces output variability that complicates downstream processing.

</details>


### [87] [Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework](https://arxiv.org/abs/2508.03092)
*Zikun Cui,Tianyi Huang,Chia-En Chiang,Cuiqianhe Du*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: With the proliferation of Large Language Models (LLMs), the detection of
misinformation has become increasingly important and complex. This research
proposes an innovative verifiable misinformation detection LLM agent that goes
beyond traditional true/false binary judgments. The agent actively verifies
claims through dynamic interaction with diverse web sources, assesses
information source credibility, synthesizes evidence, and provides a complete
verifiable reasoning process. Our designed agent architecture includes three
core tools: precise web search tool, source credibility assessment tool and
numerical claim verification tool. These tools enable the agent to execute
multi-step verification strategies, maintain evidence logs, and form
comprehensive assessment conclusions. We evaluate using standard misinformation
datasets such as FakeNewsNet, comparing with traditional machine learning
models and LLMs. Evaluation metrics include standard classification metrics,
quality assessment of reasoning processes, and robustness testing against
rewritten content. Experimental results show that our agent outperforms
baseline methods in misinformation detection accuracy, reasoning transparency,
and resistance to information rewriting, providing a new paradigm for
trustworthy AI-assisted fact-checking.

</details>


### [88] [AgentSME for Simulating Diverse Communication Modes in Smart Education](https://arxiv.org/abs/2508.03109)
*Wen-Xi Yang,Tian-Fang Zhao*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Generative agent models specifically tailored for smart education are
critical, yet remain relatively underdeveloped. A key challenge stems from the
inherent complexity of educational contexts: learners are human beings with
various cognitive behaviors, and pedagogy is fundamentally centered on
personalized human-to-human communication. To address this issue, this paper
proposes AgentSME, a unified generative agent framework powered by LLM. Three
directional communication modes are considered in the models, namely Solo,
Mono, and Echo, reflecting different types of agency autonomy and communicative
reciprocity. Accuracy is adopted as the primary evaluation metric, complemented
by three diversity indices designed to assess the diversity of reasoning
contents. Six widely used LLMs are tested to validate the robustness of
communication modes across different model tiers, which are equally divided
into base-capacity and high-capacity configurations. The results show that
generative agents that employ the Echo communication mode achieve the highest
accuracy scores, while DeepSeek exhibits the greatest diversity. This study
provides valuable information to improve agent learning capabilities and
inspire smart education models.

</details>


### [89] [Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation](https://arxiv.org/abs/2508.03117)
*Vinicius Lima,Dzung T. Phan,Jayant Kalagnanam,Dhaval Patel,Nianjun Zhou*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We present a framework for training trustworthy large language model (LLM)
agents for optimization modeling via a verifiable synthetic data generation
pipeline. Focusing on linear and mixed-integer linear programming, our approach
begins with structured symbolic representations and systematically produces
natural language descriptions, mathematical formulations, and solver-executable
code. By programmatically constructing each instance with known optimal
solutions, the pipeline ensures full verifiability and enables automatic
filtering of low-quality demonstrations generated by teacher models. Each
dataset instance includes a structured representation of the optimization
problem, a corresponding natural language description, the verified optimal
solution, and step-by-step demonstrations - generated by a teacher model - that
show how to model and solve the problem across multiple optimization modeling
languages. This enables supervised fine-tuning of open-source LLMs specifically
tailored to optimization tasks. To operationalize this pipeline, we introduce
OptiTrust, a modular LLM agent that performs multi-stage translation from
natural language to solver-ready code, leveraging stepwise demonstrations,
multi-language inference, and majority-vote cross-validation. Our agent
achieves state-of-the-art performance on standard benchmarks. Out of 7
datasets, it achieves the highest accuracy on six and outperforms the next-best
algorithm by at least 8 percentage on three of them. Our approach provides a
scalable, verifiable, and principled path toward building reliable LLM agents
for real-world optimization applications.

</details>


### [90] [Can Large Language Models Bridge the Gap in Environmental Knowledge?](https://arxiv.org/abs/2508.03149)
*Linda Smail,David Santandreu Calonge,Firuz Kamalov,Nur H. Orak*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: This research investigates the potential of Artificial Intelligence (AI)
models to bridge the knowledge gap in environmental education among university
students. By focusing on prominent large language models (LLMs) such as
GPT-3.5, GPT-4, GPT-4o, Gemini, Claude Sonnet, and Llama 2, the study assesses
their effectiveness in conveying environmental concepts and, consequently,
facilitating environmental education. The investigation employs a standardized
tool, the Environmental Knowledge Test (EKT-19), supplemented by targeted
questions, to evaluate the environmental knowledge of university students in
comparison to the responses generated by the AI models. The results of this
study suggest that while AI models possess a vast, readily accessible, and
valid knowledge base with the potential to empower both students and academic
staff, a human discipline specialist in environmental sciences may still be
necessary to validate the accuracy of the information provided.

</details>


### [91] [Causal identification with $Y_0$](https://arxiv.org/abs/2508.03167)
*Charles Tapley Hoyt,Craig Bakker,Richard J. Callahan,Joseph Cottam,August George,Benjamin M. Gyori,Haley M. Hummel,Nathaniel Merrill,Sara Mohammad Taheri,Pruthvi Prakash Navada,Marc-Antoine Parent,Adam Rupe,Olga Vitek,Jeremy Zucker*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We present the $Y_0$ Python package, which implements causal identification
algorithms that apply interventional, counterfactual, and transportability
queries to data from (randomized) controlled trials, observational studies, or
mixtures thereof. $Y_0$ focuses on the qualitative investigation of causation,
helping researchers determine whether a causal relationship can be estimated
from available data before attempting to estimate how strong that relationship
is. Furthermore, $Y_0$ provides guidance on how to transform the causal query
into a symbolic estimand that can be non-parametrically estimated from the
available data. $Y_0$ provides a domain-specific language for representing
causal queries and estimands as symbolic probabilistic expressions, tools for
representing causal graphical models with unobserved confounders, such as
acyclic directed mixed graphs (ADMGs), and implementations of numerous
identification algorithms from the recent causal inference literature. The
$Y_0$ source code can be found under the MIT License at
https://github.com/y0-causal-inference/y0 and it can be installed with pip
install y0.

</details>


### [92] [Geoint-R1: Formalizing Multimodal Geometric Reasoning with Dynamic Auxiliary Constructions](https://arxiv.org/abs/2508.03173)
*Jingxuan Wei,Caijun Jia,Qi Chen,Honghao He,Linzhuang Sun,Conghui He,Lijun Wu,Bihui Yu,Cheng Tan*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Mathematical geometric reasoning is essential for scientific discovery and
educational development, requiring precise logic and rigorous formal
verification. While recent advances in Multimodal Large Language Models (MLLMs)
have improved reasoning tasks, existing models typically struggle with formal
geometric reasoning, particularly when dynamically constructing and verifying
auxiliary geometric elements. To address these challenges, we introduce
Geoint-R1, a multimodal reasoning framework designed to generate formally
verifiable geometric solutions from textual descriptions and visual diagrams.
Geoint-R1 uniquely integrates auxiliary elements construction, formal reasoning
represented via Lean4, and interactive visualization. To systematically
evaluate and advance formal geometric reasoning, we propose the Geoint
benchmark, comprising 1,885 rigorously annotated geometry problems across
diverse topics such as plane, spatial, and solid geometry. Each problem
includes structured textual annotations, precise Lean4 code for auxiliary
constructions, and detailed solution steps verified by experts. Extensive
experiments demonstrate that Geoint-R1 significantly surpasses existing
multimodal and math-specific reasoning models, particularly on challenging
problems requiring explicit auxiliary element constructions.

</details>


### [93] [InqEduAgent: Adaptive AI Learning Partners with Gaussian Process Augmentation](https://arxiv.org/abs/2508.03174)
*Tian-Fang Zhao,Wen-Xi Yang*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Collaborative partnership matters in inquiry-oriented education. However,
most study partners are selected either rely on experience-based assignments
with little scientific planning or build on rule-based machine assistants,
encountering difficulties in knowledge expansion and inadequate flexibility.
This paper proposes an LLM-empowered agent model for simulating and selecting
learning partners tailored to inquiry-oriented learning, named InqEduAgent.
Generative agents are designed to capture cognitive and evaluative features of
learners in real-world scenarios. Then, an adaptive matching algorithm with
Gaussian process augmentation is formulated to identify patterns within prior
knowledge. Optimal learning-partner matches are provided for learners facing
different exercises. The experimental results show the optimal performance of
InqEduAgent in most knowledge-learning scenarios and LLM environment with
different levels of capabilities. This study promotes the intelligent
allocation of human-based learning partners and the formulation of AI-based
learning partners. The code, data, and appendix are publicly available at
https://github.com/InqEduAgent/InqEduAgent.

</details>


### [94] [Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning](https://arxiv.org/abs/2508.03251)
*Osama Mohammed,Jiaxin Pan,Mojtaba Nayyeri,Daniel Hernández,Steffen Staab*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Modeling evolving interactions among entities is critical in many real-world
tasks. For example, predicting driver maneuvers in traffic requires tracking
how neighboring vehicles accelerate, brake, and change lanes relative to one
another over consecutive frames. Likewise, detecting financial fraud hinges on
following the flow of funds through successive transactions as they propagate
through the network. Unlike classic time-series forecasting, these settings
demand reasoning over who interacts with whom and when, calling for a
temporal-graph representation that makes both the relations and their evolution
explicit. Existing temporal-graph methods typically use snapshot graphs to
encode temporal evolution. We introduce a full-history graph that instantiates
one node for every entity at every time step and separates two edge sets: (i)
intra-time-step edges that capture relations within a single frame and (ii)
inter-time-step edges that connect an entity to itself at consecutive steps. To
learn on this graph we design an Edge-Type Decoupled Network (ETDNet) with
parallel modules: a graph-attention module aggregates information along
intra-time-step edges, a multi-head temporal-attention module attends over an
entity's inter-time-step history, and a fusion module combines the two messages
after every layer. Evaluated on driver-intention prediction (Waymo) and Bitcoin
fraud detection (Elliptic++), ETDNet consistently surpasses strong baselines,
lifting Waymo joint accuracy to 75.6\% (vs. 74.1\%) and raising Elliptic++
illicit-class F1 to 88.1\% (vs. 60.4\%). These gains demonstrate the benefit of
representing structural and temporal relations as distinct edges in a single
graph.

</details>


### [95] [ToolVQA: A Dataset for Multi-step Reasoning VQA with External Tools](https://arxiv.org/abs/2508.03284)
*Shaofeng Yin,Ting Lei,Yang Liu*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Integrating external tools into Large Foundation Models (LFMs) has emerged as
a promising approach to enhance their problem-solving capabilities. While
existing studies have demonstrated strong performance in tool-augmented Visual
Question Answering (VQA), recent benchmarks reveal significant gaps in
real-world tool-use proficiency, particularly in functionally diverse
multimodal settings requiring multi-step reasoning. In this work, we introduce
ToolVQA, a large-scale multimodal dataset comprising 23K instances, designed to
bridge this gap. Unlike previous datasets that rely on synthetic scenarios and
simplified queries, ToolVQA features real-world visual contexts and challenging
implicit multi-step reasoning tasks, better aligning with real user
interactions. To construct this dataset, we propose ToolEngine, a novel data
generation pipeline that employs Depth-First Search (DFS) with a dynamic
in-context example matching mechanism to simulate human-like tool-use
reasoning. ToolVQA encompasses 10 multimodal tools across 7 diverse task
domains, with an average inference length of 2.78 reasoning steps per instance.
The fine-tuned 7B LFMs on ToolVQA not only achieve impressive performance on
our test set but also surpass the large close-sourced model GPT-3.5-turbo on
various out-of-distribution (OOD) datasets, demonstrating strong
generalizability to real-world tool-use scenarios.

</details>


### [96] [Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science](https://arxiv.org/abs/2508.03341)
*Jiayan Nan,Wenquan Ma,Wenlong Wu,Yize Chen*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities, yet their
inability to maintain persistent memory in long contexts limits their
effectiveness as autonomous agents in long-term interactions. While existing
memory systems have made progress, their reliance on arbitrary granularity for
defining the basic memory unit and passive, rule-based mechanisms for knowledge
extraction limits their capacity for genuine learning and evolution. To address
these foundational limitations, we present Nemori, a novel self-organizing
memory architecture inspired by human cognitive principles. Nemori's core
innovation is twofold: First, its Two-Step Alignment Principle, inspired by
Event Segmentation Theory, provides a principled, top-down method for
autonomously organizing the raw conversational stream into semantically
coherent episodes, solving the critical issue of memory granularity. Second,
its Predict-Calibrate Principle, inspired by the Free-energy Principle, enables
the agent to proactively learn from prediction gaps, moving beyond pre-defined
heuristics to achieve adaptive knowledge evolution. This offers a viable path
toward handling the long-term, dynamic workflows of autonomous agents.
Extensive experiments on the LoCoMo and LongMemEval benchmarks demonstrate that
Nemori significantly outperforms prior state-of-the-art systems, with its
advantage being particularly pronounced in longer contexts.

</details>


### [97] [Adaptive AI Agent Placement and Migration in Edge Intelligence Systems](https://arxiv.org/abs/2508.03345)
*Xingdan Wang,Jiayi He,Zhiqing Tang,Jianxiong Guo,Jiong Lou,Liping Qian,Tian Wang,Weijia Jia*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: The rise of LLMs such as ChatGPT and Claude fuels the need for AI agents
capable of real-time task handling. However, migrating data-intensive,
multi-modal edge workloads to cloud data centers, traditionally used for agent
deployment, introduces significant latency. Deploying AI agents at the edge
improves efficiency and reduces latency. However, edge environments present
challenges due to limited and heterogeneous resources. Maintaining QoS for
mobile users necessitates agent migration, which is complicated by the
complexity of AI agents coordinating LLMs, task planning, memory, and external
tools. This paper presents the first systematic deployment and management
solution for LLM-based AI agents in dynamic edge environments. We propose a
novel adaptive framework for AI agent placement and migration in edge
intelligence systems. Our approach models resource constraints and
latency/cost, leveraging ant colony algorithms and LLM-based optimization for
efficient decision-making. It autonomously places agents to optimize resource
utilization and QoS and enables lightweight agent migration by transferring
only essential state. Implemented on a distributed system using AgentScope and
validated across globally distributed edge servers, our solution significantly
reduces deployment latency and migration costs.

</details>


### [98] [Compressing Chain-of-Thought in LLMs via Step Entropy](https://arxiv.org/abs/2508.03346)
*Zeju Li,Jianyuan Zhong,Ziyang Zheng,Xiangyu Wen,Zhijian Xu,Yingying Cheng,Fan Zhang,Qiang Xu*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Large Language Models (LLMs) using Chain-of-Thought (CoT) prompting excel at
complex reasoning but generate verbose thought processes with considerable
redundancy, leading to increased inference costs and reduced efficiency. We
introduce a novel CoT compression framework based on step entropy, a metric
that quantifies the informational contribution of individual reasoning steps to
identify redundancy. Through theoretical analysis and extensive empirical
validation on mathematical reasoning benchmarks, we demonstrate that steps with
low entropy are indeed highly redundant. Our experiments reveal that an
astonishing 80\% of low-entropy intermediate steps can be pruned with minor
degradation in the final answer accuracy across DeepSeek-R1-7B, 14B and
Qwen3-8B. This finding sharply contrasts with random or high-entropy pruning,
which severely impairs reasoning performance. Building on this, we propose a
novel two-stage training strategy combining Supervised Fine-Tuning (SFT) and
Group Relative Policy Optimization (GRPO) reinforcement learning. This approach
enables LLMs to autonomously learn to generate compressed COTs during inference
by strategically incorporating [SKIP] tokens. Our method significantly enhances
LLM inference efficiency while rigorously preserving accuracy, offering
profound implications for practical LLM deployment and a deeper understanding
of reasoning structures.

</details>


### [99] [CogBench: A Large Language Model Benchmark for Multilingual Speech-Based Cognitive Impairment Assessment](https://arxiv.org/abs/2508.03360)
*Feng Rui,Zhiyao Luo,Wei Wang,Yuting Song,Yong Liu,Tingting Zhu,Jianqing Li,Xingyao Wang*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Automatic assessment of cognitive impairment from spontaneous speech offers a
promising, non-invasive avenue for early cognitive screening. However, current
approaches often lack generalizability when deployed across different languages
and clinical settings, limiting their practical utility. In this study, we
propose CogBench, the first benchmark designed to evaluate the cross-lingual
and cross-site generalizability of large language models (LLMs) for
speech-based cognitive impairment assessment. Using a unified multimodal
pipeline, we evaluate model performance on three speech datasets spanning
English and Mandarin: ADReSSo, NCMMSC2021-AD, and a newly collected test set,
CIR-E. Our results show that conventional deep learning models degrade
substantially when transferred across domains. In contrast, LLMs equipped with
chain-of-thought prompting demonstrate better adaptability, though their
performance remains sensitive to prompt design. Furthermore, we explore
lightweight fine-tuning of LLMs via Low-Rank Adaptation (LoRA), which
significantly improves generalization in target domains. These findings offer a
critical step toward building clinically useful and linguistically robust
speech-based cognitive assessment tools.

</details>


### [100] [A Comparative Study of Neurosymbolic AI Approaches to Interpretable Logical Reasoning](https://arxiv.org/abs/2508.03366)
*Michael K. Chen*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: General logical reasoning, defined as the ability to reason deductively on
domain-agnostic tasks, continues to be a challenge for large language models
(LLMs). Current LLMs fail to reason deterministically and are not
interpretable. As such, there has been a recent surge in interest in
neurosymbolic AI, which attempts to incorporate logic into neural networks. We
first identify two main neurosymbolic approaches to improving logical
reasoning: (i) the integrative approach comprising models where symbolic
reasoning is contained within the neural network, and (ii) the hybrid approach
comprising models where a symbolic solver, separate from the neural network,
performs symbolic reasoning. Both contain AI systems with promising results on
domain-specific logical reasoning benchmarks. However, their performance on
domain-agnostic benchmarks is understudied. To the best of our knowledge, there
has not been a comparison of the contrasting approaches that answers the
following question: Which approach is more promising for developing general
logical reasoning? To analyze their potential, the following best-in-class
domain-agnostic models are introduced: Logic Neural Network (LNN), which uses
the integrative approach, and LLM-Symbolic Solver (LLM-SS), which uses the
hybrid approach. Using both models as case studies and representatives of each
approach, our analysis demonstrates that the hybrid approach is more promising
for developing general logical reasoning because (i) its reasoning chain is
more interpretable, and (ii) it retains the capabilities and advantages of
existing LLMs. To support future works using the hybrid approach, we propose a
generalizable framework based on LLM-SS that is modular by design,
model-agnostic, domain-agnostic, and requires little to no human input.

</details>


### [101] [Board Game Arena: A Framework and Benchmark for Assessing Large Language Models via Strategic Play](https://arxiv.org/abs/2508.03368)
*Lucia Cipolina-Kun,Marianna Nezhurina,Jenia Jitsev*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: The Board Game Arena library provides a framework for evaluating the decision
making abilities of large language models (LLMs) through strategic board games
implemented in Google OpenSpiel library. The framework enables systematic
comparisons between LLM based agents and other agents (random, human,
reinforcement learning agents, etc.) in various game scenarios by wrapping
multiple board and matrix games and supporting different agent types. It
integrates API access to models via LiteLLM, local model deployment via vLLM,
and offers distributed execution through Ray. Additionally it provides
extensive analysis tools for the LLM reasoning traces. This paper summarizes
the structure, key characteristics, and motivation of the repository,
highlighting how it contributes to the empirical evaluation of the reasoning of
LLM and game-theoretic behavior

</details>


### [102] [Data Dependency Inference for Industrial Code Generation Based on UML Sequence Diagrams](https://arxiv.org/abs/2508.03379)
*Wenxin Mao,Zhitao Wang Long Wang,Sirong Chen,Cuiyun Gao,Luyang Cao,Ziming Liu,Qiming Zhang,Jun Zhou,Zhi Jin*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Large language models (LLMs) excel at generating code from natural language
(NL) descriptions. However, the plain textual descriptions are inherently
ambiguous and often fail to capture complex requirements like intricate system
behaviors, conditional logic, and architectural constraints; implicit data
dependencies in service-oriented architectures are difficult to infer and
handle correctly. To bridge this gap, we propose a novel step-by-step code
generation framework named UML2Dep by leveraging unambiguous formal
specifications of complex requirements. First, we introduce an enhanced Unified
Modeling Language (UML) sequence diagram tailored for service-oriented
architectures. This diagram extends traditional visual syntax by integrating
decision tables and API specifications, explicitly formalizing structural
relationships and business logic flows in service interactions to rigorously
eliminate linguistic ambiguity. Second, recognizing the critical role of data
flow, we introduce a dedicated data dependency inference (DDI) task. DDI
systematically constructs an explicit data dependency graph prior to actual
code synthesis. To ensure reliability, we formalize DDI as a constrained
mathematical reasoning task through novel prompting strategies, aligning with
LLMs' excellent mathematical strengths. Additional static parsing and
dependency pruning further reduce context complexity and cognitive load
associated with intricate specifications, thereby enhancing reasoning accuracy
and efficiency.

</details>


### [103] [Hide and Seek with LLMs: An Adversarial Game for Sneaky Error Generation and Self-Improving Diagnosis](https://arxiv.org/abs/2508.03396)
*Rui Zou,Mengqi Wei,Yutao Zhu,Jirong Wen,Xin Zhao,Jing Chen*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Large Language Models (LLMs) excel in reasoning and generation across
domains, but still struggle with identifying and diagnosing complex errors.
This stems mainly from training objectives that prioritize correct answers,
limiting exposure to and learning from errors. While recent studies have begun
to address this by introducing error signals, most rely on shallow, static
errors, restricting improvement in deep diagnostic ability. To overcome this,
we propose Hide and Seek Game (HSG), a dynamic adversarial framework for error
generation and diagnosis, and evaluate it on mathematical problem-solving. HSG
involves two adversarial roles: Sneaky, which "hides" by generating subtle,
deceptive reasoning errors, and Diagnosis, which "seeks" to accurately detect
them. Through adversarial co-evolution, both error stealth and diagnostic
precision are enhanced. Experiments on several math reasoning tasks show that
HSG significantly boosts error diagnosis, achieving 16.8\%--31.4\% higher
accuracy than baselines like GPT-4o. We also release a challenging dataset of
deceptive errors and diagnostic annotations as a benchmark for future research.

</details>


### [104] [Multi-Objective Infeasibility Diagnosis for Routing Problems Using Large Language Models](https://arxiv.org/abs/2508.03406)
*Kai Li,Ruihao Zheng,Xinye Hao,Zhenkun Wang*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: In real-world routing problems, users often propose conflicting or
unreasonable requirements, which result in infeasible optimization models due
to overly restrictive or contradictory constraints, leading to an empty
feasible solution set. Existing Large Language Model (LLM)-based methods
attempt to diagnose infeasible models, but modifying such models often involves
multiple potential adjustments that these methods do not consider. To fill this
gap, we introduce Multi-Objective Infeasibility Diagnosis (MOID), which
combines LLM agents and multi-objective optimization within an automatic
routing solver, to provide a set of representative actionable suggestions.
Specifically, MOID employs multi-objective optimization to consider both path
cost and constraint violation, generating a set of trade-off solutions, each
encompassing varying degrees of model adjustments. To extract practical
insights from these solutions, MOID utilizes LLM agents to generate a solution
analysis function for the infeasible model. This function analyzes these
distinct solutions to diagnose the original infeasible model, providing users
with diverse diagnostic insights and suggestions. Finally, we compare MOID with
several LLM-based methods on 50 types of infeasible routing problems. The
results indicate that MOID automatically generates multiple diagnostic
suggestions in a single run, providing more practical insights for restoring
model feasibility and decision-making compared to existing methods.

</details>


### [105] [Data Overdose? Time for a Quadruple Shot: Knowledge Graph Construction using Enhanced Triple Extraction](https://arxiv.org/abs/2508.03438)
*Taine J. Elliott,Stephen P. Levitt,Ken Nixon,Martin Bekker*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: The rapid expansion of publicly-available medical data presents a challenge
for clinicians and researchers alike, increasing the gap between the volume of
scientific literature and its applications. The steady growth of studies and
findings overwhelms medical professionals at large, hindering their ability to
systematically review and understand the latest knowledge. This paper presents
an approach to information extraction and automatic knowledge graph (KG)
generation to identify and connect biomedical knowledge. Through a pipeline of
large language model (LLM) agents, the system decomposes 44 PubMed abstracts
into semantically meaningful proposition sentences and extracts KG triples from
these sentences. The triples are enhanced using a combination of open domain
and ontology-based information extraction methodologies to incorporate
ontological categories. On top of this, a context variable is included during
extraction to allow the triple to stand on its own - thereby becoming
`quadruples'. The extraction accuracy of the LLM is validated by comparing
natural language sentences generated from the enhanced triples to the original
propositions, achieving an average cosine similarity of 0.874. The similarity
for generated sentences of enhanced triples were compared with generated
sentences of ordinary triples showing an increase as a result of the context
variable. Furthermore, this research explores the ability for LLMs to infer new
relationships and connect clusters in the knowledge base of the knowledge
graph. This approach leads the way to provide medical practitioners with a
centralised, updated in real-time, and sustainable knowledge source, and may be
the foundation of similar gains in a wide variety of fields.

</details>


### [106] [Toward a Graph-Theoretic Model of Belief: Confidence, Credibility, and Structural Coherence](https://arxiv.org/abs/2508.03465)
*Saleh Nikooroo*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Belief systems are often treated as globally consistent sets of propositions
or as scalar-valued probability distributions. Such representations tend to
obscure the internal structure of belief, conflate external credibility with
internal coherence, and preclude the modeling of fragmented or contradictory
epistemic states. This paper introduces a minimal formalism for belief systems
as directed, weighted graphs. In this framework, nodes represent individual
beliefs, edges encode epistemic relationships (e.g., support or contradiction),
and two distinct functions assign each belief a credibility (reflecting source
trust) and a confidence (derived from internal structural support). Unlike
classical probabilistic models, our approach does not assume prior coherence or
require belief updating. Unlike logical and argumentation-based frameworks, it
supports fine-grained structural representation without committing to binary
justification status or deductive closure. The model is purely static and
deliberately excludes inference or revision procedures. Its aim is to provide a
foundational substrate for analyzing the internal organization of belief
systems, including coherence conditions, epistemic tensions, and
representational limits. By distinguishing belief structure from belief
strength, this formalism enables a richer classification of epistemic states
than existing probabilistic, logical, or argumentation-based approaches.

</details>


### [107] [Semantic-aware Graph-guided Behavior Sequences Generation with Large Language Models for Smart Homes](https://arxiv.org/abs/2508.03484)
*Zhiyao Xu,Dan Zhao,Qingsong Zou,Qing Li,Yong Jiang,Yuhang Wang,Jingyu Xiao*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: As smart homes become increasingly prevalent, intelligent models are widely
used for tasks such as anomaly detection and behavior prediction. These models
are typically trained on static datasets, making them brittle to behavioral
drift caused by seasonal changes, lifestyle shifts, or evolving routines.
However, collecting new behavior data for retraining is often impractical due
to its slow pace, high cost, and privacy concerns. In this paper, we propose
SmartGen, an LLM-based framework that synthesizes context-aware user behavior
data to support continual adaptation of downstream smart home models. SmartGen
consists of four key components. First, we design a Time and Semantic-aware
Split module to divide long behavior sequences into manageable, semantically
coherent subsequences under dual time-span constraints. Second, we propose
Semantic-aware Sequence Compression to reduce input length while preserving
representative semantics by clustering behavior mapping in latent space. Third,
we introduce Graph-guided Sequence Synthesis, which constructs a behavior
relationship graph and encodes frequent transitions into prompts, guiding the
LLM to generate data aligned with contextual changes while retaining core
behavior patterns. Finally, we design a Two-stage Outlier Filter to identify
and remove implausible or semantically inconsistent outputs, aiming to improve
the factual coherence and behavioral validity of the generated sequences.
Experiments on three real-world datasets demonstrate that SmartGen
significantly enhances model performance on anomaly detection and behavior
prediction tasks under behavioral drift, with anomaly detection improving by
85.43% and behavior prediction by 70.51% on average. The code is available at
https://github.com/horizonsinzqs/SmartGen.

</details>


### [108] [VQA support to Arabic Language Learning Educational Tool](https://arxiv.org/abs/2508.03488)
*Khaled Bachir Delassi,Lakhdar Zeggane,Hadda Cherroun,Abdelhamid Haouhat,Kaoutar Bouzouad*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We address the problem of scarcity of educational Arabic Language Learning
tools that advocate modern pedagogical models such as active learning which
ensures language proficiency. In fact, we investigate the design and evaluation
of an AI-powered educational tool designed to enhance Arabic language learning
for non-native speakers with beginner-to-intermediate proficiency level. The
tool leverages advanced AI models to generate interactive visual quizzes,
deploying Visual Question Answering as the primary activity. Adopting a
constructivist learning approach, the system encourages active learning through
real-life visual quizzes, and image-based questions that focus on improving
vocabulary, grammar, and comprehension. The system integrates Vision-Language
Pretraining models to generate contextually relevant image description from
which Large Language Model generate assignments based on customized Arabic
language Learning quizzes thanks to prompting.
  The effectiveness of the tool is evaluated through a manual annotated
benchmark consisting of 1266 real-life visual quizzes, with human participants
providing feedback. The results show a suitable accuracy rates, validating the
tool's potential to bridge the gap in Arabic language education and
highlighting the tool's promise as a reliable, AI-powered resource for Arabic
learners, offering personalized and interactive learning experiences.

</details>


### [109] [Error Detection and Correction for Interpretable Mathematics in Large Language Models](https://arxiv.org/abs/2508.03500)
*Yijin Yang,Cristina Cornelio,Mario Leiva,Paulo Shakarian*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Recent large language models (LLMs) have demonstrated the ability to perform
explicit multi-step reasoning such as chain-of-thought prompting. However,
their intermediate steps often contain errors that can propagate leading to
inaccurate final predictions. Additionally, LLMs still struggle with
hallucinations and often fail to adhere to prescribed output formats, which is
particularly problematic for tasks like generating mathematical expressions or
source code. This work introduces EDCIM (Error Detection and Correction for
Interpretable Mathematics), a method for detecting and correcting these errors
in interpretable mathematics tasks, where the model must generate the exact
functional form that explicitly solve the problem (expressed in natural
language) rather than a black-box solution. EDCIM uses LLMs to generate a
system of equations for a given problem, followed by a symbolic error-detection
framework that identifies errors and provides targeted feedback for LLM-based
correction. To optimize efficiency, EDCIM integrates lightweight, open-source
LLMs with more powerful proprietary models, balancing cost and accuracy. This
balance is controlled by a single hyperparameter, allowing users to control the
trade-off based on their cost and accuracy requirements. Experimental results
across different datasets show that EDCIM significantly reduces both
computational and financial costs, while maintaining, and even improving,
prediction accuracy when the balance is properly configured.

</details>


### [110] [Hidden Dynamics of Massive Activations in Transformer Training](https://arxiv.org/abs/2508.03616)
*Jorge Gallego-Feliciano,S. Aaron McClendon,Juan Morinelli,Stavros Zervoudakis,Antonios Saravanos*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Massive activations are scalar values in transformer hidden states that
achieve values orders of magnitude larger than typical activations and have
been shown to be critical for model functionality. While prior work has
characterized these phenomena in fully trained models, the temporal dynamics of
their emergence during training remain poorly understood. We present the first
comprehensive analysis of massive activation development throughout transformer
training, using the Pythia model family as our testbed. Through systematic
analysis of various model sizes across multiple training checkpoints, we
demonstrate that massive activation emergence follows predictable mathematical
patterns that can be accurately modeled using an exponentially-modulated
logarithmic function with five key parameters. We develop a machine learning
framework to predict these mathematical parameters from architectural
specifications alone, achieving high accuracy for steady-state behavior and
moderate accuracy for emergence timing and magnitude. These findings enable
architects to predict and potentially control key aspects of massive activation
emergence through design choices, with significant implications for model
stability, training cycle length, interpretability, and optimization. Our
findings demonstrate that the emergence of massive activations is governed by
model design and can be anticipated, and potentially controlled, before
training begins.

</details>


### [111] [Refining Critical Thinking in LLM Code Generation: A Faulty Premise-based Evaluation Framework](https://arxiv.org/abs/2508.03622)
*Jialin Li,Jinzhe Li,Gengxu Li,Yi Chang,Yuan Wu*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: With the advancement of code generation capabilities in large language models
(LLMs), their reliance on input premises has intensified. When users provide
inputs containing faulty premises, the probability of code generation
hallucinations rises significantly, exposing deficiencies in their
self-scrutiny capabilities. This paper proposes Faulty Premises Bench
(FPBench), the first code generation evaluation framework targeting faulty
premises. By systematically constructing three categories of faulty premises
and integrating multi-dimensional evaluation metrics, it conducts in-depth
assessments of 15 representative LLMs. The key findings are as follows: (1)
Most models exhibit poor reasoning abilities and suboptimal code generation
performance under faulty premises, heavily relying on explicit prompts for
error detection, with limited self-scrutiny capabilities; (2) Faulty premises
trigger a point of diminishing returns in resource investment, leading to
blindly increasing length fails to enhance quality; (3) The three types of
faulty premises respectively activate distinct defect patterns in models,
revealing a triple dissociation in the cognitive mechanisms of code generation
models. This study not only highlights the urgent need for LLMs to proactively
verify premises in code generation but also, through the proposed FPBench
framework and multi-dimensional evaluation system, provides a theoretical
foundation and practical pathway for developing reliable, human-centric code
generation models.

</details>


### [112] [Automated Algorithmic Discovery for Gravitational-Wave Detection Guided by LLM-Informed Evolutionary Monte Carlo Tree Search](https://arxiv.org/abs/2508.03661)
*He Wang,Liang Zeng*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Computational scientific discovery increasingly relies on algorithms to
process complex data and identify meaningful patterns - yet faces persistent
challenges in gravitational-wave signal identification. While existing
algorithmic approaches like matched filtering (MF) and deep neural networks
(DNNs) have achieved partial success, their limitations directly stem from
fundamental limitations: MF's excessive computational demands arise from its
reliance on predefined theoretical waveform templates, while DNNs' black-box
architectures obscure decision logic and introduce hidden biases. We propose
Evolutionary Monte Carlo Tree Search (Evo-MCTS), a framework that addresses
these limitations through systematic algorithm space exploration guided by
domain-aware physical constraints. Our approach combines tree-structured search
with evolutionary optimization and large language model heuristics to create
interpretable algorithmic solutions. Our Evo-MCTS framework demonstrates
substantial improvements, achieving a 20.2\% improvement over state-of-the-art
gravitational wave detection algorithms on the MLGWSC-1 benchmark dataset.
High-performing algorithm variants consistently exceed thresholds. The
framework generates human-interpretable algorithmic pathways that reveal
distinct performance patterns. Beyond performance improvements, our framework
discovers novel algorithmic combinations, thereby establishing a transferable
methodology for automated algorithmic discovery across computational science
domains.

</details>


### [113] [Agent Lightning: Train ANY AI Agents with Reinforcement Learning](https://arxiv.org/abs/2508.03680)
*Xufang Luo,Yuge Zhang,Zhiyuan He,Zilong Wang,Siyun Zhao,Dongsheng Li,Luna K. Qiu,Yuqing Yang*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: We present Agent Lightning, a flexible and extensible framework that enables
Reinforcement Learning (RL)-based training of Large Language Models (LLMs) for
any AI agent. Unlike existing methods that tightly couple RL training with
agent or rely on sequence concatenation with masking, Agent Lightning achieves
complete decoupling between agent execution and training, allowing seamless
integration with existing agents developed via diverse ways (e.g., using
frameworks like LangChain, OpenAI Agents SDK, AutoGen, and building from
scratch) with almost ZERO code modifications. By formulating agent execution as
Markov decision process, we define an unified data interface and propose a
hierarchical RL algorithm, LightningRL, which contains a credit assignment
module, allowing us to decompose trajectories generated by ANY agents into
training transition. This enables RL to handle complex interaction logic, such
as multi-agent scenarios and dynamic workflows. For the system design, we
introduce a Training-Agent Disaggregation architecture, and brings agent
observability frameworks into agent runtime, providing a standardized agent
finetuning interface. Experiments across text-to-SQL, retrieval-augmented
generation, and math tool-use tasks demonstrate stable, continuous
improvements, showcasing the framework's potential for real-world agent
training and deployment.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [114] [Temporal Exploration of Random Spanning Tree Models](https://arxiv.org/abs/2508.03361)
*Samuel Baguley,Andreas Göbel,Nicolas Klodt,George Skretas,John Sylvester,Viktor Zamaraev*

Main category: cs.DM

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: The Temporal Graph Exploration problem (TEXP) takes as input a temporal
graph, i.e., a sequence of graphs $(G_i)_{i\in \mathbb{N}}$ on the same vertex
set, and asks for a walk of shortest length visiting all vertices, where the
$i$-th step uses an edge from $G_i$. If each such $G_i$ is connected, then an
exploration of length $n^2$ exists, and this is known to be the best possible
up to a constant. More fine-grained lower and upper bounds have been obtained
for restricted temporal graph classes, however, for several fundamental
classes, a large gap persists between known bounds, and it remains unclear
which properties of a temporal graph make it inherently difficult to explore.
  Motivated by this limited understanding and the central role of the Temporal
Graph Exploration problem in temporal graph theory, we study the problem in a
randomised setting. We introduce the Random Spanning Tree (RST) model, which
consists of a set of $n$-vertex trees together with an arbitrary probability
distribution $\mu$ over this set. A random temporal graph generated by the RST
model is a sequence of independent samples drawn from $\mu$.
  We initiate a systematic study of the Temporal Graph Exploration problem in
such random temporal graphs and establish tight general bounds on exploration
time. Our first main result proves that any RST model can, with high
probability (w.h.p.), be explored in $O(n^{3/2})$ time, and we show that this
bound is tight up to a constant factor. This demonstrates a fundamental
difference between the adversarial and random settings. Our second main result
shows that if all trees of an RST are subgraphs of a fixed graph with $m$ edges
then, w.h.p.\ , it can be explored in $O(m)$ time.

</details>


### [115] [Adjacent vertex distinguishing total coloring of 3-degenerate graphs](https://arxiv.org/abs/2508.03549)
*Diptimaya Behera,Mathew C. Francis,Sreejith K. Pallathumadam*

Main category: cs.DM

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: A total coloring of a simple undirected graph $G$ is an assignment of colors
to its vertices and edges such that the colors given to the vertices form a
proper vertex coloring, the colors given to the edges form a proper edge
coloring, and the color of every edge is different from that of its two
endpoints. That is, $\phi:V(G)\cup E(G)\rightarrow\mathbb{N}$ is a total
coloring of $G$ if $\phi(u)\neq\phi(v)$ and $\phi(uv)\neq\phi(u)$ for all
$uv\in E(G)$, and $\phi(uv)\neq\phi(uw)$ for any $u \in V(G)$ and distinct $v,w
\in N(u)$ (here, $N(u)$ denotes the set of neighbours of $u$). A total coloring
$\phi$ of a graph $G$ is said to be ``Adjacent Vertex Distinguishing'' (or AVD
for short) if for all $uv\in E(G)$, we have that $\phi(\{u\}\cup\{uw:w\in
N(u)\})\neq\phi(\{v\}\cup\{vw\colon w\in N(v)\})$. The AVD Total Coloring
Conjecture of Zhang, Chen, Li, Yao, Lu, and Wang (Science in China Series A:
Mathematics, 48(3):289--299, 2005) states that every graph $G$ has an AVD total
coloring using at most $\Delta(G)+3$ colors, where $\Delta(G)$ denotes the
maximum degree of $G$. For some $s\in\mathbb{N}$, a graph $G$ is said to be
$s$-degenerate if every subgraph of $G$ has minimum degree at most $s$. Miao,
Shi, Hu, and Luo (Discrete Mathematics, 339(10):2446--2449, 2016) showed that
the AVD Total Coloring Conjecture is true for 2-degenerate graphs. We verify
the conjecture for 3-degenerate graphs.

</details>
