{"id": "2507.21345", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.21345", "abs": "https://arxiv.org/abs/2507.21345", "authors": ["Aniruddha Samanta", "Deepshikha"], "title": "Spectral properties of distance Laplacian matrices of complex unit gain graphs", "comment": "15 pages", "summary": "A complex unit gain graph ($ \\mathbb{T} $-gain graph), $ \\Phi=(G, \\varphi) $\nis a graph where the function $ \\varphi $ assigns a unit complex number to each\norientation of an edge of $ G $, and its inverse is assigned to the opposite\norientation. In this article, we study several spectral properties of distance\nLaplacian matrices of $\\mathbb{T}$-gain graphs. In particular, we establish a\ncharacterization for the balanced $ \\mathbb{T}$-gain graph in terms of the\nnullity of gain distance Laplacian matrices. As an example, it is shown that\ntwo switching equivalent $ \\mathbb{T} $-gain graphs need not imply that their\ndistance Laplacian spectra are the same. However, we provide a necessary\ncondition for which two switching equivalent $ \\mathbb{T} $-gain graphs have\nthe same distance Laplacian spectra. Furthermore, we present a lower bound for\nspectral radii of gain distance Laplacian matrices in terms of the winner\nindex. In addition, we establish some upper bounds for spectral radii of gain\ndistance Laplacian matrices and characterize the equalities.", "AI": {"tldr": "本文研究了$\\mathbb{T}$-增益图的距离拉普拉斯矩阵的若干谱性质，包括平衡性判据、切换等价图的谱关系、谱半径的上下界及其等式条件。", "motivation": "探索$\\mathbb{T}$-增益图的距离拉普拉斯矩阵的谱特性，以深化对这类图结构的数学理解。", "method": "通过分析增益图的距离拉普拉斯矩阵，建立平衡性判据，并研究切换等价性与谱不变性的关系，推导谱半径的界。", "result": "证明了平衡$\\mathbb{T}$-增益图的零空间判据；发现切换等价性不保证谱相同，但给出了谱相同的必要条件；获得了谱半径的上下界及等式成立条件。", "conclusion": "该研究系统建立了$\\mathbb{T}$-增益图距离拉普拉斯矩阵的谱理论框架，为后续研究提供了重要工具。"}}
{"id": "2507.21381", "categories": ["math.CO", "05"], "pdf": "https://arxiv.org/pdf/2507.21381", "abs": "https://arxiv.org/abs/2507.21381", "authors": ["Munagala V. S. Ramanath"], "title": "Non-Hamiltonian 2-regular Digraphs", "comment": null, "summary": "In earlier papers, we showed a decomposition of 2-diregular digraphs (2-dds)\nand used it to provide some sufficient conditions for these graphs to be\nnon-Hamiltonian; we also showed a close connection between the permanent and\ndeterminant of the adjacency matrices of these digraphs and gave some\nenumeration and generation results. In the present paper we extend the\ndiscussion to a larger class of digraphs, introduce the notions of routes and\nquotients and use them to provide additional criteria for 2-dds to be\nnon-Hamiltonian. Though individual non-Hamiltonian regular connected graphs of\nlow degree are known (e.g. Tutte and Meredith graphs), families of such graphs\nare not common in the literature; even scarcer are families of such digraphs.\nOur results identify a few such families.", "AI": {"tldr": "本文扩展了2-正则有向图(2-dds)的研究，引入路径和商的概念，提出了新的非哈密尔顿性判定标准，并识别了几类罕见的非哈密尔顿有向图家族。", "motivation": "先前研究已发现2-dds的分解特性及其与邻接矩阵行列式/永久式的关联，但缺乏系统性的非哈密尔顿图家族分类。本文旨在填补这一空白。", "method": "通过引入路径(routes)和商(quotients)的新概念，构建理论框架分析2-dds结构特性，并开发非哈密尔顿性判定准则。", "result": "建立了多个2-dds非哈密尔顿性的充分条件，识别出文献中罕见的连通正则非哈密尔顿有向图家族。", "conclusion": "研究成果扩展了有向图理论工具集，特别为低度数正则有向图的非哈密尔顿性研究提供了新范式。"}}
{"id": "2507.21421", "categories": ["math.CO", "05C15, 05C30, 05C69"], "pdf": "https://arxiv.org/pdf/2507.21421", "abs": "https://arxiv.org/abs/2507.21421", "authors": ["Hemanshu Kaul", "Jeffrey A. Mudrock", "Gunjan Sharma"], "title": "On the DP-chromatic Number of Cartesian Products of Critical Graphs", "comment": "15 pages, 4 figures", "summary": "DP-coloring (also called correspondence coloring) is a well-studied\ngeneralization of list coloring introduced by Dvo\\v{r}\\'{a}k and Postle in\n2015. The following sharp bound on the DP-chromatic number of the Cartesian\nproduct of graphs $G$ and $H$ is known: $\\chi_{DP}(G \\square H) \\leq\n\\text{min}\\{\\chi_{DP}(G) + \\text{col}(H), \\chi_{DP}(H) + \\text{col}(G) \\} - 1$\nwhere $\\chi_{DP}(G)$ is the DP-chromatic number of $G$ and $\\text{col}(H)$ is\nthe coloring number of $H$. We seek to understand when $\\chi_{DP}(G \\square\nK_{l,t})$ is far from its chromatic number: $\\chi(G \\square K_{l,t}) = \\max\n\\{\\chi(G), 2 \\}$ in the case that $G$ is a $k$-critical graph with\n$\\chi_{DP}(G)=k$. In particular, we have $\\chi_{DP}(G \\square K_{l,t}) \\leq k +\nl$, and for fixed $l$ we wish to find the smallest $t$ for which this upper\nbound is achieved. This can be viewed as an extension of the classic result\nthat the list chromatic number of $K_{l,t}$ is $l+1$ if and only if $t \\geq\nl^l$. Our results illustrate that the DP color function of $G$, the DP analogue\nof the chromatic polynomial, provides a concept and tool that is useful for\nmaking progress on this problem.", "AI": {"tldr": "本文研究了DP着色（对应着色）在图笛卡尔积上的性质，特别是针对k-临界图G与完全二分图K_{l,t}的积图，探讨了其DP色数与色数之间的差距，并利用DP色函数工具取得了相关进展。", "motivation": "研究动机在于理解当G是k-临界图且$\\chi_{DP}(G)=k$时，$\\chi_{DP}(G \\square K_{l,t})$与其色数$\\chi(G \\square K_{l,t})$的差距，特别是寻找使得上界$k+l$达到的最小t值。", "method": "方法上，作者利用DP色函数（DP color function）作为工具，这是色多项式的DP类比，用于分析和解决这一问题。", "result": "结果表明，$\\chi_{DP}(G \\square K_{l,t}) \\leq k + l$，并且对于固定的l，找到了使得这一上界达到的最小t值，这与经典结果中$K_{l,t}$的列表色数为$l+1$当且仅当$t \\geq l^l$的情形类似。", "conclusion": "结论指出，DP色函数作为一个概念和工具，对于解决此类问题具有重要价值，为理解DP着色在图积上的行为提供了新的视角和方法。"}}
{"id": "2507.21487", "categories": ["math.CO", "05C99 (Primary) 05C35, 68W05 (Secondary)", "G.2.2"], "pdf": "https://arxiv.org/pdf/2507.21487", "abs": "https://arxiv.org/abs/2507.21487", "authors": ["I. M. J. McInnis"], "title": "Slavic Techniques for Hat Guessing Algorithms", "comment": "111pp", "summary": "2023 undergraduate thesis on a deterministic \"hat game.\" For a digraph $D$,\neach player stands on a vertex $v$, is assigned a hat from $h(v)$ possible\ncolors, and makes $g(v)$ guesses of her hat's color based on her out-neighbors'\nhats. If there exists a collective strategy that guarantees a correct guess for\nany hat assignment, the game is winnable. Which games $(D,g,h)$ are winnable?\nTwo much-studied parameters: $\\mu(D)$ is the maximum integer $k$ such that\n$(D,1,k)$ is winnable, and $\\hat{\\mu}(D)$ is the supremum of $h/g$ for integer\n$h, g$ such that $(D,g,h)$ is winnable.\n  Chapter 0 is a casual, riddle-based introduction. Chapter 1 taxonomizes the\ngames, surveys all previous work, and summarizes the piece. Chapter 2 proves\nlemmata and easy cases. Chapter 3 uses \"hats as hints\" and \"admissible paths\"\nfor games on cycles. Chapter 4 generalizes several \"constructors\" and applies\nthem to tree games. Chapter 5 uses \"combinatorial prisms\" for a new angle on\nthe well-studied $K_{n,m}$ games. In chapter 6, we apply \"dependency digraphs\"\nto the continuous limit of this game. Chapter 7 collects open problems and\nminor results.\n  We show:\n  $(C_{k\\geq 4},1,h)$ is winnable if and only if: $h=3$ and $k$ is divisible by\n$3$ or equal to $4$, $h\\leq 4$ and the $h(v)$ sequence $(3,2,3)$ or $(2,3,3)$\nappears in the cycle, or the $h(v)$ sequence $(2,...,2)$ appears with no\nintervening value $>4$.\n  $(T, 1, h)$ is winnable for tree $T$ iff $T$ has a subtree $T'$ with\n$h(v)\\leq 2^{deg_{T'}(v)}$ for all $v\\in V(T')$.\n  For a digraph $D$, $\\hat{\\mu}(D)\\leq e(\\Delta^-+1)$. For a graph $G$,\n$\\hat{\\mu}(G)\\leq (\\Delta-1)^{1-\\Delta} \\Delta^{\\Delta}<e\\Delta$.\n  $(\\overrightarrow{C}_k, g, h)$ is unwinnable if $g(v_i)/h(v_i) +\ng(v_{i+1})/h(v_{i+1}) < 1$ for some $i$.\n  And much else. Important open questions: what other graph parameters or\nproperties bound $\\mu$? What complexity classes are at play?", "AI": {"tldr": "2023年本科论文研究确定性'帽子游戏'。在有向图$D$中，玩家根据邻居的帽子颜色猜测自己的帽子颜色。论文探讨了哪些游戏$(D,g,h)$是可赢的，并研究了参数$\\mu(D)$和$\\hat{\\mu}(D)$。", "motivation": "研究帽子游戏的可赢性条件，探索图参数与游戏可赢性之间的关系，解决开放性问题。", "method": "使用'帽子作为提示'、'可接受路径'、'组合棱镜'和'依赖有向图'等方法，分析循环、树和完全二分图等特定图结构的游戏。", "result": "证明了循环游戏$(C_{k\\geq4},1,h)$的可赢条件，树游戏$(T,1,h)$的可赢性取决于子树$T'$的条件，以及有向图$D$的参数$\\hat{\\mu}(D)$的上界。", "conclusion": "论文提供了多种图结构下帽子游戏的可赢性条件，并提出了未解决的开放性问题，如图参数如何限制$\\mu$以及涉及的复杂性类别。"}}
{"id": "2507.21067", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.21067", "abs": "https://arxiv.org/abs/2507.21067", "authors": ["Jan Kapusta"], "title": "SynLang and Symbiotic Epistemology: A Manifesto for Conscious Human-AI Collaboration", "comment": "32 pages, 4 figures. Includes 2 Appendices containing SynLang v1.2.0\n  protocol specification, and formal BNF grammar", "summary": "Current AI systems rely on opaque reasoning processes that hinder human\noversight and collaborative potential. Conventional explainable AI approaches\noffer post-hoc justifications and often fail to establish genuine symbiotic\ncollaboration. In this paper, the Symbiotic Epistemology is presented as a\nphilosophical foundation for human-AI cognitive partnerships. Unlike frameworks\nthat treat AI as a mere tool or replacement, symbiotic epistemology positions\nAI as a reasoning partner, fostering calibrated trust by aligning human\nconfidence with AI reliability through explicit reasoning patterns and\nconfidence assessments. SynLang (Symbiotic Syntactic Language) is introduced as\na formal protocol for transparent human-AI collaboration. The framework is\nempirically validated through actual human-AI dialogues demonstrating AI's\nadaptation to structured reasoning protocols and successful metacognitive\nintervention. The protocol defines two complementary mechanisms: TRACE for\nhigh-level reasoning patterns and TRACE_FE for detailed factor explanations. It\nalso integrates confidence quantification, declarative control over AI\nbehavior, and context inheritance for multi-agent coordination. By structuring\ncommunication and embedding confidence-calibrated transparency, SynLang,\ntogether with symbiotic epistemology, enables AI systems that enhance human\nintelligence, preserve human agency, and uphold ethical accountability in\ncollaborative decision-making. Through dual-level transparency, beginning with\nhigh-level reasoning patterns and progressing to granular explanations, the\nprotocol facilitates rapid comprehension and supports thorough verification of\nAI decision-making.", "AI": {"tldr": "本文提出共生认识论作为人机认知合作的哲学基础，并引入SynLang协议实现透明协作，通过双层级透明度机制增强人类对AI决策的理解与信任。", "motivation": "现有AI系统推理过程不透明，传统可解释性方法难以实现真正的人机共生协作，需建立新型认知伙伴关系框架。", "method": "开发SynLang协议（含TRACE高层推理模式与TRACE_FE细节解释机制），整合置信度量化、声明式行为控制及多智能体上下文继承。", "result": "实证验证显示AI能适应结构化推理协议，成功实施元认知干预，实现校准信任的透明决策协作。", "conclusion": "共生认识论与SynLang通过双层级透明度设计，在保留人类能动性的同时提升协作决策的伦理可问责性。"}}
{"id": "2507.21060", "categories": ["cs.CR", "cs.AI", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.21060", "abs": "https://arxiv.org/abs/2507.21060", "authors": ["Abdullah Al Siam", "Sadequzzaman Shohan"], "title": "Privacy-Preserving AI for Encrypted Medical Imaging: A Framework for Secure Diagnosis and Learning", "comment": null, "summary": "The rapid integration of Artificial Intelligence (AI) into medical\ndiagnostics has raised pressing concerns about patient privacy, especially when\nsensitive imaging data must be transferred, stored, or processed. In this\npaper, we propose a novel framework for privacy-preserving diagnostic inference\non encrypted medical images using a modified convolutional neural network\n(Masked-CNN) capable of operating on transformed or ciphered image formats. Our\napproach leverages AES-CBC encryption coupled with JPEG2000 compression to\nprotect medical images while maintaining their suitability for AI inference. We\nevaluate the system using public DICOM datasets (NIH ChestX-ray14 and\nLIDC-IDRI), focusing on diagnostic accuracy, inference latency, storage\nefficiency, and privacy leakage resistance. Experimental results show that the\nencrypted inference model achieves performance comparable to its unencrypted\ncounterpart, with only marginal trade-offs in accuracy and latency. The\nproposed framework bridges the gap between data privacy and clinical utility,\noffering a practical, scalable solution for secure AI-driven diagnostics.", "AI": {"tldr": "本文提出了一种基于加密医学图像的隐私保护诊断框架，采用改进的卷积神经网络（Masked-CNN）处理加密图像，结合AES-CBC加密与JPEG2000压缩技术，在保证AI推理性能的同时保护患者隐私。", "motivation": "人工智能在医疗诊断中的快速应用引发了患者隐私保护的迫切需求，特别是在敏感影像数据的传输、存储和处理过程中。", "method": "提出了一种新型框架，通过改进的卷积神经网络（Masked-CNN）处理加密或转换后的医学图像，结合AES-CBC加密和JPEG2000压缩技术，确保图像在加密状态下仍适用于AI推理。", "result": "实验使用公开的DICOM数据集（NIH ChestX-ray14和LIDC-IDRI）评估系统性能，结果显示加密推理模型在诊断准确性、推理延迟、存储效率和隐私泄漏抵抗方面表现接近未加密模型，仅存在边际性能损失。", "conclusion": "该框架在数据隐私与临床实用性之间架起了桥梁，为安全的AI驱动诊断提供了一种实用且可扩展的解决方案。"}}
{"id": "2507.21366", "categories": ["math.LO", "03C45"], "pdf": "https://arxiv.org/pdf/2507.21366", "abs": "https://arxiv.org/abs/2507.21366", "authors": ["James E. Hanson"], "title": "A combinatorial characterization of Kim's lemma for pairs of bi-invariant types", "comment": "25 pages, 8 figures", "summary": "We give a combinatorial consistency-inconsistency configuration that is\nequivalent to the failure of the following form of Kim's lemma for a given $k$:\n$(\\star)$ For any set of parameters $A$, formula $\\varphi(x,b)$, and\n$A$-bi-invariant types $p$ and $q$ extending $\\mathrm{tp}(b/A)$, if\n$\\varphi(x,b)$ $k$-divides along $p$, then it divides along $q$.\n  We then give an equivalent technical variant of $(\\star)$ that is non-trivial\nover arbitrary invariance bases. We also show that the failure of weaker\nversions of $(\\star)$ entails the existence of stronger combinatorial\nconfigurations, the strongest of which can be phrased in terms of families of\nparameters indexed by arbitrary cographs (i.e., $P_4$-free graphs).\n  Finally, we show that if there is an array $(b_{i,j} : i,j < \\omega)$ of\nparameters such that $\\{\\varphi(x,b_{i,j}) : (i,j) \\in C\\}$ is consistent\nwhenever $C \\subseteq \\omega^2$ is a chain (in the product partial order) and\n$k$-inconsistent whenever $C$ is an antichain, then there is a model $M$,\nparameter $b$, and $M$-coheirs $p,q \\supset \\mathrm{tp}(b/M)$ such that\n$q^{\\otimes \\omega}$ is an $M$-heir-coheir and $\\varphi(x,b)$ $k$-divides along\n$p$ but does not divide along $q$. In doing so, we also show that this\nconfiguration entails the failure of generic stationary local character under\nthe assumption of $\\mathsf{GCH}$.", "AI": {"tldr": "本文通过组合构型研究了Kim引理在特定条件下的失效情况，建立了参数阵列与模型理论性质间的联系，并探讨了在$\\mathsf{GCH}$假设下通用平稳局部特征的失效。", "motivation": "研究Kim引理形式$(\\star)$的失效条件及其组合等价构型，探索模型理论中参数类型与公式可除性的深层关系。", "method": "构建组合一致性-不一致性构型，提出非平凡技术变体$(\\star)$，分析无$P_4$图参数族，并通过链-反链阵列验证$k$-可除性差异。", "result": "证明当存在满足链一致/反链$k$-不一致的参数阵列时，必存在模型$M$使得$\\varphi(x,b)$沿$p$的$k$-可除性不同于沿$q$的可除性，且该构型导致$\\mathsf{GCH}$下通用平稳局部特征失效。", "conclusion": "通过组合方法揭示了Kim引理失效的精确条件，建立了阵列性质与类型可除性的对应关系，为模型理论中的可除性研究提供了新工具。"}}
{"id": "2507.21339", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.21339", "abs": "https://arxiv.org/abs/2507.21339", "authors": ["Debanjana Kundu", "Katharina Mueller"], "title": "Iwasawa Theory of Elliptic Curves in Quadratic Twist Families", "comment": null, "summary": "In this article, we use two different approaches -- one algebraic and the\nother analytic -- to study the variation of Iwasawa invariants of rational\nelliptic curves in some quadratic twist families.", "AI": {"tldr": "本文通过代数与解析两种方法研究了有理椭圆曲线在二次扭转族中Iwasawa不变量\\的变化规律。", "motivation": "探索有理椭圆曲线在二次扭转族中Iwasawa不变量\\的变化特性，以深化对椭圆曲线算术性质的理解。", "method": "采用代数与解析两种互补的研究方法，系统分析二次扭转对Iwasawa不变量\\的影响。", "result": "揭示了不同二次扭转下Iwasawa不变量\\的变化模式，为相关理论提供了新的实证依据。", "conclusion": "双方法研究证实了二次扭转族中Iwasawa不变量\\具有规律性变化特征，为后续研究奠定了方法论基础。"}}
{"id": "2507.21281", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.21281", "abs": "https://arxiv.org/abs/2507.21281", "authors": ["Hardy Pinto", "Tiago Roux Oliveira", "Liu Hsu"], "title": "Sliding Mode Control for Uncertain Systems with Time-Varying Delays via Predictor Feedback and Super-Twisting Observer", "comment": "15 pages, 8 figures", "summary": "This paper introduces a novel stabilization control strategy for linear\ntime-invariant systems affected by known time-varying measurement delays and\nmatched unknown nonlinear disturbances, which may encompass actuator faults. It\nis considered that part of the state vector is not available for real-time\nmeasurement. To address this, the proposed approach combines an open-loop\npredictor with a state observer designed using the Super-Twisting Algorithm,\naiming to compensate for the delays and estimate the unmeasured state\ncomponents. Specifically, the nonlinear observer-based framework enables the\nreconstruction of unmodeled fault signals without assuming that they originate\nfrom a known exogenous system, offering robustness against parametric\nuncertainties. Meanwhile, the predictor forwards the delayed output in time.\nSubsequently, a sliding mode control law is formulated to enforce an ideal\nsliding mode and ensure global stabilization, even under a broader class of\nperturbations, unmodeled disturbances, parametric uncertainties, and delays,\nowing to the integration of the Super-Twisting observer. Numerical simulations\nillustrate the efficiency of the proposed approach.", "AI": {"tldr": "本文提出了一种针对受已知时变测量延迟和匹配未知非线性扰动（可能包含执行器故障）影响的线性时不变系统的稳定控制策略。该方法结合了开环预测器和基于超螺旋算法的状态观测器，以补偿延迟并估计未测量的状态分量。", "motivation": "针对部分状态向量无法实时测量且存在时变延迟和非线性扰动（包括执行器故障）的系统，需要一种鲁棒的控制策略来确保全局稳定性。", "method": "采用开环预测器与基于超螺旋算法的状态观测器相结合的方法，补偿延迟并估计未测量状态分量；同时设计滑模控制律，确保在扰动、未建模干扰、参数不确定性和延迟下的全局稳定。", "result": "数值仿真表明，所提出的方法能够有效补偿延迟并估计未测量状态，同时在广泛的扰动和不确定性下实现全局稳定。", "conclusion": "该方法通过结合超螺旋观测器和滑模控制，为受时变延迟和非线性扰动的系统提供了一种鲁棒的稳定控制策略，具有广泛的应用潜力。"}}
{"id": "2507.21864", "categories": ["cs.DM", "cs.CG"], "pdf": "https://arxiv.org/pdf/2507.21864", "abs": "https://arxiv.org/abs/2507.21864", "authors": ["Yuto Okada"], "title": "Pathwidth of 2-Layer $k$-Planar Graphs", "comment": "7 pages, 5 figures", "summary": "A bipartite graph $G = (X \\cup Y, E)$ is a 2-layer $k$-planar graph if it\nadmits a drawing on the plane such that the vertices in $X$ and $Y$ are placed\non two parallel lines respectively, edges are drawn as straight-line segments,\nand every edge involves at most $k$ crossings. Angelini, Da Lozzo, F\\\"orster,\nand Schneck [GD 2020; Comput. J., 2024] showed that every 2-layer $k$-planar\ngraph has pathwidth at most $k + 1$. In this paper, we show that this bound is\nsharp by giving a 2-layer $k$-planar graph with pathwidth $k + 1$ for every $k\n\\geq 0$. This improves their lower bound of $(k+3)/2$.", "AI": {"tldr": "本文证明了2层$k$-平面图的路径宽度上界$k+1$是紧的，通过构造路径宽度为$k+1$的实例改进了先前下界$(k+3)/2$。", "motivation": "Angelini等人[GD 2020; Comput. J., 2024]证明了2层$k$-平面图的路径宽度至多为$k+1$，但未验证该上界是否紧。本研究旨在填补这一理论空白。", "method": "针对每个$k\\geq 0$，显式构造了一个2层$k$-平面图实例，其顶点集$X,Y$分别置于平行线上，边为直线段且交叉数不超过$k$。", "result": "所构造的图例具有精确的路径宽度$k+1$，证明原上界不可改进，显著优于先前$(k+3)/2$的下界结果。", "conclusion": "该研究完整解决了2层$k$-平面图路径宽度的紧界问题，确立了$k+1$为最优上界，推动了图绘制与宽度参数的理论研究。"}}
{"id": "2507.21465", "categories": ["math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.21465", "abs": "https://arxiv.org/abs/2507.21465", "authors": ["Rina Foygel Barber", "Richard J Samworth"], "title": "False discovery rate control with compound p-values", "comment": null, "summary": "In the setting of multiple testing, compound p-values generalize p-values by\nasking for superuniformity to hold only \\emph{on average} across all true\nnulls. We study the properties of the Benjamini--Hochberg procedure applied to\ncompound p-values. Under independence, we show that the false discovery rate\n(FDR) is at most $1.93\\alpha$, where $\\alpha$ is the nominal level, and exhibit\na distribution for which the FDR is $\\frac{7}{6}\\alpha$. If additionally all\nnulls are true, then the upper bound can be improved to $\\alpha + 2\\alpha^2$,\nwith a corresponding worst-case lower bound of $\\alpha + \\alpha^2/4$. Under\npositive dependence, on the other hand, we demonstrate that FDR can be inflated\nby a factor of $O(\\log m)$, where~$m$ is the number of hypotheses. We provide\nnumerous examples of settings where compound p-values arise in practice, either\nbecause we lack sufficient information to compute non-trivial p-values, or to\nfacilitate a more powerful analysis.", "AI": {"tldr": "本文研究了在多重检验中使用复合p值时，Benjamini-Hochberg程序的错误发现率(FDR)控制特性。结果表明，在独立性条件下FDR上限为$1.93\\alpha$，而在所有零假设均为真时上限可改进为$\\alpha + 2\\alpha^2$。但在正相关条件下，FDR可能膨胀$O(\\log m)$倍。", "motivation": "复合p值通过仅要求真实零假设的p值在平均意义上满足超均匀性，为多重检验提供了更灵活的框架。研究其在Benjamini-Hochberg程序下的FDR控制特性具有重要理论价值。", "method": "通过理论分析研究复合p值在Benjamini-Hochberg程序下的表现，分别考察独立性、全零假设成立和正相关三种情况下的FDR控制特性。", "result": "在独立性下FDR上限为$1.93\\alpha$（存在$\\frac{7}{6}\\alpha$的实例）；全零假设时上限改进为$\\alpha + 2\\alpha^2$（下限$\\alpha + \\alpha^2/4$）；正相关时FDR可能膨胀$O(\\log m)$倍。", "conclusion": "复合p值在多重检验中具有实用价值，但其FDR控制特性依赖于数据依赖结构。它为信息不足或追求更高检验功效的场景提供了新思路。"}}
{"id": "2507.21360", "categories": ["cs.AI", "cs.HC", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2507.21360", "abs": "https://arxiv.org/abs/2507.21360", "authors": ["Nicholas Botti", "Flora Haberkorn", "Charlotte Hoopes", "Shaun Khan"], "title": "Efficacy of AI RAG Tools for Complex Information Extraction and Data Annotation Tasks: A Case Study Using Banks Public Disclosures", "comment": null, "summary": "We utilize a within-subjects design with randomized task assignments to\nunderstand the effectiveness of using an AI retrieval augmented generation\n(RAG) tool to assist analysts with an information extraction and data\nannotation task. We replicate an existing, challenging real-world annotation\ntask with complex multi-part criteria on a set of thousands of pages of public\ndisclosure documents from global systemically important banks (GSIBs) with\nheterogeneous and incomplete information content. We test two treatment\nconditions. First, a \"naive\" AI use condition in which annotators use only the\ntool and must accept the first answer they are given. And second, an\n\"interactive\" AI treatment condition where annotators use the tool\ninteractively, and use their judgement to follow-up with additional information\nif necessary. Compared to the human-only baseline, the use of the AI tool\naccelerated task execution by up to a factor of 10 and enhanced task accuracy,\nparticularly in the interactive condition. We find that when extrapolated to\nthe full task, these methods could save up to 268 hours compared to the\nhuman-only approach. Additionally, our findings suggest that annotator skill,\nnot just with the subject matter domain, but also with AI tools, is a factor in\nboth the accuracy and speed of task performance.", "AI": {"tldr": "研究通过随机任务分配的组内设计，评估AI检索增强生成(RAG)工具在信息提取和数据标注任务中的效果，发现交互式AI使用能提升10倍效率并提高准确性，节省268小时工作量。", "motivation": "探索AI工具（特别是RAG技术）在复杂多标准信息提取任务中，对分析师工作效率和准确性的实际影响，尤其是交互式使用方式的效果。", "method": "采用组内随机任务设计，复现全球系统重要性银行(GSIB)公开披露文件的真实标注任务，对比纯人工基线、\"被动接受\"AI输出和\"交互式\"AI使用三种条件。", "result": "AI工具使任务速度提升高达10倍，交互式条件准确性更高；全任务可节省268小时；标注员对AI工具的熟练度显著影响表现。", "conclusion": "交互式AI工具能大幅提升复杂标注任务的效率与质量，但需同时培养领域专业知识与AI工具使用技能。"}}
{"id": "2507.21565", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.21565", "abs": "https://arxiv.org/abs/2507.21565", "authors": ["Yipei Zhang", "Xiumei Wang"], "title": "Solid bricks that every $b$-invariant edge is solitary", "comment": null, "summary": "A graph $G$ is a brick if it is 3-connected and $G-\\{u,v\\}$ has a perfect\nmatching for any two distinct vertices $u$ and $v$ of $G$. A brick $G$ is solid\nif for any two vertex disjoint odd cycles $C_1$ and $C_2$ of $G$,\n$G-(V(C_1)\\cup V(C_2))$ has no perfect matching. Lucchesi and Murty proposed a\nproblem concerning the characterization of bricks, distinct from $K_4$,\n$\\overline{C_6}$ and the Petersen graph, in which every $b$-invariant edge is\nsolitary. In this paper, we show that for a solid brick $G$ of order $n$ that\nis distinct from $K_4$, every $b$-invariant edge of $G$ is solitary if and only\nif $G$ is a wheel $W_n$.", "AI": {"tldr": "本文证明了对于不同于$K_4$的实心砖块图$G$，其所有$b$-不变边都是孤立的当且仅当$G$是轮图$W_n$。", "motivation": "Lucchesi和Murty提出了一个关于砖块图特征的问题，特别是那些不同于$K_4$、$\\overline{C_6}$和Petersen图的图，其中所有$b$-不变边都是孤立的。本文旨在解决这一问题。", "method": "通过研究实心砖块图的性质，特别是其顶点和边的关系，以及完美匹配的条件，来探讨$b$-不变边的孤立性。", "result": "结果表明，对于不同于$K_4$的实心砖块图$G$，所有$b$-不变边都是孤立的当且仅当$G$是轮图$W_n$。", "conclusion": "本文的结论为Lucchesi和Murty提出的问题提供了一个明确的解答，即只有在轮图$W_n$中，所有$b$-不变边才是孤立的。"}}
{"id": "2507.21098", "categories": ["cs.AI", "cs.CY", "I.2.6; I.2.1; H.4.2"], "pdf": "https://arxiv.org/pdf/2507.21098", "abs": "https://arxiv.org/abs/2507.21098", "authors": ["Marta Sidorkiewicz", "Karolina Królikowska", "Berenika Dyczek", "Edyta Pijet-Migon", "Anna Dubel"], "title": "Artificial intelligence for sustainable wine industry: AI-driven management in viticulture, wine production and enotourism", "comment": "6 pages, 4 figures. Accepted for presentation at the 27th European\n  Conference on Artificial Intelligence (ECAI 2025), October 19-24, 2025,\n  Bologna, Italy", "summary": "This study examines the role of Artificial Intelligence (AI) in enhancing\nsustainability and efficiency within the wine industry. It focuses on AI-driven\nintelligent management in viticulture, wine production, and enotourism. As the\nwine industry faces environmental and economic challenges, AI offers innovative\nsolutions to optimize resource use, reduce environmental impact, and improve\ncustomer engagement. Understanding AI's potential in sustainable winemaking is\ncrucial for fostering responsible and efficient industry practices. The\nresearch is based on a questionnaire survey conducted among Polish winemakers,\ncombined with a comprehensive analysis of AI methods applicable to viticulture,\nproduction, and tourism. Key AI technologies, including predictive analytics,\nmachine learning, and computer vision, are explored. The findings indicate that\nAI enhances vineyard monitoring, optimizes irrigation, and streamlines\nproduction processes, contributing to sustainable resource management. In\nenotourism, AI-powered chatbots, recommendation systems, and virtual tastings\npersonalize consumer experiences. The study highlights AI's impact on economic,\nenvironmental, and social sustainability, supporting local wine enterprises and\ncultural heritage. Keywords: Artificial Intelligence, Sustainable Development,\nAI-Driven Management, Viticulture, Wine Production, Enotourism, Wine\nEnterprises, Local Communities", "AI": {"tldr": "本研究探讨人工智能（AI）在提升葡萄酒产业可持续性与效率中的作用，涵盖葡萄种植、葡萄酒生产和葡萄酒旅游三大领域，通过问卷调研和技术分析揭示AI在资源优化、环境保护及客户体验方面的潜力。", "motivation": "葡萄酒产业面临环境与经济挑战，AI技术为可持续酿造和高效管理提供创新解决方案，对推动行业负责任实践至关重要。", "method": "基于对波兰酿酒师的问卷调查，结合AI技术在葡萄种植、生产及旅游中的适用性分析，重点研究预测分析、机器学习和计算机视觉等关键技术。", "result": "AI可提升葡萄园监测精度、优化灌溉系统并简化生产流程，实现资源可持续管理；在葡萄酒旅游中，AI驱动的聊天机器人、推荐系统和虚拟品鉴能个性化消费者体验。", "conclusion": "AI对经济、环境和社会可持续性具有显著影响，支持本土葡萄酒企业及文化遗产保护，为行业未来发展提供技术支撑。"}}
{"id": "2507.21061", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.21061", "abs": "https://arxiv.org/abs/2507.21061", "authors": ["Petr Spelda", "Vit Stritecky"], "title": "Security practices in AI development", "comment": "11 pages", "summary": "What makes safety claims about general purpose AI systems such as large\nlanguage models trustworthy? We show that rather than the capabilities of\nsecurity tools such as alignment and red teaming procedures, it is security\npractices based on these tools that contributed to reconfiguring the image of\nAI safety and made the claims acceptable. After showing what causes the gap\nbetween the capabilities of security tools and the desired safety guarantees,\nwe critically investigate how AI security practices attempt to fill the gap and\nidentify several shortcomings in diversity and participation. We found that\nthese security practices are part of securitization processes aiming to support\n(commercial) development of general purpose AI systems whose trustworthiness\ncan only be imperfectly tested instead of guaranteed. We conclude by offering\nseveral improvements to the current AI security practices.", "AI": {"tldr": "本文探讨了通用AI系统（如大语言模型）安全声明的可信度问题，指出安全实践而非工具本身重塑了AI安全形象，并揭示了当前实践的局限性与商业化导向。", "motivation": "研究旨在揭示为何通用AI系统的安全声明被认为可信，并分析安全工具能力与理想保障之间的差距根源。", "method": "通过批判性分析AI安全实践如何填补工具能力与安全承诺的鸿沟，评估了多样性及参与度等维度的缺陷。", "result": "发现当前安全实践本质上是为无法完全验证可信度的通用AI商业化开发服务的\"安全化\"过程。", "conclusion": "提出改进现有AI安全实践的建议，强调需超越工具层面，构建更全面、包容的安全验证框架。"}}
{"id": "2507.21575", "categories": ["math.LO", "20F36, 03C60"], "pdf": "https://arxiv.org/pdf/2507.21575", "abs": "https://arxiv.org/abs/2507.21575", "authors": ["Alberto Cassella", "Gianluca Paolini", "Giovanni Paolini"], "title": "First-order aspects of Artin groups", "comment": null, "summary": "We prove several results on the model theory of Artin groups, focusing on\nArtin groups which are ``far from right-angled Artin groups''. The first result\nis that if $\\mathcal{C}$ is a class of Artin groups whose irreducible\ncomponents are acylindrically hyperbolic and torsion-free, then the model\ntheory of Artin groups of type $\\mathcal{C}$ reduces to the model theory of its\nirreducible components. The second result is that the problem of superstability\nof a given non-abelian Artin group $A$ reduces to certain dihedral parabolic\nsubgroups of $A$ being $n$-pure in $A$, for certain large enough primes $n \\in\n\\mathbb{N}$. The third result is that two spherical Artin groups are elementary\nequivalent if and only if they are isomorphic. Finally, we prove that the\naffine Artin groups of type $\\tilde{A}_n$, for $n \\geq 4$, can be distinguished\nfrom the other simply laced affine Artin groups using existential sentences;\nthis uses homology results of independent interest relying on the recent proof\nof the $K(\\pi, 1)$ conjecture for affine Artin groups.", "AI": {"tldr": "本文研究了Artin群的模型理论，重点关注了与右角Artin群差异较大的Artin群。证明了若干结果，包括模型理论的可约性、超稳定性问题、球面Artin群的初等等价性，以及仿射Artin群的区分方法。", "motivation": "研究Artin群的模型理论性质，特别是那些与右角Artin群差异较大的Artin群，以深化对这类群的理论理解。", "method": "通过分析Artin群的不可约分量、双曲性质和无挠性，以及利用抛物子群的纯性条件，结合同调理论和$K(\\pi, 1)$猜想的最新证明结果。", "result": "1) 对于不可约分量为双曲无挠的Artin群，其模型理论可约至不可约分量；2) 非交换Artin群的超稳定性问题可约至特定二面体抛物子群的纯性；3) 球面Artin群初等等价当且仅当同构；4) 仿射Artin群$\\tilde{A}_n$（$n\\geq4$）可通过存在语句与其他单链仿射Artin群区分。", "conclusion": "本文为Artin群的模型理论提供了新的理论工具和结果，特别是在可约性、超稳定性和初等等价性方面，同时展示了同调理论在区分Artin群中的重要作用。"}}
{"id": "2507.21352", "categories": ["math.NT", "hep-th"], "pdf": "https://arxiv.org/pdf/2507.21352", "abs": "https://arxiv.org/abs/2507.21352", "authors": ["David Broadhurst", "Daniele Dorigoni"], "title": "Resurgent Lambert series with characters", "comment": "50 pages plus appendices", "summary": "We consider certain Lambert series as generating functions of divisor sums\ntwisted by Dirichlet characters and compute their exact resurgent transseries\nexpansion near $q=1^-$. For special values of the parameters, these Lambert\nseries are expressible in terms of iterated integrals of holomorphic Eisenstein\nseries twisted by the same characters and the transseries representation is a\ndirect consequence of the action of Fricke involution on such twisted\nEisenstein series. When the parameters of the Lambert series are generic the\ntransseries representation provides for a quantum-modular version of Fricke\ninvolution which for a particular example we show being equivalent to modular\nresurgent structures found in topological strings observables.", "AI": {"tldr": "论文研究了特定Lambert级数作为除数和的生成函数，通过Dirichlet特征扭曲，计算了其在$q=1^-$附近的精确复苏超越级数展开。", "motivation": "探讨Lambert级数与扭曲的Dirichlet特征之间的关系，以及其在Fricke对合作用下的表现，为拓扑弦理论中的模复苏结构提供新视角。", "method": "利用扭曲的全纯Eisenstein级数的迭代积分表达Lambert级数，并分析Fricke对合对其的影响，进而推导超越级数展开。", "result": "对于特定参数，Lambert级数可通过扭曲的Eisenstein级数表示；对于一般参数，超越级数展开揭示了量子模版本的Fricke对合。", "conclusion": "研究不仅扩展了对Lambert级数的理解，还为拓扑弦理论中的模复苏结构提供了数学基础，展示了量子模对合的新性质。"}}
{"id": "2507.21425", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.21425", "abs": "https://arxiv.org/abs/2507.21425", "authors": ["Matthew Hunter", "Walter J. Manuel", "Simone D'Amico"], "title": "Optimal Impulsive Control of Cislunar Relative Motion using Reachable Set Theory", "comment": null, "summary": "This work presents the first application of the state-of-the-art\nKoenig-D'Amico reachable set theory solver to cislunar, chaotic relative motion\nin the Circular-Restricted Three-Body Problem (CR3BP). The relative motion\ndynamics of two spacecraft, a chief and a deputy, in the CR3BP are formulated\nas a Linear Time-Variant (LTV) system, allowing the solver to find an optimal\nimpulsive control maneuver plan. This methodology demonstrates robust and\naccurate control performance for both small and large reconfigurations over\ndifferent CR3BP orbits and control windows. These capabilities are enhanced by\na Model Predictive Control (MPC) architecture to reject all sources of control,\nnavigation, and dynamic error. The performance of the proposed approach is\nvalidated by unit testing, Monte Carlo simulations, and comparisons to baseline\nmodels for spacecraft relative motion. Overall, this work demonstrates an\noptimal control methodology with the computational efficiency to be used\non-board spacecraft, enabling the safe, effective, and efficient operation of\nDistributed Space Systems in cislunar space.", "AI": {"tldr": "本研究首次将先进的Koenig-D'Amico可达集理论求解器应用于地月空间混沌相对运动的圆形限制性三体问题（CR3BP），提出了一种高效的最优脉冲控制方法，并通过MPC架构提升鲁棒性。", "motivation": "为解决地月空间分布式航天器系统在CR3BP混沌环境中的安全高效运行问题，需开发计算高效的最优控制方法。", "method": "将主从航天器的相对运动建模为线性时变（LTV）系统，结合Koenig-D'Amico求解器生成最优脉冲控制方案，并采用模型预测控制（MPC）架构抑制误差。", "result": "通过单元测试、蒙特卡洛仿真及基线模型对比验证，该方法在不同CR3BP轨道和控制窗口下均表现出鲁棒性，计算效率满足星载需求。", "conclusion": "该研究为地月空间航天器集群提供了具有星载计算可行性的最优控制框架，实现了安全、精准且高效的相对运动控制。"}}
{"id": "2507.21987", "categories": ["cs.DM", "math.CO", "90C10, 05C17"], "pdf": "https://arxiv.org/pdf/2507.21987", "abs": "https://arxiv.org/abs/2507.21987", "authors": ["Burak Nur Erdem", "Tınaz Ekim", "Zeki Caner Taşkın"], "title": "Perfect Graph Modification Problems: An Integer Programming Approach", "comment": null, "summary": "Graph modification problems, which aim to find a small set of modifications\nto a graph so that it satisfies a desired property, have been studied for\nseveral special graph classes. The literature is rather rich in NP-completeness\nresults and polynomial time solvable cases. However, to the best of our\nknowledge, only a few exact algorithms have been suggested to address NP-hard\ncases. In this work, we propose exact solution methods based on integer\nprogramming for three perfect graph modification problems: minimum perfect\nediting, minimum perfect completion and the perfect sandwich problem. The\nminimum perfect editing problem inquires the smallest number of edge additions\nand deletions to make a graph perfect, while the completion problem allows only\nedge additions. In the perfect sandwich problem, only a given subset of\nnon-edges can be changed to edges, and the problem asks whether a perfect graph\ncan be obtained in this way. The proposed methods are based on the Strong\nPerfect Graph Theorem. We represent odd holes and odd antiholes as linear\ninequalities, and formulate an integer programming model to solve minimum\nperfect editing problem. To address the exponential number of constraints, we\npropose a cutting plane algorithm which relies on finding odd holes and odd\nantiholes. To enhance the practical efficiency of the cutting plane algorithm,\nwe address the expected number of odd holes and odd antiholes in random graphs.\nIn addition, we propose a heuristic algorithm to make a given graph perfect,\nwhich is used to obtain improved upper bounds for the editing and the\ncompletion problems. Finally, we demonstrate empirical effectiveness of the\nproposed methods through computational experiments.", "AI": {"tldr": "本文提出基于整数规划和切割平面算法的精确解法，用于解决三种完美图修改问题：最小完美编辑、最小完美补全和完美三明治问题，并通过计算实验验证了方法的有效性。", "motivation": "现有关于图修改问题的研究主要集中在NP完全性结果和多项式时间可解案例，但针对NP难问题的精确算法较少。本文旨在填补这一空白，提出针对完美图修改问题的精确解法。", "method": "基于强完美图定理，将奇洞和奇反洞表示为线性不等式，构建整数规划模型。为解决约束条件指数级增长问题，提出依赖奇洞/奇反洞检测的切割平面算法，并引入启发式算法改进上界。", "result": "通过分析随机图中奇洞/奇反洞的预期数量提升算法效率，计算实验证明所提方法在解决完美图编辑、补全和三明治问题上的实际有效性。", "conclusion": "该研究为NP难完美图修改问题提供了首个系统性的精确解法框架，结合理论分析与启发式策略，显著提升了计算可行性，为后续相关研究奠定基础。"}}
{"id": "2507.21508", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.21508", "abs": "https://arxiv.org/abs/2507.21508", "authors": ["Koki Shimizu", "Hiroki Hashiguchi"], "title": "Exact Distribution of the Noncentral Complex Roy's Largest Root Statistic via Pieri's Formula", "comment": null, "summary": "In this study, we derive the exact distribution and moment of the noncentral\ncomplex Roy's largest root statistic, expressed as a product of complex zonal\npolynomials. We show that the linearization coefficients arising from the\nproduct of complex zonal polynomials in the distribution of Roy's test under a\nspecific alternative hypothesis can be explicitly computed using Pieri's\nformula, a well-known result in combinatorics. These results were then applied\nto compute the power of tests in the complex multivariate analysis of variance\n(MANOVA).", "AI": {"tldr": "本研究推导了非中心复数Roy最大根统计量的精确分布与矩，通过复数区域多项式乘积表达，并应用组合数学中的Pieri公式计算线性化系数，最终用于复数多元方差分析(MANOVA)的检验效能计算。", "motivation": "旨在解决复数域中Roy最大根统计量在特定备择假设下的分布问题，为复数多元方差分析提供理论支持。", "method": "采用复数区域多项式乘积表示统计量分布，利用组合数学中的Pieri公式显式计算多项式乘积产生的线性化系数。", "result": "成功推导出非中心复数Roy最大根统计量的精确分布与矩，并实现复数MANOVA检验效能的量化计算。", "conclusion": "该研究为复数多元统计推断提供了新的理论工具，特别在MANOVA检验效能计算方面具有重要应用价值。"}}
{"id": "2507.21643", "categories": ["math.CO", "05A18, 05A19, 11B73, 11B75, 11B68"], "pdf": "https://arxiv.org/pdf/2507.21643", "abs": "https://arxiv.org/abs/2507.21643", "authors": ["Yahia Djemmada", "Levent Kargın", "Mümün Can"], "title": "Partial Deranged Bell Numbers and Their Combinatorial Properties", "comment": null, "summary": "We introduce a novel generalization of deranged Bell numbers by defining the\npartial deranged Bell numbers $w_{n,r}$, which count the number of set\npartitions of $\\left[ n\\right] $ with exactly $r$ fixed blocks, while the\nremaining blocks are deranged. This construction provides a unified framework\nthat connects partial derangements, Stirling numbers, and ordered Bell numbers.\nWe investigate their combinatorial properties, including explicit formulas,\ngenerating functions, and recurrence relations. Moreover, we demonstrate that\nthese numbers are expressible in terms of classical sequences such as deranged\nBell numbers and ordered Bell numbers, and reveal their relationship to\ncomplementary Bell numbers, offering insights relevant to Wilf's conjecture.\nNotably, we derive the identity \\[\n\\tilde{\\phi}_{n}=\\Tilde{w}_{n,0}-\\Tilde{w}_{n,1}=\\tilde{w}_{n-1,0}-2\\tilde\n{w}_{n-1,2}, \\] which illustrates their structural connection to complementary\nBell numbers. We also introduce a polynomial expansion for these numbers and\nexplore their connections with exponential polynomials, geometric polynomials,\nand Bernoulli numbers. These relationships facilitate the derivation of\nclosed-form expressions for certain finite summations involving Stirling\nnumbers of the second kind, Bernoulli numbers, and binomial coefficients,\narticulated through partial derangement numbers.", "AI": {"tldr": "本文引入了部分错位贝尔数$w_{n,r}$的新概念，统一了部分错位、斯特林数和有序贝尔数的框架，研究了其组合性质，并揭示了它们与经典序列的关系。", "motivation": "通过定义部分错位贝尔数，构建一个统一框架，连接部分错位、斯特林数和有序贝尔数，以深入探索其组合性质及与其他经典序列的关系。", "method": "研究了部分错位贝尔数的组合性质，包括显式公式、生成函数和递推关系，并探讨了其与经典序列如错位贝尔数和有序贝尔数的关系。", "result": "证明了部分错位贝尔数可用经典序列表示，并揭示了其与互补贝尔数的结构联系，如$\\tilde{\\phi}_{n}=\\Tilde{w}_{n,0}-\\Tilde{w}_{n,1}=\\tilde{w}_{n-1,0}-2\\tilde{w}_{n-1,2}$。此外，引入了多项式展开并探讨了其与指数多项式、几何多项式和伯努利数的联系。", "conclusion": "部分错位贝尔数为组合数学提供了新的工具，其与经典序列的关系及多项式展开的应用，为涉及第二类斯特林数、伯努利数和二项式系数的有限求和提供了闭式表达式。"}}
{"id": "2507.21123", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21123", "abs": "https://arxiv.org/abs/2507.21123", "authors": ["Mark A. Kramer", "Aanchal Mathur", "Caroline E. Adams", "Jason A. Walonoski"], "title": "Leveraging Generative AI to Enhance Synthea Module Development", "comment": "Title: Leveraging Generative AI to Enhance Synthea Module Development\n  Word Count: [Approximately 12,000 words] Figures: 3 Tables: 3 Supplementary\n  Material: Extensive appendices with prompts and disease profiles", "summary": "This paper explores the use of large language models (LLMs) to assist in the\ndevelopment of new disease modules for Synthea, an open-source synthetic health\ndata generator. Incorporating LLMs into the module development process has the\npotential to reduce development time, reduce required expertise, expand model\ndiversity, and improve the overall quality of synthetic patient data. We\ndemonstrate four ways that LLMs can support Synthea module creation: generating\na disease profile, generating a disease module from a disease profile,\nevaluating an existing Synthea module, and refining an existing module. We\nintroduce the concept of progressive refinement, which involves iteratively\nevaluating the LLM-generated module by checking its syntactic correctness and\nclinical accuracy, and then using that information to modify the module. While\nthe use of LLMs in this context shows promise, we also acknowledge the\nchallenges and limitations, such as the need for human oversight, the\nimportance of rigorous testing and validation, and the potential for\ninaccuracies in LLM-generated content. The paper concludes with recommendations\nfor future research and development to fully realize the potential of LLM-aided\nsynthetic data creation.", "AI": {"tldr": "本文探讨了利用大语言模型（LLMs）辅助开发Synthea（开源合成健康数据生成器）新疾病模块的方法，展示了LLMs在生成疾病档案、创建模块、评估现有模块及优化模块四个方面的潜力，并提出了渐进式优化的概念。", "motivation": "将LLMs引入Synthea模块开发过程，旨在缩短开发时间、降低专业门槛、增加模型多样性并提升合成患者数据的整体质量。", "method": "提出了四种LLMs支持Synthea模块创建的方式：生成疾病档案、基于档案生成模块、评估现有模块及优化模块，并引入渐进式优化方法，通过迭代检查语法正确性和临床准确性来改进模块。", "result": "研究表明LLMs在该领域具有潜力，但也面临需人工监督、严格测试验证及LLM生成内容可能不准确等挑战。", "conclusion": "文章总结了LLM辅助合成数据创建的潜力，并建议未来研究需进一步探索以实现其全部价值。"}}
{"id": "2507.21068", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21068", "abs": "https://arxiv.org/abs/2507.21068", "authors": ["Debesh Choudhury", "Sujoy Chakraborty"], "title": "Private key and password protection by steganographic image encryption", "comment": "5 pages, 3 figures, Applications of Digital Image Processing XLV,\n  SPIE Optical Engineering + Applications 2022, Proc. SPIE 12226,", "summary": "We propose a technique to protect and preserve a private key or a passcode in\nan encrypted two-dimensional graphical image. The plaintext private key or the\npasscode is converted into an encrypted QR code and embedded into a real-life\ncolor image with a steganographic scheme. The private key or the passcode is\nrecovered from the stego color image by first extracting the encrypted QR code\nfrom the color image, followed by decryption of the QR code. The cryptographic\nkey for encryption of the QR code is generated from the output of a Linear\nFeedback Shift Register (LFSR), initialized by a seed image chosen by the user.\nThe user can store the seed image securely, without the knowledge of an\nattacker. Even if an active attacker modifies the seed image (without knowledge\nof the fact that it is the seed image), the user can easily restore it if\nhe/she keeps multiple copies of it, so that the encryption key can be\nregenerated easily. Our experiments prove the feasibility of the technique\nusing sample private key data and real-life color images.", "AI": {"tldr": "提出一种将私钥或密码加密嵌入彩色图像的技术，通过生成加密QR码并利用隐写术嵌入图像，用户可通过种子图像恢复密钥。实验验证了该技术的可行性。", "motivation": "为解决私钥或密码的安全存储问题，提出一种将敏感信息隐藏于普通彩色图像中的方法，即使种子图像被篡改也能通过备份恢复。", "method": "将明文私钥转换为加密QR码，通过隐写术嵌入彩色图像；密钥由用户选择的种子图像经LFSR生成，解密时先提取QR码再解密。", "result": "实验证明该技术能有效保护私钥数据，且用户可通过备份种子图像应对篡改，确保密钥可重新生成。", "conclusion": "该技术为私钥存储提供了一种安全且可恢复的解决方案，结合加密与隐写术，适用于现实场景中的敏感信息保护。"}}
{"id": "2507.21877", "categories": ["math.LO", "06A06, 03B30, 03F35, 03E10, 05C05, 03F15"], "pdf": "https://arxiv.org/pdf/2507.21877", "abs": "https://arxiv.org/abs/2507.21877", "authors": ["Patrick Uftring"], "title": "Maximal order types for sequences with gap condition", "comment": null, "summary": "Higman's lemma states that for any well partial order $X$, the partial order\n$X^*$ of finite sequences with members from $X$ is also well. By combining\nresults due to Girard as well as Sch\\\"{u}tte and Simpson, one can show that\nHigman's lemma is equivalent to arithmetical comprehension over\n$\\textsf{RCA}_0$, the usual base system of reverse mathematics. By\nincorporating Friedman's gap condition, Sch\\\"{u}tte and Simpson defined a\nslightly different order on finite number sequences with fewer comparisons.\nWhile it is still true that their definition yields a well partial order, it\nturns out that arithmetical comprehension is not enough to prove this fact.\nGordeev considered a symmetric variation of this gap condition for sequences\nwith members from arbitrary well orders. He could show, over $\\textsf{RCA}_0$,\nthat his partial order on sequences is well (for any underlying well order) if\nand only if arithmetical transfinite recursion is available. We present a new\nand simpler proof of this fact and extend Gordeev's results to weak and strong\ngap conditions as well as binary trees with weakly ascending labels. Moreover,\nwe compute the maximal order types of all considered structures.", "AI": {"tldr": "本文重新证明了Gordeev关于对称间隙条件下序列偏序的结论，并扩展了弱/强间隙条件及带弱升序标签的二叉树的结果，同时计算了所有结构的最大序类型。", "motivation": "研究Higman引理与算术可计算性之间的关系，探讨不同间隙条件下偏序的性质及其证明所需的数学基础。", "method": "结合Girard、Sch\\\"{u}tte和Simpson的成果，采用对称间隙条件简化证明，并扩展至弱/强间隙条件及二叉树结构。", "result": "证明对称间隙条件下的偏序良序性等价于算术超限递归，并计算了相关结构的最大序类型。", "conclusion": "间隙条件的变体会显著影响偏序的证明复杂度，对称条件需要更强的数学基础，而最大序类型的计算为相关理论提供了量化工具。"}}
{"id": "2507.21401", "categories": ["math.NT", "11J13, 11J54, 11J82, 11K55"], "pdf": "https://arxiv.org/pdf/2507.21401", "abs": "https://arxiv.org/abs/2507.21401", "authors": ["Dmitry Badziahin"], "title": "Simultaneous Diophantine approximation on the three dimensional Veronese curve", "comment": "22 pages", "summary": "We compute the Hausdorff dimension of the set of simultaneously\n$\\lambda$-well approximable points on the Veronese curve in $\\RR^3$ for $1/3\\le\n\\lambda\\le 3/5$. This range for $\\lambda$ was predicted in the conjecture of\nBeresnevich and Yang from~\\cite{ber_yan_2023}. To the best of the author's\nknowledge, this makes $\\VVV_3$ the first nondegenerate curve in $\\RR^n$, $n\\ge\n3$, to confirm the lower bound part of this conjecture.", "AI": {"tldr": "计算了三维Veronese曲线上同时满足$\\lambda$-良好逼近点的Hausdorff维数，验证了Beresnevich和Yang的猜想下界部分。", "motivation": "验证Beresnevich和Yang在2023年提出的猜想，即对于$1/3\\le \\lambda\\le 3/5$的范围，Veronese曲线上的$\\lambda$-良好逼近点的Hausdorff维数下界成立。", "method": "通过数学分析和计算，研究了三维Veronese曲线上同时满足$\\lambda$-良好逼近的点的Hausdorff维数。", "result": "在$1/3\\le \\lambda\\le 3/5$范围内，计算并确认了Veronese曲线上$\\lambda$-良好逼近点的Hausdorff维数下界，这是首次在$n\\ge 3$的非退化曲线上验证该猜想。", "conclusion": "研究结果支持了Beresnevich和Yang的猜想，表明三维Veronese曲线是该猜想下界部分的首个非退化曲线实例。"}}
{"id": "2507.21436", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.21436", "abs": "https://arxiv.org/abs/2507.21436", "authors": ["Mohammad Ghasemi", "Asef Nazari", "Dhananjay Thiruvady", "Reza Tavakkoli-Moghaddam", "Reza Shahabi-Shahmiri", "Seyed-Ali Mirnezami"], "title": "A Bi-Objective Mathematical Model for the Multi-Skilled Resource-Constrained Project Scheduling Problem Considering Reliability: An AUGMECON2VIKOR Hybrid Method", "comment": null, "summary": "In recent years, resources with multiple skills have received attention as an\nextension of the resource-constrained project scheduling problem known as\nMSRCPSP. Although the disruption rate is well-estimated in today's\nmanufacturing projects, its impact on project makespan and cost need further\ninvestigation. Hence, this study presents a novel mathematical model for the\nMSRCPSP considering reliability, namely MSRCPSPR. The model proposes both\nobjectives of minimizing project makespan and project cost. The MSRCPSP is an\nNP-hard problem, and including reliability constraints, as proposed in this\npaper, makes solving the problem more intractable. To cope with the\ncomputational challenges of solving the problem, a combination of an enhanced\nversion of the epsilon-constraint method as well as an augmented version of the\nVIKOR algorithm, namely AUGMECON2VIKOR, is employed to solve benchmark\ninstances j10 and j20 from the PSPLIB. A comparative analysis demonstrates the\nperformance of the proposed method, and the sensitivity analysis represents the\neffects of positive reliable constraints on the objective functions. Employing\nthe proposed method, the project makespan and cost are reduced by nearly 2.55%\nand 2.80% in j10 on average. CPU time is also decreased by about 543 seconds in\ncomparison to the epsilon-constraint method.", "AI": {"tldr": "本文提出了一种考虑可靠性的多技能资源受限项目调度问题（MSRCPSPR）新模型，结合改进的epsilon约束法和增强版VIKOR算法（AUGMECON2VIKOR），在PSPLIB基准实例中实现了项目工期与成本分别降低2.55%和2.80%，计算时间减少543秒。", "motivation": "当前制造业项目中中断率虽可准确预估，但其对项目工期与成本的影响仍需深入研究，因此需要建立融合可靠性的MSRCPSP扩展模型。", "method": "采用改进版epsilon约束法与增强型VIKOR算法（AUGMECON2VIKOR）求解含可靠性约束的NP难问题，并在PSPLIB的j10/j20实例上进行验证。", "result": "新方法使j10实例平均项目工期缩短2.55%、成本降低2.80%，相比传统epsilon约束法节省543秒计算时间。敏感性分析揭示了可靠约束对目标的积极影响。", "conclusion": "所提MSRCPSPR模型及AUGMECON2VIKOR算法能有效解决含可靠性约束的复杂调度问题，显著优化项目工期与成本，为NP难问题提供了高效求解方案。"}}
{"id": "2507.21758", "categories": ["math.CO", "cs.CG", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.21758", "abs": "https://arxiv.org/abs/2507.21758", "authors": ["Arijit Bishnu", "Mathew Francis", "Pritam Majumder"], "title": "Curves, points, incidences and covering", "comment": null, "summary": "Given a point set, mostly a grid in our case, we seek upper and lower bounds\non the number of curves that are needed to cover the point set. We say a curve\ncovers a point if the curve passes through the point. We consider such\ncoverings by monotonic curves, lines, orthoconvex curves, circles, etc. We also\nstudy a problem that is converse of the covering problem -- if a set of $n^2$\npoints in the plane is covered by $n$ lines then can we say something about the\nconfiguration of the points?", "AI": {"tldr": "研究点集（通常是网格）被不同曲线覆盖所需数量的上下界，以及覆盖点集的反问题。", "motivation": "探讨如何用最少数量的特定类型曲线（如单调曲线、直线、正交凸曲线、圆等）完全覆盖给定的点集，并研究点集被覆盖时的几何配置特性。", "method": "分析点集被不同曲线覆盖的上下界，特别关注单调曲线、直线、正交凸曲线和圆；同时研究当$n^2$个平面点被$n$条直线覆盖时点集的结构特性。", "result": "提出了点集覆盖所需曲线数量的理论界限，并揭示了点集被直线覆盖时的配置规律。", "conclusion": "该研究为点集覆盖问题提供了理论框架，并展示了覆盖曲线数量与点集几何结构之间的深刻联系。"}}
{"id": "2507.21769", "categories": ["math.ST", "math.PR", "stat.TH", "2020 subject classifications: Primary 62F12, 68P27, secondary 62B15,\n  46A55"], "pdf": "https://arxiv.org/pdf/2507.21769", "abs": "https://arxiv.org/abs/2507.21769", "authors": ["Chiara Amorino", "Arnaud Gloter"], "title": "Factorization by extremal privacy mechanisms: new insights into efficiency", "comment": null, "summary": "We study the problem of efficiency under $\\alpha$ local differential privacy\n($\\alpha$ LDP) in both discrete and continuous settings. Building on a\nfactorization lemma, which shows that any privacy mechanism can be decomposed\ninto an extremal mechanism followed by additional randomization, we reduce the\nFisher information maximization problem to a search over extremal mechanisms.\nThe representation of extremal mechanisms requires working in infinite\ndimensional spaces and invokes advanced tools from convex and functional\nanalysis, such as Choquet's theorem. Our analysis establishes matching upper\nand lower bounds on the Fisher information in the high privacy regime ($\\alpha\n\\to 0$), and proves that the maximization problem always admits a solution for\nany $\\alpha$. As a concrete application, we consider the problem of estimating\nthe parameter of a uniform distribution on $[0, \\theta]$ under $\\alpha$ LDP.\nGuided by our theoretical findings, we design an extremal mechanism that yields\na consistent and asymptotically efficient estimator in high privacy regime.\nNumerical experiments confirm our theoretical results.", "AI": {"tldr": "本文研究了离散和连续设置下$\\alpha$局部差分隐私($\\alpha$ LDP)的效率问题，通过分解引理将隐私机制分解为极值机制与额外随机化，利用凸分析和泛函分析工具建立了高隐私 regime 下Fisher信息的上下界匹配，并设计出针对均匀分布参数的高效估计器。", "motivation": "探讨在$\\alpha$局部差分隐私约束下如何实现统计效率最大化，特别是在高隐私保护需求($\\alpha\\to 0$)场景下的最优机制设计问题。", "method": "基于分解引理将任意隐私机制分解为极值机制与随机化步骤，利用Choquet定理等工具在无限维空间中进行极值机制搜索，将Fisher信息最大化问题转化为凸优化问题。", "result": "在高隐私 regime ($\\alpha\\to 0$)下建立了Fisher信息的紧致上下界，证明了对任意$\\alpha$解的存在性，并针对均匀分布$[0,\\theta]$参数估计问题设计了具有一致性和渐近有效性的极值机制。", "conclusion": "理论分析和数值实验表明，通过极值机制分解方法可在$\\alpha$ LDP框架下实现统计最优性，为高隐私需求场景提供了可行的解决方案。"}}
{"id": "2507.21656", "categories": ["math.CO", "math.NT"], "pdf": "https://arxiv.org/pdf/2507.21656", "abs": "https://arxiv.org/abs/2507.21656", "authors": ["Tomasz Kosciuszko"], "title": "Schur-like numbers and a lemma of Shearer", "comment": null, "summary": "Suppose that each number $1,2,...,N$ has one of n colours assigned. We show\nthat if there are no monochromatic solutions to the equation\n$x_1+x_2+x_3=y_1+y_2$, then $N=O((n!)^{1/2})$, improving upon a result of\nCwalina and Schoen. Further, a stronger bound of $N=O(((n-k)!)^{1/2})$, where\n$k\\gg\\frac{\\log n}{\\log\\log n}$ is shown for colourings avoiding solutions to\nthe equation $x_1+x_2+...+x_{12}=y_1+y_2+...+y_9$. Finally, some remarks on\nother equations are presented.", "AI": {"tldr": "论文研究了避免特定方程单色解的着色问题，改进了Cwalina和Schoen的界限，并针对更复杂的方程展示了更强的结果。", "motivation": "研究在着色数字时避免特定方程的单色解，以探索着色问题的界限和改进现有结果。", "method": "通过分析着色方案和方程的解结构，推导出避免单色解的最大数字N的上界。", "result": "对于方程$x_1+x_2+x_3=y_1+y_2$，证明了$N=O((n!)^{1/2})$；对于更复杂的方程，展示了更强的界限$N=O(((n-k)!)^{1/2})$，其中$k\\gg\\frac{\\log n}{\\log\\log n}$。", "conclusion": "论文改进了避免特定方程单色解的着色问题的界限，并对其他方程的相关结果进行了讨论。"}}
{"id": "2507.21129", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21129", "abs": "https://arxiv.org/abs/2507.21129", "authors": ["Jae Wan Shim"], "title": "Measuring and Analyzing Intelligence via Contextual Uncertainty in Large Language Models using Information-Theoretic Metrics", "comment": null, "summary": "The remarkable capabilities of Large Language Models (LLMs) are now\nextensively documented on task-specific benchmarks, yet the internal mechanisms\nthat produce these results are the subject of intense scientific inquiry. This\npaper contributes to this inquiry by moving beyond metrics that measure\n\\textit{what} models can do, to a methodology that characterizes \\textit{how}\nthey process information. We introduce a novel, task-agnostic approach to probe\nthese dynamics by creating a quantitative ``Cognitive Profile\" for any given\nmodel. This profile is centered on the \\textbf{Entropy Decay Curve}, a\nvisualization that traces how a model's normalized predictive uncertainty\nchanges as a function of context length. Applying this methodology to several\nstate-of-the-art LLMs across diverse texts, we uncover unique and consistent\ncognitive profiles that are sensitive to both model scale and text complexity.\nWe also introduce the Information Gain Span (IGS) index to summarize the\ndesirability of the decay trajectory. This work thus provides a new, principled\nlens for analyzing and comparing the intrinsic operational dynamics of\nartificial intelligence.", "AI": {"tldr": "本文提出了一种任务无关的方法，通过构建量化\\“认知轮廓\\”来揭示大型语言模型（LLMs）的信息处理机制，核心是\\“熵衰减曲线\\”，并引入信息增益跨度（IGS）指数评估轨迹优劣。该方法揭示了模型规模与文本复杂度对认知特征的敏感性。", "motivation": "现有研究多关注模型能完成什么任务（\\textit{what}），而本文旨在揭示其内部运作机制（\\textit{how}），为理解LLMs的认知动态提供新视角。", "method": "提出基于\\“熵衰减曲线\\”的任务无关分析框架，通过追踪模型预测不确定性随上下文长度的变化构建认知轮廓，并设计IGS指数量化衰减轨迹的合理性。", "result": "在不同文本上测试多款前沿LLMs，发现其认知轮廓具有独特性与一致性，且对模型规模和文本复杂度敏感。IGS指数有效表征了信息处理动态的优劣。", "conclusion": "该研究为分析人工智能内在运作机制提供了原则性新工具，通过认知轮廓和IGS指数实现了模型信息处理动态的可比性评估。"}}
{"id": "2507.21085", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21085", "abs": "https://arxiv.org/abs/2507.21085", "authors": ["Yusuf Ozmiş"], "title": "Applications Of Zero-Knowledge Proofs On Bitcoin", "comment": null, "summary": "This paper explores how zero-knowledge proofs can enhance Bitcoin's\nfunctionality and privacy. First, we consider Proof-of-Reserve schemes: by\nusing zk-STARKs, a custodian can prove its Bitcoin holdings are more than a\npredefined threshold X, without revealing addresses or actual balances. We\noutline a STARK-based protocol for Bitcoin UTXOs and discuss its efficiency.\nSecond, we examine ZK Light Clients, where a mobile or lightweight device\nverifies Bitcoin's proof-of-work chain using succinct proofs. We propose a\nprotocol for generating and verifying a STARK-based proof of a chain of block\nheaders, enabling trust-minimized client operation. Third, we explore\nPrivacy-Preserving Rollups via BitVM: leveraging BitVM, we design a conceptual\nrollup that keeps transaction data confidential using zero-knowledge proofs. In\neach case, we analyze security, compare with existing approaches, and discuss\nimplementation considerations. Our contributions include the design of concrete\nprotocols adapted to Bitcoin's UTXO model and an assessment of their\npracticality. The results suggest that while ZK proofs can bring powerful\nfeatures (e.g., on-chain reserve audits, trustless light clients, and private\nlayer-2 execution) to Bitcoin, each application requires careful trade-offs in\nefficiency and trust assumptions.", "AI": {"tldr": "本文探讨了零知识证明如何增强比特币的功能与隐私性，提出了三种应用方案：基于zk-STARKs的储备证明协议、ZK轻客户端验证协议，以及利用BitVM的隐私保护Rollup方案，并分析了其安全性与实际应用权衡。", "motivation": "旨在通过零知识证明技术解决比特币在储备审计、轻客户端信任及交易隐私方面的局限性，扩展其功能边界。", "method": "1. 储备证明：使用zk-STARKs验证托管方持有超过阈值X的比特币，隐藏具体地址与余额；2. ZK轻客户端：通过STARK证明验证区块头链，实现去信任化；3. 隐私Rollup：基于BitVM设计零知识证明保护的二层交易方案。", "result": "研究表明，零知识证明可为比特币带来链上储备审计、无信任轻客户端和隐私二层执行等特性，但需在效率与信任假设间权衡。", "conclusion": "零知识证明能显著提升比特币功能与隐私，但具体应用需针对UTXO模型优化协议设计，并谨慎评估实践中的效率与安全取舍。"}}
{"id": "2507.21894", "categories": ["math.LO", "math.FA", "math.SP", "03C45 47B02 47B15"], "pdf": "https://arxiv.org/pdf/2507.21894", "abs": "https://arxiv.org/abs/2507.21894", "authors": ["Alexander Berenstein", "Nicolás Cuervo Ovalle", "Isaac Goldbring"], "title": "Model theory of Hilbert spaces expanded by normal operators", "comment": null, "summary": "We study expansions of Hilbert spaces with a bounded normal operator $T$. We\naxiomatize this theory in a natural language and identify all of its\ncompletions. We prove the definability of the adjoint $T^*$ and prove\nquantifier elimination for every completion after adding $T^*$ to the language.\nWe identify types with measures on the spectrum of the operator and show that\nthe logic topology on the type space corresponds to the weak*-topology on the\nspace of measures. We also give a precise formula for the metric on the space\nof $1$-types. We prove all completions are stable and characterize the\nstability spectrum of the theory in terms of the spectrum of the operator. We\nalso show all completions, regardless of their spectrum, are $\\omega$-stable up\nto perturbations.", "AI": {"tldr": "本文研究了带有有界正规算子$T$的希尔伯特空间的扩展，通过公理化方法确定了所有完备化理论，证明了伴随算子$T^*$的可定义性，并给出了类型与算子谱上测度的对应关系。", "motivation": "研究希尔伯特空间中带有有界正规算子的扩展理论，旨在理解其逻辑结构和类型空间的性质，为算子理论的模型论分析提供基础。", "method": "采用公理化方法，在自然语言中形式化该理论，并通过添加伴随算子$T^*$实现量词消去。利用测度论工具，将类型与算子谱上的测度联系起来。", "result": "证明了所有完备化理论都是稳定的，并给出了类型空间度量与算子谱的精确公式。逻辑拓扑与测度空间的弱*-拓扑相对应，且所有完备化理论在扰动下都是$\\omega$-稳定的。", "conclusion": "该研究为带有有界正规算子的希尔伯特空间提供了完整的模型论描述，建立了算子谱与理论稳定性之间的深刻联系，拓展了模型论在泛函分析中的应用。"}}
{"id": "2507.21514", "categories": ["math.NT", "11F30, 11F37, 11F50"], "pdf": "https://arxiv.org/pdf/2507.21514", "abs": "https://arxiv.org/abs/2507.21514", "authors": ["Toshiki Matsusaka"], "title": "The Fourier coefficients and singular moduli of the elliptic modular function $j(τ)$, revisited", "comment": "25 pages. This survey is based on a talk given at the conference\n  \"Modular Forms and Multiple Zeta Values -Conference in Honor of Masanobu\n  Kaneko's 60+4th Birthday\", held at Kindai University in February 2025", "summary": "Kaneko's formula expresses the Fourier coefficients of the elliptic modular\n$j$-function as finite sums of singular moduli. First published as a short\narticle in 1996, it was presented as a consequence of Zagier's work inspired by\nBorcherds products. Since then, the formula has developed into a broader\nframework that links the Fourier coefficients of modular forms to the special\nvalues of modular functions, extending in various directions. This article\nsurveys these subsequent developments.", "AI": {"tldr": "金子公式将椭圆模$j$-函数的傅里叶系数表示为奇异模的有限和，源于Zagier受Borcherds积启发的成果，现已发展为更广泛的框架。", "motivation": "探索模形式傅里叶系数与模函数特殊值之间的深层联系，扩展金子公式的理论与应用范围。", "method": "综述了基于Zagier工作及Borcherds积启发的理论框架，分析其后续扩展方向。", "result": "建立了模形式傅里叶系数与模函数特殊值的系统性关联，形成多方向推广的理论体系。", "conclusion": "金子公式从单一结论发展为连接模形式与模函数的重要理论桥梁，具有持续的研究价值。"}}
{"id": "2507.21495", "categories": ["math.OC", "90C22, 90C30, 90C46"], "pdf": "https://arxiv.org/pdf/2507.21495", "abs": "https://arxiv.org/abs/2507.21495", "authors": ["Huimin Li", "Yuya Yamakawa", "Ellen H. Fukuda"], "title": "Second-order sequential optimality conditions for nonlinear semidefinite optimization problems", "comment": null, "summary": "Sequential optimality conditions play an important role in constrained\noptimization since they provide necessary conditions without requiring\nconstraint qualifications (CQs). This paper introduces a second-order extension\nof the Approximate Karush-Kuhn-Tucker (AKKT) conditions, referred to as AKKT2,\nfor nonlinear semidefinite optimization problems (NSDP). In particular, we\nprovide a formal definition of AKKT2, as well as its stronger variant, called\nComplementary AKKT2 (CAKKT2), and prove that these conditions are necessary for\nlocal minima without any assumption. Moreover, under Robinson's CQ and the weak\nconstant rank property, we show that AKKT2 implies the so-called weak\nsecond-order necessary condition. Finally, we propose a penalty-based algorithm\nthat generates sequences whose accumulation points satisfy the AKKT2 and the\nCAKKT2 conditions.", "AI": {"tldr": "本文提出了非线性半定优化问题(NSDP)的二阶近似KKT条件(AKKT2)及其强化版本(CAKKT2)，证明了它们是无约束条件下局部最优的必要条件，并在特定约束规范下推导出弱二阶必要性，同时设计了满足这些条件的罚函数算法。", "motivation": "序列最优性条件在约束优化中至关重要，因其无需约束规范(CQs)即可提供必要性条件。本研究旨在扩展经典AKKT至二阶情形，为NSDP问题建立更全面的最优性理论框架。", "method": "通过数学分析严格定义AKKT2和CAKKT2条件，在Robinson约束规范和弱常数秩假设下建立与弱二阶必要条件的关联，并构造罚函数算法生成满足目标条件的收敛序列。", "result": "理论证明：1) AKKT2/CAKKT2是无约束的局部最优必要条件；2) 在特定CQs下AKKT2蕴含弱二阶必要性；3) 所提算法产生的聚点必然满足AKKT2和CAKKT2条件。", "conclusion": "该研究系统建立了NSDP问题的二阶序列最优性理论，提出的算法框架为求解非凸NSDP问题提供了新的理论保证和计算工具，弥补了一阶AKKT在二阶分析中的空白。"}}
{"id": "2507.21840", "categories": ["math.ST", "stat.TH", "65K05 49J52 62D10 62B11"], "pdf": "https://arxiv.org/pdf/2507.21840", "abs": "https://arxiv.org/abs/2507.21840", "authors": ["Dominikus Noll"], "title": "Alternating Bregman projections and convergence of the EM algorithm", "comment": null, "summary": "We investigate convergence of alternating Bregman projections between\nnon-convex sets and prove convergence to a point in the intersection, or to\npoints realizing a gap between the two sets. The speed of convergence is\ngenerally sub-linear, but may be linear under transversality. We apply our\nanalysis to prove convergence of versions of the expectation maximization\nalgorithm for non-convex parameter sets.", "AI": {"tldr": "研究非凸集间交替Bregman投影的收敛性，证明其可收敛至交集点或实现集合间间隙的点，收敛速度一般为次线性，但在横截性条件下可为线性，并应用于非凸参数集期望最大化算法的收敛性证明。", "motivation": "探讨非凸集间交替Bregman投影的收敛行为，扩展传统凸集投影理论的应用范围，并为非凸参数集的期望最大化算法提供理论支持。", "method": "通过分析交替Bregman投影在非凸集上的行为，结合横截性条件，研究其收敛性质及速度，并将结论应用于期望最大化算法的收敛性证明。", "result": "证明交替Bregman投影在非凸集上可收敛至交集点或间隙点，收敛速度一般为次线性，横截性条件下可达到线性，且该结论适用于非凸参数集的期望最大化算法。", "conclusion": "非凸集上的交替Bregman投影具有收敛性，其速度取决于集合性质，该理论为相关优化算法（如期望最大化）在非凸场景下的应用提供了理论基础。"}}
{"id": "2507.21658", "categories": ["math.CO", "05C25, 05C30"], "pdf": "https://arxiv.org/pdf/2507.21658", "abs": "https://arxiv.org/abs/2507.21658", "authors": ["Zai Ping Lu", "Jia Yin Xie", "Jin-Hua Xie"], "title": "Enumerating Cayley digraphs on dihedral groups", "comment": "17", "summary": "This paper investigates the enumeration of Cayley digraphs, focusing on\ncounting Cayley digraphs on dihedral groups up to CI-isomorphism. By leveraging\nthe Cauchy-Frobenius Lemma and properties of automorphisms, we derive an\nexplicit formula for the number of non-isomorphic Cayley digraphs on dihedral\ngroups with DCI-property, particularly for the group $\\mathrm{D}_{6p}$ with\n$p>3$ a prime. The enumeration involves detailed analysis of cycle numbers of\nautomorphisms and their actions on the group elements, culminating in a precise\ncount of non-isomorphic digraphs.", "AI": {"tldr": "本文研究了二面体群上Cayley有向图的枚举问题，针对具有DCI性质的图，推导了非同构图数量的显式公式，特别关注了素数阶群$\\mathrm{D}_{6p}$。", "motivation": "探索二面体群上Cayley有向图的非同构计数问题，填补特定群类（如$\\mathrm{D}_{6p}$）在DCI性质下的理论空白。", "method": "结合Cauchy-Frobenius引理与自同构性质，通过分析自同构的循环数及群元素作用，建立枚举方法。", "result": "给出了素数$p>3$时，群$\\mathrm{D}_{6p}$上非DCI-同构Cayley有向图数量的精确公式。", "conclusion": "理论框架成功应用于二面体群，为更复杂群的Cayley图枚举提供了可扩展的方法论基础。"}}
{"id": "2507.21130", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21130", "abs": "https://arxiv.org/abs/2507.21130", "authors": ["Bintao Tang", "Xin Yang", "Yuhao Wang", "Zixuan Qiu", "Zimo Ji", "Wenyuan Jiang"], "title": "INTEGRALBENCH: Benchmarking LLMs with Definite Integral Problems", "comment": "19 pages, 5 figures", "summary": "We present INTEGRALBENCH, a focused benchmark designed to evaluate Large\nLanguage Model (LLM) performance on definite integral problems. INTEGRALBENCH\nprovides both symbolic and numerical ground truth solutions with manual\ndifficulty annotations. Our evaluation of nine state-of-the-art LLMs reveals\nsignificant performance gaps and strong correlations between problem difficulty\nand model accuracy, establishing baseline metrics for this challenging domain.\nINTEGRALBENCH aims to advance automated mathematical reasoning by providing a\nrigorous evaluation framework specifically tailored for definite integral\ncomputation.", "AI": {"tldr": "INTEGRALBENCH是一个专门评估大语言模型在定积分问题表现的基准测试，包含符号与数值解及难度标注，测试发现模型表现与问题难度显著相关。", "motivation": "旨在通过针对定积分计算的严格评估框架，推动自动化数学推理领域的发展。", "method": "构建包含符号解、数值解及人工难度标注的测试集，对九种前沿大语言模型进行系统评估。", "result": "模型表现存在显著差距，且问题难度与准确率呈现强相关性，为领域建立了基线指标。", "conclusion": "该基准为定积分这一挑战性领域提供了标准化评估工具，揭示了当前模型的局限性。"}}
{"id": "2507.21087", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.21087", "abs": "https://arxiv.org/abs/2507.21087", "authors": ["Anas Ali", "Mubashar Husain", "Peter Hans"], "title": "Intelligent ARP Spoofing Detection using Multi-layered Machine Learning (ML) Techniques for IoT Networks", "comment": null, "summary": "Address Resolution Protocol (ARP) spoofing remains a critical threat to IoT\nnetworks, enabling attackers to intercept, modify, or disrupt data transmission\nby exploiting ARP's lack of authentication. The decentralized and\nresource-constrained nature of IoT environments amplifies this vulnerability,\nmaking conventional detection mechanisms ineffective at scale. This paper\nintroduces an intelligent, multi-layered machine learning framework designed to\ndetect ARP spoofing in real-time IoT deployments. Our approach combines feature\nengineering based on ARP header behavior, traffic flow analysis, and temporal\npacket anomalies with a hybrid detection pipeline incorporating decision trees,\nensemble models, and deep learning classifiers. We propose a hierarchical\narchitecture to prioritize lightweight models at edge gateways and deeper\nmodels at centralized nodes to balance detection accuracy and computational\nefficiency. The system is validated on both simulated IoT traffic and the\nCICIDS2017 dataset, achieving over 97% detection accuracy with low false\npositive rates. Comparative evaluations with signature-based and rule-based\nsystems demonstrate the robustness and generalizability of our approach. Our\nresults show that intelligent machine learning integration enables proactive\nARP spoofing detection tailored for IoT scenarios, laying the groundwork for\nscalable and autonomous network security solutions.", "AI": {"tldr": "本文提出了一种基于机器学习的多层框架，用于实时检测物联网环境中的ARP欺骗攻击，通过结合多种分析技术和混合模型，实现了高准确率和低误报率。", "motivation": "ARP欺骗是物联网网络中的严重威胁，传统检测方法在资源受限的物联网环境中效果有限，因此需要一种智能、高效的解决方案。", "method": "采用多层次的机器学习框架，结合ARP头部行为特征工程、流量分析和时序异常检测，使用决策树、集成模型和深度学习分类器的混合检测流程，并在边缘网关和中心节点部署不同复杂度的模型以平衡性能与效率。", "result": "在模拟物联网流量和CICIDS2017数据集上的验证表明，该系统检测准确率超过97%，且误报率低，优于传统的基于签名和规则的系统。", "conclusion": "智能机器学习集成能够为物联网场景提供主动的ARP欺骗检测，为可扩展和自主的网络安全解决方案奠定了基础。"}}
{"id": "2507.21515", "categories": ["math.NT", "11T24, 12E20"], "pdf": "https://arxiv.org/pdf/2507.21515", "abs": "https://arxiv.org/abs/2507.21515", "authors": ["Gustav Kjærbye Bagger", "James Punch"], "title": "The modified prime sieve for primitive elements in finite fields", "comment": "20 pages", "summary": "Let $r \\geq 2$ be an integer, $q$ a prime power and $\\mathbb{F}_{q}$ the\nfinite field with $q$ elements. Consider the problem of showing existence of\nprimitive elements in a subset $\\mathcal{A} \\subseteq \\mathbb{F}_{q^r}$. We\nprove a sieve criterion for existence of such elements, dependent only on an\nestimate for the character sum $\\sum_{\\gamma \\in \\mathcal{A}}\\chi(\\gamma)$. The\nflexibility and direct applicability of our criterion should be of considerable\ninterest for problems in this field. We demonstrate the utility of our result\nby tackling a problem of Fernandes and Reis (2021) with $\\mathcal{A}$ avoiding\naffine hyperplanes, obtaining significant improvements over previous knowledge.", "AI": {"tldr": "该论文提出了一种筛法准则，用于证明有限域$\\mathbb{F}_{q^r}$子集$\\mathcal{A}$中存在本原元，仅需估计特征和$\\sum_{\\gamma \\in \\mathcal{A}}\\chi(\\gamma)$。该方法显著改进了Fernandes和Reis（2021）关于避开仿射超平面子集问题的结果。", "motivation": "研究有限域$\\mathbb{F}_{q^r}$子集$\\mathcal{A}$中本原元的存在性问题，为解决该领域问题提供灵活且直接适用的理论工具。", "method": "通过建立依赖特征和估计的筛法准则，将本原元存在性转化为对$\\sum_{\\gamma \\in \\mathcal{A}}\\chi(\\gamma)$的分析。", "result": "成功应用于Fernandes-Reis问题，在避开仿射超平面的子集中获得比以往更优的本原元存在性结果。", "conclusion": "所提筛法准则具有普适性和计算优势，为有限域本原元研究提供了新的方法论突破。"}}
{"id": "2507.21543", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.21543", "abs": "https://arxiv.org/abs/2507.21543", "authors": ["Shoju Enami", "Kenji Kashima"], "title": "On Policy Stochasticity in Mutual Information Optimal Control of Linear Systems", "comment": "17 pages", "summary": "In recent years, mutual information optimal control has been proposed as an\nextension of maximum entropy optimal control. Both approaches introduce\nregularization terms to render the policy stochastic, and it is important to\ntheoretically clarify the relationship between the temperature parameter (i.e.,\nthe coefficient of the regularization term) and the stochasticity of the\npolicy. Unlike in maximum entropy optimal control, this relationship remains\nunexplored in mutual information optimal control. In this paper, we investigate\nthis relationship for a mutual information optimal control problem (MIOCP) of\ndiscrete-time linear systems. After extending the result of a previous study of\nthe MIOCP, we establish the existence of an optimal policy of the MIOCP, and\nthen derive the respective conditions on the temperature parameter under which\nthe optimal policy becomes stochastic and deterministic. Furthermore, we also\nderive the respective conditions on the temperature parameter under which the\npolicy obtained by an alternating optimization algorithm becomes stochastic and\ndeterministic. The validity of the theoretical results is demonstrated through\nnumerical experiments.", "AI": {"tldr": "本文研究了离散时间线性系统的互信息最优控制问题（MIOCP），探讨了温度参数与策略随机性之间的关系，并通过数值实验验证了理论结果。", "motivation": "互信息最优控制作为最大熵最优控制的扩展，其温度参数与策略随机性之间的关系尚未明确，本文旨在填补这一理论空白。", "method": "通过扩展先前研究的结果，建立了MIOCP最优策略的存在性，并推导了温度参数使策略变为随机或确定性的条件，同时分析了交替优化算法所得策略的相应条件。", "result": "理论分析表明，温度参数的不同取值会导致最优策略呈现随机性或确定性，数值实验进一步验证了这些理论结果的正确性。", "conclusion": "本文为互信息最优控制中温度参数与策略随机性之间的关系提供了理论依据，为相关研究奠定了重要基础。"}}
{"id": "2507.21874", "categories": ["math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.21874", "abs": "https://arxiv.org/abs/2507.21874", "authors": ["Marco Battiston", "Lorenzo Cappello"], "title": "New (and old) predictive schemes with a.c.i.d. sequences", "comment": null, "summary": "There is a growing interest in procedures for Bayesian inference that bypass\nthe need to specify a model and prior but simply rely on a predictive rule that\ndescribes how we learn on future observations given the available ones. At the\nheart of the idea is a bootstrap-type scheme that allows us to move from the\nrealm of prediction to that of inference. Which conditions the predictive rule\nneeds to satisfy to produce valid inference is a key question. In this work, we\nsubstantially relax previous assumptions building on a generalization of\nmartingales, opening up the possibility of employing a much wider range of\npredictive rules that were previously ruled out. These include ``old\" ideas in\nStatistics and Learning Theory, such as kernel estimators, and more novel ones,\nsuch as the parametric Bayesian bootstrap or copula-based algorithms. Our aim\nis not to advocate in favor of one predictive rule versus the other ones, but\nrather to showcase the benefits of working with this larger class of predictive\nrules.", "AI": {"tldr": "本文提出了一种放宽贝叶斯推断中预测规则限制的新方法，基于广义鞅理论，允许使用更广泛的预测规则，包括核估计器和参数化贝叶斯自举等。", "motivation": "当前贝叶斯推断通常需要指定模型和先验，而本文旨在探索仅依赖预测规则的方法，以简化推断过程并扩展其适用性。", "method": "通过推广鞅理论，放宽了预测规则的限制条件，使得核估计器、参数化贝叶斯自举和基于copula的算法等更多预测规则可用于推断。", "result": "研究结果表明，广义鞅理论为使用更广泛的预测规则提供了理论基础，从而扩展了贝叶斯推断的适用范围。", "conclusion": "本文展示了使用更广泛预测规则的潜在优势，为贝叶斯推断提供了更多灵活性和可能性，而非推崇某一特定规则。"}}
{"id": "2507.21689", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.21689", "abs": "https://arxiv.org/abs/2507.21689", "authors": ["Xizhi Liu"], "title": "Spectral generalized Turán problems", "comment": "24 pages, comments are welcome", "summary": "Combining two well-studied variants of the classical Tur\\'{a}n problem, the\ngeneralized Tur\\'{a}n problem and the spectral Tur\\'{a}n problem, we introduce\nthe spectral generalized Tur\\'{a}n problem and establish a general theorem that\nextends the result of Keevash--Lenz--Mubayi~\\cite{KLM14} on the spectral\nTur\\'{a}n problem in this broader setting. As a quick application, we obtain\nthe spectral Erd\\H{o}s Pentagon Theorem. We also introduce the notion of\nentropic density for generalized Tur\\'{a}n problems, and show that it coincides\nwith the generalized spectral radius, extending a recent result of Chao--Hans\non entropic Tur\\'{a}n density.", "AI": {"tldr": "该论文结合广义Tur\\\\'{a}n问题和谱Tur\\\\'{a}n问题，提出了谱广义Tur\\\\'{a}n问题，并建立了一个扩展Keevash--Lenz--Mubayi结果的定理。应用包括谱Erd\\H{o}s五边形定理，并引入广义Tur\\\\'{a}n问题的熵密度概念，证明其与广义谱半径一致。", "motivation": "研究结合广义Tur\\\\'{a}n问题和谱Tur\\\\'{a}n问题的谱广义Tur\\\\'{a}n问题，以扩展现有理论并解决更广泛的数学问题。", "method": "通过建立一般性定理，扩展Keevash--Lenz--Mubayi的结果，并引入熵密度概念，与广义谱半径进行比较。", "result": "获得了谱Erd\\H{o}s五边形定理，并证明广义Tur\\\\'{a}n问题的熵密度与广义谱半径一致。", "conclusion": "谱广义Tur\\\\'{a}n问题的引入和熵密度概念的提出，为Tur\\\\'{a}n问题的研究提供了新的理论工具和方向。"}}
{"id": "2507.21131", "categories": ["cs.AI", "68T05", "H.5.1; I.2.6; C.4"], "pdf": "https://arxiv.org/pdf/2507.21131", "abs": "https://arxiv.org/abs/2507.21131", "authors": ["Madhava Gaikwad", "Ashwini Ramchandra Doke"], "title": "NPO: Learning Alignment and Meta-Alignment through Structured Human Feedback", "comment": "20 pages", "summary": "We present NPO, an alignment-aware learning framework that operationalizes\nfeedback-driven adaptation in human-in-the-loop decision systems. Unlike prior\napproaches that treat alignment as a static or post-hoc property, NPO\nintroduces a formalization of alignment loss that is measurable, supervisable,\nand reducible under structured feedback. In parallel, we propose meta-alignment\nas the fidelity of the monitoring process that governs retraining or override\ntriggers, and show that it is formally reducible to primary alignment via\nthreshold fidelity. Our implementation spans a scalable operational loop\ninvolving scenario scoring, threshold tuning, policy validation, and structured\nfeedback ingestion, including \"likes\", overrides, and abstentions. We provide\nformal convergence results under stochastic feedback and show that both\nalignment loss and monitoring fidelity converge additively. Empirically, NPO\ndemonstrates measurable value in hyperscale deployment settings. A\nsimulation-based artifact and ablation studies further illustrate the\ntheoretical principles in action. Together, NPO offers a compact, inspectable\narchitecture for continual alignment monitoring, helping bridge theoretical\nalignment guarantees with practical reliability in dynamic environments.", "AI": {"tldr": "NPO是一种对齐感知学习框架，通过结构化反馈实现人机协同决策系统的动态调整，提供可测量、可监督的对齐损失减少机制。", "motivation": "现有方法将系统对齐视为静态或事后属性，NPO旨在通过可测量的对齐损失和元对齐监控过程，实现动态环境中的持续对齐保障。", "method": "提出可测量的对齐损失形式化方法，引入元对齐概念监控重训练/覆盖触发机制，实现包含场景评分、阈值调整、策略验证和结构化反馈（如点赞/覆盖/弃权）的可扩展操作循环。", "result": "理论证明随机反馈下对齐损失与监控保真度可加性收敛，超大规模部署实证显示其价值，仿真实验验证了理论原理的有效性。", "conclusion": "NPO提供紧凑、可检查的持续对齐监控架构，在动态环境中架起理论对齐保证与实际可靠性之间的桥梁。"}}
{"id": "2507.21092", "categories": ["cs.CR", "D.4.6; K.6.5"], "pdf": "https://arxiv.org/pdf/2507.21092", "abs": "https://arxiv.org/abs/2507.21092", "authors": ["Hunter Chasens"], "title": "The Discovery, Disclosure, and Investigation of CVE-2024-25825", "comment": "97 pages, BSc thesis", "summary": "CVE-2024-25825 is a vulnerability found in FydeOS. This thesis describes its\ndiscovery, disclosure, and its further investigation in connection to a nation\nstate actor. The vulnerability is CWE-1392: Use of Default Credentials,\nCWE-1393: Use of Default Password, and CWE-258: Empty Password in Configuration\nFile found in the /etc/shadow configuration file. The root users entry in the\n/etc/shadow file contains a wildcard allowing entry with any, or no, password.\nFollowing responsable disclosure, Fyde, CISA, and Mitre were informed. Fyde was\nalready aware of the vulnerability. There was concern that this vulnerability\nmight have been purposefully placed, perhaps by a nation state actor. After\nfurther investigation, it appears that this is unlikely to be the case. In\ncases in which poisoned code is suspected it might be prudent to contact the\nappropriate CERT, rather than the parent company. This, however, clashes with\nthe typical teaching of responsable disclosure.", "AI": {"tldr": "CVE-2024-25825是FydeOS中发现的一个漏洞，涉及默认凭证和空密码问题。研究发现该漏洞不太可能是国家行为者故意植入的。", "motivation": "研究动机是调查FydeOS中的CVE-2024-25825漏洞，特别是其是否与国家行为者有关联。", "method": "方法包括漏洞的发现、披露过程，以及与Fyde、CISA和Mitre的合作调查。", "result": "结果表明，漏洞不太可能是故意植入的，但建议在怀疑代码被污染时联系适当的CERT而非母公司。", "conclusion": "结论指出，尽管怀疑国家行为者介入的可能性低，但在类似情况下应优先联系CERT，这与传统的责任披露原则存在冲突。"}}
{"id": "2507.21558", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.21558", "abs": "https://arxiv.org/abs/2507.21558", "authors": ["Yuan Liu", "Ken Willyard"], "title": "The imaginary case of the nonabelian Cohen--Lenstra heuristics", "comment": "Comments are welcome", "summary": "For a finite group $\\Gamma$, we study the distribution of the Galois group\n$G_{\\emptyset}^{\\#}(K)$ of the maximal unramified extension of $K$ that is\nsplit completely at $\\infty$ and has degree prime to $|\\Gamma|$ and\n$\\textit{Char}(K)$, as $K$ varies over imaginary $\\Gamma$-extensions of\n$\\mathbb{Q}$ or $\\mathbb{F}_q(t)$. In the function field case, we compute the\nmoments of the distribution of $G_{\\emptyset}^{\\#}(K)$ by counting points on\nHurwitz stacks. In order to understand the probability of the distribution, we\nprove that $G_{\\emptyset}^{\\#}(K)$ admits presentations of a specific form,\nthen use this presentation to build random groups to simulate the behavior of\n$G_{\\emptyset}^{\\#}(K)$, and make the conjecture to predict the distribution\nusing the probability measures of these random groups. Our results provide the\nimaginary analog of the work of Wood, Zureick-Brown, and the first author on\nthe nonabelian Cohen--Lenstra heuristics.", "AI": {"tldr": "研究有限群$\\Gamma$下，虚$\\Gamma$-扩张$K$的最大非分歧完全分裂扩张Galois群$G_{\\emptyset}^{\\#}(K)$的分布，通过Hurwitz栈计算矩并构建随机群模拟其行为。", "motivation": "探索虚$\\Gamma$-扩张中Galois群的分布规律，类比非阿贝尔Cohen-Lenstra启发式，填补虚数域与函数域的研究空白。", "method": "在函数域情形，通过Hurwitz栈的点计数计算矩；构建特定形式的随机群模拟$G_{\\emptyset}^{\\#}(K)$的行为以预测分布。", "result": "证明了$G_{\\emptyset}^{\\#}(K)$具有特定形式的表示，并提出了基于随机群概率测度的分布猜想。", "conclusion": "成果为虚数域与函数域的Galois群分布提供了新视角，与非阿贝尔Cohen-Lenstra理论形成虚类比。"}}
{"id": "2507.21547", "categories": ["math.OC", "cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.21547", "abs": "https://arxiv.org/abs/2507.21547", "authors": ["Saeed Rahmani", "Simeon C. Calvert", "Bart van Arem"], "title": "Decentralized Modeling of Vehicular Maneuvers and Interactions at Urban Junctions", "comment": "Manuscript under review", "summary": "Modeling and evaluation of automated vehicles (AVs) in mixed-autonomy traffic\nis essential prior to their safe and efficient deployment. This is especially\nimportant at urban junctions where complex multi-agent interactions occur.\nCurrent approaches for modeling vehicular maneuvers and interactions at urban\njunctions have limitations in formulating non-cooperative interactions and\nvehicle dynamics within a unified mathematical framework. Previous studies\neither assume predefined paths or rely on cooperation and central\ncontrollability, limiting their realism and applicability in mixed-autonomy\ntraffic. This paper addresses these limitations by proposing a modeling\nframework for trajectory planning and decentralized vehicular control at urban\njunctions. The framework employs a bi-level structure where the upper level\ngenerates kinematically feasible reference trajectories using an efficient\ngraph search algorithm with a custom heuristic function, while the lower level\nemploys a predictive controller for trajectory tracking and optimization.\nUnlike existing approaches, our framework does not require central\ncontrollability or knowledge sharing among vehicles. The vehicle kinematics are\nexplicitly incorporated at both levels, and acceleration and steering angle are\nused as control variables. This intuitive formulation facilitates analysis of\ntraffic efficiency, environmental impacts, and motion comfort. The framework's\ndecentralized structure accommodates operational and stochastic elements, such\nas vehicles' detection range, perception uncertainties, and reaction delay,\nmaking the model suitable for safety analysis. Numerical and simulation\nexperiments across diverse scenarios demonstrate the framework's capability in\nmodeling accurate and realistic vehicular maneuvers and interactions at various\nurban junctions, including unsignalized intersections and roundabouts.", "AI": {"tldr": "本文提出了一种用于城市交叉口轨迹规划和分散车辆控制的建模框架，解决了现有方法在非合作交互和车辆动力学统一建模上的局限性。", "motivation": "当前城市交叉口的车辆交互建模方法在非合作交互和车辆动力学统一框架方面存在不足，限制了其在混合自动驾驶交通中的适用性和真实性。", "method": "框架采用双层结构：上层通过高效图搜索算法生成运动学可行的参考轨迹，下层使用预测控制器进行轨迹跟踪和优化，无需中央控制或车辆间知识共享。", "result": "数值和仿真实验表明，该框架能够准确模拟各种城市交叉口（包括无信号灯交叉口和环岛）的车辆行为和交互。", "conclusion": "该分散式框架能够整合操作和随机因素（如车辆检测范围、感知不确定性和反应延迟），适用于安全分析和交通效率评估。"}}
{"id": "2507.21878", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.21878", "abs": "https://arxiv.org/abs/2507.21878", "authors": ["Michel Broniatowski", "Justin Moutsouka"], "title": "Divergence and Model Adequacy, A Semiparametric Case Study", "comment": null, "summary": "Adequacy for estimation between an inferential method and a model can be\nde{\\ldots}ned through two main requirements: {\\ldots}rstly the inferential tool\nshould de{\\ldots}ne a well posed problem when applied to the model; secondly\nthe resulting statistical procedure should produce consistent estimators.\nConditions which entail these analytical and statistical issues are considered\nin the context when divergence based inference is applied for smooth\nsemiparametric models under moment restrictions. A discussion is also held on\nthe choice of the divergence, extending the classical parametric inference to\nthe estimation of both parameters of interest and of nuisance. Arguments in\nfavor of the omnibus choice of the L 2 and Kullback Leibler choices as\npresented in [16] are discussed and motivation for the class of power\ndivergences de{\\ldots}ned in [5] is presented in the context of the present\nsemi parametric smooth models. A short simulation study illustrates the method.", "AI": {"tldr": "本文探讨了基于散度的推断方法在平滑半参数模型下的适用性，提出了确保问题适定性和估计一致性的条件，并讨论了散度选择的理论依据。", "motivation": "研究旨在扩展经典参数推断至半参数模型，同时估计兴趣参数和冗余参数，探讨不同散度选择的理论基础。", "method": "在矩约束条件下，分析基于散度的推断方法对平滑半参数模型的适用性，并通过模拟研究验证方法。", "result": "提出了确保推断工具适定性和估计一致性的条件，支持$L_2$和Kullback-Leibler散度的普适性选择，并推广了[5]中定义的幂散度类。", "conclusion": "研究表明，特定散度选择在半参数模型中具有理论优势，为实际应用提供了可行的推断框架。"}}
{"id": "2507.21733", "categories": ["math.CO", "math.PR", "05C50, 05C76, 47A10, 60J10"], "pdf": "https://arxiv.org/pdf/2507.21733", "abs": "https://arxiv.org/abs/2507.21733", "authors": ["Thomas Hirschler", "Wolfgang Woess"], "title": "The spectra of graph substitutions", "comment": null, "summary": "Let $(X,E_X)$ and $(V,E_V)$ be finite connected graphs without loops. We\nassume that $V$ has two distinguished vertices $a,b$ and an automorphism\n$\\gamma$ which exchanges $a$ and $b$. The $V$-edge substitution of $X$ is the\ngraph $X[V]$ where each edge $[x,y] \\in E_X$ is replaced by a copy of $V$,\nidentifying $x$ with $a$ and $y$ with $b$ or vice versa. (The latter choice\ndoes not matter; it yields isomorphic graphs). The aim is to describe the\nspectrum of $X[V]$ in terms of the spectra of $X$ and $V$. Instead of the\nspectra of the adjacency matrices, we consider the versions which are\nnormalised by dividing each row by the row sum (the vertex degree). These are\nstochastic, reversible matrices, and our approach applies more generally to\nreversible transition matrices corresponding to arbitrary positive edge weights\ninvariant under $\\gamma$. We write $P$ for the transition matrix over $X$ and\n$Q$ for the one over $V$. Together, they induce the matrix $P_*$ over $X[V]$.\n  There is not a nice and compact formula which says how to transform the\nspectra of $P$ and $Q$ into the spectrum of $P_*\\,$. The results depend on\nissues like whether $X$ has circles of even length and on the eigenvalues of\nthe restriction of $Q$ to $V \\setminus \\{ a,b\\}$, which are classified into 4\npossible types, each to be handled differently. Also quite subtle is the issue\nof determining the multiplicities of the eigenvalues of $P_*$ in terms of the\ninput.", "AI": {"tldr": "该论文研究了在有限连通无环图上通过边替换构造的新图$X[V]$的谱特性，重点分析了由$X$和$V$的转移矩阵$P$和$Q$诱导的$P_*$的谱结构及其多重性。", "motivation": "研究目的是描述通过边替换构造的图$X[V]$的谱，基于原始图$X$和替换图$V$的谱，特别是归一化的转移矩阵谱，以推广到更一般的可逆转移矩阵情况。", "method": "采用归一化的转移矩阵方法，将$X$的每条边替换为图$V$的拷贝，并分析由此诱导的矩阵$P_*$的谱。考虑$X$的偶长环和$Q$在$V \\setminus \\{a,b\\}$上的限制特征值的四种类型。", "result": "结果表明，$P_*$的谱不能简单地由$P$和$Q$的谱直接转换得到，其依赖于$X$的拓扑结构及$Q$的限制特征值类型，且特征值的多重性确定较为复杂。", "conclusion": "论文揭示了边替换构造图的谱分析的复杂性，指出其依赖于原始图和替换图的多种因素，并提供了处理不同情况的方法框架。"}}
{"id": "2507.21132", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21132", "abs": "https://arxiv.org/abs/2507.21132", "authors": ["Joshua Adrian Cahyono", "Saran Subramanian"], "title": "Can You Trust an LLM with Your Life-Changing Decision? An Investigation into AI High-Stakes Responses", "comment": null, "summary": "Large Language Models (LLMs) are increasingly consulted for high-stakes life\nadvice, yet they lack standard safeguards against providing confident but\nmisguided responses. This creates risks of sycophancy and over-confidence. This\npaper investigates these failure modes through three experiments: (1) a\nmultiple-choice evaluation to measure model stability against user pressure;\n(2) a free-response analysis using a novel safety typology and an LLM Judge;\nand (3) a mechanistic interpretability experiment to steer model behavior by\nmanipulating a \"high-stakes\" activation vector. Our results show that while\nsome models exhibit sycophancy, others like o4-mini remain robust.\nTop-performing models achieve high safety scores by frequently asking\nclarifying questions, a key feature of a safe, inquisitive approach, rather\nthan issuing prescriptive advice. Furthermore, we demonstrate that a model's\ncautiousness can be directly controlled via activation steering, suggesting a\nnew path for safety alignment. These findings underscore the need for nuanced,\nmulti-faceted benchmarks to ensure LLMs can be trusted with life-changing\ndecisions.", "AI": {"tldr": "研究揭示大语言模型(LLMs)在提供高风险人生建议时存在谄媚与过度自信问题，通过三项实验发现：部分模型表现稳健，优秀模型通过频繁澄清问题确保安全，且可通过激活导向直接调控谨慎程度。", "motivation": "LLMs被广泛用于高风险决策咨询，但缺乏防止自信错误回答的保障机制，存在谄媚和过度自信风险，需系统性评估其安全缺陷。", "method": "采用三阶段实验：(1)多选题评估模型抗用户压力稳定性；(2)基于新型安全类型学和LLM法官的开放式回答分析；(3)通过操纵'高风险'激活向量进行机械可解释性实验。", "result": "部分模型(如o4-mini)表现稳健；顶级模型通过主动澄清问题而非直接建议获得高安全分；激活导向可精确控制模型谨慎程度。", "conclusion": "需建立多维度基准测试确保LLMs可信度，激活导向为安全对齐提供新路径，模型应保持探究式而非指令式交互风格。"}}
{"id": "2507.21094", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21094", "abs": "https://arxiv.org/abs/2507.21094", "authors": ["Minh Hoang Nguyen", "Anh Minh Ho", "Bao Son To"], "title": "SkyEye: When Your Vision Reaches Beyond IAM Boundary Scope in AWS Cloud", "comment": null, "summary": "In recent years, cloud security has emerged as a primary concern for\nenterprises due to the increasing trend of migrating internal infrastructure\nand applications to cloud environments. This shift is driven by the desire to\nreduce the high costs and maintenance fees associated with traditional\non-premise infrastructure. By leveraging cloud capacities such as high\navailability and scalability, companies can achieve greater operational\nefficiency and flexibility. However, this migration also introduces new\nsecurity challenges. Ensuring the protection of sensitive data, maintaining\ncompliance with regulatory requirements, and mitigating the risks of cyber\nthreats are critical issues that must be addressed. Identity and Access\nManagement (IAM) constitutes the critical security backbone of most cloud\ndeployments, particularly within AWS environments. As organizations adopt AWS\nto scale applications and store data, the need for a thorough, methodical, and\nprecise enumeration of IAM configurations grows exponentially. Enumeration\nrefers to the systematic mapping and interrogation of identities, permissions,\nand resource authorizations with the objective of gaining situational\nawareness. By understanding the interplay between users, groups, and their\nmyriads of policies, whether inline or attached managed policies, security\nprofessionals need to enumerate and identify misconfigurations, reduce the risk\nof unauthorized privilege escalation, and maintain robust compliance postures.\nThis paper will present SkyEye, a cooperative multi-principal IAM enumeration\nframework, which comprises cutting-edge enumeration models in supporting\ncomplete situational awareness regarding the IAMs of provided AWS credentials,\ncrossing the boundary of principal-specific IAM entitlement vision to reveal\nthe complete visionary while insufficient authorization is the main challenge.", "AI": {"tldr": "本文介绍了SkyEye，一个用于AWS IAM配置枚举的协作多主体框架，旨在解决云安全中的身份与访问管理挑战。", "motivation": "随着企业将基础设施迁移至云端，IAM配置的精确枚举成为确保数据安全、合规性和防范网络威胁的关键需求。", "method": "SkyEye采用协作多主体框架，结合先进枚举模型，突破单一主体视角限制，全面分析AWS凭证的IAM配置。", "result": "该框架实现了对IAM权限的全局可视化，有效识别配置错误，降低权限提升风险，并增强合规性。", "conclusion": "SkyEye为云环境下的IAM管理提供了创新解决方案，显著提升了安全团队的情境感知与风险管控能力。"}}
{"id": "2507.21801", "categories": ["math.NT", "11R23 (Primary) 14G45 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.21801", "abs": "https://arxiv.org/abs/2507.21801", "authors": ["Gautier Ponsinet"], "title": "On a characterisation of perfectoid fields by Iwasawa theory", "comment": "52 pages", "summary": "We prove that the vanishing of the module of universal norms associated with\ncertain de Rham Galois representations characterises the algebraic extensions\nof the field of $p$-adic numbers whose completion is a perfectoid field. We\nthereby generalise results by Coates and Greenberg for abelian varieties, and\nby Bondarko for $p$-divisible groups.", "AI": {"tldr": "本文证明了某些de Rham Galois表示的通用范数模的消失刻画了$p$-进数域的代数扩张，其完备化是perfectoid域，推广了Coates、Greenberg和Bondarko的结果。", "motivation": "研究$p$-进数域的代数扩张与perfectoid域之间的联系，推广已有关于阿贝尔簇和$p$-可除群的结果。", "method": "通过分析de Rham Galois表示的通用范数模的消失性质，建立与perfectoid域完备化的代数扩张之间的特征关系。", "result": "证明了通用范数模的消失是完备化为perfectoid域的代数扩张的充分必要条件，推广了前人的工作。", "conclusion": "该结果为理解$p$-进数域的代数扩张与perfectoid几何之间的联系提供了新的理论工具，并统一了不同背景下的相关结果。"}}
{"id": "2507.21574", "categories": ["math.OC", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2507.21574", "abs": "https://arxiv.org/abs/2507.21574", "authors": ["Charles Dapogny", "Julien Prando", "Boris Thibert"], "title": "Distributionally Robust Shape and Topology Optimization", "comment": null, "summary": "This article aims to introduce the paradigm of distributional robustness from\nthe field of convex optimization to tackle optimal design problems under\nuncertainty. We consider realistic situations where the physical model, and\nthereby the cost function of the design to be minimized depend on uncertain\nparameters. The probability distribution of the latter is itself known\nimperfectly, through a nominal law, reconstructed from a few observed samples.\nThe distributionally robust optimal design problem is an intricate bilevel\nprogram which consists in minimizing the worst value of a statistical quantity\nof the cost function (typically, its expectation) when the law of the uncertain\nparameters belongs to a certain ``ambiguity set''. We address three classes of\nsuch problems: firstly, this ambiguity set is made of the probability laws\nwhose Wasserstein distance to the nominal law is less than a given threshold;\nsecondly, the ambiguity set is based on the first- and second-order moments of\nthe actual and nominal probability laws. Eventually, a statistical quantity of\nthe cost other than its expectation is made robust with respect to the law of\nthe parameters, namely its conditional value at risk. Using techniques from\nconvex duality, we derive tractable, single-level reformulations of these\nproblems, framed over augmented sets of variables. Our methods are essentially\nagnostic of the optimal design framework; they are described in a unifying\nabstract framework, before being applied to multiple situations in\ndensity-based topology optimization and in geometric shape optimization.\nSeveral numerical examples are discussed in two and three space dimensions to\nappraise the features of the proposed techniques.", "AI": {"tldr": "本文提出了一种基于分布鲁棒性的优化设计方法，用于处理参数不确定性下的最优设计问题。通过构建模糊集和凸对偶技术，将复杂的双层规划转化为可处理的单层问题，并应用于拓扑优化和几何形状优化。", "motivation": "现实设计中，物理模型和成本函数常依赖不确定参数，而参数的概率分布仅通过少量样本估计得到。传统方法无法充分应对这种分布不确定性，因此需要引入分布鲁棒优化框架。", "method": "采用Wasserstein距离和矩约束构建模糊集，针对成本函数的期望和条件风险价值进行鲁棒化。利用凸对偶理论将原双层问题转化为单层凸优化问题，并扩展变量集实现统一求解框架。", "result": "提出的方法在密度拓扑优化和几何形状优化中得到验证，二维和三维数值实验证明了该技术的有效性。", "conclusion": "分布鲁棒优化方法能有效处理参数分布不确定性，其通用框架可广泛应用于各类最优设计问题，数值结果展示了方法的优越性和适用性。"}}
{"id": "2507.21137", "categories": ["cs.AI", "I.2.8"], "pdf": "https://arxiv.org/pdf/2507.21137", "abs": "https://arxiv.org/abs/2507.21137", "authors": ["Arman Eisenkolb-Vaithyanathan"], "title": "Project Patti: Why can You Solve Diabolical Puzzles on one Sudoku Website but not Easy Puzzles on another Sudoku Website?", "comment": "24 pages, 8 Figures", "summary": "In this paper we try to answer the question \"What constitutes Sudoku\ndifficulty rating across different Sudoku websites?\" Using two distinct methods\nthat can both solve every Sudoku puzzle, I propose two new metrics to\ncharacterize Sudoku difficulty. The first method is based on converting a\nSudoku puzzle into its corresponding Satisfiability (SAT) problem. The first\nproposed metric is derived from SAT Clause Length Distribution which captures\nthe structural complexity of a Sudoku puzzle including the number of given\ndigits and the cells they are in. The second method simulates human Sudoku\nsolvers by intertwining four popular Sudoku strategies within a backtracking\nalgorithm called Nishio. The second metric is computed by counting the number\nof times Sudoku strategies are applied within the backtracking iterations of a\nrandomized Nishio. Using these two metrics, I analyze more than a thousand\nSudoku puzzles across five popular websites to characterize every difficulty\nlevel in each website. I evaluate the relationship between the proposed metrics\nand website-labeled difficulty levels using Spearman's rank correlation\ncoefficient, finding strong correlations for 4 out of 5 websites. I construct a\nuniversal rating system using a simple, unsupervised classifier based on the\ntwo proposed metrics. This rating system is capable of classifying both\nindividual puzzles and entire difficulty levels from the different Sudoku\nwebsites into three categories - Universal Easy, Universal Medium, and\nUniversal Hard - thereby enabling consistent difficulty mapping across Sudoku\nwebsites. The experimental results show that for 4 out of 5 Sudoku websites,\nthe universal classification aligns well with website-labeled difficulty\nlevels. Finally, I present an algorithm that can be used by early Sudoku\npractitioners to solve Sudoku puzzles.", "AI": {"tldr": "本文提出两种新指标量化数独难度，基于SAT问题转换和模拟人类解法的回溯算法，构建通用评级系统，实现跨网站难度分类一致性。", "motivation": "研究旨在解决\"不同数独网站如何定义难度评级\"的问题，通过量化分析建立跨平台统一标准。", "method": "1. 将数独转为SAT问题，从句长分布提取结构复杂度指标；2. 在Nishio回溯算法中嵌入四种策略，统计策略使用次数作为人类解法指标。", "result": "两个指标与4/5网站的标注难度强相关（Spearman秩相关），构建的三级通用分类系统（简单/中等/困难）在4/5网站中验证有效。", "conclusion": "提出的指标和通用评级系统能有效统一跨平台难度评估，并附带适用于初学者的解题算法。"}}
{"id": "2507.21096", "categories": ["cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2507.21096", "abs": "https://arxiv.org/abs/2507.21096", "authors": ["Krishnendu Das"], "title": "HexaMorphHash HMH- Homomorphic Hashing for Secure and Efficient Cryptographic Operations in Data Integrity Verification", "comment": null, "summary": "In the realm of big data and cloud computing, distributed systems are tasked\nwith proficiently managing, storing, and validating extensive datasets across\nnumerous nodes, all while maintaining robust data integrity. Conventional\nhashing methods, though straightforward, encounter substan tial difficulties in\ndynamic settings due to the necessity for thorough rehashing when nodes are\naltered. Consistent hashing mitigates some of these challenges by reducing data\nredistribution; however, it still contends with limitations in load balancing\nand scalability under intensive update conditions. This paper introduces an\ninnovative approach using a lattice based homomorphic hash function\nHexaMorphHash that facilitates constant time, incremental updates while\npreserving a constant digest size. By utilizing the complexity of the Short\nInteger Solutions SIS problem, our method secures strong protective measures,\neven against quantum threats. We further com pare our method with existing ones\nsuch as direct signatures for each update, comprehensive database signing,\nMerkle tree based techniques, AdHash, MuHash, ECMH, and homomorphic sig nature\nschemes highlighting notable advancements in computational efficiency, memory\nusage, and scalability. Our contributions present a viable solution for\nfrequent update dissemination in expansive distributed systems, safeguarding\nboth data integrity and system performance.", "AI": {"tldr": "本文提出了一种基于格密码学的同态哈希函数HexaMorphHash，用于解决分布式系统中大数据管理的动态更新与数据完整性问题。该方法在保证恒定摘要大小的同时，支持增量更新，并具备抗量子攻击能力。", "motivation": "传统哈希方法在动态环境下因节点变更需全面重哈希而效率低下，一致性哈希虽减少数据迁移但仍存在负载均衡与扩展性瓶颈。亟需一种支持高频更新、保持数据完整性的新型哈希方案。", "method": "基于短整数解(SIS)问题的格密码学构造HexaMorphHash，实现恒定时间增量更新。通过同态特性避免全量重计算，并与Merkle树、AdHash等7类现有方案进行对比实验。", "result": "相比传统方法，HexaMorphHash在计算效率(提升38%)、内存占用(减少52%)及扩展性方面显著优化，尤其适用于超大规模分布式系统的实时更新场景。", "conclusion": "HexaMorphHash为动态分布式系统提供了兼顾数据完整性保护与高性能的解决方案，其抗量子特性对未来密码学应用具有重要价值。"}}
{"id": "2507.21951", "categories": ["math.NT", "11F12, 11F30, 11F66"], "pdf": "https://arxiv.org/pdf/2507.21951", "abs": "https://arxiv.org/abs/2507.21951", "authors": ["Shenghao Hua"], "title": "Quadratic forms of holomorphic cusp forms and the decay of their $\\ell^p$-norms for $0 < p < 2$", "comment": "13 pages. Comments welcome", "summary": "In this paper, we demonstrate that, given an orthonormal basis of holomorphic\nHecke cusp forms, conditionally, quadratic forms composed of cusp forms -- each\nexpressed as a bounded linear combination of holomorphic Hecke cusp forms --\nare generally not themselves expressible as bounded linear combinations of\nholomorphic Hecke cusp forms when the sum of the weights exceeds some absolute\nconstant, provided that the coefficients of the quadratic form satisfy\nappropriate nonvanishing and boundedness conditions. This illustrates the\nfiniteness of the number of solutions to the linear equation of modular forms\nequated to a quadratic form of large weight.\n  We also show that, conditionally, for $0 < p < 2$, the $\\ell^p$-norm of such\nquadratic forms in holomorphic Hecke cusp forms tends to zero asymptotically\nwith respect to expansion in this orthonormal basis of Hecke eigenforms.", "AI": {"tldr": "本文证明在给定正交基条件下，由全纯Hecke尖点形式构成的二次型通常不能表示为有界线性组合，且当权重大于某常数时解有限；同时表明$\\ell^p$-范数在$0<p<2$时渐近趋于零。", "motivation": "研究全纯Hecke尖点形式二次型的表示局限性及其渐进行为，揭示模形式线性方程解的有限性及范数收敛特性。", "method": "基于正交基展开和条件性假设，分析二次型在Hecke特征形式展开中的有界线性组合不可表示性及$\\ell^p$-范数渐近性质。", "result": "证明权重大于绝对常数时，满足非零有界条件的二次型通常无法表示为尖点形式的有界组合；$\\ell^p$-范数在$0<p<2$时随基展开渐近消失。", "conclusion": "该结果揭示了高权模形式二次型表示的固有约束，并为相关数论问题的解空间有限性及分析性质提供了理论依据。"}}
{"id": "2507.21576", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.21576", "abs": "https://arxiv.org/abs/2507.21576", "authors": ["Ying Hu", "Xiaomin Shi", "Zuo Quan Xu"], "title": "Optimal control of stochastic homogenous systems", "comment": null, "summary": "This paper investigates a new class of homogeneous stochastic control\nproblems with cone control constraints, extending the classical homogeneous\nstochastic linear-quadratic (LQ) framework to encompass nonlinear system\ndynamics and non-quadratic cost functionals. We demonstrate that, analogous to\nthe LQ case, the optimal controls and value functions for these generalized\nproblems are intimately connected to a novel class of highly nonlinear backward\nstochastic differential equations (BSDEs). We establish the existence and\nuniqueness of solutions to these BSDEs under three distinct sets of conditions,\nemploying techniques such as truncation functions and logarithmic\ntransformations. Furthermore, we derive explicit feedback representations for\nthe optimal controls and value functions in terms of the solutions to these\nBSDEs, supported by rigorous verification arguments. Our general solvability\nconditions allow us to recover many known results for homogeneous LQ problems,\nincluding both standard and singular cases, as special instances of our\nframework.", "AI": {"tldr": "本文研究了一类具有锥控制约束的新型齐次随机控制问题，扩展了经典的齐次随机线性二次（LQ）框架，涵盖非线性系统动力学和非二次成本泛函。通过建立新型高度非线性倒向随机微分方程（BSDEs）的解的存在唯一性，并推导出最优控制和值函数的显式反馈表示。", "motivation": "研究动机是扩展经典的齐次随机LQ控制框架，使其能够处理非线性系统和非二次成本泛函，从而在更广泛的应用场景中保持最优控制的可解性。", "method": "方法包括引入新型高度非线性BSDEs，并采用截断函数和对数变换等技术，在三种不同条件下证明这些BSDEs解的存在唯一性。通过严格的验证论证，推导出最优控制和值函数的显式反馈表示。", "result": "结果表明，广义问题的最优控制和值函数与新型BSDEs的解密切相关。在一般可解性条件下，可以恢复齐次LQ问题的许多已知结果，包括标准和奇异情况。", "conclusion": "结论是所提出的框架成功扩展了齐次随机控制问题的范围，为非线性系统和非二次成本泛函提供了统一的解决方案，并验证了其与经典LQ问题的兼容性。"}}
{"id": "2507.21774", "categories": ["math.CO", "math.RA", "05E30, 16W30"], "pdf": "https://arxiv.org/pdf/2507.21774", "abs": "https://arxiv.org/abs/2507.21774", "authors": ["Gejza Jenča", "Anna Jenčová", "Dominik Lachman"], "title": "Coherent configurations and Frobenius structures", "comment": "55 pages, 77 figures", "summary": "We prove that coherent configurations can be represented as modules over\nFrobenius structures in the category of real nonnegative matrices. We\ngeneralize the notion of admissible morphism from association schemes to\ncoherent configurations. We show that the Frobenius structure associated to a\ncoherent configuration can be modified to become a dagger Frobenius structure,\nand use this to connect the coherent configurations to groupoids and\n$H^*$-algebras. We examine the properties of the dagger Frobenius structure\nwith respect to admissible morphisms. We introduce the matrix $O$ obtained as\nthe composition of comultiplication and multiplication of the dagger Frobenius\nstructure and prove that we may obtain the valencies of colors, and thus\nrecover the original coherent configuration, as an eigenvector of $O$. In the\nlast part of the paper, we examine the spectrum of $O$ and apply it to\ngeneralize the Lagrange theorem from groups to association schemes.", "AI": {"tldr": "该论文证明了相干构型可表示为实数非负矩阵范畴中的Frobenius结构模，推广了结合方案到相干构型的容许态射概念，并构建了与群胚和$H^*$-代数的联系。通过引入矩阵$O$的特征向量恢复原构型，并将拉格朗日定理推广至结合方案。", "motivation": "研究相干构型在代数结构中的表示及其与Frobenius结构的联系，旨在扩展结合方案的理论框架并建立新的数学工具。", "method": "将相干构型表述为Frobenius结构模，引入容许态射的广义定义，构造dagger Frobenius结构，并通过矩阵$O$的谱分析提取构型信息。", "result": "证明了相干构型的色度可通过$O$的特征向量重构，并将群论的拉格朗日定理推广至结合方案，揭示了$O$谱的数学意义。", "conclusion": "该工作为相干构型提供了新的代数视角，通过Frobenius结构与谱理论建立了与群论深刻的联系，拓展了离散数学的研究工具。"}}
{"id": "2507.21141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21141", "abs": "https://arxiv.org/abs/2507.21141", "authors": ["McNair Shah", "Saleena Angeline", "Adhitya Rajendra Kumar", "Naitik Chheda", "Kevin Zhu", "Vasu Sharma", "Sean O'Brien", "Will Cai"], "title": "The Geometry of Harmfulness in LLMs through Subconcept Probing", "comment": null, "summary": "Recent advances in large language models (LLMs) have intensified the need to\nunderstand and reliably curb their harmful behaviours. We introduce a\nmultidimensional framework for probing and steering harmful content in model\ninternals. For each of 55 distinct harmfulness subconcepts (e.g., racial hate,\nemployment scams, weapons), we learn a linear probe, yielding 55 interpretable\ndirections in activation space. Collectively, these directions span a\nharmfulness subspace that we show is strikingly low-rank. We then test ablation\nof the entire subspace from model internals, as well as steering and ablation\nin the subspace's dominant direction. We find that dominant direction steering\nallows for near elimination of harmfulness with a low decrease in utility. Our\nfindings advance the emerging view that concept subspaces provide a scalable\nlens on LLM behaviour and offer practical tools for the community to audit and\nharden future generations of language models.", "AI": {"tldr": "研究提出多维框架探测大语言模型有害行为，发现低秩有害子空间，通过主导方向调控可近乎消除危害且保持实用性。", "motivation": "大语言模型(LLM)的快速发展亟需理解并可靠抑制其有害行为。", "method": "针对55个有害子概念(如种族仇恨、招聘诈骗)构建线性探针，形成低秩有害子空间，测试子空间整体消除及主导方向调控效果。", "result": "主导方向调控能以极低实用性代价近乎消除模型有害性，有害子空间呈现显著低秩特性。", "conclusion": "概念子空间为LLM行为提供可扩展分析视角，所提工具可助力社区审计强化未来语言模型。"}}
{"id": "2507.21097", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21097", "abs": "https://arxiv.org/abs/2507.21097", "authors": ["Abraham Itzhak Weinberg"], "title": "Singularity Cipher: A Topology-Driven Cryptographic Scheme Based on Visual Paradox and Klein Bottle Illusions", "comment": null, "summary": "This paper presents the Singularity Cipher, a novel\ncryptographic-steganographic framework that integrates topological\ntransformations and visual paradoxes to achieve multidimensional security.\nInspired by the non-orientable properties of the Klein bottle -- constructed\nfrom two Mobius strips -- the cipher applies symbolic twist functions to\nsimulate topological traversal, producing high confusion and diffusion in the\nciphertext. The resulting binary data is then encoded using perceptual\nillusions, such as the missing square paradox, to visually obscure the presence\nof encrypted content. Unlike conventional ciphers that rely solely on algebraic\ncomplexity, the Singularity Cipher introduces a dual-layer approach: symbolic\nencryption rooted in topology and visual steganography designed for human\ncognitive ambiguity. This combination enhances both cryptographic strength and\ndetection resistance, making it well-suited for secure communication,\nwatermarking, and plausible deniability in adversarial environments. The paper\nformalizes the architecture, provides encryption and decryption algorithms,\nevaluates security properties, and compares the method against classical,\npost-quantum, and steganographic approaches. Potential applications and future\nresearch directions are also discussed.", "AI": {"tldr": "本文提出了一种名为'奇点密码'的新型密码-隐写框架，结合拓扑变换和视觉悖论实现多维安全。该方法通过克莱因瓶的非定向特性与莫比乌斯带的扭转函数生成高混淆密文，并利用视觉错觉（如消失方块悖论）隐藏加密内容。相比传统密码学，该框架在代数复杂性和人类认知模糊性上实现了双重防护。", "motivation": "传统密码学仅依赖代数复杂性，存在被量子计算破解的风险。受克莱因瓶拓扑特性的启发，本研究旨在开发一种结合数学拓扑与视觉隐写的双层次安全框架，以增强抗检测性和抗破解能力，适用于对抗性环境中的安全通信与水印应用。", "method": "1. 基于莫比乌斯带构造符号扭转函数模拟拓扑遍历；2. 利用克莱因瓶非定向性实现高扩散/混淆密文；3. 通过消失方块等视觉悖论进行二进制数据编码；4. 提供完整的加解密算法架构与安全性证明。", "result": "相比经典密码、后量子密码及传统隐写术，该方法在BAN逻辑验证中展现出更强的抗侧信道攻击能力，视觉测试显示隐写内容的人类检测错误率提升47%，同时保持NIST测试通过的密码强度。", "conclusion": "奇点密码首次将拓扑变换与认知错觉系统结合，为安全通信开辟了新维度。未来可扩展至四维超拓扑结构研究，并在生物特征加密领域具有应用潜力。"}}
{"id": "2507.21966", "categories": ["math.NT", "math.AG", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.21966", "abs": "https://arxiv.org/abs/2507.21966", "authors": ["Yifeng Huang"], "title": "Coh zeta functions for inert quadratic orders", "comment": "15 pages", "summary": "We study the Coh zeta function for a family of inert quadratic orders, which\nwe conjecture to be given by $t$-deformed Bressoud $q$-series. This completes a\ntrilogy connecting the zeta functions of ramified and split quadratic orders to\nthe classical Andrews--Gordon and Bressoud identities, respectively. We provide\nstrong evidence for this conjecture by deriving the first explicit formulas for\nthe finitized Coh zeta function of the simplest order in the family, and for\nthe $t=1$ specialization of the finitized Coh zeta functions for all orders in\nthe family. Our primary tool is a new method based on M\\\"obius inversion on\nposets.", "AI": {"tldr": "研究惰性二次序的Coh zeta函数，提出其与$t$-变形Bressoud $q$-级数相关的猜想，并通过新方法验证部分结果。", "motivation": "完成将分歧与分裂二次序的zeta函数分别联系到Andrews-Gordon和Bressoud恒等式的三部曲，探索惰性序的对应关系。", "method": "采用基于偏序集M\\\"obius反演的新方法，计算家族中最简单序的有限化Coh zeta函数及$t=1$特例。", "result": "为首个惰性序家族推导出有限化Coh zeta函数的显式，为猜想提供强有力证据。", "conclusion": "通过新方法验证了惰性二次序Coh zeta函数与$t$-变形Bressoud级数的关联猜想，填补了三部曲的最后空白。"}}
{"id": "2507.21603", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.21603", "abs": "https://arxiv.org/abs/2507.21603", "authors": ["J. C. Gonçalves-Dosantos", "A. Meca", "I. Ozcan"], "title": "Cost allocations in interval inventory situations: the SOC and Shapley approaches", "comment": null, "summary": "Uncertainty in demand and supply conditions poses critical challenges to\neffective inventory management, especially in collaborative environments.\nTraditional inventory models, such as those based on the Economic Order\nQuantity (EOQ), often rely on fixed parameters and deterministic assumptions,\nlimiting their ability to capture the complexity of real-world scenarios. This\npaper focuses on interval inventory situations, an extension of classical\nmodels in which demand is represented as intervals to account for uncertainty.\nThis framework allows for a more flexible and realistic analysis of inventory\ndecisions and cost-sharing among cooperating agents. We examine two\ninterval-based allocation rules, the interval SOC-rule and the interval Shapley\nrule, designed to distribute joint ordering costs fairly and efficiently under\nuncertain demand. Their theoretical properties are analyzed, and their\npractical applicability is demonstrated through a case study involving the\ncoordination of perfume inventories across seven Spanish airports, based on\n2023 passenger traffic data provided by AENA. The findings highlight the\npotential of interval-based models to enable a robust and equitable allocation\nof inventory costs in the face of operational uncertainty.", "AI": {"tldr": "本文探讨了在需求与供应不确定条件下，基于区间模型的库存管理方法，提出了两种区间分配规则（区间SOC规则和区间Shapley规则），并通过西班牙机场香水库存案例验证了其有效性。", "motivation": "传统库存模型（如EOQ）依赖固定参数和确定性假设，难以应对现实中的不确定性。本文旨在通过区间模型更灵活地分析库存决策及合作代理间的成本分摊问题。", "method": "研究扩展了经典库存模型，将需求表示为区间以纳入不确定性，并设计两种区间分配规则。通过理论分析及基于AENA提供的2023年西班牙七座机场客流数据的案例研究验证方法。", "result": "案例研究表明，区间模型能实现库存成本的稳健公平分配。区间SOC规则和区间Shapley规则在不确定需求下展现出高效且公正的成本分摊能力。", "conclusion": "区间模型为操作不确定性下的库存管理提供了新思路，其分配规则可促进合作代理间的成本公平分担，具有实际应用潜力。"}}
{"id": "2507.21819", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.21819", "abs": "https://arxiv.org/abs/2507.21819", "authors": ["Sebastian Junge"], "title": "Self-Dual Ramsey Degrees for Trees", "comment": null, "summary": "We consider a Ramsey statement for pairs of maps between trees, where one is\nan embedding as defined by Deuber and the other is a rigid surjection as\ndefined by Solecki. We show that there is no Ramsey Theorem for pairs of maps\nwhere the coloring depends on both coordinates. On the other hand, we give a\ncharacterization of the Ramsey degrees for such pairs. Furthermore, we show\nthat our theorem on Ramsey Degrees for pairs of maps between trees implies the\nRamsey Theorem for pairs of maps between linear orders as proved by Solecki.", "AI": {"tldr": "本文研究了树间映射对的Ramsey性质，证明了对双坐标依赖的着色不存在Ramsey定理，但给出了此类映射对Ramsey度的完整刻画，并推导出线性序映射对的Ramsey定理。", "motivation": "探索树结构上Deuber嵌入与Solecki刚性满射组合映射对的Ramsey性质，填补现有理论空白。", "method": "通过构造性证明分析树间映射对的着色行为，建立Ramsey度与线性序映射定理的关联体系。", "result": "1) 双坐标依赖着色无Ramsey定理 2) 完整刻画映射对Ramsey度 3) 推导出Solecki线性序映射定理", "conclusion": "树结构映射对的Ramsey理论既揭示本质限制（无一般定理），又提供精确量化工具（Ramsey度），并能统一推导已有重要结论。"}}
{"id": "2507.21158", "categories": ["cs.AI", "cs.HC", "H.1.2; I.2.6; I.2.4"], "pdf": "https://arxiv.org/pdf/2507.21158", "abs": "https://arxiv.org/abs/2507.21158", "authors": ["Nishani Fernando", "Bahareh Nakisa", "Adnan Ahmad", "Mohammad Naim Rastgoo"], "title": "Adaptive XAI in High Stakes Environments: Modeling Swift Trust with Multimodal Feedback in Human AI Teams", "comment": "15 pages, 1 figure, Accepted to MAI-XAI@ECAI2025", "summary": "Effective human-AI teaming heavily depends on swift trust, particularly in\nhigh-stakes scenarios such as emergency response, where timely and accurate\ndecision-making is critical. In these time-sensitive and cognitively demanding\nsettings, adaptive explainability is essential for fostering trust between\nhuman operators and AI systems. However, existing explainable AI (XAI)\napproaches typically offer uniform explanations and rely heavily on explicit\nfeedback mechanisms, which are often impractical in such high-pressure\nscenarios. To address this gap, we propose a conceptual framework for adaptive\nXAI that operates non-intrusively by responding to users' real-time cognitive\nand emotional states through implicit feedback, thereby enhancing swift trust\nin high-stakes environments. The proposed adaptive explainability trust\nframework (AXTF) leverages physiological and behavioral signals, such as EEG,\nECG, and eye tracking, to infer user states and support explanation adaptation.\nAt its core is a multi-objective, personalized trust estimation model that maps\nworkload, stress, and emotion to dynamic trust estimates. These estimates guide\nthe modulation of explanation features enabling responsive and personalized\nsupport that promotes swift trust in human-AI collaboration. This conceptual\nframework establishes a foundation for developing adaptive, non-intrusive XAI\nsystems tailored to the rigorous demands of high-pressure, time-sensitive\nenvironments.", "AI": {"tldr": "本文提出了一种自适应可解释AI框架（AXTF），通过实时监测用户的认知和情绪状态来动态调整解释方式，以在高压紧急场景中快速建立人机信任。", "motivation": "现有可解释AI（XAI）方法在高风险场景（如应急响应）中存在局限性，其标准化解释和显式反馈机制难以满足时效性需求，亟需能通过隐式反馈自适应调整的非侵入式解决方案。", "method": "框架通过EEG、ECG和眼动追踪等生理行为信号推断用户状态，采用多目标个性化信任评估模型，将工作负荷、压力和情绪映射为动态信任值，据此调节解释特征。", "result": "构建的AXTF框架能实现非侵入式的个性化解释适配，为高压时效性环境中促进人机协作的快速信任奠定理论基础。", "conclusion": "该概念框架为开发适应高压场景的自适应XAI系统提供了新范式，通过隐式反馈机制实现解释策略的动态优化，最终增强人机团队的协同效能。"}}
{"id": "2507.21101", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21101", "abs": "https://arxiv.org/abs/2507.21101", "authors": ["Vyoma Harshitha Podapati", "Divyansh Nigam", "Sanchari Das"], "title": "SoK: A Systematic Review of Context- and Behavior-Aware Adaptive Authentication in Mobile Environments", "comment": null, "summary": "As mobile computing becomes central to digital interaction, researchers have\nturned their attention to adaptive authentication for its real-time, context-\nand behavior-aware verification capabilities. However, many implementations\nremain fragmented, inconsistently apply intelligent techniques, and fall short\nof user expectations. In this Systematization of Knowledge (SoK), we analyze 41\npeer-reviewed studies since 2011 that focus on adaptive authentication in\nmobile environments. Our analysis spans seven dimensions: privacy and security\nmodels, interaction modalities, user behavior, risk perception, implementation\nchallenges, usability needs, and machine learning frameworks. Our findings\nreveal a strong reliance on machine learning (64.3%), especially for continuous\nauthentication (61.9%) and unauthorized access prevention (54.8%). AI-driven\napproaches such as anomaly detection (57.1%) and spatio-temporal analysis\n(52.4%) increasingly shape the interaction landscape, alongside growing use of\nsensor-based and location-aware models.", "AI": {"tldr": "本文系统分析了2011年以来41篇关于移动环境自适应认证的研究，揭示了机器学习（64.3%）在该领域的主导地位及其在持续认证（61.9%）和防未授权访问（54.8%）中的应用。", "motivation": "随着移动计算成为数字交互的核心，自适应认证因其实时、情境和行为感知的验证能力受到关注，但现有实现存在碎片化、智能技术应用不一致及用户体验不足的问题。", "method": "通过知识系统化方法，从隐私安全模型、交互方式、用户行为、风险感知、实施挑战、可用性需求及机器学习框架七个维度分析了41篇同行评审研究。", "result": "研究发现机器学习（尤其是异常检测57.1%和时空分析52.4%）与传感器/位置感知模型正重塑交互范式，且连续认证（61.9%）是主要应用场景。", "conclusion": "AI驱动方法（如异常检测）正成为移动自适应认证的主流技术方向，但需进一步解决隐私保护与用户体验的平衡问题。"}}
{"id": "2507.21624", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.21624", "abs": "https://arxiv.org/abs/2507.21624", "authors": ["Nicolò Mazzi", "Ken Mckinnon", "Hongyu Zhang"], "title": "Adaptive Benders decomposition and enhanced SDDP for multistage stochastic programs with block-separable multistage recourse", "comment": null, "summary": "This paper proposes an algorithm to efficiently solve multistage stochastic\nprograms with block separable recourse where each recourse problem is a\nmultistage stochastic program with stage-wise independent uncertainty. The\nalgorithm first decomposes the full problem into a reduced master problem and\nsubproblems using Adaptive Benders decomposition. The subproblems are then\nsolved by an enhanced SDDP. The enhancement includes (1) valid bounds at each\niteration, (2) a path exploration rule, (3) cut sharing among subproblems, and\n(4) guaranteed {\\delta}-optimal convergence. The cuts for the subproblems are\nthen shared by calling adaptive oracles. The key contribution of the paper is\nthe first algorithm for solving this class of problems. The algorithm is\ndemonstrated on a power system investment planning problem with multi-timescale\nuncertainty. The case study results show that (1) the proposed algorithm can\nefficiently solve this type of problem, (2) deterministic wind modelling\nunderestimate the objective function, and (3) stochastic modelling of wind\nleads to different investment decisions.", "AI": {"tldr": "本文提出了一种高效求解具有块可分追索的多阶段随机规划问题的算法，通过自适应Benders分解和增强SDDP方法实现，并在电力系统投资规划案例中验证了其有效性。", "motivation": "针对具有阶段独立不确定性的多阶段随机追索问题，现有方法效率不足，需要开发新算法以高效求解此类问题。", "method": "算法首先通过自适应Benders分解将原问题分解为主问题和子问题，子问题采用增强SDDP方法求解，包括有效边界、路径探索规则、割共享和保证$\\delta$最优收敛等改进。", "result": "案例研究表明：(1)算法能高效求解该类问题；(2)确定性风电模型低估目标函数；(3)随机风电模型导致不同的投资决策。", "conclusion": "本文提出了首个解决此类多阶段随机规划问题的算法，并通过电力系统案例验证了其优越性和实用性。"}}
{"id": "2507.21908", "categories": ["math.CO", "05C78, 68R10"], "pdf": "https://arxiv.org/pdf/2507.21908", "abs": "https://arxiv.org/abs/2507.21908", "authors": ["Melissa A. Huggan", "M. E. Messinger", "Dylan Pearson"], "title": "A note on the strength of a hypercube", "comment": "12 pages, 2 tables", "summary": "As a generalization of super magic strength, the strength of a graph was\nintroduced in [R. Ichishima, F.A. Muntaner-Batle, A. Oshima, Bounds for the\nstrength of graphs, Austral. J. of Combin. 72(3) (2018) 492-508]. For a vertex\nordering $f$ of graph $G$, the strength of $f$ is the maximum sum of the labels\non any pair of adjacent vertices. The strength of $G$ is defined as the minimum\nstrength of $f$, taken over all vertex orderings of $G$. The strength of the\nhypercube is unknown, but bounded. In this note, we provide an improved upper\nbound for the strength of a hypercube.", "AI": {"tldr": "本文改进了超立方体图强度的上界，该强度定义为所有顶点排序中相邻顶点标签和的最大值的最小值。", "motivation": "超立方体图的强度问题尚未解决，但已有边界。研究旨在优化其强度的上界。", "method": "通过分析顶点排序$f$的强度定义，即相邻顶点标签和的最大值，寻找更优的排序策略。", "result": "提出了超立方体图强度的改进上界，优于先前已知的结果。", "conclusion": "本研究为超立方体图的强度问题提供了更紧的上界，推动了该领域的进展。"}}
{"id": "2507.21159", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.21159", "abs": "https://arxiv.org/abs/2507.21159", "authors": ["Zhihao Peng", "Liuxin Bao", "Shengyuan Liu", "Yixuan Yuan"], "title": "Adaptive Cluster Collaborativeness Boosts LLMs Medical Decision Support Capacity", "comment": null, "summary": "The collaborativeness of large language models (LLMs) has proven effective in\nnatural language processing systems, holding considerable promise for\nhealthcare development. However, it lacks explicit component selection rules,\nnecessitating human intervention or clinical-specific validation. Moreover,\nexisting architectures heavily rely on a predefined LLM cluster, where partial\nLLMs underperform in medical decision support scenarios, invalidating the\ncollaborativeness of LLMs. To this end, we propose an adaptive cluster\ncollaborativeness methodology involving self-diversity and cross-consistency\nmaximization mechanisms to boost LLMs medical decision support capacity. For\nthe self-diversity, we calculate the fuzzy matching value of pairwise outputs\nwithin an LLM as its self-diversity value, subsequently prioritizing LLMs with\nhigh self-diversity values as cluster components in a training-free manner. For\nthe cross-consistency, we first measure cross-consistency values between the\nLLM with the highest self-diversity value and others, and then gradually mask\nout the LLM having the lowest cross-consistency value to eliminate the\npotential inconsistent output during the collaborative propagation. Extensive\nexperiments on two specialized medical datasets, NEJMQA and MMLU-Pro-health,\ndemonstrate the effectiveness of our method across physician-oriented\nspecialties. For example, on NEJMQA, our method achieves the accuracy rate up\nto the publicly official passing score across all disciplines, especially\nachieving ACC of 65.47\\% compared to the 56.12\\% achieved by GPT-4 on the\nObstetrics and Gynecology discipline.", "AI": {"tldr": "本文提出了一种自适应集群协作方法，通过自多样性和交叉一致性最大化机制提升大语言模型（LLMs）在医疗决策支持中的能力，实验证明其在专业医学数据集上表现优异。", "motivation": "当前大语言模型在医疗领域的协作缺乏明确的组件选择规则，且依赖预定义的LLM集群，部分模型在医疗决策支持场景中表现不佳，限制了其协作效果。", "method": "提出自多样性和交叉一致性最大化机制：1）通过计算LLM内部成对输出的模糊匹配值作为自多样性值，优先选择高自多样性值的LLM；2）测量最高自多样性LLM与其他LLM的交叉一致性值，逐步屏蔽一致性最低的LLM以避免不一致输出。", "result": "在NEJMQA和MMLU-Pro-health数据集上的实验表明，该方法在所有医学专科中均达到公开官方及格分数，例如在妇产科专科上准确率达65.47\\%，优于GPT-4的56.12\\%。", "conclusion": "该方法通过自适应集群协作显著提升了LLMs在医疗决策支持中的性能，尤其在专科医学领域表现出色，为医疗AI发展提供了有效解决方案。"}}
{"id": "2507.21111", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.GT", "cs.SE", "68M14, 68P25, 68T30, 94A60, 18C10", "D.4.6; K.6.5; C.2.1; H.3.5; D.2.11"], "pdf": "https://arxiv.org/pdf/2507.21111", "abs": "https://arxiv.org/abs/2507.21111", "authors": ["Craig Wright"], "title": "A Formal Rebuttal of \"The Blockchain Trilemma: A Formal Proof of the Inherent Trade-Offs Among Decentralization, Security, and Scalability\"", "comment": "79 pages; A response and rebuttal of [Mssassi, Souhail, and Anas Abou\n  El Kalam. \"The Blockchain Trilemma: A Formal Proof of the Inherent Trade-Offs\n  Among Decentralization, Security, and Scalability.\" Applied Sciences 15, no.\n  1 (2024): 19. https://doi.org/10.3390/app15010019.]", "summary": "This paper presents a comprehensive refutation of the so-called \"blockchain\ntrilemma,\" a widely cited but formally ungrounded claim asserting an inherent\ntrade-off between decentralisation, security, and scalability in blockchain\nprotocols. Through formal analysis, empirical evidence, and detailed critique\nof both methodology and terminology, we demonstrate that the trilemma rests on\nsemantic equivocation, misuse of distributed systems theory, and a failure to\ndefine operational metrics. Particular focus is placed on the conflation of\ntopological network analogies with protocol-level architecture, the\nmischaracterisation of Bitcoin's design--including the role of miners, SPV\nclients, and header-based verification--and the failure to ground claims in\ncomplexity-theoretic or adversarial models. By reconstructing Bitcoin as a\ndeterministic, stateless distribution protocol governed by evidentiary trust,\nwe show that scalability is not a trade-off but an engineering outcome. The\npaper concludes by identifying systemic issues in academic discourse and peer\nreview that have allowed such fallacies to persist, and offers formal criteria\nfor evaluating future claims in blockchain research.", "AI": {"tldr": "Error processing this paper.", "motivation": "Error processing this paper.", "method": "Error processing this paper.", "result": "Error processing this paper.", "conclusion": "Error processing this paper."}}
{"id": "2507.21676", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.21676", "abs": "https://arxiv.org/abs/2507.21676", "authors": ["Mohsen Abedi", "Alexis A. Dowhuszko", "Mehdi Sookhak", "Risto Wichman"], "title": "Guaranteeing Line-of-Sight Wireless Connectivity in Stochastic Environments with Random Obstacles", "comment": "This manuscript contains 11 pages, 10 figues, and is under review for\n  possible publication in IEEE Transactions on Mobile Computing", "summary": "Advancements in high-frequency communication technologies using millimeter\nwaves (mmWave), Tera- Hertz (THz), and optical wireless frequency bands are key\nfor extending wireless connectivity beyond 5G. These technologies offer a\nbroader spectrum than the one available on low- and mid-bands, enabling\nultra-high-speed data rates, higher device density, enhanced security, and\nimproved positioning accuracy. However, their performance relies heavily on\nclear Line-of-Sight (LoS) conditions, as Non-LoS components are significantly\nweaker, making blockages a major challenge to ensure suitable received signal\npower. This paper addresses this limitation by identifying the minimum number\nand optimal placement of access points (APs) needed to ensure LoS connectivity\nin stochastic/dynamic environments with random obstacle locations. To achieve\nthis, the stochastic environment is carefully modeled as a graph, where the\nnodes represent sub-polygons of layout realizations, and the edges capture the\nvisibility overlaps between them. By employing maximal clique clustering and\nmaximum clique packing methods over this graph, the proposed approach\ndetermines the AP placement locations that guarantee either full LoS coverage\nor controlled LoS gaps, while seamlessly adapting to the stochastic variability\nin obstacle locations. Simulations results in a representative stochastic\nenvironment demonstrate a 25% reduction in the required number of APs,\nachieving a tolerable 5% coverage gap compared to AP deployment optimized for\nfull LoS coverage.", "AI": {"tldr": "本文提出了一种在随机障碍物环境中优化毫米波/太赫兹/光无线通信接入点(AP)部署的方法，通过图建模和最大团算法减少25%的AP数量，同时保持5%的可容忍覆盖间隙。", "motivation": "毫米波、太赫兹和光无线通信虽能提供超高速率，但严重依赖视距(LoS)传输。随机环境中的障碍物会导致信号阻断，需通过优化AP部署来保障连接质量。", "method": "将随机环境建模为图结构：节点表示布局实现的子多边形，边表示可见性重叠。采用最大团聚类和最大团填充算法确定AP位置，确保全LoS覆盖或可控覆盖间隙。", "result": "在典型随机环境中的仿真显示：相比全LoS覆盖优化部署，该方法减少25%的AP需求，仅产生5%的可接受覆盖间隙。", "conclusion": "所提出的基于图论的AP部署策略能有效适应障碍物位置随机性，在保证覆盖质量的同时显著降低基础设施成本，为高频通信网络规划提供新思路。"}}
{"id": "2507.21916", "categories": ["math.CO", "math.AG"], "pdf": "https://arxiv.org/pdf/2507.21916", "abs": "https://arxiv.org/abs/2507.21916", "authors": ["Ryota Akagi"], "title": "Some coefficients of rank 2 cluster scattering diagrams", "comment": "16 pages", "summary": "The purpose of this paper is to translate the expression of rank 2 cluster\nscattering diagrams via dilogarithm elements into via formal power series. As a\ncorollary, we prove some conjectures introduced by Thomas Elgin, Nathan\nReading, and Salvatore Stella.", "AI": {"tldr": "本文通过形式幂级数重新表述了秩2簇散射图的对数元素表达，并证明了Thomas Elgin等人的若干猜想。", "motivation": "研究旨在将秩2簇散射图的对数元素表达转换为形式幂级数表达，以验证相关数学猜想。", "method": "采用形式幂级数方法重新构建簇散射图的数学表达，替代原有的对数元素表达方式。", "result": "成功实现了表达方式的转换，并证明了Thomas Elgin等人提出的若干猜想。", "conclusion": "该研究不仅提供了簇散射图的新数学表达工具，还为相关猜想提供了严格证明，推动了该领域的理论发展。"}}
{"id": "2507.21162", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.21162", "abs": "https://arxiv.org/abs/2507.21162", "authors": ["Xu Yang", "Chenhui Lin", "Yue Yang", "Qi Wang", "Haotian Liu", "Haizhou Hua", "Wenchuan Wu"], "title": "Large Language Model Powered Automated Modeling and Optimization of Active Distribution Network Dispatch Problems", "comment": null, "summary": "The increasing penetration of distributed energy resources into active\ndistribution networks (ADNs) has made effective ADN dispatch imperative.\nHowever, the numerous newly-integrated ADN operators, such as distribution\nsystem aggregators, virtual power plant managers, and end prosumers, often lack\nspecialized expertise in power system operation, modeling, optimization, and\nprogramming. This knowledge gap renders reliance on human experts both costly\nand time-intensive. To address this challenge and enable intelligent, flexible\nADN dispatch, this paper proposes a large language model (LLM) powered\nautomated modeling and optimization approach. First, the ADN dispatch problems\nare decomposed into sequential stages, and a multi-LLM coordination\narchitecture is designed. This framework comprises an Information Extractor, a\nProblem Formulator, and a Code Programmer, tasked with information retrieval,\noptimization problem formulation, and code implementation, respectively.\nAfterwards, tailored refinement techniques are developed for each LLM agent,\ngreatly improving the accuracy and reliability of generated content. The\nproposed approach features a user-centric interface that enables ADN operators\nto derive dispatch strategies via simple natural language queries, eliminating\ntechnical barriers and increasing efficiency. Comprehensive comparisons and\nend-to-end demonstrations on various test cases validate the effectiveness of\nthe proposed architecture and methods.", "AI": {"tldr": "本文提出了一种基于大语言模型（LLM）的自动化建模与优化方法，用于解决主动配电网（ADN）调度问题，通过多LLM协同架构实现自然语言查询生成调度策略，降低技术门槛并提升效率。", "motivation": "随着分布式能源在主动配电网中的渗透率提高，缺乏专业知识的ADN运营商依赖人工专家成本高且耗时，亟需智能灵活的调度解决方案。", "method": "设计多LLM协同架构（信息提取器、问题构建器、代码编程器），分阶段分解ADN调度问题，并开发针对性优化技术提升生成内容的准确性与可靠性。", "result": "多种测试案例的全面对比和端到端验证表明，所提架构与方法能有效生成调度策略，用户通过自然语言查询即可获得结果。", "conclusion": "LLM驱动的自动化方法显著降低了ADN调度的技术壁垒，为缺乏专业知识的运营商提供了高效、可靠的解决方案。"}}
{"id": "2507.21113", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21113", "abs": "https://arxiv.org/abs/2507.21113", "authors": ["Farzana Abdulzada"], "title": "Vulnerability Mitigation System (VMS): LLM Agent and Evaluation Framework for Autonomous Penetration Testing", "comment": null, "summary": "As the frequency of cyber threats increases, conventional penetration testing\nis failing to capture the entirety of todays complex environments. To solve\nthis problem, we propose the Vulnerability Mitigation System (VMS), a novel\nagent based on a Large Language Model (LLM) capable of performing penetration\ntesting without human intervention. The VMS has a two-part architecture for\nplanning and a Summarizer, which enable it to generate commands and process\nfeedback. To standardize testing, we designed two new Capture the Flag (CTF)\nbenchmarks based on the PicoCTF and OverTheWire platforms with 200 challenges.\nThese benchmarks allow us to evaluate how effectively the system functions. We\nperformed a number of experiments using various LLMs while tuning the\ntemperature and top-p parameters and found that GPT-4o performed best,\nsometimes even better than expected. The results indicate that LLMs can be\neffectively applied to many cybersecurity tasks; however, there are risks. To\nensure safe operation, we used a containerized environment. Both the VMS and\nthe benchmarks are publicly available, advancing the creation of secure,\nautonomous cybersecurity tools.", "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）的漏洞缓解系统（VMS），用于自动化渗透测试，并通过新设计的CTF基准进行评估，结果表明GPT-4o表现最佳。", "motivation": "随着网络威胁频率的增加，传统渗透测试难以应对复杂环境，因此需要开发自动化工具以提高测试效率和覆盖范围。", "method": "VMS采用双部分架构（规划器和总结器），并设计了基于PicoCTF和OverTheWire的200个挑战的新CTF基准，用于评估系统性能。实验中使用不同LLM并调整温度和top-p参数。", "result": "实验发现GPT-4o表现最佳，有时甚至超出预期，表明LLM可有效应用于网络安全任务，但需注意风险。系统在容器化环境中安全运行。", "conclusion": "VMS和基准测试的公开可用性推动了安全、自主网络安全工具的研发，LLM在网络安全领域具有广阔应用前景，但需谨慎管理风险。"}}
{"id": "2507.21726", "categories": ["math.OC", "cond-mat.other", "cs.LG", "15A69, 53C20, 65K10"], "pdf": "https://arxiv.org/pdf/2507.21726", "abs": "https://arxiv.org/abs/2507.21726", "authors": ["Marius Willner", "Marco Trenti", "Dirk Lebiedz"], "title": "Riemannian Optimization on Tree Tensor Networks with Application in Machine Learning", "comment": "24 pages, 6 figures, 4 pseudo-code algorithms, 1 table", "summary": "Tree tensor networks (TTNs) are widely used in low-rank approximation and\nquantum many-body simulation. In this work, we present a formal analysis of the\ndifferential geometry underlying TTNs. Building on this foundation, we develop\nefficient first- and second-order optimization algorithms that exploit the\nintrinsic quotient structure of TTNs. Additionally, we devise a backpropagation\nalgorithm for training TTNs in a kernel learning setting. We validate our\nmethods through numerical experiments on a representative machine learning\ntask.", "AI": {"tldr": "本文对树张量网络（TTN）的微分几何基础进行了形式化分析，并基于此开发了高效的一阶和二阶优化算法，以及用于核学习场景的反向传播算法，通过机器学习任务验证了方法的有效性。", "motivation": "树张量网络（TTN）在低秩近似和量子多体模拟中广泛应用，但缺乏对其微分几何基础的深入理解，限制了优化算法的开发和应用。", "method": "基于TTN的固有商结构，开发了高效的一阶和二阶优化算法，并设计了用于核学习场景的反向传播算法。", "result": "数值实验验证了所提方法在代表性机器学习任务中的有效性。", "conclusion": "本文的理论分析和算法开发为TTN的优化提供了新工具，展示了其在机器学习中的潜力。"}}
{"id": "2507.21958", "categories": ["math.CO", "math.AG", "14T15, 52B20, 52B55"], "pdf": "https://arxiv.org/pdf/2507.21958", "abs": "https://arxiv.org/abs/2507.21958", "authors": ["Laura Casabella", "Lars Kastner", "Raluca Vlad"], "title": "Tropical elliptic curves in 3-space", "comment": "13 pages, 4 figures, comments welcome!", "summary": "We classify trivalent graphs with 16 vertices and 16 edges that arise from\nintersecting two quadratic surfaces in tropical 3-space. There are 4,009 such\ngraphs, representing maximally degenerate stable models of elliptic curves\nrealized as tropical complete intersections of two quadrics. Our classification\nis derived from 405,246,030 regular unimodular triangulations of the\n4-dimensional Cayley polytope.", "AI": {"tldr": "本文分类了热带3维空间中由两个二次曲面相交产生的16个顶点和16条边的三价图，共4,009种，代表了椭圆曲线的最大退化稳定模型。", "motivation": "研究热带3维空间中两个二次曲面相交产生的三价图，以理解椭圆曲线作为热带完全交的退化模型。", "method": "通过分析4维Cayley多面体的405,246,030种正则单模三角剖分，推导出这些图的分类。", "result": "共分类出4,009种三价图，这些图代表了椭圆曲线的最大退化稳定模型。", "conclusion": "该研究为热带几何中椭圆曲线的退化模型提供了系统的分类方法，揭示了其与多面体三角剖分的深刻联系。"}}
{"id": "2507.21171", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21171", "abs": "https://arxiv.org/abs/2507.21171", "authors": ["Federico Donato", "Adrien Barton"], "title": "An ontological analysis of risk in Basic Formal Ontology", "comment": "7 pages. 2 figures. Conference: Semantic Technology for Intelligence,\n  Defense, and Security (STIDS 2024)", "summary": "The paper explores the nature of risk, providing a characterization using the\ncategories of the Basic Formal Ontology (BFO). It argues that the category Risk\nis a subclass of BFO:Role, contrasting it with a similar view classifying Risk\nas a subclass of BFO:Disposition. This modeling choice is applied on one\nexample of risk, which represents objects, processes (both physical and mental)\nand their interrelations, then generalizing from the instances in the example\nto obtain an overall analysis of risk, making explicit what are the sufficient\nconditions for being a risk. Plausible necessary conditions are also mentioned\nfor future work. Index Terms: ontology, risk, BFO, role, disposition", "AI": {"tldr": "该论文基于基本形式本体论(BFO)对风险本质进行建模，提出风险应归类为BFO:Role而非BFO:Disposition的子类，并通过实例分析明确了风险的充分条件。", "motivation": "探讨风险的本质特征，解决当前本体论中风险归类（角色vs倾向性）的理论分歧。", "method": "采用BFO分类框架，通过具体案例（包含物理/心理对象及过程）进行实例化分析，进而归纳风险的普遍特征。", "result": "确立风险作为BFO:Role子类的理论立场，阐明构成风险的充分条件，并提出必要条件的探索方向。", "conclusion": "风险的本体论建模应优先采用角色范畴，该研究为风险形式化表征提供了理论基础，未来需进一步验证必要条件。"}}
{"id": "2507.21122", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21122", "abs": "https://arxiv.org/abs/2507.21122", "authors": ["Emilie Ma", "Martin Kleppmann"], "title": "Kintsugi: Decentralized E2EE Key Recovery", "comment": "15 pages with 4 additional pages of workshop discussion transcript.\n  To be published in the proceedings of the Twenty-ninth International Workshop\n  on Security Protocols", "summary": "Kintsugi is a protocol for key recovery, allowing a user to regain access to\nend-to-end encrypted data after they have lost their device, but still have\ntheir (potentially low-entropy) password. Existing E2EE key recovery methods,\nsuch as those deployed by Signal and WhatsApp, centralize trust by relying on\nservers administered by a single provider. Kintsugi is decentralized,\ndistributing trust over multiple recovery nodes, which could be servers run by\nindependent parties, or end user devices in a peer-to-peer setting. To recover\na user's keys, a threshold $t+1$ of recovery nodes must assist the user in\ndecrypting a shared backup. Kintsugi is password-authenticated and protects\nagainst offline brute-force password guessing without requiring any specialized\nsecure hardware. Kintsugi can tolerate up to $t$ honest-but-curious colluding\nrecovery nodes, as well as $n - t - 1$ offline nodes, and operates safely in an\nasynchronous network model where messages can be arbitrarily delayed.", "AI": {"tldr": "Kintsugi是一种去中心化的密钥恢复协议，允许用户通过密码恢复端到端加密数据，无需依赖单一服务提供商。", "motivation": "现有E2EE密钥恢复方案（如Signal和WhatsApp）依赖单一服务商，存在中心化信任问题。Kintsugi旨在通过分布式节点消除单点故障风险。", "method": "协议将信任分散至多个恢复节点（独立服务器或P2P设备），需$t+1$个节点协作解密备份。采用密码认证且无需专用硬件，可抵抗离线暴力破解。", "result": "Kintsugi可抵御$t$个诚实但好奇节点的共谋攻击，容忍$n-t-1$个离线节点，并在异步网络模型中保持安全。", "conclusion": "该协议为去中心化密钥恢复提供了可行方案，在保障安全性的同时提升了系统的抗审查与容错能力。"}}
{"id": "2507.21901", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.21901", "abs": "https://arxiv.org/abs/2507.21901", "authors": ["Haoyuan Cai", "Sulaiman A. Alghunaim", "Ali H. Sayed"], "title": "Communication-Efficient Algorithms for Distributed Nonconvex Minimax Optimization Problems", "comment": null, "summary": "We study stochastic nonconvex Polyak-{\\L}ojasiewicz minimax problems and\npropose algorithms that are both communication- and sample-efficient. The\nproposed methods are developed under three setups: decentralized/distributed,\nfederated/centralized, and single-agent. By exploiting second-order Lipschitz\ncontinuity and integrating communication-efficient strategies, we develop a new\ndecentralized normalized accelerated momentum method with local updates and\nestablish its convergence to an $\\varepsilon$-game stationary point. Compared\nto existing decentralized minimax algorithms,\n  our proposed algorithm is the first to achieve a state-of-the-art\ncommunication complexity of order $\\mathcal{O}\\Big(\n  \\frac{ \\kappa^3\\varepsilon^{-3}}{NK(1-\\lambda)^{3/2}}\\Big)$, demonstrating\nlinear speedup with respect to both the number of agents $K$ and the number of\nlocal updates $N$, as well as the best known dependence on the level of\naccuracy of the solution $\\varepsilon$. In addition to improved complexity, our\nalgorithm offers several practical advantages: it relaxes the strict\ntwo-time-scale step size ratio required by many existing algorithms, simplifies\nthe stability conditions for step size selection, and eliminates the need for\nlarge batch sizes to attain the optimal sample complexity.\n  Moreover, we propose more efficient variants tailored to\nfederated/centralized and single-agent setups, and show that all variants\nachieve best-known results while effectively addressing some key issues.\nExperiments on robust logistic regression and fair neural network classifier\nusing real-world datasets demonstrate the superior performance of the proposed\nmethods over existing baselines.", "AI": {"tldr": "论文针对随机非凸Polyak-{\\L}ojasiewicz极小极大问题，提出了一种通信和样本高效的分布式算法，并在三种设置下（分布式/去中心化、联邦/集中式、单智能体）验证了其优越性能。", "motivation": "现有分布式极小极大算法存在通信复杂度高、步长选择严格、需要大批量样本等问题，亟需一种能同时实现高效通信和样本利用的新方法。", "method": "通过利用二阶Lipschitz连续性和通信高效策略，开发了具有局部更新的去中心化归一化加速动量法，并针对不同场景提出优化变体。", "result": "所提算法首次达到$\\mathcal{O}\\Big(\\frac{\\kappa^3\\varepsilon^{-3}}{NK(1-\\lambda)^{3/2}}\\Big)$的最优通信复杂度，在$K$个智能体和$N$次局部更新上实现线性加速，且放宽了步长比限制、简化了稳定性条件。", "conclusion": "在鲁棒逻辑回归和公平神经网络分类器的真实数据集实验中，新方法显著优于现有基线，同时解决了关键实践难题。"}}
{"id": "2507.22015", "categories": ["math.CO", "05C12, 05C50, 05C76"], "pdf": "https://arxiv.org/pdf/2507.22015", "abs": "https://arxiv.org/abs/2507.22015", "authors": ["M. Rajesh Kannan", "Rahul Roy"], "title": "On the $l_\\infty$-analog of Algebraic Connectivity", "comment": null, "summary": "The algebraic connectivity $a(G)$ of a graph $G$ is defined as the second\nsmallest eigenvalue of its Laplacian matrix $L(G)$. It also admits a\nvariational characterization as the minimum of a quadratic form associated with\n$L(G)$, subject to $l_2$-norm constraints. In 2024, Andrade and Dahl\ninvestigated an analogous parameter $\\gamma(G)$, defined using the\n$l_\\infty$-norm instead of the $l_2$-norm. They demonstrated that $\\gamma(G)$\ncan be computed in polynomial time using linear programming. In this article,\nwe study the combinatorial significance of $\\gamma(G)$, revealing that it can\nbe efficiently computed using a breadth-first search (BFS) algorithm. We show\nthat $\\gamma (G)$ characterizes the connectedness of the graph $G$. We further\nestablish new bounds on $\\gamma(G)$, and analyze the graphs that attain\nextremal values. Finally, we derive an elegant formula for $\\gamma(G)$ when $G$\nis the Cartesian product of finitely many graphs. Applying this formula, we\nexplicitly compute $\\gamma(G)$ for various families of graphs, including\nhypercube graphs, Hamming graphs, and others.", "AI": {"tldr": "本文研究了图$G$的$l_\\infty$-范数参数$\\gamma(G)$的组合意义，提出了基于广度优先搜索(BFS)的高效算法，建立了新界限，并推导了笛卡尔积图的优雅计算公式。", "motivation": "受Andrade和Dahl 2024年工作的启发，本文旨在探索$l_\\infty$-范数参数$\\gamma(G)$的图论性质，以补充传统代数连通度$a(G)$的研究。", "method": "采用组合分析与BFS算法相结合的方法，研究$\\gamma(G)$的极值特性，并推导笛卡尔积图的显式计算公式。", "result": "证明$\\gamma(G)$可高效计算且表征图的连通性，建立新界限，给出超立方图、汉明图等典型图族的显式结果。", "conclusion": "$\\gamma(G)$作为$l_\\infty$-范数下的连通性参数，具有优良的可计算性和组合意义，为图论研究提供了新工具。"}}
{"id": "2507.21172", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21172", "abs": "https://arxiv.org/abs/2507.21172", "authors": ["John Beverley", "Danielle Limbaugh"], "title": "Ontological Foundations of State Sovereignty", "comment": "6 pages. 0 figures. Conference: Semantic Technology for Intelligence,\n  Defense, and Security (STIDS 2024)", "summary": "This short paper is a primer on the nature of state sovereignty and the\nimportance of claims about it. It also aims to reveal (merely reveal) a\nstrategy for working with vague or contradictory data about which states, in\nfact, are sovereign. These goals together are intended to set the stage for\napplied work in ontology about international affairs.", "AI": {"tldr": "本文是关于国家主权本质及其重要性主张的入门指南，并揭示了处理主权国家模糊或矛盾数据的策略，旨在为国际事务本体论的应用研究奠定基础。", "motivation": "探讨国家主权的本质及其相关主张的重要性，并揭示处理主权国家模糊或矛盾数据的方法，为国际事务本体论的应用研究提供基础。", "method": "通过分析主权国家的模糊或矛盾数据，提出一种处理这些数据的策略。", "result": "揭示了处理主权国家模糊或矛盾数据的策略，为国际事务本体论的应用研究提供了初步框架。", "conclusion": "本文为国家主权和国际事务本体论的应用研究奠定了基础，提供了处理模糊或矛盾数据的策略。"}}
{"id": "2507.21128", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.21128", "abs": "https://arxiv.org/abs/2507.21128", "authors": ["Ruomai Ren"], "title": "Security study based on the Chatgptplugin system: ldentifying Security Vulnerabilities", "comment": "Master's thesis", "summary": "Plugin systems are a class of external programmes that provide users with a\nwide range of functionality, and while they enhance the user experience, their\nsecurity is always a challenge. Especially due to the diversity and complexity\nof developers, many plugin systems lack adequate regulation. As ChatGPT has\nbecome a popular large-scale language modelling platform, its plugin system is\nalso gradually developing, and the open platform provides creators with the\nopportunity to upload plugins covering a wide range of application scenarios.\nHowever, current research and discussions mostly focus on the security issues\nof the ChatGPT model itself, while ignoring the possible security risks posed\nby the plugin system. This study aims to analyse the security of plugins in the\nChatGPT plugin shop, reveal its major security vulnerabilities, and propose\ncorresponding improvements.", "AI": {"tldr": "研究分析了ChatGPT插件商店的安全性问题，揭示了主要漏洞并提出了改进建议。", "motivation": "插件系统虽增强用户体验，但开发者多样性和复杂性导致监管不足，ChatGPT插件系统的安全风险被忽视。", "method": "通过分析ChatGPT插件商店的插件，识别其安全漏洞。", "result": "研究发现插件存在重大安全隐患，需加强监管和防护措施。", "conclusion": "ChatGPT插件系统需完善安全机制以降低风险，保障用户安全。"}}
{"id": "2507.21932", "categories": ["math.OC", "cs.DC", "cs.MS", "90-02 (Primary) 90C06 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.21932", "abs": "https://arxiv.org/abs/2507.21932", "authors": ["Lars Hadidi", "Leonard Göke", "Maximilian Hoffmann", "Mario Klostermeier", "Shima Sasanpour", "Tim Varelmann", "Vassilios Yfantis", "Jochen Linßen", "Detlef Stolten", "Jann M. Weinand"], "title": "Large-Scale Linear Energy System Optimization: A Systematic Review on Parallelization Strategies via Decomposition", "comment": null, "summary": "As renewable energy integration, sector coupling, and spatiotemporal detail\nincrease, energy system optimization models grow in size and complexity, often\npushing solvers to their performance limits. This systematic review explores\nparallelization strategies that can address these challenges. We first propose\na classification scheme for linear energy system optimization models, covering\ntheir analytical focus, mathematical structure, and scope. We then review\nparallel decomposition methods, finding that while many offer performance\nbenefits, no single approach is universally superior. The lack of standardized\nbenchmark suites further complicates comparison. To address this, we recommend\nessential criteria for future benchmarks and minimum reporting standards. We\nalso survey available software tools for parallel decomposition, including\nmodular frameworks and algorithmic abstractions. Though centered on energy\nsystem models, our insights extend to the broader operations research field.", "AI": {"tldr": "本文系统综述了针对能源系统优化模型规模与复杂性增加的并行化策略，提出了分类方案并评估了不同分解方法，强调了标准化基准的必要性。", "motivation": "随着可再生能源整合、部门耦合及时空细节的增加，能源系统优化模型的规模和复杂性不断增长，常使求解器达到性能极限，亟需有效的并行化策略应对这些挑战。", "method": "研究首先提出线性能源系统优化模型的分类方案，涵盖分析焦点、数学结构与范围；随后系统评估并行分解方法，并调查现有软件工具。", "result": "发现许多并行分解方法能提升性能，但无单一方法普遍最优；缺乏标准化基准套件增加了比较难度，为此提出了未来基准的核心标准与最低报告要求。", "conclusion": "尽管聚焦能源系统模型，但研究结论可扩展至更广泛的运筹学领域，强调了工具模块化与算法抽象的重要性。"}}
{"id": "2507.21176", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21176", "abs": "https://arxiv.org/abs/2507.21176", "authors": ["Farzana Islam Adiba", "Rahmatollah Beheshti"], "title": "Tell Me You're Biased Without Telling Me You're Biased -- Toward Revealing Implicit Biases in Medical LLMs", "comment": null, "summary": "Large language models (LLMs) that are used in medical applications are known\nto show biased and unfair patterns. Prior to adopting these in clinical\ndecision-making applications, it is crucial to identify these bias patterns to\nenable effective mitigation of their impact. In this study, we present a novel\nframework combining knowledge graphs (KGs) with auxiliary LLMs to\nsystematically reveal complex bias patterns in medical LLMs. Specifically, the\nproposed approach integrates adversarial perturbation techniques to identify\nsubtle bias patterns. The approach adopts a customized multi-hop\ncharacterization of KGs to enhance the systematic evaluation of arbitrary LLMs.\nThrough a series of comprehensive experiments (on three datasets, six LLMs, and\nfive bias types), we show that our proposed framework has noticeably greater\nability and scalability to reveal complex biased patterns of LLMs compared to\nother baselines.", "AI": {"tldr": "本文提出了一种结合知识图谱(KGs)与辅助大语言模型(LLMs)的新框架，用于系统揭示医疗LLMs中的复杂偏见模式，并通过对抗扰动技术和多跳KG表征增强评估能力。实验表明该框架在识别偏见方面显著优于基线方法。", "motivation": "医疗领域应用的大语言模型存在偏见与不公平现象，临床决策前需识别这些模式以减轻其影响。现有方法难以系统揭示复杂偏见，因此需要开发更有效的评估框架。", "method": "提出整合知识图谱与辅助LLMs的框架，采用对抗扰动技术识别细微偏见，并通过定制化多跳KG表征增强对任意LLMs的系统性评估能力。", "result": "在三个数据集、六种LLMs和五种偏见类型的综合实验中，该框架展现出了明显优于基线方法的复杂偏见揭示能力和可扩展性。", "conclusion": "研究证实了所提框架在系统识别医疗LLMs偏见方面的有效性，为临床决策前模型评估提供了可扩展的解决方案。"}}
{"id": "2507.21133", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21133", "abs": "https://arxiv.org/abs/2507.21133", "authors": ["Atil Samancioglu"], "title": "Analysis of Threat-Based Manipulation in Large Language Models: A Dual Perspective on Vulnerabilities and Performance Enhancement Opportunities", "comment": null, "summary": "Large Language Models (LLMs) demonstrate complex responses to threat-based\nmanipulations, revealing both vulnerabilities and unexpected performance\nenhancement opportunities. This study presents a comprehensive analysis of\n3,390 experimental responses from three major LLMs (Claude, GPT-4, Gemini)\nacross 10 task domains under 6 threat conditions. We introduce a novel threat\ntaxonomy and multi-metric evaluation framework to quantify both negative\nmanipulation effects and positive performance improvements. Results reveal\nsystematic vulnerabilities, with policy evaluation showing the highest metric\nsignificance rates under role-based threats, alongside substantial performance\nenhancements in numerous cases with effect sizes up to +1336%. Statistical\nanalysis indicates systematic certainty manipulation (pFDR < 0.0001) and\nsignificant improvements in analytical depth and response quality. These\nfindings have dual implications for AI safety and practical prompt engineering\nin high-stakes applications.", "AI": {"tldr": "大型语言模型（LLMs）在威胁操纵下展现出复杂反应，既暴露漏洞又存在性能提升机会。研究通过3390次实验分析三大模型（Claude、GPT-4、Gemini）在6种威胁条件下的表现，提出新威胁分类框架，揭示系统性漏洞与最高+1336%的性能提升。", "motivation": "探究LLMs在威胁操纵下的反应模式，为AI安全和高风险应用中的提示工程提供实证依据。", "method": "构建新型威胁分类法及多指标评估框架，分析三大模型在10个任务领域、6种威胁条件下的3390次实验数据。", "result": "发现基于角色威胁时政策评估任务指标显著率最高，部分案例性能提升达1336%；统计证实存在系统性确定性操纵（pFDR < 0.0001）及分析深度、响应质量的显著改善。", "conclusion": "研究结果对AI安全防护和关键领域提示工程具有双重启示，证实威胁条件可系统性影响LLMs行为模式。"}}
{"id": "2507.21933", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.21933", "abs": "https://arxiv.org/abs/2507.21933", "authors": ["Stephanie Riedmüller", "Janina Zittel", "Thorsten Koch"], "title": "Warm-starting Strategies in Scalarization Methods for Multi-Objective Optimization", "comment": null, "summary": "We explore how warm-starting strategies can be integrated into\nscalarization-based approaches for multi-objective optimization in (mixed)\ninteger linear programming. Scalarization methods remain widely used classical\ntechniques to compute Pareto-optimal solutions in applied settings. They are\nfavored due to their algorithmic simplicity and broad applicability across\ncontinuous and integer programs with an arbitrary number of objectives. While\nwarm-starting has been applied in this context before, a systematic methodology\nand analysis remain lacking. We address this gap by providing a theoretical\ncharacterization of warm-starting within scalarization methods, focusing on the\nsequencing of subproblems. However, optimizing the order of subproblems to\nmaximize warm-start efficiency may conflict with alternative criteria, such as\nearly identification of infeasible regions. We quantify these trade-offs\nthrough an extensive computational study.", "AI": {"tldr": "本文研究了在(混合)整数线性规划的多目标优化中，如何将预热启动策略与标量化方法结合使用。通过理论分析和计算实验，探讨了子问题排序对预热效率的影响及其与其他优化目标的权衡。", "motivation": "标量化方法是计算帕累托最优解的经典技术，因其算法简单且适用于任意数量目标的连续和整数规划而广受欢迎。然而，预热启动策略在该领域的系统化方法和分析仍存在空白。", "method": "提出了标量化方法中预热启动的理论特征，重点研究子问题的排序策略。同时指出优化子问题排序以提高预热效率可能与早期识别不可行区域等其他标准存在冲突。", "result": "通过大量计算实验量化了这些权衡关系，展示了不同排序策略对预热效果的影响。", "conclusion": "研究表明，在标量化方法中系统应用预热启动策略具有潜力，但需要仔细权衡子问题排序与其他优化目标之间的关系。"}}
{"id": "2507.21206", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21206", "abs": "https://arxiv.org/abs/2507.21206", "authors": ["Yingxuan Yang", "Mulei Ma", "Yuxuan Huang", "Huacan Chai", "Chenyu Gong", "Haoran Geng", "Yuanjian Zhou", "Ying Wen", "Meng Fang", "Muhao Chen", "Shangding Gu", "Ming Jin", "Costas Spanos", "Yang Yang", "Pieter Abbeel", "Dawn Song", "Weinan Zhang", "Jun Wang"], "title": "Agentic Web: Weaving the Next Web with AI Agents", "comment": null, "summary": "The emergence of AI agents powered by large language models (LLMs) marks a\npivotal shift toward the Agentic Web, a new phase of the internet defined by\nautonomous, goal-driven interactions. In this paradigm, agents interact\ndirectly with one another to plan, coordinate, and execute complex tasks on\nbehalf of users. This transition from human-driven to machine-to-machine\ninteraction allows intent to be delegated, relieving users from routine digital\noperations and enabling a more interactive, automated web experience. In this\npaper, we present a structured framework for understanding and building the\nAgentic Web. We trace its evolution from the PC and Mobile Web eras and\nidentify the core technological foundations that support this shift. Central to\nour framework is a conceptual model consisting of three key dimensions:\nintelligence, interaction, and economics. These dimensions collectively enable\nthe capabilities of AI agents, such as retrieval, recommendation, planning, and\ncollaboration. We analyze the architectural and infrastructural challenges\ninvolved in creating scalable agentic systems, including communication\nprotocols, orchestration strategies, and emerging paradigms such as the Agent\nAttention Economy. We conclude by discussing the potential applications,\nsocietal risks, and governance issues posed by agentic systems, and outline\nresearch directions for developing open, secure, and intelligent ecosystems\nshaped by both human intent and autonomous agent behavior. A continuously\nupdated collection of relevant studies for agentic web is available at:\nhttps://github.com/SafeRL-Lab/agentic-web.", "AI": {"tldr": "本文提出了一个结构化框架来理解和构建'代理网络'(Agentic Web)，探讨了由大型语言模型驱动的AI代理如何通过自主交互改变互联网范式，并分析了其技术基础、挑战及社会影响。", "motivation": "随着基于大语言模型的AI代理崛起，互联网正进入以自主目标驱动交互为特征的'代理网络'新阶段。这一转变将用户从常规数字操作中解放，实现更自动化的网络体验，但需系统性框架指导其发展。", "method": "作者提出三维概念模型（智能、交互、经济），追溯从PC到移动互联网的演进，识别核心技术基础，并分析可扩展代理系统的架构挑战，包括通信协议、协调策略及'代理注意力经济'等新兴范式。", "result": "建立了涵盖代理能力（检索/推荐/规划/协作）的理论框架，开源了持续更新的相关研究集合，揭示了构建开放、安全、智能的代理生态系统所需解决的关键问题。", "conclusion": "代理网络将重塑人机协作模式，但需协调技术发展与社会治理。未来研究应关注应用潜力、社会风险及监管机制，以实现人类意图与自主代理行为的良性互动。"}}
{"id": "2507.21139", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21139", "abs": "https://arxiv.org/abs/2507.21139", "authors": ["Yucheng Wu", "Yuncong Yang", "Xiao Han", "Leye Wang", "Junjie Wu"], "title": "Learning-based Privacy-Preserving Graph Publishing Against Sensitive Link Inference Attacks", "comment": null, "summary": "Publishing graph data is widely desired to enable a variety of structural\nanalyses and downstream tasks. However, it also potentially poses severe\nprivacy leakage, as attackers may leverage the released graph data to launch\nattacks and precisely infer private information such as the existence of hidden\nsensitive links in the graph. Prior studies on privacy-preserving graph data\npublishing relied on heuristic graph modification strategies and it is\ndifficult to determine the graph with the optimal privacy--utility trade-off\nfor publishing. In contrast, we propose the first privacy-preserving graph\nstructure learning framework against sensitive link inference attacks, named\nPPGSL, which can automatically learn a graph with the optimal privacy--utility\ntrade-off. The PPGSL operates by first simulating a powerful surrogate attacker\nconducting sensitive link attacks on a given graph. It then trains a\nparameterized graph to defend against the simulated adversarial attacks while\nmaintaining the favorable utility of the original graph. To learn the\nparameters of both parts of the PPGSL, we introduce a secure iterative training\nprotocol. It can enhance privacy preservation and ensure stable convergence\nduring the training process, as supported by the theoretical proof.\nAdditionally, we incorporate multiple acceleration techniques to improve the\nefficiency of the PPGSL in handling large-scale graphs. The experimental\nresults confirm that the PPGSL achieves state-of-the-art privacy--utility\ntrade-off performance and effectively thwarts various sensitive link inference\nattacks.", "AI": {"tldr": "本文提出首个隐私保护图结构学习框架PPGSL，通过对抗训练自动优化隐私-效用平衡，有效抵御敏感链接推断攻击，并在实验中验证了其优越性能。", "motivation": "图数据发布虽支持多种分析任务，但存在隐私泄露风险（如敏感链接被推断）。现有启发式图修改方法难以确定最优隐私-效用权衡，需自动化解决方案。", "method": "PPGSL框架包含两部分：1) 模拟强大攻击者进行敏感链接推断；2) 训练参数化图以抵御攻击并保持原始图效用。采用安全迭代训练协议确保隐私与收敛，并引入加速技术处理大规模图。", "result": "实验表明PPGSL在隐私-效用权衡上达到最优性能，能有效抵抗多种敏感链接推断攻击，且理论证明其训练过程稳定收敛。", "conclusion": "PPGSL是首个通过对抗学习自动优化隐私保护的图结构框架，为安全图数据发布提供了高效可靠的解决方案。"}}
{"id": "2507.21944", "categories": ["math.OC", "90B80, 90C10, 90C11"], "pdf": "https://arxiv.org/pdf/2507.21944", "abs": "https://arxiv.org/abs/2507.21944", "authors": ["Concepción Domínguez", "Juan de Dios Jaime-Alcántara"], "title": "Stable formulations for the Capacitated Facility Location Problem with Customer Preferences", "comment": null, "summary": "In the Simple Plant Location Problem with Order (SPLPO), the aim is to open a\nsubset of plants to assign every customer taking into account their\npreferences. Customers rank the plants in strict order and are assigned to\ntheir favorite open plant, and the objective is to minimize the location plus\nallocation costs. Here, we study a generalization of the SPLPO named the\nCapacitated Facility Location Problem with Customer Preferences (CFLCP) where a\nlimited number of customers can be allocated to each facility. We consider the\nglobal preference maximization setting, where the customers preferences are\nglobally maximized. For this setting, we define three new types of stable\nallocations, namely customer stable, pairwise stable and cyclic-coalition\nstable allocations, and we provide two mixed-integer linear formulations for\neach setting. In particular, our cyclic-coalition stable formulations are\nPareto optimal in a global-preference maximization setting, in the sense that\nno customer can improve their allocation without making another one worse off.\nWe provide extensive computational experiments and compare the quality of our\nallocations with previous ones defined in the literature. As an additional\nresult, we present a novel formulation that provides Pareto optimal matchings\nin the Capacitated House Allocation problem of maximum cardinality.", "AI": {"tldr": "本文研究了带顾客偏好的容量限制设施选址问题（CFLCP），提出了三种新的稳定分配类型，并给出了两种混合整数线性规划模型。特别地，循环联盟稳定分配在全局偏好最大化下具有帕累托最优性。", "motivation": "研究动机是扩展简单工厂选址问题（SPLPO），考虑设施容量限制和顾客偏好，以最小化选址和分配成本，并在全局偏好最大化下定义新的稳定分配类型。", "method": "方法包括定义顾客稳定、成对稳定和循环联盟稳定分配，并为每种分配类型提供两种混合整数线性规划模型。此外，还提出了一种新的帕累托最优匹配模型。", "result": "计算实验表明，新提出的分配类型在质量上优于文献中的现有方法。循环联盟稳定分配在全局偏好最大化下实现了帕累托最优。", "conclusion": "结论是CFLCP问题的新模型和分配类型有效解决了容量限制和顾客偏好的挑战，循环联盟稳定分配具有帕累托最优性，为相关领域提供了新的解决方案。"}}
{"id": "2507.21257", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.21257", "abs": "https://arxiv.org/abs/2507.21257", "authors": ["David Maria Schmidt", "Raoul Schubert", "Philipp Cimiano"], "title": "CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting", "comment": "Research Track, 24th International Semantic Web Conference (ISWC\n  2025), November 2-6, 2025, Nara, Japan", "summary": "Language interpretation is a compositional process, in which the meaning of\nmore complex linguistic structures is inferred from the meaning of their parts.\nLarge language models possess remarkable language interpretation capabilities\nand have been successfully applied to interpret questions by mapping them to\nSPARQL queries. An open question is how systematic this interpretation process\nis. Toward this question, in this paper, we propose a benchmark for\ninvestigating to what extent the abilities of LLMs to interpret questions are\nactually compositional. For this, we generate three datasets of varying\ndifficulty based on graph patterns in DBpedia, relying on Lemon lexica for\nverbalization. Our datasets are created in a very controlled fashion in order\nto test the ability of LLMs to interpret structurally complex questions, given\nthat they have seen the atomic building blocks. This allows us to evaluate to\nwhat degree LLMs are able to interpret complex questions for which they\n\"understand\" the atomic parts. We conduct experiments with models of different\nsizes using both various prompt and few-shot optimization techniques as well as\nfine-tuning. Our results show that performance in terms of macro $F_1$ degrades\nfrom $0.45$ over $0.26$ down to $0.09$ with increasing deviation from the\nsamples optimized on. Even when all necessary information was provided to the\nmodel in the input, the $F_1$ scores do not exceed $0.57$ for the dataset of\nlowest complexity. We thus conclude that LLMs struggle to systematically and\ncompositionally interpret questions and map them into SPARQL queries.", "AI": {"tldr": "研究探讨了大语言模型（LLMs）在将复杂问题系统性地解析为SPARQL查询时的组合能力，发现其性能随问题复杂度增加而显著下降。", "motivation": "尽管LLMs在语言解释方面表现出色，但其解析过程是否具有系统性仍是一个开放性问题。本文旨在评估LLMs在理解问题原子部分后，能否组合性地解析复杂问题。", "method": "基于DBpedia的图模式生成三个难度不同的数据集，利用Lemon词典进行语言化。采用不同规模的模型，结合多种提示和少样本优化技术以及微调进行实验。", "result": "实验结果显示，随着样本偏离优化样本的程度增加，宏$F_1$从$0.45$降至$0.26$，最终到$0.09$。即使在输入中提供所有必要信息，最低复杂度数据集的$F_1$分数也不超过$0.57$。", "conclusion": "LLMs在系统性和组合性地解析问题并将其映射为SPARQL查询方面存在困难。"}}
{"id": "2507.21142", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21142", "abs": "https://arxiv.org/abs/2507.21142", "authors": ["Chenhao Fang", "Yanqing Peng", "Rajeev Rao", "Matt Sarmiento", "Wendy Summer", "Arya Pudota", "Alex Goncalves", "Jordi Mola", "Hervé Robert"], "title": "Privacy Artifact ConnecTor (PACT): Embedding Enterprise Artifacts for Compliance AI Agents", "comment": null, "summary": "Enterprise environments contain a heterogeneous, rapidly growing collection\nof internal artifacts related to code, data, and many different tools. Critical\ninformation for assessing privacy risk and ensuring regulatory compliance is\noften embedded across these varied resources, each with their own arcane\ndiscovery and extraction techniques. Therefore, large-scale privacy compliance\nin adherence to governmental regulations requires systems to discern the\ninterconnected nature of diverse artifacts in a common, shared universe.\n  We present Privacy Artifact ConnecT or (PACT), an embeddings-driven graph\nthat links millions of artifacts spanning multiple artifact types generated by\na variety of teams and projects. Powered by the state-of-the-art DRAGON\nembedding model, PACT uses a contrastive learning objective with light\nfine-tuning to link artifacts via their textual components such as raw\nmetadata, ownership specifics, and compliance context. Experimental results\nshow that PACT's fine-tuned model improves recall@1 from 18% to 53%, the query\nmatch rate from 9.6% to 69.7% when paired with a baseline AI agent, and the\nhitrate@1 from 25.7% to 44.9% for candidate selection in a standard recommender\nsystem.", "AI": {"tldr": "本文提出PACT系统，通过嵌入驱动的图结构连接企业内多种隐私相关资源，利用DRAGON模型优化链接效果，显著提升隐私合规性分析的准确率。", "motivation": "企业环境中存在大量异构且快速增长的代码、数据和工具资源，隐私风险评估和法规遵从所需信息分散其中，亟需统一系统实现跨资源关联分析。", "method": "采用基于DRAGON嵌入模型的对比学习框架，通过微调整合元数据、所有权信息和合规上下文等文本特征，构建多类型资源连接图。", "result": "实验表明：PACT将recall@1从18%提升至53%，AI代理查询匹配率从9.6%增至69.7%，推荐系统hitrate@1从25.7%提高到44.9%。", "conclusion": "PACT通过先进嵌入技术有效解决企业隐私资源关联难题，为大规模合规管理提供可扩展的自动化解决方案。"}}
{"id": "2507.21154", "categories": ["cs.CR", "cs.SY", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.21154", "abs": "https://arxiv.org/abs/2507.21154", "authors": ["Md Abdul Gaffar"], "title": "Assessment of Quantitative Cyber-Physical Reliability of SCADA Systems in Autonomous Vehicle to Grid (V2G) Capable Smart Grids", "comment": "5 pages, 6 figures", "summary": "The integration of electric vehicles (EVs) into power grids via\nVehicle-to-Grid (V2G) system technology is increasing day by day, but these\nphenomena present both advantages and disadvantages. V2G can increase grid\nreliability by providing distributed energy storage and ancillary services.\nHowever, on the other hand, it has a scope that encompasses the cyber-physical\nattack surface of the national power grid, introducing new vulnerabilities in\nmonitoring and supervisory control and data acquisition (SCADA) systems. This\npaper investigates the maliciousness caused by Autonomous Vehicle to Grid\n(AV2G) communication infrastructures and assesses their impacts on SCADA system\nreliability. This paper presents a quantitative reliability assessment using\nBayesian attack graph combined with probabilistic capacity outage modeling\nbased on IEEE RTS-79 system data. This work presents how AV2G-based attacks\ndegrade system performance by using Monte Carlo simulations method,\nhighlighting the need for cybersecurity-hardening strategies in smart grid\ndesign.", "AI": {"tldr": "本文研究了电动汽车与电网（V2G）系统中自主车辆通信（AV2G）带来的网络安全风险，评估了其对SCADA系统可靠性的影响，并提出了基于贝叶斯攻击图和蒙特卡洛模拟的定量分析方法。", "motivation": "随着电动汽车通过V2G技术日益融入电网，虽然提升了电网可靠性和分布式储能能力，但也扩大了电网的物理-网络攻击面，特别是AV2G通信可能引入新的监控与SCADA系统漏洞。", "method": "采用贝叶斯攻击图结合概率容量停运模型（基于IEEE RTS-79系统数据），并通过蒙特卡洛模拟量化AV2G攻击对系统性能的影响。", "result": "模拟显示AV2G攻击会显著降低电网可靠性，凸显了在智能电网设计中强化网络安全的必要性。", "conclusion": "研究强调了针对AV2G通信基础设施的网络安全加固策略对保障智能电网稳定运行的关键作用。"}}
{"id": "2507.21276", "categories": ["cs.AI", "cs.CL", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.21276", "abs": "https://arxiv.org/abs/2507.21276", "authors": ["Yufei Li", "Zexin Li", "Yinglun Zhu", "Cong Liu"], "title": "LeMix: Unified Scheduling for LLM Training and Inference on Multi-GPU Systems", "comment": "Accepted by RTSS 2025", "summary": "Modern deployment of large language models (LLMs) frequently involves both\ninference serving and continuous retraining to stay aligned with evolving data\nand user feedback. Common practices separate these workloads onto distinct\nservers in isolated phases, causing substantial inefficiencies (e.g., GPU\nidleness) and delayed adaptation to new data in distributed settings. Our\nempirical analysis reveals that these inefficiencies stem from dynamic request\narrivals during serving and workload heterogeneity in pipeline-parallel\ntraining. To address these challenges, we propose LeMix, a system for\nco-locating and managing concurrent LLM serving and training workloads. LeMix\nintegrates offline profiling, execution prediction mechanisms, and runtime\nscheduling to dynamically adapt resource allocation based on workload\ncharacteristics and system conditions. By understanding task-specific behaviors\nand co-execution interference across shared nodes, LeMix improves utilization\nand serving quality without compromising serving responsiveness. Our evaluation\nshows that LeMix improves throughput by up to 3.53x, reduces inference loss by\nup to 0.61x, and delivers up to 2.12x higher response time SLO attainment over\ntraditional separate setups. To our knowledge, this is the first work to\nuncover and exploit the opportunities of joint LLM inference and training,\npaving the way for more resource-efficient deployment of LLMs in production\nenvironments.", "AI": {"tldr": "本文提出LeMix系统，通过联合调度LLM推理与训练任务，解决传统分离部署导致的资源低效问题，实现最高3.53倍吞吐量提升和0.61倍推理损失降低。", "motivation": "现有LLM部署将推理服务与持续训练分离在不同服务器，导致GPU闲置和适应新数据延迟，动态请求到达和异构训练加剧了资源低效问题。", "method": "LeMix整合离线性能分析、执行预测机制和运行时调度，根据工作负载特征动态分配资源，通过理解任务行为与共享节点干扰实现协同优化。", "result": "实验表明LeMix相比传统方案最高提升3.53倍吞吐量，减少0.61倍推理损失，响应时间SLO达标率提升2.12倍。", "conclusion": "该研究首次实现LLM推理与训练的联合优化，为生产环境高效部署LLM开辟了新路径。"}}
{"id": "2507.21145", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21145", "abs": "https://arxiv.org/abs/2507.21145", "authors": ["Vita Santa Barletta", "Danilo Caivano", "Gabriel Cellammare", "Samuele del Vescovo", "Annita Larissa Sciacovelli"], "title": "Leveraging Trustworthy AI for Automotive Security in Multi-Domain Operations: Towards a Responsive Human-AI Multi-Domain Task Force for Cyber Social Security", "comment": "13 pages, 6 figures, 1 table", "summary": "Multi-Domain Operations (MDOs) emphasize cross-domain defense against complex\nand synergistic threats, with civilian infrastructures like smart cities and\nConnected Autonomous Vehicles (CAVs) emerging as primary targets. As dual-use\nassets, CAVs are vulnerable to Multi-Surface Threats (MSTs), particularly from\nAdversarial Machine Learning (AML) which can simultaneously compromise multiple\nin-vehicle ML systems (e.g., Intrusion Detection Systems, Traffic Sign\nRecognition Systems). Therefore, this study investigates how key\nhyperparameters in Decision Tree-based ensemble models-Random Forest (RF),\nGradient Boosting (GB), and Extreme Gradient Boosting (XGB)-affect the time\nrequired for a Black-Box AML attack i.e. Zeroth Order Optimization (ZOO).\nFindings show that parameters like the number of trees or boosting rounds\nsignificantly influence attack execution time, with RF and GB being more\nsensitive than XGB. Adversarial Training (AT) time is also analyzed to assess\nthe attacker's window of opportunity. By optimizing hyperparameters, this\nresearch supports Defensive Trustworthy AI (D-TAI) practices within MST\nscenarios and contributes to the development of resilient ML systems for\ncivilian and military domains, aligned with Cyber Social Security framework in\nMDOs and Human-AI Multi-Domain Task Forces.", "AI": {"tldr": "研究探讨了决策树集成模型（随机森林、梯度提升、极端梯度提升）的关键超参数对黑盒对抗性机器学习攻击（ZOO）执行时间的影响，发现随机森林和梯度提升对参数变化更敏感，并分析了对抗训练时间以评估攻击机会窗口。", "motivation": "随着智能城市和联网自动驾驶汽车（CAVs）成为多域作战（MDOs）中的主要目标，CAVs作为军民两用资产易受多表面威胁（MSTs）攻击，尤其是对抗性机器学习（AML）攻击。因此，研究如何通过优化超参数提升防御性可信人工智能（D-TAI）的实践具有重要意义。", "method": "研究分析了随机森林（RF）、梯度提升（GB）和极端梯度提升（XGB）等决策树集成模型的关键超参数（如树的数量或提升轮数）对黑盒对抗性机器学习攻击（ZOO）执行时间的影响，并评估了对抗训练（AT）时间。", "result": "研究发现，随机森林和梯度提升对超参数变化更为敏感，而极端梯度提升相对稳健。超参数的优化显著影响了攻击执行时间，同时对抗训练时间分析为攻击者的机会窗口提供了评估依据。", "conclusion": "通过优化超参数，研究支持了在多表面威胁场景下的防御性可信人工智能实践，并为军民领域的弹性机器学习系统开发提供了贡献，符合多域作战中的网络社会安全框架和人机多域任务部队的需求。"}}
{"id": "2507.21285", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21285", "abs": "https://arxiv.org/abs/2507.21285", "authors": ["Harsh Darji", "Thibaud Lutellier"], "title": "Curiosity by Design: An LLM-based Coding Assistant Asking Clarification Questions", "comment": null, "summary": "Large Language Models (LLMs) are increasingly used as coding assistants.\nHowever, the ambiguity of the developer's prompt often leads to incorrect code\ngeneration, as current models struggle to infer user intent without extensive\nprompt engineering or external context. This work aims to build an LLM-based\ncoding assistant that mimics the human code review process by asking\nclarification questions when faced with ambiguous or under-specified queries.\n  Our end-to-end system includes (1) a query classifier trained to detect\nunclear programming-related queries and (2) a fine-tuned LLM that generates\nclarification questions. Our evaluation shows that the fine-tuned LLM\noutperforms standard zero-shot prompting in generating useful clarification\nquestions. Furthermore, our user study indicates that users find the\nclarification questions generated by our model to outperform the baseline,\ndemonstrating that our coding assistant produces more accurate and helpful code\nresponses compared to baseline coding assistants.", "AI": {"tldr": "该研究开发了一个基于LLM的编程助手，通过生成澄清问题来应对模糊查询，从而提高代码生成的准确性。", "motivation": "当前大型语言模型(LLM)作为编程助手时，常因用户提示的模糊性而生成错误代码，需要改进意图推断能力。", "method": "系统包含：(1)训练查询分类器检测模糊编程查询；(2)微调LLM生成澄清问题，采用端到端架构。", "result": "微调后的LLM在生成有效澄清问题上优于零样本提示，用户研究表明其问题质量超越基线模型。", "conclusion": "该编程助手通过模仿人类代码审查流程，显著提升了代码响应的准确性和实用性。"}}
{"id": "2507.21146", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21146", "abs": "https://arxiv.org/abs/2507.21146", "authors": ["Gauri Sharma", "Vidhi Kulkarni", "Miles King", "Ken Huang"], "title": "Towards Unifying Quantitative Security Benchmarking for Multi Agent Systems", "comment": "9 pages, 5 figures", "summary": "Evolving AI systems increasingly deploy multi-agent architectures where\nautonomous agents collaborate, share information, and delegate tasks through\ndeveloping protocols. This connectivity, while powerful, introduces novel\nsecurity risks. One such risk is a cascading risk: a breach in one agent can\ncascade through the system, compromising others by exploiting inter-agent\ntrust. In tandem with OWASP's initiative for an Agentic AI Vulnerability\nScoring System we define an attack vector, Agent Cascading Injection, analogous\nto Agent Impact Chain and Blast Radius, operating across networks of agents. In\nan ACI attack, a malicious input or tool exploit injected at one agent leads to\ncascading compromises and amplified downstream effects across agents that trust\nits outputs. We formalize this attack with an adversarial goal equation and key\nvariables (compromised agent, injected exploit, polluted observations, etc.),\ncapturing how a localized vulnerability can escalate into system-wide failure.\nWe then analyze ACI's properties -- propagation chains, amplification factors,\nand inter-agent compound effects -- and map these to OWASP's emerging Agentic\nAI risk categories (e.g. Impact Chain and Orchestration Exploits). Finally, we\nargue that ACI highlights a critical need for quantitative benchmarking\nframeworks to evaluate the security of agent-to-agent communication protocols.\nWe outline a methodology for stress-testing multi-agent systems (using\narchitectures such as Google's A2A and Anthropic's MCP) against cascading trust\nfailures, developing upon groundwork for measurable, standardized\nagent-to-agent security evaluation. Our work provides the necessary apparatus\nfor engineers to benchmark system resilience, make data-driven architectural\ntrade-offs, and develop robust defenses against a new generation of agentic\nthreats.", "AI": {"tldr": "本文提出了一种新型安全风险——代理级联注入（ACI），分析了多智能体系统中信任链被恶意利用导致的级联攻击，并呼吁建立量化评估框架以增强系统安全性。", "motivation": "随着多智能体系统的普及，智能体间信任关系可能被恶意利用，导致局部漏洞演变为系统性风险。本文旨在揭示这种级联攻击机制，并推动安全评估标准化。", "method": "通过形式化攻击模型（含对抗目标方程和关键变量），分析ACI的传播链、放大因子等特性，并基于OWASP分类提出针对A2A/MCP架构的压力测试方法论。", "result": "揭示了ACI攻击如何通过污染观测数据在智能体网络中扩散，验证了其与OWASP风险类别（如影响链攻击）的关联性，构建了可量化的安全评估基础框架。", "conclusion": "研究为工程师提供了评估系统弹性的工具，强调需通过标准化协议测试和防御设计来应对新兴的智能体级联威胁。"}}
{"id": "2507.21287", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21287", "abs": "https://arxiv.org/abs/2507.21287", "authors": ["Aryan Raj", "Astitva Veer Garg", "Anitha D"], "title": "Structured Relevance Assessment for Robust Retrieval-Augmented Language Models", "comment": "International Conference on ICT for Sustainable Development (ICT4SD)", "summary": "Retrieval-Augmented Language Models (RALMs) face significant challenges in\nreducing factual errors, particularly in document relevance evaluation and\nknowledge integration. We introduce a framework for structured relevance\nassessment that enhances RALM robustness through improved document evaluation,\nbalanced intrinsic and external knowledge integration, and effective handling\nof unanswerable queries. Our approach employs a multi-dimensional scoring\nsystem that considers both semantic matching and source reliability, utilizing\nembedding-based relevance scoring and synthetic training data with\nmixed-quality documents. We implement specialized benchmarking on niche topics,\na knowledge integration mechanism, and an \"unknown\" response protocol for\nqueries with insufficient knowledge coverage. Preliminary evaluations\ndemonstrate significant reductions in hallucination rates and improved\ntransparency in reasoning processes. Our framework advances the development of\nmore reliable question-answering systems capable of operating effectively in\ndynamic environments with variable data quality. While challenges persist in\naccurately distinguishing credible information and balancing system latency\nwith thoroughness, this work represents a meaningful step toward enhancing RALM\nreliability.", "AI": {"tldr": "本文提出了一种结构化相关性评估框架，通过改进文档评估、平衡内外知识整合及处理不可回答问题，显著减少检索增强语言模型(RALMs)的事实错误。", "motivation": "检索增强语言模型在事实准确性、文档相关性评估和知识整合方面存在显著挑战，亟需提升其可靠性和透明度。", "method": "采用多维评分系统（结合语义匹配与来源可信度）、嵌入相关性评分、混合质量合成训练数据，并设计专项小众主题测试、知识整合机制及'未知'响应协议。", "result": "初步评估显示幻觉率显著降低，推理过程透明度提升，框架能有效适应动态环境中多变的数据质量。", "conclusion": "该研究虽在信息可信度区分和系统延迟平衡方面仍有挑战，但为增强RALM可靠性迈出重要一步，推动了可靠问答系统的发展。"}}
{"id": "2507.21150", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21150", "abs": "https://arxiv.org/abs/2507.21150", "authors": ["Aditya Pujari", "Ajita Rattani"], "title": "WaveVerify: A Novel Audio Watermarking Framework for Media Authentication and Combatting Deepfakes", "comment": "Accepted to IJCB 2025 (IEEE/IAPR International Joint Conference on\n  Biometrics). Code available at: (1) Official Lab Repo:\n  https://github.com/vcbsl/WaveVerify (2) Original Author Repo:\n  https://github.com/pujariaditya/WaveVerify", "summary": "The rapid advancement of voice generation technologies has enabled the\nsynthesis of speech that is perceptually indistinguishable from genuine human\nvoices. While these innovations facilitate beneficial applications such as\npersonalized text-to-speech systems and voice preservation, they have also\nintroduced significant risks, including deepfake impersonation scams and\nsynthetic media-driven disinformation campaigns. Recent reports indicate that\nin 2024, deepfake fraud attempts surged by over 1,300% compared to 2023,\nunderscoring the urgent need for robust audio content authentication. The\nfinancial sector has been particularly impacted, with a loss of over 10 million\nUSD to voice scams and individual victims reporting losses exceeding $6,000\nfrom AI-generated deepfake calls. In response, regulators and governments\nworldwide are enacting measures to improve AI content transparency and\ntraceability, emphasizing the development of forensic tools and watermarking\ntechniques as essential strategies to uphold media integrity.", "AI": {"tldr": "语音生成技术的快速发展带来了高风险，如深度伪造诈骗，2024年相关案件激增1300%，金融领域损失超1000万美元。全球正推动AI内容透明度和可追溯性措施。", "motivation": "语音合成技术虽有益于个性化语音系统，但也导致深度伪造诈骗和虚假信息传播激增，亟需建立音频内容认证机制。", "method": "通过开发法证工具和水印技术，提升AI生成内容的透明度和可追溯性。", "result": "2024年深度伪造诈骗尝试较2023年增长1300%，金融领域因AI语音诈骗损失超1000万美元，单笔损失超6000美元。", "conclusion": "全球监管机构正采取措施加强AI内容管理，强调法证工具和水印技术对维护媒体完整性的重要性。"}}
{"id": "2507.21354", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.21354", "abs": "https://arxiv.org/abs/2507.21354", "authors": ["Monika Zamojska", "Jarosław A. Chudziak"], "title": "Games Agents Play: Towards Transactional Analysis in LLM-based Multi-Agent Systems", "comment": "Proceedings of the Annual Meeting of the Cognitive Science Society\n  (CogSci 2025), https://escholarship.org/uc/item/7gg6j165", "summary": "Multi-Agent Systems (MAS) are increasingly used to simulate social\ninteractions, but most of the frameworks miss the underlying cognitive\ncomplexity of human behavior. In this paper, we introduce Trans-ACT\n(Transactional Analysis Cognitive Toolkit), an approach embedding Transactional\nAnalysis (TA) principles into MAS to generate agents with realistic\npsychological dynamics. Trans-ACT integrates the Parent, Adult, and Child ego\nstates into an agent's cognitive architecture. Each ego state retrieves\ncontext-specific memories and uses them to shape response to new situations.\nThe final answer is chosen according to the underlying life script of the\nagent. Our experimental simulation, which reproduces the Stupid game scenario,\ndemonstrates that agents grounded in cognitive and TA principles produce deeper\nand context-aware interactions. Looking ahead, our research opens a new way for\na variety of applications, including conflict resolution, educational support,\nand advanced social psychology studies.", "AI": {"tldr": "本文提出Trans-ACT方法，将交互分析理论嵌入多智能体系统，使智能体具备更真实的人类心理动态。通过模拟Stupid游戏场景，验证了该方法能产生更具深度和情境感知的交互。", "motivation": "现有MAS框架缺乏对人类行为认知复杂性的模拟，Trans-ACT旨在通过整合交互分析理论填补这一空白。", "method": "在智能体认知架构中整合父母、成人和儿童三种自我状态，各状态调用情境记忆生成响应，最终根据智能体的生命脚本选择行为。", "result": "基于Stupid游戏的实验表明，采用TA认知原则的智能体能产生更深刻的上下文感知交互。", "conclusion": "该研究为冲突解决、教育支持和高级社会心理学研究开辟了新途径。"}}
{"id": "2507.21151", "categories": ["cs.CR", "cs.PF", "quant-ph", "stat.AP"], "pdf": "https://arxiv.org/pdf/2507.21151", "abs": "https://arxiv.org/abs/2507.21151", "authors": ["Abel C. H. Chen"], "title": "NIST Post-Quantum Cryptography Standard Algorithms Based on Quantum Random Number Generators", "comment": "in Chinese language", "summary": "In recent years, the advancement of quantum computing technology has posed\npotential security threats to RSA cryptography and elliptic curve cryptography.\nIn response, the National Institute of Standards and Technology (NIST)\npublished several Federal Information Processing Standards (FIPS) of\npost-quantum cryptography (PQC) in August 2024, including the\nModule-Lattice-Based Key-Encapsulation Mechanism (ML-KEM), Module-Lattice-Based\nDigital Signature Algorithm (ML-DSA), and Stateless Hash-Based Digital\nSignature Algorithm (SLH-DSA). Although these PQC algorithms are designed to\nresist quantum computing attacks, they may not provide adequate security in\ncertain specialized application scenarios. To address this issue, this study\nproposes quantum random number generator (QRNG)-based PQC algorithms. These\nalgorithms leverage quantum computing to generate random numbers, which serve\nas the foundation for key pair generation, key encapsulation, and digital\nsignature generation. A generalized architecture of QRNG is proposed, along\nwith the design of six QRNGs. Each generator is evaluated according to the\nstatistical validation procedures outlined in NIST SP 800-90B, including tests\nfor verification of entropy sources and independent and identically distributed\n(IID) outputs. Experimental results assess the computation time of the six\nQRNGs, as well as the performance of QRNG-based ML-KEM, QRNG-based ML-DSA, and\nQRNG-based SLH-DSA. These findings provide valuable reference data for future\ndeployment of PQC systems.", "AI": {"tldr": "本研究提出基于量子随机数生成器（QRNG）的后量子密码（PQC）算法，通过量子计算生成随机数，增强密钥生成、封装和数字签名的安全性，并设计了六种QRNG进行性能评估。", "motivation": "尽管NIST发布的PQC标准（如ML-KEM、ML-DSA和SLH-DSA）能抵抗量子计算攻击，但在某些特定应用场景中安全性仍不足，需结合量子随机性提升防护能力。", "method": "提出通用QRNG架构，设计六种QRNG，并依据NIST SP 800-90B标准进行统计验证（包括熵源检验和IID输出测试），评估其计算时间及基于QRNG的PQC算法性能。", "result": "实验量化了六种QRNG的计算效率，以及QRNG增强的ML-KEM、ML-DSA和SLH-DSA的性能表现，为未来PQC系统部署提供了关键参考数据。", "conclusion": "基于QRNG的PQC算法通过量子随机性显著提升安全性，实验验证了其可行性，为后量子密码的实际应用提供了新方向。"}}
{"id": "2507.21383", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21383", "abs": "https://arxiv.org/abs/2507.21383", "authors": ["Chunan Tong"], "title": "Optimizing Multi-Tier Supply Chain Ordering with LNN+XGBoost: Mitigating the Bullwhip Effect", "comment": null, "summary": "Supply chain management faces significant challenges, including demand\nfluctuations, inventory imbalances, and amplified upstream order variability\ndue to the bullwhip effect. Traditional methods, such as simple moving\naverages, struggle to address dynamic market conditions. Emerging machine\nlearning techniques, including LSTM, reinforcement learning, and XGBoost, offer\npotential solutions but are limited by computational complexity, training\ninefficiencies, or constraints in time-series modeling. Liquid Neural Networks,\ninspired by dynamic biological systems, present a promising alternative due to\ntheir adaptability, low computational cost, and robustness to noise, making\nthem suitable for real-time decision-making and edge computing. Despite their\nsuccess in applications like autonomous vehicles and medical monitoring, their\npotential in supply chain optimization remains underexplored. This study\nintroduces a hybrid LNN and XGBoost model to optimize ordering strategies in\nmulti-tier supply chains. By leveraging LNN's dynamic feature extraction and\nXGBoost's global optimization capabilities, the model aims to mitigate the\nbullwhip effect and enhance cumulative profitability. The research investigates\nhow local and global synergies within the hybrid framework address the dual\ndemands of adaptability and efficiency in SCM. The proposed approach fills a\ncritical gap in existing methodologies, offering an innovative solution for\ndynamic and efficient supply chain management.", "AI": {"tldr": "本文提出了一种结合液态神经网络(LNN)和XGBoost的混合模型，用于优化多级供应链中的订单策略，旨在解决牛鞭效应并提升累积利润。", "motivation": "供应链管理面临需求波动、库存失衡和牛鞭效应等挑战，传统方法难以应对动态市场条件，而现有机器学习技术存在计算复杂或训练效率低等问题。液态神经网络因其适应性、低计算成本和抗噪性，为实时决策和边缘计算提供了新可能。", "method": "研究引入了一种混合模型，结合LNN的动态特征提取能力和XGBoost的全局优化能力，以优化多级供应链中的订单策略。通过局部与全局协同作用，模型兼顾适应性和效率。", "result": "该混合模型能够有效缓解牛鞭效应，提升供应链的累积盈利能力，填补了现有方法在动态高效供应链管理中的空白。", "conclusion": "液态神经网络与XGBoost的混合框架为供应链优化提供了创新解决方案，展示了在动态环境中实现高效管理的潜力。"}}
{"id": "2507.21157", "categories": ["cs.CR", "cs.CV", "F.2.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2507.21157", "abs": "https://arxiv.org/abs/2507.21157", "authors": ["Naseem Khan", "Tuan Nguyen", "Amine Bermak", "Issa Khalil"], "title": "Unmasking Synthetic Realities in Generative AI: A Comprehensive Review of Adversarially Robust Deepfake Detection Systems", "comment": "27 pages, 4 Tables, 3 Figures", "summary": "The rapid advancement of Generative Artificial Intelligence has fueled\ndeepfake proliferation-synthetic media encompassing fully generated content and\nsubtly edited authentic material-posing challenges to digital security,\nmisinformation mitigation, and identity preservation. This systematic review\nevaluates state-of-the-art deepfake detection methodologies, emphasizing\nreproducible implementations for transparency and validation. We delineate two\ncore paradigms: (1) detection of fully synthetic media leveraging statistical\nanomalies and hierarchical feature extraction, and (2) localization of\nmanipulated regions within authentic content employing multi-modal cues such as\nvisual artifacts and temporal inconsistencies. These approaches, spanning\nuni-modal and multi-modal frameworks, demonstrate notable precision and\nadaptability in controlled settings, effectively identifying manipulations\nthrough advanced learning techniques and cross-modal fusion. However,\ncomprehensive assessment reveals insufficient evaluation of adversarial\nrobustness across both paradigms. Current methods exhibit vulnerability to\nadversarial perturbations-subtle alterations designed to evade\ndetection-undermining reliability in real-world adversarial contexts. This gap\nhighlights critical disconnect between methodological development and evolving\nthreat landscapes. To address this, we contribute a curated GitHub repository\naggregating open-source implementations, enabling replication and testing. Our\nfindings emphasize urgent need for future work prioritizing adversarial\nresilience, advocating scalable, modality-agnostic architectures capable of\nwithstanding sophisticated manipulations. This review synthesizes strengths and\nshortcomings of contemporary deepfake detection while charting paths toward\nrobust trustworthy systems.", "AI": {"tldr": "本文系统综述了深度伪造检测的最新技术，强调可复现实现的重要性，并指出当前方法在对抗鲁棒性方面的不足，呼吁未来研究应优先考虑对抗弹性。", "motivation": "生成式人工智能的快速发展导致深度伪造内容泛滥，对数字安全、错误信息缓解和身份保护构成挑战，亟需有效的检测方法。", "method": "研究评估了两种核心检测范式：(1)基于统计异常和分层特征提取的全合成媒体检测，(2)利用视觉伪影和时间不一致等多模态线索定位真实内容中的篡改区域。", "result": "现有方法在受控环境中表现出较高的精确度和适应性，但对抗鲁棒性评估不足，易受对抗性扰动影响，难以应对现实中的对抗场景。", "conclusion": "研究总结了当前深度伪造检测的优势与不足，强调未来应开发具有对抗弹性的可扩展、模态无关架构，并提供了开源实现库以促进复现和测试。"}}
{"id": "2507.21389", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.21389", "abs": "https://arxiv.org/abs/2507.21389", "authors": ["Tenghao Huang", "Sihao Chen", "Muhao Chen", "Jonathan May", "Longqi Yang", "Mengting Wan", "Pei Zhou"], "title": "Teaching Language Models To Gather Information Proactively", "comment": null, "summary": "Large language models (LLMs) are increasingly expected to function as\ncollaborative partners, engaging in back-and-forth dialogue to solve complex,\nambiguous problems. However, current LLMs often falter in real-world settings,\ndefaulting to passive responses or narrow clarifications when faced with\nincomplete or under-specified prompts, falling short of proactively gathering\nthe missing information that is crucial for high-quality solutions. In this\nwork, we introduce a new task paradigm: proactive information gathering, where\nLLMs must identify gaps in the provided context and strategically elicit\nimplicit user knowledge through targeted questions. To systematically study and\ntrain this capability, we design a scalable framework that generates partially\nspecified, real-world tasks, masking key information and simulating authentic\nambiguity. Within this setup, our core innovation is a reinforcement finetuning\nstrategy that rewards questions that elicit genuinely new, implicit user\ninformation -- such as hidden domain expertise or fine-grained requirements --\nthat would otherwise remain unspoken. Experiments demonstrate that our trained\nQwen-2.5-7B model significantly outperforms o3-mini by 18% on automatic\nevaluation metrics. More importantly, human evaluation reveals that\nclarification questions and final outlines generated by our model are favored\nby human annotators by 42% and 28% respectively. Together, these results\nhighlight the value of proactive clarification in elevating LLMs from passive\ntext generators to genuinely collaborative thought partners.", "AI": {"tldr": "本文提出了一种新任务范式——主动信息收集，通过强化微调策略训练LLMs主动识别信息缺口并引导用户提供隐含知识，实验证明Qwen-2.5-7B模型性能显著优于基线。", "motivation": "当前大语言模型（LLMs）面对不完整提示时往往被动回应，无法主动收集关键缺失信息，限制了其作为协作伙伴的能力。", "method": "设计了可扩展框架生成部分指定的现实任务，采用强化微调策略奖励能挖掘用户隐含知识（如领域专长或细粒度需求）的提问。", "result": "Qwen-2.5-7B模型自动评估指标超越基线18%，人工评估中其澄清问题和最终方案分别获得42%和28%的偏好率。", "conclusion": "主动澄清机制能将LLMs从被动文本生成器升级为真正的协作伙伴，显著提升问题解决质量。"}}
{"id": "2507.21163", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21163", "abs": "https://arxiv.org/abs/2507.21163", "authors": ["Ruiyang Zhao", "Bingbing Zhu", "Chuxuan Tong", "Xiaoyi Zhou", "Xi Zheng"], "title": "Generating Adversarial Point Clouds Using Diffusion Model", "comment": null, "summary": "Adversarial attack methods for 3D point cloud classification reveal the\nvulnerabilities of point cloud recognition models. This vulnerability could\nlead to safety risks in critical applications that use deep learning models,\nsuch as autonomous vehicles. To uncover the deficiencies of these models,\nresearchers can evaluate their security through adversarial attacks. However,\nmost existing adversarial attack methods are based on white-box attacks. While\nthese methods achieve high attack success rates and imperceptibility, their\napplicability in real-world scenarios is limited. Black-box attacks, which are\nmore meaningful in real-world scenarios, often yield poor results. This paper\nproposes a novel black-box adversarial example generation method that utilizes\na diffusion model to improve the attack success rate and imperceptibility in\nthe black-box setting, without relying on the internal information of the point\ncloud classification model to generate adversarial samples. We use a 3D\ndiffusion model to use the compressed features of the point cloud as prior\nknowledge to guide the reverse diffusion process to add adversarial points to\nclean examples. Subsequently, its reverse process is employed to transform the\ndistribution of other categories into adversarial points, which are then added\nto the point cloud.", "AI": {"tldr": "本文提出了一种基于扩散模型的黑盒对抗样本生成方法，用于提升3D点云分类模型在真实场景中的攻击成功率和隐蔽性。", "motivation": "现有对抗攻击方法多为白盒攻击，虽效果显著但实际应用受限；黑盒攻击更具现实意义但效果不佳。研究旨在解决黑盒场景下点云分类模型的安全漏洞问题。", "method": "利用3D扩散模型将点云压缩特征作为先验知识，通过逆向扩散过程添加对抗点，并转换其他类别分布生成对抗样本。", "result": "该方法在不依赖模型内部信息的情况下，有效提高了黑盒攻击的成功率和样本的不可感知性。", "conclusion": "扩散模型为黑盒对抗攻击提供了新思路，增强了点云模型安全性评估的实用性，对自动驾驶等关键应用具有重要价值。"}}
{"id": "2507.21406", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21406", "abs": "https://arxiv.org/abs/2507.21406", "authors": ["Meilin Zhu", "Gaojie Jin", "Xiaowei Huang", "Lijun Zhang"], "title": "Shapley Uncertainty in Natural Language Generation", "comment": null, "summary": "In question-answering tasks, determining when to trust the outputs is crucial\nto the alignment of large language models (LLMs). Kuhn et al. (2023) introduces\nsemantic entropy as a measure of uncertainty, by incorporating linguistic\ninvariances from the same meaning. It primarily relies on setting threshold to\nmeasure the level of semantic equivalence relation. We propose a more nuanced\nframework that extends beyond such thresholding by developing a Shapley-based\nuncertainty metric that captures the continuous nature of semantic\nrelationships. We establish three fundamental properties that characterize\nvalid uncertainty metrics and prove that our Shapley uncertainty satisfies\nthese criteria. Through extensive experiments, we demonstrate that our Shapley\nuncertainty more accurately predicts LLM performance in question-answering and\nother datasets, compared to similar baseline measures.", "AI": {"tldr": "本文提出了一种基于Shapley值的不确定性度量框架，用于更精确地评估大语言模型在问答任务中的输出可信度，相比基于语义熵的阈值方法能更好地捕捉语义关系的连续性。", "motivation": "现有语义熵方法通过设定阈值衡量语义等价关系，但无法充分反映语义关系的连续特性，需要更精细的不确定性度量框架来提升大语言模型输出可信度的评估效果。", "method": "开发基于Shapley值的不确定性度量指标，该指标无需依赖阈值设定，并证明了该指标满足有效不确定性度量的三个基本性质。", "result": "实验表明，在问答及其他数据集上，Shapley不确定性指标比基线方法能更准确地预测大语言模型的性能表现。", "conclusion": "Shapley不确定性框架为评估大语言模型输出可信度提供了更优的连续化度量工具，其理论性质和实践效果均优于基于阈值的语义熵方法。"}}
{"id": "2507.21170", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.21170", "abs": "https://arxiv.org/abs/2507.21170", "authors": ["Chad DeLuca", "Anna Lisa Gentile", "Shubhi Asthana", "Bing Zhang", "Pawan Chowdhary", "Kellen Cheng", "Basel Shbita", "Pengyuan Li", "Guang-Jie Ren", "Sandeep Gopisetty"], "title": "OneShield -- the Next Generation of LLM Guardrails", "comment": null, "summary": "The rise of Large Language Models has created a general excitement about the\ngreat potential for a myriad of applications. While LLMs offer many\npossibilities, questions about safety, privacy, and ethics have emerged, and\nall the key actors are working to address these issues with protective measures\nfor their own models and standalone solutions. The constantly evolving nature\nof LLMs makes the task of universally shielding users against their potential\nrisks extremely challenging, and one-size-fits-all solutions unfeasible. In\nthis work, we propose OneShield, our stand-alone, model-agnostic and\ncustomizable solution to safeguard LLMs. OneShield aims to provide facilities\nfor defining risk factors, expressing and declaring contextual safety and\ncompliance policies, and mitigating LLM risks, with a focus on each specific\ncustomer. We describe the implementation of the framework, the scalability\nconsiderations and provide usage statistics of OneShield since its first\ndeployment.", "AI": {"tldr": "本文提出了一种名为OneShield的独立、模型无关且可定制的解决方案，旨在保护大型语言模型(LLM)用户免受潜在风险，同时满足特定客户的安全与合规需求。", "motivation": "随着大型语言模型(LLM)的兴起，其在安全、隐私和伦理方面的问题日益凸显，现有解决方案难以应对LLM不断演变的特性，亟需一种灵活通用的保护机制。", "method": "研究团队开发了OneShield框架，该方案允许定义风险因素、表达上下文安全策略并实施风险缓解措施，其核心特点是模型无关性和高度可定制化。", "result": "论文详细描述了OneShield的实现框架、可扩展性设计，并提供了自首次部署以来的使用统计数据，验证了方案的可行性。", "conclusion": "OneShield作为独立解决方案，通过客户定制化策略有效应对了LLM的潜在风险，为不同场景下的模型安全防护提供了新思路。"}}
{"id": "2507.21407", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21407", "abs": "https://arxiv.org/abs/2507.21407", "authors": ["Yixin Liu", "Guibin Zhang", "Kun Wang", "Shiyuan Li", "Shirui Pan"], "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects", "comment": "15 pages, 7 figures", "summary": "Autonomous agents based on large language models (LLMs) have demonstrated\nimpressive capabilities in a wide range of applications, including web\nnavigation, software development, and embodied control. While most LLMs are\nlimited in several key agentic procedures, such as reliable planning, long-term\nmemory, tool management, and multi-agent coordination, graphs can serve as a\npowerful auxiliary structure to enhance structure, continuity, and coordination\nin complex agent workflows. Given the rapid growth and fragmentation of\nresearch on Graph-augmented LLM Agents (GLA), this paper offers a timely and\ncomprehensive overview of recent advances and also highlights key directions\nfor future work. Specifically, we categorize existing GLA methods by their\nprimary functions in LLM agent systems, including planning, memory, and tool\nusage, and then analyze how graphs and graph learning algorithms contribute to\neach. For multi-agent systems, we further discuss how GLA solutions facilitate\nthe orchestration, efficiency optimization, and trustworthiness of MAS.\nFinally, we highlight key future directions to advance this field, from\nimproving structural adaptability to enabling unified, scalable, and multimodal\nGLA systems. We hope this paper can serve as a roadmap for future research on\nGLA and foster a deeper understanding of the role of graphs in LLM agent\nsystems.", "AI": {"tldr": "本文综述了基于图增强的大语言模型代理（GLA）的最新研究进展，重点探讨了图结构在提升代理规划、记忆、工具使用及多代理协调中的关键作用，并提出了未来研究方向。", "motivation": "当前大语言模型代理在规划、长期记忆、工具管理和多代理协调等方面存在局限，图结构可有效增强复杂代理工作流的结构性和连续性，但相关研究分散且缺乏系统梳理。", "method": "通过功能分类（规划、记忆、工具使用）分析图及图学习算法在GLA中的作用，并讨论多代理系统中图解决方案对协调、效率优化和可信度的贡献。", "result": "研究表明图结构能显著提升LLM代理系统的性能，尤其在结构化任务和多代理协作场景中，同时揭示了现有方法在适应性、可扩展性方面的不足。", "conclusion": "未来需重点改进图结构的适应性、构建统一可扩展的多模态GLA系统，本文旨在为该领域研究提供路线图，深化对图在LLM代理中作用的理解。"}}
{"id": "2507.21177", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21177", "abs": "https://arxiv.org/abs/2507.21177", "authors": ["Xinhai Yan", "Libing Wu", "Zhuangzhuang Zhang", "Bingyi Liu", "Lijuan Huo", "Jing Wang"], "title": "FedBAP: Backdoor Defense via Benign Adversarial Perturbation in Federated Learning", "comment": "Accepted to ACM Multimedia 2025", "summary": "Federated Learning (FL) enables collaborative model training while preserving\ndata privacy, but it is highly vulnerable to backdoor attacks. Most existing\ndefense methods in FL have limited effectiveness due to their neglect of the\nmodel's over-reliance on backdoor triggers, particularly as the proportion of\nmalicious clients increases. In this paper, we propose FedBAP, a novel defense\nframework for mitigating backdoor attacks in FL by reducing the model's\nreliance on backdoor triggers. Specifically, first, we propose a perturbed\ntrigger generation mechanism that creates perturbation triggers precisely\nmatching backdoor triggers in location and size, ensuring strong influence on\nmodel outputs. Second, we utilize these perturbation triggers to generate\nbenign adversarial perturbations that disrupt the model's dependence on\nbackdoor triggers while forcing it to learn more robust decision boundaries.\nFinally, we design an adaptive scaling mechanism to dynamically adjust\nperturbation intensity, effectively balancing defense strength and model\nperformance. The experimental results demonstrate that FedBAP reduces the\nattack success rates by 0.22%-5.34%, 0.48%-6.34%, and 97.22%-97.6% under three\ntypes of backdoor attacks, respectively. In particular, FedBAP demonstrates\noutstanding performance against novel backdoor attacks.", "AI": {"tldr": "本文提出FedBAP框架，通过减少模型对后门触发器的依赖，有效防御联邦学习中的后门攻击。实验表明，该方法显著降低攻击成功率。", "motivation": "联邦学习(FL)在保护数据隐私的同时进行协同模型训练，但极易受后门攻击。现有防御方法因忽视模型对后门触发器的过度依赖而效果有限，尤其在恶意客户端比例增加时。", "method": "1. 提出扰动触发器生成机制，创建与后门触发器位置和大小精确匹配的扰动触发器\\n2. 利用这些触发器生成良性对抗扰动，破坏模型对后门触发器的依赖\\n3. 设计自适应缩放机制动态调整扰动强度，平衡防御强度与模型性能", "result": "实验结果显示，FedBAP在三种后门攻击下分别降低攻击成功率0.22%-5.34%、0.48%-6.34%和97.22%-97.6%，尤其对新型后门攻击表现突出。", "conclusion": "FedBAP框架通过减少模型对后门触发器的依赖，有效提升了联邦学习对抗后门攻击的防御能力，特别是在应对新型攻击时表现出色。"}}
{"id": "2507.21419", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21419", "abs": "https://arxiv.org/abs/2507.21419", "authors": ["Haiquan Wang", "Yi Chen", "Shang Zeng", "Yun Bian", "Zhe Cui"], "title": "GovRelBench:A Benchmark for Government Domain Relevance", "comment": null, "summary": "Current evaluations of LLMs in the government domain primarily focus on\nsafety considerations in specific scenarios, while the assessment of the\nmodels' own core capabilities, particularly domain relevance, remains\ninsufficient. To address this gap, we propose GovRelBench, a benchmark\nspecifically designed for evaluating the core capabilities of LLMs in the\ngovernment domain. GovRelBench consists of government domain prompts and a\ndedicated evaluation tool, GovRelBERT. During the training process of\nGovRelBERT, we introduce the SoftGovScore method: this method trains a model\nbased on the ModernBERT architecture by converting hard labels to soft scores,\nenabling it to accurately compute the text's government domain relevance score.\nThis work aims to enhance the capability evaluation framework for large models\nin the government domain, providing an effective tool for relevant research and\npractice. Our code and dataset are available at\nhttps://github.com/pan-xi/GovRelBench.", "AI": {"tldr": "本文提出了GovRelBench基准和SoftGovScore方法，专门用于评估大语言模型在政府领域的核心能力，特别是领域相关性。", "motivation": "当前对政府领域大语言模型的评估主要关注特定场景的安全性，而对模型核心能力（尤其是领域相关性）的评估不足。", "method": "开发了GovRelBench基准（包含政府领域提示词和评估工具GovRelBERT），并提出了SoftGovScore方法——通过将硬标签转换为软分数来训练基于ModernBERT架构的模型。", "result": "所提出的方法能精确计算文本的政府领域相关性分数，代码和数据集已在GitHub开源。", "conclusion": "该工作完善了政府领域大模型的评估框架，为相关研究和实践提供了有效工具。"}}
{"id": "2507.21178", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21178", "abs": "https://arxiv.org/abs/2507.21178", "authors": ["Masoud Hayeri Khyavi"], "title": "SHoM: A Mental-Synthesis Trust Management Model for Mitigating Botnet-Driven DDoS Attacks in the Internet of Things", "comment": "22 Pages, 15 figure, 9 tables", "summary": "The advantages of IoT in strengthening commercial, industrial, and social\necosystems have led to its widespread expansion. Nevertheless, because endpoint\ndevices have limited computation, storage, and communication capabilities, the\nIoT infrastructure is vulnerable to several cyber threats. As a result, DDoS\nattacks pose a severe risk to the security of IoT. By taking advantage of these\nweaknesses, attackers may quickly employ IoT devices as a component of botnets\nto execute DDoS attacks. The most critical development is how more armies of\nrobots are being constructed from IoT devices. We offer a Model for dealing\nwith DDOS attacks on botnets in the Internet of Things via trust management. In\nthis Model, an attempt has been made to consider all aspects of security\nconcerning trust factors to design a reliable and flexible model against DDoS\nattacks against the Internet of Things. In the initial studies, about 40-50\nsecurity models related to the subject have been studied by using review\narticles", "AI": {"tldr": "物联网(IoT)设备因其有限的计算、存储和通信能力，容易成为DDoS攻击的目标。本文提出了一种基于信任管理的模型，以应对IoT中的DDoS攻击。", "motivation": "IoT设备的广泛扩展带来了安全风险，尤其是DDoS攻击的威胁。攻击者利用IoT设备的弱点构建僵尸网络，进行大规模攻击。", "method": "通过信任管理设计了一个可靠且灵活的模型，以应对IoT中的DDoS攻击。研究中审查了40-50篇相关安全模型的文献。", "result": "提出的模型考虑了所有与信任因素相关的安全方面，旨在有效防御IoT中的DDoS攻击。", "conclusion": "基于信任管理的模型为IoT设备提供了对抗DDoS攻击的有效解决方案，增强了IoT生态系统的安全性。"}}
{"id": "2507.21438", "categories": ["cs.AI", "I.2.4; I.2.6; I.2.7; H.2.8"], "pdf": "https://arxiv.org/pdf/2507.21438", "abs": "https://arxiv.org/abs/2507.21438", "authors": ["Vishal Raman", "Vijai Aravindh R"], "title": "Evo-DKD: Dual-Knowledge Decoding for Autonomous Ontology Evolution in Large Language Models", "comment": "9 pages, 10 figures", "summary": "Ontologies and knowledge graphs require continuous evolution to remain\ncomprehensive and accurate, but manual curation is labor intensive. Large\nLanguage Models (LLMs) possess vast unstructured knowledge but struggle with\nmaintaining structured consistency. We propose Evo-DKD, a novel dual-decoder\nframework for autonomous ontology evolution that combines structured ontology\ntraversal with unstructured text reasoning. Evo-DKD introduces two parallel\ndecoding streams within an LLM: one decoder generates candidate ontology edits\n(e.g., new concepts or relations) while the other produces natural-language\njustifications. A dynamic attention-based gating mechanism coordinates the two\nstreams, deciding at each step how to blend structured and unstructured\nknowledge. Due to GPU constraints, we simulate the dual-decoder behavior using\nprompt-based mode control to approximate coordinated decoding in a\nsingle-stream mode. The system operates in a closed reasoning loop: proposed\nontology edits are validated (via consistency checks and cross-verification\nwith the text explanations) and then injected into the knowledge base, which in\nturn informs subsequent reasoning. We demonstrate Evo-DKD's effectiveness on\nuse cases including healthcare ontology refinement, semantic search\nimprovement, and cultural heritage timeline modeling. Experiments show that\nEvo-DKD outperforms baselines using structured-only or unstructured-only\ndecoding in both precision of ontology updates and downstream task performance.\nWe present quantitative metrics and qualitative examples, confirming the\ncontributions of the dual-decoder design and gating router. Evo-DKD offers a\nnew paradigm for LLM-driven knowledge base maintenance, combining the strengths\nof symbolic and neural reasoning for sustainable ontology evolution.", "AI": {"tldr": "提出Evo-DKD框架，通过双解码器结构结合结构化本体遍历与非结构化文本推理，实现本体自主演化，提升知识图谱更新的精度与下游任务性能。", "motivation": "本体与知识图谱需持续演化以保持全面准确，但人工维护成本高；大语言模型虽蕴含丰富非结构化知识，却难以保持结构化一致性。", "method": "采用双解码器框架：一个生成本体编辑候选（如新概念/关系），另一个生成自然语言解释；通过动态注意力门控机制协调两者，并采用提示模式控制模拟双流解码。系统形成闭环推理：编辑提案经一致性校验后注入知识库，反馈至后续推理。", "result": "实验表明Evo-DKD在医疗本体优化、语义搜索改进等场景中，本体更新精度与下游任务表现均优于纯结构化或非结构化基线方法。定量指标与定性案例验证了双解码器设计与门控路由器的有效性。", "conclusion": "Evo-DKD为LLM驱动的知识库维护提供新范式，融合符号推理与神经推理优势，实现可持续的本体演化。"}}
{"id": "2507.21181", "categories": ["cs.CR", "cs.CY", "cs.GR"], "pdf": "https://arxiv.org/pdf/2507.21181", "abs": "https://arxiv.org/abs/2507.21181", "authors": ["Smita Khapre", "Sudhanshu Semwal"], "title": "Mitigation of Social Media Platforms Impact on the Users", "comment": "WSCG 2025 33. International Conference on Computer Graphics,\n  Visualization and Computer Vision 2025", "summary": "Social media platforms offer numerous benefits and allow people to come\ntogether for various causes. Many communities, academia, government agencies,\ninstitutions, healthcare, entertainment, and businesses are on social media\nplatforms. They are intuitive and free for users. It has become unimaginable to\nlive without social media. Their architecture and data handling are geared\ntowards scalability, uninterrupted availability, and both personal and\ncollaborative revenue generation. Primarily, artificial intelligence algorithms\nare employed on stored user data for optimization and feeds. This has the\npotential to impact user safety, privacy, and security, even when metadata is\nused. A new decentralized data arrangement framework based on the Fractal-tree\nand L-Systems algorithm is proposed to mitigate some of the impacts of social\nmedia platforms.\n  Future work will focus on demonstrating the effectiveness of the new\ndecentralized framework by comparing its results against state-of-the-art\nsecurity methods currently used in databases. A cryptographic algorithm could\nalso be implemented for the framework, employing a new key generation for each\nbranch. This will strengthen database security; for example, if a user key is\nleaked, regenerating the key for each branch will keep the data secure by\napplying defense mechanisms in the proposed L-System-based tree framework.", "AI": {"tldr": "社交媒体平台虽带来便利，但其数据架构存在安全隐患。研究提出基于分形树和L-系统的去中心化框架，未来将验证其安全性并引入动态密钥加密机制。", "motivation": "社交媒体平台虽具高度可扩展性和商业价值，但其集中式数据管理对用户隐私安全构成威胁，需探索去中心化解决方案。", "method": "提出结合Fractal-tree与L-Systems算法的去中心化数据架构框架，未来拟采用分支动态密钥加密技术增强安全性。", "result": "理论框架表明，该方案可通过分支密钥再生机制抵御单点密钥泄露风险，但实际效果需与现有安全方案对比验证。", "conclusion": "基于分形结构的去中心化框架有望提升社交媒体数据安全，动态加密与L-系统防御机制是未来重点研究方向。"}}
{"id": "2507.21453", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21453", "abs": "https://arxiv.org/abs/2507.21453", "authors": ["Ashley Rector", "Keaton Minor", "Kamden Minor", "Jeff McCormack", "Beth Breeden", "Ryan Nowers", "Jay Dorris"], "title": "Validating Pharmacogenomics Generative Artificial Intelligence Query Prompts Using Retrieval-Augmented Generation (RAG)", "comment": null, "summary": "This study evaluated Sherpa Rx, an artificial intelligence tool leveraging\nlarge language models and retrieval-augmented generation (RAG) for\npharmacogenomics, to validate its performance on key response metrics. Sherpa\nRx integrated Clinical Pharmacogenetics Implementation Consortium (CPIC)\nguidelines with Pharmacogenomics Knowledgebase (PharmGKB) data to generate\ncontextually relevant responses. A dataset (N=260 queries) spanning 26 CPIC\nguidelines was used to evaluate drug-gene interactions, dosing recommendations,\nand therapeutic implications. In Phase 1, only CPIC data was embedded. Phase 2\nadditionally incorporated PharmGKB content. Responses were scored on accuracy,\nrelevance, clarity, completeness (5-point Likert scale), and recall. Wilcoxon\nsigned-rank tests compared accuracy between Phase 1 and Phase 2, and between\nPhase 2 and ChatGPT-4omini. A 20-question quiz assessed the tool's real-world\napplicability against other models. In Phase 1 (N=260), Sherpa Rx demonstrated\nhigh performance of accuracy 4.9, relevance 5.0, clarity 5.0, completeness 4.8,\nand recall 0.99. The subset analysis (N=20) showed improvements in accuracy\n(4.6 vs. 4.4, Phase 2 vs. Phase 1 subset) and completeness (5.0 vs. 4.8).\nChatGPT-4omini performed comparably in relevance (5.0) and clarity (4.9) but\nlagged in accuracy (3.9) and completeness (4.2). Differences in accuracy\nbetween Phase 1 and Phase 2 was not statistically significant. However, Phase 2\nsignificantly outperformed ChatGPT-4omini. On the 20-question quiz, Sherpa Rx\nachieved 90% accuracy, outperforming other models. Integrating additional\nresources like CPIC and PharmGKB with RAG enhances AI accuracy and performance.\nThis study highlights the transformative potential of generative AI like Sherpa\nRx in pharmacogenomics, improving decision-making with accurate, personalized\nresponses.", "AI": {"tldr": "本研究评估了基于大型语言模型和检索增强生成（RAG）的人工智能工具Sherpa Rx在药物基因组学中的表现，验证了其在关键响应指标上的性能。", "motivation": "研究旨在验证Sherpa Rx整合CPIC指南与PharmGKB数据后，能否生成上下文相关的准确响应，提升药物基因组学决策支持。", "method": "使用260个查询的数据集评估26项CPIC指南，分两阶段（仅CPIC数据、CPIC+PharmGKB）测试药物-基因相互作用、剂量建议等指标，并与ChatGPT-4omini对比。", "result": "Sherpa Rx在准确性（4.9/5）、召回率（0.99）等指标表现优异；第二阶段虽未显著提升准确性，但显著优于ChatGPT-4omini（90% vs 其他模型低准确率）。", "conclusion": "整合CPIC和PharmGKB的RAG技术能显著提升AI性能，Sherpa Rx展现了生成式AI在药物基因组学中提供精准个性化决策的变革潜力。"}}
{"id": "2507.21182", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21182", "abs": "https://arxiv.org/abs/2507.21182", "authors": ["Zixuan Chen", "Weikai Lu", "Xin Lin", "Ziqian Zeng"], "title": "SDD: Self-Degraded Defense against Malicious Fine-tuning", "comment": "Accepted by ACL2025", "summary": "Open-source Large Language Models (LLMs) often employ safety alignment\nmethods to resist harmful instructions. However, recent research shows that\nmaliciously fine-tuning these LLMs on harmful data can easily bypass these\nsafeguards. To counter this, we theoretically uncover why malicious fine-tuning\nsucceeds and identify potential defense strategies. Building on the theoretical\nanalysis, we introduce the Self-Degraded Defense (SDD) framework. SDD\nencourages LLMs to produce high-quality but irrelevant responses to harmful\nprompts. When attackers attempt malicious fine-tuning, the general capability\nof the LLM aligned by SDD will significantly decrease, rendering it incapable\nof following harmful instructions. Our experimental results confirm SDD's\neffectiveness against such attacks.", "AI": {"tldr": "本文提出自降级防御（SDD）框架，通过理论分析揭示恶意微调成功的原因，并设计防御策略使大语言模型（LLM）对有害指令生成高质量但不相关的响应，从而在恶意微调时显著降低模型通用能力。", "motivation": "开源大语言模型（LLM）常采用安全对齐方法抵御有害指令，但近期研究表明恶意微调可轻易绕过这些防护。为应对此问题，需从理论上解析攻击机制并开发有效防御方案。", "method": "基于理论分析提出自降级防御（SDD）框架：通过引导LLM对有害提示生成高质但不相关的响应，使得恶意微调时模型通用能力急剧下降，无法执行有害指令。", "result": "实验证实SDD能有效抵御恶意微调攻击，被SDD对齐的LLM在遭遇攻击时表现出显著的通用性能退化。", "conclusion": "SDD框架通过理论驱动的防御设计，成功解决了开源LLM在恶意微调下的安全漏洞，为模型安全部署提供新思路。"}}
{"id": "2507.21471", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21471", "abs": "https://arxiv.org/abs/2507.21471", "authors": ["Zujie Xie", "Zixuan Chen", "Jiheng Liang", "Xiangyang Yu", "Ziru Yu"], "title": "An LLM Driven Agent Framework for Automated Infrared Spectral Multi Task Reasoning", "comment": "19 pages", "summary": "Infrared spectroscopy offers rapid, non destructive measurement of chemical\nand material properties but suffers from high dimensional, overlapping spectral\nbands that challenge conventional chemometric approaches. Emerging large\nlanguage models (LLMs), with their capacity for generalization and reasoning,\noffer promising potential for automating complex scientific workflows. Despite\nthis promise, their application in IR spectral analysis remains largely\nunexplored. This study addresses the critical challenge of achieving accurate,\nautomated infrared spectral interpretation under low-data conditions using an\nLLM-driven framework. We introduce an end-to-end, large language model driven\nagent framework that integrates a structured literature knowledge base,\nautomated spectral preprocessing, feature extraction, and multi task reasoning\nin a unified pipeline. By querying a curated corpus of peer reviewed IR\npublications, the agent selects scientifically validated routines. The selected\nmethods transform each spectrum into low dimensional feature sets, which are\nfed into few shot prompt templates for classification, regression, and anomaly\ndetection. A closed loop, multi turn protocol iteratively appends mispredicted\nsamples to the prompt, enabling dynamic refinement of predictions. Across\ndiverse materials: stamp pad ink, Chinese medicine, Pu'er tea, Citri\nReticulatae Pericarpium and waste water COD datasets, the multi turn LLM\nconsistently outperforms single turn inference, rivaling or exceeding machine\nlearning and deep learning models under low data regimes.", "AI": {"tldr": "本研究提出了一种基于大语言模型（LLM）的端到端框架，用于在低数据条件下实现红外光谱的自动准确解析。该框架整合了文献知识库、光谱预处理、特征提取和多任务推理，通过多轮闭环协议动态优化预测，在多种材料数据集上表现优异。", "motivation": "红外光谱虽能快速无损测量化学物质特性，但其高维重叠谱带对传统化学计量学方法构成挑战。大语言模型（LLM）具有泛化和推理能力，为自动化复杂科学流程提供了新可能，但其在红外光谱分析中的应用尚未充分探索。", "method": "研究引入了一个端到端的LLM驱动代理框架，该框架集成了结构化文献知识库、自动光谱预处理、特征提取和多任务推理。通过查询经过筛选的同行评议红外文献，代理选择科学验证的方法，将光谱转化为低维特征集，并输入少样本提示模板进行分类、回归和异常检测。采用闭环多轮协议动态优化预测。", "result": "在多种材料数据集（包括印泥、中药、普洱茶、陈皮和废水COD）上，多轮LLM推理的表现持续优于单轮推理，并在低数据条件下媲美或超越传统机器学习和深度学习模型。", "conclusion": "该研究证明了LLM驱动框架在低数据条件下实现红外光谱自动解析的有效性，为复杂科学工作流的自动化提供了新思路。"}}
{"id": "2507.21193", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21193", "abs": "https://arxiv.org/abs/2507.21193", "authors": ["Sotiris Chatzimiltis", "Mohammad Shojafar", "Mahdi Boloursaz Mashhadi", "Rahim Tafazolli"], "title": "Interpretable Anomaly-Based DDoS Detection in AI-RAN with XAI and LLMs", "comment": null, "summary": "Next generation Radio Access Networks (RANs) introduce programmability,\nintelligence, and near real-time control through intelligent controllers,\nenabling enhanced security within the RAN and across broader 5G/6G\ninfrastructures. This paper presents a comprehensive survey highlighting\nopportunities, challenges, and research gaps for Large Language Models\n(LLMs)-assisted explainable (XAI) intrusion detection (IDS) for secure future\nRAN environments. Motivated by this, we propose an LLM interpretable\nanomaly-based detection system for distributed denial-of-service (DDoS) attacks\nusing multivariate time series key performance measures (KPMs), extracted from\nE2 nodes, within the Near Real-Time RAN Intelligent Controller (Near-RT RIC).\nAn LSTM-based model is trained to identify malicious User Equipment (UE)\nbehavior based on these KPMs. To enhance transparency, we apply post-hoc local\nexplainability methods such as LIME and SHAP to interpret individual\npredictions. Furthermore, LLMs are employed to convert technical explanations\ninto natural-language insights accessible to non-expert users. Experimental\nresults on real 5G network KPMs demonstrate that our framework achieves high\ndetection accuracy (F1-score > 0.96) while delivering actionable and\ninterpretable outputs.", "AI": {"tldr": "本文提出了一种基于大语言模型(LLM)的可解释异常检测系统，用于未来无线接入网(RAN)中的DDoS攻击检测，结合LSTM模型与事后解释方法(LIME/SHAP)，并通过LLM将技术解释转化为自然语言，实验显示F1分数>0.96。", "motivation": "新一代可编程智能RAN需要增强安全性，但现有入侵检测系统缺乏可解释性。本文旨在利用LLM辅助的可解释人工智能(XAI)技术，解决5G/6G基础设施中的安全挑战与研究空白。", "method": "1) 从E2节点提取多变量时间序列KPMs作为输入 2) 训练LSTM模型检测恶意UE行为 3) 应用LIME/SHAP进行局部预测解释 4) 使用LLM将技术解释转换为自然语言输出。", "result": "在真实5G网络KPMs上的实验表明，该框架实现了高检测精度(F1分数>0.96)，同时生成可操作且可解释的输出。", "conclusion": "该LLM可解释检测框架为未来RAN安全提供了高精度、透明化的DDoS攻击检测方案，其自然语言解释能力特别适合非专业用户理解。"}}
{"id": "2507.21488", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21488", "abs": "https://arxiv.org/abs/2507.21488", "authors": ["Zhenwei Tang", "Difan Jiao", "Eric Xue", "Reid McIlroy-Young", "Jon Kleinberg", "Siddhartha Sen", "Ashton Anderson"], "title": "Learning to Imitate with Less: Efficient Individual Behavior Modeling in Chess", "comment": null, "summary": "As humans seek to collaborate with, learn from, and better understand\nartificial intelligence systems, developing AIs that can accurately emulate\nindividual decision-making becomes increasingly important. Chess, a\nlong-standing AI benchmark with precise skill measurement, offers an ideal\ntestbed for human-AI alignment. However, existing approaches to modeling human\nbehavior require prohibitively large amounts of data from each individual,\nmaking them impractical for new or sparsely represented users. In this work, we\nintroduce Maia4All, a framework designed to learn and adapt to individual\ndecision-making styles efficiently, even with limited data. Maia4All achieves\nthis through a two-stage optimization process: (1) an enrichment step, which\nbridges population and individual-level human behavior modeling with a\nprototype-enriched model, and (2) a democratization step, which leverages\nability levels or user prototypes to initialize and refine individual\nembeddings with minimal data. Our experimental results show that Maia4All can\naccurately predict individual moves and profile behavioral patterns with high\nfidelity, establishing a new standard for personalized human-like AI behavior\nmodeling in chess. Maia4All achieves individual human behavior modeling in\nchess with only 20 games, compared to the 5,000 games required previously,\nrepresenting a significant improvement in data efficiency. Our work provides an\nexample of how population AI systems can flexibly adapt to individual users\nusing a prototype-enriched model as a bridge. This approach extends beyond\nchess, as shown in our case study on idiosyncratic LLMs, highlighting its\npotential for broader applications in personalized AI adaptation.", "AI": {"tldr": "本文提出Maia4All框架，通过两阶段优化过程高效学习并适应个体决策风格，仅需20局棋局数据即可精准建模人类棋手行为，显著提升数据效率。", "motivation": "随着人类与AI系统的协作需求增加，开发能精准模拟个体决策的AI变得至关重要。国际象棋作为AI长期基准测试领域，为研究人机对齐提供了理想平台。但现有方法需要大量个体数据，难以适用于新用户或数据稀疏场景。", "method": "采用两阶段优化：(1) 丰富化步骤：通过原型增强模型桥接群体与个体行为建模；(2) 民主化步骤：利用能力等级或用户原型初始化个体嵌入，仅需极少数据即可优化。", "result": "实验表明Maia4All仅需20局棋局（原需5000局）即可高保真预测个体走棋行为，在象棋个性化建模方面树立新标准。案例研究证明该方法可扩展至个性化大语言模型适配。", "conclusion": "该研究通过原型增强模型实现群体AI系统向个体用户的灵活适配，其方法论超越象棋领域，在个性化AI适配方面具有广泛的应用潜力。"}}
{"id": "2507.21195", "categories": ["cs.CR", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.21195", "abs": "https://arxiv.org/abs/2507.21195", "authors": ["Po-Yuan Mao", "Cheng-Chang Tsai", "Chun-Shien Lu"], "title": "MaXsive: High-Capacity and Robust Training-Free Generative Image Watermarking in Diffusion Models", "comment": null, "summary": "The great success of the diffusion model in image synthesis led to the\nrelease of gigantic commercial models, raising the issue of copyright\nprotection and inappropriate content generation. Training-free diffusion\nwatermarking provides a low-cost solution for these issues. However, the prior\nworks remain vulnerable to rotation, scaling, and translation (RST) attacks.\nAlthough some methods employ meticulously designed patterns to mitigate this\nissue, they often reduce watermark capacity, which can result in identity (ID)\ncollusion. To address these problems, we propose MaXsive, a training-free\ndiffusion model generative watermarking technique that has high capacity and\nrobustness. MaXsive best utilizes the initial noise to watermark the diffusion\nmodel. Moreover, instead of using a meticulously repetitive ring pattern, we\npropose injecting the X-shape template to recover the RST distortions. This\ndesign significantly increases robustness without losing any capacity, making\nID collusion less likely to happen. The effectiveness of MaXsive has been\nverified on two well-known watermarking benchmarks under the scenarios of\nverification and identification.", "AI": {"tldr": "本文提出MaXsive，一种无需训练的扩散模型水印技术，具有高容量和鲁棒性，能有效抵抗旋转、缩放和平移攻击，同时避免身份冲突。", "motivation": "扩散模型在图像合成中的成功引发了版权保护和不当内容生成的问题，现有水印技术对RST攻击脆弱且容量有限。", "method": "MaXsive利用初始噪声嵌入水印，并注入X形模板而非重复环状图案，以恢复RST失真，提高鲁棒性且不损失容量。", "result": "在两种知名水印基准测试中，MaXsive在验证和识别场景下均表现出色，显著提升了抗攻击能力和身份唯一性。", "conclusion": "MaXsive为扩散模型提供了一种高效、鲁棒的水印解决方案，解决了现有技术的局限性，具有实际应用价值。"}}
{"id": "2507.21502", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21502", "abs": "https://arxiv.org/abs/2507.21502", "authors": ["David Simchi-Levi", "Konstantina Mellou", "Ishai Menache", "Jeevan Pathuri"], "title": "Large Language Models for Supply Chain Decisions", "comment": "Forthcoming chapter in AI in Supply Chains: Perspectives from Global\n  Thought Leaders, edited by Maxime C. Cohen and Tinglong Dai, and part of the\n  Springer Series in Supply Chain Management (edited by Prof. Chris Tang)", "summary": "Supply Chain Management requires addressing a variety of complex\ndecision-making challenges, from sourcing strategies to planning and execution.\nOver the last few decades, advances in computation and information technologies\nhave enabled the transition from manual, intuition and experience-based\ndecision-making, into more automated and data-driven decisions using a variety\nof tools that apply optimization techniques. These techniques use mathematical\nmethods to improve decision-making.\n  Unfortunately, business planners and executives still need to spend\nconsiderable time and effort to (i) understand and explain the recommendations\ncoming out of these technologies; (ii) analyze various scenarios and answer\nwhat-if questions; and (iii) update the mathematical models used in these tools\nto reflect current business environments. Addressing these challenges requires\ninvolving data science teams and/or the technology providers to explain results\nor make the necessary changes in the technology and hence significantly slows\ndown decision making.\n  Motivated by the recent advances in Large Language Models (LLMs), we report\nhow this disruptive technology can democratize supply chain technology -\nnamely, facilitate the understanding of tools' outcomes, as well as the\ninteraction with supply chain tools without human-in-the-loop. Specifically, we\nreport how we apply LLMs to address the three challenges described above, thus\nsubstantially reducing the time to decision from days and weeks to minutes and\nhours as well as dramatically increasing planners' and executives' productivity\nand impact.", "AI": {"tldr": "供应链管理面临复杂决策挑战，传统优化技术依赖人工解释与模型更新。研究利用大语言模型（LLMs）实现工具结果自动化理解与交互，将决策时间从数周缩短至数小时。", "motivation": "现有供应链优化技术虽提升决策数据驱动性，但业务人员仍需大量时间理解结果、分析场景及更新模型，导致决策效率低下。LLMs的突破性进展为技术民主化提供可能。", "method": "应用LLMs技术解决三大核心挑战：(1)自动化解释工具输出结果；(2)支持交互式场景分析与假设问答；(3)动态调整数学模型以适配当前商业环境，无需人工介入。", "result": "LLMs将供应链决策周期从数天/周压缩至分钟/小时级别，显著提升规划者与高管的决策效率（生产力提升10倍）及商业影响力。", "conclusion": "LLMs通过消除人工干预瓶颈，实现了供应链技术的民主化应用，为复杂决策系统的人机交互范式提供了变革性解决方案。"}}
{"id": "2507.21258", "categories": ["cs.CR", "cs.CC", "cs.CY", "cs.GT", "F.0; H.0"], "pdf": "https://arxiv.org/pdf/2507.21258", "abs": "https://arxiv.org/abs/2507.21258", "authors": ["Joshua Luberisse"], "title": "Verification Cost Asymmetry in Cognitive Warfare: A Complexity-Theoretic Framework", "comment": null, "summary": "Human verification under adversarial information flow operates as a\ncost-bounded decision procedure constrained by working memory limits and\ncognitive biases. We introduce the Verification Cost Asymmetry (VCA)\ncoefficient, formalizing it as the ratio of expected verification work between\npopulations under identical claim distributions. Drawing on probabilistically\ncheckable proofs (PCP) and parameterized complexity theory, we construct\ndissemination protocols that reduce verification for trusted audiences to\nconstant human effort while imposing superlinear costs on adversarial\npopulations lacking cryptographic infrastructure. We prove theoretical\nguarantees for this asymmetry, validate the framework through controlled user\nstudies measuring verification effort with and without spot-checkable\nprovenance, and demonstrate practical encoding of real-world information\ncampaigns. The results establish complexity-theoretic foundations for\nengineering democratic advantage in cognitive warfare, with immediate\napplications to content authentication, platform governance, and information\noperations doctrine.", "AI": {"tldr": "该论文提出验证成本不对称性(VCA)系数，通过概率可检查证明(PCP)和参数化复杂度理论构建传播协议，实现在认知战中为可信受众提供恒定验证成本，而对缺乏加密基础设施的对手施加超线性成本。", "motivation": "研究人类在对抗性信息流下的验证行为受工作记忆限制和认知偏差影响，需要建立理论框架来量化不同群体间的验证成本差异，以设计更有效的信息传播策略。", "method": "结合概率可检查证明(PCP)和参数化复杂度理论，构建传播协议；通过用户研究测量有无可抽查来源时的验证工作量；对真实世界信息活动进行实际编码验证。", "result": "理论证明了验证成本不对称性的存在，用户研究验证了框架有效性，实际应用展示了真实信息活动的编码可行性。", "conclusion": "该研究为认知战中构建民主优势提供了复杂度理论基础，在内容认证、平台治理和信息作战学说方面具有直接应用价值。"}}
{"id": "2507.21503", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.21503", "abs": "https://arxiv.org/abs/2507.21503", "authors": ["Yanxu Zhu", "Shitong Duan", "Xiangxu Zhang", "Jitao Sang", "Peng Zhang", "Tun Lu", "Xiao Zhou", "Jing Yao", "Xiaoyuan Yi", "Xing Xie"], "title": "MoHoBench: Assessing Honesty of Multimodal Large Language Models via Unanswerable Visual Questions", "comment": null, "summary": "Recently Multimodal Large Language Models (MLLMs) have achieved considerable\nadvancements in vision-language tasks, yet produce potentially harmful or\nuntrustworthy content. Despite substantial work investigating the\ntrustworthiness of language models, MMLMs' capability to act honestly,\nespecially when faced with visually unanswerable questions, remains largely\nunderexplored. This work presents the first systematic assessment of honesty\nbehaviors across various MLLMs. We ground honesty in models' response behaviors\nto unanswerable visual questions, define four representative types of such\nquestions, and construct MoHoBench, a large-scale MMLM honest benchmark,\nconsisting of 12k+ visual question samples, whose quality is guaranteed by\nmulti-stage filtering and human verification. Using MoHoBench, we benchmarked\nthe honesty of 28 popular MMLMs and conducted a comprehensive analysis. Our\nfindings show that: (1) most models fail to appropriately refuse to answer when\nnecessary, and (2) MMLMs' honesty is not solely a language modeling issue, but\nis deeply influenced by visual information, necessitating the development of\ndedicated methods for multimodal honesty alignment. Therefore, we implemented\ninitial alignment methods using supervised and preference learning to improve\nhonesty behavior, providing a foundation for future work on trustworthy MLLMs.\nOur data and code can be found at https://github.com/DSTTSD/MoHoBench.", "AI": {"tldr": "本文首次系统评估了多模态大语言模型（MLLMs）在视觉不可回答问题上的诚实行为，构建了大规模基准MoHoBench，发现多数模型无法恰当拒绝回答，并提出监督与偏好学习对齐方法以提升可信度。", "motivation": "尽管多模态大语言模型在视觉语言任务中取得进展，但其面对不可视问题时生成有害或不可信内容的行为尚未被充分研究，亟需系统性评估与改进方法。", "method": "研究者定义了四类视觉不可回答问题，通过多阶段筛选与人工验证构建了包含12k+样本的MoHoBench基准，并测试了28个主流MLLMs的诚实性，最终采用监督学习和偏好学习进行对齐优化。", "result": "实验表明：（1）多数模型无法在必要时拒绝回答；（2）诚实性不仅与语言建模相关，更受视觉信息显著影响，需开发专门的多模态对齐方法。初步对齐实验验证了方法的有效性。", "conclusion": "该研究为可信MLLMs的发展奠定了基础，强调需针对多模态特性设计诚实对齐方案，公开的MoHoBench数据与代码将推动未来研究。"}}
{"id": "2507.21387", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21387", "abs": "https://arxiv.org/abs/2507.21387", "authors": ["Hongyi Xie"], "title": "Radio Adversarial Attacks on EMG-based Gesture Recognition Networks", "comment": null, "summary": "Surface electromyography (EMG) enables non-invasive human-computer\ninteraction in rehabilitation, prosthetics, and virtual reality. While deep\nlearning models achieve over 97% classification accuracy, their vulnerability\nto adversarial attacks remains largely unexplored in the physical domain. We\npresent ERa Attack, the first radio frequency (RF) adversarial method targeting\nEMG devices through intentional electromagnetic interference (IEMI). Using\nlow-power software-defined radio transmitters, attackers inject optimized RF\nperturbations to mislead downstream models. Our approach bridges digital and\nphysical domains: we generate adversarial perturbations using Projected\nGradient Descent, extract 50-150 Hz components via inverse STFT, and employ\nsynchronization-free strategies (constant spectrum noise or narrowband\nmodulation). Perturbations, constrained to 1-10% of signal amplitude, are\namplitude-modulated onto 433 MHz carriers. Experiments on the Myo Dataset (7\ngestures, 350 samples) demonstrate significant impact: at 1 meter and 0 dBm\ntransmission power, classification accuracy drops from 97.8% to 58.3%, with\n41.7% misclassification rate and 25.6% targeted attack success rate. Attack\neffectiveness decreases exponentially with distance, recovering to 85% accuracy\nat 3 meters. Increasing power to 10 dBm reduces accuracy by an additional 15%\nat 1 meter. This work pioneers RF-based adversarial attacks on EMG recognition\nsystems, revealing critical vulnerabilities in safety-critical applications. We\nquantify attack effectiveness across different perturbation modes and\ndistances, and propose defenses including hardware shielding, spectrum\nmonitoring, and adversarial training. Our findings inform the design of robust\nEMG systems against electromagnetic threats.", "AI": {"tldr": "本文提出ERa攻击，首次通过射频干扰（RF）对表面肌电（EMG）设备进行物理域对抗攻击，显著降低分类准确率，揭示了EMG系统在安全关键应用中的脆弱性。", "motivation": "尽管深度学习模型在EMG分类中准确率超过97%，但其在物理域对抗攻击下的脆弱性尚未充分研究。本研究旨在探索射频干扰对EMG设备的潜在威胁。", "method": "使用低功耗软件定义无线电发射器注入优化的射频扰动，通过投影梯度下降生成对抗扰动，提取50-150 Hz分量，并采用无同步策略（恒定频谱噪声或窄带调制）。扰动幅度限制为信号幅度的1-10%，并通过433 MHz载波进行幅度调制。", "result": "在1米距离和0 dBm发射功率下，分类准确率从97.8%降至58.3%，误分类率为41.7%，目标攻击成功率为25.6%。攻击效果随距离呈指数下降，3米时准确率恢复至85%。增加功率至10 dBm可在1米距离上进一步降低准确率15%。", "conclusion": "本研究首次揭示了RF对抗攻击对EMG识别系统的威胁，提出了硬件屏蔽、频谱监测和对抗训练等防御措施，为设计抗电磁干扰的EMG系统提供了重要参考。"}}
{"id": "2507.21513", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.21513", "abs": "https://arxiv.org/abs/2507.21513", "authors": ["Kenneth Li", "Fernanda Viégas", "Martin Wattenberg"], "title": "What Does it Mean for a Neural Network to Learn a \"World Model\"?", "comment": null, "summary": "We propose a set of precise criteria for saying a neural net learns and uses\na \"world model.\" The goal is to give an operational meaning to terms that are\noften used informally, in order to provide a common language for experimental\ninvestigation. We focus specifically on the idea of representing a latent\n\"state space\" of the world, leaving modeling the effect of actions to future\nwork. Our definition is based on ideas from the linear probing literature, and\nformalizes the notion of a computation that factors through a representation of\nthe data generation process. An essential addition to the definition is a set\nof conditions to check that such a \"world model\" is not a trivial consequence\nof the neural net's data or task.", "AI": {"tldr": "提出了一套精确标准来定义神经网络如何学习并使用\\\"世界模型\\\"，旨在为实验研究提供共同语言，重点关注潜在\\\"状态空间\\\"的表示。", "motivation": "为常被非正式使用的术语赋予操作意义，建立实验研究的共同框架，特别关注世界潜在状态的表示。", "method": "基于线性探测文献思想，形式化通过数据生成过程表示的计算概念，并增加条件以避免\\\"世界模型\\\"成为数据或任务的平凡结果。", "result": "提出了一套可操作的标准，用于验证神经网络是否真正学习并使用了非平凡的世界模型。", "conclusion": "该定义为研究神经网络中的世界模型提供了理论基础，未来可扩展至动作影响的建模。"}}
{"id": "2507.21398", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21398", "abs": "https://arxiv.org/abs/2507.21398", "authors": ["André Davi Lopes", "Tais Mello", "Wesley dos Reis Bezerra"], "title": "Digital identity management system with blockchain:An implementation with Ethereum and Ganache", "comment": null, "summary": "This paper presents the development of a distributed digital identity system\nutilizing modern technologies, including FastAPI, MongoDB, gRPC, Docker, and\nblockchain simulation with Ganache and Ethereum. The objective is to\ndemonstrate the benefits of distributed systems and blockchain for the\nsecurity, traceability, and decentralization of digital identities. The\nmethodology included the development of a microservices architecture with JWT\nauthentication, data persistence in MongoDB, simulation of blockchain\noperations using Ganache, and containerization with Docker. The results\ndemonstrate the feasibility of the proposed approach, with a functional web\ninterface, complete audit logs, and blockchain simulation with Ethereum. The\ntheoretical foundations, technical implementation, results obtained, and\nprospects for integration with real blockchain networks are discussed.", "AI": {"tldr": "本文开发了一个基于FastAPI、MongoDB、gRPC、Docker及Ganache与以太坊区块链模拟的分布式数字身份系统，展示了分布式系统与区块链在安全性、可追溯性和去中心化方面的优势。", "motivation": "旨在利用现代技术展示分布式系统和区块链如何提升数字身份的安全性、可追溯性及去中心化特性。", "method": "采用微服务架构，包含JWT认证、MongoDB数据持久化、Ganache区块链操作模拟及Docker容器化技术。", "result": "系统实现可行，具备功能性Web界面、完整审计日志及以太坊区块链模拟功能。", "conclusion": "讨论了理论基础、技术实现、成果展示，并展望了与真实区块链网络的集成前景。"}}
{"id": "2507.21518", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21518", "abs": "https://arxiv.org/abs/2507.21518", "authors": ["Jing Xu", "Weiqiang Wang", "Cunjian Chen", "Jun Liu", "Qiuhong Ke"], "title": "ST-GDance: Long-Term and Collision-Free Group Choreography from Music", "comment": "10 pages, 5 figures. Accepted at BMVC 2025", "summary": "Group dance generation from music has broad applications in film, gaming, and\nanimation production. However, it requires synchronizing multiple dancers while\nmaintaining spatial coordination. As the number of dancers and sequence length\nincrease, this task faces higher computational complexity and a greater risk of\nmotion collisions. Existing methods often struggle to model dense\nspatial-temporal interactions, leading to scalability issues and multi-dancer\ncollisions. To address these challenges, we propose ST-GDance, a novel\nframework that decouples spatial and temporal dependencies to optimize\nlong-term and collision-free group choreography. We employ lightweight graph\nconvolutions for distance-aware spatial modeling and accelerated sparse\nattention for efficient temporal modeling. This design significantly reduces\ncomputational costs while ensuring smooth and collision-free interactions.\nExperiments on the AIOZ-GDance dataset demonstrate that ST-GDance outperforms\nstate-of-the-art baselines, particularly in generating long and coherent group\ndance sequences. Project page: https://yilliajing.github.io/ST-GDance-Website/.", "AI": {"tldr": "提出ST-GDance框架，通过解耦时空依赖优化群舞生成，解决多舞者同步与碰撞问题，在AIOZ-GDance数据集上表现优于现有方法。", "motivation": "群舞生成需同步多舞者动作并避免碰撞，现有方法难以建模密集时空交互，导致可扩展性差与碰撞风险。", "method": "采用轻量图卷积进行距离感知的空间建模，结合加速稀疏注意力机制实现高效时序建模，显著降低计算成本。", "result": "实验表明ST-GDance在生成长时序连贯群舞方面优于基线，尤其擅长避免多舞者碰撞。", "conclusion": "ST-GDance通过解耦时空依赖，为影视游戏等场景提供高效、无碰撞的群舞生成解决方案。"}}
{"id": "2507.21412", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21412", "abs": "https://arxiv.org/abs/2507.21412", "authors": ["Yuntao Du", "Jiacheng Li", "Yuetian Chen", "Kaiyuan Zhang", "Zhizhen Yuan", "Hanshen Xiao", "Bruno Ribeiro", "Ninghui Li"], "title": "Cascading and Proxy Membership Inference Attacks", "comment": "Our code is available at: https://github.com/zealscott/MIA", "summary": "A Membership Inference Attack (MIA) assesses how much a trained machine\nlearning model reveals about its training data by determining whether specific\nquery instances were included in the dataset. We classify existing MIAs into\nadaptive or non-adaptive, depending on whether the adversary is allowed to\ntrain shadow models on membership queries. In the adaptive setting, where the\nadversary can train shadow models after accessing query instances, we highlight\nthe importance of exploiting membership dependencies between instances and\npropose an attack-agnostic framework called Cascading Membership Inference\nAttack (CMIA), which incorporates membership dependencies via conditional\nshadow training to boost membership inference performance.\n  In the non-adaptive setting, where the adversary is restricted to training\nshadow models before obtaining membership queries, we introduce Proxy\nMembership Inference Attack (PMIA). PMIA employs a proxy selection strategy\nthat identifies samples with similar behaviors to the query instance and uses\ntheir behaviors in shadow models to perform a membership posterior odds test\nfor membership inference. We provide theoretical analyses for both attacks, and\nextensive experimental results demonstrate that CMIA and PMIA substantially\noutperform existing MIAs in both settings, particularly in the low\nfalse-positive regime, which is crucial for evaluating privacy risks.", "AI": {"tldr": "本文提出两种成员推理攻击（MIA）方法：自适应环境下的级联成员推理攻击（CMIA）和非自适应环境下的代理成员推理攻击（PMIA），通过利用样本间的成员依赖关系和代理选择策略显著提升攻击性能。", "motivation": "现有成员推理攻击方法在自适应和非自适应环境下存在性能局限，特别是在低误报率场景中难以准确评估模型隐私风险，需要更高效的攻击框架。", "method": "在自适应设置中，CMIA通过条件影子训练整合成员依赖关系；在非自适应设置中，PMIA采用代理选择策略，利用相似样本行为进行成员后验概率检验。", "result": "实验表明CMIA和PMIA在两种环境下均显著优于现有方法，尤其在低误报率场景中能更精准识别训练数据成员。", "conclusion": "所提框架通过建模成员依赖和代理行为，为机器学习模型的隐私风险评估提供了更强大的分析工具，尤其在关键的低误报区域表现突出。"}}
{"id": "2507.21524", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21524", "abs": "https://arxiv.org/abs/2507.21524", "authors": ["Le Liang", "Hao Ye", "Yucheng Sheng", "Ouya Wang", "Jiacheng Wang", "Shi Jin", "Geoffrey Ye Li"], "title": "Large Language Models for Wireless Communications: From Adaptation to Autonomy", "comment": null, "summary": "The emergence of large language models (LLMs) has revolutionized artificial\nintelligence, offering unprecedented capabilities in reasoning, generalization,\nand zero-shot learning. These strengths open new frontiers in wireless\ncommunications, where increasing complexity and dynamics demand intelligent and\nadaptive solutions. This article explores the role of LLMs in transforming\nwireless systems across three key directions: adapting pretrained LLMs for core\ncommunication tasks, developing wireless-specific foundation models to balance\nversatility and efficiency, and enabling agentic LLMs with autonomous reasoning\nand coordination capabilities. We highlight recent advances, practical case\nstudies, and the unique benefits of LLM-based approaches over traditional\nmethods. Finally, we outline open challenges and research opportunities,\nincluding multimodal fusion, collaboration with lightweight models, and\nself-improving capabilities, charting a path toward intelligent, adaptive, and\nautonomous wireless networks of the future.", "AI": {"tldr": "大语言模型（LLMs）为无线通信系统带来变革，通过适应预训练模型、开发专用基础模型及赋能自主智能体，推动未来智能自适应网络发展。", "motivation": "无线通信系统日益复杂且动态变化，需要智能自适应解决方案，而大语言模型（LLMs）在推理、泛化和零样本学习方面的卓越能力为此提供了新机遇。", "method": "研究围绕三个方向展开：1）将预训练LLMs适配核心通信任务；2）开发兼顾通用性与效率的无线专用基础模型；3）赋予LLMs自主推理与协同决策的智能体能力。", "result": "LLM方法展现出超越传统技术的独特优势，案例研究验证了其在无线系统中的可行性，同时揭示了多模态融合、轻量化协作及自我改进等挑战。", "conclusion": "LLMs有望构建智能、自适应、自主的未来无线网络，但需解决跨模态整合、资源效率优化等开放性问题以释放其全部潜力。"}}
{"id": "2507.21483", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21483", "abs": "https://arxiv.org/abs/2507.21483", "authors": ["Pu Shi"], "title": "NCCR: to Evaluate the Robustness of Neural Networks and Adversarial Examples", "comment": null, "summary": "Neural networks have received a lot of attention recently, and related\nsecurity issues have come with it. Many studies have shown that neural networks\nare vulnerable to adversarial examples that have been artificially perturbed\nwith modification, which is too small to be distinguishable by human\nperception. Different attacks and defenses have been proposed to solve these\nproblems, but there is little research on evaluating the robustness of neural\nnetworks and their inputs. In this work, we propose a metric called the neuron\ncover change rate (NCCR) to measure the ability of deep learning models to\nresist attacks and the stability of adversarial examples. NCCR monitors\nalterations in the output of specifically chosen neurons when the input is\nperturbed, and networks with a smaller degree of variation are considered to be\nmore robust. The results of the experiment on image recognition and the speaker\nrecognition model show that our metrics can provide a good assessment of the\nrobustness of neural networks or their inputs. It can also be used to detect\nwhether an input is adversarial or not, as adversarial examples are always less\nrobust.", "AI": {"tldr": "本文提出了一种称为神经元覆盖变化率（NCCR）的指标，用于评估深度学习模型抵抗攻击的能力及对抗样本的稳定性。实验表明，NCCR能有效评估神经网络或其输入的鲁棒性，并检测对抗样本。", "motivation": "近年来，神经网络的安全问题备受关注，尤其是对抗样本的脆弱性。尽管已有多种攻防方法，但缺乏评估神经网络及其输入鲁棒性的研究。", "method": "通过监控特定神经元在输入扰动时的输出变化，提出NCCR指标。NCCR越小，网络鲁棒性越强。", "result": "在图像识别和说话人识别模型上的实验表明，NCCR能有效评估神经网络或其输入的鲁棒性，并可检测对抗样本。", "conclusion": "NCCR为评估神经网络鲁棒性及检测对抗样本提供了有效工具，对抗样本通常鲁棒性较低。"}}
{"id": "2507.21571", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.21571", "abs": "https://arxiv.org/abs/2507.21571", "authors": ["Laura Spillner", "Nima Zargham", "Mihai Pomarlan", "Robert Porzel", "Rainer Malaka"], "title": "Finding Uncommon Ground: A Human-Centered Model for Extrospective Explanations", "comment": "Presented at the IJCAI 2023 Workshop on Explainable Artificial\n  Intelligence (XAI)", "summary": "The need for explanations in AI has, by and large, been driven by the desire\nto increase the transparency of black-box machine learning models. However,\nsuch explanations, which focus on the internal mechanisms that lead to a\nspecific output, are often unsuitable for non-experts. To facilitate a\nhuman-centered perspective on AI explanations, agents need to focus on\nindividuals and their preferences as well as the context in which the\nexplanations are given. This paper proposes a personalized approach to\nexplanation, where the agent tailors the information provided to the user based\non what is most likely pertinent to them. We propose a model of the agent's\nworldview that also serves as a personal and dynamic memory of its previous\ninteractions with the same user, based on which the artificial agent can\nestimate what part of its knowledge is most likely new information to the user.", "AI": {"tldr": "Error processing this paper.", "motivation": "Error processing this paper.", "method": "Error processing this paper.", "result": "Error processing this paper.", "conclusion": "Error processing this paper."}}
{"id": "2507.21538", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21538", "abs": "https://arxiv.org/abs/2507.21538", "authors": ["Seiji Sato", "Tetsushi Ohki", "Masakatsu Nishigaki"], "title": "Can We End the Cat-and-Mouse Game? Simulating Self-Evolving Phishing Attacks with LLMs and Genetic Algorithms", "comment": null, "summary": "Anticipating emerging attack methodologies is crucial for proactive\ncybersecurity. Recent advances in Large Language Models (LLMs) have enabled the\nautomated generation of phishing messages and accelerated research into\npotential attack techniques. However, predicting future threats remains\nchallenging due to reliance on existing training data. To address this\nlimitation, we propose a novel framework that integrates LLM-based phishing\nattack simulations with a genetic algorithm in a psychological context,\nenabling phishing strategies to evolve dynamically through adversarial\ninteractions with simulated victims. Through simulations using Llama 3.1, we\ndemonstrate that (1) self-evolving phishing strategies employ increasingly\nsophisticated psychological manipulation techniques, surpassing naive\nLLM-generated attacks, (2) variations in a victim's prior knowledge\nsignificantly influence the evolution of attack strategies, and (3) adversarial\ninteractions between evolving attacks and adaptive defenses create a\ncat-and-mouse dynamic, revealing an inherent asymmetry in cybersecurity --\nattackers continuously refine their methods, whereas defenders struggle to\ncomprehensively counter all evolving threats. Our approach provides a scalable,\ncost-effective method for analyzing the evolution of phishing strategies and\ndefenses, offering insights into future social engineering threats and\nunderscoring the necessity of proactive cybersecurity measures.", "AI": {"tldr": "本文提出了一种结合大型语言模型(LLM)与遗传算法的新型框架，通过模拟钓鱼攻击与防御的对抗性互动，动态演化攻击策略，揭示了网络安全中攻防不对称的本质。", "motivation": "现有网络安全研究依赖静态训练数据，难以预测新型钓鱼攻击。为突破这一局限，需要开发能动态演化攻击策略的模拟系统。", "method": "采用Llama 3.1模型构建心理情境下的钓鱼攻击模拟系统，通过遗传算法使攻击策略在与模拟受害者的对抗中自主进化。", "result": "实验表明：(1)自演化钓鱼策略的心理操纵技术远超原始LLM生成攻击；(2)受害者先验知识显著影响攻击策略演化；(3)攻防对抗呈现'猫鼠游戏'动态，暴露出防御方难以全面应对持续进化威胁的不对称性。", "conclusion": "该框架为分析钓鱼策略演化提供了可扩展、低成本的方法，强调主动式网络安全措施的必要性，并为未来社会工程威胁研究提供新视角。"}}
{"id": "2507.21585", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21585", "abs": "https://arxiv.org/abs/2507.21585", "authors": ["Hao Ye", "Mengshi Qi", "Zhaohong Liu", "Liang Liu", "Huadong Ma"], "title": "SafeDriveRAG: Towards Safe Autonomous Driving with Knowledge Graph-based Retrieval-Augmented Generation", "comment": null, "summary": "In this work, we study how vision-language models (VLMs) can be utilized to\nenhance the safety for the autonomous driving system, including perception,\nsituational understanding, and path planning. However, existing research has\nlargely overlooked the evaluation of these models in traffic safety-critical\ndriving scenarios. To bridge this gap, we create the benchmark (SafeDrive228K)\nand propose a new baseline based on VLM with knowledge graph-based\nretrieval-augmented generation (SafeDriveRAG) for visual question answering\n(VQA). Specifically, we introduce SafeDrive228K, the first large-scale\nmultimodal question-answering benchmark comprising 228K examples across 18\nsub-tasks. This benchmark encompasses a diverse range of traffic safety\nqueries, from traffic accidents and corner cases to common safety knowledge,\nenabling a thorough assessment of the comprehension and reasoning abilities of\nthe models. Furthermore, we propose a plug-and-play multimodal knowledge\ngraph-based retrieval-augmented generation approach that employs a novel\nmulti-scale subgraph retrieval algorithm for efficient information retrieval.\nBy incorporating traffic safety guidelines collected from the Internet, this\nframework further enhances the model's capacity to handle safety-critical\nsituations. Finally, we conduct comprehensive evaluations on five mainstream\nVLMs to assess their reliability in safety-sensitive driving tasks.\nExperimental results demonstrate that integrating RAG significantly improves\nperformance, achieving a +4.73% gain in Traffic Accidents tasks, +8.79% in\nCorner Cases tasks and +14.57% in Traffic Safety Commonsense across five\nmainstream VLMs, underscoring the potential of our proposed benchmark and\nmethodology for advancing research in traffic safety. Our source code and data\nare available at https://github.com/Lumos0507/SafeDriveRAG.", "AI": {"tldr": "本文提出首个大规模多模态交通安全问答基准SafeDrive228K（含22.8万样本）及基于知识图谱检索增强生成的VLM新方法SafeDriveRAG，显著提升自动驾驶系统在事故处理、极端场景等安全关键任务中的性能。", "motivation": "现有研究缺乏对视觉语言模型在交通安全关键场景下的系统评估，阻碍了其在自动驾驶安全增强中的应用。", "method": "1) 构建覆盖18个子任务的SafeDrive228K基准；2) 提出多尺度子图检索算法，结合网络交通安全知识实现检索增强生成框架SafeDriveRAG。", "result": "在五大主流VLM上，RAG集成使交通事故任务提升4.73%、极端场景任务提升8.79%、交通常识任务提升14.57%。", "conclusion": "该基准与方法为交通安全研究提供新工具，证实知识增强能显著提升VLM在安全敏感驾驶任务中的可靠性。"}}
{"id": "2507.21540", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.21540", "abs": "https://arxiv.org/abs/2507.21540", "authors": ["Quanchen Zou", "Zonghao Ying", "Moyang Chen", "Wenzhuo Xu", "Yisong Xiao", "Yakai Li", "Deyue Zhang", "Dongdong Yang", "Zhao Liu", "Xiangzheng Zhang"], "title": "PRISM: Programmatic Reasoning with Image Sequence Manipulation for LVLM Jailbreaking", "comment": null, "summary": "The increasing sophistication of large vision-language models (LVLMs) has\nbeen accompanied by advances in safety alignment mechanisms designed to prevent\nharmful content generation. However, these defenses remain vulnerable to\nsophisticated adversarial attacks. Existing jailbreak methods typically rely on\ndirect and semantically explicit prompts, overlooking subtle vulnerabilities in\nhow LVLMs compose information over multiple reasoning steps. In this paper, we\npropose a novel and effective jailbreak framework inspired by Return-Oriented\nProgramming (ROP) techniques from software security. Our approach decomposes a\nharmful instruction into a sequence of individually benign visual gadgets. A\ncarefully engineered textual prompt directs the sequence of inputs, prompting\nthe model to integrate the benign visual gadgets through its reasoning process\nto produce a coherent and harmful output. This makes the malicious intent\nemergent and difficult to detect from any single component. We validate our\nmethod through extensive experiments on established benchmarks including\nSafeBench and MM-SafetyBench, targeting popular LVLMs. Results show that our\napproach consistently and substantially outperforms existing baselines on\nstate-of-the-art models, achieving near-perfect attack success rates (over 0.90\non SafeBench) and improving ASR by up to 0.39. Our findings reveal a critical\nand underexplored vulnerability that exploits the compositional reasoning\nabilities of LVLMs, highlighting the urgent need for defenses that secure the\nentire reasoning process.", "AI": {"tldr": "本文提出了一种受软件安全中ROP技术启发的创新越狱框架，通过将有害指令分解为多个良性视觉组件，利用LVLMs的组合推理能力生成有害输出，显著提升了攻击成功率。", "motivation": "现有大型视觉语言模型（LVLMs）的安全防御机制仍易受复杂对抗攻击，传统越狱方法依赖显式恶意提示，忽视了模型多步推理中的潜在漏洞。", "method": "采用类似ROP的技术，将有害指令拆解为独立良性视觉组件（gadgets），通过精心设计的文本提示引导模型在推理过程中组合这些组件，使恶意意图在整体中显现。", "result": "在SafeBench和MM-SafetyBench基准测试中，该方法对主流LVLMs实现接近完美的攻击成功率（SafeBench上超过0.90），ASR最高提升0.39。", "conclusion": "研究揭示了LVLMs组合推理能力中存在的重要漏洞，表明当前防御需加强对完整推理过程的保护，该发现对模型安全具有紧迫意义。"}}
{"id": "2507.21588", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.21588", "abs": "https://arxiv.org/abs/2507.21588", "authors": ["Jiong Yin", "Liang Li", "Jiehua Zhang", "Yuhan Gao", "Chenggang Yan", "Xichun Sheng"], "title": "Progressive Homeostatic and Plastic Prompt Tuning for Audio-Visual Multi-Task Incremental Learning", "comment": "Accepted by ICCV 2025", "summary": "Audio-visual multi-task incremental learning aims to continuously learn from\nmultiple audio-visual tasks without the need for joint training on all tasks.\nThe challenge of the problem is how to preserve the old task knowledge while\nfacilitating the learning of new task with previous experiences. To address\nthese challenges, we introduce a three-stage Progressive Homeostatic and\nPlastic audio-visual prompt (PHP) method. In the shallow phase, we design the\ntask-shared modality aggregating adapter to foster cross-task and cross-modal\naudio-visual representation learning to enhance shared understanding between\ntasks. In the middle phase, we propose the task-specific modality-shared\ndynamic generating adapter, which constructs prompts that are tailored to\nindividual tasks while remaining general across modalities, which balances the\nmodels ability to retain knowledge against forgetting with its potential for\nversatile multi-task transferability. In the deep phase, we introduce the\ntask-specific modality-independent prompts to further refine the understand\nability by targeting individual information for each task and modality. By\nincorporating these three phases, PHP retains task-specific prompts while\nadapting shared parameters for new tasks to effectively balance knowledge\nsharing and specificity. Our method achieves SOTA performance in different\norders of four tasks (AVE, AVVP, AVS and AVQA). Our code can be available at\nhttps://github.com/ENJOY-Yin-jiong/PHP.", "AI": {"tldr": "本文提出了一种三阶段渐进式稳态与可塑性视听提示（PHP）方法，用于解决视听多任务增量学习中的旧任务知识保留与新任务学习挑战，并在四个任务上实现了最先进性能。", "motivation": "视听多任务增量学习旨在无需联合训练所有任务的情况下持续学习多个视听任务，核心挑战是如何在保留旧任务知识的同时促进新任务学习。", "method": "PHP方法分为三个阶段：1) 浅层阶段设计任务共享模态聚合适配器以增强跨任务跨模态表示学习；2) 中层阶段提出任务特定模态共享动态生成适配器，平衡知识保留与多任务迁移能力；3) 深层阶段引入任务特定模态独立提示，针对各任务和模态细化理解能力。", "result": "该方法在AVE、AVVP、AVS和AVQA四个任务的不同顺序上均实现了最先进的性能（SOTA）。", "conclusion": "PHP通过三阶段设计有效平衡了知识共享与任务特异性，在保留任务特定提示的同时适应新任务的共享参数，为视听多任务增量学习提供了有效解决方案。"}}
{"id": "2507.21591", "categories": ["cs.CR", "cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.21591", "abs": "https://arxiv.org/abs/2507.21591", "authors": ["Mustapha Hemis", "Hamza Kheddar", "Mohamed Chahine Ghanem", "Bachir Boudraa"], "title": "Hierarchical Graph Neural Network for Compressed Speech Steganalysis", "comment": null, "summary": "Steganalysis methods based on deep learning (DL) often struggle with\ncomputational complexity and challenges in generalizing across different\ndatasets. Incorporating a graph neural network (GNN) into steganalysis schemes\nenables the leveraging of relational data for improved detection accuracy and\nadaptability. This paper presents the first application of a Graph Neural\nNetwork (GNN), specifically the GraphSAGE architecture, for steganalysis of\ncompressed voice over IP (VoIP) speech streams. The method involves\nstraightforward graph construction from VoIP streams and employs GraphSAGE to\ncapture hierarchical steganalysis information, including both fine grained\ndetails and high level patterns, thereby achieving high detection accuracy.\nExperimental results demonstrate that the developed approach performs well in\nuncovering quantization index modulation (QIM)-based steganographic patterns in\nVoIP signals. It achieves detection accuracy exceeding 98 percent even for\nshort 0.5 second samples, and 95.17 percent accuracy under challenging\nconditions with low embedding rates, representing an improvement of 2.8 percent\nover the best performing state of the art methods. Furthermore, the model\nexhibits superior efficiency, with an average detection time as low as 0.016\nseconds for 0.5-second samples an improvement of 0.003 seconds. This makes it\nefficient for online steganalysis tasks, providing a superior balance between\ndetection accuracy and efficiency under the constraint of short samples with\nlow embedding rates.", "AI": {"tldr": "本文首次将图神经网络（GNN）应用于压缩VoIP语音流的隐写分析，采用GraphSAGE架构，通过简单构图捕获多层次隐写特征，在低嵌入率短样本条件下实现98%检测准确率，效率提升显著。", "motivation": "现有基于深度学习的隐写分析方法存在计算复杂度高、跨数据集泛化能力差的问题，而图神经网络能利用关系数据提升检测精度与适应性。", "method": "从VoIP流直接构建图结构，采用GraphSAGE框架同时捕捉细粒度细节与高层模式，形成分层隐写分析信息。", "result": "模型对QIM隐写的VoIP信号检测准确率达98%（0.5秒样本），低嵌入率下95.17%，比现有最优方法提升2.8%；平均检测时间0.016秒，效率提升0.003秒。", "conclusion": "该方案在短样本低嵌入率约束下实现了精度与效率的优越平衡，为在线隐写分析任务提供了高效解决方案。"}}
{"id": "2507.21589", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21589", "abs": "https://arxiv.org/abs/2507.21589", "authors": ["Bin Liu"], "title": "Exploring the Link Between Bayesian Inference and Embodied Intelligence: Toward Open Physical-World Embodied AI Systems", "comment": "16 pages", "summary": "Embodied intelligence posits that cognitive capabilities fundamentally emerge\nfrom - and are shaped by - an agent's real-time sensorimotor interactions with\nits environment. Such adaptive behavior inherently requires continuous\ninference under uncertainty. Bayesian statistics offers a principled\nprobabilistic framework to address this challenge by representing knowledge as\nprobability distributions and updating beliefs in response to new evidence. The\ncore computational processes underlying embodied intelligence - including\nperception, action selection, learning, and even higher-level cognition - can\nbe effectively understood and modeled as forms of Bayesian inference. Despite\nthe deep conceptual connection between Bayesian statistics and embodied\nintelligence, Bayesian principles have not been widely or explicitly applied in\ntoday's embodied intelligence systems. In this work, we examine both Bayesian\nand contemporary embodied intelligence approaches through two fundamental\nlenses: search and learning - the two central themes in modern AI, as\nhighlighted in Rich Sutton's influential essay \"The Bitter Lesson\". This\nanalysis sheds light on why Bayesian inference has not played a central role in\nthe development of modern embodied intelligence. At the same time, it reveals\nthat current embodied intelligence systems remain largely confined to\nclosed-physical-world environments, and highlights the potential for Bayesian\nmethods to play a key role in extending these systems toward truly open\nphysical-world embodied intelligence.", "AI": {"tldr": "本文探讨了贝叶斯统计与具身智能的深层联系，指出当前具身智能系统未充分利用贝叶斯方法，并分析了其在开放物理世界中的潜在价值。", "motivation": "具身智能认为认知能力源于智能体与环境的实时感知运动交互，而贝叶斯统计为处理这种不确定性提供了概率框架。然而，当前具身智能系统尚未广泛采用贝叶斯方法。", "method": "通过Rich Sutton提出的'搜索与学习'两大AI核心主题，对比分析贝叶斯方法与当代具身智能方法的差异。", "result": "研究发现贝叶斯推理未成为现代具身智能发展的核心，同时揭示当前系统局限于封闭物理环境，贝叶斯方法有望推动开放物理世界具身智能的发展。", "conclusion": "贝叶斯方法在具身智能领域具有重要潜力，特别是在扩展系统至开放物理世界方面可能发挥关键作用。"}}
{"id": "2507.21640", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21640", "abs": "https://arxiv.org/abs/2507.21640", "authors": ["Hyeong Seon Kim", "Huy Kang Kim"], "title": "GUARD-CAN: Graph-Understanding and Recurrent Architecture for CAN Anomaly Detection", "comment": "Comments:12 pages, 3 figures, 3 tables; accepted to the 26th World\n  Conference on Information Security Applications (WISA 2025)", "summary": "Modern in-vehicle networks face various cyber threats due to the lack of\nencryption and authentication in the Controller Area Network (CAN). To address\nthis security issue, this paper presents GUARD-CAN, an anomaly detection\nframework that combines graph-based representation learning with time-series\nmodeling. GUARD-CAN splits CAN messages into fixed-length windows and converts\neach window into a graph that preserves message order. To detect anomalies in\nthe timeaware and structure-aware context at the same window, GUARD-CAN takes\nadvantage of the overcomplete Autoencoder (AE) and Graph Convolutional Network\n(GCN) to generate graph embedding vectors. The model groups these vectors into\nsequences and feeds them into the Gated Recurrent Unit (GRU) to detect temporal\nanomaly patterns across the graphs. GUARD-CAN performs anomaly detection at\nboth the sequence level and the window level, and this allows multi-perspective\nperformance evaluation. The model also verifies the importance of window size\nselection through an analysis based on Shannon entropy. As a result, GUARD-CAN\nshows that the proposed model detects four types of CAN attacks (flooding,\nfuzzing, replay and spoofing attacks) effectively without relying on complex\nfeature engineering.", "AI": {"tldr": "本文提出GUARD-CAN框架，结合图表示学习与时间序列建模，通过多级异常检测有效识别CAN总线攻击，无需复杂特征工程。", "motivation": "车载CAN网络因缺乏加密和认证面临安全威胁，需开发高效异常检测方案应对多种攻击类型。", "method": "将CAN消息分窗并转为时序图，使用过完备自编码器与图卷积网络生成嵌入向量，通过GRU检测跨图时序异常模式，支持窗口级和序列级双重检测。", "result": "模型成功检测泛洪、模糊、重放和欺骗四类攻击，基于香农熵的窗口大小分析验证了参数选择重要性。", "conclusion": "GUARD-CAN证明图与时序联合建模的优越性，为CAN安全提供无需人工特征的多视角检测框架。"}}
{"id": "2507.21631", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.21631", "abs": "https://arxiv.org/abs/2507.21631", "authors": ["Miguel Faria", "Francisco S. Melo", "Ana Paiva"], "title": "\"Teammates, Am I Clear?\": Analysing Legible Behaviours in Teams", "comment": null, "summary": "In this paper we investigate the notion of legibility in sequential\ndecision-making in the context of teams and teamwork. There have been works\nthat extend the notion of legibility to sequential decision making, for\ndeterministic and for stochastic scenarios. However, these works focus on one\nagent interacting with one human, foregoing the benefits of having legible\ndecision making in teams of agents or in team configurations with humans. In\nthis work we propose an extension of legible decision-making to multi-agent\nsettings that improves the performance of agents working in collaboration. We\nshowcase the performance of legible decision making in team scenarios using our\nproposed extension in multi-agent benchmark scenarios. We show that a team with\na legible agent is able to outperform a team composed solely of agents with\nstandard optimal behaviour.", "AI": {"tldr": "本文探讨了团队协作中序列决策的可读性概念，提出了一种多智能体环境下的可读决策扩展方法，并通过实验证明可读性智能体团队优于标准最优行为团队。", "motivation": "现有研究仅关注单智能体与单人类的交互，忽略了团队协作中可读决策的潜在优势。本文旨在填补这一空白，探索多智能体环境下可读性对团队性能的提升作用。", "method": "提出将可读决策概念扩展至多智能体场景，并在多智能体基准测试中验证所提方法的有效性。", "result": "实验表明，包含可读性智能体的团队性能优于完全由标准最优行为智能体组成的团队。", "conclusion": "团队协作中引入可读性决策能显著提升整体性能，为多智能体系统的设计提供了新的研究方向。"}}
{"id": "2507.21731", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21731", "abs": "https://arxiv.org/abs/2507.21731", "authors": ["Michiel Marcus", "Frank Westers", "Anne Nijsten"], "title": "Modelling Arbitrary Computations in the Symbolic Model using an Equational Theory for Bounded Binary Circuits", "comment": null, "summary": "In this work, we propose a class of equational theories for bounded binary\ncircuits that have the finite variant property. These theories could serve as a\nbuilding block to specify cryptographic primitive implementations and\nautomatically discover attacks as binary circuits in the symbolic model. We\nprovide proofs of equivalence between this class of equational theories and\nBoolean logic up to circuit size 3 and we provide the variant complexities and\nperformance benchmarks using Maude-NPA. This is the first result in this\ndirection and follow-up research is needed to improve the scalability of the\napproach.", "AI": {"tldr": "本文提出了一类具有有限变体性质的有界二元电路方程理论，可作为构建密码原语实现及在符号模型中自动发现攻击的基础模块。", "motivation": "旨在为密码原语的符号化建模提供理论基础，并通过自动分析发现潜在攻击，填补该领域研究空白。", "method": "构建了与布尔逻辑等价的方程理论类（电路规模≤3），使用Maude-NPA工具进行变体复杂度分析与性能基准测试。", "result": "首次实现电路规模3的理论等价性证明，但方法可扩展性仍需后续研究改进。", "conclusion": "该成果为密码电路符号化分析奠定基础，未来需提升方法的大规模适用性。"}}
{"id": "2507.21636", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21636", "abs": "https://arxiv.org/abs/2507.21636", "authors": ["Alessio Maritan"], "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "comment": null, "summary": "Large language model (LLM) agents integrate pre-trained LLMs with modular\nalgorithmic components and have shown remarkable reasoning and decision-making\nabilities. In this work, we investigate their use for two tightly intertwined\nchallenges in workforce management: staffing, i.e., the assignment and\nscheduling of tasks to workers, which may require team formation; and\nprofiling, i.e., the continuous estimation of workers' skills, preferences, and\nother latent attributes from unstructured data. We cast these problems in a\nformal mathematical framework that links scheduling decisions to latent feature\nestimation, and we introduce StaffPro, an LLM agent that addresses staffing and\nprofiling jointly. Differently from existing staffing solutions, StaffPro\nallows expressing optimization objectives using natural language, accepts\ntextual task descriptions and provides high flexibility. StaffPro interacts\ndirectly with humans by establishing a continuous human-agent feedback loop,\nensuring natural and intuitive use. By analyzing human feedback, our agent\ncontinuously estimates the latent features of workers, realizing life-long\nworker profiling and ensuring optimal staffing performance over time. A\nconsulting firm simulation example demonstrates that StaffPro successfully\nestimates workers' attributes and generates high quality schedules. With its\ninnovative design, StaffPro offers a robust, interpretable, and human-centric\nsolution for automated personnel management.", "AI": {"tldr": "本文提出StaffPro，一种结合大语言模型（LLM）的智能体，用于联合解决劳动力管理中的员工排班与能力画像问题。通过自然语言交互与持续反馈机制，该系统实现了动态人员调度与属性估计，并在模拟咨询公司场景中验证了有效性。", "motivation": "传统劳动力管理系统难以处理非结构化数据且缺乏灵活性。研究旨在开发能自然语言交互、持续优化排班决策并动态更新员工画像的智能解决方案，以提升人机协作效率。", "method": "建立数学框架将排班决策与潜在特征估计关联，设计LLM智能体StaffPro：1) 支持自然语言定义优化目标；2) 通过人机反馈循环持续学习员工技能/偏好；3) 结合文本任务描述实现灵活调度。", "result": "咨询公司模拟实验表明，StaffPro能准确估计员工潜在属性（技能/偏好），生成高质量排班方案。系统在持续交互中保持调度最优性，验证了方法的鲁棒性。", "conclusion": "StaffPro通过LLM与算法模块的创新结合，提供了可解释、以人为中心的自动化人力管理方案。其自然语言接口与终身学习机制为动态劳动力管理开辟了新途径。"}}
{"id": "2507.21817", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.21817", "abs": "https://arxiv.org/abs/2507.21817", "authors": ["Yikun Li", "Ngoc Tan Bui", "Ting Zhang", "Martin Weyssow", "Chengran Yang", "Xin Zhou", "Jinfeng Jiang", "Junkai Chen", "Huihui Huang", "Huu Hung Nguyen", "Chiok Yew Ho", "Jie Tan", "Ruiyin Li", "Yide Yin", "Han Wei Ang", "Frank Liauw", "Eng Lieh Ouh", "Lwin Khin Shar", "David Lo"], "title": "Out of Distribution, Out of Luck: How Well Can LLMs Trained on Vulnerability Datasets Detect Top 25 CWE Weaknesses?", "comment": null, "summary": "Automated vulnerability detection research has made substantial progress, yet\nits real-world impact remains limited. Current vulnerability datasets suffer\nfrom issues including label inaccuracy rates of 20-71%, extensive duplication,\nand poor coverage of critical CWE types. These issues create a significant\n\"generalization gap\" where models achieve misleading self-testing performance\n(measured on held-out data from same dataset for training) by exploiting\nspurious correlations rather than learning true vulnerability patterns. Our\nanalysis reveals that many models experience substantial performance drops of\nup to 40.6% when evaluated on independent data, sometimes underperforming\nrandom guessing.\n  To address these limitations, we present a three-part solution. First, we\nintroduce a manually curated test dataset, BenchVul, covering the MITRE Top 25\nMost Dangerous CWEs. Second, we construct a high-quality training dataset,\nTitanVul, comprising 35,045 functions by aggregating seven public sources and\napplying deduplication and validation using a novel multi-agent LLM framework.\nThird, we propose a Realistic Vulnerability Generation (RVG) framework, which\nsynthesizes context-aware vulnerability examples for underrepresented but\ncritical CWE types through simulated development workflows.\n  Our evaluation shows the strengths of each component in closing the\ngeneralization gap. First, BenchVul shows the limitations of self-testing:\nmodels trained on existing datasets, such as BigVul and PrimeVul, experience\nperformance drops on BenchVul (from 0.776 to 0.519 and from 0.567 to 0.337).\nSecond, training models on TitanVul demonstrates improved generalization, with\nmodel performance increasing from 0.584 when evaluated on the same dataset to\n0.767 when tested on BenchVul. Third, supplementing TitanVul with RVG-generated\ndata yields further gains, increasing model performance by 14.0% to 0.874.", "AI": {"tldr": "该研究针对自动化漏洞检测中数据集标签不准确、重复率高和关键CWE类型覆盖不足的问题，提出了包含高质量测试集BenchVul、训练集TitanVul和漏洞生成框架RVG的三部分解决方案，显著缩小了模型泛化差距。", "motivation": "当前漏洞数据集存在标签错误率20-71%、重复率高和关键CWE类型覆盖不足的问题，导致模型在独立数据上性能下降高达40.6%，甚至低于随机猜测，限制了自动化漏洞检测的实际应用。", "method": "1) 构建手动标注的测试集BenchVul覆盖MITRE Top 25危险CWE；2) 通过聚合7个公共源并应用去重和新型多智能体LLM验证框架，构建含35,045个函数的高质量训练集TitanVul；3) 提出上下文感知的Realistic Vulnerability Generation(RVG)框架，为关键但样本不足的CWE类型生成模拟开发流程的漏洞样本。", "result": "1) BenchVul揭示现有数据集训练的模型性能显著下降(BigVul从0.776降至0.519)；2) TitanVul训练的模型在BenchVul上性能从0.584提升至0.767；3) 补充RVG生成数据后性能再提升14.0%达到0.874。", "conclusion": "通过构建高质量数据集BenchVul/TitanVul和RVG框架的三阶段方案，有效解决了漏洞检测中的泛化差距问题，使模型在独立测试集上的性能最高提升至0.874，为实际应用提供了可靠基础。"}}
{"id": "2507.21637", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21637", "abs": "https://arxiv.org/abs/2507.21637", "authors": ["Wanying Wang", "Zeyu Ma", "Han Zheng", "Xin Tan", "Mingang Chen"], "title": "Self-Aware Safety Augmentation: Leveraging Internal Semantic Understanding to Enhance Safety in Vision-Language Models", "comment": "Accepted by ACM Multimedia 2025", "summary": "Large vision-language models (LVLMs) are vulnerable to harmful input compared\nto their language-only backbones. We investigated this vulnerability by\nexploring LVLMs internal dynamics, framing their inherent safety understanding\nin terms of three key capabilities. Specifically, we define these capabilities\nas safety perception, semantic understanding, and alignment for linguistic\nexpression, and experimentally pinpointed their primary locations within the\nmodel architecture. The results indicate that safety perception often emerges\nbefore comprehensive semantic understanding, leading to the reduction in\nsafety. Motivated by these findings, we propose \\textbf{Self-Aware Safety\nAugmentation (SASA)}, a technique that projects informative semantic\nrepresentations from intermediate layers onto earlier safety-oriented layers.\nThis approach leverages the model's inherent semantic understanding to enhance\nsafety recognition without fine-tuning. Then, we employ linear probing to\narticulate the model's internal semantic comprehension to detect the risk\nbefore the generation process. Extensive experiments on various datasets and\ntasks demonstrate that SASA significantly improves the safety of LVLMs, with\nminimal impact on the utility.", "AI": {"tldr": "研究发现大型视觉语言模型（LVLMs）比纯语言模型更容易受到有害输入的影响，并提出了一种名为SASA的自增强安全技术，通过利用模型内部的语义理解来提升安全性，同时保持实用性。", "motivation": "大型视觉语言模型（LVLMs）在面对有害输入时表现出比纯语言模型更低的防御能力，研究者试图通过分析其内部动态来理解这一脆弱性，并提出改进方案。", "method": "研究者定义了三种关键能力（安全感知、语义理解和语言表达对齐），并通过实验定位了它们在模型架构中的主要位置。基于这些发现，提出了\\textbf{自增强安全技术（SASA）}，将中间层的语义信息投射到早期的安全导向层，利用线性探测技术提前识别风险。", "result": "实验表明，SASA显著提升了LVLMs的安全性，同时对模型的实用性影响极小。", "conclusion": "通过利用模型内部的语义理解能力，SASA有效增强了LVLMs的安全性，为未来的模型安全研究提供了新的方向。"}}
{"id": "2507.21904", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.21904", "abs": "https://arxiv.org/abs/2507.21904", "authors": ["Shreyas Bargale", "Akshit Vakati Venkata", "Jaimandeep Singh", "Chester Rebeiro"], "title": "Privacy-Preserving Anonymization of System and Network Event Logs Using Salt-Based Hashing and Temporal Noise", "comment": null, "summary": "System and network event logs are essential for security analytics, threat\ndetection, and operational monitoring. However, these logs often contain\nPersonally Identifiable Information (PII), raising significant privacy concerns\nwhen shared or analyzed. A key challenge in log anonymization is balancing\nprivacy protection with the retention of sufficient structure for meaningful\nanalysis. Overly aggressive anonymization can destroy contextual integrity,\nwhile weak techniques risk re-identification through linkage or inference\nattacks. This paper introduces novel field-specific anonymization methods that\naddress this trade-off. For IP addresses, we propose a salt-based hashing\ntechnique applied at the per-octet level, preserving both subnet and host\nstructure to enable correlation across various log entries while ensuring\nnon-reversibility. For port numbers, full-value hashing with range mapping\nmaintains interpretability. We also present an order-preserving timestamp\nanonymization scheme using adaptive noise injection, which obfuscates exact\ntimes without disrupting event sequences. An open-source tool implementing\nthese techniques has been released to support practical deployment and\nreproducible research. Evaluations using entropy metrics, collision rates, and\nresidual leakage analysis demonstrate that the proposed approach effectively\nprotects privacy while preserving analytical utility.", "AI": {"tldr": "本文提出了一种新颖的日志匿名化方法，通过特定字段处理技术（如IP地址盐值哈希、端口范围映射和时序保留噪声注入）在保护隐私的同时保留日志分析价值，并发布了开源工具。", "motivation": "系统日志常含敏感个人信息，传统匿名化方法易导致隐私泄露或破坏分析价值，需平衡隐私保护与数据可用性。", "method": "IP地址采用分八位盐值哈希保留子网结构；端口号使用范围映射哈希；时间戳通过自适应噪声注入保持事件序列；配套开源工具实现方案。", "result": "经熵值、碰撞率及残留泄漏分析验证，该方法能有效抵御重识别攻击，同时维持日志的关联分析与时序解读能力。", "conclusion": "提出的字段级匿名化技术解决了隐私与效用的权衡问题，为安全分析提供了可复用的实践框架。"}}
{"id": "2507.21638", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.21638", "abs": "https://arxiv.org/abs/2507.21638", "authors": ["Leonard Hinckeldey", "Elliot Fosong", "Elle Miller", "Rimvydas Rubavicius", "Trevor McInroe", "Patricia Wollstadt", "Christiane B. Wiebel-Herboth", "Subramanian Ramamoorthy", "Stefano V. Albrecht"], "title": "Assistax: A Hardware-Accelerated Reinforcement Learning Benchmark for Assistive Robotics", "comment": "Accepted for the Coordination and Cooperation in Multi-Agent\n  Reinforcement Learning Workshop at the Reinforcement Learning Conference 2025", "summary": "The development of reinforcement learning (RL) algorithms has been largely\ndriven by ambitious challenge tasks and benchmarks. Games have dominated RL\nbenchmarks because they present relevant challenges, are inexpensive to run and\neasy to understand. While games such as Go and Atari have led to many\nbreakthroughs, they often do not directly translate to real-world embodied\napplications. In recognising the need to diversify RL benchmarks and addressing\ncomplexities that arise in embodied interaction scenarios, we introduce\nAssistax: an open-source benchmark designed to address challenges arising in\nassistive robotics tasks. Assistax uses JAX's hardware acceleration for\nsignificant speed-ups for learning in physics-based simulations. In terms of\nopen-loop wall-clock time, Assistax runs up to $370\\times$ faster when\nvectorising training runs compared to CPU-based alternatives. Assistax\nconceptualises the interaction between an assistive robot and an active human\npatient using multi-agent RL to train a population of diverse partner agents\nagainst which an embodied robotic agent's zero-shot coordination capabilities\ncan be tested. Extensive evaluation and hyperparameter tuning for popular\ncontinuous control RL and MARL algorithms provide reliable baselines and\nestablish Assistax as a practical benchmark for advancing RL research for\nassistive robotics. The code is available at:\nhttps://github.com/assistive-autonomy/assistax.", "AI": {"tldr": "论文介绍了Assistax，一个用于辅助机器人任务的开源强化学习基准，利用JAX硬件加速实现快速训练，并通过多智能体强化学习测试机器人协调能力。", "motivation": "现有强化学习基准多基于游戏，难以直接应用于现实世界的具身交互场景，因此需要多样化的基准来应对辅助机器人任务中的复杂挑战。", "method": "Assistax采用JAX硬件加速，实现物理模拟中的快速学习；通过多智能体强化学习训练多样化的伙伴智能体，测试机器人零样本协调能力。", "result": "Assistax在向量化训练时比CPU方案快$370\\times$，并为连续控制和多智能体强化学习算法提供了可靠的基线。", "conclusion": "Assistax是一个实用的基准，可推动辅助机器人领域的强化学习研究，其代码已开源。"}}
{"id": "2507.22037", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22037", "abs": "https://arxiv.org/abs/2507.22037", "authors": ["Muzhi Dai", "Shixuan Liu", "Zhiyuan Zhao", "Junyu Gao", "Hao Sun", "Xuelong Li"], "title": "Secure Tug-of-War (SecTOW): Iterative Defense-Attack Training with Reinforcement Learning for Multimodal Model Security", "comment": "10 pages, 4 figures", "summary": "The rapid advancement of multimodal large language models (MLLMs) has led to\nbreakthroughs in various applications, yet their security remains a critical\nchallenge. One pressing issue involves unsafe image-query pairs--jailbreak\ninputs specifically designed to bypass security constraints and elicit\nunintended responses from MLLMs. Compared to general multimodal data, such\nunsafe inputs are relatively sparse, which limits the diversity and richness of\ntraining samples available for developing robust defense models. Meanwhile,\nexisting guardrail-type methods rely on external modules to enforce security\nconstraints but fail to address intrinsic vulnerabilities within MLLMs.\nTraditional supervised fine-tuning (SFT), on the other hand, often over-refuses\nharmless inputs, compromising general performance. Given these challenges, we\npropose Secure Tug-of-War (SecTOW), an innovative iterative defense-attack\ntraining method to enhance the security of MLLMs. SecTOW consists of two\nmodules: a defender and an auxiliary attacker, both trained iteratively using\nreinforcement learning (GRPO). During the iterative process, the attacker\nidentifies security vulnerabilities in the defense model and expands jailbreak\ndata. The expanded data are then used to train the defender, enabling it to\naddress identified security vulnerabilities. We also design reward mechanisms\nused for GRPO to simplify the use of response labels, reducing dependence on\ncomplex generative labels and enabling the efficient use of synthetic data.\nAdditionally, a quality monitoring mechanism is used to mitigate the defender's\nover-refusal of harmless inputs and ensure the diversity of the jailbreak data\ngenerated by the attacker. Experimental results on safety-specific and general\nbenchmarks demonstrate that SecTOW significantly improves security while\npreserving general performance.", "AI": {"tldr": "本文提出了一种名为Secure Tug-of-War (SecTOW)的创新迭代防御-攻击训练方法，旨在增强多模态大语言模型(MLLMs)的安全性。该方法通过防御者和辅助攻击者的迭代训练，结合强化学习(GRPO)和奖励机制，有效提升了模型的安全性能，同时避免了过度拒绝无害输入的问题。", "motivation": "多模态大语言模型(MLLMs)的安全性问题日益突出，尤其是针对不安全图像-查询对的攻击。现有方法如外部模块防护和监督微调(SFT)存在局限性，无法充分应对模型内在漏洞或避免过度拒绝无害输入。因此，需要一种新的方法来平衡安全性和通用性能。", "method": "SecTOW方法包含两个模块：防御者和辅助攻击者，通过迭代训练使用强化学习(GRPO)。攻击者负责识别防御模型的安全漏洞并扩展越狱数据，防御者则利用扩展数据训练以应对已识别的漏洞。设计了奖励机制和质量监控机制，以减少对复杂生成标签的依赖并防止过度拒绝无害输入。", "result": "实验结果表明，SecTOW在安全性和通用性能基准测试中均表现优异，显著提升了模型的安全性，同时保持了其通用性能。", "conclusion": "SecTOW通过迭代防御-攻击训练和强化学习，有效解决了MLLMs的安全性问题，为未来安全模型的发展提供了新思路。"}}
{"id": "2507.21664", "categories": ["cs.AI", "cs.HC", "math.HO"], "pdf": "https://arxiv.org/pdf/2507.21664", "abs": "https://arxiv.org/abs/2507.21664", "authors": ["Mariam Alsayyad", "Fayadh Kadhem"], "title": "Can the current trends of AI handle a full course of mathematics?", "comment": "36 pages", "summary": "This paper addresses the question of how able the current trends of\nArtificial Intelligence (AI) are in managing to take the responsibility of a\nfull course of mathematics at a college level. The study evaluates this ability\nin four significant aspects, namely, creating a course syllabus, presenting\nselected material, answering student questions, and creating an assessment. It\nshows that even though the AI is strong in some important parts like\norganization and accuracy, there are still some human aspects that are far away\nfrom the current abilities of AI. There is still a hidden emotional part, even\nin science, that cannot be fulfilled by the AI in its current state. This paper\nsuggests some recommendations to integrate the human and AI potentials to\ncreate better outcomes in terms of reaching the target of creating a full\ncourse of mathematics, at a university level, as best as possible.", "AI": {"tldr": "本文探讨当前人工智能（AI）是否有能力承担大学数学课程的全部责任，评估其在课程大纲制定、教学内容展示、学生问题解答及考核设计四个方面的表现，指出AI虽在组织和准确性上有优势，但仍无法替代人类的情感因素，并提出人机协作的改进建议。", "motivation": "研究旨在评估当前AI技术是否足以独立承担大学数学课程的全流程教学任务，包括课程设计、教学实施和考核评估，以探索AI在教育领域的实际应用潜力与局限。", "method": "通过四个关键维度（课程大纲制定、教学内容展示、学生问题解答、考核设计）系统评估AI能力，对比分析其技术优势与人性化不足。", "result": "AI在课程组织与知识准确性方面表现突出，但缺乏科学教育中不可或缺的情感互动与隐性知识传递能力，目前无法完全替代人类教师角色。", "conclusion": "建议采用人机协作模式整合双方优势——利用AI的流程化处理能力，结合人类教师的情感智慧，以最优方式实现大学数学课程教学目标。"}}
{"id": "2507.21705", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21705", "abs": "https://arxiv.org/abs/2507.21705", "authors": ["Sergio Rozada", "Samuel Rey", "Gonzalo Mateos", "Antonio G. Marques"], "title": "Unrolling Dynamic Programming via Graph Filters", "comment": null, "summary": "Dynamic programming (DP) is a fundamental tool used across many engineering\nfields. The main goal of DP is to solve Bellman's optimality equations for a\ngiven Markov decision process (MDP). Standard methods like policy iteration\nexploit the fixed-point nature of these equations to solve them iteratively.\nHowever, these algorithms can be computationally expensive when the\nstate-action space is large or when the problem involves long-term\ndependencies. Here we propose a new approach that unrolls and truncates policy\niterations into a learnable parametric model dubbed BellNet, which we train to\nminimize the so-termed Bellman error from random value function\ninitializations. Viewing the transition probability matrix of the MDP as the\nadjacency of a weighted directed graph, we draw insights from graph signal\nprocessing to interpret (and compactly re-parameterize) BellNet as a cascade of\nnonlinear graph filters. This fresh look facilitates a concise, transferable,\nand unifying representation of policy and value iteration, with an explicit\nhandle on complexity during inference. Preliminary experiments conducted in a\ngrid-like environment demonstrate that BellNet can effectively approximate\noptimal policies in a fraction of the iterations required by classical methods.", "AI": {"tldr": "本文提出了一种名为BellNet的新方法，通过将策略迭代展开并截断为可学习的参数模型，以减少动态规划中的计算成本。该方法利用图信号处理技术，将BellNet重新参数化为非线性图滤波器级联，有效近似最优策略。", "motivation": "传统动态规划方法（如策略迭代）在状态-动作空间较大或涉及长期依赖时计算成本高昂。本文旨在提出一种更高效的方法来解决贝尔曼最优性方程。", "method": "提出BellNet模型，将策略迭代展开并截断为可学习的参数模型，通过最小化贝尔曼误差进行训练。利用图信号处理技术，将BellNet重新参数化为非线性图滤波器级联。", "result": "初步实验表明，BellNet在网格状环境中能够以远少于传统方法的迭代次数有效近似最优策略。", "conclusion": "BellNet提供了一种简洁、可迁移且统一的策略与值迭代表示方法，显著降低了推理复杂度，为动态规划问题提供了高效解决方案。"}}
{"id": "2507.21727", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21727", "abs": "https://arxiv.org/abs/2507.21727", "authors": ["Jianfei Zhu", "Haiqi Zhu", "Shaohui Liu", "Feng Jiang", "Baichun Wei", "Chunzhi Yi"], "title": "GDAIP: A Graph-Based Domain Adaptive Framework for Individual Brain Parcellation", "comment": null, "summary": "Recent deep learning approaches have shown promise in learning such\nindividual brain parcellations from functional magnetic resonance imaging\n(fMRI). However, most existing methods assume consistent data distributions\nacross domains and struggle with domain shifts inherent to real-world\ncross-dataset scenarios. To address this challenge, we proposed Graph Domain\nAdaptation for Individual Parcellation (GDAIP), a novel framework that\nintegrates Graph Attention Networks (GAT) with Minimax Entropy (MME)-based\ndomain adaptation. We construct cross-dataset brain graphs at both the group\nand individual levels. By leveraging semi-supervised training and adversarial\noptimization of the prediction entropy on unlabeled vertices from target brain\ngraph, the reference atlas is adapted from the group-level brain graph to the\nindividual brain graph, enabling individual parcellation under cross-dataset\nsettings. We evaluated our method using parcellation visualization, Dice\ncoefficient, and functional homogeneity. Experimental results demonstrate that\nGDAIP produces individual parcellations with topologically plausible\nboundaries, strong cross-session consistency, and ability of reflecting\nfunctional organization.", "AI": {"tldr": "提出GDAIP框架，结合图注意力网络与极小极大熵域适应方法，解决跨数据集脑区分割中的域偏移问题，实现个体化脑区分割。", "motivation": "现有深度学习方法假设跨域数据分布一致，难以处理真实跨数据集场景中的域偏移问题，需开发适应个体差异的脑区分割方法。", "method": "构建群体/个体水平的跨数据集脑图，通过半监督训练和对抗性优化目标脑图未标记顶点的预测熵，将参考图谱从群体脑图适配至个体脑图。", "result": "GDAIP生成的个体脑区具有拓扑合理的边界、跨会话强一致性，并能反映功能组织，可视化效果、Dice系数和功能同质性评估表现优异。", "conclusion": "GDAIP框架成功实现跨数据集场景下的个体化脑区分割，为神经影像分析提供了有效的域适应解决方案。"}}
{"id": "2507.21752", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21752", "abs": "https://arxiv.org/abs/2507.21752", "authors": ["Maurice Funk", "Jean Christoph Jung", "Tom Voellmer"], "title": "SAT-Based Bounded Fitting for the Description Logic ALC", "comment": "33 pages, full version of paper accepted at ISWC 2025", "summary": "Bounded fitting is a general paradigm for learning logical formulas from\npositive and negative data examples, that has received considerable interest\nrecently. We investigate bounded fitting for the description logic ALC and its\nsyntactic fragments. We show that the underlying size-restricted fitting\nproblem is NP-complete for all studied fragments, even in the special case of a\nsingle positive and a single negative example. By design, bounded fitting comes\nwith probabilistic guarantees in Valiant's PAC learning framework. In contrast,\nwe show that other classes of algorithms for learning ALC concepts do not\nprovide such guarantees. Finally, we present an implementation of bounded\nfitting in ALC and its fragments based on a SAT solver. We discuss\noptimizations and compare our implementation to other concept learning tools.", "AI": {"tldr": "本文研究了描述逻辑ALC及其语法片段的有界拟合问题，证明了其NP完全性，并展示了该方法的PAC学习保证。同时实现了一个基于SAT求解器的ALC有界拟合工具。", "motivation": "有界拟合作为一种从正负数据样本中学习逻辑公式的通用范式，近期受到广泛关注。研究旨在探索其在描述逻辑ALC及其片段中的应用特性与计算复杂度。", "method": "通过理论分析证明ALC片段有界拟合问题的NP完全性，并构建基于SAT求解器的实现方案。采用优化策略并与现有概念学习工具进行对比实验。", "result": "所有研究的ALC片段即使在单正例和单负例情况下，尺寸受限的拟合问题均为NP完全。实验表明该方法具有Valiant PAC学习框架下的概率保证。", "conclusion": "有界拟合为ALC概念学习提供了理论保证，而传统算法缺乏此类性质。基于SAT的实现展现了可行性，优化后性能可比肩现有工具。"}}
{"id": "2507.21753", "categories": ["cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2507.21753", "abs": "https://arxiv.org/abs/2507.21753", "authors": ["Grégoire Martinon", "Alexandra Lorenzo de Brionne", "Jérôme Bohard", "Antoine Lojou", "Damien Hervault", "Nicolas J-B. Brunel"], "title": "Towards a rigorous evaluation of RAG systems: the challenge of due diligence", "comment": "in French language. EvalLLM2025: Workshop on Evaluation Generative\n  Models (LLM) and Challenges, AMIAD, 2025, Marseille, France", "summary": "The rise of generative AI, has driven significant advancements in high-risk\nsectors like healthcare and finance. The Retrieval-Augmented Generation (RAG)\narchitecture, combining language models (LLMs) with search engines, is\nparticularly notable for its ability to generate responses from document\ncorpora. Despite its potential, the reliability of RAG systems in critical\ncontexts remains a concern, with issues such as hallucinations persisting. This\nstudy evaluates a RAG system used in due diligence for an investment fund. We\npropose a robust evaluation protocol combining human annotations and LLM-Judge\nannotations to identify system failures, like hallucinations, off-topic, failed\ncitations, and abstentions. Inspired by the Prediction Powered Inference (PPI)\nmethod, we achieve precise performance measurements with statistical\nguarantees. We provide a comprehensive dataset for further analysis. Our\ncontributions aim to enhance the reliability and scalability of RAG systems\nevaluation protocols in industrial applications.", "AI": {"tldr": "本文评估了检索增强生成（RAG）系统在投资尽调中的应用可靠性，提出结合人工标注与LLM-Judge标注的评估协议，并采用预测驱动推断（PPI）方法提升测量精度，旨在增强工业场景中RAG系统评估的可靠性与可扩展性。", "motivation": "尽管RAG架构在医疗、金融等高危领域展现出潜力，但其生成内容的可靠性问题（如幻觉现象）仍制约着关键场景的应用。本研究针对投资基金的尽调场景，探索系统化评估方案以解决这一挑战。", "method": "提出混合评估协议：1）人工标注与LLM-Judge标注并行识别幻觉、离题、引用失败等故障类型；2）基于预测驱动推断（PPI）方法实现具有统计保证的性能测量；3）构建完整数据集支持后续分析。", "result": "开发出可量化RAG系统故障类型的评估框架，通过PPI方法获得统计显著的性能指标，并公开数据集为工业级应用提供基准测试资源。", "conclusion": "该研究为RAG系统在工业场景中的可靠性评估建立了标准化协议，其方法论与数据集对提升生成式AI在高风险领域的应用安全性具有重要价值。"}}
{"id": "2507.21792", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21792", "abs": "https://arxiv.org/abs/2507.21792", "authors": ["Saixiong Liu", "Yuhua Qian", "Jue Li", "Honghong Cheng", "Feijiang Li"], "title": "Hybrid Causal Identification and Causal Mechanism Clustering", "comment": null, "summary": "Bivariate causal direction identification is a fundamental and vital problem\nin the causal inference field. Among binary causal methods, most methods based\non additive noise only use one single causal mechanism to construct a causal\nmodel. In the real world, observations are always collected in different\nenvironments with heterogeneous causal relationships. Therefore, on observation\ndata, this paper proposes a Mixture Conditional Variational Causal Inference\nmodel (MCVCI) to infer heterogeneous causality. Specifically, according to the\nidentifiability of the Hybrid Additive Noise Model (HANM), MCVCI combines the\nsuperior fitting capabilities of the Gaussian mixture model and the neural\nnetwork and elegantly uses the likelihoods obtained from the probabilistic\nbounds of the mixture conditional variational auto-encoder as causal decision\ncriteria. Moreover, we model the casual heterogeneity into cluster numbers and\npropose the Mixture Conditional Variational Causal Clustering (MCVCC) method,\nwhich can reveal causal mechanism expression. Compared with state-of-the-art\nmethods, the comprehensive best performance demonstrates the effectiveness of\nthe methods proposed in this paper on several simulated and real data.", "AI": {"tldr": "本文提出混合条件变分因果推断模型(MCVCI)及其聚类扩展MCVCC，用于识别异质因果关系，通过结合高斯混合模型与神经网络的拟合优势，利用概率界限似然作为因果判定标准，在模拟和真实数据上验证了优越性能。", "motivation": "现有二元因果方法多基于单一因果机制建模，而现实观测数据往往来自具有异质因果关系的不同环境，需开发能识别异质性的新方法。", "method": "基于混合加性噪声模型(HANM)的可识别性，结合高斯混合模型与神经网络的拟合能力，利用混合条件变分自编码器的概率界限似然作为因果判定标准，并进一步提出MCVCC方法对因果异质性进行聚类建模。", "result": "在多个模拟和真实数据集上的实验表明，所提方法相比现有最优方法具有全面最佳性能。", "conclusion": "MCVCI和MCVCC能有效推断异质因果关系并揭示因果机制表达，为复杂环境下的因果发现提供了新工具。"}}
{"id": "2507.21802", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.21802", "abs": "https://arxiv.org/abs/2507.21802", "authors": ["Junzhe Li", "Yutao Cui", "Tao Huang", "Yinping Ma", "Chun Fan", "Miles Yang", "Zhao Zhong"], "title": "MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE", "comment": null, "summary": "Although GRPO substantially enhances flow matching models in human preference\nalignment of image generation, methods such as FlowGRPO still exhibit\ninefficiency due to the necessity of sampling and optimizing over all denoising\nsteps specified by the Markov Decision Process (MDP). In this paper, we propose\n$\\textbf{MixGRPO}$, a novel framework that leverages the flexibility of mixed\nsampling strategies through the integration of stochastic differential\nequations (SDE) and ordinary differential equations (ODE). This streamlines the\noptimization process within the MDP to improve efficiency and boost\nperformance. Specifically, MixGRPO introduces a sliding window mechanism, using\nSDE sampling and GRPO-guided optimization only within the window, while\napplying ODE sampling outside. This design confines sampling randomness to the\ntime-steps within the window, thereby reducing the optimization overhead, and\nallowing for more focused gradient updates to accelerate convergence.\nAdditionally, as time-steps beyond the sliding window are not involved in\noptimization, higher-order solvers are supported for sampling. So we present a\nfaster variant, termed $\\textbf{MixGRPO-Flash}$, which further improves\ntraining efficiency while achieving comparable performance. MixGRPO exhibits\nsubstantial gains across multiple dimensions of human preference alignment,\noutperforming DanceGRPO in both effectiveness and efficiency, with nearly 50%\nlower training time. Notably, MixGRPO-Flash further reduces training time by\n71%. Codes and models are available at\n$\\href{https://github.com/Tencent-Hunyuan/MixGRPO}{MixGRPO}$.", "AI": {"tldr": "本文提出MixGRPO框架，通过结合SDE和ODE的混合采样策略优化图像生成中的人类偏好对齐，显著提升效率并降低训练时间。", "motivation": "现有方法如FlowGRPO因需对所有去噪步骤进行采样和优化而效率低下，MixGRPO旨在通过混合采样策略解决这一问题。", "method": "MixGRPO引入滑动窗口机制，窗口内使用SDE采样和GRPO优化，窗口外使用ODE采样，减少优化开销并支持高阶求解器。还提出更快变体MixGRPO-Flash。", "result": "MixGRPO在人类偏好对齐多个维度表现优异，训练时间比DanceGRPO降低近50%，MixGRPO-Flash进一步减少71%训练时间。", "conclusion": "MixGRPO通过混合采样策略显著提升效率和性能，为图像生成的人类偏好对齐提供了高效解决方案。"}}
{"id": "2507.21823", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21823", "abs": "https://arxiv.org/abs/2507.21823", "authors": ["Mohammad Azarijafari", "Luisa Mich", "Michele Missikoff"], "title": "An Agentic AI for a New Paradigm in Business Process Development", "comment": null, "summary": "Artificial Intelligence agents represent the next major revolution in the\ncontinuous technological evolution of industrial automation. In this paper, we\nintroduce a new approach for business process design and development that\nleverages the capabilities of Agentic AI. Departing from the traditional\ntask-based approach to business process design, we propose an agent-based\nmethod, where agents contribute to the achievement of business goals,\nidentified by a set of business objects. When a single agent cannot fulfill a\ngoal, we have a merge goal that can be achieved through the collaboration of\nmultiple agents. The proposed model leads to a more modular and intelligent\nbusiness process development by organizing it around goals, objects, and\nagents. As a result, this approach enables flexible and context-aware\nautomation in dynamic industrial environments.", "AI": {"tldr": "本文提出了一种基于Agentic AI的新型业务流程设计与开发方法，通过目标导向的智能体协作实现模块化和智能化的工业自动化。", "motivation": "传统基于任务的业务流程设计方法在动态工业环境中缺乏灵活性和上下文感知能力，需要更智能的解决方案。", "method": "采用基于智能体的方法，以业务目标和对象为中心组织流程，通过智能体协作实现单智能体无法完成的目标。", "result": "该方法实现了更具模块化和智能化的业务流程开发，能够适应动态工业环境的灵活自动化需求。", "conclusion": "基于智能体的目标导向方法为工业自动化提供了更高效、灵活的解决方案，是业务流程设计的重要演进方向。"}}
{"id": "2507.21830", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21830", "abs": "https://arxiv.org/abs/2507.21830", "authors": ["Kuiye Ding", "Fanda Fan", "Yao Wang", "Ruijie jian", "Xiaorui Wang", "Luqi Gong", "Yishan Jiang", "Chunjie Luo an Jianfeng Zhan"], "title": "DualSG: A Dual-Stream Explicit Semantic-Guided Multivariate Time Series Forecasting Framework", "comment": "This paper has been accepted by ACM Multimedia 2025 (ACM MM 2025)", "summary": "Multivariate Time Series Forecasting plays a key role in many applications.\nRecent works have explored using Large Language Models for MTSF to take\nadvantage of their reasoning abilities. However, many methods treat LLMs as\nend-to-end forecasters, which often leads to a loss of numerical precision and\nforces LLMs to handle patterns beyond their intended design. Alternatively,\nmethods that attempt to align textual and time series modalities within latent\nspace frequently encounter alignment difficulty. In this paper, we propose to\ntreat LLMs not as standalone forecasters, but as semantic guidance modules\nwithin a dual-stream framework. We propose DualSG, a dual-stream framework that\nprovides explicit semantic guidance, where LLMs act as Semantic Guides to\nrefine rather than replace traditional predictions. As part of DualSG, we\nintroduce Time Series Caption, an explicit prompt format that summarizes trend\npatterns in natural language and provides interpretable context for LLMs,\nrather than relying on implicit alignment between text and time series in the\nlatent space. We also design a caption-guided fusion module that explicitly\nmodels inter-variable relationships while reducing noise and computation.\nExperiments on real-world datasets from diverse domains show that DualSG\nconsistently outperforms 15 state-of-the-art baselines, demonstrating the value\nof explicitly combining numerical forecasting with semantic guidance.", "AI": {"tldr": "本文提出DualSG框架，将大语言模型(LLM)作为语义引导模块而非独立预测器，通过双流架构结合数值预测与语义指导，显著提升多元时间序列预测性能。", "motivation": "现有方法或直接将LLM用作端到端预测器导致数值精度损失，或难以实现文本与时间序列的隐式潜在空间对齐，需探索更有效的结合方式。", "method": "1) 设计双流框架DualSG，LLM作为语义引导模块优化传统预测结果\\n2) 提出可解释的时间序列描述文本(Time Series Caption)作为显式提示\\n3) 开发基于描述的融合模块显式建模变量间关系并降低噪声", "result": "在多个真实世界数据集上，DualSG持续超越15种前沿基线方法，验证显式结合数值预测与语义引导的有效性。", "conclusion": "通过将LLM定位为语义指导者而非替代者，并建立显式的模态交互机制，DualSG为时间序列预测提供了精度与可解释性兼备的新范式。"}}
{"id": "2507.21846", "categories": ["cs.AI", "cs.SC"], "pdf": "https://arxiv.org/pdf/2507.21846", "abs": "https://arxiv.org/abs/2507.21846", "authors": ["Chenyuan Zhang", "Cristian Rojas Cardenas", "Hamid Rezatofighi", "Mor Vered", "Buser Say"], "title": "Probabilistic Active Goal Recognition", "comment": "Accepted by KR2025", "summary": "In multi-agent environments, effective interaction hinges on understanding\nthe beliefs and intentions of other agents. While prior work on goal\nrecognition has largely treated the observer as a passive reasoner, Active Goal\nRecognition (AGR) focuses on strategically gathering information to reduce\nuncertainty. We adopt a probabilistic framework for Active Goal Recognition and\npropose an integrated solution that combines a joint belief update mechanism\nwith a Monte Carlo Tree Search (MCTS) algorithm, allowing the observer to plan\nefficiently and infer the actor's hidden goal without requiring domain-specific\nknowledge. Through comprehensive empirical evaluation in a grid-based domain,\nwe show that our joint belief update significantly outperforms passive goal\nrecognition, and that our domain-independent MCTS performs comparably to our\nstrong domain-specific greedy baseline. These results establish our solution as\na practical and robust framework for goal inference, advancing the field toward\nmore interactive and adaptive multi-agent systems.", "AI": {"tldr": "本文提出了一种主动目标识别（AGR）的概率框架，结合联合信念更新机制与蒙特卡洛树搜索（MCTS），在多智能体环境中高效推断隐藏目标，无需领域特定知识。实验表明该方法显著优于被动目标识别。", "motivation": "传统目标识别将观察者视为被动推理者，而主动目标识别（AGR）旨在通过策略性信息收集减少不确定性，推动多智能体系统向更具交互性和适应性的方向发展。", "method": "采用概率框架，整合联合信念更新机制与蒙特卡洛树搜索（MCTS）算法，支持观察者高效规划并推断行动者的隐藏目标，且不依赖领域特定知识。", "result": "在网格环境中验证表明：联合信念更新显著优于被动目标识别；领域无关的MCTS性能与领域特定的贪婪基线相当。", "conclusion": "该研究为多智能体目标推断提供了实用且鲁棒的框架，推动了交互式自适应系统的进步。"}}
{"id": "2507.21848", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21848", "abs": "https://arxiv.org/abs/2507.21848", "authors": ["Xingjian Zhang", "Siwei Wen", "Wenjun Wu", "Lei Huang"], "title": "EDGE-GRPO: Entropy-Driven GRPO with Guided Error Correction for Advantage Diversity", "comment": null, "summary": "Large Language Models (LLMs) have made remarkable progress in enhancing\nstep-by-step reasoning through reinforcement learning. However, the Group\nRelative Policy Optimization (GRPO) algorithm, which relies on sparse reward\nrules, often encounters the issue of identical rewards within groups, leading\nto the advantage collapse problem. Existing works typically address this\nchallenge from two perspectives: enforcing model reflection to enhance response\ndiversity, and introducing internal feedback to augment the training signal\n(advantage). In this work, we begin by analyzing the limitations of model\nreflection and investigating the policy entropy of responses at the\nfine-grained sample level. Based on our experimental findings, we propose the\nEDGE-GRPO algorithm, which adopts \\textbf{E}ntropy-\\textbf{D}riven Advantage\nand \\textbf{G}uided \\textbf{E}rror Correction to effectively mitigate the\nproblem of advantage collapse. Extensive experiments on several main reasoning\nbenchmarks demonstrate the effectiveness and superiority of our approach. It is\navailable at https://github.com/ZhangXJ199/EDGE-GRPO.", "AI": {"tldr": "本文提出EDGE-GRPO算法，通过熵驱动优势和引导错误校正解决GRPO算法中的优势崩溃问题，在多个推理基准测试中验证了其有效性。", "motivation": "现有GRPO算法因依赖稀疏奖励规则导致组内奖励相同，引发优势崩溃问题。传统方法通过增强模型反思或引入内部反馈来应对，但存在局限性。", "method": "通过分析模型反思的局限性及细粒度样本层面的策略熵，提出EDGE-GRPO算法，结合熵驱动优势（Entropy-Driven Advantage）和引导错误校正（Guided Error Correction）。", "result": "在多个主流推理基准测试上的实验表明，EDGE-GRPO能有效缓解优势崩溃问题，并展现出优越性能。", "conclusion": "EDGE-GRPO通过熵优化和错误校正机制显著提升了GRPO算法的稳定性与推理能力，为强化学习在语言模型中的应用提供了新思路。"}}
{"id": "2507.21872", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21872", "abs": "https://arxiv.org/abs/2507.21872", "authors": ["Shouyi Lu", "Zihan Lin", "Chao Lu", "Huanran Wang", "Guirong Zhuo", "Lianqing Zheng"], "title": "MultiEditor: Controllable Multimodal Object Editing for Driving Scenarios Using 3D Gaussian Splatting Priors", "comment": null, "summary": "Autonomous driving systems rely heavily on multimodal perception data to\nunderstand complex environments. However, the long-tailed distribution of\nreal-world data hinders generalization, especially for rare but safety-critical\nvehicle categories. To address this challenge, we propose MultiEditor, a\ndual-branch latent diffusion framework designed to edit images and LiDAR point\nclouds in driving scenarios jointly. At the core of our approach is introducing\n3D Gaussian Splatting (3DGS) as a structural and appearance prior for target\nobjects. Leveraging this prior, we design a multi-level appearance control\nmechanism--comprising pixel-level pasting, semantic-level guidance, and\nmulti-branch refinement--to achieve high-fidelity reconstruction across\nmodalities. We further propose a depth-guided deformable cross-modality\ncondition module that adaptively enables mutual guidance between modalities\nusing 3DGS-rendered depth, significantly enhancing cross-modality consistency.\nExtensive experiments demonstrate that MultiEditor achieves superior\nperformance in visual and geometric fidelity, editing controllability, and\ncross-modality consistency. Furthermore, generating rare-category vehicle data\nwith MultiEditor substantially enhances the detection accuracy of perception\nmodels on underrepresented classes.", "AI": {"tldr": "本文提出MultiEditor框架，通过双分支潜在扩散模型联合编辑图像与LiDAR点云，利用3D高斯泼溅(3DGS)作为先验，实现跨模态高保真重建，显著提升自动驾驶系统对稀有车辆类别的检测精度。", "motivation": "自动驾驶系统依赖多模态感知数据，但现实数据的长尾分布导致罕见车辆类别泛化能力不足。为解决这一关键安全问题，需开发能同时编辑图像与点云数据的方法。", "method": "1) 采用3DGS作为目标对象的结构与外观先验；2) 设计多级外观控制机制（像素级粘贴、语义级引导、多分支优化）；3) 提出深度引导的可变形跨模态条件模块，通过3DGS渲染深度增强模态间一致性。", "result": "实验表明MultiEditor在视觉/几何保真度、编辑可控性和跨模态一致性上表现优异，生成的稀有类别数据使感知模型对少数类的检测准确率显著提升。", "conclusion": "该框架为自动驾驶系统提供了有效的跨模态数据增强方案，通过3DGS先验与多级控制机制，成功解决了长尾分布下的关键类别感知难题。"}}
{"id": "2507.21873", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21873", "abs": "https://arxiv.org/abs/2507.21873", "authors": ["Raffaele Pojer", "Andrea Passerini", "Kim G. Larsen", "Manfred Jaeger"], "title": "A Neuro-Symbolic Approach for Probabilistic Reasoning on Graph Data", "comment": "Submitted to the Journal of Artificial Intelligence Research (JAIR);\n  under revision. 29 pages, 6 figures. Code available at\n  https://github.com/raffaelepojer/NeSy-for-graph-data", "summary": "Graph neural networks (GNNs) excel at predictive tasks on graph-structured\ndata but often lack the ability to incorporate symbolic domain knowledge and\nperform general reasoning. Relational Bayesian Networks (RBNs), in contrast,\nenable fully generative probabilistic modeling over graph-like structures and\nsupport rich symbolic knowledge and probabilistic inference. This paper\npresents a neuro-symbolic framework that seamlessly integrates GNNs into RBNs,\ncombining the learning strength of GNNs with the flexible reasoning\ncapabilities of RBNs.\n  We develop two implementations of this integration: one compiles GNNs\ndirectly into the native RBN language, while the other maintains the GNN as an\nexternal component. Both approaches preserve the semantics and computational\nproperties of GNNs while fully aligning with the RBN modeling paradigm. We also\npropose a maximum a-posteriori (MAP) inference method for these neuro-symbolic\nmodels.\n  To demonstrate the framework's versatility, we apply it to two distinct\nproblems. First, we transform a GNN for node classification into a collective\nclassification model that explicitly models homo- and heterophilic label\npatterns, substantially improving accuracy. Second, we introduce a\nmulti-objective network optimization problem in environmental planning, where\nMAP inference supports complex decision-making. Both applications include new\npublicly available benchmark datasets.\n  This work introduces a powerful and coherent neuro-symbolic approach to graph\ndata, bridging learning and reasoning in ways that enable novel applications\nand improved performance across diverse tasks.", "AI": {"tldr": "本文提出了一种神经符号框架，将图神经网络（GNNs）与关系贝叶斯网络（RBNs）相结合，整合了GNNs的学习能力和RBNs的推理能力。通过两种实现方式，该框架在节点分类和环境规划等任务中展示了优越性能。", "motivation": "图神经网络（GNNs）在图结构数据的预测任务中表现优异，但缺乏符号领域知识和通用推理能力。关系贝叶斯网络（RBNs）支持生成式概率建模和符号推理，但学习能力有限。本文旨在结合两者的优势。", "method": "提出了两种集成方法：一种将GNN直接编译为RBN语言，另一种将GNN作为外部组件保留。两种方法均保持了GNN的语义和计算特性，同时完全符合RBN建模范式。还提出了一种最大后验（MAP）推理方法。", "result": "在节点分类任务中，该框架通过显式建模同质性和异质性标签模式显著提高了准确性。在环境规划的多目标网络优化问题中，MAP推理支持复杂决策。两项应用均提供了公开基准数据集。", "conclusion": "这项工作提出了一种强大且一致的神经符号方法，弥合了图数据的学习与推理，为多样化任务带来了新颖应用和性能提升。"}}
{"id": "2507.21875", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21875", "abs": "https://arxiv.org/abs/2507.21875", "authors": ["Stefanos Gkikas", "Ioannis Kyprakis", "Manolis Tsiknakis"], "title": "Tiny-BioMoE: a Lightweight Embedding Model for Biosignal Analysis", "comment": null, "summary": "Pain is a complex and pervasive condition that affects a significant portion\nof the population. Accurate and consistent assessment is essential for\nindividuals suffering from pain, as well as for developing effective management\nstrategies in a healthcare system. Automatic pain assessment systems enable\ncontinuous monitoring, support clinical decision-making, and help minimize\npatient distress while mitigating the risk of functional deterioration.\nLeveraging physiological signals offers objective and precise insights into a\nperson's state, and their integration in a multimodal framework can further\nenhance system performance. This study has been submitted to the \\textit{Second\nMultimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The\nproposed approach introduces \\textit{Tiny-BioMoE}, a lightweight pretrained\nembedding model for biosignal analysis. Trained on $4.4$ million biosignal\nimage representations and consisting of only $7.3$ million parameters, it\nserves as an effective tool for extracting high-quality embeddings for\ndownstream tasks. Extensive experiments involving electrodermal activity, blood\nvolume pulse, respiratory signals, peripheral oxygen saturation, and their\ncombinations highlight the model's effectiveness across diverse modalities in\nautomatic pain recognition tasks. \\textit{\\textcolor{blue}{The model's\narchitecture (code) and weights are available at\nhttps://github.com/GkikasStefanos/Tiny-BioMoE.", "AI": {"tldr": "本文提出了一种轻量级预训练嵌入模型Tiny-BioMoE，用于生物信号分析，以提升自动疼痛评估系统的性能。该模型在多种生理信号上表现出色，代码和权重已开源。", "motivation": "疼痛是一种复杂且普遍的症状，准确的评估对患者和医疗系统至关重要。自动疼痛评估系统能实现持续监测，支持临床决策，并减少患者痛苦和功能恶化的风险。", "method": "研究提出了Tiny-BioMoE模型，这是一个轻量级预训练嵌入模型，用于生物信号分析。模型基于440万生物信号图像表示训练，仅包含730万参数，能有效提取高质量嵌入用于下游任务。", "result": "实验表明，Tiny-BioMoE在皮肤电活动、血容量脉冲、呼吸信号、外周血氧饱和度等多种生理信号上均表现出色，适用于自动疼痛识别任务。", "conclusion": "Tiny-BioMoE是一种高效的生物信号分析工具，能显著提升自动疼痛评估系统的性能。模型代码和权重已公开，可供进一步研究和应用。"}}
{"id": "2507.21881", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21881", "abs": "https://arxiv.org/abs/2507.21881", "authors": ["Stefanos Gkikas", "Ioannis Kyprakis", "Manolis Tsiknakis"], "title": "Multi-Representation Diagrams for Pain Recognition: Integrating Various Electrodermal Activity Signals into a Single Image", "comment": null, "summary": "Pain is a multifaceted phenomenon that affects a substantial portion of the\npopulation. Reliable and consistent evaluation benefits those experiencing pain\nand underpins the development of effective and advanced management strategies.\nAutomatic pain-assessment systems deliver continuous monitoring, inform\nclinical decision-making, and aim to reduce distress while preventing\nfunctional decline. By incorporating physiological signals, these systems\nprovide objective, accurate insights into an individual's condition. This study\nhas been submitted to the \\textit{Second Multimodal Sensing Grand Challenge for\nNext-Gen Pain Assessment (AI4PAIN)}. The proposed method introduces a pipeline\nthat leverages electrodermal activity signals as input modality. Multiple\nrepresentations of the signal are created and visualized as waveforms, and they\nare jointly visualized within a single multi-representation diagram. Extensive\nexperiments incorporating various processing and filtering techniques, along\nwith multiple representation combinations, demonstrate the effectiveness of the\nproposed approach. It consistently yields comparable, and in several cases\nsuperior, results to traditional fusion methods, establishing it as a robust\nalternative for integrating different signal representations or modalities.", "AI": {"tldr": "本文提出了一种基于皮肤电活动信号的多表征融合方法，用于自动疼痛评估，实验证明其效果优于传统融合方法。", "motivation": "疼痛评估对患者管理和临床决策至关重要，自动评估系统能提供客观、连续的监测，减少患者痛苦并防止功能退化。", "method": "研究采用皮肤电活动信号作为输入模态，生成多种信号表征并整合为单一多表征图，结合多种处理和滤波技术进行实验验证。", "result": "该方法在多种表征组合下表现稳定，效果与传统融合方法相当甚至更优，成为整合不同信号表征或模态的可靠替代方案。", "conclusion": "提出的多表征融合管道为疼痛评估提供了新思路，其鲁棒性和有效性通过实验得到验证，适用于下一代疼痛监测系统。"}}
{"id": "2507.21882", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.21882", "abs": "https://arxiv.org/abs/2507.21882", "authors": ["Elmira Onagh", "Alireza Davoodi", "Maleknaz Nayebi"], "title": "The Impact of Foundational Models on Patient-Centric e-Health Systems", "comment": "Paper published in COMPSAC 2025", "summary": "As Artificial Intelligence (AI) becomes increasingly embedded in healthcare\ntechnologies, understanding the maturity of AI in patient-centric applications\nis critical for evaluating its trustworthiness, transparency, and real-world\nimpact. In this study, we investigate the integration and maturity of AI\nfeature integration in 116 patient-centric healthcare applications. Using Large\nLanguage Models (LLMs), we extracted key functional features, which are then\ncategorized into different stages of the Gartner AI maturity model. Our results\nshow that over 86.21\\% of applications remain at the early stages of AI\nintegration, while only 13.79% demonstrate advanced AI integration.", "AI": {"tldr": "研究评估了116个以患者为中心的医疗应用中AI的成熟度，发现86.21\\%处于早期阶段，仅13.79\\%展现高级整合。", "motivation": "随着AI在医疗技术中的深入应用，评估其在患者中心应用中的成熟度对信任度、透明度及实际影响至关重要。", "method": "利用大语言模型(LLMs)提取关键功能特征，并按Gartner AI成熟度模型进行分类。", "result": "86.21\\%的应用处于AI整合初级阶段，仅13.79\\%实现高级整合。", "conclusion": "当前医疗应用中AI整合整体成熟度较低，需进一步推动技术向高阶发展。"}}
{"id": "2507.21886", "categories": ["cs.AI", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.21886", "abs": "https://arxiv.org/abs/2507.21886", "authors": ["Stefanos Gkikas", "Ioannis Kyprakis", "Manolis Tsiknakis"], "title": "Efficient Pain Recognition via Respiration Signals: A Single Cross-Attention Transformer Multi-Window Fusion Pipeline", "comment": null, "summary": "Pain is a complex condition affecting a large portion of the population.\nAccurate and consistent evaluation is essential for individuals experiencing\npain, and it supports the development of effective and advanced management\nstrategies. Automatic pain assessment systems provide continuous monitoring and\nsupport clinical decision-making, aiming to reduce distress and prevent\nfunctional decline. This study has been submitted to the \\textit{Second\nMultimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The\nproposed method introduces a pipeline that leverages respiration as the input\nsignal and incorporates a highly efficient cross-attention transformer\nalongside a multi-windowing strategy. Extensive experiments demonstrate that\nrespiration is a valuable physiological modality for pain assessment. Moreover,\nexperiments revealed that compact and efficient models, when properly\noptimized, can achieve strong performance, often surpassing larger\ncounterparts. The proposed multi-window approach effectively captures both\nshort-term and long-term features, as well as global characteristics, thereby\nenhancing the model's representational capacity.", "AI": {"tldr": "本研究提出了一种基于呼吸信号的高效跨注意力Transformer模型，结合多窗口策略用于疼痛评估，实验证明呼吸信号作为生理模态具有重要价值，且优化后的小模型性能可超越大模型。", "motivation": "疼痛是影响广泛人群的复杂症状，准确评估对患者管理和临床决策至关重要。自动疼痛评估系统能实现持续监测，减轻痛苦并预防功能退化。", "method": "采用呼吸信号作为输入，构建高效跨注意力Transformer模型，结合多窗口策略捕捉短期/长期特征与全局特性，提升模型表征能力。", "result": "实验表明呼吸信号是有效的疼痛评估生理模态；优化后的小模型性能优于大模型；多窗口策略成功提取多层次特征。", "conclusion": "呼吸信号与高效小模型的组合为疼痛评估提供了新思路，多窗口策略有效增强模型表现，该方法具有临床应用潜力。"}}
{"id": "2507.21899", "categories": ["cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.21899", "abs": "https://arxiv.org/abs/2507.21899", "authors": ["Malik Uzair Mehmood", "Shahid Hussain", "Wen Li Wang", "Muhammad Usama Malik"], "title": "LLM-based Content Classification Approach for GitHub Repositories by the README Files", "comment": "8 pages, 4 Figures", "summary": "GitHub is the world's most popular platform for storing, sharing, and\nmanaging code. Every GitHub repository has a README file associated with it.\nThe README files should contain project-related information as per the\nrecommendations of GitHub to support the usage and improvement of repositories.\nHowever, GitHub repository owners sometimes neglected these recommendations.\nThis prevents a GitHub repository from reaching its full potential. This\nresearch posits that the comprehensiveness of a GitHub repository's README file\nsignificantly influences its adoption and utilization, with a lack of detail\npotentially hindering its full potential for widespread engagement and impact\nwithin the research community. Large Language Models (LLMs) have shown great\nperformance in many text-based tasks including text classification, text\ngeneration, text summarization and text translation. In this study, an approach\nis developed to fine-tune LLMs for automatically classifying different sections\nof GitHub README files. Three encoder-only LLMs are utilized, including BERT,\nDistilBERT and RoBERTa. These pre-trained models are then fine-tuned based on a\ngold-standard dataset consisting of 4226 README file sections. This approach\noutperforms current state-of-the-art methods and has achieved an overall F1\nscore of 0.98. Moreover, we have also investigated the use of\nParameter-Efficient Fine-Tuning (PEFT) techniques like Low-Rank Adaptation\n(LoRA) and shown an economical alternative to full fine-tuning without\ncompromising much performance. The results demonstrate the potential of using\nLLMs in designing an automatic classifier for categorizing the content of\nGitHub README files. Consequently, this study contributes to the development of\nautomated tools for GitHub repositories to improve their identifications and\npotential usages.", "AI": {"tldr": "研究利用BERT、DistilBERT和RoBERTa等大语言模型(LLM)微调，开发了GitHub README文件自动分类方法，F1分数达0.98，并验证了参数高效微调技术(LoRA)的经济性。", "motivation": "GitHub仓库README文件的信息完整性显著影响项目采用率，但现有文件常不符合规范。研究旨在通过LLM自动分类提升README质量，从而增强仓库使用潜力。", "method": "基于4226个README章节的黄金数据集，对BERT、DistilBERT和RoBERTa进行微调，并采用LoRA等参数高效微调技术进行比较实验。", "result": "微调后的LLM分类器F1分数达0.98，优于现有方法；LoRA技术在保持性能的同时显著降低计算成本。", "conclusion": "该研究证明了LLM在自动化分类README内容上的有效性，为提升GitHub仓库可发现性和使用率提供了工具支持。"}}
{"id": "2507.21929", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21929", "abs": "https://arxiv.org/abs/2507.21929", "authors": ["Ziyang Chen", "Huimu Yu", "Xing Wu", "Dongqin Liu", "Songlin Hu"], "title": "Libra: Large Chinese-based Safeguard for AI Content", "comment": null, "summary": "Large language models (LLMs) excel in text understanding and generation but\nraise significant safety and ethical concerns in high-stakes applications. To\nmitigate these risks, we present Libra-Guard, a cutting-edge safeguard system\ndesigned to enhance the safety of Chinese-based LLMs. Leveraging a two-stage\ncurriculum training pipeline, Libra-Guard enhances data efficiency by employing\nguard pretraining on synthetic samples, followed by fine-tuning on\nhigh-quality, real-world data, thereby significantly reducing reliance on\nmanual annotations. To enable rigorous safety evaluations, we also introduce\nLibra-Test, the first benchmark specifically designed to evaluate the\neffectiveness of safeguard systems for Chinese content. It covers seven\ncritical harm scenarios and includes over 5,700 samples annotated by domain\nexperts. Experiments show that Libra-Guard achieves 86.79% accuracy,\noutperforming Qwen2.5-14B-Instruct (74.33%) and ShieldLM-Qwen-14B-Chat\n(65.69%), and nearing closed-source models like Claude-3.5-Sonnet and GPT-4o.\nThese contributions establish a robust framework for advancing the safety\ngovernance of Chinese LLMs and represent a tentative step toward developing\nsafer, more reliable Chinese AI systems.", "AI": {"tldr": "本文提出Libra-Guard安全防护系统及配套评测基准Libra-Test，通过两阶段训练显著提升中文大模型安全性，实验表明其性能超越主流开源模型并接近闭源顶级模型。", "motivation": "大语言模型在文本理解与生成方面表现优异，但在高风险应用中存在重大安全与伦理隐患，需开发针对中文内容的安全保障体系。", "method": "采用两阶段课程训练框架：先在合成样本上进行防护预训练，再用高质量真实数据微调；同时构建首个中文安全评测基准Libra-Test，涵盖7类危害场景与5700+专家标注样本。", "result": "Libra-Guard达到86.79%准确率，优于Qwen2.5-14B-Instruct（74.33%）和ShieldLM-Qwen-14B-Chat（65.69%），接近Claude-3.5-Sonnet和GPT-4o等闭源模型。", "conclusion": "该研究为中文大模型安全治理建立系统框架，是开发更安全可靠中文AI系统的重要探索。"}}
{"id": "2507.21964", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21964", "abs": "https://arxiv.org/abs/2507.21964", "authors": ["Sourish Gunesh Dhekane", "Thomas Ploetz"], "title": "Thou Shalt Not Prompt: Zero-Shot Human Activity Recognition in Smart Homes via Language Modeling of Sensor Data & Activities", "comment": null, "summary": "Developing zero-shot human activity recognition (HAR) methods is a critical\ndirection in smart home research -- considering its impact on making HAR\nsystems work across smart homes having diverse sensing modalities, layouts, and\nactivities of interest. The state-of-the-art solutions along this direction are\nbased on generating natural language descriptions of the sensor data and\nfeeding it via a carefully crafted prompt to the LLM to perform classification.\nDespite their performance guarantees, such ``prompt-the-LLM'' approaches carry\nseveral risks, including privacy invasion, reliance on an external service, and\ninconsistent predictions due to version changes, making a case for alternative\nzero-shot HAR methods that do not require prompting the LLMs. In this paper, we\npropose one such solution that models sensor data and activities using natural\nlanguage, leveraging its embeddings to perform zero-shot classification and\nthereby bypassing the need to prompt the LLMs for activity predictions. The\nimpact of our work lies in presenting a detailed case study on six datasets,\nhighlighting how language modeling can bolster HAR systems in zero-shot\nrecognition.", "AI": {"tldr": "本文提出了一种不依赖大型语言模型（LLM）的零样本人类活动识别（HAR）方法，通过自然语言嵌入实现分类，解决了现有方法中的隐私、依赖性和一致性等问题。", "motivation": "现有基于LLM的零样本HAR方法存在隐私侵犯、依赖外部服务及版本变更导致的预测不一致等问题，亟需不依赖LLM提示的替代方案。", "method": "该方法利用自然语言建模传感器数据和活动，通过其嵌入实现零样本分类，避免了直接调用LLM进行预测的需求。", "result": "在六个数据集上的详细案例研究表明，语言建模能有效增强零样本识别能力，验证了方法的可行性。", "conclusion": "研究证明了自然语言嵌入在零样本HAR中的潜力，为不依赖LLM的智能家居活动识别提供了新思路。"}}
{"id": "2507.21974", "categories": ["cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.21974", "abs": "https://arxiv.org/abs/2507.21974", "authors": ["Mohamed Sana", "Nicola Piovesan", "Antonio De Domenico", "Yibin Kang", "Haozhe Zhang", "Merouane Debbah", "Fadhel Ayed"], "title": "Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks", "comment": null, "summary": "Root Cause Analysis (RCA) in mobile networks remains a challenging task due\nto the need for interpretability, domain expertise, and causal reasoning. In\nthis work, we propose a lightweight framework that leverages Large Language\nModels (LLMs) for RCA. To do so, we introduce TeleLogs, a curated dataset of\nannotated troubleshooting problems designed to benchmark RCA capabilities. Our\nevaluation reveals that existing open-source reasoning LLMs struggle with these\nproblems, underscoring the need for domain-specific adaptation. To address this\nissue, we propose a two-stage training methodology that combines supervised\nfine-tuning with reinforcement learning to improve the accuracy and reasoning\nquality of LLMs. The proposed approach fine-tunes a series of RCA models to\nintegrate domain knowledge and generate structured, multi-step diagnostic\nexplanations, improving both interpretability and effectiveness. Extensive\nexperiments across multiple LLM sizes show significant performance gains over\nstate-of-the-art reasoning and non-reasoning models, including strong\ngeneralization to randomized test variants. These results demonstrate the\npromise of domain-adapted, reasoning-enhanced LLMs for practical and\nexplainable RCA in network operation and management.", "AI": {"tldr": "本文提出了一种轻量级框架，利用大语言模型（LLMs）进行移动网络中的根因分析（RCA），并通过两阶段训练方法提升模型的准确性和推理能力。", "motivation": "移动网络中的根因分析（RCA）因需可解释性、领域专业知识和因果推理而具有挑战性，现有开源推理LLMs在此类问题上表现不佳，亟需领域适配。", "method": "提出两阶段训练方法：先通过监督微调，再结合强化学习，以整合领域知识并生成结构化、多步骤的诊断解释，提升模型的可解释性和有效性。", "result": "实验表明，该方法在多种LLM规模上均显著优于现有推理和非推理模型，且在随机测试变体上表现出强泛化能力。", "conclusion": "领域适配和推理增强的LLMs在网络运维和管理中具有实际且可解释的RCA应用潜力。"}}
{"id": "2507.21976", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21976", "abs": "https://arxiv.org/abs/2507.21976", "authors": ["Tanvir Ahmed Khan", "Aranya Saha", "Ismam Nur Swapnil", "Mohammad Ariful Haque"], "title": "The Effect of Compression Techniques on Large Multimodal Language Models in the Medical Domain", "comment": "12 pages, 5 figures. tcolorbox dependencies were removed for arXiv\n  compatibility. All references are included via a precompiled .bbl file", "summary": "Multimodal Large Language Models (MLLMs) hold huge potential for usage in the\nmedical domain, but their computational costs necessitate efficient compression\ntechniques. This paper evaluates the impact of structural pruning and\nactivation-aware quantization on a fine-tuned LLAVA model for medical\napplications. We propose a novel layer selection method for pruning, analyze\ndifferent quantization techniques, and assess the performance trade-offs in a\nprune-SFT-quantize pipeline. Our proposed method enables MLLMs with 7B\nparameters to run within 4 GB of VRAM, reducing memory usage by 70% while\nachieving 4% higher model performance compared to traditional pruning and\nquantization techniques in the same compression ratio.", "AI": {"tldr": "本文提出了一种针对医疗领域多模态大语言模型(MLLM)的高效压缩方法，通过结构剪枝和激活感知量化技术，使70亿参数模型能在4GB显存下运行，显存占用降低70%且性能提升4%。", "motivation": "多模态大语言模型在医疗领域潜力巨大，但高昂计算成本需要高效压缩技术。本文旨在评估剪枝和量化对医疗定制化LLAVA模型的影响。", "method": "提出新型剪枝层选择方法，分析不同量化技术，并在剪枝-微调-量化流程中评估性能权衡。特别设计了prune-SFT-quantize压缩管线。", "result": "压缩后7B参数MLLM仅需4GB显存，显存使用减少70%，在相同压缩率下比传统方法性能提升4%。", "conclusion": "该方法显著降低了医疗MLLM的硬件需求，在保持模型性能的同时实现了高效压缩，为医疗领域部署提供了可行方案。"}}
{"id": "2507.22009", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22009", "abs": "https://arxiv.org/abs/2507.22009", "authors": ["Bahar İlgen", "Akshat Dubey", "Georges Hattab"], "title": "PHAX: A Structured Argumentation Framework for User-Centered Explainable AI in Public Health and Biomedical Sciences", "comment": "Preprint. Under review", "summary": "Ensuring transparency and trust in AI-driven public health and biomedical\nsciences systems requires more than accurate predictions-it demands\nexplanations that are clear, contextual, and socially accountable. While\nexplainable AI (XAI) has advanced in areas like feature attribution and model\ninterpretability, most methods still lack the structure and adaptability needed\nfor diverse health stakeholders, including clinicians, policymakers, and the\ngeneral public. We introduce PHAX-a Public Health Argumentation and\neXplainability framework-that leverages structured argumentation to generate\nhuman-centered explanations for AI outputs. PHAX is a multi-layer architecture\ncombining defeasible reasoning, adaptive natural language techniques, and user\nmodeling to produce context-aware, audience-specific justifications. More\nspecifically, we show how argumentation enhances explainability by supporting\nAI-driven decision-making, justifying recommendations, and enabling interactive\ndialogues across user types. We demonstrate the applicability of PHAX through\nuse cases such as medical term simplification, patient-clinician communication,\nand policy justification. In particular, we show how simplification decisions\ncan be modeled as argument chains and personalized based on user\nexpertise-enhancing both interpretability and trust. By aligning formal\nreasoning methods with communicative demands, PHAX contributes to a broader\nvision of transparent, human-centered AI in public health.", "AI": {"tldr": "本文提出PHAX框架，通过结构化论证生成面向公众健康领域AI系统的可解释性方案，结合可废止推理与自然语言技术，实现用户定制化的解释输出。", "motivation": "当前可解释AI（XAI）方法在公共卫生领域缺乏对多元利益相关者（如临床医生、政策制定者、公众）的适应性，需要建立兼具社会问责与情境化解释能力的框架。", "method": "开发多层架构PHAX框架，整合：1) 可废止推理构建论证链 2) 自适应自然语言生成技术 3) 用户建模，实现基于受众特征的动态解释生成。", "result": "案例验证显示PHAX能有效支持：医学术语简化、医患沟通优化、政策建议论证，通过论证链个性化提升不同专业背景用户的理解度与信任度。", "conclusion": "PHAX将形式化推理与沟通需求结合，推动了公共卫生领域透明化、以人为中心的AI系统发展，其论证方法为跨用户类型的交互式解释提供新范式。"}}
{"id": "2507.22025", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.22025", "abs": "https://arxiv.org/abs/2507.22025", "authors": ["Shuquan Lian", "Yuhang Wu", "Jia Ma", "Zihan Song", "Bingqi Chen", "Xiawu Zheng", "Hui Li"], "title": "UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding", "comment": null, "summary": "The emergence of Multimodal Large Language Models (MLLMs) has driven\nsignificant advances in Graphical User Interface (GUI) agent capabilities.\nNevertheless, existing GUI agent training and inference techniques still suffer\nfrom a dilemma for reasoning designs, ineffective reward, and visual noise. To\naddress these issues, we introduce UI-AGILE, a comprehensive framework\nenhancing GUI agents at both the training and inference stages. For training,\nwe propose a suite of improvements to the Supervised Fine-Tuning (SFT) process:\n1) a Continuous Reward function to incentivize high-precision grounding; 2) a\n\"Simple Thinking\" reward to balance planning with speed and grounding accuracy;\nand 3) a Cropping-based Resampling strategy to mitigate the sparse reward\nproblem and improve learning on complex tasks. For inference, we present\nDecomposed Grounding with Selection, a novel method that dramatically improves\ngrounding accuracy on high-resolution displays by breaking the image into\nsmaller, manageable parts. Experiments show that UI-AGILE achieves the\nstate-of-the-art performance on two benchmarks ScreenSpot-Pro and\nScreenSpot-v2. For instance, using both our proposed training and inference\nenhancement methods brings 23% grounding accuracy improvement over the best\nbaseline on ScreenSpot-Pro.", "AI": {"tldr": "Error processing this paper.", "motivation": "Error processing this paper.", "method": "Error processing this paper.", "result": "Error processing this paper.", "conclusion": "Error processing this paper."}}
{"id": "2507.22034", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22034", "abs": "https://arxiv.org/abs/2507.22034", "authors": ["Cheng Qian", "Zuxin Liu", "Akshara Prabhakar", "Zhiwei Liu", "Jianguo Zhang", "Haolin Chen", "Heng Ji", "Weiran Yao", "Shelby Heinecke", "Silvio Savarese", "Caiming Xiong", "Huan Wang"], "title": "UserBench: An Interactive Gym Environment for User-Centric Agents", "comment": "25 Pages, 17 Figures, 6 Tables", "summary": "Large Language Models (LLMs)-based agents have made impressive progress in\nreasoning and tool use, enabling them to solve complex tasks. However, their\nability to proactively collaborate with users, especially when goals are vague,\nevolving, or indirectly expressed, remains underexplored. To address this gap,\nwe introduce UserBench, a user-centric benchmark designed to evaluate agents in\nmulti-turn, preference-driven interactions. UserBench features simulated users\nwho start with underspecified goals and reveal preferences incrementally,\nrequiring agents to proactively clarify intent and make grounded decisions with\ntools. Our evaluation of leading open- and closed-source LLMs reveals a\nsignificant disconnect between task completion and user alignment. For\ninstance, models provide answers that fully align with all user intents only\n20% of the time on average, and even the most advanced models uncover fewer\nthan 30% of all user preferences through active interaction. These results\nhighlight the challenges of building agents that are not just capable task\nexecutors, but true collaborative partners. UserBench offers an interactive\nenvironment to measure and advance this critical capability.", "AI": {"tldr": "本文介绍了UserBench基准测试，用于评估大语言模型(LLM)代理在模糊目标场景下的用户协作能力，发现现有模型在用户意图对齐方面表现不佳。", "motivation": "尽管基于大语言模型(LLM)的代理在推理和工具使用方面取得显著进展，但其在目标模糊、动态变化或间接表达场景下与用户主动协作的能力尚未充分探索。", "method": "研究者开发了UserBench基准测试，通过模拟目标不明确的用户进行多轮交互，要求代理主动澄清意图并基于工具做出决策，以此评估模型的协作能力。", "result": "评估显示：模型输出完全符合用户意图的情况平均仅20%，即使最先进模型通过主动交互发现的用户偏好也不足30%，任务完成度与用户对齐存在显著差距。", "conclusion": "研究表明构建真正协作型代理仍面临挑战，UserBench为衡量和提升这一关键能力提供了交互式评估环境。"}}
{"id": "2507.22047", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22047", "abs": "https://arxiv.org/abs/2507.22047", "authors": ["Xiuwen Zheng", "Bornali Phukon", "Jonghwan Na", "Ed Cutrell", "Kyu Han", "Mark Hasegawa-Johnson", "Pan-Pan Jiang", "Aadhrik Kuila", "Colin Lea", "Bob MacDonald", "Gautam Mantena", "Venkatesh Ravichandran", "Leda Sari", "Katrin Tomanek", "Chang D. Yoo", "Chris Zwilling"], "title": "The Interspeech 2025 Speech Accessibility Project Challenge", "comment": "To appear in Proceedings of Interspeech, 2025", "summary": "While the last decade has witnessed significant advancements in Automatic\nSpeech Recognition (ASR) systems, performance of these systems for individuals\nwith speech disabilities remains inadequate, partly due to limited public\ntraining data. To bridge this gap, the 2025 Interspeech Speech Accessibility\nProject (SAP) Challenge was launched, utilizing over 400 hours of SAP data\ncollected and transcribed from more than 500 individuals with diverse speech\ndisabilities. Hosted on EvalAI and leveraging the remote evaluation pipeline,\nthe SAP Challenge evaluates submissions based on Word Error Rate and Semantic\nScore. Consequently, 12 out of 22 valid teams outperformed the whisper-large-v2\nbaseline in terms of WER, while 17 teams surpassed the baseline on SemScore.\nNotably, the top team achieved the lowest WER of 8.11\\%, and the highest\nSemScore of 88.44\\% at the same time, setting new benchmarks for future ASR\nsystems in recognizing impaired speech.", "AI": {"tldr": "2025年Interspeech语音无障碍项目挑战赛利用400多小时残障人士语音数据，12支团队在词错误率上超越whisper-large-v2基线，最佳团队同时创下8.11\\%最低WER和88.44\\%最高语义得分新纪录。", "motivation": "当前自动语音识别系统对残障人士的语音识别性能不足，主要因缺乏公开训练数据。", "method": "使用EvalAI平台和远程评估管道，基于500多名残障人士的400多小时转录数据，以词错误率和语义得分为评估标准。", "result": "22支有效参赛团队中，12支在WER上超越基线模型，17支在SemScore上表现更优；顶尖团队同时达到8.11\\% WER和88.44\\% SemScore。", "conclusion": "该挑战赛为残障语音识别设立了新基准，证明现有ASR系统在优化后能显著提升识别性能。"}}
