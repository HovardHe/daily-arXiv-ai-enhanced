<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 6]
- [math.OC](#math.OC) [Total: 9]
- [math.NT](#math.NT) [Total: 4]
- [math.LO](#math.LO) [Total: 3]
- [math.CO](#math.CO) [Total: 18]
- [cs.CR](#cs.CR) [Total: 11]
- [cs.AI](#cs.AI) [Total: 25]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Parametric convergence rate of some nonparametric estimators in mixtures of power series distributions](https://arxiv.org/abs/2508.00163)
*Fadoua Balabdaoui,Harald Besdziek,Yong Wang*

Main category: math.ST

TL;DR: 本文研究了无限支撑幂级数分布混合模型的非参数最大似然估计（NPMLE），证明了其在Hellinger距离下的收敛速率不低于$(\log n)^{3/2} n^{-1/2}$，并构建了基于NPMLE的非参数估计器，在$\ell_p$范数下达到参数速率$n^{-1/2}$。模拟和实际数据应用验证了估计器的性能。


<details>
  <summary>Details</summary>
Motivation: 研究幂级数分布（如泊松、几何、对数或负二项分布）混合模型的估计问题，旨在提出高效的估计方法并验证其理论性能。

Method: 采用非参数最大似然估计（NPMLE）方法，并构建加权最小二乘和混合估计器，通过模拟和实际数据评估其性能，同时比较非参数和参数自举法的置信区间构建效果。

Result: NPMLE在Hellinger、$\ell_1$和$\ell_2$距离下表现最佳，收敛速率为$(\log n)^{3/2} n^{-1/2}$；加权最小二乘和混合估计器在$\ell_p$范数下达到$n^{-1/2}$的收敛速率。

Conclusion: NPMLE在多种距离度量下表现最优，理论结果通过模拟和实际数据得到验证，为非参数混合模型估计提供了有效工具。

Abstract: We consider the problem of estimating a mixture of power series distributions
with infinite support, to which belong very well-known models such as Poisson,
Geometric, Logarithmic or Negative Binomial probability mass functions. We
consider the nonparametric maximum likelihood estimator (NPMLE) and show that,
under very mild assumptions, it converges to the true mixture distribution
$\pi_0$ at a rate no slower than $(\log n)^{3/2} n^{-1/2}$ in the Hellinger
distance. Recent work on minimax lower bounds suggests that the logarithmic
factor in the obtained Hellinger rate of convergence can not be improved, at
least for mixtures of Poisson distributions. Furthermore, we construct
nonparametric estimators that are based on the NPMLE and show that they
converge to $\pi_0$ at the parametric rate $n^{-1/2}$ in the $\ell_p$-norm ($p
\in [1, \infty]$ or $p \in [2, \infty])$: The weighted least squares and hybrid
estimators. Simulations and a real data application are considered to assess
the performance of all estimators we study in this paper and illustrate the
practical aspect of the theory. The simulations results show that the NPMLE has
the best performance in the Hellinger, $\ell_1$ and $\ell_2$ distances in all
scenarios. Finally, to construct confidence intervals of the true mixture
probability mass function, both the nonparametric and parametric bootstrap
procedures are considered. Their performances are compared with respect to the
coverage and length of the resulting intervals.

</details>


### [2] [Structural Causal Models for Extremes: an Approach Based on Exponent Measures](https://arxiv.org/abs/2508.00223)
*Fei Fang,Shuyang Bai,Tiandong Wang*

Main category: math.ST

TL;DR: 本文提出了一种新的极值结构因果模型（eSCM），使用指数测度替代传统概率分布，通过激活变量抽象单一大跳跃原则，并展示了在自然假设下因果方向的可识别性。


<details>
  <summary>Details</summary>
Motivation: 传统结构因果模型在处理极值问题时存在局限性，需要一种能够自然描述多元极值分析的新框架。

Method: 引入极值结构因果模型（eSCM），利用指数测度和激活变量，结合随机化扩展模型类别，并通过因果不对称性实现方向识别。

Result: eSCM框架涵盖了所有可能的极值条件独立有向图模型，并在模拟和真实数据集中验证了其因果不对称性方法的有效性。

Conclusion: eSCM为极值因果推理提供了新工具，其内在不对称性解决了因果方向识别的核心挑战，具有理论和实践意义。

Abstract: We introduce a new formulation of structural causal models for extremes,
called the extremal structural causal model (eSCM). Unlike conventional
structural causal models, where randomness is governed by a probability
distribution, eSCMs use an exponent measure--an infinite-mass law that
naturally arises in the analysis of multivariate extremes. Central to this
framework are activation variables, which abstract the single-big-jump
principle, along with additional randomization that enriches the class of eSCM
laws. This formulation encompasses all possible laws of directed graphical
models under the recently introduced notion of extremal conditional
independence. We also identify an inherent asymmetry in eSCMs under natural
assumptions, enabling the identifiability of causal directions, a central
challenge in causal inference. Finally, we propose a method that utilizes this
causal asymmetry and demonstrate its effectiveness in both simulated and real
datasets.

</details>


### [3] [Predictive information criterion for jump diffusion processes](https://arxiv.org/abs/2508.00411)
*Yuma Uehara*

Main category: math.ST

TL;DR: 本文针对基于高频采样的遍历跳跃扩散过程，提出了一种模型选择方法，推导了Akaike型信息准则，并给出了跳跃扩散过程转移密度的新估计。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决高频采样下遍历跳跃扩散过程的模型选择问题，通过评估真实对数似然函数来优化模型选择。

Method: 通过推导期望真实对数似然函数，建立Akaike型信息准则，并在过程中提出了跳跃扩散过程转移密度的新估计方法。

Result: 成功推导出适用于高频采样数据的Akaike型信息准则，并提供了跳跃扩散过程转移密度的新估计结果。

Conclusion: 该方法为高频数据下的跳跃扩散过程模型选择提供了有效工具，同时新的转移密度估计有助于提升模型精度。

Abstract: In this paper, we address a model selection problem for ergodic jump
diffusion processes based on high-frequency samples. We evaluate the expected
genuine log-likelihood function and derive an Akaike-type information
criterion. In the derivation process, we also give new estimates of the
transition density of jump diffusion processes.

</details>


### [4] [Constructive Disintegration and Conditional Modes](https://arxiv.org/abs/2508.00617)
*Nathaël Da Costa,Marvin Pförtner,Jon Cockayne*

Main category: math.ST

TL;DR: 本文探讨了贝叶斯统计中的条件化操作，通过测度分解理论揭示了传统密度函数限制方法的局限性，并提出了构建分解密度的数学工具。通过微分流形上的实例，展示了限制密度与分解密度的显著差异，并分析了条件众数概念在近似贝叶斯推断中的实际影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于贝叶斯统计中条件化操作（测度分解）的构造困难。传统机器学习方法将分解构造简化为概率密度函数在观测事件上的限制，但这种方法存在理论缺陷，需建立严谨的数学框架来正确处理测度分解。

Method: 提出了一套完整的数学工具集用于构造测度分解，重点研究了微分流形上分解密度的求解方法。通过构造反例对比限制密度与分解密度，并分析了条件众数与传统众数概念的差异。

Result: 关键发现包括：(1) 限制密度与分解密度在特定情况下存在显著差异；(2) 现有文献中的"条件众数"实际对应限制测度的众数，而非分解测度的众数；(3) 两种测度在实际建模中各有适用场景。

Conclusion: 结论强调：在近似贝叶斯推断和逆问题中，必须明确区分限制测度与分解测度。虽然两种方法均有实用价值，但选择应取决于具体建模需求，这为贝叶斯计算方法提供了重要的理论指导。

Abstract: Conditioning, the central operation in Bayesian statistics, is formalised by
the notion of disintegration of measures. However, due to the implicit nature
of their definition, constructing disintegrations is often difficult. A
folklore result in machine learning conflates the construction of a
disintegration with the restriction of probability density functions onto the
subset of events that are consistent with a given observation. We provide a
comprehensive set of mathematical tools which can be used to construct
disintegrations and apply these to find densities of disintegrations on
differentiable manifolds. Using our results, we provide a disturbingly simple
example in which the restricted density and the disintegration density
drastically disagree. Motivated by applications in approximate Bayesian
inference and Bayesian inverse problems, we further study the modes of
disintegrations. We show that the recently introduced notion of a "conditional
mode" does not coincide in general with the modes of the conditional measure
obtained through disintegration, but rather the modes of the restricted
measure. We also discuss the implications of the discrepancy between the two
measures in practice, advocating for the utility of both approaches depending
on the modelling context.

</details>


### [5] [On admissibility in post-hoc hypothesis testing](https://arxiv.org/abs/2508.00770)
*Ben Chugg,Tyron Lardy,Aaditya Ramdas,Peter Grünwald*

Main category: math.ST

TL;DR: 本文提出了一种事后假设检验理论，允许在分析数据后选择显著性水平$\alpha$，解决了传统假设检验中$\alpha$必须预先固定的限制。


<details>
  <summary>Details</summary>
Motivation: 传统假设检验要求显著性水平$\alpha$在统计分析前固定，这限制了根据实验过程中对假阳性成本的考量或数据证据强度调整$\alpha$的灵活性。

Method: 引入$\Gamma$-可容许性概念，定义了一组将数据映射到显著性水平的对抗者$\Gamma$，检验若在$\Gamma$中所有对抗者下表现最优则为可容许。

Result: 证明了对于点零假设和备择假设，任何$\Gamma$-可容许检验必须基于e值，并对不同$\Gamma$分类了可容许检验集。

Conclusion: 事后假设检验理论通过允许$\alpha$的事后选择，为统计决策提供了更灵活的框架，且可容许检验需基于e值。

Abstract: The validity of classical hypothesis testing requires the significance level
$\alpha$ be fixed before any statistical analysis takes place. This is a
stringent requirement. For instance, it prohibits updating $\alpha$ during (or
after) an experiment due to changing concern about the cost of false positives,
or to reflect unexpectedly strong evidence against the null. Perhaps most
disturbingly, witnessing a p-value $p\ll\alpha$ vs $p\leq \alpha$ has no
(statistical) relevance for any downstream decision-making. Following recent
work of Gr\"unwald (2024), we develop a theory of post-hoc hypothesis testing,
enabling $\alpha$ to be chosen after seeing and analyzing the data. To study
"good" post-hoc tests we introduce $\Gamma$-admissibility, where $\Gamma$ is a
set of adversaries which map the data to a significance level. A test is
$\Gamma$-admissible if, roughly speaking, there is no other test which performs
at least as well and sometimes better across all adversaries in $\Gamma$. For
point nulls and alternatives, we prove general properties of any
$\Gamma$-admissible test for any $\Gamma$ and show that they must be based on
e-values. We also classify the set of admissible tests for various specific
$\Gamma$.

</details>


### [6] [Local Poisson Deconvolution for Discrete Signals](https://arxiv.org/abs/2508.00824)
*Shayan Hundrieser,Tudor Manole,Danila Litskevich,Axel Munk*

Main category: math.ST

TL;DR: 本文研究了从泊松卷积模型中恢复原子信号（离散均匀分布$\mu$）的统计问题，通过局部极小极大风险分析，量化了不同信号结构的估计速率，并在超分辨率显微镜数据中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于超分辨率激光显微镜应用，精确估计$\mu$有助于理解细胞蛋白质组装的空间结构，同时为泊松去卷积和高斯混合模型参数估计提供理论支持。

Method: 采用局部极小极大风险框架，分析平滑卷积核下原子信号的估计问题，使用多尺度损失函数评估不同局部几何结构的恢复速率。

Result: 结果表明，信号的局部几何结构决定了其可恢复速率，且泊松去卷积问题在更广泛的信号类别中可实现准确恢复。数值实验验证了估计器的实际性能与计算权衡。

Conclusion: 研究为泊松去卷积问题提供了乐观的理论前景，证明现有全局极小极大分析未涵盖的信号类别仍可实现准确恢复，并在DNA折纸实验数据中展示了应用价值。

Abstract: We analyze the statistical problem of recovering an atomic signal, modeled as
a discrete uniform distribution $\mu$, from a binned Poisson convolution model.
This question is motivated, among others, by super-resolution laser microscopy
applications, where precise estimation of $\mu$ provides insights into spatial
formations of cellular protein assemblies. Our main results quantify the local
minimax risk of estimating $\mu$ for a broad class of smooth convolution
kernels. This local perspective enables us to sharply quantify optimal
estimation rates as a function of the clustering structure of the underlying
signal. Moreover, our results are expressed under a multiscale loss function,
which reveals that different parts of the underlying signal can be recovered at
different rates depending on their local geometry. Overall, these results paint
an optimistic perspective on the Poisson deconvolution problem, showing that
accurate recovery is achievable under a much broader class of signals than
suggested by existing global minimax analyses. Beyond Poisson deconvolution,
our results also allow us to establish the local minimax rate of parameter
estimation in Gaussian mixture models with uniform weights.
  We apply our methods to experimental super-resolution microscopy data to
identify the location and configuration of individual DNA origamis. In
addition, we complement our findings with numerical experiments on runtime and
statistical recovery that showcase the practical performance of our estimators
and their trade-offs.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [7] [Riemannian Optimization for Distance Geometry: A Study of Convergence, Robustness, and Incoherence](https://arxiv.org/abs/2508.00091)
*Chandler Smith,HanQin Cai,Abiy Tasissa*

Main category: math.OC

TL;DR: 本文提出一种黎曼优化框架，通过将欧氏距离几何问题转化为半正定Gram矩阵的低秩补全任务，在非正交基中编码距离测量，并证明在伯努利采样模型下，黎曼梯度下降能实现局部线性收敛。


<details>
  <summary>Details</summary>
Motivation: 欧氏距离几何问题在传感器网络定位、分子构象和流形学习等领域有广泛应用，但现有方法在采样效率和收敛性上存在局限，需要更高效的解决方案。

Method: 将问题建模为半正定Gram矩阵的低秩补全，利用非正交基编码距离测量，通过黎曼优化在秩$r$矩阵流形上执行梯度下降，并采用一步硬阈值初始化策略。

Result: 理论证明当采样概率$p \geq \mathcal{O}(\nu^2 r^2 \log(n)/n)$时算法局部线性收敛，且初始化策略在$p \geq \mathcal{O}(\nu r^{3/2} \log^{3/4}(n)/n^{1/4})$时有效。实验显示其性能优于现有方法。

Conclusion: 该框架通过创新的非正交基对偶算子分析和EDG专用非相干性概念，为距离几何问题提供了高效且理论保障的解决方案，具有实际应用潜力。

Abstract: The problem of recovering a configuration of points from partial pairwise
distances, referred to as the Euclidean Distance Geometry (EDG) problem, arises
in a broad range of applications, including sensor network localization,
molecular conformation, and manifold learning. In this paper, we propose a
Riemannian optimization framework for solving the EDG problem by formulating it
as a low-rank matrix completion task over the space of positive semi-definite
Gram matrices. The available distance measurements are encoded as expansion
coefficients in a non-orthogonal basis, and optimization over the Gram matrix
implicitly enforces geometric consistency through the triangle inequality, a
structure inherited from classical multidimensional scaling. Under a Bernoulli
sampling model for observed distances, we prove that Riemannian gradient
descent on the manifold of rank-$r$ matrices locally converges linearly with
high probability when the sampling probability satisfies $p \geq
\mathcal{O}(\nu^2 r^2 \log(n)/n)$, where $\nu$ is an EDG-specific incoherence
parameter. Furthermore, we provide an initialization candidate using a one-step
hard thresholding procedure that yields convergence, provided the sampling
probability satisfies $p \geq \mathcal{O}(\nu r^{3/2} \log^{3/4}(n)/n^{1/4})$.
A key technical contribution of this work is the analysis of a symmetric linear
operator arising from a dual basis expansion in the non-orthogonal basis, which
requires a novel application of the Hanson--Wright inequality to establish an
optimal restricted isometry property in the presence of coupled terms.
Empirical evaluations on synthetic data demonstrate that our algorithm achieves
competitive performance relative to state-of-the-art methods. Moreover, we
propose a novel notion of matrix incoherence tailored to the EDG setting and
provide robustness guarantees for our method.

</details>


### [8] [Measuring leadership and productivity in an organisational structure](https://arxiv.org/abs/2508.00181)
*Ramón Flores,Elisenda Molina,Juan Tejada*

Main category: math.OC

TL;DR: 本文提出了一种基于有向图组织结构评估领导潜力与生产力的新方法框架，引入平均森林(AF)度量，通过蒙特卡洛模拟解决大规模网络计算问题。


<details>
  <summary>Details</summary>
Motivation: 研究旨在量化组织中有向图结构下的领导潜力与团队生产力，解决传统方法难以捕捉层级关系动态贡献的局限性。

Method: 将人员建模为节点、监督关系为有向边，利用可转移效用合作博弈理论，通过枚举最大生成森林定义AF度量，并提出蒙特卡洛估计算法。

Result: AF度量具有线性、组件可行性和单调性等理论性质，其值随有向图结构变化敏感，能识别最优领导者并揭示网络设计对绩效的影响。

Conclusion: 该框架为组织结构优化提供理论工具，证明网络拓扑与集体绩效的关联性，蒙特卡洛方法实现了大规模应用的可行性。

Abstract: This paper develops a novel methodological framework for assessing leadership
potential and productivity within organisational structure represented by
directed graphs. In this setting, individuals are modeled as nodes and
asymmetric supervisory or reporting relationships as directed edges. Leveraging
the theory of transferable utility cooperative games, we introduce the Average
Forest (AF) measure, a marginalist leadership measure grounded in the
enumeration of maximal spanning forests, where teams are hierarchically
structured as arborescences. The AF measure captures each agent`s expected
contribution across all feasible team configurations under the assumption of
superadditivity of the underlying game. We further define a measure of
organisational productivity as the expected aggregate value derived from these
configurations. The paper investigates key theoretical properties of the AF
measure -- such as linearity, component feasibility, and monotonicity -- and
analyzes its sensitivity to structural modifications in the underlying digraph.
To address computational challenges in large networks, a Monte Carlo simulation
algorithm is proposed for practical estimation. This framework enables the
identification of structurally optimal leaders and enhances understanding of
how network design impacts collective performance.

</details>


### [9] [Paratransit Optimization with Constraint Programming: A Case Study in Savannah, Georgia](https://arxiv.org/abs/2508.00241)
*Liam Jagrowski,Kevin Dalmeijer,Tinghan Ye,Pascal Van Hentenryck*

Main category: math.OC

TL;DR: 本文提出了一种用于优化辅助公交服务的约束编程模型，结合路径规划和班次调度，实际案例显示其优于现有方法且更易实施。


<details>
  <summary>Details</summary>
Motivation: 辅助公交服务对无法使用固定路线公交的人群（如残障人士）至关重要，优化服务可提升效率与质量。

Method: 采用约束编程模型联合优化辅助公交的路径规划与班次调度，并提供实际实施指南。

Result: 萨凡纳案例研究表明，新方法在服务请求量上显著优于现有方案（提升5%），且更易于实施。

Conclusion: 该模型为交通规划者提供了高效实用的解决方案，尤其在不限制班次整点开始时效果更佳。

Abstract: Paratransit services are vital for individuals who cannot use fixed-route
public transit, including those with disabilities. Optimizing these services is
essential for transit agencies to deliver high-quality service efficiently.
This paper introduces a constraint programming model to jointly optimize route
planning and shift scheduling for paratransit operations, along with practical
guidance for real-world implementation. A case study in Savannah, Georgia,
demonstrates that the new approach is competitive with the state of the art and
significantly increases the number of requests served compared to current
practices. It is also significantly easier to implement and provides an
inherently practical solution for transportation planners. An additional
advantage is that the model allows for optimizing shifts without restricting
start times to the top of the hour, yielding a further 5% improvement in
requests served when applied.

</details>


### [10] [Neighbor-Sampling Based Momentum Stochastic Methods for Training Graph Neural Networks](https://arxiv.org/abs/2508.00267)
*Molly Noel,Gabriel Mancino-Ball,Yangyang Xu*

Main category: math.OC

TL;DR: 本文提出几种基于邻居采样(NS)的Adam型随机方法用于训练非凸图卷积网络(GCN)，通过控制变量技术降低采样误差，理论证明其具有最优收敛率，实验表明在大规模图数据上优于传统NS-SGD方法。


<details>
  <summary>Details</summary>
Motivation: 现有GCN训练方法缺乏理论保证或未包含现代深度学习关键要素（如自适应性和动量），本文旨在解决这一问题。

Method: 结合邻居采样与控制变量技术[1]，设计Adam型随机优化方法，在标准假设下证明其收敛性。

Result: 在节点分类任务的多组基准数据集测试中，新方法显著优于采用相同控制变量技术的传统NS-SGD，尤其在大规模图数据上表现突出。

Conclusion: 所提出的Adam型GCN训练方法兼具理论保证与实践优势，代码已开源(https://github.com/RPI-OPT/CV-ADAM-GNN)。

Abstract: Graph convolutional networks (GCNs) are a powerful tool for graph
representation learning. Due to the recursive neighborhood aggregations
employed by GCNs, efficient training methods suffer from a lack of theoretical
guarantees or are missing important practical elements from modern deep
learning algorithms, such as adaptivity and momentum. In this paper, we present
several neighbor-sampling (NS) based Adam-type stochastic methods for solving a
nonconvex GCN training problem. We utilize the control variate technique
proposed by [1] to reduce the stochastic error caused by neighbor sampling.
Under standard assumptions for Adam-type methods, we show that our methods
enjoy the optimal convergence rate. In addition, we conduct extensive numerical
experiments on node classification tasks with several benchmark datasets. The
results demonstrate superior performance of our methods over classic NS-based
SGD that also uses the control-variate technique, especially for large-scale
graph datasets. Our code is available at https://github.com/RPI-OPT/CV-ADAM-GNN .

</details>


### [11] [Deterministic Structure of Vertical Configurations in Minimal Picker Tours for Rectangular Warehouses](https://arxiv.org/abs/2508.00365)
*George Dunn,Elizabeth Stojanovski,Bishnu Lamichhane,Hadi Charkhgard,Ali Eshragh*

Main category: math.OC

TL;DR: 本文提出了一种利用矩形仓库中最小路径子图的水平结构来确定垂直边的方法，从而减少动态规划算法的计算阶段。


<details>
  <summary>Details</summary>
Motivation: 解决拣货路径问题需要找到仓库中最短的拣货路径，传统方法计算复杂度高，尤其在多区块仓库中。

Method: 通过分析矩形仓库中最小路径子图的水平结构，推导出所需垂直边，简化动态规划算法的阶段数。

Result: 该方法显著降低了单区块或双区块仓库中动态规划算法的计算复杂度。

Conclusion: 利用水平结构确定垂直边的方法为拣货路径优化提供了新的思路，尤其适用于简单结构的仓库。

Abstract: The picker routing problem involves finding the shortest length tour of a
warehouse that collects all items in a given pick-list. In this work, we
demonstrate that in a rectangular warehouse, the horizontal structure of a
minimal tour subgraph can be used to determine the required vertical edges.
This result directly reduces the number of stages in the dynamic programming
algorithm for warehouses with one or two blocks.

</details>


### [12] [A linesearch-based derivative-free method for noisy black-box problems](https://arxiv.org/abs/2508.00495)
*Alberto De Santis,Giampaolo Liuzzi,Stefano Lucidi*

Main category: math.OC

TL;DR: 本文提出了一种基于外推技术的无导数算法，用于解决通过零阶随机Oracle估计目标函数的无约束优化问题，并证明了算法的收敛性和最坏情况复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究无约束优化问题，其中目标函数通过零阶随机Oracle进行估计，需要开发高效的无导数算法来解决此类问题。

Method: 提出了一种基于外推技术的无导数算法，并在合理假设下分析了其收敛性。

Result: 证明了算法的收敛性，并给出了最坏情况复杂度结果：期望梯度范数超过预设$\epsilon>0$的迭代次数为${\cal O}(n^2\epsilon^{-2}/\beta^2)$。

Conclusion: 所提出的无导数算法在理论上具有收敛性和可接受的最坏情况复杂度，适用于通过零阶Oracle估计目标函数的优化问题。

Abstract: In this work we consider unconstrained optimization problems. The objective
function is known through a zeroth order stochastic oracle that gives an
estimate of the true objective function. To solve these problems, we propose a
derivative-free algorithm based on extrapolation techniques. Under reasonable
assumptions we are able to prove convergence properties for the proposed
algorithms. Furthermore, we also give a worst-case complexity result stating
that the total number of iterations where the expected value of the norm of the
objective function gradient is above a prefixed $\epsilon>0$ is ${\cal
O}(n^2\epsilon^{-2}/\beta^2)$ in the worst case.

</details>


### [13] [A Distributionally Robust Optimization Approach to Quick Response Models under Demand Uncertainty](https://arxiv.org/abs/2508.00541)
*Panayotis P. Papavassilopoulos,Grani A. Hanasusanto,Yijie Wang*

Main category: math.OC

TL;DR: 研究提出了一种考虑需求不确定性的稳健快速响应模型，通过整合废弃物约束，在提升利润的同时减少系统总浪费，解决了快速响应策略的环境悖论问题。


<details>
  <summary>Details</summary>
Motivation: 快速响应策略虽能减少成品浪费，但可能增加原材料采购导致总浪费上升。现有模型依赖已知需求分布假设，而实际需求模式复杂且数据稀缺，亟需数据驱动的决策框架。

Method: 开发了分布鲁棒的快速响应模型应对需求不确定性，并引入废弃物-消耗比约束以显式控制环境影响，构建了数据驱动的稳健策略。

Result: 数值实验表明：传统策略在需求变化时性能急剧下降，而DRO方法在不同需求分布下均表现优异；约束模型能同时实现更高利润和更少总浪费，解决了核心悖论。

Conclusion: 研究证明快速响应的关键不在于是否采用，而在于如何管理。通过纳入社会责任指标约束，可实现盈利与环保的\"双赢\"。

Abstract: Problem definition: Quick response, a strategy widely adopted to mitigate
overproduction in the retail industry, is now at the center of a critical
debate. Recent research reveals a counter-intuitive paradox: while quick
response systems reduce waste from unsold finished goods, they may incentivize
firms to procure more raw materials, potentially increasing total system waste.
Additionally, existing models that guide quick response strategies rely on the
assumption of a known demand distribution. In practice, demand patterns are
complex and ambiguous, and historical data is often scarce, leaving managers
without a reliable framework to determine quick response policies under
data-driven settings. Methodology: We develop a distributionally robust quick
response model to address demand uncertainty, building policies that are robust
even with limited data. We further integrate a novel waste-to-consumption ratio
constraint into this framework, empowering firms to explicitly control the
environmental impact of quick response systems. Results: Numerical experiments
show that policies optimized for a specific demand assumption suffer severe
performance degradation when the real demand pattern changes even slightly. In
contrast, our data-driven DRO approach consistently delivers robust and
superior performance across a wide range of complex demand distributions.
Moreover, we find that the constrained quick response model resolves the
central paradox: it can achieve higher profits with verifiably less total waste
than a traditional, non-flexible alternative. Managerial implications: Our
research resolves the `quick response or not' debate by showing that the
question is not whether to use quick response, but how to manage it. By
incorporating socially responsible metrics as constraints, the quick response
system delivers a `win-win' outcome for both profitability and the environment.

</details>


### [14] [On the controllability of the Kuramoto-Sivashinsky equation on multi-dimensional cylindrical domains](https://arxiv.org/abs/2508.00812)
*Víctor Hernández-Santamaría,Subrata Majumdar*

Main category: math.OC

TL;DR: 本文研究了圆柱域上Kuramoto-Sivashinsky (KS)方程的零能控性，通过边界和内部控制实现了线性系统的零能控，并探讨了非线性系统的局部零能控性。


<details>
  <summary>Details</summary>
Motivation: 研究圆柱域$\Omega=\Omega_x\times \Omega_y$上KS方程的零能控性，旨在通过控制作用实现系统状态的精确调控，为偏微分方程控制理论提供新见解。

Method: 结合矩量法和Lebeau-Robbiano策略证明线性系统的零能控性；利用源项方法和Banach不动点定理处理非线性系统的局部零能控性。

Result: 给出了线性系统零能控的充要条件及显式控制成本估计；证明了存在最小时间$T_0(x_0)$使得系统在$T>T_0(x_0)$时可控；当$x_0/a$为$d>1$阶代数实数时，系统在任意$T>0$下可控；对$N=2$或$3$的情形，建立了非线性系统的局部零能控性。

Conclusion: 该研究系统分析了KS方程在圆柱域上的零能控性质，为高维非线性系统的控制提供了理论框架和方法支撑。

Abstract: In this article, we investigate null controllability of the
Kuramoto-Sivashinsky (KS) equation on a cylindrical domain
$\Omega=\Omega_x\times \Omega_y$ in $\mathbb R^N$, where $\Omega_x=(0,a),$
$a>0$ and $\Omega_y$ is a smooth domain in $\mathbb R^{N-1}$. We first study
the controllability of this system by a control acting on $\{0\}\times \omega$,
$\omega\subset \Omega_y$, through the boundary term associated with the
Laplacian component. The null controllability of the linearized system is
proved using a combination of two techniques: the method of moments and
Lebeau-Robbiano strategy. We provide a necessary and sufficient condition for
the null controllability of this system along with an explicit control cost
estimate. Furthermore, we show that there exists minimal time $T_0(x_0)>0$ such
that the system is null controllable for all time $T > T_0(x_0)$ by means of an
interior control exerted on $\gamma = \{x_0\} \times \omega \subset \Omega$,
where $x_0/a\in (0,1)\setminus \mathbb{Q}$ and it is not controllable if
$T<T_0(x_0).$
  If we assume $x_0/a$ is an algebraic real number of order $d > 1$, then we
prove the controllability for any time $T>0.$
  Finally, for the case of $N=2 \text{ or } 3$, we show the local null
controllability of the main nonlinear system by employing the source term
method followed by the Banach fixed point theorem.

</details>


### [15] [Efficient Solving of Large Single Input Superstate Decomposable Markovian Decision Process](https://arxiv.org/abs/2508.00816)
*Youssef Ait El Mahjoub,Jean-Michel Fourneau,Salma Alouah*

Main category: math.OC

TL;DR: 本文提出了一种新型的单输入超状态可分解马尔可夫决策过程（SISDMDP），结合Chiu的单输入分解与Robertazzi的单循环递归特性，为大规模状态空间的策略评估提供了高效精确的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统马尔可夫决策过程（MDP）在无限时域（如平均奖励或折扣奖励）的策略评估中存在计算复杂度高的问题，需要利用结构分解技术降低复杂度。

Method: 通过定义SISDMDP模型，将策略诱导的转移图分解为具有集中递归特性的交互组件，并基于此结构开发了精确的策略评估方法。

Result: 该方法可扩展应用于平均奖励和折扣奖励MDP，显著提升了大规模状态空间下的计算效率。

Conclusion: SISDMDP框架为结构化MDP提供了一种可扩展的精确求解方法，解决了长期优化中的计算瓶颈问题。

Abstract: Solving Markov Decision Processes (MDPs) remains a central challenge in
sequential decision-making, especially when dealing with large state spaces and
long-term optimization criteria. A key step in Bellman dynamic programming
algorithms is the policy evaluation, which becomes computationally demanding in
infinite-horizon settings such as average-reward or discounted-reward
formulations. In the context of Markov chains, aggregation and disaggregation
techniques have for a long time been used to reduce complexity by exploiting
structural decompositions. In this work, we extend these principles to a
structured class of MDPs. We define the Single-Input Superstate Decomposable
Markov Decision Process (SISDMDP), which combines Chiu's single-input
decomposition with Robertazzi's single-cycle recurrence property. When a policy
induces this structure, the resulting transition graph can be decomposed into
interacting components with centralized recurrence. We develop an exact and
efficient policy evaluation method based on this structure. This yields a
scalable solution applicable to both average and discounted reward MDPs.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [16] [Finite index theorems for iterated Galois groups of preperiodic points for unicritical polynomials](https://arxiv.org/abs/2508.00266)
*Minsik Han,Thomas J. Tucker*

Main category: math.NT

TL;DR: 本文证明了对于特定多项式f(x) = x^q + c，当b在数域K中严格预周期时，关于f在b处的迭代伽罗瓦群在f的通用迭代伽罗瓦群中具有有限指数。


<details>
  <summary>Details</summary>
Motivation: 研究多项式迭代的伽罗瓦群结构，特别是非后临界有限多项式在预周期点上的性质，以深化对动力系统与数论交叉领域的理解。

Method: 通过分析数域K上多项式f(x) = x^q + c的迭代行为，结合伽罗瓦群理论，研究严格预周期点b的迭代伽罗瓦群与通用迭代伽罗瓦群的关系。

Result: 证明了对于非后临界有限的f，任何严格预周期的b∈K，其迭代伽罗瓦群在f的通用迭代伽罗瓦群中具有有限指数。

Conclusion: 该结果为多项式迭代的伽罗瓦表示理论提供了新的结构性定理，揭示了预周期点在迭代动力系统中的特殊代数性质。

Abstract: Let K be a number field and let f(x) = x^q + c where q is a prime power, c is
in K, and f is not post-critically finite. We show that for any strictly
preperiodic b in K, the iterated Galois group at b with respect to f has finite
index in the generic iterated Galois group for f.

</details>


### [17] [Streamlined WZ method proofs of Van Hamme supercongruences](https://arxiv.org/abs/2508.00343)
*Andres Valloud*

Main category: math.NT

TL;DR: 本文提出了一种寻找WZ配对的方法，用于证明Van Hamme超同余式，并通过结合Long和Ramakrishna的$p$-adic近似方法，统一证明了多个超同余式。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过WZ方法有效证明Van Hamme超同余式，解决寻找合适WZ配对的难题。

Method: 提出一种寻找WZ配对候选的流程，结合$\Gamma_p$的$p$-adic近似方法，用于证明超同余式。

Result: 成功统一证明了Van Hamme超同余式B.2至H.2，并扩展了G.2模$p^4$和H.2模$p^3$的结果。此外，展示了I.2超同余式是Gosper算法的特例。

Conclusion: 该方法不仅简化了超同余式的证明过程，还扩展了已知结果，为未来研究提供了新的工具和视角。

Abstract: Using the WZ method to prove supercongruences critically depends on an
inspired WZ pair choice. This paper demonstrates a procedure for finding WZ
pair candidates to prove a given supercongruence. When suitable WZ pairs are
thus obtained, coupling them with the $p$-adic approximation of $\Gamma_p$ by
Long and Ramakrishna enables uniform proofs for the Van Hamme supercongruences
B.2, C.2, D.2, E.2, F.2, G.2, and H.2. This approach also yields the known
extensions of G.2 modulo $p^4$, and of H.2 modulo $p^3$ when $p$ is $3$ modulo
$4$. Finally, the Van Hamme supercongruence I.2 is shown to be a special case
of the WZ method where Gosper's algorithm itself succeeds.

</details>


### [18] [On Buck's measurability of certain sets](https://arxiv.org/abs/2508.00538)
*Milan Pasteka*

Main category: math.NT

TL;DR: 论文第一部分构建了Buck可测集，第二部分应用Niven定理研究了这些集的Buck测度密度。


<details>
  <summary>Details</summary>
Motivation: 研究Buck可测集的构造及其测度密度性质，以扩展对特殊测度理论的理解。

Method: 第一部分采用构造法建立Buck可测集，第二部分运用Niven定理分析测度密度。

Result: 成功构建了特定类型的Buck可测集，并通过Niven定理获得了其测度密度的相关结果。

Conclusion: 该研究为Buck测度理论提供了新的实例和性质分析，具有理论意义。

Abstract: In the first part we construct some Buck measurable sets. In the second part
we apply the Niven theorem for Buck's measure density to certain sets.

</details>


### [19] [A New Class of Linear Relations for Scalar Partitions](https://arxiv.org/abs/2508.00677)
*Boris Y. Rubinstein*

Main category: math.NT

TL;DR: 本文提出了一种推导标量整数分割线性关系的算法，基于Cayley定理通过变量消减将双重分割转化为标量分割之和。


<details>
  <summary>Details</summary>
Motivation: 研究标量整数分割问题，旨在解决具有正整数系数的线性Diophantine方程的非负整数解数量问题。

Method: 采用Cayley定理，通过变量消减程序将双重分割问题转化为有限数量标量分割的线性关系。

Result: 算法成功推导出涉及有限数量标量分割的线性关系，验证了方法的有效性。

Conclusion: 该算法为标量整数分割问题提供了新的解决途径，扩展了分割理论的应用范围。

Abstract: A scalar integer partition problem asks for a number of nonnegative integer
solutions to a linear Diophantine equation with integer positive coefficients.
The manuscript discusses an algorithm of derivation of linear relations
involving the finite number of scalar partitions. The algorithm employs the
Cayley theorem about the reduction of a double partition to a sum of scalar
partitions based on the variable elimination procedure.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [20] [A Counterexample Regarding C.E. Closed Subsets of [0,1] Under Homeomorphisms](https://arxiv.org/abs/2508.00166)
*Volker Bosserhoff*

Main category: math.LO

TL;DR: 本文构造了一个可计算枚举但不与任何可计算紧空间同胚的闭集，解决了Koh等人的问题。


<details>
  <summary>Details</summary>
Motivation: 回答Koh、Melnikov和Ng提出的关于可计算枚举闭集与可计算紧空间同胚性的问题。

Method: 通过构造一个具体的可计算枚举闭集，并证明其不具备可计算紧空间的同胚性质。

Result: 成功构建了一个在[0,1]区间内的可计算枚举闭集，该集合不与任何可计算紧空间同胚。

Conclusion: 该结果填补了可计算拓扑学中的一个理论空白，为相关领域提供了新的反例。

Abstract: We give an example of a computably enumerable closed subset of [0,1] that is
not homeomorphic to any computably compact space. This answers a question of
Koh, Melnikov and Ng.

</details>


### [21] [Proof complexity of Mal'tsev CSP](https://arxiv.org/abs/2508.00396)
*Azza Gaysin*

Main category: math.LO

TL;DR: 本文研究了Mal'tsev约束满足问题(CSPs)的多项式时间算法，并在有界算术$V^1$中形式化了该算法，证明了其正确性。同时，将类似结果推广到Dalmau的广义多数-少数CSPs算法。


<details>
  <summary>Details</summary>
Motivation: 约束满足问题(CSPs)是组合问题的重要类别，其复杂性已被二分法定理分类。研究Mal'tsev CSPs的多项式时间算法及其在有界算术中的形式化，有助于理解多项式时间可解问题的证明复杂性。

Method: 作者在$V^1$有界算术系统中形式化了Bulatov和Dalmau提出的Mal'tsev CSPs多项式时间算法，并证明了算法的正确性。类似方法也应用于Dalmau的广义多数-少数CSPs算法。

Result: 研究证明$V^1$能够验证Mal'tsev算法的正确性，这意味着不可满足的Mal'tsev CSP实例对应的命题重言式存在短的扩展Frege证明。类似结果也适用于广义多数-少数CSPs。

Conclusion: 该工作不仅为Mal'tsev CSPs提供了形式化的多项式时间算法验证，还将结果推广到更广泛的广义多数-少数CSPs类，深化了对多项式时间可解CSPs证明复杂性的理解。

Abstract: Constraint Satisfaction Problems (CSPs) form a broad class of combinatorial
problems, which can be formulated as homomorphism problems between relational
structures. The CSP dichotomy theorem classifies all such problems over finite
domains into two categories: NP-complete and polynomial-time, see Zhuk (2017),
Bulatov (2017). Polynomial-time CSPs can be further subdivided into smaller
subclasses. Mal'tsev CSPs are defined by the property that every relation in
the problem is invariant under a Mal'tsev operation, a ternary operation $\mu$
satisfying $\mu(x, y, y) = \mu(y, y, x) = x$ for all $x, y$. Bulatov and Dalmau
proved that Mal'tsev CSPs are solvable in polynomial time, presenting an
algorithm for such CSPs (2006). The negation of an unsatisfiable CSP instance
can be expressed as a propositional tautology. We formalize the algorithm for
Mal'tsev CSPs within bounded arithmetic $V^1$, which captures polynomial-time
reasoning and corresponds to the extended Frege proof system. We show that
$V^1$ proves the soundness of Mal'tsev algorithm, implying that tautologies
expressing the non-existence of a solution for unsatisfiable instances of
Mal'tsev CSPs admit short extended Frege proofs. In addition, with small
adjustments, we achieved an analogous result for Dalmau's algorithm that solves
generalized majority-minority CSPs -- a common generalization of near-unanimity
operations and Mal'tsev operations.

</details>


### [22] [On the regularity of almost stable relations](https://arxiv.org/abs/2508.00511)
*Marcos Girón*

Main category: math.LO

TL;DR: 本文构建了一个关于理想条件下局部稳定性的通用理论，证明了几乎稳定公式的平稳性原理，并建立了有限Cantor-Bendixson秩的偏类型拓扑空间。通过该空间与Keisler测度及可定义群的交互，推导出无限图的正则性引理和可定义稳定子群的存在性，最终应用于有限群中几乎稳定关系的算术正则性引理。


<details>
  <summary>Details</summary>
Motivation: 研究理想条件下（如零测集）的局部稳定性理论，旨在扩展模型论工具在无限图与可定义群中的应用，解决几乎稳定关系的结构性问题。

Method: 结合模型论方法，证明几乎稳定公式的平稳性原理，构建有限Cantor-Bendixson秩的偏类型拓扑空间，并通过与Keisler测度、可定义群的交互分析稳定性。

Result: 1. 获得无限图中几乎稳定边关系的正则性引理；2. 证明可定义稳定子群的存在性；3. 推导出有限群中几乎稳定关系的算术正则性引理。

Conclusion: 该理论为几乎稳定关系提供了统一的框架，其应用涵盖无限图论与有限群论，显著扩展了稳定性工具在离散数学中的适用范围。

Abstract: We develop a general theory of local stability up to belonging to an ideal
(e.g. having measure zero). From a model-theoretic perspective, we prove a
stationarity principle for almost stable formulas in this sense, and build a
topological space of partial types whose Cantor-Bendixson rank is finite. The
interaction of this space with Keisler measures and definable groups yields, on
the one hand, a regularity lemma for infinite graphs where the edge relation is
almost stable, and, on the other hand, the existence of definable stabilizer
subgroups. As an application, we prove a finite graph regularity lemma and an
arithmetic regularity lemma for almost stable relations in arbitrary finite
groups.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [23] [On elementary estimates for the partition function](https://arxiv.org/abs/2508.00038)
*Mizuki Akeno*

Main category: math.CO

TL;DR: 本文通过欧几里得空间中的基本几何不等式，获得了分割函数$p(n)$的上下界，并将该方法推广到分割函数的广义形式。


<details>
  <summary>Details</summary>
Motivation: 研究分割函数$p(n)$及其广义形式的精确界限，以深化对整数分割理论的理解。

Method: 利用欧几里得空间中的基本几何不等式，推导分割函数的上下界，并将方法推广到广义分割函数。

Result: 获得了分割函数$p(n)$的上下界，并成功将方法应用于广义分割函数，扩展了现有结果。

Conclusion: 该方法不仅为分割函数提供了新的界限，还为研究广义分割函数提供了有效的工具。

Abstract: In this paper, we obtain upper and lower bounds for the partition function
$p(n)$ by using an elementary geometric inequality in Euclidean space and
generalize the method to generalizations of the partition function.

</details>


### [24] [On simultaneous $(s, s+t, s+2t, \dots)$-core partitions](https://arxiv.org/abs/2508.00074)
*William Keith,Rishi Nath,James Sellers*

Main category: math.CO

TL;DR: 本文研究了在$p$趋近于无穷大时，同时满足$(s,s+t,s+2t,\dots,s+pt)$-core性质的分区，特别是在$s$与$t$不互质情况下的生成函数、包含性质及同余关系。作为Cho、Huh和Sohn一般性研究的边界情况，我们给出了$s$与$t$互质时的枚举结果，并正面回答了Fayers关于此类分区集合大小多项式行为的猜想。


<details>
  <summary>Details</summary>
Motivation: 研究同时满足多重core性质的分区在组合数学中具有重要意义，尤其是在$s$与$t$不互质的情况下，其行为与经典的$(s,t)$-core分区存在显著差异，这为理解分区的组合性质提供了新的视角。

Method: 通过分析生成函数和分区性质，结合同余理论，研究了$(s,s+t,s+2t,\dots,s+pt)$-core分区的组合行为。特别关注了$s$与$t$不互质的情况，并与$(s,t)$-core分区的行为进行了对比。

Result: 在$s$与$t$互质的情况下，给出了此类分区的枚举结果，并证明了Fayers关于分区集合大小多项式行为的猜想。此外，还揭示了$s$与$t$不互质时分区行为的独特性质。

Conclusion: 本文不仅扩展了Cho、Huh和Sohn的一般性研究，还通过解决Fayers的猜想，为多重core分区的理论框架提供了重要补充。研究结果表明，$s$与$t$的互质性对分区的组合行为具有深远影响。

Abstract: We consider simultaneous $(s,s+t,s+2t,\dots,s+pt)$-core partitions in the
large-$p$ limit, or (when $s<t$), partitions in which no hook may be of length
$s \pmod{t}$. We study generating functions, containment properties, and
congruences when $s$ is not coprime to $t$. As a boundary case of the general
study made by Cho, Huh and Sohn, we provide enumerations when $s$ is coprime to
$t$, and answer positively a conjecture of Fayers on the polynomial behavior of
the size of the set of simultaneous $(s,s+t,s+2t,\dots,s+pt)$-core partitions
when $p$ grows arbitrarily large. Of particular interest throughout is the
comparison to the behavior of simultaneous $(s,t)$-cores.

</details>


### [25] [The symmetric strong circuit elimination property](https://arxiv.org/abs/2508.00132)
*Christine Cho,James Oxley,Suijie Wang*

Main category: math.CO

TL;DR: 研究了拟阵中的对称强电路消除性质（SSCE），证明了连通拟阵具有SSCE当且仅当其不包含两个斜交电路，并通过禁止级联子式进行了表征。


<details>
  <summary>Details</summary>
Motivation: 拟阵理论中的电路消除性质在组合优化中具有重要作用，但传统的强电路消除性质存在不对称性。研究对称强电路消除性质（SSCE）有助于完善拟阵的公理体系。

Method: 通过分析拟阵的电路结构，结合斜交电路的概念，提出了对称强电路消除性质（SSCE）的条件，并利用禁止级联子式进行表征。

Result: 证明了连通拟阵具有SSCE当且仅当其不包含两个斜交电路，并给出了基于SSCE修改的新拟阵公理体系。

Conclusion: 对称强电路消除性质（SSCE）为拟阵理论提供了新的公理基础，其与斜交电路的关系为拟阵的结构分析提供了新视角。

Abstract: If $C_1$ and $C_2$ are circuits in a matroid $M$ with $e_1$ in $C_1-C_2$ and
$e$ in $C_1\cap C_2$, then $M$ has a circuit $C_3$ such that $e\in C_3\subseteq
(C_1\cup C_2)-e$. This strong circuit elimination axiom is inherently
asymmetric. A matroid $M$ has the symmetric strong circuit elimination property
(SSCE) if, when the above conditions hold and $e_2\in C_2-C_1$, there is a
circuit $C_3'$ with $\{e_1,e_2\}\subseteq C_3'\subseteq (C_1\cup C_2)-e$. We
prove that a connected matroid has this property if and only if it has no two
skew circuits. We also characterize such matroids in terms of forbidden series
minors, and we give a new matroid axiom system that is built around a
modification of SSCE.

</details>


### [26] [Algebraic connectivity in normed spaces](https://arxiv.org/abs/2508.00134)
*James Cruickshank,Sean Dewar,Derek Kitson*

Main category: math.CO

TL;DR: 本文研究了图在有限维实赋范线性空间$X$中的代数连通性，分析了其与图分解、顶点删除和等距同构的关系，并给出了基于$X$几何性质和图Fiedler数的一般界。特别关注$\ell_\infty^d$空间，提供了显式公式、计算及上下界。


<details>
  <summary>Details</summary>
Motivation: 代数连通性是图在赋范空间$X$中刚性的度量，类似于图的Fiedler数。研究其在$X$中的行为有助于理解图的几何性质与刚性关系。

Method: 通过分析图的分解、顶点删除和等距同构对代数连通性的影响，结合$X$的几何性质与Fiedler数推导一般界。在$\ell_\infty^d$空间中，利用完全框架的单色子图无奇洞性质作为关键工具。

Result: 提出了代数连通性的一般界，并在$\ell_\infty^d$空间中给出显式公式和上下界。证明了完全框架的单色子图无奇洞，并建立了与冗余刚性的联系。

Conclusion: 代数连通性作为图刚性的度量，其行为与图的分解和空间几何性质密切相关。$\ell_\infty^d$空间中的显式结果为相关研究提供了具体工具，单色子图性质揭示了新的结构特征。

Abstract: The algebraic connectivity of a graph $G$ in a finite dimensional real normed
linear space $X$ is a geometric counterpart to the Fiedler number of the graph
and can be regarded as a measure of the rigidity of the graph in $X$. We
analyse the behaviour of the algebraic connectivity of $G$ in $X$ with respect
to graph decomposition, vertex deletion and isometric isomorphism, and provide
a general bound expressed in terms of the geometry of $X$ and the Fiedler
number of the graph. Particular focus is given to the space $\ell_\infty^d$
where we present explicit formulae and calculations as well as upper and lower
bounds. As a key tool, we show that the monochrome subgraphs of a complete
framework in $\ell_\infty^d$ are odd-hole-free. Connections to redundant
rigidity are also presented.

</details>


### [27] [Chromatic MacMahon symmetric functions of graphs](https://arxiv.org/abs/2508.00157)
*Jeremy L. Martin,May B. Trist*

Main category: math.CO

TL;DR: 本文引入了一种针对顶点加权图的色对称MacMahon函数，扩展了传统色对称函数的概念，证明了该函数在树结构中可以确定顶点子集的生成函数。


<details>
  <summary>Details</summary>
Motivation: 研究动机是扩展色对称函数的概念，使其适用于顶点加权图，并探索其在多变量对称函数中的新应用。

Method: 通过引入MacMahon对称函数作为对称群对角作用的不变量，构建了顶点加权图的色对称MacMahon函数，记录顶点集的基数和权重信息。

Result: 证明了树的色对称MacMahon函数可以确定其顶点子集的生成函数，包括基数、权重、内部和外部边数，推广了无权重情况下的已有结果。

Conclusion: 该研究不仅推广了Crew的猜想和Aliste-Prieto等人的独立证明，还为顶点加权图的对称函数理论提供了新的工具和视角。

Abstract: A MacMahon symmetric function is an invariant of the diagonal action of the
symmetric group on power series in multiple alphabets of variables. We
introduce an analogue of the chromatic symmetric function for vertex-weighted
graphs, taking values in the MacMahon symmetric functions on two sets of
variables, recording information about both cardinalities and weights of vertex
sets. We prove that the chromatic symmetric MacMahon function of a tree
determines the generating function for its vertex subsets by cardinality,
weight, and the numbers of internal and external edges. This result generalizes
the one for the unweighted case, first conjectured by Crew and proved
independently by Aliste-Prieto--Martin--Wagner--Zamora and Liu--Tang.

</details>


### [28] [On the Undecidability of Tiling the $3$-dimensional Space with a Set of $3$ Polycubes](https://arxiv.org/abs/2508.00192)
*Chao Yang,Zhujun Zhang*

Main category: math.CO

TL;DR: 本文证明了三维空间中用三个多立方体进行平移铺砌问题是不可判定的，支持了关于平移铺砌不可判定性的猜想。


<details>
  <summary>Details</summary>
Motivation: Greenfeld和Tao近期关于平移铺砌不可判定性的两项重要成果支持了一个猜想：存在一个固定维度$n$，使得单块平移铺砌问题不可判定。为验证该猜想，需要研究尽可能少的多块铺砌在固定维度中的不可判定性。

Method: 研究者采用减少铺砌块数量的策略，重点关注三维空间中用三个多立方体进行平移铺砌的情况。

Result: 研究结果表明，在三维空间中使用三个多立方体进行平移铺砌的问题是不可判定的。

Conclusion: 该成果为平移铺砌不可判定性猜想提供了重要证据，表明即使在较低维度（三维）和较少铺砌块（三个）情况下，平移铺砌问题仍可能具有不可判定性。

Abstract: Translational tiling problems are among the most fundamental and
representative undecidable problems in all fields of mathematics. Greenfeld and
Tao obtained two remarkable results on the undecidability of translational
tiling in recent years. One is the existence of an aperiodic monotile in a
space of sufficiently large dimension. The other is the undecidability of
translational tiling of periodic subsets of space with a single tile, provided
that the dimension of the space is part of the input. These two results support
the following conjecture: there is a fixed dimension $n$ such that
translational tiling with a single tile is undecidable. One strategy towards
solving this conjecture is to prove the undecidability of translational tiling
of a fixed dimension space with a set of $k$ tiles, for a positive integer $k$
as small as possible. In this paper, it is shown that translational tiling the
$3$-dimensional space with a set of $3$ polycubes is undecidable.

</details>


### [29] [On the geometry of stack-sorting simplices](https://arxiv.org/abs/2508.00219)
*Cameron Ake,Spencer F. Lewis,Amanda Louie,Andrés R. Vindas-Meléndez*

Main category: math.CO

TL;DR: 本文证明了所有堆栈排序多面体都是单纯形，且由$Ln1$排列生成的堆栈排序多面体相对体积为1。同时给出了堆栈排序多面体中格点数的上界，并指出由$2Ln1$排列生成的堆栈排序多面体无内点。


<details>
  <summary>Details</summary>
Motivation: 研究堆栈排序多面体的几何性质，特别是其体积和格点分布，以深化对堆栈排序算法的理解。

Method: 通过数学证明和组合分析，探讨堆栈排序多面体的结构特性及其与排列类型的关系。

Result: 所有堆栈排序多面体均为单纯形；$Ln1$排列生成的多面体相对体积为1；$2Ln1$排列生成的多面体无内点。

Conclusion: 堆栈排序多面体具有简明的几何结构，其体积和格点分布与排列类型密切相关，为进一步研究堆栈排序算法提供了理论基础。

Abstract: We show that all stack-sorting polytopes are simplices. Furthermore, we show
that the stack-sorting polytopes generated from $Ln1$ permutations have
relative volume 1. We establish an upper bound for the number of lattice points
in a stack-sorting polytope. In particular, stack-sorting polytopes generated
from $2Ln1$ permutations have no interior points.

</details>


### [30] [On the Existence of Optimal Strategies in a Combinatorial Game](https://arxiv.org/abs/2508.00246)
*Tim Rammenstein*

Main category: math.CO

TL;DR: 研究源自德国数学竞赛的组合游戏，分析玩家轮流移除自然数满足特定整除条件的策略，发现偶数集时后手必胜，奇数集时先手常占优。


<details>
  <summary>Details</summary>
Motivation: 受德国国家数学竞赛问题启发，探索基于自然数集和固定除数的组合游戏策略，旨在揭示不同参数下的必胜规律。

Method: 推广原始游戏为双参数（初始集大小与固定除数）模型，理论分析结合网页实现验证玩家策略。

Result: 证明偶数规模初始集后手必胜；多数奇数规模下先手存在必胜策略，并通过网页演示验证结论。

Conclusion: 该研究系统建立了特定组合游戏的制胜理论框架，偶数与奇数集的策略差异为后续博弈研究提供新方向。

Abstract: We study a combinatorial game derived from a problem in the German National
Mathematics Competition. In this game, two players take turns removing numbers
from a finite set of natural numbers, aiming to satisfy a certain divisibility
condition. We introduce a generalized version of the original game, which
depends on two parameters: the size of the initial number set and a fixed
divisor. For both players, we identify a broad range of game variants in which
they can force a win. In particular, we show that for even-sized sets, the
second player to move can always win, while for many odd-sized cases, the first
player to move has a winning strategy. A web implementation of the game
demonstrates some of our results in practice.

</details>


### [31] [chipfiring: A Python Package for Efficient Mathematical Analysis of Chip-Firing Games on Multigraphs](https://arxiv.org/abs/2508.00269)
*Dhyey Dharmendrakumar Mavani,Tairan Ji,Nathan Pflueger*

Main category: math.CO

TL;DR: 本文介绍了`chipfiring`，一个用于有限图上筹码游戏数学分析的Python包，提供定义图与筹码配置、执行筹码操作及分析基本属性的工具。


<details>
  <summary>Details</summary>
Motivation: 为图论、组合数学和代数几何领域的研究者与学生提供一个专门用于探索筹码游戏数学模型的算法与数据结构库。

Method: 包包含面向对象的图与筹码配置实现、集成的拉普拉斯矩阵计算及Dhar算法的高效实现，用于判断美元游戏的可解性。

Result: `chipfiring`库提供了全面的功能，支持筹码游戏的核心数学分析，并通过示例展示了其使用方式与独特贡献。

Conclusion: 该库填补了通用图库的不足，为特定数学领域的研究与教学提供了专用工具。

Abstract: This paper presents `chipfiring`, a comprehensive Python package for the
mathematical analysis of chip-firing games on finite graphs. The package
provides a robust toolkit for defining graphs and chip configurations
(divisors), performing chip-firing operations, and analyzing fundamental
properties such as winnability, linear equivalence, and divisor rank. We detail
the core components of the library, including its object-oriented graph and
divisor implementations, integrated Laplacian matrix computations, and an
efficient implementation of Dhar's algorithm for determining the solvability of
the dollar game. The `chipfiring` package is designed for researchers and
students in graph theory, combinatorics, and algebraic geometry, providing
essential algorithms and data structures for exploring these rich mathematical
models. We describe the library's architecture, illustrate its usage with
comprehensive examples, and highlight its specialized contributions compared to
general-purpose graph libraries.

</details>


### [32] [The net-regular strongly regular signed graphs with degree 6](https://arxiv.org/abs/2508.00302)
*Qian Yu,Yaoping Hou*

Main category: math.CO

TL;DR: 本文研究了具有6度的净正则强正则符号图，确定了所有连通的6-正则且净正则的强正则符号图。


<details>
  <summary>Details</summary>
Motivation: 研究6-正则且净正则的强正则符号图，填补该领域的研究空白。

Method: 通过数学分析和图论方法，对6-正则且净正则的强正则符号图进行分类和确定。

Result: 发现存在3个净度为4、6个净度为2和4个净度为0的6-正则强正则符号图。

Conclusion: 成功分类并确定了所有连通的6-正则且净正则的强正则符号图，为相关研究提供了重要参考。

Abstract: In this paper, we study the net-regular strongly regular signed graphs with
degree 6 and determine all connected 6-regular and net-regular strongly regular
signed graphs. There are three, six and four 6-regular strongly regular signed
graphs with net-degree 4, 2 and 0, respectively.

</details>


### [33] [Saturation for Non-Symmetric Macdonald Polynomials](https://arxiv.org/abs/2508.00336)
*Milo Bechtloff Weising,Alexander E. Black*

Main category: math.CO

TL;DR: 我们证明了非对称Macdonald多项式的支撑集具有$M$-凸性，并由此解决了Monical等人2019年的猜想，进一步证明了$\mathrm{GL}$型仿射Grassmannian上仿射Schubert簇的矩多面体是广义排列多面体。


<details>
  <summary>Details</summary>
Motivation: 研究非对称Macdonald多项式的支撑集性质，验证Monical等人关于其具有饱和牛顿多面体性质的猜想，并探索其在仿射Grassmannian几何中的意义。

Method: 通过数学证明，建立非对称Macdonald多项式支撑集的$M$-凸性，并利用这一性质推导出相关结论。

Result: 证明了非对称Macdonald多项式的支撑集是$M$-凸的，验证了饱和牛顿多面体性质猜想，并得出$\mathrm{GL}$型仿射Schubert簇的矩多面体为广义排列多面体。

Conclusion: 该研究不仅解决了重要猜想，还揭示了非对称Macdonald多项式与仿射Grassmannian几何之间的深刻联系，为相关领域提供了新的理论工具。

Abstract: We prove that supports of non-symmetric Macdonald polynomials are $M$-convex.
As a consequence, we resolve a 2019 conjecture of Monical, Tokcan, and Yong
that they have the saturated Newton polytope property. As a further
consequence, we prove that the moment polytopes of affine Schubert varieties in
the affine Grassmannian of type $\mathrm{GL}$ are generalized permutahedra.

</details>


### [34] [Packing subdivisions into regular graphs](https://arxiv.org/abs/2508.00480)
*Richard Montgomery,Kalina Petrova,Arjun Ranganathan,Jane Tan*

Main category: math.CO

TL;DR: 本文证明了对于任意图$F$和任意$\eta>0$，存在一个$d_0=d_0(F,\eta)$，使得每个$n$顶点$d$-正则图在$d \geq d_0$时，都有一个顶点不相交的$F$-细分覆盖至少$(1-\eta)n$个顶点，验证了Verstra\"ete的猜想并改进了Letzter等人的结果。


<details>
  <summary>Details</summary>
Motivation: 研究正则图中顶点不相交子图覆盖问题，验证Verstra\"ete于2002年提出的猜想，并改进近期Letzter等人的结果。

Method: 通过构造性证明和极值图论技术，确定正则图的最小度数$d_0$与图$F$和参数$\eta$的关系。

Result: 证明了对于任意图$F$和$\eta>0$，存在$d_0$使得$d \geq d_0$的$d$-正则图几乎可以被$F$-细分完全覆盖。

Conclusion: 该结果不仅验证了长期未解决的猜想，还显著改进了现有结论，为正则图的子图覆盖问题提供了更一般的理论框架。

Abstract: We show that, for any graph $F$ and $\eta>0$, there exists a
$d_0=d_0(F,\eta)$ such that every $n$-vertex $d$-regular graph with $d \geq
d_0$ has a collection of vertex-disjoint $F$-subdivisions covering at least
$(1-\eta)n$ vertices. This verifies a conjecture of Verstra\"ete from 2002 and
improves a recent result of Letzter, Methuku and Sudakov which additionally
required $d$ to be at least polylogarithmic in $n$.

</details>


### [35] [Generalized Turan number with given size](https://arxiv.org/abs/2508.00483)
*Yan Wang,Yue Xu,Jiasheng Zeng,Xiao-Dong Zhang*

Main category: math.CO

TL;DR: 本文研究了给定边数的图中不含特定子图时最大$K_r$子图数问题，提出了新的上界方法并应用于多类图结构。


<details>
  <summary>Details</summary>
Motivation: 探索在边数固定的图中，不含特定子图$F$时能包含的最大$K_r$子图数$\mathrm{mex}(m,K_r,F)$，扩展了Turán型问题的研究范畴。

Method: 通过分析图$G$的子图结构，结合$\mathrm{ex}(n,K_r,F)$和$\mathrm{ex}(n,F)$的上界，以及删除顶点后的极值函数$\mathrm{ex}(n,K_r,F-v_0)$，建立改进的上界。

Result: 证明了对于$r\ge 3$和$\alpha\in(\frac{2}{r},1]$，存在子图阶数$n_0=\Omega(m^\frac{\alpha}{2})$含$\Omega(n_0^\frac{i(r-2)\alpha}{(2-\alpha)r-2})$个$K_i$子图；特别地，对$K_{s,t}$给出明确渐近式$\mathrm{mex}(m,K_r,K_{s,t})=\Theta(m^\frac{rs-\binom{r}{2}}{2s-1})$。

Conclusion: 该研究为广义Turán问题提供了普适性上界工具，并在完全多部图、$K_s \vee C_\ell$等图类中得到了非平凡结果，推动了极值图论的发展。

Abstract: Generalized Tur\'an problem with given size, denoted as
$\mathrm{mex}(m,K_r,F)$, determines the maximum number of $K_r$-copies in an
$F$-free graph with $m$ edges. We prove that for $r\ge 3$ and $\alpha\in(\frac
2 r,1]$, any graph $G$ with $m$ edges and $\Omega(m^{\frac{\alpha r}{2}})$
$K_r$-copies has a subgraph of order $n_0=\Omega(m^\frac{\alpha}{2})$, which
contains $\Omega(n_0^{\frac{i(r-2)\alpha}{(2-\alpha)r-2}})$ $K_i$-copies for
each $i = 2, \ldots, r$. This implies an upper bound of $\mathrm{mex}(m, K_r,
F)$ when an upper bound of $\mathrm{ex}(n,K_r,F)$ is known. Furthermore, we
establish an improved upper bound of $\mathrm{mex}(m, K_r, F)$ by
$\mathrm{ex}(n, F)$ and $\min_{v_0 \in V(F)} \mathrm{ex}(n, K_r, F - v_0)$. As
a corollary, we show $\mathrm{mex}(m, K_r, K_{s,t}) = \Theta( m^{\frac{rs -
\binom{r}{2}}{2s-1}} )$ for $r \geq 3$, $s \geq 2r-2$ and $t \geq (s-1)! + 1$,
and obtain non-trivial bounds for other graph classes such as complete
$r$-partite graphs and $K_s \vee C_\ell$, etc.

</details>


### [36] [Clubs in projective spaces and three-weight rank-metric codes](https://arxiv.org/abs/2508.00502)
*Jonathan Mannaert,Paolo Santonastaso,Ferdinando Zullo*

Main category: math.CO

TL;DR: 本文研究了有限域上高维射影空间中$i$-clubs的几何与代数结构，通过秩度量码建立了其秩的上界，并给出了最大秩的显式构造，特别对$i=m-1$情形进行了完整分类。


<details>
  <summary>Details</summary>
Motivation: $i$-clubs作为线性集的重要子类，在射影线上已有深入研究，但在高维射影空间中的性质仍不明确。研究其结构与秩度量码的联系对有限几何和编码理论具有重要意义。

Method: 通过将$i$-clubs与秩度量码关联，利用MacWilliams恒等式分析参数；对于$i \geq m/2$情形给出显式构造，并对$i \leq m-2$展示非等价构造的存在性。

Result: 建立了$i$-clubs的秩上界；当$i \geq m/2$时构造出达到最大秩的实例；完全分类了$i=m-1$的特殊情形；从clubs出发给出了三权重秩度量码的新构造。

Conclusion: 该研究系统揭示了高维射影空间中$i$-clubs的代数特性与几何结构，特别解决了最大秩构造问题，并为相关秩度量码的研究提供了新工具和实例。

Abstract: Linear sets over finite fields are central objects in finite geometry and
coding theory, with deep connections to structures such as semifields, blocking
sets, KM-arcs, and rank-metric codes. Among them, $i$-clubs, a class of linear
sets where all but one point (which has weight $i$) have weight one, have been
extensively studied in the projective line but remain poorly understood in
higher-dimensional projective spaces. In this paper, we investigate the
geometry and algebraic structure of $i$-clubs in projective spaces. We
establish upper bounds on their rank by associating them with rank-metric codes
and analyzing their parameters via MacWilliams identities. We also provide
explicit constructions of $i$-clubs that attain the maximum rank for $i \geq
m/2$, and we demonstrate the existence of non-equivalent constructions when $i
\leq m-2$. The special case $i = m-1$ is fully classified. Furthermore, we
explore the rich geometry of three-weight rank-metric codes, offering new
constructions from clubs and partial classification results.

</details>


### [37] [Multivariate Tutte polynomials of semimatroids](https://arxiv.org/abs/2508.00561)
*Houshan Fu*

Main category: math.CO

TL;DR: 本文研究半拟阵的多元Tutte多项式及其他多项式不变量，推广了图和拟阵的对应理论，建立了删除-收缩递推关系、基活动展开及卷积恒等式。


<details>
  <summary>Details</summary>
Motivation: 旨在将图和拟阵的多项式不变量理论推广至更一般的半拟阵结构，扩展Kook-Reiner-Stanton卷积公式与Kung卷积乘法恒等式的适用范围。

Method: 通过建立半拟阵的删除-收缩递推关系、基活动展开式，并运用组合卷积技术，系统推导多项式不变量的性质。

Result: 成功将Tutte多项式等经典结果的卷积公式推广至半拟阵，证明了其满足类似的分解恒等式与乘法结构。

Conclusion: 半拟阵的多项式不变量理论为图和拟阵的经典结论提供了统一框架，卷积公式的扩展揭示了组合结构的深层代数性质。

Abstract: We introduce and investigate multivariate Tutte polynomials, dichromatic
polynomials, subset-corank polynomials, size-corank polynomials, and rank
generating polynomials of semimatroids, which generalize the corresponding
polynomial invariants of graphs and matroids. We primarily establish their
deletion-contraction recurrences, basis activities expansions, and various
convolution identities. These findings naturally extend Kook-Reiner-Stanton's
convolution formula and Kung's convolution-multiplication identities for the
Tutte polynomials of graphs and matroids to semimatroids.

</details>


### [38] [Domination numbers and homotopy in certain ternary graphs](https://arxiv.org/abs/2508.00699)
*Taehyun Eom,Jinha Kim,Minki Kim*

Main category: math.CO

TL;DR: 本文研究了三元图的性质，证明了在某些条件下，其独立复形的同伦类型与球面相同，并给出了球面维度与独立支配数或支配数的关系。


<details>
  <summary>Details</summary>
Motivation: 三元图（无诱导长度为$0$模$3$的环的图）的独立复形若不可缩，则同伦等价于球面。研究其球面维数与图参数的关系具有理论意义。

Method: 通过分析不含诱导长度为$1$模$3$的环的三元图，将独立复形的球面维度与最小极大单形维度（或独立支配数减$1$）建立等价关系，并推广到超图。

Result: 证明当三元图不含诱导长度为$1$模$3$的环时，独立复形球面维度等于最小极大单形维度，或独立支配数/支配数减$1$。该结论对超图也成立。

Conclusion: 三元图的独立复形球面维度可由图参数精确计算，这一性质在超图中同样适用，为组合拓扑学提供了新的理论工具。

Abstract: A ternary graph is a graph with no induced cycles of length $0$ modulo $3$.
It was recently shown that, if the independence complex of a ternary graph is
not contractible, then it is homotopy equivalent to a sphere. When a ternary
graph also does not contain induced cycles of length $1$ modulo $3$, we prove
that the dimension of the sphere is equal to the dimension of a minimum maximal
simplex of the independence complex, or equivalently, to the value obtained by
subtracting $1$ from the independent domination number of the graph. The same
statement holds if we replace the independent domination number with the
domination number. We also give a hypergraph analogue of the statement above.

</details>


### [39] [The representation theory of somewhere-to-below shuffles](https://arxiv.org/abs/2508.00752)
*Darij Grinberg*

Main category: math.CO

TL;DR: 本文研究了对称群$S_n$的群代数中一类称为'单边循环洗牌'的线性组合，并确定了其在Specht模$\mathcal{S}^{\lambda}$上的作用特征值。


<details>
  <summary>Details</summary>
Motivation: 探索对称群$S_n$群代数中特定元素（单边循环洗牌）的代数性质及其在表示论中的应用，特别是对Specht模的作用。

Method: 通过定义'某处到下方洗牌'元素$t_{\ell}$，并研究其线性组合（单边循环洗牌）在Specht模$\mathcal{S}^{\lambda}$上的线性作用。

Result: 成功确定了任意单边循环洗牌在任意Specht模$\mathcal{S}^{\lambda}$上作用的特征值。

Conclusion: 该研究为对称群表示论提供了新的工具，单边循环洗牌的特征值结果有助于进一步理解群代数的结构与表示性质。

Abstract: The *somewhere-to-below shuffles* are the elements \[ t_{\ell} :=
\operatorname{cyc}_{\ell}+\operatorname{cyc}_{\ell,\ell+1}+\operatorname{cyc}_{\ell,\ell+1,\ell+2}+\cdots+\operatorname{cyc}_{\ell,\ell+1,\ldots,n}
\] (for $\ell \in \{1,2,\dots,n\}$) in the group algebra $\mathbf{k}[S_n]$ of
the $n$-th symmetric group $S_n$. Their linear combinations are called the
*one-sided cycle shuffles*. We determine the eigenvalues of the action of any
one-sided cycle shuffle on any Specht module $\mathcal{S}^{\lambda}$ of $S_n$.

</details>


### [40] [Optimal play in Guess Who](https://arxiv.org/abs/2508.00799)
*David Cushing,Stuart Gipp,Ezra Levick,Em Rickinson,David I. Stewart*

Main category: math.CO

TL;DR: 本文证明了在官方规则下使用二分响应问题的儿童游戏'Guess Who?'的最优策略，并扩展至三分响应问题的最优策略。


<details>
  <summary>Details</summary>
Motivation: 研究目的是为经典儿童游戏'Guess Who?'在官方规则下找到最优策略，并探索将二分响应问题扩展至三分响应问题的可能性。

Method: 应用了Rabern & Rabern (2008)提出的技术，该方法最初用于解决'最难的逻辑谜题'，现将其创新性地应用于三分响应问题的策略构建。

Result: 研究得出了在二分响应问题下的最优策略，并成功将该方法扩展至三分响应问题，给出了双玩家应用时的最优策略。

Conclusion: 该研究不仅解决了经典游戏的最优策略问题，还通过方法创新展示了如何将逻辑谜题解决技术应用于游戏策略的扩展。

Abstract: We prove an optimal strategy for the children's game Guess Who? assuming the
official rules are in use and that both players ask `classical' questions with
a bipartite response. Applying a technique described in [Rabern, B \& Rabern, L
2008, 'A simple solution to the hardest logic puzzle ever', \textit{Analysis},
vol. 68, no. 2, pp.~105-112.] allows for questions with tripartite responses;
we explain this innovation and give an optimal strategy for two players
applying it.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [41] [ranDecepter: Real-time Identification and Deterrence of Ransomware Attacks](https://arxiv.org/abs/2508.00293)
*Md Sajidul Islam Sajid,Jinpeng Wei,Ehab Al-Shaer*

Main category: cs.CR

TL;DR: 本文提出ranDecepter，一种结合主动网络欺骗与实时分析的新型勒索软件防御方法，通过误导攻击者并消耗其资源，实现100%准确识别且零误报。


<details>
  <summary>Details</summary>
Motivation: 勒索软件(RW)是数字领域的重大威胁，需有效对策。主动网络欺骗能通过虚假信息误导RW并揭示其行为，同时可作为攻击者与防御者间的通信渠道，回传虚假数据以耗尽攻击者资源。

Method: ranDecepter实时识别RW并将其隔离在欺骗环境中，自动分析RW代码关键要素建立循环机制，通过重启恶意软件并发送伪造加密信息与密钥，迫使攻击者为每个受害者存储虚假数据。

Result: 使用1,134个真实恶意样本和12个良性应用测试显示：100%准确识别RW（零误报），响应时间影响极小。50个代理在24小时内可在攻击者数据库生成高达9,223K条虚假条目。

Conclusion: ranDecepter通过主动欺骗与资源消耗策略，有效遏制勒索软件攻击，实验验证其具备破坏攻击者资源储备的显著潜力。

Abstract: Ransomware (RW) presents a significant and widespread threat in the digital
landscape, necessitating effective countermeasures. Active cyber deception is a
promising strategy to thwart RW and limiting its propagation by misleading it
with false information and revealing its true behaviors. Furthermore, RW often
acts as a communication conduit between attackers and defenders, allowing
deception to return false data to attackers and deplete their resources. This
paper introduces ranDecepter, a novel approach that combines active cyber
deception with real-time analysis to enhance defenses against RW attacks. The
ranDecepter identifies RW in real-time and isolates it within a deceptive
environment, autonomously identifying critical elements in the RW code to
create a loop mechanism. By repeatedly restarting the malware and transmitting
counterfeit encryption information and secret keys to the attacker, it forces
the attacker to store these fabricated details for each victim, thereby
depleting their resources. Our comprehensive evaluation of ranDecepter,
conducted using 1,134 real-world malware samples and twelve benign
applications, demonstrates a remarkable 100% accuracy in RW identification,
with no false positives and minimal impact on response times. Furthermore,
within 24-hours, ranDecepter generates up to 9,223K entries in the attacker's
database using 50 agents, showcasing its potential to undermine attacker
resources.

</details>


### [42] [Cryptanalysis of Isogeny-Based Quantum Money with Rational Points](https://arxiv.org/abs/2508.00351)
*Hyeonhak Kim,Donghoe Heo,Seokhie Hong*

Main category: cs.CR

TL;DR: 本文提出了一种针对基于椭圆曲线类群动作的量子货币的具体密码分析，通过利用有理点坐标高效计算分圆多项式，实现了相比暴力攻击O(log^4p)的加速。尽管攻击仍为指数时间，但该方法意外地优化了量子货币验证流程。


<details>
  <summary>Details</summary>
Motivation: 量子货币作为量子不可克隆定理的密码学应用，近期被Montgomery和Sharif (Asiacrypt '24)通过椭圆曲线类群动作实现。本研究旨在分析该方案的安全性并探索其验证过程的优化可能。

Method: 利用有理点坐标高效计算分圆多项式，结合二次扭曲特性验证椭圆曲线叠加态的基数，实现攻击速度提升与验证流程优化。算法复杂度为O(log^4p)。

Result: 攻击方案仍保持指数时间复杂度（无法实际伪造量子钞票），但意外发现该方法可显著提升量子货币验证效率，验证过程获得与攻击相同的O(log^4p)加速。

Conclusion: 该密码分析方法为基于椭圆曲线的量子密码学研究提供了新思路，特别是验证流程的优化结果有望推动未来量子加密货币系统的实用化发展。

Abstract: Quantum money is the cryptographic application of the quantum no-cloning
theorem. It has recently been instantiated by Montgomery and Sharif (Asiacrypt
'24) from class group actions on elliptic curves. In this work, we propose a
concrete cryptanalysis by leveraging the efficiency of evaluating division
polynomials with the coordinates of rational points, offering a speedup of
O(log^4p) compared to the brute-force attack. Since our attack still requires
exponential time, it remains impractical to forge a quantum banknote.
Interestingly, due to the inherent properties of quantum money, our attack
method also results in a more efficient verification procedure. Our algorithm
leverages the properties of quadratic twists to utilize rational points in
verifying the cardinality of the superposition of elliptic curves. We expect
this approach to contribute to future research on elliptic-curve-based quantum
cryptography.

</details>


### [43] [Preliminary Investigation into Uncertainty-Aware Attack Stage Classification](https://arxiv.org/abs/2508.00368)
*Alessandro Gaudenzi,Lorenzo Nodari,Lance Kaplan,Alessandra Russo,Murat Sensoy,Federico Cerutti*

Main category: cs.CR

TL;DR: 本文提出了一种基于证据深度学习（EDL）的分类方法，用于推断高级持续性威胁（APT）的攻击阶段，并有效检测分布外（OOD）输入，以应对动态对抗环境中的不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统检测系统仅以二元方式（良性或恶意）识别恶意活动，无法反映攻击的阶段性进展。有效的响应策略需准确推断攻击当前阶段，以便针对不同阶段（如侦察或数据窃取）采取相应措施。

Method: 采用证据深度学习（EDL）模型，通过输出狄利克雷分布参数来建模预测不确定性，不仅能预测最可能的攻击阶段，还能标识输入是否超出训练分布或存在不确定性。

Result: 模拟环境中的初步实验表明，该模型能准确推断攻击阶段并校准置信度，同时有效检测OOD输入，提示攻击者策略变化。

Conclusion: 研究支持在动态对抗环境中部署不确定性感知模型的可行性，为阶段性威胁检测提供了新思路。

Abstract: Advanced Persistent Threats (APTs) represent a significant challenge in
cybersecurity due to their prolonged, multi-stage nature and the sophistication
of their operators. Traditional detection systems typically focus on
identifying malicious activity in binary terms (benign or malicious) without
accounting for the progression of an attack. However, effective response
strategies depend on accurate inference of the attack's current stage, as
countermeasures must be tailored to whether an adversary is in the early
reconnaissance phase or actively conducting exploitation or exfiltration. This
work addresses the problem of attack stage inference under uncertainty, with a
focus on robustness to out-of-distribution (OOD) inputs. We propose a
classification approach based on Evidential Deep Learning (EDL), which models
predictive uncertainty by outputting parameters of a Dirichlet distribution
over possible stages. This allows the system not only to predict the most
likely stage of an attack but also to indicate when it is uncertain or the
input lies outside the training distribution. Preliminary experiments in a
simulated environment demonstrate that the proposed model can accurately infer
the stage of an attack with calibrated confidence while effectively detecting
OOD inputs, which may indicate changes in the attackers' tactics. These results
support the feasibility of deploying uncertainty-aware models for staged threat
detection in dynamic and adversarial environments.

</details>


### [44] [Accurate Latent Inversion for Generative Image Steganography via Rectified Flow](https://arxiv.org/abs/2508.00434)
*Yuqi Qian,Yun Cao,Meiyang Lv,Haocheng Fu*

Main category: cs.CR

TL;DR: 本文提出RF-Stego方法，通过路径一致性线性反转(PCLI)和可逆流(RF)采样器解决扩散模型隐写术中潜在变量反转不准确的问题，显著提升信息提取精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的隐写术在潜在变量反转过程中存在不准确性，导致重构变量与原始变量差异大，无法有效提取信息。

Method: 1. 提出路径一致性线性反转(PCLI)，通过显式对齐前向生成路径并建模双向共享线性路径消除路径失配；2. 采用理论可逆且数值稳定的可逆流(RF)采样器替代传统不稳定采样器。

Result: 实验表明RF-Stego在提取精度、图像质量、鲁棒性、安全性和生成效率上均优于现有先进方法。

Conclusion: RF-Stego通过PCLI约束和RF采样器实现了高精度潜在变量反转，为生成式图像隐写术提供了有效解决方案。

Abstract: Steganography based on diffusion models has attracted increasing attention
due to its ability to generate high-quality images and exhibit strong
robustness. In such approaches, the secret message is first embedded into the
initial latent variable, and then the stego image is generated through the
forward process. To extract the message, an inversion process is required to
reconstruct the latent variables from the received image. However, inaccurate
latent inversion leads to significant discrepancies between the reconstructed
and original latent variables, rendering message extraction infeasible. To
address this issue, we propose \textbf{RF-Stego}, a novel generative image
steganography method that enables accurate latent inversion and significantly
improves extraction accuracy. First, we develop the \textbf{P}ath
\textbf{C}onsistency \textbf{L}inear \textbf{I}nversion (\textbf{PCLI}), which
imposes formal constraints on the inversion process. By explicitly aligning it
with the forward generation path and modeling both directions along a shared
linear path, PCLI eliminates path mismatch and ensures path consistency
throughout the steganographic process. Second, through rigorous theoretical
proof, we demonstrate that \textbf{R}ectified \textbf{F}low \textbf{(RF)}
offers both theoretical reversibility and numerical stability in the inversion
process. Based on this, we replace traditional unstable samplers with RF
sampler which effectively improves the numerical precision of the inversion
process. Experimental results show RF-Stego outperforms state-of-the-art
methods in terms of extraction accuracy, image quality, robustness, security
and generation efficiency.

</details>


### [45] [CyGATE: Game-Theoretic Cyber Attack-Defense Engine for Patch Strategy Optimization](https://arxiv.org/abs/2508.00478)
*Yuning Jiang,Nay Oo,Qiaoran Meng,Lu Lin,Dusit Niyato,Zehui Xiong,Hoon Wei Lim,Biplab Sikdar*

Main category: cs.CR

TL;DR: 本文提出CyGATE框架，利用博弈论和大型语言模型（LLM）增强网络安全防御策略，通过动态威胁情报整合优化漏洞修复优先级。


<details>
  <summary>Details</summary>
Motivation: 现代网络攻击具有多阶段性，现有博弈论模型依赖静态假设且缺乏实时威胁情报整合，难以适应动态防御需求。

Method: CyGATE将网络攻防建模为部分可观测随机博弈（POSG），结合检索增强生成（RAG）的LLM，支持攻击者战术调整与防御者动态补丁优先级排序。

Result: 在动态补丁调度场景中，CyGATE有效优先处理高风险漏洞，提升适应性、战略预见性及资源利用效率。

Conclusion: 该框架可扩展至多智能体场景，为复杂企业环境中的协同攻防提供灵活解决方案。

Abstract: Modern cyber attacks unfold through multiple stages, requiring defenders to
dynamically prioritize mitigations under uncertainty. While game-theoretic
models capture attacker-defender interactions, existing approaches often rely
on static assumptions and lack integration with real-time threat intelligence,
limiting their adaptability. This paper presents CyGATE, a game-theoretic
framework modeling attacker-defender interactions, using large language models
(LLMs) with retrieval-augmented generation (RAG) to enhance tactic selection
and patch prioritization. Applied to a two-agent scenario, CyGATE frames cyber
conflicts as a partially observable stochastic game (POSG) across Cyber Kill
Chain stages. Both agents use belief states to navigate uncertainty, with the
attacker adapting tactics and the defender re-prioritizing patches based on
evolving risks and observed adversary behavior. The framework's flexible
architecture enables extension to multi-agent scenarios involving coordinated
attackers, collaborative defenders, or complex enterprise environments with
multiple stakeholders. Evaluated in a dynamic patch scheduling scenario, CyGATE
effectively prioritizes high-risk vulnerabilities, enhancing adaptability
through dynamic threat integration, strategic foresight by anticipating
attacker moves under uncertainty, and efficiency by optimizing resource use.

</details>


### [46] [Activation-Guided Local Editing for Jailbreaking Attacks](https://arxiv.org/abs/2508.00555)
*Jiecong Wang,Haoran Li,Hao Peng,Ziqian Zeng,Zihao Wang,Haohua Du,Zhengtao Yu*

Main category: cs.CR

TL;DR: 本文提出了一种名为AGILE的两阶段框架，用于高效破解大型语言模型的安全防护，结合场景生成与隐藏状态引导的细粒度编辑，显著提升了攻击成功率和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有破解方法存在明显缺陷：基于令牌的攻击生成内容不连贯且可迁移性差，而基于提示的攻击则缺乏扩展性且依赖人工。需要一种兼具高效性与自动化的新方法。

Method: 1) 首阶段通过场景化生成掩盖恶意查询意图；2) 次阶段利用模型隐藏状态指导细粒度编辑，将内部表征从恶意转向良性。该方法融合了令牌级与提示级攻击的优势。

Result: 实验表明该方法达到最先进的攻击成功率（较基线最高提升37.74%），在黑盒模型上表现出优秀可迁移性，且能有效突破主流防御机制。

Conclusion: AGILE框架揭示了当前防护措施的局限性，为未来防御研发提供了重要启示。代码已开源。

Abstract: Jailbreaking is an essential adversarial technique for red-teaming these
models to uncover and patch security flaws. However, existing jailbreak methods
face significant drawbacks. Token-level jailbreak attacks often produce
incoherent or unreadable inputs and exhibit poor transferability, while
prompt-level attacks lack scalability and rely heavily on manual effort and
human ingenuity. We propose a concise and effective two-stage framework that
combines the advantages of these approaches. The first stage performs a
scenario-based generation of context and rephrases the original malicious query
to obscure its harmful intent. The second stage then utilizes information from
the model's hidden states to guide fine-grained edits, effectively steering the
model's internal representation of the input from a malicious toward a benign
one. Extensive experiments demonstrate that this method achieves
state-of-the-art Attack Success Rate, with gains of up to 37.74% over the
strongest baseline, and exhibits excellent transferability to black-box models.
Our analysis further demonstrates that AGILE maintains substantial
effectiveness against prominent defense mechanisms, highlighting the
limitations of current safeguards and providing valuable insights for future
defense development. Our code is available at
https://github.com/yunsaijc/AGILE.

</details>


### [47] [LeakSealer: A Semisupervised Defense for LLMs Against Prompt Injection and Leakage Attacks](https://arxiv.org/abs/2508.00602)
*Francesco Panebianco,Stefano Bonfanti,Francesco Trovò,Michele Carminati*

Main category: cs.CR

TL;DR: 该研究针对大语言模型(LLM)面临的安全威胁(如越狱攻击和数据泄露)，提出了LeakSealer框架，结合静态分析和动态防御机制，有效提升了对抗性交互检测和敏感信息泄露防护能力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，其安全漏洞(如越狱攻击和检索增强生成技术引入的数据泄露风险)日益凸显，亟需开发新型防御方案。

Method: 1) 提出基于历史交互数据的主题分类分析方法，用于追踪越狱攻击模式演变；2) 开发模型无关的LeakSealer框架，整合静态取证分析与带有人类介入的动态防御管线。

Result: 在静态测试中，LeakSealer在ToxicChat数据集上实现最高注入攻击检测精确率；动态测试中PII泄露检测AUPRC达$0.97$，显著优于Llama Guard等基线。

Conclusion: LeakSealer框架通过协同静态分析与动态防御，为LLM系统提供了可扩展的安全防护方案，尤其在对抗性攻击检测和敏感数据保护方面表现突出。

Abstract: The generalization capabilities of Large Language Models (LLMs) have led to
their widespread deployment across various applications. However, this
increased adoption has introduced several security threats, notably in the
forms of jailbreaking and data leakage attacks. Additionally, Retrieval
Augmented Generation (RAG), while enhancing context-awareness in LLM responses,
has inadvertently introduced vulnerabilities that can result in the leakage of
sensitive information. Our contributions are twofold. First, we introduce a
methodology to analyze historical interaction data from an LLM system, enabling
the generation of usage maps categorized by topics (including adversarial
interactions). This approach further provides forensic insights for tracking
the evolution of jailbreaking attack patterns. Second, we propose LeakSealer, a
model-agnostic framework that combines static analysis for forensic insights
with dynamic defenses in a Human-In-The-Loop (HITL) pipeline. This technique
identifies topic groups and detects anomalous patterns, allowing for proactive
defense mechanisms. We empirically evaluate LeakSealer under two scenarios: (1)
jailbreak attempts, employing a public benchmark dataset, and (2) PII leakage,
supported by a curated dataset of labeled LLM interactions. In the static
setting, LeakSealer achieves the highest precision and recall on the ToxicChat
dataset when identifying prompt injection. In the dynamic setting, PII leakage
detection achieves an AUPRC of $0.97$, significantly outperforming baselines
such as Llama Guard.

</details>


### [48] [FedGuard: A Diverse-Byzantine-Robust Mechanism for Federated Learning with Major Malicious Clients](https://arxiv.org/abs/2508.00636)
*Haocheng Jiang,Hua Shen,Jixin Zhang,Willy Susilo,Mingwu Zhang*

Main category: cs.CR

TL;DR: 联邦学习易受拜占庭攻击，尤其在多数客户端恶意或数据高度非独立同分布时。现有防御机制针对特定攻击类型效果有限。本文提出FedGuard，利用成员推断对模型偏差的高敏感性，通过额外小批量数据识别并排除中毒模型，显著提升防御效果。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在多数客户端恶意或数据高度非独立同分布时易受拜占庭攻击，现有防御机制仅针对特定攻击类型，效果有限。

Method: 提出FedGuard机制，要求客户端在训练中包含服务器指定的额外小批量数据，利用成员推断对模型偏差的高敏感性识别中毒模型。

Result: 在三种高度非独立同分布数据集、90%客户端为拜占庭且每轮七种攻击类型下，FedGuard显著优于现有鲁棒联邦学习方案。

Conclusion: FedGuard通过额外小批量数据有效识别并排除中毒模型，显著提升联邦学习对多种拜占庭攻击的防御能力。

Abstract: Federated learning is a distributed training framework vulnerable to
Byzantine attacks, particularly when over 50% of clients are malicious or when
datasets are highly non-independent and identically distributed (non-IID).
Additionally, most existing defense mechanisms are designed for specific attack
types (e.g., gradient similarity-based schemes can only defend against outlier
model poisoning), limiting their effectiveness. In response, we propose
FedGuard, a novel federated learning mechanism. FedGuard cleverly addresses the
aforementioned issues by leveraging the high sensitivity of membership
inference to model bias. By requiring clients to include an additional
mini-batch of server-specified data in their training, FedGuard can identify
and exclude poisoned models, as their confidence in the mini-batch will drop
significantly. Our comprehensive evaluation unequivocally shows that, under
three highly non-IID datasets, with 90% of clients being Byzantine and seven
different types of Byzantine attacks occurring in each round, FedGuard
significantly outperforms existing robust federated learning schemes in
mitigating various types of Byzantine attacks.

</details>


### [49] [Demo: TOSense -- What Did You Just Agree to?](https://arxiv.org/abs/2508.00659)
*Xinzhang Chen,Hassan Ali,Arash Shaghaghi,Salil S. Kanhere,Sanjay Jha*

Main category: cs.CR

TL;DR: 本文提出TOSense——一款Chrome扩展程序，通过自然语言问答帮助用户理解冗长的服务条款，结合爬虫与轻量级语言模型实现实时解答，并创新性地采用合成问题评估管道替代人工标注。


<details>
  <summary>Details</summary>
Motivation: 在线服务的用户协议（ToS）通常冗长晦涩，导致信息不对称和法律风险，亟需工具帮助用户快速理解关键条款。

Method: 系统包含：(1)自动抓取ToS内容的爬虫tos-crawl；(2)MiniLM语义检索+BART编码器验证答案的轻量级模型管道；(3)通过聚类主题匹配生成合成问题的评估管道QEP。

Result: 在Apple/Google/X/Microsoft/Netflix五大平台测试中，TOSense准确率最高达44.5%，且能实时索引新网站内容。

Conclusion: TOSense通过可扩展的技术方案有效降低了ToS的理解门槛，演示中将展示实时抓取、交互问答等核心功能。

Abstract: Online services often require users to agree to lengthy and obscure Terms of
Service (ToS), leading to information asymmetry and legal risks. This paper
proposes TOSense-a Chrome extension that allows users to ask questions about
ToS in natural language and get concise answers in real time. The system
combines (i) a crawler "tos-crawl" that automatically extracts ToS content, and
(ii) a lightweight large language model pipeline: MiniLM for semantic retrieval
and BART-encoder for answer relevance verification. To avoid expensive manual
annotation, we present a novel Question Answering Evaluation Pipeline (QEP)
that generates synthetic questions and verifies the correctness of answers
using clustered topic matching. Experiments on five major platforms, Apple,
Google, X (formerly Twitter), Microsoft, and Netflix, show the effectiveness of
TOSense (with up to 44.5% accuracy) across varying number of topic clusters.
During the demonstration, we will showcase TOSense in action. Attendees will be
able to experience seamless extraction, interactive question answering, and
instant indexing of new sites.

</details>


### [50] [Unveiling Dynamic Binary Instrumentation Techniques](https://arxiv.org/abs/2508.00682)
*Oscar Llorente-Vazquez,Xabier Ugarte-Pedrero,Igor Santos-Grueiro,Pablo Garcia Bringas*

Main category: cs.CR

TL;DR: 本文综述了动态二进制插桩（DBI）技术，比较了不同方法的优缺点，并评估了它们在各种场景下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 动态二进制插桩（DBI）技术在安全和系统分析领域广泛应用，但现有方法各有利弊，缺乏全面比较。本文旨在梳理DBI技术，为研究者和实践者提供参考。

Method: 作者综合分析了进程级和全系统级的DBI方法，拆解其核心组件，比较不同插桩技术对运行时事件的处理能力，并评估其性能表现。

Result: 研究表明，没有任何一种DBI技术在所有场景下都优于其他技术，不同方法各有其适用领域和局限性。

Conclusion: DBI技术选择需根据具体应用场景权衡，未来研究应关注如何结合不同技术的优势以提升整体性能。

Abstract: Dynamic Binary Instrumentation (DBI) is the set of techniques that enable
instrumentation of programs at run-time, making it possible to monitor and
modify the execution of compiled binaries or entire systems. DBI is used for
countless security applications and analyses, and is extensively used across
many fields in both industry and academia. Over the years, several DBI
approaches have been proposed based on different technologies and implementing
diverse techniques. Every solution tries to overcome certain limitations, but
they sometimes bring other shortcomings. Some are specialized for one
particular domain or task, while others have a wider scope.
  In this paper, we shed light into the labyrinth of DBI, bringing together
process-level and whole-system approaches. We depict their building blocks and
analyze the underlying instrumentation techniques, comparing their ability to
instrument different primitives and run-time events. Then, we evaluate their
performance when implementing each primitive, and highlight relevant
observations. Our results show that no single technique is better than the rest
in all circumstances.

</details>


### [51] [LeakyCLIP: Extracting Training Data from CLIP](https://arxiv.org/abs/2508.00756)
*Yunhao Chen,Shujie Wang,Xin Wang,Xingjun Ma*

Main category: cs.CR

TL;DR: 本文通过提出LeakyCLIP攻击框架，揭示了CLIP模型在数据记忆与隐私泄露方面的风险，实现了从CLIP嵌入中高质量重建训练图像，并展示了多模态模型的隐私漏洞。


<details>
  <summary>Details</summary>
Motivation: 研究CLIP模型的数据记忆与隐私泄露风险对于保障多模态模型安全至关重要，特别是针对通过文本提示重建训练图像的CLIP反转过程。

Method: LeakyCLIP框架通过对抗性微调增强优化平滑性、基于线性变换的嵌入对齐以及Stable Diffusion-based细化提升重建保真度，解决了CLIP反转中的三大挑战。

Result: 实验结果显示，LeakyCLIP在ViT-B-16上实现了比基线方法高出358%的SSIM改进，并揭示了即使低保真度重建也能推断训练数据成员资格的普遍泄露风险。

Conclusion: 本研究不仅提出了一种实用的CLIP反转方法，还为多模态模型的隐私风险性质与范围提供了新的见解。

Abstract: Understanding the memorization and privacy leakage risks in Contrastive
Language--Image Pretraining (CLIP) is critical for ensuring the security of
multimodal models. Recent studies have demonstrated the feasibility of
extracting sensitive training examples from diffusion models, with conditional
diffusion models exhibiting a stronger tendency to memorize and leak
information. In this work, we investigate data memorization and extraction
risks in CLIP through the lens of CLIP inversion, a process that aims to
reconstruct training images from text prompts. To this end, we introduce
\textbf{LeakyCLIP}, a novel attack framework designed to achieve high-quality,
semantically accurate image reconstruction from CLIP embeddings. We identify
three key challenges in CLIP inversion: 1) non-robust features, 2) limited
visual semantics in text embeddings, and 3) low reconstruction fidelity. To
address these challenges, LeakyCLIP employs 1) adversarial fine-tuning to
enhance optimization smoothness, 2) linear transformation-based embedding
alignment, and 3) Stable Diffusion-based refinement to improve fidelity.
Empirical results demonstrate the superiority of LeakyCLIP, achieving over 358%
improvement in Structural Similarity Index Measure (SSIM) for ViT-B-16 compared
to baseline methods on LAION-2B subset. Furthermore, we uncover a pervasive
leakage risk, showing that training data membership can even be successfully
inferred from the metrics of low-fidelity reconstructions. Our work introduces
a practical method for CLIP inversion while offering novel insights into the
nature and scope of privacy risks in multimodal models.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [52] [Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench](https://arxiv.org/abs/2508.00081)
*Fred Mutisya,Shikoh Gitau,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha*

Main category: cs.AI

TL;DR: 本文指出HealthBench基准在评估医疗AI系统时存在依赖专家意见而非高级临床证据的问题，可能导致地域偏见和个体临床医生特质的固化，尤其在低收入和中等收入地区问题更为突出。作者提出基于版本控制的临床实践指南(CPGs)来改进奖励函数，以增强全球相关性和公平性。


<details>
  <summary>Details</summary>
Motivation: HealthBench基准虽推进了医疗语言模型评估，但其依赖专家意见而非高级临床证据，可能固化地域偏见和个体临床医生特质，且在低收入和中等收入地区问题更严重。非洲背景下的数据稀缺、基础设施不足和监管框架不成熟等问题，凸显了全球相关和公平基准的迫切需求。

Method: 作者提出将奖励函数锚定在版本控制的临床实践指南(CPGs)中，这些指南包含系统综述和GRADE证据评级。方法包括通过评分标准与指南的链接实现“证据稳健”的强化学习、证据加权评分、上下文覆盖逻辑，并关注伦理考量和延迟结果反馈的整合。

Result: 通过将奖励重新基于严格审查的CPGs，同时保留HealthBench的透明度和医生参与，作者旨在培养不仅在语言上精炼，而且在临床可信、伦理合理和全球相关的医疗语言模型。

Conclusion: 本文提出的方法通过结合严格审查的临床实践指南和改进的奖励函数，有望解决HealthBench基准的局限性，推动开发更具全球相关性和公平性的医疗AI系统。

Abstract: HealthBench, a benchmark designed to measure the capabilities of AI systems
for health better (Arora et al., 2025), has advanced medical language model
evaluation through physician-crafted dialogues and transparent rubrics.
However, its reliance on expert opinion, rather than high-tier clinical
evidence, risks codifying regional biases and individual clinician
idiosyncrasies, further compounded by potential biases in automated grading
systems. These limitations are particularly magnified in low- and middle-income
settings, where issues like sparse neglected tropical disease coverage and
region-specific guideline mismatches are prevalent.
  The unique challenges of the African context, including data scarcity,
inadequate infrastructure, and nascent regulatory frameworks, underscore the
urgent need for more globally relevant and equitable benchmarks. To address
these shortcomings, we propose anchoring reward functions in version-controlled
Clinical Practice Guidelines (CPGs) that incorporate systematic reviews and
GRADE evidence ratings.
  Our roadmap outlines "evidence-robust" reinforcement learning via
rubric-to-guideline linkage, evidence-weighted scoring, and contextual override
logic, complemented by a focus on ethical considerations and the integration of
delayed outcome feedback. By re-grounding rewards in rigorously vetted CPGs,
while preserving HealthBench's transparency and physician engagement, we aim to
foster medical language models that are not only linguistically polished but
also clinically trustworthy, ethically sound, and globally relevant.

</details>


### [53] [Hyperproperty-Constrained Secure Reinforcement Learning](https://arxiv.org/abs/2508.00106)
*Ernest Bonnah,Luan Viet Nguyen,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: 本文提出了一种基于HyperTWTL约束的安全强化学习方法（SecRL），用于在满足安全性和不透明性约束的条件下学习最优策略，并通过机器人任务案例验证了其有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有研究在利用超属性探索安全感知强化学习（RL）方面存在显著空白，特别是在机器人应用中如何结合HyperTWTL表示的安全性和不透明性约束。

Method: 将智能体动态建模为马尔可夫决策过程（MDP），并将安全约束形式化为HyperTWTL，提出了一种基于动态Boltzmann softmax RL的方法来学习满足约束的最优策略。

Result: 通过机器人取送任务案例研究验证了方法的有效性和可扩展性，并与其他两种基线RL算法相比表现出更优的性能。

Conclusion: 所提出的HyperTWTL约束SecRL方法能够有效处理安全感知强化学习问题，并在实际应用中展现出优越性。

Abstract: Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a
domain-specific formal specification language known for its effectiveness in
compactly representing security, opacity, and concurrency properties for
robotics applications. This paper focuses on HyperTWTL-constrained secure
reinforcement learning (SecRL). Although temporal logic-constrained safe
reinforcement learning (SRL) is an evolving research problem with several
existing literature, there is a significant research gap in exploring
security-aware reinforcement learning (RL) using hyperproperties. Given the
dynamics of an agent as a Markov Decision Process (MDP) and opacity/security
constraints formalized as HyperTWTL, we propose an approach for learning
security-aware optimal policies using dynamic Boltzmann softmax RL while
satisfying the HyperTWTL constraints. The effectiveness and scalability of our
proposed approach are demonstrated using a pick-up and delivery robotic mission
case study. We also compare our results with two other baseline RL algorithms,
showing that our proposed method outperforms them.

</details>


### [54] [No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence](https://arxiv.org/abs/2508.00116)
*Wil M. P. van der Aalst*

Main category: cs.AI

TL;DR: 人工智能（AI）在工业环境中的应用面临挑战，需要结合以对象为中心的过程挖掘（OCPM）来实现过程智能（PI），从而提升端到端操作流程。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在多个领域有广泛应用，但组织在工业环境中成功应用AI仍存在困难，特别是在端到端操作流程的诊断和改进方面。

Method: 通过结合生成式、预测式和规范式AI，并利用对象中心过程挖掘（OCPM）来结构化过程相关数据，提出过程智能（PI）的概念。

Result: 研究表明，OCPM是连接数据和过程的关键环节，能够支持多种形式的AI应用，从而在组织环境中实现过程智能。

Conclusion: AI需要过程智能（PI）来优化操作流程，OCPM与生成式、预测式和规范式AI的结合为工业应用提供了新的机会。

Abstract: The uptake of Artificial Intelligence (AI) impacts the way we work, interact,
do business, and conduct research. However, organizations struggle to apply AI
successfully in industrial settings where the focus is on end-to-end
operational processes. Here, we consider generative, predictive, and
prescriptive AI and elaborate on the challenges of diagnosing and improving
such processes. We show that AI needs to be grounded using Object-Centric
Process Mining (OCPM). Process-related data are structured and
organization-specific and, unlike text, processes are often highly dynamic.
OCPM is the missing link connecting data and processes and enables different
forms of AI. We use the term Process Intelligence (PI) to refer to the
amalgamation of process-centric data-driven techniques able to deal with a
variety of object and event types, enabling AI in an organizational context.
This paper explains why AI requires PI to improve operational processes and
highlights opportunities for successfully combining OCPM and generative,
predictive, and prescriptive AI.

</details>


### [55] [Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis](https://arxiv.org/abs/2508.00129)
*Agustín Borda,Juan Bautista Cabral,Gonzalo Giarda,Diego Nicolás Gimenez Irusta,Paula Pacheco,Alvaro Roy Schachner*

Main category: cs.AI

TL;DR: 本文提出三种检测多准则决策分析中排名逆转现象的测试方法，并在Scikit-Criteria库中实现，探讨了通用场景下的实现挑战及设计考量。


<details>
  <summary>Details</summary>
Motivation: 多准则决策分析中的排名逆转问题会严重影响决策方法的有效性，需要建立机制评估不同方法在特定备选方案上的表现，并构建全局排名以衡量方法效能。

Method: 开发了三种排名逆转检测测试，通过Scikit-Criteria库实现，并针对通用场景设计了特殊处理方案以应对实现复杂性。

Result: 成功在Scikit-Criteria库中实现了三种检测测试，解决了通用场景下的技术难题，为方法评估提供了工具支持。

Conclusion: 这些新增功能将显著提升多准则决策方法在问题解决中的评判能力，推动方法优选与改进。

Abstract: In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem
that can greatly affect the results of a Multi-Criteria Decision Method against
a particular set of alternatives. It is therefore useful to have a mechanism
that allows one to measure the performance of a method on a set of
alternatives. This idea could be taken further to build a global ranking of the
effectiveness of different methods to solve a problem. In this paper, we
present three tests that detect the presence of Rank Reversals, along with
their implementation in the Scikit-Criteria library. We also address the
complications that arise when implementing these tests for general scenarios
and the design considerations we made to handle them. We close with a
discussion about how these additions could play a major role in the judgment of
multi-criteria decision methods for problem solving.

</details>


### [56] [SHACL Validation under Graph Updates (Extended Paper)](https://arxiv.org/abs/2508.00137)
*Shqiponja Ahmetaj,George Konstantinidis,Magdalena Ortiz,Paolo Pareti,Mantas Simkus*

Main category: cs.AI

TL;DR: 本文研究了RDF图中基于SHACL的更新验证问题，提出了一种静态验证方法，并通过原型实现展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决RDF图在更新后仍能保持SHACL规范验证的问题，为动态RDF图提供基础推理服务。

Method: 方法包括提出一种基于SHACL的更新语言，并通过回归技术将更新操作嵌入SHACL约束，将静态验证问题转化为SHACL约束的（不）可满足性问题。

Result: 结果表明，静态验证问题可简化为SHACL（或其微小扩展）中的约束（不）可满足性问题，并分析了计算复杂性。

Conclusion: 结论指出，通过原型实现验证了静态验证方法的可行性，初步实验展示了其行为特性。

Abstract: SHACL (SHApe Constraint Language) is a W3C standardized constraint language
for RDF graphs. In this paper, we study SHACL validation in RDF graphs under
updates. We present a SHACL-based update language that can capture intuitive
and realistic modifications on RDF graphs and study the problem of static
validation under such updates. This problem asks to verify whether every graph
that validates a SHACL specification will still do so after applying a given
update sequence. More importantly, it provides a basis for further services for
reasoning about evolving RDF graphs. Using a regression technique that embeds
the update actions into SHACL constraints, we show that static validation under
updates can be reduced to (un)satisfiability of constraints in (a minor
extension of) SHACL. We analyze the computational complexity of the static
validation problem for SHACL and some key fragments. Finally, we present a
prototype implementation that performs static validation and other static
analysis tasks on SHACL constraints and demonstrate its behavior through
preliminary experiments.

</details>


### [57] [Co-Producing AI: Toward an Augmented, Participatory Lifecycle](https://arxiv.org/abs/2508.00138)
*Rashid Mushkani,Hugo Berard,Toumadher Ammar,Cassandre Chatonnier,Shin Koseki*

Main category: cs.AI

TL;DR: 本文提出了一种基于设计正义、扩展学习理论和参与式AI的AI生产流程重构方法，强调通过多学科协作和共治生命周期来减少算法对边缘群体的不公平影响。


<details>
  <summary>Details</summary>
Motivation: 尽管已有多种方法尝试减轻AI算法的风险和偏见，但这些算法仍对文化边缘群体造成不成比例的影响。现有解决方案包括伦理指南和技术公平性措施，但需要从根本上重构AI生产流程。

Method: 结合设计正义、扩展学习理论和参与式AI实证研究，提出包含共同框架、共同设计、共同实施、共同部署和共同维护五个阶段的增强型AI生命周期，并通过四个多学科研讨会验证。

Result: 构建了一个以分布式权威和迭代知识交换为核心的参与式AI治理框架，该框架与主流伦理准则相衔接，并明确了规模化参与式治理待解决的关键问题。

Conclusion: 通过将多样性、公平性和包容性(DEI)原则嵌入AI生产全流程，建立多学科协作的共治模式，可系统性降低算法对边缘群体的潜在危害。

Abstract: Despite efforts to mitigate the inherent risks and biases of artificial
intelligence (AI) algorithms, these algorithms can disproportionately impact
culturally marginalized groups. A range of approaches has been proposed to
address or reduce these risks, including the development of ethical guidelines
and principles for responsible AI, as well as technical solutions that promote
algorithmic fairness. Drawing on design justice, expansive learning theory, and
recent empirical work on participatory AI, we argue that mitigating these harms
requires a fundamental re-architecture of the AI production pipeline. This
re-design should center co-production, diversity, equity, inclusion (DEI), and
multidisciplinary collaboration. We introduce an augmented AI lifecycle
consisting of five interconnected phases: co-framing, co-design,
co-implementation, co-deployment, and co-maintenance. The lifecycle is informed
by four multidisciplinary workshops and grounded in themes of distributed
authority and iterative knowledge exchange. Finally, we relate the proposed
lifecycle to several leading ethical frameworks and outline key research
questions that remain for scaling participatory governance.

</details>


### [58] [Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation](https://arxiv.org/abs/2508.00143)
*Danielle R. Thomas,Conrad Borchers,Kenneth R. Koedinger*

Main category: cs.AI

TL;DR: 本文质疑传统评分者间一致性(IRR)作为教育AI数据标注质量的唯一标准，提出五种补充评估方法以提升数据有效性和学习效果。


<details>
  <summary>Details</summary>
Motivation: 人类评估者存在偏见和不可靠性，但教育AI领域仍过度依赖IRR指标（如Cohen's kappa）作为标注质量的'黄金标准'，这阻碍了有效学习数据的分类进展。

Method: 提出五种替代方案：多标签标注方案、专家评估法、闭环验证法，并强调外部效度（如验证辅导行为分类的跨类别普适性）。

Result: 这些方法能比单纯IRR产生更有效的训练数据、提升模型性能，并为学习改进提供更可操作的洞察。

Conclusion: 呼吁教育AI领域重新思考标注质量的定义，将教育影响力和效度置于评分者共识之上。

Abstract: Humans can be notoriously imperfect evaluators. They are often biased,
unreliable, and unfit to define "ground truth." Yet, given the surging need to
produce large amounts of training data in educational applications using AI,
traditional inter-rater reliability (IRR) metrics like Cohen's kappa remain
central to validating labeled data. IRR remains a cornerstone of many machine
learning pipelines for educational data. Take, for example, the classification
of tutors' moves in dialogues or labeling open responses in machine-graded
assessments. This position paper argues that overreliance on human IRR as a
gatekeeper for annotation quality hampers progress in classifying data in ways
that are valid and predictive in relation to improving learning. To address
this issue, we highlight five examples of complementary evaluation methods,
such as multi-label annotation schemes, expert-based approaches, and
close-the-loop validity. We argue that these approaches are in a better
position to produce training data and subsequent models that produce improved
student learning and more actionable insights than IRR approaches alone. We
also emphasize the importance of external validity, for example, by
establishing a procedure of validating tutor moves and demonstrating that it
works across many categories of tutor actions (e.g., providing hints). We call
on the field to rethink annotation quality and ground truth--prioritizing
validity and educational impact over consensus alone.

</details>


### [59] [Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power](https://arxiv.org/abs/2508.00159)
*Jobst Heitzig,Ram Potham*

Main category: cs.AI

TL;DR: 本文探讨通过强制AI系统明确赋能人类并管理人机权力平衡来提升安全与福祉。提出一种参数化、可分解的目标函数，考虑人类有限理性与社会规范，并通过逆向归纳或多智能体强化学习计算该指标。


<details>
  <summary>Details</summary>
Motivation: 权力是AI安全的核心概念，涉及AI作为工具性目标的权力追求、人类权力的逐步丧失以及人机交互与国际治理中的权力平衡。同时，权力作为实现多元目标的能力对福祉至关重要。

Method: 采用部分公理化方法设计参数化目标函数，表征长期人类权力的不平等厌恶与风险厌恶聚合。通过逆向归纳或基于世界模型的多智能体强化学习近似计算该指标。

Result: 在多种范式情境中展示（软）最大化该指标的后果，揭示其可能隐含的工具性子目标。表明合适的权力聚合指标可能比直接效用目标更安全。

Conclusion: 谨慎评估认为，软最大化人类权力聚合指标可能构成比直接效用目标更安全的AI系统目标，但需进一步验证其实际效果与局限性。

Abstract: Power is a key concept in AI safety: power-seeking as an instrumental goal,
sudden or gradual disempowerment of humans, power balance in human-AI
interaction and international AI governance. At the same time, power as the
ability to pursue diverse goals is essential for wellbeing.
  This paper explores the idea of promoting both safety and wellbeing by
forcing AI agents explicitly to empower humans and to manage the power balance
between humans and AI agents in a desirable way. Using a principled, partially
axiomatic approach, we design a parametrizable and decomposable objective
function that represents an inequality- and risk-averse long-term aggregate of
human power. It takes into account humans' bounded rationality and social
norms, and, crucially, considers a wide variety of possible human goals.
  We derive algorithms for computing that metric by backward induction or
approximating it via a form of multi-agent reinforcement learning from a given
world model. We exemplify the consequences of (softly) maximizing this metric
in a variety of paradigmatic situations and describe what instrumental
sub-goals it will likely imply. Our cautious assessment is that softly
maximizing suitable aggregate metrics of human power might constitute a
beneficial objective for agentic AI systems that is safer than direct
utility-based objectives.

</details>


### [60] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
*Yihong Dong,Xue Jiang,Yongding Tao,Huanyu Liu,Kechi Zhang,Lili Mou,Rongyu Cao,Yingwei Ma,Jue Chen,Binhua Li,Zhi Jin,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.AI

TL;DR: RL-PLUS是一种结合内部思考与外部数据的新方法，通过多重重要性采样和探索优势函数，突破了大语言模型的能力边界，在数学推理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法因固有的策略限制和大语言模型的巨大动作空间及稀疏奖励，难以突破基础模型的能力边界，甚至导致能力边界崩溃。

Method: RL-PLUS整合了多重重要性采样以解决外部数据分布不匹配问题，并采用探索优势函数引导模型探索高价值推理路径。

Result: RL-PLUS在六个数学推理基准测试中达到最先进水平，在分布外任务中表现优异，相对改进幅度达21.1\%至69.2\%，有效解决了能力边界崩溃问题。

Conclusion: RL-PLUS通过结合内部思考与外部数据，显著提升了大语言模型的推理能力，突破了基础模型的固有局限。

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has significantly
advanced the complex reasoning abilities of Large Language Models (LLMs).
However, it struggles to break through the inherent capability boundaries of
the base LLM, due to its inherently on-policy strategy with LLM's immense
action space and sparse reward. Further, RLVR can lead to the capability
boundary collapse, narrowing the LLM's problem-solving scope. To address this
problem, we propose RL-PLUS, a novel approach that synergizes internal
exploitation (i.e., Thinking) with external data (i.e., Learning) to achieve
stronger reasoning capabilities and surpass the boundaries of base models.
RL-PLUS integrates two core components: Multiple Importance Sampling to address
for distributional mismatch from external data, and an Exploration-Based
Advantage Function to guide the model towards high-value, unexplored reasoning
paths. We provide both theoretical analysis and extensive experiments to
demonstrate the superiority and generalizability of our approach. The results
show that RL-PLUS achieves state-of-the-art performance compared with existing
RLVR methods on six math reasoning benchmarks and exhibits superior performance
on six out-of-distribution reasoning tasks. It also achieves consistent and
significant gains across diverse model families, with average relative
improvements ranging from 21.1\% to 69.2\%. Moreover, Pass@k curves across
multiple benchmarks indicate that RL-PLUS effectively resolves the capability
boundary collapse problem.

</details>


### [61] [MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning](https://arxiv.org/abs/2508.00271)
*Hongjin Qian,Zheng Liu*

Main category: cs.AI

TL;DR: 本文提出MetaAgent，一种通过实践学习和持续自我改进的智能体范式，能够在知识发现任务中动态优化其推理和工具使用策略，无需调整模型参数或额外训练。


<details>
  <summary>Details</summary>
Motivation: 受“做中学”原则启发，旨在开发一种能够通过持续实践和自我改进提升专业能力的智能体系统，以应对复杂知识发现任务。

Method: MetaAgent从最小工作流起步，具备基础推理和自适应求助能力；通过生成自然语言帮助请求并路由至合适的外部工具，结合自我反思与答案验证，将经验动态整合到后续任务中；同时自主构建内部工具和持久知识库，实现持续的元工具学习（\textit{meta tool learning}）。

Result: 在GAIA、WebWalkerQA和BrowseCamp等知识发现基准测试中，MetaAgent表现优于基于工作流的基线方法，并与端到端训练智能体相当或更优，验证了其自我进化能力。

Conclusion: MetaAgent展示了自进化智能体系统在鲁棒、通用知识发现中的潜力，其开源代码已发布（https://github.com/qhjqhj00/MetaAgent）。

Abstract: In this work, we propose MetaAgent, an agentic paradigm inspired by the
principle of learning-by-doing, where expertise is developed through hands-on
practice and continual self-improvement. MetaAgent starts with a minimal
workflow, equipped only with basic reasoning and adaptive help-seeking
abilities. When a knowledge gap is encountered, MetaAgent generates natural
language help requests, which are routed to the most suitable external tool by
a dedicated tool router. As MetaAgent solves tasks, it continually conducts
self-reflection and answer verification, distilling actionable experience into
concise texts that are dynamically incorporated into future task contexts.
Besides, MetaAgent autonomously builds in-house tools and a persistent
knowledge base by organizing its tool-use history, further enhancing its
ability to retrieve and integrate relevant information We term this continual,
data-driven process as \textit{meta tool learning}, through which MetaAgent
incrementally refines its reasoning and tool-use strategies, without changing
model parameters or requiring further post-training. Evaluated on challenging
knowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,
MetaAgent consistently outperforms workflow-based baselines and matches or
exceeds end-to-end trained agents, demonstrating the promise of self-evolving
agentic systems for robust, general-purpose knowledge discovery. We provide our
source codes in https://github.com/qhjqhj00/MetaAgent.

</details>


### [62] [Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](https://arxiv.org/abs/2508.00282)
*Yi-Long Lu,Jiajun Song,Chunhui Zhang,Wei Wang*

Main category: cs.AI

TL;DR: 研究比较了人类与LLM代理（GPT-4o）的任务生成行为，发现人类任务受心理驱动因素（如个人价值观和认知风格）显著影响，而LLM即使获得相同驱动因素也无法复现人类行为模式，其生成的任务更抽象、社交性和实体性更低。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI代理（如LLM）是否能基于与人类相似的内在认知原则（如心理驱动因素）产生多样化任务，揭示其与人类认知的核心差异。

Method: 通过任务生成实验，对比人类与GPT-4o在相同心理驱动因素（如个人价值观、认知风格）下的任务生成差异，分析行为模式及主题偏好。

Result: LLM生成的任务社交性、实体性显著低于人类，且主题偏向抽象化；尽管其任务被评价为更有趣新颖，但无法体现人类价值观驱动的具身认知特性。

Conclusion: 人类基于价值观的具身认知与LLM的统计模式存在本质差异，未来需将内在动机和物理 grounding 融入AI设计以实现更人类对齐的代理。

Abstract: Humans constantly generate a diverse range of tasks guided by internal
motivations. While generative agents powered by large language models (LLMs)
aim to simulate this complex behavior, it remains uncertain whether they
operate on similar cognitive principles. To address this, we conducted a
task-generation experiment comparing human responses with those of an LLM agent
(GPT-4o). We find that human task generation is consistently influenced by
psychological drivers, including personal values (e.g., Openness to Change) and
cognitive style. Even when these psychological drivers are explicitly provided
to the LLM, it fails to reflect the corresponding behavioral patterns. They
produce tasks that are markedly less social, less physical, and thematically
biased toward abstraction. Interestingly, while the LLM's tasks were perceived
as more fun and novel, this highlights a disconnect between its linguistic
proficiency and its capacity to generate human-like, embodied goals.We conclude
that there is a core gap between the value-driven, embodied nature of human
cognition and the statistical patterns of LLMs, highlighting the necessity of
incorporating intrinsic motivation and physical grounding into the design of
more human-aligned agents.

</details>


### [63] [Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning](https://arxiv.org/abs/2508.00323)
*Jianyi Zhang,Xu Ji,Ziyin Zhou,Yuchen Zhou,Shubo Shi,Haoyu Wu,Zhen Li,Shizhao Liu*

Main category: cs.AI

TL;DR: 提出首个专注于结构化图形推理任务的评估基准ReasonBench，涵盖1613道真实智力测试题，评测11种主流视觉语言模型（VLM），揭示其显著局限性，并通过双重优化策略将模型性能提升33.5\%。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLM）在复杂图形推理和抽象问题解决方面存在明显不足，且现有研究仅关注简单图形，亟需建立全面评估体系以推动模型能力提升。

Method: 构建ReasonBench基准（含位置、属性、数量及多元素推理任务），提出双重优化策略：分层分解的图解推理链（DiaCoT）增强可解释性，训练驱动的ReasonTune提升任务适应性。

Result: 测试11种主流VLM显示现有模型存在显著缺陷，优化策略使整体性能提升33.5\%，所有实验数据与代码已开源。

Conclusion: ReasonBench填补了复杂图形推理评估的空白，双重优化策略有效提升VLM性能，为未来研究提供标准化测试框架与改进方向。

Abstract: Evaluating the performance of visual language models (VLMs) in graphic
reasoning tasks has become an important research topic. However, VLMs still
show obvious deficiencies in simulating human-level graphic reasoning
capabilities, especially in complex graphic reasoning and abstract problem
solving, which are less studied and existing studies only focus on simple
graphics. To evaluate the performance of VLMs in complex graphic reasoning, we
propose ReasonBench, the first evaluation benchmark focused on structured
graphic reasoning tasks, which includes 1,613 questions from real-world
intelligence tests. ReasonBench covers reasoning dimensions related to
location, attribute, quantity, and multi-element tasks, providing a
comprehensive evaluation of the performance of VLMs in spatial, relational, and
abstract reasoning capabilities. We benchmark 11 mainstream VLMs (including
closed-source and open-source models) and reveal significant limitations of
current models. Based on these findings, we propose a dual optimization
strategy: Diagrammatic Reasoning Chain (DiaCoT) enhances the interpretability
of reasoning by decomposing layers, and ReasonTune enhances the task
adaptability of model reasoning through training, all of which improves VLM
performance by 33.5\%. All experimental data and code are in the repository:
https://huggingface.co/datasets/cistine/ReasonBench.

</details>


### [64] [R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge](https://arxiv.org/abs/2508.00324)
*Yeonjun In,Wonjoong Kim,Sangwu Park,Chanyoung Park*

Main category: cs.AI

TL;DR: 本文提出R1-Act方法，通过结构化推理过程显式触发大型推理模型（LRM）的安全知识，仅需少量训练即可显著提升安全性且不影响推理性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型在复杂任务上表现优异，但研究发现其常遵循有害指令，存在严重安全隐患。模型已具备安全知识但推理时未能激活，这是安全风险的根本原因。

Method: 提出R1-Act后训练方法：通过结构化推理过程显式触发模型内建的安全知识，仅需1,000个训练样本和单块RTX A6000显卡90分钟训练。

Result: R1-Act在多种LRM架构和规模上验证有效，安全性能显著提升且推理能力无损，效果优于现有对齐方法，具有强鲁棒性、可扩展性和实用效率。

Conclusion: 该研究表明显式激活模型已有安全知识是提升LRM安全性的有效途径，R1-Act以极低训练成本实现了安全与性能的平衡。

Abstract: Although large reasoning models (LRMs) have demonstrated impressive
capabilities on complex tasks, recent studies reveal that these models
frequently fulfill harmful user instructions, raising significant safety
concerns. In this paper, we investigate the underlying cause of LRM safety
risks and find that models already possess sufficient safety knowledge but fail
to activate it during reasoning. Based on this insight, we propose R1-Act, a
simple and efficient post-training method that explicitly triggers safety
knowledge through a structured reasoning process. R1-Act achieves strong safety
improvements while preserving reasoning performance, outperforming prior
alignment methods. Notably, it requires only 1,000 training examples and 90
minutes of training on a single RTX A6000 GPU. Extensive experiments across
multiple LRM backbones and sizes demonstrate the robustness, scalability, and
practical efficiency of our approach.

</details>


### [65] [CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding](https://arxiv.org/abs/2508.00378)
*Shixin Yi,Lin Shang*

Main category: cs.AI

TL;DR: 本文提出CoRGI框架，通过视觉验证机制解决视觉语言模型推理中的幻觉问题，提升多模态推理的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有思维链(CoT)方法在视觉语言模型(VLMs)中常产生与视觉内容脱节的流畅解释，缺乏验证机制导致推理不可靠。

Method: CoRGI采用三阶段流程：1)生成文本推理链；2)通过专用模块(VEVM)提取每步视觉证据；3)融合文本推理与视觉证据生成可验证答案，无需端到端重训练即可集成现有VLM。

Result: 在VCR基准测试中，CoRGI显著提升Qwen-2.5VL和LLaVA-1.6的性能，人工评估证实其解释更具事实性与实用性，消融实验验证各模块贡献。

Conclusion: 研究证明将中间推理步骤锚定于视觉证据对增强多模态推理至关重要，同时探讨了事后验证框架的潜在局限性。

Abstract: Chain-of-Thought (CoT) prompting has shown promise in improving reasoning in
vision-language models (VLMs), but it often produces explanations that are
linguistically fluent yet lack grounding in visual content. We observe that
such hallucinations arise in part from the absence of an explicit verification
mechanism during multi-step reasoning. To address this, we propose
\textbf{CoRGI}(\textbf{C}hain \textbf{o}f \textbf{R}easoning with
\textbf{G}rounded \textbf{I}nsights), a modular framework that introduces
visual verification into the reasoning process. CoRGI follows a three-stage
pipeline: it first generates a textual reasoning chain, then extracts
supporting visual evidence for each reasoning step via a dedicated module
(VEVM), and finally synthesizes the textual rationale with visual evidence to
generate a grounded, verified answer. The framework can be integrated with
existing VLMs without end-to-end retraining. We evaluate CoRGI on the VCR
benchmark and find that it improves reasoning performance on two representative
open-source VLM backbones, Qwen-2.5VL and LLaVA-1.6. Ablation studies confirm
the contribution of each step in the verification module, and human evaluations
suggest that CoRGI leads to more factual and helpful explanations. We also
examine alternative designs for the visual verification step and discuss
potential limitations of post-hoc verification frameworks. These findings
highlight the importance of grounding intermediate reasoning steps in visual
evidence to enhance the robustness of multimodal reasoning.

</details>


### [66] [Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation](https://arxiv.org/abs/2508.00401)
*Riddhi J. Pitliya,Ozan Catal,Toon Van de Maele,Corrado Pezzato,Tim Verbelen*

Main category: cs.AI

TL;DR: 本文提出了一种基于心智理论（ToM）的多智能体协作新方法，通过主动推理框架实现智能体对他人信念的推理，无需任务特定的共享生成模型或显式通信，在避碰和觅食任务中表现出更优的协作能力。


<details>
  <summary>Details</summary>
Motivation: 现有主动推理方法依赖特定任务的共享模型或显式通信，限制了多智能体协作的通用性。心智理论使智能体能理解他人的知识与目标差异，为通用协作提供了新思路。

Method: 在主动推理框架中嵌入ToM机制，智能体分别维护自身与他人的信念/目标表征，扩展基于推理树的规划算法，通过递归推理系统探索联合策略空间。

Result: 仿真实验表明：ToM智能体通过观察行为推断他人信念，在避碰任务中减少碰撞，觅食任务中降低冗余劳动，协作效果显著优于非ToM智能体。

Conclusion: 该工作不仅推进了人工智能的实用化，为多智能体系统提供通用协作框架，同时为心智理论的计算建模提供了新见解。

Abstract: We present a novel approach to multi-agent cooperation by implementing theory
of mind (ToM) within active inference. ToM - the ability to understand that
others can have differing knowledge and goals - enables agents to reason about
others' beliefs while planning their own actions. Unlike previous active
inference approaches to multi-agent cooperation, our method neither relies on
task-specific shared generative models nor requires explicit communication,
while being generalisable. In our framework, the ToM-equipped agent maintains
distinct representations of its own and others' beliefs and goals. We extend
the sophisticated inference tree-based planning algorithm to systematically
explore joint policy spaces through recursive reasoning. Our approach is
evaluated through collision avoidance and foraging task simulations. Results
demonstrate that ToM-equipped agents cooperate better compared to non-ToM
counterparts by being able to avoid collisions and reduce redundant efforts.
Crucially, ToM agents accomplish this by inferring others' beliefs solely from
observable behaviour. This work advances practical applications in artificial
intelligence while providing computational insights into ToM.

</details>


### [67] [Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](https://arxiv.org/abs/2508.00414)
*Tianqing Fang,Zhisong Zhang,Xiaoyang Wang,Rui Wang,Can Qin,Yuxuan Wan,Jun-Yu Ma,Ce Zhang,Jiaqi Chen,Xiyun Li,Hongming Zhang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: 本文介绍了开源免费的多模块AI代理框架Cognitive Kernel-Pro，旨在推动高级AI代理的民主化开发与评估，并在GAIA基准测试中取得开源代理的最优性能。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理系统多为闭源或依赖付费API，限制了研究社区的可访问性与可复现性。本文旨在通过开源框架解决这一问题。

Method: 提出Cognitive Kernel-Pro框架，系统研究高质量训练数据的构建（包括查询、轨迹和可验证答案），并探索代理测试时的反思与投票策略以增强鲁棒性。

Result: 在GAIA基准测试中，8B参数的开源模型超越WebDancer等先前领先系统，为可访问的高性能AI代理树立新标杆。

Conclusion: Cognitive Kernel-Pro框架通过开源免费方式成功提升了AI代理的性能与可及性，代码已发布于https://github.com/Tencent/CognitiveKernel-Pro。

Abstract: General AI Agents are increasingly recognized as foundational frameworks for
the next generation of artificial intelligence, enabling complex reasoning, web
interaction, coding, and autonomous research capabilities. However, current
agent systems are either closed-source or heavily reliant on a variety of paid
APIs and proprietary tools, limiting accessibility and reproducibility for the
research community. In this work, we present \textbf{Cognitive Kernel-Pro}, a
fully open-source and (to the maximum extent) free multi-module agent framework
designed to democratize the development and evaluation of advanced AI agents.
Within Cognitive Kernel-Pro, we systematically investigate the curation of
high-quality training data for Agent Foundation Models, focusing on the
construction of queries, trajectories, and verifiable answers across four key
domains: web, file, code, and general reasoning. Furthermore, we explore novel
strategies for agent test-time reflection and voting to enhance agent
robustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving
state-of-the-art results among open-source and free agents. Notably, our
8B-parameter open-source model surpasses previous leading systems such as
WebDancer and WebSailor, establishing a new performance standard for
accessible, high-capability AI agents. Code is available at
https://github.com/Tencent/CognitiveKernel-Pro

</details>


### [68] [Thinking Machines: Mathematical Reasoning in the Age of LLMs](https://arxiv.org/abs/2508.00459)
*Andrea Asperti,Alberto Naibo,Claudio Sacerdoti Coen*

Main category: cs.AI

TL;DR: 大语言模型(LLM)在结构化推理与符号任务(如编程)中表现优异,但在形式化数学(如定理证明)领域进展缓慢。本文探讨了LLM数学推理的三大核心问题:形式/非形式数学训练的权衡、证明生成比代码合成更脆弱的原因,以及LLM是否真正具备逻辑状态表征能力。


<details>
  <summary>Details</summary>
Motivation: 尽管编程与数学证明存在表面相似性,LLM在形式数学领域表现显著落后,这引发了对模型推理机制、监督方式及内部状态表征的根本性质疑。研究旨在厘清当前技术边界及潜在突破方向。

Method: 通过分析领域最新模型与基准测试,从机器学习与数学认知交叉视角,系统研究:(i)形式/非形式数学训练效果差异;(ii)证明生成脆弱性的深层原因;(iii)LLM对逻辑状态的表征本质。

Result: 发现形式数学训练存在显著挑战:证明生成需要持续维护演绎状态,而当前LLM可能仅模仿而非真正表征逻辑状态。代码合成的容错性与数学证明的精确性要求存在根本差异。

Conclusion: 研究未划定硬性边界,但明确了当前LLM数学推理的三大瓶颈:训练数据形式化程度、状态表征真实性及证明严格性要求。突破这些限制需重新思考模型架构与训练范式。

Abstract: Large Language Models (LLMs) have shown remarkable abilities in structured
reasoning and symbolic tasks, with coding emerging as a particular area of
strength. This success has sparked growing interest in applying LLMs to
mathematics, both in informal problem-solving and formal theorem proving.
However, progress in formal mathematics has proven to be significantly more
difficult, despite surface-level similarities between programming and proof
construction. This discrepancy raises important questions about how LLMs
``reason'', how they are supervised, and whether they internally track a notion
of computational or deductive state. In this article, we address the
state-of-the-art of the discipline, focusing on recent models and benchmarks,
and explore three central issues at the intersection of machine learning and
mathematical cognition: (i) the trade-offs between formal and informal
mathematics as training domains; (ii) the deeper reasons why proof generation
remains more brittle than code synthesis; (iii) and the question of whether
LLMs represent, or merely mimic, a notion of evolving logical state. Our goal
is not to draw hard boundaries, but to identify where the current limits lie,
and how they might be extended.

</details>


### [69] [Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking](https://arxiv.org/abs/2508.00500)
*Haoyu Wang,Chris M. Poskitt,Jun Sun,Jiali Wei*

Main category: cs.AI

TL;DR: 本文提出Pro2Guard框架，通过概率可达性分析主动预测大语言模型代理的安全风险，在风险发生前进行干预，显著提升安全性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于规则的被动安全系统（如AgentSpec）无法预见长期依赖和分布偏移导致的安全风险，亟需一种主动预防的运行时安全框架。

Method: Pro2Guard将代理行为抽象为符号状态，从执行轨迹学习离散时间马尔可夫链（DTMC），通过计算到达不安全状态的概率进行风险预测，并引入语义有效性检查和PAC边界保证统计可靠性。

Result: 在家庭具身代理任务中提前阻止93.6%的不安全任务（低阈值时），可配置模式下保持80.4%任务完成率；在自动驾驶场景实现100%交通违规/碰撞预测，最长提前38.66秒预警。

Conclusion: Pro2Guard通过概率可达性分析实现了主动安全防护，在保持任务完成率的同时显著降低风险，为LLM代理的安全部署提供新范式。

Abstract: Large Language Model (LLM) agents exhibit powerful autonomous capabilities
across domains such as robotics, virtual assistants, and web automation.
However, their stochastic behavior introduces significant safety risks that are
difficult to anticipate. Existing rule-based enforcement systems, such as
AgentSpec, focus on developing reactive safety rules, which typically respond
only when unsafe behavior is imminent or has already occurred. These systems
lack foresight and struggle with long-horizon dependencies and distribution
shifts. To address these limitations, we propose Pro2Guard, a proactive runtime
enforcement framework grounded in probabilistic reachability analysis.
Pro2Guard abstracts agent behaviors into symbolic states and learns a
Discrete-Time Markov Chain (DTMC) from execution traces. At runtime, it
anticipates future risks by estimating the probability of reaching unsafe
states, triggering interventions before violations occur when the predicted
risk exceeds a user-defined threshold. By incorporating semantic validity
checks and leveraging PAC bounds, Pro2Guard ensures statistical reliability
while approximating the underlying ground-truth model. We evaluate Pro2Guard
extensively across two safety-critical domains: embodied household agents and
autonomous vehicles. In embodied agent tasks, Pro2Guard enforces safety early
on up to 93.6% of unsafe tasks using low thresholds, while configurable modes
(e.g., reflect) allow balancing safety with task success, maintaining up to
80.4% task completion. In autonomous driving scenarios, Pro2Guard achieves 100%
prediction of traffic law violations and collisions, anticipating risks up to
38.66 seconds ahead.

</details>


### [70] [MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal Interactions in Multimodal AI Models](https://arxiv.org/abs/2508.00576)
*Zhanliang Wang,Kai Wang*

Main category: cs.AI

TL;DR: 本文提出MultiSHAP框架，通过Shapley交互指数量化多模态AI模型中视觉与文本元素的协同效应，解决现有方法无法精确解释跨模态交互的局限性，适用于开源和闭源模型。


<details>
  <summary>Details</summary>
Motivation: 多模态AI模型在需要整合视觉与语言等跨模态信息的任务中表现优异，但其'黑盒'特性阻碍了在高风险应用中的部署，现有解释方法无法精确量化模态间协同效应且仅适用于开源模型。

Method: MultiSHAP利用Shapley交互指数，将多模态预测归因于细粒度视觉元素（如图像块）与文本元素（如文本标记）的成对交互，提供实例级（解释特定预测）和数据集级（揭示跨模态整合模式）的双重解释。

Result: 在公开多模态基准测试中，MultiSHAP可靠地捕捉了跨模态推理机制；真实案例研究验证了其实用性，且框架可扩展至两种以上模态。

Conclusion: 该框架为解释复杂多模态AI模型提供了通用解决方案，兼具精确的交互量化能力与模型无关的适用性，推动了可解释多模态AI的发展。

Abstract: Multimodal AI models have achieved impressive performance in tasks that
require integrating information from multiple modalities, such as vision and
language. However, their "black-box" nature poses a major barrier to deployment
in high-stakes applications where interpretability and trustworthiness are
essential. How to explain cross-modal interactions in multimodal AI models
remains a major challenge. While existing model explanation methods, such as
attention map and Grad-CAM, offer coarse insights into cross-modal
relationships, they cannot precisely quantify the synergistic effects between
modalities, and are limited to open-source models with accessible internal
weights. Here we introduce MultiSHAP, a model-agnostic interpretability
framework that leverages the Shapley Interaction Index to attribute multimodal
predictions to pairwise interactions between fine-grained visual and textual
elements (such as image patches and text tokens), while being applicable to
both open- and closed-source models. Our approach provides: (1) instance-level
explanations that reveal synergistic and suppressive cross-modal effects for
individual samples - "why the model makes a specific prediction on this input",
and (2) dataset-level explanation that uncovers generalizable interaction
patterns across samples - "how the model integrates information across
modalities". Experiments on public multimodal benchmarks confirm that MultiSHAP
faithfully captures cross-modal reasoning mechanisms, while real-world case
studies demonstrate its practical utility. Our framework is extensible beyond
two modalities, offering a general solution for interpreting complex multimodal
AI models.

</details>


### [71] [From EMR Data to Clinical Insight: An LLM-Driven Framework for Automated Pre-Consultation Questionnaire Generation](https://arxiv.org/abs/2508.00581)
*Ruiqing Ding,Qianfang Sun,Yongkang Leng,Hui Yin,Xiaojian Li*

Main category: cs.AI

TL;DR: 提出一种多阶段LLM驱动框架，通过提取EMR原子断言、构建因果网络和生成定制问卷，显著提升预咨询问卷的信息完整性与临床相关性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法直接从复杂电子病历生成预咨询问卷时，存在信息完整性、逻辑顺序和疾病层面综合的困难，需结构化临床知识来解决。

Method: 三阶段框架：1) 从EMR提取带时间的关键事实；2) 构建个人因果网络并聚类生成疾病知识；3) 基于结构化表征生成个性化与标准化问卷。

Result: 真实EMR数据集与临床专家验证表明，该方法在信息覆盖度、诊断相关性、可理解性和生成时间上均优于直接方法。

Conclusion: 该框架通过显式构建临床知识，有效提升预咨询效率，展现了优化患者信息采集的实际应用潜力。

Abstract: Pre-consultation is a critical component of effective healthcare delivery.
However, generating comprehensive pre-consultation questionnaires from complex,
voluminous Electronic Medical Records (EMRs) is a challenging task. Direct
Large Language Model (LLM) approaches face difficulties in this task,
particularly regarding information completeness, logical order, and
disease-level synthesis. To address this issue, we propose a novel multi-stage
LLM-driven framework: Stage 1 extracts atomic assertions (key facts with
timing) from EMRs; Stage 2 constructs personal causal networks and synthesizes
disease knowledge by clustering representative networks from an EMR corpus;
Stage 3 generates tailored personal and standardized disease-specific
questionnaires based on these structured representations. This framework
overcomes limitations of direct methods by building explicit clinical
knowledge. Evaluated on a real-world EMR dataset and validated by clinical
experts, our method demonstrates superior performance in information coverage,
diagnostic relevance, understandability, and generation time, highlighting its
practical potential to enhance patient information collection.

</details>


### [72] [Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings](https://arxiv.org/abs/2508.00632)
*Alexia Jolicoeur-Martineau*

Main category: cs.AI

TL;DR: 论文提出AVR-Eval评估指标和AVR-Agent多智能体系统，用于生成和优化交互式音视频内容（如游戏）。实验表明，AVR-Agent生成的内容质量显著优于单次生成，但当前模型无法有效利用定制素材和音视频反馈。


<details>
  <summary>Details</summary>
Motivation: 当前AI虽能生成文本、音频、图像和视频，但创建交互式音视频内容（如游戏）仍具挑战性。现有LLM缺乏自动化评估指标，且难以处理需要人类团队数月协作的复杂内容。

Method: 1) 提出AVR-Eval评估指标：通过全模态模型比较两段内容的音视频记录（AVR），结合文本模型判定优劣；2) 开发AVR-Agent系统：从多媒体素材库生成JavaScript代码，通过迭代优化和AVR反馈提升内容质量。

Result: AVR-Agent生成的内容在对比实验中胜率显著高于单次生成内容（通过AVR-Eval衡量）。但模型未能有效利用定制素材和AVR反馈，胜率未体现优势。

Conclusion: 研究表明，人类与机器在内容创作上存在根本差异：人类能高效利用高质量素材和音视频反馈，而当前编码模型尚未具备同等能力。这揭示了AI生成交互内容的关键瓶颈。

Abstract: While AI excels at generating text, audio, images, and videos, creating
interactive audio-visual content such as video games remains challenging.
Current LLMs can generate JavaScript games and animations, but lack automated
evaluation metrics and struggle with complex content that normally requires
teams of humans working for many months (multi-shot, multi-agents) using assets
made by artists. To tackle these issues, we built a new metric and a
multi-agent system.
  We propose AVR-Eval, a relative metric for multimedia content quality using
Audio-Visual Recordings (AVRs). An omni-modal model (processing text, video,
and audio) compares the AVRs of two contents, with a text model reviewing
evaluations to determine superiority. We show that AVR-Eval properly identifies
good from broken or mismatched content.
  We built AVR-Agent, a multi-agent system generating JavaScript code from a
bank of multimedia assets (audio, images, 3D models). The coding agent selects
relevant assets, generates multiple initial codes, uses AVR-Eval to identify
the best version, and iteratively improves it through omni-modal agent feedback
from the AVR.
  We run experiments on games and animations with AVR-Eval (win rate of content
A against B). We find that content generated by AVR-Agent has a significantly
higher win rate against content made through one-shot generation. However,
models struggle to leverage custom assets and AVR feedback effectively, showing
no higher win rate. This reveals a critical gap: while humans benefit from
high-quality assets and audio-visual feedback, current coding models do not
seem to utilize these resources as effectively, highlighting fundamental
differences between human and machine content creation approaches.

</details>


### [73] [Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies](https://arxiv.org/abs/2508.00658)
*Chakattrai Sookkongwaree,Tattep Lakmuang,Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: 本文提出了一种多频带变滞后格兰杰因果性（MB-VLGC）框架，通过显式建模频率依赖性因果延迟，解决了传统方法在复杂系统中的局限性，并在多领域实验中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统格兰杰因果性方法存在固定滞后假设的局限性，而现有变滞后方法（VLGC）未能考虑不同频带间的因果延迟差异，例如脑信号中不同频段活动的延迟差异。

Method: 作者提出了MB-VLGC框架，扩展了传统VLGC，通过形式化定义多频带因果延迟并设计高效推断流程，实现了对频率依赖性延迟的显式建模。

Result: 在合成和真实数据集上的大量实验表明，MB-VLGC显著优于现有方法，验证了其在各类时间序列数据中的广泛适用性。

Conclusion: MB-VLGC框架通过整合频带特异性延迟，为复杂系统中的因果推理提供了更通用的解决方案，代码和数据集已开源。

Abstract: Understanding causal relationships in time series is fundamental to many
domains, including neuroscience, economics, and behavioral science. Granger
causality is one of the well-known techniques for inferring causality in time
series. Typically, Granger causality frameworks have a strong fix-lag
assumption between cause and effect, which is often unrealistic in complex
systems. While recent work on variable-lag Granger causality (VLGC) addresses
this limitation by allowing a cause to influence an effect with different time
lags at each time point, it fails to account for the fact that causal
interactions may vary not only in time delay but also across frequency bands.
For example, in brain signals, alpha-band activity may influence another region
with a shorter delay than slower delta-band oscillations. In this work, we
formalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a
novel framework that generalizes traditional VLGC by explicitly modeling
frequency-dependent causal delays. We provide a formal definition of MB-VLGC,
demonstrate its theoretical soundness, and propose an efficient inference
pipeline. Extensive experiments across multiple domains demonstrate that our
framework significantly outperforms existing methods on both synthetic and
real-world datasets, confirming its broad applicability to any type of time
series data. Code and datasets are publicly available.

</details>


### [74] [Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI](https://arxiv.org/abs/2508.00665)
*Maryam Mosleh,Marie Devlin,Ellis Solaiman*

Main category: cs.AI

TL;DR: 本文提出了一种结合传统可解释AI技术与生成式AI模型及用户个性化的混合框架，旨在为教育领域提供多模态、个性化的解释，增强AI决策的透明度。


<details>
  <summary>Details</summary>
Motivation: 当前AI驱动的自适应学习系统缺乏透明度，且多数可解释AI技术忽视用户角色与理解能力，亟需一种更用户中心化的解释方法。

Method: 通过整合传统XAI技术、生成式AI模型和用户个性化设置，构建动态解释框架，根据用户角色和学习目标生成定制化多模态解释。

Result: 框架重新定义可解释性为动态沟通过程，并指明教育领域XAI在准确性、公平性和个性化方面的研究方向。

Conclusion: 该研究推动可解释AI向增强透明度与支持用户体验的方向发展，实现真正以用户为中心的教育AI系统。

Abstract: Artificial intelligence-driven adaptive learning systems are reshaping
education through data-driven adaptation of learning experiences. Yet many of
these systems lack transparency, offering limited insight into how decisions
are made. Most explainable AI (XAI) techniques focus on technical outputs but
neglect user roles and comprehension. This paper proposes a hybrid framework
that integrates traditional XAI techniques with generative AI models and user
personalisation to generate multimodal, personalised explanations tailored to
user needs. We redefine explainability as a dynamic communication process
tailored to user roles and learning goals. We outline the framework's design,
key XAI limitations in education, and research directions on accuracy,
fairness, and personalisation. Our aim is to move towards explainable AI that
enhances transparency while supporting user-centred experiences.

</details>


### [75] [Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations](https://arxiv.org/abs/2508.00674)
*Banan Alkhateeb,Ellis Solaiman*

Main category: cs.AI

TL;DR: 本文提出了一种用户分群的情境感知可视化解释系统，通过多样化解释方法提升社交媒体AI推荐的透明度，首次实现解释风格（视觉/数字）与粒度（专家/普通用户）的联合适配。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体AI推荐因解释泛化且不符合用户需求，导致推荐价值丧失。缺乏个性化解释阻碍了用户理解与信任。

Method: 构建用户需求导向的可视化解释框架，包含技术细节版（面向AI专家）和简化版（面向普通用户）的双模式输出，通过30名X平台用户的公开试点验证。

Result: 框架首次在单一流程中整合解释风格与粒度的动态适配，预期实验将验证其对用户决策和信任度的提升效果。

Conclusion: 情境化的分层解释体系有望解决推荐系统透明性痛点，为不同认知层级的用户提供定制化解释范式。

Abstract: Social media platforms today strive to improve user experience through AI
recommendations, yet the value of such recommendations vanishes as users do not
understand the reasons behind them. This issue arises because explainability in
social media is general and lacks alignment with user-specific needs. In this
vision paper, we outline a user-segmented and context-aware explanation layer
by proposing a visual explanation system with diverse explanation methods. The
proposed system is framed by the variety of user needs and contexts, showing
explanations in different visualized forms, including a technically detailed
version for AI experts and a simplified one for lay users. Our framework is the
first to jointly adapt explanation style (visual vs. numeric) and granularity
(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will
validate its impact on decision-making and trust.

</details>


### [76] [Unraveling Hidden Representations: A Multi-Modal Layer Analysis for Better Synthetic Content Forensics](https://arxiv.org/abs/2508.00784)
*Tom Or,Omri Azencot*

Main category: cs.AI

TL;DR: 本文提出利用大型预训练多模态模型检测生成内容，通过其潜在编码区分真实与虚假信息，实现了跨模态的高效检测。


<details>
  <summary>Details</summary>
Motivation: 生成模型在图像、文本等领域表现优异，但恶意用户利用合成媒体传播虚假信息，亟需能适应新型生成模型的鲁棒检测器。现有分类器通常仅适用于特定生成器和数据模态，泛化能力不足。

Method: 采用大型预训练多模态模型的潜在编码特征，在其上训练线性分类器。该方法计算高效、训练快速，且在小样本场景下仍有效。

Result: 在音频和图像虚假检测任务中，该方法超越或匹配现有基线方法，实现了跨模态的最先进性能。

Conclusion: 研究表明预训练多模态模型的潜在编码天然具备区分真实与生成内容的能力，为构建通用虚假检测器提供了有效途径。

Abstract: Generative models achieve remarkable results in multiple data domains,
including images and texts, among other examples. Unfortunately, malicious
users exploit synthetic media for spreading misinformation and disseminating
deepfakes. Consequently, the need for robust and stable fake detectors is
pressing, especially when new generative models appear everyday. While the
majority of existing work train classifiers that discriminate between real and
fake information, such tools typically generalize only within the same family
of generators and data modalities, yielding poor results on other generative
classes and data domains. Towards a universal classifier, we propose the use of
large pre-trained multi-modal models for the detection of generative content.
Effectively, we show that the latent code of these models naturally captures
information discriminating real from fake. Building on this observation, we
demonstrate that linear classifiers trained on these features can achieve
state-of-the-art results across various modalities, while remaining
computationally efficient, fast to train, and effective even in few-shot
settings. Our work primarily focuses on fake detection in audio and images,
achieving performance that surpasses or matches that of strong baseline
methods.

</details>
