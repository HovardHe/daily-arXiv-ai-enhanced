<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 3]
- [math.OC](#math.OC) [Total: 9]
- [math.NT](#math.NT) [Total: 9]
- [math.LO](#math.LO) [Total: 1]
- [math.GM](#math.GM) [Total: 1]
- [math.CO](#math.CO) [Total: 17]
- [q-fin.MF](#q-fin.MF) [Total: 1]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [cs.CR](#cs.CR) [Total: 4]
- [cs.AI](#cs.AI) [Total: 23]
- [stat.TH](#stat.TH) [Total: 1]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Learning Smooth Populations of Parameters with Trial Heterogeneity](https://arxiv.org/abs/2507.23140)
*JungHo Lee,Valerio Baćak,Edward H. Kennedy*

Main category: math.ST

TL;DR: 本文研究了二项混合模型中混合分布的估计问题，考虑了试验异质性和平滑性。在密度为s-平滑的假设下，推导了核密度估计器在异质性试验下的快速误差率，并改进了现有结果。同时研究了两种密度差异的非参数估计，应用于刑事司法中贫困辩护定罪率的比较。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于刑事司法领域的应用：比较宾夕法尼亚州贫困辩护中指定律师（法院指定的私人律师）与公设辩护人的定罪率差异，发现指定律师的定罪率通常更高，可能与案件严重性这一混杂因素有关。

Method: 在密度为s-平滑的假设下，采用核密度估计器处理异质性试验的二项混合模型，推导了依赖于试验调和平均数的快速误差率，并将方法扩展到两种密度差异的非参数估计。

Result: 即使在同质性试验情况下，本文结果改进了Ye和Bickel (2021)的最优速率。实证分析显示，指定律师的估计定罪率普遍高于公设辩护人，可能与案件严重性相关。

Conclusion: 本文提出的方法在异质性试验和二项混合设定下均实现了更优的估计速率，为刑事司法系统中的辩护效果差异提供了量化分析工具，揭示了潜在的系统性偏差。

Abstract: We consider the classical problem of estimating the mixing distribution of
binomial mixtures, but under trial heterogeneity and smoothness. This problem
has been studied extensively when the trial parameter is homogeneous, but not
under the more general scenario of heterogeneous trials, and only within a low
smoothness regime, where the resulting rates are slow. Under the assumption
that the density is s-smooth, we derive fast error rates for the kernel density
estimator under trial heterogeneity that depend on the harmonic mean of the
trials. Importantly, even when reduced to the homogeneous case, our result
improves on the state-of-the-art rate of Ye and Bickel (2021). We also study
nonparametric estimation of the difference between two densities, which can be
smoother than the individual densities, in both i.i.d. and binomial-mixture
settings. Our work is motivated by an application in criminal justice:
comparing conviction rates of indigent representation in Pennsylvania. We find
that the estimated conviction rates for appointed counsel (court-appointed
private attorneys) are generally higher than those for public defenders,
potentially due to a confounding factor: appointed counsel are more likely to
take on severe cases.

</details>


### [2] [CLT in high-dimensional Bayesian linear regression with low SNR](https://arxiv.org/abs/2507.23285)
*Seunghyun Lee,Nabarun Deb,Sumit Mukherjee*

Main category: math.ST

TL;DR: 本文研究高维贝叶斯线性回归中线性统计量的中心极限定理，重点探讨非收缩机制下的后验分布特性，并构建可信区间。


<details>
  <summary>Details</summary>
Motivation: 现代高维数据集通常具有有限的信噪比，这促使我们在非收缩机制下研究后验分布的性质，其中似然和先验都不占主导地位。

Method: 结合随机场Ising模型的Berry-Esseen型边界以及一阶和二阶Poincar\\'{e}不等式，分析后验均值和一维投影的极限分布。

Result: 极限分布为高斯分布，且围绕后验的均值场近似中心化，结果不依赖于先验的稀疏性假设。

Conclusion: 研究结果为非收缩机制下的贝叶斯推断提供了理论支持，并展示了先验选择对后验分布的重要影响。

Abstract: We study central limit theorems for linear statistics in high-dimensional
Bayesian linear regression with product priors. Unlike the existing literature
where the focus is on posterior contraction, we work under a non-contracting
regime where neither the likelihood nor the prior dominates the other. This is
motivated by modern high-dimensional datasets characterized by a bounded
signal-to-noise ratio. This work takes a first step towards understanding limit
distributions for one-dimensional projections of the posterior, as well as the
posterior mean, in such regimes. Analogous to contractive settings, the
resulting limiting distributions are Gaussian, but they heavily depend on the
chosen prior and center around the Mean-Field approximation of the posterior.
We study two concrete models of interest to illustrate this phenomenon -- the
white noise design, and the (misspecified) Bayesian model. As an application,
we construct credible intervals and compute their coverage probability under
any misspecified prior. Our proofs rely on a combination of recent developments
in Berry-Esseen type bounds for Random Field Ising models and both first and
second order Poincar\'{e} inequalities. Notably, our results do not require any
sparsity assumptions on the prior.

</details>


### [3] [Optimal-Transport Based Multivariate Goodness-of-Fit Tests](https://arxiv.org/abs/2507.23490)
*Zdeněk Hlávka,Šárka Hudecová,Simos G. Meintanis*

Main category: math.ST

TL;DR: 本文提出了一种基于特征函数的多元观测拟合优度检验方法，通过多元秩比较实现分布无关的简单假设检验，并通过模拟研究验证了其在有限样本中的良好性能。


<details>
  <summary>Details</summary>
Motivation: 针对多元观测数据，开发一种计算简便且性能优越的拟合优度检验方法，以解决现有方法在复杂假设下的局限性。

Method: 利用最优测度传输理论构建多元秩，定义两样本准则测量原始观测与参考分布生成样本的秩差异，对复合假设仍需自助法近似。

Result: 渐近理论分析表明该方法具有理论保障，模拟研究（聚焦多元正态性检验）显示其在有限样本中表现优异。

Conclusion: 所提出的基于特征函数的检验方法在保持计算简便性的同时，对简单假设实现分布无关性，为多元拟合优度检验提供了有效工具。

Abstract: Characteristic-function based goodness-of-fit tests are suggested for
multivariate observations. The test statistics, which are straightforward to
compute, are defined as two-sample criteria measuring discrepancy between
multivariate ranks of the original observations and the corresponding ranks
obtained from an artificial sample generated from the reference distribution
under test. Multivariate ranks are constructed using the theory of the optimal
measure transport, thus rendering the tests of a simple null hypothesis
distribution-free, while bootstrap approximations are still necessary for
testing composite null hypotheses. Asymptotic theory is developed and a
simulation study, concentrating on comparisons with previously proposed tests
of multivariate normality, demonstrates that the method performs well in finite
samples.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [4] [Adaptive direct search algorithms for constrained optimization](https://arxiv.org/abs/2507.23054)
*Charles Audet,Théo Denorme,Youssef Diouane,Sébastien Le Digabel,Christophe Tribes*

Main category: math.OC

TL;DR: 本文提出了一种新型自适应直接搜索方法(ADS)，通过引入基于穿孔空间的接受准则，克服了MADS和SDDS两类主流无导数优化方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有无导数优化方法中，MADS受限于网格约束，而SDDS可能丢弃有效改进点。需要一种兼具灵活性和理论保证的新方法。

Method: ADS采用基于穿孔空间的新型接受准则，既不依赖网格限制，也不要求充分下降条件，保留了方向性直接搜索的理论基础。

Result: 计算实验表明，ADS在约束和无约束优化问题中均展现出优于MADS和SDDS的性能表现。

Conclusion: ADS成功融合了MADS和SDDS的优势，通过创新性接受准则实现了更灵活的搜索能力，同时保持理论严谨性。

Abstract: Two families of directional direct search methods have emerged in
derivative-free and blackbox optimization (DFO and BBO), each based on distinct
principles: Mesh Adaptive Direct Search (MADS) and Sufficient Decrease Direct
Search (SDDS). MADS restricts trial points to a mesh and accepts any
improvement, ensuring none are missed, but at the cost of restraining the
placement of trial points. SDDS allows greater freedom by evaluating points
anywhere in the space, but accepts only those yielding a sufficient decrease in
the objective function value, which may lead to discarding improving points.
  This work introduces a new class of methods, Adaptive Direct Search (ADS),
which uses a novel acceptance rule based on the so-called punctured space,
avoiding both meshes and sufficient decrease conditions. ADS enables flexible
search while addressing the limitations of MADS and SDDS, and retains the
theoretical foundations of directional direct search. Computational results in
constrained and unconstrained settings highlight its performance compared to
both MADS and SDDS.

</details>


### [5] [Stability-Constrained AC Optimal Power Flow -- A Gaussian Process-Based Approach](https://arxiv.org/abs/2507.23094)
*Vincenzo Di Vito,Kaarthik Sundar,Ferdinando Fioretto,Deepjyoti Deka*

Main category: math.OC

TL;DR: 本文提出了一种数据驱动方法，通过高斯过程模型将发电机动态特性整合到交流最优潮流问题中，确保运行点既经济又动态稳定。


<details>
  <summary>Details</summary>
Motivation: 传统交流最优潮流问题依赖稳态模型，忽略发电机动态行为，可能导致经济最优但动态不稳定的运行点。

Method: 使用高斯过程回归学习同步发电机动态微分方程解的稳定性指数，构建指数代理函数，并将概率稳定性评估直接集成到优化过程中。

Result: 在IEEE 39、57和118节点系统上的数值实验表明，该方法能高效利用有限训练数据捕捉发电机动态，实现更可靠和鲁棒的决策。

Conclusion: 所提出的动态感知交流最优潮流框架能同时满足运行安全和动态稳定性标准，适用于广泛运行条件。

Abstract: The Alternating Current Optimal Power Flow (ACOPF) problem is a core task in
power system operations, aimed at determining cost-effective generation
dispatch while satisfying physical and operational constraints. However,
conventional ACOPF formulations rely on steady-state models and neglect the
dynamic behavior of generators, which can lead to operating points that are
economically optimal but dynamically unstable. This paper proposes a novel,
data-driven approach to incorporate generator dynamics into the ACOPF using
Gaussian Process (GP) models. Specifically, it introduces an exponential
surrogate function to characterize the stability of solutions to the
differential equations governing synchronous generator dynamics. The exponent,
which indicates whether system trajectories decay (stable) or grow (unstable),
is learned as a function of the bus voltage using GP regression. Crucially, the
framework enables probabilistic stability assessment to be integrated directly
into the optimization process. The resulting dynamics-aware ACOPF formulation
identifies operating points that satisfy both operational safety and dynamic
stability criteria. Numerical experiments on the IEEE 39-bus, 57-bus, and
118-bus systems demonstrate that the proposed method efficiently captures
generator dynamics using limited training data, leading to more reliable and
robust decisions across a wide range of operating conditions.

</details>


### [6] [On the Complexity of Finding Stationary Points in Nonconvex Simple Bilevel Optimization](https://arxiv.org/abs/2507.23155)
*Jincheng Cao,Ruichen Jiang,Erfan Yazdandoost Hamedani,Aryan Mokhtari*

Main category: math.OC

TL;DR: 本文研究了一个简单的双层优化问题，提出了一种适用于非凸情况下的动态障碍梯度下降（DBGD）框架，首次实现了在多项式时间内找到联合稳定点的复杂度结果。


<details>
  <summary>Details</summary>
Motivation: 在双层优化问题中，当上下层目标函数均为光滑但可能非凸时，由于缺乏凸性或Polyak-{\L}ojasiewicz（PL）条件等结构假设，保证全局最优性通常不可行。因此，需要引入合适的稳定点概念，并设计高效算法。

Method: 采用动态障碍梯度下降（DBGD）框架的变体，该算法能够在多项式时间内找到上下层目标函数的联合稳定点，即$(\epsilon_f, \epsilon_g)$-稳定点。

Result: 算法达到$(\epsilon_f, \epsilon_g)$-稳定点的复杂度为$\mathcal{O}\left(\max\left(\epsilon_f^{-\frac{3+p}{1+p}}, \epsilon_g^{-\frac{3+p}{2}}\right)\right)$，其中$p \geq 0$为任意常数。这是首个在一般非凸简单双层问题中保证联合稳定性的离散时间算法复杂度结果。

Conclusion: 本文提出的DBGD变体首次在非凸简单双层优化问题中实现了联合稳定点的多项式时间求解，为这类问题提供了有效的解决方案。

Abstract: In this paper, we study the problem of solving a simple bilevel optimization
problem, where the upper-level objective is minimized over the solution set of
the lower-level problem. We focus on the general setting in which both the
upper- and lower-level objectives are smooth but potentially nonconvex. Due to
the absence of additional structural assumptions for the lower-level
objective-such as convexity or the Polyak-{\L}ojasiewicz (PL)
condition-guaranteeing global optimality is generally intractable. Instead, we
introduce a suitable notion of stationarity for this class of problems and aim
to design a first-order algorithm that finds such stationary points in
polynomial time. Intuitively, stationarity in this setting means the
upper-level objective cannot be substantially improved locally without causing
a larger deterioration in the lower-level objective. To this end, we show that
a simple and implementable variant of the dynamic barrier gradient descent
(DBGD) framework can effectively solve the considered nonconvex simple bilevel
problems up to stationarity. Specifically, to reach an $(\epsilon_f,
\epsilon_g)$-stationary point-where $\epsilon_f$ and $\epsilon_g$ denote the
target stationarity accuracies for the upper- and lower-level objectives,
respectively-the considered method achieves a complexity of
$\mathcal{O}\left(\max\left(\epsilon_f^{-\frac{3+p}{1+p}},
\epsilon_g^{-\frac{3+p}{2}}\right)\right)$, where $p \geq 0$ is an arbitrary
constant balancing the terms. To the best of our knowledge, this is the first
complexity result for a discrete-time algorithm that guarantees joint
stationarity for both levels in general nonconvex simple bilevel problems.

</details>


### [7] [FMIP: Multimodal Flow Matching for Mixed Integer Linear Programming](https://arxiv.org/abs/2507.23390)
*Hongpei Li,Hui Yuan,Han Zhang,Dongdong Ge,Mengdi Wang,Yinyu Ye*

Main category: math.OC

TL;DR: 本文提出FMIP框架，通过多模态流匹配建模混合整数规划中整数与连续变量的联合分布，结合引导机制提升求解质量，实验显示其性能优于现有基于GNN的基线方法50.04%。


<details>
  <summary>Details</summary>
Motivation: 现有基于图神经网络的启发式方法仅预测整数变量解，难以捕捉整数与连续变量间的复杂交互，且表征能力不足。FMIP旨在解决这些局限性。

Method: FMIP采用多模态流匹配框架建模混合解空间的联合分布，集成目标函数优化和约束满足的双重引导机制进行解采样。

Result: 在7个标准MILP基准测试中，FMIP相较现有GNN预测基线平均提升50.04%的求解质量。

Conclusion: FMIP作为新型学习式MILP求解策略，展现了处理混合变量交互的强大潜力，为复杂决策问题提供了更优解法。

Abstract: Mixed-Integer Linear Programming (MILP) is a cornerstone of mathematical
optimization, enabling the modeling of complex decision-making problems
involving both integer and continuous variables. Despite its versatility, most
MILP problems are NP-complete, making them challenging to solve in practice.
Existing graph neural network (GNN)-based heuristics aim to reduce problem
scale by predicting only the solutions on integer variables for a given
instance, struggling to capture the intricate interplay between continuous and
integer variables and lack sufficient representational power. To address these
limitations, we propose FMIP, a novel multimodal flow-matching framework that
models the joint distribution over integer and continuous variables in the
mixed solution space of MILP. To enable more accurate and scalable heuristics,
FMIP integrates a guidance mechanism to guide solution sampling under both
objective function optimization and constraint satisfaction. We evaluate FMIP
on seven standard MILP benchmarks. Our experiments show that FMIP improves
solution quality by 50.04% on average over existing GNN-based predictive
baselines. These results highlight FMIP's potential as a powerful new approach
for developing learning based MILP solution strategy.

</details>


### [8] [Popov Mirror-Prox Method for Variational Inequalities](https://arxiv.org/abs/2507.23395)
*Abhishek Chakraborty,Angelia Nedić*

Main category: math.OC

TL;DR: 本文提出了Popov镜像近端算法在多项式增长条件下求解随机和确定性变分不等式（VIs）的收敛性，并提出了无需问题特定参数的自适应步长方案。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要预先知道问题特定参数，限制了算法的通用性。本文旨在开发参数无关的自适应步长方案，以解决这一局限性。

Method: 提出了Popov镜像近端算法的参数无关步长方案（包括恒定和递减形式），适用于随机和确定性单调VIs，并扩展至H\"older连续映射的非单调VIs。

Result: 在随机和确定性单调VIs中，算法在有界约束集上实现了对偶间隙函数的最优收敛速率；对于H\"older连续映射的确定性VIs，证明了残差函数的收敛性，适用于部分非单调VIs。

Conclusion: 通过将镜像近端技术扩展至任意多项式增长的映射，本文填补了文献中的空白，并在矩阵博弈、分段二次函数和ResNet-18图像分类任务中验证了理论结果。

Abstract: This paper establishes the convergence properties of the Popov mirror-prox
algorithm for solving stochastic and deterministic variational inequalities
(VIs) under a polynomial growth condition on the mapping variation. Unlike
existing methods that require prior knowledge of problem-specific parameters,
we propose step-size schemes that are entirely parameter-free in both constant
and diminishing forms. For stochastic and deterministic monotone VIs, we
establish optimal convergence rates in terms of the dual gap function over a
bounded constraint set. Additionally, for deterministic VIs with H\"older
continuous mapping, we prove convergence in terms of the residual function
without requiring a bounded set or a monotone mapping, provided a Minty
solution exists. This allows our method to address certain classes of
non-monotone VIs. However, knowledge of the H\"older exponent is necessary to
achieve the best convergence rates in this case. By extending mirror-prox
techniques to mappings with arbitrary polynomial growth, our work bridges an
existing gap in the literature. We validate our theoretical findings with
empirical results on matrix games, piecewise quadratic functions, and image
classification tasks using ResNet-18.

</details>


### [9] [Biobjective optimization with M-convex functions](https://arxiv.org/abs/2507.23423)
*Ellen H. Fukuda,Satoru Iwata,Itsuki Nakagawa*

Main category: math.OC

TL;DR: 本文首次将多目标优化与离散凸分析相结合，针对双目标优化问题提出了多项式时间算法，特别适用于包含M$^\natural$-凸函数和二元系数线性函数的场景。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索多目标优化与离散凸分析这一未被结合的研究领域，旨在解决特定类型双目标优化问题的计算效率问题。

Method: 方法包括：1) 对含M$^\natural$-凸函数和二元线性函数的双目标问题设计多项式时间算法；2) 在M$^\natural$-凸函数为M-凸的特殊情况下提出更高效算法；3) 结合字典序优化与M$^\natural$-凸函数最小化的多项式时间方法。

Result: 结果表明：1) 特定双目标问题的整个帕累托最优值集可在多项式时间内获得；2) M-凸函数特例下算法效率更高；3) 结合字典序优化的方法同样具有多项式时间复杂度。

Conclusion: 结论指出，离散凸分析与多目标优化的结合为特定类型优化问题提供了高效求解途径，扩展了离散优化理论的应用边界。

Abstract: In this paper, we deal with two ingredients that, as far as we know, have not
been combined until now: multiobjective optimization and discrete convex
analysis. First, we show that the entire Pareto optimal value set can be
obtained in polynomial time for biobjective optimization problems with discrete
convex functions, in particular, involving an M$^\natural$-convex function and
a linear function with binary coefficients. We also observe that a more
efficient algorithm can be obtained in the special case where the
M$^\natural$-convex function is M-convex. Additionally, we present a
polynomial-time method for biobjective optimization problems that combine
M$^\natural$-convex function minimization with lexicographic optimization.

</details>


### [10] [Convergence rates of Newton's method for strongly self-concordant minimization](https://arxiv.org/abs/2507.23558)
*Nick Tsipinakis,Panos Parpas*

Main category: math.OC

TL;DR: 本文研究了牛顿法在强自协调函数（自协调函数的一个子类）上的局部收敛性，发现其二次收敛速率优于一般自协调函数，且具有更大的局部收敛区域。


<details>
  <summary>Details</summary>
Motivation: 尽管牛顿法在自协调函数上的性质已被充分研究，但针对其子类——强自协调函数的局部分析尚未见诸文献。本文旨在填补这一理论空白，探究强自协调函数是否具有更优的理论性质。

Method: 通过理论分析，比较了牛顿法在强自协调函数与一般自协调函数上的局部收敛行为，重点研究了二次收敛速率和局部收敛区域的差异。

Result: 研究发现，强自协调函数的牛顿法不仅二次收敛速率更快，而且局部收敛区域更大。这一结论适用于广泛的优化目标函数。

Conclusion: 本文完善了牛顿法应用于强自协调函数的理论体系，证实了其相较于一般自协调函数的优越性能，为后续研究提供了理论基础。

Abstract: Newton's method has been thoroughly studied for the class of self-concordant
functions. However, a local analysis specific to strongly self-concordant
functions (a subclass of the former) is missing from the literature. The local
quadratic rate of strongly self-concordant functions follows, of course, from
the known results for self-concordant functions. However, it is not known
whether strongly self-concordant functions enjoy better theoretical properties.
In this paper, we study the local convergence of Newton's method for this
subclass. We show that its quadratic convergence rate differs from that of
general self-concordant functions. In particular, it is provably faster for a
wide range of objective functions and benefits from a larger region of local
convergence. Thus, the results of this paper close the gap in the theoretical
understanding of Newton's method applied to strongly self-concordant functions.

</details>


### [11] [Combinatorial Approaches for Embedded Feature Selection in Nonlinear SVMs](https://arxiv.org/abs/2507.23711)
*Federico D'Onofrio,Yuri Faenza,Laura Palagi*

Main category: math.OC

TL;DR: 本文提出了一种基于硬基数约束的非线性支持向量机（SVM）嵌入式特征选择方法，通过混合整数非线性规划（MINLP）模型和局部搜索元启发式算法，实现了对特征数量的严格控制，并在多项式核下利用子模函数最大化提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 嵌入式特征选择（FS）旨在模型训练过程中识别最相关特征，但现有硬约束方法仅适用于线性SVM的原始形式。本文探索在非线性SVM对偶问题中直接嵌入硬基数约束，以兼顾特征选择严格性和核方法优势。

Method: 1) 将问题建模为MINLP；2) 提出适用于通用非线性核的局部搜索元启发式算法；3) 设计分解框架交替优化连续变量和二元变量子问题，多项式核下二元子问题转化为基数约束的子模最大化问题。

Result: 数值实验表明，所提算法显著优于标准MINLP求解方法，能更有效解决目标特征选择问题，尤其在多项式核场景下通过子模优化实现高效计算。

Conclusion: 该研究首次实现对非线性SVM对偶问题的硬基数约束嵌入，通过创新算法框架在保证特征选择严格性的同时利用核技巧，为可解释机器学习提供了新工具。

Abstract: Embedded Feature Selection (FS) is a classical approach for interpretable
machine learning, aiming to identify the most relevant features of a dataset
while simultaneously training the model. We consider an approach based on a
hard cardinality constraint for nonlinear SVMs. To the best of our knowledge,
hard-constraint approaches have been proposed only for the primal formulation
of linear SVMs. In contrast, we embed a hard cardinality constraint directly
into the dual of a nonlinear SVM, guaranteeing strict control over the number
of selected features while still leveraging kernelization. We formulate the
problem as a Mixed-Integer Nonlinear Programming (MINLP) model. As a first
contribution, we propose a local search metaheuristic applicable to general
nonlinear kernels. Our second and main contribution is a decomposition
framework that alternates optimization between two subproblems: one involving
only continuous variables and the other involving only binary variables. For
polynomial kernels, we show that the binary subproblem reduces to a submodular
function maximization under a cardinality constraint, enabling the use of
scalable submodular maximization algorithms within the alternating optimization
process. Numerical experiments demonstrate that our algorithms significantly
outperform standard methods for solving the proposed MINLPs, providing more
effective solutions to the addressed feature selection problem.

</details>


### [12] [Adaptive Stepsize Selection in Decentralized Convex Optimization](https://arxiv.org/abs/2507.23725)
*Ilya Kuruzov,Xiaokai Chen,Gesualdo Scutari,Alexander Gasnikov*

Main category: math.OC

TL;DR: 提出一种完全自适应的去中心化优化算法，无需全局信息即可自动调整步长，适用于强凸和非强凸问题，并保持最佳收敛速率。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化方法的收敛性依赖于预先设定的步长，这需要全局信息且实际中难以调优，限制了算法的实用性和效率。

Method: 通过仅依赖邻居通信的自适应步长策略，无需全局信息（如图连通性或局部光滑性常数），且不要求问题强凸性。

Result: 算法在强凸损失下以线性速率收敛，非强凸时以次线性速率收敛，匹配依赖参数方法的最佳已知速率。

Conclusion: 该自适应算法解决了步长调优的难题，兼具理论保证和实用性，为去中心化优化提供了更高效的解决方案。

Abstract: We study decentralized optimization where multiple agents minimize the
average of their (strongly) convex, smooth losses over a communication graph.
Convergence of the existing decentralized methods generally hinges on an
apriori, proper selection of the stepsize. Choosing this value is notoriously
delicate: (i) it demands global knowledge from all the agents of the graph's
connectivity and every local smoothness/strong-convexity constants--information
they rarely have; (ii) even with perfect information, the worst-case tuning
forces an overly small stepsize, slowing convergence in practice; and (iii)
large-scale trial-and-error tuning is prohibitive. This work introduces a
decentralized algorithm that is fully adaptive in the choice of the agents'
stepsizes, without any global information and using only neighbor-to-neighbor
communications--agents need not even know whether the problem is strongly
convex. The algorithm retains strong guarantees: it converges at \emph{linear}
rate when the losses are strongly convex and at \emph{sublinear} rate
otherwise, matching the best-known rates of (nonadaptive) parameter-dependent
methods.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [13] [On the densities of covering numbers and abundant numbers](https://arxiv.org/abs/2507.23041)
*Nathan McNew,Jai Setty*

Main category: math.NT

TL;DR: 研究了覆盖数集$\mathcal{C}$和丰数集$\mathcal{A}$的密度，证明了$\mathcal{C}$存在自然密度$d(\mathcal{C})$并给出精确范围$0.103230 < d(\mathcal{C}) < 0.103398$，同时改进了丰数密度$d(\mathcal{A})$的界限至$0.247619608 < d(\mathcal{A}) < 0.247619658$。


<details>
  <summary>Details</summary>
Motivation: 探索覆盖数（所有模数能整除其自身的整数）和丰数的集合密度，填补相关领域的研究空白。

Method: 引入函数$c(n)$衡量整数接近覆盖数的程度，结合Behrend和Del\'eglise的丰数密度估计方法，并开发新计算技术以提高精度。

Result: 确定覆盖数密度$d(\mathcal{C})$的三位小数范围，显著提升丰数密度$d(\mathcal{A})$的精度，并证明原始覆盖数的计数上界远小于原始丰数。

Conclusion: 通过创新方法精确量化了覆盖数集的密度，同时为丰数研究提供了更锐利的工具，揭示了覆盖数分布的稀疏性特征。

Abstract: We investigate the densities of the sets of abundant numbers and of covering
numbers, integers $n$ for which there exists a distinct covering system where
every modulus divides $n$. We establish that the set $\mathcal{C}$ of covering
numbers possesses a natural density $d(\mathcal{C})$ and prove that $0.103230 <
d(\mathcal{C}) < 0.103398.$ Our approach adapts methods developed by Behrend
and Del\'eglise for bounding the density of abundant numbers, by introducing a
function $c(n)$ that measures how close an integer $n$ is to being a covering
number with the property that $c(n) \leq h(n) = \sigma(n)/n$. However,
computing $d(\mathcal{C})$ to three decimal digits requires some new ideas to
simplify the computations. As a byproduct of our methods, we obtain
significantly improved bounds for $d(\mathcal{A})$, the density of abundant
numbers, namely $0.247619608 < d(\mathcal{A}) < 0.247619658$. We also show the
count of primitive covering numbers up to $x$ is $O\left(
x\exp\left(\left(-\tfrac{1}{2\sqrt{\log 2}} + \epsilon\right)\sqrt{\log x} \log
\log x\right)\right)$, which is substantially smaller than the corresponding
bound for primitive abundant numbers.

</details>


### [14] [Nonzero $\mathfrak{n}$ cohomology of Totally Degenerate Limit of Discrete Series representations](https://arxiv.org/abs/2507.23102)
*Jin Kunwoo Lee*

Main category: math.NT

TL;DR: 论文证明了完全退化离散级数表示的特定上同调群非零，并通过组合复形验证了Serre对偶性，提出了关于酉群TDLDS的Gan-Gross-Prasad型分支律猜想。


<details>
  <summary>Details</summary>
Motivation: 研究完全退化离散级数表示（TDLDS）的上同调性质，探索其在酉群表示论中的分支律规律。

Method: 使用Soergel的组合复形计算上同调群，并验证其满足Serre对偶性。

Result: 发现U(n+1)和U(n)的TDLDS在相同度数下存在两个非零上同调群。

Conclusion: 该结果暗示任意秩酉群的TDLDS可能存在Gan-Gross-Prasad型分支律，为后续研究提供了新方向。

Abstract: We show that a totally degenerate limit of discrete series representation
admits a choice of n cohomology group that is nonvanishing at a canonically
defined degree. We then show that the combinatorial complexes used by Soergel
to compute these cohomology groups satisfies Serre duality. We conclude that
this produces two n cohomology groups, each for a totally degenerate limit of
discrete series of U(n+1) and U(n), which are nonvanishing at the same degree.
This suggests Gan Gross Prasad type branching laws for the TDLDS of unitary
groups of any rank.

</details>


### [15] [Cyclotomy, cyclotomic cosets and arimetic propeties of some families in $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$](https://arxiv.org/abs/2507.23179)
*Juncheng Zhou,Hongfeng Wu*

Main category: math.NT

TL;DR: 该论文研究了在环$\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$中，利用阶为2的分圆类获得算术性质，并推广了已有结果，同时给出了该环中极小理想的本原幂等元的显式表达式。


<details>
  <summary>Details</summary>
Motivation: 研究特定条件下分圆类的算术性质，以推广已有文献中的结果，并探索环结构中的本原幂等元。

Method: 使用阶为2的分圆类，基于$n=p^sq^t$的条件（$p\equiv3 \mathrm{mod} 4$，$\gcd(\phi(p^s),\phi(q^t))=2$等），分析环$\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$的结构。

Result: 获得了分圆类的显式形式，推广了文献中的结果，并给出了极小理想的本原幂等元的显式表达式。

Conclusion: 通过分圆类的方法，成功推广了已有研究，并揭示了环$\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$中本原幂等元的结构。

Abstract: Arithmetic properties of some families in $\frac{\mathbb{F}_l[x]}{\langle
x^{p^sq^t}-1\rangle}$ are obtained by using the cyclotomic classes of order 2
with respect to $n=p^sq^t$, where $p\equiv3 \mathrm{mod} 4$,
$\gcd(\phi(p^s),\phi(q^t))=2$, $l$ is a primitive root modulo $q^t$ and
$\mathrm{ord}_{p^s}(l)=\phi(p^s)/2$. The form of these cyclotomic classes
enables us to further generalize the results obtained in \cite{ref1}. The
explicit expressions of primitive idempotents of minimal ideals in
$\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ are also obtained.

</details>


### [16] [Extending bounds on minimal ranks of universal quadratic lattices to larger number fields](https://arxiv.org/abs/2507.23338)
*Matěj Doležálek*

Main category: math.NT

TL;DR: 本文改进了Kala的技术，通过研究数域复合体中的子域结构，利用基本伽罗瓦理论将其转化为群论问题，证明了若在d次全实数域中存在通用格的最小秩$\geq r$，则在所有$k\geq3$的kd次域中也存在。


<details>
  <summary>Details</summary>
Motivation: 已有文献证明在某些全实数域族中，通用二次格的最小秩可以任意大。Kala提出了一种技术，在特定条件下将这些结果扩展到更大域（如从二次域到任意偶次域）。本文旨在改进这一技术。

Method: 通过研究数域复合体中的子域结构，利用基本伽罗瓦理论将其转化为群论问题，从而改进Kala的扩展技术。

Result: 证明了若在d次全实数域中存在通用格的最小秩$\geq r$，则在所有$k\geq3$的kd次域中也存在这样的域。

Conclusion: 本文的方法显著扩展了Kala的技术，为研究高次全实数域中通用格的最小秩提供了新的工具。

Abstract: There exist numerous results in the literature proving that within certain
families of totally real number fields, the minimal rank of a universal
quadratic lattice over such a field can be arbitrarily large. Kala introduced a
technique of extending such results to larger fields -- e.g. from quadratic
fields to fields of arbitrary even degree -- under some conditions. We present
improvements to this technique by investigating the structure of subfields
within composita of number fields, using basic Galois theory to translate this
into a group-theoretic problem. In particular, we show that if totally real
number fields with minimal rank of a universal lattice $\geq r$ exist in degree
$d$, then they also exist in degree $kd$ for all $k\geq3$.

</details>


### [17] [Discrete restrictions from Laurent monomial systems for multiple Dirichlet series](https://arxiv.org/abs/2507.23477)
*Shenghao Hua*

Main category: math.NT

TL;DR: 本文介绍了一类特殊的多元Dirichlet级数，其项支持在某个簇上并具有欧拉积结构，这些级数自然地出现在与Dirichlet扭曲相关的自守\( L \)-函数的扭曲矩中，并提出了关于这些级数解析性质的若干猜想。


<details>
  <summary>Details</summary>
Motivation: 研究多元Dirichlet级数的动机在于理解其与自守\( L \)-函数的扭曲矩之间的自然联系，以及探索这些级数的解析性质。

Method: 通过引入一类特殊的多元Dirichlet级数，并证明它们与Dirichlet扭曲的自守\( L \)-函数的扭曲矩之间的联系，从而研究这些级数的性质。

Result: 结果表明，这些多元Dirichlet级数具有欧拉积结构，并且与自守\( L \)-函数的扭曲矩密切相关。

Conclusion: 本文提出了关于这些多元Dirichlet级数解析性质的若干猜想，为未来研究提供了方向。

Abstract: We introduce a special class of multiple Dirichlet series whose terms are
supported on a variety and which admit an Euler product structure. We show that
these series arise naturally from twisted moments of automorphic \( L
\)-functions associated with Dirichlet twists. We proposed several conjectures
on the analytic properties of these series.

</details>


### [18] [Picturesque convolution-like recurrences and partial sums' generation](https://arxiv.org/abs/2507.23619)
*Ignas Gasparavičius,Andrius Grigutis,Juozas Petkelis*

Main category: math.NT

TL;DR: 本文提出了一种从已知序列${\pmb b}$推导相关序列${\pmb a}$的方法，展示了极限$\lim_{n\to\infty}a_n$与前$m$项的关系，并通过实例证明了${\pmb a}$可呈现优美几何模式或经典数列特征。


<details>
  <summary>Details</summary>
Motivation: 研究序列间特定关系（$a_n$与${\pmb b}$的加权和）的数学表达，探索其极限性质与几何/代数表现，扩展序列构造的理论框架。

Method: 建立递推关系式$a_n=\sum_{k=0}^{n+m}a_k b_{n+m-k}$，分析极限$\lim_{n\to\infty}a_n$对初始项$a_0,\ldots,a_{m-1}$的依赖性，并通过选定${\pmb b}$生成具体数列案例。

Result: 证明了${\pmb a}$的极限行为由前$m$项决定，构造出平面/空间中的规律模式序列，且当${\pmb b}$为特定序列时${\pmb a}$可退化为黎曼zeta函数部分和等经典数列。

Conclusion: 该序列构造方法具有普适性与灵活性，既能生成视觉规律的几何序列，又能涵盖重要数学函数，为序列分析与应用提供了新工具。

Abstract: Let ${\pmb b}=\{b_0,\,b_1,\,\ldots\}$ be the known sequence of numbers such
that $b_0\neq0$. In this work, we develop methods to find another sequence
${\pmb a}=\{a_0,\,a_1,\,\ldots\}$ that is related to ${\pmb b}$ as follows:
$a_n=a_0\,b_{n+m}+a_1\,b_{n+m-1}+\ldots+a_{n+m}\,b_0$,
$n\in\mathbb{N}\cup\{0\}$, $m\in\mathbb{N}$. We show the connection of
$\lim_{n\to\infty}a_n$ with $a_0,\,a_1,\,\ldots,\,a_{m-1}$ and provide varied
examples of finding the sequence ${\pmb a}$ when ${\pmb b}$ is given. We
demonstrate that the sequences ${\pmb a}$ may exhibit pretty patterns in the
plane or space. Also, we show that the properly chosen sequence ${\pmb b}$ may
define ${\pmb a}$ as some famous sequences, such as the partial sums of the
Riemann zeta function, etc.

</details>


### [19] [An evident corollary arising from Newton--Thorne](https://arxiv.org/abs/2507.23656)
*Shenghao Hua*

Main category: math.NT

TL;DR: 本文提出了一类特殊自守表示的张量积提升示例，其$L$函数匹配特性源于Schur多项式组合恒等式与Newton-Thorne定理。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于Schur多项式的组合恒等式以及Newton和Thorne的著名成果，旨在探索自守表示张量积的$L$函数匹配现象。

Method: 通过构造自守表示的多重张量积提升，并利用$L$函数匹配准则进行验证。

Result: 成功构建了满足$L$函数匹配条件的自守提升实例，揭示了组合数学与自守表示论之间的深刻联系。

Conclusion: 该研究为自守表示的张量积理论提供了新范例，同时深化了对Schur多项式组合性质与$L$函数关系的理解。

Abstract: We present a special class of examples of automorphic lifts of multiple
tensor products of automorphic representations in the sense of matching
$L$-functions, motivated by combinatorial identities for Schur polynomials and
a celebrated result of Newton and Thorne.

</details>


### [20] [A Central Limit Theorem for the Winding Number of Low-Lying Closed Geodesics](https://arxiv.org/abs/2507.23706)
*Elias Dubno*

Main category: math.NT

TL;DR: 模曲面上低洼闭合测地线的缠绕在按自然长度归一化后呈现高斯极限分布。


<details>
  <summary>Details</summary>
Motivation: 研究模曲面上闭合测地线的统计特性，揭示其缠绕行为的概率分布规律。

Method: 通过分析低洼闭合测地线的几何性质，采用自然长度归一化方法处理数据。

Result: 发现归一化后的缠绕分布符合高斯分布，为相关几何问题提供了统计依据。

Conclusion: 该结果深化了对模曲面上测地线缠绕行为的理解，为后续研究提供了新视角。

Abstract: We show that the winding of low-lying closed geodesics on the modular surface
has a Gaussian limiting distribution when normalized by any natural notion of
length.

</details>


### [21] [Bost-Connes systems and periodic Witt vectors](https://arxiv.org/abs/2507.23759)
*Bora Yalkinoglu*

Main category: math.NT

TL;DR: 利用Borger周期Witt向量理论，构建了一般数域Bost-Connes系统的算术子代数的积分细化。


<details>
  <summary>Details</summary>
Motivation: 研究Bost-Connes系统在一般数域上的算术子代数结构，寻求其积分层面的理论扩展。

Method: 采用Borger的周期Witt向量理论作为主要工具，进行代数构造。

Result: 成功构造了与一般数域Bost-Connes系统相关的算术子代数的积分细化版本。

Conclusion: 该工作为Bost-Connes系统在更广泛数域上的算术结构研究提供了新的积分框架。

Abstract: In this note, using Borger's theory of periodic Witt vectors, we construct
integral refinements of the arithmetic subalgebras associated with Bost-Connes
systems for general number fields.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [22] [Convolution semigroups for automorphism dynamics](https://arxiv.org/abs/2507.23503)
*Kyle Gannon,Daniel Max Hoffmann,Krzysztof Krupiński*

Main category: math.LO

TL;DR: 该研究从Hrushovski关于可定义模式的论文出发，建立了与一阶结构自同构群自然作用相关的Ellis半群与类型及Keisler测度集合之间的同胚映射，进而将半群运算推广为任意一阶理论中不变类型与测度的新卷积运算，并证明了幂等测度与自同构群闭子群之间的对应定理。


<details>
  <summary>Details</summary>
Motivation: 研究最初受Hrushovski关于可定义模式论文的启发，旨在探索一阶结构自同构群作用下的Ellis半群与类型及Keisler测度集合之间的关系。

Method: 通过建立Ellis半群与类型及Keisler测度集合的同胚映射，将半群运算转移至后者，并推广为不变类型与测度的新卷积运算，利用仿射类构造证明其与可定义群上标准卷积运算的等价性。

Result: 证明了幂等测度与自同构群闭子群在相对可定义拓扑下的对应定理，并通过仿射类构造表明新卷积运算能够编码可定义群上的标准可定义卷积运算。

Conclusion: 该研究不仅扩展了不变类型与测度的卷积运算理论，还为自同构群闭子群与幂等测度的关系提供了新的对应框架，具有重要的理论意义。

Abstract: Initially motivated by Hrushovski's paper on definability patterns, we obtain
homeomorphisms between Ellis semigroups related to natural actions of the
automorphism groups of first order structures and certain collections of types
and Keisler measures. Thus, we can transfer the semigroup operation from these
Ellis semigroups to the corresponding collections of types and Keisler
measures. By generalizing this transferred product, we obtain a new convolution
operation for invariant types and measures in arbitrary first-order theories.
We develop its general theory and prove several correspondence theorems between
idempotent measures and closed subgroups of the automorphism group of a
sufficiently large (so-called monster) model with respect to the relatively
definable topology. Via the affine sort construction, we demonstrate that this
new notion of convolution encodes the standard definable convolution operation
over definable groups.

</details>


<div id='math.GM'></div>

# math.GM [[Back]](#toc)

### [23] [On the Explicit Expression of an Extended Version of Riemann Zeta Function](https://arxiv.org/abs/2507.22961)
*Yushi Huang*

Main category: math.GM

TL;DR: 本文通过Mellin逆变换和柯西留数定理两种方法，研究了涉及Gamma函数和黎曼zeta函数的Mellin-Barnes型积分，推导了扩展黎曼zeta函数的显式表达式，并探讨了其在特殊函数积分和巴恩斯zeta函数中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究扩展黎曼zeta函数$\sum_{m=1}^{\infty}\sum_{n=1}^{\infty}{(m+n)^{-s}}$的显式表达式，并验证其Mellin-Barnes积分的绝对收敛性。

Method: 采用Mellin逆变换和柯西留数定理计算积分，通过改变积分路径为矩形轮廓，并应用黎曼zeta函数的函数方程、欧拉反射公式和勒让德倍元公式进行积分段评估。

Result: 成功推导出扩展黎曼zeta函数的显式表达式，并通过Hurwitz zeta函数和留数计算验证了结果的正确性。

Conclusion: 该结果不仅与涉及双曲函数等特殊函数的复杂积分相关，还可用于推导巴恩斯zeta函数的显式表达式，展示了广泛的应用潜力。

Abstract: In this paper, we focus on the explicit expression of an extended version of
Riemann zeta function. We use two different methods, Mellin inversion formula
and Cauchy's residue theorem, to calculate a Mellin-Barnes type integral of the
analytic function regarding $z$: $\Gamma(z)\Gamma(s-z)u^{-z}$ ($u\in (0,1)$,
$s\in \mathbb{C}$). We provide the necessary background on the analytic
properties of Gamma and Riemann zeta function to confirm the absolute
convergence of this Mellin-Barnes integral. Next, we represent the extended
version of Riemann zeta function
$\sum_{m=1}^{\infty}\sum_{n=1}^{\infty}{(m+n)^{-s}}$ using the following
complex integral where the real part of $s$ is larger than 2 and $c>1$ is
chosen to make $\Re(s)-c$ larger than 1.
$$\Gamma(s)\sum_{m=1}^{\infty}\sum_{n=1}^{\infty}{(m+n)^{-s}}=\frac{1}{2\pi i}
\int_{c - i\infty}^{c + i\infty} \zeta(z) \zeta(s - z) \Gamma(z) \Gamma(s - z)
\, dz$$ We provide the evaluation of this integral by changing the integration
path from straight line $\Re(z)=c$ into a rectangular contour whose left side
is positioned at negative infinity. We apply the functional equation of Riemann
zeta function, Euler's reflection formula, and Legendre's duplication formula
to evaluate the integral segment through $\Re(z)=-\infty$. After introducing
Hurwitz zeta function and properly calculating the difference between the sum
of residues in two analogous rectangular contours, we finalize the evaluation.
Lastly, we demonstrate the connection of this result with other intricate
integrals involving special functions, such as the hyperbolic function.
Additionally, we discuss its applications in deriving explicit expressions for
the Barnes zeta function.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [24] [Domination, matching and transversal numbers for Berge-$G$ hypergraphs](https://arxiv.org/abs/2507.22957)
*María José Chávez de Diego,Pablo Montero Moreno,María Trinidad Villar-Liñán*

Main category: math.CO

TL;DR: 本文研究了Berge-G超图的扩张概念，探讨了支配数、匹配数和横截数之间的关系，推广了广义幂超图的已有结果。


<details>
  <summary>Details</summary>
Motivation: 研究Berge-G超图的扩张家族，旨在扩展对广义幂超图的理解，并探索其组合性质。

Method: 通过定义图的扩张超图（非均匀Berge-G超图的子族），分析支配数、匹配数和横截数等参数。

Result: 在扩张超图家族中建立了支配数、匹配数和横截数之间的新关系，推广了先前关于广义幂超图的结果。

Conclusion: 该研究为Berge-G超图的扩张家族提供了理论框架，揭示了其组合特性，并为未来研究奠定了基础。

Abstract: Let $G=(V(G),E(G))$ be a graph and $H=(V(H),E(H))$ be a hypergraph. The
hypergraph $H$ is a {\it Berge-G} if there is a bijection $f : E(G) \mapsto
E(H)$ such that for each $e \in E(G)$ we have $e \subseteq f(e)$. We define
{\it dilations of $G$} as a particular subfamily of not necessarily uniform
Berge-$G$ hypergraphs. We examine domination, matching and transversal numbers
and some relation between these parameters in that family of hypergraphs.
  Our work generalizes previous results concerning generalized power
hypergraphs.

</details>


### [25] [Character theoretic techniques for nonabelian partial difference sets](https://arxiv.org/abs/2507.23039)
*Seth R. Nelson,Eric Swartz*

Main category: math.CO

TL;DR: 本文研究了非阿贝尔群中的部分差集（PDS），扩展了特征理论方法，证明了Ott关于广义四边形的结果在一般PDS中同样适用，并构造了新的非阿贝尔PDS实例。


<details>
  <summary>Details</summary>
Motivation: 近年来，非阿贝尔群中的PDS研究受到广泛关注，但缺乏有效的特征理论工具。本文旨在开发适用于非阿贝尔群的特征理论方法。

Method: 通过推广Ott的特征理论结果，利用群的特征理论分析PDS与共轭类的交集，并结合构造性方法识别新的PDS实例。

Result: 证明了多个PDS的不存在性，严格限制了可能存在的PDS条件，并构造了新的非阿贝尔PDS家族，包括与Clapham和Wilson研究的Steiner系统相关的无限家族。

Conclusion: 本文的特征理论方法有效解决了非阿贝尔群中PDS的构造与限制问题，为未来研究提供了新的工具和实例。

Abstract: A $(v,k,\lambda, \mu)$-partial difference set (PDS) is a subset $D$ of size
$k$ of a group $G$ of order $v$ such that every nonidentity element $g$ of $G$
can be expressed in either $\lambda$ or $\mu$ different ways as a product
$xy^{-1}$, $x, y \in D$, depending on whether or not $g$ is in $D$. If $D$ is
inverse closed and $1 \notin D$, then the Cayley graph ${\rm Cay}(G,D)$ is a
$(v,k,\lambda, \mu)$-strongly regular graph (SRG). PDSs have been studied
extensively over the years, especially in abelian groups, where techniques from
character theory have proven to be particularly effective. Recently, there has
been considerable interest in studying PDSs in nonabelian groups, and the
purpose of this paper is develop character theoretic techniques that apply in
the nonabelian setting. We prove that analogues of character theoretic results
of Ott about generalized quadrangles of order $s$ also hold in the general PDS
setting, and we are able to use these techniques to compute the intersection of
a putative PDS with the conjugacy classes of the parent group in many
instances. With these techniques, we are able to prove the nonexistence of PDSs
in numerous instances and provide severe restrictions in cases when such PDSs
may still exist. Furthermore, we are able to use these techniques
constructively, computing several examples of PDSs in nonabelian groups not
previously recognized in the literature, including an infinite family of
genuinely nonabelian PDSs associated to the block-regular Steiner triple
systems originally studied by Clapham and related infinite families of
genuinely nonabelian PDSs associated to the block-regular Steiner $2$-designs
first studied by Wilson.

</details>


### [26] [Binary matroids and degree-boundedness for pivot-minors](https://arxiv.org/abs/2507.23182)
*Rutger Campbell,James Davies,Robert Hickingbotham*

Main category: math.CO

TL;DR: 本文证明了对于任意二分图$H$和正整数$s$，排除$H$作为pivot-minor且不含$K_{s,s}$子图的图类具有有界平均度。同时证明了$K_{s,t}$-free二分圆图的最大顶点度上界并给出了紧例。


<details>
  <summary>Details</summary>
Motivation: 研究特定图类（如不含特定子图或pivot-minor的图）的结构性质，特别是平均度的界限问题，对理解图的整体行为有重要意义。

Method: 利用Geelen等人宣布的二元拟阵结构定理，并结合对$K_{s,t}$-free二分圆图的顶点度分析，通过构造性证明展示紧界。

Result: 1. 排除$H$作为pivot-minor且不含$K_{s,s}$子图的图类具有有界平均度；2. $K_{s,t}$-free二分圆图存在度数不超过$\max\{2s-2, t-1\}$的顶点，且该界限是紧的。

Conclusion: 该研究为特定约束下图的结构性质提供了理论保证，所给出的度上界紧例对极值图论具有参考价值。

Abstract: We prove that for every bipartite graph $H$ and positive integer $s$, the
class of $K_{s,s}$-subgraph-free graphs excluding $H$ as a pivot-minor has
bounded average degree. Our proof relies on the announced binary matroid
structure theorem of Geelen, Gerards, and Whittle.
  Along the way, we also prove that every $K_{s,t}$-free bipartite circle graph
with $s\le t$ has a vertex of degree at most $\max\{2s-2, t-1\}$ and provide
examples showing that this is tight.

</details>


### [27] [Weighted $K$-$k$-Schur functions and their application to the $K$-$k$-Schur alternating conjecture](https://arxiv.org/abs/2507.23222)
*Yaozhou Fan,Xing Gao*

Main category: math.CO

TL;DR: 本文引入加权$K$-$k$-Schur函数的新概念，统一并扩展了$K$-$k$-Schur函数和闭$k$-Schur Katalan函数，解决了Blasiak等人提出的$K$-$k$-Schur交替猜想。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于扩展Katalan函数类，提出更一般的加权$K$-$k$-Schur函数，以统一现有理论并解决悬而未决的交替猜想。

Method: 通过定义加权$K$-$k$-Schur函数，并研究其在特定$k$-有界分区下的交替性质，理论推导与组合分析相结合。

Result: 证明了加权$K$-$k$-Schur函数在严格递减$k$-有界分区等广泛情况下满足交替性质，从而解决了$K$-$k$-Schur交替猜想。

Conclusion: 该研究不仅解决了重要猜想，还为$K$-理论对称函数的组合结构提供了新的理论视角。

Abstract: We introduce the new concept of weighted $K$-$k$-Schur functions -- a novel
family within the broader class of Katalan functions -- that unifies and
extends both $K$-$k$-Schur functions and closed $k$-Schur Katalan functions.
This new notion exhibits a fundamental alternating property under certain
conditions on the indexed $k$-bounded partitions. As a central application, we
resolve the $K$-$k$-Schur alternating conjecture -- posed by Blasiak, Morse,
and Seelinger in 2022 -- for a wide class of $k$-bounded partitions, including
all strictly decreasing $k$-bounded partitions. Our results shed new light on
the combinatorial structure of $K$-theoretic symmetric functions.

</details>


### [28] [Perfecting the Line Graph](https://arxiv.org/abs/2507.23231)
*Hartosh Singh Bal*

Main category: math.CO

TL;DR: 本文介绍了两种将任意有限图转化为完美图的规范构造：对称提升$\mathrm{HL}'_2(G)$和有序提升$\mathrm{HL}_2(G)$，它们均源于二分双覆盖的线图且具有盒完美性。对称提升分解为对称与反对称部分，保留了线图$L(G)$的谱特性，并为正则图生成稀疏、高结构化的扩展图族。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过规范构造将任意有限图转化为完美图，同时保留或增强其组合与谱特性，为生成具有良好扩展性和结构特性的图族提供新方法。

Method: 提出对称提升$\mathrm{HL}'_2(G)$（结构不变）和有序提升$\mathrm{HL}_2(G)$（依赖顶点标记），两者均作为二分双覆盖的线图，并推广到参数化提升$\mathrm{HL}_{r,d}(G)$和$\mathrm{HL}_{r,d}'(G)$。

Result: 对称提升分解为恢复$L(G)$的对称部分和编码边重叠的反对称部分$L^-(G)$，保留了$L(G)$的所有邻接与拉普拉斯特征值。正则图（如Paley图）通过提升生成稀疏、高结构化且盒完美的扩展图族。

Conclusion: 该构造为研究盒完美随机正则图提供了可能，并通过参数化推广进一步扩展了应用范围，同时保持了基图的谱扩展与组合扩展的改进。

Abstract: This paper introduces two canonical constructions that transform arbitrary
finite graphs into perfect graphs: the symmetric lift $\mathrm{HL}'_2(G)$,
which is purely structural and label-invariant, and the ordered lift
$\mathrm{HL}_2(G)$, which depends explicitly on vertex labeling and encodes
directional information. Both lifts arise as line graphs of bipartite double
covers and are box-perfect.
  The symmetric lift $\mathrm{HL}'_2(G)$ forms a canonical 2-cover of the line
graph $L(G)$. This involution decomposes $\mathrm{HL}'_2(G)$ into symmetric and
antisymmetric components: the symmetric part recovers $L(G)$, while the
antisymmetric part yields a signed graph $L^-(G)$, the antisymmetric line
graph, with +1/-1 edges encoding consistent vs. crossed overlaps. Thus, all
adjacency and Laplacian eigenvalues of $L(G)$, with multiplicities, appear
within those of $\mathrm{HL}'_2(G)$, despite $L(G)$ typically not being a
subgraph.
  For regular graphs such as Paley graphs, this yields infinite families of
sparse, highly structured regular and box-perfect expanders that also retain
large cliques. The lift retains much of the spectral expansion of the base
while improving the combinatorial expansion. Much the same behavior is observed
with random regular base graphs, allowing for the possibility of the study of
box-perfect random regular graphs.
  Finally, we generalize these constructions to parameterized lifts
$\mathrm{HL}_{r,d}(G)$ and $\mathrm{HL}_{r,d}'(G)$ defined on ordered
$r$-tuples connected by Hamming distance constraints, which structurally encode
the base graph and remain box-perfect.

</details>


### [29] [Recent advances in arrow relations and traces of sets](https://arxiv.org/abs/2507.23375)
*Mingze Li,Jie Ma,Mingyuan Rong*

Main category: math.CO

TL;DR: 本文综述了极值集合论中的箭头关系$(n, m) \rightarrow (a, b)$，探讨了集合族与其迹之间的定量关系，并总结了该领域的最新进展。


<details>
  <summary>Details</summary>
Motivation: 箭头关系是极值集合论的核心概念，用于量化集合族与其迹之间的关系，理解这一关系有助于解决极值问题。

Method: 通过综述不同极值视角下的箭头关系问题，本文系统梳理了相关研究成果，提供了该领域的统一概述。

Result: 研究展示了箭头关系在多种极值问题中的应用，总结了不同集合族和迹之间的定量关系及其最新进展。

Conclusion: 本文为极值集合论中的箭头关系研究提供了全面综述，突出了该领域的多样性和统一性，为未来研究指明了方向。

Abstract: The arrow relation, a central concept in extremal set theory, captures
quantitative relationships between families of sets and their traces. Formally,
the arrow relation $(n, m) \rightarrow (a, b)$ signifies that for any family
$\mathcal{F} \subseteq 2^{[n]}$ with $|\mathcal{F}| \geqslant m$, there exists
an $a$-element subset $T \subseteq [n]$ such that the trace $\mathcal{F}_{|T} =
\{ F \cap T : F \in \mathcal{F} \}$ contains at least $b$ distinct sets. This
survey highlights recent progress on a variety of problems and results
connected to arrow relations. We explore diverse topics, broadly categorized by
different extremal perspectives on these relations, offering a cohesive
overview of the field.

</details>


### [30] [Combinatorial solutions to the Social Golfer Problem and Social Golfer Problem with Adjacent Group Sizes](https://arxiv.org/abs/2507.23376)
*Alice Miller,Ivaylo Valkov,R. Julian R. Abel*

Main category: math.CO

TL;DR: 论文利用可分解组合设计（如RBIBD、RGDD等）构建了社交高尔夫球手问题（SGP）及其变种（SGA）的最优解，并提出通用算法及150人内的完整解集。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过组合数学方法解决社交高尔夫球手问题及其扩展问题，寻求最优分组方案。

Method: 采用可分解平衡不完全区组设计（RBIBD）、可分解群可分设计（RGDD）等组合设计理论，并开发通用优化算法。

Result: 提供了适用于150名以内玩家的完整最优解集合，验证了组合设计在SGP/SGA问题中的有效性。

Conclusion: 组合设计理论能系统解决社交高尔夫球手类问题，所提算法具有普适性，小规模解集可直接应用。

Abstract: Resolvable combinatorial designs including Resolvable Balanced Incomplete
Block Designs, Resolvable Group Divisible Designs, Uniformly Resolvable Designs
and Mutually Orthogonal Latin Squares and Rectangles are used to construct
optimal solutions to the Social Golfer problem (SGP) and the Social Golfer
problem with adjacent group sizes (SGA). An algorithm is presented to find an
optimal solution in general, and a complete set of solutions is provided for up
to 150 players.

</details>


### [31] [Towards the classification of maximum scattered linear sets of $\mathrm{PG}(1,q^5)$](https://arxiv.org/abs/2507.23409)
*Stefano Lia,Giovanni Longobardi,Corrado Zanella*

Main category: math.CO

TL;DR: 本文研究了$\mathrm{PG}(1,q^5)$中的最大散射线性集，证明了其投影配置的几何特性决定了线性集的类型（伪规则型或LP型），并推导出新类型线性集必须满足的多项式形式。通过计算机验证，发现当$q\leq 25$时不存在新类型的最大散射线性集。


<details>
  <summary>Details</summary>
Motivation: 研究$\mathrm{PG}(1,q^5)$中最大散射线性集的投影配置特性，以分类已知的伪规则型和LP型线性集，并探索是否存在新类型的线性集。

Method: 通过分析投影配置$\Gamma,\Sigma$的几何性质，特别是点$A$和$B$的秩，结合群$\mathbb{G}=\mathrm{P}\Gamma \mathrm{L}(5,q^5)_\Sigma$的作用，推导线性集的类型及其多项式形式。

Result: 若点$A$或$B$的秩为5，则对应的最大散射线性集为LP型；若存在新类型的线性集，则必须满足$\mathrm{rk} A=\mathrm{rk} B=4$。通过计算机验证，$q\leq 25$时未发现新类型的线性集。

Conclusion: 最大散射线性集的类型由其投影配置的几何特性决定，目前仅存在伪规则型和LP型。对于$q\leq 25$，未发现新类型的线性集，但理论上可能存在满足$\mathrm{rk} A=\mathrm{rk} B=4$的新类型。

Abstract: Every maximum scattered linear set in $\mathrm{PG}(1,q^5)$ is the projection
of an $\mathbb{F}_q$-subgeometry $\Sigma$ of $\mathrm{PG}(4,q^5)$ from a plane
$\Gamma$ external to the secant variety to $\Sigma$. The pair $(\Gamma,\Sigma)$
will be called a projecting configuration for the linear set. The projecting
configurations for the only known maximum scattered linear sets in
$\mathrm{PG}(1,q^5)$, namely those of pseudoregulus and LP type, have been
characterized in the literature by B. Csajb\'{o}k, C. Zanella in 2016 and by C.
Zanella, F. Zullo in 2020. Let $(\Gamma,\Sigma)$ be a projecting configuration
for a maximum scattered linear set in $\mathrm{PG}(1,q^5)$, let $\sigma$ be a
generator of $\mathbb{G}=\mathrm{P}\Gamma \mathrm{L}(5,q^5)_\Sigma$, and
$A=\Gamma\cap\Gamma^{\sigma^4}$, $B=\Gamma\cap\Gamma^{\sigma^3}$. If $A$ and
$B$ are not both points, then the projected linear set is of pseudoregulus
type. Then, suppose that they are points. The rank of a point $X$ is the
vectorial dimension of the span of the orbit of $X$ under the action of
$\mathbb{G}$. In this paper, by investigating the geometric properties of
projecting configurations, it is proved that if at least one of the points $A$
and $B$ has rank 5, the associated maximum scattered linear set must be of LP
type. Then, if a maximum scattered linear set of a new type exists, it must be
such that $\mathrm{rk} A=\mathrm{rk} B=4$. In this paper we derive two possible
polynomial forms that such a linear set must have. An exhaustive analysis by
computer shows that for $q\leq 25$, no new maximum scattered linear set exists.

</details>


### [32] [The net-regular strongly regular signed graphs with degree 5](https://arxiv.org/abs/2507.23420)
*Qian Yu,Yaoping Hou*

Main category: math.CO

TL;DR: 本文确定了所有度数为5的连通净正则强正则符号图，发现净度数为3和1的强正则符号图分别有5个和2个。


<details>
  <summary>Details</summary>
Motivation: 研究连通净正则强正则符号图的分类，特别是度数为5的情况，以填补该领域的理论空白。

Method: 通过数学推导和图论分析，系统地搜索和验证所有可能的度数为5的连通净正则强正则符号图。

Result: 确定了度数为5的连通净正则强正则符号图的具体数量：净度数为3的有5个，净度数为1的有2个。

Conclusion: 该研究为符号图理论提供了新的分类结果，展示了度数为5的连通净正则强正则符号图的完整结构。

Abstract: In this paper, we determine all connected net-regular strongly regular signed
graphs with degree 5. There are five and two strongly regular signed graphs
with net-degree 3 and 1, respectively.

</details>


### [33] [Fuss--Catalan algebras on generalized Dyck paths via non-crossing partitions](https://arxiv.org/abs/2507.23460)
*Keiichi Shigechi*

Main category: math.CO

TL;DR: 本文研究了Fuss--Catalan代数，作为Temperley--Lieb代数的推广，通过非交叉分割作用于广义Dyck路径。建立了非交叉分割与Dyck路径的双射关系，并引入边界Fuss--Catalan代数及其可积性。


<details>
  <summary>Details</summary>
Motivation: 探索Temperley--Lieb代数的推广形式Fuss--Catalan代数，及其在非交叉分割和广义Dyck路径上的表示，旨在扩展代数结构与组合对象间的对应关系。

Method: 通过非交叉分割定义Temperley--Lieb代数，建立与Dyck路径的双射兼容性；利用非交叉分割的递增$r$-链定义Fuss--Catalan代数，并通过双射推广至广义Dyck路径；引入边界代数并研究其可积性。

Result: 证明了Kreweras自同态与弦图旋转的等价性；构造了边界Fuss--Catalan代数的新表示；在$r=2$情况下获得了反射方程的新解。

Conclusion: Fuss--Catalan代数及其边界推广为Temperley--Lieb代数提供了新的研究方向，其与非交叉分割、Dyck路径的关联及可积性结果具有理论意义。

Abstract: We study the Fuss--Catalan algebras, which are generalizations of the
Temperley--Lieb algebra and act on generalized Dyck paths, through non-crossing
partitions. First, the Temperley--Lieb algebra is defined on non-crossing
partitions, and a bijection between a Dyck path and a non-crossing partition is
shown to be compatible with the Temperley--Lieb algebra on Dyck paths, or
equivalently chord diagrams. We show that the Kreweras endomorphism on
non-crossing partitions is equivalent to the rotation of chord diagrams under
the bijection. Secondly, by considering an increasing $r$-chain in the graded
lattice of non-crossing partitions, we define the Fuss--Catalan algebras on
increasing $r$-chains. Through a bijection between an increasing $r$-chain and
a generalized Dyck path, one naturally obtains the Fuss--Catalan algebra on
generalized Dyck paths. As generalizations of the Fuss--Catalan algebra, we
introduce the one- and two-boundary Fuss--Catalan algebras. Increasing
$r$-chains of symmetric non-crossing partitions give symmetric generalized Dyck
paths by the bijection, and the boundary Fuss--Catalan algebras naturally act
on them. We show that these representations are compatible with the
diagrammatic representations of the algebras by use of generalized chord
diagrams. Thirdly, we discuss the integrability of the Fuss--Catalan algebras.
For the Fuss--Catalan algebras with boundaries, we obtain a new solution of the
reflection equation in the case of $r=2$.

</details>


### [34] [Improved bounds on the postage stamp problem for large numbers of stamps](https://arxiv.org/abs/2507.23627)
*Eric James Faust,Michael Tait*

Main category: math.CO

TL;DR: 本文研究了$h$重加性基$F_h(n)$的最小基数问题，改进了现有上下界，特别是对于较大的$h$值。


<details>
  <summary>Details</summary>
Motivation: 虽然$h$重加性基的平凡上下界$h!n \lesssim F_h(n)^h \lesssim h^h n$已广为人知，但对于$h>2$的情况研究较少。本文旨在改进这些界限。

Method: 对于下界，作者采用了概率方法并结合Berry-Esseen定理；对于上界，则利用了Jia和Shen提出的有限循环群加性基构造。

Result: 证明了对于任意$\epsilon>0$，当$h$足够大时，有$\left(\frac{1}{2}-\epsilon\right)h!\sqrt{2\pi e} n\; \leq \; F_h(n)^h \; \leq \; \left(\left(\frac{\sqrt{3}}{2}+\epsilon\right)h\right)^h n$。

Conclusion: 本文显著改进了$h$重加性基$F_h(n)$的上下界，为这一领域的进一步研究提供了新的理论基础。

Abstract: Let $F_h(n)$ denote the minimum cardinality of an additive {\em $h$-fold
basis} of $\{1,2,\cdots,n\}$: a set $S$ such that any integer in $\{1,2,\cdots,
n\}$ can be written as a sum of at most $h$ elements from $S$. While the
trivial bounds $h!n \; \lesssim \; F_h(n)^h \; \lesssim \; h^h n$ are
well-known, comparatively little has been established for $h>2$. In this paper,
we make significant improvements to both of the best-known bounds on $F_h(n)$
for sufficiently large $h$. For the lower bound, we use a probabilistic
approach along with the Berry-Esseen Theorem to improve upon the best-known
asymptotic result due to Yu. We also establish the first nontrivial asymptotic
upper bound on $F_h(n)$ by leveraging a construction for additive bases of
finite cyclic groups due to Jia and Shen. In particular, we show that given any
$\epsilon>0$, for sufficiently large $h$, we have \[
\left(\frac{1}{2}-\epsilon\right)h!\sqrt{2\pi e} n\; \leq \; F_h(n)^h \; \leq
\; \left(\left(\frac{\sqrt{3}}{2}+\epsilon\right)h\right)^h n. \]

</details>


### [35] [Oriented diameter of graphs with diameter $4$ and given maximum edge girth](https://arxiv.org/abs/2507.23517)
*Jifu Lin,Lihua You*

Main category: math.CO

TL;DR: 本文研究了无桥图的最大边围长及其强定向直径的上界，给出了直径4时的上下界。


<details>
  <summary>Details</summary>
Motivation: 研究无桥图在特定条件下的强定向直径，扩展了Chv\'atal和Thomassen等人的工作，填补了直径4时的理论空白。

Method: 通过定义最大边围长$g^*(G)$并引入函数$F(d,A)$，结合组合数学和图论方法分析定向直径的界限。

Result: 证明了当直径$d=4$且$A^*=\{2,3,6,7,8,9\}$时，$12\leq F(4,A^*)\leq 13$。

Conclusion: 该结果推进了无桥图强定向直径的理论研究，为更高维度的类似问题提供了参考框架。

Abstract: Let $G$ be a bridgeless graph. We introduce the maximum edge girth of $G$,
denoted by $g^*(G)=\max\{l_G(e)\mid e\in E(G)\}$, where $l_G(e)$ is the edge
girth of $e$, defined as the length of the shortest cycle containing $e$. Let
$F(d,A)$ be the smallest value for which every bridgeless graph $G$ with
diameter $d$ and $g^*(G)\in A$ admits a strong orientation $\overrightarrow{G}$
such that the diameter of $\overrightarrow{G}$ is at most $F(d,A)$. Let
$f(d)=F(d,A)$, where $A=\{a\in \mathbb{N}\mid 2\leq a\leq 2d+1\}$. Chv\'atal
and Thomassen (JCT-B, 1978) obtained general bounds for $f(d)$ and showed that
$f(2)=6$. Kwok et al. (JCT-B, 2010) proved that $9\leq f(3)\leq 11$. Wang and
Chen (JCT-B, 2022) determined $f(3)=9$. In this paper, we give that $12\leq
F(4,A^*)\leq 13$, where $A^*=\{2,3,6,7,8,9\}$.

</details>


### [36] [Tree-indexed sums of Catalan numbers](https://arxiv.org/abs/2507.23557)
*Alin Bostan,Valentin Féray,Paul Thévenin*

Main category: math.CO

TL;DR: 研究树索引的Catalan数乘积无限和，证明其为$1/\pi$的有理系数多项式，并给出有效算法计算这些和。


<details>
  <summary>Details</summary>
Motivation: 研究大环系统的非交叉环平面配置，需要计算树索引的Catalan数乘积和。

Method: 引入参数化提升方法，证明其可表示为第一类和第二类完全椭圆积分的多项式，且多项式次数不超过树顶点数的一半。

Result: 树索引的Catalan数乘积和是$1/\pi$的有理系数多项式，并提供了显式计算这些和的有效算法。

Conclusion: 通过参数化提升和椭圆积分多项式表示，成功计算了树索引的Catalan数乘积和，为大环系统研究提供了数学工具。

Abstract: We consider a family of infinite sums of products of Catalan numbers, indexed
by trees. We show that these sums are polynomials in $1/\pi$ with rational
coefficients; the proof is effective and provides an algorithm to explicitly
compute these sums. Along the way we introduce parametric liftings of our sums,
and show that they are polynomials in the complete elliptic integrals of the
first and second kind. Moreover, the degrees of these polynomials are at most
half of the number of vertices of the tree. The computation of these
tree-indexed sums is motivated by the study of large meandric systems, which
are non-crossing configurations of loops in the plane.

</details>


### [37] [Ramsey numbers for 1-degenerate 3-graphs](https://arxiv.org/abs/2507.23623)
*Peter Allen,Simona Boyadzhiyska,Matías Pavez-Signé*

Main category: math.CO

TL;DR: 该论文构建了一个3-均匀1-退化的超图，其2色Ramsey数为$\Omega\big(n^{3/2}/\log n\big)$，否定了超图Burr-Erd\H{o}s猜想的所有剩余开放情况，并证明了3-均匀广义刺猬图的2色Ramsey数上界为$O\big(n^{3/2}\big)$。


<details>
  <summary>Details</summary>
Motivation: 研究旨在验证超图Burr-Erd\H{o}s猜想的剩余开放情况，并探索3-均匀超图的Ramsey数性质。

Method: 通过构造一个基于著名刺猬图变体的3-均匀1-退化超图，并分析其2色Ramsey数的下界和上界。

Result: 证明了所构造超图的2色Ramsey数为$\Omega\big(n^{3/2}/\log n\big)$，且所有3-均匀广义刺猬图的2色Ramsey数上界为$O\big(n^{3/2}\big)$。

Conclusion: 该研究否定了超图Burr-Erd\H{o}s猜想的剩余开放情况，并为3-均匀超图的Ramsey数提供了近乎尖锐的上下界。

Abstract: We construct a 3-uniform 1-degenerate hypergraph on $n$ vertices whose
2-colour Ramsey number is $\Omega\big(n^{3/2}/\log n\big)$. This shows that all
remaining open cases of the hypergraph Burr-Erd\H{o}s conjecture are false. Our
graph is a variant of the celebrated hedgehog graph. We additionally show
near-sharp upper bounds, proving that all 3-uniform generalised hedgehogs have
2-colour Ramsey number $O\big(n^{3/2}\big)$.

</details>


### [38] [Erdős meets Nash-Williams](https://arxiv.org/abs/2507.23624)
*Michelle Delcourt,Cicely,Henderson,Thomas Lesgourgues,Luke Postle*

Main category: math.CO

TL;DR: 该论文将Erdős和Nash-Williams的两个猜想统一为一个联合猜想，并通过分数松弛方法将其简化为Nash-Williams猜想的分数版本，结合Delcourt和Postle的最佳已知分数界，证明了当图G的最小度至少为0.82733n时，联合猜想成立。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于Kirkman在1847年证明的Steiner三元系存在性，以及Nash-Williams和Erdős分别在1970年和1973年提出的关于三角形分解和Steiner三元系周长的猜想。2021年，Glock等人提出了这两个猜想的共同推广，即“Erdős meets Nash-Williams' Conjecture”。

Method: 论文采用新开发的精炼吸收方法（refined absorption），而非之前使用的迭代吸收方法（iterative absorption），将联合猜想简化为Nash-Williams猜想的分数松弛版本。

Result: 结合Delcourt和Postle的最佳已知分数界，证明了当图G的最小度至少为0.82733n时，联合猜想成立。这一结果推广了Barber等人关于Nash-Williams猜想的工作以及Kwan等人对Erdős猜想的解决。

Conclusion: 论文通过精炼吸收方法为Erdős和Nash-Williams的猜想提供了新的独立证明，并展示了分数松弛方法在解决此类组合问题中的有效性。

Abstract: In 1847, Kirkman proved that there exists a Steiner triple system on $n$
vertices (equivalently a triangle decomposition of the edges of $K_n$) whenever
$n$ satisfies the necessary divisibility conditions (namely $n\equiv 1,3 \mod
6$). In 1970, Nash-Williams conjectured that every graph $G$ on $n$ vertices
with minimum degree at least $3n/4$ (for $n$ large enough and satisfying the
necessary divisibility conditions) has a triangle decomposition. In 1973,
Erd\H{o}s conjectured that for each integer $g$, there exists a Steiner triple
system on $n$ vertices with girth at least $g$ (provided that $n\equiv 1,3 \mod
6$ is large enough compared to the fixed $g$). In 2021, Glock, K\"uhn, and
Osthus conjectured the common generalization of these two conjectures, dubbing
it the ``Erd\H{o}s meets Nash-Williams' Conjecture''.
  In this paper, we reduce the combined conjecture to the fractional relaxation
of the Nash-Williams' Conjecture. Combined with the best known fractional bound
of Delcourt and Postle, this proves the combined conjecture above when $G$ has
minimum degree at least $0.82733n$. We note that our result generalizes the
seminal work of Barber, K\"uhn, Lo, and Osthus on Nash-Williams' Conjecture and
the resolution of Erd\H{o}s' Conjecture by Kwan, Sah, Sawhney, and Simkin. Both
previous proofs of those results used the method of iterative absorption. Our
proof instead proceeds via the newly developed method of refined absorption
(and hence provides new independent proofs of both results).

</details>


### [39] [Which maximal subgroups are perfect codes?](https://arxiv.org/abs/2507.23635)
*Shouhong Qiao,Ning Su,Binzhou Xia,Zhishuo Zhang,Sanming Zhou*

Main category: math.CO

TL;DR: 本文系统研究了群的最大子群如何成为完美码，提出了子群完美码的局部补集特征。


<details>
  <summary>Details</summary>
Motivation: 探索群的最大子群在Cayley图中作为完美码的条件，填补子群完美码系统性研究的空白。

Method: 通过分析子群在Cayley图中的邻域特性，建立其与完美码的等价关系，并引入局部补集概念进行表征。

Result: 证明了最大子群成为完美码的充要条件取决于其局部补集的性质，为判定提供了新工具。

Conclusion: 子群完美码的局部补集特征为群论与图论的交叉研究开辟了新途径，具有重要理论价值。

Abstract: A perfect code in a graph $\Gamma=(V, E)$ is a subset $C$ of $V$ such that no
two vertices in $C$ are adjacent and every vertex in $V \setminus C$ is
adjacent to exactly one vertex in $C$. A subgroup $H$ of a group $G$ is called
a subgroup perfect code of $G$ if it is a perfect code in some Cayley graph of
$G$. In this paper, we undertake a systematic study of which maximal subgroups
of a group can be perfect codes. Our approach highlights a characterization of
subgroup perfect codes in terms of their ``local'' complements.

</details>


### [40] [Horofunctions of infinite Sierpinski polygon graphs](https://arxiv.org/abs/2507.23681)
*Daniele D'Angeli,Francesco Matucci,Davide Perego,Emanuele Rodaro*

Main category: math.CO

TL;DR: 该研究推广了D'Angeli和Donno的工作，从$r \neq 4i$（$i \in \mathbb{N}$）的$r$字母无限序列出发，构造了点有限图序列，并研究了其Gromov-Hausdorff极限图的同构类与二面体群的关系，以及horofunction边界中Busemann与非Busemann点的性质。


<details>
  <summary>Details</summary>
Motivation: 旨在扩展D'Angeli和Donno关于字母序列与图极限的研究，探索更一般的$r$字母序列条件下图极限的结构性质及其群论描述。

Method: 通过构造基于$r$字母无限序列的点有限图序列，分析其Gromov-Hausdorff极限，并利用二面体群分类同构类，同时研究horofunction边界的点类型。

Result: 证明了极限图的同构类可由二面体群描述，并揭示了horofunction边界中Busemann点与非Busemann点的分布特征。

Conclusion: 该研究为特定字母序列生成的图极限提供了群论刻画，深化了对horofunction边界结构的理解，为非$4i$字母序列的图极限理论奠定了基础。

Abstract: Generalizing works of D'Angeli and Donno, we describe, starting from an
infinite sequence over $r$ letters with $r \neq 4i$ and $i \in \mathbb{N}$, a
sequence of pointed finite graphs. We study the pointed Gromov-Hausdorff limit
graphs giving a description of isomorphim classes in terms of dihedral groups
and providing insights on the horofunction boundaries in terms of Busemann and
non-Busemann points.

</details>


<div id='q-fin.MF'></div>

# q-fin.MF [[Back]](#toc)

### [41] [Volatility Modeling with Rough Paths: A Signature-Based Alternative to Classical Expansions](https://arxiv.org/abs/2507.23392)
*Elisa Alòs,Òscar Burés,Rafael de Santiago,Josep Vives*

Main category: q-fin.MF

TL;DR: 比较了两种隐含波动率曲面校准方法：基于Malliavin微积分的二阶渐近展开法和基于粗糙路径理论的路径签名数据驱动法。后者在Heston模型和粗糙Bergomi模型下均表现出色，展现了模型无关性和适应性。


<details>
  <summary>Details</summary>
Motivation: 探讨不同校准方法在复杂波动率模型（如粗糙波动率）下的表现，寻找更灵活且不依赖特定参数形式的校准技术。

Method: 1. 渐近展开法：基于Heston型随机波动率模型推导解析公式；\n2. 签名法：将波动率建模为原始过程签名的线性泛函，无需预设参数形式。

Result: 签名法在Heston模型下精度与渐近法相当；在粗糙Bergomi模型（非马尔可夫、粗糙波动率）中仍保持准确，而渐近法失效。

Conclusion: 基于路径签名的校准方法具有模型无关性、鲁棒性和适应性，尤其适用于粗糙或非马尔可夫波动率场景。

Abstract: We compare two methodologies for calibrating implied volatility surfaces: a
second-order asymptotic expansion method derived via Malliavin calculus, and a
data-driven approach based on path signatures from rough path theory. The
former, developed in Al\`os et al. (2015), yields efficient and accurate
calibration formulas under the assumption that the asset price follows a
Heston-type stochastic volatility model. The latter models volatility as a
linear functional of the signature of a primary stochastic process, enabling a
flexible approximation without requiring a specific parametric form.
  Our numerical experiments show that the signature-based method achieves
calibration accuracy comparable to the asymptotic approach when the true
dynamics are Heston. We then test the model in a more general setting where the
asset follows a rough Bergomi volatility process-a regime beyond the scope of
the asymptotic expansion-and show that the signature approach continues to
deliver accurate results. These findings highlight the model-independence,
robustness and adaptability of signature-based calibration methods in settings
where volatility exhibits rough or non-Markovian features.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [42] [A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection](https://arxiv.org/abs/2507.22908)
*Abhishek Sawaika,Swetang Krishna,Tushar Tomar,Durga Pritam Suggisetti,Aditi Lal,Tanmaya Shrivastav,Nouhaila Innan,Muhammad Shafique*

Main category: q-fin.CP

TL;DR: 本文提出了一种结合量子增强LSTM和隐私保护技术的联邦学习框架，用于提升金融欺诈检测的准确性和数据安全性。


<details>
  <summary>Details</summary>
Motivation: 随着数字交易的快速增长，传统欺诈检测方法面临挑战，亟需更高效且安全的解决方案。

Method: 采用量子增强LSTM模型捕获复杂交易模式，并引入新型防御方法'FedRansel'抵御投毒和推理攻击。

Result: 相比传统模型，关键指标性能提升约5%，模型退化和推理准确率降低4-8%。

Conclusion: 该框架显著提高了欺诈检测精度，同时增强了敏感金融数据的安全性和保密性。

Abstract: Rapid growth of digital transactions has led to a surge in fraudulent
activities, challenging traditional detection methods in the financial sector.
To tackle this problem, we introduce a specialised federated learning framework
that uniquely combines a quantum-enhanced Long Short-Term Memory (LSTM) model
with advanced privacy preserving techniques. By integrating quantum layers into
the LSTM architecture, our approach adeptly captures complex
cross-transactional patters, resulting in an approximate 5% performance
improvement across key evaluation metrics compared to conventional models.
Central to our framework is "FedRansel", a novel method designed to defend
against poisoning and inference attacks, thereby reducing model degradation and
inference accuracy by 4-8%, compared to standard differential privacy
mechanisms. This pseudo-centralised setup with a Quantum LSTM model, enhances
fraud detection accuracy and reinforces the security and confidentiality of
sensitive financial data.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [43] [Fine-Grained Privacy Extraction from Retrieval-Augmented Generation Systems via Knowledge Asymmetry Exploitation](https://arxiv.org/abs/2507.23229)
*Yufei Chen,Yao Wang,Haibin Zhang,Tao Gu*

Main category: cs.CR

TL;DR: 本文提出了一种针对检索增强生成（RAG）系统的黑盒攻击框架，通过知识不对称性实现跨领域隐私信息精确提取，并采用思维链推理策略降低敏感内容暴露风险。实验显示单领域隐私提取率达91%，多领域达83%，敏感语句暴露减少65%。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统的隐私攻击方法难以准确识别知识库来源的句子，且跨领域鲁棒性不足。本文旨在解决这些问题，实现细粒度隐私提取并提供自适应防御基础。

Method: 1. 利用RAG与标准LLM的知识不对称性设计攻击框架\n2. 采用思维链推理生成自适应提示词\n3. 通过查询分解最大化信息差异\n4. 语义关系评分解决词汇句法歧义\n5. 基于特征分数训练神经网络识别隐私语句

Result: 单领域隐私提取准确率91%，多领域83%。案例研究中敏感语句暴露减少65%，无需预定义知识即可实现跨领域泛化。

Conclusion: 该工作填补了RAG系统攻防研究的空白，既实现了隐私信息的精准提取，又为自适应防御机制提供了理论基础。攻击框架通过迭代优化实现跨领域适用性。

Abstract: Retrieval-augmented generation (RAG) systems enhance large language models
(LLMs) by integrating external knowledge bases, but this advancement introduces
significant privacy risks. Existing privacy attacks on RAG systems can trigger
data leakage but often fail to accurately isolate knowledge-base-derived
sentences within mixed responses. They also lack robustness when applied across
multiple domains. This paper addresses these challenges by presenting a novel
black-box attack framework that exploits knowledge asymmetry between RAG and
standard LLMs to achieve fine-grained privacy extraction across heterogeneous
knowledge landscapes. We propose a chain-of-thought reasoning strategy that
creates adaptive prompts to steer RAG systems away from sensitive content.
Specifically, we first decompose adversarial queries to maximize information
disparity and then apply a semantic relationship scoring to resolve lexical and
syntactic ambiguities. We finally train a neural network on these feature
scores to precisely identify sentences containing private information. Unlike
prior work, our framework generalizes to unseen domains through iterative
refinement without pre-defined knowledge. Experimental results show that we
achieve over 91% privacy extraction rate in single-domain and 83% in
multi-domain scenarios, reducing sensitive sentence exposure by over 65% in
case studies. This work bridges the gap between attack and defense in RAG
systems, enabling precise extraction of private information while providing a
foundation for adaptive mitigation.

</details>


### [44] [Counterfactual Evaluation for Blind Attack Detection in LLM-based Evaluation Systems](https://arxiv.org/abs/2507.23453)
*Lijia Liu,Takumi Kondo,Kyohei Atarashi,Koh Takeuchi,Jiyi Li,Shigeru Saito,Hisashi Kashima*

Main category: cs.CR

TL;DR: 本文提出了一种针对LLM评估系统的防御框架SE+CFE，通过标准评估与反事实评估相结合，有效检测盲攻击，显著提升系统安全性。


<details>
  <summary>Details</summary>
Motivation: LLM评估系统易受独立于真实答案的盲攻击威胁，需开发有效防御机制以保障评估可靠性。

Method: 在标准评估(SE)基础上引入反事实评估(CFE)，通过验证候选答案在虚假基准答案下的响应一致性来检测攻击。

Result: 实验表明标准评估漏洞率高，而SE+CFE框架在保持性能的同时将攻击检测率显著提升。

Conclusion: SE+CFE框架为LLM评估系统提供了对抗盲攻击的有效解决方案，实现了安全性与功能性的平衡。

Abstract: This paper investigates defenses for LLM-based evaluation systems against
prompt injection. We formalize a class of threats called blind attacks, where a
candidate answer is crafted independently of the true answer to deceive the
evaluator. To counter such attacks, we propose a framework that augments
Standard Evaluation (SE) with Counterfactual Evaluation (CFE), which
re-evaluates the submission against a deliberately false ground-truth answer.
An attack is detected if the system validates an answer under both standard and
counterfactual conditions. Experiments show that while standard evaluation is
highly vulnerable, our SE+CFE framework significantly improves security by
boosting attack detection with minimal performance trade-offs.

</details>


### [45] [LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora](https://arxiv.org/abs/2507.23611)
*Estelle Ruellan,Eric Clay,Nicholas Ascoli*

Main category: cs.CR

TL;DR: 本文提出利用LLMs（如gpt-4o-mini）分析感染截图以提取IoC、追踪攻击活动的新方法，通过Aurora窃密木马案例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前针对窃密日志的被动分析研究存在空白，尤其是感染截图这类关键证据被忽视。面对2024年超2900万条窃密日志，传统人工分析难以规模化。

Method: 采用LLMs解析感染截图，识别恶意URL、安装文件等攻击向量，通过文件名、URL和攻击主题关联追踪恶意活动。以Aurora窃密木马为对象，分析1000张截图。

Result: 从1000张截图中提取337个可行动URL和246个相关文件，揭示三种独立攻击活动，证实LLMs在识别社会工程策略和恶意软件分发链方面的潜力。

Conclusion: 将传统日志检测转向基于感染截图的被动分析方法，为威胁情报提供了可扩展的早期干预手段，展现了LLM驱动分析的变革性价值。

Abstract: Infostealers exfiltrate credentials, session cookies, and sensitive data from
infected systems. With over 29 million stealer logs reported in 2024, manual
analysis and mitigation at scale are virtually unfeasible/unpractical. While
most research focuses on proactive malware detection, a significant gap remains
in leveraging reactive analysis of stealer logs and their associated artifacts.
Specifically, infection artifacts such as screenshots, image captured at the
point of compromise, are largely overlooked by the current literature. This
paper introduces a novel approach leveraging Large Language Models (LLMs), more
specifically gpt-4o-mini, to analyze infection screenshots to extract potential
Indicators of Compromise (IoCs), map infection vectors, and track campaigns.
Focusing on the Aurora infostealer, we demonstrate how LLMs can process
screenshots to identify infection vectors, such as malicious URLs, installer
files, and exploited software themes. Our method extracted 337 actionable URLs
and 246 relevant files from 1000 screenshots, revealing key malware
distribution methods and social engineering tactics. By correlating extracted
filenames, URLs, and infection themes, we identified three distinct malware
campaigns, demonstrating the potential of LLM-driven analysis for uncovering
infection workflows and enhancing threat intelligence. By shifting malware
analysis from traditional log-based detection methods to a reactive,
artifact-driven approach that leverages infection screenshots, this research
presents a scalable method for identifying infection vectors and enabling early
intervention.

</details>


### [46] [Polynomial Lattices for the BIKE Cryptosystem](https://arxiv.org/abs/2507.23641)
*Michael Schaller*

Main category: cs.CR

TL;DR: 本文研究了BIKE密码系统中基于多项式环的秩2格，分析了其性质并推广了弱密钥恢复方法，通过构造格并求解最短向量问题，获得了格的约化基以检测更多弱密钥。


<details>
  <summary>Details</summary>
Motivation: 研究BIKE密码系统中由公钥生成的秩2格的性质，并扩展现有弱密钥恢复方法，以提升密钥安全性分析能力。

Method: 构建多项式环上的秩2格，将弱密钥恢复问题转化为格中的最短向量问题，并进一步计算格的约化基。

Result: 证明了现有弱密钥恢复方法实质是求解所构造格的最短向量问题，通过获得约化基可检测更多潜在弱密钥。

Conclusion: 该方法不仅可找到最短向量，还能通过约化基全面检测格的弱密钥结构，为密码系统安全性分析提供了新工具。

Abstract: In this paper we introduce a rank $2$ lattice over a polynomial ring arising
from the public key of the BIKE cryptosystem \cite{aragon2022bike}. The secret
key is a sparse vector in this lattice. We study properties of this lattice and
generalize the recovery of weak keys from \cite{BardetDLO16}. In particular, we
show that they implicitly solved a shortest vector problem in the lattice we
constructed. Rather than finding only a shortest vector, we obtain a reduced
basis of the lattice which makes it possible to check for more weak keys.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [47] [Unifying Post-hoc Explanations of Knowledge Graph Completions](https://arxiv.org/abs/2507.22951)
*Alessandro Lonardi,Samy Badreddine,Tarek R. Besold,Pablo Sanchez Martin*

Main category: cs.AI

TL;DR: 本文提出知识图谱补全（KGC）后验可解释性的统一框架，通过多目标优化平衡解释的有效性与简洁性，改进评估协议，并强调解释需面向终端用户的实际需求。


<details>
  <summary>Details</summary>
Motivation: 当前KGC后验可解释性研究缺乏形式化定义与标准化评估，导致可复现性与跨研究比较困难。本文旨在建立统一方法论以推动该领域发展。

Method: 1. 提出基于多目标优化的通用框架，统一现有KGC后验解释算法；2. 改进评估协议，采用Mean Reciprocal Rank和Hits@$k$等指标；3. 强调解释需针对用户实际查询需求。

Result: 框架成功整合现有方法，实证表明改进的评估协议（如Hits@$k$）能更有效衡量解释质量，同时验证面向用户需求的解释更具实践价值。

Conclusion: 通过统一方法论与优化评估标准，本研究提升了KGC可解释性研究的可复现性与应用价值，为后续研究奠定基础。

Abstract: Post-hoc explainability for Knowledge Graph Completion (KGC) lacks
formalization and consistent evaluations, hindering reproducibility and
cross-study comparisons. This paper argues for a unified approach to post-hoc
explainability in KGC. First, we propose a general framework to characterize
post-hoc explanations via multi-objective optimization, balancing their
effectiveness and conciseness. This unifies existing post-hoc explainability
algorithms in KGC and the explanations they produce. Next, we suggest and
empirically support improved evaluation protocols using popular metrics like
Mean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of
interpretability as the ability of explanations to address queries meaningful
to end-users. By unifying methods and refining evaluation standards, this work
aims to make research in KGC explainability more reproducible and impactful.

</details>


### [48] [Data Readiness for Scientific AI at Scale](https://arxiv.org/abs/2507.23018)
*Wesley Brewer,Patrick Widener,Valentine Anantharaj,Feiyi Wang,Tom Beck,Arjun Shankar,Sarp Oral*

Main category: cs.AI

TL;DR: 本文探讨了AI数据准备原则在领导级科学数据集上的应用，提出了一个针对高性能计算环境的两维度准备框架，用于指导科学数据向AI训练数据的转化。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决科学数据在训练基础模型时的预处理挑战，特别是在气候、核聚变、生物/健康和材料等代表性领域。

Method: 方法包括分析四个典型领域的工作流程，提出一个由数据准备级别（从原始到AI就绪）和数据处理阶段（从摄入到分片）组成的两维度框架，并针对高性能计算环境进行定制。

Result: 研究结果是一个概念性的成熟度矩阵，用于表征科学数据的准备状态，并指导基础设施开发，以实现跨领域的标准化、可扩展和可复现的科学AI支持。

Conclusion: 结论是这一框架能够有效指导科学数据向AI训练数据的转化，特别是在基于Transformer的生成模型应用中，为科学AI的标准化和可扩展性提供了重要支持。

Abstract: This paper examines how Data Readiness for AI (DRAI) principles apply to
leadership-scale scientific datasets used to train foundation models. We
analyze archetypal workflows across four representative domains - climate,
nuclear fusion, bio/health, and materials - to identify common preprocessing
patterns and domain-specific constraints. We introduce a two-dimensional
readiness framework composed of Data Readiness Levels (raw to AI-ready) and
Data Processing Stages (ingest to shard), both tailored to high performance
computing (HPC) environments. This framework outlines key challenges in
transforming scientific data for scalable AI training, emphasizing
transformer-based generative models. Together, these dimensions form a
conceptual maturity matrix that characterizes scientific data readiness and
guides infrastructure development toward standardized, cross-domain support for
scalable and reproducible AI for science.

</details>


### [49] [FairReason: Balancing Reasoning and Social Bias in MLLMs](https://arxiv.org/abs/2507.23067)
*Zhenyu Pan,Yutong Zhang,Jianshu Zhang,Haoran Lu,Haozheng Luo,Yuwei Han,Philip S. Yu,Manling Li,Han Liu*

Main category: cs.AI

TL;DR: 研究发现，在多模态大语言模型（MLLMs）中，通过强化学习以1:4比例混合去偏见与推理样本，能在降低10%刻板印象的同时保留88%的推理准确率，为平衡公平性与性能提供方案。


<details>
  <summary>Details</summary>
Motivation: 尽管先进提示方案与微调技术提升了MLLMs的逻辑准确性，但其输出仍存在显著社会偏见。探索推理能力提升与偏见缓解的相互作用及潜在权衡成为紧迫课题。

Method: 基准测试了监督微调（SFT）、知识蒸馏（KD）和基于规则的强化学习（RL）三种去偏见策略，并调整各范式中去偏见与推理样本的比例以绘制权衡曲线。

Result: 强化学习框架下1:4的样本比例构成最佳平衡点：刻板印象评分降低10%，同时保留原始推理准确率的88%。

Conclusion: 研究为MLLMs的公平性-能力权衡提供了实证指导，表明通过样本比例优化和强化学习可实现偏见缓解与推理性能的协同提升。

Abstract: Multimodal Large Language Models (MLLMs) already achieve state-of-the-art
results across a wide range of tasks and modalities. To push their reasoning
ability further, recent studies explore advanced prompting schemes and
post-training fine-tuning. Although these techniques improve logical accuracy,
they frequently leave the models' outputs burdened with pronounced social
biases. Clarifying how reasoning gains interact with bias mitigation-and
whether the two objectives inherently trade off-therefore remains an open and
pressing research problem. Our study begins by benchmarking three
bias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation
(KD), and rule-based reinforcement learning (RL)-under identical conditions,
establishing their baseline strengths and weaknesses. Building on these
results, we vary the proportion of debias-focused and reasoning-centric samples
within each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps
reveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement
learning cuts stereotype scores by 10% while retaining 88% of the model's
original reasoning accuracy, offering concrete guidance for balancing fairness
and capability in MLLMs.

</details>


### [50] [Moravec's Paradox: Towards an Auditory Turing Test](https://arxiv.org/abs/2507.23091)
*David Noever,Forrest McKee*

Main category: cs.AI

TL;DR: 当前AI系统在人类轻松完成的听觉任务上表现糟糕，失败率超过93%，揭示了AI在复杂听觉场景处理中的根本缺陷。


<details>
  <summary>Details</summary>
Motivation: 受Moravec悖论启发，研究旨在量化AI与人类在听觉任务上的差距，并探究失败原因。

Method: 设计包含7类917项挑战的听觉图灵测试，评估GPT-4音频能力及Whisper等先进模型。

Result: 最佳模型准确率仅6.9%（人类52%），暴露AI在选择性注意、噪声鲁棒性和情境适应方面的缺陷。

Conclusion: 需整合选择性注意、基于物理的音频理解和情境感知的新方法，建立诊断框架衡量机器听觉进展。

Abstract: This research work demonstrates that current AI systems fail catastrophically
on auditory tasks that humans perform effortlessly. Drawing inspiration from
Moravec's paradox (i.e., tasks simple for humans often prove difficult for
machines, and vice versa), we introduce an auditory Turing test comprising 917
challenges across seven categories: overlapping speech, speech in noise,
temporal distortion, spatial audio, coffee-shop noise, phone distortion, and
perceptual illusions. Our evaluation of state-of-the-art audio models including
GPT-4's audio capabilities and OpenAI's Whisper reveals a striking failure rate
exceeding 93%, with even the best-performing model achieving only 6.9% accuracy
on tasks that humans solved at 7.5 times higher success (52%). These results
expose focusing failures in how AI systems process complex auditory scenes,
particularly in selective attention, noise robustness, and contextual
adaptation. Our benchmark not only quantifies the human-machine auditory gap
but also provides insights into why these failures occur, suggesting that
current architectures lack fundamental mechanisms for human-like auditory scene
analysis. The traditional design of audio CAPTCHAs highlights common filters
that humans evolved but machines fail to select in multimodal language models.
This work establishes a diagnostic framework for measuring progress toward
human-level machine listening and highlights the need for novel approaches
integrating selective attention, physics-based audio understanding, and
context-aware perception into multimodal AI systems.

</details>


### [51] [Argumentatively Coherent Judgmental Forecasting](https://arxiv.org/abs/2507.23163)
*Deniz Gorur,Antonio Rago,Francesca Toni*

Main category: cs.AI

TL;DR: 本文提出并形式化定义了判断性预测中的论证连贯性属性，通过实验证明过滤不连贯预测可提升人类及LLM预测准确性，但用户实验显示该属性未被广泛认同，需在群体预测前整合过滤机制。


<details>
  <summary>Details</summary>
Motivation: 研究论证结构对判断性预测的影响，提出论证连贯性作为核心属性，旨在提升预测质量并验证其实际价值。

Method: 1. 形式化定义论证连贯性；2. 评估连贯性对人类和LLM预测准确性的影响；3. 通过众包实验分析用户对连贯性的认知一致性。

Result: 过滤不连贯预测显著提升人类及LLM准确性（如GPT-3），但用户实验显示多数人未自觉遵循该属性，存在认知偏差。

Conclusion: 论证连贯性具有实践价值但需主动整合至预测流程，建议在群体预测前建立不连贯观点过滤机制以提升整体质量。

Abstract: Judgmental forecasting employs human opinions to make predictions about
future events, rather than exclusively historical data as in quantitative
forecasting. When these opinions form an argumentative structure around
forecasts, it is useful to study the properties of the forecasts from an
argumentative perspective. In this paper, we advocate and formally define a
property of argumentative coherence, which, in essence, requires that a
forecaster's reasoning is coherent with their forecast. We then conduct three
evaluations with our notion of coherence. First, we assess the impact of
enforcing coherence on human forecasters as well as on Large Language Model
(LLM)-based forecasters, given that they have recently shown to be competitive
with human forecasters. In both cases, we show that filtering out incoherent
predictions improves forecasting accuracy consistently, supporting the
practical value of coherence in both human and LLM-based forecasting. Then, via
crowd-sourced user experiments, we show that, despite its apparent
intuitiveness and usefulness, users do not generally align with this coherence
property. This points to the need to integrate, within argumentation-based
judgmental forecasting, mechanisms to filter out incoherent opinions before
obtaining group forecasting predictions.

</details>


### [52] [Tractable Responsibility Measures for Ontology-Mediated Query Answering](https://arxiv.org/abs/2507.23191)
*Meghyn Bienvenu,Diego Figueira,Pierre Lafourcade*

Main category: cs.AI

TL;DR: 本文研究了基于Shapley值的责任度量（WSMS）在ontology中介查询回答中的计算复杂性，揭示了其在特定查询类别下的可处理性边界。


<details>
  <summary>Details</summary>
Motivation: 近期研究采用责任度量量化事实对查询答案的贡献，但ontology中介查询场景下的计算复杂性尚未充分探索。

Method: 通过结合数据库领域已有成果，分析WSMS在可一阶重写查询类中的计算特性，并考察本体语言表达能力对复杂性的影响。

Result: 证明WSMS在可一阶重写查询中具有多项式数据复杂性，但本体语言支持可达性查询（如$\exists R. A \sqsubseteq A$）时问题变为shP难；同时发现即使无本体，特定结构受限合取查询仍保持可处理性。

Conclusion: 研究明确了DL-Lite方言中结构受限查询的WSMS可计算性，为ontology中介查询解释提供了理论边界。

Abstract: Recent work on quantitative approaches to explaining query answers employs
responsibility measures to assign scores to facts in order to quantify their
respective contributions to obtaining a given answer. In this paper, we study
the complexity of computing such responsibility scores in the setting of
ontology-mediated query answering, focusing on a very recently introduced
family of Shapley-value-based responsibility measures defined in terms of
weighted sums of minimal supports (WSMS). By exploiting results from the
database setting, we can show that such measures enjoy polynomial data
complexity for classes of ontology-mediated queries that are
first-order-rewritable, whereas the problem becomes "shP"-hard when the
ontology language can encode reachability queries (via axioms like $\exists R.
A \sqsubseteq A$). To better understand the tractability frontier, we next
explore the combined complexity of WSMS computation. We prove that
intractability applies already to atomic queries if the ontology language
supports conjunction, as well as to unions of `well-behaved' conjunctive
queries, even in the absence of an ontology. By contrast, our study yields
positive results for common DL-Lite dialects: by means of careful analysis, we
identify classes of structurally restricted conjunctive queries (which
intuitively disallow undesirable interactions between query atoms) that admit
tractable WSMS computation.

</details>


### [53] [Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification](https://arxiv.org/abs/2507.23197)
*Yuke Liao,Blaise Genest,Kuldeep Meel,Shaan Aryaman*

Main category: cs.AI

TL;DR: 论文提出一种新型解决方案感知的ReLU评分方法（SAS），通过分治策略将复杂问题分解为多个小规模MILP调用，显著减少二进制变量数量并保持高精度，结合混合MILP方法实现高效验证。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂ReLU变量选择时效率不足，需开发更优策略以减少计算成本并提升验证效率。

Method: 提出SAS评分方法及改进的BaB-SR/BaB-FSB分支函数（GS），结合混合MILP流程：先调用$\alpha,\beta$-CROWN快速处理简单实例，再使用部分MILP处理剩余问题。

Result: SAS将二进制变量数量降低6倍，准确率不变；混合方法使未决实例减少40%（降至8-15%），平均耗时46-417秒（含200万参数CNN）。

Conclusion: SAS与混合MILP框架显著提升验证效率，为大规模神经网络验证提供实用解决方案。

Abstract: To handle complex instances, we revisit a divide-and-conquer approach to
break down the complexity: instead of few complex BaB calls, we rely on many
small {\em partial} MILP calls. The crucial step is to select very few but very
important ReLUs to treat using (costly) binary variables. The previous attempts
were suboptimal in that respect. To select these important ReLU variables, we
propose a novel {\em solution-aware} ReLU scoring ({\sf SAS}), as well as adapt
the BaB-SR and BaB-FSB branching functions as {\em global} ReLU scoring ({\sf
GS}) functions. We compare them theoretically as well as experimentally, and
{\sf SAS} is more efficient at selecting a set of variables to open using
binary variables. Compared with previous attempts, SAS reduces the number of
binary variables by around 6 times, while maintaining the same level of
accuracy. Implemented in {\em Hybrid MILP}, calling first $\alpha,\beta$-CROWN
with a short time-out to solve easier instances, and then partial MILP,
produces a very accurate yet efficient verifier, reducing by up to $40\%$ the
number of undecided instances to low levels ($8-15\%$), while keeping a
reasonable runtime ($46s-417s$ on average per instance), even for fairly large
CNNs with 2 million parameters.

</details>


### [54] [How Far Are AI Scientists from Changing the World?](https://arxiv.org/abs/2507.23276)
*Qiujie Xie,Yixuan Weng,Minjun Zhu,Fuchen Shen,Shulin Huang,Zhen Lin,Jiahui Zhou,Zilan Mao,Zijie Yang,Linyi Yang,Jian Wu,Yue Zhang*

Main category: cs.AI

TL;DR: 本文综述了基于大语言模型（LLM）的AI科学家系统在推动科学发现方面的潜力，探讨了其当前成就、关键瓶颈及未来发展目标。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的崛起，AI科学家系统正引领科研新范式，甚至产生被顶级会议接受的论文。本文旨在评估这类系统距颠覆科研范式、解决重大挑战的实际距离。

Method: 采用前瞻性综述方法，系统分析现有AI科学家系统的成果，识别关键瓶颈，并提炼突破性科学智能体所需的核心组件。

Result: 当前系统已能生成人类未知的发现（如ICLR 2025收录的AI论文），但仍存在理论框架不完善、自主创新能力受限等瓶颈。

Conclusion: 需明确当前AI科学家的局限性，聚焦突破性发现所需的认知架构与协作机制，最终实现解决重大科学难题的终极目标。

Abstract: The emergence of large language models (LLMs) is propelling automated
scientific discovery to the next level, with LLM-based Artificial Intelligence
(AI) Scientist systems now taking the lead in scientific research. Several
influential works have already appeared in the field of AI Scientist systems,
with AI-generated research papers having been accepted at the ICLR 2025
workshop, suggesting that a human-level AI Scientist capable of uncovering
phenomena previously unknown to humans, may soon become a reality. In this
survey, we focus on the central question: How far are AI scientists from
changing the world and reshaping the scientific research paradigm? To answer
this question, we provide a prospect-driven review that comprehensively
analyzes the current achievements of AI Scientist systems, identifying key
bottlenecks and the critical components required for the emergence of a
scientific agent capable of producing ground-breaking discoveries that solve
grand challenges. We hope this survey will contribute to a clearer
understanding of limitations of current AI Scientist systems, showing where we
are, what is missing, and what the ultimate goals for scientific AI should be.

</details>


### [55] [AI Must not be Fully Autonomous](https://arxiv.org/abs/2507.23330)
*Tosin Adewumi,Lama Alkhaled,Florent Imbert,Hui Han,Nudrat Habib,Karl Löwenmark*

Main category: cs.AI

TL;DR: 本文探讨了自主人工智能（AI）的三个层级，主张不应允许AI完全自主，以避免潜在风险，特别是在人工超级智能（ASI）可能几十年内出现的背景下。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于对自主AI潜在风险的关注，尤其是在ASI可能迅速发展的背景下，强调需要人类负责任的监督来降低这些风险。

Method: 研究方法包括讨论自主性、AI和智能体的理论，提出12个支持论点、6个反论点及其反驳，并在附录中提供15个AI价值观偏差及其他风险的近期证据。

Result: 研究结果表明，完全自主的AI（第三层级）在没有人类监督的情况下可能带来重大风险，而负责任的监督是缓解这些风险的关键。

Conclusion: 结论强调不应允许AI达到完全自主的第三层级，人类监督对于确保AI的安全和符合人类价值观至关重要。

Abstract: Autonomous Artificial Intelligence (AI) has many benefits. It also has many
risks. In this work, we identify the 3 levels of autonomous AI. We are of the
position that AI must not be fully autonomous because of the many risks,
especially as artificial superintelligence (ASI) is speculated to be just
decades away. Fully autonomous AI, which can develop its own objectives, is at
level 3 and without responsible human oversight. However, responsible human
oversight is crucial for mitigating the risks. To ague for our position, we
discuss theories of autonomy, AI and agents. Then, we offer 12 distinct
arguments and 6 counterarguments with rebuttals to the counterarguments. We
also present 15 pieces of recent evidence of AI misaligned values and other
risks in the appendix.

</details>


### [56] [DSBC : Data Science task Benchmarking with Context engineering](https://arxiv.org/abs/2507.23336)
*Ram Mohan Rao Kadiyala,Siddhant Gupta,Jebish Purbey,Giulio Martini,Suman Debnath,Hamza Farooq*

Main category: cs.AI

TL;DR: 本文提出一个针对数据科学代理的全面基准测试，评估了三种大型语言模型在不同方法下的表现，揭示了性能差异及影响因素，旨在为未来研究提供基础。


<details>
  <summary>Details</summary>
Motivation: 尽管数据科学代理快速普及，但缺乏系统性评估其效能和局限性的基准测试。本文旨在填补这一空白，通过真实用户交互数据构建基准。

Method: 评估了Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini三种模型，采用零样本上下文工程、多步上下文工程及SmolAgent三种方法，覆盖八类数据科学任务，并测试模型对提示问题的敏感性及温度参数影响。

Result: 发现不同模型和方法间存在显著性能差异，温度参数对任务特定结果有重要影响，揭示了实际部署中的关键因素。

Conclusion: 提出的基准数据集和评估框架为未来开发更鲁棒高效的数据科学代理奠定了基础，强调了模型选择和方法优化的重要性。

Abstract: Recent advances in large language models (LLMs) have significantly impacted
data science workflows, giving rise to specialized data science agents designed
to automate analytical tasks. Despite rapid adoption, systematic benchmarks
evaluating the efficacy and limitations of these agents remain scarce. In this
paper, we introduce a comprehensive benchmark specifically crafted to reflect
real-world user interactions with data science agents by observing usage of our
commercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,
Gemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with
context engineering, multi-step with context engineering, and with SmolAgent.
Our benchmark assesses performance across a diverse set of eight data science
task categories, additionally exploring the sensitivity of models to common
prompting issues, such as data leakage and slightly ambiguous instructions. We
further investigate the influence of temperature parameters on overall and
task-specific outcomes for each model and approach. Our findings reveal
distinct performance disparities among the evaluated models and methodologies,
highlighting critical factors that affect practical deployment. The benchmark
dataset and evaluation framework introduced herein aim to provide a foundation
for future research of more robust and effective data science agents.

</details>


### [57] [LLM4Rail: An LLM-Augmented Railway Service Consulting Platform](https://arxiv.org/abs/2507.23377)
*Zhuo Li,Xianghuai Deng,Chiwei Feng,Hanmeng Li,Shenjie Wang,Haichao Zhang,Teng Jia,Conlin Chen,Louis Linchun Wu,Jia Wang*

Main category: cs.AI

TL;DR: 本文提出LLM4Rail平台，通过大语言模型(LLM)增强铁路咨询服务，开发了迭代式QTAO提示框架和基于CRFD-25数据集的零样本对话推荐系统，实现个性化铁路服务。


<details>
  <summary>Details</summary>
Motivation: 为满足日益增长的个性化铁路服务需求，研究团队旨在开发一个LLM赋能的综合服务平台，整合票务、餐饮推荐、天气查询及闲聊等功能。

Method: 1) 提出QTAO提示框架，结合语言推理与任务导向行动；2) 构建CRFD-25铁路餐饮数据集；3) 开发基于特征相似度后处理的零样本对话推荐系统。

Result: 成功实现：1) 可精准检索铁路运营相关信息的交互系统；2) 覆盖25类特色菜肴的公开数据集；3) 确保推荐结果与数据集对齐的约束机制。

Conclusion: LLM4Rail通过创新框架与数据集，有效解决了铁路服务个性化需求，其方法论可扩展至其他垂直领域服务场景。

Abstract: Large language models (LLMs) have significantly reshaped different walks of
business. To meet the increasing demands for individualized railway service, we
develop LLM4Rail - a novel LLM-augmented railway service consulting platform.
Empowered by LLM, LLM4Rail can provide custom modules for ticketing, railway
food & drink recommendations, weather information, and chitchat. In LLM4Rail,
we propose the iterative "Question-Thought-Action-Observation (QTAO)" prompting
framework. It meticulously integrates verbal reasoning with task-oriented
actions, that is, reasoning to guide action selection, to effectively retrieve
external observations relevant to railway operation and service to generate
accurate responses. To provide personalized onboard dining services, we first
construct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible
takeout dataset tailored for railway services. CRFD-25 covers a wide range of
signature dishes categorized by cities, cuisines, age groups, and spiciness
levels. We further introduce an LLM-based zero-shot conversational recommender
for railway catering. To address the unconstrained nature of open
recommendations, the feature similarity-based post-processing step is
introduced to ensure all the recommended items are aligned with CRFD-25
dataset.

</details>


### [58] [Chatting with your ERP: A Recipe](https://arxiv.org/abs/2507.23429)
*Jorge Ruiz Gómez,Lidia Andrés Susinos,Jorge Alamo Olivé,Sonia Rey Osorno,Manuel Luis Gonzalez Hernández*

Main category: cs.AI

TL;DR: 本文介绍了一种基于大型语言模型（LLM）的智能代理，能够通过自然语言查询与工业级ERP系统交互，并生成可执行SQL语句。


<details>
  <summary>Details</summary>
Motivation: 旨在解决工业ERP系统中自然语言查询的自动化处理问题，提升人机交互效率。

Method: 采用双代理架构（推理+批判阶段），结合开源权重LLM实现查询语句的可靠生成。

Result: 所提方法显著提高了自然语言到SQL转换的准确性，适用于生产环境。

Conclusion: 双代理LLM架构为工业ERP系统提供了高效可靠的自然语言接口解决方案。

Abstract: This paper presents the design, implementation, and evaluation behind a Large
Language Model (LLM) agent that chats with an industrial production-grade ERP
system. The agent is capable of interpreting natural language queries and
translating them into executable SQL statements, leveraging open-weight LLMs. A
novel dual-agent architecture combining reasoning and critique stages was
proposed to improve query generation reliability.

</details>


### [59] [Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation](https://arxiv.org/abs/2507.23440)
*Mingzhe Li,Xin Lu,Yanyan Zhao*

Main category: cs.AI

TL;DR: 提出Self-Foveate方法，通过多级聚焦技术增强LLM从无监督文本中合成指令的多样性与难度。


<details>
  <summary>Details</summary>
Motivation: 现有自动化指令合成方法在保证多样性与难度方面存在显著不足，需减少人工标注依赖。

Method: 采用"Micro-Scatter-Macro"多级聚焦方法，引导LLM深度挖掘无监督文本中的细粒度信息。

Result: 跨多无监督语料库与模型架构的实验验证了方法的有效性与优越性。

Conclusion: Self-Foveate显著提升合成指令质量，相关数据与代码已开源。

Abstract: Large language models (LLMs) with instruction following capabilities have
demonstrated impressive problem-solving abilities. While synthesizing
instructional data from unsupervised text has become a common approach for
training such models, conventional methods rely heavily on human effort for
data annotation. Although existing automated synthesis paradigms have
alleviated this constraint, they still exhibit significant limitations in
ensuring adequate diversity and difficulty of synthesized instructions. To
address these challenges, we propose Self-Foveate, an innovative LLM-driven
method for instruction synthesis. This approach introduces a
"Micro-Scatter-Macro" multi-level foveation methodology that effectively guides
the LLM to deeply excavate fine-grained information embedded in unsupervised
text, thereby enhancing both the diversity and difficulty of synthesized
instructions. Comprehensive experiments across multiple unsupervised corpora
and diverse model architectures validate the effectiveness and superiority of
our proposed method. We publicly release our data and codes:
https://github.com/Mubuky/Self-Foveate

</details>


### [60] [Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery](https://arxiv.org/abs/2507.23488)
*Kacper Kadziolka,Saber Salehkaleybar*

Main category: cs.AI

TL;DR: 研究发现，采用推理优先架构的大型语言模型在因果发现任务上表现显著优于传统方法，结合模块化上下文管道可进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 因果推理是大型语言模型面临的核心挑战，传统模型在数据扰动下易出现过拟合和随机性能，研究探索推理优先架构能否提升因果发现的鲁棒性。

Method: 使用Corr2Cause基准测试OpenAI的o系列和DeepSeek-R模型，提出受思维树和思维链启发的模块化上下文管道，分析推理链长度和复杂度并进行定性与定量比较。

Result: 推理优先架构模型展现出显著优势，结合上下文管道后性能提升近三倍，但需结构化框架才能最大化其潜力。

Conclusion: 先进推理模型代表重大进步，精心设计的上下文框架对释放其能力至关重要，为跨领域因果发现提供了通用方案。

Abstract: Causal inference remains a fundamental challenge for large language models.
Recent advances in internal reasoning with large language models have sparked
interest in whether state-of-the-art reasoning models can robustly perform
causal discovery-a task where conventional models often suffer from severe
overfitting and near-random performance under data perturbations. We study
causal discovery on the Corr2Cause benchmark using the emergent OpenAI's
o-series and DeepSeek-R model families and find that these reasoning-first
architectures achieve significantly greater native gains than prior approaches.
To capitalize on these strengths, we introduce a modular in-context pipeline
inspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding
nearly three-fold improvements over conventional baselines. We further probe
the pipeline's impact by analyzing reasoning chain length, complexity, and
conducting qualitative and quantitative comparisons between conventional and
reasoning models. Our findings suggest that while advanced reasoning models
represent a substantial leap forward, carefully structured in-context
frameworks are essential to maximize their capabilities and offer a
generalizable blueprint for causal discovery across diverse domains.

</details>


### [61] [Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification](https://arxiv.org/abs/2507.23497)
*David A Kelly,Hana Chockler*

Main category: cs.AI

TL;DR: 本文提出了一种基于因果关系的图像分类器解释方法，该方法兼具形式化严谨性与黑盒算法适用性，并引入了对比性和完整性解释概念。实验证明该方法高效且无需模型内部信息。


<details>
  <summary>Details</summary>
Motivation: 现有图像分类器解释方法缺乏形式化严谨性，而逻辑解释虽严谨但依赖不适用于图像分类器的严格假设。本文旨在结合两者优势。

Method: 提出因果解释框架，证明其形式化性质；引入对比性因果解释和带置信度感知的完整因果解释。实现完全黑盒算法，无需模型内部信息。

Result: 实验显示不同模型在充分性、对比性和完整性上表现各异。算法平均每图6秒完成ResNet50解释，完全黑盒且高效。

Conclusion: 因果解释兼具形式化严谨性与实践可行性，为图像分类器提供无需模型知识的可计算解释方案，开辟了新研究方向。

Abstract: Existing algorithms for explaining the outputs of image classifiers are based
on a variety of approaches and produce explanations that lack formal rigor. On
the other hand, logic-based explanations are formally and rigorously defined
but their computability relies on strict assumptions about the model that do
not hold on image classifiers.
  In this paper, we show that causal explanations, in addition to being
formally and rigorously defined, enjoy the same formal properties as
logic-based ones, while still lending themselves to black-box algorithms and
being a natural fit for image classifiers. We prove formal properties of causal
explanations and introduce contrastive causal explanations for image
classifiers. Moreover, we augment the definition of explanation with confidence
awareness and introduce complete causal explanations: explanations that are
classified with exactly the same confidence as the original image.
  We implement our definitions, and our experimental results demonstrate that
different models have different patterns of sufficiency, contrastiveness, and
completeness. Our algorithms are efficiently computable, taking on average 6s
per image on a ResNet50 model to compute all types of explanations, and are
totally black-box, needing no knowledge of the model, no access to model
internals, no access to gradient, nor requiring any properties, such as
monotonicity, of the model.

</details>


### [62] [DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer](https://arxiv.org/abs/2507.23554)
*Ruoyu Wang,Junda Wu,Yu Xia,Tong Yu,Ryan A. Rossi,Julian McAuley,Lina Yao*

Main category: cs.AI

TL;DR: 本文提出DICE框架，通过动态选择上下文示例提升LLM代理性能，解决了现有方法依赖启发式规则且缺乏理论依据的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于上下文学习的代理模型对示例选择极为敏感，次优示例会导致性能不稳定或下降，亟需一种理论支撑的通用选择方法。

Method: DICE框架通过因果视角分解示例知识，提出逐步选择准则，并证明其能提升代理性能，无需额外训练即可嵌入现有框架。

Result: 跨领域实验验证了DICE的有效性和通用性，表明基于理论的动态示例选择能显著增强代理的鲁棒性和效率。

Conclusion: 研究表明，原则性、上下文感知的示例选择对构建高效LLM代理至关重要，DICE为此提供了通用解决方案。

Abstract: Large language model-based agents, empowered by in-context learning (ICL),
have demonstrated strong capabilities in complex reasoning and tool-use tasks.
However, existing works have shown that the effectiveness of ICL is highly
sensitive to the choice of demonstrations, with suboptimal examples often
leading to unstable or degraded performance. While prior work has explored
example selection, including in some agentic or multi-step settings, existing
approaches typically rely on heuristics or task-specific designs and lack a
general, theoretically grounded criterion for what constitutes an effective
demonstration across reasoning steps. Therefore, it is non-trivial to develop a
principled, general-purpose method for selecting demonstrations that
consistently benefit agent performance. In this paper, we address this
challenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a
theoretically grounded ICL framework for agentic tasks that selects the most
relevant demonstrations at each step of reasoning. Our approach decomposes
demonstration knowledge into transferable and non-transferable components
through a causal lens, showing how the latter can introduce spurious
dependencies that impair generalization. We further propose a stepwise
selection criterion with a formal guarantee of improved agent performance.
Importantly, DICE is a general, framework-agnostic solution that can be
integrated as a plug-in module into existing agentic frameworks without any
additional training cost. Extensive experiments across diverse domains
demonstrate our method's effectiveness and generality, highlighting the
importance of principled, context-aware demo selection for robust and efficient
LLM agents.

</details>


### [63] [Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI](https://arxiv.org/abs/2507.23565)
*Botao Zhu,Xianbin Wang,Dusit Niyato*

Main category: cs.AI

TL;DR: 本文提出一种基于语义信任链的自主信任编排方法，利用智能代理与超图技术实现分布式设备间高效信任评估，解决协作系统中资源动态性与评估开销的挑战。


<details>
  <summary>Details</summary>
Motivation: 分布式协作系统中，任务复杂性、设备资源动态性及信任评估开销导致资源利用率下降，亟需一种高效自主的信任管理机制。

Method: 1) 采用智能代理在设备空闲期基于历史数据自主评估信任；2) 通过超图嵌入信任语义实现分层管理；3) 链接局部信任超图支持多跳协作。

Result: 实验证明该方法实现资源高效的信任评估，平衡评估开销与准确性，提升大规模系统协作效率。

Conclusion: 语义信任链与智能代理的结合为动态分布式系统提供了一种资源优化的信任管理范式，显著提升协作任务执行效能。

Abstract: In collaborative systems, the effective completion of tasks hinges on
task-specific trust evaluations of potential devices for distributed
collaboration. However, the complexity of tasks, the spatiotemporal dynamism of
distributed device resources, and the inevitable assessment overhead
dramatically increase the complexity and resource consumption of the trust
evaluation process. As a result, ill-timed or overly frequent trust evaluations
can reduce utilization rate of constrained resources, negatively affecting
collaborative task execution. To address this challenge, this paper proposes an
autonomous trust orchestration method based on a new concept of semantic
chain-of-trust. Our technique employs agentic AI and hypergraph to establish
and maintain trust relationships among devices. By leveraging its strengths in
autonomous perception, task decomposition, and semantic reasoning, we propose
agentic AI to perceive device states and autonomously perform trust evaluations
of collaborators based on historical performance data only during device idle
periods, thereby enabling efficient utilization of distributed resources. In
addition, agentic AI performs task-specific trust evaluations on collaborator
resources by analyzing the alignment between resource capabilities and task
requirements. Moreover, by maintaining a trust hypergraph embedded with trust
semantics for each device, agentic AI enables hierarchical management of
collaborators and identifies collaborators requiring trust evaluation based on
trust semantics, thereby achieving a balance between overhead and trust
accuracy. Furthermore, local trust hypergraphs from multiple devices can be
chained together to support multi-hop collaboration, enabling efficient
coordination in large-scale systems. Experimental results demonstrate that the
proposed method achieves resource-efficient trust evaluation.

</details>


### [64] [MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying](https://arxiv.org/abs/2507.23633)
*Qian Zhao,Zhuo Sun,Bin Guo,Zhiwen Yu*

Main category: cs.AI

TL;DR: 本文提出了一种策略引导的代理辅助记忆回忆方法，通过设计Recall Router框架和5W回忆地图，结合蒙特卡洛树搜索算法优化策略选择，开发了MemoCue代理，显著提升了记忆回忆效果。


<details>
  <summary>Details</summary>
Motivation: 传统代理辅助记忆回忆方法受限于内存模块大小，难以获取完整记忆。受记忆理论启发，通过有效线索主动激活相关记忆，提出了策略引导的新方法。

Method: 设计了5W回忆地图将记忆查询分类为五种典型场景，定义了15种回忆策略模式，结合分层回忆树和蒙特卡洛树搜索算法优化策略选择与响应生成，并微调开源大语言模型开发MemoCue代理。

Result: 在三个代表性数据集上的实验表明，MemoCue在回忆灵感方面优于基于LLM的方法17.74%，人类评估进一步验证了其在记忆回忆应用中的优势。

Conclusion: 提出的策略引导代理辅助记忆回忆方法通过Recall Router框架和MemoCue代理，有效解决了多样化遗忘场景下的策略选择和高质量响应生成问题，显著提升了记忆回忆性能。

Abstract: Agent-assisted memory recall is one critical research problem in the field of
human-computer interaction. In conventional methods, the agent can retrieve
information from its equipped memory module to help the person recall
incomplete or vague memories. The limited size of memory module hinders the
acquisition of complete memories and impacts the memory recall performance in
practice. Memory theories suggest that the person's relevant memory can be
proactively activated through some effective cues. Inspired by this, we propose
a novel strategy-guided agent-assisted memory recall method, allowing the agent
to transform an original query into a cue-rich one via the judiciously designed
strategy to help the person recall memories. To this end, there are two key
challenges. (1) How to choose the appropriate recall strategy for diverse
forgetting scenarios with distinct memory-recall characteristics? (2) How to
obtain the high-quality responses leveraging recall strategies, given only
abstract and sparsely annotated strategy patterns? To address the challenges,
we propose a Recall Router framework. Specifically, we design a 5W Recall Map
to classify memory queries into five typical scenarios and define fifteen
recall strategy patterns across the corresponding scenarios. We then propose a
hierarchical recall tree combined with the Monte Carlo Tree Search algorithm to
optimize the selection of strategy and the generation of strategy responses. We
construct an instruction tuning dataset and fine-tune multiple open-source
large language models (LLMs) to develop MemoCue, an agent that excels in
providing memory-inspired responses. Experiments on three representative
datasets show that MemoCue surpasses LLM-based methods by 17.74% in recall
inspiration. Further human evaluation highlights its advantages in
memory-recall applications.

</details>


### [65] [Personalized Education with Ranking Alignment Recommendation](https://arxiv.org/abs/2507.23664)
*Haipeng Liu,Yuxuan Liu,Ting Long*

Main category: cs.AI

TL;DR: 本文提出了一种名为排名对齐推荐（RAR）的新方法，通过将协同思想融入探索机制，解决了传统强化学习在个性化问题推荐中探索效率低下的问题。实验证明RAR能有效提升推荐性能，且该框架适用于所有基于强化学习的问题推荐系统。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的个性化问题推荐方法在训练过程中难以高效探索，无法为每位学生找到最佳问题。这限制了推荐系统的性能和效果。

Method: 提出排名对齐推荐（RAR）框架，将协同思想融入探索机制，在有限训练轮次内实现更高效的探索。该方法可应用于任何基于强化学习的问题推荐系统。

Result: 实验结果表明，RAR显著提高了推荐性能，验证了该方法在个性化问题推荐任务中的有效性。

Conclusion: RAR通过改进探索机制解决了传统强化学习推荐系统的效率问题，为个性化学习推荐提供了新的解决方案。该框架具有通用性，可广泛应用于各类基于强化学习的推荐系统。

Abstract: Personalized question recommendation aims to guide individual students
through questions to enhance their mastery of learning targets. Most previous
methods model this task as a Markov Decision Process and use reinforcement
learning to solve, but they struggle with efficient exploration, failing to
identify the best questions for each student during training. To address this,
we propose Ranking Alignment Recommendation (RAR), which incorporates
collaborative ideas into the exploration mechanism, enabling more efficient
exploration within limited training episodes. Experiments show that RAR
effectively improves recommendation performance, and our framework can be
applied to any RL-based question recommender. Our code is available in
https://github.com/wuming29/RAR.git.

</details>


### [66] [TextQuests: How Good are LLMs at Text-Based Video Games?](https://arxiv.org/abs/2507.23701)
*Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks*

Main category: cs.AI

TL;DR: 论文提出了TextQuests基准，基于Infocom互动小说游戏，用于评估AI代理在需要长期自主推理的探索性环境中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能充分评估AI代理在需要长期自主推理的探索性环境中的能力，因此需要新的评估工具。

Method: 采用Infocom互动小说游戏作为基准，禁止使用外部工具，专注于评估代理在长期上下文中的内在推理能力。

Result: TextQuests基准成功模拟了需要试错学习和持续问题解决的探索性环境，为评估AI代理的长期推理能力提供了有效工具。

Conclusion: TextQuests为开发具有更强长期自主推理能力的AI代理提供了重要基准，推动了AI在复杂环境中的实际应用。

Abstract: Evaluating AI agents within complex, interactive environments that mirror
real-world challenges is critical for understanding their practical
capabilities. While existing agent benchmarks effectively assess skills like
tool use or performance on structured tasks, they often do not fully capture an
agent's ability to operate autonomously in exploratory environments that demand
sustained, self-directed reasoning over a long and growing context. To spur the
development of agents capable of more robust intrinsic reasoning over long
horizons, we introduce TextQuests, a benchmark based on the Infocom suite of
interactive fiction games. These text-based adventures, which can take human
players over 30 hours and require hundreds of precise actions to solve, serve
as an effective proxy for evaluating AI agents on focused, stateful tasks. The
benchmark is specifically designed to assess an LLM agent's capacity for
self-contained problem-solving by precluding the use of external tools, thereby
focusing on intrinsic long-context reasoning capabilities in an exploratory
environment characterized by the need for trial-and-error learning and
sustained problem-solving within a single interactive session. We release
TextQuests at https://textquests.ai.

</details>


### [67] [Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving](https://arxiv.org/abs/2507.23726)
*Luoxin Chen,Jinming Gu,Liankai Huang,Wenhao Huang,Zhicheng Jiang,Allan Jie,Xiaoran Jin,Xing Jin,Chenggang Li,Kaijing Ma,Cheng Ren,Jiawei Shen,Wenlei Shi,Tong Sun,He Sun,Jiahui Wang,Siran Wang,Zhihong Wang,Chenrui Wei,Shufa Wei,Yonghui Wu,Yuchen Wu,Yihang Xia,Huajian Xin,Fan Yang,Huaiyuan Ying,Hongyi Yuan,Zheng Yuan,Tianyang Zhan,Chi Zhang,Yue Zhang,Ge Zhang,Tianyun Zhao,Jianqiu Zhao,Yichi Zhou,Thomas Hanwen Zhu*

Main category: cs.AI

TL;DR: Seed-Prover是一种基于强化学习和形式化验证的定理证明模型，通过迭代优化证明过程，显著提升了IMO级数学问题的解决能力。结合Seed-Geometry几何推理引擎，该系统在IMO 2025中成功证明了5/6的题目。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在数学推理中缺乏明确的监督信号，而形式化验证语言（如Lean）能提供精确的反馈。本研究旨在结合两者优势，突破自动定理证明的瓶颈。

Method: 提出Seed-Prover模型：1) 基于Lean反馈、已证引理和自我总结迭代优化证明；2) 设计三种测试时推理策略实现深度/广度搜索；3) 开发Seed-Geometry引擎解决Lean的几何支持不足问题。

Result: 1) 在形式化IMO问题上达到78.1%证明率；2) MiniF2F基准达饱和；3) PutnamBench超过50%（大幅超越SOTA）；4) IMO 2025中5/6题完全证明。

Conclusion: 该工作通过形式化验证与长链推理的结合，实现了自动数学推理的重大进展，证明了领域专用语言与强化学习协同的有效性。

Abstract: LLMs have demonstrated strong mathematical reasoning abilities by leveraging
reinforcement learning with long chain-of-thought, yet they continue to
struggle with theorem proving due to the lack of clear supervision signals when
solely using natural language. Dedicated domain-specific languages like Lean
provide clear supervision via formal verification of proofs, enabling effective
training through reinforcement learning. In this work, we propose
\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover
can iteratively refine its proof based on Lean feedback, proved lemmas, and
self-summarization. To solve IMO-level contest problems, we design three
test-time inference strategies that enable both deep and broad reasoning.
Seed-Prover proves $78.1\%$ of formalized past IMO problems, saturates MiniF2F,
and achieves over 50\% on PutnamBench, outperforming the previous
state-of-the-art by a large margin. To address the lack of geometry support in
Lean, we introduce a geometry reasoning engine \textbf{Seed-Geometry}, which
outperforms previous formal geometry engines. We use these two systems to
participate in IMO 2025 and fully prove 5 out of 6 problems. This work
represents a significant advancement in automated mathematical reasoning,
demonstrating the effectiveness of formal verification with long
chain-of-thought reasoning.

</details>


### [68] [CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks](https://arxiv.org/abs/2507.23751)
*Ping Yu,Jack Lanchantin,Tianlu Wang,Weizhe Yuan,Olga Golovneva,Ilia Kulikov,Sainbayar Sukhbaatar,Jason Weston,Jing Xu*

Main category: cs.AI

TL;DR: 提出CoT-Self-Instruct方法，通过链式思考生成高质量合成数据，显著提升LLM在可验证推理和非可验证指令任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM训练数据集在复杂推理任务上表现不足，需要一种能自动生成高质量合成数据的方法。

Method: 基于种子任务引导LLM进行链式思考（CoT）规划，生成复杂度相当的合成提示，并通过自动指标过滤高质量数据。

Result: 在MATH500等可验证推理任务上超越s1k等数据集；在AlpacaEval 2.0等非可验证任务上优于人类或标准自指令提示。

Conclusion: CoT-Self-Instruct能有效生成优质训练数据，显著提升LLM在复杂推理和指令遵循任务中的性能。

Abstract: We propose CoT-Self-Instruct, a synthetic data generation method that
instructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the
given seed tasks, and then to generate a new synthetic prompt of similar
quality and complexity for use in LLM training, followed by filtering for
high-quality data with automatic metrics. In verifiable reasoning, our
synthetic data significantly outperforms existing training datasets, such as
s1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For
non-verifiable instruction-following tasks, our method surpasses the
performance of human or standard self-instruct prompts on both AlpacaEval 2.0
and Arena-Hard.

</details>


### [69] [SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model](https://arxiv.org/abs/2507.23773)
*Mingkai Deng,Jinyu Hou,Yilin Shen,Hongxia Jin,Graham Neubig,Zhiting Hu,Eric Xing*

Main category: cs.AI

TL;DR: 本文提出SimuRA架构，通过世界模型模拟克服自回归LLM的局限性，在网页浏览任务中实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理采用单任务单代理模式，缺乏可扩展性和通用性，且受限于自回归LLM的根本缺陷。人类通过心理模拟进行推理的通用性启发本研究。

Method: 基于最优代理理论框架，SimuRA引入LLM实现的通用世界模型，利用自然语言潜在空间进行跨环境规划。特别开发了网页浏览代理SimuRA作为研究演示。

Result: 在航班搜索任务中成功率从0%提升至32.2%，基于世界模型的规划比自回归规划最高优势达124%。

Conclusion: 世界模型模拟作为推理范式展现显著优势，为训练通用LLM代理模型奠定基础。SimuRA演示系统已开放公共测试。

Abstract: AI agents built on large language models (LLMs) hold enormous promise, but
current practice focuses on a one-task-one-agent approach, which not only falls
short of scalability and generality, but also suffers from the fundamental
limitations of autoregressive LLMs. On the other hand, humans are general
agents who reason by mentally simulating the outcomes of their actions and
plans. Moving towards a more general and powerful AI agent, we introduce
SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based
on a principled formulation of optimal agent in any environment, \modelname
overcomes the limitations of autoregressive reasoning by introducing a world
model for planning via simulation. The generalized world model is implemented
using LLM, which can flexibly plan in a wide range of environments using the
concept-rich latent space of natural language. Experiments on difficult web
browsing tasks show that \modelname improves the success of flight search from
0\% to 32.2\%. World-model-based planning, in particular, shows consistent
advantage of up to 124\% over autoregressive planning, demonstrating the
advantage of world model simulation as a reasoning paradigm. We are excited
about the possibility for training a single, general agent model based on LLMs
that can act superintelligently in all environments. To start, we make SimuRA,
a web-browsing agent built on \modelname with pretrained LLMs, available as a
research demo for public testing.

</details>


<div id='stat.TH'></div>

# stat.TH [[Back]](#toc)

### [70] [Information geometry of Lévy processes and financial models](https://arxiv.org/abs/2507.23646)
*Jaehyung Choi*

Main category: stat.TH

TL;DR: 本文探讨了L\'evy过程的信息几何，推导了$\alpha$-散度，计算了Fisher信息矩阵和$\alpha$-连接，并讨论了在金融建模中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究L\'evy过程的信息几何结构，为金融建模中的随机过程提供新的几何视角和统计工具。

Method: 从$\alpha$-散度出发，推导了L\'evy过程的Fisher信息矩阵和$\alpha$-连接，并分析了多种金融相关L\'evy过程的微分几何结构。

Result: 成功建立了L\'evy过程的信息几何框架，包括tempered stable过程、CGMY模型和方差gamma过程的几何结构分析。

Conclusion: 该研究为L\'evy过程提供了信息几何的理论基础，并在金融建模中展示了实际应用潜力。

Abstract: We explore the information geometry of L\'evy processes. As a starting point,
we derive the $\alpha$-divergence between two L\'evy processes. Subsequently,
the Fisher information matrix and the $\alpha$-connection associated with the
geometry of L\'evy processes are computed from the $\alpha$-divergence. In
addition, we discuss statistical applications of this information geometry. As
illustrative examples, we investigate the differential-geometric structures of
various L\'evy processes relevant to financial modeling, including tempered
stable processes, the CGMY model, and variance gamma processes.

</details>
