{"id": "2507.22961", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2507.22961", "abs": "https://arxiv.org/abs/2507.22961", "authors": ["Yushi Huang"], "title": "On the Explicit Expression of an Extended Version of Riemann Zeta Function", "comment": "24 pages, 0 figures", "summary": "In this paper, we focus on the explicit expression of an extended version of\nRiemann zeta function. We use two different methods, Mellin inversion formula\nand Cauchy's residue theorem, to calculate a Mellin-Barnes type integral of the\nanalytic function regarding $z$: $\\Gamma(z)\\Gamma(s-z)u^{-z}$ ($u\\in (0,1)$,\n$s\\in \\mathbb{C}$). We provide the necessary background on the analytic\nproperties of Gamma and Riemann zeta function to confirm the absolute\nconvergence of this Mellin-Barnes integral. Next, we represent the extended\nversion of Riemann zeta function\n$\\sum_{m=1}^{\\infty}\\sum_{n=1}^{\\infty}{(m+n)^{-s}}$ using the following\ncomplex integral where the real part of $s$ is larger than 2 and $c>1$ is\nchosen to make $\\Re(s)-c$ larger than 1.\n$$\\Gamma(s)\\sum_{m=1}^{\\infty}\\sum_{n=1}^{\\infty}{(m+n)^{-s}}=\\frac{1}{2\\pi i}\n\\int_{c - i\\infty}^{c + i\\infty} \\zeta(z) \\zeta(s - z) \\Gamma(z) \\Gamma(s - z)\n\\, dz$$ We provide the evaluation of this integral by changing the integration\npath from straight line $\\Re(z)=c$ into a rectangular contour whose left side\nis positioned at negative infinity. We apply the functional equation of Riemann\nzeta function, Euler's reflection formula, and Legendre's duplication formula\nto evaluate the integral segment through $\\Re(z)=-\\infty$. After introducing\nHurwitz zeta function and properly calculating the difference between the sum\nof residues in two analogous rectangular contours, we finalize the evaluation.\nLastly, we demonstrate the connection of this result with other intricate\nintegrals involving special functions, such as the hyperbolic function.\nAdditionally, we discuss its applications in deriving explicit expressions for\nthe Barnes zeta function."}
{"id": "2507.23503", "categories": ["math.LO", "03C45, 03C95, 37B02, 28C10, 28E15, 43A05"], "pdf": "https://arxiv.org/pdf/2507.23503", "abs": "https://arxiv.org/abs/2507.23503", "authors": ["Kyle Gannon", "Daniel Max Hoffmann", "Krzysztof Krupiński"], "title": "Convolution semigroups for automorphism dynamics", "comment": "102 pages", "summary": "Initially motivated by Hrushovski's paper on definability patterns, we obtain\nhomeomorphisms between Ellis semigroups related to natural actions of the\nautomorphism groups of first order structures and certain collections of types\nand Keisler measures. Thus, we can transfer the semigroup operation from these\nEllis semigroups to the corresponding collections of types and Keisler\nmeasures. By generalizing this transferred product, we obtain a new convolution\noperation for invariant types and measures in arbitrary first-order theories.\nWe develop its general theory and prove several correspondence theorems between\nidempotent measures and closed subgroups of the automorphism group of a\nsufficiently large (so-called monster) model with respect to the relatively\ndefinable topology. Via the affine sort construction, we demonstrate that this\nnew notion of convolution encodes the standard definable convolution operation\nover definable groups."}
{"id": "2507.23041", "categories": ["math.NT", "11B05"], "pdf": "https://arxiv.org/pdf/2507.23041", "abs": "https://arxiv.org/abs/2507.23041", "authors": ["Nathan McNew", "Jai Setty"], "title": "On the densities of covering numbers and abundant numbers", "comment": null, "summary": "We investigate the densities of the sets of abundant numbers and of covering\nnumbers, integers $n$ for which there exists a distinct covering system where\nevery modulus divides $n$. We establish that the set $\\mathcal{C}$ of covering\nnumbers possesses a natural density $d(\\mathcal{C})$ and prove that $0.103230 <\nd(\\mathcal{C}) < 0.103398.$ Our approach adapts methods developed by Behrend\nand Del\\'eglise for bounding the density of abundant numbers, by introducing a\nfunction $c(n)$ that measures how close an integer $n$ is to being a covering\nnumber with the property that $c(n) \\leq h(n) = \\sigma(n)/n$. However,\ncomputing $d(\\mathcal{C})$ to three decimal digits requires some new ideas to\nsimplify the computations. As a byproduct of our methods, we obtain\nsignificantly improved bounds for $d(\\mathcal{A})$, the density of abundant\nnumbers, namely $0.247619608 < d(\\mathcal{A}) < 0.247619658$. We also show the\ncount of primitive covering numbers up to $x$ is $O\\left(\nx\\exp\\left(\\left(-\\tfrac{1}{2\\sqrt{\\log 2}} + \\epsilon\\right)\\sqrt{\\log x} \\log\n\\log x\\right)\\right)$, which is substantially smaller than the corresponding\nbound for primitive abundant numbers."}
{"id": "2507.23054", "categories": ["math.OC", "90C30, 90C56, 49J52", "G.1.6; G.4"], "pdf": "https://arxiv.org/pdf/2507.23054", "abs": "https://arxiv.org/abs/2507.23054", "authors": ["Charles Audet", "Théo Denorme", "Youssef Diouane", "Sébastien Le Digabel", "Christophe Tribes"], "title": "Adaptive direct search algorithms for constrained optimization", "comment": null, "summary": "Two families of directional direct search methods have emerged in\nderivative-free and blackbox optimization (DFO and BBO), each based on distinct\nprinciples: Mesh Adaptive Direct Search (MADS) and Sufficient Decrease Direct\nSearch (SDDS). MADS restricts trial points to a mesh and accepts any\nimprovement, ensuring none are missed, but at the cost of restraining the\nplacement of trial points. SDDS allows greater freedom by evaluating points\nanywhere in the space, but accepts only those yielding a sufficient decrease in\nthe objective function value, which may lead to discarding improving points.\n  This work introduces a new class of methods, Adaptive Direct Search (ADS),\nwhich uses a novel acceptance rule based on the so-called punctured space,\navoiding both meshes and sufficient decrease conditions. ADS enables flexible\nsearch while addressing the limitations of MADS and SDDS, and retains the\ntheoretical foundations of directional direct search. Computational results in\nconstrained and unconstrained settings highlight its performance compared to\nboth MADS and SDDS."}
{"id": "2507.22957", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.22957", "abs": "https://arxiv.org/abs/2507.22957", "authors": ["María José Chávez de Diego", "Pablo Montero Moreno", "María Trinidad Villar-Liñán"], "title": "Domination, matching and transversal numbers for Berge-$G$ hypergraphs", "comment": null, "summary": "Let $G=(V(G),E(G))$ be a graph and $H=(V(H),E(H))$ be a hypergraph. The\nhypergraph $H$ is a {\\it Berge-G} if there is a bijection $f : E(G) \\mapsto\nE(H)$ such that for each $e \\in E(G)$ we have $e \\subseteq f(e)$. We define\n{\\it dilations of $G$} as a particular subfamily of not necessarily uniform\nBerge-$G$ hypergraphs. We examine domination, matching and transversal numbers\nand some relation between these parameters in that family of hypergraphs.\n  Our work generalizes previous results concerning generalized power\nhypergraphs."}
{"id": "2507.22908", "categories": ["q-fin.CP", "cs.AI", "cs.LG", "I.2"], "pdf": "https://arxiv.org/pdf/2507.22908", "abs": "https://arxiv.org/abs/2507.22908", "authors": ["Abhishek Sawaika", "Swetang Krishna", "Tushar Tomar", "Durga Pritam Suggisetti", "Aditi Lal", "Tanmaya Shrivastav", "Nouhaila Innan", "Muhammad Shafique"], "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection", "comment": "To be published in proceedings of IEEE International Conference on\n  Quantum Computing and Engineering (QCE) 2025", "summary": "Rapid growth of digital transactions has led to a surge in fraudulent\nactivities, challenging traditional detection methods in the financial sector.\nTo tackle this problem, we introduce a specialised federated learning framework\nthat uniquely combines a quantum-enhanced Long Short-Term Memory (LSTM) model\nwith advanced privacy preserving techniques. By integrating quantum layers into\nthe LSTM architecture, our approach adeptly captures complex\ncross-transactional patters, resulting in an approximate 5% performance\nimprovement across key evaluation metrics compared to conventional models.\nCentral to our framework is \"FedRansel\", a novel method designed to defend\nagainst poisoning and inference attacks, thereby reducing model degradation and\ninference accuracy by 4-8%, compared to standard differential privacy\nmechanisms. This pseudo-centralised setup with a Quantum LSTM model, enhances\nfraud detection accuracy and reinforces the security and confidentiality of\nsensitive financial data."}
{"id": "2507.23229", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.23229", "abs": "https://arxiv.org/abs/2507.23229", "authors": ["Yufei Chen", "Yao Wang", "Haibin Zhang", "Tao Gu"], "title": "Fine-Grained Privacy Extraction from Retrieval-Augmented Generation Systems via Knowledge Asymmetry Exploitation", "comment": null, "summary": "Retrieval-augmented generation (RAG) systems enhance large language models\n(LLMs) by integrating external knowledge bases, but this advancement introduces\nsignificant privacy risks. Existing privacy attacks on RAG systems can trigger\ndata leakage but often fail to accurately isolate knowledge-base-derived\nsentences within mixed responses. They also lack robustness when applied across\nmultiple domains. This paper addresses these challenges by presenting a novel\nblack-box attack framework that exploits knowledge asymmetry between RAG and\nstandard LLMs to achieve fine-grained privacy extraction across heterogeneous\nknowledge landscapes. We propose a chain-of-thought reasoning strategy that\ncreates adaptive prompts to steer RAG systems away from sensitive content.\nSpecifically, we first decompose adversarial queries to maximize information\ndisparity and then apply a semantic relationship scoring to resolve lexical and\nsyntactic ambiguities. We finally train a neural network on these feature\nscores to precisely identify sentences containing private information. Unlike\nprior work, our framework generalizes to unseen domains through iterative\nrefinement without pre-defined knowledge. Experimental results show that we\nachieve over 91% privacy extraction rate in single-domain and 83% in\nmulti-domain scenarios, reducing sensitive sentence exposure by over 65% in\ncase studies. This work bridges the gap between attack and defense in RAG\nsystems, enabling precise extraction of private information while providing a\nfoundation for adaptive mitigation."}
{"id": "2507.23140", "categories": ["math.ST", "stat.AP", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.23140", "abs": "https://arxiv.org/abs/2507.23140", "authors": ["JungHo Lee", "Valerio Baćak", "Edward H. Kennedy"], "title": "Learning Smooth Populations of Parameters with Trial Heterogeneity", "comment": null, "summary": "We consider the classical problem of estimating the mixing distribution of\nbinomial mixtures, but under trial heterogeneity and smoothness. This problem\nhas been studied extensively when the trial parameter is homogeneous, but not\nunder the more general scenario of heterogeneous trials, and only within a low\nsmoothness regime, where the resulting rates are slow. Under the assumption\nthat the density is s-smooth, we derive fast error rates for the kernel density\nestimator under trial heterogeneity that depend on the harmonic mean of the\ntrials. Importantly, even when reduced to the homogeneous case, our result\nimproves on the state-of-the-art rate of Ye and Bickel (2021). We also study\nnonparametric estimation of the difference between two densities, which can be\nsmoother than the individual densities, in both i.i.d. and binomial-mixture\nsettings. Our work is motivated by an application in criminal justice:\ncomparing conviction rates of indigent representation in Pennsylvania. We find\nthat the estimated conviction rates for appointed counsel (court-appointed\nprivate attorneys) are generally higher than those for public defenders,\npotentially due to a confounding factor: appointed counsel are more likely to\ntake on severe cases."}
{"id": "2507.22951", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22951", "abs": "https://arxiv.org/abs/2507.22951", "authors": ["Alessandro Lonardi", "Samy Badreddine", "Tarek R. Besold", "Pablo Sanchez Martin"], "title": "Unifying Post-hoc Explanations of Knowledge Graph Completions", "comment": null, "summary": "Post-hoc explainability for Knowledge Graph Completion (KGC) lacks\nformalization and consistent evaluations, hindering reproducibility and\ncross-study comparisons. This paper argues for a unified approach to post-hoc\nexplainability in KGC. First, we propose a general framework to characterize\npost-hoc explanations via multi-objective optimization, balancing their\neffectiveness and conciseness. This unifies existing post-hoc explainability\nalgorithms in KGC and the explanations they produce. Next, we suggest and\nempirically support improved evaluation protocols using popular metrics like\nMean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of\ninterpretability as the ability of explanations to address queries meaningful\nto end-users. By unifying methods and refining evaluation standards, this work\naims to make research in KGC explainability more reproducible and impactful."}
{"id": "2507.23102", "categories": ["math.NT", "11F70 (primary) 11F22, 11F75 (secondary)"], "pdf": "https://arxiv.org/pdf/2507.23102", "abs": "https://arxiv.org/abs/2507.23102", "authors": ["Jin Kunwoo Lee"], "title": "Nonzero $\\mathfrak{n}$ cohomology of Totally Degenerate Limit of Discrete Series representations", "comment": null, "summary": "We show that a totally degenerate limit of discrete series representation\nadmits a choice of n cohomology group that is nonvanishing at a canonically\ndefined degree. We then show that the combinatorial complexes used by Soergel\nto compute these cohomology groups satisfies Serre duality. We conclude that\nthis produces two n cohomology groups, each for a totally degenerate limit of\ndiscrete series of U(n+1) and U(n), which are nonvanishing at the same degree.\nThis suggests Gan Gross Prasad type branching laws for the TDLDS of unitary\ngroups of any rank."}
{"id": "2507.23094", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.23094", "abs": "https://arxiv.org/abs/2507.23094", "authors": ["Vincenzo Di Vito", "Kaarthik Sundar", "Ferdinando Fioretto", "Deepjyoti Deka"], "title": "Stability-Constrained AC Optimal Power Flow -- A Gaussian Process-Based Approach", "comment": "12 pages", "summary": "The Alternating Current Optimal Power Flow (ACOPF) problem is a core task in\npower system operations, aimed at determining cost-effective generation\ndispatch while satisfying physical and operational constraints. However,\nconventional ACOPF formulations rely on steady-state models and neglect the\ndynamic behavior of generators, which can lead to operating points that are\neconomically optimal but dynamically unstable. This paper proposes a novel,\ndata-driven approach to incorporate generator dynamics into the ACOPF using\nGaussian Process (GP) models. Specifically, it introduces an exponential\nsurrogate function to characterize the stability of solutions to the\ndifferential equations governing synchronous generator dynamics. The exponent,\nwhich indicates whether system trajectories decay (stable) or grow (unstable),\nis learned as a function of the bus voltage using GP regression. Crucially, the\nframework enables probabilistic stability assessment to be integrated directly\ninto the optimization process. The resulting dynamics-aware ACOPF formulation\nidentifies operating points that satisfy both operational safety and dynamic\nstability criteria. Numerical experiments on the IEEE 39-bus, 57-bus, and\n118-bus systems demonstrate that the proposed method efficiently captures\ngenerator dynamics using limited training data, leading to more reliable and\nrobust decisions across a wide range of operating conditions."}
{"id": "2507.23039", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.23039", "abs": "https://arxiv.org/abs/2507.23039", "authors": ["Seth R. Nelson", "Eric Swartz"], "title": "Character theoretic techniques for nonabelian partial difference sets", "comment": null, "summary": "A $(v,k,\\lambda, \\mu)$-partial difference set (PDS) is a subset $D$ of size\n$k$ of a group $G$ of order $v$ such that every nonidentity element $g$ of $G$\ncan be expressed in either $\\lambda$ or $\\mu$ different ways as a product\n$xy^{-1}$, $x, y \\in D$, depending on whether or not $g$ is in $D$. If $D$ is\ninverse closed and $1 \\notin D$, then the Cayley graph ${\\rm Cay}(G,D)$ is a\n$(v,k,\\lambda, \\mu)$-strongly regular graph (SRG). PDSs have been studied\nextensively over the years, especially in abelian groups, where techniques from\ncharacter theory have proven to be particularly effective. Recently, there has\nbeen considerable interest in studying PDSs in nonabelian groups, and the\npurpose of this paper is develop character theoretic techniques that apply in\nthe nonabelian setting. We prove that analogues of character theoretic results\nof Ott about generalized quadrangles of order $s$ also hold in the general PDS\nsetting, and we are able to use these techniques to compute the intersection of\na putative PDS with the conjugacy classes of the parent group in many\ninstances. With these techniques, we are able to prove the nonexistence of PDSs\nin numerous instances and provide severe restrictions in cases when such PDSs\nmay still exist. Furthermore, we are able to use these techniques\nconstructively, computing several examples of PDSs in nonabelian groups not\npreviously recognized in the literature, including an infinite family of\ngenuinely nonabelian PDSs associated to the block-regular Steiner triple\nsystems originally studied by Clapham and related infinite families of\ngenuinely nonabelian PDSs associated to the block-regular Steiner $2$-designs\nfirst studied by Wilson."}
{"id": "2507.23453", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23453", "abs": "https://arxiv.org/abs/2507.23453", "authors": ["Lijia Liu", "Takumi Kondo", "Kyohei Atarashi", "Koh Takeuchi", "Jiyi Li", "Shigeru Saito", "Hisashi Kashima"], "title": "Counterfactual Evaluation for Blind Attack Detection in LLM-based Evaluation Systems", "comment": null, "summary": "This paper investigates defenses for LLM-based evaluation systems against\nprompt injection. We formalize a class of threats called blind attacks, where a\ncandidate answer is crafted independently of the true answer to deceive the\nevaluator. To counter such attacks, we propose a framework that augments\nStandard Evaluation (SE) with Counterfactual Evaluation (CFE), which\nre-evaluates the submission against a deliberately false ground-truth answer.\nAn attack is detected if the system validates an answer under both standard and\ncounterfactual conditions. Experiments show that while standard evaluation is\nhighly vulnerable, our SE+CFE framework significantly improves security by\nboosting attack detection with minimal performance trade-offs."}
{"id": "2507.23285", "categories": ["math.ST", "math.PR", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.23285", "abs": "https://arxiv.org/abs/2507.23285", "authors": ["Seunghyun Lee", "Nabarun Deb", "Sumit Mukherjee"], "title": "CLT in high-dimensional Bayesian linear regression with low SNR", "comment": null, "summary": "We study central limit theorems for linear statistics in high-dimensional\nBayesian linear regression with product priors. Unlike the existing literature\nwhere the focus is on posterior contraction, we work under a non-contracting\nregime where neither the likelihood nor the prior dominates the other. This is\nmotivated by modern high-dimensional datasets characterized by a bounded\nsignal-to-noise ratio. This work takes a first step towards understanding limit\ndistributions for one-dimensional projections of the posterior, as well as the\nposterior mean, in such regimes. Analogous to contractive settings, the\nresulting limiting distributions are Gaussian, but they heavily depend on the\nchosen prior and center around the Mean-Field approximation of the posterior.\nWe study two concrete models of interest to illustrate this phenomenon -- the\nwhite noise design, and the (misspecified) Bayesian model. As an application,\nwe construct credible intervals and compute their coverage probability under\nany misspecified prior. Our proofs rely on a combination of recent developments\nin Berry-Esseen type bounds for Random Field Ising models and both first and\nsecond order Poincar\\'{e} inequalities. Notably, our results do not require any\nsparsity assumptions on the prior."}
{"id": "2507.23018", "categories": ["cs.AI", "cs.CE", "cs.DC", "cs.LG", "I.2.6"], "pdf": "https://arxiv.org/pdf/2507.23018", "abs": "https://arxiv.org/abs/2507.23018", "authors": ["Wesley Brewer", "Patrick Widener", "Valentine Anantharaj", "Feiyi Wang", "Tom Beck", "Arjun Shankar", "Sarp Oral"], "title": "Data Readiness for Scientific AI at Scale", "comment": "10 pages, 1 figure, 2 tables", "summary": "This paper examines how Data Readiness for AI (DRAI) principles apply to\nleadership-scale scientific datasets used to train foundation models. We\nanalyze archetypal workflows across four representative domains - climate,\nnuclear fusion, bio/health, and materials - to identify common preprocessing\npatterns and domain-specific constraints. We introduce a two-dimensional\nreadiness framework composed of Data Readiness Levels (raw to AI-ready) and\nData Processing Stages (ingest to shard), both tailored to high performance\ncomputing (HPC) environments. This framework outlines key challenges in\ntransforming scientific data for scalable AI training, emphasizing\ntransformer-based generative models. Together, these dimensions form a\nconceptual maturity matrix that characterizes scientific data readiness and\nguides infrastructure development toward standardized, cross-domain support for\nscalable and reproducible AI for science."}
{"id": "2507.23179", "categories": ["math.NT", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.23179", "abs": "https://arxiv.org/abs/2507.23179", "authors": ["Juncheng Zhou", "Hongfeng Wu"], "title": "Cyclotomy, cyclotomic cosets and arimetic propeties of some families in $\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$", "comment": null, "summary": "Arithmetic properties of some families in $\\frac{\\mathbb{F}_l[x]}{\\langle\nx^{p^sq^t}-1\\rangle}$ are obtained by using the cyclotomic classes of order 2\nwith respect to $n=p^sq^t$, where $p\\equiv3 \\mathrm{mod} 4$,\n$\\gcd(\\phi(p^s),\\phi(q^t))=2$, $l$ is a primitive root modulo $q^t$ and\n$\\mathrm{ord}_{p^s}(l)=\\phi(p^s)/2$. The form of these cyclotomic classes\nenables us to further generalize the results obtained in \\cite{ref1}. The\nexplicit expressions of primitive idempotents of minimal ideals in\n$\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$ are also obtained."}
{"id": "2507.23155", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23155", "abs": "https://arxiv.org/abs/2507.23155", "authors": ["Jincheng Cao", "Ruichen Jiang", "Erfan Yazdandoost Hamedani", "Aryan Mokhtari"], "title": "On the Complexity of Finding Stationary Points in Nonconvex Simple Bilevel Optimization", "comment": null, "summary": "In this paper, we study the problem of solving a simple bilevel optimization\nproblem, where the upper-level objective is minimized over the solution set of\nthe lower-level problem. We focus on the general setting in which both the\nupper- and lower-level objectives are smooth but potentially nonconvex. Due to\nthe absence of additional structural assumptions for the lower-level\nobjective-such as convexity or the Polyak-{\\L}ojasiewicz (PL)\ncondition-guaranteeing global optimality is generally intractable. Instead, we\nintroduce a suitable notion of stationarity for this class of problems and aim\nto design a first-order algorithm that finds such stationary points in\npolynomial time. Intuitively, stationarity in this setting means the\nupper-level objective cannot be substantially improved locally without causing\na larger deterioration in the lower-level objective. To this end, we show that\na simple and implementable variant of the dynamic barrier gradient descent\n(DBGD) framework can effectively solve the considered nonconvex simple bilevel\nproblems up to stationarity. Specifically, to reach an $(\\epsilon_f,\n\\epsilon_g)$-stationary point-where $\\epsilon_f$ and $\\epsilon_g$ denote the\ntarget stationarity accuracies for the upper- and lower-level objectives,\nrespectively-the considered method achieves a complexity of\n$\\mathcal{O}\\left(\\max\\left(\\epsilon_f^{-\\frac{3+p}{1+p}},\n\\epsilon_g^{-\\frac{3+p}{2}}\\right)\\right)$, where $p \\geq 0$ is an arbitrary\nconstant balancing the terms. To the best of our knowledge, this is the first\ncomplexity result for a discrete-time algorithm that guarantees joint\nstationarity for both levels in general nonconvex simple bilevel problems."}
{"id": "2507.23182", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.23182", "abs": "https://arxiv.org/abs/2507.23182", "authors": ["Rutger Campbell", "James Davies", "Robert Hickingbotham"], "title": "Binary matroids and degree-boundedness for pivot-minors", "comment": "11 pages, 2 figures", "summary": "We prove that for every bipartite graph $H$ and positive integer $s$, the\nclass of $K_{s,s}$-subgraph-free graphs excluding $H$ as a pivot-minor has\nbounded average degree. Our proof relies on the announced binary matroid\nstructure theorem of Geelen, Gerards, and Whittle.\n  Along the way, we also prove that every $K_{s,t}$-free bipartite circle graph\nwith $s\\le t$ has a vertex of degree at most $\\max\\{2s-2, t-1\\}$ and provide\nexamples showing that this is tight."}
{"id": "2507.23611", "categories": ["cs.CR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23611", "abs": "https://arxiv.org/abs/2507.23611", "authors": ["Estelle Ruellan", "Eric Clay", "Nicholas Ascoli"], "title": "LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora", "comment": null, "summary": "Infostealers exfiltrate credentials, session cookies, and sensitive data from\ninfected systems. With over 29 million stealer logs reported in 2024, manual\nanalysis and mitigation at scale are virtually unfeasible/unpractical. While\nmost research focuses on proactive malware detection, a significant gap remains\nin leveraging reactive analysis of stealer logs and their associated artifacts.\nSpecifically, infection artifacts such as screenshots, image captured at the\npoint of compromise, are largely overlooked by the current literature. This\npaper introduces a novel approach leveraging Large Language Models (LLMs), more\nspecifically gpt-4o-mini, to analyze infection screenshots to extract potential\nIndicators of Compromise (IoCs), map infection vectors, and track campaigns.\nFocusing on the Aurora infostealer, we demonstrate how LLMs can process\nscreenshots to identify infection vectors, such as malicious URLs, installer\nfiles, and exploited software themes. Our method extracted 337 actionable URLs\nand 246 relevant files from 1000 screenshots, revealing key malware\ndistribution methods and social engineering tactics. By correlating extracted\nfilenames, URLs, and infection themes, we identified three distinct malware\ncampaigns, demonstrating the potential of LLM-driven analysis for uncovering\ninfection workflows and enhancing threat intelligence. By shifting malware\nanalysis from traditional log-based detection methods to a reactive,\nartifact-driven approach that leverages infection screenshots, this research\npresents a scalable method for identifying infection vectors and enabling early\nintervention."}
{"id": "2507.23490", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.23490", "abs": "https://arxiv.org/abs/2507.23490", "authors": ["Zdeněk Hlávka", "Šárka Hudecová", "Simos G. Meintanis"], "title": "Optimal-Transport Based Multivariate Goodness-of-Fit Tests", "comment": null, "summary": "Characteristic-function based goodness-of-fit tests are suggested for\nmultivariate observations. The test statistics, which are straightforward to\ncompute, are defined as two-sample criteria measuring discrepancy between\nmultivariate ranks of the original observations and the corresponding ranks\nobtained from an artificial sample generated from the reference distribution\nunder test. Multivariate ranks are constructed using the theory of the optimal\nmeasure transport, thus rendering the tests of a simple null hypothesis\ndistribution-free, while bootstrap approximations are still necessary for\ntesting composite null hypotheses. Asymptotic theory is developed and a\nsimulation study, concentrating on comparisons with previously proposed tests\nof multivariate normality, demonstrates that the method performs well in finite\nsamples."}
{"id": "2507.23067", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23067", "abs": "https://arxiv.org/abs/2507.23067", "authors": ["Zhenyu Pan", "Yutong Zhang", "Jianshu Zhang", "Haoran Lu", "Haozheng Luo", "Yuwei Han", "Philip S. Yu", "Manling Li", "Han Liu"], "title": "FairReason: Balancing Reasoning and Social Bias in MLLMs", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) already achieve state-of-the-art\nresults across a wide range of tasks and modalities. To push their reasoning\nability further, recent studies explore advanced prompting schemes and\npost-training fine-tuning. Although these techniques improve logical accuracy,\nthey frequently leave the models' outputs burdened with pronounced social\nbiases. Clarifying how reasoning gains interact with bias mitigation-and\nwhether the two objectives inherently trade off-therefore remains an open and\npressing research problem. Our study begins by benchmarking three\nbias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation\n(KD), and rule-based reinforcement learning (RL)-under identical conditions,\nestablishing their baseline strengths and weaknesses. Building on these\nresults, we vary the proportion of debias-focused and reasoning-centric samples\nwithin each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps\nreveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement\nlearning cuts stereotype scores by 10% while retaining 88% of the model's\noriginal reasoning accuracy, offering concrete guidance for balancing fairness\nand capability in MLLMs."}
{"id": "2507.23338", "categories": ["math.NT", "11E12 (Primary) 11E20, 11R32, 11R80 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.23338", "abs": "https://arxiv.org/abs/2507.23338", "authors": ["Matěj Doležálek"], "title": "Extending bounds on minimal ranks of universal quadratic lattices to larger number fields", "comment": "9 pages", "summary": "There exist numerous results in the literature proving that within certain\nfamilies of totally real number fields, the minimal rank of a universal\nquadratic lattice over such a field can be arbitrarily large. Kala introduced a\ntechnique of extending such results to larger fields -- e.g. from quadratic\nfields to fields of arbitrary even degree -- under some conditions. We present\nimprovements to this technique by investigating the structure of subfields\nwithin composita of number fields, using basic Galois theory to translate this\ninto a group-theoretic problem. In particular, we show that if totally real\nnumber fields with minimal rank of a universal lattice $\\geq r$ exist in degree\n$d$, then they also exist in degree $kd$ for all $k\\geq3$."}
{"id": "2507.23390", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.23390", "abs": "https://arxiv.org/abs/2507.23390", "authors": ["Hongpei Li", "Hui Yuan", "Han Zhang", "Dongdong Ge", "Mengdi Wang", "Yinyu Ye"], "title": "FMIP: Multimodal Flow Matching for Mixed Integer Linear Programming", "comment": "A Generative Model based Method for Mixed Integer Linear Programming", "summary": "Mixed-Integer Linear Programming (MILP) is a cornerstone of mathematical\noptimization, enabling the modeling of complex decision-making problems\ninvolving both integer and continuous variables. Despite its versatility, most\nMILP problems are NP-complete, making them challenging to solve in practice.\nExisting graph neural network (GNN)-based heuristics aim to reduce problem\nscale by predicting only the solutions on integer variables for a given\ninstance, struggling to capture the intricate interplay between continuous and\ninteger variables and lack sufficient representational power. To address these\nlimitations, we propose FMIP, a novel multimodal flow-matching framework that\nmodels the joint distribution over integer and continuous variables in the\nmixed solution space of MILP. To enable more accurate and scalable heuristics,\nFMIP integrates a guidance mechanism to guide solution sampling under both\nobjective function optimization and constraint satisfaction. We evaluate FMIP\non seven standard MILP benchmarks. Our experiments show that FMIP improves\nsolution quality by 50.04% on average over existing GNN-based predictive\nbaselines. These results highlight FMIP's potential as a powerful new approach\nfor developing learning based MILP solution strategy."}
{"id": "2507.23222", "categories": ["math.CO", "05E05, 05E10, 14N15"], "pdf": "https://arxiv.org/pdf/2507.23222", "abs": "https://arxiv.org/abs/2507.23222", "authors": ["Yaozhou Fan", "Xing Gao"], "title": "Weighted $K$-$k$-Schur functions and their application to the $K$-$k$-Schur alternating conjecture", "comment": "23 pages", "summary": "We introduce the new concept of weighted $K$-$k$-Schur functions -- a novel\nfamily within the broader class of Katalan functions -- that unifies and\nextends both $K$-$k$-Schur functions and closed $k$-Schur Katalan functions.\nThis new notion exhibits a fundamental alternating property under certain\nconditions on the indexed $k$-bounded partitions. As a central application, we\nresolve the $K$-$k$-Schur alternating conjecture -- posed by Blasiak, Morse,\nand Seelinger in 2022 -- for a wide class of $k$-bounded partitions, including\nall strictly decreasing $k$-bounded partitions. Our results shed new light on\nthe combinatorial structure of $K$-theoretic symmetric functions."}
{"id": "2507.23641", "categories": ["cs.CR", "11T71, 94A60"], "pdf": "https://arxiv.org/pdf/2507.23641", "abs": "https://arxiv.org/abs/2507.23641", "authors": ["Michael Schaller"], "title": "Polynomial Lattices for the BIKE Cryptosystem", "comment": null, "summary": "In this paper we introduce a rank $2$ lattice over a polynomial ring arising\nfrom the public key of the BIKE cryptosystem \\cite{aragon2022bike}. The secret\nkey is a sparse vector in this lattice. We study properties of this lattice and\ngeneralize the recovery of weak keys from \\cite{BardetDLO16}. In particular, we\nshow that they implicitly solved a shortest vector problem in the lattice we\nconstructed. Rather than finding only a shortest vector, we obtain a reduced\nbasis of the lattice which makes it possible to check for more weak keys."}
{"id": "2507.23646", "categories": ["stat.TH", "cs.IT", "math.DG", "math.IT", "math.PR", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2507.23646", "abs": "https://arxiv.org/abs/2507.23646", "authors": ["Jaehyung Choi"], "title": "Information geometry of Lévy processes and financial models", "comment": "21 pages", "summary": "We explore the information geometry of L\\'evy processes. As a starting point,\nwe derive the $\\alpha$-divergence between two L\\'evy processes. Subsequently,\nthe Fisher information matrix and the $\\alpha$-connection associated with the\ngeometry of L\\'evy processes are computed from the $\\alpha$-divergence. In\naddition, we discuss statistical applications of this information geometry. As\nillustrative examples, we investigate the differential-geometric structures of\nvarious L\\'evy processes relevant to financial modeling, including tempered\nstable processes, the CGMY model, and variance gamma processes."}
{"id": "2507.23091", "categories": ["cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.23091", "abs": "https://arxiv.org/abs/2507.23091", "authors": ["David Noever", "Forrest McKee"], "title": "Moravec's Paradox: Towards an Auditory Turing Test", "comment": null, "summary": "This research work demonstrates that current AI systems fail catastrophically\non auditory tasks that humans perform effortlessly. Drawing inspiration from\nMoravec's paradox (i.e., tasks simple for humans often prove difficult for\nmachines, and vice versa), we introduce an auditory Turing test comprising 917\nchallenges across seven categories: overlapping speech, speech in noise,\ntemporal distortion, spatial audio, coffee-shop noise, phone distortion, and\nperceptual illusions. Our evaluation of state-of-the-art audio models including\nGPT-4's audio capabilities and OpenAI's Whisper reveals a striking failure rate\nexceeding 93%, with even the best-performing model achieving only 6.9% accuracy\non tasks that humans solved at 7.5 times higher success (52%). These results\nexpose focusing failures in how AI systems process complex auditory scenes,\nparticularly in selective attention, noise robustness, and contextual\nadaptation. Our benchmark not only quantifies the human-machine auditory gap\nbut also provides insights into why these failures occur, suggesting that\ncurrent architectures lack fundamental mechanisms for human-like auditory scene\nanalysis. The traditional design of audio CAPTCHAs highlights common filters\nthat humans evolved but machines fail to select in multimodal language models.\nThis work establishes a diagnostic framework for measuring progress toward\nhuman-level machine listening and highlights the need for novel approaches\nintegrating selective attention, physics-based audio understanding, and\ncontext-aware perception into multimodal AI systems."}
{"id": "2507.23392", "categories": ["q-fin.MF", "math.PR", "60L70, 60H10, 91G20, 91G60, 60G22"], "pdf": "https://arxiv.org/pdf/2507.23392", "abs": "https://arxiv.org/abs/2507.23392", "authors": ["Elisa Alòs", "Òscar Burés", "Rafael de Santiago", "Josep Vives"], "title": "Volatility Modeling with Rough Paths: A Signature-Based Alternative to Classical Expansions", "comment": null, "summary": "We compare two methodologies for calibrating implied volatility surfaces: a\nsecond-order asymptotic expansion method derived via Malliavin calculus, and a\ndata-driven approach based on path signatures from rough path theory. The\nformer, developed in Al\\`os et al. (2015), yields efficient and accurate\ncalibration formulas under the assumption that the asset price follows a\nHeston-type stochastic volatility model. The latter models volatility as a\nlinear functional of the signature of a primary stochastic process, enabling a\nflexible approximation without requiring a specific parametric form.\n  Our numerical experiments show that the signature-based method achieves\ncalibration accuracy comparable to the asymptotic approach when the true\ndynamics are Heston. We then test the model in a more general setting where the\nasset follows a rough Bergomi volatility process-a regime beyond the scope of\nthe asymptotic expansion-and show that the signature approach continues to\ndeliver accurate results. These findings highlight the model-independence,\nrobustness and adaptability of signature-based calibration methods in settings\nwhere volatility exhibits rough or non-Markovian features."}
{"id": "2507.23477", "categories": ["math.NT", "05A15, 11M06, 11A07"], "pdf": "https://arxiv.org/pdf/2507.23477", "abs": "https://arxiv.org/abs/2507.23477", "authors": ["Shenghao Hua"], "title": "Discrete restrictions from Laurent monomial systems for multiple Dirichlet series", "comment": "8 pages. Comments welcome", "summary": "We introduce a special class of multiple Dirichlet series whose terms are\nsupported on a variety and which admit an Euler product structure. We show that\nthese series arise naturally from twisted moments of automorphic \\( L\n\\)-functions associated with Dirichlet twists. We proposed several conjectures\non the analytic properties of these series."}
{"id": "2507.23395", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.23395", "abs": "https://arxiv.org/abs/2507.23395", "authors": ["Abhishek Chakraborty", "Angelia Nedić"], "title": "Popov Mirror-Prox Method for Variational Inequalities", "comment": null, "summary": "This paper establishes the convergence properties of the Popov mirror-prox\nalgorithm for solving stochastic and deterministic variational inequalities\n(VIs) under a polynomial growth condition on the mapping variation. Unlike\nexisting methods that require prior knowledge of problem-specific parameters,\nwe propose step-size schemes that are entirely parameter-free in both constant\nand diminishing forms. For stochastic and deterministic monotone VIs, we\nestablish optimal convergence rates in terms of the dual gap function over a\nbounded constraint set. Additionally, for deterministic VIs with H\\\"older\ncontinuous mapping, we prove convergence in terms of the residual function\nwithout requiring a bounded set or a monotone mapping, provided a Minty\nsolution exists. This allows our method to address certain classes of\nnon-monotone VIs. However, knowledge of the H\\\"older exponent is necessary to\nachieve the best convergence rates in this case. By extending mirror-prox\ntechniques to mappings with arbitrary polynomial growth, our work bridges an\nexisting gap in the literature. We validate our theoretical findings with\nempirical results on matrix games, piecewise quadratic functions, and image\nclassification tasks using ResNet-18."}
{"id": "2507.23231", "categories": ["math.CO", "05C75, 05C50, 05C69, 68Q17, 68R10"], "pdf": "https://arxiv.org/pdf/2507.23231", "abs": "https://arxiv.org/abs/2507.23231", "authors": ["Hartosh Singh Bal"], "title": "Perfecting the Line Graph", "comment": null, "summary": "This paper introduces two canonical constructions that transform arbitrary\nfinite graphs into perfect graphs: the symmetric lift $\\mathrm{HL}'_2(G)$,\nwhich is purely structural and label-invariant, and the ordered lift\n$\\mathrm{HL}_2(G)$, which depends explicitly on vertex labeling and encodes\ndirectional information. Both lifts arise as line graphs of bipartite double\ncovers and are box-perfect.\n  The symmetric lift $\\mathrm{HL}'_2(G)$ forms a canonical 2-cover of the line\ngraph $L(G)$. This involution decomposes $\\mathrm{HL}'_2(G)$ into symmetric and\nantisymmetric components: the symmetric part recovers $L(G)$, while the\nantisymmetric part yields a signed graph $L^-(G)$, the antisymmetric line\ngraph, with +1/-1 edges encoding consistent vs. crossed overlaps. Thus, all\nadjacency and Laplacian eigenvalues of $L(G)$, with multiplicities, appear\nwithin those of $\\mathrm{HL}'_2(G)$, despite $L(G)$ typically not being a\nsubgraph.\n  For regular graphs such as Paley graphs, this yields infinite families of\nsparse, highly structured regular and box-perfect expanders that also retain\nlarge cliques. The lift retains much of the spectral expansion of the base\nwhile improving the combinatorial expansion. Much the same behavior is observed\nwith random regular base graphs, allowing for the possibility of the study of\nbox-perfect random regular graphs.\n  Finally, we generalize these constructions to parameterized lifts\n$\\mathrm{HL}_{r,d}(G)$ and $\\mathrm{HL}_{r,d}'(G)$ defined on ordered\n$r$-tuples connected by Hamming distance constraints, which structurally encode\nthe base graph and remain box-perfect."}
{"id": "2507.23163", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.23163", "abs": "https://arxiv.org/abs/2507.23163", "authors": ["Deniz Gorur", "Antonio Rago", "Francesca Toni"], "title": "Argumentatively Coherent Judgmental Forecasting", "comment": "17 pages, 18 figures, ECAI 2025", "summary": "Judgmental forecasting employs human opinions to make predictions about\nfuture events, rather than exclusively historical data as in quantitative\nforecasting. When these opinions form an argumentative structure around\nforecasts, it is useful to study the properties of the forecasts from an\nargumentative perspective. In this paper, we advocate and formally define a\nproperty of argumentative coherence, which, in essence, requires that a\nforecaster's reasoning is coherent with their forecast. We then conduct three\nevaluations with our notion of coherence. First, we assess the impact of\nenforcing coherence on human forecasters as well as on Large Language Model\n(LLM)-based forecasters, given that they have recently shown to be competitive\nwith human forecasters. In both cases, we show that filtering out incoherent\npredictions improves forecasting accuracy consistently, supporting the\npractical value of coherence in both human and LLM-based forecasting. Then, via\ncrowd-sourced user experiments, we show that, despite its apparent\nintuitiveness and usefulness, users do not generally align with this coherence\nproperty. This points to the need to integrate, within argumentation-based\njudgmental forecasting, mechanisms to filter out incoherent opinions before\nobtaining group forecasting predictions."}
{"id": "2507.23619", "categories": ["math.NT", "11B37"], "pdf": "https://arxiv.org/pdf/2507.23619", "abs": "https://arxiv.org/abs/2507.23619", "authors": ["Ignas Gasparavičius", "Andrius Grigutis", "Juozas Petkelis"], "title": "Picturesque convolution-like recurrences and partial sums' generation", "comment": null, "summary": "Let ${\\pmb b}=\\{b_0,\\,b_1,\\,\\ldots\\}$ be the known sequence of numbers such\nthat $b_0\\neq0$. In this work, we develop methods to find another sequence\n${\\pmb a}=\\{a_0,\\,a_1,\\,\\ldots\\}$ that is related to ${\\pmb b}$ as follows:\n$a_n=a_0\\,b_{n+m}+a_1\\,b_{n+m-1}+\\ldots+a_{n+m}\\,b_0$,\n$n\\in\\mathbb{N}\\cup\\{0\\}$, $m\\in\\mathbb{N}$. We show the connection of\n$\\lim_{n\\to\\infty}a_n$ with $a_0,\\,a_1,\\,\\ldots,\\,a_{m-1}$ and provide varied\nexamples of finding the sequence ${\\pmb a}$ when ${\\pmb b}$ is given. We\ndemonstrate that the sequences ${\\pmb a}$ may exhibit pretty patterns in the\nplane or space. Also, we show that the properly chosen sequence ${\\pmb b}$ may\ndefine ${\\pmb a}$ as some famous sequences, such as the partial sums of the\nRiemann zeta function, etc."}
{"id": "2507.23423", "categories": ["math.OC", "52B40, 90C27, 90C29"], "pdf": "https://arxiv.org/pdf/2507.23423", "abs": "https://arxiv.org/abs/2507.23423", "authors": ["Ellen H. Fukuda", "Satoru Iwata", "Itsuki Nakagawa"], "title": "Biobjective optimization with M-convex functions", "comment": null, "summary": "In this paper, we deal with two ingredients that, as far as we know, have not\nbeen combined until now: multiobjective optimization and discrete convex\nanalysis. First, we show that the entire Pareto optimal value set can be\nobtained in polynomial time for biobjective optimization problems with discrete\nconvex functions, in particular, involving an M$^\\natural$-convex function and\na linear function with binary coefficients. We also observe that a more\nefficient algorithm can be obtained in the special case where the\nM$^\\natural$-convex function is M-convex. Additionally, we present a\npolynomial-time method for biobjective optimization problems that combine\nM$^\\natural$-convex function minimization with lexicographic optimization."}
{"id": "2507.23375", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.23375", "abs": "https://arxiv.org/abs/2507.23375", "authors": ["Mingze Li", "Jie Ma", "Mingyuan Rong"], "title": "Recent advances in arrow relations and traces of sets", "comment": "A survey contributed to the volume for the conference Summit280", "summary": "The arrow relation, a central concept in extremal set theory, captures\nquantitative relationships between families of sets and their traces. Formally,\nthe arrow relation $(n, m) \\rightarrow (a, b)$ signifies that for any family\n$\\mathcal{F} \\subseteq 2^{[n]}$ with $|\\mathcal{F}| \\geqslant m$, there exists\nan $a$-element subset $T \\subseteq [n]$ such that the trace $\\mathcal{F}_{|T} =\n\\{ F \\cap T : F \\in \\mathcal{F} \\}$ contains at least $b$ distinct sets. This\nsurvey highlights recent progress on a variety of problems and results\nconnected to arrow relations. We explore diverse topics, broadly categorized by\ndifferent extremal perspectives on these relations, offering a cohesive\noverview of the field."}
{"id": "2507.23191", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23191", "abs": "https://arxiv.org/abs/2507.23191", "authors": ["Meghyn Bienvenu", "Diego Figueira", "Pierre Lafourcade"], "title": "Tractable Responsibility Measures for Ontology-Mediated Query Answering", "comment": "Long version of a paper to appear at KR 2025, which contains further\n  proof details in the appendix", "summary": "Recent work on quantitative approaches to explaining query answers employs\nresponsibility measures to assign scores to facts in order to quantify their\nrespective contributions to obtaining a given answer. In this paper, we study\nthe complexity of computing such responsibility scores in the setting of\nontology-mediated query answering, focusing on a very recently introduced\nfamily of Shapley-value-based responsibility measures defined in terms of\nweighted sums of minimal supports (WSMS). By exploiting results from the\ndatabase setting, we can show that such measures enjoy polynomial data\ncomplexity for classes of ontology-mediated queries that are\nfirst-order-rewritable, whereas the problem becomes \"shP\"-hard when the\nontology language can encode reachability queries (via axioms like $\\exists R.\nA \\sqsubseteq A$). To better understand the tractability frontier, we next\nexplore the combined complexity of WSMS computation. We prove that\nintractability applies already to atomic queries if the ontology language\nsupports conjunction, as well as to unions of `well-behaved' conjunctive\nqueries, even in the absence of an ontology. By contrast, our study yields\npositive results for common DL-Lite dialects: by means of careful analysis, we\nidentify classes of structurally restricted conjunctive queries (which\nintuitively disallow undesirable interactions between query atoms) that admit\ntractable WSMS computation."}
{"id": "2507.23656", "categories": ["math.NT", "11F12, 11F30, 11F66"], "pdf": "https://arxiv.org/pdf/2507.23656", "abs": "https://arxiv.org/abs/2507.23656", "authors": ["Shenghao Hua"], "title": "An evident corollary arising from Newton--Thorne", "comment": "5 pages. Comments welcome", "summary": "We present a special class of examples of automorphic lifts of multiple\ntensor products of automorphic representations in the sense of matching\n$L$-functions, motivated by combinatorial identities for Schur polynomials and\na celebrated result of Newton and Thorne."}
{"id": "2507.23558", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.23558", "abs": "https://arxiv.org/abs/2507.23558", "authors": ["Nick Tsipinakis", "Panos Parpas"], "title": "Convergence rates of Newton's method for strongly self-concordant minimization", "comment": null, "summary": "Newton's method has been thoroughly studied for the class of self-concordant\nfunctions. However, a local analysis specific to strongly self-concordant\nfunctions (a subclass of the former) is missing from the literature. The local\nquadratic rate of strongly self-concordant functions follows, of course, from\nthe known results for self-concordant functions. However, it is not known\nwhether strongly self-concordant functions enjoy better theoretical properties.\nIn this paper, we study the local convergence of Newton's method for this\nsubclass. We show that its quadratic convergence rate differs from that of\ngeneral self-concordant functions. In particular, it is provably faster for a\nwide range of objective functions and benefits from a larger region of local\nconvergence. Thus, the results of this paper close the gap in the theoretical\nunderstanding of Newton's method applied to strongly self-concordant functions."}
{"id": "2507.23376", "categories": ["math.CO", "05C20", "G.2.1"], "pdf": "https://arxiv.org/pdf/2507.23376", "abs": "https://arxiv.org/abs/2507.23376", "authors": ["Alice Miller", "Ivaylo Valkov", "R. Julian R. Abel"], "title": "Combinatorial solutions to the Social Golfer Problem and Social Golfer Problem with Adjacent Group Sizes", "comment": "53 pages (includes 24 pages of appendices. Appendix B is supporting\n  information for journal submission. Submitted to Journal of Combinatorial\n  Designs", "summary": "Resolvable combinatorial designs including Resolvable Balanced Incomplete\nBlock Designs, Resolvable Group Divisible Designs, Uniformly Resolvable Designs\nand Mutually Orthogonal Latin Squares and Rectangles are used to construct\noptimal solutions to the Social Golfer problem (SGP) and the Social Golfer\nproblem with adjacent group sizes (SGA). An algorithm is presented to find an\noptimal solution in general, and a complete set of solutions is provided for up\nto 150 players."}
{"id": "2507.23197", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23197", "abs": "https://arxiv.org/abs/2507.23197", "authors": ["Yuke Liao", "Blaise Genest", "Kuldeep Meel", "Shaan Aryaman"], "title": "Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification", "comment": null, "summary": "To handle complex instances, we revisit a divide-and-conquer approach to\nbreak down the complexity: instead of few complex BaB calls, we rely on many\nsmall {\\em partial} MILP calls. The crucial step is to select very few but very\nimportant ReLUs to treat using (costly) binary variables. The previous attempts\nwere suboptimal in that respect. To select these important ReLU variables, we\npropose a novel {\\em solution-aware} ReLU scoring ({\\sf SAS}), as well as adapt\nthe BaB-SR and BaB-FSB branching functions as {\\em global} ReLU scoring ({\\sf\nGS}) functions. We compare them theoretically as well as experimentally, and\n{\\sf SAS} is more efficient at selecting a set of variables to open using\nbinary variables. Compared with previous attempts, SAS reduces the number of\nbinary variables by around 6 times, while maintaining the same level of\naccuracy. Implemented in {\\em Hybrid MILP}, calling first $\\alpha,\\beta$-CROWN\nwith a short time-out to solve easier instances, and then partial MILP,\nproduces a very accurate yet efficient verifier, reducing by up to $40\\%$ the\nnumber of undecided instances to low levels ($8-15\\%$), while keeping a\nreasonable runtime ($46s-417s$ on average per instance), even for fairly large\nCNNs with 2 million parameters."}
{"id": "2507.23706", "categories": ["math.NT", "math.DS"], "pdf": "https://arxiv.org/pdf/2507.23706", "abs": "https://arxiv.org/abs/2507.23706", "authors": ["Elias Dubno"], "title": "A Central Limit Theorem for the Winding Number of Low-Lying Closed Geodesics", "comment": "23 pages", "summary": "We show that the winding of low-lying closed geodesics on the modular surface\nhas a Gaussian limiting distribution when normalized by any natural notion of\nlength."}
{"id": "2507.23711", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.23711", "abs": "https://arxiv.org/abs/2507.23711", "authors": ["Federico D'Onofrio", "Yuri Faenza", "Laura Palagi"], "title": "Combinatorial Approaches for Embedded Feature Selection in Nonlinear SVMs", "comment": null, "summary": "Embedded Feature Selection (FS) is a classical approach for interpretable\nmachine learning, aiming to identify the most relevant features of a dataset\nwhile simultaneously training the model. We consider an approach based on a\nhard cardinality constraint for nonlinear SVMs. To the best of our knowledge,\nhard-constraint approaches have been proposed only for the primal formulation\nof linear SVMs. In contrast, we embed a hard cardinality constraint directly\ninto the dual of a nonlinear SVM, guaranteeing strict control over the number\nof selected features while still leveraging kernelization. We formulate the\nproblem as a Mixed-Integer Nonlinear Programming (MINLP) model. As a first\ncontribution, we propose a local search metaheuristic applicable to general\nnonlinear kernels. Our second and main contribution is a decomposition\nframework that alternates optimization between two subproblems: one involving\nonly continuous variables and the other involving only binary variables. For\npolynomial kernels, we show that the binary subproblem reduces to a submodular\nfunction maximization under a cardinality constraint, enabling the use of\nscalable submodular maximization algorithms within the alternating optimization\nprocess. Numerical experiments demonstrate that our algorithms significantly\noutperform standard methods for solving the proposed MINLPs, providing more\neffective solutions to the addressed feature selection problem."}
{"id": "2507.23409", "categories": ["math.CO", "51E20, 05B25"], "pdf": "https://arxiv.org/pdf/2507.23409", "abs": "https://arxiv.org/abs/2507.23409", "authors": ["Stefano Lia", "Giovanni Longobardi", "Corrado Zanella"], "title": "Towards the classification of maximum scattered linear sets of $\\mathrm{PG}(1,q^5)$", "comment": null, "summary": "Every maximum scattered linear set in $\\mathrm{PG}(1,q^5)$ is the projection\nof an $\\mathbb{F}_q$-subgeometry $\\Sigma$ of $\\mathrm{PG}(4,q^5)$ from a plane\n$\\Gamma$ external to the secant variety to $\\Sigma$. The pair $(\\Gamma,\\Sigma)$\nwill be called a projecting configuration for the linear set. The projecting\nconfigurations for the only known maximum scattered linear sets in\n$\\mathrm{PG}(1,q^5)$, namely those of pseudoregulus and LP type, have been\ncharacterized in the literature by B. Csajb\\'{o}k, C. Zanella in 2016 and by C.\nZanella, F. Zullo in 2020. Let $(\\Gamma,\\Sigma)$ be a projecting configuration\nfor a maximum scattered linear set in $\\mathrm{PG}(1,q^5)$, let $\\sigma$ be a\ngenerator of $\\mathbb{G}=\\mathrm{P}\\Gamma \\mathrm{L}(5,q^5)_\\Sigma$, and\n$A=\\Gamma\\cap\\Gamma^{\\sigma^4}$, $B=\\Gamma\\cap\\Gamma^{\\sigma^3}$. If $A$ and\n$B$ are not both points, then the projected linear set is of pseudoregulus\ntype. Then, suppose that they are points. The rank of a point $X$ is the\nvectorial dimension of the span of the orbit of $X$ under the action of\n$\\mathbb{G}$. In this paper, by investigating the geometric properties of\nprojecting configurations, it is proved that if at least one of the points $A$\nand $B$ has rank 5, the associated maximum scattered linear set must be of LP\ntype. Then, if a maximum scattered linear set of a new type exists, it must be\nsuch that $\\mathrm{rk} A=\\mathrm{rk} B=4$. In this paper we derive two possible\npolynomial forms that such a linear set must have. An exhaustive analysis by\ncomputer shows that for $q\\leq 25$, no new maximum scattered linear set exists."}
{"id": "2507.23276", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23276", "abs": "https://arxiv.org/abs/2507.23276", "authors": ["Qiujie Xie", "Yixuan Weng", "Minjun Zhu", "Fuchen Shen", "Shulin Huang", "Zhen Lin", "Jiahui Zhou", "Zilan Mao", "Zijie Yang", "Linyi Yang", "Jian Wu", "Yue Zhang"], "title": "How Far Are AI Scientists from Changing the World?", "comment": null, "summary": "The emergence of large language models (LLMs) is propelling automated\nscientific discovery to the next level, with LLM-based Artificial Intelligence\n(AI) Scientist systems now taking the lead in scientific research. Several\ninfluential works have already appeared in the field of AI Scientist systems,\nwith AI-generated research papers having been accepted at the ICLR 2025\nworkshop, suggesting that a human-level AI Scientist capable of uncovering\nphenomena previously unknown to humans, may soon become a reality. In this\nsurvey, we focus on the central question: How far are AI scientists from\nchanging the world and reshaping the scientific research paradigm? To answer\nthis question, we provide a prospect-driven review that comprehensively\nanalyzes the current achievements of AI Scientist systems, identifying key\nbottlenecks and the critical components required for the emergence of a\nscientific agent capable of producing ground-breaking discoveries that solve\ngrand challenges. We hope this survey will contribute to a clearer\nunderstanding of limitations of current AI Scientist systems, showing where we\nare, what is missing, and what the ultimate goals for scientific AI should be."}
{"id": "2507.23759", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.23759", "abs": "https://arxiv.org/abs/2507.23759", "authors": ["Bora Yalkinoglu"], "title": "Bost-Connes systems and periodic Witt vectors", "comment": "Comments are welcome!", "summary": "In this note, using Borger's theory of periodic Witt vectors, we construct\nintegral refinements of the arithmetic subalgebras associated with Bost-Connes\nsystems for general number fields."}
{"id": "2507.23725", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.23725", "abs": "https://arxiv.org/abs/2507.23725", "authors": ["Ilya Kuruzov", "Xiaokai Chen", "Gesualdo Scutari", "Alexander Gasnikov"], "title": "Adaptive Stepsize Selection in Decentralized Convex Optimization", "comment": null, "summary": "We study decentralized optimization where multiple agents minimize the\naverage of their (strongly) convex, smooth losses over a communication graph.\nConvergence of the existing decentralized methods generally hinges on an\napriori, proper selection of the stepsize. Choosing this value is notoriously\ndelicate: (i) it demands global knowledge from all the agents of the graph's\nconnectivity and every local smoothness/strong-convexity constants--information\nthey rarely have; (ii) even with perfect information, the worst-case tuning\nforces an overly small stepsize, slowing convergence in practice; and (iii)\nlarge-scale trial-and-error tuning is prohibitive. This work introduces a\ndecentralized algorithm that is fully adaptive in the choice of the agents'\nstepsizes, without any global information and using only neighbor-to-neighbor\ncommunications--agents need not even know whether the problem is strongly\nconvex. The algorithm retains strong guarantees: it converges at \\emph{linear}\nrate when the losses are strongly convex and at \\emph{sublinear} rate\notherwise, matching the best-known rates of (nonadaptive) parameter-dependent\nmethods."}
{"id": "2507.23420", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.23420", "abs": "https://arxiv.org/abs/2507.23420", "authors": ["Qian Yu", "Yaoping Hou"], "title": "The net-regular strongly regular signed graphs with degree 5", "comment": null, "summary": "In this paper, we determine all connected net-regular strongly regular signed\ngraphs with degree 5. There are five and two strongly regular signed graphs\nwith net-degree 3 and 1, respectively."}
{"id": "2507.23330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23330", "abs": "https://arxiv.org/abs/2507.23330", "authors": ["Tosin Adewumi", "Lama Alkhaled", "Florent Imbert", "Hui Han", "Nudrat Habib", "Karl Löwenmark"], "title": "AI Must not be Fully Autonomous", "comment": "11 pages, 1 figure", "summary": "Autonomous Artificial Intelligence (AI) has many benefits. It also has many\nrisks. In this work, we identify the 3 levels of autonomous AI. We are of the\nposition that AI must not be fully autonomous because of the many risks,\nespecially as artificial superintelligence (ASI) is speculated to be just\ndecades away. Fully autonomous AI, which can develop its own objectives, is at\nlevel 3 and without responsible human oversight. However, responsible human\noversight is crucial for mitigating the risks. To ague for our position, we\ndiscuss theories of autonomy, AI and agents. Then, we offer 12 distinct\narguments and 6 counterarguments with rebuttals to the counterarguments. We\nalso present 15 pieces of recent evidence of AI misaligned values and other\nrisks in the appendix."}
{"id": "2507.23627", "categories": ["math.CO", "math.NT"], "pdf": "https://arxiv.org/pdf/2507.23627", "abs": "https://arxiv.org/abs/2507.23627", "authors": ["Eric James Faust", "Michael Tait"], "title": "Improved bounds on the postage stamp problem for large numbers of stamps", "comment": null, "summary": "Let $F_h(n)$ denote the minimum cardinality of an additive {\\em $h$-fold\nbasis} of $\\{1,2,\\cdots,n\\}$: a set $S$ such that any integer in $\\{1,2,\\cdots,\nn\\}$ can be written as a sum of at most $h$ elements from $S$. While the\ntrivial bounds $h!n \\; \\lesssim \\; F_h(n)^h \\; \\lesssim \\; h^h n$ are\nwell-known, comparatively little has been established for $h>2$. In this paper,\nwe make significant improvements to both of the best-known bounds on $F_h(n)$\nfor sufficiently large $h$. For the lower bound, we use a probabilistic\napproach along with the Berry-Esseen Theorem to improve upon the best-known\nasymptotic result due to Yu. We also establish the first nontrivial asymptotic\nupper bound on $F_h(n)$ by leveraging a construction for additive bases of\nfinite cyclic groups due to Jia and Shen. In particular, we show that given any\n$\\epsilon>0$, for sufficiently large $h$, we have \\[\n\\left(\\frac{1}{2}-\\epsilon\\right)h!\\sqrt{2\\pi e} n\\; \\leq \\; F_h(n)^h \\; \\leq\n\\; \\left(\\left(\\frac{\\sqrt{3}}{2}+\\epsilon\\right)h\\right)^h n. \\]"}
{"id": "2507.23460", "categories": ["math.CO", "cond-mat.stat-mech", "math-ph", "math.MP", "math.QA"], "pdf": "https://arxiv.org/pdf/2507.23460", "abs": "https://arxiv.org/abs/2507.23460", "authors": ["Keiichi Shigechi"], "title": "Fuss--Catalan algebras on generalized Dyck paths via non-crossing partitions", "comment": "51 pages", "summary": "We study the Fuss--Catalan algebras, which are generalizations of the\nTemperley--Lieb algebra and act on generalized Dyck paths, through non-crossing\npartitions. First, the Temperley--Lieb algebra is defined on non-crossing\npartitions, and a bijection between a Dyck path and a non-crossing partition is\nshown to be compatible with the Temperley--Lieb algebra on Dyck paths, or\nequivalently chord diagrams. We show that the Kreweras endomorphism on\nnon-crossing partitions is equivalent to the rotation of chord diagrams under\nthe bijection. Secondly, by considering an increasing $r$-chain in the graded\nlattice of non-crossing partitions, we define the Fuss--Catalan algebras on\nincreasing $r$-chains. Through a bijection between an increasing $r$-chain and\na generalized Dyck path, one naturally obtains the Fuss--Catalan algebra on\ngeneralized Dyck paths. As generalizations of the Fuss--Catalan algebra, we\nintroduce the one- and two-boundary Fuss--Catalan algebras. Increasing\n$r$-chains of symmetric non-crossing partitions give symmetric generalized Dyck\npaths by the bijection, and the boundary Fuss--Catalan algebras naturally act\non them. We show that these representations are compatible with the\ndiagrammatic representations of the algebras by use of generalized chord\ndiagrams. Thirdly, we discuss the integrability of the Fuss--Catalan algebras.\nFor the Fuss--Catalan algebras with boundaries, we obtain a new solution of the\nreflection equation in the case of $r=2$."}
{"id": "2507.23336", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.23336", "abs": "https://arxiv.org/abs/2507.23336", "authors": ["Ram Mohan Rao Kadiyala", "Siddhant Gupta", "Jebish Purbey", "Giulio Martini", "Suman Debnath", "Hamza Farooq"], "title": "DSBC : Data Science task Benchmarking with Context engineering", "comment": "32 pages", "summary": "Recent advances in large language models (LLMs) have significantly impacted\ndata science workflows, giving rise to specialized data science agents designed\nto automate analytical tasks. Despite rapid adoption, systematic benchmarks\nevaluating the efficacy and limitations of these agents remain scarce. In this\npaper, we introduce a comprehensive benchmark specifically crafted to reflect\nreal-world user interactions with data science agents by observing usage of our\ncommercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,\nGemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with\ncontext engineering, multi-step with context engineering, and with SmolAgent.\nOur benchmark assesses performance across a diverse set of eight data science\ntask categories, additionally exploring the sensitivity of models to common\nprompting issues, such as data leakage and slightly ambiguous instructions. We\nfurther investigate the influence of temperature parameters on overall and\ntask-specific outcomes for each model and approach. Our findings reveal\ndistinct performance disparities among the evaluated models and methodologies,\nhighlighting critical factors that affect practical deployment. The benchmark\ndataset and evaluation framework introduced herein aim to provide a foundation\nfor future research of more robust and effective data science agents."}
{"id": "2507.23517", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.23517", "abs": "https://arxiv.org/abs/2507.23517", "authors": ["Jifu Lin", "Lihua You"], "title": "Oriented diameter of graphs with diameter $4$ and given maximum edge girth", "comment": "29 pages, 2 figures", "summary": "Let $G$ be a bridgeless graph. We introduce the maximum edge girth of $G$,\ndenoted by $g^*(G)=\\max\\{l_G(e)\\mid e\\in E(G)\\}$, where $l_G(e)$ is the edge\ngirth of $e$, defined as the length of the shortest cycle containing $e$. Let\n$F(d,A)$ be the smallest value for which every bridgeless graph $G$ with\ndiameter $d$ and $g^*(G)\\in A$ admits a strong orientation $\\overrightarrow{G}$\nsuch that the diameter of $\\overrightarrow{G}$ is at most $F(d,A)$. Let\n$f(d)=F(d,A)$, where $A=\\{a\\in \\mathbb{N}\\mid 2\\leq a\\leq 2d+1\\}$. Chv\\'atal\nand Thomassen (JCT-B, 1978) obtained general bounds for $f(d)$ and showed that\n$f(2)=6$. Kwok et al. (JCT-B, 2010) proved that $9\\leq f(3)\\leq 11$. Wang and\nChen (JCT-B, 2022) determined $f(3)=9$. In this paper, we give that $12\\leq\nF(4,A^*)\\leq 13$, where $A^*=\\{2,3,6,7,8,9\\}$."}
{"id": "2507.23377", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23377", "abs": "https://arxiv.org/abs/2507.23377", "authors": ["Zhuo Li", "Xianghuai Deng", "Chiwei Feng", "Hanmeng Li", "Shenjie Wang", "Haichao Zhang", "Teng Jia", "Conlin Chen", "Louis Linchun Wu", "Jia Wang"], "title": "LLM4Rail: An LLM-Augmented Railway Service Consulting Platform", "comment": null, "summary": "Large language models (LLMs) have significantly reshaped different walks of\nbusiness. To meet the increasing demands for individualized railway service, we\ndevelop LLM4Rail - a novel LLM-augmented railway service consulting platform.\nEmpowered by LLM, LLM4Rail can provide custom modules for ticketing, railway\nfood & drink recommendations, weather information, and chitchat. In LLM4Rail,\nwe propose the iterative \"Question-Thought-Action-Observation (QTAO)\" prompting\nframework. It meticulously integrates verbal reasoning with task-oriented\nactions, that is, reasoning to guide action selection, to effectively retrieve\nexternal observations relevant to railway operation and service to generate\naccurate responses. To provide personalized onboard dining services, we first\nconstruct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible\ntakeout dataset tailored for railway services. CRFD-25 covers a wide range of\nsignature dishes categorized by cities, cuisines, age groups, and spiciness\nlevels. We further introduce an LLM-based zero-shot conversational recommender\nfor railway catering. To address the unconstrained nature of open\nrecommendations, the feature similarity-based post-processing step is\nintroduced to ensure all the recommended items are aligned with CRFD-25\ndataset."}
{"id": "2507.23557", "categories": ["math.CO", "cs.SC", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.23557", "abs": "https://arxiv.org/abs/2507.23557", "authors": ["Alin Bostan", "Valentin Féray", "Paul Thévenin"], "title": "Tree-indexed sums of Catalan numbers", "comment": "62 pages, 8 figures", "summary": "We consider a family of infinite sums of products of Catalan numbers, indexed\nby trees. We show that these sums are polynomials in $1/\\pi$ with rational\ncoefficients; the proof is effective and provides an algorithm to explicitly\ncompute these sums. Along the way we introduce parametric liftings of our sums,\nand show that they are polynomials in the complete elliptic integrals of the\nfirst and second kind. Moreover, the degrees of these polynomials are at most\nhalf of the number of vertices of the tree. The computation of these\ntree-indexed sums is motivated by the study of large meandric systems, which\nare non-crossing configurations of loops in the plane."}
{"id": "2507.23429", "categories": ["cs.AI", "cs.DB", "cs.ET", "cs.HC", "cs.MA", "68T50, 68P20", "I.2.7; H.2.5; H.2.8; H.5.m"], "pdf": "https://arxiv.org/pdf/2507.23429", "abs": "https://arxiv.org/abs/2507.23429", "authors": ["Jorge Ruiz Gómez", "Lidia Andrés Susinos", "Jorge Alamo Olivé", "Sonia Rey Osorno", "Manuel Luis Gonzalez Hernández"], "title": "Chatting with your ERP: A Recipe", "comment": "11 pages, includes 3 tables summarizing schema and model performance.\n  Submitted on July 31, 2025. Targets integration of LLM agents with ERP\n  systems using open-weight models and Ollama deployment", "summary": "This paper presents the design, implementation, and evaluation behind a Large\nLanguage Model (LLM) agent that chats with an industrial production-grade ERP\nsystem. The agent is capable of interpreting natural language queries and\ntranslating them into executable SQL statements, leveraging open-weight LLMs. A\nnovel dual-agent architecture combining reasoning and critique stages was\nproposed to improve query generation reliability."}
{"id": "2507.23623", "categories": ["math.CO", "05D10"], "pdf": "https://arxiv.org/pdf/2507.23623", "abs": "https://arxiv.org/abs/2507.23623", "authors": ["Peter Allen", "Simona Boyadzhiyska", "Matías Pavez-Signé"], "title": "Ramsey numbers for 1-degenerate 3-graphs", "comment": "5 pages, 2 figures", "summary": "We construct a 3-uniform 1-degenerate hypergraph on $n$ vertices whose\n2-colour Ramsey number is $\\Omega\\big(n^{3/2}/\\log n\\big)$. This shows that all\nremaining open cases of the hypergraph Burr-Erd\\H{o}s conjecture are false. Our\ngraph is a variant of the celebrated hedgehog graph. We additionally show\nnear-sharp upper bounds, proving that all 3-uniform generalised hedgehogs have\n2-colour Ramsey number $O\\big(n^{3/2}\\big)$."}
{"id": "2507.23440", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23440", "abs": "https://arxiv.org/abs/2507.23440", "authors": ["Mingzhe Li", "Xin Lu", "Yanyan Zhao"], "title": "Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation", "comment": "Accepted by Findings of ACL 2025", "summary": "Large language models (LLMs) with instruction following capabilities have\ndemonstrated impressive problem-solving abilities. While synthesizing\ninstructional data from unsupervised text has become a common approach for\ntraining such models, conventional methods rely heavily on human effort for\ndata annotation. Although existing automated synthesis paradigms have\nalleviated this constraint, they still exhibit significant limitations in\nensuring adequate diversity and difficulty of synthesized instructions. To\naddress these challenges, we propose Self-Foveate, an innovative LLM-driven\nmethod for instruction synthesis. This approach introduces a\n\"Micro-Scatter-Macro\" multi-level foveation methodology that effectively guides\nthe LLM to deeply excavate fine-grained information embedded in unsupervised\ntext, thereby enhancing both the diversity and difficulty of synthesized\ninstructions. Comprehensive experiments across multiple unsupervised corpora\nand diverse model architectures validate the effectiveness and superiority of\nour proposed method. We publicly release our data and codes:\nhttps://github.com/Mubuky/Self-Foveate"}
{"id": "2507.23624", "categories": ["math.CO", "05B07, 05B05, 05C35, 05C65"], "pdf": "https://arxiv.org/pdf/2507.23624", "abs": "https://arxiv.org/abs/2507.23624", "authors": ["Michelle Delcourt", "Cicely", "Henderson", "Thomas Lesgourgues", "Luke Postle"], "title": "Erdős meets Nash-Williams", "comment": "41 pages", "summary": "In 1847, Kirkman proved that there exists a Steiner triple system on $n$\nvertices (equivalently a triangle decomposition of the edges of $K_n$) whenever\n$n$ satisfies the necessary divisibility conditions (namely $n\\equiv 1,3 \\mod\n6$). In 1970, Nash-Williams conjectured that every graph $G$ on $n$ vertices\nwith minimum degree at least $3n/4$ (for $n$ large enough and satisfying the\nnecessary divisibility conditions) has a triangle decomposition. In 1973,\nErd\\H{o}s conjectured that for each integer $g$, there exists a Steiner triple\nsystem on $n$ vertices with girth at least $g$ (provided that $n\\equiv 1,3 \\mod\n6$ is large enough compared to the fixed $g$). In 2021, Glock, K\\\"uhn, and\nOsthus conjectured the common generalization of these two conjectures, dubbing\nit the ``Erd\\H{o}s meets Nash-Williams' Conjecture''.\n  In this paper, we reduce the combined conjecture to the fractional relaxation\nof the Nash-Williams' Conjecture. Combined with the best known fractional bound\nof Delcourt and Postle, this proves the combined conjecture above when $G$ has\nminimum degree at least $0.82733n$. We note that our result generalizes the\nseminal work of Barber, K\\\"uhn, Lo, and Osthus on Nash-Williams' Conjecture and\nthe resolution of Erd\\H{o}s' Conjecture by Kwan, Sah, Sawhney, and Simkin. Both\nprevious proofs of those results used the method of iterative absorption. Our\nproof instead proceeds via the newly developed method of refined absorption\n(and hence provides new independent proofs of both results)."}
{"id": "2507.23488", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23488", "abs": "https://arxiv.org/abs/2507.23488", "authors": ["Kacper Kadziolka", "Saber Salehkaleybar"], "title": "Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery", "comment": null, "summary": "Causal inference remains a fundamental challenge for large language models.\nRecent advances in internal reasoning with large language models have sparked\ninterest in whether state-of-the-art reasoning models can robustly perform\ncausal discovery-a task where conventional models often suffer from severe\noverfitting and near-random performance under data perturbations. We study\ncausal discovery on the Corr2Cause benchmark using the emergent OpenAI's\no-series and DeepSeek-R model families and find that these reasoning-first\narchitectures achieve significantly greater native gains than prior approaches.\nTo capitalize on these strengths, we introduce a modular in-context pipeline\ninspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding\nnearly three-fold improvements over conventional baselines. We further probe\nthe pipeline's impact by analyzing reasoning chain length, complexity, and\nconducting qualitative and quantitative comparisons between conventional and\nreasoning models. Our findings suggest that while advanced reasoning models\nrepresent a substantial leap forward, carefully structured in-context\nframeworks are essential to maximize their capabilities and offer a\ngeneralizable blueprint for causal discovery across diverse domains."}
{"id": "2507.23627", "categories": ["math.CO", "math.NT"], "pdf": "https://arxiv.org/pdf/2507.23627", "abs": "https://arxiv.org/abs/2507.23627", "authors": ["Eric James Faust", "Michael Tait"], "title": "Improved bounds on the postage stamp problem for large numbers of stamps", "comment": null, "summary": "Let $F_h(n)$ denote the minimum cardinality of an additive {\\em $h$-fold\nbasis} of $\\{1,2,\\cdots,n\\}$: a set $S$ such that any integer in $\\{1,2,\\cdots,\nn\\}$ can be written as a sum of at most $h$ elements from $S$. While the\ntrivial bounds $h!n \\; \\lesssim \\; F_h(n)^h \\; \\lesssim \\; h^h n$ are\nwell-known, comparatively little has been established for $h>2$. In this paper,\nwe make significant improvements to both of the best-known bounds on $F_h(n)$\nfor sufficiently large $h$. For the lower bound, we use a probabilistic\napproach along with the Berry-Esseen Theorem to improve upon the best-known\nasymptotic result due to Yu. We also establish the first nontrivial asymptotic\nupper bound on $F_h(n)$ by leveraging a construction for additive bases of\nfinite cyclic groups due to Jia and Shen. In particular, we show that given any\n$\\epsilon>0$, for sufficiently large $h$, we have \\[\n\\left(\\frac{1}{2}-\\epsilon\\right)h!\\sqrt{2\\pi e} n\\; \\leq \\; F_h(n)^h \\; \\leq\n\\; \\left(\\left(\\frac{\\sqrt{3}}{2}+\\epsilon\\right)h\\right)^h n. \\]"}
{"id": "2507.23497", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23497", "abs": "https://arxiv.org/abs/2507.23497", "authors": ["David A Kelly", "Hana Chockler"], "title": "Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification", "comment": "13 pages, 13 figures, appendix included", "summary": "Existing algorithms for explaining the outputs of image classifiers are based\non a variety of approaches and produce explanations that lack formal rigor. On\nthe other hand, logic-based explanations are formally and rigorously defined\nbut their computability relies on strict assumptions about the model that do\nnot hold on image classifiers.\n  In this paper, we show that causal explanations, in addition to being\nformally and rigorously defined, enjoy the same formal properties as\nlogic-based ones, while still lending themselves to black-box algorithms and\nbeing a natural fit for image classifiers. We prove formal properties of causal\nexplanations and introduce contrastive causal explanations for image\nclassifiers. Moreover, we augment the definition of explanation with confidence\nawareness and introduce complete causal explanations: explanations that are\nclassified with exactly the same confidence as the original image.\n  We implement our definitions, and our experimental results demonstrate that\ndifferent models have different patterns of sufficiency, contrastiveness, and\ncompleteness. Our algorithms are efficiently computable, taking on average 6s\nper image on a ResNet50 model to compute all types of explanations, and are\ntotally black-box, needing no knowledge of the model, no access to model\ninternals, no access to gradient, nor requiring any properties, such as\nmonotonicity, of the model."}
{"id": "2507.23635", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.23635", "abs": "https://arxiv.org/abs/2507.23635", "authors": ["Shouhong Qiao", "Ning Su", "Binzhou Xia", "Zhishuo Zhang", "Sanming Zhou"], "title": "Which maximal subgroups are perfect codes?", "comment": null, "summary": "A perfect code in a graph $\\Gamma=(V, E)$ is a subset $C$ of $V$ such that no\ntwo vertices in $C$ are adjacent and every vertex in $V \\setminus C$ is\nadjacent to exactly one vertex in $C$. A subgroup $H$ of a group $G$ is called\na subgroup perfect code of $G$ if it is a perfect code in some Cayley graph of\n$G$. In this paper, we undertake a systematic study of which maximal subgroups\nof a group can be perfect codes. Our approach highlights a characterization of\nsubgroup perfect codes in terms of their ``local'' complements."}
{"id": "2507.23554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23554", "abs": "https://arxiv.org/abs/2507.23554", "authors": ["Ruoyu Wang", "Junda Wu", "Yu Xia", "Tong Yu", "Ryan A. Rossi", "Julian McAuley", "Lina Yao"], "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "comment": null, "summary": "Large language model-based agents, empowered by in-context learning (ICL),\nhave demonstrated strong capabilities in complex reasoning and tool-use tasks.\nHowever, existing works have shown that the effectiveness of ICL is highly\nsensitive to the choice of demonstrations, with suboptimal examples often\nleading to unstable or degraded performance. While prior work has explored\nexample selection, including in some agentic or multi-step settings, existing\napproaches typically rely on heuristics or task-specific designs and lack a\ngeneral, theoretically grounded criterion for what constitutes an effective\ndemonstration across reasoning steps. Therefore, it is non-trivial to develop a\nprincipled, general-purpose method for selecting demonstrations that\nconsistently benefit agent performance. In this paper, we address this\nchallenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a\ntheoretically grounded ICL framework for agentic tasks that selects the most\nrelevant demonstrations at each step of reasoning. Our approach decomposes\ndemonstration knowledge into transferable and non-transferable components\nthrough a causal lens, showing how the latter can introduce spurious\ndependencies that impair generalization. We further propose a stepwise\nselection criterion with a formal guarantee of improved agent performance.\nImportantly, DICE is a general, framework-agnostic solution that can be\nintegrated as a plug-in module into existing agentic frameworks without any\nadditional training cost. Extensive experiments across diverse domains\ndemonstrate our method's effectiveness and generality, highlighting the\nimportance of principled, context-aware demo selection for robust and efficient\nLLM agents."}
{"id": "2507.23681", "categories": ["math.CO", "math.MG"], "pdf": "https://arxiv.org/pdf/2507.23681", "abs": "https://arxiv.org/abs/2507.23681", "authors": ["Daniele D'Angeli", "Francesco Matucci", "Davide Perego", "Emanuele Rodaro"], "title": "Horofunctions of infinite Sierpinski polygon graphs", "comment": "16 pages", "summary": "Generalizing works of D'Angeli and Donno, we describe, starting from an\ninfinite sequence over $r$ letters with $r \\neq 4i$ and $i \\in \\mathbb{N}$, a\nsequence of pointed finite graphs. We study the pointed Gromov-Hausdorff limit\ngraphs giving a description of isomorphim classes in terms of dihedral groups\nand providing insights on the horofunction boundaries in terms of Busemann and\nnon-Busemann points."}
{"id": "2507.23565", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23565", "abs": "https://arxiv.org/abs/2507.23565", "authors": ["Botao Zhu", "Xianbin Wang", "Dusit Niyato"], "title": "Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI", "comment": null, "summary": "In collaborative systems, the effective completion of tasks hinges on\ntask-specific trust evaluations of potential devices for distributed\ncollaboration. However, the complexity of tasks, the spatiotemporal dynamism of\ndistributed device resources, and the inevitable assessment overhead\ndramatically increase the complexity and resource consumption of the trust\nevaluation process. As a result, ill-timed or overly frequent trust evaluations\ncan reduce utilization rate of constrained resources, negatively affecting\ncollaborative task execution. To address this challenge, this paper proposes an\nautonomous trust orchestration method based on a new concept of semantic\nchain-of-trust. Our technique employs agentic AI and hypergraph to establish\nand maintain trust relationships among devices. By leveraging its strengths in\nautonomous perception, task decomposition, and semantic reasoning, we propose\nagentic AI to perceive device states and autonomously perform trust evaluations\nof collaborators based on historical performance data only during device idle\nperiods, thereby enabling efficient utilization of distributed resources. In\naddition, agentic AI performs task-specific trust evaluations on collaborator\nresources by analyzing the alignment between resource capabilities and task\nrequirements. Moreover, by maintaining a trust hypergraph embedded with trust\nsemantics for each device, agentic AI enables hierarchical management of\ncollaborators and identifies collaborators requiring trust evaluation based on\ntrust semantics, thereby achieving a balance between overhead and trust\naccuracy. Furthermore, local trust hypergraphs from multiple devices can be\nchained together to support multi-hop collaboration, enabling efficient\ncoordination in large-scale systems. Experimental results demonstrate that the\nproposed method achieves resource-efficient trust evaluation."}
{"id": "2507.23633", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23633", "abs": "https://arxiv.org/abs/2507.23633", "authors": ["Qian Zhao", "Zhuo Sun", "Bin Guo", "Zhiwen Yu"], "title": "MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying", "comment": null, "summary": "Agent-assisted memory recall is one critical research problem in the field of\nhuman-computer interaction. In conventional methods, the agent can retrieve\ninformation from its equipped memory module to help the person recall\nincomplete or vague memories. The limited size of memory module hinders the\nacquisition of complete memories and impacts the memory recall performance in\npractice. Memory theories suggest that the person's relevant memory can be\nproactively activated through some effective cues. Inspired by this, we propose\na novel strategy-guided agent-assisted memory recall method, allowing the agent\nto transform an original query into a cue-rich one via the judiciously designed\nstrategy to help the person recall memories. To this end, there are two key\nchallenges. (1) How to choose the appropriate recall strategy for diverse\nforgetting scenarios with distinct memory-recall characteristics? (2) How to\nobtain the high-quality responses leveraging recall strategies, given only\nabstract and sparsely annotated strategy patterns? To address the challenges,\nwe propose a Recall Router framework. Specifically, we design a 5W Recall Map\nto classify memory queries into five typical scenarios and define fifteen\nrecall strategy patterns across the corresponding scenarios. We then propose a\nhierarchical recall tree combined with the Monte Carlo Tree Search algorithm to\noptimize the selection of strategy and the generation of strategy responses. We\nconstruct an instruction tuning dataset and fine-tune multiple open-source\nlarge language models (LLMs) to develop MemoCue, an agent that excels in\nproviding memory-inspired responses. Experiments on three representative\ndatasets show that MemoCue surpasses LLM-based methods by 17.74% in recall\ninspiration. Further human evaluation highlights its advantages in\nmemory-recall applications."}
{"id": "2507.23664", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.23664", "abs": "https://arxiv.org/abs/2507.23664", "authors": ["Haipeng Liu", "Yuxuan Liu", "Ting Long"], "title": "Personalized Education with Ranking Alignment Recommendation", "comment": null, "summary": "Personalized question recommendation aims to guide individual students\nthrough questions to enhance their mastery of learning targets. Most previous\nmethods model this task as a Markov Decision Process and use reinforcement\nlearning to solve, but they struggle with efficient exploration, failing to\nidentify the best questions for each student during training. To address this,\nwe propose Ranking Alignment Recommendation (RAR), which incorporates\ncollaborative ideas into the exploration mechanism, enabling more efficient\nexploration within limited training episodes. Experiments show that RAR\neffectively improves recommendation performance, and our framework can be\napplied to any RL-based question recommender. Our code is available in\nhttps://github.com/wuming29/RAR.git."}
{"id": "2507.23701", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23701", "abs": "https://arxiv.org/abs/2507.23701", "authors": ["Long Phan", "Mantas Mazeika", "Andy Zou", "Dan Hendrycks"], "title": "TextQuests: How Good are LLMs at Text-Based Video Games?", "comment": null, "summary": "Evaluating AI agents within complex, interactive environments that mirror\nreal-world challenges is critical for understanding their practical\ncapabilities. While existing agent benchmarks effectively assess skills like\ntool use or performance on structured tasks, they often do not fully capture an\nagent's ability to operate autonomously in exploratory environments that demand\nsustained, self-directed reasoning over a long and growing context. To spur the\ndevelopment of agents capable of more robust intrinsic reasoning over long\nhorizons, we introduce TextQuests, a benchmark based on the Infocom suite of\ninteractive fiction games. These text-based adventures, which can take human\nplayers over 30 hours and require hundreds of precise actions to solve, serve\nas an effective proxy for evaluating AI agents on focused, stateful tasks. The\nbenchmark is specifically designed to assess an LLM agent's capacity for\nself-contained problem-solving by precluding the use of external tools, thereby\nfocusing on intrinsic long-context reasoning capabilities in an exploratory\nenvironment characterized by the need for trial-and-error learning and\nsustained problem-solving within a single interactive session. We release\nTextQuests at https://textquests.ai."}
{"id": "2507.23726", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23726", "abs": "https://arxiv.org/abs/2507.23726", "authors": ["Luoxin Chen", "Jinming Gu", "Liankai Huang", "Wenhao Huang", "Zhicheng Jiang", "Allan Jie", "Xiaoran Jin", "Xing Jin", "Chenggang Li", "Kaijing Ma", "Cheng Ren", "Jiawei Shen", "Wenlei Shi", "Tong Sun", "He Sun", "Jiahui Wang", "Siran Wang", "Zhihong Wang", "Chenrui Wei", "Shufa Wei", "Yonghui Wu", "Yuchen Wu", "Yihang Xia", "Huajian Xin", "Fan Yang", "Huaiyuan Ying", "Hongyi Yuan", "Zheng Yuan", "Tianyang Zhan", "Chi Zhang", "Yue Zhang", "Ge Zhang", "Tianyun Zhao", "Jianqiu Zhao", "Yichi Zhou", "Thomas Hanwen Zhu"], "title": "Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving", "comment": null, "summary": "LLMs have demonstrated strong mathematical reasoning abilities by leveraging\nreinforcement learning with long chain-of-thought, yet they continue to\nstruggle with theorem proving due to the lack of clear supervision signals when\nsolely using natural language. Dedicated domain-specific languages like Lean\nprovide clear supervision via formal verification of proofs, enabling effective\ntraining through reinforcement learning. In this work, we propose\n\\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover\ncan iteratively refine its proof based on Lean feedback, proved lemmas, and\nself-summarization. To solve IMO-level contest problems, we design three\ntest-time inference strategies that enable both deep and broad reasoning.\nSeed-Prover proves $78.1\\%$ of formalized past IMO problems, saturates MiniF2F,\nand achieves over 50\\% on PutnamBench, outperforming the previous\nstate-of-the-art by a large margin. To address the lack of geometry support in\nLean, we introduce a geometry reasoning engine \\textbf{Seed-Geometry}, which\noutperforms previous formal geometry engines. We use these two systems to\nparticipate in IMO 2025 and fully prove 5 out of 6 problems. This work\nrepresents a significant advancement in automated mathematical reasoning,\ndemonstrating the effectiveness of formal verification with long\nchain-of-thought reasoning."}
{"id": "2507.23751", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23751", "abs": "https://arxiv.org/abs/2507.23751", "authors": ["Ping Yu", "Jack Lanchantin", "Tianlu Wang", "Weizhe Yuan", "Olga Golovneva", "Ilia Kulikov", "Sainbayar Sukhbaatar", "Jason Weston", "Jing Xu"], "title": "CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks", "comment": null, "summary": "We propose CoT-Self-Instruct, a synthetic data generation method that\ninstructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the\ngiven seed tasks, and then to generate a new synthetic prompt of similar\nquality and complexity for use in LLM training, followed by filtering for\nhigh-quality data with automatic metrics. In verifiable reasoning, our\nsynthetic data significantly outperforms existing training datasets, such as\ns1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For\nnon-verifiable instruction-following tasks, our method surpasses the\nperformance of human or standard self-instruct prompts on both AlpacaEval 2.0\nand Arena-Hard."}
{"id": "2507.23773", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.23773", "abs": "https://arxiv.org/abs/2507.23773", "authors": ["Mingkai Deng", "Jinyu Hou", "Yilin Shen", "Hongxia Jin", "Graham Neubig", "Zhiting Hu", "Eric Xing"], "title": "SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model", "comment": null, "summary": "AI agents built on large language models (LLMs) hold enormous promise, but\ncurrent practice focuses on a one-task-one-agent approach, which not only falls\nshort of scalability and generality, but also suffers from the fundamental\nlimitations of autoregressive LLMs. On the other hand, humans are general\nagents who reason by mentally simulating the outcomes of their actions and\nplans. Moving towards a more general and powerful AI agent, we introduce\nSimuRA, a goal-oriented architecture for generalized agentic reasoning. Based\non a principled formulation of optimal agent in any environment, \\modelname\novercomes the limitations of autoregressive reasoning by introducing a world\nmodel for planning via simulation. The generalized world model is implemented\nusing LLM, which can flexibly plan in a wide range of environments using the\nconcept-rich latent space of natural language. Experiments on difficult web\nbrowsing tasks show that \\modelname improves the success of flight search from\n0\\% to 32.2\\%. World-model-based planning, in particular, shows consistent\nadvantage of up to 124\\% over autoregressive planning, demonstrating the\nadvantage of world model simulation as a reasoning paradigm. We are excited\nabout the possibility for training a single, general agent model based on LLMs\nthat can act superintelligently in all environments. To start, we make SimuRA,\na web-browsing agent built on \\modelname with pretrained LLMs, available as a\nresearch demo for public testing."}
{"id": "2507.22908", "categories": ["q-fin.CP", "cs.AI", "cs.LG", "I.2"], "pdf": "https://arxiv.org/pdf/2507.22908", "abs": "https://arxiv.org/abs/2507.22908", "authors": ["Abhishek Sawaika", "Swetang Krishna", "Tushar Tomar", "Durga Pritam Suggisetti", "Aditi Lal", "Tanmaya Shrivastav", "Nouhaila Innan", "Muhammad Shafique"], "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection", "comment": "To be published in proceedings of IEEE International Conference on\n  Quantum Computing and Engineering (QCE) 2025", "summary": "Rapid growth of digital transactions has led to a surge in fraudulent\nactivities, challenging traditional detection methods in the financial sector.\nTo tackle this problem, we introduce a specialised federated learning framework\nthat uniquely combines a quantum-enhanced Long Short-Term Memory (LSTM) model\nwith advanced privacy preserving techniques. By integrating quantum layers into\nthe LSTM architecture, our approach adeptly captures complex\ncross-transactional patters, resulting in an approximate 5% performance\nimprovement across key evaluation metrics compared to conventional models.\nCentral to our framework is \"FedRansel\", a novel method designed to defend\nagainst poisoning and inference attacks, thereby reducing model degradation and\ninference accuracy by 4-8%, compared to standard differential privacy\nmechanisms. This pseudo-centralised setup with a Quantum LSTM model, enhances\nfraud detection accuracy and reinforces the security and confidentiality of\nsensitive financial data."}
{"id": "2507.23611", "categories": ["cs.CR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23611", "abs": "https://arxiv.org/abs/2507.23611", "authors": ["Estelle Ruellan", "Eric Clay", "Nicholas Ascoli"], "title": "LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora", "comment": null, "summary": "Infostealers exfiltrate credentials, session cookies, and sensitive data from\ninfected systems. With over 29 million stealer logs reported in 2024, manual\nanalysis and mitigation at scale are virtually unfeasible/unpractical. While\nmost research focuses on proactive malware detection, a significant gap remains\nin leveraging reactive analysis of stealer logs and their associated artifacts.\nSpecifically, infection artifacts such as screenshots, image captured at the\npoint of compromise, are largely overlooked by the current literature. This\npaper introduces a novel approach leveraging Large Language Models (LLMs), more\nspecifically gpt-4o-mini, to analyze infection screenshots to extract potential\nIndicators of Compromise (IoCs), map infection vectors, and track campaigns.\nFocusing on the Aurora infostealer, we demonstrate how LLMs can process\nscreenshots to identify infection vectors, such as malicious URLs, installer\nfiles, and exploited software themes. Our method extracted 337 actionable URLs\nand 246 relevant files from 1000 screenshots, revealing key malware\ndistribution methods and social engineering tactics. By correlating extracted\nfilenames, URLs, and infection themes, we identified three distinct malware\ncampaigns, demonstrating the potential of LLM-driven analysis for uncovering\ninfection workflows and enhancing threat intelligence. By shifting malware\nanalysis from traditional log-based detection methods to a reactive,\nartifact-driven approach that leverages infection screenshots, this research\npresents a scalable method for identifying infection vectors and enabling early\nintervention."}
