<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 7]
- [math.OC](#math.OC) [Total: 9]
- [math.NT](#math.NT) [Total: 7]
- [math.LO](#math.LO) [Total: 2]
- [math.HO](#math.HO) [Total: 1]
- [math.CO](#math.CO) [Total: 16]
- [cs.CR](#cs.CR) [Total: 24]
- [cs.AI](#cs.AI) [Total: 23]
- [cs.DM](#cs.DM) [Total: 1]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [On unbiased estimators for functions of the rate parameter of the exponential distribution](https://arxiv.org/abs/2506.20005)
*Roberto Vila,Eduardo Yoshio Nakano*

Main category: math.ST

TL;DR: 本文显式推导了指数分布率参数多种函数的无偏估计量，包括率参数的幂、分位数、矩等，并修正了Tate提出的通用公式，同时证明了所提估计量的渐近正态性。


<details>
  <summary>Details</summary>
Motivation: 针对指数分布率参数相关函数的无偏估计问题，修正历史公式错误并扩展估计范围，为统计推断提供更可靠的工具。

Method: 通过数学推导显式构造无偏估计量，涵盖率参数的幂、分位数、生存函数等，并采用渐近理论分析估计量性质。

Result: 成功推导出包括$q$分位数、$p$阶矩等在内的无偏估计量，修正了Tate(1959)的通用公式，并证明估计量具有渐近正态性。

Conclusion: 本研究系统解决了指数分布率参数函数的无偏估计问题，理论结果对统计实践具有重要指导意义。

Abstract: In this paper, we explicitly derive unbiased estimators for various functions
of the rate parameter of the exponential distribution, including powers of the
rate parameter, the $q$th quantile, the $p$th moment, the survival function,
the maximum, minimum, probability density function, mean past lifetime, moment
generating function, and others. It is also noteworthy that this work corrects
a general formula originally proposed by Tate, R. F. (Ann. Math. Statist.,
30(2): 341-366, 1959) for constructing unbiased estimators of functions of the
exponential distribution's rate parameter in the absence of a location
parameter. Additionally, we establish a result demonstrating the asymptotic
normality of the proposed unbiased estimators.

</details>


### [2] [Modifications of the BIC for order selection in finite mixture models](https://arxiv.org/abs/2506.20124)
*Hien Duy Nguyen,TrungTin Nguyen*

Main category: math.ST

TL;DR: 本文提出了改进的$\nu$-BIC和$\epsilon$-BIC准则，通过引入对数加权因子，在更弱的模型正则性条件下实现了混合模型阶数选择的一致性。


<details>
  <summary>Details</summary>
Motivation: 传统BIC准则在混合模型阶数选择中需要强正则性假设（如高阶矩和密度函数可导性），限制了其应用范围。研究旨在放宽这些约束条件。

Method: 通过给BIC惩罚项添加极小对数权重因子（$\nu$-BIC和$\epsilon$-BIC），在保持实用效果的同时降低理论要求。

Result: 改进后的准则在无需可导性和最小矩假设下仍能保证一致性，适用于高斯混合、拉普拉斯混合及回归混合模型。

Conclusion: 微调后的BIC显著扩展了混合模型阶数选择的适用场景，为复杂数据建模提供了更灵活的理论工具。

Abstract: Finite mixture models are ubiquitous tools in modern statistical modeling,
and a frequently encountered problem that arises in their implementation is the
choice of model order. In Kerebin (2000, Sankhya: The Indian Journal of
Statistics, Series A, 62, pp. 49-66), the frequently used Bayesian information
criterion (BIC) was proved to provide consistent order estimation in the
mixture model setting. However, the result requires particularly strong model
regularity, including the existence of higher moments and higher derivatives of
the component density function. We introduce the $\nu$-BIC and $\epsilon$-BIC,
which modifies the BIC by weighting the penalty by a negligibly small
logarithmic factors that are immaterial in practice. We prove that the minor
modification enables consistency guarantees under weaker conditions,
particularly without differentiability and with minimal moment assumptions. We
demonstrate how our theory apply to obtaining order selection consistency for
Gaussian mixtures, non-differentiable Laplace mixtures, and mixtures of
regression models.

</details>


### [3] [Affine invariant interacting Langevin dynamics in Markov chain importance sampling for rare event estimation](https://arxiv.org/abs/2506.20185)
*Jason Beh,Jérôme Morio,Florian Simatos,Simon Weissmann*

Main category: math.ST

TL;DR: 本文提出了一种名为ALDI-IS的基于梯度的马尔可夫链重要性采样方法，用于稀有事件估计，通过平滑最优密度解决了非可微性问题，并分析了平滑参数对采样误差与采样难度的影响。


<details>
  <summary>Details</summary>
Motivation: 在稀有事件估计中，最优分布的对数密度非可微，导致基于梯度的MCMC方法只能逼近平滑后的最优密度，因此需要开发新的采样方案以平衡采样精度与效率。

Method: 提出ALDI-IS方法，利用仿射不变交互Langevin动力学（ALDI）从平滑后的零方差密度中采样，并分析了独立同分布采样及简化版ALDI（非调整Langevin算法）的误差界限。

Result: 研究表明，平滑参数对重要性采样误差和ALDI采样效率具有显著影响，二者之间存在权衡关系，数值实验验证了这一现象。

Conclusion: ALDI-IS为稀有事件估计提供了一种有效框架，平滑参数的选择需在低采样误差与易采样性之间取得平衡，标准测试案例验证了其可行性。

Abstract: This work considers the framework of Markov chain importance sampling~(MCIS),
in which one employs a Markov chain Monte Carlo~(MCMC) scheme to sample
particles approaching the optimal distribution for importance sampling, prior
to estimating the quantity of interest through importance sampling. In rare
event estimation, the optimal distribution admits a non-differentiable
log-density, thus gradient-based MCMC can only target a smooth approximation of
the optimal density. We propose a new gradient-based MCIS scheme for rare event
estimation, called affine invariant interacting Langevin dynamics for
importance sampling~(ALDI-IS), in which the affine invariant interacting
Langevin dynamics~(ALDI) is used to sample particles according to the smoothed
zero-variance density. We establish a non-asymptotic error bound when
importance sampling is used in conjunction with samples independently and
identically distributed according to the smoothed optiaml density to estimate a
rare event probability, and an error bound on the sampling bias when a
simplified version of ALDI, the unadjusted Langevin algorithm, is used to
sample from the smoothed optimal density. We show that the smoothing parameter
of the optimal density has a strong influence and exhibits a trade-off between
a low importance sampling error and the ease of sampling using ALDI. We perform
a numerical study of ALDI-IS and illustrate this trade-off phenomenon on
standard rare event estimation test cases.

</details>


### [4] [A model-based approach to density estimation in sup-norm](https://arxiv.org/abs/2506.20239)
*Guillaume Maillard*

Main category: math.ST

TL;DR: 提出了一种基于独立样本寻找目标密度准最佳逼近的通用方法，并解决了单指标模型中固定光滑度$\beta$情况下的开放性问题。


<details>
  <summary>Details</summary>
Motivation: 研究如何在给定模型中，基于独立样本找到目标密度的准最佳逼近，即使目标密度本身不属于该模型。

Method: 定义了一种通用方法，用于在给定模型中找到目标密度的准最佳逼近，并提供了在可数模型族中进行选择的方法。这些估计器满足一般情况下的oracle不等式。

Result: 方法的性能取决于$|p-q|$接近其最大值的集合体积，其中$p,q$属于模型（或在模型选择情况下属于两个不同模型）。在多种设置下（如给定分割上的分段多项式和各向异性光滑类）得到了最优结果。特别是在固定光滑度$\beta$的单指标模型中，恢复了一维速率，解决了开放性问题。

Conclusion: 所提出的方法在多种设置下表现优异，特别是在单指标模型中解决了开放性问题，为密度逼近和模型选择提供了有效的通用框架。

Abstract: We define a general method for finding a quasi-best approximant in sup-norm
to a target density belonging to a given model, based on independent samples
drawn from distributions which average to the target (which does not
necessarily belong to the model). We also provide a general method for
selecting among a countable family of such models. These estimators satisfy
oracle inequalities in the general setting. The quality of the bounds depends
on the volume of sets on which $|p-q|$ is close to its maximum, where $p,q$
belong to the model (or possibly to two different models, in the case of model
selection). This leads to optimal results in a number of settings, including
piecewise polynomials on a given partition and anisotropic smoothness classes.
Particularly interesting is the case of the single index model with fixed
smoothness $\beta$, where we recover the one-dimensional rate: this was an open
problem.

</details>


### [5] [Robust estimation of a Markov chain transition matrix from multiple sample paths](https://arxiv.org/abs/2506.20325)
*Lasse Leskelä,Maximilien Dreveton*

Main category: math.ST

TL;DR: 本文研究了异构马尔可夫链的转移矩阵与稳态分布估计问题，提出了适用于并行样本路径的统计推断方法，并建立了非渐近误差界与一致性保证。


<details>
  <summary>Details</summary>
Motivation: 经典马尔可夫链理论假设同质链且稳态分布已知，但实际数据常来自具有不同转移核与稳态测度的异构链。需要发展适用于此类场景的统计推断理论。

Method: 通过分析并行马尔可夫过程的经验估计量，将伯恩斯坦型界限从传统时间平均推广到集合-时间平均框架。

Result: 建立了高维场景下的非渐近误差界，适用于稀疏链、弱混合链、模型失配、非平稳初始及部分污染数据，为统计推断提供严格理论基础。

Conclusion: 该研究为现代计算应用中常见的异构马尔可夫链场景提供了统计推断的 rigorous 理论基础，扩展了传统方法的适用边界。

Abstract: Markov chains are fundamental models for stochastic dynamics, with
applications in a wide range of areas such as population dynamics, queueing
systems, reinforcement learning, and Monte Carlo methods. Estimating the
transition matrix and stationary distribution from observed sample paths is a
core statistical challenge, particularly when multiple independent trajectories
are available. While classical theory typically assumes identical chains with
known stationary distributions, real-world data often arise from heterogeneous
chains whose transition kernels and stationary measures might differ from a
common target. We analyse empirical estimators for such parallel Markov
processes and establish sharp concentration inequalities that generalise
Bernstein-type bounds from standard time averages to ensemble-time averages.
Our results provide nonasymptotic error bounds and consistency guarantees in
high-dimensional regimes, accommodating sparse or weakly mixing chains, model
mismatch, nonstationary initialisations, and partially corrupted data. These
findings offer rigorous foundations for statistical inference in heterogeneous
Markov chain settings common in modern computational applications.

</details>


### [6] [On Exponential Random Graph Models with Dyadic Independence](https://arxiv.org/abs/2506.20458)
*Kayvan Sadeghi*

Main category: math.ST

TL;DR: 论文证明了在节点参数独立且具有置换等变性的自然假设下，唯一具有n个节点参数的指数随机图模型是\b{eta}模型，并指出类似假设但参数少于n的模型为加性随机分块模型。


<details>
  <summary>Details</summary>
Motivation: 研究在特定假设条件下，指数随机图模型和随机分块模型的唯一性，以深化对网络统计模型的理解。

Method: 通过数学证明和理论分析，验证了在节点参数独立和置换等变性的假设下，\b{eta}模型和加性随机分块模型的唯一性。

Result: 证明了\b{eta}模型是指数随机图模型中唯一满足条件的模型，加性随机分块模型是参数少于n时的唯一模型，并推广到有向网络。

Conclusion: 研究结果为网络统计分析提供了理论支持，明确了特定条件下模型的唯一性，为后续研究奠定了基础。

Abstract: We show that the only exponential random graph model with n nodal parameters,
dyads being independent, and the natural assumption of permutation-equivariant
nodal parametrization is the \b{eta} model. In addition, we show that an
exponential random graph model with similar assumptions but with fewer than n
block parameters is the additive stochastic block model. We also provide
similar results for directed networks

</details>


### [7] [A High-Dimensional Statistical Theory for Convex and Nonconvex Matrix Sensing](https://arxiv.org/abs/2506.20659)
*Joshua Agterberg,René Vidal*

Main category: math.ST

TL;DR: 本文研究了高斯测量和噪声下对称低秩矩阵感知问题，发现非凸因子化方法在均方误差上一致优于凸核范数正则化方法。


<details>
  <summary>Details</summary>
Motivation: 现有工作对矩阵感知问题的凸和非凸方法进行了研究，但在高维统计模型下这些方法的精确比较仍未探索。本文旨在填补这一空白。

Method: 采用高维统计分析方法，基于矩阵算子的凸高斯极小极大定理（CGMT），研究凸和非凸公式的局部极小值及其去偏对应关系。

Result: 在适当渐近条件下，非凸因子化方法的任何局部极小值行为近似等价于矩阵去噪问题的硬阈值处理，而凸方法则近似等价于软阈值处理。非凸方法在均方误差上一致优于凸方法。

Conclusion: 本文揭示了非凸方法在高斯测量和噪声下的统计优势，相关结果可能具有独立的理论价值。

Abstract: The problem of matrix sensing, or trace regression, is a problem wherein one
wishes to estimate a low-rank matrix from linear measurements perturbed with
noise. A number of existing works have studied both convex and nonconvex
approaches to this problem, establishing minimax error rates when the number of
measurements is sufficiently large relative to the rank and dimension of the
low-rank matrix, though a precise comparison of these procedures still remains
unexplored. In this work we provide a high-dimensional statistical analysis for
symmetric low-rank matrix sensing observed under Gaussian measurements and
noise. Our main result describes a novel phenomenon: in this statistical model
and in an appropriate asymptotic regime, the behavior of any local minimum of
the nonconvex factorized approach (with known rank) is approximately equivalent
to that of the matrix hard-thresholding of a corresponding matrix denoising
problem, and the behavior of the convex nuclear-norm regularized least squares
approach is approximately equivalent to that of matrix soft-thresholding of the
same matrix denoising problem. Here "approximately equivalent" is understood in
the sense of concentration of Lipchitz functions. As a consequence, the
nonconvex procedure uniformly dominates the convex approach in mean squared
error. Our arguments are based on a matrix operator generalization of the
Convex Gaussian Min-Max Theorem (CGMT) together with studying the interplay
between local minima of the convex and nonconvex formulations and their
"debiased" counterparts, and several of these results may be of independent
interest.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [8] [Approximating the order 2 quantum Wasserstein distance using the moment-SOS hierarchy](https://arxiv.org/abs/2506.20006)
*Saroj Prasad Chhatoi,Victor Magron*

Main category: math.OC

TL;DR: 本文研究了二阶量子Wasserstein距离的计算问题，将其表述为无限维线性规划，并利用广义矩问题和矩-平方和层次结构提供收敛的下界序列。


<details>
  <summary>Details</summary>
Motivation: 最优传输理论近期被扩展到量子领域，其中密度矩阵推广了概率测度。本文旨在解决二阶量子Wasserstein距离的计算问题。

Method: 将量子Wasserstein距离表述为两个单位球面乘积上正Borel测度空间的无限维线性规划，并利用广义矩问题和矩-平方和层次结构进行计算。

Result: 通过数值实验验证了方法的有效性，展示了一序列收敛于真实距离的下界。

Conclusion: 提出的方法为量子最优传输问题的计算提供了有效工具，并通过数值实验验证了其可行性。

Abstract: Optimal transport theory has recently been extended to quantum settings,
where the density matrices generalize the probability measures. In this paper,
we study the computational aspects of the order 2 quantum Wasserstein distance,
formulating it as an infinite dimensional linear program in the space of
positive Borel measures supported on products of two unit spheres. This
formulation is recognized as an instance of the Generalized Moment Problem,
which enables us to use the moment-sums of squares hierarchy to provide a
sequence of lower bounds converging to the distance. We illustrate our approach
with numerical experiments.

</details>


### [9] [Instance Space Analysis for the Quadratic Assignment Problem](https://arxiv.org/abs/2506.20172)
*Jeffrey Christiansen,Kate Smith-Miles*

Main category: math.OC

TL;DR: 本文针对二次分配问题(QAP)，提出消除实例间非本质差异的方法，设计新特征量化实例特性，并通过实例空间分析比较进化算法与蚁群算法性能，揭示现有实例库的局限性，提出扩展实例空间的新类别。


<details>
  <summary>Details</summary>
Motivation: 在优化问题中，算法性能预测与选择具有重要实践意义，但测试实例若不能充分代表问题空间，可能导致对算法优缺点的误判。本文旨在解决QAP领域的这一问题。

Method: 1) 识别并消除QAP实例间不影响问题难度的表面差异 2) 提出多个新特征量化实例特性 3) 应用实例空间分析法比较进化算法与蚁群算法 4) 分析现有实例库与生成器的局限性

Result: 研究发现现有实例库存在明显局限，掩盖了算法的真实性能特征。通过提出的新实例类别，扩展了实例空间并获得了对问题及算法特性的新认知。

Conclusion: 通过系统化分析QAP实例空间，本研究不仅改进了算法性能评估方法，还提出了更具代表性的实例生成方案，为未来算法比较研究提供了新范式。

Abstract: For any optimisation problem where diverse algorithmic approaches are
available, the task of predicting algorithm performance and selecting the
algorithm most likely to perform well on a given instance holds great practical
interest. However, if our test instances do not adequately represent the
potential problem space, we may be misled about the strengths and weaknesses of
an algorithm. In this paper we consider algorithm prediction and selection for
the Quadratic Assignment Problem (QAP). We identify and eliminate superficial
differences between QAP instances which do not affect problem difficulty and
propose several new features for quantifying the characteristics of a
particular instance. We then apply Instance Space Analysis to compare the
performance of evolutionary and ant colony-based algorithms. Using this
analysis, we identify limitations of the existing instance libraries and
generators which obscure the true performance profile of these algorithms.
Finally, we propose new instance classes which expand the instance space and
support new insights into the properties of the problem and algorithms.

</details>


### [10] [Fast entropy-regularized SDP relaxations for permutation synchronization](https://arxiv.org/abs/2506.20191)
*Michael Lindsey,Yunpeng Shi*

Main category: math.OC

TL;DR: 本文提出了一种快速随机算法，用于解决部分排列同步（PPS）问题的半定规划（SDP）松弛，该方法在熵正则化的基础上优化了计算效率和解的唯一性。


<details>
  <summary>Details</summary>
Motivation: 部分排列同步（PPS）是多图像匹配中的核心任务，对3D重建具有重要意义。传统方法在解的唯一性和计算效率上存在不足，因此需要一种更高效且理论完备的解决方案。

Method: 基于熵正则化的半定规划（SDP）方法，针对PPS问题的特殊结构设计随机化求解器，并开发了从隐式表示的原始解变量中恢复组合解的舍入程序。

Result: 实验表明，该方法在合成和真实数据集上均实现了速度和精度的最优表现，优于传统的低秩或谱技术。

Conclusion: 熵正则化的SDP在PPS问题中展现出理论和实践上的双重优势，为多图像匹配提供了高效且可靠的解决方案。

Abstract: We introduce fast randomized algorithms for solving semidefinite programming
(SDP) relaxations of the partial permutation synchronization (PPS) problem, a
core task in multi-image matching with significant relevance to 3D
reconstruction. Our methods build on recent advances in entropy-regularized
semidefinite programming and are tailored to the unique structure of PPS, in
which the unknowns are partial permutation matrices aligning sparse and noisy
pairwise correspondences across images. We prove that entropy regularization
resolves optimizer non-uniqueness in standard relaxations, and we develop a
randomized solver with nearly optimal scaling in the number of observed
correspondences. We also develop several rounding procedures for recovering
combinatorial solutions from the implicitly represented primal solution
variable, maintaining cycle consistency if desired without harming
computational scaling. We demonstrate that our approach achieves
state-of-the-art performance on synthetic and real-world datasets in terms of
speed and accuracy. Our results highlight PPS as a paradigmatic setting in
which entropy-regularized SDP admits both theoretical and practical advantages
over traditional low-rank or spectral techniques.

</details>


### [11] [Speed-Aware Network Design: A Parametric Optimization Approach](https://arxiv.org/abs/2506.20216)
*Ugo Rosolia,Marc Bataillou Almagro,George Iosifidis,Martin Gross,Georgios Paschos*

Main category: math.OC

TL;DR: 本文提出了一种广义网络设计问题，通过引入速度覆盖概念，权衡路由成本与交付速度，并采用参数优化和采样策略解决库存建模的复杂性。


<details>
  <summary>Details</summary>
Motivation: 经典网络设计问题仅关注最小化路由成本，而实际应用中需同时考虑交付速度。速度覆盖（24小时内可送达的唯一物品数量）的引入填补了这一空白。

Method: 1. 将非线性联合路由与速度覆盖优化转化为混合整数线性规划；2. 提出采样策略避免评估速度覆盖函数的所有点。

Result: 在代表性场景和网络规模的数值测试中，该方法在综合考虑路由成本与速度覆盖收益时，平均优于基线8.36%。

Conclusion: 通过参数化建模和高效采样，该方法有效解决了库存-路由联合优化问题，为网络设计提供了新的权衡维度。

Abstract: Network design problems have been studied from the 1950s, as they can be used
in a wide range of real-world applications, e.g., design of communication and
transportation networks. In classical network design problems, the objective is
to minimize the cost of routing the demand flow through a graph. In this paper,
we introduce a generalized version of such a problem, where the objective is to
tradeoff routing costs and delivery speed; we introduce the concept of
speed-coverage, which is defined as the number of unique items that can be sent
to destinations in less than 1-day. Speed-coverage is a function of both the
network design and the inventory stored at origin nodes, e.g., an item can be
delivered in 1-day if it is in-stock at an origin that can reach a destination
within 24 hours. Modeling inventory is inherently complex, since inventory
coverage is described by an integer function with a large number of points
(exponential to the number of origin sites), each one to be evaluated using
historical data. To bypass this complexity, we first leverage a parametric
optimization approach, which converts the non-linear joint routing and
speed-coverage optimization problem into an equivalent mixed-integer linear
program. Then, we propose a sampling strategy to avoid evaluating all the
points of the speed-coverage function. The proposed method is evaluated on a
series of numerical tests with representative scenarios and network sizes. We
show that when considering the routing costs and monetary gains resulting from
speed-coverage, our approach outperforms the baseline by 8.36% on average.

</details>


### [12] [CLARSTA: A random subspace trust-region algorithm for convex-constrained derivative-free optimization](https://arxiv.org/abs/2506.20335)
*Yiwen Chen,Warren Hare,Amy Wiebe*

Main category: math.OC

TL;DR: 本文提出了一种用于凸约束无导数优化问题的随机子空间信赖域算法，通过新的模型精度定义和子空间采样方法，实现了高维问题的可靠求解。


<details>
  <summary>Details</summary>
Motivation: 针对高维凸约束无导数优化问题，现有方法在模型精度和子空间质量方面存在局限性，需要新的理论框架和算法设计。

Method: 提出仅需在约束集投影上保持精度的模型类，并引入Grassmann流形上的集中性理论来保证子空间质量，构建了随机子空间信赖域算法。

Result: 理论证明了算法的全局收敛性和最坏情况复杂度，在维度高达10000的问题上验证了算法的可靠性。

Conclusion: 该算法通过创新的模型定义和子空间采样技术，为高维凸约束无导数优化提供了有效的解决方案，具有理论和实践价值。

Abstract: This paper proposes a random subspace trust-region algorithm for general
convex-constrained derivative-free optimization (DFO) problems. Similar to
previous random subspace DFO methods, the convergence of our algorithm requires
a certain accuracy of models and a certain quality of subspaces. For model
accuracy, we define a new class of models that is only required to provide
reasonable accuracy on the projection of the constraint set onto the subspace.
We provide a new geometry measure to make these models easy to analyze,
construct, and manage. For subspace quality, we use the concentration on the
Grassmann manifold to provide a method to sample subspaces that preserve the
first-order criticality measure by a certain percentage with a certain
probability lower bound. Based on all these new theoretical results, we present
an almost-sure global convergence and a worst-case complexity analysis of our
algorithm. Numerical experiments on problems with dimensions up to 10000
demonstrate the reliable performance of our algorithm in high dimensions.

</details>


### [13] [A Complete Loss Landscape Analysis of Regularized Deep Matrix Factorization](https://arxiv.org/abs/2506.20344)
*Po Chen,Rujun Jiang,Peng Wang*

Main category: math.OC

TL;DR: 本文对正则化深度矩阵分解（DMF）的损失景观进行了全面研究，给出了临界点的闭式表达式，并建立了临界点性质（局部极小值、全局极小值、严格鞍点等）的精确条件，揭示了梯度法几乎总能收敛到局部极小值的原因。


<details>
  <summary>Details</summary>
Motivation: 尽管深度矩阵分解（DMF）在多个领域应用广泛，但其优化基础仍缺乏系统研究。本文旨在填补这一空白，深入分析正则化DMF问题的损失景观特性。

Method: 首先推导了所有临界点的闭式表达式，在此基础上建立了临界点性质的数学条件（如局部极小值、严格鞍点的判别准则），并通过数值实验可视化不同参数下的损失景观。

Result: 提出了临界点分类的充要条件，证明每个临界点要么是局部极小值，要么是严格鞍点，这解释了梯度法的高效收敛性。数值实验验证了理论结果。

Conclusion: 该研究为理解DMF的优化行为提供了理论框架，揭示了梯度法在正则化DMF问题中几乎必然收敛到局部最优解的内在机制，对实际应用具有指导意义。

Abstract: Despite its wide range of applications across various domains, the
optimization foundations of deep matrix factorization (DMF) remain largely
open. In this work, we aim to fill this gap by conducting a comprehensive study
of the loss landscape of the regularized DMF problem. Toward this goal, we
first provide a closed-form expression of all critical points. Building on
this, we establish precise conditions under which a critical point is a local
minimizer, a global minimizer, a strict saddle point, or a non-strict saddle
point. Leveraging these results, we derive a necessary and sufficient condition
under which each critical point is either a local minimizer or a strict saddle
point. This provides insights into why gradient-based methods almost always
converge to a local minimizer of the regularized DMF problem. Finally, we
conduct numerical experiments to visualize its loss landscape under different
settings to support our theory.

</details>


### [14] [A Decomposition Method for Finite-Time Stabilization of Bilinear Systems with Applications to Parabolic and Hyperbolic Equations](https://arxiv.org/abs/2506.20492)
*Kamal Fenza,Moussa Labbadi,Mohamed Ouzahra*

Main category: math.OC

TL;DR: 本文针对一类双线性系统的有限时间稳定问题，提出了一种基于分解的方法，通过将系统分解为两个子系统来简化稳定分析，并建立了闭环系统适定性的充分条件。


<details>
  <summary>Details</summary>
Motivation: 解决一类双线性系统的有限时间稳定问题，通过分解方法简化分析过程，提高控制效率。

Method: 采用分解方法，将名义系统分为两个子系统，其中一个子系统无需控制即具有有限时间稳定性，从而集中分析剩余子系统。通过建立系统和控制算子的充分条件，确保闭环系统的适定性，并利用合适的Lyapunov函数和观测条件推导稳定结果。

Result: 所提出的方法在抛物型和双曲型无限维系统示例中证明了其有效性，成功实现了有限时间稳定。

Conclusion: 通过分解方法和Lyapunov函数，本文有效解决了一类双线性系统的有限时间稳定问题，为无限维系统的控制提供了新思路。

Abstract: In this work, we address the problem of finite-time stabilization for a class
of bilinear system. We propose a decomposition-based approach in which the
nominal system is split into two subsystems, one of which is inherently
finite-time stable without control. This allows the stabilization analysis to
focus solely on the remaining subsystem. To ensure the well-posedness of the
closed-loop system, we establish sufficient conditions on the system and
control operators. The stabilization results are then derived using a suitable
Lyapunov function and an observation condition. The effectiveness of the
proposed approach is demonstrated through examples involving both parabolic and
hyperbolic infinite-dimensional systems.

</details>


### [15] [A Zeroth-Order Extra-Gradient Method For Black-Box Constrained Optimization](https://arxiv.org/abs/2506.20546)
*Yuke Zhou,Ruiyang Jin,Siyang Gao,Jianxiao Wang,Jie Song*

Main category: math.OC

TL;DR: 本文提出两种零阶优化算法ZOEG和ZOCEG，用于解决黑箱目标与约束的优化问题，理论证明其达到最优复杂度，并通过负载跟踪实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: 控制系统中非解析目标与约束问题普遍存在但缺乏高效解法，需开发适用于黑箱场景的优化方法。

Method: 将原问题重构为极小极大问题，结合额外梯度法与零阶梯度估计器设计ZOEG；进一步引入坐标梯度估计器开发ZOCEG，并提出分块坐标更新变种提升效率。

Result: ZOEG达到$\mathcal{O}(d\epsilon^{-2})$的已知最优复杂度，ZOCEG改进至$\mathcal{O}(d\epsilon^{-1})$，负载跟踪实验验证算法有效性。

Conclusion: 所提算法在理论和实验上均展现优越性，为黑箱约束优化问题提供了高效解决方案。

Abstract: Non-analytical objectives and constraints often arise in control systems,
particularly in problems with complex dynamics, which are challenging yet lack
efficient solution methods. In this work, we consider general constrained
optimization problems involving black-box objectives and constraints. To solve
it, we reformulate it as a min-max problem and propose a zeroth-order extra
gradient (ZOEG) algorithm that combines the extra gradient method with a
feedback-based stochastic zeroth-order gradient estimator. Then, we apply
another coordinate gradient estimator to design the zeroth-order coordinate
extra gradient algorithm (ZOCEG) to further improve efficiency. The theoretical
analysis shows that ZOEG can achieve the best-known oracle complexity of
$\mathcal{O}(d\epsilon^{-2})$ to get an $\epsilon$-optimal solution ($d$ is the
dimension of decision space), and ZOCEG can improve it to
$\mathcal{O}(d\epsilon^{-1})$. Furthermore, we develop a variant of ZOCEG,
which applies block coordinate updates to enhance the efficiency of single-step
gradient estimation. Finally, numerical experiments on a load tracking problem
validate our theoretical results and the effectiveness of the proposed
algorithms.

</details>


### [16] [First-order methods for stochastic and finite-sum convex optimization with deterministic constraints](https://arxiv.org/abs/2506.20630)
*Zhaosong Lu,Yifeng Xiao*

Main category: math.OC

TL;DR: 本文提出了一种新的随机一阶方法，用于求解具有确定性约束的随机凸优化问题，确保解在确定性约束下几乎必然可行，且期望最优性差距在允许范围内。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常寻找期望可行的随机最优解，但在实际应用中，约束必须几乎必然满足，因此需要一种确保确定性约束不显著违反的解决方案。

Method: 提出了两种随机一阶方法：加速随机梯度（ASG）方案和修正的方差缩减ASG方案，通过一次应用于适当选择的二次惩罚子问题序列，确保解的确定性可行性和期望最优性。

Result: 建立了计算$\epsilon$-SFSO解的一阶预言复杂度界限，并作为副产品，推导了样本平均逼近方法在求解随机优化问题时的复杂度结果。

Conclusion: 所提出的方法不仅解决了确定性约束下的随机优化问题，还为样本平均逼近方法提供了有效的求解工具，具有实际应用价值。

Abstract: In this paper, we study a class of stochastic and finite-sum convex
optimization problems with deterministic constraints. Existing methods
typically aim to find an $\epsilon$-$expectedly\ feasible\ stochastic\ optimal$
solution, in which the expected constraint violation and expected optimality
gap are both within a prescribed tolerance $\epsilon$. However, in many
practical applications, constraints must be nearly satisfied with certainty,
rendering such solutions potentially unsuitable due to the risk of substantial
violations. To address this issue, we propose stochastic first-order methods
for finding an $\epsilon$-$surely\ feasible\ stochastic\ optimal$
($\epsilon$-SFSO) solution, where the constraint violation is deterministically
bounded by $\epsilon$ and the expected optimality gap is at most $\epsilon$.
Our methods apply an accelerated stochastic gradient (ASG) scheme or a modified
variance-reduced ASG scheme $only\ once$ to a sequence of quadratic penalty
subproblems with appropriately chosen penalty parameters. We establish
first-order oracle complexity bounds for the proposed methods in computing an
$\epsilon$-SFSO solution. As a byproduct, we also derive first-order oracle
complexity results for sample average approximation method in computing an
$\epsilon$-SFSO solution of the stochastic optimization problem using our
proposed methods to solve the sample average problem.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [17] [11 can be reduced to 10](https://arxiv.org/abs/2506.19868)
*Abraham Berman,Eliyahu Levy*

Main category: math.NT

TL;DR: Laffey和Smigoc证明所有2x2双非负整数矩阵A的icpr(A)≤11，本文将其改进为≤10，并对许多小矩阵进一步降至9.15。


<details>
  <summary>Details</summary>
Motivation: 研究2x2双非负整数矩阵的icpr上界优化问题，改进现有理论结果。

Method: 通过数学证明与数值分析相结合的方法，对矩阵性质进行深入探讨。

Result: 成功将icpr(A)的上界从11降至10，并证明对小矩阵可达9.15。

Conclusion: 该研究显著改进了2x2双非负整数矩阵的icpr上界，为相关领域提供了更精确的理论工具。

Abstract: Laffey and Smigoc proved that for every 2x2 doubly nonnegative integer matrix
A, icpr(A) is less than or equal to 11. We prove that 11 can be replaced by 10,
and show that for many small matrices, even by 9.15

</details>


### [18] [The Graph Structure of a Class of Permutation Maps over Ring $\mathbb{Z}_{p^k}$](https://arxiv.org/abs/2506.20118)
*Kai Tan,Chengqing Li*

Main category: math.NT

TL;DR: 该研究提出了一个统一的分析框架，用于系统地推导$\mathbb{Z}_{p^k}$上一类置换映射的周期长度分布，结合生成函数、极小多项式和提升理论，揭示了循环结构的演化规律，并以Cat映射为例验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管在刻画全局周期方面取得了进展，但缺乏分析局部循环结构及其随算术精度增加的演化工具，这成为代数动力学和伪随机序列分析中的一个关键瓶颈。

Method: 结合生成函数、极小多项式和提升理论的技术，提出统一的分析框架，追踪模数$p^k$变化时循环结构的适应性变化。

Result: 以Cat映射为例，揭示了其循环形成和过渡的精确模式，为实验观察到的固定点实现中的规律性提供了严格解释。

Conclusion: 该分析不仅为评估其他非线性映射生成的伪随机数序列的随机性和动态行为奠定了理论基础，还对安全系统设计、计算数论和符号动力学具有广泛意义。

Abstract: Understanding the periodic and structural properties of permutation maps over
residue rings such as $\mathbb{Z}_{p^k}$ is a foundational challenge in
algebraic dynamics and pseudorandom sequence analysis. Despite notable progress
in characterizing global periods, a critical bottleneck remains: the lack of
explicit tools to analyze local cycle structures and their evolution with
increasing arithmetic precision. In this work, we propose a unified analytical
framework to systematically derive the distribution of cycle lengths for a
class of permutation maps over $\mathbb{Z}_{p^k}$. The approach combines
techniques from generating functions, minimal polynomials, and lifting theory
to track how the cycle structure adapts as the modulus $p^k$ changes. To
validate the generality and effectiveness of our method, we apply it to the
well-known Cat map as a canonical example, revealing the exact patterns
governing its cycle formation and transition. This analysis not only provides
rigorous explanations for experimentally observed regularities in fixed-point
implementations of such maps but also lays a theoretical foundation for
evaluating the randomness and dynamical behavior of pseudorandom number
sequences generated by other nonlinear maps. The results have broad
implications for secure system design, computational number theory, and
symbolic dynamics.

</details>


### [19] [Values at non-positive integers of partially twisted multiple zeta-functions II](https://arxiv.org/abs/2506.20150)
*Driss Essouabri,Kohji Matsumoto,Simon Rutard*

Main category: math.NT

TL;DR: 本文研究了多变量扭曲多重zeta函数在非正整数点的取值问题，特别是分母为一般多项式的情况，通过多重Mellin-Barnes积分公式将问题转化为完全扭曲情形，并发现某些情况下所得到的值是超越数。


<details>
  <summary>Details</summary>
Motivation: 研究多变量扭曲多重zeta函数在非正整数点的取值，特别是分母为一般多项式的情况，以扩展对这类函数性质的理解。

Method: 通过多重Mellin-Barnes积分公式，将部分扭曲情形转化为完全扭曲情形，利用de Crisenoy的定理进行求解。

Result: 获得了分母为一般多项式的多变量扭曲多重zeta函数在非正整数点的显式表达式，并发现某些情况下这些值是超越数。

Conclusion: 本文成功地将部分扭曲情形的多变量扭曲多重zeta函数的非正整数点取值问题转化为完全扭曲情形，并揭示了某些情况下取值的超越性质。

Abstract: We study the values at non-positive integer points of multi-variable twisted
multiple zeta-functions, whose each factor of the denominator is given by
polynomials. The fully twisted case was already answered by de Crisenoy. On the
partially twisted case, in one of our former article we studied the case when
each factor of the denominator is given by linear forms or power-sum forms. In
the present paper we treat the case of general polynomial denominators, and
obtain explicit forms of the values at non-positive integer points. Our
strategy is to reduce to the theorem of de Crisenoy for the fully twisted case,
via the multiple Mellin-Barnes integral formula. We observe that in some cases
the obtained values are transcendental.

</details>


### [20] [On the Minimality of the Conductor in Rank Bounds for Elliptic Curves](https://arxiv.org/abs/2506.20175)
*K. Lakshmanan*

Main category: math.NT

TL;DR: 本文证明了椭圆曲线的算术不变量中，没有比其导子更小的量能在二阶L函数的解析延拓函数方程中出现。任何尝试用更小的不变量替代导子来定义修正L函数都会与模性定理矛盾。由此得出经典秩上界$\log N_E$在解析意义下是最优的，且若子导子不变量控制无界椭圆曲线族的秩，则秩必须无界。


<details>
  <summary>Details</summary>
Motivation: 研究椭圆曲线L函数解析性质与算术不变量之间的关系，特别是探讨是否存在比导子更小的不变量能控制L函数的解析行为，从而优化经典的秩上界。

Method: 通过分析椭圆曲线L函数的函数方程结构，结合模性定理的刚性约束，采用反证法证明不存在严格小于导子的算术不变量满足函数方程要求。

Result: 1) 导子是L函数函数方程中最小可能的算术不变量；2) 经典秩上界$\operatorname{rank}(E) \ll \log N_E$无法通过替换更小的量来改进；3) 若子导子控制无界曲线族的秩，则秩必然无界。

Conclusion: 该研究确立了导子在椭圆曲线L函数理论中的极小性地位，揭示了秩上界的最优性，并将结果与秩分布的核心未解决问题联系起来，为后续研究提供了严格的理论边界。

Abstract: We show that no arithmetic invariant strictly smaller than the conductor of
an elliptic curve over \( \mathbb{Q} \) can appear in a functional equation
governing the analytic continuation of an associated \( L \)-function of degree
two. In particular, any attempt to define a modified \( L \)-function for an
elliptic curve with a smaller invariant in place of the conductor leads to a
contradiction with the Modularity Theorem. As a consequence, the classical
upper bound \( \operatorname{rank}(E) \ll \log N_E \) is analytically optimal:
no refinement replacing the conductor \( N_E \) with a smaller arithmetic
quantity is possible. We further derive a conditional corollary: if a
sub-conductor invariant were to govern the rank in an unbounded family of
elliptic curves, the ranks must be unbounded - placing our results in
connection with deep open questions concerning the distribution of ranks over
\( \mathbb{Q} \).

</details>


### [21] [On the Sierpinski triangle and its generalizations](https://arxiv.org/abs/2506.20456)
*L. De Carli,A. Echezabal,I. Morell*

Main category: math.NT

TL;DR: 通过研究m进制下十进制数间的算术运算，发现了可推广谢尔宾斯基三角形的分形结构。


<details>
  <summary>Details</summary>
Motivation: 探索不同进制下算术运算中隐藏的几何模式，扩展分形几何的理论框架。

Method: 分析m进制系统中十进制数之间的加减乘除运算，观察其生成的数字模式。

Result: 发现了具有自相似特性的分形结构，这些结构是谢尔宾斯基三角形的高维推广。

Conclusion: 算术运算在不同数制下会产生复杂的分形模式，这为分形几何提供了新的研究方向。

Abstract: By examining arithmetic operations between decimal numbers in a given base m
we uncover fractal structures that generalize the Sierpinski triangle

</details>


### [22] [Wild Galois representations: elliptic curves with wild cyclic reduction](https://arxiv.org/abs/2506.20562)
*Nirvana Coppola*

Main category: math.NT

TL;DR: 本文完成了剩余所有野性情况（即剩余特征为$p=2$或$3$时）下椭圆曲线$\ell$-adic Galois表示的计算，扩展了Kraus 1990年的分类工作。


<details>
  <summary>Details</summary>
Motivation: Kraus在1990年分类了非阿基米德局部域上椭圆曲线的$\ell$-adic Galois表示的所有可能惯性像。此前作者已计算了具有非阿贝尔惯性像的椭圆曲线的Galois表示，但剩余野性情况尚未完全解决。

Method: 基于作者博士论文第五章的方法，本文重点处理剩余特征$p=2$或$3$时，椭圆曲线在可分度被$p$整除的扩张上获得良好约化的Galois表示计算问题。

Result: 完整计算了剩余特征为$p=2$或$3$时，椭圆曲线在野性扩张（不要求惯性像非阿贝尔）下的Galois表示，填补了此前工作的空白。

Conclusion: 该研究完善了局部域上椭圆曲线Galois表示的理论框架，特别解决了$p=2,3$的野性情况，为后续相关数论问题提供了工具。

Abstract: In 1990, Kraus classified all possible inertia images of the $\ell$-adic
Galois representation attached to an elliptic curve over a non-archimedean
local field. In previous work, the author computed explicitly the Galois
representation of elliptic curves having non-abelian inertia image, a
phenomenon which only occurs when the residue characteristic of the field of
definition is $2$ or $3$ and the curve attains good reduction over some
non-abelian ramified extension. In this work, the computation of the Galois
representation in all the remaining wild cases, i.e. when the residue
characteristic is $p=2$ or $3$ and the curve attains good reduction over an
extension whose ramification degree is divisible by $p$ (without assuming the
condition on the image of inertia being non-abelian), is completed. This is
based on Chapter V of the author's PhD thesis.

</details>


### [23] [On the Moments of Exponential Sums over r-Free Polynomials](https://arxiv.org/abs/2506.20581)
*Ben Doyle*

Main category: math.NT

TL;DR: 本文研究了有限域$\mathbb{F}_q[t]$上$r$-自由多项式的指数和的$k$阶矩的精确量级，并在超临界情况$k>1+1/r$下，利用函数域版本的Hardy-Littlewood圆法得到了渐近公式。


<details>
  <summary>Details</summary>
Motivation: 研究有限域$\mathbb{F}_q[t]$上$r$-自由多项式的指数和的矩问题，扩展了Balog、Ruzsa和Keil在整数情况下的技术，旨在确定其精确量级。

Method: 采用了函数域版本的Hardy-Littlewood圆法，结合Balog、Ruzsa和Keil在整数情况下的技术，对$k$阶矩进行分析。

Result: 对于所有$k>0$，确定了$r$-自由多项式指数和的$k$阶矩的精确量级；在超临界情况$k>1+1/r$下，得到了渐近公式。

Conclusion: 本文成功地将整数情况下的技术推广到函数域，为有限域上$r$-自由多项式的指数和矩问题提供了完整的解决方案。

Abstract: Let $\mathbb{F}_q[t]$ denote the ring of polynomials over the finite field
$\mathbb{F}_q$. Building off of techniques of Balog and Ruzsa and of Keil in
the integer setting, we determine the precise order of magnitude of $k$th
moments of exponential sums over $r$-free polynomials in $\mathbb{F}_q[t]$ for
all $k>0$. In the supercritical case $k>1+1/r$, we acquire an asymptotic
formula using a function field analogue of the Hardy-Littlewood circle method.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [24] [La logique continue des corps globalement valués](https://arxiv.org/abs/2506.20120)
*Antoine Chambert-Loir*

Main category: math.LO

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: The continuous logic of globally valued fields -- A globally valued field is
a field endowed with a family of absolute values that satisfy a product
formula. Number fields and function fields in one variable give classical and
fundamental examples; Nevanlinna theory also gives rise to such structures on
the field of meromorphic functions on $\mathbf C$. These globally valued fields
can be studied in the context of continuous logic (for which the predicates are
real valued), and such a study has been undertaken some 10 years ago by Ben
Yaacov and Hrushovski, thus providing a model-theoretic framework for the
diophantine theory of heights. One of the first fundamental results in the
tehory states the the field of algebraic numbers, with its essentially unique
structure of a globally valued field, is existentially closed: every system
involving polynomial equalities and inequalities, as well as strict
inequalities in heights, possesses a solution in algebraic numbers as soon as
it possesses some solution in a globally valued extension. The proof, due to
Szachniewicz, is inspired by the proof proposed by Ben Yaacov and Hrushovski in
the case of function fields: the latter used in a crucial way the description
by Boucksom, Demailly, P\u aun and Peternell of the cone of mobile curves in a
complex projective variety, the case of number fields relies on recent results
in Arakelov geometry.

</details>


### [25] [Iterated jump noncomputability and compactness](https://arxiv.org/abs/2506.20620)
*Gavin Dooley*

Main category: math.LO

TL;DR: 使用逆向数学分析四种原则的'迭代跳跃'版本，揭示了它们之间的逻辑关系，包括无限链和无限反链，展示了自然组合原则在可证明性强度上的非线性特征。


<details>
  <summary>Details</summary>
Motivation: 研究'迭代跳跃'版本的组合原则（AST、DNR、WWKL、WKL），以理解它们在逆向数学框架下的逻辑关系和结构复杂性。

Method: 采用逆向数学方法，分析四种原则的'迭代跳跃'版本，并通过逻辑关系图（图1）总结它们的相互依赖性。

Result: 发现了无限链和无限反链的存在，后者特别展示了自然组合原则在可证明性强度上的强非线性特征。

Conclusion: 研究揭示了'迭代跳跃'版本组合原则之间的复杂逻辑结构，为逆向数学中的非线性现象提供了新的例证。

Abstract: We use reverse mathematics to analyze "iterated jump" versions of the
following four principles: the atomic model theorem with subenumerable types
(AST), the diagonally noncomputable principle (DNR), weak weak K\H{o}nig's
lemma (WWKL), and weak K\H{o}nig's lemma (WKL). The logical relationships
between these principles are summarized in Figure 1 and include, among other
things, an infinite chain and an infinite antichain, the latter of which
represents a strong form of non-linearity in terms of provability strength
among "natural" combinatorial principles.

</details>


<div id='math.HO'></div>

# math.HO [[Back]](#toc)

### [26] [Finding the Cores of Higher Graphs Using Geometric and Topological Means: A Survey](https://arxiv.org/abs/2506.19857)
*Inés García-Redondo,Claudia Landi,Sarah Percival,Anda Skeja,Bei Wang,Ling Zhou*

Main category: math.HO

TL;DR: 本文综述了利用几何与拓扑方法寻找高阶图核心的最新研究，涵盖图、超图和单纯复形等模型，重点探讨了基于离散曲率、有效电阻和持续同调的核心提取技术。


<details>
  <summary>Details</summary>
Motivation: 高阶图的核心提取能保留其几何或拓扑信息的最小表示，有助于简化复杂结构并促进图论、离散几何与计算拓扑的跨学科研究。

Method: 采用离散曲率、有效电阻和持续同调等几何拓扑工具，对图、超图及单纯复形进行核心特征分析。

Result: 建立了高阶图核心提取的统一框架，验证了几何拓扑方法在简化复杂结构中的有效性。

Conclusion: 该研究为高阶图简化提供了新思路，推动了图论与拓扑方法的交叉融合，具有潜在的理论与应用价值。

Abstract: In this survey, we explore recent literature on finding the cores of higher
graphs using geometric and topological means. We study graphs, hypergraphs, and
simplicial complexes, all of which are models of higher graphs. We study the
notion of a core, which is a minimalist representation of a higher graph that
retains its geometric or topological information. We focus on geometric and
topological methods based on discrete curvatures, effective resistance, and
persistent homology. We aim to connect tools from graph theory, discrete
geometry, and computational topology to inspire new research on the
simplification of higher graphs.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [27] [Hamilton Cycles In Vertex-Transitive Graphs of Order 10p](https://arxiv.org/abs/2506.19888)
*Huye Chen,Jingjian Li,Hao Yu*

Main category: math.CO

TL;DR: 本文证明了除Petersen图的截断外，所有阶数为$10p$（$p$为素数）的连通顶点传递图都包含哈密顿圈。


<details>
  <summary>Details</summary>
Motivation: 继阶数为$pq$（$p$和$q$为素数）的连通顶点传递图的哈密顿问题在2021年解决后，数学家们开始挑战阶数为$2pq$的图。本文进一步研究阶数为$10p$的图。

Method: 基于前人关于阶数为$10p$（$p\neq7$为素数）的连通顶点传递图包含哈密顿路径的研究，本文通过理论证明扩展了这一结论。

Result: 证明了除Petersen图的截断外，所有阶数为$10p$（$p$为素数）的连通顶点传递图都包含哈密顿圈。

Conclusion: 本文完善了阶数为$10p$的连通顶点传递图的哈密顿性问题，为相关图论研究提供了重要结论。

Abstract: After a long term efforts, the Hamiltonian problem of connected
vertex-transitive graphs of order $pq$ (where $p$ and $q$ are primes) was
finally finshed in 2021, see [10]. Fifteen years ago, mathematicians began to
challenge this problem for graphs of order $2pq$. Among of them, it was proved
in 2012 (see [21]) that every connected vertex-transitive graph of order $10p$
(where $p\neq7$ is a prime) contains a Hamilton path, with the exception of a
family of graphs which was recently confirmed in [11]. In this paper, a further
conclusion will be achieved: every connected vertex-transitive graph of order
$10p$ (where $p$ is a prime) contains a Hamilton cycle, except for the
truncation of the Petersen graph.

</details>


### [28] [New upper bounds on the order of mixed cages of girth 6](https://arxiv.org/abs/2506.20003)
*Gabriela Araujo-Pardo,Lydia Mirabel Mendoza-Cadena*

Main category: math.CO

TL;DR: 本文提出了一种新的混合图无限族，其围长为6，在某些情况下改进了现有结果。特别地，对于偶数素数幂q，构造的图族满足$n[\frac{q}{4},q;6]\leq 4q^2-4$；对于奇数素数幂q，根据条件不同，分别满足$n[\frac{q-1}{4},q;6]\leq 4q^2-4$或$n[\frac{q-3}{4},q;6]\leq 4q^2-4$。


<details>
  <summary>Details</summary>
Motivation: 研究混合笼图的最小阶数问题，特别是围长为6的情况，旨在改进现有结果并扩展混合图族的构造方法。

Method: 通过构造无限族的混合图，利用素数幂的性质，对不同情况的q进行分类讨论，并给出相应的阶数上界。

Result: 对于偶数素数幂q，证明了$n[\frac{q}{4},q;6]\leq 4q^2-4$；对于奇数素数幂q，根据$\frac{q-3}{2}$的奇偶性，分别证明了$n[\frac{q-1}{4},q;6]\leq 4q^2-4$或$n[\frac{q-3}{4},q;6]\leq 4q^2-4$。

Conclusion: 本文提出的混合图族在某些情况下改进了现有结果，为混合笼图的研究提供了新的构造方法和理论支持。

Abstract: A $[z,r;g]$-mixed cage is a mixed graph of minimum order such that each
vertex has $z$ in-arcs, $z$ out-arcs, $r$ edges, and it has girth $g$, and the
minimum order for $[z,r;g]$-mixed graphs is denoted by $n[z,r;g]$. In this
paper, we present an infinite family of mixed graphs with girth $6$, that
improves, in some cases, the families that we give in G. Araujo-Pardo and L.
Mendoza-Cadena. \textit{On Mixed Cages of girth 6}, arXiv:2401.14768v2. In
particular, if $q$ is an even prime power we construct a family of graphs that
satisfies $n[\frac{q}{4},q;6]\leq 4q^2-4$, and if $q$ is an odd prime power,
and $\frac{q-3}{2}$ is odd then our family satisfies that
$n[\frac{q-1}{4},q;6]\leq 4q^2-4$, otherwise $n[\frac{q-3}{4},q;6]\leq 4q^2-4$.

</details>


### [29] [Cluster structures in mixed Grassmanianns](https://arxiv.org/abs/2506.20038)
*Zenan Fu*

Main category: math.CO

TL;DR: 本文推广了Fomin-Pylyavskyy和Carde的结果，构建了混合格拉斯曼量坐标环中的一族自然簇结构，并利用Casals和Zaslow引入的编织工具进行描述和探索。


<details>
  <summary>Details</summary>
Motivation: 研究混合格拉斯曼量（包含向量和余向量的多元组构型空间）的坐标环中的簇结构，以推广前人工作并深化对该空间代数结构的理解。

Method: 通过编织（weaves）这一由Casals和Zaslow提出的工具，系统地构造和分析混合格拉斯曼量中的簇结构。

Result: 成功构建了一族自然的簇结构，并详细描述了这些结构在混合格拉斯曼量坐标环中的表现和性质。

Conclusion: 该研究不仅推广了现有理论，还为混合格拉斯曼量的簇代数结构提供了新的研究框架和工具。

Abstract: Generalizing the results by Fomin-Pylyavskyy and Carde, we construct a family
of natural cluster structures in the coordinate ring of a mixed Grassmannian,
the configuration space of tuples of several vectors and covectors in a
finite-dimensional complex vector space. We describe and explore these cluster
structures using the machinery of weaves introduced by Casals and Zaslow.

</details>


### [30] [The number of possibilities for random dating](https://arxiv.org/abs/2506.20072)
*Aaron Abrams,Rod Canfield,Andrew Granville*

Main category: math.CO

TL;DR: 本文提出了在正则图$G$及其同顶点子图$H$中，随机子图内$H$出现次数的简洁计算公式。


<details>
  <summary>Details</summary>
Motivation: 研究正则图与其子图之间的统计关系，为图论中的随机子图计数问题提供理论工具。

Method: 通过建立正则图$G$与子图$H$的数学关系，推导随机子图内$H$出现次数的概率公式。

Result: 获得了形式异常简洁的$H$出现次数期望值计算公式，适用于任意正则图结构。

Conclusion: 该公式为分析正则图随机子图模式提供了高效的计算框架，具有广泛的理论应用价值。

Abstract: Let $G$ be a regular graph and $H$ a subgraph on the same vertex set. We give
surprisingly compact formulas for the number of copies of $H$ one expects to
find in a random subgraph of $G$.

</details>


### [31] [Minors of non-hamiltonian polyhedra and the Herschel family](https://arxiv.org/abs/2506.20086)
*On-Hei Solomon Lo,Kenta Ozeki*

Main category: math.CO

TL;DR: 证明所有非哈密顿多面体都包含Herschel图作为子图，并解决了关于不含$K_{2,6}$子图的非哈密顿多面体的猜想。


<details>
  <summary>Details</summary>
Motivation: 解决Ellingham等人提出的关于非哈密顿多面体的猜想，特别是针对不含$K_{2,6}$子图的情况。

Method: 通过分析非哈密顿多面体的图论性质，证明其必然包含Herschel图作为子图。

Result: 所有非哈密顿多面体都包含Herschel图作为子图，并完全刻画了不含$K_{2,6}$子图的非哈密顿多面体。

Conclusion: 该研究不仅验证了猜想，还为非哈密顿多面体的结构提供了更深入的理解。

Abstract: We show that every non-hamiltonian polyhedron contains the Herschel graph as
a minor. As an application, we provide a characterization of non-hamiltonian
polyhedra without $K_{2,6}$ minors, thereby resolving a conjecture by
Ellingham, Marshall, Ozeki, Royle, and Tsuchiya.

</details>


### [32] [On minors of non-hamiltonian graphs](https://arxiv.org/abs/2506.20087)
*On-Hei Solomon Lo*

Main category: math.CO

TL;DR: 论文强化了Tutte定理，证明了4连通非哈密尔顿图必须包含$K_{3,4}$作为子图，并验证了Ding和Marshall关于3连通非哈密尔顿图的猜想。


<details>
  <summary>Details</summary>
Motivation: 研究旨在进一步刻画4连通非哈密尔顿图的极小子图结构，并验证相关猜想以推动图论领域的发展。

Method: 通过理论证明和数学推导，强化了Tutte定理，并验证了Ding和Marshall的猜想。

Result: 证明了4连通非哈密尔顿图必须包含$K_{3,4}$作为子图，并确认了3连通非哈密尔顿图包含$K_{3,4}$、$\mathfrak{Q}^+$或Herschel图作为子图的猜想。

Conclusion: 该结果为刻画极小4连通非哈密尔顿图提供了重要进展，并验证了3连通情况下的猜想，对图论研究具有深远意义。

Abstract: A theorem of Tutte states that every 4-connected non-hamiltonian graph
contains $K_{3,3}$ as a minor. We strengthen this result by proving that such a
graph must contain $K_{3,4}$ as a minor, thereby confirming a special case of a
conjecture posed by Chen, Yu, and Zang in a strong form. This result may be
viewed as a step toward characterizing the minor-minimal 4-connected
non-hamiltonian graphs. As a 3-connected analog, Ding and Marshall conjectured
that every 3-connected non-hamiltonian graph has a minor of $K_{3,4}$,
$\mathfrak{Q}^+$, or the Herschel graph, where $\mathfrak{Q}^+$ is obtained
from the cube by adding a new vertex adjacent to three independent vertices. We
confirm this conjecture.

</details>


### [33] [A generalization of Deodhar's defect statistic for Iwahori--Hecke algebras of type $BC$](https://arxiv.org/abs/2506.20099)
*Gavin Hobbs,Tommy Parisi,Mark Skandera,Jiayuan Wang*

Main category: math.CO

TL;DR: 本文扩展了Deodhar的缺陷统计方法，为类型$BC$的Kazhdan--Lusztig基元素乘积在自然基中的展开提供了组合描述。


<details>
  <summary>Details</summary>
Motivation: Deodhar的缺陷统计方法已成功应用于Iwahori--Hecke代数中简单Kazhdan--Lusztig基元素乘积的展开，但在类型$A$之外的扩展尚未充分研究。本文旨在填补这一空白。

Method: 借鉴Clearwater等人在类型$A$中的工作，作者将Deodhar的方法推广到类型$BC$，特别关注同时在类型$B$和$C$中光滑的超八面体群元素。

Result: 成功推导出类型$BC$中Kazhdan--Lusztig基元素乘积在自然基中的组合展开公式，扩展了Deodhar的原始结果。

Conclusion: 该研究不仅完善了类型$BC$的Kazhdan--Lusztig理论，还为相关组合结构提供了新的计算工具。

Abstract: Let $H$ be the Iwahori--Hecke algebra corresponding to any Coxeter group.
Deodhar's defect statistic [Geom. Dedicata 36, (1990) pp.95--119] allows one to
expand products of simple Kazhdan--Lusztig basis elements of $H$ in the natural
basis of $H$. Clearwater and the third author gave a type-$A$ extension [Ann.
Comb. 25, no. 3 (2021) pp.757--787] of this formula which combinatorially
describes the natural expansion of products of Kazhdan--Lusztig basis elements
indexed by smooth elements of the symmetric group. We similarly give a
type-$BC$ extension of Deodhar's result which combinatorially describes the
natural expansion of Kazhdan--Lusztig basis elements indexed by hyperoctahedral
group elements which are simultaneously smooth in types $B$ and $C$.

</details>


### [34] [On the homogeneity problem of the Kazhdan-Lusztig ideals](https://arxiv.org/abs/2506.20153)
*Adhip Ganguly,Shyamashree Upadhyay*

Main category: math.CO

TL;DR: 本文研究了Kazhdan-Lusztig理想的不齐次性充分条件，并探讨了其标准齐次性的充要条件。


<details>
  <summary>Details</summary>
Motivation: 旨在为Kazhdan-Lusztig理想的不齐次性提供理论支持，并探索其标准齐次性的判定条件。

Method: 通过数学推导和条件分析，识别不齐次性的充分条件，并尝试构建标准齐次性的充要条件框架。

Result: 确定了Kazhdan-Lusztig理想不齐次性的若干充分条件，为标准齐次性问题的研究奠定了基础。

Conclusion: 该研究推进了对Kazhdan-Lusztig理想齐次性问题的理解，为后续相关理论工作提供了重要参考。

Abstract: In this paper, we identify some sufficient conditions for a Kazhdan-Lusztig
ideal to be inhomogeneous. Also, we attempt to approach the problem of giving
some necessary and sufficient conditions for a Kazhdan-Lusztig ideal to be
"standard homogeneous".

</details>


### [35] [Adjacency spectral radius and H-factors in 1-binding graphs](https://arxiv.org/abs/2506.20273)
*Sizhong Zhou,Tao Zhang,Zhiren Sun*

Main category: math.CO

TL;DR: 本文通过Lu和Kano的H-因子存在性定理，为1-绑定图提出了一个基于邻接谱半径的充分条件，确保在满足特定条件下存在H-因子。


<details>
  <summary>Details</summary>
Motivation: 研究图的H-因子存在性问题，特别是通过邻接谱半径这一图论工具，为1-绑定图提供一个新的判定条件。

Method: 利用Lu和Kano的H-因子存在性定理，结合图的邻接矩阵和邻接谱半径$\rho(G)$，分析1-绑定图的结构特性。

Result: 证明当连通1-绑定图$G$的阶数$n\geq11$且$\rho(G)\geq\rho(K_1\vee(K_{n-4}\cup K_2\cup K_1))$时，除非$G$为特定图结构，否则对任意满足$H^{-1}(1)$为偶数的集合函数$H$，$G$都存在H-因子。

Conclusion: 通过邻接谱半径这一工具，为1-绑定图的H-因子存在性提供了一个有效的充分条件，扩展了相关图因子的理论结果。

Abstract: Let $G$ be a graph, and let $H:V(G)\longrightarrow\{\{1\},\{0,2\}\}$ be a
set-valued function. Hence, $H(v)$ equals $\{1\}$ or $\{0,2\}$ for any $v\in
V(G)$. We let $$ H^{-1}(1)=\{v: v\in V(G) \ \mbox{and} \ H(v)=1\}. $$ An
$H$-factor of $G$ is a spanning subgraph $F$ of $G$ such that $d_F(v)\in H(v)$
for each $v\in V(G)$. Lu and Kano showed a characterization for the existence
of an $H$-factor in a graph [Characterization of 1-tough graphs using factors,
Discrete Math. 343 (2020) 111901]. Let $A(G)$ and $\rho(G)$ denote the
adjacency matrix and the adjacency spectral radius of $G$, respectively. By
using Lu and Kano's result, we pose a sufficient condition with respect to the
adjacency spectral radius to guarantee the existence of an $H$-factor in a
1-binding graph. In this paper, we prove that if a connected 1-binding graph
$G$ of order $n\geq11$ satisfies $\rho(G)\geq\rho(K_1\vee(K_{n-4}\cup K_2\cup
K_1))$, then $G$ has an $H$-factor for each
$H:V(G)\longrightarrow\{\{1\},\{0,2\}\}$ with $H^{-1}(1)$ even, unless
$G=K_1\vee(K_{n-4}\cup K_2\cup K_1)$.

</details>


### [36] [On Base, Normal and Near-normal Sequences](https://arxiv.org/abs/2506.20296)
*Xu Wang,Jiayi Zhu*

Main category: math.CO

TL;DR: 该论文研究了基序列BS(n+1,n)的存在性，验证了基序列猜想在n=41,42,43时成立，并首次发现了Yang猜想的反例n=42和44。同时，证明了对于n=8k-2（k为正整数）不存在正规序列NS(n)。


<details>
  <summary>Details</summary>
Motivation: 研究基序列BS(n+1,n)的存在性及其子类（正规序列NS(n)和近正规序列NNS(n)）的性质，验证相关猜想并探索其适用范围。

Method: 通过算法构造BS(n+1,n)序列，并对NS(n)和NNS(n)进行穷举搜索，验证其存在性。

Result: 成功构造了n=41,42,43的BS(n+1,n)序列，发现n=42和44不存在NNS(n)，并证明n=41,42,43,44,45不存在NS(n)，且对于n=8k-2（k为正整数）不存在NS(n)。

Conclusion: 基序列猜想在n≤43时成立，但Yang猜想在n=42和44时不成立。此外，正规序列NS(n)在特定条件下不存在，为相关理论研究提供了新的反例和限制条件。

Abstract: The base sequences BS(n+1,n) are four sequences of $\pm1$ and lengths
n+1,n+1,n,n with zero auto correlation. The base sequence conjecture states
that BS(n+1,n) exists for all integers $n>0$ and has been verified for
$n\le40$. We present our algorithm and gives construction of BS(n+1,n) for
$n=41,42,43$.
  The Normal sequences NS (n) and the Near-normal sequences NNS (n) are
subclasses of BS(n+1,n). Yang conjecture asserts that there is a NNS(n) for
each even integer n and has been verified for $n\le40$. We found that there is
no NNS(n) for n=42 and 44 by exhaustive search, which gives the first counter
case of Yang conjecture. We also show that there is no NS(n) for
n=41,42,43,44,45 by exhaustive search and proves that no NS(n) exist for
$n=8k-2,k \in Z_+$.

</details>


### [37] [Conformal Rigidity and Spectral Embeddings of Graphs](https://arxiv.org/abs/2506.20541)
*João Gouveia,Stefan Steinerberger,Rekha R. Thomas*

Main category: math.CO

TL;DR: 研究了共形刚性图的结构，证明了所有1-行走正则图都具有共形刚性，并利用对称性给出了顶点传递图共形刚性的充要条件。


<details>
  <summary>Details</summary>
Motivation: 探索共形刚性图的结构特性，特别是通过图拉普拉斯算子的特征值变化来定义刚性，并扩展已知的刚性图类别。

Method: 利用边等距谱嵌入与共形刚性的联系，结合图的对称性分析，并应用半定规划技术。

Result: 证明了1-行走正则图具有共形刚性，给出了阿贝尔群上凯莱图刚性的充要条件，并展示了一类无限共形刚性循环图族。

Conclusion: 现有理论尚未完全解释某些显式共形刚性图的性质，对称性分析和半定规划为刚性判定提供了新工具。

Abstract: We investigate the structure of conformally rigid graphs. Graphs are
conformally rigid if introducing edge weights cannot increase (decrease) the
second (last) eigenvalue of the Graph Laplacian. Edge-transitive graphs and
distance-regular graphs are known to be conformally rigid. We establish new
results using the connection between conformal rigidity and edge-isometric
spectral embeddings of the graph. All $1$-walk regular graphs are conformally
rigid, a consequence of a stronger property of their embeddings. Using
symmetries of the graph, we establish two related characterizations of when a
vertex-transitive graph is conformally rigid. This provides a necessary and
sufficient condition for a Cayley graph on an abelian group to be conformally
rigid. As an application we exhibit an infinite family of conformally rigid
circulants. Our symmetry technique can be interpreted in the language of
semidefinite programming which provides another criterion for conformal
rigidity in terms of edge orbits. The paper also describes a number of explicit
conformally rigid graphs whose conformal rigidity is not yet explained by the
existing theory.

</details>


### [38] [Enumeration of subsets with closedness in finite fields of characteristic 2](https://arxiv.org/abs/2506.20351)
*Nithish Kumar R,Vadiraja Bhatta G. R.,Prasanna Poojary*

Main category: math.CO

TL;DR: 本文研究了加法群子集中的加法封闭性（称为r值），在特征为2的有限域中枚举子集的r值并表示为值谱，进而分析其作为部分Steiner三元系、无和集、Sidon集及Schure三元组的性质。


<details>
  <summary>Details</summary>
Motivation: 探索加法群子集中不同大小子集的封闭性特征，通过r值谱揭示其内在结构特性，为组合数学中的特殊集合类型研究提供新视角。

Method: 在特征为2的有限域中系统枚举子集的r值，将封闭性量化为离散值谱，并关联至部分Steiner三元系等组合结构进行分析。

Result: 成功建立了有限域子集r值的计算框架，验证了r值谱与多种组合结构（如无和集、Sidon集）之间的对应关系。

Conclusion: r值谱为理解加法封闭性提供了统一工具，未来可扩展至其他域特征及更复杂的组合系统研究。

Abstract: The additive closedness in the subset of an additive group is termed as
r-value. The nature of closedness in different subsets of fixed size is
observed as a spectrum of r-values. We enumerate r-values of subsets in finite
fields of characteristic 2 and represent them as the spectrum of values. Based
on these values the subsets can be further studied as partial Steiner triple
systems, sum-free sets, Sidon sets, and Schure triples.

</details>


### [39] [On the Erdős-Ko-Rado problem of flags with type $\{1, n-3 \}$ of finite sets](https://arxiv.org/abs/2506.20556)
*Philipp Heering*

Main category: math.CO

TL;DR: 本文研究了有限集合上特定类型标志的最大非对立Erd\H{o}s-Ko-Rado集的大小，解决了Metsch提出的关于类型$\{1,n-3\}$标志的一个开放问题。


<details>
  <summary>Details</summary>
Motivation: Metsch在2022年提出了确定类型$T$且$|T|=2$的标志的最大非对立Erd\H{o}s-Ko-Rado集大小的问题，本文旨在为此问题做出贡献。

Method: 通过分析有限集合上类型为$\{1,n-3\}$的标志的性质，研究了非对立标志集的最大可能大小。

Result: 确定了具有$n$个元素的有限集合上类型为$\{1,n-3\}$的标志的最大非对立Erd\H{o}s-Ko-Rado集的大小，并回答了Metsch提出的一个小规模案例的开放问题。

Conclusion: 本研究为理解标志的非对立Erd\H{o}s-Ko-Rado集的最大规模提供了新的见解，特别是对于类型$\{1,n-3\}$的标志，解决了相关开放问题。

Abstract: A flag of a finite set $S$ is a set $f$ of non-empty, proper subsets of $S$,
such that $X\subseteq Y$ or $Y\subseteq X$ for all $X,Y\in f$. Two flags $f_1$
and $f_2$ of $S$ are opposite if $X_1\cap X_2=\emptyset$, or $X_1\cup X_2=S$
for all $X_1\in f_1$ and $X_2\in f_2$. The set $\{|X| \mid X\in f \}$ is the
type of a flag $f$. A set of pairwise non-opposite flags is an
Erd\H{o}s-Ko-Rado set. In 2022 Metsch posed the problem of determining the
maximum size of all Erd\H{o}s-Ko-Rado sets of flags of type $T$ with $|T|=2$.
We contribute towards this by determining the maximum size for flags of type
$\{ 1,n-3\}$ for finite sets with $n$ elements. Furthermore we answer an open
questions of Metsch regarding a small case.

</details>


### [40] [On likelihood of a Condorcet winner for uniformly random and independent voter preferences](https://arxiv.org/abs/2506.20613)
*Boris Pittel*

Main category: math.CO

TL;DR: 研究投票竞赛模型，证明当选民数$m$远大于候选人数$n$的四次方时，存在Condorcet赢家的概率趋近于1。


<details>
  <summary>Details</summary>
Motivation: 探讨在选民偏好随机且独立的情况下，Condorcet赢家出现的概率，扩展了Robert May和Lisa Sauermann关于固定选民数$m$的研究。

Method: 使用数学建模分析投票竞赛，假设选民偏好服从"公正文化"（impartial culture）分布，即每个选民独立且均匀随机地从所有$n!$种偏好中选择。

Result: 当选民数$m$无限增长且$m\gg n^4$时，存在Condorcet赢家的概率为$1-O(n^2/m^{1/2})\to 1$。

Conclusion: 在选民数远大于候选人数四次方的条件下，几乎必然存在Condorcet赢家，这与固定选民数时的低概率形成鲜明对比。

Abstract: We study a mathematical model of voting contest with $m$ voters and $n$
candidates, with each voter ranking the candidates in order of preference,
without ties. A Condorcet winner is a candidate who gets more than $m/2$ votes
in pairwise contest with every other candidate. An ``impartial culture''
setting is the case when each voter chooses his/her candidate preference list
uniformly at random from all $n!$ preferences, and does it independently of all
other voters. For impartial culture case, Robert May and Lisa Sauermann showed
that when $m=2k-1$ is fixed ($k=2$ and $k>2$ respectively), and $n$ grows
indefinitely, the probability of a Condorcet winner is small, of order
$n^{-(k-1)/k}$. We show that when $m$ grows indefinitely and $m\gg n^4$, the
probability of a Condercet winner is $1-O(n^2/m^{1/2})\to 1$.

</details>


### [41] [Labeled Chip-Firing on Directed $k$-ary Trees and Where Chips Land](https://arxiv.org/abs/2506.20656)
*Ryota Inagaki,Tanya Khovanova,Austin Luo*

Main category: math.CO

TL;DR: 研究无限有根k叉树上的筹码博弈变体，分析稳定配置中筹码分布规律及范围长度特性。


<details>
  <summary>Details</summary>
Motivation: 探索无限有根k叉树上特定筹码分配规则下的稳定状态性质，扩展组合博弈理论的应用场景。

Method: 在根节点放置$k^n$个标记筹码，定义顶点触发规则（选择第i小筹码发送至第i左子树），直至达到稳定状态。

Result: 证明了稳定配置中筹码呈区间分布的特性，精确描述了各筹码的可能落点范围及其长度关系。

Conclusion: 该研究为无限树结构上的组合博弈提供了稳定状态分析框架，揭示了筹码传递的规律性模式。

Abstract: Chip-firing is a combinatorial game played on a graph, in which chips are
placed and dispersed on the vertices until a stable configuration is achieved.
We study a chip-firing variant on an infinite, rooted directed $k$-ary tree,
where we place $k^n$ chips labeled $1,2,3,\dots, k^n$ on the root for some
nonnegative integer $n$. A vertex $v$ can fire if it has at least $k$ chips;
when it fires, $k$ chips are selected, and the chip with the $i$th smallest
label is sent to the $i$th leftmost child of $v$. A stable configuration is
reached when no vertices can fire. In this paper, we prove numerous properties
of the stable configuration, such as that chips land on vertices in ranges and
the lengths of those ranges. We also describe where each chip can land. This
helps us describe possible stable configurations of the game.

</details>


### [42] [On graph automorphisms related to Snort](https://arxiv.org/abs/2506.20669)
*Rylo Ashmore,Beth Ann Austin,Alfie M. Davies,Danny Dyer,William Kellough*

Main category: math.CO

TL;DR: 研究了Snort游戏中不同图位置的胜负结果，提出了可反对图的概念并给出了其充要条件，证明了该性质在多种图积下的保持性，回答了Kakihara猜想，并应用结果确定了多种$n\times m$棋盘图的Snort游戏胜负。


<details>
  <summary>Details</summary>
Motivation: 探讨Snort游戏中图的性质与胜负策略之间的关系，特别是通过图的自同构性质来研究第二玩家的必胜策略。

Method: 定义了可反对图的概念，给出了其充要条件，并研究了该性质在图积操作下的保持性；同时提出了类似定义以研究第一玩家的必胜策略。

Result: 证明了可反对性在多种图积下保持，给出了第二玩家必胜但图不可反对的反例（回答了Kakihara猜想），并确定了多种棋盘图上的Snort游戏结果。

Conclusion: 通过图的自同构性质可以有效分析Snort游戏的胜负策略，可反对性及其推广定义为此类组合游戏研究提供了新工具，棋盘图的应用展示了理论的实际价值。

Abstract: We study the outcomes of various positions of the game Snort. When played on
graphs admitting an automorphism of order two that maps vertices outside of
their closed neighbourhoods (called opposable graphs), the second player has a
winning strategy. We give a necessary and sufficient condition for a graph to
be opposable, and prove that the property of being opposable is preserved by
several graph products. We show examples that a graph being second-player win
does not imply that the graph is opposable, which answers Kakihara's
conjecture. We give an analogous definition to opposability, which gives a
first-player winning strategy; we prove a necessary condition for this property
to be preserved by the Cartesian and strong products. As an application of our
results, we determine the outcome of Snort when played on various $n\times m$
chess graphs.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [43] [Secure Energy Transactions Using Blockchain Leveraging AI for Fraud Detection and Energy Market Stability](https://arxiv.org/abs/2506.19870)
*Md Asif Ul Hoq Khan,MD Zahedul Islam,Istiaq Ahmed,Md Masud Karim Rabbi,Farhana Rahman Anonna,MD Abdul Fahim Zeeshan,Mehedi Hasan Ridoy,Bivash Ranjan Chowdhury,Md Nazmul Shakir Rabbi,GM Alamin Sadnan*

Main category: cs.CR

TL;DR: 本研究开发了一个结合区块链与人工智能的安全、智能、高效的去中心化能源交易系统，旨在解决美国分布式能源市场中安全性与欺诈检测等长期挑战。


<details>
  <summary>Details</summary>
Motivation: 随着点对点交易与去中心化电网的发展，美国能源市场面临安全性与交易真实性等新挑战，亟需构建可靠的新型交易系统。

Method: 整合区块链层与AI层双架构，采用120万条模拟P2P能源交易数据，运用高性能机器学习模型识别欺诈行为。

Result: 系统成功实现基于区块链的安全交易验证，并通过AI模型有效检测分布式市场中的异常交易模式。

Conclusion: 区块链与人工智能的协同应用为去中心化能源市场提供了安全可靠的解决方案，显著提升交易安全性与市场可信度。

Abstract: Peer-to-peer trading and the move to decentralized grids have reshaped the
energy markets in the United States. Notwithstanding, such developments lead to
new challenges, mainly regarding the safety and authenticity of energy trade.
This study aimed to develop and build a secure, intelligent, and efficient
energy transaction system for the decentralized US energy market. This research
interlinks the technological prowess of blockchain and artificial intelligence
(AI) in a novel way to solve long-standing challenges in the distributed energy
market, specifically those of security, fraudulent behavior detection, and
market reliability. The dataset for this research is comprised of more than 1.2
million anonymized energy transaction records from a simulated peer-to-peer
(P2P) energy exchange network emulating real-life blockchain-based American
microgrids, including those tested by LO3 Energy and Grid+ Labs. Each record
contains detailed fields of transaction identifier, timestamp, energy volume
(kWh), transaction type (buy/sell), unit price, prosumer/consumer identifier
(hashed for privacy), smart meter readings, geolocation regions, and settlement
confirmation status. The dataset also includes system-calculated behavior
metrics of transaction rate, variability of energy production, and historical
pricing patterns. The system architecture proposed involves the integration of
two layers, namely a blockchain layer and artificial intelligence (AI) layer,
each playing a unique but complementary function in energy transaction securing
and market intelligence improvement. The machine learning models used in this
research were specifically chosen for their established high performance in
classification tasks, specifically in the identification of energy transaction
fraud in decentralized markets.

</details>


### [44] [An Attack Method for Medical Insurance Claim Fraud Detection based on Generative Adversarial Network](https://arxiv.org/abs/2506.19871)
*Yining Pang,Chenghan Li*

Main category: cs.CR

TL;DR: 本文提出一种基于GAN的方法对保险欺诈检测系统进行对抗攻击，实验显示攻击者无需了解训练数据或模型细节即可生成被误判为合法的欺诈案例，成功率高达99\%，凸显了增强模型鲁棒性的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 保险欺诈检测对保障系统安全至关重要，但现有AI模型缺乏标准化防御机制，易受对抗性威胁。本文旨在揭示这一漏洞，推动检测系统的稳健性提升。

Method: 采用生成对抗网络（GAN）生成对抗样本，通过微调真实保险记录和索赔数据，构造可欺骗检测系统的欺诈案例。

Result: 攻击者在未知训练数据及模型细节的情况下，实现99\%的攻击成功率（ASR），证明当前系统易被对抗性操作绕过。

Conclusion: 研究结果警示保险欺诈检测模型亟需强化对抗鲁棒性，以确保保险系统的稳定性和可靠性。

Abstract: Insurance fraud detection represents a pivotal advancement in modern
insurance service, providing intelligent and digitalized monitoring to enhance
management and prevent fraud. It is crucial for ensuring the security and
efficiency of insurance systems. Although AI and machine learning algorithms
have demonstrated strong performance in detecting fraudulent claims, the
absence of standardized defense mechanisms renders current systems vulnerable
to emerging adversarial threats. In this paper, we propose a GAN-based approach
to conduct adversarial attacks on fraud detection systems. Our results indicate
that an attacker, without knowledge of the training data or internal model
details, can generate fraudulent cases that are classified as legitimate with a
99\% attack success rate (ASR). By subtly modifying real insurance records and
claims, adversaries can significantly increase the fraud risk, potentially
bypassing compromised detection systems. These findings underscore the urgent
need to enhance the robustness of insurance fraud detection models against
adversarial manipulation, thereby ensuring the stability and reliability of
different insurance systems.

</details>


### [45] [Towards Provable (In)Secure Model Weight Release Schemes](https://arxiv.org/abs/2506.19874)
*Xing Yang,Bingtao Wang,Yuhao Wang,Zimo Ji,Terry Jingchen Zhang,Wenyuan Jiang*

Main category: cs.CR

TL;DR: 本文通过引入严格的安全定义，对现有安全权重发布方案进行形式化分析，并以TaylorMLP为例揭示其未能实现安全目标的漏洞。


<details>
  <summary>Details</summary>
Motivation: 当前安全权重发布方案缺乏严格的安全理论基础，仅提供非正式的安全保证，需要建立形式化的安全评估框架。

Method: 借鉴密码学成果提出多项具体安全定义，并以主流方案TaylorMLP为案例进行安全性分析。

Result: 分析发现TaylorMLP存在参数提取漏洞，证明其无法达成宣称的非正式安全目标。

Conclusion: 研究呼吁机器学习与安全领域的交叉研究需采用严格方法，并为未来权重发布方案的设计评估提供范式。

Abstract: Recent secure weight release schemes claim to enable open-source model
distribution while protecting model ownership and preventing misuse. However,
these approaches lack rigorous security foundations and provide only informal
security guarantees. Inspired by established works in cryptography, we
formalize the security of weight release schemes by introducing several
concrete security definitions. We then demonstrate our definition's utility
through a case study of TaylorMLP, a prominent secure weight release scheme.
Our analysis reveals vulnerabilities that allow parameter extraction thus
showing that TaylorMLP fails to achieve its informal security goals. We hope
this work will advocate for rigorous research at the intersection of machine
learning and security communities and provide a blueprint for how future weight
release schemes should be designed and evaluated.

</details>


### [46] [Robust Anomaly Detection in Network Traffic: Evaluating Machine Learning Models on CICIDS2017](https://arxiv.org/abs/2506.19877)
*Zhaoyang Xu,Yunbo Liu*

Main category: cs.CR

TL;DR: 本文比较了四种机器学习模型在入侵检测中的表现，发现监督学习模型在已知攻击上表现优异但在未知攻击上表现不佳，而无监督模型在未知攻击上更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 寻找适合入侵检测的机器学习范式对于构建有效且泛化的安全解决方案至关重要。

Method: 研究在CICIDS2017数据集上对比了四种模型：多层感知机(MLP)、一维卷积神经网络(CNN)、单类支持向量机(OCSVM)和局部离群因子(LOF)，分别在已知攻击和未知攻击场景下的表现。

Result: 监督学习的MLP和CNN在已知攻击上准确率接近完美，但在未知攻击上召回率大幅下降；无监督的LOF在未知攻击上召回率高但误报率也高；边界检测的OCSVM在精度和召回率上表现最平衡。

Conclusion: 研究结果为动态网络环境中选择入侵检测系统模型提供了实用指导，OCSVM在两种场景下均表现出稳健的检测能力。

Abstract: Identifying suitable machine learning paradigms for intrusion detection
remains critical for building effective and generalizable security solutions.
In this study, we present a controlled comparison of four representative models
- Multi-Layer Perceptron (MLP), 1D Convolutional Neural Network (CNN),
One-Class Support Vector Machine (OCSVM) and Local Outlier Factor (LOF) - on
the CICIDS2017 dataset under two scenarios: detecting known attack types and
generalizing to previously unseen threats. Our results show that supervised MLP
and CNN achieve near-perfect accuracy on familiar attacks but suffer drastic
recall drops on novel attacks. Unsupervised LOF attains moderate overall
accuracy and high recall on unknown threats at the cost of elevated false
alarms, while boundary-based OCSVM balances precision and recall best,
demonstrating robust detection across both scenarios. These findings offer
practical guidance for selecting IDS models in dynamic network environments.

</details>


### [47] [Blameless Users in a Clean Room: Defining Copyright Protection for Generative Models](https://arxiv.org/abs/2506.19881)
*Aloni Cohen*

Main category: cs.CR

TL;DR: 本文重新审视了生成模型输出是否侵犯训练数据版权的可证明保护问题，指出原有NAF标准的不足，提出了新的无责复制保护框架和清洁室复制保护机制，并证明了差分隐私在满足特定条件时可实现版权保护。


<details>
  <summary>Details</summary>
Motivation: 研究生成模型输出在何种条件下能确保不侵犯训练数据版权，批判性评估现有NAF标准的有效性，并寻求更坚实的技术和法律基础。

Method: 1) 揭示NAF标准存在允许逐字复制的缺陷；2) 提出无责复制保护框架及其实例化方案——清洁室复制保护；3) 形式化差分隐私与版权的关系，证明其在数据集满足去重要求时的保护性。

Result: 1) 证明NAF单独使用无法防止侵权；2) 提出清洁室机制使用户能通过反事实行为控制复制风险；3) 建立差分隐私在黄金数据集下隐含清洁室保护的数学证明。

Conclusion: 通过构建新的理论框架和形式化证明，为生成模型的版权保护提供了更严谨的基础，特别是指出差分隐私在满足版权去重要求时的保护作用。

Abstract: Are there any conditions under which a generative model's outputs are
guaranteed not to infringe the copyrights of its training data? This is the
question of "provable copyright protection" first posed by Vyas, Kakade, and
Barak (ICML 2023). They define near access-freeness (NAF) and propose it as
sufficient for protection. This paper revisits the question and establishes new
foundations for provable copyright protection -- foundations that are firmer
both technically and legally. First, we show that NAF alone does not prevent
infringement. In fact, NAF models can enable verbatim copying, a blatant
failure of copy protection that we dub being tainted. Then, we introduce our
blameless copy protection framework for defining meaningful guarantees, and
instantiate it with clean-room copy protection. Clean-room copy protection
allows a user to control their risk of copying by behaving in a way that is
unlikely to copy in a counterfactual clean-room setting. Finally, we formalize
a common intuition about differential privacy and copyright by proving that DP
implies clean-room copy protection when the dataset is golden, a copyright
deduplication requirement.

</details>


### [48] [Diffusion-based Task-oriented Semantic Communications with Model Inversion Attack](https://arxiv.org/abs/2506.19886)
*Xuesong Wang,Mo Li,Xingyan Shi,Zhaoqian Liu,Shenghao Yang*

Main category: cs.CR

TL;DR: 本文提出了一种基于扩散机制的语义通信框架DiffSem，通过自参考标签嵌入优化语义信息重建，显著提升任务性能，并在动态信道中保持稳定表现。同时提出新指标量化攻击者语义保真度，实验证明DiffSem在MNIST数据集上分类准确率提升10.03%，且传统图像质量指标与任务相关语义信息泄露存在显著偏差。


<details>
  <summary>Details</summary>
Motivation: 面向任务的语义通信是6G网络中的新兴范式，其核心挑战在于平衡隐私保护与任务准确性。传统系统易受模型逆向攻击，且依赖图像质量指标（如PSNR/SSIM）评估攻击严重性，但这些指标无法充分反映语义差异。因此需设计新型框架及评估标准。

Method: 提出DiffSem框架：1) 采用扩散机制与自参考标签嵌入优化语义重建；2) 补偿信道噪声并引入语义信息失真以增强鲁棒性；3) 设计新指标量化攻击者语义保真度，替代传统图像质量评估。

Result: 在MNIST数据集上，DiffSem使分类准确率提升10.03%，且在动态信道环境下性能稳定。实验证实传统图像质量指标（如PSNR/SSIM）与任务相关语义泄露程度存在显著偏差。

Conclusion: DiffSem通过扩散机制有效提升语义通信的任务性能与抗干扰能力，同时提出的新评估指标更精准反映语义安全性。该研究为6G网络中隐私保护与效能平衡提供了新思路。

Abstract: Semantic communication has emerged as a promising neural network-based system
design for 6G networks. Task-oriented semantic communication is a novel
paradigm whose core goal is to efficiently complete specific tasks by
transmitting semantic information, optimizing communication efficiency and task
performance. The key challenge lies in preserving privacy while maintaining
task accuracy, as this scenario is susceptible to model inversion attacks. In
such attacks, adversaries can restore or even reconstruct input data by
analyzing and processing model outputs, owing to the neural network-based
nature of the systems. In addition, traditional systems use image quality
indicators (such as PSNR or SSIM) to assess attack severity, which may be
inadequate for task-oriented semantic communication, since visual differences
do not necessarily ensure semantic divergence. In this paper, we propose a
diffusion-based semantic communication framework, named DiffSem, that optimizes
semantic information reconstruction through a diffusion mechanism with
self-referential label embedding to significantly improve task performance. Our
model also compensates channel noise and adopt semantic information distortion
to ensure the robustness of the system in various signal-to-noise ratio
environments. To evaluate the attacker's effectiveness, we propose a new metric
that better quantifies the semantic fidelity of estimations from the adversary.
Experimental results based on this criterion show that on the MNIST dataset,
DiffSem improves the classification accuracy by 10.03%, and maintain stable
performance under dynamic channels. Our results further demonstrate that
significant deviation exists between traditional image quality indicators and
the leakage of task-relevant semantic information.

</details>


### [49] [Retrieval-Confused Generation is a Good Defender for Privacy Violation Attack of Large Language Models](https://arxiv.org/abs/2506.19889)
*Wanli Peng,Xin Chen,Hang Fu,XinYu He,Xue Yiming,Juan Wen*

Main category: cs.CR

TL;DR: 本文提出了一种基于检索混淆生成(RCG)的新型防御范式，用于高效隐蔽地防御大型语言模型(LLM)的隐私侵犯攻击(PVA)。该方法通过改写攻击查询、构建干扰数据库和无关检索策略，使攻击者获得错误个人信息，从而有效抵御PVA。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法依赖LLM匿名化输入查询，计算成本高且效果不佳；直接拒绝PVA查询会暴露防御方法，促使攻击进化。因此需要开发更高效隐蔽的防御机制。

Method: 1) 设计改写提示诱导LLM重构攻击查询的"用户评论"以构建干扰数据库；2) 采用最不相关检索策略从干扰库中检索目标数据；3) 用检索数据替换原始"数据评论"生成防御性查询。

Result: 在两个数据集和八个主流LLM上的实验表明，该方法能有效使攻击者获取错误个人属性，显著提升防御性能。

Conclusion: RCG防御范式通过主动干扰攻击查询的语义关联性，实现了对PVA的高效隐蔽防御，为LLM隐私保护提供了新思路。

Abstract: Recent advances in large language models (LLMs) have made a profound impact
on our society and also raised new security concerns. Particularly, due to the
remarkable inference ability of LLMs, the privacy violation attack (PVA),
revealed by Staab et al., introduces serious personal privacy issues. Existing
defense methods mainly leverage LLMs to anonymize the input query, which
requires costly inference time and cannot gain satisfactory defense
performance. Moreover, directly rejecting the PVA query seems like an effective
defense method, while the defense method is exposed, promoting the evolution of
PVA. In this paper, we propose a novel defense paradigm based on
retrieval-confused generation (RCG) of LLMs, which can efficiently and covertly
defend the PVA. We first design a paraphrasing prompt to induce the LLM to
rewrite the "user comments" of the attack query to construct a disturbed
database. Then, we propose the most irrelevant retrieval strategy to retrieve
the desired user data from the disturbed database. Finally, the "data comments"
are replaced with the retrieved user data to form a defended query, leading to
responding to the adversary with some wrong personal attributes, i.e., the
attack fails. Extensive experiments are conducted on two datasets and eight
popular LLMs to comprehensively evaluate the feasibility and the superiority of
the proposed defense method.

</details>


### [50] [RepuNet: A Reputation System for Mitigating Malicious Clients in DFL](https://arxiv.org/abs/2506.19892)
*Isaac Marroqui Penalva,Enrique Tomás Martínez Beltrán,Manuel Gil Pérez,Alberto Huertas Celdrán*

Main category: cs.CR

TL;DR: 本文提出RepuNet，一种去中心化信誉系统，用于检测和缓解去中心化联邦学习（DFL）中的恶意行为，通过动态评估节点行为并调整其在模型聚合中的影响力，实验证明其在MNIST和CIFAR-10数据集上具有高效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习（DFL）中节点自主选择聚合对等节点，易受模型投毒、延迟攻击和消息洪泛等恶意行为影响，现有解决方案存在配置僵化、计算开销大或适应性有限等问题。

Method: RepuNet通过模型相似性、参数变化、消息延迟和通信量等指标动态评估节点行为，并基于信誉分数调整节点在模型聚合中的影响力，集成至Nebula DFL平台进行实验验证。

Result: 在MNIST和CIFAR-10非独立同分布数据集上，RepuNet对恶意行为的检测F1分数分别超过95%和约76%，展现了良好的适应性和鲁棒性。

Conclusion: RepuNet能有效应对DFL中的多种威胁，具有实际应用潜力，为去中心化联邦学习环境提供了可靠的安全保障。

Abstract: Decentralized Federated Learning (DFL) enables nodes to collaboratively train
models without a central server, introducing new vulnerabilities since each
node independently selects peers for model aggregation. Malicious nodes may
exploit this autonomy by sending corrupted models (model poisoning), delaying
model submissions (delay attack), or flooding the network with excessive
messages, negatively affecting system performance. Existing solutions often
depend on rigid configurations or additional infrastructures such as
blockchain, leading to computational overhead, scalability issues, or limited
adaptability. To overcome these limitations, this paper proposes RepuNet, a
decentralized reputation system that categorizes threats in DFL and dynamically
evaluates node behavior using metrics like model similarity, parameter changes,
message latency, and communication volume. Nodes' influence in model
aggregation is adjusted based on their reputation scores. RepuNet was
integrated into the Nebula DFL platform and experimentally evaluated with MNIST
and CIFAR-10 datasets under non-IID distributions, using federations of up to
25 nodes in both fully connected and random topologies. Different attack
intensities, frequencies, and activation intervals were tested. Results
demonstrated that RepuNet effectively detects and mitigates malicious behavior,
achieving F1 scores above 95% for MNIST scenarios and approximately 76% for
CIFAR-10 cases. These outcomes highlight RepuNet's adaptability, robustness,
and practical potential for mitigating threats in decentralized federated
learning environments.

</details>


### [51] [Anti-Phishing Training Does Not Work: A Large-Scale Empirical Assessment of Multi-Modal Training Grounded in the NIST Phish Scale](https://arxiv.org/abs/2506.19899)
*Andrew T. Rozema,James C. Davis*

Main category: cs.CR

TL;DR: 钓鱼邮件是重大网络安全威胁，但现有钓鱼意识培训效果存疑。本研究通过大规模实验发现NIST钓鱼难度量表能有效预测点击率（7.0\%简单邮件至15.0\%复杂邮件），但三种培训方式（讲座式、互动式、对照组）均未显著降低点击率（p=0.450）或提高举报率（p=0.417），效应量均小于0.01。


<details>
  <summary>Details</summary>
Motivation: 现有研究存在两个关键空白：(1)缺乏验证的钓鱼诱饵难度评估工具，(2)缺少真实商业环境中不同培训方式的对比。鉴于合规要求下企业投入大量预算进行钓鱼培训，需实证评估其效果以指导网络安全投资决策。

Method: 在美国金融科技公司开展大规模实验（N=12,511），采用双因素设计：比较三种培训方式（讲座式/互动式/对照组）对员工应对不同难度钓鱼邮件（使用NIST Phish Scale分级）的影响，统计点击率和举报率差异。

Result: NIST钓鱼量表显著预测行为（简单邮件点击率7.0\% vs复杂邮件15.0\%，p<0.001），但培训组间无显著差异（点击率p=0.450，举报率p=0.417），所有培训效应量η²<0.01。

Conclusion: 结果证实钓鱼培训效果微乎其微，支持采用深度防御策略：应通过流程优化和技术升级减少对人因素的依赖，同时质疑合规驱动的培训投入合理性。

Abstract: Social engineering attacks using email, commonly known as phishing, are a
critical cybersecurity threat. Phishing attacks often lead to operational
incidents and data breaches. As a result, many organizations allocate a
substantial portion of their cybersecurity budgets to phishing awareness
training, driven in part by compliance requirements. However, the effectiveness
of this training remains in dispute. Empirical evidence of training
(in)effectiveness is essential for evidence-based cybersecurity investment and
policy development. Despite recent measurement studies, two critical gaps
remain in the literature:
  (1) we lack a validated measure of phishing lure difficulty, and
  (2) there are few comparisons of different types of training in real-world
business settings.
  To fill these gaps, we conducted a large-scale study ($N = 12{,}511$) of
phishing effectiveness at a US-based financial technology (``fintech'') firm.
Our two-factor design compared the effect of treatments (lecture-based,
interactive, and control groups) on subjects' susceptibility to phishing lures
of varying complexity (using the NIST Phish Scale). The NIST Phish Scale
successfully predicted behavior (click rates: 7.0\% easy to 15.0\% hard emails,
p $<$ 0.001), but training showed no significant main effects on clicks (p =
0.450) or reporting (p = 0.417). Effect sizes remained below 0.01, indicating
little practical value in any of the phishing trainings we deployed. Our
results add to the growing evidence that phishing training is ineffective,
reinforcing the importance of phishing defense-in-depth and the merit of
changes to processes and technology to reduce reliance on humans, as well as
rebuking the training costs necessitated by regulatory requirements.

</details>


### [52] [A Hybrid Intrusion Detection System with a New Approach to Protect the Cybersecurity of Cloud Computing](https://arxiv.org/abs/2506.19934)
*Maryam Mahdi Al-Husseini*

Main category: cs.CR

TL;DR: 本文提出了一种混合入侵检测系统（HyIDS），采用能量谷优化器（EVO）进行特征选择，并结合监督机器学习模型，显著提高了检测准确率和性能。


<details>
  <summary>Details</summary>
Motivation: 云计算环境中智能设备的广泛使用带来了严重的安全威胁，传统入侵检测系统存在局限性，需要更高效的混合入侵检测系统来应对复杂性和性能问题。

Method: 研究提出了一种新的HyIDS方法，使用EVO进行最优特征选择，并采用监督机器学习模型进行分类，通过CIC_DDoS2019、CSE_CIC_DDoS2018和NSL-KDD数据集进行验证。

Result: 实验结果表明，D_TreeEVO模型在CIC_DDoS2019数据集上准确率达99.13%，检测率为98.941%；在CSE_CIC_DDoS2018数据集上准确率达99.78%；在NSL-KDD数据集上准确率为99.50%，检测率为99.48%。EVO在特征选择上优于GWO。

Conclusion: EVO作为HyIDS的优化器表现优异，能够显著提升入侵检测系统的性能，为云计算环境中的网络安全提供了更有效的解决方案。

Abstract: Cybersecurity is one of the foremost challenges facing the world of cloud
computing. Recently, the widespread adoption of smart devices in cloud
computing environments that provide Internet-based services has become
prevalent. Therefore, it is essential to consider the security threats in these
environments. The use of intrusion detection systems can mitigate the
vulnerabilities of these systems. Furthermore, hybrid intrusion detection
systems can provide better protection compared to conventional intrusion
detection systems. These systems manage issues related to complexity,
dimensionality, and performance. This research aims to propose a Hybrid
Intrusion Detection System (HyIDS) that identifies and mitigates initial
threats. The main innovation of this research is the introduction of a new
method for hybrid intrusion detection systems (HyIDS). For this purpose, an
Energy-Valley Optimizer (EVO) is used to select an optimal feature set, which
is then classified using supervised machine learning models. The proposed
approach is evaluated using the CIC_DDoS2019, CSE_CIC_DDoS2018, and NSL-KDD
datasets. For evaluation and testing, the proposed system has been run for a
total of 32 times. The results of the proposed approach are compared with the
Grey Wolf Optimizer (GWO). With the CIC_DDoS2019 dataset, the D_TreeEVO model
achieves an accuracy of 99.13% and a detection rate of 98.941%. Furthermore,
this result reaches 99.78% for the CSE_CIC_DDoS2018 dataset. In comparison to
NSL-KDD, it has an accuracy of 99.50% and a detection rate (DT) of 99.48%. For
feature selection, EVO outperforms GWO. The results of this research indicate
that EVO yields better results as an optimizer for HyIDS performance.

</details>


### [53] [Quantum-Resistant Domain Name System: A Comprehensive System-Level Study](https://arxiv.org/abs/2506.19943)
*Juyoul Lee,Sanzida Hoque,Abdullah Aydeger,Engin Zeydan*

Main category: cs.CR

TL;DR: 该论文提出了一种名为PQC-DNS的统一框架，用于评估DNS在后量子时代的加密安全性，通过实验验证了多种后量子密码方案的性能与安全性。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算机的发展，传统DNS协议在量子攻击面前显得脆弱，亟需研究如何保障DNS在后量子时代的机密性、真实性和完整性。

Method: 研究团队开发了PQC-DNS框架，整合了Open Quantum Safe库，在BIND9和TLS 1.3中实现了基于格和哈希的后量子密码方案，并通过容器化测试平台评估了性能与安全影响。

Result: 实验表明，基于格的MLKEM和Falcon方案具有实用的延迟和资源占用，而基于哈希的SPHINCS+则显著增加了消息大小和处理开销。研究还揭示了降级风险、分片漏洞等安全问题。

Conclusion: 该研究为部署抗量子DNS提供了实践指导，并为保障核心互联网协议在后量子时代的安全性做出了贡献。

Abstract: The Domain Name System (DNS) plays a foundational role in Internet
infrastructure, yet its core protocols remain vulnerable to compromise by
quantum adversaries. As cryptographically relevant quantum computers become a
realistic threat, ensuring DNS confidentiality, authenticity, and integrity in
the post-quantum era is imperative. In this paper, we present a comprehensive
system-level study of post-quantum DNS security across three widely deployed
mechanisms: DNSSEC, DNS-over-TLS (DoT), and DNS-over-HTTPS (DoH). We propose
Post-Quantum Cryptographic (PQC)-DNS, a unified framework for benchmarking DNS
security under legacy, post-quantum, and hybrid cryptographic configurations.
Our implementation leverages the Open Quantum Safe (OQS) libraries and
integrates lattice- and hash-based primitives into BIND9 and TLS 1.3 stacks. We
formalize performance and threat models and analyze the impact of post-quantum
key encapsulation and digital signatures on end-to-end DNS resolution.
Experimental results on a containerized testbed reveal that lattice-based
primitives such as Module-Lattice-Based Key-Encapsulation Mechanism (MLKEM) and
Falcon offer practical latency and resource profiles, while hash-based schemes
like SPHINCS+ significantly increase message sizes and processing overhead. We
also examine security implications including downgrade risks, fragmentation
vulnerabilities, and susceptibility to denial-of-service amplification. Our
findings inform practical guidance for deploying quantum-resilient DNS and
contribute to the broader effort of securing core Internet protocols for the
post-quantum future.

</details>


### [54] [Can One Safety Loop Guard Them All? Agentic Guard Rails for Federated Computing](https://arxiv.org/abs/2506.20000)
*Narasimha Raghavan Veeraragavan,Jan Franz Nygård*

Main category: cs.CR

TL;DR: Guardian-FC是一个新颖的双层框架，用于隐私保护的联邦计算，统一了多种隐私保护机制的安全执行，包括加密后端和统计技术。


<details>
  <summary>Details</summary>
Motivation: 为了解决联邦计算中隐私保护机制多样化和安全执行不一致的问题，提出了一个统一的安全框架。

Method: 框架采用两层设计，通过后端中立的领域特定语言（DSL）和执行提供者（EPs）解耦安全护栏与隐私机制，并由Agentic-AI控制平面强制执行安全循环。

Result: Guardian-FC支持快速失败的任务准入和无缝扩展到新的隐私后端，并提供了形式化模型基础进行验证。

Conclusion: 论文提出了一个研究议程，邀请社区共同推进自适应护栏调优、多后端组合、DSL规范开发以及编译器可扩展性。

Abstract: We propose Guardian-FC, a novel two-layer framework for privacy preserving
federated computing that unifies safety enforcement across diverse privacy
preserving mechanisms, including cryptographic back-ends like fully homomorphic
encryption (FHE) and multiparty computation (MPC), as well as statistical
techniques such as differential privacy (DP). Guardian-FC decouples guard-rails
from privacy mechanisms by executing plug-ins (modular computation units),
written in a backend-neutral, domain-specific language (DSL) designed
specifically for federated computing workflows and interchangeable Execution
Providers (EPs), which implement DSL operations for various privacy back-ends.
An Agentic-AI control plane enforces a finite-state safety loop through signed
telemetry and commands, ensuring consistent risk management and auditability.
The manifest-centric design supports fail-fast job admission and seamless
extensibility to new privacy back-ends. We present qualitative scenarios
illustrating backend-agnostic safety and a formal model foundation for
verification. Finally, we outline a research agenda inviting the community to
advance adaptive guard-rail tuning, multi-backend composition, DSL
specification development, implementation, and compiler extensibility alongside
human-override usability.

</details>


### [55] [Attack Smarter: Attention-Driven Fine-Grained Webpage Fingerprinting Attacks](https://arxiv.org/abs/2506.20082)
*Yali Yuan,Weiyi Zou,Guang Cheng*

Main category: cs.CR

TL;DR: 本文提出了一种名为ADWPF的注意力驱动细粒度网页指纹攻击方法，通过建模网站子页面为独立类别并处理多标签浏览场景，显著提升了大规模环境下的识别性能。


<details>
  <summary>Details</summary>
Motivation: 传统网站指纹攻击(WF)在实验环境中有效，但仅局限于识别主页，难以应对实际场景中用户快速访问多个子页面及多标签浏览的复杂情况。网页指纹(WPF)通过将子页面建模为独立类别扩展了WF框架，但面临类间差异小、流量段重叠等挑战。

Method: ADWPF方法在训练阶段基于注意力图对流量显著区域进行针对性增强（注意力裁剪和掩蔽），从原始和增强流量中提取低维特征，并通过自注意力模块捕捉全局上下文模式。针对多标签场景，采用残差注意力生成不同时间位置网页的类别特定表示。

Result: 大量实验表明，ADWPF在不同规模的数据集上持续超越现有最先进基线方法，验证了其在大规模环境中的有效性。

Conclusion: 该研究通过注意力机制和针对性数据增强解决了网页指纹攻击中的关键挑战，为大规模实际场景中的用户匿名性保护提出了新的攻防研究方向。

Abstract: Website Fingerprinting (WF) attacks aim to infer which websites a user is
visiting by analyzing traffic patterns, thereby compromising user anonymity.
Although this technique has been demonstrated to be effective in controlled
experimental environments, it remains largely limited to small-scale scenarios,
typically restricted to recognizing website homepages. In practical settings,
however, users frequently access multiple subpages in rapid succession, often
before previous content fully loads. WebPage Fingerprinting (WPF) generalizes
the WF framework to large-scale environments by modeling subpages of the same
site as distinct classes. These pages often share similar page elements,
resulting in lower inter-class variance in traffic features. Furthermore, we
consider multi-tab browsing scenarios, in which a single trace encompasses
multiple categories of webpages. This leads to overlapping traffic segments,
and similar features may appear in different positions within the traffic,
thereby increasing the difficulty of classification. To address these
challenges, we propose an attention-driven fine-grained WPF attack, named
ADWPF. Specifically, during the training phase, we apply targeted augmentation
to salient regions of the traffic based on attention maps, including attention
cropping and attention masking. ADWPF then extracts low-dimensional features
from both the original and augmented traffic and applies self-attention modules
to capture the global contextual patterns of the trace. Finally, to handle the
multi-tab scenario, we employ the residual attention to generate class-specific
representations of webpages occurring at different temporal positions.
Extensive experiments demonstrate that the proposed method consistently
surpasses state-of-the-art baselines across datasets of different scales.

</details>


### [56] [Secure Multi-Key Homomorphic Encryption with Application to Privacy-Preserving Federated Learning](https://arxiv.org/abs/2506.20101)
*Jiahui Wu,Tiecheng Sun,Fucai Luo,Haiyan Wang,Weizhe Zhang*

Main category: cs.CR

TL;DR: 本文发现多密钥同态加密方案CDKS在多方安全计算中存在安全漏洞，可能导致明文信息泄露。作者提出新型安全方案SMHE，通过引入掩蔽机制增强保密性，并在隐私保护联邦学习中验证其高效性。


<details>
  <summary>Details</summary>
Motivation: CDKS方案在隐私保护联邦学习等场景中意外泄露参与者明文数据，亟需设计能保障跨方计算机密性的新型多密钥同态加密框架。

Method: 在BFV/CKKS多密钥框架中嵌入创新性掩蔽机制，构建SMHE方案。基于该方案实现隐私保护联邦学习应用，并量化评估性能开销。

Result: 实验表明：基于多密钥CKKS的SMHE方案仅带来不足2倍的运行时与通信开销增长，较CDKS方案显著提升安全性。代码已开源。

Conclusion: SMHE方案成功解决了CDKS的明文泄露缺陷，以可接受性能代价为多方安全计算提供更强保密保障，具有实际部署价值。

Abstract: Multi-Key Homomorphic Encryption (MKHE), proposed by Lopez-Alt et al. (STOC
2012), allows for performing arithmetic computations directly on ciphertexts
encrypted under distinct keys. Subsequent works by Chen and Dai et al. (CCS
2019) and Kim and Song et al. (CCS 2023) extended this concept by proposing
multi-key BFV/CKKS variants, referred to as the CDKS scheme. These variants
incorporate asymptotically optimal techniques to facilitate secure computation
across multiple data providers. In this paper, we identify a critical security
vulnerability in the CDKS scheme when applied to multiparty secure computation
tasks, such as privacy-preserving federated learning (PPFL). In particular, we
show that CDKS may inadvertently leak plaintext information from one party to
others. To mitigate this issue, we propose a new scheme, SMHE (Secure Multi-Key
Homomorphic Encryption), which incorporates a novel masking mechanism into the
multi-key BFV and CKKS frameworks to ensure that plaintexts remain confidential
throughout the computation. We implement a PPFL application using SMHE and
demonstrate that it provides significantly improved security with only a modest
overhead in homomorphic evaluation. For instance, our PPFL model based on
multi-key CKKS incurs less than a 2\times runtime and communication traffic
increase compared to the CDKS-based PPFL model. The code is publicly available
at https://github.com/JiahuiWu2022/SMHE.git.

</details>


### [57] [Autonomous Cyber Resilience via a Co-Evolutionary Arms Race within a Fortified Digital Twin Sandbox](https://arxiv.org/abs/2506.20102)
*Malikussaid,Sutiyo*

Main category: cs.CR

TL;DR: 论文提出ARC框架，通过红蓝代理的协同进化机制实现工业控制系统动态安全防御，实验证明其能有效检测新型攻击并自主修补漏洞。


<details>
  <summary>Details</summary>
Motivation: IT与OT融合导致关键基础设施面临新型自适应攻击，传统静态防御失效，需建立涵盖系统模型、数据同步和分析引擎弹性的'信任三位一体'新范式。

Method: 采用深度强化学习(DRL)训练'红代理'自主发现隐蔽攻击路径，同时通过对抗训练强化'蓝代理'防御能力，在F-SCDT沙箱中形成持续进化的攻防体系。

Result: 在TEP和SWaT测试平台验证中，协同进化机制使攻击检测性能显著提升（ROC曲线和SHAP图佐证），F-ARC架构兼具可解释性(XAI)与可扩展性。

Conclusion: ARC框架代表从静态防御到动态自主安全范式的根本转变，为关键基础设施提供持续自我强化的安全保障机制。

Abstract: The convergence of IT and OT has created hyper-connected ICS, exposing
critical infrastructure to a new class of adaptive, intelligent adversaries
that render static defenses obsolete. Existing security paradigms often fail to
address a foundational "Trinity of Trust," comprising the fidelity of the
system model, the integrity of synchronizing data, and the resilience of the
analytical engine against sophisticated evasion. This paper introduces the ARC
framework, a method for achieving analytical resilience through an autonomous,
closed-loop hardening process. ARC establishes a perpetual co-evolutionary arms
race within the high-fidelity sandbox of a F-SCDT. A DRL agent, the "Red
Agent," is formalized and incentivized to autonomously discover stealthy,
physically-plausible attack paths that maximize process disruption while
evading detection. Concurrently, an ensemble-based "Blue Agent" defender is
continuously hardened via adversarial training against the evolving threats
discovered by its adversary. This co-evolutionary dynamic forces both agents to
become progressively more sophisticated, enabling the system to autonomously
probe and patch its own vulnerabilities. Experimental validation on both the
TEP and the SWaT testbeds demonstrates the framework's superior performance. A
comprehensive ablation study, supported by extensive visualizations including
ROC curves and SHAP plots, reveals that the co-evolutionary process itself is
responsible for a significant performance increase in detecting novel attacks.
By integrating XAI to ensure operator trust and proposing a scalable F-ARC
architecture, this work presents ARC not merely as an improvement, but as a
necessary paradigm shift toward dynamic, self-improving security for the future
of critical infrastructure.

</details>


### [58] [Evaluating Disassembly Errors With Only Binaries](https://arxiv.org/abs/2506.20109)
*Lambang Akbar Wijayadi,Yuancheng Jiang,Roland H. C. Yap,Zhenkai Liang,Zhuohao Liu*

Main category: cs.CR

TL;DR: 本文提出了TraceBin，一种仅需二进制文件即可评估反汇编错误的新方法，无需源代码假设，通过动态执行发现错误，显著提升自动化安全任务的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有反汇编错误研究依赖源代码和编译器工具链，与仅有二进制文件的现实场景矛盾。TraceBin旨在解决这一根本问题，首次实现无源码条件下的反汇编错误评估。

Method: TraceBin采用动态执行技术定位反汇编错误，专注于自动化安全任务（如静态插桩、二进制加固）中的错误检测，通过目标二进制自身揭示潜在问题。

Result: 实验表明TraceBin能发现：(i)与现有研究一致的无源码错误；(ii)控制流导致的反汇编错误；(iii)新型错误；(iv)非C/C++二进制错误；(v)闭源二进制错误；(vi)证明错误可能导致重大安全隐患。

Conclusion: TraceBin在主流反汇编器中检出大量错误，尤其适用于依赖反汇编的（闭源）二进制文件自动化安全任务，填补了无源码评估的技术空白。

Abstract: Disassemblers are crucial in the analysis and modification of binaries.
Existing works showing disassembler errors largely rely on practical
implementation without specific guarantees and assume source code and compiler
toolchains to evaluate ground truth. However, the assumption of source code is
contrary to typical binary scenarios where only the binary is available. In
this work, we investigate an approach with minimal assumptions and a sound
approach to disassembly error evaluation that does not require source code. Any
source code does not address the fundamental problem of binary disassembly and
fails when only the binary exists. As far as we know, this is the first work to
evaluate disassembly errors using only the binary. We propose TraceBin, which
uses dynamic execution to find disassembly errors. TraceBin targets the use
case where the disassembly is used in an automated fashion for security tasks
on a target binary, such as static binary instrumentation, binary hardening,
automated code repair, and so on, which may be affected by disassembly errors.
Discovering disassembly errors in the target binary aids in reducing problems
caused by such errors. Furthermore, we are not aware of existing approaches
that can evaluate errors given only a target binary, as they require source
code. Our evaluation shows TraceBin finds: (i) errors consistent with existing
studies even without source; (ii) disassembly errors due to control flow; (iii)
new interesting errors; (iv) errors in non-C/C++ binaries; (v) errors in
closed-source binaries; and (vi) show that disassembly errors can have
significant security implications. Overall, our experimental results show that
TraceBin finds many errors in existing popular disassemblers. It is also
helpful in automated security tasks on (closed source) binaries relying on
disassemblers.

</details>


### [59] [JsDeObsBench: Measuring and Benchmarking LLMs for JavaScript Deobfuscation](https://arxiv.org/abs/2506.20170)
*Guoqiang Chen,Xin Jin,Zhiqiang Lin*

Main category: cs.CR

TL;DR: 本文介绍了JsDeObsBench基准测试，用于系统评估大型语言模型（LLM）在JavaScript反混淆任务中的表现，揭示了LLM在代码简化方面的优势及在语法准确性和执行可靠性上的挑战。


<details>
  <summary>Details</summary>
Motivation: JavaScript混淆技术常被用于隐藏恶意代码，而现有研究缺乏对LLM反混淆能力的系统评估。本文旨在填补这一空白，量化LLM在反混淆任务中的效果与局限。

Method: 研究团队构建了JsDeObsBench基准，涵盖从基础变量重命名到复杂结构变换的多种混淆技术，并测试了GPT-4o、Mixtral、Llama和DeepSeek-Coder等前沿LLM模型。

Result: 实验表明LLM在代码简化方面表现优异，但在保持语法准确性和执行可靠性上仍存在挑战。在JS恶意软件反混淆任务中，LLM展现出安全应用潜力。

Conclusion: 研究证实了LLM在反混淆应用中的实用性，同时指出了关键改进方向，为后续研究提供了重要基准。

Abstract: Deobfuscating JavaScript (JS) code poses a significant challenge in web
security, particularly as obfuscation techniques are frequently used to conceal
malicious activities within scripts. While Large Language Models (LLMs) have
recently shown promise in automating the deobfuscation process, transforming
detection and mitigation strategies against these obfuscated threats, a
systematic benchmark to quantify their effectiveness and limitations has been
notably absent. To address this gap, we present JsDeObsBench, a dedicated
benchmark designed to rigorously evaluate the effectiveness of LLMs in the
context of JS deobfuscation. We detail our benchmarking methodology, which
includes a wide range of obfuscation techniques ranging from basic variable
renaming to sophisticated structure transformations, providing a robust
framework for assessing LLM performance in real-world scenarios. Our extensive
experimental analysis investigates the proficiency of cutting-edge LLMs, e.g.,
GPT-4o, Mixtral, Llama, and DeepSeek-Coder, revealing superior performance in
code simplification despite challenges in maintaining syntax accuracy and
execution reliability compared to baseline methods. We further evaluate the
deobfuscation of JS malware to exhibit the potential of LLMs in security
scenarios. The findings highlight the utility of LLMs in deobfuscation
applications and pinpoint crucial areas for further improvement.

</details>


### [60] [Measuring Modern Phishing Tactics: A Quantitative Study of Body Obfuscation Prevalence, Co-occurrence, and Filter Impact](https://arxiv.org/abs/2506.20228)
*Antony Dalmiere,Zheng Zhou,Guillaume Auriol,Vincent Nicomette,Pascal Marchand*

Main category: cs.CR

TL;DR: 研究通过分析386封钓鱼邮件，量化了十种邮件正文混淆技术，发现Base64编码和图片藏文显著关联反垃圾邮件规避能力，为复合混淆策略提供了量化基准。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击常使用邮件正文混淆技术绕过检测，但缺乏对这些技术组合方式及其对过滤器评分影响的定量研究。

Method: 实证分析386封已验证钓鱼邮件，统计十种混淆技术流行度与共现模式，并采用多元线性回归评估其与反垃圾邮件评分的关联性。

Result: 图片藏文(47.0%)、Base64编码(31.2%)和无效HTML(28.8%)最普遍；回归模型(R${}^2$=0.486, p<0.001)显示Base64编码和图片藏文组合显著降低反垃圾评分(p<0.05)，而无效HTML则与更高评分相关。

Conclusion: 研究确立了复合混淆策略的量化基准，表明需要针对组合式混淆技术开发多模态防御方案。

Abstract: Phishing attacks frequently use email body obfuscation to bypass detection
filters, but quantitative insights into how techniques are combined and their
impact on filter scores remain limited. This paper addresses this gap by
empirically investigating the prevalence, co-occurrence patterns, and spam
score associations of body obfuscation techniques. Analysing 386 verified
phishing emails, we quantified ten techniques, identified significant pairwise
co-occurrences revealing strategic layering like the presence of text in images
with multipart abuse, and assessed associations with antispam scores using
multilinear regression. Text in Image (47.0%), Base64 Encoding (31.2%), and
Invalid HTML (28.8%) were highly prevalent. Regression (R${}^2$=0.486, p<0.001)
linked Base64 Encoding and Text in Image with significant antispam evasion
(p<0.05) in this configuration, suggesting potential bypass capabilities, while
Invalid HTML correlated with higher scores. These findings establish a
quantitative baseline for complex evasion strategies, underscoring the need for
multi-modal defences against combined obfuscation tactics.

</details>


### [61] [Communication-Efficient Publication of Sparse Vectors under Differential Privacy](https://arxiv.org/abs/2506.20234)
*Quentin Hillebrand,Vorapong Suppakitpaisarn,Tetsuo Shibuya*

Main category: cs.CR

TL;DR: 本文提出一种差分隐私算法，用于发布稀疏向量聚合矩阵，显著降低通信成本至$O(\varepsilon m)$，优于传统随机响应方法的$\Omega(n \times N)$，且在隐私预算$\varepsilon$降低时效率更高。


<details>
  <summary>Details</summary>
Motivation: 传统差分隐私方法（如随机响应）在处理稀疏向量聚合矩阵（如社交网络邻接矩阵、推荐系统用户-物品交互矩阵）时通信成本过高（$\Omega(n \times N)$），难以适用于大规模数据。

Method: 设计了一种新型差分隐私算法，通过优化通信机制将成本降至$O(\varepsilon m)$，并证明其输出结果与随机响应方法等效。

Result: 理论分析与实验验证表明，该算法在精度、通信效率（成本低于非隐私场景的$\Omega(m \log n)$）和计算复杂度方面均表现优异，且隐私预算降低时效率进一步提升。

Conclusion: 该算法实现了隐私保护与效率的平衡，为稀疏矩阵的差分隐私发布提供了实用解决方案，尤其适用于大规模数据场景。

Abstract: In this work, we propose a differentially private algorithm for publishing
matrices aggregated from sparse vectors. These matrices include social network
adjacency matrices, user-item interaction matrices in recommendation systems,
and single nucleotide polymorphisms (SNPs) in DNA data. Traditionally,
differential privacy in vector collection relies on randomized response, but
this approach incurs high communication costs. Specifically, for a matrix with
$N$ users, $n$ columns, and $m$ nonzero elements, conventional methods require
$\Omega(n \times N)$ communication, making them impractical for large-scale
data. Our algorithm significantly reduces this cost to $O(\varepsilon m)$,
where $\varepsilon$ is the privacy budget. Notably, this is even lower than the
non-private case, which requires $\Omega(m \log n)$ communication. Moreover, as
the privacy budget decreases, communication cost further reduces, enabling
better privacy with improved efficiency. We theoretically prove that our method
yields results identical to those of randomized response, and experimental
evaluations confirm its effectiveness in terms of accuracy, communication
efficiency, and computational complexity.

</details>


### [62] [Don't Hash Me Like That: Exposing and Mitigating Hash-Induced Unfairness in Local Differential Privacy](https://arxiv.org/abs/2506.20290)
*Berkay Kemal Balioglu,Alireza Khodaie,Mehmet Emre Gursoy*

Main category: cs.CR

TL;DR: 本文揭示了局部差分隐私（LDP）协议中哈希函数选择可能导致的不公平问题，并提出了一种基于熵的公平约束方法Fair-OLH（F-OLH）来缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 在LDP框架下，哈希函数常用于用户端编码和扰动，但其安全性和隐私影响尚未被充分研究。研究发现，不同哈希函数可能导致用户在面对推理和投毒攻击时存在显著差异，即使协议和隐私预算相同。

Method: 提出了Fair-OLH（F-OLH），这是OLH（Optimal Local Hashing）的一种变体，通过在哈希函数选择中引入基于熵的公平约束，确保用户间的公平性。

Result: 实验表明，F-OLH在可接受的时间开销下，能够有效缓解由哈希函数引起的不公平问题。

Conclusion: 哈希函数的选择在LDP协议中是一个潜在的不公平来源，而F-OLH通过公平约束显著改善了这一问题，为隐私保护数据收集提供了更公平的解决方案。

Abstract: Local differential privacy (LDP) has become a widely accepted framework for
privacy-preserving data collection. In LDP, many protocols rely on hash
functions to implement user-side encoding and perturbation. However, the
security and privacy implications of hash function selection have not been
previously investigated. In this paper, we expose that the hash functions may
act as a source of unfairness in LDP protocols. We show that although users
operate under the same protocol and privacy budget, differences in hash
functions can lead to significant disparities in vulnerability to inference and
poisoning attacks. To mitigate hash-induced unfairness, we propose Fair-OLH
(F-OLH), a variant of OLH that enforces an entropy-based fairness constraint on
hash function selection. Experiments show that F-OLH is effective in mitigating
hash-induced unfairness under acceptable time overheads.

</details>


### [63] [SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models](https://arxiv.org/abs/2506.20415)
*Dipayan Saha,Shams Tarek,Hasan Al Shaikh,Khan Thamid Hasan,Pavan Sai Nalluri,Md. Ajoad Hasan,Nashmin Alam,Jingbo Zhou,Sujan Kumar Saha,Mark Tehranipoor,Farimah Farahmandi*

Main category: cs.CR

TL;DR: 本文提出SV-LLM系统，利用多智能体协作的大语言模型（LLM）自动化提升SoC安全验证，解决传统方法在自动化、扩展性等方面的不足。


<details>
  <summary>Details</summary>
Motivation: 传统SoC安全验证技术面临自动化不足、扩展性差等挑战，而大语言模型（LLM）的自然语言理解和代码生成能力为解决这些问题提供了新思路。

Method: SV-LLM采用多智能体系统，集成专门代理执行问答、资产识别、威胁建模等任务，结合上下文学习、微调和检索增强生成（RAG）优化性能。

Result: 案例研究和实验表明，SV-LLM能减少人工干预、提高准确性并加速安全分析，支持在设计周期早期主动识别和缓解风险。

Conclusion: SV-LLM展现了通过多智能体LLM协作变革硬件安全实践的潜力，为SoC安全验证提供了高效、自动化的解决方案。

Abstract: Ensuring the security of complex system-on-chips (SoCs) designs is a critical
imperative, yet traditional verification techniques struggle to keep pace due
to significant challenges in automation, scalability, comprehensiveness, and
adaptability. The advent of large language models (LLMs), with their remarkable
capabilities in natural language understanding, code generation, and advanced
reasoning, presents a new paradigm for tackling these issues. Moving beyond
monolithic models, an agentic approach allows for the creation of multi-agent
systems where specialized LLMs collaborate to solve complex problems more
effectively. Recognizing this opportunity, we introduce SV-LLM, a novel
multi-agent assistant system designed to automate and enhance SoC security
verification. By integrating specialized agents for tasks like verification
question answering, security asset identification, threat modeling, test plan
and property generation, vulnerability detection, and simulation-based bug
validation, SV-LLM streamlines the workflow. To optimize their performance in
these diverse tasks, agents leverage different learning paradigms, such as
in-context learning, fine-tuning, and retrieval-augmented generation (RAG). The
system aims to reduce manual intervention, improve accuracy, and accelerate
security analysis, supporting proactive identification and mitigation of risks
early in the design cycle. We demonstrate its potential to transform hardware
security practices through illustrative case studies and experiments that
showcase its applicability and efficacy.

</details>


### [64] [Generative AI for Vulnerability Detection in 6G Wireless Networks: Advances, Case Study, and Future Directions](https://arxiv.org/abs/2506.20488)
*Shuo Yang,Xinran Zheng,Jinfeng Xu,Jinze Li,Danyang Song,Zheyu Chen,Edith C. H. Ngai*

Main category: cs.CR

TL;DR: 本文探讨了生成式AI（GAI）在6G无线网络漏洞检测中的应用，提出了一个三层框架，并通过案例研究展示了其有效性，同时指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着6G、物联网和边缘计算的快速发展，网络攻击面扩大，传统安全方法难以应对零日漏洞和动态网络环境中的威胁，需要更智能的漏洞检测机制。

Method: 提出了一个包含技术层、能力层和应用层的三层框架，系统分析了VAEs、GANs、LLMs和GDMs在安全防护中的作用，并通过LLM驱动的代码漏洞检测案例进行实践验证。

Result: 案例研究表明，GAI在漏洞检测中表现出高效性和适应性，但也面临轻量化模型、高真实性数据生成等挑战。

Conclusion: 本文为研究人员和实践者提供了利用GAI构建6G网络弹性安全解决方案的路线图，并指出了未来在轻量化模型、隐私保护技术等方面的研究方向。

Abstract: The rapid advancement of 6G wireless networks, IoT, and edge computing has
significantly expanded the cyberattack surface, necessitating more intelligent
and adaptive vulnerability detection mechanisms. Traditional security methods,
while foundational, struggle with zero-day exploits, adversarial threats, and
context-dependent vulnerabilities in highly dynamic network environments.
Generative AI (GAI) emerges as a transformative solution, leveraging synthetic
data generation, multimodal reasoning, and adaptive learning to enhance
security frameworks. This paper explores the integration of GAI-powered
vulnerability detection in 6G wireless networks, focusing on code auditing,
protocol security, cloud-edge defenses, and hardware protection. We introduce a
three-layer framework comprising the Technology Layer, Capability Layer, and
Application Layer to systematically analyze the role of VAEs, GANs, LLMs, and
GDMs in securing next-generation wireless ecosystems. To demonstrate practical
implementation, we present a case study on LLM-driven code vulnerability
detection, highlighting its effectiveness, performance, and challenges.
Finally, we outline future research directions, including lightweight models,
high-authenticity data generation, external knowledge integration, and
privacy-preserving technologies. By synthesizing current advancements and open
challenges, this work provides a roadmap for researchers and practitioners to
harness GAI for building resilient and adaptive security solutions in 6G
networks.

</details>


### [65] [Vulnerability Disclosure through Adaptive Black-Box Adversarial Attacks on NIDS](https://arxiv.org/abs/2506.20576)
*Sabrine Ennaji,Elhadj Benkhelifa,Luigi V. Mancini*

Main category: cs.CR

TL;DR: 本文提出了一种针对网络流量结构化数据的黑盒对抗攻击新方法，通过自适应特征选择和因果分析实现高效攻击，实验证明其在最小交互下能有效规避检测。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击理论在实际结构化数据（如网络流量）应用中存在差距，特征间依赖关系导致有效攻击困难，且现有方法模糊性限制了可复现性，防御措施难以应对持续演变的攻击。

Method: 提出严格遵循黑盒约束的轻量级攻击方法：采用变点检测和因果分析的自适应特征选择策略，仅针对敏感特征进行扰动，最大限度减少交互以避免被发现。

Result: 实验表明该方法能以极低计算成本和最少交互次数有效规避检测系统，显著提升现实场景中的适应性和适用性。

Conclusion: 该研究推进了网络流量对抗攻击的理解，为开发鲁棒防御机制奠定基础，其轻量级设计确保高可部署性。

Abstract: Adversarial attacks, wherein slight inputs are carefully crafted to mislead
intelligent models, have attracted increasing attention. However, a critical
gap persists between theoretical advancements and practical application,
particularly in structured data like network traffic, where interdependent
features complicate effective adversarial manipulations. Moreover, ambiguity in
current approaches restricts reproducibility and limits progress in this field.
Hence, existing defenses often fail to handle evolving adversarial attacks.
This paper proposes a novel approach for black-box adversarial attacks, that
addresses these limitations. Unlike prior work, which often assumes system
access or relies on repeated probing, our method strictly respect black-box
constraints, reducing interaction to avoid detection and better reflect
real-world scenarios. We present an adaptive feature selection strategy using
change-point detection and causality analysis to identify and target sensitive
features to perturbations. This lightweight design ensures low computational
cost and high deployability. Our comprehensive experiments show the attack's
effectiveness in evading detection with minimal interaction, enhancing its
adaptability and applicability in real-world scenarios. By advancing the
understanding of adversarial attacks in network traffic, this work lays a
foundation for developing robust defenses.

</details>


### [66] [On the Impact of Sybil-based Attacks on Mobile Crowdsensing for Transportation](https://arxiv.org/abs/2506.20585)
*Alexander Söderhäll,Zahra Alimadadi,Panos Papadimitratos*

Main category: cs.CR

TL;DR: 移动群智感知（MCS）在导航应用中易受虚假数据攻击（Sybil攻击），导致路线规划失效。本文通过实验证明，仅需3%的虚假用户即可使平均行程时间增加20%。


<details>
  <summary>Details</summary>
Motivation: 导航类移动群智感知（N-MCS）系统易受虚假数据攻击，攻击者通过伪造多设备数据谎报路况，导致系统推荐低效路线，影响整体交通流。研究旨在量化此类攻击的实际影响。

Method: 基于SUMO交通模拟器和InTAS路网构建N-MCS系统，设计针对个体及群体用户的攻击实验，结合图论选择攻击目标，分析攻击资源与路网位置、虚假数据量的关系。

Result: 实验表明，攻击成功率取决于目标路段的路网结构及虚假数据占比。当虚假用户占3%时，用户平均行程时间增加20%，路线被恶意篡改。

Conclusion: Sybil攻击对N-MCS系统具有显著破坏性，需设计防御机制以应对虚假数据注入，确保交通导航服务的可靠性。

Abstract: Mobile Crowd-Sensing (MCS) enables users with personal mobile devices (PMDs)
to gain information on their surroundings. Users collect and contribute data on
different phenomena using their PMD sensors, and the MCS system processes this
data to extract valuable information for end users. Navigation MCS-based
applications (N-MCS) are prevalent and important for transportation: users
share their location and speed while driving and, in return, find efficient
routes to their destinations. However, N-MCS are currently vulnerable to
malicious contributors, often termed Sybils: submitting falsified data,
seemingly from many devices that are not truly present on target roads, falsely
reporting congestion when there is none, thus changing the road status the
N-MCS infers. The attack effect is that the N-MCS returns suboptimal routes to
users, causing late arrival and, overall, deteriorating road traffic flow. We
investigate exactly the impact of Sybil-based attacks on N-MCS: we design an
N-MCS system that offers efficient routing on top of the vehicular simulator
SUMO, using the InTAS road network as our scenario. We design experiments
attacking an individual N-MCS user as well as a larger population of users,
selecting the adversary targets based on graph-theoretical arguments. Our
experiments show that the resources required for a successful attack depend on
the location of the attack (i.e., the surrounding road network and traffic) and
the extent of Sybil contributed data for the targeted road(s). We demonstrate
that Sybil attacks can alter the route of N-MCS users, increasing average
travel time by 20% with Sybils 3% of the N-MCS user population.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [67] [Prover Agent: An Agent-based Framework for Formal Mathematical Proofs](https://arxiv.org/abs/2506.19923)
*Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai*

Main category: cs.AI

TL;DR: 提出Prover Agent智能体，通过结合大语言模型与Lean证明助手，实现86.1%的MiniF2F基准成功率，创下小语言模型方法的新纪录。


<details>
  <summary>Details</summary>
Motivation: 为解决自动定理证明中形式化与非形式化推理的协同问题，开发能高效生成辅助引理并降低计算成本的智能体。

Method: 整合非形式化推理LLM、形式化证明模型及Lean反馈机制，通过生成辅助引理协同探索整体证明策略。

Result: 在MiniF2F基准测试中达到86.1%成功率，以远低于先前方法的样本预算实现小语言模型领域最优性能。

Conclusion: 案例研究表明生成引理对解决复杂问题具有关键作用，该方法为自动定理证明提供了高效新范式。

Abstract: We present Prover Agent, a novel AI agent for automated theorem proving that
integrates large language models (LLMs) with a formal proof assistant, Lean.
Prover Agent coordinates an informal reasoning LLM, a formal prover model, and
feedback from Lean while also generating auxiliary lemmas to assist in
discovering the overall proof strategy. It achieves an 86.1% success rate on
the MiniF2F benchmark, establishing a new state-of-the-art among methods using
small language models (SLMs) with a much lower sample budget than previous
approaches. We also present case studies illustrating how these generated
lemmas contribute to solving challenging problems.

</details>


### [68] [Context Attribution with Multi-Armed Bandit Optimization](https://arxiv.org/abs/2506.19977)
*Deng Pan,Keerthiram Murugesan,Nuno Moniz,Nitesh Chawla*

Main category: cs.AI

TL;DR: 提出一种基于组合多臂老虎机(CMAB)的上下文归因框架，通过组合汤普森采样(CTS)高效探索上下文子集，显著提升查询效率并保持高归因保真度。


<details>
  <summary>Details</summary>
Motivation: 理解检索上下文中哪些部分影响大语言模型的生成答案，对构建可解释且可信的生成式QA系统至关重要。传统扰动归因方法(如SHAP)计算成本高且采样效率低。

Method: 将上下文片段视为老虎机臂，采用组合汤普森采样(CTS)在有限查询预算下探索指数级上下文子集空间。基于归一化token似然的奖励函数评估子集对原始响应的支持程度。

Result: 在多样化数据集和LLMs上的实验表明，该方法以更少模型查询达到竞争性归因质量，计算效率显著优于传统扰动方法。

Conclusion: 该框架通过自适应平衡探索与利用，为生成式QA系统提供高效可扩展的归因方案，增强了模型决策的可解释性。

Abstract: Understanding which parts of the retrieved context contribute to a large
language model's generated answer is essential for building interpretable and
trustworthy generative QA systems. We propose a novel framework that formulates
context attribution as a combinatorial multi-armed bandit (CMAB) problem. Each
context segment is treated as a bandit arm, and we employ Combinatorial
Thompson Sampling (CTS) to efficiently explore the exponentially large space of
context subsets under a limited query budget. Our method defines a reward
function based on normalized token likelihoods, capturing how well a subset of
segments supports the original model response. Unlike traditional
perturbation-based attribution methods such as SHAP, which sample subsets
uniformly and incur high computational costs, our approach adaptively balances
exploration and exploitation by leveraging posterior estimates of segment
relevance. This leads to substantially improved query efficiency while
maintaining high attribution fidelity. Extensive experiments on diverse
datasets and LLMs demonstrate that our method achieves competitive attribution
quality with fewer model queries.

</details>


### [69] [QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges](https://arxiv.org/abs/2506.20008)
*Abdul Basit,Minghao Shao,Haider Asif,Nouhaila Innan,Muhammad Kashif,Alberto Marchisio,Muhammad Shafique*

Main category: cs.AI

TL;DR: 本文评估了大语言模型（LLMs）在基于PennyLane的量子代码生成中的表现，引入QHackBench基准数据集，并比较了标准提示与检索增强生成（RAG）的效果。结果表明RAG增强模型在复杂量子算法中表现接近标准提示，同时提出了多智能体评估流程以提升执行成功率。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在代码生成方面展现出强大潜力，但其在量子计算领域的应用尚未充分探索。本文旨在填补这一空白，通过实际量子编程挑战评估LLMs的性能。

Method: 研究使用QHack竞赛的真实挑战构建了QHackBench数据集，采用标准提示和RAG两种方法评估模型。评估框架从功能正确性、语法有效性和执行成功率三个维度衡量模型表现，并引入多智能体流程迭代修正错误解决方案。

Result: 实验结果显示，在增强PennyLane数据集的支持下，RAG增强模型的表现与标准提示相近，尤其在复杂量子算法中。多智能体评估流程进一步提高了代码执行的成功率。

Conclusion: 本研究为AI辅助量子编程提供了新的基准数据集和评估框架，公开了QHackBench及相关资源以促进后续研究。结果表明LLMs在量子代码生成中具有潜力，而RAG和多智能体方法能有效提升性能。

Abstract: Recent advances in Large Language Models (LLMs) have demonstrated strong
potential in code generation, yet their effectiveness in quantum computing
remains underexplored. This paper benchmarks LLMs for PennyLane-based quantum
code generation using real-world challenges from the Quantum Hackathon (QHack).
We introduce QHackBench, a novel benchmark dataset derived from QHack
competitions, and evaluate model performance under vanilla prompting and
Retrieval-Augmented Generation (RAG). Our structured evaluation framework
assesses functional correctness, syntactic validity, and execution success
across varying challenge difficulties. Results indicate that RAG-enhanced
models, supplemented with an augmented PennyLane dataset, approximately
generate similar results as the standard prompting, particularly in complex
quantum algorithms. Additionally, we introduce a multi-agent evaluation
pipeline that iteratively refines incorrect solutions, further enhancing
execution success rates. To foster further research, we commit to publicly
releasing QHackBench, along with our evaluation framework and experimental
results, enabling continued advancements in AI-assisted quantum programming.

</details>


### [70] [Accurate and Energy Efficient: Local Retrieval-Augmented Generation Models Outperform Commercial Large Language Models in Medical Tasks](https://arxiv.org/abs/2506.20009)
*Konstantinos Vrettos,Michail E. Klontzas*

Main category: cs.AI

TL;DR: 研究表明，基于开源LLM的自定义RAG框架在医疗任务中表现优于商业模型，同时显著降低能耗和碳排放。


<details>
  <summary>Details</summary>
Motivation: 人工智能在医疗领域的广泛应用引发了对环境与伦理问题的担忧，特别是商业大语言模型的高资源消耗及患者隐私安全问题。

Method: 开发了可监控能耗的RAG框架，测试了包括llama3.1:8b和medgemma-4b-it在内的开源模型，并与DeepSeekV3-R1等商业模型进行对比评估。

Result: llama3.1-RAG模型以58.5%准确率优于所有对比模型，单位能耗性能达0.52，总碳排放仅473克，比o4-mini节能172%且准确率更高。

Conclusion: 本地化LLM开发的RAG系统在医疗领域兼具性能与环保优势，模块化框架符合联合国可持续发展目标。

Abstract: Background The increasing adoption of Artificial Intelligence (AI) in
healthcare has sparked growing concerns about its environmental and ethical
implications. Commercial Large Language Models (LLMs), such as ChatGPT and
DeepSeek, require substantial resources, while the utilization of these systems
for medical purposes raises critical issues regarding patient privacy and
safety. Methods We developed a customizable Retrieval-Augmented Generation
(RAG) framework for medical tasks, which monitors its energy usage and CO2
emissions. This system was then used to create RAGs based on various
open-source LLMs. The tested models included both general purpose models like
llama3.1:8b and medgemma-4b-it, which is medical-domain specific. The best RAGs
performance and energy consumption was compared to DeepSeekV3-R1 and OpenAIs
o4-mini model. A dataset of medical questions was used for the evaluation.
Results Custom RAG models outperformed commercial models in accuracy and energy
consumption. The RAG model built on llama3.1:8B achieved the highest accuracy
(58.5%) and was significantly better than other models, including o4-mini and
DeepSeekV3-R1. The llama3.1-RAG also exhibited the lowest energy consumption
and CO2 footprint among all models, with a Performance per kWh of 0.52 and a
total CO2 emission of 473g. Compared to o4-mini, the llama3.1-RAG achieved 2.7x
times more accuracy points per kWh and 172% less electricity usage while
maintaining higher accuracy. Conclusion Our study demonstrates that local LLMs
can be leveraged to develop RAGs that outperform commercial, online LLMs in
medical tasks, while having a smaller environmental impact. Our modular
framework promotes sustainable AI development, reducing electricity usage and
aligning with the UNs Sustainable Development Goals.

</details>


### [71] [Achieving Trustworthy Real-Time Decision Support Systems with Low-Latency Interpretable AI Models](https://arxiv.org/abs/2506.20018)
*Zechun Deng,Ziwei Liu,Ziqian Bi,Junhao Song,Chia Xin Liang,Joe Yeong,Junfeng Hao*

Main category: cs.AI

TL;DR: 本文探讨了利用低延迟AI模型的实时决策支持系统，结合了整体AI驱动决策工具、边缘物联网技术集成以及有效人机协作方法的最新进展。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决资源有限情况下的决策支持问题，探索如何通过大型语言模型等技术提升决策效率。

Method: 通过详细综述，分析了DeLLMa等技术发展、模型压缩方法及边缘设备分析改进，并讨论了资源限制和适应性框架需求。

Result: 研究提供了开发策略和应用领域的实用视角，指出了构建更高效灵活AI支持系统的机会。

Conclusion: 结论为这一快速变化领域的未来突破奠定了基础，强调了AI如何重塑实时决策支持。

Abstract: This paper investigates real-time decision support systems that leverage
low-latency AI models, bringing together recent progress in holistic AI-driven
decision tools, integration with Edge-IoT technologies, and approaches for
effective human-AI teamwork. It looks into how large language models can assist
decision-making, especially when resources are limited. The research also
examines the effects of technical developments such as DeLLMa, methods for
compressing models, and improvements for analytics on edge devices, while also
addressing issues like limited resources and the need for adaptable frameworks.
Through a detailed review, the paper offers practical perspectives on
development strategies and areas of application, adding to the field by
pointing out opportunities for more efficient and flexible AI-supported
systems. The conclusions set the stage for future breakthroughs in this
fast-changing area, highlighting how AI can reshape real-time decision support.

</details>


### [72] [Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning](https://arxiv.org/abs/2506.20020)
*Saloni Dash,Amélie Reymond,Emma S. Spiro,Aylin Caliskan*

Main category: cs.AI

TL;DR: 研究发现，大型语言模型（LLMs）在赋予特定政治和社会人口属性的人设后，会表现出类似人类的动机性推理偏差，这种偏差难以通过常规提示方法消除。


<details>
  <summary>Details</summary>
Motivation: 人类推理常因身份保护等动机产生偏见，影响理性决策。集体层面的动机性推理在讨论气候变化或疫苗安全等关键问题时可能加剧社会分裂。此前研究表明LLMs也存在类似认知偏差，但其是否因身份认同选择性推理尚不明确。

Method: 研究为8个LLMs（开源和商业模型）赋予4类政治/社会属性的8种人设，测试其在两项人类研究任务中的表现：错误信息标题真实性判断和数字科学证据评估。

Result: 带人设的LLMs真实性判断准确率下降达9%。政治人设模型在枪控证据评估中，当事实与其政治身份一致时正确率提升90%。现有提示去偏方法基本无效。

Conclusion: 首次证实LLMs会表现出顽固的类人动机性推理，常规去偏方法难以缓解，可能加剧LLMs和人类身份认同驱动的非理性推理。

Abstract: Reasoning in humans is prone to biases due to underlying motivations like
identity protection, that undermine rational decision-making and judgment. This
motivated reasoning at a collective level can be detrimental to society when
debating critical issues such as human-driven climate change or vaccine safety,
and can further aggravate political polarization. Prior studies have reported
that large language models (LLMs) are also susceptible to human-like cognitive
biases, however, the extent to which LLMs selectively reason toward
identity-congruent conclusions remains largely unexplored. Here, we investigate
whether assigning 8 personas across 4 political and socio-demographic
attributes induces motivated reasoning in LLMs. Testing 8 LLMs (open source and
proprietary) across two reasoning tasks from human-subject studies -- veracity
discernment of misinformation headlines and evaluation of numeric scientific
evidence -- we find that persona-assigned LLMs have up to 9% reduced veracity
discernment relative to models without personas. Political personas
specifically, are up to 90% more likely to correctly evaluate scientific
evidence on gun control when the ground truth is congruent with their induced
political identity. Prompt-based debiasing methods are largely ineffective at
mitigating these effects. Taken together, our empirical findings are the first
to suggest that persona-assigned LLMs exhibit human-like motivated reasoning
that is hard to mitigate through conventional debiasing prompts -- raising
concerns of exacerbating identity-congruent reasoning in both LLMs and humans.

</details>


### [73] [DiaLLMs: EHR Enhanced Clinical Conversational System for Clinical Test Recommendation and Diagnosis Prediction](https://arxiv.org/abs/2506.20059)
*Weijieying Ren,Tianxiang Zhao,Lei Wang,Tianchun Wang,Vasant Honavar*

Main category: cs.AI

TL;DR: 提出首个整合电子健康记录(EHR)的医疗大语言模型DiaLLM，通过临床测试参考策略和强化学习框架，实现临床检查推荐、结果解读和诊断预测，显著提升临床适用性。


<details>
  <summary>Details</summary>
Motivation: 现有医疗大语言模型忽视电子健康记录(EHR)的核心作用且仅关注诊断推荐，限制了临床实用性。需开发能整合EHR数据并支持全流程临床决策的模型。

Method: 1) 设计临床测试参考(CTR)策略将临床代码映射为可读描述并分类检测结果\n2) 采用强化学习框架进行证据收集和自动诊断\n3) 引入拒绝采样策略缩减动作空间\n4) 设计确认奖励和类别敏感诊断奖励机制

Result: 实验表明DiaLLM在临床检查推荐和诊断预测任务上全面超越基线模型，验证了EHR整合与强化学习框架的有效性。

Conclusion: DiaLLM通过创新性地融合EHR数据与对话系统，建立了更符合真实医疗场景的决策支持范式，为医疗AI的临床落地提供了新方向。

Abstract: Recent advances in Large Language Models (LLMs) have led to remarkable
progresses in medical consultation. However, existing medical LLMs overlook the
essential role of Electronic Health Records (EHR) and focus primarily on
diagnosis recommendation, limiting their clinical applicability. We propose
DiaLLM, the first medical LLM that integrates heterogeneous EHR data into
clinically grounded dialogues, enabling clinical test recommendation, result
interpretation, and diagnosis prediction to better align with real-world
medical practice. To construct clinically grounded dialogues from EHR, we
design a Clinical Test Reference (CTR) strategy that maps each clinical code to
its corresponding description and classifies test results as "normal" or
"abnormal". Additionally, DiaLLM employs a reinforcement learning framework for
evidence acquisition and automated diagnosis. To handle the large action space,
we introduce a reject sampling strategy to reduce redundancy and improve
exploration efficiency. Furthermore, a confirmation reward and a
class-sensitive diagnosis reward are designed to guide accurate diagnosis
prediction. Extensive experimental results demonstrate that DiaLLM outperforms
baselines in clinical test recommendation and diagnosis prediction.

</details>


### [74] [AI Copilots for Reproducibility in Science: A Case Study](https://arxiv.org/abs/2506.20130)
*Adrien Bibal,Steven N. Minton,Deborah Khider,Yolanda Gil*

Main category: cs.AI

TL;DR: 本文介绍OpenPub平台及其AI驱动的可复现性助手，该工具通过分析论文材料生成结构化Jupyter Notebook，将复现时间从30小时缩短至1小时，显著提升计算复现效率。


<details>
  <summary>Details</summary>
Motivation: 开放科学倡议虽推动研究透明化，但成果独立复现仍具挑战性。本研究旨在通过AI工具降低复现负担，促进可验证的科学交流。

Method: 开发模块化OpenPub平台，其核心'可复现性助手'能解析稿件、代码及补充材料，自动生成带修复建议的Jupyter Notebook，并系统性检测复现障碍如缺失超参数、未记录预处理步骤等。

Result: 在已知复现基准的论文测试中，系统将复现时间从30+小时压缩至约1小时，对图表和结果的计算复现覆盖率高，并能准确识别各类复现壁垒。

Conclusion: AI工具可有效减轻复现工作负担，模块化架构为拓展其他开放科学目标奠定基础，有助于提升科研透明度和可验证性。

Abstract: Open science initiatives seek to make research outputs more transparent,
accessible, and reusable, but ensuring that published findings can be
independently reproduced remains a persistent challenge. This paper introduces
OpenPub, an AI-powered platform that supports researchers, reviewers, and
readers through a suite of modular copilots focused on key open science tasks.
In this work, we present the Reproducibility Copilot, which analyzes
manuscripts, code, and supplementary materials to generate structured Jupyter
Notebooks and recommendations aimed at facilitating computational, or "rote",
reproducibility. We conducted feasibility tests using previously studied
research papers with known reproducibility benchmarks. Results indicate that
OpenPub can substantially reduce reproduction time - from over 30 hours to
about 1 hour - while achieving high coverage of figures, tables, and results
suitable for computational reproduction. The system systematically detects
barriers to reproducibility, including missing hyperparameters, undocumented
preprocessing steps, and incomplete or inaccessible datasets. These findings
suggest that AI-driven tools can meaningfully reduce the burden of
reproducibility efforts and contribute to more transparent and verifiable
scientific communication. The modular copilot architecture also provides a
foundation for extending AI assistance to additional open science objectives
beyond reproducibility.

</details>


### [75] [Language Modeling by Language Models](https://arxiv.org/abs/2506.20249)
*Junyan Cheng,Peter Clark,Kyle Richardson*

Main category: cs.AI

TL;DR: 提出多智能体LLM系统Genesys，通过模拟研究流程（提案、实现、验证）自动发现新型语言模型架构，采用遗传编程框架提升效率，实验验证1062个新设计，部分性能超越现有架构。


<details>
  <summary>Details</summary>
Motivation: 探索利用LLM自动化发现新型语言模型架构的可能性，解决人工设计效率低下的问题。

Method: 1) 多智能体模拟研究全流程（提案→代码生成→预训练→评估） 2) 采用阶梯式规模验证（14M~350M参数） 3) 创新遗传编程框架替代直接提示生成

Result: 1) 生成1162个新架构，1062个完成全流程验证 2) 最佳设计在6/9基准测试中超越GPT2、Mamba2 3) 遗传编程使成功生成率提升约86%

Conclusion: Genesys系统证明LLM可有效自动化架构探索，遗传编程框架显著提升效率，为自主发现系统设计提供新见解。

Abstract: Can we leverage LLMs to model the process of discovering novel language model
(LM) architectures? Inspired by real research, we propose a multi-agent LLM
approach that simulates the conventional stages of research, from ideation and
literature search (proposal stage) to design implementation (code generation),
generative pre-training, and downstream evaluation (verification). Using ideas
from scaling laws, our system, Genesys, employs a Ladder of Scales approach;
new designs are proposed, adversarially reviewed, implemented, and selectively
verified at increasingly larger model scales (14M$\sim$350M parameters) with a
narrowing budget (the number of models we can train at each scale). To help
make discovery efficient and factorizable, Genesys uses a novel genetic
programming backbone, which we show has empirical advantages over commonly used
direct prompt generation workflows (e.g., $\sim$86\% percentage point
improvement in successful design generation, a key bottleneck). We report
experiments involving 1,162 newly discovered designs (1,062 fully verified
through pre-training) and find the best designs to be highly competitive with
known architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common
benchmarks). We couple these results with comprehensive system-level ablations
and formal results, which give broader insights into the design of effective
autonomous discovery systems.

</details>


### [76] [Enterprise Large Language Model Evaluation Benchmark](https://arxiv.org/abs/2506.20274)
*Liya Wang,David Yi,Damien Jose,John Passarelli,James Gao,Jordan Leventis,Kang Li*

Main category: cs.AI

TL;DR: 本文提出一个基于布鲁姆分类法的14任务框架，用于全面评估大语言模型(LLM)在企业场景中的能力，并构建了包含9700个样本的基准测试。研究发现开源模型在推理任务上可媲美商业模型，但在判断类任务中存在过度思考问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试(如MMLU)无法充分评估LLM在企业特定任务中的复杂表现，亟需开发更贴合企业需求的评估体系。

Method: 开发可扩展的标注流程，结合LLM作为标注员、LLM作为评判员以及纠错检索增强生成(CRAG)技术，构建了包含9700个样本的鲁棒基准数据集。

Result: 评估6个主流模型显示：开源模型(如DeepSeek R1)在推理任务上表现接近商业模型，但在判断类场景中因过度思考而落后；基准测试揭示了企业应用中的关键性能差距。

Conclusion: 本研究为企业提供了定制化评估蓝图，推动LLM的实际部署应用，并为模型优化提供了可操作的改进方向。

Abstract: Large Language Models (LLMs) ) have demonstrated promise in boosting
productivity across AI-powered tools, yet existing benchmarks like Massive
Multitask Language Understanding (MMLU) inadequately assess enterprise-specific
task complexities. We propose a 14-task framework grounded in Bloom's Taxonomy
to holistically evaluate LLM capabilities in enterprise contexts. To address
challenges of noisy data and costly annotation, we develop a scalable pipeline
combining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented
generation (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six
leading models shows open-source contenders like DeepSeek R1 rival proprietary
models in reasoning tasks but lag in judgment-based scenarios, likely due to
overthinking. Our benchmark reveals critical enterprise performance gaps and
offers actionable insights for model optimization. This work provides
enterprises a blueprint for tailored evaluations and advances practical LLM
deployment.

</details>


### [77] [Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards](https://arxiv.org/abs/2506.20332)
*Jihao Gu,Qihang Ai,Yingyao Wang,Pi Bu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Ziming Wang,Yingxiu Zhao,Ming-Liang Zhang,Jun Song,Yuning Jiang,Bo Zheng*

Main category: cs.AI

TL;DR: 本文提出Mobile-R1方法，通过任务级奖励的多轮交互强化学习提升移动代理的探索与纠错能力，并开源了包含数据集、基准测试及模型权重的资源。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的移动代理虽能理解复杂指令并优化动作输出，但因依赖离线强化学习或动作级奖励，导致环境交互受限，易陷入局部最优，探索与纠错能力不足。

Method: 提出三阶段训练框架：1)初始格式微调；2)基于动作级奖励的单步在线训练；3)基于多轮轨迹的任务级奖励在线训练，以增强代理的动态交互能力。

Result: 构建了覆盖28个中文应用的24,521条标注数据集及500条轨迹的基准测试，Mobile-R1性能显著提升，所有资源将开源。

Conclusion: Mobile-R1通过任务级多轮强化学习有效解决了移动代理的局部最优问题，其开源资源将推动相关领域研究。

Abstract: Vision-language model-based mobile agents have gained the ability to not only
understand complex instructions and mobile screenshots, but also optimize their
action outputs via thinking and reasoning, benefiting from reinforcement
learning, such as Group Relative Policy Optimization (GRPO). However, existing
research centers on offline reinforcement learning training or online
optimization using action-level rewards, which limits the agent's dynamic
interaction with the environment. This often results in agents settling into
local optima, thereby weakening their ability for exploration and error action
correction. To address these challenges, we introduce an approach called
Mobile-R1, which employs interactive multi-turn reinforcement learning with
task-level rewards for mobile agents. Our training framework consists of three
stages: initial format finetuning, single-step online training via action-level
reward, followed by online training via task-level reward based on multi-turn
trajectories. This strategy is designed to enhance the exploration and error
correction capabilities of Mobile-R1, leading to significant performance
improvements. Moreover, we have collected a dataset covering 28 Chinese
applications with 24,521 high-quality manual annotations and established a new
benchmark with 500 trajectories. We will open source all resources, including
the dataset, benchmark, model weight, and codes:
https://mobile-r1.github.io/Mobile-R1/.

</details>


### [78] [Tabular Feature Discovery With Reasoning Type Exploration](https://arxiv.org/abs/2506.20357)
*Sungwon Han,Sungkyu Park,Seungeon Lee*

Main category: cs.AI

TL;DR: 本文提出了一种名为REFeat的新方法，通过引导大型语言模型（LLM）利用多种推理类型生成多样且信息丰富的特征，解决了现有LLM方法在表格数据特征工程中生成特征过于简单或重复的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的表格数据特征生成方法存在生成特征过于简单或重复的问题，部分原因是LLM选择的转换存在固有偏差以及生成过程中缺乏结构化推理指导。

Method: REFeat方法通过引导LLM利用多种推理类型（如因果推理、类比推理等）来指导特征生成过程，从而生成多样且信息丰富的特征。

Result: 在59个基准数据集上的实验表明，REFeat不仅平均预测准确率更高，而且能够发现更多样且更有意义的特征。

Conclusion: 这些结果凸显了将丰富的推理模式和自适应策略选择融入LLM驱动的表格数据特征发现中的潜力。

Abstract: Feature engineering for tabular data remains a critical yet challenging step
in machine learning. Recently, large language models (LLMs) have been used to
automatically generate new features by leveraging their vast knowledge.
However, existing LLM-based approaches often produce overly simple or
repetitive features, partly due to inherent biases in the transformations the
LLM chooses and the lack of structured reasoning guidance during generation. In
this paper, we propose a novel method REFeat, which guides an LLM to discover
diverse and informative features by leveraging multiple types of reasoning to
steer the feature generation process. Experiments on 59 benchmark datasets
demonstrate that our approach not only achieves higher predictive accuracy on
average, but also discovers more diverse and meaningful features. These results
highlight the promise of incorporating rich reasoning paradigms and adaptive
strategy selection into LLM-driven feature discovery for tabular data.

</details>


### [79] [Paladin-mini: A Compact and Efficient Grounding Model Excelling in Real-World Scenarios](https://arxiv.org/abs/2506.20384)
*Dror Ivry,Oran Nahum*

Main category: cs.AI

TL;DR: 本文提出了Paladin-mini（3.8B参数的开源分类模型）和grounding-benchmark评估数据集，用于解决上下文中的声明验证问题，并展示了其与当前最先进技术的对比结果。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在给定上下文中验证声明是否有支持证据的问题（即声明接地问题），这对现实场景中的关键推理任务至关重要。

Method: 方法包括：1) 开发紧凑型开源分类模型Paladin-mini（3.8B参数）；2) 构建新的评估数据集grounding-benchmark；3) 与现有最优模型进行基准测试对比。

Result: 实验结果表明Paladin-mini在真实场景中表现稳健，论文提供了清晰可复现的基准测试结果。

Conclusion: Paladin-mini和grounding-benchmark为声明接地问题提供了有效的解决方案和评估标准，其紧凑模型设计尤其适合实际应用部署。

Abstract: This paper introduces two significant contributions to address the issue of
grounding claims in a given context. Grounding means that given a context
(document) and a claim, there's at least one supportive evidence for the claim
in the document. We will introduce Paladin-mini, a compact (3.8B parameters)
open-source classifier model (used for labeling data as grounded or ungrounded)
engineered for robust performance in real-world scenarios, and the
grounding-benchmark, a new evaluation dataset designed to assess performance on
critical reasoning tasks. We'll also demonstrate the results of Paladin-mini
with benchmarks against the current State-of-the-art and share clear and
reproducible results.

</details>


### [80] [Smart Ride and Delivery Services with Electric Vehicles: Leveraging Bidirectional Charging for Profit Optimisation](https://arxiv.org/abs/2506.20401)
*Jinchun Du,Bojie Shen,Muhammad Aamir Cheema,Adel N. Toosi*

Main category: cs.AI

TL;DR: 本文提出电动汽车定向问题与车网互动（EVOP-V2G）模型，通过混合整数规划和元启发式算法优化电动车司机的利润，实验显示该方法可显著提升收益并支持电网。


<details>
  <summary>Details</summary>
Motivation: 随着电动车在共享出行中的普及，其续航短和充电管理问题日益突出。车网互动（V2G）技术带来新机遇，但也增加了运营复杂性，需开发智能调度方案以最大化司机利润。

Method: 建立混合整数规划（MIP）模型，提出两种近优元启发式算法：进化算法（EA）和大邻域搜索（LNS），以动态电价、充电站选择和路径约束为变量进行优化。

Result: 真实数据实验表明，相比基线方法，该算法可使司机利润翻倍，在小规模实例中接近最优解，且在大规模实例中展现出色扩展性。

Conclusion: 研究为电动车智能调度系统提供了高效解决方案，既能提升司机收益，又能通过V2G技术主动支持电网，推动可持续交通发展。

Abstract: With the rising popularity of electric vehicles (EVs), modern service
systems, such as ride-hailing delivery services, are increasingly integrating
EVs into their operations. Unlike conventional vehicles, EVs often have a
shorter driving range, necessitating careful consideration of charging when
fulfilling requests. With recent advances in Vehicle-to-Grid (V2G) technology -
allowing EVs to also discharge energy back to the grid - new opportunities and
complexities emerge. We introduce the Electric Vehicle Orienteering Problem
with V2G (EVOP-V2G): a profit-maximization problem where EV drivers must select
customer requests or orders while managing when and where to charge or
discharge. This involves navigating dynamic electricity prices, charging
station selection, and route constraints. We formulate the problem as a Mixed
Integer Programming (MIP) model and propose two near-optimal metaheuristic
algorithms: one evolutionary (EA) and the other based on large neighborhood
search (LNS). Experiments on real-world data show our methods can double driver
profits compared to baselines, while maintaining near-optimal performance on
small instances and excellent scalability on larger ones. Our work highlights a
promising path toward smarter, more profitable EV-based mobility systems that
actively support the energy grid.

</details>


### [81] [GymPN: A Library for Decision-Making in Process Management Systems](https://arxiv.org/abs/2506.20404)
*Riccardo Lo Bianco,Willem van Jaarsveld,Remco Dijkman*

Main category: cs.AI

TL;DR: 本文介绍了一个名为GymPN的软件库，利用深度强化学习优化业务流程中的决策制定，解决了部分流程可观察性和多决策建模的关键问题。


<details>
  <summary>Details</summary>
Motivation: 业务流程管理系统需要优化任务分配、执行时机和人员指派等关键决策，现有工具在支持这些决策时存在局限性。

Method: GymPN基于深度强化学习，新增了对部分流程可观察性和多决策建模的支持，突破了以往工作的限制。

Result: 在八种典型业务流程决策问题模式上的评估表明，GymPN能轻松建模目标问题并学习最优决策策略。

Conclusion: GymPN通过创新性地解决部分可观察性和多决策问题，为业务流程提供了更贴近现实的决策支持工具。

Abstract: Process management systems support key decisions about the way work is
allocated in organizations. This includes decisions on which task to perform
next, when to execute the task, and who to assign the task to. Suitable
software tools are required to support these decisions in a way that is optimal
for the organization. This paper presents a software library, called GymPN,
that supports optimal decision-making in business processes using Deep
Reinforcement Learning. GymPN builds on previous work that supports task
assignment in business processes, introducing two key novelties: support for
partial process observability and the ability to model multiple decisions in a
business process. These novel elements address fundamental limitations of
previous work and thus enable the representation of more realistic process
decisions. We evaluate the library on eight typical business process
decision-making problem patterns, showing that GymPN allows for easy modeling
of the desired problems, as well as learning optimal decision policies.

</details>


### [82] [Mixtures of Neural Cellular Automata: A Stochastic Framework for Growth Modelling and Self-Organization](https://arxiv.org/abs/2506.20486)
*Salvatore Milite,Giulio Caravagna,Andrea Sottoriva*

Main category: cs.AI

TL;DR: 本文提出混合神经细胞自动机（MNCA），通过引入概率规则和固有噪声，增强了对生物系统随机性的建模能力，在组织生长、图像形态生成和显微镜图像分割中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统神经细胞自动机（NCA）的确定性限制了其对真实生物物理系统随机性的建模能力，需要开发能捕捉随机动态的新框架。

Method: 将混合模型思想融入NCA范式，结合概率规则分配和固有噪声，构建MNCA框架以模拟多样化局部行为和生物随机过程。

Result: MNCA在组织生长模拟、图像形态生成鲁棒性和显微镜图像分割中展现出更强的抗干扰能力、更真实的生物生长模式复现及可解释的规则分割。

Conclusion: MNCA作为建模随机动力系统的有力工具，为自生长过程研究提供了新途径，在生命科学领域具有应用潜力。

Abstract: Neural Cellular Automata (NCAs) are a promising new approach to model
self-organizing processes, with potential applications in life science.
However, their deterministic nature limits their ability to capture the
stochasticity of real-world biological and physical systems.
  We propose the Mixture of Neural Cellular Automata (MNCA), a novel framework
incorporating the idea of mixture models into the NCA paradigm. By combining
probabilistic rule assignments with intrinsic noise, MNCAs can model diverse
local behaviors and reproduce the stochastic dynamics observed in biological
processes.
  We evaluate the effectiveness of MNCAs in three key domains: (1) synthetic
simulations of tissue growth and differentiation, (2) image morphogenesis
robustness, and (3) microscopy image segmentation. Results show that MNCAs
achieve superior robustness to perturbations, better recapitulate real
biological growth patterns, and provide interpretable rule segmentation. These
findings position MNCAs as a promising tool for modeling stochastic dynamical
systems and studying self-growth processes.

</details>


### [83] [Engineering Sentience](https://arxiv.org/abs/2506.20504)
*Konstantin Demin,Taylor Webb,Eric Elmoznino,Hakwan Lau*

Main category: cs.AI

TL;DR: 本文提出了一个适用于机器设计的感知定义，强调功能性计算实现与主观体验的结合，并探讨了潜在实现方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在为AI设计有意义的感知能力，避免无意中创造具有感知的人工智能，并及时识别其存在。

Method: 提出感知需具备断言性（持久性）与质性特征，并结合当前技术勾勒可能的实现路径。

Result: 构建了功能性感知的理论框架，说明特定感官信号需满足双重特性才能实现人工感知。

Conclusion: 明确人工代理功能性感知的实现条件，既有助于定向开发，也能预警非预期感知体的产生。

Abstract: We spell out a definition of sentience that may be useful for designing and
building it in machines. We propose that for sentience to be meaningful for AI,
it must be fleshed out in functional, computational terms, in enough detail to
allow for implementation. Yet, this notion of sentience must also reflect
something essentially 'subjective', beyond just having the general capacity to
encode perceptual content. For this specific functional notion of sentience to
occur, we propose that certain sensory signals need to be both assertoric
(persistent) and qualitative. To illustrate the definition in more concrete
terms, we sketch out some ways for potential implementation, given current
technology. Understanding what it takes for artificial agents to be
functionally sentient can also help us avoid creating them inadvertently, or at
least, realize that we have created them in a timely manner.

</details>


### [84] [Case-based Reasoning Augmented Large Language Model Framework for Decision Making in Realistic Safety-Critical Driving Scenarios](https://arxiv.org/abs/2506.20531)
*Wenbin Gan,Minh-Son Dao,Koji Zettsu*

Main category: cs.AI

TL;DR: 本文提出了一种基于案例推理增强的大型语言模型（CBR-LLM）框架，用于复杂风险场景下的紧急避障决策，通过结合语义场景理解和历史驾驶案例检索，提升决策准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 安全关键场景下的驾驶需要快速、基于情境的决策，但现有大型语言模型（LLM）在领域适应、情境接地和缺乏经验知识方面存在局限，难以在动态高风险环境中做出可靠决策。

Method: 提出CBR-LLM框架，整合行车记录仪视频的语义场景理解与历史驾驶案例检索，利用风险感知提示策略和相似性案例检索增强LLM的上下文学习能力。

Result: 实验表明，该框架显著提高了决策准确性、理由质量以及与人类专家行为的一致性，相似性案例检索在上下文学习中优于随机采样。

Conclusion: 案例研究验证了框架在真实复杂场景中的鲁棒性，表明其可作为智能驾驶系统的自适应、可信赖决策支持工具。

Abstract: Driving in safety-critical scenarios requires quick, context-aware
decision-making grounded in both situational understanding and experiential
reasoning. Large Language Models (LLMs), with their powerful general-purpose
reasoning capabilities, offer a promising foundation for such decision-making.
However, their direct application to autonomous driving remains limited due to
challenges in domain adaptation, contextual grounding, and the lack of
experiential knowledge needed to make reliable and interpretable decisions in
dynamic, high-risk environments. To address this gap, this paper presents a
Case-Based Reasoning Augmented Large Language Model (CBR-LLM) framework for
evasive maneuver decision-making in complex risk scenarios. Our approach
integrates semantic scene understanding from dashcam video inputs with the
retrieval of relevant past driving cases, enabling LLMs to generate maneuver
recommendations that are both context-sensitive and human-aligned. Experiments
across multiple open-source LLMs show that our framework improves decision
accuracy, justification quality, and alignment with human expert behavior.
Risk-aware prompting strategies further enhance performance across diverse risk
types, while similarity-based case retrieval consistently outperforms random
sampling in guiding in-context learning. Case studies further demonstrate the
framework's robustness in challenging real-world conditions, underscoring its
potential as an adaptive and trustworthy decision-support tool for intelligent
driving systems.

</details>


### [85] [Fine-Tuning and Prompt Engineering of LLMs, for the Creation of Multi-Agent AI for Addressing Sustainable Protein Production Challenges](https://arxiv.org/abs/2506.20598)
*Alexander D. Kalian,Jaewook Lee,Stefan P. Johannesson,Lennart Otte,Christer Hogstrand,Miao Guo*

Main category: cs.AI

TL;DR: 研究提出了一种多智能体AI框架，用于支持可持续蛋白质生产研究，重点关注微生物蛋白质来源，通过检索增强生成（RAG）系统优化文献搜索和信息提取，并开发了用户界面。


<details>
  <summary>Details</summary>
Motivation: 全球对可持续蛋白质来源的需求加速了开发智能工具的需求，以快速处理和合成特定领域的科学知识。

Method: 研究采用了基于GPT的大型语言模型（LLM）构建了两个智能体：一个用于检索微生物蛋白质生产相关文献，另一个用于提取生物和化学信息。通过微调和提示工程两种方法优化智能体性能。

Result: 两种优化方法均有效提升了信息提取智能体的性能，基于变换器的余弦相似度得分最高提升了25%，平均得分达到$\geq 0.89$。微调方法平均得分更高（$\geq 0.94$），而提示工程方法的统计不确定性较低。

Conclusion: 多智能体AI框架在可持续蛋白质生产研究中表现出潜力，微调方法在性能提升上更为显著，同时开发了用户界面以支持系统使用。

Abstract: The global demand for sustainable protein sources has accelerated the need
for intelligent tools that can rapidly process and synthesise domain-specific
scientific knowledge. In this study, we present a proof-of-concept multi-agent
Artificial Intelligence (AI) framework designed to support sustainable protein
production research, with an initial focus on microbial protein sources. Our
Retrieval-Augmented Generation (RAG)-oriented system consists of two GPT-based
LLM agents: (1) a literature search agent that retrieves relevant scientific
literature on microbial protein production for a specified microbial strain,
and (2) an information extraction agent that processes the retrieved content to
extract relevant biological and chemical information. Two parallel
methodologies, fine-tuning and prompt engineering, were explored for agent
optimisation. Both methods demonstrated effectiveness at improving the
performance of the information extraction agent in terms of transformer-based
cosine similarity scores between obtained and ideal outputs. Mean cosine
similarity scores were increased by up to 25%, while universally reaching mean
scores of $\geq 0.89$ against ideal output text. Fine-tuning overall improved
the mean scores to a greater extent (consistently of $\geq 0.94$) compared to
prompt engineering, although lower statistical uncertainties were observed with
the latter approach. A user interface was developed and published for enabling
the use of the multi-agent AI system, alongside preliminary exploration of
additional chemical safety-based search capabilities

</details>


### [86] [CogGen: A Learner-Centered Generative AI Architecture for Intelligent Tutoring with Programming Video](https://arxiv.org/abs/2506.20600)
*Wengxi Li,Roy Pea,Nick Haber,Hari Subramonyam*

Main category: cs.AI

TL;DR: CogGen是一种以学习者为中心的AI架构，通过将学生建模与基于认知学徒框架的生成式AI辅导相结合，将编程视频转化为互动、自适应的学习体验。


<details>
  <summary>Details</summary>
Motivation: 当前视频编程教育缺乏互动性和个性化，CogGen旨在通过AI技术弥补这一缺陷，提升学习效果。

Method: 架构包含三个核心组件：(1)按学习目标分割视频，(2)应用认知学徒策略的对话式辅导引擎，(3)基于贝叶斯知识追踪（Bayesian Knowledge Tracing）的自适应学生模型。

Result: 技术评估显示视频分割准确率高，且在教学的知识、方法、行动和互动层面均表现出强教育一致性。消融实验证实各组件对生成有效指导均不可或缺。

Conclusion: 该研究通过结合结构化学生建模与交互式AI对话，推动了AI辅助教学的发展，为规模化提升视频编程教育提供了可行方案。

Abstract: We introduce CogGen, a learner-centered AI architecture that transforms
programming videos into interactive, adaptive learning experiences by
integrating student modeling with generative AI tutoring based on the Cognitive
Apprenticeship framework. The architecture consists of three components: (1)
video segmentation by learning goals, (2) a conversational tutoring engine
applying Cognitive Apprenticeship strategies, and (3) a student model using
Bayesian Knowledge Tracing to adapt instruction. Our technical evaluation
demonstrates effective video segmentation accuracy and strong pedagogical
alignment across knowledge, method, action, and interaction layers. Ablation
studies confirm the necessity of each component in generating effective
guidance. This work advances AI-powered tutoring by bridging structured student
modeling with interactive AI conversations, offering a scalable approach to
enhancing video-based programming education.

</details>


### [87] [AI Assistants to Enhance and Exploit the PETSc Knowledge Base](https://arxiv.org/abs/2506.20608)
*Barry Smith,Junchao Zhang,Hong Zhang,Lois Curfman McInnes,Murat Keceli,Archit Vasan,Satish Balay,Toby Isaac,Le Chen,Venkatram Vishwanath*

Main category: cs.AI

TL;DR: PETSc团队利用大型语言模型（LLM）构建知识管理系统，整合分散的技术知识，通过RAG、重排序算法和聊天机器人等工具提升用户支持与开发效率，重点关注可扩展Krylov求解器，旨在建立科学软件中知识中心AI的扩展框架。


<details>
  <summary>Details</summary>
Motivation: PETSc作为高性能科学计算库，30年积累的知识分散且非结构化，难以被用户和开发者有效利用，需通过AI技术激活这些知识资源。

Method: 结合检索增强生成（RAG）、重排序算法和定制聊天机器人，利用Argonne领导计算设施资源，评估不同LLM和嵌入模型，设计用户界面。

Result: 初步构建了面向PETSc的LLM工具系统，验证了其在增强数值软件开发和使用中的潜力，特别是对可扩展Krylov求解器的支持。

Conclusion: 提出扩展该系统为动态演进平台的愿景，通过知识中心AI推动科学软件生态发展，加速科研发现进程。

Abstract: Generative AI, especially through large language models (LLMs), is
transforming how technical knowledge can be accessed, reused, and extended.
PETSc, a widely used numerical library for high-performance scientific
computing, has accumulated a rich but fragmented knowledge base over its three
decades of development, spanning source code, documentation, mailing lists,
GitLab issues, Discord conversations, technical papers, and more. Much of this
knowledge remains informal and inaccessible to users and new developers. To
activate and utilize this knowledge base more effectively, the PETSc team has
begun building an LLM-powered system that combines PETSc content with custom
LLM tools -- including retrieval-augmented generation (RAG), reranking
algorithms, and chatbots -- to assist users, support developers, and propose
updates to formal documentation. This paper presents initial experiences
designing and evaluating these tools, focusing on system architecture, using
RAG and reranking for PETSc-specific information, evaluation methodologies for
various LLMs and embedding models, and user interface design. Leveraging the
Argonne Leadership Computing Facility resources, we analyze how LLM responses
can enhance the development and use of numerical software, with an initial
focus on scalable Krylov solvers. Our goal is to establish an extensible
framework for knowledge-centered AI in scientific software, enabling scalable
support, enriched documentation, and enhanced workflows for research and
development. We conclude by outlining directions for expanding this system into
a robust, evolving platform that advances software ecosystems to accelerate
scientific discovery.

</details>


### [88] [Towards Community-Driven Agents for Machine Learning Engineering](https://arxiv.org/abs/2506.20640)
*Sijie Li,Weiwei Sun,Shanda Li,Ameet Talwalkar,Yiming Yang*

Main category: cs.AI

TL;DR: 本文介绍了MLE-Live评估框架及CoMind智能体，该智能体能在模拟Kaggle社区中交流知识并开发新方案，性能超越79.2%人类选手。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的ML智能体通常孤立运作，无法像人类研究者那样通过社区交流获取洞见。为弥补这一差距，研究团队开发了支持知识共享的评估框架。

Method: 提出MLE-Live实时评估框架，用于测试智能体在模拟Kaggle社区中的协作能力；并在此基础上开发了CoMind智能体，擅长在群体环境中交换见解和创新解决方案。

Result: CoMind在MLE-Live框架下达到最先进性能，在四项Kaggle竞赛中平均超越79.2%的人类参赛者。代码已开源。

Conclusion: 研究表明，具备社区协作能力的ML智能体（如CoMind）能显著提升研究效率，为自动化机器学习开辟了新方向。

Abstract: Large language model-based machine learning (ML) agents have shown great
promise in automating ML research. However, existing agents typically operate
in isolation on a given research problem, without engaging with the broader
research community, where human researchers often gain insights and contribute
by sharing knowledge. To bridge this gap, we introduce MLE-Live, a live
evaluation framework designed to assess an agent's ability to communicate with
and leverage collective knowledge from a simulated Kaggle research community.
Building on this framework, we propose CoMind, a novel agent that excels at
exchanging insights and developing novel solutions within a community context.
CoMind achieves state-of-the-art performance on MLE-Live and outperforms 79.2%
human competitors on average across four ongoing Kaggle competitions. Our code
is released at https://github.com/comind-ml/CoMind.

</details>


### [89] [The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind](https://arxiv.org/abs/2506.20664)
*Andrei Lupu,Timon Willi,Jakob Foerster*

Main category: cs.AI

TL;DR: 本文提出Decrypto，一个基于游戏的多智能体推理与心理理论（ToM）基准测试平台，旨在解决现有基准测试的局限性，并通过实验验证了当前大型语言模型（LLM）在多智能体推理和ToM任务上的表现不及人类和简单基线模型。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）获得代理能力，它们需要在复杂的多智能体场景中导航，与人类用户和其他智能体在合作与竞争环境中互动。然而，LLM在多智能体能力和心理理论（ToM）方面的表现尚不明确，现有基准测试存在范围狭窄、数据泄漏、饱和和缺乏交互性等问题。

Method: 作者提出Decrypto，一个基于游戏的基准测试平台，灵感来自认知科学、计算语用学和多智能体强化学习。该平台旨在消除其他基准测试中常见的混杂因素，并通过全面的实证评估、鲁棒性研究和人机交叉实验验证其设计。

Result: 实验发现，LLM在游戏中的表现落后于人类和简单的词嵌入基线模型。此外，在Decrypto中设计的经典认知科学实验变体中，最先进的推理模型在ToM任务上的表现显著不如旧版模型。

Conclusion: Decrypto填补了当前推理和ToM评估的关键空白，为开发更优的人工智能代理铺平了道路。研究结果表明，现有LLM在多智能体推理和ToM任务上仍有显著提升空间。

Abstract: As Large Language Models (LLMs) gain agentic abilities, they will have to
navigate complex multi-agent scenarios, interacting with human users and other
agents in cooperative and competitive settings. This will require new reasoning
skills, chief amongst them being theory of mind (ToM), or the ability to reason
about the "mental" states of other agents. However, ToM and other multi-agent
abilities in LLMs are poorly understood, since existing benchmarks suffer from
narrow scope, data leakage, saturation, and lack of interactivity. We thus
propose Decrypto, a game-based benchmark for multi-agent reasoning and ToM
drawing inspiration from cognitive science, computational pragmatics and
multi-agent reinforcement learning. It is designed to be as easy as possible in
all other dimensions, eliminating confounding factors commonly found in other
benchmarks. To our knowledge, it is also the first platform for designing
interactive ToM experiments.
  We validate the benchmark design through comprehensive empirical evaluations
of frontier LLMs, robustness studies, and human-AI cross-play experiments. We
find that LLM game-playing abilities lag behind humans and simple
word-embedding baselines. We then create variants of two classic cognitive
science experiments within Decrypto to evaluate three key ToM abilities.
Surprisingly, we find that state-of-the-art reasoning models are significantly
worse at those tasks than their older counterparts. This demonstrates that
Decrypto addresses a crucial gap in current reasoning and ToM evaluations, and
paves the path towards better artificial agents.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [90] [Modeling energy collection with shortest paths in rectangular grids: an efficient algorithm for energy harvesting](https://arxiv.org/abs/2506.20196)
*José-Miguel Díaz-Bañez,José-Manuel Higes-López,Miguel-Angel Pérez-Cutiño,Tom Todtenhaupt*

Main category: cs.DM

TL;DR: 本文提出了一种减少槽式太阳能场旋转次数的方法，在保持能量收集效率的同时延长系统寿命。


<details>
  <summary>Details</summary>
Motivation: 槽式太阳能场的连续太阳跟踪运动导致跟踪系统磨损和退化，因此需要研究在不影响能量捕获的情况下最小化旋转次数。

Method: 通过将问题转化为基于网格的路径优化，设计了多项式时间算法，该算法不受全天天气变化的影响。

Result: 真实数据模拟和实验表明，太阳能跟踪器的旋转运动可以减少至少10%，同时保持95%以上的能量收集效率。

Conclusion: 该方法为延长太阳能场的使用寿命提供了可扩展的解决方案，并且可以与太阳辐照度预测结合，增强其在实际部署中的鲁棒性。

Abstract: Parabolic Trough solar fields are among the most prominent methods for
harnessing solar energy. However, continuous sun-tracking movements leads to
wear and degradation of the tracking system, raising the question of whether
the rotations can be minimized without compromising energy capture. In this
paper, we address this question by exploring two problems: (1) minimizing the
number of SCA rotational movements while maintaining energy production within a
specified range, and (2) maximizing energy capture when the number of rotations
is limited. Unlike prior work, we develop a general framework that considers
variable conditions. By transforming the problem into grid-based path
optimization, we design polynomial-time algorithms that can operate
independently of the weather throughout the day. Through realistic simulations
and experiments using real-world data, our methods show that rotational
movements of solar trackers can be reduced by at least 10% while maintaining
over 95% energy collection efficiency. These results offer a scalable solution
for improving the operational lifespan of the solar field. Furthermore, our
methods can be integrated with solar irradiance forecasting, enhancing their
robustness and suitability for real-world deployment.

</details>
