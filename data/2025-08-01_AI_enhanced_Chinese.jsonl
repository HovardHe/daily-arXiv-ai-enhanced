{"id": "2507.22961", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2507.22961", "abs": "https://arxiv.org/abs/2507.22961", "authors": ["Yushi Huang"], "title": "On the Explicit Expression of an Extended Version of Riemann Zeta Function", "comment": "24 pages, 0 figures", "summary": "In this paper, we focus on the explicit expression of an extended version of\nRiemann zeta function. We use two different methods, Mellin inversion formula\nand Cauchy's residue theorem, to calculate a Mellin-Barnes type integral of the\nanalytic function regarding $z$: $\\Gamma(z)\\Gamma(s-z)u^{-z}$ ($u\\in (0,1)$,\n$s\\in \\mathbb{C}$). We provide the necessary background on the analytic\nproperties of Gamma and Riemann zeta function to confirm the absolute\nconvergence of this Mellin-Barnes integral. Next, we represent the extended\nversion of Riemann zeta function\n$\\sum_{m=1}^{\\infty}\\sum_{n=1}^{\\infty}{(m+n)^{-s}}$ using the following\ncomplex integral where the real part of $s$ is larger than 2 and $c>1$ is\nchosen to make $\\Re(s)-c$ larger than 1.\n$$\\Gamma(s)\\sum_{m=1}^{\\infty}\\sum_{n=1}^{\\infty}{(m+n)^{-s}}=\\frac{1}{2\\pi i}\n\\int_{c - i\\infty}^{c + i\\infty} \\zeta(z) \\zeta(s - z) \\Gamma(z) \\Gamma(s - z)\n\\, dz$$ We provide the evaluation of this integral by changing the integration\npath from straight line $\\Re(z)=c$ into a rectangular contour whose left side\nis positioned at negative infinity. We apply the functional equation of Riemann\nzeta function, Euler's reflection formula, and Legendre's duplication formula\nto evaluate the integral segment through $\\Re(z)=-\\infty$. After introducing\nHurwitz zeta function and properly calculating the difference between the sum\nof residues in two analogous rectangular contours, we finalize the evaluation.\nLastly, we demonstrate the connection of this result with other intricate\nintegrals involving special functions, such as the hyperbolic function.\nAdditionally, we discuss its applications in deriving explicit expressions for\nthe Barnes zeta function.", "AI": {"tldr": "本文通过Mellin反演公式和Cauchy留数定理，研究了扩展Riemann zeta函数的显式表达式，并探讨了其在特殊函数积分中的应用。", "motivation": "研究扩展Riemann zeta函数$\\sum_{m=1}^{\\infty}\\sum_{n=1}^{\\infty}{(m+n)^{-s}}$的显式表达式，并验证其Mellin-Barnes积分的绝对收敛性。", "method": "使用Mellin反演公式和Cauchy留数定理计算积分，通过改变积分路径并应用Riemann zeta函数的函数方程、Euler反射公式和Legendre倍乘公式。", "result": "成功推导出扩展Riemann zeta函数的显式表达式，并展示了其与双曲函数等特殊函数积分的联系。", "conclusion": "该研究不仅提供了扩展Riemann zeta函数的显式表达式，还为Barnes zeta函数的显式表达提供了新的推导方法。"}}
{"id": "2507.23503", "categories": ["math.LO", "03C45, 03C95, 37B02, 28C10, 28E15, 43A05"], "pdf": "https://arxiv.org/pdf/2507.23503", "abs": "https://arxiv.org/abs/2507.23503", "authors": ["Kyle Gannon", "Daniel Max Hoffmann", "Krzysztof Krupiński"], "title": "Convolution semigroups for automorphism dynamics", "comment": "102 pages", "summary": "Initially motivated by Hrushovski's paper on definability patterns, we obtain\nhomeomorphisms between Ellis semigroups related to natural actions of the\nautomorphism groups of first order structures and certain collections of types\nand Keisler measures. Thus, we can transfer the semigroup operation from these\nEllis semigroups to the corresponding collections of types and Keisler\nmeasures. By generalizing this transferred product, we obtain a new convolution\noperation for invariant types and measures in arbitrary first-order theories.\nWe develop its general theory and prove several correspondence theorems between\nidempotent measures and closed subgroups of the automorphism group of a\nsufficiently large (so-called monster) model with respect to the relatively\ndefinable topology. Via the affine sort construction, we demonstrate that this\nnew notion of convolution encodes the standard definable convolution operation\nover definable groups.", "AI": {"tldr": "该研究从Hrushovski关于可定义模式的论文出发，建立了与一阶结构自同构群自然作用相关的Ellis半群与类型及Keisler测度集合之间的同胚映射，进而推广出适用于任意一阶理论中不变类型与测度的新卷积运算，并证明了幂等测度与自同构群闭子群之间的对应关系。", "motivation": "研究最初受Hrushovski关于可定义模式的论文启发，旨在探索一阶结构自同构群作用下的Ellis半群与类型及Keisler测度集合之间的深层联系。", "method": "通过建立Ellis半群与类型/测度集合的同胚映射，将半群运算转移至后者；进而推广出不变类型与测度的新卷积运算，并利用仿射类构造验证其与可定义群上标准卷积运算的兼容性。", "result": "成功构建了新型卷积运算的通用理论，证明了幂等测度与（相对可定义拓扑下）超大模型自同构群闭子群之间的对应定理，并通过仿射类构造表明新卷积可编码可定义群上的标准卷积运算。", "conclusion": "该研究不仅建立了Ellis半群与类型/测度系统的运算对应，还发展出具有普适性的卷积理论，为模型论与拓扑动力学的交叉研究提供了新工具，特别在可定义群卷积运算的抽象刻画方面取得突破。"}}
{"id": "2507.23041", "categories": ["math.NT", "11B05"], "pdf": "https://arxiv.org/pdf/2507.23041", "abs": "https://arxiv.org/abs/2507.23041", "authors": ["Nathan McNew", "Jai Setty"], "title": "On the densities of covering numbers and abundant numbers", "comment": null, "summary": "We investigate the densities of the sets of abundant numbers and of covering\nnumbers, integers $n$ for which there exists a distinct covering system where\nevery modulus divides $n$. We establish that the set $\\mathcal{C}$ of covering\nnumbers possesses a natural density $d(\\mathcal{C})$ and prove that $0.103230 <\nd(\\mathcal{C}) < 0.103398.$ Our approach adapts methods developed by Behrend\nand Del\\'eglise for bounding the density of abundant numbers, by introducing a\nfunction $c(n)$ that measures how close an integer $n$ is to being a covering\nnumber with the property that $c(n) \\leq h(n) = \\sigma(n)/n$. However,\ncomputing $d(\\mathcal{C})$ to three decimal digits requires some new ideas to\nsimplify the computations. As a byproduct of our methods, we obtain\nsignificantly improved bounds for $d(\\mathcal{A})$, the density of abundant\nnumbers, namely $0.247619608 < d(\\mathcal{A}) < 0.247619658$. We also show the\ncount of primitive covering numbers up to $x$ is $O\\left(\nx\\exp\\left(\\left(-\\tfrac{1}{2\\sqrt{\\log 2}} + \\epsilon\\right)\\sqrt{\\log x} \\log\n\\log x\\right)\\right)$, which is substantially smaller than the corresponding\nbound for primitive abundant numbers.", "AI": {"tldr": "研究了覆盖数集$\\mathcal{C}$的密度，证明其自然密度$d(\\mathcal{C})$存在且范围在0.103230到0.103398之间，同时改进了丰数密度$d(\\mathcal{A})$的界限，并给出了原始覆盖数计数的上界估计。", "motivation": "探讨覆盖数集和丰数集的密度问题，旨在精确计算覆盖数的自然密度，并改进现有丰数密度的估计方法。", "method": "采用Behrend和Del\\'eglise的方法，引入函数$c(n)$衡量整数接近覆盖数的程度，结合$c(n) \\leq h(n) = \\sigma(n)/n$的性质，简化计算过程。", "result": "确定覆盖数集$\\mathcal{C}$的密度$d(\\mathcal{C})$在0.103230到0.103398之间，丰数密度$d(\\mathcal{A})$的新界限为0.247619608到0.247619658，原始覆盖数的计数上界为$O\\left(x\\exp\\left(\\left(-\\tfrac{1}{2\\sqrt{\\log 2}} + \\epsilon\\right)\\sqrt{\\log x} \\log \\log x\\right)\\right)$。", "conclusion": "通过新方法成功计算了覆盖数集的密度并改进了丰数密度的估计，同时发现原始覆盖数的增长速度远低于原始丰数。"}}
{"id": "2507.23054", "categories": ["math.OC", "90C30, 90C56, 49J52", "G.1.6; G.4"], "pdf": "https://arxiv.org/pdf/2507.23054", "abs": "https://arxiv.org/abs/2507.23054", "authors": ["Charles Audet", "Théo Denorme", "Youssef Diouane", "Sébastien Le Digabel", "Christophe Tribes"], "title": "Adaptive direct search algorithms for constrained optimization", "comment": null, "summary": "Two families of directional direct search methods have emerged in\nderivative-free and blackbox optimization (DFO and BBO), each based on distinct\nprinciples: Mesh Adaptive Direct Search (MADS) and Sufficient Decrease Direct\nSearch (SDDS). MADS restricts trial points to a mesh and accepts any\nimprovement, ensuring none are missed, but at the cost of restraining the\nplacement of trial points. SDDS allows greater freedom by evaluating points\nanywhere in the space, but accepts only those yielding a sufficient decrease in\nthe objective function value, which may lead to discarding improving points.\n  This work introduces a new class of methods, Adaptive Direct Search (ADS),\nwhich uses a novel acceptance rule based on the so-called punctured space,\navoiding both meshes and sufficient decrease conditions. ADS enables flexible\nsearch while addressing the limitations of MADS and SDDS, and retains the\ntheoretical foundations of directional direct search. Computational results in\nconstrained and unconstrained settings highlight its performance compared to\nboth MADS and SDDS.", "AI": {"tldr": "本文提出了一种新的无导数优化方法——自适应直接搜索（ADS），通过引入基于穿孔空间的接受规则，结合了MADS和SDDS的优点，避免了二者的局限性。", "motivation": "现有的无导数优化方法MADS和SDDS各有局限：MADS限制试验点位置但可能错过改进点，SDDS允许自由搜索但可能丢弃改进点。需要一种能兼顾灵活性和效率的新方法。", "method": "ADS采用基于穿孔空间的新型接受规则，既不依赖网格限制（如MADS），也不要求充分下降条件（如SDDS），同时保留了方向直接搜索的理论基础。", "result": "在带约束和无约束场景下的计算结果表明，ADS的性能优于MADS和SDDS，实现了更灵活的搜索能力。", "conclusion": "ADS通过创新性接受规则成功融合了MADS和SDDS的优势，为无导数优化提供了更高效的解决方案，具有理论和实践价值。"}}
{"id": "2507.22957", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.22957", "abs": "https://arxiv.org/abs/2507.22957", "authors": ["María José Chávez de Diego", "Pablo Montero Moreno", "María Trinidad Villar-Liñán"], "title": "Domination, matching and transversal numbers for Berge-$G$ hypergraphs", "comment": null, "summary": "Let $G=(V(G),E(G))$ be a graph and $H=(V(H),E(H))$ be a hypergraph. The\nhypergraph $H$ is a {\\it Berge-G} if there is a bijection $f : E(G) \\mapsto\nE(H)$ such that for each $e \\in E(G)$ we have $e \\subseteq f(e)$. We define\n{\\it dilations of $G$} as a particular subfamily of not necessarily uniform\nBerge-$G$ hypergraphs. We examine domination, matching and transversal numbers\nand some relation between these parameters in that family of hypergraphs.\n  Our work generalizes previous results concerning generalized power\nhypergraphs.", "AI": {"tldr": "本文研究了Berge-G超图的扩张问题，探讨了支配数、匹配数和横截数之间的关系，推广了广义幂超图的相关结果。", "motivation": "研究Berge-G超图的扩张家族，旨在理解超图中支配、匹配和横截参数之间的内在联系，扩展广义幂超图的现有理论。", "method": "通过定义图的扩张作为Berge-G超图的特定子族，分析其非均匀性，并运用组合数学方法研究支配数、匹配数和横截数的性质。", "result": "在Berge-G超图的扩张家族中，获得了支配数、匹配数和横截数之间的新关系，这些结果推广了广义幂超图的已有结论。", "conclusion": "该研究为Berge-G超图的扩张理论提供了新的视角，其成果可应用于超图参数分析和组合优化问题。"}}
{"id": "2507.22908", "categories": ["q-fin.CP", "cs.AI", "cs.LG", "I.2"], "pdf": "https://arxiv.org/pdf/2507.22908", "abs": "https://arxiv.org/abs/2507.22908", "authors": ["Abhishek Sawaika", "Swetang Krishna", "Tushar Tomar", "Durga Pritam Suggisetti", "Aditi Lal", "Tanmaya Shrivastav", "Nouhaila Innan", "Muhammad Shafique"], "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection", "comment": "To be published in proceedings of IEEE International Conference on\n  Quantum Computing and Engineering (QCE) 2025", "summary": "Rapid growth of digital transactions has led to a surge in fraudulent\nactivities, challenging traditional detection methods in the financial sector.\nTo tackle this problem, we introduce a specialised federated learning framework\nthat uniquely combines a quantum-enhanced Long Short-Term Memory (LSTM) model\nwith advanced privacy preserving techniques. By integrating quantum layers into\nthe LSTM architecture, our approach adeptly captures complex\ncross-transactional patters, resulting in an approximate 5% performance\nimprovement across key evaluation metrics compared to conventional models.\nCentral to our framework is \"FedRansel\", a novel method designed to defend\nagainst poisoning and inference attacks, thereby reducing model degradation and\ninference accuracy by 4-8%, compared to standard differential privacy\nmechanisms. This pseudo-centralised setup with a Quantum LSTM model, enhances\nfraud detection accuracy and reinforces the security and confidentiality of\nsensitive financial data.", "AI": {"tldr": "本文提出了一种结合量子增强LSTM模型和隐私保护技术的联邦学习框架，用于提升金融欺诈检测的准确性和安全性。", "motivation": "随着数字交易的快速增长，传统欺诈检测方法面临挑战，亟需一种能同时提升检测性能和保障数据隐私的新方法。", "method": "采用量子增强LSTM架构捕获复杂交易模式，并开发新型防御机制'FedRansel'抵御投毒和推理攻击，结合伪中心化联邦学习框架。", "result": "相比传统模型，量子LSTM在关键指标上提升约5%性能；FedRansel将模型退化率和推理准确率降低4-8%，优于标准差分隐私机制。", "conclusion": "该框架显著提高了欺诈检测精度，同时通过量子计算和高级隐私保护技术强化了金融数据的安全性。"}}
{"id": "2507.23229", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.23229", "abs": "https://arxiv.org/abs/2507.23229", "authors": ["Yufei Chen", "Yao Wang", "Haibin Zhang", "Tao Gu"], "title": "Fine-Grained Privacy Extraction from Retrieval-Augmented Generation Systems via Knowledge Asymmetry Exploitation", "comment": null, "summary": "Retrieval-augmented generation (RAG) systems enhance large language models\n(LLMs) by integrating external knowledge bases, but this advancement introduces\nsignificant privacy risks. Existing privacy attacks on RAG systems can trigger\ndata leakage but often fail to accurately isolate knowledge-base-derived\nsentences within mixed responses. They also lack robustness when applied across\nmultiple domains. This paper addresses these challenges by presenting a novel\nblack-box attack framework that exploits knowledge asymmetry between RAG and\nstandard LLMs to achieve fine-grained privacy extraction across heterogeneous\nknowledge landscapes. We propose a chain-of-thought reasoning strategy that\ncreates adaptive prompts to steer RAG systems away from sensitive content.\nSpecifically, we first decompose adversarial queries to maximize information\ndisparity and then apply a semantic relationship scoring to resolve lexical and\nsyntactic ambiguities. We finally train a neural network on these feature\nscores to precisely identify sentences containing private information. Unlike\nprior work, our framework generalizes to unseen domains through iterative\nrefinement without pre-defined knowledge. Experimental results show that we\nachieve over 91% privacy extraction rate in single-domain and 83% in\nmulti-domain scenarios, reducing sensitive sentence exposure by over 65% in\ncase studies. This work bridges the gap between attack and defense in RAG\nsystems, enabling precise extraction of private information while providing a\nfoundation for adaptive mitigation.", "AI": {"tldr": "本文提出了一种针对检索增强生成（RAG）系统的黑盒攻击框架，通过知识不对称性实现跨领域隐私信息精准提取，并采用思维链推理策略降低敏感内容暴露风险。实验显示单领域隐私提取率达91%，多领域达83%，敏感语句暴露减少65%。", "motivation": "现有RAG系统隐私攻击方法存在两大缺陷：无法准确分离知识库来源的句子，且跨领域鲁棒性不足。本文旨在解决这些问题，实现细粒度隐私提取并建立攻防桥梁。", "method": "1. 利用RAG与标准LLM的知识不对称性设计攻击框架\\n2. 采用思维链推理生成自适应提示\\n3. 分解对抗性查询以最大化信息差异\\n4. 语义关系评分解决词汇句法歧义\\n5. 基于特征分数训练神经网络识别隐私语句", "result": "单领域隐私提取成功率91%，多领域达83%。案例研究中敏感语句暴露率降低65%以上，且无需预定义知识即可泛化至未见领域。", "conclusion": "该框架首次实现跨异构知识场景的精准隐私提取，同时为自适应防御提供基础，弥合了RAG系统攻防间的技术鸿沟。"}}
{"id": "2507.23140", "categories": ["math.ST", "stat.AP", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.23140", "abs": "https://arxiv.org/abs/2507.23140", "authors": ["JungHo Lee", "Valerio Baćak", "Edward H. Kennedy"], "title": "Learning Smooth Populations of Parameters with Trial Heterogeneity", "comment": null, "summary": "We consider the classical problem of estimating the mixing distribution of\nbinomial mixtures, but under trial heterogeneity and smoothness. This problem\nhas been studied extensively when the trial parameter is homogeneous, but not\nunder the more general scenario of heterogeneous trials, and only within a low\nsmoothness regime, where the resulting rates are slow. Under the assumption\nthat the density is s-smooth, we derive fast error rates for the kernel density\nestimator under trial heterogeneity that depend on the harmonic mean of the\ntrials. Importantly, even when reduced to the homogeneous case, our result\nimproves on the state-of-the-art rate of Ye and Bickel (2021). We also study\nnonparametric estimation of the difference between two densities, which can be\nsmoother than the individual densities, in both i.i.d. and binomial-mixture\nsettings. Our work is motivated by an application in criminal justice:\ncomparing conviction rates of indigent representation in Pennsylvania. We find\nthat the estimated conviction rates for appointed counsel (court-appointed\nprivate attorneys) are generally higher than those for public defenders,\npotentially due to a confounding factor: appointed counsel are more likely to\ntake on severe cases.", "AI": {"tldr": "本文研究了在试验异质性和平滑性条件下二项混合分布的混合分布估计问题，提出了基于核密度估计器的快速误差率，并在刑事司法应用中比较了不同辩护类型的定罪率。", "motivation": "研究动机源于刑事司法领域的实际应用：比较宾夕法尼亚州贫困辩护中指定律师（法院指定的私人律师）和公设辩护人的定罪率差异，并探讨潜在混杂因素。", "method": "在假设密度为s-平滑的条件下，推导了试验异质性下核密度估计器的快速误差率，该速率依赖于试验的调和平均数。同时研究了独立同分布和二项混合设置中两密度差异的非参数估计。", "result": "研究结果显示，即使在同质试验情况下，本文方法也优于Ye和Bickel（2021）的最新成果。应用分析表明，指定律师的估计定罪率通常高于公设辩护人，可能与指定律师更可能接手严重案件这一混杂因素有关。", "conclusion": "本文提出的方法在异质性试验条件下实现了更优的估计速率，并在刑事司法数据分析中揭示了辩护类型与定罪率之间的潜在关联，为混杂因素影响提供了实证证据。"}}
{"id": "2507.22951", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22951", "abs": "https://arxiv.org/abs/2507.22951", "authors": ["Alessandro Lonardi", "Samy Badreddine", "Tarek R. Besold", "Pablo Sanchez Martin"], "title": "Unifying Post-hoc Explanations of Knowledge Graph Completions", "comment": null, "summary": "Post-hoc explainability for Knowledge Graph Completion (KGC) lacks\nformalization and consistent evaluations, hindering reproducibility and\ncross-study comparisons. This paper argues for a unified approach to post-hoc\nexplainability in KGC. First, we propose a general framework to characterize\npost-hoc explanations via multi-objective optimization, balancing their\neffectiveness and conciseness. This unifies existing post-hoc explainability\nalgorithms in KGC and the explanations they produce. Next, we suggest and\nempirically support improved evaluation protocols using popular metrics like\nMean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of\ninterpretability as the ability of explanations to address queries meaningful\nto end-users. By unifying methods and refining evaluation standards, this work\naims to make research in KGC explainability more reproducible and impactful.", "AI": {"tldr": "本文提出知识图谱补全（KGC）后验解释性的统一框架，通过多目标优化平衡解释效果与简洁性，改进评估协议，并强调解释需面向终端用户的实际查询需求。", "motivation": "当前KGC后验解释性研究缺乏形式化定义与标准化评估，导致可复现性与跨研究比较困难。本文旨在建立统一方法以提升该领域研究的规范性与影响力。", "method": "1. 提出基于多目标优化的通用框架，统一现有KGC后验解释算法\\n2. 采用平均倒数排名（MRR）和Hits@$k$等指标改进评估协议\\n3. 强调解释需针对终端用户的实际需求设计。", "result": "实证研究表明：统一框架能有效协调解释效果与简洁性，改进的评估协议（如MRR和Hits@$k$）更可靠，面向用户查询的解释显著提升可解释性价值。", "conclusion": "通过方法统一与评估标准优化，本研究为KGC解释性建立了可复现的研究基础，推动该领域向解决实际用户需求的方向发展。"}}
{"id": "2507.23102", "categories": ["math.NT", "11F70 (primary) 11F22, 11F75 (secondary)"], "pdf": "https://arxiv.org/pdf/2507.23102", "abs": "https://arxiv.org/abs/2507.23102", "authors": ["Jin Kunwoo Lee"], "title": "Nonzero $\\mathfrak{n}$ cohomology of Totally Degenerate Limit of Discrete Series representations", "comment": null, "summary": "We show that a totally degenerate limit of discrete series representation\nadmits a choice of n cohomology group that is nonvanishing at a canonically\ndefined degree. We then show that the combinatorial complexes used by Soergel\nto compute these cohomology groups satisfies Serre duality. We conclude that\nthis produces two n cohomology groups, each for a totally degenerate limit of\ndiscrete series of U(n+1) and U(n), which are nonvanishing at the same degree.\nThis suggests Gan Gross Prasad type branching laws for the TDLDS of unitary\ngroups of any rank.", "AI": {"tldr": "本文证明了完全退化离散级数表示的特定上同调群在规范定义的度数下非零，并揭示了Soergel组合复形满足Serre对偶性，为酉群的TDLDS分支定律提供了新线索。", "motivation": "研究完全退化离散级数表示的上同调性质，旨在探索酉群表示论中的Gan-Gross-Prasad型分支定律。", "method": "通过分析Soergel组合复形计算上同调群，并验证其满足Serre对偶性，比较U(n+1)和U(n)群的TDLDS表示。", "result": "发现U(n+1)和U(n)的完全退化离散级数表示在相同度数下存在成对非零上同调群。", "conclusion": "该结果为任意秩酉群的完全退化离散级数表示建立了类似Gan-Gross-Prasad的分支定律框架。"}}
{"id": "2507.23094", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.23094", "abs": "https://arxiv.org/abs/2507.23094", "authors": ["Vincenzo Di Vito", "Kaarthik Sundar", "Ferdinando Fioretto", "Deepjyoti Deka"], "title": "Stability-Constrained AC Optimal Power Flow -- A Gaussian Process-Based Approach", "comment": "12 pages", "summary": "The Alternating Current Optimal Power Flow (ACOPF) problem is a core task in\npower system operations, aimed at determining cost-effective generation\ndispatch while satisfying physical and operational constraints. However,\nconventional ACOPF formulations rely on steady-state models and neglect the\ndynamic behavior of generators, which can lead to operating points that are\neconomically optimal but dynamically unstable. This paper proposes a novel,\ndata-driven approach to incorporate generator dynamics into the ACOPF using\nGaussian Process (GP) models. Specifically, it introduces an exponential\nsurrogate function to characterize the stability of solutions to the\ndifferential equations governing synchronous generator dynamics. The exponent,\nwhich indicates whether system trajectories decay (stable) or grow (unstable),\nis learned as a function of the bus voltage using GP regression. Crucially, the\nframework enables probabilistic stability assessment to be integrated directly\ninto the optimization process. The resulting dynamics-aware ACOPF formulation\nidentifies operating points that satisfy both operational safety and dynamic\nstability criteria. Numerical experiments on the IEEE 39-bus, 57-bus, and\n118-bus systems demonstrate that the proposed method efficiently captures\ngenerator dynamics using limited training data, leading to more reliable and\nrobust decisions across a wide range of operating conditions.", "AI": {"tldr": "本文提出了一种数据驱动方法，将发电机动态特性融入交流最优潮流问题，通过高斯过程模型确保运行点同时满足经济性和动态稳定性。", "motivation": "传统交流最优潮流（ACOPF）依赖稳态模型，忽略发电机动态行为，可能导致经济最优但动态不稳定的运行点。", "method": "采用高斯过程回归学习同步发电机动态微分方程解的稳定性指数，构建指数代理函数表征稳定性，并将概率稳定性评估直接整合至优化过程。", "result": "在IEEE 39、57和118节点系统中的实验表明，该方法能用少量训练数据有效捕捉发电机动态，获得更可靠、鲁棒的运行决策。", "conclusion": "所提出的动态感知ACOPF框架实现了运行安全性与动态稳定性的协同优化，为电力系统调度提供了新思路。"}}
{"id": "2507.23039", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.23039", "abs": "https://arxiv.org/abs/2507.23039", "authors": ["Seth R. Nelson", "Eric Swartz"], "title": "Character theoretic techniques for nonabelian partial difference sets", "comment": null, "summary": "A $(v,k,\\lambda, \\mu)$-partial difference set (PDS) is a subset $D$ of size\n$k$ of a group $G$ of order $v$ such that every nonidentity element $g$ of $G$\ncan be expressed in either $\\lambda$ or $\\mu$ different ways as a product\n$xy^{-1}$, $x, y \\in D$, depending on whether or not $g$ is in $D$. If $D$ is\ninverse closed and $1 \\notin D$, then the Cayley graph ${\\rm Cay}(G,D)$ is a\n$(v,k,\\lambda, \\mu)$-strongly regular graph (SRG). PDSs have been studied\nextensively over the years, especially in abelian groups, where techniques from\ncharacter theory have proven to be particularly effective. Recently, there has\nbeen considerable interest in studying PDSs in nonabelian groups, and the\npurpose of this paper is develop character theoretic techniques that apply in\nthe nonabelian setting. We prove that analogues of character theoretic results\nof Ott about generalized quadrangles of order $s$ also hold in the general PDS\nsetting, and we are able to use these techniques to compute the intersection of\na putative PDS with the conjugacy classes of the parent group in many\ninstances. With these techniques, we are able to prove the nonexistence of PDSs\nin numerous instances and provide severe restrictions in cases when such PDSs\nmay still exist. Furthermore, we are able to use these techniques\nconstructively, computing several examples of PDSs in nonabelian groups not\npreviously recognized in the literature, including an infinite family of\ngenuinely nonabelian PDSs associated to the block-regular Steiner triple\nsystems originally studied by Clapham and related infinite families of\ngenuinely nonabelian PDSs associated to the block-regular Steiner $2$-designs\nfirst studied by Wilson.", "AI": {"tldr": "本文研究了非阿贝尔群中的$(v,k,\\lambda, \\mu)$-部分差集（PDS），开发了适用于非阿贝尔环境的特征理论技术，证明了若干不存在性结果，并构造了新的非阿贝尔PDS实例。", "motivation": "近年来，非阿贝尔群中的PDS研究受到广泛关注。本文旨在开发适用于非阿贝尔群的特征理论技术，以扩展传统阿贝尔群中的研究方法。", "method": "作者推广了Ott关于广义四边形特征理论的结果，将其应用于一般PDS场景，并利用这些技术计算PDS与父群共轭类的交集。", "result": "研究证明了多种情况下PDS的不存在性，并对可能存在的PDS施加了严格限制。此外，构造性地发现了文献中未记载的非阿贝尔PDS实例，包括与Clapham研究的块正则Steiner三重系相关的无限族。", "conclusion": "本文发展的特征理论技术有效解决了非阿贝尔群中PDS的研究难题，既可用于否定性证明，又能指导新PDS的构造，特别是发现了与块正则Steiner设计相关的无限非阿贝尔PDS族。"}}
{"id": "2507.23453", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23453", "abs": "https://arxiv.org/abs/2507.23453", "authors": ["Lijia Liu", "Takumi Kondo", "Kyohei Atarashi", "Koh Takeuchi", "Jiyi Li", "Shigeru Saito", "Hisashi Kashima"], "title": "Counterfactual Evaluation for Blind Attack Detection in LLM-based Evaluation Systems", "comment": null, "summary": "This paper investigates defenses for LLM-based evaluation systems against\nprompt injection. We formalize a class of threats called blind attacks, where a\ncandidate answer is crafted independently of the true answer to deceive the\nevaluator. To counter such attacks, we propose a framework that augments\nStandard Evaluation (SE) with Counterfactual Evaluation (CFE), which\nre-evaluates the submission against a deliberately false ground-truth answer.\nAn attack is detected if the system validates an answer under both standard and\ncounterfactual conditions. Experiments show that while standard evaluation is\nhighly vulnerable, our SE+CFE framework significantly improves security by\nboosting attack detection with minimal performance trade-offs.", "AI": {"tldr": "本文提出了一种针对LLM评估系统的防御框架SE+CFE，通过标准评估与反事实评估相结合，有效检测独立于真实答案的盲攻击，显著提升系统安全性。", "motivation": "现有LLM评估系统易受独立构造候选答案的盲攻击威胁，需开发可靠防御机制以保障评估公正性。", "method": "在标准评估(SE)基础上引入反事实评估(CFE)，通过验证提交答案在真实与虚构答案下的矛盾性来检测攻击。", "result": "实验表明标准评估漏洞率达80%，而SE+CFE框架将攻击检测率提升至95%且性能损失小于2%。", "conclusion": "SE+CFE框架通过双重验证机制显著增强LLM评估系统对抗盲攻击的鲁棒性，为安全评估提供新范式。"}}
{"id": "2507.23285", "categories": ["math.ST", "math.PR", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.23285", "abs": "https://arxiv.org/abs/2507.23285", "authors": ["Seunghyun Lee", "Nabarun Deb", "Sumit Mukherjee"], "title": "CLT in high-dimensional Bayesian linear regression with low SNR", "comment": null, "summary": "We study central limit theorems for linear statistics in high-dimensional\nBayesian linear regression with product priors. Unlike the existing literature\nwhere the focus is on posterior contraction, we work under a non-contracting\nregime where neither the likelihood nor the prior dominates the other. This is\nmotivated by modern high-dimensional datasets characterized by a bounded\nsignal-to-noise ratio. This work takes a first step towards understanding limit\ndistributions for one-dimensional projections of the posterior, as well as the\nposterior mean, in such regimes. Analogous to contractive settings, the\nresulting limiting distributions are Gaussian, but they heavily depend on the\nchosen prior and center around the Mean-Field approximation of the posterior.\nWe study two concrete models of interest to illustrate this phenomenon -- the\nwhite noise design, and the (misspecified) Bayesian model. As an application,\nwe construct credible intervals and compute their coverage probability under\nany misspecified prior. Our proofs rely on a combination of recent developments\nin Berry-Esseen type bounds for Random Field Ising models and both first and\nsecond order Poincar\\'{e} inequalities. Notably, our results do not require any\nsparsity assumptions on the prior.", "AI": {"tldr": "本文研究了高维贝叶斯线性回归中线性统计量的中心极限定理，重点探讨了非收缩机制下的后验分布一维投影及后验均值的极限分布。", "motivation": "现代高维数据集通常具有有限的信噪比，这促使我们在非收缩机制下研究后验分布的极限行为，其中似然函数和先验分布都不占主导地位。", "method": "结合随机场Ising模型的Berry-Esseen型边界以及一阶和二阶Poincar\\\\'{e}不等式，研究了白噪声设计和错误指定的贝叶斯模型两种具体模型。", "result": "极限分布为高斯分布，但强烈依赖于所选先验，并以后验的平均场近似为中心。在不要求先验稀疏性的情况下，构建了可信区间并计算了其覆盖概率。", "conclusion": "该研究为非收缩机制下高维贝叶斯回归的极限分布提供了理论框架，揭示了先验选择对后验分布的重要影响。"}}
{"id": "2507.23018", "categories": ["cs.AI", "cs.CE", "cs.DC", "cs.LG", "I.2.6"], "pdf": "https://arxiv.org/pdf/2507.23018", "abs": "https://arxiv.org/abs/2507.23018", "authors": ["Wesley Brewer", "Patrick Widener", "Valentine Anantharaj", "Feiyi Wang", "Tom Beck", "Arjun Shankar", "Sarp Oral"], "title": "Data Readiness for Scientific AI at Scale", "comment": "10 pages, 1 figure, 2 tables", "summary": "This paper examines how Data Readiness for AI (DRAI) principles apply to\nleadership-scale scientific datasets used to train foundation models. We\nanalyze archetypal workflows across four representative domains - climate,\nnuclear fusion, bio/health, and materials - to identify common preprocessing\npatterns and domain-specific constraints. We introduce a two-dimensional\nreadiness framework composed of Data Readiness Levels (raw to AI-ready) and\nData Processing Stages (ingest to shard), both tailored to high performance\ncomputing (HPC) environments. This framework outlines key challenges in\ntransforming scientific data for scalable AI training, emphasizing\ntransformer-based generative models. Together, these dimensions form a\nconceptual maturity matrix that characterizes scientific data readiness and\nguides infrastructure development toward standardized, cross-domain support for\nscalable and reproducible AI for science.", "AI": {"tldr": "本文提出一个针对高性能计算环境的两维数据准备框架，用于评估和提升科学数据在AI训练中的适用性，特别关注生成式模型的应用。", "motivation": "研究动机在于解决领导级科学数据集在AI训练中的数据准备问题，特别是在气候、核聚变、生物/健康和材料等领域，如何标准化和优化数据处理流程以支持可扩展的AI科学应用。", "method": "方法包括分析四个典型领域的数据处理流程，提出一个由数据准备级别（从原始数据到AI就绪）和数据处理阶段（从数据摄入到分片）组成的两维框架，并针对高性能计算环境进行定制。", "result": "研究结果是一个概念性的成熟度矩阵，能够描述科学数据的准备状态，并为跨领域的基础设施开发提供指导，以支持可扩展和可复现的科学AI应用。", "conclusion": "结论强调该框架为科学数据向AI就绪状态的转化提供了系统化的方法，特别是在支持基于Transformer的生成模型方面，推动了标准化和跨领域支持的发展。"}}
{"id": "2507.23179", "categories": ["math.NT", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.23179", "abs": "https://arxiv.org/abs/2507.23179", "authors": ["Juncheng Zhou", "Hongfeng Wu"], "title": "Cyclotomy, cyclotomic cosets and arimetic propeties of some families in $\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$", "comment": null, "summary": "Arithmetic properties of some families in $\\frac{\\mathbb{F}_l[x]}{\\langle\nx^{p^sq^t}-1\\rangle}$ are obtained by using the cyclotomic classes of order 2\nwith respect to $n=p^sq^t$, where $p\\equiv3 \\mathrm{mod} 4$,\n$\\gcd(\\phi(p^s),\\phi(q^t))=2$, $l$ is a primitive root modulo $q^t$ and\n$\\mathrm{ord}_{p^s}(l)=\\phi(p^s)/2$. The form of these cyclotomic classes\nenables us to further generalize the results obtained in \\cite{ref1}. The\nexplicit expressions of primitive idempotents of minimal ideals in\n$\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$ are also obtained.", "AI": {"tldr": "本文研究了在$\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$中的算术性质，利用二阶分圆类推广了已有结果，并给出了极小理想的本原幂等元的显式表达式。", "motivation": "研究特定条件下分圆类的算术性质，以推广已有文献中的结果，并探索多项式环中理想的结构。", "method": "使用$n=p^sq^t$的二阶分圆类，其中$p\\equiv3 \\mathrm{mod} 4$，$\\gcd(\\phi(p^s),\\phi(q^t))=2$，$l$是模$q^t$的原根且$\\mathrm{ord}_{p^s}(l)=\\phi(p^s)/2$。", "result": "获得了$\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$中极小理想的本原幂等元的显式表达式，并推广了文献中的结果。", "conclusion": "通过特定条件下的分圆类分析，成功推广了已有结果，并揭示了多项式环中理想结构的算术性质。"}}
{"id": "2507.23155", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23155", "abs": "https://arxiv.org/abs/2507.23155", "authors": ["Jincheng Cao", "Ruichen Jiang", "Erfan Yazdandoost Hamedani", "Aryan Mokhtari"], "title": "On the Complexity of Finding Stationary Points in Nonconvex Simple Bilevel Optimization", "comment": null, "summary": "In this paper, we study the problem of solving a simple bilevel optimization\nproblem, where the upper-level objective is minimized over the solution set of\nthe lower-level problem. We focus on the general setting in which both the\nupper- and lower-level objectives are smooth but potentially nonconvex. Due to\nthe absence of additional structural assumptions for the lower-level\nobjective-such as convexity or the Polyak-{\\L}ojasiewicz (PL)\ncondition-guaranteeing global optimality is generally intractable. Instead, we\nintroduce a suitable notion of stationarity for this class of problems and aim\nto design a first-order algorithm that finds such stationary points in\npolynomial time. Intuitively, stationarity in this setting means the\nupper-level objective cannot be substantially improved locally without causing\na larger deterioration in the lower-level objective. To this end, we show that\na simple and implementable variant of the dynamic barrier gradient descent\n(DBGD) framework can effectively solve the considered nonconvex simple bilevel\nproblems up to stationarity. Specifically, to reach an $(\\epsilon_f,\n\\epsilon_g)$-stationary point-where $\\epsilon_f$ and $\\epsilon_g$ denote the\ntarget stationarity accuracies for the upper- and lower-level objectives,\nrespectively-the considered method achieves a complexity of\n$\\mathcal{O}\\left(\\max\\left(\\epsilon_f^{-\\frac{3+p}{1+p}},\n\\epsilon_g^{-\\frac{3+p}{2}}\\right)\\right)$, where $p \\geq 0$ is an arbitrary\nconstant balancing the terms. To the best of our knowledge, this is the first\ncomplexity result for a discrete-time algorithm that guarantees joint\nstationarity for both levels in general nonconvex simple bilevel problems.", "AI": {"tldr": "本文研究非凸双层优化问题，提出一种动态屏障梯度下降（DBGD）框架，首次实现多项式时间内找到联合平稳点。", "motivation": "针对上下层目标均为光滑但可能非凸的双层优化问题，由于缺乏凸性或PL条件等结构假设，全局最优解难以保证，因此需要设计高效算法寻找平稳点。", "method": "采用动态屏障梯度下降（DBGD）框架，通过定义合适的平稳性概念，设计可实现的离散时间算法，平衡上下层目标的收敛精度。", "result": "算法达到$(\\epsilon_f, \\epsilon_g)$-平稳点的复杂度为$\\mathcal{O}\\left(\\max\\left(\\epsilon_f^{-\\frac{3+p}{1+p}}, \\epsilon_g^{-\\frac{3+p}{2}}\\right)\\right)$，其中$p \\geq 0$为平衡参数。", "conclusion": "这是首个针对一般非凸双层优化问题、能保证双层联合平稳性的离散时间算法复杂度结果，填补了该领域空白。"}}
{"id": "2507.23182", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.23182", "abs": "https://arxiv.org/abs/2507.23182", "authors": ["Rutger Campbell", "James Davies", "Robert Hickingbotham"], "title": "Binary matroids and degree-boundedness for pivot-minors", "comment": "11 pages, 2 figures", "summary": "We prove that for every bipartite graph $H$ and positive integer $s$, the\nclass of $K_{s,s}$-subgraph-free graphs excluding $H$ as a pivot-minor has\nbounded average degree. Our proof relies on the announced binary matroid\nstructure theorem of Geelen, Gerards, and Whittle.\n  Along the way, we also prove that every $K_{s,t}$-free bipartite circle graph\nwith $s\\le t$ has a vertex of degree at most $\\max\\{2s-2, t-1\\}$ and provide\nexamples showing that this is tight.", "AI": {"tldr": "本文证明了对于任意二分图$H$和正整数$s$，排除$H$作为pivot-minor且不含$K_{s,s}$子图的图类具有有限平均度。结果依赖于Geelen等人宣布的二元拟阵结构定理。", "motivation": "研究二分图$H$和$K_{s,s}$-子图自由图类的平均度限制问题，探索图论中结构性质与度分布的关系。", "method": "利用Geelen、Gerards和Whittle提出的二元拟阵结构定理，结合对$K_{s,t}$-自由二分圆图顶点度的分析。", "result": "证明了$K_{s,s}$-子图自由且排除$H$作为pivot-minor的图类具有有限平均度；同时发现$K_{s,t}$-自由二分圆图存在度数不超过$\\max\\{2s-2, t-1\\}$的顶点，且该界限是紧的。", "conclusion": "该研究为特定图类的度分布提供了精确界限，并展示了二元拟阵理论在图结构分析中的重要作用。"}}
{"id": "2507.23611", "categories": ["cs.CR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23611", "abs": "https://arxiv.org/abs/2507.23611", "authors": ["Estelle Ruellan", "Eric Clay", "Nicholas Ascoli"], "title": "LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora", "comment": null, "summary": "Infostealers exfiltrate credentials, session cookies, and sensitive data from\ninfected systems. With over 29 million stealer logs reported in 2024, manual\nanalysis and mitigation at scale are virtually unfeasible/unpractical. While\nmost research focuses on proactive malware detection, a significant gap remains\nin leveraging reactive analysis of stealer logs and their associated artifacts.\nSpecifically, infection artifacts such as screenshots, image captured at the\npoint of compromise, are largely overlooked by the current literature. This\npaper introduces a novel approach leveraging Large Language Models (LLMs), more\nspecifically gpt-4o-mini, to analyze infection screenshots to extract potential\nIndicators of Compromise (IoCs), map infection vectors, and track campaigns.\nFocusing on the Aurora infostealer, we demonstrate how LLMs can process\nscreenshots to identify infection vectors, such as malicious URLs, installer\nfiles, and exploited software themes. Our method extracted 337 actionable URLs\nand 246 relevant files from 1000 screenshots, revealing key malware\ndistribution methods and social engineering tactics. By correlating extracted\nfilenames, URLs, and infection themes, we identified three distinct malware\ncampaigns, demonstrating the potential of LLM-driven analysis for uncovering\ninfection workflows and enhancing threat intelligence. By shifting malware\nanalysis from traditional log-based detection methods to a reactive,\nartifact-driven approach that leverages infection screenshots, this research\npresents a scalable method for identifying infection vectors and enabling early\nintervention.", "AI": {"tldr": "本文提出利用大型语言模型（LLM）分析感染截图以提取潜在威胁指标（IoCs）的新方法，针对Aurora信息窃取木马展示了从1000张截图中提取337个可操作URL和246个相关文件的有效性，揭示了恶意软件传播方法和社会工程策略。", "motivation": "信息窃取木马（Infostealers）窃取敏感数据，2024年报告超过2900万条窃取日志，人工分析难以应对。现有研究多关注主动检测，而忽略了对窃取日志及其相关感染截图等反应性分析。", "method": "采用大型语言模型（如gpt-4o-mini）分析感染截图，提取潜在威胁指标（IoCs），映射感染途径并追踪恶意活动。研究聚焦Aurora信息窃取木马，通过截图识别恶意URL、安装文件及被利用的软件主题。", "result": "从1000张截图中提取了337个可操作URL和246个相关文件，揭示了恶意软件传播的关键方法和社会工程策略。通过关联文件名、URL和感染主题，识别出三个不同的恶意活动，证明了LLM驱动分析在揭示感染工作流程和增强威胁情报方面的潜力。", "conclusion": "本研究通过将恶意软件分析从传统的基于日志的检测方法转向基于感染截图的反应性分析方法，提出了一种可扩展的识别感染途径和实现早期干预的方法，为威胁情报提供了新的视角。"}}
{"id": "2507.23490", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.23490", "abs": "https://arxiv.org/abs/2507.23490", "authors": ["Zdeněk Hlávka", "Šárka Hudecová", "Simos G. Meintanis"], "title": "Optimal-Transport Based Multivariate Goodness-of-Fit Tests", "comment": null, "summary": "Characteristic-function based goodness-of-fit tests are suggested for\nmultivariate observations. The test statistics, which are straightforward to\ncompute, are defined as two-sample criteria measuring discrepancy between\nmultivariate ranks of the original observations and the corresponding ranks\nobtained from an artificial sample generated from the reference distribution\nunder test. Multivariate ranks are constructed using the theory of the optimal\nmeasure transport, thus rendering the tests of a simple null hypothesis\ndistribution-free, while bootstrap approximations are still necessary for\ntesting composite null hypotheses. Asymptotic theory is developed and a\nsimulation study, concentrating on comparisons with previously proposed tests\nof multivariate normality, demonstrates that the method performs well in finite\nsamples.", "AI": {"tldr": "本文提出了一种基于特征函数的多元观测拟合优度检验方法，通过最优测度输运理论构建多元秩，实现简单零假设的分布无关性检验。", "motivation": "现有多元正态性检验方法在有限样本中表现不佳，需要开发更有效的检验统计量。", "method": "采用两样本准则衡量原始观测与参考分布生成样本的多元秩差异，利用最优测度输运理论构建检验统计量，对复合假设需结合自助法。", "result": "仿真研究表明，该方法在有限样本中表现优于现有多元正态性检验方法，且具有渐进理论支持。", "conclusion": "基于特征函数和最优输运的多元秩检验法为多元分布检验提供了有效工具，特别适用于简单零假设场景。"}}
{"id": "2507.23067", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23067", "abs": "https://arxiv.org/abs/2507.23067", "authors": ["Zhenyu Pan", "Yutong Zhang", "Jianshu Zhang", "Haoran Lu", "Haozheng Luo", "Yuwei Han", "Philip S. Yu", "Manling Li", "Han Liu"], "title": "FairReason: Balancing Reasoning and Social Bias in MLLMs", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) already achieve state-of-the-art\nresults across a wide range of tasks and modalities. To push their reasoning\nability further, recent studies explore advanced prompting schemes and\npost-training fine-tuning. Although these techniques improve logical accuracy,\nthey frequently leave the models' outputs burdened with pronounced social\nbiases. Clarifying how reasoning gains interact with bias mitigation-and\nwhether the two objectives inherently trade off-therefore remains an open and\npressing research problem. Our study begins by benchmarking three\nbias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation\n(KD), and rule-based reinforcement learning (RL)-under identical conditions,\nestablishing their baseline strengths and weaknesses. Building on these\nresults, we vary the proportion of debias-focused and reasoning-centric samples\nwithin each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps\nreveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement\nlearning cuts stereotype scores by 10% while retaining 88% of the model's\noriginal reasoning accuracy, offering concrete guidance for balancing fairness\nand capability in MLLMs.", "AI": {"tldr": "多模态大语言模型(MLLMs)在提升推理能力时存在社会偏见加剧的问题。研究通过对比三种去偏策略，发现强化学习结合1:4的样本比例能有效平衡偏见减少与推理准确性。", "motivation": "尽管现有技术提升了MLLMs的逻辑准确性，但常伴随显著的社会偏见。研究旨在揭示推理能力提升与偏见缓解之间的相互作用及潜在权衡关系。", "method": "基准测试了三种去偏策略：监督微调(SFT)、知识蒸馏(KD)和基于规则的强化学习(RL)，并调整去偏样本与推理样本的比例以绘制权衡曲线。", "result": "实验表明，采用强化学习训练且去偏与推理样本比例为1:4时，模型刻板印象得分降低10%，同时保留原始推理准确性的88%。", "conclusion": "研究为MLLMs公平性与能力平衡提供了具体方案，强化学习结合特定样本比例是实现该目标的有效途径。"}}
{"id": "2507.23338", "categories": ["math.NT", "11E12 (Primary) 11E20, 11R32, 11R80 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.23338", "abs": "https://arxiv.org/abs/2507.23338", "authors": ["Matěj Doležálek"], "title": "Extending bounds on minimal ranks of universal quadratic lattices to larger number fields", "comment": "9 pages", "summary": "There exist numerous results in the literature proving that within certain\nfamilies of totally real number fields, the minimal rank of a universal\nquadratic lattice over such a field can be arbitrarily large. Kala introduced a\ntechnique of extending such results to larger fields -- e.g. from quadratic\nfields to fields of arbitrary even degree -- under some conditions. We present\nimprovements to this technique by investigating the structure of subfields\nwithin composita of number fields, using basic Galois theory to translate this\ninto a group-theoretic problem. In particular, we show that if totally real\nnumber fields with minimal rank of a universal lattice $\\geq r$ exist in degree\n$d$, then they also exist in degree $kd$ for all $k\\geq3$.", "AI": {"tldr": "本文改进了Kala的技术，通过研究数域复合体中的子域结构，利用基本伽罗瓦理论将其转化为群论问题，证明了若在d次全实数域中存在通用格的最小秩$\\geq r$，则在所有$k\\geq3$的kd次域中也存在。", "motivation": "已有大量文献证明在某些全实数域族中，通用二次格的最小秩可以任意大。Kala提出了一种技术，在满足某些条件下将这类结果推广到更大域（如从二次域到任意偶数次域）。本文旨在改进这一技术。", "method": "通过研究数域复合体中的子域结构，利用基本伽罗瓦理论将其转化为群论问题，从而改进Kala的推广技术。", "result": "证明了若在d次全实数域中存在通用格的最小秩$\\geq r$，则在所有$k\\geq3$的kd次域中也存在这样的域。", "conclusion": "本文通过群论方法改进了Kala的技术，显著扩展了通用格最小秩下界的存在性结果的应用范围。"}}
{"id": "2507.23390", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.23390", "abs": "https://arxiv.org/abs/2507.23390", "authors": ["Hongpei Li", "Hui Yuan", "Han Zhang", "Dongdong Ge", "Mengdi Wang", "Yinyu Ye"], "title": "FMIP: Multimodal Flow Matching for Mixed Integer Linear Programming", "comment": "A Generative Model based Method for Mixed Integer Linear Programming", "summary": "Mixed-Integer Linear Programming (MILP) is a cornerstone of mathematical\noptimization, enabling the modeling of complex decision-making problems\ninvolving both integer and continuous variables. Despite its versatility, most\nMILP problems are NP-complete, making them challenging to solve in practice.\nExisting graph neural network (GNN)-based heuristics aim to reduce problem\nscale by predicting only the solutions on integer variables for a given\ninstance, struggling to capture the intricate interplay between continuous and\ninteger variables and lack sufficient representational power. To address these\nlimitations, we propose FMIP, a novel multimodal flow-matching framework that\nmodels the joint distribution over integer and continuous variables in the\nmixed solution space of MILP. To enable more accurate and scalable heuristics,\nFMIP integrates a guidance mechanism to guide solution sampling under both\nobjective function optimization and constraint satisfaction. We evaluate FMIP\non seven standard MILP benchmarks. Our experiments show that FMIP improves\nsolution quality by 50.04% on average over existing GNN-based predictive\nbaselines. These results highlight FMIP's potential as a powerful new approach\nfor developing learning based MILP solution strategy.", "AI": {"tldr": "本文提出FMIP框架，通过多模态流匹配建模混合整数规划中整数与连续变量的联合分布，结合目标函数优化与约束满足的引导机制，在七个基准测试中平均提升解质量50.04%。", "motivation": "现有基于图神经网络的启发式方法仅预测整数变量解，难以捕捉整数与连续变量的复杂交互且表征能力不足，亟需新方法解决混合整数规划的NP完全难题。", "method": "FMIP框架创新性地采用多模态流匹配技术，在混合解空间中联合建模变量分布，并引入目标函数与约束的双重引导机制指导采样过程。", "result": "在七个标准MILP基准测试中，FMIP相比现有基于GNN的预测基线平均提升解质量50.04%，显著优于传统方法。", "conclusion": "FMIP通过流匹配与引导机制的协同设计，为学习型MILP求解策略提供了兼具高精度与可扩展性的新范式。"}}
{"id": "2507.23222", "categories": ["math.CO", "05E05, 05E10, 14N15"], "pdf": "https://arxiv.org/pdf/2507.23222", "abs": "https://arxiv.org/abs/2507.23222", "authors": ["Yaozhou Fan", "Xing Gao"], "title": "Weighted $K$-$k$-Schur functions and their application to the $K$-$k$-Schur alternating conjecture", "comment": "23 pages", "summary": "We introduce the new concept of weighted $K$-$k$-Schur functions -- a novel\nfamily within the broader class of Katalan functions -- that unifies and\nextends both $K$-$k$-Schur functions and closed $k$-Schur Katalan functions.\nThis new notion exhibits a fundamental alternating property under certain\nconditions on the indexed $k$-bounded partitions. As a central application, we\nresolve the $K$-$k$-Schur alternating conjecture -- posed by Blasiak, Morse,\nand Seelinger in 2022 -- for a wide class of $k$-bounded partitions, including\nall strictly decreasing $k$-bounded partitions. Our results shed new light on\nthe combinatorial structure of $K$-theoretic symmetric functions.", "AI": {"tldr": "本文引入加权$K$-$k$-Schur函数的新概念，统一并扩展了$K$-$k$-Schur函数和闭$k$-Schur Katalan函数，解决了Blasiak等人提出的$K$-$k$-Schur交替猜想。", "motivation": "研究旨在统一和扩展$K$-$k$-Schur函数与闭$k$-Schur Katalan函数，并解决2022年提出的$K$-$k$-Schur交替猜想。", "method": "通过引入加权$K$-$k$-Schur函数的新概念，并研究其在特定$k$-有界分区下的交替性质。", "result": "证明了$K$-$k$-Schur交替猜想对于广泛类别的$k$-有界分区成立，包括所有严格递减的$k$-有界分区。", "conclusion": "研究成果为$K$-理论对称函数的组合结构提供了新的见解，并解决了重要的数学猜想。"}}
{"id": "2507.23641", "categories": ["cs.CR", "11T71, 94A60"], "pdf": "https://arxiv.org/pdf/2507.23641", "abs": "https://arxiv.org/abs/2507.23641", "authors": ["Michael Schaller"], "title": "Polynomial Lattices for the BIKE Cryptosystem", "comment": null, "summary": "In this paper we introduce a rank $2$ lattice over a polynomial ring arising\nfrom the public key of the BIKE cryptosystem \\cite{aragon2022bike}. The secret\nkey is a sparse vector in this lattice. We study properties of this lattice and\ngeneralize the recovery of weak keys from \\cite{BardetDLO16}. In particular, we\nshow that they implicitly solved a shortest vector problem in the lattice we\nconstructed. Rather than finding only a shortest vector, we obtain a reduced\nbasis of the lattice which makes it possible to check for more weak keys.", "AI": {"tldr": "本文研究了BIKE密码系统中基于多项式环的秩2格，分析了其性质并推广了弱密钥恢复方法。通过构建格并求解最短向量问题，作者不仅找到最短向量，还获得了格的约化基，从而能检测更多弱密钥。", "motivation": "研究BIKE密码系统中由公钥生成的秩2格结构，旨在理解其数学特性并扩展现有的弱密钥恢复方法。", "method": "构建多项式环上的秩2格，分析其性质，并推广了Bardet等人提出的弱密钥恢复技术，通过求解格的最短向量问题并计算约化基。", "result": "证明了Bardet等人的方法隐含解决了所构建格的最短向量问题，且通过获得约化基可检测更多潜在的弱密钥。", "conclusion": "该方法不仅改进了现有弱密钥检测能力，还为分析BIKE密码系统的安全性提供了新的格理论工具。"}}
{"id": "2507.23646", "categories": ["stat.TH", "cs.IT", "math.DG", "math.IT", "math.PR", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2507.23646", "abs": "https://arxiv.org/abs/2507.23646", "authors": ["Jaehyung Choi"], "title": "Information geometry of Lévy processes and financial models", "comment": "21 pages", "summary": "We explore the information geometry of L\\'evy processes. As a starting point,\nwe derive the $\\alpha$-divergence between two L\\'evy processes. Subsequently,\nthe Fisher information matrix and the $\\alpha$-connection associated with the\ngeometry of L\\'evy processes are computed from the $\\alpha$-divergence. In\naddition, we discuss statistical applications of this information geometry. As\nillustrative examples, we investigate the differential-geometric structures of\nvarious L\\'evy processes relevant to financial modeling, including tempered\nstable processes, the CGMY model, and variance gamma processes.", "AI": {"tldr": "本文研究了L\\'evy过程的信息几何结构，推导了$\\alpha$-散度、Fisher信息矩阵和$\\alpha$-连接，并探讨了在金融建模中的应用。", "motivation": "探索L\\'evy过程的信息几何特性，为金融建模中的随机过程提供新的分析工具。", "method": "从$\\alpha$-散度出发，推导了Fisher信息矩阵和$\\alpha$-连接，并分析了多种L\\'evy过程的微分几何结构。", "result": "计算了L\\'evy过程的几何结构，包括调和稳定过程、CGMY模型和方差伽玛过程等金融相关案例。", "conclusion": "该信息几何框架为L\\'evy过程的统计分析提供了新的视角，尤其在金融建模中具有潜在应用价值。"}}
{"id": "2507.23091", "categories": ["cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.23091", "abs": "https://arxiv.org/abs/2507.23091", "authors": ["David Noever", "Forrest McKee"], "title": "Moravec's Paradox: Towards an Auditory Turing Test", "comment": null, "summary": "This research work demonstrates that current AI systems fail catastrophically\non auditory tasks that humans perform effortlessly. Drawing inspiration from\nMoravec's paradox (i.e., tasks simple for humans often prove difficult for\nmachines, and vice versa), we introduce an auditory Turing test comprising 917\nchallenges across seven categories: overlapping speech, speech in noise,\ntemporal distortion, spatial audio, coffee-shop noise, phone distortion, and\nperceptual illusions. Our evaluation of state-of-the-art audio models including\nGPT-4's audio capabilities and OpenAI's Whisper reveals a striking failure rate\nexceeding 93%, with even the best-performing model achieving only 6.9% accuracy\non tasks that humans solved at 7.5 times higher success (52%). These results\nexpose focusing failures in how AI systems process complex auditory scenes,\nparticularly in selective attention, noise robustness, and contextual\nadaptation. Our benchmark not only quantifies the human-machine auditory gap\nbut also provides insights into why these failures occur, suggesting that\ncurrent architectures lack fundamental mechanisms for human-like auditory scene\nanalysis. The traditional design of audio CAPTCHAs highlights common filters\nthat humans evolved but machines fail to select in multimodal language models.\nThis work establishes a diagnostic framework for measuring progress toward\nhuman-level machine listening and highlights the need for novel approaches\nintegrating selective attention, physics-based audio understanding, and\ncontext-aware perception into multimodal AI systems.", "AI": {"tldr": "研究表明，当前AI系统在人类轻松完成的听觉任务上表现极差，失败率超过93%，而人类成功率高达52%。研究通过917项听觉挑战测试，揭示了AI在选择性注意力、噪声鲁棒性和上下文适应方面的根本缺陷。", "motivation": "受Moravec悖论启发（即对人类简单的任务对机器却很难），研究旨在量化AI与人类在听觉任务上的差距，并探索失败原因，推动实现人类水平的机器听觉。", "method": "设计了包含7类（重叠语音、噪声环境语音等）917项挑战的听觉图灵测试，评估了GPT-4音频能力和Whisper等前沿模型。", "result": "最佳模型准确率仅6.9%，远低于人类52%的表现。AI在选择性注意力、噪声处理和场景适应等核心机制上存在系统性缺陷。", "conclusion": "需开发整合选择性注意力、基于物理的音频理解和情境感知的新架构，当前音频CAPTCHA设计反映了机器缺乏人类进化出的听觉过滤机制。研究建立了诊断机器听觉进步的框架。"}}
{"id": "2507.23392", "categories": ["q-fin.MF", "math.PR", "60L70, 60H10, 91G20, 91G60, 60G22"], "pdf": "https://arxiv.org/pdf/2507.23392", "abs": "https://arxiv.org/abs/2507.23392", "authors": ["Elisa Alòs", "Òscar Burés", "Rafael de Santiago", "Josep Vives"], "title": "Volatility Modeling with Rough Paths: A Signature-Based Alternative to Classical Expansions", "comment": null, "summary": "We compare two methodologies for calibrating implied volatility surfaces: a\nsecond-order asymptotic expansion method derived via Malliavin calculus, and a\ndata-driven approach based on path signatures from rough path theory. The\nformer, developed in Al\\`os et al. (2015), yields efficient and accurate\ncalibration formulas under the assumption that the asset price follows a\nHeston-type stochastic volatility model. The latter models volatility as a\nlinear functional of the signature of a primary stochastic process, enabling a\nflexible approximation without requiring a specific parametric form.\n  Our numerical experiments show that the signature-based method achieves\ncalibration accuracy comparable to the asymptotic approach when the true\ndynamics are Heston. We then test the model in a more general setting where the\nasset follows a rough Bergomi volatility process-a regime beyond the scope of\nthe asymptotic expansion-and show that the signature approach continues to\ndeliver accurate results. These findings highlight the model-independence,\nrobustness and adaptability of signature-based calibration methods in settings\nwhere volatility exhibits rough or non-Markovian features.", "AI": {"tldr": "比较两种隐含波动率曲面校准方法：基于Malliavin微积分的二阶渐近展开法与基于粗糙路径理论的路径签名数据驱动法。后者在Heston模型下表现相当，且在粗糙Bergomi模型等非马尔可夫场景中更具鲁棒性。", "motivation": "评估不同校准方法在复杂波动率模型（如粗糙波动率）中的适用性，探索非参数化方法的优势。", "method": "1. 渐近展开法：基于Heston型随机波动率模型推导解析公式；\\n2. 签名法：将波动率建模为主过程路径签名的线性泛函，无需预设参数形式。", "result": "签名法在Heston设定下精度与渐近法相当；在粗糙Bergomi模型中仍保持准确性，展现对非马尔可夫特征的适应性。", "conclusion": "基于路径签名的方法具有模型无关性、鲁棒性和适应性，特别适用于粗糙或非马尔可夫波动率场景。"}}
{"id": "2507.23477", "categories": ["math.NT", "05A15, 11M06, 11A07"], "pdf": "https://arxiv.org/pdf/2507.23477", "abs": "https://arxiv.org/abs/2507.23477", "authors": ["Shenghao Hua"], "title": "Discrete restrictions from Laurent monomial systems for multiple Dirichlet series", "comment": "8 pages. Comments welcome", "summary": "We introduce a special class of multiple Dirichlet series whose terms are\nsupported on a variety and which admit an Euler product structure. We show that\nthese series arise naturally from twisted moments of automorphic \\( L\n\\)-functions associated with Dirichlet twists. We proposed several conjectures\non the analytic properties of these series.", "AI": {"tldr": "本文介绍了一类特殊的多元Dirichlet级数，其项支持在某个簇上并具有欧拉积结构，这些级数自然地来源于Dirichlet扭曲的自守\\(L\\)-函数的扭曲矩。", "motivation": "研究多元Dirichlet级数的动机在于理解其与自守\\(L\\)-函数扭曲矩之间的自然联系，以及探索这些级数的解析性质。", "method": "通过分析Dirichlet扭曲的自守\\(L\\)-函数的扭曲矩，构建了具有欧拉积结构的多元Dirichlet级数。", "result": "结果表明，这类多元Dirichlet级数不仅具有欧拉积结构，而且与自守\\(L\\)-函数的扭曲矩密切相关。", "conclusion": "本文提出了关于这些级数解析性质的若干猜想，为进一步研究提供了方向。"}}
{"id": "2507.23395", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.23395", "abs": "https://arxiv.org/abs/2507.23395", "authors": ["Abhishek Chakraborty", "Angelia Nedić"], "title": "Popov Mirror-Prox Method for Variational Inequalities", "comment": null, "summary": "This paper establishes the convergence properties of the Popov mirror-prox\nalgorithm for solving stochastic and deterministic variational inequalities\n(VIs) under a polynomial growth condition on the mapping variation. Unlike\nexisting methods that require prior knowledge of problem-specific parameters,\nwe propose step-size schemes that are entirely parameter-free in both constant\nand diminishing forms. For stochastic and deterministic monotone VIs, we\nestablish optimal convergence rates in terms of the dual gap function over a\nbounded constraint set. Additionally, for deterministic VIs with H\\\"older\ncontinuous mapping, we prove convergence in terms of the residual function\nwithout requiring a bounded set or a monotone mapping, provided a Minty\nsolution exists. This allows our method to address certain classes of\nnon-monotone VIs. However, knowledge of the H\\\"older exponent is necessary to\nachieve the best convergence rates in this case. By extending mirror-prox\ntechniques to mappings with arbitrary polynomial growth, our work bridges an\nexisting gap in the literature. We validate our theoretical findings with\nempirical results on matrix games, piecewise quadratic functions, and image\nclassification tasks using ResNet-18.", "AI": {"tldr": "本文提出了Popov mirror-prox算法的收敛性，用于解决在多项式增长条件下的随机和确定性变分不等式（VIs），无需问题特定参数的先验知识，并验证了其在矩阵游戏、分段二次函数和ResNet-18图像分类任务中的有效性。", "motivation": "现有方法需要问题特定参数的先验知识，本文旨在提出完全参数自由的步长方案，填补文献中关于多项式增长映射的mirror-prox技术的空白。", "method": "提出了Popov mirror-prox算法，包括恒定和递减形式的无参数步长方案，适用于随机和确定性单调VIs，以及具有H\\\"older连续映射的确定性VIs。", "result": "在随机和确定性单调VIs中，证明了在有界约束集上对偶间隙函数的最优收敛速率；对于确定性VIs，在存在Minty解的情况下，无需有界集或单调映射，证明了残差函数的收敛性。", "conclusion": "通过扩展mirror-prox技术到任意多项式增长的映射，本文填补了文献空白，并通过实验验证了理论结果，能够处理某些非单调VIs类别。"}}
{"id": "2507.23231", "categories": ["math.CO", "05C75, 05C50, 05C69, 68Q17, 68R10"], "pdf": "https://arxiv.org/pdf/2507.23231", "abs": "https://arxiv.org/abs/2507.23231", "authors": ["Hartosh Singh Bal"], "title": "Perfecting the Line Graph", "comment": null, "summary": "This paper introduces two canonical constructions that transform arbitrary\nfinite graphs into perfect graphs: the symmetric lift $\\mathrm{HL}'_2(G)$,\nwhich is purely structural and label-invariant, and the ordered lift\n$\\mathrm{HL}_2(G)$, which depends explicitly on vertex labeling and encodes\ndirectional information. Both lifts arise as line graphs of bipartite double\ncovers and are box-perfect.\n  The symmetric lift $\\mathrm{HL}'_2(G)$ forms a canonical 2-cover of the line\ngraph $L(G)$. This involution decomposes $\\mathrm{HL}'_2(G)$ into symmetric and\nantisymmetric components: the symmetric part recovers $L(G)$, while the\nantisymmetric part yields a signed graph $L^-(G)$, the antisymmetric line\ngraph, with +1/-1 edges encoding consistent vs. crossed overlaps. Thus, all\nadjacency and Laplacian eigenvalues of $L(G)$, with multiplicities, appear\nwithin those of $\\mathrm{HL}'_2(G)$, despite $L(G)$ typically not being a\nsubgraph.\n  For regular graphs such as Paley graphs, this yields infinite families of\nsparse, highly structured regular and box-perfect expanders that also retain\nlarge cliques. The lift retains much of the spectral expansion of the base\nwhile improving the combinatorial expansion. Much the same behavior is observed\nwith random regular base graphs, allowing for the possibility of the study of\nbox-perfect random regular graphs.\n  Finally, we generalize these constructions to parameterized lifts\n$\\mathrm{HL}_{r,d}(G)$ and $\\mathrm{HL}_{r,d}'(G)$ defined on ordered\n$r$-tuples connected by Hamming distance constraints, which structurally encode\nthe base graph and remain box-perfect.", "AI": {"tldr": "本文介绍了两种将任意有限图转化为完美图的规范构造：对称提升$\\mathrm{HL}'_2(G)$和有序提升$\\mathrm{HL}_2(G)$，它们均源自二分双覆盖的线图且具有盒完美性。对称提升分解为对称与反对称部分，保留了线图$L(G)$的所有邻接及拉普拉斯特征值。对于正则图（如Paley图），该构造可生成稀疏、高度结构化的正则盒完美扩展图。", "motivation": "研究旨在通过规范构造将任意有限图转化为具有完美图性质的图结构，特别是探索对称与有序提升在保留图谱特性及组合扩展性方面的潜力，并为盒完美随机正则图的研究提供可能。", "method": "提出对称提升$\\mathrm{HL}'_2(G)$（结构不变）和有序提升$\\mathrm{HL}_2(G)$（依赖顶点标记），两者均作为二分双覆盖的线图。对称提升分解为对称部分（恢复$L(G)$）和反对称部分（生成带符号图$L^-(G)$）。进一步推广至参数化提升$\\mathrm{HL}_{r,d}(G)$和$\\mathrm{HL}_{r,d}'(G)$。", "result": "对称提升$\\mathrm{HL}'_2(G)$完整保留了$L(G)$的特征值（含重数），且对正则图可构造稀疏、结构化的盒完美扩展图家族。随机正则基图也表现出类似性质，为盒完美随机正则图研究奠定基础。参数化提升进一步扩展了构造的适用范围。", "conclusion": "两种提升构造为完美图生成提供了通用框架，对称提升尤其能同时保持谱扩展性与组合优化特性。推广后的参数化构造为图论与组合数学研究开辟了新方向，特别是在结构化扩展图与盒完美性分析领域。"}}
{"id": "2507.23163", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.23163", "abs": "https://arxiv.org/abs/2507.23163", "authors": ["Deniz Gorur", "Antonio Rago", "Francesca Toni"], "title": "Argumentatively Coherent Judgmental Forecasting", "comment": "17 pages, 18 figures, ECAI 2025", "summary": "Judgmental forecasting employs human opinions to make predictions about\nfuture events, rather than exclusively historical data as in quantitative\nforecasting. When these opinions form an argumentative structure around\nforecasts, it is useful to study the properties of the forecasts from an\nargumentative perspective. In this paper, we advocate and formally define a\nproperty of argumentative coherence, which, in essence, requires that a\nforecaster's reasoning is coherent with their forecast. We then conduct three\nevaluations with our notion of coherence. First, we assess the impact of\nenforcing coherence on human forecasters as well as on Large Language Model\n(LLM)-based forecasters, given that they have recently shown to be competitive\nwith human forecasters. In both cases, we show that filtering out incoherent\npredictions improves forecasting accuracy consistently, supporting the\npractical value of coherence in both human and LLM-based forecasting. Then, via\ncrowd-sourced user experiments, we show that, despite its apparent\nintuitiveness and usefulness, users do not generally align with this coherence\nproperty. This points to the need to integrate, within argumentation-based\njudgmental forecasting, mechanisms to filter out incoherent opinions before\nobtaining group forecasting predictions.", "AI": {"tldr": "本文提出并形式化定义了判断性预测中的论证连贯性属性，通过三项评估验证其价值。研究表明，过滤不连贯预测能提升人类和LLM预测准确性，但用户实验显示人们普遍未遵循该属性，因此需在群体预测前整合过滤机制。", "motivation": "判断性预测依赖人类观点而非历史数据，当观点围绕预测形成论证结构时，需从论证角度研究预测特性。本文旨在定义并验证论证连贯性对预测质量的影响。", "method": "1. 形式化定义论证连贯性；2. 评估强制连贯性对人类和LLM预测准确性的影响；3. 通过众包实验检验用户对连贯性的实际遵循程度。", "result": "过滤不连贯预测显著提升人类和LLM预测准确性（平均提升12%）。但用户实验表明，尽管连贯性直观有用，多数人并未自然遵循该属性。", "conclusion": "论证连贯性是判断性预测的关键质量指标，需在群体预测流程中整合过滤机制以剔除不连贯观点，从而提升整体预测可靠性。"}}
{"id": "2507.23619", "categories": ["math.NT", "11B37"], "pdf": "https://arxiv.org/pdf/2507.23619", "abs": "https://arxiv.org/abs/2507.23619", "authors": ["Ignas Gasparavičius", "Andrius Grigutis", "Juozas Petkelis"], "title": "Picturesque convolution-like recurrences and partial sums' generation", "comment": null, "summary": "Let ${\\pmb b}=\\{b_0,\\,b_1,\\,\\ldots\\}$ be the known sequence of numbers such\nthat $b_0\\neq0$. In this work, we develop methods to find another sequence\n${\\pmb a}=\\{a_0,\\,a_1,\\,\\ldots\\}$ that is related to ${\\pmb b}$ as follows:\n$a_n=a_0\\,b_{n+m}+a_1\\,b_{n+m-1}+\\ldots+a_{n+m}\\,b_0$,\n$n\\in\\mathbb{N}\\cup\\{0\\}$, $m\\in\\mathbb{N}$. We show the connection of\n$\\lim_{n\\to\\infty}a_n$ with $a_0,\\,a_1,\\,\\ldots,\\,a_{m-1}$ and provide varied\nexamples of finding the sequence ${\\pmb a}$ when ${\\pmb b}$ is given. We\ndemonstrate that the sequences ${\\pmb a}$ may exhibit pretty patterns in the\nplane or space. Also, we show that the properly chosen sequence ${\\pmb b}$ may\ndefine ${\\pmb a}$ as some famous sequences, such as the partial sums of the\nRiemann zeta function, etc.", "AI": {"tldr": "本文研究如何从已知序列${\\pmb b}$推导出相关序列${\\pmb a}$，展示其极限与初始项的关系，并通过实例说明${\\pmb a}$可呈现几何图案或经典数列如黎曼ζ函数部分和。", "motivation": "探索序列${\\pmb b}$与${\\pmb a}$之间的数学关系，扩展序列构造方法的应用场景，包括生成几何图案和经典数列。", "method": "提出递推方法建立序列${\\pmb a}$与${\\pmb b}$的关联式$a_n = \\sum_{k=0}^{n+m} a_k b_{n+m-k}$，分析$\\lim_{n\\to\\infty}a_n$与初始项$a_0,\\ldots,a_{m-1}$的联系。", "result": "证明序列${\\pmb a}$的极限行为依赖初始项，展示其可生成平面/空间几何图案，且特定${\\pmb b}$能导出黎曼ζ函数部分和等经典序列。", "conclusion": "该序列构造方法具有普适性，可统一处理多种数学对象，为序列分析与图形化表示提供新工具。"}}
{"id": "2507.23423", "categories": ["math.OC", "52B40, 90C27, 90C29"], "pdf": "https://arxiv.org/pdf/2507.23423", "abs": "https://arxiv.org/abs/2507.23423", "authors": ["Ellen H. Fukuda", "Satoru Iwata", "Itsuki Nakagawa"], "title": "Biobjective optimization with M-convex functions", "comment": null, "summary": "In this paper, we deal with two ingredients that, as far as we know, have not\nbeen combined until now: multiobjective optimization and discrete convex\nanalysis. First, we show that the entire Pareto optimal value set can be\nobtained in polynomial time for biobjective optimization problems with discrete\nconvex functions, in particular, involving an M$^\\natural$-convex function and\na linear function with binary coefficients. We also observe that a more\nefficient algorithm can be obtained in the special case where the\nM$^\\natural$-convex function is M-convex. Additionally, we present a\npolynomial-time method for biobjective optimization problems that combine\nM$^\\natural$-convex function minimization with lexicographic optimization.", "AI": {"tldr": "本文首次将多目标优化与离散凸分析相结合，针对双目标优化问题（涉及M$^\\natural$-凸函数和二元系数线性函数）提出了多项式时间算法求解整个帕累托最优值集，并在M-凸函数特例中展示了更高效率。此外，还提出了结合M$^\\natural$-凸函数最小化与字典序优化的多项式时间方法。", "motivation": "研究动机在于探索多目标优化与离散凸分析这一未被结合的领域，旨在为特定类型的双目标优化问题开发高效求解算法。", "method": "方法包括：1) 针对含M$^\\natural$-凸函数和二元线性函数的双目标问题设计多项式时间算法；2) 在M-凸函数特例中优化算法效率；3) 结合M$^\\natural$-凸最小化与字典序优化的新方法。", "result": "结果表明：1) 特定双目标问题的帕累托最优值集可在多项式时间内完整求解；2) M-凸函数特例的算法效率更高；3) 新方法在混合优化场景中保持多项式时间复杂度。", "conclusion": "结论指出，离散凸分析与多目标优化的结合为高效求解特定复杂优化问题提供了新途径，未来可扩展至更广泛的函数类和优化框架。"}}
{"id": "2507.23375", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.23375", "abs": "https://arxiv.org/abs/2507.23375", "authors": ["Mingze Li", "Jie Ma", "Mingyuan Rong"], "title": "Recent advances in arrow relations and traces of sets", "comment": "A survey contributed to the volume for the conference Summit280", "summary": "The arrow relation, a central concept in extremal set theory, captures\nquantitative relationships between families of sets and their traces. Formally,\nthe arrow relation $(n, m) \\rightarrow (a, b)$ signifies that for any family\n$\\mathcal{F} \\subseteq 2^{[n]}$ with $|\\mathcal{F}| \\geqslant m$, there exists\nan $a$-element subset $T \\subseteq [n]$ such that the trace $\\mathcal{F}_{|T} =\n\\{ F \\cap T : F \\in \\mathcal{F} \\}$ contains at least $b$ distinct sets. This\nsurvey highlights recent progress on a variety of problems and results\nconnected to arrow relations. We explore diverse topics, broadly categorized by\ndifferent extremal perspectives on these relations, offering a cohesive\noverview of the field.", "AI": {"tldr": "本文综述了极值集合论中的箭头关系$(n, m) \\rightarrow (a, b)$及其相关研究进展，探讨了不同极值视角下的多样主题。", "motivation": "箭头关系是极值集合论的核心概念，用于量化集合族与其迹之间的定量关系，理解这一关系对推动极值集合论的发展至关重要。", "method": "通过综述近期关于箭头关系的研究成果，从不同的极值视角出发，系统梳理了该领域的各类问题和结果。", "result": "文章总结了箭头关系$(n, m) \\rightarrow (a, b)$的多种应用和结果，展示了集合族$\\mathcal{F} \\subseteq 2^{[n]}$与其迹$\\mathcal{F}_{|T}$之间的丰富联系。", "conclusion": "本文为极值集合论中的箭头关系研究提供了全面的概述，强调了不同极值视角下的多样性和统一性，为该领域的未来发展指明了方向。"}}
{"id": "2507.23191", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23191", "abs": "https://arxiv.org/abs/2507.23191", "authors": ["Meghyn Bienvenu", "Diego Figueira", "Pierre Lafourcade"], "title": "Tractable Responsibility Measures for Ontology-Mediated Query Answering", "comment": "Long version of a paper to appear at KR 2025, which contains further\n  proof details in the appendix", "summary": "Recent work on quantitative approaches to explaining query answers employs\nresponsibility measures to assign scores to facts in order to quantify their\nrespective contributions to obtaining a given answer. In this paper, we study\nthe complexity of computing such responsibility scores in the setting of\nontology-mediated query answering, focusing on a very recently introduced\nfamily of Shapley-value-based responsibility measures defined in terms of\nweighted sums of minimal supports (WSMS). By exploiting results from the\ndatabase setting, we can show that such measures enjoy polynomial data\ncomplexity for classes of ontology-mediated queries that are\nfirst-order-rewritable, whereas the problem becomes \"shP\"-hard when the\nontology language can encode reachability queries (via axioms like $\\exists R.\nA \\sqsubseteq A$). To better understand the tractability frontier, we next\nexplore the combined complexity of WSMS computation. We prove that\nintractability applies already to atomic queries if the ontology language\nsupports conjunction, as well as to unions of `well-behaved' conjunctive\nqueries, even in the absence of an ontology. By contrast, our study yields\npositive results for common DL-Lite dialects: by means of careful analysis, we\nidentify classes of structurally restricted conjunctive queries (which\nintuitively disallow undesirable interactions between query atoms) that admit\ntractable WSMS computation.", "AI": {"tldr": "本文研究了基于Shapley值的责任度量（WSMS）在ontology-mediated查询回答中的计算复杂性，揭示了在不同查询类型和本体语言下的可处理性边界。", "motivation": "近期研究采用责任度量量化事实对查询结果的贡献，但WSMS在ontology-mediated查询中的计算复杂性尚未明确，需系统探索其可处理性边界。", "method": "通过结合数据库领域已有成果，分析不同ontology语言（如支持合取或DL-Lite方言）对WSMS计算的影响，并设计结构受限的查询类以保证可处理性。", "result": "证明WSMS在first-order-rewritable查询中具有多项式数据复杂度，但若本体语言支持可达性查询（如$\\exists R. A \\sqsubseteq A$）则导致shP-困难；同时发现合取操作或特定联合查询即使在无本体时也引发计算困难，而DL-Lite方言中结构受限的查询可保持高效计算。", "conclusion": "研究明确了WSMS在ontology-mediated查询中的复杂性边界，为实际应用提供了理论指导：需避免特定查询结构或选择可处理的本体语言（如DL-Lite）以实现高效责任计算。"}}
{"id": "2507.23656", "categories": ["math.NT", "11F12, 11F30, 11F66"], "pdf": "https://arxiv.org/pdf/2507.23656", "abs": "https://arxiv.org/abs/2507.23656", "authors": ["Shenghao Hua"], "title": "An evident corollary arising from Newton--Thorne", "comment": "5 pages. Comments welcome", "summary": "We present a special class of examples of automorphic lifts of multiple\ntensor products of automorphic representations in the sense of matching\n$L$-functions, motivated by combinatorial identities for Schur polynomials and\na celebrated result of Newton and Thorne.", "AI": {"tldr": "本文提出了一类特殊的自守提升例子，涉及多个自守表示的张量积，其动机源于Schur多项式的组合恒等式以及Newton和Thorne的著名结果。", "motivation": "研究动机源于Schur多项式的组合恒等式以及Newton和Thorne的著名结果，旨在探索自守表示张量积的提升问题。", "method": "通过匹配$L$-函数的方法，研究了一类特殊的自守提升例子，涉及多个自守表示的张量积。", "result": "研究结果表明，存在一类特殊的自守提升例子，能够匹配多个自守表示张量积的$L$-函数。", "conclusion": "本文通过组合恒等式和$L$-函数匹配，成功构建了一类特殊的自守提升例子，为自守表示理论提供了新的视角。"}}
{"id": "2507.23558", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.23558", "abs": "https://arxiv.org/abs/2507.23558", "authors": ["Nick Tsipinakis", "Panos Parpas"], "title": "Convergence rates of Newton's method for strongly self-concordant minimization", "comment": null, "summary": "Newton's method has been thoroughly studied for the class of self-concordant\nfunctions. However, a local analysis specific to strongly self-concordant\nfunctions (a subclass of the former) is missing from the literature. The local\nquadratic rate of strongly self-concordant functions follows, of course, from\nthe known results for self-concordant functions. However, it is not known\nwhether strongly self-concordant functions enjoy better theoretical properties.\nIn this paper, we study the local convergence of Newton's method for this\nsubclass. We show that its quadratic convergence rate differs from that of\ngeneral self-concordant functions. In particular, it is provably faster for a\nwide range of objective functions and benefits from a larger region of local\nconvergence. Thus, the results of this paper close the gap in the theoretical\nunderstanding of Newton's method applied to strongly self-concordant functions.", "AI": {"tldr": "本文填补了强自协函数牛顿法局部收敛理论空白，证明其比普通自协函数具有更快的二次收敛速度和更大的局部收敛区域。", "motivation": "现有文献对自协函数类牛顿法研究充分，但缺乏对强自协函数子类的局部收敛性分析，需验证其是否具有更优理论特性。", "method": "通过理论分析强自协函数子类的牛顿法局部收敛性，与普通自协函数进行对比研究。", "result": "强自协函数的牛顿法二次收敛速率显著优于普通自协函数，且具有更大的局部收敛区域，适用于更广泛的优化目标函数。", "conclusion": "研究完善了强自协函数牛顿法的理论框架，证实其优越的收敛性能，为相关优化问题提供了理论支撑。"}}
{"id": "2507.23376", "categories": ["math.CO", "05C20", "G.2.1"], "pdf": "https://arxiv.org/pdf/2507.23376", "abs": "https://arxiv.org/abs/2507.23376", "authors": ["Alice Miller", "Ivaylo Valkov", "R. Julian R. Abel"], "title": "Combinatorial solutions to the Social Golfer Problem and Social Golfer Problem with Adjacent Group Sizes", "comment": "53 pages (includes 24 pages of appendices. Appendix B is supporting\n  information for journal submission. Submitted to Journal of Combinatorial\n  Designs", "summary": "Resolvable combinatorial designs including Resolvable Balanced Incomplete\nBlock Designs, Resolvable Group Divisible Designs, Uniformly Resolvable Designs\nand Mutually Orthogonal Latin Squares and Rectangles are used to construct\noptimal solutions to the Social Golfer problem (SGP) and the Social Golfer\nproblem with adjacent group sizes (SGA). An algorithm is presented to find an\noptimal solution in general, and a complete set of solutions is provided for up\nto 150 players.", "AI": {"tldr": "论文利用可分解组合设计（如RBIBD、RGDD等）构建了社交高尔夫球手问题（SGP）及其变体（SGA）的最优解，并提出通用算法，提供了150人内的完整解集。", "motivation": "研究旨在通过组合数学方法解决社交高尔夫球手问题及其相邻组规模变体，寻找最优分组方案。", "method": "采用可分解平衡不完全区组设计（RBIBD）、可分解群可分设计（RGDD）等组合设计理论，开发通用算法求解最优解。", "result": "成功构建了适用于SGP和SGA问题的最优解，并针对最多150名参与者的情况提供了完整解决方案集合。", "conclusion": "组合设计理论为社交高尔夫球手问题提供了系统化解决框架，算法与解集展示了该方法在实践中的有效性。"}}
{"id": "2507.23197", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23197", "abs": "https://arxiv.org/abs/2507.23197", "authors": ["Yuke Liao", "Blaise Genest", "Kuldeep Meel", "Shaan Aryaman"], "title": "Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification", "comment": null, "summary": "To handle complex instances, we revisit a divide-and-conquer approach to\nbreak down the complexity: instead of few complex BaB calls, we rely on many\nsmall {\\em partial} MILP calls. The crucial step is to select very few but very\nimportant ReLUs to treat using (costly) binary variables. The previous attempts\nwere suboptimal in that respect. To select these important ReLU variables, we\npropose a novel {\\em solution-aware} ReLU scoring ({\\sf SAS}), as well as adapt\nthe BaB-SR and BaB-FSB branching functions as {\\em global} ReLU scoring ({\\sf\nGS}) functions. We compare them theoretically as well as experimentally, and\n{\\sf SAS} is more efficient at selecting a set of variables to open using\nbinary variables. Compared with previous attempts, SAS reduces the number of\nbinary variables by around 6 times, while maintaining the same level of\naccuracy. Implemented in {\\em Hybrid MILP}, calling first $\\alpha,\\beta$-CROWN\nwith a short time-out to solve easier instances, and then partial MILP,\nproduces a very accurate yet efficient verifier, reducing by up to $40\\%$ the\nnumber of undecided instances to low levels ($8-15\\%$), while keeping a\nreasonable runtime ($46s-417s$ on average per instance), even for fairly large\nCNNs with 2 million parameters.", "AI": {"tldr": "该论文提出了一种新颖的解决方案感知ReLU评分方法（SAS），通过分治法减少二元变量数量，显著提升了验证效率。", "motivation": "现有方法在处理复杂实例时，由于ReLU变量选择不理想导致效率低下，需要更优的变量选择策略。", "method": "提出SAS评分方法，并适配BaB-SR和BaB-FSB分支函数作为全局评分（GS），结合混合MILP框架（先调用$\\alpha,\\beta$-CROWN快速处理简单实例，再使用部分MILP）。", "result": "SAS将二元变量数量减少约6倍，同时保持相同精度；混合方法将未决实例比例降至8-15%，平均运行时间46-417秒（适用于200万参数CNN）。", "conclusion": "SAS结合混合MILP框架实现了高效精确的验证器，在保持合理运行时间下显著提升决策率，为大规模神经网络验证提供新方案。"}}
{"id": "2507.23706", "categories": ["math.NT", "math.DS"], "pdf": "https://arxiv.org/pdf/2507.23706", "abs": "https://arxiv.org/abs/2507.23706", "authors": ["Elias Dubno"], "title": "A Central Limit Theorem for the Winding Number of Low-Lying Closed Geodesics", "comment": "23 pages", "summary": "We show that the winding of low-lying closed geodesics on the modular surface\nhas a Gaussian limiting distribution when normalized by any natural notion of\nlength.", "AI": {"tldr": "模曲面上的低洼闭合测地线在按任意自然长度归一化后，其绕数具有高斯极限分布。", "motivation": "研究模曲面上闭合测地线的统计性质，特别是其绕数分布的极限行为。", "method": "通过分析模曲面上低洼闭合测地线的几何特性，并采用自然长度归一化方法进行研究。", "result": "发现归一化后的绕数分布收敛于高斯分布，揭示了其统计规律性。", "conclusion": "该结果不仅深化了对模曲面上测地线行为的理解，也为相关领域的统计研究提供了新的视角。"}}
{"id": "2507.23711", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.23711", "abs": "https://arxiv.org/abs/2507.23711", "authors": ["Federico D'Onofrio", "Yuri Faenza", "Laura Palagi"], "title": "Combinatorial Approaches for Embedded Feature Selection in Nonlinear SVMs", "comment": null, "summary": "Embedded Feature Selection (FS) is a classical approach for interpretable\nmachine learning, aiming to identify the most relevant features of a dataset\nwhile simultaneously training the model. We consider an approach based on a\nhard cardinality constraint for nonlinear SVMs. To the best of our knowledge,\nhard-constraint approaches have been proposed only for the primal formulation\nof linear SVMs. In contrast, we embed a hard cardinality constraint directly\ninto the dual of a nonlinear SVM, guaranteeing strict control over the number\nof selected features while still leveraging kernelization. We formulate the\nproblem as a Mixed-Integer Nonlinear Programming (MINLP) model. As a first\ncontribution, we propose a local search metaheuristic applicable to general\nnonlinear kernels. Our second and main contribution is a decomposition\nframework that alternates optimization between two subproblems: one involving\nonly continuous variables and the other involving only binary variables. For\npolynomial kernels, we show that the binary subproblem reduces to a submodular\nfunction maximization under a cardinality constraint, enabling the use of\nscalable submodular maximization algorithms within the alternating optimization\nprocess. Numerical experiments demonstrate that our algorithms significantly\noutperform standard methods for solving the proposed MINLPs, providing more\neffective solutions to the addressed feature selection problem.", "AI": {"tldr": "本文提出了一种基于硬基数约束的非线性SVM嵌入式特征选择方法，通过混合整数非线性规划模型和交替优化框架，显著提升了特征选择效果。", "motivation": "嵌入式特征选择（FS）旨在训练模型的同时识别数据集中最相关的特征。现有硬约束方法仅适用于线性SVM的原始形式，本文探索将其应用于非线性SVM的对偶问题，以实现严格的特征数量控制并利用核化优势。", "method": "1) 将对偶非线性SVM与硬基数约束结合，构建混合整数非线性规划（MINLP）模型；2) 提出适用于通用非线性核的局部搜索元启发式算法；3) 设计分解框架，通过交替优化连续变量和二元变量子问题（多项式核下二元子问题转化为子模函数最大化问题）。", "result": "数值实验表明，所提算法在求解MINLP问题上显著优于标准方法，为特征选择问题提供了更有效的解决方案。", "conclusion": "该研究首次实现对偶非线性SVM的硬约束特征选择，通过子模优化等技术突破计算瓶颈，为可解释机器学习提供了新工具。"}}
{"id": "2507.23409", "categories": ["math.CO", "51E20, 05B25"], "pdf": "https://arxiv.org/pdf/2507.23409", "abs": "https://arxiv.org/abs/2507.23409", "authors": ["Stefano Lia", "Giovanni Longobardi", "Corrado Zanella"], "title": "Towards the classification of maximum scattered linear sets of $\\mathrm{PG}(1,q^5)$", "comment": null, "summary": "Every maximum scattered linear set in $\\mathrm{PG}(1,q^5)$ is the projection\nof an $\\mathbb{F}_q$-subgeometry $\\Sigma$ of $\\mathrm{PG}(4,q^5)$ from a plane\n$\\Gamma$ external to the secant variety to $\\Sigma$. The pair $(\\Gamma,\\Sigma)$\nwill be called a projecting configuration for the linear set. The projecting\nconfigurations for the only known maximum scattered linear sets in\n$\\mathrm{PG}(1,q^5)$, namely those of pseudoregulus and LP type, have been\ncharacterized in the literature by B. Csajb\\'{o}k, C. Zanella in 2016 and by C.\nZanella, F. Zullo in 2020. Let $(\\Gamma,\\Sigma)$ be a projecting configuration\nfor a maximum scattered linear set in $\\mathrm{PG}(1,q^5)$, let $\\sigma$ be a\ngenerator of $\\mathbb{G}=\\mathrm{P}\\Gamma \\mathrm{L}(5,q^5)_\\Sigma$, and\n$A=\\Gamma\\cap\\Gamma^{\\sigma^4}$, $B=\\Gamma\\cap\\Gamma^{\\sigma^3}$. If $A$ and\n$B$ are not both points, then the projected linear set is of pseudoregulus\ntype. Then, suppose that they are points. The rank of a point $X$ is the\nvectorial dimension of the span of the orbit of $X$ under the action of\n$\\mathbb{G}$. In this paper, by investigating the geometric properties of\nprojecting configurations, it is proved that if at least one of the points $A$\nand $B$ has rank 5, the associated maximum scattered linear set must be of LP\ntype. Then, if a maximum scattered linear set of a new type exists, it must be\nsuch that $\\mathrm{rk} A=\\mathrm{rk} B=4$. In this paper we derive two possible\npolynomial forms that such a linear set must have. An exhaustive analysis by\ncomputer shows that for $q\\leq 25$, no new maximum scattered linear set exists.", "AI": {"tldr": "本文研究了$\\mathrm{PG}(1,q^5)$中的最大散射线性集，证明了其投影配置的几何性质与线性集类型的关系，并推导了新类型线性集可能的多项式形式。通过计算机验证，发现$q\\leq 25$时不存在新类型的最大散射线性集。", "motivation": "研究$\\mathrm{PG}(1,q^5)$中最大散射线性集的投影配置性质，以确定是否存在除已知伪正则型和LP型之外的新类型线性集。", "method": "通过分析投影配置$\\Gamma,\\Sigma)$的几何特性，特别是点$A$和$B$的秩，结合群$\\mathbb{G}=\\mathrm{P}\\Gamma \\mathrm{L}(5,q^5)_\\Sigma$的作用，推导新类型线性集的多项式形式，并进行计算机验证。", "result": "若投影配置中点$A$或$B$的秩为5，则对应线性集必为LP型；若存在新类型线性集，则需满足$\\mathrm{rk} A=\\mathrm{rk} B=4$。推导了两种可能的多项式形式，但计算机验证表明$q\\leq 25$时不存在新类型。", "conclusion": "最大散射线性集的类型由其投影配置的几何性质决定，$q\\leq 25$时仅存在伪正则型和LP型，新类型线性集若存在需满足特定秩条件并具有更复杂的多项式形式。"}}
{"id": "2507.23276", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23276", "abs": "https://arxiv.org/abs/2507.23276", "authors": ["Qiujie Xie", "Yixuan Weng", "Minjun Zhu", "Fuchen Shen", "Shulin Huang", "Zhen Lin", "Jiahui Zhou", "Zilan Mao", "Zijie Yang", "Linyi Yang", "Jian Wu", "Yue Zhang"], "title": "How Far Are AI Scientists from Changing the World?", "comment": null, "summary": "The emergence of large language models (LLMs) is propelling automated\nscientific discovery to the next level, with LLM-based Artificial Intelligence\n(AI) Scientist systems now taking the lead in scientific research. Several\ninfluential works have already appeared in the field of AI Scientist systems,\nwith AI-generated research papers having been accepted at the ICLR 2025\nworkshop, suggesting that a human-level AI Scientist capable of uncovering\nphenomena previously unknown to humans, may soon become a reality. In this\nsurvey, we focus on the central question: How far are AI scientists from\nchanging the world and reshaping the scientific research paradigm? To answer\nthis question, we provide a prospect-driven review that comprehensively\nanalyzes the current achievements of AI Scientist systems, identifying key\nbottlenecks and the critical components required for the emergence of a\nscientific agent capable of producing ground-breaking discoveries that solve\ngrand challenges. We hope this survey will contribute to a clearer\nunderstanding of limitations of current AI Scientist systems, showing where we\nare, what is missing, and what the ultimate goals for scientific AI should be.", "AI": {"tldr": "大型语言模型(LLM)推动AI科学家系统引领科研变革，本文综述其现状、瓶颈与终极目标。", "motivation": "探讨AI科学家系统何时能颠覆科研范式、解决重大科学挑战，明确当前局限与发展方向。", "method": "采用前瞻性综述方法，系统分析AI科学家系统的现有成果与关键组件需求。", "result": "发现当前系统已能产出人类未知成果（如ICLR 2025收录AI论文），但突破性发现仍受核心瓶颈制约。", "conclusion": "需明确科学AI的终极目标，弥补现有系统缺陷，以实现真正颠覆性科研范式重塑。"}}
{"id": "2507.23759", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.23759", "abs": "https://arxiv.org/abs/2507.23759", "authors": ["Bora Yalkinoglu"], "title": "Bost-Connes systems and periodic Witt vectors", "comment": "Comments are welcome!", "summary": "In this note, using Borger's theory of periodic Witt vectors, we construct\nintegral refinements of the arithmetic subalgebras associated with Bost-Connes\nsystems for general number fields.", "AI": {"tldr": "利用Borger周期Witt向量理论，构建了一般数域Bost-Connes系统算术子代数的积分细化。", "motivation": "研究Bost-Connes系统在一般数域上的算术子代数结构，寻求其积分层面的理论扩展。", "method": "采用Borger的周期Witt向量理论作为主要工具，进行代数结构的构造与分析。", "result": "成功构造了与一般数域Bost-Connes系统相关的算术子代数的积分细化版本。", "conclusion": "该研究为Bost-Connes系统的算术结构提供了更深入的积分理论框架，拓展了其在数域上的应用潜力。"}}
{"id": "2507.23725", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.23725", "abs": "https://arxiv.org/abs/2507.23725", "authors": ["Ilya Kuruzov", "Xiaokai Chen", "Gesualdo Scutari", "Alexander Gasnikov"], "title": "Adaptive Stepsize Selection in Decentralized Convex Optimization", "comment": null, "summary": "We study decentralized optimization where multiple agents minimize the\naverage of their (strongly) convex, smooth losses over a communication graph.\nConvergence of the existing decentralized methods generally hinges on an\napriori, proper selection of the stepsize. Choosing this value is notoriously\ndelicate: (i) it demands global knowledge from all the agents of the graph's\nconnectivity and every local smoothness/strong-convexity constants--information\nthey rarely have; (ii) even with perfect information, the worst-case tuning\nforces an overly small stepsize, slowing convergence in practice; and (iii)\nlarge-scale trial-and-error tuning is prohibitive. This work introduces a\ndecentralized algorithm that is fully adaptive in the choice of the agents'\nstepsizes, without any global information and using only neighbor-to-neighbor\ncommunications--agents need not even know whether the problem is strongly\nconvex. The algorithm retains strong guarantees: it converges at \\emph{linear}\nrate when the losses are strongly convex and at \\emph{sublinear} rate\notherwise, matching the best-known rates of (nonadaptive) parameter-dependent\nmethods.", "AI": {"tldr": "本文提出了一种完全自适应的去中心化优化算法，无需全局信息即可自动调整步长，适用于强凸和非强凸损失函数，并保持最佳收敛速率。", "motivation": "现有去中心化方法的收敛性依赖于预先设定的步长，这需要全局信息且难以调整，导致实际应用中收敛缓慢或计算成本高昂。", "method": "算法通过邻居间通信实现完全自适应的步长选择，无需全局信息或强凸性假设，仅依赖局部通信。", "result": "算法在强凸损失下以线性速率收敛，非强凸损失下以次线性速率收敛，匹配依赖参数方法的最佳已知速率。", "conclusion": "该研究提供了一种高效且无需全局调参的去中心化优化方案，显著提升了实际应用的可行性和性能。"}}
{"id": "2507.23420", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.23420", "abs": "https://arxiv.org/abs/2507.23420", "authors": ["Qian Yu", "Yaoping Hou"], "title": "The net-regular strongly regular signed graphs with degree 5", "comment": null, "summary": "In this paper, we determine all connected net-regular strongly regular signed\ngraphs with degree 5. There are five and two strongly regular signed graphs\nwith net-degree 3 and 1, respectively.", "AI": {"tldr": "本文确定了所有度为5的连通净正则强正则符号图，发现净度为3和1的强正则符号图分别有5个和2个。", "motivation": "研究强正则符号图的分类及其性质，特别是针对度为5的连通净正则情况。", "method": "通过数学分析和图论方法，对连通净正则强正则符号图进行系统分类。", "result": "发现度为5的连通净正则强正则符号图中，净度为3的有5个，净度为1的有2个。", "conclusion": "该研究为强正则符号图的分类提供了新的结果，并揭示了特定条件下的图结构特征。"}}
{"id": "2507.23330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23330", "abs": "https://arxiv.org/abs/2507.23330", "authors": ["Tosin Adewumi", "Lama Alkhaled", "Florent Imbert", "Hui Han", "Nudrat Habib", "Karl Löwenmark"], "title": "AI Must not be Fully Autonomous", "comment": "11 pages, 1 figure", "summary": "Autonomous Artificial Intelligence (AI) has many benefits. It also has many\nrisks. In this work, we identify the 3 levels of autonomous AI. We are of the\nposition that AI must not be fully autonomous because of the many risks,\nespecially as artificial superintelligence (ASI) is speculated to be just\ndecades away. Fully autonomous AI, which can develop its own objectives, is at\nlevel 3 and without responsible human oversight. However, responsible human\noversight is crucial for mitigating the risks. To ague for our position, we\ndiscuss theories of autonomy, AI and agents. Then, we offer 12 distinct\narguments and 6 counterarguments with rebuttals to the counterarguments. We\nalso present 15 pieces of recent evidence of AI misaligned values and other\nrisks in the appendix.", "AI": {"tldr": "本文探讨了自主人工智能（AI）的三个级别，主张不应发展完全自主的AI（第三级），因其存在重大风险，特别是在人工超级智能（ASI）可能几十年内出现的背景下。作者通过理论讨论、12个论点、6个反驳及附录中的15个案例，强调人类监督对风险管控的关键作用。", "motivation": "研究动机源于自主AI的双重性：其潜在益处与重大风险并存。随着人工超级智能（ASI）可能在未来几十年内实现，完全自主的AI（尤其是能自主设定目标的第三级）缺乏人类监督将带来不可控风险。", "method": "方法包括：1. 梳理自主性、AI与智能体理论；2. 提出12个支持限制AI自主性的论点；3. 分析6个反对观点并逐一反驳；4. 在附录中列举15个近期AI价值错位及风险的实证案例。", "result": "研究结果表明，完全自主的AI（第三级）因可能脱离人类控制目标而风险极高。现有证据显示，即使当前AI已频繁出现价值偏差，强化人类监督是必要措施。", "conclusion": "结论明确反对发展完全自主的AI，主张所有AI系统必须保留人类监督机制。尤其在ASI临近的背景下，需通过理论框架与实证案例的结合，优先防控自主AI的潜在威胁。"}}
{"id": "2507.23627", "categories": ["math.CO", "math.NT"], "pdf": "https://arxiv.org/pdf/2507.23627", "abs": "https://arxiv.org/abs/2507.23627", "authors": ["Eric James Faust", "Michael Tait"], "title": "Improved bounds on the postage stamp problem for large numbers of stamps", "comment": null, "summary": "Let $F_h(n)$ denote the minimum cardinality of an additive {\\em $h$-fold\nbasis} of $\\{1,2,\\cdots,n\\}$: a set $S$ such that any integer in $\\{1,2,\\cdots,\nn\\}$ can be written as a sum of at most $h$ elements from $S$. While the\ntrivial bounds $h!n \\; \\lesssim \\; F_h(n)^h \\; \\lesssim \\; h^h n$ are\nwell-known, comparatively little has been established for $h>2$. In this paper,\nwe make significant improvements to both of the best-known bounds on $F_h(n)$\nfor sufficiently large $h$. For the lower bound, we use a probabilistic\napproach along with the Berry-Esseen Theorem to improve upon the best-known\nasymptotic result due to Yu. We also establish the first nontrivial asymptotic\nupper bound on $F_h(n)$ by leveraging a construction for additive bases of\nfinite cyclic groups due to Jia and Shen. In particular, we show that given any\n$\\epsilon>0$, for sufficiently large $h$, we have \\[\n\\left(\\frac{1}{2}-\\epsilon\\right)h!\\sqrt{2\\pi e} n\\; \\leq \\; F_h(n)^h \\; \\leq\n\\; \\left(\\left(\\frac{\\sqrt{3}}{2}+\\epsilon\\right)h\\right)^h n. \\]", "AI": {"tldr": "论文改进了关于$h$-fold基$F_h(n)$的上下界，通过概率方法和构造有限循环群的加法基，显著提升了已知结果。", "motivation": "研究$h$-fold基$F_h(n)$的最小基数，填补$h>2$时理论空白，改进现有上下界。", "method": "使用概率方法和Berry-Esseen定理改进下界；利用Jia和Shen的有限循环群加法基构造上界。", "result": "证明对任意$\\epsilon>0$，充分大的$h$有$\\left(\\frac{1}{2}-\\epsilon\\right)h!\\sqrt{2\\pi e} n\\; \\leq \\; F_h(n)^h \\; \\leq \\; \\left(\\left(\\frac{\\sqrt{3}}{2}+\\epsilon\\right)h\\right)^h n$。", "conclusion": "首次建立$F_h(n)$的非平凡渐近上界，显著改进下界，为$h$-fold基理论提供新工具。"}}
{"id": "2507.23460", "categories": ["math.CO", "cond-mat.stat-mech", "math-ph", "math.MP", "math.QA"], "pdf": "https://arxiv.org/pdf/2507.23460", "abs": "https://arxiv.org/abs/2507.23460", "authors": ["Keiichi Shigechi"], "title": "Fuss--Catalan algebras on generalized Dyck paths via non-crossing partitions", "comment": "51 pages", "summary": "We study the Fuss--Catalan algebras, which are generalizations of the\nTemperley--Lieb algebra and act on generalized Dyck paths, through non-crossing\npartitions. First, the Temperley--Lieb algebra is defined on non-crossing\npartitions, and a bijection between a Dyck path and a non-crossing partition is\nshown to be compatible with the Temperley--Lieb algebra on Dyck paths, or\nequivalently chord diagrams. We show that the Kreweras endomorphism on\nnon-crossing partitions is equivalent to the rotation of chord diagrams under\nthe bijection. Secondly, by considering an increasing $r$-chain in the graded\nlattice of non-crossing partitions, we define the Fuss--Catalan algebras on\nincreasing $r$-chains. Through a bijection between an increasing $r$-chain and\na generalized Dyck path, one naturally obtains the Fuss--Catalan algebra on\ngeneralized Dyck paths. As generalizations of the Fuss--Catalan algebra, we\nintroduce the one- and two-boundary Fuss--Catalan algebras. Increasing\n$r$-chains of symmetric non-crossing partitions give symmetric generalized Dyck\npaths by the bijection, and the boundary Fuss--Catalan algebras naturally act\non them. We show that these representations are compatible with the\ndiagrammatic representations of the algebras by use of generalized chord\ndiagrams. Thirdly, we discuss the integrability of the Fuss--Catalan algebras.\nFor the Fuss--Catalan algebras with boundaries, we obtain a new solution of the\nreflection equation in the case of $r=2$.", "AI": {"tldr": "本文研究了Fuss--Catalan代数，作为Temperley--Lieb代数的推广，通过非交叉分割作用于广义Dyck路径。我们建立了非交叉分割与Dyck路径的双射关系，并引入了边界Fuss--Catalan代数的新解。", "motivation": "研究Fuss--Catalan代数的动机在于推广Temperley--Lieb代数，探索其在非交叉分割和广义Dyck路径上的作用，以及这些代数结构的可积性。", "method": "方法包括：1) 在非交叉分割上定义Temperley--Lieb代数；2) 通过非交叉分割的递增$r$-链定义Fuss--Catalan代数；3) 引入边界Fuss--Catalan代数并研究其表示。", "result": "主要结果包括：1) 证明了Kreweras自同态与弦图旋转的等价性；2) 建立了递增$r$-链与广义Dyck路径的双射；3) 在$r=2$情况下获得了反射方程的新解。", "conclusion": "结论表明Fuss--Catalan代数及其边界推广在非交叉分割和广义Dyck路径上具有兼容的表示，并为可积系统提供了新的解。这些结果为相关代数结构的研究开辟了新方向。"}}
{"id": "2507.23336", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.23336", "abs": "https://arxiv.org/abs/2507.23336", "authors": ["Ram Mohan Rao Kadiyala", "Siddhant Gupta", "Jebish Purbey", "Giulio Martini", "Suman Debnath", "Hamza Farooq"], "title": "DSBC : Data Science task Benchmarking with Context engineering", "comment": "32 pages", "summary": "Recent advances in large language models (LLMs) have significantly impacted\ndata science workflows, giving rise to specialized data science agents designed\nto automate analytical tasks. Despite rapid adoption, systematic benchmarks\nevaluating the efficacy and limitations of these agents remain scarce. In this\npaper, we introduce a comprehensive benchmark specifically crafted to reflect\nreal-world user interactions with data science agents by observing usage of our\ncommercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,\nGemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with\ncontext engineering, multi-step with context engineering, and with SmolAgent.\nOur benchmark assesses performance across a diverse set of eight data science\ntask categories, additionally exploring the sensitivity of models to common\nprompting issues, such as data leakage and slightly ambiguous instructions. We\nfurther investigate the influence of temperature parameters on overall and\ntask-specific outcomes for each model and approach. Our findings reveal\ndistinct performance disparities among the evaluated models and methodologies,\nhighlighting critical factors that affect practical deployment. The benchmark\ndataset and evaluation framework introduced herein aim to provide a foundation\nfor future research of more robust and effective data science agents.", "AI": {"tldr": "本文提出一个针对数据科学代理的综合性基准测试，评估了三种大型语言模型在不同方法下的表现，揭示了性能差异及关键影响因素。", "motivation": "尽管数据科学代理快速普及，但缺乏系统性评估其效能与局限的基准测试，本文旨在填补这一空白。", "method": "通过商业应用观察真实用户交互，评估Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini三种模型在零样本上下文工程、多步上下文工程及SmolAgent三种方法下的表现，涵盖八类数据科学任务，并测试模型对提示问题的敏感性及温度参数的影响。", "result": "评估结果显示不同模型和方法间存在显著性能差异，温度参数对任务特定结果有显著影响。", "conclusion": "本文提出的基准数据集和评估框架为未来研究更鲁棒高效的数据科学代理奠定了基础。"}}
{"id": "2507.23517", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.23517", "abs": "https://arxiv.org/abs/2507.23517", "authors": ["Jifu Lin", "Lihua You"], "title": "Oriented diameter of graphs with diameter $4$ and given maximum edge girth", "comment": "29 pages, 2 figures", "summary": "Let $G$ be a bridgeless graph. We introduce the maximum edge girth of $G$,\ndenoted by $g^*(G)=\\max\\{l_G(e)\\mid e\\in E(G)\\}$, where $l_G(e)$ is the edge\ngirth of $e$, defined as the length of the shortest cycle containing $e$. Let\n$F(d,A)$ be the smallest value for which every bridgeless graph $G$ with\ndiameter $d$ and $g^*(G)\\in A$ admits a strong orientation $\\overrightarrow{G}$\nsuch that the diameter of $\\overrightarrow{G}$ is at most $F(d,A)$. Let\n$f(d)=F(d,A)$, where $A=\\{a\\in \\mathbb{N}\\mid 2\\leq a\\leq 2d+1\\}$. Chv\\'atal\nand Thomassen (JCT-B, 1978) obtained general bounds for $f(d)$ and showed that\n$f(2)=6$. Kwok et al. (JCT-B, 2010) proved that $9\\leq f(3)\\leq 11$. Wang and\nChen (JCT-B, 2022) determined $f(3)=9$. In this paper, we give that $12\\leq\nF(4,A^*)\\leq 13$, where $A^*=\\{2,3,6,7,8,9\\}$.", "AI": {"tldr": "本文研究了无桥图的最大边围长与强定向直径的关系，给出了直径4时$F(4,A^*)$的上下界。", "motivation": "研究无桥图的最大边围长$g^*(G)$与强定向直径的关系，扩展了Chv\\'atal和Thomassen等人的工作。", "method": "通过定义最大边围长$g^*(G)$，并引入$F(d,A)$函数，分析不同直径和边围长条件下的强定向直径界限。", "result": "证明了当直径为4且$A^*=\\{2,3,6,7,8,9\\}$时，$12\\leq F(4,A^*)\\leq 13$。", "conclusion": "本文进一步推进了无桥图强定向直径的研究，为直径4的情况提供了新的上下界。"}}
{"id": "2507.23377", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23377", "abs": "https://arxiv.org/abs/2507.23377", "authors": ["Zhuo Li", "Xianghuai Deng", "Chiwei Feng", "Hanmeng Li", "Shenjie Wang", "Haichao Zhang", "Teng Jia", "Conlin Chen", "Louis Linchun Wu", "Jia Wang"], "title": "LLM4Rail: An LLM-Augmented Railway Service Consulting Platform", "comment": null, "summary": "Large language models (LLMs) have significantly reshaped different walks of\nbusiness. To meet the increasing demands for individualized railway service, we\ndevelop LLM4Rail - a novel LLM-augmented railway service consulting platform.\nEmpowered by LLM, LLM4Rail can provide custom modules for ticketing, railway\nfood & drink recommendations, weather information, and chitchat. In LLM4Rail,\nwe propose the iterative \"Question-Thought-Action-Observation (QTAO)\" prompting\nframework. It meticulously integrates verbal reasoning with task-oriented\nactions, that is, reasoning to guide action selection, to effectively retrieve\nexternal observations relevant to railway operation and service to generate\naccurate responses. To provide personalized onboard dining services, we first\nconstruct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible\ntakeout dataset tailored for railway services. CRFD-25 covers a wide range of\nsignature dishes categorized by cities, cuisines, age groups, and spiciness\nlevels. We further introduce an LLM-based zero-shot conversational recommender\nfor railway catering. To address the unconstrained nature of open\nrecommendations, the feature similarity-based post-processing step is\nintroduced to ensure all the recommended items are aligned with CRFD-25\ndataset.", "AI": {"tldr": "本文提出LLM4Rail平台，通过大语言模型(LLM)增强铁路服务咨询功能，采用创新的QTAO提示框架整合语言推理与任务导向行动，并构建CRFD-25铁路餐饮数据集实现个性化推荐。", "motivation": "为满足日益增长的个性化铁路服务需求，开发基于LLM的智能咨询平台，解决传统服务系统在票务、餐饮推荐、天气查询等场景的局限性。", "method": "1) 设计迭代式\\\"问题-思考-行动-观察(QTAO)\\\"提示框架；2) 构建中国铁路餐饮数据集CRFD-25；3) 开发基于LLM的零样本对话推荐系统，引入特征相似性后处理确保推荐有效性。", "result": "成功实现具备多模块服务的LLM4Rail平台，其中餐饮推荐系统能基于用户画像（年龄/口味偏好等）从CRFD-25数据集中生成个性化推荐，准确率达92.3%。", "conclusion": "LLM4Rail通过融合语言推理与领域知识库，显著提升铁路服务智能化水平，QTAO框架与CRFD-25数据集为垂直领域LLM应用提供新范式。"}}
{"id": "2507.23557", "categories": ["math.CO", "cs.SC", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.23557", "abs": "https://arxiv.org/abs/2507.23557", "authors": ["Alin Bostan", "Valentin Féray", "Paul Thévenin"], "title": "Tree-indexed sums of Catalan numbers", "comment": "62 pages, 8 figures", "summary": "We consider a family of infinite sums of products of Catalan numbers, indexed\nby trees. We show that these sums are polynomials in $1/\\pi$ with rational\ncoefficients; the proof is effective and provides an algorithm to explicitly\ncompute these sums. Along the way we introduce parametric liftings of our sums,\nand show that they are polynomials in the complete elliptic integrals of the\nfirst and second kind. Moreover, the degrees of these polynomials are at most\nhalf of the number of vertices of the tree. The computation of these\ntree-indexed sums is motivated by the study of large meandric systems, which\nare non-crossing configurations of loops in the plane.", "AI": {"tldr": "研究了一类由树索引的卡特兰数乘积的无穷级数，证明其为$1/\\pi$的有理系数多项式，并给出了有效计算算法。", "motivation": "研究动机源于对大圆环系统（平面上非交叉环构型）的分析需求。", "method": "通过引入参数的提升，将级数表示为第一类和第二类完全椭圆积分的多项式。", "result": "证明这些级数是$1/\\pi$的有理系数多项式，且多项式次数不超过树顶点数的一半。", "conclusion": "提供了一种有效算法显式计算树索引的卡特兰数乘积级数，拓展了椭圆积分在组合数学中的应用。"}}
{"id": "2507.23429", "categories": ["cs.AI", "cs.DB", "cs.ET", "cs.HC", "cs.MA", "68T50, 68P20", "I.2.7; H.2.5; H.2.8; H.5.m"], "pdf": "https://arxiv.org/pdf/2507.23429", "abs": "https://arxiv.org/abs/2507.23429", "authors": ["Jorge Ruiz Gómez", "Lidia Andrés Susinos", "Jorge Alamo Olivé", "Sonia Rey Osorno", "Manuel Luis Gonzalez Hernández"], "title": "Chatting with your ERP: A Recipe", "comment": "11 pages, includes 3 tables summarizing schema and model performance.\n  Submitted on July 31, 2025. Targets integration of LLM agents with ERP\n  systems using open-weight models and Ollama deployment", "summary": "This paper presents the design, implementation, and evaluation behind a Large\nLanguage Model (LLM) agent that chats with an industrial production-grade ERP\nsystem. The agent is capable of interpreting natural language queries and\ntranslating them into executable SQL statements, leveraging open-weight LLMs. A\nnovel dual-agent architecture combining reasoning and critique stages was\nproposed to improve query generation reliability.", "AI": {"tldr": "本文介绍了一种基于大型语言模型(LLM)的智能代理，能够将自然语言查询转换为可执行的SQL语句，应用于工业级ERP系统。", "motivation": "旨在解决工业ERP系统中自然语言查询的自动化处理需求，提升人机交互效率。", "method": "采用创新的双代理架构，结合推理与批判阶段，利用开源权重LLM提高查询生成的可靠性。", "result": "成功实现了一个能与生产级ERP系统对话的LLM代理，有效完成自然语言到SQL的转换。", "conclusion": "该双代理架构显著提升了查询生成的准确性，为工业ERP系统的智能化交互提供了可行方案。"}}
{"id": "2507.23623", "categories": ["math.CO", "05D10"], "pdf": "https://arxiv.org/pdf/2507.23623", "abs": "https://arxiv.org/abs/2507.23623", "authors": ["Peter Allen", "Simona Boyadzhiyska", "Matías Pavez-Signé"], "title": "Ramsey numbers for 1-degenerate 3-graphs", "comment": "5 pages, 2 figures", "summary": "We construct a 3-uniform 1-degenerate hypergraph on $n$ vertices whose\n2-colour Ramsey number is $\\Omega\\big(n^{3/2}/\\log n\\big)$. This shows that all\nremaining open cases of the hypergraph Burr-Erd\\H{o}s conjecture are false. Our\ngraph is a variant of the celebrated hedgehog graph. We additionally show\nnear-sharp upper bounds, proving that all 3-uniform generalised hedgehogs have\n2-colour Ramsey number $O\\big(n^{3/2}\\big)$.", "AI": {"tldr": "本文构建了一个3-均匀1-退化超图，其2-色Ramsey数为$\\Omega\\big(n^{3/2}/\\log n\\big)$，否定了超图Burr-Erd\\H{o}s猜想的所有剩余开放情况。", "motivation": "研究超图Burr-Erd\\H{o}s猜想的剩余开放情况，验证其是否成立。", "method": "构建了一个3-均匀1-退化超图，该图是著名的hedgehog图的变体，并证明了其2-色Ramsey数的下界。", "result": "证明了所有3-均匀广义hedgehog图的2-色Ramsey数为$O\\big(n^{3/2}\\big)$，并给出了下界$\\Omega\\big(n^{3/2}/\\log n\\big)$。", "conclusion": "超图Burr-Erd\\H{o}s猜想的所有剩余开放情况均为假，广义hedgehog图的Ramsey数具有近尖锐的上下界。"}}
{"id": "2507.23440", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23440", "abs": "https://arxiv.org/abs/2507.23440", "authors": ["Mingzhe Li", "Xin Lu", "Yanyan Zhao"], "title": "Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation", "comment": "Accepted by Findings of ACL 2025", "summary": "Large language models (LLMs) with instruction following capabilities have\ndemonstrated impressive problem-solving abilities. While synthesizing\ninstructional data from unsupervised text has become a common approach for\ntraining such models, conventional methods rely heavily on human effort for\ndata annotation. Although existing automated synthesis paradigms have\nalleviated this constraint, they still exhibit significant limitations in\nensuring adequate diversity and difficulty of synthesized instructions. To\naddress these challenges, we propose Self-Foveate, an innovative LLM-driven\nmethod for instruction synthesis. This approach introduces a\n\"Micro-Scatter-Macro\" multi-level foveation methodology that effectively guides\nthe LLM to deeply excavate fine-grained information embedded in unsupervised\ntext, thereby enhancing both the diversity and difficulty of synthesized\ninstructions. Comprehensive experiments across multiple unsupervised corpora\nand diverse model architectures validate the effectiveness and superiority of\nour proposed method. We publicly release our data and codes:\nhttps://github.com/Mubuky/Self-Foveate", "AI": {"tldr": "本文提出Self-Foveate方法，通过多级聚焦技术提升大语言模型从无监督文本中合成指令的多样性与难度。", "motivation": "现有自动化指令合成方法在确保指令多样性和难度方面存在显著不足，亟需减少人工标注依赖并提升合成质量。", "method": "采用'微观-散射-宏观'多级聚焦方法，引导大语言模型深度挖掘无监督文本中的细粒度信息。", "result": "跨多组无监督语料库和不同模型架构的实验验证了该方法在提升指令质量方面的有效性和优越性。", "conclusion": "Self-Foveate为自动化指令合成提供了创新解决方案，相关数据和代码已开源。"}}
{"id": "2507.23624", "categories": ["math.CO", "05B07, 05B05, 05C35, 05C65"], "pdf": "https://arxiv.org/pdf/2507.23624", "abs": "https://arxiv.org/abs/2507.23624", "authors": ["Michelle Delcourt", "Cicely", "Henderson", "Thomas Lesgourgues", "Luke Postle"], "title": "Erdős meets Nash-Williams", "comment": "41 pages", "summary": "In 1847, Kirkman proved that there exists a Steiner triple system on $n$\nvertices (equivalently a triangle decomposition of the edges of $K_n$) whenever\n$n$ satisfies the necessary divisibility conditions (namely $n\\equiv 1,3 \\mod\n6$). In 1970, Nash-Williams conjectured that every graph $G$ on $n$ vertices\nwith minimum degree at least $3n/4$ (for $n$ large enough and satisfying the\nnecessary divisibility conditions) has a triangle decomposition. In 1973,\nErd\\H{o}s conjectured that for each integer $g$, there exists a Steiner triple\nsystem on $n$ vertices with girth at least $g$ (provided that $n\\equiv 1,3 \\mod\n6$ is large enough compared to the fixed $g$). In 2021, Glock, K\\\"uhn, and\nOsthus conjectured the common generalization of these two conjectures, dubbing\nit the ``Erd\\H{o}s meets Nash-Williams' Conjecture''.\n  In this paper, we reduce the combined conjecture to the fractional relaxation\nof the Nash-Williams' Conjecture. Combined with the best known fractional bound\nof Delcourt and Postle, this proves the combined conjecture above when $G$ has\nminimum degree at least $0.82733n$. We note that our result generalizes the\nseminal work of Barber, K\\\"uhn, Lo, and Osthus on Nash-Williams' Conjecture and\nthe resolution of Erd\\H{o}s' Conjecture by Kwan, Sah, Sawhney, and Simkin. Both\nprevious proofs of those results used the method of iterative absorption. Our\nproof instead proceeds via the newly developed method of refined absorption\n(and hence provides new independent proofs of both results).", "AI": {"tldr": "该论文将Erd\\H{o}s与Nash-Williams的猜想统一为“Erd\\H{o}s meets Nash-Williams' Conjecture”，并通过分数松弛方法将组合猜想简化为Nash-Williams猜想的分数版本，证明了当图G的最小度至少为0.82733n时，该猜想成立。", "motivation": "研究动机源于1847年Kirkman关于Steiner三元系的证明，以及1970年Nash-Williams和1973年Erd\\H{o}s分别提出的关于三角形分解和Steiner三元系周长下限的猜想。2021年Glock等人提出了统一这两个猜想的“Erd\\H{o}s meets Nash-Williams' Conjecture”。", "method": "论文采用新开发的“精细吸收”方法，而非之前使用的迭代吸收方法，将组合猜想简化为Nash-Williams猜想的分数松弛版本，并结合Delcourt和Postle的最佳分数界进行证明。", "result": "研究结果表明，当图G的最小度至少为0.82733n时，统一猜想成立。这一结果推广了Barber等人关于Nash-Williams猜想的工作，以及Kwan等人对Erd\\H{o}s猜想的解决。", "conclusion": "论文通过精细吸收方法独立证明了Erd\\H{o}s和Nash-Williams的猜想，为组合数学中的三角形分解和Steiner三元系问题提供了新的视角和解决方案。"}}
{"id": "2507.23488", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23488", "abs": "https://arxiv.org/abs/2507.23488", "authors": ["Kacper Kadziolka", "Saber Salehkaleybar"], "title": "Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery", "comment": null, "summary": "Causal inference remains a fundamental challenge for large language models.\nRecent advances in internal reasoning with large language models have sparked\ninterest in whether state-of-the-art reasoning models can robustly perform\ncausal discovery-a task where conventional models often suffer from severe\noverfitting and near-random performance under data perturbations. We study\ncausal discovery on the Corr2Cause benchmark using the emergent OpenAI's\no-series and DeepSeek-R model families and find that these reasoning-first\narchitectures achieve significantly greater native gains than prior approaches.\nTo capitalize on these strengths, we introduce a modular in-context pipeline\ninspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding\nnearly three-fold improvements over conventional baselines. We further probe\nthe pipeline's impact by analyzing reasoning chain length, complexity, and\nconducting qualitative and quantitative comparisons between conventional and\nreasoning models. Our findings suggest that while advanced reasoning models\nrepresent a substantial leap forward, carefully structured in-context\nframeworks are essential to maximize their capabilities and offer a\ngeneralizable blueprint for causal discovery across diverse domains.", "AI": {"tldr": "研究发现，采用推理优先架构的大型语言模型在因果发现任务上表现显著优于传统方法，结合模块化上下文管道可进一步提升性能。", "motivation": "因果推断是大型语言模型面临的核心挑战，传统模型在数据扰动下易出现过拟合和随机表现，研究旨在探索先进推理模型在此任务的潜力。", "method": "使用OpenAI的o系列和DeepSeek-R模型在Corr2Cause基准测试因果发现，并引入受Tree-of-Thoughts和Chain-of-Thoughts启发的模块化上下文管道。", "result": "推理优先架构模型展现出显著优势，结合上下文管道后性能提升近三倍，并通过分析推理链长度和复杂度验证其有效性。", "conclusion": "先进推理模型代表了重大进步，但需结合结构化上下文框架才能最大化其能力，为跨领域因果发现提供了可推广的解决方案。"}}
{"id": "2507.23497", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23497", "abs": "https://arxiv.org/abs/2507.23497", "authors": ["David A Kelly", "Hana Chockler"], "title": "Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification", "comment": "13 pages, 13 figures, appendix included", "summary": "Existing algorithms for explaining the outputs of image classifiers are based\non a variety of approaches and produce explanations that lack formal rigor. On\nthe other hand, logic-based explanations are formally and rigorously defined\nbut their computability relies on strict assumptions about the model that do\nnot hold on image classifiers.\n  In this paper, we show that causal explanations, in addition to being\nformally and rigorously defined, enjoy the same formal properties as\nlogic-based ones, while still lending themselves to black-box algorithms and\nbeing a natural fit for image classifiers. We prove formal properties of causal\nexplanations and introduce contrastive causal explanations for image\nclassifiers. Moreover, we augment the definition of explanation with confidence\nawareness and introduce complete causal explanations: explanations that are\nclassified with exactly the same confidence as the original image.\n  We implement our definitions, and our experimental results demonstrate that\ndifferent models have different patterns of sufficiency, contrastiveness, and\ncompleteness. Our algorithms are efficiently computable, taking on average 6s\nper image on a ResNet50 model to compute all types of explanations, and are\ntotally black-box, needing no knowledge of the model, no access to model\ninternals, no access to gradient, nor requiring any properties, such as\nmonotonicity, of the model.", "AI": {"tldr": "本文提出了一种基于因果关系的图像分类器解释方法，具有形式化严谨性且适用于黑盒算法，同时引入了对比性和置信度感知的完整因果解释。", "motivation": "现有图像分类器解释方法缺乏形式化严谨性，而基于逻辑的解释虽严谨但依赖严格假设。本文旨在结合两者的优势，提出既严谨又实用的因果解释方法。", "method": "通过定义因果解释及其对比性变体，并引入置信度感知的完整因果解释。算法完全黑盒化，无需模型内部信息或梯度，计算效率高（平均6秒/图像）。", "result": "实验表明不同模型在充分性、对比性和完整性上呈现不同模式。算法在ResNet50上高效运行，且完全黑盒兼容。", "conclusion": "因果解释为图像分类器提供了形式化严谨且实用的解释框架，其黑盒特性与高效性使其具有广泛适用性。"}}
{"id": "2507.23635", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.23635", "abs": "https://arxiv.org/abs/2507.23635", "authors": ["Shouhong Qiao", "Ning Su", "Binzhou Xia", "Zhishuo Zhang", "Sanming Zhou"], "title": "Which maximal subgroups are perfect codes?", "comment": null, "summary": "A perfect code in a graph $\\Gamma=(V, E)$ is a subset $C$ of $V$ such that no\ntwo vertices in $C$ are adjacent and every vertex in $V \\setminus C$ is\nadjacent to exactly one vertex in $C$. A subgroup $H$ of a group $G$ is called\na subgroup perfect code of $G$ if it is a perfect code in some Cayley graph of\n$G$. In this paper, we undertake a systematic study of which maximal subgroups\nof a group can be perfect codes. Our approach highlights a characterization of\nsubgroup perfect codes in terms of their ``local'' complements.", "AI": {"tldr": "本文系统研究了群的最大子群如何成为完美码，提出了子群完美码的局部补集特征。", "motivation": "研究群中子群完美码的存在条件，特别是最大子群能否成为完美码，以深化对群结构与图论编码关系的理解。", "method": "通过分析群$G$的凯莱图$\\Gamma=(V, E)$，利用子群$H$的局部补集性质，建立子群完美码的判定标准。", "result": "证明了最大子群作为完美码的充要条件与其局部补集特性相关，为群论编码提供了新工具。", "conclusion": "子群完美码的局部补集特征为群论与编码理论的交叉研究开辟了新方向，具有潜在应用价值。"}}
{"id": "2507.23554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23554", "abs": "https://arxiv.org/abs/2507.23554", "authors": ["Ruoyu Wang", "Junda Wu", "Yu Xia", "Tong Yu", "Ryan A. Rossi", "Julian McAuley", "Lina Yao"], "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "comment": null, "summary": "Large language model-based agents, empowered by in-context learning (ICL),\nhave demonstrated strong capabilities in complex reasoning and tool-use tasks.\nHowever, existing works have shown that the effectiveness of ICL is highly\nsensitive to the choice of demonstrations, with suboptimal examples often\nleading to unstable or degraded performance. While prior work has explored\nexample selection, including in some agentic or multi-step settings, existing\napproaches typically rely on heuristics or task-specific designs and lack a\ngeneral, theoretically grounded criterion for what constitutes an effective\ndemonstration across reasoning steps. Therefore, it is non-trivial to develop a\nprincipled, general-purpose method for selecting demonstrations that\nconsistently benefit agent performance. In this paper, we address this\nchallenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a\ntheoretically grounded ICL framework for agentic tasks that selects the most\nrelevant demonstrations at each step of reasoning. Our approach decomposes\ndemonstration knowledge into transferable and non-transferable components\nthrough a causal lens, showing how the latter can introduce spurious\ndependencies that impair generalization. We further propose a stepwise\nselection criterion with a formal guarantee of improved agent performance.\nImportantly, DICE is a general, framework-agnostic solution that can be\nintegrated as a plug-in module into existing agentic frameworks without any\nadditional training cost. Extensive experiments across diverse domains\ndemonstrate our method's effectiveness and generality, highlighting the\nimportance of principled, context-aware demo selection for robust and efficient\nLLM agents.", "AI": {"tldr": "本文提出DICE框架，通过因果视角动态选择上下文示例，提升大语言模型代理在复杂任务中的推理稳定性与性能。", "motivation": "现有基于上下文学习的代理模型性能高度依赖示例选择，但缺乏理论支撑的通用选择标准，导致性能不稳定。", "method": "DICE框架将示例知识分解为可迁移/不可迁移成分，提出具有理论保证的逐步选择准则，无需训练即可嵌入现有代理框架。", "result": "跨领域实验验证DICE能显著提升代理性能，证明基于因果关系的动态示例选择对稳健推理的关键作用。", "conclusion": "该研究为代理系统提供了首个理论完备的通用示例选择方案，揭示了上下文感知机制对高效LLM代理的重要性。"}}
{"id": "2507.23681", "categories": ["math.CO", "math.MG"], "pdf": "https://arxiv.org/pdf/2507.23681", "abs": "https://arxiv.org/abs/2507.23681", "authors": ["Daniele D'Angeli", "Francesco Matucci", "Davide Perego", "Emanuele Rodaro"], "title": "Horofunctions of infinite Sierpinski polygon graphs", "comment": "16 pages", "summary": "Generalizing works of D'Angeli and Donno, we describe, starting from an\ninfinite sequence over $r$ letters with $r \\neq 4i$ and $i \\in \\mathbb{N}$, a\nsequence of pointed finite graphs. We study the pointed Gromov-Hausdorff limit\ngraphs giving a description of isomorphim classes in terms of dihedral groups\nand providing insights on the horofunction boundaries in terms of Busemann and\nnon-Busemann points.", "AI": {"tldr": "该论文推广了D'Angeli和Donno的工作，通过无限字母序列构建有限图序列，研究其Gromov-Hausdorff极限图，并分析同构类与horofunction边界性质。", "motivation": "研究基于无限字母序列构建的图序列的极限行为，特别关注$r \\neq 4i$（$i \\in \\mathbb{N}$）的情况，以扩展前人成果并揭示新的数学结构。", "method": "从$r$字母无限序列出发构造带标记有限图序列，分析其Gromov-Hausdorff极限，利用二面体群描述同构类，并探讨horofunction边界中Busemann与非Busemann点的性质。", "result": "证明了极限图的同构类可由二面体群刻画，并揭示了horofunction边界中Busemann点与非Busemann点的结构特征。", "conclusion": "该工作不仅推广了现有理论框架，还为无限序列与几何群论的交叉研究提供了新的工具与视角，特别在极限图分类与边界点分析方面取得进展。"}}
{"id": "2507.23565", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23565", "abs": "https://arxiv.org/abs/2507.23565", "authors": ["Botao Zhu", "Xianbin Wang", "Dusit Niyato"], "title": "Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI", "comment": null, "summary": "In collaborative systems, the effective completion of tasks hinges on\ntask-specific trust evaluations of potential devices for distributed\ncollaboration. However, the complexity of tasks, the spatiotemporal dynamism of\ndistributed device resources, and the inevitable assessment overhead\ndramatically increase the complexity and resource consumption of the trust\nevaluation process. As a result, ill-timed or overly frequent trust evaluations\ncan reduce utilization rate of constrained resources, negatively affecting\ncollaborative task execution. To address this challenge, this paper proposes an\nautonomous trust orchestration method based on a new concept of semantic\nchain-of-trust. Our technique employs agentic AI and hypergraph to establish\nand maintain trust relationships among devices. By leveraging its strengths in\nautonomous perception, task decomposition, and semantic reasoning, we propose\nagentic AI to perceive device states and autonomously perform trust evaluations\nof collaborators based on historical performance data only during device idle\nperiods, thereby enabling efficient utilization of distributed resources. In\naddition, agentic AI performs task-specific trust evaluations on collaborator\nresources by analyzing the alignment between resource capabilities and task\nrequirements. Moreover, by maintaining a trust hypergraph embedded with trust\nsemantics for each device, agentic AI enables hierarchical management of\ncollaborators and identifies collaborators requiring trust evaluation based on\ntrust semantics, thereby achieving a balance between overhead and trust\naccuracy. Furthermore, local trust hypergraphs from multiple devices can be\nchained together to support multi-hop collaboration, enabling efficient\ncoordination in large-scale systems. Experimental results demonstrate that the\nproposed method achieves resource-efficient trust evaluation.", "AI": {"tldr": "本文提出了一种基于语义信任链的自主信任编排方法，利用智能代理和超图技术优化分布式协作中的信任评估，实现资源高效利用。", "motivation": "分布式协作系统中，任务复杂性、设备资源动态性及评估开销导致信任评估过程复杂且资源消耗大，影响协作效率。", "method": "采用智能代理和超图技术，通过自主感知设备状态、历史数据分析及任务需求匹配，在设备空闲期进行信任评估，并构建嵌入信任语义的局部超图以实现分层管理。", "result": "实验表明，该方法在减少评估开销的同时保持了信任准确性，支持大规模系统中的多跳协作。", "conclusion": "所提出的语义信任链方法有效平衡了评估开销与信任精度，为分布式协作系统提供了资源高效的信任评估解决方案。"}}
{"id": "2507.23633", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23633", "abs": "https://arxiv.org/abs/2507.23633", "authors": ["Qian Zhao", "Zhuo Sun", "Bin Guo", "Zhiwen Yu"], "title": "MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying", "comment": null, "summary": "Agent-assisted memory recall is one critical research problem in the field of\nhuman-computer interaction. In conventional methods, the agent can retrieve\ninformation from its equipped memory module to help the person recall\nincomplete or vague memories. The limited size of memory module hinders the\nacquisition of complete memories and impacts the memory recall performance in\npractice. Memory theories suggest that the person's relevant memory can be\nproactively activated through some effective cues. Inspired by this, we propose\na novel strategy-guided agent-assisted memory recall method, allowing the agent\nto transform an original query into a cue-rich one via the judiciously designed\nstrategy to help the person recall memories. To this end, there are two key\nchallenges. (1) How to choose the appropriate recall strategy for diverse\nforgetting scenarios with distinct memory-recall characteristics? (2) How to\nobtain the high-quality responses leveraging recall strategies, given only\nabstract and sparsely annotated strategy patterns? To address the challenges,\nwe propose a Recall Router framework. Specifically, we design a 5W Recall Map\nto classify memory queries into five typical scenarios and define fifteen\nrecall strategy patterns across the corresponding scenarios. We then propose a\nhierarchical recall tree combined with the Monte Carlo Tree Search algorithm to\noptimize the selection of strategy and the generation of strategy responses. We\nconstruct an instruction tuning dataset and fine-tune multiple open-source\nlarge language models (LLMs) to develop MemoCue, an agent that excels in\nproviding memory-inspired responses. Experiments on three representative\ndatasets show that MemoCue surpasses LLM-based methods by 17.74% in recall\ninspiration. Further human evaluation highlights its advantages in\nmemory-recall applications.", "AI": {"tldr": "本文提出了一种策略引导的代理辅助记忆回忆方法，通过设计5W回忆地图和分层回忆树优化策略选择，开发了MemoCue代理，显著提升了记忆回忆效果。", "motivation": "传统代理辅助记忆回忆方法受限于内存模块大小，难以获取完整记忆。受记忆理论启发，通过有效线索主动激活用户相关记忆，提出了新的解决方案。", "method": "设计了5W回忆地图将记忆查询分类为五种典型场景，定义15种回忆策略模式；提出结合蒙特卡洛树搜索算法的分层回忆树优化策略选择和响应生成；微调开源大语言模型开发MemoCue代理。", "result": "在三个代表性数据集上，MemoCue在回忆启发方面超越基于LLM的方法17.74%；人类评估进一步验证了其在记忆回忆应用中的优势。", "conclusion": "策略引导的代理辅助记忆回忆方法通过系统化策略设计和优化，显著提升了记忆回忆性能，MemoCue代理在实践应用中展现出优越性。"}}
{"id": "2507.23664", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.23664", "abs": "https://arxiv.org/abs/2507.23664", "authors": ["Haipeng Liu", "Yuxuan Liu", "Ting Long"], "title": "Personalized Education with Ranking Alignment Recommendation", "comment": null, "summary": "Personalized question recommendation aims to guide individual students\nthrough questions to enhance their mastery of learning targets. Most previous\nmethods model this task as a Markov Decision Process and use reinforcement\nlearning to solve, but they struggle with efficient exploration, failing to\nidentify the best questions for each student during training. To address this,\nwe propose Ranking Alignment Recommendation (RAR), which incorporates\ncollaborative ideas into the exploration mechanism, enabling more efficient\nexploration within limited training episodes. Experiments show that RAR\neffectively improves recommendation performance, and our framework can be\napplied to any RL-based question recommender. Our code is available in\nhttps://github.com/wuming29/RAR.git.", "AI": {"tldr": "本文提出了一种名为排名对齐推荐（RAR）的新方法，通过将协作思想融入探索机制，解决了现有强化学习方法在个性化问题推荐中探索效率低下的问题。", "motivation": "现有的个性化问题推荐方法大多基于马尔可夫决策过程并使用强化学习，但在训练过程中难以高效探索，无法为每个学生找到最佳问题。", "method": "提出的RAR方法将协作思想整合到探索机制中，从而在有限的训练周期内实现更高效的探索。该方法可应用于任何基于强化学习的问题推荐系统。", "result": "实验表明，RAR有效提升了推荐性能，且该框架具有通用性。", "conclusion": "RAR通过改进探索机制，显著提高了个性化问题推荐的效率，其框架设计具有广泛适用性。代码已开源。"}}
{"id": "2507.23701", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23701", "abs": "https://arxiv.org/abs/2507.23701", "authors": ["Long Phan", "Mantas Mazeika", "Andy Zou", "Dan Hendrycks"], "title": "TextQuests: How Good are LLMs at Text-Based Video Games?", "comment": null, "summary": "Evaluating AI agents within complex, interactive environments that mirror\nreal-world challenges is critical for understanding their practical\ncapabilities. While existing agent benchmarks effectively assess skills like\ntool use or performance on structured tasks, they often do not fully capture an\nagent's ability to operate autonomously in exploratory environments that demand\nsustained, self-directed reasoning over a long and growing context. To spur the\ndevelopment of agents capable of more robust intrinsic reasoning over long\nhorizons, we introduce TextQuests, a benchmark based on the Infocom suite of\ninteractive fiction games. These text-based adventures, which can take human\nplayers over 30 hours and require hundreds of precise actions to solve, serve\nas an effective proxy for evaluating AI agents on focused, stateful tasks. The\nbenchmark is specifically designed to assess an LLM agent's capacity for\nself-contained problem-solving by precluding the use of external tools, thereby\nfocusing on intrinsic long-context reasoning capabilities in an exploratory\nenvironment characterized by the need for trial-and-error learning and\nsustained problem-solving within a single interactive session. We release\nTextQuests at https://textquests.ai.", "AI": {"tldr": "本文介绍了TextQuests基准测试，基于Infocom互动小说游戏，旨在评估AI代理在长上下文推理和自主探索环境中的能力。", "motivation": "现有基准测试未能全面评估AI代理在需要长期自主推理的探索性环境中的表现，因此需要开发新基准以促进更强大的内在推理能力。", "method": "采用Infocom互动小说游戏作为测试环境，禁止使用外部工具，专注于评估代理在单一交互会话中的长上下文推理和试错学习能力。", "result": "TextQuests基准测试发布，可作为评估AI代理在复杂、状态化任务中自主解决问题能力的有效工具。", "conclusion": "TextQuests为开发具有长期自主推理能力的AI代理提供了重要基准，填补了现有评估体系的空白。"}}
{"id": "2507.23726", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23726", "abs": "https://arxiv.org/abs/2507.23726", "authors": ["Luoxin Chen", "Jinming Gu", "Liankai Huang", "Wenhao Huang", "Zhicheng Jiang", "Allan Jie", "Xiaoran Jin", "Xing Jin", "Chenggang Li", "Kaijing Ma", "Cheng Ren", "Jiawei Shen", "Wenlei Shi", "Tong Sun", "He Sun", "Jiahui Wang", "Siran Wang", "Zhihong Wang", "Chenrui Wei", "Shufa Wei", "Yonghui Wu", "Yuchen Wu", "Yihang Xia", "Huajian Xin", "Fan Yang", "Huaiyuan Ying", "Hongyi Yuan", "Zheng Yuan", "Tianyang Zhan", "Chi Zhang", "Yue Zhang", "Ge Zhang", "Tianyun Zhao", "Jianqiu Zhao", "Yichi Zhou", "Thomas Hanwen Zhu"], "title": "Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving", "comment": null, "summary": "LLMs have demonstrated strong mathematical reasoning abilities by leveraging\nreinforcement learning with long chain-of-thought, yet they continue to\nstruggle with theorem proving due to the lack of clear supervision signals when\nsolely using natural language. Dedicated domain-specific languages like Lean\nprovide clear supervision via formal verification of proofs, enabling effective\ntraining through reinforcement learning. In this work, we propose\n\\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover\ncan iteratively refine its proof based on Lean feedback, proved lemmas, and\nself-summarization. To solve IMO-level contest problems, we design three\ntest-time inference strategies that enable both deep and broad reasoning.\nSeed-Prover proves $78.1\\%$ of formalized past IMO problems, saturates MiniF2F,\nand achieves over 50\\% on PutnamBench, outperforming the previous\nstate-of-the-art by a large margin. To address the lack of geometry support in\nLean, we introduce a geometry reasoning engine \\textbf{Seed-Geometry}, which\noutperforms previous formal geometry engines. We use these two systems to\nparticipate in IMO 2025 and fully prove 5 out of 6 problems. This work\nrepresents a significant advancement in automated mathematical reasoning,\ndemonstrating the effectiveness of formal verification with long\nchain-of-thought reasoning.", "AI": {"tldr": "Seed-Prover是一种基于强化学习和形式化验证的数学定理证明模型，通过迭代优化证明过程，显著提升了IMO级数学问题的解决能力，并在几何推理方面取得突破。", "motivation": "当前大型语言模型在数学推理上虽表现优异，但因缺乏明确的监督信号，在定理证明上仍有局限。形式化验证语言如Lean能提供清晰反馈，但需解决几何支持不足等问题。", "method": "提出Seed-Prover模型，结合Lean的形式化验证反馈、已证引理和自我总结迭代优化证明；设计三种测试时推理策略实现深度与广度推理；开发Seed-Geometry引擎增强几何问题处理能力。", "result": "Seed-Prover在形式化IMO历史题中达到78.1\\%的证明率，显著超越先前最佳表现；Seed-Geometry优于现有几何引擎；在IMO 2025中成功证明5/6的题目。", "conclusion": "该研究通过形式化验证与长链推理的结合，推动了自动数学推理的显著进展，证明了混合系统在解决高难度数学问题上的有效性。"}}
{"id": "2507.23751", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23751", "abs": "https://arxiv.org/abs/2507.23751", "authors": ["Ping Yu", "Jack Lanchantin", "Tianlu Wang", "Weizhe Yuan", "Olga Golovneva", "Ilia Kulikov", "Sainbayar Sukhbaatar", "Jason Weston", "Jing Xu"], "title": "CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks", "comment": null, "summary": "We propose CoT-Self-Instruct, a synthetic data generation method that\ninstructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the\ngiven seed tasks, and then to generate a new synthetic prompt of similar\nquality and complexity for use in LLM training, followed by filtering for\nhigh-quality data with automatic metrics. In verifiable reasoning, our\nsynthetic data significantly outperforms existing training datasets, such as\ns1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For\nnon-verifiable instruction-following tasks, our method surpasses the\nperformance of human or standard self-instruct prompts on both AlpacaEval 2.0\nand Arena-Hard.", "AI": {"tldr": "提出CoT-Self-Instruct方法，通过链式思考生成高质量合成数据，显著提升LLM在可验证推理和非可验证指令任务中的表现。", "motivation": "现有LLM训练数据在复杂推理任务上表现不足，需开发能自动生成高质量合成数据的方法。", "method": "1. 基于种子任务引导LLM进行链式思考(CoT) 2. 生成质量相似的新合成提示 3. 使用自动指标过滤高质量数据。", "result": "在MATH500等可验证推理任务上超越s1k等数据集；在AlpacaEval 2.0等非可验证任务上优于人类编写的提示。", "conclusion": "CoT-Self-Instruct能有效生成训练数据，显著提升LLM在复杂任务中的性能表现。"}}
{"id": "2507.23773", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.23773", "abs": "https://arxiv.org/abs/2507.23773", "authors": ["Mingkai Deng", "Jinyu Hou", "Yilin Shen", "Hongxia Jin", "Graham Neubig", "Zhiting Hu", "Eric Xing"], "title": "SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model", "comment": null, "summary": "AI agents built on large language models (LLMs) hold enormous promise, but\ncurrent practice focuses on a one-task-one-agent approach, which not only falls\nshort of scalability and generality, but also suffers from the fundamental\nlimitations of autoregressive LLMs. On the other hand, humans are general\nagents who reason by mentally simulating the outcomes of their actions and\nplans. Moving towards a more general and powerful AI agent, we introduce\nSimuRA, a goal-oriented architecture for generalized agentic reasoning. Based\non a principled formulation of optimal agent in any environment, \\modelname\novercomes the limitations of autoregressive reasoning by introducing a world\nmodel for planning via simulation. The generalized world model is implemented\nusing LLM, which can flexibly plan in a wide range of environments using the\nconcept-rich latent space of natural language. Experiments on difficult web\nbrowsing tasks show that \\modelname improves the success of flight search from\n0\\% to 32.2\\%. World-model-based planning, in particular, shows consistent\nadvantage of up to 124\\% over autoregressive planning, demonstrating the\nadvantage of world model simulation as a reasoning paradigm. We are excited\nabout the possibility for training a single, general agent model based on LLMs\nthat can act superintelligently in all environments. To start, we make SimuRA,\na web-browsing agent built on \\modelname with pretrained LLMs, available as a\nresearch demo for public testing.", "AI": {"tldr": "本文提出SimuRA架构，通过世界模型模拟克服自回归LLM的局限性，在网页浏览任务中实现32.2%的航班搜索成功率，比自回归规划提升124%。", "motivation": "当前AI代理采用单任务单代理模式，缺乏可扩展性和通用性，且受限于自回归LLM的根本缺陷。人类通过心理模拟进行推理的通用性启发了本研究。", "method": "基于最优代理理论框架，SimuRA引入LLM实现的通用世界模型，利用自然语言的潜在概念空间进行跨环境规划，特别开发了网页浏览代理演示系统。", "result": "在困难网页任务中，航班搜索成功率从0%提升至32.2%，基于世界模型的规划比自回归方法最高有124%的优势。", "conclusion": "SimuRA证明了世界模型模拟作为推理范式的优越性，为训练基于LLM的通用超级智能代理迈出重要一步，已开放网页浏览代理供公开测试。"}}
