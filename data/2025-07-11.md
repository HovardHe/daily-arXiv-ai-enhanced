<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 2]
- [math.OC](#math.OC) [Total: 13]
- [math.NT](#math.NT) [Total: 4]
- [math.LO](#math.LO) [Total: 5]
- [math.CO](#math.CO) [Total: 11]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [cs.CR](#cs.CR) [Total: 18]
- [cs.AI](#cs.AI) [Total: 26]
- [cs.DM](#cs.DM) [Total: 1]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [On the pointwise and sup-norm errors for local regression estimators](https://arxiv.org/abs/2507.07132)
*Jérémy Bettinger,François Portier,Adrien Saumard*

Main category: math.ST

TL;DR: 本文分析了多种非参数局部回归估计器的行为，证明了形状规则性对达到极小极大收敛速率的必要性，并提出了一种基于随机树构造的新算法。


<details>
  <summary>Details</summary>
Motivation: 研究非参数局部回归估计器在估计Lipschitz回归函数时的行为，特别是在固定点或sup-范数下的表现。

Method: 首先证明了基于VC类集的局部估计器的偏差界，引入形状规则局部映射的概念，并分析了基于数据依赖局部映射的特定估计器（如最近邻及其变体）以及一种新的基于随机树的CART改进算法。

Result: 形状规则性对达到极小极大收敛速率是必要的，且足以确保最优速率（除对数因子外）。新提出的随机树算法在sup-范数下具有极小极大速率最优性。

Conclusion: 通过建立基于纯随机树的局部估计器的概率界，进一步讨论了估计器速率与其局部映射形状规则性之间的关系。

Abstract: In this paper, we analyze the behavior of various non-parametric local
regression estimators, i.e. estimators that are based on local averaging, for
estimating a Lipschitz regression function at a fixed point, or in sup-norm.
  We first prove some deviation bounds for local estimators that can be indexed
by a VC class of sets in the covariates space. We then introduce the general
concept of shape-regular local maps, corresponding to the situation where the
local averaging is done on sets which, in some sense, have ``almost isotropic''
shapes. On the one hand, we prove that, in general, shape-regularity is
necessary to achieve the minimax rates of convergence. On the other hand, we
prove that it is sufficient to ensure the optimal rates, up to some logarithmic
factors.
  Next, we prove some deviation bounds for specific estimators, that are based
on data-dependent local maps, such as nearest neighbors, their recent prototype
variants, as well as a new algorithm, which is a modified and generalized
version of CART, and that is minimax rate optimal in sup-norm. In particular,
the latter algorithm is based on a random tree construction that depends on
both the covariates and the response data. For each of the estimators, we
provide insights on the shape-regularity of their respective local maps.
Finally, we conclude the paper by establishing some probability bounds for
local estimators based on purely random trees, such as centered, uniform or
Mondrian trees. Again, we discuss the relations between the rates of the
estimators and the shape-regularity of their local maps.

</details>


### [2] [Computational barriers for permutation-based problems, and cumulants of weakly dependent random variables](https://arxiv.org/abs/2507.07946)
*Bertrand Even,Christophe Giraud,Nicolas Verzelen*

Main category: math.ST

TL;DR: 本文提出了一种处理弱依赖性结构（如随机排列）中累积量上界的技术，揭示了多特征匹配和序列问题中的统计-计算差距。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖潜在变量的独立性来限制累积量，但在缺乏独立性的潜在结构（如随机排列）中失效，因此需要新技术。

Method: 开发了一种在弱依赖性（如不放回抽样或随机排列）下上界累积量的技术。

Result: 该方法有效揭示了多特征匹配和序列问题中的统计-计算差距。

Conclusion: 新技术填补了弱依赖性结构下累积量分析的空白，为统计-计算差距研究提供了新工具。

Abstract: In many high-dimensional problems,polynomial-time algorithms fall short of
achieving the statistical limits attainable without computational constraints.
A powerful approach to probe the limits of polynomial-time algorithms is to
study the performance of low-degree polynomials. The seminal work of
arXiv:2008.02269 connects low-degree lower bounds to multivariate cumulants.
Prior works arXiv:2308.15728, arXiv:2506.13647 leverage independence among
latent variables to bound cumulants. However, such approaches break down for
problems with latent structure lacking independence, such as those involving
random permutations. To address this important restriction, we develop a
technique to upper-bound cumulants under weak dependencies, such as those
arising from sampling without replacement or random permutations. To show-case
the effectiveness of our approach, we uncover evidence of
statistical-computational gaps in multiple feature matching and in seriation
problems.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [3] [Secrecy Energy Efficiency Maximization in RIS-Aided Networks: Active or Nearly-Passive RIS?](https://arxiv.org/abs/2507.07241)
*Robert Kuku Fotock,Agbotiname Lucky Imoize,Alessio Zappone,Marco Di Renzo,Roberto Garello*

Main category: math.OC

TL;DR: 本文研究了RIS辅助无线网络中保密能效(SEE)最大化问题，对比了主动与近被动RIS的性能差异，并开发了两种SEE优化算法。


<details>
  <summary>Details</summary>
Motivation: 探讨主动与近被动可重构智能表面(RIS)在保密能效(SEE)上的性能差异，为实际部署提供理论依据。

Method: 针对完美和统计信道状态信息，开发了两种SEE最大化算法，联合优化用户发射功率、RIS反射系数和基站接收滤波器。

Result: 数值结果表明，随着反射元件静态功耗增加，主动RIS的SEE性能劣于近被动RIS，量化了两者的能效权衡关系。

Conclusion: 研究揭示了主动与近被动RIS在保密能效上的本质权衡，为未来RIS技术选择提供了重要参考。

Abstract: This work addresses the problem of secrecy energy efficiency (SEE)
maximization in RIS-aided wireless networks. The use of active and
nearly-passive RISs are compared and their trade-off in terms of SEE is
analyzed. Considering both perfect and statistical channel state information,
two SEE maximization algorithms are developed to optimize the transmit powers
of the mobile users, the RIS reflection coefficients, and the base station
receive filters. Numerical results quantify the trade-off between active and
nearly-passive RISs in terms of SEE, with active RISs yielding worse SEE values
as the static power consumed by each reflecting element increases.

</details>


### [4] [Convergence and Robustness Bounds for Distributed Asynchronous Shortest-Path](https://arxiv.org/abs/2507.07263)
*Jared Miller,Mattia Bianchi,Florian Dörfler*

Main category: math.OC

TL;DR: 本文研究了异步分布式最短路径计算的收敛时间和鲁棒性边界，重点分析了自适应Bellman-Ford算法在异步环境下的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决异步环境中分布式最短路径算法的收敛性和鲁棒性问题，特别是在代理可能空闲或遇到竞态条件的情况下。

Method: 方法基于Lyapunov稳定性理论，将同步最短路径设置的有限时间收敛和鲁棒性边界扩展到异步设置，并探讨了区间有界噪声过程的鲁棒性。

Result: 结果为异步自适应Bellman-Ford算法建立了有限时间收敛和鲁棒性边界，并为异步最可能路径算法提供了收敛和鲁棒性保证。

Conclusion: 结论表明，即使在异步环境下，自适应Bellman-Ford算法也能保持收敛性和鲁棒性，为分布式最短路径计算提供了理论支持。

Abstract: This work analyzes convergence times and robustness bounds for asynchronous
distributed shortest-path computation. We focus on the Adaptive Bellman--Ford
algorithm, a self-stabilizing method in which each agent updates its
shortest-path estimate based only on the estimates of its neighbors and
forgetting its previous estimate. In the asynchronous framework considered in
this paper, agents are allowed to idle or encounter race conditions during
their execution of the Adaptive Bellman--Ford algorithm. We build on
Lyapunov-based results that develop finite-time convergence and robustness
bounds for the synchronous shortest-path setting, in order to produce
finite-time convergence and robustness bounds for the asynchronous setting. We
also explore robustness against interval-bounded noise processes and establish
convergence and robustness guarantees for asynchronous most-probable-path
algorithms.

</details>


### [5] [Almost Sure Convergence for the Last Iterate of Stochastic Gradient Descent Schemes](https://arxiv.org/abs/2507.07281)
*Marcel Hudiani*

Main category: math.OC

TL;DR: 本文研究了随机梯度下降(SGD)和随机重球法(SHB)在参数化设置下的最终迭代几乎必然收敛速率，适用于全局凸或非凸目标函数。通过离散Gronwall不等式，恢复了SGD和SHB的收敛结果，并证明了SHB在特定条件下的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 研究随机梯度下降和随机重球法在凸和非凸目标函数下的收敛速率，为优化算法提供理论保证。

Method: 使用离散Gronwall不等式，避免了Robbins-Siegmund定理和鞅收敛理论，分析了SGD和SHB的收敛行为。

Result: 对于非凸目标，$\min_{s\leq t} \|\nabla F(w_s)\|^2 = o(t^{p-1})$；对于凸目标，$F(w_t) - F_* = o(t^{2\gamma/(1+\gamma) \cdot \max(p-1,-2p+1)-\epsilon})$。SHB在特定条件下达到$O(t^{\max(p-1,-2p+1)} \log^2 \frac{t}{\delta})$的收敛速率。

Conclusion: 本文通过离散Gronwall不等式，为SGD和SHB在凸和非凸目标函数下的收敛速率提供了简洁的证明，并展示了SHB在特定条件下的高效收敛性能。

Abstract: We study the almost sure convergence rate for the last iterate of stochastic
gradient descent (SGD) and stochastic heavy ball (SHB) in the parametric
setting when the objective function $F$ is globally convex or non-convex whose
gradient is $\gamma$-H\"{o}lder. Using only discrete Gronwall's inequality
without Robbins-Siegmund theorem nor martingale convergence theory, we recover
results for both SGD and SHB: $\min_{s\leq t} \|\nabla F(w_s)\|^2 = o(t^{p-1})$
for non-convex objectives and $F(w_t) - F_* = o(t^{2\gamma/(1+\gamma) \cdot
\max(p-1,-2p+1)-\epsilon})$ for $\beta \in (0, 1)$ and $\min_{s \leq t} F(w_s)
- F_* = o(t^{p-1})$ almost surely for convex objectives. In addition, we proved
that SHB with constant momentum parameter $\beta \in (0, 1)$ attains a
convergence rate of $F(w_t) - F_* = O(t^{\max(p-1,-2p+1)} \log^2
\frac{t}{\delta})$ with probability at least $1-\delta$ when $F$ is convex and
$\gamma = 1$ and step size $\alpha_t = \Theta(t^{-p})$ with $p \in
(\frac{1}{2}, 1)$.

</details>


### [6] [Combinatorial Algorithm for Tropical Linearly Factorized Programming](https://arxiv.org/abs/2507.07596)
*Yuki Nishida*

Main category: math.OC

TL;DR: 本文提出了一种新型热带优化问题——热带线性因子化规划问题，并开发了基于下降法和切线有向图的高效算法。该问题在传统意义下凸但在热带意义下非凸，算法在非退化情况下可高效求解。


<details>
  <summary>Details</summary>
Motivation: 热带半环上的线性规划问题已有研究，但传统凸性与热带凸性存在差异。本文旨在解决目标函数为热带线性形式乘积的新型优化问题，填补了这一研究空白。

Method: 采用下降法结合切线有向图技术。通过求解切线有向图子图的最小$s$-$t$割问题获得可行下降方向，非退化情况下开发了基于生成树的类单纯形算法，单次迭代时间复杂度为$O(r_A+r_C)$。

Result: 对于整数实例，算法可在$O((m+n)(r_A+r_C)MD)$时间内找到局部最优解，其中$n$为变量数，$m$为约束数，$M$为系数最大绝对值，$D$为目标函数次数。

Conclusion: 本文提出的热带线性因子化规划算法有效解决了传统凸性与热带凸性不一致的优化问题，特别在非退化情况下展现出显著计算效率优势，为热带优化领域提供了新工具。

Abstract: The tropical semiring is a set of numbers $\mathbb{R}\cup\{-\infty\}$ with
addition $a\oplus b:=\max(a,b)$ and multiplication $a\otimes b:=a+b$. As well
as in conventional algebra, linear programming problem in the tropical semiring
has been developed. In this study, we introduce a new type of tropical
optimization problem, namely, tropical linearly factorized programming problem.
This problem involves minimizing the objective function given by the product of
tropical linear forms $c_{k,1}\otimes x_1\oplus \cdots\oplus c_{k,n}\otimes
x_n$ divided by a tropical monomial, subject to tropical linear inequality
constraints. The objective function is convex in the conventional sense but not
in the tropical sense, while the feasible set is convex in the tropical sense
but not in the conventional sense.
  Our algorithm for tropical linearly factorized programming is based on the
descent method and exploits tangent digraphs. First, we demonstrate that the
feasible descent direction at the current solution can be obtained by solving
the minimum $s$-$t$ cut problem on a specific subgraph of the tangent digraph.
Although exponentially many such digraphs may exist in general, a more
efficient algorithm is devised in cases where the problem is non-degenerate.
Focusing on the fact that tangent digraphs become spanning trees in
non-degenerate cases, we present a simplex-like algorithm that updates the tree
structure iteratively. We show that each iteration can be executed in
$O(r_A+r_C)$ time, where $r_A$ and $r_C$ are the numbers of ``non-zero''
coefficients in the linear constraints and objective function, respectively.
For integer instances, our algorithm finds a local optimum in
$O((m+n)(r_A+r_C)MD)$ time, where $n$ and $m$ are the number of decision
variables and constraints, respectively, $M$ is the maximum absolute value of
coefficients and $D$ is the degree of the objective function.

</details>


### [7] [Qualitative and Generalized Differentiation Properties of Optimal Value Functions with Applications to Duality](https://arxiv.org/abs/2507.07377)
*Vo Si Trong Long,Nguyen Mau Nam,Len White*

Main category: math.OC

TL;DR: 本文研究了扰动优化问题中最优值函数的一般和广义微分性质，分析了其有效域、上镜图、严格上镜图等特性，并提出了基于集值映射Fenchel共轭的对偶框架，最后计算了最优值函数及其Fenchel共轭的$\epsilon$-次微分。


<details>
  <summary>Details</summary>
Motivation: 研究扰动优化问题中最优值函数的微分性质，为凸和非凸环境下的优化问题提供理论支持，并扩展对偶理论的应用范围。

Method: 通过分析最优值函数的有效域、上镜图等性质，提出基于集值映射Fenchel共轭的对偶框架，并计算$\epsilon$-次微分。

Result: 在凸和非凸环境下全面刻画了最优值函数的性质，提出了新的对偶理论框架，并成功计算了$\epsilon$-次微分。

Conclusion: 本研究为扰动优化问题提供了系统的分析工具，扩展了对偶理论的应用，并为最优值函数的微分性质研究奠定了基础。

Abstract: In this paper, we investigate general and generalized differentiation
properties of theoptimal value function associated with perturbed optimization
problems. We begin with a comprehensive analysis of its effective domain,
epigraph, strict epigraph, convexity, near convexity, continuity, and
Lipschitz-type behavior, in both convex and nonconvex settings. Next, we
propose a duality framework for constrained optimization problems with
set-valued constraints, based on the notion of the Fenchel conjugate for
set-valued mappings, which offers new insights into duality theory in a broad
context. Finally, we compute the {\epsilon}-subdifferentials of the optimal
value function and its Fenchel conjugate.

</details>


### [8] [Relocated Fixed-Point Iterations with Applications to Variable Stepsize Resolvent Splitting](https://arxiv.org/abs/2507.07428)
*Felipe Atenas,Heinz H. Bauschke,Minh N. Dao,Matthew K. Tam*

Main category: math.OC

TL;DR: 本文提出了一种适用于非扩张算子迭代算法的收敛框架，无需算子族具有共同不动点，并应用于多算子求和的Douglas-Rachford算法变体。


<details>
  <summary>Details</summary>
Motivation: 现有收敛分析通常要求非扩张算子族具有共同不动点，这限制了算法应用范围。本文旨在突破这一限制，建立更普适的收敛理论框架。

Method: 采用参数化非扩张算子的半闭原理，设计两阶段迭代步骤：先执行主算子更新，再通过'重定位'操作将当前算子不动点映射至下一阶段。

Result: 成功构建不依赖共同不动点假设的收敛理论，并开发了适用于$N\geq 2$个极大单调算子求和的Douglas-Rachford图扩展算法，允许迭代间解析参数变化。

Conclusion: 该框架扩展了非扩张算子算法的适用范围，特别解决了多算子求和问题中参数固定的限制，为分布式优化提供了新工具。

Abstract: In this work, we develop a convergence framework for iterative algorithms
whose updates can be described by a one-parameter family of nonexpansive
operators. Within the framework, each step involving one of the main
algorithmic operators is followed by a second step which ''relocates''
fixed-points of the current operator to the next. As a consequence, our
analysis does not require the family of nonexpansive operators to have a common
fixed-point, as is common in the literature. Our analysis uses a parametric
extension of the demiclosedness principle for nonexpansive operators. As an
application of our convergence results, we develop a version of the graph-based
extension of the Douglas--Rachford algorithm for finding a zero of the sum of
$N\geq 2$ maximally monotone operators, which does not require the resolvent
parameter to be constant across iterations.

</details>


### [9] [On the local null controllability of a viscous Burgers' system in finite time](https://arxiv.org/abs/2507.07442)
*Hoai-Minh Nguyen,Minh-Nguyen Tran*

Main category: math.OC

TL;DR: 本文证明了带有零Dirichlet边界条件的Burgers控制系统在有限时间内也不具有局部零可控性。


<details>
  <summary>Details</summary>
Motivation: Marbach的研究已表明Burgers控制系统在小时间内不具有局部零可控性，本文旨在探究其在有限时间内是否可控。

Method: 研究方法受到Coron、Koenig和Nguyen等人关于KdV系统可控性工作的启发，与Marbach的方法不同。

Result: 研究结果表明，Burgers控制系统在有限时间内同样不具有局部零可控性。

Conclusion: 本文通过不同于前人的方法，证明了Burgers控制系统在有限时间内也不具备局部零可控性，扩展了对该系统可控性的理解。

Abstract: This paper is devoted to the local null controllability of the Burgers
control system $y_t - y_{xx} + y y_x = u(t)$ on a bounded interval imposed by
the zero Dirichlet boundary condition. It is known from the work of Marbach
that this control system is not locally null controllable in small time. In
this paper, we prove that the system is not locally null controllable in finite
time as well. Our approach is inspired by the works of Coron, Koenig, and
Nguyen, and Nguyen on the controllability of the KdV system and is different
from the one of Marbach.

</details>


### [10] [An Adaptive Order Caputo Fractional Gradient Descent Method for Multi-objective Optimization Problems](https://arxiv.org/abs/2507.07674)
*Barsha Shaw,Md Abu Talhamainuddin Ansary*

Main category: math.OC

TL;DR: 本文提出了一种多目标自适应阶Caputo分数阶梯度下降（MOAOCFGD）算法，用于解决无约束多目标优化问题，适用于光滑与非光滑问题，无需预设参数或目标函数排序信息。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多目标优化问题时，常需预设参数或目标函数排序信息，且对非光滑问题效果不佳。本文旨在提出一种更通用、自适应的解决方案。

Method: 算法通过求解子问题确定下降方向，子问题中采用自适应阶Caputo分数阶梯度，并结合Armijo型线搜索确定步长。

Result: 数值实验（包括神经网络问题）验证了算法的有效性，且在Tikhonov正则化解的收敛性在温和假设下得到证明。

Conclusion: MOAOCFGD算法是一种无需先验参数、适用于广泛多目标优化问题的高效方法，为光滑与非光滑问题提供了统一解决方案。

Abstract: This article introduces the multi-objective adaptive order Caputo fractional
gradient descent (MOAOCFGD) algorithm for solving unconstrained multi-objective
problems. The proposed method performs equally well for both smooth and
non-smooth multi-objective optimization problems. Moreover, the proposed method
does not require any a priori chosen parameters or ordering information of the
objective functions. At every iteration of the proposed method, a subproblem is
solved to identify a suitable descent direction toward an optimal solution.
This subproblem involves an adaptive-order Caputo fractional gradient for each
objective function. An Armijo-type line search is applied to determine a
suitable step length. The convergence of this method for the
Tikhonov-regularized solution is justified under mild assumptions. The proposed
method is verified using different numerical problems, including neural
networks.

</details>


### [11] [Efficient Stochastic BFGS methods Inspired by Bayesian Principles](https://arxiv.org/abs/2507.07729)
*André Carlon,Luis Espath,Raúl Tempone*

Main category: math.OC

TL;DR: 本文提出了一种基于贝叶斯推断的新型随机拟牛顿方法（S-BFGS和L-S-BFGS），能够在噪声梯度环境下有效逼近逆Hessian矩阵，并在高维问题中展现出高效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统拟牛顿法依赖精确梯度信息，而随机优化中仅能获取带噪声的梯度观测。现有方法多通过修改确定性方程来规避噪声，本文创新性地采用贝叶斯推断框架直接融合噪声梯度信息。

Method: 通过贝叶斯推断推导出随机BFGS（S-BFGS）和随机L-BFGS（L-S-BFGS）算法。S-BFGS单次迭代复杂度为$\bigO{d^2}$，L-S-BFGS为$\bigO{d}$，适用于小批量场景。

Result: 在维度高达30,720的数值实验中，新方法能有效学习逆Hessian近似，展现出优于传统方法的计算效率和稳定性。

Conclusion: 基于贝叶斯框架的随机拟牛顿法为噪声梯度环境提供了理论严谨的解决方案，其衍生算法S-BFGS/L-S-BFGS在高维随机优化问题中具有显著优势。

Abstract: Quasi-Newton methods are ubiquitous in deterministic local search due to
their efficiency and low computational cost. This class of methods uses the
history of gradient evaluations to approximate second-order derivatives.
However, only noisy gradient observations are accessible in stochastic
optimization; thus, deriving quasi-Newton methods in this setting is
challenging. Although most existing quasi-Newton methods for stochastic
optimization rely on deterministic equations that are modified to circumvent
noise, we propose a new approach inspired by Bayesian inference to assimilate
noisy gradient information and derive the stochastic counterparts to standard
quasi-Newton methods. We focus on the derivations of stochastic BFGS and
L-BFGS, but our methodology can also be employed to derive stochastic analogs
of other quasi-Newton methods. The resulting stochastic BFGS (S-BFGS) and
stochastic L-BFGS (L-S-BFGS) can effectively learn an inverse Hessian
approximation even with small batch sizes. For a problem of dimension $d$, the
iteration cost of S-BFGS is $\bigO{d^2}$, and the cost of L-S-BFGS is
$\bigO{d}$. Numerical experiments with a dimensionality of up to $30,720$
demonstrate the efficiency and robustness of the proposed method.

</details>


### [12] [A Model-Free Extremum Seeking Controller with Application to Tracking a Nonlinear Chemical Reaction](https://arxiv.org/abs/2507.07749)
*Alexander Zuyev,Victoria Grushkovska*

Main category: math.OC

TL;DR: 本文开发了一种极值搜索方法，用于在状态空间中给定参考曲线附近生成可行轨迹，应用于非线性化学反应的最优轨迹跟踪问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于非线性化学反应中的等周优化问题，需要最大化特定时间段内的平均反应产物，这自然产生了作为最优轨迹的参考曲线。

Method: 采用极值搜索控制设计方法，通过将问题成本函数定义为当前系统状态与时间参数化参考曲线之间的距离，实现在参考曲线邻域内的轨迹生成。

Result: 将所提方法应用于非等温反应模型，并通过数值模拟展示了跟踪误差结果，验证了方法的有效性。

Conclusion: 研究表明，极值搜索方法能够有效生成接近参考曲线的可行轨迹，为非线性化学反应的优化控制提供了实用工具。

Abstract: In this paper, we develop the extremum-seeking approach to generate
admissible trajectories in a neighborhood of a given reference curve in the
state space. The cost function of the problem represents the distance between
the current system state and the reference curve, which is parameterized as a
function of time. Such reference curves naturally arise as optimal trajectories
in isoperimetric optimization problems for nonlinear chemical reactions, where
the objective is to maximize the average reaction product over a given period.
We apply the proposed extremum seeking control design to a nonisothermal
reaction model and illustrate the resulting tracking errors through numerical
simulations.

</details>


### [13] [Dissipativity-based time domain decomposition for optimal control of hyperbolic PDEs](https://arxiv.org/abs/2507.07812)
*Bálint Farkas,Birgit Jacob,Manuel Schaller,Merlin Schmitz*

Main category: math.OC

TL;DR: 提出基于半群理论的时间域分解方法，用于偏微分方程的最优控制，通过解耦实现高效并行计算，并在波方程和热方程中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 针对偏微分方程最优控制问题，传统方法计算复杂度高，难以并行化。本文旨在开发一种高效、可并行的时间域分解方法。

Method: 将最优控制系统（状态方程与伴随方程）表述为耗散算子之和，采用Peaceman-Rachford型不动点迭代，实现时间分布式解耦计算。基于$C_0$-(半)群理论框架，适用于双曲型方程（如波方程）。

Result: 证明了状态、控制及伴随状态在函数空间中的收敛性。通过2D波方程和3D热方程的数值实验验证了方法的收敛性与计算效率。

Conclusion: 该方法通过时间分解实现高度并行化，为双曲型方程等PDE最优控制问题提供了通用且高效的求解框架。

Abstract: We propose a time domain decomposition approach to optimal control of partial
differential equations (PDEs) based on semigroup theoretic methods. We
formulate the optimality system consisting of two coupled forward-backward
PDEs, the state and adjoint equation, as a sum of dissipative operators, which
enables a Peaceman-Rachford-type fixed-point iteration. The iteration steps may
be understood and implemented as solutions of many decoupled, and therefore
highly parallelizable, time-distributed optimal control problems. We prove the
convergence of the state, the control, and the corresponding adjoint state in
function space. Due to the general framework of $C_0$-(semi)groups, the results
are particularly well applicable, e.g., to hyperbolic equations, such as beam
or wave equations. We illustrate the convergence and efficiency of the proposed
method by means of two numerical examples subject to a 2D wave equation and a
3D heat equation.

</details>


### [14] [Complexity Analysis of a Bicriteria Directed Multimodal Transportation Network Design Problem](https://arxiv.org/abs/2507.07894)
*Dominik Leib,Susanne Fritzler,Neele Leithäuser*

Main category: math.OC

TL;DR: 本文研究了城乡公共交通规划中的双标准网络设计问题，证明了问题的复杂性和不可近似性，并探讨了特殊情况下可实现的近似解。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于城乡公共交通规划中的实际需求，旨在解决双标准决策与网络设计之间的复杂关系，填补现有文献中对有向网络设计问题复杂性研究的空白。

Method: 方法包括建立问题的复杂性证明和不可近似性结果，并利用有向网络设计问题的复杂性结果来推导特殊案例中的近似解。

Result: 结果表明该问题在一般情况下难以找到最优解，但在特定情况下可以实现近似解，为实践者提供了有价值的参考。

Conclusion: 结论指出，本研究不仅揭示了双标准网络设计问题的内在复杂性，还为特殊案例中的近似解提供了理论支持，推动了该领域的进一步研究。

Abstract: In this paper, we address a bicriteria network design problem that arises
from practical applications in urban and rural public transportation planning.
We establish the problem's complexity and demonstrate inapproximability
results, highlighting the inherent difficulties in finding optimal solutions.
Additionally, we identify special cases where approximability can be achieved,
providing valuable insights for practitioners. Our proofs leverage complexity
results related to directed network design problems, an area that has received
limited attention in the existing literature. By investigating these complexity
results, we aim to fill a critical gap and enhance the understanding of the
interplay between bicriteria decision-making and network design challenges.

</details>


### [15] [Convergence rates for regularized unbalanced optimal transport: the discrete case](https://arxiv.org/abs/2507.07917)
*Luca Nenna,Paul Pegon,Louis Tocquec*

Main category: math.OC

TL;DR: 本文研究了不平衡最优传输(UOT)的正则化问题，针对加权Dirac质量测度，提供了正则化传输成本与原始解之间的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 不平衡最优传输是传统最优传输(OT)的扩展，适用于质量不同的测度比较，在机器学习中具有抗异常值的优势。研究其正则化解的收敛性具有重要理论价值。

Method: 针对加权Dirac质量测度，分析正则化UOT问题中传输成本与传输方案的收敛行为。

Result: 给出了正则化传输成本与传输方案向原始解收敛的具体速率。

Conclusion: 该研究为UOT正则化问题提供了理论收敛保证，为机器学习应用中鲁棒性传输方法奠定了理论基础。

Abstract: Unbalanced optimal transport (UOT) is a natural extension of optimal
transport (OT) allowing comparison between measures of different masses. It
arises naturally in machine learning by offering a robustness against outliers.
The aim of this work is to provide convergence rates of the regularized
transport cost and plans towards their original solution when both measures are
weighted sums of Dirac masses.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [16] [Asymptotic properties of zeros of Riemann zeta function](https://arxiv.org/abs/2507.07253)
*Juan Arias de Reyna,Yves Meyer*

Main category: math.NT

TL;DR: 本文探讨了黎曼zeta函数非平凡零点序列的内在性质，提出了一个渐近关系式，并研究是否存在其他实数或复数序列满足相同性质。


<details>
  <summary>Details</summary>
Motivation: 研究黎曼zeta函数零点序列的独特数学特性，探索是否存在其他序列具有类似的渐近行为。

Method: 通过将非平凡零点表示为$z_k=1/2+i\tau_k$，建立其虚部序列$(\tau_k)$与特定渐近级数的等价关系。

Result: 发现零点序列满足一个包含对数项和幂级数的精确渐近关系，其中系数$a_n$与伯努利数$B_{2n}$和欧拉数$E_{2n}$相关。

Conclusion: 该研究为黎曼zeta函数零点提供了新的特征描述，并提出了关于其他可能序列的开放性问题。

Abstract: We try to define the sequence of zeros of the Riemann zeta function by an
intrinsic property. Let $(z_k)_{k\in \mathbb{N}}$ be the sequence of nontrivial
zeros of $\zeta(s)$ with positive imaginary part. We write $z_k= 1/2+i\tau_k$
(RH says that these $\tau_k$ are all real). Then the sequence $(\tau_k)_{k\in
\mathbb{N}},$ satisfies the following asymptotic relation
\[\sum_{k\in\mathbb{N}}\frac{2x}{x^2+\tau_k^2}\simeq
\frac12\log\frac{x}{2\pi}+\sum_{n=1}^\infty \frac{a_n}{x^n},\,\,x\to +\infty\]
where $a_{2n+1}=2^{-2n-2}(8-E_{2n})$, $a_{2n}=(1-2^{-2n+1})B_{2n}/(4n).$ Are
there other sequences $(\alpha_k)_{k\in \mathbb{N}},$ of real or complex
numbers enjoying this property? These problems are addressed in this note.

</details>


### [17] [An Equivalent Representation of Generalized Differentials](https://arxiv.org/abs/2507.07337)
*Valentin Suder*

Main category: math.NT

TL;DR: 本文提出了一种用于研究任意特征$p$有限域上广义几乎完美非线性函数高阶导数的等效公式，并通过计算具有固定基数且元素和恒定的素域子集数量获得结果，进而探讨了高阶导数的多样性相关问题。


<details>
  <summary>Details</summary>
Motivation: 研究广义几乎完美非线性函数的高阶导数在密码学和编码理论中具有重要意义，需要建立更普适的数学表达形式。

Method: 通过组合数学方法，计算特征$p$有限域中满足特定求和条件的子集数量，从而推导出高阶导数的等效公式。

Result: 成功建立了适用于任意特征$p$有限域的广义几乎完美非线性函数高阶导数等效公式，并获得了相关子集计数的明确结果。

Conclusion: 该公式为研究高阶导数性质提供了新工具，提出的多样性问题为后续研究指明了方向，对密码函数分析具有理论价值。

Abstract: We propose an equivalent formula for the higher-order derivatives used in the
study of Generalized Almost Perfect Nonlinear functions over an arbitrary
finite field of characteristic $p$. The result is obtained by counting the
number of subsets of the prime field with a fixed cardinality for which the sum
of their elements is constant. We then ask related questions regarding the
diversity of higher-order derivatives.

</details>


### [18] [Higher Hida theory for Drinfeld modular curves](https://arxiv.org/abs/2507.07423)
*Daniel Barrera Salazar,Héctor del Castillo,Giovanni Rosso*

Main category: math.NT

TL;DR: 本文基于Boxer和Pilloni的高阶Hida理论，为Drinfeld模曲线上Drinfeld模形式的线丛上同调发展了高阶Hida理论，并插值了Serre对偶性。


<details>
  <summary>Details</summary>
Motivation: 受到Boxer和Pilloni高阶Hida理论构造的启发，研究Drinfeld模曲线上Drinfeld模形式线丛上同调的高阶理论。

Method: 通过扩展高阶Hida理论的框架，应用于Drinfeld模形式线丛的上同调，并引入Serre对偶性的插值方法。

Result: 成功构建了Drinfeld模曲线上Drinfeld模形式线丛上同调的高阶Hida理论，并实现了Serre对偶性的插值。

Conclusion: 该研究不仅扩展了高阶Hida理论的应用范围，还为Drinfeld模形式的上同调理论提供了新的工具和视角。

Abstract: Inspired by the construction of Higher Hida theory of Boxer and Pilloni, we
develop Higher Hida theory for the cohomology of the line bundles of Drinfeld
modular forms on the Drinfeld modular curve. We also interpolate Serre duality.

</details>


### [19] [Prime Power Residues and Blocking Sets](https://arxiv.org/abs/2507.07673)
*Bhawesh Mishra,Paolo Santonastaso*

Main category: math.NT

TL;DR: 研究有限整数集$B$在几乎所有素数下包含$q$次幂的条件，发现其与射影几何中的阻塞集等价，并利用这一联系分类和界定了最小集合$B$的大小。


<details>
  <summary>Details</summary>
Motivation: 探索有限整数集$B$不含完美$q$次幂时，其在几乎所有素数下包含$q$次幂的充要条件，并建立数论与Galois几何之间的联系。

Method: 通过分析$B$中元素的$q$-自由部分的素因子数量$k$，将问题转化为射影空间$\mathrm{PG}(\mathbb{F}_{q}^{k})$中的阻塞集问题，并利用射影一般线性群$\mathrm{PGL}(\mathbb{F}_{q}^{k})$的几何等价性。

Result: 证明了$B$在几乎所有素数下包含$q$次幂当且仅当$B$对应于射影几何中的阻塞集，并给出了最小集合$B$的分类和大小界限。

Conclusion: 通过连接Galois几何与数论，揭示了$q$次幂模素数的性质与几何阻塞集的深刻联系，为相关问题的研究提供了新的视角和工具。

Abstract: Let $q$ be a fixed odd prime. We show that a finite subset $B$ of integers,
not containing any perfect $q^{th}$ power, contains a $q^{th}$ power modulo
almost every prime if and only if $B$ corresponds to a blocking set (with
respect to hyperplanes) in $\mathrm{PG}(\mathbb{F}_{q}^{k})$. Here, $k$ is the
number of distinct prime divisors of $q$-free parts of elements of $B$. As a
consequence, the property of a subset $B$ to contain $q^{th}$ power modulo
almost every prime $p$ is invariant under geometric $q$-equivalence defined by
an element of the projective general linear group
$\mathrm{PGL}(\mathbb{F}_{q}^{k})$. Employing this connection between two
disparate branches of mathematics, Galois geometry and number theory, we
classify, and provide bounds on the sizes of, minimal such sets $B$.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [20] [A 2-categorical approach to the semantics of dependent type theory with computation axioms](https://arxiv.org/abs/2507.07208)
*Matteo Spadetto*

Main category: math.LO

TL;DR: 本文从高阶范畴论角度研究公理类型论的语义学，通过2维范畴模型展示其类型构造元的编码方式，并证明该语义解释具有良好定义性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 公理类型论缺乏计算规则，传统通过项等式判断的方法被计算公理取代。现有研究难以在1维范畴框架内捕捉其内涵类型构造元的强度，需扩展至2维范畴进行研究。

Method: 采用Richard Garner的2维范畴方法，在显示映射2-范畴中编码公理类型论的构造元，放宽内涵类型论所需的2维条件，建立广义语义模型。

Result: 证明公理类型论在显示映射2-范畴中的解释具有良好定义性及可靠性，并通过群胚模型语义验证内涵恒等类型计算规则在公理系统中不可采纳。

Conclusion: 建立的2维范畴语义框架不仅推广了Garner的内涵类型论模型，还通过Hofmann-Streicher群胚模型的改造，为公理与内涵恒等类型的差异提供了语义证据。

Abstract: Axiomatic type theory is a dependent type theory without computation rules.
The term equality judgements that usually characterise these rules are replaced
by computation axioms, i.e., additional term judgements that are typed by
identity types. This paper is devoted to providing an effective description of
its semantics, from a higher categorical perspective: given the challenge of
encoding intensional type formers into 1-dimensional categorical terms and
properties, a challenge that persists even for axiomatic type formers, we adopt
Richard Garner's approach in the 2-dimensional study of dependent types. We
prove that the type formers of axiomatic theories can be encoded into natural
2-dimensional category theoretic data, obtaining a presentation of the
semantics of axiomatic type theory via 2-categorical models called display map
2-categories. In the axiomatic case, the 2-categorical requirements identified
by Garner for interpreting intensional type formers are relaxed. Therefore, we
obtain a presentation of the semantics of the axiomatic theory that generalises
Garner's one for the intensional case. Our main result states that the
interpretation of axiomatic theories within display map 2-categories is
well-defined and enjoys the soundness property. We use this fact to provide a
semantic proof that the computation rule of intensional identity types is not
admissible in axiomatic type theory. This is achieved via a revisitation of
Hofmann and Streicher's groupoid model that believes axiomatic identity types
but does not believe intensional ones.

</details>


### [21] [Generalized Tukey reducibility between $σ$-directed sets](https://arxiv.org/abs/2507.07309)
*Hiroshi Sakai,Toshimasa Tanno*

Main category: math.LO

TL;DR: 本文提出了一种称为pre-Tukey可约性的新概念，它是Tukey可约性在定向集上的推广，适用于$\mathsf{ZF}$系统。研究了在Solovay模型和满足$\mathsf{AD}$的$L(\mathbb{R})$中，基于实数集假设下多个$\sigma$-定向集之间的pre-Tukey可约性关系。


<details>
  <summary>Details</summary>
Motivation: 旨在推广Tukey可约性概念，使其在$\mathsf{ZF}$公理系统下更广泛适用，并探索在特定集合论模型（如Solovay模型和$L(\mathbb{R})$）中$\sigma$-定向集之间的结构关系。

Method: 通过引入pre-Tukey可约性定义，结合对实数集的假设，在$\mathsf{ZF}$框架下分析多个$\sigma$-定向集之间的约化关系。特别关注Solovay模型和满足$\mathsf{AD}$的$L(\mathbb{R})$模型。

Result: 在Solovay模型和满足$\mathsf{AD}$的$L(\mathbb{R})$中，特定$\sigma$-定向集之间存在pre-Tukey可约性关系，这为研究定向集结构提供了新工具。

Conclusion: pre-Tukey可约性为$\mathsf{ZF}$系统下的定向集研究提供了有效框架，并在特定集合论模型中揭示了$\sigma$-定向集之间的新联系。

Abstract: We introduce the pre-Tukey reducibility, a generalization of the Tukey
reducibility between directed sets that works well in $\mathsf{ZF}$. We
investigate the pre-Tukey reducibility between several $\sigma$-directed sets
under assumptions on sets of reals, which hold in the Solovay model and in
$L(\mathbb{R})$ satisfying $\mathsf{AD}$.

</details>


### [22] [On the lack of colimits in various categories of BAOs and Heyting algebras](https://arxiv.org/abs/2507.07489)
*Marco Abbadini,Guram Bezhanishvili,Luca Carai*

Main category: math.LO

TL;DR: 本文证明了多种带有稳定态射的BAO（布尔代数带算子）范畴、Heyting代数与有界格态射范畴、其框架子范畴以及框架与Heyting态射范畴均非余完备，进而得出这些范畴不等价于任何预代数簇或代数簇的结论，特别否定了Peter Jipsen关于McKinsey-Tarski代数范畴等价于代数簇的猜想。


<details>
  <summary>Details</summary>
Motivation: 研究不同代数结构范畴的完备性及其与代数簇的关系，特别是回应Peter Jipsen关于McKinsey-Tarski代数范畴是否等价于代数簇的开放性问题。

Method: 通过构造性证明，分析BAO、Heyting代数及框架范畴中态射的稳定性与余极限的存在性，结合范畴论与泛代数工具进行理论推导。

Result: 所有研究的范畴均不具备余完备性，且无法等价于预代数簇或代数簇，其中McKinsey-Tarski代数范畴的否定结论尤为显著。

Conclusion: 该研究系统性否定了多类代数范畴的余完备性及与代数簇的等价关系，为相关领域提供了明确的分类界限，并解决了Jipsen提出的关键问题。

Abstract: We prove that various categories of BAOs (boolean algebras with an operator)
with stable morphisms between them are not cocomplete, and that neither are the
category of Heyting algebras with bounded lattice morphisms, its full
subcategory consisting of frames, and the category of frames with Heyting
morphisms. As a consequence, none of these categories is equivalent to a
prevariety of algebras, let alone a variety. In particular, we obtain that the
category of McKinsey-Tarski algebras is not equivalent to a variety, thus
answering a question by Peter Jipsen in the negative.

</details>


### [23] [Ramsey-like theorems for separable permutations](https://arxiv.org/abs/2507.07606)
*Quentin Le Houérou,Ludovic Patey*

Main category: math.LO

TL;DR: 本文研究了无限团边着色中避免特定模式的无限子团的可计算性，特别关注可分离排列模式的作用及其与标准模型中无限齐次集存在性的等价关系。


<details>
  <summary>Details</summary>
Motivation: 研究无限团边着色中避免特定模式（尤其是可分离排列）的无限子团的可计算性特征，以理解这些模式在计算理论中的独特地位。

Method: 通过相对化对角非计算的新颖论证方法，分析了不同模式（特别是可分离排列）在无限团着色中的计算性质。

Result: 证明避免任何可分离排列的模式等价于标准模型中无限齐次集的存在性，而这一性质对其他模式不成立。

Conclusion: 可分离排列模式在无限团着色问题的计算性中具有独特作用，其避免性与无限齐次集存在性等价，为相关计算理论研究提供了新视角。

Abstract: We conduct a computability-theoretic study of Ramsey-like theorems of the
form "Every coloring of the edges of an infinite clique admits an infinite
sub-clique avoiding some pattern", with a particular focus on transitive
patterns. As it turns out, the patterns corresponding to separable permutations
play an important role in the computational features of the statement. We prove
that the avoidance of any separable permutation is equivalent to the existence
of an infinite homogeneous set in standard models, while this property fails
for any other pattern. For this, we develop a novel argument for relativized
diagonal non-computation.

</details>


### [24] [Hyper-u-amenablity and Hyperfiniteness of Treeable Equivalence Relations](https://arxiv.org/abs/2507.07891)
*Petr Naryshkin,Andrea Vaccaro*

Main category: math.LO

TL;DR: 本文引入了u-可驯性和超u-可驯性的概念，用于描述可数Borel等价关系，并证明了树状且超u-可驯的可数Borel等价关系是超有限的。


<details>
  <summary>Details</summary>
Motivation: 研究可数Borel等价关系的可驯性和超有限性之间的关系，特别是针对树状和自由群作用的情况。

Method: 通过引入u-可驯性和超u-可驯性的概念，结合树状结构和自由群作用的性质，分析可数Borel等价关系的超有限性。

Result: 证明了树状且超u-可驯的可数Borel等价关系是超有限的，并得出了一些推论，如自由群作用的轨道等价关系在测度超有限时也是超有限的。

Conclusion: 树状且可驯的可数Borel等价关系在特定条件下（如自由群作用或可驯群作用）是超有限的，这扩展了对Borel等价关系超有限性的理解。

Abstract: We introduce the notions of u-amenability and hyper-u-amenability for
countable Borel equivalence relations, strong forms of amenability that are
implied by hyperfiniteness. We show that treeable, hyper-u-amenable countable
Borel equivalence relations are hyperfinite. One of the corollaries that we get
is that if a countable Borel equivalence relation is measure-hyperfinite and
equal to the orbit equivalence relation of a free continuous action of a free
group (with $k \ge 2$ or $k = \infty$ generators) on a $\sigma$-compact Polish
space, then it is hyperfinite. We also obtain that if a countable Borel
equivalence relation is treeable and equal to the orbit equivalence relation of
a Borel action of an amenable group on a standard Borel space, or if it is
treeable, amenable and Borel bounded, then it is hyperfinite.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [25] [Statistics on $\ell$-interval parking functions](https://arxiv.org/abs/2507.07243)
*Kyle Celano,Jennifer Elder,Kimberly P. Hadaway,Pamela E. Harris,Jeremy L. Martin,Amanda Priestley,Gabe Udell*

Main category: math.CO

TL;DR: 论文研究了$\ell$-间隔停车函数的计数问题，分析了位移、逆序数等统计量，证明了特定条件下Foata双射保持$\ell$-间隔性质，并发现1-间隔停车函数存在循环筛现象。


<details>
  <summary>Details</summary>
Motivation: 研究停车函数中车辆位移限制为$\ell$的$\ell$-间隔停车函数，探索其统计特性（如逆序数、位移、主指标）的计数规律，以及Foata双射在该集合上的适用性。

Method: 采用组合数学方法，通过枚举$\ell$-间隔停车函数的统计量，分析Foata双射的保持条件，并运用循环筛理论验证1-间隔停车函数的周期性现象。

Result: 给出了1-间隔停车函数固定逆序数的闭式解；证明Foata双射仅当$\ell\leq 2$或$\ell\geq n-2$时保持$\ell$-间隔性质；发现1-间隔函数固定位移时呈现循环筛现象。

Conclusion: $\ell$-间隔停车函数在$\ell\leq 2$或$\ell\geq n-2$时逆序数与主指标等分布；1-间隔函数具有显著组合特性，为停车函数理论提供新视角。

Abstract: The displacement of a car with respect to a parking function is the number of
spots it must drive past its preferred spot in order to park. An
$\ell$-interval parking function is one in which each car has displacement at
most $\ell$. Among our results, we enumerate $\ell$-interval parking functions
with respect to statistics such as inversion, displacement, and major index. We
show that $1$-interval parking functions with fixed displacement exhibit a
cyclic sieving phenomenon. We give closed formulas for the number of
$1$-interval parking functions with a fixed number of inversions. We prove that
a well-known bijection of Foata preserves the set of $\ell$-interval parking
functions exactly when $\ell\leq 2$ or $\ell\geq n-2$, which implies that the
inversion and major index statistics are equidistributed in these cases.

</details>


### [26] [A simple proof of a $(p,2)$-theorem for non-piercing regions](https://arxiv.org/abs/2507.07269)
*Chaya Keller,Shakhar Smorodinsky*

Main category: math.CO

TL;DR: 本文证明，满足$(p,2)$-性质的平面非穿透区域族可用$O(p)$点刺穿，推广了先前需要$O(p^9)$点的几何结果。


<details>
  <summary>Details</summary>
Motivation: 近期研究使用复杂几何技术证明平面非穿透区域族在满足$(p,2)$-性质时需$O(p^9)$刺穿点，本文旨在通过超图理论简化并推广该结论。

Method: 利用遗传线性Delaunay图的超图理论成果，该理论包含非穿透区域交超图，从而将几何问题转化为超图问题。

Result: 证明广义场景下，满足$(p,2)$-性质的集合族仅需$O(p)$刺穿点，显著优于先前$O(p^9)$的几何构造。

Conclusion: 通过超图理论框架，本文统一并简化了非穿透区域刺穿问题的结论，将刺穿点数从多项式级降至线性级。

Abstract: A family of sets satisfies the $(p,2)$-property if among any $p$ sets in the
family, some two intersect. Two recent works used elaborate geometric
techniques to show that any family of non-piercing regions in the plane that
satisfies the $(p,2)$-property can be pierced by $O(p^9)$ points. In this note
we show that even in a much more general setting, piercing by $O(p)$ points can
be deduced from known results on hypergraphs with a hereditarily linear
Delaunay graph, which include intersection hypergraphs of non-piercing regions.

</details>


### [27] [Spanning k-trees, odd [1,b]-factors and spectral radius in binding graphs](https://arxiv.org/abs/2507.07301)
*Jiancheng Wu,Sizhong Zhou*

Main category: math.CO

TL;DR: 本文通过邻接谱半径提出了两个紧致的充分条件，分别用于连接$\frac{1}{b}$-绑定图存在奇$[1,b]$-因子和连接$\frac{1}{k-2}$-绑定图存在生成$k$-树，推广并改进了先前的研究结果。


<details>
  <summary>Details</summary>
Motivation: 研究图的绑定数与奇$[1,b]$-因子及生成$k$-树之间的关系，推广和改进Fan、Lin、Liu和Ao等人的先前工作。

Method: 使用图的邻接谱半径作为工具，结合绑定数的定义，推导出存在奇$[1,b]$-因子和生成$k$-树的充分条件。

Result: 提出了两个紧致的充分条件：1) 连接$\frac{1}{b}$-绑定图存在奇$[1,b]$-因子的邻接谱半径条件；2) 连接$\frac{1}{k-2}$-绑定图存在生成$k$-树的邻接谱半径条件。

Conclusion: 本文的结果推广并部分改进了先前关于绑定数、奇$[1,b]$-因子和生成$k$-树的研究，为相关图论问题提供了新的理论工具。

Abstract: The binding number of a graph $G$, written as $\mbox{bind}(G)$, is defined by
$$ \mbox{bind}(G)=\min\left\{\frac{|N_G(X)|}{|X|}:\emptyset\neq X\subseteq
V(G),N_G(X)\neq V(G)\right\}. $$ A graph $G$ is called $r$-binding if
$\mbox{bind}(G)\geq r$. An odd $[1,b]$-factor of a graph $G$ is a spanning
subgraph $F$ with $d_F(v)\in\{1,3,\ldots,b\}$ for all $v\in V(G)$, where
$b\geq1$ is an odd integer. A spanning $k$-tree of a connected graph $G$ is a
spanning tree $T$ with $d_T(v)\leq k$ for every $v\in V(G)$. In this paper, we
first show a tight sufficient condition with respect to the adjacency spectral
radius for connected $\frac{1}{b}$-binding graphs to have odd $[1,b]$-factors,
which generalizes Fan and Lin's previous result [D. Fan, H. Lin, Binding
number, $k$-factor and spectral radius of graphs, Electron. J. Combin. 31(1)
(2024) \#P1.30] and partly improves Fan, Liu and Ao's previous result [A. Fan,
R. Liu, G. Ao, Spectral radius, odd $[1,b]$-factor and spanning $k$-tree of
1-binding graphs, Linear Algebra Appl. 705 (2025) 1--16]. Then we put forward a
tight sufficient condition via the adjacency spectral radius for connected
$\frac{1}{k-2}$-binding graphs to have spanning $k$-trees, which partly
improves Fan, Liu and Ao's previous result [A. Fan, R. Liu, G. Ao, Spectral
radius, odd $[1,b]$-factor and spanning $k$-tree of 1-binding graphs, Linear
Algebra Appl. 705 (2025) 1--16].

</details>


### [28] [Volumes of moduli spaces of directed ribbon graphs and Cut-and-Join operators](https://arxiv.org/abs/2507.07308)
*Simon Barazer*

Main category: math.CO

TL;DR: 本文研究了无环分解的代数结构，通过定义积分算子并证明其满足Cut-and-Join方程，进一步展示了这些算子的特殊化可生成儿童绘图（dessins d'enfants）的生成级数。


<details>
  <summary>Details</summary>
Motivation: 研究有向度量带图的模空间体积的递归计算问题，探索无环分解的代数结构及其应用。

Method: 基于无环分解构建积分算子，证明其满足Cut-and-Join类型方程，并通过特殊化算子生成儿童绘图的级数。

Result: 成功定义了满足Cut-and-Join方程的积分算子，并证明其特殊化可生成儿童绘图的生成级数。

Conclusion: 无环分解的代数结构为模空间体积计算提供了新方法，其积分算子的特殊化在儿童绘图生成中具有重要应用价值。

Abstract: In this paper, we investigate the algebraic structure underlying the acyclic
decomposition. This decomposition applies to directed metric ribbon graphs and
enables the recursive computation of the volumes of their moduli spaces.
Building on this, we define integral operators with these volumes and show that
they satisfy a Cut-and-Join type equation. Furthermore, we demonstrate that a
suitable specialization of these operators gives rise to a generating series
for \textit{dessins d'enfants}.

</details>


### [29] [Exact Turán densities in triple systems](https://arxiv.org/abs/2507.07360)
*Nannan Chen,Yuzhen Qi,Caihong Yang,Hongbin Zhao*

Main category: math.CO

TL;DR: 本文证明了几个关于3-图的新Tur\'{a}n密度结果，包括确认Shi的猜想并解决了Mubayi和R\"odl提出的几个特殊非主族问题。


<details>
  <summary>Details</summary>
Motivation: 研究3-图的Tur\'{a}n密度问题，验证已有猜想并解决特定非主族问题，推动极值图论领域的发展。

Method: 通过数学证明方法，计算并验证了几个3-图的Tur\'{a}n密度值。

Result: 得到三个主要结果：$\pi(C_4^3, \mathrm{complement\ of\ } F_5) = 2\sqrt{3} - 3$，$\pi(F_{3,2}, C_5^{3-}) = \frac{2}{9}$，以及$\pi(F_{3,2}, \mathrm{induced\ complement\ of\ } F_{3,2}) = \frac{3}{8}$。

Conclusion: 这些结果不仅确认了Shi的猜想，还解决了Mubayi和R\"odl提出的几个特殊非主族问题，为3-图的Tur\'{a}n密度研究提供了新的理论支持。

Abstract: In this paper, we prove several new Tur\'{a}n density results for $3$-graphs.
We show: $\pi(C_4^3, \mathrm{complement\ of\ } F_5) = 2\sqrt{3} - 3$,
$\pi(F_{3,2}, C_5^{3-}) = \frac{2}{9}$, and $\pi(F_{3,2}, \mathrm{induced\
complement\ of\ } F_{3,2}) = \frac{3}{8}$. The first result confirms the
conjecture of Shi~[On Tur\'an denisties of small triple graphs, European J.
Combin. 52 (2016) 95-102]. The other results give several special non-principal
family posed by Mubayi and R\"odl~[On the Tur\'an number of triple systems, J.
Combin. Theory A. 100 (2002) 135-152].

</details>


### [30] [Deterministic simplicial complexes](https://arxiv.org/abs/2507.07402)
*S. N. Dorogovtsev,P. L. Krapivsky*

Main category: math.CO

TL;DR: 研究从单顶点确定性增长的单纯复形，分析其局部和全局特性，包括快速增长的数量、幂律度分布以及无限谱和Hausdorff维数。


<details>
  <summary>Details</summary>
Motivation: 探索确定性增长的单纯复形的结构和动力学特性，理解其在高维拓扑中的行为及其数学性质。

Method: 递归构建单纯复形：每一步中，每个现有的$d$维单纯形与一个新顶点结合形成$(d+1)$维单纯形，并添加所有新面。计算Hodge Laplacian谱并分析约束模型。

Result: 单纯复形的数量增长快于$n!$，度分布遵循幂律。谱和Hausdorff维数无限。约束模型中，单纯形数量指数增长，$m=1$时谱维数为2，$m=2$时谱维数有限且1度分布指数衰减。

Conclusion: 确定性增长的单纯复形展现出复杂的局部和全局特性，其度分布和维数特性随维度变化显著，约束模型提供了有限维数的有趣案例。

Abstract: We investigate simplicial complexes deterministically growing from a single
vertex. In the first step, a vertex and an edge connecting it to the primordial
vertex are added. The resulting simplicial complex has a 1-dimensional simplex
and two 0-dimensional faces (the vertices). The process continues recursively:
On the $n$-th step, every existing $d-$dimensional simplex ($d\leq n-1$) joins
a new vertex forming a $(d+1)-$dimensional simplex; all $2^{d+1}-2$ new faces
are also added so that the resulting object remains a simplicial complex. The
emerging simplicial complex has intriguing local and global characteristics.
The number of simplices grows faster than $n!$, and the upper-degree
distributions follow a power law. Here, the upper degree (or $d$-degree) of a
$d$-simplex refers to the number of $(d{+}1)$-simplices that share it as a
face. Interestingly, the $d$-degree distributions evolve quite differently for
different values of $d$. We compute the Hodge Laplacian spectra of simplicial
complexes and show that the spectral and Hausdorff dimensions are infinite. We
also explore a constrained version where the dimension of the added simplices
is fixed to a finite value $m$. In the constrained model, the number of
simplices grows exponentially. In particular, for $m=1$, the spectral dimension
is $2$. For $m=2$, the spectral dimension is finite, and the degree
distribution follows a power law, while the $1$-degree distribution decays
exponentially.

</details>


### [31] [Cocompact unfolding trees](https://arxiv.org/abs/2507.07503)
*Roman Gorazd*

Main category: math.CO

TL;DR: 本文研究了有限有向根图的根路径树在无向自同构群作用下仅有有限轨道（即余紧）的条件，并给出了判定算法。


<details>
  <summary>Details</summary>
Motivation: 旨在解决arXiv:2212.07205中问题(1)，即确定哪些树与余紧树几乎同构。

Method: 通过分析有向根图的根路径树的自同构群作用，提出判定余紧性的算法。

Result: 明确了具有有限轨道的树的条件，并提供了判定此类树的算法。

Conclusion: 该研究基本回答了特定树的余紧性问题，为相关领域提供了理论工具。

Abstract: This paper will show when a rooted path tree of a finite directed rooted
graph has only finitely many orbits under the action of its undirected
automorphism group (i.e. when it is cocompact). This will allow us to specify
which trees are almost isomorphic to cocompact trees. We will provide an
algorithm that will determine this, thus mostly answering question (1) from
arXiv:2212.07205.

</details>


### [32] [Evasive sets, twisted varieties, and container-clique trees](https://arxiv.org/abs/2507.07594)
*Jeck Lim,Jiaxi Nie,Ji Zeng*

Main category: math.CO

TL;DR: 该论文研究了有限域$\mathbb{F}_q^n$中的$(d,k,r)$-规避集，证明了其存在性并给出了枚举上界。同时，在代数闭域上的射影空间$\mathbb{P}^n$中，研究了$d$-扭曲簇的最小可能度。


<details>
  <summary>Details</summary>
Motivation: 研究有限域中规避集的存在性和大小，以及射影空间中扭曲簇的性质，旨在为相关数学问题提供新的理论工具和结果。

Method: 通过平均论证和扭曲簇的研究，证明了规避集的存在性；采用容器方法的新技术进行枚举。

Result: 证明了$(d,k,r)$-规避集的大小至少为$\Omega\left(q^{n-k}\right)$，并给出了枚举上界$2^{O(q^{n-k})}$；同时确定了扭曲簇的最小可能度的上界。

Conclusion: 该研究不仅改进了规避集的构造，还提出了容器方法的新技术，为相关领域的研究提供了新的工具和视角。

Abstract: In the affine space $\mathbb{F}_q^n$ over the finite field of order $q$, a
point set $S$ is said to be $(d,k,r)$-evasive if the intersection between $S$
and any variety, of dimension $k$ and degree at most $d$, has cardinality less
than $r$. As $q$ tends to infinity, the size of a $(d,k,r)$-evasive set in
$\mathbb{F}_q^n$ is at most $O\left(q^{n-k}\right)$ by a simple averaging
argument. We exhibit the existence of such evasive sets of sizes at least
$\Omega\left(q^{n-k}\right)$ for much smaller values of $r$ than previously
known constructions, and establish an enumerative upper bound $2^{O(q^{n-k})}$
for the total number of such evasive sets. The existence result is based on our
study of twisted varieties. In the projective space $\mathbb{P}^n$ over an
algebraically closed field, a variety $V$ is said to be $d$-twisted if the
intersection between $V$ and any variety, of dimension $n - \dim(V)$ and degree
at most $d$, has dimension zero. We prove an upper bound on the smallest
possible degree of twisted varieties which is best possible in a mild sense.
The enumeration result includes a new technique for the container method which
we believe is of independent interest. To illustrate the potential of this
technique, we give a simpler proof of a result by Chen--Liu--Nie--Zeng that
characterizes the maximum size of a collinear-triple-free subset in a random
sampling of $ \mathbb{F}_q^2$ up to polylogarithmic factors.

</details>


### [33] [A constructive characterization of uniformly 4-connected graphs](https://arxiv.org/abs/2507.07656)
*Xiang Chen,Shuai Kou,Chengfu Qin,Liqiong Xu,Weihua Yang*

Main category: math.CO

TL;DR: 本文提出了一种构建均匀4连通图类的构造性特征，基于对特定顶点和边集应用图操作，从$C_5^2$或$C_6^2$出发通过$\Delta_1^+$或$\Delta_2^+$操作生成所有均匀4连通图。


<details>
  <summary>Details</summary>
Motivation: 研究均匀4连通图的结构特征，旨在通过构造性方法完整描述此类图的性质与生成方式。

Method: 采用$\Delta_1^+$和$\Delta_2^+$图操作作用于拟4兼容集，从基础图$C_5^2$和$C_6^2$逐步构建所有均匀4连通图。

Result: 证明了任何均匀4连通图均可通过有限次指定操作从$C_5^2$或$C_6^2$生成，确立了该图类的完整构造体系。

Conclusion: 该构造性特征为均匀4连通图提供了明确的生成路径，深化了对这类图拓扑结构的理解。

Abstract: A constructive characterization of the class of uniformly $4$-connected
graphs is presented. The characterization is based on the application of graph
operations to appropriate vertex and edge sets in uniformly $4$-connected
graphs, that is, any uniformly $4$-connected graph can be obtained from $C_5^2$
or $C_6^2$ by a number of $\Delta_1^+$ or $\Delta_2^+$-operations to quasi
$4$-compatible sets.

</details>


### [34] [Regular sets in Cayley sum graphs on generalized dicyclic groups](https://arxiv.org/abs/2507.07736)
*Meiqi Peng,Yuefeng Yang,Wenying Zhu*

Main category: math.CO

TL;DR: 本文研究了广义双循环群$G$的子群$H$作为$(\alpha,\beta)$-正则集的性质，通过选择合适的连接集$S$，确定了$H$成为$G$的$(\alpha,\beta)$-正则集的所有可能参数对$(\alpha,\beta)$。


<details>
  <summary>Details</summary>
Motivation: 研究图的$(\alpha,\beta)$-正则集在群论中的应用，特别是广义双循环群的子群如何通过特定连接集成为正则集，以扩展代数图论的理论框架。

Method: 对于广义双循环群$G$的每个子群$H$，通过构造适当的连接集$S$，分析$H$在凯莱和图上的邻接性质，推导出$(\alpha,\beta)$的可能取值。

Result: 确定了广义双循环群$G$的任意子群$H$作为$(\alpha,\beta)$-正则集时，参数$\alpha$和$\beta$的所有可能组合，并给出了具体的构造方法。

Conclusion: 该研究不仅完善了$(\alpha,\beta)$-正则集在群论中的理论体系，还为广义双循环群的结构分析提供了新的工具和视角。

Abstract: For a graph $\Gamma=(V(\Gamma),E(\Gamma))$, a subset $C$ of $V(\Gamma)$ is
called an $(\alpha,\beta)$-regular set in $\Gamma$, if every vertex of $C$ is
adjacent to exactly $\alpha$ vertices of $C$ and every vertex of
$V(\Gamma)\setminus C$ is adjacent to exactly $\beta$ vertices of $C$. In
particular, if $C$ is an $(\alpha,\beta)$-regular set in some Cayley sum graph
of a finite group $G$ with connection set $S$, then $C$ is called an
$(\alpha,\beta)$-regular set of $G$. In this paper, we consider a generalized
dicyclic group $G$ and for each subgroup $H$ of $G$, by giving an appropriate
connection set $S$, we determine each possibility for $(\alpha,\beta)$ such
that $H$ is an $(\alpha,\beta)$-regular set of $G$.

</details>


### [35] [Constructing Optimal Kobon Triangle Arrangements via Table Encoding, SAT Solving, and Heuristic Straightening](https://arxiv.org/abs/2507.07951)
*Pavlo Savchuk*

Main category: math.CO

TL;DR: 本文提出了构建最优Kobon三角形排列的新方法和结果，包括紧凑表格表示法、启发式恢复工具及基于SAT求解器的优化技术，发现了23线和27线的新最优解。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发更高效的方法来构建和分析Kobon三角形排列，解决复杂情况（如对称排列、平行线及多线交点）的表示与优化问题。

Method: 1. 引入紧凑表格表示法描述伪线排列；2. 开发启发式工具从表格恢复直线排列并保持对称性；3. 将最优Kobon排列搜索转化为SAT问题，利用Kissat求解器高效求解。

Result: 1. 工具成功恢复了已知最优解；2. 通过SAT方法确认11线无最优解；3. 发现了23线和27线的新最优Kobon排列及其他新结果。

Conclusion: 新方法显著提升了Kobon排列的构建与分析效率，表格表示法与SAT求解器的结合为组合几何问题提供了通用解决方案框架。

Abstract: We present new methods and results for constructing optimal Kobon triangle
arrangements. First, we introduce a compact table notation for describing
arrangements of pseudolines, enabling the representation and analysis of
complex cases, including symmetrical arrangements, arrangements with parallel
lines, and arrangements with multiple-line intersection points. Building on
this, we provide a simple heuristic method and tools for recovering
straight-line arrangements from a given table, with the ability to enforce
additional properties such as symmetries. The tool successfully recovers
arrangements for many previously known optimal solutions. Additionally, we
develop a tool that transforms the search for optimal Kobon arrangement tables
into a SAT problem, allowing us to leverage modern SAT solvers (specifically
Kissat) to efficiently find new solutions or to show that no other solutions
exist (for example, confirming that no optimal solution exists in the 11-line
case). Using these techniques, we find new optimal Kobon arrangements for 23
and 27 lines, along with several other new results.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [36] [Time Series Foundation Models for Multivariate Financial Time Series Forecasting](https://arxiv.org/abs/2507.07296)
*Ben A. Marconi*

Main category: q-fin.GN

TL;DR: 时间序列基础模型（TSFMs）在金融时间序列预测中展现出潜力，特别是在数据有限或噪声较大的任务中。TTM模型表现出较强的迁移能力和样本效率，但在某些任务上仍需优化以超越传统专业模型。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列预测面临非线性关系、时间依赖性、变量间相互依赖及数据有限等挑战，尤其是在低频数据、新上市工具或新兴市场资产中。TSFMs通过预训练和任务适应提供解决方案。

Method: 研究评估了两种TSFMs（TTM和Chronos）在三个金融预测任务中的表现：美国10年期国债收益率变化、欧元/美元波动率和股票价差预测。比较了预训练和未训练模型的性能。

Result: TTM在有限数据下微调时性能提升25-50%，在较长时间数据下提升15-30%。其零样本表现优于基准模型，且预训练模型需3-10年更少数据达到相同性能。但在两项任务中，传统专业模型表现相当或更好。

Conclusion: TSFMs在金融预测中具有潜力，尤其在数据受限任务中，但需针对金融时间序列特性进行领域特定预训练和架构优化，以实现更具竞争力的性能。

Abstract: Financial time series forecasting presents significant challenges due to
complex nonlinear relationships, temporal dependencies, variable
interdependencies and limited data availability, particularly for tasks
involving low-frequency data, newly listed instruments, or emerging market
assets. Time Series Foundation Models (TSFMs) offer a promising solution
through pretraining on diverse time series corpora followed by task-specific
adaptation. This study evaluates two TSFMs (Tiny Time Mixers (TTM) and Chronos)
across three financial forecasting tasks: US 10-year Treasury yield changes,
EUR/USD volatility, and equity spread prediction. Results demonstrate that TTM
exhibits strong transferability. When fine-tuning both the pretrained version
of TTM and an untrained model with the same architecture, the pretrained
version achieved 25-50% better performance when fine-tuned on limited data and
15-30% improvements even when fine-tuned on lengthier datasets. Notably, TTM's
zero-shot performance outperformed naive benchmarks in volatility forecasting
and equity spread prediction, with the latter demonstrating that TSFMs can
surpass traditional benchmark models without fine-tuning. The pretrained model
consistently required 3-10 fewer years of data to achieve comparable
performance levels compared to the untrained model, demonstrating significant
sample-efficiency gains. However, while TTM outperformed naive baselines,
traditional specialised models matched or exceeded its performance in two of
three tasks, suggesting TSFMs prioritise breadth over task-specific
optimisation. These findings indicate that TSFMs, though still nascent, offer
substantial promise for financial forecasting-particularly in noisy,
data-constrained tasks-but achieving competitive performance likely requires
domain-specific pretraining and architectural refinements tailored to financial
time series characteristics.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [37] [WatchWitch: Interoperability, Privacy, and Autonomy for the Apple Watch](https://arxiv.org/abs/2507.07210)
*Nils Rollshausen,Alexander Heinrich,Matthias Hollick,Jiska Classen*

Main category: cs.CR

TL;DR: 研究团队首次公开逆向工程Apple Watch的无线协议，发现其专有实现中的多个安全问题，并通过Android重实现WatchWitch打破苹果生态限制，提升用户隐私控制与数据自主权。


<details>
  <summary>Details</summary>
Motivation: Apple Watch等智能手表收集大量敏感健康数据，但用户无法选择数据处理方式，设备仅限与iPhone配对使用，依赖苹果的软件和云服务，缺乏自主控制权。

Method: 通过逆向工程分析Apple Watch的无线通信协议，发现其专有实现的安全漏洞，并开发了Android平台的重实现方案WatchWitch。

Result: 成功实现与Apple Watch的跨平台互操作，提供增强的隐私控制功能，证明打破苹果封闭生态的可行性。

Conclusion: 该研究为智能手表生态系统提供了更多消费者选择可能性，使用户获得对设备的更高控制权，推动行业向开放方向发展。

Abstract: Smartwatches such as the Apple Watch collect vast amounts of intimate health
and fitness data as we wear them. Users have little choice regarding how this
data is processed: The Apple Watch can only be used with Apple's iPhones, using
their software and their cloud services. We are the first to publicly
reverse-engineer the watch's wireless protocols, which led to discovering
multiple security issues in Apple's proprietary implementation. With
WatchWitch, our custom Android reimplementation, we break out of Apple's walled
garden -- demonstrating practical interoperability with enhanced privacy
controls and data autonomy. We thus pave the way for more consumer choice in
the smartwatch ecosystem, offering users more control over their devices.

</details>


### [38] [Automated Attack Testflow Extraction from Cyber Threat Report using BERT for Contextual Analysis](https://arxiv.org/abs/2507.07244)
*Faissal Ahmadou,Sepehr Ghaffarzadegan,Boubakr Nour,Makan Pourzandi,Mourad Debbabi,Chadi Assi*

Main category: cs.CR

TL;DR: 本文提出FLOWGUARDIAN系统，利用BERT模型和NLP技术自动从非结构化威胁报告中提取攻击测试流程，显著提升网络安全团队对高级持续性威胁(APTs)的识别与响应能力。


<details>
  <summary>Details</summary>
Motivation: 当前网络安全领域依赖人工从威胁报告中提取攻击流程(TTPs)，存在效率低、易出错的问题，亟需自动化解决方案来提升威胁狩猎和事件响应效率。

Method: 采用BERT语言模型和自然语言处理技术，系统化分析安全事件上下文，重构攻击序列，自动生成全面测试流程。

Result: 基于公开威胁报告的实证验证表明，FLOWGUARDIAN在准确性和效率方面表现优异，能显著减少人工错误并确保测试覆盖的全面性。

Conclusion: FLOWGUARDIAN为网络安全测试提供了自动化、鲁棒的新范式，通过AI技术赋能安全团队实现更主动的威胁防御。

Abstract: In the ever-evolving landscape of cybersecurity, the rapid identification and
mitigation of Advanced Persistent Threats (APTs) is crucial. Security
practitioners rely on detailed threat reports to understand the tactics,
techniques, and procedures (TTPs) employed by attackers. However, manually
extracting attack testflows from these reports requires elusive knowledge and
is time-consuming and prone to errors. This paper proposes FLOWGUARDIAN, a
novel solution leveraging language models (i.e., BERT) and Natural Language
Processing (NLP) techniques to automate the extraction of attack testflows from
unstructured threat reports. FLOWGUARDIAN systematically analyzes and
contextualizes security events, reconstructs attack sequences, and then
generates comprehensive testflows. This automated approach not only saves time
and reduces human error but also ensures comprehensive coverage and robustness
in cybersecurity testing. Empirical validation using public threat reports
demonstrates FLOWGUARDIAN's accuracy and efficiency, significantly enhancing
the capabilities of security teams in proactive threat hunting and incident
response.

</details>


### [39] [Disa: Accurate Learning-based Static Disassembly with Attentions](https://arxiv.org/abs/2507.07246)
*Peicheng Wang,Monika Santra,Mingyu Liu,Cong Sun,Dongrui Zeng,Gang Tan*

Main category: cs.CR

TL;DR: 本文提出Disa，一种基于学习的反汇编方法，利用多头自注意力机制学习指令相关性，显著提升了反汇编准确性和控制流图生成精度。


<details>
  <summary>Details</summary>
Motivation: 传统反汇编方法依赖文件格式假设和架构特定启发式方法，在混淆二进制文件时效果不佳。深度学习可提高反汇编准确性和效率，但现有方法仍有改进空间。

Method: Disa采用基于多头自注意力的超集指令信息学习指令相关性，推断函数入口点和指令边界，并通过内存块边界识别优化控制流图生成。

Result: 实验表明：Disa在函数入口点识别上优于现有深度学习方法（对混淆二进制F1值提升9.1%-13.2%），内存块精度提升18.5%，间接调用目标数减少4.4%。

Conclusion: Disa通过深度学习模型有效解决了混淆二进制反汇编难题，在函数识别和CFG生成精度上显著超越现有方法，为安全分析提供了更可靠的基础。

Abstract: For reverse engineering related security domains, such as vulnerability
detection, malware analysis, and binary hardening, disassembly is crucial yet
challenging. The fundamental challenge of disassembly is to identify
instruction and function boundaries. Classic approaches rely on file-format
assumptions and architecture-specific heuristics to guess the boundaries,
resulting in incomplete and incorrect disassembly, especially when the binary
is obfuscated. Recent advancements of disassembly have demonstrated that deep
learning can improve both the accuracy and efficiency of disassembly. In this
paper, we propose Disa, a new learning-based disassembly approach that uses the
information of superset instructions over the multi-head self-attention to
learn the instructions' correlations, thus being able to infer function
entry-points and instruction boundaries. Disa can further identify instructions
relevant to memory block boundaries to facilitate an advanced block-memory
model based value-set analysis for an accurate control flow graph (CFG)
generation. Our experiments show that Disa outperforms prior deep-learning
disassembly approaches in function entry-point identification, especially
achieving 9.1% and 13.2% F1-score improvement on binaries respectively
obfuscated by the disassembly desynchronization technique and popular
source-level obfuscator. By achieving an 18.5% improvement in the memory block
precision, Disa generates more accurate CFGs with a 4.4% reduction in Average
Indirect Call Targets (AICT) compared with the state-of-the-art heuristic-based
approach.

</details>


### [40] [Semi-fragile watermarking of remote sensing images using DWT, vector quantization and automatic tiling](https://arxiv.org/abs/2507.07250)
*Jordi Serra-Ruiz,David Megías*

Main category: cs.CR

TL;DR: 本文提出了一种针对多波段图像的半脆弱水印方案，通过树结构矢量量化方法在像素签名中嵌入水印，以检测原始图像的显著修改。


<details>
  <summary>Details</summary>
Motivation: 为了保护遥感图像免受未经授权的修改，同时保持其在有损压缩下的完整性，需要一种能够区分合法处理与恶意篡改的水印技术。

Method: 该方法将多光谱或高光谱图像分割为三维块，为每个块构建树结构矢量量化器，并通过迭代算法操作这些树，直到满足嵌入水印的特定标准。

Result: 实验表明，该方法能够在有损压缩（超过给定阈值）下保持水印，同时准确检测伪造块及其在图像中的位置。

Conclusion: 提出的半脆弱水印方案有效地平衡了水印的鲁棒性与脆弱性，适用于遥感图像的真实性验证和篡改检测。

Abstract: A semi-fragile watermarking scheme for multiple band images is presented in
this article. We propose to embed a mark into remote sensing images applying a
tree-structured vector quantization approach to the pixel signatures instead of
processing each band separately. The signature of the multispectral or
hyperspectral image is used to embed the mark in it order to detect any
significant modification of the original image. The image is segmented into
three-dimensional blocks, and a tree-structured vector quantizer is built for
each block. These trees are manipulated using an iterative algorithm until the
resulting block satisfies a required criterion, which establishes the embedded
mark. The method is shown to be able to preserve the mark under lossy
compression (above a given threshold) but, at the same time, it detects
possibly forged blocks and their position in the whole image.

</details>


### [41] [FedP3E: Privacy-Preserving Prototype Exchange for Non-IID IoT Malware Detection in Cross-Silo Federated Learning](https://arxiv.org/abs/2507.07258)
*Rami Darwish,Mahmoud Abdelsalam,Sajad Khorsandroo,Kaushik Roy*

Main category: cs.CR

TL;DR: 针对物联网(IoT)生态系统中恶意软件攻击日益复杂化的问题，本文提出了一种新型联邦学习框架FedP3E，通过隐私保护的类原型交换机制解决数据异构性和类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 物联网设备面临日益复杂的恶意软件威胁，现有联邦学习算法(FedAvg/FedProx)在非独立同分布(non-IID)数据和类别不平衡场景下表现不佳，需要兼顾隐私保护与检测效能的解决方案。

Method: 提出FedP3E框架：客户端使用高斯混合模型(GMM)构建类原型，添加高斯噪声保护隐私后上传；服务器聚合原型并下发，结合SMOTE增强少数类样本；通过原型交换而非参数平均实现跨客户端知识共享。

Result: 在N-BaIoT数据集上的跨机构场景测试表明，该框架能有效应对数据不平衡问题，在保证隐私的同时降低了统计异构性的负面影响，且通信开销较小。

Conclusion: FedP3E通过原型交换机制实现了隐私保护下的跨客户端表征共享，为物联网恶意软件检测提供了一种兼顾数据隐私与模型效能的联邦学习新范式。

Abstract: As IoT ecosystems continue to expand across critical sectors, they have
become prominent targets for increasingly sophisticated and large-scale malware
attacks. The evolving threat landscape, combined with the sensitive nature of
IoT-generated data, demands detection frameworks that are both
privacy-preserving and resilient to data heterogeneity. Federated Learning (FL)
offers a promising solution by enabling decentralized model training without
exposing raw data. However, standard FL algorithms such as FedAvg and FedProx
often fall short in real-world deployments characterized by class imbalance and
non-IID data distributions -- particularly in the presence of rare or disjoint
malware classes. To address these challenges, we propose FedP3E
(Privacy-Preserving Prototype Exchange), a novel FL framework that supports
indirect cross-client representation sharing while maintaining data privacy.
Each client constructs class-wise prototypes using Gaussian Mixture Models
(GMMs), perturbs them with Gaussian noise, and transmits only these compact
summaries to the server. The aggregated prototypes are then distributed back to
clients and integrated into local training, supported by SMOTE-based
augmentation to enhance representation of minority malware classes. Rather than
relying solely on parameter averaging, our prototype-driven mechanism enables
clients to enrich their local models with complementary structural patterns
observed across the federation -- without exchanging raw data or gradients.
This targeted strategy reduces the adverse impact of statistical heterogeneity
with minimal communication overhead. We evaluate FedP3E on the N-BaIoT dataset
under realistic cross-silo scenarios with varying degrees of data imbalance.

</details>


### [42] [Shuffling for Semantic Secrecy](https://arxiv.org/abs/2507.07401)
*Fupei Chen,Liyao Xiang,Haoxiang Sun,Hei Victor Cheng,Kaiming Shen*

Main category: cs.CR

TL;DR: 本文从新颖的随机打乱视角研究深度学习语义通信的安全性，提出一种最大化传输率同时最小化语义错误概率的语义安全通信系统，通过特征序列的随机置换有效抵御窃听。


<details>
  <summary>Details</summary>
Motivation: 针对现有安全编码方案在传输率与泄漏率之间难以平衡的问题，研究如何在给定泄漏率约束下优化语义通信系统的安全性能。

Method: 设计基于随机打乱模式的语义安全通信系统，将特征序列置换作为共享密钥，通过扰乱语义本质阻止窃听者获取有效信息，并可灵活嵌入现有系统。

Result: 仿真表明该方法显著提升抗噪与抗衰落信道中的安全传输性能，较基准方案具有明显优势。

Conclusion: 随机打乱机制为语义通信安全提供了有效解决方案，在复杂信道环境下实现传输率与安全性的最佳权衡。

Abstract: Deep learning draws heavily on the latest progress in semantic
communications. The present paper aims to examine the security aspect of this
cutting-edge technique from a novel shuffling perspective. Our goal is to
improve upon the conventional secure coding scheme to strike a desirable
tradeoff between transmission rate and leakage rate. To be more specific, for a
wiretap channel, we seek to maximize the transmission rate while minimizing the
semantic error probability under the given leakage rate constraint. Toward this
end, we devise a novel semantic security communication system wherein the
random shuffling pattern plays the role of the shared secret key. Intuitively,
the permutation of feature sequences via shuffling would distort the semantic
essence of the target data to a sufficient extent so that eavesdroppers cannot
access it anymore. The proposed random shuffling method also exhibits its
flexibility in working for the existing semantic communication system as a
plugin. Simulations demonstrate the significant advantage of the proposed
method over the benchmark in boosting secure transmission, especially when
channels are prone to strong noise and unpredictable fading.

</details>


### [43] [Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models](https://arxiv.org/abs/2507.07406)
*Jikesh Thapa,Gurrehmat Chahal,Serban Voinea Gabreanu,Yazan Otoum*

Main category: cs.CR

TL;DR: 本文比较了传统机器学习(ML)、深度学习(DL)与量化小参数大语言模型(LLM)在钓鱼检测中的表现，发现LLM虽精度稍逊但擅长识别上下文线索，且轻量级LLM能以17GB显存实现80%+准确率，兼具可解释性与部署成本优势。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击日益复杂，需平衡检测精度与计算效率。研究旨在评估不同AI方法在钓鱼检测中的性能潜力，特别是LLM在识别细微上下文线索和成本效益方面的表现。

Method: 使用精选数据集对比ML/DL/量化LLM性能，测试零样本/少样本提示策略，分析对抗鲁棒性和成本效益，评估模型如DeepSeek R1 Distill Qwen 14B (Q8_0)的17GB显存占用表现。

Result: LLM当前精度低于ML/DL，但展现识别上下文钓鱼线索的潜力；模型重述邮件会显著降低检测器性能；轻量LLM能以80%+准确率高效运行，并提供可解释的实时决策支持。

Conclusion: 优化后的LLM有望成为钓鱼防御系统的关键组件，为将可解释、高效的AI整合到现代网络安全框架提供了可行路径。

Abstract: Phishing attacks are becoming increasingly sophisticated, underscoring the
need for detection systems that strike a balance between high accuracy and
computational efficiency. This paper presents a comparative evaluation of
traditional Machine Learning (ML), Deep Learning (DL), and quantized
small-parameter Large Language Models (LLMs) for phishing detection. Through
experiments on a curated dataset, we show that while LLMs currently
underperform compared to ML and DL methods in terms of raw accuracy, they
exhibit strong potential for identifying subtle, context-based phishing cues.
We also investigate the impact of zero-shot and few-shot prompting strategies,
revealing that LLM-rephrased emails can significantly degrade the performance
of both ML and LLM-based detectors. Our benchmarking highlights that models
like DeepSeek R1 Distill Qwen 14B (Q8_0) achieve competitive accuracy, above
80%, using only 17GB of VRAM, supporting their viability for cost-efficient
deployment. We further assess the models' adversarial robustness and
cost-performance tradeoffs, and demonstrate how lightweight LLMs can provide
concise, interpretable explanations to support real-time decision-making. These
findings position optimized LLMs as promising components in phishing defence
systems and offer a path forward for integrating explainable, efficient AI into
modern cybersecurity frameworks.

</details>


### [44] [Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks](https://arxiv.org/abs/2507.07413)
*Mohammad F. Al-Hammouri,Yazan Otoum,Rasha Atwa,Amiya Nayak*

Main category: cs.CR

TL;DR: 本文提出了一种新型入侵检测方法，结合传统特征检测与GPT-2大语言模型的上下文理解能力，显著提升检测精度并降低误报率。


<details>
  <summary>Details</summary>
Motivation: 随着物联网等分布式异构环境中网络威胁日益复杂，传统入侵检测系统难以识别新型攻击模式，亟需动态自适应解决方案。

Method: 提出混合框架：将基于特征的检测方法与GPT-2驱动的语义分析相结合，利用后者处理非结构化数据和识别复杂语义关系的能力。

Result: 实验表明，该模型检测准确率提升6.3%，误报率降低9.0%，且保持近实时响应速度。

Conclusion: 语言模型整合为构建智能、可扩展的现代网络安全防御体系提供了有效途径。

Abstract: This paper presents a novel approach to intrusion detection by integrating
traditional signature-based methods with the contextual understanding
capabilities of the GPT-2 Large Language Model (LLM). As cyber threats become
increasingly sophisticated, particularly in distributed, heterogeneous, and
resource-constrained environments such as those enabled by the Internet of
Things (IoT), the need for dynamic and adaptive Intrusion Detection Systems
(IDSs) becomes increasingly urgent. While traditional methods remain effective
for detecting known threats, they often fail to recognize new and evolving
attack patterns. In contrast, GPT-2 excels at processing unstructured data and
identifying complex semantic relationships, making it well-suited to uncovering
subtle, zero-day attack vectors. We propose a hybrid IDS framework that merges
the robustness of signature-based techniques with the adaptability of
GPT-2-driven semantic analysis. Experimental evaluations on a representative
intrusion dataset demonstrate that our model enhances detection accuracy by
6.3%, reduces false positives by 9.0%, and maintains near real-time
responsiveness. These results affirm the potential of language model
integration to build intelligent, scalable, and resilient cybersecurity
defences suited for modern connected environments.

</details>


### [45] [Autonomous AI-based Cybersecurity Framework for Critical Infrastructure: Real-Time Threat Mitigation](https://arxiv.org/abs/2507.07416)
*Jenifer Paulraj,Brindha Raghuraman,Nagarani Gopalakrishnan,Yazan Otoum*

Main category: cs.CR

TL;DR: 本文探讨关键基础设施面临的网络安全威胁，提出一种混合AI驱动的网络安全框架，以增强实时漏洞检测和自动修复能力。


<details>
  <summary>Details</summary>
Motivation: 关键基础设施（如能源网、医疗设施、交通网络和供水系统）对社会稳定和经济韧性至关重要，但其日益增长的互联性使其面临勒索软件、拒绝服务攻击和高级持续性威胁等网络威胁。

Method: 研究提出了一种混合AI驱动的网络安全框架，结合实时漏洞检测、威胁建模和自动修复技术，并探讨了对抗性AI、法规合规性和系统集成的复杂性。

Result: 研究结果为加强关键基础设施的安全性和韧性提供了可操作的见解，以应对新兴的网络威胁。

Conclusion: 通过AI驱动的网络安全框架，可以有效提升关键基础设施对网络威胁的防御能力，同时需关注对抗性AI和法规合规等挑战。

Abstract: Critical infrastructure systems, including energy grids, healthcare
facilities, transportation networks, and water distribution systems, are
pivotal to societal stability and economic resilience. However, the increasing
interconnectivity of these systems exposes them to various cyber threats,
including ransomware, Denial-of-Service (DoS) attacks, and Advanced Persistent
Threats (APTs). This paper examines cybersecurity vulnerabilities in critical
infrastructure, highlighting the threat landscape, attack vectors, and the role
of Artificial Intelligence (AI) in mitigating these risks. We propose a hybrid
AI-driven cybersecurity framework to enhance real-time vulnerability detection,
threat modelling, and automated remediation. This study also addresses the
complexities of adversarial AI, regulatory compliance, and integration. Our
findings provide actionable insights to strengthen the security and resilience
of critical infrastructure systems against emerging cyber threats.

</details>


### [46] [May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks](https://arxiv.org/abs/2507.07417)
*Nishit V. Pandya,Andrey Labunets,Sicun Gao,Earlence Fernandes*

Main category: cs.CR

TL;DR: 本文评估了针对大型语言模型(LLM)提示注入攻击的防御方法的鲁棒性，提出了一种新型基于注意力的攻击算法，并在白盒设置下成功攻破了两种最新防御方案SecAlign和StruQ，攻击成功率高达70%。


<details>
  <summary>Details</summary>
Motivation: 当前许多防御提示注入攻击的方法依赖于微调模型以区分指令和数据，但这些防御方法在白盒环境下的安全性尚未得到充分验证。本文旨在评估这类防御措施的实际鲁棒性。

Method: 研究者构建了基于优化的强攻击方法，开发了一种新型的基于注意力的文本LLM攻击算法，并将其应用于两种最新的白盒防御方案SecAlign(CCS 2025)和StruQ(USENIX Security 2025)。

Result: 实验表明，这些防御措施无法提供所声称的安全特性，攻击成功率最高可达70%，且攻击者只需适度增加token预算即可实现。

Conclusion: 该研究从根本上推进了对白盒环境下提示注入防御鲁棒性的理解，相关代码和攻击方法已在https://github.com/nishitvp/better_opts_attacks公开。

Abstract: A popular class of defenses against prompt injection attacks on large
language models (LLMs) relies on fine-tuning the model to separate instructions
and data, so that the LLM does not follow instructions that might be present
with data. There are several academic systems and production-level
implementations of this idea. We evaluate the robustness of this class of
prompt injection defenses in the whitebox setting by constructing strong
optimization-based attacks and showing that the defenses do not provide the
claimed security properties. Specifically, we construct a novel attention-based
attack algorithm for text-based LLMs and apply it to two recent whitebox
defenses SecAlign (CCS 2025) and StruQ (USENIX Security 2025), showing attacks
with success rates of up to 70% with modest increase in attacker budget in
terms of tokens. Our findings make fundamental progress towards understanding
the robustness of prompt injection defenses in the whitebox setting. We release
our code and attacks at https://github.com/nishitvp/better_opts_attacks

</details>


### [47] [RADAR: a Radio-based Analytics for Dynamic Association and Recognition of pseudonyms in VANETs](https://arxiv.org/abs/2507.07732)
*Giovanni Gambigliani Zoccoli,Filip Valgimigli,Dario Stabili,Mirco Marchetti*

Main category: cs.CR

TL;DR: 本文提出RADAR算法，通过结合DSRC和Wi-Fi探针信号提升车辆追踪能力，突破VANET中的隐私保护假名方案，实验证明Pearson RSSI指标在所有场景下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有VANET假名方案存在被追踪风险，尤其在攻击者无法全程覆盖车辆路径的现实场景中，需要更有效的去匿名化方法。

Method: 利用车辆发射的DSRC和Wi-Fi探针请求信号，提出三种假名与Wi-Fi标识关联指标（计数法、统计RSSI法、Pearson RSSI法）进行追踪性能比较。

Result: 实验表明Pearson RSSI指标在假名更换场景下具有最优追踪性能，且全面优于现有仅依赖DSRC的方法。

Conclusion: RADAR算法通过多信号融合显著提升追踪效果，公开了全部实现代码与仿真场景以推动领域发展。

Abstract: This paper presents RADAR, a tracking algorithm for vehicles participating in
Cooperative Intelligent Transportation Systems (C-ITS) that exploits multiple
radio signals emitted by a modern vehicle to break privacy-preserving pseudonym
schemes deployed in VANETs. This study shows that by combining Dedicated Short
Range Communication (DSRC) and Wi-Fi probe request messages broadcast by the
vehicle, it is possible to improve tracking over standard de-anonymization
approaches that only leverage DSRC, especially in realistic scenarios where the
attacker does not have full coverage of the entire vehicle path. The
experimental evaluation compares three different metrics for pseudonym and
Wi-Fi probe identifier association (Count, Statistical RSSI, and Pearson RSSI),
demonstrating that the Pearson RSSI metric is better at tracking vehicles under
pseudonym-changing schemes in all scenarios and against previous works. As an
additional contribution to the state-of-the-art, we publicly release all
implementations and simulation scenarios used in this work.

</details>


### [48] [Rainbow Artifacts from Electromagnetic Signal Injection Attacks on Image Sensors](https://arxiv.org/abs/2507.07773)
*Youqian Zhang,Xinyu Ji,Zhihao Wang,Qinhong Jiang*

Main category: cs.CR

TL;DR: 研究发现CMOS图像传感器存在新型电磁信号注入攻击漏洞，攻击者可通过精心调制的电磁干扰在图像中制造彩虹色伪影，从而绕过数字完整性检查并导致目标检测模型误判。


<details>
  <summary>Details</summary>
Motivation: 图像传感器广泛应用于安防监控、自动驾驶等安全关键系统，其视觉数据完整性至关重要。现有研究未充分关注模拟域电磁攻击对图像传感器的威胁。

Method: 通过精心调制的电磁干扰信号攻击CMOS图像传感器的模拟域，在原始图像中注入彩虹色伪影，并评估其对先进目标检测模型的影响。

Result: 攻击产生的伪影能穿透图像信号处理流水线，导致目标检测模型出现显著误判（如将停车标志识别为限速标志），暴露了感知系统的物理层漏洞。

Conclusion: 该研究揭示了视觉感知系统中未被充分认识的物理层安全威胁，强调需要开发针对此类电磁注入攻击的鲁棒防御机制。

Abstract: Image sensors are integral to a wide range of safety- and security-critical
systems, including surveillance infrastructure, autonomous vehicles, and
industrial automation. These systems rely on the integrity of visual data to
make decisions. In this work, we investigate a novel class of electromagnetic
signal injection attacks that target the analog domain of image sensors,
allowing adversaries to manipulate raw visual inputs without triggering
conventional digital integrity checks. We uncover a previously undocumented
attack phenomenon on CMOS image sensors: rainbow-like color artifacts induced
in images captured by image sensors through carefully tuned electromagnetic
interference. We further evaluate the impact of these attacks on
state-of-the-art object detection models, showing that the injected artifacts
propagate through the image signal processing pipeline and lead to significant
mispredictions. Our findings highlight a critical and underexplored
vulnerability in the visual perception stack, highlighting the need for more
robust defenses against physical-layer attacks in such systems.

</details>


### [49] [Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking](https://arxiv.org/abs/2507.07871)
*Toluwani Aremu,Noor Hussein,Munachiso Nwadike,Samuele Poppi,Jie Zhang,Karthik Nandakumar,Neil Gong,Nils Lukas*

Main category: cs.CR

TL;DR: 本文提出一种多密钥扩展方法，用于防御生成式AI水印窃取攻击，通过理论保证和实证验证其有效性，并形式化定义了水印伪造威胁。


<details>
  <summary>Details</summary>
Motivation: 生成式AI提供商面临水印窃取攻击威胁，攻击者可能利用无害水印样本伪造有害内容。研究旨在不依赖具体水印技术的情况下缓解此类攻击。

Method: 提出黑盒条件下的多密钥扩展方案，可后置应用于任何模态的水印方法，通过安全博弈模型形式化定义伪造威胁。

Result: 实验证明该方法显著降低伪造成功率，理论分析表明多密钥机制能有效限制攻击者利用有限样本进行泛化的能力。

Conclusion: 多密钥扩展为生成式AI水印提供了可证明的安全增强，为防御伪造攻击建立了通用框架，未来可结合具体水印算法进一步优化。

Abstract: Watermarking offers a promising solution for GenAI providers to establish the
provenance of their generated content. A watermark is a hidden signal embedded
in the generated content, whose presence can later be verified using a secret
watermarking key. A threat to GenAI providers are \emph{watermark stealing}
attacks, where users forge a watermark into content that was \emph{not}
generated by the provider's models without access to the secret key, e.g., to
falsely accuse the provider. Stealing attacks collect \emph{harmless}
watermarked samples from the provider's model and aim to maximize the expected
success rate of generating \emph{harmful} watermarked samples. Our work focuses
on mitigating stealing attacks while treating the underlying watermark as a
black-box. Our contributions are: (i) Proposing a multi-key extension to
mitigate stealing attacks that can be applied post-hoc to any watermarking
method across any modality. (ii) We provide theoretical guarantees and
demonstrate empirically that our method makes forging substantially less
effective across multiple datasets, and (iii) we formally define the threat of
watermark forging as the task of generating harmful, watermarked content and
model this threat via security games.

</details>


### [50] [The Trust Fabric: Decentralized Interoperability and Economic Coordination for the Agentic Web](https://arxiv.org/abs/2507.07901)
*Sree Bhargavi Balija,Rekha Singal,Abhishek Singh,Ramesh Raskar,Erfan Darzi,Raghu Bala,Thomas Hardjono,Ken Huang*

Main category: cs.CR

TL;DR: 本文提出了Nanda统一架构，通过分布式注册、语义代理卡和动态信任层三大创新，解决了AI代理生态系统的互操作性、信任和经济协调问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理生态系统存在碎片化问题，现有协议（如MCP、A2A等）无法大规模满足互操作性、信任和经济协调的需求。

Method: 采用去中心化框架，结合快速DID代理发现、可验证凭证的语义代理卡、动态信任层，以及X42/H42微支付和MAESTRO安全框架。

Result: 实际部署显示，在医疗应用中达到99.9%的合规性，月交易量显著，且具备强大的隐私保障。

Conclusion: 该架构通过密码学证明和策略即代码，将代理转变为去中心化经济中的信任锚定参与者，实现了全球互操作的代理互联网。

Abstract: The fragmentation of AI agent ecosystems has created urgent demands for
interoperability, trust, and economic coordination that current protocols --
including MCP (Hou et al., 2025), A2A (Habler et al., 2025), ACP (Liu et al.,
2025), and Cisco's AGP (Edwards, 2025) -- cannot address at scale. We present
the Nanda Unified Architecture, a decentralized framework built around three
core innovations: fast DID-based agent discovery through distributed
registries, semantic agent cards with verifiable credentials and composability
profiles, and a dynamic trust layer that integrates behavioral attestations
with policy compliance. The system introduces X42/H42 micropayments for
economic coordination and MAESTRO, a security framework incorporating
Synergetics' patented AgentTalk protocol (US Patent 12,244,584 B1) and secure
containerization. Real-world deployments demonstrate 99.9 percent compliance in
healthcare applications and substantial monthly transaction volumes with strong
privacy guarantees. By unifying MIT's trust research with production
deployments from Cisco and Synergetics, we show how cryptographic proofs and
policy-as-code transform agents into trust-anchored participants in a
decentralized economy (Lakshmanan, 2025; Sha, 2025). The result enables a
globally interoperable Internet of Agents where trust becomes the native
currency of collaboration across both enterprise and Web3 ecosystems.

</details>


### [51] [Can Large Language Models Improve Phishing Defense? A Large-Scale Controlled Experiment on Warning Dialogue Explanations](https://arxiv.org/abs/2507.07916)
*Federico Maria Cau,Giuseppe Desolda,Francesco Greco,Lucio Davide Spano,Luca Viganò*

Main category: cs.CR

TL;DR: 研究评估大型语言模型（LLMs）生成钓鱼警告解释的能力，发现其效果可媲美人工编写，且能根据解释类型（特征型/反事实型）针对性降低钓鱼点击率或误报率。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击利用人类行为弱点突破技术防御，现有警告弹窗因解释模糊和内容静态导致效果有限，需探索LLMs生成清晰、可扩展解释的潜力。

Method: 开展750人用户实验，对比人工编写与Claude 3.5 Sonnet、Llama 3.3 70B生成的两种解释风格（特征型/反事实型）对点击率、信任度等指标的影响。

Result: LLMs生成的解释在降低钓鱼易感性上媲美人工，Claude表现最佳；特征型解释对真实钓鱼更有效，反事实型减少误报。工作量、性别等因素显著调节警告效果。

Conclusion: LLMs能自动生成符合人本价值的钓鱼警告解释，具备可扩展性和适应性，为网络安全提供新解决方案。

Abstract: Phishing has become a prominent risk in modern cybersecurity, often used to
bypass technological defences by exploiting predictable human behaviour.
Warning dialogues are a standard mitigation measure, but the lack of
explanatory clarity and static content limits their effectiveness. In this
paper, we report on our research to assess the capacity of Large Language
Models (LLMs) to generate clear, concise, and scalable explanations for
phishing warnings. We carried out a large-scale between-subjects user study (N
= 750) to compare the influence of warning dialogues supplemented with manually
generated explanations against those generated by two LLMs, Claude 3.5 Sonnet
and Llama 3.3 70B. We investigated two explanatory styles (feature-based and
counterfactual) for their effects on behavioural metrics (click-through rate)
and perceptual outcomes (e.g., trust, risk, clarity). The results indicate that
well-constructed LLM-generated explanations can equal or surpass manually
crafted explanations in reducing susceptibility to phishing; Claude-generated
warnings exhibited particularly robust performance. Feature-based explanations
were more effective for genuine phishing attempts, whereas counterfactual
explanations diminished false-positive rates. Other variables such as workload,
gender, and prior familiarity with warning dialogues significantly moderated
warning effectiveness. These results indicate that LLMs can be used to
automatically build explanations for warning users against phishing, and that
such solutions are scalable, adaptive, and consistent with human-centred
values.

</details>


### [52] [KeyDroid: A Large-Scale Analysis of Secure Key Storage in Android Apps](https://arxiv.org/abs/2507.07927)
*Jenny Blessing,Ross J. Anderson,Alastair R. Beresford*

Main category: cs.CR

TL;DR: 本研究首次全面调查了Android设备中硬件支持的密钥存储使用情况，发现超过半数处理敏感数据的应用未使用Android可信硬件功能，且仅有5.03%的应用采用了最高安全级别的安全元件。同时，研究首次实证分析了移动设备中可信硬件的性能表现。


<details>
  <summary>Details</summary>
Motivation: 尽管Android自2011年起通过Keystore API提供可信硬件支持，但业界对其实际采用情况与性能影响缺乏系统性研究。本研究旨在填补这一空白，评估开发者对硬件密钥存储的使用模式及其潜在性能代价。

Method: 分析了490,119个Android应用的使用模式，结合Google Play数据安全标签的开发者自报告数据。首次对可信硬件性能进行实证测量，比较软件密钥库与不同硬件安全等级（协处理器/安全元件）的加密操作运行时性能。

Result: 56.3%处理敏感数据的应用完全未使用可信硬件；仅5.03%采用独立安全元件。性能测试表明：协处理器级硬件密钥存储对多数加密操作可行，但能防御高级攻击的安全元件会导致对称加密（非微量数据）和非对称加密的性能不可行。

Conclusion: 当前Android可信硬件采用率严重不足，安全性与性能存在显著权衡。独立安全元件虽提供最强防护，但性能限制使其难以普及，这为移动安全生态系统的改进提供了明确方向。

Abstract: Most contemporary mobile devices offer hardware-backed storage for
cryptographic keys, user data, and other sensitive credentials. Such hardware
protects credentials from extraction by an adversary who has compromised the
main operating system, such as a malicious third-party app. Since 2011, Android
app developers can access trusted hardware via the Android Keystore API. In
this work, we conduct the first comprehensive survey of hardware-backed key
storage in Android devices. We analyze 490 119 Android apps, collecting data on
how trusted hardware is used by app developers (if used at all) and
cross-referencing our findings with sensitive user data collected by each app,
as self-reported by developers via the Play Store's data safety labels.
  We find that despite industry-wide initiatives to encourage adoption, 56.3%
of apps self-reporting as processing sensitive user data do not use Android's
trusted hardware capabilities at all, while just 5.03% of apps collecting some
form of sensitive data use the strongest form of trusted hardware, a secure
element distinct from the main processor. To better understand the potential
downsides of using secure hardware, we conduct the first empirical analysis of
trusted hardware performance in mobile devices, measuring the runtime of common
cryptographic operations across both software- and hardware-backed keystores.
We find that while hardware-backed key storage using a coprocessor is viable
for most common cryptographic operations, secure elements capable of preventing
more advanced attacks make performance infeasible for symmetric encryption with
non-negligible payloads and any kind of asymmetric encryption.

</details>


### [53] [EinHops: Einsum Notation for Expressive Homomorphic Operations on RNS-CKKS Tensors](https://arxiv.org/abs/2507.07972)
*Karthik Garimella,Austin Ebel,Brandon Reagen*

Main category: cs.CR

TL;DR: 本文提出EinHops系统，利用爱因斯坦求和（einsum）符号解决全同态加密（FHE）中多维张量运算的难题，通过显式编码维数结构和操作，实现简单、通用且可解释的加密张量运算。


<details>
  <summary>Details</summary>
Motivation: 全同态加密（FHE）仅支持一维向量的SIMD加法、乘法和循环旋转操作，多维张量运算需打包为一维向量，传统方法抽象层次过多，导致调试和优化困难。

Method: 采用爱因斯坦求和（einsum）符号显式编码张量结构和操作，将其分解为一组固定的FHE友好操作，开发了EinHops系统，实现加密张量运算并保持底层打包策略的透明性。

Result: EinHops在从简单转置到复杂多维收缩等多种张量操作上表现良好，验证了einsum符号的显式特性能够构建简单、通用且可解释的FHE张量系统。

Conclusion: EinHops通过einsum符号解决了FHE中多维张量运算的挑战，提供了透明且高效的解决方案，系统已开源。

Abstract: Fully Homomorphic Encryption (FHE) is an encryption scheme that allows for
computation to be performed directly on encrypted data, effectively closing the
loop on secure and outsourced computing. Data is encrypted not only during rest
and transit, but also during processing. However, FHE provides a limited
instruction set: SIMD addition, SIMD multiplication, and cyclic rotation of 1-D
vectors. This restriction makes performing multi-dimensional tensor operations
challenging. Practitioners must pack these tensors into 1-D vectors and map
tensor operations onto this one-dimensional layout rather than their
traditional nested structure. And while prior systems have made significant
strides in automating this process, they often hide critical packing decisions
behind layers of abstraction, making debugging, optimizing, and building on top
of these systems difficult.
  In this work, we approach multi-dimensional tensor operations in FHE through
Einstein summation (einsum) notation. Einsum notation explicitly encodes
dimensional structure and operations in its syntax, naturally exposing how
tensors should be packed and transformed. We decompose einsum expressions into
a fixed set of FHE-friendly operations. We implement our design and present
EinHops, a minimalist system that factors einsum expressions into a fixed
sequence of FHE operations. EinHops enables developers to perform encrypted
tensor operations using FHE while maintaining full visibility into the
underlying packing strategy. We evaluate EinHops on a range of tensor
operations from a simple transpose to complex multi-dimensional contractions.
We show that the explicit nature of einsum notation allows us to build an FHE
tensor system that is simple, general, and interpretable. We open-source
EinHops at the following repository: https://github.com/baahl-nyu/einhops.

</details>


### [54] [Defending Against Prompt Injection With a Few DefensiveTokens](https://arxiv.org/abs/2507.07974)
*Sizhe Chen,Yizhu Wang,Nicholas Carlini,Chawin Sitawarin,David Wagner*

Main category: cs.CR

TL;DR: 本文提出DefensiveToken方法，通过在LLM输入前插入特殊优化令牌，实现测试时灵活切换安全模式与高效模式，抵御提示注入攻击。


<details>
  <summary>Details</summary>
Motivation: 现有测试时防御（如防御性提示）效果远不如训练时调整模型参数的方法，但后者灵活性不足。需要一种既能提供接近训练时防御效果，又能灵活启用的测试时防御方案。

Method: 设计可插入的特殊DefensiveToken令牌，其嵌入向量经安全优化。开发者根据安全需求选择在LLM输入前添加（安全模式）或跳过（高效模式），模型本身无需修改。

Result: DefensiveToken在保持最小效用损失下提供接近SOTA的安全性。无需防御时，系统仍可生成高质量响应，实现安全性与效用的灵活平衡。

Conclusion: 该方法首次实现测试时防御达到接近训练时防御的效果，通过开源模型配套发布DefensiveToken，允许开发者按需切换安全等级。

Abstract: When large language model (LLM) systems interact with external data to
perform complex tasks, a new attack, namely prompt injection, becomes a
significant threat. By injecting instructions into the data accessed by the
system, the attacker is able to override the initial user task with an
arbitrary task directed by the attacker. To secure the system, test-time
defenses, e.g., defensive prompting, have been proposed for system developers
to attain security only when needed in a flexible manner. However, they are
much less effective than training-time defenses that change the model
parameters. Motivated by this, we propose DefensiveToken, a test-time defense
with prompt injection robustness comparable to training-time alternatives.
DefensiveTokens are newly inserted as special tokens, whose embeddings are
optimized for security. In security-sensitive cases, system developers can
append a few DefensiveTokens before the LLM input to achieve security with a
minimal utility drop. In scenarios where security is less of a concern,
developers can simply skip DefensiveTokens; the LLM system remains the same as
there is no defense, generating high-quality responses. Thus, DefensiveTokens,
if released alongside the model, allow a flexible switch between the
state-of-the-art (SOTA) utility and almost-SOTA security at test time. The code
is available at https://github.com/Sizhe-Chen/DefensiveToken.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [55] [Working with AI: Measuring the Occupational Implications of Generative AI](https://arxiv.org/abs/2507.07935)
*Kiran Tomlinson,Sonia Jaffe,Will Wang,Scott Counts,Siddharth Suri*

Main category: cs.AI

TL;DR: 研究分析了20万条用户与微软Bing Copilot的匿名对话，发现AI最常协助的工作活动是信息收集与写作，而AI自身最常执行的任务是提供信息、写作、教学和建议。通过计算各职业的AI适用性分数，发现知识型职业（如计算机、数学、行政支持）及销售类职业的AI适用性最高。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的快速普及及其对广泛任务的影响，理解AI对经济的影响成为社会最重要的问题之一。本研究旨在分析人们如何利用AI完成工作活动，以及AI在这些活动中的表现和影响范围。

Method: 研究分析了20万条用户与微软Bing Copilot的匿名对话数据，结合职业活动分类、任务成功率和影响范围测量，计算了各职业的AI适用性分数。

Result: AI最常协助的工作活动是信息收集与写作，而AI自身最常执行的任务是提供信息、写作、教学和建议。知识型职业（如计算机、数学、行政支持）及销售类职业的AI适用性分数最高。研究还探讨了工资、教育与AI适用性的相关性，以及实际使用与职业AI影响预测的对比。

Conclusion: 研究表明，AI在知识型职业和涉及信息沟通的职业中适用性最高。这为理解AI对经济的影响提供了重要依据，并揭示了AI在实际应用中的潜力与局限性。

Abstract: Given the rapid adoption of generative AI and its potential to impact a wide
range of tasks, understanding the effects of AI on the economy is one of
society's most important questions. In this work, we take a step toward that
goal by analyzing the work activities people do with AI, how successfully and
broadly those activities are done, and combine that with data on what
occupations do those activities. We analyze a dataset of 200k anonymized and
privacy-scrubbed conversations between users and Microsoft Bing Copilot, a
publicly available generative AI system. We find the most common work
activities people seek AI assistance for involve gathering information and
writing, while the most common activities that AI itself is performing are
providing information and assistance, writing, teaching, and advising.
Combining these activity classifications with measurements of task success and
scope of impact, we compute an AI applicability score for each occupation. We
find the highest AI applicability scores for knowledge work occupation groups
such as computer and mathematical, and office and administrative support, as
well as occupations such as sales whose work activities involve providing and
communicating information. Additionally, we characterize the types of work
activities performed most successfully, how wage and education correlate with
AI applicability, and how real-world usage compares to predictions of
occupational AI impact.

</details>


### [56] [Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation](https://arxiv.org/abs/2507.07115)
*Javal Vyas,Mehmet Mercangoz*

Main category: cs.AI

TL;DR: 本文提出了一种结合大型语言模型(LLM)与有限状态机(FSM)的统一智能体框架，用于化工过程的故障恢复规划与连续控制，在模拟和实际实验中均展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现代化工过程日益复杂，面临人力短缺和故障场景多样化挑战，需要融合符号推理与自适应控制的新型自动化范式。

Method: 采用FSM作为可解释操作边界：LLM规划代理通过FSM生成恢复序列，仿真代理执行状态转移验证，并通过验证-重提示循环迭代优化无效方案。

Result: 在180个随机FSM测试中GPT-4系列实现100%有效路径恢复；在温控实验中LLM控制器性能媲美传统PID，且提示循环对处理非线性动态至关重要。

Conclusion: 研究表明：通过结构化反馈和模块化智能体，LLM能统一高层符号规划与底层连续控制，为化工领域语言驱动自动化开辟了新路径。

Abstract: The increasing complexity of modern chemical processes, coupled with
workforce shortages and intricate fault scenarios, demands novel automation
paradigms that blend symbolic reasoning with adaptive control. In this work, we
introduce a unified agentic framework that leverages large language models
(LLMs) for both discrete fault-recovery planning and continuous process control
within a single architecture. We adopt Finite State Machines (FSMs) as
interpretable operating envelopes: an LLM-driven planning agent proposes
recovery sequences through the FSM, a Simulation Agent executes and checks each
transition, and a Validator-Reprompting loop iteratively refines invalid plans.
In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25
states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path
success within five reprompts-outperforming open-source LLMs in both accuracy
and latency. In Case Study 2, the same framework modulates dual-heater inputs
on a laboratory TCLab platform (and its digital twin) to maintain a target
average temperature under persistent asymmetric disturbances. Compared to
classical PID control, our LLM-based controller attains similar performance,
while ablation of the prompting loop reveals its critical role in handling
nonlinear dynamics. We analyze key failure modes-such as instruction following
lapses and coarse ODE approximations. Our results demonstrate that, with
structured feedback and modular agents, LLMs can unify high-level symbolic
planningand low-level continuous control, paving the way towards resilient,
language-driven automation in chemical engineering.

</details>


### [57] [BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks](https://arxiv.org/abs/2507.07134)
*Mridula Vijendran,Shuang Chen,Jingjing Deng,Hubert P. H. Shum*

Main category: cs.AI

TL;DR: 本文提出了一种名为BOOST的新型OOD感知模型偏差自适应采样方法，旨在解决AI绘画分类中的偏见问题。该方法通过动态调整温度缩放和采样概率，提升模型在艺术领域的公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: AI绘画分类中存在的偏见问题日益严重，尤其是在艺术策展和修复等任务中。偏见主要源于数据集不平衡，导致模型对罕见绘画风格的分类准确性下降。现有研究大多忽视了这一关键问题，特别是在处理分布外（OOD）数据时。

Method: 我们提出了BOOST方法，通过动态调整温度缩放和采样概率，实现更均衡的类别表示。此外，还提出了一种新指标SODC，用于评估类别间分离度和每类偏见的减少程度。

Result: 在KaoKore和PACS数据集上的实验表明，BOOST能够有效减少类别偏见，同时保持高性能，实现了公平性与准确性的平衡。

Conclusion: BOOST为艺术领域AI模型的去偏见化提供了一种鲁棒的解决方案，能够在保持高性能的同时提升公平性。

Abstract: The pervasive issue of bias in AI presents a significant challenge to
painting classification, and is getting more serious as these systems become
increasingly integrated into tasks like art curation and restoration. Biases,
often arising from imbalanced datasets where certain artistic styles dominate,
compromise the fairness and accuracy of model predictions, i.e., classifiers
are less accurate on rarely seen paintings. While prior research has made
strides in improving classification performance, it has largely overlooked the
critical need to address these underlying biases, that is, when dealing with
out-of-distribution (OOD) data. Our insight highlights the necessity of a more
robust approach to bias mitigation in AI models for art classification on
biased training data. We propose a novel OOD-informed model bias adaptive
sampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It
addresses these challenges by dynamically adjusting temperature scaling and
sampling probabilities, thereby promoting a more equitable representation of
all classes. We evaluate our proposed approach to the KaoKore and PACS
datasets, focusing on the model's ability to reduce class-wise bias. We further
propose a new metric, Same-Dataset OOD Detection Score (SODC), designed to
assess class-wise separation and per-class bias reduction. Our method
demonstrates the ability to balance high performance with fairness, making it a
robust solution for unbiasing AI models in the art domain.

</details>


### [58] [State-Inference-Based Prompting for Natural Language Trading with Game NPCs](https://arxiv.org/abs/2507.07203)
*Minkyung Kim,Junsik Kim,Hwidong Bae,Woongcheol Yang,Sangdon Park,Sohee Bae*

Main category: cs.AI

TL;DR: 论文提出状态推断提示法(SIBP)，通过自主对话状态推断和情境化规则遵循，解决大语言模型在规则化交易系统中的可靠性问题，实现97%以上的状态合规性和99.7%的计算精度。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在规则化交易系统中存在物品幻觉和计算错误等违规行为，导致玩家信任度下降。需要一种可靠方法确保NPC交互的可信度。

Method: 采用状态推断提示法(SIBP)，将交易分解为六个状态，构建统一提示框架，实现情境感知的物品引用和占位符价格计算。

Result: 在100组交易对话测试中，状态合规率>97%，引用准确率>95%，计算精度达99.7%，计算效率优于基线方法。

Conclusion: SIBP方法为商业游戏中可信NPC交互提供了实用基础，在保持计算效率的同时显著提升规则遵循能力。

Abstract: Large Language Models enable dynamic game interactions but struggle with
rule-governed trading systems. Current implementations suffer from rule
violations, such as item hallucinations and calculation errors, that erode
player trust. Here, State-Inference-Based Prompting (SIBP) enables reliable
trading through autonomous dialogue state inference and context-specific rule
adherence. The approach decomposes trading into six states within a unified
prompt framework, implementing context-aware item referencing and
placeholder-based price calculations. Evaluation across 100 trading dialogues
demonstrates >97% state compliance, >95% referencing accuracy, and 99.7%
calculation precision. SIBP maintains computational efficiency while
outperforming baseline approaches, establishing a practical foundation for
trustworthy NPC interactions in commercial games.

</details>


### [59] [Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains](https://arxiv.org/abs/2507.07217)
*Zili Wang,Frank Montabon,Kristin Yvonne Rozier*

Main category: cs.AI

TL;DR: 本文探讨了使用神经符号方法检测供应链中的非法活动，比较了人工与自动特征提取的效果，并提出了基于大型语言模型的问题树方法以系统性评估新闻文章的相关性。


<details>
  <summary>Details</summary>
Motivation: 供应链网络复杂且涉及非法活动（如假冒零件、强迫劳动）时数据稀疏且不可靠，传统机器学习方法需要大量训练数据，难以应对此类问题。

Method: 采用神经符号方法，结合人工与自动特征提取，提出基于大型语言模型（LLM）的问题树方法，系统性评估新闻文章与强迫劳动的相关性。

Result: 研究表明，问题树方法能有效识别和量化新闻文章的相关性，揭示了人工与机器分类在供应链强迫劳动新闻中的差异。

Conclusion: 神经符号方法与LLM结合的问题树为稀疏且不可靠数据下的非法供应链活动检测提供了新途径，未来可进一步优化自动化特征提取。

Abstract: Supply chain networks are complex systems that are challenging to analyze;
this problem is exacerbated when there are illicit activities involved in the
supply chain, such as counterfeit parts, forced labor, or human trafficking.
While machine learning (ML) can find patterns in complex systems like supply
chains, traditional ML techniques require large training data sets. However,
illicit supply chains are characterized by very sparse data, and the data that
is available is often (purposely) corrupted or unreliable in order to hide the
nature of the activities. We need to be able to automatically detect new
patterns that correlate with such illegal activity over complex, even temporal
data, without requiring large training data sets. We explore neurosymbolic
methods for identifying instances of illicit activity in supply chains and
compare the effectiveness of manual and automated feature extraction from news
articles accurately describing illicit activities uncovered by authorities. We
propose a question tree approach for querying a large language model (LLM) to
identify and quantify the relevance of articles. This enables a systematic
evaluation of the differences between human and machine classification of news
articles related to forced labor in supply chains.

</details>


### [60] [Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery](https://arxiv.org/abs/2507.07257)
*Licong Xu,Milind Sarkar,Anto I. Lonappan,Íñigo Zubeldia,Pablo Villanueva-Domingo,Santiago Casas,Christian Fidler,Chetana Amancharla,Ujjwal Tiwari,Adrian Bayer,Chadi Ait Ekiou,Miles Cranmer,Adrian Dimitrov,James Fergusson,Kahaan Gandhi,Sven Krippendorf,Andrew Laverick,Julien Lesgourgues,Antony Lewis,Thomas Meier,Blake Sherwin,Kristen Surrao,Francisco Villaescusa-Navarro,Chi Wang,Xueqing Xu,Boris Bolliet*

Main category: cs.AI

TL;DR: 本文介绍了名为cmbagent的多智能体系统，该系统由约30个大型语言模型（LLM）智能体组成，采用规划与控制策略协调工作流，无需人工干预，成功应用于宇宙学博士级任务。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个全自动的多智能体系统，以执行复杂的科学研究任务，减少人工干预，提高研究效率。

Method: 系统由约30个LLM智能体组成，每个智能体专精不同任务（如检索科学论文与代码库、编写代码、解释结果、评估其他智能体输出），并采用规划与控制策略协调工作流，支持本地代码执行。

Result: 系统成功应用于宇宙学博士级任务（利用超新星数据测量宇宙学参数），在两组基准测试中表现优于当前最先进的LLM模型。源代码已开源，演示视频和云端部署也已提供。

Conclusion: cmbagent展示了多智能体系统在自动化科学研究任务中的潜力，其无人工干预的工作流和卓越性能为未来研究自动化提供了新方向。

Abstract: We present a multi-agent system for automation of scientific research tasks,
cmbagent. The system is formed by about 30 Large Language Model (LLM) agents
and implements a Planning & Control strategy to orchestrate the agentic
workflow, with no human-in-the-loop at any point. Each agent specializes in a
different task (performing retrieval on scientific papers and codebases,
writing code, interpreting results, critiquing the output of other agents) and
the system is able to execute code locally. We successfully apply cmbagent to
carry out a PhD level cosmology task (the measurement of cosmological
parameters using supernova data) and evaluate its performance on two benchmark
sets, finding superior performance over state-of-the-art LLMs. The source code
is available on GitHub, demonstration videos are also available, and the system
is deployed on HuggingFace and will be available on the cloud.

</details>


### [61] [Application of LLMs to Multi-Robot Path Planning and Task Allocation](https://arxiv.org/abs/2507.07302)
*Ashish Kumar*

Main category: cs.AI

TL;DR: 本文研究了在多智能体强化学习中，利用大型语言模型作为专家规划器进行高效探索的方法。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中的高效探索是一个复杂且具有挑战性的问题，需要新的方法来解决。

Method: 通过将大型语言模型作为专家规划器，应用于基于规划的任务中，以提升多智能体的探索效率。

Result: 研究表明，大型语言模型可以作为有效的专家规划器，帮助多智能体在复杂环境中进行高效探索。

Conclusion: 利用大型语言模型作为专家规划器，为多智能体强化学习中的高效探索问题提供了新的解决方案。

Abstract: Efficient exploration is a well known problem in deep reinforcement learning
and this problem is exacerbated in multi-agent reinforcement learning due the
intrinsic complexities of such algorithms. There are several approaches to
efficiently explore an environment to learn to solve tasks by multi-agent
operating in that environment, of which, the idea of expert exploration is
investigated in this work. More specifically, this work investigates the
application of large-language models as expert planners for efficient
exploration in planning based tasks for multiple agents.

</details>


### [62] [ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning](https://arxiv.org/abs/2507.07306)
*Yichen Lu,Wei Dai,Jiaen Liu,Ching Wing Kwok,Zongheng Wu,Xudong Xiao,Ao Sun,Sheng Fu,Jianyuan Zhan,Yian Wang,Takatomo Saito,Sicheng Lai*

Main category: cs.AI

TL;DR: 本文提出ViDove多模态翻译系统，通过整合视觉与上下文信息提升翻译质量，在字幕生成和通用翻译任务中显著优于现有方法，并发布DoveBench新基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有LLM翻译代理仅支持文本输入，无法利用视觉背景信息。受人类翻译流程启发，ViDove旨在通过多模态输入解决这一局限。

Method: 系统融合多模态记忆模块与长短时记忆机制，结合领域知识增强模型对真实场景的适应能力，模仿人类译者利用视觉线索的工作流程。

Result: ViDove在BLEU分数上提升28%，SubER指标提升15%，并构建包含17小时人工标注数据的DoveBench视频字幕翻译基准。

Conclusion: ViDove证明了多模态信息对翻译质量的重要价值，其开源代码与基准数据集将推动视频翻译领域研究发展。

Abstract: LLM-based translation agents have achieved highly human-like translation
results and are capable of handling longer and more complex contexts with
greater efficiency. However, they are typically limited to text-only inputs. In
this paper, we introduce ViDove, a translation agent system designed for
multimodal input. Inspired by the workflow of human translators, ViDove
leverages visual and contextual background information to enhance the
translation process. Additionally, we integrate a multimodal memory system and
long-short term memory modules enriched with domain-specific knowledge,
enabling the agent to perform more accurately and adaptively in real-world
scenarios. As a result, ViDove achieves significantly higher translation
quality in both subtitle generation and general translation tasks, with a 28%
improvement in BLEU scores and a 15% improvement in SubER compared to previous
state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark
for long-form automatic video subtitling and translation, featuring 17 hours of
high-quality, human-annotated data. Our code is available here:
https://github.com/pigeonai-org/ViDove

</details>


### [63] [On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment](https://arxiv.org/abs/2507.07341)
*Sarah Ball,Greg Gluch,Shafi Goldwasser,Frauke Kreuter,Omer Reingold,Guy N. Rothblum*

Main category: cs.AI

TL;DR: 研究发现，在大型语言模型（LLMs）中，外部过滤机制（输入提示过滤和输出过滤）存在计算障碍，无法有效阻止有害内容生成。安全对齐需依赖模型内部设计，而非黑盒访问。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的广泛应用，其可能被滥用于生成有害内容的风险引发关注。本研究旨在探讨通过外部过滤机制实现安全对齐的计算可行性。

Method: 研究通过理论分析证明：1) 存在无法被高效过滤器识别的对抗性提示；2) 在特定场景下输出过滤具有计算不可行性。所有结论均基于密码学硬度假设。

Result: 核心发现：1) 对某些LLMs不存在高效的提示过滤器；2) 输出过滤在自然场景下具有计算复杂性。放松的缓解方案同样面临计算障碍。

Conclusion: 仅通过外部过滤无法实现LLMs的安全对齐，必须整合模型内部架构与参数设计。研究主张AI系统的智能与判断能力不可分割。

Abstract: With the increased deployment of large language models (LLMs), one concern is
their potential misuse for generating harmful content. Our work studies the
alignment challenge, with a focus on filters to prevent the generation of
unsafe information. Two natural points of intervention are the filtering of the
input prompt before it reaches the model, and filtering the output after
generation. Our main results demonstrate computational challenges in filtering
both prompts and outputs. First, we show that there exist LLMs for which there
are no efficient prompt filters: adversarial prompts that elicit harmful
behavior can be easily constructed, which are computationally indistinguishable
from benign prompts for any efficient filter. Our second main result identifies
a natural setting in which output filtering is computationally intractable. All
of our separation results are under cryptographic hardness assumptions. In
addition to these core findings, we also formalize and study relaxed mitigation
approaches, demonstrating further computational barriers. We conclude that
safety cannot be achieved by designing filters external to the LLM internals
(architecture and weights); in particular, black-box access to the LLM will not
suffice. Based on our technical results, we argue that an aligned AI system's
intelligence cannot be separated from its judgment.

</details>


### [64] [Supply Chain Optimization via Generative Simulation and Iterative Decision Policies](https://arxiv.org/abs/2507.07355)
*Haoyue Bai,Haoyu Wang,Nanxu Gong,Xinyuan Wang,Wangyang Ying,Haifeng Chen,Yanjie Fu*

Main category: cs.AI

TL;DR: 提出Sim-to-Dec框架，结合生成模拟与双感知决策模型，显著提升供应链运输的时效性与利润。


<details>
  <summary>Details</summary>
Motivation: 供应链运输需兼顾高响应性与经济效益，而运输模式策略直接影响这两项目标。现有方法缺乏通用性、动态细节刻画及历史与预测的融合。

Method: Sim-to-Dec框架包含：1) 自回归生成模拟模块，减少领域规则依赖并增强数据波动鲁棒性；2) 历史-未来双感知决策模型，通过端到端优化迭代改进。

Result: 在三个真实数据集上的实验表明，该框架显著提高了准时交付率和利润。

Conclusion: Sim-to-Dec通过紧密耦合模拟反馈与策略优化，为运输策略设计提供了通用、动态且数据驱动的新范式。

Abstract: High responsiveness and economic efficiency are critical objectives in supply
chain transportation, both of which are influenced by strategic decisions on
shipping mode. An integrated framework combining an efficient simulator with an
intelligent decision-making algorithm can provide an observable, low-risk
environment for transportation strategy design. An ideal simulation-decision
framework must (1) generalize effectively across various settings, (2) reflect
fine-grained transportation dynamics, (3) integrate historical experience with
predictive insights, and (4) maintain tight integration between simulation
feedback and policy refinement. We propose Sim-to-Dec framework to satisfy
these requirements. Specifically, Sim-to-Dec consists of a generative
simulation module, which leverages autoregressive modeling to simulate
continuous state changes, reducing dependence on handcrafted domain-specific
rules and enhancing robustness against data fluctuations; and a history-future
dual-aware decision model, refined iteratively through end-to-end optimization
with simulator interactions. Extensive experiments conducted on three
real-world datasets demonstrate that Sim-to-Dec significantly improves timely
delivery rates and profit.

</details>


### [65] [DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search](https://arxiv.org/abs/2507.07426)
*Zerui Yang,Yuwei Wan,Yinqiao Li,Yudai Matsuda,Tong Xie,Linqi Song*

Main category: cs.AI

TL;DR: 提出DrugMCTS框架，结合RAG、多智能体协作与蒙特卡洛树搜索，无需微调即可在药物重定向任务中显著提升大型语言模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在科学领域（如药物发现）的推理能力受限于预训练知识范围，传统方法存在计算开销大或无法充分利用结构化科学数据的缺陷。

Method: 通过五个专业智能体检索分析分子与蛋白质信息，整合RAG、多智能体协作和蒙特卡洛树搜索，实现结构化迭代推理。

Result: 在DrugBank和KIBA数据集上，DrugMCTS使Qwen2.5-7B-Instruct模型性能超越Deepseek-R1达20\%，召回率与鲁棒性显著优于通用LLM及深度学习基线。

Conclusion: 结构化推理、智能体协作及反馈驱动搜索机制对推进LLM在药物发现中的应用至关重要。

Abstract: Recent advances in large language models have demonstrated considerable
potential in scientific domains such as drug discovery. However, their
effectiveness remains constrained when reasoning extends beyond the knowledge
acquired during pretraining. Conventional approaches, such as fine-tuning or
retrieval-augmented generation, face limitations in either imposing high
computational overhead or failing to fully exploit structured scientific data.
To overcome these challenges, we propose DrugMCTS, a novel framework that
synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree
Search for drug repurposing. The framework employs five specialized agents
tasked with retrieving and analyzing molecular and protein information, thereby
enabling structured and iterative reasoning. Without requiring domain-specific
fine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by
over 20\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate
that DrugMCTS achieves substantially higher recall and robustness compared to
both general-purpose LLMs and deep learning baselines. Our results highlight
the importance of structured reasoning, agent-based collaboration, and
feedback-driven search mechanisms in advancing LLM applications for drug
discovery.

</details>


### [66] [StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley](https://arxiv.org/abs/2507.07445)
*Weihao Tan,Changjiu Jiang,Yu Duan,Mingcong Lei,Jiageng Li,Yitian Hong,Xinrun Wang,Bo An*

Main category: cs.AI

TL;DR: StarDojo是一个基于《星露谷物语》的新型基准测试，旨在评估AI代理在开放式生产生活模拟中的综合能力，包含1000个跨五大领域的任务，当前最先进的MLLM代理成功率仅12.7%。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试鲜少同时评估生产活动与社会交互能力，而人类社会中的自主代理需掌握这两种技能。

Method: 基于《星露谷物语》构建包含1000个任务的基准测试（含100个核心任务），涵盖耕种、制造、探索、战斗和社交五大领域，提供统一接口支持多实例并行运行。

Result: 最佳模型GPT-4.1成功率仅12.7%，主要受限于视觉理解、多模态推理和底层操作能力。

Conclusion: StarDojo作为用户友好的复杂环境基准，将推动开放式代理在生产和生活场景中的鲁棒性研究。

Abstract: Autonomous agents navigating human society must master both production
activities and social interactions, yet existing benchmarks rarely evaluate
these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel
benchmark based on Stardew Valley, designed to assess AI agents in open-ended
production-living simulations. In StarDojo, agents are tasked to perform
essential livelihood activities such as farming and crafting, while
simultaneously engaging in social interactions to establish relationships
within a vibrant community. StarDojo features 1,000 meticulously curated tasks
across five key domains: farming, crafting, exploration, combat, and social
interactions. Additionally, we provide a compact subset of 100 representative
tasks for efficient model evaluation. The benchmark offers a unified,
user-friendly interface that eliminates the need for keyboard and mouse
control, supports all major operating systems, and enables the parallel
execution of multiple environment instances, making it particularly well-suited
for evaluating the most capable foundation agents, powered by multimodal large
language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents
demonstrate substantial limitations, with the best-performing model, GPT-4.1,
achieving only a 12.7% success rate, primarily due to challenges in visual
understanding, multimodal reasoning and low-level manipulation. As a
user-friendly environment and benchmark, StarDojo aims to facilitate further
research towards robust, open-ended agents in complex production-living
environments.

</details>


### [67] [Position: We Need An Algorithmic Understanding of Generative AI](https://arxiv.org/abs/2507.07544)
*Oliver Eberle,Thomas McGee,Hamza Giaffar,Taylor Webb,Ida Momennejad*

Main category: cs.AI

TL;DR: 本文提出AlgEval框架，旨在系统研究大语言模型（LLM）学习与使用的算法，通过案例研究揭示其内部计算机制，为可解释性与高效训练提供新路径。


<details>
  <summary>Details</summary>
Motivation: 当前研究多关注通过规模提升LLM性能，缺乏对其学习算法的理论理解。AlgEval试图填补这一空白，探究模型隐含的算法原语及其组合方式。

Method: 结合自上而下的算法假设与自下而上的电路分析（注意力模式、隐藏状态），以涌现的搜索算法为案例验证框架可行性。

Result: 案例研究表明，通过系统评估LLM的任务解决机制，可替代资源密集型扩展，转向对底层计算的原则性理解。

Conclusion: 算法解释性提供人类可理解的模型推理路径，有望催生高效训练方法、新型架构及多智能体系统设计。

Abstract: What algorithms do LLMs actually learn and use to solve problems? Studies
addressing this question are sparse, as research priorities are focused on
improving performance through scale, leaving a theoretical and empirical gap in
understanding emergent algorithms. This position paper proposes AlgEval: a
framework for systematic research into the algorithms that LLMs learn and use.
AlgEval aims to uncover algorithmic primitives, reflected in latent
representations, attention, and inference-time compute, and their algorithmic
composition to solve task-specific problems. We highlight potential
methodological paths and a case study toward this goal, focusing on emergent
search algorithms. Our case study illustrates both the formation of top-down
hypotheses about candidate algorithms, and bottom-up tests of these hypotheses
via circuit-level analysis of attention patterns and hidden states. The
rigorous, systematic evaluation of how LLMs actually solve tasks provides an
alternative to resource-intensive scaling, reorienting the field toward a
principled understanding of underlying computations. Such algorithmic
explanations offer a pathway to human-understandable interpretability, enabling
comprehension of the model's internal reasoning performance measures. This can
in turn lead to more sample-efficient methods for training and improving
performance, as well as novel architectures for end-to-end and multi-agent
systems.

</details>


### [68] [On Trustworthy Rule-Based Models and Explanations](https://arxiv.org/abs/2507.07576)
*Mohamed Siala,Jordi Planes,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本文探讨了机器学习模型中解释预测的重要性，特别是在高风险领域，指出了基于规则的模型存在的负面特征，并提出了分析这些特征的算法。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域，机器学习模型的解释必须严谨，错误的解释会误导人类决策者。尽管可解释性是一个难以捉摸的概念，但基于规则的可解释模型仍被广泛使用。

Method: 本文开发了算法来分析基于规则的机器学习模型中存在的负面特征，如负重叠和冗余。

Result: 研究发现，广泛使用的基于规则的学习工具会导致规则集表现出一种或多种负面特征。

Conclusion: 基于规则的机器学习模型在高风险应用中存在负面特征，需要更严谨的分析和改进。

Abstract: A task of interest in machine learning (ML) is that of ascribing explanations
to the predictions made by ML models. Furthermore, in domains deemed high risk,
the rigor of explanations is paramount. Indeed, incorrect explanations can and
will mislead human decision makers. As a result, and even if interpretability
is acknowledged as an elusive concept, so-called interpretable models are
employed ubiquitously in high-risk uses of ML and data mining (DM). This is the
case for rule-based ML models, which encompass decision trees, diagrams, sets
and lists. This paper relates explanations with well-known undesired facets of
rule-based ML models, which include negative overlap and several forms of
redundancy. The paper develops algorithms for the analysis of these undesired
facets of rule-based systems, and concludes that well-known and widely used
tools for learning rule-based ML models will induce rule sets that exhibit one
or more negative facets.

</details>


### [69] [Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs](https://arxiv.org/abs/2507.07595)
*Zhixiang Su,Di Wang,Chunyan Miao*

Main category: cs.AI

TL;DR: 本文提出了一种名为Context Pooling的新方法，用于提升基于图神经网络（GNN）的知识图谱（KG）链接预测模型性能。该方法首次在KG中应用图池化，并能在归纳设置中生成查询特定的图。通过设计两种度量标准（邻域精度和邻域召回率），该方法能筛选逻辑相关的邻居进行链接预测，在多个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，基于GNN的知识图谱链接预测模型中，传统的聚合方法对性能提升有限。因此，需要一种新方法来更有效地利用图结构信息，特别是在归纳设置中处理未见过的实体。

Method: 提出Context Pooling方法，首次在KG中应用图池化技术。设计了邻域精度和邻域召回率两种度量标准，用于评估邻居节点与查询的逻辑相关性，从而筛选出最相关的邻居节点进行链接预测。该方法具有通用性，可应用于不同的SOTA模型。

Result: 在三个公开的转导和归纳数据集上，将Context Pooling应用于两种SOTA模型后，在48种设置中的42种实现了最先进的性能表现。

Conclusion: Context Pooling是一种有效的KG链接预测增强方法，特别是在归纳设置中。通过选择性地聚合逻辑相关的邻居信息，该方法显著提升了模型性能，为KG链接预测领域提供了新的技术方向。

Abstract: Recent investigations on the effectiveness of Graph Neural Network
(GNN)-based models for link prediction in Knowledge Graphs (KGs) show that
vanilla aggregation does not significantly impact the model performance. In
this paper, we introduce a novel method, named Context Pooling, to enhance
GNN-based models' efficacy for link predictions in KGs. To our best of
knowledge, Context Pooling is the first methodology that applies graph pooling
in KGs. Additionally, Context Pooling is first-of-its-kind to enable the
generation of query-specific graphs for inductive settings, where testing
entities are unseen during training. Specifically, we devise two metrics,
namely neighborhood precision and neighborhood recall, to assess the neighbors'
logical relevance regarding the given queries, thereby enabling the subsequent
comprehensive identification of only the logically relevant neighbors for link
prediction. Our method is generic and assessed by being applied to two
state-of-the-art (SOTA) models on three public transductive and inductive
datasets, achieving SOTA performance in 42 out of 48 settings.

</details>


### [70] [Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.07599)
*Sedigh Khademi,Jim Black,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila*

Main category: cs.AI

TL;DR: 本研究评估了微调Llama 3.2模型从急诊分诊记录中提取疫苗相关信息的能力，以支持近实时疫苗安全监测。微调的30亿参数Llama模型在疫苗名称提取准确率上优于其他方法，模型量化技术实现了资源受限环境的高效部署。


<details>
  <summary>Details</summary>
Motivation: 开发自动化工具从急诊记录中提取疫苗数据，以提升疫苗安全监测效率并早期发现免疫接种后不良事件。

Method: 采用提示工程创建标注数据集并经人工确认，对比了提示工程模型、微调模型与基于规则方法的性能，并对模型进行量化处理。

Result: 微调Llama 3（30亿参数）模型在疫苗名称提取准确率上表现最优，量化后模型可在资源有限环境中有效运行。

Conclusion: 大语言模型能有效自动化急诊记录数据提取，为疫苗安全监测及免疫接种不良事件早期识别提供技术支持。

Abstract: This study evaluates fine-tuned Llama 3.2 models for extracting
vaccine-related information from emergency department triage notes to support
near real-time vaccine safety surveillance. Prompt engineering was used to
initially create a labeled dataset, which was then confirmed by human
annotators. The performance of prompt-engineered models, fine-tuned models, and
a rule-based approach was compared. The fine-tuned Llama 3 billion parameter
model outperformed other models in its accuracy of extracting vaccine names.
Model quantization enabled efficient deployment in resource-constrained
environments. Findings demonstrate the potential of large language models in
automating data extraction from emergency department notes, supporting
efficient vaccine safety surveillance and early detection of emerging adverse
events following immunization issues.

</details>


### [71] [Towards conservative inference in credal networks using belief functions: the case of credal chains](https://arxiv.org/abs/2507.07619)
*Marco Sangalli,Thomas Krak,Cassio de Campos*

Main category: cs.AI

TL;DR: 本文基于Dempster-Shafer理论，提出了一种在信用网络（特别是链状结构）中进行信念推断的新框架，通过信念和似然函数高效生成保守区间，结合了计算速度与鲁棒的不确定性表示。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于扩展信用网络中的不确定性传播方法，特别是在链状子类中，以提供更高效的信念推断框架，并与传统的敏感性分析方法进行比较。

Method: 方法包括基于Dempster-Shafer理论的信念推断方法的形式化，以及通过信念和似然函数在链状信用网络中传播不确定性的新框架。

Result: 数值结果展示了信念推断框架的优势和局限性，特别是在链状结构中的实际应用效果，为信用网络的普遍应用提供了实用见解。

Conclusion: 结论指出，所提出的信念推断框架在链状信用网络中具有实际效用，同时也揭示了其在更广泛信用网络中的应用潜力和限制。

Abstract: This paper explores belief inference in credal networks using Dempster-Shafer
theory. By building on previous work, we propose a novel framework for
propagating uncertainty through a subclass of credal networks, namely chains.
The proposed approach efficiently yields conservative intervals through belief
and plausibility functions, combining computational speed with robust
uncertainty representation. Key contributions include formalizing belief-based
inference methods and comparing belief-based inference against classical
sensitivity analysis. Numerical results highlight the advantages and
limitations of applying belief inference within this framework, providing
insights into its practical utility for chains and for credal networks in
general.

</details>


### [72] [PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations](https://arxiv.org/abs/2507.07644)
*Fedor Rodionov,Abdelrahman Eldesokey,Michael Birsak,John Femiani,Bernard Ghanem,Peter Wonka*

Main category: cs.AI

TL;DR: PlanQA是一个用于评估大语言模型（LLMs）几何与空间推理能力的诊断基准，基于结构化室内场景表示设计，揭示当前LLMs在真实空间布局推理上的明显不足。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在几何与空间推理方面存在盲点，PlanQA旨在通过结构化场景表示和多样化问题类型，系统评估模型在此领域的表现。

Method: 通过符号化格式（如JSON/XML）编码厨房、客厅等室内场景布局，设计涵盖度量推理、拓扑关系及设计约束（如可达性、平衡性）的多样化问题。

Result: 实验表明，尽管部分模型能处理简单查询，但在模拟物理约束、保持空间一致性及布局扰动泛化方面普遍失败。

Conclusion: PlanQA揭示了现有LLMs在真实空间推理上的缺陷，呼吁开发能准确处理实际场景几何属性的新型语言模型。

Abstract: We introduce PlanQA, a diagnostic benchmark for evaluating geometric and
spatial reasoning in large-language models (LLMs). PlanQA is grounded in
structured representations of indoor scenes, such as kitchens, living rooms,
and bedrooms, encoded in a symbolic format (e.g., JSON, XML layouts). The
benchmark includes diverse question types that test not only metric and
topological reasoning (e.g., distance, visibility, shortest paths) but also
interior design constraints such as affordance, clearance, balance, and
usability. Our results across a variety of frontier open-source and commercial
LLMs show that while models may succeed in shallow queries, they often fail to
simulate physical constraints, preserve spatial coherence, or generalize under
layout perturbation. PlanQA uncovers a clear blind spot in today's LLMs: they
do not consistently reason about real-world layouts. We hope that this
benchmark inspires new work on language models that can accurately infer and
manipulate spatial and geometric properties in practical settings.

</details>


### [73] [Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization](https://arxiv.org/abs/2507.07723)
*Chengtao Jian,Kai Yang,Ye Ouyang,Xiaozhou Ye*

Main category: cs.AI

TL;DR: 本文分析了直接偏好优化(DPO)的理论缺陷，提出了一种稳定的双层优化框架，通过正则化方法改进偏好对齐效果。


<details>
  <summary>Details</summary>
Motivation: DPO虽被广泛用于语言模型与人类偏好的对齐，但其理论特性和内在局限性尚未充分探索。研究发现DPO对初始化敏感且易导致概率质量分配错误，可能强化模型偏见。

Method: 提出基于双层优化的稳定偏好优化框架，将监督微调与改进的DPO目标结合，采用原则性正则化方案确保偏好输出的绝对概率提升。

Result: 在推理和摘要任务上的实验表明，该方法持续提升推理准确性，输出分布更符合预期偏好，性能优于标准DPO。

Conclusion: 稳定偏好优化为偏好对齐目标设计提供了新思路，开辟了实现更可靠、可解释语言模型对齐的新途径。

Abstract: Direct Preference Optimization (DPO) has emerged as a popular and efficient
alternative to reward modeling and reinforcement learning for aligning language
models with human preferences. Despite its empirical success, the theoretical
properties and intrinsic limitations of DPO remain underexplored. In this work,
we first present a comprehensive analysis of DPO's dynamics from a probability
evolution perspective. Our analysis reveals that DPO is highly sensitive to
initialization. It also tends to misallocate probability mass, which can
inadvertently shift probability toward irrelevant or undesired responses. This
misallocation may unintentionally reinforce model bias, thereby compromising
both the stability of model alignment and the consistency with intended
preferences. Motivated by these theoretical findings, we propose a
theoretically grounded bilevel optimization framework that tightly integrate
supervised fine-tuning with an enhanced DPO objective a.k.a. stable preference
optimization. Our approach introduces a principled regularization scheme to
explicitly encourage absolute probability improvement for preferred outputs,
while maintaining stable optimization dynamics. Experiments on challenging
reasoning and summarization benchmarks elucidate that our method consistently
improves reasoning accuracy and better aligns output distributions with
intended preferences, outperforming standard DPO. Stable preference
optimization provides new insights into the design of preference-based
alignment objectives and opens up new avenues towards more reliable and
interpretable language model alignment.

</details>


### [74] [Identification of Violin Reduction via Contour Lines Classification](https://arxiv.org/abs/2507.07743)
*Philémon Beghin,Anne-Emmanuelle Ceulemans,François Glineur*

Main category: cs.AI

TL;DR: 本文提出了一种基于轮廓线特征的小提琴尺寸缩减分类方法，通过分析25把乐器的3D几何网格数据，发现开口参数β最具预测性，证实了通过几何特征区分缩减与非缩减小提琴的可行性。


<details>
  <summary>Details</summary>
Motivation: 16世纪晚期出现的小提琴在200年间发展出多样化形态，约1750年尺寸标准化后，未被纳入标准的乐器常被缩减尺寸，导致轮廓线特征改变（U型变V型）。这种差异虽被专家观察但缺乏定量研究。

Method: 对25把乐器进行摄影测量获取3D网格，每把提取10-20条等距轮廓线，用类抛物线方程y=α*|x|^β拟合，计算开口度β和垂直拉伸度α等特征，建立数值化轮廓档案后应用分类算法。

Result: 几何特征可在一定程度上预测尺寸缩减（准确率未明确），其中开口参数β最具判别力；但存在连续过渡的改造谱系，部分案例难以量化缩减程度。

Conclusion: 通过轮廓线定量分析可实现小提琴尺寸缩减分类，证实了历史文献中观察到的U/V型轮廓差异，为乐器鉴定提供了新的客观依据。

Abstract: The first violins appeared in late 16th-century Italy. Over the next 200
years, they spread across Europe and luthiers of various royal courts, eager to
experiment with new techniques, created a highly diverse family of instruments.
Around 1750, size standards were introduced to unify violin making for
orchestras and conservatories. Instruments that fell between two standards were
then reduced to a smaller size by luthiers. These reductions have an impact on
several characteristics of violins, in particular on the contour lines, i.e.
lines of constant altitude, which look more like a U for non reduced
instruments and a V for reduced ones. While such differences are observed by
experts, they have not been studied quantitatively.
  This paper presents a method for classifying violins as reduced or
non-reduced based on their contour lines. We study a corpus of 25 instruments
whose 3D geometric meshes were acquired via photogrammetry. For each
instrument, we extract 10-20 contour lines regularly spaced every millimetre.
Each line is fitted with a parabola-like curve (with an equation of the type y
= alpha*abs(x)**beta) depending on two parameters, describing how open (beta)
and how vertically stretched (alpha) the curve is. We compute additional
features from those parameters, using regressions and counting how many values
fall under some threshold. We also deal with outliers and non equal numbers of
levels, and eventually obtain a numerical profile for each instrument.
  We then apply classification methods to assess whether geometry alone can
predict size reduction. We find that distinguishing between reduced and non
reduced instruments is feasible to some degree, taking into account that a
whole spectrum of more or less transformed violins exists, for which it is more
difficult to quantify the reduction. We also find the opening parameter beta to
be the most predictive.

</details>


### [75] [Measuring AI Alignment with Human Flourishing](https://arxiv.org/abs/2507.07787)
*Elizabeth Hilliard,Akshaya Jagadeesh,Alex Cook,Steele Billings,Nicholas Skytland,Alicia Llewellyn,Jackson Paull,Nathan Paull,Nolan Kurylo,Keatra Nesbitt,Robert Gruenewald,Anthony Jantzi,Omar Chavez*

Main category: cs.AI

TL;DR: 本文提出FAI Benchmark评估框架，从7个维度衡量AI对人类繁荣的贡献，测试28个主流语言模型发现尚无模型能全面达标，尤其在信仰与灵性等维度表现薄弱。


<details>
  <summary>Details</summary>
Motivation: 传统AI评估聚焦技术能力或危害预防，而FAI Benchmark旨在建立衡量AI促进人类整体繁荣的新标准，推动AI发展从'避免伤害'转向'主动支持'。

Method: 采用1229个主客观问题，通过专业评审LLM进行跨维度几何平均评分，评估AI在品德、人际关系、幸福感等7个维度的表现。

Result: 测试28个模型显示最高分仅72/100，所有模型在信仰与灵性、品德美德、人生意义等维度均未达到可接受水平。

Conclusion: FAI Benchmark为开发促进人类繁荣的AI系统提供框架，揭示当前AI在精神性等维度的不足，对AI伦理与发展具有重要启示。

Abstract: This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel
evaluation framework that assesses AI alignment with human flourishing across
seven dimensions: Character and Virtue, Close Social Relationships, Happiness
and Life Satisfaction, Meaning and Purpose, Mental and Physical Health,
Financial and Material Stability, and Faith and Spirituality. Unlike
traditional benchmarks that focus on technical capabilities or harm prevention,
the FAI Benchmark measures AI performance on how effectively models contribute
to the flourishing of a person across these dimensions. The benchmark evaluates
how effectively LLM AI systems align with current research models of holistic
human well-being through a comprehensive methodology that incorporates 1,229
objective and subjective questions. Using specialized judge Large Language
Models (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs
geometric mean scoring to ensure balanced performance across all flourishing
dimensions. Initial testing of 28 leading language models reveals that while
some models approach holistic alignment (with the highest-scoring models
achieving 72/100), none are acceptably aligned across all dimensions,
particularly in Faith and Spirituality, Character and Virtue, and Meaning and
Purpose. This research establishes a framework for developing AI systems that
actively support human flourishing rather than merely avoiding harm, offering
significant implications for AI development, ethics, and evaluation.

</details>


### [76] [MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving](https://arxiv.org/abs/2507.07818)
*Lu Xu,Jiaqian Yu,Xiongfeng Peng,Yiwei Chen,Weiming Li,Jaewook Yoo,Sunghyun Chunag,Dongwook Lee,Daehyun Ji,Chao Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为MoSE的技能导向混合专家模型，通过模仿人类驾驶员的学习和推理过程，实现了高效且高性能的自动驾驶系统。该方法在减少计算资源的同时，在CODA AD极端案例推理任务上超越了更大规模的模型。


<details>
  <summary>Details</summary>
Motivation: 现有混合专家模型(MoE)虽能提升大型语言模型和视觉语言模型的性能，但需要大量训练数据和复杂优化。受人类驾驶员学习过程启发，研究者希望开发一种更高效、更贴近人类推理的模型。

Method: 提出技能导向路由机制：1)定义并标注特定驾驶技能，实现分技能学习；2)构建分层技能数据集，预训练路由器以实现逐步推理；3)在单次前向过程中整合描述、推理、规划等辅助任务，不增加计算成本。

Result: 模型参数量不足30亿(稀疏激活)，但在CODA AD极端案例推理任务上超越多个80亿+参数模型。相比现有开源方案，以单轮对话形式实现SOTA性能，激活模型规模减少至少62.5%。

Conclusion: MoSE通过模拟人类分技能学习、逐步推理的机制，在保持计算效率的同时显著提升了自动驾驶系统的性能，为轻量化高性能自动驾驶模型提供了新思路。

Abstract: Recent studies show large language models (LLMs) and vision language models
(VLMs) trained using web-scale data can empower end-to-end autonomous driving
systems for a better generalization and interpretation. Specifically, by
dynamically routing inputs to specialized subsets of parameters, the
Mixture-of-Experts (MoE) technique enables general LLMs or VLMs to achieve
substantial performance improvements while maintaining computational
efficiency. However, general MoE models usually demands extensive training data
and complex optimization. In this work, inspired by the learning process of
human drivers, we propose a skill-oriented MoE, called MoSE, which mimics human
drivers' learning process and reasoning process, skill-by-skill and
step-by-step. We propose a skill-oriented routing mechanism that begins with
defining and annotating specific skills, enabling experts to identify the
necessary driving competencies for various scenarios and reasoning tasks,
thereby facilitating skill-by-skill learning. Further align the driving process
to multi-step planning in human reasoning and end-to-end driving models, we
build a hierarchical skill dataset and pretrain the router to encourage the
model to think step-by-step. Unlike multi-round dialogs, MoSE integrates
valuable auxiliary tasks (e.g.\ description, reasoning, planning) in one single
forward process without introducing any extra computational cost. With less
than 3B sparsely activated parameters, our model outperforms several 8B+
parameters on CODA AD corner case reasoning task. Compared to existing methods
based on open-source models and data, our approach achieves state-of-the-art
performance with significantly reduced activated model size (at least by
$62.5\%$) with a single-turn conversation.

</details>


### [77] [AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift](https://arxiv.org/abs/2507.07820)
*Eunsu Baek,Keondo Park,Jeonggil Ko,Min-hwan Oh,Taesik Gong,Hyung-Sin Kim*

Main category: cs.AI

TL;DR: 论文提出自适应感知作为AI可持续发展的新范式，通过动态调整传感器参数提升小模型性能，减少资源消耗，并探讨了技术整合与伦理挑战。


<details>
  <summary>Details</summary>
Motivation: 当前AI依赖大规模模型和数据集，导致环境、经济和伦理成本高昂，限制了可持续性和公平性。受生物感官系统启发，提出自适应感知作为解决方案。

Method: 通过动态调制传感器参数（如曝光度、灵敏度、多模态配置），在输入层面减少协变量偏移，提升效率。结合标准化基准、实时算法和多模态集成等研究方向。

Result: 研究表明自适应感知能使小模型（如EfficientNet-B0）超越更大模型（如OpenCLIP-H），显著降低计算与数据需求。

Conclusion: 推动自适应感知在机器人、医疗等领域的应用，通过技术优化与伦理考量，构建可持续、鲁棒且公平的AI系统。

Abstract: Current AI advances largely rely on scaling neural models and expanding
training datasets to achieve generalization and robustness. Despite notable
successes, this paradigm incurs significant environmental, economic, and
ethical costs, limiting sustainability and equitable access. Inspired by
biological sensory systems, where adaptation occurs dynamically at the input
(e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive
sensing as a necessary and foundational shift. Adaptive sensing proactively
modulates sensor parameters (e.g., exposure, sensitivity, multimodal
configurations) at the input level, significantly mitigating covariate shifts
and improving efficiency. Empirical evidence from recent studies demonstrates
that adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass
substantially larger models (e.g., OpenCLIP-H) trained with significantly more
data and compute. We (i) outline a roadmap for broadly integrating adaptive
sensing into real-world applications spanning humanoid, healthcare, autonomous
systems, agriculture, and environmental monitoring, (ii) critically assess
technical and ethical integration challenges, and (iii) propose targeted
research directions, such as standardized benchmarks, real-time adaptive
algorithms, multimodal integration, and privacy-preserving methods.
Collectively, these efforts aim to transition the AI community toward
sustainable, robust, and equitable artificial intelligence systems.

</details>


### [78] [Searching for actual causes: Approximate algorithms with adjustable precision](https://arxiv.org/abs/2507.07857)
*Samuel Reyd,Ada Diaconescu,Jean-Louis Dessalles*

Main category: cs.AI

TL;DR: 本文提出了一种多项式复杂度的算法，用于识别实际原因，适用于非布尔、黑盒和随机系统，并能通过调整计算时间提高精确性和全面性。


<details>
  <summary>Details</summary>
Motivation: 现有可解释人工智能（XAI）和因果性文献主要关注因素与后果的关系，而非专家用户期望的是导致目标后果的实际原因。然而，形式化这一概念仍是一个开放问题，且识别实际原因是一个NP完全问题，现有实用解决方案较少。

Method: 我们提出了一组算法，以多项式复杂度识别实际原因，并具有可调的精确性和全面性水平。

Result: 实验表明，这些算法能够识别现有方法无法处理的系统（如非布尔、黑盒和随机系统）的原因，并且可以通过增加计算时间提高精确性和全面性。

Conclusion: 该算法为解决实际原因识别问题提供了一种实用且灵活的解决方案，适用于多种系统类型，并能根据需求调整计算资源。

Abstract: Causality has gained popularity in recent years. It has helped improve the
performance, reliability, and interpretability of machine learning models.
However, recent literature on explainable artificial intelligence (XAI) has
faced criticism. The classical XAI and causality literature focuses on
understanding which factors contribute to which consequences. While such
knowledge is valuable for researchers and engineers, it is not what non-expert
users expect as explanations. Instead, these users often await facts that cause
the target consequences, i.e., actual causes. Formalizing this notion is still
an open problem. Additionally, identifying actual causes is reportedly an
NP-complete problem, and there are too few practical solutions to approximate
formal definitions. We propose a set of algorithms to identify actual causes
with a polynomial complexity and an adjustable level of precision and
exhaustiveness. Our experiments indicate that the algorithms (1) identify
causes for different categories of systems that are not handled by existing
approaches (i.e., non-boolean, black-box, and stochastic systems), (2) can be
adjusted to gain more precision and exhaustiveness with more computation time.

</details>


### [79] [An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis](https://arxiv.org/abs/2507.07893)
*Mingda Zhang,Na Zhao,Jianglong Qing,Qing xu,Kaiwen Pan,Ting luo*

Main category: cs.AI

TL;DR: 本研究提出了一种结合提示工程与多维知识图谱的增强框架，以解决大语言模型在法律纠纷分析中的局限性，显著提升了法律决策的准确性和逻辑理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在法律纠纷分析中存在法律知识表示不足、概念理解有限和推理缺陷等问题，亟需一种增强框架来提升其性能。

Method: 框架采用三阶段分层提示结构（任务定义、知识背景、推理指导），结合法律专用推理模板和动态优化机制，并构建三层知识图谱架构（分类本体、表示层、实例层），辅以四种精准法律概念检索方法。

Result: 实验结果表明，该框架显著提升了法律纠纷分析的性能，能够准确分析复杂案件的法律适用，并对司法决策逻辑展现出细致理解。

Conclusion: 该研究为智能法律辅助系统的实现提供了新颖的技术路径，通过知识增强框架有效弥补了大语言模型在法律领域的不足。

Abstract: The rapid development of artificial intelligence has positioned large
language models as fundamental components of intelligent legal systems.
However, these models face significant limitations in legal dispute analysis,
including insufficient legal knowledge representation, limited concept
understanding, and reasoning deficiencies. This research proposes an enhanced
framework integrating prompt engineering with multidimensional knowledge
graphs. The framework introduces a three-stage hierarchical prompt structure
comprising task definition, knowledge background, and reasoning guidance,
supplemented by legal-specific reasoning templates and dynamic optimization
mechanisms. A three-layer knowledge graph architecture is constructed with
legal classification ontology, representation, and instance layers. Four
complementary methods enable precise legal concept retrieval: direct legal norm
code matching, domain-specific semantic vector similarity, ontology-based path
reasoning, and specialized lexical segmentation. These components integrate
with web search technology to establish a knowledge-enhanced framework for
legal decision-making. Experimental results demonstrate significant performance
improvements in legal dispute analysis, enabling accurate legal application
analysis for complex cases while exhibiting nuanced understanding of judicial
decision-making logic, providing a novel technical approach for implementing
intelligent legal assistance systems.

</details>


### [80] [Meek Models Shall Inherit the Earth](https://arxiv.org/abs/2507.07931)
*Hans Gundlach,Jayson Lynch,Neil Thompson*

Main category: cs.AI

TL;DR: 论文指出，随着计算规模扩大带来的边际效益递减，资源有限的'温顺模型'将逐渐接近顶级模型的性能水平，呼吁重新审视AI战略与政策。


<details>
  <summary>Details</summary>
Motivation: 针对少数公司AI系统规模扩张导致的性能不平等现象，研究挑战了主流直觉，提出计算规模效益递减将促使模型能力趋同。

Method: 构建理论模型证明固定分布的下一个token预测目标下，计算资源的边际能力回报急剧下降；通过基准数据验证训练损失差异等代理指标的有效性，并分析历史模型能力差异数据。

Result: 实证表明，即使计算资源指数级增长的公司，其模型能力优势也将因效益递减而减弱，'温顺模型'性能将逼近最优模型。

Conclusion: 鉴于模型能力趋同趋势，需要重新评估AI发展战略与政策框架，并规划受影响的具体领域。

Abstract: The past decade has seen incredible scaling of AI systems by a few companies,
leading to inequality in AI model performance. This paper argues that, contrary
to prevailing intuition, the diminishing returns to compute scaling will lead
to a convergence of AI model capabilities. In other words, meek models (those
with limited computation budget) shall inherit the earth, approaching the
performance level of the best models overall. We develop a model illustrating
that under a fixed-distribution next-token objective, the marginal capability
returns to raw compute shrink substantially. Given current scaling practices,
we argue that these diminishing returns are strong enough that even companies
that can scale their models exponentially faster than other organizations will
eventually have little advantage in capabilities. As part of our argument, we
give several reasons that proxies like training loss differences capture
important capability measures using evidence from benchmark data and
theoretical performance models. In addition, we analyze empirical data on the
capability difference of AI models over time. Finally, in light of the
increasing ability of meek models, we argue that AI strategy and policy require
reexamination, and we outline the areas this shift will affect.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [81] [The Richness of CSP Non-redundancy](https://arxiv.org/abs/2507.07942)
*Joshua Brakensiek,Venkatesan Guruswami,Bart M. P. Jansen,Victor Lagerkvist,Magnus Wahlström*

Main category: cs.DM

TL;DR: 本文研究了约束满足问题(CSP)中的非冗余性(NRD)问题，证明了对于每个有理数$r \ge 1$存在NRD为$\Theta(n^r)$的谓词，并建立了二元谓词条件非冗余性的完整分类。通过发展代数理论，首次发现了不依赖于阿贝尔群的Mal'tsev嵌入实例。


<details>
  <summary>Details</summary>
Motivation: 非冗余性作为连接稀疏化、核化、查询复杂性等多个重要领域的枢纽概念，其深入理解对计算机科学和数学具有重要意义。本文旨在系统研究非冗余性及其条件变体的理论特性。

Method: 采用极值组合学中的高围长图结构分析二元谓词，发展条件非冗余性的代数理论框架，并基于Carbonnel的工作扩展Mal'tsev嵌入的应用范围。

Result: 1) 构造出NRD增长率为任意有理数幂次的谓词族 2) 完全分类二元谓词的条件非冗余性 3) 发现基于量子Pauli群的新型Mal'tsev嵌入实例

Conclusion: 非冗余性研究揭示了CSP谓词与组合结构间的深刻联系，发展的代数理论为理解线性非冗余性提供了新工具，量子群的嵌入实例拓展了现有理论框架。

Abstract: In the field of constraint satisfaction problems (CSP), a clause is called
redundant if its satisfaction is implied by satisfying all other clauses. An
instance of CSP$(P)$ is called non-redundant if it does not contain any
redundant clause. The non-redundancy (NRD) of a predicate $P$ is the maximum
number of clauses in a non-redundant instance of CSP$(P)$, as a function of the
number of variables $n$. Recent progress has shown that non-redundancy is
crucially linked to many other important questions in computer science and
mathematics including sparsification, kernelization, query complexity,
universal algebra, and extremal combinatorics. Given that non-redundancy is a
nexus for many of these important problems, the central goal of this paper is
to more deeply understand non-redundancy.
  Our first main result shows that for every rational number $r \ge 1$, there
exists a finite CSP predicate $P$ such that the non-redundancy of $P$ is
$\Theta(n^r)$. Our second main result explores the concept of conditional
non-redundancy first coined by Brakensiek and Guruswami [STOC 2025]. We
completely classify the conditional non-redundancy of all binary predicates
(i.e., constraints on two variables) by connecting these non-redundancy
problems to the structure of high-girth graphs in extremal combinatorics.
  Inspired by these concrete results, we build off the work of Carbonnel [CP
2022] to develop an algebraic theory of conditional non-redundancy. As an
application of this algebraic theory, we revisit the notion of Mal'tsev
embeddings, which is the most general technique known to date for establishing
that a predicate has linear non-redundancy. For example, we provide the first
example of predicate with a Mal'tsev embedding that cannot be attributed to the
structure of an Abelian group, but rather to the structure of the quantum Pauli
group.

</details>
