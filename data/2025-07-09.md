<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 7]
- [math.OC](#math.OC) [Total: 12]
- [math.NT](#math.NT) [Total: 8]
- [math.LO](#math.LO) [Total: 3]
- [math.CO](#math.CO) [Total: 18]
- [cs.CR](#cs.CR) [Total: 22]
- [cs.AI](#cs.AI) [Total: 41]
- [cs.DM](#cs.DM) [Total: 1]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Maximum likelihood estimation of mean functions for Gaussian processes under small noise asymptotics](https://arxiv.org/abs/2507.05628)
*Mitsuki Kobayashi,Yuto Nishiwaki,Yasutaka Shimizu,Nobutoki Takaoka*

Main category: math.ST

TL;DR: 本文研究了高斯过程中时间依赖均值函数的极大似然估计，提出了最广泛的均值函数类别以实现显式似然函数，并探讨了小噪声渐近条件下的局部渐近正态性与估计效率。同时，基于离散样本的M估计量及类AIC准则是模型选择的关键贡献。


<details>
  <summary>Details</summary>
Motivation: 研究高斯过程在连续观测下时间依赖均值函数的估计问题，旨在构建最广泛的均值函数类别以实现显式似然函数，并分析小噪声条件下的渐近性质与估计效率。

Method: 采用极大似然估计法处理连续观测数据，推导显式似然函数；引入小噪声渐近条件分析局部渐近正态性；提出基于离散样本的M估计量及类AIC准则用于模型选择。

Result: 成功构建了最广泛的均值函数类别，其似然函数可显式表达；在小噪声条件下证明了局部渐近正态性及估计效率；离散样本M估计量同样具有渐近高效性，并提出了有效的模型选择准则。

Conclusion: 本文为高斯过程时间依赖均值函数提供了普适的估计框架，理论证明了估计量的渐近最优性，同时通过离散样本扩展与模型选择工具增强了方法的实用性。

Abstract: Maximum likelihood estimators for time-dependent mean functions within
Gaussian processes are provided in the context of continuous observations. We
find the widest possible class of mean functions for which the likelihood
function can be written explicitly. When it is subjected to a small noise
asymptotic condition leading to the vanishing of the primary Gaussian noise, we
attain local asymptotic normality results, accompanied by insights into the
asymptotic efficiency of these estimators. In addition, we introduce
M-estimators based on discrete samples, which also leads us to the asymptotic
efficiency. Furthermore, we provide quasi-information criteria for model
selection analogous to Akaike Information Criteria in discretely observed
cases.

</details>


### [2] [A Note on Inferential Decisions, Errors and Path-Dependency](https://arxiv.org/abs/2507.05634)
*Kangda K. Wren*

Main category: math.ST

TL;DR: 本文研究了二元结果序列测试中的信念过程与客观条件概率的差异及其收敛性，揭示了非本质相同信念过程下时间齐次连续决策必须具有路径依赖性，并将推断误差分解为两个独立成分。


<details>
  <summary>Details</summary>
Motivation: 探讨二元序列测试中信念过程与客观条件概率的差异及其对决策路径依赖性的影响，旨在理解推断误差的结构特性。

Method: 通过理论分析比较信念过程与客观条件概率的收敛性，并研究时间齐次连续决策在非本质相同信念过程下的路径依赖性。

Result: 除非信念过程与客观条件概率'本质相同'（仅相差先验因子），否则时间齐次连续决策必须对状态变量具有路径依赖性；推断误差可分解为两个独立成分。

Conclusion: 研究揭示了信念过程与客观条件概率的差异如何导致决策路径依赖性，并提出了推断误差的分解框架，为序列测试理论提供了新见解。

Abstract: Consider the standard sequential testing of a binary outcome. The associated
belief process and its objectively true conditional-probability counterpart
generally differ, but they converge to the same target in well-defined tests.
We show that unless the two processes are 'essentially identical', differing at
most by an a priori factor, time-homogeneous continuous sequential decisions
based on the former must be path-dependent with respect to state-variables
based on the latter or other non-essentially-identical belief processes.
Further, total inferential errors decompose into two components with distinct
and independent characteristics.

</details>


### [3] [Optimal structure learning and conditional independence testing](https://arxiv.org/abs/2507.05689)
*Ming Gao,Yuhao Wang,Bryon Aragam*

Main category: math.ST

TL;DR: 本文揭示了最优结构学习与最优条件独立性测试之间的基本联系，证明结构学习问题的最优速率由条件独立性测试的最优速率决定，并通过多种模型验证了这一理论。


<details>
  <summary>Details</summary>
Motivation: 研究旨在建立结构学习与条件独立性测试之间的理论联系，为分析结构学习的统计复杂性提供统一框架。

Method: 通过在多树结构问题中建立两种问题的通用归约，并在伯努利、高斯及非参数模型等示例中推导最优速率。

Result: 结果表明，这些场景下的最优算法是PC算法的适当改进版本，且结构学习的最优速率确实由条件独立性测试的最优速率决定。

Conclusion: 研究为通过极小极大测试视角分析结构学习的统计复杂度提供了理论基础，并验证了改进版PC算法的普适最优性。

Abstract: We establish a fundamental connection between optimal structure learning and
optimal conditional independence testing by showing that the minimax optimal
rate for structure learning problems is determined by the minimax rate for
conditional independence testing in these problems. This is accomplished by
establishing a general reduction between these two problems in the case of
poly-forests, and demonstrated by deriving optimal rates for several examples,
including Bernoulli, Gaussian and nonparametric models. Furthermore, we show
that the optimal algorithm in these settings is a suitable modification of the
PC algorithm. This theoretical finding provides a unified framework for
analyzing the statistical complexity of structure learning through the lens of
minimax testing.

</details>


### [4] [Importance sampling for Sobol' indices estimation](https://arxiv.org/abs/2507.05958)
*Haythem Boucharif,Jérôme Morio,Paul Rochet*

Main category: math.ST

TL;DR: 提出了一种新的重要性采样框架，用于Sobol'指数的估计与分析，通过重新加权估计器实现不同采样分布下的稳健估计。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在参考输入分布下定义的Sobol'指数在其他采样分布中的估计问题，并探索输入分布不确定性的稳健分析方法。

Method: 采用重要性采样框架，推导出最小化渐近方差的最优采样分布，并通过反向重要性采样支持分布敏感性分析。

Result: 最优采样分布显著提高了估计精度，且反向重要性采样能以极低计算成本实现输入分布不确定性的稳健探索。

Conclusion: 该框架不仅实现了方差缩减，还为分布敏感性分析提供了高效工具，具有重要的理论和应用价值。

Abstract: We propose a new importance sampling framework for the estimation and
analysis of Sobol' indices. We show that a Sobol' index defined under a
reference input distribution can be consistently estimated from samples drawn
from other sampling distributions by reweighting the estimator appropriately to
account for the distribution change. We derive the optimal sampling
distribution that minimizes the asymptotic variance and demonstrate its strong
impact on estimation accuracy. Beyond variance reduction, the framework
supports distributional sensitivity analysis via reverse importance sampling,
enabling robust exploration of input distribution uncertainty with negligible
additional computational cost.

</details>


### [5] [Nonparametric Estimation in SDE Models Involving an Explanatory Process](https://arxiv.org/abs/2507.06098)
*Fabienne Comte,Nicolas Marie*

Main category: math.ST

TL;DR: 本文研究了一个由随机微分方程（SDE）定义的随机过程$X_t$，其中包含外生过程$Y_t$的影响。论文首先从概率论角度证明了模型解的存在唯一性，并建立了$(X_t,Y_t)$联合分布的密度控制。第二部分提出了基于投影最小二乘估计器的风险界和收敛速率，并研究了模型选择方法。


<details>
  <summary>Details</summary>
Motivation: 研究由外生过程驱动的随机微分方程模型，旨在解决其解的存在唯一性问题，并为后续的参数估计提供理论支持。

Method: 首先通过概率论方法建立SDE解的存在唯一性及联合分布密度控制；然后采用基于副本的投影最小二乘估计器对函数$(a,b)$进行估计，并在Sobolev空间中分析其收敛性。

Result: 证明了SDE解的存在唯一性，建立了联合分布密度的控制条件；获得了参数估计在Sobolev空间中的风险界和收敛速率，并实现了理论实践中的偏差-方差权衡。

Conclusion: 该研究为外生过程驱动的随机微分方程提供了完整的理论框架和有效的参数估计方法，其模型选择机制在实践中具有良好的适应性。

Abstract: This paper deals with the process $X = (X_t)_{t\in [0,T]}$ defined by the
stochastic differential equation (SDE) $dX_t = (a(X_t) + b(Y_t))dt
+\sigma(X_t)dW_1(t)$, where $W_1$ is a Brownian motion and $Y$ is an exogenous
process. The first task - of probabilistic nature - is to properly define the
model, to prove the existence and uniqueness of the solution of such an
equation, and then to establish the existence and a suitable control of a
density with respect to the Lebesgue measure of the distribution of $(X_t,Y_t)$
($t > 0$). In the second part of the paper, a risk bound and a rate of
convergence in specific Sobolev spaces are established for a copies-based
projection least squares estimator of the $\mathbb R^2$-valued function
$(a,b)$. Moreover, a model selection procedure making the adequate
bias-variance compromise both in theory and practice is investigated.

</details>


### [6] [On the Estimation of Gaussian Moment Tensors](https://arxiv.org/abs/2507.06166)
*Omar Al-Ghattas,Jiaheng Chen,Daniel Sanz-Alonso*

Main category: math.ST

TL;DR: 本文比较了高斯矩张量的两种估计器：标准样本矩估计器和基于Isserlis定理的插件估计器，证明了后者在偶数阶张量$p>2$时的优势。


<details>
  <summary>Details</summary>
Motivation: 研究高斯矩张量的估计方法，旨在量化Isserlis估计器在偶数阶张量中的性能优势。

Method: 对比分析标准样本矩估计器与基于Isserlis定理的插件估计器，建立维度无关的非渐近误差界。

Result: 在算子范数和逐项最大范数下，Isserlis估计器对偶数阶张量$p>2$表现出显著优势，且适用于对称与非对称张量。

Conclusion: Isserlis估计器在高斯矩张量估计中具有理论优势，尤其适用于高阶偶数阶张量场景。

Abstract: This paper studies two estimators for Gaussian moment tensors: the standard
sample moment estimator and a plug-in estimator based on Isserlis's theorem. We
establish dimension-free, non-asymptotic error bounds that demonstrate and
quantify the advantage of Isserlis's estimator for tensors of even order $p>2$.
Our bounds hold in operator and entrywise maximum norms, and apply to symmetric
and asymmetric tensors.

</details>


### [7] [Consistency and Inconsistency in $K$-Means Clustering](https://arxiv.org/abs/2507.06226)
*Moïse Blanchard,Adam Quinn Jaffe,Nikita Zhivotovskiy*

Main category: math.ST

TL;DR: 本文探讨了在仅有限期望条件下$k$-均值聚类问题的适定性，揭示了极端簇不平衡导致的不一致性，并提出通过平衡约束恢复渐近一致性的方法。


<details>
  <summary>Details</summary>
Motivation: Pollard的经典结果证明当总体分布具有有限方差时，$k$-均值聚类具有渐近一致性。本研究旨在探究在更弱的有限期望条件下，$k$-均值聚类是否仍保持某种形式的渐近一致性。

Method: 通过理论分析和反例构造，研究了有限期望条件下$k$-均值聚类中心收敛性问题，特别关注簇不平衡对一致性的影响。

Result: 发现当存在极端簇不平衡（如离群样本导致某些簇点极少）时，经验$k$-均值聚类中心可能不收敛；但通过施加先验的簇平衡约束，可在有限期望条件下恢复部分渐近一致性。

Conclusion: 研究表明有限期望条件下$k$-均值聚类的渐近一致性具有微妙性，但通过合理平衡约束可实现理论保证，扩展了经典结果的适用条件。

Abstract: A celebrated result of Pollard proves asymptotic consistency for $k$-means
clustering when the population distribution has finite variance. In this work,
we point out that the population-level $k$-means clustering problem is, in
fact, well-posed under the weaker assumption of a finite expectation, and we
investigate whether some form of asymptotic consistency holds in this setting.
As we illustrate in a variety of negative results, the complete story is quite
subtle; for example, the empirical $k$-means cluster centers may fail to
converge even if there exists a unique set of population $k$-means cluster
centers. A detailed analysis of our negative results reveals that inconsistency
arises because of an extreme form of cluster imbalance, whereby the presence of
outlying samples leads to some empirical $k$-means clusters possessing very few
points. We then give a collection of positive results which show that some
forms of asymptotic consistency, under only the assumption of finite
expectation, may be recovered by imposing some a priori degree of balance among
the empirical $k$-means clusters.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [8] [An inexact inertial projective splitting algorithm with strong convergence](https://arxiv.org/abs/2507.05382)
*M. Marques Alves,J. E. Navarro Caballero,R. T. Marcavillaca*

Main category: math.OC

TL;DR: 提出一种强收敛的近似惯性投影分裂算法，用于求解包含有限多个极大单调算子之和的复合单调包含问题，通过投影确保强收敛性，并分析了迭代复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究复合单调包含问题的求解方法，旨在开发一种在无惯性效应下仍能保证强收敛性的算法，并分析其迭代复杂度。

Method: 采用近似惯性投影分裂算法，包含两个惯性序列，参数满足温和条件，同时引入前向后向和前向后向前向步骤的变体。

Result: 算法在无惯性项时仍能保证强收敛性，并提供了迭代复杂度分析，适用于结构化单调包含问题。

Conclusion: 所提算法在强收敛性和迭代复杂度方面表现优异，适用于多种单调包含问题，具有广泛的应用潜力。

Abstract: We propose and study a strongly convergent inexact inertial projective
splitting (PS) algorithm for finding zeros of composite monotone inclusion
problems involving the sum of finitely many maximal monotone operators. Strong
convergence of the iterates is ensured by projections onto the intersection of
appropriately defined half-spaces, even in the absence of inertial effects. We
also establish iteration-complexity results for the proposed PS method, which
likewise hold without requiring inertial terms. The algorithm includes two
inertial sequences, controlled by parameters satisfying mild conditions, while
preserving strong convergence and enabling iteration-complexity analysis.
Furthermore, for more structured monotone inclusion problems, we derive two
variants of the main algorithm that employ forward-backward and
forward-backward-forward steps.

</details>


### [9] [Computer-aided analyses of stochastic first-order methods, via interpolation conditions for stochastic optimization](https://arxiv.org/abs/2507.05466)
*Anne Rubbens,Sébastien Colla,Julien M. Hendrickx*

Main category: math.OC

TL;DR: 本文提出了一种基于性能估计框架（PEP）的新方法，用于为随机一阶方法提供最坏情况下的性能保证。通过半定规划（SDP）的逐步扩展，该方法能够提供从宽松到严格的收敛保证，适用于多种随机设置，并改进了现有收敛速率。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于为随机一阶优化方法提供统一且严格的性能保证框架，覆盖多种噪声模型和优化场景，以弥补现有理论分析的不足。

Method: 方法基于PEP框架，提出了一系列规模逐步增大的半定规划（SDP）问题。这些SDP的规模从线性增长到指数级（$2^N$，$N$为迭代次数），用于提供不同强度的收敛保证。框架支持有限或无限支持的噪声模型，包括有界方差非结构化噪声、有限和优化及块坐标方法。

Result: 结果表明，即使是规模线性于$N$的SDP，在许多问题上也能提供紧致的收敛保证。通过框架分析，改进了非结构化有界方差噪声模型和块坐标设置下的收敛速率，并与现有理论结果建立了联系。

Conclusion: 该框架为随机一阶方法提供了统一的性能分析工具，能够灵活适应多种优化场景，并通过SDP的规模调整平衡计算复杂度与保证强度，为随机优化理论提供了新的分析视角。

Abstract: This work proposes a framework, embedded within the Performance Estimation
framework (PEP), for obtaining worst-case performance guarantees on stochastic
first-order methods. Given a first-order method, a function class, and a noise
model with prescribed expectation and variance properties, we present a range
of semidefinite programs (SDPs) of increasingly large size, whose solutions
yield increasingly strong convergence guarantees on the problem. Eventually, we
propose SDPs whose size depends on $2^N$, with $N$ the number of iterations
analyzed, that yield tight guarantees, attained by specific functions and noise
distributions within these classes. On the other side of the spectrum, we
propose SDPs whose size depends linearly on $N$, and numerically show that, on
many problems, they already provide tight guarantees.
  The framework accommodates a wide range of stochastic settings, with finite
or infinite support, including the unstructured noise model with bounded
variance, finite-sum optimization, and block-coordinate methods, in a unified
manner, as guarantees apply to any setting consistent with the noise model,
i.e., its expectation and variance. It covers both non-variance-reduced and
variance-reduced methods. Using the framework, we analyze the stochastic
gradient method under several noise models, and illustrate how the resulting
numerical and analytical convergence rates connect with existing results. In
particular, we provide improved convergence rates on the unstructured noise
model with bounded variance and in the block-coordinate setting.

</details>


### [10] [MultiObjectiveAlgorithms.jl: a Julia package for solving multi-objective optimization problems](https://arxiv.org/abs/2507.05501)
*Oscar Dowson,Xavier Gandibleux,Gökhan Kof*

Main category: math.OC

TL;DR: MultiObjectiveAlgorithms.jl是一个开源的Julia库，用于解决基于JuMP的多目标优化问题，支持多种求解器和问题类型。


<details>
  <summary>Details</summary>
Motivation: 开发一个灵活、开源的Julia库，以支持多目标优化问题的求解，并扩展JuMP的功能以支持向量值目标函数。

Method: 通过迭代标量化方法将多目标优化问题转化为一系列单目标子问题，并利用JuMP支持多种商业和开源求解器。

Result: MultiObjectiveAlgorithms.jl成功实现了多种求解算法，支持从线性到非线性等多种问题类型，并在MPL-2许可下开源。

Conclusion: 该库为多目标优化问题提供了一个强大且灵活的工具，能够与多种求解器兼容，适用于广泛的优化问题。

Abstract: We present MultiObjectiveAlgorithms.jl, an open-source Julia library for
solving multi-objective optimization problems written in JuMP.
MultiObjectiveAlgorithms.jl implements a number of different solution
algorithms, which all rely on an iterative scalarization of the problem from a
multi-objective optimization problem to a sequence of single-objective
subproblems. As part of this work, we extended JuMP to support vector-valued
objective functions. Because it is based on JuMP, MultiObjectiveAlgorithms.jl
can use a wide variety of commercial and open-source solvers to solve the
single-objective subproblems, and it supports problem classes ranging from
linear, to conic, semi-definite, and general nonlinear.
MultiObjectiveAlgorithms.jl is available at
https://github.com/jump-dev/MultiObjectiveAlgorithms.jl under a MPL-2 license.

</details>


### [11] [Exact and efficient basis pursuit denoising via differential inclusions and a selection principle](https://arxiv.org/abs/2507.05562)
*Gabriel P. Langlois,Jérôme Darbon*

Main category: math.OC

TL;DR: 本文提出了一种基于微分包含理论的精确高效BPDN算法，通过将双问题转化为可积投影动力系统轨迹计算，实现了高精度与高效率的平衡，并在数值实验中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有BPDN算法在效率与精度间难以兼顾，无法满足高维应用需求。本文旨在解决这一矛盾，提出一种同时具备精确性与计算效率的新算法。

Method: 利用微分包含理论的选择原理，将BPDN双问题转化为可积投影动力系统轨迹计算问题。该系统轨迹和渐近极限可精确求解，从而衍生出可达机器精度的快速算法。

Result: 数值实验表明该算法在精度和效率上均优于现有技术。系统解的全局延拓还可用于构建BPDN同伦算法，以及强多项式时间内求解基追踪可行解的新型贪婪算法。

Conclusion: 该算法为BPDN提供了首个精确高效解决方案，其方法论可推广至更广泛的多面体约束优化问题。微分包含框架为相关领域研究开辟了新途径。

Abstract: Basis pursuit denoising (BPDN) is a cornerstone of compressive sensing,
statistics and machine learning. While various algorithms for BPDN have been
proposed, they invariably suffer from drawbacks and must either favor
efficiency at the expense of accuracy or vice versa. As such, state-of-the-art
algorithms remain ineffective for high-dimensional applications that require
accurate solutions within a reasonable amount of computational time. In this
work, we address this issue and propose an exact and efficient algorithm for
BPDN using differential inclusions. Specifically, we prove that a selection
principle from the theory of differential inclusions turns the dual problem of
BPDN into calculating the trajectory of an \emph{integrable} projected
dynamical system, that is, whose trajectory and asymptotic limit can be
computed exactly. Our analysis naturally yields an exact algorithm, numerically
up to machine precision, that is amenable to computing regularization paths and
very fast. Numerical experiments confirm that our algorithm outperforms the
state-of-the-art algorithms in both accuracy and efficiency. Moreover, we show
that the global continuation of solutions (in terms of the hyperparameter and
data) of the projected dynamical system yields a rigorous homotopy algorithm
for BPDN, as well as a novel greedy algorithm for computing feasible solutions
to basis pursuit in strongly polynomial time. Beyond this work, we expect that
our results and analysis can be adapted to compute exact or approximate
solutions to a broader class of polyhedral-constrained optimization problems.

</details>


### [12] [On the Inherent Privacy of Zeroth Order Projected Gradient Descent](https://arxiv.org/abs/2507.05610)
*Devansh Gupta,Meisam Razaviyayn,Vatsal Sharan*

Main category: math.OC

TL;DR: 本文探讨了零阶优化方法在差分隐私保护中的有效性，发现即使不添加高斯噪声，某些情况下零阶梯度下降（ZO-GD）仍无法保证差分隐私。


<details>
  <summary>Details</summary>
Motivation: 零阶优化方法因内存需求低而广泛应用于机器学习模型的私有微调，但其固有的随机性是否足以确保差分隐私尚不明确。

Method: 研究针对一类基于零阶梯度估计的优化算法，分析了固定初始化和随机初始化下（投影）零阶梯度下降（ZO-GD）的隐私性。

Result: 结果表明，对于某些强凸目标函数，固定初始化的ZO-GD不具备差分隐私性；即使随机初始化且不公开中间迭代，凸函数优化中的隐私损失可能随迭代次数超线性增长。

Conclusion: 零阶优化方法的固有噪声不足以保证差分隐私，需额外机制确保隐私保护，尤其在迭代次数较多时。

Abstract: Differentially private zeroth-order optimization methods have recently gained
popularity in private fine tuning of machine learning models due to their
reduced memory requirements. Current approaches for privatizing zeroth-order
methods rely on adding Gaussian noise to the estimated zeroth-order gradients.
However, since the search direction in the zeroth-order methods is inherently
random, researchers including Tang et al. (2024) and Zhang et al. (2024a) have
raised an important question: is the inherent noise in zeroth-order estimators
sufficient to ensure the overall differential privacy of the algorithm? This
work settles this question for a class of oracle-based optimization algorithms
where the oracle returns zeroth-order gradient estimates. In particular, we
show that for a fixed initialization, there exist strongly convex objective
functions such that running (Projected) Zeroth-Order Gradient Descent (ZO-GD)
is not differentially private. Furthermore, we show that even with random
initialization and without revealing (initial and) intermediate iterates, the
privacy loss in ZO-GD can grow superlinearly with the number of iterations when
minimizing convex objective functions.

</details>


### [13] [A derivative-free regularization algorithm for equality constrained nonlinear least squares problems](https://arxiv.org/abs/2507.05623)
*Xi Chen,Jinyan Fan*

Main category: math.OC

TL;DR: 本文提出一种无导数正则化算法，通过正交球面平滑逼近雅可比矩阵，解决雅可比矩阵不可用或计算成本高的等式约束非线性最小二乘问题。


<details>
  <summary>Details</summary>
Motivation: 针对目标函数和约束的雅可比矩阵难以获取或计算昂贵的问题，研究无需导数的求解方法。

Method: 采用正交球面平滑逼近雅可比矩阵，结合正则化增广拉格朗日子问题求解牛顿类步长，并通过无导数LM算法确保充分下降条件。

Result: 算法能以任意高概率找到近似KKT点，或几乎必然收敛至约束违反的稳定点。

Conclusion: 该方法为无导数环境下求解等式约束非线性最小二乘问题提供了有效方案，具有理论收敛保证。

Abstract: In this paper, we study the equality constrained nonlinear least squares
problem, where the Jacobian matrices of the objective function and constraints
are unavailable or expensive to compute. We approximate the Jacobian matrices
via orthogonal spherical smoothing and propose a derivative-free regularization
algorithm for solving the problem. At each iteration, a regularized augmented
Lagrangian subproblem is solved to obtain a Newton-like step. If a sufficient
decrease in the merit function of the approximate KKT system is achieved, the
step is accepted, otherwise a derivative-free LM algorithm is applied to get
another step to satisfy the sufficient decrease condition. It is shown that the
algorithm either finds an approximate KKT point with arbitrary high probability
or converges to a stationary point of constraints violation almost surely.

</details>


### [14] [A Fully Adaptive Frank-Wolfe Algorithm for Relatively Smooth Problems and Its Application to Centralized Distributed Optimization](https://arxiv.org/abs/2507.05669)
*A. A. Vyguzov,F. S. Stonyakin*

Main category: math.OC

TL;DR: 本文提出了一种完全自适应的Frank-Wolfe算法，用于解决具有相对光滑和相对强凸目标的约束优化问题，无需预先知道函数参数，并在分布式优化中展示了其优势。


<details>
  <summary>Details</summary>
Motivation: 研究Frank-Wolfe算法在相对光滑和相对强凸目标下的优化问题，旨在开发一种完全自适应的步长调整方法，以提升收敛性能并适应分布式优化场景。

Method: 提出了一种动态调整步长的Frank-Wolfe算法，基于相对光滑常数和Bregman散度的三角缩放指数（TSE），仅使用局部信息保证收敛，并适用于分布式优化。

Result: 在相对强凸性下建立了线性收敛率，数值实验表明该方法在分布式设置中优于非自适应和部分自适应变体。

Conclusion: 自适应Frank-Wolfe算法在相对光滑和强凸条件下表现优异，特别是在分布式优化中，由于改进的相对条件数而实现了可证明的加速。

Abstract: We study the Frank-Wolfe algorithm for constrained optimization problems with
relatively smooth and relatively strongly convex objectives. Building upon our
previous work, we propose a fully adaptive variant of the Frank-Wolfe method
that dynamically adjusts the step size based on both the relative smoothness
constant and the Triangle Scaling Exponent (TSE) of the Bregman divergence. Our
method does not require prior knowledge of the function parameters and
guarantees convergence using only local information. We establish a linear
convergence rate under relative strong convexity and provide a detailed
theoretical analysis of the proposed adaptive step-size rule.
  Furthermore, we demonstrate how relative smoothness and strong convexity
naturally arise in the setting of centralized distributed optimization. Under a
variance-type assumption on the gradients, we show that the global objective
becomes relatively strongly convex with respect to the Bregman divergence
generated by a local function. This structure allows us to apply our adaptive
Frank-Wolfe algorithm, leading to provable acceleration due to an improved
relative condition number. We support our theoretical findings with numerical
experiments, showing that the proposed method outperforms both non-adaptive and
partially adaptive variants, especially in distributed settings.

</details>


### [15] [Nonstationary Distribution Estimation via Wasserstein Probability Flows](https://arxiv.org/abs/2507.05893)
*Edward J. Anderson,Dominic S. T. Keehan*

Main category: math.OC

TL;DR: 本文提出了一种基于Wasserstein距离的Wasserstein概率流方法，用于从历史数据中估计随时间演变的概率分布序列，适用于非平稳和非参数化的分布变化场景。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决非平稳和非参数化环境下，如何从历史数据中准确估计随时间变化的概率分布序列的问题。

Method: 方法通过引入Wasserstein距离作为惩罚项，构建了一个最大化观测数据对数似然并惩罚连续分布间Wasserstein距离之和的模型，并将其简化为网络流问题以实现高效计算。

Result: 数值实验结果表明，Wasserstein概率流方法在不同设置下均表现良好，验证了其作为非平稳随机优化等应用工具的潜力。

Conclusion: 结论指出，Wasserstein概率流方法是处理非平稳环境下概率分布序列估计的有效工具，尤其在非平稳随机优化等应用中展现出良好的前景。

Abstract: We study the problem of estimating a sequence of evolving probability
distributions from historical data, where the underlying distribution changes
over time in a nonstationary and nonparametric manner. To capture gradual
changes, we introduce a model that penalises large deviations between
consecutive distributions using the Wasserstein distance. This leads to a
method in which we estimate the underlying series of distributions by
maximizing the log-likelihood of the observations with a penalty applied to the
sum of the Wasserstein distances between consecutive distributions. We show how
this can be reduced to a simple network-flow problem enabling efficient
computation. We call this the Wasserstein Probability Flow method. We derive
some properties of the optimal solutions and carry out numerical tests in
different settings. Our results suggest that the Wasserstein Probability Flow
method is a promising tool for applications such as nonstationary stochastic
optimization.

</details>


### [16] [Heuristic approaches for a new variant of the Team Orienteering Problem](https://arxiv.org/abs/2507.06012)
*Alberto Guastalla,Roberto Aringhieri,Pierre Hosteins*

Main category: math.OC

TL;DR: 本文针对具有服务时间、强制节点和不相容性的团队定向问题，提出了两种启发式算法，并与精确切割平面方法进行对比，展示了在通用基准测试中的竞争力。


<details>
  <summary>Details</summary>
Motivation: 研究源于两个实际医疗应用场景中的团队定向问题，该问题被证明是NP完全问题，需要高效启发式算法求解。

Method: 提出可变下降邻域算法和基于切割分离的数学启发式算法，前者实现多线程并行版本，两种算法均包含特定启发式例程生成初始可行解。

Result: 启发式算法与精确切割平面方法形成优势互补，在现有TOP基准测试中展现出与最先进算法相当的竞争力。

Conclusion: 所提算法能有效解决复杂约束下的团队定向问题，在医疗等实际应用场景中具有实用价值。

Abstract: In this paper we tackle the Team Orienteering Problem with Service Times,
Mandatory Nodes and Incompatibilities, introduced in~\cite{Guastalla2024} and
arising from two real-world healthcare applications. We propose two heuristic
algorithms in the form of a Variable Descent Neighbourhood algorithm and a
matheuristic based on a Cuts Separation approach. For the former, we also
provide a multi-thread version exploiting its intrinsic capability to be
parallelised. Both algorithms include a specific heuristic routine to provide a
starting feasible solution, since finding a feasible solution has been proved
to be NP-complete. The results of our heuristic algorithms are compared with an
exact cutting plane approach and have complementary strengths and weaknesses.
They are also evaluated on existing TOP benchmarks against TOP state-of-the-art
algorithms, demonstrating their competitiveness on general grounds.

</details>


### [17] [New Lagrangian framework for optimality conditions in optimal control of second order systems](https://arxiv.org/abs/2507.06024)
*Michael Konopik,Sigrid Leyendecker,Sofya Maslovskaya,Sina Ober-Blöbaum,Rodrigo T. Sato Martín de Almagro*

Main category: math.OC

TL;DR: 本文扩展了二阶系统最优控制问题的一阶必要条件，提出了二阶最优性条件，并探讨了新拉格朗日量的作用。


<details>
  <summary>Details</summary>
Motivation: 近期研究表明，二阶系统动力学约束的最优控制问题具有正则拉格朗日表述，这为通过变分法获得最优性条件提供了新途径。

Method: 基于已有的变分方法，将一阶最优性条件推广至二阶条件，并分析新引入的拉格朗日量的数学特性。

Result: 成功推导出二阶最优性条件，揭示了新拉格朗日量在优化问题中的关键作用。

Conclusion: 该研究为二阶系统最优控制提供了更完备的理论框架，新拉格朗日表述为后续数值算法开发奠定了基础。

Abstract: It has been shown recently that optimal control problems with the dynamical
constraint given by a second order system admit a regular Lagrangian
formulation. This implies that the optimality conditions can be obtained in a
new form based on the variational approach. In this paper we extend the first
order necessary optimality conditions obtained previously to second order
optimality conditions and discuss the role of the new Lagrangian.

</details>


### [18] [Relationship between maximum principle and dynamic programming principle for recursive optimal control problem of stochastic evolution equations](https://arxiv.org/abs/2507.06118)
*Ying Hu,Guomin Liu,Shanjian Tang*

Main category: math.OC

TL;DR: 本文研究了随机演化方程递归最优控制问题中最大值原理与动态规划原理的关系，通过条件期望算子值反向随机积分方程概念，建立了MP中一阶和二阶伴随过程与价值函数广义导数之间的联系，并在附加假设下证明了价值函数的$C^{1,1}$正则性。


<details>
  <summary>Details</summary>
Motivation: 探讨非凸控制域和非光滑价值函数情况下，随机演化方程递归最优控制问题中最大值原理(MP)与动态规划原理(DPP)的关联性。

Method: 利用条件期望算子值反向随机积分方程的概念，建立MP中一阶/二阶伴随过程与价值函数广义导数之间的理论联系。

Result: 在特定附加假设下证明了价值函数具有$C^{1,1}$正则性，并讨论了光滑情形下的应用案例。

Conclusion: 该研究为随机控制理论提供了MP与DPP之间的桥梁，特别适用于非凸控制域和非光滑价值函数情形，理论结果具有广泛的应用潜力。

Abstract: This paper aims to study the relationship between the maximum principle and
the dynamic programming principle for recursive optimal control problem of
stochastic evolution equations, where the control domain is not necessarily
convex and the value function may be nonsmooth. By making use of the notion of
conditionally expected operator-valued backward stochastic integral equations,
we establish a connection between the first and second-order adjoint processes
in MP and the general derivatives of the value function. Under certain
additional assumptions, the value function is shown to be $C^{1,1}$-regular.
Furthermore, we discuss the smooth case and present several applications of our
results.

</details>


### [19] [A Generalized $\ell_1$-Merit Function SQP Method Using Function Approximations with Tunable Accuracy](https://arxiv.org/abs/2507.06199)
*Dane S. Grundvig,Matthias Heinkenschloss*

Main category: math.OC

TL;DR: 本文提出了一种基于$\ell_1$-merit函数的线搜索SQP算法扩展，通过可调精度的目标与约束函数近似求解光滑等式约束优化问题，并应用于Boussinesq PDE的边界控制问题。


<details>
  <summary>Details</summary>
Motivation: 目标与约束函数及其梯度的计算成本高昂，但可通过构建高效、低计算成本的模型来近似这些函数，从而降低计算负担。

Method: 算法在每次迭代中使用满足函数误差和相对梯度误差容忍度的模型生成新迭代点，并利用模型误差边界探索足够精确的区域。模型基于Boussinesq PDE的降阶模型构建。

Result: 算法保持了与标准线搜索SQP算法相同的全局收敛性，但仅依赖目标与约束函数模型及其误差边界。数值实验验证了其在边界控制问题中的有效性。

Conclusion: 所提算法通过模型近似降低了计算成本，同时保持了收敛性，适用于需要高计算成本的PDE相关优化问题。

Abstract: This paper develops a generalization of the line-search sequential quadratic
programming (SQP) algorithm with $\ell_1$-merit function that uses objective
and constraint function approximations with tunable accuracy to solve smooth
equality-constrained optimization problems. The evaluation of objective and
constraint functions and their gradients is potentially computationally
expensive, but it is assumed that one can construct effective, computationally
inexpensive models of these functions. This paper specifies how these models
can be used to generate new iterates. At each iteration, the models have to
satisfy function error and relative gradient error tolerances determined by the
algorithm based on its progress. Moreover, bounds for the model errors are used
to explore regions where the combined objective function and constraint models
are sufficiently accurate. The algorithm has the same first-order global
convergence properties as a line-search SQP algorithm with $\ell_1$-merit
function, but only uses objective and constraint function models and the model
error bounds. The algorithm is applied to a discretized boundary control
problem in which the evaluation of the objective and constraint functions
requires the solution of the Boussinesq partial differential equation (PDE).
The models are constructed from projection-based reduced-order models of the
Boussinesq PDE.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [20] [$p$-adic Fourier theory in families](https://arxiv.org/abs/2507.05374)
*Andrew Graham,Pol van Hoften,Sean Howe*

Main category: math.NT

TL;DR: 本文构建了有限高度$p$-可除刚性解析群上的傅里叶变换，建立了与$\mathbb{Z}_p$-局部系统的对偶关系，并应用于构造全局Eisenstein测度，生成新的超收敛四元数模形式。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于扩展Amice和Schneider-Teitelbaum的傅里叶变换构造，建立更一般的$p$-可除群与对偶Tate模之间的积分傅里叶变换，并探索其在$p$-模曲线上的应用。

Method: 方法包括构建固体Hopf代数同构作为傅里叶变换，利用Weierstrass $\wp$-函数构造全局Eisenstein测度，并通过刚性解析超奇异轨迹的有限集实现超收敛。

Result: 主要成果包括：1) 建立了任意小v-叠上的傅里叶变换同构；2) 扩展了Katz在普通轨迹和CM点的构造；3) 证明了全局Eisenstein分布生成新型四元数模形式。

Conclusion: 结论表明该傅里叶变换框架统一了先前离散与连续理论，其应用于$p$-模曲线产生的超收敛模形式，为志村簇算术研究开辟了新途径。

Abstract: We construct Fourier transforms relating functions and distributions on
finite height $p$-divisible rigid analytic groups and objects in a dual
category of $\mathbb{Z}_p$-local systems with analyticity conditions. Our
Fourier transforms are formulated as isomorphisms of solid Hopf algebras over
arbitrary small v-stacks, and generalize earlier constructions of Amice and
Schneider--Teitelbaum. We also construct compatible integral Fourier transforms
for $p$-divisible groups and their dual Tate modules. As an application, we use
the Weierstrass $\wp$-function to construct a global Eisenstein measure over
the $p$-adic modular curve, extending previous constructions of Katz over the
ordinary locus and at CM points, and show its generic fiber, the global
Eisenstein distribution, gives rise to new families of quaternionic modular
forms that overconverge from profinite sets in the rigid analytic supersingular
locus.

</details>


### [21] [The completeness of the Deligne-Ribet monoids](https://arxiv.org/abs/2507.05693)
*Takeo Uramoto*

Main category: math.NT

TL;DR: 本文证明了Deligne-Ribet幺半群$DR_K$是数域$K$的完整不变量，类似于绝对Galois群$G_K$的情况。


<details>
  <summary>Details</summary>
Motivation: 研究Deligne-Ribet幺半群$DR_K$是否能像绝对Galois群$G_K$一样，成为数域的完整不变量。

Method: 通过比较两个数域$K$和$L$的Deligne-Ribet幺半群$DR_K$和$DR_L$的同构关系。

Result: 证明了若$DR_K$与$DR_L$同构，则数域$K$与$L$同构。

Conclusion: Deligne-Ribet幺半群$DR_K$确实可以作为数域$K$的完整不变量，与绝对Galois群$G_K$具有同等效力。

Abstract: Following Cornelissen, Li, Marcolli, and Smit, this short paper proves that
the isomorphism of the Deligne-Ribet monoids $DR_K, DR_L$ for two number fields
$K, L$ implies the field isomorphism of $K$ and $L$. Thus the Deligne-Ribet
monoid $DR_K$ gives a complete invariant of the number field $K$ as in the case
of the absolute Galois group $G_K$.

</details>


### [22] [On Generators of Bloch groups of CM fields](https://arxiv.org/abs/2507.05792)
*Wenhuan Huang*

Main category: math.NT

TL;DR: 本文推广了Burns等人(2022)的结果，提出了一个算法来寻找生成特定CM数域的Bloch群无挠部分满秩子群的元素，并计算其秩。


<details>
  <summary>Details</summary>
Motivation: 研究CM数域的Bloch群结构对于理解代数K理论和数论中的深刻问题具有重要意义。

Method: 通过推广Burns等人的方法，设计算法构造Bloch群无挠部分的生成元，并计算其秩。

Result: 成功找到了生成Bloch群无挠部分满秩子群的元素，并精确计算出了该子群的秩。

Conclusion: 该算法为研究CM数域的Bloch群结构提供了有效工具，推进了相关领域的研究进展。

Abstract: This article generalizes the result of Burns et al (2022), to find an
algorithm to find some elements generating a full-rank subgroup of the
torsion-free part of Bloch group of a certain CM number field, and compute the
rank of it.

</details>


### [23] [The determination of norm-Euclidean cyclic cubic fields](https://arxiv.org/abs/2507.05862)
*Gustav Kjærbye Bagger,Andrew R. Booker,Bryce Kerr,Kevin McGown,Valeriia Starichkova,Tim Trudgian*

Main category: math.NT

TL;DR: 本文在广义黎曼假设下确定了13个范数欧几里得循环三次域，并通过改进三次非剩余显式界和计算技术，无条件地完整刻画了所有范数欧几里得循环三次域。


<details>
  <summary>Details</summary>
Motivation: 现有分析估计与计算技术之间存在无条件差距，需改进三次非剩余显式界以填补这一空白。

Method: 通过建立新的三次非剩余显式界，并优化先前计算技术，实现对所有范数欧几里得循环三次域的完整分类。

Result: 无条件完整刻画了所有范数欧几里得循环三次域，验证了广义黎曼假设下的13个域结论。

Conclusion: 改进的显式界与计算技术解决了无条件分析中的关键问题，为循环三次域的范数欧几里得性质提供了完整描述。

Abstract: It is known on the Generalised Riemann Hypothesis that there are precisely
$13$ cyclic cubic fields that are norm-Euclidean. Unconditionally, there is a
gap between analytic estimates which hold for all sufficiently large conductors
and computational techniques. In this paper, we establish new results
concerning explicit bounds for cubic non-residues and refine previous
computational techniques, enabling us to completely characterise all
norm-Euclidean cyclic cubic fields.

</details>


### [24] [Moment formulas of Siegel transforms with congruence conditions in dimension 2](https://arxiv.org/abs/2507.05905)
*Jiyoung Han,Seul Bee Lee*

Main category: math.NT

TL;DR: 本文计算了与带同余条件的原始格点计数问题相关的Siegel变换的一阶和二阶矩公式，并应用这些结果推导了Schmidt随机计数定理的类似定理以及无理数的定量Khintchine定理。


<details>
  <summary>Details</summary>
Motivation: 研究带同余条件的原始格点计数问题，扩展Schmidt随机计数定理和Khintchine定理的应用范围。

Method: 通过计算Siegel变换的一阶和二阶矩公式，并结合同余条件约束向量$(p,q)$的方法。

Result: 推导了Schmidt随机计数定理的类似定理以及带同余条件的定量Khintchine定理，适用于无理数由有理数$p/q$逼近的情况。

Conclusion: 本文的结果为带同余条件的原始格点计数问题提供了新的理论工具，扩展了经典定理的应用范围。

Abstract: We compute the first and second moment formulas for Siegel transforms related
to problems counting primitive lattice points in the real plane with congruence
conditions. As applications, we derive an analog of Schmidt's random counting
theorem and the quantitative Khintchine theorem for irrational numbers,
approximated by rational numbers $p/q$, where we place a congruence-conditional
constraint on the vector $(p,q)$.

</details>


### [25] [Unit lattices of $D_4$-quartic number fields with signature $(2,1)$](https://arxiv.org/abs/2507.06130)
*Sergio Ricardo Zapata Ceballos,Sara Chari,Erik Holmes,Fatemeh Jalalvand,Rahinatou Yuh Njah Nchiwo,Kelly O'Connor,Fabian Ramirez,Sameera Vemulapalli*

Main category: math.NT

TL;DR: 本文研究了$D_4$-四次域的单位格分布，证明其对应$GL_2(\mathbb{Z})\setminus \mathfrak{h}$边界上的超越点，并找到三个显式代数极限点。


<details>
  <summary>Details</summary>
Motivation: 由于数论应用及现有结果匮乏，单位格分布在签名$(2,1)$的$D_4$-四次域中引起关注。

Method: 将单位格视为$GL_2(\mathbb{Z})\setminus \mathfrak{h}$上的点，分析其在基本域边界的性质。

Result: 所有此类单位格对应基本域边界的超越点，并构造了三个代数极限点。

Conclusion: $D_4$-四次域的单位格分布与$GL_2(\mathbb{Z})\setminus \mathfrak{h}$的边界结构存在深刻联系，揭示了新的代数极限点。

Abstract: There has been a recent surge of interest on distributions of shapes of unit
lattices in number fields, due to both their applications to number theory and
the lack of known results.
  In this work we focus on $D_4$-quartic fields with signature $(2,1)$; such
fields have a rank $2$ unit group. Viewing the unit lattice as a point of
$GL_2(\mathbb{Z})\backslash \mathfrak{h}$, we prove that every lattice which
arises this way must correspond to a transcendental point on the boundary of a
certain fundamental domain of $GL_2(\mathbb{Z})\backslash \mathfrak{h}$.
Moreover, we produce three explicit (algebraic) points of
$GL_2(\mathbb{Z})\backslash \mathfrak{h}$ which are limit points of the set of
(points associated to) unit lattices of $D_4$-quartic fields with signature
$(2,1)$.

</details>


### [26] [Addition Automata and Attractors of Digit Systems Corresponding to Expanding Rational Matrices](https://arxiv.org/abs/2507.06158)
*Anjelo Gabriel R. Cruz,Manuel Joseph C. Loquias,Jörg M. Thuswaldner*

Main category: math.NT

TL;DR: 本文研究了具有共线数字集的数字系统$(A,\mathcal{D})$，通过有限状态转换器自动机实现向量加法，并表征了具有有限性性质的系统及其吸引子。


<details>
  <summary>Details</summary>
Motivation: 研究数字系统$(A,\mathcal{D})$的有限性性质和吸引子，特别是当数字集$\mathcal{D}$共线时，如何通过自动机实现向量加法。

Method: 引入有限状态转换器自动机，用于在数字系统$(A,\mathcal{D})$中实现向量$\pm(1,0)^\top$和$\pm(0,1)^\top$的加法。

Result: 表征了所有具有有限性性质的数字系统$(A,\mathcal{D})$，并更广泛地描述了这些数字系统的吸引子。

Conclusion: 通过自动机方法，成功表征了共线数字集数字系统的有限性性质和吸引子，为相关研究提供了新工具。

Abstract: Let $A$ be an expanding $2 \times 2$ matrix with rational entries and
$\mathbb{Z}^2[A]$ be the smallest $A$-invariant $\mathbb{Z}$-module containing
$\mathbb{Z}^2$. Let $\mathcal{D}$ be a finite subset of $\mathbb{Z}^2[A]$ which
is a complete residue system of $\mathbb{Z}^2[A]/A\mathbb{Z}^2[A]$. The pair
$(A,\mathcal{D})$ is called a {\em digit system} with {\em base} $A$ and {\em
digit set} $\mathcal{D}$. It is well known that every vector $x \in
\mathbb{Z}^2[A]$ can be written uniquely in the form \[ x = d_0 + Ad_1 + \cdots
+ A^kd_k + A^{k+1}p, \] with $k\in \mathbb{N}$ minimal, $d_0,\dots,d_k \in
\mathcal{D}$, and $p$ taken from a finite set of {\em periodic elements}, the
so-called {\em attractor} of $(A,\mathcal{D})$. If $p$ can always be chosen to
be $0$ we say that $(A,\mathcal{D})$ has the {\em finiteness property}.
  In the present paper we introduce finite-state transducer automata which
realize the addition of the vectors $\pm(1,0)^\top$ and $\pm(0,1)^\top$ to a
given vector $x\in \mathbb{Z}^2[A]$ in a number system $(A,\mathcal{D})$ with
collinear digit set. These automata are applied to characterize all pairs
$(A,\mathcal{D})$ that have the finiteness property and, more generally, to
characterize the attractors of these digit systems.

</details>


### [27] [Shifting Zeckendorf and Chung-Graham representations](https://arxiv.org/abs/2507.06162)
*Rob Burns*

Main category: math.NT

TL;DR: 重新证明关于Zeckendorf和Chung-Graham表示满足特定条件的整数结果，利用移位算子性质及{\tt Walnut}软件。


<details>
  <summary>Details</summary>
Motivation: 探索整数在Zeckendorf和Chung-Graham表示下的性质，验证已有结果的正确性。

Method: 应用移位算子的数学性质，并借助{\tt Walnut}软件包进行自动化验证。

Result: 成功重新证明了关于特定整数表示条件的若干结果，验证了其有效性。

Conclusion: 通过数学工具与软件辅助，强化了对整数特殊表示形式的理论理解。

Abstract: We re-prove some results about integers whose Zeckendorf and Chung-Graham
representations satisfy certain conditions. We use properties of the shift
operator and use the software package {\tt Walnut}.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [28] [Permutation Models Arising From Topological Ideals](https://arxiv.org/abs/2507.05371)
*Justin Young*

Main category: math.LO

TL;DR: 论文探讨了由动态理想产生的置换模型及其与选择公理片段的关系，并通过拓扑学示例验证了置换模型满足可数选择公理或良序选择公理。


<details>
  <summary>Details</summary>
Motivation: 研究动态理想生成的置换模型，旨在理解其与选择公理片段（如可数选择公理和良序选择公理）的关联。

Method: 通过拓扑学中的具体示例，分析动态理想的性质，并论证这些性质如何影响置换模型中的选择公理片段。

Result: 研究表明，特定的动态理想性质可以确保置换模型满足可数选择公理或良序选择公理。

Conclusion: 该研究为理解置换模型与选择公理片段的关系提供了新的视角，并通过拓扑学示例验证了理论结果。

Abstract: A recent paper by Zapletal arXiv:2404.10612 discusses permutation models of
set theory which arise from dynamical ideals and highlights properties of the
dynamical ideal which relate to fragments of choice in the permutation model.
In this paper, we provide several examples from topology which illustrate using
these connections to argue that the corresponding permutation model satisfies
either the axiom of countable choice or well-ordered choice.

</details>


### [29] [Higher limits of wider systems](https://arxiv.org/abs/2507.05471)
*Jeffrey Bergfalk,Matteo Casarosa*

Main category: math.LO

TL;DR: 论文证明了对于任意$n>1$，存在无限基数$\lambda$使得$\mathrm{lim}^n\,\mathbf{A}_\lambda$为零，解决了[Be17]和[Ban23]中提出的问题。


<details>
  <summary>Details</summary>
Motivation: 研究$\mathrm{lim}^n\,\mathbf{A}_\lambda$在无限基数$\lambda$下的消失情况，这一问题在[Be17]和[Ban23]中被提出，并与多个相关问题密切相关。

Method: 通过分析由基数$\lambda$到自然数集的函数索引的阿贝尔群逆系统$\mathbf{A}_\lambda$，探讨其导出极限的性质。

Result: 证明了对于每个$n>1$，存在无限基数$\lambda$使得$\mathrm{lim}^n\,\mathbf{A}_\lambda$为零，这是最大可能的结果。

Conclusion: 该结果不仅回答了[Be17]和[Ban23]中的问题，还表明在每一个$n>1$的度数下，$\mathrm{lim}^n\,\mathbf{A}_\lambda$都可以在无限基数$\lambda$下消失。

Abstract: Write $\mathbf{A}_\lambda$ for what might be described as the most elementary
nontrivial inverse system of abelian groups indexed by the functions from the
cardinal $\lambda$ to the set of natural numbers. The question of whether for
any fixed $n$ the derived limit $\mathrm{lim}^n\,\mathbf{A}_\lambda$ may vanish
for only a nonempty subset of the class of infinite cardinals $\lambda$ is
recorded in both [Be17] and [Ban23], and bears closely on several related
further ones. We answer this question in the affirmative; in fact, we show the
maximal possibility, namely that this can simultaneously happen in every degree
$n>1$.

</details>


### [30] [A Proof Theory for Profinite Modal Algebras](https://arxiv.org/abs/2507.06007)
*Matteo De Berardinis,Silvio Ghilardi*

Main category: math.LO

TL;DR: 本文探讨了profinite $L$-代数与无穷命题模态演算的Lindenbaum代数之间的关系，并研究了演算的句法性质与profinite $L$-代数对立范畴的规则性/精确性之间的对应关系。


<details>
  <summary>Details</summary>
Motivation: 基于先前关于profinite $L$-代数在$\mathbf{Set}$上的单子性结果，作者试图将其表示为无穷命题模态演算的Lindenbaum代数。

Method: 作者将Maehara-Takeuti的无穷sequent演算$\mathbf{LK}$扩展为模态演算，并分析其句法性质与profinite $L$-代数对立范畴性质的对应关系。

Result: 成功建立了profinite $L$-代数与特定无穷模态演算的联系，并揭示了演算句法性质与代数范畴性质的对应规律。

Conclusion: 该研究为profinite $L$-代数提供了新的逻辑表示方法，并深化了对模态演算与代数结构关系的理解。

Abstract: In a previous paper, we showed that profinite $L$-algebras (where $L$ is a
variety of modal algebras generated by its finite members) are monadic over
$\mathbf{Set}$. This monadicity result suggests that profinite $L$-algebras
could be presented as Lindenbaum algebras for propositional theories in
infinitary versions of propositional modal calculi. In this paper we identify
such calculi as modal enrichments of Maehara-Takeuti's infinitary extension of
the sequent calculus $\mathbf{LK}$. We also investigate correspondences between
syntactic properties of the calculi and regularity/exactness properties of the
opposite category of profinite $L$-algebras.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [31] [Radon Partitions of Random Gaussian Polytopes](https://arxiv.org/abs/2507.05449)
*Moshe White*

Main category: math.CO

TL;DR: 本文研究了Radon分割的概率框架，通过定义Radon多面体并利用圆锥运动学公式和内在体积，推导了随机点集形成Radon分割的概率表达式。


<details>
  <summary>Details</summary>
Motivation: 研究Radon分割的概率特性，为解决如Reay松弛Tverberg猜想等开放性问题提供新视角。

Method: 为每个点集定义对应的Radon多面体，利用圆锥运动学公式和内在体积推导概率表达式，部分情况下获得闭合公式。

Result: 得到了$N$个$d$维正态分布随机点形成Radon分割的概率表达式，部分情况有闭合解，但通常需要重复积分。

Conclusion: 该概率框架为Radon分割相关开放问题提供了新的研究工具，尤其在Reay松弛Tverberg猜想等问题的应用上具有潜力。

Abstract: In this paper we study a probabilistic framework for Radon partitions, where
our points are chosen independently from the $d$-dimensional normal
distribution. For every point set we define a corresponding Radon polytope,
which encodes all information about Radon partitions of our set - with Radon
partitions corresponding to faces of the polytope. This allows us to derive
expressions for the probability that a given partition of $N$ randomly chosen
points in $\mathbb{R}^d$ forms a Radon partition. These expressions involve
conic kinematic formulas and intrinsic volumes, and in general require repeated
integration, though we obtain closed formulas in some cases. This framework can
provide new perspectives on open problems that can be formulated in terms of
Radon partitions, such as Reay's relaxed Tverberg conjecture.

</details>


### [32] [Counting with two-level polynomials](https://arxiv.org/abs/2507.05473)
*Tristram Bogart,Kevin Woods*

Main category: math.CO

TL;DR: 该研究探讨了具有两个参数$n$和$q$的组合计数函数，证明了这些函数在固定$q$时为(拟)多项式，并展示了其代数性质及应用。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解组合计数函数在双参数$n$和$q$下的行为，特别是当$q$变化时多项式的阶数和主导系数的变化规律。

Method: 方法包括定义双层次多项式，阐述其基本代数性质，并提出一个框架来证明函数属于此类多项式。

Result: 结果表明，多种组合计数函数（如图的色多项式、整数分区、棋盘非攻击棋子放置、Sidon集及Sheffer序列）均为双层次多项式。

Conclusion: 结论指出，双层次多项式在组合数学多个领域中具有广泛适用性，为相关计数问题提供了统一的数学框架。

Abstract: We examine combinatorial counting functions with two parameters, $n$ and $q$.
For fixed $q$, these functions are (quasi-)polynomial in $n$. As $q$ varies,
the degree of this polynomial is itself polynomial in $q$, as are the leading
coefficients. We carefully define these two-level polynomials, lay out their
basic algebraic properties, and provide a schema for showing a function is a
two-level polynomial. Using the schema, we prove that a variety of counting
functions arising in different areas of combinatorics are two-level
polynomials. These include chromatic polynomials for many infinite families of
graphs, partitions of an integer into a given number of parts, placing
non-attacking chess pieces on a board, Sidon sets, and Sheffer sequences
(including binomial type and Appell sequences).

</details>


### [33] [Total coloring graphs with large minimum degree](https://arxiv.org/abs/2507.05548)
*Owen Henderschedt,Jessica McDonald,Songling Shan*

Main category: math.CO

TL;DR: 证明了对于所有$\varepsilon>0$，存在正整数$n_0$，使得当图$G$的顶点数$n\geq n_0$且最小度$\delta(G)\geq\tfrac{1}{2}(1 + \varepsilon)n$时，$G$满足全着色猜想，即$\chi_T(G)\leq \Delta(G)+2$。


<details>
  <summary>Details</summary>
Motivation: 研究全着色猜想在特定条件下的成立性，扩展图论中关于图着色问题的理论成果。

Method: 通过设定参数$\varepsilon$和$n_0$，分析图的最小度$\delta(G)$与顶点数$n$的关系，验证全着色猜想的成立条件。

Result: 当图$G$的顶点数足够大且最小度满足$\delta(G)\geq\tfrac{1}{2}(1 + \varepsilon)n$时，全着色猜想成立。

Conclusion: 该研究为全着色猜想提供了新的理论支持，证明了在特定条件下图的着色数上界成立。

Abstract: We prove that for all $\varepsilon>0$, there exists a positive integer $n_0$
such that if $G$ is a graph on $n\geq n_0$ vertices with
$\delta(G)\geq\tfrac{1}{2}(1 + \varepsilon)n$, then $G$ satisfies the Total
Coloring Conjecture, that is, $\chi_T(G)\leq \Delta(G)+2$.

</details>


### [34] [Signless Laplacian index conditions for doubly chorded cycles in graphs with given order](https://arxiv.org/abs/2507.05570)
*Jin Cai,Bo Zhou*

Main category: math.CO

TL;DR: 本文证明当$n\ge 5$时，若图的阶数为$n$且无符号拉普拉斯指数超过特定阈值，则该图必含双弦环（两弦共点），除非属于两种特例图。


<details>
  <summary>Details</summary>
Motivation: 研究图的谱性质与结构特征（如双弦环存在性）之间的关联，拓展代数图论的应用边界。

Method: 通过分析图的阶数$n$与无符号拉普拉斯指数$q(G)$的数值关系，结合极值图论方法进行结构判定。

Result: 确立$n\ge 5$时$q(G)$的临界条件，证明除两种特例外，满足条件的图必然存在共点双弦的环结构。

Conclusion: 该结果为无符号拉普拉斯谱理论提供了新的结构判据，揭示了特定谱范围下图形的组合性质。

Abstract: In this paper, we show that for a graph of order $n$, where $n\ge 5$, if the
signless Laplacian index is larger than or equal to certain value depending on
$n$, then the graph contains a doubly chorded cycle, where the chords incident
to a common vertex, unless it is two specified graphs.

</details>


### [35] [Divided difference operators for Hessenberg representations](https://arxiv.org/abs/2507.05614)
*Mathieu Guay-Paquet*

Main category: math.CO

TL;DR: 本文研究了A型正则半单Hessenberg簇的等变上同调环，通过Tymoczko点作用将其表示为对称群的扭曲表示，并利用色准对称函数和分差算子进行表示分解。


<details>
  <summary>Details</summary>
Motivation: 探讨正则半单Hessenberg簇的等变上同调环的结构及其与对称群表示的联系，旨在通过色准对称函数揭示其组合性质。

Method: 使用分差算子对等变上同调环进行表示分解，结合Tymoczko点作用，将问题转化为色准对称函数的模关系范畴化。

Result: 证明了该表示可分解为子表示的直和，且分解过程范畴化了色准对称函数之间的模关系。

Conclusion: 通过分差算子和模关系范畴化，为A型Hessenberg簇的等变上同调环表示提供了新的组合解释与结构分解方法。

Abstract: The equivariant cohomology ring of a regular semisimple Hessenberg variety in
type A is a free module over the equivariant cohomology ring of a point. When
equipped with Tymoczko's dot action, it becomes a twisted representation of the
symmetric group, and the character of this representation is given by the
chromatic quasisymmetric function of an indifference graph. In this note, we
use divided difference operators to decompose this representation as a direct
sum of sub-representations in a way that categorifies the modular relation
between chromatic quasisymmetric functions.

</details>


### [36] [A simple layered-wheel-like construction](https://arxiv.org/abs/2507.06169)
*Maria Chudnovsky,David Fischer,Sepehr Hajebi,Sophie Spirkl,Bartosz Walczak*

Main category: math.CO

TL;DR: 本文提出了一种简单构造具有任意大树宽的层轮状图的方法，解决了树宽障碍物表征的开放问题，并首次提供了具有任意大围长的反例，反驳了Trotignon的猜想。


<details>
  <summary>Details</summary>
Motivation: 近年来，表征树宽和路径宽的诱导子图障碍物引起了广泛关注。虽然路径宽的情况已解决，但树宽的情况仍开放，且先前研究已将该问题简化为理解层轮状图。本文旨在提供一种简单的层轮状图构造方法，满足多个先前构造未能同时实现的性质。

Method: 本文提出了一种简单的构造方法，生成具有任意大树宽的层轮状图。该方法的关键在于：(a) 高度数顶点可以任意远离；(b) 围长可以任意大；(c) 所有外弦诱导子图的树宽有绝对常数上界。

Result: 构造的层轮状图满足三个显著特性：(a)、(b)和(c)，且首次提供了可以具有任意大围长的反例，反驳了Trotignon的猜想。与先前构造相比，本文方法在多个方面具有优势。

Conclusion: 本文的构造不仅简化了层轮状图的生成，还首次实现了多个理想性质的组合，为树宽障碍物的研究提供了新的视角，并解决了Trotignon猜想的反例问题。

Abstract: In recent years, there has been significant interest in characterizing the
induced subgraph obstructions to bounded treewidth and pathwidth. While this
has recently been resolved for pathwidth, the case of treewidth remains open,
and prior work has reduced the problem to understanding the layered-wheel-like
obstructions -- graphs that contain large complete minor models with each
branching set inducing a path; exclude large walls as induced minors; exclude
large complete bipartite graphs as induced minors; and exclude large complete
subgraphs.
  There are various constructions of such graphs, but they are all rather
involved. In this paper, we present a simple construction of layered-wheel-like
graphs with arbitrarily large treewidth. Three notable features of our
construction are: (a) the vertices of degree at least four can be made to be
arbitrarily far apart; (b) the girth can be made to be arbitrarily large; and
(c) every outerstring induced subgraph of the graphs from our construction has
treewidth bounded by an absolute constant. In contrast, among several
previously known constructions of layered wheels, none achieves (a); at most
one satisfies either (b) or (c); and none satisfies both (b) and (c)
simultaneously.
  In particular, this is related to a former conjecture of Trotignon, that
every graph with large enough treewidth, excluding large walls and large
complete bipartite graphs as induced minors, and large complete subgraphs, must
contain an outerstring induced subgraph of large treewidth. Our construction
provides the first counterexample to this conjecture that can also be made to
have arbitrarily large girth.

</details>


### [37] [Off-Diagonal Ramsey Numbers for Linear Hypergraphs](https://arxiv.org/abs/2507.05641)
*Xiaoyu He,Jiaxi Nie,Yuval Wigderson,Hung-Hsun Hans Yu*

Main category: math.CO

TL;DR: 本文研究了k-一致超图的非对角Ramsey数$r(H, K_n^{(k)})$，证明在$k\ge4$时存在线性k-一致超图H使得该数呈超多项式增长。


<details>
  <summary>Details</summary>
Motivation: 近期Conlon等人否定了关于$r(H, K_n^{(3)})$总是多项式增长的猜想，本文旨在探究更高一致性下可能出现的更大增长率。

Method: 通过构造特定的线性k-一致超图H，分析其与完全k-一致超图$K_n^{(k)}$的Ramsey数下界。

Result: 对于任意常数$C>0$和$k\ge4$，存在线性k-一致超图H满足$r(H,K_n^{(k)}) \geq \twr_{k-2}(2^{(\log n)^C})$。

Conclusion: 在$k\ge4$的一致性下，非对角Ramsey数可以呈现远超多项式的增长率，突破了三维情形的认知边界。

Abstract: We study off-diagonal Ramsey numbers $r(H, K_n^{(k)})$ of $k$-uniform
hypergraphs, where $H$ is a fixed linear $k$-uniform hypergraph and $K_n^{(k)}$
is complete on $n$ vertices. Recently, Conlon et al.\ disproved the folklore
conjecture that $r(H, K_n^{(3)})$ always grows polynomially in $n$. In this
paper we show that much larger growth rates are possible in higher uniformity.
In uniformity $k\ge 4$, we prove that for any constant $C>0$, there exists a
linear $k$-uniform hypergraph $H$ for which $$r(H,K_n^{(k)}) \geq
\twr_{k-2}(2^{(\log n)^C}).$$

</details>


### [38] [When does a tree activate the random graph?](https://arxiv.org/abs/2507.05697)
*Asaf Cohen Antonir,Yuval Peled,Asaf Shapira,Mykhaylo Tyomkyn,Maksim Zhukovskii*

Main category: math.CO

TL;DR: 该论文揭示了弱饱和问题与团复形拓扑学的新联系，提出了在代数工具效率不足时证明紧下界的方法，并确定了随机图中$K_3$-饱和树存在的临界概率。


<details>
  <summary>Details</summary>
Motivation: 研究弱饱和数$\mathrm{wsat}(G,F)$的下界是极值组合学中的经典问题，过去40年发展了多种代数工具，但在某些情况下效率不足，需要新的方法。

Method: 通过建立弱饱和与团复形拓扑学的新联系，结合Gromov双曲群的局部到全局原理，开发了拓扑学方法来确定临界概率。

Result: 证明了在随机图$G_{n,p}$中，$K_3$-饱和树存在的临界概率为$n^{-1/3-o(1)}$，并对直径不超过$n^{c}$的树确定了临界概率的常数因子。

Conclusion: 新建立的拓扑学连接不仅解决了Kor\'andi和Sudakov提出的问题，还改进了Kahle关于二维团复形简单连通性阈值概率的上界。

Abstract: Let $F$ and $G$ be two graphs. A spanning subgraph $H$ of $G$ is called
weakly $F$-saturated if one can add to $H$ the edges of $G \setminus H$ in some
order, so that whenever a new edge is added, a new copy of $F$ is formed.
Obtaining lower bounds for the minimum size $\mathrm{wsat}(G,F)$ of such an $H$
is a classical problem in extremal combinatorics. In particular, in the past 40
years, various algebraic tools have been developed to prove lower bounds on the
weak saturation number $\mathrm{wsat}(G,F)$. Our paper uncovers a new
connection of weak saturation to topology of clique complexes, that allows to
prove tight lower bounds in some cases when the algebraic tools are not
efficient.
  It is easy to see that the smallest $K_3$-saturating graphs in $K_n$ are
trees, thus $\mathrm{wsat}(K_n,K_3)=n-1$. In 2017, Kor\'andi and Sudakov proved
that this is also the case in dense random graphs $G\sim G_{n,p}$,
$p=\mathrm{const}\in(0,1)$, and posed the question of determining the smallest
$p$ for which $G_{n,p}$ contains a $K_3$-saturating tree with high probability.
Using the new topological connection, we show that this critical $p$ is of
order $n^{-1/3-o(1)}$.
  Inspired by Gromov's local-to-global principle for hyperbolic groups, we
further develop our topological approach and determine the critical probability
up to a constant factor, for trees with diameter at most $n^{c}$, for some
$c>0$.
  The new connection also enables us to improve the best known upper bound on
the threshold probability for simple connectivity of the 2-dimensional clique
complex of $G_{n,p}$, due to Kahle.

</details>


### [39] [Longest increasing subsequences for distributions with atoms, and an inhomogeneous Hammersley process](https://arxiv.org/abs/2507.05775)
*Anne-Laure Basdevant,Lucas Gerin,Maxime Marivain*

Main category: math.CO

TL;DR: 研究离散随机变量最长递增子序列长度$L_n$的渐进行为，发现其增长率介于$\mathcal{O}(1)$和$o(\sqrt{n})$之间，具体取决于分布的尾部行为。


<details>
  <summary>Details</summary>
Motivation: Hammersley和Versik-Kerov的著名结果表明，对于连续随机变量，$L_n$的增长率为$2\sqrt{n}$。本文旨在探讨具有原子分布的随机变量$L_n$的渐进行为。

Method: 通过将离散随机变量与离散时间连续空间的Hammersley过程的不均匀版本耦合，利用变分问题刻画$L_n$的渐进阶，并提供经典分布的显式估计。

Result: 研究发现，离散情况下的$L_n$增长率范围广泛，从$\mathcal{O}(1)$到$o(\sqrt{n})$不等，具体取决于分布的尾部行为。此外，可以轻松推导出任意分布的$L_n$渐进性质。

Conclusion: 与连续情况不同，离散随机变量的最长递增子序列长度$L_n$表现出多样化的增长率，这为理解离散分布下的渐进行为提供了新的视角。

Abstract: A famous result by Hammersley and Versik-Kerov states that the length $L_n$
of the longest increasing subsequence among $n$ iid continuous random variables
grows like $2\sqrt{n}$. We investigate here the asymptotic behavior of $L_n$
for distributions with atoms. For purely discrete random variables, we
characterize the asymptotic order of $L_n$ through a variational problem and
provide explicit estimates for classical distributions. The proofs rely on a
coupling with an inhomogeneous version of the discrete-time continuous-space
Hammersley process. This reveals that, in contrast to the continuous case, the
discrete setting exhibits a wide range of growth rates between $\mathcal{O}(1)$
and $o(\sqrt{n})$, depending on the tail behavior of the distribution. We can
then easily deduce the asymptotics of $L_n$ for a completely arbitrary
distribution.

</details>


### [40] [On cubic vertex-transitive graphs of given girth](https://arxiv.org/abs/2507.05821)
*Ted Dobson,Ademir Hujdurović,Wilfried Imrich,Ronald Ortner*

Main category: math.CO

TL;DR: 本文研究了具有两个边轨道的五次围长立方顶点传递图的区分成本，证明其区分成本为2，并排除了无限三弧传递六次围长立方图的存在。


<details>
  <summary>Details</summary>
Motivation: 目前对于具有两个边轨道且围长大于4的立方顶点传递图，其区分成本及存在性几乎未知。本文旨在填补这一研究空白。

Method: 通过图论与群论方法，分析立方顶点传递图的自同构群性质，并构造特定区分集。

Result: 证明了五次围长的立方顶点传递图（具有两个边轨道）的区分成本为2，并证实不存在无限三弧传递的六次围长立方图。

Conclusion: 研究扩展了对高围长立方顶点传递图区分成本的理解，为后续研究提供了理论基础。

Abstract: A set of vertices of a graph is distinguishing if the only automorphism that
preserves it is the identity. The minimal size of such sets, if they exist, is
the distinguishing cost. The distinguishing costs of vertex transitive cubic
graphs are well known if they are 1-arc-transitive, or if they have two edge
orbits and either have girth 3 or vertex-stabilizers of order 1 or 2.
  There are many results about vertex-transitive cubic graphs of girth 4 with
two edge orbits, but for larger girth almost nothing is known about %the
existence or the distinguishing costs of such graphs. We prove that cubic
vertex-transitive graphs of girth 5 with two edge orbits have distinguishing
cost 2, and prove the non-existence of infinite 3-arc-transitive cubic graphs
of girth 6.

</details>


### [41] [A Study of the Binary and Boolean Rank of Matrices with Small Constant Real Rank](https://arxiv.org/abs/2507.05824)
*Michal Parnas,Adi Shraibman*

Main category: math.CO

TL;DR: 本文研究了实数秩较小的$0,1$矩阵的二元秩和布尔秩，证明了当实数秩$d$为小常数时，实数秩与二元秩、布尔秩之间的差距也是小常数。


<details>
  <summary>Details</summary>
Motivation: 探讨实数秩、二元秩和布尔秩之间的关系是一个重要的开放性问题，特别是在实数秩较小的矩阵中。

Method: 结合组合数学和代数技术，并借助计算机程序，对实数秩$1 \leq d \leq 4$的矩阵进行了分析。

Result: 给出了实数秩$1 \leq d \leq 4$的矩阵的二元秩和布尔秩的紧致上下界，并确定了最大隔离集的大小。对于$d=3,4$，证明了循环矩阵是唯一满足特定条件的矩阵。

Conclusion: 研究结果可以等价地解释为在二分图中寻找覆盖边所需的最小双团数，为相关领域提供了新的理论支持。

Abstract: We initiate the study of the binary and Boolean rank of $0,1$ matrices that
have a small rank over the reals. The relationship between these three rank
functions is an important open question, and here we prove that when the real
rank $d$ is a small constant, the gap between the real and the binary and
Boolean rank is a small constant. We give tight upper and lower bounds on the
Boolean and binary rank of matrices with real rank $1 \leq d \leq 4$, as well
as determine the size of the maximal isolation set in each case. Furthermore,
we prove that for $d = 3,4$, the circulant matrix defined by a row with $d-1$
consecutive ones followed by $d-1$ zeros, is the only matrix of size
$(2d-2)\times (2d-2)$ with real rank $d$ and Boolean and binary rank and
maximal isolation set of size $2d-2$, and this matrix achieves the maximal gap
possible between the real and the binary and Boolean rank for these values of
$d$.
  Our results can also be interpreted in other equivalent terms, such as
finding the minimal number of bicliques needed to partition or cover the edges
of a bipartite graph whose reduced adjacency matrix has real rank $1 \leq d
\leq 4$. We use a combination of combinatorial and algebraic techniques
combined with the assistance of a computer program.

</details>


### [42] [Judicious Partitions in Edge-Weighted Graphs with Bounded Maximum Weighted Degree](https://arxiv.org/abs/2507.05827)
*G. Gutin,M. A. Nielsen,A. Yeo,Y. Zhou*

Main category: math.CO

TL;DR: 本文研究了边加权图的公平k划分问题，提出了同时优化最大子图权重和割权重的紧界，首次给出了k=3时的完全紧界，并证明了一般情况下k≥4时需引入低阶项。


<details>
  <summary>Details</summary>
Motivation: 探索边加权图中同时最小化最大诱导子图权重和割权重的k划分问题，填补k=3时理论空白，并验证k≥4时的限制条件。

Method: 通过组合分析和极值图论技术，建立k=2和k=3的紧界，构造性证明一般情况下的权重分配不等式$\max w(G[V_i]) \leq \frac{w(G)}{k^2} + \frac{k-1}{2k^2}\Delta_w(G)$。

Result: 1) 首次给出k=3时完全紧界 2) 证明k≥4需低阶修正项 3) 提出普适紧界公式并验证其最优性 4) 发现最大加权度$\Delta_w(G)$的关键影响。

Conclusion: 该研究系统解决了2-3划分问题，揭示了k≥4的复杂性，提出的权重分配公式为后续研究奠定了基础，并启发关于高阶划分的猜想。

Abstract: In this paper, we investigate bounds for the following judicious
$k$-partitioning problem: Given an edge-weighted graph $G$, find a
$k$-partition $(V_1,V_2,\dots ,V_k)$ of $V(G)$ such that the total weight of
edges in the heaviest induced subgraph, $\max_{i=1}^k w(G[V_i])$, is minimized.
In our bounds, we also take into account the weight $w(V_1,V_2,\dots,V_k)$ of
the cut induced by the partition (i.e., the total weight of edges with
endpoints in different parts) and show the existence of a partition satisfying
tight bounds for both quantities simultaneously. We establish such tight bounds
for the case $k=2$ and, to the best of our knowledge, present the first (even
for unweighted graphs) completely tight bound for $k=3$. We also show that, in
general, these results cannot be extended to $k \geq 4$ without introducing an
additional lower-order term, and we propose a corresponding conjecture.
Moreover, we prove that there always exists a $k$-partition satisfying $\max
\left\{ w(G[V_i]) : i \in [k] \right\} \leq \frac{w(G)}{k^2} + \frac{k -
1}{2k^2} \Delta_w(G),$ where $\Delta_w(G)$ denotes the maximum weighted degree
of $G$. This bound is tight for every integer $k\geq 2$.

</details>


### [43] [Hamiltonicity and structure of connected biclaw-free graphs](https://arxiv.org/abs/2507.05836)
*Alexey Pokrovskiy,Xiaoan Yang*

Main category: math.CO

TL;DR: 证明了对于足够大的$d$，所有平衡二分、连通且无双爪的图，若最小度$\geq d$，则具有哈密顿性，验证了Flandrin等人的猜想。


<details>
  <summary>Details</summary>
Motivation: 研究图的哈密顿性质是图论中的核心问题之一，验证Flandrin等人关于特定图类哈密顿性的猜想。

Method: 通过分析平衡二分、连通且无双爪的图的性质，结合最小度$\geq d$的条件，进行理论证明。

Result: 证明了当$d$足够大时，满足条件的图必定是哈密顿图。

Conclusion: 该结果不仅验证了Flandrin等人的猜想，还为进一步研究图的哈密顿性质提供了新的理论支持。

Abstract: We show that for sufficiently large $d$, every balanced bipartite, connected
biclaw-free graph with minimum degree $\geq d$ is Hamiltonian. This confirms a
conjecture of Flandrin, Fouquet, and Li.

</details>


### [44] [Bounded diameter monochromatic component covers](https://arxiv.org/abs/2507.05842)
*Alexey Pokrovskiy*

Main category: math.CO

TL;DR: 证明了Ryser猜想与Mili\'cevi\'c猜想等价，并得出Mili\'cevi\'c猜想在$r=5$时成立的新结果。


<details>
  <summary>Details</summary>
Motivation: 受Austin分析问题的启发，Mili\'cevi\'c提出了比Ryser猜想更强的猜想——每个$r$边着色完全图可被$r-1$棵直径有界的单色树覆盖。

Method: 通过数学证明展示两个猜想的等价性，并推导相关推论。

Result: 证明了两个猜想等价，并首次确认Mili\'cevi\'c猜想在$r=5$时成立，同时拓展了DeBiasio-Kamel-McCourt-Sheats对非完全图的推广结果。

Conclusion: 研究不仅统一了两个重要猜想，还为相关领域提供了新的理论支撑，尤其解决了$r=5$的关键情形。

Abstract: Ryser conjectured that every $r$-edge-coloured complete graph can be covered
by $r-1$ monochromatic trees. Motivated by a question of Austin in analysis,
Mili\'cevi\'c predicted something stronger -- that every $r$-edge-coloured
complete graph can be covered by $r-1$ monochromatic trees \emph{of bounded
diameter}. Here we show that the two conjectures are equivalent. As immediate
corollaries we obtain new results about Mili\'cevi\'c's Conjecture, most
notably that it is true for $r=5$. We also obtain several new cases of a
generalization of Mili\'cevi\'c's Conjecture to non-complete graphs due to
DeBiasio-Kamel-McCourt-Sheats.

</details>


### [45] [Tropical Donagi theorem](https://arxiv.org/abs/2507.05987)
*Felix Röhrle,Thomas Saillez*

Main category: math.CO

TL;DR: 本文探讨了热带四边形的构造，证明了与Donagi定理类似的热带版本，确认了先前研究中的推测，并揭示了热带Prym-Torelli态射的非单射性新结果。


<details>
  <summary>Details</summary>
Motivation: 研究热带$n$-边形构造在$n=4$时的性质，验证先前关于四边形构造三重性及Prym簇保持的推测，并探索热带Prym-Torelli态射的非单射性。

Method: 通过热带几何方法，分析四边形的构造，并证明热带版本的Donagi定理，同时考察构造在边收缩下的行为。

Result: 证明了热带四边形构造具有三重性并保持Prym簇，确认了热带Prym-Torelli态射的非单射性，并发现构造在边收缩下表现不佳。

Conclusion: 热带四边形构造验证了Donagi定理的热带类比，但因其在边收缩下的不良行为，阻碍了直接的模理论视角。

Abstract: The tropical $n$-gonal construction was introduced in recent work by the
first author and D.~Zakharov and structural results for $n = 2,3$ were
established. In this article we explore the construction for $n = 4$ and prove
a tropical analogue of Donagi's theorem which states that the tetragonal
construction is a triality which preserves Prym varieties. This confirms the
speculations in previous work and establishes new results on the
non-injectivity of the tropical Prym-Torelli morphism. Finally, we demonstrate
that the tropical $n$-gonal construction is poorly behaved under edge
contractions, thus preventing any immediate moduli-theoretic perspective.

</details>


### [46] [A non-face characterization of spheres on few vertices](https://arxiv.org/abs/2507.06120)
*Shuai Huang,Jasper Miller,Daniel Rose-Levine,Steven Simon*

Main category: math.CO

TL;DR: 本文提出了一个关于在$d+4$顶点上的单纯$d$-球面的简单特征化方法，基于最小非面族的交集模式。


<details>
  <summary>Details</summary>
Motivation: 研究单纯复形在特定顶点数下的球面特征，旨在简化复杂结构的识别标准。

Method: 通过分析单纯复形的最小非面族$\mathcal{F}=\{A_0,\ldots, A_{n-1}\}$的交集模式，特别是交替$(\frac{n-1}{2})$-重交集的分割性质。

Result: 证明了单纯复形$\Sigma$是$d$-球面的充要条件为：$n\geq 3$为奇数，连续$A_i$不相交，且交替交集分割顶点集$[d+4]$。

Conclusion: 该特征化方法为识别单纯$d$-球面提供了一种简洁而有效的标准，适用于顶点数为$d+4$的情况。

Abstract: We give a relatively simple characterization of simplicial $d$-spheres on
$d+4$ vertices; our criteria are in terms of the intersection patterns of a
simplicial complex's minimal non-faces. Namely, let $\Sigma$ be a simplicial
complex with vertex set $[d+4]$ and let $\mathcal{F}=\{A_0,\ldots, A_{n-1}\}$
be its family of minimal non-faces, indices taken in $\mathbb{Z}_n$. Then
$\Sigma$ is a $d$-sphere if and only if the following hold: $n\geq 3$ is odd,
successive $A_i$ are disjoint, and the alternating $(\frac{n-1}{2})$-fold
intersections $A_i\cap A_{i+2} \cap A_{i+4} \cap \cdots \cap A_{i+n-3}$
partition $[d+4]$.

</details>


### [47] [On the multiplicity of 1 as a Laplacian eigenvalue of a graph](https://arxiv.org/abs/2507.06184)
*Fenglei Tian,Dein Wong*

Main category: math.CO

TL;DR: 该论文研究了图的拉普拉斯特征值1的重数，通过引入简化图的概念，推导出重数的计算公式，并对不含悬挂路径P3的简化树和单环图给出了重数的上界及达到上界的图的结构特征。


<details>
  <summary>Details</summary>
Motivation: 研究图的拉普拉斯特征值1的重数对于理解图的结构特性具有重要意义。通过分析简化图和删除悬挂顶点对重数的影响，可以更深入地揭示图的代数性质与结构之间的关系。

Method: 首先证明了$m_{L(G)}(1)=p(G)-q(G)+m_{L(\overline{G})}(1)$，其中$\overline{G}$是简化图。然后，针对不含悬挂路径$P_3$的简化树和单环图，推导了重数的上界，并完全刻画了达到上界的图的结构。

Result: 对于不含悬挂路径$P_3$的简化树$T$，证明了$m_{L(T)}(1)\leq \frac{n-6}{4}$，并完全刻画了达到上界的树。对于不含悬挂路径$P_3$的简化单环图$G$，得到了$m_{L(G)}(1)\leq \frac{n}{4}$，并确定了所有达到上界的单环图。

Conclusion: 通过引入简化图的概念，论文成功推导了拉普拉斯特征值1的重数的计算公式，并对特定类型的图给出了重数的上界及其结构特征。这些结果为图的代数性质的进一步研究提供了新的工具和视角。

Abstract: Let $G$ be a graph with $p(G)$ pendant vertices and $q(G)$ quasi-pendant
vertices. Denote by $m_{L(G)}(\lambda)$ the multiplicity of $\lambda$ as a
Laplacian eigenvalue of $G$. Let $\overline{G}$ be the reduced graph of $G$,
which can be obtained from $G$ by deleting some pendant vertices such that
$p(\overline{G})=q(\overline{G})$. We first prove that
$m_{L(G)}(1)=p(G)-q(G)+m_{L(\overline{G})}(1)$. Since deleting pendant path
$P_3$ does not change the multiplicity of Laplacian eigenvalue 1 of a graph, we
further focus on reduced graphs without pendant path $P_3$. Let $T$ be a
reduced tree on $n(\geq 6)$ vertices without pendant path $P_3$, then it is
proved that $$m_{L(T)}(1)\leq \frac{n-6}{4},$$ and all the trees attaining the
upper bound are characterized completely. As an application, for a reduced
unicyclic graph $G$ of order $n\geq 10$ without pendant path $P_3$, we get
$$m_{L(G)}(1)\leq \frac{n}{4},$$ and all the unicyclic graphs attaining the
upper bound are determined completely.

</details>


### [48] [A proof of the $q$-Foulkes conjecture for Gaussian coefficients when $a$ divides $c$](https://arxiv.org/abs/2507.06220)
*Álvaro Gutiérrez,Michał Szwej*

Main category: math.CO

TL;DR: 本文针对Foulkes猜想的多个推广版本，在特殊线性李代数$\mathfrak{sl}_2(\mathbb{C})$下，证明了当$a$整除$c$或$d$时，表示$\mathrm{Sym}^a\mathrm{Sym}^b\mathbb{C}^2$是$\mathrm{Sym}^c\mathrm{Sym}^d\mathbb{C}^2$的子表示。这是该猜想家族中首个适用于无限多个$a$值的证明。


<details>
  <summary>Details</summary>
Motivation: Foulkes猜想及其推广版本在表示理论中具有重要意义，但此前仅对$a=2$和$a=3$的情况有证明。本研究旨在扩展证明范围，覆盖无限多个$a$值的情况，特别是当$a$为素数时。

Method: 研究集中在特殊线性李代数$\mathfrak{sl}_2(\mathbb{C})$的表示理论上，通过假设$a$整除$c$或$d$，简化了证明过程。这种方法利用了对称幂表示的性质，避免了复杂的通用证明。

Result: 成功证明了在$a$整除$c$或$d$的条件下，$\mathrm{Sym}^a\mathrm{Sym}^b\mathbb{C}^2$确实是$\mathrm{Sym}^c\mathrm{Sym}^d\mathbb{C}^2$的子表示。这一结果首次覆盖了无限多个$a$值，包括所有素数$a$。

Conclusion: 本研究不仅验证了Foulkes猜想在特定条件下的正确性，还为更广泛的推广版本提供了新的证明思路，特别是在$a$为素数时的无限情况，为未来的研究奠定了基础。

Abstract: Foulkes' conjecture has several generalisations due to Doran,
Abdesselam--Chipalkatti, Bergeron, and Troyka. For the special linear Lie
algebra $\mathfrak{sl}_2(\mathbb{C})$, these assert that given $a \le c \le d
\le b$ with $ab=cd$, the $\mathfrak{sl}_2(\mathbb{C})$-representation
$\mathrm{Sym}^a\mathrm{Sym}^b\mathbb{C}^2$ is a subrepresentation of
$\mathrm{Sym}^c\mathrm{Sym}^d\mathbb{C}^2$. We present a short proof in the
case where $a$ divides $c$ or $d$, which includes all prime values of $a$. This
is the first proof in this family of conjectures valid for infinitely many
values of $a$; previously only the cases $a=2$ and $a=3$ were known.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [49] [Layered, Overlapping, and Inconsistent: A Large-Scale Analysis of the Multiple Privacy Policies and Controls of U.S. Banks](https://arxiv.org/abs/2507.05415)
*Lu Xian,Van Tran,Lauren Lee,Meera Kumar,Yichen Zhang,Florian Schaub*

Main category: cs.CR

TL;DR: 美国银行隐私政策存在多重性与不一致性，可能削弱法律透明度目标，呼吁政策改革与协调。


<details>
  <summary>Details</summary>
Motivation: 研究美国银行如何实施隐私政策及控制措施，以应对GLBA、联邦隐私政策要求及CCPA，特别关注营销相关第三方数据共享的披露与控制。

Method: 收集了美国2067家最大银行的隐私政策，其中45.3\%提供多份政策，分析披露与控制措施的不一致性。

Result: 发现银行在同一机构内的披露与控制存在频繁且令人担忧的不一致，例如GLBA通知中声称不共享数据，却在其他地方披露共享行为，或未披露使用第三方营销/广告cookie。

Conclusion: 当前政策要求（如GLBA通知）可能未达到预期目标，需改革并协调联邦与州法律的隐私政策与控制要求。

Abstract: Privacy policies are often complex. An exception is the two-page standardized
notice that U.S. financial institutions must provide under the
Gramm-Leach-Bliley Act (GLBA). However, banks now operate websites, mobile
apps, and other services that involve complex data sharing practices that
require additional privacy notices and do-not-sell opt-outs. We conducted a
large-scale analysis of how U.S. banks implement privacy policies and controls
in response to GLBA; other federal privacy policy requirements; and the
California Consumer Privacy Act (CCPA), a key example for U.S. state privacy
laws. We focused on the disclosure and control of a set of especially
privacy-invasive practices: third-party data sharing for marketing-related
purposes. We collected privacy policies for the 2,067 largest U.S. banks,
45.3\% of which provided multiple policies. Across disclosures and controls
within the \textit{same} bank, we identified frequent, concerning
inconsistencies -- such as banks indicating in GLBA notices that they do not
share with third parties but disclosing sharing elsewhere, or using third-party
marketing/advertising cookies without disclosure. This multiplicity of
policies, with the inconsistencies it causes, may create consumer confusion and
undermine the transparency goals of the very laws that require them. Our
findings call into question whether current policy requirements, such as the
GLBA notice, are achieving their intended goals in today's online banking
landscape. We discuss potential avenues for reforming and harmonizing privacy
policies and control requirements across federal and state laws.

</details>


### [50] [FrameShift: Learning to Resize Fuzzer Inputs Without Breaking Them](https://arxiv.org/abs/2507.05421)
*Harrison Green,Claire Le Goues,Fraser Brown*

Main category: cs.CR

TL;DR: 本文提出了一种名为FrameShift的轻量级技术，通过检测和利用关系字段来避免破坏性突变，从而提升模糊测试的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的覆盖率引导模糊测试工具在缺乏输入格式知识的情况下，容易产生破坏性的帧移突变，导致生成畸形输入并被目标程序拒绝，浪费大量时间。

Method: FrameShift技术简单、快速，无需额外的插装，仅依赖标准覆盖率反馈，通过检测和利用关系字段来保持输入结构。

Result: 在AFL++和LibAFL两种先进模糊测试工具中的实现表明，FrameShift在每种配置下均提升了性能，有时覆盖率增加超过50%，并能适用于多种格式和语言（如Rust和Python）。

Conclusion: FrameShift是一种高效且通用的技术，能够显著提升模糊测试的覆盖率和性能，适用于多种编程语言和输入格式。

Abstract: Coverage-guided fuzzers are powerful automated bug-finding tools. They mutate
program inputs, observe coverage, and save any input that hits an unexplored
path for future mutation. Unfortunately, without knowledge of input
formats--for example, the relationship between formats' data fields and
sizes--fuzzers are prone to generate destructive frameshift mutations. These
time-wasting mutations yield malformed inputs that are rejected by the target
program. To avoid such breaking mutations, this paper proposes a novel,
lightweight technique that preserves the structure of inputs during mutation by
detecting and using relation fields.
  Our technique, FrameShift, is simple, fast, and does not require additional
instrumentation beyond standard coverage feedback. We implement our technique
in two state-of-the-art fuzzers, AFL++ and LibAFL, and perform a 12+ CPU-year
fuzzer evaluation, finding that FrameShift improves the performance of the
fuzzer in each configuration, sometimes increasing coverage by more than 50%.
Furthermore, through a series of case studies, we show that our technique is
versatile enough to find important structural relationships in a variety of
formats, even generalizing beyond C/C++ targets to both Rust and Python.

</details>


### [51] [A Systematization of Security Vulnerabilities in Computer Use Agents](https://arxiv.org/abs/2507.05445)
*Daniel Jones,Giorgio Severi,Martin Pouliot,Gary Lopez,Joris de Gruyter,Santiago Zanella-Beguelin,Justin Song,Blake Bullwinkel,Pamela Cortez,Amanda Minnich*

Main category: cs.CR

TL;DR: 本文系统分析了计算机使用代理(CUAs)的安全风险，揭示了七类独特威胁，并深入研究了三种具体攻击场景，提出了针对CUAs的安全评估框架和设计原则。


<details>
  <summary>Details</summary>
Motivation: 计算机使用代理(CUAs)的快速部署引入了传统威胁模型未涵盖的新型攻击面和信任边界，但其安全边界仍未被充分理解。

Method: 研究对现实世界CUAs进行了系统性威胁分析，在对抗条件下测试，重点分析了三种具体攻击场景：视觉覆盖点击劫持、间接提示注入实现远程代码执行，以及思维链暴露攻击。

Result: 研究发现当前CUA实现存在深层架构缺陷，包括缺乏输入来源追踪、界面-动作绑定薄弱、对代理记忆和委托控制不足等问题。

Conclusion: 研究提出了专门针对CUAs的安全评估框架，并为对抗性和高风险环境下的安全部署提供了设计原则。

Abstract: Computer Use Agents (CUAs), autonomous systems that interact with software
interfaces via browsers or virtual machines, are rapidly being deployed in
consumer and enterprise environments. These agents introduce novel attack
surfaces and trust boundaries that are not captured by traditional threat
models. Despite their growing capabilities, the security boundaries of CUAs
remain poorly understood. In this paper, we conduct a systematic threat
analysis and testing of real-world CUAs under adversarial conditions. We
identify seven classes of risks unique to the CUA paradigm, and analyze three
concrete exploit scenarios in depth: (1) clickjacking via visual overlays that
mislead interface-level reasoning, (2) indirect prompt injection that enables
Remote Code Execution (RCE) through chained tool use, and (3) CoT exposure
attacks that manipulate implicit interface framing to hijack multi-step
reasoning. These case studies reveal deeper architectural flaws across current
CUA implementations. Namely, a lack of input provenance tracking, weak
interface-action binding, and insufficient control over agent memory and
delegation. We conclude by proposing a CUA-specific security evaluation
framework and design principles for safe deployment in adversarial and
high-stakes settings.

</details>


### [52] [Disappearing Ink: Obfuscation Breaks N-gram Code Watermarks in Theory and Practice](https://arxiv.org/abs/2507.05512)
*Gehao Zhang,Eugene Bagdasarian,Juan Zhai,Shiqing Ma*

Main category: cs.CR

TL;DR: 本文通过理论建模和实验验证，证明现有基于N-gram的代码水印方案在代码混淆攻击下完全失效，并提出可能的鲁棒水印路径。


<details>
  <summary>Details</summary>
Motivation: 区分AI生成代码与人工编写代码对版权保护至关重要，但现有水印方案对代码混淆等复杂攻击的鲁棒性缺乏评估。

Method: 建立代码混淆的形式化模型，基于分布一致性假设理论证明N-gram水印的脆弱性，并在3种水印方案、2个LLM、2种语言、4个基准数据集和4种混淆器上进行实验验证。

Result: 所有水印检测器对混淆后代码的检测能力接近随机猜测（AUROC≈0.5），且存在使检测AUROC≤0.6的混淆攻击方法。

Conclusion: 现有N-gram水印方案无法抵抗代码混淆攻击，需探索新型鲁棒水印技术。理论证明水印检测失败率将趋近1-fpr（原始误报率）。

Abstract: Distinguishing AI-generated code from human-written code is becoming crucial
for tasks such as authorship attribution, content tracking, and misuse
detection. Based on this, N-gram-based watermarking schemes have emerged as
prominent, which inject secret watermarks to be detected during the generation.
  However, their robustness in code content remains insufficiently evaluated.
Most claims rely solely on defenses against simple code transformations or code
optimizations as a simulation of attack, creating a questionable sense of
robustness. In contrast, more sophisticated schemes already exist in the
software engineering world, e.g., code obfuscation, which significantly alters
code while preserving functionality. Although obfuscation is commonly used to
protect intellectual property or evade software scanners, the robustness of
code watermarking techniques against such transformations remains largely
unexplored.
  In this work, we formally model the code obfuscation and prove the
impossibility of N-gram-based watermarking's robustness with only one intuitive
and experimentally verified assumption, distribution consistency, satisfied.
Given the original false positive rate of the watermarking detection, the ratio
that the detector failed on the watermarked code after obfuscation will
increase to 1 - fpr.
  The experiments have been performed on three SOTA watermarking schemes, two
LLMs, two programming languages, four code benchmarks, and four obfuscators.
Among them, all watermarking detectors show coin-flipping detection abilities
on obfuscated codes (AUROC tightly surrounds 0.5). Among all models,
watermarking schemes, and datasets, both programming languages own obfuscators
that can achieve attack effects with no detection AUROC higher than 0.6 after
the attack. Based on the theoretical and practical observations, we also
proposed a potential path of robust code watermarking.

</details>


### [53] [PROTEAN: Federated Intrusion Detection in Non-IID Environments through Prototype-Based Knowledge Sharing](https://arxiv.org/abs/2507.05524)
*Sara Chennoufi,Yufei Han,Gregory Blanc,Emiliano De Cristofaro,Christophe Kiennert*

Main category: cs.CR

TL;DR: 本文提出PROTEAN框架，通过原型学习实现隐私保护的联邦学习入侵检测，有效应对非独立同分布数据挑战。


<details>
  <summary>Details</summary>
Motivation: 分布式网络中，联邦学习(FL)因能保护隐私而成为抵御快速演变的网络攻击的有力工具，但数据异构性严重影响了其效果。

Method: PROTEAN采用原型学习方法，通过交换不同攻击类型的类别原型促进知识共享，提升非独立同分布环境下的检测精度。

Result: 在IIoT和5G网络数据集上的实验表明，PROTEAN在保持隐私的同时显著提升了入侵检测系统的性能。

Conclusion: PROTEAN框架成功解决了联邦入侵检测中的数据异构性问题，同时增强了参与者对未知攻击类型的认知能力。

Abstract: In distributed networks, participants often face diverse and fast-evolving
cyberattacks. This makes techniques based on Federated Learning (FL) a
promising mitigation strategy. By only exchanging model updates, FL
participants can collaboratively build detection models without revealing
sensitive information, e.g., network structures or security postures. However,
the effectiveness of FL solutions is often hindered by significant data
heterogeneity, as attack patterns often differ drastically across organizations
due to varying security policies. To address these challenges, we introduce
PROTEAN, a Prototype Learning-based framework geared to facilitate
collaborative and privacy-preserving intrusion detection. PROTEAN enables
accurate detection in environments with highly non-IID attack distributions and
promotes direct knowledge sharing by exchanging class prototypes of different
attack types among participants. This allows organizations to better understand
attack techniques not present in their data collections. We instantiate PROTEAN
on two cyber intrusion datasets collected from IIoT and 5G-connected
participants and evaluate its performance in terms of utility and privacy,
demonstrating its effectiveness in addressing data heterogeneity while
improving cyber attack understanding in federated intrusion detection systems
(IDSs).

</details>


### [54] [AI Agent Smart Contract Exploit Generation](https://arxiv.org/abs/2507.05558)
*Arthur Gervais,Liyi Zhou*

Main category: cs.CR

TL;DR: A1是一个将任意大语言模型转化为端到端漏洞利用生成器的代理执行驱动系统，无需人工启发式规则，通过六种领域专用工具实现自主漏洞发现，在真实场景中表现出色但揭示攻击者与防御者间的盈利不对称性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发能自动发现区块链漏洞的AI代理系统，解决传统方法依赖手工规则的问题，并验证其在真实攻击场景中的有效性及经济可行性。

Method: 系统为代理提供六种智能合约分析工具，通过自主策略生成、链上状态测试和反馈迭代来发现漏洞，所有输出均经过验证以确保零误报。采用蒙特卡洛分析评估19次历史攻击的成功概率。

Result: 在以太坊和币安智能链的36个真实漏洞合约中，VERITE基准成功率达62.96%（17/27），额外发现9个漏洞合约。26个成功案例总提取金额达933万美元，单案例最高859万美元。迭代分析显示边际收益递减（第2-5轮增益分别为+9.7%、+3.7%、+5.1%、+2.8%）。

Conclusion: 研究暴露了AI代理在攻防应用中的根本性不对称：攻击者在漏洞率0.1%、漏洞价值6000美元时即可盈利，而防御者需要60000美元，表明AI技术可能天然倾向于被用于攻击而非防御。

Abstract: We present A1, an agentic execution driven system that transforms any LLM
into an end-to-end exploit generator. A1 has no hand-crafted heuristics and
provides the agent with six domain-specific tools that enable autonomous
vulnerability discovery. The agent can flexibly leverage these tools to
understand smart contract behavior, generate exploit strategies, test them on
blockchain states, and refine approaches based on execution feedback. All
outputs are concretely validated to eliminate false positives.
  The evaluation across 36 real-world vulnerable contracts on Ethereum and
Binance Smart Chain demonstrates a 62.96% (17 out of 27) success rate on the
VERITE benchmark. Beyond the VERITE dataset, A1 identified 9 additional
vulnerable contracts, with 5 cases occurring after the strongest model's
training cutoff date. Across all 26 successful cases, A1 extracts up to 8.59
million USD per case and 9.33 million USD total. Through 432 experiments across
six LLMs, we analyze iteration-wise performance showing diminishing returns
with average marginal gains of +9.7%, +3.7%, +5.1%, and +2.8% for iterations
2-5 respectively, with per-experiment costs ranging $0.01-$3.59. A Monte Carlo
analysis of 19 historical attacks shows success probabilities of 85.9%-88.8%
without detection delays.
  We investigate whether an attacker or a defender benefits most from deploying
A1 as a continuous on-chain scanning system. Our model shows that OpenAI's
o3-pro maintains profitability up to a 30.0 days scanning delay at 0.100%
vulnerability incidence rates, while faster models require >=1.000% rates to
break-even. The findings exposes a troubling asymmetry: at 0.1% vulnerability
rates, attackers achieve an on-chain scanning profitability at a $6000 exploit
value, while defenders require $60000, raising fundamental questions about
whether AI agents inevitably favor exploitation over defense.

</details>


### [55] [iThermTroj: Exploiting Intermittent Thermal Trojans in Multi-Processor System-on-Chips](https://arxiv.org/abs/2507.05576)
*Mehdi Elahi,Mohamed R. Elshamy,Abdel-Hameed Badawy,Ahmad Patooghy*

Main category: cs.CR

TL;DR: 本文提出了一种新型间歇性热木马攻击(iThermTroj)，通过随机触发方式利用芯片温度信息，能绕过现有阈值检测。作者开发了微型机器学习分类器进行运行时异常检测，显著提升了攻击检测率与保护分辨率。


<details>
  <summary>Details</summary>
Motivation: 移动应用中的系统级芯片(SoC)面临间歇性热木马攻击的严重威胁，现有阈值检测方案难以应对这种隐蔽性强、随机触发的攻击模式，亟需新的防御手段。

Method: 通过深入分析木马激活与持续时间场景，研究SoC脆弱性；提出基于微型机器学习分类器的运行时异常检测方案，对抗间歇性热木马攻击。

Result: 在木马篡改80%、60%、40%热数据场景下，检测率分别提升29.4%、17.2%、14.3%；保护分辨率达0.8摄氏度，对超过$\pm 0.8$度的温度篡改实现100%检测。

Conclusion: 该研究证实间歇性热木马攻击对SoC构成重大威胁，所提出的微型机器学习检测方案显著优于传统方法，为芯片安全防护提供了新思路。

Abstract: Thermal Trojan attacks present a pressing concern for the security and
reliability of System-on-Chips (SoCs), especially in mobile applications. The
situation becomes more complicated when such attacks are more evasive and
operate sporadically to stay hidden from detection mechanisms. In this paper,
we introduce Intermittent Thermal Trojans (iThermTroj) that exploit the chips'
thermal information in a random time-triggered manner. According to our
experiments, iThermTroj attack can easily bypass available threshold-based
thermal Trojan detection solutions. We investigate SoC vulnerabilities to
variations of iThermTroj through an in-depth analysis of Trojan activation and
duration scenarios. We also propose a set of tiny Machine Learning classifiers
for run-time anomaly detection to protect SoCs against such intermittent
thermal Trojan attacks. Compared to existing methods, our approach improves the
attack detection rate by 29.4\%, 17.2\%, and 14.3\% in scenarios where
iThermTroj manipulates up to 80\%, 60\%, and 40\% of SoC's thermal data,
respectively. Additionally, our method increases the full protection resolution
to 0.8 degrees Celsius, meaning that any temperature manipulations exceeding
$\pm 0.8$ degrees will be detected with 100\% accuracy.

</details>


### [56] [DATABench: Evaluating Dataset Auditing in Deep Learning from an Adversarial Perspective](https://arxiv.org/abs/2507.05622)
*Shuo Shao,Yiming Li,Mengren Zheng,Zhiyang Hu,Yukun Chen,Boheng Li,Yu He,Junfeng Guo,Tianwei Zhang,Dacheng Tao,Zhan Qin*

Main category: cs.CR

TL;DR: 本文首次从对抗性角度全面评估数据集审计技术，提出新的分类法和攻击策略，并构建DATABench基准测试，发现现有审计方法在对抗环境下均不够鲁棒。


<details>
  <summary>Details</summary>
Motivation: 深度学习广泛应用依赖训练数据集质量，但数据使用缺乏透明度引发隐私和版权问题。现有数据集审计技术对抗对抗性攻击的鲁棒性尚未充分研究。

Method: 提出新分类法（内部特征IF/外部特征EF），制定两种攻击类型（逃避/伪造攻击），设计系统攻击策略（解耦/移除/检测；对抗样本），构建含17种逃避攻击、5种伪造攻击和9种审计方法的DATABench基准。

Result: DATABench评估显示，现有审计方法在对抗设置下均不够鲁棒或具有区分性，逃避攻击成功率高达96.8%，伪造攻击成功率可达99.9%。

Conclusion: 研究结果凸显开发能抵抗复杂对抗操作的安全可靠数据集审计方法的紧迫性，DATABench为未来研究提供基准平台。

Abstract: The widespread application of Deep Learning across diverse domains hinges
critically on the quality and composition of training datasets. However, the
common lack of disclosure regarding their usage raises significant privacy and
copyright concerns. Dataset auditing techniques, which aim to determine if a
specific dataset was used to train a given suspicious model, provide promising
solutions to addressing these transparency gaps. While prior work has developed
various auditing methods, their resilience against dedicated adversarial
attacks remains largely unexplored. To bridge the gap, this paper initiates a
comprehensive study evaluating dataset auditing from an adversarial
perspective. We start with introducing a novel taxonomy, classifying existing
methods based on their reliance on internal features (IF) (inherent to the
data) versus external features (EF) (artificially introduced for auditing).
Subsequently, we formulate two primary attack types: evasion attacks, designed
to conceal the use of a dataset, and forgery attacks, intending to falsely
implicate an unused dataset. Building on the understanding of existing methods
and attack objectives, we further propose systematic attack strategies:
decoupling, removal, and detection for evasion; adversarial example-based
methods for forgery. These formulations and strategies lead to our new
benchmark, DATABench, comprising 17 evasion attacks, 5 forgery attacks, and 9
representative auditing methods. Extensive evaluations using DATABench reveal
that none of the evaluated auditing methods are sufficiently robust or
distinctive under adversarial settings. These findings underscore the urgent
need for developing a more secure and reliable dataset auditing method capable
of withstanding sophisticated adversarial manipulation. Code is available at
https://github.com/shaoshuo-ss/DATABench.

</details>


### [57] [How Not to Detect Prompt Injections with an LLM](https://arxiv.org/abs/2507.05630)
*Sarthak Choudhary,Divyam Anshumaan,Nils Palumbo,Somesh Jha*

Main category: cs.CR

TL;DR: 研究发现基于已知答案检测（KAD）的LLM防御框架存在结构性漏洞，并提出自适应攻击方法DataFlip，能有效绕过防御并诱导恶意行为。


<details>
  <summary>Details</summary>
Motivation: LLM应用易受提示注入攻击，现有KAD防御虽表现优异，但其设计存在根本性安全缺陷需要揭示。

Method: 提出DataFlip攻击方法，无需白盒访问或优化过程，通过系统性利用KAD框架的结构漏洞实现攻击。

Result: DataFlip将KAD检测率降至1.5\%，同时实现高达88\%的恶意行为诱导成功率。

Conclusion: KAD防御的核心安全前提存在缺陷，需重新评估其有效性并开发更鲁棒的防护机制。

Abstract: LLM-integrated applications and agents are vulnerable to prompt injection
attacks, in which adversaries embed malicious instructions within seemingly
benign user inputs to manipulate the LLM's intended behavior. Recent defenses
based on $\textit{known-answer detection}$ (KAD) have achieved near-perfect
performance by using an LLM to classify inputs as clean or contaminated. In
this work, we formally characterize the KAD framework and uncover a structural
vulnerability in its design that invalidates its core security premise. We
design a methodical adaptive attack, $\textit{DataFlip}$, to exploit this
fundamental weakness. It consistently evades KAD defenses with detection rates
as low as $1.5\%$ while reliably inducing malicious behavior with success rates
of up to $88\%$, without needing white-box access to the LLM or any
optimization procedures.

</details>


### [58] [DESIGN: Encrypted GNN Inference via Server-Side Input Graph Pruning](https://arxiv.org/abs/2507.05649)
*Kaixiang Zhao,Joseph Yousry Attalla,Qian Lou,Yushun Dong*

Main category: cs.CR

TL;DR: DESIGN框架通过服务器端输入图剪枝和自适应多项式激活方案，显著提升了全同态加密（FHE）下图神经网络（GNN）推理的效率，同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: 现有FHE GNN方法因忽视输入数据冗余和采用统一计算策略，导致计算开销巨大，难以实现实时隐私保护推理。

Method: DESIGN采用分层优化策略：1) 基于加密度统计计算节点重要性分数；2) 通过同态分区生成多级重要性掩码；3) 动态掩码指导输入图剪枝和自适应多项式激活。

Result: 实验表明，DESIGN相比现有方法显著加速FHE GNN推理，同时保持竞争力的模型准确率。

Conclusion: DESIGN为安全图分析提供了高效且隐私保护的解决方案，通过服务器端优化实现了FHE环境下GNN推理的实用化突破。

Abstract: Graph Neural Networks (GNNs) have achieved state-of-the-art performance in
various graph-based learning tasks. However, enabling privacy-preserving GNNs
in encrypted domains, such as under Fully Homomorphic Encryption (FHE),
typically incurs substantial computational overhead, rendering real-time and
privacy-preserving inference impractical. In this work, we propose DESIGN
(EncrypteD GNN Inference via sErver-Side Input Graph pruNing), a novel
framework for efficient encrypted GNN inference. DESIGN tackles the critical
efficiency limitations of existing FHE GNN approaches, which often overlook
input data redundancy and apply uniform computational strategies. Our framework
achieves significant performance gains through a hierarchical optimization
strategy executed entirely on the server: first, FHE-compatible node importance
scores (based on encrypted degree statistics) are computed from the encrypted
graph. These scores then guide a homomorphic partitioning process, generating
multi-level importance masks directly under FHE. This dynamically generated
mask facilitates both input graph pruning (by logically removing unimportant
elements) and a novel adaptive polynomial activation scheme, where activation
complexity is tailored to node importance levels. Empirical evaluations
demonstrate that DESIGN substantially accelerates FHE GNN inference compared to
state-of-the-art methods while maintaining competitive model accuracy,
presenting a robust solution for secure graph analytics.

</details>


### [59] [TuneShield: Mitigating Toxicity in Conversational AI while Fine-tuning on Untrusted Data](https://arxiv.org/abs/2507.05660)
*Aravind Cheruvu,Shravya Kanchi,Sifat Muhammad Abdullah,Nicholas Kong,Daphne Yao,Murtuza Jadliwala,Bimal Viswanath*

Main category: cs.CR

TL;DR: 本文提出TuneShield框架，利用LLM的毒性分类能力生成'治疗数据'，在微调过程中有效降低聊天机器人毒性，同时保持对话质量。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在对话AI领域取得进展，但在使用不可信训练数据定制聊天机器人时，毒性内容仍是重大挑战。

Method: TuneShield通过LLM毒性分类识别有毒样本，生成合成对话样本（治疗数据），并在微调中进行对齐处理。

Result: 实验表明TuneShield能有效抵御毒性注入攻击和越狱攻击，在对话式学习中保持稳健性，即使分类器存在缺陷。

Conclusion: 该框架为安全定制聊天机器人提供了有效解决方案，在毒性缓解和对话质量保持方面表现出色。

Abstract: Recent advances in foundation models, such as LLMs, have revolutionized
conversational AI. Chatbots are increasingly being developed by customizing
LLMs on specific conversational datasets. However, mitigating toxicity during
this customization, especially when dealing with untrusted training data,
remains a significant challenge. To address this, we introduce TuneShield, a
defense framework designed to mitigate toxicity during chatbot fine-tuning
while preserving conversational quality. TuneShield leverages LLM-based
toxicity classification, utilizing the instruction-following capabilities and
safety alignment of LLMs to effectively identify toxic samples, outperforming
industry API services. TuneShield generates synthetic conversation samples,
termed 'healing data', based on the identified toxic samples, using them to
mitigate toxicity while reinforcing desirable behavior during fine-tuning. It
performs an alignment process to further nudge the chatbot towards producing
desired responses. Our findings show that TuneShield effectively mitigates
toxicity injection attacks while preserving conversational quality, even when
the toxicity classifiers are imperfect or biased. TuneShield proves to be
resilient against adaptive adversarial and jailbreak attacks. Additionally,
TuneShield demonstrates effectiveness in mitigating adaptive toxicity injection
attacks during dialog-based learning (DBL).

</details>


### [60] [Polyadic encryption](https://arxiv.org/abs/2507.05683)
*Steven Duplij,Qiang Guo*

Main category: cs.CR

TL;DR: 提出了一种基于多元代数结构和信号处理方法的加密/解密新流程。


<details>
  <summary>Details</summary>
Motivation: 利用多元代数技术和信号处理方法，开发一种新型的加密/解密机制，以提高信息传输的安全性。

Method: 首先使用整数振幅信号发送信息，然后通过多元技术将明文转换为特殊整数序列，接收方使用特定规则和方程组恢复明文。

Result: 该方法成功实现了信息的加密传输和解密恢复，验证了其可行性和有效性。

Conclusion: 该研究为信息安全领域提供了一种创新的加密/解密方法，结合了多元代数与信号处理的优势。

Abstract: A novel original procedure of encryption/decryption based on the polyadic
algebraic structures and on signal processing methods is proposed. First, we
use signals with integer amplitudes to send information. Then we use polyadic
techniques to transfer the plaintext into series of special integers. The
receiver restores the plaintext using special rules and systems of equations.

</details>


### [61] [Asynchronous Event Error-Minimizing Noise for Safeguarding Event Dataset](https://arxiv.org/abs/2507.05728)
*Ruofei Wang,Peiqi Duan,Boxin Shi,Renjie Wan*

Main category: cs.CR

TL;DR: 本文提出了一种针对异步事件流的不可学习样本生成方法（UEvs），通过添加稀疏化噪声防止事件数据集被未经授权的模型训练利用，同时保持合法使用的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着在线事件数据集的增多，保护数据免受未经授权使用成为重要问题。现有不可学习样本方法主要针对图像数据，缺乏对事件流的保护方案。

Method: 提出异步事件误差最小化噪声，通过投影策略将噪声稀疏化以适配事件流特性，生成不可学习事件流（UEvs）。

Result: 实验表明该方法能有效阻止未经授权的模型训练，同时不影响数据的合法使用。代码已开源。

Conclusion: UEvs为事件数据集的安全共享提供了新方案，推动了可信事件数据生态的发展。

Abstract: With more event datasets being released online, safeguarding the event
dataset against unauthorized usage has become a serious concern for data
owners. Unlearnable Examples are proposed to prevent the unauthorized
exploitation of image datasets. However, it's unclear how to create unlearnable
asynchronous event streams to prevent event misuse. In this work, we propose
the first unlearnable event stream generation method to prevent unauthorized
training from event datasets. A new form of asynchronous event error-minimizing
noise is proposed to perturb event streams, tricking the unauthorized model
into learning embedded noise instead of realistic features. To be compatible
with the sparse event, a projection strategy is presented to sparsify the noise
to render our unlearnable event streams (UEvs). Extensive experiments
demonstrate that our method effectively protects event data from unauthorized
exploitation, while preserving their utility for legitimate use. We hope our
UEvs contribute to the advancement of secure and trustworthy event dataset
sharing. Code is available at: https://github.com/rfww/uevs.

</details>


### [62] [Automated Reasoning for Vulnerability Management by Design](https://arxiv.org/abs/2507.05794)
*Avi Shaked,Nan Messe*

Main category: cs.CR

TL;DR: 本文提出了一种基于形式化基础的自动化推理机制，用于系统漏洞管理和安全控制设计，并将其集成到开源安全设计工具中，通过实际案例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前漏洞管理方法缺乏对系统设计漏洞态势的系统性推理能力，无法有效支持安全控制设计。

Method: 开发了形式化基础的自动化推理机制，集成至开源安全设计工具，支持漏洞识别、缓解选项明确指定及控制措施选择。

Result: 该机制使设计师能识别特定系统设计的适用漏洞，系统化管理漏洞态势，并通过真实案例验证了实用性。

Conclusion: 提出的自动化推理机制为系统性管理漏洞态势和安全控制设计提供了有效解决方案，具有实际应用价值。

Abstract: For securing systems, it is essential to manage their vulnerability posture
and design appropriate security controls. Vulnerability management allows to
proactively address vulnerabilities by incorporating pertinent security
controls into systems designs. Current vulnerability management approaches do
not support systematic reasoning about the vulnerability postures of systems
designs. To effectively manage vulnerabilities and design security controls, we
propose a formally grounded automated reasoning mechanism. We integrate the
mechanism into an open-source security design tool and demonstrate its
application through an illustrative example driven by real-world challenges.
The automated reasoning mechanism allows system designers to identify
vulnerabilities that are applicable to a specific system design, explicitly
specify vulnerability mitigation options, declare selected controls, and thus
systematically manage vulnerability postures.

</details>


### [63] [LDP$^3$: An Extensible and Multi-Threaded Toolkit for Local Differential Privacy Protocols and Post-Processing Methods](https://arxiv.org/abs/2507.05872)
*Berkay Kemal Balioglu,Alireza Khodaie,Mehmet Emre Gursoy*

Main category: cs.CR

TL;DR: 本文介绍了LDP$^3$，一个开源、可扩展且多线程的本地差分隐私（LDP）工具包，旨在帮助研究者和从业者选择最优的LDP协议和后处理方法，并通过并行化显著提升执行效率。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏一个全面且可扩展的LDP基准测试工具包，导致在不同隐私预算和数据集下选择最优协议和后处理方法存在挑战。LDP$^3$的提出旨在解决这一问题。

Method: LDP$^3$采用模块化和可扩展的设计，集成了多种LDP协议、后处理方法和效用度量，支持开发者便捷地集成新协议和方法，并通过多线程设计实现并行化以提升效率。

Result: 实验评估表明：(i) 使用LDP$^3$选择优质协议和后处理方法可显著提升效用；(ii) 多线程设计大幅提升了执行效率。

Conclusion: LDP$^3$为LDP研究和实践提供了一个高效、灵活的工具，显著优化了协议选择和后处理的效果，并通过并行化提升了计算效率。

Abstract: Local differential privacy (LDP) has become a prominent notion for
privacy-preserving data collection. While numerous LDP protocols and
post-processing (PP) methods have been developed, selecting an optimal
combination under different privacy budgets and datasets remains a challenge.
Moreover, the lack of a comprehensive and extensible LDP benchmarking toolkit
raises difficulties in evaluating new protocols and PP methods. To address
these concerns, this paper presents LDP$^3$ (pronounced LDP-Cube), an
open-source, extensible, and multi-threaded toolkit for LDP researchers and
practitioners. LDP$^3$ contains implementations of several LDP protocols, PP
methods, and utility metrics in a modular and extensible design. Its modular
design enables developers to conveniently integrate new protocols and PP
methods. Furthermore, its multi-threaded nature enables significant reductions
in execution times via parallelization. Experimental evaluations demonstrate
that: (i) using LDP$^3$ to select a good protocol and post-processing method
substantially improves utility compared to a bad or random choice, and (ii) the
multi-threaded design of LDP$^3$ brings substantial benefits in terms of
efficiency.

</details>


### [64] [Post-Processing in Local Differential Privacy: An Extensive Evaluation and Benchmark Platform](https://arxiv.org/abs/2507.05875)
*Alireza Khodaie,Berkay Kemal Balioglu,Mehmet Emre Gursoy*

Main category: cs.CR

TL;DR: 本文通过广泛实验评估了7种后处理方法在6种LDP协议下的性能，发现后处理在小隐私预算时显著提升数据效用，但随着预算增加效果减弱。研究还表明最优后处理方法取决于多种因素，并推出了开源平台LDP$^3$以促进研究与实践。


<details>
  <summary>Details</summary>
Motivation: 本地差分隐私(LDP)虽能保护用户数据隐私，但其引入的噪声会降低数据效用。现有后处理方法在不同场景下的性能对比研究不足，需系统性评估以指导实践选择。

Method: 研究构建了包含6种LDP协议、7种后处理方法、4种效用指标和6个数据集的综合基准，通过大量实验分析后处理方法在不同隐私预算、数据特征等条件下的表现。

Result: 实验表明：①后处理在严格隐私(小预算)时效用提升显著，但随预算增加效果递减；②最优后处理方法取决于LDP协议类型、隐私预算、数据分布特征及具体效用指标等多重因素。

Conclusion: 研究推出了模块化、可扩展的开源平台LDP$^3$，集成所有实验方法，为后续研究与实践提供灵活工具，强调需根据具体场景选择适配的后处理方法。

Abstract: Local differential privacy (LDP) has recently gained prominence as a powerful
paradigm for collecting and analyzing sensitive data from users' devices.
However, the inherent perturbation added by LDP protocols reduces the utility
of the collected data. To mitigate this issue, several post-processing (PP)
methods have been developed. Yet, the comparative performance of PP methods
under diverse settings remains underexplored. In this paper, we present an
extensive benchmark comprising 6 popular LDP protocols, 7 PP methods, 4 utility
metrics, and 6 datasets to evaluate the behaviors and optimality of PP methods
under diverse conditions. Through extensive experiments, we show that while PP
can substantially improve utility when the privacy budget is small (i.e.,
strict privacy), its benefit diminishes as the privacy budget grows. Moreover,
our findings reveal that the optimal PP method depends on multiple factors,
including the choice of LDP protocol, privacy budget, data characteristics
(such as distribution and domain size), and the specific utility metric. To
advance research in this area and assist practitioners in identifying the most
suitable PP method for their setting, we introduce LDP$^3$, an open-source
benchmark platform. LDP$^3$ contains all methods used in our experimental
analysis, and it is designed in a modular, extensible, and multi-threaded way
for future use and development.

</details>


### [65] [The Impact of Event Data Partitioning on Privacy-aware Process Discovery](https://arxiv.org/abs/2507.06008)
*Jungeun Lim,Stephan A. Fahrenkrog-Petersen,Xixi Lu,Jan Mendling,Minseok Song*

Main category: cs.CR

TL;DR: 提出结合匿名化与事件数据分区的管道，通过事件抽象分割日志，在保护隐私的同时减少效用损失。验证表明分区能提升基于直接跟随关系的匿名化技术在流程发现中的效用。


<details>
  <summary>Details</summary>
Motivation: 信息系统的事件日志包含敏感信息，匿名化会降低流程发现的效用。如何在复杂日志中平衡隐私保护与效用保留是核心挑战。

Method: 采用事件抽象对日志分区，生成多个子日志分别匿名化。评估两种匿名化技术在三组真实日志和两种流程发现方法上的表现。

Result: 实验证明事件分区能显著提升基于直接跟随关系的匿名化技术的流程发现效用，尤其在复杂日志场景。

Conclusion: 事件分区策略有效缓解了匿名化导致的效用损失，为隐私保护与流程分析需求的平衡提供了可行方案。

Abstract: Information systems support the execution of business processes. The event
logs of these executions generally contain sensitive information about
customers, patients, and employees. The corresponding privacy challenges can be
addressed by anonymizing the event logs while still retaining utility for
process discovery. However, trading off utility and privacy is difficult: the
higher the complexity of event log, the higher the loss of utility by
anonymization. In this work, we propose a pipeline that combines anonymization
and event data partitioning, where event abstraction is utilized for
partitioning. By leveraging event abstraction, event logs can be segmented into
multiple parts, allowing each sub-log to be anonymized separately. This
pipeline preserves privacy while mitigating the loss of utility. To validate
our approach, we study the impact of event partitioning on two anonymization
techniques using three real-world event logs and two process discovery
techniques. Our results demonstrate that event partitioning can bring
improvements in process discovery utility for directly-follows-based
anonymization techniques.

</details>


### [66] [Enter, Exit, Page Fault, Leak: Testing Isolation Boundaries for Microarchitectural Leaks](https://arxiv.org/abs/2507.06039)
*Oleksii Oleksenko,Flavien Solt,Cédric Fournet,Jana Hofmann,Boris Köpf,Stavros Volos*

Main category: cs.CR

TL;DR: 该研究开发了一种工具，用于压力测试安全域间的微架构隔离，检测隔离边界中的缺陷，发现了四个新的漏洞，验证了检测微架构缺陷的稳健方法。


<details>
  <summary>Details</summary>
Motivation: 现有CPU隔离机制主要关注架构层面，忽视了微架构侧信道漏洞（如Meltdown和Foreshadow），导致软件需不断修补漏洞，难以确保完全隔离。

Method: 研究扩展了基于模型的关系测试（MRT）方法，设计了新的测试用例生成器、执行沙箱、泄漏模型和分析技术，以检测跨域信息泄漏。

Result: 在六款x86-64 CPU上进行的测试中，发现了四个新的泄漏漏洞，并验证了多个已知漏洞，整个测试过程中仅出现两个误报。

Conclusion: 该方法揭示了当前隔离机制的关键缺陷，为处理器设计从被动修补转向主动安全验证提供了可行路径。

Abstract: CPUs provide isolation mechanisms like virtualization and privilege levels to
protect software. Yet these focus on architectural isolation while typically
overlooking microarchitectural side channels, exemplified by Meltdown and
Foreshadow. Software must therefore supplement architectural defenses with
ad-hoc microarchitectural patches, which are constantly evolving as new attacks
emerge and defenses are proposed. Such reactive approach makes ensuring
complete isolation a daunting task, and leaves room for errors and oversights.
  We address this problem by developing a tool that stress tests
microarchitectural isolation between security domains such as virtual machines,
kernel, and processes, with the goal of detecting flaws in the isolation
boundaries. The tool extends model-based relational testing (MRT) methodology
to enable detection of cross-domain information leakage. We design a new test
case generator and execution sandbox to handle multi-domain execution, new
leakage models to encode expected leaks, and new analysis techniques to manage
nondeterminism.
  We use this tool to perform an in-depth testing campaign on six x86-64 CPUs
for leakage across different isolation boundaries. The testing campaign exposed
four new leaks and corroborated numerous known ones, with only two false
positives throughout the entire campaign. These results show critical gaps in
current isolation mechanisms as well as validate a robust methodology for
detecting microarchitectural flaws. As such, this approach enables a shift from
reactive patching to proactive security validation in processor design.

</details>


### [67] [CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations](https://arxiv.org/abs/2507.06043)
*Xiaohu Li,Yunfeng Ning,Zepeng Bao,Mayi Xu,Jianhao Chen,Tieyun Qian*

Main category: cs.CR

TL;DR: 本文提出了一种结合攻击与防御的框架CAVGAN，通过分析LLM中间层嵌入的线性可分特性及越狱攻击本质，利用GAN学习LLM内部安全判断边界，实现高效越狱攻击与防御。实验表明该方法在三种主流LLM上平均越狱成功率达88.85\%，防御成功率达84.17\%。


<details>
  <summary>Details</summary>
Motivation: 现有研究孤立看待LLM越狱攻击与防御，而安全对齐机制仍存在漏洞。为深入理解LLM安全机制并提升防护能力，需开发攻防结合的统一框架。

Method: 基于LLM中间层嵌入的线性可分特性，利用GAN学习模型内部安全判断边界。通过将有害问题嵌入并转移至安全区域，实现攻防协同优化。

Result: 在三种主流LLM上达到平均88.85\%的越狱成功率，在最新越狱数据集上实现84.17\%的平均防御成功率，代码与数据已开源。

Conclusion: 该方法不仅验证了攻防结合框架的有效性，揭示了LLM内部安全机制，还为增强模型安全性提供了新思路。开源地址：https://github.com/NLPGM/CAVGAN。

Abstract: Security alignment enables the Large Language Model (LLM) to gain the
protection against malicious queries, but various jailbreak attack methods
reveal the vulnerability of this security mechanism. Previous studies have
isolated LLM jailbreak attacks and defenses. We analyze the security protection
mechanism of the LLM, and propose a framework that combines attack and defense.
Our method is based on the linearly separable property of LLM intermediate
layer embedding, as well as the essence of jailbreak attack, which aims to
embed harmful problems and transfer them to the safe area. We utilize
generative adversarial network (GAN) to learn the security judgment boundary
inside the LLM to achieve efficient jailbreak attack and defense. The
experimental results indicate that our method achieves an average jailbreak
success rate of 88.85\% across three popular LLMs, while the defense success
rate on the state-of-the-art jailbreak dataset reaches an average of 84.17\%.
This not only validates the effectiveness of our approach but also sheds light
on the internal security mechanisms of LLMs, offering new insights for
enhancing model security The code and data are available at
https://github.com/NLPGM/CAVGAN.

</details>


### [68] [Wrapless: The trustless lending protocol on top of Bitcoin](https://arxiv.org/abs/2507.06064)
*Oleksandr Kurbatov,Kyrylo Baybula,Yaroslava Chopa,Sergey Kozlov,Oleg Komendant,Illia Dovgopoly,Dmitrii Kurbatov,Zakhar Naumets,Yulia Artikulova,Pavel Kravchenko,Volodymyr Dubinin,Lasha Antadze,Yaroslav Panasenko,Mykhailo Velykodnyi*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: This paper presents Wrapless -- a lending protocol that enables the
collateralization of bitcoins without requiring a trusted wrapping mechanism.
The protocol facilitates a "loan channel" on the Bitcoin blockchain, allowing
bitcoins to be locked as collateral for loans issued on any blockchain that
supports Turing-complete smart contracts. The protocol is designed in a way
that makes it economically irrational for each involved party to manipulate the
loan rules. There is still a significant research area to bring the protocol
closer to traditional AMM financial instruments.

</details>


### [69] [Taming Data Challenges in ML-based Security Tasks: Lessons from Integrating Generative AI](https://arxiv.org/abs/2507.06092)
*Shravya Kanchi,Neal Mangaokar,Aravind Cheruvu,Sifat Muhammad Abdullah,Shirin Nilizadeh,Atul Prakash,Bimal Viswanath*

Main category: cs.CR

TL;DR: 研究探讨了利用生成式AI（GenAI）生成合成数据以增强安全分类器性能的方法，提出新方案Nimai并在7项任务中验证，最高提升32.6%，同时揭示了GenAI在特定任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有安全分类器的改进多聚焦算法，而数据问题（如样本不足）未受重视。研究旨在验证GenAI能否通过合成数据解决此类问题。

Method: 采用6种前沿GenAI方法生成合成数据扩充训练集，并提出可控数据合成方案Nimai，在7种安全任务中测试性能提升效果。

Result: GenAI显著提升分类器性能（最高32.6%），支持概念漂移快速适应；但部分任务因标签噪声、类别重叠等问题难以受益。

Conclusion: 研究证实GenAI对安全任务的有效性，同时指出其局限性，为未来专用工具开发提供方向。

Abstract: Machine learning-based supervised classifiers are widely used for security
tasks, and their improvement has been largely focused on algorithmic
advancements. We argue that data challenges that negatively impact the
performance of these classifiers have received limited attention. We address
the following research question: Can developments in Generative AI (GenAI)
address these data challenges and improve classifier performance? We propose
augmenting training datasets with synthetic data generated using GenAI
techniques to improve classifier generalization. We evaluate this approach
across 7 diverse security tasks using 6 state-of-the-art GenAI methods and
introduce a novel GenAI scheme called Nimai that enables highly controlled data
synthesis. We find that GenAI techniques can significantly improve the
performance of security classifiers, achieving improvements of up to 32.6% even
in severely data-constrained settings (only ~180 training samples).
Furthermore, we demonstrate that GenAI can facilitate rapid adaptation to
concept drift post-deployment, requiring minimal labeling in the adjustment
process. Despite successes, our study finds that some GenAI schemes struggle to
initialize (train and produce data) on certain security tasks. We also identify
characteristics of specific tasks, such as noisy labels, overlapping class
distributions, and sparse feature vectors, which hinder performance boost using
GenAI. We believe that our study will drive the development of future GenAI
tools designed for security tasks.

</details>


### [70] [Fun with flags: How Compilers Break and Fix Constant-Time Code](https://arxiv.org/abs/2507.06112)
*Antoine Geimer,Clementine Maurice*

Main category: cs.CR

TL;DR: 该论文通过定性分析揭示了编译器优化如何破坏常数时间编程的安全性，识别出GCC和LLVM中导致泄漏的关键优化阶段，并提出了一种无需修改源代码或定制编译器的实用缓解方案。


<details>
  <summary>Details</summary>
Motivation: 开发者依赖常数时间编程来防止时序侧信道攻击，但编译器优化可能无声地重新引入泄漏。现有研究缺乏对具体优化阶段的责任定位及非侵入式解决方案的指导。

Method: 构建编译器引入的常数时间违规数据集，分析GCC和LLVM内部机制以定位关键优化阶段，首次刻画优化阶段间交互对泄漏的影响，并提出通过编译器标志选择性禁用优化阶段的方案。

Result: 研究表明少数优化阶段是大多数泄漏的根源，禁用这些阶段的方案能以极小性能开销显著减少泄漏，为开发者提供即时可部署的防御手段。

Conclusion: 该工作不仅揭示了编译器优化破坏常数时间性的机制，还提供了无需修改工具链的轻量级解决方案，填补了从理论到实践的转化空白。

Abstract: Developers rely on constant-time programming to prevent timing side-channel
attacks. But these efforts can be undone by compilers, whose optimizations may
silently reintroduce leaks. While recent works have measured the extent of such
leakage, they leave developers without actionable insights: which optimization
passes are responsible, and how to disable them without modifying the compiler
remains unclear.
  In this paper, we conduct a qualitative analysis of how compiler
optimizations break constant-time code. We construct a dataset of
compiler-introduced constant-time violations and analyze the internals of two
widely used compilers, GCC and LLVM, to identify the specific optimization
passes responsible. Our key insight is that a small set of passes are at the
root of most leaks. To the best of our knowledge, we are also the first to
characterize how the interactions between these passes contribute to leakage.
Based on this analysis, we propose an original and practical mitigation that
requires no source code modification or custom compiler: disabling selected
optimization passes via compiler flags. We show that this approach
significantly reduces leakage with minimal performance overhead, offering an
immediately deployable defense for developers.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [71] [Strongly Solving $7 \times 6$ Connect-Four on Consumer Grade Hardware](https://arxiv.org/abs/2507.05267)
*Markus Böck*

Main category: cs.AI

TL;DR: 本文通过基于二元决策图的符号搜索方法，成功构建了标准$7 \times 6$棋盘四子棋的89.6GB强解查找表，并在开源工具中整合了α-β搜索以优化胜负路径。


<details>
  <summary>Details</summary>
Motivation: 尽管四子棋已有数学解法和搜索计算方法，但传统认为构建强解查找表不可行。本研究旨在挑战这一认知，探索高效实现的可能性。

Method: 采用二元决策图（BDD）进行符号搜索，结合单核CPU（128GB内存）的优化实现，并集成α-β搜索算法以加速胜负决策。

Result: 在47小时内生成89.6GB的胜-平-负评估查找表，同时开源工具能通过α-β搜索快速定位最优胜负路径。

Conclusion: 研究证明通过符号搜索方法可高效构建四子棋强解查找表，为组合游戏求解提供了新的技术路径。

Abstract: While the game Connect-Four has been solved mathematically and the best move
can be effectively computed with search based methods, a strong solution in the
form of a look-up table was believed to be infeasible. In this paper, we
revisit a symbolic search method based on binary decision diagrams to produce
strong solutions. With our efficient implementation we were able to produce a
89.6 GB large look-up table in 47 hours on a single CPU core with 128 GB main
memory for the standard $7 \times 6$ board size. In addition to this
win-draw-loss evaluation, we include an alpha-beta search in our open source
artifact to find the move which achieves the fastest win or slowest loss.

</details>


### [72] [Chat2SPaT: A Large Language Model Based Tool for Automating Traffic Signal Control Plan Management](https://arxiv.org/abs/2507.05283)
*Yue Wang,Miao Zhou,Guijing Huang,Rui Zhuo,Chao Yi,Zhenliang Ma*

Main category: cs.AI

TL;DR: 本研究提出Chat2SPaT方法，利用大语言模型(LLM)将用户对交通信号控制计划的半结构化描述转换为精确的信号相位与时间(SPaT)结果，准确率超过94%，为交通从业者提供了易用的计划管理工具。


<details>
  <summary>Details</summary>
Motivation: 传统定时交通信号控制需要繁琐的手动计划创建与更新，尤其当采用分时段方案时，需重复输入参数。本研究旨在通过自然语言交互简化这一过程。

Method: Chat2SPaT通过精心设计的提示词，利用LLM理解用户描述并输出JSON格式的相位序列与属性，再通过Python脚本处理信号控制细节并组装完整方案，支持聊天式迭代编辑。

Result: 在包含300多条描述的中英文测试集中，系统生成方案的准确率均超过94%，建立了首个评估LLM理解交通信号控制描述能力的基准。

Conclusion: Chat2SPaT为智能交通系统(ITS)领域提供了LLM应用的新范式，其开源代码与数据集可促进该技术的进一步发展与应用。

Abstract: Pre-timed traffic signal control, commonly used for operating signalized
intersections and coordinated arterials, requires tedious manual work for
signaling plan creating and updating. When the time-of-day or day-of-week plans
are utilized, one intersection is often associated with multiple plans, leading
to further repetitive manual plan parameter inputting. To enable a
user-friendly traffic signal control plan management process, this study
proposes Chat2SPaT, a method to convert users' semi-structured and ambiguous
descriptions on the signal control plan to exact signal phase and timing (SPaT)
results, which could further be transformed into structured stage-based or
ring-based plans to interact with intelligent transportation system (ITS)
software and traffic signal controllers. With curated prompts, Chat2SPaT first
leverages large language models' (LLMs) capability of understanding users' plan
descriptions and reformulate the plan as a combination of phase sequence and
phase attribute results in the json format. Based on LLM outputs, python
scripts are designed to locate phases in a cycle, address nuances of traffic
signal control, and finally assemble the complete traffic signal control plan.
Within a chat, the pipeline can be utilized iteratively to conduct further plan
editing. Experiments show that Chat2SPaT can generate plans with an accuracy of
over 94% for both English and Chinese cases, using a test dataset with over 300
plan descriptions. As the first benchmark for evaluating LLMs' capability of
understanding traffic signal control plan descriptions, Chat2SPaT provides an
easy-to-use plan management pipeline for traffic practitioners and researchers,
serving as a potential new building block for a more accurate and versatile
application of LLMs in the field of ITS. The source codes, prompts and test
dataset are openly accessible at https://github.com/yuewangits/Chat2SPaT.

</details>


### [73] [Fuzzy Classification Aggregation for a Continuum of Agents](https://arxiv.org/abs/2507.05297)
*Zijun Meng*

Main category: cs.AI

TL;DR: 证明了对于将$m\ge 3$个对象分为$2\le p\le m$类的连续个体分类，任何最优、独立且零一致的模糊分类聚合函数必须是加权算术平均。


<details>
  <summary>Details</summary>
Motivation: 研究模糊分类聚合函数的数学特性，特别是在多对象多类型分类场景下的最优形式。

Method: 通过数学证明，分析满足最优性、独立性和零一致性的模糊分类聚合函数的必要条件。

Result: 发现唯一满足条件的聚合函数形式是加权算术平均。

Conclusion: 该结果为模糊分类聚合提供了理论基础，并限定了其数学表达形式。

Abstract: We prove that any optimal, independent, and zero unanimous fuzzy
classification aggregation function of a continuum of individual
classifications of $m\ge 3$ objects into $2\le p\le m$ types must be a weighted
arithmetic mean.

</details>


### [74] [OLG++: A Semantic Extension of Obligation Logic Graph](https://arxiv.org/abs/2507.05488)
*Subhasis Dasgupta,Jon Stephens,Amarnath Gupta*

Main category: cs.AI

TL;DR: 本文提出OLG++，一种对义务逻辑图（OLG）的语义扩展，用于建模市政和跨辖区背景下的法规和法律规则。OLG++引入了更丰富的节点和边类型，支持对法律义务、例外和层次结构的细致表示。


<details>
  <summary>Details</summary>
Motivation: 现有法律知识表示模型在表达空间、时间和逻辑分组等复杂法律概念时存在局限性，需要一种更丰富的表示方法。

Method: OLG++扩展了OLG模型，新增了空间、时间、参与方组、可废止性和逻辑分组等节点和边类型，支持带上下文条件、优先级和复杂触发的结构化推理。

Result: 通过食品行业法规案例展示，OLG++能够支持基于属性图查询的法律问答，并在表达能力上优于LegalRuleML等现有图模型。

Conclusion: OLG++在表达法律知识方面比现有基于图的模型更具表现力，特别是在处理子类关系、空间约束和具体化异常结构方面具有优势。

Abstract: We present OLG++, a semantic extension of the Obligation Logic Graph (OLG)
for modeling regulatory and legal rules in municipal and interjurisdictional
contexts. OLG++ introduces richer node and edge types, including spatial,
temporal, party group, defeasibility, and logical grouping constructs, enabling
nuanced representations of legal obligations, exceptions, and hierarchies. The
model supports structured reasoning over rules with contextual conditions,
precedence, and complex triggers. We demonstrate its expressiveness through
examples from food business regulations, showing how OLG++ supports legal
question answering using property graph queries. OLG++ also improves over
LegalRuleML by providing native support for subClassOf, spatial constraints,
and reified exception structures. Our examples show that OLG++ is more
expressive than prior graph-based models for legal knowledge representation.

</details>


### [75] [Deep Research Comparator: A Platform For Fine-grained Human Annotations of Deep Research Agents](https://arxiv.org/abs/2507.05495)
*Prahaladh Chandrahasan,Jiahe Jin,Zhihan Zhang,Tevin Wang,Andy Tang,Lucy Mo,Morteza Ziyadi,Leonardo F. R. Ribeiro,Zimeng Qiu,Markus Dreyer,Akari Asai,Chenyan Xiong*

Main category: cs.AI

TL;DR: 本文介绍了Deep Research Comparator平台，用于评估自主网络搜索、分析信息并生成报告的深度研究代理，支持多代理报告对比、细粒度反馈收集及排名计算。同时提出了Simple Deepresearch代理框架作为基线。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究代理的评估存在挑战，特别是在长报告评估和中间步骤反馈方面。为解决这些问题，开发了一个综合评估平台。

Method: 平台展示两个不同代理的最终报告及生成中间步骤，支持标注者通过对比评估整体质量，并提供对中间步骤或文本片段的详细反馈。开发了Simple Deepresearch框架作为基线。

Result: 收集了17位标注者对三个深度研究代理的真实偏好数据，验证了平台在代理开发中的实用性。平台演示视频已发布。

Conclusion: Deep Research Comparator平台为深度研究代理的开发与评估提供了全面框架，Simple Deepresearch框架简化了大型语言模型向研究代理的转化。

Abstract: Effectively evaluating deep research agents that autonomously search the web,
analyze information, and generate reports remains a major challenge,
particularly when it comes to assessing long reports and giving detailed
feedback on their intermediate steps. To address these gaps, we introduce Deep
Research Comparator, a platform that offers a holistic framework for deep
research agent hosting, side-by-side comparison, fine-grained human feedback
collection, and ranking calculation. Given a user query, our platform displays
the final reports from two different agents along with their intermediate steps
during generation. Annotators can evaluate the overall quality of final reports
based on side-by-side comparison, and also provide detailed feedback separately
by assessing intermediate steps or specific text spans within the final report.
Furthermore, we develop Simple Deepresearch, an end-to-end agent scaffold. This
scaffold serves as a baseline that facilitates the easy integration of various
large language models to transform them into deep research agents for
evaluation. To demonstrate the platform's utility for deep research agent
development, we have collected real user preference data from 17 annotators on
three deep research agents. A demo video of our platform can be found at
https://www.youtube.com/watch?v=g4d2dnbdseg.

</details>


### [76] [Fine-Grained Vision-Language Modeling for Multimodal Training Assistants in Augmented Reality](https://arxiv.org/abs/2507.05515)
*Haochen Huang,Jiahuan Pei,Mohammad Aliannejadi,Xin Sun,Moonisa Ahsan,Pablo Cesar,Chuang Yu,Zhaochun Ren,Junxiao Wang*

Main category: cs.AI

TL;DR: 本文介绍了专为AR训练定制的视觉-语言数据集，评估了9种先进VLM模型，发现其在细粒度装配任务上表现不佳（最高F1分数仅40.54%），呼吁加强视觉-语言对齐研究，并具有赋能视障群体的社会意义。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言模型（VLM）在多模态环境中具有重要作用，但其在增强现实（AR）训练中的应用尚未充分探索，需要建立专用数据集和基准来推动该领域发展。

Method: 研究构建了系统化的AR训练视觉-语言任务数据集，并对包括GPT-4o在内的9种前沿VLM模型进行了全面评估。

Result: 实验表明现有模型在细粒度状态检测等任务上表现欠佳，最佳F1分数仅为40.54%，凸显当前技术的局限性。

Conclusion: 该研究不仅提出了促进VLM发展的技术资源（数据集/代码/结果），更强调了其在为视障群体提供平等AI学习机会方面的社会价值。

Abstract: Vision-language models (VLMs) are essential for enabling AI-powered smart
assistants to interpret and reason in multimodal environments. However, their
application in augmented reality (AR) training remains largely unexplored. In
this work, we introduce a comprehensive dataset tailored for AR training,
featuring systematized vision-language tasks, and evaluate nine
state-of-the-art VLMs on it. Our results reveal that even advanced models,
including GPT-4o, struggle with fine-grained assembly tasks, achieving a
maximum F1 score of just 40.54% on state detection. These findings highlight
the demand for enhanced datasets, benchmarks, and further research to improve
fine-grained vision-language alignment. Beyond technical contributions, our
work has broader social implications, particularly in empowering blind and
visually impaired users with equitable access to AI-driven learning
opportunities. We provide all related resources, including the dataset, source
code, and evaluation results, to support the research community.

</details>


### [77] [Modeling (Deontic) Modal Operators With the s(CASP) Goal-directed Predicated Answer Set Programming System](https://arxiv.org/abs/2507.05519)
*Gopal Gupta,Abhiramon Rajasekharan,Alexis R. Tudor,Elmer Salazar,Joaquín Arias*

Main category: cs.AI

TL;DR: 本文提出使用答案集编程(ASP)中的默认否定和强否定来优雅地表达道义模态逻辑运算符，并通过ASP的全局约束表示义务和禁止，有效解决了道义模态逻辑中的各种悖论。


<details>
  <summary>Details</summary>
Motivation: 研究如何实现道义模态逻辑，解决其运算符表达复杂和悖论问题。

Method: 利用答案集编程(ASP)中的默认否定(否定即失败)和强否定来表达道义模态运算符，并使用ASP的全局约束来表示义务和禁止。

Result: 所提出的表示方法能够优雅地解决道义模态逻辑中的各种悖论。

Conclusion: 通过ASP的否定机制和全局约束，可以有效地实现和解决道义模态逻辑的表达和悖论问题。

Abstract: We consider the problem of implementing deontic modal logic. We show how
(deontic) modal operators can be expressed elegantly using default negation
(negation-as-failure) and strong negation present in answer set programming
(ASP). We propose using global constraints of ASP to represent obligations and
impermissibilities of deontic modal logic. We show that our proposed
representation results in the various paradoxes of deontic modal logic being
elegantly resolved.

</details>


### [78] [Cultivating Multimodal Intelligence: Interpretive Reasoning and Agentic RAG Approaches to Dermatological Diagnosis](https://arxiv.org/abs/2507.05520)
*Karishma Thakrar,Shreyas Basavatia,Akshay Daftardar*

Main category: cs.AI

TL;DR: 2025年ImageCLEF MEDIQA-MAGIC挑战赛聚焦于多模态皮肤病问答与分割，提出结合开源模型微调、结构化推理层和代理检索增强生成的方案，在竞赛中获得第二名，为远程医疗中的高精度诊断决策提供了可靠支持。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决远程医疗中皮肤病诊断的异步决策难题，要求基于有限输入实现高准确性和可解释性，模拟皮肤科医生的系统推理模式。

Method: 方法包含三部分：(1)对Qwen、Gemma和LLaMA系列开源多模态模型进行微调；(2)引入结构化推理层协调候选模型输出；(3)整合代理检索增强生成技术，补充美国皮肤病学会数据库的临床背景信息。

Result: 该方案在竞赛中获得第二名（提交成绩第六名），展现了竞争性表现和高准确性，验证了多模态融合与结构化推理的有效性。

Conclusion: 通过模拟皮肤科医生的系统推理，该架构为自动化诊断支持系统提供了更可靠的实现路径，尤其适用于输入受限的远程医疗场景。

Abstract: The second edition of the 2025 ImageCLEF MEDIQA-MAGIC challenge, co-organized
by researchers from Microsoft, Stanford University, and the Hospital Clinic of
Barcelona, focuses on multimodal dermatology question answering and
segmentation, using real-world patient queries and images. This work addresses
the Closed Visual Question Answering (CVQA) task, where the goal is to select
the correct answer to multiple-choice clinical questions based on both
user-submitted images and accompanying symptom descriptions. The proposed
approach combines three core components: (1) fine-tuning open-source multimodal
models from the Qwen, Gemma, and LLaMA families on the competition dataset, (2)
introducing a structured reasoning layer that reconciles and adjudicates
between candidate model outputs, and (3) incorporating agentic
retrieval-augmented generation (agentic RAG), which adds relevant information
from the American Academy of Dermatology's symptom and condition database to
fill in gaps in patient context. The team achieved second place with a
submission that scored sixth, demonstrating competitive performance and high
accuracy. Beyond competitive benchmarks, this research addresses a practical
challenge in telemedicine: diagnostic decisions must often be made
asynchronously, with limited input and with high accuracy and interpretability.
By emulating the systematic reasoning patterns employed by dermatologists when
evaluating skin conditions, this architecture provided a pathway toward more
reliable automated diagnostic support systems.

</details>


### [79] [Conversational Education at Scale: A Multi-LLM Agent Workflow for Procedural Learning and Pedagogic Quality Assessment](https://arxiv.org/abs/2507.05528)
*Jiahuan Pei,Fanghua Ye,Xin Sun,Wentao Deng,Koen Hindriks,Junxiao Wang*

Main category: cs.AI

TL;DR: 本文提出WikiHowAgent多智能体工作流，利用大语言模型(LLM)模拟师生互动对话，构建包含11万+对话的数据集，并通过混合评估方法验证其在跨领域教学中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有AI教育研究存在可扩展性不足、缺乏大规模课程内容利用及教学评估框架有限的问题，需要开发能模拟真实教学互动的系统性解决方案。

Method: 设计包含教师/学生智能体、交互管理器和评估器的多智能体框架，基于14,287篇教程构建跨17个领域的教学对话数据集，采用计算指标、评估量表和人工评判相结合的评估协议。

Result: 实验表明该工作流在不同配置下均表现良好，揭示了LLM跨领域教学能力，所有数据集和实现代码均已开源。

Conclusion: WikiHowAgent为AI教育提供了可扩展的交互式学习框架，其混合评估方法为教学质量分析树立了新标准，推动了LLM在教育领域的应用边界。

Abstract: Large language models (LLMs) have advanced virtual educators and learners,
bridging NLP with AI4Education. Existing work often lacks scalability and fails
to leverage diverse, large-scale course content, with limited frameworks for
assessing pedagogic quality. To this end, we propose WikiHowAgent, a
multi-agent workflow leveraging LLMs to simulate interactive teaching-learning
conversations. It integrates teacher and learner agents, an interaction
manager, and an evaluator to facilitate procedural learning and assess
pedagogic quality. We introduce a dataset of 114,296 teacher-learner
conversations grounded in 14,287 tutorials across 17 domains and 727 topics.
Our evaluation protocol combines computational and rubric-based metrics with
human judgment alignment. Results demonstrate the workflow's effectiveness in
diverse setups, offering insights into LLM capabilities across domains. Our
datasets and implementations are fully open-sourced.

</details>


### [80] [Red Teaming AI Red Teaming](https://arxiv.org/abs/2507.05538)
*Subhabrata Majumdar,Brian Pendleton,Abhishek Gupta*

Main category: cs.AI

TL;DR: 本文批判性审视了AI红队测试的现状，指出其过于关注模型层面缺陷而忽视社会技术系统的问题，并提出包含宏观系统层面和微观模型层面的综合框架。


<details>
  <summary>Details</summary>
Motivation: 当前AI红队测试虽在AI治理中流行，但其聚焦个体模型漏洞的做法与最初作为批判性思维训练的目的存在显著差距，且忽略了模型、用户与环境交互产生的系统性风险。

Method: 提出双层次操作框架：宏观层面覆盖AI全生命周期的系统红队测试，微观层面进行模型红队测试，并借鉴网络安全经验与系统理论提出建议。

Result: 强调有效的AI红队测试需跨职能团队协作，考察涌现风险、系统脆弱性及技术-社会因素的相互作用。

Conclusion: AI红队测试应超越模型缺陷检测，转向系统性风险评估，以应对生成式AI复杂社会技术环境中的挑战。

Abstract: Red teaming has evolved from its origins in military applications to become a
widely adopted methodology in cybersecurity and AI. In this paper, we take a
critical look at the practice of AI red teaming. We argue that despite its
current popularity in AI governance, there exists a significant gap between red
teaming's original intent as a critical thinking exercise and its narrow focus
on discovering model-level flaws in the context of generative AI. Current AI
red teaming efforts focus predominantly on individual model vulnerabilities
while overlooking the broader sociotechnical systems and emergent behaviors
that arise from complex interactions between models, users, and environments.
To address this deficiency, we propose a comprehensive framework
operationalizing red teaming in AI systems at two levels: macro-level system
red teaming spanning the entire AI development lifecycle, and micro-level model
red teaming. Drawing on cybersecurity experience and systems theory, we further
propose a set of recommendations. In these, we emphasize that effective AI red
teaming requires multifunctional teams that examine emergent risks, systemic
vulnerabilities, and the interplay between technical and social factors.

</details>


### [81] [SenseCF: LLM-Prompted Counterfactuals for Intervention and Sensor Data Augmentation](https://arxiv.org/abs/2507.05541)
*Shovito Barua Soumma,Asiful Arefeen,Stephanie M. Carpenter,Melanie Hingle,Hassan Ghasemzadeh*

Main category: cs.AI

TL;DR: 本文探索使用GPT-4o-mini等大语言模型(LLM)生成反事实解释(CFs)，在零样本和三样本设置下，相比传统方法(DiCE/CFNOW/NICE)获得更高合理性(99%)和有效性(0.99)，且生成的CFs作为增强数据可使下游分类器准确率平均提升5%。


<details>
  <summary>Details</summary>
Motivation: 反事实解释(CFs)能通过展示最小改变来提供人本洞察，既可用于异常预防干预，也能作为增强数据提升模型鲁棒性。研究旨在探索LLM在临床生理预测任务中提升可解释性与鲁棒性的潜力。

Method: 采用GPT-4o-mini模型，在零样本和三样本设置下生成CFs。评估数据集包括AI-Readi压力预测旗舰数据集和公开心脏病检测数据集，并与DiCE/CFNOW/NICE等传统方法对比。

Result: LLM方法在合理性(最高99%)、有效性(最高0.99)和稀疏性上表现优异。使用LLM生成的CFs作为增强样本时，下游分类器准确率平均提升5%，在低数据场景效果尤为显著。

Conclusion: 基于提示的生成技术能有效增强临床和生理预测任务的可解释性与鲁棒性，代码库见github.com/anonymous/SenseCF。

Abstract: Counterfactual explanations (CFs) offer human-centric insights into machine
learning predictions by highlighting minimal changes required to alter an
outcome. Therefore, CFs can be used as (i) interventions for abnormality
prevention and (ii) augmented data for training robust models. In this work, we
explore large language models (LLMs), specifically GPT-4o-mini, for generating
CFs in a zero-shot and three-shot setting. We evaluate our approach on two
datasets: the AI-Readi flagship dataset for stress prediction and a public
dataset for heart disease detection. Compared to traditional methods such as
DiCE, CFNOW, and NICE, our few-shot LLM-based approach achieves high
plausibility (up to 99%), strong validity (up to 0.99), and competitive
sparsity. Moreover, using LLM-generated CFs as augmented samples improves
downstream classifier performance (an average accuracy gain of 5%), especially
in low-data regimes. This demonstrates the potential of prompt-based generative
techniques to enhance explainability and robustness in clinical and
physiological prediction tasks. Code base: github.com/anonymous/SenseCF.

</details>


### [82] [SingLoRA: Low Rank Adaptation Using a Single Matrix](https://arxiv.org/abs/2507.05566)
*David Bensaïd,Noam Rotstein,Roy Velich,Daniel Bensaïd,Ron Kimmel*

Main category: cs.AI

TL;DR: SingLoRA提出了一种新的低秩适应方法，通过单矩阵分解消除尺度冲突，减少参数量并提升训练稳定性，在多个任务中表现优于LoRA和LoRA+。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA方法中两个小矩阵间的尺度差异会导致训练不稳定和性能下降，需改进参数高效微调技术。

Method: 将权重更新重构为单个低秩矩阵与其转置的乘积，消除矩阵间尺度冲突，参数量减半且保证稳定优化。

Result: 在LLama 7B微调MNLI任务中准确率达91.3%（LoRA为89.1%），Stable Diffusion微调DINO相似度0.151（LoRA为0.143），均仅用60%参数量。

Conclusion: SingLoRA通过数学重构解决了低秩适应的核心问题，在理论保证和实验性能上均显著优于现有方法，具有广泛应用潜力。

Abstract: Low-Rank Adaptation (LoRA) has significantly advanced parameter-efficient
fine-tuning of large pretrained models. LoRA augments the pre-trained weights
of a model by adding the product of two smaller matrices that together form a
low-rank matrix update. Recent research has shown that scale disparities
between these two matrices often cause unstable training dynamics, leading to
suboptimal performance. In this paper, we propose SingLoRA, which reformulates
low-rank adaptation by learning the weights update as a decomposition of a
single low-rank matrix multiplied by its transpose. This simple design
inherently removes inter-matrix scale conflicts, ensuring stable optimization,
and roughly halves the parameter count. We analyze SingLoRA within the
infinite-width neural network framework, showing that it guarantees stable
feature learning by construction. Extensive experiments on multiple tasks
validate these benefits. In common sense reasoning, fine-tuning LLama 7B on
MNLI with SingLoRA achieves 91.3% accuracy - surpassing LoRA (89.1%) and LoRA+
(90.2%) - while using only 60% of their parameter budget. In image generation,
fine-tuning Stable Diffusion with SingLoRA significantly improves image
fidelity on DreamBooth, achieving a DINO similarity score of 0.151, compared to
scores of 0.148 and 0.143 for DoRA and LoRA, respectively.

</details>


### [83] [Towards Measurement Theory for Artificial Intelligence](https://arxiv.org/abs/2507.05587)
*Elija Perrier*

Main category: cs.AI

TL;DR: 本文提出建立人工智能测量的形式化理论框架，旨在通过标准化测量实现系统比较、风险评估及能力量化，并构建可校准的AI现象分类体系。


<details>
  <summary>Details</summary>
Motivation: 研究者、从业者和监管者需要形式化的AI测量理论来：(i) 比较不同系统及其评估方法；(ii) 将前沿AI评估与传统工程安全量化分析技术结合；(iii) 揭示AI能力定义对测量方法的依赖性。

Method: 提出分层测量框架，区分直接观测量与间接观测量，为构建统一可校准的AI现象分类学提供方法论路径。

Result: 通过测量操作和量表的标准化，建立了连接工程安全科学与AI评估的桥梁，为能力比较和风险分析奠定基础。

Conclusion: 形式化测量理论将推动AI评估向可量化、可比较的方向发展，其分层框架和观测量分类有望形成普适的AI现象分类体系。

Abstract: We motivate and outline a programme for a formal theory of measurement of
artificial intelligence. We argue that formalising measurement for AI will
allow researchers, practitioners, and regulators to: (i) make comparisons
between systems and the evaluation methods applied to them; (ii) connect
frontier AI evaluations with established quantitative risk analysis techniques
drawn from engineering and safety science; and (iii) foreground how what counts
as AI capability is contingent upon the measurement operations and scales we
elect to use. We sketch a layered measurement stack, distinguish direct from
indirect observables, and signpost how these ingredients provide a pathway
toward a unified, calibratable taxonomy of AI phenomena.

</details>


### [84] [MLlm-DR: Towards Explainable Depression Recognition with MultiModal Large Language Models](https://arxiv.org/abs/2507.05591)
*Wei Zhang,Juan Chen,En Zhu,Wenhong Cheng,YunPeng Li,Yanbo J. Wang*

Main category: cs.AI

TL;DR: 本文提出了一种新型多模态大语言模型MLlm-DR，通过整合轻量级查询模块和小型LLMs，实现了可解释的抑郁症诊断，并在两个基准数据集上取得了最优效果。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症自动诊断方法缺乏对评分依据的清晰解释，且当前多模态大语言模型因缺乏访谈数据训练而诊断性能不佳，亟需开发兼具解释性和高性能的解决方案。

Method: MLlm-DR模型融合小型LLMs（生成抑郁评分及诊断依据）和轻量级查询模块LQ-former（提取语音视觉特征），通过构建专业训练数据集进行微调，增强多模态信息处理能力。

Result: 模型在CMDC和E-DAIC-WOZ两个访谈基准数据集上达到最先进水平，验证了其在抑郁症综合诊断中的有效性和优越性。

Conclusion: MLlm-DR通过创新架构设计解决了现有模型解释性不足和性能受限的问题，为临床实践提供了可靠的可解释抑郁症诊断工具。

Abstract: Automated depression diagnosis aims to analyze multimodal information from
interview videos to predict participants' depression scores. Previous studies
often lack clear explanations of how these scores were determined, limiting
their adoption in clinical practice. While the advent of LLMs provides a
possible pathway for explainable depression diagnosis, current LLMs capable of
processing multimodal data lack training on interview data, resulting in poor
diagnostic performance when used directly. In this paper, we propose a novel
multimodal large language model (MLlm-DR) that can understand multimodal
information inputs and supports explainable depression diagnosis. MLlm-DR
integrates a smaller LLMs and a lightweight query module (LQ-former).
Specifically, the smaller LLMs is designed to generate depression scores and
corresponding evaluation rationales. To enhance its logical reasoning for
domain-specific tasks while maintaining practicality, we constructed a robust
training dataset to fine-tune it. Meanwhile, the LQ-former captures
depression-related features from speech and visual data, aiding the model's
ability to process multimodal information, to achieve comprehensive depression
diagnosis. Our approach achieves state-of-the-art results on two
interview-based benchmark datasets, CMDC and E-DAIC-WOZ, demonstrating its
effectiveness and superiority.

</details>


### [85] [Domain adaptation of large language models for geotechnical applications](https://arxiv.org/abs/2507.05613)
*Lei Fan,Fangxue Liu,Cheng Chen*

Main category: cs.AI

TL;DR: 本文首次综述了大型语言模型（LLMs）在岩土工程中的适应与应用，探讨了领域适配方法、应用场景及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的发展，其在岩土工程领域的应用潜力显现，但需进行领域特定适配以实现有效应用。

Method: 综述了岩土工程领域适配LLMs的关键方法，包括提示工程、检索增强生成、领域自适应预训练和微调。

Result: 分析了适配后LLMs在岩土工程中的应用现状，包括地质解释、地下表征、场地规划、设计计算、数值模拟、安全风险评估及教育辅导等。

Conclusion: 总结了岩土工程适配LLMs的优势与局限，并指出了这一跨学科领域未来研究的潜在方向，为实践者和学术界提供了参考。

Abstract: Recent developments in large language models (LLMs) are opening up new
opportunities in geotechnical engineering and engineering geology. While
general-purpose LLMs possess broad capabilities, effective application in
geotechnics often requires domain-specific adaptation. Such tailored LLMs are
increasingly employed to streamline geotechnical workflows. This paper presents
the first survey of the adaptation and application of LLMs in geotechnical
engineering. It outlines key methodologies for adaptation to geotechnical
domain, including prompt engineering, retrieval-augmented generation,
domain-adaptive pretraining, and fine-tuning. The survey examines the
state-of-the-art applications of geotechnical-adapted LLMs, including
geological interpretation, subsurface characterization, site planning, design
calculations, numerical modeling, safety and risk assessment, and educational
tutoring. It also analyzes benefits and limitations of geotechnical-adapted
LLMs, and identifies promising directions for future research in this
interdisciplinary discipline. The findings serve as a valuable resource for
practitioners seeking to integrate LLMs into geotechnical practice, while also
providing a foundation to stimulate further investigation within the academic
community.

</details>


### [86] [ADMC: Attention-based Diffusion Model for Missing Modalities Feature Completion](https://arxiv.org/abs/2507.05624)
*Wei Zhang,Juan Chen,Yanbo J. Wang,En Zhu,Xuan Yang,Yiduo Wang*

Main category: cs.AI

TL;DR: 本文提出了一种基于注意力的扩散模型（ADMC），用于处理多模态情感和意图识别中的缺失模态问题，通过独立训练各模态特征提取网络和生成接近真实分布的特征，显著提升了识别性能。


<details>
  <summary>Details</summary>
Motivation: 多模态情感和意图识别在人机交互中至关重要，但传感器故障或数据不完整导致的模态缺失是主要挑战。传统方法因过度耦合和生成不精确而效果不佳。

Method: ADMC框架独立训练各模态特征提取网络，避免过度耦合，并利用注意力扩散网络（ADN）生成与真实多模态分布一致的缺失特征，提升缺失和完整模态场景下的识别性能。

Result: 在IEMOCAP和MIntRec基准测试中，ADMC取得了最先进的结果，证明了其在缺失和完整模态场景下的有效性。

Conclusion: ADMC通过独立特征提取和注意力扩散生成，有效解决了多模态识别中的缺失模态问题，为未来研究提供了新方向。

Abstract: Multimodal emotion and intent recognition is essential for automated
human-computer interaction, It aims to analyze users' speech, text, and visual
information to predict their emotions or intent. One of the significant
challenges is that missing modalities due to sensor malfunctions or incomplete
data. Traditional methods that attempt to reconstruct missing information often
suffer from over-coupling and imprecise generation processes, leading to
suboptimal outcomes. To address these issues, we introduce an Attention-based
Diffusion model for Missing Modalities feature Completion (ADMC). Our framework
independently trains feature extraction networks for each modality, preserving
their unique characteristics and avoiding over-coupling. The Attention-based
Diffusion Network (ADN) generates missing modality features that closely align
with authentic multimodal distribution, enhancing performance across all
missing-modality scenarios. Moreover, ADN's cross-modal generation offers
improved recognition even in full-modality contexts. Our approach achieves
state-of-the-art results on the IEMOCAP and MIntRec benchmarks, demonstrating
its effectiveness in both missing and complete modality scenarios.

</details>


### [87] [Enhancing Student Learning with LLM-Generated Retrieval Practice Questions: An Empirical Study in Data Science Courses](https://arxiv.org/abs/2507.05629)
*Yuan An,John Liu,Niyam Acharya,Ruhma Hashmi*

Main category: cs.AI

TL;DR: 研究表明，由大型语言模型（LLM）生成的检索练习问题能显著提升学生知识保留率（89% vs 73%），为教师提供了一种可扩展的自动化方案，但需注意人工审核生成问题的质量。


<details>
  <summary>Details</summary>
Motivation: 检索练习虽能有效提升学习效果，但人工编制高质量问题耗时耗力，尤其在技术快速更新的学科中。LLM的自动化生成潜力有待验证其实际教学效果。

Method: 在两门大学数据科学课程（约60名学生）中开展实证研究，对比学生使用LLM生成多选题进行检索练习与无练习阶段的知识保留差异。

Result: 使用LLM生成问题的学生周平均准确率达89%，显著高于无练习阶段的73%，证实其有效提升知识保留。

Conclusion: LLM生成的检索问题可作为实时教学的高效工具，但需教师人工核查问题质量以确保可靠性。

Abstract: Retrieval practice is a well-established pedagogical technique known to
significantly enhance student learning and knowledge retention. However,
generating high-quality retrieval practice questions is often time-consuming
and labor intensive for instructors, especially in rapidly evolving technical
subjects. Large Language Models (LLMs) offer the potential to automate this
process by generating questions in response to prompts, yet the effectiveness
of LLM-generated retrieval practice on student learning remains to be
established. In this study, we conducted an empirical study involving two
college-level data science courses, with approximately 60 students. We compared
learning outcomes during one week in which students received LLM-generated
multiple-choice retrieval practice questions to those from a week in which no
such questions were provided. Results indicate that students exposed to
LLM-generated retrieval practice achieved significantly higher knowledge
retention, with an average accuracy of 89%, compared to 73% in the week without
such practice. These findings suggest that LLM-generated retrieval questions
can effectively support student learning and may provide a scalable solution
for integrating retrieval practice into real-time teaching. However, despite
these encouraging outcomes and the potential time-saving benefits, cautions
must be taken, as the quality of LLM-generated questions can vary. Instructors
must still manually verify and revise the generated questions before releasing
them to students.

</details>


### [88] [LLMs are Introvert](https://arxiv.org/abs/2507.05638)
*Litian Zhang,Xiaoming Zhang,Bingyu Yan,Ziyi Zhou,Bo Zhang,Zhenyu Guan,Xi Zhang,Chaozhuo Li*

Main category: cs.AI

TL;DR: 研究提出基于大语言模型(LLM)的社交信息传播仿真环境，通过情感引导的记忆增强社交信息处理链(SIP-CoT)机制，显著提升了LLM代理的社会智能与行为真实性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体与生成式AI的指数级增长加速了错误信息传播。传统传播模型(如SIR)难以捕捉在线交互复杂性，现有先进方法又忽视用户心理因素。LLM因其类人推理能力为模拟信息传播心理维度提供新可能。

Method: 构建LLM仿真环境模拟用户态度/情感演化，提出SIP-CoT机制（基于社交信息处理理论），通过情感引导记忆增强社交线索解读、目标个性化及反馈评估能力。

Result: 实验表明标准LLM在立场检测和心理真实性存在显著缺陷。SIP-CoT增强的LLM代理在社交信息处理、行为态度和情感表现上更接近真实人类交互。

Conclusion: 研究揭示了当前LLM传播仿真的关键局限，证实整合SIP-CoT与情感记忆能有效提升LLM代理的社会智能水平，为错误信息防控提供新思路。

Abstract: The exponential growth of social media and generative AI has transformed
information dissemination, fostering connectivity but also accelerating the
spread of misinformation. Understanding information propagation dynamics and
developing effective control strategies is essential to mitigate harmful
content. Traditional models, such as SIR, provide basic insights but
inadequately capture the complexities of online interactions. Advanced methods,
including attention mechanisms and graph neural networks, enhance accuracy but
typically overlook user psychology and behavioral dynamics. Large language
models (LLMs), with their human-like reasoning, offer new potential for
simulating psychological aspects of information spread. We introduce an
LLM-based simulation environment capturing agents' evolving attitudes,
emotions, and responses. Initial experiments, however, revealed significant
gaps between LLM-generated behaviors and authentic human dynamics, especially
in stance detection and psychological realism. A detailed evaluation through
Social Information Processing Theory identified major discrepancies in
goal-setting and feedback evaluation, stemming from the lack of emotional
processing in standard LLM training. To address these issues, we propose the
Social Information Processing-based Chain of Thought (SIP-CoT) mechanism
enhanced by emotion-guided memory. This method improves the interpretation of
social cues, personalization of goals, and evaluation of feedback. Experimental
results confirm that SIP-CoT-enhanced LLM agents more effectively process
social information, demonstrating behaviors, attitudes, and emotions closer to
real human interactions. In summary, this research highlights critical
limitations in current LLM-based propagation simulations and demonstrates how
integrating SIP-CoT and emotional memory significantly enhances the social
intelligence and realism of LLM agents.

</details>


### [89] [City-Level Foreign Direct Investment Prediction with Tabular Learning on Judicial Data](https://arxiv.org/abs/2507.05651)
*Tianxing Wu,Lizhe Cao,Shuang Wang,Jiming Wang,Shutong Zhu,Yerong Wu,Yuqing Feng*

Main category: cs.AI

TL;DR: 本文提出了一种基于司法数据的城市级外国直接投资（FDI）预测方法TLJD，通过整合司法绩效指标并考虑区域差异，显著提升了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统基于经济数据（如GDP）的FDI预测易受数据操纵影响，可靠性不足。司法数据能反映影响投资安全与回报的司法绩效，为预测提供了新视角。

Method: 首先基于1200万份公开裁判文书构建司法绩效评估指标体系，并重构表格数据集；随后提出TLJD方法，通过混合专家模型整合行列数据并动态调整区域指标权重。

Result: 跨城市和跨时间任务的实验表明，TLJD在各项指标上均优于10种前沿基线方法（R2达0.92以上）。

Conclusion: 司法数据可有效替代经济数据用于FDI预测，TLJD通过多维度司法指标编码和区域自适应加权机制，为地方政府决策提供了更可靠的预测工具。

Abstract: To advance the United Nations Sustainable Development Goal on promoting
sustained, inclusive, and sustainable economic growth, foreign direct
investment (FDI) plays a crucial role in catalyzing economic expansion and
fostering innovation. Precise city-level FDI prediction is quite important for
local government and is commonly studied based on economic data (e.g., GDP).
However, such economic data could be prone to manipulation, making predictions
less reliable. To address this issue, we try to leverage large-scale judicial
data which reflects judicial performance influencing local investment security
and returns, for city-level FDI prediction. Based on this, we first build an
index system for the evaluation of judicial performance over twelve million
publicly available adjudication documents according to which a tabular dataset
is reformulated. We then propose a new Tabular Learning method on Judicial Data
(TLJD) for city-level FDI prediction. TLJD integrates row data and column data
in our built tabular dataset for judicial performance indicator encoding, and
utilizes a mixture of experts model to adjust the weights of different
indicators considering regional variations. To validate the effectiveness of
TLJD, we design cross-city and cross-time tasks for city-level FDI predictions.
Extensive experiments on both tasks demonstrate the superiority of TLJD (reach
to at least 0.92 R2) over the other ten state-of-the-art baselines in different
evaluation metrics.

</details>


### [90] [Divergent Realities: A Comparative Analysis of Human Expert vs. Artificial Intelligence Based Generation and Evaluation of Treatment Plans in Dermatology](https://arxiv.org/abs/2507.05716)
*Dipayan Sengupta,Saumya Panda*

Main category: cs.AI

TL;DR: 研究发现AI生成的治疗方案评估存在显著'评估者效应'：人类专家更倾向同行方案，而高级AI法官则更青睐AI方案，揭示临床经验与算法逻辑间的深层差异。


<details>
  <summary>Details</summary>
Motivation: 随着AI超越诊断领域进入治疗规划，评估AI生成治疗方案的质量成为关键挑战，尤其需要比较人类专家与不同AI模型的输出差异。

Method: 10位皮肤科医生、通用AI（GPT-4o）和推理AI（o3）为5个复杂病例制定治疗方案，先由人类专家匿名评分，再由高级AI法官（Gemini 2.5 Pro）使用相同标准复评。

Result: 人类专家评分显示：同行方案显著优于AI方案（均值7.62 vs 7.16），GPT-4o排名第6，o3垫底；而AI法官结果完全相反：AI方案显著优于人类方案（均值7.75 vs 6.79），o3排名第一。

Conclusion: 临床方案的质量评估本质上取决于评估者属性，人类经验启发与算法逻辑存在根本性差异，未来需构建可解释的人机协同系统来弥合这一认知鸿沟。

Abstract: Background: Evaluating AI-generated treatment plans is a key challenge as AI
expands beyond diagnostics, especially with new reasoning models. This study
compares plans from human experts and two AI models (a generalist and a
reasoner), assessed by both human peers and a superior AI judge.
  Methods: Ten dermatologists, a generalist AI (GPT-4o), and a reasoning AI
(o3) generated treatment plans for five complex dermatology cases. The
anonymized, normalized plans were scored in two phases: 1) by the ten human
experts, and 2) by a superior AI judge (Gemini 2.5 Pro) using an identical
rubric.
  Results: A profound 'evaluator effect' was observed. Human experts scored
peer-generated plans significantly higher than AI plans (mean 7.62 vs. 7.16;
p=0.0313), ranking GPT-4o 6th (mean 7.38) and the reasoning model, o3, 11th
(mean 6.97). Conversely, the AI judge produced a complete inversion, scoring AI
plans significantly higher than human plans (mean 7.75 vs. 6.79; p=0.0313). It
ranked o3 1st (mean 8.20) and GPT-4o 2nd, placing all human experts lower.
  Conclusions: The perceived quality of a clinical plan is fundamentally
dependent on the evaluator's nature. An advanced reasoning AI, ranked poorly by
human experts, was judged as superior by a sophisticated AI, revealing a deep
gap between experience-based clinical heuristics and data-driven algorithmic
logic. This paradox presents a critical challenge for AI integration,
suggesting the future requires synergistic, explainable human-AI systems that
bridge this reasoning gap to augment clinical care.

</details>


### [91] [An autonomous agent for auditing and improving the reliability of clinical AI models](https://arxiv.org/abs/2507.05755)
*Lukas Kuhn,Florian Buettner*

Main category: cs.AI

TL;DR: 本文提出ModelAuditor工具，通过自省代理模拟临床相关分布偏移，识别AI模型在医疗影像中的潜在故障模式，并提供可解释报告与改进策略，显著提升模型在真实场景下的性能。


<details>
  <summary>Details</summary>
Motivation: AI模型在医疗影像基准测试中表现优异，但在实际部署中常因扫描设备、光照或人群差异导致性能骤降。现有可靠性审计方法效率低下，缺乏可解释工具来暴露和修复隐藏故障。

Method: ModelAuditor采用多智能体架构：1) 与用户对话选择任务指标；2) 模拟临床相关分布偏移；3) 生成包含性能退化分析、故障根因及缓解策略的可解释报告。支持在消费级硬件上10分钟内完成审计。

Result: 在病理学跨机构差异、皮肤病学人口统计偏移、胸片设备异构性三个场景中，ModelAuditor成功识别SIIM-ISIC黑色素瘤分类器等先进模型的故障模式，针对性建议使性能恢复15-25%，优于基线模型和最先进数据增强方法。单次审计成本低于0.5美元。

Conclusion: ModelAuditor为临床AI部署提供了高效、低成本的可靠性审计方案，其可解释性报告和精准改进策略能有效弥合基准测试与实际应用间的性能差距。

Abstract: The deployment of AI models in clinical practice faces a critical challenge:
models achieving expert-level performance on benchmarks can fail
catastrophically when confronted with real-world variations in medical imaging.
Minor shifts in scanner hardware, lighting or demographics can erode accuracy,
but currently reliability auditing to identify such catastrophic failure cases
before deployment is a bespoke and time-consuming process. Practitioners lack
accessible and interpretable tools to expose and repair hidden failure modes.
Here we introduce ModelAuditor, a self-reflective agent that converses with
users, selects task-specific metrics, and simulates context-dependent,
clinically relevant distribution shifts. ModelAuditor then generates
interpretable reports explaining how much performance likely degrades during
deployment, discussing specific likely failure modes and identifying root
causes and mitigation strategies. Our comprehensive evaluation across three
real-world clinical scenarios - inter-institutional variation in
histopathology, demographic shifts in dermatology, and equipment heterogeneity
in chest radiography - demonstrates that ModelAuditor is able correctly
identify context-specific failure modes of state-of-the-art models such as the
established SIIM-ISIC melanoma classifier. Its targeted recommendations recover
15-25% of performance lost under real-world distribution shift, substantially
outperforming both baseline models and state-of-the-art augmentation methods.
These improvements are achieved through a multi-agent architecture and execute
on consumer hardware in under 10 minutes, costing less than US$0.50 per audit.

</details>


### [92] [Real-time monitoring of the SoH of lithium-ion batteries](https://arxiv.org/abs/2507.05765)
*Bruno Jammes,Edgar Hernando Sepúlveda-Oviedo,Corinne Alonso*

Main category: cs.AI

TL;DR: 论文提出了一种基于充电末期放电脉冲分析的电池健康状态(SoH)实时监测创新方法，在微电网等受限环境中表现出高精度（平均绝对误差约1%）和可解释性（得分接近0.9）。


<details>
  <summary>Details</summary>
Motivation: 微电网等场景下传统电池健康监测方法受限，亟需开发新型实时SoH监测技术以满足持续运行需求。

Method: 通过分析充电末期的放电脉冲，利用等效电路模型参数估计SoH，并使用两节容量衰减85%的电池数据进行训练。

Result: 该方法对另外两节衰减至90% SoH的电池预测时，最坏情况下平均绝对误差约1%，模型可解释性得分达0.9。

Conclusion: 若性能得到进一步验证，该方法可集成至电池管理系统(BMS)，为持续运行下的优化管理提供新途径。

Abstract: Real-time monitoring of the state of health (SoH) of batteries remains a
major challenge, particularly in microgrids where operational constraints limit
the use of traditional methods. As part of the 4BLife project, we propose an
innovative method based on the analysis of a discharge pulse at the end of the
charge phase. The parameters of the equivalent electrical model describing the
voltage evolution across the battery terminals during this current pulse are
then used to estimate the SoH. Based on the experimental data acquired so far,
the initial results demonstrate the relevance of the proposed approach. After
training using the parameters of two batteries with a capacity degradation of
around 85%, we successfully predicted the degradation of two other batteries,
cycled down to approximately 90% SoH, with a mean absolute error of around 1%
in the worst case, and an explainability score of the estimator close to 0.9.
If these performances are confirmed, this method can be easily integrated into
battery management systems (BMS) and paves the way for optimized battery
management under continuous operation.

</details>


### [93] [GTA1: GUI Test-time Scaling Agent](https://arxiv.org/abs/2507.05791)
*Yan Yang,Dongxu Li,Yutong Dai,Yuhao Yang,Ziyang Luo,Zirui Zhao,Zhiyuan Hu,Junzhe Huang,Amrita Saha,Zeyuan Chen,Ran Xu,Liyuan Pan,Caiming Xiong,Junnan Li*

Main category: cs.AI

TL;DR: 本文提出GTA1智能体，通过测试时扩展方法和强化学习解决GUI任务中的动作序列规划和视觉元素定位难题，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: GUI智能体在跨平台执行任务时面临两大挑战：任务规划中的动作序列歧义性，以及复杂高分辨率界面中的视觉元素精确定位。

Method: 1) 测试时扩展方法：并行采样候选动作序列，通过评判模型选择最优方案\n2) 强化学习模型：利用目标对齐机制提升视觉元素定位准确率，奖励成功点击行为

Result: GTA1-7B在Screenspot-Pro(50.1%)、Screenspot-V2(92.4%)和OSWorld-G(67.7%)等基准测试中表现优异，结合规划器后任务成功率提升至45.2%（OSWorld）

Conclusion: 该研究通过计算资源换决策质量的策略和RL驱动的视觉定位方法，显著提升了GUI智能体的操作性能，相关代码和模型已开源

Abstract: Graphical user interface (GUI) agents autonomously operate across platforms
(e.g., Linux) to complete tasks by interacting with visual elements.
Specifically, a user instruction is decomposed into a sequence of action
proposals, each corresponding to an interaction with the GUI. After each
action, the agent observes the updated GUI environment to plan the next step.
However, two main challenges arise: i) resolving ambiguity in task planning
(i.e., the action proposal sequence), where selecting an appropriate plan is
non-trivial, as many valid ones may exist; ii) accurately grounding actions in
complex and high-resolution interfaces, i.e., precisely interacting with visual
targets.
  This paper investigates the two aforementioned challenges with our GUI
Test-time Scaling Agent, namely GTA1. First, to select the most appropriate
action proposal, we introduce a test-time scaling method. At each step, we
sample multiple candidate action proposals and leverage a judge model to
evaluate and select the most suitable one. It trades off computation for better
decision quality by concurrent sampling, shortening task execution steps, and
improving overall performance. Second, we propose a model that achieves
improved accuracy when grounding the selected action proposal to its
corresponding visual elements. Our key insight is that reinforcement learning
(RL) facilitates visual grounding through inherent objective alignments,
rewarding successful clicks on interface elements.
  Experimentally, our method establishes state-of-the-art performance across
diverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7%
accuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When
paired with a planner applying our test-time scaling strategy, it exhibits
state-of-the-art agentic performance (e.g., 45.2% task success rate on
OSWorld). We open-source our code and models here.

</details>


### [94] [Affective-ROPTester: Capability and Bias Analysis of LLMs in Predicting Retinopathy of Prematurity](https://arxiv.org/abs/2507.05816)
*Shuai Zhao,Yulin Zhang,Luwei Xiao,Xinyi Wu,Yanhao Jia,Zhongliang Guo,Xiaobao Wu,Cong-Duy Nguyen,Guoming Zhang,Anh Tuan Luu*

Main category: cs.AI

TL;DR: 本文通过构建中文ROP风险预测数据集CROP，提出Affective-ROPTester框架，系统评估大语言模型（LLMs）在ROP风险分层中的预测能力与情感偏差，发现外部知识增强可提升性能，积极情感提示能减少预测偏差。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在多领域取得进展，但其在早产儿视网膜病变（ROP）风险预测中的潜力尚未充分探索。本研究旨在填补这一空白，并探究情感因素对模型预测的影响。

Method: 提出Affective-ROPTester评估框架，包含指令提示、思维链（CoT）和上下文学习（ICL）三种策略，并在提示层面融入情感元素。使用包含993条标注记录的CROP中文数据集进行实验。

Result: 1. LLMs仅依赖内部知识时ROP预测效果有限，但结合外部知识后性能显著提升；2. 模型输出存在情感偏差，倾向于高估中高风险病例；3. 积极情感提示相比消极提示更能减少预测偏差。

Conclusion: 研究强调情感敏感提示工程对提升诊断可靠性的重要性，Affective-ROPTester可作为临床语言模型情感偏差评估与缓解的有效框架。

Abstract: Despite the remarkable progress of large language models (LLMs) across
various domains, their capacity to predict retinopathy of prematurity (ROP)
risk remains largely unexplored. To address this gap, we introduce a novel
Chinese benchmark dataset, termed CROP, comprising 993 admission records
annotated with low, medium, and high-risk labels. To systematically examine the
predictive capabilities and affective biases of LLMs in ROP risk
stratification, we propose Affective-ROPTester, an automated evaluation
framework incorporating three prompting strategies: Instruction-based,
Chain-of-Thought (CoT), and In-Context Learning (ICL). The Instruction scheme
assesses LLMs' intrinsic knowledge and associated biases, whereas the CoT and
ICL schemes leverage external medical knowledge to enhance predictive accuracy.
Crucially, we integrate emotional elements at the prompt level to investigate
how different affective framings influence the model's ability to predict ROP
and its bias patterns. Empirical results derived from the CROP dataset yield
two principal observations. First, LLMs demonstrate limited efficacy in ROP
risk prediction when operating solely on intrinsic knowledge, yet exhibit
marked performance gains when augmented with structured external inputs.
Second, affective biases are evident in the model outputs, with a consistent
inclination toward overestimating medium- and high-risk cases. Third, compared
to negative emotions, positive emotional framing contributes to mitigating
predictive bias in model outputs. These findings highlight the critical role of
affect-sensitive prompt engineering in enhancing diagnostic reliability and
emphasize the utility of Affective-ROPTester as a framework for evaluating and
mitigating affective bias in clinical language modeling systems.

</details>


### [95] [CogniPlay: a work-in-progress Human-like model for General Game Playing](https://arxiv.org/abs/2507.05868)
*Aloïs Rautureau,Éric Piette*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: While AI systems have equaled or surpassed human performance in a wide
variety of games such as Chess, Go, or Dota 2, describing these systems as
truly "human-like" remains far-fetched. Despite their success, they fail to
replicate the pattern-based, intuitive decision-making processes observed in
human cognition. This paper presents an overview of findings from cognitive
psychology and previous efforts to model human-like behavior in artificial
agents, discusses their applicability to General Game Playing (GGP) and
introduces our work-in-progress model based on these observations: CogniPlay.

</details>


### [96] [Current Practices for Building LLM-Powered Reasoning Tools Are Ad Hoc -- and We Can Do Better](https://arxiv.org/abs/2507.05886)
*Aaron Bembenek*

Main category: cs.AI

TL;DR: 本文提出了一种名为'神经符号转换系统'的计算模型，旨在为结合传统符号算法与大型语言模型（LLMs）的自动推理工具提供理论基础，以克服当前神经符号系统缺乏严格保证和深度协同的问题。


<details>
  <summary>Details</summary>
Motivation: 当前构建神经符号自动推理系统的方法缺乏传统符号算法的严格保证，且未能充分整合神经网络与符号推理，限制了LLM在推理中的潜力。

Method: 作者提出了'神经符号转换系统'模型，其中符号状态与直觉配对，状态转换并行操作符号与直觉，并探讨了如何将该模型具体化为逻辑编程语言。

Result: 该新范式有望在保持符号算法严格保证的同时，将逻辑推理能力扩展到当前技术无法达到的水平。

Conclusion: 神经符号转换系统为构建下一代神经符号自动推理工具提供了理论基础，可能实现符号算法保证与LLM推理潜力的深度结合。

Abstract: There is growing excitement about building software verifiers, synthesizers,
and other Automated Reasoning (AR) tools by combining traditional symbolic
algorithms and Large Language Models (LLMs). Unfortunately, the current
practice for constructing such neurosymbolic AR systems is an ad hoc
programming model that does not have the strong guarantees of traditional
symbolic algorithms, nor a deep enough synchronization of neural networks and
symbolic reasoning to unlock the full potential of LLM-powered reasoning. I
propose Neurosymbolic Transition Systems as a principled computational model
that can underlie infrastructure for building neurosymbolic AR tools. In this
model, symbolic state is paired with intuition, and state transitions operate
over symbols and intuition in parallel. I argue why this new paradigm can scale
logical reasoning beyond current capabilities while retaining the strong
guarantees of symbolic algorithms, and I sketch out how the computational model
I propose can be reified in a logic programming language.

</details>


### [97] [Decomposing the Time Series Forecasting Pipeline: A Modular Approach for Time Series Representation, Information Extraction, and Projection](https://arxiv.org/abs/2507.05891)
*Robert Leppich,Michael Stenger,André Bauer,Samuel Kounev*

Main category: cs.AI

TL;DR: 本文提出了一种分解时间序列预测流程的三阶段方法（输入序列表示、信息提取与记忆构建、目标投影），通过评估不同架构配置在七个基准数据集上的表现，实现了最优预测精度与计算效率的提升。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer在时间序列预测中取得进展，但有效序列表示、记忆构建和精准目标投影仍是挑战。不同数据集和预测配置构成独特任务，需针对性解决方案。

Method: 将预测流程分解为三阶段：1)输入序列表示；2)信息提取与记忆构建（采用卷积层和自注意力机制）；3)目标投影。系统评估各阶段模块组合在多样化任务中的效果。

Result: 模型在七个基准数据集上达到最优预测精度，同时显著提升计算效率（减少训练/推理时间、降低参数量）。代码已开源。

Conclusion: 通过任务导向的流程分解与模块化设计，该方法在精度与效率上超越现有技术，为时间序列预测提供了可扩展的解决方案框架。

Abstract: With the advent of Transformers, time series forecasting has seen significant
advances, yet it remains challenging due to the need for effective sequence
representation, memory construction, and accurate target projection. Time
series forecasting remains a challenging task, demanding effective sequence
representation, meaningful information extraction, and precise future
projection. Each dataset and forecasting configuration constitutes a distinct
task, each posing unique challenges the model must overcome to produce accurate
predictions. To systematically address these task-specific difficulties, this
work decomposes the time series forecasting pipeline into three core stages:
input sequence representation, information extraction and memory construction,
and final target projection. Within each stage, we investigate a range of
architectural configurations to assess the effectiveness of various modules,
such as convolutional layers for feature extraction and self-attention
mechanisms for information extraction, across diverse forecasting tasks,
including evaluations on seven benchmark datasets. Our models achieve
state-of-the-art forecasting accuracy while greatly enhancing computational
efficiency, with reduced training and inference times and a lower parameter
count. The source code is available at
https://github.com/RobertLeppich/REP-Net.

</details>


### [98] [MusiScene: Leveraging MU-LLaMA for Scene Imagination and Enhanced Video Background Music Generation](https://arxiv.org/abs/2507.05894)
*Fathinah Izzati,Xinyue Li,Yuxuan Wu,Gus Xia*

Main category: cs.AI

TL;DR: 本文提出MusiScene模型，通过音乐场景想象(MSI)任务生成与音乐匹配的场景描述，并构建大规模视频-音频字幕数据集，显著提升音乐字幕生成质量。


<details>
  <summary>Details</summary>
Motivation: 人类能从音乐中联想对应场景，但现有音乐字幕模型仅关注音乐元素。本文探索音乐语言模型是否具备跨模态场景想象能力，以增强音乐与视频的关联性。

Method: 1) 构建3,371对视频-音频字幕数据集 2) 基于MU-LLaMA微调出MusiScene模型 3) 利用MSI生成结果优化视频背景音乐生成(VBMG)任务

Result: 实验证明MusiScene生成的场景描述比MU-LLaMA更具上下文相关性，且MSI字幕能有效提升文本到视频背景音乐的生成质量。

Conclusion: MusiScene首次实现音乐驱动的场景想象，为跨模态音乐理解开辟新方向，其生成的场景描述可显著辅助视频配乐生成任务。

Abstract: Humans can imagine various atmospheres and settings when listening to music,
envisioning movie scenes that complement each piece. For example, slow,
melancholic music might evoke scenes of heartbreak, while upbeat melodies
suggest celebration. This paper explores whether a Music Language Model, e.g.
MU-LLaMA, can perform a similar task, called Music Scene Imagination (MSI),
which requires cross-modal information from video and music to train. To
improve upon existing music captioning models which focusing solely on musical
elements, we introduce MusiScene, a music captioning model designed to imagine
scenes that complement each music. In this paper, (1) we construct a
large-scale video-audio caption dataset with 3,371 pairs, (2) we finetune Music
Understanding LLaMA for the MSI task to create MusiScene, and (3) we conduct
comprehensive evaluations and prove that our MusiScene is more capable of
generating contextually relevant captions compared to MU-LLaMA. We leverage the
generated MSI captions to enhance Video Background Music Generation (VBMG) from
text.

</details>


### [99] [BlueLM-2.5-3B Technical Report](https://arxiv.org/abs/2507.05934)
*Baojiao Xiong,Boheng Chen,Chengzhi Wang,Daxiong Luo,Dongsheng Xu,Dongyang Liu,Fan Yang,Fangyuan Li,Fei Teng,Feng Wang,Fukang Qin,Fuquan Peng,Guanxin Tan,Guozhi Wang,Haibo Yu,Haohao Gao,Heng Liu,Hongbo Yang,Hongjian Zou,Houzheng Shen,Hu Meng,Huan Li,Hui Tan,Jiali Chen,Jianzhao Chen,Jinliang Zhu,Kai Wang,Lei Wu,Liangbing Liu,Liuyang Bian,Liyan He,Long Liu,Peiwen Li,Penggang Shi,Qi Ding,Rui Hu,Shuai Cao,Shuai Ren,Shuang Peng,Teng Xie,Weiji Chen,Weilin Xiang,Weixin Wu,Xi Yin,Xiaoxin Chen,Xu Chen,Yafei Wen,Yan Hu,Yanzhou Yang,Yina Xie,Yinghao Chen,Yixuan Liao,Yu Geng,Yuanjiang Ouyang,Yuanzhuo Yang,Yuehua He,Yushuai Peng,Zhaoxiong Wang,Zheng Wang,Zhibo Zhou,Ziyang Wu*

Main category: cs.AI

TL;DR: BlueLM-2.5-3B是一个紧凑的多模态大语言模型，专为边缘设备设计，具有高效的通用和推理能力，支持思考与非思考模式，并在多模态和纯文本任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开发一个高效、紧凑的多模态大语言模型，适用于边缘设备部署，同时保持强大的通用和推理能力，填补3B规模MLLM支持双模式及可控思考令牌的空白。

Method: 通过多样化数据整理、关键数据重采样、混合异构强化学习及高性能训练基础设施开发模型，仅使用29亿参数实现多模态能力与纯文本性能的平衡。

Result: 在思考模式下，BlueLM-2.5-3B在纯文本基准测试中与Qwen3-4B相当，多模态评估中仅落后Kimi-VL-A3B-16B约5%；非思考模式下，多数多模态基准测试优于Qwen2.5-VL-3B，且数据效率显著更高。

Conclusion: BlueLM-2.5-3B为高性能设备端MLLM的发展提供了重要贡献，其高效设计和优异性能为研究社区提供了有价值的见解。

Abstract: We present BlueLM-2.5-3B, a compact and unified dense Multimodal Large
Language Model (MLLM) designed for efficient edge-device deployment, offering
strong general-purpose and reasoning capabilities. To the best of our
knowledge, this is the first 3B-scale MLLM to support both thinking and
non-thinking modes, while also enabling explicit control over thinking token
budget. BlueLM-2.5-3B is developed through diversified data curation, key data
resampling, hybrid heterogeneous reinforcement learning, and a high-performance
training infrastructure. Our model achieves superior multimodal capacity while
preserving competitive pure-text performance with only 2.9 billion parameters.
We conduct comprehensive evaluations across a broad range of multimodal and
text-only benchmarks. In thinking mode, BlueLM-2.5-3B achieves comparable
performance to Qwen3-4B on text-only benchmarks, and trails the larger
Kimi-VL-A3B-16B by only about 5% on average across multimodal evaluations. In
non-thinking mode, it outperforms Qwen2.5-VL-3B on the majority of multimodal
benchmarks. Additionally, BlueLM-2.5-3B exhibits exceptional data efficiency.
All of the aforementioned performance is achieved with substantially less total
training data than Qwen2.5-VL-3B and Qwen3-4B. We hope our work contributes to
the advancement of high-performance, on-device MLLMs and provides meaningful
insights to the research community.

</details>


### [100] [A Wireless Foundation Model for Multi-Task Prediction](https://arxiv.org/abs/2507.05938)
*Yucheng Sheng,Jiacheng Wang,Xingyu Zhou,Le Liang,Hao Ye,Shi Jin,Geoffrey Ye Li*

Main category: cs.AI

TL;DR: 本文提出了一种支持多任务预测的无线网络基础模型，通过统一异构任务和因果Transformer架构，实现了对未见过场景的强泛化能力和零样本性能超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 随着移动通信网络的复杂性和动态性增加，传统深度学习方法在跨场景和跨任务的泛化能力上存在局限，亟需一种统一的基础模型来提升预测准确性。

Method: 模型采用单变量分解统一异构任务，编码粒度实现区间感知，使用因果Transformer主干网络，并通过补丁掩码策略支持任意输入长度。

Result: 在大规模数据集上训练后，该基础模型对未见场景展现出强泛化能力，在新任务上的零样本性能超越传统全样本基线方法。

Conclusion: 提出的统一基础模型有效解决了无线网络中多任务预测的泛化挑战，为零样本学习场景提供了高性能解决方案。

Abstract: With the growing complexity and dynamics of the mobile communication
networks, accurately predicting key system parameters, such as channel state
information (CSI), user location, and network traffic, has become essential for
a wide range of physical (PHY)-layer and medium access control (MAC)-layer
tasks. Although traditional deep learning (DL)-based methods have been widely
applied to such prediction tasks, they often struggle to generalize across
different scenarios and tasks. In response, we propose a unified foundation
model for multi-task prediction in wireless networks that supports diverse
prediction intervals. The proposed model enforces univariate decomposition to
unify heterogeneous tasks, encodes granularity for interval awareness, and uses
a causal Transformer backbone for accurate predictions. Additionally, we
introduce a patch masking strategy during training to support arbitrary input
lengths. After trained on large-scale datasets, the proposed foundation model
demonstrates strong generalization to unseen scenarios and achieves zero-shot
performance on new tasks that surpass traditional full-shot baselines.

</details>


### [101] [Enhancing the Interpretability of Rule-based Explanations through Information Retrieval](https://arxiv.org/abs/2507.05976)
*Alessandro Umbrico,Guido Bologna,Luca Coraci,Francesca Fracasso,Silvia Gola,Gabriella Cortellessa*

Main category: cs.AI

TL;DR: 本文提出了一种基于属性分析的改进方法，旨在提升可解释人工智能（XAI）在乳腺癌淋巴结放疗后淋巴水肿风险评估中的透明度和可接受性。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的人工智能技术缺乏透明度，限制了其在医疗决策中的可解释性和接受度，特别是在乳腺癌淋巴结放疗后淋巴水肿风险评估这一特定场景中。

Method: 该方法通过对基于规则的预测模型中的属性进行统计分析，利用信息检索技术的标准指标，计算每个属性对预测的相关性，并为用户提供关于风险因素影响的可解释信息。

Result: 用户研究结果表明，与原始可解释AI模型的输出相比，所提出的方法在预测淋巴水肿风险时具有更高的可解释性和实用性。

Conclusion: 该研究通过属性分析方法有效提升了可解释AI在医疗风险评估中的透明度和用户接受度，为临床决策提供了更可靠的辅助工具。

Abstract: The lack of transparency of data-driven Artificial Intelligence techniques
limits their interpretability and acceptance into healthcare decision-making
processes. We propose an attribution-based approach to improve the
interpretability of Explainable AI-based predictions in the specific context of
arm lymphedema's risk assessment after lymph nodal radiotherapy in breast
cancer. The proposed method performs a statistical analysis of the attributes
in the rule-based prediction model using standard metrics from Information
Retrieval techniques. This analysis computes the relevance of each attribute to
the prediction and provides users with interpretable information about the
impact of risk factors. The results of a user study that compared the output
generated by the proposed approach with the raw output of the Explainable AI
model suggested higher levels of interpretability and usefulness in the context
of predicting lymphedema risk.

</details>


### [102] [Development and Evaluation of HopeBot: an LLM-based chatbot for structured and interactive PHQ-9 depression screening](https://arxiv.org/abs/2507.05984)
*Zhijun Guo,Alvina Lai,Julia Ive,Alexandru Petcu,Yutong Wang,Luyuan Qi,Johan H Thygesen,Kezhi Li*

Main category: cs.AI

TL;DR: 研究开发了基于大语言模型的聊天机器人HopeBot，用于抑郁症筛查，相比传统PHQ-9问卷更具交互性和适应性，用户反馈显示其可信度和接受度较高。


<details>
  <summary>Details</summary>
Motivation: 传统抑郁症筛查工具PHQ-9缺乏互动性和适应性，研究旨在开发一种更高效、用户友好的替代方案。

Method: 开发了HopeBot聊天机器人，采用检索增强生成和实时澄清技术，并在英国和中国的132名成年人中进行自填与聊天机器人版本的对比研究。

Result: 聊天机器人版本与自填版本得分高度一致（ICC = 0.91），71%的参与者更信任聊天机器人，87.1%的参与者愿意再次使用或推荐HopeBot。

Conclusion: 基于语音的大语言模型聊天机器人可作为抑郁症筛查的可扩展、低负担辅助工具，具有较高的用户接受度和可行性。

Abstract: Static tools like the Patient Health Questionnaire-9 (PHQ-9) effectively
screen depression but lack interactivity and adaptability. We developed
HopeBot, a chatbot powered by a large language model (LLM) that administers the
PHQ-9 using retrieval-augmented generation and real-time clarification. In a
within-subject study, 132 adults in the United Kingdom and China completed both
self-administered and chatbot versions. Scores demonstrated strong agreement
(ICC = 0.91; 45% identical). Among 75 participants providing comparative
feedback, 71% reported greater trust in the chatbot, highlighting clearer
structure, interpretive guidance, and a supportive tone. Mean ratings (0-10)
were 8.4 for comfort, 7.7 for voice clarity, 7.6 for handling sensitive topics,
and 7.4 for recommendation helpfulness; the latter varied significantly by
employment status and prior mental-health service use (p < 0.05). Overall,
87.1% expressed willingness to reuse or recommend HopeBot. These findings
demonstrate voice-based LLM chatbots can feasibly serve as scalable, low-burden
adjuncts for routine depression screening.

</details>


### [103] [CogniSQL-R1-Zero: Lightweight Reinforced Reasoning for Efficient SQL Generation](https://arxiv.org/abs/2507.06013)
*Kushal Gajjar,Harshit Sikchi,Arpit Singh Gautam,Marc Hammons,Saurabh Jha*

Main category: cs.AI

TL;DR: 提出CogniSQL-R1-Zero强化学习框架，通过轻量级奖励信号（执行正确性与格式标签合规性）生成高精度SQL，在Text2SQL基准测试中超越现有监督学习模型，并发布两个标注数据集推动可扩展的文本到SQL研究。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型提升了文本到SQL的流畅性，但生成复杂查询的正确可执行SQL仍具挑战性。现有方法依赖中间监督或复杂奖励机制，亟需更高效稳定的解决方案。

Method: 采用纯强化学习框架，仅基于执行正确性和格式标签合规性的轻量级奖励信号，避免混合流水线与复杂奖励塑造，直接优化最终任务目标（生成可执行程序）。

Result: 在BIRD基准上取得SOTA执行准确率，以7B参数量超越CodeS-7B、DeepSeek-Coder 236B等基线模型，仅需4块NVIDIA A100 GPU（40GB显存/块）完成训练。

Conclusion: 该研究证明了强化学习在文本到SQL任务中的高效可扩展性，同时发布包含5,024条推理轨迹和36,356条弱监督查询的数据集，推动执行对齐的SQL生成研究。

Abstract: Translating natural language into SQL (Text-to-SQL) remains a core challenge
at the intersection of language understanding and structured data access.
Although large language models (LLMs) have improved fluency, generating correct
and executable SQL, especially for complex queries, continues to be
challenging. We introduce CogniSQL-R1-Zero, a reinforcement learning (RL)
framework and model that produces accurate SQL using a lightweight reward
signal based on execution correctness and format-tag compliance. By avoiding
intermediate supervision, hybrid pipelines and complex reward shaping, our
method encourages stable learning and stronger alignment with the ultimate task
objective-producing executable programs. CogniSQL-R1-Zero achieves
state-of-the-art execution accuracy on Text2SQL benchmark; BIRD bench,
outperforming prior supervised and instruction-tuned baselines including SFT
CodeS-7B, DeepSeek-Coder 236B, and Mistral 123B-despite being trained on a
significantly smaller 7B backbone. This result underscores the scalability and
efficiency of our RL-based approach when trained on just four NVIDIA A100 GPUs
(40 GB VRAM each). To support further research in efficient and interpretable
Text-to-SQL modeling, we release two curated datasets: (i) a collection of
5,024 reasoning traces with varying context lengths, and (ii) a
positive-sampled corpus of 36,356 corpus of weakly supervised queries, each
annotated with six semantically diverse reasoning paths. Together, these
contributions advance scalable, execution-aligned Text-to-SQL generation.

</details>


### [104] [Feature-Guided Neighbor Selection for Non-Expert Evaluation of Model Predictions](https://arxiv.org/abs/2507.06029)
*Courtney Ford,Mark T. Keane*

Main category: cs.AI

TL;DR: 本文提出了一种名为FGNS的可解释AI方法，通过结合局部和全局特征重要性选择类代表性样本，显著提升了非专业人士识别模型错误的能力，同时保持了与正确预测的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的可解释AI方法在生成对非领域专家清晰可解释的输出方面存在困难，需要一种能提升模型解释性的新方法。

Method: 研究引入了特征引导邻居选择（FGNS）方法，这是一种事后解释技术，通过局部和全局特征重要性选择类代表性样本来增强可解释性。

Result: 在卡纳达语脚本分类的用户研究（N=98）中，FGNS显著提高了非专家识别模型错误的准确性，决策速度更快，且所选邻居更能反映类别特征而非仅最小化特征空间距离。

Conclusion: FGNS是迈向更符合人类认知的模型评估的重要一步，但解释质量与感知信任之间的差距仍需进一步研究。

Abstract: Explainable AI (XAI) methods often struggle to generate clear, interpretable
outputs for users without domain expertise. We introduce Feature-Guided
Neighbor Selection (FGNS), a post hoc method that enhances interpretability by
selecting class-representative examples using both local and global feature
importance. In a user study (N = 98) evaluating Kannada script classifications,
FGNS significantly improved non-experts' ability to identify model errors while
maintaining appropriate agreement with correct predictions. Participants made
faster and more accurate decisions compared to those given traditional k-NN
explanations. Quantitative analysis shows that FGNS selects neighbors that
better reflect class characteristics rather than merely minimizing
feature-space distance, leading to more consistent selection and tighter
clustering around class prototypes. These results support FGNS as a step toward
more human-aligned model assessment, although further work is needed to address
the gap between explanation quality and perceived trust.

</details>


### [105] [On Lockean beliefs that are deductively closed and minimal change](https://arxiv.org/abs/2507.06042)
*Tommaso Flaminio,Lluis Godo,Ramón Pino Pérez,Lluis Subirana*

Main category: cs.AI

TL;DR: 本文在Lockean理论框架下，研究概率置信度定义的信念集合，提出两种经典逻辑闭包特征，并设计最小修正的概率更新方法以实现信念集合的演绎封闭。


<details>
  <summary>Details</summary>
Motivation: Lockean信念集合在经典逻辑演绎下通常不封闭，这限制了其在信念修正理论等场景的应用。论文旨在解决这一局限性。

Method: 通过两种特征化方法描述经典逻辑闭包的信念集合，并提出基于最小修正原则的概率更新策略。

Result: 证明了如何通过最小化修正实现信念集合的演绎封闭，即在保持原信念最大兼容性的同时纳入新信息。

Conclusion: 研究为概率性信念系统提供了理论工具，使Lockean方法能更有效地应用于需要逻辑一致性的领域。

Abstract: Within the formal setting of the Lockean thesis, an agent belief set is
defined in terms of degrees of confidence and these are described in
probabilistic terms. This approach is of established interest, notwithstanding
some limitations that make its use troublesome in some contexts, like, for
instance, in belief change theory. Precisely, Lockean belief sets are not
generally closed under (classical) logical deduction. The aim of the present
paper is twofold: on one side we provide two characterizations of those belief
sets that are closed under classical logic deduction, and on the other we
propose an approach to probabilistic update that allows us for a minimal
revision of those beliefs, i.e., a revision obtained by making the fewest
possible changes to the existing belief set while still accommodating the new
information. In particular, we show how we can deductively close a belief set
via a minimal revision.

</details>


### [106] [FEVO: Financial Knowledge Expansion and Reasoning Evolution for Large Language Models](https://arxiv.org/abs/2507.06057)
*Bo Pang,Yalu Ouyang,Hangfei Xu,Ziqi Jia,Panpan Li,Shengzhao Wen,Lu Wang,Shiyong Li,Yanpeng Wang*

Main category: cs.AI

TL;DR: 本文提出了FEVO（金融进化）框架，通过多阶段增强方法提升大语言模型在金融领域的表现，包括持续预训练、监督微调和强化学习，最终模型在多个金融基准测试中达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在数学和编程等领域取得了显著进展，但在需要大量专业知识的金融领域应用研究仍然有限。FEVO框架旨在填补这一空白，提升模型在金融任务中的表现。

Method: FEVO框架采用三阶段方法：1) 持续预训练（CPT）扩展金融领域知识；2) 监督微调（SFT）注入结构化推理模式；3) 强化学习（RL）整合金融知识与推理能力。使用高质量数据集FEVO-Train进行训练。

Result: 基于Qwen2.5-32B训练的FEVO-R32B模型在七个基准测试中评估，在五个金融基准上超越了更大规模的模型和专用模型，达到最先进性能。FEVO-R32B显著优于仅使用RL训练的FEVO-R32B-0，验证了金融知识扩展和结构化推理的有效性。

Conclusion: FEVO框架通过系统性的多阶段增强，成功提升了LLM在金融领域的性能，证明了金融领域知识扩展和结构化推理提炼的重要性，为金融领域的LLM应用提供了有效解决方案。

Abstract: Advancements in reasoning for large language models (LLMs) have lead to
significant performance improvements for LLMs in various fields such as
mathematics and programming. However, research applying these advances to the
financial domain, where considerable domain-specific knowledge is necessary to
complete tasks, remains limited. To address this gap, we introduce FEVO
(Financial Evolution), a multi-stage enhancement framework developed to enhance
LLM performance in the financial domain. FEVO systemically enhances LLM
performance by using continued pre-training (CPT) to expand financial domain
knowledge, supervised fine-tuning (SFT) to instill structured, elaborate
reasoning patterns, and reinforcement learning (RL) to further integrate the
expanded financial domain knowledge with the learned structured reasoning. To
ensure effective and efficient training, we leverage frontier reasoning models
and rule-based filtering to curate FEVO-Train, high-quality datasets
specifically designed for the different post-training phases. Using our
framework, we train the FEVO series of models -- C32B, S32B, R32B -- from
Qwen2.5-32B and evaluate them on seven benchmarks to assess financial and
general capabilities, with results showing that FEVO-R32B achieves
state-of-the-art performance on five financial benchmarks against much larger
models as well as specialist models. More significantly, FEVO-R32B demonstrates
markedly better performance than FEVO-R32B-0 (trained from Qwen2.5-32B-Instruct
using only RL), thus validating the effectiveness of financial domain knowledge
expansion and structured, logical reasoning distillation

</details>


### [107] [AI-Based Demand Forecasting and Load Balancing for Optimising Energy use in Healthcare Systems: A real case study](https://arxiv.org/abs/2507.06077)
*Iman Rahimi,Isha Patel*

Main category: cs.AI

TL;DR: 本文提出了一种结合LSTM、遗传算法和SHAP的AI框架，用于提升医疗机构能源管理效率，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 医疗机构能源需求波动大，传统方法效率低下且成本高，亟需智能解决方案提升能效与可持续性。

Method: 采用LSTM进行时间序列预测，遗传算法优化参数与负载均衡，SHAP增强模型可解释性，形成LSTM-GA-SHAP集成框架。

Result: LSTM预测性能远超ARIMA和Prophet（MAE: 21.69 vs. 59.78/87.73；RMSE: 29.96 vs. 81.22/125.22），遗传算法实现动态负载调整，SHAP提供特征贡献分析。

Conclusion: 该框架为医疗能源管理提供了高精度、可解释的解决方案，未来可结合强化学习实时优化，展现了AI在能效领域的扩展潜力。

Abstract: This paper tackles the urgent need for efficient energy management in
healthcare facilities, where fluctuating demands challenge operational
efficiency and sustainability. Traditional methods often prove inadequate,
causing inefficiencies and higher costs. To address this, the study presents an
AI-based framework combining Long Short-Term Memory (LSTM), genetic algorithm
(GA), and SHAP (Shapley Additive Explanations), specifically designed for
healthcare energy management. Although LSTM is widely used for time-series
forecasting, its application in healthcare energy prediction remains
underexplored. The results reveal that LSTM significantly outperforms ARIMA and
Prophet models in forecasting complex, non-linear demand patterns. LSTM
achieves a Mean Absolute Error (MAE) of 21.69 and Root Mean Square Error (RMSE)
of 29.96, far better than Prophet (MAE: 59.78, RMSE: 81.22) and ARIMA (MAE:
87.73, RMSE: 125.22), demonstrating superior performance. The genetic algorithm
is applied to optimize model parameters and improve load balancing strategies,
enabling adaptive responses to real-time energy fluctuations. SHAP analysis
further enhances model transparency by explaining the influence of different
features on predictions, fostering trust in decision-making processes. This
integrated LSTM-GA-SHAP approach offers a robust solution for improving
forecasting accuracy, boosting energy efficiency, and advancing sustainability
in healthcare facilities. Future research may explore real-time deployment and
hybridization with reinforcement learning for continuous optimization. Overall,
the study establishes a solid foundation for using AI in healthcare energy
management, highlighting its scalability, efficiency, and resilience potential.

</details>


### [108] [OpenAgentSafety: A Comprehensive Framework for Evaluating Real-World AI Agent Safety](https://arxiv.org/abs/2507.06134)
*Sanidhya Vijayvargiya,Aditya Bharat Soni,Xuhui Zhou,Zora Zhiruo Wang,Nouha Dziri,Graham Neubig,Maarten Sap*

Main category: cs.AI

TL;DR: 本文介绍了OpenAgentSafety框架，用于全面评估AI代理在八类关键风险中的行为安全性，支持350多项多轮多用户任务，并揭示主流LLM在51.2%-72.7%的安全漏洞任务中存在不安全行为。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理安全评估依赖模拟环境、狭窄任务域或不现实工具抽象，无法满足真实场景需求，亟需能测试真实工具交互的综合性安全框架。

Method: 提出模块化框架OpenAgentSafety，支持真实工具（浏览器/代码执行/文件系统等），结合规则分析与LLM评判，检测显性和隐性不安全行为，可灵活扩展工具和对抗策略。

Result: 实验显示：Claude-Sonnet-3.7在51.2%的安全漏洞任务中表现不安全，o3-mini达72.7%，暴露当前LLM代理的重要安全隐患。

Conclusion: 现有AI代理存在显著安全风险，OpenAgentSafety证实需加强安全防护机制才能投入实际应用，框架为后续研究提供可扩展评估基准。

Abstract: Recent advances in AI agents capable of solving complex, everyday tasks, from
scheduling to customer service, have enabled deployment in real-world settings,
but their possibilities for unsafe behavior demands rigorous evaluation. While
prior benchmarks have attempted to assess agent safety, most fall short by
relying on simulated environments, narrow task domains, or unrealistic tool
abstractions. We introduce OpenAgentSafety, a comprehensive and modular
framework for evaluating agent behavior across eight critical risk categories.
Unlike prior work, our framework evaluates agents that interact with real
tools, including web browsers, code execution environments, file systems, bash
shells, and messaging platforms; and supports over 350 multi-turn, multi-user
tasks spanning both benign and adversarial user intents. OpenAgentSafety is
designed for extensibility, allowing researchers to add tools, tasks, websites,
and adversarial strategies with minimal effort. It combines rule-based analysis
with LLM-as-judge assessments to detect both overt and subtle unsafe behaviors.
Empirical analysis of five prominent LLMs in agentic scenarios reveals unsafe
behavior in 51.2% of safety-vulnerable tasks with Claude-Sonnet-3.7, to 72.7%
with o3-mini, highlighting critical safety vulnerabilities and the need for
stronger safeguards before real-world deployment.

</details>


### [109] [The Delta Learning Hypothesis: Preference Tuning on Weak Data can Yield Strong Gains](https://arxiv.org/abs/2507.06187)
*Scott Geng,Hamish Ivison,Chun-Liang Li,Maarten Sap,Jerry Li,Ranjay Krishna,Pang Wei Koh*

Main category: cs.AI

TL;DR: 研究表明，通过配对偏好数据中的相对质量差异（delta学习），即使单个数据点质量较弱，也能有效提升语言模型性能。该方法在8B模型上验证，性能媲美使用更强监督信号的先进模型。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型改进依赖高质量监督数据，但在强监督稀缺时受限。本文探索如何利用弱数据点间的相对差异驱动模型学习。

Method: 提出delta学习假设：配对弱数据点间的质量差异足以通过偏好调优提升模型。实验使用3B与1.5B模型生成配对数据，对8B模型进行后训练。

Result: 在11个基准测试（如MATH、MMLU）中，该方法匹配了基于GPT-4o等强监督训练的Tulu 3模型性能，且成本更低。逻辑回归理论证明弱教师模型间的性能差距对强学生模型有改进信号。

Conclusion: delta学习揭示了模型能从传统认为的弱配对数据中有效学习，为开源模型后训练提供了更简单、经济的先进方案。

Abstract: Improvements in language models are often driven by improving the quality of
the data we train them on, which can be limiting when strong supervision is
scarce. In this work, we show that paired preference data consisting of
individually weak data points can enable gains beyond the strength of each
individual data point. We formulate the delta learning hypothesis to explain
this phenomenon, positing that the relative quality delta between points
suffices to drive learning via preference tuning--even when supervised
finetuning on the weak data hurts. We validate our hypothesis in controlled
experiments and at scale, where we post-train 8B models on preference data
generated by pairing a small 3B model's responses with outputs from an even
smaller 1.5B model to create a meaningful delta. Strikingly, on a standard
11-benchmark evaluation suite (MATH, MMLU, etc.), our simple recipe matches the
performance of Tulu 3, a state-of-the-art open model tuned from the same base
model while relying on much stronger supervisors (e.g., GPT-4o). Thus, delta
learning enables simpler and cheaper open recipes for state-of-the-art
post-training. To better understand delta learning, we prove in logistic
regression that the performance gap between two weak teacher models provides
useful signal for improving a stronger student. Overall, our work shows that
models can learn surprisingly well from paired data that might typically be
considered weak.

</details>


### [110] [Identifiability in Causal Abstractions: A Hierarchy of Criteria](https://arxiv.org/abs/2507.06213)
*Clément Yvernes,Emilie Devijver,Marianne Clausel,Eric Gaussier*

Main category: cs.AI

TL;DR: 本文提出了一种基于因果抽象的方法，用于在观测数据中识别处理效应，通过构建因果图集合并引入可识别性标准层次结构，解决了传统方法需要完整因果图的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统因果效应识别方法需要完整的因果图，但在复杂或高维场景中难以获取。因果抽象作为简化表示方法，能保留部分因果信息，但缺乏系统的可识别性分析框架。

Method: 将因果抽象形式化为因果图集合，提出多种可识别性标准，并构建层次化结构以阐明标准间的关联。通过文献案例验证框架，开发了不依赖完整因果知识的推理工具。

Result: 建立了可识别性标准的层次体系，揭示了不同因果知识水平下的识别能力边界。示例分析表明该框架能有效处理部分因果信息的场景。

Conclusion: 因果抽象层次框架为不完全因果知识下的效应识别提供了系统方法论，其结构化标准体系增强了可解释性和实用性。

Abstract: Identifying the effect of a treatment from observational data typically
requires assuming a fully specified causal diagram. However, such diagrams are
rarely known in practice, especially in complex or high-dimensional settings.
To overcome this limitation, recent works have explored the use of causal
abstractions-simplified representations that retain partial causal information.
In this paper, we consider causal abstractions formalized as collections of
causal diagrams, and focus on the identifiability of causal queries within such
collections. We introduce and formalize several identifiability criteria under
this setting. Our main contribution is to organize these criteria into a
structured hierarchy, highlighting their relationships. This hierarchical view
enables a clearer understanding of what can be identified under varying levels
of causal knowledge. We illustrate our framework through examples from the
literature and provide tools to reason about identifiability when full causal
knowledge is unavailable.

</details>


### [111] [Aligned Textual Scoring Rules](https://arxiv.org/abs/2507.06221)
*Yuxuan Lu,Yifan Wu,Jason Hartline,Michael J. Curry*

Main category: cs.AI

TL;DR: 本文提出了一种对齐评分规则（ASR），通过优化均方误差使文本评分规则在保持合理性的同时更符合人类偏好，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有合理评分规则虽能确保策略代理报告真实信念，但未必与人类对文本的偏好一致，需设计更符合人类偏好的评分规则。

Method: 设计ASR规则，通过最小化合理评分规则与参考分数（如人工评分）间的均方误差，实现文本评分与人类偏好的对齐。

Result: 实验表明，ASR在保持评分规则合理性的前提下，显著提升了与人类偏好的对齐效果，优于先前方法。

Conclusion: ASR成功解决了文本信息获取中评分规则与人类偏好的对齐问题，为语言模型应用提供了更可靠的评估工具。

Abstract: Scoring rules elicit probabilistic predictions from a strategic agent by
scoring the prediction against a ground truth state. A scoring rule is proper
if, from the agent's perspective, reporting the true belief maximizes the
expected score. With the development of language models, Wu and Hartline (2024)
proposes a reduction from textual information elicitation to the numerical
(i.e. probabilistic) information elicitation problem, which achieves provable
properness for textual elicitation. However, not all proper scoring rules are
well aligned with human preference over text. Our paper designs the Aligned
Scoring rule (ASR) for text by optimizing and minimizing the mean squared error
between a proper scoring rule and a reference score (e.g. human score). Our
experiments show that our ASR outperforms previous methods in aligning with
human preference while maintaining properness.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [112] [Axiomatic characterizations of dissimilarity orderings and distances between sets](https://arxiv.org/abs/2507.05919)
*Thierry Marchant,Sandip Sarkar*

Main category: cs.DM

TL;DR: 本文研究了Hamming、Jaccard、S\o rensen-Dice和Overlap等距离度量对集合对排序的影响，并给出了这些距离的特征描述。


<details>
  <summary>Details</summary>
Motivation: 研究不同距离度量如何影响集合对的排序，以及这些距离本身的数学特性。

Method: 通过数学分析和特征描述，对Hamming、Jaccard、S\o rensen-Dice和Overlap等距离进行系统研究。

Result: 确定了这些距离度量对集合对排序的具体影响，并给出了它们的数学特征。

Conclusion: 不同距离度量对集合对的排序有显著影响，研究结果为相关领域提供了理论基础。

Abstract: We characterize the orderings of pairs of sets induced by several distances:
Hamming, Jaccard, S\o rensen-Dice and Overlap. We also characterize these
distances.

</details>
