{"id": "2506.17943", "categories": ["math.LO", "03F30, 03C20, 03H15"], "pdf": "https://arxiv.org/pdf/2506.17943", "abs": "https://arxiv.org/abs/2506.17943", "authors": ["Wei Wang"], "title": "Finite Combinatorics and Fragments of Arithmetic", "comment": null, "summary": "In fragments of first order arithmetic, definable maps on finite domains\ncould behave very differently from finite maps. Here combinatorial properties\nof $\\Sigma_{n+1}$-definable maps on finite domains are compared in the absence\nof $B\\Sigma_{n+1}$. It is shown that $\\mathrm{GPHP}(\\Sigma_{n+1})$ (the\n$\\Sigma_{n+1}$-instance of Kaye's General Pigeonhole Principle) lies strictly\nbetween $\\mathrm{CARD}(\\Sigma_{n+1})$ and $\\mathrm{WPHP}(\\Sigma_{n+1})$ (Weak\nPigeonhole Principle for $\\Sigma_{n+1}$-maps), and also that\n$\\mathrm{FRT}(\\Sigma_{n+1})$ (Finite Ramsey's Theorem for $\\Sigma_{n+1}$-maps)\ndoes not imply $\\mathrm{WPHP}(\\Sigma_{n+1})$."}
{"id": "2506.17982", "categories": ["math.LO", "math.AC", "math.AT", "math.CT", "math.KT", "03E15, 13D07 (Primary) 13D09, 13F05 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.17982", "abs": "https://arxiv.org/abs/2506.17982", "authors": ["Matteo Casarosa", "Martino Lupini"], "title": "Projective length, phantom extensions, and the structure of flat modules", "comment": "97 pages", "summary": "We consider the natural generalization of the notion of the order of a\nphantom map from the topological setting to triangulated categories. When\napplied to the derived category of the category of countable flat modules over\na countable Dedekind domain, this yields a notion of\\emph{\\ phantom extension}\nof order $\\alpha <\\omega _{1}$. We provide a complexity-theoretic\ncharacterization of the module $\\mathrm{Ph}% ^{\\alpha }\\mathrm{Ext}\\left(\nC,A\\right) $ of phantom extensions of order $\\alpha $ with respect to the\nstructure of \\emph{phantom Polish module} on $\\mathrm{Ext}\\left( C,A\\right) $\nobtained by considering it as an object of the left heart of the quasi-abelian\ncategory of Polish modules. We use this characterization to prove the following\nDichotomy Theorem: either all the extensions of a countable flat module $A$ are\ntrivial (which happens precisely when $A$ is divisible) or $A$ has phantom\nextensions of arbitrarily high order.\n  By producing canonical phantom projective resolutions of order $\\alpha $, we\nprove that phantom extensions of order $\\alpha $ define on the category of\ncountable flat modules an exact structure $\\mathcal{E}_{\\alpha }$ that is\nhereditary with enough projectives, and the functor $\\mathrm{Ph}^{\\alpha }%\n\\mathrm{Ext}$ is the derived functor of $\\mathrm{Hom}$ with respect to\n$\\mathcal{E}_{\\alpha }$. We prove a Structure Theorem characterizing the\nobjects of the class $\\mathcal{P}_{\\alpha }$ of countable flat modules that\nhave \\emph{projective length at most }$\\alpha $ (i.e., are $\\mathcal{E}_{\\alpha\n}$-projective) as the direct summands of colimits of presheaves of finite flat\nmodules over well-founded forests of rank $% 1+\\alpha $ regarded as ordered\nsets. This can be seen as the first analogue in the flat case of the classical\nUlm Classification Theorem for torsion modules."}
{"id": "2506.17448", "categories": ["math.ST", "stat.ME", "stat.TH", "60G70, 62G32, 62E20,"], "pdf": "https://arxiv.org/pdf/2506.17448", "abs": "https://arxiv.org/abs/2506.17448", "authors": ["David L. Carl", "Simone A. Padoan", "Stefano Rizzelli"], "title": "Asymptotic theory for the likelihood-based block maxima method in time series", "comment": null, "summary": "This paper develops a rigorous asymptotic framework for likelihood-based\ninference in the Block Maxima (BM) method for stationary time series. While\nBayesian inference under the BM approach has been widely studied in the\nindependence setting, no asymptotic theory currently exists for time series.\nFurther results are needed to establish that BM method can be applied with the\nkind of dependent time series models relevant to applied fields. To address\nthis gap we first establish a comprehensive likelihood theory for the\nmisspecified Generalized Extreme Value (GEV) model under serial dependence. Our\nresults include uniform convergence of the empirical log-likelihood process,\ncontraction rates for the Maximum Likelihood Estimator, and a local\nasymptotically Gaussian expansion. Building on this foundation, we develop the\nasymptotic theory of Bayesian inference for the GEV parameters, the extremal\nindex, $T$-time-horizon return levels, and extreme quantiles (Value at Risk).\nUnder general conditions on the prior, we prove posterior consistency,\n$\\sqrt{k}$-contraction rates, Bernstein-von Mises theorems, and asymptotic\ncoverage properties for credible intervals. For inference on the extremal\nindex, we propose an adjusted posterior distribution that corrects for poor\ncoverage exhibited by a naive Bayesian approach. Simulations show excellent\ninferential performances for the proposed methodology."}
{"id": "2506.17233", "categories": ["cs.CR", "11Y05"], "pdf": "https://arxiv.org/pdf/2506.17233", "abs": "https://arxiv.org/abs/2506.17233", "authors": ["Akihisa Yorozu"], "title": "A Geometric Square-Based Approach to RSA Integer Factorization", "comment": "3 pages", "summary": "We present a new approach to RSA factorization inspired by geometric\ninterpretations and square differences. This method reformulates the problem in\nterms of the distance between perfect squares and provides a recurrence\nrelation that allows rapid convergence when the RSA modulus has closely spaced\nprime factors. Although this method is efficient for small semiprimes, it does\nnot yet succeed in factoring large challenges like RSA-100 in practical time,\nhighlighting both its potential and current limitations."}
{"id": "2506.17239", "categories": ["q-fin.GN"], "pdf": "https://arxiv.org/pdf/2506.17239", "abs": "https://arxiv.org/abs/2506.17239", "authors": ["Gurkirat Wadhwa", "Akansh Verma", "Veeraruna Kavitha", "Priyank Sinha"], "title": "Price equilibria with positive margins in loyal-strategic markets with discrete prices", "comment": null, "summary": "In competitive supply chains (SCs), pricing decisions are crucial, as they\ndirectly impact market share and profitability. Traditional SC models often\nassume continuous pricing for mathematical convenience, overlooking the\npractical reality of discrete price increments driven by currency constraints.\nAdditionally, customer behavior, influenced by loyalty and strategic\nconsiderations, plays a significant role in purchasing decisions. To address\nthese gaps, this study examines a SC model involving one supplier and two\nmanufacturers, incorporating realistic factors such as customer demand\nsegmentation and discrete price setting. Our analysis shows that the Nash\nequilibria (NE) among manufacturers are not unique, we then discuss the focal\nequilibrium. Our analysis also reveals that low denomination factors can lead\nto instability as the corresponding game does not have NE. Numerical\nsimulations demonstrate that even small changes in price increments\nsignificantly affect the competitive dynamics and market share distribution."}
{"id": "2506.17401", "categories": ["math.CO", "math.GR", "math.NT"], "pdf": "https://arxiv.org/pdf/2506.17401", "abs": "https://arxiv.org/abs/2506.17401", "authors": ["NathanaÃ«l Hassler", "Andrew Treglown"], "title": "Notes on sum-free sets in abelian groups", "comment": "17 pages", "summary": "In this paper we highlight a few open problems concerning maximal sum-free\nsets in abelian groups. In addition, for most even order abelian groups $G$ we\nasymptotically determine the number of maximal distinct sum-free subsets in\n$G$. Our proof makes use of the container method."}
{"id": "2506.17235", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2506.17235", "abs": "https://arxiv.org/abs/2506.17235", "authors": ["Wenpeng Zhang"], "title": "Some interesting number theory problems", "comment": null, "summary": "The main purpose of this paper is to propose some interesting number theory\nproblems related to the Legendre's symbol and the two-term exponential sums."}
{"id": "2506.17416", "categories": ["math.NT", "11M06, 11R42, 11M99, 11S40"], "pdf": "https://arxiv.org/pdf/2506.17416", "abs": "https://arxiv.org/abs/2506.17416", "authors": ["Stephan Ramon Garcia", "Ethan Simpson Lee"], "title": "Explicit conditional bounds for the residue of a Dedekind zeta-function at $s=1$", "comment": "15 pages", "summary": "We prove new explicit conditional bounds for the residue at $s=1$ of the\nDedekind zeta-function associated to a number field. Our bounds are concrete\nand all constants are presented with explicit numerical values."}
{"id": "2506.18494", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2506.18494", "abs": "https://arxiv.org/abs/2506.18494", "authors": ["Jamolidin K. Abdurakhmanov"], "title": "Distribution of codewords on the faces of a hypercube and new combinatorial identities", "comment": null, "summary": "We present a novel framework for studying combinatorial identities through\nthe geometric lens of subset distributions in q-valued cubes. By analyzing how\nelements of arbitrary subsets are distributed among the faces of the cube\nE_q^n, we discover new combinatorial identities with geometric significance. We\nprove that for any subset A contained in E_2^n, the rank function satisfies\nrefined bounds that lead to exact computations for small cardinalities.\nSpecifically, we show that for odd cardinalities, the lower bound is\n4D_A/(|A|^2-1) where D_A is the sum of all pairwise Hamming distances in A. Our\nmain theorem establishes identities connecting the number of k-dimensional\nfaces containing exactly e elements of a subset to binomial sums over all\nsubsets of specified cardinality. This yields a parametric family of identities\nwhere classical results emerge as special cases. As applications, we derive a\ngeometric interpretation of Vandermonde's identity by examining faces of\nq-valued cubes, revealing that this classical result naturally arises from\ncounting element distributions. We also obtain a completely new identity for\neven-weight vectors: (2^(k-1) - 1) times 2^(n-1) times binomial(n,k) equals the\nsum over i from 1 to floor(n/2) of binomial(n,2i) times binomial(n-2i,k-2i).\nThis identity, valid for all 1 <= k <= n, demonstrates how geometric\nperspectives can uncover hidden combinatorial relationships. Our framework\nprovides a unified approach for generating new identities and understanding\nexisting ones through subset rank analysis."}
{"id": "2506.17289", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17289", "abs": "https://arxiv.org/abs/2506.17289", "authors": ["Rahul Raja", "Arpita Vats"], "title": "Evaluating Generalization and Representation Stability in Small LMs via Prompting", "comment": "Accepted at ICML", "summary": "We investigate the generalization capabilities of small language models under\ntwo popular adaptation paradigms: few-shot prompting and supervised\nfine-tuning. While prompting is often favored for its parameter efficiency and\nflexibility, it remains unclear how robust this approach is in low-resource\nsettings and under distributional shifts. This paper presents a comparative\nstudy of prompting and fine-tuning across task formats, prompt styles, and\nmodel scales, with a focus on their behavior in both in-distribution and\nout-of-distribution (OOD) settings.\n  Beyond accuracy, we analyze the internal representations learned by each\napproach to assess the stability and abstraction of task-specific features. Our\nfindings highlight critical differences in how small models internalize and\ngeneralize knowledge under different adaptation strategies. This work offers\npractical guidance for model selection in low-data regimes and contributes\nempirical insight into the ongoing debate over prompting versus fine-tuning.\nCode for the experiments is available at the following"}
{"id": "2506.17463", "categories": ["math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.17463", "abs": "https://arxiv.org/abs/2506.17463", "authors": ["Bongjung Sung", "Peter D. Hoff"], "title": "Testing Separability of High-Dimensional Covariance Matrices", "comment": "60 pages, 25 pages in the main text", "summary": "Due to their parsimony, separable covariance models have been popular in\nmodeling matrix-variate data. However, the inference from such a model may be\nmisleading if the population covariance matrix $\\Sigma$ is actually\nnon-separable, motivating the use of statistical tests of separability.\nLikelihood ratio tests have tractable null distributions and good power when\nthe sample size $n$ is larger than the number of variables $p$, but are not\nwell-defined otherwise. Other existing separability tests for the $p>n$ case\nhave low power for small sample sizes, and have null distributions that depend\non unknown parameters, preventing exact error rate control. To address these\nissues, we propose novel invariant tests leveraging the core covariance matrix,\na complementary notion to a separable covariance matrix. We show that testing\nseparability of $\\Sigma$ is equivalent to testing sphericity of its core\ncomponent. With this insight, we construct test statistics that are\nwell-defined in high-dimensional settings and have distributions that are\ninvariant under the null hypothesis of separability, allowing for exact\nsimulation of null distributions. We study asymptotic null distributions and\nprove consistency of our tests in a $p/n\\rightarrow\\gamma\\in(0,\\infty)$\nasymptotic regime. The large power of our proposed tests relative to existing\nprocedures is demonstrated numerically."}
{"id": "2506.17236", "categories": ["cs.CR", "cs.CE", "cs.DC"], "pdf": "https://arxiv.org/pdf/2506.17236", "abs": "https://arxiv.org/abs/2506.17236", "authors": ["Serdar Metin"], "title": "Design, Implementation, and Analysis of Fair Faucets for Blockchain Ecosystems", "comment": "PhD thesis, 98 pages, 4 figures", "summary": "The present dissertation addresses the problem of fairly distributing shared\nresources in non-commercial blockchain networks. Blockchains are distributed\nsystems that order and timestamp records of a given network of users, in a\npublic, cryptographically secure, and consensual way. The records, which may in\nkind be events, transaction orders, sets of rules for structured transactions\netc. are placed within well-defined datastructures called blocks, and they are\nlinked to each other by the virtue of cryptographic pointers, in a total\nordering which represents their temporal relations of succession. The ability\nto operate on the blockchain, and/or to contribute a record to the content of a\nblock are shared resources of the blockchain systems. In commercial networks,\nthese resources are exchanged in return for fiat money, and consequently,\nfairness is not a relevant problem in terms of computer engineering. In\nnon-commercial networks, however, monetary solutions are not available, by\ndefinition. The present non-commercial blockchain networks employ trivial\ndistribution mechanisms called faucets, which offer fixed amounts of free\ntokens (called cryptocurrencies) specific to the given network. This mechanism,\nalthough simple and efficient, is prone to denial of service (DoS) attacks and\ncannot address the fairness problem. In the present dissertation, the faucet\nmechanism is adapted for fair distribution, in line with Max-min Fairness\nscheme. In total, we contributed 6 distinct Max-min Fair algorithms as\nefficient blockchain faucets. The algorithms we contribute are resistant to DoS\nattacks, low-cost in terms of blockchain computation economics, and they also\nallow for different user weighting policies."}
{"id": "2506.17628", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.17628", "abs": "https://arxiv.org/abs/2506.17628", "authors": ["Changjiang Bu", "Lixiang Chen", "Ge Lin"], "title": "The characteristic polynomial of sunflowers", "comment": null, "summary": "A uniform hypergraph is called a sunflower if all of its hyperedges intersect\nin the same set of vertices. In this paper, we determine the eigenvalues and\nspectral moments of a sunflower, thereby obtaining an explicit formula for its\ncharacteristic polynomial."}
{"id": "2506.17240", "categories": ["math.GM", "51M04, 51-08"], "pdf": "https://arxiv.org/pdf/2506.17240", "abs": "https://arxiv.org/abs/2506.17240", "authors": ["Stanley Rabinowitz", "Ercole Suppa"], "title": "More Relationships between a Central Quadrilateral and its Reference Quadrilateral", "comment": null, "summary": "The diagonals of a quadrilateral form four associated triangles, called half\ntriangles. Each half triangle is bounded by two sides of the quadrilateral and\none diagonal. If we locate a triangle center (such as the incenter, centroid,\northocenter, etc.) in each of these triangles, the four triangle centers form\nanother quadrilateral called a central quadrilateral. For each of various\nshaped quadrilaterals, and each of 1000 different triangle centers, we compare\nthe reference quadrilateral to the central quadrilateral. Using a computer, we\ndetermine how the two quadrilaterals are related. For example, we test to see\nif the two quadrilaterals are congruent, similar, have the same area, or have\nthe same perimeter."}
{"id": "2506.17605", "categories": ["math.NT", "11G05 (Primary) 14G05 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.17605", "abs": "https://arxiv.org/abs/2506.17605", "authors": ["Ben Savoie"], "title": "Infinitely many elliptic curves over $\\mathbb{Q}(i)$ with rank 2 and $j$-invariant 1728", "comment": "10 pages", "summary": "We prove that there exist infinitely many elliptic curves over\n$\\mathbb{Q}(i)$ of the form $y^2 = x^3 - \\gamma^2 x$, where $\\gamma \\in\n\\mathbb{Z}[i]$, with rank 2. In addition, we prove that if $p$ and $q$ are\nrational twin primes with $p \\equiv 5 \\bmod 8$, then $y^2 = x^3 + p q x$ has\nrank 2 over $\\mathbb{Q}(i)$. Lastly, we prove that if $p$ is a rational prime\nof the form $p = a^2 + b^4$ (of which there are infinitely many) and $p\n\\not\\equiv 1 \\bmod 16$, then $y^2 = x^3 - p x$ has rank 2 over $\\mathbb{Q}(i)$."}
{"id": "2506.18578", "categories": ["cs.DM", "cs.DS", "math.CO", "q-bio.PE", "05C85 (Primary), 05C20, 05C90, 06A07, 92D10 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.18578", "abs": "https://arxiv.org/abs/2506.18578", "authors": ["Narmina Baghirova", "Esther Galby", "Martin MilaniÄ"], "title": "Perfect phylogenies via the Minimum Uncovering Branching problem: efficiently solvable cases", "comment": null, "summary": "In this paper, we present new efficiently solvable cases of the Minimum\nUncovering Branching problem, an optimization problem with applications in\ncancer genomics introduced by Hujdurovi\\'c, Husi\\'c, Milani\\v{c}, Rizzi, and\nTomescu in 2018. The problem involves a family of finite sets, and the goal is\nto map each non-maximal set to exactly one set that contains it, minimizing the\nsum of uncovered elements across all sets in the family. Hujdurovi\\'c et al.\nformulated the problem in terms of branchings of the digraph formed by the\nproper set inclusion relation on the input sets and studied the problem\ncomplexity based on properties of the corresponding partially ordered set, in\nparticular, with respect to its height and width, defined respectively as the\nmaximum cardinality of a chain and an antichain. They showed that the problem\nis APX-complete for instances of bounded height and that a constant-factor\napproximation algorithm exists for instances of bounded width, but left the\nexact complexity for bounded-width instances open. In this paper, we answer\nthis question by proving that the problem is solvable in polynomial time. We\nderive this result by examining the structural properties of optimal solutions\nand reducing the problem to computing maximum matchings in bipartite graphs and\nmaximum weight antichains in partially ordered sets. We also introduce a new\npolynomially computable lower bound and identify another condition for\npolynomial-time solvability."}
{"id": "2506.17300", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17300", "abs": "https://arxiv.org/abs/2506.17300", "authors": ["Daniel T. Chang"], "title": "Individual Causal Inference with Structural Causal Model", "comment": null, "summary": "Individual causal inference (ICI) uses causal inference methods to understand\nand predict the effects of interventions on individuals, considering their\nspecific characteristics / facts. It aims to estimate individual causal effect\n(ICE), which varies across individuals. Estimating ICE can be challenging due\nto the limited data available for individuals, and the fact that most causal\ninference methods are population-based. Structural Causal Model (SCM) is\nfundamentally population-based. Therefore, causal discovery (structural\nlearning and parameter learning), association queries and intervention queries\nare all naturally population-based. However, exogenous variables (U) in SCM can\nencode individual variations and thus provide the mechanism for individualized\npopulation per specific individual characteristics / facts. Based on this, we\npropose ICI with SCM as a \"rung 3\" causal inference, because it involves\n\"imagining\" what would be the causal effect of a hypothetical intervention on\nan individual, given the individual's observed characteristics / facts.\nSpecifically, we propose the indiv-operator, indiv(W), to formalize/represent\nthe population individualization process, and the individual causal query, P(Y\n| indiv(W), do(X), Z), to formalize/represent ICI. We show and argue that ICI\nwith SCM is inference on individual alternatives (possible), not individual\ncounterfactuals (non-actual)."}
{"id": "2506.17527", "categories": ["math.ST", "math.CO", "math.PR", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.17527", "abs": "https://arxiv.org/abs/2506.17527", "authors": ["Shuyang Gong", "Zhangsong Li", "Qiheng Xu"], "title": "Detection and Reconstruction of a Random Hypergraph from Noisy Graph Projection", "comment": "18 pages, 1 figure", "summary": "For a $d$-uniform random hypergraph on $n$ vertices in which hyperedges are\nincluded i.i.d.\\ so that the average degree in the hypergraph is\n$n^{\\delta+o(1)}$, the projection of such a hypergraph is a graph on the same\n$n$ vertices where an edge connects two vertices if and only if they belong to\na same hyperedge. In this work, we study the inference problem where the\nobservation is a \\emph{noisy} version of the graph projection where each edge\nin the projection is kept with probability $p=n^{-1+\\alpha+o(1)}$ and each edge\nnot in the projection is added with probability $q=n^{-1+\\beta+o(1)}$. For all\nconstant $d$, we establish sharp thresholds for both detection (distinguishing\nthe noisy projection from an Erd\\H{o}s-R\\'enyi random graph with edge density\n$q$) and reconstruction (estimating the original hypergraph). Notably, our\nresults reveal a \\emph{detection-reconstruction gap} phenomenon in this\nproblem. Our work also answers a problem raised in \\cite{BGPY25+}."}
{"id": "2506.17245", "categories": ["cs.CR", "68M25 (Primary), 68Q85, 94A60 (Secondary)", "D.4.6; K.6.5; H.2.0; H.3.3"], "pdf": "https://arxiv.org/pdf/2506.17245", "abs": "https://arxiv.org/abs/2506.17245", "authors": ["Sagar Neupane"], "title": "Detecting and Mitigating SQL Injection Vulnerabilities in Web Applications", "comment": "24 pages, 4 figures", "summary": "SQL injection (SQLi) remains a critical vulnerability in web applications,\nenabling attackers to manipulate databases through malicious inputs. Despite\nadvancements in mitigation techniques, the evolving complexity of web\napplications and attack strategies continues to pose significant risks. This\npaper presents a comprehensive penetration testing methodology to identify,\nexploit, and mitigate SQLi vulnerabilities in a PHP-MySQL-based web\napplication. Utilizing tools such as OWASP ZAP, sqlmap, and Nmap, the study\ndemonstrates a systematic approach to vulnerability assessment and remediation.\nThe findings underscore the efficacy of input sanitization and prepared\nstatements in mitigating SQLi risks, while highlighting the need for ongoing\nsecurity assessments to address emerging threats. The study contributes to the\nfield by providing practical insights into effective detection and prevention\nstrategies, supported by a real-world case study."}
{"id": "2506.17652", "categories": ["math.CO", "05D40, 05B15, 05C15"], "pdf": "https://arxiv.org/pdf/2506.17652", "abs": "https://arxiv.org/abs/2506.17652", "authors": ["Tantan Dai", "Alexander Divoux", "Tom Kelly"], "title": "Entropy Bounds for Perfect Matchings in Bipartite Hypergraphs", "comment": "10 pages, 1 figure", "summary": "A hypergraph is \\textit{bipartite with bipartition} $(A, B)$ if every edge\nhas exactly one vertex in $A$, and a matching in such a hypergraph is\n\\textit{$A$-perfect} if it saturates every vertex in $A$. We prove an upper\nbound on the number of $A$-perfect matchings in uniform hypergraphs with small\nmaximum codegree. Using this result, we prove that there exist order-$n$ Latin\nsquares with at most $(n/e^{2.117})^n$ transversals when $n$ is odd and $n\n\\equiv 0\\pmod 3$. We also show that $k$-uniform $D$-regular hypergraphs on $n$\nvertices have at most $((1+o(1))q/e^k)^{Dn/k}$ proper $q$-edge-colorings when\n$q = (1+o(1))D$ and the maximum codegree is $o(q)$."}
{"id": "2506.18103", "categories": ["math.GM", "11B37 (Primary), 11B83, 11B75 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.18103", "abs": "https://arxiv.org/abs/2506.18103", "authors": ["Benoit Cloitre"], "title": "A study of a family of self-referential sequences", "comment": "17 pages, 3 figures", "summary": "We introduce and analyze a three-parameter family of self-referential integer\nsequences $S(x,y,z)$: starting from $a(1)=x$, each term advances by $y$ when\nthe index $k$ has already appeared as a value and by $z$ otherwise. This simple\nrule generates a surprising zoo of behaviors, many of which are catalogued --\nalbeit in a rather unstructured fashion -- in the OEIS. Whenever $y>z>0$, we\nprove that the density $a(k)/k$ converges to the positive root of $r^2 - z r -\n(y - z) = 0$. Two subfamilies, $S(x,Z+1,Z)$ and $S(x,Z,Z+1)$, yield explicit\nnon-homogeneous Beatty sequences, providing explicit formulas for numerous OEIS\nentries. For $y=0$ and $z \\ge 2$, the sequences eventually become periodic and\nsatisfy linear recurrences. Critical cases with a zero discriminant unveil\ngeometric patterns on triangular, square, and hexagonal lattices. Finally, via\ntree-like representations we uncover a tight link with meta-Fibonacci\nrecurrences."}
{"id": "2506.17684", "categories": ["math.NT", "Primary 11B99, Secondary 11A07"], "pdf": "https://arxiv.org/pdf/2506.17684", "abs": "https://arxiv.org/abs/2506.17684", "authors": ["Cristian Cobeli", "Alexandru Zaharescu", "Zhuo Zhang"], "title": "Pattern formation Statistics on Fermat Quotients", "comment": "18 pages, 4 tables, and 4 figures", "summary": "Despite their simple definition as $\\mathfrak{q}_p(b):=\\frac{b^{p-1}-1}{p}\n\\pmod p$, for $0\\le b \\le p^2-1$ and $\\gcd(b,p)=1$, and their regular\narrangement in a $p\\times(p-1)$ Fermat quotient matrix $\\mathtt{FQM}(p)$ of\nintegers from $[0,p-1]$, Fermat quotients modulo $p$ are well known for their\noverall lack of regularity. Here, we discuss this contrasting effect by proving\nthat, on the one hand, any line of the matrix behaves like an analogue of a\nrandomly distributed sequence of numbers, and on the other hand, the spatial\nstatistics of distances on regular $N$-patterns confirm the natural\nexpectations."}
{"id": "2506.17271", "categories": ["math.OC", "cs.DM", "cs.GT", "90-XX"], "pdf": "https://arxiv.org/pdf/2506.17271", "abs": "https://arxiv.org/abs/2506.17271", "authors": ["Antoine Lhomme", "Nicolas Catusse", "Nadia Brauner"], "title": "On the convergence of computational methods for the online bin stretching problem", "comment": null, "summary": "Online bin stretching is an online packing problem where some of the best\nknown lower and upper bounds were found through computational searches. The\nlimiting factor in obtaining better bounds with such methods is the\ncomputational time allowed. However, there is still no theoretical guarantee\nthat such methods do converge towards the optimal online performance. This\npaper shows that such methods do, in fact, converge; moreover, bounds on the\ngap to the optimal are also given. These results frame a theoretical foundation\nfor the convergence of computational approaches for online problems."}
{"id": "2506.17434", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17434", "abs": "https://arxiv.org/abs/2506.17434", "authors": ["Sydney Levine", "Matija Franklin", "Tan Zhi-Xuan", "Secil Yanik Guyot", "Lionel Wong", "Daniel Kilov", "Yejin Choi", "Joshua B. Tenenbaum", "Noah Goodman", "Seth Lazar", "Iason Gabriel"], "title": "Resource Rational Contractualism Should Guide AI Alignment", "comment": "24 pages, 10 figures", "summary": "AI systems will soon have to navigate human environments and make decisions\nthat affect people and other AI agents whose goals and values diverge.\nContractualist alignment proposes grounding those decisions in agreements that\ndiverse stakeholders would endorse under the right conditions, yet securing\nsuch agreement at scale remains costly and slow -- even for advanced AI. We\ntherefore propose Resource-Rational Contractualism (RRC): a framework where AI\nsystems approximate the agreements rational parties would form by drawing on a\ntoolbox of normatively-grounded, cognitively-inspired heuristics that trade\neffort for accuracy. An RRC-aligned agent would not only operate efficiently,\nbut also be equipped to dynamically adapt to and interpret the ever-changing\nhuman social world."}
{"id": "2506.18215", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.18215", "abs": "https://arxiv.org/abs/2506.18215", "authors": ["Marco Avella-Medina", "Richard Davis", "Gennady Samorodnitsky"], "title": "Estimating quantile treatments without strict overlap", "comment": null, "summary": "We consider the problem of estimating quantile treatment effects without\nassuming strict overlap , i.e., we do not assume that the propensity score is\nbounded away from zero. More specifically, we consider an inverse probability\nweighting (IPW) approach for estimating quantiles in the potential outcomes\nframework and pay special attention to scenarios where the propensity scores\ncan tend to zero as a regularly varying function. Our approach effectively\nconsiders a heavy-tailed objective function for estimating the quantile\nprocess. We introduce a truncated IPW estimator that is shown to outperform the\nstandard quantile IPW estimator when strict overlap does not hold. We show that\nthe limiting distribution of the estimated quantile process follows a stable\ndistribution and converges at the rate $n^{1-1/\\gamma}$, where $\\gamma>1$ is\nthe tail index of the propensity scores when they tend to zero. We illustrate\nthe performance of our estimators in numerical experiments and in a dataset\nthat exhibits the presence of extreme propensity scores."}
{"id": "2506.17266", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17266", "abs": "https://arxiv.org/abs/2506.17266", "authors": ["Sunil Kumar Jang Bahadur", "Gopala Dhar"], "title": "Securing Generative AI Agentic Workflows: Risks, Mitigation, and a Proposed Firewall Architecture", "comment": "Proposed workflow", "summary": "Generative Artificial Intelligence (GenAI) presents significant advancements\nbut also introduces novel security challenges, particularly within agentic\nworkflows where AI agents operate autonomously. These risks escalate in\nmulti-agent systems due to increased interaction complexity. This paper\noutlines critical security vulnerabilities inherent in GenAI agentic workflows,\nincluding data privacy breaches, model manipulation, and issues related to\nagent autonomy and system integration. It discusses key mitigation strategies\nsuch as data encryption, access control, prompt engineering, model monitoring,\nagent sandboxing, and security audits. Furthermore, it details a proposed\n\"GenAI Security Firewall\" architecture designed to provide comprehensive,\nadaptable, and efficient protection for these systems by integrating various\nsecurity services and leveraging GenAI itself for enhanced defense. Addressing\nthese security concerns is paramount for the responsible and safe deployment of\nthis transformative technology."}
{"id": "2506.17659", "categories": ["math.CO", "math.SP"], "pdf": "https://arxiv.org/pdf/2506.17659", "abs": "https://arxiv.org/abs/2506.17659", "authors": ["Lies Beers", "Raffaella Mulas"], "title": "Coloring outside the lines: Spectral bounds for generalized hypergraph colorings", "comment": null, "summary": "It is known that, for an oriented hypergraph with (vertex) coloring number\n$\\chi$ and smallest and largest normalized Laplacian eigenvalues $\\lambda_1$\nand $\\lambda_N$, respectively, the inequality $\\chi\\geq\n(\\lambda_N-\\lambda_1)/\\min\\{\\lambda_N-1,1-\\lambda_1\\}$ holds. We provide\nnecessary conditions for oriented hypergraphs for which this bound is tight.\nFocusing on $c$-uniform unoriented hypergraphs, we then generalize the bound to\nthe setting of \\emph{$d$-proper colorings}: colorings in which no edge contains\nmore than $d$ vertices of the same color. We also adapt our proof techniques to\nderive analogous spectral bounds for \\emph{$d$-improper colorings} of graphs\nand for edge colorings of hypergraphs. Moreover, for all coloring notions\nconsidered, we provide necessary conditions under which the bound is an\nequality."}
{"id": "2506.17753", "categories": ["math.NT", "Primary 11F72, Secondary 37C35, 37D40"], "pdf": "https://arxiv.org/pdf/2506.17753", "abs": "https://arxiv.org/abs/2506.17753", "authors": ["Christos Katsivelos"], "title": "The hyperbolic lattice counting problem in large dimensions", "comment": "19 pages", "summary": "For $n\\geq 3$ and $\\Gamma$ a cocompact lattice acting on the hyperbolic space\n$\\mathbb{H}^n$, we investigate the average behaviour of the error term in the\ncircle problem. First, we explore the local average of the error term over\ncompact sets of $\\Gamma\\backslash\\mathbb{H}^n$. Our upper bound depends on the\nquantum variance and the spectral exponential sums appearing in the study of\nthe Prime geodesic theorem. We also prove $\\Omega$-results for the mean value\nand the second moment of the error term."}
{"id": "2506.17442", "categories": ["cs.AI", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17442", "abs": "https://arxiv.org/abs/2506.17442", "authors": ["Hao Guan", "David Bates", "Li Zhou"], "title": "Keeping Medical AI Healthy: A Review of Detection and Correction Methods for System Degradation", "comment": "15 pages, 5 figures", "summary": "Artificial intelligence (AI) is increasingly integrated into modern\nhealthcare, offering powerful support for clinical decision-making. However, in\nreal-world settings, AI systems may experience performance degradation over\ntime, due to factors such as shifting data distributions, changes in patient\ncharacteristics, evolving clinical protocols, and variations in data quality.\nThese factors can compromise model reliability, posing safety concerns and\nincreasing the likelihood of inaccurate predictions or adverse outcomes. This\nreview presents a forward-looking perspective on monitoring and maintaining the\n\"health\" of AI systems in healthcare. We highlight the urgent need for\ncontinuous performance monitoring, early degradation detection, and effective\nself-correction mechanisms. The paper begins by reviewing common causes of\nperformance degradation at both data and model levels. We then summarize key\ntechniques for detecting data and model drift, followed by an in-depth look at\nroot cause analysis. Correction strategies are further reviewed, ranging from\nmodel retraining to test-time adaptation. Our survey spans both traditional\nmachine learning models and state-of-the-art large language models (LLMs),\noffering insights into their strengths and limitations. Finally, we discuss\nongoing technical challenges and propose future research directions. This work\naims to guide the development of reliable, robust medical AI systems capable of\nsustaining safe, long-term deployment in dynamic clinical settings."}
{"id": "2506.17269", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17269", "abs": "https://arxiv.org/abs/2506.17269", "authors": ["Paritosh Ranjan", "Surajit Majumder", "Prodip Roy"], "title": "Digital Privacy Everywhere", "comment": "18 pages, 10 figures", "summary": "The increasing proliferation of digital and mobile devices equipped with\ncameras, microphones, GPS, and other privacy invasive components has raised\nsignificant concerns for businesses operating in sensitive or policy restricted\nenvironments. Current solutions rely on passive enforcement, such as signage or\nverbal instructions, which are largely ineffective. This paper presents Digital\nPrivacy Everywhere (DPE), a comprehensive and scalable system designed to\nactively enforce custom privacy policies for digital devices within predefined\nphysical boundaries. The DPE architecture includes a centralized management\nconsole, field verification units (FVUs), enforcement modules for mobile\ndevices (EMMDs), and an External Geo Ownership Service (EGOS). These components\ncollaboratively detect, configure, and enforce privacy settings such as\ndisabling cameras, microphones, or radios across various premises like\ntheaters, hospitals, financial institutions, and educational facilities. The\nsystem ensures privacy compliance in real time while maintaining a seamless\nuser experience and operational scalability across geographies."}
{"id": "2506.17706", "categories": ["math.CO", "math.QA", "05E05, 20C08, 17B37"], "pdf": "https://arxiv.org/pdf/2506.17706", "abs": "https://arxiv.org/abs/2506.17706", "authors": ["Mikhail Zaitsev"], "title": "Quantum $\\mathfrak{gl}$-weight system and its average values", "comment": null, "summary": "We present a proof of a recent conjecture due to M. Kazarian, E. Krasilnikov,\nS. Lando, and M. Shapiro, which describes the average value of the universal\n$\\mathfrak{gl}$-weight system on permutations. The proof uses a quantum\nanalogue of the $\\mathfrak{gl}$-weight system on Hecke algebras of type $A$,\nwhich leads to a one-parameter deformation of the average value of the\nuniversal ${\\mathfrak{gl}}$-weight system. We show that the average value of\nthe quantum weight system is a linear combination of one-part Schur functions,\nwith coefficients being $q$-analogues of Bernoulli polynomials."}
{"id": "2506.18065", "categories": ["math.NT", "11N32 (11N37, 11D57, 11G35)"], "pdf": "https://arxiv.org/pdf/2506.18065", "abs": "https://arxiv.org/abs/2506.18065", "authors": ["Yijie Diao"], "title": "Liouville function, von Mangoldt function and norm forms at random binary forms", "comment": "39 pages", "summary": "We analyze the average behavior of various arithmetic functions at the values\nof degree $d$ binary forms ordered by height, with probability $1$. This\napproach yields averaged versions of the Chowla conjecture and the Bateman-Horn\nconjecture for random binary forms. Furthermore, we show that the rational\nHasse principle holds for almost all Ch\\^atelet varieties defined by a fixed\nnorm form of degree $e$ and by varying binary forms of fixed degree $d$,\nprovided $e$ divides $d$. This proves an average version of a conjecture of\nColliot-Th\\'el\\`ene."}
{"id": "2506.17449", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17449", "abs": "https://arxiv.org/abs/2506.17449", "authors": ["Manasa Bharadwaj", "Nikhil Verma", "Kevin Ferreira"], "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "comment": null, "summary": "Efforts to improve Large Language Model (LLM) agent performance on complex\ntasks have largely focused on fine-tuning and iterative self-correction.\nHowever, these approaches often lack generalizable mechanisms for longterm\nlearning and remain inefficient in dynamic environments. We introduce\nOmniReflect, a hierarchical, reflection-driven framework that constructs a\nconstitution, a compact set of guiding principles distilled from task\nexperiences, to enhance the effectiveness and efficiency of an LLM agent.\nOmniReflect operates in two modes: Self-sustaining, where a single agent\nperiodically curates its own reflections during task execution, and\nCo-operative, where a Meta-advisor derives a constitution from a small\ncalibration set to guide another agent. To construct these constitutional\nprinciples, we employ Neural, Symbolic, and NeuroSymbolic techniques, offering\na balance between contextual adaptability and computational efficiency.\nEmpirical results averaged across models show major improvements in task\nsuccess, with absolute gains of +10.3% on ALFWorld, +23.8% on BabyAI, and +8.3%\non PDDL in the Self-sustaining mode. Similar gains are seen in the Co-operative\nmode, where a lightweight Qwen3-4B ReAct agent outperforms all Reflexion\nbaselines on BabyAI. These findings highlight the robustness and effectiveness\nof OmniReflect across environments and backbones."}
{"id": "2506.17260", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17260", "abs": "https://arxiv.org/abs/2506.17260", "authors": ["Chunfeng Cui", "Liqun Qi", "Yi Xu"], "title": "Sum-of-Squares Biquadratic Polynomials", "comment": null, "summary": "Hilbert indicated that a positive semi-definite (psd) homogeneous quartic\npolynomial of four variables may not be sum of squares (sos). A $2 \\times 2$\nbiquadratic polynomial is a homogeneous quartic polynomial of four variables.\nIs a psd $2 \\times 2$ biquadratic polynomial sos? In this paper, we present a\nnecessary and sufficient condition for a $2 \\times 2$ psd biquadratic\npolynomial to be sos. We show that if a $2 \\times 2$ sos biquadratic polynomial\nis sos, then it is sos of tetranomials, its sos rank is at most $4$, and the\ncoefficients of the tetranomials can be orthogonal to each other. We show that\na $2 \\times 2$ psd biquadratic polynomial with one half-cross term or without\nhalf-cross terms is always sos of binomials (sosb). Sufficient conditions for\n$2 \\times 2$ psd biquadratic polynomials with two half-cross terms to be sosb\nare presented. We also present a case in which the psd biquadratic polynomials\nare sos of trinomials (sostri)."}
{"id": "2506.17279", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17279", "abs": "https://arxiv.org/abs/2506.17279", "authors": ["Yash Sinha", "Manit Baser", "Murari Mandal", "Dinil Mon Divakaran", "Mohan Kankanhalli"], "title": "Step-by-Step Reasoning Attack: Revealing 'Erased' Knowledge in Large Language Models", "comment": null, "summary": "Knowledge erasure in large language models (LLMs) is important for ensuring\ncompliance with data and AI regulations, safeguarding user privacy, mitigating\nbias, and misinformation. Existing unlearning methods aim to make the process\nof knowledge erasure more efficient and effective by removing specific\nknowledge while preserving overall model performance, especially for retained\ninformation. However, it has been observed that the unlearning techniques tend\nto suppress and leave the knowledge beneath the surface, thus making it\nretrievable with the right prompts. In this work, we demonstrate that\n\\textit{step-by-step reasoning} can serve as a backdoor to recover this hidden\ninformation. We introduce a step-by-step reasoning-based black-box attack,\nSleek, that systematically exposes unlearning failures. We employ a structured\nattack framework with three core components: (1) an adversarial prompt\ngeneration strategy leveraging step-by-step reasoning built from LLM-generated\nqueries, (2) an attack mechanism that successfully recalls erased content, and\nexposes unfair suppression of knowledge intended for retention and (3) a\ncategorization of prompts as direct, indirect, and implied, to identify which\nquery types most effectively exploit unlearning weaknesses. Through extensive\nevaluations on four state-of-the-art unlearning techniques and two widely used\nLLMs, we show that existing approaches fail to ensure reliable knowledge\nremoval. Of the generated adversarial prompts, 62.5% successfully retrieved\nforgotten Harry Potter facts from WHP-unlearned Llama, while 50% exposed unfair\nsuppression of retained knowledge. Our work highlights the persistent risks of\ninformation leakage, emphasizing the need for more robust unlearning strategies\nfor erasure."}
{"id": "2506.17777", "categories": ["math.CO", "cs.CG", "52C10"], "pdf": "https://arxiv.org/pdf/2506.17777", "abs": "https://arxiv.org/abs/2506.17777", "authors": ["Noga Alon", "Shakhar Smorodinsky"], "title": "Extended VC-dimension, and Radon and Tverberg type theorems for unions of convex sets", "comment": null, "summary": "We define and study an extension of the notion of the VC-dimension of a\nhypergraph and apply it to establish a Tverberg type theorem for unions of\nconvex sets. We also prove a new Radon type theorem for unions of convex sets,\n  vastly improving the estimates in an earlier result of B\\'ar\\'any and Kalai."}
{"id": "2506.18236", "categories": ["math.NT", "11F55, 11F60, 11F70"], "pdf": "https://arxiv.org/pdf/2506.18236", "abs": "https://arxiv.org/abs/2506.18236", "authors": ["Nobuki Takeda"], "title": "Differential operators on Hermitian modular forms on $\\mathrm{u}(n, n)$", "comment": null, "summary": "We construct explicit differential operators on hermitian modular forms,\nextending methods developed for Siegel modular forms. These differential\noperators are closely related to the two-variable spherical pluriharmonic\npolynomials. We construct explicit bases for the space of such polynomials and\nuse them to build concrete operators. As an application, we derive an exact\npullback formula for hermitian Eisenstein series."}
{"id": "2506.17484", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17484", "abs": "https://arxiv.org/abs/2506.17484", "authors": ["Yao Zhang", "Zaixi Shang", "Silpan Patel", "Mikel Zuniga"], "title": "From Unstructured Communication to Intelligent RAG: Multi-Agent Automation for Supply Chain Knowledge Bases", "comment": "Accepted In Proceedings of the 1st Workshop on AI for Supply Chain:\n  Today and Future @ 31st ACM SIGKDD Conference on Knowledge Discovery and Data\n  Mining V.2 (KDD 25), August 3, 2025, Toronto, ON, Canada. ACM, New York, NY,\n  USA, 14 pages, 2 figures", "summary": "Supply chain operations generate vast amounts of operational data; however,\ncritical knowledge such as system usage practices, troubleshooting workflows,\nand resolution techniques often remains buried within unstructured\ncommunications like support tickets, emails, and chat logs. While RAG systems\naim to leverage such communications as a knowledge base, their effectiveness is\nlimited by raw data challenges: support tickets are typically noisy,\ninconsistent, and incomplete, making direct retrieval suboptimal. Unlike\nexisting RAG approaches that focus on runtime optimization, we introduce a\nnovel offline-first methodology that transforms these communications into a\nstructured knowledge base. Our key innovation is a LLMs-based multi-agent\nsystem orchestrating three specialized agents: Category Discovery for taxonomy\ncreation, Categorization for ticket grouping, and Knowledge Synthesis for\narticle generation. Applying our methodology to real-world support tickets with\nresolution notes and comments, our system creates a compact knowledge base -\nreducing total volume to just 3.4% of original ticket data while improving\nquality. Experiments demonstrate that our prebuilt knowledge base in RAG\nsystems significantly outperforms traditional RAG implementations (48.74% vs.\n38.60% helpful answers) and achieves a 77.4% reduction in unhelpful responses.\nBy automating institutional knowledge capture that typically remains siloed in\nexperts' heads, our solution translates to substantial operational efficiency:\nreducing support workload, accelerating resolution times, and creating\nself-improving systems that automatically resolve approximately 50% of future\nsupply chain tickets. Our approach addresses a key gap in knowledge management\nby transforming transient communications into structured, reusable knowledge\nthrough intelligent offline processing rather than latency-inducing runtime\narchitectures."}
{"id": "2506.17270", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17270", "abs": "https://arxiv.org/abs/2506.17270", "authors": ["Janine Strotherm", "Julian Rolfes", "Barbara Hammer"], "title": "Existence and Uniqueness of Physically Correct Hydraulic States in Water Distribution Systems -- A theoretical analysis on the solvability of non-linear systems of equations in the context of water distribution systems", "comment": null, "summary": "Planning and extension of water distribution systems (WDSs) plays a key role\nin the development of smart cities, driven by challenges such as urbanization\nand climate change. In this context, the correct estimation of physically\ncorrect hydraulic states, i.e., pressure heads, water demands and water flows,\nis of high interest. Hydraulic emulators such as EPANET or more recently,\nphysic-informed surrogate models are used to solve this task. They require a\nsubset of observed states, such as heads at reservoirs and water demands, as\ninputs to estimate the whole hydraulic state. In order to obtain reliable\nresults of such emulators, but also to be able to give theoretical guarantees\nof their estimations, an important question is whether theoretically, the\nsubset of observed states that the emulator requires as an input suffices to\nderive the whole state, purely based on the physical properties, also called\nhydraulic principles, it obeys. This questions translates to solving linear and\nnon-linear systems of equations. Previous articles investigate on the existence\nquestion under the term observability analysis, however, they rely on the\napproximation of the non-linear principles using Taylor approximation and on\nnetwork-dependent numerical or algebraic algorithms. In this work, we provide\npurely theoretical guarantees on the existence and uniqueness of solutions to\nthe non-linear hydraulic principles, and by this, the existence and uniqueness\nof physically correct states, given common subsets of them -- a result that\nseems to be common-sense in the water community but has never been rigorously\nproven. We show that previous existence results are special cases of our more\ngeneral findings, and therefore lay the foundation for further analysis and\ntheoretical guarantees of the before-mentioned hydraulic emulators."}
{"id": "2506.17292", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17292", "abs": "https://arxiv.org/abs/2506.17292", "authors": ["Quan Nguyen", "Minh N. Vu", "Truc Nguyen", "My T. Thai"], "title": "Theoretically Unmasking Inference Attacks Against LDP-Protected Clients in Federated Vision Models", "comment": "Accepted to ICML 2025", "summary": "Federated Learning enables collaborative learning among clients via a\ncoordinating server while avoiding direct data sharing, offering a perceived\nsolution to preserve privacy. However, recent studies on Membership Inference\nAttacks (MIAs) have challenged this notion, showing high success rates against\nunprotected training data. While local differential privacy (LDP) is widely\nregarded as a gold standard for privacy protection in data analysis, most\nstudies on MIAs either neglect LDP or fail to provide theoretical guarantees\nfor attack success rates against LDP-protected data. To address this gap, we\nderive theoretical lower bounds for the success rates of low-polynomial time\nMIAs that exploit vulnerabilities in fully connected or self-attention layers.\nWe establish that even when data are protected by LDP, privacy risks persist,\ndepending on the privacy budget. Practical evaluations on federated vision\nmodels confirm considerable privacy risks, revealing that the noise required to\nmitigate these attacks significantly degrades models' utility."}
{"id": "2506.17804", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.17804", "abs": "https://arxiv.org/abs/2506.17804", "authors": ["Kada Williams"], "title": "Greedy Gossiping", "comment": null, "summary": "The renowned Gossiping Problem (1971) asks the following. There are $n$\npeople who each know an item of gossip. In a telephone call, two people share\nall the gossip they know. How many calls are needed for all of them to be\ninformed of all the gossip? If $n\\ge 4$, the answer is $2n-4$.\n  We initiate and solve the related Greedy Gossiping Problem: given a fixed\nnumber $m<2n-4$ of calls, at most how much gossip can be known altogether? If\nevery call increases the total knowledge of gossip as much as possible, the sum\nreaches $n^2$ only when $m=2n-3$. Our main result is that surprisingly, for\neach $m<2n-4$, this calling strategy is optimal."}
{"id": "2506.18287", "categories": ["math.NT", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.18287", "abs": "https://arxiv.org/abs/2506.18287", "authors": ["Chen Wang", "Sheng-Jie Wang"], "title": "On a conjectural supercongruence involving the dual sequence $s_n(x)$", "comment": "16 pages", "summary": "In 2017, motivated by a supercongruence conjectured by Kimoto and Wakayama\nand confirmed by Long, Osburn and Swisher, Z.-W. Sun introduced the sequence of\npolynomials: $$\ns_n(x)=\\sum_{k=0}^n\\binom{n}{k}\\binom{x}{k}\\binom{x+k}{k}=\\sum_{k=0}^n\\binom{n}{k}(-1)^k\\binom{x}{k}\\binom{-1-x}{k}\n$$ and investigated its congruence properties. In particular, Z.-W. Sun\nconjectured that for any prime $p>3$ and $p$-adic integer $x\\neq-1/2$ one has\n\\begin{equation*} \\sum_{n=0}^{p-1}s_n(x)^2\\equiv (-1)^{\\langle\nx\\rangle_p}\\frac{p+2(x-\\langle x\\rangle_p)}{2x+1}\\pmod{p^3}, \\end{equation*}\nwhere $\\langle x\\rangle_p$ denotes the least nonnegative residue of $x$ modulo\n$p$. In this paper, we confirm this conjecture."}
{"id": "2506.17514", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17514", "abs": "https://arxiv.org/abs/2506.17514", "authors": ["Ninareh Mehrabi", "Tharindu Kumarage", "Kai-Wei Chang", "Aram Galstyan", "Rahul Gupta"], "title": "Kaleidoscopic Teaming in Multi Agent Simulations", "comment": null, "summary": "Warning: This paper contains content that may be inappropriate or offensive.\n  AI agents have gained significant recent attention due to their autonomous\ntool usage capabilities and their integration in various real-world\napplications. This autonomy poses novel challenges for the safety of such\nsystems, both in single- and multi-agent scenarios. We argue that existing red\nteaming or safety evaluation frameworks fall short in evaluating safety risks\nin complex behaviors, thought processes and actions taken by agents. Moreover,\nthey fail to consider risks in multi-agent setups where various vulnerabilities\ncan be exposed when agents engage in complex behaviors and interactions with\neach other. To address this shortcoming, we introduce the term kaleidoscopic\nteaming which seeks to capture complex and wide range of vulnerabilities that\ncan happen in agents both in single-agent and multi-agent scenarios. We also\npresent a new kaleidoscopic teaming framework that generates a diverse array of\nscenarios modeling real-world human societies. Our framework evaluates safety\nof agents in both single-agent and multi-agent setups. In single-agent setup,\nan agent is given a scenario that it needs to complete using the tools it has\naccess to. In multi-agent setup, multiple agents either compete against or\ncooperate together to complete a task in the scenario through which we capture\nexisting safety vulnerabilities in agents. We introduce new in-context\noptimization techniques that can be used in our kaleidoscopic teaming framework\nto generate better scenarios for safety analysis. Lastly, we present\nappropriate metrics that can be used along with our framework to measure safety\nof agents. Utilizing our kaleidoscopic teaming framework, we identify\nvulnerabilities in various models with respect to their safety in agentic\nuse-cases."}
{"id": "2506.17271", "categories": ["math.OC", "cs.DM", "cs.GT", "90-XX"], "pdf": "https://arxiv.org/pdf/2506.17271", "abs": "https://arxiv.org/abs/2506.17271", "authors": ["Antoine Lhomme", "Nicolas Catusse", "Nadia Brauner"], "title": "On the convergence of computational methods for the online bin stretching problem", "comment": null, "summary": "Online bin stretching is an online packing problem where some of the best\nknown lower and upper bounds were found through computational searches. The\nlimiting factor in obtaining better bounds with such methods is the\ncomputational time allowed. However, there is still no theoretical guarantee\nthat such methods do converge towards the optimal online performance. This\npaper shows that such methods do, in fact, converge; moreover, bounds on the\ngap to the optimal are also given. These results frame a theoretical foundation\nfor the convergence of computational approaches for online problems."}
{"id": "2506.17299", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17299", "abs": "https://arxiv.org/abs/2506.17299", "authors": ["Shuyi Lin", "Anshuman Suri", "Alina Oprea", "Cheng Tan"], "title": "LLM Jailbreak Oracle", "comment": null, "summary": "As large language models (LLMs) become increasingly deployed in\nsafety-critical applications, the lack of systematic methods to assess their\nvulnerability to jailbreak attacks presents a critical security gap. We\nintroduce the jailbreak oracle problem: given a model, prompt, and decoding\nstrategy, determine whether a jailbreak response can be generated with\nlikelihood exceeding a specified threshold. This formalization enables a\nprincipled study of jailbreak vulnerabilities. Answering the jailbreak oracle\nproblem poses significant computational challenges -- the search space grows\nexponentially with the length of the response tokens. We present Boa, the first\nefficient algorithm for solving the jailbreak oracle problem. Boa employs a\nthree-phase search strategy: (1) constructing block lists to identify refusal\npatterns, (2) breadth-first sampling to identify easily accessible jailbreaks,\nand (3) depth-first priority search guided by fine-grained safety scores to\nsystematically explore promising low-probability paths. Boa enables rigorous\nsecurity assessments including systematic defense evaluation, standardized\ncomparison of red team attacks, and model certification under extreme\nadversarial conditions."}
{"id": "2506.17862", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.17862", "abs": "https://arxiv.org/abs/2506.17862", "authors": ["Tewodros Amdeberhan", "Doron Zeilberger"], "title": "Proofs Of Three Geode Conjectures", "comment": "9 pages", "summary": "In the May 2025 issue of the Amer. Math. Monthly, Norman J. Wildberger and\nDean Rubine intoduced a new kind of multi-indexed numbers, that they call\n`Geode numbers', obtained from the Hyper-Catalan numbers. They posed three\nintriguing conjectures about them, that are proved in this note."}
{"id": "2506.18299", "categories": ["math.NT", "11T23, 14F20"], "pdf": "https://arxiv.org/pdf/2506.18299", "abs": "https://arxiv.org/abs/2506.18299", "authors": ["Dante Bonolis", "Emmanuel Kowalski", "Katharine Woo"], "title": "Stratification theorems for exponential sums in families", "comment": "44 pages; 1 appendix by Forey, Fres\\'an and Kowalski", "summary": "We survey some of the stratification theorems concerning exponential sums\nover finite fields, especially those due to Katz-Laumon and Fouvry-Katz, as\nwell as some of their applications. Moreover, motivated partly by recent work\nof Bonolis, Pierce and Woo (arXiv:2505.11226), we prove that these\nstratification statements admit uniform variants in families, both\nalgebraically and analytically.\n  The paper includes an Appendix by Forey, Fres\\'an and Kowalski (excerpted\nfrom arXiv:2109.11961), which provides an elementary intuitive introduction to\ntrace functions in more than one variable over finite fields."}
{"id": "2506.17585", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17585", "abs": "https://arxiv.org/abs/2506.17585", "authors": ["Yukun Huang", "Sanxing Chen", "Jian Pei", "Manzil Zaheer", "Bhuwan Dhingra"], "title": "Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models", "comment": null, "summary": "Trustworthy language models should provide both correct and verifiable\nanswers. While language models can sometimes attribute their outputs to\npretraining data, their citations are often unreliable due to hallucination. As\na result, current systems insert citations by querying an external retriever at\ninference time, introducing latency, infrastructure dependence, and\nvulnerability to retrieval noise. We explore whether LLMs can be made to\nreliably attribute to the documents seen during (continual)\npretraining--without test-time retrieval--by revising the training process. To\nevaluate this, we release CitePretrainBench, a benchmark that mixes real-world\ncorpora (Wikipedia, Common Crawl, arXiv) with novel, unseen documents and\nprobes both short-form (single fact) and long-form (multi-fact) citation tasks.\nOur approach follows a two-stage process: (1) continual pretraining to bind\nfacts to persistent document identifiers, and (2) instruction tuning to elicit\ncitation behavior. We find that simple Passive Indexing, which appends an\nidentifier to each document, helps memorize verbatim text but fails on\nparaphrased or compositional facts. Instead, we propose Active Indexing, which\ncontinually pretrains on synthetic QA pairs that (1) restate each fact in\ndiverse compositional forms, and (2) require bidirectional source-to-fact and\nfact-to-source generation, jointly teaching the model to generate content from\na cited source and to attribute its own answers. Experiments with Qwen2.5-7B\nand 3B show that Active Indexing consistently outperforms Passive Indexing\nacross all tasks and models, with citation precision gains up to 30.2 percent.\nOur ablation studies reveal that performance continues to improve as we scale\nthe amount of augmented data, showing a clear upward trend even at 16 times the\noriginal token count."}
{"id": "2506.17273", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17273", "abs": "https://arxiv.org/abs/2506.17273", "authors": ["Marc Lambert"], "title": "The LQR-SchrÃ¶dinger Bridge", "comment": null, "summary": "We consider the Schr{\\\"o}dinger bridge problem in discrete time, where the\npathwise cost is replaced by a sum of quadratic functions, taking the form of a\nlinear quadratic regulator (LQR) cost. This cost comprises potential terms that\nact as attractors and kinetic terms that control the diffusion of the process.\nWhen the two boundary marginals are Gaussian, we show that the\nLQR-Schr{\\\"o}dinger bridge problem can be solved in closed form. We follow the\ndynamic programming principle, interpreting the Kantorovich potentials as\ncost-to-go functions. Under the LQR-Gaussian assumption, these potentials can\nbe propagated exactly in a backward and forward passes, leading to a system of\ndual Riccati equations, well known in estimation and control. This system\nconverges rapidly in practice. We then show that the optimal process is\nMarkovian and compute its transition kernel in closed form as well as the\nGaussian marginals. Through numerical experiments, we demonstrate that this\napproach can be used to construct complex, non-homogeneous Gaussian processes\nwith acceleration and loops, given well-chosen attractive potentials. Moreover,\nthis approach allows extending the Bures transport between Gaussian\ndistributions to more complex geometries with negative curvature."}
{"id": "2506.17308", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17308", "abs": "https://arxiv.org/abs/2506.17308", "authors": ["Koichi Nagatsuka", "Terufumi Morishita", "Yasuhiro Sogawa"], "title": "A Nested Watermark for Large Language Models", "comment": "6 pages, 3 figures", "summary": "The rapid advancement of large language models (LLMs) has raised concerns\nregarding their potential misuse, particularly in generating fake news and\nmisinformation. To address these risks, watermarking techniques for\nautoregressive language models have emerged as a promising means for detecting\nLLM-generated text. Existing methods typically embed a watermark by increasing\nthe probabilities of tokens within a group selected according to a single\nsecret key. However, this approach suffers from a critical limitation: if the\nkey is leaked, it becomes impossible to trace the text's provenance or\nattribute authorship. To overcome this vulnerability, we propose a novel nested\nwatermarking scheme that embeds two distinct watermarks into the generated text\nusing two independent keys. This design enables reliable authorship\nidentification even in the event that one key is compromised. Experimental\nresults demonstrate that our method achieves high detection accuracy for both\nwatermarks while maintaining the fluency and overall quality of the generated\ntext."}
{"id": "2506.17915", "categories": ["math.CO", "05C05, 05C09"], "pdf": "https://arxiv.org/pdf/2506.17915", "abs": "https://arxiv.org/abs/2506.17915", "authors": ["Cheng Zeng", "Gengji Li"], "title": "Some sharp bounds on the average Steiner (k, l)-eccentricity for trees", "comment": "14 pages, 6 figures", "summary": "In this paper we introduce some transformations for trees that do not\nincrease the average Steiner $(k,l)$-eccentricity for all $0\\leq l\\leq k\\leq\nn$. Using these transformations, we obtain some sharp bounds on the average\nSteiner $(k,l)$-eccentricity for trees with some certain conditions, including\ngiven nodes, given diameter, given max degree and given leaves, and get the\ncorresponding extremal trees as well."}
{"id": "2506.18395", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.18395", "abs": "https://arxiv.org/abs/2506.18395", "authors": ["Hong Ziwei", "Zheng Zhiyong"], "title": "The second moment of Ramanujan sums", "comment": null, "summary": "In this paper, we analyze $C(x, y)$, the second moment of Ramanujan sums.\nAssuming the Riemann Hypothesis, we derive an asymptotic formula for $C(x, y)$\nwith improved error term precision. The key feature of our approach is that it\nallows $x$ and $y$ to be arbitrarily close."}
{"id": "2506.17589", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17589", "abs": "https://arxiv.org/abs/2506.17589", "authors": ["Bowen Wang"], "title": "Taming the Untamed: Graph-Based Knowledge Retrieval and Reasoning for MLLMs to Conquer the Unknown", "comment": null, "summary": "The real value of knowledge lies not just in its accumulation, but in its\npotential to be harnessed effectively to conquer the unknown. Although recent\nmultimodal large language models (MLLMs) exhibit impressing multimodal\ncapabilities, they often fail in rarely encountered domain-specific tasks due\nto limited relevant knowledge. To explore this, we adopt visual game cognition\nas a testbed and select Monster Hunter: World as the target to construct a\nmultimodal knowledge graph (MH-MMKG), which incorporates multi-modalities and\nintricate entity relations. We also design a series of challenging queries\nbased on MH-MMKG to evaluate the models' ability for complex knowledge\nretrieval and reasoning. Furthermore, we propose a multi-agent retriever that\nenables a model to autonomously search relevant knowledge without additional\ntraining. Experimental results show that our approach significantly enhances\nthe performance of MLLMs, providing a new perspective on multimodal\nknowledge-augmented reasoning and laying a solid foundation for future\nresearch."}
{"id": "2506.17305", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17305", "abs": "https://arxiv.org/abs/2506.17305", "authors": ["Vinesha Peiris", "Nadezda Sukhorukova", "Julien Ugon"], "title": "KKT-based optimality conditions for neural network approximation", "comment": "Submitted to a journal", "summary": "In this paper, we obtain necessary optimality conditions for neural network\napproximation. We consider neural networks in Manhattan ($l_1$ norm) and\nChebyshev ($\\max$ norm). The optimality conditions are based on neural networks\nwith at most one hidden layer. We reformulate nonsmooth unconstrained\noptimisation problems as larger dimension constrained problems with smooth\nobjective functions and constraints. Then we use KKT conditions to develop the\nnecessary conditions and present the optimality conditions in terms of convex\nanalysis and convex sets."}
{"id": "2506.17309", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17309", "abs": "https://arxiv.org/abs/2506.17309", "authors": ["Aditya Choudhary", "Sarthak Pawar", "Yashodhara Haribhakta"], "title": "Efficient Malware Detection with Optimized Learning on High-Dimensional Features", "comment": "This paper has been accepted for presentation at the International\n  Conference on Innovations in Intelligent Systems: Advancements in Computing,\n  Communication, and Cybersecurity (ISAC3)", "summary": "Malware detection using machine learning requires feature extraction from\nbinary files, as models cannot process raw binaries directly. A common approach\ninvolves using LIEF for raw feature extraction and the EMBER vectorizer to\ngenerate 2381-dimensional feature vectors. However, the high dimensionality of\nthese features introduces significant computational challenges. This study\naddresses these challenges by applying two dimensionality reduction techniques:\nXGBoost-based feature selection and Principal Component Analysis (PCA). We\nevaluate three reduced feature dimensions (128, 256, and 384), which correspond\nto approximately 5.4%, 10.8%, and 16.1% of the original 2381 features, across\nfour models-XGBoost, LightGBM, Extra Trees, and Random Forest-using a unified\ntraining, validation, and testing split formed from the EMBER-2018, ERMDS, and\nBODMAS datasets. This approach ensures generalization and avoids dataset bias.\nExperimental results show that LightGBM trained on the 384-dimensional feature\nset after XGBoost feature selection achieves the highest accuracy of 97.52% on\nthe unified dataset, providing an optimal balance between computational\nefficiency and detection performance. The best model, trained in 61 minutes\nusing 30 GB of RAM and 19.5 GB of disk space, generalizes effectively to\ncompletely unseen datasets, maintaining 95.31% accuracy on TRITIUM and 93.98%\naccuracy on INFERNO. These findings present a scalable, compute-efficient\napproach for malware detection without compromising accuracy."}
{"id": "2506.17921", "categories": ["math.CO", "05C20 (Primary) 05C35 (Secondary)", "G.2.2"], "pdf": "https://arxiv.org/pdf/2506.17921", "abs": "https://arxiv.org/abs/2506.17921", "authors": ["Vasily Buslov"], "title": "How Trees on Atoms of Subset Algebras Define Minimal Forests and Their Growth", "comment": "23 pages, 7 figures", "summary": "A complete description is given of how minimal trees on atoms of the algebra\nof subsets $\\mathfrak{A}_k$ generated by minimal spanning $k$-component forests\nof a weighted digraph $V$ determine the form of these forests and how forests\ngrow with increasing number of arcs (that is with a decrease in the number of\ntrees). Precise bounds are established on what can be extracted about the tree\nstructure of the original graph if the minimal trees on the atoms of a single\nalgebra $\\mathfrak{A}_k$ are known, and also what minimum spanning forests with\nfewer components can be constructed based on this, and what exactly additional\ninformation is required to determine minimum spanning forests consisting of\neven fewer components."}
{"id": "2506.18461", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.18461", "abs": "https://arxiv.org/abs/2506.18461", "authors": ["Hongguang Wu", "Jun Qiu"], "title": "Partial sums of the hyperharmonic series", "comment": null, "summary": "In 1946, Erd\\\"os and Niven proved that no two partial sums of the harmonic\nseries are equal. In this paper, we extend this result by demonstrating that no\ntwo partial sums of the hyperharmonic series are equal."}
{"id": "2506.17644", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17644", "abs": "https://arxiv.org/abs/2506.17644", "authors": ["Zimo Ji", "Daoyuan Wu", "Wenyuan Jiang", "Pingchuan Ma", "Zongjie Li", "Shuai Wang"], "title": "Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges", "comment": null, "summary": "Capture-the-Flag (CTF) competitions are crucial for cybersecurity education\nand training. As large language models (LLMs) evolve, there is increasing\ninterest in their ability to automate CTF challenge solving. For example, DARPA\nhas organized the AIxCC competition since 2023 to advance AI-powered automated\noffense and defense. However, this demands a combination of multiple abilities,\nfrom knowledge to reasoning and further to actions. In this paper, we highlight\nthe importance of technical knowledge in solving CTF problems and deliberately\nconstruct a focused benchmark, CTFKnow, with 3,992 questions to measure LLMs'\nperformance in this core aspect. Our study offers a focused and innovative\nmeasurement of LLMs' capability in understanding CTF knowledge and applying it\nto solve CTF challenges. Our key findings reveal that while LLMs possess\nsubstantial technical knowledge, they falter in accurately applying this\nknowledge to specific scenarios and adapting their strategies based on feedback\nfrom the CTF environment.\n  Based on insights derived from this measurement study, we propose CTFAgent, a\nnovel LLM-driven framework for advancing CTF problem-solving. CTFAgent\nintroduces two new modules: two-stage Retrieval Augmented Generation (RAG) and\ninteractive Environmental Augmentation, which enhance LLMs' technical knowledge\nand vulnerability exploitation on CTF, respectively. Our experimental results\nshow that, on two popular CTF datasets, CTFAgent both achieves over 80%\nperformance improvement. Moreover, in the recent picoCTF2024 hosted by CMU,\nCTFAgent ranked in the top 23.6% of nearly 7,000 participating teams. This\nreflects the benefit of our measurement study and the potential of our\nframework in advancing LLMs' capabilities in CTF problem-solving."}
{"id": "2506.17405", "categories": ["math.OC", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2506.17405", "abs": "https://arxiv.org/abs/2506.17405", "authors": ["Bowen Li", "Ya-xiang Yuan"], "title": "Convergent Proximal Multiblock ADMM for Nonconvex Dynamics-Constrained Optimization", "comment": "32 pages, 6 figures", "summary": "This paper proposes a provably convergent multiblock ADMM for nonconvex\noptimization with nonlinear dynamics constraints, overcoming the divergence\nissue in classical extensions. We consider a class of optimization problems\nthat arise from discretization of dynamics-constrained variational problems\nthat are optimization problems for a functional constrained by time-dependent\nODEs or PDEs. This is a family of $n$-sum nonconvex optimization problems with\nnonlinear constraints. We study the convergence properties of the proximal\nalternating direction method of multipliers (proximal ADMM) applied to those\nproblems. Taking the advantage of the special problem structure, we show that\nunder local Lipschitz and local $L$-smooth conditions, the sequence generated\nby the proximal ADMM is bounded and all accumulation points are KKT points.\nBased on our analysis, we also design a procedure to determine the penalty\nparameters $\\rho_i$ and the proximal parameters $\\eta_i$. We further prove that\namong all the subsequences that converge, the fast one converges at the rate of\n$o(1/k)$. The numerical experiments are performed on 4D variational data\nassimilation problems and as the solver of implicit schemes for stiff problems.\nThe proposed proximal ADMM has more stable performance than gradient-based\nmethods. We discuss the implementation to solve the subproblems, a new way to\nsolve the implicit schemes, and the advantages of the proposed algorithm."}
{"id": "2506.17315", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.17315", "abs": "https://arxiv.org/abs/2506.17315", "authors": ["Chuan Yan", "Liuhuo Wan", "Bowei Guan", "Fengqi Yu", "Guangdong Bai", "Jin Song Dong"], "title": "Tracking GPTs Third Party Service: Automation, Analysis, and Insights", "comment": "The 1st International Workshop on LLM App Store Analysis (LLMapp\n  2025)", "summary": "ChatGPT has quickly advanced from simple natural language processing to\ntackling more sophisticated and specialized tasks. Drawing inspiration from the\nsuccess of mobile app ecosystems, OpenAI allows developers to create\napplications that interact with third-party services, known as GPTs. GPTs can\nchoose to leverage third-party services to integrate with specialized APIs for\ndomain-specific applications. However, the way these disclose privacy setting\ninformation limits accessibility and analysis, making it challenging to\nsystematically evaluate the data privacy implications of third-party integrate\nto GPTs. In order to support academic research on the integration of\nthird-party services in GPTs, we introduce GPTs-ThirdSpy, an automated\nframework designed to extract privacy settings of GPTs. GPTs-ThirdSpy provides\nacademic researchers with real-time, reliable metadata on third-party services\nused by GPTs, enabling in-depth analysis of their integration, compliance, and\npotential security risks. By systematically collecting and structuring this\ndata, GPTs-ThirdSpy facilitates large-scale research on the transparency and\nregulatory challenges associated with the GPT app ecosystem."}
{"id": "2506.17922", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.17922", "abs": "https://arxiv.org/abs/2506.17922", "authors": ["Aleams Barra"], "title": "A unified approach to total irregular labeling", "comment": null, "summary": "We present a unified approach to compute the total vertex irregularity\nstrength (tvs) of various graphs, employing a novel technique recently proposed\nby Barra et al. For graphs such as cycles, paths, prisms, wheels, complete\ngraphs, helm graphs, friendship graphs, and $K_{n,n}$ , we offer simplified and\nunified proofs of their previously established tvs values. Furthermore, we\nresolve an open problem by determining the tvs for simple 2-regular graphs."}
{"id": "2506.18712", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.18712", "abs": "https://arxiv.org/abs/2506.18712", "authors": ["Tewodros Amdeberhan", "George E. Andrews", "Cristina Ballantine"], "title": "Lambert series and double Lambert series", "comment": "19 pages", "summary": "We consider relationships between classical Lambert series, multiple Lambert\nseries and classical $q$-series of the Rogers-Ramanujan type. We conclude with\na contemplation on the Andrews-Dixit-Schultz-Yee conjecture."}
{"id": "2506.17667", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17667", "abs": "https://arxiv.org/abs/2506.17667", "authors": ["Lintao Wang", "Encheng Su", "Jiaqi Liu", "Pengze Li", "Peng Xia", "Jiabei Xiao", "Wenlong Zhang", "Xinnan Dai", "Xi Chen", "Yuan Meng", "Mingyu Ding", "Lei Bai", "Wanli Ouyang", "Shixiang Tang", "Aoran Wang", "Xinzhu Ma"], "title": "PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models", "comment": null, "summary": "Physics problem-solving is a challenging domain for large AI models,\nrequiring integration of conceptual understanding, mathematical reasoning, and\ninterpretation of physical diagrams. Current evaluation methodologies show\nnotable limitations in capturing the breadth and complexity of\nundergraduate-level physics, underscoring the need for more rigorous\nassessments. To this end, we present PhysUniBench, a large-scale multimodal\nbenchmark designed to evaluate and improve the reasoning capabilities of\nmultimodal large language models (MLLMs) specifically on undergraduate-level\nphysics problems. PhysUniBench consists of 3,304 physics questions spanning 8\nmajor sub-disciplines of physics, each accompanied by one visual diagrams. The\nbenchmark includes both open-ended and multiple-choice questions,\nsystematically curated and difficulty-rated through an iterative\nmodel-in-the-loop process. The benchmark's construction involved a rigorous\nmulti-stage process, including multiple roll-outs, expert-level evaluation,\nautomated filtering of easily solved problems, and a nuanced difficulty grading\nsystem with five levels. Through extensive experiments, we observe that current\nstate-of-the-art models encounter substantial challenges in physics reasoning.\nFor example, GPT-4o mini achieves only about 34.2\\% accuracy in the proposed\nPhysUniBench. These results highlight that current MLLMs struggle with advanced\nphysics reasoning, especially on multi-step problems and those requiring\nprecise diagram interpretation. By providing a broad and rigorous assessment\ntool, PhysUniBench aims to drive progress in AI for Science, encouraging the\ndevelopment of models with stronger physical reasoning, problem-solving skills,\nand multimodal understanding. The benchmark and evaluation scripts are\navailable at https://prismax-team.github.io/PhysUniBenchmark/."}
{"id": "2506.17465", "categories": ["math.OC", "47A52, 65-02, 34A55, 65L09, 65N21, 65T60"], "pdf": "https://arxiv.org/pdf/2506.17465", "abs": "https://arxiv.org/abs/2506.17465", "authors": ["Clemens Kirisits", "Bochra Mejri", "Sergei Pereverzev", "Otmar Scherzer", "Cong Shi"], "title": "Regularization of Nonlinear Inverse Problems -- From Functional Analysis to Data-Driven Approaches", "comment": null, "summary": "The focus of this book is on the analysis of regularization methods for\nsolving \\emph{nonlinear inverse problems}. Specifically, we place a strong\nemphasis on techniques that incorporate supervised or unsupervised data derived\nfrom prior experiments. This approach enables the integration of data-driven\ninsights into the solution of inverse problems governed by physical models.\n\\emph{Inverse problems}, in general, aim to uncover the \\emph{inner mechanisms}\nof an observed system based on indirect or incomplete measurements. This field\nhas far-reaching applications across various disciplines, such as medical or\ngeophysical imaging, as well as, more broadly speaking, industrial processes\nwhere identifying hidden parameters is essential."}
{"id": "2506.17317", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17317", "abs": "https://arxiv.org/abs/2506.17317", "authors": ["Liuhuo Wan", "Chuan Yan", "Mark Huasong Meng", "Kailong Wang", "Haoyu Wang", "Guangdong Bai", "Jin Song Dong"], "title": "Beyond the Scope: Security Testing of Permission Management in Team Workspace", "comment": null, "summary": "Nowadays team workspaces are widely adopted for multi-user collaboration and\ndigital resource management. To further broaden real-world applications,\nmainstream team workspaces platforms, such as Google Workspace and Microsoft\nOneDrive, allow third-party applications (referred to as add-ons) to be\nintegrated into their workspaces, significantly extending the functionality of\nteam workspaces. The powerful multi-user collaboration capabilities and\nintegration of add-ons make team workspaces a central hub for managing shared\nresources and protecting them against unauthorized access. Due to the\ncollaboration features of team workspaces, add-ons involved in collaborations\nmay bypass the permission isolation enforced by the administrator, unlike in\nsingle-user permission management.\n  This paper aims to investigate the permission management landscape of team\nworkspaces add-ons. To this end, we perform an in-depth analysis of the\nenforced access control mechanism inherent in this ecosystem, considering both\nmulti-user and cross-app features. We identify three potential security risks\nthat can be exploited to cause permission escalation. We then systematically\nreveal the landscape of permission escalation risks in the current ecosystem.\nSpecifically, we propose an automated tool, TAI, to systematically test all\npossible interactions within this ecosystem. Our evaluation reveals that\npermission escalation vulnerabilities are widespread in this ecosystem, with 41\ninteractions identified as problematic. Our findings should raise an alert to\nboth the team workspaces platforms and third-party developers."}
{"id": "2506.18073", "categories": ["math.CO", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2506.18073", "abs": "https://arxiv.org/abs/2506.18073", "authors": ["Nero Ziyu Li", "Frank Xin Hu", "Thomas Britz"], "title": "Reducible Iterated Graph Systems: multiscale-freeness and multifractals", "comment": null, "summary": "Iterated Graph Systems (IGS) aims to transplant ideas from fractal geometry\ninto graph theory. Building on this framework, we extend Edge IGS from the\nprimitive to the reducible setting. Within this broader context, we formulate\nrigorous definitions of multifractality and multiscale-freeness for graph\nfractals, and we establish conditions that are equivalent to the occurrence of\nthese two phenomena. We further determine the corresponding fractal and degree\nspectra, proving that both are finite and discrete. These results complete the\nfoundational theory of Edge IGS by filling the gap left by the primitive case\nstudied in [1,2]."}
{"id": "2506.18776", "categories": ["math.NT", "math.AG", "20K15, 11J95, 11R32, 11G50"], "pdf": "https://arxiv.org/pdf/2506.18776", "abs": "https://arxiv.org/abs/2506.18776", "authors": ["Sara Checcoli", "Gabriel Andreas Dill"], "title": "New evidence for RÃ©mond's generalisation of Lehmer's conjecture", "comment": "33 pages. Comments are welcome!", "summary": "In this article, we generalise a result of Pottmeyer from the multiplicative\ngroup of the algebraic numbers to almost split semiabelian varieties defined\nover number fields. This concerns a consequence of R\\'emond's generalisation of\nLehmer's conjecture. Namely, for a finite rank subgroup $\\Gamma$ of an almost\nsplit semiabelian variety $G$, we consider the group of rational points of $G$\nover a finite extension of the field generated by the saturated closure of\n$\\Gamma$, i.e. the division closure of the subgroup generated by $\\Gamma$ and\nall its images under geometric endomorphisms of $G$. We show that this becomes\na free group after one quotients out the saturated closure of $\\Gamma$. The\nproof uses, amongst other ingredients, a criterion of Pottmeyer, which relies\non a result of Pontryagin, together with a result from Kummer theory, of which\nwe reproduce a proof by R\\'emond."}
{"id": "2506.17697", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17697", "abs": "https://arxiv.org/abs/2506.17697", "authors": ["Bohan Tang", "Dezhao Luo", "Jingxuan Chen", "Shaogang Gong", "Jianye Hao", "Jun Wang", "Kun Shao"], "title": "Beyond Syntax: Action Semantics Learning for App Agents", "comment": null, "summary": "The advent of Large Language Models (LLMs) enables the rise of App agents\nthat interpret user intent and operate smartphone Apps through actions such as\nclicking and scrolling. While prompt-based solutions with closed LLM APIs show\npromising ability, they incur heavy compute costs and external API dependency.\nFine-tuning smaller open-source LLMs solves these limitations. However, current\nfine-tuning methods use a syntax learning paradigm that forces agents to\nreproduce exactly the ground truth action strings, leading to\nout-of-distribution (OOD) vulnerability. To fill this gap, we propose Action\nSemantics Learning (ASL), a novel learning framework, where the learning\nobjective is capturing the semantics of the ground truth actions. Specifically,\ninspired by the programming language theory, we define the action semantics for\nApp agents as the state transition induced by the action in the user interface.\nWith this insight, ASL employs a novel SEmantic Estimator (SEE) to compute a\nsemantic reward to train the App agents in generating actions aligned with the\nsemantics of ground truth actions, even when the syntactic forms differ. To\nsupport the effectiveness of ASL, we theoretically demonstrate the superior\nrobustness of ASL for the OOD problem compared with the existing syntax\nlearning paradigm. Extensive experiments on offline and online smartphone App\noperation benchmarks show that ASL significantly improves the accuracy and\ngeneralisation of App agents over existing methods."}
{"id": "2506.17650", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17650", "abs": "https://arxiv.org/abs/2506.17650", "authors": ["Haihao Lu", "Wanyu Zhang"], "title": "Enhanced PDHG for Linear Programming with Online Preconditioning", "comment": null, "summary": "We present an online preconditioning technique for the primal-dual hybrid\ngradient (PDHG) algorithm for linear programming (LP). The method adaptively\nupdates primal and dual preconditioners using an online optimization framework.\nTo improve its practical performance, we introduce several algorithmic\nenhancements, including using normalized online loss functions and updating\npreconditioners infrequently. We implement the technique on top of vanilla PDHG\nand the GPU-based LP solver cuPDLP.jl, and benchmark its performance on\nstandard LP datasets. Our numerical experiments demonstrate that online\npreconditioning effectively reduces both iteration counts and overall solving\ntime."}
{"id": "2506.17318", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17318", "abs": "https://arxiv.org/abs/2506.17318", "authors": ["Atharv Singh Patlan", "Ashwin Hebbar", "Pramod Viswanath", "Prateek Mittal"], "title": "Context manipulation attacks : Web agents are susceptible to corrupted memory", "comment": "10 pages, 6 figures", "summary": "Autonomous web navigation agents, which translate natural language\ninstructions into sequences of browser actions, are increasingly deployed for\ncomplex tasks across e-commerce, information retrieval, and content discovery.\nDue to the stateless nature of large language models (LLMs), these agents rely\nheavily on external memory systems to maintain context across interactions.\nUnlike centralized systems where context is securely stored server-side, agent\nmemory is often managed client-side or by third-party applications, creating\nsignificant security vulnerabilities. This was recently exploited to attack\nproduction systems.\n  We introduce and formalize \"plan injection,\" a novel context manipulation\nattack that corrupts these agents' internal task representations by targeting\nthis vulnerable context. Through systematic evaluation of two popular web\nagents, Browser-use and Agent-E, we show that plan injections bypass robust\nprompt injection defenses, achieving up to 3x higher attack success rates than\ncomparable prompt-based attacks. Furthermore, \"context-chained injections,\"\nwhich craft logical bridges between legitimate user goals and attacker\nobjectives, lead to a 17.7% increase in success rate for privacy exfiltration\ntasks. Our findings highlight that secure memory handling must be a first-class\nconcern in agentic systems."}
{"id": "2506.18113", "categories": ["math.CO", "math.AG", "52C35, 52C10, 05D40"], "pdf": "https://arxiv.org/pdf/2506.18113", "abs": "https://arxiv.org/abs/2506.18113", "authors": ["Zichao Dong", "Zijian Xu"], "title": "Large grid subsets without many cospherical points", "comment": "9 pages", "summary": "Motivated by intuitions from projective algebraic geometry, we provide a\nnovel construction of subsets of the $d$-dimensional grid $[n]^d$ of size $n -\no(n)$ with no $d + 2$ points on a sphere or a hyperplane. For $d = 2$, this\nimproves the previously best known lower bound of $n/4$ toward the\nErd\\H{o}s--Purdy problem due to Thiele in 1995. For $d \\ge 3$, this improves\nthe recent $\\Omega \\bigl( n^{\\frac{3}{d+1}-o(1)} \\bigr)$ bound due to Suk and\nWhite, confirming their conjectured $\\Omega \\bigl( n^{\\frac{d}{d+1}} \\bigr)$\nbound in a strong sense, and asymptotically resolves the generalized\nErd\\H{o}s--Purdy problem posed by Brass, Moser, and Pach."}
{"id": "2506.18874", "categories": ["math.NT", "math.AG", "11G05 (Primary) 11G15, 11N45 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.18874", "abs": "https://arxiv.org/abs/2506.18874", "authors": ["Adrian Barquero-Sanchez", "Daniel Mora-Mora"], "title": "Counting elliptic curves over $\\mathbb{Q}$ with bounded naive height", "comment": "27 pages, 6 tables, 1 figure; code available on GitHub to reproduce\n  all computations", "summary": "In this paper, we give exact and asymptotic formulas for counting elliptic\ncurves $ E_{A,B} \\colon y^2 = x^3 + Ax + B $ with $ A, B \\in \\mathbb{Z} $,\nordered by naive height. We study the family of all such curves and also\nseveral natural subfamilies, including those with fixed $ j $-invariant and\nthose with complex multiplication (CM). In particular, we provide formulas for\ntwo commonly used normalizations of the naive height appearing in the\nliterature: the calibrated naive height, defined by \\[\nH^{\\mathrm{cal}}(E_{A,B}) := \\max\\{ 4|A|^3, 27B^2 \\}, \\] and the uncalibrated\nnaive height, defined by \\[ H^{\\mathrm{ncal}}(E_{A,B}) := \\max\\{ |A|^3, B^2 \\}.\n\\] In fact, we prove our theorems with respect to the more general naive height\n$H_{\\alpha, \\beta}(E_{A,B}) := \\max\\{ \\alpha |A|^3, \\beta B^2 \\}$, defined for\narbitrary positive real numbers $\\alpha, \\beta \\in \\mathbb{R}_{> 0}$.\n  As part of our approach, we give a completely explicit parametrization of the\nset of curves $ E_{A,B} $ with fixed $ j $-invariant and bounded naive height,\ndescribing them as twists of the curve $ E_{A_j, B_j} $ of minimal naive height\nfor the given $ j $-invariant. We also include tables comparing and verifying\nour theoretical predictions with exact counts obtained via exhaustive computer\nsearches, and we compute data for CM elliptic curves of naive height up to $\n10^{30} $. Code in SageMath is provided to compute all exact and asymptotic\nformulas appearing in the paper."}
{"id": "2506.17784", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17784", "abs": "https://arxiv.org/abs/2506.17784", "authors": ["Song Wang", "Zhen Tan", "Zihan Chen", "Shuang Zhou", "Tianlong Chen", "Jundong Li"], "title": "AnyMAC: Cascading Flexible Multi-Agent Collaboration via Next-Agent Prediction", "comment": null, "summary": "Recent progress in large language model (LLM)-based multi-agent collaboration\nhighlights the power of structured communication in enabling collective\nintelligence. However, existing methods largely rely on static or graph-based\ninter-agent topologies, lacking the potential adaptability and flexibility in\ncommunication. In this work, we propose a new framework that rethinks\nmulti-agent coordination through a sequential structure rather than a graph\nstructure, offering a significantly larger topology space for multi-agent\ncommunication. Our method focuses on two key directions: (1) Next-Agent\nPrediction, which selects the most suitable agent role at each step, and (2)\nNext-Context Selection (NCS), which enables each agent to selectively access\nrelevant information from any previous step. Together, these components\nconstruct task-adaptive communication pipelines that support both role\nflexibility and global information flow. Extensive evaluations across multiple\nbenchmarks demonstrate that our approach achieves superior performance while\nsubstantially reducing communication overhead."}
{"id": "2506.17666", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17666", "abs": "https://arxiv.org/abs/2506.17666", "authors": ["Harshit M. Ratandhara", "Mohit Kumar"], "title": "An Analytical Framework for the Linear Best-Worst Method and its Application to Achieve Sustainable Development Goals--Oriented Agri-Food Supply Chains", "comment": null, "summary": "The Best-Worst Method (BWM) has emerged as a prominent multi-criteria\ndecision-making method for determining the weights of the decision criteria.\nAmong various BWM models, this research focuses on the linear model of the BWM.\nThis model calculates weights by solving an optimization problem, necessitating\noptimization software. In this article, we present a novel framework that\nsolves this optimization model mathematically, yielding an analytical\nexpression for the resultant weights, thus eliminating the requirement for an\noptimization software. The proposed approach enhances both the conceptual\nclarity of the underlying optimization process and the computational efficiency\nof the model. Based of this framework, we demonstrate the model's limited\nresponse to data variations, i.e., its lower data sensitivity. We also compute\nthe values of consistency index for the linear BWM, which are required to\ncalculate the consistency ratio - a consistency indicator used for assessing\ninconsistency in input data. Finally, we illustrate the validity and\napplicability of the proposed approach through five numerical examples and a\nreal-world case study that ranks eighteen drivers across three categories -\nIndustry 4.0, sustainability, and circular economy - in relation to sustainable\ndevelopment goals-driven agri-food supply chains."}
{"id": "2506.17329", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17329", "abs": "https://arxiv.org/abs/2506.17329", "authors": ["Pedro H. Lui", "Lucas P. Siqueira", "Juliano F. Kazienko", "Vagner E. Quincozes", "Silvio E. Quincozes", "Daniel Welfer"], "title": "On the Performance of Cyber-Biomedical Features for Intrusion Detection in Healthcare 5.0", "comment": "12 pages, 7 figures, conference", "summary": "Healthcare 5.0 integrates Artificial Intelligence (AI), the Internet of\nThings (IoT), real-time monitoring, and human-centered design toward\npersonalized medicine and predictive diagnostics. However, the increasing\nreliance on interconnected medical technologies exposes them to cyber threats.\nMeanwhile, current AI-driven cybersecurity models often neglect biomedical\ndata, limiting their effectiveness and interpretability. This study addresses\nthis gap by applying eXplainable AI (XAI) to a Healthcare 5.0 dataset that\nintegrates network traffic and biomedical sensor data. Classification outputs\nindicate that XGBoost achieved 99% F1-score for benign and data alteration, and\n81% for spoofing. Explainability findings reveal that network data play a\ndominant role in intrusion detection whereas biomedical features contributed to\nspoofing detection, with temperature reaching a Shapley values magnitude of\n0.37."}
{"id": "2506.18235", "categories": ["math.CO", "05C55, 05D10"], "pdf": "https://arxiv.org/pdf/2506.18235", "abs": "https://arxiv.org/abs/2506.18235", "authors": ["Zhiyu Cheng", "Zhidan Luo", "Pingge Chen"], "title": "All Ramsey critical graphs for a large tree versus $tK_{m}$", "comment": null, "summary": "Let $H, H_{1}$ and $H_{2}$ be graphs, and let $H\\rightarrow (H_{1}, H_{2})$\ndenote that any red-blue coloring of $E(H)$ yields a red copy of $H_{1}$ or a\nblue copy of $H_{2}$. The Ramsey number for $H_{1}$ versus $H_{2}$, $r(H_{1},\nH_{2})$, is the minimum integer $N$ such that $K_{N}\\rightarrow (H_{1},\nH_{2})$. The Ramsey critical graph $H$ for $H_{1}$ versus $H_{2}$ is a red-blue\nedge-colored $K_{N- 1}$ such that $H\\not\\rightarrow (H_{1}, H_{2})$, where $N=\nr(H_{1}, H_{2})$. In this paper, we characterize all Ramsey critical graphs for\na large tree versus $tK_{m}$. As a corollary, we determine the star-critical\nRamsey number for a large tree versus $tK_{m}$."}
{"id": "2506.17401", "categories": ["math.CO", "math.GR", "math.NT"], "pdf": "https://arxiv.org/pdf/2506.17401", "abs": "https://arxiv.org/abs/2506.17401", "authors": ["NathanaÃ«l Hassler", "Andrew Treglown"], "title": "Notes on sum-free sets in abelian groups", "comment": "17 pages", "summary": "In this paper we highlight a few open problems concerning maximal sum-free\nsets in abelian groups. In addition, for most even order abelian groups $G$ we\nasymptotically determine the number of maximal distinct sum-free subsets in\n$G$. Our proof makes use of the container method."}
{"id": "2506.17788", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "I.2.1; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.17788", "abs": "https://arxiv.org/abs/2506.17788", "authors": ["Shahab Rahimirad", "Guven Gergerli", "Lucia Romero", "Angela Qian", "Matthew Lyle Olson", "Simon Stepputtis", "Joseph Campbell"], "title": "Bayesian Social Deduction with Graph-Informed Language Models", "comment": "32 pages, 10 figures. Under review", "summary": "Social reasoning - inferring unobservable beliefs and intentions from partial\nobservations of other agents - remains a challenging task for large language\nmodels (LLMs). We evaluate the limits of current reasoning language models in\nthe social deduction game Avalon and find that while the largest models\ndemonstrate strong performance, they require extensive test-time inference and\ndegrade sharply when distilled to smaller, real-time-capable variants. To\naddress this, we introduce a hybrid reasoning framework that externalizes\nbelief inference to a structured probabilistic model, while using an LLM for\nlanguage understanding and interaction. Our approach achieves competitive\nperformance with much larger models in Agent-Agent play and, notably, is the\nfirst language agent to defeat human players in a controlled study - achieving\na 67% win rate and receiving higher qualitative ratings than both reasoning\nbaselines and human teammates. We release code, models, and a dataset to\nsupport future work on social reasoning in LLM agents, which can be found at\nhttps://camp-lab-purdue.github.io/bayesian-social-deduction/"}
{"id": "2506.17696", "categories": ["math.OC", "cs.NA", "math.NA", "stat.ML", "I.6.1; G.1.2; G.1.6"], "pdf": "https://arxiv.org/pdf/2506.17696", "abs": "https://arxiv.org/abs/2506.17696", "authors": ["Du-Yi Wang", "Guo Liang", "Guangwu Liu", "Kun Zhang"], "title": "Regular Tree Search for Simulation Optimization", "comment": null, "summary": "Tackling simulation optimization problems with non-convex objective functions\nremains a fundamental challenge in operations research. In this paper, we\npropose a class of random search algorithms, called Regular Tree Search, which\nintegrates adaptive sampling with recursive partitioning of the search space.\nThe algorithm concentrates simulations on increasingly promising regions by\niteratively refining a tree structure. A tree search strategy guides sampling\ndecisions, while partitioning is triggered when the number of samples in a leaf\nnode exceeds a threshold that depends on its depth. Furthermore, a specific\ntree search strategy, Upper Confidence Bounds applied to Trees (UCT), is\nemployed in the Regular Tree Search. We prove global convergence under\nsub-Gaussian noise, based on assumptions involving the optimality gap, without\nrequiring continuity of the objective function. Numerical experiments confirm\nthat the algorithm reliably identifies the global optimum and provides accurate\nestimates of its objective value."}
{"id": "2506.17336", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17336", "abs": "https://arxiv.org/abs/2506.17336", "authors": ["Yubeen Bae", "Minchan Kim", "Jaejin Lee", "Sangbum Kim", "Jaehyung Kim", "Yejin Choi", "Niloofar Mireshghallah"], "title": "Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases", "comment": "29 pages", "summary": "Large language models (LLMs) are increasingly used as personal agents,\naccessing sensitive user data such as calendars, emails, and medical records.\nUsers currently face a trade-off: They can send private records, many of which\nare stored in remote databases, to powerful but untrusted LLM providers,\nincreasing their exposure risk. Alternatively, they can run less powerful\nmodels locally on trusted devices. We bridge this gap. Our Socratic\nChain-of-Thought Reasoning first sends a generic, non-private user query to a\npowerful, untrusted LLM, which generates a Chain-of-Thought (CoT) prompt and\ndetailed sub-queries without accessing user data. Next, we embed these\nsub-queries and perform encrypted sub-second semantic search using our\nHomomorphically Encrypted Vector Database across one million entries of a\nsingle user's private data. This represents a realistic scale of personal\ndocuments, emails, and records accumulated over years of digital activity.\nFinally, we feed the CoT prompt and the decrypted records to a local language\nmodel and generate the final response. On the LoCoMo long-context QA benchmark,\nour hybrid framework, combining GPT-4o with a local Llama-3.2-1B model,\noutperforms using GPT-4o alone by up to 7.1 percentage points. This\ndemonstrates a first step toward systems where tasks are decomposed and split\nbetween untrusted strong LLMs and weak local ones, preserving user privacy."}
{"id": "2506.18345", "categories": ["math.CO", "math.PR", "05C35, 05C76"], "pdf": "https://arxiv.org/pdf/2506.18345", "abs": "https://arxiv.org/abs/2506.18345", "authors": ["BoÅ¡tjan BreÅ¡ar", "Jaka HedÅ¾et", "Michael A. Henning"], "title": "On polluted bootstrap percolation in Cartesian grids", "comment": "11 pages, 3 figures", "summary": "Given a graph $G$ and assuming that some vertices of $G$ are infected, the\n$r$-neighbor bootstrap percolation rule makes an uninfected vertex $v$ infected\nif $v$ has at least $r$ infected neighbors. The $r$-percolation number, $m(G,\nr)$, of $G$ is the minimum cardinality of a set of initially infected vertices\nin $G$ such that after continuously performing the $r$-neighbor bootstrap\npercolation rule each vertex of $G$ eventually becomes infected. In this paper,\nwe continue the study of polluted bootstrap percolation introduced and studied\nby Gravner and McDonald [Bootstrap percolation in a polluted environment. J.\\\nStat\\ Physics 87 (1997) 915--927] where in this variant some vertices are\npermanently in the non-infected state. We study an extremal (combinatorial)\nversion of the bootstrap percolation problem in a polluted environment, where\nour main focus is on the class of grid graphs, that is, the Cartesian product\n$P_m \\square P_n$ of two paths $P_m$ and $P_n$ on $m$ and $n$ vertices,\nrespectively. Given a number of polluted vertices in a Cartesian grid we\nestablish a closed formula for the minimum $2$-neighbor bootstrap percolation\nnumber of the polluted grid, and obtain a lower bound for the other extreme."}
{"id": "2506.17792", "categories": ["cs.AI", "cs.LO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.17792", "abs": "https://arxiv.org/abs/2506.17792", "authors": ["Alexandros Evangelidis", "Gricel VÃ¡zquez", "Simos Gerasimou"], "title": "Efficient Strategy Synthesis for MDPs via Hierarchical Block Decomposition", "comment": null, "summary": "Software-intensive systems, such as software product lines and robotics,\nutilise Markov decision processes (MDPs) to capture uncertainty and analyse\nsequential decision-making problems. Despite the usefulness of conventional\npolicy synthesis methods, they fail to scale to large state spaces. Our\napproach addresses this issue and accelerates policy synthesis in large MDPs by\ndynamically refining the MDP and iteratively selecting the most fragile MDP\nregions for refinement. This iterative procedure offers a balance between\naccuracy and efficiency, as refinement occurs only when necessary. Through a\ncomprehensive empirical evaluation comprising diverse case studies and MDPs up\nto 1M states, we demonstrate significant performance improvements yielded by\nour approach compared to the leading probabilistic model checker PRISM (up to\n2x), thus offering a very competitive solution for real-world policy synthesis\ntasks in larger MDPs."}
{"id": "2506.17698", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17698", "abs": "https://arxiv.org/abs/2506.17698", "authors": ["Jelena Diakonikolas"], "title": "Pushing the Complexity Boundaries of Fixed-Point Equations: Adaptation to Contraction and Controlled Expansion", "comment": null, "summary": "Fixed-point equations with Lipschitz operators have been studied for more\nthan a century, and are central to problems in mathematical optimization, game\ntheory, economics, and dynamical systems, among others. When the Lipschitz\nconstant of the operator is larger than one (i.e., when the operator is\nexpansive), it is well known that approximating fixed-point equations becomes\ncomputationally intractable even in basic finite-dimensional settings. In this\nwork, we aim to push these complexity boundaries by introducing algorithms that\ncan address problems with mildly expansive (i.e., with Lipschitz constant\nslightly larger than one) operators not excluded by existing lower bounds,\nattaining the best possible fixed-point error up to universal constants. We\nfurther introduce a class of \\emph{gradually expansive operators} that allow\nfor constant (up to $\\approx 1.4$) expansion between points, for which we prove\nconvergence to $\\epsilon$-approximate fixed points in order-$(1/\\epsilon)$\niterations for $\\epsilon > 0.$ Our algorithms automatically adapt to the\nLipschitz constant of the operator and attain optimal oracle complexity bounds\nwhen the input operator is nonexpansive or contractive. Our results apply to\ngeneral, possibly infinite-dimensional normed vector spaces and can be extended\nto positively curved geodesic metric spaces."}
{"id": "2506.17349", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17349", "abs": "https://arxiv.org/abs/2506.17349", "authors": ["Akarsh K Nair", "Shanik Hubert Satheesh Kumar.", "Deepti Gupta"], "title": "AndroIDS : Android-based Intrusion Detection System using Federated Learning", "comment": null, "summary": "The exponential growth of android-based mobile IoT systems has significantly\nincreased the susceptibility of devices to cyberattacks, particularly in smart\nhomes, UAVs, and other connected mobile environments. This article presents a\nfederated learning-based intrusion detection framework called AndroIDS that\nleverages system call traces as a personalized and privacy-preserving data\nsource. Unlike conventional centralized approaches, the proposed method enables\ncollaborative anomaly detection without sharing raw data, thus preserving user\nprivacy across distributed nodes. A generalized system call dataset was\ngenerated to reflect realistic android system behavior and serves as the\nfoundation for experimentation. Extensive evaluation demonstrates the\neffectiveness of the FL model under both IID and non-IID conditions, achieving\nan accuracy of 96.46 % and 92.87 %, and F1-scores of 89 % and 86 %,\nrespectively. These results highlight the models robustness to data\nheterogeneity, with only a minor performance drop in the non-IID case. Further,\na detailed comparison with centralized deep learning further illustrates\ntrade-offs in detection performance and deployment feasibility. Overall, the\nresults validate the practical applicability of the proposed approach for\nsecure and scalable intrusion detection in real-world mobile IoT scenarios."}
{"id": "2506.18700", "categories": ["math.CO", "05E30, 05E18"], "pdf": "https://arxiv.org/pdf/2506.18700", "abs": "https://arxiv.org/abs/2506.18700", "authors": ["Ian Seong"], "title": "Counting edges of different types in a local graph of a Grassmann graph", "comment": "22 pages, 3 figures", "summary": "Let $\\mathbb{F}_q$ denote a finite field with $q$ elements. Let $n,k$ denote\nintegers with $n>2k\\geq 6$. Let $V$ denote a vector space over $\\mathbb{F}_{q}$\nthat has dimension $n$. The vertex set of the Grassmann graph $J_q(n,k)$\nconsists of the $k$-dimensional subspaces of $V$. Two vertices of $J_q(n,k)$\nare adjacent whenever their intersection has dimension $k-1$. Let $\\partial$\ndenote the path-length distance function of $J_q(n,k)$. Pick vertices $x,y$ of\n$J_q(n,k)$ such that $1<\\partial(x,y)<k$. Let $\\Gamma(x)$ denote the local\ngraph of $x$ in $J_q(n,k)$. In this paper we define three types of edges in\n$\\Gamma(x)$, namely type $0$, type $+$, and type $-$; for adjacent $w,z\\in\n\\Gamma(x)$ such that $\\partial(w,y)=\\partial(z,y)$, the type of the edge $wz$\ndepends on the subspaces $w+z,w,z,w\\cap z$ and their intersections with $y$.\nOur general goal is to count the number of edges in $\\Gamma(x)$ for each type.\nConsider a two-vertex stabilizer $\\text{Stab}(x,y)$ in $GL(V)$; it is known\nthat the $\\text{Stab}(x,y)$-action on $\\Gamma(x)$ has five orbits. Pick two\norbits $\\mathcal{O},\\mathcal{N}$ that are not necessarily distinct; for a given\n$w\\in \\mathcal{O}$, we find the number of vertices in $z\\in \\mathcal{N}$ such\nthat the edge $wz$ has (i) type $0$, (ii) type $+$, (iii) type $-$. To find\nthese numbers, we make heavy use of a subalgebra $\\mathcal{H}$ of\n$\\text{Mat}_{P}(\\mathbb{C})$; the algebra $\\mathcal{H}$ contains matrices that\nare closely related to the five orbits of the $\\text{Stab}(x,y)$-action on\n$\\Gamma(x)$."}
{"id": "2506.17834", "categories": ["cs.AI", "cs.HC", "I.2.6; H.5.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.17834", "abs": "https://arxiv.org/abs/2506.17834", "authors": ["Carter Blair", "Kate Larson", "Edith Law"], "title": "Reflective Verbal Reward Design for Pluralistic Alignment", "comment": "9 pages, 3 figures, accepted to the IJCAI 2025 Human-Centred AI\n  track. Project repository at: https://osf.io/8yxf2/", "summary": "AI agents are commonly aligned with \"human values\" through reinforcement\nlearning from human feedback (RLHF), where a single reward model is learned\nfrom aggregated human feedback and used to align an agent's behavior. However,\nhuman values are not homogeneous--different people hold distinct and sometimes\nconflicting values. Aggregating feedback into a single reward model risks\ndisproportionately suppressing minority preferences. To address this, we\npresent a novel reward modeling approach for learning individualized reward\nmodels. Our approach uses a language model to guide users through reflective\ndialogues where they critique agent behavior and construct their preferences.\nThis personalized dialogue history, containing the user's reflections and\ncritiqued examples, is then used as context for another language model that\nserves as an individualized reward function (what we call a \"verbal reward\nmodel\") for evaluating new trajectories. In studies with 30 participants, our\nmethod achieved a 9-12% improvement in accuracy over non-reflective verbal\nreward models while being more sample efficient than traditional supervised\nlearning methods."}
{"id": "2506.17814", "categories": ["math.OC", "49J40, 65K10, 65K15, 90C25, 90C33"], "pdf": "https://arxiv.org/pdf/2506.17814", "abs": "https://arxiv.org/abs/2506.17814", "authors": ["Roger Behling", "Yunier Bello-Cruz", "Alfredo Iusem", "Di Liu", "Luiz-Rafael Santos"], "title": "On circumcentered direct methods for monotone variational inequality problems", "comment": null, "summary": "The variational inequality problem (VIP) plays a central role in the theory\nand applications in continuous optimization. In particular, minimization\nproblems and KKT systems can be regard as VIPs. In this work, we present the\nfirst methods using circumcenter iterations for solving VIPs. The\ncircumcentered-reflection method (CRM) is a tool based on projections developed\nwith the aim of finding a point in the intersection of finitely many closed\nconvex sets. CRM has gone through enhancements and adaptations over the last\nfew years and was proven to be faster in many settings than competitors such as\nalternating projections and the Douglas-Rachford method. One of the nice\nfeatures of CRM is that it is able to deal with approximate projections, which\nis exactly what we enforced in this article theoretically and numerically. We\npresent both a circumcenter method for the VIP with paramonotone operator and\nmonotone operator, the first employing exact projections and the second\napproximate ones. Convergence results showing their convergence are\nestablished. Numerically, our experiments indicate good performance, including\nadvantages over the well-know extragradient method."}
{"id": "2506.17350", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17350", "abs": "https://arxiv.org/abs/2506.17350", "authors": ["Yinghao Wu", "Liyan Zhang"], "title": "CUBA: Controlled Untargeted Backdoor Attack against Deep Neural Networks", "comment": null, "summary": "Backdoor attacks have emerged as a critical security threat against deep\nneural networks in recent years. The majority of existing backdoor attacks\nfocus on targeted backdoor attacks, where trigger is strongly associated to\nspecific malicious behavior. Various backdoor detection methods depend on this\ninherent property and shows effective results in identifying and mitigating\nsuch targeted attacks. However, a purely untargeted attack in backdoor\nscenarios is, in some sense, self-weakening, since the target nature is what\nmakes backdoor attacks so powerful. In light of this, we introduce a novel\nConstrained Untargeted Backdoor Attack (CUBA), which combines the flexibility\nof untargeted attacks with the intentionality of targeted attacks. The\ncompromised model, when presented with backdoor images, will classify them into\nrandom classes within a constrained range of target classes selected by the\nattacker. This combination of randomness and determinedness enables the\nproposed untargeted backdoor attack to natively circumvent existing backdoor\ndefense methods. To implement the untargeted backdoor attack under controlled\nflexibility, we propose to apply logit normalization on cross-entropy loss with\nflipped one-hot labels. By constraining the logit during training, the\ncompromised model will show a uniform distribution across selected target\nclasses, resulting in controlled untargeted attack. Extensive experiments\ndemonstrate the effectiveness of the proposed CUBA on different datasets."}
{"id": "2506.18782", "categories": ["math.CO", "05C30"], "pdf": "https://arxiv.org/pdf/2506.18782", "abs": "https://arxiv.org/abs/2506.18782", "authors": ["Padmini Mukkamala"], "title": "Triangle-free subsets of the Hypercube", "comment": "7 pages", "summary": "We study the problem of determining the largest subset of vertices of the $n$\ndimensional hypercube without three vertices at a Hamming distance of exactly\n$r$ from each other. In particular, we provide a lower bound of\n$\\frac{c2^n}{e^r2^{\\frac r2} (\\frac nr)^{\\frac{3r}{4}}}$ and an upper bound of\n$O(\\frac{r2^n}{n+1})$ when $2r \\le n$. In particular, when $r$ is a constant,\nthe lower bound is $\\frac{c2^n}{n^{3r/4}}$, while the upper bound is\n$\\frac{c'2^n}{n}$."}
{"id": "2506.17846", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17846", "abs": "https://arxiv.org/abs/2506.17846", "authors": ["Elija Perrier"], "title": "Out of Control -- Why Alignment Needs Formal Control Theory (and an Alignment Control Stack)", "comment": "Under review for Neurips 2025", "summary": "This position paper argues that formal optimal control theory should be\ncentral to AI alignment research, offering a distinct perspective from\nprevailing AI safety and security approaches. While recent work in AI safety\nand mechanistic interpretability has advanced formal methods for alignment,\nthey often fall short of the generalisation required of control frameworks for\nother technologies. There is also a lack of research into how to render\ndifferent alignment/control protocols interoperable. We argue that by recasting\nalignment through principles of formal optimal control and framing alignment in\nterms of hierarchical stack from physical to socio-technical layers according\nto which controls may be applied we can develop a better understanding of the\npotential and limitations for controlling frontier models and agentic AI\nsystems. To this end, we introduce an Alignment Control Stack which sets out a\nhierarchical layered alignment stack, identifying measurement and control\ncharacteristics at each layer and how different layers are formally\ninteroperable. We argue that such analysis is also key to the assurances that\nwill be needed by governments and regulators in order to see AI technologies\nsustainably benefit the community. Our position is that doing so will bridge\nthe well-established and empirically validated methods of optimal control with\npractical deployment considerations to create a more comprehensive alignment\nframework, enhancing how we approach safety and reliability for advanced AI\nsystems."}
{"id": "2506.17884", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17884", "abs": "https://arxiv.org/abs/2506.17884", "authors": ["Lingzi Jin", "Xiao Wang", "Xiaojun Chen"], "title": "Nonconvex Nonsmooth Multicomposite Optimization and Its Applications to Recurrent Neural Networks", "comment": null, "summary": "We consider a class of nonconvex nonsmooth multicomposite optimization\nproblems where the objective function consists of a Tikhonov regularizer and a\ncomposition of multiple nonconvex nonsmooth component functions. Such\noptimization problems arise from tangible applications in machine learning and\nbeyond. To define and compute its first-order and second-order\nd(irectional)-stationary points effectively, we first derive the closed-form\nexpression of the tangent cone for the feasible region of its constrained\nreformulation. Building on this, we establish its equivalence with the\ncorresponding constrained and $\\ell_1$-penalty reformulations in terms of\nglobal optimality and d-stationarity. The equivalence offers indirect methods\nto attain the first-order and second-order d-stationary points of the original\nproblem in certain cases. We apply our results to the training process of\nrecurrent neural networks (RNNs)."}
{"id": "2506.17353", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17353", "abs": "https://arxiv.org/abs/2506.17353", "authors": ["Zongjie Li", "Daoyuan Wu", "Shuai Wang", "Zhendong Su"], "title": "Differentiation-Based Extraction of Proprietary Data from Fine-Tuned LLMs", "comment": "In Proceedings of the 2025 ACM SIGSAC Conference on Computer and\n  Communications Security (CCS'25), October 13-17, 2025, Taipei, Taiwan, China.\n  ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/3719027.3744856", "summary": "The increasing demand for domain-specific and human-aligned Large Language\nModels (LLMs) has led to the widespread adoption of Supervised Fine-Tuning\n(SFT) techniques. SFT datasets often comprise valuable instruction-response\npairs, making them highly valuable targets for potential extraction. This paper\nstudies this critical research problem for the first time. We start by formally\ndefining and formulating the problem, then explore various attack goals, types,\nand variants based on the unique properties of SFT data in real-world\nscenarios. Based on our analysis of extraction behaviors of direct extraction,\nwe develop a novel extraction method specifically designed for SFT models,\ncalled Differentiated Data Extraction (DDE), which exploits the confidence\nlevels of fine-tuned models and their behavioral differences from pre-trained\nbase models. Through extensive experiments across multiple domains and\nscenarios, we demonstrate the feasibility of SFT data extraction using DDE. Our\nresults show that DDE consistently outperforms existing extraction baselines in\nall attack settings. To counter this new attack, we propose a defense mechanism\nthat mitigates DDE attacks with minimal impact on model performance. Overall,\nour research reveals hidden data leak risks in fine-tuned LLMs and provides\ninsights for developing more secure models."}
{"id": "2506.18788", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.18788", "abs": "https://arxiv.org/abs/2506.18788", "authors": ["Erik Panzer"], "title": "Graph theoretic properties of Speyer's matroid polynomial $g_M(t)$", "comment": "56 pages, 8 tables, 17 figures, associated with open-source code and\n  a data set", "summary": "We prove relations between the number of $k$-connected components of a graph,\nCrapo's invariant $\\beta(M)$ of a matroid, and Speyer's polynomial $g_M(t)$.\nThese yield a simple interpretation of $g_M'(-1)$ when $M$ is graphic or\ncographic. Furthermore, we improve Ferroni's algorithm to compute $g_M(t)$ and\nprovide an implementation and an extensive data set. These calculations reveal\na large number of graph theoretic constraints on the second derivative\n$g_M''(-1)$, which we thus advertise as an intriguing new invariant of graphs.\nWe also propose a relation between the flow polynomial and $g_M''(0)$ for cubic\ngraphs."}
{"id": "2506.17878", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17878", "abs": "https://arxiv.org/abs/2506.17878", "authors": ["Tam Trinh", "Manh Nguyen", "Truong-Son Hy"], "title": "Towards Robust Fact-Checking: A Multi-Agent System with Advanced Evidence Retrieval", "comment": null, "summary": "The rapid spread of misinformation in the digital era poses significant\nchallenges to public discourse, necessitating robust and scalable fact-checking\nsolutions. Traditional human-led fact-checking methods, while credible,\nstruggle with the volume and velocity of online content, prompting the\nintegration of automated systems powered by Large Language Models (LLMs).\nHowever, existing automated approaches often face limitations, such as handling\ncomplex claims, ensuring source credibility, and maintaining transparency. This\npaper proposes a novel multi-agent system for automated fact-checking that\nenhances accuracy, efficiency, and explainability. The system comprises four\nspecialized agents: an Input Ingestion Agent for claim decomposition, a Query\nGeneration Agent for formulating targeted subqueries, an Evidence Retrieval\nAgent for sourcing credible evidence, and a Verdict Prediction Agent for\nsynthesizing veracity judgments with human-interpretable explanations.\nEvaluated on benchmark datasets (FEVEROUS, HOVER, SciFact), the proposed system\nachieves a 12.3% improvement in Macro F1-score over baseline methods. The\nsystem effectively decomposes complex claims, retrieves reliable evidence from\ntrusted sources, and generates transparent explanations for verification\ndecisions. Our approach contributes to the growing field of automated\nfact-checking by providing a more accurate, efficient, and transparent\nverification methodology that aligns with human fact-checking practices while\nmaintaining scalability for real-world applications. Our source code is\navailable at https://github.com/HySonLab/FactAgent"}
{"id": "2506.17924", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.17924", "abs": "https://arxiv.org/abs/2506.17924", "authors": ["Shenglu Wang", "Kairui Feng", "Mengqi Xue", "Yue Song"], "title": "Inverse Chance Constrained Optimal Power Flow", "comment": "3 pages, 1 figure", "summary": "The chance constrained optimal power flow (CC-OPF) essentially finds the\nlow-cost generation dispatch scheme ensuring operational constraints are met\nwith a specified probability, termed the security level. While the security\nlevel is a crucial input parameter, how it shapes the CC-OPF feasibility\nboundary has not been revealed. Changing the security level from a parameter to\na decision variable, this letter proposes the inverse CC-OPF that seeks the\nhighest feasible security level supported by the system. To efficiently solve\nthis problem, we design a Newton-Raphson-like iteration algorithm leveraging\nthe duality-based sensitivity analysis of an associated surrogate problem.\nNumerical experiments validate the proposed approach, revealing complex\nfeasibility boundaries for security levels that underscore the importance of\ncoordinating security levels across multiple chance constraints."}
{"id": "2506.17371", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2506.17371", "abs": "https://arxiv.org/abs/2506.17371", "authors": ["Thilina Pathirana", "Ruxandra F. Olimid"], "title": "Secret Sharing in 5G-MEC: Applicability for joint Security and Dependability", "comment": "10 pages, 5 figures, Accepted to the proceedings of 22nd\n  International Conference on Privacy, Security, and Trust (PST2025)", "summary": "Multi-access Edge Computing (MEC), an enhancement of 5G, processes data\ncloser to its generation point, reducing latency and network load. However, the\ndistributed and edge-based nature of 5G-MEC presents privacy and security\nchallenges, including data exposure risks. Ensuring efficient manipulation and\nsecurity of sensitive data at the edge is crucial. To address these challenges,\nwe investigate the usage of threshold secret sharing in 5G-MEC storage, an\napproach that enhances both security and dependability. A (k,n) threshold\nsecret sharing scheme splits and stores sensitive data among n nodes, requiring\nat least k nodes for reconstruction. The solution ensures confidentiality by\nprotecting data against fewer than k colluding nodes and enhances availability\nby tolerating up to n-k failing nodes. This approach mitigates threats such as\nunauthorized access and node failures, whether accidental or intentional. We\nfurther discuss a method for selecting the convenient MEHs to store the shares,\nconsidering the MEHs' trustworthiness level as a main criterion. Although we\ndefine our proposal in the context of secret-shared data storage, it can be\nseen as an independent, standalone selection process for 5G-MEC trustworthy\nnode selection in other scenarios too."}
{"id": "2506.17527", "categories": ["math.ST", "math.CO", "math.PR", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.17527", "abs": "https://arxiv.org/abs/2506.17527", "authors": ["Shuyang Gong", "Zhangsong Li", "Qiheng Xu"], "title": "Detection and Reconstruction of a Random Hypergraph from Noisy Graph Projection", "comment": "18 pages, 1 figure", "summary": "For a $d$-uniform random hypergraph on $n$ vertices in which hyperedges are\nincluded i.i.d.\\ so that the average degree in the hypergraph is\n$n^{\\delta+o(1)}$, the projection of such a hypergraph is a graph on the same\n$n$ vertices where an edge connects two vertices if and only if they belong to\na same hyperedge. In this work, we study the inference problem where the\nobservation is a \\emph{noisy} version of the graph projection where each edge\nin the projection is kept with probability $p=n^{-1+\\alpha+o(1)}$ and each edge\nnot in the projection is added with probability $q=n^{-1+\\beta+o(1)}$. For all\nconstant $d$, we establish sharp thresholds for both detection (distinguishing\nthe noisy projection from an Erd\\H{o}s-R\\'enyi random graph with edge density\n$q$) and reconstruction (estimating the original hypergraph). Notably, our\nresults reveal a \\emph{detection-reconstruction gap} phenomenon in this\nproblem. Our work also answers a problem raised in \\cite{BGPY25+}."}
{"id": "2506.17900", "categories": ["cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2506.17900", "abs": "https://arxiv.org/abs/2506.17900", "authors": ["Cheng Ji", "Huaiying Luo"], "title": "Leveraging Large Language Model for Intelligent Log Processing and Autonomous Debugging in Cloud AI Platforms", "comment": "Accepted by 2025 8th International Conference on Advanced Electronic\n  Materials, Computers and Software Engineering (AEMCSE 2025)", "summary": "With the increasing complexity and rapid expansion of the scale of AI systems\nin cloud platforms, the log data generated during system operation is massive,\nunstructured, and semantically ambiguous, which brings great challenges to\nfault location and system self-repair. In order to solve this problem, this\npaper proposes an intelligent log processing and automatic debugging framework\nbased on Large Language Model (LLM), named Intelligent Debugger (LLM-ID). This\nmethod is extended on the basis of the existing pre-trained Transformer model,\nand integrates a multi-stage semantic inference mechanism to realize the\ncontext understanding of system logs and the automatic reconstruction of fault\nchains. Firstly, the system log is dynamically structured, and the unsupervised\nclustering and embedding mechanism is used to extract the event template and\nsemantic schema. Subsequently, the fine-tuned LLM combined with the multi-round\nattention mechanism to perform contextual reasoning on the log sequence to\ngenerate potential fault assumptions and root cause paths. Furthermore, this\npaper introduces a reinforcement learning-based policy-guided recovery planner,\nwhich is driven by the remediation strategy generated by LLM to support dynamic\ndecision-making and adaptive debugging in the cloud environment. Compared with\nthe existing rule engine or traditional log analysis system, the proposed model\nhas stronger semantic understanding ability, continuous learning ability and\nheterogeneous environment adaptability. Experiments on the cloud platform log\ndataset show that LLM-ID improves the fault location accuracy by 16.2%, which\nis significantly better than the current mainstream methods"}
{"id": "2506.18004", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.18004", "abs": "https://arxiv.org/abs/2506.18004", "authors": ["Roberto Boffadossi", "Marco Leonesio", "Lorenzo Fagiano"], "title": "ROBBO: An Efficient Method for Pareto Front Estimation with Guaranteed Accuracy", "comment": "35 pages, 10 figures, under review", "summary": "A new method to estimate the Pareto Front (PF) in bi-objective optimization\nproblems is presented. Assuming a continuous PF, the approach, named ROBBO\n(RObust and Balanced Bi-objective Optimization), needs to sample at most a\nfinite, pre-computed number of PF points. Upon termination, it guarantees that\nthe worst-case approximation error lies within a desired tolerance range,\npredefined by the decision maker, for each of the two objective functions.\nTheoretical results are derived, about the worst-case number of PF samples\nrequired to guarantee the wanted accuracy, both in general and for specific\nsampling methods from the literature. A comparative analysis, both theoretical\nand numerical, demonstrates the superiority of the proposed method with respect\nto popular ones. The approach is finally showcased in a constrained\npath-following problem for a 2-axis positioning system and in a steady-state\noptimization problem for a Continuous-flow Stirred Tank Reactor. An open demo\nimplementation of ROBBO is made available online."}
{"id": "2506.17446", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.17446", "abs": "https://arxiv.org/abs/2506.17446", "authors": ["Nesrine Benchoubane", "Eray Guven", "Gunes Karabulut Kurt"], "title": "Open Sky, Open Threats: Replay Attacks in Space Launch and Re-entry Phases", "comment": null, "summary": "This paper examines the effects of replay attacks on the integrity of both\nuplink and downlink communications during critical phases of spacecraft\ncommunication. By combining software-defined radios (SDRs) with a real-time\nchannel emulator, we replicate realistic attack conditions on the Orion\nspacecraft's communication systems in both launch and reentry. Our evaluation\nshows that, under replay attacks, the attacker's signal can overpower\nlegitimate transmissions, leading to a Signal to Noise Ratio (SNR) difference\nof up to -7.8 dB during reentry and -6.5 dB during launch. To mitigate these\nthreats, we propose a more secure receiver design incorporating a\nphase-coherency-dependent decision-directed (DD) equalizer with a narrowed\nphase-locked loop (PLL) bandwidth. This configuration enhances resilience by\nmaking synchronization more sensitive to phase distortions caused by replay\ninterference."}
{"id": "2506.18287", "categories": ["math.NT", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.18287", "abs": "https://arxiv.org/abs/2506.18287", "authors": ["Chen Wang", "Sheng-Jie Wang"], "title": "On a conjectural supercongruence involving the dual sequence $s_n(x)$", "comment": "16 pages", "summary": "In 2017, motivated by a supercongruence conjectured by Kimoto and Wakayama\nand confirmed by Long, Osburn and Swisher, Z.-W. Sun introduced the sequence of\npolynomials: $$\ns_n(x)=\\sum_{k=0}^n\\binom{n}{k}\\binom{x}{k}\\binom{x+k}{k}=\\sum_{k=0}^n\\binom{n}{k}(-1)^k\\binom{x}{k}\\binom{-1-x}{k}\n$$ and investigated its congruence properties. In particular, Z.-W. Sun\nconjectured that for any prime $p>3$ and $p$-adic integer $x\\neq-1/2$ one has\n\\begin{equation*} \\sum_{n=0}^{p-1}s_n(x)^2\\equiv (-1)^{\\langle\nx\\rangle_p}\\frac{p+2(x-\\langle x\\rangle_p)}{2x+1}\\pmod{p^3}, \\end{equation*}\nwhere $\\langle x\\rangle_p$ denotes the least nonnegative residue of $x$ modulo\n$p$. In this paper, we confirm this conjecture."}
{"id": "2506.17913", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17913", "abs": "https://arxiv.org/abs/2506.17913", "authors": ["Jinjie Wei", "Jiyao Liu", "Lihao Liu", "Ming Hu", "Junzhi Ning", "Mingcheng Li", "Weijie Yin", "Junjun He", "Xiao Liang", "Chao Feng", "Dingkang Yang"], "title": "Learning, Reasoning, Refinement: A Framework for Kahneman's Dual-System Intelligence in GUI Agents", "comment": null, "summary": "Graphical User Interface (GUI) agents have made significant progress in\nautomating digital tasks through the utilization of computer vision and\nlanguage models. Nevertheless, existing agent systems encounter notable\nlimitations. Firstly, they predominantly depend on trial and error decision\nmaking rather than progressive reasoning, thereby lacking the capability to\nlearn and adapt from interactive encounters. Secondly, these systems are\nassessed using overly simplistic single step accuracy metrics, which do not\nadequately reflect the intricate nature of real world GUI interactions. In this\npaper, we present CogniGUI, a cognitive framework developed to overcome these\nlimitations by enabling adaptive learning for GUI automation resembling\nhuman-like behavior. Inspired by Kahneman's Dual Process Theory, our approach\ncombines two main components: (1) an omni parser engine that conducts immediate\nhierarchical parsing of GUI elements through quick visual semantic analysis to\nidentify actionable components, and (2) a Group based Relative Policy\nOptimization (GRPO) grounding agent that assesses multiple interaction paths\nusing a unique relative reward system, promoting minimal and efficient\noperational routes. This dual-system design facilitates iterative ''exploration\nlearning mastery'' cycles, enabling the agent to enhance its strategies over\ntime based on accumulated experience. Moreover, to assess the generalization\nand adaptability of agent systems, we introduce ScreenSeek, a comprehensive\nbenchmark that includes multi application navigation, dynamic state\ntransitions, and cross interface coherence, which are often overlooked\nchallenges in current benchmarks. Experimental results demonstrate that\nCogniGUI surpasses state-of-the-art methods in both the current GUI grounding\nbenchmarks and our newly proposed benchmark."}
{"id": "2506.18075", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.18075", "abs": "https://arxiv.org/abs/2506.18075", "authors": ["Liyuan Liang", "Gan Luo", "Kun Yuan"], "title": "On the Linear Speedup of the Push-Pull Method for Decentralized Optimization over Digraphs", "comment": null, "summary": "The linear speedup property is essential for demonstrating the advantage of\ndistributed algorithms over their single-node counterparts. In this paper, we\nstudy the stochastic Push-Pull method, a widely adopted decentralized\noptimization algorithm over directed graphs (digraphs). Unlike methods that\nrely solely on row-stochastic or column-stochastic mixing matrices, Push-Pull\navoids nonlinear correction and has shown superior empirical performance across\na variety of settings. However, its theoretical analysis remains challenging,\nand the linear speedup property has not been generally establishe--revealing a\nsignificant gap between empirical success and limited theoretical\nunderstanding. To bridge this gap, we propose a novel analysis framework and\nprove that Push-Pull achieves linear speedup over arbitrary strongly connected\ndigraphs. Our results provide the comprehensive theoretical understanding for\nstochastic Push-Pull, aligning its theory with empirical performance. Code:\n\\href{https://github.com/pkumelon/PushPull}{https://github.com/pkumelon/PushPull}."}
{"id": "2506.17504", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17504", "abs": "https://arxiv.org/abs/2506.17504", "authors": ["Hinata Nishino", "Kazumasa Omote", "Keita Emura"], "title": "A Smart Contract-based Non-Transferable Signature Verification System using Nominative Signatures", "comment": "An extended abstract appeared at the 20th Asia Joint Conference on\n  Information Security (AsiaJCIS) 2025", "summary": "Nominative signatures allow us to indicate who can verify a signature, and\nthey can be employed to construct a non-transferable signature verification\nsystem that prevents the signature verification by a third party in unexpected\nsituations. For example, this system can prevent IOU/loan certificate\nverification in unexpected situations. However, nominative signatures\nthemselves do not allow the verifier to check whether the funds will be\ntransferred in the future or have been transferred.It would be desirable to\nverify the fact simultaneously when the system involves a certain money\ntransfer such as cryptocurrencies/cryptoassets. In this paper, we propose a\nsmart contract-based non-transferable signature verification system using\nnominative signatures. We pay attention to the fact that the invisibility,\nwhich is a security requirement to be held for nominative signatures, allows us\nto publish nominative signatures on the blockchain. Our system can verify\nwhether a money transfer actually will take place, in addition to indicating\nwho can verify a signature. We transform the Hanaoka-Schuldt nominative\nsignature scheme (ACNS 2011, IEICE Trans. 2016) which is constructed over a\nsymmetric pairing to a scheme constructed over an asymmetric pairing, and\nevaluate the gas cost when a smart contract runs the verification algorithm of\nthe modified Hanaoka-Schuldt nominative signature scheme."}
{"id": "2506.18578", "categories": ["cs.DM", "cs.DS", "math.CO", "q-bio.PE", "05C85 (Primary), 05C20, 05C90, 06A07, 92D10 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.18578", "abs": "https://arxiv.org/abs/2506.18578", "authors": ["Narmina Baghirova", "Esther Galby", "Martin MilaniÄ"], "title": "Perfect phylogenies via the Minimum Uncovering Branching problem: efficiently solvable cases", "comment": null, "summary": "In this paper, we present new efficiently solvable cases of the Minimum\nUncovering Branching problem, an optimization problem with applications in\ncancer genomics introduced by Hujdurovi\\'c, Husi\\'c, Milani\\v{c}, Rizzi, and\nTomescu in 2018. The problem involves a family of finite sets, and the goal is\nto map each non-maximal set to exactly one set that contains it, minimizing the\nsum of uncovered elements across all sets in the family. Hujdurovi\\'c et al.\nformulated the problem in terms of branchings of the digraph formed by the\nproper set inclusion relation on the input sets and studied the problem\ncomplexity based on properties of the corresponding partially ordered set, in\nparticular, with respect to its height and width, defined respectively as the\nmaximum cardinality of a chain and an antichain. They showed that the problem\nis APX-complete for instances of bounded height and that a constant-factor\napproximation algorithm exists for instances of bounded width, but left the\nexact complexity for bounded-width instances open. In this paper, we answer\nthis question by proving that the problem is solvable in polynomial time. We\nderive this result by examining the structural properties of optimal solutions\nand reducing the problem to computing maximum matchings in bipartite graphs and\nmaximum weight antichains in partially ordered sets. We also introduce a new\npolynomially computable lower bound and identify another condition for\npolynomial-time solvability."}
{"id": "2506.17930", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.NE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.17930", "abs": "https://arxiv.org/abs/2506.17930", "authors": ["Jianyu Wang", "Zhiqiang Hu", "Lidong Bing"], "title": "Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective", "comment": "ICML 2025, and Code will be released at:\n  https://github.com/jianyu-cs/PromptQuine/", "summary": "We propose a novel prompt design paradigm that challenges conventional wisdom\nin large language model (LLM) prompting. While conventional wisdom prioritizes\nwell-crafted instructions and demonstrations for in-context learning (ICL), we\nshow that pruning random demonstrations into seemingly incoherent \"gibberish\"\ncan remarkably improve performance across diverse tasks. Notably, the\n\"gibberish\" always matches or surpasses state-of-the-art automatic prompt\noptimization techniques, achieving substantial gains regardless of LLM\nalignment. Nevertheless, discovering an effective pruning strategy is\nnon-trivial, as existing attribution methods and prompt compression algorithms\nfail to deliver robust results, let alone human intuition. In terms of this, we\npropose a self-discover prompt optimization framework, PromptQuine, an\nevolutionary search framework that automatically searches for the pruning\nstrategy by itself using only low-data regimes. Much like the emergent\ncomplexity in nature--such as symbiosis and self-organization--arising in\nresponse to resource constraints, our framework evolves and refines\nunconventional yet highly effective prompts by leveraging only the tokens\npresent within the context. We demonstrate its effectiveness across\nclassification, multi-choice question answering, generation and math reasoning\ntasks across LLMs, while achieving decent runtime efficiency. We hope our\nfindings can guide mechanistic studies on in-context learning, and provide a\ncall to action, to pave the way for more open-ended search algorithms for more\neffective LLM prompting."}
{"id": "2506.18195", "categories": ["math.OC", "cs.AI", "cs.MA", "cs.SY", "eess.SY", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2506.18195", "abs": "https://arxiv.org/abs/2506.18195", "authors": ["Giacomo Como", "Fabio Fagnani", "Anton Proskurnikov"], "title": "Wisdom of Crowds Through Myopic Self-Confidence Adaptation", "comment": null, "summary": "The wisdom of crowds is an umbrella term for phenomena suggesting that the\ncollective judgment or decision of a large group can be more accurate than the\nindividual judgments or decisions of the group members. A well-known example\nillustrating this concept is the competition at a country fair described by\nGalton, where the median value of the individual guesses about the weight of an\nox resulted in an astonishingly accurate estimate of the actual weight. This\nphenomenon resembles classical results in probability theory and relies on\nindependent decision-making. The accuracy of the group's final decision can be\nsignificantly reduced if the final agents' opinions are driven by a few\ninfluential agents.\n  In this paper, we consider a group of agents who initially possess\nuncorrelated and unbiased noisy measurements of a common state of the world.\nAssume these agents iteratively update their estimates according to a simple\nnon-Bayesian learning rule, commonly known in mathematical sociology as the\nFrench-DeGroot dynamics or iterative opinion pooling. As a result of this\niterative distributed averaging process, each agent arrives at an asymptotic\nestimate of the state of the world, with the variance of this estimate\ndetermined by the matrix of weights the agents assign to each other. Every\nagent aims at minimizing the variance of her asymptotic estimate of the state\nof the world; however, such variance is also influenced by the weights\nallocated by other agents. To achieve the best possible estimate, the agents\nmust then solve a game-theoretic, multi-objective optimization problem defined\nby the available sets of influence weights. We characterize both the Pareto\nfrontier and the set of Nash equilibria in the resulting game. Additionally, we\nexamine asynchronous best-response dynamics for the group of agents and prove\ntheir convergence to the set of strict Nash equilibria."}
{"id": "2506.17512", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17512", "abs": "https://arxiv.org/abs/2506.17512", "authors": ["Julien Piet", "Vivian Fang", "Rishi Khare", "Vern Paxson", "Raluca Ada Popa", "David Wagner"], "title": "Semantic-Aware Parsing for Security Logs", "comment": null, "summary": "Security analysts struggle to quickly and efficiently query and correlate log\ndata due to the heterogeneity and lack of structure in real-world logs.\nExisting AI-based parsers focus on learning syntactic log templates but lack\nthe semantic interpretation needed for querying. Directly querying large\nlanguage models on raw logs is impractical at scale and vulnerable to prompt\ninjection attacks.\n  In this paper, we introduce Matryoshka, the first end-to-end system\nleveraging LLMs to automatically generate semantically-aware structured log\nparsers. Matryoshka combines a novel syntactic parser-employing precise regular\nexpressions rather than wildcards-with a completely new semantic parsing layer\nthat clusters variables and maps them into a queryable, contextually meaningful\nschema. This approach provides analysts with queryable and semantically rich\ndata representations, facilitating rapid and precise log querying without the\ntraditional burden of manual parser construction. Additionally, Matryoshka can\nmap the newly created fields to recognized attributes within the Open\nCybersecurity Schema Framework (OCSF), enabling interoperability.\n  We evaluate Matryoshka on a newly curated real-world log benchmark,\nintroducing novel metrics to assess how consistently fields are named and\nmapped across logs. Matryoshka's syntactic parser outperforms prior works, and\nthe semantic layer achieves an F1 score of 0.95 on realistic security queries.\nAlthough mapping fields to the extensive OCSF taxonomy remains challenging,\nMatryoshka significantly reduces manual effort by automatically extracting and\norganizing valuable fields, moving us closer to fully automated, AI-driven log\nanalytics."}
{"id": "2506.17959", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17959", "abs": "https://arxiv.org/abs/2506.17959", "authors": ["Lizzy Farrugia", "Lilian M. Azzopardi", "Jeremy Debattista", "Charlie Abela"], "title": "medicX-KG: A Knowledge Graph for Pharmacists' Drug Information Needs", "comment": null, "summary": "The role of pharmacists is evolving from medicine dispensing to delivering\ncomprehensive pharmaceutical services within multidisciplinary healthcare\nteams. Central to this shift is access to accurate, up-to-date medicinal\nproduct information supported by robust data integration. Leveraging artificial\nintelligence and semantic technologies, Knowledge Graphs (KGs) uncover hidden\nrelationships and enable data-driven decision-making. This paper presents\nmedicX-KG, a pharmacist-oriented knowledge graph supporting clinical and\nregulatory decisions. It forms the semantic layer of the broader medicX\nplatform, powering predictive and explainable pharmacy services. medicX-KG\nintegrates data from three sources, including, the British National Formulary\n(BNF), DrugBank, and the Malta Medicines Authority (MMA) that addresses Malta's\nregulatory landscape and combines European Medicines Agency alignment with\npartial UK supply dependence. The KG tackles the absence of a unified national\ndrug repository, reducing pharmacists' reliance on fragmented sources. Its\ndesign was informed by interviews with practicing pharmacists to ensure\nreal-world applicability. We detail the KG's construction, including data\nextraction, ontology design, and semantic mapping. Evaluation demonstrates that\nmedicX-KG effectively supports queries about drug availability, interactions,\nadverse reactions, and therapeutic classes. Limitations, including missing\ndetailed dosage encoding and real-time updates, are discussed alongside\ndirections for future enhancements."}
{"id": "2506.18265", "categories": ["math.OC", "90-08, 90C11, 90C22"], "pdf": "https://arxiv.org/pdf/2506.18265", "abs": "https://arxiv.org/abs/2506.18265", "authors": ["Daniel de Roux", "Zedong Peng", "David E. Bernal Neira"], "title": "Spectral Outer-Approximation Algorithms for Binary Semidefinite Problems", "comment": null, "summary": "Integer semidefinite programming (ISDP) has recently gained attention due to\nits connection to binary quadratically constrained quadratic programs (BQCQPs),\nwhich can be exactly reformulated as binary semidefinite programs (BSDPs).\nHowever, it remains unclear whether this reformulation effectively uses\nexisting ISDP solvers to address BQCQPs. To the best of our knowledge, no\nspecialized ISDP algorithms exploit the unique structure of BSDPs derived from\nBQCQPs. This paper proposes a novel spectral outer approximation algorithm\ntailored for BSDPs derived from BQCQP reformulations. Our approach is inspired\nby polyhedral and second-order representable regions that outer approximate the\nfeasible set of a semidefinite program relying on a spectral decomposition of a\nmatrix that simultaneously diagonalizes the objective matrix and an aggregation\nof the constraint matrices. Computational experiments show that our algorithm\nis competitive with, and in some cases outperforms, state-of-the-art ISDP\nsolvers such as SCIP-SDP and PAJARITO, highlighting ISDP's potential for\nsolving BQCQPs."}
{"id": "2506.17622", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17622", "abs": "https://arxiv.org/abs/2506.17622", "authors": ["Shengchen Ling", "Yuefeng Du", "Yajin Zhou", "Lei Wu", "Cong Wang", "Xiaohua Jia", "Houmin Yan"], "title": "SoK: Stablecoin Designs, Risks, and the Stablecoin LEGO", "comment": null, "summary": "Stablecoins have become significant assets in modern finance, with a market\ncapitalization exceeding USD 246 billion (May 2025). Yet, despite their\nsystemic importance, a comprehensive and risk-oriented understanding of crucial\naspects like their design trade-offs, security dynamics, and interdependent\nfailure pathways often remains underdeveloped. This SoK confronts this gap\nthrough a large-scale analysis of 157 research studies, 95 active stablecoins,\nand 44 major security incidents. Our analysis establishes four pivotal\ninsights: 1) stability is best understood not an inherent property but an\nemergent, fragile state reliant on the interplay between market confidence and\ncontinuous liquidity; 2) stablecoin designs demonstrate trade-offs in risk\nspecialization instead of mitigation; 3) the widespread integration of yield\nmechanisms imposes a \"dual mandate\" that creates a systemic tension between the\ncore mission of stability and the high-risk financial engineering required for\ncompetitive returns; and 4) major security incidents act as acute \"evolutionary\npressures\", forging resilience by stress-testing designs and aggressively\nredefining the security frontier. We introduce the Stablecoin LEGO framework, a\nquantitative methodology mapping historical failures to current designs. Its\napplication reveals that a lower assessed risk strongly correlates with\nintegrating lessons from past incidents. We hope this provides a systematic\nfoundation for building, evaluating, and regulating more resilient stablecoins."}
{"id": "2506.18019", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18019", "abs": "https://arxiv.org/abs/2506.18019", "authors": ["Yuanchen Bei", "Weizhi Zhang", "Siwen Wang", "Weizhi Chen", "Sheng Zhou", "Hao Chen", "Yong Li", "Jiajun Bu", "Shirui Pan", "Yizhou Yu", "Irwin King", "Fakhri Karray", "Philip S. Yu"], "title": "Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities", "comment": "20 pages, 7 figures", "summary": "AI agents have experienced a paradigm shift, from early dominance by\nreinforcement learning (RL) to the rise of agents powered by large language\nmodels (LLMs), and now further advancing towards a synergistic fusion of RL and\nLLM capabilities. This progression has endowed AI agents with increasingly\nstrong abilities. Despite these advances, to accomplish complex real-world\ntasks, agents are required to plan and execute effectively, maintain reliable\nmemory, and coordinate smoothly with other agents. Achieving these capabilities\ninvolves contending with ever-present intricate information, operations, and\ninteractions. In light of this challenge, data structurization can play a\npromising role by transforming intricate and disorganized data into\nwell-structured forms that agents can more effectively understand and process.\nIn this context, graphs, with their natural advantage in organizing, managing,\nand harnessing intricate data relationships, present a powerful data paradigm\nfor structurization to support the capabilities demanded by advanced AI agents.\nTo this end, this survey presents a first systematic review of how graphs can\nempower AI agents. Specifically, we explore the integration of graph techniques\nwith core agent functionalities, highlight notable applications, and identify\nprospective avenues for future research. By comprehensively surveying this\nburgeoning intersection, we hope to inspire the development of next-generation\nAI agents equipped to tackle increasingly sophisticated challenges with graphs.\nRelated resources are collected and continuously updated for the community in\nthe Github link."}
{"id": "2506.18278", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.18278", "abs": "https://arxiv.org/abs/2506.18278", "authors": ["Yujie Liu", "Vincent Y. F. Tan", "Yunbei Xu"], "title": "Finite-Time Information-Theoretic Bounds in Queueing Control", "comment": null, "summary": "We establish the first finite-time information-theoretic lower bounds-and\nderive new policies that achieve them-for the total queue length in scheduling\nproblems over stochastic processing networks with both adversarial and\nstochastic arrivals. Prior analyses of MaxWeight guarantee only stability and\nasymptotic optimality in heavy traffic; we prove that, at finite horizons,\nMaxWeight can incur strictly larger backlog by problem-dependent factors which\nwe identify. Our main innovations are 1) a minimax framework that pinpoints the\nprecise problem parameters governing any policy's finite-time performance; 2)\nan information-theoretic lower bound on total queue length; 3) fundamental\nlimitation of MaxWeight that it is suboptimal in finite time; and 4) a new\nscheduling rule that minimizes the full Lyapunov drift-including its\nsecond-order term-thereby matching the lower bound under certain conditions, up\nto universal constants. These findings reveal a fundamental limitation on\n\"drift-only\" methods and points the way toward principled, non-asymptotic\noptimality in queueing control."}
{"id": "2506.17625", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17625", "abs": "https://arxiv.org/abs/2506.17625", "authors": ["Pengzhen Ke", "Liang Feng Zhang", "Huaxiong Wang", "Li-Ping Wang"], "title": "List-Decodable Byzantine Robust PIR: Lower Communication Complexity, Higher Byzantine Tolerance, Smaller List Size", "comment": "Submitted to AsiaCrypt 2025", "summary": "Private Information Retrieval (PIR) is a privacy-preserving primitive in\ncryptography. Significant endeavors have been made to address the variant of\nPIR concerning the malicious servers. Among those endeavors, list-decodable\nByzantine robust PIR schemes may tolerate a majority of malicious responding\nservers that provide incorrect answers. In this paper, we propose two perfect\nlist-decodable BRPIR schemes. Our schemes are the first ones that can\nsimultaneously handle a majority of malicious responding servers, achieve a\ncommunication complexity of $o(n^{1/2})$ for a database of size n, and provide\na nontrivial estimation on the list sizes. Compared with the existing\nsolutions, our schemes attain lower communication complexity, higher byzantine\ntolerance, and smaller list size."}
{"id": "2506.18044", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18044", "abs": "https://arxiv.org/abs/2506.18044", "authors": ["Joseph Babb", "Joohyung Lee"], "title": "Action Language BC+", "comment": "Journal of Logic and Computation, 2015", "summary": "Action languages are formal models of parts of natural language that are\ndesigned to describe effects of actions. Many of these languages can be viewed\nas high level notations of answer set programs structured to represent\ntransition systems. However, the form of answer set programs considered in the\nearlier work is quite limited in comparison with the modern Answer Set\nProgramming (ASP) language, which allows several useful constructs for\nknowledge representation, such as choice rules, aggregates, and abstract\nconstraint atoms. We propose a new action language called BC+, which closes the\ngap between action languages and the modern ASP language. The main idea is to\ndefine the semantics of BC+ in terms of general stable model semantics for\npropositional formulas, under which many modern ASP language constructs can be\nidentified with shorthands for propositional formulas. Language BC+ turns out\nto be sufficiently expressive to encompass the best features of other action\nlanguages, such as languages B, C, C+, and BC. Computational methods available\nin ASP solvers are readily applicable to compute BC+, which led to an\nimplementation of the language by extending system cplus2asp."}
{"id": "2506.18301", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.18301", "abs": "https://arxiv.org/abs/2506.18301", "authors": ["Johannes Heid", "Nils Bornhorst", "Eric TÃ¶nges", "Philipp HÃ¤rtel", "Denis Mende", "Martin Braun"], "title": "A Computationally Efficient Method for Solving Mixed-Integer AC Optimal Power Flow Problems", "comment": null, "summary": "Stepwise controllable devices, such as switched capacitors or stepwise\ncontrollable loads and generators, transform the nonconvex AC optimal power\nflow (AC-OPF) problem into a nonconvex mixed-integer (MI) programming problem\nwhich is generally hard to solve optimally. Existing methods for solving\nMI-AC-OPF problems usually suffer from either limited accuracy or computational\nintractability, making them impractical for real-world applications. To address\nthese challenges, we propose an efficient iterative deflation approach\nproviding high-quality approximate solutions. In each iteration, a continuously\nrelaxed version of the MI-AC-OPF problem is solved and one candidate integer\nvalue is systematically eliminated based on the evaluation of a simple power\nflow result. The computational complexity of the proposed algorithm grows\nlinearly with the number of integer optimization variables, ensuring\nscalability. Simulations demonstrate that the proposed approach achieves\nsignificant improvements in solution accuracy compared to a state-of-the-art\napproach. Thus, the proposed method is promising for solving practical\nMI-AC-OPF problems."}
{"id": "2506.17767", "categories": ["cs.CR", "cs.DC", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17767", "abs": "https://arxiv.org/abs/2506.17767", "authors": ["Hsuan-Po Liu", "Hessam Mahdavifar"], "title": "A Locally Differential Private Coding-Assisted Succinct Histogram Protocol", "comment": null, "summary": "A succinct histogram captures frequent items and their frequencies across\nclients and has become increasingly important for large-scale,\nprivacy-sensitive machine learning applications. To develop a rigorous\nframework to guarantee privacy for the succinct histogram problem, local\ndifferential privacy (LDP) has been utilized and shown promising results. To\npreserve data utility under LDP, which essentially works by intentionally\nadding noise to data, error-correcting codes naturally emerge as a promising\ntool for reliable information collection. This work presents the first\npractical $(\\epsilon,\\delta)$-LDP protocol for constructing succinct histograms\nusing error-correcting codes. To this end, polar codes and their\nsuccessive-cancellation list (SCL) decoding algorithms are leveraged as the\nunderlying coding scheme. More specifically, our protocol introduces\nGaussian-based perturbations to enable efficient soft decoding. Experiments\ndemonstrate that our approach outperforms prior methods, particularly for items\nwith low true frequencies, while maintaining similar frequency estimation\naccuracy."}
{"id": "2506.18056", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18056", "abs": "https://arxiv.org/abs/2506.18056", "authors": ["Paolo Baldi", "Fabio Aurelio D'Asaro", "Abeer Dyoub", "Francesca Alessandra Lisi"], "title": "Weighted Assumption Based Argumentation to reason about ethical principles and actions", "comment": null, "summary": "We augment Assumption Based Argumentation (ABA for short) with weighted\nargumentation. In a nutshell, we assign weights to arguments and then derive\nthe weight of attacks between ABA arguments. We illustrate our proposal through\nrunning examples in the field of ethical reasoning, and present an\nimplementation based on Answer Set Programming."}
{"id": "2506.18409", "categories": ["math.OC", "math.DS", "11Y55, 11K31, 39A12, 90C26"], "pdf": "https://arxiv.org/pdf/2506.18409", "abs": "https://arxiv.org/abs/2506.18409", "authors": ["AssalÃ© AdjÃ©"], "title": "On the Maximization of Real Sequences", "comment": "31 pages", "summary": "In this paper, we study a maximization problem on real sequences. More\nprecisely, for a given sequence, we are interesting in computing the supremum\nof the sequence and an index for which the associated term is maximal. We\npropose a general methodology to solve this maximization problem. The method is\nbased on upper approximations constructed from pairs of eventually decreasing\nsequences of strictly increasing continuous functions on $[0,1]$ and of scalars\nin $(0,1)$. Then, we can associate integers with those pairs using inverses on\n$[0,1]$ of the functions. We prove that such pairs always exist and one\nprovides the index maximizer. In general, such pairs provide an upper bound of\nthe greatest maximizer of the sequence. Finally, we apply the methodology on\nconcrete examples including famous sequences such as logistic, Fibonacci and\nSyracuse sequences. We also apply our techniques to norm based peaks\ncomputation problems on discrete-time linear systems."}
{"id": "2506.17795", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17795", "abs": "https://arxiv.org/abs/2506.17795", "authors": ["Rachel Cazzola", "Cyrus Minwalla", "Calvin Chan", "Jim Plusquellic"], "title": "A TRNG Implemented using a Soft-Data Based Sponge Function within a Unified Strong PUF Architecture", "comment": null, "summary": "Hardware security primitives including True Random Number Generators (TRNG)\nand Physical Unclonable Functions (PUFs) are central components to establishing\na root of trust in microelectronic systems. In this paper, we propose a unified\nPUF-TRNG architecture that leverages a combination of the static entropy\navailable in a strong PUF called the shift-register, reconvergent-fanout (SiRF)\nPUF, and the dynamic entropy associated with random noise present in path delay\nmeasurements. The SiRF PUF uses an engineered netlist containing a large number\nof paths as the source of static entropy, and a time-to-digital-converter (TDC)\nas a high-resolution, embedded instrument for measuring path delays, where\nmeasurement noise serves as the source of dynamic entropy. A novel data\npostprocessing algorithm is proposed based on a modified duplex sponge\nconstruction. The sponge function operates on soft data, i.e., fixed point data\nvalues, to add entropy to the ensuing random bit sequences and to increase the\nbit generation rate. A postprocessing algorithm for reproducing PUF-generated\nencryption keys is also used in the TRNG to protect against temperature voltage\nattacks designed to subvert the random characteristics in the bit sequences.\nThe unified PUF-TRNG architecture is implemented across multiple instances of a\nZYBO Z7-10 FPGA board and extensively tested with NIST SP 800-22, NIST SP\n800-90B, AIS-31, and DieHarder test suites. Results indicate a stable and\nrobust TRNG design with excellent min-entropy and a moderate data rate."}
{"id": "2506.18096", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18096", "abs": "https://arxiv.org/abs/2506.18096", "authors": ["Yuxuan Huang", "Yihang Chen", "Haozheng Zhang", "Kang Li", "Meng Fang", "Linyi Yang", "Xiaoguang Li", "Lifeng Shang", "Songcen Xu", "Jianye Hao", "Kun Shao", "Jun Wang"], "title": "Deep Research Agents: A Systematic Examination And Roadmap", "comment": null, "summary": "The rapid progress of Large Language Models (LLMs) has given rise to a new\ncategory of autonomous AI systems, referred to as Deep Research (DR) agents.\nThese agents are designed to tackle complex, multi-turn informational research\ntasks by leveraging a combination of dynamic reasoning, adaptive long-horizon\nplanning, multi-hop information retrieval, iterative tool use, and the\ngeneration of structured analytical reports. In this paper, we conduct a\ndetailed analysis of the foundational technologies and architectural components\nthat constitute Deep Research agents. We begin by reviewing information\nacquisition strategies, contrasting API-based retrieval methods with\nbrowser-based exploration. We then examine modular tool-use frameworks,\nincluding code execution, multimodal input processing, and the integration of\nModel Context Protocols (MCPs) to support extensibility and ecosystem\ndevelopment. To systematize existing approaches, we propose a taxonomy that\ndifferentiates between static and dynamic workflows, and we classify agent\narchitectures based on planning strategies and agent composition, including\nsingle-agent and multi-agent configurations. We also provide a critical\nevaluation of current benchmarks, highlighting key limitations such as\nrestricted access to external knowledge, sequential execution inefficiencies,\nand misalignment between evaluation metrics and the practical objectives of DR\nagents. Finally, we outline open challenges and promising directions for future\nresearch. A curated and continuously updated repository of DR agent research is\navailable at: {https://github.com/ai-agents-2030/awesome-deep-research-agent}."}
{"id": "2506.18417", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.18417", "abs": "https://arxiv.org/abs/2506.18417", "authors": ["Thomas Berger"], "title": "An improved input-constrained funnel controller for nonlinear systems", "comment": null, "summary": "We present an improvement of a recent funnel controller design for uncertain\nnonlinear multi-input, multi-output systems modeled by higher order functional\ndifferential equations in the presence of input constraints. The objective is\nto guarantee the evolution of the tracking error within a performance funnel\nwith prescribed desired shape for the case of inactive saturation. Compared to\nits precursor, controller complexity is significantly reduced, much fewer\ndesign parameters are involved and simulations exhibit a superior performance."}
{"id": "2506.17805", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17805", "abs": "https://arxiv.org/abs/2506.17805", "authors": ["Md. Kamrul Hossain", "Walid Aljoby", "Anis Elgabli", "Ahmed M. Abdelmoniem", "Khaled A. Harras"], "title": "AdRo-FL: Informed and Secure Client Selection for Federated Learning in the Presence of Adversarial Aggregator", "comment": "17 pages", "summary": "Federated Learning (FL) enables collaborative learning without exposing\nclients' data. While clients only share model updates with the aggregator,\nstudies reveal that aggregators can infer sensitive information from these\nupdates. Secure Aggregation (SA) protects individual updates during\ntransmission; however, recent work demonstrates a critical vulnerability where\nadversarial aggregators manipulate client selection to bypass SA protections,\nconstituting a Biased Selection Attack (BSA). Although verifiable random\nselection prevents BSA, it precludes informed client selection essential for FL\nperformance. We propose Adversarial Robust Federated Learning (AdRo-FL), which\nsimultaneously enables: informed client selection based on client utility, and\nrobust defense against BSA maintaining privacy-preserving aggregation. AdRo-FL\nimplements two client selection frameworks tailored for distinct settings. The\nfirst framework assumes clients are grouped into clusters based on mutual\ntrust, such as different branches of an organization. The second framework\nhandles distributed clients where no trust relationships exist between them.\nFor the cluster-oriented setting, we propose a novel defense against BSA by (1)\nenforcing a minimum client selection quota from each cluster, supervised by a\ncluster-head in every round, and (2) introducing a client utility function to\nprioritize efficient clients. For the distributed setting, we design a\ntwo-phase selection protocol: first, the aggregator selects the top clients\nbased on our utility-driven ranking; then, a verifiable random function (VRF)\nensures a BSA-resistant final selection. AdRo-FL also applies quantization to\nreduce communication overhead and sets strict transmission deadlines to improve\nenergy efficiency. AdRo-FL achieves up to $1.85\\times$ faster time-to-accuracy\nand up to $1.06\\times$ higher final accuracy compared to insecure baselines."}
{"id": "2506.18126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18126", "abs": "https://arxiv.org/abs/2506.18126", "authors": ["Xiang Yuming", "Li Sizhao", "Li Rongpeng", "Zhao Zhifeng", "Zhang Honggang"], "title": "Decentralized Consensus Inference-based Hierarchical Reinforcement Learning for Multi-Constrained UAV Pursuit-Evasion Game", "comment": null, "summary": "Multiple quadrotor unmanned aerial vehicle (UAV) systems have garnered\nwidespread research interest and fostered tremendous interesting applications,\nespecially in multi-constrained pursuit-evasion games (MC-PEG). The Cooperative\nEvasion and Formation Coverage (CEFC) task, where the UAV swarm aims to\nmaximize formation coverage across multiple target zones while collaboratively\nevading predators, belongs to one of the most challenging issues in MC-PEG,\nespecially under communication-limited constraints. This multifaceted problem,\nwhich intertwines responses to obstacles, adversaries, target zones, and\nformation dynamics, brings up significant high-dimensional complications in\nlocating a solution. In this paper, we propose a novel two-level framework\n(i.e., Consensus Inference-based Hierarchical Reinforcement Learning (CI-HRL)),\nwhich delegates target localization to a high-level policy, while adopting a\nlow-level policy to manage obstacle avoidance, navigation, and formation.\nSpecifically, in the high-level policy, we develop a novel multi-agent\nreinforcement learning module, Consensus-oriented Multi-Agent Communication\n(ConsMAC), to enable agents to perceive global information and establish\nconsensus from local states by effectively aggregating neighbor messages.\nMeanwhile, we leverage an Alternative Training-based Multi-agent proximal\npolicy optimization (AT-M) and policy distillation to accomplish the low-level\ncontrol. The experimental results, including the high-fidelity\nsoftware-in-the-loop (SITL) simulations, validate that CI-HRL provides a\nsuperior solution with enhanced swarm's collaborative evasion and task\ncompletion capabilities."}
{"id": "2506.18806", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.18806", "abs": "https://arxiv.org/abs/2506.18806", "authors": ["Yihong Zhou", "Hanbin Yang", "Thomas Morstyn"], "title": "FICA: Faster Inner Convex Approximation of Chance Constrained Grid Dispatch with Decision-Coupled Uncertainty", "comment": "10 pages, in review for IEEE Transactions on Power Systems", "summary": "This paper proposes a Faster Inner Convex Approximation (FICA) method for\nsolving power system dispatch problems with Wasserstein distributionally robust\njoint chance constraints (WJCC) and incorporating the modelling of the\nautomatic generation control factors. The problem studied belongs to the\ncomputationally challenging class of WJCC with left-hand-side uncertainty\n(LHS-WJCC). By exploiting the special one-dimensional structure (even if only\npartially present) of the problem, the proposed FICA incorporates a set of\nstrong valid inequalities to accelerate the solution process. We prove that\nFICA achieves the same optimality as the well-known conditional value-at-risk\n(CVaR) inner convex approximation method. Our numerical experiments demonstrate\nthat the proposed FICA can yield 40x computational speedup compared to CVaR,\nand can even reach up to 500x speedup when the optimisation horizon exceeds 16\ntime steps. This speedup is achieved when only 50% of constraints in a WJCC\nhave the one-dimensional structure. The approximation quality is numerically\nverified to be the same as CVaR, and the quality gap is below 1% when compared\nto the computationally demanding exact reformulation of the LHS-WJCC in most\ncases. We also discuss the applications of FICA in optimisation problems from\nother domains that (partially) exhibit the one-dimensional structure."}
{"id": "2506.17865", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.17865", "abs": "https://arxiv.org/abs/2506.17865", "authors": ["Dinesh Reddy Ankireddy", "Sudipta Paria", "Aritra Dasgupta", "Sandip Ray", "Swarup Bhunia"], "title": "LASA: Enhancing SoC Security Verification with LLM-Aided Property Generation", "comment": "9 pages, 5 figures, 5 tables", "summary": "Ensuring the security of modern System-on-Chip (SoC) designs poses\nsignificant challenges due to increasing complexity and distributed assets\nacross the intellectual property (IP) blocks. Formal property verification\n(FPV) provides the capability to model and validate design behaviors through\nsecurity properties with model checkers; however, current practices require\nsignificant manual efforts to create such properties, making them\ntime-consuming, costly, and error-prone. The emergence of Large Language Models\n(LLMs) has showcased remarkable proficiency across diverse domains, including\nHDL code generation and verification tasks. Current LLM-based techniques often\nproduce vacuous assertions and lack efficient prompt generation, comprehensive\nverification, and bug detection. This paper presents LASA, a novel framework\nthat leverages LLMs and retrieval-augmented generation (RAG) to produce\nnon-vacuous security properties and SystemVerilog Assertions (SVA) from design\nspecifications and related documentation for bus-based SoC designs. LASA\nintegrates commercial EDA tool for FPV to generate coverage metrics and\niteratively refines prompts through a feedback loop to enhance coverage. The\neffectiveness of LASA is validated through various open-source SoC designs,\ndemonstrating high coverage values with an average of ~88\\%, denoting\ncomprehensive verification through efficient generation of security properties\nand SVAs. LASA also demonstrates bug detection capabilities, identifying five\nunique bugs in the buggy OpenTitan SoC from Hack@DAC'24 competition."}
{"id": "2506.18135", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18135", "abs": "https://arxiv.org/abs/2506.18135", "authors": ["Zijun Chen", "Zhanpeng Zhou", "Bo Zhang", "Weinan Zhang", "Xi Sun", "Junchi Yan"], "title": "SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging", "comment": "preprint, accepted at IJCNN2025", "summary": "Model merging has gained increasing attention due to its intriguing property:\ninterpolating the parameters of different task-specific fine-tuned models leads\nto multi-task abilities. However, despite its empirical success, the underlying\nmechanisms of model merging remain poorly understood. In this work, we delve\ninto the mechanism behind model merging from a representation perspective. Our\nanalysis reveals that model merging achieves multi-task abilities through two\nkey capabilities: i) distinguishing samples from different tasks, and ii)\nadapting to the corresponding expert model for each sample. These two\ncapabilities allow the merged model to retain task-specific expertise, enabling\nefficient multi-task adaptation. Building on these insights, we propose\n\\texttt{SE-Merging}, a self-enhanced model merging framework that leverages\nthese two characteristics to dynamically identify the corresponding task for\neach sample and then adaptively rescales the merging coefficients to further\nenhance task-specific expertise in the merged model. Notably,\n\\texttt{SE-Merging} achieves dynamic model merging without additional training.\nExtensive experiments demonstrate that \\texttt{SE-Merging} achieves significant\nperformance improvements while remaining compatible with existing model merging\ntechniques."}
{"id": "2506.18884", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.18884", "abs": "https://arxiv.org/abs/2506.18884", "authors": ["Flavien LÃ©ger", "Maxime Sylvestre"], "title": "A comparison principle for variational problems : with an application to optimal transport", "comment": null, "summary": "We study variational problems on Banach spaces which involve submodular\nenergies. We extend the notion of exchangeability to this infinite dimensional\nsetting and show that it is in duality with submodularity. These two notions\nallow us to derive comparison principle in an abstract fashion. We apply our\nresults to the optimal transport and entropic optimal transport problems. We\nthen derive comparison principles on the Kantorovich and Schr\\\"odinger\npotentials. We also prove comparison principles for the associated JKO schemes."}
{"id": "2506.17935", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2506.17935", "abs": "https://arxiv.org/abs/2506.17935", "authors": ["Zhengwu Huang", "Ding Deng", "Pengyue Sun", "Guangfu Sun", "Xiaomei Tang"], "title": "Cost-Effective Optimization and Implementation of the CRT-Paillier Decryption Algorithm for Enhanced Performance", "comment": "19 pages,7 figures", "summary": "To address the privacy protection problem in cloud computing, privacy\nenhancement techniques such as the Paillier additive homomorphism algorithm are\nreceiving widespread attention. Paillier algorithm allows addition and scalar\nmultiplication operations in dencrypted state, which can effectively protect\nprivacy. However, its computational efficiency is limited by complex modulo\noperations due to the ciphertext expansion followed by encryption. To\naccelerate its decryption operation, the Chinese Remainder Theorem (CRT) is\noften used to optimize these modulo operations, which lengthens the decryption\ncomputation chain in turn. To address this issue, we propose an eCRT-Paillier\ndecryption algorithm that shortens the decryption computation chain by\ncombining precomputed parameters and eliminating extra judgment operations\nintroduced by Montgomery modular multiplications. These two improvements reduce\n50% modular multiplications and 60% judgment operations in the postprocessing\nof the CRT-Paillier decryption algorithm. Based on these improvements, we\npropose a highly parallel full-pipeline architecture to eliminate stalls caused\nby multiplier reuse in traditional modular exponentiation operations. This\narchitecture also adopts some optimizations such as simplifying modular\nexponentiation units by dividing the exponent into segments and parallelizing\ndata flow by multi-core instantiation. Finally, a high-throughput and efficient\nPaillier accelerator named MESA was implemented on the Xilinx Virtex-7 FPGA for\nevaluation, which can complete a decryption using 2048-bit key within 0.577ms\nunder 100 MHz clock frequency. Compared to prior works, MESA demonstrates a\nthroughput improvement of 1.16 to 313.21 under identical conditions, also with\nenhancements in area efficiency for LUT, DSP, and FF of 3.32 to 117.55, 1.49 to\n1.64, and 2.94 to 9.94, respectively."}
{"id": "2506.18149", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18149", "abs": "https://arxiv.org/abs/2506.18149", "authors": ["Fumian Chen", "Sotheara Veng", "Joshua Wilson", "Xiaoming Li", "Hui Fang"], "title": "CoachGPT: A Scaffolding-based Academic Writing Assistant", "comment": "SIGIR 2025 DEMO Pre-print", "summary": "Academic writing skills are crucial for students' success, but can feel\noverwhelming without proper guidance and practice, particularly when writing in\na second language. Traditionally, students ask instructors or search\ndictionaries, which are not universally accessible. Early writing assistants\nemerged as rule-based systems that focused on detecting misspellings,\nsubject-verb disagreements, and basic punctuation errors; however, they are\ninaccurate and lack contextual understanding. Machine learning-based assistants\ndemonstrate a strong ability for language understanding but are expensive to\ntrain. Large language models (LLMs) have shown remarkable capabilities in\ngenerating responses in natural languages based on given prompts. Still, they\nhave a fundamental limitation in education: they generate essays without\nteaching, which can have detrimental effects on learning when misused. To\naddress this limitation, we develop CoachGPT, which leverages large language\nmodels (LLMs) to assist individuals with limited educational resources and\nthose who prefer self-paced learning in academic writing. CoachGPT is an AI\nagent-based web application that (1) takes instructions from experienced\neducators, (2) converts instructions into sub-tasks, and (3) provides real-time\nfeedback and suggestions using large language models. This unique scaffolding\nstructure makes CoachGPT unique among existing writing assistants. Compared to\nexisting writing assistants, CoachGPT provides a more immersive writing\nexperience with personalized feedback and guidance. Our user studies prove the\nusefulness of CoachGPT and the potential of large language models for academic\nwriting."}
{"id": "2506.17988", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17988", "abs": "https://arxiv.org/abs/2506.17988", "authors": ["Seongjin Kim", "Sanguk Yun", "Jungho Jang"], "title": "Secure User-friendly Blockchain Modular Wallet Design Using Android & OP-TEE", "comment": "25 pages", "summary": "Emerging crypto economies still hemorrhage digital assets because legacy\nwallets leak private keys at almost every layer of the software stack, from\nuser-space libraries to kernel memory dumps. This paper solves that twin crisis\nof security and interoperability by re-imagining key management as a\nplatform-level service anchored in ARM TrustZone through OP-TEE. Our\narchitecture fractures the traditional monolithic Trusted Application into\nper-chain modules housed in a multi-tenant TA store, finally breaking OP-TEE's\nsingle-binary ceiling. A cryptographically sealed firmware-over-the-air\npipeline welds each TA set to an Android system image, enabling hot-swap\nupdates while Verified Boot enforces rollback protection. Every package carries\na chained signature developer first, registry second so even a compromised\nsupply chain cannot smuggle malicious code past the Secure World's RSA-PSS\ngatekeeper. Inside the TEE, strict inter-TA isolation, cache partitioning, and\nGP-compliant crypto APIs ensure secrets never bleed across trust boundaries or\ntiming domains. The Rich Execution Environment can interact only via\nhardware-mediated Secure Monitor Calls, collapsing the surface exposed to\nmalware in Android space. End-users enjoy a single polished interface yet can\ninstall or retire Bitcoin, Ethereum, Solana, or tomorrow's chain with one tap,\nshrinking both storage footprint and audit scope. For auditors, the composition\nmodel slashes duplicated verification effort by quarantining blockchain logic\ninside narrowly scoped modules that share formally specified interfaces. Our\nthreat analysis spans six adversary layers and shows how the design neutralizes\nREE malware sniffing, OTA injection, and cross-module side channels without\nexotic hardware. A reference implementation on AOSP exports a Wallet Manager\nHAL, custom SELinux domains, and a CI/CD pipeline that vet community modules\nbefore release. The result is not merely another hardware wallet but a\nprogrammable substrate that can evolve at the velocity of the blockchain\necosystem. By welding radical extensibility to hardware-anchored assurance, the\nplatform closes the security-usability gap that has long stymied mass-market\nself-custody. We posit that modular TEEs are the missing OS primitive for Web3,\nmuch as virtual memory unlocked multi-tasking in classical computing. Together,\nthese contributions sketch a blueprint for multi-chain asset management that is\nauditable, resilient, and poised for global deployment."}
{"id": "2506.18156", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18156", "abs": "https://arxiv.org/abs/2506.18156", "authors": ["Akash Kundu", "Rishika Goswami"], "title": "AI Through the Human Lens: Investigating Cognitive Theories in Machine Psychology", "comment": null, "summary": "We investigate whether Large Language Models (LLMs) exhibit human-like\ncognitive patterns under four established frameworks from psychology: Thematic\nApperception Test (TAT), Framing Bias, Moral Foundations Theory (MFT), and\nCognitive Dissonance. We evaluated several proprietary and open-source models\nusing structured prompts and automated scoring. Our findings reveal that these\nmodels often produce coherent narratives, show susceptibility to positive\nframing, exhibit moral judgments aligned with Liberty/Oppression concerns, and\ndemonstrate self-contradictions tempered by extensive rationalization. Such\nbehaviors mirror human cognitive tendencies yet are shaped by their training\ndata and alignment methods. We discuss the implications for AI transparency,\nethical deployment, and future work that bridges cognitive psychology and AI\nsafety"}
{"id": "2506.18053", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18053", "abs": "https://arxiv.org/abs/2506.18053", "authors": ["Marcos Florencio", "Thomas Barton"], "title": "Mechanistic Interpretability in the Presence of Architectural Obfuscation", "comment": null, "summary": "Architectural obfuscation - e.g., permuting hidden-state tensors, linearly\ntransforming embedding tables, or remapping tokens - has recently gained\ntraction as a lightweight substitute for heavyweight cryptography in\nprivacy-preserving large-language-model (LLM) inference. While recent work has\nshown that these techniques can be broken under dedicated reconstruction\nattacks, their impact on mechanistic interpretability has not been\nsystematically studied. In particular, it remains unclear whether scrambling a\nnetwork's internal representations truly thwarts efforts to understand how the\nmodel works, or simply relocates the same circuits to an unfamiliar coordinate\nsystem. We address this gap by analyzing a GPT-2-small model trained from\nscratch with a representative obfuscation map. Assuming the obfuscation map is\nprivate and the original basis is hidden (mirroring an honest-but-curious\nserver), we apply logit-lens attribution, causal path-patching, and\nattention-head ablation to locate and manipulate known circuits. Our findings\nreveal that obfuscation dramatically alters activation patterns within\nattention heads yet preserves the layer-wise computational graph. This\ndisconnect hampers reverse-engineering of user prompts: causal traces lose\ntheir alignment with baseline semantics, and token-level logit attributions\nbecome too noisy to reconstruct. At the same time, feed-forward and residual\npathways remain functionally intact, suggesting that obfuscation degrades\nfine-grained interpretability without compromising top-level task performance.\nThese results establish quantitative evidence that architectural obfuscation\ncan simultaneously (i) retain global model behaviour and (ii) impede\nmechanistic analyses of user-specific content. By mapping where\ninterpretability breaks down, our study provides guidance for future privacy\ndefences and for robustness-aware interpretability tooling."}
{"id": "2506.18158", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.18158", "abs": "https://arxiv.org/abs/2506.18158", "authors": ["Xinzge Gao", "Chuanrui Hu", "Bin Chen", "Teng Li"], "title": "Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation", "comment": null, "summary": "Multimodal large language models (MLLMs) are attracting growing attention in\nthe development of Graphical User Interface (GUI) agents. Existing approaches\noften rely on historical screenshots or actions to implicitly represent the\ntask state. This reliance poses challenges for GUI agents in accurately\nunderstanding task states and underscores the absence of effective mechanisms\nto store critical information in complex and lengthy cross-app tasks. To\naddress these challenges, we propose Chain-of-Memory (CoM), a novel approach\nfor explicitly modeling short-term and long-term memory in GUI agents. CoM\nachieves this by capturing action descriptions, integrating task-relevant\nscreen information, and maintaining a dedicated memory module to store and\nmanage this information. By leveraging explicit memory representations, CoM\nenables GUI agents to better understand task states and retain critical\nhistorical information persistently. To equip GUI agents with memory management\ncapabilities and evaluate the effectiveness of CoM, we developed the GUI\nOdyssey-CoM, a dataset comprising 111k screen-action pairs annotated with\nChain-of-Memory. Experimental results demonstrate that CoM significantly\nimproves GUI agents' performance in cross-application tasks. Additionally, GUI\nOdyssey-CoM enables 7B models to achieve memory management capabilities\ncomparable to 72B models. The dataset and code will be open-sourced."}
{"id": "2506.18087", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18087", "abs": "https://arxiv.org/abs/2506.18087", "authors": ["Huaiying Luo", "Cheng Ji"], "title": "Federated Learning-Based Data Collaboration Method for Enhancing Edge Cloud AI System Security Using Large Language Models", "comment": "Accepted by the 2025 5th International Symposium on Computer\n  Technology and Information Science (ISCTIS 2025)", "summary": "With the widespread application of edge computing and cloud systems in\nAI-driven applications, how to maintain efficient performance while ensuring\ndata privacy has become an urgent security issue. This paper proposes a\nfederated learning-based data collaboration method to improve the security of\nedge cloud AI systems, and use large-scale language models (LLMs) to enhance\ndata privacy protection and system robustness. Based on the existing federated\nlearning framework, this method introduces a secure multi-party computation\nprotocol, which optimizes the data aggregation and encryption process between\ndistributed nodes by using LLM to ensure data privacy and improve system\nefficiency. By combining advanced adversarial training techniques, the model\nenhances the resistance of edge cloud AI systems to security threats such as\ndata leakage and model poisoning. Experimental results show that the proposed\nmethod is 15% better than the traditional federated learning method in terms of\ndata protection and model robustness."}
{"id": "2506.18183", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18183", "abs": "https://arxiv.org/abs/2506.18183", "authors": ["Zhiting Mei", "Christina Zhang", "Tenny Yin", "Justin Lidard", "Ola Shorinwa", "Anirudha Majumdar"], "title": "Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?", "comment": null, "summary": "Reasoning language models have set state-of-the-art (SOTA) records on many\nchallenging benchmarks, enabled by multi-step reasoning induced using\nreinforcement learning. However, like previous language models, reasoning\nmodels are prone to generating confident, plausible responses that are\nincorrect (hallucinations). Knowing when and how much to trust these models is\ncritical to the safe deployment of reasoning models in real-world applications.\nTo this end, we explore uncertainty quantification of reasoning models in this\nwork. Specifically, we ask three fundamental questions: First, are reasoning\nmodels well-calibrated? Second, does deeper reasoning improve model\ncalibration? Finally, inspired by humans' innate ability to double-check their\nthought processes to verify the validity of their answers and their confidence,\nwe ask: can reasoning models improve their calibration by explicitly reasoning\nabout their chain-of-thought traces? We introduce introspective uncertainty\nquantification (UQ) to explore this direction. In extensive evaluations on SOTA\nreasoning models across a broad range of benchmarks, we find that reasoning\nmodels: (i) are typically overconfident, with self-verbalized confidence\nestimates often greater than 85% particularly for incorrect responses, (ii)\nbecome even more overconfident with deeper reasoning, and (iii) can become\nbetter calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not\nuniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we\nconclude with important research directions to design necessary UQ benchmarks\nand improve the calibration of reasoning models."}
{"id": "2506.18100", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.18100", "abs": "https://arxiv.org/abs/2506.18100", "authors": ["Taimoor Ahmad", "Anas Ali"], "title": "Optimizing Resource Allocation and Energy Efficiency in Federated Fog Computing for IoT", "comment": null, "summary": "Address Resolution Protocol (ARP) spoofing attacks severely threaten Internet\nof Things (IoT) networks by allowing attackers to intercept, modify, or block\ncommunications. Traditional detection methods are insufficient due to high\nfalse positives and poor adaptability. This research proposes a multi-layered\nmachine learning-based framework for intelligently detecting ARP spoofing in\nIoT networks. Our approach utilizes an ensemble of classifiers organized into\nmultiple layers, each layer optimizing detection accuracy and reducing false\nalarms. Experimental evaluations demonstrate significant improvements in\ndetection accuracy (up to 97.5\\%), reduced false positive rates (less than\n2\\%), and faster detection time compared to existing methods. Our key\ncontributions include introducing multi-layer ensemble classifiers specifically\ntuned for IoT networks, systematically addressing dataset imbalance problems,\nintroducing a dynamic feedback mechanism for classifier retraining, and\nvalidating practical applicability through extensive simulations. This research\nenhances security management in IoT deployments, providing robust defenses\nagainst ARP spoofing attacks and improving reliability and trust in IoT\nenvironments."}
{"id": "2506.18187", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.18187", "abs": "https://arxiv.org/abs/2506.18187", "authors": ["Shahriar Noroozizadeh", "Pim Welle", "Jeremy C. Weiss", "George H. Chen"], "title": "The Impact of Medication Non-adherence on Adverse Outcomes: Evidence from Schizophrenia Patients via Survival Analysis", "comment": "Conference on Health, Inference, and Learning (CHIL 2025)", "summary": "This study quantifies the association between non-adherence to antipsychotic\nmedications and adverse outcomes in individuals with schizophrenia. We frame\nthe problem using survival analysis, focusing on the time to the earliest of\nseveral adverse events (early death, involuntary hospitalization, jail\nbooking). We extend standard causal inference methods (T-learner, S-learner,\nnearest neighbor matching) to utilize various survival models to estimate\nindividual and average treatment effects, where treatment corresponds to\nmedication non-adherence. Analyses are repeated using different amounts of\nlongitudinal information (3, 6, 9, and 12 months). Using data from Allegheny\nCounty in western Pennsylvania, we find strong evidence that non-adherence\nadvances adverse outcomes by approximately 1 to 4 months. Ablation studies\nconfirm that county-provided risk scores adjust for key confounders, as their\nremoval amplifies the estimated effects. Subgroup analyses by medication\nformulation (injectable vs. oral) and medication type consistently show that\nnon-adherence is associated with earlier adverse events. These findings\nhighlight the clinical importance of adherence in delaying psychiatric crises\nand show that integrating survival analysis with causal inference tools can\nyield policy-relevant insights. We caution that although we apply causal\ninference, we only make associative claims and discuss assumptions needed for\ncausal interpretation."}
{"id": "2506.18114", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.18114", "abs": "https://arxiv.org/abs/2506.18114", "authors": ["Ioannis Panopoulos", "Maria-Lamprini A. Bartsioka", "Sokratis Nikolaidis", "Stylianos I. Venieris", "Dimitra I. Kaklamani", "Iakovos S. Venieris"], "title": "Dynamic Temporal Positional Encodings for Early Intrusion Detection in IoT", "comment": "Accepted at the 10th International Conference on Smart and\n  Sustainable Technologies (SpliTech 2025)", "summary": "The rapid expansion of the Internet of Things (IoT) has introduced\nsignificant security challenges, necessitating efficient and adaptive Intrusion\nDetection Systems (IDS). Traditional IDS models often overlook the temporal\ncharacteristics of network traffic, limiting their effectiveness in early\nthreat detection. We propose a Transformer-based Early Intrusion Detection\nSystem (EIDS) that incorporates dynamic temporal positional encodings to\nenhance detection accuracy while maintaining computational efficiency. By\nleveraging network flow timestamps, our approach captures both sequence\nstructure and timing irregularities indicative of malicious behaviour.\nAdditionally, we introduce a data augmentation pipeline to improve model\nrobustness. Evaluated on the CICIoT2023 dataset, our method outperforms\nexisting models in both accuracy and earliness. We further demonstrate its\nreal-time feasibility on resource-constrained IoT devices, achieving\nlow-latency inference and minimal memory footprint."}
{"id": "2506.18213", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18213", "abs": "https://arxiv.org/abs/2506.18213", "authors": ["MarÃ­a Victoria Carro", "Denise Alejandra Mester", "Francisca Gauna Selasco", "Luca NicolÃ¡s Forziati Gangi", "Matheo Sandleris Musa", "Lola Ramos Pereyra", "Mario Leiva", "Juan Gustavo Corvalan", "MarÃ­a Vanina Martinez", "Gerardo Simari"], "title": "A Conceptual Framework for AI Capability Evaluations", "comment": "arXiv admin note: text overlap with arXiv:2306.04181 by other authors", "summary": "As AI systems advance and integrate into society, well-designed and\ntransparent evaluations are becoming essential tools in AI governance,\ninforming decisions by providing evidence about system capabilities and risks.\nYet there remains a lack of clarity on how to perform these assessments both\ncomprehensively and reliably. To address this gap, we propose a conceptual\nframework for analyzing AI capability evaluations, offering a structured,\ndescriptive approach that systematizes the analysis of widely used methods and\nterminology without imposing new taxonomies or rigid formats. This framework\nsupports transparency, comparability, and interpretability across diverse\nevaluations. It also enables researchers to identify methodological weaknesses,\nassists practitioners in designing evaluations, and provides policymakers with\nan accessible tool to scrutinize, compare, and navigate complex evaluation\nlandscapes."}
{"id": "2506.18150", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.18150", "abs": "https://arxiv.org/abs/2506.18150", "authors": ["Karthik Garimella", "Austin Ebel", "Gabrielle De Micheli", "Brandon Reagen"], "title": "HE-LRM: Encrypted Deep Learning Recommendation Models using Fully Homomorphic Encryption", "comment": "14 pages, 10 figures, 2 tables", "summary": "Fully Homomorphic Encryption (FHE) is an encryption scheme that not only\nencrypts data but also allows for computations to be applied directly on the\nencrypted data. While computationally expensive, FHE can enable\nprivacy-preserving neural inference in the client-server setting: a client\nencrypts their input with FHE and sends it to an untrusted server. The server\nthen runs neural inference on the encrypted data and returns the encrypted\nresults. The client decrypts the output locally, keeping both the input and\nresult private from the server. Private inference has focused on networks with\ndense inputs such as image classification, and less attention has been given to\nnetworks with sparse features. Unlike dense inputs, sparse features require\nefficient encrypted lookup operations into large embedding tables, which\npresent computational and memory constraints for FHE.\n  In this paper, we explore the challenges and opportunities when applying FHE\nto Deep Learning Recommendation Models (DLRM) from both a compiler and systems\nperspective. DLRMs utilize conventional MLPs for dense features and embedding\ntables to map sparse, categorical features to dense vector representations. We\ndevelop novel methods for performing compressed embedding lookups in order to\nreduce FHE computational costs while keeping the underlying model performant.\nOur embedding lookup improves upon a state-of-the-art approach by $77 \\times$.\nFurthermore, we present an efficient multi-embedding packing strategy that\nenables us to perform a 44 million parameter embedding lookup under FHE.\nFinally, we integrate our solutions into the open-source Orion framework and\npresent HE-LRM, an end-to-end encrypted DLRM. We evaluate HE-LRM on UCI (health\nprediction) and Criteo (click prediction), demonstrating that with the right\ncompression and packing strategies, encrypted inference for recommendation\nsystems is practical."}
{"id": "2506.18233", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18233", "abs": "https://arxiv.org/abs/2506.18233", "authors": ["Ruike Zhu", "Hanwen Zhang", "Tianyu Shi", "Chi Wang", "Tianyi Zhou", "Zengyi Qin"], "title": "The 4th Dimension for Scaling Model Size", "comment": null, "summary": "Scaling the size of large language models typically involves three\ndimensions: depth, width, and the number of parameters. In this work, we\nexplore a fourth dimension, virtual logical depth (VLD), which increases the\neffective algorithmic depth without changing the overall parameter count by\nreusing parameters within the model. Although parameter reuse is not a new\nconcept, its potential and characteristics in model scaling have not been\nthoroughly studied. Through carefully designed controlled experiments, we make\nthe following key discoveries regarding VLD scaling:\n  VLD scaling forces the knowledge capacity of the model to remain almost\nconstant, with only minor variations.\n  VLD scaling enables a significant improvement in reasoning capability,\nprovided the scaling method is properly implemented.\n  The number of parameters correlates with knowledge capacity, but not with\nreasoning capability. Under certain conditions, it is not necessary to increase\nthe parameter count to enhance reasoning.\n  These findings are consistent across various model configurations and are\nlikely to be generally valid within the scope of our experiments."}
{"id": "2506.18189", "categories": ["cs.CR", "cs.CY", "C.2.4"], "pdf": "https://arxiv.org/pdf/2506.18189", "abs": "https://arxiv.org/abs/2506.18189", "authors": ["Maxwell Koegler"], "title": "SoK: Current State of Ethereum's Enshrined Proposer Builder Separation", "comment": "12 pages, 2 figures, submitted to The Science of Blockchain\n  Conference 2025", "summary": "Initially introduced to Ethereum via Flashbots' MEV-boost, Proposer-Builder\nSeparation allows proposers to auction off blockspace to a market of\ntransaction orderers, known as builders. PBS is currently available to\nvalidators through the aforementioned MEV-boost, but its unregulated and\nrelay-dependent nature has much of the Ethereum community calling for its\nenshrinement. Providing a protocol-integrated PBS marketspace and communication\nchannel for payload outsourcing is termed PBS enshrinement. Although ePBS\npotentially introduces native MEV mitigation mechanisms and reduces validator\noperation costs, fears of multiparty collusion and chain stagnation are all too\nreal. In addition to mitigating these potential drawbacks, PBS research pursues\nmany tenets revered by Web3 enthusiasts, including but not limited to,\ncensorship resistance, validator reward equity, and deflationary finance. The\nsubsequent SoK will identify current PBS mechanisms, the need for enshrinement,\nadditions to the ePBS upgrade, and the existing or potential on-chain\nsocioeconomic implications of each."}
{"id": "2506.18260", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18260", "abs": "https://arxiv.org/abs/2506.18260", "authors": ["FuTe Wong"], "title": "Advanced For-Loop for QML algorithm search", "comment": "7 pages, 8 figures", "summary": "This paper introduces an advanced framework leveraging Large Language\nModel-based Multi-Agent Systems (LLMMA) for the automated search and\noptimization of Quantum Machine Learning (QML) algorithms. Inspired by Google\nDeepMind's FunSearch, the proposed system works on abstract level to\niteratively generates and refines quantum transformations of classical machine\nlearning algorithms (concepts), such as the Multi-Layer Perceptron,\nforward-forward and backpropagation algorithms. As a proof of concept, this\nwork highlights the potential of agentic frameworks to systematically explore\nclassical machine learning concepts and adapt them for quantum computing,\npaving the way for efficient and automated development of QML algorithms.\nFuture directions include incorporating planning mechanisms and optimizing\nstrategy in the search space for broader applications in quantum-enhanced\nmachine learning."}
{"id": "2506.18203", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18203", "abs": "https://arxiv.org/abs/2506.18203", "authors": ["Jon Saad-Falcon", "E. Kelly Buchanan", "Mayee F. Chen", "Tzu-Heng Huang", "Brendan McLaughlin", "Tanvir Bhathal", "Shang Zhu", "Ben Athiwaratkun", "Frederic Sala", "Scott Linderman", "Azalia Mirhoseini", "Christopher RÃ©"], "title": "Shrinking the Generation-Verification Gap with Weak Verifiers", "comment": null, "summary": "Verifiers can improve language model capabilities by scoring and ranking\nresponses from generated candidates. Currently, high-quality verifiers are\neither unscalable (e.g., humans) or limited in utility (e.g., tools like Lean).\nWhile LM judges and reward models have become broadly useful as general-purpose\nverifiers, a significant performance gap remains between them and oracle\nverifiers (verifiers with perfect accuracy). To help close this gap, we\nintroduce Weaver, a framework for designing a strong verifier by combining\nmultiple weak, imperfect verifiers. We find weighted ensembles of verifiers,\nwhich typically require learning from labeled data, significantly outperform\nunweighted combinations due to differences in verifier accuracies. To reduce\ndependency on labeled data, Weaver leverages weak supervision to estimate each\nverifier's accuracy and combines outputs into a unified score that better\nreflects true response quality. However, directly applying weak supervision\nalgorithms poses challenges, including inconsistent verifier output formats and\nhandling low-quality verifiers. Weaver addresses these using dataset statistics\nto normalize outputs and filter specific verifiers. We study Weaver's\neffectiveness in test-time repeated sampling, where a model generates multiple\ncandidate responses and selects one. Our evaluations show Weaver significantly\nimproves over Pass@1-performance when selecting the first candidate-across\nreasoning and math tasks, achieving o3-mini-level accuracy with Llama 3.3 70B\nInstruct as generator, and an ensemble of 70B or smaller judge and reward\nmodels as verifiers (87.7% average). This gain mirrors the jump between GPT-4o\nand o3-mini (69.0% vs. 86.7%), which required extensive finetuning and\npost-training. To reduce computational costs of verifier ensembles, we train a\n400M cross-encoder using Weaver's combined output scores."}
{"id": "2506.18348", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18348", "abs": "https://arxiv.org/abs/2506.18348", "authors": ["Weilun Yu", "Shixiang Tang", "Yonggui Huang", "Nanqing Dong", "Li Fan", "Honggang Qi", "Wei Liu", "Xiaoli Diao", "Xi Chen", "Wanli Ouyang"], "title": "Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team", "comment": null, "summary": "Scientific progress increasingly relies on effective collaboration among\nresearchers, a dynamic that large language models (LLMs) have only begun to\nemulate. While recent LLM-based scientist agents show promise in autonomous\nscientific discovery, they often lack the interactive reasoning and evaluation\nmechanisms essential to real-world research. We propose IDVSCI (Internal\nDiscussion and Vote SCIentists), a multi-agent framework built on LLMs that\nincorporates two key innovations: a Dynamic Knowledge Exchange mechanism\nenabling iterative feedback among agents, and a Dual-Diversity Review paradigm\nthat simulates heterogeneous expert evaluation. These components jointly\npromote deeper reasoning and the generation of more creative and impactful\nscientific ideas. To evaluate the effectiveness and generalizability of our\napproach, we conduct experiments on two datasets: a widely used benchmark in\ncomputer science and a new dataset we introduce in the health sciences domain.\nResults show that IDVSCI consistently achieves the best performance across both\ndatasets, outperforming existing systems such as AI Scientist and VIRSCI. These\nfindings highlight the value of modeling interaction and peer review dynamics\nin LLM-based autonomous research."}
{"id": "2506.18245", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.18245", "abs": "https://arxiv.org/abs/2506.18245", "authors": ["Lei Yu", "Zhirong Huang", "Hang Yuan", "Shiqi Cheng", "Li Yang", "Fengjun Zhang", "Chenjie Shen", "Jiajia Ma", "Jingyuan Zhang", "Junyi Lu", "Chun Zuo"], "title": "Smart-LLaMA-DPO: Reinforced Large Language Model for Explainable Smart Contract Vulnerability Detection", "comment": "Accepted to ISSTA 2025", "summary": "Smart contract vulnerability detection remains a major challenge in\nblockchain security. Existing vulnerability detection methods face two main\nissues: (1) Existing datasets lack comprehensive coverage and high-quality\nexplanations for preference learning. (2) Large language models (LLMs) often\nstruggle with accurately interpreting specific concepts in smart contract\nsecurity. Empirical analysis shows that even after continual pre-training (CPT)\nand supervised fine-tuning (SFT), LLMs may misinterpret the execution order of\nstate changes, resulting in incorrect explanations despite making correct\ndetection decisions. To address these challenges, we propose Smart-LLaMA-DPO\nbased on LLaMA-3.1-8B. We construct a comprehensive dataset covering four major\nvulnerability types and machine-unauditable vulnerabilities, including precise\nlabels, explanations, and locations for SFT, as well as high-quality and\nlow-quality output pairs for Direct Preference Optimization (DPO). Second, we\nperform CPT using large-scale smart contract to enhance the LLM's understanding\nof specific security practices in smart contracts. Futhermore, we conduct SFT\nwith our comprehensive dataset. Finally, we apply DPO, leveraging human\nfeedback and a specially designed loss function that increases the probability\nof preferred explanations while reducing the likelihood of non-preferred\noutputs. We evaluate Smart-LLaMA-DPO on four major vulnerability types:\nreentrancy, timestamp dependence, integer overflow/underflow, and delegatecall,\nas well as machine-unauditable vulnerabilities. Our method significantly\noutperforms state-of-the-art baselines, with average improvements of 10.43% in\nF1 score and 7.87% in accuracy. Moreover, both LLM evaluation and human\nevaluation confirm that our method generates more correct, thorough, and clear\nexplanations."}
{"id": "2506.18424", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.18424", "abs": "https://arxiv.org/abs/2506.18424", "authors": ["Chengjie Liu", "Weiyu Chen", "Huiyao Xu", "Yuan Du", "Jun Yang", "Li Du"], "title": "A Large Language Model-based Multi-Agent Framework for Analog Circuits' Sizing Relationships Extraction", "comment": "Accepted by ISEDA 2025", "summary": "In the design process of the analog circuit pre-layout phase, device sizing\nis an important step in determining whether an analog circuit can meet the\nrequired performance metrics. Many existing techniques extract the circuit\nsizing task as a mathematical optimization problem to solve and continuously\nimprove the optimization efficiency from a mathematical perspective. But they\nignore the automatic introduction of prior knowledge, fail to achieve effective\npruning of the search space, which thereby leads to a considerable compression\nmargin remaining in the search space. To alleviate this problem, we propose a\nlarge language model (LLM)-based multi-agent framework for analog circuits'\nsizing relationships extraction from academic papers. The search space in the\nsizing process can be effectively pruned based on the sizing relationship\nextracted by this framework. Eventually, we conducted tests on 3 types of\ncircuits, and the optimization efficiency was improved by $2.32 \\sim 26.6\n\\times$. This work demonstrates that the LLM can effectively prune the search\nspace for analog circuit sizing, providing a new solution for the combination\nof LLMs and conventional analog circuit design automation methods."}
{"id": "2506.18462", "categories": ["cs.CR", "I.2"], "pdf": "https://arxiv.org/pdf/2506.18462", "abs": "https://arxiv.org/abs/2506.18462", "authors": ["Fatemeh Jalalvand", "Mohan Baruwal Chhetri", "Surya Nepal", "CÃ©cile Paris"], "title": "Adaptive alert prioritisation in security operations centres via learning to defer with human feedback", "comment": "No comment", "summary": "Alert prioritisation (AP) is crucial for security operations centres (SOCs)\nto manage the overwhelming volume of alerts and ensure timely detection and\nresponse to genuine threats, while minimising alert fatigue. Although\npredictive AI can process large alert volumes and identify known patterns, it\nstruggles with novel and evolving scenarios that demand contextual\nunderstanding and nuanced judgement. A promising solution is Human-AI teaming\n(HAT), which combines human expertise with AI's computational capabilities.\nLearning to Defer (L2D) operationalises HAT by enabling AI to \"defer\" uncertain\nor unfamiliar cases to human experts. However, traditional L2D models rely on\nstatic deferral policies that do not evolve with experience, limiting their\nability to learn from human feedback and adapt over time. To overcome this, we\nintroduce Learning to Defer with Human Feedback (L2DHF), an adaptive deferral\nframework that leverages Deep Reinforcement Learning from Human Feedback\n(DRLHF) to optimise deferral decisions. By dynamically incorporating human\nfeedback, L2DHF continuously improves AP accuracy and reduces unnecessary\ndeferrals, enhancing SOC effectiveness and easing analyst workload. Experiments\non two widely used benchmark datasets, UNSW-NB15 and CICIDS2017, demonstrate\nthat L2DHF significantly outperforms baseline models. Notably, it achieves\n13-16% higher AP accuracy for critical alerts on UNSW-NB15 and 60-67% on\nCICIDS2017. It also reduces misprioritisations, for example, by 98% for\nhigh-category alerts on CICIDS2017. Moreover, L2DHF decreases deferrals, for\nexample, by 37% on UNSW-NB15, directly reducing analyst workload. These gains\nare achieved with efficient execution, underscoring L2DHF's practicality for\nreal-world SOC deployment."}
{"id": "2506.18428", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.18428", "abs": "https://arxiv.org/abs/2506.18428", "authors": ["Feng He", "Zhenyang Liu", "Marco Valentino", "Zhixue Zhao"], "title": "How Robust is Model Editing after Fine-Tuning? An Empirical Study on Text-to-Image Diffusion Models", "comment": null, "summary": "Model editing offers a low-cost technique to inject or correct a particular\nbehavior in a pre-trained model without extensive retraining, supporting\napplications such as factual correction and bias mitigation. Despite this\ncommon practice, it remains unknown whether edits persist after fine-tuning or\nwhether they are inadvertently reversed. This question has fundamental\npractical implications. For example, if fine-tuning removes prior edits, it\ncould serve as a defence mechanism against hidden malicious edits. Vice versa,\nthe unintended removal of edits related to bias mitigation could pose serious\nsafety concerns. We systematically investigate the interaction between model\nediting and fine-tuning in the context of T2I diffusion models, which are known\nto exhibit biases and generate inappropriate content. Our study spans two T2I\nmodel families (Stable Diffusion and FLUX), two sota editing techniques, and\nthree fine-tuning methods (DreamBooth, LoRA, and DoRA). Through an extensive\nempirical analysis across diverse editing tasks and evaluation metrics, our\nfindings reveal a trend: edits generally fail to persist through fine-tuning,\neven when fine-tuning is tangential or unrelated to the edits. Notably, we\nobserve that DoRA exhibits the strongest edit reversal effect. At the same\ntime, among editing methods, UCE demonstrates greater robustness, retaining\nsignificantly higher efficacy post-fine-tuning compared to ReFACT. These\nfindings highlight a crucial limitation in current editing methodologies,\nemphasizing the need for more robust techniques to ensure reliable long-term\ncontrol and alignment of deployed AI systems. These findings have dual\nimplications for AI safety: they suggest that fine-tuning could serve as a\nremediation mechanism for malicious edits while simultaneously highlighting the\nneed for re-editing after fine-tuning to maintain beneficial safety and\nalignment properties."}
{"id": "2506.18470", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.18470", "abs": "https://arxiv.org/abs/2506.18470", "authors": ["Daniele Canavese", "Leonardo Regano", "Bjorn De Sutter", "Cataldo Basile"], "title": "Automatic Selection of Protections to Mitigate Risks Against Software Applications", "comment": null, "summary": "This paper introduces a novel approach for the automated selection of\nsoftware protections to mitigate MATE risks against critical assets within\nsoftware applications. We formalize the key elements involved in protection\ndecision-making - including code artifacts, assets, security requirements,\nattacks, and software protections - and frame the protection process through a\ngame-theoretic model. In this model, a defender strategically applies\nprotections to various code artifacts of a target application, anticipating\nrepeated attack attempts by adversaries against the confidentiality and\nintegrity of the application's assets. The selection of the optimal defense\nmaximizes resistance to attacks while ensuring the application remains usable\nby constraining the overhead introduced by protections. The game is solved\nthrough a heuristic based on a mini-max depth-first exploration strategy,\naugmented with dynamic programming optimizations for improved efficiency.\nCentral to our formulation is the introduction of the Software Protection\nIndex, an original contribution that extends existing notions of potency and\nresilience by evaluating protection effectiveness against attack paths using\nsoftware metrics and expert assessments. We validate our approach through a\nproof-of-concept implementation and expert evaluations, demonstrating that\nautomated software protection is a practical and effective solution for risk\nmitigation in software."}
{"id": "2506.18511", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18511", "abs": "https://arxiv.org/abs/2506.18511", "authors": ["Yu Han", "Aaron Ceross", "Jeroen H. M. Bergmann"], "title": "Standard Applicability Judgment and Cross-jurisdictional Reasoning: A RAG-based Framework for Medical Device Compliance", "comment": null, "summary": "Identifying the appropriate regulatory standard applicability remains a\ncritical yet understudied challenge in medical device compliance, frequently\nnecessitating expert interpretation of fragmented and heterogeneous\ndocumentation across different jurisdictions. To address this challenge, we\nintroduce a modular AI system that leverages a retrieval-augmented generation\n(RAG) pipeline to automate standard applicability determination. Given a\nfree-text device description, our system retrieves candidate standards from a\ncurated corpus and uses large language models to infer jurisdiction-specific\napplicability, classified as Mandatory, Recommended, or Not Applicable, with\ntraceable justifications. We construct an international benchmark dataset of\nmedical device descriptions with expert-annotated standard mappings, and\nevaluate our system against retrieval-only, zero-shot, and rule-based\nbaselines. The proposed approach attains a classification accuracy of 73% and a\nTop-5 retrieval recall of 87%, demonstrating its effectiveness in identifying\nrelevant regulatory standards. We introduce the first end-to-end system for\nstandard applicability reasoning, enabling scalable and interpretable\nAI-supported regulatory science. Notably, our region-aware RAG agent performs\ncross-jurisdictional reasoning between Chinese and U.S. standards, supporting\nconflict resolution and applicability justification across regulatory\nframeworks."}
{"id": "2506.18516", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.18516", "abs": "https://arxiv.org/abs/2506.18516", "authors": ["Francesco Marchiori", "Marco Alecci", "Luca Pajola", "Mauro Conti"], "title": "DUMB and DUMBer: Is Adversarial Training Worth It in the Real World?", "comment": "Accepted at ESORICS 2025", "summary": "Adversarial examples are small and often imperceptible perturbations crafted\nto fool machine learning models. These attacks seriously threaten the\nreliability of deep neural networks, especially in security-sensitive domains.\nEvasion attacks, a form of adversarial attack where input is modified at test\ntime to cause misclassification, are particularly insidious due to their\ntransferability: adversarial examples crafted against one model often fool\nother models as well. This property, known as adversarial transferability,\ncomplicates defense strategies since it enables black-box attacks to succeed\nwithout direct access to the victim model. While adversarial training is one of\nthe most widely adopted defense mechanisms, its effectiveness is typically\nevaluated on a narrow and homogeneous population of models. This limitation\nhinders the generalizability of empirical findings and restricts practical\nadoption.\n  In this work, we introduce DUMBer, an attack framework built on the\nfoundation of the DUMB (Dataset soUrces, Model architecture, and Balance)\nmethodology, to systematically evaluate the resilience of adversarially trained\nmodels. Our testbed spans multiple adversarial training techniques evaluated\nacross three diverse computer vision tasks, using a heterogeneous population of\nuniquely trained models to reflect real-world deployment variability. Our\nexperimental pipeline comprises over 130k evaluations spanning 13\nstate-of-the-art attack algorithms, allowing us to capture nuanced behaviors of\nadversarial training under varying threat models and dataset conditions. Our\nfindings offer practical, actionable insights for AI practitioners, identifying\nwhich defenses are most effective based on the model, dataset, and attacker\nsetup."}
{"id": "2506.18538", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18538", "abs": "https://arxiv.org/abs/2506.18538", "authors": ["Rifat Ara Shams", "Didar Zowghi", "Muneera Bano"], "title": "A Question Bank to Assess AI Inclusivity: Mapping out the Journey from Diversity Errors to Inclusion Excellence", "comment": null, "summary": "Ensuring diversity and inclusion (D&I) in artificial intelligence (AI) is\ncrucial for mitigating biases and promoting equitable decision-making. However,\nexisting AI risk assessment frameworks often overlook inclusivity, lacking\nstandardized tools to measure an AI system's alignment with D&I principles.\nThis paper introduces a structured AI inclusivity question bank, a\ncomprehensive set of 253 questions designed to evaluate AI inclusivity across\nfive pillars: Humans, Data, Process, System, and Governance. The development of\nthe question bank involved an iterative, multi-source approach, incorporating\ninsights from literature reviews, D&I guidelines, Responsible AI frameworks,\nand a simulated user study. The simulated evaluation, conducted with 70\nAI-generated personas related to different AI jobs, assessed the question\nbank's relevance and effectiveness for AI inclusivity across diverse roles and\napplication domains. The findings highlight the importance of integrating D&I\nprinciples into AI development workflows and governance structures. The\nquestion bank provides an actionable tool for researchers, practitioners, and\npolicymakers to systematically assess and enhance the inclusivity of AI\nsystems, paving the way for more equitable and responsible AI technologies."}
{"id": "2506.18543", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18543", "abs": "https://arxiv.org/abs/2506.18543", "authors": ["Xiaodong Wu", "Xiangman Li", "Jianbing Ni"], "title": "Security Assessment of DeepSeek and GPT Series Models against Jailbreak Attacks", "comment": null, "summary": "The widespread deployment of large language models (LLMs) has raised critical\nconcerns over their vulnerability to jailbreak attacks, i.e., adversarial\nprompts that bypass alignment mechanisms and elicit harmful or policy-violating\noutputs. While proprietary models like GPT-4 have undergone extensive\nevaluation, the robustness of emerging open-source alternatives such as\nDeepSeek remains largely underexplored, despite their growing adoption in\nreal-world applications. In this paper, we present the first systematic\njailbreak evaluation of DeepSeek-series models, comparing them with GPT-3.5 and\nGPT-4 using the HarmBench benchmark. We evaluate seven representative attack\nstrategies across 510 harmful behaviors categorized by both function and\nsemantic domain. Our analysis reveals that DeepSeek's Mixture-of-Experts (MoE)\narchitecture introduces routing sparsity that offers selective robustness\nagainst optimization-based attacks such as TAP-T, but leads to significantly\nhigher vulnerability under prompt-based and manually engineered attacks. In\ncontrast, GPT-4 Turbo demonstrates stronger and more consistent safety\nalignment across diverse behaviors, likely due to its dense Transformer design\nand reinforcement learning from human feedback. Fine-grained behavioral\nanalysis and case studies further show that DeepSeek often routes adversarial\nprompts to under-aligned expert modules, resulting in inconsistent refusal\nbehaviors. These findings highlight a fundamental trade-off between\narchitectural efficiency and alignment generalization, emphasizing the need for\ntargeted safety tuning and modular alignment strategies to ensure secure\ndeployment of open-source LLMs."}
{"id": "2506.18559", "categories": ["cs.AI", "cs.LO", "I.2.7; F.4.1"], "pdf": "https://arxiv.org/pdf/2506.18559", "abs": "https://arxiv.org/abs/2506.18559", "authors": ["Hong Qing Yu"], "title": "T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent", "comment": null, "summary": "Large language models excel at generating fluent text but frequently struggle\nwith structured reasoning involving temporal constraints, causal relationships,\nand probabilistic reasoning. To address these limitations, we propose Temporal\nCausal Probabilistic Description Logic (T-CPDL), an integrated framework that\nextends traditional Description Logic with temporal interval operators,\nexplicit causal relationships, and probabilistic annotations. We present two\ndistinct variants of T-CPDL: one capturing qualitative temporal relationships\nthrough Allen's interval algebra, and another variant enriched with explicit\ntimestamped causal assertions. Both variants share a unified logical structure,\nenabling complex reasoning tasks ranging from simple temporal ordering to\nnuanced probabilistic causation. Empirical evaluations on temporal reasoning\nand causal inference benchmarks confirm that T-CPDL substantially improves\ninference accuracy, interpretability, and confidence calibration of language\nmodel outputs. By delivering transparent reasoning paths and fine-grained\ntemporal and causal semantics, T-CPDL significantly enhances the capability of\nlanguage models to support robust, explainable, and trustworthy\ndecision-making. This work also lays the groundwork for developing advanced\nLogic-Retrieval-Augmented Generation (Logic-RAG) frameworks, potentially\nboosting the reasoning capabilities and efficiency of knowledge graph-enhanced\nRAG systems."}
{"id": "2506.18685", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.18685", "abs": "https://arxiv.org/abs/2506.18685", "authors": ["Yara SchÃ¼tt", "Esfandiar Mohammadi"], "title": "Understanding the Theoretical Guarantees of DPM", "comment": null, "summary": "In this study, we conducted an in-depth examination of the utility analysis\nof the differentially private mechanism (DPM). The authors of DPM have already\nestablished the probability of a good split being selected and of DPM halting.\nIn this study, we expanded the analysis of the stopping criterion and provided\nan interpretation of these guarantees in the context of realistic input\ndistributions. Our findings revealed constraints on the minimum cluster size\nand the metric weight for the scoring function. Furthermore, we introduced an\ninterpretation of the utility of DPM through the lens of the clustering metric,\nthe silhouette score. Our findings indicate that even when an optimal DPM-based\nsplit is employed, the silhouette score of the resulting clustering may still\ndecline. This observation calls into question the suitability of the silhouette\nscore as a clustering metric. Finally, we examined the potential of the\nunderlying concept of DPM by linking it to a more theoretical view, that of\n$(\\xi, \\rho)$-separability. This extensive analysis of the theoretical\nguarantees of DPM allows a better understanding of its behaviour for arbitrary\ninputs. From these guarantees, we can analyse the impact of different\nhyperparameters and different input data sets, thereby promoting the\napplication of DPM in practice for unknown settings and data sets."}
{"id": "2506.18586", "categories": ["cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18586", "abs": "https://arxiv.org/abs/2506.18586", "authors": ["Zijie Yang", "Qiji Zhou", "Fang Guo", "Sijie Zhang", "Yexun Xi", "Jinglei Nie", "Yudian Zhu", "Liping Huang", "Chou Wu", "Yonghe Xia", "Xiaoyu Ma", "Yingming Pu", "Panzhong Lu", "Junshu Pan", "Mingtao Chen", "Tiannan Guo", "Yanmei Dou", "Hongyu Chen", "Anping Zeng", "Jiaxing Huang", "Tian Xu", "Yue Zhang"], "title": "Airalogy: AI-empowered universal data digitization for research automation", "comment": "146 pages, 6 figures, 49 supplementary figures", "summary": "Research data are the foundation of Artificial Intelligence (AI)-driven\nscience, yet current AI applications remain limited to a few fields with\nreadily available, well-structured, digitized datasets. Achieving comprehensive\nAI empowerment across multiple disciplines is still out of reach. Present-day\nresearch data collection is often fragmented, lacking unified standards,\ninefficiently managed, and difficult to share. Creating a single platform for\nstandardized data digitization needs to overcome the inherent challenge of\nbalancing between universality (supporting the diverse, ever-evolving needs of\nvarious disciplines) and standardization (enforcing consistent formats to fully\nenable AI). No existing platform accommodates both facets. Building a truly\nmultidisciplinary platform requires integrating scientific domain knowledge\nwith sophisticated computing skills. Researchers often lack the computational\nexpertise to design customized and standardized data recording methods, whereas\nplatform developers rarely grasp the intricate needs of multiple scientific\ndomains. These gaps impede research data standardization and hamper AI-driven\nprogress. In this study, we address these challenges by developing Airalogy\n(https://airalogy.com), the world's first AI- and community-driven platform\nthat balances universality and standardization for digitizing research data\nacross multiple disciplines. Airalogy represents entire research workflows\nusing customizable, standardized data records and offers an advanced AI\nresearch copilot for intelligent Q&A, automated data entry, analysis, and\nresearch automation. Already deployed in laboratories across all four schools\nof Westlake University, Airalogy has the potential to accelerate and automate\nscientific innovation in universities, industry, and the global research\ncommunity-ultimately benefiting humanity as a whole."}
{"id": "2506.18715", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.18715", "abs": "https://arxiv.org/abs/2506.18715", "authors": ["Stefano Perone", "Simone Guarino", "Luca Faramondi", "Roberto Setola"], "title": "Vulnerability Assessment Combining CVSS Temporal Metrics and Bayesian Networks", "comment": "This paper has been accepted for the 2025 IEEE International\n  Conference on Cyber Security and Resilience (CSR), Chania, Crete, Greece,\n  August 4-6 2025", "summary": "Vulnerability assessment is a critical challenge in cybersecurity,\nparticularly in industrial environments. This work presents an innovative\napproach by incorporating the temporal dimension into vulnerability assessment,\nan aspect neglected in existing literature. Specifically, this paper focuses on\nrefining vulnerability assessment and prioritization by integrating Common\nVulnerability Scoring System (CVSS) Temporal Metrics with Bayesian Networks to\naccount for exploit availability, remediation efforts, and confidence in\nreported vulnerabilities. Through probabilistic modeling, Bayesian networks\nenable a structured and adaptive evaluation of vulnerabilities, allowing for\nmore accurate prioritization and decision-making. The proposed approach\ndynamically computes the Temporal Score and updates the CVSS Base Score by\nprocessing data on exploits and fixes from vulnerability databases."}
{"id": "2506.18628", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18628", "abs": "https://arxiv.org/abs/2506.18628", "authors": ["Piotr Matys", "Jan Eliasz", "Konrad KieÅczyÅski", "MikoÅaj Langner", "Teddy Ferdinan", "Jan KocoÅ", "PrzemysÅaw Kazienko"], "title": "AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs", "comment": "ICCS 2025 Workshops", "summary": "In real-world applications, Large Language Models (LLMs) often hallucinate,\neven in Retrieval-Augmented Generation (RAG) settings, which poses a\nsignificant challenge to their deployment. In this paper, we introduce\nAggTruth, a method for online detection of contextual hallucinations by\nanalyzing the distribution of internal attention scores in the provided context\n(passage). Specifically, we propose four different variants of the method, each\nvarying in the aggregation technique used to calculate attention scores. Across\nall LLMs examined, AggTruth demonstrated stable performance in both same-task\nand cross-task setups, outperforming the current SOTA in multiple scenarios.\nFurthermore, we conducted an in-depth analysis of feature selection techniques\nand examined how the number of selected attention heads impacts detection\nperformance, demonstrating that careful selection of heads is essential to\nachieve optimal results."}
{"id": "2506.18767", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.18767", "abs": "https://arxiv.org/abs/2506.18767", "authors": ["Yifan Zhang", "Yongchao Dang", "Masoud Kaveh", "Zheng Yan", "Riku JÃ¤ntti", "Zhu Han"], "title": "Physical Layer Challenge-Response Authentication between Ambient Backscatter Devices", "comment": null, "summary": "Ambient backscatter communication (AmBC) has become an integral part of\nubiquitous Internet of Things (IoT) applications due to its energy-harvesting\ncapabilities and ultra-low-power consumption. However, the open wireless\nenvironment exposes AmBC systems to various attacks, and existing\nauthentication methods cannot be implemented between resource-constrained\nbackscatter devices (BDs) due to their high computational demands.To this end,\nthis paper proposes PLCRA-BD, a novel physical layer challenge-response\nauthentication scheme between BDs in AmBC that overcomes BDs' limitations,\nsupports high mobility, and performs robustly against impersonation and\nwireless attacks. It constructs embedded keys as physical layer fingerprints\nfor lightweight identification and designs a joint transceiver that integrates\nBDs' backscatter waveform with receiver functionality to mitigate interference\nfrom ambient RF signals by exploiting repeated patterns in OFDM symbols. Based\non this, a challenge-response authentication procedure is introduced to enable\nlow-complexity fingerprint exchange between two paired BDs leveraging channel\ncoherence, while securing the exchange process using a random number and\nunpredictable channel fading. Additionally, we optimize the authentication\nprocedure for high-mobility scenarios, completing exchanges within the channel\ncoherence time to minimize the impact of dynamic channel fluctuations. Security\nanalysis confirms its resistance against impersonation, eavesdropping, replay,\nand counterfeiting attacks. Extensive simulations validate its effectiveness in\nresource-constrained BDs, demonstrating high authentication accuracy across\ndiverse channel conditions, robustness against multiple wireless attacks, and\nsuperior efficiency compared to traditional authentication schemes."}
{"id": "2506.18651", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18651", "abs": "https://arxiv.org/abs/2506.18651", "authors": ["Shuocun Yang", "Huawen Hu", "Enze Shi", "Shu Zhang"], "title": "Dual-level Behavioral Consistency for Inter-group and Intra-group Coordination in Multi-Agent Systems", "comment": null, "summary": "Behavioral diversity in Multi-agent reinforcement learning(MARL) represents\nan emerging and promising research area. Prior work has largely centered on\nintra-group behavioral consistency in multi-agent systems, with limited\nattention given to behavioral consistency in multi-agent grouping scenarios. In\nthis paper, we introduce Dual-Level Behavioral Consistency (DLBC), a novel MARL\ncontrol method designed to explicitly regulate agent behaviors at both\nintra-group and inter-group levels. DLBC partitions agents into distinct groups\nand dynamically modulates behavioral diversity both within and between these\ngroups. By dynamically modulating behavioral diversity within and between these\ngroups, DLBC achieves enhanced division of labor through inter-group\nconsistency, which constrains behavioral strategies across different groups.\nSimultaneously, intra-group consistency, achieved by aligning behavioral\nstrategies within each group, fosters stronger intra-group cooperation.\nCrucially, DLBC's direct constraint of agent policy functions ensures its broad\napplicability across various algorithmic frameworks. Experimental results in\nvarious grouping cooperation scenarios demonstrate that DLBC significantly\nenhances both intra-group cooperative performance and inter-group task\nspecialization, yielding substantial performance improvements. DLBC provides\nnew ideas for behavioral consistency control of multi-intelligent body systems,\nand its potential for application in more complex tasks and dynamic\nenvironments can be further explored in the future."}
{"id": "2506.18780", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2506.18780", "abs": "https://arxiv.org/abs/2506.18780", "authors": ["Shuangbao Paul Wang"], "title": "Design high-confidence computers using trusted instructional set architecture and emulators", "comment": null, "summary": "High-confidence computing relies on trusted instructional set architecture,\nsealed kernels, and secure operating systems. Cloud computing depends on\ntrusted systems for virtualization tasks. Branch predictions and pipelines are\nessential in improving performance of a CPU/GPU. But Spectre and Meltdown make\nmodern processors vulnerable to be exploited. Disabling the prediction and\npipeline is definitely not a good solution. On the other hand, current software\npatches can only address non-essential issues around Meltdown. This paper\nintroduces a holistic approach in trusted computer architecture design and\nemulation."}
{"id": "2506.18777", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.18777", "abs": "https://arxiv.org/abs/2506.18777", "authors": ["Jonathan Cook", "Silvia Sapora", "Arash Ahmadian", "Akbir Khan", "Tim Rocktaschel", "Jakob Foerster", "Laura Ruis"], "title": "Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training", "comment": null, "summary": "Training large language models (LLMs) on source code significantly enhances\ntheir general-purpose reasoning abilities, but the mechanisms underlying this\ngeneralisation are poorly understood. In this paper, we propose Programming by\nBackprop (PBB) as a potential driver of this effect - teaching a model to\nevaluate a program for inputs by training on its source code alone, without\never seeing I/O examples. To explore this idea, we finetune LLMs on two sets of\nprograms representing simple maths problems and algorithms: one with source\ncode and I/O examples (w/ IO), the other with source code only (w/o IO). We\nfind evidence that LLMs have some ability to evaluate w/o IO programs for\ninputs in a range of experimental settings, and make several observations.\nFirstly, PBB works significantly better when programs are provided as code\nrather than semantically equivalent language descriptions. Secondly, LLMs can\nproduce outputs for w/o IO programs directly, by implicitly evaluating the\nprogram within the forward pass, and more reliably when stepping through the\nprogram in-context via chain-of-thought. We further show that PBB leads to more\nrobust evaluation of programs across inputs than training on I/O pairs drawn\nfrom a distribution that mirrors naturally occurring data. Our findings suggest\na mechanism for enhanced reasoning through code training: it allows LLMs to\ninternalise reusable algorithmic abstractions. Significant scope remains for\nfuture work to enable LLMs to more effectively learn from symbolic procedures,\nand progress in this direction opens other avenues like model alignment by\ntraining on formal constitutional principles."}
{"id": "2506.18795", "categories": ["cs.CR", "cs.SE", "D.2.4; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.18795", "abs": "https://arxiv.org/abs/2506.18795", "authors": ["Jiachi Chen", "Yiming Shen", "Jiashuo Zhang", "Zihao Li", "John Grundy", "Zhenzhe Shao", "Yanlin Wang", "Jiashui Wang", "Ting Chen", "Zibin Zheng"], "title": "FORGE: An LLM-driven Framework for Large-Scale Smart Contract Vulnerability Dataset Construction", "comment": "Accepted for the 48th International Conference on Software\n  Engineering (ICSE 2026)", "summary": "High-quality smart contract vulnerability datasets are critical for\nevaluating security tools and advancing smart contract security research. Two\nmajor limitations of current manual dataset construction are (1)\nlabor-intensive and error-prone annotation processes limiting the scale,\nquality, and evolution of the dataset, and (2) absence of standardized\nclassification rules results in inconsistent vulnerability categories and\nlabeling results across different datasets. To address these limitations, we\npresent FORGE, the first automated approach for constructing smart contract\nvulnerability datasets. FORGE leverages an LLM-driven pipeline to extract\nhigh-quality vulnerabilities from real-world audit reports and classify them\naccording to the CWE, the most widely recognized classification in software\nsecurity. FORGE employs a divide-and-conquer strategy to extract structured and\nself-contained vulnerability information from these reports. Additionally, it\nuses a tree-of-thoughts technique to classify the vulnerability information\ninto the hierarchical CWE classification. To evaluate FORGE's effectiveness, we\nrun FORGE on 6,454 real-world audit reports and generate a dataset comprising\n81,390 solidity files and 27,497 vulnerability findings across 296 CWE\ncategories. Manual assessment of the dataset demonstrates high extraction\nprecision and classification consistency with human experts (precision of 95.6%\nand inter-rater agreement k-$\\alpha$ of 0.87). We further validate the\npracticality of our dataset by benchmarking 13 existing security tools on our\ndataset. The results reveal the significant limitations in current detection\ncapabilities. Furthermore, by analyzing the severity-frequency distribution\npatterns through a unified CWE perspective in our dataset, we highlight\ninconsistency between current smart contract research focus and priorities\nidentified from real-world vulnerabilities..."}
{"id": "2506.18783", "categories": ["cs.AI", "cs.MA", "68T07", "I.2.11; I.2.7; I.2.8"], "pdf": "https://arxiv.org/pdf/2506.18783", "abs": "https://arxiv.org/abs/2506.18783", "authors": ["Kamil Szczepanik", "JarosÅaw A. Chudziak"], "title": "TRIZ Agents: A Multi-Agent LLM Approach for TRIZ-Based Innovation", "comment": "12 pages, 10 figures, 2 tables, Accepted at the 17th International\n  Conference on Agents and Artificial Intelligence (ICAART 2025). Final version\n  published in Proceedings of ICAART 2025 (Vol. 1), pages 196-207", "summary": "TRIZ, the Theory of Inventive Problem Solving, is a structured,\nknowledge-based framework for innovation and abstracting problems to find\ninventive solutions. However, its application is often limited by the\ncomplexity and deep interdisciplinary knowledge required. Advancements in Large\nLanguage Models (LLMs) have revealed new possibilities for automating parts of\nthis process. While previous studies have explored single LLMs in TRIZ\napplications, this paper introduces a multi-agent approach. We propose an\nLLM-based multi-agent system, called TRIZ agents, each with specialized\ncapabilities and tool access, collaboratively solving inventive problems based\non the TRIZ methodology. This multi-agent system leverages agents with various\ndomain expertise to efficiently navigate TRIZ steps. The aim is to model and\nsimulate an inventive process with language agents. We assess the effectiveness\nof this team of agents in addressing complex innovation challenges based on a\nselected case study in engineering. We demonstrate the potential of agent\ncollaboration to produce diverse, inventive solutions. This research\ncontributes to the future of AI-driven innovation, showcasing the advantages of\ndecentralized problem-solving in complex ideation tasks."}
{"id": "2506.18848", "categories": ["cs.CR", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2506.18848", "abs": "https://arxiv.org/abs/2506.18848", "authors": ["Sara D. Cardell"], "title": "Cellular Automata as Generators of Interleaving Sequences", "comment": null, "summary": "An interleaving sequence is obtained by combining or intertwining elements\nfrom two or more sequences. On the other hand, cellular automata are known to\nbe generators for keystream sequences. In this paper we present two families of\none-dimensional cellular automata as generators of interleaving sequences. This\nstudy aims to close a notable gap within the current body of literature by\nexploring the capacity of cellular automata to generate interleaving sequences.\nWhile previous works have separately examined cellular automata as sequence\ngenerators and interleaving sequences, there exists limited literature\ninterconnecting these two topics. Our study seeks to bridge this gap, providing\nperspectives on the generation of interleaving sequences through the\nutilisation of cellular automata, thereby fostering a deeper understanding of\nboth disciplines."}
{"id": "2506.18810", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.18810", "abs": "https://arxiv.org/abs/2506.18810", "authors": ["Siao Tang", "Xinyin Ma", "Gongfan Fang", "Xinchao Wang"], "title": "ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation", "comment": "Codes are available at https://github.com/tsa18/ConciseHint", "summary": "Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and\nOpenAI o1 series have achieved notable performance enhancements on complex\nreasoning tasks by scaling up the generation length by Chain-of-Thought (CoT).\nHowever, an emerging issue is their inclination to produce excessively verbose\nreasoning processes, leading to the inefficiency problem. Existing literature\non improving efficiency mainly adheres to the before-reasoning paradigms such\nas prompting and reasoning or fine-tuning and reasoning, but ignores the\npromising direction of directly encouraging the model to speak concisely by\nintervening during the generation of reasoning. In order to fill the blank, we\npropose a framework dubbed ConciseHint, which continuously encourages the\nreasoning model to speak concisely by injecting the textual hint (manually\ndesigned or trained on the concise data) during the token generation of the\nreasoning process. Besides, ConciseHint is adaptive to the complexity of the\nquery by adaptively adjusting the hint intensity, which ensures it will not\nundermine model performance. Experiments on the state-of-the-art LRMs,\nincluding DeepSeek-R1 and Qwen-3 series, demonstrate that our method can\neffectively produce concise reasoning processes while maintaining performance\nwell. For instance, we achieve a reduction ratio of 65\\% for the reasoning\nlength on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss."}
{"id": "2506.18870", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.18870", "abs": "https://arxiv.org/abs/2506.18870", "authors": ["Yugeng Liu", "Zheng Li", "Hai Huang", "Michael Backes", "Yang Zhang"], "title": "Amplifying Machine Learning Attacks Through Strategic Compositions", "comment": null, "summary": "Machine learning (ML) models are proving to be vulnerable to a variety of\nattacks that allow the adversary to learn sensitive information, cause\nmispredictions, and more. While these attacks have been extensively studied,\ncurrent research predominantly focuses on analyzing each attack type\nindividually. In practice, however, adversaries may employ multiple attack\nstrategies simultaneously rather than relying on a single approach. This\nprompts a crucial yet underexplored question: When the adversary has multiple\nattacks at their disposal, are they able to mount or amplify the effect of one\nattack with another? In this paper, we take the first step in studying the\nstrategic interactions among different attacks, which we define as attack\ncompositions. Specifically, we focus on four well-studied attacks during the\nmodel's inference phase: adversarial examples, attribute inference, membership\ninference, and property inference. To facilitate the study of their\ninteractions, we propose a taxonomy based on three stages of the attack\npipeline: preparation, execution, and evaluation. Using this taxonomy, we\nidentify four effective attack compositions, such as property inference\nassisting attribute inference at its preparation level and adversarial examples\nassisting property inference at its execution level. We conduct extensive\nexperiments on the attack compositions using three ML model architectures and\nthree benchmark image datasets. Empirical results demonstrate the effectiveness\nof these four attack compositions. We implement and release a modular reusable\ntoolkit, COAT. Arguably, our work serves as a call for researchers and\npractitioners to consider advanced adversarial settings involving multiple\nattack strategies, aiming to strengthen the security and robustness of AI\nsystems."}
{"id": "2506.18887", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY", "I.2.7; I.2.6; I.2.1; D.3.3; C.4"], "pdf": "https://arxiv.org/pdf/2506.18887", "abs": "https://arxiv.org/abs/2506.18887", "authors": ["Vansh Sharma", "Venkat Raman"], "title": "Steering Conceptual Bias via Transformer Latent-Subspace Activation", "comment": null, "summary": "This work examines whether activating latent subspaces in language models\n(LLMs) can steer scientific code generation toward a specific programming\nlanguage. Five causal LLMs were first evaluated on scientific coding prompts to\nquantify their baseline bias among four programming languages. A static\nneuron-attribution method, perturbing the highest activated MLP weight for a\nC++ or CPP token, proved brittle and exhibited limited generalization across\nprompt styles and model scales. To address these limitations, a\ngradient-refined adaptive activation steering framework (G-ACT) was developed:\nper-prompt activation differences are clustered into a small set of steering\ndirections, and lightweight per-layer probes are trained and refined online to\nselect the appropriate steering vector. In LLaMA-3.2 3B, this approach reliably\nbiases generation towards the CPP language by increasing the average probe\nclassification accuracy by 15% and the early layers (0-6) improving the probe\nclassification accuracy by 61.5% compared to the standard ACT framework. For\nLLaMA-3.3 70B, where attention-head signals become more diffuse, targeted\ninjections at key layers still improve language selection. Although per-layer\nprobing introduces a modest inference overhead, it remains practical by\nsteering only a subset of layers and enables reproducible model behavior. These\nresults demonstrate a scalable, interpretable and efficient mechanism for\nconcept-level control for practical agentic systems."}
{"id": "2506.18902", "categories": ["cs.AI", "cs.CL", "cs.IR", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2506.18902", "abs": "https://arxiv.org/abs/2506.18902", "authors": ["Michael GÃ¼nther", "Saba Sturua", "Mohammad Kalim Akram", "Isabelle Mohr", "Andrei Ungureanu", "Sedigheh Eslami", "Scott Martens", "Bo Wang", "Nan Wang", "Han Xiao"], "title": "jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval", "comment": "22 pages, 1-10 main, 14-22 experimental results, benchmark tables", "summary": "We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding\nmodel that unifies text and image representations through a novel architecture\nsupporting both single-vector and multi-vector embeddings in the late\ninteraction style. The model incorporates task-specific Low-Rank Adaptation\n(LoRA) adapters to optimize performance across diverse retrieval scenarios,\nincluding query-based information retrieval, cross-modal semantic similarity,\nand programming code search. Comprehensive evaluations demonstrate that\njina-embeddings-v4 achieves state-of-the-art performance on both single- modal\nand cross-modal retrieval tasks, with particular strength in processing\nvisually rich content such as tables, charts, diagrams, and mixed-media\nformats. To facilitate evaluation of this capability, we also introduce\nJina-VDR, a novel benchmark specifically designed for visually rich image\nretrieval."}
{"id": "2506.17279", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17279", "abs": "https://arxiv.org/abs/2506.17279", "authors": ["Yash Sinha", "Manit Baser", "Murari Mandal", "Dinil Mon Divakaran", "Mohan Kankanhalli"], "title": "Step-by-Step Reasoning Attack: Revealing 'Erased' Knowledge in Large Language Models", "comment": null, "summary": "Knowledge erasure in large language models (LLMs) is important for ensuring\ncompliance with data and AI regulations, safeguarding user privacy, mitigating\nbias, and misinformation. Existing unlearning methods aim to make the process\nof knowledge erasure more efficient and effective by removing specific\nknowledge while preserving overall model performance, especially for retained\ninformation. However, it has been observed that the unlearning techniques tend\nto suppress and leave the knowledge beneath the surface, thus making it\nretrievable with the right prompts. In this work, we demonstrate that\n\\textit{step-by-step reasoning} can serve as a backdoor to recover this hidden\ninformation. We introduce a step-by-step reasoning-based black-box attack,\nSleek, that systematically exposes unlearning failures. We employ a structured\nattack framework with three core components: (1) an adversarial prompt\ngeneration strategy leveraging step-by-step reasoning built from LLM-generated\nqueries, (2) an attack mechanism that successfully recalls erased content, and\nexposes unfair suppression of knowledge intended for retention and (3) a\ncategorization of prompts as direct, indirect, and implied, to identify which\nquery types most effectively exploit unlearning weaknesses. Through extensive\nevaluations on four state-of-the-art unlearning techniques and two widely used\nLLMs, we show that existing approaches fail to ensure reliable knowledge\nremoval. Of the generated adversarial prompts, 62.5% successfully retrieved\nforgotten Harry Potter facts from WHP-unlearned Llama, while 50% exposed unfair\nsuppression of retained knowledge. Our work highlights the persistent risks of\ninformation leakage, emphasizing the need for more robust unlearning strategies\nfor erasure."}
{"id": "2506.17292", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17292", "abs": "https://arxiv.org/abs/2506.17292", "authors": ["Quan Nguyen", "Minh N. Vu", "Truc Nguyen", "My T. Thai"], "title": "Theoretically Unmasking Inference Attacks Against LDP-Protected Clients in Federated Vision Models", "comment": "Accepted to ICML 2025", "summary": "Federated Learning enables collaborative learning among clients via a\ncoordinating server while avoiding direct data sharing, offering a perceived\nsolution to preserve privacy. However, recent studies on Membership Inference\nAttacks (MIAs) have challenged this notion, showing high success rates against\nunprotected training data. While local differential privacy (LDP) is widely\nregarded as a gold standard for privacy protection in data analysis, most\nstudies on MIAs either neglect LDP or fail to provide theoretical guarantees\nfor attack success rates against LDP-protected data. To address this gap, we\nderive theoretical lower bounds for the success rates of low-polynomial time\nMIAs that exploit vulnerabilities in fully connected or self-attention layers.\nWe establish that even when data are protected by LDP, privacy risks persist,\ndepending on the privacy budget. Practical evaluations on federated vision\nmodels confirm considerable privacy risks, revealing that the noise required to\nmitigate these attacks significantly degrades models' utility."}
{"id": "2506.17299", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17299", "abs": "https://arxiv.org/abs/2506.17299", "authors": ["Shuyi Lin", "Anshuman Suri", "Alina Oprea", "Cheng Tan"], "title": "LLM Jailbreak Oracle", "comment": null, "summary": "As large language models (LLMs) become increasingly deployed in\nsafety-critical applications, the lack of systematic methods to assess their\nvulnerability to jailbreak attacks presents a critical security gap. We\nintroduce the jailbreak oracle problem: given a model, prompt, and decoding\nstrategy, determine whether a jailbreak response can be generated with\nlikelihood exceeding a specified threshold. This formalization enables a\nprincipled study of jailbreak vulnerabilities. Answering the jailbreak oracle\nproblem poses significant computational challenges -- the search space grows\nexponentially with the length of the response tokens. We present Boa, the first\nefficient algorithm for solving the jailbreak oracle problem. Boa employs a\nthree-phase search strategy: (1) constructing block lists to identify refusal\npatterns, (2) breadth-first sampling to identify easily accessible jailbreaks,\nand (3) depth-first priority search guided by fine-grained safety scores to\nsystematically explore promising low-probability paths. Boa enables rigorous\nsecurity assessments including systematic defense evaluation, standardized\ncomparison of red team attacks, and model certification under extreme\nadversarial conditions."}
{"id": "2506.17318", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17318", "abs": "https://arxiv.org/abs/2506.17318", "authors": ["Atharv Singh Patlan", "Ashwin Hebbar", "Pramod Viswanath", "Prateek Mittal"], "title": "Context manipulation attacks : Web agents are susceptible to corrupted memory", "comment": "10 pages, 6 figures", "summary": "Autonomous web navigation agents, which translate natural language\ninstructions into sequences of browser actions, are increasingly deployed for\ncomplex tasks across e-commerce, information retrieval, and content discovery.\nDue to the stateless nature of large language models (LLMs), these agents rely\nheavily on external memory systems to maintain context across interactions.\nUnlike centralized systems where context is securely stored server-side, agent\nmemory is often managed client-side or by third-party applications, creating\nsignificant security vulnerabilities. This was recently exploited to attack\nproduction systems.\n  We introduce and formalize \"plan injection,\" a novel context manipulation\nattack that corrupts these agents' internal task representations by targeting\nthis vulnerable context. Through systematic evaluation of two popular web\nagents, Browser-use and Agent-E, we show that plan injections bypass robust\nprompt injection defenses, achieving up to 3x higher attack success rates than\ncomparable prompt-based attacks. Furthermore, \"context-chained injections,\"\nwhich craft logical bridges between legitimate user goals and attacker\nobjectives, lead to a 17.7% increase in success rate for privacy exfiltration\ntasks. Our findings highlight that secure memory handling must be a first-class\nconcern in agentic systems."}
{"id": "2506.17329", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17329", "abs": "https://arxiv.org/abs/2506.17329", "authors": ["Pedro H. Lui", "Lucas P. Siqueira", "Juliano F. Kazienko", "Vagner E. Quincozes", "Silvio E. Quincozes", "Daniel Welfer"], "title": "On the Performance of Cyber-Biomedical Features for Intrusion Detection in Healthcare 5.0", "comment": "12 pages, 7 figures, conference", "summary": "Healthcare 5.0 integrates Artificial Intelligence (AI), the Internet of\nThings (IoT), real-time monitoring, and human-centered design toward\npersonalized medicine and predictive diagnostics. However, the increasing\nreliance on interconnected medical technologies exposes them to cyber threats.\nMeanwhile, current AI-driven cybersecurity models often neglect biomedical\ndata, limiting their effectiveness and interpretability. This study addresses\nthis gap by applying eXplainable AI (XAI) to a Healthcare 5.0 dataset that\nintegrates network traffic and biomedical sensor data. Classification outputs\nindicate that XGBoost achieved 99% F1-score for benign and data alteration, and\n81% for spoofing. Explainability findings reveal that network data play a\ndominant role in intrusion detection whereas biomedical features contributed to\nspoofing detection, with temperature reaching a Shapley values magnitude of\n0.37."}
{"id": "2506.17350", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17350", "abs": "https://arxiv.org/abs/2506.17350", "authors": ["Yinghao Wu", "Liyan Zhang"], "title": "CUBA: Controlled Untargeted Backdoor Attack against Deep Neural Networks", "comment": null, "summary": "Backdoor attacks have emerged as a critical security threat against deep\nneural networks in recent years. The majority of existing backdoor attacks\nfocus on targeted backdoor attacks, where trigger is strongly associated to\nspecific malicious behavior. Various backdoor detection methods depend on this\ninherent property and shows effective results in identifying and mitigating\nsuch targeted attacks. However, a purely untargeted attack in backdoor\nscenarios is, in some sense, self-weakening, since the target nature is what\nmakes backdoor attacks so powerful. In light of this, we introduce a novel\nConstrained Untargeted Backdoor Attack (CUBA), which combines the flexibility\nof untargeted attacks with the intentionality of targeted attacks. The\ncompromised model, when presented with backdoor images, will classify them into\nrandom classes within a constrained range of target classes selected by the\nattacker. This combination of randomness and determinedness enables the\nproposed untargeted backdoor attack to natively circumvent existing backdoor\ndefense methods. To implement the untargeted backdoor attack under controlled\nflexibility, we propose to apply logit normalization on cross-entropy loss with\nflipped one-hot labels. By constraining the logit during training, the\ncompromised model will show a uniform distribution across selected target\nclasses, resulting in controlled untargeted attack. Extensive experiments\ndemonstrate the effectiveness of the proposed CUBA on different datasets."}
{"id": "2506.17353", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17353", "abs": "https://arxiv.org/abs/2506.17353", "authors": ["Zongjie Li", "Daoyuan Wu", "Shuai Wang", "Zhendong Su"], "title": "Differentiation-Based Extraction of Proprietary Data from Fine-Tuned LLMs", "comment": "In Proceedings of the 2025 ACM SIGSAC Conference on Computer and\n  Communications Security (CCS'25), October 13-17, 2025, Taipei, Taiwan, China.\n  ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/3719027.3744856", "summary": "The increasing demand for domain-specific and human-aligned Large Language\nModels (LLMs) has led to the widespread adoption of Supervised Fine-Tuning\n(SFT) techniques. SFT datasets often comprise valuable instruction-response\npairs, making them highly valuable targets for potential extraction. This paper\nstudies this critical research problem for the first time. We start by formally\ndefining and formulating the problem, then explore various attack goals, types,\nand variants based on the unique properties of SFT data in real-world\nscenarios. Based on our analysis of extraction behaviors of direct extraction,\nwe develop a novel extraction method specifically designed for SFT models,\ncalled Differentiated Data Extraction (DDE), which exploits the confidence\nlevels of fine-tuned models and their behavioral differences from pre-trained\nbase models. Through extensive experiments across multiple domains and\nscenarios, we demonstrate the feasibility of SFT data extraction using DDE. Our\nresults show that DDE consistently outperforms existing extraction baselines in\nall attack settings. To counter this new attack, we propose a defense mechanism\nthat mitigates DDE attacks with minimal impact on model performance. Overall,\nour research reveals hidden data leak risks in fine-tuned LLMs and provides\ninsights for developing more secure models."}
{"id": "2506.18053", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18053", "abs": "https://arxiv.org/abs/2506.18053", "authors": ["Marcos Florencio", "Thomas Barton"], "title": "Mechanistic Interpretability in the Presence of Architectural Obfuscation", "comment": null, "summary": "Architectural obfuscation - e.g., permuting hidden-state tensors, linearly\ntransforming embedding tables, or remapping tokens - has recently gained\ntraction as a lightweight substitute for heavyweight cryptography in\nprivacy-preserving large-language-model (LLM) inference. While recent work has\nshown that these techniques can be broken under dedicated reconstruction\nattacks, their impact on mechanistic interpretability has not been\nsystematically studied. In particular, it remains unclear whether scrambling a\nnetwork's internal representations truly thwarts efforts to understand how the\nmodel works, or simply relocates the same circuits to an unfamiliar coordinate\nsystem. We address this gap by analyzing a GPT-2-small model trained from\nscratch with a representative obfuscation map. Assuming the obfuscation map is\nprivate and the original basis is hidden (mirroring an honest-but-curious\nserver), we apply logit-lens attribution, causal path-patching, and\nattention-head ablation to locate and manipulate known circuits. Our findings\nreveal that obfuscation dramatically alters activation patterns within\nattention heads yet preserves the layer-wise computational graph. This\ndisconnect hampers reverse-engineering of user prompts: causal traces lose\ntheir alignment with baseline semantics, and token-level logit attributions\nbecome too noisy to reconstruct. At the same time, feed-forward and residual\npathways remain functionally intact, suggesting that obfuscation degrades\nfine-grained interpretability without compromising top-level task performance.\nThese results establish quantitative evidence that architectural obfuscation\ncan simultaneously (i) retain global model behaviour and (ii) impede\nmechanistic analyses of user-specific content. By mapping where\ninterpretability breaks down, our study provides guidance for future privacy\ndefences and for robustness-aware interpretability tooling."}
{"id": "2506.18087", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18087", "abs": "https://arxiv.org/abs/2506.18087", "authors": ["Huaiying Luo", "Cheng Ji"], "title": "Federated Learning-Based Data Collaboration Method for Enhancing Edge Cloud AI System Security Using Large Language Models", "comment": "Accepted by the 2025 5th International Symposium on Computer\n  Technology and Information Science (ISCTIS 2025)", "summary": "With the widespread application of edge computing and cloud systems in\nAI-driven applications, how to maintain efficient performance while ensuring\ndata privacy has become an urgent security issue. This paper proposes a\nfederated learning-based data collaboration method to improve the security of\nedge cloud AI systems, and use large-scale language models (LLMs) to enhance\ndata privacy protection and system robustness. Based on the existing federated\nlearning framework, this method introduces a secure multi-party computation\nprotocol, which optimizes the data aggregation and encryption process between\ndistributed nodes by using LLM to ensure data privacy and improve system\nefficiency. By combining advanced adversarial training techniques, the model\nenhances the resistance of edge cloud AI systems to security threats such as\ndata leakage and model poisoning. Experimental results show that the proposed\nmethod is 15% better than the traditional federated learning method in terms of\ndata protection and model robustness."}
{"id": "2506.18195", "categories": ["math.OC", "cs.AI", "cs.MA", "cs.SY", "eess.SY", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2506.18195", "abs": "https://arxiv.org/abs/2506.18195", "authors": ["Giacomo Como", "Fabio Fagnani", "Anton Proskurnikov"], "title": "Wisdom of Crowds Through Myopic Self-Confidence Adaptation", "comment": null, "summary": "The wisdom of crowds is an umbrella term for phenomena suggesting that the\ncollective judgment or decision of a large group can be more accurate than the\nindividual judgments or decisions of the group members. A well-known example\nillustrating this concept is the competition at a country fair described by\nGalton, where the median value of the individual guesses about the weight of an\nox resulted in an astonishingly accurate estimate of the actual weight. This\nphenomenon resembles classical results in probability theory and relies on\nindependent decision-making. The accuracy of the group's final decision can be\nsignificantly reduced if the final agents' opinions are driven by a few\ninfluential agents.\n  In this paper, we consider a group of agents who initially possess\nuncorrelated and unbiased noisy measurements of a common state of the world.\nAssume these agents iteratively update their estimates according to a simple\nnon-Bayesian learning rule, commonly known in mathematical sociology as the\nFrench-DeGroot dynamics or iterative opinion pooling. As a result of this\niterative distributed averaging process, each agent arrives at an asymptotic\nestimate of the state of the world, with the variance of this estimate\ndetermined by the matrix of weights the agents assign to each other. Every\nagent aims at minimizing the variance of her asymptotic estimate of the state\nof the world; however, such variance is also influenced by the weights\nallocated by other agents. To achieve the best possible estimate, the agents\nmust then solve a game-theoretic, multi-objective optimization problem defined\nby the available sets of influence weights. We characterize both the Pareto\nfrontier and the set of Nash equilibria in the resulting game. Additionally, we\nexamine asynchronous best-response dynamics for the group of agents and prove\ntheir convergence to the set of strict Nash equilibria."}
{"id": "2506.18245", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.18245", "abs": "https://arxiv.org/abs/2506.18245", "authors": ["Lei Yu", "Zhirong Huang", "Hang Yuan", "Shiqi Cheng", "Li Yang", "Fengjun Zhang", "Chenjie Shen", "Jiajia Ma", "Jingyuan Zhang", "Junyi Lu", "Chun Zuo"], "title": "Smart-LLaMA-DPO: Reinforced Large Language Model for Explainable Smart Contract Vulnerability Detection", "comment": "Accepted to ISSTA 2025", "summary": "Smart contract vulnerability detection remains a major challenge in\nblockchain security. Existing vulnerability detection methods face two main\nissues: (1) Existing datasets lack comprehensive coverage and high-quality\nexplanations for preference learning. (2) Large language models (LLMs) often\nstruggle with accurately interpreting specific concepts in smart contract\nsecurity. Empirical analysis shows that even after continual pre-training (CPT)\nand supervised fine-tuning (SFT), LLMs may misinterpret the execution order of\nstate changes, resulting in incorrect explanations despite making correct\ndetection decisions. To address these challenges, we propose Smart-LLaMA-DPO\nbased on LLaMA-3.1-8B. We construct a comprehensive dataset covering four major\nvulnerability types and machine-unauditable vulnerabilities, including precise\nlabels, explanations, and locations for SFT, as well as high-quality and\nlow-quality output pairs for Direct Preference Optimization (DPO). Second, we\nperform CPT using large-scale smart contract to enhance the LLM's understanding\nof specific security practices in smart contracts. Futhermore, we conduct SFT\nwith our comprehensive dataset. Finally, we apply DPO, leveraging human\nfeedback and a specially designed loss function that increases the probability\nof preferred explanations while reducing the likelihood of non-preferred\noutputs. We evaluate Smart-LLaMA-DPO on four major vulnerability types:\nreentrancy, timestamp dependence, integer overflow/underflow, and delegatecall,\nas well as machine-unauditable vulnerabilities. Our method significantly\noutperforms state-of-the-art baselines, with average improvements of 10.43% in\nF1 score and 7.87% in accuracy. Moreover, both LLM evaluation and human\nevaluation confirm that our method generates more correct, thorough, and clear\nexplanations."}
{"id": "2506.18543", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18543", "abs": "https://arxiv.org/abs/2506.18543", "authors": ["Xiaodong Wu", "Xiangman Li", "Jianbing Ni"], "title": "Security Assessment of DeepSeek and GPT Series Models against Jailbreak Attacks", "comment": null, "summary": "The widespread deployment of large language models (LLMs) has raised critical\nconcerns over their vulnerability to jailbreak attacks, i.e., adversarial\nprompts that bypass alignment mechanisms and elicit harmful or policy-violating\noutputs. While proprietary models like GPT-4 have undergone extensive\nevaluation, the robustness of emerging open-source alternatives such as\nDeepSeek remains largely underexplored, despite their growing adoption in\nreal-world applications. In this paper, we present the first systematic\njailbreak evaluation of DeepSeek-series models, comparing them with GPT-3.5 and\nGPT-4 using the HarmBench benchmark. We evaluate seven representative attack\nstrategies across 510 harmful behaviors categorized by both function and\nsemantic domain. Our analysis reveals that DeepSeek's Mixture-of-Experts (MoE)\narchitecture introduces routing sparsity that offers selective robustness\nagainst optimization-based attacks such as TAP-T, but leads to significantly\nhigher vulnerability under prompt-based and manually engineered attacks. In\ncontrast, GPT-4 Turbo demonstrates stronger and more consistent safety\nalignment across diverse behaviors, likely due to its dense Transformer design\nand reinforcement learning from human feedback. Fine-grained behavioral\nanalysis and case studies further show that DeepSeek often routes adversarial\nprompts to under-aligned expert modules, resulting in inconsistent refusal\nbehaviors. These findings highlight a fundamental trade-off between\narchitectural efficiency and alignment generalization, emphasizing the need for\ntargeted safety tuning and modular alignment strategies to ensure secure\ndeployment of open-source LLMs."}
