<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 3]
- [math.OC](#math.OC) [Total: 16]
- [math.NT](#math.NT) [Total: 11]
- [math.LO](#math.LO) [Total: 4]
- [math.CO](#math.CO) [Total: 12]
- [cs.CR](#cs.CR) [Total: 24]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.DM](#cs.DM) [Total: 1]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Identifiability by common backdoor in summary causal graphs of time series](https://arxiv.org/abs/2506.14862)
*Clément Yvernes,Charles K. Assaad,Emilie Devijver,Eric Gaussier*

Main category: math.ST

TL;DR: 本文研究了时间序列中干预的可识别性问题，探讨了在仅能获得摘要因果图的情况下，如何通过共同后门集判断多干预多效应的可识别性，并提出了相应的判定算法。


<details>
  <summary>Details</summary>
Motivation: 干预的可识别性问题旨在评估给定干预的总效应是否可以用无do公式表示，从而仅通过观测数据进行计算。在时间序列背景下，当仅能获得真实因果图的抽象表示（摘要因果图）时，这一问题尤为重要。

Method: 研究聚焦于通过共同后门集进行识别，针对时间序列（包括随时间一致和不一致的情况），建立了存在此类集合的条件，并提供了复杂度有限的算法来判定问题是否可识别。

Result: 研究确立了在时间序列中（无论是否随时间一致）存在共同后门集的条件，并开发了算法以有效判定干预效应的可识别性。

Conclusion: 本文为时间序列中多干预多效应的可识别性问题提供了理论框架和实用算法，扩展了因果推断在抽象因果图背景下的应用范围。

Abstract: The identifiability problem for interventions aims at assessing whether the
total effect of some given interventions can be written with a do-free formula,
and thus be computed from observational data only. We study this problem,
considering multiple interventions and multiple effects, in the context of time
series when only abstractions of the true causal graph in the form of summary
causal graphs are available. We focus in this study on identifiability by a
common backdoor set, and establish, for time series with and without
consistency throughout time, conditions under which such a set exists. We also
provide algorithms of limited complexity to decide whether the problem is
identifiable or not.

</details>


### [2] [Probabilistic closed-form formulas for pricing nonlinear payoff variance and volatility derivatives under Schwartz model with time-varying log-return volatility](https://arxiv.org/abs/2506.15386)
*Nontawat Bunchak,Udomsak Rakwongwan,Phiraphat Sutthimat*

Main category: math.ST

TL;DR: 本文提出了离散时间观测下非线性收益波动率和方差衍生品的闭式解析定价公式，基于Schwartz单因子模型，解决了时变对数收益波动率假设下的定价难题，并通过蒙特卡洛模拟验证了方法的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决时变对数收益波动率假设下波动率和方差衍生品的解析定价问题，填补现有文献中非线性收益衍生品定价公式的空白。

Method: 采用概率密度函数方法，解析计算已实现方差平方根的期望，推导波动率互换和波动率看涨期权的定价公式，并对常数对数收益波动率情形进行简化和敏感性分析。

Result: 提出了Schwartz单因子模型下波动率互换的闭式近似解，并通过数值实验验证了价格波动率和交易日数量对波动率/方差互换公平执行价的影响。

Conclusion: 所提出的解析方法在计算效率和准确性上表现优异，为非线性波动率衍生品定价提供了实用工具，扩展了Schwartz模型的应用场景。

Abstract: This paper presents closed-form analytical formulas for pricing volatility
and variance derivatives with nonlinear payoffs under discrete-time
observations. The analysis is based on a probabilistic approach assuming that
the underlying asset price follows the Schwartz one-factor model, where the
volatility of log-returns is time-varying. A difficult challenge in this
pricing problem is to solve an analytical formula under the assumption of
time-varying log-return volatility, resulting in the realized variance being
distributed according to a linear combination of independent noncentral
chi-square random variables with weighted parameters. By utilizing the
probability density function, we analytically compute the expectation of the
square root of the realized variance and derive pricing formulas for volatility
swaps. Additionally, we derive analytical pricing formulas for volatility call
options. For the payoff function without the square root, we also derive
corresponding formulas for variance swaps and variance call options.
Additionally, we study the case of constant log-return volatility; simplified
pricing formulas are derived and sensitivity with respect to volatility (vega)
is analytically studied. Furthermore,we propose simple closed-form
approximations for pricing volatility swaps under the Schwartz one-factor
model. The accuracy and efficiency of the proposed methods are demonstrated
through Monte Carlo simulations, and the impact of price volatility and the
number of trading days on fair strike prices of volatility and variance swaps
is investigated across various numerical experiments.

</details>


### [3] [Density estimation via periodic scaled Korobov kernel method with exponential decay condition](https://arxiv.org/abs/2506.15419)
*Ziyang Ye,Haoyuan Tan,Xiaoqun Wang,Zhijian He*

Main category: math.ST

TL;DR: 本文提出了一种名为周期性缩放Korobov核（PSKK）的非参数密度估计方法，适用于$\mathbb{R}^d$空间，通过模运算将目标密度转换为周期性版本，并利用核岭回归在缩放Korobov空间中进行估计，从而扩展了先前方法的适用范围。


<details>
  <summary>Details</summary>
Motivation: 现有核方法要求密度函数具有固有周期性，限制了其在无界域上的应用。本文旨在消除这一限制，实现对非周期性密度函数的有效估计。

Method: 通过模运算将目标密度包装为周期性版本，随后在缩放Korobov空间中应用核岭回归，扩展了Kazashi和Nobile（2023）提出的核方法。

Result: 理论分析表明，对于具有$\alpha$阶光滑性和指数衰减的密度函数，该方法实现了$\mathcal{O}(M^{-1/(1+1/(2\alpha)+\epsilon)})$的均方积分误差（MISE）收敛速率，其中$\epsilon>0$可任意小。数值实验验证了理论结果，并显示在大样本情况下优于传统核密度估计。

Conclusion: PSKK方法不仅匹配了先前核方法的收敛速率，而且适用于更广泛的非周期性分布，为无界域上的密度估计提供了有效工具。

Abstract: We propose the periodic scaled Korobov kernel (PSKK) method for nonparametric
density estimation on $\mathbb{R}^d$. By first wrapping the target density into
a periodic version through modulo operation and subsequently applying kernel
ridge regression in scaled Korobov spaces, we extend the kernel approach
proposed by Kazashi and Nobile (SIAM J. Numer. Anal., 2023) and eliminate its
requirement for inherent periodicity of the density function. This key
modification enables effective estimation of densities defined on unbounded
domains. We establish rigorous mean integrated squared error (MISE) bounds,
proving that for densities with smoothness of order $\alpha$ and exponential
decay, our method achieves the $\mathcal{O}(M^{-1/(1+1/(2\alpha)+\epsilon)})$
MISE convergence rate with an arbitrarily small $\epsilon>0$. While matching
the convergence rate of the previous kernel approach, our approach applies to a
broader class of non-periodic distributions. Numerical experiments confirm the
theoretical results and demonstrate significant improvement over traditional
kernel density estimation in large-sample regimes.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [4] [On λ-Cent-Dians and Generalized-Center for Network Design: Formulations and Algorithms](https://arxiv.org/abs/2506.14839)
*Víctor Bucarey,Natividad González-Blanco,Martine Labbé,Juan A. Mesa*

Main category: math.OC

TL;DR: 本文研究网络设计中的$\lambda$-中心问题，提出算法视角的广义$\lambda$-中心问题解决方案，包括数学建模、双层结构分析及帕累托最优集参数化方法，并通过Benders分解法实现大规模求解。


<details>
  <summary>Details</summary>
Motivation: 研究旨在在预算约束下设计子网络，高效服务多个起点/终点需求对，扩展了\cite{bucarey2024on}的工作，解决广义$\lambda$-中心问题。

Method: 提出$\lambda\geq 0$的数学公式，分析$\lambda>1$时的双层结构，引入最大$\lambda$-中心概念，通过混合整数线性规划实现帕累托最优集参数化，并对$\lambda\in[0,1]$采用Benders分解法。

Result: 通过不平等度量评估不同解的质量，验证了方法的有效性，Benders分解法成功实现了大规模问题的求解。

Conclusion: 研究为网络设计中的$\lambda$-中心问题提供了全面的算法解决方案，特别是在参数化帕累托最优集和大规模求解方面取得了显著进展。

Abstract: In this paper, we study the $\lambda$-centdian problem in the domain of
Network Design. The focus is on designing a sub-network within a given
underlying network while adhering to a budget constraint. This sub-network is
intended to efficiently serve a collection of origin/destination demand pairs.
We extend the work presented in \cite{bucarey2024on}, providing an algorithmic
perspective on the generalized $\lambda$-centdian problem. In particular, we
provide a mathematical formulation for $\lambda\geq 0$ and discuss the bilevel
structure of this problem for $\lambda>1$. Furthermore, we describe a procedure
to obtain a complete parametrization of the Pareto-optimality set based on
solving two mixed integer linear formulations by introducing the concept of
maximum $\lambda$-cent-dian. We evaluate the quality of the different solution
concepts using some inequality measures. Finally, for $\lambda\in[0,1]$, we
study the implementation of a Benders decomposition method to solve it at
scale.

</details>


### [5] [An efficient co-simulation and control approach to tackle complex multi-domain energetic systems: concepts and applications of the PEGASE platform](https://arxiv.org/abs/2506.15195)
*Mathieu Vallee,Roland Baviere,Valérie Seguin,Valéry Vuillerme,Nicolas Lamaison,Michael Nikhil Descamps,Antoine Aurousseau*

Main category: math.OC

TL;DR: 本文介绍了一款名为PEGASE的新型研究软件，专为复杂多领域能源系统的先进控制策略设计、验证和部署而开发。该软件具备高效的协同仿真引擎，并集成了基于规则的控制策略和模型预测控制（MPC）解决方案。


<details>
  <summary>Details</summary>
Motivation: 针对多领域大规模能源系统的高复杂性，传统整体式解决方案效率低下。PEGASE采用分而治之的原则，通过分解问题域实现高效仿真与控制。

Method: PEGASE基于两大核心组件：1)支持FMI标准或API接口的仿真模型集成框架；2)支持多时间步长的多线程排序器。此外还配备了MPC框架，结合预测数据管理和混合整数线性规划建模器，采用C++实现以降低求解时间。

Result: 通过四个应用案例（包括聚光太阳能热电站和区域供热网络优化控制）验证了该平台的鲁棒性和通用性，展示了其处理各类能源系统复杂性的能力。

Conclusion: PEGASE平台通过模块化设计和先进控制框架，有效解决了多领域能源系统的仿真与控制挑战，其工业协议接口还支持实际能源系统的实时控制。

Abstract: In this paper, we present a novel research software, called PEGASE, suitable
for the design, validation and deployment of advanced control strategies for
complex multi-domain energy systems. PEGASE especially features a highly
efficient cosimulation engine, together with integrated solutions for defining
both rule-based control strategies and Model-Predictive Control (MPC). The main
principle behind the PEGASE platform is divide-and-conquer. Indeed, rather than
trying to solve a problem as a monolithic entity, which can be highly complex
for multi-domain large-scale systems, it is often more efficient to decompose
it into several domains or sub-problems, and to simulate them in a decoupled
way. To provide its cosimulation capabilities, we based PEGASE on two main
components. The first one is a framework for integrating simulation models,
which can be either compatible with the FMI standard or interfaced through an
Application Programming Interface (API). The second one is a multi-threaded
sequencer enabling several simulation sequences with different time steps. To
provide advanced control capabilities, we also equipped PEGASE with a framework
for MPC combining a comprehensive management of predictions data and a modeler
dedicated to the formulation of Mixed Integer Linear Programs. We implemented
this framework in C++ providing low formulation and resolution times for
typical applications. Connection to hardware is also available via standard
industry protocols thereby allowing PEGASE to control real energy systems. In
this paper, we show how these basic functionalities, combined with dedicated
modeling tools, enable setting up simulation and control applications suitable
for tackling the complexity of various kinds of energy systems. To illustrate
this, we present four application examples from our recent research work. These
examples cover several domains, from concentrated solar thermal plants to
optimal control of district heating networks. The variety of examples
demonstrates the robustness and genericity of the approach.

</details>


### [6] [Operational Control of a Multi-energy District Heating System: Comparison of Model-Predictive Control and Rule-Based Control](https://arxiv.org/abs/2506.15197)
*Michael Nikhil Descamps,Nicolas Lamaison,Mathieu Vallee,Roland Baviere*

Main category: math.OC

TL;DR: 本研究比较了区域供热网络中的两种控制策略：基于规则的响应式控制（RBC）和模型预测控制（MPC），发现MPC在降低运营成本和应对能源波动方面更具优势。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索多能源区域供热网络的高效运营控制策略，以应对电力价格波动和太阳能间歇性等挑战。

Method: 通过Modelica建立小规模区域供热网络模型，结合热泵、燃气锅炉和太阳能集热场，使用Pegase平台实现RBC和MPC策略的仿真比较。

Result: MPC策略显著降低了运营成本，尤其在处理可变电价和间歇性太阳能时表现更优，且仿真工具支持20分钟内完成全年模拟。

Conclusion: 模型预测控制（MPC）在多能源供热系统中具有显著经济优势，研究验证了仿真工具在复杂控制策略快速验证中的实用性。

Abstract: This study focuses on operational control strategies for a multi-energy
District Heating Network (DHN). Two control strategies are investigated and
compared: (i) a reactive rule-based control (RBC) and (ii) a model predictive
control (MPC). For the purpose of the study a small scale district heating
network is modelled using Modelica. The production plant combines a heat pump,
a gas boiler and a thermal solar field on the production side with a storage
tank for flexibility purposes. On the consumption side, the virtual buildings
are aggregated into a single consumer. We use our co-simulation and control
platform, called Pegase, to implement the studied strategies. For both
strategies the goal is to meet the consumers' demand while satisfying technical
constraints. In addition MPC has the objective to minimize the operational
costs, taking into account variable electricity prices and availability of
solar thermal resource. Different scenarios are also defined and compared to
study the effect of the heat plant sizing and forecasting error. The
operational cost is reduced when switching from RBC to a MPC. As can be
expected, MPC is more efficient when dealing with variable energy costs,
intermittent solar energy and storage capabilities. This study also
demonstrates how our tools enable an easy coupling of Modelica-based simulation
with various control strategies. It especially supports the implementation and
validation of complex MPC strategies in an efficient way, and yearly
simulations are performed within 20 minutes.

</details>


### [7] [Contribution of expert aggregation to temperature prediction part II: Second order bounds with sleeping experts](https://arxiv.org/abs/2506.15216)
*Léo Pfitzner,Olivier Wintenberger,Olivier Mestre*

Main category: math.OC

TL;DR: 本文通过引入睡眠专家框架(SEF)和梯度提升回归树改进了专家聚合(EA)的温度预测方法，提高了反应速度并减少了大误差，同时保持了均方根误差不变。


<details>
  <summary>Details</summary>
Motivation: 旨在提升第一部分中专家聚合(EA)的温度预测性能，使其更具响应性，同时控制误差水平。

Method: 采用睡眠专家框架(SEF)更高效利用有偏专家，结合梯度提升回归树处理专家使用时机的不确定性，并在BOA自适应聚合器上实现在线应用。

Result: 新方法在保持均方根误差的同时提高了反应速度，显著减少了预测中的大误差。

Conclusion: 通过SEF与EA前导跟踪的元聚合策略，有效平衡了预测精度与噪声控制，实现了更优的在线温度预测性能。

Abstract: In this paper we improve on the temperature predictions made with (online)
Expert Aggregation (EA) [Cesa-Bianchi and Lugosi, 2006] in Part I. In
particular, we make the aggregation more reactive, whilst maintaining at least
the same root mean squared error and reducing the number of large errors. We
have achieved this by using the Sleeping Expert Framework (SEF) [Freund et al.,
1997, Devaine et al., 2013], which allows the more efficient use of biased
experts (bad on average but which may be good at some point). To deal with the
fact that, unlike in Devaine et al. [2013], we do not know in advance when to
use these biased experts, we resorted to gradient boosted regression trees
[Chen and Guestrin, 2016] and provide regret bounds against sequences of
experts [Mourtada and Maillard, 2017] which take into account this uncertainty.
We applied this in a fully online way on BOA [Wintenberger, 2024], an adaptive
aggregation with second order regret bounds, which had the best results in Part
I. Finally, we made a meta-aggregation with the EA follow the leader. This
chooses whether or not to use the SEF in order to limit the possible noise
added by the SEF.

</details>


### [8] [On the Effectiveness of Classical Regression Methods for Optimal Switching Problems](https://arxiv.org/abs/2506.15436)
*Martin Andersson,Benny Avelin,Marcus Olofsson*

Main category: math.OC

TL;DR: 简单回归方法在1到50维的最优切换问题中展现出稳健且接近最优的性能，无需复杂调参即可超越神经网络。


<details>
  <summary>Details</summary>
Motivation: 研究旨在验证简单回归方法在高维最优切换问题中的有效性，尤其关注其在含噪声训练目标下的稳健性。

Method: 采用Longstaff-Schwartz算法与经典方法（如$k$-NN），测试了八种回归方法在四个基准问题上的表现，并分析了PCA对$k$-NN的维度扩展作用。

Result: 简单方法在多样化问题中保持稳定性能，$k$-NN在跳跃扩散动力学下具有集中性边界，PCA使其适应高维场景。

Conclusion: 实践表明：经过最小调参的简单回归方法能为计算密集型切换问题提供可靠解决方案，优于复杂替代方案。

Abstract: Simple regression methods provide robust, near-optimal solutions for optimal
switching problems in dimensions ranging from 1 to 50. While the theory
requires solving intractable PDE systems, the Longstaff-Schwartz algorithm with
classical approaches like $k$-NN achieves excellent switching decisions without
extensive hyperparameter tuning. Testing eight regression approaches on four
benchmark problems, we find that simple methods maintain stable performance
across diverse problem characteristics, even after extensive neural network
optimization. The contaminated training targets inherent to backward
induction-where each target contains both approximation bias and Monte Carlo
noise-actually favor these robust approaches over more complex alternatives
such as neural networks. Further, we establish concentration bounds for $k$-NN
regression under jump-diffusion dynamics and show that PCA enables $k$-NN to
scale to high dimensions. For practitioners: simple, minimally-tuned regression
methods offer reliable performance for computationally demanding switching
problems.

</details>


### [9] [Contribution of expert aggregation to temperature prediction part I](https://arxiv.org/abs/2506.15217)
*Léo Pfitzner,Olivier Wintenberger,Olivier Mestre,Marion Riverain*

Main category: math.OC

TL;DR: 本文提出了一种利用专家聚合（EA）策略优化数值天气预报（NWP）模型温度预测的方法，展示了其在提升预测精度方面的有效性，并比较了不同EA策略的优劣。


<details>
  <summary>Details</summary>
Motivation: 现有多种数值天气预报模型及其统计后处理（MOS）方法，但如何最优整合这些预测结果仍具挑战性。专家聚合（EA）因其在线性、模型适应性及理论保障等优势成为解决方案。

Method: 采用专家聚合策略（EA）进行确定性温度预测，通过动态加权整合不同NWP模型及后处理模型的输出，并对比分析多种EA策略在不同场景下的表现。

Result: 研究表明，EA策略能显著提升温度预测精度，甚至优于后处理的NWP模型；同时揭示了不同策略在适应性、计算效率等方面的差异。

Conclusion: 专家聚合方法为多模型温度预测提供了有效框架，但其性能受策略选择及场景限制，未来需进一步优化以适应更复杂的气象条件。

Abstract: Many Numerical Weather Prediction (NWP) models and their associated Model
Output Statistics (MOS) are available. Combining all of these predictions in an
optimal way is however not straightforward. This can be achieved thanks to
Expert Aggregation (EA) [Cesa-Bianchi and Lugosi, 2006, Gaillard et al., 2014,
Wintenberger, 2024] which has many advantages, such as being online, being
adaptive to model changes and having theoretical guarantees. Hence, in this
paper, we propose a method for making deterministic temperature predictions
with EA strategies and show how this can improve temperature predictions, even
those of post processed NWP models. We also compare different EA strategies in
various settings and discuss certain limitations.

</details>


### [10] [Polynomial Eigenfunctions and Matrix Lyapunov Equations from Energy Balance Integrals](https://arxiv.org/abs/2506.15288)
*Netzer Moriya*

Main category: math.OC

TL;DR: 本文建立了一个统一理论框架，将经典正交多项式系统与矩阵Lyapunov方程通过随机动力系统中的能量耗散物理原理联系起来，揭示了二者在能量耗散结构上的对偶性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于构建一个连接经典正交多项式与矩阵Lyapunov方程的数学框架，通过能量耗散的物理原理揭示二者之间的本质联系。

Method: 方法基于无限维Hilbert空间中的能量平衡原理，推导出包含谱几何和协方差动力学的主积分表示，并通过有限维投影再现经典矩阵方程。

Result: 结果表明经典正交多项式（如Zernike、Hermite、球谐函数）与矩阵Lyapunov方程是同一能量耗散结构的对偶表现，且添加均匀耗散可保持多项式本征函数结构。

Conclusion: 该框架为经典微分算子的物理一致性提供了能量平衡条件，同时揭示了噪声过程对称性如何决定方程的具体结构。

Abstract: We establish a unified theoretical framework that connects classical
orthogonal polynomial systems to matrix Lyapunov equations through the
fundamental physics of energy dissipation in stochastic dynamical systems.
Starting from the energy balance principle in infinite-dimensional Hilbert
spaces, we derive a master integral representation that naturally encompasses
both spectral geometry and covariance dynamics. The theory reveals that
established orthogonal polynomials (Zernike, Hermite, spherical harmonics) and
matrix Lyapunov equations are dual manifestations of the same underlying energy
dissipation structure. We provide rigorous mathematical foundations showing how
finite-dimensional projections of infinite-dimensional energy integrals
reproduce classical matrix equations, with specific structure determined by the
symmetries of noise processes. The framework demonstrates that adding uniform
dissipation to classical differential operators preserves their polynomial
eigenfunction structure while ensuring the energy balance conditions required
for physical consistency.

</details>


### [11] [Proximal Operators of Sorted Nonconvex Penalties](https://arxiv.org/abs/2506.15315)
*Anne Gagneux,Mathurin Massias,Emmanuel Soubies*

Main category: math.OC

TL;DR: 本文研究了稀疏信号恢复中的变量自动分组问题，提出了一类排序非凸惩罚项，并开发了高效计算其近端算子的方法，适用于弱凸和非凸两种情况。


<details>
  <summary>Details</summary>
Motivation: 稀疏信号恢复中需要自动变量分组，现有方法如SLOPE虽能促进变量聚类，但存在系数收缩问题。非凸惩罚可减少收缩，但计算近端算子具有挑战性。

Method: 针对弱凸情况（如排序MCP/SCAD），采用PAV算法精确计算近端算子；针对非凸情况（如排序Lq，q∈(0,1)），提出改进PAV算法高效求解。

Result: 理论分析揭示了非凸近端问题极小值的新特性，实验验证了排序非凸惩罚在变量分组和减少系数偏差方面的优势。

Conclusion: 排序非凸惩罚项结合高效近端算法，为稀疏信号恢复提供了兼具变量聚类能力和低收缩特性的新解决方案。

Abstract: This work studies the problem of sparse signal recovery with automatic
grouping of variables. To this end, we investigate sorted nonsmooth penalties
as a regularization approach for generalized linear models. We focus on a
family of sorted nonconvex penalties which generalizes the Sorted L1 Norm
(SLOPE). These penalties are designed to promote clustering of variables due to
their sorted nature, while the nonconvexity reduces the shrinkage of
coefficients. Our goal is to provide efficient ways to compute their proximal
operator, enabling the use of popular proximal algorithms to solve composite
optimization problems with this choice of sorted penalties. We distinguish
between two classes of problems: the weakly convex case where computing the
proximal operator remains a convex problem, and the nonconvex case where
computing the proximal operator becomes a challenging nonconvex combinatorial
problem. For the weakly convex case (e.g. sorted MCP and SCAD), we explain how
the Pool Adjacent Violators (PAV) algorithm can exactly compute the proximal
operator. For the nonconvex case (e.g. sorted Lq with q in ]0,1[), we show that
a slight modification of this algorithm turns out to be remarkably efficient to
tackle the computation of the proximal operator. We also present new
theoretical insights on the minimizers of the nonconvex proximal problem. We
demonstrate the practical interest of using such penalties on several
experiments.

</details>


### [12] [Optimal Control of Thin-Film Flow on a Flexible Topography](https://arxiv.org/abs/2506.15340)
*S. Alrashidy,A. Kalogirou,D. Kalise,K. G. van der Zee*

Main category: math.OC

TL;DR: 本文提出了一种数学模型，用于优化控制受外力影响的柔性地形上的薄膜流动，包括薄膜破裂和气泡合并现象。通过非线性润滑方程和能量耗散定律，推导出最优控制条件，并采用数值方法实现高效稳定的计算。结果表明，该控制策略能精确调控薄膜形态，加速稳态收敛并抑制不稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一种优化控制方法，通过外部力调控柔性地形上的薄膜流动，解决薄膜破裂和气泡合并等复杂流体动力学问题，实现薄膜形态的精确控制。

Method: 建立非线性润滑方程描述流体动力学，引入全局能量耗散定律；推导连续时间下的最优控制条件（耦合前向-后向偏微分方程），采用一阶IMEX时间离散和降维梯度下降法进行数值求解。

Result: 数值实验表明，该控制策略能在薄膜破裂等极端条件下仍实现目标形态，显著加速系统稳态收敛、抑制失稳现象，并有效稳定去润湿过程。

Conclusion: 所提出的最优控制模型通过分布式外力精确调控薄膜动力学，为复杂流体界面控制提供了理论框架和高效数值工具，在微流体等领域具有应用潜力。

Abstract: This work presents a mathematical model for the optimal control of thin-film
flows over a flexible topography influenced by an external force. Our thin-film
model allows for the rupture of films as well as the coalescence of bubbles.
The objective is to find the optimal distributed force acting on the topography
that minimises the differences between actual and desired thin-film profiles. A
nonlinear lubrication equation governing the fluid dynamics and appropriate
functional settings for this model are presented. It is also shown that this
system satisfies a global energy-dissipation law for a suitable energy
functional. Optimality conditions are derived for the solution of the
minimisation problem of a specified cost function across a time horizon. These
conditions are formulated at a continuous level as a system of coupled,
forward-backward PDEs, which are subsequently discretised for numerical
investigation. To ensure computational efficiency and stability, first-order
Implicit-Explicit (IMEX) time-stepping schemes are employed to handle the
nonlinearities in the model, and a reduced gradient descent algorithm is
applied to obtain a numerical approximation of the optimal control signal.
Numerical results illustrate that controlling the thin film, even during
rupture, achieves a precise film profile. This control strategy accelerates
convergence towards a steady state, reduces instabilities, stabilises dewetting
processes, and meets the desired profile specifications.

</details>


### [13] [Multi-Timescale Gradient Sliding for Distributed Optimization](https://arxiv.org/abs/2506.15387)
*Junhui Zhang,Patrick Jaillet*

Main category: math.OC

TL;DR: 本文提出了两种一阶方法MT-GS和AMT-GS，用于解决非光滑凸分布式优化问题，通过多时间尺度梯度滑动减少通信轮次，并实现最优的$\epsilon$依赖性。


<details>
  <summary>Details</summary>
Motivation: 分布式优化中，减少通信轮次并利用目标函数间的相似性是一个关键挑战。本文旨在解决这一问题，同时保持算法的确定性和灵活性。

Method: 基于块可分解的原始-对偶形式化和多时间尺度滑动方法，MT-GS和AMT-GS允许不同子集以不同速率通信，并实现对偶块的多速率更新。

Result: MT-GS和AMT-GS在寻找$\epsilon$-次优解时，通信轮次和次梯度步数均达到最优的$\epsilon$依赖性，且通信轮次对相似性度量$A$的线性依赖是最优的。

Conclusion: 本文提出的方法不仅解决了非光滑目标下通信轮次对$A$的线性依赖是否可达的开放性问题，还为分布式优化提供了高效且灵活的解决方案。

Abstract: We propose two first-order methods for convex, non-smooth, distributed
optimization problems, hereafter called Multi-Timescale Gradient Sliding
(MT-GS) and its accelerated variant (AMT-GS). Our MT-GS and AMT-GS can take
advantage of similarities between (local) objectives to reduce the
communication rounds, are flexible so that different subsets (of agents) can
communicate at different, user-picked rates, and are fully deterministic. These
three desirable features are achieved through a block-decomposable primal-dual
formulation, and a multi-timescale variant of the sliding method introduced in
Lan et al. (2020), Lan (2016), where different dual blocks are updated at
potentially different rates.
  To find an $\epsilon$-suboptimal solution, the complexities of our algorithms
achieve optimal dependency on $\epsilon$: MT-GS needs
$O(\overline{r}A/\epsilon)$ communication rounds and
$O(\overline{r}/\epsilon^2)$ subgradient steps for Lipchitz objectives, and
AMT-GS needs $O(\overline{r}A/\sqrt{\epsilon\mu})$ communication rounds and
$O(\overline{r}/(\epsilon\mu))$ subgradient steps if the objectives are also
$\mu$-strongly convex. Here, $\overline{r}$ measures the ``average rate of
updates'' for dual blocks, and $A$ measures similarities between (subgradients
of) local functions. In addition, the linear dependency of communication rounds
on $A$ is optimal (Arjevani and Shamir 2015), thereby providing a positive
answer to the open question whether such dependency is achievable for
non-smooth objectives (Arjevani and Shamir 2015).

</details>


### [14] [Efficient Online Mirror Descent Stochastic Approximation for Multi-Stage Stochastic Programming](https://arxiv.org/abs/2506.15392)
*Junhui Zhang,Patrick Jaillet*

Main category: math.OC

TL;DR: 本文研究了多阶段随机规划问题的无约束和极小极大鞍点变体，提出了一种基于随机条件梯度预言机的新方法，并通过半在线视角降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统多阶段随机规划中决策通过约束耦合，本文探索通过目标函数耦合的变体，旨在降低计算复杂度并提高算法效率。

Method: 引入随机条件梯度预言机概念，结合镜像下降随机逼近算法；采用半在线视角延迟决策，实现异步计算以降低复杂度。

Result: 证明了加速镜像下降随机逼近算法的收敛性（期望与高概率）；通过延迟决策将复杂度从指数级降至线性级。

Conclusion: 所提出的随机条件梯度预言机和半在线方法有效解决了多阶段随机规划的计算挑战，为大规模问题提供了实用解决方案。

Abstract: We study the unconstrained and the minimax saddle point variants of the
convex multi-stage stochastic programming problem, where consecutive decisions
are coupled through the objective functions, rather than through the
constraints. Based on the analysis of deterministic mirror descent algorithms
with inexact gradients, we introduce the idea of \textit{stochastic conditional
gradient oracles}, a multi-stage analog of the stochastic gradient oracles used
in (classical) stochastic programming. We show one approach to construct such
oracles and prove the convergence of the (accelerated) mirror descent
stochastic approximation, both in expectation and with high probability. To
further reduce the oracle complexity, we view the problem from a
\textit{semi-online} perspective, where the stage $t$ decision variables are
constructed $s$ stages in advance, instead of before stage $1$. We show that
the delay in decision making allows an asynchronous implementation of the
mirror descent stochastic approximation algorithms. By avoiding computing
solutions for scenarios that are inconsistent with information available during
stage $t$, the complexity is reduced from exponential to linear in the number
of stages.

</details>


### [15] [A polynomial projective algorithm for convex feasibility problems with positive-definite constraints](https://arxiv.org/abs/2506.15484)
*Sergei Chubanov*

Main category: math.OC

TL;DR: 本文研究了一类与自对偶锥相关的谱面投影变换，并提出了一种多项式时间算法来解决具有正定约束的凸可行性问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于改进现有凸可行性问题的求解效率，特别是在涉及正定矩阵约束的情况下，通过引入投影变换和势函数来优化算法性能。

Method: 方法包括在每次迭代中寻找可行解或生成有效不等式，通过投影变换将解集拉近关联谱面的中心，并使用势函数衡量接近程度。

Result: 结果表明，该算法在方程数量不小于正半定锥秩和的情况下，能够更精确地界定现有复杂度界限。

Conclusion: 结论指出，所提出的算法在特定条件下显著提升了凸可行性问题的求解效率，为相关优化问题提供了新的理论工具。

Abstract: We study a class of projective transformations of spectraplexes associated
with self-dual cones and, on this basis, propose a polynomial-time algorithm
for convex feasibility problems with positive definite constraints. At each
iteration of the algorithm, either a feasible solution is found or a suitable
valid inequality inducing a projective transformation allowing to bring the
solution set closer to the center of an associated spectraplex. The closeness
to the center is measured in terms of a potential function. The running time of
our algorithm makes the existing complexity bounds more precise for the case
when the number of equations linking the positive definite variable matrices is
not less than the sum of the ranks of the respective positive-semidefinite
cones.

</details>


### [16] [On Exact Solutions to the Linear Bellman Equation](https://arxiv.org/abs/2506.15527)
*David Ohlin,Richard Pates,Murat Arcak*

Main category: math.OC

TL;DR: 本文提出了线性算子动态系统最优控制的充分条件，推导出贝尔曼方程的显式解，并证明了线性可解MDP类自然满足这些条件，可推广至半线性动态系统。


<details>
  <summary>Details</summary>
Motivation: 研究目的是为线性算子动态系统建立分布式计算友好的贝尔曼方程显式解条件，并将线性可解MDP框架扩展到含输入非线性的场景。

Method: 通过重构线性可解MDP为连续状态最优控制问题，验证其满足贝尔曼方程显式解条件，并扩展至半线性动态系统。

Result: 提出的条件适用于线性二次成本场景（如随机最短路径和LQR问题），证明了线性可解MDP类具有天然的显式解特性。

Conclusion: 该研究为处理输入非线性的半线性系统提供了理论框架，并在经典控制问题中验证了条件的实用性。

Abstract: This paper presents sufficient conditions for optimal control of systems with
dynamics given by a linear operator, in order to obtain an explicit solution to
the Bellman equation that can be calculated in a distributed fashion. Further,
the class of Linearly Solvable MDP is reformulated as a continuous-state
optimal control problem. It is shown that this class naturally satisfies the
conditions for explicit solution of the Bellman equation, motivating the
extension of previous results to semilinear dynamics to account for input
nonlinearities. The applicability of the given conditions is illustrated in
scenarios with linear and quadratic cost, corresponding to the Stochastic
Shortest Path and Linear-Quadratic Regulator problems.

</details>


### [17] [Long run control of nonhomogeneous Markov processes](https://arxiv.org/abs/2506.15542)
*Łukasz Stettner*

Main category: math.OC

TL;DR: 论文研究了非齐次马尔可夫过程的平均奖励和风险敏感奖励泛函，证明了贝尔曼方程解的存在性、值函数对风险参数的连续性，以及泛函在马尔可夫控制点态收敛下的稳定性。


<details>
  <summary>Details</summary>
Motivation: 探讨非齐次马尔可夫控制过程中平均单位时间奖励和风险敏感奖励泛函的性质，为随机控制理论提供新的分析工具。

Method: 通过建立合适的贝尔曼方程，分析其解的存在性，并研究值函数对风险参数的连续性及泛函在控制收敛下的稳定性。

Result: 证明了贝尔曼方程解的存在性，展示了值函数对风险参数的连续性，并验证了泛函在马尔可夫控制点态收敛下的稳定性。

Conclusion: 该研究为非齐次马尔可夫控制过程的奖励泛函分析提供了理论支持，拓展了随机控制理论的应用范围。

Abstract: In the paper average reward per unit time and average risk sensitive reward
functionals are considered for controlled nonhomogeneous Markov processes.
Existence of solutions to suitable Bellman equations is shown. Continuity of
the value functions with respect to risk parameter is also proved. Finally
stability of functionals with respect to pointwise convergence of Markov
controls is studied.

</details>


### [18] [Primal-Dual Coordinate Descent for Nonconvex-Nonconcave Saddle Point Problems Under the Weak MVI Assumption](https://arxiv.org/abs/2506.15597)
*Iyad Walwil,Olivier Fercoq*

Main category: math.OC

TL;DR: 本文提出了两种新型原始-对偶算法（NC-PDHG和NC-SPDHG），用于解决弱Minty变分不等式描述的非凸、非凹、非光滑鞍点问题。通过结合PEPit工具和自动Lyapunov函数技术，成功设计了首个基于坐标的随机算法，并在数值实验中验证了其优于现有算法的性能。


<details>
  <summary>Details</summary>
Motivation: 针对非凸非凹非光滑鞍点问题缺乏有效算法，特别是基于坐标的随机方法尚属空白。研究团队借助计算机辅助工具PEPit突破理论证明难题，旨在开发适应问题结构的常步长收敛算法。

Method: 1) NC-PDHG：扩展经典PDHG算法至非凸非凹场景；2) NC-SPDHG：引入随机外推坐标下降法，成为首个解决此类问题的随机原始-对偶算法。采用PEPit工具与自动Lyapunov函数技术进行收敛性证明。

Result: 在弱MVI参数温和条件下，两种算法均实现常步长收敛。数值实验（含逻辑回归平方损失、感知器回归）显示线性收敛速度，性能超越现有最优算法。NC-SPDHG在凸凹最小二乘问题中与SAGA算法表现相当。

Conclusion: 所提算法填补了非凸非凹鞍点问题随机方法的空白，理论证明创新性地结合计算机辅助分析工具。实验验证了其在复杂优化问题中的高效性和广泛适用性，为相关领域提供了新的解决方案。

Abstract: We introduce two novel primal-dual algorithms for addressing nonconvex,
nonconcave, and nonsmooth saddle point problems characterized by the weak Minty
Variational Inequality (MVI). The first algorithm, Nonconvex-Nonconcave
Primal-Dual Hybrid Gradient (NC-PDHG), extends the well-known Primal-Dual
Hybrid Gradient (PDHG) method to this challenging problem class. The second
algorithm, Nonconvex-Nonconcave Stochastic Primal-Dual Hybrid Gradient
(NC-SPDHG), incorporates a randomly extrapolated primal-dual coordinate descent
approach, extending the Stochastic Primal-Dual Hybrid Gradient (SPDHG)
algorithm.
  To our knowledge, designing a coordinate-based algorithm to solve
nonconvex-nonconcave saddle point problems is unprecedented, and proving its
convergence posed significant difficulties. This challenge motivated us to
utilize PEPit, a Python-based tool for computer-assisted worst-case analysis of
first-order optimization methods. By integrating PEPit with automated Lyapunov
function techniques, we successfully derived the NC-SPDHG algorithm.
  Both methods are effective under a mild condition on the weak MVI parameter,
achieving convergence with constant step sizes that adapt to the structure of
the problem. Numerical experiments on logistic regression with squared loss and
perceptron-regression problems validate our theoretical findings and show their
efficiency compared to existing state-of-the-art algorithms, where linear
convergence is observed. Additionally, we conduct a convex-concave
least-squares experiment to show that NC-SPDHG performs competitively with
SAGA, a leading algorithm in the smooth convex setting.

</details>


### [19] [Heavy Ball and Nesterov Accelerations with Hessian-driven Damping for Nonconvex Optimization](https://arxiv.org/abs/2506.15632)
*N. Hadjisavvas,F. Lara,R. T. Marcavillaca,P. T. Vuong*

Main category: math.OC

TL;DR: 本文研究了一种针对强拟凸函数的二阶动力系统，提出了两种基于梯度的时间离散化算法，均实现了线性收敛，并通过数值实验验证了结果。


<details>
  <summary>Details</summary>
Motivation: 针对强拟凸函数优化问题，传统动量方法常出现振荡现象，研究旨在通过引入Hessian驱动的阻尼项提升算法稳定性和收敛性能。

Method: 1. 提出带Hessian修正的重球法，包含曲率相关项；2. 设计自适应动量的Nesterov型加速法，引入局部曲率修正项。两种算法均从连续时间模型离散化得到。

Result: 理论证明两种算法在迭代值和函数值上均能线性收敛至最优解，数值实验验证了其抑制振荡和提升收敛的效果。

Conclusion: 研究揭示了连续时间动力学与离散优化算法在强拟凸目标下的深刻联系，所提方法为动量类算法提供了新的改进方向。

Abstract: In this work, we investigate a second-order dynamical system with
Hessian-driven damping tailored for a class of nonconvex functions called
strongly quasiconvex. Buil\-ding upon this continuous-time model, we derive two
discrete-time gra\-dient-based algorithms through time discretizations. The
first is a Heavy Ball method with Hessian correction, incorporating
cur\-va\-tu\-re-dependent terms that arise from discretizing the Hessian
damping component. The second is a Nesterov-type accelerated method with
adaptive momentum, fea\-tu\-ring correction terms that account for local
curvature. Both algorithms aim to enhance stability and convergence
performance, particularly by mi\-ti\-ga\-ting oscillations commonly observed in
cla\-ssi\-cal momentum me\-thods. Furthermore, in both cases we establish
li\-near convergence to the optimal solution for the iterates and functions
values. Our approach highlights the rich interplay between continuous-time
dynamics and discrete optimization algorithms in the se\-tting of strongly
quasiconvex objectives. Numerical experiments are presented to support obtained
results.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [20] [Special Cases of the Shafarevich Conjecture for Complete Intersections in Abelian Varieties](https://arxiv.org/abs/2506.14935)
*Frank Lu*

Main category: math.NT

TL;DR: 本文利用Lawrence-Venkatesh方法，证明了数域$K$上某些阿贝尔簇中超曲面完全交的Shafarevich猜想，关键创新在于计算欧拉示性数及证明Hodge结构的单值群大性质。


<details>
  <summary>Details</summary>
Motivation: 研究数域上阿贝尔簇中完全交的Shafarevich猜想，旨在扩展对算术几何中丢番图性质的理解。

Method: 结合Lawrence-Venkatesh方法，通过计算特定完全交的欧拉示性数，并将Hodge结构单值群的组合性质转化为Tannaka群问题。

Result: 成功证明了目标完全交的Shafarevich猜想，并建立了中间上同调族单值群的大性质与组合结构的联系。

Conclusion: 该工作不仅验证了猜想，还为类似算术几何问题提供了通过Hodge理论与组合方法结合的新途径。

Abstract: In this paper, we prove the Shafarevich conjecture for certain complete
intersections of hypersurfaces in abelian varieties defined over a number field
$K$ using the Lawrence-Venkatesh method. The main new inputs we need are
computation of certain Euler characteristics of these complete intersections
and a big monodromy statement for the variation of Hodge structure arising from
the middle cohomology of a family of such complete intersections. Following
\cite{ls25}, we prove the latter by relating this monodromy statement to a
statement about Tannaka groups, which we then convert into a combinatorial
statement.

</details>


### [21] [Triangular and tetrahedral number differences of sumset sizes in additive number theory](https://arxiv.org/abs/2506.15015)
*Melvyn B. Nathanson*

Main category: math.NT

TL;DR: 本文研究了整数有限集合的和集大小分布，发现四元集合的流行和集大小呈现与三角数及四面体数相关的意外模式。


<details>
  <summary>Details</summary>
Motivation: 以往研究主要关注极小和集（Freiman定理）或极大和集（Sidon集与$B_h$集），本文旨在探索整数有限集合和集大小的完整分布范围。

Method: 通过分析不同大小整数集合的和集分布，特别聚焦于四元集合的和集规模统计特性。

Result: 发现四元集合的流行和集大小分布存在与三角数($\frac{n(n+1)}{2}$)及四面体数($\frac{n(n+1)(n+2)}{6}$)相关的数学模式。

Conclusion: 该研究揭示了整数集合和集大小分布中未被注意的数学结构，为加性组合学提供了新的研究方向。

Abstract: The study of sums of finite sets of integers has mostly concentrated on sets
with very small sumsets (Freiman's theorem and related work) and on sets with
very large sumsets (Sidon sets and $B_h$-sets). This paper considers the full
range of sumset sizes of finite sets of integers and an unexpected pattern
(related to the triangular and tetrahedral numbers) that appears in the
distribution of popular sumset sizes of sets of size 4.

</details>


### [22] [On the Modern Structure of the Gauss-Landau Theorem](https://arxiv.org/abs/2506.15101)
*Manuel M. Aguilera*

Main category: math.NT

TL;DR: 该论文形式化了高斯-兰道定理，提出了一种统一的质因数分解方法来计算有限非零整数集的最大公约数（GCD）和最小公倍数（LCM）。


<details>
  <summary>Details</summary>
Motivation: 尽管这些定理在初等数论教学中常作为启发式方法使用，但文献中尚未对其进行明确的形式化或命名。此形式化旨在加深理解并促进其在数学教学和研究中的应用。

Method: 通过质因数分解的统一框架，对GCD和LCM的计算进行了形式化处理。

Result: 成功建立了高斯-兰道定理的形式化体系，为GCD和LCM的计算提供了理论基础。

Conclusion: 该形式化不仅填补了文献空白，还为数学教育及研究提供了实用的工具和方法。

Abstract: We formalize the Gauss-Landau theorem, providing a unified prime
factorization approach to computing the GCD and LCM of finite nonzero integer
sets. Although commonly used as a heuristic or technique in elementary number
theory education, these theorems have not been explicitly formalized or named
in the literature. This formalization aims to enhance understanding and
facilitate adoption in mathematical instruction and research.

</details>


### [23] [Characterizing infinite torsion subgroups of the circle through arithmetic-type sequences](https://arxiv.org/abs/2506.15257)
*Ayan Ghosh,Pratulananda Das*

Main category: math.NT

TL;DR: 本文基于Das等人的工作，研究了算术型序列对应的特征子群结构，证明了其可数性与挠性的等价关系，并发现圆群的无限挠子群可由有界比算术型序列表征，同时指出Eggleston定理的二分性在广义算术型序列中不成立。


<details>
  <summary>Details</summary>
Motivation: 延续Das等人对算术型序列特征子群结构的研究，进一步探索其可数性、挠性及表征能力，并检验经典结论在更广泛序列类中的适用性。

Method: 通过分析算术型序列与特征子群的对应关系，结合挠子群的性质，采用构造性证明与反例验证相结合的方法。

Result: 1. 算术型序列特征子群可数当且仅当其为挠子群；\n2. 圆群的无限挠子群可由有界比算术型序列表征；\n3. Eggleston定理二分性在广义算术型序列中失效。

Conclusion: 算术型序列特征子群具有明确的挠性-可数性对应关系，且能完全表征圆群的无限挠结构，但经典二分性质无法推广至更一般的序列类。

Abstract: In a recent work [Das et al., Bull. Sci. Math. 199 (2025), 103580], the
structure of characterized subgroups corresponding to arithmetic-type sequences
was investigated. Building upon this work, we further show that a characterized
subgroup associated with an arithmetic-type sequence is countable if and only
if it is torsion. Further we prove that any infinite torsion subgroup of the
circle can be characterized by an arithmetic-type sequence with bounded ratio.
Moreover, our findings demonstrate that the dichotomy observed in Eggleston's
theorem [Theorem 16, Eggleston, Proc. Lond. Math. Soc. 54(2) (1952), 42--93]
for arithmetic sequences does not extend, in general, to the broader class of
arithmetic-type sequences.

</details>


### [24] [Metric Poissonian pair correlationa and additive energy](https://arxiv.org/abs/2506.15274)
*Tanmoy Bera,E. Malavika*

Main category: math.NT

TL;DR: 本文证明了当自然数严格递增序列$(a_n)$的加性能量小于$N^3/(\log N)^C$（$C\geq13.155$）时，$\{a_n\alpha\}$对几乎所有$\alpha\in\mathbb{R}$具有泊松对相关性，改进了Bloom和Walker的下界。


<details>
  <summary>Details</summary>
Motivation: 研究严格递增自然数序列的加性能量与泊松对相关性之间的关系，为已有理论提供更优的下界。

Method: 通过分析序列的加性能量上界，结合数学推导证明泊松对相关性的存在性。

Result: 当加性能量小于$N^3/(\log N)^C$且$C\geq13.155$时，序列$\{a_n\alpha\}$对几乎所有实数$\alpha$具有泊松对相关性。

Conclusion: 该结果将加性能量下界中的指数$C$优化至13.155，推进了Bloom和Walker的已有工作。

Abstract: In this article we prove that if the additive energy of a strictly increasing
sequence $(a_n)$ of natural numbers is less than $N^3/(\log N)^C$ for some
$C\geq13.155$, then $(\{a_n\alpha\})$ has Poissonian pair correlation for
almost all $\alpha\in\mathbb{R}.$ This provides a lower bound for the exponent
$C$ in the additive energy bound established by Bloom and Walker[3].

</details>


### [25] [Singular intersections on families of abelian varieties](https://arxiv.org/abs/2506.15344)
*Nicola Ottolini*

Main category: math.NT

TL;DR: 本文证明了在$\overline{\mathbb{Q}}$上定义的曲线$\mathcal{C}$与阿贝尔概形$\mathcal{A}$的真平坦子群概形相切的点集是有限的。


<details>
  <summary>Details</summary>
Motivation: 研究阿贝尔概形中曲线与子群概形的切点问题，属于不可能交问题框架，是相对Pink猜想的变体。

Method: 使用代数几何和数论工具，分析曲线$\mathcal{C}$与阿贝尔概形$\mathcal{A}$的子群概形的切点性质。

Result: 证明了$\mathcal{C}$与$\mathcal{A}$的真平坦子群概形相切的点集是有限的。

Conclusion: 该结果为不可能交问题提供了新的理论支持，扩展了相对Pink猜想的研究范围。

Abstract: Let $S$ be a smooth irreducible curve defined over $\overline{\mathbb{Q}}$,
let $\mathcal{A}$ be an abelian scheme over $S$ and $\mathcal{C}$ a curve
inside $\mathcal{A}$, both defined over $\overline{\mathbb{Q}}$. In this paper
we prove that the set of points in which $\mathcal{C}$ intersects proper flat
subgroup schemes of $\mathcal{A}$ tangentially is finite. This fits in the
framework of the so-called problems of unlikely intersections, and can be seen
as a variation of the relative Pink conjecture for abelian varieties.

</details>


### [26] [A categorical formulation of the Deligne-Terasoma approach to double shuffle theory](https://arxiv.org/abs/2506.15348)
*Benjamin Enriquez,Khalef Yaddaden*

Main category: math.NT

TL;DR: 本文提出了一种具有分解结构的双模（BFS）概念，并证明该结构能产生代数态射，为双洗理论中的Betti与de Rham谐波余积提供了几何构造解释。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过引入BFS结构，统一解释双洗理论中Betti与de Rham谐波余积的几何构造基础。

Method: 定义具有分解结构的双模（BFS），证明其可诱导代数态射，并关联至双洗理论中的几何构造。

Result: BFS框架成功解释了双洗理论中谐波余积的几何构造，验证了其数学一致性。

Conclusion: BFS结构为双洗理论的几何构造提供了新视角，未来可拓展至其他数学结构的统一描述。

Abstract: In this paper, we introduce the notion of a bimodule with a factorization
structure (BFS) and show that such a structure gives rise to an algebra
morphism. We then prove that this framework offers an interpretation of the
geometric construction underlying both the Betti and de Rham harmonic
coproducts of the double shuffle theory developed in \cite{DeT, EF1, EF2, EF3}.

</details>


### [27] [Patterns in Growth and Distribution of Unbounded Prime Number Walks](https://arxiv.org/abs/2506.15357)
*Alberto Fraile,Daniel Fernández,Roberto Martínez,Theophanes E. Raptis*

Main category: math.NT

TL;DR: 本文证明了素数行走（PW）覆盖的区域是无界的，并进一步探讨了其性质及衍生问题。


<details>
  <summary>Details</summary>
Motivation: 基于前期工作中素数行走在方形网格上的数值结果，验证其覆盖区域无界性的核心猜想。

Method: 通过分析素数行走的轨迹特性，采用数学证明与数值实验相结合的方法。

Result: 证实了素数行走覆盖的区域确实无界，并揭示了其扩展过程中的新特性。

Conclusion: 素数行走的无界性为后续研究开辟了新方向，需进一步探索其数学机制与应用潜力。

Abstract: In our previous work, we defined a prime walk (PW) on a square grid and
presented several intriguing numerical results. Here, we demonstrate the main
conjecture presented there, namely, that the area covered by the prime walk is
unbounded. Taking this fact into account, we examine in further detail the
properties of the PW and explore new questions that arise naturally in this
analysis.

</details>


### [28] [No Nowhere Continuous Function Maps all Non-Normal Numbers to Normal Numbers](https://arxiv.org/abs/2506.15422)
*Chokri Manai*

Main category: math.NT

TL;DR: 本文证明了不存在任何非空开区间$I$和非常数连续函数$\phi$，能将所有非正规数映射为正规数。相反，正规数集$\mathcal{N}$不具有此性质，并构造了一个将正规数映射为非正规数的康托型连续函数。


<details>
  <summary>Details</summary>
Motivation: 研究非正规数集$\mathcal{N}^c$的性质，探讨是否存在连续函数能将非正规数映射为正规数，以揭示$\mathcal{N}^c$的丰富性及其与正规数集$\mathcal{N}$的差异。

Method: 通过反证法否定存在性，并利用康托型构造法显式构建一个非常数连续函数$\hat{C}$，将正规数映射为非正规数。

Result: 不存在任何开区间$I$和非常数连续函数$\phi$满足$\varphi(I \cap \mathcal{N}^c) \subset \mathcal{N}$，但存在康托型连续函数$\hat{C}$实现$\mathcal{N} \to \mathcal{N}^c$的映射。

Conclusion: 非正规数集$\mathcal{N}^c$的复杂性使其无法通过连续函数局部转换为正规数，而正规数集$\mathcal{N}$则具有可被连续函数‘破坏’其正规性的特殊性质。

Abstract: In this work, we consider the set of non-normal numbers $\mathcal{N}^c$ and
ask if there is a non-empty open interval $I$ and a nowhere constant continuous
function $\phi: I \to \rr$ which maps all non-normal numbers to normal numbers,
i.e., $\varphi(I \cap \mathcal{N}^c) \subset \mathcal{N}.$ We answer this
question negatively. This result can be seen as a further manifestation of the
richness of the null set $\mathcal{N}^c$. Surprisingly, the "bigger" set of
normal numbers $\mathcal{N}$ does not share this property and we will give an
explicit Cantor-type construction of a nowhere constant continuous function
$\hat{C}$, which maps all normal numbers to non-normal numbers.

</details>


### [29] [Evaluation of Modular Polynomials from Supersingular Elliptic Curves](https://arxiv.org/abs/2506.15429)
*Maria Corte-Real Santos,Jonathan Komada Eriksen,Antonin Leroux,Michael Meyer,Lorenz Panny*

Main category: math.NT

TL;DR: 本文提出了两种基于CRT方法和超奇异曲线的新算法，用于计算模素数$p$下级别$\ell$的模多项式，具有最优内存需求，并在特定条件下达到最佳时间复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有算法在计算模多项式时内存需求较高，且时间复杂度仍有优化空间。本文旨在开发内存最优且高效的通用算法。

Method: 第一种算法结合了Sutherland(2013)的混合算法与Leroux(2023)的超奇异曲线方法；第二种算法通过子算法高效处理$\Fp$上的超奇异$j$-不变量，实现$\ell$的二次复杂度。

Result: 算法一达到$\Tilde{O}(\ell^3 \log^{3} \ell + \ell \log p)$时间复杂度（与Sutherland算法相当）且内存最优；算法二首次实现$\ell$的二次复杂度并保持内存最优。

Conclusion: 新算法在内存效率和时间复杂度上取得突破，可扩展至Weber函数等模多项式计算，配套实现代码具有广泛适用性。

Abstract: We present several new algorithms to evaluate modular polynomials of level
$\ell$ modulo a prime $p$ on an input $j$.
  More precisely, we introduce two new generic algorithms, sharing the
following similarities: they are based on a CRT approach; they make use of
supersingular curves and the Deuring correspondence; and, their memory
requirements are optimal.
  The first algorithm combines the ideas behind a hybrid algorithm of
Sutherland in 2013 with a recent algorithm to compute modular polynomials using
supersingular curves introduced in 2023 by Leroux. The complexity (holding
around several plausible heuristic assumptions) of the resulting algorithm
matches the $\Tilde{O}(\ell^3 \log^{3} \ell + \ell \log p)$ time complexity of
the best known algorithm by Sutherland, but has an optimal memory requirement.
  Our second algorithm is based on a sub-algorithm that can evaluate modular
polynomials efficiently on supersingular $j$-invariants defined over $\Fp$, and
achieves heuristic complexity quadratic in both $\ell$ and $\log j$, and linear
in $\log p$. In particular, it is the first generic algorithm with optimal
memory requirement to obtain a quadratic complexity in~$\ell$.
  Additionally, we show how to adapt our method to the computation of other
types of modular polynomials such as the one stemming from Weber's function.
  Finally, we provide an optimised implementation of the two algorithms
detailed in this paper, though we emphasise that various modules in our
codebase
  may find applications outside their use in this paper.

</details>


### [30] [Long strings of composite values of polynomials and a basis of order 2](https://arxiv.org/abs/2506.15641)
*Artyom Radomskii*

Main category: math.NT

TL;DR: 该论文证明了对于任何在$\mathbb{Q}$上不可约且首项系数为正的多项式$f: \mathbb{Z}\to \mathbb{Z}$，当$N$足够大时，存在两个连续正整数串$I_{1}$和$I_{2}$，使得$I_{1}\cup I_{2} \subset [1, N]$且$f(n)$在$I_{1}\cup I_{2}$上均为合数。这一结果推广了文献[5]中关于$f(n)=n$的结论。


<details>
  <summary>Details</summary>
Motivation: 研究多项式在连续整数区间上的取值是否为合数，是数论中的一个重要问题。本文旨在推广已有结果，从线性多项式扩展到更一般的不可约多项式。

Method: 通过构造两个长度与$\log N$和$\log \log N$相关的连续整数区间$I_{1}$和$I_{2}$，并证明在这些区间上多项式$f(n)$的取值均为合数。

Result: 对于足够大的$N$，存在两个连续正整数串$I_{1}$和$I_{2}$，其长度$m = [(\log N) (\log \log N)^{1/325525}]$，且$f(n)$在$I_{1}\cup I_{2}$上均为合数。

Conclusion: 本文成功将文献[5]中关于线性多项式的结果推广到更一般的不可约多项式，为研究多项式在连续整数区间上的合数分布提供了新的理论支持。

Abstract: We show that for any polynomial $f: \mathbb{Z}\to \mathbb{Z}$ with positive
leading coefficient and irreducible over $\mathbb{Q}$, if $N$ is large enough
then there are two strings of consecutive positive integers
$I_{1}=\{n_1-m,\ldots, n_1+m\}$ and $I_{2}=\{n_2-m, \ldots, n_2+m\}$, where $m
= [(\log N) (\log \log N)^{1/325525}]$, such that $I_{1}\cup I_{2} \subset [1,
N]$, $N = n_1 + n_2$, and $f(n)$ is composite for any $n\in I_{1}\cup I_{2}$.
This extends the result in [5] which showed the same result but with $f(n)=n$.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [31] [Class of extensions of real field and their topological properties](https://arxiv.org/abs/2506.14838)
*E. V. Alexandrov*

Main category: math.LO

TL;DR: 本文定义了实数域的适当扩展类，并研究了这些扩展的拓扑性质。这些扩展可以是连通的（此时集合对二元运算不封闭）或非连通的（此时构成线性有序域），未来可应用于构建能感知零勒贝格测度集的测度。


<details>
  <summary>Details</summary>
Motivation: 研究实数域扩展类的拓扑性质，为构建新型测度理论奠定基础，特别是针对零勒贝格测度集的感知问题。

Method: 通过定义实数域的特定扩展类，分析其连通性与代数封闭性，区分连通扩展（二元运算不封闭）与非连通扩展（形成线性有序域）。

Result: 发现连通扩展对加法乘法不封闭，而非连通扩展具有线性序结构；两类扩展的拓扑性质差异为测度构造提供了新途径。

Conclusion: 实数域扩展的拓扑分类揭示了代数与序结构的深层联系，未来可应用于开发能检测零测集的测度工具。

Abstract: Proper classes of extensions of real field was defined and topological
properties of these extensions were studied. These extensions can be connected,
in this case such set is not closed under binary operations (addition and
multiplication), and not connected, in this case this extension is linearly
ordered field. In the future these constructions can be applied to building
measure that "feels" set of zero Lebesgue measure.

</details>


### [32] [Definability of complex functions in o-minimal structures](https://arxiv.org/abs/2506.15119)
*Adele Padgett,Patrick Speissegger*

Main category: math.LO

TL;DR: 证明了$\mathbf{an}^*$和$\mathcal{G}$类函数的全纯延拓在o-极小结构$\mathbb{R}_{\mathrm{an}^*}$和$\mathbb{R}_{\mathcal{G}}$中可定义，并给出了最优复域。应用包括描述黎曼$\zeta$函数和$\Gamma$函数在相应o-极小扩张中的最优可定义域。


<details>
  <summary>Details</summary>
Motivation: 研究特定函数类在全纯延拓下的可定义性，为复分析函数在o-极小结构中的模型论性质提供理论基础。

Method: 通过构造复域证明全纯延拓的可定义性，并验证这些域的最优性。

Result: 确定了$\mathbf{an}^*$和$\mathcal{G}$类函数在对应o-极小结构中的最优可定义复域，并应用于黎曼$\zeta$函数和$\Gamma$函数。

Conclusion: 该研究为复变函数在o-极小结构中的可定义性提供了具体实例和理论框架，拓展了模型论与复分析的交叉应用。

Abstract: We prove that some holomorphic continuations of functions in the classes
$\mathbf{an}^*$ and $\mathcal{G}$ are definable in the o-minimal structures
$\mathbb{R}_{\mathrm{an}^*}$ and $\mathbb{R}_{\mathcal{G}}$ respectively. More
specifically, we give complex domains on which the holomorphic continuations
are definable, and show they are optimal. As an application, we describe
optimal domains on which the Riemann $\zeta$ function is definable in o-minimal
expansions of $\mathbb{R}_{\mathrm{an}^*,\exp}$ and on which the $\Gamma$
function is definable in o-minimal expansions of
$\mathbb{R}_{\mathcal{G},\exp}$.

</details>


### [33] [$Σ^1_3$ sets in the Sacks model](https://arxiv.org/abs/2506.15308)
*Jonathan Schilhan*

Main category: math.LO

TL;DR: 在可构造宇宙上的迭代Sacks模型中，证明了$\Sigma^1_3$集的Mansfield-Solovay定理成立，并确定了Bernstein集的最优复杂度为$\Delta^1_4$。


<details>
  <summary>Details</summary>
Motivation: 研究迭代Sacks模型中$\Sigma^1_3$集的Mansfield-Solovay定理是否成立，并探索Bernstein集的最优复杂度。

Method: 基于Kanovei的结果，在可构造宇宙上的迭代Sacks模型中进行理论推导和分析。

Result: 证明了$\Sigma^1_3$集的Mansfield-Solovay定理成立，且Bernstein集的最优复杂度为$\Delta^1_4$。

Conclusion: 该研究为投影层次结构中非平凡水平的Mansfield-Solovay定理分离提供了理论基础。

Abstract: We show that in the iterated Sacks model over the constructible universe the
Mansfield-Solovay Theorem holds for $\Sigma^1_3$ sets. In particular, every
$\mathbf{\Sigma}^1_3$ set is Marczewski measurable and the optimal complexity
for a Bernstein set is $\Delta^1_4$. Based on a result by Kanovei, we also
briefly show how to separate the Mansfield-Solovay Theorem at non-trivial
levels of the projective hierarchy.

</details>


### [34] [Strongly First Order Disjunctive Embedded Dependencies in Team Semantics](https://arxiv.org/abs/2506.15367)
*Pietro Galliani*

Main category: math.LO

TL;DR: 本文研究了团队语义中一阶逻辑的扩展表达力问题，特别关注了与数据库理论相关的析取嵌入式依赖关系。


<details>
  <summary>Details</summary>
Motivation: 团队语义通过引入新型原子扩展了一阶逻辑的表达能力，其中许多原子受数据库理论启发。研究这些扩展何时不增加一阶逻辑的表达力具有重要意义。

Method: 作者对（域独立的）析取嵌入式依赖关系进行了特征化分析，这些依赖关系在添加到一阶团队语义时不会增强其表达力。

Result: 研究确定了那些不会增加一阶团队语义表达力的析取嵌入式依赖关系的具体特征。

Conclusion: 该工作为理解团队语义中逻辑扩展的表达力边界提供了理论依据，特别针对与数据库理论相关的依赖关系。

Abstract: First Order Team Semantics is a generalization of Tarskian Semantics in which
formulas are satisfied with respect to sets of assignments. In Team Semantics,
it is possible to extend First Order Logic via new types of atoms that describe
dependencies between variables; some of these extensions are strictly more
expressive than First Order Logic, while others are reducible to it.
  Many of the atoms studied in Team Semantics are inspired by Database Theory
and belong in particular to the class of Disjunctive Embedded Dependencies, a
very general family of dependencies that contains most of the dependencies of
practical interest in the study of databases.
  In this work, I provide a characterization for the (domain-independent)
Disjunctive Embedded Dependencies that fail to increase the expressive power of
First-Order Team Semantics when added to it.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [35] [Factorizations in Geometric Lattices](https://arxiv.org/abs/2506.14892)
*Alex Aguila,Elvis Cabrera,Jyrko Correa-Morris*

Main category: math.CO

TL;DR: 本文研究了与有限集$X$的划分格$\Pi(X)$同构的几何格中的原子分解，探讨了原子性在这些格中的作用，并研究了函数$\mathfrak{N}$及红色原子集$\mathcal{R}$的性质。


<details>
  <summary>Details</summary>
Motivation: 基于D.D. Anderson等人在交换代数分解理论中引入的概念，研究几何格中的原子分解，以深化对划分格$\Pi(X)$的理解。

Method: 首先分析函数$\mathfrak{N}\colon \Pi(X) \rightarrow \mathbb{N}$的特性，然后考察红色原子集$\mathcal{R}$，并推导出枚举特定分区的递归公式$\pmb{\pi}(X, j, s, \mathcal{R})$。

Result: 得出了关于函数$\mathfrak{N}$的主要特性，并针对红色原子集$\mathcal{R}$，提出了一个递归公式，用于计算特定秩的分区数量。

Conclusion: 研究揭示了原子分解在几何格中的重要性，特别是红色原子集$\mathcal{R}$在划分格$\Pi(X)$中的枚举性质，为相关领域提供了新的理论工具。

Abstract: This article investigates atomic decompositions in geometric lattices
isomorphic to the partition lattice $\Pi(X)$ of a finite set $X$, a fundamental
structure in lattice theory and combinatorics. We explore the role of atomicity
in these lattices, building on concepts introduced by D.D. Anderson, D.F.
Anderson, and M. Zafrullah within the context of factorization theory in
commutative algebra. As part of the study, we first examine the main
characteristics of the function $\mathfrak{N}\colon \Pi(X) \rightarrow
\mathbb{N}$, which assigns to each partition $\pi$ the number of minimal atomic
decompositions of $\pi$. We then consider a distinguished subset of atoms,
$\mathcal{R}$, referred to as the set of red atoms, and derive a recursive
formula for $\pmb{\pi}(X, j, s, \mathcal{R})$, which enumerates the rank-$j$
partitions expressible as the join of exactly $s$ red atoms.

</details>


### [36] [Short monochromatic odd cycles](https://arxiv.org/abs/2506.14910)
*Oliver Janzer,Fredy Yip*

Main category: math.CO

TL;DR: 本文证明了在完全图$K_{2^k+1}$的任意$k$-边着色中，存在长度至多为$O(k^{3/2}2^{k/2})$的单色奇环，显著改进了之前的结果。


<details>
  <summary>Details</summary>
Motivation: 1973年，Erd\H{o}s和Graham提出了估计$L(k)$的问题，即在$K_{2^k+1}$的任意$k$-边着色中，存在长度不超过$L(k)$的单色奇环的最小值。

Method: 结合代数组合学和逼近理论的工具，作者改进了Gir\~ao和Hunter的上界结果。

Result: 证明了$L(k)=O(k^{3/2}2^{k/2})$，相比之前的$O(\frac{2^k}{k^{1-o(1)}})$有指数级改进。

Conclusion: 该研究在单色奇环长度上界问题上取得了突破性进展，为相关领域提供了新的理论工具。

Abstract: It is easy to see that every $k$-edge-colouring of the complete graph on
$2^k+1$ vertices contains a monochromatic odd cycle. In 1973, Erd\H{o}s and
Graham asked to estimate the smallest $L(k)$ such that every $k$-edge-colouring
of $K_{2^k+1}$ contains a monochromatic odd cycle of length at most $L(k)$.
Recently, Gir\~ao and Hunter obtained the first nontrivial upper bound by
showing that $L(k)=O(\frac{2^k}{k^{1-o(1)}})$, which improves the trivial bound
by a polynomial factor. We obtain an exponential improvement by proving that
$L(k)=O(k^{3/2}2^{k/2})$. Our proof combines tools from algebraic combinatorics
and approximation theory.

</details>


### [37] [Hamiltonian connectivity of some base-cobase graphs](https://arxiv.org/abs/2506.15049)
*Leonardo Martínez-Sandoval,Kolja Knauer*

Main category: math.CO

TL;DR: 本文探讨了拟阵基-余基图的哈密顿连通性，证明了某些特定类别的拟阵（如格路径拟阵的串并联扩展、轮形拟阵和涡旋拟阵）具有该性质，但通过正则拟阵$R_{10}$给出了Farber等人问题的反例。


<details>
  <summary>Details</summary>
Motivation: 研究拟阵基-余基图是否继承基图的哈密顿连通性质，回应Farber、Richter和Shank在1985年提出的问题。

Method: 采用多面体方法分析格路径拟阵的串并联扩展图，并通过构造性证明验证轮形/涡旋拟阵的性质，最后用$R_{10}$作为反例。

Result: 1. 格路径拟阵串并联扩展的基-余基图具有哈密顿连通性\n2. 轮形/涡旋拟阵的基-余基图同样满足该性质\n3. 正则拟阵$R_{10}$打破了该性质的普适性

Conclusion: 拟阵基-余基图的哈密顿连通性仅适用于特定子类，$R_{10}$的存在表明Farber等人的猜想不具普遍性，为拟阵图论研究提供了新的边界条件。

Abstract: There has been wide interest in understanding which properties of base graphs
of matroids extend to base-cobase graphs of matroids. A significant result of
Naddef and Pulleyblank (1984) shows that the $1$-skeleton of any
$(0,1)$-polytope is either a hypercube, or Hamiltonian-connected, i.e. there is
a Hamiltonian path connecting any two vertices. In particular, this is true for
base graphs of matroids. A natural question raised by Farber, Richter, and
Shank (1985) is whether this extends to base-cobase graphs.
  First, we use the polytopal approach to show Hamiltonian connectivity of
base-cobase graphs of series-parallel extensions of lattice path matroids. On
the other hand, we show that this method extends to only very special classes
related to identically self-dual matroids. Second, we show that base-cobase
graphs of wheels and whirls are Hamiltonian connected. Last, we show that the
regular matroid $R_{10}$ yields a negative answer to the question of Farber,
Richter, and Shank.

</details>


### [38] [Some remarks on Folkman graphs for triangles](https://arxiv.org/abs/2506.14942)
*Eion Mulrenin*

Main category: math.CO

TL;DR: 本文研究了基于Hermitian单位几何图的Folkman定理类似性质，证明了对于所有素数幂$q \geq 4$，存在具有"准Folkman"性质的图$H_q$，其中$q=4$时顶点数为208。通过随机修改破坏所有$K_4$后，大$q$情况下仍大概率保持Ramsey性质。


<details>
  <summary>Details</summary>
Motivation: Folkman定理中$f(2,3,4)$的定量研究长期面临挑战，当前记录$f(2,3,4) \leq 786$依赖计算机辅助。本文旨在探索基于有限几何图的新型构造方法，以突破传统Folkman图的研究局限。

Method: 利用射影平面上Hermitian单位几何图序列$H_q$，通过分析其三角形子集$\mathcal{T}_q$的着色性质，并引入随机图修改技术破坏$K_4$结构同时保留Ramsey特性。

Result: 证明对所有素数幂$q \geq 4$，$H_q$存在不生成$K_4$的三角形集$\mathcal{T}_q$，但任意二边着色必产生$\mathcal{T}_q$中的单色三角形。特别地，$q=4$时构造出208顶点满足该性质的图。

Conclusion: 几何图$H_q$系列提供了研究Folkman性质的新途径，随机化方法为平衡$K_4$-free与Ramsey性质提供了有效工具，未来可推广至更高阶团的研究。

Abstract: Folkman's theorem asserts the existence of graphs $G$ which are $K_4$-free,
but which have the property that every two-coloring of $E(G)$ contains a
monochromatic triangle. The quantitative aspects of $f(2,3,4)$, the least $n$
such that there exists an $n$-vertex graph with both properties above, are
notoriously difficult; a series of improvements over the span of two decades
witnessed the solution to two \$100 Erd\H{o}s problems, and the current record
due to Lange, Radziszowski, and Xu now stands at $f(2,3,4) \leq 786$, the proof
of which is computer-assisted.
  In this paper, we study Folkman-like properties of a sequence $H_q$ of finite
geometric graphs constructed using Hermitian unitals over projective planes
which were instrumental in the recent Mattheus-Verstra\"ete breakthrough on
off-diagonal Ramsey numbers. We show that for all prime powers $q \geq 4$,
there exists a subset $\mathcal{T}_q$ of triangles in $H_q$ such that no four
span a $K_4$ in $H_q$, but every two-coloring of $E(H_q)$ induces a
monochromatic triangle in $\mathcal{T}_q$. For $q=4$, this gives a graph on
$208$ vertices with this "quasi-Folkman" property. Moreover, we show that a
certain random alteration of $H_q$ which destroys all of its $K_4$'s will, for
large $q$, maintain the Ramsey property with high probability.

</details>


### [39] [Positive $m$-divisible non-crossing partitions and their Kreweras maps](https://arxiv.org/abs/2506.14996)
*Christian Krattenthaler,Christian Stump*

Main category: math.CO

TL;DR: 本文研究了正$m$可分非交叉分区及其正Kreweras映射，在经典类型中给出了组合实现，并证明了这些映射在圆环和环面上的伪旋转性质，最终建立了循环筛选现象。


<details>
  <summary>Details</summary>
Motivation: 探索正$m$可分非交叉分区的组合性质及其在经典与例外类型中的不变性，旨在建立更广泛的循环筛选理论框架。

Method: 在经典类型中通过非交叉集分区实现组合模型，在例外类型中开发新组合模型，并利用伪旋转和参数枚举进行分析。

Result: 成功描述了正Kreweras映射幂次下的不变分区，验证了循环筛选现象，并在经典与例外类型中均获得枚举结果。

Conclusion: 研究统一了正$m$可分非交叉分区的组合与几何表征，为循环筛选现象提供了多类型支持的理论依据。

Abstract: We study positive $m$-divisible non-crossing partitions and their positive
Kreweras maps. In classical types, we describe their combinatorial realisations
as certain non-crossing set partitions. We also realise these positive Kreweras
maps as pseudo-rotations on a circle, respectively on an annulus. We enumerate
positive $m$-divisible non-crossing partitions in classical types that are
invariant under powers of the positive Kreweras maps with respect to several
parameters. In order to cope with the exceptional types, we develop a different
combinatorial model in general type describing positive $m$-divisible
non-crossing partitions that are invariant under powers of the positive
Kreweras maps. We finally show that altogether these results establish several
cyclic sieving phenomena.

</details>


### [40] [Matroid complexes and Orlik-Solomon algebras](https://arxiv.org/abs/2506.15048)
*Basile Coron*

Main category: math.CO

TL;DR: 本文为超可解拟阵的Orlik-Solomon代数构建了一个组合拟自由微分分次模型，推广了Kontsevich为辫子排列引入的cdga，并证明该模型具有广义合作结构，进而用此模型新证明了超可解拟阵的Orlik-Solomon代数是Koszul的。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于将Kontsevich为辫子排列引入的cdga推广到拟阵框架下，构建超可解拟阵Orlik-Solomon代数的组合模型，并探索其代数性质。

Method: 方法基于拟阵理论的经典概念（如模性、单元素扩张、广义平行连接），构建拟自由微分分次模型，并证明其携带广义合作结构。

Result: 主要成果是成功构建了超可解拟阵Orlik-Solomon代数的组合模型，并证明该模型具有合作结构，同时给出了这些代数Koszul性的新证明。

Conclusion: 结论表明所构建的模型不仅推广了Kontsevich的工作，还为研究拟阵代数结构提供了新工具，特别适用于超可解拟阵的Koszul性证明。

Abstract: In this article we construct a combinatorial quasi-free differential graded
model for the Orlik-Solomon algebra of supersolvable matroids, which
generalizes in a matroidal setting the cdga of admissible graphs introduced by
M. Kontsevich for the braid arrangements. Our construction draws on well-known
concepts from matroid theory, including modularity, single-element extensions,
and generalized parallel connections. We also show that this model carries a
cooperadic structure in a suitably generalized sense. As an application, we use
this model to give a new proof that the Orlik-Solomon algebras of supersolvable
matroids are Koszul.

</details>


### [41] [Higher diameters of Cayley digraphs](https://arxiv.org/abs/2506.15137)
*G. C. Magda,J. Rubin,S. Streipert,C. Watt,A. Kumar,G. P. Constantine*

Main category: math.CO

TL;DR: 本文定义并研究了凯莱有向图的高阶直径。


<details>
  <summary>Details</summary>
Motivation: 探索凯莱有向图的高阶直径性质，以深化对图论中距离概念的理解。

Method: 通过数学定义和理论分析，引入并研究凯莱有向图的高阶直径。

Result: 提出了凯莱有向图高阶直径的定义，并初步探讨了其性质。

Conclusion: 凯莱有向图的高阶直径是一个值得深入研究的图论新方向。

Abstract: Higher diameters of Cayley digraphs are defined and studied.

</details>


### [42] [Antimagic labelings of a complete graph](https://arxiv.org/abs/2506.15221)
*Dr A. N. Bhavale*

Main category: math.CO

TL;DR: 本文证明了对于$n \geq 3$的完全图$K_n$，其不仅是超反魔图，还是全反魔全图，并且存在反魔定向。


<details>
  <summary>Details</summary>
Motivation: Hartsfield和Ringel在1990年提出了反魔图的概念，并猜想除$K_2$外，所有连通图（特别是树）都是反魔的。Hefetz等人在2010年进一步提出了两个问题：任何简单连通无向图的所有定向是否都是反魔的？以及对于任何无向图$G$，是否存在一个反魔定向？本文旨在回答这些问题。

Method: 本文利用了Bhavale提出的边标记方法，对给定的$n$个顶点且无孤立顶点的图进行标记，进而证明了完全图$K_n$的性质。

Result: 研究结果表明，对于$n \geq 3$的完全图$K_n$，其不仅是超反魔图，还是全反魔全图，并且存在一个反魔定向。

Conclusion: 本文通过Bhavale的标记方法，成功证明了完全图$K_n$在$n \geq 3$时的超反魔性和全反魔性，并确认了其反魔定向的存在性，为反魔图理论提供了新的结果。

Abstract: In $1990$, Hartsfield and Ringel introduced antimagic graphs. Hartsfield and
Ringel conjectured that every connected graph (and in particular, a tree)
except $K_2$ is antimagic. In $2010$, Hefetz et al.\ raised two questions: Is
every orientation of any simple connected undirected graph antimagic? and Given
any undirected graph $G$, does there exist an orientation of $G$ which is
antimagic? They call such an orientation an {\it antimagic orientation} of $G$.
Recently, Bhavale provided an edge labeling for a given graph on $n$ vertices
without isolated vertices. In this paper, using the labeling of Bhavale, we
prove that a complete graph $K_n$ for $n \geq 3$ is super antimagic as well as
totally antimagic total graph. We also prove that there exists an antimagic
orientation of $K_n$ for $n \geq 3$.

</details>


### [43] [Structured and Punctured Nullstellensätze](https://arxiv.org/abs/2506.15281)
*Erhard Aichinger,John R. Schmitt,Henry Zhan*

Main category: math.CO

TL;DR: 本文对多项式零点定理（Nullstellensatz）进行了推广，特别是对Schauz和Nica的结果进行了统一推广，并扩展了Alon和F\"uredi的非零计数定理至穿孔网格。


<details>
  <summary>Details</summary>
Motivation: 多项式零点定理在代数几何和组合数学中具有重要地位，如Hilbert的零点定理和Alon的组合零点定理。已有多种推广形式，但缺乏统一框架。本文旨在提供更一般的推广结果。

Method: 通过研究多元多项式除法中特定单项式的不变性，建立了一种新的理论框架。该方法结合了Schauz、Nica以及Ball和Serra的技术，并扩展了Clark的证明方法。

Result: 成功将Schauz和Nica的结果统一为一个更一般的定理，并进一步将Alon和F\"uredi的非零计数定理推广至穿孔网格（即形式为$X \setminus Y$的集合，其中$X,Y$为网格）。

Conclusion: 本文不仅统一了多项已有成果，还通过创新的方法扩展了多项式零点定理的应用范围，特别是在具有对称性的网格和穿孔网格上的应用。

Abstract: A Nullstellensatz is a theorem providing information on polynomials that
vanish on a certain set: David Hilbert's Nullstellensatz (1893) is a
cornerstone of algebraic geometry, and Noga Alon's Combinatorial
Nullstellensatz (1999) is a powerful tool in the "Polynomial Method", a
technique used in combinatorics. Alon's Theorem excludes that a polynomial
vanishing on a grid contains a monomial with certain properties. This theorem
has been generalized in several directions, two of which we will consider in
detail: Terence Tao and Van H. Vu (2006), Uwe Schauz (2008) and Micha\l{}
Laso\'n (2010) exclude more monomials, and recently, Bogdan Nica (2023)
improved the result for grids with additional symmetries in their side edges.
Simeon Ball and Oriol Serra (2009) incorporated the multiplicity of zeros and
gave Nullstellens\"atze for punctured grids, which are sets of the form $X
\setminus Y$ with both $X,Y$ grids.
  We generalize some of these results; in particular, we provide a common
generalization to the results of Schauz and Nica. To this end, we establish
that during multivariate polynomial division, certain monomials are unaffected.
This also allows us to generalize Pete L. Clark's proof of the nonzero counting
theorem by Alon and F\"uredi to punctured grids.

</details>


### [44] [Posets for Specht ideals of essential real reflection groups](https://arxiv.org/abs/2506.15335)
*Sebastian Debus,Kurt Klement Gottwald*

Main category: math.CO

TL;DR: 本文扩展了Specht理想理论至D型反射群和二面体群，完成了所有无限族实反射群的组合研究。


<details>
  <summary>Details</summary>
Motivation: Specht理想是由与群表示相关的Specht多项式生成的多项式环中的对称理想，此前仅在A型和B型反射群中研究过。为了全面理解其组合结构，需将其理论扩展至其他反射群。

Method: 研究将Specht理想的理论从A型和B型反射群推广至D型反射群和二面体群，分析其包含关系和簇结构。

Result: 成功将Specht理想理论扩展至D型反射群和二面体群，揭示了其丰富的组合结构，填补了理论空白。

Conclusion: 本研究完成了所有无限族实反射群中Specht理想的组合研究，为相关数学领域提供了完整的理论基础。

Abstract: Specht ideals are symmetric ideals in the polynomial ring generated by Specht
polynomials associated with group representations. These ideals were previously
studied for reflection groups of types $A$ and $B$, where their inclusion
relations and their varieties reflect rich combinatorial structures. In this
paper, we extend this theory to type $D$ and the dihedral groups. Our results
complete the combinatorial study of Specht ideals across all infinite families
of essential real reflection groups.

</details>


### [45] [Inverse eigenvalue problem for discrete Schrödinger operators of a graph](https://arxiv.org/abs/2506.15430)
*Anzila Laikhuram,Jephian C. -H. Lin*

Main category: math.CO

TL;DR: 本文研究了图的离散薛定谔算子的逆特征值问题，通过图结构限制和强性质分析，解决了最多5个顶点图的该问题。


<details>
  <summary>Details</summary>
Motivation: 离散薛定谔算子在振动理论和Colin de Verdi\`ere参数研究中具有重要作用，其逆特征值问题需要明确图的可能谱特征。

Method: 利用图结构的强性质，建立了超图引理、解放引理和分岔引理的类似版本，并基于这些结果进行分析。

Result: 研究结果表明，与图的逆特征值问题相比，离散薛定谔算子的解更为受限，并成功解决了最多5个顶点图的逆特征值问题。

Conclusion: 通过图结构限制和强性质分析，本文为离散薛定谔算子的逆特征值问题提供了解决方案，特别适用于小规模图。

Abstract: A discrete Schr\"odinger operator of a graph $G$ is a real symmetric matrix
whose $i,j$-entry, $i \neq j$, is negative if $\{i,j\}$ is an edge and zero if
it is not an edge, while diagonal entries can be any real numbers. The discrete
Schr\"odinger operators have been used to study vibration theory and the Colin
de Verdi\`ere parameter. The inverse eigenvalue problem for discrete
Schr\"odinger operators of a graph aims to characterize the possible spectra
among discrete Schr\"odinger operators of a graph. Comparing to the inverse
eigenvalue problem of a graph, the answers turn out to be more limited, and
several restrictions based on graph structure are given. Using the strong
properties, analogous versions of the supergraph lemma, the liberation lemma,
and the bifurcation lemma are established. Using these results, the inverse
eigenvalue problem for discrete Schr\"odinger operators is resolved for each
graph with at most $5$ vertices.

</details>


### [46] [Is it easy to regularize a hypergraph with easy links?](https://arxiv.org/abs/2506.15582)
*Lior Gishboliner,Asaf Shapira,Yuval Wigderson*

Main category: math.CO

TL;DR: 本文改进了Terry和Wolf关于3-图同质分割的结果，将双指数界提升至单指数界，并证明该界最优。同时推广到所有k≥3的一致超图，并揭示了顶点链接具有多项式大小ε-正则分割时，3-图仍可能仅具有塔型大小正则分割的反直觉现象。


<details>
  <summary>Details</summary>
Motivation: 研究超图存在小ε-正则分割的条件是广泛研究计划的一部分。尽管图的情况已被较好理解，但对3-图及以上超图的情况仍知之甚少。本文旨在探索顶点链接具有多项式大小ε-同质分割时，整个3-图是否必然存在小同质分割。

Method: 通过构造性证明和反例分析，首先改进Terry的双指数界至单指数界，并验证其最优性；其次考察仅要求顶点链接具有多项式大小ε-正则分割时，证明整个3-图的正则分割大小可能爆炸至塔型函数。

Result: 1) 推翻Terry猜想，证明3-图同质分割存在单指数界且不可改进；2) 该结果可推广至所有k≥3一致超图；3) 发现顶点链接具有多项式正则分割时，整体正则分割仍可能需塔型大小的反例。

Conclusion: 超图正则分割问题在k≥3时展现出与图论截然不同的复杂性：即使局部条件（顶点链接）具备良好分割性质，整体分割复杂度仍可能急剧增长。这为超图正则性理论建立了新的边界认知。

Abstract: A partition of a (hyper)graph is $\varepsilon$-homogenous if the edge
densities between almost all clusters are either at most $\varepsilon$ or at
least $1-\varepsilon$. Suppose a $3$-graph has the property that the link of
every vertex has an $\varepsilon$-homogenous partition of size
$\text{poly}(1/\varepsilon)$. Does this guarantee that the $3$-graph also has a
small homogenous partition? Terry and Wolf proved that such a $3$-graph has an
$\varepsilon$-homogenous partition of size given by a wowzer-type function.
Terry recently improved this to a double exponential bound, and conjectured
that this bound is tight. Our first result in this paper disproves this
conjecture by giving an improved (single) exponential bound, which is best
possible. We further obtain an analogous result for $k$-graphs of all
uniformities $k \geq 3$.
  The above problem is part of a much broader programme which seeks to
understand the conditions under which a (hyper)graph has small
$\varepsilon$-regular partitions. While this problem is fairly well understood
for graphs, the situation is (as always) much more involved already for
$3$-graphs. For example, it is natural to ask if one can strengthen our first
result by only requiring each link to have $\varepsilon$-regular partitions of
size $\text{poly}(1/\varepsilon)$. Our second result shows that surprisingly
the answer is `no', namely, a $3$-graph might only have regular partitions of
tower-type size, even though the link of every vertex has an
$\varepsilon$-regular partition of polynomial size.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [47] [Winter Soldier: Backdooring Language Models at Pre-Training with Indirect Data Poisoning](https://arxiv.org/abs/2506.14913)
*Wassim Bouaziz,Mathurin Videau,Nicolas Usunier,El-Mahdi El-Mhamdi*

Main category: cs.CR

TL;DR: 本文提出了一种间接数据投毒方法，通过梯度优化的提示调校使语言模型学习训练数据中不存在的秘密序列，实现了高效的数据集保护和溯源，且不影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)预训练依赖来源复杂的大规模文本数据，现有数据溯源方法依赖训练数据记忆性，而模型提供方会限制这种记忆。本研究探索不依赖记忆性的间接数据投毒方案。

Method: 采用基于梯度优化的提示调校技术，使模型学习训练语料中不存在的'秘密提示-秘密响应'序列。在从头预训练的模型上验证，仅需污染不到0.005%的token。

Result: 该方法能以极高置信度($p < 10^{-55}$)检测秘密序列，且具有理论可证明性。关键的是，模型在标准评测中性能无下降，且秘密序列从未出现在训练集中。

Conclusion: 间接数据投毒不仅可行，还能有效实现数据集保护和溯源。该方法突破了传统依赖数据记忆的限制，为LLM训练数据监管提供了新思路。

Abstract: The pre-training of large language models (LLMs) relies on massive text
datasets sourced from diverse and difficult-to-curate origins. Although
membership inference attacks and hidden canaries have been explored to trace
data usage, such methods rely on memorization of training data, which LM
providers try to limit. In this work, we demonstrate that indirect data
poisoning (where the targeted behavior is absent from training data) is not
only feasible but also allow to effectively protect a dataset and trace its
use. Using gradient-based optimization prompt-tuning, we make a model learn
arbitrary secret sequences: secret responses to secret prompts that are absent
from the training corpus. We validate our approach on language models
pre-trained from scratch and show that less than 0.005% of poisoned tokens are
sufficient to covertly make a LM learn a secret and detect it with extremely
high confidence ($p < 10^{-55}$) with a theoretically certifiable scheme.
Crucially, this occurs without performance degradation (on LM benchmarks) and
despite secrets never appearing in the training set.

</details>


### [48] [Fair Data Exchange with Constant-Time Proofs](https://arxiv.org/abs/2506.14944)
*Majid Khabbazian*

Main category: cs.CR

TL;DR: 本文提出了一种改进的公平数据交换协议，通过将文件视为Reed-Solomon编码字并扩展为低速率编码，实现了证明和验证时间的常数级开销，同时保持了完全的客户端和服务器公平性。


<details>
  <summary>Details</summary>
Motivation: 现有的公平数据交换协议虽然实现了按文件付费的原子传输和恒定大小的证明，但其证明者和验证者的运行时间仍与文件长度线性相关，需要优化。

Method: 将文件视为速率1的Reed-Solomon编码字，扩展为具有恒定冗余的低速率编码，加密后仅对少量随机密文子集进行正确性证明，利用RS解码修复损坏符号。

Result: 协议将证明和验证成本降低至接近常数，保持了完全的公平性，仅增加了可调的通信冗余开销，并通过zk-SNARK修复了比特币实现中的椭圆曲线不匹配问题。

Conclusion: 改进后的协议在链下运行整个交换过程，仅在通道不可用时需要两次链上交易，显著提升了效率和实用性。

Abstract: The Fair Data Exchange (FDE) protocol introduced at CCS 2024 offers atomic
pay-per-file transfers with constant-size proofs, but its prover and verifier
runtimes still scale linearly with the file length n. We collapse these costs
to essentially constant by viewing the file as a rate-1 Reed-Solomon (RS)
codeword, extending it to a lower-rate RS code with constant redundancy,
encrypting this extended vector, and then proving correctness for only a small
random subset of the resulting ciphertexts; RS decoding repairs any corrupted
symbols with negligible failure probability. Our protocol preserves full
client- and server-fairness, and adds only a tunable communication redundancy
overhead.
  Finally, we patch the elliptic-curve mismatch in the Bitcoin instantiation of
FDE with a compact zk-SNARK, enabling the entire exchange to run off-chain and
falling back to just two on-chain transactions when channels are unavailable.

</details>


### [49] [Narrowing the Gap between TEEs Threat Model and Deployment Strategies](https://arxiv.org/abs/2506.14964)
*Filip Rezabek,Jonathan Passerat-Palmbach,Moe Mahhouk,Frieder Erdmann,Andrew Miller*

Main category: cs.CR

TL;DR: 保密虚拟机(CVMs)虽提供数据使用隔离，但缺乏物理层面防护和侧信道攻击防御，需依赖可信云提供商。当前TEE认证未绑定运营商信息，导致用户无法评估物理攻击风险。论文提出通过PPID等方案扩展认证机制以解决这一关键限制。


<details>
  <summary>Details</summary>
Motivation: 现有CVMs威胁模型存在错位：仅防护租户间攻击，却未向外部用户提供不依赖云服务商的端到端安全保障。TEE认证未包含运营商信息，导致物理攻击风险难以评估。

Method: 提出利用受保护平台标识符(PPID)等方案将CVM与云服务商绑定，并探讨TEE认证机制的强化与扩展路径。需解决不同TEE厂商实现差异、认证流程异构等互操作性挑战。

Result: 分析表明当前TEE认证存在关键局限：认证验证困难、迁移复杂度高、应用开发仍需可信第三方，这些因素阻碍CVMs的广泛采用。

Conclusion: 必须扩展TEE认证机制以包含运营商绑定信息，通过PPID等方案解决物理攻击风险盲区，同时需标准化实现以提升互操作性，这是CVMs大规模应用的前提条件。

Abstract: Confidential Virtual Machines (CVMs) provide isolation guarantees for data in
use, but their threat model does not include physical level protection and
side-channel attacks. Therefore, current deployments rely on trusted cloud
providers to host the CVMs' underlying infrastructure. However, TEE
attestations do not provide information about the operator hosting a CVM.
Without knowing whether a Trusted Execution Environment (TEE) runs within a
provider's infrastructure, a user cannot accurately assess the risks of
physical attacks. We observe a misalignment in the threat model where the
workloads are protected against other tenants but do not offer end-to-end
security assurances to external users without relying on cloud providers. The
attestation should be extended to bind the CVM with the provider. A possible
solution can rely on the Protected Platform Identifier (PPID), a unique CPU
identifier. However, the implementation details of various TEE manufacturers,
attestation flows, and providers vary. This makes verification of attestations,
ease of migration, and building applications without relying on a trusted party
challenging, highlighting a key limitation that must be addressed for the
adoption of CVMs. We discuss two points focusing on hardening and extensions of
TEEs' attestation.

</details>


### [50] [Private Continual Counting of Unbounded Streams](https://arxiv.org/abs/2506.15018)
*Ben Jacobsen,Kassem Fawaz*

Main category: cs.CR

TL;DR: 本文提出了一种新颖的差分隐私连续计数算法，适用于输入规模未知的无界场景，通过基于对数扰动的矩阵分解方法实现了平滑误差和高效性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于矩阵机制的最优算法需要预先知道输入规模$n$，而常见的'倍增技巧'会导致次优和非平滑误差。本文旨在解决无界场景下的差分隐私连续计数问题。

Method: 引入基于函数$\frac{1}{\sqrt{1-z}}$对数扰动的新型矩阵分解方法，该函数在先前研究中被广泛研究。算法空间复杂度为$O(t)$，每轮摊销时间复杂度为$O(\log t)$。

Result: 对于任意$\alpha > 0$和$t\leq n$，算法能以$O(\log^{2+2\alpha}(t))$方差私有估计前$t$个数据点的和。实证显示当$t$高达$2^{24}$时，方差仅为Henzinger等人算法的1.5倍。

Conclusion: 该算法在无界场景下实现了与有界场景最优算法可比的性能，且具有平滑误差特性，其矩阵分解方法可能具有独立研究价值。

Abstract: We study the problem of differentially private continual counting in the
unbounded setting where the input size $n$ is not known in advance. Current
state-of-the-art algorithms based on optimal instantiations of the matrix
mechanism cannot be directly applied here because their privacy guarantees only
hold when key parameters are tuned to $n$. Using the common `doubling trick'
avoids knowledge of $n$ but leads to suboptimal and non-smooth error. We solve
this problem by introducing novel matrix factorizations based on logarithmic
perturbations of the function $\frac{1}{\sqrt{1-z}}$ studied in prior works,
which may be of independent interest. The resulting algorithm has smooth error,
and for any $\alpha > 0$ and $t\leq n$ it is able to privately estimate the sum
of the first $t$ data points with $O(\log^{2+2\alpha}(t))$ variance. It
requires $O(t)$ space and amortized $O(\log t)$ time per round, compared to
$O(\log(n)\log(t))$ variance, $O(n)$ space and $O(n \log n)$ pre-processing
time for the nearly-optimal bounded-input algorithm of Henzinger et al. (SODA
2023). Empirically, we find that our algorithm's performance is also comparable
to theirs in absolute terms: our variance is less than $1.5\times$ theirs for
$t$ as large as $2^{24}$.

</details>


### [51] [Systems-Theoretic and Data-Driven Security Analysis in ML-enabled Medical Devices](https://arxiv.org/abs/2506.15028)
*Gargi Mitra,Mohammadreza Hallajiyan,Inji Kim,Athish Pranav Dharmalingam,Mohammed Elnawawy,Shahrear Iqbal,Karthik Pattabiraman,Homa Alemzadeh*

Main category: cs.CR

TL;DR: AI/ML在医疗设备中的应用虽提升了诊疗能力，但也带来了严重的网络安全风险。本文强调需在上市前解决这些挑战，并提出了一套工具帮助进行全面的风险评估。


<details>
  <summary>Details</summary>
Motivation: AI/ML医疗设备的复杂性和互联性增加了网络安全风险，可能导致模型误预测，威胁患者安全，因此需在设计阶段就确保设备安全。

Method: 通过分析公开的设备召回、不良事件和已知漏洞数据，理解AI/ML医疗设备的威胁态势，并设计了一套工具帮助安全分析师进行上市前风险评估。

Result: 提出了一套工具和技术，旨在帮助制造商将网络安全作为AI/ML医疗设备的核心设计原则，从而确保患者安全。

Conclusion: 在AI/ML医疗设备的上市前阶段解决网络安全问题至关重要，本文的工具和方法有助于制造商在设计阶段嵌入安全原则，保障患者安全。

Abstract: The integration of AI/ML into medical devices is rapidly transforming
healthcare by enhancing diagnostic and treatment facilities. However, this
advancement also introduces serious cybersecurity risks due to the use of
complex and often opaque models, extensive interconnectivity, interoperability
with third-party peripheral devices, Internet connectivity, and vulnerabilities
in the underlying technologies. These factors contribute to a broad attack
surface and make threat prevention, detection, and mitigation challenging.
Given the highly safety-critical nature of these devices, a cyberattack on
these devices can cause the ML models to mispredict, thereby posing significant
safety risks to patients. Therefore, ensuring the security of these devices
from the time of design is essential. This paper underscores the urgency of
addressing the cybersecurity challenges in ML-enabled medical devices at the
pre-market phase. We begin by analyzing publicly available data on device
recalls and adverse events, and known vulnerabilities, to understand the threat
landscape of AI/ML-enabled medical devices and their repercussions on patient
safety. Building on this analysis, we introduce a suite of tools and techniques
designed by us to assist security analysts in conducting comprehensive
premarket risk assessments. Our work aims to empower manufacturers to embed
cybersecurity as a core design principle in AI/ML-enabled medical devices,
thereby making them safe for patients.

</details>


### [52] [MECHA: Multithreaded and Efficient Cryptographic Hardware Access](https://arxiv.org/abs/2506.15034)
*Pratama Derry,Laksmono Agus Mahardika Ari,Iqbal Muhammad,Howon Kim*

Main category: cs.CR

TL;DR: 本文提出了一种多线程高效加密硬件访问框架(MECHA)，通过UNIX域套接字管理多应用请求，显著提升加密操作效率，实验显示并发请求速度提升83%。


<details>
  <summary>Details</summary>
Motivation: 传统加密接口存在上下文切换开销，MECHA旨在消除该瓶颈，为云计算和物联网等场景提供高效并发加密解决方案。

Method: 采用Server线程、Client线程、Transceiver线程及Sender/Receiver队列结构，支持任意通信协议的无缝移植。

Result: 实验数据表明，相比传统设计，MECHA使并发加密请求处理速度提升83%。

Conclusion: MECHA架构在安全通信领域具有重要应用潜力，能高效管理并发加密请求，适用于从云计算到物联网的广泛场景。

Abstract: This paper presents a multithread and efficient cryptographic hardware access
(MECHA) for efficient and fast cryptographic operations that eliminates the
need for context switching. Utilizing a UNIX domain socket, MECHA manages
multiple requests from multiple applications simultaneously, resulting in
faster processing and improved efficiency. We comprise several key components,
including the Server thread, Client thread, Transceiver thread, and a pair of
Sender and Receiver queues. MECHA design is portable and can be used with any
communication protocol, with experimental results demonstrating a 83% increase
in the speed of concurrent cryptographic requests compared to conventional
interface design. MECHA architecture has significant potential in the field of
secure communication applications ranging from cloud computing to the IoT,
offering a faster and more efficient solution for managing multiple
cryptographic operation requests concurrently.

</details>


### [53] [Advanced Prediction of Hypersonic Missile Trajectories with CNN-LSTM-GRU Architectures](https://arxiv.org/abs/2506.15043)
*Amir Hossein Baradaran*

Main category: cs.CR

TL;DR: 本文提出了一种新型混合深度学习模型，结合CNN、LSTM和GRU网络，用于高精度预测高超音速导弹的复杂轨迹，显著提升了防御系统的预测能力。


<details>
  <summary>Details</summary>
Motivation: 高超音速导弹因其极速和高机动性对国家安全构成重大威胁，准确预测其轨迹是实施有效拦截的关键。

Method: 采用卷积神经网络（CNN）、长短期记忆网络（LSTM）和门控循环单元（GRU）相结合的混合深度学习架构，充分利用各模型的优势进行轨迹预测。

Result: 所提出的方法能够高精度预测高超音速导弹的复杂轨迹，为防御策略和导弹拦截技术提供了重要支持。

Conclusion: 研究表明，先进机器学习技术能显著增强防御系统的预测能力，为应对高超音速导弹威胁提供了有效解决方案。

Abstract: Advancements in the defense industry are paramount for ensuring the safety
and security of nations, providing robust protection against emerging threats.
Among these threats, hypersonic missiles pose a significant challenge due to
their extreme speeds and maneuverability, making accurate trajectory prediction
a critical necessity for effective countermeasures. This paper addresses this
challenge by employing a novel hybrid deep learning approach, integrating
Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM) networks,
and Gated Recurrent Units (GRUs). By leveraging the strengths of these
architectures, the proposed method successfully predicts the complex
trajectories of hypersonic missiles with high accuracy, offering a significant
contribution to defense strategies and missile interception technologies. This
research demonstrates the potential of advanced machine learning techniques in
enhancing the predictive capabilities of defense systems.

</details>


### [54] [Toward a Lightweight, Scalable, and Parallel Secure Encryption Engine](https://arxiv.org/abs/2506.15070)
*Rasha Karakchi,Rye Stahle-Smith,Nishant Chinnasami,Tiffany Yu*

Main category: cs.CR

TL;DR: 本文提出SPiME，一种轻量级、可扩展且兼容FPGA的安全内存处理器加密架构，通过将AES-128直接集成到内存处理框架中，显著提升了边缘计算中的数据加密效率。


<details>
  <summary>Details</summary>
Motivation: 物联网应用的指数增长加剧了对高效、高吞吐量和节能的边缘数据处理的迫切需求。传统的以CPU为中心的加密方法在延迟敏感和资源受限的环境中面临性能瓶颈和数据移动过大的问题。

Method: SPiME架构采用模块化并行内存处理单元阵列，每个单元结合AES核心和最小控制单元，实现分布式就地加密，并通过Verilog实现并在AMD UltraScale和UltraScale+ FPGA上进行测试。

Result: 评估结果显示，SPiME可扩展到超过4000个并行单元，同时在高性能设备上保持关键FPGA资源利用率低于5%，并实现超过25 Gbps的持续加密吞吐量，具有可预测的低延迟性能。

Conclusion: SPiME架构的可移植性、可配置性和资源效率使其成为安全边缘计算、嵌入式加密系统和可定制硬件加速器的理想解决方案。

Abstract: The exponential growth of Internet of Things (IoT) applications has
intensified the demand for efficient, high-throughput, and energy-efficient
data processing at the edge. Conventional CPU-centric encryption methods suffer
from performance bottlenecks and excessive data movement, especially in
latency-sensitive and resource-constrained environments. In this paper, we
present SPiME, a lightweight, scalable, and FPGA-compatible Secure
Processor-in-Memory Encryption architecture that integrates the Advanced
Encryption Standard (AES-128) directly into a Processing-in-Memory (PiM)
framework. SPiME is designed as a modular array of parallel PiM units, each
combining an AES core with a minimal control unit to enable distributed
in-place encryption with minimal overhead. The architecture is fully
implemented in Verilog and tested on multiple AMD UltraScale and UltraScale+
FPGAs. Evaluation results show that SPiME can scale beyond 4,000 parallel units
while maintaining less than 5\% utilization of key FPGA resources on high-end
devices. It delivers over 25~Gbps in sustained encryption throughput with
predictable, low-latency performance. The design's portability,
configurability, and resource efficiency make it a compelling solution for
secure edge computing, embedded cryptographic systems, and customizable
hardware accelerators.

</details>


### [55] [CWGAN-GP Augmented CAE for Jamming Detection in 5G-NR in Non-IID Datasets](https://arxiv.org/abs/2506.15075)
*Samhita Kuili,Mohammadreza Amini,Burak Kantarci*

Main category: cs.CR

TL;DR: 本文提出了一种基于卷积自编码器(CAE)的5G-NR无线网络干扰检测方法，通过生成对抗网络(CWGAN-GP)解决数据不平衡问题，在复杂异构数据集上实现了优于对比模型的检测性能。


<details>
  <summary>Details</summary>
Motivation: 5G-NR网络中普遍存在的空中干扰攻击会严重影响信号接收质量，需要开发鲁棒的干扰检测方法应对异构I/Q数据集、同步信号块(SSB)特征提取及数据不平衡等挑战。

Method: 采用加性高斯白噪声(AWGN)模拟干扰环境，利用卷积自编码器(CAE)进行干扰检测，并通过Conv1D条件Wasserstein生成对抗网络(CWGAN-GP)对多数类和少数类SSB观测数据进行平衡处理。

Result: CAE模型在增强数据集上表现出色，平均精确率97.33%、召回率91.33%、F1分数94.08%、准确率94.35%，性能显著优于卷积去噪自编码器(CDAE)和卷积稀疏自编码器(CSAE)。

Conclusion: 研究表明CAE模型能有效应对数据异构性挑战，在5G-NR网络干扰检测中展现出强大的鲁棒性，为实际应用提供了可靠解决方案。

Abstract: In the ever-expanding domain of 5G-NR wireless cellular networks,
over-the-air jamming attacks are prevalent as security attacks, compromising
the quality of the received signal. We simulate a jamming environment by
incorporating additive white Gaussian noise (AWGN) into the real-world In-phase
and Quadrature (I/Q) OFDM datasets. A Convolutional Autoencoder (CAE) is
exploited to implement a jamming detection over various characteristics such as
heterogenous I/Q datasets; extracting relevant information on Synchronization
Signal Blocks (SSBs), and fewer SSB observations with notable class imbalance.
Given the characteristics of datasets, balanced datasets are acquired by
employing a Conv1D conditional Wasserstein Generative Adversarial
Network-Gradient Penalty(CWGAN-GP) on both majority and minority SSB
observations. Additionally, we compare the performance and detection ability of
the proposed CAE model on augmented datasets with benchmark models:
Convolutional Denoising Autoencoder (CDAE) and Convolutional Sparse Autoencoder
(CSAE). Despite the complexity of data heterogeneity involved across all
datasets, CAE depicts the robustness in detection performance of jammed signal
by achieving average values of 97.33% precision, 91.33% recall, 94.08%
F1-score, and 94.35% accuracy over CDAE and CSAE.

</details>


### [56] [Flexible Hardware-Enabled Guarantees for AI Compute](https://arxiv.org/abs/2506.15093)
*James Petrie,Onni Aarne,Nora Ammann,David Dalrymple*

Main category: cs.CR

TL;DR: 本文提出了一种名为flexHEGs的硬件保障系统，旨在通过可审计的处理器和安全外壳解决AI发展中的国际安全与隐私保护问题。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统日益强大，其对国际安全的威胁与日俱增，现有治理方法难以在不泄露敏感信息或国家安全的前提下有效应对这些挑战。

Method: flexHEGs系统由可审计的保障处理器和安全外壳组成，前者监控加速器使用情况，后者提供物理防篡改保护。系统完全开源，具备灵活可更新的验证能力。

Result: flexHEGs能够支持多种治理机制，包括隐私保护模型评估、受控部署、训练计算限制和自动安全协议执行。

Conclusion: 尽管技术挑战巨大，flexHEGs为解决前沿AI发展中的监管和国际安全问题提供了一种可行方案。

Abstract: As artificial intelligence systems become increasingly powerful, they pose
growing risks to international security, creating urgent coordination
challenges that current governance approaches struggle to address without
compromising sensitive information or national security. We propose flexible
hardware-enabled guarantees (flexHEGs), that could be integrated with AI
accelerators to enable trustworthy, privacy-preserving verification and
enforcement of claims about AI development. FlexHEGs consist of an auditable
guarantee processor that monitors accelerator usage and a secure enclosure
providing physical tamper protection. The system would be fully open source
with flexible, updateable verification capabilities. FlexHEGs could enable
diverse governance mechanisms including privacy-preserving model evaluations,
controlled deployment, compute limits for training, and automated safety
protocol enforcement. In this first part of a three part series, we provide a
comprehensive introduction of the flexHEG system, including an overview of the
governance and security capabilities it offers, its potential development and
adoption paths, and the remaining challenges and limitations it faces. While
technically challenging, flexHEGs offer an approach to address emerging
regulatory and international security challenges in frontier AI development.

</details>


### [57] [International Security Applications of Flexible Hardware-Enabled Guarantees](https://arxiv.org/abs/2506.15100)
*Onni Aarne,James Petrie*

Main category: cs.CR

TL;DR: 本文探讨了灵活硬件保障技术（flexHEGs）如何通过标准化设计、生态系统防御和明确的操作参数，为国际可信AI治理提供技术基础，以应对恶意使用、失控风险、军事AI系统风险及战略稳定等安全挑战。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术快速发展，flexHEGs为解决国际安全挑战提供了新机遇，需建立全面的治理框架来管理AI相关芯片的风险，确保国际安全与稳定。

Method: 研究分析了flexHEGs在四种国际安全场景中的应用，比较了基于验证的协议和基于规则集的协议两种治理模型，并通过博弈论分析评估了全面flexHEG协议的稳定性。

Result: 博弈论分析表明，在合理的国家偏好和灾难性风险假设下，全面的flexHEG协议可以保持稳定，但需解决技术门槛、现有硬件管理及治理权力滥用等实施挑战。

Conclusion: 尽管需要广泛的国际协调，flexHEGs仍可能为管理AI风险提供必要的技术基础，以应对国际安全与稳定面临的新兴威胁。

Abstract: As AI capabilities advance rapidly, flexible hardware-enabled guarantees
(flexHEGs) offer opportunities to address international security challenges
through comprehensive governance frameworks. This report examines how flexHEGs
could enable internationally trustworthy AI governance by establishing
standardized designs, robust ecosystem defenses, and clear operational
parameters for AI-relevant chips. We analyze four critical international
security applications: limiting proliferation to address malicious use,
implementing safety norms to prevent loss of control, managing risks from
military AI systems, and supporting strategic stability through
balance-of-power mechanisms while respecting national sovereignty. The report
explores both targeted deployments for specific high-risk facilities and
comprehensive deployments covering all AI-relevant compute. We examine two
primary governance models: verification-based agreements that enable
transparent compliance monitoring, and ruleset-based agreements that
automatically enforce international rules through cryptographically-signed
updates. Through game-theoretic analysis, we demonstrate that comprehensive
flexHEG agreements could remain stable under reasonable assumptions about state
preferences and catastrophic risks. The report addresses critical
implementation challenges including technical thresholds for AI-relevant chips,
management of existing non-flexHEG hardware, and safeguards against abuse of
governance power. While requiring significant international coordination,
flexHEGs could provide a technical foundation for managing AI risks at the
scale and speed necessary to address emerging threats to international security
and stability.

</details>


### [58] [EVA-S2PMLP: Secure and Scalable Two-Party MLP via Spatial Transformation](https://arxiv.org/abs/2506.15102)
*Shizhao Peng,Shoumo Li,Tianle Tao*

Main category: cs.CR

TL;DR: 本文提出EVA-S2PMLP框架，一种高效、可验证且准确的安全两方多层感知器方案，通过空间尺度优化提升隐私保护与性能，在金融、医疗等跨机构场景中实现隐私保护的神经网络训练。


<details>
  <summary>Details</summary>
Motivation: 垂直分区场景下的隐私保护神经网络训练对跨机构安全协作建模至关重要，需解决实数域可靠计算与通信开销大的问题。

Method: 提出安全转换管道将标量输入映射至向量/矩阵空间，包含线性/非线性安全计算的原子协议模块，支持安全激活、矩阵运算及损失评估。

Result: 理论验证协议可靠性，实验显示通信开销降低12.3倍，基准数据集上模型效用与数据保密性兼得。

Conclusion: EVA-S2PMLP在保证严格数据机密性的同时维持模型实用性，为跨组织AI应用提供实用解决方案。

Abstract: Privacy-preserving neural network training in vertically partitioned
scenarios is vital for secure collaborative modeling across institutions. This
paper presents \textbf{EVA-S2PMLP}, an Efficient, Verifiable, and Accurate
Secure Two-Party Multi-Layer Perceptron framework that introduces spatial-scale
optimization for enhanced privacy and performance. To enable reliable
computation under real-number domain, EVA-S2PMLP proposes a secure
transformation pipeline that maps scalar inputs to vector and matrix spaces
while preserving correctness. The framework includes a suite of atomic
protocols for linear and non-linear secure computations, with modular support
for secure activation, matrix-vector operations, and loss evaluation.
Theoretical analysis confirms the reliability, security, and asymptotic
complexity of each protocol. Extensive experiments show that EVA-S2PMLP
achieves high inference accuracy and significantly reduced communication
overhead, with up to $12.3\times$ improvement over baselines. Evaluation on
benchmark datasets demonstrates that the framework maintains model utility
while ensuring strict data confidentiality, making it a practical solution for
privacy-preserving neural network training in finance, healthcare, and
cross-organizational AI applications.

</details>


### [59] [PDLRecover: Privacy-preserving Decentralized Model Recovery with Machine Unlearning](https://arxiv.org/abs/2506.15112)
*Xiangman Li,Xiaodong Wu,Jianbing Ni,Mohamed Mahmoud,Maazen Alsabaan*

Main category: cs.CR

TL;DR: 本文提出PDLRecover方法，通过利用历史模型信息高效恢复被投毒攻击破坏的全局模型，同时保护隐私并减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 去中心化学习易受投毒攻击，现有防御方法难以恢复已受损的全局模型，而直接重训练存在效率、一致性和隐私问题。

Method: PDLRecover利用近似Hessian矩阵计算的线性特性，结合秘密共享技术保护历史更新数据，采用客户端准备、周期性恢复更新和最终精确更新三阶段确保模型鲁棒性与收敛性。

Result: 实验表明恢复后的全局模型性能接近完全重训练模型，计算和时间成本显著降低，且有效防止了本地模型参数泄漏。

Conclusion: PDLRecover在保证恢复准确性的同时实现了隐私保护，为去中心化学习中的模型恢复提供了高效解决方案。

Abstract: Decentralized learning is vulnerable to poison attacks, where malicious
clients manipulate local updates to degrade global model performance. Existing
defenses mainly detect and filter malicious models, aiming to prevent a limited
number of attackers from corrupting the global model. However, restoring an
already compromised global model remains a challenge. A direct approach is to
remove malicious clients and retrain the model using only the benign clients.
Yet, retraining is time-consuming, computationally expensive, and may
compromise model consistency and privacy.
  We propose PDLRecover, a novel method to recover a poisoned global model
efficiently by leveraging historical model information while preserving
privacy. The main challenge lies in protecting shared historical models while
enabling parameter estimation for model recovery. By exploiting the linearity
of approximate Hessian matrix computation, we apply secret sharing to protect
historical updates, ensuring local models are not leaked during transmission or
reconstruction. PDLRecover introduces client-side preparation, periodic
recovery updates, and a final exact update to ensure robustness and convergence
of the recovered model. Periodic updates maintain accurate curvature
information, and the final step ensures high-quality convergence. Experiments
show that the recovered global model achieves performance comparable to a fully
retrained model but with significantly reduced computation and time cost.
Moreover, PDLRecover effectively prevents leakage of local model parameters,
ensuring both accuracy and privacy in recovery.

</details>


### [60] [CipherMind: The Longest Codebook in the World](https://arxiv.org/abs/2506.15117)
*Ming Nie,Zhixiong Yang,Bingsheng Wei*

Main category: cs.CR

TL;DR: 本文提出CipherMind，利用大语言模型推理的确定性微调中间结果作为传输内容，实现通信加密。该方法适用于网关内传输等场景，理论上可基于任何大模型实现。


<details>
  <summary>Details</summary>
Motivation: 受大语言模型广泛应用的启发，作者探索利用其推理过程实现通信加密。大模型的语义参数具有底层实现不透明、可解释性弱的特点，适合作为加密手段。

Method: 通过确定性微调大模型推理过程，提取中间结果作为加密传输内容。该方法不依赖传统加密算法，而是利用大模型本身的特性实现信息隐藏。

Result: 提出的CipherMind框架证明大模型中间结果可用于安全通信，特别适用于网关内传输等特定场景。理论分析表明该方案具有普适性，可基于各类大模型实现。

Conclusion: 研究表明大语言模型的推理过程可创新性地应用于通信加密领域，为安全传输提供了新范式。该方法拓展了大模型的应用边界，具有重要实践价值。

Abstract: In recent years, the widespread application of large language models has
inspired us to consider using inference for communication encryption. We
therefore propose CipherMind, which utilizes intermediate results from
deterministic fine-tuning of large model inferences as transmission content.
The semantic parameters of large models exhibit characteristics like opaque
underlying implementations and weak interpretability, thus enabling their use
as an encryption method for data transmission. This communication paradigm can
be applied in scenarios like intra-gateway transmission, and theoretically, it
can be implemented using any large model as its foundation.

</details>


### [61] [RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments](https://arxiv.org/abs/2506.15253)
*Yuchuan Fu,Xiaohan Yuan,Dongxia Wang*

Main category: cs.CR

TL;DR: 本文介绍了RAS-Eval，一个针对大型语言模型（LLM）代理在动态环境中的安全评估基准，包含80个测试用例和3,802个攻击任务，覆盖11个CWE类别。评估显示攻击平均降低任务完成率36.78%，学术环境中成功率高达85.65%。


<details>
  <summary>Details</summary>
Motivation: 由于LLM代理在医疗和金融等关键领域的快速部署，亟需建立标准化的安全评估基准以应对动态环境中的安全挑战。

Method: 研究团队开发了RAS-Eval基准，支持模拟和真实工具执行，测试用例涵盖JSON、LangGraph和MCP格式，并评估了6种先进LLM模型在不同场景下的表现。

Result: 攻击显著降低了代理的任务完成率（平均36.78%），学术环境攻击成功率高达85.65%。研究还发现安全能力符合缩放定律，大模型表现优于小模型。

Conclusion: 研究揭示了现实世界LLM代理部署的重大安全风险，为未来安全研究提供了基础框架。代码和数据已开源。

Abstract: The rapid deployment of Large language model (LLM) agents in critical domains
like healthcare and finance necessitates robust security frameworks. To address
the absence of standardized evaluation benchmarks for these agents in dynamic
environments, we introduce RAS-Eval, a comprehensive security benchmark
supporting both simulated and real-world tool execution. RAS-Eval comprises 80
test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration
(CWE) categories, with tools implemented in JSON, LangGraph, and Model Context
Protocol (MCP) formats. We evaluate 6 state-of-the-art LLMs across diverse
scenarios, revealing significant vulnerabilities: attacks reduced agent task
completion rates (TCR) by 36.78% on average and achieved an 85.65% success rate
in academic settings. Notably, scaling laws held for security capabilities,
with larger models outperforming smaller counterparts. Our findings expose
critical risks in real-world agent deployments and provide a foundational
framework for future security research. Code and data are available at
https://github.com/lanzer-tree/RAS-Eval.

</details>


### [62] [From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem](https://arxiv.org/abs/2506.15170)
*Yanxu Mao,Tiehan Cui,Peipei Liu,Datao You,Hongsong Zhu*

Main category: cs.CR

TL;DR: 本文系统综述了大型语言模型(LLMs)向多模态和智能代理发展过程中日益严重的越狱攻击安全风险，分类整理了攻击技术、防御策略及研究局限，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs向多模态LLMs(MLLMs)和智能代理演进，其能力扩展的同时引入了更严峻的安全风险，亟需系统梳理越狱攻击与防御机制的研究现状。

Method: 1) 追溯LLMs到MLLMs/代理的发展路径及安全挑战 2) 从攻击影响和可见性角度分类主流越狱技术 3) 按响应时机和技术路线组织防御策略 4) 指出现有研究的四大局限性。

Result: 提出了攻击方法/数据集/评估指标的全面分析框架，构建了防御策略的结构化认知体系，并更新了最新研究成果，明确了数据集构建、评估框架优化等未来方向。

Conclusion: 研究深化了对越狱机制的理解，为LLMs生态中更具韧性的防御策略发展提供了系统性指导，需重点关注混合攻击分类、代理安全等未解决问题。

Abstract: Large language models (LLMs) are rapidly evolving from single-modal systems
to multimodal LLMs and intelligent agents, significantly expanding their
capabilities while introducing increasingly severe security risks. This paper
presents a systematic survey of the growing complexity of jailbreak attacks and
corresponding defense mechanisms within the expanding LLM ecosystem. We first
trace the developmental trajectory from LLMs to MLLMs and Agents, highlighting
the core security challenges emerging at each stage. Next, we categorize
mainstream jailbreak techniques from both the attack impact and visibility
perspectives, and provide a comprehensive analysis of representative attack
methods, related datasets, and evaluation metrics. On the defense side, we
organize existing strategies based on response timing and technical approach,
offering a structured understanding of their applicability and implementation.
Furthermore, we identify key limitations in existing surveys, such as
insufficient attention to agent-specific security issues, the absence of a
clear taxonomy for hybrid jailbreak methods, a lack of detailed analysis of
experimental setups, and outdated coverage of recent advancements. To address
these limitations, we provide an updated synthesis of recent work and outline
future research directions in areas such as dataset construction, evaluation
framework optimization, and strategy generalization. Our study seeks to enhance
the understanding of jailbreak mechanisms and facilitate the advancement of
more resilient and adaptive defense strategies in the context of ever more
capable LLMs.

</details>


### [63] [Evaluation Pipeline for systematically searching for Anomaly Detection Systems](https://arxiv.org/abs/2506.15388)
*Florian Rokohl,Alexander Lehnert,Marc Reichenbach*

Main category: cs.CR

TL;DR: 提出基于FPGA的实时异常检测系统，用于医疗数字化环境中的恶意客户端识别。


<details>
  <summary>Details</summary>
Motivation: 医疗数字化带来便利的同时也面临网络安全威胁，需要实时且低功耗的入侵检测方案。

Method: 采用FPGA硬件实现实时异常检测系统，通过整体系统评估满足实时性与功耗限制。

Result: 系统成功在硬件层面实现实时恶意流量检测，符合医疗场景的严苛性能要求。

Conclusion: 基于FPGA的硬件检测方案为医疗网络安全提供了高效可靠的实时防护手段。

Abstract: Digitalization in the medical world provides major benefits while making it a
target for attackers and thus hard to secure. To deal with network intruders we
propose an anomaly detection system on hardware to detect malicious clients in
real-time. We meet real-time and power restrictions using FPGAs. Overall system
performance is achieved via the presented holistic system evaluation.

</details>


### [64] [LLM vs. SAST: A Technical Analysis on Detecting Coding Bugs of GPT4-Advanced Data Analysis](https://arxiv.org/abs/2506.15212)
*Madjid G. Tehrani,Eldar Sultanow,William J. Buchanan,Mahkame Houmani,Christel H. Djaha Fodja*

Main category: cs.CR

TL;DR: 研究探讨GPT-4在软件漏洞扫描中的效能，发现其准确率高达94%，优于传统静态应用安全测试工具。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理技术的快速发展，大型语言模型如GPT-4在安全漏洞扫描等多样化应用中展现出潜力，本研究旨在评估其与传统工具的对比效果。

Method: 通过分析一系列安全错误，比较GPT-4（高级数据分析功能）与传统静态应用安全测试工具在检测32种可被利用漏洞中的表现。

Result: GPT-4的漏洞检测准确率达到94%，显著优于传统静态应用安全测试工具。

Conclusion: 研究不仅展示了GPT-4在漏洞扫描中的卓越性能，还强调了AI设计中默认安全及其他安全最佳实践的重要性。

Abstract: With the rapid advancements in Natural Language Processing (NLP), large
language models (LLMs) like GPT-4 have gained significant traction in diverse
applications, including security vulnerability scanning. This paper
investigates the efficacy of GPT-4 in identifying software vulnerabilities
compared to traditional Static Application Security Testing (SAST) tools.
Drawing from an array of security mistakes, our analysis underscores the potent
capabilities of GPT-4 in LLM-enhanced vulnerability scanning. We unveiled that
GPT-4 (Advanced Data Analysis) outperforms SAST by an accuracy of 94% in
detecting 32 types of exploitable vulnerabilities. This study also addresses
the potential security concerns surrounding LLMs, emphasising the imperative of
security by design/default and other security best practices for AI.

</details>


### [65] [Facility Location Problem under Local Differential Privacy without Super-set Assumption](https://arxiv.org/abs/2506.15224)
*Kevin Pfisterer,Quentin Hillebrand,Vorapong Suppakitpaisarn*

Main category: cs.CR

TL;DR: 本文在本地差分隐私（LDP）框架下提出了一种改进的设施选址问题模型，通过新算法实现了常数近似比，突破了原有$\Omega(\sqrt{n})$的下界限制，并在实验中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统差分隐私算法在设施选址问题中存在$\Omega(\sqrt{n})$的近似比下界，而超集假设可能损害用户隐私。本研究旨在开发更高效的LDP算法以解决这一矛盾。

Method: 提出了一种新的LDP算法框架，通过改进的隐私保护机制处理用户位置数据，避免了超集假设的使用。

Result: 算法实现了常数近似比和较小加性误差，实验表明其在合成和真实数据集上均优于传统方法。

Conclusion: 该研究证明了LDP框架下可突破原有近似比下界，为隐私保护的设施选址问题提供了更优解决方案。

Abstract: In this paper, we introduce an adaptation of the facility location problem
and analyze it within the framework of local differential privacy (LDP). Under
this model, we ensure the privacy of client presence at specific locations.
When n is the number of points, Gupta et al. established a lower bound of
$\Omega(\sqrt{n})$ on the approximation ratio for any differentially private
algorithm applied to the original facility location problem. As a result,
subsequent works have adopted the super-set assumption, which may, however,
compromise user privacy. We show that this lower bound does not apply to our
adaptation by presenting an LDP algorithm that achieves a constant
approximation ratio with a relatively small additive factor. Additionally, we
provide experimental results demonstrating that our algorithm outperforms the
straightforward approach on both synthetically generated and real-world
datasets.

</details>


### [66] [Detecting Hardware Trojans in Microprocessors via Hardware Error Correction Code-based Modules](https://arxiv.org/abs/2506.15417)
*Alessandro Palumbo,Ruben Salvador*

Main category: cs.CR

TL;DR: 本文提出了一种基于硬件的检测方法，利用纠错码（ECC）在RISC-V微处理器上检测运行时硬件木马（HT）激活，实现了100%的检测率且无额外延迟。


<details>
  <summary>Details</summary>
Motivation: 软件可利用的硬件木马（HT）允许攻击者执行未授权软件或获取特权操作权限，威胁系统安全，亟需有效检测手段。

Method: 采用基于汉明单纠错（HSEC）架构的硬件安全检查器（HSC），通过ECC检测恶意指令注入，保护正常执行流。

Result: 实验显示该方法对潜在HT激活的检测率达到100%，无假阳性或漏检，仅需72个LUT、24个FF和0.5个BRAM，且不影响处理器频率。

Conclusion: 所提方案以极低开销实现了高效HT检测，为硬件安全提供了可靠保障，适用于实际部署。

Abstract: Software-exploitable Hardware Trojans (HTs) enable attackers to execute
unauthorized software or gain illicit access to privileged operations. This
manuscript introduces a hardware-based methodology for detecting runtime HT
activations using Error Correction Codes (ECCs) on a RISC-V microprocessor.
Specifically, it focuses on HTs that inject malicious instructions, disrupting
the normal execution flow by triggering unauthorized programs. To counter this
threat, the manuscript introduces a Hardware Security Checker (HSC) leveraging
Hamming Single Error Correction (HSEC) architectures for effective HT
detection. Experimental results demonstrate that the proposed solution achieves
a 100% detection rate for potential HT activations, with no false positives or
undetected attacks. The implementation incurs minimal overhead, requiring only
72 #LUTs, 24 #FFs, and 0.5 #BRAM while maintaining the microprocessor's
original operating frequency and introducing no additional time delay.

</details>


### [67] [Side-Channel Extraction of Dataflow AI Accelerator Hardware Parameters](https://arxiv.org/abs/2506.15432)
*Guillaume Lomet,Ruben Salvador,Brice Colombier,Vincent Grosso,Olivier Sentieys,Cedric Killian*

Main category: cs.CR

TL;DR: 本文提出了一种针对FINN框架生成的数据流神经网络加速器的侧信道攻击方法，通过无监督降维和轻量级分类器，高效恢复硬件配置参数，攻击时间短且准确率高。


<details>
  <summary>Details</summary>
Motivation: 数据流神经网络加速器虽然部署便捷，但其易受侧信道攻击，导致知识产权被逆向工程。现有方法计算开销大，需更高效的攻击方案。

Method: 采用无监督降维技术降低计算开销，结合随机森林分类器从侧信道迹线中恢复折叠和量化参数，攻击阶段仅需数百毫秒。

Result: 攻击方法在337毫秒内恢复硬件参数的准确率超过95%，421毫秒内完全恢复参数（平均4条迹线），相比现有方法时间开销降低940倍和110倍。

Conclusion: 该方法在加速器数据流全负载下仍有效，提供了更现实的攻击场景，且无需迹线平均即可获得优于现有方法的结果。

Abstract: Dataflow neural network accelerators efficiently process AI tasks on FPGAs,
with deployment simplified by ready-to-use frameworks and pre-trained models.
However, this convenience makes them vulnerable to malicious actors seeking to
reverse engineer valuable Intellectual Property (IP) through Side-Channel
Attacks (SCA). This paper proposes a methodology to recover the hardware
configuration of dataflow accelerators generated with the FINN framework.
Through unsupervised dimensionality reduction, we reduce the computational
overhead compared to the state-of-the-art, enabling lightweight classifiers to
recover both folding and quantization parameters. We demonstrate an attack
phase requiring only 337 ms to recover the hardware parameters with an accuracy
of more than 95% and 421 ms to fully recover these parameters with an averaging
of 4 traces for a FINN-based accelerator running a CNN, both using a random
forest classifier on side-channel traces, even with the accelerator dataflow
fully loaded. This approach offers a more realistic attack scenario than
existing methods, and compared to SoA attacks based on tsfresh, our method
requires 940x and 110x less time for preparation and attack phases,
respectively, and gives better results even without averaging traces.

</details>


### [68] [An efficient construction of Raz's two-source randomness extractor with improved parameters](https://arxiv.org/abs/2506.15547)
*Cameron Foreman,Lewis Wooltorton,Kevin Milner,Florian J. Curchod*

Main category: cs.CR

TL;DR: 本文改进了Raz的随机性提取器，将其计算时间从多项式降至准线性，并降低了熵需求，提供了易于使用的开源实现。


<details>
  <summary>Details</summary>
Motivation: Raz的原始提取器虽能结合两个独立弱随机源生成近乎完美的随机数，但其计算时间至少为四次多项式，不切实际。

Method: 提出了一种改进的Raz提取器，具有准线性计算时间，并引入新的分析定理以减少熵需求，同时提供了开源代码实现。

Result: 改进后的提取器在计算效率上显著优于原始构造，并支持强量子证明版本，数值参数计算模块进一步提升了实用性。

Conclusion: 本研究不仅提升了Raz提取器的计算效率，还降低了熵需求，为实际应用提供了高效且易于实现的解决方案。

Abstract: Randomness extractors are algorithms that distill weak random sources into
near-perfect random numbers. Two-source extractors enable this distillation
process by combining two independent weak random sources. Raz's extractor (STOC
'05) was the first to achieve this in a setting where one source has linear
min-entropy (i.e., proportional to its length), while the other has only
logarithmic min-entropy in its length. However, Raz's original construction is
impractical due to a polynomial computation time of at least degree 4. Our work
solves this problem by presenting an improved version of Raz's extractor with
quasi-linear computation time, as well as a new analytic theorem with reduced
entropy requirements. We provide comprehensive analytical and numerical
comparisons of our construction with others in the literature, and we derive
strong and quantum-proof versions of our efficient Raz extractor. Additionally,
we offer an easy-to-use, open-source code implementation of the extractor and a
numerical parameter calculation module.

</details>


### [69] [deepSURF: Detecting Memory Safety Vulnerabilities in Rust Through Fuzzing LLM-Augmented Harnesses](https://arxiv.org/abs/2506.15648)
*Georgios Androutsopoulos,Antonio Bianchi*

Main category: cs.CR

TL;DR: 本文介绍了deepSURF工具，通过结合静态分析与基于大型语言模型（LLM）的模糊测试引导技术，有效检测Rust库中的内存安全漏洞，特别是在处理不安全代码时表现出色。


<details>
  <summary>Details</summary>
Motivation: 尽管Rust默认保证内存安全，但不安全代码的使用仍可能导致漏洞。现有工具在检测能力、处理Rust特有类型或减少人工干预方面存在不足。

Method: deepSURF采用静态分析与LLM引导的模糊测试生成相结合的方法，通过替换泛型为自定义类型并生成特定trait实现，模拟用户行为。同时利用LLM动态增强模糊测试用例，探索复杂API交互。

Result: 在27个真实Rust库的测试中，deepSURF成功复现了20个已知内存安全漏洞，并发现了6个新漏洞，性能优于现有工具。

Conclusion: deepSURF通过创新方法显著提升了Rust内存安全漏洞的检测能力，为不安全代码的自动化测试提供了有效解决方案。

Abstract: Although Rust ensures memory safety by default, it also permits the use of
unsafe code, which can introduce memory safety vulnerabilities if misused.
Unfortunately, existing tools for detecting memory bugs in Rust typically
exhibit limited detection capabilities, inadequately handle Rust-specific
types, or rely heavily on manual intervention.
  To address these limitations, we present deepSURF, a tool that integrates
static analysis with Large Language Model (LLM)-guided fuzzing harness
generation to effectively identify memory safety vulnerabilities in Rust
libraries, specifically targeting unsafe code. deepSURF introduces a novel
approach for handling generics by substituting them with custom types and
generating tailored implementations for the required traits, enabling the
fuzzer to simulate user-defined behaviors within the fuzzed library.
Additionally, deepSURF employs LLMs to augment fuzzing harnesses dynamically,
facilitating exploration of complex API interactions and significantly
increasing the likelihood of exposing memory safety vulnerabilities. We
evaluated deepSURF on 27 real-world Rust crates, successfully rediscovering 20
known memory safety bugs and uncovering 6 previously unknown vulnerabilities,
demonstrating clear improvements over state-of-the-art tools.

</details>


### [70] [PhishDebate: An LLM-Based Multi-Agent Framework for Phishing Website Detection](https://arxiv.org/abs/2506.15656)
*Wenhao Li,Selvakumar Manickam,Yung-wey Chong,Shankar Karuppayah*

Main category: cs.CR

TL;DR: 本文提出PhishDebate框架，通过多智能体辩论机制提升钓鱼网站检测的准确性与可解释性，实验显示其召回率和真阳性率均达98.2%。


<details>
  <summary>Details</summary>
Motivation: 现有钓鱼检测方法依赖单智能体分类，存在幻觉风险且缺乏可解释性和鲁棒性，亟需新型解决方案。

Method: 采用模块化多智能体辩论框架，包含URL结构、HTML组成、语义内容和品牌仿冒四个专项分析智能体，由协调员和裁决官进行决策整合。

Result: 在真实钓鱼数据集上实现98.2%召回率和真阳性率，显著优于单智能体和思维链基线方法。

Conclusion: PhishDebate通过结构化辩论机制实现高精度检测，模块化设计支持灵活配置，适用于不同资源需求场景。

Abstract: Phishing websites continue to pose a significant cybersecurity threat, often
leveraging deceptive structures, brand impersonation, and social engineering
tactics to evade detection. While recent advances in large language models
(LLMs) have enabled improved phishing detection through contextual
understanding, most existing approaches rely on single-agent classification
facing the risks of hallucination and lack interpretability or robustness. To
address these limitations, we propose PhishDebate, a modular multi-agent
LLM-based debate framework for phishing website detection. PhishDebate employs
four specialized agents to independently analyze different textual aspects of a
webpage--URL structure, HTML composition, semantic content, and brand
impersonation--under the coordination of a Moderator and a final Judge. Through
structured debate and divergent thinking, the framework delivers more accurate
and interpretable decisions. Extensive evaluations on commercial LLMs
demonstrate that PhishDebate achieves 98.2% recall and 98.2% True Positive Rate
(TPR) on a real-world phishing dataset, and outperforms single-agent and Chain
of Thought (CoT) baselines. Additionally, its modular design allows agent-level
configurability, enabling adaptation to varying resource and application
requirements.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [71] [CALM: Contextual Analog Logic with Multimodality](https://arxiv.org/abs/2506.14936)
*Maxwell J. Jacobson,Corey J. Maley,Yexiang Xue*

Main category: cs.AI

TL;DR: 本文提出CALM框架，融合符号推理与神经生成，实现多模态数据下的上下文敏感决策。实验显示其在物体摆放任务中准确率达92.2%，超越传统逻辑与LLM基线。


<details>
  <summary>Details</summary>
Motivation: 经典二值逻辑无法捕捉人类决策的细微差别，且在多模态环境中依赖人工标注，存在僵化性。神经网络虽擅长多模态特征提取，但缺乏可解释的推理结构。CALM旨在弥合逻辑系统与神经感知的鸿沟。

Method: CALM通过域树表示谓词，利用神经网络迭代优化模拟真值，并经过符号推理模块约束。神经网络捕获多模态信息，符号模块确保逻辑约束满足。

Result: 在填空式物体摆放任务中，CALM以92.2%准确率显著优于传统逻辑(86.3%)和LLM(59.4%)。人类研究表明其生成的空间热图既符合逻辑约束，又贴合人类偏好。

Conclusion: CALM证明了在多模态环境中结合逻辑结构与神经处理的可行性，为需要逻辑精确性、可解释性及多模态处理能力的下一代AI系统奠定基础。

Abstract: In this work, we introduce Contextual Analog Logic with Multimodality (CALM).
CALM unites symbolic reasoning with neural generation, enabling systems to make
context-sensitive decisions grounded in real-world multi-modal data.
  Background: Classic bivalent logic systems cannot capture the nuance of human
decision-making. They also require human grounding in multi-modal environments,
which can be ad-hoc, rigid, and brittle. Neural networks are good at extracting
rich contextual information from multi-modal data, but lack interpretable
structures for reasoning.
  Objectives: CALM aims to bridge the gap between logic and neural perception,
creating an analog logic that can reason over multi-modal inputs. Without this
integration, AI systems remain either brittle or unstructured, unable to
generalize robustly to real-world tasks. In CALM, symbolic predicates evaluate
to analog truth values computed by neural networks and constrained search.
  Methods: CALM represents each predicate using a domain tree, which
iteratively refines its analog truth value when the contextual groundings of
its entities are determined. The iterative refinement is predicted by neural
networks capable of capturing multi-modal information and is filtered through a
symbolic reasoning module to ensure constraint satisfaction.
  Results: In fill-in-the-blank object placement tasks, CALM achieved 92.2%
accuracy, outperforming classical logic (86.3%) and LLM (59.4%) baselines. It
also demonstrated spatial heatmap generation aligned with logical constraints
and delicate human preferences, as shown by a human study.
  Conclusions: CALM demonstrates the potential to reason with logic structure
while aligning with preferences in multi-modal environments. It lays the
foundation for next-gen AI systems that require the precision and
interpretation of logic and the multimodal information processing of neural
networks.

</details>


### [72] [MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2506.14990)
*Tristan Tomilin,Luka van den Boogaard,Samuel Garcin,Bram Grooten,Meng Fang,Mykola Pechenizkiy*

Main category: cs.AI

TL;DR: 本文介绍了MEAL（多智能体自适应学习环境），这是首个专为持续多智能体强化学习（CMARL）设计的基准测试。MEAL利用JAX实现GPU加速，能在普通台式机上几小时内完成100个任务的持续学习。研究发现，简单结合现有CL和MARL方法在复杂场景中表现不佳，并揭示了CMARL的关键架构与算法特征。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习研究中，持续学习（CL）在合作多智能体环境中的探索严重不足。现有CL基准测试受限于CPU计算能力，无法支持长任务序列。MEAL旨在填补这一空白，为CMARL研究提供高效测试平台。

Method: 采用JAX框架实现GPU加速，构建包含100个连续任务的测试环境。通过系统消融实验，分析不同架构和算法在复杂协作场景中的表现。

Result: 实验表明：1）传统CL与MARL方法组合在简单环境中有效，但在需要持续协调的复杂场景中失效；2）成功识别出影响CMARL性能的关键技术要素。

Conclusion: MEAL基准的建立推动了CMARL领域发展，其GPU加速设计显著提升实验效率。研究发现现有方法存在局限性，为未来算法改进指明了方向。

Abstract: Benchmarks play a crucial role in the development and analysis of
reinforcement learning (RL) algorithms, with environment availability strongly
impacting research. One particularly underexplored intersection is continual
learning (CL) in cooperative multi-agent settings. To remedy this, we introduce
MEAL (Multi-agent Environments for Adaptive Learning), the first benchmark
tailored for continual multi-agent reinforcement learning (CMARL). Existing CL
benchmarks run environments on the CPU, leading to computational bottlenecks
and limiting the length of task sequences. MEAL leverages JAX for GPU
acceleration, enabling continual learning across sequences of 100 tasks on a
standard desktop PC in a few hours. We show that naively combining popular CL
and MARL methods yields strong performance on simple environments, but fails to
scale to more complex settings requiring sustained coordination and adaptation.
Our ablation study identifies architectural and algorithmic features critical
for CMARL on MEAL.

</details>


### [73] [Truncated Proximal Policy Optimization](https://arxiv.org/abs/2506.15050)
*Tiantian Fan,Lingjun Liu,Yu Yue,Jiaze Chen,Chengyi Wang,Qiying Yu,Chi Zhang,Zhiqi Lin,Ruofei Zhu,Yufeng Yuan,Xiaochen Zuo,Bole Ma,Mofan Zhang,Gaohong Liu,Ru Zhang,Haotian Zhou,Cong Xie,Ruidong Zhu,Zhi Zhang,Xin Liu,Mingxuan Wang,Lin Yan,Yonghui Wu*

Main category: cs.AI

TL;DR: 本文提出了一种名为截断近端策略优化（T-PPO）的新方法，旨在提高大型语言模型（LLM）在推理任务中的训练效率。通过优化策略更新和限制生成长度，T-PPO显著减少了训练时间，同时保持了模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统的近端策略优化（PPO）由于同步生成长响应的特性，导致硬件利用率低且训练耗时。随着响应长度的增加，这一问题愈发严重，亟需一种高效的替代方案。

Method: T-PPO通过两项创新提升效率：(1) 扩展广义优势估计（EGAE），利用不完整响应进行优势估计；(2) 设计选择性过滤机制，独立优化策略和价值模型，减少冗余计算。

Result: 在AIME 2024的32B基础模型上，T-PPO将推理型LLM的训练效率最高提升2.5倍，且性能优于现有方法。

Conclusion: T-PPO通过创新的截断训练框架，有效解决了长序列生成场景下的效率瓶颈，为强化学习在LLM推理任务中的应用提供了新范式。

Abstract: Recently, test-time scaling Large Language Models (LLMs) have demonstrated
exceptional reasoning capabilities across scientific and professional tasks by
generating long chains-of-thought (CoT). As a crucial component for developing
these reasoning models, reinforcement learning (RL), exemplified by Proximal
Policy Optimization (PPO) and its variants, allows models to learn through
trial and error. However, PPO can be time-consuming due to its inherent
on-policy nature, which is further exacerbated by increasing response lengths.
In this work, we propose Truncated Proximal Policy Optimization (T-PPO), a
novel extension to PPO that improves training efficiency by streamlining policy
update and length-restricted response generation. T-PPO mitigates the issue of
low hardware utilization, an inherent drawback of fully synchronized
long-generation procedures, where resources often sit idle during the waiting
periods for complete rollouts. Our contributions are two-folds. First, we
propose Extended Generalized Advantage Estimation (EGAE) for advantage
estimation derived from incomplete responses while maintaining the integrity of
policy learning. Second, we devise a computationally optimized mechanism that
allows for the independent optimization of the policy and value models. By
selectively filtering prompt and truncated tokens, this mechanism reduces
redundant computations and accelerates the training process without sacrificing
convergence performance. We demonstrate the effectiveness and efficacy of T-PPO
on AIME 2024 with a 32B base model. The experimental results show that T-PPO
improves the training efficiency of reasoning LLMs by up to 2.5x and
outperforms its existing competitors.

</details>


### [74] [HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges](https://arxiv.org/abs/2506.15196)
*Xianliang Yang,Ling Zhang,Haolong Qian,Lei Song,Jiang Bian*

Main category: cs.AI

TL;DR: HeurAgenix是一个基于大语言模型的两阶段超启发式框架，通过演化启发式策略并动态选择最优策略，显著提升组合优化问题的求解性能。


<details>
  <summary>Details</summary>
Motivation: 传统启发式算法设计依赖人工经验且难以泛化，需要自动化框架来生成和选择高效启发式策略。

Method: 1) 利用LLM对比种子解与优质解以提取演化策略；2) 动态选择启发式策略，支持直接使用LLM或微调轻量模型；3) 采用双奖励机制缓解标注噪声问题。

Result: 在标准测试集上，HeurAgenix性能超越现有LLM超启发式方法，并媲美专业求解器。

Conclusion: 该框架为组合优化提供了可扩展的自动化解决方案，代码已开源。

Abstract: Heuristic algorithms play a vital role in solving combinatorial optimization
(CO) problems, yet traditional designs depend heavily on manual expertise and
struggle to generalize across diverse instances. We introduce
\textbf{HeurAgenix}, a two-stage hyper-heuristic framework powered by large
language models (LLMs) that first evolves heuristics and then selects among
them automatically. In the heuristic evolution phase, HeurAgenix leverages an
LLM to compare seed heuristic solutions with higher-quality solutions and
extract reusable evolution strategies. During problem solving, it dynamically
picks the most promising heuristic for each problem state, guided by the LLM's
perception ability. For flexibility, this selector can be either a
state-of-the-art LLM or a fine-tuned lightweight model with lower inference
cost. To mitigate the scarcity of reliable supervision caused by CO complexity,
we fine-tune the lightweight heuristic selector with a dual-reward mechanism
that jointly exploits singals from selection preferences and state perception,
enabling robust selection under noisy annotations. Extensive experiments on
canonical benchmarks show that HeurAgenix not only outperforms existing
LLM-based hyper-heuristics but also matches or exceeds specialized solvers.
Code is available at https://github.com/microsoft/HeurAgenix.

</details>


### [75] [Multi-Agent Reinforcement Learning for Autonomous Multi-Satellite Earth Observation: A Realistic Case Study](https://arxiv.org/abs/2506.15207)
*Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Jimmy Cao,Ryszard Kowalczyk*

Main category: cs.AI

TL;DR: 本文探讨了基于强化学习(RL)和多智能体强化学习(MARL)的低地球轨道(LEO)卫星自主地球观测(EO)任务规划，解决了多卫星系统中的实时决策和协调挑战。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道卫星的指数级增长，传统优化方法难以应对动态地球观测任务的实时决策需求，需采用RL和MARL技术实现自主协调。

Method: 研究通过单卫星操作建模扩展到多卫星星座的MARL框架，解决了能源、数据存储限制及部分可观测下的分散协调问题，并评估了PPO、IPPO、MAPPO和HAPPO等先进算法的性能。

Result: 结果表明，MARL能有效平衡成像与资源管理，解决多卫星协调中的非平稳性和奖励依赖性，为自主卫星操作提供了实用指南。

Conclusion: 本研究为分散式地球观测任务的政策学习奠定了基础，展示了MARL在自主卫星协调中的潜力。

Abstract: The exponential growth of Low Earth Orbit (LEO) satellites has revolutionised
Earth Observation (EO) missions, addressing challenges in climate monitoring,
disaster management, and more. However, autonomous coordination in
multi-satellite systems remains a fundamental challenge. Traditional
optimisation approaches struggle to handle the real-time decision-making
demands of dynamic EO missions, necessitating the use of Reinforcement Learning
(RL) and Multi-Agent Reinforcement Learning (MARL). In this paper, we
investigate RL-based autonomous EO mission planning by modelling
single-satellite operations and extending to multi-satellite constellations
using MARL frameworks. We address key challenges, including energy and data
storage limitations, uncertainties in satellite observations, and the
complexities of decentralised coordination under partial observability. By
leveraging a near-realistic satellite simulation environment, we evaluate the
training stability and performance of state-of-the-art MARL algorithms,
including PPO, IPPO, MAPPO, and HAPPO. Our results demonstrate that MARL can
effectively balance imaging and resource management while addressing
non-stationarity and reward interdependency in multi-satellite coordination.
The insights gained from this study provide a foundation for autonomous
satellite operations, offering practical guidelines for improving policy
learning in decentralised EO missions.

</details>


### [76] [Joint Computation Offloading and Resource Allocation for Uncertain Maritime MEC via Cooperation of UAVs and Vessels](https://arxiv.org/abs/2506.15225)
*Jiahao You,Ziye Jia,Chao Dong,Qihui Wu,Zhu Han*

Main category: cs.AI

TL;DR: 本文提出了一种基于无人机和船舶协作的海事物联网(MIoT)计算卸载与资源分配框架，利用Lyapunov优化和异构智能体软演员-评论家算法解决任务不确定性问题，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 海事物联网计算需求激增，但不确定任务导致计算卸载和资源分配效率低下，亟需通过无人机与船舶协作的MEC框架解决这一挑战。

Method: 1) 建立无人机-船舶协作MEC框架 2) 采用Lyapunov优化处理任务不确定性 3) 将问题转化为马尔可夫博弈 4) 提出异构智能体SAC算法求解。

Result: 仿真实验表明，所提方法能有效优化海事场景下的计算卸载与资源分配，显著降低任务总执行时间。

Conclusion: 该协作框架结合Lyapunov优化和强化学习，为不确定海事任务提供了高效的计算卸载与资源分配解决方案。

Abstract: The computation demands from the maritime Internet of Things (MIoT) increase
rapidly in recent years, and the unmanned aerial vehicles (UAVs) and vessels
based multi-access edge computing (MEC) can fulfill these MIoT requirements.
However, the uncertain maritime tasks present significant challenges of
inefficient computation offloading and resource allocation. In this paper, we
focus on the maritime computation offloading and resource allocation through
the cooperation of UAVs and vessels, with consideration of uncertain tasks.
Specifically, we propose a cooperative MEC framework for computation offloading
and resource allocation, including MIoT devices, UAVs and vessels. Then, we
formulate the optimization problem to minimize the total execution time. As for
the uncertain MIoT tasks, we leverage Lyapunov optimization to tackle the
unpredictable task arrivals and varying computational resource availability. By
converting the long-term constraints into short-term constraints, we obtain a
set of small-scale optimization problems. Further, considering the
heterogeneity of actions and resources of UAVs and vessels, we reformulate the
small-scale optimization problem into a Markov game (MG). Moreover, a
heterogeneous-agent soft actor-critic is proposed to sequentially update
various neural networks and effectively solve the MG problem. Finally,
simulations are conducted to verify the effectiveness in addressing
computational offloading and resource allocation.

</details>


### [77] [Efficient and Generalizable Environmental Understanding for Visual Navigation](https://arxiv.org/abs/2506.15377)
*Ruoyu Wang,Xinshu Li,Chen Wang,Lina Yao*

Main category: cs.AI

TL;DR: 本文提出了一种因果感知导航方法（CAN），通过引入因果理解模块来提升智能体在视觉导航任务中的环境理解能力，实验表明该方法在多种任务和模拟环境中均优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉导航方法通常同时处理所有历史观测数据，忽视了数据内部的关联结构，这可能限制了任务性能的进一步提升。本文从因果关系的角度分析了导航任务的独特特性，旨在解决这一局限性。

Method: 作者提出了因果感知导航（CAN）框架，其中包含一个因果理解模块，用于增强智能体对环境因果关系的建模能力。该方法无需额外计算开销，适用于强化学习和监督学习场景。

Result: 实验评估表明，CAN方法在多种任务和模拟环境中 consistently 优于基线模型。消融研究证实，性能提升主要归功于因果理解模块的有效性。

Conclusion: 通过因果视角重新审视导航任务，本文提出的CAN框架显著提升了智能体的导航性能。因果理解模块的泛化能力为未来导航研究提供了新的方向。

Abstract: Visual Navigation is a core task in Embodied AI, enabling agents to navigate
complex environments toward given objectives. Across diverse settings within
Navigation tasks, many necessitate the modelling of sequential data accumulated
from preceding time steps. While existing methods perform well, they typically
process all historical observations simultaneously, overlooking the internal
association structure within the data, which may limit the potential for
further improvements in task performance. We address this by examining the
unique characteristics of Navigation tasks through the lens of causality,
introducing a causal framework to highlight the limitations of conventional
sequential methods. Leveraging this insight, we propose Causality-Aware
Navigation (CAN), which incorporates a Causal Understanding Module to enhance
the agent's environmental understanding capability. Empirical evaluations show
that our approach consistently outperforms baselines across various tasks and
simulation environments. Extensive ablations studies attribute these gains to
the Causal Understanding Module, which generalizes effectively in both
Reinforcement and Supervised Learning settings without computational overhead.

</details>


### [78] [Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents](https://arxiv.org/abs/2506.15567)
*Aline Dobrovsky,Konstantin Schekotihin,Christian Burmer*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型（LLM）的规划代理（LPA），用于辅助故障分析（FA）工程师处理复杂案例。LPA通过整合LLM与高级规划能力及外部工具，实现了自主处理查询、检索数据及生成可读响应，验证了其在FA任务中的有效性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 故障分析（FA）是一个复杂且知识密集的过程。随着AI模型在FA实验室中的部署增加，如何将这些组件协调成高效且与FA流程无缝集成的工作流成为挑战。

Method: 研究设计并实现了一种基于大语言模型（LLM）的规划代理（LPA），该代理结合了LLM的高级规划能力和外部工具使用，能够自主处理复杂查询、从外部系统检索相关数据并生成人类可读的响应。

Result: 评估结果表明，LPA在支持FA任务方面具有操作有效性和可靠性。

Conclusion: 基于LLM的规划代理（LPA）能够有效辅助FA工程师解决分析案例，展示了AI在故障分析领域的应用潜力。

Abstract: Failure Analysis (FA) is a highly intricate and knowledge-intensive process.
The integration of AI components within the computational infrastructure of FA
labs has the potential to automate a variety of tasks, including the detection
of non-conformities in images, the retrieval of analogous cases from diverse
data sources, and the generation of reports from annotated images. However, as
the number of deployed AI models increases, the challenge lies in orchestrating
these components into cohesive and efficient workflows that seamlessly
integrate with the FA process.
  This paper investigates the design and implementation of a Large Language
Model (LLM)-based Planning Agent (LPA) to assist FA engineers in solving their
analysis cases. The LPA integrates LLMs with advanced planning capabilities and
external tool utilization, enabling autonomous processing of complex queries,
retrieval of relevant data from external systems, and generation of
human-readable responses. Evaluation results demonstrate the agent's
operational effectiveness and reliability in supporting FA tasks.

</details>


### [79] [The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games](https://arxiv.org/abs/2506.15624)
*Lyle Goodyear,Rachel Guo,Ramesh Johari*

Main category: cs.AI

TL;DR: 本文提出了一个统一框架，用于系统构建大语言模型（LLM）在重复多智能体游戏中的自然语言状态表示，并发现状态表示方式对智能体行为有显著影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究在LLM智能体的游戏历史编码上采取临时方法，掩盖了状态表示对行为的影响并限制了研究间的可比性。

Method: 框架从三个维度表征状态表示方法：动作信息量、奖励信息量和提示风格（自然语言压缩程度），并应用于动态自私路由游戏进行验证。

Result: 实验表明：1) 摘要化历史表示；2) 提供遗憾而非原始收益信息；3) 限制他人动作信息时，LLM智能体行为更接近博弈论均衡预测且游戏更稳定。

Conclusion: 自然语言状态表示形式显著影响LLM智能体的博弈行为，合理设计可提升其与理论预测的一致性及稳定性。

Abstract: Large Language Models (LLMs) have shown promise as decision-makers in dynamic
settings, but their stateless nature necessitates creating a natural language
representation of history. We present a unifying framework for systematically
constructing natural language "state" representations for prompting LLM agents
in repeated multi-agent games. Previous work on games with LLM agents has taken
an ad hoc approach to encoding game history, which not only obscures the impact
of state representation on agents' behavior, but also limits comparability
between studies. Our framework addresses these gaps by characterizing methods
of state representation along three axes: action informativeness (i.e., the
extent to which the state representation captures actions played); reward
informativeness (i.e., the extent to which the state representation describes
rewards obtained); and prompting style (or natural language compression, i.e.,
the extent to which the full text history is summarized).
  We apply this framework to a dynamic selfish routing game, chosen because it
admits a simple equilibrium both in theory and in human subject experiments
\cite{rapoport_choice_2009}. Despite the game's relative simplicity, we find
that there are key dependencies of LLM agent behavior on the natural language
state representation. In particular, we observe that representations which
provide agents with (1) summarized, rather than complete, natural language
representations of past history; (2) information about regrets, rather than raw
payoffs; and (3) limited information about others' actions lead to behavior
that more closely matches game theoretic equilibrium predictions, and with more
stable game play by the agents. By contrast, other representations can exhibit
either large deviations from equilibrium, higher variation in dynamic game play
over time, or both.

</details>


### [80] [The AI Policy Module: Developing Computer Science Student Competency in AI Ethics and Policy](https://arxiv.org/abs/2506.15639)
*James Weichert,Daniel Dunlap,Mohammed Farghally,Hoda Eldardiry*

Main category: cs.AI

TL;DR: 本文提出在计算机科学课程中引入AI政策模块，旨在培养学生将伦理原则转化为实践的能力，并通过试点调查验证了该模块的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术深入个人与专业领域，现有计算机课程难以培养AI从业者将抽象伦理原则和政策偏好融入系统设计的能力，亟需加强AI政策教育。

Method: 开发了AI政策模块2.0版本，包含技术作业“AI监管”，并通过课前课后问卷调查评估学生对AI伦理与政策的态度变化。

Result: 模块实施后，学生对AI技术伦理影响的关注度提升，参与AI监管讨论的信心增强，技术作业被证明是探索AI对齐限度的有效工具。

Conclusion: AI政策模块成功填补了计算机课程空白，证明了政策教育对培养具备伦理意识的AI工程师的重要性。

Abstract: As artificial intelligence (AI) further embeds itself into many settings
across personal and professional contexts, increasing attention must be paid
not only to AI ethics, but also to the governance and regulation of AI
technologies through AI policy. However, the prevailing post-secondary
computing curriculum is currently ill-equipped to prepare future AI
practitioners to confront increasing demands to implement abstract ethical
principles and normative policy preferences into the design and development of
AI systems. We believe that familiarity with the 'AI policy landscape' and the
ability to translate ethical principles to practices will in the future
constitute an important responsibility for even the most technically-focused AI
engineers.
  Toward preparing current computer science (CS) students for these new
expectations, we developed an AI Policy Module to introduce discussions of AI
policy into the CS curriculum. Building on a successful pilot in fall 2024, in
this innovative practice full paper we present an updated and expanded version
of the module, including a technical assignment on "AI regulation". We present
the findings from our pilot of the AI Policy Module 2.0, evaluating student
attitudes towards AI ethics and policy through pre- and post-module surveys.
Following the module, students reported increased concern about the ethical
impacts of AI technologies while also expressing greater confidence in their
abilities to engage in discussions about AI regulation. Finally, we highlight
the AI Regulation Assignment as an effective and engaging tool for exploring
the limits of AI alignment and emphasizing the role of 'policy' in addressing
ethical challenges.

</details>


### [81] [Exploring and Exploiting the Inherent Efficiency within Large Reasoning Models for Self-Guided Efficiency Enhancement](https://arxiv.org/abs/2506.15647)
*Weixiang Zhao,Jiahe Guo,Yang Deng,Xingyu Sui,Yulin Hu,Yanyan Zhao,Wanxiang Che,Bing Qin,Tat-Seng Chua,Ting Liu*

Main category: cs.AI

TL;DR: 大型推理模型（LRMs）存在过度思考问题，导致推理效率低下。研究发现模型本身具备简洁推理能力，提出两种轻量级方法提升效率：无需训练的激活导向技术和自奖励强化学习框架，实验证明能显著缩短推理长度并保持性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型在复杂问题解决中表现出过度思考现象，产生冗余内容，降低效率并增加推理成本。研究旨在揭示其低效根源，并探索模型内在的简洁推理潜力。

Method: 提出两种方法：1）效率导向（Efficiency Steering），通过模型表示空间的单一方向调控推理行为；2）自奖励效率强化学习（Self-Rewarded Efficiency RL），动态平衡任务准确性与简洁性。

Result: 在七个大型推理模型和多个数学推理基准测试中，新方法显著减少推理长度（平均降低30%），同时保持或提升任务性能（准确率提高2-5%）。

Conclusion: 研究表明，通过引导模型内在能力可实现自驱动的效率提升，为未来高效推理模型设计提供了新方向。

Abstract: Recent advancements in large reasoning models (LRMs) have significantly
enhanced language models' capabilities in complex problem-solving by emulating
human-like deliberative thinking. However, these models often exhibit
overthinking (i.e., the generation of unnecessarily verbose and redundant
content), which hinders efficiency and inflates inference cost. In this work,
we explore the representational and behavioral origins of this inefficiency,
revealing that LRMs inherently possess the capacity for more concise reasoning.
Empirical analyses show that correct reasoning paths vary significantly in
length, and the shortest correct responses often suffice, indicating untapped
efficiency potential. Exploiting these findings, we propose two lightweight
methods to enhance LRM efficiency. First, we introduce Efficiency Steering, a
training-free activation steering technique that modulates reasoning behavior
via a single direction in the model's representation space. Second, we develop
Self-Rewarded Efficiency RL, a reinforcement learning framework that
dynamically balances task accuracy and brevity by rewarding concise correct
solutions. Extensive experiments on seven LRM backbones across multiple
mathematical reasoning benchmarks demonstrate that our methods significantly
reduce reasoning length while preserving or improving task performance. Our
results highlight that reasoning efficiency can be improved by leveraging and
guiding the intrinsic capabilities of existing models in a self-guided manner.

</details>


### [82] [SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence](https://arxiv.org/abs/2506.15672)
*Yao Zhang,Chenyang Lin,Shijie Tang,Haokun Chen,Shijie Zhou,Yunpu Ma,Volker Tresp*

Main category: cs.AI

TL;DR: SwarmAgentic提出了一种全自动代理系统生成框架，通过语言驱动探索和群体智能优化，实现了从零开始的代理生成与协作优化，在六项开放任务中显著超越基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统生成框架缺乏完全自主性，无法实现从零生成、自我优化和协作，限制了适应性和可扩展性。

Method: 受粒子群优化(PSO)启发，框架维护候选系统种群，通过反馈引导更新联合优化代理功能与协作，支持对系统级结构的高效搜索。

Result: 在旅行规划等六项任务中，仅需任务描述和目标函数即实现261.8%的相对性能提升，验证了全自动化在非结构化任务中的有效性。

Conclusion: 该框架将群体智能与全自动多代理生成相结合，为可扩展的自主代理系统设计迈出重要一步，代码已开源。

Abstract: The rapid progress of Large Language Models has advanced agentic systems in
decision-making, coordination, and task execution. Yet, existing agentic system
generation frameworks lack full autonomy, missing from-scratch agent
generation, self-optimizing agent functionality, and collaboration, limiting
adaptability and scalability. We propose SwarmAgentic, a framework for fully
automated agentic system generation that constructs agentic systems from
scratch and jointly optimizes agent functionality and collaboration as
interdependent components through language-driven exploration. To enable
efficient search over system-level structures, SwarmAgentic maintains a
population of candidate systems and evolves them via feedback-guided updates,
drawing inspiration from Particle Swarm Optimization (PSO). We evaluate our
method on six real-world, open-ended, and exploratory tasks involving
high-level planning, system-level coordination, and creative reasoning. Given
only a task description and an objective function, SwarmAgentic outperforms all
baselines, achieving a +261.8% relative improvement over ADAS on the
TravelPlanner benchmark, highlighting the effectiveness of full automation in
structurally unconstrained tasks. This framework marks a significant step
toward scalable and autonomous agentic system design, bridging swarm
intelligence with fully automated system multi-agent generation. Our code is
publicly released at https://yaoz720.github.io/SwarmAgentic/.

</details>


### [83] [Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence](https://arxiv.org/abs/2506.15677)
*Yining Hong,Rui Sun,Bingxuan Li,Xingcheng Yao,Maxine Wu,Alexander Chien,Da Yin,Ying Nian Wu,Zhecan James Wang,Kai-Wei Chang*

Main category: cs.AI

TL;DR: 本文提出了一种新型AI代理范式——具身网络代理（Embodied Web Agents），通过统一仿真平台整合3D物理环境与网络接口，构建跨领域任务基准测试，揭示了当前AI系统与人类能力间的显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理往往割裂地处理数字信息或物理交互，无法完成需要整合物理与数字智能的任务（如在线烹饪、动态导航等）。研究旨在弥合这一鸿沟。

Method: 开发了具身网络代理任务环境仿真平台，将真实3D室内外环境与功能性网络接口深度整合，并发布包含烹饪、导航、购物等跨领域任务的基准测试集。

Result: 实验表明当前最先进AI系统在跨领域协调推理能力上与人类存在显著差距，同时为具身认知与网络知识访问的交叉研究提供了明确挑战与机遇。

Conclusion: 该研究通过开放数据集与平台（https://embodied-web-agent.github.io/），为开发整合物理交互与网络推理的通用智能体奠定了基础。

Abstract: AI agents today are mostly siloed - they either retrieve and reason over vast
amount of digital information and knowledge obtained online; or interact with
the physical world through embodied perception, planning and action - but
rarely both. This separation limits their ability to solve tasks that require
integrated physical and digital intelligence, such as cooking from online
recipes, navigating with dynamic map data, or interpreting real-world landmarks
using web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI
agents that fluidly bridge embodiment and web-scale reasoning. To
operationalize this concept, we first develop the Embodied Web Agents task
environments, a unified simulation platform that tightly integrates realistic
3D indoor and outdoor environments with functional web interfaces. Building
upon this platform, we construct and release the Embodied Web Agents Benchmark,
which encompasses a diverse suite of tasks including cooking, navigation,
shopping, tourism, and geolocation - all requiring coordinated reasoning across
physical and digital realms for systematic assessment of cross-domain
intelligence. Experimental results reveal significant performance gaps between
state-of-the-art AI systems and human capabilities, establishing both
challenges and opportunities at the intersection of embodied cognition and
web-scale knowledge access. All datasets, codes and websites are publicly
available at our project page https://embodied-web-agent.github.io/.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [84] [A survey of Chernoff and Hoeffding bounds](https://arxiv.org/abs/2506.15612)
*Alexandros V. Gerbessiotis*

Main category: cs.DM

TL;DR: 本文是一篇综述论文，探讨了Chernoff和Hoeffding开创性论文中的原始界限，并涵盖了多种形式的衍生界限。


<details>
  <summary>Details</summary>
Motivation: 旨在为感兴趣的研究者提供一个参考界限的存储库。

Method: 提供了完整的证明，根据需要详细阐述了各种界限的推导过程。

Result: 汇集了多种形式的界限，包括原始界限及其衍生版本，为研究者提供了全面的参考。

Conclusion: 该论文为概率界限领域的研究者提供了宝贵的参考资料，涵盖了从原始到衍生的多种界限形式。

Abstract: This is a survey paper that discusses the original bounds of the seminal
papers by Chernoff and Hoeffding. Moreover, it includes a variety of derivative
bounds in a variety of forms. Complete proofs are provided as needed. The
intent is to provide a repository of reference bounds for the interested
researcher.

</details>
