{"id": "2507.18577", "categories": ["q-fin.CP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.18577", "abs": "https://arxiv.org/abs/2507.18577", "authors": ["Liyuan Chen", "Shuoling Liu", "Jiangpeng Yan", "Xiaoyu Wang", "Henglin Liu", "Chuang Li", "Kecheng Jiao", "Jixuan Ying", "Yang Veronica Liu", "Qiang Yang", "Xiu Li"], "title": "Advancing Financial Engineering with Foundation Models: Progress, Applications, and Challenges", "comment": "Under Review", "summary": "The advent of foundation models (FMs) - large-scale pre-trained models with\nstrong generalization capabilities - has opened new frontiers for financial\nengineering. While general-purpose FMs such as GPT-4 and Gemini have\ndemonstrated promising performance in tasks ranging from financial report\nsummarization to sentiment-aware forecasting, many financial applications\nremain constrained by unique domain requirements such as multimodal reasoning,\nregulatory compliance, and data privacy. These challenges have spurred the\nemergence of Financial Foundation Models (FFMs) - a new class of models\nexplicitly designed for finance. This survey presents a comprehensive overview\nof FFMs, with a taxonomy spanning three key modalities: Financial Language\nFoundation Models (FinLFMs), Financial Time-Series Foundation Models\n(FinTSFMs), and Financial Visual-Language Foundation Models (FinVLFMs). We\nreview their architectures, training methodologies, datasets, and real-world\napplications. Furthermore, we identify critical challenges in data\navailability, algorithmic scalability, and infrastructure constraints, and\noffer insights into future research opportunities. We hope this survey serves\nas both a comprehensive reference for understanding FFMs and a practical\nroadmap for future innovation. An updated collection of FFM-related\npublications and resources will be maintained on our website\nhttps://github.com/FinFM/Awesome-FinFMs."}
{"id": "2507.17850", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17850", "abs": "https://arxiv.org/abs/2507.17850", "authors": ["Rodrigo Moreira", "Larissa F. Rodrigues Moreira", "Flávio de Oliveira Silva"], "title": "Performance Evaluation and Threat Mitigation in Large-scale 5G Core Deployment", "comment": null, "summary": "The deployment of large-scale software-based 5G core functions presents\nsignificant challenges due to their reliance on optimized and intelligent\nresource provisioning for their services. Many studies have focused on\nanalyzing the impact of resource allocation for complex deployments using\nmathematical models, queue theories, or even Artificial Intelligence (AI). This\npaper elucidates the effects of chaotic workloads, generated by Distributed\nDenial of Service (DDoS) on different Network Functions (NFs) on User Equipment\nregistration performance. Our findings highlight the necessity of diverse\nresource profiles to ensure Service-Level Agreement (SLA) compliance in\nlarge-scale 5G core deployments. Additionally, our analysis of packet capture\napproaches demonstrates the potential of kernel-based monitoring for scalable\nsecurity threat defense. Finally, our empirical evaluation provides insights\ninto the effective deployment of 5G NFs in complex scenarios."}
{"id": "2507.17888", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17888", "abs": "https://arxiv.org/abs/2507.17888", "authors": ["Nima Atashin", "Behrouz Tork Ladani", "Mohammadreza Sharbaf"], "title": "Learning to Locate: GNN-Powered Vulnerability Path Discovery in Open Source Code", "comment": "8 pages, 5 Figures", "summary": "Detecting security vulnerabilities in open-source software is a critical task\nthat is highly regarded in the related research communities. Several approaches\nhave been proposed in the literature for detecting vulnerable codes and\nidentifying the classes of vulnerabilities. However, there is still room to\nwork in explaining the root causes of detected vulnerabilities through locating\nvulnerable statements and the discovery of paths leading to the activation of\nthe vulnerability. While frameworks like SliceLocator offer explanations by\nidentifying vulnerable paths, they rely on rule-based sink identification that\nlimits their generalization. In this paper, we introduce VulPathFinder, an\nexplainable vulnerability path discovery framework that enhances SliceLocator's\nmethodology by utilizing a novel Graph Neural Network (GNN) model for detecting\nsink statements, rather than relying on predefined rules. The proposed GNN\ncaptures semantic and syntactic dependencies to find potential sink points\n(PSPs), which are candidate statements where vulnerable paths end. After\ndetecting PSPs, program slicing can be used to extract potentially vulnerable\npaths, which are then ranked by feeding them back into the target graph-based\ndetector. Ultimately, the most probable path is returned, explaining the root\ncause of the detected vulnerability. We demonstrated the effectiveness of the\nproposed approach by performing evaluations on a benchmark of the buffer\noverflow CWEs from the SARD dataset, providing explanations for the\ncorresponding detected vulnerabilities. The results show that VulPathFinder\noutperforms both original SliceLocator and GNNExplainer (as a general GNN\nexplainability tool) in discovery of vulnerability paths to identified PSPs."}
{"id": "2507.17956", "categories": ["cs.CR", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.17956", "abs": "https://arxiv.org/abs/2507.17956", "authors": ["Russell O'Connor", "Andrew Poelstra"], "title": "Formal Verification of the Safegcd Implementation", "comment": "15 pages; Coq sources can be found at\n  https://github.com/BlockstreamResearch/simplicity/tree/c1dddedd553b403da877377e658f17f0d2184cc4/Coq/C/secp256k1\n  ; Alectryon preview can be viewed at e.g.\n  https://html-preview.github.io/?url=https://github.com/BlockstreamResearch/simplicity/blob/c1dddedd553b403da877377e658f17f0d2184cc4/alectryon/verif_modinv64_impl.v.html", "summary": "The modular inverse is an essential piece of computation required for\nelliptic curve operations used for digital signatures in Bitcoin and other\napplications. A novel approach to the extended Euclidean algorithm has been\ndeveloped by Bernstein and Yang within the last few years and incorporated into\nthe libsecp256k1 cryptographic library used by Bitcoin. However, novel\nalgorithms introduce new risks of errors. To address this we have completed a\ncomputer verified proof of the correctness of (one of) libsecp256k1's modular\ninverse implementations with the Coq proof assistant using the Verifiable C's\nimplementation of separation logic."}
{"id": "2507.17780", "categories": ["cs.DM", "cs.AI", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.17780", "abs": "https://arxiv.org/abs/2507.17780", "authors": ["Randy Davila", "Boris Brimkov", "Ryan Pepper"], "title": "In Reverie Together: Ten Years of Mathematical Discovery with a Machine Collaborator", "comment": null, "summary": "We present four open conjectures in graph theory generated by the automated\nconjecturing system \\texttt{TxGraffiti}. Each conjecture is concise, grounded\nin natural graph invariants, and empirically validated across hundreds of\ngraphs. Despite extensive effort, these statements remain unresolved--defying\nboth proof and counterexample. They are not only mathematical challenges but\ncreative expressions--born of symbolic pattern recognition and\nmathematician-defined heuristics, refined through years of human dialogue, and\nnow offered back to the community as collaborative artifacts. These conjectures\ninvite not only formal proof, but also reflection on how machines can evoke\nwonder, spark curiosity, and contribute to the raw material of discovery. By\nhighlighting these problems, we aim to inspire both human mathematicians and AI\nsystems to engage with them--not only to solve them, but to reflect on what it\nmeans when machines participate meaningfully in the creative process of\nmathematical thought."}
{"id": "2507.17962", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17962", "abs": "https://arxiv.org/abs/2507.17962", "authors": ["Nowfel Mashnoor", "Mohammad Akyash", "Hadi Kamali", "Kimia Azar"], "title": "TimelyHLS: LLM-Based Timing-Aware and Architecture-Specific FPGA HLS Optimization", "comment": null, "summary": "Achieving timing closure and design-specific optimizations in FPGA-targeted\nHigh-Level Synthesis (HLS) remains a significant challenge due to the complex\ninteraction between architectural constraints, resource utilization, and the\nabsence of automated support for platform-specific pragmas. In this work, we\npropose TimelyHLS, a novel framework integrating Large Language Models (LLMs)\nwith Retrieval-Augmented Generation (RAG) to automatically generate and\niteratively refine HLS code optimized for FPGA-specific timing and performance\nrequirements. TimelyHLS is driven by a structured architectural knowledge base\ncontaining FPGA-specific features, synthesis directives, and pragma templates.\nGiven a kernel, TimelyHLS generates HLS code annotated with both\ntiming-critical and design-specific pragmas. The synthesized RTL is then\nevaluated using commercial toolchains, and simulation correctness is verified\nagainst reference outputs via custom testbenches. TimelyHLS iteratively\nincorporates synthesis logs and performance reports into the LLM engine for\nrefinement in the presence of functional discrepancies. Experimental results\nacross 10 FPGA architectures and diverse benchmarks show that TimelyHLS reduces\nthe need for manual tuning by up to 70%, while achieving up to 4x latency\nspeedup (e.g., 3.85x for Matrix Multiplication, 3.7x for Bitonic Sort) and over\n50% area savings in certain cases (e.g., 57% FF reduction in Viterbi).\nTimelyHLS consistently achieves timing closure and functional correctness\nacross platforms, highlighting the effectiveness of LLM-driven,\narchitecture-aware synthesis in automating FPGA design."}
{"id": "2507.17913", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.17913", "abs": "https://arxiv.org/abs/2507.17913", "authors": ["Elizaveta Iarovikova", "Andrey Kupavskii"], "title": "A complete $t$-intersection theorem for families of spanning trees", "comment": "arXiv admin note: text overlap with arXiv:2405.07843", "summary": "Let $\\mathcal T_n$ denote the set of all labelled spanning trees of $K_n$. A\nfamily $\\mathcal F \\subset \\mathcal T_n$ is $t$-intersecting if for all $A, B\n\\in \\mathcal F$ the trees $A$ and $B$ share at least $t$ edges. In this paper,\nwe determine for $n>n_0$ the size of the largest $t$-intersecting family\n$\\mathcal F\\subset \\mathcal T_n$ for all meaningful values of $t$ ($t\\le n-1$).\nThis result is a rare instance when a complete $t$-intersection theorem for a\ngiven type of structures is known."}
{"id": "2507.18021", "categories": ["math.ST", "cs.DS", "cs.LG", "math.FA", "math.PR", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.18021", "abs": "https://arxiv.org/abs/2507.18021", "authors": ["Yunbum Kook"], "title": "Zeroth-order log-concave sampling", "comment": "30 pages", "summary": "We study the zeroth-order query complexity of log-concave sampling,\nspecifically uniform sampling from convex bodies using membership oracles. We\npropose a simple variant of the proximal sampler that achieves the query\ncomplexity with matched R\\'enyi orders between the initial warmness and output\nguarantee. Specifically, for any $\\varepsilon>0$ and $q\\geq2$, the sampler,\ninitialized at $\\pi_{0}$, outputs a sample whose law is $\\varepsilon$-close in\n$q$-R\\'enyi divergence to $\\pi$, the uniform distribution over a convex body in\n$\\mathbb{R}^{d}$, using\n$\\widetilde{O}(qM_{q}^{q/(q-1)}d^{2}\\,\\lVert\\operatorname{cov}\\pi\\rVert\\log\\frac{1}{\\varepsilon})$\nmembership queries, where\n$M_{q}=\\lVert\\text{d}\\pi_{0}/\\text{d}\\pi\\rVert_{L^{q}(\\pi)}$.\n  We further introduce a simple annealing scheme that produces a warm start in\n$q$-R\\'enyi divergence (i.e., $M_{q}=O(1)$) using\n$\\widetilde{O}(qd^{2}R^{3/2}\\,\\lVert\\operatorname{cov}\\pi\\rVert^{1/4})$\nqueries, where $R^{2}=\\mathbb{E}_{\\pi}[|\\cdot|^{2}]$. This interpolates between\nknown complexities for warm-start generation in total variation and\nR\\'enyi-infinity divergence. To relay a R\\'enyi warmness across the annealing\nscheme, we establish hypercontractivity under simultaneous heat flow and\ntranslate it into an improved mixing guarantee for the proximal sampler under a\nlogarithmic Sobolev inequality. These results extend naturally to general\nlog-concave distributions accessible via evaluation oracles, incurring\nadditional quadratic queries."}
{"id": "2507.17776", "categories": ["math.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17776", "abs": "https://arxiv.org/abs/2507.17776", "authors": ["Jie Fan"], "title": "Axiomatizing Rumsfeld Ignorance", "comment": "This is an almost-final version", "summary": "In a recent paper, Kit Fine presents some striking results concerning the\nlogical properties of (first-order) ignorance, second-order ignorance and\nRumsfeld ignorance. However, Rumsfeld ignorance is definable in terms of\nignorance, which makes some existing results and the axiomatization problem\ntrivial. A main reason is that the accessibility relations for the implicit\nknowledge operator contained in the packaged operators of ignorance and\nRumsfeld ignorance are the same. In this work, we assume the two accessibility\nrelations to be different so that one of them is an arbitrary subset of the\nother. This will avoid the definability issue and retain most of the previous\nvalidities. The main results are axiomatizations over various proper bi-frame\nclasses. Finally we apply our framework to analyze Fine's results."}
{"id": "2507.17777", "categories": ["cs.AI", "76A02"], "pdf": "https://arxiv.org/pdf/2507.17777", "abs": "https://arxiv.org/abs/2507.17777", "authors": ["Theofanis Aravanis", "Grigorios Chrimatopoulos", "Mohammad Ferdows", "Michalis Xenos", "Efstratios Em Tzirtzilakis"], "title": "ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics", "comment": "This research was implemented in the framework of the Action\n  \"Flagship actions in interdisciplinary scientific fields with a special focus\n  on the productive fabric'', which is implemented through the National\n  Recovery and Resilience Fund Greece 2.0 and funded by the European\n  Union--NextGenerationEU (Project ID: TAEDR-0535983)", "summary": "Unlike conventional Machine-Learning (ML) approaches, often criticized as\n\"black boxes\", Symbolic Regression (SR) stands out as a powerful tool for\nrevealing interpretable mathematical relationships in complex physical systems,\nrequiring no a priori assumptions about models' structures. Motivated by the\nrecognition that, in fluid mechanics, an understanding of the underlying flow\nphysics is as crucial as accurate prediction, this study applies SR to model a\nfundamental three-dimensional (3D) incompressible flow in a rectangular\nchannel, focusing on the (axial) velocity and pressure fields under laminar\nconditions. By employing the PySR library, compact symbolic equations were\nderived directly from numerical simulation data, revealing key characteristics\nof the flow dynamics. These equations not only approximate the parabolic\nvelocity profile and pressure drop observed in the studied fluid flow, but also\nperfectly coincide with analytical solutions from the literature. Furthermore,\nwe propose an innovative approach that integrates SR with the\nknowledge-representation framework of Answer Set Programming (ASP), combining\nthe generative power of SR with the declarative reasoning strengths of ASP. The\nproposed hybrid SR/ASP framework ensures that the SR-generated symbolic\nexpressions are not only statistically accurate, but also physically plausible,\nadhering to domain-specific principles. Overall, the study highlights two key\ncontributions: SR's ability to simplify complex flow behaviours into concise,\ninterpretable equations, and the potential of knowledge-representation\napproaches to improve the reliability and alignment of data-driven SR models\nwith domain principles. Insights from the examined 3D channel flow pave the way\nfor integrating such hybrid approaches into efficient frameworks, [...] where\nexplainable predictions and real-time data analysis are crucial."}
{"id": "2507.17949", "categories": ["math.NT", "11F11, 11F30"], "pdf": "https://arxiv.org/pdf/2507.17949", "abs": "https://arxiv.org/abs/2507.17949", "authors": ["Paul Jenkins", "Jeremy Rouse"], "title": "Modular Forms with Only Nonnegative Coefficients", "comment": "23 pages", "summary": "We study modular forms for $\\textrm{SL}_2(\\mathbb{Z})$ with no negative\nFourier coefficients. Let $A(k)$ be the positive integer where if the first\n$A(k)$ Fourier coefficients of a modular form of weight $k$ for\n$\\textrm{SL}_2(\\mathbb{Z})$ are nonnegative, then all of its Fourier\ncoefficients are nonnegative, so that $A(k)$ can be interpreted as a\n``nonnegativity Sturm bound''. We give upper and lower bounds for $A(k)$, as\nwell as an upper bound on the $n$th Fourier coefficient of any form with no\nnegative Fourier coefficients."}
{"id": "2507.17939", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.17939", "abs": "https://arxiv.org/abs/2507.17939", "authors": ["Chris King", "Homayoun Hamedmoghadam", "Christos Cassandras", "Fabian Wirth", "Robert Shorten"], "title": "Dynamic access pricing control for fair and stable resource sharing", "comment": "13 pages, 9 figures", "summary": "In this paper we consider the use of pricing as a regulatory mechanism when\nan unknown number of autonomous agents compete for access to a scarce shared\nresource. In standard dynamic pricing systems, an increasing price is used to\nbalance supply and demand for a resource in a constrained environment. A major\ndrawback of dynamic pricing is that it is socially regressive as such systems\nfavour price-insensitive traffic (inelastic) and control the demand at the\nexpense of price-sensitive traffic (elastic). We tackle this challenge by\ndescribing a new form of pricing that strikes a balance between using price to\nmanage demand for a resource and ensuring fair access to the resource for both\nelastic and inelastic traffic. Our system gives rise to a switched non-linear\nODE model, the stability of which is equivalent to ensuring the fairness\nproperties of the pricing system. Simulations demonstrate the efficacy of the\noverall design."}
{"id": "2507.17885", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.17885", "abs": "https://arxiv.org/abs/2507.17885", "authors": ["Bojana Borovićanin", "Dragana Božović", "Edin Glogić", "Daša Mesarič Štesl", "Simon Špacapan", "Emir Zogić"], "title": "New results on the Wiener index of trees with a given diameter", "comment": null, "summary": "We study the Wiener index of a class of trees with fixed diameter and order.\nA double broom is a tree such that there exist two vertices $u$ and $v$, such\nthat each leaf of $T$ is adjacent to $u$ or $v$. We prove that for a tree $T$\nof diameter $d$ and (sufficiently large) order $n$ such that $n\\leq d-2+4\n\\left\\lfloor \\sqrt{ \\frac{d-1}{2}} \\right\\rfloor$, $T$ has maximum Wiener index\n(in the class of trees of diameter $d$ and order $n$) if and only if $T$ is a\ndouble broom. Our results are sharp up to a small constant."}
{"id": "2507.17978", "categories": ["cs.CR", "cs.AI", "cs.HC", "68P20 (Primary) 68T05, 68T07, 68T10 (Secondary)", "K.6.5; I.2.6; I.2.7; C.2.0"], "pdf": "https://arxiv.org/pdf/2507.17978", "abs": "https://arxiv.org/abs/2507.17978", "authors": ["Paulo Mendes", "Eva Maia", "Isabel Praça"], "title": "MeAJOR Corpus: A Multi-Source Dataset for Phishing Email Detection", "comment": "8 pages, 2 tables, WI-IAT 2025 conference", "summary": "Phishing emails continue to pose a significant threat to cybersecurity by\nexploiting human vulnerabilities through deceptive content and malicious\npayloads. While Machine Learning (ML) models are effective at detecting\nphishing threats, their performance largely relies on the quality and diversity\nof the training data. This paper presents MeAJOR (Merged email Assets from\nJoint Open-source Repositories) Corpus, a novel, multi-source phishing email\ndataset designed to overcome critical limitations in existing resources. It\nintegrates 135894 samples representing a broad number of phishing tactics and\nlegitimate emails, with a wide spectrum of engineered features. We evaluated\nthe dataset's utility for phishing detection research through systematic\nexperiments with four classification models (RF, XGB, MLP, and CNN) across\nmultiple feature configurations. Results highlight the dataset's effectiveness,\nachieving 98.34% F1 with XGB. By integrating broad features from multiple\ncategories, our dataset provides a reusable and consistent resource, while\naddressing common challenges like class imbalance, generalisability and\nreproducibility."}
{"id": "2507.18129", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.18129", "abs": "https://arxiv.org/abs/2507.18129", "authors": ["Yaacov Pariente", "Vadim Indelman"], "title": "Bounding Conditional Value-at-Risk via Auxiliary Distributions with Bounded Discrepancies", "comment": null, "summary": "In this paper, we develop a theoretical framework for bounding the CVaR of a\nrandom variable $X$ using another related random variable $Y$, under\nassumptions on their cumulative and density functions. Our results yield\npractical tools for approximating $\\operatorname{CVaR}_\\alpha(X)$ when direct\ninformation about $X$ is limited or sampling is computationally expensive, by\nexploiting a more tractable or observable random variable $Y$. Moreover, the\nderived bounds provide interpretable concentration inequalities that quantify\nhow the tail risk of $X$ can be controlled via $Y$."}
{"id": "2507.18245", "categories": ["math.LO", "Primary: 54E55. Secondary: 06D50, 06D22, 06E15, 06F30, 06B35, 06D05"], "pdf": "https://arxiv.org/pdf/2507.18245", "abs": "https://arxiv.org/abs/2507.18245", "authors": ["Marco Abbadini", "Achim Jung"], "title": "On the symmetry behind duality", "comment": null, "summary": "Open sets and compact saturated sets enjoy a perfect formal symmetry, at\nleast for classes of spaces such as Stone spaces or spectral spaces. For larger\nclasses of spaces, a perfect symmetry may not be available, although strong\nsigns of it may remain. These signs appear especially in the classes of spaces\ninvolved in Stone-like dualities (such as sober spaces).\n  In this article, we introduce a framework with a perfect symmetry between\nopen sets and compact saturated sets, and which includes sober spaces. Our main\nresult is an extension of the duality between sober spaces and spatial frames\nto a duality between two categories, each equipped with a self-duality. On the\nspatial side, the self-duality extends de Groot self-duality for stably compact\nspaces, which swaps open sets with complements of compact saturated sets; this\nself-duality is made possible using structures reminiscent of bitopological\nspaces. On the pointfree side, the self-duality is an extension of Lawson\nself-duality for continuous domains and is achieved via a framework analogous\nto that of d-frames.\n  We show how to derive from our main result the well-known duality between\nlocally compact sober spaces and locally compact frames. In doing so, we\nprovide a presentation of continuous domains in a manner akin to d-frames."}
{"id": "2507.17874", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17874", "abs": "https://arxiv.org/abs/2507.17874", "authors": ["SaiBarath Sundar", "Pranav Satheesan", "Udayaadithya Avadhanam"], "title": "I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis", "comment": null, "summary": "Recent advances in agentic systems for data analysis have emphasized\nautomation of insight generation through multi-agent frameworks, and\norchestration layers. While these systems effectively manage tasks like query\ntranslation, data transformation, and visualization, they often overlook the\nstructured reasoning process underlying analytical thinking. Reasoning large\nlanguage models (LLMs) used for multi-step problem solving are trained as\ngeneral-purpose problem solvers. As a result, their reasoning or thinking steps\ndo not adhere to fixed processes for specific tasks. Real-world data analysis\nrequires a consistent cognitive workflow: interpreting vague goals, grounding\nthem in contextual knowledge, constructing abstract plans, and adapting\nexecution based on intermediate outcomes. We introduce I2I-STRADA\n(Information-to-Insight via Structured Reasoning Agent for Data Analysis), an\nagentic architecture designed to formalize this reasoning process. I2I-STRADA\nfocuses on modeling how analysis unfolds via modular sub-tasks that reflect the\ncognitive steps of analytical reasoning. Evaluations on the DABstep and DABench\nbenchmarks show that I2I-STRADA outperforms prior systems in planning coherence\nand insight alignment, highlighting the importance of structured cognitive\nworkflows in agent design for data analysis."}
{"id": "2507.17967", "categories": ["math.NT", "math.AG", "11F80, 14G05, 11G05, 11D72, 11D41"], "pdf": "https://arxiv.org/pdf/2507.17967", "abs": "https://arxiv.org/abs/2507.17967", "authors": ["Lorenzo Furio", "Davide Lombardo"], "title": "On 7-adic Galois representations for elliptic curves over $\\mathbb{Q}$", "comment": "32 pages", "summary": "In recent years, significant progress has been made on Mazur's Program B,\nwith many authors beginning a systematic classification of all possible images\nof $p$-adic Galois representations attached to elliptic curves over\n$\\mathbb{Q}$. Currently, the classification is only complete for $p \\in\n\\{2,3,13,17\\}$. The main difficulty for other primes arises from the need to\nunderstand elliptic curves whose mod-$p^n$ Galois representations are contained\nin the normaliser of a non-split Cartan subgroup. Equivalently, this amounts to\ndetermining the rational points on the modular curves $X_{ns}^+(p^n)$. Here, we\nconsider the case $p=7$ and show that the modular curve $X_{ns}^+(49)$, of\ngenus 69, has no non-CM rational points. To achieve this, we establish a\ncorrespondence between the rational points on $X_{ns}^+(49)$ and the primitive\ninteger solutions of the generalised Fermat equation $a^2 + 28b^3 = 27 c^7$,\nthe resolution of which can be reduced to determining the rational points of\nseveral genus-three curves. Furthermore, we reduce the complete classification\nof $7$-adic images to the determination of the rational points of a single\nplane quartic."}
{"id": "2507.17983", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.17983", "abs": "https://arxiv.org/abs/2507.17983", "authors": ["Ang Xu", "Chiwei Yan"], "title": "Dispatching and Pricing in Two-Sided Spatial Queues", "comment": null, "summary": "We study a dispatching and pricing problem in two-sided spatial queues with\nfixed supply, motivated by ride-hailing and robotaxi platforms. Idle drivers\nqueue on one side, waiting to pick up riders, while riders queue on the other,\nwaiting to be matched with available drivers. The platform seeks to maximize\nnet profit, penalized by rider waiting penalties, by jointly optimizing\nstate-dependent dispatching and pricing decisions. We formulate this problem as\na Markov decision process with state-dependent service times that capture key\nfeatures of spatial matching. We show that, under mild assumptions, the optimal\ndispatching policy admits a closed-form expression with a zigzag structure.\nThis policy significantly improves the tractability of pricing optimization due\nto the resulting closed-form stationary distribution and a substantially\nreduced state space. Building on this insight, we propose an efficient and\nscalable dynamic programming heuristic to approximate the optimal zigzag policy\nin more general settings. Extensive numerical experiments with both the\nanalytical model and a ride-hailing simulation demonstrate that our algorithm\nis both near-optimal and highly scalable."}
{"id": "2507.17913", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.17913", "abs": "https://arxiv.org/abs/2507.17913", "authors": ["Elizaveta Iarovikova", "Andrey Kupavskii"], "title": "A complete $t$-intersection theorem for families of spanning trees", "comment": "arXiv admin note: text overlap with arXiv:2405.07843", "summary": "Let $\\mathcal T_n$ denote the set of all labelled spanning trees of $K_n$. A\nfamily $\\mathcal F \\subset \\mathcal T_n$ is $t$-intersecting if for all $A, B\n\\in \\mathcal F$ the trees $A$ and $B$ share at least $t$ edges. In this paper,\nwe determine for $n>n_0$ the size of the largest $t$-intersecting family\n$\\mathcal F\\subset \\mathcal T_n$ for all meaningful values of $t$ ($t\\le n-1$).\nThis result is a rare instance when a complete $t$-intersection theorem for a\ngiven type of structures is known."}
{"id": "2507.18034", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18034", "abs": "https://arxiv.org/abs/2507.18034", "authors": ["Haonan An", "Guang Hua", "Hangcheng Cao", "Zhengru Fang", "Guowen Xu", "Susanto Rahardja", "Yuguang Fang"], "title": "Removing Box-Free Watermarks for Image-to-Image Models via Query-Based Reverse Engineering", "comment": null, "summary": "The intellectual property of deep generative networks (GNets) can be\nprotected using a cascaded hiding network (HNet) which embeds watermarks (or\nmarks) into GNet outputs, known as box-free watermarking. Although both GNet\nand HNet are encapsulated in a black box (called operation network, or ONet),\nwith only the generated and marked outputs from HNet being released to end\nusers and deemed secure, in this paper, we reveal an overlooked vulnerability\nin such systems. Specifically, we show that the hidden GNet outputs can still\nbe reliably estimated via query-based reverse engineering, leaking the\ngenerated and unmarked images, despite the attacker's limited knowledge of the\nsystem. Our first attempt is to reverse-engineer an inverse model for HNet\nunder the stringent black-box condition, for which we propose to exploit the\nquery process with specially curated input images. While effective, this method\nyields unsatisfactory image quality. To improve this, we subsequently propose\nan alternative method leveraging the equivalent additive property of box-free\nmodel watermarking and reverse-engineering a forward surrogate model of HNet,\nwith better image quality preservation. Extensive experimental results on image\nprocessing and image generation tasks demonstrate that both attacks achieve\nimpressive watermark removal success rates (100%) while also maintaining\nexcellent image quality (reaching the highest PSNR of 34.69 dB), substantially\noutperforming existing attacks, highlighting the urgent need for robust\ndefensive strategies to mitigate the identified vulnerability in box-free model\nwatermarking."}
{"id": "2507.18170", "categories": ["math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.18170", "abs": "https://arxiv.org/abs/2507.18170", "authors": ["Nils Sturma", "Mathias Drton"], "title": "Trek-Based Parameter Identification for Linear Causal Models With Arbitrarily Structured Latent Variables", "comment": null, "summary": "We develop a criterion to certify whether causal effects are identifiable in\nlinear structural equation models with latent variables. Linear structural\nequation models correspond to directed graphs whose nodes represent the random\nvariables of interest and whose edges are weighted with linear coefficients\nthat correspond to direct causal effects. In contrast to previous\nidentification methods, we do not restrict ourselves to settings where the\nlatent variables constitute independent latent factors (i.e., to source nodes\nin the graphical representation of the model). Our novel latent-subgraph\ncriterion is a purely graphical condition that is sufficient for\nidentifiability of causal effects by rational formulas in the covariance\nmatrix. To check the latent-subgraph criterion, we provide a sound and complete\nalgorithm that operates by solving an integer linear program. While it targets\neffects involving observed variables, our new criterion is also useful for\nidentifying effects between latent variables, as it allows one to transform the\ngiven model into a simpler measurement model for which other existing tools\nbecome applicable."}
{"id": "2507.18564", "categories": ["math.LO", "math.GN", "03D55, 54D10 (Primary) 03D45, 06A05, 54G20 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.18564", "abs": "https://arxiv.org/abs/2507.18564", "authors": ["Andrew DeLapo", "David Gonzalez"], "title": "Computability of Separation Axioms in Countable Second Countable Spaces", "comment": null, "summary": "We analyze the effective content of countable, second countable topological\nspaces by directly calculating the complexity of several topologically defined\nindex sets. We focus on the separation principles, calibrating an arithmetic\ncompleteness result for each of the Tychonoff separation axioms. Beyond this,\nwe prove completeness results for various other topological properties, such as\nbeing Polish and having a particular Cantor-Bendixson rank, using tools from\ncomputable structure theory. This work contrasts with previous work analyzing\ncountable, second countable spaces which used the framework of reverse\nmathematics, as reverse mathematics generally lacks the precision to pin down\nexact arithmetic complexity levels for properties of interest."}
{"id": "2507.17927", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17927", "abs": "https://arxiv.org/abs/2507.17927", "authors": ["Timothy Tin Long Yu", "Mahdi Mostajabdaveh", "Jabo Serge Byusa", "Rindra Ramamonjison", "Giuseppe Carenini", "Kun Mao", "Zirui Zhou", "Yong Zhang"], "title": "SMARTAPS: Tool-augmented LLMs for Operations Management", "comment": "https://aaai.org/conference/aaai/aaai-25/bridge-ai-orms/", "summary": "Large language models (LLMs) present intriguing opportunities to enhance user\ninteraction with traditional algorithms and tools in real-world applications.\nAn advanced planning system (APS) is a sophisticated software that leverages\noptimization to help operations planners create, interpret, and modify an\noperational plan. While highly beneficial, many customers are priced out of\nusing an APS due to the ongoing costs of consultants responsible for\ncustomization and maintenance. To address the need for a more accessible APS\nexpressed by supply chain planners, we present SmartAPS, a conversational\nsystem built on a tool-augmented LLM. Our system provides operations planners\nwith an intuitive natural language chat interface, allowing them to query\ninformation, perform counterfactual reasoning, receive recommendations, and\nexecute scenario analysis to better manage their operation. A short video\ndemonstrating the system has been released: https://youtu.be/KtIrJjlDbyw"}
{"id": "2507.17986", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.17986", "abs": "https://arxiv.org/abs/2507.17986", "authors": ["Milad Ghadimi"], "title": "Heuristic Bounded Prime Gaps via a Chaotic Multidimensional Sieve and Random Matrix Theory", "comment": null, "summary": "We present the Enhanced Multidimensional Chaotic Heuristic Sieve (EMCHS), a\nnovel probabilistic framework that integrates chaotic perturbations and random\nmatrix theory (RMT) to suggest improved bounds on prime gaps. Building upon the\nfoundational sieves of Goldston-Pintz-Yildirim and Maynard, EMCHS heuristically\nsuggests unconditional gaps of at most 180 and conditional gaps of at most 8\nunder a partial Elliott-Halberstam conjecture (EHC) with delta = 0.3. These\nheuristic suggestions surpass Maynard's unconditional bound of 246 through\nrefined polytope optimizations and probabilistic enhancements. We provide\nrigorous proofs for certain analytic components (such as bounding chaotic\nperturbations via ergodic theory) and explicitly distinguish which arguments\nand conclusions are heuristic or conjectural. Numerical evidence for primes up\nto 10^18 supports the framework, and we discuss limitations and avenues for\nfuture rigorous work."}
{"id": "2507.18030", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.18030", "abs": "https://arxiv.org/abs/2507.18030", "authors": ["Takuya Ikeda", "Masaaki Nagahara"], "title": "Sparse optimal control for infinite-dimensional linear systems with applications to graphon control", "comment": "16 pages", "summary": "Large-scale networked systems typically operate under resource constraints,\nand it is also difficult to exactly obtain the network structure between nodes.\nTo address these issues, this paper investigates a sparse optimal control for\ninfinite-dimensional linear systems and its application to networked systems\nwhere the network structure is represented by a limit function called a graphon\nthat captures the overall connection pattern. The contributions of this paper\nare twofold: (i) To reduce computational complexity, we derive a sufficient\ncondition under which the sparse optimal control can be obtained by solving its\ncorresponding L1 optimization problem. Furthermore, we introduce a class of\nnon-convex optimal control problems such that the optimal solution always\ncoincides with a sparse optimal control, provided that the non-convex problems\nadmit optimal solutions. (ii) We show that the sparse optimal control for\nlarge-scale finite-dimensional networked systems can be approximated by that of\nthe corresponding limit graphon system, provided that the underlying graph is\nclose to the limit graphon in the cut-norm topology. The effectiveness of the\nproposed approach is illustrated through numerical examples."}
{"id": "2507.17947", "categories": ["math.CO", "05A15, 05A05"], "pdf": "https://arxiv.org/pdf/2507.17947", "abs": "https://arxiv.org/abs/2507.17947", "authors": ["Toufik Mansour", "Mark Shattuck"], "title": "On ascent sequences avoiding 021 and a pattern of length four", "comment": null, "summary": "Ascent sequences of length $n$ avoiding the pattern $021$ are enumerated by\nthe $n$-th Catalan number $C_n=\\frac{1}{n+1}\\binom{2n}{n}$. In this paper, we\nextend this result and enumerate ascent sequences avoiding $\\{021,\\tau\\}$,\nwhere $\\tau$ is a pattern of length four. We in turn identify all of the\ncorresponding Wilf-equivalence classes and find generating function formulas\ncorresponding to each class. In a couple of cases, we make use of an auxiliary\nstatistic and the kernel method to ascertain the generating function. In\nseveral cases, our work of enumeration is shortened by establishing the\nequivalence of $\\{021,\\tau\\}$- and $\\{021,\\tau'\\}$-avoiders of a given length\nthrough an explicit bijection. As a consequence of our results, one obtains new\ncombinatorial interpretations in terms of ascent sequences for several of the\nentries in the OEIS."}
{"id": "2507.18036", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.18036", "abs": "https://arxiv.org/abs/2507.18036", "authors": ["Haonan An", "Guang Hua", "Yu Guo", "Hangcheng Cao", "Susanto Rahardja", "Yuguang Fang"], "title": "NWaaS: Nonintrusive Watermarking as a Service for X-to-Image DNN", "comment": null, "summary": "The intellectual property of deep neural network (DNN) models can be\nprotected with DNN watermarking, which embeds copyright watermarks into model\nparameters (white-box), model behavior (black-box), or model outputs\n(box-free), and the watermarks can be subsequently extracted to verify model\nownership or detect model theft. Despite recent advances, these existing\nmethods are inherently intrusive, as they either modify the model parameters or\nalter the structure. This natural intrusiveness raises concerns about\nwatermarking-induced shifts in model behavior and the additional cost of\nfine-tuning, further exacerbated by the rapidly growing model size. As a\nresult, model owners are often reluctant to adopt DNN watermarking in practice,\nwhich limits the development of practical Watermarking as a Service (WaaS)\nsystems. To address this issue, we introduce Nonintrusive Watermarking as a\nService (NWaaS), a novel trustless paradigm designed for X-to-Image models, in\nwhich we hypothesize that with the model untouched, an owner-defined watermark\ncan still be extracted from model outputs. Building on this concept, we propose\nShadowMark, a concrete implementation of NWaaS which addresses critical\ndeployment challenges by establishing a robust and nonintrusive side channel in\nthe protected model's black-box API, leveraging a key encoder and a watermark\ndecoder. It is significantly distinctive from existing solutions by attaining\nthe so-called absolute fidelity and being applicable to different DNN\narchitectures, while being also robust against existing attacks, eliminating\nthe fidelity-robustness trade-off. Extensive experiments on image-to-image,\nnoise-to-image, noise-and-text-to-image, and text-to-image models, demonstrate\nthe efficacy and practicality of ShadowMark for real-world deployment of\nnonintrusive DNN watermarking."}
{"id": "2507.18279", "categories": ["math.ST", "math.AP", "math.DS", "math.PR", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.18279", "abs": "https://arxiv.org/abs/2507.18279", "authors": ["Dimiri Konen", "Richard Nickl"], "title": "Data assimilation with the 2D Navier-Stokes equations: Optimal Gaussian asymptotics for the posterior measure", "comment": null, "summary": "A functional Bernstein - von Mises theorem is proved for posterior measures\narising in a data assimilation problem with the two-dimensional Navier-Stokes\nequation where a Gaussian process prior is assigned to the initial condition of\nthe system. The posterior measure, which provides the update in the space of\nall trajectories arising from a discrete sample of the (deterministic)\ndynamics, is shown to be approximated by a Gaussian random vector field arising\nfrom the solution to a linear parabolic PDE with Gaussian initial condition.\nThe approximation holds in the strong sense of the supremum norm on the\nregression functions, showing that predicting future states of Navier-Stokes\nsystems admits $1/\\sqrt N$-consistent estimators even for commonly used\nnonparametric models. Consequences for coverage of credible bands and\nuncertainty quantification are discussed. A local asymptotic minimax theorem is\nderived that describes the lower bound for estimating the state of the\nnonlinear system, which is shown to be attained by the Bayesian data\nassimilation algorithm."}
{"id": "2507.17988", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17988", "abs": "https://arxiv.org/abs/2507.17988", "authors": ["Dario Della Monica", "Angelo Montanari", "Pietro Sala"], "title": "Synthesis of timeline-based planning strategies avoiding determinization", "comment": "arXiv admin note: text overlap with arXiv:2410.22757", "summary": "Qualitative timeline-based planning models domains as sets of independent,\nbut\n  interacting, components whose behaviors over time, the timelines, are\ngoverned\n  by sets of qualitative temporal constraints (ordering relations), called\n  synchronization rules.\n  Its plan-existence problem has been shown to be PSPACE-complete; in\n  particular, PSPACE-membership has been proved via reduction to the\n  nonemptiness problem for nondeterministic finite automata.\n  However, nondeterministic automata cannot be directly used to synthesize\n  planning strategies as a costly determinization step is needed.\n  In this paper, we identify a fragment of qualitative timeline-based planning\n  whose plan-existence problem can be directly mapped into the nonemptiness\n  problem of deterministic finite automata, which can then\n  synthesize strategies.\n  In addition, we identify a maximal subset of Allen's relations that fits into\n  such a deterministic fragment."}
{"id": "2507.18057", "categories": ["math.NT", "Primary: 11P05. Secondary: 11P55, 11L07, 11L15"], "pdf": "https://arxiv.org/pdf/2507.18057", "abs": "https://arxiv.org/abs/2507.18057", "authors": ["Anji Dong", "Katerina Saettone", "Kendra Song", "Alexandru Zaharescu"], "title": "Cannonball Polygons with Multiplicities", "comment": "22 pages", "summary": "We generalize the Cannonball Problem by introducing integer-valued and\nnon-increasing arithmetic functions $w$. We associate these functions $w$ with\ncertain polygons, which we call cannonball polygons. Through this\ncorrespondence, we show that for any $Z\\in\\mathbb{N}$, there exists a\ncannonball polygon with multiplicity 8 and largest side of length $Z$.\nMoreover, for any multiplicity $s$ greater than 8, we provide an asymptotic\nformula for the number of distinct classes of cannonball polygons with\nmultiplicity $s$."}
{"id": "2507.18114", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.18114", "abs": "https://arxiv.org/abs/2507.18114", "authors": ["Lechen Feng", "Xun Li", "Yuan-Hua Ni"], "title": "Nonconvex Optimization Framework for Group-Sparse Feedback Linear-Quadratic Optimal Control I: Penalty Approach", "comment": null, "summary": "This paper develops a unified nonconvex optimization framework for the design\nof group-sparse feedback controllers in infinite-horizon linear-quadratic (LQ)\nproblems. We address two prominent extensions of the classical LQ problem: the\ndistributed LQ problem with fixed communication topology (DFT-LQ) and the\nsparse feedback LQ problem (SF-LQ), both of which are motivated by the need for\nscalable and structure-aware control in large-scale systems. Unlike existing\napproaches that rely on convex relaxations or are limited to block-diagonal\nstructures, we directly formulate the controller synthesis as a\nfinite-dimensional nonconvex optimization problem with group $\\ell_0$-norm\nregularization, capturing general sparsity patterns. We establish a connection\nbetween DFT-LQ and SF-LQ problems, showing that both can be addressed within\nour unified framework. Furthermore, we propose a penalty-based proximal\nalternating linearized minimization (PALM) algorithm and provide a rigorous\nconvergence analysis under mild assumptions, overcoming the lack of coercivity\nin the objective function. The proposed method admits efficient solvers for all\nsubproblems and guarantees global convergence to critical points. Our results\nfill a key gap in the literature by enabling the direct design of group-sparse\nfeedback gains with theoretical guarantees, without resorting to convex\nsurrogates or restrictive structural assumptions."}
{"id": "2507.18045", "categories": ["math.CO", "math.GR"], "pdf": "https://arxiv.org/pdf/2507.18045", "abs": "https://arxiv.org/abs/2507.18045", "authors": ["Shuxing Li", "Koji Momihara"], "title": "Cyclotomic construction of $λ$-fold near-factorizations of cyclic groups", "comment": "11 pages", "summary": "The study of near-factorizations of finite groups dates back to the 1950s.\nRecently, this topic has attracted renewed attention, and the concept has been\nextended to $\\lambda$-fold near-factorizations, in which each non-identity\ngroup element appears exactly $\\lambda \\ge 1$ times. This paper presents a\ncyclotomic construction of $\\lambda$-fold near-factorizations in the cyclic\ngroup $\\mathbb{F}_p$, where $p = 4n^4 + 12n^2 + 1$ is prime for $n \\ge 1$."}
{"id": "2507.18053", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.18053", "abs": "https://arxiv.org/abs/2507.18053", "authors": ["Haoran Gao", "Yuanhe Zhang", "Zhenhong Zhou", "Lei Jiang", "Fanyu Meng", "Yujia Xiao", "Kun Wang", "Yang Liu", "Junlan Feng"], "title": "RECALLED: An Unbounded Resource Consumption Attack on Large Vision-Language Models", "comment": null, "summary": "Resource Consumption Attacks (RCAs) have emerged as a significant threat to\nthe deployment of Large Language Models (LLMs). With the integration of vision\nmodalities, additional attack vectors exacerbate the risk of RCAs in large\nvision-language models (LVLMs). However, existing red-teaming studies have\nlargely overlooked visual inputs as a potential attack surface, resulting in\ninsufficient mitigation strategies against RCAs in LVLMs. To address this gap,\nwe propose RECALLED (\\textbf{RE}source \\textbf{C}onsumption \\textbf{A}ttack on\n\\textbf{L}arge Vision-\\textbf{L}anguag\\textbf{E} Mo\\textbf{D}els), the first\napproach for exploiting visual modalities to trigger unbounded RCAs\nred-teaming. First, we present \\textit{Vision Guided Optimization}, a\nfine-grained pixel-level optimization, to obtain \\textit{Output Recall}\nadversarial perturbations, which can induce repeating output. Then, we inject\nthe perturbations into visual inputs, triggering unbounded generations to\nachieve the goal of RCAs. Additionally, we introduce \\textit{Multi-Objective\nParallel Losses} to generate universal attack templates and resolve\noptimization conflicts when intending to implement parallel attacks. Empirical\nresults demonstrate that RECALLED increases service response latency by over 26\n$\\uparrow$, resulting in an additional 20\\% increase in GPU utilization and\nmemory consumption. Our study exposes security vulnerabilities in LVLMs and\nestablishes a red-teaming framework that can facilitate future defense\ndevelopment against RCAs."}
{"id": "2507.18307", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.18307", "abs": "https://arxiv.org/abs/2507.18307", "authors": ["Mateusz Krukowski"], "title": "ROC curves for LDA classifiers", "comment": null, "summary": "In the paper, we derive an analytic formula for the ROC curves of the LDA\nclassifiers. We establish elementary properties of these curves (monotonicity\nand concavity) and provide formulae for the area under curve (AUC) and the\nYouden J-index."}
{"id": "2507.18004", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18004", "abs": "https://arxiv.org/abs/2507.18004", "authors": ["Yusen Peng", "Shuhua Mao"], "title": "E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI", "comment": "44 pages,11 figures", "summary": "How can AI move beyond imitation toward genuine creativity? This paper\nproposes the E.A.R.T.H. framework, a five-stage generative pipeline that\ntransforms model-generated errors into creative assets through Error\ngeneration, Amplification, Refine selection, Transform, and Harness feedback.\nDrawing on cognitive science and generative modeling, we posit that \"creative\npotential hides in failure\" and operationalize this via structured prompts,\nsemantic scoring, and human-in-the-loop evaluation. Implemented using\nLLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2, and Stable Diffusion, the\npipeline employs a composite reward function based on novelty, surprise, and\nrelevance. At the Refine stage, creativity scores increase by 52.5% (1.179 to\n1.898, t = -5.56, p < 0.001), with final outputs reaching 2.010 - a 70.4%\nimprovement. Refined slogans are 48.4% shorter, 40.7% more novel, with only a\n4.0% drop in relevance. Cross-modal tests show strong slogan-to-image alignment\n(CLIPScore: 0.249; BERTScore F1: 0.816). In human evaluations, 60% of outputs\nscored >= 4.0, with metaphorical slogans (avg. 4.09) outperforming literal ones\n(3.99). Feedback highlights stylistic precision and emotional resonance. These\nresults demonstrate that error-centered, feedback-driven generation enhances\ncreativity, offering a scalable path toward self-evolving, human-aligned\ncreative AI."}
{"id": "2507.18121", "categories": ["math.NT", "Primary 11M06, 11R42, Secondary 11M26"], "pdf": "https://arxiv.org/pdf/2507.18121", "abs": "https://arxiv.org/abs/2507.18121", "authors": ["Diksha Rani Bansal", "Bibekananda Maji"], "title": "Number Field Analogue of Jacobi Theta Relation And Zeros of Dedekind zeta function on Re$(s)=1/2$", "comment": "30 pages, comments are welcome!", "summary": "In 1914, Hardy proved that there are infinitely many non-trivial zeros of the\nRiemann zeta function $\\zeta(s)$ on the critical line Re$(s)=1/2$ using the\nJacobi theta relation. In this paper, we first establish a number field\nanalogue of the Jacobi theta relation and as an application, we show the\nexistence of infinitely many non-trivial zeros of the Dedekind zeta function\n$\\zeta_\\mathbb{F}(s)$ on Re$(s)=1/2$, for any number field $\\mathbb{F}$. Quite\ninterestingly, we also prove that the Jacobi theta relation is equivalent to an\nintriguing identity of Hardy, Littlewood and Ramanujan."}
{"id": "2507.18277", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.18277", "abs": "https://arxiv.org/abs/2507.18277", "authors": ["Dongxuan Zhu", "Weihuan Huang", "Caihua Chen"], "title": "Boosting Accelerated Proximal Gradient Method with Adaptive Sampling for Stochastic Composite Optimization", "comment": "31 pages", "summary": "We develop an adaptive Nesterov accelerated proximal gradient (adaNAPG)\nalgorithm for stochastic composite optimization problems, boosting the Nesterov\naccelerated proximal gradient (NAPG) algorithm through the integration of an\nadaptive sampling strategy for gradient estimation. We provide a complexity\nanalysis demonstrating that the new algorithm, adaNAPG, achieves both the\noptimal iteration complexity and the optimal sample complexity as outlined in\nthe existing literature. Additionally, we establish a central limit theorem for\nthe iteration sequence of the new algorithm adaNAPG, elucidating its\nconvergence rate and efficiency."}
{"id": "2507.18090", "categories": ["math.CO", "05C10, 05C30, 05C38, 05C40"], "pdf": "https://arxiv.org/pdf/2507.18090", "abs": "https://arxiv.org/abs/2507.18090", "authors": ["Gyaneshwar Agrahari", "Xiaonan Liu", "Zhiyu Wang"], "title": "Counting $k$-cycles in $5$-connected planar triangulations", "comment": null, "summary": "We show that every $n$-vertex $5$-connected planar triangulation has at most\n$9n-50$ many cycles of length $5$ for all $n\\ge 20$ and this upper bound is\ntight. We also show that for every $k\\geq 6$, there exists some constant $C(k)$\nsuch that for sufficiently large $n$, every $n$-vertex $5$-connected planar\ngraph has at most $C(k) \\cdot n^{\\lfloor{k/3}\\rfloor}$ many cycles of length\n$k$. This upper bound is asymptotically tight for all $k\\geq 6$."}
{"id": "2507.18075", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18075", "abs": "https://arxiv.org/abs/2507.18075", "authors": ["Jacob Mahon", "Chenxi Hou", "Zhihao Yao"], "title": "PyPitfall: Dependency Chaos and Software Supply Chain Vulnerabilities in Python", "comment": null, "summary": "Python software development heavily relies on third-party packages. Direct\nand transitive dependencies create a labyrinth of software supply chains. While\nit is convenient to reuse code, vulnerabilities within these dependency chains\ncan propagate through dependencies, potentially affecting down-stream packages\nand applications. PyPI, the official Python package repository, hosts many\npackages and lacks a comprehensive analysis of the prevalence of vulnerable\ndependencies. This paper introduces PyPitfall, a quantitative analysis of\nvulnerable dependencies across the PyPI ecosystem. We analyzed the dependency\nstructures of 378,573 PyPI packages and identified 4,655 packages that\nexplicitly require at least one known-vulnerable version and 141,044 packages\nthat permit vulnerable versions within specified ranges. By characterizing the\necosystem-wide dependency landscape and the security impact of transitive\ndependencies, we aim to raise awareness of Python software supply chain\nsecurity."}
{"id": "2507.18505", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.18505", "abs": "https://arxiv.org/abs/2507.18505", "authors": ["Javed Hazarika", "Debashis Paul"], "title": "LSD of sample covariances of superposition of matrices with separable covariance structure", "comment": null, "summary": "We study the asymptotic behavior of the spectra of matrices of the form $S_n\n= \\frac{1}{n}XX^*$ where $X =\\sum_{r=1}^K X_r$, where $X_r =\nA_r^\\frac{1}{2}Z_rB_r^\\frac{1}{2}$, $K \\in \\mathbb{N}$ and $A_r,B_r$ are\nsequences of positive semi-definite matrices of dimensions $p\\times p$ and\n$n\\times n$, respectively. We establish the existence of a limiting spectral\ndistribution for $S_n$ by assuming that matrices $\\{A_r\\}_{r=1}^K$ are\nsimultaneously diagonalizable and $\\{B_r\\}_{r=1}^K$ are simultaneously\ndigaonalizable, and that the joint spectral distributions of $\\{A_r\\}_{r=1}^K$\nand $\\{B_r\\}_{r=1}^K$ converge to $K$-dimensional distributions, as $p,n\\to\n\\infty$ such that $p/n \\to c \\in (0,\\infty)$. The LSD of $S_n$ is characterized\nby system of equations with unique solutions within the class of Stieltjes\ntransforms of measures on $\\mathbb{R}_+$. These results generalize existing\nresults on the LSD of sample covariances when the data matrices have a\nseparable covariance structure."}
{"id": "2507.18022", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.18022", "abs": "https://arxiv.org/abs/2507.18022", "authors": ["Victoria R. Li", "Johnathan Sun", "Martin Wattenberg"], "title": "Does visualization help AI understand data?", "comment": "5 pages, 6 figures", "summary": "Charts and graphs help people analyze data, but can they also be useful to AI\nsystems? To investigate this question, we perform a series of experiments with\ntwo commercial vision-language models: GPT 4.1 and Claude 3.5. Across three\nrepresentative analysis tasks, the two systems describe synthetic datasets more\nprecisely and accurately when raw data is accompanied by a scatterplot,\nespecially as datasets grow in complexity. Comparison with two baselines --\nproviding a blank chart and a chart with mismatched data -- shows that the\nimproved performance is due to the content of the charts. Our results are\ninitial evidence that AI systems, like humans, can benefit from visualization."}
{"id": "2507.18152", "categories": ["math.NT", "Primary 11M32, Secondary 11B35"], "pdf": "https://arxiv.org/pdf/2507.18152", "abs": "https://arxiv.org/abs/2507.18152", "authors": ["Takashi Miyagawa"], "title": "On the Laurent series Expansions of the Barnes Double Zeta-Function", "comment": "12 pages", "summary": "The Laurent series expansions of complex functions play a crucial role in\nanalyzing their behavior near poles. In particular, Laurent series expansions\nhave been extensively studied in the theory of zeta-functions. It is well known\nthat the Laurent series expansion of the Riemann zeta-function features the\nEuler-Stieltjes constants in its coefficients. Similar phenomena occur in the\nLaurent series expansion of the Hurwitz zeta-function, which is of considerable\ninterest.\n  In this paper, we compute the Laurent series expansions of the Barnes double\nzeta-function $ \\zeta_2 (s, \\alpha ; v, w ) $ at $s=1$ and $s=2$, and show that\na constant analogous to the Euler-Stieltjes constant appears in the constant\nterm."}
{"id": "2507.18363", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.18363", "abs": "https://arxiv.org/abs/2507.18363", "authors": ["Xiaoxi Jia", "Peter Ochs"], "title": "General Proximal Quasi-Newton Methods based on model functions for nonsmooth nonconvex problems", "comment": null, "summary": "In this manuscript, we propose a general proximal quasi-Newton method\ntailored for nonconvex and nonsmooth optimization problems, where we do not\nrequire the sequence of the variable metric (or Hessian approximation) to be\nuniformly bounded as a prerequisite, instead, the variable metric is updated by\na continuous matrix generator. From the respective of the algorithm, the\nobjective function is approximated by the so-called local model function and\nsubproblems aim to exploit the proximal point(s) of such model function, which\nhelp to achieve the sufficiently decreasing functional sequence along with the\nbacktracking line search principle. Under mild assumptions in terms of the\nfirst-order information of the model function, every accumulation point of the\ngenerated sequence is stationary and the sequence of the variable metric is\nproved not to be bounded. Additionally, if the function has the\nKurdyka-{\\L}ojasiewicz property at the corresponding accumulation point, we\nfind that the whole sequence is convergent to the stationary point, and the\nsequence of the variable metric is proved to be uniformly bounded. Through the\nabove results, we think that the boundedness of the sequence of the variable\nmetric should depend on the regularity of objectives, rather than being assumed\nas a prior for nonsmooth optimization problems. Numerical experiments on\npolytope feasibility problems and (sparse) quadratic inverse problems\ndemonstrate the effectiveness of our proposed model-based proximal quasi-Newton\nmethod, in comparison with the associated model-based proximal gradient method."}
{"id": "2507.18097", "categories": ["math.CO", "05A19, 05C05"], "pdf": "https://arxiv.org/pdf/2507.18097", "abs": "https://arxiv.org/abs/2507.18097", "authors": ["Fern Gossow"], "title": "Ordered trees and the Geode", "comment": "7 pages, comments welcome", "summary": "In recent work of Wildberger and Rubine, it is shown that the formal power\nseries $\\mathbf{S}$ in the variables $t_1,t_2,\\dots$ satisfying\n$\\mathbf{S}=1+\\sum_{n\\geq 1} t_n\\mathbf{S}^n$ has a factorisation\n$\\mathbf{S}=1+(t_1+t_2+\\cdots)\\mathbf{G}$, where $\\mathbf{G}$ is a power series\nwith nonnegative coefficients called the Geode. In this note we give a\ncombinatorial interpretation for the coefficients of $\\mathbf{G}$ based on\nordered trees. This amends the statement of a disproved conjecture of\nWildberger and Rubine which suggests a similar (but incorrect) interpretation."}
{"id": "2507.18157", "categories": ["cs.CR", "quant-ph", "Primary:94A60, Secondary:68P25, Tertiary:81P94"], "pdf": "https://arxiv.org/pdf/2507.18157", "abs": "https://arxiv.org/abs/2507.18157", "authors": ["Chao Liu", "Shuai Zhao", "Chenhao Jia", "Gengran Hu", "Tingting Cui"], "title": "An Improved ChaCha Algorithm Based on Quantum Random Number", "comment": "20 pages,4 figures", "summary": "Due to the merits of high efficiency and strong security against timing and\nside-channel attacks, ChaCha has been widely applied in real-time communication\nand data streaming scenarios. However, with the rapid development of\nAI-assisted cryptanalysis and quantum computing technologies, there are serious\nchallenges to the secure implementation of ChaCha cipher. To further strengthen\nthe security of ChaCha cipher, we propose an improved variant based on quantum\nrandom numbers, i.e., Quantum Random Number Enhanced ChaCha (QRE-ChaCha).\nSpecifically, the design XORs the initial constants with quantum random numbers\nand periodically injects quantum random numbers into selected state words\nduring odd rounds to enhance diffusion. Compared with the original ChaCha, the\npresent variant shows stronger resistance to differential attacks and generates\na keystream with statistical randomness, thereby offering increased robustness\nagainst both classical and quantum attacks. To evaluate the security and\nperformance of the present ChaCha, our analysis proceeds in three main parts.\nFirstly, we analyze its theoretical security in terms of quantum randomness and\nattack testing, and conduct differential cryptanalysis with an automated search\nmethod based on the Boolean satisfiability problem (SAT). Secondly, we subject\nthe keystream generated by the cipher to randomness tests using the NIST\nstatistical test suite and the GM/T 0005-2021 randomness testing standard.\nFinally, we assess its encryption and decryption performance by measuring its\nencryption speed on files of various sizes. According to the results, the\npresent ChaCha is significantly improved to resist differential attacks while\nmaintaining the high efficiency of the original ChaCha cipher, and its\nkeystream successfully passes statistical randomness tests using the NIST and\nGM/T 0005-2021 standards, meeting cryptographic application requirements."}
{"id": "2507.18059", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.18059", "abs": "https://arxiv.org/abs/2507.18059", "authors": ["Yueheng Li", "Guangming Xie", "Zongqing Lu"], "title": "Multi-Agent Guided Policy Optimization", "comment": null, "summary": "Due to practical constraints such as partial observability and limited\ncommunication, Centralized Training with Decentralized Execution (CTDE) has\nbecome the dominant paradigm in cooperative Multi-Agent Reinforcement Learning\n(MARL). However, existing CTDE methods often underutilize centralized training\nor lack theoretical guarantees. We propose Multi-Agent Guided Policy\nOptimization (MAGPO), a novel framework that better leverages centralized\ntraining by integrating centralized guidance with decentralized execution.\nMAGPO uses an auto-regressive joint policy for scalable, coordinated\nexploration and explicitly aligns it with decentralized policies to ensure\ndeployability under partial observability. We provide theoretical guarantees of\nmonotonic policy improvement and empirically evaluate MAGPO on 43 tasks across\n6 diverse environments. Results show that MAGPO consistently outperforms strong\nCTDE baselines and matches or surpasses fully centralized approaches, offering\na principled and practical solution for decentralized multi-agent learning. Our\ncode and experimental data can be found in https://github.com/liyheng/MAGPO."}
{"id": "2507.18186", "categories": ["math.NT", "11M06"], "pdf": "https://arxiv.org/pdf/2507.18186", "abs": "https://arxiv.org/abs/2507.18186", "authors": ["Peng Gao", "Liangyi Zhao"], "title": "Twisted fourth moment of Dirichlet $L$-functions to a fixed modulus", "comment": "32 pages", "summary": "We evaluate the twisted four moment on the critical line of the family of\nDirichlet $L$-functions to a fixed prime power modulus, obtaining an asymptotic\nformula with a power saving error term."}
{"id": "2507.18609", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.18609", "abs": "https://arxiv.org/abs/2507.18609", "authors": ["Iasson Karafyllis", "Miroslav Krstic"], "title": "Partial-State DADS Control for Matched Unmodeled Dynamics", "comment": "28 pages. arXiv admin note: text overlap with arXiv:2311.07938,\n  arXiv:2402.17222, arXiv:2410.16691", "summary": "We extend the Deadzone-Adapted Disturbance Suppression (DADS) control to\ntime-invariant systems with dynamic uncertainties that satisfy the matching\ncondition and for which no bounds for the disturbance and the unknown\nparameters are known. This problem is equivalent to partial-state adaptive\nfeedback, where the states modeling the dynamic uncertainty are unmeasured. We\nshow that the DADS controller can bypass small-gain conditions and achieve\nrobust regulation for systems in spite of the fact that the strength of the\ninterconnections has no known bound. Moreover, no gain and state drift arise,\nregardless of the size of the disturbances and unknown parameters. Finally, the\npaper provides the detailed analysis of a control system where the unmeasured\nstate (or the dynamic uncertainty) is infinite-dimensional and described by a\nreaction-diffusion Partial Differential Equation, where the diffusion\ncoefficient and the reaction term are unknown. It is shown that even in the\ninfinite-dimensional case, a DADS controller can be designed and guarantees\nrobust regulation of the plant state."}
{"id": "2507.18120", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.18120", "abs": "https://arxiv.org/abs/2507.18120", "authors": ["Kaizhe Chen", "Jack H. Koolen", "Shiping Liu"], "title": "Edge-connectivity of graphs with non-negative Bakry-Émery curvature and amply regular graphs", "comment": "18 pages", "summary": "We establish a sharp edge-connectivity estimate for graphs with non-negative\nBakry-\\'Emery curvature. This leads to a geometric criterion for the existence\nof a perfect matching. Precisely, we show that any regular graph with\nnon-negative Bakry-\\'Emery curvature and an even or infinite number of vertices\nhas a perfect matching. Through a synthesis of combinatorial and\ncurvature-related techniques, we determine the edge-connectivity of (possibly\ninfinite) amply regular graphs."}
{"id": "2507.18215", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18215", "abs": "https://arxiv.org/abs/2507.18215", "authors": ["Chang Gong", "Zhongwen Li", "Xiaoqi Li"], "title": "Information Security Based on LLM Approaches: A Review", "comment": null, "summary": "Information security is facing increasingly severe challenges, and\ntraditional protection means are difficult to cope with complex and changing\nthreats. In recent years, as an emerging intelligent technology, large language\nmodels (LLMs) have shown a broad application prospect in the field of\ninformation security. In this paper, we focus on the key role of LLM in\ninformation security, systematically review its application progress in\nmalicious behavior prediction, network threat analysis, system vulnerability\ndetection, malicious code identification, and cryptographic algorithm\noptimization, and explore its potential in enhancing security protection\nperformance. Based on neural networks and Transformer architecture, this paper\nanalyzes the technical basis of large language models and their advantages in\nnatural language processing tasks. It is shown that the introduction of large\nlanguage modeling helps to improve the detection accuracy and reduce the false\nalarm rate of security systems. Finally, this paper summarizes the current\napplication results and points out that it still faces challenges in model\ntransparency, interpretability, and scene adaptability, among other issues. It\nis necessary to explore further the optimization of the model structure and the\nimprovement of the generalization ability to realize a more intelligent and\naccurate information security protection system."}
{"id": "2507.18074", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18074", "abs": "https://arxiv.org/abs/2507.18074", "authors": ["Yixiu Liu", "Yang Nan", "Weixian Xu", "Xiangkun Hu", "Lyumanshan Ye", "Zhen Qin", "Pengfei Liu"], "title": "AlphaGo Moment for Model Architecture Discovery", "comment": null, "summary": "While AI systems demonstrate exponentially improving capabilities, the pace\nof AI research itself remains linearly bounded by human cognitive capacity,\ncreating an increasingly severe development bottleneck. We present ASI-Arch,\nthe first demonstration of Artificial Superintelligence for AI research\n(ASI4AI) in the critical domain of neural architecture discovery--a fully\nautonomous system that shatters this fundamental constraint by enabling AI to\nconduct its own architectural innovation. Moving beyond traditional Neural\nArchitecture Search (NAS), which is fundamentally limited to exploring\nhuman-defined spaces, we introduce a paradigm shift from automated optimization\nto automated innovation. ASI-Arch can conduct end-to-end scientific research in\nthe domain of architecture discovery, autonomously hypothesizing novel\narchitectural concepts, implementing them as executable code, training and\nempirically validating their performance through rigorous experimentation and\npast experience. ASI-Arch conducted 1,773 autonomous experiments over 20,000\nGPU hours, culminating in the discovery of 106 innovative, state-of-the-art\n(SOTA) linear attention architectures. Like AlphaGo's Move 37 that revealed\nunexpected strategic insights invisible to human players, our AI-discovered\narchitectures demonstrate emergent design principles that systematically\nsurpass human-designed baselines and illuminate previously unknown pathways for\narchitectural innovation. Crucially, we establish the first empirical scaling\nlaw for scientific discovery itself--demonstrating that architectural\nbreakthroughs can be scaled computationally, transforming research progress\nfrom a human-limited to a computation-scalable process. We provide\ncomprehensive analysis of the emergent design patterns and autonomous research\ncapabilities that enabled these breakthroughs, establishing a blueprint for\nself-accelerating AI systems."}
{"id": "2507.18465", "categories": ["math.NT", "11T06 (Primary), 11T71 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.18465", "abs": "https://arxiv.org/abs/2507.18465", "authors": ["Soniya Takshak", "Rajendra Kumar Sharma"], "title": "The Exact Enumeration of $4$-nomial and $5$-nomial Multiples of the Product of Primitive Polynomials over GF(2)", "comment": "10 pages", "summary": "Linear feedback shift registers (LFSRs) are used to generate secret keys in\nstream cipher cryptosystems. There are different kinds of key-stream generators\nlike filter generators, combination generators, clock-controlled generators,\netc. For a combination generator, the connection polynomial is the product of\nthe connection polynomials of constituent LFSRs. For better cryptographic\nproperties, the connection polynomials of the constituent LFSRs should be\nprimitive with coprime degrees. The cryptographic systems using LFSRs as their\ncomponents are vulnerable to correlation attacks. The attack heavily depends on\nthe $t$-nomial multiples of the connection polynomial for small values of $t$.\nIn 2005, Maitra, Gupta, and Venkateswarlu provided a lower bound for the number\nof $t$-nomial multiples of the product of primitive polynomials over GF(2). The\nlower bound is exact when $t=3$. In this article, we provide the exact number\nof $4$-nomial and $5$-nomial multiples of the product of primitive polynomials.\nThis helps us to choose a more suitable connection polynomial to resist the\ncorrelation attacks. Next, we disprove a conjecture by Maitra, Gupta, and\nVenkateswarlu."}
{"id": "2507.18434", "categories": ["math.CO", "cs.NA", "math.NA", "math.OC", "05A05, 05A15, 05A20 (Primary), 06A07, 65H04, 41A10, 41A45, 41A60,\n  90C23 (Secondary)", "G.2.1; G.1.2; G.1.3; G.1.5; G.1.6"], "pdf": "https://arxiv.org/pdf/2507.18434", "abs": "https://arxiv.org/abs/2507.18434", "authors": ["Alejandro González Nevado"], "title": "Guessing sequences of eigenvectors for LMPs defining spectrahedral relaxations of Eulerian rigidly convex sets", "comment": "51 pages. Preprint extracted from a selection, rewrite and\n  recombination of several sections and chapters from my PhD thesis. For more\n  possible lines of research in these related directions, we direct the\n  interested reader to arXiv:2503.04628 and to arXiv:2507.03800", "summary": "Stable multivariate Eulerian polynomials were introduced by Br\\\"and\\'en.\nParticularizing some variables, it is possible to extract real zero\nmultivariate Eulerian polynomials from them. These real zero multivariate\nEulerian polynomials can be fed into constructions of spectrahedral relaxations\nproviding therefore approximations to the (Eulerian) rigidly convex sets\ndefined by these polynomials. The accuracy of these approximations is measured\nthrough the behaviour in the diagonal, where the usual univariate Eulerian\npolynomials sit. In particular, in this sense, the accuracy of the global\nspectrahedral approximation produced by the spectrahedral relaxation can be\nmeasured in terms of bounds for the extreme roots of univariate Eulerian\npolynomials. The bounds thus obtained beat the previous bounds found in the\nliterature. However, the bound explicitly studied and obtained before beat the\npreviously known bounds by a quantity going to $0$ when $n$ goes to infinity.\nHere we use numerical experiments to construct a sequence of vectors providing\na (linearized) bound whose difference with the previous known bounds is a\ngrowing exponential function (going therefore fast to infinity when $n$ grows).\nThis allows us to establish a better (diagonal) measure of accuracy for the\nspectrahedral relaxation of the Eulerian rigidly convex sets. In particular, we\nwill achieve this by linearizing through the sequence of vectors\n$\\{(y,(-2^{m-i})_{i=3}^{m},(0,\\frac{1}{2}),(1)_{i=1}^{m})\\in\\mathbb{R}^{n+1}\\}_{n=1}^{\\infty}$\nfor even $n=2m$."}
{"id": "2507.18230", "categories": ["math.CO", "05E16, 05E18, 06A07, 06B10, 16E30"], "pdf": "https://arxiv.org/pdf/2507.18230", "abs": "https://arxiv.org/abs/2507.18230", "authors": ["Colin Defant", "Yuhan Jiang", "Rene Marczinzik", "Adrien Segovia", "David E Speyer", "Hugh Thomas", "Nathan Williams"], "title": "Rowmotion and Echelonmotion", "comment": "20 pages, 5 figures", "summary": "Given a linear extension $\\sigma$ of a finite poset $R$, we consider the\npermutation matrix indexing the Schubert cell containing the Cartan matrix of\n$R$ with respect to $\\sigma$. This yields a bijection\n$\\mathrm{Ech}_\\sigma\\colon R\\to R$ that we call echelonmotion; it is the\ninverse of the Coxeter permutation studied by Kl\\'asz, Marczinzik, and Thomas.\nThose authors proved that echelonmotion agrees with rowmotion when $R$ is a\ndistributive lattice. We generalize this result to semidistributive lattices.\nIn addition, we prove that every trim lattice has a linear extension with\nrespect to which echelonmotion agrees with rowmotion. We also show that\nechelonmotion on an Eulerian poset (with respect to any linear extension) is an\ninvolution. Finally, we initiate the study of echelon-independent posets, which\nare posets for which echelonmotion is independent of the chosen linear\nextension. We prove that a lattice is echelon-independent if and only if it is\nsemidistributive. Moreover, we show that echelon-independent connected posets\nare bounded and have semidistributive MacNeille completions."}
{"id": "2507.18249", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.18249", "abs": "https://arxiv.org/abs/2507.18249", "authors": ["Muhammad M. Roomi", "S. M. Suhail Hussain", "Ee-Chien Chang", "David M. Nicol", "Daisuke Mashima"], "title": "Auto-SGCR: Automated Generation of Smart Grid Cyber Range Using IEC 61850 Standard Models", "comment": "12 pages", "summary": "Digitalization of power grids have made them increasingly susceptible to\ncyber-attacks in the past decade. Iterative cybersecurity testing is\nindispensable to counter emerging attack vectors and to ensure dependability of\ncritical infrastructure. Furthermore, these can be used to evaluate\ncybersecurity configuration, effectiveness of the cybersecurity measures\nagainst various attack vectors, as well as to train smart grid cybersecurity\nexperts defending the system. Enabling extensive experiments narrows the gap\nbetween academic research and production environment. A high-fidelity cyber\nrange is vital as it is often infeasible to conduct such experiments and\ntraining using production environment. However, the design and implementation\nof cyber range requires extensive domain knowledge of physical and cyber aspect\nof the infrastructure. Furthermore, costs incurred for setup and maintenance of\ncyber range are significant. Moreover, most existing smart grid cyber ranges\nare designed as a one-off, proprietary system, and are limited in terms of\nconfigurability, accessibility, portability, and reproducibility. To address\nthese challenges, an automated Smart grid Cyber Range generation framework is\npresented in this paper. Initially a human-/machine-friendly, XML-based\nmodeling language called Smart Grid Modeling Language was defined, which\nincorporates IEC 61850 System Configuration Language files. Subsequently, a\ntoolchain to parse SG-ML model files and automatically instantiate a functional\nsmart grid cyber range was developed. The developed SG-ML models can be easily\nshared and/or modified to reproduce or customize for any cyber range. The\napplication of Auto-SGCR is demonstrated through case studies with large-scale\nsubstation models. The toolchain along with example SG-ML models have been\nopen-sourced."}
{"id": "2507.18115", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.18115", "abs": "https://arxiv.org/abs/2507.18115", "authors": ["Soorya Ram Shimgekar", "Shayan Vassef", "Abhay Goyal", "Navin Kumar", "Koustuv Saha"], "title": "Agentic AI framework for End-to-End Medical Data Inference", "comment": "10 pages, 5 figures, 2 tables, BIBM conference", "summary": "Building and deploying machine learning solutions in healthcare remains\nexpensive and labor-intensive due to fragmented preprocessing workflows, model\ncompatibility issues, and stringent data privacy constraints. In this work, we\nintroduce an Agentic AI framework that automates the entire clinical data\npipeline, from ingestion to inference, through a system of modular,\ntask-specific agents. These agents handle both structured and unstructured\ndata, enabling automatic feature selection, model selection, and preprocessing\nrecommendation without manual intervention. We evaluate the system on publicly\navailable datasets from geriatrics, palliative care, and colonoscopy imaging.\nFor example, in the case of structured data (anxiety data) and unstructured\ndata (colonoscopy polyps data), the pipeline begins with file-type detection by\nthe Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring\nprivacy compliance, where we first identify the data type and then anonymize\nit. The Feature Extraction Agent identifies features using an embedding-based\napproach for tabular data, extracting all column names, and a multi-stage\nMedGemma-based approach for image data, which infers modality and disease name.\nThese features guide the Model-Data Feature Matcher Agent in selecting the\nbest-fit model from a curated repository. The Preprocessing Recommender Agent\nand Preprocessing Implementor Agent then apply tailored preprocessing based on\ndata type and model requirements. Finally, the ``Model Inference Agent\" runs\nthe selected model on the uploaded data and generates interpretable outputs\nusing tools like SHAP, LIME, and DETR attention maps. By automating these\nhigh-friction stages of the ML lifecycle, the proposed framework reduces the\nneed for repeated expert intervention, offering a scalable, cost-efficient\npathway for operationalizing AI in clinical environments."}
{"id": "2507.18574", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.18574", "abs": "https://arxiv.org/abs/2507.18574", "authors": ["Asuka Shiga"], "title": "Infinitely many pairs of non-isomorphic elliptic curves sharing the same BSD invariants", "comment": "10 pages", "summary": "We prove that there exist infinitely many pairs of non-isomorphic elliptic\ncurves over $\\mathbb{Q}$ sharing the same BSD invariants -- including their\n$L$-functions, Mordell--Weil groups, Tate--Shafarevich groups, Tamagawa\nnumbers, regulators, and real periods -- and their Kodaira symbols and minimal\ndiscriminants, while having distinct $j$-invariants."}
{"id": "2507.18272", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.18272", "abs": "https://arxiv.org/abs/2507.18272", "authors": ["Csilla Bujtás", "Vesna Iršič Chenoweth", "Sandi Klavžar", "Gang Zhang"], "title": "The $d$-distance $p$-packing domination number: complexity and trees", "comment": null, "summary": "A set of vertices $X\\subseteq V(G)$ is a $d$-distance dominating set if for\nevery $u\\in V(G)\\setminus X$ there exists $x\\in X$ such that $d(u,x) \\le d$,\nand $X$ is a $p$-packing if $d(u,v) \\ge p+1$ for every different $u,v\\in X$.\nThe $d$-distance $p$-packing domination number $\\gamma_d^p(G)$ of $G$ is the\nminimum size of a set of vertices of $G$ which is both a $d$-distance\ndominating set and a $p$-packing. It is proved that for every two fixed\nintegers $d$ and $p$ with $2 \\le d$ and $0 \\le p \\leq 2d-1$, the decision\nproblem whether $\\gamma_d^p(G) \\leq k$ holds is NP-complete for bipartite\nplanar graphs. For a tree $T$ on $n$ vertices with $\\ell$ leaves and $s$\nsupport vertices it is proved that (i) $\\gamma_2^0(T) \\geq\n\\frac{n-\\ell-s+4}{5}$, (ii) $\\left \\lceil \\frac{n-\\ell-s+4}{5} \\right \\rceil\n\\leq \\gamma_2^2(T) \\leq \\left \\lfloor \\frac{n+3s-1}{5} \\right \\rfloor$, and if\n$d \\geq 2$, then (iii) $\\gamma_d^2(T) \\leq \\frac{n-2\\sqrt{n}+d+1}{d}$.\nInequality (i) improves an earlier bound due to Meierling and Volkmann, and\nindependently Raczek, Lema\\'nska, and Cyman, while (iii) extends an earlier\nresult for $\\gamma_2^2(T)$ due to Henning. Sharpness of the bounds are\ndiscussed and established in most cases. It is also proved that every connected\ngraph $G$ contains a spanning tree $T$ such that $\\gamma_2^2(T) \\leq\n\\gamma_2^2(G)$."}
{"id": "2507.18302", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.18302", "abs": "https://arxiv.org/abs/2507.18302", "authors": ["Delong Ran", "Xinlei He", "Tianshuo Cong", "Anyu Wang", "Qi Li", "Xiaoyun Wang"], "title": "LoRA-Leak: Membership Inference Attacks Against LoRA Fine-tuned Language Models", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Language Models (LMs) typically adhere to a \"pre-training and fine-tuning\"\nparadigm, where a universal pre-trained model can be fine-tuned to cater to\nvarious specialized domains. Low-Rank Adaptation (LoRA) has gained the most\nwidespread use in LM fine-tuning due to its lightweight computational cost and\nremarkable performance. Because the proportion of parameters tuned by LoRA is\nrelatively small, there might be a misleading impression that the LoRA\nfine-tuning data is invulnerable to Membership Inference Attacks (MIAs).\nHowever, we identify that utilizing the pre-trained model can induce more\ninformation leakage, which is neglected by existing MIAs. Therefore, we\nintroduce LoRA-Leak, a holistic evaluation framework for MIAs against the\nfine-tuning datasets of LMs. LoRA-Leak incorporates fifteen membership\ninference attacks, including ten existing MIAs, and five improved MIAs that\nleverage the pre-trained model as a reference. In experiments, we apply\nLoRA-Leak to three advanced LMs across three popular natural language\nprocessing tasks, demonstrating that LoRA-based fine-tuned LMs are still\nvulnerable to MIAs (e.g., 0.775 AUC under conservative fine-tuning settings).\nWe also applied LoRA-Leak to different fine-tuning settings to understand the\nresulting privacy risks. We further explore four defenses and find that only\ndropout and excluding specific LM layers during fine-tuning effectively\nmitigate MIA risks while maintaining utility. We highlight that under the\n\"pre-training and fine-tuning\" paradigm, the existence of the pre-trained model\nmakes MIA a more severe risk for LoRA-based LMs. We hope that our findings can\nprovide guidance on data privacy protection for specialized LM providers."}
{"id": "2507.18123", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.18123", "abs": "https://arxiv.org/abs/2507.18123", "authors": ["Sedigh Khademi", "Christopher Palmer", "Muhammad Javed", "Hazel Clothier", "Jim Buttery", "Gerardo Luis Dimaguila", "Jim Black"], "title": "Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes", "comment": "14 pages", "summary": "The rapid development of COVID-19 vaccines has showcased the global\ncommunitys ability to combat infectious diseases. However, the need for\npost-licensure surveillance systems has grown due to the limited window for\nsafety data collection in clinical trials and early widespread implementation.\nThis study aims to employ Natural Language Processing techniques and Active\nLearning to rapidly develop a classifier that detects potential vaccine safety\nissues from emergency department notes. ED triage notes, containing expert,\nsuccinct vital patient information at the point of entry to health systems, can\nsignificantly contribute to timely vaccine safety signal surveillance. While\nkeyword-based classification can be effective, it may yield false positives and\ndemand extensive keyword modifications. This is exacerbated by the infrequency\nof vaccination-related ED presentations and their similarity to other reasons\nfor ED visits. NLP offers a more accurate and efficient alternative, albeit\nrequiring annotated data, which is often scarce in the medical field. Active\nlearning optimizes the annotation process and the quality of annotated data,\nwhich can result in faster model implementation and improved model performance.\nThis work combines active learning, data augmentation, and active learning and\nevaluation techniques to create a classifier that is used to enhance vaccine\nsafety surveillance from ED triage notes."}
{"id": "2507.18589", "categories": ["math.NT", "11C20, 15A15, 11A15"], "pdf": "https://arxiv.org/pdf/2507.18589", "abs": "https://arxiv.org/abs/2507.18589", "authors": ["Chen-Kai Ren", "Zhi-Wei Sun"], "title": "Evaluation of a determinant involving Legendre symbols", "comment": "14 pages", "summary": "Let $p>3$ be a prime, and let $(\\frac{\\cdot}p)$ be the Legendre symbol. Let\n$A_p(x)$ denote the matrix $[x+a_{ij}]_{1\\leqslant i,j\\leqslant (p-1)/2}$,\nwhere $$ a_{ij}=\\begin{cases} (\\frac{j}{p}) &\\text{if} \\ i=1, \\$\\frac{i+j}{p})\n&\\text{if} \\ i>1. \\end{cases}$$ In 2018 Z.-W. Sun conjectured that $\\det\nA_p(0)=-2^{(p-3)/2}$ if $p\\equiv 3 \\pmod{4}$, which was later confirmed by G.\nZaimi. In this paper we evaluate $\\det A_p(x)$ completely."}
{"id": "2507.18306", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.18306", "abs": "https://arxiv.org/abs/2507.18306", "authors": ["Boštjan Brešar", "Michael A. Henning", "Babak Samadi"], "title": "On $k$-coalition in graphs: bounds and exact values", "comment": null, "summary": "Given a graph $G=\\big{(}V(G),E(G)\\big{)}$, a set $S\\subseteq V(G)$ is called\na $k$-dominating set if every vertex in $V(G)\\setminus S$ has at least $k$\nneighbors in $S$. Two disjoint sets $A,B\\subset V(G)$ form a $k$-coalition in\n$G$ if neither set is a $k$-dominating set in $G$ but their union $A\\cup B$ is\na $k$-dominating set. A partition $\\Omega$ of $V(G)$ is a $k$-coalition\npartition if each set in $\\Omega$ is either a $k$-dominating set of cardinality\n$k$ or forms a $k$-coalition with another set in $\\Omega$. The $k$-coalition\nnumber $C_{k}(G)$ equals the maximum cardinality of a $k$-coalition partition\nof $G$. In this work, we give general upper and lower bounds on this parameter.\nIn particular, we show that if $G$ has minimum degree $\\delta \\ge 2$ and\nmaximum degree $\\Delta \\ge 4 \\lfloor \\delta/2 \\rfloor$, then $C_{2}(G) \\leq\n(\\Delta-2\\lfloor \\delta/2 \\rfloor+1)(\\lfloor \\delta/2 \\rfloor+1) + \\lceil\n\\delta/2 \\rceil+1$, and this bound is sharp. If $T$ is a tree of order~$n \\ge\n2$, then we prove the upper bound $C_{2}(T) \\leq \\big\\lfloor\n\\frac{n}{2}\\big\\rfloor+1$ and we characterize the extremal trees achieving\nequality in this bound. We determine the exact value of $C_{k}(G)$ for any\ncubic graph $G$ and $k\\geq2$. Finally, we give the exact value of $C_{k}$ for\nany complete bipartite graph, which completes a partial result and resolves an\nissue from an earlier paper."}
{"id": "2507.18360", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18360", "abs": "https://arxiv.org/abs/2507.18360", "authors": ["André Menolli", "Luiz Fernando Nunes", "Thiago A. Coleti"], "title": "Conformidade com os Requisitos Legais de Privacidade de Dados: Um Estudo sobre Técnicas de Anonimização", "comment": "in Portuguese language", "summary": "The protection of personal data has become a central topic in software\ndevelopment, especially with the implementation of the General Data Protection\nLaw (LGPD) in Brazil and the General Data Protection Regulation (GDPR) in the\nEuropean Union. With the enforcement of these laws, certain software quality\ncriteria have become mandatory, such as data anonymization, which is one of the\nmain aspects addressed by these regulations. The aim of this article is to\nanalyze data anonymization techniques and assess their effectiveness in\nensuring compliance with legal requirements and the utility of the data for its\nintended purpose. Techniques such as aggregation, generalization, perturbation,\nand k-anonymity were investigated and applied to datasets containing personal\nand sensitive data. The analysis revealed significant variations in the\neffectiveness of each method, highlighting the need to balance privacy and data\nutility."}
{"id": "2507.18145", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.18145", "abs": "https://arxiv.org/abs/2507.18145", "authors": ["Moritz Schönherr", "Carsten Lutz"], "title": "Logical Characterizations of GNNs with Mean Aggregation", "comment": null, "summary": "We study the expressive power of graph neural networks (GNNs) with mean as\nthe aggregation function. In the non-uniform setting, we show that such GNNs\nhave exactly the same expressive power as ratio modal logic, which has modal\noperators expressing that at least a certain ratio of the successors of a\nvertex satisfies a specified property. The non-uniform expressive power of mean\nGNNs is thus higher than that of GNNs with max aggregation, but lower than for\nsum aggregation--the latter are characterized by modal logic and graded modal\nlogic, respectively. In the uniform setting, we show that the expressive power\nrelative to MSO is exactly that of alternation-free modal logic, under the\nnatural assumptions that combination functions are continuous and\nclassification functions are thresholds. This implies that, relative to MSO and\nin the uniform setting, mean GNNs are strictly less expressive than sum GNNs\nand max GNNs. When any of the assumptions is dropped, the expressive power\nincreases."}
{"id": "2507.18432", "categories": ["math.CO", "math.QA"], "pdf": "https://arxiv.org/pdf/2507.18432", "abs": "https://arxiv.org/abs/2507.18432", "authors": ["Wen Ting Zhang", "Rui Zhi Tang", "Jin Xing Zhao"], "title": "Web Diagrams of Cluster Variables for Grassmannian Gr(4,8)", "comment": null, "summary": "Gaetz, Pechenik, Pfannerer, Striker, and Swanson introduced the concept of\nhourglass plabic graphs and provided a method for computing web diagrams and\ninvariants corresponding to $4\\times n$ Young tableaux, while Elkin, Musiker,\nand Wright applied Lam's method to explicitly compute the webs compatible with\ncluster variables in Gr(3,n) and their twists, namely, the preimages of the\nimmanant map introduced by Fraser, Lam, and Le. In this paper, we use these two\nmethods to compute both the web diagrams and the dual webs corresponding to\nquadratic and cubic cluster variables in the Grassmannian cluster algebra\nC[Gr(4,8)]."}
{"id": "2507.18478", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18478", "abs": "https://arxiv.org/abs/2507.18478", "authors": ["Shariq Murtuza"], "title": "Scout: Leveraging Large Language Models for Rapid Digital Evidence Discovery", "comment": null, "summary": "Recent technological advancements and the prevalence of technology in day to\nday activities have caused a major increase in the likelihood of the\ninvolvement of digital evidence in more and more legal investigations.\nConsumer-grade hardware is growing more powerful, with expanding memory and\nstorage sizes and enhanced processor capabilities. Forensics investigators\noften have to sift through gigabytes of data during an ongoing investigation\nmaking the process tedious. Memory forensics, disk analysis all are well\nsupported by state of the art tools that significantly lower the effort\nrequired to be put in by a forensic investigator by providing string searches,\nanalyzing images file etc. During the course of the investigation a lot of\nfalse positives are identified that need to be lowered. This work presents\nScout, a digital forensics framework that performs preliminary evidence\nprocessing and prioritizing using large language models. Scout deploys\nfoundational language models to identify relevant artifacts from a large number\nof potential evidence files (disk images, captured network packets, memory\ndumps etc.) which would have taken longer to get identified. Scout employs text\nbased large language models can easily process files with textual information.\nFor the forensic analysis of multimedia files like audio, image, video, office\ndocuments etc. multimodal models are employed by Scout. Scout was able to\nidentify and realize the evidence file that were of potential interest for the\ninvestigator."}
{"id": "2507.18178", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18178", "abs": "https://arxiv.org/abs/2507.18178", "authors": ["Mutian Yang", "Jiandong Gao", "Ji Wu"], "title": "Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory", "comment": null, "summary": "While large language models (LLMs) leverage both knowledge and reasoning\nduring inference, the capacity to distinguish between them plays a pivotal role\nin model analysis, interpretability, and development. Inspired by dual-system\ncognitive theory, we propose a cognition attribution framework to decouple the\ncontribution of knowledge and reasoning. In particular, the cognition of LLMs\nis decomposed into two distinct yet complementary phases: knowledge retrieval\n(Phase 1) and reasoning adjustment (Phase 2). To separate these phases, LLMs\nare prompted to generate answers under two different cognitive modes, fast\nthinking and slow thinking, respectively. The performance under different\ncognitive modes is analyzed to quantify the contribution of knowledge and\nreasoning. This architecture is employed to 15 LLMs across 3 datasets. Results\nreveal: (1) reasoning adjustment is domain-specific, benefiting\nreasoning-intensive domains (e.g., mathematics, physics, and chemistry) and\npotentially imparing knowledge-intensive domains. (2) Parameter scaling\nimproves both knowledge and reasoning, with knowledge improvements being more\npronounced. Additionally, parameter scaling make LLMs reasoning significantly\nmore prudent, while moderately more intelligent. (3) Knowledge primarily\nresides in lower network layers, while reasoning operates in higher layers. Our\nframework not only helps understand LLMs from a \"decoupling\" perspective, but\nalso provides new insights into existing research, including scaling laws,\nhierarchical knowledge editing, and limitations of small-model reasoning."}
{"id": "2507.18434", "categories": ["math.CO", "cs.NA", "math.NA", "math.OC", "05A05, 05A15, 05A20 (Primary), 06A07, 65H04, 41A10, 41A45, 41A60,\n  90C23 (Secondary)", "G.2.1; G.1.2; G.1.3; G.1.5; G.1.6"], "pdf": "https://arxiv.org/pdf/2507.18434", "abs": "https://arxiv.org/abs/2507.18434", "authors": ["Alejandro González Nevado"], "title": "Guessing sequences of eigenvectors for LMPs defining spectrahedral relaxations of Eulerian rigidly convex sets", "comment": "51 pages. Preprint extracted from a selection, rewrite and\n  recombination of several sections and chapters from my PhD thesis. For more\n  possible lines of research in these related directions, we direct the\n  interested reader to arXiv:2503.04628 and to arXiv:2507.03800", "summary": "Stable multivariate Eulerian polynomials were introduced by Br\\\"and\\'en.\nParticularizing some variables, it is possible to extract real zero\nmultivariate Eulerian polynomials from them. These real zero multivariate\nEulerian polynomials can be fed into constructions of spectrahedral relaxations\nproviding therefore approximations to the (Eulerian) rigidly convex sets\ndefined by these polynomials. The accuracy of these approximations is measured\nthrough the behaviour in the diagonal, where the usual univariate Eulerian\npolynomials sit. In particular, in this sense, the accuracy of the global\nspectrahedral approximation produced by the spectrahedral relaxation can be\nmeasured in terms of bounds for the extreme roots of univariate Eulerian\npolynomials. The bounds thus obtained beat the previous bounds found in the\nliterature. However, the bound explicitly studied and obtained before beat the\npreviously known bounds by a quantity going to $0$ when $n$ goes to infinity.\nHere we use numerical experiments to construct a sequence of vectors providing\na (linearized) bound whose difference with the previous known bounds is a\ngrowing exponential function (going therefore fast to infinity when $n$ grows).\nThis allows us to establish a better (diagonal) measure of accuracy for the\nspectrahedral relaxation of the Eulerian rigidly convex sets. In particular, we\nwill achieve this by linearizing through the sequence of vectors\n$\\{(y,(-2^{m-i})_{i=3}^{m},(0,\\frac{1}{2}),(1)_{i=1}^{m})\\in\\mathbb{R}^{n+1}\\}_{n=1}^{\\infty}$\nfor even $n=2m$."}
{"id": "2507.18631", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18631", "abs": "https://arxiv.org/abs/2507.18631", "authors": ["Hao Li", "Lijun Li", "Zhenghao Lu", "Xianyi Wei", "Rui Li", "Jing Shao", "Lei Sha"], "title": "Layer-Aware Representation Filtering: Purifying Finetuning Data to Preserve LLM Safety Alignment", "comment": null, "summary": "With rapid advancement and increasing accessibility of LLMs, fine-tuning\naligned models has become a critical step for adapting them to real-world\napplications, which makes the safety of this fine-tuning process more important\nthan ever. However, recent studies have highlighted a critical challenge: even\nwhen fine-tuning with seemingly benign downstream datasets, the safety of\naligned LLMs can be compromised, making them more susceptible to malicious\ninstructions. In this paper, we show that fine-tuning datasets often contain\nsamples with safety-degrading features that are not easily identifiable on the\nsurface. These samples can significantly degrade the safety alignment of LLMs\nduring fine-tuning. To address this issue, we propose LARF, a\n\\textbf{L}ayer-\\textbf{A}ware \\textbf{R}epresentation \\textbf{F}iltering\nmethod. This method identifies safety-sensitive layers within the LLM and\nleverages their representations to detect which data samples in the\npost-training dataset contain safety-degrading features. Experimental results\ndemonstrate that LARF can effectively identify benign data with\nsafety-degrading features. After removing such data, the safety alignment\ndegradation caused by fine-tuning is mitigated. Please see our code at\n\\href{https://github.com/LLLeoLi/LARF}{https://github.com/LLLeoLi/LARF}."}
{"id": "2507.18198", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18198", "abs": "https://arxiv.org/abs/2507.18198", "authors": ["Felicidad Aguado", "Pedro Cabalar", "Brais Muñiz", "Gilberto Pérez", "Concepción Vidal"], "title": "Comparing Non-minimal Semantics for Disjunction in Answer Set Programming", "comment": null, "summary": "In this paper, we compare four different semantics for disjunction in Answer\nSet Programming that, unlike stable models, do not adhere to the principle of\nmodel minimality. Two of these approaches, Cabalar and Mu\\~niz' \\emph{Justified\nModels} and Doherty and Szalas' \\emph{Strongly Supported Models}, directly\nprovide an alternative non-minimal semantics for disjunction. The other two,\nAguado et al's \\emph{Forks} and Shen and Eiter's \\emph{Determining Inference}\n(DI) semantics, actually introduce a new disjunction connective, but are\ncompared here as if they constituted new semantics for the standard disjunction\noperator. We are able to prove that three of these approaches (Forks, Justified\nModels and a reasonable relaxation of the DI semantics) actually coincide,\nconstituting a common single approach under different definitions. Moreover,\nthis common semantics always provides a superset of the stable models of a\nprogram (in fact, modulo any context) and is strictly stronger than the fourth\napproach (Strongly Supported Models), that actually treats disjunctions as in\nclassical logic."}
{"id": "2507.18506", "categories": ["math.CO", "05C15, 05C17, 05C69"], "pdf": "https://arxiv.org/pdf/2507.18506", "abs": "https://arxiv.org/abs/2507.18506", "authors": ["Lizhong Chen", "Hongyang Wang"], "title": "Perfect divisibility of $(P_2\\cup P_4,\\mbox{bull})$-free graphs", "comment": "8 pages, 2 figures", "summary": "A graph $G$ is perfectly divisible if, for every induced subgraph $H$ of $G$,\nthe vertex set $V(H)$ admits a partition $(A, B)$ such that $H[A]$ is perfect\nand $\\omega(H[B])<\\omega(H)$. We prove that every ($P_2\\cup P_4$, bull)-free\ngraph $G$ with $\\omega(G)\\geq3$ is perfectly divisible hence the chromatic\nnumber satisfies $\\chi(G)\\leq\\binom{\\omega(G)+1}{2}$. The clique-number\ncondition is tight: counterexamples exist for $\\omega(G)=2$. Additionally, we\nprovide a short proof of the perfect divisibility of ($P_5$, bull)-free graphs,\noriginally established by Chudnovsky and Sivaraman [J. Graph Theory 90 (2019),\n54-60.]."}
{"id": "2507.18290", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18290", "abs": "https://arxiv.org/abs/2507.18290", "authors": ["Antonino Rotolo", "Beatrice Ferrigno", "Jose Miguel Angel Garcia Godinez", "Claudio Novelli", "Giovanni Sartor"], "title": "Foundations for Risk Assessment of AI in Protecting Fundamental Rights", "comment": "24 pages, 1 figure. To be published in: The Philosophical Foundations\n  of Information Technology Law. Oxford University Press, Oxford", "summary": "This chapter introduces a conceptual framework for qualitative risk\nassessment of AI, particularly in the context of the EU AI Act. The framework\naddresses the complexities of legal compliance and fundamental rights\nprotection by itegrating definitional balancing and defeasible reasoning.\nDefinitional balancing employs proportionality analysis to resolve conflicts\nbetween competing rights, while defeasible reasoning accommodates the dynamic\nnature of legal decision-making. Our approach stresses the need for an analysis\nof AI deployment scenarios and for identifying potential legal violations and\nmulti-layered impacts on fundamental rights. On the basis of this analysis, we\nprovide philosophical foundations for a logical account of AI risk analysis. In\nparticular, we consider the basic building blocks for conceptually grasping the\ninteraction between AI deployment scenarios and fundamental rights,\nincorporating in defeasible reasoning definitional balancing and arguments\nabout the contextual promotion or demotion of rights. This layered approach\nallows for more operative models of assessment of both high-risk AI systems and\nGeneral Purpose AI (GPAI) systems, emphasizing the broader applicability of the\nlatter. Future work aims to develop a formal model and effective algorithms to\nenhance AI risk assessment, bridging theoretical insights with practical\napplications to support responsible AI governance."}
{"id": "2507.18535", "categories": ["math.CO", "05C05, 05C69"], "pdf": "https://arxiv.org/pdf/2507.18535", "abs": "https://arxiv.org/abs/2507.18535", "authors": ["Mazharuddin Mehraban", "Saeid Alikhani"], "title": "Stability of $2$-domination number of a graph", "comment": "11 pages, 2 figures", "summary": "This paper delves into the stability of the $2$-domination number in simple\nundirected graphs. The $2$-domination number of a graph $G$, $\\gamma_2(G)$,\nrepresents the minimum size of a vertex subset where every other vertex in the\ngraph is adjacent to at least two members of the subset. We define the\n$2$-domination stability, $st_{\\gamma_2}(G)$, as the smallest number of\nvertices whose removal causes a change in $\\gamma_2(G)$. Our primary\ncontributions include computing this parameter for specific graphs,\nestablishing various bounds for this stability and determining its behavior\nunder certain graph operations combining two graphs."}
{"id": "2507.18337", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18337", "abs": "https://arxiv.org/abs/2507.18337", "authors": ["Peter Baumgartner", "Lachlan McGinness"], "title": "The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams", "comment": null, "summary": "We present our method for automatically marking Physics exams. The marking\nproblem consists in assessing typed student answers for correctness with\nrespect to a ground truth solution. This is a challenging problem that we seek\nto tackle using a combination of a computer algebra system, an SMT solver and a\nterm rewriting system. A Large Language Model is used to interpret and remove\nerrors from student responses and rewrite these in a machine readable format.\nOnce formalized and language-aligned, the next step then consists in applying\nautomated reasoning techniques for assessing student solution correctness. We\nconsider two methods of automated theorem proving: off-the-shelf SMT solving\nand term rewriting systems tailored for physics problems involving\ntrigonometric expressions. The development of the term rewrite system and\nestablishing termination and confluence properties was not trivial, and we\ndescribe it in some detail in the paper. We evaluate our system on a rich pool\nof over 1500 real-world student exam responses from the 2023 Australian Physics\nOlympiad."}
{"id": "2507.18629", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.18629", "abs": "https://arxiv.org/abs/2507.18629", "authors": ["Pitchayut Saengrungkongka"], "title": "On $t$-intersecting Families of Spanning Trees", "comment": null, "summary": "We prove that there exists a constant $c>0$ such that for all integers $2\\leq\nt\\leq cn$, if $\\calA$ is a collection of spanning trees in $K_n$ such that any\ntwo intersect at at least $t$ edges, then $|\\calA|\\leq 2^tn^{n-t-2}$. This\nbound is tight; the equality is achieved when $\\calA$ is a collection of\nspanning trees containing a fixed $t$ disjoint edges. This is an improvement of\na result by Frankl, Hurlbert, Ihringer, Kupavskii, Lindzey, Meagher, and\nPantagi, who proved such a result for $t=O\\left(\\frac n{\\log n}\\right)$."}
{"id": "2507.18368", "categories": ["cs.AI", "I.2.0; I.2.6; J.4"], "pdf": "https://arxiv.org/pdf/2507.18368", "abs": "https://arxiv.org/abs/2507.18368", "authors": ["Zhuang Qiang Bok", "Watson Wei Khong Chua"], "title": "Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios", "comment": "Accepted by Agentic & GenAI Evaluation KDD2025: KDD workshop on\n  Evaluation and Trustworthiness of Agentic and Generative AI Models\n  https://kdd-eval-workshop.github.io/genai-evaluation-kdd2025/", "summary": "Most reasoning benchmarks for LLMs emphasize factual accuracy or step-by-step\nlogic. In finance, however, professionals must not only converge on optimal\ndecisions but also generate creative, plausible futures under uncertainty. We\nintroduce ConDiFi, a benchmark that jointly evaluates divergent and convergent\nthinking in LLMs for financial tasks.\n  ConDiFi features 607 macro-financial prompts for divergent reasoning and 990\nmulti-hop adversarial MCQs for convergent reasoning. Using this benchmark, we\nevaluated 14 leading models and uncovered striking differences. Despite high\nfluency, GPT-4o underperforms on Novelty and Actionability. In contrast, models\nlike DeepSeek-R1 and Cohere Command R+ rank among the top for generating\nactionable, insights suitable for investment decisions. ConDiFi provides a new\nperspective to assess reasoning capabilities essential to safe and strategic\ndeployment of LLMs in finance."}
{"id": "2507.17780", "categories": ["cs.DM", "cs.AI", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.17780", "abs": "https://arxiv.org/abs/2507.17780", "authors": ["Randy Davila", "Boris Brimkov", "Ryan Pepper"], "title": "In Reverie Together: Ten Years of Mathematical Discovery with a Machine Collaborator", "comment": null, "summary": "We present four open conjectures in graph theory generated by the automated\nconjecturing system \\texttt{TxGraffiti}. Each conjecture is concise, grounded\nin natural graph invariants, and empirically validated across hundreds of\ngraphs. Despite extensive effort, these statements remain unresolved--defying\nboth proof and counterexample. They are not only mathematical challenges but\ncreative expressions--born of symbolic pattern recognition and\nmathematician-defined heuristics, refined through years of human dialogue, and\nnow offered back to the community as collaborative artifacts. These conjectures\ninvite not only formal proof, but also reflection on how machines can evoke\nwonder, spark curiosity, and contribute to the raw material of discovery. By\nhighlighting these problems, we aim to inspire both human mathematicians and AI\nsystems to engage with them--not only to solve them, but to reflect on what it\nmeans when machines participate meaningfully in the creative process of\nmathematical thought."}
{"id": "2507.18391", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18391", "abs": "https://arxiv.org/abs/2507.18391", "authors": ["Shiye Lei", "Zhihao Cheng", "Kai Jia", "Dacheng Tao"], "title": "Revisiting LLM Reasoning via Information Bottleneck", "comment": null, "summary": "Large language models (LLMs) have recently demonstrated remarkable progress\nin reasoning capabilities through reinforcement learning with verifiable\nrewards (RLVR). By leveraging simple rule-based rewards, RL effectively\nincentivizes LLMs to produce extended chain-of-thought (CoT) reasoning\ntrajectories, progressively guiding them toward correct answers. However,\nexisting approaches remain largely heuristic and intuition-driven, limiting the\ndevelopment of principled methodologies. In this paper, we present a\ntheoretical characterization of LLM reasoning grounded in information\nbottleneck (IB) principle, introducing IB-aware reasoning optimization (IBRO),\na framework that encourages reasoning trajectories to be both informative about\nthe final correct answer and generalizable across diverse prompts. We derive a\npractical token-level surrogate objective and propose an efficient\napproximation, resulting in the lightweight IB regularization method. This\ntechnique integrates seamlessly into existing RL-based post-training frameworks\nwithout additional computational overhead, requiring only a one-line code\nmodification. Empirically, we validate IB regularization across multiple\nmathematical reasoning benchmarks and RL algorithms, demonstrating consistent\nimprovements in LLM reasoning performance."}
{"id": "2507.18398", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18398", "abs": "https://arxiv.org/abs/2507.18398", "authors": ["Kwong Ho Li", "Wathsala Karunarathne"], "title": "Optimising Call Centre Operations using Reinforcement Learning: Value Iteration versus Proximal Policy Optimisation", "comment": "10 pages", "summary": "This paper investigates the application of Reinforcement Learning (RL) to\noptimise call routing in call centres to minimise client waiting time and staff\nidle time. Two methods are compared: a model-based approach using Value\nIteration (VI) under known system dynamics, and a model-free approach using\nProximal Policy Optimisation (PPO) that learns from experience. For the\nmodel-based approach, a theoretical model is used, while a simulation model\ncombining Discrete Event Simulation (DES) with the OpenAI Gym environment is\ndeveloped for model-free learning. Both models frame the problem as a Markov\nDecision Process (MDP) within a Skills-Based Routing (SBR) framework, with\nPoisson client arrivals and exponentially distributed service and abandonment\ntimes. For policy evaluation, random, VI, and PPO policies are evaluated using\nthe simulation model. After 1,000 test episodes, PPO consistently achives the\nhighest rewards, along with the lowest client waiting time and staff idle time,\ndespite requiring longer training time."}
{"id": "2507.18413", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18413", "abs": "https://arxiv.org/abs/2507.18413", "authors": ["Enrico Santi", "Fabio Tardivo", "Agostino Dovier", "Andrea Formisano"], "title": "GPU Accelerated Compact-Table Propagation", "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "summary": "Constraint Programming developed within Logic Programming in the Eighties;\nnowadays all Prolog systems encompass modules capable of handling constraint\nprogramming on finite domains demanding their solution to a constraint solver.\nThis work focuses on a specific form of constraint, the so-called table\nconstraint, used to specify conditions on the values of variables as an\nenumeration of alternative options. Since every condition on a set of finite\ndomain variables can be ultimately expressed as a finite set of cases, Table\ncan, in principle, simulate any other constraint. These characteristics make\nTable one of the most studied constraints ever, leading to a series of\nincreasingly efficient propagation algorithms. Despite this, it is not uncommon\nto encounter real-world problems with hundreds or thousands of valid cases that\nare simply too many to be handled effectively with standard CPU-based\napproaches. In this paper, we deal with the Compact-Table (CT) algorithm, the\nstate-of-the-art propagation algorithms for Table. We describe how CT can be\nenhanced by exploiting the massive computational power offered by modern GPUs\nto handle large Table constraints. In particular, we report on the design and\nimplementation of GPU-accelerated CT, on its integration into an existing\nconstraint solver, and on an experimental validation performed on a significant\nset of instances."}
{"id": "2507.18550", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.18550", "abs": "https://arxiv.org/abs/2507.18550", "authors": ["Manuel de Sousa Ribeiro", "Afonso Leote", "João Leite"], "title": "On the Performance of Concept Probing: The Influence of the Data (Extended Version)", "comment": "Extended version of the paper published in Proceedings of the\n  European Conference on Artificial Intelligence (ECAI 2025)", "summary": "Concept probing has recently garnered increasing interest as a way to help\ninterpret artificial neural networks, dealing both with their typically large\nsize and their subsymbolic nature, which ultimately renders them unfeasible for\ndirect human interpretation. Concept probing works by training additional\nclassifiers to map the internal representations of a model into human-defined\nconcepts of interest, thus allowing humans to peek inside artificial neural\nnetworks. Research on concept probing has mainly focused on the model being\nprobed or the probing model itself, paying limited attention to the data\nrequired to train such probing models. In this paper, we address this gap.\nFocusing on concept probing in the context of image classification tasks, we\ninvestigate the effect of the data used to train probing models on their\nperformance. We also make available concept labels for two widely used\ndatasets."}
{"id": "2507.18576", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.18576", "abs": "https://arxiv.org/abs/2507.18576", "authors": ["Shanghai AI Lab", ":", "Yicheng Bao", "Guanxu Chen", "Mingkang Chen", "Yunhao Chen", "Chiyu Chen", "Lingjie Chen", "Sirui Chen", "Xinquan Chen", "Jie Cheng", "Yu Cheng", "Dengke Deng", "Yizhuo Ding", "Dan Ding", "Xiaoshan Ding", "Yi Ding", "Zhichen Dong", "Lingxiao Du", "Yuyu Fan", "Xinshun Feng", "Yanwei Fu", "Yuxuan Gao", "Ruijun Ge", "Tianle Gu", "Lujun Gui", "Jiaxuan Guo", "Qianxi He", "Yuenan Hou", "Xuhao Hu", "Hong Huang", "Kaichen Huang", "Shiyang Huang", "Yuxian Jiang", "Shanzhe Lei", "Jie Li", "Lijun Li", "Hao Li", "Juncheng Li", "Xiangtian Li", "Yafu Li", "Lingyu Li", "Xueyan Li", "Haotian Liang", "Dongrui Liu", "Qihua Liu", "Zhixuan Liu", "Bangwei Liu", "Huacan Liu", "Yuexiao Liu", "Zongkai Liu", "Chaochao Lu", "Yudong Lu", "Xiaoya Lu", "Zhenghao Lu", "Qitan Lv", "Caoyuan Ma", "Jiachen Ma", "Xiaoya Ma", "Zhongtian Ma", "Lingyu Meng", "Ziqi Miao", "Yazhe Niu", "Yuezhang Peng", "Yuan Pu", "Han Qi", "Chen Qian", "Xingge Qiao", "Jingjing Qu", "Jiashu Qu", "Wanying Qu", "Wenwen Qu", "Xiaoye Qu", "Qihan Ren", "Qingnan Ren", "Qingyu Ren", "Jing Shao", "Wenqi Shao", "Shuai Shao", "Dongxing Shi", "Xin Song", "Xinhao Song", "Yan Teng", "Xuan Tong", "Yingchun Wang", "Xuhong Wang", "Shujie Wang", "Xin Wang", "Yige Wang", "Yixu Wang", "Yuanfu Wang", "Futing Wang", "Ruofan Wang", "Wenjie Wang", "Yajie Wang", "Muhao Wei", "Xiaoyu Wen", "Fenghua Weng", "Yuqi Wu", "Yingtong Xiong", "Xingcheng Xu", "Chao Yang", "Yue Yang", "Yang Yao", "Yulei Ye", "Zhenyun Yin", "Yi Yu", "Bo Zhang", "Qiaosheng Zhang", "Jinxuan Zhang", "Yexin Zhang", "Yinqiang Zheng", "Hefeng Zhou", "Zhanhui Zhou", "Pengyu Zhu", "Qingzi Zhu", "Yubo Zhu", "Bowen Zhou"], "title": "SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\\circ}$ Law", "comment": "47 pages, 18 figures, authors are listed in alphabetical order by\n  their last names", "summary": "We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that\ndemonstrates the coevolution of capabilities and safety. It is developed by our\nproposed SafeLadder framework, which incorporates large-scale, progressive,\nsafety-oriented reinforcement learning post-training, supported by a suite of\nmulti-principled verifiers. Unlike previous alignment methods such as RLHF that\nsimply learn human preferences, SafeLadder enables SafeWork-R1 to develop\nintrinsic safety reasoning and self-reflection abilities, giving rise to safety\n`aha' moments. Notably, SafeWork-R1 achieves an average improvement of\n$46.54\\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks\nwithout compromising general capabilities, and delivers state-of-the-art safety\nperformance compared to leading proprietary models such as GPT-4.1 and Claude\nOpus 4. To further bolster its reliability, we implement two distinct\ninference-time intervention methods and a deliberative search mechanism,\nenforcing step-level verification. Finally, we further develop\nSafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and\nSafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and\ncapability can co-evolve synergistically, highlighting the generalizability of\nour framework in building robust, reliable, and trustworthy general-purpose AI."}
{"id": "2507.17776", "categories": ["math.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17776", "abs": "https://arxiv.org/abs/2507.17776", "authors": ["Jie Fan"], "title": "Axiomatizing Rumsfeld Ignorance", "comment": "This is an almost-final version", "summary": "In a recent paper, Kit Fine presents some striking results concerning the\nlogical properties of (first-order) ignorance, second-order ignorance and\nRumsfeld ignorance. However, Rumsfeld ignorance is definable in terms of\nignorance, which makes some existing results and the axiomatization problem\ntrivial. A main reason is that the accessibility relations for the implicit\nknowledge operator contained in the packaged operators of ignorance and\nRumsfeld ignorance are the same. In this work, we assume the two accessibility\nrelations to be different so that one of them is an arbitrary subset of the\nother. This will avoid the definability issue and retain most of the previous\nvalidities. The main results are axiomatizations over various proper bi-frame\nclasses. Finally we apply our framework to analyze Fine's results."}
{"id": "2507.17780", "categories": ["cs.DM", "cs.AI", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.17780", "abs": "https://arxiv.org/abs/2507.17780", "authors": ["Randy Davila", "Boris Brimkov", "Ryan Pepper"], "title": "In Reverie Together: Ten Years of Mathematical Discovery with a Machine Collaborator", "comment": null, "summary": "We present four open conjectures in graph theory generated by the automated\nconjecturing system \\texttt{TxGraffiti}. Each conjecture is concise, grounded\nin natural graph invariants, and empirically validated across hundreds of\ngraphs. Despite extensive effort, these statements remain unresolved--defying\nboth proof and counterexample. They are not only mathematical challenges but\ncreative expressions--born of symbolic pattern recognition and\nmathematician-defined heuristics, refined through years of human dialogue, and\nnow offered back to the community as collaborative artifacts. These conjectures\ninvite not only formal proof, but also reflection on how machines can evoke\nwonder, spark curiosity, and contribute to the raw material of discovery. By\nhighlighting these problems, we aim to inspire both human mathematicians and AI\nsystems to engage with them--not only to solve them, but to reflect on what it\nmeans when machines participate meaningfully in the creative process of\nmathematical thought."}
{"id": "2507.17850", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17850", "abs": "https://arxiv.org/abs/2507.17850", "authors": ["Rodrigo Moreira", "Larissa F. Rodrigues Moreira", "Flávio de Oliveira Silva"], "title": "Performance Evaluation and Threat Mitigation in Large-scale 5G Core Deployment", "comment": null, "summary": "The deployment of large-scale software-based 5G core functions presents\nsignificant challenges due to their reliance on optimized and intelligent\nresource provisioning for their services. Many studies have focused on\nanalyzing the impact of resource allocation for complex deployments using\nmathematical models, queue theories, or even Artificial Intelligence (AI). This\npaper elucidates the effects of chaotic workloads, generated by Distributed\nDenial of Service (DDoS) on different Network Functions (NFs) on User Equipment\nregistration performance. Our findings highlight the necessity of diverse\nresource profiles to ensure Service-Level Agreement (SLA) compliance in\nlarge-scale 5G core deployments. Additionally, our analysis of packet capture\napproaches demonstrates the potential of kernel-based monitoring for scalable\nsecurity threat defense. Finally, our empirical evaluation provides insights\ninto the effective deployment of 5G NFs in complex scenarios."}
{"id": "2507.17978", "categories": ["cs.CR", "cs.AI", "cs.HC", "68P20 (Primary) 68T05, 68T07, 68T10 (Secondary)", "K.6.5; I.2.6; I.2.7; C.2.0"], "pdf": "https://arxiv.org/pdf/2507.17978", "abs": "https://arxiv.org/abs/2507.17978", "authors": ["Paulo Mendes", "Eva Maia", "Isabel Praça"], "title": "MeAJOR Corpus: A Multi-Source Dataset for Phishing Email Detection", "comment": "8 pages, 2 tables, WI-IAT 2025 conference", "summary": "Phishing emails continue to pose a significant threat to cybersecurity by\nexploiting human vulnerabilities through deceptive content and malicious\npayloads. While Machine Learning (ML) models are effective at detecting\nphishing threats, their performance largely relies on the quality and diversity\nof the training data. This paper presents MeAJOR (Merged email Assets from\nJoint Open-source Repositories) Corpus, a novel, multi-source phishing email\ndataset designed to overcome critical limitations in existing resources. It\nintegrates 135894 samples representing a broad number of phishing tactics and\nlegitimate emails, with a wide spectrum of engineered features. We evaluated\nthe dataset's utility for phishing detection research through systematic\nexperiments with four classification models (RF, XGB, MLP, and CNN) across\nmultiple feature configurations. Results highlight the dataset's effectiveness,\nachieving 98.34% F1 with XGB. By integrating broad features from multiple\ncategories, our dataset provides a reusable and consistent resource, while\naddressing common challenges like class imbalance, generalisability and\nreproducibility."}
{"id": "2507.18215", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18215", "abs": "https://arxiv.org/abs/2507.18215", "authors": ["Chang Gong", "Zhongwen Li", "Xiaoqi Li"], "title": "Information Security Based on LLM Approaches: A Review", "comment": null, "summary": "Information security is facing increasingly severe challenges, and\ntraditional protection means are difficult to cope with complex and changing\nthreats. In recent years, as an emerging intelligent technology, large language\nmodels (LLMs) have shown a broad application prospect in the field of\ninformation security. In this paper, we focus on the key role of LLM in\ninformation security, systematically review its application progress in\nmalicious behavior prediction, network threat analysis, system vulnerability\ndetection, malicious code identification, and cryptographic algorithm\noptimization, and explore its potential in enhancing security protection\nperformance. Based on neural networks and Transformer architecture, this paper\nanalyzes the technical basis of large language models and their advantages in\nnatural language processing tasks. It is shown that the introduction of large\nlanguage modeling helps to improve the detection accuracy and reduce the false\nalarm rate of security systems. Finally, this paper summarizes the current\napplication results and points out that it still faces challenges in model\ntransparency, interpretability, and scene adaptability, among other issues. It\nis necessary to explore further the optimization of the model structure and the\nimprovement of the generalization ability to realize a more intelligent and\naccurate information security protection system."}
{"id": "2507.18302", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.18302", "abs": "https://arxiv.org/abs/2507.18302", "authors": ["Delong Ran", "Xinlei He", "Tianshuo Cong", "Anyu Wang", "Qi Li", "Xiaoyun Wang"], "title": "LoRA-Leak: Membership Inference Attacks Against LoRA Fine-tuned Language Models", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Language Models (LMs) typically adhere to a \"pre-training and fine-tuning\"\nparadigm, where a universal pre-trained model can be fine-tuned to cater to\nvarious specialized domains. Low-Rank Adaptation (LoRA) has gained the most\nwidespread use in LM fine-tuning due to its lightweight computational cost and\nremarkable performance. Because the proportion of parameters tuned by LoRA is\nrelatively small, there might be a misleading impression that the LoRA\nfine-tuning data is invulnerable to Membership Inference Attacks (MIAs).\nHowever, we identify that utilizing the pre-trained model can induce more\ninformation leakage, which is neglected by existing MIAs. Therefore, we\nintroduce LoRA-Leak, a holistic evaluation framework for MIAs against the\nfine-tuning datasets of LMs. LoRA-Leak incorporates fifteen membership\ninference attacks, including ten existing MIAs, and five improved MIAs that\nleverage the pre-trained model as a reference. In experiments, we apply\nLoRA-Leak to three advanced LMs across three popular natural language\nprocessing tasks, demonstrating that LoRA-based fine-tuned LMs are still\nvulnerable to MIAs (e.g., 0.775 AUC under conservative fine-tuning settings).\nWe also applied LoRA-Leak to different fine-tuning settings to understand the\nresulting privacy risks. We further explore four defenses and find that only\ndropout and excluding specific LM layers during fine-tuning effectively\nmitigate MIA risks while maintaining utility. We highlight that under the\n\"pre-training and fine-tuning\" paradigm, the existence of the pre-trained model\nmakes MIA a more severe risk for LoRA-based LMs. We hope that our findings can\nprovide guidance on data privacy protection for specialized LM providers."}
{"id": "2507.18577", "categories": ["q-fin.CP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.18577", "abs": "https://arxiv.org/abs/2507.18577", "authors": ["Liyuan Chen", "Shuoling Liu", "Jiangpeng Yan", "Xiaoyu Wang", "Henglin Liu", "Chuang Li", "Kecheng Jiao", "Jixuan Ying", "Yang Veronica Liu", "Qiang Yang", "Xiu Li"], "title": "Advancing Financial Engineering with Foundation Models: Progress, Applications, and Challenges", "comment": "Under Review", "summary": "The advent of foundation models (FMs) - large-scale pre-trained models with\nstrong generalization capabilities - has opened new frontiers for financial\nengineering. While general-purpose FMs such as GPT-4 and Gemini have\ndemonstrated promising performance in tasks ranging from financial report\nsummarization to sentiment-aware forecasting, many financial applications\nremain constrained by unique domain requirements such as multimodal reasoning,\nregulatory compliance, and data privacy. These challenges have spurred the\nemergence of Financial Foundation Models (FFMs) - a new class of models\nexplicitly designed for finance. This survey presents a comprehensive overview\nof FFMs, with a taxonomy spanning three key modalities: Financial Language\nFoundation Models (FinLFMs), Financial Time-Series Foundation Models\n(FinTSFMs), and Financial Visual-Language Foundation Models (FinVLFMs). We\nreview their architectures, training methodologies, datasets, and real-world\napplications. Furthermore, we identify critical challenges in data\navailability, algorithmic scalability, and infrastructure constraints, and\noffer insights into future research opportunities. We hope this survey serves\nas both a comprehensive reference for understanding FFMs and a practical\nroadmap for future innovation. An updated collection of FFM-related\npublications and resources will be maintained on our website\nhttps://github.com/FinFM/Awesome-FinFMs."}
