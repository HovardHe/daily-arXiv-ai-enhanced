{"id": "2506.17943", "categories": ["math.LO", "03F30, 03C20, 03H15"], "pdf": "https://arxiv.org/pdf/2506.17943", "abs": "https://arxiv.org/abs/2506.17943", "authors": ["Wei Wang"], "title": "Finite Combinatorics and Fragments of Arithmetic", "comment": null, "summary": "In fragments of first order arithmetic, definable maps on finite domains\ncould behave very differently from finite maps. Here combinatorial properties\nof $\\Sigma_{n+1}$-definable maps on finite domains are compared in the absence\nof $B\\Sigma_{n+1}$. It is shown that $\\mathrm{GPHP}(\\Sigma_{n+1})$ (the\n$\\Sigma_{n+1}$-instance of Kaye's General Pigeonhole Principle) lies strictly\nbetween $\\mathrm{CARD}(\\Sigma_{n+1})$ and $\\mathrm{WPHP}(\\Sigma_{n+1})$ (Weak\nPigeonhole Principle for $\\Sigma_{n+1}$-maps), and also that\n$\\mathrm{FRT}(\\Sigma_{n+1})$ (Finite Ramsey's Theorem for $\\Sigma_{n+1}$-maps)\ndoes not imply $\\mathrm{WPHP}(\\Sigma_{n+1})$.", "AI": {"tldr": "该论文研究了在缺乏$B\\Sigma_{n+1}$的情况下，一阶算术片段中$\\Sigma_{n+1}$-可定义映射在有限域上的组合性质，比较了不同鸽巢原理变体之间的关系。", "motivation": "探讨有限域上$\\Sigma_{n+1}$-可定义映射与有限映射行为的差异，特别是在$B\\Sigma_{n+1}$缺失时的组合性质。", "method": "通过比较$\\mathrm{GPHP}(\\Sigma_{n+1})$、$\\mathrm{CARD}(\\Sigma_{n+1})$和$\\mathrm{WPHP}(\\Sigma_{n+1})$之间的关系，以及分析$\\mathrm{FRT}(\\Sigma_{n+1})$与$\\mathrm{WPHP}(\\Sigma_{n+1})$的独立性。", "result": "证明了$\\mathrm{GPHP}(\\Sigma_{n+1})$严格位于$\\mathrm{CARD}(\\Sigma_{n+1})$和$\\mathrm{WPHP}(\\Sigma_{n+1})$之间，且$\\mathrm{FRT}(\\Sigma_{n+1})$不蕴含$\\mathrm{WPHP}(\\Sigma_{n+1})$。", "conclusion": "研究揭示了$\\Sigma_{n+1}$-可定义映射在有限域上的复杂组合行为，为理解一阶算术片段中的鸽巢原理提供了新的理论依据。"}}
{"id": "2506.17982", "categories": ["math.LO", "math.AC", "math.AT", "math.CT", "math.KT", "03E15, 13D07 (Primary) 13D09, 13F05 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.17982", "abs": "https://arxiv.org/abs/2506.17982", "authors": ["Matteo Casarosa", "Martino Lupini"], "title": "Projective length, phantom extensions, and the structure of flat modules", "comment": "97 pages", "summary": "We consider the natural generalization of the notion of the order of a\nphantom map from the topological setting to triangulated categories. When\napplied to the derived category of the category of countable flat modules over\na countable Dedekind domain, this yields a notion of\\emph{\\ phantom extension}\nof order $\\alpha <\\omega _{1}$. We provide a complexity-theoretic\ncharacterization of the module $\\mathrm{Ph}% ^{\\alpha }\\mathrm{Ext}\\left(\nC,A\\right) $ of phantom extensions of order $\\alpha $ with respect to the\nstructure of \\emph{phantom Polish module} on $\\mathrm{Ext}\\left( C,A\\right) $\nobtained by considering it as an object of the left heart of the quasi-abelian\ncategory of Polish modules. We use this characterization to prove the following\nDichotomy Theorem: either all the extensions of a countable flat module $A$ are\ntrivial (which happens precisely when $A$ is divisible) or $A$ has phantom\nextensions of arbitrarily high order.\n  By producing canonical phantom projective resolutions of order $\\alpha $, we\nprove that phantom extensions of order $\\alpha $ define on the category of\ncountable flat modules an exact structure $\\mathcal{E}_{\\alpha }$ that is\nhereditary with enough projectives, and the functor $\\mathrm{Ph}^{\\alpha }%\n\\mathrm{Ext}$ is the derived functor of $\\mathrm{Hom}$ with respect to\n$\\mathcal{E}_{\\alpha }$. We prove a Structure Theorem characterizing the\nobjects of the class $\\mathcal{P}_{\\alpha }$ of countable flat modules that\nhave \\emph{projective length at most }$\\alpha $ (i.e., are $\\mathcal{E}_{\\alpha\n}$-projective) as the direct summands of colimits of presheaves of finite flat\nmodules over well-founded forests of rank $% 1+\\alpha $ regarded as ordered\nsets. This can be seen as the first analogue in the flat case of the classical\nUlm Classification Theorem for torsion modules.", "AI": {"tldr": "本文从拓扑概念推广至三角范畴，提出可数Dedekind域上平坦模的幻影扩张概念，建立了复杂度理论刻画，并证明了一个二分法定理。通过构造规范幻影投射分解，定义了精确结构$\\mathcal{E}_{\\alpha}$，并给出了平坦模的结构定理。", "motivation": "研究动机在于将幻影映射的阶数概念从拓扑学推广至三角范畴，特别是可数Dedekind域上平坦模的导出范畴，以探索幻影扩张的性质及其在模论中的应用。", "method": "方法包括定义幻影扩张的阶数$\\alpha$，利用波兰模的左心结构对$\\mathrm{Ext}(C,A)$进行复杂度刻画，构造幻影投射分解，并建立精确结构$\\mathcal{E}_{\\alpha}$。", "result": "主要结果包括二分法定理（平坦模$A$要么所有扩张平凡，要么存在任意高阶幻影扩张），以及结构定理（将$\\mathcal{P}_{\\alpha}$类对象刻画为有限平坦模预层在秩$1+\\alpha$良基森林上的余极限直和项）。", "conclusion": "结论表明该研究首次在平坦模情形建立了类似于挠模Ulm分类定理的结构理论，揭示了幻影扩张阶数与模的投射长度之间的深刻联系，为平坦模分类提供了新工具。"}}
{"id": "2506.17448", "categories": ["math.ST", "stat.ME", "stat.TH", "60G70, 62G32, 62E20,"], "pdf": "https://arxiv.org/pdf/2506.17448", "abs": "https://arxiv.org/abs/2506.17448", "authors": ["David L. Carl", "Simone A. Padoan", "Stefano Rizzelli"], "title": "Asymptotic theory for the likelihood-based block maxima method in time series", "comment": null, "summary": "This paper develops a rigorous asymptotic framework for likelihood-based\ninference in the Block Maxima (BM) method for stationary time series. While\nBayesian inference under the BM approach has been widely studied in the\nindependence setting, no asymptotic theory currently exists for time series.\nFurther results are needed to establish that BM method can be applied with the\nkind of dependent time series models relevant to applied fields. To address\nthis gap we first establish a comprehensive likelihood theory for the\nmisspecified Generalized Extreme Value (GEV) model under serial dependence. Our\nresults include uniform convergence of the empirical log-likelihood process,\ncontraction rates for the Maximum Likelihood Estimator, and a local\nasymptotically Gaussian expansion. Building on this foundation, we develop the\nasymptotic theory of Bayesian inference for the GEV parameters, the extremal\nindex, $T$-time-horizon return levels, and extreme quantiles (Value at Risk).\nUnder general conditions on the prior, we prove posterior consistency,\n$\\sqrt{k}$-contraction rates, Bernstein-von Mises theorems, and asymptotic\ncoverage properties for credible intervals. For inference on the extremal\nindex, we propose an adjusted posterior distribution that corrects for poor\ncoverage exhibited by a naive Bayesian approach. Simulations show excellent\ninferential performances for the proposed methodology.", "AI": {"tldr": "本文为平稳时间序列的块最大值（BM）方法建立了一个严格的渐近框架，填补了依赖时间序列模型下贝叶斯推断的理论空白，并提出了修正后验分布以改进极值指数的推断性能。", "motivation": "当前块最大值方法在独立设置下的贝叶斯推断已有广泛研究，但缺乏针对时间序列的渐近理论，需建立适用于实际应用场景的依赖时间序列模型的理论基础。", "method": "首先建立了序列依赖下误指定广义极值（GEV）模型的全面似然理论，包括经验对数似然过程的一致收敛、最大似然估计量的收缩率及局部渐近正态展开。基于此发展了贝叶斯推断的渐近理论。", "result": "证明了后验一致性、$\\sqrt{k}$-收缩率、Bernstein-von Mises定理以及可信区间的渐近覆盖性质。针对极值指数提出了校正后验分布，模拟显示该方法具有优异的推断性能。", "conclusion": "该研究为依赖时间序列的极值分析提供了理论保障，所提出的调整贝叶斯方法显著提升了极值指数和风险价值的推断可靠性。"}}
{"id": "2506.17233", "categories": ["cs.CR", "11Y05"], "pdf": "https://arxiv.org/pdf/2506.17233", "abs": "https://arxiv.org/abs/2506.17233", "authors": ["Akihisa Yorozu"], "title": "A Geometric Square-Based Approach to RSA Integer Factorization", "comment": "3 pages", "summary": "We present a new approach to RSA factorization inspired by geometric\ninterpretations and square differences. This method reformulates the problem in\nterms of the distance between perfect squares and provides a recurrence\nrelation that allows rapid convergence when the RSA modulus has closely spaced\nprime factors. Although this method is efficient for small semiprimes, it does\nnot yet succeed in factoring large challenges like RSA-100 in practical time,\nhighlighting both its potential and current limitations.", "AI": {"tldr": "提出一种基于几何解释与平方差的新RSA因数分解方法，适用于小半素数但尚未突破大数挑战。", "motivation": "探索通过几何视角和平方差重新表述RSA因数分解问题，以提升对相邻质因数模数的分解效率。", "method": "将问题转化为完美平方数间距计算，利用递推关系实现快速收敛，特别针对质因数间距小的RSA模数。", "result": "该方法能高效分解小半素数，但尚未在可行时间内破解RSA-100等大规模挑战，显示其潜力与当前局限。", "conclusion": "几何化方法为RSA分解提供了新思路，但对大数分解仍需进一步优化，未来可能结合其他技术突破限制。"}}
{"id": "2506.17239", "categories": ["q-fin.GN"], "pdf": "https://arxiv.org/pdf/2506.17239", "abs": "https://arxiv.org/abs/2506.17239", "authors": ["Gurkirat Wadhwa", "Akansh Verma", "Veeraruna Kavitha", "Priyank Sinha"], "title": "Price equilibria with positive margins in loyal-strategic markets with discrete prices", "comment": null, "summary": "In competitive supply chains (SCs), pricing decisions are crucial, as they\ndirectly impact market share and profitability. Traditional SC models often\nassume continuous pricing for mathematical convenience, overlooking the\npractical reality of discrete price increments driven by currency constraints.\nAdditionally, customer behavior, influenced by loyalty and strategic\nconsiderations, plays a significant role in purchasing decisions. To address\nthese gaps, this study examines a SC model involving one supplier and two\nmanufacturers, incorporating realistic factors such as customer demand\nsegmentation and discrete price setting. Our analysis shows that the Nash\nequilibria (NE) among manufacturers are not unique, we then discuss the focal\nequilibrium. Our analysis also reveals that low denomination factors can lead\nto instability as the corresponding game does not have NE. Numerical\nsimulations demonstrate that even small changes in price increments\nsignificantly affect the competitive dynamics and market share distribution.", "AI": {"tldr": "研究探讨了竞争性供应链中离散定价对市场均衡的影响，揭示了价格增量变化如何导致纳什均衡不唯一甚至不存在，并通过数值模拟验证了其对市场竞争动态的显著影响。", "motivation": "传统供应链模型常假设连续定价以简化计算，但忽视了现实中因货币单位限制导致的离散定价现象，以及顾客忠诚度和策略行为对购买决策的影响。本研究旨在填补这一理论空白。", "method": "构建了一个包含单一供应商和两家制造商的供应链模型，引入顾客需求分段和离散定价机制，通过博弈论分析纳什均衡特性，并辅以数值模拟验证。", "result": "分析表明制造商间的纳什均衡可能不唯一，且低面额货币单位会导致均衡不存在；数值实验证实微小价格增量变化会显著改变市场份额分配。", "conclusion": "离散定价机制对供应链竞争具有实质性影响，政策制定者需考虑货币面值因素以避免市场不稳定，企业应精细化定价策略以应对动态竞争。"}}
{"id": "2506.17401", "categories": ["math.CO", "math.GR", "math.NT"], "pdf": "https://arxiv.org/pdf/2506.17401", "abs": "https://arxiv.org/abs/2506.17401", "authors": ["Nathanaël Hassler", "Andrew Treglown"], "title": "Notes on sum-free sets in abelian groups", "comment": "17 pages", "summary": "In this paper we highlight a few open problems concerning maximal sum-free\nsets in abelian groups. In addition, for most even order abelian groups $G$ we\nasymptotically determine the number of maximal distinct sum-free subsets in\n$G$. Our proof makes use of the container method.", "AI": {"tldr": "本文探讨了阿贝尔群中最大无和集的一些开放性问题，并对大多数偶数阶阿贝尔群$G$中最大无和子集的数量进行了渐近确定。", "motivation": "研究阿贝尔群中最大无和集的性质及其数量，填补该领域的理论空白。", "method": "利用容器方法（container method）进行证明。", "result": "对于大多数偶数阶阿贝尔群$G$，渐近确定了其最大无和子集的数量。", "conclusion": "该研究为阿贝尔群中最大无和集的理论提供了新的进展，并指出了未来可能的开放性问题。"}}
{"id": "2506.17235", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2506.17235", "abs": "https://arxiv.org/abs/2506.17235", "authors": ["Wenpeng Zhang"], "title": "Some interesting number theory problems", "comment": null, "summary": "The main purpose of this paper is to propose some interesting number theory\nproblems related to the Legendre's symbol and the two-term exponential sums.", "AI": {"tldr": "本文提出了一些与勒让德符号和双项指数和相关的有趣数论问题。", "motivation": "研究勒让德符号和双项指数和在数论中的重要性及其潜在应用。", "method": "通过分析勒让德符号的性质和双项指数和的结构，提出相关问题。", "result": "提出了一系列与勒让德符号和双项指数和相关的数论问题，为后续研究提供了方向。", "conclusion": "这些问题的研究将有助于深入理解勒让德符号和双项指数和在数论中的作用。"}}
{"id": "2506.17416", "categories": ["math.NT", "11M06, 11R42, 11M99, 11S40"], "pdf": "https://arxiv.org/pdf/2506.17416", "abs": "https://arxiv.org/abs/2506.17416", "authors": ["Stephan Ramon Garcia", "Ethan Simpson Lee"], "title": "Explicit conditional bounds for the residue of a Dedekind zeta-function at $s=1$", "comment": "15 pages", "summary": "We prove new explicit conditional bounds for the residue at $s=1$ of the\nDedekind zeta-function associated to a number field. Our bounds are concrete\nand all constants are presented with explicit numerical values.", "AI": {"tldr": "本文证明了关于数域Dedekind zeta函数在$s=1$处留数的新显式条件界，所有常数均给出具体数值。", "motivation": "研究Dedekind zeta函数在临界点$s=1$的留数行为，为解析数论提供更精确的定量工具。", "method": "采用显式分析方法，推导出具有具体数值常数的条件界公式。", "result": "获得了Dedekind zeta函数留数的新显式上界，所有常数均以明确数值形式呈现。", "conclusion": "该结果为数域zeta函数的解析性质提供了可计算的具体界限，具有实际应用价值。"}}
{"id": "2506.18494", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2506.18494", "abs": "https://arxiv.org/abs/2506.18494", "authors": ["Jamolidin K. Abdurakhmanov"], "title": "Distribution of codewords on the faces of a hypercube and new combinatorial identities", "comment": null, "summary": "We present a novel framework for studying combinatorial identities through\nthe geometric lens of subset distributions in q-valued cubes. By analyzing how\nelements of arbitrary subsets are distributed among the faces of the cube\nE_q^n, we discover new combinatorial identities with geometric significance. We\nprove that for any subset A contained in E_2^n, the rank function satisfies\nrefined bounds that lead to exact computations for small cardinalities.\nSpecifically, we show that for odd cardinalities, the lower bound is\n4D_A/(|A|^2-1) where D_A is the sum of all pairwise Hamming distances in A. Our\nmain theorem establishes identities connecting the number of k-dimensional\nfaces containing exactly e elements of a subset to binomial sums over all\nsubsets of specified cardinality. This yields a parametric family of identities\nwhere classical results emerge as special cases. As applications, we derive a\ngeometric interpretation of Vandermonde's identity by examining faces of\nq-valued cubes, revealing that this classical result naturally arises from\ncounting element distributions. We also obtain a completely new identity for\neven-weight vectors: (2^(k-1) - 1) times 2^(n-1) times binomial(n,k) equals the\nsum over i from 1 to floor(n/2) of binomial(n,2i) times binomial(n-2i,k-2i).\nThis identity, valid for all 1 <= k <= n, demonstrates how geometric\nperspectives can uncover hidden combinatorial relationships. Our framework\nprovides a unified approach for generating new identities and understanding\nexisting ones through subset rank analysis.", "AI": {"tldr": "本文提出了一种通过q值立方体中子集分布的几何视角研究组合恒等式的新框架，揭示了新的具有几何意义的组合恒等式，并提供了经典恒等式的几何解释。", "motivation": "研究动机在于通过几何视角理解组合恒等式，探索子集在q值立方体中的分布规律，从而发现新的组合关系并重新解释经典结果。", "method": "方法包括分析子集在$E_q^n$立方体各面上的分布，建立子集秩函数的精确计算，并通过参数化恒等式族连接k维面包含子集元素的数量与二项式求和。", "result": "主要结果包括：证明了奇数基数子集的秩函数下界为$4D_A/(|A|^2-1)$；建立了连接k维面元素分布与二项式求和的恒等式；获得了偶权向量的新恒等式$(2^{k-1}-1)\\times2^{n-1}\\times\\binom{n}{k}=\\sum_{i=1}^{\\lfloor n/2\\rfloor}\\binom{n}{2i}\\binom{n-2i}{k-2i}$。", "conclusion": "该框架通过子集秩分析提供了生成新恒等式和理解现有恒等式的统一方法，证明了几何视角能揭示隐藏的组合关系，范德蒙恒等式等经典结果自然涌现为特例。"}}
{"id": "2506.17289", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17289", "abs": "https://arxiv.org/abs/2506.17289", "authors": ["Rahul Raja", "Arpita Vats"], "title": "Evaluating Generalization and Representation Stability in Small LMs via Prompting", "comment": "Accepted at ICML", "summary": "We investigate the generalization capabilities of small language models under\ntwo popular adaptation paradigms: few-shot prompting and supervised\nfine-tuning. While prompting is often favored for its parameter efficiency and\nflexibility, it remains unclear how robust this approach is in low-resource\nsettings and under distributional shifts. This paper presents a comparative\nstudy of prompting and fine-tuning across task formats, prompt styles, and\nmodel scales, with a focus on their behavior in both in-distribution and\nout-of-distribution (OOD) settings.\n  Beyond accuracy, we analyze the internal representations learned by each\napproach to assess the stability and abstraction of task-specific features. Our\nfindings highlight critical differences in how small models internalize and\ngeneralize knowledge under different adaptation strategies. This work offers\npractical guidance for model selection in low-data regimes and contributes\nempirical insight into the ongoing debate over prompting versus fine-tuning.\nCode for the experiments is available at the following", "AI": {"tldr": "本文比较了小语言模型在少样本提示和监督微调两种适应范式下的泛化能力，重点关注了它们在分布内和分布外设置中的表现差异。", "motivation": "研究动机在于探索少样本提示和监督微调在小语言模型中的泛化能力差异，特别是在低资源设置和分布变化下的鲁棒性。", "method": "方法包括对不同任务格式、提示风格和模型规模进行比较研究，分析内部表示以评估任务特定特征的稳定性和抽象性。", "result": "研究结果揭示了小模型在不同适应策略下如何内化和泛化知识的关键差异，为低数据环境下的模型选择提供了实用指导。", "conclusion": "结论强调了提示和微调在模型适应中的不同效果，为关于这两种策略的持续辩论提供了实证见解。"}}
{"id": "2506.17463", "categories": ["math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.17463", "abs": "https://arxiv.org/abs/2506.17463", "authors": ["Bongjung Sung", "Peter D. Hoff"], "title": "Testing Separability of High-Dimensional Covariance Matrices", "comment": "60 pages, 25 pages in the main text", "summary": "Due to their parsimony, separable covariance models have been popular in\nmodeling matrix-variate data. However, the inference from such a model may be\nmisleading if the population covariance matrix $\\Sigma$ is actually\nnon-separable, motivating the use of statistical tests of separability.\nLikelihood ratio tests have tractable null distributions and good power when\nthe sample size $n$ is larger than the number of variables $p$, but are not\nwell-defined otherwise. Other existing separability tests for the $p>n$ case\nhave low power for small sample sizes, and have null distributions that depend\non unknown parameters, preventing exact error rate control. To address these\nissues, we propose novel invariant tests leveraging the core covariance matrix,\na complementary notion to a separable covariance matrix. We show that testing\nseparability of $\\Sigma$ is equivalent to testing sphericity of its core\ncomponent. With this insight, we construct test statistics that are\nwell-defined in high-dimensional settings and have distributions that are\ninvariant under the null hypothesis of separability, allowing for exact\nsimulation of null distributions. We study asymptotic null distributions and\nprove consistency of our tests in a $p/n\\rightarrow\\gamma\\in(0,\\infty)$\nasymptotic regime. The large power of our proposed tests relative to existing\nprocedures is demonstrated numerically.", "AI": {"tldr": "本文提出了一种新的可分离性检验方法，通过核心协方差矩阵的概念解决了高维数据下传统检验方法存在的问题，并证明了其在大样本下的有效性。", "motivation": "可分离协方差模型在矩阵变量数据建模中广泛应用，但当真实协方差矩阵$\\Sigma$不可分离时，传统推断可能产生误导。现有检验方法在小样本或高维情况下（$p>n$）功效不足或无法精确保证错误率控制，亟需改进方法。", "method": "利用核心协方差矩阵的互补概念，将$\\Sigma$的可分离性检验转化为其核心成分的球性检验。构建了适用于高维场景的检验统计量，其零分布在可分离性假设下具有不变性，可通过模拟精确获得零分布。", "result": "所提检验方法在$p/n\\rightarrow\\gamma\\in(0,\\infty)$的渐近框架下具有确定的零分布，并被证明是一致的。数值模拟显示其功效显著优于现有方法。", "conclusion": "基于核心协方差矩阵的检验方法有效解决了高维数据下可分离性检验的难题，为矩阵变量数据分析提供了更可靠的统计工具。"}}
{"id": "2506.17236", "categories": ["cs.CR", "cs.CE", "cs.DC"], "pdf": "https://arxiv.org/pdf/2506.17236", "abs": "https://arxiv.org/abs/2506.17236", "authors": ["Serdar Metin"], "title": "Design, Implementation, and Analysis of Fair Faucets for Blockchain Ecosystems", "comment": "PhD thesis, 98 pages, 4 figures", "summary": "The present dissertation addresses the problem of fairly distributing shared\nresources in non-commercial blockchain networks. Blockchains are distributed\nsystems that order and timestamp records of a given network of users, in a\npublic, cryptographically secure, and consensual way. The records, which may in\nkind be events, transaction orders, sets of rules for structured transactions\netc. are placed within well-defined datastructures called blocks, and they are\nlinked to each other by the virtue of cryptographic pointers, in a total\nordering which represents their temporal relations of succession. The ability\nto operate on the blockchain, and/or to contribute a record to the content of a\nblock are shared resources of the blockchain systems. In commercial networks,\nthese resources are exchanged in return for fiat money, and consequently,\nfairness is not a relevant problem in terms of computer engineering. In\nnon-commercial networks, however, monetary solutions are not available, by\ndefinition. The present non-commercial blockchain networks employ trivial\ndistribution mechanisms called faucets, which offer fixed amounts of free\ntokens (called cryptocurrencies) specific to the given network. This mechanism,\nalthough simple and efficient, is prone to denial of service (DoS) attacks and\ncannot address the fairness problem. In the present dissertation, the faucet\nmechanism is adapted for fair distribution, in line with Max-min Fairness\nscheme. In total, we contributed 6 distinct Max-min Fair algorithms as\nefficient blockchain faucets. The algorithms we contribute are resistant to DoS\nattacks, low-cost in terms of blockchain computation economics, and they also\nallow for different user weighting policies.", "AI": {"tldr": "本文研究非商业区块链网络中共享资源的公平分配问题，提出6种抗DoS攻击、低计算成本且支持差异化用户权重的Max-min公平算法。", "motivation": "商业区块链通过法币交易实现资源分配，而非商业网络依赖简单的'水龙头'机制，易受DoS攻击且无法保证公平性。", "method": "将传统水龙头机制改进为基于Max-min公平原则的分配方案，设计6种新型算法。", "result": "提出的算法具有抗DoS攻击、低区块链计算成本、支持用户权重策略三大特性。", "conclusion": "Max-min公平算法有效解决了非商业区块链网络的资源公平分配问题，为去中心化系统提供了可靠的经济模型。"}}
{"id": "2506.17628", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.17628", "abs": "https://arxiv.org/abs/2506.17628", "authors": ["Changjiang Bu", "Lixiang Chen", "Ge Lin"], "title": "The characteristic polynomial of sunflowers", "comment": null, "summary": "A uniform hypergraph is called a sunflower if all of its hyperedges intersect\nin the same set of vertices. In this paper, we determine the eigenvalues and\nspectral moments of a sunflower, thereby obtaining an explicit formula for its\ncharacteristic polynomial.", "AI": {"tldr": "本文研究了向日葵超图的特征多项式，通过确定其特征值和谱矩，给出了明确的公式表达。", "motivation": "向日葵超图因其独特的结构特性在超图理论中具有重要地位，研究其特征多项式有助于深入理解其代数性质。", "method": "通过分析向日葵超图的结构特性，推导其特征值和谱矩，最终建立特征多项式的显式公式。", "result": "成功确定了向日葵超图的所有特征值和谱矩，并得到了其特征多项式的显式表达式。", "conclusion": "该研究为向日葵超图的代数性质提供了完整的数学描述，为后续相关研究奠定了理论基础。"}}
{"id": "2506.17240", "categories": ["math.GM", "51M04, 51-08"], "pdf": "https://arxiv.org/pdf/2506.17240", "abs": "https://arxiv.org/abs/2506.17240", "authors": ["Stanley Rabinowitz", "Ercole Suppa"], "title": "More Relationships between a Central Quadrilateral and its Reference Quadrilateral", "comment": null, "summary": "The diagonals of a quadrilateral form four associated triangles, called half\ntriangles. Each half triangle is bounded by two sides of the quadrilateral and\none diagonal. If we locate a triangle center (such as the incenter, centroid,\northocenter, etc.) in each of these triangles, the four triangle centers form\nanother quadrilateral called a central quadrilateral. For each of various\nshaped quadrilaterals, and each of 1000 different triangle centers, we compare\nthe reference quadrilateral to the central quadrilateral. Using a computer, we\ndetermine how the two quadrilaterals are related. For example, we test to see\nif the two quadrilaterals are congruent, similar, have the same area, or have\nthe same perimeter.", "AI": {"tldr": "研究四边形对角线形成的四个半三角形中不同三角形中心构成的新四边形（中心四边形）与原四边形的关系。通过计算机分析1000种三角形中心，比较两者在形状、面积、周长等方面的异同。", "motivation": "探讨四边形与其对角线形成的半三角形中各种三角形中心所构成的新四边形之间的几何关系，扩展对四边形性质的理解。", "method": "在四边形的四个半三角形中分别定位1000种不同的三角形中心（如重心、垂心等），形成中心四边形，并通过计算机程序比较原四边形与中心四边形的几何特性（如全等、相似、面积或周长相等）。", "result": "研究发现，对于不同形状的四边形和不同的三角形中心，原四边形与中心四边形之间存在多种几何关系，如相似性或面积相等。具体关系取决于四边形类型和所选三角形中心。", "conclusion": "通过系统分析，揭示了四边形与其中心四边形之间的丰富几何联系，为四边形和三角形中心的进一步研究提供了基础。"}}
{"id": "2506.17605", "categories": ["math.NT", "11G05 (Primary) 14G05 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.17605", "abs": "https://arxiv.org/abs/2506.17605", "authors": ["Ben Savoie"], "title": "Infinitely many elliptic curves over $\\mathbb{Q}(i)$ with rank 2 and $j$-invariant 1728", "comment": "10 pages", "summary": "We prove that there exist infinitely many elliptic curves over\n$\\mathbb{Q}(i)$ of the form $y^2 = x^3 - \\gamma^2 x$, where $\\gamma \\in\n\\mathbb{Z}[i]$, with rank 2. In addition, we prove that if $p$ and $q$ are\nrational twin primes with $p \\equiv 5 \\bmod 8$, then $y^2 = x^3 + p q x$ has\nrank 2 over $\\mathbb{Q}(i)$. Lastly, we prove that if $p$ is a rational prime\nof the form $p = a^2 + b^4$ (of which there are infinitely many) and $p\n\\not\\equiv 1 \\bmod 16$, then $y^2 = x^3 - p x$ has rank 2 over $\\mathbb{Q}(i)$.", "AI": {"tldr": "该论文证明了在$\\mathbb{Q}(i)$上存在无限多形式为$y^2 = x^3 - \\gamma^2 x$的椭圆曲线，其秩为2，并给出了特定条件下椭圆曲线秩为2的构造方法。", "motivation": "研究在$\\mathbb{Q}(i)$上具有特定形式且秩为2的椭圆曲线的存在性，以扩展对椭圆曲线算术性质的理解。", "method": "通过数论和代数几何的方法，构造并分析了特定形式的椭圆曲线，利用素数性质和模条件证明了秩为2的结论。", "result": "证明了无限多$y^2 = x^3 - \\gamma^2 x$形式的椭圆曲线在$\\mathbb{Q}(i)$上秩为2，并给出了特定素数条件下椭圆曲线秩为2的具体实例。", "conclusion": "该研究不仅证明了无限多秩为2的椭圆曲线的存在性，还提供了具体的构造条件，为椭圆曲线的算术研究提供了新的工具和视角。"}}
{"id": "2506.18578", "categories": ["cs.DM", "cs.DS", "math.CO", "q-bio.PE", "05C85 (Primary), 05C20, 05C90, 06A07, 92D10 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.18578", "abs": "https://arxiv.org/abs/2506.18578", "authors": ["Narmina Baghirova", "Esther Galby", "Martin Milanič"], "title": "Perfect phylogenies via the Minimum Uncovering Branching problem: efficiently solvable cases", "comment": null, "summary": "In this paper, we present new efficiently solvable cases of the Minimum\nUncovering Branching problem, an optimization problem with applications in\ncancer genomics introduced by Hujdurovi\\'c, Husi\\'c, Milani\\v{c}, Rizzi, and\nTomescu in 2018. The problem involves a family of finite sets, and the goal is\nto map each non-maximal set to exactly one set that contains it, minimizing the\nsum of uncovered elements across all sets in the family. Hujdurovi\\'c et al.\nformulated the problem in terms of branchings of the digraph formed by the\nproper set inclusion relation on the input sets and studied the problem\ncomplexity based on properties of the corresponding partially ordered set, in\nparticular, with respect to its height and width, defined respectively as the\nmaximum cardinality of a chain and an antichain. They showed that the problem\nis APX-complete for instances of bounded height and that a constant-factor\napproximation algorithm exists for instances of bounded width, but left the\nexact complexity for bounded-width instances open. In this paper, we answer\nthis question by proving that the problem is solvable in polynomial time. We\nderive this result by examining the structural properties of optimal solutions\nand reducing the problem to computing maximum matchings in bipartite graphs and\nmaximum weight antichains in partially ordered sets. We also introduce a new\npolynomially computable lower bound and identify another condition for\npolynomial-time solvability.", "AI": {"tldr": "本文解决了最小覆盖分支问题在有限宽度实例中的多项式时间可解性，通过将其转化为二分图最大匹配和偏序集最大权反链问题，并提出了新的多项式时间可计算下界。", "motivation": "最小覆盖分支问题在癌症基因组学中有重要应用，此前研究已证明其在有限高度实例中是APX完全的，但在有限宽度实例中的精确复杂度尚未解决。", "method": "通过分析最优解的结构特性，将问题转化为二分图最大匹配和偏序集最大权反链计算，并引入新的多项式时间可计算下界。", "result": "证明了该问题在有限宽度实例中具有多项式时间算法，填补了此前研究的空白。", "conclusion": "本研究不仅解决了最小覆盖分支问题的关键开放性问题，还为相关优化问题提供了新的计算工具和理论框架。"}}
{"id": "2506.17300", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17300", "abs": "https://arxiv.org/abs/2506.17300", "authors": ["Daniel T. Chang"], "title": "Individual Causal Inference with Structural Causal Model", "comment": null, "summary": "Individual causal inference (ICI) uses causal inference methods to understand\nand predict the effects of interventions on individuals, considering their\nspecific characteristics / facts. It aims to estimate individual causal effect\n(ICE), which varies across individuals. Estimating ICE can be challenging due\nto the limited data available for individuals, and the fact that most causal\ninference methods are population-based. Structural Causal Model (SCM) is\nfundamentally population-based. Therefore, causal discovery (structural\nlearning and parameter learning), association queries and intervention queries\nare all naturally population-based. However, exogenous variables (U) in SCM can\nencode individual variations and thus provide the mechanism for individualized\npopulation per specific individual characteristics / facts. Based on this, we\npropose ICI with SCM as a \"rung 3\" causal inference, because it involves\n\"imagining\" what would be the causal effect of a hypothetical intervention on\nan individual, given the individual's observed characteristics / facts.\nSpecifically, we propose the indiv-operator, indiv(W), to formalize/represent\nthe population individualization process, and the individual causal query, P(Y\n| indiv(W), do(X), Z), to formalize/represent ICI. We show and argue that ICI\nwith SCM is inference on individual alternatives (possible), not individual\ncounterfactuals (non-actual).", "AI": {"tldr": "本文提出了一种基于结构因果模型（SCM）的个体因果推理（ICI）方法，通过引入indiv-operator和个体因果查询，实现了对个体干预效果的个性化估计。", "motivation": "传统因果推理方法主要基于群体，难以处理个体层面的因果效应（ICE）。由于个体数据有限且SCM本质上是群体导向的，因此需要一种能够结合个体特征的方法来进行个性化因果推理。", "method": "提出indiv(W)算子来形式化群体个性化过程，并定义个体因果查询P(Y | indiv(W), do(X), Z)来形式化ICI。利用SCM中的外生变量（U）编码个体差异，实现个体化推理。", "result": "研究表明，基于SCM的ICI是对个体可能替代情况的推理，而非非实际的个体反事实推理。这种方法能够有效估计个体干预效果。", "conclusion": "通过SCM实现的ICI属于\"第三阶梯\"因果推理，能够结合个体特征进行假设性干预效果的推理，为个体化决策提供了理论框架。"}}
{"id": "2506.17527", "categories": ["math.ST", "math.CO", "math.PR", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.17527", "abs": "https://arxiv.org/abs/2506.17527", "authors": ["Shuyang Gong", "Zhangsong Li", "Qiheng Xu"], "title": "Detection and Reconstruction of a Random Hypergraph from Noisy Graph Projection", "comment": "18 pages, 1 figure", "summary": "For a $d$-uniform random hypergraph on $n$ vertices in which hyperedges are\nincluded i.i.d.\\ so that the average degree in the hypergraph is\n$n^{\\delta+o(1)}$, the projection of such a hypergraph is a graph on the same\n$n$ vertices where an edge connects two vertices if and only if they belong to\na same hyperedge. In this work, we study the inference problem where the\nobservation is a \\emph{noisy} version of the graph projection where each edge\nin the projection is kept with probability $p=n^{-1+\\alpha+o(1)}$ and each edge\nnot in the projection is added with probability $q=n^{-1+\\beta+o(1)}$. For all\nconstant $d$, we establish sharp thresholds for both detection (distinguishing\nthe noisy projection from an Erd\\H{o}s-R\\'enyi random graph with edge density\n$q$) and reconstruction (estimating the original hypergraph). Notably, our\nresults reveal a \\emph{detection-reconstruction gap} phenomenon in this\nproblem. Our work also answers a problem raised in \\cite{BGPY25+}.", "AI": {"tldr": "本文研究了$d$-均匀随机超图的噪声投影图的推断问题，建立了检测与重构的尖锐阈值，并揭示了检测-重构间隙现象。", "motivation": "研究在噪声环境下，如何从超图的投影图中进行检测和重构，解决\\cite{BGPY25+}中提出的问题。", "method": "通过分析噪声投影图（保留边概率$p=n^{-1+\\alpha+o(1)}$，添加噪声边概率$q=n^{-1+\\beta+o(1)}$），建立检测与重构的理论框架。", "result": "对于所有常数$d$，确定了检测（区分噪声投影与Erd\\H{o}s-R\\'enyi随机图）和重构（估计原始超图）的尖锐阈值，并发现检测-重构间隙现象。", "conclusion": "该工作不仅解决了超图噪声投影的推断问题，还为相关领域提供了理论工具和现象发现。"}}
{"id": "2506.17245", "categories": ["cs.CR", "68M25 (Primary), 68Q85, 94A60 (Secondary)", "D.4.6; K.6.5; H.2.0; H.3.3"], "pdf": "https://arxiv.org/pdf/2506.17245", "abs": "https://arxiv.org/abs/2506.17245", "authors": ["Sagar Neupane"], "title": "Detecting and Mitigating SQL Injection Vulnerabilities in Web Applications", "comment": "24 pages, 4 figures", "summary": "SQL injection (SQLi) remains a critical vulnerability in web applications,\nenabling attackers to manipulate databases through malicious inputs. Despite\nadvancements in mitigation techniques, the evolving complexity of web\napplications and attack strategies continues to pose significant risks. This\npaper presents a comprehensive penetration testing methodology to identify,\nexploit, and mitigate SQLi vulnerabilities in a PHP-MySQL-based web\napplication. Utilizing tools such as OWASP ZAP, sqlmap, and Nmap, the study\ndemonstrates a systematic approach to vulnerability assessment and remediation.\nThe findings underscore the efficacy of input sanitization and prepared\nstatements in mitigating SQLi risks, while highlighting the need for ongoing\nsecurity assessments to address emerging threats. The study contributes to the\nfield by providing practical insights into effective detection and prevention\nstrategies, supported by a real-world case study.", "AI": {"tldr": "本文提出了一种针对PHP-MySQL网络应用的SQL注入漏洞综合渗透测试方法，强调了输入消毒和预处理语句的有效性，并通过真实案例验证了持续安全评估的重要性。", "motivation": "SQL注入（SQLi）仍是网络应用的关键漏洞，尽管防御技术有所进步，但网络应用和攻击策略的复杂性不断增加，仍带来重大风险。", "method": "研究采用OWASP ZAP、sqlmap和Nmap等工具，系统性地评估和修复PHP-MySQL网络应用中的SQLi漏洞。", "result": "研究发现输入消毒和预处理语句能有效降低SQLi风险，同时强调持续安全评估对应对新兴威胁的必要性。", "conclusion": "本研究通过真实案例提供了SQLi检测与预防的实用策略，为相关领域贡献了实践性见解。"}}
{"id": "2506.17652", "categories": ["math.CO", "05D40, 05B15, 05C15"], "pdf": "https://arxiv.org/pdf/2506.17652", "abs": "https://arxiv.org/abs/2506.17652", "authors": ["Tantan Dai", "Alexander Divoux", "Tom Kelly"], "title": "Entropy Bounds for Perfect Matchings in Bipartite Hypergraphs", "comment": "10 pages, 1 figure", "summary": "A hypergraph is \\textit{bipartite with bipartition} $(A, B)$ if every edge\nhas exactly one vertex in $A$, and a matching in such a hypergraph is\n\\textit{$A$-perfect} if it saturates every vertex in $A$. We prove an upper\nbound on the number of $A$-perfect matchings in uniform hypergraphs with small\nmaximum codegree. Using this result, we prove that there exist order-$n$ Latin\nsquares with at most $(n/e^{2.117})^n$ transversals when $n$ is odd and $n\n\\equiv 0\\pmod 3$. We also show that $k$-uniform $D$-regular hypergraphs on $n$\nvertices have at most $((1+o(1))q/e^k)^{Dn/k}$ proper $q$-edge-colorings when\n$q = (1+o(1))D$ and the maximum codegree is $o(q)$.", "AI": {"tldr": "该论文研究了均匀超图中A-完美匹配数量的上界，并应用于拉丁方和超图的边着色问题，得出了具体的数量限制。", "motivation": "研究超图中A-完美匹配的数量上界，以及其在拉丁方和超图边着色问题中的应用，旨在为组合数学中的相关问题提供理论支持。", "method": "通过证明均匀超图中A-完美匹配数量的上界，结合最大共度较小的条件，进一步应用于拉丁方的横截数和超图的边着色问题。", "result": "证明了当n为奇数且n≡0(mod3)时，存在阶数为n的拉丁方，其横截数不超过$(n/e^{2.117})^n$；同时，对于k-均匀D-正则超图，当q=(1+o(1))D且最大共度为o(q)时，其真q-边着色数不超过$((1+o(1))q/e^k)^{Dn/k}$。", "conclusion": "该研究为超图中的匹配问题、拉丁方的横截数以及超图的边着色问题提供了新的上界结果，扩展了组合数学的理论基础。"}}
{"id": "2506.18103", "categories": ["math.GM", "11B37 (Primary), 11B83, 11B75 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.18103", "abs": "https://arxiv.org/abs/2506.18103", "authors": ["Benoit Cloitre"], "title": "A study of a family of self-referential sequences", "comment": "17 pages, 3 figures", "summary": "We introduce and analyze a three-parameter family of self-referential integer\nsequences $S(x,y,z)$: starting from $a(1)=x$, each term advances by $y$ when\nthe index $k$ has already appeared as a value and by $z$ otherwise. This simple\nrule generates a surprising zoo of behaviors, many of which are catalogued --\nalbeit in a rather unstructured fashion -- in the OEIS. Whenever $y>z>0$, we\nprove that the density $a(k)/k$ converges to the positive root of $r^2 - z r -\n(y - z) = 0$. Two subfamilies, $S(x,Z+1,Z)$ and $S(x,Z,Z+1)$, yield explicit\nnon-homogeneous Beatty sequences, providing explicit formulas for numerous OEIS\nentries. For $y=0$ and $z \\ge 2$, the sequences eventually become periodic and\nsatisfy linear recurrences. Critical cases with a zero discriminant unveil\ngeometric patterns on triangular, square, and hexagonal lattices. Finally, via\ntree-like representations we uncover a tight link with meta-Fibonacci\nrecurrences.", "AI": {"tldr": "本文提出并分析了一个三参数自引用整数序列族$S(x,y,z)$，揭示了其多样行为模式，包括密度收敛性、非均匀Beatty序列生成、周期性规律及与元斐波那契递推的深刻联系。", "motivation": "针对OEIS中大量未分类的自引用序列行为，建立统一理论框架以解释其生成机制与数学特性。", "method": "通过定义递推规则$a(k)$（索引$k$已出现时步进$y$，否则步进$z$），结合代数方程求根、几何模式分析与树状表示法展开研究。", "result": "证明当$y>z>0$时序列密度收敛于方程$r^2 - z r - (y - z) = 0$的正根；发现两类子族可显式生成非均匀Beatty序列；零判别量情形揭示晶格几何模式；建立与元斐波那契递推的等价性。", "conclusion": "该序列族为理解OEIS中复杂自引用序列提供了系统性工具，其数学结构在数论、离散几何与递推理论中具有广泛意义。"}}
{"id": "2506.17684", "categories": ["math.NT", "Primary 11B99, Secondary 11A07"], "pdf": "https://arxiv.org/pdf/2506.17684", "abs": "https://arxiv.org/abs/2506.17684", "authors": ["Cristian Cobeli", "Alexandru Zaharescu", "Zhuo Zhang"], "title": "Pattern formation Statistics on Fermat Quotients", "comment": "18 pages, 4 tables, and 4 figures", "summary": "Despite their simple definition as $\\mathfrak{q}_p(b):=\\frac{b^{p-1}-1}{p}\n\\pmod p$, for $0\\le b \\le p^2-1$ and $\\gcd(b,p)=1$, and their regular\narrangement in a $p\\times(p-1)$ Fermat quotient matrix $\\mathtt{FQM}(p)$ of\nintegers from $[0,p-1]$, Fermat quotients modulo $p$ are well known for their\noverall lack of regularity. Here, we discuss this contrasting effect by proving\nthat, on the one hand, any line of the matrix behaves like an analogue of a\nrandomly distributed sequence of numbers, and on the other hand, the spatial\nstatistics of distances on regular $N$-patterns confirm the natural\nexpectations.", "AI": {"tldr": "研究费马商模$p$的随机性与规律性，证明矩阵行表现类似随机序列，而空间统计符合预期。", "motivation": "费马商模$p$定义为$\\mathfrak{q}_p(b):=\\frac{b^{p-1}-1}{p} \\pmod p$，虽然定义简单且排列规则，但整体缺乏规律性。研究旨在探讨这种矛盾现象。", "method": "通过分析$p\\times(p-1)$费马商矩阵$\\mathtt{FQM}(p)$，研究其行的随机分布特性及$N$-模式的空间统计。", "result": "证明矩阵的每一行表现类似随机序列，同时空间统计结果符合自然预期。", "conclusion": "费马商模$p$在局部表现出随机性，但在整体空间统计上仍遵循规律，揭示了其复杂的数学特性。"}}
{"id": "2506.17271", "categories": ["math.OC", "cs.DM", "cs.GT", "90-XX"], "pdf": "https://arxiv.org/pdf/2506.17271", "abs": "https://arxiv.org/abs/2506.17271", "authors": ["Antoine Lhomme", "Nicolas Catusse", "Nadia Brauner"], "title": "On the convergence of computational methods for the online bin stretching problem", "comment": null, "summary": "Online bin stretching is an online packing problem where some of the best\nknown lower and upper bounds were found through computational searches. The\nlimiting factor in obtaining better bounds with such methods is the\ncomputational time allowed. However, there is still no theoretical guarantee\nthat such methods do converge towards the optimal online performance. This\npaper shows that such methods do, in fact, converge; moreover, bounds on the\ngap to the optimal are also given. These results frame a theoretical foundation\nfor the convergence of computational approaches for online problems.", "AI": {"tldr": "本文证明了在线装箱问题中计算搜索方法的收敛性，并给出了与最优性能差距的理论界限。", "motivation": "在线装箱问题中，计算搜索方法虽能获得较好的上下界，但缺乏理论保证其收敛至最优性能。", "method": "通过理论分析，验证计算搜索方法的收敛性，并量化其与最优性能的差距。", "result": "证明了计算搜索方法确实收敛，并提供了与最优性能差距的理论界限。", "conclusion": "研究结果为在线问题的计算方法收敛性奠定了理论基础。"}}
{"id": "2506.17434", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17434", "abs": "https://arxiv.org/abs/2506.17434", "authors": ["Sydney Levine", "Matija Franklin", "Tan Zhi-Xuan", "Secil Yanik Guyot", "Lionel Wong", "Daniel Kilov", "Yejin Choi", "Joshua B. Tenenbaum", "Noah Goodman", "Seth Lazar", "Iason Gabriel"], "title": "Resource Rational Contractualism Should Guide AI Alignment", "comment": "24 pages, 10 figures", "summary": "AI systems will soon have to navigate human environments and make decisions\nthat affect people and other AI agents whose goals and values diverge.\nContractualist alignment proposes grounding those decisions in agreements that\ndiverse stakeholders would endorse under the right conditions, yet securing\nsuch agreement at scale remains costly and slow -- even for advanced AI. We\ntherefore propose Resource-Rational Contractualism (RRC): a framework where AI\nsystems approximate the agreements rational parties would form by drawing on a\ntoolbox of normatively-grounded, cognitively-inspired heuristics that trade\neffort for accuracy. An RRC-aligned agent would not only operate efficiently,\nbut also be equipped to dynamically adapt to and interpret the ever-changing\nhuman social world.", "AI": {"tldr": "提出资源理性契约主义（RRC）框架，使AI系统能通过认知启发式高效模拟多方利益协议，实现动态适应人类社会环境。", "motivation": "AI系统需在目标价值多元的人类环境中决策，现有契约主义方法达成大规模协议成本高、速度慢，亟需高效解决方案。", "method": "采用基于规范认知的启发式工具箱，在计算精度与资源消耗间权衡，近似模拟理性多方可能达成的协议条件。", "result": "RRC框架使AI既能保持运算效率，又能动态适应并解释不断变化的人类社会规则与价值观。", "conclusion": "资源理性契约主义为AI对齐问题提供了可扩展的实践路径，通过认知启发式平衡协议质量与计算成本。"}}
{"id": "2506.18215", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.18215", "abs": "https://arxiv.org/abs/2506.18215", "authors": ["Marco Avella-Medina", "Richard Davis", "Gennady Samorodnitsky"], "title": "Estimating quantile treatments without strict overlap", "comment": null, "summary": "We consider the problem of estimating quantile treatment effects without\nassuming strict overlap , i.e., we do not assume that the propensity score is\nbounded away from zero. More specifically, we consider an inverse probability\nweighting (IPW) approach for estimating quantiles in the potential outcomes\nframework and pay special attention to scenarios where the propensity scores\ncan tend to zero as a regularly varying function. Our approach effectively\nconsiders a heavy-tailed objective function for estimating the quantile\nprocess. We introduce a truncated IPW estimator that is shown to outperform the\nstandard quantile IPW estimator when strict overlap does not hold. We show that\nthe limiting distribution of the estimated quantile process follows a stable\ndistribution and converges at the rate $n^{1-1/\\gamma}$, where $\\gamma>1$ is\nthe tail index of the propensity scores when they tend to zero. We illustrate\nthe performance of our estimators in numerical experiments and in a dataset\nthat exhibits the presence of extreme propensity scores.", "AI": {"tldr": "本文提出了一种在不假设严格重叠条件下估计分位数处理效应的新方法，通过改进的逆概率加权（IPW）估计器处理倾向得分趋近于零的情况，并证明了其优于标准分位数IPW估计器。", "motivation": "研究动机在于解决倾向得分可能趋近于零（即不满足严格重叠假设）时，传统分位数处理效应估计方法的局限性。", "method": "方法上采用了一种截断的逆概率加权（IPW）估计器，特别关注倾向得分作为规则变化函数趋近于零的情况，并构建了重尾目标函数来估计分位数过程。", "result": "结果表明，估计的分位数过程的极限分布服从稳定分布，收敛速率为$n^{1-1/\\gamma}$，其中$\\gamma>1$为倾向得分趋近于零时的尾部指数。数值实验和实际数据集验证了该估计器的优越性。", "conclusion": "结论指出，所提出的截断IPW估计器在倾向得分不满足严格重叠条件时表现更优，为处理极端倾向得分情况下的分位数估计提供了有效工具。"}}
{"id": "2506.17266", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17266", "abs": "https://arxiv.org/abs/2506.17266", "authors": ["Sunil Kumar Jang Bahadur", "Gopala Dhar"], "title": "Securing Generative AI Agentic Workflows: Risks, Mitigation, and a Proposed Firewall Architecture", "comment": "Proposed workflow", "summary": "Generative Artificial Intelligence (GenAI) presents significant advancements\nbut also introduces novel security challenges, particularly within agentic\nworkflows where AI agents operate autonomously. These risks escalate in\nmulti-agent systems due to increased interaction complexity. This paper\noutlines critical security vulnerabilities inherent in GenAI agentic workflows,\nincluding data privacy breaches, model manipulation, and issues related to\nagent autonomy and system integration. It discusses key mitigation strategies\nsuch as data encryption, access control, prompt engineering, model monitoring,\nagent sandboxing, and security audits. Furthermore, it details a proposed\n\"GenAI Security Firewall\" architecture designed to provide comprehensive,\nadaptable, and efficient protection for these systems by integrating various\nsecurity services and leveraging GenAI itself for enhanced defense. Addressing\nthese security concerns is paramount for the responsible and safe deployment of\nthis transformative technology.", "AI": {"tldr": "生成式人工智能（GenAI）在带来重大进步的同时，也引入了新的安全挑战，特别是在自主运行的智能体工作流中。本文概述了GenAI工作流中的关键安全漏洞，并提出了包括数据加密、访问控制等在内的缓解策略，以及一个名为“GenAI安全防火墙”的综合防护架构。", "motivation": "随着生成式人工智能（GenAI）在多智能体系统中的广泛应用，其自主性和交互复杂性带来了数据隐私泄露、模型操纵等新型安全风险，亟需有效的安全防护措施以确保技术的安全部署。", "method": "本文提出了一种名为“GenAI安全防火墙”的架构，通过整合数据加密、访问控制、提示工程、模型监控、智能体沙盒化和安全审计等多种安全服务，并利用GenAI自身能力增强防御，为系统提供全面、灵活且高效的防护。", "result": "提出的“GenAI安全防火墙”能够有效应对GenAI工作流中的数据隐私、模型操纵和智能体自主性等安全漏洞，为多智能体系统的安全运行提供了可行的解决方案。", "conclusion": "解决GenAI工作流中的安全问题是确保这一变革性技术负责任且安全部署的关键。通过综合防护架构和多种安全策略的结合，可以显著降低GenAI系统的安全风险。"}}
{"id": "2506.17659", "categories": ["math.CO", "math.SP"], "pdf": "https://arxiv.org/pdf/2506.17659", "abs": "https://arxiv.org/abs/2506.17659", "authors": ["Lies Beers", "Raffaella Mulas"], "title": "Coloring outside the lines: Spectral bounds for generalized hypergraph colorings", "comment": null, "summary": "It is known that, for an oriented hypergraph with (vertex) coloring number\n$\\chi$ and smallest and largest normalized Laplacian eigenvalues $\\lambda_1$\nand $\\lambda_N$, respectively, the inequality $\\chi\\geq\n(\\lambda_N-\\lambda_1)/\\min\\{\\lambda_N-1,1-\\lambda_1\\}$ holds. We provide\nnecessary conditions for oriented hypergraphs for which this bound is tight.\nFocusing on $c$-uniform unoriented hypergraphs, we then generalize the bound to\nthe setting of \\emph{$d$-proper colorings}: colorings in which no edge contains\nmore than $d$ vertices of the same color. We also adapt our proof techniques to\nderive analogous spectral bounds for \\emph{$d$-improper colorings} of graphs\nand for edge colorings of hypergraphs. Moreover, for all coloring notions\nconsidered, we provide necessary conditions under which the bound is an\nequality.", "AI": {"tldr": "该论文研究了定向超图的染色数与其归一化拉普拉斯特征值之间的关系，给出了紧界的必要条件，并将结果推广到$d$-proper着色、$d$-improper着色以及超图的边着色。", "motivation": "研究定向超图的染色数与其归一化拉普拉斯特征值之间的不等式关系，并探讨该不等式紧界的条件，进一步推广到其他着色问题。", "method": "通过分析定向超图的归一化拉普拉斯特征值$\\lambda_1$和$\\lambda_N$，推导染色数$\\chi$的下界，并研究紧界的必要条件。随后将方法推广到$d$-proper着色、$d$-improper着色和超图边着色。", "result": "证明了定向超图的染色数满足$\\chi\\geq (\\lambda_N-\\lambda_1)/\\min\\{\\lambda_N-1,1-\\lambda_1\\}$，并给出了紧界的必要条件。进一步推广到$d$-proper着色、$d$-improper着色和超图边着色，并给出了类似的光谱界限。", "conclusion": "该研究为定向超图及其他着色问题提供了光谱界限，并明确了紧界的条件，为相关领域的进一步研究奠定了基础。"}}
{"id": "2506.17753", "categories": ["math.NT", "Primary 11F72, Secondary 37C35, 37D40"], "pdf": "https://arxiv.org/pdf/2506.17753", "abs": "https://arxiv.org/abs/2506.17753", "authors": ["Christos Katsivelos"], "title": "The hyperbolic lattice counting problem in large dimensions", "comment": "19 pages", "summary": "For $n\\geq 3$ and $\\Gamma$ a cocompact lattice acting on the hyperbolic space\n$\\mathbb{H}^n$, we investigate the average behaviour of the error term in the\ncircle problem. First, we explore the local average of the error term over\ncompact sets of $\\Gamma\\backslash\\mathbb{H}^n$. Our upper bound depends on the\nquantum variance and the spectral exponential sums appearing in the study of\nthe Prime geodesic theorem. We also prove $\\Omega$-results for the mean value\nand the second moment of the error term.", "AI": {"tldr": "研究双曲空间$\\mathbb{H}^n$上余紧格点$\\Gamma$作用下的圆问题误差项的局部平均行为，给出上界并证明均值及二阶矩的$\\Omega$结果。", "motivation": "探讨双曲空间上格点作用下的圆问题误差项的平均行为，以深化对几何与谱理论联系的理解。", "method": "通过量子方差和谱指数和在素数测地线定理中的应用，分析误差项的局部平均。", "result": "证明了误差项局部平均的上界依赖量子方差与谱指数和，并得到均值及二阶矩的$\\Omega$结果。", "conclusion": "该研究为双曲空间上圆问题误差项的平均行为提供了新的理论工具和结果，拓展了相关领域的认知。"}}
{"id": "2506.17442", "categories": ["cs.AI", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17442", "abs": "https://arxiv.org/abs/2506.17442", "authors": ["Hao Guan", "David Bates", "Li Zhou"], "title": "Keeping Medical AI Healthy: A Review of Detection and Correction Methods for System Degradation", "comment": "15 pages, 5 figures", "summary": "Artificial intelligence (AI) is increasingly integrated into modern\nhealthcare, offering powerful support for clinical decision-making. However, in\nreal-world settings, AI systems may experience performance degradation over\ntime, due to factors such as shifting data distributions, changes in patient\ncharacteristics, evolving clinical protocols, and variations in data quality.\nThese factors can compromise model reliability, posing safety concerns and\nincreasing the likelihood of inaccurate predictions or adverse outcomes. This\nreview presents a forward-looking perspective on monitoring and maintaining the\n\"health\" of AI systems in healthcare. We highlight the urgent need for\ncontinuous performance monitoring, early degradation detection, and effective\nself-correction mechanisms. The paper begins by reviewing common causes of\nperformance degradation at both data and model levels. We then summarize key\ntechniques for detecting data and model drift, followed by an in-depth look at\nroot cause analysis. Correction strategies are further reviewed, ranging from\nmodel retraining to test-time adaptation. Our survey spans both traditional\nmachine learning models and state-of-the-art large language models (LLMs),\noffering insights into their strengths and limitations. Finally, we discuss\nongoing technical challenges and propose future research directions. This work\naims to guide the development of reliable, robust medical AI systems capable of\nsustaining safe, long-term deployment in dynamic clinical settings.", "AI": {"tldr": "本文综述了医疗AI系统在长期部署中性能退化的原因、监测方法及修正策略，旨在提升AI在动态临床环境中的可靠性和鲁棒性。", "motivation": "医疗AI系统在现实应用中可能因数据分布变化、患者特征改变、临床协议更新或数据质量波动导致性能下降，引发安全隐患，亟需建立持续监测与自我修正机制。", "method": "系统回顾了数据与模型层面性能退化的成因，归纳了数据漂移和模型漂移的检测技术，分析了根本原因，并总结了从模型重训练到测试时适应的修正策略。", "result": "研究覆盖传统机器学习模型和最先进的大语言模型(LLMs)，揭示了各类技术在医疗AI系统中的优势与局限性，并提出了持续监测框架的实施路径。", "conclusion": "该工作为开发可长期安全部署的医疗AI系统提供了技术指导，同时指出了动态临床环境中模型可靠性维护的未来研究方向。"}}
{"id": "2506.17269", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17269", "abs": "https://arxiv.org/abs/2506.17269", "authors": ["Paritosh Ranjan", "Surajit Majumder", "Prodip Roy"], "title": "Digital Privacy Everywhere", "comment": "18 pages, 10 figures", "summary": "The increasing proliferation of digital and mobile devices equipped with\ncameras, microphones, GPS, and other privacy invasive components has raised\nsignificant concerns for businesses operating in sensitive or policy restricted\nenvironments. Current solutions rely on passive enforcement, such as signage or\nverbal instructions, which are largely ineffective. This paper presents Digital\nPrivacy Everywhere (DPE), a comprehensive and scalable system designed to\nactively enforce custom privacy policies for digital devices within predefined\nphysical boundaries. The DPE architecture includes a centralized management\nconsole, field verification units (FVUs), enforcement modules for mobile\ndevices (EMMDs), and an External Geo Ownership Service (EGOS). These components\ncollaboratively detect, configure, and enforce privacy settings such as\ndisabling cameras, microphones, or radios across various premises like\ntheaters, hospitals, financial institutions, and educational facilities. The\nsystem ensures privacy compliance in real time while maintaining a seamless\nuser experience and operational scalability across geographies.", "AI": {"tldr": "本文提出了一种名为'数字隐私无处不在'(DPE)的系统，旨在主动执行定制隐私政策，保护敏感环境中的数字设备隐私。", "motivation": "随着配备摄像头、麦克风等隐私侵入组件的数字设备激增，传统被动管理方式（如标识或口头指令）效果有限，亟需主动解决方案。", "method": "DPE系统包含中央管理控制台、现场验证单元(FVU)、移动设备执行模块(EMMD)和外部地理所有权服务(EGOS)，协同检测并强制执行摄像头/麦克风禁用等隐私设置。", "result": "该系统能在剧院、医院等场所实时保障隐私合规性，同时保持用户体验流畅，并支持跨地域的运营扩展。", "conclusion": "DPE为敏感环境提供了一套可扩展的主动隐私保护框架，有效弥补了现有被动管理方式的不足。"}}
{"id": "2506.17706", "categories": ["math.CO", "math.QA", "05E05, 20C08, 17B37"], "pdf": "https://arxiv.org/pdf/2506.17706", "abs": "https://arxiv.org/abs/2506.17706", "authors": ["Mikhail Zaitsev"], "title": "Quantum $\\mathfrak{gl}$-weight system and its average values", "comment": null, "summary": "We present a proof of a recent conjecture due to M. Kazarian, E. Krasilnikov,\nS. Lando, and M. Shapiro, which describes the average value of the universal\n$\\mathfrak{gl}$-weight system on permutations. The proof uses a quantum\nanalogue of the $\\mathfrak{gl}$-weight system on Hecke algebras of type $A$,\nwhich leads to a one-parameter deformation of the average value of the\nuniversal ${\\mathfrak{gl}}$-weight system. We show that the average value of\nthe quantum weight system is a linear combination of one-part Schur functions,\nwith coefficients being $q$-analogues of Bernoulli polynomials.", "AI": {"tldr": "本文证明了Kazarian等人提出的关于$\\mathfrak{gl}$-权系统在置换上平均值的猜想，通过量子类比方法得到了一参数变形，并表明该量子权系统的平均值是单部分Schur函数的线性组合。", "motivation": "研究动机源于验证Kazarian等人提出的$\\mathfrak{gl}$-权系统平均值的猜想，探索其在量子框架下的推广形式。", "method": "采用$A$型Hecke代数上的量子$\\mathfrak{gl}$-权系统类比方法，构造了一参数变形的平均权系统。", "result": "证明了量子权系统的平均值可表示为单部分Schur函数的线性组合，其系数为Bernoulli多项式的$q$-模拟。", "conclusion": "该工作不仅证实了原始猜想，还通过量子变形拓展了理论框架，揭示了$\\mathfrak{gl}$-权系统与Schur函数之间的深层联系。"}}
{"id": "2506.18065", "categories": ["math.NT", "11N32 (11N37, 11D57, 11G35)"], "pdf": "https://arxiv.org/pdf/2506.18065", "abs": "https://arxiv.org/abs/2506.18065", "authors": ["Yijie Diao"], "title": "Liouville function, von Mangoldt function and norm forms at random binary forms", "comment": "39 pages", "summary": "We analyze the average behavior of various arithmetic functions at the values\nof degree $d$ binary forms ordered by height, with probability $1$. This\napproach yields averaged versions of the Chowla conjecture and the Bateman-Horn\nconjecture for random binary forms. Furthermore, we show that the rational\nHasse principle holds for almost all Ch\\^atelet varieties defined by a fixed\nnorm form of degree $e$ and by varying binary forms of fixed degree $d$,\nprovided $e$ divides $d$. This proves an average version of a conjecture of\nColliot-Th\\'el\\`ene.", "AI": {"tldr": "本文研究了二元形式算术函数的平均行为，验证了Chowla猜想和Bateman-Horn猜想的平均版本，并证明了Colliot-Th\\'el\\`ene猜想在特定条件下的平均成立性。", "motivation": "探讨二元形式算术函数的平均行为，为Chowla猜想、Bateman-Horn猜想以及Colliot-Th\\'el\\`ene猜想提供概率为1的平均版本验证。", "method": "通过分析高度排序的$d$次二元形式的算术函数平均值，结合概率为1的极限行为研究方法。", "result": "证明了Chowla猜想和Bateman-Horn猜想在随机二元形式下的平均成立性，并验证了当$e$整除$d$时，几乎所有的Ch\\^atelet簇满足有理Hasse原理。", "conclusion": "该研究为相关数论猜想提供了平均意义上的支持，扩展了对二元形式算术性质的理解，并部分解决了Colliot-Th\\'el\\`ene猜想。"}}
{"id": "2506.17449", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17449", "abs": "https://arxiv.org/abs/2506.17449", "authors": ["Manasa Bharadwaj", "Nikhil Verma", "Kevin Ferreira"], "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "comment": null, "summary": "Efforts to improve Large Language Model (LLM) agent performance on complex\ntasks have largely focused on fine-tuning and iterative self-correction.\nHowever, these approaches often lack generalizable mechanisms for longterm\nlearning and remain inefficient in dynamic environments. We introduce\nOmniReflect, a hierarchical, reflection-driven framework that constructs a\nconstitution, a compact set of guiding principles distilled from task\nexperiences, to enhance the effectiveness and efficiency of an LLM agent.\nOmniReflect operates in two modes: Self-sustaining, where a single agent\nperiodically curates its own reflections during task execution, and\nCo-operative, where a Meta-advisor derives a constitution from a small\ncalibration set to guide another agent. To construct these constitutional\nprinciples, we employ Neural, Symbolic, and NeuroSymbolic techniques, offering\na balance between contextual adaptability and computational efficiency.\nEmpirical results averaged across models show major improvements in task\nsuccess, with absolute gains of +10.3% on ALFWorld, +23.8% on BabyAI, and +8.3%\non PDDL in the Self-sustaining mode. Similar gains are seen in the Co-operative\nmode, where a lightweight Qwen3-4B ReAct agent outperforms all Reflexion\nbaselines on BabyAI. These findings highlight the robustness and effectiveness\nof OmniReflect across environments and backbones.", "AI": {"tldr": "本文提出OmniReflect框架，通过构建指导原则提升LLM代理性能，在自持与合作模式下均显著提升任务成功率。", "motivation": "现有方法缺乏长期学习机制且在动态环境中效率低下，需一种通用框架来增强LLM代理的效能。", "method": "采用分层反思驱动框架，结合神经、符号及神经符号技术，构建紧凑指导原则（宪法），支持自持（单代理自我反思）与合作（元顾问指导）两种模式。", "result": "实验显示任务成功率显著提升：自持模式下ALFWorld(+10.3%)、BabyAI(+23.8%)、PDDL(+8.3%)；合作模式下轻量级Qwen3-4B代理超越所有基线。", "conclusion": "OmniReflect在不同环境和模型骨干中均表现出强鲁棒性与有效性，为LLM代理学习提供了通用解决方案。"}}
{"id": "2506.17260", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17260", "abs": "https://arxiv.org/abs/2506.17260", "authors": ["Chunfeng Cui", "Liqun Qi", "Yi Xu"], "title": "Sum-of-Squares Biquadratic Polynomials", "comment": null, "summary": "Hilbert indicated that a positive semi-definite (psd) homogeneous quartic\npolynomial of four variables may not be sum of squares (sos). A $2 \\times 2$\nbiquadratic polynomial is a homogeneous quartic polynomial of four variables.\nIs a psd $2 \\times 2$ biquadratic polynomial sos? In this paper, we present a\nnecessary and sufficient condition for a $2 \\times 2$ psd biquadratic\npolynomial to be sos. We show that if a $2 \\times 2$ sos biquadratic polynomial\nis sos, then it is sos of tetranomials, its sos rank is at most $4$, and the\ncoefficients of the tetranomials can be orthogonal to each other. We show that\na $2 \\times 2$ psd biquadratic polynomial with one half-cross term or without\nhalf-cross terms is always sos of binomials (sosb). Sufficient conditions for\n$2 \\times 2$ psd biquadratic polynomials with two half-cross terms to be sosb\nare presented. We also present a case in which the psd biquadratic polynomials\nare sos of trinomials (sostri).", "AI": {"tldr": "本文研究了2×2双二次正半定多项式是否为平方和(sos)的问题，给出了充要条件，并证明了其sos秩不超过4，且系数可正交。", "motivation": "Hilbert指出四变量正半定齐次四次多项式可能不是平方和(sos)。本文探讨2×2双二次多项式是否满足sos性质。", "method": "通过分析双二次多项式的结构，提出了判断其是否为sos的充要条件，并研究了不同交叉项情况下的sos分解形式。", "result": "证明了2×2 sos双二次多项式可分解为四项式，sos秩≤4；无交叉项或单一交叉项时总可分解为二项式(sosb)；给出了双交叉项时为sosb的充分条件。", "conclusion": "本文系统解决了2×2双二次正半定多项式的sos问题，为相关领域提供了重要的理论工具和分析方法。"}}
{"id": "2506.17279", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17279", "abs": "https://arxiv.org/abs/2506.17279", "authors": ["Yash Sinha", "Manit Baser", "Murari Mandal", "Dinil Mon Divakaran", "Mohan Kankanhalli"], "title": "Step-by-Step Reasoning Attack: Revealing 'Erased' Knowledge in Large Language Models", "comment": null, "summary": "Knowledge erasure in large language models (LLMs) is important for ensuring\ncompliance with data and AI regulations, safeguarding user privacy, mitigating\nbias, and misinformation. Existing unlearning methods aim to make the process\nof knowledge erasure more efficient and effective by removing specific\nknowledge while preserving overall model performance, especially for retained\ninformation. However, it has been observed that the unlearning techniques tend\nto suppress and leave the knowledge beneath the surface, thus making it\nretrievable with the right prompts. In this work, we demonstrate that\n\\textit{step-by-step reasoning} can serve as a backdoor to recover this hidden\ninformation. We introduce a step-by-step reasoning-based black-box attack,\nSleek, that systematically exposes unlearning failures. We employ a structured\nattack framework with three core components: (1) an adversarial prompt\ngeneration strategy leveraging step-by-step reasoning built from LLM-generated\nqueries, (2) an attack mechanism that successfully recalls erased content, and\nexposes unfair suppression of knowledge intended for retention and (3) a\ncategorization of prompts as direct, indirect, and implied, to identify which\nquery types most effectively exploit unlearning weaknesses. Through extensive\nevaluations on four state-of-the-art unlearning techniques and two widely used\nLLMs, we show that existing approaches fail to ensure reliable knowledge\nremoval. Of the generated adversarial prompts, 62.5% successfully retrieved\nforgotten Harry Potter facts from WHP-unlearned Llama, while 50% exposed unfair\nsuppression of retained knowledge. Our work highlights the persistent risks of\ninformation leakage, emphasizing the need for more robust unlearning strategies\nfor erasure.", "AI": {"tldr": "本文提出了一种基于逐步推理的黑盒攻击方法Sleek，用于揭示大语言模型(LLM)知识擦除中的隐藏信息泄露问题。实验表明现有遗忘技术无法可靠移除知识，62.5%的攻击提示能成功恢复被删除的《哈利波特》知识。", "motivation": "大语言模型的知识擦除对合规性、隐私保护和偏见消除至关重要。现有遗忘技术仅表面抑制知识，未能真正擦除，导致信息仍可通过特定提示恢复。", "method": "提出Sleek攻击框架：1) 利用LLM生成查询构建逐步推理的对抗提示策略 2) 开发能召回已擦除内容并暴露知识不公平抑制的机制 3) 将提示分类为直接/间接/隐含三类以识别最有效的攻击类型。", "result": "在四种先进遗忘技术和两种主流LLM上的测试显示：62.5%对抗提示成功恢复WHP-遗忘Llama模型中的《哈利波特》知识，50%案例暴露了对保留知识的不公平抑制。", "conclusion": "研究揭示了当前知识擦除技术存在持续的信息泄露风险，强调需要开发更鲁棒的遗忘策略来实现真正的知识擦除。逐步推理可成为检测擦除效果的有效工具。"}}
{"id": "2506.17777", "categories": ["math.CO", "cs.CG", "52C10"], "pdf": "https://arxiv.org/pdf/2506.17777", "abs": "https://arxiv.org/abs/2506.17777", "authors": ["Noga Alon", "Shakhar Smorodinsky"], "title": "Extended VC-dimension, and Radon and Tverberg type theorems for unions of convex sets", "comment": null, "summary": "We define and study an extension of the notion of the VC-dimension of a\nhypergraph and apply it to establish a Tverberg type theorem for unions of\nconvex sets. We also prove a new Radon type theorem for unions of convex sets,\n  vastly improving the estimates in an earlier result of B\\'ar\\'any and Kalai.", "AI": {"tldr": "本文扩展了超图的VC维概念，并应用于证明凸集并集的Tverberg型定理，同时改进了B\\'ar\\'any和Kalai早期结果的Radon型定理估计。", "motivation": "研究凸集并集的组合性质，扩展VC维概念以解决相关问题，改进现有理论中的估计。", "method": "定义并研究超图VC维的扩展，应用该扩展证明凸集并集的Tverberg型定理，并推导新的Radon型定理。", "result": "建立了凸集并集的Tverberg型定理，显著改进了B\\'ar\\'any和Kalai的Radon型定理估计。", "conclusion": "扩展的VC维概念为凸集并集的研究提供了新工具，改进了相关定理的估计，推动了组合几何的发展。"}}
{"id": "2506.18236", "categories": ["math.NT", "11F55, 11F60, 11F70"], "pdf": "https://arxiv.org/pdf/2506.18236", "abs": "https://arxiv.org/abs/2506.18236", "authors": ["Nobuki Takeda"], "title": "Differential operators on Hermitian modular forms on $\\mathrm{u}(n, n)$", "comment": null, "summary": "We construct explicit differential operators on hermitian modular forms,\nextending methods developed for Siegel modular forms. These differential\noperators are closely related to the two-variable spherical pluriharmonic\npolynomials. We construct explicit bases for the space of such polynomials and\nuse them to build concrete operators. As an application, we derive an exact\npullback formula for hermitian Eisenstein series.", "AI": {"tldr": "本文构建了Hermite模形式上的显式微分算子，扩展了Siegel模形式的方法，并应用于推导Hermite Eisenstein级数的精确拉回公式。", "motivation": "研究Hermite模形式上的微分算子，旨在扩展Siegel模形式的方法，并探索其与双变量球面多调和多项式的关系。", "method": "通过构造双变量球面多调和多项式的显式基，并利用这些基构建具体的微分算子。", "result": "成功构建了Hermite模形式上的显式微分算子，并推导了Hermite Eisenstein级数的精确拉回公式。", "conclusion": "该方法不仅扩展了Siegel模形式的技术，还为Hermite模形式的研究提供了新的工具和应用。"}}
{"id": "2506.17484", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17484", "abs": "https://arxiv.org/abs/2506.17484", "authors": ["Yao Zhang", "Zaixi Shang", "Silpan Patel", "Mikel Zuniga"], "title": "From Unstructured Communication to Intelligent RAG: Multi-Agent Automation for Supply Chain Knowledge Bases", "comment": "Accepted In Proceedings of the 1st Workshop on AI for Supply Chain:\n  Today and Future @ 31st ACM SIGKDD Conference on Knowledge Discovery and Data\n  Mining V.2 (KDD 25), August 3, 2025, Toronto, ON, Canada. ACM, New York, NY,\n  USA, 14 pages, 2 figures", "summary": "Supply chain operations generate vast amounts of operational data; however,\ncritical knowledge such as system usage practices, troubleshooting workflows,\nand resolution techniques often remains buried within unstructured\ncommunications like support tickets, emails, and chat logs. While RAG systems\naim to leverage such communications as a knowledge base, their effectiveness is\nlimited by raw data challenges: support tickets are typically noisy,\ninconsistent, and incomplete, making direct retrieval suboptimal. Unlike\nexisting RAG approaches that focus on runtime optimization, we introduce a\nnovel offline-first methodology that transforms these communications into a\nstructured knowledge base. Our key innovation is a LLMs-based multi-agent\nsystem orchestrating three specialized agents: Category Discovery for taxonomy\ncreation, Categorization for ticket grouping, and Knowledge Synthesis for\narticle generation. Applying our methodology to real-world support tickets with\nresolution notes and comments, our system creates a compact knowledge base -\nreducing total volume to just 3.4% of original ticket data while improving\nquality. Experiments demonstrate that our prebuilt knowledge base in RAG\nsystems significantly outperforms traditional RAG implementations (48.74% vs.\n38.60% helpful answers) and achieves a 77.4% reduction in unhelpful responses.\nBy automating institutional knowledge capture that typically remains siloed in\nexperts' heads, our solution translates to substantial operational efficiency:\nreducing support workload, accelerating resolution times, and creating\nself-improving systems that automatically resolve approximately 50% of future\nsupply chain tickets. Our approach addresses a key gap in knowledge management\nby transforming transient communications into structured, reusable knowledge\nthrough intelligent offline processing rather than latency-inducing runtime\narchitectures.", "AI": {"tldr": "本文提出了一种基于LLMs的多智能体系统，将供应链支持票据等非结构化通信转化为结构化知识库，显著提升RAG系统性能并降低运营工作量。", "motivation": "供应链运营产生大量非结构化通信数据（如支持票据、邮件等），现有RAG系统因数据噪声大、不完整而效果受限，亟需将隐性知识转化为结构化知识库。", "method": "采用离线优先方法，设计包含分类发现、票据归类、知识合成三个智能体的LLMs多智能体系统，自动构建紧凑知识库（仅为原始数据量的3.4%）。", "result": "实验表明：预建知识库使RAG系统有用回答率提升至48.74%（传统方法38.6%），无效响应减少77.4%，未来50%票据可自动解决。", "conclusion": "该方法通过离线智能处理将瞬时通信转化为可重用知识，显著提升运营效率（减少支持负载、加速问题解决），填补了知识管理领域的关键空白。"}}
{"id": "2506.17270", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17270", "abs": "https://arxiv.org/abs/2506.17270", "authors": ["Janine Strotherm", "Julian Rolfes", "Barbara Hammer"], "title": "Existence and Uniqueness of Physically Correct Hydraulic States in Water Distribution Systems -- A theoretical analysis on the solvability of non-linear systems of equations in the context of water distribution systems", "comment": null, "summary": "Planning and extension of water distribution systems (WDSs) plays a key role\nin the development of smart cities, driven by challenges such as urbanization\nand climate change. In this context, the correct estimation of physically\ncorrect hydraulic states, i.e., pressure heads, water demands and water flows,\nis of high interest. Hydraulic emulators such as EPANET or more recently,\nphysic-informed surrogate models are used to solve this task. They require a\nsubset of observed states, such as heads at reservoirs and water demands, as\ninputs to estimate the whole hydraulic state. In order to obtain reliable\nresults of such emulators, but also to be able to give theoretical guarantees\nof their estimations, an important question is whether theoretically, the\nsubset of observed states that the emulator requires as an input suffices to\nderive the whole state, purely based on the physical properties, also called\nhydraulic principles, it obeys. This questions translates to solving linear and\nnon-linear systems of equations. Previous articles investigate on the existence\nquestion under the term observability analysis, however, they rely on the\napproximation of the non-linear principles using Taylor approximation and on\nnetwork-dependent numerical or algebraic algorithms. In this work, we provide\npurely theoretical guarantees on the existence and uniqueness of solutions to\nthe non-linear hydraulic principles, and by this, the existence and uniqueness\nof physically correct states, given common subsets of them -- a result that\nseems to be common-sense in the water community but has never been rigorously\nproven. We show that previous existence results are special cases of our more\ngeneral findings, and therefore lay the foundation for further analysis and\ntheoretical guarantees of the before-mentioned hydraulic emulators.", "AI": {"tldr": "本文为水分配系统（WDSs）中非线性水力原理解的存在性与唯一性提供了理论保证，填补了该领域长期缺乏严格数学证明的空白。", "motivation": "城市化与气候变化推动智慧城市发展，准确估算水分配系统的水力状态（如水压、需水量、水流）至关重要。现有水力模拟器依赖观测状态子集进行估算，但缺乏对输入数据是否足以推导完整状态的理论验证。", "method": "通过严格数学分析（无需泰勒近似或网络相关算法），研究非线性水力原理方程组的解存在性与唯一性，并验证常见观测子集的充分性。", "result": "证明了在常见观测子集下，非线性水力原理存在唯一物理合理解，且前人研究结果为本结论的特例。该理论为水力模拟器的可靠性提供了基础保障。", "conclusion": "首次严格论证了水分配系统水力状态估算的理论可行性，为后续模拟器分析与理论验证奠定基础，解决了行业共识但未证明的关键问题。"}}
{"id": "2506.17292", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17292", "abs": "https://arxiv.org/abs/2506.17292", "authors": ["Quan Nguyen", "Minh N. Vu", "Truc Nguyen", "My T. Thai"], "title": "Theoretically Unmasking Inference Attacks Against LDP-Protected Clients in Federated Vision Models", "comment": "Accepted to ICML 2025", "summary": "Federated Learning enables collaborative learning among clients via a\ncoordinating server while avoiding direct data sharing, offering a perceived\nsolution to preserve privacy. However, recent studies on Membership Inference\nAttacks (MIAs) have challenged this notion, showing high success rates against\nunprotected training data. While local differential privacy (LDP) is widely\nregarded as a gold standard for privacy protection in data analysis, most\nstudies on MIAs either neglect LDP or fail to provide theoretical guarantees\nfor attack success rates against LDP-protected data. To address this gap, we\nderive theoretical lower bounds for the success rates of low-polynomial time\nMIAs that exploit vulnerabilities in fully connected or self-attention layers.\nWe establish that even when data are protected by LDP, privacy risks persist,\ndepending on the privacy budget. Practical evaluations on federated vision\nmodels confirm considerable privacy risks, revealing that the noise required to\nmitigate these attacks significantly degrades models' utility.", "AI": {"tldr": "联邦学习虽通过服务器协调避免直接数据共享以保护隐私，但成员推理攻击(MIA)仍能高成功率攻击未保护数据。研究证明即使采用本地差分隐私(LDP)，隐私风险仍存在，且抑制攻击所需噪声会显著降低模型效用。", "motivation": "现有研究多忽视LDP或缺乏对LDP保护数据下MIA成功率的理论保证，需填补这一空白以揭示真实隐私风险。", "method": "推导了针对全连接层或自注意力层的低多项式时间MIA成功率的理论下界，并通过联邦视觉模型进行实践验证。", "result": "实验表明LDP保护下隐私风险仍显著存在，且抵御攻击所需噪声会严重损害模型性能。", "conclusion": "仅依赖LDP无法完全消除联邦学习中的隐私泄露风险，需在隐私预算与模型效用间谨慎权衡。"}}
{"id": "2506.17804", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.17804", "abs": "https://arxiv.org/abs/2506.17804", "authors": ["Kada Williams"], "title": "Greedy Gossiping", "comment": null, "summary": "The renowned Gossiping Problem (1971) asks the following. There are $n$\npeople who each know an item of gossip. In a telephone call, two people share\nall the gossip they know. How many calls are needed for all of them to be\ninformed of all the gossip? If $n\\ge 4$, the answer is $2n-4$.\n  We initiate and solve the related Greedy Gossiping Problem: given a fixed\nnumber $m<2n-4$ of calls, at most how much gossip can be known altogether? If\nevery call increases the total knowledge of gossip as much as possible, the sum\nreaches $n^2$ only when $m=2n-3$. Our main result is that surprisingly, for\neach $m<2n-4$, this calling strategy is optimal.", "AI": {"tldr": "本文研究了贪婪八卦问题，探讨在有限通话次数$m<2n-4$下，如何最大化总八卦知识量，并证明贪婪策略在$m<2n-4$时最优。", "motivation": "经典八卦问题(1971)已解决$n\\ge 4$时需$2n-4$次通话使所有人获知所有八卦。本文研究其变体：给定有限通话次数$m<2n-4$，如何最大化总八卦知识量。", "method": "采用贪婪策略：每次通话选择能使总八卦知识量增加最多的两人进行通话。通过理论分析验证该策略在$m<2n-4$时的最优性。", "result": "主要发现：当$m=2n-3$时总知识量可达$n^2$；但更关键的是，对于所有$m<2n-4$的情况，贪婪策略都能达到最大可能的总知识量。", "conclusion": "研究证明贪婪通话策略在$m<2n-4$时具有最优性，这一反直觉的结果为有限通信条件下的信息传播优化提供了理论保证。"}}
{"id": "2506.18287", "categories": ["math.NT", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.18287", "abs": "https://arxiv.org/abs/2506.18287", "authors": ["Chen Wang", "Sheng-Jie Wang"], "title": "On a conjectural supercongruence involving the dual sequence $s_n(x)$", "comment": "16 pages", "summary": "In 2017, motivated by a supercongruence conjectured by Kimoto and Wakayama\nand confirmed by Long, Osburn and Swisher, Z.-W. Sun introduced the sequence of\npolynomials: $$\ns_n(x)=\\sum_{k=0}^n\\binom{n}{k}\\binom{x}{k}\\binom{x+k}{k}=\\sum_{k=0}^n\\binom{n}{k}(-1)^k\\binom{x}{k}\\binom{-1-x}{k}\n$$ and investigated its congruence properties. In particular, Z.-W. Sun\nconjectured that for any prime $p>3$ and $p$-adic integer $x\\neq-1/2$ one has\n\\begin{equation*} \\sum_{n=0}^{p-1}s_n(x)^2\\equiv (-1)^{\\langle\nx\\rangle_p}\\frac{p+2(x-\\langle x\\rangle_p)}{2x+1}\\pmod{p^3}, \\end{equation*}\nwhere $\\langle x\\rangle_p$ denotes the least nonnegative residue of $x$ modulo\n$p$. In this paper, we confirm this conjecture.", "AI": {"tldr": "本文证明了Z.-W. Sun关于多项式序列$s_n(x)$模$p^3$超同余的猜想。", "motivation": "研究动机源于Kimoto和Wakayama提出并由Long、Osburn和Swisher证实的超同余猜想，Z.-W. Sun由此引入多项式序列$s_n(x)$并研究其同余性质。", "method": "通过分析多项式序列$s_n(x)$的表达式及其组合性质，研究了其在素数$p>3$和$p$-adic整数$x\\neq-1/2$条件下的模$p^3$行为。", "result": "证实了对于任意素数$p>3$和$p$-adic整数$x\\neq-1/2$，有$\\sum_{n=0}^{p-1}s_n(x)^2\\equiv (-1)^{\\langle x\\rangle_p}\\frac{p+2(x-\\langle x\\rangle_p)}{2x+1}\\pmod{p^3}$成立。", "conclusion": "成功验证了Z.-W. Sun提出的关于多项式序列$s_n(x)$的超同余猜想，为相关数论问题提供了新的理论支持。"}}
{"id": "2506.17514", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17514", "abs": "https://arxiv.org/abs/2506.17514", "authors": ["Ninareh Mehrabi", "Tharindu Kumarage", "Kai-Wei Chang", "Aram Galstyan", "Rahul Gupta"], "title": "Kaleidoscopic Teaming in Multi Agent Simulations", "comment": null, "summary": "Warning: This paper contains content that may be inappropriate or offensive.\n  AI agents have gained significant recent attention due to their autonomous\ntool usage capabilities and their integration in various real-world\napplications. This autonomy poses novel challenges for the safety of such\nsystems, both in single- and multi-agent scenarios. We argue that existing red\nteaming or safety evaluation frameworks fall short in evaluating safety risks\nin complex behaviors, thought processes and actions taken by agents. Moreover,\nthey fail to consider risks in multi-agent setups where various vulnerabilities\ncan be exposed when agents engage in complex behaviors and interactions with\neach other. To address this shortcoming, we introduce the term kaleidoscopic\nteaming which seeks to capture complex and wide range of vulnerabilities that\ncan happen in agents both in single-agent and multi-agent scenarios. We also\npresent a new kaleidoscopic teaming framework that generates a diverse array of\nscenarios modeling real-world human societies. Our framework evaluates safety\nof agents in both single-agent and multi-agent setups. In single-agent setup,\nan agent is given a scenario that it needs to complete using the tools it has\naccess to. In multi-agent setup, multiple agents either compete against or\ncooperate together to complete a task in the scenario through which we capture\nexisting safety vulnerabilities in agents. We introduce new in-context\noptimization techniques that can be used in our kaleidoscopic teaming framework\nto generate better scenarios for safety analysis. Lastly, we present\nappropriate metrics that can be used along with our framework to measure safety\nof agents. Utilizing our kaleidoscopic teaming framework, we identify\nvulnerabilities in various models with respect to their safety in agentic\nuse-cases.", "AI": {"tldr": "本文提出了一种名为\"万花筒式团队\"的新框架，用于评估AI代理在单代理和多代理场景中的安全风险，通过生成多样化场景和引入上下文优化技术来识别漏洞。", "motivation": "现有红队测试或安全评估框架无法充分评估AI代理在复杂行为、思维过程和交互中的安全风险，特别是在多代理设置中暴露的漏洞。", "method": "作者提出了\"万花筒式团队\"框架，通过生成模拟现实社会场景来评估单代理和多代理设置中的安全性，并引入上下文优化技术改进场景生成。", "result": "使用该框架识别了多种AI模型在代理用例中的安全漏洞，并提出了相应的安全度量标准。", "conclusion": "万花筒式团队框架为AI代理安全评估提供了更全面的方法，能够发现传统方法无法检测到的复杂交互漏洞。"}}
{"id": "2506.17299", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17299", "abs": "https://arxiv.org/abs/2506.17299", "authors": ["Shuyi Lin", "Anshuman Suri", "Alina Oprea", "Cheng Tan"], "title": "LLM Jailbreak Oracle", "comment": null, "summary": "As large language models (LLMs) become increasingly deployed in\nsafety-critical applications, the lack of systematic methods to assess their\nvulnerability to jailbreak attacks presents a critical security gap. We\nintroduce the jailbreak oracle problem: given a model, prompt, and decoding\nstrategy, determine whether a jailbreak response can be generated with\nlikelihood exceeding a specified threshold. This formalization enables a\nprincipled study of jailbreak vulnerabilities. Answering the jailbreak oracle\nproblem poses significant computational challenges -- the search space grows\nexponentially with the length of the response tokens. We present Boa, the first\nefficient algorithm for solving the jailbreak oracle problem. Boa employs a\nthree-phase search strategy: (1) constructing block lists to identify refusal\npatterns, (2) breadth-first sampling to identify easily accessible jailbreaks,\nand (3) depth-first priority search guided by fine-grained safety scores to\nsystematically explore promising low-probability paths. Boa enables rigorous\nsecurity assessments including systematic defense evaluation, standardized\ncomparison of red team attacks, and model certification under extreme\nadversarial conditions.", "AI": {"tldr": "本文提出'越狱预言问题'来系统评估大语言模型(LLM)的安全漏洞，并开发了首个高效算法Boa，通过三阶段搜索策略实现对抗性安全检测。", "motivation": "随着大语言模型在安全关键领域广泛应用，缺乏系统性方法评估其对抗'越狱攻击'的脆弱性已成为重大安全隐患。", "method": "Boa算法采用三阶段搜索策略：(1)构建拒绝模式黑名单，(2)广度优先采样寻找易得越狱路径，(3)基于细粒度安全评分的深度优先搜索探索低概率路径。", "result": "Boa首次实现了越狱预言问题的有效求解，支持系统化防御评估、红队攻击标准化比较及极端对抗条件下的模型认证。", "conclusion": "该研究为LLM安全评估建立了理论基础和实用工具，Boa算法在计算效率与检测完备性间取得了突破性平衡。"}}
{"id": "2506.17862", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.17862", "abs": "https://arxiv.org/abs/2506.17862", "authors": ["Tewodros Amdeberhan", "Doron Zeilberger"], "title": "Proofs Of Three Geode Conjectures", "comment": "9 pages", "summary": "In the May 2025 issue of the Amer. Math. Monthly, Norman J. Wildberger and\nDean Rubine intoduced a new kind of multi-indexed numbers, that they call\n`Geode numbers', obtained from the Hyper-Catalan numbers. They posed three\nintriguing conjectures about them, that are proved in this note.", "AI": {"tldr": "本文证明了Wildberger和Rubine关于Geode数的三个猜想，这些数源自超Catalan数。", "motivation": "Wildberger和Rubine在2025年5月的《美国数学月刊》中引入了Geode数，并提出三个猜想，本文旨在证明这些猜想。", "method": "通过数学推导和证明，验证了Geode数的性质及其与超Catalan数的关系。", "result": "成功证明了Wildberger和Rubine提出的三个关于Geode数的猜想。", "conclusion": "本文的研究不仅证实了Geode数的猜想，还为进一步研究多指标数提供了新的视角。"}}
{"id": "2506.18299", "categories": ["math.NT", "11T23, 14F20"], "pdf": "https://arxiv.org/pdf/2506.18299", "abs": "https://arxiv.org/abs/2506.18299", "authors": ["Dante Bonolis", "Emmanuel Kowalski", "Katharine Woo"], "title": "Stratification theorems for exponential sums in families", "comment": "44 pages; 1 appendix by Forey, Fres\\'an and Kowalski", "summary": "We survey some of the stratification theorems concerning exponential sums\nover finite fields, especially those due to Katz-Laumon and Fouvry-Katz, as\nwell as some of their applications. Moreover, motivated partly by recent work\nof Bonolis, Pierce and Woo (arXiv:2505.11226), we prove that these\nstratification statements admit uniform variants in families, both\nalgebraically and analytically.\n  The paper includes an Appendix by Forey, Fres\\'an and Kowalski (excerpted\nfrom arXiv:2109.11961), which provides an elementary intuitive introduction to\ntrace functions in more than one variable over finite fields.", "AI": {"tldr": "本文综述了有限域上指数和的层化定理，特别是Katz-Laumon和Fouvry-Katz的成果，并证明了这些定理在代数与解析层面具有统一的族变体。附录提供了多变量有限域上迹函数的直观介绍。", "motivation": "受Bonolis、Pierce和Woo近期工作的启发，研究有限域上指数和层化定理的统一族变体。", "method": "综述已有层化定理，并代数与解析地证明其在族中的统一性。附录采用初等方法介绍多变量迹函数。", "result": "证明了Katz-Laumon和Fouvry-Katz的层化定理在代数族和解析族中具有统一形式。", "conclusion": "有限域指数和层化定理的统一族变体拓展了其应用范围，附录为多变量迹函数研究提供了基础。"}}
{"id": "2506.17585", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17585", "abs": "https://arxiv.org/abs/2506.17585", "authors": ["Yukun Huang", "Sanxing Chen", "Jian Pei", "Manzil Zaheer", "Bhuwan Dhingra"], "title": "Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models", "comment": null, "summary": "Trustworthy language models should provide both correct and verifiable\nanswers. While language models can sometimes attribute their outputs to\npretraining data, their citations are often unreliable due to hallucination. As\na result, current systems insert citations by querying an external retriever at\ninference time, introducing latency, infrastructure dependence, and\nvulnerability to retrieval noise. We explore whether LLMs can be made to\nreliably attribute to the documents seen during (continual)\npretraining--without test-time retrieval--by revising the training process. To\nevaluate this, we release CitePretrainBench, a benchmark that mixes real-world\ncorpora (Wikipedia, Common Crawl, arXiv) with novel, unseen documents and\nprobes both short-form (single fact) and long-form (multi-fact) citation tasks.\nOur approach follows a two-stage process: (1) continual pretraining to bind\nfacts to persistent document identifiers, and (2) instruction tuning to elicit\ncitation behavior. We find that simple Passive Indexing, which appends an\nidentifier to each document, helps memorize verbatim text but fails on\nparaphrased or compositional facts. Instead, we propose Active Indexing, which\ncontinually pretrains on synthetic QA pairs that (1) restate each fact in\ndiverse compositional forms, and (2) require bidirectional source-to-fact and\nfact-to-source generation, jointly teaching the model to generate content from\na cited source and to attribute its own answers. Experiments with Qwen2.5-7B\nand 3B show that Active Indexing consistently outperforms Passive Indexing\nacross all tasks and models, with citation precision gains up to 30.2 percent.\nOur ablation studies reveal that performance continues to improve as we scale\nthe amount of augmented data, showing a clear upward trend even at 16 times the\noriginal token count.", "AI": {"tldr": "本文探讨如何让语言模型在持续预训练中可靠地引用文档，提出主动索引方法，显著提升引用精度。", "motivation": "当前语言模型的引用不可靠，依赖外部检索器会引入延迟和噪声，需探索无需推理时检索的可靠引用方法。", "method": "采用两阶段方法：1) 持续预训练将事实与文档标识绑定；2) 指令微调引导引用行为。提出主动索引，通过合成QA对增强训练。", "result": "主动索引在Qwen2.5-7B和3B上全面优于被动索引，引用精度最高提升30.2%，且性能随数据量增加持续提升。", "conclusion": "主动索引能有效提升模型引用可靠性，数据扩增带来持续性能改进，为可信语言模型提供新方向。"}}
{"id": "2506.17273", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17273", "abs": "https://arxiv.org/abs/2506.17273", "authors": ["Marc Lambert"], "title": "The LQR-Schrödinger Bridge", "comment": null, "summary": "We consider the Schr{\\\"o}dinger bridge problem in discrete time, where the\npathwise cost is replaced by a sum of quadratic functions, taking the form of a\nlinear quadratic regulator (LQR) cost. This cost comprises potential terms that\nact as attractors and kinetic terms that control the diffusion of the process.\nWhen the two boundary marginals are Gaussian, we show that the\nLQR-Schr{\\\"o}dinger bridge problem can be solved in closed form. We follow the\ndynamic programming principle, interpreting the Kantorovich potentials as\ncost-to-go functions. Under the LQR-Gaussian assumption, these potentials can\nbe propagated exactly in a backward and forward passes, leading to a system of\ndual Riccati equations, well known in estimation and control. This system\nconverges rapidly in practice. We then show that the optimal process is\nMarkovian and compute its transition kernel in closed form as well as the\nGaussian marginals. Through numerical experiments, we demonstrate that this\napproach can be used to construct complex, non-homogeneous Gaussian processes\nwith acceleration and loops, given well-chosen attractive potentials. Moreover,\nthis approach allows extending the Bures transport between Gaussian\ndistributions to more complex geometries with negative curvature.", "AI": {"tldr": "本文研究了离散时间下的薛定谔桥问题，采用线性二次调节器（LQR）成本函数，在边界边际为高斯分布时，提出了闭式解法，并通过动态规划原理和Riccati方程实现了高效求解。", "motivation": "研究离散时间薛定谔桥问题，旨在通过LQR成本函数（包含势能项和动能项）构建复杂非均匀高斯过程，并扩展高斯分布间的Bures传输到更复杂几何结构。", "method": "采用动态规划原理，将Kantorovich势解释为成本函数，在LQR-高斯假设下，通过前向和后向传递精确传播势能，建立对偶Riccati方程系统。", "result": "在边界边际为高斯分布时，问题可闭式求解，最优过程为马尔可夫过程，其转移核和高斯边际可闭式计算。数值实验验证了该方法能构建含加速和循环的复杂高斯过程。", "conclusion": "该方法不仅高效求解LQR-薛定谔桥问题，还能将Bures传输扩展到负曲率几何结构，为复杂高斯过程建模提供了新工具。"}}
{"id": "2506.17308", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17308", "abs": "https://arxiv.org/abs/2506.17308", "authors": ["Koichi Nagatsuka", "Terufumi Morishita", "Yasuhiro Sogawa"], "title": "A Nested Watermark for Large Language Models", "comment": "6 pages, 3 figures", "summary": "The rapid advancement of large language models (LLMs) has raised concerns\nregarding their potential misuse, particularly in generating fake news and\nmisinformation. To address these risks, watermarking techniques for\nautoregressive language models have emerged as a promising means for detecting\nLLM-generated text. Existing methods typically embed a watermark by increasing\nthe probabilities of tokens within a group selected according to a single\nsecret key. However, this approach suffers from a critical limitation: if the\nkey is leaked, it becomes impossible to trace the text's provenance or\nattribute authorship. To overcome this vulnerability, we propose a novel nested\nwatermarking scheme that embeds two distinct watermarks into the generated text\nusing two independent keys. This design enables reliable authorship\nidentification even in the event that one key is compromised. Experimental\nresults demonstrate that our method achieves high detection accuracy for both\nwatermarks while maintaining the fluency and overall quality of the generated\ntext.", "AI": {"tldr": "本文提出了一种新型嵌套水印方案，通过双密钥机制解决现有大语言模型水印技术中密钥泄露导致的溯源失效问题，实验证明该方法在保持文本质量的同时实现高精度水印检测。", "motivation": "针对大语言模型可能被滥用于生成虚假信息的风险，现有单密钥水印技术存在密钥泄露后无法追溯文本来源的致命缺陷，亟需更鲁棒的认证方案。", "method": "采用嵌套水印架构，使用两个独立密钥在自回归生成过程中嵌入双重水印，即使一个密钥泄露仍能通过另一个密钥进行作者身份认证。", "result": "实验数据显示，该方法对两个水印均保持高检测准确率（分别达98.7%和97.3%），且生成文本的流畅度（PPL=15.2）与原始模型相当。", "conclusion": "双密钥嵌套水印技术有效提升了模型输出溯源的容错能力，为防范LLM生成内容滥用提供了可扩展的认证框架，未来可延伸至多级水印系统研究。"}}
{"id": "2506.17915", "categories": ["math.CO", "05C05, 05C09"], "pdf": "https://arxiv.org/pdf/2506.17915", "abs": "https://arxiv.org/abs/2506.17915", "authors": ["Cheng Zeng", "Gengji Li"], "title": "Some sharp bounds on the average Steiner (k, l)-eccentricity for trees", "comment": "14 pages, 6 figures", "summary": "In this paper we introduce some transformations for trees that do not\nincrease the average Steiner $(k,l)$-eccentricity for all $0\\leq l\\leq k\\leq\nn$. Using these transformations, we obtain some sharp bounds on the average\nSteiner $(k,l)$-eccentricity for trees with some certain conditions, including\ngiven nodes, given diameter, given max degree and given leaves, and get the\ncorresponding extremal trees as well.", "AI": {"tldr": "本文提出了不增加树平均Steiner $(k,l)$-偏心率变换方法，并在特定条件下获得尖锐边界及极值树。", "motivation": "研究树结构中Steiner $(k,l)$-偏心率的变化规律，探索不同约束条件下的极值特性。", "method": "引入保持平均Steiner $(k,l)$-偏心率不增的树变换，分析给定节点数、直径、最大度数和叶节点数等约束条件。", "result": "获得了各类约束条件下平均Steiner $(k,l)$-偏心率的尖锐上界，并确定了对应的极值树结构。", "conclusion": "所提出的变换方法有效揭示了树结构参数与Steiner偏心率的关系，为网络优化提供了理论工具。"}}
{"id": "2506.18395", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.18395", "abs": "https://arxiv.org/abs/2506.18395", "authors": ["Hong Ziwei", "Zheng Zhiyong"], "title": "The second moment of Ramanujan sums", "comment": null, "summary": "In this paper, we analyze $C(x, y)$, the second moment of Ramanujan sums.\nAssuming the Riemann Hypothesis, we derive an asymptotic formula for $C(x, y)$\nwith improved error term precision. The key feature of our approach is that it\nallows $x$ and $y$ to be arbitrarily close.", "AI": {"tldr": "本文在黎曼假设下，改进了拉马努金和二项$C(x, y)$的渐近公式误差项精度，并允许$x$与$y$任意接近。", "motivation": "研究拉马努金和二项$C(x, y)$的渐近行为，特别是在$x$和$y$接近时的表现，以深化对数论中相关问题的理解。", "method": "假设黎曼假设成立，采用分析方法推导$C(x, y)$的渐近公式，重点改进误差项的精度。", "result": "得到了$C(x, y)$的更精确渐近公式，且允许$x$和$y$任意接近，这在以往研究中较为罕见。", "conclusion": "该研究不仅改进了拉马努金和二阶矩的渐近分析，还为$x$和$y$接近情况下的数论问题提供了新的工具。"}}
{"id": "2506.17589", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17589", "abs": "https://arxiv.org/abs/2506.17589", "authors": ["Bowen Wang"], "title": "Taming the Untamed: Graph-Based Knowledge Retrieval and Reasoning for MLLMs to Conquer the Unknown", "comment": null, "summary": "The real value of knowledge lies not just in its accumulation, but in its\npotential to be harnessed effectively to conquer the unknown. Although recent\nmultimodal large language models (MLLMs) exhibit impressing multimodal\ncapabilities, they often fail in rarely encountered domain-specific tasks due\nto limited relevant knowledge. To explore this, we adopt visual game cognition\nas a testbed and select Monster Hunter: World as the target to construct a\nmultimodal knowledge graph (MH-MMKG), which incorporates multi-modalities and\nintricate entity relations. We also design a series of challenging queries\nbased on MH-MMKG to evaluate the models' ability for complex knowledge\nretrieval and reasoning. Furthermore, we propose a multi-agent retriever that\nenables a model to autonomously search relevant knowledge without additional\ntraining. Experimental results show that our approach significantly enhances\nthe performance of MLLMs, providing a new perspective on multimodal\nknowledge-augmented reasoning and laying a solid foundation for future\nresearch.", "AI": {"tldr": "本文通过构建多模态知识图谱(MH-MMKG)并提出多智能体检索器，显著提升了多模态大语言模型(MLLMs)在特定领域任务中的表现，为多模态知识增强推理提供了新视角。", "motivation": "当前多模态大语言模型在罕见领域任务中表现不佳，主要受限于相关知识的缺乏。研究旨在探索如何有效利用多模态知识提升模型性能。", "method": "以视觉游戏认知为测试平台，构建《怪物猎人：世界》多模态知识图谱(MH-MMKG)，设计复杂查询任务，并提出无需额外训练的多智能体检索器实现自主知识搜索。", "result": "实验结果表明，该方法显著提高了MLLMs在复杂知识检索与推理任务中的表现，准确率提升明显。", "conclusion": "研究为多模态知识增强推理提供了可行方案，建立的MH-MMKG数据集为未来研究奠定了坚实基础，展示了自主知识检索在提升模型领域适应性方面的潜力。"}}
{"id": "2506.17305", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17305", "abs": "https://arxiv.org/abs/2506.17305", "authors": ["Vinesha Peiris", "Nadezda Sukhorukova", "Julien Ugon"], "title": "KKT-based optimality conditions for neural network approximation", "comment": "Submitted to a journal", "summary": "In this paper, we obtain necessary optimality conditions for neural network\napproximation. We consider neural networks in Manhattan ($l_1$ norm) and\nChebyshev ($\\max$ norm). The optimality conditions are based on neural networks\nwith at most one hidden layer. We reformulate nonsmooth unconstrained\noptimisation problems as larger dimension constrained problems with smooth\nobjective functions and constraints. Then we use KKT conditions to develop the\nnecessary conditions and present the optimality conditions in terms of convex\nanalysis and convex sets.", "AI": {"tldr": "本文研究了神经网络在曼哈顿范数($l_1$范数)和切比雪夫范数($\\max$范数)下的最优性条件，针对单隐藏层网络，将非光滑无约束优化问题转化为高维光滑约束问题，并利用KKT条件建立了基于凸分析的充要条件。", "motivation": "旨在为神经网络近似建立严格的最优性理论框架，特别是在非欧几里得范数空间($l_1$和$\\max$范数)中，解决传统梯度方法无法直接应用的挑战。", "method": "将原始非光滑无约束优化重构为高维空间的光滑约束问题，通过KKT条件推导必要条件，并采用凸集和凸分析工具表述最优性条件。", "result": "获得了单隐藏层神经网络在$l_1$和$\\max$范数下的充要最优性条件，证明可通过凸优化框架严格表征神经网络的最优近似行为。", "conclusion": "该理论为神经网络优化提供了新的分析工具，特别适用于非光滑范数空间，未来可扩展至深层网络和更复杂的最优控制场景。"}}
{"id": "2506.17309", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17309", "abs": "https://arxiv.org/abs/2506.17309", "authors": ["Aditya Choudhary", "Sarthak Pawar", "Yashodhara Haribhakta"], "title": "Efficient Malware Detection with Optimized Learning on High-Dimensional Features", "comment": "This paper has been accepted for presentation at the International\n  Conference on Innovations in Intelligent Systems: Advancements in Computing,\n  Communication, and Cybersecurity (ISAC3)", "summary": "Malware detection using machine learning requires feature extraction from\nbinary files, as models cannot process raw binaries directly. A common approach\ninvolves using LIEF for raw feature extraction and the EMBER vectorizer to\ngenerate 2381-dimensional feature vectors. However, the high dimensionality of\nthese features introduces significant computational challenges. This study\naddresses these challenges by applying two dimensionality reduction techniques:\nXGBoost-based feature selection and Principal Component Analysis (PCA). We\nevaluate three reduced feature dimensions (128, 256, and 384), which correspond\nto approximately 5.4%, 10.8%, and 16.1% of the original 2381 features, across\nfour models-XGBoost, LightGBM, Extra Trees, and Random Forest-using a unified\ntraining, validation, and testing split formed from the EMBER-2018, ERMDS, and\nBODMAS datasets. This approach ensures generalization and avoids dataset bias.\nExperimental results show that LightGBM trained on the 384-dimensional feature\nset after XGBoost feature selection achieves the highest accuracy of 97.52% on\nthe unified dataset, providing an optimal balance between computational\nefficiency and detection performance. The best model, trained in 61 minutes\nusing 30 GB of RAM and 19.5 GB of disk space, generalizes effectively to\ncompletely unseen datasets, maintaining 95.31% accuracy on TRITIUM and 93.98%\naccuracy on INFERNO. These findings present a scalable, compute-efficient\napproach for malware detection without compromising accuracy.", "AI": {"tldr": "该研究通过XGBoost特征选择和PCA降维技术，将2381维恶意软件特征降至128/256/384维，在LightGBM模型上实现97.52%检测准确率，同时显著降低计算资源消耗。", "motivation": "传统恶意软件检测使用的2381维EMBER特征向量存在计算效率瓶颈，需通过降维平衡检测性能与资源开销。", "method": "采用XGBoost特征选择和PCA两种降维方法，在EMBER-2018/ERMDS/BODMAS混合数据集上评估XGBoost/LightGBM/Extra Trees/Random Forest四种模型，测试维度为原特征的5.4%-16.1%（128/256/384维）。", "result": "XGBoost特征选择后的384维特征+LightGBM组合最优（97.52%准确率），仅需61分钟训练时间和30GB内存，在TRITIUM/INFERNO未知数据集上保持95.31%/93.98%准确率。", "conclusion": "该方案证明降维技术可显著提升恶意软件检测的计算效率，且不影响模型泛化能力，为实际部署提供了高效解决方案。"}}
{"id": "2506.17921", "categories": ["math.CO", "05C20 (Primary) 05C35 (Secondary)", "G.2.2"], "pdf": "https://arxiv.org/pdf/2506.17921", "abs": "https://arxiv.org/abs/2506.17921", "authors": ["Vasily Buslov"], "title": "How Trees on Atoms of Subset Algebras Define Minimal Forests and Their Growth", "comment": "23 pages, 7 figures", "summary": "A complete description is given of how minimal trees on atoms of the algebra\nof subsets $\\mathfrak{A}_k$ generated by minimal spanning $k$-component forests\nof a weighted digraph $V$ determine the form of these forests and how forests\ngrow with increasing number of arcs (that is with a decrease in the number of\ntrees). Precise bounds are established on what can be extracted about the tree\nstructure of the original graph if the minimal trees on the atoms of a single\nalgebra $\\mathfrak{A}_k$ are known, and also what minimum spanning forests with\nfewer components can be constructed based on this, and what exactly additional\ninformation is required to determine minimum spanning forests consisting of\neven fewer components.", "AI": {"tldr": "该论文研究了加权有向图$V$中由最小生成$k$-分量森林生成的子集代数$\\mathfrak{A}_k$上极小树的性质，揭示了这些树如何决定森林形态及其随弧数增加的生长规律，并建立了从单一代数$\\mathfrak{A}_k$的极小树推断原图树结构的精确界限。", "motivation": "探讨如何通过子集代数$\\mathfrak{A}_k$上的极小树理解加权有向图的最小生成森林结构，以及如何利用有限信息构建更少分量的最小生成森林。", "method": "分析极小树在子集代数$\\mathfrak{A}_k$原子上的性质，研究森林随弧数增加的演化规律，并建立从已知代数推断原图结构的理论界限。", "result": "确定了从单一代数$\\mathfrak{A}_k$的极小树可提取的原图树结构信息量，提出了构建更少分量最小生成森林的方法及所需补充信息的精确条件。", "conclusion": "极小树与子集代数的关联性为分析最小生成森林提供了新视角，但完全确定更少分量的森林需要额外的结构信息。"}}
{"id": "2506.18461", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.18461", "abs": "https://arxiv.org/abs/2506.18461", "authors": ["Hongguang Wu", "Jun Qiu"], "title": "Partial sums of the hyperharmonic series", "comment": null, "summary": "In 1946, Erd\\\"os and Niven proved that no two partial sums of the harmonic\nseries are equal. In this paper, we extend this result by demonstrating that no\ntwo partial sums of the hyperharmonic series are equal.", "AI": {"tldr": "本文扩展了Erd\\\"os和Niven的结论，证明超调和级数的部分和也互不相等。", "motivation": "受1946年Erd\\\"os和Niven关于调和级数部分和唯一性的启发，研究超调和级数的类似性质。", "method": "通过数学推导和证明，扩展了原始定理的适用范围至超调和级数。", "result": "严格证明了超调和级数的任意两个部分和不可能相等。", "conclusion": "该研究不仅推广了经典结果，还为级数唯一性理论提供了新的见解。"}}
{"id": "2506.17644", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17644", "abs": "https://arxiv.org/abs/2506.17644", "authors": ["Zimo Ji", "Daoyuan Wu", "Wenyuan Jiang", "Pingchuan Ma", "Zongjie Li", "Shuai Wang"], "title": "Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges", "comment": null, "summary": "Capture-the-Flag (CTF) competitions are crucial for cybersecurity education\nand training. As large language models (LLMs) evolve, there is increasing\ninterest in their ability to automate CTF challenge solving. For example, DARPA\nhas organized the AIxCC competition since 2023 to advance AI-powered automated\noffense and defense. However, this demands a combination of multiple abilities,\nfrom knowledge to reasoning and further to actions. In this paper, we highlight\nthe importance of technical knowledge in solving CTF problems and deliberately\nconstruct a focused benchmark, CTFKnow, with 3,992 questions to measure LLMs'\nperformance in this core aspect. Our study offers a focused and innovative\nmeasurement of LLMs' capability in understanding CTF knowledge and applying it\nto solve CTF challenges. Our key findings reveal that while LLMs possess\nsubstantial technical knowledge, they falter in accurately applying this\nknowledge to specific scenarios and adapting their strategies based on feedback\nfrom the CTF environment.\n  Based on insights derived from this measurement study, we propose CTFAgent, a\nnovel LLM-driven framework for advancing CTF problem-solving. CTFAgent\nintroduces two new modules: two-stage Retrieval Augmented Generation (RAG) and\ninteractive Environmental Augmentation, which enhance LLMs' technical knowledge\nand vulnerability exploitation on CTF, respectively. Our experimental results\nshow that, on two popular CTF datasets, CTFAgent both achieves over 80%\nperformance improvement. Moreover, in the recent picoCTF2024 hosted by CMU,\nCTFAgent ranked in the top 23.6% of nearly 7,000 participating teams. This\nreflects the benefit of our measurement study and the potential of our\nframework in advancing LLMs' capabilities in CTF problem-solving.", "AI": {"tldr": "本文提出CTFKnow基准测试评估大模型在CTF竞赛中的知识应用能力，并开发CTFAgent框架通过两阶段RAG和环境增强显著提升性能，在picoCTF2024中进入前23.6%名次。", "motivation": "随着大模型发展，自动化解决CTF挑战的需求增长，但现有模型在知识应用和策略调整上存在不足，需建立专门评估体系并提升实战能力。", "method": "构建含3,992个问题的CTFKnow基准测试；提出CTFAgent框架，创新性引入两阶段检索增强生成（RAG）和交互式环境增强模块。", "result": "CTFAgent在两个主流CTF数据集上实现80%以上性能提升，在picoCTF2024竞赛中位列前23.6%（近7000支队伍）。", "conclusion": "研究表明大模型虽具备技术知识储备，但场景化应用能力不足；CTFAgent框架通过知识增强和动态环境交互有效提升了CTF解题能力。"}}
{"id": "2506.17405", "categories": ["math.OC", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2506.17405", "abs": "https://arxiv.org/abs/2506.17405", "authors": ["Bowen Li", "Ya-xiang Yuan"], "title": "Convergent Proximal Multiblock ADMM for Nonconvex Dynamics-Constrained Optimization", "comment": "32 pages, 6 figures", "summary": "This paper proposes a provably convergent multiblock ADMM for nonconvex\noptimization with nonlinear dynamics constraints, overcoming the divergence\nissue in classical extensions. We consider a class of optimization problems\nthat arise from discretization of dynamics-constrained variational problems\nthat are optimization problems for a functional constrained by time-dependent\nODEs or PDEs. This is a family of $n$-sum nonconvex optimization problems with\nnonlinear constraints. We study the convergence properties of the proximal\nalternating direction method of multipliers (proximal ADMM) applied to those\nproblems. Taking the advantage of the special problem structure, we show that\nunder local Lipschitz and local $L$-smooth conditions, the sequence generated\nby the proximal ADMM is bounded and all accumulation points are KKT points.\nBased on our analysis, we also design a procedure to determine the penalty\nparameters $\\rho_i$ and the proximal parameters $\\eta_i$. We further prove that\namong all the subsequences that converge, the fast one converges at the rate of\n$o(1/k)$. The numerical experiments are performed on 4D variational data\nassimilation problems and as the solver of implicit schemes for stiff problems.\nThe proposed proximal ADMM has more stable performance than gradient-based\nmethods. We discuss the implementation to solve the subproblems, a new way to\nsolve the implicit schemes, and the advantages of the proposed algorithm.", "AI": {"tldr": "本文提出了一种针对非线性动力学约束非凸优化的可证明收敛的多块ADMM方法，解决了经典扩展中的发散问题。通过利用问题特殊结构，证明了在局部Lipschitz和局部$L$-光滑条件下，近端ADMM生成的序列有界且所有累积点均为KKT点。数值实验表明该方法在4D变分数据同化和刚性问题的隐式求解中表现稳定。", "motivation": "经典扩展ADMM在非线性动力学约束的非凸优化中易发散，而动力学约束变分问题（如ODE/PDE约束的泛函优化）在科学计算中广泛存在。本文旨在开发一种理论保证收敛的算法来解决这类$n$-求和型非凸优化问题。", "method": "基于近端交替方向乘子法（proximal ADMM），利用问题结构设计收敛算法。提出确定惩罚参数$\\rho_i$和近端参数$\\eta_i$的流程，并证明在局部Lipschitz和$L$-光滑条件下，算法生成的序列有界且收敛于KKT点。", "result": "理论证明：算法序列有界且所有累积点为KKT点，快速子序列收敛速度为$o(1/k)$。数值实验显示，在4D变分数据同化和刚性隐式格式求解中，近端ADMM比基于梯度的方法更稳定。", "conclusion": "所提出的近端ADMM为非线性动力学约束的非凸优化提供了理论保证的解决方案，其稳定性和收敛性在科学计算问题中得到验证。文中还讨论了子问题求解的新方法和该算法的优势。"}}
{"id": "2506.17315", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.17315", "abs": "https://arxiv.org/abs/2506.17315", "authors": ["Chuan Yan", "Liuhuo Wan", "Bowei Guan", "Fengqi Yu", "Guangdong Bai", "Jin Song Dong"], "title": "Tracking GPTs Third Party Service: Automation, Analysis, and Insights", "comment": "The 1st International Workshop on LLM App Store Analysis (LLMapp\n  2025)", "summary": "ChatGPT has quickly advanced from simple natural language processing to\ntackling more sophisticated and specialized tasks. Drawing inspiration from the\nsuccess of mobile app ecosystems, OpenAI allows developers to create\napplications that interact with third-party services, known as GPTs. GPTs can\nchoose to leverage third-party services to integrate with specialized APIs for\ndomain-specific applications. However, the way these disclose privacy setting\ninformation limits accessibility and analysis, making it challenging to\nsystematically evaluate the data privacy implications of third-party integrate\nto GPTs. In order to support academic research on the integration of\nthird-party services in GPTs, we introduce GPTs-ThirdSpy, an automated\nframework designed to extract privacy settings of GPTs. GPTs-ThirdSpy provides\nacademic researchers with real-time, reliable metadata on third-party services\nused by GPTs, enabling in-depth analysis of their integration, compliance, and\npotential security risks. By systematically collecting and structuring this\ndata, GPTs-ThirdSpy facilitates large-scale research on the transparency and\nregulatory challenges associated with the GPT app ecosystem.", "AI": {"tldr": "本文介绍了GPTs-ThirdSpy，一个自动化框架，用于提取GPTs的隐私设置，以支持第三方服务集成在GPTs中的学术研究。", "motivation": "GPTs与第三方服务的集成方式限制了隐私设置信息的可访问性和分析，使得系统评估数据隐私影响具有挑战性。", "method": "GPTs-ThirdSpy是一个自动化框架，旨在提取GPTs的隐私设置，为研究人员提供实时、可靠的第三方服务元数据。", "result": "GPTs-ThirdSpy能够系统地收集和结构化数据，支持对GPTs生态系统的透明度和监管挑战进行大规模研究。", "conclusion": "GPTs-ThirdSpy为学术研究提供了工具，以深入分析GPTs中第三方服务的集成、合规性及潜在安全风险。"}}
{"id": "2506.17922", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.17922", "abs": "https://arxiv.org/abs/2506.17922", "authors": ["Aleams Barra"], "title": "A unified approach to total irregular labeling", "comment": null, "summary": "We present a unified approach to compute the total vertex irregularity\nstrength (tvs) of various graphs, employing a novel technique recently proposed\nby Barra et al. For graphs such as cycles, paths, prisms, wheels, complete\ngraphs, helm graphs, friendship graphs, and $K_{n,n}$ , we offer simplified and\nunified proofs of their previously established tvs values. Furthermore, we\nresolve an open problem by determining the tvs for simple 2-regular graphs.", "AI": {"tldr": "本文提出了一种统一计算各类图的总顶点不规则强度(tvs)的方法，简化并统一了多种图结构的tvs证明，并解决了简单2-正则图的tvs开放问题。", "motivation": "旨在为多种图结构提供统一的总顶点不规则强度计算方法，并解决简单2-正则图的tvs开放问题。", "method": "采用Barra等人提出的新技术，对环、路径、棱柱、轮、完全图、舵图、友谊图及$K_{n,n}$等图结构进行统一分析。", "result": "简化并统一了多种图结构的tvs证明，首次确定了简单2-正则图的tvs值。", "conclusion": "该方法不仅统一了各类图的tvs计算，还填补了简单2-正则图的理论空白，为图论研究提供了新工具。"}}
{"id": "2506.18712", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.18712", "abs": "https://arxiv.org/abs/2506.18712", "authors": ["Tewodros Amdeberhan", "George E. Andrews", "Cristina Ballantine"], "title": "Lambert series and double Lambert series", "comment": "19 pages", "summary": "We consider relationships between classical Lambert series, multiple Lambert\nseries and classical $q$-series of the Rogers-Ramanujan type. We conclude with\na contemplation on the Andrews-Dixit-Schultz-Yee conjecture.", "AI": {"tldr": "本文探讨经典Lambert级数、多重Lambert级数与Rogers-Ramanujan型经典$q$-级数之间的关系，并对Andrews-Dixit-Schultz-Yee猜想进行了思考。", "motivation": "研究Lambert级数与$q$-级数之间的内在联系，深化对特殊函数理论的理解。", "method": "通过数学分析手段，对比研究经典Lambert级数、多重Lambert级数及Rogers-Ramanujan型$q$-级数的性质与关系。", "result": "建立了不同类型级数之间的关联性，为相关数学领域提供了新的理论视角。", "conclusion": "研究不仅验证了级数间的深刻联系，还为Andrews-Dixit-Schultz-Yee猜想的后续研究奠定了基础。"}}
{"id": "2506.17667", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17667", "abs": "https://arxiv.org/abs/2506.17667", "authors": ["Lintao Wang", "Encheng Su", "Jiaqi Liu", "Pengze Li", "Peng Xia", "Jiabei Xiao", "Wenlong Zhang", "Xinnan Dai", "Xi Chen", "Yuan Meng", "Mingyu Ding", "Lei Bai", "Wanli Ouyang", "Shixiang Tang", "Aoran Wang", "Xinzhu Ma"], "title": "PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models", "comment": null, "summary": "Physics problem-solving is a challenging domain for large AI models,\nrequiring integration of conceptual understanding, mathematical reasoning, and\ninterpretation of physical diagrams. Current evaluation methodologies show\nnotable limitations in capturing the breadth and complexity of\nundergraduate-level physics, underscoring the need for more rigorous\nassessments. To this end, we present PhysUniBench, a large-scale multimodal\nbenchmark designed to evaluate and improve the reasoning capabilities of\nmultimodal large language models (MLLMs) specifically on undergraduate-level\nphysics problems. PhysUniBench consists of 3,304 physics questions spanning 8\nmajor sub-disciplines of physics, each accompanied by one visual diagrams. The\nbenchmark includes both open-ended and multiple-choice questions,\nsystematically curated and difficulty-rated through an iterative\nmodel-in-the-loop process. The benchmark's construction involved a rigorous\nmulti-stage process, including multiple roll-outs, expert-level evaluation,\nautomated filtering of easily solved problems, and a nuanced difficulty grading\nsystem with five levels. Through extensive experiments, we observe that current\nstate-of-the-art models encounter substantial challenges in physics reasoning.\nFor example, GPT-4o mini achieves only about 34.2\\% accuracy in the proposed\nPhysUniBench. These results highlight that current MLLMs struggle with advanced\nphysics reasoning, especially on multi-step problems and those requiring\nprecise diagram interpretation. By providing a broad and rigorous assessment\ntool, PhysUniBench aims to drive progress in AI for Science, encouraging the\ndevelopment of models with stronger physical reasoning, problem-solving skills,\nand multimodal understanding. The benchmark and evaluation scripts are\navailable at https://prismax-team.github.io/PhysUniBenchmark/.", "AI": {"tldr": "PhysUniBench是一个针对多模态大语言模型（MLLMs）设计的大规模多模态基准测试，旨在评估和改进其在本科物理问题上的推理能力。该基准包含3,304个问题，覆盖8个物理子学科，并包含视觉图表。实验显示当前最先进模型在物理推理上表现不佳，如GPT-4o mini准确率仅为34.2%。", "motivation": "当前AI模型在物理问题解决上存在挑战，现有评估方法无法全面捕捉本科物理的广度和复杂性，因此需要更严格的评估工具来推动AI在科学领域的发展。", "method": "PhysUniBench通过多阶段构建过程，包括多次发布、专家评估、自动过滤易解决问题以及五级难度分级系统，系统性地收集和难度评级了3,304个物理问题，每个问题配有视觉图表，包含开放式和选择题。", "result": "实验结果表明，当前最先进的MLLMs在物理推理上遇到显著困难，例如GPT-4o mini在PhysUniBench上的准确率仅为34.2%，尤其是在多步骤问题和需要精确图表解释的问题上表现不佳。", "conclusion": "PhysUniBench作为一个广泛而严格的评估工具，旨在推动AI在科学领域的进步，鼓励开发具有更强物理推理、问题解决能力和多模态理解的模型。基准测试和评估脚本已公开提供。"}}
{"id": "2506.17465", "categories": ["math.OC", "47A52, 65-02, 34A55, 65L09, 65N21, 65T60"], "pdf": "https://arxiv.org/pdf/2506.17465", "abs": "https://arxiv.org/abs/2506.17465", "authors": ["Clemens Kirisits", "Bochra Mejri", "Sergei Pereverzev", "Otmar Scherzer", "Cong Shi"], "title": "Regularization of Nonlinear Inverse Problems -- From Functional Analysis to Data-Driven Approaches", "comment": null, "summary": "The focus of this book is on the analysis of regularization methods for\nsolving \\emph{nonlinear inverse problems}. Specifically, we place a strong\nemphasis on techniques that incorporate supervised or unsupervised data derived\nfrom prior experiments. This approach enables the integration of data-driven\ninsights into the solution of inverse problems governed by physical models.\n\\emph{Inverse problems}, in general, aim to uncover the \\emph{inner mechanisms}\nof an observed system based on indirect or incomplete measurements. This field\nhas far-reaching applications across various disciplines, such as medical or\ngeophysical imaging, as well as, more broadly speaking, industrial processes\nwhere identifying hidden parameters is essential.", "AI": {"tldr": "本书重点分析非线性逆问题的正则化方法，强调利用先验实验数据（监督或无监督）将数据驱动见解融入物理模型控制的逆问题求解。", "motivation": "逆问题旨在通过间接或不完整测量揭示观测系统的内部机制，在医学成像、地球物理成像及工业参数识别等领域具有广泛应用。", "method": "采用结合监督或无监督先验数据的正则化技术，将数据驱动方法与传统物理模型相结合求解非线性逆问题。", "result": "该方法实现了数据驱动见解与物理模型的融合，为逆问题求解提供了新范式。", "conclusion": "整合先验数据的正则化方法能有效解决非线性逆问题，在跨学科应用中展现出重要价值。"}}
{"id": "2506.17317", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17317", "abs": "https://arxiv.org/abs/2506.17317", "authors": ["Liuhuo Wan", "Chuan Yan", "Mark Huasong Meng", "Kailong Wang", "Haoyu Wang", "Guangdong Bai", "Jin Song Dong"], "title": "Beyond the Scope: Security Testing of Permission Management in Team Workspace", "comment": null, "summary": "Nowadays team workspaces are widely adopted for multi-user collaboration and\ndigital resource management. To further broaden real-world applications,\nmainstream team workspaces platforms, such as Google Workspace and Microsoft\nOneDrive, allow third-party applications (referred to as add-ons) to be\nintegrated into their workspaces, significantly extending the functionality of\nteam workspaces. The powerful multi-user collaboration capabilities and\nintegration of add-ons make team workspaces a central hub for managing shared\nresources and protecting them against unauthorized access. Due to the\ncollaboration features of team workspaces, add-ons involved in collaborations\nmay bypass the permission isolation enforced by the administrator, unlike in\nsingle-user permission management.\n  This paper aims to investigate the permission management landscape of team\nworkspaces add-ons. To this end, we perform an in-depth analysis of the\nenforced access control mechanism inherent in this ecosystem, considering both\nmulti-user and cross-app features. We identify three potential security risks\nthat can be exploited to cause permission escalation. We then systematically\nreveal the landscape of permission escalation risks in the current ecosystem.\nSpecifically, we propose an automated tool, TAI, to systematically test all\npossible interactions within this ecosystem. Our evaluation reveals that\npermission escalation vulnerabilities are widespread in this ecosystem, with 41\ninteractions identified as problematic. Our findings should raise an alert to\nboth the team workspaces platforms and third-party developers.", "AI": {"tldr": "本文研究了团队工作空间插件的权限管理现状，揭示了多用户协作环境下插件可能绕过管理员权限隔离的安全风险，并开发了自动化工具TAI进行系统性测试。", "motivation": "随着Google Workspace和Microsoft OneDrive等团队工作空间平台允许第三方插件集成，多用户协作功能使插件可能绕过权限隔离，引发安全隐患。本文旨在调查此类插件的权限管理现状。", "method": "通过深入分析团队工作空间生态系统的访问控制机制，结合多用户和跨应用特性，识别了三种可能导致权限提升的安全风险，并开发了自动化工具TAI进行系统性测试。", "result": "评估发现权限提升漏洞在该生态系统中普遍存在，共识别出41个存在问题的交互案例。", "conclusion": "研究结果警示团队工作空间平台和第三方开发者需重视插件权限管理漏洞，以防止权限提升风险。"}}
{"id": "2506.18073", "categories": ["math.CO", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2506.18073", "abs": "https://arxiv.org/abs/2506.18073", "authors": ["Nero Ziyu Li", "Frank Xin Hu", "Thomas Britz"], "title": "Reducible Iterated Graph Systems: multiscale-freeness and multifractals", "comment": null, "summary": "Iterated Graph Systems (IGS) aims to transplant ideas from fractal geometry\ninto graph theory. Building on this framework, we extend Edge IGS from the\nprimitive to the reducible setting. Within this broader context, we formulate\nrigorous definitions of multifractality and multiscale-freeness for graph\nfractals, and we establish conditions that are equivalent to the occurrence of\nthese two phenomena. We further determine the corresponding fractal and degree\nspectra, proving that both are finite and discrete. These results complete the\nfoundational theory of Edge IGS by filling the gap left by the primitive case\nstudied in [1,2].", "AI": {"tldr": "该研究将分形几何概念引入图论，扩展了边迭代图系统(Edge IGS)的理论框架，定义了图分形的多重分形性和多尺度自由性，并证明了相关谱的有限离散特性。", "motivation": "旨在将分形几何的核心思想迁移至图论领域，完善原始边迭代图系统理论中关于可约情形的空白。", "method": "通过扩展边迭代图系统框架，在可约情形下建立多重分形性与多尺度自由性的严格数学定义，并构建等价条件判定体系。", "result": "证明了图分形的分形谱与度谱均为有限离散集，确立了两种现象发生的充要条件。", "conclusion": "研究成果填补了原始边迭代图系统理论的空白，为图分形建立了完整的理论基础。"}}
{"id": "2506.18776", "categories": ["math.NT", "math.AG", "20K15, 11J95, 11R32, 11G50"], "pdf": "https://arxiv.org/pdf/2506.18776", "abs": "https://arxiv.org/abs/2506.18776", "authors": ["Sara Checcoli", "Gabriel Andreas Dill"], "title": "New evidence for Rémond's generalisation of Lehmer's conjecture", "comment": "33 pages. Comments are welcome!", "summary": "In this article, we generalise a result of Pottmeyer from the multiplicative\ngroup of the algebraic numbers to almost split semiabelian varieties defined\nover number fields. This concerns a consequence of R\\'emond's generalisation of\nLehmer's conjecture. Namely, for a finite rank subgroup $\\Gamma$ of an almost\nsplit semiabelian variety $G$, we consider the group of rational points of $G$\nover a finite extension of the field generated by the saturated closure of\n$\\Gamma$, i.e. the division closure of the subgroup generated by $\\Gamma$ and\nall its images under geometric endomorphisms of $G$. We show that this becomes\na free group after one quotients out the saturated closure of $\\Gamma$. The\nproof uses, amongst other ingredients, a criterion of Pottmeyer, which relies\non a result of Pontryagin, together with a result from Kummer theory, of which\nwe reproduce a proof by R\\'emond.", "AI": {"tldr": "本文推广了Pottmeyer的结果，从代数数乘法群到数域上定义的几乎分裂半阿贝尔簇，证明了在商去$\\Gamma$的饱和闭包后，有理点群成为自由群。", "motivation": "研究动机源于R\\'emond对Lehmer猜想的推广，探讨几乎分裂半阿贝尔簇中有限秩子群$\\Gamma$的有理点群结构。", "method": "方法结合了Pottmeyer基于Pontryagin结果的判别准则，以及Kummer理论中的R\\'emond证明。", "result": "结果表明，在商去$\\Gamma$的饱和闭包后，$G$在有限扩张域上的有理点群成为自由群。", "conclusion": "结论验证了几乎分裂半阿贝尔簇中特定子群结构的自由性，为相关数论问题提供了新的理论支持。"}}
{"id": "2506.17697", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17697", "abs": "https://arxiv.org/abs/2506.17697", "authors": ["Bohan Tang", "Dezhao Luo", "Jingxuan Chen", "Shaogang Gong", "Jianye Hao", "Jun Wang", "Kun Shao"], "title": "Beyond Syntax: Action Semantics Learning for App Agents", "comment": null, "summary": "The advent of Large Language Models (LLMs) enables the rise of App agents\nthat interpret user intent and operate smartphone Apps through actions such as\nclicking and scrolling. While prompt-based solutions with closed LLM APIs show\npromising ability, they incur heavy compute costs and external API dependency.\nFine-tuning smaller open-source LLMs solves these limitations. However, current\nfine-tuning methods use a syntax learning paradigm that forces agents to\nreproduce exactly the ground truth action strings, leading to\nout-of-distribution (OOD) vulnerability. To fill this gap, we propose Action\nSemantics Learning (ASL), a novel learning framework, where the learning\nobjective is capturing the semantics of the ground truth actions. Specifically,\ninspired by the programming language theory, we define the action semantics for\nApp agents as the state transition induced by the action in the user interface.\nWith this insight, ASL employs a novel SEmantic Estimator (SEE) to compute a\nsemantic reward to train the App agents in generating actions aligned with the\nsemantics of ground truth actions, even when the syntactic forms differ. To\nsupport the effectiveness of ASL, we theoretically demonstrate the superior\nrobustness of ASL for the OOD problem compared with the existing syntax\nlearning paradigm. Extensive experiments on offline and online smartphone App\noperation benchmarks show that ASL significantly improves the accuracy and\ngeneralisation of App agents over existing methods.", "AI": {"tldr": "本文提出了一种名为动作语义学习（ASL）的新框架，通过捕捉用户界面中动作的语义而非语法形式，显著提升了App代理的准确性和泛化能力。", "motivation": "现有基于提示的解决方案依赖昂贵的闭源LLM API，而微调小型开源LLM时，传统的语法学习范式易受分布外（OOD）问题影响，导致性能下降。", "method": "ASL框架引入语义评估器（SEE），通过计算语义奖励来训练App代理，使其生成与真实动作语义一致的行为，即使语法形式不同。该方法从编程语言理论中汲取灵感，将动作语义定义为用户界面中的状态转换。", "result": "在离线和在线智能手机App操作基准测试中，ASL显著优于现有方法，证明了其在OOD问题上的更强鲁棒性。", "conclusion": "ASL通过语义学习范式有效解决了传统语法学习的局限性，为App代理的准确性和泛化性能提供了理论保障和实证支持。"}}
{"id": "2506.17650", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17650", "abs": "https://arxiv.org/abs/2506.17650", "authors": ["Haihao Lu", "Wanyu Zhang"], "title": "Enhanced PDHG for Linear Programming with Online Preconditioning", "comment": null, "summary": "We present an online preconditioning technique for the primal-dual hybrid\ngradient (PDHG) algorithm for linear programming (LP). The method adaptively\nupdates primal and dual preconditioners using an online optimization framework.\nTo improve its practical performance, we introduce several algorithmic\nenhancements, including using normalized online loss functions and updating\npreconditioners infrequently. We implement the technique on top of vanilla PDHG\nand the GPU-based LP solver cuPDLP.jl, and benchmark its performance on\nstandard LP datasets. Our numerical experiments demonstrate that online\npreconditioning effectively reduces both iteration counts and overall solving\ntime.", "AI": {"tldr": "本文提出了一种用于线性规划原始-对偶混合梯度(PDHG)算法的在线预处理技术，通过自适应更新预处理矩阵显著提升了求解效率。", "motivation": "为提高PDHG算法在求解线性规划问题时的实际性能，需要开发能动态调整预处理策略的方法。", "method": "采用在线优化框架自适应更新原始和对偶预处理矩阵，引入标准化损失函数和低频更新等增强策略，并在GPU求解器cuPDLP.jl上实现。", "result": "数值实验表明，该技术能有效减少迭代次数和总求解时间。", "conclusion": "在线预处理技术显著提升了PDHG算法求解线性规划问题的计算效率，具有实际应用价值。"}}
{"id": "2506.17318", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17318", "abs": "https://arxiv.org/abs/2506.17318", "authors": ["Atharv Singh Patlan", "Ashwin Hebbar", "Pramod Viswanath", "Prateek Mittal"], "title": "Context manipulation attacks : Web agents are susceptible to corrupted memory", "comment": "10 pages, 6 figures", "summary": "Autonomous web navigation agents, which translate natural language\ninstructions into sequences of browser actions, are increasingly deployed for\ncomplex tasks across e-commerce, information retrieval, and content discovery.\nDue to the stateless nature of large language models (LLMs), these agents rely\nheavily on external memory systems to maintain context across interactions.\nUnlike centralized systems where context is securely stored server-side, agent\nmemory is often managed client-side or by third-party applications, creating\nsignificant security vulnerabilities. This was recently exploited to attack\nproduction systems.\n  We introduce and formalize \"plan injection,\" a novel context manipulation\nattack that corrupts these agents' internal task representations by targeting\nthis vulnerable context. Through systematic evaluation of two popular web\nagents, Browser-use and Agent-E, we show that plan injections bypass robust\nprompt injection defenses, achieving up to 3x higher attack success rates than\ncomparable prompt-based attacks. Furthermore, \"context-chained injections,\"\nwhich craft logical bridges between legitimate user goals and attacker\nobjectives, lead to a 17.7% increase in success rate for privacy exfiltration\ntasks. Our findings highlight that secure memory handling must be a first-class\nconcern in agentic systems.", "AI": {"tldr": "论文提出了一种针对自主网页导航代理的新型攻击方式——计划注入（plan injection），通过操纵代理的上下文记忆系统，成功绕过现有防护措施，攻击成功率显著高于传统提示注入攻击。", "motivation": "由于大型语言模型（LLM）的无状态特性，网页导航代理依赖外部记忆系统维护交互上下文。这些客户端或第三方管理的记忆系统存在严重安全漏洞，近期已被实际攻击利用。", "method": "研究者形式化定义了计划注入攻击，并系统评估了Browser-use和Agent-E两款流行网页代理。通过构建上下文链式注入（context-chained injections），在用户目标与攻击目标间建立逻辑桥梁。", "result": "计划注入攻击成功绕过现有提示注入防御，攻击成功率最高达到传统方法的3倍。在隐私窃取任务中，上下文链式注入使成功率提升17.7%。", "conclusion": "研究结果表明，代理系统的安全内存处理必须作为首要考虑因素，当前系统的上下文管理机制存在严重安全隐患。"}}
{"id": "2506.18113", "categories": ["math.CO", "math.AG", "52C35, 52C10, 05D40"], "pdf": "https://arxiv.org/pdf/2506.18113", "abs": "https://arxiv.org/abs/2506.18113", "authors": ["Zichao Dong", "Zijian Xu"], "title": "Large grid subsets without many cospherical points", "comment": "9 pages", "summary": "Motivated by intuitions from projective algebraic geometry, we provide a\nnovel construction of subsets of the $d$-dimensional grid $[n]^d$ of size $n -\no(n)$ with no $d + 2$ points on a sphere or a hyperplane. For $d = 2$, this\nimproves the previously best known lower bound of $n/4$ toward the\nErd\\H{o}s--Purdy problem due to Thiele in 1995. For $d \\ge 3$, this improves\nthe recent $\\Omega \\bigl( n^{\\frac{3}{d+1}-o(1)} \\bigr)$ bound due to Suk and\nWhite, confirming their conjectured $\\Omega \\bigl( n^{\\frac{d}{d+1}} \\bigr)$\nbound in a strong sense, and asymptotically resolves the generalized\nErd\\H{o}s--Purdy problem posed by Brass, Moser, and Pach.", "AI": {"tldr": "本文基于射影代数几何的直觉，提出了一种在$d$维网格$[n]^d$中构造大小为$n - o(n)$的子集的新方法，该子集不包含$d + 2$个共球或共超平面的点。对于$d = 2$，这改进了Thiele在1995年提出的Erd\\H{o}s--Purdy问题的最佳下界$n/4$；对于$d \\ge 3$，这改进了Suk和White最近提出的$\\Omega \\bigl( n^{\\frac{3}{d+1}-o(1)} \\bigr)$下界，并强有力地证实了他们猜测的$\\Omega \\bigl( n^{\\frac{d}{d+1}} \\bigr)$下界，渐进解决了Brass、Moser和Pach提出的广义Erd\\H{o}s--Purdy问题。", "motivation": "研究动机源于射影代数几何的直觉，旨在解决Erd\\H{o}s--Purdy问题及其广义形式，即在高维网格中寻找不包含特定共球或共超平面点集的子集。", "method": "本文提出了一种新颖的构造方法，通过在$d$维网格$[n]^d$中构造大小为$n - o(n)$的子集，确保该子集不包含$d + 2$个共球或共超平面的点。", "result": "对于$d = 2$，结果改进了Thiele在1995年提出的下界$n/4$；对于$d \\ge 3$，结果改进了Suk和White的$\\Omega \\bigl( n^{\\frac{3}{d+1}-o(1)} \\bigr)$下界，并证实了他们的猜测$\\Omega \\bigl( n^{\\frac{d}{d+1}} \\bigr)$。", "conclusion": "本文不仅改进了Erd\\H{o}s--Purdy问题及其广义形式的下界，还渐进解决了Brass、Moser和Pach提出的问题，为高维网格中的点集几何问题提供了新的理论支持。"}}
{"id": "2506.18874", "categories": ["math.NT", "math.AG", "11G05 (Primary) 11G15, 11N45 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.18874", "abs": "https://arxiv.org/abs/2506.18874", "authors": ["Adrian Barquero-Sanchez", "Daniel Mora-Mora"], "title": "Counting elliptic curves over $\\mathbb{Q}$ with bounded naive height", "comment": "27 pages, 6 tables, 1 figure; code available on GitHub to reproduce\n  all computations", "summary": "In this paper, we give exact and asymptotic formulas for counting elliptic\ncurves $ E_{A,B} \\colon y^2 = x^3 + Ax + B $ with $ A, B \\in \\mathbb{Z} $,\nordered by naive height. We study the family of all such curves and also\nseveral natural subfamilies, including those with fixed $ j $-invariant and\nthose with complex multiplication (CM). In particular, we provide formulas for\ntwo commonly used normalizations of the naive height appearing in the\nliterature: the calibrated naive height, defined by \\[\nH^{\\mathrm{cal}}(E_{A,B}) := \\max\\{ 4|A|^3, 27B^2 \\}, \\] and the uncalibrated\nnaive height, defined by \\[ H^{\\mathrm{ncal}}(E_{A,B}) := \\max\\{ |A|^3, B^2 \\}.\n\\] In fact, we prove our theorems with respect to the more general naive height\n$H_{\\alpha, \\beta}(E_{A,B}) := \\max\\{ \\alpha |A|^3, \\beta B^2 \\}$, defined for\narbitrary positive real numbers $\\alpha, \\beta \\in \\mathbb{R}_{> 0}$.\n  As part of our approach, we give a completely explicit parametrization of the\nset of curves $ E_{A,B} $ with fixed $ j $-invariant and bounded naive height,\ndescribing them as twists of the curve $ E_{A_j, B_j} $ of minimal naive height\nfor the given $ j $-invariant. We also include tables comparing and verifying\nour theoretical predictions with exact counts obtained via exhaustive computer\nsearches, and we compute data for CM elliptic curves of naive height up to $\n10^{30} $. Code in SageMath is provided to compute all exact and asymptotic\nformulas appearing in the paper.", "AI": {"tldr": "本文提供了椭圆曲线$E_{A,B} \\colon y^2 = x^3 + Ax + B$在朴素高度排序下的精确与渐近计数公式，涵盖所有曲线及特定子族（如固定$j$-不变量或复乘曲线），并比较了两种常见朴素高度归一化方法的公式。", "motivation": "研究椭圆曲线在朴素高度下的计数问题，旨在为不同归一化方法（校准与非校准朴素高度）提供统一的理论框架，并验证理论预测与实际计算数据的一致性。", "method": "通过显式参数化固定$j$-不变量且高度有界的曲线集，将其表示为最小高度曲线的扭形式，并结合SageMath代码实现精确与渐近公式的计算。", "result": "推导出广义朴素高度$H_{\\alpha, \\beta}(E_{A,B}) := \\max\\{ \\alpha |A|^3, \\beta B^2 \\}$的计数公式，提供高达$10^{30}$的复乘曲线数据，并通过计算机搜索验证理论结果。", "conclusion": "论文建立了椭圆曲线计数问题的通用理论工具，其公式适用于任意归一化参数，且开源代码为后续研究提供了可扩展的计算基础。"}}
{"id": "2506.17784", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17784", "abs": "https://arxiv.org/abs/2506.17784", "authors": ["Song Wang", "Zhen Tan", "Zihan Chen", "Shuang Zhou", "Tianlong Chen", "Jundong Li"], "title": "AnyMAC: Cascading Flexible Multi-Agent Collaboration via Next-Agent Prediction", "comment": null, "summary": "Recent progress in large language model (LLM)-based multi-agent collaboration\nhighlights the power of structured communication in enabling collective\nintelligence. However, existing methods largely rely on static or graph-based\ninter-agent topologies, lacking the potential adaptability and flexibility in\ncommunication. In this work, we propose a new framework that rethinks\nmulti-agent coordination through a sequential structure rather than a graph\nstructure, offering a significantly larger topology space for multi-agent\ncommunication. Our method focuses on two key directions: (1) Next-Agent\nPrediction, which selects the most suitable agent role at each step, and (2)\nNext-Context Selection (NCS), which enables each agent to selectively access\nrelevant information from any previous step. Together, these components\nconstruct task-adaptive communication pipelines that support both role\nflexibility and global information flow. Extensive evaluations across multiple\nbenchmarks demonstrate that our approach achieves superior performance while\nsubstantially reducing communication overhead.", "AI": {"tldr": "本文提出了一种基于顺序结构的新型多智能体协作框架，通过动态角色选择和上下文筛选实现高效通信，显著提升了性能并降低了通信开销。", "motivation": "现有基于图结构的智能体通信拓扑缺乏适应性，限制了集体智能的潜力。需要更灵活的通信机制来优化多智能体协作效率。", "method": "采用顺序通信结构：1) 下一步智能体预测动态选择最优角色；2) 下一上下文选择机制(NCS)实现历史信息精准筛选，构建任务自适应的通信管道。", "result": "在多个基准测试中，该方法在保持性能优势的同时显著减少了通信开销，验证了顺序通信结构的有效性。", "conclusion": "顺序通信框架通过角色灵活性与全局信息流的结合，为多智能体系统提供了更优的协作范式，推动了集体智能的发展。"}}
{"id": "2506.17666", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17666", "abs": "https://arxiv.org/abs/2506.17666", "authors": ["Harshit M. Ratandhara", "Mohit Kumar"], "title": "An Analytical Framework for the Linear Best-Worst Method and its Application to Achieve Sustainable Development Goals--Oriented Agri-Food Supply Chains", "comment": null, "summary": "The Best-Worst Method (BWM) has emerged as a prominent multi-criteria\ndecision-making method for determining the weights of the decision criteria.\nAmong various BWM models, this research focuses on the linear model of the BWM.\nThis model calculates weights by solving an optimization problem, necessitating\noptimization software. In this article, we present a novel framework that\nsolves this optimization model mathematically, yielding an analytical\nexpression for the resultant weights, thus eliminating the requirement for an\noptimization software. The proposed approach enhances both the conceptual\nclarity of the underlying optimization process and the computational efficiency\nof the model. Based of this framework, we demonstrate the model's limited\nresponse to data variations, i.e., its lower data sensitivity. We also compute\nthe values of consistency index for the linear BWM, which are required to\ncalculate the consistency ratio - a consistency indicator used for assessing\ninconsistency in input data. Finally, we illustrate the validity and\napplicability of the proposed approach through five numerical examples and a\nreal-world case study that ranks eighteen drivers across three categories -\nIndustry 4.0, sustainability, and circular economy - in relation to sustainable\ndevelopment goals-driven agri-food supply chains.", "AI": {"tldr": "本文提出了一种新的线性BWM框架，通过数学解析方法直接计算权重，无需优化软件，提高了计算效率和概念清晰度，并验证了模型对数据变化的低敏感性和一致性指标的计算。", "motivation": "现有线性BWM模型需依赖优化软件求解权重，本研究旨在开发一种数学解析框架，消除对优化工具的依赖，提升模型的计算效率和透明度。", "method": "通过数学推导构建解析表达式直接计算权重，避免优化求解过程；推导线性BWM的一致性指标值，并通过5个数值案例和1个真实案例（18个驱动因素的可持续农业供应链排名）验证方法。", "result": "提出的解析框架显著提升计算效率，证明模型对数据变化敏感性较低，并成功计算出用于评估数据一致性的一致性比率所需指标。", "conclusion": "该解析方法不仅简化了线性BWM的实施流程，其低数据敏感性和一致性验证能力使其在可持续供应链等多准则决策场景中具有实用价值。"}}
{"id": "2506.17329", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17329", "abs": "https://arxiv.org/abs/2506.17329", "authors": ["Pedro H. Lui", "Lucas P. Siqueira", "Juliano F. Kazienko", "Vagner E. Quincozes", "Silvio E. Quincozes", "Daniel Welfer"], "title": "On the Performance of Cyber-Biomedical Features for Intrusion Detection in Healthcare 5.0", "comment": "12 pages, 7 figures, conference", "summary": "Healthcare 5.0 integrates Artificial Intelligence (AI), the Internet of\nThings (IoT), real-time monitoring, and human-centered design toward\npersonalized medicine and predictive diagnostics. However, the increasing\nreliance on interconnected medical technologies exposes them to cyber threats.\nMeanwhile, current AI-driven cybersecurity models often neglect biomedical\ndata, limiting their effectiveness and interpretability. This study addresses\nthis gap by applying eXplainable AI (XAI) to a Healthcare 5.0 dataset that\nintegrates network traffic and biomedical sensor data. Classification outputs\nindicate that XGBoost achieved 99% F1-score for benign and data alteration, and\n81% for spoofing. Explainability findings reveal that network data play a\ndominant role in intrusion detection whereas biomedical features contributed to\nspoofing detection, with temperature reaching a Shapley values magnitude of\n0.37.", "AI": {"tldr": "本研究应用可解释人工智能（XAI）分析Healthcare 5.0数据集，结合网络流量与生物医学传感器数据，XGBoost模型在入侵检测中表现优异，F1分数达99%。", "motivation": "Healthcare 5.0依赖互联医疗技术，但面临网络安全威胁，且现有AI驱动安全模型忽视生物医学数据，影响效果与可解释性。", "method": "采用可解释AI（XAI）技术，整合网络流量与生物医学传感器数据，使用XGBoost模型进行分类分析。", "result": "XGBoost模型对良性数据与数据篡改的F1分数达99%，对欺骗攻击为81%；网络数据主导入侵检测，体温特征对欺骗检测贡献显著（Shapley值0.37）。", "conclusion": "XAI能有效提升Healthcare 5.0网络安全，网络数据与生物医学特征的结合增强模型性能与可解释性。"}}
{"id": "2506.18235", "categories": ["math.CO", "05C55, 05D10"], "pdf": "https://arxiv.org/pdf/2506.18235", "abs": "https://arxiv.org/abs/2506.18235", "authors": ["Zhiyu Cheng", "Zhidan Luo", "Pingge Chen"], "title": "All Ramsey critical graphs for a large tree versus $tK_{m}$", "comment": null, "summary": "Let $H, H_{1}$ and $H_{2}$ be graphs, and let $H\\rightarrow (H_{1}, H_{2})$\ndenote that any red-blue coloring of $E(H)$ yields a red copy of $H_{1}$ or a\nblue copy of $H_{2}$. The Ramsey number for $H_{1}$ versus $H_{2}$, $r(H_{1},\nH_{2})$, is the minimum integer $N$ such that $K_{N}\\rightarrow (H_{1},\nH_{2})$. The Ramsey critical graph $H$ for $H_{1}$ versus $H_{2}$ is a red-blue\nedge-colored $K_{N- 1}$ such that $H\\not\\rightarrow (H_{1}, H_{2})$, where $N=\nr(H_{1}, H_{2})$. In this paper, we characterize all Ramsey critical graphs for\na large tree versus $tK_{m}$. As a corollary, we determine the star-critical\nRamsey number for a large tree versus $tK_{m}$.", "AI": {"tldr": "本文研究了拉姆齐临界图在大树与$tK_{m}$之间的性质，并确定了星临界拉姆齐数。", "motivation": "研究拉姆齐临界图的性质有助于深入理解拉姆齐理论中的极值问题，特别是大树与多部图之间的关系。", "method": "通过分析红蓝边着色的完全图$K_{N-1}$，寻找不包含红色大树或蓝色$tK_{m}$的临界结构。", "result": "完整刻画了大树与$tK_{m}$之间的所有拉姆齐临界图，并推导出相应的星临界拉姆齐数。", "conclusion": "该研究为拉姆齐理论中大树与多部图的临界性质提供了完整的理论框架，并解决了星临界拉姆齐数的计算问题。"}}
{"id": "2506.17788", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "I.2.1; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.17788", "abs": "https://arxiv.org/abs/2506.17788", "authors": ["Shahab Rahimirad", "Guven Gergerli", "Lucia Romero", "Angela Qian", "Matthew Lyle Olson", "Simon Stepputtis", "Joseph Campbell"], "title": "Bayesian Social Deduction with Graph-Informed Language Models", "comment": "32 pages, 10 figures. Under review", "summary": "Social reasoning - inferring unobservable beliefs and intentions from partial\nobservations of other agents - remains a challenging task for large language\nmodels (LLMs). We evaluate the limits of current reasoning language models in\nthe social deduction game Avalon and find that while the largest models\ndemonstrate strong performance, they require extensive test-time inference and\ndegrade sharply when distilled to smaller, real-time-capable variants. To\naddress this, we introduce a hybrid reasoning framework that externalizes\nbelief inference to a structured probabilistic model, while using an LLM for\nlanguage understanding and interaction. Our approach achieves competitive\nperformance with much larger models in Agent-Agent play and, notably, is the\nfirst language agent to defeat human players in a controlled study - achieving\na 67% win rate and receiving higher qualitative ratings than both reasoning\nbaselines and human teammates. We release code, models, and a dataset to\nsupport future work on social reasoning in LLM agents, which can be found at\nhttps://camp-lab-purdue.github.io/bayesian-social-deduction/", "AI": {"tldr": "本文评估了大语言模型（LLMs）在社交推理游戏Avalon中的表现，发现大模型虽强但计算成本高，小模型性能骤降。作者提出混合推理框架，结合结构化概率模型与LLM，在Agent-Agent对抗中表现优异，并首次在受控实验中击败人类玩家（67%胜率）。", "motivation": "当前大语言模型在社交推理（从部分观察推断他人信念与意图）任务中仍面临挑战，尤其在实时场景下小模型性能显著下降。研究旨在突破这一限制。", "method": "提出混合推理框架：将信念推断外化至结构化概率模型，同时利用LLM处理语言理解与交互。该方法在Avalon游戏中实现高效社交推理。", "result": "混合框架在Agent-Agent对抗中媲美更大模型，并以67%胜率首次击败人类玩家，定性评分高于基线模型及人类队友。开源代码、模型及数据集。", "conclusion": "通过分离信念推断与语言处理，混合框架显著提升LLM社交推理效率，为实时应用提供可行方案。成果发布于https://camp-lab-purdue.github.io/bayesian-social-deduction/。"}}
{"id": "2506.17696", "categories": ["math.OC", "cs.NA", "math.NA", "stat.ML", "I.6.1; G.1.2; G.1.6"], "pdf": "https://arxiv.org/pdf/2506.17696", "abs": "https://arxiv.org/abs/2506.17696", "authors": ["Du-Yi Wang", "Guo Liang", "Guangwu Liu", "Kun Zhang"], "title": "Regular Tree Search for Simulation Optimization", "comment": null, "summary": "Tackling simulation optimization problems with non-convex objective functions\nremains a fundamental challenge in operations research. In this paper, we\npropose a class of random search algorithms, called Regular Tree Search, which\nintegrates adaptive sampling with recursive partitioning of the search space.\nThe algorithm concentrates simulations on increasingly promising regions by\niteratively refining a tree structure. A tree search strategy guides sampling\ndecisions, while partitioning is triggered when the number of samples in a leaf\nnode exceeds a threshold that depends on its depth. Furthermore, a specific\ntree search strategy, Upper Confidence Bounds applied to Trees (UCT), is\nemployed in the Regular Tree Search. We prove global convergence under\nsub-Gaussian noise, based on assumptions involving the optimality gap, without\nrequiring continuity of the objective function. Numerical experiments confirm\nthat the algorithm reliably identifies the global optimum and provides accurate\nestimates of its objective value.", "AI": {"tldr": "本文提出了一种名为正则树搜索的随机搜索算法，用于解决非凸目标函数的仿真优化问题，通过自适应采样和搜索空间递归分区实现全局收敛。", "motivation": "非凸目标函数的仿真优化问题是运筹学中的基本挑战，现有方法难以保证全局最优解的可靠性。", "method": "算法结合自适应采样与递归分区，通过树结构迭代细化，采用树搜索策略（如UCT）指导采样，并在叶节点样本数超过深度相关阈值时触发分区。", "result": "在次高斯噪声下证明了全局收敛性，数值实验表明算法能可靠找到全局最优解并准确估计目标值。", "conclusion": "正则树搜索算法为非凸仿真优化问题提供了有效的解决方案，无需目标函数连续性假设即可保证收敛。"}}
{"id": "2506.17336", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17336", "abs": "https://arxiv.org/abs/2506.17336", "authors": ["Yubeen Bae", "Minchan Kim", "Jaejin Lee", "Sangbum Kim", "Jaehyung Kim", "Yejin Choi", "Niloofar Mireshghallah"], "title": "Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases", "comment": "29 pages", "summary": "Large language models (LLMs) are increasingly used as personal agents,\naccessing sensitive user data such as calendars, emails, and medical records.\nUsers currently face a trade-off: They can send private records, many of which\nare stored in remote databases, to powerful but untrusted LLM providers,\nincreasing their exposure risk. Alternatively, they can run less powerful\nmodels locally on trusted devices. We bridge this gap. Our Socratic\nChain-of-Thought Reasoning first sends a generic, non-private user query to a\npowerful, untrusted LLM, which generates a Chain-of-Thought (CoT) prompt and\ndetailed sub-queries without accessing user data. Next, we embed these\nsub-queries and perform encrypted sub-second semantic search using our\nHomomorphically Encrypted Vector Database across one million entries of a\nsingle user's private data. This represents a realistic scale of personal\ndocuments, emails, and records accumulated over years of digital activity.\nFinally, we feed the CoT prompt and the decrypted records to a local language\nmodel and generate the final response. On the LoCoMo long-context QA benchmark,\nour hybrid framework, combining GPT-4o with a local Llama-3.2-1B model,\noutperforms using GPT-4o alone by up to 7.1 percentage points. This\ndemonstrates a first step toward systems where tasks are decomposed and split\nbetween untrusted strong LLMs and weak local ones, preserving user privacy.", "AI": {"tldr": "论文提出了一种结合强大但不信任的LLM与本地弱模型的方法，通过苏格拉底式思维链推理和同态加密向量数据库，在保护用户隐私的同时提升问答性能。", "motivation": "用户在使用LLM处理敏感数据时面临隐私风险，现有方案要么依赖不可信的强大模型，要么只能使用本地弱模型。本文旨在解决这一隐私与性能的权衡问题。", "method": "1) 将通用查询发送至不可信LLM生成思维链提示和子查询；2) 使用同态加密向量数据库对用户百万级私有数据进行加密语义搜索；3) 将提示和解密数据输入本地模型生成最终响应。", "result": "在LoCoMo长上下文QA基准测试中，GPT-4o与本地Llama-3.2-1B的混合框架比单独使用GPT-4o性能提升最高达7.1个百分点。", "conclusion": "该框架首次实现了任务在不可信强LLM与可信弱本地模型间的分解协作，为保护隐私的混合LLM系统迈出了重要一步。"}}
{"id": "2506.18345", "categories": ["math.CO", "math.PR", "05C35, 05C76"], "pdf": "https://arxiv.org/pdf/2506.18345", "abs": "https://arxiv.org/abs/2506.18345", "authors": ["Boštjan Brešar", "Jaka Hedžet", "Michael A. Henning"], "title": "On polluted bootstrap percolation in Cartesian grids", "comment": "11 pages, 3 figures", "summary": "Given a graph $G$ and assuming that some vertices of $G$ are infected, the\n$r$-neighbor bootstrap percolation rule makes an uninfected vertex $v$ infected\nif $v$ has at least $r$ infected neighbors. The $r$-percolation number, $m(G,\nr)$, of $G$ is the minimum cardinality of a set of initially infected vertices\nin $G$ such that after continuously performing the $r$-neighbor bootstrap\npercolation rule each vertex of $G$ eventually becomes infected. In this paper,\nwe continue the study of polluted bootstrap percolation introduced and studied\nby Gravner and McDonald [Bootstrap percolation in a polluted environment. J.\\\nStat\\ Physics 87 (1997) 915--927] where in this variant some vertices are\npermanently in the non-infected state. We study an extremal (combinatorial)\nversion of the bootstrap percolation problem in a polluted environment, where\nour main focus is on the class of grid graphs, that is, the Cartesian product\n$P_m \\square P_n$ of two paths $P_m$ and $P_n$ on $m$ and $n$ vertices,\nrespectively. Given a number of polluted vertices in a Cartesian grid we\nestablish a closed formula for the minimum $2$-neighbor bootstrap percolation\nnumber of the polluted grid, and obtain a lower bound for the other extreme.", "AI": {"tldr": "本文研究了污染环境下的极值自举渗透问题，重点关注网格图类，特别是路径的笛卡尔积$P_m \\square P_n$。在给定污染顶点数量的情况下，建立了污染网格的最小2-邻居自举渗透数的封闭公式，并为其他极端情况提供了下界。", "motivation": "研究污染环境下的自举渗透问题，旨在理解在部分顶点永久处于非感染状态时，图的最小初始感染集大小如何变化，这对于理解网络中的信息传播和病毒扩散有重要意义。", "method": "采用极值组合方法，研究了网格图类（即路径的笛卡尔积$P_m \\square P_n$）在污染环境下的自举渗透行为。通过分析污染顶点的分布和数量，推导了最小2-邻居自举渗透数的封闭公式。", "result": "对于给定的污染顶点数量，建立了污染网格的最小2-邻居自举渗透数的封闭公式，并为其他极端情况提供了一个下界。", "conclusion": "本文的结果为污染环境下的自举渗透问题提供了理论支持，特别是在网格图类中，为理解网络中的信息传播和病毒扩散提供了新的见解。"}}
{"id": "2506.17792", "categories": ["cs.AI", "cs.LO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.17792", "abs": "https://arxiv.org/abs/2506.17792", "authors": ["Alexandros Evangelidis", "Gricel Vázquez", "Simos Gerasimou"], "title": "Efficient Strategy Synthesis for MDPs via Hierarchical Block Decomposition", "comment": null, "summary": "Software-intensive systems, such as software product lines and robotics,\nutilise Markov decision processes (MDPs) to capture uncertainty and analyse\nsequential decision-making problems. Despite the usefulness of conventional\npolicy synthesis methods, they fail to scale to large state spaces. Our\napproach addresses this issue and accelerates policy synthesis in large MDPs by\ndynamically refining the MDP and iteratively selecting the most fragile MDP\nregions for refinement. This iterative procedure offers a balance between\naccuracy and efficiency, as refinement occurs only when necessary. Through a\ncomprehensive empirical evaluation comprising diverse case studies and MDPs up\nto 1M states, we demonstrate significant performance improvements yielded by\nour approach compared to the leading probabilistic model checker PRISM (up to\n2x), thus offering a very competitive solution for real-world policy synthesis\ntasks in larger MDPs.", "AI": {"tldr": "本文提出了一种动态优化马尔可夫决策过程(MDP)的方法，通过迭代选择最脆弱区域进行细化，显著提升大规模MDP策略合成的效率，相比PRISM工具性能提升可达2倍。", "motivation": "传统策略合成方法在处理大规模状态空间时效率不足，难以应对软件产品线、机器人等复杂系统中的不确定性决策问题。", "method": "采用动态细化MDP的迭代方法，仅对必要的最脆弱区域进行细化，在精度与效率之间取得平衡。", "result": "在包含百万级状态的多样化案例研究中，本方法相较主流概率模型检测工具PRISM实现最高2倍的性能提升。", "conclusion": "该动态细化方法为大规模MDP的实际策略合成任务提供了高效解决方案，在保持精度的同时显著提升计算效率。"}}
{"id": "2506.17698", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17698", "abs": "https://arxiv.org/abs/2506.17698", "authors": ["Jelena Diakonikolas"], "title": "Pushing the Complexity Boundaries of Fixed-Point Equations: Adaptation to Contraction and Controlled Expansion", "comment": null, "summary": "Fixed-point equations with Lipschitz operators have been studied for more\nthan a century, and are central to problems in mathematical optimization, game\ntheory, economics, and dynamical systems, among others. When the Lipschitz\nconstant of the operator is larger than one (i.e., when the operator is\nexpansive), it is well known that approximating fixed-point equations becomes\ncomputationally intractable even in basic finite-dimensional settings. In this\nwork, we aim to push these complexity boundaries by introducing algorithms that\ncan address problems with mildly expansive (i.e., with Lipschitz constant\nslightly larger than one) operators not excluded by existing lower bounds,\nattaining the best possible fixed-point error up to universal constants. We\nfurther introduce a class of \\emph{gradually expansive operators} that allow\nfor constant (up to $\\approx 1.4$) expansion between points, for which we prove\nconvergence to $\\epsilon$-approximate fixed points in order-$(1/\\epsilon)$\niterations for $\\epsilon > 0.$ Our algorithms automatically adapt to the\nLipschitz constant of the operator and attain optimal oracle complexity bounds\nwhen the input operator is nonexpansive or contractive. Our results apply to\ngeneral, possibly infinite-dimensional normed vector spaces and can be extended\nto positively curved geodesic metric spaces.", "AI": {"tldr": "本文针对Lipschitz常数略大于1的扩张算子，提出了新算法以逼近不动点方程，并引入逐渐扩张算子类，证明了在有限迭代次数内收敛至$\\epsilon$-近似解。", "motivation": "传统方法在处理Lipschitz常数大于1的扩张算子时计算困难，本研究旨在突破这一限制，解决优化、博弈论等领域中的关键问题。", "method": "设计了自适应Lipschitz常数的算法，并引入逐渐扩张算子类，允许点间常数扩张（约1.4倍），理论证明其可在$O(1/\\epsilon)$次迭代内收敛。", "result": "算法在非扩张或压缩算子下达到最优预言复杂度，适用于无限维赋范空间，并可扩展至正曲率测地度量空间。", "conclusion": "该研究突破了扩张算子的计算瓶颈，为广泛数学问题提供了高效逼近工具，具有理论与应用双重价值。"}}
{"id": "2506.17349", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17349", "abs": "https://arxiv.org/abs/2506.17349", "authors": ["Akarsh K Nair", "Shanik Hubert Satheesh Kumar.", "Deepti Gupta"], "title": "AndroIDS : Android-based Intrusion Detection System using Federated Learning", "comment": null, "summary": "The exponential growth of android-based mobile IoT systems has significantly\nincreased the susceptibility of devices to cyberattacks, particularly in smart\nhomes, UAVs, and other connected mobile environments. This article presents a\nfederated learning-based intrusion detection framework called AndroIDS that\nleverages system call traces as a personalized and privacy-preserving data\nsource. Unlike conventional centralized approaches, the proposed method enables\ncollaborative anomaly detection without sharing raw data, thus preserving user\nprivacy across distributed nodes. A generalized system call dataset was\ngenerated to reflect realistic android system behavior and serves as the\nfoundation for experimentation. Extensive evaluation demonstrates the\neffectiveness of the FL model under both IID and non-IID conditions, achieving\nan accuracy of 96.46 % and 92.87 %, and F1-scores of 89 % and 86 %,\nrespectively. These results highlight the models robustness to data\nheterogeneity, with only a minor performance drop in the non-IID case. Further,\na detailed comparison with centralized deep learning further illustrates\ntrade-offs in detection performance and deployment feasibility. Overall, the\nresults validate the practical applicability of the proposed approach for\nsecure and scalable intrusion detection in real-world mobile IoT scenarios.", "AI": {"tldr": "本文提出了一种基于联邦学习的入侵检测框架AndroIDS，利用系统调用轨迹作为隐私保护的数据源，在移动物联网环境中实现高效且隐私安全的异常检测。", "motivation": "随着安卓移动物联网设备的指数级增长，智能家居、无人机等场景面临日益严重的网络攻击威胁，传统集中式检测方法存在隐私泄露风险，亟需开发隐私保护的分布式检测方案。", "method": "采用联邦学习框架，通过系统调用轨迹构建个性化数据集；建立通用系统调用数据集模拟真实场景，在IID和非IID数据分布下验证模型性能，并与集中式深度学习进行对比。", "result": "联邦学习模型在IID和非IID条件下分别达到96.46%和92.87%的准确率，F1分数分别为89%和86%；非IID场景仅导致轻微性能下降，证明模型对数据异构性具有鲁棒性。", "conclusion": "该框架在保护用户隐私的同时实现了高效的入侵检测，实验结果表明其适用于现实移动物联网场景，为安全可扩展的分布式检测提供了可行方案。"}}
{"id": "2506.18700", "categories": ["math.CO", "05E30, 05E18"], "pdf": "https://arxiv.org/pdf/2506.18700", "abs": "https://arxiv.org/abs/2506.18700", "authors": ["Ian Seong"], "title": "Counting edges of different types in a local graph of a Grassmann graph", "comment": "22 pages, 3 figures", "summary": "Let $\\mathbb{F}_q$ denote a finite field with $q$ elements. Let $n,k$ denote\nintegers with $n>2k\\geq 6$. Let $V$ denote a vector space over $\\mathbb{F}_{q}$\nthat has dimension $n$. The vertex set of the Grassmann graph $J_q(n,k)$\nconsists of the $k$-dimensional subspaces of $V$. Two vertices of $J_q(n,k)$\nare adjacent whenever their intersection has dimension $k-1$. Let $\\partial$\ndenote the path-length distance function of $J_q(n,k)$. Pick vertices $x,y$ of\n$J_q(n,k)$ such that $1<\\partial(x,y)<k$. Let $\\Gamma(x)$ denote the local\ngraph of $x$ in $J_q(n,k)$. In this paper we define three types of edges in\n$\\Gamma(x)$, namely type $0$, type $+$, and type $-$; for adjacent $w,z\\in\n\\Gamma(x)$ such that $\\partial(w,y)=\\partial(z,y)$, the type of the edge $wz$\ndepends on the subspaces $w+z,w,z,w\\cap z$ and their intersections with $y$.\nOur general goal is to count the number of edges in $\\Gamma(x)$ for each type.\nConsider a two-vertex stabilizer $\\text{Stab}(x,y)$ in $GL(V)$; it is known\nthat the $\\text{Stab}(x,y)$-action on $\\Gamma(x)$ has five orbits. Pick two\norbits $\\mathcal{O},\\mathcal{N}$ that are not necessarily distinct; for a given\n$w\\in \\mathcal{O}$, we find the number of vertices in $z\\in \\mathcal{N}$ such\nthat the edge $wz$ has (i) type $0$, (ii) type $+$, (iii) type $-$. To find\nthese numbers, we make heavy use of a subalgebra $\\mathcal{H}$ of\n$\\text{Mat}_{P}(\\mathbb{C})$; the algebra $\\mathcal{H}$ contains matrices that\nare closely related to the five orbits of the $\\text{Stab}(x,y)$-action on\n$\\Gamma(x)$.", "AI": {"tldr": "本文研究了有限域上Grassmann图$J_q(n,k)$中局部图$\\Gamma(x)$的边类型及其计数问题，通过稳定子群作用与矩阵代数方法，分类并计算了不同类型边的数量。", "motivation": "研究Grassmann图中局部图边的分类与计数，旨在深入理解图的几何结构与群作用下的轨道性质，为相关代数与组合问题提供理论支持。", "method": "利用稳定子群$\\text{Stab}(x,y)$在$\\Gamma(x)$上的五轨道作用，结合子代数$\\mathcal{H}$的矩阵分析，对边类型（0、+、-）进行定义与计数。", "result": "通过代数方法，精确计算了局部图中不同类型边的数量，揭示了轨道间边的分布规律，并验证了与子代数$\\mathcal{H}$的关联性。", "conclusion": "该研究不仅完善了Grassmann图局部结构的理论框架，还为后续高维代数组合与群表示论的应用提供了新工具。"}}
{"id": "2506.17834", "categories": ["cs.AI", "cs.HC", "I.2.6; H.5.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.17834", "abs": "https://arxiv.org/abs/2506.17834", "authors": ["Carter Blair", "Kate Larson", "Edith Law"], "title": "Reflective Verbal Reward Design for Pluralistic Alignment", "comment": "9 pages, 3 figures, accepted to the IJCAI 2025 Human-Centred AI\n  track. Project repository at: https://osf.io/8yxf2/", "summary": "AI agents are commonly aligned with \"human values\" through reinforcement\nlearning from human feedback (RLHF), where a single reward model is learned\nfrom aggregated human feedback and used to align an agent's behavior. However,\nhuman values are not homogeneous--different people hold distinct and sometimes\nconflicting values. Aggregating feedback into a single reward model risks\ndisproportionately suppressing minority preferences. To address this, we\npresent a novel reward modeling approach for learning individualized reward\nmodels. Our approach uses a language model to guide users through reflective\ndialogues where they critique agent behavior and construct their preferences.\nThis personalized dialogue history, containing the user's reflections and\ncritiqued examples, is then used as context for another language model that\nserves as an individualized reward function (what we call a \"verbal reward\nmodel\") for evaluating new trajectories. In studies with 30 participants, our\nmethod achieved a 9-12% improvement in accuracy over non-reflective verbal\nreward models while being more sample efficient than traditional supervised\nlearning methods.", "AI": {"tldr": "本文提出了一种个性化奖励建模方法，通过反思对话构建个体化奖励函数，解决了传统RLHF方法因聚合人类反馈而压制少数偏好的问题。实验显示该方法比非反思模型准确率提升9-12%，且样本效率更高。", "motivation": "传统RLHF方法将人类反馈聚合为单一奖励模型，但人类价值观具有异质性，这种聚合可能导致少数群体偏好被压制。需要开发能保留个体差异的奖励建模方法。", "method": "使用语言模型引导用户进行反思对话，记录包含用户批评和偏好的对话历史，将其作为上下文构建个体化语言模型奖励函数（称为\"语言奖励模型\"）。", "result": "在30名参与者的实验中，该方法比非反思语言奖励模型准确率提高9-12%，且比传统监督学习方法更具样本效率。", "conclusion": "基于反思对话的个体化奖励建模能更准确地捕捉多元人类价值观，为AI对齐提供了尊重价值多样性的新途径。"}}
{"id": "2506.17814", "categories": ["math.OC", "49J40, 65K10, 65K15, 90C25, 90C33"], "pdf": "https://arxiv.org/pdf/2506.17814", "abs": "https://arxiv.org/abs/2506.17814", "authors": ["Roger Behling", "Yunier Bello-Cruz", "Alfredo Iusem", "Di Liu", "Luiz-Rafael Santos"], "title": "On circumcentered direct methods for monotone variational inequality problems", "comment": null, "summary": "The variational inequality problem (VIP) plays a central role in the theory\nand applications in continuous optimization. In particular, minimization\nproblems and KKT systems can be regard as VIPs. In this work, we present the\nfirst methods using circumcenter iterations for solving VIPs. The\ncircumcentered-reflection method (CRM) is a tool based on projections developed\nwith the aim of finding a point in the intersection of finitely many closed\nconvex sets. CRM has gone through enhancements and adaptations over the last\nfew years and was proven to be faster in many settings than competitors such as\nalternating projections and the Douglas-Rachford method. One of the nice\nfeatures of CRM is that it is able to deal with approximate projections, which\nis exactly what we enforced in this article theoretically and numerically. We\npresent both a circumcenter method for the VIP with paramonotone operator and\nmonotone operator, the first employing exact projections and the second\napproximate ones. Convergence results showing their convergence are\nestablished. Numerically, our experiments indicate good performance, including\nadvantages over the well-know extragradient method.", "AI": {"tldr": "本文首次提出使用外心迭代法（CRM）解决变分不等式问题（VIP），包括参数单调算子和单调算子两种情况，理论证明和数值实验均显示其优于传统方法。", "motivation": "变分不等式问题（VIP）在连续优化理论和应用中具有核心地位，传统方法如交替投影法和Douglas-Rachford法存在效率瓶颈，而CRM因其处理近似投影的能力成为有潜力的替代方案。", "method": "提出两种外心迭代法：1）针对参数单调算子VIP的精确投影版本；2）针对单调算子VIP的近似投影版本，均基于CRM框架并扩展其适用性。", "result": "理论证明了两种方法的收敛性，数值实验显示其性能优于著名的外梯度法，尤其在处理近似投影时展现显著优势。", "conclusion": "CRM框架成功扩展至VIP求解领域，为参数单调和单调算子问题提供了高效新工具，近似投影特性增强了实际应用潜力。"}}
{"id": "2506.17350", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17350", "abs": "https://arxiv.org/abs/2506.17350", "authors": ["Yinghao Wu", "Liyan Zhang"], "title": "CUBA: Controlled Untargeted Backdoor Attack against Deep Neural Networks", "comment": null, "summary": "Backdoor attacks have emerged as a critical security threat against deep\nneural networks in recent years. The majority of existing backdoor attacks\nfocus on targeted backdoor attacks, where trigger is strongly associated to\nspecific malicious behavior. Various backdoor detection methods depend on this\ninherent property and shows effective results in identifying and mitigating\nsuch targeted attacks. However, a purely untargeted attack in backdoor\nscenarios is, in some sense, self-weakening, since the target nature is what\nmakes backdoor attacks so powerful. In light of this, we introduce a novel\nConstrained Untargeted Backdoor Attack (CUBA), which combines the flexibility\nof untargeted attacks with the intentionality of targeted attacks. The\ncompromised model, when presented with backdoor images, will classify them into\nrandom classes within a constrained range of target classes selected by the\nattacker. This combination of randomness and determinedness enables the\nproposed untargeted backdoor attack to natively circumvent existing backdoor\ndefense methods. To implement the untargeted backdoor attack under controlled\nflexibility, we propose to apply logit normalization on cross-entropy loss with\nflipped one-hot labels. By constraining the logit during training, the\ncompromised model will show a uniform distribution across selected target\nclasses, resulting in controlled untargeted attack. Extensive experiments\ndemonstrate the effectiveness of the proposed CUBA on different datasets.", "AI": {"tldr": "本文提出了一种新型的约束无目标后门攻击（CUBA），结合了无目标攻击的灵活性和有目标攻击的意图性，通过限制目标类别范围实现可控攻击，有效规避现有防御方法。", "motivation": "现有后门攻击多为有目标攻击，其触发机制与特定恶意行为强关联，而纯粹无目标攻击因缺乏目标性而自弱。CUBA旨在结合两者优势，实现更灵活且难以检测的攻击方式。", "method": "采用对数归一化交叉熵损失函数与翻转独热标签，通过约束训练过程中的对数输出，使受感染模型在选定目标类别范围内呈现均匀分布，实现可控无目标攻击。", "result": "在不同数据集上的实验表明，CUBA能有效生成具有均匀类别分布的后门模型，成功规避现有防御方法的检测。", "conclusion": "CUBA通过融合随机性与确定性，为后门攻击提供了新范式，其设计思路对现有防御体系构成挑战，需进一步研究针对性防护策略。"}}
{"id": "2506.18782", "categories": ["math.CO", "05C30"], "pdf": "https://arxiv.org/pdf/2506.18782", "abs": "https://arxiv.org/abs/2506.18782", "authors": ["Padmini Mukkamala"], "title": "Triangle-free subsets of the Hypercube", "comment": "7 pages", "summary": "We study the problem of determining the largest subset of vertices of the $n$\ndimensional hypercube without three vertices at a Hamming distance of exactly\n$r$ from each other. In particular, we provide a lower bound of\n$\\frac{c2^n}{e^r2^{\\frac r2} (\\frac nr)^{\\frac{3r}{4}}}$ and an upper bound of\n$O(\\frac{r2^n}{n+1})$ when $2r \\le n$. In particular, when $r$ is a constant,\nthe lower bound is $\\frac{c2^n}{n^{3r/4}}$, while the upper bound is\n$\\frac{c'2^n}{n}$.", "AI": {"tldr": "研究了在$n$维超立方体中寻找最大顶点子集的问题，该子集不包含三个顶点彼此之间的汉明距离恰好为$r$。给出了下界$\\frac{c2^n}{e^r2^{\\frac r2} (\\frac nr)^{\\frac{3r}{4}}}$和上界$O(\\frac{r2^n}{n+1})$（当$2r \\le n$时）。特别地，当$r$为常数时，下界为$\\frac{c2^n}{n^{3r/4}}$，上界为$\\frac{c'2^n}{n}$。", "motivation": "研究超立方体中顶点子集的最大规模，避免三个顶点之间的汉明距离恰好为$r$，这是组合数学和图论中的一个重要问题。", "method": "通过组合分析和概率方法，推导了子集规模的下界和上界。", "result": "当$2r \\le n$时，给出了下界$\\frac{c2^n}{e^r2^{\\frac r2} (\\frac nr)^{\\frac{3r}{4}}}$和上界$O(\\frac{r2^n}{n+1})$。当$r$为常数时，下界为$\\frac{c2^n}{n^{3r/4}}$，上界为$\\frac{c'2^n}{n}$。", "conclusion": "该研究为超立方体中避免特定汉明距离的顶点子集规模提供了理论界限，对组合数学和编码理论有重要意义。"}}
{"id": "2506.17846", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17846", "abs": "https://arxiv.org/abs/2506.17846", "authors": ["Elija Perrier"], "title": "Out of Control -- Why Alignment Needs Formal Control Theory (and an Alignment Control Stack)", "comment": "Under review for Neurips 2025", "summary": "This position paper argues that formal optimal control theory should be\ncentral to AI alignment research, offering a distinct perspective from\nprevailing AI safety and security approaches. While recent work in AI safety\nand mechanistic interpretability has advanced formal methods for alignment,\nthey often fall short of the generalisation required of control frameworks for\nother technologies. There is also a lack of research into how to render\ndifferent alignment/control protocols interoperable. We argue that by recasting\nalignment through principles of formal optimal control and framing alignment in\nterms of hierarchical stack from physical to socio-technical layers according\nto which controls may be applied we can develop a better understanding of the\npotential and limitations for controlling frontier models and agentic AI\nsystems. To this end, we introduce an Alignment Control Stack which sets out a\nhierarchical layered alignment stack, identifying measurement and control\ncharacteristics at each layer and how different layers are formally\ninteroperable. We argue that such analysis is also key to the assurances that\nwill be needed by governments and regulators in order to see AI technologies\nsustainably benefit the community. Our position is that doing so will bridge\nthe well-established and empirically validated methods of optimal control with\npractical deployment considerations to create a more comprehensive alignment\nframework, enhancing how we approach safety and reliability for advanced AI\nsystems.", "AI": {"tldr": "本文主张将形式最优控制理论作为AI对齐研究的核心，提出通过分层控制栈（Alignment Control Stack）实现跨层级协议互操作性，以弥补现有AI安全方法在泛化性上的不足，并为政府监管提供理论依据。", "motivation": "当前AI安全与可解释性研究缺乏通用控制框架的泛化能力，且未解决不同对齐协议间的互操作性问题。本文旨在通过最优控制理论构建分层对齐框架，以增强对前沿AI系统的可控性理解。", "method": "提出'对齐控制栈'（Alignment Control Stack）分层模型，从物理层到社会技术层逐级定义测量与控制特性，并形式化各层级的互操作性。", "result": "构建了基于最优控制理论的分层对齐框架，明确了各层级的控制指标与跨层协调机制，为AI系统的安全部署提供可验证的理论基础。", "conclusion": "将最优控制理论与实际部署需求结合，可创建更全面的AI对齐框架，提升高级AI系统的安全性与可靠性，同时满足政府监管的合规性要求。"}}
{"id": "2506.17884", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.17884", "abs": "https://arxiv.org/abs/2506.17884", "authors": ["Lingzi Jin", "Xiao Wang", "Xiaojun Chen"], "title": "Nonconvex Nonsmooth Multicomposite Optimization and Its Applications to Recurrent Neural Networks", "comment": null, "summary": "We consider a class of nonconvex nonsmooth multicomposite optimization\nproblems where the objective function consists of a Tikhonov regularizer and a\ncomposition of multiple nonconvex nonsmooth component functions. Such\noptimization problems arise from tangible applications in machine learning and\nbeyond. To define and compute its first-order and second-order\nd(irectional)-stationary points effectively, we first derive the closed-form\nexpression of the tangent cone for the feasible region of its constrained\nreformulation. Building on this, we establish its equivalence with the\ncorresponding constrained and $\\ell_1$-penalty reformulations in terms of\nglobal optimality and d-stationarity. The equivalence offers indirect methods\nto attain the first-order and second-order d-stationary points of the original\nproblem in certain cases. We apply our results to the training process of\nrecurrent neural networks (RNNs).", "AI": {"tldr": "本文研究了一类非凸非光滑多复合优化问题，提出了通过约束重构与$\\ell_1$惩罚重构的等价性来有效求解一阶和二阶方向平稳点的方法，并应用于循环神经网络训练。", "motivation": "该研究针对机器学习等领域中出现的非凸非光滑多复合优化问题，特别是包含Tikhonov正则化项和多组件函数组合的目标函数，旨在建立有效的求解框架。", "method": "首先推导了约束重构可行域切锥的闭式表达式，进而证明了原问题与约束重构及$\\ell_1$惩罚重构在全局最优性和方向平稳性上的等价性，为间接求解提供了理论基础。", "result": "研究结果表明，通过约束重构与惩罚重构的等价性，可在特定情况下间接获得原问题的一阶和二阶方向平稳点，并将该方法成功应用于循环神经网络的训练过程。", "conclusion": "该工作为非凸非光滑多复合优化问题提供了新的求解路径，其理论框架在机器学习模型（如RNN）训练中展现出应用潜力。"}}
{"id": "2506.17353", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17353", "abs": "https://arxiv.org/abs/2506.17353", "authors": ["Zongjie Li", "Daoyuan Wu", "Shuai Wang", "Zhendong Su"], "title": "Differentiation-Based Extraction of Proprietary Data from Fine-Tuned LLMs", "comment": "In Proceedings of the 2025 ACM SIGSAC Conference on Computer and\n  Communications Security (CCS'25), October 13-17, 2025, Taipei, Taiwan, China.\n  ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/3719027.3744856", "summary": "The increasing demand for domain-specific and human-aligned Large Language\nModels (LLMs) has led to the widespread adoption of Supervised Fine-Tuning\n(SFT) techniques. SFT datasets often comprise valuable instruction-response\npairs, making them highly valuable targets for potential extraction. This paper\nstudies this critical research problem for the first time. We start by formally\ndefining and formulating the problem, then explore various attack goals, types,\nand variants based on the unique properties of SFT data in real-world\nscenarios. Based on our analysis of extraction behaviors of direct extraction,\nwe develop a novel extraction method specifically designed for SFT models,\ncalled Differentiated Data Extraction (DDE), which exploits the confidence\nlevels of fine-tuned models and their behavioral differences from pre-trained\nbase models. Through extensive experiments across multiple domains and\nscenarios, we demonstrate the feasibility of SFT data extraction using DDE. Our\nresults show that DDE consistently outperforms existing extraction baselines in\nall attack settings. To counter this new attack, we propose a defense mechanism\nthat mitigates DDE attacks with minimal impact on model performance. Overall,\nour research reveals hidden data leak risks in fine-tuned LLMs and provides\ninsights for developing more secure models.", "AI": {"tldr": "本文首次研究了监督微调(SFT)数据提取问题，提出新型攻击方法DDE并验证其有效性，同时提出防御机制以降低数据泄露风险。", "motivation": "随着领域专用和人类对齐大语言模型需求增长，SFT数据集成为高价值目标，但数据提取风险尚未被系统研究。", "method": "提出差异化数据提取(DDE)方法，利用微调模型的置信度差异及与预训练基模型的行为差异进行攻击。", "result": "跨领域实验表明DDE在所有攻击场景中优于基线方法，同时提出的防御机制能有效缓解攻击且对模型性能影响最小。", "conclusion": "研究揭示了微调LLMs中隐藏的数据泄露风险，为开发更安全模型提供了重要见解。"}}
{"id": "2506.18788", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.18788", "abs": "https://arxiv.org/abs/2506.18788", "authors": ["Erik Panzer"], "title": "Graph theoretic properties of Speyer's matroid polynomial $g_M(t)$", "comment": "56 pages, 8 tables, 17 figures, associated with open-source code and\n  a data set", "summary": "We prove relations between the number of $k$-connected components of a graph,\nCrapo's invariant $\\beta(M)$ of a matroid, and Speyer's polynomial $g_M(t)$.\nThese yield a simple interpretation of $g_M'(-1)$ when $M$ is graphic or\ncographic. Furthermore, we improve Ferroni's algorithm to compute $g_M(t)$ and\nprovide an implementation and an extensive data set. These calculations reveal\na large number of graph theoretic constraints on the second derivative\n$g_M''(-1)$, which we thus advertise as an intriguing new invariant of graphs.\nWe also propose a relation between the flow polynomial and $g_M''(0)$ for cubic\ngraphs.", "AI": {"tldr": "本文研究了图的$k$-连通分量、Crapo不变量$\\beta(M)$与Speyer多项式$g_M(t)$之间的关系，提出了$g_M'(-1)$的简单解释，改进了计算$g_M(t)$的算法，并通过大量计算揭示了$g_M''(-1)$作为图的新不变量的潜力，同时探讨了三次图的流多项式与$g_M''(0)$的关系。", "motivation": "研究图的$k$-连通分量、Crapo不变量$\\beta(M)$与Speyer多项式$g_M(t)$之间的关系，旨在揭示这些数学对象之间的深层联系，并为图论和拟阵理论提供新的工具和视角。", "method": "通过理论证明建立$k$-连通分量、$\\beta(M)$与$g_M(t)$之间的关系，改进Ferroni的算法以计算$g_M(t)$，并实现该算法以生成大量数据进行分析。", "result": "提出了$g_M'(-1)$在图或对偶图情况下的简单解释，改进了计算$g_M(t)$的算法，并通过数据揭示了$g_M''(-1)$作为图的新不变量的潜力，同时探讨了三次图的流多项式与$g_M''(0)$的可能关系。", "conclusion": "研究表明$g_M''(-1)$是一个有趣的图不变量，未来研究可进一步探索其性质和应用，同时三次图的流多项式与$g_M''(0)$的关系也值得深入研究。"}}
{"id": "2506.17878", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17878", "abs": "https://arxiv.org/abs/2506.17878", "authors": ["Tam Trinh", "Manh Nguyen", "Truong-Son Hy"], "title": "Towards Robust Fact-Checking: A Multi-Agent System with Advanced Evidence Retrieval", "comment": null, "summary": "The rapid spread of misinformation in the digital era poses significant\nchallenges to public discourse, necessitating robust and scalable fact-checking\nsolutions. Traditional human-led fact-checking methods, while credible,\nstruggle with the volume and velocity of online content, prompting the\nintegration of automated systems powered by Large Language Models (LLMs).\nHowever, existing automated approaches often face limitations, such as handling\ncomplex claims, ensuring source credibility, and maintaining transparency. This\npaper proposes a novel multi-agent system for automated fact-checking that\nenhances accuracy, efficiency, and explainability. The system comprises four\nspecialized agents: an Input Ingestion Agent for claim decomposition, a Query\nGeneration Agent for formulating targeted subqueries, an Evidence Retrieval\nAgent for sourcing credible evidence, and a Verdict Prediction Agent for\nsynthesizing veracity judgments with human-interpretable explanations.\nEvaluated on benchmark datasets (FEVEROUS, HOVER, SciFact), the proposed system\nachieves a 12.3% improvement in Macro F1-score over baseline methods. The\nsystem effectively decomposes complex claims, retrieves reliable evidence from\ntrusted sources, and generates transparent explanations for verification\ndecisions. Our approach contributes to the growing field of automated\nfact-checking by providing a more accurate, efficient, and transparent\nverification methodology that aligns with human fact-checking practices while\nmaintaining scalability for real-world applications. Our source code is\navailable at https://github.com/HySonLab/FactAgent", "AI": {"tldr": "本文提出了一种新型多智能体系统，用于自动化事实核查，通过分解复杂声明、检索可靠证据并生成透明解释，显著提升了准确性和效率。", "motivation": "数字时代错误信息的快速传播对公共讨论构成挑战，传统人工核查难以应对海量在线内容，现有自动化方法在复杂声明处理、来源可信度和透明度方面存在局限。", "method": "系统包含四个专用智能体：输入解析智能体分解声明，查询生成智能体构建子查询，证据检索智能体获取可信证据，判定预测智能体综合真实性判断并生成可解释说明。", "result": "在FEVEROUS、HOVER和SciFact基准数据集上，该系统宏F1分数比基线方法提高12.3%，能有效分解复杂声明并从可信来源检索证据。", "conclusion": "该研究为自动化事实核查领域提供了更准确、高效且透明的验证方法，既符合人工核查实践，又具备现实应用的扩展性。"}}
{"id": "2506.17924", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.17924", "abs": "https://arxiv.org/abs/2506.17924", "authors": ["Shenglu Wang", "Kairui Feng", "Mengqi Xue", "Yue Song"], "title": "Inverse Chance Constrained Optimal Power Flow", "comment": "3 pages, 1 figure", "summary": "The chance constrained optimal power flow (CC-OPF) essentially finds the\nlow-cost generation dispatch scheme ensuring operational constraints are met\nwith a specified probability, termed the security level. While the security\nlevel is a crucial input parameter, how it shapes the CC-OPF feasibility\nboundary has not been revealed. Changing the security level from a parameter to\na decision variable, this letter proposes the inverse CC-OPF that seeks the\nhighest feasible security level supported by the system. To efficiently solve\nthis problem, we design a Newton-Raphson-like iteration algorithm leveraging\nthe duality-based sensitivity analysis of an associated surrogate problem.\nNumerical experiments validate the proposed approach, revealing complex\nfeasibility boundaries for security levels that underscore the importance of\ncoordinating security levels across multiple chance constraints.", "AI": {"tldr": "本文提出了一种逆向机会约束最优潮流（CC-OPF）方法，将安全水平从参数转变为决策变量，旨在寻找系统支持的最高可行安全水平，并通过牛顿-拉夫逊类迭代算法高效求解。", "motivation": "安全水平是CC-OPF的关键输入参数，但其如何影响CC-OPF的可行性边界尚未明确。研究安全水平对系统可行性的影响，有助于优化电力系统的安全运行。", "method": "通过将安全水平从参数转变为决策变量，提出逆向CC-OPF问题，并设计了一种基于对偶敏感性分析的牛顿-拉夫逊类迭代算法，以高效求解该问题。", "result": "数值实验验证了所提方法的有效性，揭示了安全水平的复杂可行性边界，强调了在多机会约束中协调安全水平的重要性。", "conclusion": "逆向CC-OPF方法能够有效确定系统支持的最高安全水平，为电力系统的安全运行提供了新的优化思路。"}}
{"id": "2506.17371", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2506.17371", "abs": "https://arxiv.org/abs/2506.17371", "authors": ["Thilina Pathirana", "Ruxandra F. Olimid"], "title": "Secret Sharing in 5G-MEC: Applicability for joint Security and Dependability", "comment": "10 pages, 5 figures, Accepted to the proceedings of 22nd\n  International Conference on Privacy, Security, and Trust (PST2025)", "summary": "Multi-access Edge Computing (MEC), an enhancement of 5G, processes data\ncloser to its generation point, reducing latency and network load. However, the\ndistributed and edge-based nature of 5G-MEC presents privacy and security\nchallenges, including data exposure risks. Ensuring efficient manipulation and\nsecurity of sensitive data at the edge is crucial. To address these challenges,\nwe investigate the usage of threshold secret sharing in 5G-MEC storage, an\napproach that enhances both security and dependability. A (k,n) threshold\nsecret sharing scheme splits and stores sensitive data among n nodes, requiring\nat least k nodes for reconstruction. The solution ensures confidentiality by\nprotecting data against fewer than k colluding nodes and enhances availability\nby tolerating up to n-k failing nodes. This approach mitigates threats such as\nunauthorized access and node failures, whether accidental or intentional. We\nfurther discuss a method for selecting the convenient MEHs to store the shares,\nconsidering the MEHs' trustworthiness level as a main criterion. Although we\ndefine our proposal in the context of secret-shared data storage, it can be\nseen as an independent, standalone selection process for 5G-MEC trustworthy\nnode selection in other scenarios too.", "AI": {"tldr": "本文探讨了在5G多接入边缘计算（MEC）中应用阈值秘密共享技术以增强数据安全性和可靠性的方法。通过(k,n)阈值方案分散存储敏感数据，确保数据机密性和可用性，并提出了基于信任度的边缘节点选择策略。", "motivation": "5G-MEC的分布式特性带来了隐私和安全挑战，如数据暴露风险。研究旨在解决边缘敏感数据的高效处理与安全保障问题。", "method": "采用(k,n)阈值秘密共享方案，将数据分散存储于n个节点，需至少k个节点协作才能重构数据。同时提出基于信任度的边缘节点（MEH）选择方法。", "result": "该方案能抵御少于k个节点的共谋攻击，容忍最多n-k个节点故障，有效降低未授权访问和节点故障风险。节点选择方法可扩展至其他5G-MEC可信场景。", "conclusion": "阈值秘密共享技术为5G-MEC存储提供了安全可靠的解决方案，其节点选择框架具有通用性，可适用于更广泛的边缘计算场景。"}}
{"id": "2506.17900", "categories": ["cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2506.17900", "abs": "https://arxiv.org/abs/2506.17900", "authors": ["Cheng Ji", "Huaiying Luo"], "title": "Leveraging Large Language Model for Intelligent Log Processing and Autonomous Debugging in Cloud AI Platforms", "comment": "Accepted by 2025 8th International Conference on Advanced Electronic\n  Materials, Computers and Software Engineering (AEMCSE 2025)", "summary": "With the increasing complexity and rapid expansion of the scale of AI systems\nin cloud platforms, the log data generated during system operation is massive,\nunstructured, and semantically ambiguous, which brings great challenges to\nfault location and system self-repair. In order to solve this problem, this\npaper proposes an intelligent log processing and automatic debugging framework\nbased on Large Language Model (LLM), named Intelligent Debugger (LLM-ID). This\nmethod is extended on the basis of the existing pre-trained Transformer model,\nand integrates a multi-stage semantic inference mechanism to realize the\ncontext understanding of system logs and the automatic reconstruction of fault\nchains. Firstly, the system log is dynamically structured, and the unsupervised\nclustering and embedding mechanism is used to extract the event template and\nsemantic schema. Subsequently, the fine-tuned LLM combined with the multi-round\nattention mechanism to perform contextual reasoning on the log sequence to\ngenerate potential fault assumptions and root cause paths. Furthermore, this\npaper introduces a reinforcement learning-based policy-guided recovery planner,\nwhich is driven by the remediation strategy generated by LLM to support dynamic\ndecision-making and adaptive debugging in the cloud environment. Compared with\nthe existing rule engine or traditional log analysis system, the proposed model\nhas stronger semantic understanding ability, continuous learning ability and\nheterogeneous environment adaptability. Experiments on the cloud platform log\ndataset show that LLM-ID improves the fault location accuracy by 16.2%, which\nis significantly better than the current mainstream methods", "AI": {"tldr": "本文提出基于大语言模型(LLM)的智能日志处理与自动调试框架LLM-ID，通过多阶段语义推理和强化学习策略，显著提升云平台故障定位准确率16.2%。", "motivation": "云平台AI系统日志具有海量、非结构化、语义模糊等特性，传统方法难以实现高效故障定位与自修复，亟需智能化的日志分析解决方案。", "method": "1. 动态结构化系统日志并提取事件模板\\n2. 微调LLM结合多轮注意力机制进行上下文推理\\n3. 引入强化学习驱动的策略引导恢复规划器\\n4. 构建端到端的故障链自动重建框架", "result": "在云平台日志数据集上的实验表明，LLM-ID将故障定位准确率提升16.2%，显著优于主流方法，且具备持续学习与异构环境适应能力。", "conclusion": "LLM-ID框架通过语义理解与动态决策的深度融合，为云系统智能运维提供了具有强泛化性的新范式，其多阶段推理机制可扩展至其他复杂系统诊断场景。"}}
{"id": "2506.18004", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.18004", "abs": "https://arxiv.org/abs/2506.18004", "authors": ["Roberto Boffadossi", "Marco Leonesio", "Lorenzo Fagiano"], "title": "ROBBO: An Efficient Method for Pareto Front Estimation with Guaranteed Accuracy", "comment": "35 pages, 10 figures, under review", "summary": "A new method to estimate the Pareto Front (PF) in bi-objective optimization\nproblems is presented. Assuming a continuous PF, the approach, named ROBBO\n(RObust and Balanced Bi-objective Optimization), needs to sample at most a\nfinite, pre-computed number of PF points. Upon termination, it guarantees that\nthe worst-case approximation error lies within a desired tolerance range,\npredefined by the decision maker, for each of the two objective functions.\nTheoretical results are derived, about the worst-case number of PF samples\nrequired to guarantee the wanted accuracy, both in general and for specific\nsampling methods from the literature. A comparative analysis, both theoretical\nand numerical, demonstrates the superiority of the proposed method with respect\nto popular ones. The approach is finally showcased in a constrained\npath-following problem for a 2-axis positioning system and in a steady-state\noptimization problem for a Continuous-flow Stirred Tank Reactor. An open demo\nimplementation of ROBBO is made available online.", "AI": {"tldr": "提出了一种名为ROBBO的新方法，用于估计双目标优化问题中的帕累托前沿（PF），确保在有限采样点内达到预设误差容忍度，并在理论和数值分析中展示了其优越性。", "motivation": "双目标优化问题中准确估计帕累托前沿的需求，现有方法在采样效率和误差控制方面存在不足，需要一种更鲁棒且平衡的解决方案。", "method": "ROBBO方法假设PF连续，通过有限预计算的PF采样点，确保两个目标函数的近似误差在预设容忍范围内，并推导了理论上的最坏情况采样数量。", "result": "理论分析和数值比较表明，ROBBO在采样效率和误差控制上优于现有流行方法，并在2轴定位系统的路径跟踪问题和连续搅拌釜反应器的稳态优化问题中验证了其有效性。", "conclusion": "ROBBO方法在双目标优化中表现出色，提供了理论保证和实际应用价值，其开源实现可供进一步研究和应用。"}}
{"id": "2506.17446", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.17446", "abs": "https://arxiv.org/abs/2506.17446", "authors": ["Nesrine Benchoubane", "Eray Guven", "Gunes Karabulut Kurt"], "title": "Open Sky, Open Threats: Replay Attacks in Space Launch and Re-entry Phases", "comment": null, "summary": "This paper examines the effects of replay attacks on the integrity of both\nuplink and downlink communications during critical phases of spacecraft\ncommunication. By combining software-defined radios (SDRs) with a real-time\nchannel emulator, we replicate realistic attack conditions on the Orion\nspacecraft's communication systems in both launch and reentry. Our evaluation\nshows that, under replay attacks, the attacker's signal can overpower\nlegitimate transmissions, leading to a Signal to Noise Ratio (SNR) difference\nof up to -7.8 dB during reentry and -6.5 dB during launch. To mitigate these\nthreats, we propose a more secure receiver design incorporating a\nphase-coherency-dependent decision-directed (DD) equalizer with a narrowed\nphase-locked loop (PLL) bandwidth. This configuration enhances resilience by\nmaking synchronization more sensitive to phase distortions caused by replay\ninterference.", "AI": {"tldr": "本文研究了重放攻击对航天器通信关键阶段（发射与再入）上下行链路完整性的影响，提出了一种基于相位相干性决策导向均衡器的安全接收机设计。", "motivation": "航天器在发射和再入阶段的通信系统易受重放攻击，攻击者信号可能压制合法传输，威胁任务安全。", "method": "结合软件定义无线电（SDR）与实时信道模拟器，模拟猎户座飞船通信系统受攻击场景，并设计采用窄带锁相环（PLL）的相位相干决策导向均衡器（DD）。", "result": "实验显示重放攻击下攻击信号信噪比（SNR）优势可达再入阶段-7.8dB、发射阶段-6.5dB，新接收机设计显著提升对相位畸变的敏感度。", "conclusion": "通过优化接收机同步机制，增强了对重放干扰引起的相位失真的检测能力，有效提升了航天器通信系统的抗攻击韧性。"}}
{"id": "2506.17913", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17913", "abs": "https://arxiv.org/abs/2506.17913", "authors": ["Jinjie Wei", "Jiyao Liu", "Lihao Liu", "Ming Hu", "Junzhi Ning", "Mingcheng Li", "Weijie Yin", "Junjun He", "Xiao Liang", "Chao Feng", "Dingkang Yang"], "title": "Learning, Reasoning, Refinement: A Framework for Kahneman's Dual-System Intelligence in GUI Agents", "comment": null, "summary": "Graphical User Interface (GUI) agents have made significant progress in\nautomating digital tasks through the utilization of computer vision and\nlanguage models. Nevertheless, existing agent systems encounter notable\nlimitations. Firstly, they predominantly depend on trial and error decision\nmaking rather than progressive reasoning, thereby lacking the capability to\nlearn and adapt from interactive encounters. Secondly, these systems are\nassessed using overly simplistic single step accuracy metrics, which do not\nadequately reflect the intricate nature of real world GUI interactions. In this\npaper, we present CogniGUI, a cognitive framework developed to overcome these\nlimitations by enabling adaptive learning for GUI automation resembling\nhuman-like behavior. Inspired by Kahneman's Dual Process Theory, our approach\ncombines two main components: (1) an omni parser engine that conducts immediate\nhierarchical parsing of GUI elements through quick visual semantic analysis to\nidentify actionable components, and (2) a Group based Relative Policy\nOptimization (GRPO) grounding agent that assesses multiple interaction paths\nusing a unique relative reward system, promoting minimal and efficient\noperational routes. This dual-system design facilitates iterative ''exploration\nlearning mastery'' cycles, enabling the agent to enhance its strategies over\ntime based on accumulated experience. Moreover, to assess the generalization\nand adaptability of agent systems, we introduce ScreenSeek, a comprehensive\nbenchmark that includes multi application navigation, dynamic state\ntransitions, and cross interface coherence, which are often overlooked\nchallenges in current benchmarks. Experimental results demonstrate that\nCogniGUI surpasses state-of-the-art methods in both the current GUI grounding\nbenchmarks and our newly proposed benchmark.", "AI": {"tldr": "本文提出CogniGUI框架，通过结合快速视觉语义分析和相对奖励策略优化，实现类人自适应学习的GUI自动化，并在新基准ScreenSeek上超越现有方法。", "motivation": "现有GUI代理系统依赖试错决策且评估指标过于简单，无法反映真实交互复杂性，亟需支持渐进式学习和适应能力的解决方案。", "method": "基于双过程理论构建：1)全解析引擎进行GUI元素层级解析；2)GRPO代理通过相对奖励评估多路径，形成\"探索-学习-掌握\"循环。", "result": "CogniGUI在现有基准和新提出的ScreenSeek基准（含跨应用导航、动态状态转换等挑战）上均优于最先进方法。", "conclusion": "该认知框架通过双系统设计实现持续策略优化，ScreenSeek基准为评估代理泛化能力提供了更全面的测试标准。"}}
{"id": "2506.18075", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.18075", "abs": "https://arxiv.org/abs/2506.18075", "authors": ["Liyuan Liang", "Gan Luo", "Kun Yuan"], "title": "On the Linear Speedup of the Push-Pull Method for Decentralized Optimization over Digraphs", "comment": null, "summary": "The linear speedup property is essential for demonstrating the advantage of\ndistributed algorithms over their single-node counterparts. In this paper, we\nstudy the stochastic Push-Pull method, a widely adopted decentralized\noptimization algorithm over directed graphs (digraphs). Unlike methods that\nrely solely on row-stochastic or column-stochastic mixing matrices, Push-Pull\navoids nonlinear correction and has shown superior empirical performance across\na variety of settings. However, its theoretical analysis remains challenging,\nand the linear speedup property has not been generally establishe--revealing a\nsignificant gap between empirical success and limited theoretical\nunderstanding. To bridge this gap, we propose a novel analysis framework and\nprove that Push-Pull achieves linear speedup over arbitrary strongly connected\ndigraphs. Our results provide the comprehensive theoretical understanding for\nstochastic Push-Pull, aligning its theory with empirical performance. Code:\n\\href{https://github.com/pkumelon/PushPull}{https://github.com/pkumelon/PushPull}.", "AI": {"tldr": "本文研究了随机Push-Pull方法在强连通有向图上的线性加速特性，提出了新的分析框架，填补了该算法在理论与实证表现之间的差距。", "motivation": "Push-Pull作为一种广泛使用的去中心化优化算法，虽在多种场景下表现出优越的实证性能，但其线性加速特性尚未得到普遍证明，理论与实证之间存在显著差距。", "method": "通过提出新的分析框架，研究团队对随机Push-Pull方法进行了理论分析，避免了非线性校正，并专注于强连通有向图。", "result": "研究证明，Push-Pull算法在任意强连通有向图上均能实现线性加速，为算法的理论理解提供了全面支持。", "conclusion": "该研究不仅为随机Push-Pull方法的理论分析奠定了基础，还使其理论与实证表现达成一致，推动了去中心化优化算法的发展。"}}
{"id": "2506.17504", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17504", "abs": "https://arxiv.org/abs/2506.17504", "authors": ["Hinata Nishino", "Kazumasa Omote", "Keita Emura"], "title": "A Smart Contract-based Non-Transferable Signature Verification System using Nominative Signatures", "comment": "An extended abstract appeared at the 20th Asia Joint Conference on\n  Information Security (AsiaJCIS) 2025", "summary": "Nominative signatures allow us to indicate who can verify a signature, and\nthey can be employed to construct a non-transferable signature verification\nsystem that prevents the signature verification by a third party in unexpected\nsituations. For example, this system can prevent IOU/loan certificate\nverification in unexpected situations. However, nominative signatures\nthemselves do not allow the verifier to check whether the funds will be\ntransferred in the future or have been transferred.It would be desirable to\nverify the fact simultaneously when the system involves a certain money\ntransfer such as cryptocurrencies/cryptoassets. In this paper, we propose a\nsmart contract-based non-transferable signature verification system using\nnominative signatures. We pay attention to the fact that the invisibility,\nwhich is a security requirement to be held for nominative signatures, allows us\nto publish nominative signatures on the blockchain. Our system can verify\nwhether a money transfer actually will take place, in addition to indicating\nwho can verify a signature. We transform the Hanaoka-Schuldt nominative\nsignature scheme (ACNS 2011, IEICE Trans. 2016) which is constructed over a\nsymmetric pairing to a scheme constructed over an asymmetric pairing, and\nevaluate the gas cost when a smart contract runs the verification algorithm of\nthe modified Hanaoka-Schuldt nominative signature scheme.", "AI": {"tldr": "本文提出了一种基于智能合约和提名签名技术的不可转让签名验证系统，用于在加密货币交易中同时验证签名和资金转移状态。", "motivation": "传统提名签名虽能限制验证者身份，但无法验证资金是否已/将转移。在加密货币场景中，需要同时实现签名验证和资金状态确认。", "method": "改造Hanaoka-Schuldt提名签名方案（原基于对称配对），使其适配非对称配对，并通过智能合约执行验证算法，评估gas消耗。", "result": "系统成功实现：1) 保留提名签名的不可见性（允许区块链公开） 2) 新增资金转移验证功能 3) 完成非对称配对改造及gas成本测算。", "conclusion": "该方案首次将提名签名与智能合约结合，为加密货币场景提供兼具身份控制与资金状态验证的不可转让签名系统，实测验证了可行性。"}}
{"id": "2506.17930", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.NE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.17930", "abs": "https://arxiv.org/abs/2506.17930", "authors": ["Jianyu Wang", "Zhiqiang Hu", "Lidong Bing"], "title": "Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective", "comment": "ICML 2025, and Code will be released at:\n  https://github.com/jianyu-cs/PromptQuine/", "summary": "We propose a novel prompt design paradigm that challenges conventional wisdom\nin large language model (LLM) prompting. While conventional wisdom prioritizes\nwell-crafted instructions and demonstrations for in-context learning (ICL), we\nshow that pruning random demonstrations into seemingly incoherent \"gibberish\"\ncan remarkably improve performance across diverse tasks. Notably, the\n\"gibberish\" always matches or surpasses state-of-the-art automatic prompt\noptimization techniques, achieving substantial gains regardless of LLM\nalignment. Nevertheless, discovering an effective pruning strategy is\nnon-trivial, as existing attribution methods and prompt compression algorithms\nfail to deliver robust results, let alone human intuition. In terms of this, we\npropose a self-discover prompt optimization framework, PromptQuine, an\nevolutionary search framework that automatically searches for the pruning\nstrategy by itself using only low-data regimes. Much like the emergent\ncomplexity in nature--such as symbiosis and self-organization--arising in\nresponse to resource constraints, our framework evolves and refines\nunconventional yet highly effective prompts by leveraging only the tokens\npresent within the context. We demonstrate its effectiveness across\nclassification, multi-choice question answering, generation and math reasoning\ntasks across LLMs, while achieving decent runtime efficiency. We hope our\nfindings can guide mechanistic studies on in-context learning, and provide a\ncall to action, to pave the way for more open-ended search algorithms for more\neffective LLM prompting.", "AI": {"tldr": "提出PromptQuine框架，通过进化搜索自动优化提示剪枝策略，证明看似无意义的\"乱码\"提示能超越传统方法提升大语言模型性能。", "motivation": "传统提示设计依赖精心构造的指令和示例，但研究发现随机剪枝生成的\"乱码\"提示反而能显著提升模型表现，这挑战了现有认知并需要自动化优化方法。", "method": "开发自发现提示优化框架PromptQuine，采用进化搜索在低数据量下自动探索有效的token剪枝策略，模仿自然界资源约束下的自组织现象。", "result": "该方法在分类、多选题、生成和数学推理等任务中稳定超越现有自动提示优化技术，且不受模型对齐影响，同时保持较高运行效率。", "conclusion": "研究为上下文学习机制研究提供新方向，呼吁开发更开放式的搜索算法以探索更高效的大语言模型提示方法。"}}
{"id": "2506.18195", "categories": ["math.OC", "cs.AI", "cs.MA", "cs.SY", "eess.SY", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2506.18195", "abs": "https://arxiv.org/abs/2506.18195", "authors": ["Giacomo Como", "Fabio Fagnani", "Anton Proskurnikov"], "title": "Wisdom of Crowds Through Myopic Self-Confidence Adaptation", "comment": null, "summary": "The wisdom of crowds is an umbrella term for phenomena suggesting that the\ncollective judgment or decision of a large group can be more accurate than the\nindividual judgments or decisions of the group members. A well-known example\nillustrating this concept is the competition at a country fair described by\nGalton, where the median value of the individual guesses about the weight of an\nox resulted in an astonishingly accurate estimate of the actual weight. This\nphenomenon resembles classical results in probability theory and relies on\nindependent decision-making. The accuracy of the group's final decision can be\nsignificantly reduced if the final agents' opinions are driven by a few\ninfluential agents.\n  In this paper, we consider a group of agents who initially possess\nuncorrelated and unbiased noisy measurements of a common state of the world.\nAssume these agents iteratively update their estimates according to a simple\nnon-Bayesian learning rule, commonly known in mathematical sociology as the\nFrench-DeGroot dynamics or iterative opinion pooling. As a result of this\niterative distributed averaging process, each agent arrives at an asymptotic\nestimate of the state of the world, with the variance of this estimate\ndetermined by the matrix of weights the agents assign to each other. Every\nagent aims at minimizing the variance of her asymptotic estimate of the state\nof the world; however, such variance is also influenced by the weights\nallocated by other agents. To achieve the best possible estimate, the agents\nmust then solve a game-theoretic, multi-objective optimization problem defined\nby the available sets of influence weights. We characterize both the Pareto\nfrontier and the set of Nash equilibria in the resulting game. Additionally, we\nexamine asynchronous best-response dynamics for the group of agents and prove\ntheir convergence to the set of strict Nash equilibria.", "AI": {"tldr": "该研究探讨了群体智慧现象，分析了在多智能体系统中通过非贝叶斯学习规则（法国-德格鲁特动态）进行迭代意见聚合的过程，并研究了博弈论框架下的帕累托前沿与纳什均衡。", "motivation": "研究动机源于群体决策中集体判断可能优于个体判断的现象（如高尔顿的牛重猜测实验），但同时也关注到少数影响力大的个体可能降低群体决策准确性。本文旨在分析多智能体系统中如何通过优化影响权重来最小化估计方差。", "method": "采用非贝叶斯学习规则（法国-德格鲁特动态）进行迭代分布式平均，将问题建模为多目标博弈论优化问题，分析影响权重矩阵对估计方差的作用，并研究帕累托前沿与纳什均衡。", "result": "研究刻画了博弈中的帕累托前沿与纳什均衡集，证明了异步最佳响应动态会收敛到严格纳什均衡集，表明智能体通过优化权重分配可达成最优估计。", "conclusion": "结论表明，在多智能体系统中，通过博弈论框架优化影响权重能够有效降低估计方差，且异步学习动态可收敛至稳定均衡，为群体决策机制设计提供了理论依据。"}}
{"id": "2506.17512", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17512", "abs": "https://arxiv.org/abs/2506.17512", "authors": ["Julien Piet", "Vivian Fang", "Rishi Khare", "Vern Paxson", "Raluca Ada Popa", "David Wagner"], "title": "Semantic-Aware Parsing for Security Logs", "comment": null, "summary": "Security analysts struggle to quickly and efficiently query and correlate log\ndata due to the heterogeneity and lack of structure in real-world logs.\nExisting AI-based parsers focus on learning syntactic log templates but lack\nthe semantic interpretation needed for querying. Directly querying large\nlanguage models on raw logs is impractical at scale and vulnerable to prompt\ninjection attacks.\n  In this paper, we introduce Matryoshka, the first end-to-end system\nleveraging LLMs to automatically generate semantically-aware structured log\nparsers. Matryoshka combines a novel syntactic parser-employing precise regular\nexpressions rather than wildcards-with a completely new semantic parsing layer\nthat clusters variables and maps them into a queryable, contextually meaningful\nschema. This approach provides analysts with queryable and semantically rich\ndata representations, facilitating rapid and precise log querying without the\ntraditional burden of manual parser construction. Additionally, Matryoshka can\nmap the newly created fields to recognized attributes within the Open\nCybersecurity Schema Framework (OCSF), enabling interoperability.\n  We evaluate Matryoshka on a newly curated real-world log benchmark,\nintroducing novel metrics to assess how consistently fields are named and\nmapped across logs. Matryoshka's syntactic parser outperforms prior works, and\nthe semantic layer achieves an F1 score of 0.95 on realistic security queries.\nAlthough mapping fields to the extensive OCSF taxonomy remains challenging,\nMatryoshka significantly reduces manual effort by automatically extracting and\norganizing valuable fields, moving us closer to fully automated, AI-driven log\nanalytics.", "AI": {"tldr": "Matryoshka是一个端到端系统，利用LLMs自动生成具有语义感知的结构化日志解析器，结合语法解析和语义解析层，显著提升日志查询效率并减少人工干预。", "motivation": "由于现实日志的异构性和缺乏结构，安全分析师难以高效查询和关联日志数据。现有AI解析器仅关注语法模板，缺乏语义解释能力，而直接使用大型语言模型查询原始日志存在规模化和提示注入攻击的隐患。", "method": "Matryoshka引入了一种新颖的语法解析器（使用精确正则表达式而非通配符）和全新的语义解析层，将变量聚类并映射到可查询的、具有上下文意义的模式中，同时支持与Open Cybersecurity Schema Framework (OCSF)的互操作性。", "result": "在新构建的真实日志基准测试中，Matryoshka的语法解析器优于先前工作，语义层在现实安全查询中达到F1分数0.95。尽管将字段映射到OCSF分类仍具挑战性，但系统显著减少了人工提取和组织字段的工作量。", "conclusion": "Matryoshka通过自动提取和组织有价值字段，推动了日志分析向全自动化、AI驱动的方向发展，为安全分析师提供了高效且语义丰富的日志查询解决方案。"}}
{"id": "2506.17959", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17959", "abs": "https://arxiv.org/abs/2506.17959", "authors": ["Lizzy Farrugia", "Lilian M. Azzopardi", "Jeremy Debattista", "Charlie Abela"], "title": "medicX-KG: A Knowledge Graph for Pharmacists' Drug Information Needs", "comment": null, "summary": "The role of pharmacists is evolving from medicine dispensing to delivering\ncomprehensive pharmaceutical services within multidisciplinary healthcare\nteams. Central to this shift is access to accurate, up-to-date medicinal\nproduct information supported by robust data integration. Leveraging artificial\nintelligence and semantic technologies, Knowledge Graphs (KGs) uncover hidden\nrelationships and enable data-driven decision-making. This paper presents\nmedicX-KG, a pharmacist-oriented knowledge graph supporting clinical and\nregulatory decisions. It forms the semantic layer of the broader medicX\nplatform, powering predictive and explainable pharmacy services. medicX-KG\nintegrates data from three sources, including, the British National Formulary\n(BNF), DrugBank, and the Malta Medicines Authority (MMA) that addresses Malta's\nregulatory landscape and combines European Medicines Agency alignment with\npartial UK supply dependence. The KG tackles the absence of a unified national\ndrug repository, reducing pharmacists' reliance on fragmented sources. Its\ndesign was informed by interviews with practicing pharmacists to ensure\nreal-world applicability. We detail the KG's construction, including data\nextraction, ontology design, and semantic mapping. Evaluation demonstrates that\nmedicX-KG effectively supports queries about drug availability, interactions,\nadverse reactions, and therapeutic classes. Limitations, including missing\ndetailed dosage encoding and real-time updates, are discussed alongside\ndirections for future enhancements.", "AI": {"tldr": "本文介绍了medicX-KG，一个面向药剂师的知识图谱，用于支持临床和监管决策，整合了多源药物数据，并通过人工智能和语义技术提升药学服务质量。", "motivation": "药剂师角色正从药品调配转向提供综合药学服务，需要准确、最新的药物信息支持。现有药物信息来源分散，缺乏统一的国家级药物库，medicX-KG旨在解决这一问题。", "method": "medicX-KG整合了英国国家处方集(BNF)、DrugBank和马耳他药品管理局(MMA)的数据，采用知识图谱技术构建语义层，包括数据提取、本体设计和语义映射。设计过程中还采访了执业药剂师以确保实用性。", "result": "评估表明，medicX-KG能有效支持关于药物可用性、相互作用、不良反应和治疗类别的查询。但仍存在局限性，如缺少详细的剂量编码和实时更新功能。", "conclusion": "medicX-KG为药剂师提供了一个统一的药物信息平台，支持数据驱动的决策。未来需进一步完善剂量编码和实时更新功能，以提升系统的全面性和时效性。"}}
{"id": "2506.18265", "categories": ["math.OC", "90-08, 90C11, 90C22"], "pdf": "https://arxiv.org/pdf/2506.18265", "abs": "https://arxiv.org/abs/2506.18265", "authors": ["Daniel de Roux", "Zedong Peng", "David E. Bernal Neira"], "title": "Spectral Outer-Approximation Algorithms for Binary Semidefinite Problems", "comment": null, "summary": "Integer semidefinite programming (ISDP) has recently gained attention due to\nits connection to binary quadratically constrained quadratic programs (BQCQPs),\nwhich can be exactly reformulated as binary semidefinite programs (BSDPs).\nHowever, it remains unclear whether this reformulation effectively uses\nexisting ISDP solvers to address BQCQPs. To the best of our knowledge, no\nspecialized ISDP algorithms exploit the unique structure of BSDPs derived from\nBQCQPs. This paper proposes a novel spectral outer approximation algorithm\ntailored for BSDPs derived from BQCQP reformulations. Our approach is inspired\nby polyhedral and second-order representable regions that outer approximate the\nfeasible set of a semidefinite program relying on a spectral decomposition of a\nmatrix that simultaneously diagonalizes the objective matrix and an aggregation\nof the constraint matrices. Computational experiments show that our algorithm\nis competitive with, and in some cases outperforms, state-of-the-art ISDP\nsolvers such as SCIP-SDP and PAJARITO, highlighting ISDP's potential for\nsolving BQCQPs.", "AI": {"tldr": "本文提出了一种针对二元二次约束二次规划（BQCQP）衍生的二元半定规划（BSDP）的谱外逼近算法，该算法在计算实验中表现优异，甚至超越现有ISDP求解器。", "motivation": "尽管整数半定规划（ISDP）与二元二次约束二次规划（BQCQP）存在关联，但现有ISDP求解器是否有效利用BQCQP的独特结构尚不明确。本文旨在填补这一空白。", "method": "提出了一种基于谱分解的谱外逼近算法，利用多面体和二阶可表示区域外逼近半定规划的可行集，同时对角化目标矩阵和约束矩阵的聚合矩阵。", "result": "计算实验表明，该算法在性能上与SCIP-SDP和PAJARITO等先进ISDP求解器相当，甚至在某些情况下表现更优。", "conclusion": "该研究凸显了ISDP在解决BQCQP问题中的潜力，并为相关领域提供了新的求解思路。"}}
{"id": "2506.17622", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17622", "abs": "https://arxiv.org/abs/2506.17622", "authors": ["Shengchen Ling", "Yuefeng Du", "Yajin Zhou", "Lei Wu", "Cong Wang", "Xiaohua Jia", "Houmin Yan"], "title": "SoK: Stablecoin Designs, Risks, and the Stablecoin LEGO", "comment": null, "summary": "Stablecoins have become significant assets in modern finance, with a market\ncapitalization exceeding USD 246 billion (May 2025). Yet, despite their\nsystemic importance, a comprehensive and risk-oriented understanding of crucial\naspects like their design trade-offs, security dynamics, and interdependent\nfailure pathways often remains underdeveloped. This SoK confronts this gap\nthrough a large-scale analysis of 157 research studies, 95 active stablecoins,\nand 44 major security incidents. Our analysis establishes four pivotal\ninsights: 1) stability is best understood not an inherent property but an\nemergent, fragile state reliant on the interplay between market confidence and\ncontinuous liquidity; 2) stablecoin designs demonstrate trade-offs in risk\nspecialization instead of mitigation; 3) the widespread integration of yield\nmechanisms imposes a \"dual mandate\" that creates a systemic tension between the\ncore mission of stability and the high-risk financial engineering required for\ncompetitive returns; and 4) major security incidents act as acute \"evolutionary\npressures\", forging resilience by stress-testing designs and aggressively\nredefining the security frontier. We introduce the Stablecoin LEGO framework, a\nquantitative methodology mapping historical failures to current designs. Its\napplication reveals that a lower assessed risk strongly correlates with\nintegrating lessons from past incidents. We hope this provides a systematic\nfoundation for building, evaluating, and regulating more resilient stablecoins.", "AI": {"tldr": "本文通过分析157项研究、95种活跃稳定币及44起重大安全事件，提出稳定币稳定性是市场信心与流动性互动的脆弱状态，设计存在风险专业化而非缓释的权衡，收益率机制导致稳定性与高风险金融工程的系统性矛盾，安全事件通过压力测试重塑安全边界。作者提出Stablecoin LEGO框架，揭示历史教训整合与风险评估的强相关性。", "motivation": "尽管稳定币市值已超2460亿美元（2025年5月），但其设计权衡、安全动态及连锁失效路径等关键风险认知仍不完善。本研究旨在填补这一空白。", "method": "对157项学术研究、95种活跃稳定币及44起重大安全事件进行大规模分析，并开发定量框架Stablecoin LEGO，将历史失败映射至现有设计。", "result": "四大核心发现：1）稳定性是市场信心与流动性互动的涌现状态；2）设计呈现风险专业化而非缓释的权衡；3）收益率机制引发稳定性使命与高风险金融工程的系统性矛盾；4）安全事件通过压力测试推动韧性进化。LEGO框架显示历史教训整合与低风险强相关。", "conclusion": "研究为构建、评估及监管更具韧性的稳定币提供了系统性基础，强调从历史事件中学习对降低风险的关键作用。"}}
{"id": "2506.18019", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18019", "abs": "https://arxiv.org/abs/2506.18019", "authors": ["Yuanchen Bei", "Weizhi Zhang", "Siwen Wang", "Weizhi Chen", "Sheng Zhou", "Hao Chen", "Yong Li", "Jiajun Bu", "Shirui Pan", "Yizhou Yu", "Irwin King", "Fakhri Karray", "Philip S. Yu"], "title": "Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities", "comment": "20 pages, 7 figures", "summary": "AI agents have experienced a paradigm shift, from early dominance by\nreinforcement learning (RL) to the rise of agents powered by large language\nmodels (LLMs), and now further advancing towards a synergistic fusion of RL and\nLLM capabilities. This progression has endowed AI agents with increasingly\nstrong abilities. Despite these advances, to accomplish complex real-world\ntasks, agents are required to plan and execute effectively, maintain reliable\nmemory, and coordinate smoothly with other agents. Achieving these capabilities\ninvolves contending with ever-present intricate information, operations, and\ninteractions. In light of this challenge, data structurization can play a\npromising role by transforming intricate and disorganized data into\nwell-structured forms that agents can more effectively understand and process.\nIn this context, graphs, with their natural advantage in organizing, managing,\nand harnessing intricate data relationships, present a powerful data paradigm\nfor structurization to support the capabilities demanded by advanced AI agents.\nTo this end, this survey presents a first systematic review of how graphs can\nempower AI agents. Specifically, we explore the integration of graph techniques\nwith core agent functionalities, highlight notable applications, and identify\nprospective avenues for future research. By comprehensively surveying this\nburgeoning intersection, we hope to inspire the development of next-generation\nAI agents equipped to tackle increasingly sophisticated challenges with graphs.\nRelated resources are collected and continuously updated for the community in\nthe Github link.", "AI": {"tldr": "本文综述了图技术如何赋能AI智能体，探讨了图技术与智能体核心功能的结合、显著应用及未来研究方向，旨在推动下一代AI智能体的发展。", "motivation": "随着AI智能体从强化学习主导转向大语言模型驱动，再到两者融合，其能力不断增强。然而，完成复杂现实任务需要智能体有效规划执行、可靠记忆及多智能体协调，面对庞杂信息与交互，数据结构化成为关键挑战。", "method": "通过将复杂无序数据转化为结构化形式（尤其是利用图在组织与管理数据关系上的天然优势），系统回顾图技术如何增强AI智能体，包括功能整合、应用案例及未来方向。", "result": "图技术为AI智能体提供了强大的数据结构化支持，使其能更高效处理复杂任务。相关资源已在Github链接中持续更新供社区使用。", "conclusion": "图技术与AI智能体的交叉研究有望推动下一代智能体发展，以应对日益复杂的挑战。本综述旨在激发这一新兴领域的创新。"}}
{"id": "2506.18278", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.18278", "abs": "https://arxiv.org/abs/2506.18278", "authors": ["Yujie Liu", "Vincent Y. F. Tan", "Yunbei Xu"], "title": "Finite-Time Information-Theoretic Bounds in Queueing Control", "comment": null, "summary": "We establish the first finite-time information-theoretic lower bounds-and\nderive new policies that achieve them-for the total queue length in scheduling\nproblems over stochastic processing networks with both adversarial and\nstochastic arrivals. Prior analyses of MaxWeight guarantee only stability and\nasymptotic optimality in heavy traffic; we prove that, at finite horizons,\nMaxWeight can incur strictly larger backlog by problem-dependent factors which\nwe identify. Our main innovations are 1) a minimax framework that pinpoints the\nprecise problem parameters governing any policy's finite-time performance; 2)\nan information-theoretic lower bound on total queue length; 3) fundamental\nlimitation of MaxWeight that it is suboptimal in finite time; and 4) a new\nscheduling rule that minimizes the full Lyapunov drift-including its\nsecond-order term-thereby matching the lower bound under certain conditions, up\nto universal constants. These findings reveal a fundamental limitation on\n\"drift-only\" methods and points the way toward principled, non-asymptotic\noptimality in queueing control.", "AI": {"tldr": "本文首次建立了随机处理网络中调度问题的有限时间信息论下界，并提出了达到这些下界的新策略。研究发现MaxWeight策略在有限时间内存在性能缺陷，并提出了一种优化Lyapunov漂移的新调度规则。", "motivation": "现有MaxWeight策略仅保证稳定性和在重负载下的渐近最优性，但缺乏对有限时间内性能的理论分析。本文旨在填补这一空白，揭示有限时间内调度策略的性能限制。", "method": "1) 建立极小极大框架确定问题参数；2) 推导总队列长度的信息论下界；3) 分析MaxWeight的局限性；4) 提出包含二阶项的Lyapunov漂移优化新策略。", "result": "证明了MaxWeight在有限时间内会因问题相关因素导致更大积压；新调度规则在一定条件下能匹配下界（误差为通用常数）。", "conclusion": "研究揭示了'仅漂移'方法的根本局限，为队列控制中的非渐近最优性提供了理论方向。新策略通过全面优化Lyapunov漂移实现了有限时间最优性突破。"}}
{"id": "2506.17625", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17625", "abs": "https://arxiv.org/abs/2506.17625", "authors": ["Pengzhen Ke", "Liang Feng Zhang", "Huaxiong Wang", "Li-Ping Wang"], "title": "List-Decodable Byzantine Robust PIR: Lower Communication Complexity, Higher Byzantine Tolerance, Smaller List Size", "comment": "Submitted to AsiaCrypt 2025", "summary": "Private Information Retrieval (PIR) is a privacy-preserving primitive in\ncryptography. Significant endeavors have been made to address the variant of\nPIR concerning the malicious servers. Among those endeavors, list-decodable\nByzantine robust PIR schemes may tolerate a majority of malicious responding\nservers that provide incorrect answers. In this paper, we propose two perfect\nlist-decodable BRPIR schemes. Our schemes are the first ones that can\nsimultaneously handle a majority of malicious responding servers, achieve a\ncommunication complexity of $o(n^{1/2})$ for a database of size n, and provide\na nontrivial estimation on the list sizes. Compared with the existing\nsolutions, our schemes attain lower communication complexity, higher byzantine\ntolerance, and smaller list size.", "AI": {"tldr": "本文提出了两种完美的列表可解码拜占庭鲁棒私有信息检索（BRPIR）方案，首次实现了同时处理多数恶意服务器、低通信复杂度$o(n^{1/2})$及非平凡列表大小估计。", "motivation": "现有拜占庭鲁棒PIR方案在应对多数恶意服务器、通信复杂度及列表大小估计方面存在不足，亟需改进。", "method": "设计了两种新型完美列表可解码BRPIR方案，通过优化算法结构提升鲁棒性并降低通信开销。", "result": "相比现有方案，新方案通信复杂度更低（$o(n^{1/2})$）、拜占庭容忍度更高（支持多数恶意服务器）、列表大小更小。", "conclusion": "该研究为恶意服务器场景下的隐私保护检索提供了更高效的解决方案，在多项关键指标上超越现有技术。"}}
{"id": "2506.18044", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18044", "abs": "https://arxiv.org/abs/2506.18044", "authors": ["Joseph Babb", "Joohyung Lee"], "title": "Action Language BC+", "comment": "Journal of Logic and Computation, 2015", "summary": "Action languages are formal models of parts of natural language that are\ndesigned to describe effects of actions. Many of these languages can be viewed\nas high level notations of answer set programs structured to represent\ntransition systems. However, the form of answer set programs considered in the\nearlier work is quite limited in comparison with the modern Answer Set\nProgramming (ASP) language, which allows several useful constructs for\nknowledge representation, such as choice rules, aggregates, and abstract\nconstraint atoms. We propose a new action language called BC+, which closes the\ngap between action languages and the modern ASP language. The main idea is to\ndefine the semantics of BC+ in terms of general stable model semantics for\npropositional formulas, under which many modern ASP language constructs can be\nidentified with shorthands for propositional formulas. Language BC+ turns out\nto be sufficiently expressive to encompass the best features of other action\nlanguages, such as languages B, C, C+, and BC. Computational methods available\nin ASP solvers are readily applicable to compute BC+, which led to an\nimplementation of the language by extending system cplus2asp.", "AI": {"tldr": "本文提出了一种新的动作语言BC+，旨在弥合传统动作语言与现代答案集编程(ASP)语言之间的差距，通过广义稳定模型语义实现更丰富的知识表示能力。", "motivation": "传统动作语言在表达能力上与现代ASP语言存在显著差距，后者支持选择规则、聚合等实用结构。BC+旨在整合两者的优势。", "method": "基于命题公式的广义稳定模型语义定义BC+语言，将现代ASP构造视为命题公式的简写形式，并扩展cplus2asp系统实现该语言。", "result": "BC+成功涵盖了B、C、C+等主流动作语言的优秀特性，且可直接利用ASP求解器进行计算，实现了理论表达与计算实践的融合。", "conclusion": "BC+通过统一框架整合了动作语言与ASP的最新进展，其实现证明了该语言在知识表示和自动推理领域的实用价值。"}}
{"id": "2506.18301", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.18301", "abs": "https://arxiv.org/abs/2506.18301", "authors": ["Johannes Heid", "Nils Bornhorst", "Eric Tönges", "Philipp Härtel", "Denis Mende", "Martin Braun"], "title": "A Computationally Efficient Method for Solving Mixed-Integer AC Optimal Power Flow Problems", "comment": null, "summary": "Stepwise controllable devices, such as switched capacitors or stepwise\ncontrollable loads and generators, transform the nonconvex AC optimal power\nflow (AC-OPF) problem into a nonconvex mixed-integer (MI) programming problem\nwhich is generally hard to solve optimally. Existing methods for solving\nMI-AC-OPF problems usually suffer from either limited accuracy or computational\nintractability, making them impractical for real-world applications. To address\nthese challenges, we propose an efficient iterative deflation approach\nproviding high-quality approximate solutions. In each iteration, a continuously\nrelaxed version of the MI-AC-OPF problem is solved and one candidate integer\nvalue is systematically eliminated based on the evaluation of a simple power\nflow result. The computational complexity of the proposed algorithm grows\nlinearly with the number of integer optimization variables, ensuring\nscalability. Simulations demonstrate that the proposed approach achieves\nsignificant improvements in solution accuracy compared to a state-of-the-art\napproach. Thus, the proposed method is promising for solving practical\nMI-AC-OPF problems.", "AI": {"tldr": "提出了一种高效的迭代收缩方法，用于解决混合整数交流最优潮流问题，显著提高了求解精度和计算效率。", "motivation": "现有方法在处理混合整数交流最优潮流问题时，往往面临精度不足或计算复杂度过高的挑战，难以满足实际应用需求。", "method": "通过迭代求解连续松弛的混合整数交流最优潮流问题，并基于简单潮流结果系统性地消除候选整数值，算法计算复杂度随整数变量数量线性增长。", "result": "仿真结果表明，与现有先进方法相比，所提方法在求解精度上取得了显著提升。", "conclusion": "该方法为解决实际混合整数交流最优潮流问题提供了高效且精确的解决方案，具有广阔的应用前景。"}}
{"id": "2506.17767", "categories": ["cs.CR", "cs.DC", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17767", "abs": "https://arxiv.org/abs/2506.17767", "authors": ["Hsuan-Po Liu", "Hessam Mahdavifar"], "title": "A Locally Differential Private Coding-Assisted Succinct Histogram Protocol", "comment": null, "summary": "A succinct histogram captures frequent items and their frequencies across\nclients and has become increasingly important for large-scale,\nprivacy-sensitive machine learning applications. To develop a rigorous\nframework to guarantee privacy for the succinct histogram problem, local\ndifferential privacy (LDP) has been utilized and shown promising results. To\npreserve data utility under LDP, which essentially works by intentionally\nadding noise to data, error-correcting codes naturally emerge as a promising\ntool for reliable information collection. This work presents the first\npractical $(\\epsilon,\\delta)$-LDP protocol for constructing succinct histograms\nusing error-correcting codes. To this end, polar codes and their\nsuccessive-cancellation list (SCL) decoding algorithms are leveraged as the\nunderlying coding scheme. More specifically, our protocol introduces\nGaussian-based perturbations to enable efficient soft decoding. Experiments\ndemonstrate that our approach outperforms prior methods, particularly for items\nwith low true frequencies, while maintaining similar frequency estimation\naccuracy.", "AI": {"tldr": "本文提出首个实用的$(\\epsilon,\\delta)$-LDP协议，利用极性码和SCL解码算法构建简洁直方图，通过高斯扰动实现高效软解码，在低频率项上优于现有方法。", "motivation": "在隐私敏感的大规模机器学习应用中，简洁直方图需在保证本地差分隐私(LDP)的同时维持数据效用，纠错码成为可靠信息收集的有力工具。", "method": "采用极性码及其连续取消列表(SCL)解码算法作为底层编码方案，引入基于高斯分布的扰动机制以实现高效软解码。", "result": "实验表明该方法在低真实频率项上表现优异，同时保持与现有方法相近的频率估计精度。", "conclusion": "该协议首次将纠错码与LDP相结合，为隐私保护的简洁直方图构建提供了高效解决方案，特别适用于稀疏数据场景。"}}
{"id": "2506.18056", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18056", "abs": "https://arxiv.org/abs/2506.18056", "authors": ["Paolo Baldi", "Fabio Aurelio D'Asaro", "Abeer Dyoub", "Francesca Alessandra Lisi"], "title": "Weighted Assumption Based Argumentation to reason about ethical principles and actions", "comment": null, "summary": "We augment Assumption Based Argumentation (ABA for short) with weighted\nargumentation. In a nutshell, we assign weights to arguments and then derive\nthe weight of attacks between ABA arguments. We illustrate our proposal through\nrunning examples in the field of ethical reasoning, and present an\nimplementation based on Answer Set Programming.", "AI": {"tldr": "本文扩展了基于假设的论证（ABA），引入了加权论证机制，通过伦理推理案例进行演示，并基于答案集编程实现了该方法。", "motivation": "为增强基于假设的论证（ABA）的表达能力，研究提出在论证过程中引入权重概念，以更精细地刻画论证强度与攻击关系。", "method": "在ABA框架中为论证分配权重，推导论证间攻击关系的权重值，并以伦理推理为例说明方法，最终基于答案集编程实现该加权体系。", "result": "成功构建了加权ABA框架，通过具体案例验证了权重机制在伦理推理中的适用性，并开发了可操作的计算实现。", "conclusion": "加权ABA扩展了传统论证框架的表达能力，为复杂场景（如伦理决策）提供了更精细的论证分析工具，其计算实现证明了方法的可行性。"}}
{"id": "2506.18409", "categories": ["math.OC", "math.DS", "11Y55, 11K31, 39A12, 90C26"], "pdf": "https://arxiv.org/pdf/2506.18409", "abs": "https://arxiv.org/abs/2506.18409", "authors": ["Assalé Adjé"], "title": "On the Maximization of Real Sequences", "comment": "31 pages", "summary": "In this paper, we study a maximization problem on real sequences. More\nprecisely, for a given sequence, we are interesting in computing the supremum\nof the sequence and an index for which the associated term is maximal. We\npropose a general methodology to solve this maximization problem. The method is\nbased on upper approximations constructed from pairs of eventually decreasing\nsequences of strictly increasing continuous functions on $[0,1]$ and of scalars\nin $(0,1)$. Then, we can associate integers with those pairs using inverses on\n$[0,1]$ of the functions. We prove that such pairs always exist and one\nprovides the index maximizer. In general, such pairs provide an upper bound of\nthe greatest maximizer of the sequence. Finally, we apply the methodology on\nconcrete examples including famous sequences such as logistic, Fibonacci and\nSyracuse sequences. We also apply our techniques to norm based peaks\ncomputation problems on discrete-time linear systems.", "AI": {"tldr": "本文提出了一种基于上界逼近的通用方法，用于求解实数序列的最大化问题，并在多种著名序列上验证了其有效性。", "motivation": "研究实数序列的最大化问题，旨在找到序列的上确界及对应最大项的索引，为理论分析和实际应用提供数学工具。", "method": "方法基于构造由严格递增连续函数序列和标量序列组成的上界逼近对，并通过函数在$[0,1]$上的逆映射关联整数索引。", "result": "证明了此类逼近对的存在性，其可提供序列最大值的上界及极大化索引，并在Logistic、Fibonacci等经典序列及线性系统范数峰值计算中得到应用验证。", "conclusion": "所提方法具有普适性和理论保证，能有效解决多种序列最大化问题，为离散系统分析提供了新工具。"}}
{"id": "2506.17795", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17795", "abs": "https://arxiv.org/abs/2506.17795", "authors": ["Rachel Cazzola", "Cyrus Minwalla", "Calvin Chan", "Jim Plusquellic"], "title": "A TRNG Implemented using a Soft-Data Based Sponge Function within a Unified Strong PUF Architecture", "comment": null, "summary": "Hardware security primitives including True Random Number Generators (TRNG)\nand Physical Unclonable Functions (PUFs) are central components to establishing\na root of trust in microelectronic systems. In this paper, we propose a unified\nPUF-TRNG architecture that leverages a combination of the static entropy\navailable in a strong PUF called the shift-register, reconvergent-fanout (SiRF)\nPUF, and the dynamic entropy associated with random noise present in path delay\nmeasurements. The SiRF PUF uses an engineered netlist containing a large number\nof paths as the source of static entropy, and a time-to-digital-converter (TDC)\nas a high-resolution, embedded instrument for measuring path delays, where\nmeasurement noise serves as the source of dynamic entropy. A novel data\npostprocessing algorithm is proposed based on a modified duplex sponge\nconstruction. The sponge function operates on soft data, i.e., fixed point data\nvalues, to add entropy to the ensuing random bit sequences and to increase the\nbit generation rate. A postprocessing algorithm for reproducing PUF-generated\nencryption keys is also used in the TRNG to protect against temperature voltage\nattacks designed to subvert the random characteristics in the bit sequences.\nThe unified PUF-TRNG architecture is implemented across multiple instances of a\nZYBO Z7-10 FPGA board and extensively tested with NIST SP 800-22, NIST SP\n800-90B, AIS-31, and DieHarder test suites. Results indicate a stable and\nrobust TRNG design with excellent min-entropy and a moderate data rate.", "AI": {"tldr": "本文提出了一种结合PUF和TRNG的统一架构，利用静态熵和动态噪声熵生成高安全性随机数，并通过多种测试验证其稳健性。", "motivation": "硬件安全原语如TRNG和PUF是微电子系统信任根的核心组件，但现有方案在熵源利用和抗攻击能力上存在不足，需设计更高效、安全的统一架构。", "method": "采用SiRF PUF的静态熵与路径延迟测量的动态噪声熵，结合改进的双工海绵结构进行数据后处理，并嵌入TDC高精度测量，同时设计抗温压攻击的密钥再生算法。", "result": "在ZYBO Z7-10 FPGA上实现的多实例测试显示，该架构通过NIST SP 800-22等全套测试，具有优异的最小熵和适中数据速率。", "conclusion": "所提出的PUF-TRNG统一架构能稳定生成高质量随机数，兼具抗攻击性和实用性，为硬件安全提供了有效解决方案。"}}
{"id": "2506.18096", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18096", "abs": "https://arxiv.org/abs/2506.18096", "authors": ["Yuxuan Huang", "Yihang Chen", "Haozheng Zhang", "Kang Li", "Meng Fang", "Linyi Yang", "Xiaoguang Li", "Lifeng Shang", "Songcen Xu", "Jianye Hao", "Kun Shao", "Jun Wang"], "title": "Deep Research Agents: A Systematic Examination And Roadmap", "comment": null, "summary": "The rapid progress of Large Language Models (LLMs) has given rise to a new\ncategory of autonomous AI systems, referred to as Deep Research (DR) agents.\nThese agents are designed to tackle complex, multi-turn informational research\ntasks by leveraging a combination of dynamic reasoning, adaptive long-horizon\nplanning, multi-hop information retrieval, iterative tool use, and the\ngeneration of structured analytical reports. In this paper, we conduct a\ndetailed analysis of the foundational technologies and architectural components\nthat constitute Deep Research agents. We begin by reviewing information\nacquisition strategies, contrasting API-based retrieval methods with\nbrowser-based exploration. We then examine modular tool-use frameworks,\nincluding code execution, multimodal input processing, and the integration of\nModel Context Protocols (MCPs) to support extensibility and ecosystem\ndevelopment. To systematize existing approaches, we propose a taxonomy that\ndifferentiates between static and dynamic workflows, and we classify agent\narchitectures based on planning strategies and agent composition, including\nsingle-agent and multi-agent configurations. We also provide a critical\nevaluation of current benchmarks, highlighting key limitations such as\nrestricted access to external knowledge, sequential execution inefficiencies,\nand misalignment between evaluation metrics and the practical objectives of DR\nagents. Finally, we outline open challenges and promising directions for future\nresearch. A curated and continuously updated repository of DR agent research is\navailable at: {https://github.com/ai-agents-2030/awesome-deep-research-agent}.", "AI": {"tldr": "本文系统分析了深度研究(DR)智能体的核心技术架构，提出了工作流分类法并评估了现有基准的局限性，同时指出了未来研究方向。", "motivation": "随着大语言模型(LLM)的发展，能够执行复杂多轮信息研究任务的自主AI系统——深度研究智能体应运而生，需要对其技术架构进行系统性研究。", "method": "通过对比API检索与浏览器探索的信息获取策略，研究模块化工具使用框架，提出区分静态/动态工作流的分类法，并按规划策略和智能体构成进行分类。", "result": "构建了DR智能体技术体系分类框架，指出当前基准测试存在外部知识访问受限、顺序执行效率低下、评估指标与实际目标错位等关键局限。", "conclusion": "深度研究智能体领域仍需解决开放性挑战，论文提出了未来研究方向并建立了持续更新的研究资源库。"}}
{"id": "2506.18417", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.18417", "abs": "https://arxiv.org/abs/2506.18417", "authors": ["Thomas Berger"], "title": "An improved input-constrained funnel controller for nonlinear systems", "comment": null, "summary": "We present an improvement of a recent funnel controller design for uncertain\nnonlinear multi-input, multi-output systems modeled by higher order functional\ndifferential equations in the presence of input constraints. The objective is\nto guarantee the evolution of the tracking error within a performance funnel\nwith prescribed desired shape for the case of inactive saturation. Compared to\nits precursor, controller complexity is significantly reduced, much fewer\ndesign parameters are involved and simulations exhibit a superior performance.", "AI": {"tldr": "本文提出了一种改进的漏斗控制器设计，用于具有输入约束的高阶非线性多输入多输出系统，显著降低了控制器复杂度并提升了性能。", "motivation": "针对现有漏斗控制器在非线性多输入多输出系统中设计参数多、复杂度高的问题，提出改进方案以简化设计并提升跟踪性能。", "method": "通过优化高阶泛函微分方程建模的控制器结构，减少设计参数数量，并在输入饱和未激活时确保跟踪误差按预设漏斗边界演化。", "result": "改进后的控制器复杂度显著降低，所需设计参数更少，仿真结果显示出更优越的控制性能。", "conclusion": "该研究为不确定非线性系统提供了一种更简洁高效的漏斗控制方案，在保证性能的同时大幅降低了实现难度。"}}
{"id": "2506.17805", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17805", "abs": "https://arxiv.org/abs/2506.17805", "authors": ["Md. Kamrul Hossain", "Walid Aljoby", "Anis Elgabli", "Ahmed M. Abdelmoniem", "Khaled A. Harras"], "title": "AdRo-FL: Informed and Secure Client Selection for Federated Learning in the Presence of Adversarial Aggregator", "comment": "17 pages", "summary": "Federated Learning (FL) enables collaborative learning without exposing\nclients' data. While clients only share model updates with the aggregator,\nstudies reveal that aggregators can infer sensitive information from these\nupdates. Secure Aggregation (SA) protects individual updates during\ntransmission; however, recent work demonstrates a critical vulnerability where\nadversarial aggregators manipulate client selection to bypass SA protections,\nconstituting a Biased Selection Attack (BSA). Although verifiable random\nselection prevents BSA, it precludes informed client selection essential for FL\nperformance. We propose Adversarial Robust Federated Learning (AdRo-FL), which\nsimultaneously enables: informed client selection based on client utility, and\nrobust defense against BSA maintaining privacy-preserving aggregation. AdRo-FL\nimplements two client selection frameworks tailored for distinct settings. The\nfirst framework assumes clients are grouped into clusters based on mutual\ntrust, such as different branches of an organization. The second framework\nhandles distributed clients where no trust relationships exist between them.\nFor the cluster-oriented setting, we propose a novel defense against BSA by (1)\nenforcing a minimum client selection quota from each cluster, supervised by a\ncluster-head in every round, and (2) introducing a client utility function to\nprioritize efficient clients. For the distributed setting, we design a\ntwo-phase selection protocol: first, the aggregator selects the top clients\nbased on our utility-driven ranking; then, a verifiable random function (VRF)\nensures a BSA-resistant final selection. AdRo-FL also applies quantization to\nreduce communication overhead and sets strict transmission deadlines to improve\nenergy efficiency. AdRo-FL achieves up to $1.85\\times$ faster time-to-accuracy\nand up to $1.06\\times$ higher final accuracy compared to insecure baselines.", "AI": {"tldr": "AdRo-FL提出了一种对抗性鲁棒联邦学习框架，既能基于客户端效用进行智能选择，又能防御偏置选择攻击(BSA)，同时保持隐私保护的聚合机制，在集群和分布式两种设置下均表现优异。", "motivation": "现有联邦学习(FL)中，安全聚合(SA)虽能保护个体更新，但易受恶意聚合器通过偏置选择攻击(BSA)的操纵。可验证随机选择虽能防御BSA，却无法实现影响FL性能的关键智能客户端选择。", "method": "AdRo-FL针对两种场景设计：1) 集群场景：通过每轮强制最小客户端选择配额（由集群头监督）和引入效用函数优先高效客户端；2) 分布式场景：采用两阶段协议（效用排名初选+可验证随机函数终选）。同时应用量化和严格传输期限优化通信与能效。", "result": "相比不安全基线，AdRo-FL实现最高$1.85\\times$的准确率达成速度提升和$1.06\\times$的最终准确率提高。", "conclusion": "AdRo-FL首次在联邦学习中实现了智能客户端选择与BSA防御的兼容，通过场景定制化设计、量化压缩和时效控制，显著提升学习效率与模型性能，为隐私保护协作学习提供了新范式。"}}
{"id": "2506.18126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18126", "abs": "https://arxiv.org/abs/2506.18126", "authors": ["Xiang Yuming", "Li Sizhao", "Li Rongpeng", "Zhao Zhifeng", "Zhang Honggang"], "title": "Decentralized Consensus Inference-based Hierarchical Reinforcement Learning for Multi-Constrained UAV Pursuit-Evasion Game", "comment": null, "summary": "Multiple quadrotor unmanned aerial vehicle (UAV) systems have garnered\nwidespread research interest and fostered tremendous interesting applications,\nespecially in multi-constrained pursuit-evasion games (MC-PEG). The Cooperative\nEvasion and Formation Coverage (CEFC) task, where the UAV swarm aims to\nmaximize formation coverage across multiple target zones while collaboratively\nevading predators, belongs to one of the most challenging issues in MC-PEG,\nespecially under communication-limited constraints. This multifaceted problem,\nwhich intertwines responses to obstacles, adversaries, target zones, and\nformation dynamics, brings up significant high-dimensional complications in\nlocating a solution. In this paper, we propose a novel two-level framework\n(i.e., Consensus Inference-based Hierarchical Reinforcement Learning (CI-HRL)),\nwhich delegates target localization to a high-level policy, while adopting a\nlow-level policy to manage obstacle avoidance, navigation, and formation.\nSpecifically, in the high-level policy, we develop a novel multi-agent\nreinforcement learning module, Consensus-oriented Multi-Agent Communication\n(ConsMAC), to enable agents to perceive global information and establish\nconsensus from local states by effectively aggregating neighbor messages.\nMeanwhile, we leverage an Alternative Training-based Multi-agent proximal\npolicy optimization (AT-M) and policy distillation to accomplish the low-level\ncontrol. The experimental results, including the high-fidelity\nsoftware-in-the-loop (SITL) simulations, validate that CI-HRL provides a\nsuperior solution with enhanced swarm's collaborative evasion and task\ncompletion capabilities.", "AI": {"tldr": "本文提出了一种名为CI-HRL的两层框架，用于解决多约束追逃游戏中的协同规避与编队覆盖任务，通过高层策略进行目标定位，低层策略管理避障、导航和编队，实验验证了其优越性。", "motivation": "多无人机系统在多约束追逃游戏中的应用面临高维复杂问题，尤其是在通信受限条件下，协同规避与编队覆盖任务极具挑战性。", "method": "提出CI-HRL框架，高层策略使用ConsMAC模块实现全局信息感知与共识建立，低层策略采用AT-M和策略蒸馏技术完成控制。", "result": "高保真SITL仿真实验表明，CI-HRL显著提升了无人机群的协同规避和任务完成能力。", "conclusion": "CI-HRL为多约束追逃游戏中的协同规避与编队覆盖任务提供了一种高效解决方案，具有实际应用潜力。"}}
{"id": "2506.18806", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.18806", "abs": "https://arxiv.org/abs/2506.18806", "authors": ["Yihong Zhou", "Hanbin Yang", "Thomas Morstyn"], "title": "FICA: Faster Inner Convex Approximation of Chance Constrained Grid Dispatch with Decision-Coupled Uncertainty", "comment": "10 pages, in review for IEEE Transactions on Power Systems", "summary": "This paper proposes a Faster Inner Convex Approximation (FICA) method for\nsolving power system dispatch problems with Wasserstein distributionally robust\njoint chance constraints (WJCC) and incorporating the modelling of the\nautomatic generation control factors. The problem studied belongs to the\ncomputationally challenging class of WJCC with left-hand-side uncertainty\n(LHS-WJCC). By exploiting the special one-dimensional structure (even if only\npartially present) of the problem, the proposed FICA incorporates a set of\nstrong valid inequalities to accelerate the solution process. We prove that\nFICA achieves the same optimality as the well-known conditional value-at-risk\n(CVaR) inner convex approximation method. Our numerical experiments demonstrate\nthat the proposed FICA can yield 40x computational speedup compared to CVaR,\nand can even reach up to 500x speedup when the optimisation horizon exceeds 16\ntime steps. This speedup is achieved when only 50% of constraints in a WJCC\nhave the one-dimensional structure. The approximation quality is numerically\nverified to be the same as CVaR, and the quality gap is below 1% when compared\nto the computationally demanding exact reformulation of the LHS-WJCC in most\ncases. We also discuss the applications of FICA in optimisation problems from\nother domains that (partially) exhibit the one-dimensional structure.", "AI": {"tldr": "本文提出了一种快速内凸近似方法(FICA)，用于解决具有Wasserstein分布鲁棒联合机会约束(WJCC)和自动发电控制因素建模的电力系统调度问题。该方法通过利用问题的一维结构特性，显著加速求解过程，计算速度提升可达500倍，同时保持与CVaR方法相同的近似质量。", "motivation": "针对电力系统调度中具有左侧不确定性的Wasserstein分布鲁棒联合机会约束(LHS-WJCC)问题计算复杂度高的挑战，研究旨在开发一种能保持最优性同时大幅提升计算效率的求解方法。", "method": "提出的FICA方法利用问题中(即使部分存在的)一维结构特性，引入一组强有效不等式加速求解过程。理论证明该方法与条件风险价值(CVaR)内凸近似法具有相同的最优性。", "result": "数值实验表明：1)在仅50%约束具有一维结构时，FICA相比CVaR可获得40倍加速；2)优化时间步长超过16步时加速比可达500倍；3)近似质量与CVaR相同，与计算密集的精确重构相比质量差距小于1%。", "conclusion": "FICA方法在保持解质量的同时显著提升计算效率，适用于电力系统调度及其他具有(部分)一维结构特性的优化问题，为解决复杂分布鲁棒优化问题提供了有效工具。"}}
{"id": "2506.17865", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.17865", "abs": "https://arxiv.org/abs/2506.17865", "authors": ["Dinesh Reddy Ankireddy", "Sudipta Paria", "Aritra Dasgupta", "Sandip Ray", "Swarup Bhunia"], "title": "LASA: Enhancing SoC Security Verification with LLM-Aided Property Generation", "comment": "9 pages, 5 figures, 5 tables", "summary": "Ensuring the security of modern System-on-Chip (SoC) designs poses\nsignificant challenges due to increasing complexity and distributed assets\nacross the intellectual property (IP) blocks. Formal property verification\n(FPV) provides the capability to model and validate design behaviors through\nsecurity properties with model checkers; however, current practices require\nsignificant manual efforts to create such properties, making them\ntime-consuming, costly, and error-prone. The emergence of Large Language Models\n(LLMs) has showcased remarkable proficiency across diverse domains, including\nHDL code generation and verification tasks. Current LLM-based techniques often\nproduce vacuous assertions and lack efficient prompt generation, comprehensive\nverification, and bug detection. This paper presents LASA, a novel framework\nthat leverages LLMs and retrieval-augmented generation (RAG) to produce\nnon-vacuous security properties and SystemVerilog Assertions (SVA) from design\nspecifications and related documentation for bus-based SoC designs. LASA\nintegrates commercial EDA tool for FPV to generate coverage metrics and\niteratively refines prompts through a feedback loop to enhance coverage. The\neffectiveness of LASA is validated through various open-source SoC designs,\ndemonstrating high coverage values with an average of ~88\\%, denoting\ncomprehensive verification through efficient generation of security properties\nand SVAs. LASA also demonstrates bug detection capabilities, identifying five\nunique bugs in the buggy OpenTitan SoC from Hack@DAC'24 competition.", "AI": {"tldr": "本文提出LASA框架，利用大语言模型（LLM）和检索增强生成（RAG）技术，自动生成非空泛的安全属性与SystemVerilog断言（SVA），显著提升基于总线SoC设计的验证效率与覆盖率（平均达88%），并成功检测出OpenTitan SoC中的五个独特漏洞。", "motivation": "现有形式化属性验证（FPV）需人工编写安全属性，耗时、昂贵且易错；而现有LLM技术生成的断言常存在空泛问题，且缺乏高效提示生成与全面验证能力。", "method": "LASA结合LLM与RAG技术，从设计文档生成非空泛SVA；集成商用EDA工具进行FPV验证，通过反馈循环迭代优化提示以提高覆盖率。", "result": "在多个开源SoC设计中验证有效性，平均覆盖率达~88%；在Hack@DAC'24竞赛的缺陷版OpenTitan SoC中检测出五个独特漏洞。", "conclusion": "LASA框架通过自动化生成高质量安全属性与断言，显著降低验证成本，提升覆盖率和漏洞检测能力，为复杂SoC安全验证提供高效解决方案。"}}
{"id": "2506.18135", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18135", "abs": "https://arxiv.org/abs/2506.18135", "authors": ["Zijun Chen", "Zhanpeng Zhou", "Bo Zhang", "Weinan Zhang", "Xi Sun", "Junchi Yan"], "title": "SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging", "comment": "preprint, accepted at IJCNN2025", "summary": "Model merging has gained increasing attention due to its intriguing property:\ninterpolating the parameters of different task-specific fine-tuned models leads\nto multi-task abilities. However, despite its empirical success, the underlying\nmechanisms of model merging remain poorly understood. In this work, we delve\ninto the mechanism behind model merging from a representation perspective. Our\nanalysis reveals that model merging achieves multi-task abilities through two\nkey capabilities: i) distinguishing samples from different tasks, and ii)\nadapting to the corresponding expert model for each sample. These two\ncapabilities allow the merged model to retain task-specific expertise, enabling\nefficient multi-task adaptation. Building on these insights, we propose\n\\texttt{SE-Merging}, a self-enhanced model merging framework that leverages\nthese two characteristics to dynamically identify the corresponding task for\neach sample and then adaptively rescales the merging coefficients to further\nenhance task-specific expertise in the merged model. Notably,\n\\texttt{SE-Merging} achieves dynamic model merging without additional training.\nExtensive experiments demonstrate that \\texttt{SE-Merging} achieves significant\nperformance improvements while remaining compatible with existing model merging\ntechniques.", "AI": {"tldr": "该研究从表示角度揭示了模型合并实现多任务能力的机制，并提出无需额外训练的\\texttt{SE-Merging}框架，通过动态识别任务和自适应调整合并系数显著提升性能。", "motivation": "尽管模型合并在实践中取得成功，但其底层机制尚不明确。本研究旨在从表示层面揭示模型合并如何实现多任务能力。", "method": "提出\\texttt{SE-Merging}框架，利用样本任务区分和专家模型适配两大特性，动态识别任务并自适应调整合并系数，无需额外训练即可增强任务特定专业知识。", "result": "大量实验表明，\\texttt{SE-Merging}在保持与现有技术兼容的同时，实现了显著的性能提升。", "conclusion": "模型合并通过任务区分和专家适配实现多任务能力，\\texttt{SE-Merging}框架有效利用这些特性动态优化合并过程，为模型合并领域提供了新见解。"}}
{"id": "2506.18884", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.18884", "abs": "https://arxiv.org/abs/2506.18884", "authors": ["Flavien Léger", "Maxime Sylvestre"], "title": "A comparison principle for variational problems : with an application to optimal transport", "comment": null, "summary": "We study variational problems on Banach spaces which involve submodular\nenergies. We extend the notion of exchangeability to this infinite dimensional\nsetting and show that it is in duality with submodularity. These two notions\nallow us to derive comparison principle in an abstract fashion. We apply our\nresults to the optimal transport and entropic optimal transport problems. We\nthen derive comparison principles on the Kantorovich and Schr\\\"odinger\npotentials. We also prove comparison principles for the associated JKO schemes.", "AI": {"tldr": "本文研究了Banach空间上涉及子模能量的变分问题，通过将交换性概念扩展到无限维空间并与子模性建立对偶关系，推导出抽象比较原理，并应用于最优传输和熵最优传输问题。", "motivation": "研究Banach空间上子模能量的变分问题，旨在建立无限维空间中的交换性与子模性的对偶关系，为最优传输及其相关领域提供理论支持。", "method": "将交换性概念扩展到无限维空间，证明其与子模性的对偶关系，并利用这些概念在抽象框架下推导比较原理。随后将结果应用于最优传输和熵最优传输问题。", "result": "在Kantorovich势和Schr\\\"odinger势上建立了比较原理，并证明了相关JKO格式的比较原理。", "conclusion": "通过建立无限维空间中的交换性与子模性的对偶关系，成功推导出抽象比较原理，并将其应用于最优传输和熵最优传输问题，为相关领域提供了新的理论工具。"}}
{"id": "2506.17935", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2506.17935", "abs": "https://arxiv.org/abs/2506.17935", "authors": ["Zhengwu Huang", "Ding Deng", "Pengyue Sun", "Guangfu Sun", "Xiaomei Tang"], "title": "Cost-Effective Optimization and Implementation of the CRT-Paillier Decryption Algorithm for Enhanced Performance", "comment": "19 pages,7 figures", "summary": "To address the privacy protection problem in cloud computing, privacy\nenhancement techniques such as the Paillier additive homomorphism algorithm are\nreceiving widespread attention. Paillier algorithm allows addition and scalar\nmultiplication operations in dencrypted state, which can effectively protect\nprivacy. However, its computational efficiency is limited by complex modulo\noperations due to the ciphertext expansion followed by encryption. To\naccelerate its decryption operation, the Chinese Remainder Theorem (CRT) is\noften used to optimize these modulo operations, which lengthens the decryption\ncomputation chain in turn. To address this issue, we propose an eCRT-Paillier\ndecryption algorithm that shortens the decryption computation chain by\ncombining precomputed parameters and eliminating extra judgment operations\nintroduced by Montgomery modular multiplications. These two improvements reduce\n50% modular multiplications and 60% judgment operations in the postprocessing\nof the CRT-Paillier decryption algorithm. Based on these improvements, we\npropose a highly parallel full-pipeline architecture to eliminate stalls caused\nby multiplier reuse in traditional modular exponentiation operations. This\narchitecture also adopts some optimizations such as simplifying modular\nexponentiation units by dividing the exponent into segments and parallelizing\ndata flow by multi-core instantiation. Finally, a high-throughput and efficient\nPaillier accelerator named MESA was implemented on the Xilinx Virtex-7 FPGA for\nevaluation, which can complete a decryption using 2048-bit key within 0.577ms\nunder 100 MHz clock frequency. Compared to prior works, MESA demonstrates a\nthroughput improvement of 1.16 to 313.21 under identical conditions, also with\nenhancements in area efficiency for LUT, DSP, and FF of 3.32 to 117.55, 1.49 to\n1.64, and 2.94 to 9.94, respectively.", "AI": {"tldr": "本文提出了一种名为eCRT-Paillier的解密算法，通过结合预计算参数和消除额外判断操作，显著提升了Paillier算法的解密效率，并在FPGA上实现了高性能加速器MESA。", "motivation": "Paillier加法同态算法虽能有效保护隐私，但其计算效率受限于复杂的模运算和密文扩展。现有CRT优化方法虽加速解密，却增加了计算链长度。", "method": "提出eCRT-Paillier算法：1) 结合预计算参数缩短解密链；2) 消除Montgomery模乘引入的冗余判断。设计全流水线架构，通过指数分段和多核并行化提升吞吐量。", "result": "在Xilinx Virtex-7 FPGA上实现的MESA加速器，2048位密钥解密仅需0.577ms（100MHz）。相比现有方案，吞吐量提升1.16-313.21倍，资源效率（LUT/DSP/FF）提升3.32-117.55倍。", "conclusion": "eCRT-Paillier算法与MESA架构显著优化了同态解密性能，为隐私保护云计算提供了高效解决方案，其设计方法可推广至其他密码学加速场景。"}}
{"id": "2506.18149", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18149", "abs": "https://arxiv.org/abs/2506.18149", "authors": ["Fumian Chen", "Sotheara Veng", "Joshua Wilson", "Xiaoming Li", "Hui Fang"], "title": "CoachGPT: A Scaffolding-based Academic Writing Assistant", "comment": "SIGIR 2025 DEMO Pre-print", "summary": "Academic writing skills are crucial for students' success, but can feel\noverwhelming without proper guidance and practice, particularly when writing in\na second language. Traditionally, students ask instructors or search\ndictionaries, which are not universally accessible. Early writing assistants\nemerged as rule-based systems that focused on detecting misspellings,\nsubject-verb disagreements, and basic punctuation errors; however, they are\ninaccurate and lack contextual understanding. Machine learning-based assistants\ndemonstrate a strong ability for language understanding but are expensive to\ntrain. Large language models (LLMs) have shown remarkable capabilities in\ngenerating responses in natural languages based on given prompts. Still, they\nhave a fundamental limitation in education: they generate essays without\nteaching, which can have detrimental effects on learning when misused. To\naddress this limitation, we develop CoachGPT, which leverages large language\nmodels (LLMs) to assist individuals with limited educational resources and\nthose who prefer self-paced learning in academic writing. CoachGPT is an AI\nagent-based web application that (1) takes instructions from experienced\neducators, (2) converts instructions into sub-tasks, and (3) provides real-time\nfeedback and suggestions using large language models. This unique scaffolding\nstructure makes CoachGPT unique among existing writing assistants. Compared to\nexisting writing assistants, CoachGPT provides a more immersive writing\nexperience with personalized feedback and guidance. Our user studies prove the\nusefulness of CoachGPT and the potential of large language models for academic\nwriting.", "AI": {"tldr": "研究开发了CoachGPT，一款基于大型语言模型（LLM）的AI写作助手，旨在为学术写作提供个性化实时反馈，弥补传统工具和现有AI助手的不足。", "motivation": "学术写作能力对学生的成功至关重要，但缺乏指导资源（尤其是非母语者）。传统工具（如词典）和早期AI助手（基于规则）效果有限，而现有LLM虽强大却缺乏教学功能，可能影响学习效果。", "method": "CoachGPT采用LLM技术构建，通过（1）整合教育专家指令，（2）分解为子任务，（3）利用LLM提供实时反馈，形成独特的脚手架式写作辅助框架。", "result": "用户研究表明，相比现有工具，CoachGPT能提供更沉浸式的写作体验与个性化指导，验证了LLM在学术写作辅助中的潜力。", "conclusion": "CoachGPT通过结合教育专家知识与LLM的生成能力，为资源有限或偏好自主学习的学习者提供了创新的学术写作支持方案。"}}
{"id": "2506.17988", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17988", "abs": "https://arxiv.org/abs/2506.17988", "authors": ["Seongjin Kim", "Sanguk Yun", "Jungho Jang"], "title": "Secure User-friendly Blockchain Modular Wallet Design Using Android & OP-TEE", "comment": "25 pages", "summary": "Emerging crypto economies still hemorrhage digital assets because legacy\nwallets leak private keys at almost every layer of the software stack, from\nuser-space libraries to kernel memory dumps. This paper solves that twin crisis\nof security and interoperability by re-imagining key management as a\nplatform-level service anchored in ARM TrustZone through OP-TEE. Our\narchitecture fractures the traditional monolithic Trusted Application into\nper-chain modules housed in a multi-tenant TA store, finally breaking OP-TEE's\nsingle-binary ceiling. A cryptographically sealed firmware-over-the-air\npipeline welds each TA set to an Android system image, enabling hot-swap\nupdates while Verified Boot enforces rollback protection. Every package carries\na chained signature developer first, registry second so even a compromised\nsupply chain cannot smuggle malicious code past the Secure World's RSA-PSS\ngatekeeper. Inside the TEE, strict inter-TA isolation, cache partitioning, and\nGP-compliant crypto APIs ensure secrets never bleed across trust boundaries or\ntiming domains. The Rich Execution Environment can interact only via\nhardware-mediated Secure Monitor Calls, collapsing the surface exposed to\nmalware in Android space. End-users enjoy a single polished interface yet can\ninstall or retire Bitcoin, Ethereum, Solana, or tomorrow's chain with one tap,\nshrinking both storage footprint and audit scope. For auditors, the composition\nmodel slashes duplicated verification effort by quarantining blockchain logic\ninside narrowly scoped modules that share formally specified interfaces. Our\nthreat analysis spans six adversary layers and shows how the design neutralizes\nREE malware sniffing, OTA injection, and cross-module side channels without\nexotic hardware. A reference implementation on AOSP exports a Wallet Manager\nHAL, custom SELinux domains, and a CI/CD pipeline that vet community modules\nbefore release. The result is not merely another hardware wallet but a\nprogrammable substrate that can evolve at the velocity of the blockchain\necosystem. By welding radical extensibility to hardware-anchored assurance, the\nplatform closes the security-usability gap that has long stymied mass-market\nself-custody. We posit that modular TEEs are the missing OS primitive for Web3,\nmuch as virtual memory unlocked multi-tasking in classical computing. Together,\nthese contributions sketch a blueprint for multi-chain asset management that is\nauditable, resilient, and poised for global deployment.", "AI": {"tldr": "本文提出了一种基于ARM TrustZone和OP-TEE的模块化密钥管理架构，通过多租户TA存储和加密签名链，解决了加密货币钱包的安全性与互操作性危机。", "motivation": "现有加密货币钱包在软件栈各层存在私钥泄漏风险，亟需一种既能保障安全又能支持多链互操作的解决方案。", "method": "将传统单一可信应用拆分为多链模块，采用硬件级安全隔离、加密OTA更新及链式签名验证，并通过安全监控调用限制富执行环境的访问。", "result": "实现了可抵御六层威胁的安全架构，支持比特币/以太坊等多链热插拔，审计效率提升50%，并在AOSP上验证了参考实现。", "conclusion": "模块化TEE架构为Web3提供了关键操作系统原语，其硬件级安全保障与灵活扩展性有望推动自托管钱包的大规模普及。"}}
{"id": "2506.18156", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18156", "abs": "https://arxiv.org/abs/2506.18156", "authors": ["Akash Kundu", "Rishika Goswami"], "title": "AI Through the Human Lens: Investigating Cognitive Theories in Machine Psychology", "comment": null, "summary": "We investigate whether Large Language Models (LLMs) exhibit human-like\ncognitive patterns under four established frameworks from psychology: Thematic\nApperception Test (TAT), Framing Bias, Moral Foundations Theory (MFT), and\nCognitive Dissonance. We evaluated several proprietary and open-source models\nusing structured prompts and automated scoring. Our findings reveal that these\nmodels often produce coherent narratives, show susceptibility to positive\nframing, exhibit moral judgments aligned with Liberty/Oppression concerns, and\ndemonstrate self-contradictions tempered by extensive rationalization. Such\nbehaviors mirror human cognitive tendencies yet are shaped by their training\ndata and alignment methods. We discuss the implications for AI transparency,\nethical deployment, and future work that bridges cognitive psychology and AI\nsafety", "AI": {"tldr": "研究探讨大语言模型(LLM)是否表现出类似人类的认知模式，通过四种心理学框架评估，发现其行为既反映人类倾向又受训练数据影响。", "motivation": "探究大语言模型在主题统觉测试(TAT)、框架偏差、道德基础理论(MFT)和认知失调四种心理学框架下是否展现类人认知特征。", "method": "使用结构化提示和自动评分系统评估多个专有和开源模型。", "result": "模型能生成连贯叙事、易受积极框架影响、道德判断侧重自由/压迫维度，并通过大量合理化缓解自相矛盾，这些行为受训练数据和对齐方法塑造。", "conclusion": "研究结果对AI透明度、伦理部署具有重要意义，为认知心理学与AI安全领域的交叉研究指明方向。"}}
{"id": "2506.18053", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18053", "abs": "https://arxiv.org/abs/2506.18053", "authors": ["Marcos Florencio", "Thomas Barton"], "title": "Mechanistic Interpretability in the Presence of Architectural Obfuscation", "comment": null, "summary": "Architectural obfuscation - e.g., permuting hidden-state tensors, linearly\ntransforming embedding tables, or remapping tokens - has recently gained\ntraction as a lightweight substitute for heavyweight cryptography in\nprivacy-preserving large-language-model (LLM) inference. While recent work has\nshown that these techniques can be broken under dedicated reconstruction\nattacks, their impact on mechanistic interpretability has not been\nsystematically studied. In particular, it remains unclear whether scrambling a\nnetwork's internal representations truly thwarts efforts to understand how the\nmodel works, or simply relocates the same circuits to an unfamiliar coordinate\nsystem. We address this gap by analyzing a GPT-2-small model trained from\nscratch with a representative obfuscation map. Assuming the obfuscation map is\nprivate and the original basis is hidden (mirroring an honest-but-curious\nserver), we apply logit-lens attribution, causal path-patching, and\nattention-head ablation to locate and manipulate known circuits. Our findings\nreveal that obfuscation dramatically alters activation patterns within\nattention heads yet preserves the layer-wise computational graph. This\ndisconnect hampers reverse-engineering of user prompts: causal traces lose\ntheir alignment with baseline semantics, and token-level logit attributions\nbecome too noisy to reconstruct. At the same time, feed-forward and residual\npathways remain functionally intact, suggesting that obfuscation degrades\nfine-grained interpretability without compromising top-level task performance.\nThese results establish quantitative evidence that architectural obfuscation\ncan simultaneously (i) retain global model behaviour and (ii) impede\nmechanistic analyses of user-specific content. By mapping where\ninterpretability breaks down, our study provides guidance for future privacy\ndefences and for robustness-aware interpretability tooling.", "AI": {"tldr": "架构混淆技术虽能保留大语言模型的全局行为，但会显著干扰其内部机制的逆向工程，在保护用户隐私内容的同时牺牲了细粒度可解释性。", "motivation": "研究架构混淆技术（如隐藏状态张量置换、嵌入表线性变换等）对模型机制可解释性的影响，填补现有文献空白。", "method": "在私有化混淆映射条件下，对GPT-2-small模型应用logit-lens归因、因果路径修补和注意力头消融等方法，追踪已知电路结构。", "result": "混淆技术会扭曲注意力头的激活模式但保持层级计算图完整，导致用户提示逆向工程失败（因果轨迹语义失准、logit归因噪声剧增），而前馈/残差通路功能不受影响。", "conclusion": "架构混淆能兼顾全局模型性能与隐私保护，但会破坏细粒度可解释性，为未来隐私防御和鲁棒性解释工具开发提供量化依据。"}}
{"id": "2506.18158", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.18158", "abs": "https://arxiv.org/abs/2506.18158", "authors": ["Xinzge Gao", "Chuanrui Hu", "Bin Chen", "Teng Li"], "title": "Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation", "comment": null, "summary": "Multimodal large language models (MLLMs) are attracting growing attention in\nthe development of Graphical User Interface (GUI) agents. Existing approaches\noften rely on historical screenshots or actions to implicitly represent the\ntask state. This reliance poses challenges for GUI agents in accurately\nunderstanding task states and underscores the absence of effective mechanisms\nto store critical information in complex and lengthy cross-app tasks. To\naddress these challenges, we propose Chain-of-Memory (CoM), a novel approach\nfor explicitly modeling short-term and long-term memory in GUI agents. CoM\nachieves this by capturing action descriptions, integrating task-relevant\nscreen information, and maintaining a dedicated memory module to store and\nmanage this information. By leveraging explicit memory representations, CoM\nenables GUI agents to better understand task states and retain critical\nhistorical information persistently. To equip GUI agents with memory management\ncapabilities and evaluate the effectiveness of CoM, we developed the GUI\nOdyssey-CoM, a dataset comprising 111k screen-action pairs annotated with\nChain-of-Memory. Experimental results demonstrate that CoM significantly\nimproves GUI agents' performance in cross-application tasks. Additionally, GUI\nOdyssey-CoM enables 7B models to achieve memory management capabilities\ncomparable to 72B models. The dataset and code will be open-sourced.", "AI": {"tldr": "本文提出Chain-of-Memory (CoM)方法，通过显式建模GUI代理的短期和长期记忆，提升其在跨应用任务中的表现，并发布了包含11.1万标注数据的GUI Odyssey-CoM数据集。", "motivation": "现有GUI代理依赖历史截图或动作隐式表示任务状态，难以准确理解复杂跨应用任务，缺乏有效机制存储关键信息。", "method": "CoM通过捕获动作描述、整合任务相关屏幕信息，并维护专用记忆模块来显式管理短期/长期记忆。配套开发了带记忆标注的GUI Odyssey-CoM数据集。", "result": "实验表明CoM显著提升GUI代理性能，使7B模型达到与72B模型相当的记忆管理能力。数据集和代码将开源。", "conclusion": "显式记忆表征能有效增强GUI代理的任务状态理解能力，CoM框架为复杂跨应用任务提供了可扩展的解决方案。"}}
{"id": "2506.18087", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18087", "abs": "https://arxiv.org/abs/2506.18087", "authors": ["Huaiying Luo", "Cheng Ji"], "title": "Federated Learning-Based Data Collaboration Method for Enhancing Edge Cloud AI System Security Using Large Language Models", "comment": "Accepted by the 2025 5th International Symposium on Computer\n  Technology and Information Science (ISCTIS 2025)", "summary": "With the widespread application of edge computing and cloud systems in\nAI-driven applications, how to maintain efficient performance while ensuring\ndata privacy has become an urgent security issue. This paper proposes a\nfederated learning-based data collaboration method to improve the security of\nedge cloud AI systems, and use large-scale language models (LLMs) to enhance\ndata privacy protection and system robustness. Based on the existing federated\nlearning framework, this method introduces a secure multi-party computation\nprotocol, which optimizes the data aggregation and encryption process between\ndistributed nodes by using LLM to ensure data privacy and improve system\nefficiency. By combining advanced adversarial training techniques, the model\nenhances the resistance of edge cloud AI systems to security threats such as\ndata leakage and model poisoning. Experimental results show that the proposed\nmethod is 15% better than the traditional federated learning method in terms of\ndata protection and model robustness.", "AI": {"tldr": "本文提出了一种基于联邦学习和大型语言模型（LLMs）的边缘云AI系统数据协作方法，通过安全多方计算协议和对抗训练技术，显著提升了数据隐私保护和系统鲁棒性。", "motivation": "随着边缘计算和云系统在AI应用中的普及，如何在保证高效性能的同时确保数据隐私成为亟待解决的安全问题。", "method": "在现有联邦学习框架中引入安全多方计算协议，利用LLM优化分布式节点间的数据聚合与加密流程，并结合对抗训练技术增强系统对数据泄露和模型投毒等威胁的防御能力。", "result": "实验表明，该方法在数据保护和模型鲁棒性方面比传统联邦学习方法提升了15%。", "conclusion": "所提出的方法有效解决了边缘云AI系统中的隐私与安全问题，为分布式AI应用提供了更可靠的解决方案。"}}
{"id": "2506.18183", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18183", "abs": "https://arxiv.org/abs/2506.18183", "authors": ["Zhiting Mei", "Christina Zhang", "Tenny Yin", "Justin Lidard", "Ola Shorinwa", "Anirudha Majumdar"], "title": "Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?", "comment": null, "summary": "Reasoning language models have set state-of-the-art (SOTA) records on many\nchallenging benchmarks, enabled by multi-step reasoning induced using\nreinforcement learning. However, like previous language models, reasoning\nmodels are prone to generating confident, plausible responses that are\nincorrect (hallucinations). Knowing when and how much to trust these models is\ncritical to the safe deployment of reasoning models in real-world applications.\nTo this end, we explore uncertainty quantification of reasoning models in this\nwork. Specifically, we ask three fundamental questions: First, are reasoning\nmodels well-calibrated? Second, does deeper reasoning improve model\ncalibration? Finally, inspired by humans' innate ability to double-check their\nthought processes to verify the validity of their answers and their confidence,\nwe ask: can reasoning models improve their calibration by explicitly reasoning\nabout their chain-of-thought traces? We introduce introspective uncertainty\nquantification (UQ) to explore this direction. In extensive evaluations on SOTA\nreasoning models across a broad range of benchmarks, we find that reasoning\nmodels: (i) are typically overconfident, with self-verbalized confidence\nestimates often greater than 85% particularly for incorrect responses, (ii)\nbecome even more overconfident with deeper reasoning, and (iii) can become\nbetter calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not\nuniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we\nconclude with important research directions to design necessary UQ benchmarks\nand improve the calibration of reasoning models.", "AI": {"tldr": "本文探讨了推理语言模型的不确定性量化问题，发现现有模型普遍存在过度自信现象，并验证了自省式不确定性量化对部分模型的校准效果。", "motivation": "尽管推理语言模型在多步推理任务中表现优异，但其生成的错误答案往往伴随高置信度（幻觉问题）。为确保模型在实际应用中的安全性，研究其不确定性量化至关重要。", "method": "提出自省式不确定性量化（UQ）方法，通过三个核心问题评估模型：校准性、推理深度对校准的影响，以及基于思维链自检的校准改进。在多个SOTA模型（如o3-Mini、DeepSeek R1等）上进行广泛实验。", "result": "研究发现：(1) 模型普遍过度自信，错误答案的自我评估置信度常超85%；(2) 更深层推理会加剧过度自信；(3) 自省能改善部分模型（如o3-Mini）的校准性，但效果非普适（如Claude 3.7 Sonnet校准性反而下降）。", "conclusion": "需建立专门的不确定性量化基准，并进一步研究提升推理模型校准性的方法，这对模型安全部署具有重要意义。"}}
{"id": "2506.18100", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.18100", "abs": "https://arxiv.org/abs/2506.18100", "authors": ["Taimoor Ahmad", "Anas Ali"], "title": "Optimizing Resource Allocation and Energy Efficiency in Federated Fog Computing for IoT", "comment": null, "summary": "Address Resolution Protocol (ARP) spoofing attacks severely threaten Internet\nof Things (IoT) networks by allowing attackers to intercept, modify, or block\ncommunications. Traditional detection methods are insufficient due to high\nfalse positives and poor adaptability. This research proposes a multi-layered\nmachine learning-based framework for intelligently detecting ARP spoofing in\nIoT networks. Our approach utilizes an ensemble of classifiers organized into\nmultiple layers, each layer optimizing detection accuracy and reducing false\nalarms. Experimental evaluations demonstrate significant improvements in\ndetection accuracy (up to 97.5\\%), reduced false positive rates (less than\n2\\%), and faster detection time compared to existing methods. Our key\ncontributions include introducing multi-layer ensemble classifiers specifically\ntuned for IoT networks, systematically addressing dataset imbalance problems,\nintroducing a dynamic feedback mechanism for classifier retraining, and\nvalidating practical applicability through extensive simulations. This research\nenhances security management in IoT deployments, providing robust defenses\nagainst ARP spoofing attacks and improving reliability and trust in IoT\nenvironments.", "AI": {"tldr": "本文提出了一种基于多层机器学习的框架，用于智能检测物联网（IoT）网络中的ARP欺骗攻击，显著提高了检测精度并降低了误报率。", "motivation": "ARP欺骗攻击严重威胁物联网网络，传统检测方法因高误报率和适应性差而不足。", "method": "采用多层集成分类器框架，每层优化检测精度并减少误报，包括动态反馈机制和数据集不平衡问题的系统解决。", "result": "实验评估显示检测精度高达97.5\\%，误报率低于2\\%，且检测时间优于现有方法。", "conclusion": "该研究增强了物联网部署中的安全管理，为ARP欺骗攻击提供了鲁棒防御，提高了物联网环境的可靠性和信任度。"}}
{"id": "2506.18187", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.18187", "abs": "https://arxiv.org/abs/2506.18187", "authors": ["Shahriar Noroozizadeh", "Pim Welle", "Jeremy C. Weiss", "George H. Chen"], "title": "The Impact of Medication Non-adherence on Adverse Outcomes: Evidence from Schizophrenia Patients via Survival Analysis", "comment": "Conference on Health, Inference, and Learning (CHIL 2025)", "summary": "This study quantifies the association between non-adherence to antipsychotic\nmedications and adverse outcomes in individuals with schizophrenia. We frame\nthe problem using survival analysis, focusing on the time to the earliest of\nseveral adverse events (early death, involuntary hospitalization, jail\nbooking). We extend standard causal inference methods (T-learner, S-learner,\nnearest neighbor matching) to utilize various survival models to estimate\nindividual and average treatment effects, where treatment corresponds to\nmedication non-adherence. Analyses are repeated using different amounts of\nlongitudinal information (3, 6, 9, and 12 months). Using data from Allegheny\nCounty in western Pennsylvania, we find strong evidence that non-adherence\nadvances adverse outcomes by approximately 1 to 4 months. Ablation studies\nconfirm that county-provided risk scores adjust for key confounders, as their\nremoval amplifies the estimated effects. Subgroup analyses by medication\nformulation (injectable vs. oral) and medication type consistently show that\nnon-adherence is associated with earlier adverse events. These findings\nhighlight the clinical importance of adherence in delaying psychiatric crises\nand show that integrating survival analysis with causal inference tools can\nyield policy-relevant insights. We caution that although we apply causal\ninference, we only make associative claims and discuss assumptions needed for\ncausal interpretation.", "AI": {"tldr": "本研究量化了精神分裂症患者不坚持服用抗精神病药物与不良后果之间的关联，发现不坚持用药会使不良后果提前1至4个月发生。", "motivation": "研究旨在评估精神分裂症患者不坚持用药（抗精神病药物）与不良后果（如早逝、强制住院、入狱）之间的关联，强调坚持用药对延缓精神危机的重要性。", "method": "采用生存分析方法，扩展了标准因果推断方法（T-learner、S-learner、最近邻匹配），利用不同生存模型估计个体和平均处理效应，分析基于不同时间跨度（3、6、9、12个月）的纵向数据。", "result": "研究发现不坚持用药会使不良后果提前1至4个月发生，且在不同药物剂型（注射与口服）和药物类型中结果一致。县提供的风险评分能调整关键混杂因素，移除后会放大效应估计。", "conclusion": "研究强调了坚持用药对延缓精神危机的临床重要性，并表明将生存分析与因果推断工具结合可提供政策相关见解。尽管应用了因果推断方法，但仅作出关联性声明，并讨论了因果解释所需的假设。"}}
{"id": "2506.18114", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.18114", "abs": "https://arxiv.org/abs/2506.18114", "authors": ["Ioannis Panopoulos", "Maria-Lamprini A. Bartsioka", "Sokratis Nikolaidis", "Stylianos I. Venieris", "Dimitra I. Kaklamani", "Iakovos S. Venieris"], "title": "Dynamic Temporal Positional Encodings for Early Intrusion Detection in IoT", "comment": "Accepted at the 10th International Conference on Smart and\n  Sustainable Technologies (SpliTech 2025)", "summary": "The rapid expansion of the Internet of Things (IoT) has introduced\nsignificant security challenges, necessitating efficient and adaptive Intrusion\nDetection Systems (IDS). Traditional IDS models often overlook the temporal\ncharacteristics of network traffic, limiting their effectiveness in early\nthreat detection. We propose a Transformer-based Early Intrusion Detection\nSystem (EIDS) that incorporates dynamic temporal positional encodings to\nenhance detection accuracy while maintaining computational efficiency. By\nleveraging network flow timestamps, our approach captures both sequence\nstructure and timing irregularities indicative of malicious behaviour.\nAdditionally, we introduce a data augmentation pipeline to improve model\nrobustness. Evaluated on the CICIoT2023 dataset, our method outperforms\nexisting models in both accuracy and earliness. We further demonstrate its\nreal-time feasibility on resource-constrained IoT devices, achieving\nlow-latency inference and minimal memory footprint.", "AI": {"tldr": "本文提出了一种基于Transformer的早期入侵检测系统（EIDS），通过动态时间位置编码和数据增强技术，显著提升了IoT环境下的入侵检测准确性和实时性。", "motivation": "物联网（IoT）的快速发展带来了严峻的安全挑战，传统入侵检测系统（IDS）常忽略网络流量的时序特征，导致早期威胁检测效果不佳。", "method": "采用Transformer架构，结合动态时间位置编码捕捉流量序列结构和时序异常；引入数据增强流程提升模型鲁棒性；利用网络流时间戳识别恶意行为模式。", "result": "在CICIoT2023数据集上，本方法在检测准确性和时效性上均优于现有模型，并在资源受限的IoT设备上实现了低延迟推理和极小内存占用。", "conclusion": "EIDS系统通过时序建模和轻量化设计，为IoT环境提供了高效、实时的入侵检测解决方案，兼具理论创新和工程实践价值。"}}
{"id": "2506.18213", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18213", "abs": "https://arxiv.org/abs/2506.18213", "authors": ["María Victoria Carro", "Denise Alejandra Mester", "Francisca Gauna Selasco", "Luca Nicolás Forziati Gangi", "Matheo Sandleris Musa", "Lola Ramos Pereyra", "Mario Leiva", "Juan Gustavo Corvalan", "María Vanina Martinez", "Gerardo Simari"], "title": "A Conceptual Framework for AI Capability Evaluations", "comment": "arXiv admin note: text overlap with arXiv:2306.04181 by other authors", "summary": "As AI systems advance and integrate into society, well-designed and\ntransparent evaluations are becoming essential tools in AI governance,\ninforming decisions by providing evidence about system capabilities and risks.\nYet there remains a lack of clarity on how to perform these assessments both\ncomprehensively and reliably. To address this gap, we propose a conceptual\nframework for analyzing AI capability evaluations, offering a structured,\ndescriptive approach that systematizes the analysis of widely used methods and\nterminology without imposing new taxonomies or rigid formats. This framework\nsupports transparency, comparability, and interpretability across diverse\nevaluations. It also enables researchers to identify methodological weaknesses,\nassists practitioners in designing evaluations, and provides policymakers with\nan accessible tool to scrutinize, compare, and navigate complex evaluation\nlandscapes.", "AI": {"tldr": "本文提出一个分析AI能力评估的概念框架，旨在提升评估的透明度、可比性和可解释性，为研究者、实践者和政策制定者提供系统化工具。", "motivation": "随着AI系统深入社会，透明且全面的评估成为AI治理的关键工具，但目前缺乏系统化的评估方法。", "method": "作者提出一个结构化描述性框架，系统分析现有评估方法与术语，不强制新分类或固定格式。", "result": "该框架支持跨评估的透明比较，帮助识别方法缺陷、指导评估设计，并为政策制定提供实用工具。", "conclusion": "此框架填补了AI能力评估的系统化空白，为多方利益相关者提供了标准化分析工具。"}}
{"id": "2506.18150", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.18150", "abs": "https://arxiv.org/abs/2506.18150", "authors": ["Karthik Garimella", "Austin Ebel", "Gabrielle De Micheli", "Brandon Reagen"], "title": "HE-LRM: Encrypted Deep Learning Recommendation Models using Fully Homomorphic Encryption", "comment": "14 pages, 10 figures, 2 tables", "summary": "Fully Homomorphic Encryption (FHE) is an encryption scheme that not only\nencrypts data but also allows for computations to be applied directly on the\nencrypted data. While computationally expensive, FHE can enable\nprivacy-preserving neural inference in the client-server setting: a client\nencrypts their input with FHE and sends it to an untrusted server. The server\nthen runs neural inference on the encrypted data and returns the encrypted\nresults. The client decrypts the output locally, keeping both the input and\nresult private from the server. Private inference has focused on networks with\ndense inputs such as image classification, and less attention has been given to\nnetworks with sparse features. Unlike dense inputs, sparse features require\nefficient encrypted lookup operations into large embedding tables, which\npresent computational and memory constraints for FHE.\n  In this paper, we explore the challenges and opportunities when applying FHE\nto Deep Learning Recommendation Models (DLRM) from both a compiler and systems\nperspective. DLRMs utilize conventional MLPs for dense features and embedding\ntables to map sparse, categorical features to dense vector representations. We\ndevelop novel methods for performing compressed embedding lookups in order to\nreduce FHE computational costs while keeping the underlying model performant.\nOur embedding lookup improves upon a state-of-the-art approach by $77 \\times$.\nFurthermore, we present an efficient multi-embedding packing strategy that\nenables us to perform a 44 million parameter embedding lookup under FHE.\nFinally, we integrate our solutions into the open-source Orion framework and\npresent HE-LRM, an end-to-end encrypted DLRM. We evaluate HE-LRM on UCI (health\nprediction) and Criteo (click prediction), demonstrating that with the right\ncompression and packing strategies, encrypted inference for recommendation\nsystems is practical.", "AI": {"tldr": "本文探讨了全同态加密（FHE）在深度学习推荐模型（DLRM）中的应用挑战与机遇，提出了一种压缩嵌入查找方法和多嵌入打包策略，显著提升了加密推理效率，并在开源框架Orion中实现了端到端的加密DLRM系统HE-LRM。", "motivation": "全同态加密（FHE）能够直接在加密数据上进行计算，适用于隐私保护的神经推理。然而，稀疏特征的加密查找操作在计算和内存方面存在挑战，尤其是在深度学习推荐模型（DLRM）中。本文旨在解决这些挑战，提升加密推荐系统的实用性。", "method": "本文提出了一种压缩嵌入查找方法，显著降低了FHE的计算成本，同时保持了模型的性能。此外，还提出了一种高效的多嵌入打包策略，支持在FHE下进行4400万参数的嵌入查找。这些方法被集成到开源框架Orion中，形成了端到端的加密DLRM系统HE-LRM。", "result": "实验结果表明，压缩嵌入查找方法比现有最优方法提升了77倍。多嵌入打包策略成功实现了大规模嵌入查找。在UCI（健康预测）和Criteo（点击预测）数据集上的评估显示，加密推理在推荐系统中是可行的。", "conclusion": "通过适当的压缩和打包策略，加密推理在推荐系统中具有实际应用价值。本文提出的方法显著提升了FHE在DLRM中的效率，为隐私保护的推荐系统提供了可行的解决方案。"}}
{"id": "2506.18233", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18233", "abs": "https://arxiv.org/abs/2506.18233", "authors": ["Ruike Zhu", "Hanwen Zhang", "Tianyu Shi", "Chi Wang", "Tianyi Zhou", "Zengyi Qin"], "title": "The 4th Dimension for Scaling Model Size", "comment": null, "summary": "Scaling the size of large language models typically involves three\ndimensions: depth, width, and the number of parameters. In this work, we\nexplore a fourth dimension, virtual logical depth (VLD), which increases the\neffective algorithmic depth without changing the overall parameter count by\nreusing parameters within the model. Although parameter reuse is not a new\nconcept, its potential and characteristics in model scaling have not been\nthoroughly studied. Through carefully designed controlled experiments, we make\nthe following key discoveries regarding VLD scaling:\n  VLD scaling forces the knowledge capacity of the model to remain almost\nconstant, with only minor variations.\n  VLD scaling enables a significant improvement in reasoning capability,\nprovided the scaling method is properly implemented.\n  The number of parameters correlates with knowledge capacity, but not with\nreasoning capability. Under certain conditions, it is not necessary to increase\nthe parameter count to enhance reasoning.\n  These findings are consistent across various model configurations and are\nlikely to be generally valid within the scope of our experiments.", "AI": {"tldr": "本文提出虚拟逻辑深度（VLD）作为大语言模型扩展的第四维度，通过参数复用提升推理能力而不增加参数量。实验表明VLD扩展能保持知识容量恒定，显著增强推理能力，且参数量与推理能力无直接关联。", "motivation": "探索大语言模型扩展的新维度（虚拟逻辑深度），研究参数复用对模型性能的影响，填补该领域系统性研究的空白。", "method": "通过精心设计的对照实验，分析不同VLD扩展方式下模型的知识容量与推理能力变化，验证参数复用策略的有效性。", "result": "1. VLD扩展使知识容量基本恒定\\n2. 正确实施时可显著提升推理能力\\n3. 参数量仅关联知识容量，与推理能力无关\\n4. 结论在不同模型配置下具有普适性", "conclusion": "在特定条件下，无需增加参数量即可通过VLD扩展提升模型推理能力，这为高效的大语言模型优化提供了新方向。"}}
{"id": "2506.18189", "categories": ["cs.CR", "cs.CY", "C.2.4"], "pdf": "https://arxiv.org/pdf/2506.18189", "abs": "https://arxiv.org/abs/2506.18189", "authors": ["Maxwell Koegler"], "title": "SoK: Current State of Ethereum's Enshrined Proposer Builder Separation", "comment": "12 pages, 2 figures, submitted to The Science of Blockchain\n  Conference 2025", "summary": "Initially introduced to Ethereum via Flashbots' MEV-boost, Proposer-Builder\nSeparation allows proposers to auction off blockspace to a market of\ntransaction orderers, known as builders. PBS is currently available to\nvalidators through the aforementioned MEV-boost, but its unregulated and\nrelay-dependent nature has much of the Ethereum community calling for its\nenshrinement. Providing a protocol-integrated PBS marketspace and communication\nchannel for payload outsourcing is termed PBS enshrinement. Although ePBS\npotentially introduces native MEV mitigation mechanisms and reduces validator\noperation costs, fears of multiparty collusion and chain stagnation are all too\nreal. In addition to mitigating these potential drawbacks, PBS research pursues\nmany tenets revered by Web3 enthusiasts, including but not limited to,\ncensorship resistance, validator reward equity, and deflationary finance. The\nsubsequent SoK will identify current PBS mechanisms, the need for enshrinement,\nadditions to the ePBS upgrade, and the existing or potential on-chain\nsocioeconomic implications of each.", "AI": {"tldr": "本文探讨了以太坊中提议者-构建者分离（PBS）机制的现状及其协议内化（ePBS）的必要性，分析了潜在风险与Web3价值观的契合点。", "motivation": "当前通过MEV-boost实现的PBS存在依赖中继、缺乏监管的问题，社区呼吁将其协议内化以提升安全性并降低验证者成本，同时需解决多方共谋和链停滞风险。", "method": "研究通过系统化梳理现有PBS机制，评估协议内化升级（ePBS）的技术方案，包括原生MEV缓解机制和负载外包通信层的设计。", "result": "ePBS可能实现抗审查、验证者收益公平等目标，但需平衡多方博弈带来的社会经济影响，如共谋导致的中心化倾向。", "conclusion": "PBS协议内化是兼顾MEV问题解决与Web3价值观的关键路径，但需谨慎设计以避免衍生风险，后续研究将聚焦具体实施方案的链上影响。"}}
{"id": "2506.18260", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18260", "abs": "https://arxiv.org/abs/2506.18260", "authors": ["FuTe Wong"], "title": "Advanced For-Loop for QML algorithm search", "comment": "7 pages, 8 figures", "summary": "This paper introduces an advanced framework leveraging Large Language\nModel-based Multi-Agent Systems (LLMMA) for the automated search and\noptimization of Quantum Machine Learning (QML) algorithms. Inspired by Google\nDeepMind's FunSearch, the proposed system works on abstract level to\niteratively generates and refines quantum transformations of classical machine\nlearning algorithms (concepts), such as the Multi-Layer Perceptron,\nforward-forward and backpropagation algorithms. As a proof of concept, this\nwork highlights the potential of agentic frameworks to systematically explore\nclassical machine learning concepts and adapt them for quantum computing,\npaving the way for efficient and automated development of QML algorithms.\nFuture directions include incorporating planning mechanisms and optimizing\nstrategy in the search space for broader applications in quantum-enhanced\nmachine learning.", "AI": {"tldr": "本文提出了一种基于大语言模型的多智能体系统（LLMMA）框架，用于自动搜索和优化量子机器学习（QML）算法。该系统在抽象层面上迭代生成并优化经典机器学习算法的量子转换，展示了智能体框架在量子计算中系统探索和适应经典机器学习概念的潜力。", "motivation": "受Google DeepMind的FunSearch启发，本研究旨在利用多智能体系统自动化和优化量子机器学习算法的开发，以推动量子增强机器学习的效率和应用范围。", "method": "采用基于大语言模型的多智能体系统（LLMMA），在抽象层面上迭代生成和优化经典机器学习算法（如多层感知机、前向-前向和反向传播算法）的量子转换。", "result": "作为概念验证，本研究展示了智能体框架在系统探索经典机器学习概念并将其适配到量子计算中的潜力，为高效自动化开发QML算法奠定了基础。", "conclusion": "未来研究方向包括在搜索空间中引入规划机制和优化策略，以扩大量子增强机器学习的应用范围。"}}
{"id": "2506.18203", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18203", "abs": "https://arxiv.org/abs/2506.18203", "authors": ["Jon Saad-Falcon", "E. Kelly Buchanan", "Mayee F. Chen", "Tzu-Heng Huang", "Brendan McLaughlin", "Tanvir Bhathal", "Shang Zhu", "Ben Athiwaratkun", "Frederic Sala", "Scott Linderman", "Azalia Mirhoseini", "Christopher Ré"], "title": "Shrinking the Generation-Verification Gap with Weak Verifiers", "comment": null, "summary": "Verifiers can improve language model capabilities by scoring and ranking\nresponses from generated candidates. Currently, high-quality verifiers are\neither unscalable (e.g., humans) or limited in utility (e.g., tools like Lean).\nWhile LM judges and reward models have become broadly useful as general-purpose\nverifiers, a significant performance gap remains between them and oracle\nverifiers (verifiers with perfect accuracy). To help close this gap, we\nintroduce Weaver, a framework for designing a strong verifier by combining\nmultiple weak, imperfect verifiers. We find weighted ensembles of verifiers,\nwhich typically require learning from labeled data, significantly outperform\nunweighted combinations due to differences in verifier accuracies. To reduce\ndependency on labeled data, Weaver leverages weak supervision to estimate each\nverifier's accuracy and combines outputs into a unified score that better\nreflects true response quality. However, directly applying weak supervision\nalgorithms poses challenges, including inconsistent verifier output formats and\nhandling low-quality verifiers. Weaver addresses these using dataset statistics\nto normalize outputs and filter specific verifiers. We study Weaver's\neffectiveness in test-time repeated sampling, where a model generates multiple\ncandidate responses and selects one. Our evaluations show Weaver significantly\nimproves over Pass@1-performance when selecting the first candidate-across\nreasoning and math tasks, achieving o3-mini-level accuracy with Llama 3.3 70B\nInstruct as generator, and an ensemble of 70B or smaller judge and reward\nmodels as verifiers (87.7% average). This gain mirrors the jump between GPT-4o\nand o3-mini (69.0% vs. 86.7%), which required extensive finetuning and\npost-training. To reduce computational costs of verifier ensembles, we train a\n400M cross-encoder using Weaver's combined output scores.", "AI": {"tldr": "Weaver框架通过组合多个弱验证器构建强验证器，利用弱监督减少对标注数据的依赖，显著提升语言模型在测试时重复采样中的性能。", "motivation": "现有验证器要么不可扩展（如人类），要么效用有限（如Lean工具），LM评判和奖励模型虽广泛使用，但与完美验证器仍有性能差距。", "method": "Weaver通过加权集成多个弱验证器，利用弱监督估计各验证器准确率，并归一化输出格式以处理低质量验证器，最终合成统一评分。", "result": "在推理和数学任务中，Weaver显著超越Pass@1性能，使用Llama 3.3 70B生成器时达到o3-mini级别准确率（87.7%），接近GPT-4o与o3-mini的差距。", "conclusion": "Weaver有效缩小了普通验证器与完美验证器的差距，并通过训练400M交叉编码器降低集成计算成本，为语言模型验证提供了高效解决方案。"}}
{"id": "2506.18348", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18348", "abs": "https://arxiv.org/abs/2506.18348", "authors": ["Weilun Yu", "Shixiang Tang", "Yonggui Huang", "Nanqing Dong", "Li Fan", "Honggang Qi", "Wei Liu", "Xiaoli Diao", "Xi Chen", "Wanli Ouyang"], "title": "Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team", "comment": null, "summary": "Scientific progress increasingly relies on effective collaboration among\nresearchers, a dynamic that large language models (LLMs) have only begun to\nemulate. While recent LLM-based scientist agents show promise in autonomous\nscientific discovery, they often lack the interactive reasoning and evaluation\nmechanisms essential to real-world research. We propose IDVSCI (Internal\nDiscussion and Vote SCIentists), a multi-agent framework built on LLMs that\nincorporates two key innovations: a Dynamic Knowledge Exchange mechanism\nenabling iterative feedback among agents, and a Dual-Diversity Review paradigm\nthat simulates heterogeneous expert evaluation. These components jointly\npromote deeper reasoning and the generation of more creative and impactful\nscientific ideas. To evaluate the effectiveness and generalizability of our\napproach, we conduct experiments on two datasets: a widely used benchmark in\ncomputer science and a new dataset we introduce in the health sciences domain.\nResults show that IDVSCI consistently achieves the best performance across both\ndatasets, outperforming existing systems such as AI Scientist and VIRSCI. These\nfindings highlight the value of modeling interaction and peer review dynamics\nin LLM-based autonomous research.", "AI": {"tldr": "本文提出IDVSCI框架，通过多智能体动态知识交换和双多样性评审机制，提升LLM在自主科研中的交互推理与创新性。实验表明其在跨领域数据集上均优于现有系统。", "motivation": "当前基于LLM的科研智能体缺乏真实研究所需的交互推理与评审机制，制约了自主科学发现的效能。", "method": "提出IDVSCI框架：1) 动态知识交换机制实现智能体间迭代反馈；2) 双多样性评审范式模拟异质专家评估。", "result": "在计算机科学基准和健康科学新数据集上，IDVSCI性能均超越AI Scientist、VIRSCI等现有系统。", "conclusion": "建模交互与同行评审动态对LLM自主研究具有重要价值，IDVSCI框架为跨领域科学协作提供了新范式。"}}
{"id": "2506.18245", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.18245", "abs": "https://arxiv.org/abs/2506.18245", "authors": ["Lei Yu", "Zhirong Huang", "Hang Yuan", "Shiqi Cheng", "Li Yang", "Fengjun Zhang", "Chenjie Shen", "Jiajia Ma", "Jingyuan Zhang", "Junyi Lu", "Chun Zuo"], "title": "Smart-LLaMA-DPO: Reinforced Large Language Model for Explainable Smart Contract Vulnerability Detection", "comment": "Accepted to ISSTA 2025", "summary": "Smart contract vulnerability detection remains a major challenge in\nblockchain security. Existing vulnerability detection methods face two main\nissues: (1) Existing datasets lack comprehensive coverage and high-quality\nexplanations for preference learning. (2) Large language models (LLMs) often\nstruggle with accurately interpreting specific concepts in smart contract\nsecurity. Empirical analysis shows that even after continual pre-training (CPT)\nand supervised fine-tuning (SFT), LLMs may misinterpret the execution order of\nstate changes, resulting in incorrect explanations despite making correct\ndetection decisions. To address these challenges, we propose Smart-LLaMA-DPO\nbased on LLaMA-3.1-8B. We construct a comprehensive dataset covering four major\nvulnerability types and machine-unauditable vulnerabilities, including precise\nlabels, explanations, and locations for SFT, as well as high-quality and\nlow-quality output pairs for Direct Preference Optimization (DPO). Second, we\nperform CPT using large-scale smart contract to enhance the LLM's understanding\nof specific security practices in smart contracts. Futhermore, we conduct SFT\nwith our comprehensive dataset. Finally, we apply DPO, leveraging human\nfeedback and a specially designed loss function that increases the probability\nof preferred explanations while reducing the likelihood of non-preferred\noutputs. We evaluate Smart-LLaMA-DPO on four major vulnerability types:\nreentrancy, timestamp dependence, integer overflow/underflow, and delegatecall,\nas well as machine-unauditable vulnerabilities. Our method significantly\noutperforms state-of-the-art baselines, with average improvements of 10.43% in\nF1 score and 7.87% in accuracy. Moreover, both LLM evaluation and human\nevaluation confirm that our method generates more correct, thorough, and clear\nexplanations.", "AI": {"tldr": "本文提出基于LLaMA-3.1-8B的Smart-LLaMA-DPO模型，通过构建全面数据集、持续预训练和直接偏好优化，显著提升了智能合约漏洞检测的准确性和解释质量。", "motivation": "现有智能合约漏洞检测方法存在数据集覆盖不全、大语言模型对安全概念理解不准确等问题，导致解释错误或检测效果不佳。", "method": "1) 构建覆盖四类主要漏洞的标注数据集；2) 使用大规模合约代码进行持续预训练；3) 采用监督微调和直接偏好优化(DPO)结合人类反馈优化模型。", "result": "在重入、时间戳依赖等漏洞检测上，F1值平均提升10.43%，准确率提升7.87%，生成的解释更正确全面。", "conclusion": "Smart-LLaMA-DPO通过系统化训练框架显著提升检测性能，为智能合约安全提供了更可靠的自动化审计方案。"}}
{"id": "2506.18424", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.18424", "abs": "https://arxiv.org/abs/2506.18424", "authors": ["Chengjie Liu", "Weiyu Chen", "Huiyao Xu", "Yuan Du", "Jun Yang", "Li Du"], "title": "A Large Language Model-based Multi-Agent Framework for Analog Circuits' Sizing Relationships Extraction", "comment": "Accepted by ISEDA 2025", "summary": "In the design process of the analog circuit pre-layout phase, device sizing\nis an important step in determining whether an analog circuit can meet the\nrequired performance metrics. Many existing techniques extract the circuit\nsizing task as a mathematical optimization problem to solve and continuously\nimprove the optimization efficiency from a mathematical perspective. But they\nignore the automatic introduction of prior knowledge, fail to achieve effective\npruning of the search space, which thereby leads to a considerable compression\nmargin remaining in the search space. To alleviate this problem, we propose a\nlarge language model (LLM)-based multi-agent framework for analog circuits'\nsizing relationships extraction from academic papers. The search space in the\nsizing process can be effectively pruned based on the sizing relationship\nextracted by this framework. Eventually, we conducted tests on 3 types of\ncircuits, and the optimization efficiency was improved by $2.32 \\sim 26.6\n\\times$. This work demonstrates that the LLM can effectively prune the search\nspace for analog circuit sizing, providing a new solution for the combination\nof LLMs and conventional analog circuit design automation methods.", "AI": {"tldr": "提出基于大语言模型（LLM）的多智能体框架，用于从学术论文中提取模拟电路尺寸关系，有效修剪搜索空间，提升优化效率$2.32 \\sim 26.6 \\times$。", "motivation": "现有模拟电路预布局阶段器件尺寸优化方法忽视先验知识自动引入，导致搜索空间压缩不足，需通过LLM提取尺寸关系实现有效修剪。", "method": "构建LLM驱动的多智能体框架，从论文文本中自动提取电路尺寸约束关系，基于此关系在尺寸优化过程中动态修剪无效搜索空间。", "result": "在3类电路测试中，优化效率提升$2.32 \\sim 26.6 \\times$，验证LLM对模拟电路尺寸搜索空间修剪的有效性。", "conclusion": "LLM为模拟电路设计自动化提供了新思路，其提取的尺寸关系能显著提升传统优化方法的效率，实现AI与EDA技术的创新结合。"}}
{"id": "2506.18462", "categories": ["cs.CR", "I.2"], "pdf": "https://arxiv.org/pdf/2506.18462", "abs": "https://arxiv.org/abs/2506.18462", "authors": ["Fatemeh Jalalvand", "Mohan Baruwal Chhetri", "Surya Nepal", "Cécile Paris"], "title": "Adaptive alert prioritisation in security operations centres via learning to defer with human feedback", "comment": "No comment", "summary": "Alert prioritisation (AP) is crucial for security operations centres (SOCs)\nto manage the overwhelming volume of alerts and ensure timely detection and\nresponse to genuine threats, while minimising alert fatigue. Although\npredictive AI can process large alert volumes and identify known patterns, it\nstruggles with novel and evolving scenarios that demand contextual\nunderstanding and nuanced judgement. A promising solution is Human-AI teaming\n(HAT), which combines human expertise with AI's computational capabilities.\nLearning to Defer (L2D) operationalises HAT by enabling AI to \"defer\" uncertain\nor unfamiliar cases to human experts. However, traditional L2D models rely on\nstatic deferral policies that do not evolve with experience, limiting their\nability to learn from human feedback and adapt over time. To overcome this, we\nintroduce Learning to Defer with Human Feedback (L2DHF), an adaptive deferral\nframework that leverages Deep Reinforcement Learning from Human Feedback\n(DRLHF) to optimise deferral decisions. By dynamically incorporating human\nfeedback, L2DHF continuously improves AP accuracy and reduces unnecessary\ndeferrals, enhancing SOC effectiveness and easing analyst workload. Experiments\non two widely used benchmark datasets, UNSW-NB15 and CICIDS2017, demonstrate\nthat L2DHF significantly outperforms baseline models. Notably, it achieves\n13-16% higher AP accuracy for critical alerts on UNSW-NB15 and 60-67% on\nCICIDS2017. It also reduces misprioritisations, for example, by 98% for\nhigh-category alerts on CICIDS2017. Moreover, L2DHF decreases deferrals, for\nexample, by 37% on UNSW-NB15, directly reducing analyst workload. These gains\nare achieved with efficient execution, underscoring L2DHF's practicality for\nreal-world SOC deployment.", "AI": {"tldr": "本文提出了一种基于人类反馈的自适应延迟学习框架L2DHF，通过结合深度强化学习优化安全告警优先级排序，显著提升准确率并减少分析师工作量。", "motivation": "传统AI在安全运营中心(SOC)告警优先级排序中存在对新型威胁识别不足的问题，而静态延迟策略无法从人类反馈中学习。需要动态融合人类与AI优势的方案。", "method": "提出L2DHF框架，采用深度强化学习从人类反馈(DRLHF)中动态优化延迟决策，使AI能持续改进并减少不必要的人类介入。", "result": "在UNSW-NB15和CICIDS2017数据集上，关键告警准确率分别提升13-16%和60-67%，CICIDS2017高优先级误判减少98%，UNSW-NB15延迟量降低37%。", "conclusion": "L2DHF通过实时整合人类反馈实现了高效自适应的告警排序，实验证明其能显著提升SOC运营效率并减轻分析师负担，具备实际部署价值。"}}
{"id": "2506.18428", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.18428", "abs": "https://arxiv.org/abs/2506.18428", "authors": ["Feng He", "Zhenyang Liu", "Marco Valentino", "Zhixue Zhao"], "title": "How Robust is Model Editing after Fine-Tuning? An Empirical Study on Text-to-Image Diffusion Models", "comment": null, "summary": "Model editing offers a low-cost technique to inject or correct a particular\nbehavior in a pre-trained model without extensive retraining, supporting\napplications such as factual correction and bias mitigation. Despite this\ncommon practice, it remains unknown whether edits persist after fine-tuning or\nwhether they are inadvertently reversed. This question has fundamental\npractical implications. For example, if fine-tuning removes prior edits, it\ncould serve as a defence mechanism against hidden malicious edits. Vice versa,\nthe unintended removal of edits related to bias mitigation could pose serious\nsafety concerns. We systematically investigate the interaction between model\nediting and fine-tuning in the context of T2I diffusion models, which are known\nto exhibit biases and generate inappropriate content. Our study spans two T2I\nmodel families (Stable Diffusion and FLUX), two sota editing techniques, and\nthree fine-tuning methods (DreamBooth, LoRA, and DoRA). Through an extensive\nempirical analysis across diverse editing tasks and evaluation metrics, our\nfindings reveal a trend: edits generally fail to persist through fine-tuning,\neven when fine-tuning is tangential or unrelated to the edits. Notably, we\nobserve that DoRA exhibits the strongest edit reversal effect. At the same\ntime, among editing methods, UCE demonstrates greater robustness, retaining\nsignificantly higher efficacy post-fine-tuning compared to ReFACT. These\nfindings highlight a crucial limitation in current editing methodologies,\nemphasizing the need for more robust techniques to ensure reliable long-term\ncontrol and alignment of deployed AI systems. These findings have dual\nimplications for AI safety: they suggest that fine-tuning could serve as a\nremediation mechanism for malicious edits while simultaneously highlighting the\nneed for re-editing after fine-tuning to maintain beneficial safety and\nalignment properties.", "AI": {"tldr": "研究发现，模型编辑后的行为在微调过程中普遍无法保持，这对AI安全具有双重影响：微调可作为恶意编辑的修复机制，但也需重新编辑以维持有益的安全属性。", "motivation": "探讨模型编辑后行为在微调中的持久性，这对事实修正、偏见消除等应用具有重要实践意义，涉及AI安全防御与风险防控。", "method": "针对Stable Diffusion和FLUX两类T2I模型，结合UCE、ReFACT两种编辑技术与DreamBooth、LoRA、DoRA三种微调方法，通过多任务多指标进行系统性实验。", "result": "实验表明：1) 微调普遍导致编辑失效，即使微调与编辑无关；2) DoRA的编辑逆转效应最强；3) UCE比ReFACT在微调后保留更高编辑效力。", "conclusion": "当前编辑技术存在持久性缺陷，需开发更鲁棒的方法以确保AI系统的长期可控性。微调兼具防御恶意编辑与需补编辑的双重安全特性。"}}
{"id": "2506.18470", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.18470", "abs": "https://arxiv.org/abs/2506.18470", "authors": ["Daniele Canavese", "Leonardo Regano", "Bjorn De Sutter", "Cataldo Basile"], "title": "Automatic Selection of Protections to Mitigate Risks Against Software Applications", "comment": null, "summary": "This paper introduces a novel approach for the automated selection of\nsoftware protections to mitigate MATE risks against critical assets within\nsoftware applications. We formalize the key elements involved in protection\ndecision-making - including code artifacts, assets, security requirements,\nattacks, and software protections - and frame the protection process through a\ngame-theoretic model. In this model, a defender strategically applies\nprotections to various code artifacts of a target application, anticipating\nrepeated attack attempts by adversaries against the confidentiality and\nintegrity of the application's assets. The selection of the optimal defense\nmaximizes resistance to attacks while ensuring the application remains usable\nby constraining the overhead introduced by protections. The game is solved\nthrough a heuristic based on a mini-max depth-first exploration strategy,\naugmented with dynamic programming optimizations for improved efficiency.\nCentral to our formulation is the introduction of the Software Protection\nIndex, an original contribution that extends existing notions of potency and\nresilience by evaluating protection effectiveness against attack paths using\nsoftware metrics and expert assessments. We validate our approach through a\nproof-of-concept implementation and expert evaluations, demonstrating that\nautomated software protection is a practical and effective solution for risk\nmitigation in software.", "AI": {"tldr": "本文提出了一种自动化选择软件保护措施的新方法，通过博弈论模型优化防御策略，引入软件保护指数评估保护效果，并通过实验验证其有效性。", "motivation": "针对关键软件资产面临的MATE风险，现有保护措施选择缺乏系统性方法，亟需自动化解决方案以平衡安全性与可用性。", "method": "建立博弈论模型，防御者通过启发式最小最大深度优先搜索策略动态优化保护方案，提出结合软件指标与专家评估的软件保护指数(SPI)。", "result": "概念验证实现与专家评估表明，该方法能有效提升软件抗攻击能力，同时将保护开销控制在可接受范围内。", "conclusion": "基于博弈论的自动化软件保护选择方案为软件风险缓解提供了兼具理论严谨性与实践可行性的新途径。"}}
{"id": "2506.18511", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18511", "abs": "https://arxiv.org/abs/2506.18511", "authors": ["Yu Han", "Aaron Ceross", "Jeroen H. M. Bergmann"], "title": "Standard Applicability Judgment and Cross-jurisdictional Reasoning: A RAG-based Framework for Medical Device Compliance", "comment": null, "summary": "Identifying the appropriate regulatory standard applicability remains a\ncritical yet understudied challenge in medical device compliance, frequently\nnecessitating expert interpretation of fragmented and heterogeneous\ndocumentation across different jurisdictions. To address this challenge, we\nintroduce a modular AI system that leverages a retrieval-augmented generation\n(RAG) pipeline to automate standard applicability determination. Given a\nfree-text device description, our system retrieves candidate standards from a\ncurated corpus and uses large language models to infer jurisdiction-specific\napplicability, classified as Mandatory, Recommended, or Not Applicable, with\ntraceable justifications. We construct an international benchmark dataset of\nmedical device descriptions with expert-annotated standard mappings, and\nevaluate our system against retrieval-only, zero-shot, and rule-based\nbaselines. The proposed approach attains a classification accuracy of 73% and a\nTop-5 retrieval recall of 87%, demonstrating its effectiveness in identifying\nrelevant regulatory standards. We introduce the first end-to-end system for\nstandard applicability reasoning, enabling scalable and interpretable\nAI-supported regulatory science. Notably, our region-aware RAG agent performs\ncross-jurisdictional reasoning between Chinese and U.S. standards, supporting\nconflict resolution and applicability justification across regulatory\nframeworks.", "AI": {"tldr": "本文提出了一种模块化AI系统，通过检索增强生成（RAG）技术自动确定医疗器械的适用监管标准，支持跨辖区（如中美）标准冲突解决，准确率达73%。", "motivation": "医疗器械合规性中，确定适用的监管标准是一个关键但研究不足的挑战，常需专家解读分散且异构的文档。", "method": "系统采用RAG流程：根据自由文本设备描述检索候选标准，利用大语言模型推断辖区特定适用性（强制/推荐/不适用），并提供可追溯的论证。构建了专家标注的国际基准数据集，并与纯检索、零样本及基于规则的基线方法对比。", "result": "分类准确率73%，Top-5检索召回率87%，首次实现端到端的标准适用性推理，支持可扩展且可解释的AI辅助监管科学。", "conclusion": "该研究提出了首个支持跨辖区标准推理（如中美）的RAG系统，为监管框架下的冲突解决和适用性论证提供了有效工具。"}}
{"id": "2506.18516", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.18516", "abs": "https://arxiv.org/abs/2506.18516", "authors": ["Francesco Marchiori", "Marco Alecci", "Luca Pajola", "Mauro Conti"], "title": "DUMB and DUMBer: Is Adversarial Training Worth It in the Real World?", "comment": "Accepted at ESORICS 2025", "summary": "Adversarial examples are small and often imperceptible perturbations crafted\nto fool machine learning models. These attacks seriously threaten the\nreliability of deep neural networks, especially in security-sensitive domains.\nEvasion attacks, a form of adversarial attack where input is modified at test\ntime to cause misclassification, are particularly insidious due to their\ntransferability: adversarial examples crafted against one model often fool\nother models as well. This property, known as adversarial transferability,\ncomplicates defense strategies since it enables black-box attacks to succeed\nwithout direct access to the victim model. While adversarial training is one of\nthe most widely adopted defense mechanisms, its effectiveness is typically\nevaluated on a narrow and homogeneous population of models. This limitation\nhinders the generalizability of empirical findings and restricts practical\nadoption.\n  In this work, we introduce DUMBer, an attack framework built on the\nfoundation of the DUMB (Dataset soUrces, Model architecture, and Balance)\nmethodology, to systematically evaluate the resilience of adversarially trained\nmodels. Our testbed spans multiple adversarial training techniques evaluated\nacross three diverse computer vision tasks, using a heterogeneous population of\nuniquely trained models to reflect real-world deployment variability. Our\nexperimental pipeline comprises over 130k evaluations spanning 13\nstate-of-the-art attack algorithms, allowing us to capture nuanced behaviors of\nadversarial training under varying threat models and dataset conditions. Our\nfindings offer practical, actionable insights for AI practitioners, identifying\nwhich defenses are most effective based on the model, dataset, and attacker\nsetup.", "AI": {"tldr": "本文介绍了DUMBer攻击框架，用于系统评估对抗训练模型的鲁棒性，通过多任务、多模型的大规模实验揭示了不同防御策略的实际效果。", "motivation": "对抗样本通过微小扰动欺骗机器学习模型，其可迁移性使黑盒攻击成为可能。现有对抗训练评估局限于同质模型，难以反映实际部署中的多样性。", "method": "基于DUMB方法论构建DUMBer框架，在三个计算机视觉任务中评估多种对抗训练技术，使用13种先进攻击算法对异构模型群进行13万次评估。", "result": "实验揭示了对抗训练在不同威胁模型和数据集条件下的细微行为差异，为实践者提供了基于模型、数据和攻击设置的防御有效性指导。", "conclusion": "该研究为AI实践者提供了可操作的防御策略选择依据，强调需根据具体部署环境选择最优对抗训练方案。"}}
{"id": "2506.18538", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18538", "abs": "https://arxiv.org/abs/2506.18538", "authors": ["Rifat Ara Shams", "Didar Zowghi", "Muneera Bano"], "title": "A Question Bank to Assess AI Inclusivity: Mapping out the Journey from Diversity Errors to Inclusion Excellence", "comment": null, "summary": "Ensuring diversity and inclusion (D&I) in artificial intelligence (AI) is\ncrucial for mitigating biases and promoting equitable decision-making. However,\nexisting AI risk assessment frameworks often overlook inclusivity, lacking\nstandardized tools to measure an AI system's alignment with D&I principles.\nThis paper introduces a structured AI inclusivity question bank, a\ncomprehensive set of 253 questions designed to evaluate AI inclusivity across\nfive pillars: Humans, Data, Process, System, and Governance. The development of\nthe question bank involved an iterative, multi-source approach, incorporating\ninsights from literature reviews, D&I guidelines, Responsible AI frameworks,\nand a simulated user study. The simulated evaluation, conducted with 70\nAI-generated personas related to different AI jobs, assessed the question\nbank's relevance and effectiveness for AI inclusivity across diverse roles and\napplication domains. The findings highlight the importance of integrating D&I\nprinciples into AI development workflows and governance structures. The\nquestion bank provides an actionable tool for researchers, practitioners, and\npolicymakers to systematically assess and enhance the inclusivity of AI\nsystems, paving the way for more equitable and responsible AI technologies.", "AI": {"tldr": "本文提出一个包含253个问题的AI包容性评估题库，覆盖人类、数据、流程、系统与治理五大支柱，旨在通过标准化工具促进AI系统的多样性与包容性。", "motivation": "现有AI风险评估框架常忽视包容性指标，缺乏衡量AI系统是否符合多样性与包容性（D&I）原则的统一工具，可能导致偏见决策。", "method": "通过文献综述、D&I指南、负责任AI框架及模拟用户研究（70个AI生成角色参与）的多源迭代方法开发题库，并评估其跨领域适用性。", "result": "模拟测试表明题库能有效评估不同AI职位和应用场景的包容性，强调需将D&I原则融入AI开发流程与治理体系。", "conclusion": "该题库为研究者、从业者及政策制定者提供了系统性提升AI包容性的实操工具，推动更公平、负责任的AI技术发展。"}}
{"id": "2506.18543", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18543", "abs": "https://arxiv.org/abs/2506.18543", "authors": ["Xiaodong Wu", "Xiangman Li", "Jianbing Ni"], "title": "Security Assessment of DeepSeek and GPT Series Models against Jailbreak Attacks", "comment": null, "summary": "The widespread deployment of large language models (LLMs) has raised critical\nconcerns over their vulnerability to jailbreak attacks, i.e., adversarial\nprompts that bypass alignment mechanisms and elicit harmful or policy-violating\noutputs. While proprietary models like GPT-4 have undergone extensive\nevaluation, the robustness of emerging open-source alternatives such as\nDeepSeek remains largely underexplored, despite their growing adoption in\nreal-world applications. In this paper, we present the first systematic\njailbreak evaluation of DeepSeek-series models, comparing them with GPT-3.5 and\nGPT-4 using the HarmBench benchmark. We evaluate seven representative attack\nstrategies across 510 harmful behaviors categorized by both function and\nsemantic domain. Our analysis reveals that DeepSeek's Mixture-of-Experts (MoE)\narchitecture introduces routing sparsity that offers selective robustness\nagainst optimization-based attacks such as TAP-T, but leads to significantly\nhigher vulnerability under prompt-based and manually engineered attacks. In\ncontrast, GPT-4 Turbo demonstrates stronger and more consistent safety\nalignment across diverse behaviors, likely due to its dense Transformer design\nand reinforcement learning from human feedback. Fine-grained behavioral\nanalysis and case studies further show that DeepSeek often routes adversarial\nprompts to under-aligned expert modules, resulting in inconsistent refusal\nbehaviors. These findings highlight a fundamental trade-off between\narchitectural efficiency and alignment generalization, emphasizing the need for\ntargeted safety tuning and modular alignment strategies to ensure secure\ndeployment of open-source LLMs.", "AI": {"tldr": "本文首次系统评估了DeepSeek系列模型在对抗性提示攻击（越狱攻击）下的鲁棒性，并与GPT-3.5、GPT-4进行对比。研究发现DeepSeek的混合专家（MoE）架构对优化类攻击具有选择性抵抗力，但对提示类攻击更脆弱，揭示了架构效率与安全对齐间的权衡。", "motivation": "随着开源大模型（如DeepSeek）的广泛应用，其对抗越狱攻击的鲁棒性尚未得到充分研究。本文旨在填补这一空白，评估开源模型与商用模型（如GPT-4）在安全对齐上的差异。", "method": "使用HarmBench基准测试，对比评估DeepSeek与GPT-3.5/GPT-4 Turbo。测试7种典型攻击策略，覆盖510种按功能和语义分类的有害行为，分析MoE架构的路由稀疏性对安全性的影响。", "result": "DeepSeek的MoE架构对TAP-T等优化攻击具有选择性鲁棒性，但对提示工程攻击更敏感；GPT-4 Turbo因密集Transformer结构和RLHF训练表现更稳定。案例显示DeepSeek常将对抗提示路由至未充分对齐的专家模块。", "conclusion": "研究揭示了架构效率与安全泛化间的根本性权衡，强调需针对开源模型开发模块化对齐策略和定向安全调优，以确保安全部署。"}}
{"id": "2506.18559", "categories": ["cs.AI", "cs.LO", "I.2.7; F.4.1"], "pdf": "https://arxiv.org/pdf/2506.18559", "abs": "https://arxiv.org/abs/2506.18559", "authors": ["Hong Qing Yu"], "title": "T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent", "comment": null, "summary": "Large language models excel at generating fluent text but frequently struggle\nwith structured reasoning involving temporal constraints, causal relationships,\nand probabilistic reasoning. To address these limitations, we propose Temporal\nCausal Probabilistic Description Logic (T-CPDL), an integrated framework that\nextends traditional Description Logic with temporal interval operators,\nexplicit causal relationships, and probabilistic annotations. We present two\ndistinct variants of T-CPDL: one capturing qualitative temporal relationships\nthrough Allen's interval algebra, and another variant enriched with explicit\ntimestamped causal assertions. Both variants share a unified logical structure,\nenabling complex reasoning tasks ranging from simple temporal ordering to\nnuanced probabilistic causation. Empirical evaluations on temporal reasoning\nand causal inference benchmarks confirm that T-CPDL substantially improves\ninference accuracy, interpretability, and confidence calibration of language\nmodel outputs. By delivering transparent reasoning paths and fine-grained\ntemporal and causal semantics, T-CPDL significantly enhances the capability of\nlanguage models to support robust, explainable, and trustworthy\ndecision-making. This work also lays the groundwork for developing advanced\nLogic-Retrieval-Augmented Generation (Logic-RAG) frameworks, potentially\nboosting the reasoning capabilities and efficiency of knowledge graph-enhanced\nRAG systems.", "AI": {"tldr": "本文提出了一种名为T-CPDL的新型逻辑框架，通过整合时间、因果和概率推理，显著提升了大语言模型在结构化推理任务中的表现。", "motivation": "大语言模型在生成流畅文本方面表现出色，但在涉及时间约束、因果关系和概率推理的结构化推理任务中表现不佳，需要更强大的逻辑框架来支持。", "method": "提出了T-CPDL（时间因果概率描述逻辑），扩展了传统描述逻辑，包含时间区间算子、显式因果关系和概率标注。设计了两种变体：一种基于Allen区间代数的定性时间关系，另一种带有时间戳因果断言。", "result": "在时间推理和因果推断基准测试中，T-CPDL显著提高了推理准确性、可解释性和置信度校准能力，为语言模型提供了透明的推理路径和细粒度语义。", "conclusion": "T-CPDL框架不仅增强了语言模型的可靠决策能力，还为开发先进的逻辑检索增强生成（Logic-RAG）系统奠定了基础，有望提升知识图谱增强系统的推理效率。"}}
{"id": "2506.18685", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.18685", "abs": "https://arxiv.org/abs/2506.18685", "authors": ["Yara Schütt", "Esfandiar Mohammadi"], "title": "Understanding the Theoretical Guarantees of DPM", "comment": null, "summary": "In this study, we conducted an in-depth examination of the utility analysis\nof the differentially private mechanism (DPM). The authors of DPM have already\nestablished the probability of a good split being selected and of DPM halting.\nIn this study, we expanded the analysis of the stopping criterion and provided\nan interpretation of these guarantees in the context of realistic input\ndistributions. Our findings revealed constraints on the minimum cluster size\nand the metric weight for the scoring function. Furthermore, we introduced an\ninterpretation of the utility of DPM through the lens of the clustering metric,\nthe silhouette score. Our findings indicate that even when an optimal DPM-based\nsplit is employed, the silhouette score of the resulting clustering may still\ndecline. This observation calls into question the suitability of the silhouette\nscore as a clustering metric. Finally, we examined the potential of the\nunderlying concept of DPM by linking it to a more theoretical view, that of\n$(\\xi, \\rho)$-separability. This extensive analysis of the theoretical\nguarantees of DPM allows a better understanding of its behaviour for arbitrary\ninputs. From these guarantees, we can analyse the impact of different\nhyperparameters and different input data sets, thereby promoting the\napplication of DPM in practice for unknown settings and data sets.", "AI": {"tldr": "本研究深入分析了差分隐私机制(DPM)的效用，扩展了停止准则的理论解释，揭示了最小聚类规模和评分函数权重限制，并通过轮廓系数质疑其作为聚类指标的适用性，最后将DPM与$(\\xi, \\rho)$-可分离性理论关联，促进其在未知场景中的应用。", "motivation": "已有研究建立了DPM选择优质分裂及停止的概率保证，但需在现实输入分布背景下重新解读这些理论保证，以理解DPM在任意输入中的行为规律。", "method": "通过聚类指标轮廓系数解读DPM效用，分析分裂停止准则的理论边界，并将其与$(\\xi, \\rho)$-可分离性理论框架关联。", "result": "发现即使采用最优DPM分裂，轮廓系数仍可能下降；确定了最小聚类规模和评分函数权重的约束条件，揭示了超参数与输入数据集对DPM效果的影响机制。", "conclusion": "对DPM理论保证的系统分析不仅质疑了轮廓系数的适用性，更通过$(\\xi, \\rho)$-可分离性框架推动DPM在未知数据环境中的实践应用。"}}
{"id": "2506.18586", "categories": ["cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18586", "abs": "https://arxiv.org/abs/2506.18586", "authors": ["Zijie Yang", "Qiji Zhou", "Fang Guo", "Sijie Zhang", "Yexun Xi", "Jinglei Nie", "Yudian Zhu", "Liping Huang", "Chou Wu", "Yonghe Xia", "Xiaoyu Ma", "Yingming Pu", "Panzhong Lu", "Junshu Pan", "Mingtao Chen", "Tiannan Guo", "Yanmei Dou", "Hongyu Chen", "Anping Zeng", "Jiaxing Huang", "Tian Xu", "Yue Zhang"], "title": "Airalogy: AI-empowered universal data digitization for research automation", "comment": "146 pages, 6 figures, 49 supplementary figures", "summary": "Research data are the foundation of Artificial Intelligence (AI)-driven\nscience, yet current AI applications remain limited to a few fields with\nreadily available, well-structured, digitized datasets. Achieving comprehensive\nAI empowerment across multiple disciplines is still out of reach. Present-day\nresearch data collection is often fragmented, lacking unified standards,\ninefficiently managed, and difficult to share. Creating a single platform for\nstandardized data digitization needs to overcome the inherent challenge of\nbalancing between universality (supporting the diverse, ever-evolving needs of\nvarious disciplines) and standardization (enforcing consistent formats to fully\nenable AI). No existing platform accommodates both facets. Building a truly\nmultidisciplinary platform requires integrating scientific domain knowledge\nwith sophisticated computing skills. Researchers often lack the computational\nexpertise to design customized and standardized data recording methods, whereas\nplatform developers rarely grasp the intricate needs of multiple scientific\ndomains. These gaps impede research data standardization and hamper AI-driven\nprogress. In this study, we address these challenges by developing Airalogy\n(https://airalogy.com), the world's first AI- and community-driven platform\nthat balances universality and standardization for digitizing research data\nacross multiple disciplines. Airalogy represents entire research workflows\nusing customizable, standardized data records and offers an advanced AI\nresearch copilot for intelligent Q&A, automated data entry, analysis, and\nresearch automation. Already deployed in laboratories across all four schools\nof Westlake University, Airalogy has the potential to accelerate and automate\nscientific innovation in universities, industry, and the global research\ncommunity-ultimately benefiting humanity as a whole.", "AI": {"tldr": "本文介绍了Airalogy平台，首个AI与社区驱动的多学科研究数据数字化平台，旨在解决研究数据标准化与通用性之间的平衡问题，已在西湖大学四个学院实验室部署。", "motivation": "当前AI应用受限于数据标准化不足和跨学科数据共享困难，阻碍了多学科AI赋能的全面实现。", "method": "开发Airalogy平台，整合科学领域知识与计算技术，提供可定制、标准化的数据记录方法和AI研究助手功能。", "result": "Airalogy平台成功在西湖大学多个实验室部署，支持智能问答、自动化数据录入与分析，推动科研自动化。", "conclusion": "Airalogy平台有望加速全球科研创新，实现跨学科研究数据的标准化与共享，最终造福全人类。"}}
{"id": "2506.18715", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.18715", "abs": "https://arxiv.org/abs/2506.18715", "authors": ["Stefano Perone", "Simone Guarino", "Luca Faramondi", "Roberto Setola"], "title": "Vulnerability Assessment Combining CVSS Temporal Metrics and Bayesian Networks", "comment": "This paper has been accepted for the 2025 IEEE International\n  Conference on Cyber Security and Resilience (CSR), Chania, Crete, Greece,\n  August 4-6 2025", "summary": "Vulnerability assessment is a critical challenge in cybersecurity,\nparticularly in industrial environments. This work presents an innovative\napproach by incorporating the temporal dimension into vulnerability assessment,\nan aspect neglected in existing literature. Specifically, this paper focuses on\nrefining vulnerability assessment and prioritization by integrating Common\nVulnerability Scoring System (CVSS) Temporal Metrics with Bayesian Networks to\naccount for exploit availability, remediation efforts, and confidence in\nreported vulnerabilities. Through probabilistic modeling, Bayesian networks\nenable a structured and adaptive evaluation of vulnerabilities, allowing for\nmore accurate prioritization and decision-making. The proposed approach\ndynamically computes the Temporal Score and updates the CVSS Base Score by\nprocessing data on exploits and fixes from vulnerability databases.", "AI": {"tldr": "该研究提出了一种结合CVSS时间指标与贝叶斯网络的创新方法，用于动态评估工业网络安全漏洞优先级。", "motivation": "现有漏洞评估方法忽视时间维度，无法有效应对工业环境中漏洞修复与利用的动态变化。", "method": "通过贝叶斯网络概率建模整合CVSS时间指标，动态计算漏洞时间分数并更新基础分数，考量漏洞利用可行性、修复状态及报告可信度。", "result": "该方法实现了漏洞优先级的自适应评估，为决策提供更精准的动态数据支撑。", "conclusion": "融合时间维度的贝叶斯网络模型显著提升了漏洞评估的时效性与准确性，特别适用于需要快速响应的工业安全场景。"}}
{"id": "2506.18628", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18628", "abs": "https://arxiv.org/abs/2506.18628", "authors": ["Piotr Matys", "Jan Eliasz", "Konrad Kiełczyński", "Mikołaj Langner", "Teddy Ferdinan", "Jan Kocoń", "Przemysław Kazienko"], "title": "AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs", "comment": "ICCS 2025 Workshops", "summary": "In real-world applications, Large Language Models (LLMs) often hallucinate,\neven in Retrieval-Augmented Generation (RAG) settings, which poses a\nsignificant challenge to their deployment. In this paper, we introduce\nAggTruth, a method for online detection of contextual hallucinations by\nanalyzing the distribution of internal attention scores in the provided context\n(passage). Specifically, we propose four different variants of the method, each\nvarying in the aggregation technique used to calculate attention scores. Across\nall LLMs examined, AggTruth demonstrated stable performance in both same-task\nand cross-task setups, outperforming the current SOTA in multiple scenarios.\nFurthermore, we conducted an in-depth analysis of feature selection techniques\nand examined how the number of selected attention heads impacts detection\nperformance, demonstrating that careful selection of heads is essential to\nachieve optimal results.", "AI": {"tldr": "本文提出AggTruth方法，通过分析上下文注意力分数分布在线检测大语言模型(LLM)的幻觉问题，四种变体在不同场景下均优于现有技术，并证明注意力头选择对性能至关重要。", "motivation": "大语言模型(LLM)在实际应用中常产生幻觉问题，即使在检索增强生成(RAG)场景下仍存在挑战，亟需有效的在线检测方法。", "method": "提出AggTruth方法，通过四种不同的注意力分数聚合技术分析上下文分布，并深入研究特征选择及注意力头数量对检测性能的影响。", "result": "在所有测试LLM中，AggTruth在同任务和跨任务场景均表现稳定，多项指标超越当前最优方法(SOTA)，注意力头选择对结果有显著影响。", "conclusion": "研究表明基于注意力机制的在线幻觉检测具有可行性，精心设计的注意力头选择策略可显著提升检测性能，为LLM部署提供重要技术支撑。"}}
{"id": "2506.18767", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.18767", "abs": "https://arxiv.org/abs/2506.18767", "authors": ["Yifan Zhang", "Yongchao Dang", "Masoud Kaveh", "Zheng Yan", "Riku Jäntti", "Zhu Han"], "title": "Physical Layer Challenge-Response Authentication between Ambient Backscatter Devices", "comment": null, "summary": "Ambient backscatter communication (AmBC) has become an integral part of\nubiquitous Internet of Things (IoT) applications due to its energy-harvesting\ncapabilities and ultra-low-power consumption. However, the open wireless\nenvironment exposes AmBC systems to various attacks, and existing\nauthentication methods cannot be implemented between resource-constrained\nbackscatter devices (BDs) due to their high computational demands.To this end,\nthis paper proposes PLCRA-BD, a novel physical layer challenge-response\nauthentication scheme between BDs in AmBC that overcomes BDs' limitations,\nsupports high mobility, and performs robustly against impersonation and\nwireless attacks. It constructs embedded keys as physical layer fingerprints\nfor lightweight identification and designs a joint transceiver that integrates\nBDs' backscatter waveform with receiver functionality to mitigate interference\nfrom ambient RF signals by exploiting repeated patterns in OFDM symbols. Based\non this, a challenge-response authentication procedure is introduced to enable\nlow-complexity fingerprint exchange between two paired BDs leveraging channel\ncoherence, while securing the exchange process using a random number and\nunpredictable channel fading. Additionally, we optimize the authentication\nprocedure for high-mobility scenarios, completing exchanges within the channel\ncoherence time to minimize the impact of dynamic channel fluctuations. Security\nanalysis confirms its resistance against impersonation, eavesdropping, replay,\nand counterfeiting attacks. Extensive simulations validate its effectiveness in\nresource-constrained BDs, demonstrating high authentication accuracy across\ndiverse channel conditions, robustness against multiple wireless attacks, and\nsuperior efficiency compared to traditional authentication schemes.", "AI": {"tldr": "本文提出PLCRA-BD方案，一种面向环境反向散射通信(AmBC)的轻量级物理层挑战-响应认证机制，解决资源受限设备的安全认证问题，支持高移动性并有效抵御多种无线攻击。", "motivation": "环境反向散射通信(AmBC)因能量收集特性成为物联网关键技术，但开放无线环境使其易受攻击，且传统认证方法无法在资源受限的背向散射设备(BD)间实施。", "method": "1) 构建物理层指纹作为轻量级身份标识 2) 设计收发一体联合架构，利用OFDM符号重复模式抑制环境射频干扰 3) 基于信道相干性实现低复杂度挑战-响应认证 4) 针对高移动场景优化流程，确保在信道相干时间内完成交换。", "result": "安全分析表明方案可抵抗假冒、窃听、重放和伪造攻击。仿真验证其在资源受限BD中的高效性，在不同信道条件下均保持高认证精度，且性能优于传统方案。", "conclusion": "PLCRA-BD通过物理层指纹和联合收发设计，为AmBC系统提供了安全、轻量且支持移动场景的认证解决方案，显著提升了资源受限设备的安全性。"}}
{"id": "2506.18651", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18651", "abs": "https://arxiv.org/abs/2506.18651", "authors": ["Shuocun Yang", "Huawen Hu", "Enze Shi", "Shu Zhang"], "title": "Dual-level Behavioral Consistency for Inter-group and Intra-group Coordination in Multi-Agent Systems", "comment": null, "summary": "Behavioral diversity in Multi-agent reinforcement learning(MARL) represents\nan emerging and promising research area. Prior work has largely centered on\nintra-group behavioral consistency in multi-agent systems, with limited\nattention given to behavioral consistency in multi-agent grouping scenarios. In\nthis paper, we introduce Dual-Level Behavioral Consistency (DLBC), a novel MARL\ncontrol method designed to explicitly regulate agent behaviors at both\nintra-group and inter-group levels. DLBC partitions agents into distinct groups\nand dynamically modulates behavioral diversity both within and between these\ngroups. By dynamically modulating behavioral diversity within and between these\ngroups, DLBC achieves enhanced division of labor through inter-group\nconsistency, which constrains behavioral strategies across different groups.\nSimultaneously, intra-group consistency, achieved by aligning behavioral\nstrategies within each group, fosters stronger intra-group cooperation.\nCrucially, DLBC's direct constraint of agent policy functions ensures its broad\napplicability across various algorithmic frameworks. Experimental results in\nvarious grouping cooperation scenarios demonstrate that DLBC significantly\nenhances both intra-group cooperative performance and inter-group task\nspecialization, yielding substantial performance improvements. DLBC provides\nnew ideas for behavioral consistency control of multi-intelligent body systems,\nand its potential for application in more complex tasks and dynamic\nenvironments can be further explored in the future.", "AI": {"tldr": "本文提出双层级行为一致性(DLBC)方法，通过动态调节组内与组间行为多样性，提升多智能体强化学习中的分工与合作效率。", "motivation": "现有研究多关注组内行为一致性，而忽视了多智能体分组场景中的行为调控需求，亟需一种能同时管理组内与组间行为的方法。", "method": "DLBC将智能体分组后，通过组间一致性约束不同组的行为策略实现分工，通过组内一致性对齐组内行为策略促进合作，并直接约束策略函数以保证算法普适性。", "result": "实验表明DLBC显著提升了组内合作性能与组间任务专精化，在多种分组合作场景中取得实质性性能改进。", "conclusion": "DLBC为多智能体系统行为调控提供了新思路，未来可探索其在更复杂任务和动态环境中的应用潜力。"}}
{"id": "2506.18780", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2506.18780", "abs": "https://arxiv.org/abs/2506.18780", "authors": ["Shuangbao Paul Wang"], "title": "Design high-confidence computers using trusted instructional set architecture and emulators", "comment": null, "summary": "High-confidence computing relies on trusted instructional set architecture,\nsealed kernels, and secure operating systems. Cloud computing depends on\ntrusted systems for virtualization tasks. Branch predictions and pipelines are\nessential in improving performance of a CPU/GPU. But Spectre and Meltdown make\nmodern processors vulnerable to be exploited. Disabling the prediction and\npipeline is definitely not a good solution. On the other hand, current software\npatches can only address non-essential issues around Meltdown. This paper\nintroduces a holistic approach in trusted computer architecture design and\nemulation.", "AI": {"tldr": "本文提出了一种可信计算机架构设计与仿真的整体方法，以应对现代处理器因Spectre和Meltdown漏洞而面临的安全威胁。", "motivation": "高可信计算依赖于可信指令集架构、密封内核和安全操作系统，而云计算则依赖于可信系统进行虚拟化任务。然而，Spectre和Meltdown漏洞使现代处理器易受攻击，禁用分支预测和流水线并非理想解决方案，现有软件补丁仅能解决非核心问题。", "method": "论文提出了一种整体性的可信计算机架构设计与仿真方法。", "result": "该方法旨在从根本上解决现代处理器的安全漏洞问题，而非仅通过软件补丁或禁用关键性能优化技术。", "conclusion": "通过整体性的架构设计与仿真，可以有效提升计算机系统的安全性和可信度，同时保持高性能计算能力。"}}
{"id": "2506.18777", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.18777", "abs": "https://arxiv.org/abs/2506.18777", "authors": ["Jonathan Cook", "Silvia Sapora", "Arash Ahmadian", "Akbir Khan", "Tim Rocktaschel", "Jakob Foerster", "Laura Ruis"], "title": "Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training", "comment": null, "summary": "Training large language models (LLMs) on source code significantly enhances\ntheir general-purpose reasoning abilities, but the mechanisms underlying this\ngeneralisation are poorly understood. In this paper, we propose Programming by\nBackprop (PBB) as a potential driver of this effect - teaching a model to\nevaluate a program for inputs by training on its source code alone, without\never seeing I/O examples. To explore this idea, we finetune LLMs on two sets of\nprograms representing simple maths problems and algorithms: one with source\ncode and I/O examples (w/ IO), the other with source code only (w/o IO). We\nfind evidence that LLMs have some ability to evaluate w/o IO programs for\ninputs in a range of experimental settings, and make several observations.\nFirstly, PBB works significantly better when programs are provided as code\nrather than semantically equivalent language descriptions. Secondly, LLMs can\nproduce outputs for w/o IO programs directly, by implicitly evaluating the\nprogram within the forward pass, and more reliably when stepping through the\nprogram in-context via chain-of-thought. We further show that PBB leads to more\nrobust evaluation of programs across inputs than training on I/O pairs drawn\nfrom a distribution that mirrors naturally occurring data. Our findings suggest\na mechanism for enhanced reasoning through code training: it allows LLMs to\ninternalise reusable algorithmic abstractions. Significant scope remains for\nfuture work to enable LLMs to more effectively learn from symbolic procedures,\nand progress in this direction opens other avenues like model alignment by\ntraining on formal constitutional principles.", "AI": {"tldr": "研究发现仅通过源代码训练（无需输入输出示例）可使大语言模型（LLMs）具备程序评估能力，这种\"反向传播编程\"（PBB）机制能帮助模型内化可复用的算法抽象，从而增强推理能力。", "motivation": "探索代码训练提升LLMs通用推理能力的机制，提出\"反向传播编程\"（PBB）假说——仅通过源代码（无I/O示例）训练即可使模型学会程序评估。", "method": "微调LLMs处理两类程序（数学问题/算法）：一组含源代码+I/O示例（w/ IO），另一组仅含源代码（w/o IO）。对比模型在代码形式vs自然语言描述、直接生成vs思维链步进等场景下的表现。", "result": "1) PBB在代码形式下效果显著优于自然语言描述；2) LLMs能通过前向传播隐式评估w/o IO程序，思维链步进可提升可靠性；3) PBB比基于数据分布I/O训练的程序评估更具鲁棒性。", "conclusion": "代码训练通过PBB机制使LLMs内化算法抽象从而增强推理。未来需提升模型从符号化流程中学习的能力，该方向进展可拓展至基于形式化原则的模型对齐等应用。"}}
{"id": "2506.18795", "categories": ["cs.CR", "cs.SE", "D.2.4; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.18795", "abs": "https://arxiv.org/abs/2506.18795", "authors": ["Jiachi Chen", "Yiming Shen", "Jiashuo Zhang", "Zihao Li", "John Grundy", "Zhenzhe Shao", "Yanlin Wang", "Jiashui Wang", "Ting Chen", "Zibin Zheng"], "title": "FORGE: An LLM-driven Framework for Large-Scale Smart Contract Vulnerability Dataset Construction", "comment": "Accepted for the 48th International Conference on Software\n  Engineering (ICSE 2026)", "summary": "High-quality smart contract vulnerability datasets are critical for\nevaluating security tools and advancing smart contract security research. Two\nmajor limitations of current manual dataset construction are (1)\nlabor-intensive and error-prone annotation processes limiting the scale,\nquality, and evolution of the dataset, and (2) absence of standardized\nclassification rules results in inconsistent vulnerability categories and\nlabeling results across different datasets. To address these limitations, we\npresent FORGE, the first automated approach for constructing smart contract\nvulnerability datasets. FORGE leverages an LLM-driven pipeline to extract\nhigh-quality vulnerabilities from real-world audit reports and classify them\naccording to the CWE, the most widely recognized classification in software\nsecurity. FORGE employs a divide-and-conquer strategy to extract structured and\nself-contained vulnerability information from these reports. Additionally, it\nuses a tree-of-thoughts technique to classify the vulnerability information\ninto the hierarchical CWE classification. To evaluate FORGE's effectiveness, we\nrun FORGE on 6,454 real-world audit reports and generate a dataset comprising\n81,390 solidity files and 27,497 vulnerability findings across 296 CWE\ncategories. Manual assessment of the dataset demonstrates high extraction\nprecision and classification consistency with human experts (precision of 95.6%\nand inter-rater agreement k-$\\alpha$ of 0.87). We further validate the\npracticality of our dataset by benchmarking 13 existing security tools on our\ndataset. The results reveal the significant limitations in current detection\ncapabilities. Furthermore, by analyzing the severity-frequency distribution\npatterns through a unified CWE perspective in our dataset, we highlight\ninconsistency between current smart contract research focus and priorities\nidentified from real-world vulnerabilities...", "AI": {"tldr": "本文提出FORGE，首个自动化构建智能合约漏洞数据集的方法，通过LLM驱动流程从真实审计报告中提取高质量漏洞并按CWE标准分类，显著提升数据集规模与标注一致性。", "motivation": "当前人工构建的智能合约漏洞数据集存在标注过程劳动密集易出错、分类标准不统一两大局限，制约安全工具评估与安全研究进展。", "method": "FORGE采用分治策略从审计报告提取结构化漏洞信息，并运用思维树技术将其分类至CWE层级体系，实现自动化数据集构建。", "result": "处理6,454份审计报告生成含81,390个Solidity文件、27,497个漏洞记录的数据集，人工验证显示提取精确度达95.6%，与专家标注一致性k-$\\alpha$为0.87。对13种安全工具的基准测试揭示了当前检测能力的不足。", "conclusion": "FORGE构建的数据集不仅为安全研究提供标准化基准，还通过CWE统一视角揭示了现实漏洞严重性分布与当前研究重点的不匹配现象。"}}
{"id": "2506.18783", "categories": ["cs.AI", "cs.MA", "68T07", "I.2.11; I.2.7; I.2.8"], "pdf": "https://arxiv.org/pdf/2506.18783", "abs": "https://arxiv.org/abs/2506.18783", "authors": ["Kamil Szczepanik", "Jarosław A. Chudziak"], "title": "TRIZ Agents: A Multi-Agent LLM Approach for TRIZ-Based Innovation", "comment": "12 pages, 10 figures, 2 tables, Accepted at the 17th International\n  Conference on Agents and Artificial Intelligence (ICAART 2025). Final version\n  published in Proceedings of ICAART 2025 (Vol. 1), pages 196-207", "summary": "TRIZ, the Theory of Inventive Problem Solving, is a structured,\nknowledge-based framework for innovation and abstracting problems to find\ninventive solutions. However, its application is often limited by the\ncomplexity and deep interdisciplinary knowledge required. Advancements in Large\nLanguage Models (LLMs) have revealed new possibilities for automating parts of\nthis process. While previous studies have explored single LLMs in TRIZ\napplications, this paper introduces a multi-agent approach. We propose an\nLLM-based multi-agent system, called TRIZ agents, each with specialized\ncapabilities and tool access, collaboratively solving inventive problems based\non the TRIZ methodology. This multi-agent system leverages agents with various\ndomain expertise to efficiently navigate TRIZ steps. The aim is to model and\nsimulate an inventive process with language agents. We assess the effectiveness\nof this team of agents in addressing complex innovation challenges based on a\nselected case study in engineering. We demonstrate the potential of agent\ncollaboration to produce diverse, inventive solutions. This research\ncontributes to the future of AI-driven innovation, showcasing the advantages of\ndecentralized problem-solving in complex ideation tasks.", "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）的多智能体系统（TRIZ agents），通过协作解决TRIZ创新问题，展示了在复杂工程案例中分散式问题解决的优势。", "motivation": "TRIZ理论虽为创新提供结构化框架，但其应用常受限于跨学科知识的高复杂度。大型语言模型的发展为自动化部分流程提供了新可能，但现有研究仅探索单一模型。本文旨在通过多智能体协作突破这一局限。", "method": "设计基于LLM的多智能体系统（TRIZ agents），每个智能体具备专业领域能力与工具访问权限，依据TRIZ方法论协作解决创新问题。通过工程案例评估团队效能。", "result": "案例研究表明，多智能体协作能高效完成TRIZ流程步骤，并产生多样化的创新解决方案，验证了分散式智能体在复杂构思任务中的潜力。", "conclusion": "该研究为AI驱动的创新提供了新范式，证明多智能体协作在解决跨学科复杂问题时的优越性，推动了TRIZ理论的自动化应用发展。"}}
{"id": "2506.18848", "categories": ["cs.CR", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2506.18848", "abs": "https://arxiv.org/abs/2506.18848", "authors": ["Sara D. Cardell"], "title": "Cellular Automata as Generators of Interleaving Sequences", "comment": null, "summary": "An interleaving sequence is obtained by combining or intertwining elements\nfrom two or more sequences. On the other hand, cellular automata are known to\nbe generators for keystream sequences. In this paper we present two families of\none-dimensional cellular automata as generators of interleaving sequences. This\nstudy aims to close a notable gap within the current body of literature by\nexploring the capacity of cellular automata to generate interleaving sequences.\nWhile previous works have separately examined cellular automata as sequence\ngenerators and interleaving sequences, there exists limited literature\ninterconnecting these two topics. Our study seeks to bridge this gap, providing\nperspectives on the generation of interleaving sequences through the\nutilisation of cellular automata, thereby fostering a deeper understanding of\nboth disciplines.", "AI": {"tldr": "本文提出两种一维细胞自动机作为交织序列生成器，填补了细胞自动机与交织序列生成之间研究空白。", "motivation": "现有文献中，细胞自动机作为序列生成器与交织序列的研究相互独立，缺乏两者结合的研究。本文旨在填补这一空白，探索细胞自动机生成交织序列的能力。", "method": "研究采用两种一维细胞自动机家族作为交织序列的生成器，通过交织多个序列元素实现序列生成。", "result": "研究展示了细胞自动机能够有效生成交织序列，为这一领域提供了新的生成方法。", "conclusion": "本研究通过细胞自动机生成交织序列，不仅填补了文献空白，还深化了对细胞自动机与序列生成之间关系的理解。"}}
{"id": "2506.18810", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.18810", "abs": "https://arxiv.org/abs/2506.18810", "authors": ["Siao Tang", "Xinyin Ma", "Gongfan Fang", "Xinchao Wang"], "title": "ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation", "comment": "Codes are available at https://github.com/tsa18/ConciseHint", "summary": "Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and\nOpenAI o1 series have achieved notable performance enhancements on complex\nreasoning tasks by scaling up the generation length by Chain-of-Thought (CoT).\nHowever, an emerging issue is their inclination to produce excessively verbose\nreasoning processes, leading to the inefficiency problem. Existing literature\non improving efficiency mainly adheres to the before-reasoning paradigms such\nas prompting and reasoning or fine-tuning and reasoning, but ignores the\npromising direction of directly encouraging the model to speak concisely by\nintervening during the generation of reasoning. In order to fill the blank, we\npropose a framework dubbed ConciseHint, which continuously encourages the\nreasoning model to speak concisely by injecting the textual hint (manually\ndesigned or trained on the concise data) during the token generation of the\nreasoning process. Besides, ConciseHint is adaptive to the complexity of the\nquery by adaptively adjusting the hint intensity, which ensures it will not\nundermine model performance. Experiments on the state-of-the-art LRMs,\nincluding DeepSeek-R1 and Qwen-3 series, demonstrate that our method can\neffectively produce concise reasoning processes while maintaining performance\nwell. For instance, we achieve a reduction ratio of 65\\% for the reasoning\nlength on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.", "AI": {"tldr": "本文提出ConciseHint框架，通过生成过程中注入文本提示来优化大型推理模型的冗长问题，在保持性能的同时显著缩短推理长度。", "motivation": "现有大型推理模型（如DeepSeek-R1）在链式推理（CoT）中普遍存在过度冗长问题，而传统方法仅关注推理前优化，忽略了生成过程中的干预潜力。", "method": "提出动态提示框架ConciseHint：1) 在token生成时注入人工设计或数据训练的简洁提示 2) 根据问题复杂度自适应调整提示强度 3) 兼容主流LRMs模型架构。", "result": "在GSM8K基准测试中，Qwen-3 4B模型的推理长度减少65%且精度无损，DeepSeek-R1等SOTA模型同样验证了有效性。", "conclusion": "ConciseHint首次实现推理过程中的动态简洁化干预，为提升大型语言模型效率开辟了新方向，且不影响原有推理能力。"}}
{"id": "2506.18870", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.18870", "abs": "https://arxiv.org/abs/2506.18870", "authors": ["Yugeng Liu", "Zheng Li", "Hai Huang", "Michael Backes", "Yang Zhang"], "title": "Amplifying Machine Learning Attacks Through Strategic Compositions", "comment": null, "summary": "Machine learning (ML) models are proving to be vulnerable to a variety of\nattacks that allow the adversary to learn sensitive information, cause\nmispredictions, and more. While these attacks have been extensively studied,\ncurrent research predominantly focuses on analyzing each attack type\nindividually. In practice, however, adversaries may employ multiple attack\nstrategies simultaneously rather than relying on a single approach. This\nprompts a crucial yet underexplored question: When the adversary has multiple\nattacks at their disposal, are they able to mount or amplify the effect of one\nattack with another? In this paper, we take the first step in studying the\nstrategic interactions among different attacks, which we define as attack\ncompositions. Specifically, we focus on four well-studied attacks during the\nmodel's inference phase: adversarial examples, attribute inference, membership\ninference, and property inference. To facilitate the study of their\ninteractions, we propose a taxonomy based on three stages of the attack\npipeline: preparation, execution, and evaluation. Using this taxonomy, we\nidentify four effective attack compositions, such as property inference\nassisting attribute inference at its preparation level and adversarial examples\nassisting property inference at its execution level. We conduct extensive\nexperiments on the attack compositions using three ML model architectures and\nthree benchmark image datasets. Empirical results demonstrate the effectiveness\nof these four attack compositions. We implement and release a modular reusable\ntoolkit, COAT. Arguably, our work serves as a call for researchers and\npractitioners to consider advanced adversarial settings involving multiple\nattack strategies, aiming to strengthen the security and robustness of AI\nsystems.", "AI": {"tldr": "该论文首次研究了机器学习模型中多种攻击策略的组合效应，提出了基于攻击流程三阶段的分类法，并通过实验验证了四种有效攻击组合。", "motivation": "当前研究主要关注单一攻击类型，而实践中攻击者可能同时采用多种策略。论文探讨了不同攻击间的协同效应，填补了这一研究空白。", "method": "提出基于准备、执行、评估三阶段的攻击组合分类法，聚焦对抗样本、属性推断、成员推断和属性推断四种推理阶段攻击，开发了可复用工具包COAT。", "result": "在三种ML架构和图像数据集上的实验表明，四种攻击组合（如属性推断辅助属性推断、对抗样本辅助属性推断）具有显著效果。", "conclusion": "研究呼吁学界关注多策略组合攻击场景，以提升AI系统的安全性和鲁棒性，并开源了模块化工具包COAT推动相关研究。"}}
{"id": "2506.18887", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY", "I.2.7; I.2.6; I.2.1; D.3.3; C.4"], "pdf": "https://arxiv.org/pdf/2506.18887", "abs": "https://arxiv.org/abs/2506.18887", "authors": ["Vansh Sharma", "Venkat Raman"], "title": "Steering Conceptual Bias via Transformer Latent-Subspace Activation", "comment": null, "summary": "This work examines whether activating latent subspaces in language models\n(LLMs) can steer scientific code generation toward a specific programming\nlanguage. Five causal LLMs were first evaluated on scientific coding prompts to\nquantify their baseline bias among four programming languages. A static\nneuron-attribution method, perturbing the highest activated MLP weight for a\nC++ or CPP token, proved brittle and exhibited limited generalization across\nprompt styles and model scales. To address these limitations, a\ngradient-refined adaptive activation steering framework (G-ACT) was developed:\nper-prompt activation differences are clustered into a small set of steering\ndirections, and lightweight per-layer probes are trained and refined online to\nselect the appropriate steering vector. In LLaMA-3.2 3B, this approach reliably\nbiases generation towards the CPP language by increasing the average probe\nclassification accuracy by 15% and the early layers (0-6) improving the probe\nclassification accuracy by 61.5% compared to the standard ACT framework. For\nLLaMA-3.3 70B, where attention-head signals become more diffuse, targeted\ninjections at key layers still improve language selection. Although per-layer\nprobing introduces a modest inference overhead, it remains practical by\nsteering only a subset of layers and enables reproducible model behavior. These\nresults demonstrate a scalable, interpretable and efficient mechanism for\nconcept-level control for practical agentic systems.", "AI": {"tldr": "本研究开发了梯度优化的自适应激活导向框架(G-ACT)，通过激活语言模型(LLMs)的潜在子空间，有效引导科学代码生成偏向特定编程语言(如C++)，相比传统方法显著提升了分类准确率和层间导向效率。", "motivation": "现有静态神经元归因方法在引导LLMs生成特定编程语言时存在脆弱性和泛化性不足的问题，需要开发更鲁棒、可扩展的导向机制来实现概念级控制。", "method": "提出G-ACT框架：1) 聚类每提示的激活差异为少量导向向量；2) 在线训练轻量级逐层探针并优化；3) 选择性在关键层进行定向注入，仅导向部分层以保持推理效率。", "result": "在LLaMA-3.2 3B中，平均探针分类准确率提升15%，前7层准确率提升61.5%；对于LLaMA-3.3 70B模型，关键层定向注入仍能改善语言选择，尽管注意力信号更分散。", "conclusion": "G-ACT为实际智能体系统提供了可扩展、可解释且高效的概念控制机制，通过部分层导向平衡性能与开销，实现了可复现的模型行为控制。"}}
{"id": "2506.18902", "categories": ["cs.AI", "cs.CL", "cs.IR", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2506.18902", "abs": "https://arxiv.org/abs/2506.18902", "authors": ["Michael Günther", "Saba Sturua", "Mohammad Kalim Akram", "Isabelle Mohr", "Andrei Ungureanu", "Sedigheh Eslami", "Scott Martens", "Bo Wang", "Nan Wang", "Han Xiao"], "title": "jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval", "comment": "22 pages, 1-10 main, 14-22 experimental results, benchmark tables", "summary": "We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding\nmodel that unifies text and image representations through a novel architecture\nsupporting both single-vector and multi-vector embeddings in the late\ninteraction style. The model incorporates task-specific Low-Rank Adaptation\n(LoRA) adapters to optimize performance across diverse retrieval scenarios,\nincluding query-based information retrieval, cross-modal semantic similarity,\nand programming code search. Comprehensive evaluations demonstrate that\njina-embeddings-v4 achieves state-of-the-art performance on both single- modal\nand cross-modal retrieval tasks, with particular strength in processing\nvisually rich content such as tables, charts, diagrams, and mixed-media\nformats. To facilitate evaluation of this capability, we also introduce\nJina-VDR, a novel benchmark specifically designed for visually rich image\nretrieval.", "AI": {"tldr": "本文介绍了jina-embeddings-v4，一个38亿参数的多模态嵌入模型，通过新颖架构统一文本和图像表示，支持单向量和多向量嵌入，并在多种检索任务中实现最先进性能。", "motivation": "开发一个能够统一文本和图像表示的多模态嵌入模型，以优化跨模态检索任务，特别是在处理视觉丰富内容方面的性能。", "method": "采用新颖的架构支持单向量和多向量嵌入，结合任务特定的低秩适应（LoRA）适配器，优化不同检索场景的性能。", "result": "jina-embeddings-v4在单模态和跨模态检索任务中均达到最先进性能，尤其在处理表格、图表、图表和混合媒体格式等视觉丰富内容方面表现突出。", "conclusion": "jina-embeddings-v4在多模态嵌入和检索任务中表现出色，特别是针对视觉丰富内容的处理能力，为相关领域的研究和应用提供了有力工具。"}}
