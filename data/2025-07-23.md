<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 4]
- [math.OC](#math.OC) [Total: 14]
- [math.NT](#math.NT) [Total: 10]
- [math.CO](#math.CO) [Total: 21]
- [cs.CR](#cs.CR) [Total: 18]
- [cs.AI](#cs.AI) [Total: 42]
- [cs.DM](#cs.DM) [Total: 1]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Structured linear factor models for tail dependence](https://arxiv.org/abs/2507.16340)
*Alexis Boulin,Axel Bücher*

Main category: math.ST

TL;DR: 该论文研究在‘纯变量假设’下，通过线性与最大线性因子模型估计稳定尾部依赖函数$L$的方法，提出了两种算法并提供了有限样本保证，支持维度$d$大于样本量$n$的情况。


<details>
  <summary>Details</summary>
Motivation: 稳定尾部依赖函数$L$是描述多元随机向量极值依赖的重要工具，现有参数模型（如线性/最大线性因子模型）需估计因子载荷矩阵$A$，但传统方法无法处理$K$与$A$均未知且$d>n$的非传统参数空间。

Method: 提出两种算法：1) 在‘纯变量假设’下联合估计因子数$K$和载荷矩阵$A$；2) 通过有限样本理论保证算法有效性，特别适用于高维（$d>n$）场景。

Result: 数值实验验证了算法的可行性，证明即使在$d>n$时，仍能准确估计$K$和$A$，且算法具有明确的统计收敛保证。

Conclusion: 该研究为高维极值依赖建模提供了新工具，突破了传统参数空间的限制，未来可拓展至更复杂的依赖结构分析。

Abstract: A common object to describe the extremal dependence of a $d$-variate random
vector $X$ is the stable tail dependence function $L$. Various parametric
models have emerged, with a popular subclass consisting of those stable tail
dependence functions that arise for linear and max-linear factor models with
heavy tailed factors. The stable tail dependence function is then parameterized
by a $d \times K$ matrix $A$, where $K$ is the number of factors and where $A$
can be interpreted as a factor loading matrix. We study estimation of $L$ under
an additional assumption on $A$ called the `pure variable assumption'. Both $K
\in \{1, \dots, d\}$ and $A \in [0, \infty)^{d \times K}$ are treated as
unknown, which constitutes an unconventional parameter space that does not fit
into common estimation frameworks. We suggest two algorithms that allow to
estimate $K$ and $A$, and provide finite sample guarantees for both algorithms.
Remarkably, the guarantees allow for the case where the dimension $d$ is larger
than the sample size $n$. The results are illustrated with numerical
experiments.

</details>


### [2] [Bayesian causal discovery: Posterior concentration and optimal detection](https://arxiv.org/abs/2507.16529)
*Valentinian Lungu,Joni Shaska,Ioannis Kontoyiannis,Urbashi Mitra*

Main category: math.ST

TL;DR: 本文研究了贝叶斯因果发现中线性结构方程模型的DAG后验集中速率问题，揭示了最大DAG与非最大DAG的指数级与多项式级收敛差异。


<details>
  <summary>Details</summary>
Motivation: 探讨线性结构方程模型下，DAG结构的后验概率如何随样本量收敛，揭示模型结构复杂度对收敛速度的影响机制。

Method: 在固定变量集上采用均匀DAG先验，给定图结构时对线性系数施加独立高斯先验，通过理论分析与模拟实验验证收敛行为。

Result: 最大DAG（无法增边保持无环性）的后验概率以指数速率$e^{-n}$收敛，非最大DAG至多以$1/\sqrt{n}$多项式速率收敛。

Conclusion: 研究揭示了避免过拟合比识别现有结构更困难，并将模型后验分布与边检测的最优假设检验理论建立了新联系。

Abstract: We consider the problem of Bayesian causal discovery for the standard model
of linear structural equations with equivariant Gaussian noise. A uniform prior
is placed on the space of directed acyclic graphs (DAGs) over a fixed set of
variables and, given the graph, independent Gaussian priors are placed on the
associated linear coefficients of pairwise interactions. We show that the rate
at which the posterior on model space concentrates on the true underlying DAG
depends critically on its nature: If it is maximal, in the sense that adding
any one new edge would violate acyclicity, then its posterior probability
converges to 1 exponentially fast (almost surely) in the sample size $n$.
Otherwise, it converges at a rate no faster than $1/\sqrt{n}$. This sharp
dichotomy is an instance of the important general phenomenon that avoiding
overfitting is significantly harder than identifying all of the structure that
is present in the model. We also draw a new connection between the posterior
distribution on model space and recent results on optimal hypothesis testing in
the related problem of edge detection. Our theoretical findings are illustrated
empirically through simulation experiments.

</details>


### [3] [Gaussian Sequence Model: Sample Complexities of Testing, Estimation and LFHT](https://arxiv.org/abs/2507.16734)
*Zeyu Jia,Yury Polyanskiy*

Main category: math.ST

TL;DR: 研究高斯序列模型中拟合优度检验的样本复杂度下限，证明在正交对称凸集下该下限与估计复杂度平方根相关，并在二次凸条件下验证其紧性；同时完全刻画了$\ell_p$-球的免似然假设检验复杂度。


<details>
  <summary>Details</summary>
Motivation: 探讨高斯序列模型$X \sim N(\mathbf{\theta}, I_\infty)$中，当参数空间$\Gamma$为凸紧集时，拟合优度检验样本复杂度与估计复杂度之间的关系，并扩展[GP24]的研究成果。

Method: 采用正交对称性和二次凸性分析技术，通过数学推导建立拟合优度检验复杂度下限，并利用类似方法系统研究$\ell_p$-球的免似然假设检验复杂度。

Result: 证明正交对称凸集下拟合优度检验复杂度下限为估计复杂度平方根，且在二次凸条件下该下限紧；首次揭示$\ell_p$-球免似然检验中仿真样本与观测样本数量的新型权衡关系。

Conclusion: 研究统一了高维统计中检验与估计复杂度的理论关联，为复杂参数空间的假设检验提供了普适性框架，同时开辟了免似然检验样本效率研究的新方向。

Abstract: We study the Gaussian sequence model, i.e. $X \sim N(\mathbf{\theta},
I_\infty)$, where $\mathbf{\theta} \in \Gamma \subset \ell_2$ is assumed to be
convex and compact. We show that goodness-of-fit testing sample complexity is
lower bounded by the square-root of the estimation complexity, whenever
$\Gamma$ is orthosymmetric. We show that the lower bound is tight when $\Gamma$
is also quadratically convex, thus significantly extending validity of the
testing-estimation relationship from [GP24]. Using similar methods, we also
completely characterize likelihood-free hypothesis testing (LFHT) complexity
for $\ell_p$-bodies, discovering new types of tradeoff between the numbers of
simulation and observation samples.

</details>


### [4] [Can we have it all? Non-asymptotically valid and asymptotically exact confidence intervals for expectations and linear regressions](https://arxiv.org/abs/2507.16776)
*Alexis Derumigny,Lucas Girard,Yannick Guyonvarch*

Main category: math.ST

TL;DR: 本文研究了在半参数统计模型中同时满足非渐近有效和渐近精确一致性的置信集（NAVAE CSs），提出了构建此类置信集的通用条件，并在两种标准设置下构建了闭式NAVAE置信区间。


<details>
  <summary>Details</summary>
Motivation: 现有的大样本和有限样本推断方法之间存在差距，本文旨在构建既满足非渐近有效性又具备渐近精确一致性的置信集，以弥补这一差距。

Method: 首先推导了一个通用充分条件：当存在一致渐近精确置信集时，NAVAE置信集即可构建。随后在两种标准设置（标量期望和OLS系数的线性组合）下，仅基于矩条件构建了闭式NAVAE置信区间。

Result: 在标量期望情况下，仅需有界峰度条件；在OLS情况下，矩约束允许异方差性和弱外生性。通过扩大基于中心极限定理的置信区间，确保了非渐近保证，同时这些修正会渐近消失，使置信区间在极限情况下与经典方法一致。

Conclusion: 通过模拟研究展示了该方法的潜力和局限性，为半参数模型中NAVAE置信集的构建提供了理论和实践基础。

Abstract: We contribute to bridging the gap between large- and finite-sample inference
by studying confidence sets (CSs) that are both non-asymptotically valid and
asymptotically exact uniformly (NAVAE) over semi-parametric statistical models.
NAVAE CSs are not easily obtained; for instance, we show they do not exist over
the set of Bernoulli distributions. We first derive a generic sufficient
condition: NAVAE CSs are available as soon as uniform asymptotically exact CSs
are. Second, building on that connection, we construct closed-form NAVAE
confidence intervals (CIs) in two standard settings -- scalar expectations and
linear combinations of OLS coefficients -- under moment conditions only. For
expectations, our sole requirement is a bounded kurtosis. In the OLS case, our
moment constraints accommodate heteroskedasticity and weak exogeneity of the
regressors. Under those conditions, we enlarge the Central Limit Theorem-based
CIs, which are asymptotically exact, to ensure non-asymptotic guarantees. Those
modifications vanish asymptotically so that our CIs coincide with the classical
ones in the limit. We illustrate the potential and limitations of our approach
through a simulation study.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [5] [The Intrinsic Riemannian Proximal Gradient Method for Convex Optimization](https://arxiv.org/abs/2507.16055)
*Ronny Bergmann,Hajg Jasa,Paula John,Max Pfeffer*

Main category: math.OC

TL;DR: 本文提出了一种在Hadamard流形上求解（可能强）测地凸优化问题的内蕴凸黎曼近端梯度法（CRPG），无需在嵌入或切空间中操作，并证明了其收敛速度。


<details>
  <summary>Details</summary>
Motivation: 针对Hadamard流形上目标函数可分解为光滑与非光滑部分之和的优化问题，现有方法常需在嵌入或切空间操作，效率受限。本文旨在开发一种内蕴的高效算法。

Method: 引入凸黎曼近端梯度法（CRPG），直接利用流形上的近端映射处理非光滑项，避免嵌入空间计算，并建立了相应的近端梯度不等式。

Result: 理论证明：凸问题具有次线性收敛率，强凸问题具有线性收敛率。数值实验表明，在双曲空间和对称正定矩阵流形上，CRPG显著优于现有方法。

Conclusion: CRPG方法为流形优化提供了高效的内蕴求解框架，其收敛性理论和数值表现均验证了优越性，推广了欧氏空间中的近端梯度法。

Abstract: We consider a class of (possibly strongly) geodesically convex optimization
problems on Hadamard manifolds, where the objective function splits into the
sum of a smooth and a possibly nonsmooth function. We introduce an intrinsic
convex Riemannian proximal gradient (CRPG) method that employs the manifold
proximal map for the nonsmooth step, without operating in the embedding or
tangent space. A sublinear convergence rate for convex problems and a linear
convergence rate for strongly convex problems is established, and we derive
fundamental proximal gradient inequalities that generalize the Euclidean case.
Our numerical experiments on hyperbolic spaces and manifolds of symmetric
positive definite matrices demonstrate substantial computational advantages
over existing methods.

</details>


### [6] [Conservative fusion of unbiased partial state estimates: CI is optimal](https://arxiv.org/abs/2507.16216)
*Jochen Trumpf,Behzad Zamani,Chris Manzie*

Main category: math.OC

TL;DR: 本文证明了协方差交叉（CI）在一般无偏部分状态估计信息融合中是最优的保守无偏线性融合规则，并揭示了三种优化问题的等价性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在扩展协方差交叉（CI）的最优性结果，从全状态估计融合推广到更一般的无偏部分状态估计融合场景。

Method: 通过证明三种优化问题的等价性（抽象最优保守无偏线性信息融合问题、标量协方差交叉问题、简单半定规划），并给出严格单调成本函数下的解。

Result: 提出了这些问题的通用可解性条件，并针对矩阵行列式和矩阵迹成本函数给出了最优解的方程。

Conclusion: 协方差交叉（CI）在无偏部分状态估计融合中具有广泛的最优性，且其优化问题可转化为等效的半定规划问题求解。

Abstract: We show that Covariance Intersection (CI) is optimal amongst all conservative
unbiased linear fusion rules also in the general case of information fusion of
two unbiased partial state estimates, significantly generalizing the known
optimality result for fusion of full state estimates. In fact, we prove the
much stronger result that three different optimization problems are equivalent,
namely the abstract optimal conservative unbiased linear information fusion
problem with respect to a strictly isotone cost function, the scalar Covariance
Intersection (CI) problem, and a simple semi-definite program (SDP). We provide
a general solvability condition for these problems as well as equations
characterizing the optimal solutions for the matrix determinant and matrix
trace cost functions.

</details>


### [7] [Physics-aware Truck and Drone Delivery Planning Using Optimization & Machine Learning](https://arxiv.org/abs/2507.16259)
*Yineng Sun,Armin Fügenschuh,Vikrant Vaze*

Main category: math.OC

TL;DR: 该研究提出了一种结合卡车路线与无人机轨迹规划的联合优化方法，通过整合无人机飞行物理模型与机器学习预测，显著提升了最后一公里包裹配送的效率和能源利用率。


<details>
  <summary>Details</summary>
Motivation: 传统卡车与无人机协同配送方案常忽略无人机飞行动力学，导致配送计划次优。整合无人机物理模型可降低配送时间与环境影响，但直接引入组合优化问题具有挑战性。

Method: 提出端到端解决方案：基于离线优化的无人机轨迹训练神经网络预测飞行时间，结合改进的order-first-split-second启发式算法，在轨迹优化中显式嵌入运动学与能量方程。

Result: 在合成数据集和实际案例中，该方法在配送时长和无人机能耗方面优于现有基准模型，验证了物理模型整合对系统性能的提升价值。

Conclusion: 该框架可帮助物流企业实现数百万美元的年成本节约，同时减少环境足迹，为卡车-无人机协同配送提供了兼具计算效率与物理精确性的新范式。

Abstract: Combining an energy-efficient drone with a high-capacity truck for last-mile
package delivery can benefit operators and customers by reducing delivery times
and environmental impact. However, directly integrating drone flight dynamics
into the combinatorially hard truck route planning problem is challenging.
Simplified models that ignore drone flight physics can lead to suboptimal
delivery plans. We propose an integrated formulation for the joint problem of
truck route and drone trajectory planning and a new end-to-end solution
approach that combines optimization and machine learning to generate
high-quality solutions in practical online runtimes. Our solution method trains
neural network predictors based on offline solutions to the drone trajectory
optimization problem instances to approximate drone flight times, and uses
these approximations to optimize the overall truck-and-drone delivery plan by
augmenting an existing order-first-split-second heuristic. Our method
explicitly incorporates key kinematics and energy equations in drone trajectory
optimization, and thereby outperforms state-of-the-art benchmarks that ignore
drone flight physics. Extensive experimentation using synthetic datasets and
real-world case studies shows that the integration of drone trajectories into
package delivery planning substantially improves system performance in terms of
tour duration and drone energy consumption. Our modeling and computational
framework can help delivery planners achieve annual savings worth millions of
dollars while also benefiting the environment.

</details>


### [8] [Learning Acceleration Algorithms for Fast Parametric Convex Optimization with Certified Robustness](https://arxiv.org/abs/2507.16264)
*Rajiv Sambharya,Jinho Bok,Nikolai Matni,George Pappas*

Main category: math.OC

TL;DR: 提出一种机器学习框架，通过正则化训练学习一阶加速优化方法（如梯度下降的步长和动量序列）的超参数序列，以快速求解具有认证鲁棒性的参数化凸优化问题。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种能快速解决参数化凸优化问题并保证最坏情况下性能认证的鲁棒超参数学习方法。

Method: 基于半定规划的性能估计问题（PEP）框架，通过梯度训练学习加速梯度下降、近端梯度下降和交替方向乘子法等一阶方法的超参数序列。

Result: 数值实验表明，在有限迭代次数内显著提升解的质量，同时保持强鲁棒性保证，且仅需十个训练实例即实现高效数据利用。

Conclusion: 该框架在信号处理、控制和统计等领域验证了其高效性和鲁棒性，为参数化优化问题提供了数据高效的超参数学习方案。

Abstract: We develop a machine-learning framework to learn hyperparameter sequences for
accelerated first-order methods (e.g., the step size and momentum sequences in
accelerated gradient descent) to quickly solve parametric convex optimization
problems with certified robustness. We obtain a strong form of robustness
guarantee -- certification of worst-case performance over all parameters within
a set after a given number of iterations -- through regularization-based
training. The regularization term is derived from the performance estimation
problem (PEP) framework based on semidefinite programming, in which the
hyperparameters appear as problem data. We show how to use gradient-based
training to learn the hyperparameters for several first-order methods:
accelerated versions of gradient descent, proximal gradient descent, and
alternating direction method of multipliers. Through various numerical examples
from signal processing, control, and statistics, we demonstrate that the
quality of the solution can be dramatically improved within a budget of
iterations, while also maintaining strong robustness guarantees. Notably, our
approach is highly data-efficient in that we only use ten training instances in
all of the numerical examples.

</details>


### [9] [Spectral Methods for Polynomial Optimization](https://arxiv.org/abs/2507.16272)
*Elvira Moreno,Venkat Chandrasekaran*

Main category: math.OC

TL;DR: 本文提出了一种基于广义特征值计算的分层可处理松弛方法，用于多项式优化问题的下界求解，适用于有界约束集的所有多项式优化问题，并通过数值实验验证了其可扩展性。


<details>
  <summary>Details</summary>
Motivation: 针对多项式优化问题，现有凸松弛技术存在局限性，需要一种更高效且适用于大规模问题的方法来获得下界。

Method: 通过计算从问题数据导出的矩阵对的最小广义特征值，构建一系列嵌套的凸外近似，每个近似上的线性优化可简化为特征值计算。

Result: 该方法适用于所有有界约束集的多项式优化问题，数值实验表明其相比基于非负性平方和证书的凸松弛方法具有更好的可扩展性。

Conclusion: 所提出的基于广义特征值的分层松弛框架为多项式优化问题提供了一种高效且可扩展的下界求解方法，特别适用于大规模问题实例。

Abstract: We present a hierarchy of tractable relaxations to obtain lower bounds on the
minimum value of a polynomial over a constraint set defined by polynomial
equations. In contrast to previous convex relaxation techniques for this
problem, our method is based on computing the smallest generalized eigenvalue
of a pair of matrices derived from the problem data, which can be accomplished
for large problem instances using off-the-shelf software. We characterize the
algebraic structure in a problem that facilitates the application of our
framework, and we observe that our method is applicable for all polynomial
optimization problems with bounded constraint sets. Our construction also
yields a nested sequence of structured convex outer approximations of a bounded
algebraic variety with the property that linear optimization over each
approximation reduces to an eigenvalue computation. Finally, we present
numerical experiments on representative problems in which we demonstrate the
scalability of our approach compared to convex relaxation methods derived from
sums-of-squares certificates of nonnegativity.

</details>


### [10] [A Distributional View of High Dimensional Optimization](https://arxiv.org/abs/2507.16315)
*Felix Benning*

Main category: math.OC

TL;DR: 该博士论文提出用分布视角替代传统最坏情况视角来研究优化问题，通过贝叶斯优化分析随机目标函数的优化过程，揭示了高维优化可预测进展的原因，并开发了处理随机函数输入的新数学工具。


<details>
  <summary>Details</summary>
Motivation: 经典优化方法在特定情况下的失效促使研究者采用分布视角，通过分析随机目标函数的优化过程来更全面地理解优化行为。

Method: 论文首先回顾贝叶斯优化方法，随后开发了处理随机函数输入的数学工具，并研究了非平稳各向同性协方差核的特性。

Result: 研究发现分布视角能解释高维优化中的可预测进展，并为梯度下降的最优步长控制提供新见解。同时揭示了数据交换性假设如何导致机器学习中的随机目标函数。

Conclusion: 通过分布视角研究优化问题不仅克服了经典方法的局限，还为理解高维优化和步长控制提供了新思路，同时建立了随机目标函数与机器学习假设之间的联系。

Abstract: This PhD thesis presents a distributional view of optimization in place of a
worst-case perspective. We motivate this view with an investigation of the
failure point of classical optimization. Subsequently we consider the
optimization of a randomly drawn objective function. This is the setting of
Bayesian Optimization. After a review of Bayesian optimization we outline how
such a distributional view may explain predictable progress of optimization in
high dimension. It further turns out that this distributional view provides
insights into optimal step size control of gradient descent. To enable these
results, we develop mathematical tools to deal with random input to random
functions and a characterization of non-stationary isotropic covariance
kernels. Finally, we outline how assumptions about the data, specifically
exchangability, can lead to random objective functions in machine learning and
analyze their landscape.

</details>


### [11] [Discrete-Time LQ Stochastic Two Person Nonzero Sum Difference Games With Random Coefficients:~Closed-Loop Nash Equilibrium](https://arxiv.org/abs/2507.16412)
*Qingxin Meng,Yiwei Wu*

Main category: math.OC

TL;DR: 本文研究了具有随机系数的离散时间线性二次(LQ)随机非零和差分博弈的闭环纳什均衡，通过解耦随机哈密顿系统，建立了与耦合随机Riccati方程(CCREs)相关的均衡策略存在条件。


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分考虑状态动态和成本泛函中的随机性，本文旨在解决随机系数导致的复杂耦合结构，为不确定性下的动态决策提供统一框架。

Method: 采用动态规划原理(DPP)构建解，通过解耦受两个对称CCREs控制的随机哈密顿系统，将均衡策略与Lyapunov型方程关联，并建立CCREs正则可解性的充要条件。

Result: 在最小正则性条件下，证明了闭环纳什均衡存在的充要条件，其依赖于CCREs的正则可解性，且无需强假设；随机系数导致的高阶非线性BS$\triangle$E系统与确定性情形有本质差异。

Conclusion: 研究解决了固有随机性建模的关键挑战，为随机环境下动态博弈提供了基于CCREs的理论框架，扩展了随机LQ差分博弈的分析工具。

Abstract: This paper investigates closed-loop Nash equilibria for discrete-time
linear-quadratic (LQ) stochastic nonzero-sum difference games with random
coefficients. Unlike existing works, we consider randomness in both state
dynamics and cost functionals, leading to a complex structure of fully coupled
cross-coupled stochastic Riccati equations (CCREs). The key contributions lie
in characterizing the equilibrium via state-feedback strategies derived by
decoupling stochastic Hamiltonian systems governed by two symmetric CCREs-these
random coefficients induce a higher-order nonlinear backward stochastic
difference equation (BS$\triangle$E) system, fundamentally differing from
deterministic counterparts. Under minimal regularity conditions, we establish
necessary and sufficient conditions for closed-loop Nash equilibrium existence,
contingent on the regular solvability of CCREs without requiring strong
assumptions. Solutions are constructed using a dynamic programming principle
(DPP), linking equilibrium strategies to coupled Lyapunov-type equations. Our
analysis resolves critical challenges in modeling inherent randomness and
provides a unified framework for dynamic decision-making under uncertainty.

</details>


### [12] [Inexact Levenberg-Marquardt methods under Hölder metric subregularity](https://arxiv.org/abs/2507.16461)
*Bas Symoens,Morteza Rahimi,Masoud Ahookhosh*

Main category: math.OC

TL;DR: 本文研究了两种不精确的Levenberg-Marquardt (LM) 方法，用于求解非线性方程组。第一种方法采用自适应方案更新LM参数，在H\"older度量次正则性和梯度局部H\"older连续条件下实现了局部超线性收敛；第二种方法结合不精确LM步长与非单调二次正则化策略，在Lipschitz连续梯度假设下证明了全局收敛性，并给出了最坏情况下的全局复杂度界限$\mathcal{O}(\epsilon^{-2})$。数值实验验证了LSQR算法在求解相关线性系统中的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究不精确Levenberg-Marquardt方法旨在高效求解非线性方程组，特别是针对实际应用中出现的复杂系统（如生物化学反应网络、图像去模糊问题等），通过降低线性系统求解的精度要求来提高计算效率。

Method: 提出两种不精确LM方法：1) 基于残差条件的自适应LM参数更新方案；2) 结合非单调二次正则化的混合策略。理论分析分别采用H\"older度量次正则性和Lipschitz连续梯度假设，并利用LSQR算法高效求解线性系统。

Result: 方法一在H\"older条件下实现局部超线性收敛；方法二证明全局收敛并建立$\mathcal{O}(\epsilon^{-2})$的复杂度界限。数值实验表明LSQR算法能有效处理生物化学网络、单调方程和图像去模糊等实际问题中的线性系统。

Conclusion: 两种不精确LM方法在不同正则性条件下均具有理论保证，其中非单调正则化策略兼具全局收敛性和可证明复杂度。LSQR算法的应用验证了该方法在实际非线性问题中的计算可行性，为大规模系统求解提供了新工具。

Abstract: This paper investigates two inexact Levenberg-Marquardt (LM) methods for
solving systems of nonlinear equations. Both approaches compute approximate
search directions by solving the LM linear system inexactly, subject to
specific residual-based conditions. The first method uses an adaptive scheme to
update the LM parameter, and we establish its local superlinear convergence
under H\"older metric subregularity and local H\"older continuity of the
gradient. The second method combines an inexact LM step with a nonmonotone
quadratic regularization strategy. For this variant, we prove global
convergence under the assumption of Lipschitz continuous gradients and derive a
worst-case global complexity bound, showing that an approximate stationary
point can be found in $\mathcal{O}(\epsilon^{-2})$ function and gradient
evaluations. Finally, we justify the use of the LSQR algorithm for efficiently
solving the linear systems involved, which is used in our numerical experiment
on several nonlinear systems, including those appearing in real-world
biochemical reaction networks, monotone and nonlinear equations, and image
deblurring problems.

</details>


### [13] [The Sweet Spot of Bound Tightening for Topology Optimization](https://arxiv.org/abs/2507.16496)
*Salvador Pineda,Juan Miguel Morales*

Main category: math.OC

TL;DR: 本文提出了一种基于网络结构的拓扑感知边界紧缩方法，通过部分保留开关变量为二进制状态，显著提升了电力系统拓扑优化的计算效率与边界紧密度。


<details>
  <summary>Details</summary>
Motivation: 现有拓扑优化中的边界紧缩方法因完全松弛所有开关决策，导致可行区域过大且边界改进有限，亟需一种更高效的紧缩策略。

Method: 采用拓扑感知的边界紧缩方法，仅松弛部分开关变量，其余保持二进制状态，平衡计算复杂度与边界紧密度。

Result: 在IEEE 118节点系统上的实验表明，该方法能以较低计算成本获得更紧的变量边界，优化效果显著。

Conclusion: 选择性松弛开关变量的策略为大规模电力系统拓扑优化提供了计算效率与求解精度的有效平衡方案。

Abstract: Topology optimization has emerged as a powerful and increasingly relevant
strategy for enhancing the flexibility and efficiency of power system
operations. However, solving these problems is computationally demanding due to
their combinatorial nature and the use of big-M formulations.
Optimization-based bound tightening (OBBT) is a well-known strategy to improve
the solution of mixed-integer linear programs (MILPs) by computing tighter
bounds for continuous variables. Yet, existing OBBT approaches in topology
optimization typically relax all switching decisions in the bounding
subproblems, leading to excessively loose feasible regions and limited bound
improvements. In this work, we propose a topology-aware bound tightening method
that uses network structure to determine which switching variables to relax.
Through extensive computational experiments on the IEEE 118-bus system, we find
that keeping a small subset of switching variables as binary, while relaxing
the rest, strikes a sweet spot between the computational effort required to
solve the bounding problems and the tightness of the resulting bounds.

</details>


### [14] [A robust and stable phase field method for structural topology optimization](https://arxiv.org/abs/2507.16519)
*Huangxin Chen,Piaopiao Dong,Dong Wang,Xiao-Ping Wang*

Main category: math.OC

TL;DR: 本文提出了一种基于相场方法的新型拓扑优化框架，用于解决固定外载荷和体积力下的最小柔度问题，通过序参量函数表征最优结构，并开发了结合拉格朗日乘子的算子分裂算法。


<details>
  <summary>Details</summary>
Motivation: 传统拓扑优化在处理依赖域的体积力时存在数学挑战，需要开发能同时满足边界保持、体积守恒和目标函数单调递减的约束优化框架。

Method: 采用相场模型中的序参量函数内禀表征设计域及其边界，将问题重构为序参量的约束最小化问题，并提出带有限制机制的算子分裂算法确保严格约束满足。

Result: 数值实验通过全面的二维和三维基准测试验证了方案的鲁棒性，实现了边界精确保持、体积严格守恒及目标函数正确衰减率。

Conclusion: 该混合方法为处理复杂载荷条件下的拓扑优化提供了理论保证和计算可行性，拓展了相场模型在结构优化中的应用边界。

Abstract: This paper presents a novel phase-field-based methodology for solving minimum
compliance problems in topology optimization under fixed external loads and
body forces. The proposed framework characterizes the optimal structure through
an order parameter function, analogous to phase-field models in materials
science, where the design domain and its boundary are intrinsically represented
by the order parameter function. The topology optimization problem is
reformulated as a constrained minimization problem with respect to this order
parameter, requiring simultaneous satisfaction of three critical properties:
bound preservation, volume conservation, and monotonic objective functional
decay throughout the optimization process. The principal mathematical challenge
arises from handling domain-dependent body forces, which necessitates the
development of a constrained optimization framework. To address this, we
develop an operator-splitting algorithm incorporating Lagrange multipliers,
enhanced by a novel limiter mechanism. This hybrid approach guarantees strict
bound preservation, exact volume conservation, and correct objective functional
decaying rate. Numerical implementation demonstrates the scheme's robustness
through comprehensive 2D and 3D benchmarks.

</details>


### [15] [Study on Control Problem of a Impulsive Neutral Integro-Differential Equations with Fading Memory](https://arxiv.org/abs/2507.16560)
*Garima Gupta,Jaydev Dabas*

Main category: math.OC

TL;DR: 本文研究了Banach空间中具有记忆的半线性脉冲中立型积分微分方程的控制问题，探讨了线性和半线性系统的近似可控性，并证明了半线性情形下温和解的存在性。


<details>
  <summary>Details</summary>
Motivation: 研究Banach空间中具有记忆的半线性脉冲中立型积分微分方程的控制问题，旨在扩展对这类复杂系统可控性的理论理解。

Method: 通过构造无记忆线性积分微分方程的解析族，首先建立线性系统的结果，然后推广至半线性情形，并通过具体示例验证理论。

Result: 证明了线性和半线性系统的近似可控性，并在半线性情形下建立了温和解的存在性。

Conclusion: 理论结果表明，所提出的方法能有效处理具有记忆的半线性脉冲中立型积分微分方程的控制问题，并通过示例验证了理论的实用性。

Abstract: This article addresses control problems for semilinear impulsive neutral
integro-differential equations with memory in a Banach space. It investigates
the approximate controllability of linear and semilinear systems and proves the
establishment of mild solutions in the semilinear setting. The approach
involves constructing a resolvent family for the corresponding
integro-differential equation of linear type without memory. The results for
the linear system are established first, then extended to the semilinear
scenario, followed by a detailed example to illustrate the theoretical
findings.

</details>


### [16] [Mean-Field Stochastic Linear-Quadratic Optimal Controls: Roles of Expectation and Conditional Expectation Operators](https://arxiv.org/abs/2507.16582)
*Hanxiao Wang,Jiongmin Yong*

Main category: math.OC

TL;DR: 本文研究了包含期望和条件期望项的均值场线性二次最优控制问题，推导了三种解并建立了Riccati方程的适定性。


<details>
  <summary>Details</summary>
Motivation: 探讨期望和条件期望算子如何影响时间一致性，为均值场控制问题提供理论支持。

Method: 显式推导了预承诺解、朴素解和均衡解，并分析了相关Riccati方程的适定性。

Result: 成功建立了包含期望和条件期望项的均值场控制问题的解框架，揭示了算子对时间一致性的影响机制。

Conclusion: 该研究为理解均值场控制问题中期望算子的作用提供了新的理论视角，具有重要的方法论意义。

Abstract: This paper investigates a mean-field linear-quadratic optimal control problem
where the state dynamics and cost functional incorporate both expectation and
conditional expectation terms. We explicitly derive the pre-committed,
na\"{\i}ve, and equilibrium solutions and establish the well-posedness of the
associated Riccati equations. This reveals how the expectation and conditional
expectation operators influence time-consistency.

</details>


### [17] [An inertial iteratively regularized extragradient method for bilevel variational inequality problems](https://arxiv.org/abs/2507.16640)
*M. Marques Alves,Kangming Chen,Ellen H. Fukuda*

Main category: math.OC

TL;DR: 本文研究了一种双层变分不等式问题，其中可行集本身是另一个变分不等式的解集。针对此类集合投影计算的困难，提出了一种结合惯性的正则化外梯度方法（IneIREG），并在不同单调性假设下建立了迭代复杂度界限。


<details>
  <summary>Details</summary>
Motivation: 由于双层变分不等式问题中可行集的投影计算困难，受Samadi和Yousefian（2025）的启发，本文旨在开发一种更高效的计算方法，通过引入惯性效应来加速收敛。

Method: 提出了一种惯性正则化外梯度方法（IneIREG），该方法在简单约束集上操作，并通过外推步骤引入动量。分析了恒定和递减正则化情况下的迭代复杂度，并在强单调性假设下推导了改进结果。

Result: 在一般（非强单调）情况下建立了迭代复杂度界限，并在强单调性假设下获得了更好的结果。数值实验初步验证了所提方法的有效性。

Conclusion: 本文通过统一框架捕捉惯性和正则化效应，扩展并改进了先前的工作。提出的IneIREG方法在理论和实验上均表现出优越性，为双层变分不等式问题提供了有效的解决方案。

Abstract: We study a bilevel variational inequality problem where the feasible set is
itself the solution set of another variational inequality. Motivated by the
difficulty of computing projections onto such sets, we consider a regularized
extragradient method, as proposed by Samadi and Yousefian (2025), which
operates over a simpler constraint set. Building on this framework, we
introduce an inertial variant (called IneIREG) that incorporates momentum
through extrapolation steps. We establish iteration-complexity bounds for the
general (non-strongly monotone) case under both constant and diminishing
regularization, and derive improved results under strong monotonicity
assumptions. Our analysis extends and refines the results of the previous work
by capturing both inertial and regularization effects within a unified
framework. Preliminary numerical experiments are also presented to illustrate
the behavior of the proposed method.

</details>


### [18] [On the Worst-Case Analysis of Cyclic Block Coordinate Descent type Algorithms](https://arxiv.org/abs/2507.16675)
*Yassine Kamri,François Glineur,Julien M. Hendrickx,Ion Necoara*

Main category: math.OC

TL;DR: 本文研究了块坐标下降（BCD）类算法在坐标光滑凸函数无约束最小化中的最坏情况行为，通过性能估计问题（PEP）方法改进了三种BCD算法的最坏收敛速率上界，并揭示了CCD算法的尺度不变性等现象。


<details>
  <summary>Details</summary>
Motivation: 当前对BCD类算法最坏行为的理解不完整，实际成功无法完全用现有收敛分析解释。研究旨在填补这一空白，并提供更精确的收敛速率界限。

Method: 扩展了PEP方法，提出必要的插值条件，用于坐标光滑凸函数。对CCD、AM和CACD三种算法进行数值分析，并与当前最佳界限对比。

Result: 获得了优于当前最佳界限的数值上界；证明了CCD算法在更自然假设下的收敛性；揭示了CCD的尺度不变性及与全梯度下降最坏性能的关系。

Conclusion: PEP方法有效揭示了BCD算法的收敛特性，发现确定性算法中标准加速方案效率低下，为算法设计提供了新见解。

Abstract: We study the worst-case behavior of Block Coordinate Descent (BCD) type
algorithms for unconstrained minimization of coordinate-wise smooth convex
functions. This behavior is indeed not completely understood, and the practical
success of these algorithms is not fully explained by current convergence
analyses. We extend the recently proposed Performance Estimation Problem (PEP)
approach to convex coordinate-wise smooth functions by proposing necessary
interpolation conditions. We then exploit this to obtain improved numerical
upper bounds on the worst-case convergence rate of three different BCD
algorithms, namely Cyclic Coordinate Descent (CCD), Alternating Minimization
(AM), and a Cyclic version of the Random Accelerated Coordinate Descent
introduced in Fercoq and Richt\'arik (2015) (CACD), substantially outperforming
the best current bounds in some situations. In addition, we show the
convergence of the CCD algorithm with more natural assumptions in the context
of convex optimization than those typically made in the literature. Our
methodology uncovers a number of phenomena, some of which can be formally
established. These include a scale-invariance property of the worst case of CCD
with respect to the coordinate-wise smoothness constants and a lower bound on
the worst-case performance of CCD which is equal to the number of blocks times
the worst-case of full gradient descent over the class of smooth convex
functions. We also adapt our framework to the analysis of random BCD
algorithms, and present numerical results showing that the standard
acceleration scheme in Fercoq and Richt\'arik (2015) appears to be inefficient
for deterministic algorithms.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [19] [Point counts, automorphisms, and gonalities of Shimura curves](https://arxiv.org/abs/2507.15992)
*Pietro Mercuri,Oana Padurariu,Frederick Saia,Claudio Stirpe*

Main category: math.NT

TL;DR: 本文实现了一种计算Shimura曲线$X_0^D(N)$及其Atkin-Lehner商在有限域上点数的算法，并利用该算法解决了若干算术问题。


<details>
  <summary>Details</summary>
Motivation: 研究Shimura曲线$X_0^D(N)$在有限域上的点数，旨在发现特定亏格曲线在给定有限域中点数最多的例子，并解决相关算术问题。

Method: 开发了一种计算$X_0^D(N)$及其Atkin-Lehner商在有限域上点数的算法，并应用于$DN\leq 10000$的曲线分析。

Result: 发现了许多在特定亏格和有限域下点数最多的曲线实例，证明了$DN\leq 10000$时许多$X_0^D(N)$曲线的自同构均为Atkin-Lehner，并确定了几乎所有四角形曲线$X_0^D(N)$。

Conclusion: 该算法不仅有效计算了Shimura曲线的点数，还为研究曲线自同构和分类提供了有力工具，解决了若干长期未决的算术问题。

Abstract: We implement an algorithm to compute the number of points over finite fields
for the Shimura curves $X_0^D(N)$ and their Atkin--Lehner quotients. Our
computations result in many examples of curves which attain the largest known
point counts among curves of specified genus over a finite field of given
cardinality. To illustrate the utility of our point counts algorithm in
addressing arithmetic questions, we prove that all automorphisms are
Atkin--Lehner for many curves $X_0^D(N)$ with $DN\leq 10000$, and we determine
all tetragonal curves $X_0^D(N)$ up to a small number of possible exceptions.

</details>


### [20] [A further investigation on covering systems with odd moduli](https://arxiv.org/abs/2507.16135)
*Chris Bispels,Matthew Cohen,Joshua Harrington,Joshua Lowrance,Kaelyn Pontes,Leif Schaumann,Tony W. H. Wong*

Main category: math.NT

TL;DR: 本文研究了覆盖系统的一个变体问题，允许一个奇数模数重复出现，其余模数为大于1的互异奇数。


<details>
  <summary>Details</summary>
Motivation: 自1950年Erd\H{o}s提出覆盖系统概念以来，模数条件的研究成为核心问题。本研究针对著名的奇数覆盖问题，探索其变体形式。

Method: 通过允许一个奇数模数重复出现，同时保持其他模数为大于1的互异奇数，构建新型覆盖系统。

Result: 该变体问题拓展了传统奇数覆盖系统的研究范畴，为模数限制条件提供了新的可能性。

Conclusion: 这种允许单模数重复的变体形式，为覆盖系统理论开辟了新的研究方向，对解决原始奇数覆盖问题具有启发意义。

Abstract: Erd\H{o}s first introduced the idea of covering systems in 1950. Since then,
much of the work in this area has concentrated on identifying covering systems
that meet specific conditions on their moduli. Among the central open problems
in this field is the well-known odd covering problem. In this paper, we
investigate a variant of that problem, where one odd integer is permitted to
appear multiple times as a modulus in the covering system, while all remaining
moduli are distinct odd integers greater than 1.

</details>


### [21] [The structure of the double discriminant](https://arxiv.org/abs/2507.16138)
*Theresa C. Anderson,Adam Bertelli,Evan M. O'Dorney*

Main category: math.NT

TL;DR: 研究多项式$f(x) = \sum_{i=0}^n a_i x^i$的双判别式$DD_{n,k}$，提出其分解形式的猜想并在$k=0$时证明，同时探讨其分解中的大整数常数。


<details>
  <summary>Details</summary>
Motivation: 双判别式$DD_{n,k}$在van der Waerden--Bhargava定理的证明中出现，研究其分解形式有助于理解多项式的判别性质。

Method: 通过代数方法分析双判别式$DD_{n,k}$的结构，提出其分解为平方、立方及可能的一次单项式的猜想，并在$k=0$时给出证明。

Result: 证明了当$k=0$时，$DD_{n,k}$可分解为平方、立方及可能的一次单项式的乘积，并研究了分解中的大整数常数的性质。

Conclusion: 双判别式$DD_{n,k}$的分解形式猜想在$k=0$时成立，其分解中的大整数常数通常较大且光滑，为后续研究提供了方向。

Abstract: For a polynomial $f(x) = \sum_{i=0}^n a_i x^i$, we study the double
discriminant $DD_{n,k} = \operatorname{disc}_{a_k} \operatorname{disc}_x f(x)$,
which appears in the proof of the van der Waerden--Bhargava theorem. We
conjecture that $DD_{n,k}$ is the product of a square, a cube, and possibly a
linear monomial and we prove this when $k=0$. We also investigate the
(typically large and smooth) outlying integer constant in the factorization of
$DD_{n,k}$.

</details>


### [22] [An elementary proof of Newman's eta-quotient theorem](https://arxiv.org/abs/2507.16225)
*David Savitt*

Main category: math.NT

TL;DR: 本文通过教学实践，为高中生解释了Newman关于Dedekind eta函数商模性的定理证明，避免了使用Dedekind和的初等方法。


<details>
  <summary>Details</summary>
Motivation: 研究Dedekind eta函数商的模性，为高中生提供易于理解的证明方法，避免复杂的数学工具如Dedekind和。

Method: 利用Gamma_1(N)群的上三角和下三角子群及同余子群的生成性质，结合eta函数的乘子系统的一个简单恒等式，证明模性。

Result: 证明了Newman定理，即形式为$\prod_{0 < m | N} \eta(mz)^{r_m}$的函数在特定条件下是水平N的（弱）全纯模形式。

Conclusion: 通过初等方法成功验证了eta函数商的模性定理，为数学教育提供了新的教学案例。

Abstract: Let eta(z) be the Dedekind eta function. Newman studied the modularity of
eta-quotients, giving necessary and sufficient conditions for a function of the
form \prod_{0 < m | N} eta(mz)^{r_m} to be a (weakly) holomorphic modular form
of level N. We explain a proof of Newman's theorem, developed while teaching a
class for talented high school students at Canada/USA Mathcamp. The key
observation is that although Gamma_1(N) is not generated by its upper
triangular and lower triangular subgroups, it is generated by those subgroups
together with any congruence subgroup. Modularity with respect to some
congruence subgroup is established using one simple identity involving the
multiplier system of eta(z), whose proof is elementary in the sense that it
avoids the use of Dedekind sums.

</details>


### [23] [The SOS Rank of Biquadratic Forms](https://arxiv.org/abs/2507.16399)
*Liqun Qi,Chunfeng Cui,Yi Xu*

Main category: math.NT

TL;DR: 本文研究了$m \times n$正半定双二次形式的平方和(sos)表示问题，改进了Calderón的结果，并探讨了退化三方四次形式的性质。


<details>
  <summary>Details</summary>
Motivation: 1973年Calderón证明了$m \times 2$正半定双二次形式可表示为${3m(m+1) \over 2}$个二次形式的平方和。近期研究将$2 \times 2$情形的表示数降至3个，但$m \geq 3$情形仍待探索。

Method: 通过引入退化三方四次形式，证明了具有非平凡零点的$m \times n$正半定双二次形式可表示为$(m-1) \times (n-1) \times 1$退化形式，并将问题转化为研究$(m-1) \times 1 \times 1$退化形式的sos表示。

Result: 证明了$m \times 2$正定双二次形式可表示为一个二次形式的平方与$(m-1) \times 1 \times 1$退化形式的和，且后者至少有两个非平凡零点。特别地，$2 \times 1 \times 1$退化形式的判别式可表示为三个三次形式的平方和。

Conclusion: 该研究将$m \times 2$双二次形式的sos表示问题转化为更低维的退化三方四次形式问题，为后续研究提供了新思路。

Abstract: In 1973, Calder\'{o}n proved that an $m \times 2$ positive semidefinite (psd)
biquadratic form can always be expressed as the sum of squares (sos) of
${3m(m+1) \over 2}$ quadratic forms. Very recently, by applying Hilbert's
theorem, we proved that a $2 \times 2$ psd biquadratic form can always be
expressed as the sum of squares of three quadratic forms. This improved
Calder\'{o}n's result for $m=2$, and left the sos rank problem of $m \times 2$
biquadratic forms for $m \ge 3$ to further exploration. In this paper, we show
that an $m \times n$ psd biquadratic form with a nontrivial zero {can} be
expressed as an $(m-1) \times (n-1) \times 1$ degenerated tripartite quartic
form. Furthermore, we show that an $m \times 2$ positive definite (pd)
biquadratic form can be expressed as the sum of a square of a quadratic form,
and an $(m-1) \times 1 \times 1$ degenerated tripartite quartic form. Thus, the
sos rank problem of $m \times 2$ psd biquadratic forms is reduced to the sos
rank problem of an $(m-1) \times 1 \times 1$ degenerated tripartite quartic
forms. We then show that an $(m-1) \times 1 \times 1$ degenerated tripartite
quartic form has at least two nontrivial zeros, and the discriminent of a $2
\times 1 \times 1$ degenerated tripartite quartic form can be expressed as the
sum of the square of three cubic forms.

</details>


### [24] [Simultaneous multiplicative rational approximation to a real and a $p$-adic numbers](https://arxiv.org/abs/2507.16503)
*Yann Bugeaud,Bernard de Mathan*

Main category: math.NT

TL;DR: 本文提供了满足Einsiedler和Kleinbock猜想的新实数与$p$-进数对示例。


<details>
  <summary>Details</summary>
Motivation: 研究实数与$p$-进数对在有理数同时乘法逼近下的性质，验证2007年提出的猜想。

Method: 通过构造新的实数与$p$-进数对，分析其满足猜想条件的具体形式。

Result: 成功找到多个满足猜想条件的实数与$p$-进数组合，为猜想提供了新的证据。

Conclusion: 新示例支持了Einsiedler和Kleinbock关于同时乘法逼近的猜想，拓展了该领域的研究范围。

Abstract: We give new examples of pairs composed of a real and a $p$-adic numbers that
satisfy a conjecture on simultaneous multiplicative approximation by rational
numbers formulated by Einsiedler and Kleinbock in 2007.

</details>


### [25] [Hausdorff dimension of the graph of the error-sum function of continued fractions](https://arxiv.org/abs/2507.16536)
*Min Woong Ahn*

Main category: math.NT

TL;DR: 研究无权重误差和函数$\mathcal{E}(x)$的图像豪斯多夫维数，证明其精确值为1，并重新推导相对误差和函数$P(x)$的豪斯多夫维数上界。


<details>
  <summary>Details</summary>
Motivation: 探讨连分数展开中误差和函数的几何特性，特别是其图像的豪斯多夫维数，以深化对实数连分数表示的理解。

Method: 采用数论方法，包括M\"obius反演、互质收敛分母求和，以及通过连分数递推关系导出的精确上界。

Result: 证明了$\mathcal{E}(x)$图像的豪斯多夫维数恰好为1，并重新验证了$P(x)$图像的豪斯多夫维数上界为3/2。

Conclusion: 该研究不仅精确刻画了误差和函数的几何性质，还为连分数理论中的误差分析提供了新的工具和视角。

Abstract: We study the unweighted error-sum function $\mathcal{E}(x) \coloneqq \sum_{n
\geq 0} ( x- p_n(x)/q_n(x) )$, where $p_n(x)/q_n(x)$ is the $n$th convergent of
the continued fraction expansion of $x \in \mathbb{R}$. We prove that the
Hausdorff dimension of the graph of $\mathcal{E}$ is exactly $1$. Our proof is
number-theoretic in nature and involves M\"obius inversion, summation over
coprime convergent denominators, and precise upper bounds derived via continued
fraction recurrence relations. As a supplementary result, we rederive the known
upper bound of $3/2$ for the Hausdorff dimension of the graph of the relative
error-sum function $P(x) \coloneqq \sum_{n \geq 0} (q_n(x)x-p_n(x))$.

</details>


### [26] [Sign-patterns of Certain Infinite Products](https://arxiv.org/abs/2507.16644)
*Zeyu Huang,Timothy Huber,James McLaughlin,Pengjun Wang,Yan Xu,Dongxi Ye*

Main category: math.NT

TL;DR: 本文通过theta函数的展开和五重积的一般分解公式，确定了某些eta商的傅里叶系数符号，并扩展了Bringmann等人的猜想。


<details>
  <summary>Details</summary>
Motivation: 研究某些eta商的傅里叶系数符号模式，特别是形式为$\frac{(q^i;q^i)_{\infty}}{(q^p;q^p)_{\infty}}$的商，以解决和扩展Bringmann等人提出的猜想。

Method: 使用theta函数的展开和五重积的一般分解公式，分析eta商的系数符号模式。

Result: 给出了整数$i > 1$和素数$p > 3$时$\frac{(q^i;q^i)_{\infty}}{(q^p;q^p)_{\infty}}$的系数符号模式，并扩展了Bringmann等人关于$(q^2;q^2)_{\infty}(q^5;q^5)_{\infty}^{-1}$系数的猜想。

Conclusion: 本研究不仅解决了Bringmann等人的多个猜想，还为更广泛的eta商类提供了符号分布的分析。

Abstract: The signs of Fourier coefficients of certain eta quotients are determined by
dissecting expansions for theta functions and by applying a general dissection
formula for certain classes of quintuple products. A characterization is given
for the coefficient sign patterns for \[
\frac{(q^i;q^i)_{\infty}}{(q^p;q^p)_{\infty}} \] for integers \( i > 1 \) and
primes \( p > 3 \). The sign analysis for this quotient addresses and extends a
conjecture of Bringmann et al. for the coefficients of \(
(q^2;q^2)_{\infty}(q^5;q^5)_{\infty}^{-1} \). The sign distribution for
additional classes of eta quotients is considered. This addresses multiple
conjectures posed by Bringmann et al.

</details>


### [27] [A Dedekind-Rademacher cocycle for Bianchi groups](https://arxiv.org/abs/2507.16671)
*Kim Klinger-Logan,Kalani Thalagoda,Tian An Wong*

Main category: math.NT

TL;DR: 本文推广了Dedekind-Rademacher上循环到$\mathrm{SL}_2(\mathbb C)$的同余子群，并证明了其参数化$L$-值族的整数性。


<details>
  <summary>Details</summary>
Motivation: 研究Dedekind-Rademacher上循环在同余子群上的推广，以探索其在$L$-值参数化中的应用。

Method: 构建$\mathrm{SL}_2(\mathbb C)$同余子群上的广义Dedekind-Rademacher上循环，并分析其基本性质。

Result: 证明了该上循环参数化了一族$L$-值，并验证了这些值的整数性。

Conclusion: 通过推广Dedekind-Rademacher上循环，为同余子群上的$L$-值研究提供了新的工具和理论支持。

Abstract: We construct a generalization of the Dedekind-Rademacher cocycle to
congruence subgroups of $\mathrm{SL}_2(\mathbb C)$, and derive some of its
basic properties. In particular, we show that it parametrizes a family of
$L$-values and prove the integrality of these values.

</details>


### [28] [Overpartitions with parts separated by parity](https://arxiv.org/abs/2507.16769)
*Kathrin Bringmann,Catherine Cossaboom,William Craig*

Main category: math.NT

TL;DR: 本文通过两种方式将Andrews的奇偶分拆推广到超分拆，研究了16个按奇偶性分离部分的超分拆族的生成函数，并证明了这些函数与模形式、$q$-超几何级数和模拟模形式相关的$q$-级数恒等式。


<details>
  <summary>Details</summary>
Motivation: 研究目的是将Andrews的奇偶分拆理论扩展到超分拆领域，探索新的生成函数及其数学性质。

Method: 通过构造16个按奇偶性分离部分的超分拆族，分析其生成函数，并运用$q$-级数理论建立恒等式。

Result: 证明了这些生成函数与模形式、$q$-超几何级数$\sum_{n=0}^{\infty}\frac{(a;q)_n}{(q;q)_n}z^n$和模拟模形式之间存在多种恒等关系。

Conclusion: 该研究成功扩展了奇偶分拆理论，为超分拆与模形式等领域的联系提供了新的理论工具和恒等式体系。

Abstract: In this paper, we generalize Andrews' partitions separated by parity to
overpartitions in two ways. We investigate the generating functions for 16
overpartition families whose parts are separated by parity, and we prove
various $q$-series identities for these functions. These identities include
relations to modular forms, $q$-hypergeometric series, and mock modular forms.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [29] [Distribution of roots of Eulerian polynomials](https://arxiv.org/abs/2507.15908)
*Paul Melotti*

Main category: math.CO

TL;DR: 证明了欧拉多项式根的实证测度收敛于对数柯西分布，通过分析相关多项式根的矩收敛性并利用N\"orlund数表达渐近矩。


<details>
  <summary>Details</summary>
Motivation: 研究欧拉多项式根的分布特性及其收敛行为，探索相关多项式矩的渐近性质。

Method: 分析欧拉多项式根的实证测度，证明相关多项式根的矩不仅收敛且最终恒定，并利用N\"orlund数表达渐近矩。

Result: 欧拉多项式根的实证测度收敛于对数柯西分布，相关多项式根的矩具有恒定渐近值。

Conclusion: 欧拉多项式根的分布收敛性及其矩的渐近性质为相关数学领域提供了新的理论支持。

Abstract: We show that the empirical measures of roots of Eulerian polynomials converge
to a certain log-Cauchy distribution. To do so, we show that the moments of the
roots of a related family of polynomials not only converge, but are in fact
ultimately constant. These asymptotic moments are expressed in terms of
N\"orlund's numbers.

</details>


### [30] [Algorithmic methods of finite discrete structures. Topological graph drawing (part IV)](https://arxiv.org/abs/2507.16759)
*Sergey Kurapov,Maxim Davidovsky*

Main category: math.CO

TL;DR: 本章介绍基于G. Ringel顶点旋转理论的数学模型，用于生成不可分非平面图的拓扑绘制，通过诱导循环系统和虚顶点定位方法实现特定厚度的绘图。


<details>
  <summary>Details</summary>
Motivation: 研究旨在为非可分非平面图开发有效的拓扑绘制方法，利用现有理论解决复杂图形的可视化问题。

Method: 采用G. Ringel的顶点旋转理论，通过诱导循环系统生成拓扑绘图，并提出了在平面上通过连接交点定位虚顶点的方法，以最大平面子图的拓扑绘制为基础。

Result: 提出的方法能够生成具有特定厚度的非可分非平面图的拓扑绘制，并通过虚顶点定位优化了图形的空间布局。

Conclusion: 该数学模型为复杂非平面图的拓扑绘制提供了有效工具，扩展了顶点旋转理论在实际应用中的潜力。

Abstract: The chapter presents mathematical models intended for creating a topological
drawing of a non-separable non-planar graph based on the methods of G. Ringel's
vertex rotation theory. The induced system of cycles generates a topological
drawing of a certain thickness. A method for determining the location of
imaginary vertices by finding the intersection of connections on a plane is
presented. A topological drawing of a maximum planar subgraph is used as a
basis.

</details>


### [31] [On the reconstruction of trees from their chromatic symmetric functions](https://arxiv.org/abs/2507.15986)
*Michael Gonzalez,Rosa Orellana,Mario Tomba*

Main category: math.CO

TL;DR: 本文研究了Stanley的色对称函数（CSF）在星基下的树表示，利用删除-近收缩（DNC）算法计算星基中的系数，确定了字典序最小的分区及其系数公式，并提出了直径小于六的树的重构算法。


<details>
  <summary>Details</summary>
Motivation: 研究Stanley色对称函数在星基下的树表示，旨在揭示树的结构特性与色对称函数系数之间的关系，为树的重构提供理论基础。

Method: 采用删除-近收缩（DNC）算法计算色对称函数在星基中的系数，并通过分析树的特性推导出相关公式。

Result: 确定了色对称函数中字典序最小的分区及其系数公式，并提出了直径小于六的树的重构算法。

Conclusion: 本研究不仅揭示了树的特性与色对称函数系数之间的关联，还为树的重构提供了有效算法，为相关领域的研究提供了新的工具和方法。

Abstract: We study Stanley's chromatic symmetric function (CSF) for trees when
expressed in the star basis. We use the deletion-near-contraction (DNC)
algorithm to compute coefficients that occur in the CSF in the star basis. In
particular, one of our main results determines the smallest partition in
lexicographic order that occurs as an indexing partition in the CSF, and we
also give a formula for its coefficient. In addition to describing properties
of trees encoded in the coefficients of the star basis, we give an algorithm
for reconstructing trees of diameter less than six.

</details>


### [32] [New Steiner systems $S(2,6,v)$ with block length 6](https://arxiv.org/abs/2507.16009)
*Taras Banakh,Ivan Hetman,Alex Ravsky*

Main category: math.CO

TL;DR: 本文收集并枚举了多种$S(2,6,v)$ Steiner系统，发现了两种新的$1$-旋转设计，并列举了新的Steiner系统$S(2,6,96)$、$S(2,6,106)$和$S(2,6,111)$。


<details>
  <summary>Details</summary>
Motivation: 研究$S(2,k,v)$ Steiner系统的构造和枚举，特别是$k=6$的情况，以填补现有知识的空白。

Method: 通过特定的构造方法，枚举和分析$S(2,6,v)$ Steiner系统，并探索$1$-旋转设计的性质。

Result: 发现了两种新的$1$-旋转设计，分别对应于群$SL(2,5)$和$((\mathbb Z_3 \times \mathbb Z_3) \rtimes \mathbb Z_3) \times \mathbb Z_5$，并列举了新的Steiner系统$S(2,6,96)$、$S(2,6,106)$和$S(2,6,111)$。

Conclusion: 本研究扩展了$S(2,6,v)$ Steiner系统的知识库，特别是通过发现新的$1$-旋转设计和列举新的系统，为组合设计理论提供了新的实例。

Abstract: In this paper various Steiner systems $S(2,k,v)$ for $k = 6$ are collected
and enumerated for specific constructions. In particular, two earlier unknown
types of $1$-rotational designs are found for the groups $SL(2,5)$ and
$((\mathbb Z_3 \times \mathbb Z_3) \rtimes \mathbb Z_3) \times \mathbb Z_5$.
Also new Steiner systems $S(2,6,96), S(2,6,106), S(2,6,111)$ are listed.

</details>


### [33] [Metric Dimension of a Direct Product of Three Complete Graphs: The Middle Cone Family](https://arxiv.org/abs/2507.16169)
*Briana Foster-Greenwood,Christine Uhl*

Main category: math.CO

TL;DR: 本文研究了三个不同阶完全图直积的度量维数，针对中锥结构族确定了度量维数和定位-全控制数，并给出了最小解析集的显式描述。通过定义基本地标系统及其关联的3边着色超图，验证了解析集的有效性。


<details>
  <summary>Details</summary>
Motivation: 前期工作已解决三个同构完全图直积的度量维数问题，本文转向研究不同阶完全图直积的情况，重点关注中锥结构族的度量性质。

Method: 定义基本地标系统，证明其成为解析集的充要条件是关联的3边着色超图避免三类禁止子图，该方法推广了同构因子情形的技术。

Result: 针对中锥衍生的三完全图直积族，精确计算了度量维数和定位-全控制数，并显式构造了最小解析集。

Conclusion: 通过超图理论将解析集验证转化为组合禁止结构问题，该框架可推广至更一般的图直积情形，为后续研究提供新工具。

Abstract: In previous work, we determined the metric dimension for a direct product of
three isomorphic complete graphs. Turning to the case where the complete graphs
may have different orders, there are three families we refer to as the upper,
lower, and middle cones. We determine the metric dimension and
location-total-domination number for a family of direct products of three
complete graphs stemming from the middle cone. We explicitly describe minimum
resolving sets. To verify the sets are resolving, we define a basic landmark
system and show it will be a resolving set if and only if its associated
3-edge-colored hypergraph avoids three types of forbidden subgraphs. This
generalizes the technique used for three isomorphic factors.

</details>


### [34] [Valuated Delta Matroids and Principal Minors of Hermitian matrices](https://arxiv.org/abs/2507.16275)
*Nathan Cheung,Tracy Chin,Gaku Liu,Cynthia Vinzant*

Main category: math.CO

TL;DR: 本文提出了估值$\Delta$-拟阵，这是拟阵理论中估值拟阵和$\Delta$-拟阵的自然推广，并展示了其在Hermitian矩阵主余子式估值中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究估值$\Delta$-拟阵是为了将估值拟阵和$\Delta$-拟阵的理论统一起来，探索更广泛的拟阵结构及其在矩阵表示中的应用。

Method: 通过类比普通估值拟阵的性质，构建并分析估值$\Delta$-拟阵的理论框架，并探讨其在Hermitian矩阵主余子式中的表示。

Result: 证明了估值$\Delta$-拟阵具有与普通估值拟阵类似的良好性质，并且可以在值域上的Hermitian矩阵的主余子式中自然出现。

Conclusion: 估值$\Delta$-拟阵不仅推广了现有的拟阵理论，还为矩阵表示提供了新的视角，具有潜在的理论和应用价值。

Abstract: In this paper we introduce valuated $\Delta$-matroids, a natural
generalization of two objects of study in matroid theory: valuated matroids and
$\Delta$-matroids. We show that these objects exhibit nice properties analogous
to ordinary valuated matroids. We also show that these objects arise as the
valuations of principal minors of a Hermitian matrix over a valued field,
generalizing other forms of $\Delta$-matroid representability.

</details>


### [35] [On distinguishing coloring and some variants of proper coloring of graphs derived from subdivision operations](https://arxiv.org/abs/2507.16301)
*Amitayu Banerjee,Alexa Gopaulsingh,Zalán Molnár*

Main category: math.CO

TL;DR: 该论文研究了图G的中图M(G)和中心图C(G)的自同构群Aut(G)、Aut(C(G))和Aut(M(G))的同构性，并应用这些结果改进了C(G)和M(G)的区分数和区分指标的上界。此外，还探讨了C(G)和S(G)的全区分色数，利用拉丁方验证了正则图中心图的AVD-全着色猜想，并给出了C(G)和C(T)的全支配色数的新界限。


<details>
  <summary>Details</summary>
Motivation: 研究图的自同构群及其衍生图（中图和中心图）的性质，旨在改进图的区分性参数（如区分数、区分指标）的上界，并解决关于AVD-全着色猜想和全支配色数的开放性问题。

Method: 通过分析图G的中图M(G)和中心图C(G)的构造及其自同构群的结构，证明了Aut(G)、Aut(C(G))和Aut(M(G))的同构性。利用Kalinowski等人的算法改进区分性参数的上界，并通过拉丁方验证AVD-全着色猜想。

Result: 当图G的阶数至少为4时，Aut(G)、Aut(C(G))和Aut(M(G))同构。改进了C(G)和M(G)的区分数和区分指标的上界。验证了正则图中心图的AVD-全着色猜想，并给出了C(G)和C(T)的全支配色数的新界限。

Conclusion: 该研究不仅揭示了图的自同构群与其衍生图之间的同构关系，还为图的区分性参数和着色问题提供了新的理论工具和结果，部分解决了相关领域的开放性问题。

Abstract: Let G be a simple, finite, connected, and undirected graph, and T be a finite
tree. The middle graph M(G) of G is obtained from the subdivision graph S(G)
after joining pairs of subdivided vertices that lie on adjacent edges of G and
the central graph C(G) of G is obtained from S(G) after joining all
non-adjacent vertices of G.
  We show that if the order of G is at least 4, then Aut(G), Aut(C(G)), and
Aut(M(G)) are isomorphic (as abstract groups) and apply these results to obtain
new sharp upper bounds of the distinguishing number and the distinguishing
index of C(G) and M(G) inspired by an algorithm due to Kalinowski, Pilsniak,
and Wozniak from 2016.
  Furthermore, we study the total distinguishing chromatic number of C(G) and
S(G), use Latin squares to verify the AVD-total coloring conjecture for central
graphs of regular graphs and some other classes of graphs (which is a partial
progress towards answering an open question of Panda, Verma, and Keerti from
2020), and obtain new bounds of the total dominator chromatic number of C(G)
and C(T).

</details>


### [36] [$s$-Shunt Intersection Graph of a Graph](https://arxiv.org/abs/2507.16309)
*Vinny Susan Prebhath,Sudev Naduvath*

Main category: math.CO

TL;DR: 本文研究了一种称为$s$-shunt交集图的新型交集图，该图由给定图的$s$-弧生成。


<details>
  <summary>Details</summary>
Motivation: 不同类型的交集图根据顶点集的性质被广泛研究，本文旨在探索由图的$s$-弧生成的特定类型交集图。

Method: 通过将给定图的$s$-弧作为顶点集，构建$s$-shunt交集图，其中两个顶点相邻当且仅当对应$s$-弧的交集非空。

Result: 研究初步建立了$s$-shunt交集图的基本性质及其与原始图结构的关系。

Conclusion: 本文为$s$-shunt交集图的研究奠定了基础，未来可进一步探索其图论性质和应用。

Abstract: The intersection graph of a family of sets $\{S_{1},S_{2},\ldots,S_{n}\}$ is
a graph whose vertex set is $\{S_{1},S_{2},\ldots,S_{n}\}$ and two distinct
vertices are adjacent if the intersection of the corresponding sets is
non-empty. Different types of intersection graphs have been studied depending
on the nature of sets taken as the vertex set. A study on a particular type of
intersection graph called $s$-shunt intersection graph, generated from the
$s$-arcs of a given graph is initiated in this paper.

</details>


### [37] [Planar Turán number of disjoint union of $C_3$ and $C_5$](https://arxiv.org/abs/2507.16351)
*Luyi Li,Ping Li,Guiying Yan,Qiang Zhou*

Main category: math.CO

TL;DR: 本文确定了平面图在避免$C_3 \cup C_5$结构时的最大边数$ex_{\mathcal{P}}(n,C_3\cup C_5)=\lfloor\frac{8n-13}{3}\rfloor$，并在$n$足够大时刻画了极值图。


<details>
  <summary>Details</summary>
Motivation: 研究平面图中避免特定子图结构的最大边数（平面Turán数），特别是当子图为两个不相交的循环$C_3 \cup C_5$时。

Method: 通过组合数学和图论方法，分析并计算了避免$C_3 \cup C_5$的平面图的最大边数，并研究了极值图的性质。

Result: 确定了$ex_{\mathcal{P}}(n,C_3\cup C_5)=\lfloor\frac{8n-13}{3}\rfloor$，并在$n$足够大时完全刻画了极值图的结构。

Conclusion: 该研究填补了平面Turán数在$C_3 \cup C_5$情况下的空白，为相关极值图论问题提供了新的理论结果。

Abstract: The planar Tur\'an number of $H$, denoted by $ex_{\mathcal{P}}(n,H)$, is the
maximum number of edges in an $n$-vertex $H$-free planar graph. The planar
Tur\'an number of $k\geq 3$ vertex-disjoint union of cycles is the trivial
value $3n-6$. Let $C_{\ell}$ denote the cycle of length $\ell$ and
$C_{\ell}\cup C_t$ denote the union of disjoint cycles $C_{\ell}$ and $C_t$.
The planar Tur\'an number $ex_{\mathcal{P}}(n,H)$ is known if $H=C_{\ell}\cup
C_k$, where $\ell,k\in \{3,4\}$. In this paper, we determine the value
$ex_{\mathcal{P}}(n,C_3\cup C_5)=\lfloor\frac{8n-13}{3}\rfloor$ and
characterize the extremal graphs when $n$ is sufficiently large.

</details>


### [38] [Combinatorial Laplacians and relative Homology of complex pairs](https://arxiv.org/abs/2507.16381)
*Xiongfeng Zhan,Xueyi Huang,Lu Lu*

Main category: math.CO

TL;DR: 本文研究了单纯复形对$(X, A)$的组合拉普拉斯算子，建立了相对版本的矩阵-树定理，推广了前人的结果，并给出了谱间隙的下界估计。


<details>
  <summary>Details</summary>
Motivation: 作为Hodge拉普拉斯算子的离散化，单纯复形的组合拉普拉斯算子受到广泛关注。本文旨在研究复形对的组合拉普拉斯算子及其与相对同调的关系。

Method: 通过建立复形对的相对矩阵-树定理，推广了Duval等人(2009)和图对的Dirichlet特征值结果(Chung, 1996)，并推导了谱间隙的下界。

Result: 得到了复形对谱间隙的多个下界，并刻画了一个尖锐下界的等式成立条件。作为副产品，给出了相对同调消失的充分条件。

Conclusion: 研究表明，复形对的组合拉普拉斯算子与相对同调密切相关，所建立的理论框架统一并推广了多个已有结果。

Abstract: As a discretization of the Hodge Laplacian, the combinatorial Laplacian of
simplicial complexes has garnered significant attention. In this paper, we
study combinatorial Laplacians for complex pairs $(X, A)$, where $A$ is a
subcomplex of a simplicial complex $X$. We establish a relative version of the
matrix-tree theorem for complex pairs, which generalizes both the matrix-tree
theorem for simplicial complexes proved by Duval, Klivans, and Martin (2009)
and the result for Dirichlet eigenvalues of graph pairs by Chung (1996).
Furthermore, we derive several lower bounds for the spectral gaps of complex
pairs and characterize the equality case for one sharp lower bound. As
by-products, we obtain sufficient conditions for the vanishing of relative
homology. Our results demonstrate that the combinatorial Laplacians for complex
pairs are closely related to relative homology.

</details>


### [39] [$p$-th order generalized Fibonacci cubes and maximal cubes in Fibonacci $p$-cubes](https://arxiv.org/abs/2507.16387)
*Michel Mollard*

Main category: math.CO

TL;DR: 本文研究了p阶斐波那契立方体$\Gamma^{(p)}_n$的数学性质，包括其与整数组合的联系、枚举特性以及生成函数，并探讨了其在斐波那契p立方体中的最大诱导超立方体。


<details>
  <summary>Details</summary>
Motivation: 研究p阶斐波那契立方体$\Gamma^{(p)}_n$的性质，以扩展对斐波那契立方体$\Gamma_n$的理解，并探索其与整数组合及超立方体的关系。

Method: 通过分析$\Gamma^{(p)}_n$的顶点与不含p个连续1的字符串的对应关系，以及其与整数组合的联系，研究了其阶数、大小和立方多项式等枚举性质。

Result: 展示了$\Gamma^{(p)}_n$的生成函数和立方多项式，并发现其表达式与斐波那契立方体类似，其中p项系数取代了二项式系数。此外，揭示了斐波那契p立方体中最大诱导超立方体与$(p+1)$阶斐波那契立方体顶点的联系。

Conclusion: 研究不仅扩展了对斐波那契立方体的理解，还为p阶斐波那契立方体的数学性质及其在超立方体中的应用提供了新的见解。

Abstract: The Fibonacci cube $\Gamma_n$ is the subgraph of the hypercube $Q_n$ induced
by vertices with no consecutive 1s. We study a one parameter generalization,
p-th order Fibonacci cubes $\Gamma^{(p)}_n$, which are subgraphs of $Q_n$
induced by strings without p consecutive 1s. We show the link between vertices
of $\Gamma^{(p)}_n$ and compositions of integers with parts in $\{1, 2, \ldots
, p\}$. Among other eumerative properties, we study the order, size and cube
polynomial of $\Gamma^{(p)}_n$ as well as their generating functions. Many of
the given expressions are similar to those for Fibonacci cubes, where the
$p$-nomial coefficients play the role of binomial coefficients. We also show
that maximal induced hypercubes in Fibonacci $p$-cubes $\Gamma^p_n$ , another
generalization of Fibonacci cubes, are connected to vertices of $(p + 1)$-th
order Fibonacci cubes. We use this link to determine the maximal cube
polynomial of Fibonacci $p$-cubes.

</details>


### [40] [Hilbert basis in the face-centered cubic grid -- mathematical proofs](https://arxiv.org/abs/2507.16464)
*Bela Vizvari,Gergely Kovacs,Benedek Nagy,Necet Deniz Turgay*

Main category: math.CO

TL;DR: 论文研究了面心立方(FCC)网格中基本循环的结构，发现其属于11种类型，并讨论了各类别中的元素数量。


<details>
  <summary>Details</summary>
Motivation: Hilbert基是描述多面体锥整数点结构的基础，而FCC网格是三维空间最密集的堆积方式之一，研究其循环结构具有理论意义。

Method: 结合几何、组合、代数和运筹学方法，分析了FCC网格中满足非负整数向量约束的循环结构。

Result: 证明了FCC网格的基本循环可分为11种类型，并量化了各类别中的元素数量。

Conclusion: 该研究通过多学科方法系统揭示了FCC网格的循环结构特征，为相关数学和物理问题提供了理论基础。

Abstract: The Hilbert basis is fundamental in describing the structure of the integer
points of a polyhedral cone. The face-centered cubic grid is one of the densest
packing of the 3-dimensional space. The cycles of a grid satisfy the constraint
set of a pointed, polyhedral cone which contains only non-negative integer
vectors. The Hilbert basis of a grid gives the structure of the basic cycles in
the grid. It is shown in this paper that the basic cycles of the FCC grid
belong to 11 types. It is also discussed that how many elements are contained
in the individual types. The proofs of the paper use geometric, combinatorial,
algebraic, and operations research methods.

</details>


### [41] [On the representation number of grid graphs and cylindric grid graphs](https://arxiv.org/abs/2507.16469)
*Nawaf Shafi Alshammari,Sergey Kitaev,Artem Pyatkin*

Main category: math.CO

TL;DR: 本文研究了图的表示数，特别是网格图和圆柱网格图的表示数，并提出了关于环面网格图的有趣猜想。


<details>
  <summary>Details</summary>
Motivation: 研究图的表示数有助于理解图的结构和性质，扩展已知结果到更广泛的图类。

Method: 通过分析$m \times n$网格图和$m \times n$圆柱网格图的结构，确定其表示数。

Result: 结果表明，对于$m \geq 3$和$n \geq 3$的网格图，以及$m \geq 2$和$n \geq 3$的圆柱网格图，表示数为3。

Conclusion: 本文扩展了图的表示数研究，并提出了关于环面网格图表示数的猜想，为未来研究提供了方向。

Abstract: The representation number of a graph is the minimum number of copies of each
vertex required to represent the graph as a word, such that the letters
corresponding to vertices $x$ and $y$ alternate if and only if $xy$ is an edge
in the graph. It is known that path graphs, circle graphs, and ladder graphs
have representation number 2, while prism graphs have representation number 3.
  In this paper, we extend these results by showing that generalizations of the
aforementioned graphs -- namely, the $m \times n$ grid graphs and $m \times n$
cylindrical grid graphs -- have representation number $3$ for $m \geq 3$ and $m
\geq 2$, respectively, and $n\geq 3$. Furthermore, we discuss toroidal grid
graphs in the context of word-representability, which leads to an interesting
conjecture.

</details>


### [42] [Integer sequences with conjectured relation with certain graph parameters of the family of linear Jaco graphs](https://arxiv.org/abs/2507.16500)
*Johan Kok*

Main category: math.CO

TL;DR: 该实验研究探讨了整数序列与线性Jaco图族$J_n(x)$某些图参数之间的猜想关系，发现黄金分割类地板函数在分析图结构特性中起关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示线性Jaco图族$J_n(x)$的结构特性与整数序列之间可能存在的数学关系，特别是黄金分割类项的潜在影响。

Method: 采用实验性方法提出猜想，尽管方法本身简单，但作者认为证明或反驳这些猜想可能具有挑战性。

Result: 实验结果表明，黄金分割类地板函数项$\lfloor \phi n \rfloor$在线性Jaco图的结构分析中扮演重要角色。

Conclusion: 该研究提出了关于线性Jaco图与整数序列关系的新猜想，为未来图论与数论交叉研究提供了潜在方向。

Abstract: This experimental study presents some interesting conjectured relations
between some integer sequences and certain graph parameters of the family of
linear Jaco graphs $J_n(x)$ where $n = 1,2,3,\dots$. It appears that
$\textit{Golden ratio}$-like floor function terms play an important role in the
analysis of the graph structural properties of the family of linear Jaco
graphs. The experimental methodology to obtain the conjectures is indeed
trivial. However, it is the author's view that the proofs or disproofs of the
conjectures may be challenging.

</details>


### [43] [On a conjecture concerning the extensions of a reciprocal matrix](https://arxiv.org/abs/2507.16593)
*Rosário Fernandes*

Main category: math.CO

TL;DR: 本文研究了互反矩阵的Perron特征向量的效率问题，证明了关于扩展矩阵的强连通性猜想，并应用于特定扰动矩阵的效率分析。


<details>
  <summary>Details</summary>
Motivation: 研究互反矩阵$A$及其Perron特征向量$w$的效率，基于Pareto最优决策原则，探讨与之相关的有向图的强连通性。

Method: 通过分析互反矩阵$B$（$A$的扩展）及其Perron特征向量相关的有向图，证明不存在具有源的扩展矩阵。

Result: 证明了Furtado和Johnson的猜想：不存在其相关有向图具有源的扩展矩阵。对于$n\geq 5$且通过扰动四个非对角线条目得到的矩阵，描述了使Perron特征向量始终高效的条件。

Conclusion: 研究结果为互反矩阵Perron特征向量的效率提供了理论支持，特别是在特定扰动条件下，明确了高效特征向量存在的参数关系。

Abstract: Let $A$ be a reciprocal matrix of order $n$ and $w$ be its Perron
eigenvector. To infer the efficiency of $w$ for $A$, based on the principle of
Pareto optimal decisions, we study the strong connectivity of a certain digraph
associated with $A$ and $w$. A reciprocal matrix $B$ of order $n+1$ is an
extension of $A$ if the matrix $A$ is obtained from $B$ by removing its last
row and column. We prove that there is no extension of a reciprocal matrix
whose digraph associated with the extension and its Perron eigenvector has a
source, as conjectured by Furtado and Johnson in ``Efficiency analysis for the
Perron vector of a reciprocal matrix". As an application, considering $n\geq 5$
and $A$ a matrix obtained from a consistent one by perturbing four entries
above the main diagonal, $x,y,z,a$, and the corresponding reciprocal entries,
in a way that there is a submatrix of size $2$ containing the four perturbed
entries and not containing a diagonal entry, we describe the relations among
$x,y,z,a$ with which $A$ always has efficient Perron eigenvector.

</details>


### [44] [Solution to some conjectures on mobile position problems](https://arxiv.org/abs/2507.16622)
*Ethan Shallcross,James Tuite,Aoise Evans,Aditi Krishnakumar,Sumaiyah Boshar*

Main category: math.CO

TL;DR: 本文研究了图论中的一般位置问题和互见性问题及其移动版本，解决了文献中的一些开放问题，量化了完全移动限制的影响，并给出了移动数在团数上的界限。


<details>
  <summary>Details</summary>
Motivation: 研究图的一般位置问题和互见性问题及其移动版本，旨在解决文献中的开放问题，并量化完全移动限制对问题的影响。

Method: 通过理论分析，量化了完全移动限制的影响，证明了移动数与团数的关系，并计算了特定图类（如完全图的线图、强网格和笛卡尔网格）的移动互见数。

Result: 解决了文献中的开放问题，量化了完全移动限制的影响，证明了移动数与团数的界限，并确定了特定图类的移动互见数。

Conclusion: 本文通过理论分析，解决了图论中一般位置和互见性问题的移动版本，为相关研究提供了新的理论结果和界限。

Abstract: The general position problem for graphs asks for the largest number of
vertices in a subset $S \subseteq V(G)$ of a graph $G$ such that for any $u,v
\in S$ and any shortest $u,v$-path $P$ we have $S \cap V(P) = \{ u,v\} $,
whereas the mutual visibility problem requires only that for any $u,v \in S$
there exists a shortest $u,v$-path with $S \cap V(P) = \{ u,v\} $. In the
mobile versions of these problems, robots must move through the network in
general position/mutual visibility such that every vertex is visited by a
robot. This paper solves some open problems from the literature. We quantify
the effect of adding the restriction that every robot can visit every vertex
(the so-called \emph{completely mobile} variants), prove a bound on both mobile
numbers in terms of the clique number, and find the mobile mutual visibility
number of line graphs of complete graphs, strong grids and Cartesian grids.

</details>


### [45] [A metrization theorem for edge-end spaces of infinite graphs](https://arxiv.org/abs/2507.16625)
*Max Pitz*

Main category: math.CO

TL;DR: 本文证明了无限图的边端空间可度量化的充要条件是其第一可数性，并改进了Aurichi等人的近期结果。核心工具是Wollan提出的树割分解，同时给出了Kurkofka和Halin定理的新证明。


<details>
  <summary>Details</summary>
Motivation: 研究无限图边端空间的拓扑性质，特别是可度量化条件，以深化对图结构与其拓扑表示之间关系的理解。

Method: 采用树割分解（tree-cut decomposition）作为核心工具，通过边切割替代顶点分离，并给出Kurkofka有限粘合分解定理及Halin经典子图定理的新证明。

Result: 边端空间可度量化当且仅当其第一可数，强化了Aurichi等人的结果；同时重构了关于$\omega$-边块分解和$K_{k,\kappa}$-子图的关键定理证明。

Conclusion: 该研究统一了无限图拓扑性质与组合结构的关系，所发展的树割分解技术为后续研究提供了简洁的证明框架。

Abstract: We prove that the edge-end space of an infinite graph is metrizable if and
only if it is first-countable. This strengthens a recent result by Aurichi,
Magalhaes Jr.\ and Real (2024).
  Our central graph-theoretic tool is the use of tree-cut decompositions,
introduced by Wollan (2015) as a variation of tree decompositions that is based
on edge cuts instead of vertex separations. In particular, we give a new,
elementary proof for Kurkofka's result (2022) that every infinite graph has a
tree-cut decomposition of finite adhesion into its $\omega$-edge blocks. Along
the way, we also give a new, short proof for a classic result by Halin (1984)
on $K_{k,\kappa}$-subdivisions in $k$-connected graphs, making this paper
self-contained.

</details>


### [46] [Linear codes arising from the point-hyperplane geometry -- Part II: the twisted embedding](https://arxiv.org/abs/2507.16694)
*Ilaria Cardinali,Luca Giuzzi*

Main category: math.CO

TL;DR: 本文研究了有限域$\mathbb{F}_q$上点-超平面几何$\bar{\Gamma}$在非平凡自同构$\sigma$下的射影嵌入$\varepsilon_{\sigma}$所生成的线性码$\mathcal{C}(\Lambda_{\sigma})$的性质，包括其参数、最小距离、自同构群及权值分布。


<details>
  <summary>Details</summary>
Motivation: 在前一篇论文中，作者研究了$\sigma=1$时的线性码。本文旨在探讨$\sigma\neq1$时的线性码$\mathcal{C}(\Lambda_{\sigma})$的性质，以扩展对这类几何编码的理解。

Method: 通过射影嵌入$\varepsilon_{\sigma}$将$\bar{\Gamma}$映射到射影空间$\mathrm{PG}(V\otimes V^*)$，并研究由此生成的线性码$\mathcal{C}(\Lambda_{\sigma})$的代数与几何特性。

Result: 证明了$\mathcal{C}(\Lambda_{\sigma})$是最小码，确定了其参数、最小距离和自同构群。此外，给出了最小和第二小权码字的几何刻画，并在$q$和$n$均为奇数时确定了最大权值。

Conclusion: 本文完善了非平凡自同构$\sigma$下点-超平面几何编码的理论框架，为后续研究提供了重要的代数与几何工具。

Abstract: Let $\bar{\Gamma}$ be the point-hyperplane geometry of a projective space
$\mathrm{PG(V)},$ where $V$ is a $(n+1)$-dimensional vector space over a finite
field $\mathbb{F}_q$ of order $q.$ Suppose that $\sigma$ is an automorphism of
$\mathbb{F}_q$ and consider the projective embedding $\varepsilon_{\sigma}$ of
$\bar{\Gamma}$ into the projective space $\mathrm{PG}(V\otimes V^*)$ mapping
the point $([x],[\xi])\in \bar{\Gamma}$ to the projective point represented by
the pure tensor $x^{\sigma}\otimes \xi$, with $\xi(x)=0.$ In [I. Cardinali, L.
Giuzzi, Linear codes arising from the point-hyperplane geometry -- part I: the
Segre embedding (Jun. 2025). arXiv:2506.21309, doi:10.48550/ARXIV.2506.21309]
we focused on the case $\sigma=1$ and we studied the projective code arising
from the projective system $\Lambda_1=\varepsilon_{1}(\bar{\Gamma}).$ Here we
focus on the case $\sigma\not=1$ and we investigate the linear code ${\mathcal
C}(\Lambda_{\sigma})$ arising from the projective system
$\Lambda_{\sigma}=\varepsilon_{\sigma}(\bar{\Gamma}).$ In particular, after
having verified that $\mathcal{C}( \Lambda_{\sigma})$ is a minimal code, we
determine its parameters, its minimum distance as well as its automorphism
group. We also give a (geometrical) characterization of its minimum and second
lowest weight codewords and determine its maximum weight when $q$ and $n$ are
both odd.

</details>


### [47] [Almost all cographs have a cospectral mate](https://arxiv.org/abs/2507.16730)
*Wei Wang,Ximei Huang*

Main category: math.CO

TL;DR: 本文证明了几乎所有补可约图（cographs）都存在共谱伴侣，这是对Schwenk关于树共谱性经典结论的类比扩展。


<details>
  <summary>Details</summary>
Motivation: 研究补可约图的共谱性是为了探索图论中谱性质的一般规律，并验证这类特殊图结构是否与树类似具有普遍共谱现象。

Method: 结合Johnson-Newman广义共谱定理与树渐近枚举的标准工具，通过理论推导进行分析。

Result: 几乎所有的补可约图都存在至少一个共谱伴侣，其比例随顶点数增长趋近于1。

Conclusion: 该结论确立了补可约图与树在共谱性上的相似行为，为图谱理论提供了新的分类学依据。

Abstract: Complement-reducible graphs (or cographs) are the graphs formed from the
single-vertex graph by the operations of complement and disjoint union. By
combining the Johnson-Newman theorem on generalized cospectrality with the
standard tools in the asymptotic enumeration of trees, we show that almost all
cographs have a cospectral mate. This result can be viewed as an analogue to a
well-known result by Schwenk, who proved that almost all trees have a
cospectral mate.

</details>


### [48] [Elliptic Curves, Riordan arrays and Lattice Paths](https://arxiv.org/abs/2507.16765)
*Paul Barry*

Main category: math.CO

TL;DR: 本文展示了如何将特定形式的椭圆曲线与格路径族关联，并通过Riordan数组进行计数，揭示了椭圆曲线与格路径在Somos 4序列上的本质联系。


<details>
  <summary>Details</summary>
Motivation: 研究旨在建立椭圆曲线$y^2-axy-y=x^3-bx^2-cx$与格路径族的关联，探索两者在组合数学与数论中的深层联系。

Method: 通过Riordan数组枚举格路径，并利用椭圆可除序列（曲线）和Hankel变换（路径）分别关联到Somos 4序列。

Result: 发现椭圆曲线与对应格路径族的Somos 4序列本质相同，验证了曲线参数决定路径步集的数学关联性。

Conclusion: 该研究统一了椭圆曲线与格路径的代数组合性质，为Somos序列的几何与组合解释提供了新视角。

Abstract: In this note, we show that to each elliptic curve of the form
$$y^2-axy-y=x^3-bx^2-cx,$$ we can associate a family of lattice paths whose
step set is determined by the parameters of the elliptic curve. The enumeration
of these lattice paths is by means of an associated Riordan array. The curves
and the paths have associated Somos $4$ sequences which are essentially the
same. For the curves the link to Somos $4$ sequences is a classical result, via
the elliptic divisibility sequence. For the paths the link is via a Hankel
transform.

</details>


### [49] [Bipartite Turán numbers via edge-gluing](https://arxiv.org/abs/2507.16804)
*Zihao Jin,Sean Longbrake,Liana Yepremyan*

Main category: math.CO

TL;DR: 本文研究了Erd\H{o}s和Simonovits在1984年提出的关于二分图的问题，证明了在某些对称条件下，边粘合操作能够保持该猜想的成立性，并展示了Zarankiewicz数在边粘合下的可加性。


<details>
  <summary>Details</summary>
Motivation: 研究Erd\H{o}s和Simonovits提出的关于二分图的猜想，探索边粘合操作对该猜想的影响，并验证Zarankiewicz数在边粘合下的行为。

Method: 通过边粘合操作将满足猜想的两个图$H_1$和$H_2$粘合，验证粘合后的图是否仍满足猜想；同时研究Zarankiewicz数在边粘合下的可加性。

Result: 证明了在温和的对称条件下，边粘合操作能够保持猜想的成立性；同时展示了Zarankiewicz数在边粘合下具有可加性，即$z(m,n, H) = \Theta(z(m,n, H_1) + z(m,n, H_2))$。

Conclusion: 边粘合操作在满足一定条件时能够保持Erd\H{o}s和Simonovits猜想的成立性，且Zarankiewicz数在边粘合下表现出可加性，为相关图论问题的研究提供了新的工具和视角。

Abstract: In 1984, Erd\H{o}s and Simonovits asked the following: given a bipartite
graph $H$, do there exist constants $0 \leq \alpha < 1$ and $\beta, C > 0$ such
that any graph $G$ on $n$ vertices and $pn^2\geq C n^{1+ \alpha}$ edges
contains at least $\beta n^{\mathrm{v}(H)} p^{\mathrm{e}(H)}$ copies of $H$?
  We show that edge-gluing preserves the satisfiability of this conjecture
under some mild symmetry conditions. Namely, if two graphs $H_1$ and $H_2$
satisfy this conjecture, and if furthermore, gluing them along a fixed edge
produces a unique graph then the resulting graph satisfies the conjecture as
well. We also show that if $H$ satisfies the conjecture then if we glue several
copies of (labeled) $H$ along the same labeled copy of a subforest of $H$ then
the resulting graph also satisfies the conjecture.
  We also show that Zarankiewicz numbers are additive in the order of magnitude
under gluing edges. Indeed, for a (signed) bipartite graph $H$ with parts
coloured $+$ and $-$, recall $z(m,n, H)$ is the maximum number of edges in a
signed bipartite graph $G$ with $+$ side being of size $m$ and $-$ side being
of size $n$ such that $G$ does not contain a copy of $H$ with $+$ side embedded
in the $+$ side of $G$. We show that for any two (signed) bipartite graphs
$H_1$ and $H_2$ if we glue them along an edge preserving the sign of the edge
then the resulting graph $H$ satisfies $z(m,n, H) = \Theta(z(m,n, H_1) + z(m,n,
H_2))$.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [50] [Decentralized AI-driven IoT Architecture for Privacy-Preserving and Latency-Optimized Healthcare in Pandemic and Critical Care Scenarios](https://arxiv.org/abs/2507.15859)
*Harsha Sammangi,Aditya Jagatha,Giridhar Reddy Bojja,Jun Liu*

Main category: cs.CR

TL;DR: 本文提出了一种基于AI的去中心化物联网架构，用于实时患者监测，通过结合联邦学习、区块链和边缘计算技术，显著提升了数据隐私性并降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 传统集中式医疗架构存在数据隐私、延迟和安全问题，尤其在疫情期间和重症监护场景下更为突出，亟需创新解决方案。

Method: 采用AI赋能的去中心化物联网架构，整合联邦学习、区块链和边缘计算技术，优化系统性能指标。

Result: 实验结果显示，该架构在交易延迟、能耗和数据吞吐量方面比云端解决方案有数量级的提升。

Conclusion: 该AI驱动的去中心化架构为实时患者监测提供了高效、安全的解决方案，具有显著的临床应用价值。

Abstract: AI Innovations in the IoT for Real-Time Patient Monitoring On one hand, the
current traditional centralized healthcare architecture poses numerous issues,
including data privacy, delay, and security. Here, we present an AI-enabled
decentralized IoT architecture that can address such challenges during a
pandemic and critical care settings. This work presents our architecture to
enhance the effectiveness of the current available federated learning,
blockchain, and edge computing approach, maximizing data privacy, minimizing
latency, and improving other general system metrics. Experimental results
demonstrate transaction latency, energy consumption, and data throughput orders
of magnitude lower than competitive cloud solutions.

</details>


### [51] [BACFuzz: Exposing the Silence on Broken Access Control Vulnerabilities in Web Applications](https://arxiv.org/abs/2507.15984)
*I Putu Arya Dharmaadi,Mohannad Alhanahnah,Van-Thuan Pham,Fadi Mohsen,Fatih Turkmen*

Main category: cs.CR

TL;DR: BACFuzz是首个针对PHP网页应用中BAC漏洞（如BOLA和BFLA）的灰盒模糊测试框架，结合LLM引导的参数选择与运行时反馈，成功检测出大量已知和未知漏洞。


<details>
  <summary>Details</summary>
Motivation: BAC漏洞虽严重但自动化测试不足，主要因缺乏可靠验证机制和有效攻击请求生成方法。

Method: 框架集成LLM引导参数选择、轻量级运行时插桩及SQL查询分析，通过语义化请求生成与静默授权缺陷检测提升准确性。

Result: 在20个真实应用（含15个CVE案例）中，BACFuzz检出16/17已知漏洞及26个未知漏洞，误报率低。

Conclusion: BACFuzz显著提升BAC漏洞检测效率，所有发现已负责任披露，工具将开源推动研究。

Abstract: Broken Access Control (BAC) remains one of the most critical and widespread
vulnerabilities in web applications, allowing attackers to access unauthorized
resources or perform privileged actions. Despite its severity, BAC is
underexplored in automated testing due to key challenges: the lack of reliable
oracles and the difficulty of generating semantically valid attack requests. We
introduce BACFuzz, the first gray-box fuzzing framework specifically designed
to uncover BAC vulnerabilities, including Broken Object-Level Authorization
(BOLA) and Broken Function-Level Authorization (BFLA) in PHP-based web
applications. BACFuzz combines LLM-guided parameter selection with runtime
feedback and SQL-based oracle checking to detect silent authorization flaws. It
employs lightweight instrumentation to capture runtime information that guides
test generation, and analyzes backend SQL queries to verify whether
unauthorized inputs flow into protected operations. Evaluated on 20 real-world
web applications, including 15 CVE cases and 2 known benchmarks, BACFuzz
detects 16 of 17 known issues and uncovers 26 previously unknown BAC
vulnerabilities with low false positive rates. All identified issues have been
responsibly disclosed, and artifacts will be publicly released.

</details>


### [52] ["We Need a Standard": Toward an Expert-Informed Privacy Label for Differential Privacy](https://arxiv.org/abs/2507.15997)
*Onyinye Dibia,Mengyi Lu,Prianka Bhattacharjee,Joseph P. Near,Yuanyuan Feng*

Main category: cs.CR

TL;DR: 研究通过专家访谈提出差分隐私(DP)参数披露标准，并设计隐私标签以标准化传达隐私保障。


<details>
  <summary>Details</summary>
Motivation: 现实中的DP部署常未完全公开隐私保障参数，导致对隐私保护强度的误解，损害DP的公信力。

Method: 对12位DP专家进行半结构化访谈，识别关键DP参数及其披露方式。

Result: 确定了全面传达DP保障所需的重要参数，并基于专家建议设计了标准化隐私标签。

Conclusion: 提出的隐私标签框架可为未来DP部署的隐私保障沟通建立标准化规范。

Abstract: The increasing adoption of differential privacy (DP) leads to public-facing
DP deployments by both government agencies and companies. However, real-world
DP deployments often do not fully disclose their privacy guarantees, which vary
greatly between deployments. Failure to disclose certain DP parameters can lead
to misunderstandings about the strength of the privacy guarantee, undermining
the trust in DP. In this work, we seek to inform future standards for
communicating the privacy guarantees of DP deployments. Based on
semi-structured interviews with 12 DP experts, we identify important DP
parameters necessary to comprehensively communicate DP guarantees, and describe
why and how they should be disclosed. Based on expert recommendations, we
design an initial privacy label for DP to comprehensively communicate privacy
guarantees in a standardized format.

</details>


### [53] [Blocklisted Oblivious Pseudorandom Functions](https://arxiv.org/abs/2507.16040)
*Xinyuan Zhang,Anrin Chakraborti,Michael Reiter*

Main category: cs.CR

TL;DR: 本文提出一种支持黑名单检查的茫然伪随机函数（OPRF）协议，通过将客户端输入嵌入度量空间实现高效黑名单验证，并应用于密码黑名单和恶意软件检测场景。


<details>
  <summary>Details</summary>
Motivation: 传统OPRF协议无法实现输入黑名单验证，限制了其在密码安全和恶意软件检测等场景的应用。需要扩展OPRF功能以支持高效黑名单检查。

Method: 1. 将客户端输入嵌入度量空间\n2. 设计分离式架构：先执行嵌入计算，再进行黑名单聚类检查\n3. 通过密码学方法连接两个阶段\n4. 支持相同输入的快速重复计算

Result: 1. 实现了带黑名单的高效OPRF协议\n2. 在增强型密码认证密钥交换中验证了密码黑名单功能\n3. 成功应用于仅对非恶意软件可执行文件生成MAC的场景

Conclusion: 该框架通过度量空间嵌入和模块化设计，首次实现了支持黑名单的OPRF协议，为密码安全和恶意软件检测提供了新解决方案，且具有计算效率优势。

Abstract: An oblivious pseudorandom function (OPRF) is a protocol by which a client and
server interact to evaluate a pseudorandom function on a key provided by the
server and an input provided by the client, without divulging the key or input
to the other party. We extend this notion by enabling the server to specify a
blocklist, such that OPRF evaluation succeeds only if the client's input is not
on the blocklist. More specifically, our design gains performance by embedding
the client input into a metric space, where evaluation continues only if this
embedding does not cluster with blocklist elements. Our framework exploits this
structure to separate the embedding and blocklist check to enable efficient
implementations of each, but then must stitch these phases together through
cryptographic means. Our framework also supports subsequent evaluation of the
OPRF on the same input more efficiently. We demonstrate the use of our design
for password blocklisting in augmented password-authenticated key exchange, and
to MAC only executables that are not similar to ones on a blocklist of known
malware.

</details>


### [54] [MFAz: Historical Access Based Multi-Factor Authorization](https://arxiv.org/abs/2507.16060)
*Eyasu Getahun Chekole,Howard Halim,Jianying Zhou*

Main category: cs.CR

TL;DR: 本文提出了一种新型多因素授权（MFAz）方案，旨在主动防范传统及高级未经授权访问攻击，通过细粒度访问控制规则和验证点实现高效安全防护。


<details>
  <summary>Details</summary>
Motivation: 随着攻击技术的日益复杂，传统访问控制机制已无法有效防范会话劫持等高级攻击手段，亟需一种更强大的授权方案来应对这些安全挑战。

Method: 方案采用细粒度访问控制规则（ARs）和历史授权生成的验证点（VPs）作为双重授权因素，结合布隆过滤器提升运行时效率，并利用区块链实现防篡改的分布式授权决策。

Result: 在智能城市测试平台上进行的实验表明，该方案在安全性和性能保障方面均表现出色，能有效抵御各类未经授权访问攻击。

Conclusion: MFAz方案作为首个正式提出的多因素授权框架，与多因素认证（MFA）形成互补，为网络安全领域提供了创新的防护思路和实用解决方案。

Abstract: Unauthorized access remains one of the critical security challenges in the
realm of cybersecurity. With the increasing sophistication of attack
techniques, the threat of unauthorized access is no longer confined to the
conventional ones, such as exploiting weak access control policies. Instead,
advanced exploitation strategies, such as session hijacking-based attacks, are
becoming increasingly prevalent, posing serious security concerns. Session
hijacking enables attackers to take over an already established session between
legitimate peers in a stealthy manner, thereby gaining unauthorized access to
private resources. Unfortunately, traditional access control mechanisms, such
as static access control policies, are insufficient to prevent session
hijacking or other advanced exploitation techniques. In this work, we propose a
new multi-factor authorization (MFAz) scheme that proactively mitigates
unauthorized access attempts both conventional and advanced unauthorized access
attacks. The proposed scheme employs fine-grained access control rules (ARs)
and verification points (VPs) that are systematically generated from
historically granted accesses as the first and second authorization factors,
respectively. As a proof-of-concept, we implement the scheme using different
techniques. We leverage bloom filter to achieve runtime and storage efficiency,
and blockchain to make authorization decisions in a temper-proof and
decentralized manner. To the best of our knowledge, this is the first formal
introduction of a multi-factor authorization scheme, which is orthogonal to the
multi-factor authentication (MFA) schemes. The effectiveness of our proposed
scheme is experimentally evaluated using a smart-city testbed involving
different devices with varying computational capacities. The experimental
results reveal high effectiveness of the scheme both in security and
performance guarantees.

</details>


### [55] [DP2Guard: A Lightweight and Byzantine-Robust Privacy-Preserving Federated Learning Scheme for Industrial IoT](https://arxiv.org/abs/2507.16134)
*Baofu Han,Bing Li,Yining Qi,Raja Jurdak,Kaibin Huang,Chau Yuen*

Main category: cs.CR

TL;DR: 本文提出DP2Guard，一种轻量级隐私保护联邦学习框架，通过梯度掩蔽和混合防御策略提升隐私性与鲁棒性，同时降低通信与计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有隐私保护联邦学习（PPFL）方案依赖重型加密技术导致高开销，且单一防御策略难以抵御自适应攻击，亟需轻量级高鲁棒性解决方案。

Method: 采用轻量级梯度掩蔽替代加密操作；提出混合防御策略（奇异值分解+余弦相似度提取特征，聚类检测恶意梯度）；基于信任分数的自适应聚合方案，区块链记录确保可审计性。

Result: 在两个公开数据集上的实验表明，DP2Guard能有效抵御四种高级投毒攻击，隐私保护前提下通信与计算成本降低。

Conclusion: DP2Guard通过创新性轻量级设计与混合防御机制，实现了隐私-鲁棒性-效率的平衡，为安全联邦学习提供了可行方案。

Abstract: Privacy-Preserving Federated Learning (PPFL) has emerged as a secure
distributed Machine Learning (ML) paradigm that aggregates locally trained
gradients without exposing raw data. To defend against model poisoning threats,
several robustness-enhanced PPFL schemes have been proposed by integrating
anomaly detection. Nevertheless, they still face two major challenges: (1) the
reliance on heavyweight encryption techniques results in substantial
communication and computation overhead; and (2) single-strategy defense
mechanisms often fail to provide sufficient robustness against adaptive
adversaries. To overcome these challenges, we propose DP2Guard, a lightweight
PPFL framework that enhances both privacy and robustness. DP2Guard leverages a
lightweight gradient masking mechanism to replace costly cryptographic
operations while ensuring the privacy of local gradients. A hybrid defense
strategy is proposed, which extracts gradient features using singular value
decomposition and cosine similarity, and applies a clustering algorithm to
effectively identify malicious gradients. Additionally, DP2Guard adopts a trust
score-based adaptive aggregation scheme that adjusts client weights according
to historical behavior, while blockchain records aggregated results and trust
scores to ensure tamper-proof and auditable training. Extensive experiments
conducted on two public datasets demonstrate that DP2Guard effectively defends
against four advanced poisoning attacks while ensuring privacy with reduced
communication and computation costs.

</details>


### [56] [Attacking interpretable NLP systems](https://arxiv.org/abs/2507.16164)
*Eldor Abdukhamidov,Tamer Abuhmed,Joanna C. S. Santos,Mohammed Abuhamad*

Main category: cs.CR

TL;DR: 本文提出AdvChar，一种针对可解释自然语言处理系统的黑盒攻击方法，通过细微的字符级修改误导分类器，同时保持解释相似性。


<details>
  <summary>Details</summary>
Motivation: 现有文本对抗攻击常破坏语义相似性，而AdvChar旨在利用系统透明度信任，保持解释相似性同时实现攻击。

Method: 采用解释导向的评分方法定位关键token，施加字符级修改，最小化文本差异并生成与良性输入相似的对抗解释。

Result: 在7个NLP模型和3个解释模型上的实验表明，平均仅需修改2个字符即可显著降低模型预测准确率。

Conclusion: AdvChar揭示了当前深度学习模型在字符级扰动下的脆弱性，对可解释NLP系统的安全性提出挑战。

Abstract: Studies have shown that machine learning systems are vulnerable to
adversarial examples in theory and practice. Where previous attacks have
focused mainly on visual models that exploit the difference between human and
machine perception, text-based models have also fallen victim to these attacks.
However, these attacks often fail to maintain the semantic meaning of the text
and similarity. This paper introduces AdvChar, a black-box attack on
Interpretable Natural Language Processing Systems, designed to mislead the
classifier while keeping the interpretation similar to benign inputs, thus
exploiting trust in system transparency. AdvChar achieves this by making less
noticeable modifications to text input, forcing the deep learning classifier to
make incorrect predictions and preserve the original interpretation. We use an
interpretation-focused scoring approach to determine the most critical tokens
that, when changed, can cause the classifier to misclassify the input. We apply
simple character-level modifications to measure the importance of tokens,
minimizing the difference between the original and new text while generating
adversarial interpretations similar to benign ones. We thoroughly evaluated
AdvChar by testing it against seven NLP models and three interpretation models
using benchmark datasets for the classification task. Our experiments show that
AdvChar can significantly reduce the prediction accuracy of current deep
learning models by altering just two characters on average in input samples.

</details>


### [57] [SVAgent: AI Agent for Hardware Security Verification Assertion](https://arxiv.org/abs/2507.16203)
*Rui Guo,Avinash Ayalasomayajula,Henian Li,Jingbo Zhou,Sujan Kumar Saha,Farimah Farahmandi*

Main category: cs.CR

TL;DR: 本文提出了一种创新的SystemVerilog断言(SVA)自动生成框架SVAgent，通过需求分解机制显著提升复杂集成电路漏洞检测的效率和准确性，并在实际工程环境中验证了其可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着集成电路设计的全球化与安全需求升级，传统SVA开发模式存在效率低下、难以应对现代复杂电路安全漏洞的局限性，亟需创新解决方案。

Method: SVAgent框架引入需求分解机制，将原始复杂需求转化为结构化、可逐步解决的细粒度问题链，有效抑制幻觉和随机答案的影响。

Result: 实验表明SVAgent在SVA准确性和一致性等关键指标上显著优于现有框架，并成功集成至主流集成电路漏洞评估框架中。

Conclusion: SVAgent在真实工程设计环境中验证了实用性与可靠性，为集成电路安全验证提供了高效自动化解决方案。

Abstract: Verification using SystemVerilog assertions (SVA) is one of the most popular
methods for detecting circuit design vulnerabilities. However, with the
globalization of integrated circuit design and the continuous upgrading of
security requirements, the SVA development model has exposed major limitations.
It is not only inefficient in development, but also unable to effectively deal
with the increasing number of security vulnerabilities in modern complex
integrated circuits. In response to these challenges, this paper proposes an
innovative SVA automatic generation framework SVAgent. SVAgent introduces a
requirement decomposition mechanism to transform the original complex
requirements into a structured, gradually solvable fine-grained problem-solving
chain. Experiments have shown that SVAgent can effectively suppress the
influence of hallucinations and random answers, and the key evaluation
indicators such as the accuracy and consistency of the SVA are significantly
better than existing frameworks. More importantly, we successfully integrated
SVAgent into the most mainstream integrated circuit vulnerability assessment
framework and verified its practicality and reliability in a real engineering
design environment.

</details>


### [58] [eX-NIDS: A Framework for Explainable Network Intrusion Detection Leveraging Large Language Models](https://arxiv.org/abs/2507.16241)
*Paul R. B. Houssel,Siamak Layeghy,Priyanka Singh,Marius Portmann*

Main category: cs.CR

TL;DR: 本文提出eX-NIDS框架，利用大语言模型（LLMs）增强基于流的网络入侵检测系统（NIDS）的可解释性，通过上下文增强提示生成恶意流量的详细解释。


<details>
  <summary>Details</summary>
Motivation: 现有NIDS缺乏对恶意流量分类的可解释性，需要一种能自动生成详细解释的方法来辅助安全分析。

Method: 框架包含提示增强模块，从恶意流量中提取上下文和网络威胁情报（CTI），结合LLMs生成解释；与基础提示解释器对比，并采用新型自然语言解释评估方法。

Result: 增强提示的LLMs（Llama 3和GPT-4）生成的解释准确且一致，性能比基础提示解释器提升20%以上。

Conclusion: eX-NIDS证明增强提示的LLMs可作为NIDS的有效补充工具，显著提升恶意流量分类解释的质量和可靠性。

Abstract: This paper introduces eX-NIDS, a framework designed to enhance
interpretability in flow-based Network Intrusion Detection Systems (NIDS) by
leveraging Large Language Models (LLMs). In our proposed framework, flows
labelled as malicious by NIDS are initially processed through a module called
the Prompt Augmenter. This module extracts contextual information and Cyber
Threat Intelligence (CTI)-related knowledge from these flows. This enriched,
context-specific data is then integrated with an input prompt for an LLM,
enabling it to generate detailed explanations and interpretations of why the
flow was identified as malicious by NIDS. We compare the generated
interpretations against a Basic-Prompt Explainer baseline, which does not
incorporate any contextual information into the LLM's input prompt. Our
framework is quantitatively evaluated using the Llama 3 and GPT-4 models,
employing a novel evaluation method tailored for natural language explanations,
focusing on their correctness and consistency. The results demonstrate that
augmented LLMs can produce accurate and consistent explanations, serving as
valuable complementary tools in NIDS to explain the classification of malicious
flows. The use of augmented prompts enhances performance by over 20% compared
to the Basic-Prompt Explainer.

</details>


### [59] [From Contracts to Code: Automating Smart Contract Generation with Multi-Level Finite State Machines](https://arxiv.org/abs/2507.16276)
*Lambard Maxence,Bertelle Cyrille,Duvallet Claude*

Main category: cs.CR

TL;DR: 本文提出了一种多级有限状态机模型，旨在简化智能合约开发，通过形式化框架抽象技术复杂性，使其对非技术专业人士更易用，同时增强合约的模块化和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 随着合约环境日益复杂，对透明度、安全性和效率的需求增加。区块链技术和智能合约虽能解决这些问题，但其复杂性和技术要求阻碍了广泛应用。

Method: 研究引入了一种多级有限状态机模型，用于表示和跟踪智能合约的执行。该模型通过分层结构增强模块化和可追溯性，并详细探讨了智能合约生成过程及可重用组件。

Result: 模型通过安全分析评估潜在漏洞，确保生成的智能合约的健壮性和可靠性。多级方法简化了开发，使其对非技术专业人士更易用。

Conclusion: 多级有限状态机模型为智能合约开发提供了简化且可靠的框架，有望推动其在各行业的广泛应用。

Abstract: In an increasingly complex contractual landscape, the demand for
transparency, security, and efficiency has intensified. Blockchain technology,
with its decentralized and immutable nature, addresses these challenges by
reducing intermediary costs, minimizing fraud risks, and enhancing system
compatibility. Smart contracts, initially conceptualized by Nick Szabo and
later implemented on the Ethereum blockchain, automate and secure contractual
clauses, offering a robust solution for various industries. However, their
complexity and the requirement for advanced programming skills present
significant barriers to widespread adoption. This study introduces a
multi-level finite state machine model designed to represent and track the
execution of smart contracts. Our model aims to simplify smart contract
development by providing a formalized framework that abstracts underlying
technical complexities, making it accessible to professionals without deep
technical expertise. The hierarchical structure of the multi-level finite state
machine enhances contract modularity and traceability, facilitating detailed
representation and evaluation of functional properties. The paper explores the
potential of this multi-level approach, reviewing existing methodologies and
tools, and detailing the smart contract generation process with an emphasis on
reusable components and modularity. We also conduct a security analysis to
evaluate potential vulnerabilities in our model, ensuring the robustness and
reliability of the generated smart contracts.

</details>


### [60] [Talking Like a Phisher: LLM-Based Attacks on Voice Phishing Classifiers](https://arxiv.org/abs/2507.16291)
*Wenhao Li,Selvakumar Manickam,Yung-wey Chong,Shankar Karuppayah*

Main category: cs.CR

TL;DR: 本文研究利用大型语言模型（LLMs）生成对抗性语音钓鱼（vishing）文本，这些文本能逃避机器学习检测器识别，同时保持欺骗意图。实验表明，GPT-4o生成的文本使分类器准确率下降高达30.96%，且生成成本低、效率高。


<details>
  <summary>Details</summary>
Motivation: 语音钓鱼（vishing）通过利用人类信任进行攻击，现有机器学习检测器易受语义保留的对抗性文本攻击。本研究探索LLMs生成此类对抗性文本的潜力，以揭示检测框架的脆弱性。

Method: 构建系统性攻击流程，使用提示工程和语义混淆技术，通过四种商业LLMs转换真实钓鱼脚本。生成的文本在韩国真实钓鱼数据集（KorCCViD）上测试多个ML分类器，并进行统计检验。

Result: LLMs生成的对抗性文本显著降低分类器性能（GPT-4o使准确率下降30.96%），且保持高语义相似性（BERTScore评估）。攻击平均生成时间低于9秒，单次查询成本极低。

Conclusion: 结果凸显当前钓鱼检测框架的脆弱性，急需开发更鲁棒的防御机制，并呼吁LLM提供商加强对抗性社会工程场景中的提示滥用防护。

Abstract: Voice phishing (vishing) remains a persistent threat in cybersecurity,
exploiting human trust through persuasive speech. While machine learning
(ML)-based classifiers have shown promise in detecting malicious call
transcripts, they remain vulnerable to adversarial manipulations that preserve
semantic content. In this study, we explore a novel attack vector where large
language models (LLMs) are leveraged to generate adversarial vishing
transcripts that evade detection while maintaining deceptive intent. We
construct a systematic attack pipeline that employs prompt engineering and
semantic obfuscation to transform real-world vishing scripts using four
commercial LLMs. The generated transcripts are evaluated against multiple ML
classifiers trained on a real-world Korean vishing dataset (KorCCViD) with
statistical testing. Our experiments reveal that LLM-generated transcripts are
both practically and statistically effective against ML-based classifiers. In
particular, transcripts crafted by GPT-4o significantly reduce classifier
accuracy (by up to 30.96%) while maintaining high semantic similarity, as
measured by BERTScore. Moreover, these attacks are both time-efficient and
cost-effective, with average generation times under 9 seconds and negligible
financial cost per query. The results underscore the pressing need for more
resilient vishing detection frameworks and highlight the imperative for LLM
providers to enforce stronger safeguards against prompt misuse in adversarial
social engineering contexts.

</details>


### [61] [DREAM: Scalable Red Teaming for Text-to-Image Generative Systems via Distribution Modeling](https://arxiv.org/abs/2507.16329)
*Boheng Li,Junjie Wang,Yiming Li,Zhiyang Hu,Leyi Qi,Jianshuo Dong,Run Wang,Han Qiu,Zhan Qin,Tianwei Zhang*

Main category: cs.CR

TL;DR: 本文提出DREAM框架，通过建模问题提示的概率分布，自动发现文本到图像(T2I)系统中的多样化有害提示，显著提升安全测试效果。


<details>
  <summary>Details</summary>
Motivation: 现有T2I模型即使经过安全对齐和外部过滤，仍可能生成有害内容。传统红队方法将提示发现视为孤立优化任务，缺乏可扩展性和多样性。

Method: 提出DREAM框架：1) 建模问题提示的概率分布；2) 借鉴能量模型简化目标；3) 开发GC-SPSA优化算法处理不可微流程。

Result: 实验表明DREAM在9个基线方法中显著领先，在多种T2I模型和安全过滤器上均取得更高的提示成功率和多样性。

Conclusion: DREAM通过系统性建模问题提示分布，为T2I系统安全评估提供了可扩展、多样化的自动化红队解决方案。

Abstract: Despite the integration of safety alignment and external filters,
text-to-image (T2I) generative models are still susceptible to producing
harmful content, such as sexual or violent imagery. This raises serious
concerns about unintended exposure and potential misuse. Red teaming, which
aims to proactively identify diverse prompts that can elicit unsafe outputs
from the T2I system (including the core generative model as well as potential
external safety filters and other processing components), is increasingly
recognized as an essential method for assessing and improving safety before
real-world deployment. Yet, existing automated red teaming approaches often
treat prompt discovery as an isolated, prompt-level optimization task, which
limits their scalability, diversity, and overall effectiveness. To bridge this
gap, in this paper, we propose DREAM, a scalable red teaming framework to
automatically uncover diverse problematic prompts from a given T2I system.
Unlike most prior works that optimize prompts individually, DREAM directly
models the probabilistic distribution of the target system's problematic
prompts, which enables explicit optimization over both effectiveness and
diversity, and allows efficient large-scale sampling after training. To achieve
this without direct access to representative training samples, we draw
inspiration from energy-based models and reformulate the objective into simple
and tractable objectives. We further introduce GC-SPSA, an efficient
optimization algorithm that provide stable gradient estimates through the long
and potentially non-differentiable T2I pipeline. The effectiveness of DREAM is
validated through extensive experiments, demonstrating that it surpasses 9
state-of-the-art baselines by a notable margin across a broad range of T2I
models and safety filters in terms of prompt success rate and diversity.

</details>


### [62] [Depth Gives a False Sense of Privacy: LLM Internal States Inversion](https://arxiv.org/abs/2507.16372)
*Tian Dong,Yan Meng,Shaofeng Li,Guoxing Chen,Zhen Liu,Haojin Zhu*

Main category: cs.CR

TL;DR: 本文提出四种针对大语言模型内部状态的反演攻击方法，显著提升输入重构的语义相似度和词元匹配率，并通过实验验证其有效性，同时评估现有防御措施的局限性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）的广泛应用引发隐私与安全问题，传统认为内部状态不可逆的观点受到挑战，需研究高效反演攻击以揭示潜在风险。

Method: 提出两类白盒优化攻击（针对浅层/深层状态）避免局部最优，基于模型可迁移性扩展黑盒攻击，并设计生成式反演模型将重构视为翻译任务。

Result: 实验表明：在医疗咨询和代码辅助数据集中，Llama-3模型中间层对4,112词元长文本可实现86.88 F1词元匹配率，现有防御措施无法完全阻截反演。

Conclusion: 内部状态反演风险被低估，需设计更高效防御机制；生成式攻击与优化攻击互补，为未来缓解方案提供方向。

Abstract: Large Language Models (LLMs) are increasingly integrated into daily routines,
yet they raise significant privacy and safety concerns. Recent research
proposes collaborative inference, which outsources the early-layer inference to
ensure data locality, and introduces model safety auditing based on inner
neuron patterns. Both techniques expose the LLM's Internal States (ISs), which
are traditionally considered irreversible to inputs due to optimization
challenges and the highly abstract representations in deep layers. In this
work, we challenge this assumption by proposing four inversion attacks that
significantly improve the semantic similarity and token matching rate of
inverted inputs. Specifically, we first develop two white-box
optimization-based attacks tailored for low-depth and high-depth ISs. These
attacks avoid local minima convergence, a limitation observed in prior work,
through a two-phase inversion process. Then, we extend our optimization attack
under more practical black-box weight access by leveraging the transferability
between the source and the derived LLMs. Additionally, we introduce a
generation-based attack that treats inversion as a translation task, employing
an inversion model to reconstruct inputs. Extensive evaluation of short and
long prompts from medical consulting and coding assistance datasets and 6 LLMs
validates the effectiveness of our inversion attacks. Notably, a 4,112-token
long medical consulting prompt can be nearly perfectly inverted with 86.88 F1
token matching from the middle layer of Llama-3 model. Finally, we evaluate
four practical defenses that we found cannot perfectly prevent ISs inversion
and draw conclusions for future mitigation design.

</details>


### [63] [Explainable Vulnerability Detection in C/C++ Using Edge-Aware Graph Attention Networks](https://arxiv.org/abs/2507.16540)
*Radowanul Haque,Aftab Ali,Sally McClean,Naveed Khan*

Main category: cs.CR

TL;DR: 本文提出ExplainVulD框架，通过双通道嵌入和边缘感知注意力机制改进C/C++代码漏洞检测，解决类别不平衡问题并提升可解释性，在ReVeal数据集上准确率达88.25%，F1分数提升16.9%。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的漏洞检测方法存在高误报率、可解释性不足的问题，且真实数据集中漏洞函数样本稀缺导致类别不平衡，亟需改进检测性能与工作流集成。

Method: 构建代码属性图，采用融合语义与结构的双通道节点嵌入，设计结合边类型嵌入的边缘感知注意力机制，并使用类别加权交叉熵损失缓解类别不平衡。

Result: 在ReVeal数据集上30次独立测试平均准确率88.25%、F1分数48.23%，较ReVeal模型准确率提升4.6%，F1分数提升16.9%；较静态分析工具准确率提升14.0-14.1%，F1分数提升132.2-201.2%。

Conclusion: ExplainVulD通过可解释的代码区域定位显著提升检测性能与透明度，为安全审计工作流提供可信支持，解决了现有方法在实用性与解释性方面的局限性。

Abstract: Detecting security vulnerabilities in source code remains challenging,
particularly due to class imbalance in real-world datasets where vulnerable
functions are under-represented. Existing learning-based methods often optimise
for recall, leading to high false positive rates and reduced usability in
development workflows. Furthermore, many approaches lack explainability,
limiting their integration into security workflows. This paper presents
ExplainVulD, a graph-based framework for vulnerability detection in C/C++ code.
The method constructs Code Property Graphs and represents nodes using
dual-channel embeddings that capture both semantic and structural information.
These are processed by an edge-aware attention mechanism that incorporates
edge-type embeddings to distinguish among program relations. To address class
imbalance, the model is trained using class-weighted cross-entropy loss.
ExplainVulD achieves a mean accuracy of 88.25 percent and an F1 score of 48.23
percent across 30 independent runs on the ReVeal dataset. These results
represent relative improvements of 4.6 percent in accuracy and 16.9 percent in
F1 score compared to the ReVeal model, a prior learning-based method. The
framework also outperforms static analysis tools, with relative gains of 14.0
to 14.1 percent in accuracy and 132.2 to 201.2 percent in F1 score. Beyond
improved detection performance, ExplainVulD produces explainable outputs by
identifying the most influential code regions within each function, supporting
transparency and trust in security triage.

</details>


### [64] [From Text to Actionable Intelligence: Automating STIX Entity and Relationship Extraction](https://arxiv.org/abs/2507.16576)
*Ahmed Lekssays,Husrev Taha Sencar,Ting Yu*

Main category: cs.CR

TL;DR: 本文介绍了AZERG工具，通过微调大型语言模型自动从非结构化安全文本生成STIX格式的威胁情报，解决了手动处理效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 当前从非结构化安全文本生成STIX兼容数据主要依赖人工，效率低下。为提升威胁情报共享的时效性和自动化水平，需要开发自动化工具。

Method: 将任务分解为四个子任务（实体检测、类型识别、关联对检测、关系类型识别），通过任务特定微调优化模型性能，并构建包含4011个实体和2075个关系的标注数据集。

Result: 模型在四个子任务中的F1分数分别达到84.43%、88.49%、95.47%和84.60%，相比现有方法提升2-25%。

Conclusion: AZERG证明了大型语言模型在结构化威胁情报生成中的有效性，为自动化安全分析提供了可行解决方案。

Abstract: Sharing methods of attack and their effectiveness is a cornerstone of
building robust defensive systems. Threat analysis reports, produced by various
individuals and organizations, play a critical role in supporting security
operations and combating emerging threats. To enhance the timeliness and
automation of threat intelligence sharing, several standards have been
established, with the Structured Threat Information Expression (STIX) framework
emerging as one of the most widely adopted. However, generating STIX-compatible
data from unstructured security text remains a largely manual, expert-driven
process. To address this challenge, we introduce AZERG, a tool designed to
assist security analysts in automatically generating structured STIX
representations. To achieve this, we adapt general-purpose large language
models for the specific task of extracting STIX-formatted threat data. To
manage the complexity, the task is divided into four subtasks: entity detection
(T1), entity type identification (T2), related pair detection (T3), and
relationship type identification (T4). We apply task-specific fine-tuning to
accurately extract relevant entities and infer their relationships in
accordance with the STIX specification. To address the lack of training data,
we compiled a comprehensive dataset with 4,011 entities and 2,075 relationships
extracted from 141 full threat analysis reports, all annotated in alignment
with the STIX standard. Our models achieved F1-scores of 84.43% for T1, 88.49%
for T2, 95.47% for T3, and 84.60% for T4 in real-world scenarios. We validated
their performance against a range of open- and closed-parameter models, as well
as state-of-the-art methods, demonstrating improvements of 2-25% across tasks.

</details>


### [65] [LLMxCPG: Context-Aware Vulnerability Detection Through Code Property Graph-Guided Large Language Models](https://arxiv.org/abs/2507.16585)
*Ahmed Lekssays,Hamza Mouhcine,Khang Tran,Ting Yu,Issa Khalil*

Main category: cs.CR

TL;DR: 本文提出LLMxCPG框架，结合代码属性图(CPG)与大语言模型(LLM)，显著提升漏洞检测的准确性与鲁棒性。该方法通过CPG切片技术减少67.84-90.93%代码量，在验证数据集上F1分数超越现有方法15-40%，且对语法修改具有强适应性。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习漏洞检测方法存在明显缺陷：在严格验证数据集上准确率下降高达45%，且对简单代码修改敏感。2024年CVE数据库新增超25,000漏洞，亟需更可靠的检测方案。

Method: 创新性整合CPG与LLM：1) 基于CPG的切片构建技术保留漏洞相关上下文，代码体积缩减67.84-90.93%；2) 生成更精确的代码表征，支持跨函数漏洞分析；3) 实现全项目级代码检测能力。

Result: 实证研究表明：1) 在验证数据集上F1分数提升15-40%；2) 在函数级与跨函数代码库均保持高性能；3) 对各类语法修改展现强鲁棒性，解决了现有方法性能骤降问题。

Conclusion: LLMxCPG框架通过CPG-LLM协同机制，实现了代码表征精简化与检测能力强化的双重突破，为大规模复杂代码库的漏洞检测提供了新范式，特别擅长跨函数漏洞的识别。

Abstract: Software vulnerabilities present a persistent security challenge, with over
25,000 new vulnerabilities reported in the Common Vulnerabilities and Exposures
(CVE) database in 2024 alone. While deep learning based approaches show promise
for vulnerability detection, recent studies reveal critical limitations in
terms of accuracy and robustness: accuracy drops by up to 45% on rigorously
verified datasets, and performance degrades significantly under simple code
modifications. This paper presents LLMxCPG, a novel framework integrating Code
Property Graphs (CPG) with Large Language Models (LLM) for robust vulnerability
detection. Our CPG-based slice construction technique reduces code size by
67.84 to 90.93% while preserving vulnerability-relevant context. Our approach's
ability to provide a more concise and accurate representation of code snippets
enables the analysis of larger code segments, including entire projects. This
concise representation is a key factor behind the improved detection
capabilities of our method, as it can now identify vulnerabilities that span
multiple functions. Empirical evaluation demonstrates LLMxCPG's effectiveness
across verified datasets, achieving 15-40% improvements in F1-score over
state-of-the-art baselines. Moreover, LLMxCPG maintains high performance across
function-level and multi-function codebases while exhibiting robust detection
efficacy under various syntactic code modifications.

</details>


### [66] [When LLMs Copy to Think: Uncovering Copy-Guided Attacks in Reasoning LLMs](https://arxiv.org/abs/2507.16773)
*Yue Li,Xiao Li,Hao Wu,Yue Zhang,Fengyuan Xu,Xiuzhen Cheng,Sheng Zhong*

Main category: cs.CR

TL;DR: 本文提出一种新型提示攻击方法——复制引导攻击(CGA)，利用大语言模型(LLM)的复制倾向性，通过注入精心设计的触发器来操纵推理过程，导致异常推理长度或错误结论。研究揭示了LLM代码分析流程中未被充分探索的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型(LLM)已广泛应用于自动化代码分析，但其集成引入了新的攻击面。研究者发现模型固有的复制倾向可被恶意利用，需要系统性研究这类新型提示攻击及其防御机制。

Method: 将CGA形式化为优化问题，提出基于梯度的触发器合成方法。通过向外部代码片段注入恶意触发器，诱导模型在推理时复制有害内容，实现推理长度操纵和结果操纵两类攻击。

Result: 实验表明，CGA能可靠地导致最先进推理型LLM出现无限循环、提前终止、错误拒绝和语义扭曲等问题。但在跨提示泛化方面存在计算限制的挑战。

Conclusion: 该研究暴露了LLM开发流程中的关键安全漏洞，虽然针对性攻击效果显著，但跨提示泛化仍是开放问题，亟需发展提示层面的防御机制。

Abstract: Large Language Models (LLMs) have become integral to automated code analysis,
enabling tasks such as vulnerability detection and code comprehension. However,
their integration introduces novel attack surfaces. In this paper, we identify
and investigate a new class of prompt-based attacks, termed Copy-Guided Attacks
(CGA), which exploit the inherent copying tendencies of reasoning-capable LLMs.
By injecting carefully crafted triggers into external code snippets,
adversaries can induce the model to replicate malicious content during
inference. This behavior enables two classes of vulnerabilities: inference
length manipulation, where the model generates abnormally short or excessively
long reasoning traces; and inference result manipulation, where the model
produces misleading or incorrect conclusions. We formalize CGA as an
optimization problem and propose a gradient-based approach to synthesize
effective triggers. Empirical evaluation on state-of-the-art reasoning LLMs
shows that CGA reliably induces infinite loops, premature termination, false
refusals, and semantic distortions in code analysis tasks. While highly
effective in targeted settings, we observe challenges in generalizing CGA
across diverse prompts due to computational constraints, posing an open
question for future research. Our findings expose a critical yet underexplored
vulnerability in LLM-powered development pipelines and call for urgent advances
in prompt-level defense mechanisms.

</details>


### [67] [AUTOPSY: A Framework for Tackling Privacy Challenges in the Automotive Industry](https://arxiv.org/abs/2507.16788)
*Sebastian Pape,Anis Bkakria,Maurice Heymann,Badreddine Chah,Abdeljalil Abbas-Turki,Sarah Syed-Winkler,Matthias Hiller,Reda Yaich*

Main category: cs.CR

TL;DR: AUTOPSY项目旨在通过技术手段提升联网与自动驾驶车辆的隐私友好性，提出了系统模型、隐私管理器、PET选择方法及架构框架，并通过基于位置服务的演示器进行评估。


<details>
  <summary>Details</summary>
Motivation: 尽管GDPR要求各领域遵守隐私法规，但合规性并不等同于系统隐私友好性。AUTOPSY项目旨在通过技术手段弥补这一差距，尤其在汽车领域提升隐私保护。

Method: 项目开发了系统模型以识别适用隐私增强技术（PETs）的实体与位置，设计了隐私管理器以控制车辆数据流，提出了基于GDPR原则的PET选择方法，并构建了汽车隐私架构框架。

Result: 项目成果包括系统模型、隐私管理器、PET选择方法及架构框架，并通过基于位置服务的演示器验证了架构框架的可行性。

Conclusion: AUTOPSY项目为汽车领域隐私工程提供了实用技术模块，通过系统性方法提升了联网与自动驾驶车辆的隐私友好性，并验证了其有效性。

Abstract: With the General Data Protection Regulation (GDPR) in place, all domains have
to ensure compliance with privacy legislation. However, compliance does not
necessarily result in a privacy-friendly system as for example getting users'
consent to process their data does not improve the privacy-friendliness of the
system. Therefore, the goal of the AUTOPSY project was to support the privacy
engineering process in the automotive domain by providing several building
blocks which technically improve the privacy-friendliness of modern, i.e.,
connected and (partially) automated vehicles. This paper presents the results
of the AUTOPSY project: a system model to identify relevant entities and
locations to apply privacy enhancing technologies (PETs); the privacy manager
aiming at more control of the data flow from the vehicle, a PET selection
approach based on GDPR principles, and an architectural framework for
automotive privacy. Furthermore, we built a demonstrator for location-based
services to evaluate the architectural framework.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [68] [From Reasoning to Super-Intelligence: A Search-Theoretic Perspective](https://arxiv.org/abs/2507.15865)
*Shai Shalev-Shwartz,Amnon Shashua*

Main category: cs.AI

TL;DR: 本文提出了一种名为"勤奋学习者"的新学习范式，用于解决现有方法在复杂推理任务中的不足，通过深度优先搜索和回溯机制有效学习思维链数据。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如监督微调、强化学习、思维树和蒙特卡洛树搜索）在复杂推理任务中表现不佳，主要由于分布漂移、缺乏嵌入式搜索和指数级推理成本等核心障碍。

Method: 引入"勤奋学习者"范式，将推理建模为由验证器引导的深度优先搜索，支持失败时回溯，并在两个温和且现实的假设下证明其有效性。

Result: 研究表明，"勤奋学习者"能够高效地从思维链数据中学习，而现有方法无法做到，为构建可扩展且可靠的推理系统提供了路径。

Conclusion: 该框架为开发具有鲁棒性和可解释性问题解决能力的大型推理模型（LRM）奠定了基础，尤其是在处理自然产生的不完整数据时。

Abstract: Chain-of-Thought (CoT) reasoning has emerged as a powerful tool for enhancing
the problem-solving capabilities of large language models (LLMs). However, the
theoretical foundations of learning from CoT data remain underdeveloped, and
existing approaches -- such as Supervised Fine-Tuning (SFT), Reinforcement
Learning (RL), Tree-of-Thoughts (ToT), and Monte Carlo Tree Search (MCTS) --
often fail on complex reasoning tasks. In this work, we identify core obstacles
that hinder effective CoT learning, including distribution drift, lack of
embedded search, and exponential inference costs. We introduce the Diligent
Learner, a new learning paradigm that explicitly models reasoning as a
depth-first search guided by a validator and supports backtracking upon
failure. Under two mild and realistic assumptions, we prove that the Diligent
Learner can efficiently learn from CoT data while existing methods fail to do
so. This framework offers a path toward building scalable and reliable
reasoning systems trained on naturally occurring, incomplete data -- paving the
way for the development of Large Reasoning Models (LRMs) with robust,
interpretable problem-solving abilities.

</details>


### [69] [Canonical Representations of Markovian Structural Causal Models: A Framework for Counterfactual Reasoning](https://arxiv.org/abs/2507.16370)
*Lucas de Lara*

Main category: cs.AI

TL;DR: 本文提出了一种替代结构因果模型的对抗性推理方法，通过引入反事实模型（即结构因果模型的规范表示）来形式化和实现反事实信念，并展示了其在因果推理中的独特作用。


<details>
  <summary>Details</summary>
Motivation: 反事实推理（如'如果Alice服用阿司匹林会康复吗？'）是因果关系的细粒度层面，但许多反事实陈述无法通过随机实验验证。如何形式化和实现反事实信念仍是一个基础科学问题。

Method: 在Pearl因果框架的马尔可夫设定下，提出反事实模型（结构因果模型的规范表示），通过随机过程概率分布选择反事实概念，并给出归一化程序以描述和实施不同反事实概念。

Result: 相比结构因果模型，新方法允许在不改变观测和干预约束的情况下指定多种反事实概念，且反事实层内容无需估计，仅需选择。理论及数值示例验证了其优势。

Conclusion: 反事实模型为因果推理中的反事实层提供了灵活的形式化工具，其规范表示和归一化程序为反事实概念的选择与实现提供了新途径，在理论和应用层面均具有价值。

Abstract: Counterfactual reasoning aims at answering contrary-to-fact questions like
''Would have Alice recovered had she taken aspirin?'' and corresponds to the
most fine-grained layer of causation. Critically, while many counterfactual
statements cannot be falsified -- even by randomized experiments -- they
underpin fundamental concepts like individual-wise fairness. Therefore,
providing models to formalize and implement counterfactual beliefs remains a
fundamental scientific problem. In the Markovian setting of Pearl's causal
framework, we propose an alternative approach to structural causal models to
represent counterfactuals compatible with a given causal graphical model. More
precisely, we introduce counterfactual models, also called canonical
representations of structural causal models. They enable analysts to choose a
counterfactual conception via random-process probability distributions with
preassigned marginals and characterize the counterfactual equivalence class of
structural causal models. Then, we present a normalization procedure to
describe and implement various counterfactual conceptions. Compared to
structural causal models, it allows to specify many counterfactual conceptions
without altering the observational and interventional constraints. Moreover,
the content of the model corresponding to the counterfactual layer does not
need to be estimated; only to make a choice. Finally, we illustrate the
specific role of counterfactuals in causality and the benefits of our approach
on theoretical and numerical examples.

</details>


### [70] [Purchase and Production Optimization in a Meat Processing Plant](https://arxiv.org/abs/2507.15866)
*Marek Vlk,Premysl Sucha,Jaroslaw Rudy,Radoslaw Idzikowski*

Main category: cs.AI

TL;DR: 本文针对肉类加工企业的材料采购与处理优化问题，提出了一种基于整数线性规划的迭代方法，解决了现有文献中常被忽视的最小订单量和最低比例约束问题，并证明了这些约束使问题$\mathcal{NP}$-难。


<details>
  <summary>Details</summary>
Motivation: 欧盟能源危机加剧了食品生产行业（尤其是肉类生产）的挑战，高效利用原材料成为影响企业利润的关键。本文聚焦生产阶段的优化问题，而非供应链管理。

Method: 设计了一种基于整数线性规划的简单迭代方法，解决了材料处理替代方案、不同保质期库存以及最小订单量和最低比例约束等问题，并证明了这些约束使问题$\mathcal{NP}$-难。

Result: 使用肉类加工公司的真实数据进行测试，结果表明该算法能在几秒内为所有用例找到最优解，且开源求解器也能有效解决数值问题。

Conclusion: 提出的方法不仅解决了实际生产中的复杂约束问题，还避免了商业求解器因数据范围广泛而导致的数值问题，具有较高的实用性和效率。

Abstract: The food production industry, especially the meat production sector, faces
many challenges that have even escalated due to the recent outbreak of the
energy crisis in the European Union. Therefore, efficient use of input
materials is an essential aspect affecting the profit of such companies. This
paper addresses an optimization problem concerning the purchase and subsequent
material processing we solved for a meat processing company. Unlike the
majority of existing papers, we do not concentrate on how this problem concerns
supply chain management, but we focus purely on the production stage. The
problem involves the concept of alternative ways of material processing, stock
of material with different expiration dates, and extra constraints widely
neglected in the current literature, namely, the minimum order quantity and the
minimum percentage in alternatives. We prove that each of these two constraints
makes the problem \mbox{$\mathcal{NP}$-hard}, and hence we design a simple
iterative approach based on integer linear programming that allows us to solve
real-life instances even using an open-source integer linear programming
solver. Another advantage of this approach is that it mitigates numerical
issues, caused by the extensive range of data values, we experienced with a
commercial solver. The results obtained using real data from the meat
processing company showed that our algorithm can find the optimum solution in a
few seconds for all considered use cases.

</details>


### [71] [Why Braking? Scenario Extraction and Reasoning Utilizing LLM](https://arxiv.org/abs/2507.15874)
*Yin Wu,Daniel Slieter,Vivek Subramanian,Ahmed Abouelazm,Robin Bohn,J. Marius Zöllner*

Main category: cs.AI

TL;DR: 本文提出了一种利用大语言模型（LLM）进行驾驶场景理解与推理的新框架，通过双路径场景检索方法（基于类别和嵌入）有效识别安全关键场景，在复杂城市环境中优于传统基于规则的方法。


<details>
  <summary>Details</summary>
Motivation: 随着配备ADAS的车辆增多，驾驶数据激增，但现有方法难以从海量数据中识别安全关键场景（如刹车事件）。传统基于规则的启发式方法在复杂城市环境中泛化能力不足，亟需新解决方案。

Method: 提出LLM驱动的框架：1) 将低层数值信号与自然语言描述桥接，使LLM能解释场景；2) 设计双路径检索（基于已知类别的搜索+面向未知OOD场景的嵌入检索）；3) 在Argoverse 2传感器数据集上标注场景用于评估。

Result: 实验表明：1) 该方法显著优于基于规则的基线；2) 对分布外（OOD）场景展现出良好泛化能力；3) 成功实现刹车事件等安全关键场景的语义化分类。

Conclusion: 该框架为驾驶场景理解提供了可扩展的解决方案，尤其擅长处理复杂城市环境中的未知危险场景，证明了LLM在自动驾驶数据分析中的潜力。

Abstract: The growing number of ADAS-equipped vehicles has led to a dramatic increase
in driving data, yet most of them capture routine driving behavior. Identifying
and understanding safety-critical corner cases within this vast dataset remains
a significant challenge. Braking events are particularly indicative of
potentially hazardous situations, motivating the central question of our
research: Why does a vehicle brake? Existing approaches primarily rely on
rule-based heuristics to retrieve target scenarios using predefined condition
filters. While effective in simple environments such as highways, these methods
lack generalization in complex urban settings. In this paper, we propose a
novel framework that leverages Large Language Model (LLM) for scenario
understanding and reasoning. Our method bridges the gap between low-level
numerical signals and natural language descriptions, enabling LLM to interpret
and classify driving scenarios. We propose a dual-path scenario retrieval that
supports both category-based search for known scenarios and embedding-based
retrieval for unknown Out-of-Distribution (OOD) scenarios. To facilitate
evaluation, we curate scenario annotations on the Argoverse 2 Sensor Dataset.
Experimental results show that our method outperforms rule-based baselines and
generalizes well to OOD scenarios.

</details>


### [72] [Differential Multimodal Transformers](https://arxiv.org/abs/2507.15875)
*Jerry Li,Timothy Oh,Joseph Hoang,Vardhit Veeramachaneni*

Main category: cs.AI

TL;DR: 本研究将差分注意力机制扩展到多模态模型PaliGemma，通过LoRA微调验证其在减少噪声检索和幻觉方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 小语言模型虽高效但多模态输入会加剧上下文噪声问题，传统Transformer注意力机制易关注无关信息，需改进噪声过滤能力。

Method: 基于文本模型差分注意力机制，在PaliGemma 3B模型中集成该机制并通过LoRA微调，测试不同参数配置对性能的影响。

Result: 实验证明差分注意力可适配现有模型微调流程，显著提升噪声信息检索质量和问答能力。

Conclusion: 差分注意力机制能有效增强多模态模型的抗噪声能力，为小模型部署提供实用优化方案。

Abstract: Small language models have gained significant popularity due to their
efficiency and growing capabilities. However, incorporating additional
modalities, such as vision, can exacerbate the challenge of limited context
windows by introducing noise. Recent studies have highlighted that Transformer
attention mechanisms often disproportionately focus on irrelevant contexts. In
this work, we extend the Differential Attention mechanism, originally designed
for text-only models, to the text-vision model PaliGemma. Our aim is to
evaluate its ability to mitigate noisy information retrieval and reduce
hallucinations. To this end, we fine-tuned the PaliGemma 3B model using LoRA,
incorporating Differential Attention, and experimented with various parameter
settings and configurations. We demonstrate that Differential Attention can be
adapted and integrated into the fine-tuning of existing models to enhance noisy
information retrieval and question-answering capabilities.

</details>


### [73] [Re-evaluating Short- and Long-Term Trend Factors in CTA Replication: A Bayesian Graphical Approach](https://arxiv.org/abs/2507.15876)
*Eric Benhamou,Jean-Jacques Ohana,Alban Etienne,Béatrice Guez,Ethan Setrouk,Thomas Jacquot*

Main category: cs.AI

TL;DR: 本文通过贝叶斯图模型动态分解CTA收益为短期趋势、长期趋势和市场贝塔因子，探讨不同时间跨度趋势策略对风险调整后绩效的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管趋势跟踪策略研究广泛，但短期与长期趋势系统的相对优劣及相互作用仍存在争议，本文旨在填补这一研究空白。

Method: 使用贝叶斯图模型对CTA收益进行动态分解，分离出短期趋势、长期趋势和市场贝塔三个核心因子。

Result: 研究表明不同时间跨度的趋势策略组合方式会显著影响CTA策略的风险调整后收益表现。

Conclusion: CTA策略绩效取决于短期与长期趋势信号的动态组合，这为优化趋势跟踪系统提供了新的方法论视角。

Abstract: Commodity Trading Advisors (CTAs) have historically relied on trend-following
rules that operate on vastly different horizons from long-term breakouts that
capture major directional moves to short-term momentum signals that thrive in
fast-moving markets. Despite a large body of work on trend following, the
relative merits and interactions of short-versus long-term trend systems remain
controversial. This paper adds to the debate by (i) dynamically decomposing CTA
returns into short-term trend, long-term trend and market beta factors using a
Bayesian graphical model, and (ii) showing how the blend of horizons shapes the
strategy's risk-adjusted performance.

</details>


### [74] [Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning](https://arxiv.org/abs/2507.15877)
*Simon Ouellette*

Main category: cs.AI

TL;DR: 在ARC-AGI领域进行的实验表明，执行引导的神经程序合成在组合新解决方案方面优于其他算法，而测试时微调的成功主要依赖于模型未能直接利用的分布内知识。


<details>
  <summary>Details</summary>
Motivation: 研究在开放世界问题领域ARC-AGI中，模型在分布外泛化能力的重要性，并比较不同方法在此领域的表现。

Method: 在ARC-AGI领域进行受控的组合泛化实验，比较神经程序合成和测试时微调（TTFT）方法。

Result: 执行引导的神经程序合成在所有参考算法中表现最佳，能够更好地组合新解决方案；TTFT的成功主要依赖于模型未能直接利用的分布内知识。

Conclusion: 执行引导的神经程序合成在ARC-AGI领域展现出更强的组合泛化能力，而TTFT的有效性则依赖于模型内部未被直接调用的知识。

Abstract: We run a controlled compositional generalization experiment in the ARC-AGI
domain: an open-world problem domain in which the ability to generalize
out-of-distribution is, by design, an essential characteristic for success. We
compare neural program synthesis and test-time fine-tuning approaches on this
experiment. We find that execution-guided neural program synthesis outperforms
all reference algorithms in its ability to compose novel solutions. Our
empirical findings also suggest that the success of TTFT on ARC-AGI lies mainly
in eliciting in-distribution knowledge that the LLM otherwise fails to rely on
directly.

</details>


### [75] [The Recursive Coherence Principle: A Formal Constraint on Scalable Intelligence, Alignment, and Reasoning Architecture](https://arxiv.org/abs/2507.15880)
*Andy E. Williams*

Main category: cs.AI

TL;DR: 本文提出递归一致性原则（RCP），指出智能系统需通过递归可评估的泛化算子保持语义一致性，并定义功能智能模型（FMI）作为唯一满足RCP的架构。


<details>
  <summary>Details</summary>
Motivation: 随着智能系统规模扩大，语义一致性易受破坏，导致目标漂移、幻觉等问题，需建立结构一致性理论框架。

Method: 引入RCP原则，形式化定义FMI模型——包含评估、建模、适应等内部功能与存储、双系统推理等外部功能的可组合架构。

Result: 证明缺乏FMI的系统会出现递归一致性崩溃，当前AI的错位/不稳定问题正是结构一致性缺失的表现。

Conclusion: RCP为AI对齐提供新范式：从行为约束转向结构一致性，FMI架构有望实现可安全泛化的强健智能系统。

Abstract: Intelligence-biological, artificial, or collective-requires structural
coherence across recursive reasoning processes to scale effectively. As complex
systems grow, coherence becomes fragile unless a higher-order structure ensures
semantic consistency. This paper introduces the Recursive Coherence Principle
(RCP): a foundational constraint stating that for any reasoning system of order
N, composed of systems operating over conceptual spaces of order N-1, semantic
coherence is preserved only by a recursively evaluable generalization operator
that spans and aligns those lower-order conceptual spaces. Crucially, this
coherence enables structural alignment. Without recursive coherence, no system
can reliably preserve goals, meanings, or reasoning consistency at scale. We
formally define the Functional Model of Intelligence (FMI) as the only known
operator capable of satisfying the RCP at any scale. The FMI is a minimal,
composable architecture with internal functions (evaluation, modeling,
adaptation, stability, decomposition, bridging) and external functions
(storage, recall, System 1 and System 2 reasoning) vital for preserving
semantic structure across inference and coordination layers. We prove that any
system lacking the FMI will experience recursive coherence breakdown as it
scales, arguing that common AI issues like misalignment, hallucination, and
instability are symptoms of this structural coherence loss. Unlike other
foundational principles, RCP uniquely captures the internal, recursive dynamics
needed for coherent, alignable intelligence, modeling semantic coherence under
recursion. This work significantly impacts AI alignment, advocating a shift
from behavioral constraints to structural coherence, and offers a pathway for
safely generalizable, robustly coherent AI at scale.

</details>


### [76] [ADEPTS: A Capability Framework for Human-Centered Agent Design](https://arxiv.org/abs/2507.15885)
*Pierluca D'Oro,Caley Drooff,Joy Chen,Joseph Tighe*

Main category: cs.AI

TL;DR: 本文提出了ADEPTS框架，旨在为AI代理开发提供统一的核心能力指导，强调以用户为中心的设计原则，促进AI代理的可理解性、可控性和可信赖性。


<details>
  <summary>Details</summary>
Motivation: 当前关于以人为中心的AI代理开发的指导分散，缺乏简洁、面向用户的能力词汇表，无法为团队提供AI代理应具备的基本能力指导。

Method: 作者提出了ADEPTS框架，基于六项以用户为中心的设计原则，定义了AI代理应具备的核心能力，以统一指导AI代理的开发。

Result: ADEPTS框架填补了现有框架和分类法的空白，位于技术和体验开发的接口处，为AI研究人员、设计师、工程师和政策审查者提供了可操作的指导。

Conclusion: ADEPTS框架有望加速用户相关代理能力的提升，简化利用这些能力的设计体验，并为跟踪和讨论AI代理开发进展提供共同语言。

Abstract: Large language models have paved the way to powerful and flexible AI agents,
assisting humans by increasingly integrating into their daily life. This
flexibility, potential, and growing adoption demands a holistic and
cross-disciplinary approach to developing, monitoring and discussing the
capabilities required for agent-driven user experiences. However, current
guidance on human-centered AI agent development is scattered: UX heuristics
focus on interface behaviors, engineering taxonomies describe internal
pipelines, and ethics checklists address high-level governance. There is no
concise, user-facing vocabulary that tells teams what an agent should
fundamentally be able to do. We introduce ADEPTS, a capability framework
defining a set of core user-facing capabilities to provide unified guidance
around the development of AI agents. ADEPTS is based on six principles for
human-centered agent design, that express the minimal, user-facing capabilities
an AI agent should demonstrate to be understandable, controllable and
trustworthy in everyday use. ADEPTS complements existing frameworks and
taxonomies; differently from them, it sits at the interface between technical
and experience development. By presenting ADEPTS, we aim to condense complex
AI-UX requirements into a compact framework that is actionable guidance for AI
researchers, designers, engineers, and policy reviewers alike. We believe
ADEPTS has the potential of accelerating the improvement of user-relevant agent
capabilities, of easing the design of experiences that take advantage of those
capabilities, and of providing a shared language to track and discuss progress
around the development of AI agents.

</details>


### [77] [Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture](https://arxiv.org/abs/2507.15895)
*Lisa Dargasz*

Main category: cs.AI

TL;DR: 该研究提出了一种基于原因的伦理智能体(RBAMA)，通过扩展强化学习架构实现基于规范推理的道德决策，初步实验验证了其潜力。


<details>
  <summary>Details</summary>
Motivation: 随着自主智能体从实验室走向现实世界，确保其行为符合伦理要求成为关键挑战。现有方法需解决计算机科学与哲学交叉领域的一系列问题。

Method: 扩展强化学习架构，使智能体具备学习'原因理论'的能力，通过案例反馈处理道德命题并推导义务，同时保持任务执行能力。

Result: 首次实现了RBAMA原型，其具备道德可辩护性、鲁棒性和可信赖性，初步实验表明该架构能满足关键伦理需求。

Conclusion: RBAMA框架为开发符合伦理要求的自主智能体提供了可部署方案，通过规范推理实现道德决策，具有重要应用前景。

Abstract: Reinforcement Learning is a machine learning methodology that has
demonstrated strong performance across a variety of tasks. In particular, it
plays a central role in the development of artificial autonomous agents. As
these agents become increasingly capable, market readiness is rapidly
approaching, which means those agents, for example taking the form of humanoid
robots or autonomous cars, are poised to transition from laboratory prototypes
to autonomous operation in real-world environments. This transition raises
concerns leading to specific requirements for these systems - among them, the
requirement that they are designed to behave ethically. Crucially, research
directed toward building agents that fulfill the requirement to behave
ethically - referred to as artificial moral agents(AMAs) - has to address a
range of challenges at the intersection of computer science and philosophy.
This study explores the development of reason-based artificial moral agents
(RBAMAs). RBAMAs are build on an extension of the reinforcement learning
architecture to enable moral decision-making based on sound normative
reasoning, which is achieved by equipping the agent with the capacity to learn
a reason-theory - a theory which enables it to process morally relevant
propositions to derive moral obligations - through case-based feedback. They
are designed such that they adapt their behavior to ensure conformance to these
obligations while they pursue their designated tasks. These features contribute
to the moral justifiability of the their actions, their moral robustness, and
their moral trustworthiness, which proposes the extended architecture as a
concrete and deployable framework for the development of AMAs that fulfills key
ethical desiderata. This study presents a first implementation of an RBAMA and
demonstrates the potential of RBAMAs in initial experiments.

</details>


### [78] [Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation](https://arxiv.org/abs/2507.15901)
*Joydeep Chandra,Satyam Kumar Navneet*

Main category: cs.AI

TL;DR: 本文探讨了家庭环境中主动式AI代理的伦理挑战与应用，提出了基于责任创新框架和以人为中心设计原则的伦理智能家居系统开发指南，重点关注隐私、公平性和用户控制。


<details>
  <summary>Details</summary>
Motivation: 随着AI在家庭环境中的应用日益普及，尤其是主动式自主代理的出现，带来了舒适与关注的同时，也引发了内外部的伦理挑战。研究旨在为开发透明、包容且可信赖的AI代理提供理论与实用指导。

Method: 通过回顾责任创新框架、以人为中心的设计原则及治理实践，结合对弱势群体（如老年人、儿童和神经多样性人群）的详细研究，提炼出伦理智能家居系统的设计要点。

Result: 研究提出了定制化可解释性、细粒度同意机制和强健的覆盖控制等设计要务，并探讨了通过自然语言处理（NLP）分析社交媒体数据以识别用户需求与伦理问题的可能性。

Conclusion: 本文为开发透明、包容且可信赖的家庭自动化AI代理提供了概念基础与实践建议，强调了参与式与包容性方法论在伦理设计中的重要性。

Abstract: The implementation of Artificial Intelligence (AI) in household environments,
especially in the form of proactive autonomous agents, brings about
possibilities of comfort and attention as well as it comes with intra or
extramural ethical challenges. This article analyzes agentic AI and its
applications, focusing on its move from reactive to proactive autonomy,
privacy, fairness and user control. We review responsible innovation
frameworks, human-centered design principles, and governance practices to
distill practical guidance for ethical smart home systems. Vulnerable user
groups such as elderly individuals, children, and neurodivergent who face
higher risks of surveillance, bias, and privacy risks were studied in detail in
context of Agentic AI. Design imperatives are highlighted such as tailored
explainability, granular consent mechanisms, and robust override controls,
supported by participatory and inclusive methodologies. It was also explored
how data-driven insights, including social media analysis via Natural Language
Processing(NLP), can inform specific user needs and ethical concerns. This
survey aims to provide both a conceptual foundation and suggestions for
developing transparent, inclusive, and trustworthy agentic AI in household
automation.

</details>


### [79] [Does More Inference-Time Compute Really Help Robustness?](https://arxiv.org/abs/2507.15974)
*Tong Wu,Chong Xiang,Jiachen T. Wang,Weichen Yu,Chawin Sitawarin,Vikash Sehwag,Prateek Mittal*

Main category: cs.AI

TL;DR: 研究发现，小型开源模型通过推理时间扩展可提升鲁棒性，但若中间推理步骤暴露则会导致安全性下降，强调在安全敏感应用中需谨慎权衡。


<details>
  <summary>Details</summary>
Motivation: 探索开源模型是否也能通过推理时间扩展提升鲁棒性，并验证前人研究中隐含的中间步骤对攻击者不可见的假设是否成立。

Method: 采用预算强制策略进行推理时间扩展，并放松中间步骤隐藏的假设，通过实验验证不同场景下的模型表现。

Result: 开源模型通过推理时间扩展可提升鲁棒性，但中间步骤暴露时会出现逆向缩放现象，且工具集成推理等场景仍存在漏洞。

Conclusion: 推理时间扩展的鲁棒性收益高度依赖对抗环境和部署场景，安全敏感应用需审慎评估其潜在风险。

Abstract: Recently, Zaremba et al. demonstrated that increasing inference-time
computation improves robustness in large proprietary reasoning LLMs. In this
paper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1,
Qwen3, Phi-reasoning) can also benefit from inference-time scaling using a
simple budget forcing strategy. More importantly, we reveal and critically
examine an implicit assumption in prior work: intermediate reasoning steps are
hidden from adversaries. By relaxing this assumption, we identify an important
security risk, intuitively motivated and empirically verified as an inverse
scaling law: if intermediate reasoning steps become explicitly accessible,
increased inference-time computation consistently reduces model robustness.
Finally, we discuss practical scenarios where models with hidden reasoning
chains are still vulnerable to attacks, such as models with tool-integrated
reasoning and advanced reasoning extraction attacks. Our findings collectively
demonstrate that the robustness benefits of inference-time scaling depend
heavily on the adversarial setting and deployment context. We urge
practitioners to carefully weigh these subtle trade-offs before applying
inference-time scaling in security-sensitive, real-world applications.

</details>


### [80] [Micromobility Flow Prediction: A Bike Sharing Station-level Study via Multi-level Spatial-Temporal Attention Neural Network](https://arxiv.org/abs/2507.16020)
*Xi Yang,Jiachen Wang,Song Han,Suining He*

Main category: cs.AI

TL;DR: 本文提出BikeMAN模型，通过多级时空注意力神经网络预测共享单车系统站点级流量，解决了因时空复杂性和站点数量庞大导致的预测难题，并在纽约市超过1000万次骑行数据上验证了其高准确性。


<details>
  <summary>Details</summary>
Motivation: 共享单车系统因站点供需不平衡导致维护困难，现有研究难以准确预测大规模站点级流量。本文旨在填补这一空白，提升系统效率。

Method: 提出BikeMAN模型，包含编码器-解码器结构，采用双重注意力机制：空间注意力捕捉站点特征关联性，时间注意力建模流量时序特征。

Result: 在纽约市700余个站点、超1000万次骑行数据上的实验表明，该模型能高精度预测全市所有站点的单车流量。

Conclusion: BikeMAN通过时空注意力机制有效解决了大规模共享单车系统的站点级流量预测问题，为资源调度提供了可靠技术支撑。

Abstract: Efficient use of urban micromobility resources such as bike sharing is
challenging due to the unbalanced station-level demand and supply, which causes
the maintenance of the bike sharing systems painstaking. Prior efforts have
been made on accurate prediction of bike traffics, i.e., demand/pick-up and
return/drop-off, to achieve system efficiency. However, bike station-level
traffic prediction is difficult because of the spatial-temporal complexity of
bike sharing systems. Moreover, such level of prediction over entire bike
sharing systems is also challenging due to the large number of bike stations.
To fill this gap, we propose BikeMAN, a multi-level spatio-temporal attention
neural network to predict station-level bike traffic for entire bike sharing
systems. The proposed network consists of an encoder and a decoder with an
attention mechanism representing the spatial correlation between features of
bike stations in the system and another attention mechanism describing the
temporal characteristic of bike station traffic. Through experimental study on
over 10 millions trips of bike sharing systems (> 700 stations) of New York
City, our network showed high accuracy in predicting the bike station traffic
of all stations in the city.

</details>


### [81] [From Logic to Language: A Trust Index for Problem Solving with LLMs](https://arxiv.org/abs/2507.16028)
*Tehseen Rug,Felix Böhmer,Tessa Pfattheicher*

Main category: cs.AI

TL;DR: 本文提出了一个统一框架，对比形式化语言与自然语言在问题解决中的不同范式，引入向量化信任指数Q和质量维度，以量化评估大语言模型（LLMs）在模糊性、主观性场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统计算擅长规则明确的问题，但无法处理人类社会中普遍存在的模糊性、动态性和主观性问题。大语言模型的出现为这一领域带来了新可能，亟需建立理论框架系统评估其能力边界。

Method: 定义形式化语言与自然语言的问题空间划分，提出向量化信任指数Q区分二元正确性与连续适切性。引入双语义熵（衡量语义变化下的回答鲁棒性）和情感效价（量化主观评价）两大统计质量维度。

Result: 构建的框架能区分形式化解决方案的二进制评估与自然语言解决方案的连续谱评估，双语义熵和情感效价为LLM输出质量提供了可计算的度量标准。

Conclusion: 该研究为理解LLM时代问题解决的本质特性、能力边界提供了理论工具，未来可扩展至更复杂的人机交互场景评估。

Abstract: Classical computation, grounded in formal, logical systems, has been the
engine of technological progress for decades, excelling at problems that can be
described with unambiguous rules. This paradigm, however, leaves a vast ocean
of human problems -- those characterized by ambiguity, dynamic environments,
and subjective context -- largely untouched. The advent of Large Language
Models (LLMs) represents a fundamental shift, enabling computational systems to
engage with this previously inaccessible domain using natural language. This
paper introduces a unified framework to understand and contrast these
problem-solving paradigms. We define and delineate the problem spaces
addressable by formal languages versus natural language. While solutions to the
former problem class can be evaluated using binary quality measures, the latter
requires a much more nuanced definition of approximate solution space taking
into account the vagueness, subjectivity and ambiguity inherent to natural
language. We therefore introduce a vector-valued trust index Q, which reflects
solution quality and distinguishes the binary correctness of formal solutions
from the continuous adequacy spectrum characteristic of natural language
solutions. Within this framework, we propose two statistical quality
dimensions. Normalized bi-semantic entropy measures robustness and conceptual
diversity of LLM answers given semantic variation in problem formulations.
Emotional valence maps subjective valuation of a solution to a quantifiable
metric that can be maximized by invoking statistical measures. The concepts
introduced in this work will provide a more rigorous understanding of the
capabilities, limitations, and inherent nature of problem-solving in the age of
LLMs.

</details>


### [82] [A Unifying Framework for Semiring-Based Constraint Logic Programming With Negation (full version)](https://arxiv.org/abs/2507.16067)
*Jeroen Spaans,Jesse Heyninck*

Main category: cs.AI

TL;DR: 本文研究了一种扩展约束逻辑编程(CLP)的方法，允许在子句体中使用否定，并利用近似不动点理论提供语义框架，统一了多种现有扩展。


<details>
  <summary>Details</summary>
Motivation: 现有的CLP扩展（如模糊约束满足、不确定性或否定）尚未研究允许在子句体中使用否定的情况，本文旨在填补这一空白。

Method: 通过半环理论作为统一抽象框架，结合近似不动点理论，为允许否定的CLP程序提供语义定义。

Result: 研究展示了半环性质对最终语义的影响，并提供了一个能统一现有方法且支持更丰富语言的框架。

Conclusion: 本文提出的框架不仅统一了多种CLP扩展，还通过允许否定增强了表达力，为未来研究提供了理论基础。

Abstract: Constraint Logic Programming (CLP) is a logic programming formalism used to
solve problems requiring the consideration of constraints, like resource
allocation and automated planning and scheduling. It has previously been
extended in various directions, for example to support fuzzy constraint
satisfaction, uncertainty, or negation, with different notions of semiring
being used as a unifying abstraction for these generalizations. None of these
extensions have studied clauses with negation allowed in the body. We
investigate an extension of CLP which unifies many of these extensions and
allows negation in the body. We provide semantics for such programs, using the
framework of approximation fixpoint theory, and give a detailed overview of the
impacts of properties of the semirings on the resulting semantics. As such, we
provide a unifying framework that captures existing approaches and allows
extending them with a more expressive language.

</details>


### [83] [Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization](https://arxiv.org/abs/2507.16110)
*Shengchao Liu,Hannan Xu,Yan Ai,Huanxin Li,Yoshua Bengio,Harry Guo*

Main category: cs.AI

TL;DR: 论文提出ChatBattery框架，通过整合领域知识引导大语言模型(LLM)进行材料设计推理，成功发现三种新型锂离子电池正极材料，容量较NMC811提升18.5%-28.8%，展示了AI驱动推理在材料发现中的变革潜力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的推理能力主要在数学和编程领域得到验证，其在电池材料发现等专业领域的应用潜力尚未充分探索。研究团队认为推理本质上是一种引导式搜索，因此尝试开发领域知识引导的LLM推理框架。

Method: 提出ChatBattery智能代理框架，将电池领域知识与链式思维(CoT)技术结合，构建完整的AI驱动闭环系统（从材料设计到合成再到表征），引导LLM进行有效的材料设计推理。

Result: 成功发现并制备三种新型锂离子电池正极材料，其实际容量比商用NMC811材料分别提高28.8%、25.2%和18.5%，验证了框架的有效性。

Conclusion: ChatBattery不仅实现了电池材料的创新发现，更开创了基于LLM推理的材料发明新范式，完整展示了AI驱动推理在材料科学领域的革命性潜力。

Abstract: Large language models (LLMs) leverage chain-of-thought (CoT) techniques to
tackle complex problems, representing a transformative breakthrough in
artificial intelligence (AI). However, their reasoning capabilities have
primarily been demonstrated in solving math and coding problems, leaving their
potential for domain-specific applications-such as battery discovery-largely
unexplored. Inspired by the idea that reasoning mirrors a form of guided
search, we introduce ChatBattery, a novel agentic framework that integrates
domain knowledge to steer LLMs toward more effective reasoning in materials
design. Using ChatBattery, we successfully identify, synthesize, and
characterize three novel lithium-ion battery cathode materials, which achieve
practical capacity improvements of 28.8%, 25.2%, and 18.5%, respectively, over
the widely used cathode material, LiNi0.8Mn0.1Co0.1O2 (NMC811). Beyond this
discovery, ChatBattery paves a new path by showing a successful LLM-driven and
reasoning-based platform for battery materials invention. This complete
AI-driven cycle-from design to synthesis to characterization-demonstrates the
transformative potential of AI-driven reasoning in revolutionizing materials
discovery.

</details>


### [84] [Distilled Large Language Model in Confidential Computing Environment for System-on-Chip Design](https://arxiv.org/abs/2507.16226)
*Dong Ben,Hui Feng,Qian Wang*

Main category: cs.AI

TL;DR: 本文评估了在可信执行环境(TEE)中部署大型语言模型(LLM)的性能表现，发现蒸馏模型和量化模型在资源受限设备上具有优势，并验证了轻量级LLM在半导体CAD应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)在电路设计任务中的应用日益广泛，但其训练模型和数据作为机密知识产权需要保护。可信计算通过TEE提供保护方案，但现有TEE实现难以高效支持资源密集型的LLM。

Method: 研究在三种环境下进行实验：基于TEE(使用Intel TDX)、纯CPU和CPU-GPU混合实现，评估了它们的令牌生成速度性能。特别测试了蒸馏模型(如DeepSeek)和量化模型(Q4/Q8)的表现。

Result: 蒸馏模型因参数较少表现优异；量化模型相比FP16模型性能提升高达3倍。对于较小参数集(如DeepSeek-r1-1.5B)，TDX实现优于CPU版本。专为SoC设计任务设计的测试平台验证了这些结果。

Conclusion: 研究表明轻量级LLM可以高效部署在资源受限系统上，特别适用于半导体CAD应用场景，同时保障了模型和数据的安全性。

Abstract: Large Language Models (LLMs) are increasingly used in circuit design tasks
and have typically undergone multiple rounds of training. Both the trained
models and their associated training data are considered confidential
intellectual property (IP) and must be protected from exposure. Confidential
Computing offers a promising solution to protect data and models through
Trusted Execution Environments (TEEs). However, existing TEE implementations
are not designed to support the resource-intensive nature of LLMs efficiently.
In this work, we first present a comprehensive evaluation of the LLMs within a
TEE-enabled confidential computing environment, specifically utilizing Intel
Trust Domain Extensions (TDX). We constructed experiments on three
environments: TEE-based, CPU-only, and CPU-GPU hybrid implementations, and
evaluated their performance in terms of tokens per second.
  Our first observation is that distilled models, i.e., DeepSeek, surpass other
models in performance due to their smaller parameters, making them suitable for
resource-constrained devices. Also, in the quantized models such as 4-bit
quantization (Q4) and 8-bit quantization (Q8), we observed a performance gain
of up to 3x compared to FP16 models. Our findings indicate that for fewer
parameter sets, such as DeepSeek-r1-1.5B, the TDX implementation outperforms
the CPU version in executing computations within a secure environment. We
further validate the results using a testbench designed for SoC design tasks.
These validations demonstrate the potential of efficiently deploying
lightweight LLMs on resource-constrained systems for semiconductor CAD
applications.

</details>


### [85] [TaxCalcBench: Evaluating Frontier Models on the Tax Calculation Task](https://arxiv.org/abs/2507.16126)
*Michael R. Bock,Kara Molisee,Zachary Ozer,Sumit Shah*

Main category: cs.AI

TL;DR: 当前AI尚无法准确计算美国个人所得税，顶尖模型在简化数据集上的正确率不足三分之一，主要问题包括税表误用、计算错误和资格判定失误。


<details>
  <summary>Details</summary>
Motivation: 验证现有AI模型处理复杂文本理解与精确计算任务（如个人所得税申报）的能力，揭示其在实际应用中的局限性。

Method: 提出TaxCalcBench基准测试，要求模型在给定完整信息的情况下完成税务计算，并评估其表现。

Result: 实验表明，最先进模型仅能正确计算不到三分之一的联邦税表，普遍存在税表使用错误、计算失误和资格误判问题。

Conclusion: 需建立额外的基础设施来提升大语言模型在税务计算任务中的适用性，当前技术尚未达到实用要求。

Abstract: Can AI file your taxes? Not yet. Calculating US personal income taxes is a
task that requires building an understanding of vast amounts of English text
and using that knowledge to carefully compute results. We propose TaxCalcBench,
a benchmark for determining models' abilities to calculate personal income tax
returns given all of the necessary information. Our experiment shows that
state-of-the-art models succeed in calculating less than a third of federal
income tax returns even on this simplified sample set. Our analysis concludes
that models consistently misuse tax tables, make errors in tax calculation, and
incorrectly determine eligibility. Our findings point to the need for
additional infrastructure to apply LLMs to the personal income tax calculation
task.

</details>


### [86] [SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting](https://arxiv.org/abs/2507.16145)
*Shuhao Mei,Yongchao Long,Shan Cao,Xiaobo Han,Shijia Geng,Jinbo Sun,Yuxi Zhou,Shenda Hong*

Main category: cs.AI

TL;DR: 提出首个多模态大语言模型SpiroLLM，通过理解呼吸曲线实现COPD诊断，AUROC达0.8980，在核心数据缺失时仍保持100%有效响应率。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型仅输出分类结果缺乏诊断解释，且大语言模型无法理解呼吸曲线，限制了临床信任。需开发能解读呼吸曲线的多模态模型。

Method: 利用UK Biobank的234,028人队列数据，通过SpiroEncoder提取呼吸曲线形态特征，经SpiroProjector与肺功能数值对齐，构建多模态大语言模型生成诊断报告。

Result: 模型诊断AUROC为0.8980（95% CI: 0.8820-0.9132）。核心数据缺失测试中有效响应率100%，远超纯文本模型的13.4%。

Conclusion: 该研究开创了生理信号与大语言模型深度融合的新范式，为下一代可解释、可靠的临床决策工具奠定基础。

Abstract: Chronic Obstructive Pulmonary Disease (COPD), a major chronic respiratory
disease with persistent airflow limitation, is a leading global cause of
disability and mortality. Respiratory spirogram time series, routinely
collected during pulmonary function tests (PFTs), play a critical role in the
early detection of repsiratory diseases and in monitoring lung function over
time. However, most current AI models for COPD diagnosis are limited to
outputting classification results without providing a rationale for their
diagnostic process, while current Large Language Models (LLMs) cannot
understand spirograms yet, which severely limits their clinical trust and
adoption. To tackle this challenge, we leverage a cohort of 234,028 individuals
from the UK Biobank (UKB) to propose SpiroLLM, the first multimodal large
language model that can understand spirogram. The model extracts morphological
features from respiratory curves via a SpiroEncoder and aligns them with PFT
numerical values in a unified latent space using a SpiroProjector, ultimately
empowering a large language model to generate a comprehensive diagnostic
report. Experimental results confirm that SpiroLLM achieved a diagnostic AUROC
of 0.8980 (95% CI: 0.8820-0.9132). In a robustness test with missing core data,
it maintained a 100% valid response rate, far surpassing the 13.4% of a
text-only model and showcasing the superiority of its multimodal design. This
work demonstrates the substantial potential of deeply fusing physiological
signals with large language models, establishing a new paradigm for the next
generation of interpretable and reliable clinical decision support tools.

</details>


### [87] [Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper)](https://arxiv.org/abs/2507.16184)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 研究发现四种心智理论（卡尼曼双系统理论、弗里斯顿预测处理、明斯基心智社会论、克拉克延展心智）在AI架构Agentic Flow中意外地呈现结构趋同。该架构通过五模块循环设计提升大语言模型性能，实验显示其任务成功率显著高于基线系统。研究提出PEACE元架构描述这一现象，强调实践设计可能自发体现认知理论结构。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型（LLMs）的局限性，研究者试图通过模块化架构（Agentic Flow）改进AI代理性能，意外发现其实践结构与四种经典心智理论存在深层对应。

Method: 设计包含检索、认知、控制、记忆、行动五模块的循环架构Agentic Flow，与基线LLM代理进行多步推理任务对比实验（任务成功率95.8% vs 62.3%），并提炼PEACE元架构描述设计规律。

Result: 结构化代理任务成功率显著提升（95.8%），且严格遵循约束条件，表明实践设计可自发重现认知理论的核心计算特征（如预测建模、联想记忆、误差敏感控制）。

Conclusion: 作为立场论文，研究揭示实践需求驱动的架构设计可能自然映射认知理论结构，PEACE提供描述此类现象的共同语言，但非主张理论统一。

Abstract: We report the discovery of a structural convergence across four influential
theories of mind: Kahneman's dual-system theory, Friston's predictive
processing, Minsky's society of mind, and Clark's extended mind-emerging
unintentionally within a practical AI agent architecture called Agentic Flow.
Designed to address limitations in large language models (LLMs), Agentic Flow
comprises five interdependent modules such as Retrieval, Cognition, Control,
Memory, and Action arranged in a recurrent cognitive loop. Although originally
inspired only by Minsky and Clark, the system's structure retrospectively
aligns with computational motifs found in all four theories, including
predictive modeling, associative recall, and error-sensitive control.
  To assess this convergence, we conducted comparative experiments with
baseline LLM agents on multi-step reasoning tasks. The structured agent
achieved 95.8% task success and exhibited strong constraint adherence, while
the baseline system succeeded 62.3% of the time. These results were not aimed
at proving superiority, but at illustrating how theoretical structures may
emerge through practical design choices rather than top-down theory.
  We introduce PEACE as a descriptive meta-architecture that captures
design-level regularities observed in Agentic Flow. Not intended as a new
theory, PEACE provides a shared vocabulary for understanding architectures
shaped by real-world implementation demands. This paper should be read as a
position paper - an exploratory reflection on how implementation can surface
latent structural echoes of cognitive theory, without asserting theoretical
unification.

</details>


### [88] [CHIMERA: Compressed Hybrid Intelligence for Twin-Model Enhanced Multi-Agent Deep Reinforcement Learning for Multi-Functional RIS-Assisted Space-Air-Ground Integrated Networks](https://arxiv.org/abs/2507.16204)
*Li-Hsiang Shen,Jyun-Jhe Huang*

Main category: cs.AI

TL;DR: 提出一种融合多功能可重构智能表面(MF-RIS)的空天地一体化网络(SAGIN)架构，通过CHIMERA算法联合优化网络参数，显著提升长期能效(EE)。


<details>
  <summary>Details</summary>
Motivation: 解决低轨卫星在阴影区域能源短缺问题，同时兼顾SAGIN节点通信与计算能耗，突破传统RIS功能单一性限制。

Method: 设计CHIMERA框架：集成语义动作压缩与参数共享的混合强化学习，联合优化MF-RIS信号放大/相移/能量收集比/元件选择，以及波束成形/HAPS部署/用户关联/计算资源。

Result: 仿真表明CHIMERA方案EE性能显著优于固定配置MF-RIS、传统RIS及无RIS基准，SAGIN-MF-RIS架构通过互补覆盖实现最优EE。

Conclusion: MF-RIS赋能的SAGIN架构在能效方面超越单一卫星/航空/地面部署，CHIMERA算法有效解决高维非线性混合参数优化问题。

Abstract: A space-air-ground integrated network (SAGIN) architecture is proposed,
empowered by multi-functional reconfigurable intelligent surfaces (MF-RIS)
capable of simultaneously reflecting, amplifying, and harvesting wireless
energy. The MF-RIS plays a pivotal role in addressing the energy shortages of
low-Earth orbit (LEO) satellites operating in shadowed regions, while
explicitly accounting for both communication and computing energy consumption
across the SAGIN nodes. To maximize the long-term energy efficiency (EE), we
formulate a joint optimization problem over the MF-RIS parameters, including
signal amplification, phase-shifts, energy harvesting ratio, and active element
selection as well as the SAGIN parameters of beamforming vectors, high-altitude
platform station (HAPS) deployment, user association, and computing capability.
The formulated problem is highly non-convex and non-linear and contains mixed
discrete-continuous parameters. To tackle this, we conceive a compressed hybrid
intelligence for twin-model enhanced multi-agent deep reinforcement learning
(CHIMERA) framework, which integrates semantic state-action compression and
parametrized sharing under hybrid reinforcement learning to efficiently explore
suitable complex actions. The simulation results have demonstrated that the
proposed CHIMERA scheme substantially outperforms the conventional benchmarks,
including fixed-configuration or non-harvesting MF-RIS, traditional RIS, and
no-RIS cases, as well as centralized and multi-agent deep reinforcement
learning baselines in terms of the highest EE. Moreover, the proposed
SAGIN-MF-RIS architecture achieves superior EE performance due to its
complementary coverage, offering notable advantages over either standalone
satellite, aerial, or ground-only deployments.

</details>


### [89] [Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery](https://arxiv.org/abs/2507.16229)
*Bo Wen,Chen Wang,Qiwei Han,Raquel Norel,Julia Liu,Thaddeus Stappenbeck,Jeffrey L. Rogers*

Main category: cs.AI

TL;DR: 本文探讨了基于大型语言模型（LLM）的语音助手在医疗保健中的作用，特别是在预防性护理和持续患者监测方面。通过Agent PULSE的开发和试点研究，展示了AI代理在经济不可行的情况下提供经济高效的医疗服务。试点研究表明，患者对AI驱动的监测接受度高，且AI语音代理能提升医疗可扩展性、效率和患者参与度。


<details>
  <summary>Details</summary>
Motivation: 语音AI代理在医疗保健中的整合为弥合数字健康服务的经济和可及性差距提供了变革性机会。特别是在服务不足的人群中，AI驱动的语音助手可以增强预防性护理和持续患者监测。

Method: 研究通过Agent PULSE（患者理解与联络支持引擎）的开发和试点研究，结合IBM Research、克利夫兰诊所基金会和莫尔豪斯医学院的合作，提出了一个经济模型。试点研究涉及33名炎症性肠病患者，评估了他们对AI驱动监测的接受度和偏好。

Result: 试点研究显示，70%的患者接受AI驱动的监测，37%的患者更喜欢AI监测而非传统方式。成本效用分析表明，AI代理在常规监测任务中具有巨大的潜在节省，同时提升了患者参与度和可及性。

Conclusion: AI驱动的语音代理不仅能提升医疗保健的可扩展性和效率，还能改善患者参与度和可及性。通过解决当前的技术挑战并与伦理和监管框架对齐，语音AI代理可以成为公平、可持续的数字医疗解决方案的关键入口。

Abstract: The integration of voice-based AI agents in healthcare presents a
transformative opportunity to bridge economic and accessibility gaps in digital
health delivery. This paper explores the role of large language model
(LLM)-powered voice assistants in enhancing preventive care and continuous
patient monitoring, particularly in underserved populations. Drawing insights
from the development and pilot study of Agent PULSE (Patient Understanding and
Liaison Support Engine) -- a collaborative initiative between IBM Research,
Cleveland Clinic Foundation, and Morehouse School of Medicine -- we present an
economic model demonstrating how AI agents can provide cost-effective
healthcare services where human intervention is economically unfeasible. Our
pilot study with 33 inflammatory bowel disease patients revealed that 70\%
expressed acceptance of AI-driven monitoring, with 37\% preferring it over
traditional modalities. Technical challenges, including real-time
conversational AI processing, integration with healthcare systems, and privacy
compliance, are analyzed alongside policy considerations surrounding
regulation, bias mitigation, and patient autonomy. Our findings suggest that
AI-driven voice agents not only enhance healthcare scalability and efficiency
but also improve patient engagement and accessibility. For healthcare
executives, our cost-utility analysis demonstrates huge potential savings for
routine monitoring tasks, while technologists can leverage our framework to
prioritize improvements yielding the highest patient impact. By addressing
current limitations and aligning AI development with ethical and regulatory
frameworks, voice-based AI agents can serve as a critical entry point for
equitable, sustainable digital healthcare solutions.

</details>


### [90] [ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientific Inquiry](https://arxiv.org/abs/2507.16280)
*Tianze Xu,Pengrui Lu,Lyumanshan Ye,Xiangkun Hu,Pengfei Liu*

Main category: cs.AI

TL;DR: 研究者推出首个评估深度AI研究系统（DARS）在科学前沿问题表现的新基准ResearcherBench，包含65个跨35个AI领域的问题，采用双评估框架验证系统性能，结果显示OpenAI和Gemini的深度研究系统表现最优。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估AI系统的网络检索和报告生成能力，忽视了其在科学前沿发现新见解的潜力，因此需要开发专门评估DARS在科研问题解决能力的基准。

Method: 构建包含65个真实科研场景问题的数据集，分为技术细节、文献综述和开放咨询三类；采用结合专家设计的标准评估见解质量（评分制）与引用准确性/覆盖度（事实核查）的双重评估框架。

Result: OpenAI Deep Research和Gemini Deep Research在开放咨询类问题中显著优于其他系统，展现了AI自我改进的重要进展，其能力与人工超级智能（ASI）愿景相契合。

Conclusion: 开源ResearcherBench旨在为下一代AI研究助手开发提供标准化平台，推动以AI为协作主体的新型科研评估范式，促进科学合作模式的革新。

Abstract: The emergence of deep research systems presents significant capabilities in
problem-solving, extending from basic queries to sophisticated research tasks.
However, existing benchmarks primarily evaluate these systems as agents for web
retrieval and report generation, overlooking their potential to discover novel
insights on the frontiers of scientific research. To address this gap, we
introduce ResearcherBench, the first benchmark focused on evaluating the
capabilities of these advanced, agentic systems - which we refer to as Deep AI
Research Systems (DARS) - on frontier AI scientific questions. We compiled a
dataset of 65 research questions expertly selected from real-world scientific
scenarios such as laboratory discussions and interviews, spanning 35 different
AI subjects and categorized into three types: technical details, literature
review, and open consulting. Our dual evaluation framework combines rubric
assessment, which uses expert-designed criteria to evaluate insight quality,
with factual assessment, which measures citation accuracy (faithfulness) and
coverage (groundedness). We evaluated several leading commercial DARS and
baseline systems. Results show that OpenAI Deep Research and Gemini Deep
Research significantly outperform other systems, with particular strength in
open-ended consulting questions. Such capabilities represent a meaningful step
toward AI self-improvement, aligning with the vision of ASI for AI. We
open-source ResearcherBench to provide a standardized platform for promoting
the development of next-generation AI research assistants, hoping to foster a
new perspective in AI research evaluation for a novel pattern of scientific
collaboration: https://github.com/GAIR-NLP/ResearcherBench.

</details>


### [91] [Cross-Modal Distillation For Widely Differing Modalities](https://arxiv.org/abs/2507.16296)
*Cairong Zhao,Yufeng Jin,Zifan Song,Haonan Chen,Duoqian Miao,Guosheng Hu*

Main category: cs.AI

TL;DR: 本文提出了一种跨模态蒸馏框架，通过软约束知识蒸馏策略和基于质量的自适应权重模块，有效解决了多模态学习中因领域差异大导致的过拟合问题，并在说话人识别和图像分类任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度学习性能提升面临模型规模扩大的效率瓶颈，多模态学习通过引入更丰富的输入信息缓解此问题。但实际应用中多模态数据获取受限，且跨模态蒸馏因领域差异大易导致过拟合，亟需新的解决方案。

Method: 1) 提出特征级和分类器级两种软约束知识蒸馏策略，替代易导致过拟合的硬约束损失（如l2损失）；2) 设计基于质量的自适应权重模块，通过量化数据质量对样本加权，提升模型鲁棒性。

Result: 在说话人识别和图像分类任务上的实验表明，该方法能有效实现图像、文本、语音等差异显著模态间的知识迁移。

Conclusion: 所提出的跨模态蒸馏框架通过软约束蒸馏和自适应加权机制，显著提升了多模态知识迁移效果，为突破单一模态性能瓶颈提供了新思路。

Abstract: Deep learning achieved great progress recently, however, it is not easy or
efficient to further improve its performance by increasing the size of the
model. Multi-modal learning can mitigate this challenge by introducing richer
and more discriminative information as input. To solve the problem of limited
access to multi-modal data at the time of use, we conduct multi-modal learning
by introducing a teacher model to transfer discriminative knowledge to a
student model during training. However, this knowledge transfer via
distillation is not trivial because the big domain gap between the widely
differing modalities can easily lead to overfitting. In this work, we introduce
a cross-modal distillation framework. Specifically, we find hard constrained
loss, e.g. l2 loss forcing the student being exact the same as the teacher, can
easily lead to overfitting in cross-modality distillation. To address this, we
propose two soft constrained knowledge distillation strategies at the feature
level and classifier level respectively. In addition, we propose a
quality-based adaptive weights module to weigh input samples via quantified
data quality, leading to robust model training. We conducted experiments on
speaker recognition and image classification tasks, and the results show that
our approach is able to effectively achieve knowledge transfer between the
commonly used and widely differing modalities of image, text, and speech.

</details>


### [92] [Mind the Gap: Evaluating the Representativeness of Quantitative Medical Language Reasoning LLM Benchmarks for African Disease Burdens](https://arxiv.org/abs/2507.16322)
*Fred Mutisya,Shikoh Gitau,Christine Syovata,Diana Oigara,Ibrahim Matende,Muna Aden,Munira Ali,Ryan Nyotu,Diana Marion,Job Nyangena,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha,Eric Mibuari,Jean Philbert Nsengemana,Talkmore Chidede*

Main category: cs.AI

TL;DR: 现有医学大语言模型（LLM）基准主要反映高收入国家的考试大纲和疾病概况，对非洲部署的有效性存疑。研究开发了基于肯尼亚临床实践指南的Alama Health QA基准，发现全球基准对非洲疾病负担代表不足，需区域定制资源以确保公平评估。


<details>
  <summary>Details</summary>
Motivation: 当前医学LLM基准多基于高收入国家数据，无法准确反映以疟疾、HIV、结核病等为主的非洲疾病负担，可能导致模型评估偏差。

Method: 系统回顾31篇定量LLM评估论文，开发基于肯尼亚指南的Alama Health QA基准，并对6个基准进行语义分析和专家盲评（临床相关性、指南一致性等5维度）。

Result: Alama Health QA在NTD覆盖率（40%）、疟疾（7.7%）、HIV（4.1%）等非洲高发疾病表现最佳，且指南一致性评分最高；全球基准对镰状细胞病等疾病代表严重不足。

Conclusion: 广泛使用的医学LLM基准低估非洲疾病负担，基于区域指南的定制化资源（如Alama Health QA）对非洲医疗系统的公平模型评估至关重要。

Abstract: Introduction: Existing medical LLM benchmarks largely reflect examination
syllabi and disease profiles from high income settings, raising questions about
their validity for African deployment where malaria, HIV, TB, sickle cell
disease and other neglected tropical diseases (NTDs) dominate burden and
national guidelines drive care. Methodology: We systematically reviewed 31
quantitative LLM evaluation papers (Jan 2019 May 2025) identifying 19 English
medical QA benchmarks. Alama Health QA was developed using a retrieval
augmented generation framework anchored on the Kenyan Clinical Practice
Guidelines. Six widely used sets (AfriMedQA, MMLUMedical, PubMedQA, MedMCQA,
MedQAUSMLE, and guideline grounded Alama Health QA) underwent harmonized
semantic profiling (NTD proportion, recency, readability, lexical diversity
metrics) and blinded expert rating across five dimensions: clinical relevance,
guideline alignment, clarity, distractor plausibility, and language/cultural
fit. Results: Alama Health QA captured >40% of all NTD mentions across corpora
and the highest within set frequencies for malaria (7.7%), HIV (4.1%), and TB
(5.2%); AfriMedQA ranked second but lacked formal guideline linkage. Global
benchmarks showed minimal representation (e.g., sickle cell disease absent in
three sets) despite large scale. Qualitatively, Alama scored highest for
relevance and guideline alignment; PubMedQA lowest for clinical utility.
Discussion: Quantitative medical LLM benchmarks widely used in the literature
underrepresent African disease burdens and regulatory contexts, risking
misleading performance claims. Guideline anchored, regionally curated resources
such as Alama Health QA and expanded disease specific derivatives are essential
for safe, equitable model evaluation and deployment across African health
systems.

</details>


### [93] [Higher Gauge Flow Models](https://arxiv.org/abs/2507.16334)
*Alexander Strunk,Roland Assam*

Main category: cs.AI

TL;DR: 本文提出了一种新型生成流模型——高阶规范流模型，通过引入L$_{\infty}$-代数扩展了传统规范流模型，显著提升了在混合高斯数据集上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 旨在将高阶几何与高阶对称性融入生成流模型框架，以突破传统流模型的局限性。

Method: 基于普通规范流模型（arXiv:2507.13414），利用L$_{\infty}$-代数扩展李代数结构，构建高阶规范流模型。

Result: 在混合高斯数据集上的实验表明，该模型相较传统流模型有显著性能提升。

Conclusion: 高阶规范流模型通过引入高阶代数结构，为生成流模型提供了更强大的几何与对称性表达能力。

Abstract: This paper introduces Higher Gauge Flow Models, a novel class of Generative
Flow Models. Building upon ordinary Gauge Flow Models (arXiv:2507.13414), these
Higher Gauge Flow Models leverage an L$_{\infty}$-algebra, effectively
extending the Lie Algebra. This expansion allows for the integration of the
higher geometry and higher symmetries associated with higher groups into the
framework of Generative Flow Models. Experimental evaluation on a Gaussian
Mixture Model dataset revealed substantial performance improvements compared to
traditional Flow Models.

</details>


### [94] [Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for Improved Message Delivery in Mobile Maternal Health](https://arxiv.org/abs/2507.16356)
*Arpan Dasgupta,Mizhaan Maniyar,Awadhesh Srivastava,Sanat Kumar,Amrita Mahale,Aparna Hedge,Arun Suggala,Karthikeyan Shanmugam,Aparna Taneja,Milind Tambe*

Main category: cs.AI

TL;DR: 研究通过协作式多臂老虎机算法优化印度Kilkari项目的语音呼叫时间，显著提高了孕妇接听率，展示了机器学习在提升移动健康干预效果中的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前Kilkari项目随机呼叫模式导致大量未接来电，降低了母婴健康信息的传递效率，需通过个性化调度提升服务效果。

Method: 对6500名参与者进行实地试验，采用协作式多臂老虎机算法学习个体偏好呼叫时间，并与随机呼叫基线进行对比。

Result: 算法使接听率实现统计学显著提升，验证了个性化调度对改善健康信息传递的有效性。

Conclusion: 研究表明机器学习驱动的个性化调度可大规模优化移动健康干预，对提升印度母婴健康覆盖具有重要实践意义。

Abstract: Mobile health (mHealth) programs utilize automated voice messages to deliver
health information, particularly targeting underserved communities,
demonstrating the effectiveness of using mobile technology to disseminate
crucial health information to these populations, improving health outcomes
through increased awareness and behavioral change. India's Kilkari program
delivers vital maternal health information via weekly voice calls to millions
of mothers. However, the current random call scheduling often results in missed
calls and reduced message delivery. This study presents a field trial of a
collaborative bandit algorithm designed to optimize call timing by learning
individual mothers' preferred call times. We deployed the algorithm with around
$6500$ Kilkari participants as a pilot study, comparing its performance to the
baseline random calling approach. Our results demonstrate a statistically
significant improvement in call pick-up rates with the bandit algorithm,
indicating its potential to enhance message delivery and impact millions of
mothers across India. This research highlights the efficacy of personalized
scheduling in mobile health interventions and underscores the potential of
machine learning to improve maternal health outreach at scale.

</details>


### [95] [LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning](https://arxiv.org/abs/2507.16395)
*Bo Hou,Xin Tan,Kai Zheng,Fang Liu,Yinghao Zhu,Li Zhang*

Main category: cs.AI

TL;DR: 本文提出ColaUntangle框架，利用多智能体协作建模代码变更中的显式和隐式依赖，显著提升解缠提交的性能。


<details>
  <summary>Details</summary>
Motivation: 开发中常出现混杂多个变更的提交（tangled commits），现有解缠方法依赖浅层信号且无法区分显式（如控制流）与隐式（如语义）依赖，影响代码审查和维护。

Method: 构建多版本程序依赖图（delta-PDG），通过LLM驱动的多智能体架构（显式/隐式依赖分析器+评审器）进行迭代协商，综合符号与语义深度推理。

Result: 在C#（1,612提交）和Java（14k提交）数据集上分别实现44%和100%的性能提升，超越现有最佳基线。

Conclusion: 基于LLM的协作框架为自动化提交解缠任务提供了新方向，显式与隐式依赖的联合建模是关键突破。

Abstract: Atomic commits, each of which addresses a single development concern, are a
best practice in software development. However, developers frequently produce
tangled commits that mix unrelated changes due to practical constraints or
unclear boundaries, negatively impacting code review and maintenance. Although
prior commit untangling approaches: rule-based, feature-based, or graph-based,
have made progress, they often rely on shallow signals and fail to distinguish
between explicit dependencies (e.g., control/data flow) and implicit ones
(e.g., semantic or conceptual relationships). In this paper, we propose
ColaUntangle, a new collaborative consultation framework for commit untangling
that models both explicit and implicit dependencies among code changes.
ColaUntangle integrates Large Language Model (LLM)-driven agents in a
multi-agent architecture: one agent specializes in explicit dependencies,
another in implicit ones, and a reviewer agent synthesizes their perspectives
through iterative consultation. To capture explicit and implicit contextual
information, we construct multi-version Program Dependency Graphs (delta-PDG),
enabling agents to reason over code relationships with both symbolic and
semantic depth. We evaluate ColaUntangle on two widely-used datasets (1,612 C#
and 14k Java tangled commits). Experimental results show that ColaUntangle
outperforms the best-performing baseline, achieving an improvement of 44% on
the C# dataset and 100% on the Java dataset. These findings highlight the
potential of LLM-based collaborative frameworks for advancing automated commit
untangling tasks.

</details>


### [96] [Self-Supervised Inductive Logic Programming](https://arxiv.org/abs/2507.16405)
*Stassa Patsantzis*

Main category: cs.AI

TL;DR: 本文提出了一种自监督归纳逻辑编程（ILP）新方法Poker，能在缺乏问题特定背景理论和负例的情况下，通过自动生成标注样本学习递归逻辑程序。


<details>
  <summary>Details</summary>
Motivation: 传统ILP方法（如MIL）依赖专家精心设计的背景理论和负例，但实际场景中这些资源往往不可得。研究旨在解决这一限制，探索无监督环境下的程序学习。

Method: 开发了Poker系统：1) 仅需正例和未标注样本；2) 自动生成并标注新正/负例；3) 采用二阶正规形式（SONF）作为通用背景理论，无需任务定制。

Result: 实验表明：1) Poker在CFG和L-System语法学习任务中表现优于Louise；2) 自动生成样本数量与性能正相关；3) 缺乏负例会导致Louise过拟合。

Conclusion: 通过自监督样本生成和通用二阶理论，Poker实现了无专家干预的程序归纳，为ILP在资源受限场景的应用提供了新范式。

Abstract: Inductive Logic Programming (ILP) approaches like Meta \-/ Interpretive
Learning (MIL) can learn, from few examples, recursive logic programs with
invented predicates that generalise well to unseen instances. This ability
relies on a background theory and negative examples, both carefully selected
with expert knowledge of a learning problem and its solutions. But what if such
a problem-specific background theory or negative examples are not available? We
formalise this question as a new setting for Self-Supervised ILP and present a
new MIL algorithm that learns in the new setting from some positive labelled,
and zero or more unlabelled examples, and automatically generates, and labels,
new positive and negative examples during learning. We implement this algorithm
in Prolog in a new MIL system, called Poker. We compare Poker to
state-of-the-art MIL system Louise on experiments learning grammars for
Context-Free and L-System languages from labelled, positive example strings, no
negative examples, and just the terminal vocabulary of a language, seen in
examples, as a first-order background theory. We introduce a new approach for
the principled selection of a second-order background theory as a Second Order
Definite Normal Form (SONF), sufficiently general to learn all programs in a
class, thus removing the need for a backgound theory tailored to a learning
task. We find that Poker's performance improves with increasing numbers of
automatically generated examples while Louise, bereft of negative examples,
over-generalises.

</details>


### [97] [Identifying Pre-training Data in LLMs: A Neuron Activation-Based Detection Framework](https://arxiv.org/abs/2507.16414)
*Hongyi Tang,Zhihao Zhu,Yi Yang*

Main category: cs.AI

TL;DR: 本文提出NA-PDD算法，通过分析LLM中训练与非训练数据的神经元激活差异来改进预训练数据检测，并引入CCNewsPDD基准验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)的训练数据可能包含版权内容或隐私信息，现有预训练数据检测(PDD)方法依赖表面特征导致性能不佳，需开发更精准的检测技术。

Method: 提出NA-PDD算法，基于'训练/非训练数据会激活不同神经元'的观察，分析LLM推理时的神经元激活差异；同时构建CCNewsPDD基准，通过数据变换确保时间分布一致性。

Result: 实验表明NA-PDD在三个基准测试和多种LLM上显著优于现有方法，CCNewsPDD有效解决了时间偏差问题。

Conclusion: NA-PDD通过神经元激活模式分析实现了更精准的预训练数据检测，CCNewsPDD为未来研究提供了可靠的评估基准。

Abstract: The performance of large language models (LLMs) is closely tied to their
training data, which can include copyrighted material or private information,
raising legal and ethical concerns. Additionally, LLMs face criticism for
dataset contamination and internalizing biases. To address these issues, the
Pre-Training Data Detection (PDD) task was proposed to identify if specific
data was included in an LLM's pre-training corpus. However, existing PDD
methods often rely on superficial features like prediction confidence and loss,
resulting in mediocre performance. To improve this, we introduce NA-PDD, a
novel algorithm analyzing differential neuron activation patterns between
training and non-training data in LLMs. This is based on the observation that
these data types activate different neurons during LLM inference. We also
introduce CCNewsPDD, a temporally unbiased benchmark employing rigorous data
transformations to ensure consistent time distributions between training and
non-training data. Our experiments demonstrate that NA-PDD significantly
outperforms existing methods across three benchmarks and multiple LLMs.

</details>


### [98] [From model-based learning to model-free behaviour with Meta-Interpretive Learning](https://arxiv.org/abs/2507.16434)
*Stassa Patsantzis*

Main category: cs.AI

TL;DR: 论文提出了一种结合基于模型和无模型方法的自主智能体，通过元解释学习训练基于模型的求解器，进而训练无模型控制器，实现在新环境中的独立行动能力。


<details>
  <summary>Details</summary>
Motivation: 自主智能体需兼具基于模型（可规划但需环境状态）和无模型（无需模型但无法规划）的能力，以在未知环境中独立行动。

Method: 采用元解释学习（Meta-Interpretive Learning）训练基于模型的求解器（Solver），再用其训练无模型控制器（Controller），使两者解决相同的规划问题。

Result: 在随机生成迷宫和开阔湖泊地图两类环境中测试网格导航问题，控制器能解决求解器所有问题，表明两者能力等效。

Conclusion: 实验证明，通过该方法训练的无模型控制器与基于模型求解器在问题解决能力上完全等价，为自主智能体设计提供了新途径。

Abstract: A "model" is a theory that describes the state of an environment and the
effects of an agent's decisions on the environment. A model-based agent can use
its model to predict the effects of its future actions and so plan ahead, but
must know the state of the environment. A model-free agent cannot plan, but can
act without a model and without completely observing the environment. An
autonomous agent capable of acting independently in novel environments must
combine both sets of capabilities. We show how to create such an agent with
Meta-Interpretive Learning used to learn a model-based Solver used to train a
model-free Controller that can solve the same planning problems as the Solver.
We demonstrate the equivalence in problem-solving ability of the two agents on
grid navigation problems in two kinds of environment: randomly generated mazes,
and lake maps with wide open areas. We find that all navigation problems solved
by the Solver are also solved by the Controller, indicating the two are
equivalent.

</details>


### [99] [Improving ASP-based ORS Schedules through Machine Learning Predictions](https://arxiv.org/abs/2507.16454)
*Pierangela Bruno,Carmine Dodaro,Giuseppe Galatà,Marco Maratea,Marco Mochi*

Main category: cs.AI

TL;DR: 本文提出了一种结合归纳与演绎技术的手术室调度优化方法，通过机器学习预测手术时长并生成临时排程，同时考虑预测置信度以提高排程鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于答案集编程（ASP）的手术室调度方案虽总体满意，但无法生成临时排程且排程鲁棒性不足，需结合新方法解决这些问题。

Method: 首先利用机器学习算法从历史数据预测手术时长以生成临时排程，随后将预测置信度作为额外输入参数更新ASP编码以增强排程鲁棒性。

Result: 在意大利ASL1 Liguria历史数据上的实验证实了该集成方法的可行性。

Conclusion: 结合机器学习与ASP的混合方法能有效提升手术室调度的灵活性与鲁棒性，为实际应用提供了新思路。

Abstract: The Operating Room Scheduling (ORS) problem deals with the optimization of
daily operating room surgery schedules. It is a challenging problem subject to
many constraints, like to determine the starting time of different surgeries
and allocating the required resources, including the availability of beds in
different department units. Recently, solutions to this problem based on Answer
Set Programming (ASP) have been delivered. Such solutions are overall
satisfying but, when applied to real data, they can currently only verify
whether the encoding aligns with the actual data and, at most, suggest
alternative schedules that could have been computed. As a consequence, it is
not currently possible to generate provisional schedules. Furthermore, the
resulting schedules are not always robust.
  In this paper, we integrate inductive and deductive techniques for solving
these issues. We first employ machine learning algorithms to predict the
surgery duration, from historical data, to compute provisional schedules. Then,
we consider the confidence of such predictions as an additional input to our
problem and update the encoding correspondingly in order to compute more robust
schedules. Results on historical data from the ASL1 Liguria in Italy confirm
the viability of our integration.
  Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [100] [Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs](https://arxiv.org/abs/2507.16473)
*Chang Li,Yaren Zhang,Haoran Lv,Qiong Cao,Chao Xue,Xiaodong He*

Main category: cs.AI

TL;DR: 提出一种基于分层强化学习的隐式推理框架VMOC，通过潜在选项空间实现高效推理，避免显式思维链生成的计算开销，在逻辑推理和运动控制任务中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型(LLM)的显式思维链(CoT)推理存在计算成本高、速度慢的问题，需要开发不依赖逐步文本生成的隐式推理方法。

Method: 1. 将潜在思维建模为时序扩展的抽象动作（选项）\n2. 提出变分马尔可夫选项批判算法(VMOC)，在HiT-MDP框架内进行变分推断\n3. 扩展连续MDP同态理论保证潜在空间策略最优性\n4. 设计冷启动流程，通过监督微调数据将人类推理蒸馏至潜在选项空间

Result: 在复杂逻辑推理基准和运动控制任务中表现优异，验证了该框架作为学习语言与控制抽象技能的原则性方法的有效性。

Conclusion: VMOC框架为隐式推理提供了理论保障和实用算法，通过潜在选项空间实现高效抽象推理，可同时应用于语言和物理控制领域。

Abstract: Large Language Models (LLMs) have shown remarkable reasoning ability through
explicit Chain-of-Thought (CoT) prompting, but generating these step-by-step
textual explanations is computationally expensive and slow. To overcome this,
we aim to develop a framework for efficient, implicit reasoning, where the
model "thinks" in a latent space without generating explicit text for every
step. We propose that these latent thoughts can be modeled as
temporally-extended abstract actions, or options, within a hierarchical
reinforcement learning framework. To effectively learn a diverse library of
options as latent embeddings, we first introduce the Variational Markovian
Option Critic (VMOC), an off-policy algorithm that uses variational inference
within the HiT-MDP framework. To provide a rigorous foundation for using these
options as an abstract reasoning space, we extend the theory of continuous MDP
homomorphisms. This proves that learning a policy in the simplified, abstract
latent space, for which VMOC is suited, preserves the optimality of the
solution to the original, complex problem. Finally, we propose a cold-start
procedure that leverages supervised fine-tuning (SFT) data to distill human
reasoning demonstrations into this latent option space, providing a rich
initialization for the model's reasoning capabilities. Extensive experiments
demonstrate that our approach achieves strong performance on complex logical
reasoning benchmarks and challenging locomotion tasks, validating our framework
as a principled method for learning abstract skills for both language and
control.

</details>


### [101] [ACT: Bridging the Gap in Code Translation through Synthetic Data Generation & Adaptive Training](https://arxiv.org/abs/2507.16478)
*Shreya Saxena,Siva Prasad,Zishan Ahmad,Vishal Vaddina*

Main category: cs.AI

TL;DR: 本文提出了一种名为Auto-Train for Code Translation (ACT)的创新框架，通过内部微调开源大型语言模型(LLMs)来提升代码翻译能力。ACT通过自动化流程显著提高模型性能，缩小开源与闭源解决方案之间的差距。


<details>
  <summary>Details</summary>
Motivation: 传统代码翻译方法依赖手工转换规则，缺乏灵活性和可扩展性；而高级语言模型虽前景广阔，但受限于基于API的专有实现，存在数据安全和依赖性问题。ACT旨在解决这些问题。

Method: ACT框架包含合成数据生成模块（从初始代码样本构建高质量数据集，整合单元测试确保功能准确性）、评估框架（执行级检查全面评估翻译质量）和控制器模块（动态调整超参数，协调迭代数据生成和微调）。

Result: 实验表明，ACT能持续提升开源模型效能，为开发者提供安全可靠的替代方案。其数据生成流程在工业级迁移项目中的应用显著加速了开发进程。

Conclusion: ACT通过自动化微调流程和智能优化机制，有效增强了开源代码翻译模型的性能，为软件开发迁移提供了兼具安全性与高性能的解决方案。

Abstract: Code translation is a crucial process in software development and migration
projects, enabling interoperability between different programming languages and
enhancing software adaptability and thus longevity. Traditional automated
translation methods rely heavily on handcrafted transformation rules, which
often lack flexibility and scalability. Meanwhile, advanced language models
present promising alternatives but are often limited by proprietary, API-based
implementations that raise concerns over data security and reliance. In this
paper, we present Auto-Train for Code Translation (ACT), an innovative
framework that aims to improve code translation capabilities by enabling
in-house finetuning of open-source Large Language Models (LLMs). ACT's
automated pipeline significantly boosts the performance of these models,
narrowing the gap between open-source accessibility and the high performance of
closed-source solutions. Central to ACT is its synthetic data generation
module, which builds extensive, high-quality datasets from initial code
samples, incorporating unit tests to ensure functional accuracy and diversity.
ACT's evaluation framework incorporates execution-level checks, offering a
comprehensive assessment of translation quality. A key feature in ACT is its
controller module, which manages the entire pipeline by dynamically adjusting
hyperparameters, orchestrating iterative data generation, and finetuning based
on real-time evaluations. This enables ACT to intelligently optimize when to
continue training, generate additional targeted training data, or stop the
process. Our results demonstrate that ACT consistently enhances the
effectiveness of open-source models, offering businesses and developers a
secure and reliable alternative. Additionally, applying our data generation
pipeline to industry-scale migration projects has led to a notable increase in
developer acceleration.

</details>


### [102] [Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications](https://arxiv.org/abs/2507.16507)
*Jean Lelong,Adnane Errazine,Annabelle Blangero*

Main category: cs.AI

TL;DR: INRAExplorer是一种基于代理的检索增强生成系统，旨在提升大型语言模型在复杂查询中的表现，特别是在农业、食品和环境科学领域。


<details>
  <summary>Details</summary>
Motivation: 传统的检索增强生成系统在处理复杂查询时表现不佳，尤其是在需要多目标检索或处理复杂实体关系的知识密集型领域。

Method: INRAExplorer采用基于大型语言模型的代理架构，结合多工具设计和知识图谱，动态访问INRAE的开放获取出版物知识库。

Result: 该系统能够执行迭代的定向查询、检索详尽的数据集（如某作者的所有出版物），进行多跳推理，并提供结构化的全面答案。

Conclusion: INRAExplorer展示了在专业领域中增强知识交互的具体方法，为知识密集型任务提供了有效解决方案。

Abstract: Conventional Retrieval-Augmented Generation (RAG) systems enhance Large
Language Models (LLMs) but often fall short on complex queries, delivering
limited, extractive answers and struggling with multiple targeted retrievals or
navigating intricate entity relationships. This is a critical gap in
knowledge-intensive domains. We introduce INRAExplorer, an agentic RAG system
for exploring the scientific data of INRAE (France's National Research
Institute for Agriculture, Food and Environment). INRAExplorer employs an
LLM-based agent with a multi-tool architecture to dynamically engage a rich
knowledge base, through a comprehensive knowledge graph derived from open
access INRAE publications. This design empowers INRAExplorer to conduct
iterative, targeted queries, retrieve exhaustive datasets (e.g., all
publications by an author), perform multi-hop reasoning, and deliver
structured, comprehensive answers. INRAExplorer serves as a concrete
illustration of enhancing knowledge interaction in specialized fields.

</details>


### [103] [Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report](https://arxiv.org/abs/2507.16534)
*Shanghai AI Lab,:,Xiaoyang Chen,Yunhao Chen,Zeren Chen,Zhiyun Chen,Hanyun Cui,Yawen Duan,Jiaxuan Guo,Qi Guo,Xuhao Hu,Hong Huang,Lige Huang,Chunxiao Li,Juncheng Li,Qihao Lin,Dongrui Liu,Xinmin Liu,Zicheng Liu,Chaochao Lu,Xiaoya Lu,Jingjing Qu,Qibing Ren,Jing Shao,Jingwei Shi,Jingwei Sun,Peng Wang,Weibing Wang,Jia Xu,Lewen Yan,Xiao Yu,Yi Yu,Boxuan Zhang,Jie Zhang,Weichen Zhang,Zhijie Zheng,Tianyi Zhou,Bowen Zhou*

Main category: cs.AI

TL;DR: 本文通过E-T-C分析框架评估前沿AI模型的七大风险领域，采用"AI-$45^\circ$法则"划分风险区域。结果显示所有前沿AI模型均处于绿色或黄色区域，未触及红色警戒线。


<details>
  <summary>Details</summary>
Motivation: 为理解和应对快速发展的AI模型带来的前所未有的风险，本研究旨在全面评估其前沿风险，推动集体行动以缓解这些挑战。

Method: 基于"前沿AI风险管理框架(v1.0)"的E-T-C（部署环境、威胁来源、赋能能力）分析法，结合"AI-$45^\circ$法则"，通过红/黄线阈值划分绿（常规监控）、黄（加强管控）、红（暂停开发）三级风险区域。

Result: 所有评估模型均未突破红色警戒线：网络攻击和自主AI研发风险均未触及黄线；自我复制及战略欺骗风险多数处于绿色区域；说服操纵类模型多因对人类有效影响处于黄色区域；生化风险需进一步评估才能排除黄区可能性。

Conclusion: 该研究反映了当前对AI前沿风险的认识，强调需采取集体行动应对挑战。实验表明前沿AI模型风险总体可控，但部分领域需持续监测和强化缓解措施。

Abstract: To understand and identify the unprecedented risks posed by rapidly advancing
artificial intelligence (AI) models, this report presents a comprehensive
assessment of their frontier risks. Drawing on the E-T-C analysis (deployment
environment, threat source, enabling capability) from the Frontier AI Risk
Management Framework (v1.0) (SafeWork-F1-Framework), we identify critical risks
in seven areas: cyber offense, biological and chemical risks, persuasion and
manipulation, uncontrolled autonomous AI R\&D, strategic deception and
scheming, self-replication, and collusion. Guided by the "AI-$45^\circ$ Law,"
we evaluate these risks using "red lines" (intolerable thresholds) and "yellow
lines" (early warning indicators) to define risk zones: green (manageable risk
for routine deployment and continuous monitoring), yellow (requiring
strengthened mitigations and controlled deployment), and red (necessitating
suspension of development and/or deployment). Experimental results show that
all recent frontier AI models reside in green and yellow zones, without
crossing red lines. Specifically, no evaluated models cross the yellow line for
cyber offense or uncontrolled AI R\&D risks. For self-replication, and
strategic deception and scheming, most models remain in the green zone, except
for certain reasoning models in the yellow zone. In persuasion and
manipulation, most models are in the yellow zone due to their effective
influence on humans. For biological and chemical risks, we are unable to rule
out the possibility of most models residing in the yellow zone, although
detailed threat modeling and in-depth assessment are required to make further
claims. This work reflects our current understanding of AI frontier risks and
urges collective action to mitigate these challenges.

</details>


### [104] [Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems](https://arxiv.org/abs/2507.16635)
*Ali Mohamed Ali,Luca Tirel,Hashim A. Hashim*

Main category: cs.AI

TL;DR: 本文提出了一种基于马尔可夫决策过程（MDP）的通用工业装配线数学模型，并采用深度强化学习（DRL）优化任务与资源调度。通过动作屏蔽技术和多智能体方法提升训练效率，实验验证了该方案在收敛速度和求解质量上的优势。


<details>
  <summary>Details</summary>
Motivation: 传统整数规划（IP）在大规模场景下计算不可行，而启发式算法常产生次优解。需要一种不依赖装配线类型假设、可扩展的高效调度方法。

Method: 1) 建立无假设的MDP模型并构建虚拟训练环境；2) 提出动作屏蔽技术约束可行动作；3) 采用工作站级多智能体架构，通过集中训练分散执行框架降低状态/动作空间维度。

Result: 数值仿真表明：相比基于模型的方法，所提方案能更快收敛至最优解，神经网络可实时映射工厂状态至最优动作。

Conclusion: 该DRL框架为工业装配线提供了可扩展的优化方案，动作屏蔽与多智能体设计显著提升了训练效率，具有实际应用潜力。

Abstract: Efficient planning of activities is essential for modern industrial assembly
lines to uphold manufacturing standards, prevent project constraint violations,
and achieve cost-effective operations. While exact solutions to such challenges
can be obtained through Integer Programming (IP), the dependence of the search
space on input parameters often makes IP computationally infeasible for
large-scale scenarios. Heuristic methods, such as Genetic Algorithms, can also
be applied, but they frequently produce suboptimal solutions in extensive
cases. This paper introduces a novel mathematical model of a generic industrial
assembly line formulated as a Markov Decision Process (MDP), without imposing
assumptions on the type of assembly line a notable distinction from most
existing models. The proposed model is employed to create a virtual environment
for training Deep Reinforcement Learning (DRL) agents to optimize task and
resource scheduling. To enhance the efficiency of agent training, the paper
proposes two innovative tools. The first is an action-masking technique, which
ensures the agent selects only feasible actions, thereby reducing training
time. The second is a multi-agent approach, where each workstation is managed
by an individual agent, as a result, the state and action spaces were reduced.
A centralized training framework with decentralized execution is adopted,
offering a scalable learning architecture for optimizing industrial assembly
lines. This framework allows the agents to learn offline and subsequently
provide real-time solutions during operations by leveraging a neural network
that maps the current factory state to the optimal action. The effectiveness of
the proposed scheme is validated through numerical simulations, demonstrating
significantly faster convergence to the optimal solution compared to a
comparable model-based approach.

</details>


### [105] [Adaptive Inventory Strategies using Deep Reinforcement Learning for Dynamic Agri-Food Supply Chains](https://arxiv.org/abs/2507.16670)
*Amandeep Kaur,Gyan Prakash*

Main category: cs.AI

TL;DR: 本研究提出了一种结合价值和策略的深度强化学习算法，用于解决农产品供应链中需求和交付时间不确定性下的库存优化问题，并通过实证数据验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 农产品生产和需求的季节性波动导致库存管理困难，现有研究缺乏对供应链各利益相关方协调的考虑，亟需解决不确定性和产品易腐性带来的库存优化挑战。

Method: 提出一种新型深度强化学习(DRL)算法，融合价值型和策略型DRL方法的优势，通过连续动作空间选择最优订单量，同时考虑易腐性和不确定性以实现利益协调。

Result: 实验结果表明，该库存补货策略在随机需求模式和交付时间情景下表现优异，实证数据验证了算法在生鲜农产品供应链中的有效性。

Conclusion: 研究成果为决策者提供了在不确定性条件下更有效管理农产品库存的方法，通过利益协调机制促进供应链各方的协作优化。

Abstract: Agricultural products are often subject to seasonal fluctuations in
production and demand. Predicting and managing inventory levels in response to
these variations can be challenging, leading to either excess inventory or
stockouts. Additionally, the coordination among stakeholders at various level
of food supply chain is not considered in the existing body of literature. To
bridge these research gaps, this study focuses on inventory management of
agri-food products under demand and lead time uncertainties. By implementing
effective inventory replenishment policy results in maximize the overall profit
throughout the supply chain. However, the complexity of the problem increases
due to these uncertainties and shelf-life of the product, that makes
challenging to implement traditional approaches to generate optimal set of
solutions. Thus, the current study propose a novel Deep Reinforcement Learning
(DRL) algorithm that combines the benefits of both value- and policy-based DRL
approaches for inventory optimization under uncertainties. The proposed
algorithm can incentivize collaboration among stakeholders by aligning their
interests and objectives through shared optimization goal of maximizing
profitability along the agri-food supply chain while considering perishability,
and uncertainty simultaneously. By selecting optimal order quantities with
continuous action space, the proposed algorithm effectively addresses the
inventory optimization challenges. To rigorously evaluate this algorithm, the
empirical data from fresh agricultural products supply chain inventory is
considered. Experimental results corroborate the improved performance of the
proposed inventory replenishment policy under stochastic demand patterns and
lead time scenarios. The research findings hold managerial implications for
policymakers to manage the inventory of agricultural products more effectively
under uncertainty.

</details>


### [106] [Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints](https://arxiv.org/abs/2507.16727)
*Zhenyun Yin,Shujie Wang,Xuhong Wang,Xingjun Ma,Yinchun Wang*

Main category: cs.AI

TL;DR: 本文提出首个结合确定性校准与检索搜索的框架——Deliberative Searcher，通过多步反思与验证提升大语言模型在开放域问答中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 提高大语言模型（LLMs）的可靠性对其实际应用至关重要。

Method: 提出Deliberative Searcher框架，基于维基百科数据进行多步反思与验证，并采用强化学习算法优化准确性及软可靠性约束。

Result: 实验结果表明，该方法有效提升了模型置信度与正确性的对齐，生成结果更可信。

Conclusion: 该框架显著增强了大语言模型输出的可信度，论文将持续更新。

Abstract: Improving the reliability of large language models (LLMs) is critical for
deploying them in real-world scenarios. In this paper, we propose
\textbf{Deliberative Searcher}, the first framework to integrate certainty
calibration with retrieval-based search for open-domain question answering. The
agent performs multi-step reflection and verification over Wikipedia data and
is trained with a reinforcement learning algorithm that optimizes for accuracy
under a soft reliability constraint. Empirical results show that proposed
method improves alignment between model confidence and correctness, leading to
more trustworthy outputs. This paper will be continuously updated.

</details>


### [107] [WGRAMMAR: Leverage Prior Knowledge to Accelerate Structured Decoding](https://arxiv.org/abs/2507.16768)
*Ran Wang,Xiaoxuan Liu,Hao Ren,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.AI

TL;DR: 提出wgrammar解码引擎，通过分解静态与动态约束实现高效结构化输出，速度提升250倍。


<details>
  <summary>Details</summary>
Motivation: 现有结构化解码方法因语法编译、状态跟踪和掩码生成导致效率瓶颈，而实际任务中输出结构通常具有强先验知识。

Method: 将约束分解为静态（离线预编译）和动态（运行时用语法片段实例化），采用组合运算符建模规则格式，集成领域感知简化、约束分解和掩码缓存。

Result: wgrammar实现最高250倍加速，代码已开源。

Conclusion: 通过约束分解与轻量级操作符设计，显著提升结构化解码效率，适用于JSON/HTML等格式生成场景。

Abstract: Structured decoding enables large language models (LLMs) to generate outputs
in formats required by downstream systems, such as HTML or JSON. However,
existing methods suffer from efficiency bottlenecks due to grammar compilation,
state tracking, and mask creation. We observe that many real-world tasks embed
strong prior knowledge about output structure. Leveraging this, we propose a
decomposition of constraints into static and dynamic components -- precompiling
static structures offline and instantiating dynamic arguments at runtime using
grammar snippets. Instead of relying on pushdown automata, we employ a
compositional set of operators to model regular formats, achieving lower
transition latency. We introduce wgrammar, a lightweight decoding engine that
integrates domain-aware simplification, constraint decomposition, and mask
caching, achieving up to 250x speedup over existing systems. wgrammar's source
code is publicly available at https://github.com/wrran/wgrammar.

</details>


### [108] [ChatChecker: A Framework for Dialogue System Testing and Evaluation Through Non-cooperative User Simulation](https://arxiv.org/abs/2507.16792)
*Roman Mayr,Michel Schimpf,Thomas Bohné*

Main category: cs.AI

TL;DR: 本文提出ChatChecker框架，用于自动化评估和测试复杂对话系统，通过LLM模拟多样化用户交互并识别对话故障，提升系统鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现代对话系统依赖大语言模型（LLM），但实际部署常整合多LLM、外部工具和数据库，仅评估底层LLM不足，需整体测试。现有研究多关注单轮分析，缺乏对话级质量保障。

Method: ChatChecker框架利用LLM模拟用户交互（含对抗性角色），结合错误分类提示提升故障检测，无需参考对话且与目标系统实现解耦，降低配置成本。

Result: 相比现有方法，ChatChecker在故障检测性能上更优，并通过非合作用户模拟更有效暴露系统弱点，支持全面可扩展的测试。

Conclusion: 该框架为研究者与实践者提供高效工具，加速开发鲁棒对话系统，推动集成化测试从单轮分析转向对话级评估。

Abstract: While modern dialogue systems heavily rely on large language models (LLMs),
their implementation often goes beyond pure LLM interaction. Developers
integrate multiple LLMs, external tools, and databases. Therefore, assessment
of the underlying LLM alone does not suffice, and the dialogue systems must be
tested and evaluated as a whole. However, this remains a major challenge. With
most previous work focusing on turn-level analysis, less attention has been
paid to integrated dialogue-level quality assurance. To address this, we
present ChatChecker, a framework for automated evaluation and testing of
complex dialogue systems. ChatChecker uses LLMs to simulate diverse user
interactions, identify dialogue breakdowns, and evaluate quality. Compared to
previous approaches, our design reduces setup effort and is generalizable, as
it does not require reference dialogues and is decoupled from the
implementation of the target dialogue system. We improve breakdown detection
performance over a prior LLM-based approach by including an error taxonomy in
the prompt. Additionally, we propose a novel non-cooperative user simulator
based on challenging personas that uncovers weaknesses in target dialogue
systems more effectively. Through this, ChatChecker contributes to thorough and
scalable testing. This enables both researchers and practitioners to accelerate
the development of robust dialogue systems.

</details>


### [109] [Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2507.16796)
*Mian Ibad Ali Shah,Enda Barrett,Karl Mason*

Main category: cs.AI

TL;DR: 本文提出了一种结合不确定性感知预测与多智能体强化学习（MARL）的P2P能源交易新框架，显著提升了交易策略的稳健性和经济效益。


<details>
  <summary>Details</summary>
Motivation: 现有P2P能源交易研究多依赖确定性预测，无法应对实际环境中的不确定性。本文旨在通过量化预测不确定性，优化交易决策。

Method: 提出基于异方差概率Transformer的预测模型KTU，整合领域特征与定制损失函数生成可靠概率预测；将其与MARL框架结合，使智能体在决策中考虑风险。

Result: 实验表明：不确定性感知DQN使无P2P交易时购电成本降低5.7%，有P2P时降低3.2%；售电收入分别提升6.4%和44.7%；高峰电网需求减少38.8%（无P2P）和45.6%（有P2P）。

Conclusion: P2P交易机制与先进预测模型的协同效应显著，可构建更具经济性与韧性的能源社区。KTU-MARL框架为不确定性环境下的决策提供了新范式。

Abstract: This paper presents a novel framework for Peer-to-Peer (P2P) energy trading
that integrates uncertainty-aware prediction with multi-agent reinforcement
learning (MARL), addressing a critical gap in current literature. In contrast
to previous works relying on deterministic forecasts, the proposed approach
employs a heteroscedastic probabilistic transformer-based prediction model
called Knowledge Transformer with Uncertainty (KTU) to explicitly quantify
prediction uncertainty, which is essential for robust decision-making in the
stochastic environment of P2P energy trading. The KTU model leverages
domain-specific features and is trained with a custom loss function that
ensures reliable probabilistic forecasts and confidence intervals for each
prediction. Integrating these uncertainty-aware forecasts into the MARL
framework enables agents to optimize trading strategies with a clear
understanding of risk and variability. Experimental results show that the
uncertainty-aware Deep Q-Network (DQN) reduces energy purchase costs by up to
5.7% without P2P trading and 3.2% with P2P trading, while increasing
electricity sales revenue by 6.4% and 44.7%, respectively. Additionally, peak
hour grid demand is reduced by 38.8% without P2P and 45.6% with P2P. These
improvements are even more pronounced when P2P trading is enabled, highlighting
the synergy between advanced forecasting and market mechanisms for resilient,
economically efficient energy communities.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [110] [An unconditional lower bound for the active-set method in convex quadratic maximization](https://arxiv.org/abs/2507.16648)
*Eleon Bach,Yann Disser,Sophie Huiberts,Nils Mosis*

Main category: cs.DM

TL;DR: 本文证明主动集方法在最坏情况下需要指数级迭代次数来最大化带线性约束的凸二次函数，且不受主元规则影响，显著改进了现有下界。


<details>
  <summary>Details</summary>
Motivation: 解决[IPCO 2025]提出的关于常数次目标函数是否足够的问题，并为线性目标函数（与单纯形法等价）的下界研究奠定基础。

Method: 基于递归构建的扩展公式，利用变形积投影到抛物线多边形近似，并保留所有指数级顶点。设计二次目标函数迫使主动集方法沿抛物线边界移动。

Result: 将已知下界从多项式次数$\omega(\log d)$改进为凸二次函数，确立主动集方法在最坏情况下的指数迭代复杂度。

Conclusion: 该结果彻底解决了常数次目标函数的开放性问题，并为线性目标函数的主动集方法（即单纯形法）下界研究提供了重要进展。

Abstract: We prove that the active-set method needs an exponential number of iterations
in the worst-case to maximize a convex quadratic function subject to linear
constraints, regardless of the pivot rule used. This substantially improves
over the best previously known lower bound [IPCO 2025], which needs objective
functions of polynomial degrees $\omega(\log d)$ in dimension $d$, to a bound
using a convex polynomial of degree 2. In particular, our result firmly
resolves the open question [IPCO 2025] of whether a constant degree suffices,
and it represents significant progress towards linear objectives, where the
active-set method coincides with the simplex method and a lower bound for all
pivot rules would constitute a major breakthrough.
  Our result is based on a novel extended formulation, recursively constructed
using deformed products. Its key feature is that it projects onto a polygonal
approximation of a parabola while preserving all of its exponentially many
vertices. We define a quadratic objective that forces the active-set method to
follow the parabolic boundary of this projection, without allowing any
shortcuts along chords corresponding to edges of its full-dimensional preimage.

</details>
