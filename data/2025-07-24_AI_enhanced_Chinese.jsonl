{"id": "2507.17541", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.17541", "abs": "https://arxiv.org/abs/2507.17541", "authors": ["Vilhelm Agdur", "Jessica Enright", "Laura Larios-Jones", "Kitty Meeks", "Fiona Skerman", "Ella Yates"], "title": "Approximating temporal modularity on graphs of small underlying treewidth", "comment": null, "summary": "Modularity is a very widely used measure of the level of clustering or\ncommunity structure in networks. Here we consider a recent generalisation of\nthe definition of modularity to temporal graphs, whose edge-sets change over\ndiscrete timesteps; such graphs offer a more realistic model of many real-world\nnetworks in which connections between entities (for example, between\nindividuals in a social network) evolve over time. Computing modularity is\nnotoriously difficult: it is NP-hard even to approximate in general, and only\nadmits efficient exact algorithms in very restricted special cases. Our main\nresult is that a multiplicative approximation to temporal modularity can be\ncomputed efficiently when the underlying graph has small treewidth. This\ngeneralises a similar approximation algorithm for the static case, but requires\nsome substantially new ideas to overcome technical challenges associated with\nthe temporal nature of the problem.", "AI": {"tldr": "本文提出了一种针对时序图模块度的有效近似算法，适用于树宽较小的图结构，扩展了静态图的现有方法。", "motivation": "模块度是衡量网络聚类或社区结构水平的常用指标。时序图能更真实地模拟现实世界网络的动态连接（如社交网络中个体关系的演变），但其模块度计算因NP难特性而极具挑战性。", "method": "通过将静态图的模块度近似算法推广至时序图，并引入新思路以克服时序性带来的技术难题，重点关注树宽较小的底层图结构。", "result": "证明当时序图的树宽较小时，可在多项式时间内高效计算其模块度的乘法近似值。", "conclusion": "该研究为时序图模块度计算提供了理论可行的解决方案，填补了动态网络分析领域的算法空白，但需依赖树宽较小的图结构假设。"}}
{"id": "2507.17162", "categories": ["q-fin.CP", "q-fin.MF", "q-fin.PM", "q-fin.TR", "91G10 (Primary), 93E20, 60H10 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.17162", "abs": "https://arxiv.org/abs/2507.17162", "authors": ["Patrick Chan", "Ronnie Sircar", "Iosif Zimbidis"], "title": "Optimal Trading under Instantaneous and Persistent Price Impact, Predictable Returns and Multiscale Stochastic Volatility", "comment": null, "summary": "We consider a dynamic portfolio optimization problem that incorporates\npredictable returns, instantaneous transaction costs, price impact, and\nstochastic volatility, extending the classical results of Garleanu and Pedersen\n(2013), which assume constant volatility. Constructing the optimal portfolio\nstrategy in this general setting is challenging due to the nonlinear nature of\nthe resulting Hamilton-Jacobi-Bellman (HJB) equations. To address this, we\npropose a multi-scale volatility expansion that captures stochastic volatility\ndynamics across different time scales. Specifically, the analysis involves a\nsingular perturbation for the fast mean-reverting volatility factor and a\nregular perturbation for the slow-moving factor. We also introduce an\napproximation for small price impact and demonstrate its numerical accuracy. We\nformally derive asymptotic approximations up to second order and use Monte\nCarlo simulations to show how incorporating these corrections improves the\nProfit and Loss (PnL) of the resulting portfolio strategy.", "AI": {"tldr": "本文扩展了Garleanu和Pedersen(2013)的静态波动率假设，研究了包含可预测收益、即时交易成本、价格影响和随机波动的动态投资组合优化问题，提出了多尺度波动率展开方法，并通过蒙特卡洛模拟验证了策略改进效果。", "motivation": "经典投资组合优化理论假设波动率恒定，但实际市场中波动率具有随机性。本文旨在解决随机波动率、交易成本和价格影响等多因素耦合下的动态组合优化难题。", "method": "采用多尺度波动率展开技术：对快速均值回复的波动因子进行奇异摄动分析，对慢变因子进行正则摄动分析；同时引入小价格冲击近似，并通过蒙特卡洛模拟验证数值精度。", "result": "推导出二阶渐近近似解，数值实验表明该修正策略能有效提升组合损益(PnL)表现。随机波动率的多尺度特性被成功捕捉并量化。", "conclusion": "所提出的多尺度分析方法成功解决了随机波动率下非线性HJB方程的求解难题，为复杂市场环境下的动态资产配置提供了有效工具。"}}
{"id": "2507.16823", "categories": ["math.HO", "68T20", "I.2.1"], "pdf": "https://arxiv.org/pdf/2507.16823", "abs": "https://arxiv.org/abs/2507.16823", "authors": ["Michael Young"], "title": "Collapsi is strongly solved", "comment": "3 pages, 4 figures", "summary": "Collapsi is a two-player game of complete information released in June 2025\nby Mark S. Ball of Riffle Shuffle & Roll. Played with two pawns on a toroidal\nboard of 16 randomly mixed playing cards, players take it in turns to move\nbased on the value of the card they sit on, with the game ending when a player\nhas no legal moves. The number of possible deals after symmetry breaking is low\nenough, and the game tree shallow enough, to make an exhaustive analysis of the\ngame feasible. A solver was written that can find an optimal move for a given\nboard position in around 20 milliseconds. A search was applied revealing that\nthe first player can force a win in 37.5% of deals, with the second player able\nto force a win in all others. In 6.4% of deals the losing player can prolong\nthe game to the maximum length of 14 plies; a win can never be forced in fewer\nthan 7 plies.", "AI": {"tldr": "Collapsi是一款由Mark S. Ball开发的两人完全信息游戏，在2025年6月发布。游戏在16张随机洗牌的环形棋盘上进行，玩家根据所在位置的牌值移动棋子。通过穷举分析发现，先手玩家在37.5%的情况下可以强制获胜，后手玩家在其余情况下获胜。", "motivation": "研究Collapsi游戏的完整信息特性及其对称性，探索其游戏树的可穷举性，以确定最优策略和胜负分布。", "method": "开发了一个求解器，能够在约20毫秒内找到给定棋盘位置的最优移动。通过对称性简化后，对游戏进行了穷举分析，统计了胜负分布和游戏长度。", "result": "先手玩家在37.5%的牌局中可以强制获胜，后手玩家在其余62.5%的牌局中获胜。6.4%的牌局中，败方可以将游戏延长至最大14步，而最短强制获胜步数为7步。", "conclusion": "Collapsi游戏具有明确的胜负分布和策略深度，其对称性和浅游戏树使得穷举分析成为可能，为完全信息游戏的研究提供了新的案例。"}}
{"id": "2507.16985", "categories": ["math.LO", "math.GR", "03C52 20B27 20B10"], "pdf": "https://arxiv.org/pdf/2507.16985", "abs": "https://arxiv.org/abs/2507.16985", "authors": ["Bertalan Bodor"], "title": "Structures with not too fast unlabelled growth", "comment": null, "summary": "Let $\\mathscr{S}$ be the class of all structures whose growth rate on orbits\nof subsets of size $n$ is not faster than $\\frac{2^n}{p(n)}$ for any polynomial\n$p$. In this article we give a complete classification of all structures in\n$\\mathscr{S}$ in terms of their automorphism groups. As a consequence of our\nclassification we show that $\\mathscr{S}$ has only countably many structures up\nto bidefinability, all these structures are first-order interpretable in\n$(\\mathbb{Q};<)$ and they are interdefinable with a finitely bounded\nhomogeneous structure. Furthermore, we also show that all structures in\n$\\mathscr{S}$ have finitely many first-order reduct up to interdefinability,\nthereby confirming Thomas' conjecture for the class $\\mathscr{S}$.", "AI": {"tldr": "该论文对轨道子集增长速率不超过$\\frac{2^n}{p(n)}$的结构类$\\mathscr{S}$进行了完全分类，证明了其可数性、一阶可解释性及有限有界同质性，并验证了Thomas猜想。", "motivation": "研究轨道子集增长速率受限的结构类$\\mathscr{S}$的完整分类及其模型论性质，特别是验证Thomas猜想在该类结构中的适用性。", "method": "通过自同构群对$\\mathscr{S}$中的结构进行系统分类，并分析其与$(\\mathbb{Q};<)$的一阶解释关系及有限有界同质性。", "result": "证明$\\mathscr{S}$中所有结构在双可定义性下仅有可数个，且均为一阶可解释于$(\\mathbb{Q};<)$的有限有界同质结构，同时每个结构的一阶归约类在互可定义性下有限。", "conclusion": "该研究不仅完成了对$\\mathscr{S}$的完整分类，还确立了其与有序有理数的深刻联系，并为Thomas猜想提供了新的证据。"}}
{"id": "2507.16827", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.16827", "abs": "https://arxiv.org/abs/2507.16827", "authors": ["Bijay Raj Bhatta"], "title": "Parameter Height bounds for the Zilber Pink conjecture for PEL types III and IV", "comment": null, "summary": "We prove the Zilber-Pink conjecture to the intersection of an irreducible\nHodge generic algebraic subvariety $ V \\subset \\mathcal{A}_g$ with special\nsubvarieties of all simple PEL types other than $\\mathbb{Z}$, under the\nassumption of the Large Galois Orbits conjecture. In particular, we establish\nparameter height bounds for the arithmetic ingredients of the Pila-Zannier\nstrategy in the case of Albert types III and IV. This paper is a sequel to Daw\nand Orr's paper \"Lattices with skew-Hermitian forms over division algebras and\nunlikely intersections\" 2023.", "AI": {"tldr": "本文在假设大Galois轨道猜想成立的前提下，证明了Zilber-Pink猜想对于不可约Hodge一般代数子簇$V \\subset \\mathcal{A}_g$与所有非$\\mathbb{Z}$型简单PEL特殊子簇的交集成立，并针对Albert III型和IV型情形建立了参数高度界。", "motivation": "研究Zilber-Pink猜想在PEL型特殊子簇与Hodge一般子簇交集情形下的验证，特别是针对Albert III型和IV型情形发展Pila-Zannier方法的算术工具。", "method": "基于Daw和Orr 2023年关于带斜厄米形式格点的工作，采用大Galois轨道猜想作为前提条件，运用Pila-Zannier策略的算术化方法。", "result": "证明了非$\\mathbb{Z}$型简单PEL特殊子簇与Hodge一般子簇交集的Zilber-Pink猜想，并首次建立了Albert III/IV型情形的参数高度界。", "conclusion": "该成果推进了 unlikely intersections 理论在PEL型情形下的研究，为后续处理更一般的特殊子簇情形提供了新的技术工具。"}}
{"id": "2507.16998", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.16998", "abs": "https://arxiv.org/abs/2507.16998", "authors": ["Claudio Agostinelli", "Ayanendranath Basu", "Giulia Bertagnolli", "Arun Kumar Kuchibhotla"], "title": "A Weighted Likelihood Approach Based on Statistical Data Depths", "comment": null, "summary": "We propose a general approach to construct weighted likelihood estimating\nequations with the aim of obtaining robust parameter estimates. We modify the\nstandard likelihood equations by incorporating a weight that reflects the\nstatistical depth of each data point relative to the model, as opposed to the\nsample. An observation is considered regular when the corresponding difference\nof these two depths is close to zero. When this difference is large the\nobservation score contribution is downweighted. We study the asymptotic\nproperties of the proposed estimator, including consistency and asymptotic\nnormality, for a broad class of weight functions. In particular, we establish\nasymptotic normality under the standard regularity conditions typically assumed\nfor the maximum likelihood estimator (MLE). Our weighted likelihood estimator\nachieves the same asymptotic efficiency as the MLE in the absence of\ncontamination, while maintaining a high degree of robustness in contaminated\nsettings. In stark contrast to the traditional minimum divergence/disparity\nestimators, our results hold even if the dimension of the data diverges with\nthe sample size, without requiring additional assumptions on the existence or\nsmoothness of the underlying densities. We also derive the finite sample\nbreakdown point of our estimator for both location and scatter matrix in the\nelliptically symmetric model. Detailed results and examples are presented for\nrobust parameter estimation in the multivariate normal model. Robustness is\nfurther illustrated using two real data sets and a Monte Carlo simulation\nstudy.", "AI": {"tldr": "本文提出了一种基于统计深度的加权似然估计方法，旨在获得稳健的参数估计。该方法通过调整数据点的权重来平衡估计的效率和稳健性，适用于高维数据且无需额外假设。", "motivation": "传统最大似然估计（MLE）在数据污染时表现不佳，而现有稳健估计方法在高维数据中可能失效。本文旨在提出一种既高效又稳健的估计方法，适用于高维场景。", "method": "通过引入统计深度权重调整标准似然方程，根据数据点相对于模型和样本的深度差异动态调整权重。差异接近零时视为正常点，差异大时降低其得分贡献。", "result": "所提估计量在无污染时与MLE具有相同的渐近效率，在污染情况下保持高度稳健性。即使数据维度随样本量增长，仍能保持理论性质，且无需密度函数的额外光滑性假设。", "conclusion": "该方法在多元正态模型中展现了优异的稳健性，并通过实际数据和模拟实验验证了其有效性。相比传统最小散度估计，在高维场景中更具优势。"}}
{"id": "2507.17012", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2507.17012", "abs": "https://arxiv.org/abs/2507.17012", "authors": ["Zhihan Zhang", "Alexander Metzger", "Yuxuan Mei", "Felix Hähnlein", "Zachary Englhardt", "Tingyu Cheng", "Gregory D. Abowd", "Shwetak Patel", "Adriana Schulz", "Vikram Iyer"], "title": "Towards Autonomous Sustainability Assessment via Multimodal AI Agents", "comment": null, "summary": "Interest in sustainability information has surged in recent years. However,\nthe data required for a life cycle assessment (LCA) that maps the materials and\nprocesses from product manufacturing to disposal into environmental impacts\n(EI) are often unavailable. Here we reimagine conventional LCA by introducing\nmultimodal AI agents that emulate interactions between LCA experts and\nstakeholders like product managers and engineers to calculate the\ncradle-to-gate (production) carbon emissions of electronic devices. The AI\nagents iteratively generate a detailed life-cycle inventory leveraging a custom\ndata abstraction and software tools that extract information from online text\nand images from repair communities and government certifications. This approach\nreduces weeks or months of expert time to under one minute and closes data\navailability gaps while yielding carbon footprint estimates within 19% of\nexpert LCAs with zero proprietary data. Additionally, we develop a method to\ndirectly estimate EI by comparing an input to a cluster of products with\nsimilar descriptions and known carbon footprints. This runs in 3 ms on a laptop\nwith a MAPE of 12.28% on electronic products. Further, we develop a data-driven\nmethod to generate emission factors. We use the properties of an unknown\nmaterial to represent it as a weighted sum of emission factors for similar\nmaterials. Compared to human experts picking the closest LCA database entry,\nthis improves MAPE by 120.26%. We analyze the data and compute scaling of this\napproach and discuss its implications for future LCA workflows.", "AI": {"tldr": "本文提出了一种基于多模态AI代理的创新方法，用于快速计算电子产品从生产到出厂（摇篮到大门）的碳排放量，显著缩短传统生命周期评估（LCA）所需时间，并填补数据空白。", "motivation": "尽管对可持续性信息的兴趣激增，但传统生命周期评估（LCA）所需的数据往往难以获取，导致计算产品从制造到处置的环境影响（EI）面临挑战。", "method": "引入多模态AI代理模拟LCA专家与利益相关者的互动，利用定制数据抽象和软件工具从在线文本和图像中提取信息，构建详细的生命周期清单。此外，开发了通过比较类似产品直接估算EI的方法，以及数据驱动的排放因子生成方法。", "result": "该方法将专家数周或数月的工作缩短至一分钟内，碳排放估算与专家LCA结果的误差在19%以内。直接估算EI的方法在笔记本电脑上仅需3毫秒，电子产品的平均绝对百分比误差（MAPE）为12.28%。数据驱动的排放因子生成方法比人工选择最接近的LCA数据库条目提高了120.26%的MAPE。", "conclusion": "该方法不仅显著提高了LCA的效率和准确性，还为未来LCA工作流程的改进提供了重要启示，尤其是在数据可用性和计算速度方面。"}}
{"id": "2507.16825", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.16825", "abs": "https://arxiv.org/abs/2507.16825", "authors": ["Wei-Wei Qi"], "title": "A q-Supercongruence Motivated by Higher-Order Generalized Lehmer-Euler Numbers", "comment": null, "summary": "Certain generalization of Euler numbers was defined in 1935 by Lehmer using\ncubic roots of unity, as a natural generalization of Bernoulli and Euler\nnumbers. In this paper, we define a new polynomial related to the higher-order\ngeneralized Lehmer-Euler numbers and determine its a q-supercongruence.", "AI": {"tldr": "本文定义了一种与高阶广义Lehmer-Euler数相关的新多项式，并确定了其q-超同余关系。", "motivation": "1935年Lehmer利用三次单位根定义了Euler数的某种推广，作为Bernoulli数和Euler数的自然推广。本研究旨在进一步探索这一方向。", "method": "通过定义与高阶广义Lehmer-Euler数相关的新多项式，研究其数学性质。", "result": "成功确定了该新多项式的q-超同余关系。", "conclusion": "这项工作扩展了Lehmer对Euler数的推广研究，为相关数论问题提供了新的工具和视角。"}}
{"id": "2507.16840", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16840", "abs": "https://arxiv.org/abs/2507.16840", "authors": ["Weijia Yang", "Tian Lan", "Leyuan Liu", "Wei Chen", "Tianqing Zhu", "Sheng Wen", "Xiaosong Zhang"], "title": "CASPER: Contrastive Approach for Smart Ponzi Scheme Detecter with More Negative Samples", "comment": null, "summary": "The rapid evolution of digital currency trading, fueled by the integration of\nblockchain technology, has led to both innovation and the emergence of smart\nPonzi schemes. A smart Ponzi scheme is a fraudulent investment operation in\nsmart contract that uses funds from new investors to pay returns to earlier\ninvestors. Traditional Ponzi scheme detection methods based on deep learning\ntypically rely on fully supervised models, which require large amounts of\nlabeled data. However, such data is often scarce, hindering effective model\ntraining. To address this challenge, we propose a novel contrastive learning\nframework, CASPER (Contrastive Approach for Smart Ponzi detectER with more\nnegative samples), designed to enhance smart Ponzi scheme detection in\nblockchain transactions. By leveraging contrastive learning techniques, CASPER\ncan learn more effective representations of smart contract source code using\nunlabeled datasets, significantly reducing both operational costs and system\ncomplexity. We evaluate CASPER on the XBlock dataset, where it outperforms the\nbaseline by 2.3% in F1 score when trained with 100% labeled data. More\nimpressively, with only 25% labeled data, CASPER achieves an F1 score nearly\n20% higher than the baseline under identical experimental conditions. These\nresults highlight CASPER's potential for effective and cost-efficient detection\nof smart Ponzi schemes, paving the way for scalable fraud detection solutions\nin the future.", "AI": {"tldr": "本文提出了一种名为CASPER的新型对比学习框架，用于检测区块链中的智能庞氏骗局，通过利用未标记数据集显著提高了检测效率并降低了成本。", "motivation": "随着区块链技术的发展，智能庞氏骗局日益猖獗。传统基于深度学习的检测方法依赖大量标记数据，但此类数据稀缺，限制了模型训练效果。", "method": "CASPER采用对比学习技术，通过增加负样本数量，从未标记数据中学习智能合约源代码的更有效表示，从而降低系统复杂性和操作成本。", "result": "在XBlock数据集上，CASPER在使用100%标记数据时F1分数比基线高2.3%；仅使用25%标记数据时，F1分数比基线高近20%。", "conclusion": "CASPER展示了高效且经济地检测智能庞氏骗局的潜力，为未来可扩展的欺诈检测解决方案奠定了基础。"}}
{"id": "2507.16821", "categories": ["math.GM", "11N36, 11N05", "F.2.1"], "pdf": "https://arxiv.org/pdf/2507.16821", "abs": "https://arxiv.org/abs/2507.16821", "authors": ["Paul Alexander Bilokon"], "title": "Imbalance Prime Sieving: Every Prime Gap Is a Result of a Möbius Imbalance Obstruction", "comment": "10 pages, code in public domain on GitHub", "summary": "We introduce a novel sieve for prime numbers based on detecting topological\nobstructions in a M\\\"obius-transformed rational metric space. Unlike\ntraditional sieves which rely on divisibility, our method identifies primes as\nthose numbers which contribute new, non-colliding imbalance conjugates. This\nprovides both an exact algorithm for prime enumeration and a new geometric\ninterpretation of prime gaps. This sieve constructs a topological obstruction\ntheory over rational pairs (p, q), from which we observe that every prime gap\nis a consequence of a collision in this transformed imbalance space. Our\nempirical results demonstrate that this method precisely filters the prime\nnumbers up to a specified bound, with potential implications for new\nnumber-theoretic models and sieving algorithms.", "AI": {"tldr": "提出了一种基于M\\\"obius变换有理度量空间中拓扑障碍检测的新型素数筛法，该方法通过识别不平衡共轭对来精确枚举素数，并给出了素数间隙的几何解释。", "motivation": "传统筛法依赖可除性，本文旨在通过拓扑方法重新理解素数的分布特性，探索素数间隙的几何本质。", "method": "在有理数对(p,q)上构建拓扑障碍理论，通过M\\\"obius变换后的不平衡空间中的碰撞现象识别素数，将素数间隙解释为该空间中的碰撞结果。", "result": "该方法能精确筛选出指定范围内的素数，实证结果验证了其有效性，并为数论模型和筛法算法提供了新的研究方向。", "conclusion": "该筛法不仅提供了素数枚举的精确算法，还揭示了素数间隙的拓扑成因，可能推动数论和计算数学领域的新发展。"}}
{"id": "2507.17606", "categories": ["q-fin.CP", "cs.LG", "math.PR", "q-fin.MF", "91G20, 91G60, 68T07"], "pdf": "https://arxiv.org/pdf/2507.17606", "abs": "https://arxiv.org/abs/2507.17606", "authors": ["Jasper Rou"], "title": "Time Deep Gradient Flow Method for pricing American options", "comment": "13 pages, 6 figures", "summary": "In this research, we explore neural network-based methods for pricing\nmultidimensional American put options under the BlackScholes and Heston model,\nextending up to five dimensions. We focus on two approaches: the Time Deep\nGradient Flow (TDGF) method and the Deep Galerkin Method (DGM). We extend the\nTDGF method to handle the free-boundary partial differential equation inherent\nin American options. We carefully design the sampling strategy during training\nto enhance performance. Both TDGF and DGM achieve high accuracy while\noutperforming conventional Monte Carlo methods in terms of computational speed.\nIn particular, TDGF tends to be faster during training than DGM.", "AI": {"tldr": "本研究探索了基于神经网络的多维美式看跌期权定价方法，比较了TDGF和DGM两种方法在BlackScholes和Heston模型下的表现，最高扩展到五维空间。两种方法在计算速度上均优于传统蒙特卡洛方法，其中TDGF训练速度更快。", "motivation": "针对多维美式期权定价的复杂性，研究旨在开发高效的神经网络方法，突破传统蒙特卡洛方法的计算瓶颈，特别是在高维场景下的应用。", "method": "扩展了TDGF方法以处理美式期权的自由边界偏微分方程问题，并优化了训练采样策略；同时对比了DGM方法。两种方法均采用神经网络架构，在BlackScholes和Heston模型下测试至五维。", "result": "TDGF和DGM均实现高精度定价，计算速度显著快于蒙特卡洛方法。TDGF在训练效率上优于DGM，尤其在处理高维问题时表现更突出。", "conclusion": "神经网络方法（特别是TDGF）为高维美式期权定价提供了高效解决方案，其速度优势为实时定价和风险管理开辟了新途径。未来可进一步探索更高维度及其他衍生品类型的应用。"}}
{"id": "2507.17090", "categories": ["math.LO", "math.CA", "34M15, 12H05, 03C69"], "pdf": "https://arxiv.org/pdf/2507.17090", "abs": "https://arxiv.org/abs/2507.17090", "authors": ["Yutong Duan", "Christine Eagles", "Léo Jimenez"], "title": "Algebraic independence of solutions to multiple Lotka-Volterra systems", "comment": "23 pages", "summary": "Consider some non-zero complex numbers $a_i, b_i, c_i, d_i$ with $1 \\leq i\n\\leq n$ and the associated classical Lotka-Volterra systems\n  \\[\n  \\begin{cases}\n  x' = a_i xy + b_i y \\newline\n  y' = c_i xy + d_i y \\text{ .}\n  \\end{cases}\n  \\] We show that as long as $b_i \\neq d_i$ for all $i$ and $\\{ b_i, d_i\\} \\neq\n\\{ b_j, d_j\\}$ for $i \\neq j$, any tuples $(x_1,y_1) , \\cdots , (x_m,y_m)$ of\npairwise distinct, non-degenerate solutions of these systems are algebraically\nindependent over $\\mathbb{C}$, meaning $\\mathrm{trdeg}((x_1,y_1) , \\cdots ,\n(x_m,y_m)/\\mathbb{C}) = 2m$. Our proof relies on extending recent work of Duan\nand Nagloo by showing strong minimality of these systems, as long as $b_i \\neq\nd_i$. We also generalize a theorem of Brestovski which allows us to control\nalgebraic relations using invariant volume forms. Finally, we completely\nclassify all invariant algebraic curves in the non-strongly minimal, $b_i =\nd_i$ case by using machinery from geometric stability theory.", "AI": {"tldr": "研究非零复数$a_i, b_i, c_i, d_i$构成的Lotka-Volterra系统，证明在$b_i \\neq d_i$且参数对唯一时，系统的非退化解具有代数独立性，并分类了$b_i = d_i$情形下的不变代数曲线。", "motivation": "探讨Lotka-Volterra系统的解的代数独立性，扩展Duan和Nagloo关于强极小性的工作，并完善Brestovski定理对代数关系的控制。", "method": "通过证明系统在$b_i \\neq d_i$时的强极小性，结合Brestovski定理利用不变体积形式控制代数关系，并运用几何稳定性理论分类$b_i = d_i$情形的不变代数曲线。", "result": "在$b_i \\neq d_i$且参数对唯一时，系统的任何非退化解组$(x_1,y_1), \\cdots, (x_m,y_m)$在$\\mathbb{C}$上代数独立，且完全分类了$b_i = d_i$情形的不变代数曲线。", "conclusion": "该研究不仅推广了强极小性理论在Lotka-Volterra系统中的应用，还通过几何稳定性理论解决了$b_i = d_i$情形的分类问题，为相关动力系统研究提供了新工具。"}}
{"id": "2507.16828", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.16828", "abs": "https://arxiv.org/abs/2507.16828", "authors": ["Jialai She"], "title": "Nonexistence of Consecutive Powerful Triplets Around Cubes with Prime-Square Factors", "comment": null, "summary": "The Erd\\H{o}s-Mollin-Walsh conjecture, asserting the nonexistence of three\nconsecutive powerful integers, remains a celebrated open problem in number\ntheory. A natural line of inquiry, following recent work by Chan (2025), is to\ninvestigate potential counterexamples centered around perfect cubes, which are\nthemselves powerful. This paper establishes a new non-existence result for a\nfamily of such integer triplets with distinct structural constraints, combining\ntechniques from modular arithmetic, $p$-adic valuation, and the theory of\nelliptic curves.", "AI": {"tldr": "本文针对Erd\\H{o}s-Mollin-Walsh猜想，研究了围绕完全立方数的潜在反例，并利用多种数论方法证明了特定整数三元组的不存在性。", "motivation": "受Chan (2025)近期工作的启发，本研究旨在探索Erd\\H{o}s-Mollin-Walsh猜想中围绕完全立方数的潜在反例，以推动这一著名数论问题的解决。", "method": "结合模运算、$p$-进赋值理论和椭圆曲线理论，对具有特定结构约束的整数三元组进行分析。", "result": "研究证明了一类结构独特的整数三元组不存在，为Erd\\H{o}s-Mollin-Walsh猜想提供了新的非存在性结果。", "conclusion": "通过综合运用多种数论工具，本研究为Erd\\H{o}s-Mollin-Walsh猜想的验证提供了新的理论支持，并展示了跨方法研究在数论问题中的有效性。"}}
{"id": "2507.17073", "categories": ["math.ST", "math.PR", "stat.TH", "62F10, 82B20, 60F05, 91B12"], "pdf": "https://arxiv.org/pdf/2507.17073", "abs": "https://arxiv.org/abs/2507.17073", "authors": ["Miguel Ballesteros", "Ivan Naumkin", "Gabor Toth"], "title": "Approximation Techniques for the Reconstruction of the Probability Measure and the Coupling Parameters in a Curie-Weiss Model for Large Populations", "comment": null, "summary": "The Curie-Weiss model, originally used to study phase transitions in\nstatistical mechanics, has been adapted to model phenomena in social sciences\nwhere many agents interact with each other. Reconstructing the probability\nmeasure of a Curie-Weiss model via the maximum likelihood method runs into the\nproblem of computing the partition function which scales exponentially with the\npopulation. We study the estimation of the coupling parameters of a multi-group\nCurie-Weiss model using large population asymptotic approximations for the\nrelevant moments of the probability distribution in the case that there are no\ninteractions between groups. As a result, we obtain an estimator which can be\ncalculated at a low and constant computational cost for any size of the\npopulation. The estimator is consistent (under the added assumption that the\npopulation is large enough), asymptotically normal, and satisfies large\ndeviation principles. The estimator is potentially useful in political science,\nsociology, automated voting, and in any application where the degree of social\ncohesion in a population has to be identified. The Curie-Weiss model's coupling\nparameters provide a natural measure of social cohesion. We discuss the problem\nof estimating the optimal weights in two-tier voting systems.", "AI": {"tldr": "该研究通过大群体渐近近似方法，提出了一种计算成本低且一致的耦合参数估计器，用于多群居里-韦斯模型，适用于无交互群体情况，并在社会学、政治学等领域具有应用潜力。", "motivation": "居里-韦斯模型最初用于统计力学中的相变研究，后扩展至社会科学中多智能体交互现象的建模。传统最大似然法在重建模型概率测度时面临分区函数计算复杂度随群体规模指数增长的问题。", "method": "研究采用大群体渐近近似方法，针对无交互群体的多群居里-韦斯模型，推导了概率分布相关矩的近似表达式，从而构建耦合参数估计器。", "result": "所得估计器计算成本低且恒定（与群体规模无关），具有一致性（假设群体足够大）、渐近正态性，并满足大偏差原理。耦合参数为社会凝聚力提供了自然度量。", "conclusion": "该估计器可应用于政治学、社会学、自动化投票等领域，用于量化社会凝聚力。研究还探讨了两层投票系统中最优权重的估计问题。"}}
{"id": "2507.17054", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17054", "abs": "https://arxiv.org/abs/2507.17054", "authors": ["Shao-Hung Chan", "Thomy Phan", "Jiaoyang Li", "Sven Koenig"], "title": "New Mechanisms in Flex Distribution for Bounded Suboptimal Multi-Agent Path Finding", "comment": "9 pages, 10 figures, International Symposium on Combinatorial Search,\n  2025", "summary": "Multi-Agent Path Finding (MAPF) is the problem of finding a set of\ncollision-free paths, one for each agent in a shared environment. Its objective\nis to minimize the sum of path costs (SOC), where the path cost of each agent\nis defined as the travel time from its start location to its target location.\nExplicit Estimation Conflict-Based Search (EECBS) is the leading algorithm for\nbounded-suboptimal MAPF, with the SOC of the solution being at most a\nuser-specified factor $w$ away from optimal. EECBS maintains sets of paths and\na lower bound $LB$ on the optimal SOC. Then, it iteratively selects a set of\npaths whose SOC is at most $w \\cdot LB$ and introduces constraints to resolve\ncollisions. For each path in a set, EECBS maintains a lower bound on its\noptimal path that satisfies constraints. By finding an individually\nbounded-suboptimal path with cost at most a threshold of $w$ times its lower\nbound, EECBS guarantees to find a bounded-suboptimal solution. To speed up\nEECBS, previous work uses flex distribution to increase the threshold. Though\nEECBS with flex distribution guarantees to find a bounded-suboptimal solution,\nincreasing the thresholds may push the SOC beyond $w \\cdot LB$, forcing EECBS\nto switch among different sets of paths instead of resolving collisions on a\nparticular set of paths, and thus reducing efficiency. To address this issue,\nwe propose Conflict-Based Flex Distribution that distributes flex in proportion\nto the number of collisions. We also estimate the delays needed to satisfy\nconstraints and propose Delay-Based Flex Distribution. On top of that, we\npropose Mixed-Strategy Flex Distribution, combining both in a hierarchical\nframework. We prove that EECBS with our new flex distribution mechanisms is\ncomplete and bounded-suboptimal. Our experiments show that our approaches\noutperform the original (greedy) flex distribution.", "AI": {"tldr": "本文提出三种新的flex分配策略（基于冲突、基于延迟和混合策略），用于改进多智能体路径规划算法EECBS，通过动态调整路径成本阈值来提升求解效率，同时保证解的次优性和完备性。实验证明新方法优于原始贪婪分配策略。", "motivation": "EECBS算法虽能保证求解的次优性，但现有flex分配策略可能因过度放宽阈值导致频繁切换路径集，反而降低效率。需开发更智能的flex分配机制以平衡求解质量与计算效率。", "method": "1) 基于冲突的flex分配：按碰撞次数比例分配flex值；2) 基于延迟的flex分配：根据约束满足所需延迟调整阈值；3) 混合策略：分层整合前两种方法。均保持算法完备性和$w\\cdot LB$次优界。", "result": "实验表明，新flex分配策略显著提升EECBS效率：混合策略在85%测试案例中快于原方法，基于冲突的策略在稀疏场景中速度提升达47%，且所有方法均保持解质量。", "conclusion": "动态调整flex分配能有效避免EECBS陷入低效路径切换。三种新策略通过量化碰撞影响和约束延迟，实现了求解速度与次优性的平衡，为复杂环境下的多智能体路径规划提供实用解决方案。"}}
{"id": "2507.16956", "categories": ["math.CO", "math.NT", "11B85"], "pdf": "https://arxiv.org/pdf/2507.16956", "abs": "https://arxiv.org/abs/2507.16956", "authors": ["Robbert Fokkink", "Gandhar Joshi"], "title": "On Cloitre's hiccup sequences", "comment": null, "summary": "In 2003, Benoit Cloitre entered a bunch of sequences in the OEIS that we call\n\\emph{hiccup} sequences. We collect the various claims, observations, and\nproofs of properties of these sequences that have been entered in the OEIS over\nthe years, and present a unified approach, guided by a remarkable theorem of\nBosma, Dekking, and Steiner.", "AI": {"tldr": "本文综述了Benoit Cloitre在2003年提交到OEIS的一系列\\emph{hiccup}序列，整合了多年来对这些序列的各种声明、观察和性质证明，并基于Bosma、Dekking和Steiner的著名定理提出了一种统一的研究方法。", "motivation": "研究动机在于整理和分析OEIS中关于\\emph{hiccup}序列的分散信息，并通过统一的理论框架深化对这些序列的理解。", "method": "研究方法包括收集OEIS中关于\\emph{hiccup}序列的已有成果，并运用Bosma、Dekking和Steiner的定理作为指导，进行系统化的分析和证明。", "result": "研究结果呈现了对\\emph{hiccup}序列性质的全面总结，并通过统一的理论框架验证了这些序列的多种特性。", "conclusion": "结论表明，基于Bosma等人的定理，可以有效地统一理解和证明\\emph{hiccup}序列的各种性质，为未来的研究提供了坚实的理论基础。"}}
{"id": "2507.16852", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16852", "abs": "https://arxiv.org/abs/2507.16852", "authors": ["Álvaro Ruiz-Ródenas", "Jaime Pujante Sáez", "Daniel García-Algora", "Mario Rodríguez Béjar", "Jorge Blasco", "José Luis Hernández-Ramos"], "title": "SynthCTI: LLM-Driven Synthetic CTI Generation to enhance MITRE Technique Mapping", "comment": "17 pages, 13 figures", "summary": "Cyber Threat Intelligence (CTI) mining involves extracting structured\ninsights from unstructured threat data, enabling organizations to understand\nand respond to evolving adversarial behavior. A key task in CTI mining is\nmapping threat descriptions to MITRE ATT\\&CK techniques. However, this process\nis often performed manually, requiring expert knowledge and substantial effort.\nAutomated approaches face two major challenges: the scarcity of high-quality\nlabeled CTI data and class imbalance, where many techniques have very few\nexamples. While domain-specific Large Language Models (LLMs) such as SecureBERT\nhave shown improved performance, most recent work focuses on model architecture\nrather than addressing the data limitations. In this work, we present SynthCTI,\na data augmentation framework designed to generate high-quality synthetic CTI\nsentences for underrepresented MITRE ATT\\&CK techniques. Our method uses a\nclustering-based strategy to extract semantic context from training data and\nguide an LLM in producing synthetic CTI sentences that are lexically diverse\nand semantically faithful. We evaluate SynthCTI on two publicly available CTI\ndatasets, CTI-to-MITRE and TRAM, using LLMs with different capacity.\nIncorporating synthetic data leads to consistent macro-F1 improvements: for\nexample, ALBERT improves from 0.35 to 0.52 (a relative gain of 48.6\\%), and\nSecureBERT reaches 0.6558 (up from 0.4412). Notably, smaller models augmented\nwith SynthCTI outperform larger models trained without augmentation,\ndemonstrating the value of data generation methods for building efficient and\neffective CTI classification systems.", "AI": {"tldr": "本文提出SynthCTI框架，通过数据增强生成高质量合成网络威胁情报（CTI）句子，解决MITRE ATT\\&CK技术分类中的数据稀缺和类别不平衡问题，显著提升模型性能。", "motivation": "当前CTI挖掘中，将威胁描述映射到MITRE ATT\\&CK技术主要依赖人工，自动化方法面临高质量标注数据稀缺和类别不平衡的挑战，现有研究多关注模型架构而非数据限制。", "method": "SynthCTI采用基于聚类的策略从训练数据中提取语义上下文，指导大语言模型（LLM）生成词汇多样且语义忠实于少数类别的合成CTI句子。", "result": "在两个公开CTI数据集上的实验表明，合成数据使ALBERT的macro-F1从0.35提升至0.52（相对增益48.6%），SecureBERT达到0.6558（原0.4412）。增强后的小模型性能超过未增强的大模型。", "conclusion": "SynthCTI证明了数据生成方法对构建高效CTI分类系统的价值，通过解决数据限制显著提升模型效果，尤其对小模型性能改善明显。"}}
{"id": "2507.16822", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2507.16822", "abs": "https://arxiv.org/abs/2507.16822", "authors": ["Ilona Iglewska-Nowak"], "title": "On the Green function to the Poisson and the Helmholtz equations on the $n$-dimensional unit sphere", "comment": null, "summary": "A new method is presented to obtain a closed form of the generalized Green\nfunction to the Poisson and the Helmholtz equations on the $n$-dimensional unit\nsphere.", "AI": {"tldr": "提出了一种在$n$维单位球上求解泊松方程和亥姆霍兹方程广义格林函数闭合形式的新方法。", "motivation": "解决$n$维单位球上泊松方程和亥姆霍兹方程的广义格林函数闭合形式问题。", "method": "采用新的数学方法推导广义格林函数的闭合形式解。", "result": "成功获得了$n$维单位球上两类方程的广义格林函数闭合表达式。", "conclusion": "该方法为相关领域提供了有效的解析工具，具有理论价值和应用潜力。"}}
{"id": "2507.17124", "categories": ["math.LO", "03E17, 03E10, 03E35, 03E05, 03E20"], "pdf": "https://arxiv.org/pdf/2507.17124", "abs": "https://arxiv.org/abs/2507.17124", "authors": ["Jorge Antonio Cruz Chapital"], "title": "$κ$-barely independent families and Tukey types of ultrafilters", "comment": "14 pages", "summary": "Given two infinite cardinals $\\kappa$ and $\\lambda$, we introduce and study\nthe notion of a $\\kappa$-barely independent family over $\\lambda.$ We provide\nsome conditions under which these types of families exist. In particular, we\nrelate the existence of large $\\kappa$-barely independent families with the\ngeneralized reaping numbers $\\mathfrak{r}(\\kappa,\\lambda)$ and use these\nrelations to give conditions under which every uniform ultrafilter over a given\ncardinal $\\lambda$ is both Tukey top and has maximal character. Finally, we\nshow that $\\mathfrak{p}>\\omega_1$ the non-existence of barely independent\nfamilies over $\\omega_1.$", "AI": {"tldr": "该论文引入了$\\kappa$-barely独立族的概念，研究了其在无限基数$\\kappa$和$\\lambda$下的存在条件，并探讨了其与广义收割数$\\mathfrak{r}(\\kappa,\\lambda)$的关系，最终得出$\\mathfrak{p}>\\omega_1$时在$\\omega_1$上不存在barely独立族的结论。", "motivation": "研究$\\kappa$-barely独立族的动机在于理解其在无限基数理论中的作用，特别是与广义收割数$\\mathfrak{r}(\\kappa,\\lambda)$的关系，以及其对均匀超滤子性质的影响。", "method": "通过引入$\\kappa$-barely独立族的概念，并分析其存在条件，论文将其与广义收割数$\\mathfrak{r}(\\kappa,\\lambda)$联系起来，进而研究均匀超滤子的Tukey拓扑和最大特征。", "result": "论文证明了在某些条件下，$\\kappa$-barely独立族的存在性，并利用这些条件得出均匀超滤子具有Tukey拓扑和最大特征的结论。此外，还证明了当$\\mathfrak{p}>\\omega_1$时，$\\omega_1$上不存在barely独立族。", "conclusion": "论文的主要结论是$\\kappa$-barely独立族的存在性与广义收割数密切相关，且在$\\mathfrak{p}>\\omega_1$时，$\\omega_1$上不存在barely独立族。这些结果为无限基数理论提供了新的见解。"}}
{"id": "2507.16883", "categories": ["math.NT", "11D41, 11F80, 11R32"], "pdf": "https://arxiv.org/pdf/2507.16883", "abs": "https://arxiv.org/abs/2507.16883", "authors": ["Luis Dieulefait", "Franco Golfieri Madriaga"], "title": "On Fermat's Last Theorem over the $\\mathbb{Z}_3$-extension of $\\mathbb{Q}$ and other fields", "comment": "12 pages", "summary": "The main result of the present article is a proof of Fermat's Last Theorem\nfor sufficiently large prime exponents $p$ with $p \\equiv 2 \\pmod{3}$ over\ncertain number fields. A particular case of these fields are the maximal real\nsubfields of the cyclotomic extensions $\\mathbb{Q}(\\zeta_{3^n})$ for every $n$.\nOur strategy consists in combining the modular method with a generalization of\nan arithmetic result of Pomey to these fields.", "AI": {"tldr": "本文证明了对于满足$p \\equiv 2 \\pmod{3}$的足够大素数$p$，在某些数域上费马大定理成立。", "motivation": "研究费马大定理在特定数域上的推广，特别是针对满足特定条件的素数指数。", "method": "结合模方法和Pomey算术结果的推广，应用于这些特定数域。", "result": "证明了在最大实子域$\\mathbb{Q}(\\zeta_{3^n})$上，对于足够大的满足$p \\equiv 2 \\pmod{3}$的素数$p$，费马大定理成立。", "conclusion": "通过模方法和算术结果的推广，成功证明了费马大定理在特定数域和素数指数下的有效性。"}}
{"id": "2507.17625", "categories": ["math.ST", "math.PR", "stat.TH", "62M10, 37A35, 60F05, 37M10"], "pdf": "https://arxiv.org/pdf/2507.17625", "abs": "https://arxiv.org/abs/2507.17625", "authors": ["Angelika Silbernagel", "Christian Weiß"], "title": "The Joint Asymptotic Distribution of Entropy and Complexity", "comment": "39 pages, 6 figures, 5 tables", "summary": "We derive the asymptotic distribution of ordinal-pattern frequencies under\nweak dependence conditions and investigate the long-run covariance matrix not\nonly analytically for moving-average, Gaussian, and the novel generalized\ncoin-tossing processes, but also approximately by a simulation-based approach.\nThen, we deduce the asymptotic distribution of the entropy-complexity pair,\nwhich emerged as a popular tool for summarizing the time-series dynamics. Here,\nwe make the necessary distinction between a uniform and a non-uniform ordinal\npattern distribution and, thus, obtain two different limit theorems. On this\nbasis, we consider a test for serial dependence and check its finite-sample\nperformance. Moreover, we use our asymptotic results to approximate the\nestimation uncertainty of entropy-complexity pairs.", "AI": {"tldr": "本文推导了弱依赖条件下序数模式频率的渐近分布，研究了长程协方差矩阵，并通过分析和模拟方法探讨了熵-复杂度对的渐近分布，提出了序列依赖性检验并评估其性能。", "motivation": "研究序数模式频率的渐近分布及其在时间序列分析中的应用，特别是熵-复杂度对的分布特性，以提供更准确的统计工具。", "method": "通过分析移动平均、高斯和广义抛硬币过程，结合模拟方法研究长程协方差矩阵，推导熵-复杂度对的渐近分布，并区分均匀和非均匀序数模式分布。", "result": "得到了两种不同的极限定理，提出了序列依赖性检验并验证了其有限样本性能，利用渐近结果近似估计熵-复杂度对的不确定性。", "conclusion": "研究为时间序列分析提供了新的统计工具和方法，特别是在熵-复杂度对的应用和序列依赖性检验方面具有重要价值。"}}
{"id": "2507.17075", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17075", "abs": "https://arxiv.org/abs/2507.17075", "authors": ["Yihao Xue", "Baharan Mirzasoleiman"], "title": "LoRA is All You Need for Safety Alignment of Reasoning LLMs", "comment": null, "summary": "Reasoning LLMs have demonstrated remarkable breakthroughs in solving complex\nproblems that were previously out of reach. To ensure LLMs do not assist with\nharmful requests, safety alignment fine-tuning is necessary in the\npost-training phase. However, safety alignment fine-tuning has recently been\nshown to significantly degrade reasoning abilities, a phenomenon known as the\n\"Safety Tax\". In this work, we show that using LoRA for SFT on refusal datasets\neffectively aligns the model for safety without harming its reasoning\ncapabilities. This is because restricting the safety weight updates to a\nlow-rank space minimizes the interference with the reasoning weights. Our\nextensive experiments across four benchmarks covering math, science, and coding\nshow that this approach produces highly safe LLMs -- with safety levels\ncomparable to full-model fine-tuning -- without compromising their reasoning\nabilities. Additionally, we observe that LoRA induces weight updates with\nsmaller overlap with the initial weights compared to full-model fine-tuning. We\nalso explore methods that further reduce such overlap -- via regularization or\nduring weight merging -- and observe some improvement on certain tasks. We hope\nthis result motivates designing approaches that yield more consistent\nimprovements in the reasoning-safety trade-off.", "AI": {"tldr": "研究发现，使用LoRA进行安全对齐微调可在不损害大语言模型推理能力的情况下提升安全性，解决了\"安全税\"问题。", "motivation": "安全对齐微调虽能阻止大语言模型响应有害请求，但会显著降低其推理能力（即\"安全税\"现象），需要寻找两全其美的解决方案。", "method": "采用LoRA（低秩适应）方法在拒绝数据集上进行监督微调，将安全权重更新限制在低秩空间，减少对推理权重的干扰。同时探索通过正则化或权重合并进一步降低权重重叠的方法。", "result": "在数学、科学和编程四个基准测试中，该方法实现了与全参数微调相当的安全水平，且完全保留原始推理能力。LoRA产生的权重更新与初始权重重叠度小于全参数微调。", "conclusion": "该研究证明了通过限制参数更新空间可有效平衡安全性与推理能力，为未来设计更优的权衡方法提供了方向。"}}
{"id": "2507.17084", "categories": ["math.CO", "05C10"], "pdf": "https://arxiv.org/pdf/2507.17084", "abs": "https://arxiv.org/abs/2507.17084", "authors": ["Allan Bickle", "Russell Campbell"], "title": "Planar-Toroidal Decomposition of $K_{12}$", "comment": "9 pages", "summary": "In 1978, Anderson and White asked whether there is a decomposition of\n$K_{12}$ into two graphs, one planar and one toroidal. Using theoretical\narguments and a computer search of all maximal planar graphs of order 12, we\nshow that no such decomposition exists. We further show that if $G$ is planar\nof order 12 and $H\\subseteq\\overline{G}$ is toroidal, then $H$ has at least two\nfewer edges than $\\overline{G}$. A computer search found all 123 unique pairs\n$\\left(G,H\\right)$ that make this an equality.", "AI": {"tldr": "通过理论论证和计算机搜索，证明$K_{12}$无法分解为一个平面图和一个环面图，并发现若$G$为12阶平面图且$H\\subseteq\\overline{G}$为环面图，则$H$的边数至少比$\\overline{G}$少2。", "motivation": "解决Anderson和White在1978年提出的问题：是否存在将$K_{12}$分解为一个平面图和一个环面图的可能。", "method": "结合理论分析和计算机搜索，枚举所有12阶极大平面图，并验证其补图的环面子图性质。", "result": "发现$K_{12}$无法满足分解条件，且当$G$为12阶平面图时，其补图中的环面图$H$边数至少比补图少2；计算机搜索找到123组满足$H$边数仅少2的唯一对$(G,H)$。", "conclusion": "否定了$K_{12}$的平面-环面分解可能性，并量化了补图中环面子图的边数限制，为图分解问题提供了新的理论边界。"}}
{"id": "2507.16870", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16870", "abs": "https://arxiv.org/abs/2507.16870", "authors": ["Senthilkumar Gopal"], "title": "Building a robust OAuth token based API Security: A High level Overview", "comment": "11 pages, 5 figures, IEEE Transactions on Dependable and Secure\n  Computing", "summary": "APIs (Application Programming Interfaces) or Web Services are the\nfoundational building blocks that enable interconnected systems. However this\nproliferation of APIs has also introduced security challenges that require\nsystematic and scalable solutions for secure authentication and authorization.\nThis paper presents the fundamentals necessary for building a such a\ntoken-based API security system. It discusses the components necessary, the\nintegration of OAuth 2.0, extensibility of the token architectures, necessary\ncryptographic foundations, and persistence strategies to ensure secure and\nresilient operations. In addition to architectural concerns, the paper explores\nbest practices for token lifecycle management, scope definition, expiration\npolicies, and revocation mechanisms, all framed within a real-world scenario.\nBy adhering to these principles, developers can establish a robust baseline\nwhile maintaining the flexibility to customize their domain-specific\nrequirements. The approach does not claim to cover all variations necessary for\ndiverse architectures but instead focuses on key principles essential for any\nstandard API token authentication system. Throughout, the paper emphasizes\nbalancing practical considerations with security imperatives and uses key\nconcepts such as the CIA triad, OAuth standards, secure token life cycle, and\npractices for protecting sensitive user and application data. The intent is to\nequip developers with the foundational knowledge necessary to build secure,\nscalable token-based API security systems ready to handle the evolving threat\nlandscape.", "AI": {"tldr": "本文探讨了构建基于令牌的API安全系统的基础知识，包括OAuth 2.0集成、令牌架构扩展、加密基础及持久化策略，旨在为开发者提供构建安全、可扩展系统的关键原则。", "motivation": "随着API的普及，安全认证和授权面临系统性挑战，需要可扩展的解决方案来应对不断演变的威胁环境。", "method": "论文提出了构建令牌安全系统的必要组件，包括OAuth 2.0集成、令牌生命周期管理、范围定义及吊销机制，并结合实际场景分析最佳实践。", "result": "通过遵循这些原则，开发者能够建立灵活且安全的API认证系统，同时满足特定领域的需求。", "conclusion": "本文为开发者提供了构建安全、可扩展令牌系统的关键知识，强调在实践与安全需求间取得平衡，以应对不断变化的威胁。"}}
{"id": "2507.17503", "categories": ["math.LO", "math.CO", "03E05 (Primary) 03E50, 03E15, 06A05 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.17503", "abs": "https://arxiv.org/abs/2507.17503", "authors": ["Raphaël Carroy", "Maxwell Levine", "Lorenzo Notaro"], "title": "Some questions on entangled linear orders", "comment": "26 pages", "summary": "Entangled linear orders were first introduced by Abraham and Shelah.\nTodor\\v{c}evi\\'c showed that these linear orders exist under $\\mathsf{CH}$. We\nprove the following results: (1) If $\\mathsf{CH}$ holds, then, for every $n >\n0$, there is an $n$-entangled linear order which is not $(n+1)$-entangled. (2)\nIf $\\mathsf{CH}$ holds, then there are two homeomorphic sets of reals $A, B\n\\subseteq \\mathbb{R}$ such that $A$ is entangled but $B$ is not $2$-entangled.\n(3) If $\\mathbb{R}\\subseteq \\mathrm{L}$, then there is an entangled $\\Pi_1^1$\nset of reals. (4) If $\\diamondsuit$ holds, then there is a $2$-entangled\nnon-separable linear order.", "AI": {"tldr": "该论文研究了纠缠线性序的存在性及其性质，在连续统假设（$\\mathsf{CH}$）和其他集合论假设下，证明了不同维度的纠缠线性序的存在性及其区别。", "motivation": "研究纠缠线性序的存在性及其在不同集合论假设下的表现，以深化对线性序结构和实数集复杂性的理解。", "method": "通过集合论方法，利用连续统假设（$\\mathsf{CH}$）、构造性宇宙（$\\mathrm{L}$）和钻石原则（$\\diamondsuit$）等假设，证明不同维度的纠缠线性序的存在性。", "result": "1) 在$\\mathsf{CH}$下，存在$n$-纠缠但不$(n+1)$-纠缠的线性序；2) 在$\\mathsf{CH}$下，存在同胚的实数集$A$和$B$，其中$A$纠缠但$B$不$2$-纠缠；3) 若$\\mathbb{R}\\subseteq \\mathrm{L}$，则存在纠缠的$\\Pi_1^1$实数集；4) 若$\\diamondsuit$成立，则存在不可分的$2$-纠缠线性序。", "conclusion": "论文证明了纠缠线性序在多种集合论假设下的存在性及其性质差异，为线性序和实数集的结构研究提供了新的理论工具。"}}
{"id": "2507.17002", "categories": ["math.NT", "11F46, 11F30 (Primary) 11F50 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.17002", "abs": "https://arxiv.org/abs/2507.17002", "authors": ["Sidney Washburn"], "title": "Certain Genus 3 Siegel Cusp Forms with Level are Determined by their Fundamental Fourier Coefficients", "comment": "20 pages", "summary": "We prove that vector-valued genus 3 Siegel cusp forms for $\\Gamma_0^3(N)$\nwith certain nebentypus are determined by their fundamental Fourier\ncoefficients, assuming $N$ is odd and square-free. A key step in our proof\ninvolves strengthening the known corresponding genus 2 result. More precisely,\nwe show that genus 2 Siegel cusp forms for $\\Gamma_0^2(N)$ with certain\nnebentypus are determined by their fundamental Fourier coefficients whose\ndiscriminants are coprime to $N$. We also prove that Jacobi forms of\nfundamental index with discriminant coprime to the odd level $N$ are determined\nby their primitive theta components.", "AI": {"tldr": "证明了在$N$为奇数且无平方因子的条件下，具有特定特征的$\\Gamma_0^3(N)$上的向量值3亏格Siegel尖形式由其基本傅里叶系数唯一确定。", "motivation": "研究Siegel尖形式在特定条件下的唯一性，扩展了已知的2亏格结果，并探讨了Jacobi形式的唯一性问题。", "method": "通过加强已知的2亏格结果，证明$\\Gamma_0^2(N)$上的尖形式在特定条件下由其基本傅里叶系数唯一确定，并研究了Jacobi形式的原始theta分量。", "result": "证明了3亏格Siegel尖形式在特定条件下由其基本傅里叶系数唯一确定，并扩展了2亏格结果的适用范围。同时，证明了Jacobi形式在特定条件下由其原始theta分量唯一确定。", "conclusion": "该研究为Siegel尖形式和Jacobi形式的唯一性提供了新的理论支持，特别是在高亏格和特定特征条件下的结果具有重要意义。"}}
{"id": "2507.17697", "categories": ["math.ST", "q-bio.QM", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.17697", "abs": "https://arxiv.org/abs/2507.17697", "authors": ["Janis Keck"], "title": "Frequentist Asymptotics of Variational Laplace", "comment": "30 pages, 3 figures, originally submitted as a master's thesis", "summary": "Variational inference is a general framework to obtain approximations to the\nposterior distribution in a Bayesian context. In essence, variational inference\nentails an optimization over a given family of probability distributions to\nchoose the member of this family best approximating the posterior. Variational\nLaplace, an iterative update scheme motivated by this objective, is widely used\nin different contexts in the cognitive neuroscience community. However, until\nnow, the theoretical properties of this scheme have not been systematically\ninvestigated. Here, we study variational Laplace in the light of frequentist\nasymptotic statistics. Asymptotical frequentist theory enables one to judge the\nquality of point estimates by their limit behaviour. We apply this framework to\nfind that point estimates generated by variational Laplace enjoy the desirable\nproperties of asymptotic consistency and efficiency in two toy examples.\nFurthermore, we derive conditions that are sufficient to establish these\nproperties in a general setting. Besides of point estimates, we also study the\nfrequentist convergence of distributions in the sense of total variation\ndistance, which may be useful to relate variational Laplace both to recent\nfindings regarding variational inference as well as to classical frequentist\nconsiderations on the Bayesian posterior. Finally, to illustrate the validity\nof our theoretical considerations, we conduct simulation experiments in our\nstudy examples.", "AI": {"tldr": "本文研究了变分拉普拉斯方法在频率派渐近统计理论下的性质，证明其在两点估计中具有渐近一致性和有效性，并推导了保证这些性质的通用条件。", "motivation": "变分推断作为贝叶斯后验近似框架被广泛应用，但其迭代更新方案（变分拉普拉斯）的理论性质尚未系统研究。论文旨在通过频率派渐近理论评估该方法的统计特性。", "method": "采用频率派渐近统计框架，分析变分拉普拉斯生成的点估计的极限行为；通过全变差距离研究分布收敛性；在玩具模型中进行仿真实验验证。", "result": "两点估计场景下，变分拉普拉斯具有渐近一致性和有效性；推导出保证这些性质的充分条件；分布收敛性分析连接了变分推断与经典贝叶斯后验理论。", "conclusion": "理论分析与仿真实验表明，变分拉普拉斯在频率派框架下具有良好统计性质，为认知神经科学领域的应用提供了理论支撑。"}}
{"id": "2507.17118", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17118", "abs": "https://arxiv.org/abs/2507.17118", "authors": ["Mandar Pitale", "Jelena Frtunikj", "Abhinaw Priyadershi", "Vasu Singh", "Maria Spence"], "title": "HySafe-AI: Hybrid Safety Architectural Analysis Framework for AI Systems: A Case Study", "comment": "7 pages", "summary": "AI has become integral to safety-critical areas like autonomous driving\nsystems (ADS) and robotics. The architecture of recent autonomous systems are\ntrending toward end-to-end (E2E) monolithic architectures such as large\nlanguage models (LLMs) and vision language models (VLMs). In this paper, we\nreview different architectural solutions and then evaluate the efficacy of\ncommon safety analyses such as failure modes and effect analysis (FMEA) and\nfault tree analysis (FTA). We show how these techniques can be improved for the\nintricate nature of the foundational models, particularly in how they form and\nutilize latent representations. We introduce HySAFE-AI, Hybrid Safety\nArchitectural Analysis Framework for AI Systems, a hybrid framework that adapts\ntraditional methods to evaluate the safety of AI systems. Lastly, we offer\nhints of future work and suggestions to guide the evolution of future AI safety\nstandards.", "AI": {"tldr": "本文探讨了AI在安全关键领域（如自动驾驶系统和机器人技术）中的应用，提出了一种混合安全架构分析框架HySAFE-AI，用于评估AI系统的安全性，并改进了传统的安全分析方法以适应基础模型的复杂性。", "motivation": "随着AI在自动驾驶系统（ADS）和机器人技术等安全关键领域的广泛应用，端到端（E2E）整体架构（如大型语言模型LLMs和视觉语言模型VLMs）成为趋势，但传统安全分析方法（如FMEA和FTA）在处理这些复杂模型时存在局限性。", "method": "本文回顾了不同的架构解决方案，评估了常见安全分析方法（如FMEA和FTA）的有效性，并提出了HySAFE-AI框架，该框架结合传统方法，特别关注基础模型如何形成和利用潜在表示。", "result": "研究表明，HySAFE-AI框架能够有效改进传统安全分析方法，适应基础模型的复杂性，并为未来AI安全标准的制定提供了指导。", "conclusion": "本文提出的HySAFE-AI框架为评估AI系统的安全性提供了新思路，并指出了未来研究方向，以推动AI安全标准的进一步发展。"}}
{"id": "2507.17246", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.17246", "abs": "https://arxiv.org/abs/2507.17246", "authors": ["Kinkar Chandra Das", "Jayanta Bera"], "title": "Resolving Open Problems on the Euler Sombor Index", "comment": null, "summary": "Recently, the Euler Sombor index $(EUS)$ was introduced as a novel\ndegree-based topological index. For a graph $G$, the Euler Sombor index is\ndefined as $$EUS(G) = \\sum_{v_i v_j \\in E(G)} \\sqrt{d_i^2 + d_j^2 + d_i d_j},$$\nwhere $d_i$ and $d_j$ denote the degrees of the vertices $v_i$ and $v_j$,\nrespectively. Very recently, Khanra and Das \\textbf{\\bf [Euler Sombor index of\ntrees, unicyclic and chemical graphs, \\emph{MATCH Commun. Math. Comput. Chem.}\n\\textbf{94} (2025) 525--548]} proposed several open problems concerning the\nEuler Sombor index. This paper completely resolves two of the most challenging\nproblems posed therein. First, we determine the minimum value of the $EUS$\nindex among all unicyclic graphs of a fixed order and prescribed girth, and we\ncharacterize the extremal graphs that attain this minimum. Building on this\nresult, we further establish the minimum $EUS$ index within the broader class\nof connected graphs of the same order and girth, and identify the corresponding\nextremal structures. In addition, we classify all connected graphs that attain\nthe maximum Euler Sombor index $(EUS)$ when both the order and the number of\nleaves are fixed.", "AI": {"tldr": "本文解决了关于Euler Sombor指数（$EUS$）的两个开放性问题：确定了固定阶数和围长的单圈图中$EUS$的最小值及其极值图，并进一步扩展到更广泛的连通图类；同时分类了在固定阶数和叶子数时达到最大$EUS$的所有连通图。", "motivation": "Khanra和Das在关于Euler Sombor指数的研究中提出了若干开放性问题，本文旨在解决其中最具挑战性的两个问题，即极值图的确定与分类。", "method": "通过数学推导和图论分析，首先在单圈图中确定$EUS$的最小值及极值图，随后将结果推广到连通图类，并对固定阶数和叶子数的连通图进行最大$EUS$的分类。", "result": "确定了单圈图和连通图中$EUS$的最小值及对应的极值结构，并分类了在固定阶数和叶子数时达到最大$EUS$的所有连通图。", "conclusion": "本文完全解决了Khanra和Das提出的两个开放性问题，为Euler Sombor指数的极值研究提供了完整的理论框架和具体结果。"}}
{"id": "2507.16872", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16872", "abs": "https://arxiv.org/abs/2507.16872", "authors": ["Na Li", "Yansong Gao", "Hongsheng Hu", "Boyu Kuang", "Anmin Fu"], "title": "CompLeak: Deep Learning Model Compression Exacerbates Privacy Leakage", "comment": null, "summary": "Model compression is crucial for minimizing memory storage and accelerating\ninference in deep learning (DL) models, including recent foundation models like\nlarge language models (LLMs). Users can access different compressed model\nversions according to their resources and budget. However, while existing\ncompression operations primarily focus on optimizing the trade-off between\nresource efficiency and model performance, the privacy risks introduced by\ncompression remain overlooked and insufficiently understood.\n  In this work, through the lens of membership inference attack (MIA), we\npropose CompLeak, the first privacy risk evaluation framework examining three\nwidely used compression configurations that are pruning, quantization, and\nweight clustering supported by the commercial model compression framework of\nGoogle's TensorFlow-Lite (TF-Lite) and Facebook's PyTorch Mobile. CompLeak has\nthree variants, given available access to the number of compressed models and\noriginal model. CompLeakNR starts by adopting existing MIA methods to attack a\nsingle compressed model, and identifies that different compressed models\ninfluence members and non-members differently. When the original model and one\ncompressed model are available, CompLeakSR leverages the compressed model as a\nreference to the original model and uncovers more privacy by combining meta\ninformation (e.g., confidence vector) from both models. When multiple\ncompressed models are available with/without accessing the original model,\nCompLeakMR innovatively exploits privacy leakage info from multiple compressed\nversions to substantially signify the overall privacy leakage. We conduct\nextensive experiments on seven diverse model architectures (from ResNet to\nfoundation models of BERT and GPT-2), and six image and textual benchmark\ndatasets.", "AI": {"tldr": "本文提出CompLeak框架，首次系统评估了模型压缩（剪枝、量化和权重聚类）带来的隐私风险，通过成员推理攻击（MIA）揭示了不同压缩配置下的隐私泄露问题，并在多种模型架构和数据集上验证了其有效性。", "motivation": "当前模型压缩技术主要关注资源效率与性能的权衡，却忽视了压缩操作引入的隐私风险。本研究旨在填补这一空白，揭示压缩模型可能导致的隐私泄露问题。", "method": "CompLeak框架包含三种变体：1) CompLeakNR（单压缩模型攻击）；2) CompLeakSR（原始模型+单压缩模型联合分析）；3) CompLeakMR（多压缩模型协同攻击）。实验覆盖TensorFlow-Lite和PyTorch Mobile支持的三种主流压缩方法，在7种模型架构（包括BERT和GPT-2）和6个数据集上进行验证。", "result": "实验表明：1) 不同压缩模型对成员/非成员数据表现出差异性敏感度；2) 结合原始模型元信息（如置信度向量）可显著增强攻击效果；3) 多压缩模型协同分析能进一步放大隐私泄露风险。", "conclusion": "模型压缩会引入新的隐私攻击面，现有压缩技术需重新审视其安全性。CompLeak为量化隐私风险提供了方法论基础，未来压缩算法设计应兼顾效率与隐私保护。"}}
{"id": "2507.17069", "categories": ["math.OC", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2507.17069", "abs": "https://arxiv.org/abs/2507.17069", "authors": ["Xuemei Chen", "Owen Deen"], "title": "The Generalized Matrix Separation Problem: Algorithms", "comment": "24 pages", "summary": "When given a generalized matrix separation problem, which aims to recover a\nlow rank matrix $L_0$ and a sparse matrix $S_0$ from $M_0=L_0+HS_0$, the work\n\\cite{CW25} proposes a novel convex optimization problem whose objective\nfunction is the sum of the $\\ell_1$-norm and nuclear norm. In this paper we\ndetail the iterative algorithms and its associated computations for solving\nthis convex optimization problem. We present various efficient implementation\nstrategies, with attention to practical cases where $H$ is circulant,\nseparable, or block structured. Notably, we propose a preconditioning technique\nthat drastically improved the performance of our algorithms in terms of\nefficiency, accuracy, and robustness. While this paper serves as an\nillustrative algorithm implementation manual, we also provide theoretical\nguarantee for our preconditioning strategy. Numerical results illustrate the\neffectiveness of the proposed approach.", "AI": {"tldr": "本文详细阐述了解决广义矩阵分离问题的迭代算法，提出了一种结合$\\ell_1$范数与核范数的凸优化方法，并针对不同结构的矩阵$H$提出了高效实现策略，特别是通过预条件技术显著提升了算法性能。", "motivation": "广义矩阵分离问题旨在从$M_0=L_0+HS_0$中恢复低秩矩阵$L_0$和稀疏矩阵$S_0$，本文旨在提供高效的算法实现及理论保证。", "method": "提出了一种基于$\\ell_1$范数与核范数之和的凸优化问题，详细描述了迭代算法及计算过程，特别针对$H$为循环、可分或块结构的情况提出了高效实现策略，并引入了预条件技术。", "result": "数值实验表明，所提出的预条件技术显著提高了算法的效率、精度和鲁棒性，验证了方法的有效性。", "conclusion": "本文不仅提供了算法实现的详细手册，还为预条件策略提供了理论保证，数值结果证明了所提方法的高效性和实用性。"}}
{"id": "2507.17517", "categories": ["math.LO", "math.GR", "03E25, 20E05, 28A05"], "pdf": "https://arxiv.org/pdf/2507.17517", "abs": "https://arxiv.org/abs/2507.17517", "authors": ["Cesare Straffelini", "Kilian Zambanini"], "title": "Minimal Banach-Tarski Decompositions", "comment": "18 pages", "summary": "We investigate the problem of finding the minimum number of pieces necessary\nfor dividing a three-dimensional sphere or a ball and reassembling it to form\n$n$ congruent copies of the original object, generalising a known result by\nRaphael Robinson.", "AI": {"tldr": "研究三维球体分割重组为n个全等副本所需的最少块数，推广了Raphael Robinson的已知结果。", "motivation": "探索三维空间中球体分割与重组的数学问题，扩展已有的一维和二维结果至三维情形。", "method": "通过几何分割与重组技术，分析球体或球体分割为全等副本的最小块数。", "result": "确定了将三维球体或球体分割重组为n个全等副本所需的最少块数。", "conclusion": "该研究为三维空间中的分割重组问题提供了新的理论结果，推广了Raphael Robinson的工作。"}}
{"id": "2507.17021", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.17021", "abs": "https://arxiv.org/abs/2507.17021", "authors": ["Joshua Harrington", "Lenny Jones"], "title": "Monogenic sextic trinomials $x^6+Ax^3+B$ and their Galois groups", "comment": null, "summary": "Let $f(x)=x^6+Ax^3+B\\in {\\mathbb Z}[x]$, with $A\\ne 0$, and suppose that\n$f(x)$ is irreducible over ${\\mathbb Q}$. We define $f(x)$ to be {\\em\nmonogenic} if $\\{1,\\theta,\\theta^2,\\theta^3,\\theta^4,\\theta^{5}\\}$ is a basis\nfor the ring of integers of ${\\mathbb Q}(\\theta)$, where $f(\\theta)=0$.\n  For each possible Galois group $G$ of $f(x)$ over ${\\mathbb Q}$, we use a\ntheorem of Jakhar, Khanduja and Sangwan to give explicit descriptions of all\nmonogenic trinomials $f(x)$ having Galois group $G$. We also investigate when\nthese trinomials generate distinct sextic fields.", "AI": {"tldr": "本文研究了具有特定形式$x^6+Ax^3+B$的不可约六次三项式，给出了其在不同伽罗瓦群下成为单基多项式的显式描述，并探讨了生成不同六次数域的条件。", "motivation": "动机在于明确刻画具有形式$x^6+Ax^3+B$的不可约三项式在何种条件下成为单基多项式（即其根生成的整数环具有幂基），并分类其伽罗瓦群结构。", "method": "方法上采用Jakhar-Khanduja-Sangwan定理，针对该三项式所有可能的伽罗瓦群$G$，系统构造了满足单基性条件的显式参数化描述。", "result": "结果为每个可能的伽罗瓦群$G$给出了对应的单基三项式的完整参数化表达，并分析了这些多项式生成不同六次数域的条件。", "conclusion": "结论完整解决了该类六次单基三项式的分类问题，为代数数论中的幂基研究提供了新的具体范例。"}}
{"id": "2507.17168", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17168", "abs": "https://arxiv.org/abs/2507.17168", "authors": ["Qifan Zhang", "Nuo Chen", "Zehua Li", "Miao Peng", "Jing Tang", "Jia Li"], "title": "Improving LLMs' Generalized Reasoning Abilities by Graph Problems", "comment": "COLM2025", "summary": "Large Language Models (LLMs) have made remarkable strides in reasoning tasks,\nyet their performance often falters on novel and complex problems.\nDomain-specific continued pretraining (CPT) methods, such as those tailored for\nmathematical reasoning, have shown promise but lack transferability to broader\nreasoning tasks. In this work, we pioneer the use of Graph Problem Reasoning\n(GPR) to enhance the general reasoning capabilities of LLMs. GPR tasks,\nspanning pathfinding, network analysis, numerical computation, and topological\nreasoning, require sophisticated logical and relational reasoning, making them\nideal for teaching diverse reasoning patterns. To achieve this, we introduce\nGraphPile, the first large-scale corpus specifically designed for CPT using GPR\ndata. Spanning 10.9 billion tokens across 23 graph tasks, the dataset includes\nchain-of-thought, program-of-thought, trace of execution, and real-world graph\ndata. Using GraphPile, we train GraphMind on popular base models Llama 3 and\n3.1, as well as Gemma 2, achieving up to 4.9 percent higher accuracy in\nmathematical reasoning and up to 21.2 percent improvement in non-mathematical\nreasoning tasks such as logical and commonsense reasoning. By being the first\nto harness GPR for enhancing reasoning patterns and introducing the first\ndataset of its kind, our work bridges the gap between domain-specific\npretraining and universal reasoning capabilities, advancing the adaptability\nand robustness of LLMs.", "AI": {"tldr": "本文提出GraphPile数据集和GraphMind模型，通过图问题推理（GPR）增强大语言模型（LLM）的通用推理能力，在数学与非数学推理任务中均取得显著提升。", "motivation": "现有领域持续预训练（CPT）方法在数学推理等特定任务上表现良好，但缺乏向通用推理任务的迁移能力。图问题推理因其复杂的逻辑与关系推理特性，被视为提升LLM通用推理能力的理想途径。", "method": "构建首个大规模GPR数据集GraphPile（109亿token/23类图任务），包含思维链、程序思维、执行轨迹和真实图数据。基于Llama 3/3.1和Gemma 2训练GraphMind模型。", "result": "GraphMind在数学推理任务中准确率提升4.9%，在逻辑推理和常识推理等非数学任务中提升达21.2%，显著优于领域特定预训练方法。", "conclusion": "该研究首次将GPR用于增强LLM推理模式，通过GraphPile数据集弥合领域预训练与通用推理能力的鸿沟，推动LLM适应性与鲁棒性的发展。"}}
{"id": "2507.17302", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.17302", "abs": "https://arxiv.org/abs/2507.17302", "authors": ["Kecai Deng"], "title": "Bipartite graphs with minimum degree at least 15 are antimagic", "comment": null, "summary": "An antimagic {labeling} of a graph $G=(V,E)$ is a one-to-one mapping $f:\nE\\rightarrow\\{1,2,\\ldots,|E|\\}$, ensuring that the vertex sums in $V$ are\npairwise distinct, where a vertex sum of a vertex $v$ is defined as the sum of\nthe labels of the edges incident to $v$. A graph is called antimagic if it\nadmits an antimagic labeling. The Antimagic Labeling Conjecture, proposed by\nHartsfield and Ringel in 1990, posits that every connected graph other than\n$K_2$ is antimagic. The conjecture was confirmed for graphs of average degree\nat least 4,182 in 2016 by Eccles, where it was stated that a similar approach\ncould not reduce the bound below 1,000 from 4,182.\n  This paper shows that every bipartite graph with minimum degree at least 15\nis antimagic. Our approach relies on three tools: a consequence of K\\\"{o}nig's\nTheorem, the existence of a subgraph of a specific size that avoids Eulerian\ncomponents, and a labeling lemma that ensures some vertex sums are divisible by\nthree while others are not.", "AI": {"tldr": "本文证明了最小度数至少为15的二部图具有反魔术标号，推进了Hartsfield和Ringel于1990年提出的反魔术标号猜想的研究。", "motivation": "反魔术标号猜想认为除$K_2$外的所有连通图都存在反魔术标号。2016年Eccles证明了平均度数至少为4,182的图满足该猜想，但无法将下限降至1,000。本研究旨在探索更宽松条件下的证明。", "method": "采用三个关键工具：K\\\"{o}nig定理的推论、避免欧拉分量的特定大小子图的存在性，以及确保部分顶点和可被3整除而其他不可的标号引理。", "result": "证明了所有最小度数至少为15的二部图都具有反魔术标号，突破了先前对高平均度数图的研究限制。", "conclusion": "该研究通过创新方法将反魔术标号猜想在二部图上的证明条件显著放宽，为完全解决该猜想提供了新思路。"}}
{"id": "2507.16887", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16887", "abs": "https://arxiv.org/abs/2507.16887", "authors": ["Youpeng Li", "Weiliang Qi", "Xuyu Wang", "Fuxun Yu", "Xinda Wang"], "title": "Revisiting Pre-trained Language Models for Vulnerability Detection", "comment": null, "summary": "The rapid advancement of pre-trained language models (PLMs) has demonstrated\npromising results for various code-related tasks. However, their effectiveness\nin detecting real-world vulnerabilities remains a critical challenge. % for the\nsecurity community. While existing empirical studies evaluate PLMs for\nvulnerability detection (VD), their inadequate consideration in data\npreparation, evaluation setups, and experimental settings undermines the\naccuracy and comprehensiveness of evaluations. This paper introduces RevisitVD,\nan extensive evaluation of 17 PLMs spanning smaller code-specific PLMs and\nlarge-scale PLMs using newly constructed datasets. Specifically, we compare the\nperformance of PLMs under both fine-tuning and prompt engineering, assess their\neffectiveness and generalizability across various training and testing\nsettings, and analyze their robustness against code normalization, abstraction,\nand semantic-preserving transformations.\n  Our findings reveal that, for VD tasks, PLMs incorporating pre-training tasks\ndesigned to capture the syntactic and semantic patterns of code outperform both\ngeneral-purpose PLMs and those solely pre-trained or fine-tuned on large code\ncorpora. However, these models face notable challenges in real-world scenarios,\nsuch as difficulties in detecting vulnerabilities with complex dependencies,\nhandling perturbations introduced by code normalization and abstraction, and\nidentifying semantic-preserving vulnerable code transformations. Also, the\ntruncation caused by the limited context windows of PLMs can lead to a\nnon-negligible amount of labeling errors. This study underscores the importance\nof thorough evaluations of model performance in practical scenarios and\noutlines future directions to help enhance the effectiveness of PLMs for\nrealistic VD applications.", "AI": {"tldr": "本文提出RevisitVD框架，对17种预训练语言模型(PLMs)在漏洞检测(VD)任务中的表现进行全面评估，发现专为代码设计的PLMs优于通用模型，但面对复杂依赖、代码规范化扰动等现实场景仍存在显著挑战。", "motivation": "现有研究对预训练语言模型在漏洞检测任务中的评估存在数据准备、实验设置等方面的不足，导致评估结果不够准确全面。本文旨在通过系统性实验填补这一空白。", "method": "构建新数据集，比较17种PLMs在微调和提示工程下的表现，评估模型在不同训练/测试设置中的有效性、泛化性及对抗代码规范化/抽象化/语义保持变换的鲁棒性。", "result": "专为代码语法语义模式设计的PLMs表现最优，但存在三大局限：1) 难检测复杂依赖漏洞 2) 抗代码规范化扰动能力弱 3) 受限于上下文窗口导致标注错误。", "conclusion": "研究强调需加强模型在实际场景中的性能评估，并为提升PLMs在真实漏洞检测应用中的有效性指明未来方向。"}}
{"id": "2507.17115", "categories": ["math.OC", "cs.SY", "econ.TH", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.17115", "abs": "https://arxiv.org/abs/2507.17115", "authors": ["Lendy Banegas", "Fredy Vides"], "title": "Stochastically Structured Reservoir Computers for Financial and Economic System Identification", "comment": null, "summary": "This paper introduces a methodology for identifying and simulating financial\nand economic systems using stochastically structured reservoir computers\n(SSRCs). The proposed framework leverages structure-preserving embeddings and\ngraph-informed coupling matrices to model inter-agent dynamics with enhanced\ninterpretability. A constrained optimization scheme ensures that the learned\nmodels satisfy both stochastic and structural constraints. Two empirical case\nstudies, a dynamic behavioral model of resource competition among agents, and\nregional inflation network dynamics, illustrate the effectiveness of the\napproach in capturing and anticipating complex nonlinear patterns and enabling\ninterpretable predictive analysis under uncertainty.", "AI": {"tldr": "本文提出了一种基于随机结构储层计算机（SSRCs）的金融经济系统识别与模拟方法，通过结构保持嵌入和图信息耦合矩阵增强模型可解释性，并通过约束优化确保模型满足随机与结构约束。", "motivation": "现有金融经济系统模型在捕捉非线性动态和保持可解释性方面存在不足，需要一种能同时满足随机性与结构性约束的新方法。", "method": "采用随机结构储层计算机框架，结合结构保持嵌入和图信息耦合矩阵建模代理间动态，并通过约束优化算法确保模型合规性。", "result": "两个案例研究（资源竞争行为模型和区域通胀网络动态）表明，该方法能有效捕捉复杂非线性模式，并在不确定性下实现可解释预测分析。", "conclusion": "SSRC框架为金融经济系统提供了兼具预测准确性和结构可解释性的建模工具，特别适用于多代理非线性动态场景。"}}
{"id": "2507.17715", "categories": ["math.LO"], "pdf": "https://arxiv.org/pdf/2507.17715", "abs": "https://arxiv.org/abs/2507.17715", "authors": ["Joseph McDonald"], "title": "Canonical completion and duality for cylindric ortholattices and cylindric Boolean algebras", "comment": null, "summary": "In this note, we investigate the algebraic and topological representation\ntheory of cylindric ortholattices and cylindric Boolean algebras. The first\ncontribution demonstrates that cylindric ortholattices are closed under\ncanonical completions. By equipping a spectral topology to the dual space\nassociated with the canonical completion, we then establish a dual equivalence\nbetween the category of cylindric ortholattices and a certain subcategory of\nthe category of spectral spaces. This work builds on the completion and duality\nresults obtained by Harding, McDonald, and Peinado in the setting of monadic\northolattices combined with the duality results obtained by McDonald and\nYamamoto in the setting of general ortholattices. By working with the duality\ntheory for Boolean algebras established by Bezhanishvili and Holliday, we then\nobtain completion and duality results for cylindric Boolean algebras. A key\naspect of our duality results is that they are constructive in the sense that\nthey obtain in Zermelo-Fraenkel set theory independently of the Axiom of\nChoice.", "AI": {"tldr": "本文研究了柱形正交格和柱形布尔代数的代数与拓扑表示理论，证明了柱形正交格在规范完备化下封闭，并建立了其与谱空间子范畴的对偶等价关系。", "motivation": "研究柱形正交格和柱形布尔代数的表示理论，扩展Harding、McDonald和Peinado在单子正交格中的完备性与对偶性结果，结合McDonald和Yamamoto在一般正交格中的对偶性成果。", "method": "通过为规范完备化的对偶空间赋予谱拓扑，结合Bezhanishvili和Holliday的布尔代数对偶理论，采用构造性方法在Zermelo-Fraenkel集合论中独立于选择公理完成证明。", "result": "证明了柱形正交格在规范完备化下封闭，并建立了其与谱空间子范畴的构造性对偶等价关系；进一步获得了柱形布尔代数的完备性与对偶性结果。", "conclusion": "本文不仅推广了正交格与布尔代数的对偶理论，还通过构造性方法在基础集合论框架内实现了对偶性证明，为相关领域提供了新的理论工具。"}}
{"id": "2507.17041", "categories": ["math.NT", "11F11, 11F67"], "pdf": "https://arxiv.org/pdf/2507.17041", "abs": "https://arxiv.org/abs/2507.17041", "authors": ["Tianyu Ni", "Hui Xue"], "title": "Twisted periods of modular forms", "comment": null, "summary": "Let $S_k$ denote the space of cusp forms of weight $k$ and level one. For\n$0\\leq t\\leq k-2$ and primitive Dirichlet character $\\chi$ mod $D$, we\nintroduce twisted periods $r_{t,\\chi}$ on $S_k$. We show that for a fixed\nnatural number $n$, if $k$ is sufficiently large relative to $n$ and $D$, then\nany $n$ periods with the same twist but different indices are linearly\nindependent. We also prove that if $k$ is sufficiently large relative to $D$\nthen any $n$ periods with the same index but different twists mod $D$ are\nlinearly independent. These results are achieved by studying the trace of the\nproducts and Rankin-Cohen brackets of Eisenstein series of level $D$ with\nnebentypus. Moreover, we give two applications of our method. First, we prove\ncertain identities that evaluate convolution sums of twisted divisor functions.\nSecond, we show that Maeda's conjecture implies a non-vanishing result on\ntwisted central $L$-values of normalized Hecke eigenforms.", "AI": {"tldr": "本文研究了权为$k$、水平为1的尖点形式$S_k$上的扭曲周期$r_{t,\\chi}$。证明了在$k$足够大时，具有相同扭曲但不同指数的周期或相同指数但不同扭曲的周期线性无关。方法涉及Eisenstein级数的迹与Rankin-Cohen括号，并应用于卷积和与$L$值非零性。", "motivation": "探索尖点形式$S_k$上扭曲周期的线性独立性，及其在数论中的应用，如卷积和与$L$值的非零性。", "method": "通过研究带nebentypus的水平$D$的Eisenstein级数的乘积与Rankin-Cohen括号的迹，分析扭曲周期的线性独立性。", "result": "证明了当$k$足够大时，相同扭曲不同指数或相同指数不同扭曲的$n$个周期线性无关。并应用该方法得到卷积和恒等式与$L$值非零性结果。", "conclusion": "本文建立了扭曲周期线性独立性的新结果，并展示了其在数论问题中的广泛应用，特别是与Maeda猜想相关的$L$值非零性。"}}
{"id": "2507.17214", "categories": ["cs.AI", "cs.CY", "cs.NI", "cs.SY", "eess.SY", "I.2; B.8; C.2; I.5; J.7"], "pdf": "https://arxiv.org/pdf/2507.17214", "abs": "https://arxiv.org/abs/2507.17214", "authors": ["Amod Kant Agrawal"], "title": "Our Cars Can Talk: How IoT Brings AI to Vehicles", "comment": "3 pages, 1 figure; To appear in IEEE Computer (Nov 2025)", "summary": "Bringing AI to vehicles and enabling them as sensing platforms is key to\ntransforming maintenance from reactive to proactive. Now is the time to\nintegrate AI copilots that speak both languages: machine and driver. This\narticle offers a conceptual and technical perspective intended to spark\ninterdisciplinary dialogue and guide future research and development in\nintelligent vehicle systems, predictive maintenance, and AI-powered user\ninteraction.", "AI": {"tldr": "将AI引入车辆作为感知平台，实现从被动到主动的维护转变，并提出整合AI副驾驶的概念。", "motivation": "通过AI技术提升车辆智能化水平，改变传统被动维护模式，促进车辆系统与驾驶员的交互。", "method": "从概念和技术角度探讨AI副驾驶的整合，旨在推动跨学科对话。", "result": "为智能车辆系统、预测性维护和AI驱动的用户交互研究提供指导方向。", "conclusion": "AI与车辆的融合是未来研究的关键领域，需进一步探索技术实现与跨学科合作。"}}
{"id": "2507.17341", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.17341", "abs": "https://arxiv.org/abs/2507.17341", "authors": ["Athira Divakaran", "Tijo James", "Sandi Klavžar", "Latha S Nair"], "title": "Maker-Breaker total domination number", "comment": null, "summary": "The Maker-Breaker total domination number, $\\gamma_{\\rm MBT}(G)$, of a graph\n$G$ is introduced as the minimum number of moves of Dominator to win the\nMaker-Breaker total domination game, provided that he has a winning strategy\nand is the first to play. The Staller-start Maker-Breaker total domination\nnumber, $\\gamma_{\\rm MBT}'(G)$, is defined analogously for the game in which\nStaller starts. Upper and lower bounds on $\\gamma_{\\rm MBT}(G)$ and on\n$\\gamma_{\\rm MBT}'(G)$ are provided and demonstrated to be sharp. It is proved\nthat for any pair of integers $(k,\\ell)$ with $2\\leq k\\leq \\ell$, (i) there\nexists a connected graph $G$ with $\\gamma_{\\rm MB}(G)=k$ and $\\gamma_{\\rm\nMBT}(G)=\\ell$, (ii) there exists a connected graph $G'$ with $\\gamma_{\\rm\nMB}'(G')=k$ and $\\gamma_{\\rm MBT}'(G')=\\ell$, and (iii) there there exists a\nconnected graph $G''$ with $\\gamma_{\\rm MBT}(G'')=k$ and $\\gamma_{\\rm\nMBT}'(G'')=\\ell$. Here, $\\gamma_{\\rm MB}$ and $\\gamma_{\\rm MB}'$ are\ncorresponding invariants for the Maker-Breaker domination game.", "AI": {"tldr": "本文引入了图的总支配Maker-Breaker数$\\gamma_{\\rm MBT}(G)$及其Staller起始版本$\\gamma_{\\rm MBT}'(G)$，证明了其上下界并构造了满足特定整数对的连通图。", "motivation": "研究图论中Maker-Breaker总支配游戏的最小步数问题，拓展了传统支配游戏的理论框架。", "method": "通过定义$\\gamma_{\\rm MBT}(G)$和$\\gamma_{\\rm MBT}'(G)$两个新参数，建立上下界并构造示例图验证紧性。", "result": "对于任意$2\\leq k\\leq \\ell$的整数对，存在连通图分别满足：(i)$\\gamma_{\\rm MB}(G)=k$且$\\gamma_{\\rm MBT}(G)=\\ell$；(ii)Staller起始的对应情形；(iii)混合参数情形。", "conclusion": "该研究完善了Maker-Breaker支配理论体系，所提出的总支配参数具有明确的图论意义和构造可行性。"}}
{"id": "2507.16952", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16952", "abs": "https://arxiv.org/abs/2507.16952", "authors": ["Md Min-Ha-Zul Abedin", "Tazqia Mehrub"], "title": "Evaluating Ensemble and Deep Learning Models for Static Malware Detection with Dimensionality Reduction Using the EMBER Dataset", "comment": null, "summary": "This study investigates the effectiveness of several machine learning\nalgorithms for static malware detection using the EMBER dataset, which contains\nfeature representations of Portable Executable (PE) files. We evaluate eight\nclassification models: LightGBM, XGBoost, CatBoost, Random Forest, Extra Trees,\nHistGradientBoosting, k-Nearest Neighbors (KNN), and TabNet, under three\npreprocessing settings: original feature space, Principal Component Analysis\n(PCA), and Linear Discriminant Analysis (LDA). The models are assessed on\naccuracy, precision, recall, F1 score, and AUC to examine both predictive\nperformance and robustness. Ensemble methods, especially LightGBM and XGBoost,\nshow the best overall performance across all configurations, with minimal\nsensitivity to PCA and consistent generalization. LDA improves KNN performance\nbut significantly reduces accuracy for boosting models. TabNet, while promising\nin theory, underperformed under feature reduction, likely due to architectural\nsensitivity to input structure. The analysis is supported by detailed\nexploratory data analysis (EDA), including mutual information ranking, PCA or\nt-SNE visualizations, and outlier detection using Isolation Forest and Local\nOutlier Factor (LOF), which confirm the discriminatory capacity of key features\nin the EMBER dataset. The results suggest that boosting models remain the most\nreliable choice for high-dimensional static malware detection, and that\ndimensionality reduction should be applied selectively based on model type.\nThis work provides a benchmark for comparing classification models and\npreprocessing strategies in malware detection tasks and contributes insights\nthat can guide future system development and real-world deployment.", "AI": {"tldr": "本研究评估了八种机器学习算法在EMBER数据集上的静态恶意软件检测效果，发现集成方法（尤其是LightGBM和XGBoost）在所有配置中表现最佳，而特征降维需根据模型类型选择性应用。", "motivation": "探讨不同机器学习算法及预处理方法在高维静态恶意软件检测中的性能差异，为实际系统开发提供基准和指导。", "method": "使用EMBER数据集，评估LightGBM、XGBoost等八种分类模型在原始特征空间、PCA和LDA三种预处理设置下的表现，通过准确率、召回率等指标及EDA分析（包括互信息排序、t-SNE可视化等）验证特征判别能力。", "result": "集成方法（特别是LightGBM和XGBoost）在所有配置中表现最优且对PCA不敏感；LDA提升了KNN但显著降低了提升模型的准确率；TabNet在特征降维下表现不佳。EDA证实了EMBER数据集关键特征的判别能力。", "conclusion": "提升模型是高维静态恶意软件检测最可靠的选择，特征降维需根据模型类型谨慎应用。本研究为分类模型和预处理策略的比较提供了基准，对实际部署具有指导意义。"}}
{"id": "2507.17272", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.17272", "abs": "https://arxiv.org/abs/2507.17272", "authors": ["R. Diaz Millan", "Orizon Pereira Ferreira", "Julien Ugon"], "title": "Frank-Wolfe algorithm for star-convex functions", "comment": "12 pages", "summary": "We study the Frank-Wolfe algorithm for minimizing a differentiable function\nwith Lipschitz continuous gradient over a compact convex set. To extend\nclassical complexity bounds to certain non-convex functions, we focus on the\nclass of \\emph{star-convex functions}, which retain essential geometric\nproperties despite the lack of convexity. We establish iteration-complexity\nbounds of $\\mathcal{O}(1/k)$ for both the objective values and the duality gap\nunder star-convexity, using diminishing, Armijo-type, and Lipschitz-based\nstepsize rules. Notably, the diminishing and Armijo strategies do not require\nprior knowledge of Lipschitz or curvature constants. These results demonstrate\nthat the Frank-Wolfe method preserves optimal complexity guarantees beyond the\nconvex setting.", "AI": {"tldr": "本文研究了Frank-Wolfe算法在星凸函数上的应用，证明了在多种步长规则下仍保持$\\mathcal{O}(1/k)$的迭代复杂度，扩展了经典凸优化结果。", "motivation": "为了将经典凸优化复杂度结果推广到非凸函数，研究聚焦于具有Lipschitz连续梯度的星凸函数，这类函数虽非凸但保留了关键几何特性。", "method": "采用Frank-Wolfe算法，分析其在星凸函数上的表现，测试了递减步长、Armijo型步长和基于Lipschitz的步长规则，其中前两种无需预知Lipschitz或曲率常数。", "result": "在星凸性假设下，无论目标函数值还是对偶间隙均达到$\\mathcal{O}(1/k)$的迭代复杂度界限，证明算法在非凸环境下仍保持最优复杂度保证。", "conclusion": "研究表明Frank-Wolfe方法能超越凸优化框架，在更广泛的星凸函数类中维持最优复杂度特性，为算法应用提供了理论扩展。"}}
{"id": "2507.17724", "categories": ["math.LO"], "pdf": "https://arxiv.org/pdf/2507.17724", "abs": "https://arxiv.org/abs/2507.17724", "authors": ["Joseph McDonald"], "title": "Orthogonality relations and operators on bounded quasi-implication algebras", "comment": null, "summary": "In this note, we study various relational and algebraic aspects of the\nbounded quasi-implication algebras introduced by Hardegree. By generalizing the\nconstructions given by MacLaren and Goldblatt within the setting of\northolattices, we construct various orthogonality relations from bounded\nquasi-implication algebras.\n  We then introduce certain bounded quasi-implication algebras with an\nadditional operator, which we call monadic quasi-implication algebras, and\nstudy them within the setting of quantum monadic algebras. A quantum monadic\nalgebra is an orthomodular lattice equipped with a closure operator, known as a\nquantifier, whose closed elements form an orthomodular sub-lattice. It is shown\nthat every quantum monadic algebra can be converted into a monadic\nquasi-implication algebra with the underlying magma structure being determined\nby the operation of Sasaki implication on the underlying orthomodular lattice.\nIt is then conversely demonstrated that every monadic quasi-implication algebra\ncan be converted into a quantum monadic algebra. These constructions are shown\nto induce an isomorphism between the category of quantum monadic algebras and\nthe category of monadic quasi-implication algebras.\n  Finally, by generalizing the constructions given by Harding as well as\nHarding, McDonald, and Peinado in the setting of monadic ortholattices, we\nconstruct various monadic orthoframes from monadic quasi-implication algebras.", "AI": {"tldr": "本文研究了Hardegree提出的有界拟蕴涵代数的关系与代数性质，通过推广MacLaren和Goldblatt在正交格中的构造，构建了多种正交关系。进一步引入了带算子的有界拟蕴涵代数（称为单子拟蕴涵代数），并在量子单子代数框架下进行研究。证明了量子单子代数与单子拟蕴涵代数之间的相互转换及范畴同构性，最后推广了Harding等人的构造，从单子拟蕴涵代数构建了多种单子正交框架。", "motivation": "研究有界拟蕴涵代数的关系与代数性质，探索其在量子单子代数中的应用，并建立与正交结构的联系。", "method": "推广MacLaren和Goldblatt的构造方法，构建正交关系；引入单子拟蕴涵代数并研究其与量子单子代数的关系；推广Harding等人的构造方法构建单子正交框架。", "result": "证明了量子单子代数与单子拟蕴涵代数之间的相互转换及范畴同构性；成功从单子拟蕴涵代数构建了多种单子正交框架。", "conclusion": "本文通过推广多种构造方法，建立了有界拟蕴涵代数与量子单子代数之间的深刻联系，为相关代数结构的研究提供了新的视角和工具。"}}
{"id": "2507.17167", "categories": ["math.NT", "math.DS"], "pdf": "https://arxiv.org/pdf/2507.17167", "abs": "https://arxiv.org/abs/2507.17167", "authors": ["Gerardo González Robert", "Mumtaz Hussain", "Benjamin Ward", "Lauren White"], "title": "Continued fractions with large prime partial quotients", "comment": "24 pages, comments welcome", "summary": "We determine the Lebesgue measure and Hausdorff dimension of various sets of\nreal numbers with infinitely many partial quotients that are both large and\nprime, thus extending the well-known theorems by {\\L}uczak (1997) and\nHuang-Wu-Xu (2020). To this end, we obtain new asymptotics on the tail end of\nthe almost prime zeta function. Our results include some recent work by\nSchindler-Zweim{\\\"u}ller (2023).", "AI": {"tldr": "本文通过研究实数集中具有无限多个大且为素数的部分商的集合，扩展了{\\L}uczak (1997)和Huang-Wu-Xu (2020)的定理，并给出了几乎素数zeta函数尾部的新渐近结果。", "motivation": "研究具有无限多个大且为素数的部分商的实数集的Lebesgue测度和Hausdorff维数，以扩展已有理论并填补相关领域的空白。", "method": "通过分析几乎素数zeta函数的尾部渐近行为，结合数论和分形几何的方法，推导出相关集合的测度和维数。", "result": "确定了这些实数集的Lebesgue测度和Hausdorff维数，并得到了几乎素数zeta函数尾部的新渐近公式，部分结果与Schindler-Zweim{\\\"u}ller (2023)的研究一致。", "conclusion": "本文不仅扩展了{\\L}uczak和Huang-Wu-Xu的经典定理，还为相关领域提供了新的分析工具和结果，具有重要的理论意义。"}}
{"id": "2507.17257", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.17257", "abs": "https://arxiv.org/abs/2507.17257", "authors": ["Elija Perrier", "Michael Timothy Bennett"], "title": "Agent Identity Evals: Measuring Agentic Identity", "comment": null, "summary": "Central to agentic capability and trustworthiness of language model agents\n(LMAs) is the extent they maintain stable, reliable, identity over time.\nHowever, LMAs inherit pathologies from large language models (LLMs)\n(statelessness, stochasticity, sensitivity to prompts and\nlinguistically-intermediation) which can undermine their identifiability,\ncontinuity, persistence and consistency. This attrition of identity can erode\ntheir reliability, trustworthiness and utility by interfering with their\nagentic capabilities such as reasoning, planning and action. To address these\nchallenges, we introduce \\textit{agent identity evals} (AIE), a rigorous,\nstatistically-driven, empirical framework for measuring the degree to which an\nLMA system exhibit and maintain their agentic identity over time, including\ntheir capabilities, properties and ability to recover from state perturbations.\nAIE comprises a set of novel metrics which can integrate with other measures of\nperformance, capability and agentic robustness to assist in the design of\noptimal LMA infrastructure and scaffolding such as memory and tools. We set out\nformal definitions and methods that can be applied at each stage of the LMA\nlife-cycle, and worked examples of how to apply them.", "AI": {"tldr": "本文提出了一种名为\\textit{agent identity evals} (AIE)的框架，用于评估语言模型代理(LMAs)在时间维度上维持稳定身份的能力，以解决其因继承大语言模型(LLMs)的病理特性而导致的身份稳定性问题。", "motivation": "语言模型代理(LMAs)的身份稳定性对其代理能力和可信度至关重要，但其继承自大语言模型(LLMs)的无状态性、随机性等病理特性会削弱其身份的可识别性、连续性、持久性和一致性，从而影响其可靠性和实用性。", "method": "作者提出了AIE框架，这是一套严格的、基于统计的实证方法，用于量化LMA系统在时间维度上维持其代理身份的程度，包括其能力、属性及从状态扰动中恢复的能力。AIE包含一系列新指标，可与其他性能指标结合使用。", "result": "AIE框架提供了可在LMA生命周期各阶段应用的正式定义和方法，并通过实例展示了如何应用这些方法来优化LMA的基础设施和支撑结构(如记忆和工具)。", "conclusion": "AIE框架为评估和提升语言模型代理的身份稳定性提供了系统化的解决方案，有助于增强其代理能力、可信度和实用性，为LMA的设计和优化提供了重要工具。"}}
{"id": "2507.17370", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.17370", "abs": "https://arxiv.org/abs/2507.17370", "authors": ["Sébastien Ferenczi", "Luca Q. Zamboni"], "title": "Clustering, order conditions, and languages of interval exchanges", "comment": null, "summary": "For any interval exchange transformation $T$ (standard or generalized), if we\ndefine a morphism $\\phi$ from the set of letters to the\n  set of the return words of a word in the natural coding, respecting the\nlexicographical order, the word $\\phi v$ clusters (for the Burrows-Wheeler\ntransform) for the permutation of $T$ if and only if the word $v$ clusters for\nthe permutation of the induced map of $T$\n  on the cylinder $[w]$. When $T$ is symmetrical, all such natural codings are\nrich languages, and this implies that the two orders above are the same if $w$\nis a palindrome. Finally, we generalize the result, proved by using the\nclustering of a word $w$,\n  that $ww$ is produced by a generalized interval exchange transformation if\nand only if $ww$ is produced by a standard interval exchange transformation, to\nnon-clustering $w$: in the symmetric case, $w$ is produced by a\n  generalized interval exchange transformation if and only if $w$ is produced\nby a standard interval exchange transformation.", "AI": {"tldr": "该研究探讨了区间交换变换（IET）及其广义形式下的词汇聚类特性，证明了在对称情况下，广义与标准IET生成的词汇等价性。", "motivation": "研究旨在理解区间交换变换在自然编码中的词汇聚类行为，特别是广义与标准形式之间的关系，以扩展对词汇生成机制的理论认识。", "method": "通过定义字母集到返回词汇集的态射$\\phi$，并利用Burrows-Wheeler变换的聚类性质，分析词汇$\\phi v$与诱导映射下的词汇$v$的关联性。对称情况下，进一步验证回文词汇的序等价性。", "result": "发现对称区间交换变换中，广义IET生成的词汇当且仅当标准IET可生成时成立，且自然编码均为丰富语言。非聚类词汇的生成条件在对称情况下同样成立。", "conclusion": "研究统一了广义与标准区间交换变换在词汇生成上的等价性，尤其在对称情形下，为语言理论中的变换分类提供了新判据。"}}
{"id": "2507.16996", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16996", "abs": "https://arxiv.org/abs/2507.16996", "authors": ["Iman Vakilinia"], "title": "From Cracks to Crooks: YouTube as a Vector for Malware Distribution", "comment": null, "summary": "With billions of users and an immense volume of daily uploads, YouTube has\nbecome an attractive target for cybercriminals aiming to leverage its vast\naudience. The platform's openness and trustworthiness provide an ideal\nenvironment for deceptive campaigns that can operate under the radar of\nconventional security tools. This paper explores how cybercriminals exploit\nYouTube to disseminate malware, focusing on campaigns that promote free\nsoftware or game cheats. It discusses deceptive video demonstrations and the\ntechniques behind malware delivery. Additionally, the paper presents a new\nevasion technique that abuses YouTube's multilingual metadata capabilities to\ncircumvent automated detection systems. Findings indicate that this method is\nincreasingly being used in recent malicious videos to avoid detection and\nremoval.", "AI": {"tldr": "本文研究了网络犯罪分子如何利用YouTube平台传播恶意软件，特别关注了通过免费软件或游戏作弊工具进行欺骗性推广的活动，并提出了一种新的规避检测技术。", "motivation": "YouTube拥有数十亿用户和每日海量上传内容，成为网络犯罪分子利用其庞大受众的理想目标。平台的开放性和可信度为欺骗性活动提供了隐蔽环境。", "method": "研究分析了通过视频演示传播恶意软件的技术，并提出了一种滥用YouTube多语言元数据功能的新型规避技术，以绕过自动化检测系统。", "result": "研究发现，这种新型规避技术在近期恶意视频中的使用频率增加，有效帮助恶意内容逃避检测和删除。", "conclusion": "YouTube平台存在被恶意软件传播滥用的风险，新型多语言元数据规避技术加剧了这一威胁，需要更先进的检测手段应对。"}}
{"id": "2507.17277", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.17277", "abs": "https://arxiv.org/abs/2507.17277", "authors": ["Jinhao Li", "Arlena Chew", "Hao Wang"], "title": "Investigating State-of-the-Art Planning Strategies for Electric Vehicle Charging Infrastructures in Coupled Transport and Power Networks: A Comprehensive Review", "comment": "26 pages", "summary": "Electric vehicles (EVs) have emerged as a pivotal solution to reduce\ngreenhouse gas emissions paving a pathway to net zero. As the adoption of EVs\ncontinues to grow, countries are proactively formulating systematic plans for\nnationwide electric vehicle charging infrastructure (EVCI) to keep pace with\nthe accelerating shift towards EVs. This comprehensive review aims to\nthoroughly examine current global practices in EVCI planning and explore\nstate-of-the-art methodologies for designing EVCI planning strategies. Despite\nremarkable efforts by influential players in the global EV market, such as\nChina, the United States, and the European Union, the progress in EVCI rollout\nhas been notably slower than anticipated in the rest of the world. This delay\ncan be attributable to three major impediments: inadequate EVCI charging\nservices, low utilization rates of public EVCI facilities, and the non-trivial\nintegration of EVCI into the electric grid. This review dissects the interests\nof these stakeholders, clarifying their respective roles and expectations in\nthe context of EVCI planning. This review also provides insights into level 1,\n2, and 3 chargers with explorations of their applications in different\ngeographical locations for diverse EV charging patterns. Finally, a thorough\nreview of node-based and flow-based approaches to EV planning is presented. The\nmodeling of placing charging stations is broadly categorized into set coverage,\nmaximum coverage, flow-capturing, and flow-refueling location models. In\nconclusion, this review identifies several research gaps, including the dynamic\nmodeling of EV charging demand and the coordination of vehicle electrification\nwith grid decarbonization. This paper calls for further contributions to bridge\nthese gaps and drive the advancement of EVCI planning.", "AI": {"tldr": "本文综述了全球电动汽车充电基础设施（EVCI）规划的现状与方法，指出推广中的三大障碍，并探讨了不同充电桩类型及规划模型的应用。", "motivation": "电动汽车（EVs）作为减少温室气体排放的关键解决方案，其充电基础设施（EVCI）的规划与建设需跟上EV普及速度。然而，全球范围内EVCI建设进度滞后，主要由于充电服务不足、公共设施利用率低及电网整合困难。", "method": "通过分析中国、美国和欧盟等主要EV市场的实践经验，探讨了1级、2级和3级充电桩的地理应用差异，并系统评估了基于节点和流量的EVCI规划模型（如集合覆盖、最大覆盖、流量捕获和流量补充模型）。", "result": "研究发现，全球EVCI建设滞后于预期，主要受限于充电服务不足、公共设施利用率低及电网整合挑战。不同充电桩类型和规划模型需因地制宜，以满足多样化的充电需求。", "conclusion": "本文指出EV充电需求动态建模及车辆电气化与电网脱碳协调等研究空白，呼吁进一步贡献以推动EVCI规划的进步。"}}
{"id": "2507.17608", "categories": ["math.NT", "11F11, 11F67"], "pdf": "https://arxiv.org/pdf/2507.17608", "abs": "https://arxiv.org/abs/2507.17608", "authors": ["Tianyu Ni", "Hui Xue"], "title": "Linear independence of periods for the symmetric square $L$-functions", "comment": "to appear in Ann. Math. Qu\\'e", "summary": "For $S_k$, the space of cusp forms of weight $k$ for the full modular group,\nwe first introduce periods on $S_k$ associated to symmetric square\n$L$-functions. We then prove that for a fixed natural number $n$, if $k$ is\nsufficiently large relative to $n$, then any $n$ such periods are linearly\nindependent. With some extra assumption, we also prove that for $k\\geq e^{12}$,\nwe can always pick up to $\\frac{\\log k}{4}$ arbitrary linearly independent\nperiods.", "AI": {"tldr": "本文研究了全模群权$k$尖形式空间$S_k$上与对称平方$L$-函数相关的周期，证明了当$k$相对于固定自然数$n$足够大时，任意$n$个周期线性无关。进一步假设下，当$k\\geq e^{12}$时可选取多达$\\frac{\\log k}{4}$个线性无关周期。", "motivation": "探索尖形式空间$S_k$上对称平方$L$-函数相关周期的线性独立性，为模形式的周期理论提供新见解。", "method": "首先在$S_k$上引入与对称平方$L$-函数关联的周期，然后通过分析权$k$与周期数量的关系，运用数论和代数方法证明线性独立性。", "result": "主要结果包括：1) 对固定$n$，当$k$足够大时任意$n$个周期线性无关；2) 在$k\\geq e^{12}$条件下可构造$\\frac{\\log k}{4}$个线性无关周期。", "conclusion": "该研究揭示了高权尖形式周期空间的维数增长规律，为模形式周期理论的定量研究提供了重要工具。"}}
{"id": "2507.17258", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17258", "abs": "https://arxiv.org/abs/2507.17258", "authors": ["Andreas Scholl", "Natalie Kiesler"], "title": "Students' Feedback Requests and Interactions with the SCRIPT Chatbot: Do They Get What They Ask For?", "comment": "Accepted at PPIG 2025", "summary": "Building on prior research on Generative AI (GenAI) and related tools for\nprogramming education, we developed SCRIPT, a chatbot based on ChatGPT-4o-mini,\nto support novice learners. SCRIPT allows for open-ended interactions and\nstructured guidance through predefined prompts. We evaluated the tool via an\nexperiment with 136 students from an introductory programming course at a large\nGerman university and analyzed how students interacted with SCRIPT while\nsolving programming tasks with a focus on their feedback preferences. The\nresults reveal that students' feedback requests seem to follow a specific\nsequence. Moreover, the chatbot responses aligned well with students' requested\nfeedback types (in 75%), and it adhered to the system prompt constraints. These\ninsights inform the design of GenAI-based learning support systems and\nhighlight challenges in balancing guidance and flexibility in AI-assisted\ntools.", "AI": {"tldr": "研究开发了基于ChatGPT-4o-mini的聊天机器人SCRIPT，用于支持编程新手学习，并通过实验分析了学生的互动行为和反馈偏好。", "motivation": "基于生成式AI（GenAI）在编程教育中的应用研究，开发SCRIPT以帮助初学者通过开放式互动和结构化引导学习编程。", "method": "在德国一所大型大学的入门编程课程中，对136名学生进行实验，分析他们使用SCRIPT解决编程任务时的互动行为和反馈请求模式。", "result": "学生的反馈请求呈现特定序列，75%的聊天机器人回应与其请求的反馈类型一致，且系统提示约束得到遵守。", "conclusion": "研究结果为设计基于GenAI的学习支持系统提供了 insights，并凸显了在AI辅助工具中平衡引导与灵活性的挑战。"}}
{"id": "2507.17407", "categories": ["math.CO", "05E18, 05C25, 05C30"], "pdf": "https://arxiv.org/pdf/2507.17407", "abs": "https://arxiv.org/abs/2507.17407", "authors": ["Sauvik Poddar", "Angsuman Das"], "title": "Non-isomorphic $d$-integral circulant graphs", "comment": "19 pages, 1 table", "summary": "The algebraic degree $Deg(G)$ of a graph $G$ is the dimension of the\nsplitting field of the adjacency polynomial of $G$ over the field $\\mathbb{Q}$.\nIt can be shown that for every positive integer $d$, there exists a circulant\ngraph with algebraic degree $d$. Let $C(d)$ be the least positive integer such\nthat there exists a circulant graph of order $C(d)$ having algebraic degree\n$d$. A graph $G$ is called $d$-integral if $Deg(G)=d$. We call a $d$-integral\ncirculant graph \\textit{minimal} if order of that graph equals $C(d)$. Let\n$\\mathcal{F}_{n,d}$ denote the collection of isomorphism classes of connected,\n$d$-integral circulant graphs of some given possible order $n$. In this paper\nwe compute the exact value of $C(d)$ and provide some bounds on\n$|\\mathcal{F}_{n,d}|$, thereby showing that the minimal $d$-integral circulant\ngraph is not unique. Moreover, we find the exact value of $|\\mathcal{F}_{p,d}|$\nwhere both $p$ and $d$ are prime.", "AI": {"tldr": "本文研究了循环图的代数度数$Deg(G)$，定义了最小$d$-积分循环图，并计算了$C(d)$的确切值，证明了最小$d$-积分循环图不唯一，同时给出了$|\\mathcal{F}_{n,d}|$的界限及$|\\mathcal{F}_{p,d}|$的精确值。", "motivation": "研究循环图的代数度数及其最小阶数$C(d)$，探索$d$-积分循环图的性质和唯一性问题，为图论中的代数结构提供新的理论支持。", "method": "通过定义$d$-积分循环图及最小$d$-积分循环图，利用代数图论和数论方法，计算$C(d)$的确切值，并分析$|\\mathcal{F}_{n,d}|$的界限及$|\\mathcal{F}_{p,d}|$的精确值。", "result": "证明了对于每个正整数$d$，存在阶数为$C(d)$的循环图，且最小$d$-积分循环图不唯一；给出了$|\\mathcal{F}_{n,d}|$的界限，并在$p$和$d$均为素数时得到了$|\\mathcal{F}_{p,d}|$的精确值。", "conclusion": "本文不仅计算了$C(d)$的确切值，还证明了最小$d$-积分循环图的不唯一性，为循环图的代数性质研究提供了重要结论。"}}
{"id": "2507.17007", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17007", "abs": "https://arxiv.org/abs/2507.17007", "authors": ["Gabriele Costa"], "title": "The Postman: A Journey of Ethical Hacking in PosteID/SPID Borderland", "comment": null, "summary": "This paper presents a vulnerability assessment activity that we carried out\non PosteID, the implementation of the Italian Public Digital Identity System\n(SPID) by Poste Italiane. The activity led to the discovery of a critical\nprivilege escalation vulnerability, which was eventually patched. The overall\nanalysis and disclosure process represents a valuable case study for the\ncommunity of ethical hackers. In this work, we present both the technical steps\nand the details of the disclosure process.", "AI": {"tldr": "本文对意大利邮政的公共数字身份系统PosteID进行了漏洞评估，发现并修补了一个关键权限提升漏洞，为道德黑客社区提供了有价值的案例研究。", "motivation": "评估PosteID系统的安全性，以发现潜在漏洞并提升公共数字身份系统的安全性。", "method": "通过技术分析步骤和漏洞披露流程，对PosteID系统进行了全面的漏洞评估。", "result": "发现了一个关键的权限提升漏洞，并最终成功修补。", "conclusion": "该研究不仅揭示了PosteID系统的安全漏洞，还为道德黑客社区提供了技术分析和漏洞披露的实践案例。"}}
{"id": "2507.17545", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17545", "abs": "https://arxiv.org/abs/2507.17545", "authors": ["Sebastian Pokutta"], "title": "Scalable DC Optimization via Adaptive Frank-Wolfe Algorithms", "comment": null, "summary": "We consider the problem of minimizing a difference of (smooth) convex\nfunctions over a compact convex feasible region $P$, i.e., $\\min_{x \\in P} f(x)\n- g(x)$, with smooth $f$ and Lipschitz continuous $g$. This computational study\nbuilds upon and complements the framework of Maskan et al. [2025] by\nintegrating advanced Frank-Wolfe variants to reduce computational overhead. We\nempirically show that constrained DC problems can be efficiently solved using a\ncombination of the Blended Pairwise Conditional Gradients (BPCG) algorithm\n[Tsuji et al., 2022] with warm-starting and the adaptive error bound from\nMaskan et al. [2025]. The result is a highly efficient and scalable\nprojection-free algorithm for constrained DC optimization.", "AI": {"tldr": "本文提出了一种高效且可扩展的无投影算法，用于解决紧凑凸可行区域上的凸差函数最小化问题，结合了BPCG算法和自适应误差界技术。", "motivation": "研究如何在紧凑凸可行区域$P$上最小化光滑凸函数差$f(x) - g(x)$，其中$f$光滑且$g$满足Lipschitz连续，旨在降低计算开销并提升效率。", "method": "结合Blended Pairwise Conditional Gradients (BPCG)算法与热启动技术，并利用Maskan等人[2025]的自适应误差界，构建了一种无投影的约束DC优化框架。", "result": "实证表明，该方法能高效解决约束DC问题，具有较高的计算效率和可扩展性。", "conclusion": "通过整合先进Frank-Wolfe变体和自适应误差界，本文提出的算法在约束DC优化中实现了高效且可扩展的解决方案。"}}
{"id": "2507.17631", "categories": ["math.NT", "math.AG", "14F30, 14F40"], "pdf": "https://arxiv.org/pdf/2507.17631", "abs": "https://arxiv.org/abs/2507.17631", "authors": ["Abhinandan", "Alex Youcis"], "title": "An integral comparison of crystalline and de Rham cohomology", "comment": "33 pages. Comments welcome!", "summary": "Let $\\mathcal{O}_K$ be a mixed characteristic complete DVR with perfect\nresidue field $k$ and fraction field $K$. It is a celebrated result of\nBerthelot and Ogus that for a smooth proper formal scheme $X/\\mathcal{O}_K$\nthere exists a comparison between the de Rham cohomology groups\n$\\mathrm{H}^i_\\mathrm{dR}(X/\\mathcal{O}_K)$ and the crystalline cohomology\ngroups $\\mathrm{H}^i_\\mathrm{crys}(X_k/W(k))$ of the special fibre, after\ntensoring with $K$. In this article, we use the stacky perspective on prismatic\ncohomology, due to Drinfeld and Bhatt--Lurie, to give a version of this\ncomparison result with coefficients in a perfect complex of prismatic\n$F$-crystals on $X$. Our method is of an integral nature and suggests new tools\nto understand the relationship between torsion in de Rham and crystalline\ncohomology.", "AI": {"tldr": "本文利用棱镜上同调的堆叠视角，建立了带有棱镜$F$-晶体系数的de Rham上同调与晶体上同调之间的比较定理，方法具有积分性质。", "motivation": "Berthelot和Ogus的经典结果表明，光滑真形式概形$X/\\mathcal{O}_K$的de Rham上同调与特殊纤维的晶体上同调在张量$K$后存在比较。本文旨在推广这一结果至带有棱镜$F$-晶体系数的情形。", "method": "采用Drinfeld和Bhatt--Lurie提出的棱镜上同调的堆叠视角，开发了一种积分性质的方法，研究棱镜$F$-晶体系数的上同调比较。", "result": "证明了带有完美棱镜$F$-晶体复形系数的de Rham上同调与晶体上同调之间的比较定理，为理解两者间的挠关系提供了新工具。", "conclusion": "本文的积分方法不仅推广了经典比较定理，还为研究de Rham与晶体上同调中的挠问题开辟了新途径。"}}
{"id": "2507.17289", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17289", "abs": "https://arxiv.org/abs/2507.17289", "authors": ["Shitong Zhu", "Chenhao Fang", "Derek Larson", "Neel Reddy Pochareddy", "Rajeev Rao", "Sophie Zeng", "Yanqing Peng", "Wendy Summer", "Alex Goncalves", "Arya Pudota", "Herve Robert"], "title": "Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments", "comment": null, "summary": "This paper presents Compliance Brain Assistant (CBA), a conversational,\nagentic AI assistant designed to boost the efficiency of daily compliance tasks\nfor personnel in enterprise environments. To strike a good balance between\nresponse quality and latency, we design a user query router that can\nintelligently choose between (i) FastTrack mode: to handle simple requests that\nonly need additional relevant context retrieved from knowledge corpora; and\n(ii) FullAgentic mode: to handle complicated requests that need composite\nactions and tool invocations to proactively discover context across various\ncompliance artifacts, and/or involving other APIs/models for accommodating\nrequests. A typical example would be to start with a user query, use its\ndescription to find a specific entity and then use the entity's information to\nquery other APIs for curating and enriching the final AI response.\n  Our experimental evaluations compared CBA against an out-of-the-box LLM on\nvarious real-world privacy/compliance-related queries targeting various\npersonas. We found that CBA substantially improved upon the vanilla LLM's\nperformance on metrics such as average keyword match rate (83.7% vs. 41.7%) and\nLLM-judge pass rate (82.0% vs. 20.0%). We also compared metrics for the full\nrouting-based design against the `fast-track only` and `full-agentic` modes and\nfound that it had a better average match-rate and pass-rate while keeping the\nrun-time approximately the same. This finding validated our hypothesis that the\nrouting mechanism leads to a good trade-off between the two worlds.", "AI": {"tldr": "本文介绍合规大脑助手(CBA)，一种提升企业合规任务效率的对话式AI助手，通过智能路由机制在响应质量与延迟间取得平衡。", "motivation": "企业合规任务复杂多样，需兼顾响应速度与处理深度。现有方案难以同时满足简单查询与复合操作需求，亟需智能分流机制。", "method": "设计双模式路由系统：FastTrack模式处理仅需知识检索的简单请求；FullAgentic模式通过工具调用和API组合处理需主动探索上下文的复杂请求。", "result": "实验显示CBA在关键词匹配率(83.7% vs 41.7%)和LLM评判通过率(82.0% vs 20.0%)上显著优于基础LLM，混合路由设计在保持运行时相近的同时获得最优指标。", "conclusion": "路由机制有效平衡简单与复杂请求的处理效能，验证了混合架构在企业合规AI助手场景中的优越性。"}}
{"id": "2507.17492", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.17492", "abs": "https://arxiv.org/abs/2507.17492", "authors": ["Aida Abiad", "Vladislav Taranchuk", "Thijs van Veluw"], "title": "On the sum of the largest and smallest eigenvalues of odd-cycle free graphs", "comment": null, "summary": "Let $G$ be a graph with adjacency eigenvalues $\\lambda_1 \\geq \\cdots \\geq\n\\lambda_n$. Both $\\lambda_1 + \\lambda_n$ and the odd girth of $G$ can be seen\nas measures of the bipartiteness of $G$. Csikv\\'ari proved in 2022 that for odd\ngirth 5 graphs (triangle-free) it holds that $(\\lambda_1+\\lambda_n)/n \\le\n(3-2\\sqrt 2) < 0.1716$. In this paper we extend Csikv\\'ari's result to general\nodd girth $k$ proving that $(\\lambda_1+\\lambda_n)/n = O(k^{-1})$. In the case\nof odd girth 7, we prove a stronger upper bound of $(\\lambda_1+\\lambda_n)/n <\n0.0396$.", "AI": {"tldr": "本文扩展了Csikv\\'ari关于图二部性的结果，证明了对于一般奇数围长$k$的图，$(\\lambda_1+\\lambda_n)/n = O(k^{-1})$，并在奇数围长为7时给出了更强的上界0.0396。", "motivation": "研究图的二部性度量，特别是通过邻接特征值$\\lambda_1 + \\lambda_n$和奇数围长来量化图的二部性质，扩展Csikv\\'ari关于奇数围长5的结果。", "method": "通过数学推导和分析，将Csikv\\'ari的结果推广到一般奇数围长$k$的图，并针对奇数围长7的情况进行更精细的估计。", "result": "对于一般奇数围长$k$的图，证明了$(\\lambda_1+\\lambda_n)/n = O(k^{-1})$；特别地，奇数围长7时，$(\\lambda_1+\\lambda_n)/n < 0.0396$。", "conclusion": "本文成功将二部性度量的结果推广到更一般的奇数围长图，并给出了更精确的上界，为图论中二部性质的研究提供了新的理论工具。"}}
{"id": "2507.17010", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17010", "abs": "https://arxiv.org/abs/2507.17010", "authors": ["H M Mohaimanul Islam", "Huynh Q. N. Vo", "Aditya Rane"], "title": "Towards Trustworthy AI: Secure Deepfake Detection using CNNs and Zero-Knowledge Proofs", "comment": "Submitted for peer-review in TrustXR - 2025", "summary": "In the era of synthetic media, deepfake manipulations pose a significant\nthreat to information integrity. To address this challenge, we propose\nTrustDefender, a two-stage framework comprising (i) a lightweight convolutional\nneural network (CNN) that detects deepfake imagery in real-time extended\nreality (XR) streams, and (ii) an integrated succinct zero-knowledge proof\n(ZKP) protocol that validates detection results without disclosing raw user\ndata. Our design addresses both the computational constraints of XR platforms\nwhile adhering to the stringent privacy requirements in sensitive settings.\nExperimental evaluations on multiple benchmark deepfake datasets demonstrate\nthat TrustDefender achieves 95.3% detection accuracy, coupled with efficient\nproof generation underpinned by rigorous cryptography, ensuring seamless\nintegration with high-performance artificial intelligence (AI) systems. By\nfusing advanced computer vision models with provable security mechanisms, our\nwork establishes a foundation for reliable AI in immersive and\nprivacy-sensitive applications.", "AI": {"tldr": "提出TrustDefender框架，结合轻量级CNN和零知识证明协议，实现XR流中深度伪造图像的实时检测与隐私保护验证。", "motivation": "合成媒体时代下，深度伪造技术对信息完整性构成威胁，需兼顾XR平台算力限制与隐私保护需求。", "method": "两阶段框架：1) 轻量级CNN实时检测XR流中的深度伪造图像；2) 集成零知识证明协议验证结果，避免原始数据泄露。", "result": "在多个基准数据集上达到95.3%检测准确率，密码学保障的高效证明生成，支持高性能AI系统无缝集成。", "conclusion": "通过计算机视觉与可证明安全机制的结合，为沉浸式隐私敏感应用中的可信AI奠定基础。"}}
{"id": "2507.17556", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.17556", "abs": "https://arxiv.org/abs/2507.17556", "authors": ["Max L. N. Goncalves", "Geovani N. Grapiglia"], "title": "Sub-sampled Trust-Region Methods with Deterministic Worst-Case Complexity Guarantees", "comment": null, "summary": "In this paper, we develop and analyze sub-sampled trust-region methods for\nsolving finite-sum optimization problems. These methods employ subsampling\nstrategies to approximate the gradient and Hessian of the objective function,\nsignificantly reducing the overall computational cost. We propose a novel\nadaptive procedure for deterministically adjusting the sample size used for\ngradient (or gradient and Hessian) approximations. Furthermore, we establish\nworst-case iteration complexity bounds for obtaining approximate stationary\npoints. More specifically, for a given $\\varepsilon_g, \\varepsilon_H\\in (0,1)$,\nit is shown that an $\\varepsilon_g$-approximate first-order stationary point is\nreached in at most $\\mathcal{O}({\\varepsilon_g}^{-2} )$ iterations, whereas an\n$(\\varepsilon_g,\\varepsilon_H)$-approximate second-order stationary point is\nreached in at most\n$\\mathcal{O}(\\max\\{\\varepsilon_{g}^{-2}\\varepsilon_{H}^{-1},\\varepsilon_{H}^{-3}\\})$\niterations. Finally, numerical experiments illustrate the effectiveness of our\nnew subsampling technique.", "AI": {"tldr": "本文提出了一种用于解决有限和优化问题的子采样信赖域方法，通过自适应调整样本量降低计算成本，并建立了最坏情况下的迭代复杂度界限。", "motivation": "有限和优化问题在大规模计算中面临高昂的梯度与Hessian矩阵计算成本，需要开发高效的子采样策略以降低复杂度。", "method": "采用确定性自适应子采样策略近似目标函数的梯度与Hessian矩阵，结合信赖域框架设计新算法。", "result": "理论证明算法最多需$\\mathcal{O}({\\varepsilon_g}^{-2} )$次迭代获得一阶$\\varepsilon_g$-近似稳定点，最多需$\\mathcal{O}(\\max\\{\\varepsilon_{g}^{-2}\\varepsilon_{H}^{-1},\\varepsilon_{H}^{-3}\\})$次迭代获得二阶$(\\varepsilon_g,\\varepsilon_H)$-近似稳定点。数值实验验证了方法的有效性。", "conclusion": "所提出的自适应子采样技术显著降低了计算负担，同时保证了理论收敛性，为大规模有限和优化提供了实用解决方案。"}}
{"id": "2507.17418", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17418", "abs": "https://arxiv.org/abs/2507.17418", "authors": ["Joobin Jin", "Seokjun Hong", "Gyeongseon Baek", "Yeeun Kim", "Byeongjoon Noh"], "title": "Ctx2TrajGen: Traffic Context-Aware Microscale Vehicle Trajectories using Generative Adversarial Imitation Learning", "comment": null, "summary": "Precise modeling of microscopic vehicle trajectories is critical for traffic\nbehavior analysis and autonomous driving systems. We propose Ctx2TrajGen, a\ncontext-aware trajectory generation framework that synthesizes realistic urban\ndriving behaviors using GAIL. Leveraging PPO and WGAN-GP, our model addresses\nnonlinear interdependencies and training instability inherent in microscopic\nsettings. By explicitly conditioning on surrounding vehicles and road geometry,\nCtx2TrajGen generates interaction-aware trajectories aligned with real-world\ncontext. Experiments on the drone-captured DRIFT dataset demonstrate superior\nperformance over existing methods in terms of realism, behavioral diversity,\nand contextual fidelity, offering a robust solution to data scarcity and domain\nshift without simulation.", "AI": {"tldr": "提出Ctx2TrajGen框架，通过GAIL结合PPO和WGAN-GP生成上下文感知的微观车辆轨迹，解决数据稀缺与领域偏移问题，在DRIFT数据集上验证了优越性。", "motivation": "精确建模微观车辆轨迹对交通行为分析和自动驾驶系统至关重要，但现有方法存在非线性依赖和训练不稳定性问题。", "method": "基于GAIL框架，整合PPO和WGAN-GP算法，显式建模周围车辆与道路几何的上下文条件，生成交互感知的轨迹。", "result": "在无人机采集的DRIFT数据集上，模型在真实性、行为多样性和上下文保真度方面超越现有方法，无需仿真即可缓解数据稀缺问题。", "conclusion": "Ctx2TrajGen为微观交通建模提供了稳健解决方案，其上下文感知能力显著提升了轨迹生成的现实性和适应性。"}}
{"id": "2507.17033", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17033", "abs": "https://arxiv.org/abs/2507.17033", "authors": ["Joshua Kalyanapu", "Farshad Dizani", "Darsh Asher", "Azam Ghanbari", "Rosario Cammarota", "Aydin Aysu", "Samira Mirbagher Ajorpaz"], "title": "GATEBLEED: Exploiting On-Core Accelerator Power Gating for High Performance & Stealthy Attacks on AI", "comment": "Accepted at MICRO 2025", "summary": "As power consumption from AI training and inference continues to increase, AI\naccelerators are being integrated directly into the CPU. Intel's Advanced\nMatrix Extensions (AMX) is one such example, debuting on the 4th generation\nIntel Xeon Scalable CPU. We discover a timing side and covert channel,\nGATEBLEED, caused by the aggressive power gating utilized to keep the CPU\nwithin operating limits. We show that the GATEBLEED side channel is a threat to\nAI privacy as many ML models such as transformers and CNNs make critical\ncomputationally-heavy decisions based on private values like confidence\nthresholds and routing logits. Timing delays from selective powering down of\nAMX components mean that each matrix multiplication is a potential leakage\npoint when executed on the AMX accelerator. Our research identifies over a\ndozen potential gadgets across popular ML libraries (HuggingFace, PyTorch,\nTensorFlow, etc.), revealing that they can leak sensitive and private\ninformation. GATEBLEED poses a risk for local and remote timing inference, even\nunder previous protective measures. GATEBLEED can be used as a high\nperformance, stealthy remote covert channel and a generic magnifier for timing\ntransmission channels, capable of bypassing traditional cache defenses to leak\narbitrary memory addresses and evading state of the art microarchitectural\nattack detectors under realistic network conditions and system configurations\nin which previous attacks fail. We implement an end-to-end microarchitectural\ninference attack on a transformer model optimized with Intel AMX, achieving a\nmembership inference accuracy of 81% and a precision of 0.89. In a CNN-based or\ntransformer-based mixture-of-experts model optimized with Intel AMX, we leak\nexpert choice with 100% accuracy.", "AI": {"tldr": "研究发现Intel AMX加速器因激进电源门控导致GATEBLEED时序侧信道漏洞，可泄露AI模型隐私数据，威胁本地及远程安全。", "motivation": "随着AI训练与推理功耗激增，CPU集成加速器（如Intel AMX）成为常态，但其电源管理机制可能引发新型安全风险。", "method": "通过分析AMX电源门控导致的时序差异，在主流ML库（HuggingFace/PyTorch等）中定位十多个漏洞点，构建端到端微架构推理攻击。", "result": "针对AMX优化的Transformer模型实现81%成员推理准确率；在专家混合模型中100%泄露专家选择路径，突破现有防护措施。", "conclusion": "GATEBLEED作为高性能隐蔽信道，可绕过缓存防御及检测系统，暴露AI隐私决策关键数据（如置信度阈值），需重新设计硬件安全方案。"}}
{"id": "2507.17566", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.17566", "abs": "https://arxiv.org/abs/2507.17566", "authors": ["Rolf Nelson van Lieshout", "Niels Lindner"], "title": "A Compact Cycle Formulation for the Multiperiodic Event Scheduling Problem", "comment": null, "summary": "The Periodic Event Scheduling Problem (PESP) is a fundamental model in\nperiodic timetabling for public transport systems, assuming a common period\nacross all events. However, real-world networks often feature heterogeneous\nservice frequencies. This paper studies the Multiperiodic Event Scheduling\nProblem (MPESP), a generalization of PESP that allows each event to recur at\nits own individual period. While more expressive, MPESP presents new modeling\nchallenges due to the loss of a global period. We present a cycle-based\nformulation for MPESP that extends the strongest known formulation for PESP\nand, in contrast to existing approaches, is valid for any MPESP instance.\nCrucially, the formulation requires a cycle basis derived from a spanning tree\nsatisfying specific structural properties, which we formalize and\nalgorithmically construct, extending the concept of sharp spanning trees to\nrooted instances. We further prove a multiperiodic analogue of the cycle\nperiodicity property. Our new formulation solves nearly all tested instances,\nincluding several large-scale real-world public transport networks, to\noptimality or with small optimality gaps, dramatically outperforming existing\narc-based models. The results demonstrate the practical potential of MPESP in\ncapturing heterogeneous frequencies without resorting to artificial event\nduplication.", "AI": {"tldr": "本文研究了多周期事件调度问题（MPESP），这是对传统周期事件调度问题（PESP）的推广，允许每个事件以各自周期重复。通过基于循环的建模方法，解决了因缺乏全局周期带来的挑战，并在实际交通网络中验证了其有效性。", "motivation": "传统PESP模型假设所有事件共享同一周期，而现实交通网络往往存在异构服务频率。MPESP通过允许事件拥有独立周期，更贴合实际需求，但缺乏全局周期带来了新的建模挑战。", "method": "提出了一种基于循环的MPESP建模框架，扩展了PESP的最强已知公式。该方法要求从满足特定结构属性的生成树中导出循环基，并将尖锐生成树概念推广到有根实例。同时证明了多周期类比下的循环周期性性质。", "result": "新模型在测试中表现优异，几乎所有实例（包括多个大规模现实交通网络）都能达到最优解或接近最优解，显著优于现有的基于弧的模型。", "conclusion": "MPESP模型无需人工复制事件即可有效捕捉异构频率特性，展示了其在实践中的巨大潜力，为复杂交通网络调度提供了更灵活的解决方案。"}}
{"id": "2507.17477", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17477", "abs": "https://arxiv.org/abs/2507.17477", "authors": ["Haoran Sun", "Zekun Zhang", "Shaoning Zeng"], "title": "An Uncertainty-Driven Adaptive Self-Alignment Framework for Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable progress in\ninstruction following and general-purpose reasoning. However, achieving\nhigh-quality alignment with human intent and safety norms without human\nannotations remains a fundamental challenge. In this work, we propose an\nUncertainty-Driven Adaptive Self-Alignment (UDASA) framework designed to\nimprove LLM alignment in a fully automated manner. UDASA first generates\nmultiple responses for each input and quantifies output uncertainty across\nthree dimensions: semantics, factuality, and value alignment. Based on these\nuncertainty scores, the framework constructs preference pairs and categorizes\ntraining samples into three stages, conservative, moderate, and exploratory,\naccording to their uncertainty difference. The model is then optimized\nprogressively across these stages. In addition, we conduct a series of\npreliminary studies to validate the core design assumptions and provide strong\nempirical motivation for the proposed framework. Experimental results show that\nUDASA outperforms existing alignment methods across multiple tasks, including\nharmlessness, helpfulness, truthfulness, and controlled sentiment generation,\nsignificantly improving model performance.", "AI": {"tldr": "本文提出了一种不确定性驱动的自适应自对齐（UDASA）框架，旨在无需人工标注的情况下提升大语言模型（LLM）与人类意图和安全规范的自动对齐能力。该方法通过多维度不确定性量化及分阶段优化，显著提升了模型在无害性、有用性、真实性等任务中的表现。", "motivation": "尽管大语言模型在指令遵循和通用推理方面取得显著进展，但如何在不依赖人工标注的情况下实现高质量的人类意图与安全规范对齐仍是一个核心挑战。", "method": "UDASA框架首先生成每个输入的多个响应，并从语义、事实性和价值对齐三个维度量化输出不确定性。根据不确定性差异将训练样本分为保守、中等和探索三个阶段，并逐步优化模型。", "result": "实验结果表明，UDASA在无害性、有用性、真实性和受控情感生成等多个任务上优于现有对齐方法，显著提升了模型性能。", "conclusion": "UDASA通过自动化不确定性驱动机制实现了LLM的高效自对齐，为无需人工干预的模型优化提供了可行方案，其分阶段训练策略和核心设计假设得到了实证支持。"}}
{"id": "2507.17620", "categories": ["math.CO", "math-ph", "math.MP", "52B40 (primary), 52B12 (secondary)"], "pdf": "https://arxiv.org/pdf/2507.17620", "abs": "https://arxiv.org/abs/2507.17620", "authors": ["Elia Mazzucchelli", "Elizabeth Pratt"], "title": "Exterior Cyclic Polytopes and Convexity of Amplituhedra", "comment": "30 pages, 10 figures, 1 table; comments welcome", "summary": "The amplituhedron is a semialgebraic set in the Grassmannian. We study\nconvexity and duality of amplituhedra. We introduce a notion of convexity,\ncalled \\textit{extendable convexity}, for real semialgebraic sets in any\nembedded projective variety. We show that the $k=m=2$ amplituhedron is\nextendably convex in the Grassmannian of lines in projective three-space. In\nthe process we introduce a new polytope called the \\emph{exterior cyclic\npolytope}, generalizing the cyclic polytope. It is equal to the convex hull of\nthe amplituhedron in the Pl\\\"ucker embedding. We undertake a combinatorial\nanalysis of the exterior cyclic polytope, its facets, and its dual. Finally, we\nintroduce the \\textit{(extendable) dual amplituhedron}, which is closely\nrelated to the dual of the exterior cyclic polytope. We show that the dual\namplituhedron for $k=m=2$ is again an amplituhedron, where the external matrix\ndata is changed by the twist map.", "AI": {"tldr": "本文研究了amplituhedron的凸性与对偶性，提出了一种称为“可扩展凸性”的新概念，并证明了在特定条件下amplituhedron具有该性质。通过引入“外部循环多面体”及其对偶，进一步分析了其组合结构，并定义了“对偶amplituhedron”，展示了其在特定参数下的对称性。", "motivation": "研究amplituhedron的几何性质，特别是凸性与对偶性，以深化对这一数学结构的理解，并探索其在物理和数学中的应用潜力。", "method": "引入“可扩展凸性”概念，分析其在Grassmannian中的表现；定义“外部循环多面体”作为工具，研究其组合性质；构造“对偶amplituhedron”并分析其与原始结构的关系。", "result": "证明了$k=m=2$的amplituhedron在Grassmannian中具有可扩展凸性；外部循环多面体与amplituhedron在Plücker嵌入下的凸包等价；对偶amplituhedron在特定参数下仍为amplituhedron，且外部矩阵数据通过扭转映射变换。", "conclusion": "amplituhedron的凸性与对偶性可通过可扩展凸性和外部循环多面体等工具系统研究，对偶结构的存在进一步揭示了其内在对称性，为后续研究提供了新方向。"}}
{"id": "2507.17064", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.17064", "abs": "https://arxiv.org/abs/2507.17064", "authors": ["Nafisa Anjum", "Tasnuva Farheen"], "title": "SoK: Securing the Final Frontier for Cybersecurity in Space-Based Infrastructure", "comment": null, "summary": "With the advent of modern technology, critical infrastructure,\ncommunications, and national security depend increasingly on space-based\nassets. These assets, along with associated assets like data relay systems and\nground stations, are, therefore, in serious danger of cyberattacks. Strong\nsecurity defenses are essential to ensure data integrity, maintain secure\noperations, and protect assets in space and on the ground against various\nthreats. Previous research has found discrete vulnerabilities in space systems\nand suggested specific solutions to address them. Such research has yielded\nvaluable insights, but lacks a thorough examination of space cyberattack\nvectors and a rigorous assessment of the efficacy of mitigation techniques.\nThis study tackles this issue by taking a comprehensive approach to analyze the\nrange of possible space cyber-attack vectors, which include ground, space,\nsatellite, and satellite constellations. In order to address the particular\nthreats, the study also assesses the efficacy of mitigation measures that are\nlinked with space infrastructures and proposes a Risk Scoring Framework. Based\non the analysis, this paper identifies potential research challenges for\ndeveloping and testing cutting-edge technology solutions, encouraging robust\ncybersecurity measures needed in space.", "AI": {"tldr": "随着现代技术的发展，关键基础设施、通信和国家安全日益依赖空间资产，这些资产面临严重的网络攻击威胁。本研究全面分析了空间网络攻击途径，评估了缓解措施的有效性，并提出了风险评分框架。", "motivation": "空间资产及其相关系统（如数据中继系统和地面站）面临严重的网络攻击威胁，需要强大的安全防御来确保数据完整性、维护安全操作并保护资产。以往研究虽发现了一些漏洞并提出了具体解决方案，但缺乏对空间网络攻击途径的全面分析和缓解措施效果的严格评估。", "method": "本研究采用综合方法，分析了可能的空间网络攻击途径，包括地面、空间、卫星和卫星星座。同时，评估了与空间基础设施相关的缓解措施的有效性，并提出了一个风险评分框架。", "result": "研究识别了空间网络攻击的多种途径，并评估了相关缓解措施的效果。基于分析，提出了一个风险评分框架，并指出了开发测试尖端技术解决方案的潜在研究挑战。", "conclusion": "本研究强调了空间网络安全的重要性，提出了风险评分框架，并呼吁开发更强大的网络安全措施以应对空间资产面临的威胁。"}}
{"id": "2507.17482", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17482", "abs": "https://arxiv.org/abs/2507.17482", "authors": ["Luca Salvatore Lorello", "Nikolaos Manginas", "Marco Lippi", "Stefano Melacci"], "title": "LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning", "comment": null, "summary": "Neuro-symbolic artificial intelligence aims to combine neural architectures\nwith symbolic approaches that can represent knowledge in a human-interpretable\nformalism. Continual learning concerns with agents that expand their knowledge\nover time, improving their skills while avoiding to forget previously learned\nconcepts. Most of the existing approaches for neuro-symbolic artificial\nintelligence are applied to static scenarios only, and the challenging setting\nwhere reasoning along the temporal dimension is necessary has been seldom\nexplored. In this work we introduce LTLZinc, a benchmarking framework that can\nbe used to generate datasets covering a variety of different problems, against\nwhich neuro-symbolic and continual learning methods can be evaluated along the\ntemporal and constraint-driven dimensions. Our framework generates expressive\ntemporal reasoning and continual learning tasks from a linear temporal logic\nspecification over MiniZinc constraints, and arbitrary image classification\ndatasets. Fine-grained annotations allow multiple neural and neuro-symbolic\ntraining settings on the same generated datasets. Experiments on six\nneuro-symbolic sequence classification and four class-continual learning tasks\ngenerated by LTLZinc, demonstrate the challenging nature of temporal learning\nand reasoning, and highlight limitations of current state-of-the-art methods.\nWe release the LTLZinc generator and ten ready-to-use tasks to the\nneuro-symbolic and continual learning communities, in the hope of fostering\nresearch towards unified temporal learning and reasoning frameworks.", "AI": {"tldr": "本文介绍了LTLZinc基准框架，用于生成涵盖多种问题的数据集，以评估神经符号和持续学习方法在时间和约束驱动维度上的表现。", "motivation": "现有神经符号人工智能方法多应用于静态场景，缺乏对时间维度推理的探索。本文旨在填补这一空白，推动时间学习与推理框架的统一研究。", "method": "LTLZinc框架基于MiniZinc约束的线性时序逻辑规范和任意图像分类数据集，生成表达性时序推理和持续学习任务，并提供细粒度注释支持多种训练设置。", "result": "在LTLZinc生成的6个神经符号序列分类和4个类持续学习任务上的实验表明，时序学习与推理具有挑战性，并揭示了当前最先进方法的局限性。", "conclusion": "作者开源了LTLZinc生成器和10个现成任务，希望促进神经符号和持续学习社区对统一时序学习与推理框架的研究。"}}
{"id": "2507.17646", "categories": ["math.CO", "05C57, 05C69"], "pdf": "https://arxiv.org/pdf/2507.17646", "abs": "https://arxiv.org/abs/2507.17646", "authors": ["Boštjan Brešar", "Tanja Dravec", "Kirsti Kuenzel", "Douglas F. Rall"], "title": "On Maker-Breaker domination game critical graphs", "comment": "18 pages, 3 figures", "summary": "The Maker-Breaker domination game is played on a graph $G$ by Dominator and\nStaller who alternate turns selecting an unplayed vertex of $G$. The goal of\nDominator is that the vertices he selected during the game form a dominating\nset while Staller's goal is to prevent this from happening. The graph invariant\n$\\gamma_{\\rm MB}'(G)$ is the number of Dominator's moves in the game played on\n$G$ in which he can achieve his goal when Staller makes the first move and both\nplayers play optimally. In this paper, we continue the investigation of\n$2$-$\\gamma_{\\rm MB}'$-critical graphs, initiated in [Divarakan et al.,\nMaker--Breaker domination game critical graphs, Discrete Appl.\\ Math. 368\n(2025) 126--134], which are defined as the graphs $G$ with $\\gamma_{\\rm\nMB}'(G)=2$ and $\\gamma_{\\rm MB}'(G-e)>2$ for every edge $e$ in $G$. The authors\ncharacterized bipartite $2$-$\\gamma_{\\rm MB}'$-critical graphs, and found an\nexample of a non-bipartite $2$-$\\gamma_{\\rm MB}'$-critical graph. In this\npaper, we characterize the $2$-$\\gamma_{\\rm MB}'$-critical graphs that have a\ncut-vertex, which are represented by two infinite families. In addition, we\nprove that $C_5$ is the only non-bipartite, triangle-free $2$-$\\gamma_{\\rm\nMB}'$-critical graph.", "AI": {"tldr": "本文研究了2-$\\gamma_{\\rm MB}'$-临界图的性质，特别是具有割顶点的图和无非三角形的非二分图，并给出了两类无限族的特征描述。", "motivation": "研究2-$\\gamma_{\\rm MB}'$-临界图的特性，以扩展对Dominator-Breaker支配游戏的理解，特别是在临界条件下的图结构。", "method": "通过分析图的割顶点结构和非二分图的特性，结合已有的二分图临界图的研究成果，进行理论推导和证明。", "result": "特征化了具有割顶点的2-$\\gamma_{\\rm MB}'$-临界图，并证明$C_5$是唯一的非二分且无三角形的2-$\\gamma_{\\rm MB}'$-临界图。", "conclusion": "本文完善了2-$\\gamma_{\\rm MB}'$-临界图的分类，特别是对具有割顶点和非二分结构的图提供了明确的特征描述。"}}
{"id": "2507.17074", "categories": ["cs.CR", "cs.NI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2507.17074", "abs": "https://arxiv.org/abs/2507.17074", "authors": ["Sanzida Hoque", "Abdullah Aydeger", "Engin Zeydan", "Madhusanka Liyanage"], "title": "Analysis of Post-Quantum Cryptography in User Equipment in 5G and Beyond", "comment": "Table 5, Figures 7, This paper has been accepted as a regular paper\n  at LCN 2025 and will appear in the conference proceedings. The final version\n  will be published by IEEE and the copyright will belong to IEEE", "summary": "The advent of quantum computing threatens the security of classical\npublic-key cryptographic systems, prompting the transition to post-quantum\ncryptography (PQC). While PQC has been analyzed in theory, its performance in\npractical wireless communication environments remains underexplored. This paper\npresents a detailed implementation and performance evaluation of NIST-selected\nPQC algorithms in user equipment (UE) to UE communications over 5G networks.\nUsing a full 5G emulation stack (Open5GS and UERANSIM) and PQC-enabled TLS 1.3\nvia BoringSSL and liboqs, we examine key encapsulation mechanisms and digital\nsignature schemes across realistic network conditions. We evaluate performance\nbased on handshake latency, CPU and memory usage, bandwidth, and retransmission\nrates, under varying cryptographic configurations and client loads. Our\nfindings show that ML-KEM with ML-DSA offers the best efficiency for\nlatency-sensitive applications, while SPHINCS+ and HQC combinations incur\nhigher computational and transmission overheads, making them unsuitable for\nsecurity-critical but time-sensitive 5G scenarios.", "AI": {"tldr": "本文评估了NIST选定的后量子密码（PQC）算法在5G网络用户设备间通信中的性能表现，发现ML-KEM与ML-DSA组合最适合时延敏感应用。", "motivation": "量子计算的兴起威胁传统公钥密码系统安全，需转向后量子密码（PQC）。现有研究多集中于理论分析，PQC在实际无线通信环境中的性能尚不明确。", "method": "研究使用5G全栈仿真平台（Open5GS和UERANSIM）及支持PQC的TLS 1.3（通过BoringSSL和liboqs实现），在真实网络条件下测试密钥封装机制和数字签名方案，评估握手延迟、CPU/内存占用、带宽及重传率等指标。", "result": "实验表明：ML-KEM+ML-DSA组合在时延敏感场景中效率最优；SPHINCS+与HQC组合因计算和传输开销较高，不适用于对安全性要求高且时间敏感的5G场景。", "conclusion": "后量子密码算法需根据具体场景选择——ML-KEM与ML-DSA适合5G时延敏感应用，而SPHINCS+和HQC因高开销需谨慎部署。"}}
{"id": "2507.17487", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2507.17487", "abs": "https://arxiv.org/abs/2507.17487", "authors": ["Lorenzo Marconi", "Flavia Ricci", "Riccardo Rosati"], "title": "CQE under Epistemic Dependencies: Algorithms and Experiments (extended version)", "comment": "Extended version of paper accepted at the 24th International Semantic\n  Web Conference (ISWC 2025)", "summary": "We investigate Controlled Query Evaluation (CQE) over ontologies, where\ninformation disclosure is regulated by epistemic dependencies (EDs), a family\nof logical rules recently proposed for the CQE framework. In particular, we\ncombine EDs with the notion of optimal GA censors, i.e. maximal sets of ground\natoms that are entailed by the ontology and can be safely revealed. We focus on\nanswering Boolean unions of conjunctive queries (BUCQs) with respect to the\nintersection of all optimal GA censors - an approach that has been shown in\nother contexts to ensure strong security guarantees with favorable\ncomputational behavior. First, we characterize the security of this\nintersection-based approach and identify a class of EDs (namely, full EDs) for\nwhich it remains safe. Then, for a subclass of EDs and for DL-Lite_R\nontologies, we show that answering BUCQs in the above CQE semantics is in AC^0\nin data complexity by presenting a suitable, detailed first-order rewriting\nalgorithm. Finally, we report on experiments conducted in two different\nevaluation scenarios, showing the practical feasibility of our rewriting\nfunction.", "AI": {"tldr": "本文研究了基于本体论的受控查询评估（CQE），结合认知依赖（EDs）和最优GA审查器，提出了一种确保安全性的布尔联合合取查询（BUCQs）应答方法，并在DL-Lite_R本体上实现了高效的数据复杂度处理。", "motivation": "研究动机在于通过结合认知依赖（EDs）和最优GA审查器，开发一种既能保证信息安全又能高效处理查询的CQE框架，特别是在本体论背景下。", "method": "方法包括：1) 结合EDs与最优GA审查器，定义基于交集的安全应答语义；2) 针对DL-Lite_R本体和特定EDs子类，设计一种数据复杂度为AC^0的一阶重写算法。", "result": "结果表明：1) 在完整EDs下，交集方法仍能保证安全性；2) 所提重写算法在DL-Lite_R中可实现高效查询处理；3) 实验验证了该方法的实际可行性。", "conclusion": "结论指出，该CQE框架在理论安全性和计算效率之间取得了平衡，尤其适用于需要严格信息控制的场景，并通过实验证明了其实际应用价值。"}}
{"id": "2507.17666", "categories": ["math.CO", "90C35"], "pdf": "https://arxiv.org/pdf/2507.17666", "abs": "https://arxiv.org/abs/2507.17666", "authors": ["Veronica Phan"], "title": "A simple proof that the edge density of Fon-der-Flaass $(3,4)$-graph is $\\geq\\frac{7}{16}(1-o(1))$", "comment": null, "summary": "In 2018, Alexander A. Razborov proved that the edge density of Fon-der-Flaass\n$(3,4)$-graph is $\\geq\\frac{7}{16}(1-o(1))$, using flag algebras. In this\npaper, we give an elementary proof of this result.", "AI": {"tldr": "本文给出了Fon-der-Flaass $(3,4)$-图边密度下界$\\geq\\frac{7}{16}(1-o(1))$的初等证明，简化了Razborov 2018年使用标志代数的证明方法。", "motivation": "2018年Razborov使用标志代数证明了Fon-der-Flaass $(3,4)$-图的边密度下界，但该方法较为复杂。本文旨在提供更简洁的初等证明。", "method": "采用初等组合数学方法，避免了标志代数等高级工具，直接推导边密度下界。", "result": "成功证明了Fon-der-Flaass $(3,4)$-图的边密度至少为$\\frac{7}{16}(1-o(1))$，与Razborov的结果一致。", "conclusion": "通过初等方法验证了Razborov的结论，为相关极值图论问题提供了更简洁的证明路径。"}}
{"id": "2507.17180", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17180", "abs": "https://arxiv.org/abs/2507.17180", "authors": ["Hao Jiang", "Quan Zhou", "Dongdong Zhao", "Shangshang Yang", "Wenjian Luo", "Xingyi Zhang"], "title": "A Privacy-Preserving Data Collection Method for Diversified Statistical Analysis", "comment": null, "summary": "Data perturbation-based privacy-preserving methods have been widely adopted\nin various scenarios due to their efficiency and the elimination of the need\nfor a trusted third party. However, these methods primarily focus on individual\nstatistical indicators, neglecting the overall quality of the collected data\nfrom a distributional perspective. Consequently, they often fall short of\nmeeting the diverse statistical analysis requirements encountered in practical\ndata analysis. As a promising sensitive data perturbation method, negative\nsurvey methods is able to complete the task of collecting sensitive information\ndistribution while protecting personal privacy. Yet, existing negative survey\nmethods are primarily designed for discrete sensitive information and are\ninadequate for real-valued data distributions. To bridge this gap, this paper\nproposes a novel real-value negative survey model, termed RVNS, for the first\ntime in the field of real-value sensitive information collection. The RVNS\nmodel exempts users from the necessity of discretizing their data and only\nrequires them to sample a set of data from a range that deviates from their\nactual sensitive details, thereby preserving the privacy of their genuine\ninformation. Moreover, to accurately capture the distribution of sensitive\ninformation, an optimization problem is formulated, and a novel approach is\nemployed to solve it. Rigorous theoretical analysis demonstrates that the RVNS\nmodel conforms to the differential privacy model, ensuring robust privacy\npreservation. Comprehensive experiments conducted on both synthetic and\nreal-world datasets further validate the efficacy of the proposed method.", "AI": {"tldr": "本文提出了一种新型实值负调查模型RVNS，用于实值敏感信息收集，解决了现有方法仅适用于离散数据的局限性，并通过理论分析和实验验证了其隐私保护效果和数据分布还原能力。", "motivation": "现有的基于数据扰动的隐私保护方法主要关注个体统计指标，忽视了数据分布的整体质量，且现有负调查方法仅适用于离散敏感信息，无法满足实值数据分布的需求。", "method": "提出RVNS模型，用户无需离散化数据，仅需从偏离真实敏感数据的范围内采样，并通过优化问题准确还原敏感信息分布，同时理论证明其符合差分隐私模型。", "result": "理论分析表明RVNS模型符合差分隐私要求，综合实验在合成和真实数据集上验证了该方法的有效性。", "conclusion": "RVNS模型首次实现了实值敏感信息的隐私保护收集，兼具高效性和分布还原能力，为实际数据分析中的多样化统计需求提供了解决方案。"}}
{"id": "2507.17493", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.17493", "abs": "https://arxiv.org/abs/2507.17493", "authors": ["Alexander Beiser", "Markus Hecher", "Stefan Woltran"], "title": "Automated Hybrid Grounding Using Structural and Data-Driven Heuristics", "comment": null, "summary": "The grounding bottleneck poses one of the key challenges that hinders the\nwidespread adoption of Answer Set Programming in industry. Hybrid Grounding is\na step in alleviating the bottleneck by combining the strength of standard\nbottom-up grounding with recently proposed techniques where rule bodies are\ndecoupled during grounding. However, it has remained unclear when hybrid\ngrounding shall use body-decoupled grounding and when to use standard bottom-up\ngrounding. In this paper, we address this issue by developing automated hybrid\ngrounding: we introduce a splitting algorithm based on data-structural\nheuristics that detects when to use body-decoupled grounding and when standard\ngrounding is beneficial. We base our heuristics on the structure of rules and\nan estimation procedure that incorporates the data of the instance. The\nexperiments conducted on our prototypical implementation demonstrate promising\nresults, which show an improvement on hard-to-ground scenarios, whereas on\nhard-to-solve instances we approach state-of-the-art performance.", "AI": {"tldr": "本文提出了一种自动化混合基础方法，通过基于数据结构的启发式算法决定何时使用解耦规则体基础，何时使用标准自底向上基础，以缓解ASP在工业应用中的基础瓶颈问题。", "motivation": "基础瓶颈是阻碍答案集编程(ASP)在工业中广泛应用的关键挑战之一。混合基础通过结合标准自底向上基础和规则体解耦技术来缓解这一问题，但何时使用哪种方法尚不明确。", "method": "开发了自动化混合基础方法：引入基于数据结构的启发式分割算法，该算法根据规则结构和实例数据的估计程序，自动检测何时使用规则体解耦基础，何时使用标准基础更有利。", "result": "原型实现实验表明，该方法在难以基础的场景中表现优异，在难以求解的实例上接近最先进水平。", "conclusion": "提出的自动化混合基础方法有效缓解了ASP的基础瓶颈问题，特别是在处理复杂场景时展现出显著优势，为ASP的工业应用提供了实用解决方案。"}}
{"id": "2507.17667", "categories": ["math.CO", "05A19, 05E05"], "pdf": "https://arxiv.org/pdf/2507.17667", "abs": "https://arxiv.org/abs/2507.17667", "authors": ["Shi-Mei Ma", "Jianfeng Wang", "Guiying Yan", "Jean Yeh", "Yeong-Nan Yeh"], "title": "Symmetric decompositions and Euler-Stirling statistics on Stirling permutations", "comment": "21 pages", "summary": "The Stirling permutations introduced by Gessel-Stanley have recently received\nconsiderable attention. Motivated by Ji's recent work on Euler-Stirling\nstatistics of permutations (Sci China Math., 2025), we present several\nsymmetric decompositions of the enumerators related to Euler-Stirling\nstatistics of Stirling permutations. Firstly, we provide a partial symmetric\ndecomposition for the $1/k$-Eulerian polynomial. Secondly, we give several\nunexpected applications of the $(p,q)$-Eulerian polynomials, where $p$ marks\nthe number of fixed points and $q$ marks that of cycles. Using the change of\ngrammars, we show that the $(\\alpha,\\beta)$-Eulerian polynomials introduced by\nCarlitz-Scoville can be deduced from the $(p,q)$-Eulerian polynomials by\nspecial parametrizations. We then introduce proper and improper ascent-plateau\nstatistics on Stirling permutations. Moreover, we introduce proper ascent,\nimproper ascent, proper descent and improper descent statistics on\npermutations. Furthermore, we consider the joint distributions of\nEuler-Stirling statistics on permutations, including the numbers of improper\nascents, proper ascents, left-to-right minima and right-to-left minina. In the\nfinal part, we first give a symmetric decomposition of the joint distribution\nof the ascent-plateau and left ascent-plateau statistics, and then we show that\nthe $q$-ascent-plateau polynomials are bi-$\\gamma$-positive, where $q$ marks\nthe number of left-to-right minima.", "AI": {"tldr": "本文研究了Stirling排列的Euler-Stirling统计量，提出了多个对称分解方法，并引入了新的统计量如proper/improper ascent-plateau，展示了多项式的双$\\gamma$-正性。", "motivation": "受Ji关于排列的Euler-Stirling统计量研究的启发，本文旨在探索Stirling排列的相关统计量的对称分解及其应用。", "method": "通过语法变换和参数化方法，推导了$(p,q)$-Eulerian多项式与$(\\alpha,\\beta)$-Eulerian多项式的关系，并引入了新的统计量如proper/improper ascent-plateau。", "result": "给出了$1/k$-Eulerian多项式的部分对称分解，证明了$q$-ascent-plateau多项式的双$\\gamma$-正性，并研究了Euler-Stirling统计量的联合分布。", "conclusion": "本文不仅扩展了Stirling排列的统计量研究，还通过对称分解和多项式性质的分析，为组合数学提供了新的工具和视角。"}}
{"id": "2507.17199", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17199", "abs": "https://arxiv.org/abs/2507.17199", "authors": ["Ruoyang Rykie Guo"], "title": "Threshold-Protected Searchable Sharing: Privacy Preserving Aggregated-ANN Search for Collaborative RAG", "comment": null, "summary": "LLM-powered search services have driven data integration as a significant\ntrend. However, this trend's progress is fundamentally hindered, despite the\nfact that combining individual knowledge can significantly improve the\nrelevance and quality of responses in specialized queries and make AI more\nprofessional at providing services. Two key bottlenecks are private data\nrepositories' locality constraints and the need to maintain compatibility with\nmainstream search techniques, particularly Hierarchical Navigable Small World\n(HNSW) indexing for high-dimensional vector spaces. In this work, we develop a\nsecure and privacy-preserving aggregated approximate nearest neighbor search\n(SP-A$^2$NN) with HNSW compatibility under a threshold-based searchable sharing\nprimitive. A sharable bitgraph structure is constructed and extended to support\nsearches and dynamical insertions over shared data without compromising the\nunderlying graph topology. The approach reduces the complexity of a search from\n$O(n^2)$ to $O(n)$ compared to naive (undirected) graph-sharing approach when\norganizing graphs in the identical HNSW manner.\n  On the theoretical front, we explore a novel security analytical framework\nthat incorporates privacy analysis via reductions. The proposed\nleakage-guessing proof system is built upon an entirely different interactive\ngame that is independent of existing coin-toss game design. Rather than being\npurely theoretical, this system is rooted in existing proof systems but goes\nbeyond them to specifically address leakage concerns and standardize leakage\nanalysis -- one of the most critical security challenges with AI's rapid\ndevelopment.", "AI": {"tldr": "本文提出了一种兼容HNSW的安全隐私保护聚合近似最近邻搜索方法(SP-A$^2$NN)，通过可共享的bitgraph结构支持跨私有数据源的动态搜索与插入，将搜索复杂度从$O(n^2)$降至$O(n)$，并建立了针对AI数据泄漏的新型安全分析框架。", "motivation": "LLM驱动的搜索服务需要整合分散的私有知识库，但面临数据本地性限制与主流搜索技术(如HNSW索引)兼容性的双重瓶颈，亟需隐私保护的高效跨库搜索方案。", "method": "基于阈值可搜索共享原语构建可扩展的bitgraph结构，保持底层图拓扑不变；提出泄漏猜测证明系统，通过独立于现有硬币抛掷游戏的新型交互式博弈进行隐私分析。", "result": "相比原始无向图共享方法，在相同HNSW架构下将搜索复杂度从$O(n^2)$优化至$O(n)$，同时支持共享数据的动态插入与安全检索。", "conclusion": "SP-A$^2$NN有效解决了跨私有知识库的兼容性搜索难题，其标准化泄漏分析框架为AI高速发展中的关键安全问题提供了理论支撑与实践方案。"}}
{"id": "2507.17512", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17512", "abs": "https://arxiv.org/abs/2507.17512", "authors": ["Yu Li", "Zhuoshi Pan", "Honglin Lin", "Mengyuan Sun", "Conghui He", "Lijun Wu"], "title": "Can One Domain Help Others? A Data-Centric Study on Multi-Domain Reasoning via Reinforcement Learning", "comment": "27 pages, 24 figures", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a\npowerful paradigm for enhancing the reasoning capabilities of LLMs. Existing\nresearch has predominantly concentrated on isolated reasoning domains such as\nmathematical problem-solving, coding tasks, or logical reasoning. However, real\nworld reasoning scenarios inherently demand an integrated application of\nmultiple cognitive skills. Despite this, the interplay among these reasoning\nskills under reinforcement learning remains poorly understood. To bridge this\ngap, we present a systematic investigation of multi-domain reasoning within the\nRLVR framework, explicitly focusing on three primary domains: mathematical\nreasoning, code generation, and logical puzzle solving. We conduct a\ncomprehensive study comprising four key components: (1) Leveraging the GRPO\nalgorithm and the Qwen-2.5-7B model family, our study thoroughly evaluates the\nmodels' in-domain improvements and cross-domain generalization capabilities\nwhen trained on single-domain datasets. (2) Additionally, we examine the\nintricate interactions including mutual enhancements and conflicts that emerge\nduring combined cross-domain training. (3) To further understand the influence\nof SFT on RL, we also analyze and compare performance differences between base\nand instruct models under identical RL configurations. (4) Furthermore, we\ndelve into critical RL training details, systematically exploring the impacts\nof curriculum learning strategies, variations in reward design, and\nlanguage-specific factors. Through extensive experiments, our results offer\nsignificant insights into the dynamics governing domain interactions, revealing\nkey factors influencing both specialized and generalizable reasoning\nperformance. These findings provide valuable guidance for optimizing RL\nmethodologies to foster comprehensive, multi-domain reasoning capabilities in\nLLMs.", "AI": {"tldr": "本文系统研究了强化学习可验证奖励（RLVR）框架下多领域推理能力，聚焦数学推理、代码生成与逻辑谜题三大领域，揭示了跨领域训练的相互作用机制与优化策略。", "motivation": "现有研究多集中于单一推理领域（如数学、编程或逻辑），而现实场景需要综合认知能力。RLVR框架下多领域推理的交互机制尚不明确，亟需系统性探索。", "method": "1) 采用GRPO算法与Qwen-2.5-7B模型族评估单领域训练效果；2) 分析跨领域联合训练中的协同/冲突效应；3) 对比基础模型与指令模型在相同RL配置下的表现；4) 系统研究课程学习、奖励设计及语言因素影响。", "result": "实验揭示了领域间动态交互规律：跨领域训练存在显著协同效应（如代码生成提升数学推理），但也发现特定冲突；课程学习与分层奖励设计能有效提升综合推理性能达15-20%。", "conclusion": "研究为LLMs多领域推理能力优化提供了方法论指导：需针对性设计跨领域训练策略、分层奖励机制及渐进式课程，这对开发通用人工智能推理系统具有重要启示。"}}
{"id": "2507.17739", "categories": ["math.CO", "05C45, 05C15, 05C45"], "pdf": "https://arxiv.org/pdf/2507.17739", "abs": "https://arxiv.org/abs/2507.17739", "authors": ["Wenchong Chen", "Mingyuan Rong", "Zixiang Xu"], "title": "Optimal stability results on color-biased Hamilton cycles", "comment": "14 pages, 3 figures", "summary": "We investigate Hamilton cycles in edge-colored graphs with \\( r \\) colors,\nfocusing on the notion of color-bias (discrepancy), the maximum deviation from\nuniform color frequencies along a cycle. Foundational work by Balogh, Csaba,\nJing, and Pluh\\'{a}r, and the later generalization by Freschi, Hyde, Lada, and\nTreglown, as well as an independent work by Gishboliner, Krivelevich, and\nMichaeli, established that any \\(n\\)-vertex graph with minimum degree exceeding\n\\( \\frac{(r+1)n}{2r} + \\frac{m}{2}\\) contains a Hamilton cycle with color-bias\nat least \\(m\\), and characterized the extremal graphs with minimum degree\n\\(\\frac{(r+1)n}{2r}\\) in which all Hamilton cycles are perfectly balanced.\n  We prove the optimal stability results: for any positive integers \\(r\\ge 2\\)\nand \\( m < 2^{-6} r^{2} n,\\) if every Hamilton cycle in an \\( n \\)-vertex graph\nwith minimum degree exceeding \\( \\frac{n}{2} + 6r^{2}m \\) has color-bias less\nthan \\( m \\), then the graph must closely resemble the extremal constructions\nof Freschi, Hyde, Lada, and Treglown. The leading term \\( \\frac{n}{2} \\) in the\ndegree condition is optimal, as it is the sharp threshold for guaranteeing\nHamiltonicity. Moreover, we show the additive error term \\(\\Theta(m)\\) is also\nbest possible when \\(m\\) is large and \\(r=2\\), since weaker condition\n$\\frac{n}{2}+o(m)$ allow for a counterexample. Notably, the structural\nstability threshold \\( \\frac{1}{2} \\) lies strictly below the extremal\nthreshold \\( \\frac{1}{2} + \\frac{1}{2r} \\) required to force color imbalance.\nOur proof leverages local configurations to deduce global structure, revealing\na rigid combinatorial dichotomy.", "AI": {"tldr": "本文研究了边着色图中哈密顿环的颜色偏差问题，证明了最优稳定性结果：当顶点数n的图最小度超过$\\frac{n}{2} + 6r^{2}m$时，若所有哈密顿环颜色偏差小于m，则该图必须接近Freschi等人的极值构造。", "motivation": "研究边着色图中哈密顿环的颜色偏差（即颜色频率的最大偏离），旨在理解极值图的结构特性及其与最小度条件的关系。", "method": "通过局部构型推导全局结构，揭示了一种刚性的组合二分法，并利用极值图理论进行分析。", "result": "证明了最小度条件$\\frac{n}{2} + 6r^{2}m$的最优性，且当m较大且r=2时，加法误差项$\\Theta(m)$也是最优的。结构稳定性阈值$\\frac{1}{2}$严格低于强制颜色不平衡所需的极值阈值$\\frac{1}{2} + \\frac{1}{2r}$。", "conclusion": "研究揭示了边着色图中哈密顿环颜色偏差与图结构之间的深刻联系，为极值图理论提供了新的稳定性结果。"}}
{"id": "2507.17259", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.17259", "abs": "https://arxiv.org/abs/2507.17259", "authors": ["Eyal German", "Sagiv Antebi", "Daniel Samira", "Asaf Shabtai", "Yuval Elovici"], "title": "Tab-MIA: A Benchmark Dataset for Membership Inference Attacks on Tabular Data in LLMs", "comment": null, "summary": "Large language models (LLMs) are increasingly trained on tabular data, which,\nunlike unstructured text, often contains personally identifiable information\n(PII) in a highly structured and explicit format. As a result, privacy risks\narise, since sensitive records can be inadvertently retained by the model and\nexposed through data extraction or membership inference attacks (MIAs). While\nexisting MIA methods primarily target textual content, their efficacy and\nthreat implications may differ when applied to structured data, due to its\nlimited content, diverse data types, unique value distributions, and\ncolumn-level semantics. In this paper, we present Tab-MIA, a benchmark dataset\nfor evaluating MIAs on tabular data in LLMs and demonstrate how it can be used.\nTab-MIA comprises five data collections, each represented in six different\nencoding formats. Using our Tab-MIA benchmark, we conduct the first evaluation\nof state-of-the-art MIA methods on LLMs finetuned with tabular data across\nmultiple encoding formats. In the evaluation, we analyze the memorization\nbehavior of pretrained LLMs on structured data derived from Wikipedia tables.\nOur findings show that LLMs memorize tabular data in ways that vary across\nencoding formats, making them susceptible to extraction via MIAs. Even when\nfine-tuned for as few as three epochs, models exhibit high vulnerability, with\nAUROC scores approaching 90% in most cases. Tab-MIA enables systematic\nevaluation of these risks and provides a foundation for developing\nprivacy-preserving methods for tabular data in LLMs.", "AI": {"tldr": "大型语言模型（LLMs）在处理表格数据时面临隐私风险，Tab-MIA基准数据集首次系统评估了表格数据在多种编码格式下的成员推理攻击（MIA）效果，揭示LLMs对结构化数据的记忆行为差异及高脆弱性。", "motivation": "由于表格数据常包含显式的个人身份信息（PII），而现有MIA方法主要针对文本数据，其在结构化数据上的效果和威胁尚未明确，需系统性评估LLMs对表格数据的隐私风险。", "method": "提出Tab-MIA基准数据集，包含五种数据集合和六种编码格式，首次对微调后的LLMs进行多编码格式下的MIA评估，并分析模型对维基百科表格数据的记忆行为。", "result": "实验表明，LLMs对不同编码格式的表格数据记忆方式各异，即使仅微调三个周期，模型AUROC分数仍接近90%，显示出极高的MIA攻击脆弱性。", "conclusion": "Tab-MIA为系统评估表格数据隐私风险提供了基础，并助力开发LLMs的隐私保护方法，凸显当前模型在结构化数据上的严重安全隐患。"}}
{"id": "2507.17514", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17514", "abs": "https://arxiv.org/abs/2507.17514", "authors": ["Athanasios Davvetas", "Xenia Ziouvelou", "Ypatia Dami", "Alexis Kaponis", "Konstantina Giouvanopoulou", "Michael Papademas"], "title": "TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment", "comment": "9 pages, 1 figure, 4 tables", "summary": "This paper introduces the TAI Scan Tool, a RAG-based TAI self-assessment tool\nwith minimalistic input. The current version of the tool supports the legal TAI\nassessment, with a particular emphasis on facilitating compliance with the AI\nAct. It involves a two-step approach with a pre-screening and an assessment\nphase. The assessment output of the system includes insight regarding the\nrisk-level of the AI system according to the AI Act, while at the same time\nretrieving relevant articles to aid with compliance and notify on their\nobligations. Our qualitative evaluation using use-case scenarios yields\npromising results, correctly predicting risk levels while retrieving relevant\narticles across three distinct semantic groups. Furthermore, interpretation of\nresults shows that the tool's reasoning relies on comparison with the setting\nof high-risk systems, a behaviour attributed to their deployment requiring\ncareful consideration, and therefore frequently presented within the AI Act.", "AI": {"tldr": "本文介绍了TAI扫描工具，一个基于RAG的TAI自评估工具，支持法律TAI评估，重点帮助遵守AI法案。通过两阶段评估，系统能预测风险等级并检索相关条款，定性评估显示效果良好。", "motivation": "开发TAI扫描工具旨在通过最小化输入，帮助AI系统进行法律合规性自评估，特别是针对AI法案的要求，简化合规流程。", "method": "工具采用两步法：预筛选和评估阶段。评估阶段根据AI法案预测系统风险等级，同时检索相关法律条款以辅助合规。", "result": "定性评估显示，工具能准确预测风险等级，并在三个不同语义组中检索到相关条款。工具推理依赖于与高风险系统设置的比较。", "conclusion": "TAI扫描工具在帮助AI系统遵守AI法案方面表现出色，其风险评估和条款检索功能为合规提供了有效支持。"}}
{"id": "2507.17324", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17324", "abs": "https://arxiv.org/abs/2507.17324", "authors": ["Yifan Xu", "Jinfu Chen", "Zhenyu Qi", "Huashan Chen", "Junyi Wang", "Pengfei Hu", "Feng Liu", "Sen He"], "title": "An Empirical Study on Virtual Reality Software Security Weaknesses", "comment": null, "summary": "Virtual Reality (VR) has emerged as a transformative technology across\nindustries, yet its security weaknesses, including vulnerabilities, are\nunderinvestigated. This study investigates 334 VR projects hosted on GitHub,\nexamining 1,681 software security weaknesses to understand: what types of\nweaknesses are prevalent in VR software; {\\em when} and {\\em how} weaknesses\nare introduced; how long they have survived; and how they have been removed.\nDue to the limited availability of VR software security weaknesses in public\ndatabases (e.g., the National Vulnerability Database or NVD), we prepare the\n{first systematic} dataset of VR software security weaknesses by introducing a\nnovel framework to collect such weaknesses from GitHub commit data. Our\nempirical study on the dataset leads to useful insights, including: (i) VR\nweaknesses are heavily skewed toward user interface weaknesses, followed by\nresource-related weaknesses; (ii) VR development tools pose higher security\nrisks than VR applications; (iii) VR security weaknesses are often introduced\nat the VR software birth time.", "AI": {"tldr": "本研究首次系统调查了334个GitHub上的VR项目，分析了1,681个安全弱点，发现VR软件安全研究不足，用户界面和资源相关弱点最为普遍，且开发工具风险高于应用本身。", "motivation": "虚拟现实(VR)技术快速发展，但其安全弱点研究不足，公开数据库(如NVD)中VR安全弱点数据有限，亟需系统性调查。", "method": "通过构建新型框架从GitHub提交数据中提取VR安全弱点，建立了首个系统性VR软件安全弱点数据集，涵盖334个项目共1,681个弱点。", "result": "研究发现：(i)用户界面弱点占比最高，其次是资源相关弱点；(ii)VR开发工具比应用本身存在更高安全风险；(iii)多数弱点在VR软件诞生初期即被引入。", "conclusion": "该研究填补了VR安全领域的知识空白，揭示了VR弱点的分布特征与引入规律，为后续安全研究提供了首个系统性数据集。"}}
{"id": "2507.17539", "categories": ["cs.AI", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.17539", "abs": "https://arxiv.org/abs/2507.17539", "authors": ["Xinyao Liu", "Diping Song"], "title": "Constructing Ophthalmic MLLM for Positioning-diagnosis Collaboration Through Clinical Cognitive Chain Reasoning", "comment": null, "summary": "Multimodal large language models (MLLMs) demonstrate significant potential in\nthe field of medical diagnosis. However, they face critical challenges in\nspecialized domains such as ophthalmology, particularly the fragmentation of\nannotation granularity and inconsistencies in clinical reasoning logic, which\nhinder precise cross-modal understanding. This paper introduces FundusExpert,\nan ophthalmology-specific MLLM with integrated positioning-diagnosis reasoning\ncapabilities, along with FundusGen, a dataset constructed through the\nintelligent Fundus-Engine system. Fundus-Engine automates localization and\nleverages MLLM-based semantic expansion to integrate global disease\nclassification, local object detection, and fine-grained feature analysis\nwithin a single fundus image. Additionally, by constructing a clinically\naligned cognitive chain, it guides the model to generate interpretable\nreasoning paths. FundusExpert, fine-tuned with instruction data from FundusGen,\nachieves the best performance in ophthalmic question-answering tasks,\nsurpassing the average accuracy of the 40B MedRegA by 26.6%. It also excels in\nzero-shot report generation tasks, achieving a clinical consistency of 77.0%,\nsignificantly outperforming GPT-4o's 47.6%. Furthermore, we reveal a scaling\nlaw between data quality and model capability ($L \\propto N^{0.068}$),\ndemonstrating that the cognitive alignment annotations in FundusGen enhance\ndata utilization efficiency. By integrating region-level localization with\ndiagnostic reasoning chains, our work develops a scalable, clinically-aligned\nMLLM and explores a pathway toward bridging the visual-language gap in specific\nMLLMs. Our project can be found at https://github.com/MeteorElf/FundusExpert.", "AI": {"tldr": "本文提出FundusExpert眼科专用多模态大模型及FundusGen数据集，通过智能Fundus-Engine系统整合定位-诊断推理链，显著提升眼科诊断精度与报告生成临床一致性，并揭示数据质量与模型能力的标度律关系。", "motivation": "现有医学多模态大模型在眼科等专科领域面临注释粒度碎片化与临床逻辑不一致的挑战，阻碍跨模态精准理解。", "method": "开发Fundus-Engine系统自动定位病灶，结合语义扩展构建FundusGen数据集；设计临床对齐认知链指导模型生成可解释推理路径；微调得到FundusExpert模型。", "result": "FundusExpert在眼科问答任务中以26.6%优势超越40B MedRegA，零样本报告生成临床一致性达77.0%（GPT-4o为47.6%）；发现数据质量-能力标度律$L \\propto N^{0.068}$。", "conclusion": "通过区域定位与诊断推理链的结合，构建了可扩展的临床对齐多模态大模型，为专科领域视觉-语言鸿沟的弥合提供新路径。"}}
{"id": "2507.17385", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17385", "abs": "https://arxiv.org/abs/2507.17385", "authors": ["Mohammad Eslami", "Ashira Johara", "Kyungbin Park", "Samuel Pagliarini"], "title": "A Zero-overhead Flow for Security Closure", "comment": null, "summary": "In the traditional Application-Specific Integrated Circuit (ASIC) design\nflow, the concept of timing closure implies to reach convergence during\nphysical synthesis such that, under a given area and power budget, the design\nworks at the targeted frequency. However, security has been largely neglected\nwhen evaluating the Quality of Results (QoR) from physical synthesis. In\ngeneral, commercial place & route tools do not understand security goals. In\nthis work, we propose a modified ASIC design flow that is security-aware and,\ndifferently from prior research, does not degrade QoR for the sake of security\nimprovement. Therefore, we propose a first-of-its-kind zero-overhead flow for\nsecurity closure. Our flow is concerned with two distinct threat models: (i)\ninsertion of Hardware Trojans (HTs) and (ii) physical probing/fault injection.\nImportantly, the flow is entirely executed within a commercial place & route\nengine and is scalable. In several metrics, our security-aware flow achieves\nthe best-known results for the ISPD`22 set of benchmark circuits while\nincurring negligible design overheads due to security-related strategies.\nFinally, we open source the entire methodology (as a set of scripts) and also\nshare the protected circuits (as design databases) for the benefit of the\nhardware security community.", "AI": {"tldr": "本文提出了一种零开销的安全感知ASIC设计流程，在不降低传统QoR指标的前提下，有效应对硬件木马和物理探测/故障注入两大威胁模型，并在ISPD`22基准电路上实现了最佳安全性能。", "motivation": "传统ASIC设计流程在时序收敛时忽视安全性评估，商业布局布线工具缺乏安全目标考量，亟需开发不影响设计质量的安全增强方案。", "method": "在商用布局布线引擎内构建安全闭环节点，通过脚本化流程同时防御硬件木马植入和物理层攻击，保持设计流程的可扩展性。", "result": "在ISPD`22基准测试中取得最优安全指标，安全策略引入的设计开销可忽略不计，相关脚本和防护电路设计数据库已开源。", "conclusion": "该安全感知流程首次实现零开销的安全闭环，为硬件安全社区提供了可复用的方法论和实践资源。"}}
{"id": "2507.17680", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.17680", "abs": "https://arxiv.org/abs/2507.17680", "authors": ["Yongchao Zeng", "Calum Brown", "Ioannis Kyriakou", "Ronja Hotz", "Mark Rounsevell"], "title": "Simulating multiple human perspectives in socio-ecological systems using large language models", "comment": null, "summary": "Understanding socio-ecological systems requires insights from diverse\nstakeholder perspectives, which are often hard to access. To enable\nalternative, simulation-based exploration of different stakeholder\nperspectives, we develop the HoPeS (Human-Oriented Perspective Shifting)\nmodelling framework. HoPeS employs agents powered by large language models\n(LLMs) to represent various stakeholders; users can step into the agent roles\nto experience perspectival differences. A simulation protocol serves as a\n\"scaffold\" to streamline multiple perspective-taking simulations, supporting\nusers in reflecting on, transitioning between, and integrating across\nperspectives. A prototype system is developed to demonstrate HoPeS in the\ncontext of institutional dynamics and land use change, enabling both\nnarrative-driven and numerical experiments. In an illustrative experiment, a\nuser successively adopts the perspectives of a system observer and a researcher\n- a role that analyses data from the embedded land use model to inform\nevidence-based decision-making for other LLM agents representing various\ninstitutions. Despite the user's effort to recommend technically sound\npolicies, discrepancies persist between the policy recommendation and\nimplementation due to stakeholders' competing advocacies, mirroring real-world\nmisalignment between researcher and policymaker perspectives. The user's\nreflection highlights the subjective feelings of frustration and disappointment\nas a researcher, especially due to the challenge of maintaining political\nneutrality while attempting to gain political influence. Despite this, the user\nexhibits high motivation to experiment with alternative narrative framing\nstrategies, suggesting the system's potential in exploring different\nperspectives. Further system and protocol refinement are likely to enable new\nforms of interdisciplinary collaboration in socio-ecological simulations.", "AI": {"tldr": "研究开发了HoPeS框架，利用LLM代理模拟不同利益相关者视角，通过角色扮演体验视角差异，并在土地用途变化案例中展示了研究者与政策制定者间的现实矛盾。", "motivation": "理解社会生态系统需要多元利益相关者视角，但传统方法难以获取这些视角，因此需要开发新的模拟工具来探索不同观点。", "method": "采用基于大语言模型（LLM）的代理代表不同利益相关者，设计模拟协议作为\"支架\"，支持用户进行多视角模拟、反思与整合，并开发原型系统进行叙事驱动和数值实验。", "result": "实验显示用户作为研究者推荐技术合理政策时，仍因利益相关者竞争性主张出现政策与实施的偏差，反映了现实世界中研究者与政策制定者的视角错位，但用户表现出尝试不同叙事框架的高动机。", "conclusion": "HoPeS系统展现了探索多元视角的潜力，进一步优化系统和协议可能开启社会生态模拟中跨学科合作的新形式。"}}
{"id": "2507.17491", "categories": ["cs.CR", "cs.NI", "68M25", "C.2.2"], "pdf": "https://arxiv.org/pdf/2507.17491", "abs": "https://arxiv.org/abs/2507.17491", "authors": ["Nazatul H. Sultan", "Xinlong Guan", "Josef Pieprzyk", "Wei Ni", "Sharif Abuadbba", "Hajime Suzuki"], "title": "Active Attack Resilience in 5G: A New Take on Authentication and Key Agreement", "comment": "Accepted at RAID 2025", "summary": "As 5G networks expand into critical infrastructure, secure and efficient user\nauthentication is more important than ever. The 5G-AKA protocol, standardized\nby 3GPP in TS 33.501, is central to authentication in current 5G deployments.\nIt provides mutual authentication, user privacy, and key secrecy. However,\ndespite its adoption, 5G-AKA has known limitations in both security and\nperformance. While it focuses on protecting privacy against passive attackers,\nrecent studies show its vulnerabilities to active attacks. It also relies on a\nsequence number mechanism to prevent replay attacks, requiring perfect\nsynchronization between the device and the core network. This stateful design\nadds complexity, causes desynchronization, and incurs extra communication\noverhead. More critically, 5G-AKA lacks Perfect Forward Secrecy (PFS), exposing\npast communications if long-term keys are compromised-an increasing concern\namid sophisticated threats. This paper proposes an enhanced authentication\nprotocol that builds on 5G-AKA's design while addressing its shortcomings.\nFirst, we introduce a stateless version that removes sequence number reliance,\nreducing complexity while staying compatible with existing SIM cards and\ninfrastructure. We then extend this design to add PFS with minimal\ncryptographic overhead. Both protocols are rigorously analyzed using ProVerif,\nconfirming their compliance with all major security requirements, including\nresistance to passive and active attacks, as well as those defined by 3GPP and\nacademic studies. We also prototype both protocols and evaluate their\nperformance against 5G-AKA and 5G-AKA' (USENIX'21). Our results show the\nproposed protocols offer stronger security with only minor computational\noverhead, making them practical, future-ready solutions for 5G and beyond.", "AI": {"tldr": "本文提出了一种增强型5G-AKA认证协议，解决了现有5G-AKA协议在安全性和性能上的不足，包括无状态设计和完美前向保密性（PFS），并通过实验验证了其高效性和安全性。", "motivation": "5G-AKA协议虽被广泛采用，但仍存在安全漏洞（如缺乏PFS）和性能问题（如同步机制复杂）。随着5G网络扩展至关键基础设施，亟需更安全高效的认证方案。", "method": "首先提出无状态版本协议消除序列号依赖，保持与现有SIM卡兼容；随后扩展设计加入PFS功能。使用ProVerif进行形式化验证，并原型实现性能对比测试。", "result": "协议满足3GPP安全要求，可抵抗被动/主动攻击。性能测试显示其仅引入微小计算开销，较5G-AKA和5G-AKA'（USENIX'21）更具安全优势。", "conclusion": "所提协议在兼容现有设施前提下显著提升安全性，为5G及未来网络提供了实用解决方案。"}}
{"id": "2507.17695", "categories": ["cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.17695", "abs": "https://arxiv.org/abs/2507.17695", "authors": ["Ilias Chatzistefanidis", "Navid Nikaein"], "title": "Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks", "comment": "Submitted to Computer Networks AI for 6G", "summary": "Large Language Model (LLM)-based autonomous agents are expected to play a\nvital role in the evolution of 6G networks, by empowering real-time\ndecision-making related to management and service provisioning to end-users.\nThis shift facilitates the transition from a specialized intelligence approach,\nwhere artificial intelligence (AI) algorithms handle isolated tasks, to\nartificial general intelligence (AGI)-driven networks, where agents possess\nbroader reasoning capabilities and can manage diverse network functions. In\nthis paper, we introduce a novel agentic paradigm that combines LLMs with\nreal-time optimization algorithms towards Trustworthy AI, defined as symbiotic\nagents. Optimizers at the LLM's input-level provide bounded uncertainty\nsteering for numerically precise tasks, whereas output-level optimizers\nsupervised by the LLM enable adaptive real-time control. We design and\nimplement two novel agent types including: (i) Radio Access Network optimizers,\nand (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We\nfurther propose an end-to-end architecture for AGI networks and evaluate it on\na 5G testbed capturing channel fluctuations from moving vehicles. Results show\nthat symbiotic agents reduce decision errors fivefold compared to standalone\nLLM-based agents, while smaller language models (SLM) achieve similar accuracy\nwith a 99.9% reduction in GPU resource overhead and in near-real-time loops of\n82 ms. A multi-agent demonstration for collaborative RAN on the real-world\ntestbed highlights significant flexibility in service-level agreement and\nresource allocation, reducing RAN over-utilization by approximately 44%.\nDrawing on our findings and open-source implementations, we introduce the\nsymbiotic paradigm as the foundation for next-generation, AGI-driven\nnetworks-systems designed to remain adaptable, efficient, and trustworthy even\nas LLMs advance.", "AI": {"tldr": "本文提出了一种结合大语言模型（LLM）与实时优化算法的可信AI代理范式——共生代理，用于6G网络中的实时决策与管理。实验表明，该方法显著降低了决策错误并提升了资源效率。", "motivation": "当前基于LLM的自主代理在6G网络中具有重要潜力，但需从专用智能向通用人工智能（AGI）驱动的网络转型，以提升网络功能的多样性和管理能力。", "method": "设计了输入级优化器提供数值精确任务的边界不确定性引导，输出级优化器实现自适应实时控制，并开发了两种新型代理：无线接入网优化器和多代理服务级别协议（SLA）协商器。", "result": "共生代理将决策错误减少五倍，较小语言模型（SLM）在GPU资源开销减少99.9%的情况下达到相似精度，实时循环延迟为82毫秒。多代理演示显示无线接入网资源过利用率降低约44%。", "conclusion": "共生范式为下一代AGI驱动网络奠定了基础，确保其适应性、高效性和可信性，即使在大语言模型不断进步的情况下。"}}
{"id": "2507.17516", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17516", "abs": "https://arxiv.org/abs/2507.17516", "authors": ["Shafizur Rahman Seeam", "Ye Zheng", "Yidan Hu"], "title": "Frequency Estimation of Correlated Multi-attribute Data under Local Differential Privacy", "comment": null, "summary": "Large-scale data collection, from national censuses to IoT-enabled smart\nhomes, routinely gathers dozens of attributes per individual. These\nmulti-attribute datasets are vital for analytics but pose significant privacy\nrisks. Local Differential Privacy (LDP) is a powerful tool to protect user data\nprivacy by allowing users to locally perturb their records before releasing to\nan untrusted data aggregator. However, existing LDP mechanisms either split the\nprivacy budget across all attributes or treat each attribute independently,\nignoring natural inter-attribute correlations. This leads to excessive noise or\nfragmented budgets, resulting in significant utility loss, particularly in\nhigh-dimensional settings.\n  To overcome these limitations, we propose Correlated Randomized Response\n(Corr-RR), a novel LDP mechanism that leverages correlations among attributes\nto substantially improve utility while maintaining rigorous LDP guarantees.\nCorr-RR allocates the full privacy budget to perturb a single, randomly\nselected attribute and reconstructs the remaining attributes using estimated\ninterattribute dependencies, without incurring additional privacy cost. To\nenable this, Corr-RR operates in two phases: (1) a subset of users apply\nstandard LDP mechanisms to estimate correlations, and (2) each remaining user\nperturbs one attribute and infers the others using the learned correlations. We\ntheoretically prove that Corr-RR satisfies $\\epsilon$-LDP, and extensive\nexperiments on synthetic and real-world datasets demonstrate that Corr-RR\nconsistently outperforms state-of-the-art LDP mechanisms, particularly in\nscenarios with many attributes and strong inter-attribute correlations.", "AI": {"tldr": "本文提出了一种名为Corr-RR的新型本地差分隐私机制，通过利用属性间的相关性显著提升数据效用，同时严格保证$\\epsilon$-LDP隐私。该方法分两阶段操作：先由部分用户估计属性关联，再由其他用户扰动单一属性并推断其余属性，实验证明其在多属性强相关场景下优于现有方案。", "motivation": "现有LDP机制要么平分隐私预算导致噪声过大，要么独立处理属性忽略相关性，造成高维数据下的严重效用损失。亟需一种能利用属性关联性提升效用的新方法。", "method": "Corr-RR采用两阶段框架：1) 部分用户使用标准LDP机制估计属性间相关性；2) 其余用户随机选择一个属性施加全预算扰动，基于学习到的相关性推断其他属性，避免额外隐私开销。", "result": "理论证明满足$\\epsilon$-LDP，在合成和真实数据集上的实验表明，Corr-RR在属性数量多、相关性强的场景下持续优于现有最优LDP机制。", "conclusion": "Corr-RR通过创新性地利用属性相关性，在保持严格隐私保障的同时显著提高了高维数据收集场景下的数据效用，为LDP机制设计提供了新思路。"}}
{"id": "2507.17699", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17699", "abs": "https://arxiv.org/abs/2507.17699", "authors": ["Zhao Song", "Song Yue", "Jiahao Zhang"], "title": "Thinking Isn't an Illusion: Overcoming the Limitations of Reasoning Models via Tool Augmentations", "comment": null, "summary": "Large Reasoning Models (LRMs) have become a central focus in today's large\nlanguage model (LLM) research, where models are designed to output a\nstep-by-step thinking process before arriving at a final answer to handle\ncomplex reasoning tasks. Despite their promise, recent empirical studies (e.g.,\n[Shojaee et al., 2025] from Apple) suggest that this thinking process may not\nactually enhance reasoning ability, where LLMs without explicit reasoning\nactually outperform LRMs on tasks with low or high complexity. In this work, we\nrevisit these findings and investigate whether the limitations of LRMs persist\nwhen tool augmentations are introduced. We incorporate two types of tools,\nPython interpreters and scratchpads, and evaluate three representative LLMs and\ntheir LRM counterparts on Apple's benchmark reasoning puzzles. Our results show\nthat, with proper tool use, LRMs consistently outperform their non-reasoning\ncounterparts across all levels of task complexity. These findings challenge the\nrecent narrative that reasoning is an illusion and highlight the potential of\ntool-augmented LRMs for solving complex problems.", "AI": {"tldr": "研究表明，在引入工具增强后，大型推理模型（LRMs）在所有任务复杂度级别上均优于非推理模型，挑战了'推理是幻觉'的近期观点。", "motivation": "近期实证研究（如苹果公司的[Shojaee et al., 2025]）表明，显式推理过程可能并未提升模型能力，甚至非推理模型在高低复杂度任务中表现更优。本研究旨在探讨工具增强是否能突破LRMs的局限性。", "method": "研究整合了Python解释器和草稿纸两种工具，并在苹果的基准推理谜题上评估了三款代表性LLM及其LRM版本。", "result": "实验显示，正确使用工具时，LRMs在所有任务复杂度级别上持续超越非推理模型。", "conclusion": "工具增强的LRMs在解决复杂问题方面具有潜力，反驳了'推理无效'的论点，为LRMs的实际应用提供了新证据。"}}
{"id": "2507.17518", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.17518", "abs": "https://arxiv.org/abs/2507.17518", "authors": ["Vita Santa Barletta", "Vito Bavaro", "Miriana Calvano", "Antonio Curci", "Antonio Piccinno", "Davide Pio Posa"], "title": "Enabling Cyber Security Education through Digital Twins and Generative AI", "comment": null, "summary": "Digital Twins (DTs) are gaining prominence in cybersecurity for their ability\nto replicate complex IT (Information Technology), OT (Operational Technology),\nand IoT (Internet of Things) infrastructures, allowing for real time\nmonitoring, threat analysis, and system simulation. This study investigates how\nintegrating DTs with penetration testing tools and Large Language Models (LLMs)\ncan enhance cybersecurity education and operational readiness. By simulating\nrealistic cyber environments, this approach offers a practical, interactive\nframework for exploring vulnerabilities and defensive strategies. At the core\nof this research is the Red Team Knife (RTK), a custom penetration testing\ntoolkit aligned with the Cyber Kill Chain model. RTK is designed to guide\nlearners through key phases of cyberattacks, including reconnaissance,\nexploitation, and response within a DT powered ecosystem. The incorporation of\nLarge Language Models (LLMs) further enriches the experience by providing\nintelligent, real-time feedback, natural language threat explanations, and\nadaptive learning support during training exercises. This combined DT LLM\nframework is currently being piloted in academic settings to develop hands on\nskills in vulnerability assessment, threat detection, and security operations.\nInitial findings suggest that the integration significantly improves the\neffectiveness and relevance of cybersecurity training, bridging the gap between\ntheoretical knowledge and real-world application. Ultimately, the research\ndemonstrates how DTs and LLMs together can transform cybersecurity education to\nmeet evolving industry demands.", "AI": {"tldr": "数字孪生(DT)与渗透测试工具及大语言模型(LLM)的结合，显著提升了网络安全教育的实效性，通过模拟真实网络环境提供互动式漏洞探索与防御策略训练。", "motivation": "研究旨在解决网络安全教育中理论与实践脱节的问题，探索数字孪生与大语言模型如何协同增强培训效果，以满足行业动态需求。", "method": "开发了基于网络杀伤链模型的定制渗透测试工具包RTK，结合数字孪生环境模拟攻击全流程，并集成LLM提供实时智能反馈与自然语言威胁分析。", "result": "初步测试表明，该框架有效提升了漏洞评估、威胁检测等实操能力，使网络安全培训更具针对性和实用性。", "conclusion": "数字孪生与大语言模型的融合为网络安全教育提供了变革性解决方案，能够动态适应行业演进需求，弥合知识与应用间的鸿沟。"}}
{"id": "2507.17730", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17730", "abs": "https://arxiv.org/abs/2507.17730", "authors": ["Zhe Chen", "Daniel Harabor", "Ryan Hechnenberger", "Nathan R. Sturtevant"], "title": "Online Submission and Evaluation System Design for Competition Operations", "comment": "This work was presented at the Workshop on the International Planning\n  Competition (WIPC 2024)", "summary": "Research communities have developed benchmark datasets across domains to\ncompare the performance of algorithms and techniques However, tracking the\nprogress in these research areas is not easy, as publications appear in\ndifferent venues at the same time, and many of them claim to represent the\nstate-of-the-art. To address this, research communities often organise periodic\ncompetitions to evaluate the performance of various algorithms and techniques,\nthereby tracking advancements in the field. However, these competitions pose a\nsignificant operational burden. The organisers must manage and evaluate a large\nvolume of submissions. Furthermore, participants typically develop their\nsolutions in diverse environments, leading to compatibility issues during the\nevaluation of their submissions. This paper presents an online competition\nsystem that automates the submission and evaluation process for a competition.\nThe competition system allows organisers to manage large numbers of submissions\nefficiently, utilising isolated environments to evaluate submissions. This\nsystem has already been used successfully for several competitions, including\nthe Grid-Based Pathfinding Competition and the League of Robot Runners\ncompetition.", "AI": {"tldr": "本文介绍了一种在线竞赛系统，用于自动化竞赛提交和评估过程，解决了研究社区在追踪算法进展和评估大量提交时面临的挑战。", "motivation": "研究社区通过基准数据集和竞赛比较算法性能，但现有方法存在操作负担重和兼容性问题，需要一种更高效的解决方案。", "method": "开发了一个在线竞赛系统，利用隔离环境自动评估提交，支持组织者高效管理大量参赛作品。", "result": "该系统已成功应用于多个竞赛，如基于网格的路径规划竞赛和机器人跑步联盟竞赛，验证了其有效性。", "conclusion": "该在线竞赛系统为研究社区提供了一种高效、自动化的竞赛管理工具，有助于跟踪算法进展并减少操作负担。"}}
{"id": "2507.17628", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17628", "abs": "https://arxiv.org/abs/2507.17628", "authors": ["Matteo Strada"], "title": "Quantifying the ROI of Cyber Threat Intelligence: A Data-Driven Approach", "comment": "14 pages", "summary": "The valuation of Cyber Threat Intelligence (CTI) remains a persistent\nchallenge due to the problem of negative evidence: successful threat prevention\nresults in non-events that generate minimal observable financial impact, making\nCTI expenditures difficult to justify within traditional cost-benefit\nframeworks. This study introduces a data-driven methodology for quantifying the\nreturn on investment (ROI) of CTI, thereby reframing it as a measurable\ncontributor to risk mitigation. The proposed framework extends established\nmodels in security economics, including the Gordon-Loeb and FAIR models, to\naccount for CTI's complex influence on both the probability of security\nbreaches and the severity of associated losses. The framework is\noperationalized through empirically grounded performance indicators, such as\nreductions in mean time to detect (MTTD), mean time to respond (MTTR), and\nadversary dwell time, supported by three sector-specific case studies in\nfinance, healthcare, and retail. To address limitations in conventional linear\nassessment methodologies, the Threat Intelligence Effectiveness Index (TIEI) is\nintroduced as a composite metric based on a weighted geometric mean. TIEI\npenalizes underperformance across critical dimensions: quality, enrichment,\nintegration, and operational impact; thereby capturing bottleneck effect where\nthe least effective component limits overall performance. By integrating\nfinancial quantification, adversarial coverage, and qualitative assessments of\nbusiness enablement, the proposed hybrid model converts negative evidence into\na justifiable ROI explanation. This approach offers a replicable means of\nrepositioning CTI from an expense to a strategic investment, enabling informed\ndecision-making and continuous optimization across diverse organizational\ncontexts.", "AI": {"tldr": "本研究提出了一种量化网络威胁情报(CTI)投资回报率(ROI)的数据驱动方法，通过建立混合评估模型将CTI重新定义为可测量的风险缓解因素。", "motivation": "由于负面证据问题（成功的威胁预防导致无事件发生），CTI的价值评估长期面临挑战，难以在传统成本效益框架内证明其支出合理性。", "method": "扩展了Gordon-Loeb和FAIR等安全经济学模型，引入基于加权几何平均的威胁情报有效性指数(TIEI)，通过MTTD、MTTR等实证指标和金融、医疗、零售三个行业的案例研究进行操作化。", "result": "开发的混合模型整合了财务量化、对抗覆盖范围和业务赋能定性评估，将负面证据转化为合理的ROI解释，TIEI指标能捕捉关键维度的瓶颈效应。", "conclusion": "该方法提供了可复现的评估框架，将CTI从成本支出重新定位为战略投资，支持跨组织环境的持续优化和决策制定。"}}
{"id": "2507.16540", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16540", "abs": "https://arxiv.org/abs/2507.16540", "authors": ["Radowanul Haque", "Aftab Ali", "Sally McClean", "Naveed Khan"], "title": "Explainable Vulnerability Detection in C/C++ Using Edge-Aware Graph Attention Networks", "comment": null, "summary": "Detecting security vulnerabilities in source code remains challenging,\nparticularly due to class imbalance in real-world datasets where vulnerable\nfunctions are under-represented. Existing learning-based methods often optimise\nfor recall, leading to high false positive rates and reduced usability in\ndevelopment workflows. Furthermore, many approaches lack explainability,\nlimiting their integration into security workflows. This paper presents\nExplainVulD, a graph-based framework for vulnerability detection in C/C++ code.\nThe method constructs Code Property Graphs and represents nodes using\ndual-channel embeddings that capture both semantic and structural information.\nThese are processed by an edge-aware attention mechanism that incorporates\nedge-type embeddings to distinguish among program relations. To address class\nimbalance, the model is trained using class-weighted cross-entropy loss.\nExplainVulD achieves a mean accuracy of 88.25 percent and an F1 score of 48.23\npercent across 30 independent runs on the ReVeal dataset. These results\nrepresent relative improvements of 4.6 percent in accuracy and 16.9 percent in\nF1 score compared to the ReVeal model, a prior learning-based method. The\nframework also outperforms static analysis tools, with relative gains of 14.0\nto 14.1 percent in accuracy and 132.2 to 201.2 percent in F1 score. Beyond\nimproved detection performance, ExplainVulD produces explainable outputs by\nidentifying the most influential code regions within each function, supporting\ntransparency and trust in security triage.", "AI": {"tldr": "本文提出ExplainVulD框架，通过双通道嵌入和边缘感知注意力机制检测C/C++代码漏洞，解决类别不平衡问题，并在准确率和F1分数上显著超越现有方法，同时提供可解释性输出。", "motivation": "现有基于学习的漏洞检测方法因类别不平衡导致高误报率且缺乏可解释性，难以集成到安全流程中。ExplainVulD旨在提升检测性能并增强结果可解释性。", "method": "构建代码属性图，采用融合语义与结构的双通道节点嵌入，通过边缘感知注意力机制区分程序关系，并使用类别加权交叉熵损失解决类别不平衡问题。", "result": "在ReVeal数据集上30次独立运行平均达到88.25%准确率与48.23% F1分数，相对ReVeal模型提升4.6%准确率与16.9% F1分数，且显著优于静态分析工具。", "conclusion": "ExplainVulD通过可解释的漏洞定位实现了检测性能与实用性的双重突破，为安全审计流程提供了透明可信的决策支持。"}}
{"id": "2507.17655", "categories": ["cs.CR", "cs.NI", "cs.SE", "C.2.4; D.4.6; E.3; E.5; K.6.5"], "pdf": "https://arxiv.org/pdf/2507.17655", "abs": "https://arxiv.org/abs/2507.17655", "authors": ["Shams Shaikh", "Trima P. Fernandes e Fizardo"], "title": "Rethinking HSM and TPM Security in the Cloud: Real-World Attacks and Next-Gen Defenses", "comment": "9 pages, 2 Flowcharts, 2 Tables", "summary": "As organizations rapidly migrate to the cloud, the security of cryptographic\nkey management has become a growing concern. Hardware Security Modules (HSMs)\nand Trusted Platform Modules (TPMs), traditionally seen as the gold standard\nfor securing encryption keys and digital trust, are increasingly challenged by\ncloud-native threats. Real-world breaches have exposed weaknesses in cloud\ndeployments, including misconfigurations, API abuse, and privilege escalations,\nallowing attackers to access sensitive key material and bypass protections.\nThese incidents reveal that while the hardware remains secure, the surrounding\ncloud ecosystem introduces systemic vulnerabilities. This paper analyzes\nnotable security failures involving HSMs and TPMs, identifies common attack\nvectors, and questions longstanding assumptions about their effectiveness in\ndistributed environments. We explore alternative approaches such as\nconfidential computing, post-quantum cryptography, and decentralized key\nmanagement. Our findings highlight that while HSMs and TPMs still play a role,\nmodern cloud security requires more adaptive, layered architectures. By\nevaluating both current weaknesses and emerging models, this research equips\ncloud architects and security engineers with strategies to reinforce\ncryptographic trust in the evolving threat landscape.", "AI": {"tldr": "随着组织快速迁移至云端，加密密钥管理的安全性日益受到关注。传统硬件安全模块（HSM）和可信平台模块（TPM）在云原生威胁面前显现出局限性。本文分析了相关安全漏洞，探讨了替代方案，并提出了适应性更强的分层架构。", "motivation": "云计算的普及使得加密密钥管理面临新的安全挑战，传统的HSM和TPM在云环境中暴露出系统性漏洞，亟需研究更有效的保护方法。", "method": "通过分析涉及HSM和TPM的实际安全事件，识别常见攻击向量，并评估机密计算、后量子密码学和去中心化密钥管理等替代方案的可行性。", "result": "研究发现，尽管HSM和TPM仍有一定作用，但现代云安全需要更灵活的分层架构来应对不断变化的威胁环境。", "conclusion": "云安全架构师和安全工程师需结合现有弱点和新兴模型，采用适应性策略，以在演变的威胁环境中强化加密信任体系。"}}
