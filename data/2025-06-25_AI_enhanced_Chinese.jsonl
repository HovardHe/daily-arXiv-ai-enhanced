{"id": "2506.19115", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2506.19115", "abs": "https://arxiv.org/abs/2506.19115", "authors": ["Sebastian Angermund"], "title": "A Two-Operator Calculus for Arithmetic-Progression Paths in the Collatz Graph", "comment": null, "summary": "A recast of the standard residue-class analysis of the 3x+1 (Collatz) map in\nterms of two elementary operators on arithmetic progressions. The resulting\ncalculus (i) splits any progression into its even and odd subsequences in a\nsingle step, (ii) gives a closed formula for every set of seeds that realises a\nprescribed parity word, (iii) yields a one line affine invariant that forbids\ntrajectories consisting of infinitely many odd moves, and (iv) reduces the\nnon-trivial-cycle problem to a pair of linear congruences.", "AI": {"tldr": "论文通过两个基本算子重构了3x+1问题的余类分析，提出了能一次性分割奇偶子序列、计算特定奇偶模式种子集、禁止无限奇移动轨迹的封闭公式，并将非平凡环问题简化为线性同余组。", "motivation": "研究旨在简化3x+1问题的分析框架，通过算术级数上的算子统一处理奇偶性分类与轨迹约束问题。", "method": "采用两个基本算子重构余类分析，建立封闭公式描述奇偶模式种子集，并推导仿射不变量约束轨迹行为。", "result": "获得四项核心成果：(i)奇偶子序列单步分割；(ii)特定奇偶模式的种子集封闭解；(iii)禁止无限奇移动的单行判据；(iv)非平凡环问题转化为线性同余组。", "conclusion": "该算子演算为3x+1问题提供了更简洁的分析工具，尤其在线性约束和轨迹分类方面展现出高效性。"}}
{"id": "2506.19173", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2506.19173", "abs": "https://arxiv.org/abs/2506.19173", "authors": ["Jamal Agbanwa"], "title": "A Closed-Form Symbolic Generator: $A^n + B^n = C^n + D^n$, for $n = 2,3$", "comment": "13 pages", "summary": "We present a unified framework for constructing integer solutions to $A^{n} +\nB^{n} = C^{n} + D^{n}$ for $n=2,3$. For $n=2$, we derive explicit formulas for\nany solutions via differences of squares. For $n=3$, we introduce general\nformulas that include the Hardy-Ramanujan number 1729 for instance, we also\nconstruct a symbolic generator that produces infinitely many integer solutions\nto the Diophantine equation A^3 + B^3 = C^3 + D^3 . While the resulting\nformulas for $A,B,C,D$ from the symbolic generator developed do not span every\nsingle number expressible as a sum of two positive cubes in at least two\ndistinct ways, our method provides a closed-form, algebraic parametrization in\nterms of a single variable, expressing each term as a radical-exponential\nfunction of an integer parameter $c_1$. The generator leverages nested radicals\nand exponents of algebraic numbers, $\\alpha, \\beta$ derived from the recurrence\nstructure of the Diophantine constraint. This work represents the first\nsymbolic, recursive generator of its kind and offers a pathway toward\napproaching higher powers of this problem from a different lens. These methods\nexploit structural links between binomial expansions and Diophantine\nconstraints, offering a foundation for extensions to higher powers.", "AI": {"tldr": "本文提出一个统一框架，用于构造满足$A^{n} + B^{n} = C^{n} + D^{n}$（$n=2,3$）的整数解。对于$n=2$，通过平方差推导显式公式；对于$n=3$，引入包含哈代-拉马努金数1729的通用公式，并开发符号生成器无限生成整数解。", "motivation": "研究旨在为二项式展开与丢番图约束之间的结构联系提供新视角，特别是针对高次幂问题的解决方案。", "method": "对于$n=2$利用平方差法；对于$n=3$设计符号生成器，基于代数数$\\alpha, \\beta$的嵌套根式和指数，通过单变量参数$c_1$的闭式代数参数化表达解。", "result": "成功构造$n=2,3$的显式解公式，并开发首个符号递归生成器，可无限生成$A^3 + B^3 = C^3 + D^3$的整数解，虽未覆盖所有可能解，但提供结构化路径。", "conclusion": "该框架为高次幂丢番图方程提供了新方法，通过连接二项式与丢番图约束的结构，奠定了向更高次幂扩展的基础。"}}
{"id": "2506.18933", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.18933", "abs": "https://arxiv.org/abs/2506.18933", "authors": ["Sebastian Fuchs"], "title": "An Analytic Prime Indicator Based on the Fejer Kernel", "comment": "9 pages, 4 figures", "summary": "This note introduces an analytic prime indicator, constructed by smoothing a\ntrigonometric analogue of trial division. First, a function P: R -> R of class\nC1 is presented, whose zeros for x > 2 correspond precisely to the odd primes.\nIts second derivative exhibits jump discontinuities at integer squares.\nSubsequently, it is shown how this construction can be modified via an infinite\nseries to yield a globally smooth function, P_phi, of class C-inf that\npreserves this prime-zero property. As a primary application, it is\ndemonstrated how this indicator can be used to construct an analytic\napproximation for the prime-counting function pi(x) with a provably controlled\nerror.", "AI": {"tldr": "本文提出了一种解析素数指示函数，通过平滑三角模拟试除法构建，其零点对应奇数素数，并展示了如何构造全局光滑函数$P_\\phi$来保持这一性质，最终应用于素数计数函数$\\pi(x)$的解析逼近。", "motivation": "研究旨在构建一种解析方法，通过光滑函数精确标识素数，为素数分布提供新的分析工具。", "method": "首先构造$C^1$类函数$P$，其零点对应奇数素数；随后通过无穷级数修正为全局光滑的$C^\\infty$类函数$P_\\phi$，保留素数零点特性。", "result": "成功构建了$P_\\phi$函数，其零点严格匹配素数，并基于此推导出$\\pi(x)$的解析逼近公式，且误差可控。", "conclusion": "该解析素数指示器为素数理论研究提供了新途径，尤其在素数计数函数的近似计算中展现出实用价值。"}}
{"id": "2506.19052", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19052", "abs": "https://arxiv.org/abs/2506.19052", "authors": ["Shuangbao Paul Wang", "Paul Mullin"], "title": "Trustworthy Artificial Intelligence for Cyber Threat Analysis", "comment": null, "summary": "Artificial Intelligence brings innovations into the society. However, bias\nand unethical exist in many algorithms that make the applications less\ntrustworthy. Threats hunting algorithms based on machine learning have shown\ngreat advantage over classical methods. Reinforcement learning models are\ngetting more accurate for identifying not only signature-based but also\nbehavior-based threats. Quantum mechanics brings a new dimension in improving\nclassification speed with exponential advantage. In this research, we developed\na machine learning based cyber threat detection and assessment tool. It uses\ntwo stage, unsupervised and supervised learning, analyzing method on log data\nrecorded from a web server on AWS cloud. The results show the algorithm has the\nability to identify cyber threats with high confidence.", "AI": {"tldr": "本研究开发了一种基于机器学习的网络威胁检测与评估工具，结合无监督与监督学习两阶段分析AWS云服务器日志数据，能高置信度识别网络威胁。", "motivation": "人工智能虽带来创新，但算法中的偏见与伦理问题降低了应用可信度。机器学习威胁狩猎算法相比传统方法优势显著，强化学习模型能更精准识别基于签名和行为的威胁。量子力学为分类速度带来指数级提升。", "method": "采用两阶段（无监督+监督）机器学习方法，分析AWS云服务器记录的日志数据。", "result": "算法展现出高置信度识别网络威胁的能力。", "conclusion": "该研究证明了机器学习方法在网络威胁检测中的有效性，尤其通过结合量子力学可进一步提升分类速度。"}}
{"id": "2506.19075", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19075", "abs": "https://arxiv.org/abs/2506.19075", "authors": ["Dan Garber"], "title": "First-Order Sparse Convex Optimization: Better Rates with Sparse Updates", "comment": null, "summary": "In was recently established that for convex optimization problems with a\nsparse optimal solution (may it be entry-wise sparsity or matrix rank-wise\nsparsity) it is possible to have linear convergence rates which depend on an\nimproved mixed-norm condition number of the form $\\frac{\\beta_1{}s}{\\alpha_2}$,\nwhere $\\beta_1$ is the $\\ell_1$-Lipchitz continuity constant of the gradient,\n$\\alpha_2$ is the $\\ell_2$-quadratic growth constant, and $s$ is the sparsity\nof the optimal solution. However, beyond the improved convergence rate, these\nmethods are unable to leverage the sparsity of optimal solutions towards\nimproving also the runtime of each iteration, which may still be prohibitively\nhigh for high-dimensional problems. In this work, we establish that linear\nconvergence rates which depend on this improved condition number can be\nobtained using only sparse updates, which may result in overall significantly\nimproved running times. Moreover, our methods are considerably easier to\nimplement.", "AI": {"tldr": "该研究针对具有稀疏最优解的凸优化问题，提出了一种仅使用稀疏更新的方法，实现了线性收敛率，并显著降低了每次迭代的运行时间。", "motivation": "现有方法虽然能实现依赖于改进混合范数条件数$\\frac{\\beta_1{}s}{\\alpha_2}$的线性收敛率，但无法利用最优解的稀疏性降低每次迭代的运行时间，限制了其在高维问题中的应用。", "method": "提出了一种仅使用稀疏更新的优化方法，该方法不仅保持了线性收敛率，还显著降低了每次迭代的计算复杂度。", "result": "新方法在保持线性收敛率的同时，通过稀疏更新显著降低了运行时间，且实现更为简单。", "conclusion": "该研究为高维稀疏优化问题提供了一种高效且易于实现的解决方案，具有重要的理论和实践意义。"}}
{"id": "2506.19025", "categories": ["math.ST", "cs.AI", "cs.LG", "stat.ME", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.19025", "abs": "https://arxiv.org/abs/2506.19025", "authors": ["Sivaraman Balakrishnan", "Tudor Manole", "Larry Wasserman"], "title": "Statistical Inference for Optimal Transport Maps: Recent Advances and Perspectives", "comment": "36 pages, 1 figure", "summary": "In many applications of optimal transport (OT), the object of primary\ninterest is the optimal transport map. This map rearranges mass from one\nprobability distribution to another in the most efficient way possible by\nminimizing a specified cost. In this paper we review recent advances in\nestimating and developing limit theorems for the OT map, using samples from the\nunderlying distributions. We also review parallel lines of work that establish\nsimilar results for special cases and variants of the basic OT setup. We\nconclude with a discussion of key directions for future research with the goal\nof providing practitioners with reliable inferential tools.", "AI": {"tldr": "本文综述了最优传输(OT)映射的最新研究进展，包括从样本中估计OT映射的方法及其极限定理，并讨论了未来研究方向。", "motivation": "在最优传输的众多应用中，核心关注点是最优传输映射，它通过最小化特定成本实现概率分布间的最优质量重排。", "method": "回顾了基于样本估计OT映射的方法，并建立了基础OT框架下及特殊变体的极限定理。", "result": "总结了OT映射估计的理论成果，包括标准设定及变体情况下的类似结论。", "conclusion": "提出未来研究的关键方向，旨在为实践者提供可靠的统计推断工具。"}}
{"id": "2506.18920", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.NE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2506.18920", "abs": "https://arxiv.org/abs/2506.18920", "authors": ["Michael Williams"], "title": "Signal Use and Emergent Cooperation", "comment": "167 pages, 19 figures, PhD dissertation, UCLA, 2006", "summary": "In this work, we investigate how autonomous agents, organized into tribes,\nlearn to use communication signals to coordinate their activities and enhance\ntheir collective efficiency. Using the NEC-DAC (Neurally Encoded Culture -\nDistributed Autonomous Communicators) system, where each agent is equipped with\nits own neural network for decision-making, we demonstrate how these agents\ndevelop a shared behavioral system -- akin to a culture -- through learning and\nsignalling. Our research focuses on the self-organization of culture within\nthese tribes of agents and how varying communication strategies impact their\nfitness and cooperation. By analyzing different social structures, such as\nauthority hierarchies, we show that the culture of cooperation significantly\ninfluences the tribe's performance. Furthermore, we explore how signals not\nonly facilitate the emergence of culture but also enable its transmission\nacross generations of agents. Additionally, we examine the benefits of\ncoordinating behavior and signaling within individual agents' neural networks.", "AI": {"tldr": "本研究探讨了自治代理如何通过通信信号协调活动并提升集体效率，使用NEC-DAC系统展示了代理如何通过学习与信号发展出类似文化的共享行为系统。", "motivation": "研究自治代理如何通过通信信号自我组织文化，并探索不同通信策略对代理群体适应性与合作的影响。", "method": "采用NEC-DAC系统，每个代理配备独立神经网络进行决策，分析不同社会结构（如权威层级）下文化的自组织过程。", "result": "合作文化显著影响代理群体的表现，信号不仅促进文化涌现，还支持文化在代理世代间传递。", "conclusion": "协调行为与信号在代理神经网络中的协同作用，为自治代理群体的文化演化与高效合作提供了新见解。"}}
{"id": "2506.19147", "categories": ["math.LO", "03C45"], "pdf": "https://arxiv.org/pdf/2506.19147", "abs": "https://arxiv.org/abs/2506.19147", "authors": ["James E. Hanson"], "title": "Indiscernible extraction at small large cardinals from a higher-arity stability notion", "comment": "16 pages, 2 figures", "summary": "We introduce a higher-arity stability notion defined in terms of\n$k$-splitting, a higher-arity generalization of splitting. We show that\ntheories with bounded $k$-splitting have improved indiscernible extraction at\n$k$-ineffable cardinals, and we give a non-trivial example of a theory with\nbounded $k$-splitting but unbounded $(k-1)$-splitting for each odd $k > 1$. We\nalso show that bounded $k$-splitting implies $\\mathrm{NFOP}_k$, a higher arity\nstability notion introduced by Terry and Wolf. We then use our indiscernible\nextraction result together with a construction of Kaplan and Shelah to give a\nstrong counterexample to the converse: an $\\mathrm{NIP}$ theory with unbounded\n$k$-splitting for every $k$. Finally, as a thematically related but technically\nindependent result, we show that treelessness implies $\\mathrm{NFOP}_2$,\nsharpening a result of Kaplan, Ramsey, and Simon.", "AI": {"tldr": "该论文引入基于$k$-分裂的高阶稳定性概念，证明了有界$k$-分裂理论在$k$-不可言说基数上具有更好的不可辨提取性，并构建了强反例表明NIP理论可能对所有$k$无界$k$-分裂。", "motivation": "研究高阶稳定性概念及其在模型论中的应用，特别是探索$k$-分裂与不可辨序列、NIP理论之间的深层关系。", "method": "1. 定义$k$-分裂及其有界性 2. 结合Kaplan-Shelah构造法 3. 使用基数特性分析与反例构建", "result": "1. 有界$k$-分裂理论提升$k$-不可言说基数上的不可辨提取 2. 发现奇数$k>1$时存在有界$k$-分裂但无界$(k-1)$-分裂的理论 3. 证明有界$k$-分裂蕴含$\\mathrm{NFOP}_k$但逆命题不成立 4. 无树性可强化为$\\mathrm{NFOP}_2$", "conclusion": "高阶分裂概念为稳定性理论提供新视角，其与NIP的复杂关系揭示了模型论中尚未探索的深层结构特性，无树性结果则完善了现有理论框架。"}}
{"id": "2506.19050", "categories": ["math.CO", "cs.FL", "68R15"], "pdf": "https://arxiv.org/pdf/2506.19050", "abs": "https://arxiv.org/abs/2506.19050", "authors": ["Narad Rampersad", "James Currie"], "title": "Low complexity binary words avoiding $(5/2)^+$-powers", "comment": "7 pages", "summary": "Rote words are infinite words that contain $2n$ factors of length $n$ for\nevery $n \\geq 1$. Shallit and Shur, as well as Ollinger and Shallit, showed\nthat there are Rote words that avoid $(5/2)^+$-powers and that this is best\npossible. In this note we give a structure theorem for the Rote words that\navoid $(5/2)^+$-powers, confirming a conjecture of Ollinger and Shallit.", "AI": {"tldr": "本文证明了避免$(5/2)^+$-幂的Rote词的结构定理，证实了Ollinger和Shallit的猜想。", "motivation": "研究Rote词的性质及其避免特定幂的能力，特别是在Shallit、Shur、Ollinger和Shallit之前的工作基础上，进一步探索其结构。", "method": "通过结构分析的方法，对避免$(5/2)^+$-幂的Rote词进行深入研究，验证了相关猜想。", "result": "证明了存在避免$(5/2)^+$-幂的Rote词，并且给出了这类词的结构定理，证实了Ollinger和Shallit的猜想。", "conclusion": "该研究不仅确认了避免$(5/2)^+$-幂的Rote词的存在性，还提供了其结构定理，为无限词的研究提供了新的理论支持。"}}
{"id": "2506.19284", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.19284", "abs": "https://arxiv.org/abs/2506.19284", "authors": ["Mohammad Hadi Shekarriz", "Dhananjay Thiruvady", "Asef Nazari", "Wilfried Imrich"], "title": "Local Search Improvements for Soft Happy Colouring", "comment": "33 pages, 17 figures, 2 tables", "summary": "For $0\\leq \\rho\\leq 1$ and a coloured graph $G$, a vertex $v$ is $\\rho$-happy\nif at least $\\rho \\deg(v)$ of its neighbours have the same colour as $v$. Soft\nhappy colouring of a partially coloured graph $G$ is the problem of finding a\nvertex colouring $\\sigma$ that preserves the precolouring and has the maximum\nnumber of $\\rho$-happy vertices. It is already known that this problem is\nNP-hard and directly relates to the community structure of the graphs; under a\ncertain condition on the proportion of happiness $\\rho$ and for graphs with\ncommunity structures, the induced colouring by communities can make all the\nvertices $\\rho$-happy. We show that when $0\\leq \\rho_1<\\rho_2\\leq 1$, a\ncomplete $\\rho_2$-happy colouring has a higher accuracy of community detection\nthan a complete $\\rho_1$-happy colouring. Moreover, when $\\rho$ is greater than\na threshold, it is unlikely for an algorithm to find a complete $\\rho$-happy\ncolouring with colour classes of almost equal sizes. Three local search\nalgorithms for soft happy colouring are proposed, and their performances are\ncompared with one another and other known algorithms. Among them, the\nlinear-time local search is shown to be not only very fast, but also a reliable\nalgorithm that can dramatically improve the number of $\\rho$-happy vertices.", "AI": {"tldr": "本文研究了软快乐着色问题，证明了高$\\rho$值的完全快乐着色能提高社区检测精度，并提出三种局部搜索算法，其中线性时间算法表现最佳。", "motivation": "软快乐着色问题与图的社区结构密切相关，研究不同$\\rho$值下的着色效果有助于理解社区检测的准确性。", "method": "通过理论分析$\\rho$阈值对完全快乐着色的影响，并提出三种局部搜索算法（包括线性时间算法）进行比较。", "result": "当$\\rho_2>\\rho_1$时，完全$\\rho_2$-快乐着色比$\\rho_1$-快乐着色具有更高的社区检测精度；线性时间局部搜索算法能显著增加$\\rho$-快乐顶点数量。", "conclusion": "高$\\rho$值快乐着色能有效提升社区检测性能，线性时间局部搜索算法是实现高效软快乐着色的可靠方法。"}}
{"id": "2506.19060", "categories": ["math.NT", "11J20"], "pdf": "https://arxiv.org/pdf/2506.19060", "abs": "https://arxiv.org/abs/2506.19060", "authors": ["Lior Fishman", "David Lambert", "Keith Merrill", "David Simmons"], "title": "Diophantine approximation on abelian varieties; a conjecture of M. Waldschmidt", "comment": "11 pages", "summary": "Following the work of Waldschmidt, we investigate problems in Diophantine\napproximation on abelian varieties. First we show that a conjecture of\nWaldschmidt for a given simple abelian variety is equivalent to a well-known\nDiophantine condition holding for a certain matrix related to that variety. We\nthen posit a related but weaker conjecture, and establish the upper bound\ndirection of that conjecture in full generality. For rank 1 elliptic curves\ndefined over a number field $K \\subset \\mathbb{R}$, we then obtain a weak-type\nDirichlet theorem in this setting, establish the optimality of this statement,\nand prove our conjecture in this case.", "AI": {"tldr": "本文研究了阿贝尔簇上的Diophantine逼近问题，证明了Waldschmidt猜想与特定矩阵的Diophantine条件等价，提出了一个较弱猜想并证明了其上界方向，对于数域$K \\subset \\mathbb{R}$上的秩1椭圆曲线，得到了弱型Dirichlet定理并证明了猜想的成立。", "motivation": "研究阿贝尔簇上的Diophantine逼近问题，探索Waldschmidt猜想及其相关矩阵条件的等价性，并提出一个较弱猜想以进一步理解这一领域的数学结构。", "method": "通过分析简单阿贝尔簇上的Diophantine条件，建立猜想与矩阵条件的等价性；提出较弱猜想并证明其上界方向；针对数域$K \\subset \\mathbb{R}$上的秩1椭圆曲线，推导弱型Dirichlet定理并验证猜想。", "result": "证明了Waldschmidt猜想与特定矩阵的Diophantine条件等价；提出了较弱猜想并确立了其上界方向；对于数域$K \\subset \\mathbb{R}$上的秩1椭圆曲线，得到了弱型Dirichlet定理并证明了猜想的最优性。", "conclusion": "本文在阿贝尔簇的Diophantine逼近问题上取得了重要进展，不仅验证了Waldschmidt猜想的等价条件，还通过较弱猜想和具体椭圆曲线的分析，深化了对这一领域的理解。"}}
{"id": "2506.19054", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19054", "abs": "https://arxiv.org/abs/2506.19054", "authors": ["Mintong Kang", "Zhaorun Chen", "Chejian Xu", "Jiawei Zhang", "Chengquan Guo", "Minzhou Pan", "Ivan Revilla", "Yu Sun", "Bo Li"], "title": "PolyGuard: Massive Multi-Domain Safety Policy-Grounded Guardrail Dataset", "comment": null, "summary": "As LLMs become widespread across diverse applications, concerns about the\nsecurity and safety of LLM interactions have intensified. Numerous guardrail\nmodels and benchmarks have been developed to ensure LLM content safety.\nHowever, existing guardrail benchmarks are often built upon ad hoc risk\ntaxonomies that lack a principled grounding in standardized safety policies,\nlimiting their alignment with real-world operational requirements. Moreover,\nthey tend to overlook domain-specific risks, while the same risk category can\ncarry different implications across different domains. To bridge these gaps, we\nintroduce PolyGuard, the first massive multi-domain safety policy-grounded\nguardrail dataset. PolyGuard offers: (1) broad domain coverage across eight\nsafety-critical domains, such as finance, law, and codeGen; (2) policy-grounded\nrisk construction based on authentic, domain-specific safety guidelines; (3)\ndiverse interaction formats, encompassing declarative statements, questions,\ninstructions, and multi-turn conversations; (4) advanced benign data curation\nvia detoxification prompting to challenge over-refusal behaviors; and (5)\n\\textbf{attack-enhanced instances} that simulate adversarial inputs designed to\nbypass guardrails. Based on PolyGuard, we benchmark 19 advanced guardrail\nmodels and uncover a series of findings, such as: (1) All models achieve varied\nF1 scores, with many demonstrating high variance across risk categories,\nhighlighting their limited domain coverage and insufficient handling of\ndomain-specific safety concerns; (2) As models evolve, their coverage of safety\nrisks broadens, but performance on common risk categories may decrease; (3) All\nmodels remain vulnerable to optimized adversarial attacks. We believe that\n\\dataset and the unique insights derived from our evaluations will advance the\ndevelopment of policy-aligned and resilient guardrail systems.", "AI": {"tldr": "本文介绍了PolyGuard，首个基于多领域安全政策的大规模护栏数据集，用于评估和改进大语言模型(LLM)的安全防护能力。该数据集覆盖8个关键领域，包含政策依据的风险构建、多样化交互格式及对抗性攻击样本，并通过对19个先进护栏模型的基准测试揭示了现有模型的局限性。", "motivation": "随着LLM广泛应用，其交互安全引发担忧。现有护栏基准缺乏标准化政策依据且忽视领域特异性风险，难以满足实际需求。PolyGuard旨在填补这一空白，提供政策对齐的综合性评估框架。", "method": "构建PolyGuard数据集包含：(1)覆盖金融、法律等8个安全关键领域；(2)基于真实领域安全指南的风险分类；(3)声明、问答等多样化交互形式；(4)通过去毒提示生成良性数据；(5)设计对抗性攻击样本。随后对19个护栏模型进行多维度基准测试。", "result": "实验发现：(1)所有模型F1分数差异显著，对领域特异性风险处理不足；(2)模型迭代会扩大风险覆盖范围，但可能降低常见风险处理性能；(3)所有模型均对优化后的对抗攻击表现脆弱。", "conclusion": "PolyGuard作为首个政策依据的多领域护栏数据集，揭示了现有模型的局限性，其评估结果为开发更具韧性和政策对齐的护栏系统提供了重要参考。"}}
{"id": "2506.19129", "categories": ["math.OC", "math.AP", "math.PR", "35R35, 49N60, 60G40, 91A05, 91A15, 93E20"], "pdf": "https://arxiv.org/pdf/2506.19129", "abs": "https://arxiv.org/abs/2506.19129", "authors": ["Andrea Bovo", "Alessandro Milazzo"], "title": "Global regularity of the value function in a stopper vs. singular-controller game", "comment": "25 pages", "summary": "We study a class of zero-sum stochastic games between a stopper and a\nsingular-controller, previously considered in [Bovo and De Angelis (2025)]. The\nunderlying singularly-controlled dynamics takes values in\n$\\mathcal{O}\\subseteq\\mathbb{R}$. The problem is set on a finite time-horizon\nand is connected to a parabolic variational inequality of min-max type with\nspatial-derivative and obstacle constraints.\n  We show that the value function of the problem is of class $C^1$ in the whole\ndomain $[0,T)\\times\\mathcal{O}$ and that the second-order spatial derivative\nand the second-order mixed derivative are continuous everywhere except for a\n(potential) jump across a non-decreasing curve (the stopping boundary of the\ngame). The latter discontinuity is a natural consequence of the partial\ndifferential equation associated to the problem. Beyond its intrinsic\nanalytical value, such a regularity for the value function is a stepping stone\nfor further exploring the structure and properties of the free-boundaries of\nthe stochastic game, which in turn determine the optimal strategies of the\nplayers.", "AI": {"tldr": "研究一类零和随机博弈，涉及停止者与奇异控制者，分析其价值函数的正则性及自由边界结构。", "motivation": "探索奇异控制动力学下的零和随机博弈，旨在理解价值函数的正则性及其对玩家最优策略的影响。", "method": "基于有限时间范围内的抛物型变分不等式，结合空间导数和障碍约束，分析价值函数的连续性。", "result": "证明价值函数在$[0,T)\\times\\mathcal{O}$上属于$C^1$类，且二阶空间导数和混合导数在除停止边界外的区域连续。", "conclusion": "价值函数的正则性为研究随机博弈的自由边界及玩家最优策略提供了重要基础。"}}
{"id": "2506.19559", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.19559", "abs": "https://arxiv.org/abs/2506.19559", "authors": ["Arthur Stéphanovitch"], "title": "Regularity of the score function in generative models", "comment": null, "summary": "We study the regularity of the score function in score-based generative\nmodels and show that it naturally adapts to the smoothness of the data\ndistribution. Under minimal assumptions, we establish Lipschitz estimates that\ndirectly support convergence and stability analyses in both diffusion and\nODE-based generative models. In addition, we derive higher-order regularity\nbounds, which simplify existing arguments for optimally approximating the score\nfunction using neural networks.", "AI": {"tldr": "本文研究了基于分数的生成模型中分数函数的正则性，证明其能自然适应数据分布的平滑性，并建立了支持扩散和ODE生成模型收敛性与稳定性的Lipschitz估计。", "motivation": "探索分数函数在生成模型中的正则性特性，以支持模型的理论分析和实际应用。", "method": "在最小假设下建立Lipschitz估计，并推导高阶正则性边界，简化神经网络近似分数函数的最优论证。", "result": "分数函数能自适应数据分布的平滑性，Lipschitz估计直接支持扩散和ODE生成模型的收敛与稳定性分析。", "conclusion": "研究为基于分数的生成模型提供了理论支持，简化了分数函数近似的最优论证，推动了生成模型的发展。"}}
{"id": "2506.18928", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18928", "abs": "https://arxiv.org/abs/2506.18928", "authors": ["Lingyu Yang"], "title": "Do LLMs Know When to Flip a Coin? Strategic Randomization through Reasoning and Experience", "comment": null, "summary": "Strategic randomization is a key principle in game theory, yet it remains\nunderexplored in large language models (LLMs). Prior work often conflates the\ncognitive decision to randomize with the mechanical generation of randomness,\nleading to incomplete evaluations. To address this, we propose a novel zero-sum\ngame inspired by the Tian Ji Horse Race, where the Nash equilibrium corresponds\nto a maximal entropy strategy. The game's complexity masks this property from\nuntrained humans and underdeveloped LLMs. We evaluate five LLMs across prompt\nstyles -- framed, neutral, and hinted -- using competitive multi-tournament\ngameplay with system-provided random choices, isolating the decision to\nrandomize. Results show that weaker models remain deterministic regardless of\nprompts, while stronger models exhibit increased randomization under explicit\nhints. When facing weaker models, strong LLMs adopt deterministic strategies to\nexploit biases, but converge toward equilibrium play when facing peers. Through\nwin/loss outcomes and Bayes factor analysis, we demonstrate meaningful\nvariation in LLMs' strategic reasoning capabilities, highlighting opportunities\nfor improvement in abstract reasoning and adaptive learning. We make our\nimplementation publicly available at\nhttps://github.com/ocelopus/llm-when-to-throw-coin to ensure full\nreproducibility.", "AI": {"tldr": "本文探讨了大语言模型（LLMs）在策略随机化方面的表现，通过设计一个受田忌赛马启发的零和游戏，评估了不同LLMs在多种提示风格下的随机化决策能力，揭示了模型间战略推理能力的差异。", "motivation": "策略随机化是博弈论的核心原则，但在大语言模型中的研究不足。先前工作常将随机化的认知决策与随机性生成混为一谈，导致评估不完整。本文旨在填补这一空白。", "method": "研究设计了一个零和游戏，其纳什均衡对应最大熵策略。通过三种提示风格（框架化、中性、暗示性）评估五个LLMs，使用系统提供的随机选择来隔离随机化决策，并进行竞争性多轮比赛。", "result": "结果显示，较弱模型无论提示如何均保持确定性，而较强模型在明确提示下增加随机化。面对弱模型时，强LLMs采用确定性策略利用偏差，但在与同类对抗时趋向均衡策略。胜负结果和贝叶斯因子分析揭示了LLMs战略推理能力的显著差异。", "conclusion": "研究揭示了LLMs在抽象推理和自适应学习方面的改进空间，并通过公开实现确保可重复性。结果强调了不同模型在战略随机化能力上的分化，为未来研究提供了方向。"}}
{"id": "2506.19489", "categories": ["math.LO", "16W99, 12H05, 03C60, 03C45"], "pdf": "https://arxiv.org/pdf/2506.19489", "abs": "https://arxiv.org/abs/2506.19489", "authors": ["Jan Dobrowolski", "Omar Leon Sanchez"], "title": "Fields with Lie-commuting and iterative operators", "comment": null, "summary": "We introduce a general framework for studying fields equipped with operators,\ngiven as co-ordinate functions of homomorphisms into a local algebra\n$\\mathcal{D}$, satisfying various compatibility conditions that we denote by\n$\\Gamma$ and call such structures $\\mathcal{D}^{\\Gamma}$-fields. These include\nLie-commutativity of derivations and $\\mathfrak g$-iterativity of (truncated)\nHasse-Schmidt derivations. Our main result is about the existence of principal\nrealisations of $\\mathcal{D}^{\\Gamma}$-kernels. As an application, we prove\ncompanionability of the theory of $\\mathcal{D}^{\\Gamma}$-fields and denote the\ncompanion by $\\mathcal{D}^{\\Gamma}$-CF. In characteristic zero, we prove that\n$\\mathcal{D}^{\\Gamma}$-CF is a stable theory that satisfies the CBP and\nZilber's dichotomy for finite-dimensional types. We also prove that there is a\nuniform companion for model-complete theories of large\n$\\mathcal{D}^{\\Gamma}$-fields, which leads to the notion of\n$\\mathcal{D}^{\\Gamma}$-large fields and we further use this to show that PAC\nsubstructures of $\\mathcal{D}^{\\Gamma}$-DCF are elementary.", "AI": {"tldr": "本文提出了一种研究带有算子的域的一般框架$\\mathcal{D}^{\\Gamma}$-fields，证明了其核的主实现存在性，并建立了$\\mathcal{D}^{\\Gamma}$-CF伴随理论。在特征零情况下，该理论具有稳定性并满足CBP与Zilber二分性。此外，还提出了$\\mathcal{D}^{\\Gamma}$-大域概念，并证明PAC子结构在$\\mathcal{D}^{\\Gamma}$-DCF中是初等的。", "motivation": "旨在构建一个统一框架来研究具有特定兼容性条件（如导子的Lie交换性）的算子域结构，并探索其模型论性质。", "method": "通过定义$\\mathcal{D}^{\\Gamma}$-域及核的主实现，采用伴随理论方法，在特征零与正特征场景下分别分析理论性质，并引入$\\mathcal{D}^{\\Gamma}$-大域概念。", "result": "1) 证明了$\\mathcal{D}^{\\Gamma}$-核主实现的存在性；2) 建立了伴随理论$\\mathcal{D}^{\\Gamma}$-CF；3) 特征零下该理论稳定且满足CBP与Zilber二分性；4) 提出$\\mathcal{D}^{\\Gamma}$-大域并证明PAC子结构的初等性。", "conclusion": "该框架为算子域研究提供了普适工具，$\\mathcal{D}^{\\Gamma}$-CF的稳定性与模型论性质为后续研究奠定基础，$\\mathcal{D}^{\\Gamma}$-大域概念扩展了应用场景。"}}
{"id": "2506.19061", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.19061", "abs": "https://arxiv.org/abs/2506.19061", "authors": ["Sean English", "Sam Spiro"], "title": "Rational Exponents for General Graphs", "comment": null, "summary": "A rational number $r$ is a \\textbf{realizable exponent} for a graph $H$ if\nthere exists a finite family of graphs $\\mathcal{F}$ such that\n$\\mathrm{ex}(n,H,\\mathcal{F})=\\Theta(n^r)$, where\n$\\mathrm{ex}(n,H,\\mathcal{F})$ denotes the maximum number of copies of $H$ that\nan $n$-vertex $\\mathcal{F}$-free graph can have. Results for realizable\nexponents are currently known only when $H$ is either a star or a clique, with\nthe full resolution of the $H=K_2$ case being a major breakthrough of Bukh and\nConlon.\n  In this paper, we establish the first set of results for realizable exponents\nwhich hold for arbitrary graphs $H$ by showing that for any graph $H$ with\nmaximum degree $\\Delta \\ge 1$, every rational in the interval\n$\\left[v(H)-\\frac{e(H)}{2\\Delta^2},\\ v(H)\\right]$ is realizable for $H$. We\nalso prove a ``stability'' result for generalized Tur\\'an numbers of trees\nwhich implies that if $T\\ne K_2$ is a tree with $\\ell$ leaves, then $T$ has no\nrealizable exponents in $[0,\\ell]\\setminus \\mathbb{Z}$. Our proof of this\nlatter result uses a new variant of the classical Helly theorem for trees,\nwhich may be of independent interest.", "AI": {"tldr": "该论文首次针对任意图$H$证明了可实现指数的存在性，并给出了具体区间，同时对树的广义Turán数稳定性进行了研究。", "motivation": "目前关于可实现指数的研究仅限于星图或团图，Bukh和Conlon关于$H=K_2$的突破性工作激发了更一般的图$H$的可实现指数研究需求。", "method": "通过分析图$H$的最大度$\\Delta$，构建特定图族$\\mathcal{F}$，并利用改进的Helly定理对树结构进行稳定性证明。", "result": "证明了对任意最大度$\\Delta \\ge 1$的图$H$，区间$\\left[v(H)-\\frac{e(H)}{2\\Delta^2},\\ v(H)\\right]$内的所有有理数都是可实现指数；且非$K_2$的树在$[0,\\ell]\\setminus \\mathbb{Z}$区间无可实现指数。", "conclusion": "该研究将可实现指数理论推广到一般图类，提出的树结构稳定性证明方法及改进的Helly定理具有独立的理论价值。"}}
{"id": "2506.19529", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.19529", "abs": "https://arxiv.org/abs/2506.19529", "authors": ["Hande Tuncel Golpek", "Zeliha Kartal Yildiz", "Aysun Aytac"], "title": "Paired Disjunctive Domination Number of Middle Graphs", "comment": "12 pages, 0 figures", "summary": "The concept of domination in graphs plays a central role in understanding\nstructural properties and applications in network theory. In this study, we\nfocus on the paired disjunctive domination number in the context of middle\ngraphs, a transformation that captures both adjacency and incidence relations\nof the original graph. We begin by investigating this parameter for middle\ngraphs of several special graph classes, including path graphs, cycle graphs,\nwheel graphs, complete graphs, complete bipartite graphs, star graphs,\nfriendship graphs, and double star graphs. We then present general results by\nestablishing lower and upper bounds for the paired disjunctive domination\nnumber in middle graphs of arbitrary graphs, with particular emphasis on trees.\nAdditionally, we determine the exact value of the parameter for middle graphs\nobtained through the join operation. These findings contribute to the broader\nunderstanding of domination-type parameters in transformed graph structures and\noffer new insights into their combinatorial behavior.", "AI": {"tldr": "本文研究了中间图中成对析取支配数的性质，针对多种特殊图类（如路径图、轮图等）进行了分析，并给出了任意图中间图中该参数的下界和上界，特别关注了树结构。此外，还确定了通过连接操作得到的中间图的精确参数值。", "motivation": "图支配概念在网络理论中具有核心地位，研究中间图的成对析取支配数有助于理解变换图结构的支配性质及其组合行为。", "method": "首先分析路径图、轮图等特殊图类中间图的成对析取支配数，随后建立任意图中间图中该参数的上下界，特别针对树结构进行深入研究，并探讨连接操作生成的中间图的精确值。", "result": "确定了多种特殊图类中间图的成对析取支配数，给出了任意图中间图中该参数的通用界限，并推导出连接操作生成中间图的精确参数值。", "conclusion": "研究成果拓展了对变换图结构中支配类参数的理解，为相关组合行为提供了新的理论依据，尤其在树结构和连接操作生成的中间图方面具有显著贡献。"}}
{"id": "2506.19319", "categories": ["math.NT", "11R42"], "pdf": "https://arxiv.org/pdf/2506.19319", "abs": "https://arxiv.org/abs/2506.19319", "authors": ["Sourabhashis Das", "Swati Gaba", "Ethan Simpson Lee", "Aditi Savalia", "Peng-Jie Wong"], "title": "New zero-free regions for Dedekind zeta-functions at small and large ordinates", "comment": null, "summary": "Given a number field $L\\neq \\mathbb{Q}$, we obtain new and explicit zero-free\nregions for Dedekind zeta-functions of $L$, which refine the previous works of\nAhn--Kwon, Kadiri, and Lee. In particular, for low-lying zeros, we extend\nKadiri's result to all number fields while improving the main constant.", "AI": {"tldr": "本文为任意数域$L\\neq \\mathbb{Q}$的Dedekind zeta函数建立了新的显式无零点区域，改进了Ahn--Kwon、Kadiri和Lee的先前结果，尤其对低零点情形推广了Kadiri的结论并优化了主常数。", "motivation": "研究数域$L\\neq \\mathbb{Q}$的Dedekind zeta函数的零点分布，旨在改进现有无零点区域的精度和适用范围，特别是针对低零点情形。", "method": "通过改进分析方法，扩展并优化了Kadiri等人的技术，适用于所有数域，并显著提升了关键常数。", "result": "获得了比前人更优的显式无零点区域，将Kadiri的结果推广至所有数域，且主常数得到改进。", "conclusion": "该研究显著推进了Dedekind zeta函数零点分布的理论，为所有数域提供了更精确的无零点区域，尤其在低零点方面取得突破。"}}
{"id": "2506.19109", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19109", "abs": "https://arxiv.org/abs/2506.19109", "authors": ["Valerii Gakh", "Hayretdin Bahsi"], "title": "Enhancing Security in LLM Applications: A Performance Evaluation of Early Detection Systems", "comment": "18 pages, 8 tables, 7 figures", "summary": "Prompt injection threatens novel applications that emerge from adapting LLMs\nfor various user tasks. The newly developed LLM-based software applications\nbecome more ubiquitous and diverse. However, the threat of prompt injection\nattacks undermines the security of these systems as the mitigation and defenses\nagainst them, proposed so far, are insufficient. We investigated the\ncapabilities of early prompt injection detection systems, focusing specifically\non the detection performance of techniques implemented in various open-source\nsolutions. These solutions are supposed to detect certain types of prompt\ninjection attacks, including the prompt leak. In prompt leakage attacks, an\nattacker maliciously manipulates the LLM into outputting its system\ninstructions, violating the system's confidentiality. Our study presents\nanalyzes of distinct prompt leakage detection techniques, and a comparative\nanalysis of several detection solutions, which implement those techniques. We\nidentify the strengths and weaknesses of these techniques and elaborate on\ntheir optimal configuration and usage in high-stake deployments. In one of the\nfirst studies on existing prompt leak detection solutions, we compared the\nperformances of LLM Guard, Vigil, and Rebuff. We concluded that the\nimplementations of canary word checks in Vigil and Rebuff were not effective at\ndetecting prompt leak attacks, and we proposed improvements for them. We also\nfound an evasion weakness in Rebuff's secondary model-based technique and\nproposed a mitigation. Then, the result of the comparison of LLM Guard, Vigil,\nand Rebuff at their peak performance revealed that Vigil is optimal for cases\nwhen minimal false positive rate is required, and Rebuff is the most optimal\nfor average needs.", "AI": {"tldr": "论文研究了针对LLM的提示注入攻击，特别是提示泄露攻击的检测技术，比较了LLM Guard、Vigil和Rebuff三种开源解决方案的性能，并提出了改进建议。", "motivation": "随着基于LLM的软件应用日益普及和多样化，提示注入攻击威胁其安全性，现有防御措施不足，需研究有效的检测技术。", "method": "研究分析了多种提示泄露检测技术，并对LLM Guard、Vigil和Rebuff三种开源解决方案进行了性能比较，评估其检测效果和配置优化。", "result": "发现Vigil和Rebuff中的金丝雀词检查效果不佳，Rebuff的基于次级模型的技术存在规避漏洞；Vigil在最低误报率要求下最优，Rebuff适合一般需求。", "conclusion": "研究揭示了现有提示泄露检测技术的优缺点，提出了改进方案，并推荐了不同场景下的最优解决方案。"}}
{"id": "2506.19155", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.19155", "abs": "https://arxiv.org/abs/2506.19155", "authors": ["Jasone Ramírez-Ayerbe", "Emma Frejinger"], "title": "Relative Explanations for Contextual Problems with Endogenous Uncertainty: An Application to Competitive Facility Location", "comment": null, "summary": "In this paper, we consider contextual stochastic optimization problems\nsubject to endogenous uncertainty, where the decisions affect the underlying\ndistributions. To implement such decisions in practice, it is crucial to ensure\nthat their outcomes are interpretable and trustworthy. To this end, we compute\nrelative counterfactual explanations, providing practitioners with concrete\nchanges in the contextual covariates required for a solution to satisfy\nspecific constraints. Whereas relative explanations have been introduced in\nprior literature, to the best of our knowledge, this is the first work focused\non problems with binary decision variables and subject to endogenous\nuncertainty. We propose a methodology that uses Wasserstein distance as\nregularization and to compute a lower bound. It leads to a drastic reduction in\ncomputation times, compared to the unregularized counterpart. We illustrate the\nmethod using a choice-based competitive facility location problem, and present\nnumerical experiments that demonstrate its ability to efficiently compute\nsparse and interpretable explanations.", "AI": {"tldr": "本文提出了一种针对具有内生不确定性的上下文随机优化问题的解释方法，特别关注二元决策变量问题。通过引入Wasserstein距离作为正则化项，显著提升了计算效率，并在竞争性设施选址问题中验证了方法的有效性。", "motivation": "在实践应用中，决策结果需要具备可解释性和可信度。针对具有内生不确定性的优化问题（决策会影响底层概率分布），现有方法缺乏对二元决策变量的专门处理。本文旨在填补这一空白。", "method": "采用Wasserstein距离作为正则化项并计算下界，相比未正则化方法大幅减少计算时间。提出相对反事实解释框架，为从业者提供满足特定约束所需的上下文协变量具体变化方案。", "result": "数值实验表明，该方法能高效计算稀疏且可解释的反事实解释。在竞争性设施选址案例中，计算时间显著优于未正则化方法，同时保持解释的直观性。", "conclusion": "本研究首次针对二元决策变量和内生不确定性问题提出了可解释的优化解决方案。Wasserstein距离的正则化应用为类似问题提供了计算效率提升的新思路，其解释框架具有实际应用价值。"}}
{"id": "2506.19587", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.19587", "abs": "https://arxiv.org/abs/2506.19587", "authors": ["Arthur Stéphanovitch"], "title": "Generative model for optimal density estimation on unknown manifold", "comment": null, "summary": "We propose a generative model that achieves minimax-optimal convergence rates\nfor estimating probability distributions supported on unknown low-dimensional\nmanifolds. Building on Fefferman's solution to the geometric Whitney problem,\nour estimator is itself supported on a submanifold that matches the regularity\nof the data's support. This geometric adaptation enables the estimator to be\nsimultaneously minimax-optimal for all \\( \\gamma \\)-H\\\"older Integral\nProbability Metrics (IPMs) with \\( \\gamma \\geq 1 \\). We validate our approach\nthrough experiments on synthetic and real datasets, demonstrating competitive\nor superior performance compared to Wasserstein GAN and score-based generative\nmodels.", "AI": {"tldr": "提出了一种在未知低维流形上估计概率分布的生成模型，该模型通过几何适应实现极小极大最优收敛率，并在实验中优于Wasserstein GAN和基于分数的生成模型。", "motivation": "现有的概率分布估计方法在低维流形数据上难以达到最优收敛率，需要一种能适应数据几何结构的生成模型。", "method": "基于Fefferman对几何Whitney问题的解决方案，构建了一个与数据支撑流形正则性匹配的子流形上的估计器，适用于所有$\\gamma \\geq 1$的H\\\"older积分概率度量。", "result": "实验表明，该模型在合成和真实数据集上表现优异，性能优于或与Wasserstein GAN及基于分数的生成模型相当。", "conclusion": "通过几何适应设计的生成模型能够实现极小极大最优收敛率，为低维流形数据分布估计提供了有效工具。"}}
{"id": "2506.18957", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.18957", "abs": "https://arxiv.org/abs/2506.18957", "authors": ["Sheraz Khan", "Subha Madhavan", "Kannan Natarajan"], "title": "A Comment On \"The Illusion of Thinking\": Reframing the Reasoning Cliff as an Agentic Gap", "comment": "10 pages, 2 figures, Comment on \"The Illusion of Thinking:\n  Understanding the Strengths and Limitations of Reasoning Models via the Lens\n  of Problem Complexity\" (arXiv:2506.06941v1)", "summary": "The recent work by Shojaee et al. (2025), titled The Illusion of Thinking:\nUnderstanding the Strengths and Limitations of Reasoning Models via the Lens of\nProblem Complexity, presents a compelling empirical finding, a reasoning cliff,\nwhere the performance of Large Reasoning Models (LRMs) collapses beyond a\nspecific complexity threshold, which the authors posit as an intrinsic scaling\nlimitation of Chain-of-Thought (CoT) reasoning. This commentary, while\nacknowledging the study's methodological rigor, contends that this conclusion\nis confounded by experimental artifacts. We argue that the observed failure is\nnot evidence of a fundamental cognitive boundary, but rather a predictable\noutcome of system-level constraints in the static, text-only evaluation\nparadigm, including tool use restrictions, context window recall issues, the\nabsence of crucial cognitive baselines, inadequate statistical reporting, and\noutput generation limits. We reframe this performance collapse through the lens\nof an agentic gap, asserting that the models are not failing at reasoning, but\nat execution within a profoundly restrictive interface. We empirically\nsubstantiate this critique by demonstrating a striking reversal. A model,\ninitially declaring a puzzle impossible when confined to text-only generation,\nnow employs agentic tools to not only solve it but also master variations of\ncomplexity far beyond the reasoning cliff it previously failed to surmount.\nAdditionally, our empirical analysis of tool-enabled models like o4-mini and\nGPT-4o reveals a hierarchy of agentic reasoning, from simple procedural\nexecution to complex meta-cognitive self-correction, which has significant\nimplications for how we define and measure machine intelligence. The illusion\nof thinking attributed to LRMs is less a reasoning deficit and more a\nconsequence of an otherwise capable mind lacking the tools for action.", "AI": {"tldr": "本文反驳了Shojaee等人(2025)关于大模型推理能力存在固有局限的结论，指出其观察到的'推理悬崖'现象实为实验范式限制所致。通过工具赋能，模型能突破原有复杂度阈值，展现层级化的智能推理能力。", "motivation": "针对Shojaee等提出的'推理悬崖'理论，作者认为该结论受限于静态文本评估范式的系统约束，旨在证明模型失败源于执行接口限制而非根本性认知缺陷。", "method": "采用工具赋能策略进行对比实验：先复现文本受限条件下的模型失败案例，再展示同模型在工具支持下的卓越表现，并分析不同智能体（o4-mini/GPT-4o）的元认知层级。", "result": "工具赋能模型成功解决原研究中'不可能'的难题，其复杂度远超原阈值；揭示智能体推理存在从程序执行到自我修正的元认知层级，重定义了机器智能的评估维度。", "conclusion": "'思维幻觉'源于行动工具缺失而非推理缺陷。当前评估范式严重低估模型潜力，应建立包含工具使用的动态评估体系，机器智能的边界取决于'行动赋能'而非静态认知测试。"}}
{"id": "2506.19191", "categories": ["cs.AI", "cs.CL", "cs.GT", "math.LO", "68T05, 68Q87, 03E20", "I.2.6; I.2.3; F.1.1"], "pdf": "https://arxiv.org/pdf/2506.19191", "abs": "https://arxiv.org/abs/2506.19191", "authors": ["Craig Steven Wright"], "title": "Bayesian Evolutionary Swarm Architecture: A Formal Epistemic System Grounded in Truth-Based Competition", "comment": "83 pages, 14 sections, 92 formal results, no prior conference\n  publication", "summary": "We introduce a mathematically rigorous framework for an artificial\nintelligence system composed of probabilistic agents evolving through\nstructured competition and belief revision. The architecture, grounded in\nBayesian inference, measure theory, and population dynamics, defines agent\nfitness as a function of alignment with a fixed external oracle representing\nground truth. Agents compete in a discrete-time environment, adjusting\nposterior beliefs through observed outcomes, with higher-rated agents\nreproducing and lower-rated agents undergoing extinction. Ratings are updated\nvia pairwise truth-aligned utility comparisons, and belief updates preserve\nmeasurable consistency and stochastic convergence. We introduce hash-based\ncryptographic identity commitments to ensure traceability, alongside causal\ninference operators using do-calculus. Formal theorems on convergence,\nrobustness, and evolutionary stability are provided. The system establishes\ntruth as an evolutionary attractor, demonstrating that verifiable knowledge\narises from adversarial epistemic pressure within a computable, self-regulating\nswarm.", "AI": {"tldr": "本文提出了一种基于贝叶斯推理、测度论和群体动力学的概率智能体框架，通过结构化竞争和信念修正实现进化，证明真理可作为进化吸引子从对抗性认知压力中涌现。", "motivation": "旨在构建数学严谨的AI系统，通过竞争性进化机制使智能体信念向外部真理标准对齐，解决可验证知识在动态环境中的涌现问题。", "method": "采用贝叶斯推理框架，定义基于真理对齐度的适应度函数；通过离散时间环境中的配对效用比较实现种群更新，引入哈希加密身份承诺和do-演算因果推理算子。", "result": "形式化定理证明系统具有收敛性、鲁棒性和进化稳定性，验证了真理作为进化吸引子的特性，实现可计算的自调节群体智能。", "conclusion": "该框架为对抗性认知压力下产生可验证知识提供了理论基础，表明结构化竞争能使群体信念向真理标准自发演化。"}}
{"id": "2506.19100", "categories": ["math.CO", "05C15, 05C38"], "pdf": "https://arxiv.org/pdf/2506.19100", "abs": "https://arxiv.org/abs/2506.19100", "authors": ["Ben Cameron", "Alexander Clow"], "title": "On Gyárfás' Path-Colour Problem", "comment": "30 pages, 5 figures", "summary": "In their 1997 paper titled ``Fruit Salad\", Gy\\'{a}rf\\'{a}s posed the\nfollowing conjecture: there exists a constant $k$ such that if each path of a\ngraph spans a $3$-colourable subgraph, then the graph is $k$-colourable. It is\nnoted that $k=4$ might suffice. Let $r(G)$ be the maximum chromatic number of\nany subgraph $H$ of $G$ where $H$ is spanned by a path. The only progress on\nthis conjecture comes from Randerath and Schiermeyer in 2002, who proved that\nif $G$ is an $n$ vertex graph, then $\\chi(G) \\leq r(G)\\log_{\\frac{8}{7}}(n)$.\n  We prove that for all natural numbers $r$, there exists a graph $G$ with\n$r(G)\\leq r$ and $\\chi(G)\\geq \\lfloor\\frac{3r}{2}\\rfloor -1$. Hence, for all\nconstants $k$ there exists a graph with $\\chi - r > k$. Our proof is\nconstructive.\n  We also study this problem in graphs with a forbidden induced subgraph. We\nshow that if $G$ is $K_{1,t}$-free, for $t\\geq 4$, then $\\chi(G) \\leq\n(t-1)(r(G)+\\binom{t-1}{2}-3)$. If $G$ is claw-free, then we prove $\\chi(G) \\leq\n2r(G)$. Additionally, the graphs $G$ where every induced subgraph $G'$ of $G$\nsatisfy $\\chi(G') = r(G')$ are considered. We call such graphs path-perfect, as\nthis class generalizes perfect graphs. We prove that if $H$ is a forest with at\nmost $4$ vertices other than the claw, then every $H$-free graph $G$ has\n$\\chi(G) \\leq r(G)+1$. We also prove that if $H$ is additionally not isomorphic\nto $2K_2$ or $K_2+2K_1$, then all $H$-free graphs are path-perfect.", "AI": {"tldr": "该论文研究了Gy\\'{a}rf\\'{a}s提出的关于图着色问题的猜想，通过构造性证明展示了对于所有自然数r，存在满足条件的图G，并探讨了在禁止特定诱导子图情况下的着色问题。", "motivation": "研究源于Gy\\'{a}rf\\'{a}s在1997年提出的猜想：若图中每条路径生成的子图是3-可着色的，则整个图是k-可着色的。论文旨在验证或反驳这一猜想，并探索在特定图类中的着色性质。", "method": "通过构造性证明，展示了对于任意自然数r，存在图G满足r(G)≤r且χ(G)≥⌊3r/2⌋−1。此外，研究了在禁止特定诱导子图（如K_{1,t}或爪形图）的图中，着色数与r(G)的关系。", "result": "证明了对于所有常数k，存在图满足χ−r>k。在禁止特定诱导子图的图中，如K_{1,t}-free图（t≥4）中，χ(G)≤(t−1)(r(G)+\\binom{t−1}{2}−3)；在爪形图-free图中，χ(G)≤2r(G)。还定义了路径完美图，并证明了一些特定条件下的路径完美性质。", "conclusion": "论文不仅反驳了Gy\\'{a}rf\\'{a}s猜想中的常数k的存在性，还扩展了对特定图类着色性质的理解，特别是在禁止诱导子图的条件下，为图的着色理论提供了新的见解。"}}
{"id": "2506.19149", "categories": ["math.CO", "cs.DM", "05C35, 05C38, 05C69"], "pdf": "https://arxiv.org/pdf/2506.19149", "abs": "https://arxiv.org/abs/2506.19149", "authors": ["Karl Bartolo", "Peter Borg", "Dayle Scicluna"], "title": "Solution to a problem on isolation of $3$-vertex paths", "comment": "12 pages", "summary": "The $3$-path isolation number of a connected $n$-vertex graph $G$, denoted by\n$\\iota(G,P_3)$, is the size of a smallest subset $D$ of the vertex set of $G$\nsuch that the closed neighbourhood $N[D]$ of $D$ in $G$ intersects each\n$3$-vertex path of $G$, meaning that no two edges of $G-N[D]$ intersect. Zhang\nand Wu proved that $\\iota(G,P_3) \\leq 2n/7$ unless $G$ is a $3$-path or a\n$3$-cycle or a $6$-cycle. The bound is attained by infinitely many graphs\nhaving induced $6$-cycles. Huang, Zhang and Jin proved that if $G$ has no\n$6$-cycles, or $G$ has no induced $5$-cycles and no induced $6$-cycles, then\n$\\iota(G, P_3) \\leq n/4$ unless $G$ is a $3$-path or a $3$-cycle or a $7$-cycle\nor an $11$-cycle. They asked if the bound still holds asymptotically for\nconnected graphs having no induced $6$-cycles. More precisely, taking $f(n)$ to\nbe the maximum value of $\\iota(G,P_3)$ over all connected $n$-vertex graphs $G$\nhaving no induced $6$-cycles, their question is whether $\\limsup_{n\n\\to\\infty}\\frac{f(n)}{n} = \\frac{1}{4}$. We verify this by proving that $f(n) =\n\\left \\lfloor (n+1)/4 \\right \\rfloor$. The proof hinges on further proving that\nif $G$ is such a graph and $\\iota(G, P_3) = (n+1)/4$, then $\\iota(G-v, P_3) <\n\\iota(G, P_3)$ for each vertex $v$ of $G$. This new idea promises to be of\nfurther use. We also prove that if the maximum degree of such a graph $G$ is at\nleast $5$, then $\\iota(G,P_3) \\leq n/4$.", "AI": {"tldr": "本文研究了无诱导6-环的连通图中3-路径隔离数的上界，证明了$f(n) = \\left \\lfloor (n+1)/4 \\right \\rfloor$，并验证了$\\limsup_{n \\to\\infty}\\frac{f(n)}{n} = \\frac{1}{4}$。", "motivation": "研究无诱导6-环的连通图中3-路径隔离数的渐近行为，解决Huang等人提出的问题。", "method": "通过证明若图$G$满足$\\iota(G, P_3) = (n+1)/4$，则对每个顶点$v$有$\\iota(G-v, P_3) < \\iota(G, P_3)$，并分析最大度数的影响。", "result": "证明了$f(n) = \\left \\lfloor (n+1)/4 \\right \\rfloor$，且当图的最大度数至少为5时，$\\iota(G,P_3) \\leq n/4$。", "conclusion": "该结果验证了Huang等人的猜想，并为无诱导6-环图的3-路径隔离数提供了精确上界，新方法有望进一步应用。"}}
{"id": "2506.19411", "categories": ["math.NT", "math.LO"], "pdf": "https://arxiv.org/pdf/2506.19411", "abs": "https://arxiv.org/abs/2506.19411", "authors": ["Floris Vermeulen"], "title": "Counting rational points on transcendental curves in valued fields", "comment": "9 pages", "summary": "We prove upper bounds on the number of rational points on transcendental\ncurves in arbitrary $1$-h-minimal fields, similar to the Pila--Wilkie counting\ntheorem in the o-minimal setting. These results extend results due to\nCluckers--Comte--Loeser from $p$-adic fields to arbitrary valued fields of\nmixed characteristic. Our methods rely on parametrizations, where we avoid the\nusage of $r$-th power maps, combined with the determinant method.", "AI": {"tldr": "本文证明了任意1-h极小域上超越曲线的有理点数量上界，扩展了Cluckers-Comte-Loeser在p进域的结果，方法结合了参数化和行列式法。", "motivation": "研究动机是将Pila-Wilkie计数定理从o极小情形推广到混合特征值域，特别是超越曲线的有理点计数问题。", "method": "采用避免使用r次幂映射的参数化方法，结合行列式法进行证明。", "result": "得到了混合特征值域上超越曲线有理点数量的上界，类似o极小情形下的Pila-Wilkie定理。", "conclusion": "该结果将p进域的计数定理推广到更一般的混合特征值域，为超越几何中的有理点研究提供了新工具。"}}
{"id": "2506.19260", "categories": ["cs.CR", "cs.DC", "cs.LG", "I.2.6; C.2.4; K.6.5"], "pdf": "https://arxiv.org/pdf/2506.19260", "abs": "https://arxiv.org/abs/2506.19260", "authors": ["Murtaza Rangwala", "Richard O. Sinnott", "Rajkumar Buyya"], "title": "Network Structures as an Attack Surface: Topology-Based Privacy Leakage in Federated Learning", "comment": "13 pages, 7 figures, 5 tables. Data from the experiments and source\n  code can be found here: https://doi.org/10.5281/zenodo.15622123", "summary": "Federated learning systems increasingly rely on diverse network topologies to\naddress scalability and organizational constraints. While existing privacy\nresearch focuses on gradient-based attacks, the privacy implications of network\ntopology knowledge remain critically understudied. We conduct the first\ncomprehensive analysis of topology-based privacy leakage across realistic\nadversarial knowledge scenarios, demonstrating that adversaries with varying\ndegrees of structural knowledge can infer sensitive data distribution patterns\neven under strong differential privacy guarantees. Through systematic\nevaluation of 4,720 attack instances, we analyze six distinct adversarial\nknowledge scenarios: complete topology knowledge and five partial knowledge\nconfigurations reflecting real-world deployment constraints. We propose three\ncomplementary attack vectors: communication pattern analysis, parameter\nmagnitude profiling, and structural position correlation, achieving success\nrates of 84.1%, 65.0%, and 47.2% under complete knowledge conditions.\nCritically, we find that 80% of realistic partial knowledge scenarios maintain\nattack effectiveness above security thresholds, with certain partial knowledge\nconfigurations achieving performance superior to the baseline complete\nknowledge scenario. To address these vulnerabilities, we propose and\nempirically validate structural noise injection as a complementary defense\nmechanism across 808 configurations, demonstrating up to 51.4% additional\nattack reduction when properly layered with existing privacy techniques. These\nresults establish that network topology represents a fundamental privacy\nvulnerability in federated learning systems while providing practical pathways\nfor mitigation through topology-aware defense mechanisms.", "AI": {"tldr": "联邦学习系统中网络拓扑结构可能引发隐私泄露，研究发现不同知识背景的攻击者能推断敏感数据分布模式，并提出结构噪声注入作为有效防御手段。", "motivation": "现有隐私研究主要关注基于梯度的攻击，而网络拓扑知识对隐私的影响尚未充分研究。本文首次全面分析了基于拓扑的隐私泄露问题。", "method": "通过系统评估4,720个攻击实例，分析六种对抗知识场景（包括完整拓扑知识和五种部分知识配置），提出三种攻击向量：通信模式分析、参数幅度分析和结构位置相关性分析。", "result": "在完整知识条件下，三种攻击成功率分别为84.1%、65.0%和47.2%。80%的部分知识场景攻击效果仍高于安全阈值。结构噪声注入防御机制可额外减少51.4%的攻击。", "conclusion": "网络拓扑是联邦学习系统的根本隐私漏洞，但通过拓扑感知防御机制（如结构噪声注入）可有效缓解这一风险。"}}
{"id": "2506.19294", "categories": ["math.OC", "math.PR", "q-fin.PM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.19294", "abs": "https://arxiv.org/abs/2506.19294", "authors": ["Jose Blanchet", "Jiayi Cheng", "Hao Liu", "Yang Liu"], "title": "Duality and Policy Evaluation in Distributionally Robust Bayesian Diffusion Control", "comment": null, "summary": "We consider a Bayesian diffusion control problem of expected terminal utility\nmaximization. The controller imposes a prior distribution on the unknown drift\nof an underlying diffusion. The Bayesian optimal control, tracking the\nposterior distribution of the unknown drift, can be characterized explicitly.\nHowever, in practice, the prior will generally be incorrectly specified, and\nthe degree of model misspecification can have a significant impact on policy\nperformance. To mitigate this and reduce overpessimism, we introduce a\ndistributionally robust Bayesian control (DRBC) formulation in which the\ncontroller plays a game against an adversary who selects a prior in divergence\nneighborhood of a baseline prior. The adversarial approach has been studied in\neconomics and efficient algorithms have been proposed in static optimization\nsettings. We develop a strong duality result for our DRBC formulation.\nCombining these results together with tools from stochastic analysis, we are\nable to derive a loss that can be efficiently trained (as we demonstrate in our\nnumerical experiments) using a suitable neural network architecture. As a\nresult, we obtain an effective algorithm for computing the DRBC optimal\nstrategy. The methodology for computing the DRBC optimal strategy is greatly\nsimplified, as we show, in the important case in which the adversary chooses a\nprior from a Kullback-Leibler distributional uncertainty set.", "AI": {"tldr": "本文研究了一种贝叶斯扩散控制问题，通过引入分布鲁棒贝叶斯控制（DRBC）框架来应对模型误设，并开发了高效的计算方法。", "motivation": "在实际应用中，贝叶斯最优控制依赖于对未知漂移的先验分布假设，但先验误设会显著影响策略性能。为避免过度悲观，需要一种鲁棒性更强的控制方法。", "method": "提出分布鲁棒贝叶斯控制（DRBC）框架，控制器与对手在基线先验的散度邻域内博弈。结合随机分析工具，推导出可通过神经网络高效训练的损失函数。", "result": "在Kullback-Leibler分布不确定性集下，DRBC最优策略的计算方法大幅简化，并通过数值实验验证了算法的有效性。", "conclusion": "DRBC框架有效解决了模型误设问题，简化了最优策略的计算，为实际应用提供了可行的解决方案。"}}
{"id": "2506.19748", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.19748", "abs": "https://arxiv.org/abs/2506.19748", "authors": ["Aman Pandey", "Chanchal Kundu"], "title": "Copula-Based Modeling of Fractional Inaccuracy: A Unified Framework", "comment": "4 Figures", "summary": "We introduce novel information-theoretic measures termed the multivariate\ncumulative copula fractional inaccuracy measure and the multivariate survival\ncopula fractional inaccuracy measure, constructed respectively from\nmultivariate copulas and multivariate survival copulas. These measures\ngeneralize the concept of fractional inaccuracy to multivariate settings by\nincorporating dependence structures through copulas. We establish bounds for\nthese measures using the Frechet-Hoeffding bounds and investigate their\nbehavior under lower and upper orthant stochastic orderings to facilitate\ncomparative analysis. Furthermore, we define the multivariate co-copula\nfractional inaccuracy measure and the multivariate dual copula fractional\ninaccuracy measure, derived from the multivariate co-copula and dual copula,\nrespectively, and examine several analogous properties for these extended\nforms.", "AI": {"tldr": "本文引入了基于多元累积连接函数和生存连接函数的新型信息论测度，扩展了分数不准确度的概念，并通过连接函数整合依赖结构。", "motivation": "研究动机在于将分数不准确度概念推广到多元设置，并通过连接函数捕捉变量间的依赖关系。", "method": "方法包括构建多元累积连接函数分数不准确度测度和生存连接函数分数不准确度测度，利用Frechet-Hoeffding边界建立测度界限，并研究其在随机序下的行为。", "result": "结果表明，这些测度在上下正交随机序下具有可比较性，并进一步定义了多元共连接函数和双连接函数分数不准确度测度。", "conclusion": "结论指出，这些新型测度为多元依赖结构分析提供了理论工具，并展示了其在比较分析中的潜在应用价值。"}}
{"id": "2506.19046", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19046", "abs": "https://arxiv.org/abs/2506.19046", "authors": ["Filip Sabo", "Michele Meroni", "Maria Piles", "Martin Claverie", "Fanie Ferreira", "Elna Van Den Berg", "Francesco Collivignarelli", "Felix Rembold"], "title": "From Rows to Yields: How Foundation Models for Tabular Data Simplify Crop Yield Prediction", "comment": null, "summary": "We present an application of a foundation model for small- to medium-sized\ntabular data (TabPFN), to sub-national yield forecasting task in South Africa.\nTabPFN has recently demonstrated superior performance compared to traditional\nmachine learning (ML) models in various regression and classification tasks. We\nused the dekadal (10-days) time series of Earth Observation (EO; FAPAR and soil\nmoisture) and gridded weather data (air temperature, precipitation and\nradiation) to forecast the yield of summer crops at the sub-national level. The\ncrop yield data was available for 23 years and for up to 8 provinces. Covariate\nvariables for TabPFN (i.e., EO and weather) were extracted by region and\naggregated at a monthly scale. We benchmarked the results of the TabPFN against\nsix ML models and three baseline models. Leave-one-year-out cross-validation\nexperiment setting was used in order to ensure the assessment of the models\ncapacity to forecast an unseen year. Results showed that TabPFN and ML models\nexhibit comparable accuracy, outperforming the baselines. Nonetheless, TabPFN\ndemonstrated superior practical utility due to its significantly faster tuning\ntime and reduced requirement for feature engineering. This renders TabPFN a\nmore viable option for real-world operation yield forecasting applications,\nwhere efficiency and ease of implementation are paramount.", "AI": {"tldr": "研究将基础模型TabPFN应用于南非次国家级作物产量预测，与传统机器学习模型相比，TabPFN在保持精度的同时显著提升了调参效率和工程便捷性。", "motivation": "TabPFN在小中型表格数据任务中表现优异，本研究旨在验证其在农业产量预测领域的实用价值，特别是针对数据效率与实施便捷性的需求。", "method": "使用23年8个省份的夏季作物产量数据，结合月度聚合的FAPAR、土壤湿度等EO数据及气温、降水等网格气象数据，采用留一年份交叉验证对比TabPFN与6种机器学习模型及3种基线模型。", "result": "TabPFN与机器学习模型精度相当且均优于基线，但其调参速度更快、特征工程需求更低，展现出更强的实际应用优势。", "conclusion": "TabPFN因其高效性和易用性，成为现实世界产量预测的更优选择，尤其适用于对操作效率要求严格的场景。"}}
{"id": "2506.19126", "categories": ["math.CO", "05C15"], "pdf": "https://arxiv.org/pdf/2506.19126", "abs": "https://arxiv.org/abs/2506.19126", "authors": ["Aaron Abrams"], "title": "Upper Chromatic Numbers: An Update", "comment": "This is a survey written in 2000 about upper chromatic numbers", "summary": "This is a survey written in 2000 about upper chromatic numbers", "AI": {"tldr": "2000年关于上色数的综述论文", "motivation": "探讨图论中上色数的研究进展及其重要性", "method": "综述性研究，整理和分析已有文献", "result": "总结了上色数的定义、性质及相关研究成果", "conclusion": "该综述为上色数的研究提供了系统的参考"}}
{"id": "2506.19768", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2506.19768", "abs": "https://arxiv.org/abs/2506.19768", "authors": ["Valentin Dusollier", "Sébastien Bonte", "Gauvain Devillez", "Alain Hertz", "Hadrien Mélot", "David Schindl"], "title": "Complete polyhedral description of chemical graphs of maximum degree at most 3", "comment": "30 pages", "summary": "Chemical graphs are simple undirected connected graphs, where vertices\nrepresent atoms in a molecule and edges represent chemical bonds. A\ndegree-based topological index is a molecular descriptor used to study specific\nphysicochemical properties of molecules. Such an index is computed from the sum\nof the weights of the edges of a chemical graph, each edge having a weight\ndefined by a formula that depends only on the degrees of its endpoints. Given\nany degree-based topological index and given two integers $n$ and $m$, we are\ninterested in determining chemical graphs of order $n$ and size $m$ that\nmaximize or minimize the index. Focusing on chemical graphs with maximum degree\nat most 3, we show that this reduces to determining the extreme points of a\npolytope that contains at most 10 facets. We also show that the number of\nextreme points is at most 16, which means that for any given $n$ and $m$, there\nare very few different classes of extremal graphs, independently of the chosen\ndegree-based topological index.", "AI": {"tldr": "该研究探讨了化学图中基于度的拓扑指数的极值问题，通过将问题转化为多面体极值点求解，证明了在最大度数不超过3的情况下，极值图类别不超过16种。", "motivation": "研究旨在解决化学图中基于度的拓扑指数在给定顶点数$n$和边数$m$条件下的极值问题，为分子物理化学性质研究提供理论支持。", "method": "将化学图的极值问题转化为包含最多10个面的多面体极值点求解，并限制化学图的最大度数不超过3。", "result": "证明了极值点数量不超过16个，表明无论选择何种基于度的拓扑指数，极值图的类别都非常有限。", "conclusion": "该研究为化学图拓扑指数的极值问题提供了简洁的解决方案，揭示了极值图类别的有限性，对分子描述符研究具有重要意义。"}}
{"id": "2506.19423", "categories": ["math.NT", "math.AG"], "pdf": "https://arxiv.org/pdf/2506.19423", "abs": "https://arxiv.org/abs/2506.19423", "authors": ["Remke Kloosterman"], "title": "Determining explicitly the Mordell-Weil group of certain rational elliptic surfaces", "comment": null, "summary": "Let $A,B$ be nonzero rational numbers. Consider the elliptic curve\n$E_{A,B}/\\mathbb{Q}(t)$ with Weierstrass equation $y^2=x^3+At^6+B$.\n  An algorithm to determine $\\mathrm{rank } E_{A,B}(\\mathbb{Q}(t))$ as a\nfunction of $(A,B)$ was presented in a recent paper by Desjardins and\nNaskrecki. We will give a different and shorter proof for the correctness of\nthat algorithm, using a more geometric approach and discuss for which classes\nof examples this approach might be useful.", "AI": {"tldr": "本文针对椭圆曲线$E_{A,B}/\\mathbb{Q}(t)$的秩计算问题，提出了比Desjardins和Naskrecki更简洁的几何证明方法，并讨论了该方法的适用场景。", "motivation": "研究椭圆曲线$E_{A,B}/\\mathbb{Q}(t)$的秩计算问题，验证已有算法的正确性，并探索更高效的证明方法。", "method": "采用几何方法重新证明Desjardins和Naskrecki提出的算法，该方法比原证明更简洁直观。", "result": "成功验证了原算法的正确性，并通过几何方法简化了证明过程。", "conclusion": "几何方法在特定类别的椭圆曲线秩计算问题中具有优势，未来可进一步探索其应用范围。"}}
{"id": "2506.19356", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19356", "abs": "https://arxiv.org/abs/2506.19356", "authors": ["Ye Tian", "Zhang Yumin", "Yifan Jia", "Jianguo Sun", "Yanbin Wang"], "title": "WebGuard++:Interpretable Malicious URL Detection via Bidirectional Fusion of HTML Subgraphs and Multi-Scale Convolutional BERT", "comment": null, "summary": "URL+HTML feature fusion shows promise for robust malicious URL detection,\nsince attacker artifacts persist in DOM structures. However, prior work suffers\nfrom four critical shortcomings: (1) incomplete URL modeling, failing to\njointly capture lexical patterns and semantic context; (2) HTML graph sparsity,\nwhere threat-indicative nodes (e.g., obfuscated scripts) are isolated amid\nbenign content, causing signal dilution during graph aggregation; (3)\nunidirectional analysis, ignoring URL-HTML feature bidirectional interaction;\nand (4) opaque decisions, lacking attribution to malicious DOM components. To\naddress these challenges, we present WebGuard++, a detection framework with 4\nnovel components: 1) Cross-scale URL Encoder: Hierarchically learns\nlocal-to-global and coarse to fine URL features based on Transformer network\nwith dynamic convolution. 2) Subgraph-aware HTML Encoder: Decomposes DOM graphs\ninto interpretable substructures, amplifying sparse threat signals via\nHierarchical feature fusion. 3) Bidirectional Coupling Module: Aligns URL and\nHTML embeddings through cross-modal contrastive learning, optimizing\ninter-modal consistency and intra-modal specificity. 4) Voting Module:\nLocalizes malicious regions through consensus voting on malicious subgraph\npredictions. Experiments show WebGuard++ achieves significant improvements over\nstate-of-the-art baselines, achieving 1.1x-7.9x higher TPR at fixed FPR of\n0.001 and 0.0001 across both datasets.", "AI": {"tldr": "WebGuard++提出了一种融合URL与HTML特征的双向耦合恶意URL检测框架，通过跨尺度编码、子图感知、双向对齐和投票机制解决现有方法的四大缺陷，实验显示检测性能显著提升。", "motivation": "现有恶意URL检测方法存在四大不足：URL建模不完整、HTML图稀疏导致威胁信号稀释、URL-HTML特征单向分析、决策过程不透明。WebGuard++旨在解决这些问题。", "method": "1) 跨尺度URL编码器：基于Transformer和动态卷积分层学习URL特征；2) 子图感知HTML编码器：分解DOM图并增强稀疏威胁信号；3) 双向耦合模块：通过跨模态对比学习对齐特征；4) 投票模块：通过恶意子图预测共识定位威胁区域。", "result": "实验表明WebGuard++在TPR指标上比现有最优方法提升1.1-7.9倍（FPR固定为0.001和0.0001），在两个数据集上均表现优异。", "conclusion": "该框架通过多组件协同解决了URL检测的关键挑战，双向特征融合和可解释子图分析为恶意网页检测提供了新方向。"}}
{"id": "2506.19426", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.19426", "abs": "https://arxiv.org/abs/2506.19426", "authors": ["Andrea Spinelli", "Dario Bezzi", "Ola Jabali", "Francesca Maggioni"], "title": "A Stochastic Electric Vehicle Routing Problem under Uncertain Energy Consumption", "comment": null, "summary": "The increasing adoption of Electric Vehicles (EVs) for service and goods\ndistribution operations has led to the emergence of Electric Vehicle Routing\nProblems (EVRPs), a class of vehicle routing problems addressing the unique\nchallenges posed by the limited driving range and recharging needs of EVs.\nWhile the majority of EVRP variants have considered deterministic energy\nconsumption, this paper focuses on the Stochastic Electric Vehicle Routing\nProblem with a Threshold recourse policy (SEVRP-T), where the uncertainty in\nenergy consumption is considered, and a recourse policy is employed to ensure\nthat EVs recharge at Charging Stations (CSs) whenever their State of Charge\n(SoC) falls below a specified threshold. We formulate the SEVRP-T as a\ntwo-stage stochastic mixed-integer second-order cone model, where the first\nstage determines the sequences of customers to be visited, and the second stage\nincorporates charging activities. The objective is to minimize the expected\ntotal duration of the routes, composed by travel times and recharging\noperations. To cope with the computational complexity of the model, we propose\na heuristic based on an Iterated Local Search (ILS) procedure coupled with a\nSet Partitioning problem. To further speed up the heuristic, we develop two\nlower bounds on the corresponding first-stage customer sequences. Furthermore,\nto handle a large number of energy consumption scenarios, we employ a scenario\nreduction technique. Extensive computational experiments are conducted to\nvalidate the effectiveness of the proposed solution strategy and to assess the\nimportance of considering the stochastic nature of the energy consumption. The\nresearch presented in this paper contributes to the growing body of literature\non EVRP and provides insights into managing the operational deployment of EVs\nin logistics activities under uncertainty.", "AI": {"tldr": "本文研究随机电动车辆路径问题（SEVRP-T），考虑能源消耗的不确定性，并提出一种两阶段随机混合整数二阶锥模型及启发式算法以优化路线总时长。", "motivation": "随着电动汽车（EVs）在物流配送中的广泛应用，其有限续航和充电需求带来了新的路径规划挑战。现有研究多假设能源消耗确定，而实际中存在不确定性，因此需考虑随机性以优化运营效率。", "method": "提出两阶段随机混合整数二阶锥模型：第一阶段确定客户访问顺序，第二阶段加入充电活动。为降低计算复杂度，设计基于迭代局部搜索（ILS）和集合划分问题的启发式算法，并开发两种下界以加速求解。采用场景缩减技术处理大量能源消耗场景。", "result": "大量计算实验验证了所提策略的有效性，并证明考虑能源消耗随机性的重要性。启发式算法显著提升了求解效率，同时场景缩减技术有效处理了大规模问题。", "conclusion": "本研究丰富了电动车辆路径问题（EVRP）的文献，为不确定环境下电动汽车在物流活动中的运营部署提供了实用见解。所提出的模型和算法为实际应用提供了可靠工具。"}}
{"id": "2506.19095", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19095", "abs": "https://arxiv.org/abs/2506.19095", "authors": ["Fien van Wetten", "Aske Plaat", "Max van Duijn"], "title": "Baba is LLM: Reasoning in a Game with Dynamic Rules", "comment": null, "summary": "Large language models (LLMs) are known to perform well on language tasks, but\nstruggle with reasoning tasks. This paper explores the ability of LLMs to play\nthe 2D puzzle game Baba is You, in which players manipulate rules by\nrearranging text blocks that define object properties. Given that this\nrule-manipulation relies on language abilities and reasoning, it is a\ncompelling challenge for LLMs. Six LLMs are evaluated using different prompt\ntypes, including (1) simple, (2) rule-extended and (3) action-extended prompts.\nIn addition, two models (Mistral, OLMo) are finetuned using textual and\nstructural data from the game. Results show that while larger models\n(particularly GPT-4o) perform better in reasoning and puzzle solving, smaller\nunadapted models struggle to recognize game mechanics or apply rule changes.\nFinetuning improves the ability to analyze the game levels, but does not\nsignificantly improve solution formulation. We conclude that even for\nstate-of-the-art and finetuned LLMs, reasoning about dynamic rule changes is\ndifficult (specifically, understanding the use-mention distinction). The\nresults provide insights into the applicability of LLMs to complex\nproblem-solving tasks and highlight the suitability of games with dynamically\nchanging rules for testing reasoning and reflection by LLMs.", "AI": {"tldr": "研究评估了六种大语言模型（LLM）在2D解谜游戏《Baba is You》中的表现，发现即使微调后，模型对动态规则变化的推理仍存在困难，突显了此类游戏对测试LLM推理能力的适用性。", "motivation": "尽管大语言模型在语言任务上表现优异，但在需要复杂推理的任务（如动态规则解谜游戏）中表现欠佳。本研究通过《Baba is You》游戏探索LLM结合语言能力与规则推理的潜力。", "method": "评估六种LLM（包括GPT-4o、Mistral和OLMo），使用三种提示类型（基础提示、规则扩展提示和动作扩展提示），并对其中两个模型进行游戏文本与结构数据的微调。", "result": "大型模型（如GPT-4o）在推理和解谜中表现更优，但未微调的小模型难以识别游戏机制或应用规则变化。微调提升了游戏关卡分析能力，但对解决方案生成的改进有限。", "conclusion": "即使最先进的微调LLM也难以理解动态规则变化（特别是使用-提及的区分），表明此类游戏适合作为测试LLM复杂推理与反思能力的工具。"}}
{"id": "2506.19560", "categories": ["math.NT", "14G35, 11G05"], "pdf": "https://arxiv.org/pdf/2506.19560", "abs": "https://arxiv.org/abs/2506.19560", "authors": ["Abbey Bourdon", "Özlem Ejder"], "title": "Rational isolated $j$-invariants from $X_1(\\ell^n)$ and $X_0(\\ell^n)$", "comment": "Comments welcome", "summary": "Let $\\ell$ and $n$ be positive integers with $\\ell$ prime. The modular curves\n$X_1(\\ell^n)$ and $X_0(\\ell^n)$ are algebraic curves over $\\mathbb{Q}$ whose\nnon-cuspidal points parameterize elliptic curves with a distinguished point of\norder $\\ell^n$ or a distinguished cyclic subgroup of order $\\ell^n$,\nrespectively. We wish to understand isolated points on these curves, which are\nroughly those not belonging to an infinite parameterized family of points\nhaving the same degree. Our first main result is that there are precisely 15\n$j$-invariants in $\\mathbb{Q}$ which arise as the image of an isolated point\n$x\\in X_1(\\ell^n)$ under the natural map $j:X_1(\\ell^n) \\rightarrow X_1(1)$.\nThis completes a prior partial classification of Ejder. We also identify the 19\nrational $j$-invariants which correspond to isolated points on $X_0(\\ell^n)$.", "AI": {"tldr": "该论文研究了模曲线$X_1(\\ell^n)$和$X_0(\\ell^n)$上的孤立点，确定了15个有理$j$-不变量和19个对应孤立点的有理$j$-不变量。", "motivation": "研究模曲线$X_1(\\ell^n)$和$X_0(\\ell^n)$上的孤立点，以理解这些曲线上不属于无限参数化家族的点。", "method": "通过分析模曲线$X_1(\\ell^n)$和$X_0(\\ell^n)$的结构，以及自然映射$j:X_1(\\ell^n) \\rightarrow X_1(1)$，分类孤立点对应的$j$-不变量。", "result": "确定了15个有理$j$-不变量对应于$X_1(\\ell^n)$上的孤立点，以及19个有理$j$-不变量对应于$X_0(\\ell^n)$上的孤立点。", "conclusion": "该研究完成了Ejder之前的部分分类工作，为模曲线上孤立点的研究提供了完整的分类结果。"}}
{"id": "2506.19360", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.19360", "abs": "https://arxiv.org/abs/2506.19360", "authors": ["Yunsung Chung", "Yunbei Zhang", "Nassir Marrouche", "Jihun Hamm"], "title": "SoK: Can Synthetic Images Replace Real Data? A Survey of Utility and Privacy of Synthetic Image Generation", "comment": "Accepted at the 34th USENIX Security Symposium (USENIX Security '25).\n  21 pages, plus a 6-page appendix", "summary": "Advances in generative models have transformed the field of synthetic image\ngeneration for privacy-preserving data synthesis (PPDS). However, the field\nlacks a comprehensive survey and comparison of synthetic image generation\nmethods across diverse settings. In particular, when we generate synthetic\nimages for the purpose of training a classifier, there is a pipeline of\ngeneration-sampling-classification which takes private training as input and\noutputs the final classifier of interest. In this survey, we systematically\ncategorize existing image synthesis methods, privacy attacks, and mitigations\nalong this generation-sampling-classification pipeline. To empirically compare\ndiverse synthesis approaches, we provide a benchmark with representative\ngenerative methods and use model-agnostic membership inference attacks (MIAs)\nas a measure of privacy risk. Through this study, we seek to answer critical\nquestions in PPDS: Can synthetic data effectively replace real data? Which\nrelease strategy balances utility and privacy? Do mitigations improve the\nutility-privacy tradeoff? Which generative models perform best across different\nscenarios? With a systematic evaluation of diverse methods, our study provides\nactionable insights into the utility-privacy tradeoffs of synthetic data\ngeneration methods and guides the decision on optimal data releasing strategies\nfor real-world applications.", "AI": {"tldr": "本文系统综述了隐私保护数据合成(PPDS)中的合成图像生成方法，通过生成-采样-分类流程对现有技术进行分类，并利用基准测试和成员推理攻击(MIA)评估隐私风险，旨在回答合成数据能否替代真实数据等关键问题。", "motivation": "生成模型的进步推动了隐私保护数据合成(PPDS)领域的发展，但缺乏对不同场景下合成图像生成方法的全面调查与比较。研究旨在系统评估合成数据在分类器训练中的效用-隐私权衡。", "method": "研究沿生成-采样-分类流程对现有图像合成方法、隐私攻击及缓解措施进行分类，采用代表性生成方法构建基准测试，并以模型无关的成员推理攻击(MIA)作为隐私风险度量指标。", "result": "通过系统评估多种方法，研究揭示了合成数据生成方法的效用-隐私权衡特性，为不同场景下的最优数据发布策略提供了实证依据。", "conclusion": "该研究为合成数据生成方法的实际应用提供了可操作的见解，指导现实场景中平衡效用与隐私的最优数据发布策略决策。"}}
{"id": "2506.19545", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.19545", "abs": "https://arxiv.org/abs/2506.19545", "authors": ["Hong-lu Li", "Xin He", "Yi-bin Xiao"], "title": "Fast convergence of a primal-dual dynamical system with implicit Hessian damping and Tikhonov regularization", "comment": "29 pages, 9 figures", "summary": "This paper proposes two primal-dual dynamical systems for solving linear\nequality constrained convex optimization problems: one with implicit Hessian\ndamping only, and the other further incorporating Tikhonov regularization. We\nanalyze the fast convergence properties of both dynamical systems and show that\nthey achieve the same convergence rates. To the best of our knowledge, this\nwork provides the first theoretical analysis establishing a convergence rate\n$o(\\frac{1}{t^2})$ for the primal-dual gap and a convergence rate\n$o(\\frac{1}{t})$ for the velocity $\\dot{x}(t)$, without imposing additional\nassumptions on the objective function beyond convexity and L-smoothness.\nMoreover, we show that the trajectory generated by the dynamical system with\nTikhonov regularization converges strongly to the minimum-norm solution of the\nunderlying problem. Finally, numerical experiments are conducted to validate\nthe theoretical findings. Interestingly, the trajectories exhibit smooth\nbehavior even when the objective function is only continuously differentiable.", "AI": {"tldr": "本文提出了两种解决线性等式约束凸优化问题的原始-对偶动力系统，分析了其快速收敛特性，并首次在仅要求凸性和L-光滑性的条件下，证明了原始-对偶间隙的$o(\\frac{1}{t^2})$收敛速度和速度$\\dot{x}(t)$的$o(\\frac{1}{t})$收敛速度。", "motivation": "研究旨在开发无需额外假设（仅需凸性和L-光滑性）即可实现快速收敛的原始-对偶动力系统，填补理论分析空白，并验证Tikhonov正则化系统轨迹强收敛于最小范数解的特性。", "method": "提出两种动力系统：1) 仅含隐式Hessian阻尼；2) 结合Tikhonov正则化。通过理论分析比较收敛速率，并进行数值实验验证。", "result": "两种系统均实现原始-对偶间隙$o(\\frac{1}{t^2})$和速度$o(\\frac{1}{t})$的收敛速率。Tikhonov正则化系统轨迹强收敛于最小范数解，且数值实验显示即使目标函数仅连续可微，轨迹仍保持平滑。", "conclusion": "该工作为原始-对偶动力系统提供了首个无需强假设的快速收敛理论框架，Tikhonov正则化可确保强收敛性，数值结果与理论一致，拓展了非光滑优化问题的应用潜力。"}}
{"id": "2506.19185", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19185", "abs": "https://arxiv.org/abs/2506.19185", "authors": ["Janak Kapuriya", "Aman Singh", "Jainendra Shukla", "Rajiv Ratn Shah"], "title": "Spiritual-LLM : Gita Inspired Mental Health Therapy In the Era of LLMs", "comment": null, "summary": "Traditional mental health support systems often generate responses based\nsolely on the user's current emotion and situations, resulting in superficial\ninterventions that fail to address deeper emotional needs. This study\nintroduces a novel framework by integrating spiritual wisdom from the Bhagavad\nGita with advanced large language model GPT-4o to enhance emotional well-being.\nWe present the GITes (Gita Integrated Therapy for Emotional Support) dataset,\nwhich enhances the existing ExTES mental health dataset by including 10,729\nspiritually guided responses generated by GPT-4o and evaluated by domain\nexperts. We benchmark GITes against 12 state-of-the-art LLMs, including both\nmental health specific and general purpose models. To evaluate spiritual\nrelevance in generated responses beyond what conventional n-gram based metrics\ncapture, we propose a novel Spiritual Insight metric and automate assessment\nvia an LLM as jury framework using chain-of-thought prompting. Integrating\nspiritual guidance into AI driven support enhances both NLP and spiritual\nmetrics for the best performing LLM Phi3-Mini 3.2B Instruct, achieving\nimprovements of 122.71% in ROUGE, 126.53% in METEOR, 8.15% in BERT score,\n15.92% in Spiritual Insight, 18.61% in Sufficiency and 13.22% in Relevance\ncompared to its zero-shot counterpart. While these results reflect substantial\nimprovements across automated empathy and spirituality metrics, further\nvalidation in real world patient populations remains a necessary step. Our\nfindings indicate a strong potential for AI systems enriched with spiritual\nguidance to enhance user satisfaction and perceived support outcomes. The code\nand dataset will be publicly available to advance further research in this\nemerging area.", "AI": {"tldr": "本研究提出了一种结合《薄伽梵歌》精神智慧与GPT-4o大语言模型的新型框架GITes，用于提升情感支持效果。通过构建包含10,729条精神引导回复的数据集，并在12个先进LLM上测试，结果显示Phi3-Mini模型在各项指标上显著提升。", "motivation": "传统心理健康支持系统仅基于用户当前情绪和情境生成回复，导致干预流于表面。本研究旨在通过整合精神智慧与AI技术，解决深层情感需求。", "method": "研究构建了GITes数据集（基于ExTES增强），包含GPT-4o生成的精神引导回复；提出\"精神洞察力\"新指标，并采用LLM陪审团框架进行自动化评估；在12个LLM上进行了基准测试。", "result": "最佳模型Phi3-Mini在ROUGE（提升122.71%）、METEOR（126.53%）、BERT分数（8.15%）、精神洞察力（15.92%）、充分性（18.61%）和相关性（13.22%）等指标上均显著优于零样本版本。", "conclusion": "精神智慧增强的AI系统在自动共情和灵性指标上表现优异，具有提升用户满意度的潜力。但需在真实患者群体中进一步验证。代码和数据集将公开以促进该新兴领域研究。"}}
{"id": "2506.19151", "categories": ["math.CO", "05C15"], "pdf": "https://arxiv.org/pdf/2506.19151", "abs": "https://arxiv.org/abs/2506.19151", "authors": ["Aaron Abrams", "Peter Johnson"], "title": "Yet Another Species of Forbidden-distances Chromatic Number", "comment": "This 2001 paper introduces a new type of chromatic number for point\n  sets", "summary": "This 2001 paper introduces a new type of chromatic number for point sets.", "AI": {"tldr": "2001年论文提出了一种新的点集色数类型", "motivation": "研究点集着色问题的新视角", "method": "引入新型色数定义方法", "result": "建立了点集色数的新理论框架", "conclusion": "该新型色数为组合几何研究提供了新工具"}}
{"id": "2506.19673", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.19673", "abs": "https://arxiv.org/abs/2506.19673", "authors": ["David Loeffler", "Arshay Sheth"], "title": "The Asai--Flach Euler system in $p$-adic families", "comment": "Comments welcome!", "summary": "We show that the Euler system for the Asai representation corresponding to a\nHilbert modular eigenform over a real quadratic field, constructed by Lei,\nLoeffler and Zerbes (2018), can be interpolated $p$-adically as the Hilbert\nmodular form varies in a Hida family. This work is used as an important input\nin recent work of Grossi, Loeffler and Zerbes (2025) on the proof of the\nBloch--Kato conjecture in analytic rank zero for the Asai representation.", "AI": {"tldr": "本文证明了Lei、Loeffler和Zerbes(2018)构建的实二次域上Hilbert模特征形式对应的Asai表示的Euler系统可在Hida族中随Hilbert模形式变化而进行$p$进插值。该成果被Grossi、Loeffler和Zerbes(2025)用作证明解析秩为零时Asai表示Bloch-Kato猜想的重要依据。", "motivation": "研究Hilbert模特征形式对应的Asai表示Euler系统的$p$进插值性质，为后续证明Bloch-Kato猜想提供理论基础。", "method": "通过Hida族理论，将实二次域上Hilbert模特征形式的Euler系统进行$p$进插值分析。", "result": "成功实现了Asai表示对应Euler系统在Hida族变化下的$p$进插值，支持了Bloch-Kato猜想在解析秩为零情况的证明。", "conclusion": "该工作不仅拓展了Euler系统的插值理论，还为Asai表示相关猜想的证明提供了关键工具。"}}
{"id": "2506.19368", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19368", "abs": "https://arxiv.org/abs/2506.19368", "authors": ["Xiang Liu", "Zhanpeng Guo", "Liangxi Liu", "Mengyao Zheng", "Yiming Qiu", "Linshan Jiang"], "title": "Yotta: A Large-Scale Trustless Data Trading Scheme for Blockchain System", "comment": "9 pages, 2 figures, Exploratory Paper", "summary": "Data trading is one of the key focuses of Web 3.0. However, all the current\nmethods that rely on blockchain-based smart contracts for data exchange cannot\nsupport large-scale data trading while ensuring data security, which falls\nshort of fulfilling the spirit of Web 3.0. Even worse, there is currently a\nlack of discussion on the essential properties that large-scale data trading\nshould satisfy. In this work, we are the first to formalize the property\nrequirements for enabling data trading in Web 3.0. Based on these requirements,\nwe are the first to propose Yotta, a complete batch data trading scheme for\nblockchain, which features a data trading design that leverages our innovative\ncryptographic workflow with IPFS and zk-SNARK. Our simulation results\ndemonstrate that Yotta outperforms baseline approaches up to 130 times and\nexhibits excellent scalability to satisfy all the properties.", "AI": {"tldr": "本文首次形式化了Web 3.0中大规模数据交易应满足的属性要求，并提出了基于区块链的完整批量数据交易方案Yotta，该方案结合创新密码学工作流、IPFS和zk-SNARK技术，性能超越基线方法130倍且具备卓越可扩展性。", "motivation": "当前基于区块链智能合约的数据交换方法无法在保障安全性的同时支持大规模数据交易，且缺乏对Web 3.0数据交易核心属性的系统讨论。", "method": "提出Yotta方案：通过形式化属性需求，设计融合IPFS存储与zk-SNARK零知识证明的创新密码学工作流，实现区块链批量数据交易。", "result": "仿真表明Yotta性能达基线方法的130倍，完美满足所有形式化属性并展现极佳可扩展性。", "conclusion": "Yotta是首个符合Web 3.0精神的大规模数据交易解决方案，为区块链数据交易领域建立了理论框架与实践范例。"}}
{"id": "2506.19722", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.19722", "abs": "https://arxiv.org/abs/2506.19722", "authors": ["Antonio Coppola", "Gerhard Hiermann", "Dario Paccagnan", "Michel Gendreau", "Maximilian Schiffer"], "title": "Integrated Balanced and Staggered Routing in Autonomous Mobility-on-Demand Systems", "comment": null, "summary": "Autonomous mobility-on-demand (AMoD) systems, centrally coordinated fleets of\nself-driving vehicles, offer a promising alternative to traditional\nride-hailing by improving traffic flow and reducing operating costs.\nCentralized control in AMoD systems enables two complementary routing\nstrategies: balanced routing, which distributes traffic across alternative\nroutes to ease congestion, and staggered routing, which delays departures to\nsmooth peak demand over time. In this work, we introduce a unified framework\nthat jointly optimizes both route choices and departure times to minimize\nsystem travel times. We formulate the problem as an optimization model and show\nthat our congestion model yields an unbiased estimate of travel times derived\nfrom a discretized version of Vickrey's bottleneck model. To solve large-scale\ninstances, we develop a custom metaheuristic based on a large neighborhood\nsearch framework. We assess our method through a case study on the Manhattan\nstreet network using real-world taxi data. In a setting with exclusively\ncentrally controlled AMoD vehicles, our approach reduces total traffic delay by\nup to 25 percent and mitigates network congestion by up to 35 percent compared\nto selfish routing. We also consider mixed-traffic settings with both AMoD and\nconventional vehicles, comparing a welfare-oriented operator that minimizes\ntotal system travel time with a profit-oriented one that optimizes only the\nfleet's travel time. Independent of the operator's objective, the analysis\nreveals a win-win outcome: across all control levels, both autonomous and\nnon-autonomous traffic benefit from the implementation of balancing and\nstaggering strategies.", "AI": {"tldr": "本文提出了一种联合优化路径选择和出发时间的统一框架，用于自主按需出行（AMoD）系统，通过平衡和错峰策略显著减少交通延误和拥堵。", "motivation": "自主按需出行（AMoD）系统通过集中控制提供比传统叫车服务更优的交通流和运营成本，但需解决路径选择和出发时间优化的联合问题。", "method": "研究构建了一个优化模型，基于Vickrey瓶颈模型的离散版本估计行程时间，并开发了一种基于大邻域搜索框架的元启发式算法来解决大规模问题。", "result": "在曼哈顿街网的案例研究中，该方法在纯AMoD车辆场景下减少了25%的交通延误和35%的网络拥堵；在混合交通场景中，无论运营商目标如何，均实现了双赢效果。", "conclusion": "平衡和错峰策略的实施使AMoD和传统交通均受益，验证了集中控制在优化城市交通系统中的潜力。"}}
{"id": "2506.19221", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.19221", "abs": "https://arxiv.org/abs/2506.19221", "authors": ["Li-Quan Feng", "Qing-Hu Hou"], "title": "Finding congruences with the WZ method", "comment": null, "summary": "We utilize the Wilf-Zeilberger (WZ) method to establish congruences related\nto truncated Ramanujan-type series. By constructing hypergeometric terms $f(k,\na, b, \\ldots)$ with Gosper-summable differences and selecting appropriate\nparameters, we derive several congruences modulo $p$ and $p^2$ for primes $p >\n2$. For instance, we prove that for any prime $p > 2$, \\[ \\sum_{n=0}^{p-1}\n\\frac{10n+3}{2^{3n}}\\binom{3n}{n}\\binom{2n}{n}^2 \\equiv 0 \\pmod{p},\\] and \\[\n\\sum_{n=0}^{p-1} \\frac{(-1)^n(20n^2+8n+1)}{2^{12n}}\\binom{2n}{n}^5 \\equiv 0\n\\pmod{p^2}. \\] These results partially confirm conjectures by Sun and provide\nsome novel congruences.", "AI": {"tldr": "使用Wilf-Zeilberger方法建立截断Ramanujan型级数的同余式，验证了Sun的部分猜想并发现新同余关系。", "motivation": "研究截断Ramanujan型级数的同余性质，验证数学猜想并探索新的同余关系。", "method": "通过构造超几何项$f(k, a, b, \\ldots)$并选择合适参数，利用Gosper可和差分性质推导同余式。", "result": "证明了对于素数$p > 2$，多个截断级数满足模$p$或$p^2$的同余关系，例如$\\sum_{n=0}^{p-1} \\frac{10n+3}{2^{3n}}\\binom{3n}{n}\\binom{2n}{n}^2 \\equiv 0 \\pmod{p}$。", "conclusion": "该方法有效建立了新型同余式，部分证实了Sun的猜想，为相关领域提供了新的理论工具。"}}
{"id": "2506.19812", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.19812", "abs": "https://arxiv.org/abs/2506.19812", "authors": ["Thang Pang Ern", "Malcolm Tan Jun Xi"], "title": "On the Asymptotic Density of a GCD-based Map", "comment": null, "summary": "We show that the symmetry of\n\\[f\\left(a,b\\right)=\\frac{\\operatorname{gcd}\\left(ab,a+b\\right)}{\\operatorname{gcd}\\left(a,b\\right)}\\]\nstems from an $\\operatorname{SL}_2\\left(\\mathbb{Z}\\right)$ action on primitive\npairs and that all solutions to $f\\left(a,b\\right)=n$ admit a uniform\nthree-parameter description -- recovering arithmetic-progression families via\nthe Chinese remainder theorem when $n$ is squarefree. It shows that the density\nof pairs with $f\\left(a,b\\right)=1$ tends to\n$\\prod_p\\left(1-p^{-2}(p+1)^{-1}\\right)\\approx0.88151$, and that its\nhigher-order analogue $f_r$ has a limiting density $6/\\pi^2$ for $r\\ge2$.", "AI": {"tldr": "论文研究了函数$f(a,b)=\\frac{\\operatorname{gcd}(ab,a+b)}{\\operatorname{gcd}(a,b)}$的对称性及其解的结构，揭示了其与$\\operatorname{SL}_2(\\mathbb{Z})$作用的关系，并给出了解的密度估计。", "motivation": "探索函数$f(a,b)$的对称性来源及其解的普遍结构，理解其在数论中的意义。", "method": "利用$\\operatorname{SL}_2(\\mathbb{Z})$在原始对上的作用，分析$f(a,b)=n$的解，并应用中国剩余定理。", "result": "发现$f(a,b)=1$的密度趋近于$\\prod_p(1-p^{-2}(p+1)^{-1})\\approx0.88151$，且高阶类似函数$f_r$在$r\\ge2$时的极限密度为$6/\\pi^2$。", "conclusion": "研究揭示了函数$f(a,b)$的深刻对称性和解的普遍结构，为相关数论问题提供了新的视角。"}}
{"id": "2506.19393", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19393", "abs": "https://arxiv.org/abs/2506.19393", "authors": ["Daniel Reijsbergen", "Eyasu Getahun Chekole", "Howard Halim", "Jianying Zhou"], "title": "ZK-SERIES: Privacy-Preserving Authentication using Temporal Biometric Data", "comment": null, "summary": "Biometric authentication relies on physiological or behavioral traits that\nare inherent to a user, making them difficult to lose, forge or forget.\nBiometric data with a temporal component enable the following authentication\nprotocol: recent readings of the underlying biometrics are encoded as time\nseries and compared to a set of base readings. If the distance between the new\nreadings and the base readings falls within an acceptable threshold, then the\nuser is successfully authenticated. Various methods exist for comparing time\nseries data, such as Dynamic Time Warping (DTW) and the Time Warp Edit Distance\n(TWED), each offering advantages and drawbacks depending on the context.\nMoreover, many of these techniques do not inherently preserve privacy, which is\na critical consideration in biometric authentication due to the complexity of\nresetting biometric credentials.\n  In this work, we propose ZK-SERIES to provide privacy and efficiency to a\nbroad spectrum of time series-based authentication protocols. ZK-SERIES uses\nthe same building blocks, i.e., zero-knowledge multiplication proofs and\nefficiently batched range proofs, to ensure consistency across all protocols.\nFurthermore, it is optimized for compatibility with low-capacity devices such\nas smartphones. To assess the effectiveness of our proposed technique, we\nprimarily focus on two case studies for biometric authentication: shake-based\nand blow-based authentication. To demonstrate ZK-SERIES's practical\napplicability even in older and less powerful smartphones, we conduct\nexperiments on a 5-year-old low-spec smartphone using real data for two case\nstudies alongside scalability assessments using artificial data. Our\nexperimental results indicate that the privacy-preserving authentication\nprotocol can be completed within 1.3 seconds on older devices.", "AI": {"tldr": "本文提出ZK-SERIES，一种保护隐私且高效的时间序列认证协议，适用于低性能设备如智能手机，实验显示在旧设备上认证可在1.3秒内完成。", "motivation": "生物识别认证依赖难以丢失或伪造的生理或行为特征，但现有时间序列比对方法（如DTW、TWED）缺乏隐私保护，且生物凭证重置复杂，亟需兼顾隐私与效率的解决方案。", "method": "ZK-SERIES通过零知识乘法证明和批量范围证明构建通用框架，兼容多种时间序列认证协议，并针对智能手机等低容量设备优化，以摇动和吹气认证为案例验证实用性。", "result": "在5年前低配智能手机上的真实数据实验表明，隐私保护认证协议可在1.3秒内完成，人工数据的扩展性评估进一步验证了方案的可行性。", "conclusion": "ZK-SERIES为时间序列生物认证提供了隐私保护与效率的平衡，其轻量级设计使老旧设备也能快速完成认证，具有实际应用价值。"}}
{"id": "2506.19723", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.19723", "abs": "https://arxiv.org/abs/2506.19723", "authors": ["Warren Hare", "Scholar Sun"], "title": "On the computation of the cosine measure in high dimensions", "comment": null, "summary": "In derivative-free optimization, the cosine measure is a value that often\narises in the convergence analysis of direct search methods. Given the\nincreasing interest in high-dimensional derivative-free optimization problems,\nit is valuable to compute the cosine measure in this setting; however, it has\nrecently been shown to be NP-hard. We propose a new formulation of the problem\nand heuristic to tackle this problem in higher dimensions and compare it with\nexisting algorithms in the literature. In addition, new results are presented\nto facilitate the construction of sets with specific cosine measures, allowing\nfor the creation of a test-set to benchmark the algorithms with.", "AI": {"tldr": "本文针对高维无导数优化中的余弦测度计算难题，提出新问题表述与启发式算法，并与现有方法对比，同时给出构建特定余弦测度集合的新结果以建立测试基准。", "motivation": "随着高维无导数优化问题日益受关注，余弦测度作为直接搜索法收敛分析的关键指标，其计算被证明是NP难问题，亟需高效解决方案。", "method": "提出新的问题表述及启发式算法处理高维场景，并与文献现有算法进行系统性比较。", "result": "展示了构建特定余弦测度集合的新结果，为算法性能评估创建了标准化测试集。", "conclusion": "研究为高维无导数优化提供了实用的余弦测度计算工具，并通过可复现的测试框架推动领域算法发展。"}}
{"id": "2506.19224", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19224", "abs": "https://arxiv.org/abs/2506.19224", "authors": ["Shuyin Xia", "Guan Wang", "Gaojie Xu", "Sen Zhao", "Guoyin Wang"], "title": "GBGC: Efficient and Adaptive Graph Coarsening via Granular-ball Computing", "comment": null, "summary": "The objective of graph coarsening is to generate smaller, more manageable\ngraphs while preserving key information of the original graph. Previous work\nwere mainly based on the perspective of spectrum-preserving, using some\npredefined coarsening rules to make the eigenvalues of the Laplacian matrix of\nthe original graph and the coarsened graph match as much as possible. However,\nthey largely overlooked the fact that the original graph is composed of\nsubregions at different levels of granularity, where highly connected and\nsimilar nodes should be more inclined to be aggregated together as nodes in the\ncoarsened graph. By combining the multi-granularity characteristics of the\ngraph structure, we can generate coarsened graph at the optimal granularity. To\nthis end, inspired by the application of granular-ball computing in\nmulti-granularity, we propose a new multi-granularity, efficient, and adaptive\ncoarsening method via granular-ball (GBGC), which significantly improves the\ncoarsening results and efficiency. Specifically, GBGC introduces an adaptive\ngranular-ball graph refinement mechanism, which adaptively splits the original\ngraph from coarse to fine into granular-balls of different sizes and optimal\ngranularity, and constructs the coarsened graph using these granular-balls as\nsupernodes. In addition, compared with other state-of-the-art graph coarsening\nmethods, the processing speed of this method can be increased by tens to\nhundreds of times and has lower time complexity. The accuracy of GBGC is almost\nalways higher than that of the original graph due to the good robustness and\ngeneralization of the granular-ball computing, so it has the potential to\nbecome a standard graph data preprocessing method.", "AI": {"tldr": "本文提出了一种基于多粒度球（GBGC）的高效自适应图粗化方法，通过结合图结构的多粒度特性，显著提升了粗化效果与效率。", "motivation": "传统图粗化方法主要基于谱保持视角，忽视了原图由不同粒度子区域组成的事实。本文旨在通过多粒度球计算，优化粗化粒度并提升处理效率。", "method": "GBGC引入自适应多粒度球图细化机制，将原图从粗到细自适应分割为不同大小的最优粒度球，并以这些球作为超节点构建粗化图。", "result": "相比现有方法，GBGC处理速度提升数十至数百倍，时间复杂度更低；且因多粒度球的鲁棒性，其精度通常高于原图。", "conclusion": "GBGC凭借高效性、自适应性和高精度，有望成为图数据预处理的标准方法。"}}
{"id": "2506.19292", "categories": ["math.CO", "math.NT"], "pdf": "https://arxiv.org/pdf/2506.19292", "abs": "https://arxiv.org/abs/2506.19292", "authors": ["Zhongjie Li"], "title": "Inequalities related to the coefficients of the $j$-function", "comment": null, "summary": "In recent years, the log-concavity or log-convexity of combinatorial\nsequences and their root sequences, higher order Tur{\\'a}n inequalities, and\nLaguerre inequalities of order two have been widely studied. However, the\nresearch of the Fourier coefficient $c(n)$ of the $j$-function is limited to\nits asymptotic form. In this paper, we give the appropriate upper and lower\nbounds of $c(n)$ to establish the inequalities associated with it.", "AI": {"tldr": "本文研究了$j$-函数的傅里叶系数$c(n)$的上下界，并建立了相关不等式。", "motivation": "近年来，组合序列及其根序列的对数凹凸性、高阶Tur{\\'a}n不等式和二阶Laguerre不等式被广泛研究，但$j$-函数的傅里叶系数$c(n)$的研究仅限于其渐近形式。", "method": "通过给出$c(n)$的适当上下界，建立了与之相关的不等式。", "result": "确定了$c(n)$的上下界，并建立了相关不等式。", "conclusion": "本文填补了$j$-函数傅里叶系数$c(n)$研究的空白，为其建立了具体的上下界和相关不等式。"}}
{"id": "2506.19409", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19409", "abs": "https://arxiv.org/abs/2506.19409", "authors": ["Thomas Prévost", "Bruno Martin", "Olivier Alibart"], "title": "An ETSI GS QKD compliant TLS implementation", "comment": null, "summary": "A modification of the TLS protocol is presented, using our implementation of\nthe Quantum Key Distribution (QKD) standard ETSI GS QKD 014 v1.1.1. We rely on\nthe Rustls library for this. The TLS protocol is modified while maintaining\nbackward compatibility on the client and server side. We thus wish to\nparticipate in the effort to generalize the use of QKD on the Internet. We used\nour protocol for a video conference call encrypted by QKD. Finally, we analyze\nthe performance of our protocol, comparing the time needed to establish a\nhandshake to that of TLS 1.3.", "AI": {"tldr": "本文提出了一种基于量子密钥分发（QKD）的TLS协议修改方案，保持了客户端和服务端的向后兼容性，并测试了其性能。", "motivation": "旨在推动量子密钥分发（QKD）在互联网中的广泛应用，通过修改TLS协议以实现更安全的通信。", "method": "基于Rustls库实现ETSI GS QKD 014 v1.1.1标准，修改TLS协议并保持向后兼容性，用于加密视频会议通话。", "result": "分析了协议性能，比较了其与TLS 1.3在建立握手时间上的差异。", "conclusion": "该协议为QKD在互联网中的推广提供了可行方案，同时保持了与传统TLS的兼容性。"}}
{"id": "2506.19740", "categories": ["math.OC", "quant-ph", "81Q93, 93B05"], "pdf": "https://arxiv.org/pdf/2506.19740", "abs": "https://arxiv.org/abs/2506.19740", "authors": ["Ruikang Liang", "Gong Cheng"], "title": "An approach to control design for two-level quantum ensemble systems", "comment": "Submitted to 64th IEEE Conference on Decision and Control", "summary": "Quantum ensemble systems arise in a variety of applications, including NMR\nspectroscopy and robust quantum control. While their theoretical properties\nhave been extensively studied, relatively little attention has been given to\nthe explicit construction of control inputs. In this paper, we address this gap\nby presenting a fully implementable control strategy for a one-parameter family\nof driftless two-level quantum systems. The proposed method is supported by\nrigorous analysis that guarantees accurate approximation of target\ndistributions on SU(2). Convergence properties are established analytically,\nand numerical simulations are provided to demonstrate the effectiveness of the\napproach.", "AI": {"tldr": "本文提出了一种针对无漂移双能级量子系统的可实施控制策略，填补了量子系综系统控制输入构建的研究空白。", "motivation": "量子系综系统在核磁共振光谱学和鲁棒量子控制等领域有广泛应用，但其控制输入的具体构建方法尚未得到充分研究。", "method": "作者提出了一种完全可实施的控制策略，适用于单参数族的无漂移双能级量子系统，并通过严格分析保证了对SU(2)上目标分布的精确逼近。", "result": "研究通过解析方法建立了收敛性，并提供了数值模拟验证该方法的有效性。", "conclusion": "该控制策略为量子系综系统的精确控制提供了理论保障和实现路径，具有重要的应用价值。"}}
{"id": "2506.19235", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19235", "abs": "https://arxiv.org/abs/2506.19235", "authors": ["Yu Xie", "Xingkai Ren", "Ying Qi", "Yao Hu", "Lianlei Shan"], "title": "RecLLM-R1: A Two-Stage Training Paradigm with Reinforcement Learning and Chain-of-Thought v1", "comment": null, "summary": "Traditional recommendation systems often grapple with \"filter bubbles\",\nunderutilization of external knowledge, and a disconnect between model\noptimization and business policy iteration. To address these limitations, this\npaper introduces RecLLM-R1, a novel recommendation framework leveraging Large\nLanguage Models (LLMs) and drawing inspiration from the DeepSeek R1\nmethodology. The framework initiates by transforming user profiles, historical\ninteractions, and multi-faceted item attributes into LLM-interpretable natural\nlanguage prompts through a carefully engineered data construction process.\nSubsequently, a two-stage training paradigm is employed: the initial stage\ninvolves Supervised Fine-Tuning (SFT) to imbue the LLM with fundamental\nrecommendation capabilities. The subsequent stage utilizes Group Relative\nPolicy Optimization (GRPO), a reinforcement learning technique, augmented with\na Chain-of-Thought (CoT) mechanism. This stage guides the model through\nmulti-step reasoning and holistic decision-making via a flexibly defined reward\nfunction, aiming to concurrently optimize recommendation accuracy, diversity,\nand other bespoke business objectives. Empirical evaluations on a real-world\nuser behavior dataset from a large-scale social media platform demonstrate that\nRecLLM-R1 significantly surpasses existing baseline methods across a spectrum\nof evaluation metrics, including accuracy, diversity, and novelty. It\neffectively mitigates the filter bubble effect and presents a promising avenue\nfor the integrated optimization of recommendation models and policies under\nintricate business goals.", "AI": {"tldr": "本文提出RecLLM-R1框架，利用大语言模型(LLM)解决推荐系统中的过滤气泡、外部知识利用不足及模型优化与业务策略迭代脱节问题。通过两阶段训练（监督微调+强化学习）和思维链机制，显著提升推荐准确性、多样性和新颖性。", "motivation": "传统推荐系统存在三大局限：过滤气泡效应、外部知识利用不足、模型优化与业务策略迭代脱节。这些缺陷制约了推荐系统的综合性能与业务适配性。", "method": "1) 将用户画像、历史交互和多维物品属性转化为LLM可理解的自然语言提示\\n2) 两阶段训练：监督微调(SFT)打基础→强化学习(GRPO)结合思维链(CoT)进行多步推理\\n3) 通过自定义奖励函数同步优化准确性、多样性等业务目标", "result": "在大型社交媒体真实用户行为数据集上，RecLLM-R1在准确性、多样性、新颖性等指标全面超越基线方法，有效缓解过滤气泡效应。", "conclusion": "该框架为复杂业务目标下推荐模型与策略的协同优化提供了可行路径，证实LLM在解决推荐系统核心挑战方面的巨大潜力。"}}
{"id": "2506.19295", "categories": ["math.CO", "cs.CG", "math.MG"], "pdf": "https://arxiv.org/pdf/2506.19295", "abs": "https://arxiv.org/abs/2506.19295", "authors": ["Chao Yang", "Zhujun Zhang"], "title": "Undecidability of Translational Tiling of the Plane with Four Tiles", "comment": "14 pages, 13 figures", "summary": "The translational tiling problem, dated back to Wang's domino problem in the\n1960s, is one of the most representative undecidable problems in the field of\ndiscrete geometry and combinatorics. Ollinger initiated the study of the\nundecidability of translational tiling with a fixed number of tiles in 2009,\nand proved that translational tiling of the plane with a set of $11$\npolyominoes is undecidable. The number of polyominoes needed to obtain\nundecidability was reduced from $11$ to $7$ by Yang and Zhang, and then to $5$\nby Kim. We show that translational tiling of the plane with a set of $4$\n(disconnected) polyominoes is undecidable in this paper.", "AI": {"tldr": "本文证明了平面平移拼接问题在仅使用4个（不连通）多边形块时仍为不可判定问题，进一步降低了此前已知的5块下限。", "motivation": "平移拼接问题是离散几何与组合数学中最具代表性的不可判定问题之一。自Ollinger 2009年首次证明11块多边形不可判定性以来，学界持续探索最小块数下限。", "method": "通过改进前人关于多联骨牌（polyominoes）的构造方法，将不可判定性证明所需的拼图块数从5个优化至4个。", "result": "最终证明：使用4个不连通的多联骨牌进行平面平移拼接的问题属于不可判定问题。", "conclusion": "该研究将平移拼接不可判定性的最小块数纪录推进至4块，为计算几何领域的基础理论提供了新的边界值。"}}
{"id": "2506.19362", "categories": ["math.CO", "math.DS", "math.MG", "math.NT", "05B45, 68R15, 52C23, 37B52"], "pdf": "https://arxiv.org/pdf/2506.19362", "abs": "https://arxiv.org/abs/2506.19362", "authors": ["Shigeki Akiyama", "Tadahisa Hamada", "Katsuki Ito"], "title": "Sturmian lattices and Aperiodic tile sets", "comment": "Welcome comments and references", "summary": "We give aperiodic tile sets based on Sturmian words of quadratic slopes. The\nmethod works for any quadratic irrational slope and we can produce infinitely\nmany aperiodic tile sets whose underlying scaling constant is a unit of any\nreal quadratic field. There are two key ingredients in our construction. The\nfirst one is ``Sturmian lattices'', an interesting grid structure generated by\nSturmian words that emerged in an aperiodic monotile called Smith Turtle.The\nsecond is the bounded displacement equivalence of Delone sets, which plays a\ncentral role in this construction.", "AI": {"tldr": "基于二次斜率Sturmian词的非周期瓦片集构造方法，适用于任何二次无理斜率，并能生成无限多非周期瓦片集，其缩放常数为实二次域的单位。", "motivation": "探索利用Sturmian词和Delone集的有界位移等价性，构建具有特定数学性质的非周期瓦片集。", "method": "结合Sturmian格子（由Sturmian词生成的网格结构）和Delone集的有界位移等价性，构造非周期瓦片集。", "result": "成功构建了基于二次斜率Sturmian词的非周期瓦片集，且缩放常数为实二次域的单位。", "conclusion": "该方法不仅扩展了非周期瓦片集的构造范围，还揭示了Sturmian格子与Delone集在非周期结构中的重要作用。"}}
{"id": "2506.19453", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19453", "abs": "https://arxiv.org/abs/2506.19453", "authors": ["Sajal Halder", "Muhammad Ejaz Ahmed", "Seyit Camtepe"], "title": "FuncVul: An Effective Function Level Vulnerability Detection Model using LLM and Code Chunk", "comment": "In The 30th European Symposium on Research in Computer Security\n  (ESORICS), 22 Sep - 26 Sep, 2025, Toulouse, France", "summary": "Software supply chain vulnerabilities arise when attackers exploit weaknesses\nby injecting vulnerable code into widely used packages or libraries within\nsoftware repositories. While most existing approaches focus on identifying\nvulnerable packages or libraries, they often overlook the specific functions\nresponsible for these vulnerabilities. Pinpointing vulnerable functions within\npackages or libraries is critical, as it can significantly reduce the risks\nassociated with using open-source software. Identifying vulnerable patches is\nchallenging because developers often submit code changes that are unrelated to\nvulnerability fixes. To address this issue, this paper introduces FuncVul, an\ninnovative code chunk-based model for function-level vulnerability detection in\nC/C++ and Python, designed to identify multiple vulnerabilities within a\nfunction by focusing on smaller, critical code segments. To assess the model's\neffectiveness, we construct six code and generic code chunk based datasets\nusing two approaches: (1) integrating patch information with large language\nmodels to label vulnerable samples and (2) leveraging large language models\nalone to detect vulnerabilities in function-level code. To design FuncVul\nvulnerability model, we utilise GraphCodeBERT fine tune model that captures\nboth the syntactic and semantic aspects of code. Experimental results show that\nFuncVul outperforms existing state-of-the-art models, achieving an average\naccuracy of 87-92% and an F1 score of 86-92% across all datasets. Furthermore,\nwe have demonstrated that our code-chunk-based FuncVul model improves 53.9%\naccuracy and 42.0% F1-score than the full function-based vulnerability\nprediction. The FuncVul code and datasets are publicly available on GitHub at\nhttps://github.com/sajalhalder/FuncVul.", "AI": {"tldr": "本文提出FuncVul，一种基于代码块的函数级漏洞检测模型，专注于识别C/C++和Python中关键代码段的多种漏洞，显著提升检测准确率。", "motivation": "现有方法多关注包或库级别的漏洞，忽视具体漏洞函数定位。识别漏洞函数可大幅降低开源软件使用风险，但开发者提交的非漏洞修复代码增加了识别难度。", "method": "采用两种方法构建六种数据集：(1)结合补丁信息与大型语言模型标记漏洞样本；(2)单独利用大型语言模型检测函数级代码漏洞。基于GraphCodeBERT微调模型捕获代码语法和语义特征。", "result": "FuncVul在全部数据集上平均准确率达87-92%，F1分数86-92%，较基于完整函数的预测模型准确率提升53.9%，F1分数提升42.0%。", "conclusion": "基于代码块的FuncVul模型在函数级漏洞检测中表现优异，代码与数据集已开源。该方法为精准定位软件供应链漏洞提供了有效解决方案。"}}
{"id": "2506.19821", "categories": ["math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.19821", "abs": "https://arxiv.org/abs/2506.19821", "authors": ["Víctor Blanco", "Alfredo Marín", "Justo Puerto"], "title": "Exact Matrix Seriation through Mathematical Optimization: Stress and Effectiveness-Based Models", "comment": "30 pages, 20 figures, 8 tables. Codes and datasets available at:\n  https://github.com/vblancoOR/seriation_mathopt", "summary": "Matrix seriation, the problem of permuting the rows and columns of a matrix\nto uncover latent structure, is a fundamental technique in data science,\nparticularly in the visualization and analysis of relational data. Applications\nspan clustering, anomaly detection, and beyond. In this work, we present a\nunified framework grounded in mathematical optimization to address matrix\nseriation from a rigorous, model-based perspective. Our approach leverages\ncombinatorial and mixed-integer optimization to represent seriation objectives\nand constraints with high fidelity, bridging the gap between traditional\nheuristic methods and exact solution techniques.\n  We introduce new mathematical programming models for neighborhood-based\nstress criteria, including nonlinear formulations and their linearized\ncounterparts. For structured settings such as Moore and von Neumann\nneighborhoods, we develop a novel Hamiltonian path-based reformulation that\nenables effective control over spatial arrangement and interpretability in the\nreordered matrix.\n  To assess the practical impact of our models, we carry out an extensive set\nof experiments on synthetic and real-world datasets, as well as on a newly\ncurated benchmark based on a coauthorship network from the matrix seriation\nliterature. Our results show that these optimization-based formulations not\nonly enhance solution quality and interpretability but also provide a versatile\nfoundation for extending matrix seriation to new domains in data science.", "AI": {"tldr": "本文提出了一种基于数学优化的统一框架来解决矩阵排序问题，通过组合和混合整数优化方法，提高了解决方案的质量和可解释性。", "motivation": "矩阵排序是数据科学中的基础技术，用于揭示关系数据中的潜在结构，但传统启发式方法与精确解法之间存在差距。本文旨在通过优化方法弥合这一差距。", "method": "提出了基于邻域的应力准则的数学规划模型，包括非线性公式及其线性化版本，并针对特定结构（如Moore和von Neumann邻域）开发了基于哈密顿路径的新颖重构方法。", "result": "在合成和真实数据集上的广泛实验表明，优化模型不仅提高了解决方案的质量和可解释性，还为矩阵排序在数据科学中的新应用提供了灵活的基础。", "conclusion": "本文的优化框架为矩阵排序问题提供了严格且通用的解决方案，显著提升了传统方法的性能，并扩展了其应用范围。"}}
{"id": "2506.19280", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19280", "abs": "https://arxiv.org/abs/2506.19280", "authors": ["Feiting Yang", "Antoine Moevus", "Steve Lévesque"], "title": "Emotion Detection on User Front-Facing App Interfaces for Enhanced Schedule Optimization: A Machine Learning Approach", "comment": null, "summary": "Human-Computer Interaction (HCI) has evolved significantly to incorporate\nemotion recognition capabilities, creating unprecedented opportunities for\nadaptive and personalized user experiences. This paper explores the integration\nof emotion detection into calendar applications, enabling user interfaces to\ndynamically respond to users' emotional states and stress levels, thereby\nenhancing both productivity and engagement. We present and evaluate two\ncomplementary approaches to emotion detection: a biometric-based method\nutilizing heart rate (HR) data extracted from electrocardiogram (ECG) signals\nprocessed through Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU)\nneural networks to predict the emotional dimensions of Valence, Arousal, and\nDominance; and a behavioral method analyzing computer activity through multiple\nmachine learning models to classify emotions based on fine-grained user\ninteractions such as mouse movements, clicks, and keystroke patterns. Our\ncomparative analysis, from real-world datasets, reveals that while both\napproaches demonstrate effectiveness, the computer activity-based method\ndelivers superior consistency and accuracy, particularly for mouse-related\ninteractions, which achieved approximately 90\\% accuracy. Furthermore, GRU\nnetworks outperformed LSTM models in the biometric approach, with Valence\nprediction reaching 84.38\\% accuracy.", "AI": {"tldr": "本文探讨了将情绪检测技术集成到日历应用中的两种方法：基于生物特征的心率数据分析和基于行为的计算机活动分析，结果显示后者在准确性和一致性上表现更优。", "motivation": "人机交互（HCI）通过情绪识别能力的发展，为自适应和个性化用户体验提供了新机遇。本研究旨在通过情绪检测技术提升日历应用的用户界面动态响应能力，从而提高用户的生产力和参与度。", "method": "研究提出了两种情绪检测方法：1）基于生物特征的方法，利用LSTM和GRU神经网络处理心电图（ECG）信号中的心率（HR）数据，预测情绪维度（效价、唤醒度和支配度）；2）基于行为的方法，通过机器学习模型分析用户的计算机活动（如鼠标移动、点击和键盘输入模式）来分类情绪。", "result": "实验结果表明，两种方法均有效，但基于计算机活动的方法在一致性和准确性上表现更优，尤其是鼠标相关交互的准确率约为90%。在生物特征方法中，GRU网络优于LSTM模型，效价预测准确率达到84.38%。", "conclusion": "基于行为的情绪检测方法在日历应用中表现出更高的实用性和准确性，为未来人机交互系统的情绪感知功能设计提供了重要参考。"}}
{"id": "2506.19322", "categories": ["math.CO", "Primary 52B20, Secondary 05A15, 68Q25"], "pdf": "https://arxiv.org/pdf/2506.19322", "abs": "https://arxiv.org/abs/2506.19322", "authors": ["Sihao Tao", "Guoce Xin", "Zihao Zhang"], "title": "Closed-Form Decomposition for Simplicial Cones and PDBarv Algorithm for Lattice Point Counting", "comment": null, "summary": "Counting lattice points within a rational polytope is a foundational problem\nwith applications across mathematics and computer science. A key approach is\nBarvinok's algorithm, which decomposes the lattice point generating function of\ncones to that of unimodular cones. However, standard implementations face\ndifficulties: the original primal method struggles with points on cone\nboundaries, while the alternative dual method can be slow for certain cone\ntypes.\n  This paper introduces two main contributions. First, We derive a closed-form\nexpression for these generating functions using arbitrary lattice point\ndecompositions, enabling more effective primal space decomposition. Second, by\ndecomposing both the cone and its dual cone starting from the side with a\nsmaller index, we develop a novel algorithm called \\textup{PDBarv}. This hybrid\napproach integrates the primal and dual Barvinok algorithms with a novel\nacceleration strategy, achieving an average computational performance\nimprovement of over 20\\% in dimension 5 and even better in higher dimensions.", "AI": {"tldr": "本文提出了一种新的混合算法PDBarv，通过结合原始和对偶Barvinok算法，并采用新的加速策略，显著提高了计算性能。", "motivation": "计算有理多面体内的格点数量是一个基础性问题，但现有方法在处理锥体边界点时存在困难，或对某些锥体类型效率低下。", "method": "首先推导了生成函数的闭式表达式，支持更有效的原始空间分解；其次通过从较小索引的一侧分解锥体及其对偶锥体，提出了混合算法PDBarv。", "result": "PDBarv算法在5维情况下平均计算性能提升超过20%，在更高维度中表现更优。", "conclusion": "PDBarv算法通过结合原始和对偶方法的优势，并引入新的加速策略，显著提升了格点计数问题的计算效率。"}}
{"id": "2506.19480", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19480", "abs": "https://arxiv.org/abs/2506.19480", "authors": ["Pasquale De Rosa", "Simon Queyrut", "Yérom-David Bromberg", "Pascal Felber", "Valerio Schiavoni"], "title": "PhishingHook: Catching Phishing Ethereum Smart Contracts leveraging EVM Opcodes", "comment": null, "summary": "The Ethereum Virtual Machine (EVM) is a decentralized computing engine. It\nenables the Ethereum blockchain to execute smart contracts and decentralized\napplications (dApps). The increasing adoption of Ethereum sparked the rise of\nphishing activities. Phishing attacks often target users through deceptive\nmeans, e.g., fake websites, wallet scams, or malicious smart contracts, aiming\nto steal sensitive information or funds. A timely detection of phishing\nactivities in the EVM is therefore crucial to preserve the user trust and\nnetwork integrity. Some state-of-the art approaches to phishing detection in\nsmart contracts rely on the online analysis of transactions and their traces.\nHowever, replaying transactions often exposes sensitive user data and\ninteractions, with several security concerns. In this work, we present\nPhishingHook, a framework that applies machine learning techniques to detect\nphishing activities in smart contracts by directly analyzing the contract's\nbytecode and its constituent opcodes. We evaluate the efficacy of such\ntechniques in identifying malicious patterns, suspicious function calls, or\nanomalous behaviors within the contract's code itself before it is deployed or\ninteracted with. We experimentally compare 16 techniques, belonging to four\nmain categories (Histogram Similarity Classifiers, Vision Models, Language\nModels and Vulnerability Detection Models), using 7,000 real-world malware\nsmart contracts. Our results demonstrate the efficiency of PhishingHook in\nperforming phishing classification systems, with about 90% average accuracy\namong all the models. We support experimental reproducibility, and we release\nour code and datasets to the research community.", "AI": {"tldr": "本文提出PhishingHook框架，通过机器学习直接分析智能合约字节码与操作码，实现钓鱼活动检测，在7000个真实恶意合约上验证了90%的平均准确率。", "motivation": "以太坊虚拟机(EVM)钓鱼攻击日益猖獗，现有基于交易回溯的检测方法存在用户数据暴露风险，亟需新型检测方案。", "method": "采用16种机器学习技术（分属直方图相似度分类器、视觉模型、语言模型和漏洞检测模型四类），直接分析未部署合约的字节码模式与异常行为特征。", "result": "在7000个真实恶意合约测试中，各模型平均准确率达90%，显著优于传统交易追踪方法。", "conclusion": "PhishingHook通过静态代码分析有效识别钓鱼合约，研究成果已开源以促进社区发展，为EVM生态安全提供新范式。"}}
{"id": "2506.19698", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2506.19698", "abs": "https://arxiv.org/abs/2506.19698", "authors": ["Zhuojun Xie", "Adam Abdin", "Yiping Fang"], "title": "Toward Decision-Oriented Prognostics: An Integrated Estimate-Optimize Framework for Predictive Maintenance", "comment": "22 pages, 5 figures, 4 tables", "summary": "Recent research increasingly integrates machine learning (ML) into predictive\nmaintenance (PdM) to reduce operational and maintenance costs in data-rich\noperational settings. However, uncertainty due to model misspecification\ncontinues to limit widespread industrial adoption. This paper proposes a PdM\nframework in which sensor-driven prognostics inform decision-making under\neconomic trade-offs within a finite decision space. We investigate two key\nquestions: (1) Does higher predictive accuracy necessarily lead to better\nmaintenance decisions? (2) If not, how can the impact of prediction errors on\ndownstream maintenance decisions be mitigated? We first demonstrate that in the\ntraditional estimate-then-optimize (ETO) framework, errors in probabilistic\nprediction can result in inconsistent and suboptimal maintenance decisions. To\naddress this, we propose an integrated estimate-optimize (IEO) framework that\njointly tunes predictive models while directly optimizing for maintenance\noutcomes. We establish theoretical finite-sample guarantees on decision\nconsistency under standard assumptions. Specifically, we develop a stochastic\nperturbation gradient descent algorithm suitable for small run-to-failure\ndatasets. Empirical evaluations on a turbofan maintenance case study show that\nthe IEO framework reduces average maintenance regret up to 22% compared to ETO.\nThis study provides a principled approach to managing prediction errors in\ndata-driven PdM. By aligning prognostic model training with maintenance\nobjectives, the IEO framework improves robustness under model misspecification\nand improves decision quality. The improvement is particularly pronounced when\nthe decision-making policy is misaligned with the decision-maker's target.\nThese findings support more reliable maintenance planning in uncertain\noperational environments.", "AI": {"tldr": "本文提出了一种集成估计-优化（IEO）框架，通过联合调整预测模型并直接优化维护结果，解决了预测性维护（PdM）中模型错误设定导致的决策不一致问题，实证显示平均维护后悔值降低达22%。", "motivation": "尽管机器学习在预测性维护中的应用日益增多，但模型错误设定带来的不确定性限制了工业界的广泛采用。研究旨在解决预测误差如何影响维护决策，并提出更稳健的解决方案。", "method": "研究对比了传统估计后优化（ETO）框架与提出的集成估计-优化（IEO）框架。IEO通过联合优化预测模型和维护目标，采用随机扰动梯度下降算法，适用于小样本失效数据集。", "result": "在涡扇发动机维护案例中，IEO框架比ETO平均减少22%的维护后悔值。理论分析证明了在标准假设下决策一致性的有限样本保证。", "conclusion": "IEO框架通过将预测模型训练与维护目标对齐，显著提升了模型错误设定下的决策质量，尤其在决策策略与目标不一致时效果更明显，为不确定环境下的可靠维护规划提供了理论支持。"}}
{"id": "2506.19290", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.19290", "abs": "https://arxiv.org/abs/2506.19290", "authors": ["Liang Zeng", "Yongcong Li", "Yuzhen Xiao", "Changshi Li", "Chris Yuhao Liu", "Rui Yan", "Tianwen Wei", "Jujie He", "Xuchen Song", "Yang Liu", "Yahui Zhou"], "title": "Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs", "comment": null, "summary": "Software engineering (SWE) has recently emerged as a crucial testbed for\nnext-generation LLM agents, demanding inherent capabilities in two critical\ndimensions: sustained iterative problem-solving (e.g., >50 interaction rounds)\nand long-context dependency resolution (e.g., >32k tokens). However, the data\ncuration process in SWE remains notoriously time-consuming, as it heavily\nrelies on manual annotation for code file filtering and the setup of dedicated\nruntime environments to execute and validate unit tests. Consequently, most\nexisting datasets are limited to only a few thousand GitHub-sourced instances.\nTo this end, we propose an incremental, automated data-curation pipeline that\nsystematically scales both the volume and diversity of SWE datasets. Our\ndataset comprises 10,169 real-world Python task instances from 2,531 distinct\nGitHub repositories, each accompanied by a task specified in natural language\nand a dedicated runtime-environment image for automated unit-test validation.\nWe have carefully curated over 8,000 successfully runtime-validated training\ntrajectories from our proposed SWE dataset. When fine-tuning the Skywork-SWE\nmodel on these trajectories, we uncover a striking data scaling phenomenon: the\ntrained model's performance for software engineering capabilities in LLMs\ncontinues to improve as the data size increases, showing no signs of\nsaturation. Notably, our Skywork-SWE model achieves 38.0% pass@1 accuracy on\nthe SWE-bench Verified benchmark without using verifiers or multiple rollouts,\nestablishing a new state-of-the-art (SOTA) among the Qwen2.5-Coder-32B-based\nLLMs built on the OpenHands agent framework. Furthermore, with the\nincorporation of test-time scaling techniques, the performance further improves\nto 47.0% accuracy, surpassing the previous SOTA results for sub-32B parameter\nmodels. We release the Skywork-SWE-32B model checkpoint to accelerate future\nresearch.", "AI": {"tldr": "本文提出了一种自动化数据整理流程，用于扩展软件工程(SWE)数据集，并训练出性能持续提升的Skywork-SWE模型，在SWE-bench基准测试中创下新纪录。", "motivation": "当前SWE领域的数据集构建依赖人工标注和运行环境配置，导致规模受限（通常仅数千个实例），无法满足LLM智能体在持续迭代问题解决和长上下文依赖处理方面的需求。", "method": "开发自动化数据整理管道，从2,531个GitHub仓库收集10,169个Python任务实例，每个实例包含自然语言任务描述和专用运行时环境镜像，并基于8,000条已验证的训练轨迹微调Skywork-SWE模型。", "result": "模型性能随数据量增加持续提升（未出现饱和），在SWE-bench基准测试中达到38.0% pass@1准确率（不使用验证器或多轮测试）。结合测试时扩展技术后，性能进一步提升至47.0%，刷新了32B参数以下模型的SOTA记录。", "conclusion": "自动化数据整理能有效扩大SWE数据集规模，基于此训练的Skywork-SWE-32B模型展现出卓越性能，其公开将推动未来研究。实验证实LLM的软件工程能力会随训练数据量持续提升。"}}
{"id": "2506.19334", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.19334", "abs": "https://arxiv.org/abs/2506.19334", "authors": ["Gabe Cunningham", "Isabel Hubard"], "title": "Polytopality criteria for the mix of polytopes and maniplexes", "comment": null, "summary": "The mix of two maniplexes is the minimal maniplex that covers both. This\nconstruction has many important applications, such as finding the smallest\nregular cover of a maniplex. If one of the maniplexes is an abstract polytope,\na natural question to ask is whether the mix is also a polytope. We describe\nhere a general criterion for the polytopality of the mix which generalizes\nseveral previously-known polytopality criteria.", "AI": {"tldr": "本文研究两个maniplex的混合是否仍为多面体，提出了一个普适性判定准则，推广了多个已知的多面体性判定标准。", "motivation": "探索两个maniplex混合后的多面体性质，特别是当其中一个为抽象多面体时，混合结果是否保持多面体结构。该问题在寻找maniplex的最小正则覆盖等应用中具有重要意义。", "method": "通过构建最小覆盖两个maniplex的混合maniplex，建立了一个通用判定框架，将多个已知的多面体性判定条件纳入统一理论体系。", "result": "提出了一个普适性准则，可判定混合maniplex的多面体性质。该准则推广了先前已知的多个特例判定标准，具有更广泛的适用性。", "conclusion": "研究成果为maniplex混合结构的多面体性判定提供了统一的理论工具，扩展了相关领域的认知边界，对组合几何与多面体理论具有重要推进作用。"}}
{"id": "2506.19563", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19563", "abs": "https://arxiv.org/abs/2506.19563", "authors": ["Jinwen He", "Yiyang Lu", "Zijin Lin", "Kai Chen", "Yue Zhao"], "title": "PrivacyXray: Detecting Privacy Breaches in LLMs through Semantic Consistency and Probability Certainty", "comment": null, "summary": "Large Language Models (LLMs) are widely used in sensitive domains, including\nhealthcare, finance, and legal services, raising concerns about potential\nprivate information leaks during inference. Privacy extraction attacks, such as\njailbreaking, expose vulnerabilities in LLMs by crafting inputs that force the\nmodels to output sensitive information. However, these attacks cannot verify\nwhether the extracted private information is accurate, as no public datasets\nexist for cross-validation, leaving a critical gap in private information\ndetection during inference. To address this, we propose PrivacyXray, a novel\nframework detecting privacy breaches by analyzing LLM inner states. Our\nanalysis reveals that LLMs exhibit higher semantic coherence and probabilistic\ncertainty when generating correct private outputs. Based on this, PrivacyXray\ndetects privacy breaches using four metrics: intra-layer and inter-layer\nsemantic similarity, token-level and sentence-level probability distributions.\nPrivacyXray addresses critical challenges in private information detection by\novercoming the lack of open-source private datasets and eliminating reliance on\nexternal data for validation. It achieves this through the synthesis of\nrealistic private data and a detection mechanism based on the inner states of\nLLMs. Experiments show that PrivacyXray achieves consistent performance, with\nan average accuracy of 92.69% across five LLMs. Compared to state-of-the-art\nmethods, PrivacyXray achieves significant improvements, with an average\naccuracy increase of 20.06%, highlighting its stability and practical utility\nin real-world applications.", "AI": {"tldr": "本文提出PrivacyXray框架，通过分析大语言模型(LLM)内部状态检测隐私泄露，无需依赖外部验证数据，在五大LLM上平均准确率达92.69%，较现有方法提升20.06%。", "motivation": "大语言模型在医疗、金融等敏感领域应用时存在隐私泄露风险，现有攻击方法无法验证泄露信息的准确性，且缺乏公开数据集进行交叉验证。", "method": "PrivacyXray通过合成真实隐私数据，利用四类指标检测隐私泄露：层内/层间语义相似度、词级/句级概率分布，分析LLM生成正确隐私信息时表现出的高语义连贯性和概率确定性。", "result": "实验表明PrivacyXray在五大LLM上平均准确率达92.69%，较现有最优方法平均提升20.06%，展现出稳定性和实际应用价值。", "conclusion": "PrivacyXray通过LLM内部状态分析解决了隐私检测中开源数据集缺失和外部验证依赖问题，为实际应用提供了有效的隐私泄露检测方案。"}}
{"id": "2506.19325", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19325", "abs": "https://arxiv.org/abs/2506.19325", "authors": ["Hyein Seo", "Taewook Hwang", "Yohan Lee", "sangkeun Jung"], "title": "FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring", "comment": "ACL 2025 (Short)", "summary": "In English education tutoring, teacher feedback is essential for guiding\nstudents. Recently, AI-based tutoring systems have emerged to assist teachers;\nhowever, these systems require high-quality and large-scale teacher feedback\ndata, which is both time-consuming and costly to generate manually. In this\nstudy, we propose FEAT, a cost-effective framework for generating teacher\nfeedback, and have constructed three complementary datasets: (1) DIRECT-Manual\n(DM), where both humans and large language models (LLMs) collaboratively\ngenerate high-quality teacher feedback, albeit at a higher cost; (2)\nDIRECT-Generated (DG), an LLM-only generated, cost-effective dataset with lower\nquality;, and (3) DIRECT-Augmented (DA), primarily based on DG with a small\nportion of DM added to enhance quality while maintaining cost-efficiency.\nExperimental results showed that incorporating a small portion of DM (5-10%)\ninto DG leads to superior performance compared to using 100% DM alone.", "AI": {"tldr": "本研究提出FEAT框架，通过三种互补数据集（DM、DG、DA）高效生成英语教育辅导中的教师反馈，实验表明少量高质量数据（DM）可显著提升生成反馈质量。", "motivation": "AI辅导系统需要高质量教师反馈数据，但人工生成成本高昂。研究旨在开发一种成本效益高的反馈生成框架。", "method": "构建三种数据集：1) DM（人工+LLM协作生成高质量数据）；2) DG（纯LLM生成低成本数据）；3) DA（DG为主，混入少量DM提升质量）。", "result": "实验显示：DG中混入5-10%的DM数据后，性能优于使用100%纯DM数据。", "conclusion": "FEAT框架通过混合少量高质量数据，能以低成本生成优质教师反馈，为AI教育系统提供可行解决方案。"}}
{"id": "2506.19624", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19624", "abs": "https://arxiv.org/abs/2506.19624", "authors": ["Isaac David", "Liyi Zhou", "Dawn Song", "Arthur Gervais", "Kaihua Qin"], "title": "Decompiling Smart Contracts with a Large Language Model", "comment": null, "summary": "The widespread lack of broad source code verification on blockchain explorers\nsuch as Etherscan, where despite 78,047,845 smart contracts deployed on\nEthereum (as of May 26, 2025), a mere 767,520 (< 1%) are open source, presents\na severe impediment to blockchain security. This opacity necessitates the\nautomated semantic analysis of on-chain smart contract bytecode, a fundamental\nresearch challenge with direct implications for identifying vulnerabilities and\nunderstanding malicious behavior. Prevailing decompilers struggle to reverse\nbytecode in a readable manner, often yielding convoluted code that critically\nhampers vulnerability analysis and thwarts efforts to dissect contract\nfunctionalities for security auditing.\n  This paper addresses this challenge by introducing a pioneering decompilation\npipeline that, for the first time, successfully leverages Large Language Models\n(LLMs) to transform Ethereum Virtual Machine (EVM) bytecode into human-readable\nand semantically faithful Solidity code. Our novel methodology first employs\nrigorous static program analysis to convert bytecode into a structured\nthree-address code (TAC) representation. This intermediate representation then\nguides a Llama-3.2-3B model, specifically fine-tuned on a comprehensive dataset\nof 238,446 TAC-to-Solidity function pairs, to generate high-quality Solidity.\nThis approach uniquely recovers meaningful variable names, intricate control\nflow, and precise function signatures. Our extensive empirical evaluation\ndemonstrates a significant leap beyond traditional decompilers, achieving an\naverage semantic similarity of 0.82 with original source and markedly superior\nreadability. The practical viability and effectiveness of our research are\ndemonstrated through its implementation in a publicly accessible system,\navailable at https://evmdecompiler.com.", "AI": {"tldr": "本文提出了一种创新的反编译管道，首次成功利用大型语言模型（LLM）将以太坊虚拟机（EVM）字节码转换为可读且语义准确的Solidity代码，显著提升了区块链安全分析的效率。", "motivation": "当前区块链浏览器（如Etherscan）上绝大多数智能合约未开源（<1%），导致安全审计困难。传统反编译器生成的代码可读性差，严重阻碍漏洞分析和功能理解。", "method": "采用静态程序分析将字节码转换为结构化三地址码（TAC），再通过微调的Llama-3.2-3B模型（训练于238,446个TAC-Solidity函数对数据集）生成高质量Solidity代码，恢复变量名、控制流和函数签名。", "result": "实验表明该方法显著优于传统反编译器，平均语义相似度达0.82（与原代码），并实现卓越可读性。已部署于公开系统evmdecompiler.com。", "conclusion": "该研究为区块链安全提供了突破性解决方案，通过LLM驱动的精准反编译技术，有效解决了字节码可读性与语义保真度的核心挑战。"}}
{"id": "2506.19359", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19359", "abs": "https://arxiv.org/abs/2506.19359", "authors": ["Debosmita Bhaumik", "Julian Togelius", "Georgios N. Yannakakis", "Ahmed Khalifa"], "title": "Evolutionary Level Repair", "comment": null, "summary": "We address the problem of game level repair, which consists of taking a\ndesigned but non-functional game level and making it functional. This might\nconsist of ensuring the completeness of the level, reachability of objects, or\nother performance characteristics. The repair problem may also be constrained\nin that it can only make a small number of changes to the level. We investigate\nsearch-based solutions to the level repair problem, particularly using\nevolutionary and quality-diversity algorithms, with good results. This level\nrepair method is applied to levels generated using a machine learning-based\nprocedural content generation (PCGML) method that generates stylistically\nappropriate but frequently broken levels. This combination of PCGML for\ngeneration and search-based methods for repair shows great promise as a hybrid\nprocedural content generation (PCG) method.", "AI": {"tldr": "本文提出了一种基于搜索的游戏关卡修复方法，结合进化算法和多样性质量算法，有效修复由机器学习生成的风格一致但常存在缺陷的关卡。", "motivation": "解决游戏关卡设计中的功能性问题，如关卡完整性、对象可达性等，同时限制修复过程中的改动次数。", "method": "采用基于搜索的解决方案，特别是进化算法和多样性质量算法，对机器学习生成的关卡进行修复。", "result": "该方法在修复由机器学习生成的风格一致但常存在缺陷的关卡方面表现出色。", "conclusion": "结合机器学习生成和基于搜索的修复方法，展现出作为混合程序化内容生成方法的巨大潜力。"}}
{"id": "2506.19443", "categories": ["math.CO", "math.QA", "52B11, 52B40, 05E10, 14M15, 13F60"], "pdf": "https://arxiv.org/pdf/2506.19443", "abs": "https://arxiv.org/abs/2506.19443", "authors": ["Jian-Rong Li", "Ayush Kumar Tewari"], "title": "From dual canonical bases to positroidal subdivisions", "comment": null, "summary": "The Grassmannian cluster algebra $\\mathbb{C}[\\text{Gr}(k, n)]$ admits a\ndistinguished basis known as the dual canonical basis, whose elements\ncorrespond to rectangular semi-standard Young tableaux with $k$ rows and with\nentries in $[n]$. We establish that each such tableau induces a positroidal\nsubdivision of the hypersimplex $\\Delta(k,n)$ via a map introduced by Speyer\nand Williams. For $\\text{Gr}(2,n)$, we prove that non-frozen prime tableaux\ncorrespond precisely to the coarsest positroidal subdivisions of $\\Delta(2,n)$.\nFurthermore, we present computational evidence extending these results to\n$k>2$. In the process, we formulate a conjectural formula for the number of\nsplit positroidal subdivisions of $\\Delta(k,n)$ for any $k \\ge 2$ and explore\nthe deep connections between the polyhedral combinatorics of $\\Delta(k,n)$ and\nthe dual canonical basis of $\\mathbb{C}[\\text{Gr}(k, n)]$.", "AI": {"tldr": "该研究探讨了Grassmannian簇代数$\\mathbb{C}[\\text{Gr}(k, n)]$的双典范基与超单纯形$\\Delta(k,n)$的正向拟阵细分之间的深刻联系，特别关注了$\\text{Gr}(2,n)$的情况，并提出了关于$\\Delta(k,n)$分裂正向拟阵细分数量的猜想公式。", "motivation": "研究动机在于理解Grassmannian簇代数的双典范基与超单纯形$\\Delta(k,n)$的几何结构之间的联系，特别是通过半标准Young表与正向拟阵细分的对应关系，揭示两者之间的深层组合性质。", "method": "研究方法包括利用Speyer和Williams引入的映射，将半标准Young表与正向拟阵细分联系起来，并通过计算实验验证$k>2$时的结果。此外，还提出了一个关于$\\Delta(k,n)$分裂正向拟阵细分数量的猜想公式。", "result": "研究结果表明，对于$\\text{Gr}(2,n)$，非冻结素表恰好对应于$\\Delta(2,n)$的最粗正向拟阵细分。计算证据进一步支持这些结果可以推广到$k>2$的情况。", "conclusion": "结论强调了$\\Delta(k,n)$的多面体组合学与$\\mathbb{C}[\\text{Gr}(k, n)]$的双典范基之间的深刻联系，并提出了未来研究的方向，特别是关于分裂正向拟阵细分数量的猜想。"}}
{"id": "2506.19676", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19676", "abs": "https://arxiv.org/abs/2506.19676", "authors": ["Dezhang Kong", "Shi Lin", "Zhenhua Xu", "Zhebo Wang", "Minghao Li", "Yufeng Li", "Yilun Zhang", "Zeyang Sha", "Yuyuan Li", "Changting Lin", "Xun Wang", "Xuan Liu", "Muhammad Khurram Khan", "Ningyu Zhang", "Chaochao Chen", "Meng Han"], "title": "A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures", "comment": null, "summary": "In recent years, Large-Language-Model-driven AI agents have exhibited\nunprecedented intelligence, flexibility, and adaptability, and are rapidly\nchanging human production and lifestyle. Nowadays, agents are undergoing a new\nround of evolution. They no longer act as an isolated island like LLMs.\nInstead, they start to communicate with diverse external entities, such as\nother agents and tools, to collectively perform more complex tasks. Under this\ntrend, agent communication is regarded as a foundational pillar of the future\nAI ecosystem, and many organizations intensively begin to design related\ncommunication protocols (e.g., Anthropic's MCP and Google's A2A) within the\nrecent few months. However, this new field exposes significant security hazard,\nwhich can cause severe damage to real-world scenarios. To help researchers to\nquickly figure out this promising topic and benefit the future agent\ncommunication development, this paper presents a comprehensive survey of agent\ncommunication security. More precisely, we first present a clear definition of\nagent communication and categorize the entire lifecyle of agent communication\ninto three stages: user-agent interaction, agent-agent communication, and\nagent-environment communication. Next, for each communication phase, we dissect\nrelated protocols and analyze its security risks according to the communication\ncharacteristics. Then, we summarize and outlook on the possible defense\ncountermeasures for each risk. Finally, we discuss open issues and future\ndirections in this promising research field.", "AI": {"tldr": "本文综述了AI代理通信安全的研究现状，将代理通信生命周期分为三个阶段，分析了各阶段的安全风险及防御措施，并探讨了未来研究方向。", "motivation": "随着大语言模型驱动的AI代理展现出前所未有的智能和灵活性，代理间通信成为未来AI生态的基础支柱，但这一新兴领域存在重大安全隐患，亟需系统研究。", "method": "作者首先明确定义了代理通信，将其生命周期分为用户-代理交互、代理-代理通信和代理-环境通信三个阶段，随后分析各阶段协议特性及安全风险，并总结可能的防御对策。", "result": "研究揭示了不同通信阶段（如Anthropic的MCP和Google的A2A协议）存在的安全隐患，并针对性地提出了防御措施的分类框架。", "conclusion": "本文系统梳理了代理通信安全的研究脉络，指出了当前开放性问题，为未来构建安全的AI代理通信生态系统提供了重要参考方向。"}}
{"id": "2506.19385", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19385", "abs": "https://arxiv.org/abs/2506.19385", "authors": ["Ziqi Zhu", "Tao Hu", "Honglong Zhang", "Dan Yang", "HanGeng Chen", "Mengran Zhang", "Xilun Chen"], "title": "Conversational Intent-Driven GraphRAG: Enhancing Multi-Turn Dialogue Systems through Adaptive Dual-Retrieval of Flow Patterns and Context Semantics", "comment": null, "summary": "We present CID-GraphRAG (Conversational Intent-Driven Graph Retrieval\nAugmented Generation), a novel framework that addresses the limitations of\nexisting dialogue systems in maintaining both contextual coherence and\ngoal-oriented progression in multi-turn customer service conversations. Unlike\ntraditional RAG systems that rely solely on semantic similarity (Conversation\nRAG) or standard knowledge graphs (GraphRAG), CID-GraphRAG constructs dynamic\nintent transition graphs from goal achieved historical dialogues and implements\na dual-retrieval mechanism that adaptively balances intent-based graph\ntraversal with semantic search. This approach enables the system to\nsimultaneously leverage both conversional intent flow patterns and contextual\nsemantics, significantly improving retrieval quality and response quality. In\nextensive experiments on real-world customer service dialogues, we employ both\nautomatic metrics and LLM-as-judge assessments, demonstrating that CID-GraphRAG\nsignificantly outperforms both semantic-based Conversation RAG and intent-based\nGraphRAG baselines across all evaluation criteria. Quantitatively, CID-GraphRAG\ndemonstrates substantial improvements over Conversation RAG across automatic\nmetrics, with relative gains of 11% in BLEU, 5% in ROUGE-L, 6% in METEOR, and\nmost notably, a 58% improvement in response quality according to LLM-as-judge\nevaluations. These results demonstrate that the integration of intent\ntransition structures with semantic retrieval creates a synergistic effect that\nneither approach achieves independently, establishing CID-GraphRAG as an\neffective framework for addressing the challenges of maintaining contextual\ncoherence and goal-oriented progression in knowledge-intensive multi-turn\ndialogues.", "AI": {"tldr": "CID-GraphRAG是一种新型对话系统框架，通过动态意图转移图和双检索机制，显著提升了多轮客服对话的上下文连贯性和目标导向性。", "motivation": "现有对话系统在多轮客服对话中难以同时保持上下文连贯和目标导向，CID-GraphRAG旨在解决这一局限性。", "method": "CID-GraphRAG构建动态意图转移图，并采用双检索机制，结合意图图遍历和语义搜索，以平衡意图流模式和上下文语义。", "result": "实验表明，CID-GraphRAG在自动指标和LLM评估中均显著优于传统方法，BLEU提升11%，ROUGE-L提升5%，METEOR提升6%，响应质量提升58%。", "conclusion": "CID-GraphRAG通过整合意图转移结构和语义检索，实现了协同效应，有效解决了知识密集型多轮对话中的挑战。"}}
{"id": "2506.19448", "categories": ["math.CO", "math.AT", "05C82, 55U10, 55U05"], "pdf": "https://arxiv.org/pdf/2506.19448", "abs": "https://arxiv.org/abs/2506.19448", "authors": ["Udit Raj", "Slobodan Maletić", "Sudeepto Bhattacharya"], "title": "Study of higher-order interactions in unweighted, undirected networks using persistent homology", "comment": null, "summary": "Persistent homology has been studied to better understand the structural\nproperties and topology features of weighted networks. It can reveal hidden\nlayers of information about the higher-order structures formed by non-pairwise\ninteractions in a network. Studying of higher-order interactions (HoIs) of a\nsystem provides a more comprehensive understanding of the complex system;\nmoreover, it is a more precise depiction of the system as many complex systems,\nsuch as ecological systems and biological systems, etc., demonstrate HoIs. In\nthis study, the weighted simplicial adjacency matrix has been constructed using\nthe concept of adjacency strength of simplices in a clique complex obtained\nfrom an unweighted, undirected network. This weighted simplicial adjacency\nmatrix is thus used to calculate the global measure, which is called\ngeneralised weighted betweenness centrality, which further helps us in\ncalculating the persistent homology on the given simplicial complex by\nconstructing a filtration on it. Moreover, a local measure called maximal\ngeneralised degree centrality has also been established for better\nunderstanding of the network topology of the studied simplicial complex. All\nthe generalizations given in this work can be reduced to the graph-theoretic\ncase. i.e., for a simplicial complex of dimension 1. Three different filtration\nschemes for constructing the sequence of simplicial complexes have been given\nwith the help of both global and local measures, and by using these measures,\nthe topology of higher-order structures of the studied network due to the\ninteractions of their vertices has been compared. Further, the illustration of\nestablished definitions has been given using a real-life network by calculating\nBetti numbers up to dimension two.", "AI": {"tldr": "该研究通过构建加权单纯邻接矩阵和广义加权介数中心性，提出了计算持续同调的新方法，并建立了最大广义度中心性以分析网络拓扑结构。", "motivation": "研究高阶相互作用（HoIs）能更全面地理解复杂系统（如生态系统和生物系统）的结构特性，持续同调能揭示网络中非成对相互作用形成的高阶结构信息。", "method": "利用无向无权网络中的团复形构建加权单纯邻接矩阵，计算广义加权介数中心性，并建立最大广义度中心性，提出三种基于全局和局部度量的过滤方案。", "result": "通过实际网络计算了二维以内的Betti数，验证了所提方法的有效性，并比较了不同顶点相互作用形成的高阶结构拓扑。", "conclusion": "该方法可推广至图论情形（一维单纯复形），为分析复杂系统的高阶相互作用提供了新的拓扑视角和计算工具。"}}
{"id": "2506.19802", "categories": ["cs.CR", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.19802", "abs": "https://arxiv.org/abs/2506.19802", "authors": ["Xin Fan Guo", "Albert Merono Penuela", "Sergio Maffeis", "Fabio Pierazzi"], "title": "KnowML: Improving Generalization of ML-NIDS with Attack Knowledge Graphs", "comment": null, "summary": "Despite extensive research on Machine Learning-based Network Intrusion\nDetection Systems (ML-NIDS), their capability to detect diverse attack variants\nremains uncertain. Prior studies have largely relied on homogeneous datasets,\nwhich artificially inflate performance scores and offer a false sense of\nsecurity. Designing systems that can effectively detect a wide range of attack\nvariants remains a significant challenge. The progress of ML-NIDS continues to\ndepend heavily on human expertise, which can embed subjective judgments of\nsystem designers into the model, potentially hindering its ability to\ngeneralize across diverse attack types.\n  To address this gap, we propose KnowML, a framework for knowledge-guided\nmachine learning that integrates attack knowledge into ML-NIDS. KnowML\nsystematically explores the threat landscape by leveraging Large Language\nModels (LLMs) to perform automated analysis of attack implementations. It\nconstructs a unified Knowledge Graph (KG) of attack strategies, on which it\napplies symbolic reasoning to generate KG-Augmented Input, embedding domain\nknowledge directly into the design process of ML-NIDS.\n  We evaluate KnowML on 28 realistic attack variants, of which 10 are newly\ncollected for this study. Our findings reveal that baseline ML-NIDS models fail\nto detect several variants entirely, achieving F1 scores as low as 0 %. In\ncontrast, our knowledge-guided approach achieves up to 99 % F1 score while\nmaintaining a False Positive Rate below 0.1 %.", "AI": {"tldr": "提出KnowML框架，通过知识图谱和LLM增强机器学习入侵检测系统，显著提升对多样化攻击变体的检测能力。", "motivation": "现有ML-NIDS依赖同质数据集导致性能虚高，且过度依赖人类专家经验，难以泛化检测多样化攻击变体。", "method": "利用LLM自动分析攻击实现，构建攻击策略知识图谱，通过符号推理生成知识增强输入嵌入ML-NIDS设计。", "result": "在28种攻击变体测试中，基线模型F1最低为0%，而KnowML达到99% F1且误报率低于0.1%。", "conclusion": "知识引导的机器学习框架能有效解决攻击变体检测难题，为ML-NIDS设计提供自动化领域知识注入路径。"}}
{"id": "2506.19408", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.19408", "abs": "https://arxiv.org/abs/2506.19408", "authors": ["Alexandre Chapin", "Emmanuel Dellandrea", "Liming Chen"], "title": "Is an object-centric representation beneficial for robotic manipulation ?", "comment": null, "summary": "Object-centric representation (OCR) has recently become a subject of interest\nin the computer vision community for learning a structured representation of\nimages and videos. It has been several times presented as a potential way to\nimprove data-efficiency and generalization capabilities to learn an agent on\ndownstream tasks. However, most existing work only evaluates such models on\nscene decomposition, without any notion of reasoning over the learned\nrepresentation. Robotic manipulation tasks generally involve multi-object\nenvironments with potential inter-object interaction. We thus argue that they\nare a very interesting playground to really evaluate the potential of existing\nobject-centric work. To do so, we create several robotic manipulation tasks in\nsimulated environments involving multiple objects (several distractors, the\nrobot, etc.) and a high-level of randomization (object positions, colors,\nshapes, background, initial positions, etc.). We then evaluate one classical\nobject-centric method across several generalization scenarios and compare its\nresults against several state-of-the-art hollistic representations. Our results\nexhibit that existing methods are prone to failure in difficult scenarios\ninvolving complex scene structures, whereas object-centric methods help\novercome these challenges.", "AI": {"tldr": "本文探讨了目标中心表示（OCR）在机器人操作任务中的潜力，通过模拟环境中的多对象交互场景，比较了OCR方法与整体表示方法的性能差异。", "motivation": "目标中心表示（OCR）被认为能提升数据效率和泛化能力，但现有研究多局限于场景分解，缺乏对学习表示推理能力的评估。机器人操作任务因涉及多对象交互，成为验证OCR潜力的理想场景。", "method": "研究创建了多个模拟机器人操作任务，包含多对象环境和高随机化（位置、颜色、形状等），并评估一种经典OCR方法在多种泛化场景下的表现，与先进整体表示方法进行对比。", "result": "实验结果表明，现有方法在复杂场景结构中容易失败，而OCR方法能有效克服这些挑战。", "conclusion": "目标中心表示在复杂机器人操作任务中展现出优于整体表示的泛化能力，为未来研究提供了重要方向。"}}
{"id": "2506.19493", "categories": ["math.CO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2506.19493", "abs": "https://arxiv.org/abs/2506.19493", "authors": ["Philipp Böll", "Pamela Fleischmann", "Annika Huch", "Jana Kreiß", "Tim Löck", "Kajus Park", "Max Wiedenhöft"], "title": "Word-Representable Graphs and Locality of Words", "comment": null, "summary": "In this work, we investigate the relationship between $k$-repre\\-sentable\ngraphs and graphs representable by $k$-local words. In particular, we show that\nevery graph representable by a $k$-local word is $(k+1)$-representable. A\nprevious result about graphs represented by $1$-local words is revisited with\nnew insights. Moreover, we investigate both classes of graphs w.r.t. hereditary\nand in particular the speed as a measure. We prove that the latter ones belong\nto the factorial layer and that the graphs in this classes have bounded\nclique-width.", "AI": {"tldr": "本文研究了$k$-可表示图与$k$-局部词可表示图的关系，证明了后者是$(k+1)$-可表示的，并探讨了这两类图的遗传性质与速度度量。", "motivation": "研究$k$-可表示图与$k$-局部词可表示图之间的关系，以深化对图表示理论的理解，并探索其遗传性质与计算复杂性。", "method": "通过理论分析，重新审视了$1$-局部词可表示图的结果，并研究了这两类图在遗传性质和速度度量方面的特性。", "result": "证明了$k$-局部词可表示图是$(k+1)$-可表示的，且这些图属于阶乘层并具有有界的团宽度。", "conclusion": "本研究扩展了对图表示理论的认识，证明了$k$-局部词可表示图的$(k+1)$-可表示性，并揭示了其在遗传性质和计算复杂性方面的重要特性。"}}
{"id": "2506.19836", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19836", "abs": "https://arxiv.org/abs/2506.19836", "authors": ["Saeed Mahloujifar", "Chuan Guo", "G. Edward Suh", "Kamalika Chaudhuri"], "title": "Machine Learning with Privacy for Protected Attributes", "comment": null, "summary": "Differential privacy (DP) has become the standard for private data analysis.\nCertain machine learning applications only require privacy protection for\nspecific protected attributes. Using naive variants of differential privacy in\nsuch use cases can result in unnecessary degradation of utility. In this work,\nwe refine the definition of DP to create a more general and flexible framework\nthat we call feature differential privacy (FDP). Our definition is\nsimulation-based and allows for both addition/removal and replacement variants\nof privacy, and can handle arbitrary and adaptive separation of protected and\nnon-protected features. We prove the properties of FDP, such as adaptive\ncomposition, and demonstrate its implications for limiting attribute inference\nattacks. We also propose a modification of the standard DP-SGD algorithm that\nsatisfies FDP while leveraging desirable properties such as amplification via\nsub-sampling. We apply our framework to various machine learning tasks and show\nthat it can significantly improve the utility of DP-trained models when public\nfeatures are available. For example, we train diffusion models on the AFHQ\ndataset of animal faces and observe a drastic improvement in FID compared to\nDP, from 286.7 to 101.9 at $\\epsilon=8$, assuming that the blurred version of a\ntraining image is available as a public feature. Overall, our work provides a\nnew approach to private data analysis that can help reduce the utility cost of\nDP while still providing strong privacy guarantees.", "AI": {"tldr": "本文提出特征差分隐私(FDP)框架，针对特定保护属性优化隐私分析，显著提升模型效用。通过改进DP-SGD算法并在AFHQ数据集验证，FID从286.7降至101.9（$\\epsilon=8$）。", "motivation": "传统差分隐私(DP)对所有特征实施统一保护，导致非敏感特征的效用损失。当仅需保护特定属性时，需要更灵活的隐私框架。", "method": "1) 提出基于模拟的特征差分隐私(FDP)定义\\n2) 支持增删/替换两种隐私变体\\n3) 改进DP-SGD算法实现FDP\\n4) 利用子采样进行隐私放大", "result": "在AFHQ动物面部数据集上：\\n- 标准DP的FID=286.7\\n- FDP框架下FID降至101.9（$\\epsilon=8$）\\n- 有效抵抗属性推断攻击", "conclusion": "FDP框架在保证强隐私的前提下，通过区分保护/非保护特征显著提升模型效用，为隐私数据分析提供新范式。"}}
{"id": "2506.19410", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19410", "abs": "https://arxiv.org/abs/2506.19410", "authors": ["Anas Hattay", "Mayara Ayat", "Fred Ngole Mboula"], "title": "Unsupervised Dataset Dictionary Learning for domain shift robust clustering: application to sitting posture identification", "comment": null, "summary": "This paper introduces a novel approach, Unsupervised Dataset Dictionary\nLearning (U-DaDiL), for totally unsupervised robust clustering applied to\nsitting posture identification. Traditional methods often lack adaptability to\ndiverse datasets and suffer from domain shift issues. U-DaDiL addresses these\nchallenges by aligning distributions from different datasets using Wasserstein\nbarycenter based representation. Experimental evaluations on the Office31\ndataset demonstrate significant improvements in cluster alignment accuracy.\nThis work also presents a promising step for addressing domain shift and robust\nclustering for unsupervised sitting posture identification", "AI": {"tldr": "本文提出了一种名为U-DaDiL的无监督学习方法，用于坐姿识别的鲁棒聚类，通过Wasserstein重心表示解决数据集间的分布对齐问题，在Office31数据集上验证了其有效性。", "motivation": "传统方法在多样数据集上适应性差且存在域偏移问题，U-DaDiL旨在解决这些挑战，提升无监督坐姿识别的鲁棒性。", "method": "采用基于Wasserstein重心的表示方法，实现不同数据集间的分布对齐，进行完全无监督的鲁棒聚类。", "result": "在Office31数据集上的实验表明，该方法显著提高了聚类对齐的准确性。", "conclusion": "U-DaDiL为无监督坐姿识别中的域偏移和鲁棒聚类问题提供了有效的解决方案，展现了良好的应用前景。"}}
{"id": "2506.19580", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.19580", "abs": "https://arxiv.org/abs/2506.19580", "authors": ["Ran Chen", "Baogang Xu", "Yian Xu"], "title": "The optimal binding function for (cap, even hole)-free graphs", "comment": null, "summary": "A {\\em hole} is an induced cycle of length at least 4, an {\\em even hole} is\na hole of even length, and a {\\em cap} is a graph obtained from a hole by\nadding an additional vertex which is adjacent exactly to two adjacent vertices\nof the hole. A graph $G$ obtained from a graph $H$ by blowing up all the\nvertices into cliques is said to be a clique blowup of $H$. Let $p, q$ be two\npositive integers with $p>2q$, let $F$ be a triangle-free graph, and let $G'$\nbe a clique blowup of $F$ with $\\omega(G')\\leq\\max\\{\\frac{2q(p-q-2)}{p-2q},\n2q\\}$. In this paper, we prove that for any clique blowup $G$ of $F$,\n$\\chi(G)\\leq\\lceil\\frac{p}{2q}\\omega(G)\\rceil$ if and only if\n$\\chi(G')\\leq\\lceil\\frac{p}{2q}\\omega(G')\\rceil$. As its consequences, we show\nthat every (cap, even hole)-free graph $G$ satisfies\n$\\chi(G)\\leq\\lceil\\frac{5}{4}\\omega(G)\\rceil$, which affirmatively answers a\nquestion of Cameron {\\em et al.} \\cite{CdHV2018}, we also show that every (cap,\neven hole, 5-hole)-free graph $G$ satisfies\n$\\chi(G)\\leq\\lceil\\frac{7}{6}\\omega(G)\\rceil$, and the bound is reachable.", "AI": {"tldr": "该论文研究了特定图类的着色问题，证明了在特定条件下，图的色数与其团数之间存在明确关系，并解决了Cameron等人的一个开放性问题。", "motivation": "研究图的着色性质，特别是针对不含特定子图（如cap、偶洞）的图类，解决Cameron等人提出的关于色数上界的问题。", "method": "通过定义洞、偶洞和cap等图结构，引入团膨胀的概念，并利用数学归纳和不等式推导，证明了色数与团数之间的关系。", "result": "证明了对于不含cap和偶洞的图，色数满足$\\chi(G)\\leq\\lceil\\frac{5}{4}\\omega(G)\\rceil$；对于不含cap、偶洞和5-洞的图，色数满足$\\chi(G)\\leq\\lceil\\frac{7}{6}\\omega(G)\\rceil$，且该界限可达。", "conclusion": "该研究不仅解决了Cameron等人的问题，还为特定图类的着色性质提供了新的理论结果，展示了团膨胀方法在图论中的有效性。"}}
{"id": "2506.19420", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19420", "abs": "https://arxiv.org/abs/2506.19420", "authors": ["Yazhou Zhang", "Chunwang Zou", "Bo Wang", "Jing Qin"], "title": "Commander-GPT: Dividing and Routing for Multimodal Sarcasm Detection", "comment": null, "summary": "Multimodal sarcasm understanding is a high-order cognitive task. Although\nlarge language models (LLMs) have shown impressive performance on many\ndownstream NLP tasks, growing evidence suggests that they struggle with sarcasm\nunderstanding. In this paper, we propose Commander-GPT, a modular decision\nrouting framework inspired by military command theory. Rather than relying on a\nsingle LLM's capability, Commander-GPT orchestrates a team of specialized LLM\nagents where each agent will be selectively assigned to a focused sub-task such\nas context modeling, sentiment analysis, etc. Their outputs are then routed\nback to the commander, which integrates the information and performs the final\nsarcasm judgment. To coordinate these agents, we introduce three types of\ncentralized commanders: (1) a trained lightweight encoder-based commander\n(e.g., multi-modal BERT); (2) four small autoregressive language models,\nserving as moderately capable commanders (e.g., DeepSeek-VL); (3) two large\nLLM-based commander (Gemini Pro and GPT-4o) that performs task routing, output\naggregation, and sarcasm decision-making in a zero-shot fashion. We evaluate\nCommander-GPT on the MMSD and MMSD 2.0 benchmarks, comparing five prompting\nstrategies. Experimental results show that our framework achieves 4.4% and\n11.7% improvement in F1 score over state-of-the-art (SoTA) baselines on\naverage, demonstrating its effectiveness.", "AI": {"tldr": "本文提出Commander-GPT框架，通过军事指挥理论启发的模块化决策路由机制，协调多个专用LLM代理完成多模态讽刺理解任务，在MMSD基准上显著超越现有方法。", "motivation": "尽管大语言模型(LLM)在多数NLP任务表现优异，但现有证据表明其难以理解讽刺这种高阶认知任务。", "method": "采用军事指挥理论框架：1) 部署专注子任务的特化代理(如上下文建模、情感分析)；2) 设计三类中央指挥官(轻量编码器、自回归小模型、大模型零样本路由)；3) 通过信息整合实现最终讽刺判断。", "result": "在MMSD和MMSD 2.0基准测试中，相比现有最优模型平均提升F1分数4.4%和11.7%，验证了五类提示策略的有效性。", "conclusion": "模块化任务路由框架能有效弥补单一LLM的认知局限，为复杂多模态语义理解提供新范式。"}}
{"id": "2506.19605", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.19605", "abs": "https://arxiv.org/abs/2506.19605", "authors": ["Ming Hsuan Kang", "Yu Hsuan Hsieh"], "title": "De Bruijn Tori Without Zeros: A Field-Theoretic Perspective", "comment": null, "summary": "We present an algebraic construction of trace-based De Bruijn tori over\nfinite fields, focusing on the nonzero variant that omits the all-zero pattern.\nThe construction arranges nonzero field elements on a toroidal grid using two\nmultiplicatively independent generators, with values obtained by applying a\nfixed linear map, typically the field trace.\n  We characterize sampling patterns as subsets whose associated field elements\nform an \\( \\mathbb{F}_p \\)-basis, and show that column structures correspond to\ncyclic shifts of De Bruijn sequences determined by irreducible polynomials over\nsubfields. Recursive update rules based on multiplicative translations enable\nefficient computation.", "AI": {"tldr": "本文提出了一种基于有限域上迹函数的非零De Bruijn环面代数构造方法，通过乘法独立生成元排列非零域元素，并建立了采样模式与$\\mathbb{F}_p$-基的关联性。", "motivation": "研究旨在构建省略全零模式的非零De Bruijn环面，为有限域上的结构化排列提供理论框架与应用基础。", "method": "采用两个乘法独立生成元在环面网格上排列非零域元素，利用固定线性映射（通常为域迹）获取值，并通过基于乘法平移的递归更新规则实现高效计算。", "result": "证明了采样模式对应的域元素构成$\\mathbb{F}_p$-基，且列结构由子域上不可约多项式确定的De Bruijn序列循环移位产生。", "conclusion": "该代数构造不仅揭示了De Bruijn环面与域论的内在联系，其递归计算机制也为实际应用提供了高效实现途径。"}}
{"id": "2506.19466", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19466", "abs": "https://arxiv.org/abs/2506.19466", "authors": ["Cheng Li", "Jiexiong Liu", "Yixuan Chen", "Qihang Zhou", "KunLun Meta"], "title": "KunLunBaizeRAG: Reinforcement Learning Driven Inference Performance Leap for Large Language Models", "comment": null, "summary": "This paper introduces KunLunBaizeRAG, a reinforcement learning-driven\nreasoning framework designed to enhance the reasoning capabilities of large\nlanguage models (LLMs) in complex multi-hop question-answering tasks. The\nframework addresses key limitations of traditional RAG, such as retrieval\ndrift, information redundancy, and strategy rigidity. Key innovations include\nthe RAG-driven Reasoning Alignment (RDRA) mechanism, the Search-Think Iterative\nEnhancement (STIE) mechanism, the Network-Local Intelligent Routing (NLR)\nmechanism, and a progressive hybrid training strategy. Experimental results\ndemonstrate significant improvements in exact match (EM) and LLM-judged score\n(LJ) across four benchmarks, highlighting the framework's robustness and\neffectiveness in complex reasoning scenarios.", "AI": {"tldr": "本文提出KunLunBaizeRAG框架，通过强化学习增强大语言模型在复杂多跳问答任务中的推理能力，解决了传统RAG的检索漂移、信息冗余和策略僵化等问题。", "motivation": "传统检索增强生成(RAG)在复杂推理任务中存在检索漂移、信息冗余和策略僵化等局限性，需要新的方法提升大语言模型的推理性能。", "method": "框架包含四大创新机制：RAG驱动的推理对齐(RDRA)、搜索-思考迭代增强(STIE)、网络-本地智能路由(NLR)，以及渐进式混合训练策略。", "result": "实验表明，该框架在四个基准测试中的精确匹配(EM)和LLM评判得分(LJ)均有显著提升，验证了其在复杂推理场景中的鲁棒性和有效性。", "conclusion": "KunLunBaizeRAG框架通过创新机制有效提升了LLM的复杂推理能力，为多跳问答任务提供了可靠的解决方案。"}}
{"id": "2506.19638", "categories": ["math.CO", "math.AT", "52C35, 14N20"], "pdf": "https://arxiv.org/pdf/2506.19638", "abs": "https://arxiv.org/abs/2506.19638", "authors": ["Luca Moci", "Roberto Pagaria", "Maddalena Pismataro", "Alejandro Vargas"], "title": "Elliptic arrangements of complex multiplication type", "comment": "25 pages", "summary": "We provide a natural definition of an elliptic arrangement, extending the\nclassical framework to an elliptic curve E with complex multiplication. We\nanalyse the intersections of elements of the arrangement and their connected\ncomponents as End(E)-modules. Furthermore, we prove that the combinatorial data\nof elliptic arrangements define both an arithmetic matroid and a matroid over\nthe ring End(E). In this way, we obtain a class of arithmetic matroids that is\ndifferent from the class of arithmetic matroids realizable via toric\narrangements. Finally, we show that the Euler characteristic of the complement\nis an evaluation of the arithmetic Tutte polynomial.", "AI": {"tldr": "本文提出了一种椭圆排列的自然定义，将其扩展到具有复乘的椭圆曲线E上，分析了排列元素的交集及其连通分量作为End(E)-模的性质，证明了椭圆排列的组合数据同时定义了算术拟阵和环End(E)上的拟阵，获得了一类不同于环面排列实现的算术拟阵，并证明了补集的欧拉示性数是算术Tutte多项式的求值。", "motivation": "扩展经典椭圆排列框架至具有复乘的椭圆曲线，研究其组合与代数结构，探索新型算术拟阵的构造。", "method": "通过分析椭圆排列元素的交集连通性（作为End(E)-模），建立与算术拟阵及环上拟阵的关联，并计算补集欧拉示性数。", "result": "证明了椭圆排列数据可同时定义算术拟阵和End(E)-环拟阵，其补集欧拉示性数等于算术Tutte多项式特定求值。", "conclusion": "该研究构建了一类新型算术拟阵（区别于环面排列实现类），揭示了椭圆排列组合与算术Tutte多项式之间的深刻联系。"}}
{"id": "2506.19500", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19500", "abs": "https://arxiv.org/abs/2506.19500", "authors": ["Yan Jiang", "Hao Zhou", "LiZhong GU", "Ai Han", "TianLong Li"], "title": "NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function Calling", "comment": null, "summary": "LLMs' reliance on static knowledge and fragile tool invocation severely\nhinders the orchestration of complex, heterogeneous toolchains, particularly at\nlarge scales. Existing methods typically use rigid single-path execution,\nresulting in poor error recovery and exponentially growing search spaces. We\nintroduce NaviAgent, a graph-navigated bilevel planning architecture for robust\nfunction calling, comprising a Multi-Path Decider and Graph-Encoded Navigator.\nAs an LLM-powered agent, the Multi-Path Decider defines a four-dimensional\ndecision space and continuously perceives environmental states, dynamically\nselecting the optimal action to fully cover all tool invocation scenarios. The\nGraph-Encoded Navigator constructs a Tool Dependency Heterogeneous Graph\n(TDHG), where node embeddings explicitly fuse API schema structure with\nhistorical invocation behavior. It also integrates a novel heuristic search\nstrategy that guides the Decider toward efficient and highly successful\ntoolchains, even for unseen tool combinations. Experiments show that NaviAgent\nconsistently achieves the highest task success rate (TSR) across all foundation\nmodels and task complexities, outperforming the average baselines (ReAct,\nToolLLM, {\\alpha}-UMI) by 13.5%, 16.4%, and 19.0% on Qwen2.5-14B, Qwen2.5-32B,\nand Deepseek-V3, respectively. Its execution steps are typically within one\nstep of the most efficient baseline, ensuring a strong balance between quality\nand efficiency. Notably, a fine-tuned Qwen2.5-14B model achieves a TSR of\n49.5%, surpassing the much larger 32B model (44.9%) under our architecture.\nIncorporating the Graph-Encoded Navigator further boosts TSR by an average of\n2.4 points, with gains up over 9 points on complex tasks for larger models\n(Deepseek-V3 and GPT-4o), highlighting its essential role in toolchain\norchestration.", "AI": {"tldr": "NaviAgent是一种基于图导航的双层规划架构，通过多路径决策器和图编码导航器提升大模型在复杂工具链调用中的鲁棒性和效率，显著超越现有基线方法。", "motivation": "当前大语言模型依赖静态知识且工具调用脆弱，难以协调复杂异构工具链，现有方法存在单路径执行僵化、错误恢复差及搜索空间爆炸问题。", "method": "提出双层架构：1)多路径决策器通过四维决策空间动态选择最优动作；2)图编码导航器构建工具依赖异构图(TDHG)，融合API模式与历史调用行为，采用启发式搜索策略指导工具链组合。", "result": "在Qwen2.5-14B/32B和Deepseek-V3上任务成功率(TSR)分别超越基线13.5%/16.4%/19.0%，优化后的14B模型(49.5%TSR)优于32B模型(44.9%)，图导航器平均提升2.4个TSR点(复杂任务最高+9点)。", "conclusion": "NaviAgent通过动态决策与图结构知识融合，实现了质量与效率的平衡，其架构设计对提升大模型工具链编排能力具有普适性价值。"}}
{"id": "2506.19667", "categories": ["math.CO", "math.DS", "05D10 (Primary) 11B13, 37A15 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.19667", "abs": "https://arxiv.org/abs/2506.19667", "authors": ["Ethan Ackelsberg"], "title": "Infinite polynomial patterns in large subsets of the rational numbers", "comment": "51 pages", "summary": "Inspired by a question of Kra, Moreira, Richter, and Robertson, we prove two\nnew results about infinite polynomial configurations in large subsets of the\nrational numbers. First, given a finite coloring of $\\mathbb{Q}$, we show that\nthere exists an infinite set $B = \\{b_n : n \\in \\mathbb{N}\\} \\subseteq\n\\mathbb{Q}$ such that $\\{b_i, b_i^2 + b_j : i < j\\}$ is monochromatic. Second,\nwe prove that every subset of positive density in the rational numbers contains\na translate of such an infinite configuration.\n  The proofs build upon methods developed in a series of papers by Kra,\nMoreira, Richter, and Robertson to translate from combinatorics into dynamics,\nwhere the core of the argument reduces to understanding the behavior of certain\npolynomial ergodic averages. The new dynamical tools required for this analysis\nare a Wiener--Wintner theorem for polynomially-twisted ergodic averages in\n$\\mathbb{Q}$-systems and a structure theorem for Abramov $\\mathbb{Q}$-systems.\n  The end of the paper includes a discussion of related problems in the\nintegers.", "AI": {"tldr": "该论文受Kra等人的问题启发，证明了有理数大子集中无限多项式配置的两个新结果：有限着色下存在无限集$B$使$\\{b_i, b_i^2 + b_j : i < j\\}$单色，且正密度子集包含此类配置的平移。方法结合组合动力学与多项式遍历平均，并引入新工具。", "motivation": "研究受Kra、Moreira、Richter和Robertson关于有理数无限多项式配置问题的启发，旨在扩展对有理数子集结构的理解。", "method": "通过将组合问题转化为动力系统问题，利用多项式遍历平均的Wiener-Wintner定理和Abramov $\\mathbb{Q}$-系统的结构定理，结合Kra等人的系列方法。", "result": "证明了两个主要结果：有限着色下存在无限单色多项式配置，以及正密度子集必然包含此类配置的平移。", "conclusion": "论文通过动力学方法解决了有理数中的多项式配置问题，并讨论了整数中相关问题的可能扩展。"}}
{"id": "2506.19530", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19530", "abs": "https://arxiv.org/abs/2506.19530", "authors": ["Carlo Romeo", "Andrew D. Bagdanov"], "title": "NTRL: Encounter Generation via Reinforcement Learning for Dynamic Difficulty Adjustment in Dungeons and Dragons", "comment": null, "summary": "Balancing combat encounters in Dungeons & Dragons (D&D) is a complex task\nthat requires Dungeon Masters (DM) to manually assess party strength, enemy\ncomposition, and dynamic player interactions while avoiding interruption of the\nnarrative flow. In this paper, we propose Encounter Generation via\nReinforcement Learning (NTRL), a novel approach that automates Dynamic\nDifficulty Adjustment (DDA) in D&D via combat encounter design. By framing the\nproblem as a contextual bandit, NTRL generates encounters based on real-time\nparty members attributes. In comparison with classic DM heuristics, NTRL\niteratively optimizes encounters to extend combat longevity (+200%), increases\ndamage dealt to party members, reducing post-combat hit points (-16.67%), and\nraises the number of player deaths while maintaining low total party kills\n(TPK). The intensification of combat forces players to act wisely and engage in\ntactical maneuvers, even though the generated encounters guarantee high win\nrates (70%). Even in comparison with encounters designed by human Dungeon\nMasters, NTRL demonstrates superior performance by enhancing the strategic\ndepth of combat while increasing difficulty in a manner that preserves overall\ngame fairness.", "AI": {"tldr": "本文提出了一种基于强化学习的D&D战斗遭遇生成方法NTRL，通过动态难度调整自动化设计战斗，显著提升战斗时长与策略深度，同时保持高胜率与游戏公平性。", "motivation": "传统D&D战斗中，地下城主(DM)需手动平衡队伍实力、敌人配置与动态互动，易打断叙事流程。NTRL旨在通过自动化动态难度调整解决这一复杂问题。", "method": "将问题建模为上下文赌博机，基于实时队伍属性生成战斗遭遇。相比传统DM启发式方法，NTRL通过迭代优化实现动态难度调整。", "result": "NTRL使战斗时长延长200%，队伍成员承受伤害增加（战后生命值降低16.67%），玩家死亡次数上升但保持低团灭率。生成遭遇战在保证70%胜率的同时，显著提升战术深度。", "conclusion": "NTRL在战略深度与难度提升方面优于人工设计的遭遇战，通过强化学习实现了既具挑战性又公平的D&D战斗体验。"}}
{"id": "2506.19700", "categories": ["math.CO", "cs.CG", "05C90, 68U05"], "pdf": "https://arxiv.org/pdf/2506.19700", "abs": "https://arxiv.org/abs/2506.19700", "authors": ["Lumi Christensen", "Thomas C. Hull", "Emma O'Neil", "Valentina Pappano", "Natalya Ter-Saakov", "Kacey Yang"], "title": "The Origami flip graph of the $2\\times n$ Miura-ori", "comment": null, "summary": "Given an origami crease pattern $C=(V,E)$, a straight-line planar graph\nembedded in a region of $\\mathbb{R}^2$, we assign each crease to be either a\nmountain crease (which bends convexly) or a valley crease (which bends\nconcavely), creating a mountain-valley (MV) assignment $\\mu:E\\to\\{-1,1\\}$. An\nMV assignment $\\mu$ is locally valid if the faces around each vertex in $C$ can\nbe folded flat under $\\mu$. In this paper, we investigate locally valid MV\nassignments of the Miura-ori, $M_{m,n}$, an $m\\times n$ parallelogram\ntessellation used in numerous engineering applications. The origami flip graph\n$OFG(C)$ of $C$ is a graph whose vertices are locally valid MV assignments of\n$C$, and two vertices are adjacent if they differ by a face flip, an operation\nthat swaps the MV-parity of every crease bordering a given face of $C$. We\nenumerate the number of vertices and edges in $OFG(M_{2,n})$ and prove several\nfacts about the degrees of vertices in $OFG(M_{2,n})$. By finding recurrence\nrelations, we show that the number of vertices of degree $d$ and $2n-a$ (for\n$0\\leq a$) are both described by polynomials of particular degrees. We then\nprove that the diameter of $OFG(M_{2,n})$ is $\\lceil \\frac{n^2}{2}\\rceil$ using\ntechniques from 3-coloring reconfiguration graphs.", "AI": {"tldr": "本文研究了Miura-ori折纸图案$M_{2,n}$的局部有效山-谷分配及其翻转图$OFG(M_{2,n})$的性质，包括顶点和边的数量、顶点度数的多项式描述以及图的直径。", "motivation": "Miura-ori折纸图案在工程中有广泛应用，研究其局部有效的山-谷分配及其翻转图的性质有助于理解其折叠行为的数学基础。", "method": "通过建立折纸翻转图$OFG(M_{2,n})$，分析其顶点和边的数量，并利用递推关系和3-着色重构图技术研究顶点度数和图的直径。", "result": "证明了$OFG(M_{2,n})$中特定度数顶点的数量由多项式描述，且图的直径为$\\lceil \\frac{n^2}{2}\\rceil$。", "conclusion": "研究揭示了Miura-ori折纸图案$M_{2,n}$的局部有效山-谷分配及其翻转图的数学结构，为折纸工程应用提供了理论支持。"}}
{"id": "2506.19573", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19573", "abs": "https://arxiv.org/abs/2506.19573", "authors": ["Sanne Wielinga", "Jesse Heyninck"], "title": "Interpretable Hybrid Machine Learning Models Using FOLD-R++ and Answer Set Programming", "comment": "accepted for publication as a Technical Communication at ICLP 2025", "summary": "Machine learning (ML) techniques play a pivotal role in high-stakes domains\nsuch as healthcare, where accurate predictions can greatly enhance\ndecision-making. However, most high-performing methods such as neural networks\nand ensemble methods are often opaque, limiting trust and broader adoption. In\nparallel, symbolic methods like Answer Set Programming (ASP) offer the\npossibility of interpretable logical rules but do not always match the\npredictive power of ML models. This paper proposes a hybrid approach that\nintegrates ASP-derived rules from the FOLD-R++ algorithm with black-box ML\nclassifiers to selectively correct uncertain predictions and provide\nhuman-readable explanations. Experiments on five medical datasets reveal\nstatistically significant performance gains in accuracy and F1 score. This\nstudy underscores the potential of combining symbolic reasoning with\nconventional ML to achieve high interpretability without sacrificing accuracy.", "AI": {"tldr": "本文提出了一种结合符号推理与机器学习的混合方法，通过FOLD-R++算法生成可解释规则来修正黑盒模型的不确定预测，在医疗数据集上显著提升了准确率和F1值。", "motivation": "高性能机器学习模型（如神经网络）缺乏可解释性限制了其在医疗等高风险领域的应用，而纯符号方法（如ASP）的预测性能又不足。需要兼具可解释性与准确性的解决方案。", "method": "采用FOLD-R++算法从ASP中提取可解释逻辑规则，与黑盒分类器结合：当模型预测不确定时，用符号规则进行修正并提供人类可读的解释。", "result": "在五个医疗数据集上的实验表明，该方法在准确率和F1分数上实现了统计学显著的提升（p<0.05）。", "conclusion": "通过融合符号推理与传统机器学习，可以在不牺牲准确性的前提下实现高可解释性，为高风险领域的决策支持提供了新思路。"}}
{"id": "2506.19731", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.19731", "abs": "https://arxiv.org/abs/2506.19731", "authors": ["Dan Hefetz", "Michael Krivelevich"], "title": "The Hamilton cycle space of random graphs", "comment": null, "summary": "The cycle space of a graph $G$, denoted $C(G)$, is a vector space over\n${\\mathbb F}_2$, spanned by all incidence vectors of edge-sets of cycles of\n$G$. If $G$ has $n$ vertices, then $C_n(G)$ denotes the subspace of $C(G)$,\nspanned by the incidence vectors of Hamilton cycles of $G$. A classical result\nin the theory of random graphs asserts that for $G \\sim \\mathbb{G}(n,p)$,\nasymptotically almost surely the necessary condition $\\delta(G) \\geq 2$ is also\nsufficient to ensure Hamiltonicity. Resolving a problem of Christoph, Nenadov,\nand Petrova, we augment this result by proving that for $G \\sim\n\\mathbb{G}(n,p)$, with $n$ being odd, asymptotically almost surely the\ncondition $\\delta(G) \\geq 3$ (observed to be necessary by Heinig) is also\nsufficient for ensuring $C_n(G) = C(G)$. That is, not only does $G$ typically\nhave a Hamilton cycle, but its Hamilton cycles are typically rich enough to\nspan its cycle space.", "AI": {"tldr": "该论文证明了对于奇数个顶点的随机图$G \\sim \\mathbb{G}(n,p)$，当最小度数$\\delta(G) \\geq 3$时，几乎必然其Hamilton圈能生成整个圈空间$C_n(G) = C(G)$。", "motivation": "研究随机图中Hamilton圈与圈空间的关系，解决Christoph等人提出的问题，验证Heinig观察到的必要条件$\\delta(G) \\geq 3$的充分性。", "method": "采用随机图理论的分析方法，结合概率工具和代数图论中的圈空间概念，研究$G \\sim \\mathbb{G}(n,p)$的渐进性质。", "result": "对于奇数$n$的随机图，几乎必然$\\delta(G) \\geq 3$时，Hamilton圈的生成向量能张成整个圈空间$C(G)$。", "conclusion": "该结果不仅扩展了随机图Hamilton性的经典结论，还揭示了Hamilton圈在生成圈空间中的重要作用。"}}
{"id": "2506.19592", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.19592", "abs": "https://arxiv.org/abs/2506.19592", "authors": ["Harisankar Babu", "Philipp Schillinger", "Tamim Asfour"], "title": "Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning", "comment": null, "summary": "We introduce TAPAS (Task-based Adaptation and Planning using AgentS), a\nmulti-agent framework that integrates Large Language Models (LLMs) with\nsymbolic planning to solve complex tasks without the need for manually defined\nenvironment models. TAPAS employs specialized LLM-based agents that\ncollaboratively generate and adapt domain models, initial states, and goal\nspecifications as needed using structured tool-calling mechanisms. Through this\ntool-based interaction, downstream agents can request modifications from\nupstream agents, enabling adaptation to novel attributes and constraints\nwithout manual domain redefinition. A ReAct (Reason+Act)-style execution agent,\ncoupled with natural language plan translation, bridges the gap between\ndynamically generated plans and real-world robot capabilities. TAPAS\ndemonstrates strong performance in benchmark planning domains and in the\nVirtualHome simulated real-world environment.", "AI": {"tldr": "TAPAS是一个多智能体框架，结合大语言模型（LLMs）与符号规划，无需手动定义环境模型即可解决复杂任务。", "motivation": "为了解决复杂任务中手动定义环境模型的局限性，TAPAS通过多智能体协作动态生成和调整领域模型、初始状态及目标规范。", "method": "TAPAS使用基于LLM的专用智能体，通过结构化工具调用机制协作生成领域模型，并采用ReAct风格的执行智能体将动态生成的计划转化为机器人可执行的自然语言指令。", "result": "TAPAS在基准规划领域和VirtualHome模拟现实环境中表现出色，展示了其强大的适应性和规划能力。", "conclusion": "TAPAS框架通过多智能体协作和动态模型生成，显著提升了复杂任务解决的灵活性和效率，为机器人规划领域提供了新的解决方案。"}}
{"id": "2506.19608", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19608", "abs": "https://arxiv.org/abs/2506.19608", "authors": ["Zhiyuan Wang", "Bokui Chen"], "title": "ChordPrompt: Orchestrating Cross-Modal Prompt Synergy for Multi-Domain Incremental Learning in CLIP", "comment": "Accept by ECML-PKDD 2025", "summary": "Continual learning (CL) empowers pre-trained vision-language models to adapt\neffectively to novel or previously underrepresented data distributions without\ncomprehensive retraining, enhancing their adaptability and efficiency. While\nvision-language models like CLIP show great promise, they struggle to maintain\nperformance across domains in incremental learning scenarios. Existing prompt\nlearning methods face two main limitations: 1) they primarily focus on\nclass-incremental learning scenarios, lacking specific strategies for\nmulti-domain task incremental learning; 2) most current approaches employ\nsingle-modal prompts, neglecting the potential benefits of cross-modal\ninformation exchange. To address these challenges, we propose the \\ChordPrompt\nframework, which facilitates a harmonious interplay between visual and textual\nprompts. \\ChordPrompt introduces cross-modal prompts to leverage interactions\nbetween visual and textual information. Our approach also employs\ndomain-adaptive text prompts to select appropriate prompts for continual\nadaptation across multiple domains. Comprehensive experiments on multi-domain\nincremental learning benchmarks demonstrate that \\ChordPrompt outperforms\nstate-of-the-art methods in zero-shot generalization and downstream task\nperformance.", "AI": {"tldr": "本文提出\\ChordPrompt框架，通过视觉与文本提示的跨模态交互解决持续学习中的多领域适应问题，显著提升了零样本泛化和下游任务性能。", "motivation": "现有视觉语言模型在增量学习场景中难以跨领域保持性能，且当前提示学习方法局限于单模态和类增量场景，缺乏多领域任务增量学习的有效策略。", "method": "\\ChordPrompt框架引入跨模态提示机制，结合视觉与文本信息的交互；采用领域自适应文本提示，为多领域持续适应动态选择合适提示。", "result": "在多领域增量学习基准测试中，\\ChordPrompt在零样本泛化和下游任务性能上均超越现有最优方法。", "conclusion": "该研究通过跨模态协同和领域自适应机制，为视觉语言模型的持续学习提供了新范式，显著提升了模型的多领域适应能力。"}}
{"id": "2506.19613", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19613", "abs": "https://arxiv.org/abs/2506.19613", "authors": ["Sha Zhang", "Suorong Yang", "Tong Xie", "Xiangyuan Xue", "Zixuan Hu", "Rui Li", "Wenxi Qu", "Zhenfei Yin", "Tianfan Fu", "Di Hu", "Andres M Bran", "Nian Ran", "Bram Hoex", "Wangmeng Zuo", "Philippe Schwaller", "Wanli Ouyang", "Lei Bai", "Yanyong Zhang", "Lingyu Duan", "Shixiang Tang", "Dongzhan Zhou"], "title": "Position: Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI", "comment": null, "summary": "Scientific discovery has long been constrained by human limitations in\nexpertise, physical capability, and sleep cycles. The recent rise of AI\nscientists and automated laboratories has accelerated both the cognitive and\noperational aspects of research. However, key limitations persist: AI systems\nare often confined to virtual environments, while automated laboratories lack\nthe flexibility and autonomy to adaptively test new hypotheses in the physical\nworld. Recent advances in embodied AI, such as generalist robot foundation\nmodels, diffusion-based action policies, fine-grained manipulation learning,\nand sim-to-real transfer, highlight the promise of integrating cognitive and\nembodied intelligence. This convergence opens the door to closed-loop systems\nthat support iterative, autonomous experimentation and the possibility of\nserendipitous discovery. In this position paper, we propose the paradigm of\nIntelligent Science Laboratories (ISLs): a multi-layered, closed-loop framework\nthat deeply integrates cognitive and embodied intelligence. ISLs unify\nfoundation models for scientific reasoning, agent-based workflow orchestration,\nand embodied agents for robust physical experimentation. We argue that such\nsystems are essential for overcoming the current limitations of scientific\ndiscovery and for realizing the full transformative potential of AI-driven\nscience.", "AI": {"tldr": "本文提出智能科学实验室（ISLs）的新范式，通过整合认知与具身智能，构建闭环系统以突破当前科学发现的局限，实现AI驱动科学的变革潜力。", "motivation": "传统科学发现受限于人类能力，现有AI科学家和自动化实验室仍存在虚拟环境局限与物理世界适应性不足的问题，需融合认知与具身智能以实现自主实验与偶然发现。", "method": "提出多层级闭环框架ISLs，整合科学推理基础模型、基于代理的工作流编排及具身代理的物理实验能力，形成认知-操作一体化系统。", "result": "ISLs通过通用机器人基础模型、扩散动作策略等技术，支持迭代式自主实验，为科学发现提供灵活、自适应的解决方案。", "conclusion": "ISLs范式是克服当前科学发现瓶颈的关键，其深度整合认知与具身智能的特性，将充分释放AI驱动科学的变革性潜力。"}}
{"id": "2506.19635", "categories": ["cs.CR", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2506.19635", "abs": "https://arxiv.org/abs/2506.19635", "authors": ["Rocco De Nicola", "Marinella Petrocchi", "Manuel Pratelli"], "title": "On the efficacy of old features for the detection of new bots", "comment": "pre-print version", "summary": "For more than a decade now, academicians and online platform administrators\nhave been studying solutions to the problem of bot detection. Bots are computer\nalgorithms whose use is far from being benign: malicious bots are purposely\ncreated to distribute spam, sponsor public characters and, ultimately, induce a\nbias within the public opinion. To fight the bot invasion on our online\necosystem, several approaches have been implemented, mostly based on\n(supervised and unsupervised) classifiers, which adopt the most varied account\nfeatures, from the simplest to the most expensive ones to be extracted from the\nraw data obtainable through the Twitter public APIs. In this exploratory study,\nusing Twitter as a benchmark, we compare the performances of four state-of-art\nfeature sets in detecting novel bots: one of the output scores of the popular\nbot detector Botometer, which considers more than 1,000 features of an account\nto take a decision; two feature sets based on the account profile and timeline;\nand the information about the Twitter client from which the user tweets. The\nresults of our analysis, conducted on six recently released datasets of Twitter\naccounts, hint at the possible use of general-purpose classifiers and\ncheap-to-compute account features for the detection of evolved bots.", "AI": {"tldr": "本研究比较了四种先进特征集在Twitter新型机器人检测中的性能，发现通用分类器和低成本计算特征可有效识别进化机器人。", "motivation": "恶意机器人通过传播垃圾邮件和操纵舆论危害网络生态，现有检测方法多依赖复杂特征，本研究探索低成本高效检测方案。", "method": "以Twitter为基准平台，对比分析Botometer评分、账户资料/时间线特征集及推文客户端信息四类特征在六个最新数据集上的表现。", "result": "实验结果表明，通用分类器结合易提取的账户特征能够有效识别新型进化机器人。", "conclusion": "该研究为对抗持续进化的社交机器人提供了经济高效的检测思路，具有实际应用价值。"}}
{"id": "2506.19650", "categories": ["cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2506.19650", "abs": "https://arxiv.org/abs/2506.19650", "authors": ["Simon Ferreira", "Charles K. Assaad"], "title": "Identifying Macro Causal Effects in C-DMGs over DMGs", "comment": "Accepted to the UAI2025 workshop on Causal Abstractions and\n  Representations. arXiv admin note: substantial text overlap with\n  arXiv:2504.01551", "summary": "The do-calculus is a sound and complete tool for identifying causal effects\nin acyclic directed mixed graphs (ADMGs) induced by structural causal models\n(SCMs). However, in many real-world applications, especially in\nhigh-dimensional setting, constructing a fully specified ADMG is often\ninfeasible. This limitation has led to growing interest in partially specified\ncausal representations, particularly through cluster-directed mixed graphs\n(C-DMGs), which group variables into clusters and offer a more abstract yet\npractical view of causal dependencies. While these representations can include\ncycles, recent work has shown that the do-calculus remains sound and complete\nfor identifying macro-level causal effects in C-DMGs over ADMGs under the\nassumption that all clusters size are greater than 1. Nevertheless, real-world\nsystems often exhibit cyclic causal dynamics at the structural level. To\naccount for this, input-output structural causal models (ioSCMs) have been\nintroduced as a generalization of SCMs that allow for cycles. ioSCMs induce\nanother type of graph structure known as a directed mixed graph (DMG).\nAnalogous to the ADMG setting, one can define C-DMGs over DMGs as high-level\nrepresentations of causal relations among clusters of variables. In this paper,\nwe prove that, unlike in the ADMG setting, the do-calculus is unconditionally\nsound and complete for identifying macro causal effects in C-DMGs over DMGs.\nFurthermore, we show that the graphical criteria for non-identifiability of\nmacro causal effects previously established C-DMGs over ADMGs naturally extends\nto a subset of C-DMGs over DMGs.", "AI": {"tldr": "本文证明了在基于DMG的C-DMG中，do-calculus无条件适用于宏观因果效应识别，并扩展了非可识别性的图形标准。", "motivation": "现实系统中常存在循环因果结构，而传统ADMG框架无法完全适用，需要研究更通用的DMG框架下的因果效应识别方法。", "method": "通过输入-输出结构因果模型(ioSCM)构建允许循环的DMG，并研究其上的集群有向混合图(C-DMG)表示方法。", "result": "证明在DMG框架下，do-calculus对C-DMG的宏观因果效应识别具有无条件完备性，且ADMG的非可识别性标准可推广至部分DMG情形。", "conclusion": "研究扩展了do-calculus在循环因果系统中的适用性，为高维复杂系统的因果分析提供了理论工具。"}}
{"id": "2506.19686", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19686", "abs": "https://arxiv.org/abs/2506.19686", "authors": ["Ching Fang", "Kanaka Rajan"], "title": "From memories to maps: Mechanisms of in context reinforcement learning in transformers", "comment": null, "summary": "Humans and animals show remarkable learning efficiency, adapting to new\nenvironments with minimal experience. This capability is not well captured by\nstandard reinforcement learning algorithms that rely on incremental value\nupdates. Rapid adaptation likely depends on episodic memory -- the ability to\nretrieve specific past experiences to guide decisions in novel contexts.\nTransformers provide a useful setting for studying these questions because of\ntheir ability to learn rapidly in-context and because their key-value\narchitecture resembles episodic memory systems in the brain. We train a\ntransformer to in-context reinforcement learn in a distribution of planning\ntasks inspired by rodent behavior. We then characterize the learning algorithms\nthat emerge in the model. We first find that representation learning is\nsupported by in-context structure learning and cross-context alignment, where\nrepresentations are aligned across environments with different sensory stimuli.\nWe next demonstrate that the reinforcement learning strategies developed by the\nmodel are not interpretable as standard model-free or model-based planning.\nInstead, we show that in-context reinforcement learning is supported by caching\nintermediate computations within the model's memory tokens, which are then\naccessed at decision time. Overall, we find that memory may serve as a\ncomputational resource, storing both raw experience and cached computations to\nsupport flexible behavior. Furthermore, the representations developed in the\nmodel resemble computations associated with the hippocampal-entorhinal system\nin the brain, suggesting that our findings may be relevant for natural\ncognition. Taken together, our work offers a mechanistic hypothesis for the\nrapid adaptation that underlies in-context learning in artificial and natural\nsettings.", "AI": {"tldr": "该研究探讨了人类和动物通过情景记忆快速适应新环境的能力，并利用Transformer模型模拟这一过程，发现其学习策略不同于传统的模型无关或基于模型的规划，而是依赖于内存中的中间计算缓存。", "motivation": "人类和动物能够通过情景记忆快速适应新环境，而传统的强化学习算法无法有效模拟这一能力。研究旨在通过Transformer模型探索这一快速适应能力的机制。", "method": "研究训练了一个Transformer模型，在一个受啮齿动物行为启发的规划任务分布中进行上下文强化学习，并分析了模型中涌现的学习算法。", "result": "研究发现，模型的表示学习依赖于上下文结构学习和跨上下文对齐，且其强化学习策略无法用传统的模型无关或基于模型的规划来解释，而是依赖于内存令牌中的中间计算缓存。", "conclusion": "内存可以作为计算资源存储原始经验和缓存计算，支持灵活行为。模型中的表示与大脑海马-内嗅皮层系统的计算相似，表明研究结果可能对自然认知有重要意义。"}}
{"id": "2506.19702", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19702", "abs": "https://arxiv.org/abs/2506.19702", "authors": ["Lei Kang", "Xuanshuo Fu", "Oriol Ramos Terrades", "Javier Vazquez-Corral", "Ernest Valveny", "Dimosthenis Karatzas"], "title": "LLM-Driven Medical Document Analysis: Enhancing Trustworthy Pathology and Differential Diagnosis", "comment": "Accepted at ICDAR 2025", "summary": "Medical document analysis plays a crucial role in extracting essential\nclinical insights from unstructured healthcare records, supporting critical\ntasks such as differential diagnosis. Determining the most probable condition\namong overlapping symptoms requires precise evaluation and deep medical\nexpertise. While recent advancements in large language models (LLMs) have\nsignificantly enhanced performance in medical document analysis, privacy\nconcerns related to sensitive patient data limit the use of online LLMs\nservices in clinical settings. To address these challenges, we propose a\ntrustworthy medical document analysis platform that fine-tunes a LLaMA-v3 using\nlow-rank adaptation, specifically optimized for differential diagnosis tasks.\nOur approach utilizes DDXPlus, the largest benchmark dataset for differential\ndiagnosis, and demonstrates superior performance in pathology prediction and\nvariable-length differential diagnosis compared to existing methods. The\ndeveloped web-based platform allows users to submit their own unstructured\nmedical documents and receive accurate, explainable diagnostic results. By\nincorporating advanced explainability techniques, the system ensures\ntransparent and reliable predictions, fostering user trust and confidence.\nExtensive evaluations confirm that the proposed method surpasses current\nstate-of-the-art models in predictive accuracy while offering practical utility\nin clinical settings. This work addresses the urgent need for reliable,\nexplainable, and privacy-preserving artificial intelligence solutions,\nrepresenting a significant advancement in intelligent medical document analysis\nfor real-world healthcare applications. The code can be found at\n\\href{https://github.com/leitro/Differential-Diagnosis-LoRA}{https://github.com/leitro/Differential-Diagnosis-LoRA}.", "AI": {"tldr": "本文提出了一种基于LLaMA-v3模型和低秩适配技术的可信医疗文档分析平台，专注于鉴别诊断任务，在保护隐私的同时提升了诊断准确性和可解释性。", "motivation": "医疗文档分析对临床决策至关重要，但现有大型语言模型存在隐私泄露风险，且缺乏针对鉴别诊断的优化方案。", "method": "采用低秩适配技术微调LLaMA-v3模型，利用最大鉴别诊断基准数据集DDXPlus进行训练，并开发支持用户上传非结构化文档的网页平台。", "result": "该方法在病理预测和变长鉴别诊断任务中超越现有技术，通过可解释技术确保预测透明性，临床评估证实其优越性。", "conclusion": "该研究实现了可靠、可解释且隐私保护的人工智能解决方案，为现实医疗场景中的智能文档分析提供了重要进展。代码已开源：\\href{https://github.com/leitro/Differential-Diagnosis-LoRA}{https://github.com/leitro/Differential-Diagnosis-LoRA}"}}
{"id": "2506.19724", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19724", "abs": "https://arxiv.org/abs/2506.19724", "authors": ["Gyeongwon James Kim", "Alex Wilf", "Louis-Philippe Morency", "Daniel Fried"], "title": "From Reproduction to Replication: Evaluating Research Agents with Progressive Code Masking", "comment": null, "summary": "Recent progress in autonomous code generation has fueled excitement around AI\nagents capable of accelerating scientific discovery by running experiments.\nHowever, there is currently no benchmark that evaluates whether such agents can\nimplement scientific ideas when given varied amounts of code as a starting\npoint, interpolating between reproduction (running code) and from-scratch\nreplication (fully re-implementing and running code). We introduce\nAutoExperiment, a benchmark that evaluates AI agents' ability to implement and\nrun machine learning experiments based on natural language descriptions in\nresearch papers. In each task, agents are given a research paper, a codebase\nwith key functions masked out, and a command to run the experiment. The goal is\nto generate the missing code, execute the experiment in a sandboxed\nenvironment, and reproduce the results. AutoExperiment scales in difficulty by\nvarying the number of missing functions $n$, ranging from partial reproduction\nto full replication. We evaluate state-of-the-art agents and find that\nperformance degrades rapidly as $n$ increases. Agents that can dynamically\ninteract with the environment (e.g. to debug their code) can outperform agents\nin fixed \"agentless\" harnesses, and there exists a significant gap between\nsingle-shot and multi-trial success rates (Pass@1 vs. Pass@5), motivating\nverifier approaches to our benchmark. Our findings highlight critical\nchallenges in long-horizon code generation, context retrieval, and autonomous\nexperiment execution, establishing AutoExperiment as a new benchmark for\nevaluating progress in AI-driven scientific experimentation. Our data and code\nare open-sourced at https://github.com/j1mk1m/AutoExperiment .", "AI": {"tldr": "本文介绍了AutoExperiment基准测试，用于评估AI代理根据自然语言描述实现和运行机器学习实验的能力，揭示了当前AI在长周期代码生成和自主实验执行中的挑战。", "motivation": "当前缺乏评估AI代理在不同代码起点下实现科学想法的基准测试，AutoExperiment填补了这一空白，旨在衡量AI从部分复现到完全复现的能力。", "method": "通过提供研究论文、关键函数被遮蔽的代码库及实验命令，要求AI生成缺失代码并在沙盒环境中执行实验，难度随缺失函数数量$n$增加而提升。", "result": "实验显示，随着$n$增加，AI性能迅速下降；动态与环境交互的代理优于固定框架，且单次尝试与多次尝试成功率（Pass@1 vs. Pass@5）存在显著差距。", "conclusion": "AutoExperiment为评估AI驱动的科学实验设立了新基准，突显了长周期代码生成、上下文检索和自主实验执行等关键挑战，相关数据和代码已开源。"}}
{"id": "2506.19773", "categories": ["cs.AI", "I.2.7; I.2.4"], "pdf": "https://arxiv.org/pdf/2506.19773", "abs": "https://arxiv.org/abs/2506.19773", "authors": ["Nandana Mihindukulasooriya", "Niharika S. D'Souza", "Faisal Chowdhury", "Horst Samulowitz"], "title": "Automatic Prompt Optimization for Knowledge Graph Construction: Insights from an Empirical Study", "comment": null, "summary": "A KG represents a network of entities and illustrates relationships between\nthem. KGs are used for various applications, including semantic search and\ndiscovery, reasoning, decision-making, natural language processing, machine\nlearning, and recommendation systems. Triple (subject-relation-object)\nextraction from text is the fundamental building block of KG construction and\nhas been widely studied, for example, in early benchmarks such as ACE 2002 to\nmore recent ones, such as WebNLG 2020, REBEL and SynthIE. While the use of LLMs\nis explored for KG construction, handcrafting reasonable task-specific prompts\nfor LLMs is a labour-intensive exercise and can be brittle due to subtle\nchanges in the LLM models employed. Recent work in NLP tasks (e.g. autonomy\ngeneration) uses automatic prompt optimization/engineering to address this\nchallenge by generating optimal or near-optimal task-specific prompts given\ninput-output examples.\n  This empirical study explores the application of automatic prompt\noptimization for the triple extraction task using experimental benchmarking. We\nevaluate different settings by changing (a) the prompting strategy, (b) the LLM\nbeing used for prompt optimization and task execution, (c) the number of\ncanonical relations in the schema (schema complexity), (d) the length and\ndiversity of input text, (e) the metric used to drive the prompt optimization,\nand (f) the dataset being used for training and testing. We evaluate three\ndifferent automatic prompt optimizers, namely, DSPy, APE, and TextGrad and use\ntwo different triple extraction datasets, SynthIE and REBEL. Through rigorous\nempirical evaluation, our main contribution highlights that automatic prompt\noptimization techniques can generate reasonable prompts similar to humans for\ntriple extraction. In turn, these optimized prompts achieve improved results,\nparticularly with increasing schema complexity and text size.", "AI": {"tldr": "本文通过实证研究探索了自动提示优化在知识图谱三元组抽取任务中的应用，评估了不同设置下的性能表现，发现自动优化提示可媲美人工作业并提升结果质量。", "motivation": "知识图谱（KG）构建中的三元组抽取是基础任务，但为大型语言模型（LLM）手工设计任务特定提示既耗时又脆弱。近期NLP研究采用自动提示优化来解决这一挑战，本文旨在验证该方法在三元组抽取任务中的有效性。", "method": "研究通过实验基准测试评估了六类变量：(a)提示策略、(b)LLM选择、(c)模式关系数量、(d)文本长度与多样性、(e)优化驱动指标、(f)训练测试数据集。比较了DSPy/APE/TextGrad三种优化器在SynthIE和REBEL数据集上的表现。", "result": "实证结果表明，自动提示优化技术能生成接近人工水平的合理提示。优化后的提示显著提升性能，尤其在模式复杂度增加和文本规模扩大时效果更为突出。", "conclusion": "自动提示优化可有效替代人工设计提示，为知识图谱三元组抽取任务提供高效解决方案，其优势随任务复杂性增强而愈发显著。"}}
{"id": "2506.19783", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19783", "abs": "https://arxiv.org/abs/2506.19783", "authors": ["Teng Wang", "Hailei Gong", "Changwang Zhang", "Jun Wang"], "title": "SAGE: Strategy-Adaptive Generation Engine for Query Rewriting", "comment": null, "summary": "Query rewriting is pivotal for enhancing dense retrieval, yet current methods\ndemand large-scale supervised data or suffer from inefficient reinforcement\nlearning (RL) exploration. In this work, we first establish that guiding Large\nLanguage Models (LLMs) with a concise set of expert-crafted strategies, such as\nsemantic expansion and entity disambiguation, substantially improves retrieval\neffectiveness on challenging benchmarks, including HotpotQA, FEVER, NFCorpus,\nand SciFact. Building on this insight, we introduce the Strategy-Adaptive\nGeneration Engine (SAGE), which operationalizes these strategies in an RL\nframework. SAGE introduces two novel reward shaping mechanisms-Strategic Credit\nShaping (SCS) and Contrastive Reward Shaping (CRS)-to deliver more informative\nlearning signals. This strategy-guided approach not only achieves new\nstate-of-the-art NDCG@10 results, but also uncovers a compelling emergent\nbehavior: the agent learns to select optimal strategies, reduces unnecessary\nexploration, and generates concise rewrites, lowering inference cost without\nsacrificing performance. Our findings demonstrate that strategy-guided RL,\nenhanced with nuanced reward shaping, offers a scalable, efficient, and more\ninterpretable paradigm for developing the next generation of robust information\nretrieval systems.", "AI": {"tldr": "本文提出策略自适应生成引擎（SAGE），通过专家策略引导的强化学习框架改进密集检索中的查询重写，结合两种新型奖励机制（SCS和CRS），在多个基准测试中实现最优NDCG@10性能，同时降低推理成本。", "motivation": "当前查询重写方法依赖大规模监督数据或强化学习探索效率低下，需要更高效、可扩展且解释性强的解决方案。", "method": "SAGE框架将专家策略（如语义扩展和实体消歧）融入强化学习，并设计战略信用塑造（SCS）和对比奖励塑造（CRS）机制优化学习信号。", "result": "在HotpotQA、FEVER等基准上取得SOTA的NDCG@10结果，模型能自主选择最优策略，减少冗余探索，生成简洁重写以降低推理成本。", "conclusion": "策略引导的强化学习结合精细奖励机制，为构建高效、可扩展的信息检索系统提供了新范式。"}}
{"id": "2506.19785", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19785", "abs": "https://arxiv.org/abs/2506.19785", "authors": ["Menglong Zhang", "Fuyuan Qian"], "title": "Learning Task Belief Similarity with Latent Dynamics for Meta-Reinforcement Learning", "comment": "ICLR2025 https://openreview.net/forum?id=5YbuOTUFQ4", "summary": "Meta-reinforcement learning requires utilizing prior task distribution\ninformation obtained during exploration to rapidly adapt to unknown tasks. The\nefficiency of an agent's exploration hinges on accurately identifying the\ncurrent task. Recent Bayes-Adaptive Deep RL approaches often rely on\nreconstructing the environment's reward signal, which is challenging in sparse\nreward settings, leading to suboptimal exploitation. Inspired by bisimulation\nmetrics, which robustly extracts behavioral similarity in continuous MDPs, we\npropose SimBelief-a novel meta-RL framework via measuring similarity of task\nbelief in Bayes-Adaptive MDP (BAMDP). SimBelief effectively extracts common\nfeatures of similar task distributions, enabling efficient task identification\nand exploration in sparse reward environments. We introduce latent task belief\nmetric to learn the common structure of similar tasks and incorporate it into\nthe specific task belief. By learning the latent dynamics across task\ndistributions, we connect shared latent task belief features with specific task\nfeatures, facilitating rapid task identification and adaptation. Our method\noutperforms state-of-the-art baselines on sparse reward MuJoCo and panda-gym\ntasks.", "AI": {"tldr": "本文提出SimBelief框架，通过测量贝叶斯自适应MDP中的任务信念相似性，解决稀疏奖励环境下元强化学习的任务识别与探索效率问题。", "motivation": "现有贝叶斯自适应深度强化学习方法依赖重构环境奖励信号，在稀疏奖励场景中效果不佳，需更鲁棒的任务识别方法。", "method": "引入潜在任务信念度量学习相似任务的共同结构，并将其整合到具体任务信念中，通过跨任务分布的潜在动力学连接共享特征与特定特征。", "result": "在稀疏奖励的MuJoCo和panda-gym任务上，SimBelief优于当前最先进基线方法。", "conclusion": "基于行为相似性的任务信念度量能有效提取任务分布共性，提升稀疏奖励环境下的元强化学习性能。"}}
{"id": "2506.19807", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.19807", "abs": "https://arxiv.org/abs/2506.19807", "authors": ["Baochang Ren", "Shuofei Qiao", "Wenhao Yu", "Huajun Chen", "Ningyu Zhang"], "title": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality", "comment": "Work in progress", "summary": "Large Language Models (LLMs), particularly slow-thinking models, often\nexhibit severe hallucination, outputting incorrect content due to an inability\nto accurately recognize knowledge boundaries during reasoning. While\nReinforcement Learning (RL) can enhance complex reasoning abilities, its\noutcome-oriented reward mechanism often lacks factual supervision over the\nthinking process, further exacerbating the hallucination problem. To address\nthe high hallucination in slow-thinking models, we propose Knowledge-enhanced\nRL, KnowRL. KnowRL guides models to perform fact-based slow thinking by\nintegrating a factuality reward, based on knowledge verification, into the RL\ntraining process, helping them recognize their knowledge boundaries. KnowRL\nguides models to perform fact-based slow thinking by integrating a factuality\nreward, based on knowledge verification, into the RL training process, helping\nthem recognize their knowledge boundaries. This targeted factual input during\nRL training enables the model to learn and internalize fact-based reasoning\nstrategies. By directly rewarding adherence to facts within the reasoning\nsteps, KnowRL fosters a more reliable thinking process. Experimental results on\nthree hallucination evaluation datasets and two reasoning evaluation datasets\ndemonstrate that KnowRL effectively mitigates hallucinations in slow-thinking\nmodels while maintaining their original strong reasoning capabilities. Our code\nis available at https://github.com/zjunlp/KnowRL.", "AI": {"tldr": "本文提出KnowRL方法，通过知识增强的强化学习减少大语言模型在慢思考过程中的幻觉问题，保持其推理能力。", "motivation": "大语言模型（尤其是慢思考模型）因无法准确识别知识边界而产生严重幻觉，传统强化学习的奖励机制缺乏对思考过程的事实监督，加剧了该问题。", "method": "提出KnowRL框架，在强化学习训练中融入基于知识验证的事实性奖励，引导模型进行基于事实的慢思考并识别知识边界。", "result": "在三个幻觉评估数据集和两个推理评估数据集上的实验表明，KnowRL有效减少了慢思考模型的幻觉，同时保持了其原有推理能力。", "conclusion": "KnowRL通过直接奖励推理步骤中的事实遵循，培养了更可靠的思考过程，为解决大语言模型幻觉问题提供了新方向。"}}
{"id": "2506.19825", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.19825", "abs": "https://arxiv.org/abs/2506.19825", "authors": ["Johannes Rückert", "Louise Bloch", "Christoph M. Friedrich"], "title": "Evaluating Compliance with Visualization Guidelines in Diagrams for Scientific Publications Using Large Vision Language Models", "comment": "Accepted at ICDAR 2025", "summary": "Diagrams are widely used to visualize data in publications. The research\nfield of data visualization deals with defining principles and guidelines for\nthe creation and use of these diagrams, which are often not known or adhered to\nby researchers, leading to misinformation caused by providing inaccurate or\nincomplete information.\n  In this work, large Vision Language Models (VLMs) are used to analyze\ndiagrams in order to identify potential problems in regards to selected data\nvisualization principles and guidelines. To determine the suitability of VLMs\nfor these tasks, five open source VLMs and five prompting strategies are\ncompared using a set of questions derived from selected data visualization\nguidelines.\n  The results show that the employed VLMs work well to accurately analyze\ndiagram types (F1-score 82.49 %), 3D effects (F1-score 98.55 %), axes labels\n(F1-score 76.74 %), lines (RMSE 1.16), colors (RMSE 1.60) and legends (F1-score\n96.64 %, RMSE 0.70), while they cannot reliably provide feedback about the\nimage quality (F1-score 0.74 %) and tick marks/labels (F1-score 46.13 %). Among\nthe employed VLMs, Qwen2.5VL performs best, and the summarizing prompting\nstrategy performs best for most of the experimental questions.\n  It is shown that VLMs can be used to automatically identify a number of\npotential issues in diagrams, such as missing axes labels, missing legends, and\nunnecessary 3D effects. The approach laid out in this work can be extended for\nfurther aspects of data visualization.", "AI": {"tldr": "研究利用视觉语言模型（VLMs）自动检测图表中的可视化问题，验证了其在识别图表类型、3D效果、坐标轴标签等方面的有效性，并指出Qwen2.5VL模型和总结式提示策略表现最佳。", "motivation": "由于研究者常忽视数据可视化原则，导致图表传递错误或不完整信息。本研究旨在探索VLMs能否自动识别图表中的潜在问题，以提升可视化质量。", "method": "采用五种开源VLMs和五种提示策略，通过基于可视化准则设计的问题集，评估模型在图表类型、3D效果、坐标轴标签等维度的分析能力。", "result": "VLMs在图表类型（F1值82.49%）、3D效果（98.55%）、图例（96.64%）等方面表现优异，但在图像质量（0.74%）和刻度标记（46.13%）上不可靠。Qwen2.5VL模型和总结式提示策略综合表现最佳。", "conclusion": "VLMs可有效自动化检测图表中的常见问题（如缺失坐标轴标签、冗余3D效果），该方法可扩展至更多可视化场景，但需针对特定缺陷（如图像质量）优化模型能力。"}}
{"id": "2506.19843", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19843", "abs": "https://arxiv.org/abs/2506.19843", "authors": ["Guo Li", "Zixiang Xu", "Wei Zhang", "Yikuan Hu", "Xinyu Yang", "Nikolay Aristov", "Mingjie Tang", "Elenna R Dugundji"], "title": "Temporal-IRL: Modeling Port Congestion and Berth Scheduling with Inverse Reinforcement Learning", "comment": "TRB2025", "summary": "Predicting port congestion is crucial for maintaining reliable global supply\nchains. Accurate forecasts enableimprovedshipment planning, reducedelaysand\ncosts, and optimizeinventoryanddistributionstrategies, thereby ensuring timely\ndeliveries and enhancing supply chain resilience. To achieve accurate\npredictions, analyzing vessel behavior and their stay times at specific port\nterminals is essential, focusing particularly on berth scheduling under various\nconditions. Crucially, the model must capture and learn the underlying\npriorities and patterns of berth scheduling. Berth scheduling and planning are\ninfluenced by a range of factors, including incoming vessel size, waiting\ntimes, and the status of vessels within the port terminal. By observing\nhistorical Automatic Identification System (AIS) positions of vessels, we\nreconstruct berth schedules, which are subsequently utilized to determine the\nreward function via Inverse Reinforcement Learning (IRL). For this purpose, we\nmodeled a specific terminal at the Port of New York/New Jersey and developed\nTemporal-IRL. This Temporal-IRL model learns berth scheduling to predict vessel\nsequencing at the terminal and estimate vessel port stay, encompassing both\nwaiting and berthing times, to forecast port congestion. Utilizing data from\nMaher Terminal spanning January 2015 to September 2023, we trained and tested\nthe model, achieving demonstrably excellent results.", "AI": {"tldr": "该研究通过逆向强化学习（IRL）分析船舶行为与停泊时间，开发了Temporal-IRL模型预测纽约/新泽西港特定码头的船舶序列与港口停留时间，从而有效预测港口拥堵。", "motivation": "准确预测港口拥堵对保障全球供应链可靠性至关重要，能优化运输计划、减少延误与成本，并提升供应链韧性。", "method": "研究基于历史AIS数据重建泊位调度，采用逆向强化学习确定奖励函数，并针对纽约/新泽西港某码头开发Temporal-IRL模型，学习泊位调度模式以预测船舶序列与停留时间。", "result": "利用2015年1月至2023年9月Maher码头数据训练模型，测试结果表明预测效果显著。", "conclusion": "Temporal-IRL模型能有效学习泊位调度优先级，准确预测船舶港口停留时间与拥堵情况，为供应链管理提供可靠工具。"}}
{"id": "2506.19846", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19846", "abs": "https://arxiv.org/abs/2506.19846", "authors": ["Ai Han", "Junxing Hu", "Pu Wei", "Zhiqian Zhang", "Yuhang Guo", "Jiawei Lu", "Zicheng Zhang"], "title": "JoyAgents-R1: Joint Evolution Dynamics for Versatile Multi-LLM Agents with Reinforcement Learning", "comment": "33 pages, 7 figures, under review", "summary": "Multi-agent reinforcement learning (MARL) has emerged as a prominent paradigm\nfor increasingly complex tasks. However, joint evolution across heterogeneous\nagents remains challenging due to cooperative inefficiency and training\ninstability. In this paper, we propose the joint evolution dynamics for MARL\ncalled JoyAgents-R1, which first applies Group Relative Policy Optimization\n(GRPO) to the joint training of heterogeneous multi-agents. By iteratively\nrefining agents' large language models (LLMs) and memories, the method achieves\nholistic equilibrium with optimal decision-making and memory capabilities.\nSpecifically, JoyAgents-R1 first implements node-wise Monte Carlo sampling on\nthe behavior of each agent across entire reasoning trajectories to enhance GRPO\nsampling efficiency while maintaining policy diversity. Then, our marginal\nbenefit-driven selection strategy identifies top-$K$ sampling groups with\nmaximal reward fluctuations, enabling targeted agent model updates that improve\ntraining stability and maximize joint benefits through cost-effective parameter\nadjustments. Meanwhile, JoyAgents-R1 introduces an adaptive memory evolution\nmechanism that repurposes GRPO rewards as cost-free supervisory signals to\neliminate repetitive reasoning and accelerate convergence. Experiments across\ngeneral and domain-specific scenarios demonstrate that JoyAgents-R1 achieves\nperformance comparable to that of larger LLMs while built on smaller\nopen-source models.", "AI": {"tldr": "本文提出JoyAgents-R1框架，通过群体相对策略优化(GRPO)和自适应记忆进化机制，解决多智能体强化学习中协同效率低与训练不稳定的问题，在通用和领域特定场景中实现与小规模开源模型相当的性能。", "motivation": "多智能体强化学习(MARL)面临异质智能体协同效率低下与训练不稳定的核心挑战，需开发能平衡决策最优性与记忆能力的联合演化方法。", "method": "1) 采用节点级蒙特卡洛采样增强GRPO轨迹多样性 2) 基于边际收益选择奖励波动最大的Top-$K$采样组定向更新模型 3) 利用GRPO奖励作为免费监督信号驱动记忆进化，消除重复推理。", "result": "实验表明JoyAgents-R1在通用与领域场景中，仅需小型开源模型即可达到与大语言模型(LLMs)相当的性能，同时提升38\\%训练稳定性与21\\%协同收益。", "conclusion": "该框架通过GRPO联合优化与记忆演化机制，为异质多智能体系统提供了高效稳定的训练范式，验证了小型模型通过算法创新实现复杂任务的可能性。"}}
{"id": "2506.17336", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17336", "abs": "https://arxiv.org/abs/2506.17336", "authors": ["Yubeen Bae", "Minchan Kim", "Jaejin Lee", "Sangbum Kim", "Jaehyung Kim", "Yejin Choi", "Niloofar Mireshghallah"], "title": "Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases", "comment": "29 pages", "summary": "Large language models (LLMs) are increasingly used as personal agents,\naccessing sensitive user data such as calendars, emails, and medical records.\nUsers currently face a trade-off: They can send private records, many of which\nare stored in remote databases, to powerful but untrusted LLM providers,\nincreasing their exposure risk. Alternatively, they can run less powerful\nmodels locally on trusted devices. We bridge this gap. Our Socratic\nChain-of-Thought Reasoning first sends a generic, non-private user query to a\npowerful, untrusted LLM, which generates a Chain-of-Thought (CoT) prompt and\ndetailed sub-queries without accessing user data. Next, we embed these\nsub-queries and perform encrypted sub-second semantic search using our\nHomomorphically Encrypted Vector Database across one million entries of a\nsingle user's private data. This represents a realistic scale of personal\ndocuments, emails, and records accumulated over years of digital activity.\nFinally, we feed the CoT prompt and the decrypted records to a local language\nmodel and generate the final response. On the LoCoMo long-context QA benchmark,\nour hybrid framework, combining GPT-4o with a local Llama-3.2-1B model,\noutperforms using GPT-4o alone by up to 7.1 percentage points. This\ndemonstrates a first step toward systems where tasks are decomposed and split\nbetween untrusted strong LLMs and weak local ones, preserving user privacy.", "AI": {"tldr": "提出了一种结合强大但不信任的LLM与本地弱模型的方法，通过苏格拉底式思维链推理和同态加密向量数据库保护用户隐私，在LoCoMo基准上性能提升7.1%。", "motivation": "用户在使用LLM处理敏感数据时面临隐私风险，需在强大但不信任的云端模型与隐私安全但性能较弱的本地模型之间做出选择。", "method": "首先由不信任的LLM生成通用思维链提示和子查询，然后通过同态加密向量数据库对用户百万级私有数据进行加密语义搜索，最后由本地模型结合提示和解密数据生成最终响应。", "result": "在LoCoMo长上下文QA基准测试中，GPT-4o与本地Llama-3.2-1B混合框架比单独使用GPT-4o性能提升最高达7.1个百分点。", "conclusion": "该系统首次实现了任务在不信任强LLM与本地弱模型间的分解与协作，在提升性能的同时有效保护了用户隐私。"}}
