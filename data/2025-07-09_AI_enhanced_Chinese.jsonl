{"id": "2507.05449", "categories": ["math.CO", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.05449", "abs": "https://arxiv.org/abs/2507.05449", "authors": ["Moshe White"], "title": "Radon Partitions of Random Gaussian Polytopes", "comment": "19 pages, 5 figures. This paper appeared as a chapter in the PhD\n  thesis of the author - submitted in May 2023, and approved in October 2023.\n  References might not be up to date", "summary": "In this paper we study a probabilistic framework for Radon partitions, where\nour points are chosen independently from the $d$-dimensional normal\ndistribution. For every point set we define a corresponding Radon polytope,\nwhich encodes all information about Radon partitions of our set - with Radon\npartitions corresponding to faces of the polytope. This allows us to derive\nexpressions for the probability that a given partition of $N$ randomly chosen\npoints in $\\mathbb{R}^d$ forms a Radon partition. These expressions involve\nconic kinematic formulas and intrinsic volumes, and in general require repeated\nintegration, though we obtain closed formulas in some cases. This framework can\nprovide new perspectives on open problems that can be formulated in terms of\nRadon partitions, such as Reay's relaxed Tverberg conjecture.", "AI": {"tldr": "本文研究了Radon分割的概率框架，通过定义Radon多面体并利用圆锥运动学公式和内在体积，推导了随机点集形成Radon分割的概率表达式。", "motivation": "研究Radon分割的概率特性，为解决如Reay松弛Tverberg猜想等开放性问题提供新视角。", "method": "为每个点集定义对应的Radon多面体，利用圆锥运动学公式和内在体积推导概率表达式，部分情况下获得闭合公式。", "result": "得到了$N$个$d$维正态分布随机点形成Radon分割的概率表达式，部分情况有闭合解，但通常需要重复积分。", "conclusion": "该概率框架为Radon分割相关开放问题提供了新的研究工具，尤其在Reay松弛Tverberg猜想等问题的应用上具有潜力。"}}
{"id": "2507.05473", "categories": ["math.CO", "05A99, 05C31, 52C07"], "pdf": "https://arxiv.org/pdf/2507.05473", "abs": "https://arxiv.org/abs/2507.05473", "authors": ["Tristram Bogart", "Kevin Woods"], "title": "Counting with two-level polynomials", "comment": "35 pages", "summary": "We examine combinatorial counting functions with two parameters, $n$ and $q$.\nFor fixed $q$, these functions are (quasi-)polynomial in $n$. As $q$ varies,\nthe degree of this polynomial is itself polynomial in $q$, as are the leading\ncoefficients. We carefully define these two-level polynomials, lay out their\nbasic algebraic properties, and provide a schema for showing a function is a\ntwo-level polynomial. Using the schema, we prove that a variety of counting\nfunctions arising in different areas of combinatorics are two-level\npolynomials. These include chromatic polynomials for many infinite families of\ngraphs, partitions of an integer into a given number of parts, placing\nnon-attacking chess pieces on a board, Sidon sets, and Sheffer sequences\n(including binomial type and Appell sequences).", "AI": {"tldr": "该研究探讨了具有两个参数$n$和$q$的组合计数函数，证明了这些函数在固定$q$时为(拟)多项式，并展示了其代数性质及应用。", "motivation": "研究动机在于理解组合计数函数在双参数$n$和$q$下的行为，特别是当$q$变化时多项式的阶数和主导系数的变化规律。", "method": "方法包括定义双层次多项式，阐述其基本代数性质，并提出一个框架来证明函数属于此类多项式。", "result": "结果表明，多种组合计数函数（如图的色多项式、整数分区、棋盘非攻击棋子放置、Sidon集及Sheffer序列）均为双层次多项式。", "conclusion": "结论指出，双层次多项式在组合数学多个领域中具有广泛适用性，为相关计数问题提供了统一的数学框架。"}}
{"id": "2507.05548", "categories": ["math.CO", "05C15"], "pdf": "https://arxiv.org/pdf/2507.05548", "abs": "https://arxiv.org/abs/2507.05548", "authors": ["Owen Henderschedt", "Jessica McDonald", "Songling Shan"], "title": "Total coloring graphs with large minimum degree", "comment": "arXiv admin note: text overlap with arXiv:2405.07382", "summary": "We prove that for all $\\varepsilon>0$, there exists a positive integer $n_0$\nsuch that if $G$ is a graph on $n\\geq n_0$ vertices with\n$\\delta(G)\\geq\\tfrac{1}{2}(1 + \\varepsilon)n$, then $G$ satisfies the Total\nColoring Conjecture, that is, $\\chi_T(G)\\leq \\Delta(G)+2$.", "AI": {"tldr": "证明了对于所有$\\varepsilon>0$，存在正整数$n_0$，使得当图$G$的顶点数$n\\geq n_0$且最小度$\\delta(G)\\geq\\tfrac{1}{2}(1 + \\varepsilon)n$时，$G$满足全着色猜想，即$\\chi_T(G)\\leq \\Delta(G)+2$。", "motivation": "研究全着色猜想在特定条件下的成立性，扩展图论中关于图着色问题的理论成果。", "method": "通过设定参数$\\varepsilon$和$n_0$，分析图的最小度$\\delta(G)$与顶点数$n$的关系，验证全着色猜想的成立条件。", "result": "当图$G$的顶点数足够大且最小度满足$\\delta(G)\\geq\\tfrac{1}{2}(1 + \\varepsilon)n$时，全着色猜想成立。", "conclusion": "该研究为全着色猜想提供了新的理论支持，证明了在特定条件下图的着色数上界成立。"}}
{"id": "2507.05570", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.05570", "abs": "https://arxiv.org/abs/2507.05570", "authors": ["Jin Cai", "Bo Zhou"], "title": "Signless Laplacian index conditions for doubly chorded cycles in graphs with given order", "comment": null, "summary": "In this paper, we show that for a graph of order $n$, where $n\\ge 5$, if the\nsignless Laplacian index is larger than or equal to certain value depending on\n$n$, then the graph contains a doubly chorded cycle, where the chords incident\nto a common vertex, unless it is two specified graphs.", "AI": {"tldr": "本文证明当$n\\ge 5$时，若图的阶数为$n$且无符号拉普拉斯指数超过特定阈值，则该图必含双弦环（两弦共点），除非属于两种特例图。", "motivation": "研究图的谱性质与结构特征（如双弦环存在性）之间的关联，拓展代数图论的应用边界。", "method": "通过分析图的阶数$n$与无符号拉普拉斯指数$q(G)$的数值关系，结合极值图论方法进行结构判定。", "result": "确立$n\\ge 5$时$q(G)$的临界条件，证明除两种特例外，满足条件的图必然存在共点双弦的环结构。", "conclusion": "该结果为无符号拉普拉斯谱理论提供了新的结构判据，揭示了特定谱范围下图形的组合性质。"}}
{"id": "2507.05382", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.05382", "abs": "https://arxiv.org/abs/2507.05382", "authors": ["M. Marques Alves", "J. E. Navarro Caballero", "R. T. Marcavillaca"], "title": "An inexact inertial projective splitting algorithm with strong convergence", "comment": "31 pages", "summary": "We propose and study a strongly convergent inexact inertial projective\nsplitting (PS) algorithm for finding zeros of composite monotone inclusion\nproblems involving the sum of finitely many maximal monotone operators. Strong\nconvergence of the iterates is ensured by projections onto the intersection of\nappropriately defined half-spaces, even in the absence of inertial effects. We\nalso establish iteration-complexity results for the proposed PS method, which\nlikewise hold without requiring inertial terms. The algorithm includes two\ninertial sequences, controlled by parameters satisfying mild conditions, while\npreserving strong convergence and enabling iteration-complexity analysis.\nFurthermore, for more structured monotone inclusion problems, we derive two\nvariants of the main algorithm that employ forward-backward and\nforward-backward-forward steps.", "AI": {"tldr": "提出一种强收敛的近似惯性投影分裂算法，用于求解包含有限多个极大单调算子之和的复合单调包含问题，通过投影确保强收敛性，并分析了迭代复杂度。", "motivation": "研究复合单调包含问题的求解方法，旨在开发一种在无惯性效应下仍能保证强收敛性的算法，并分析其迭代复杂度。", "method": "采用近似惯性投影分裂算法，包含两个惯性序列，参数满足温和条件，同时引入前向后向和前向后向前向步骤的变体。", "result": "算法在无惯性项时仍能保证强收敛性，并提供了迭代复杂度分析，适用于结构化单调包含问题。", "conclusion": "所提算法在强收敛性和迭代复杂度方面表现优异，适用于多种单调包含问题，具有广泛的应用潜力。"}}
{"id": "2507.05374", "categories": ["math.NT", "math.AG", "math.RT", "11S31, 11F85, 14G22, 14G45"], "pdf": "https://arxiv.org/pdf/2507.05374", "abs": "https://arxiv.org/abs/2507.05374", "authors": ["Andrew Graham", "Pol van Hoften", "Sean Howe"], "title": "$p$-adic Fourier theory in families", "comment": "80 pages. Comments welcome!", "summary": "We construct Fourier transforms relating functions and distributions on\nfinite height $p$-divisible rigid analytic groups and objects in a dual\ncategory of $\\mathbb{Z}_p$-local systems with analyticity conditions. Our\nFourier transforms are formulated as isomorphisms of solid Hopf algebras over\narbitrary small v-stacks, and generalize earlier constructions of Amice and\nSchneider--Teitelbaum. We also construct compatible integral Fourier transforms\nfor $p$-divisible groups and their dual Tate modules. As an application, we use\nthe Weierstrass $\\wp$-function to construct a global Eisenstein measure over\nthe $p$-adic modular curve, extending previous constructions of Katz over the\nordinary locus and at CM points, and show its generic fiber, the global\nEisenstein distribution, gives rise to new families of quaternionic modular\nforms that overconverge from profinite sets in the rigid analytic supersingular\nlocus.", "AI": {"tldr": "本文构建了有限高度$p$-可除刚性解析群上的傅里叶变换，建立了与$\\mathbb{Z}_p$-局部系统的对偶关系，并应用于构造全局Eisenstein测度，生成新的超收敛四元数模形式。", "motivation": "研究动机在于扩展Amice和Schneider-Teitelbaum的傅里叶变换构造，建立更一般的$p$-可除群与对偶Tate模之间的积分傅里叶变换，并探索其在$p$-模曲线上的应用。", "method": "方法包括构建固体Hopf代数同构作为傅里叶变换，利用Weierstrass $\\wp$-函数构造全局Eisenstein测度，并通过刚性解析超奇异轨迹的有限集实现超收敛。", "result": "主要成果包括：1) 建立了任意小v-叠上的傅里叶变换同构；2) 扩展了Katz在普通轨迹和CM点的构造；3) 证明了全局Eisenstein分布生成新型四元数模形式。", "conclusion": "结论表明该傅里叶变换框架统一了先前离散与连续理论，其应用于$p$-模曲线产生的超收敛模形式，为志村簇算术研究开辟了新途径。"}}
{"id": "2507.05919", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2507.05919", "abs": "https://arxiv.org/abs/2507.05919", "authors": ["Thierry Marchant", "Sandip Sarkar"], "title": "Axiomatic characterizations of dissimilarity orderings and distances between sets", "comment": null, "summary": "We characterize the orderings of pairs of sets induced by several distances:\nHamming, Jaccard, S\\o rensen-Dice and Overlap. We also characterize these\ndistances.", "AI": {"tldr": "本文研究了Hamming、Jaccard、S\\o rensen-Dice和Overlap等距离度量对集合对排序的影响，并给出了这些距离的特征描述。", "motivation": "研究不同距离度量如何影响集合对的排序，以及这些距离本身的数学特性。", "method": "通过数学分析和特征描述，对Hamming、Jaccard、S\\o rensen-Dice和Overlap等距离进行系统研究。", "result": "确定了这些距离度量对集合对排序的具体影响，并给出了它们的数学特征。", "conclusion": "不同距离度量对集合对的排序有显著影响，研究结果为相关领域提供了理论基础。"}}
{"id": "2507.05267", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05267", "abs": "https://arxiv.org/abs/2507.05267", "authors": ["Markus Böck"], "title": "Strongly Solving $7 \\times 6$ Connect-Four on Consumer Grade Hardware", "comment": null, "summary": "While the game Connect-Four has been solved mathematically and the best move\ncan be effectively computed with search based methods, a strong solution in the\nform of a look-up table was believed to be infeasible. In this paper, we\nrevisit a symbolic search method based on binary decision diagrams to produce\nstrong solutions. With our efficient implementation we were able to produce a\n89.6 GB large look-up table in 47 hours on a single CPU core with 128 GB main\nmemory for the standard $7 \\times 6$ board size. In addition to this\nwin-draw-loss evaluation, we include an alpha-beta search in our open source\nartifact to find the move which achieves the fastest win or slowest loss.", "AI": {"tldr": "本文通过基于二元决策图的符号搜索方法，成功构建了标准$7 \\times 6$棋盘四子棋的89.6GB强解查找表，并在开源工具中整合了α-β搜索以优化胜负路径。", "motivation": "尽管四子棋已有数学解法和搜索计算方法，但传统认为构建强解查找表不可行。本研究旨在挑战这一认知，探索高效实现的可能性。", "method": "采用二元决策图（BDD）进行符号搜索，结合单核CPU（128GB内存）的优化实现，并集成α-β搜索算法以加速胜负决策。", "result": "在47小时内生成89.6GB的胜-平-负评估查找表，同时开源工具能通过α-β搜索快速定位最优胜负路径。", "conclusion": "研究证明通过符号搜索方法可高效构建四子棋强解查找表，为组合游戏求解提供了新的技术路径。"}}
{"id": "2507.05371", "categories": ["math.LO", "03E25, 22F05 (Primary) 57N50, 57M60 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.05371", "abs": "https://arxiv.org/abs/2507.05371", "authors": ["Justin Young"], "title": "Permutation Models Arising From Topological Ideals", "comment": "13 pages", "summary": "A recent paper by Zapletal arXiv:2404.10612 discusses permutation models of\nset theory which arise from dynamical ideals and highlights properties of the\ndynamical ideal which relate to fragments of choice in the permutation model.\nIn this paper, we provide several examples from topology which illustrate using\nthese connections to argue that the corresponding permutation model satisfies\neither the axiom of countable choice or well-ordered choice.", "AI": {"tldr": "论文探讨了由动态理想产生的置换模型及其与选择公理片段的关系，并通过拓扑学示例验证了置换模型满足可数选择公理或良序选择公理。", "motivation": "研究动态理想生成的置换模型，旨在理解其与选择公理片段（如可数选择公理和良序选择公理）的关联。", "method": "通过拓扑学中的具体示例，分析动态理想的性质，并论证这些性质如何影响置换模型中的选择公理片段。", "result": "研究表明，特定的动态理想性质可以确保置换模型满足可数选择公理或良序选择公理。", "conclusion": "该研究为理解置换模型与选择公理片段的关系提供了新的视角，并通过拓扑学示例验证了理论结果。"}}
{"id": "2507.05628", "categories": ["math.ST", "stat.TH", "60G15, 62F12"], "pdf": "https://arxiv.org/pdf/2507.05628", "abs": "https://arxiv.org/abs/2507.05628", "authors": ["Mitsuki Kobayashi", "Yuto Nishiwaki", "Yasutaka Shimizu", "Nobutoki Takaoka"], "title": "Maximum likelihood estimation of mean functions for Gaussian processes under small noise asymptotics", "comment": null, "summary": "Maximum likelihood estimators for time-dependent mean functions within\nGaussian processes are provided in the context of continuous observations. We\nfind the widest possible class of mean functions for which the likelihood\nfunction can be written explicitly. When it is subjected to a small noise\nasymptotic condition leading to the vanishing of the primary Gaussian noise, we\nattain local asymptotic normality results, accompanied by insights into the\nasymptotic efficiency of these estimators. In addition, we introduce\nM-estimators based on discrete samples, which also leads us to the asymptotic\nefficiency. Furthermore, we provide quasi-information criteria for model\nselection analogous to Akaike Information Criteria in discretely observed\ncases.", "AI": {"tldr": "本文研究了高斯过程中时间依赖均值函数的极大似然估计，提出了最广泛的均值函数类别以实现显式似然函数，并探讨了小噪声渐近条件下的局部渐近正态性与估计效率。同时，基于离散样本的M估计量及类AIC准则是模型选择的关键贡献。", "motivation": "研究高斯过程在连续观测下时间依赖均值函数的估计问题，旨在构建最广泛的均值函数类别以实现显式似然函数，并分析小噪声条件下的渐近性质与估计效率。", "method": "采用极大似然估计法处理连续观测数据，推导显式似然函数；引入小噪声渐近条件分析局部渐近正态性；提出基于离散样本的M估计量及类AIC准则用于模型选择。", "result": "成功构建了最广泛的均值函数类别，其似然函数可显式表达；在小噪声条件下证明了局部渐近正态性及估计效率；离散样本M估计量同样具有渐近高效性，并提出了有效的模型选择准则。", "conclusion": "本文为高斯过程时间依赖均值函数提供了普适的估计框架，理论证明了估计量的渐近最优性，同时通过离散样本扩展与模型选择工具增强了方法的实用性。"}}
{"id": "2507.05415", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05415", "abs": "https://arxiv.org/abs/2507.05415", "authors": ["Lu Xian", "Van Tran", "Lauren Lee", "Meera Kumar", "Yichen Zhang", "Florian Schaub"], "title": "Layered, Overlapping, and Inconsistent: A Large-Scale Analysis of the Multiple Privacy Policies and Controls of U.S. Banks", "comment": "Accepted for publication in CCS 2025. This is a pre-publication\n  version", "summary": "Privacy policies are often complex. An exception is the two-page standardized\nnotice that U.S. financial institutions must provide under the\nGramm-Leach-Bliley Act (GLBA). However, banks now operate websites, mobile\napps, and other services that involve complex data sharing practices that\nrequire additional privacy notices and do-not-sell opt-outs. We conducted a\nlarge-scale analysis of how U.S. banks implement privacy policies and controls\nin response to GLBA; other federal privacy policy requirements; and the\nCalifornia Consumer Privacy Act (CCPA), a key example for U.S. state privacy\nlaws. We focused on the disclosure and control of a set of especially\nprivacy-invasive practices: third-party data sharing for marketing-related\npurposes. We collected privacy policies for the 2,067 largest U.S. banks,\n45.3\\% of which provided multiple policies. Across disclosures and controls\nwithin the \\textit{same} bank, we identified frequent, concerning\ninconsistencies -- such as banks indicating in GLBA notices that they do not\nshare with third parties but disclosing sharing elsewhere, or using third-party\nmarketing/advertising cookies without disclosure. This multiplicity of\npolicies, with the inconsistencies it causes, may create consumer confusion and\nundermine the transparency goals of the very laws that require them. Our\nfindings call into question whether current policy requirements, such as the\nGLBA notice, are achieving their intended goals in today's online banking\nlandscape. We discuss potential avenues for reforming and harmonizing privacy\npolicies and control requirements across federal and state laws.", "AI": {"tldr": "美国银行隐私政策存在多重性与不一致性，可能削弱法律透明度目标，呼吁政策改革与协调。", "motivation": "研究美国银行如何实施隐私政策及控制措施，以应对GLBA、联邦隐私政策要求及CCPA，特别关注营销相关第三方数据共享的披露与控制。", "method": "收集了美国2067家最大银行的隐私政策，其中45.3\\%提供多份政策，分析披露与控制措施的不一致性。", "result": "发现银行在同一机构内的披露与控制存在频繁且令人担忧的不一致，例如GLBA通知中声称不共享数据，却在其他地方披露共享行为，或未披露使用第三方营销/广告cookie。", "conclusion": "当前政策要求（如GLBA通知）可能未达到预期目标，需改革并协调联邦与州法律的隐私政策与控制要求。"}}
{"id": "2507.05614", "categories": ["math.CO", "math.AG", "math.AT", "math.RT"], "pdf": "https://arxiv.org/pdf/2507.05614", "abs": "https://arxiv.org/abs/2507.05614", "authors": ["Mathieu Guay-Paquet"], "title": "Divided difference operators for Hessenberg representations", "comment": "23 pages", "summary": "The equivariant cohomology ring of a regular semisimple Hessenberg variety in\ntype A is a free module over the equivariant cohomology ring of a point. When\nequipped with Tymoczko's dot action, it becomes a twisted representation of the\nsymmetric group, and the character of this representation is given by the\nchromatic quasisymmetric function of an indifference graph. In this note, we\nuse divided difference operators to decompose this representation as a direct\nsum of sub-representations in a way that categorifies the modular relation\nbetween chromatic quasisymmetric functions.", "AI": {"tldr": "本文研究了A型正则半单Hessenberg簇的等变上同调环，通过Tymoczko点作用将其表示为对称群的扭曲表示，并利用色准对称函数和分差算子进行表示分解。", "motivation": "探讨正则半单Hessenberg簇的等变上同调环的结构及其与对称群表示的联系，旨在通过色准对称函数揭示其组合性质。", "method": "使用分差算子对等变上同调环进行表示分解，结合Tymoczko点作用，将问题转化为色准对称函数的模关系范畴化。", "result": "证明了该表示可分解为子表示的直和，且分解过程范畴化了色准对称函数之间的模关系。", "conclusion": "通过分差算子和模关系范畴化，为A型Hessenberg簇的等变上同调环表示提供了新的组合解释与结构分解方法。"}}
{"id": "2507.05466", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.05466", "abs": "https://arxiv.org/abs/2507.05466", "authors": ["Anne Rubbens", "Sébastien Colla", "Julien M. Hendrickx"], "title": "Computer-aided analyses of stochastic first-order methods, via interpolation conditions for stochastic optimization", "comment": null, "summary": "This work proposes a framework, embedded within the Performance Estimation\nframework (PEP), for obtaining worst-case performance guarantees on stochastic\nfirst-order methods. Given a first-order method, a function class, and a noise\nmodel with prescribed expectation and variance properties, we present a range\nof semidefinite programs (SDPs) of increasingly large size, whose solutions\nyield increasingly strong convergence guarantees on the problem. Eventually, we\npropose SDPs whose size depends on $2^N$, with $N$ the number of iterations\nanalyzed, that yield tight guarantees, attained by specific functions and noise\ndistributions within these classes. On the other side of the spectrum, we\npropose SDPs whose size depends linearly on $N$, and numerically show that, on\nmany problems, they already provide tight guarantees.\n  The framework accommodates a wide range of stochastic settings, with finite\nor infinite support, including the unstructured noise model with bounded\nvariance, finite-sum optimization, and block-coordinate methods, in a unified\nmanner, as guarantees apply to any setting consistent with the noise model,\ni.e., its expectation and variance. It covers both non-variance-reduced and\nvariance-reduced methods. Using the framework, we analyze the stochastic\ngradient method under several noise models, and illustrate how the resulting\nnumerical and analytical convergence rates connect with existing results. In\nparticular, we provide improved convergence rates on the unstructured noise\nmodel with bounded variance and in the block-coordinate setting.", "AI": {"tldr": "本文提出了一种基于性能估计框架（PEP）的新方法，用于为随机一阶方法提供最坏情况下的性能保证。通过半定规划（SDP）的逐步扩展，该方法能够提供从宽松到严格的收敛保证，适用于多种随机设置，并改进了现有收敛速率。", "motivation": "研究动机在于为随机一阶优化方法提供统一且严格的性能保证框架，覆盖多种噪声模型和优化场景，以弥补现有理论分析的不足。", "method": "方法基于PEP框架，提出了一系列规模逐步增大的半定规划（SDP）问题。这些SDP的规模从线性增长到指数级（$2^N$，$N$为迭代次数），用于提供不同强度的收敛保证。框架支持有限或无限支持的噪声模型，包括有界方差非结构化噪声、有限和优化及块坐标方法。", "result": "结果表明，即使是规模线性于$N$的SDP，在许多问题上也能提供紧致的收敛保证。通过框架分析，改进了非结构化有界方差噪声模型和块坐标设置下的收敛速率，并与现有理论结果建立了联系。", "conclusion": "该框架为随机一阶方法提供了统一的性能分析工具，能够灵活适应多种优化场景，并通过SDP的规模调整平衡计算复杂度与保证强度，为随机优化理论提供了新的分析视角。"}}
{"id": "2507.05693", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.05693", "abs": "https://arxiv.org/abs/2507.05693", "authors": ["Takeo Uramoto"], "title": "The completeness of the Deligne-Ribet monoids", "comment": "5 pages", "summary": "Following Cornelissen, Li, Marcolli, and Smit, this short paper proves that\nthe isomorphism of the Deligne-Ribet monoids $DR_K, DR_L$ for two number fields\n$K, L$ implies the field isomorphism of $K$ and $L$. Thus the Deligne-Ribet\nmonoid $DR_K$ gives a complete invariant of the number field $K$ as in the case\nof the absolute Galois group $G_K$.", "AI": {"tldr": "本文证明了Deligne-Ribet幺半群$DR_K$是数域$K$的完整不变量，类似于绝对Galois群$G_K$的情况。", "motivation": "研究Deligne-Ribet幺半群$DR_K$是否能像绝对Galois群$G_K$一样，成为数域的完整不变量。", "method": "通过比较两个数域$K$和$L$的Deligne-Ribet幺半群$DR_K$和$DR_L$的同构关系。", "result": "证明了若$DR_K$与$DR_L$同构，则数域$K$与$L$同构。", "conclusion": "Deligne-Ribet幺半群$DR_K$确实可以作为数域$K$的完整不变量，与绝对Galois群$G_K$具有同等效力。"}}
{"id": "2507.06169", "categories": ["math.CO", "cs.DM", "05C75 (Primary) 05C83 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.06169", "abs": "https://arxiv.org/abs/2507.06169", "authors": ["Maria Chudnovsky", "David Fischer", "Sepehr Hajebi", "Sophie Spirkl", "Bartosz Walczak"], "title": "A simple layered-wheel-like construction", "comment": "16 pages, 2 figures", "summary": "In recent years, there has been significant interest in characterizing the\ninduced subgraph obstructions to bounded treewidth and pathwidth. While this\nhas recently been resolved for pathwidth, the case of treewidth remains open,\nand prior work has reduced the problem to understanding the layered-wheel-like\nobstructions -- graphs that contain large complete minor models with each\nbranching set inducing a path; exclude large walls as induced minors; exclude\nlarge complete bipartite graphs as induced minors; and exclude large complete\nsubgraphs.\n  There are various constructions of such graphs, but they are all rather\ninvolved. In this paper, we present a simple construction of layered-wheel-like\ngraphs with arbitrarily large treewidth. Three notable features of our\nconstruction are: (a) the vertices of degree at least four can be made to be\narbitrarily far apart; (b) the girth can be made to be arbitrarily large; and\n(c) every outerstring induced subgraph of the graphs from our construction has\ntreewidth bounded by an absolute constant. In contrast, among several\npreviously known constructions of layered wheels, none achieves (a); at most\none satisfies either (b) or (c); and none satisfies both (b) and (c)\nsimultaneously.\n  In particular, this is related to a former conjecture of Trotignon, that\nevery graph with large enough treewidth, excluding large walls and large\ncomplete bipartite graphs as induced minors, and large complete subgraphs, must\ncontain an outerstring induced subgraph of large treewidth. Our construction\nprovides the first counterexample to this conjecture that can also be made to\nhave arbitrarily large girth.", "AI": {"tldr": "本文提出了一种简单构造具有任意大树宽的层轮状图的方法，解决了树宽障碍物表征的开放问题，并首次提供了具有任意大围长的反例，反驳了Trotignon的猜想。", "motivation": "近年来，表征树宽和路径宽的诱导子图障碍物引起了广泛关注。虽然路径宽的情况已解决，但树宽的情况仍开放，且先前研究已将该问题简化为理解层轮状图。本文旨在提供一种简单的层轮状图构造方法，满足多个先前构造未能同时实现的性质。", "method": "本文提出了一种简单的构造方法，生成具有任意大树宽的层轮状图。该方法的关键在于：(a) 高度数顶点可以任意远离；(b) 围长可以任意大；(c) 所有外弦诱导子图的树宽有绝对常数上界。", "result": "构造的层轮状图满足三个显著特性：(a)、(b)和(c)，且首次提供了可以具有任意大围长的反例，反驳了Trotignon的猜想。与先前构造相比，本文方法在多个方面具有优势。", "conclusion": "本文的构造不仅简化了层轮状图的生成，还首次实现了多个理想性质的组合，为树宽障碍物的研究提供了新的视角，并解决了Trotignon猜想的反例问题。"}}
{"id": "2507.05283", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05283", "abs": "https://arxiv.org/abs/2507.05283", "authors": ["Yue Wang", "Miao Zhou", "Guijing Huang", "Rui Zhuo", "Chao Yi", "Zhenliang Ma"], "title": "Chat2SPaT: A Large Language Model Based Tool for Automating Traffic Signal Control Plan Management", "comment": null, "summary": "Pre-timed traffic signal control, commonly used for operating signalized\nintersections and coordinated arterials, requires tedious manual work for\nsignaling plan creating and updating. When the time-of-day or day-of-week plans\nare utilized, one intersection is often associated with multiple plans, leading\nto further repetitive manual plan parameter inputting. To enable a\nuser-friendly traffic signal control plan management process, this study\nproposes Chat2SPaT, a method to convert users' semi-structured and ambiguous\ndescriptions on the signal control plan to exact signal phase and timing (SPaT)\nresults, which could further be transformed into structured stage-based or\nring-based plans to interact with intelligent transportation system (ITS)\nsoftware and traffic signal controllers. With curated prompts, Chat2SPaT first\nleverages large language models' (LLMs) capability of understanding users' plan\ndescriptions and reformulate the plan as a combination of phase sequence and\nphase attribute results in the json format. Based on LLM outputs, python\nscripts are designed to locate phases in a cycle, address nuances of traffic\nsignal control, and finally assemble the complete traffic signal control plan.\nWithin a chat, the pipeline can be utilized iteratively to conduct further plan\nediting. Experiments show that Chat2SPaT can generate plans with an accuracy of\nover 94% for both English and Chinese cases, using a test dataset with over 300\nplan descriptions. As the first benchmark for evaluating LLMs' capability of\nunderstanding traffic signal control plan descriptions, Chat2SPaT provides an\neasy-to-use plan management pipeline for traffic practitioners and researchers,\nserving as a potential new building block for a more accurate and versatile\napplication of LLMs in the field of ITS. The source codes, prompts and test\ndataset are openly accessible at https://github.com/yuewangits/Chat2SPaT.", "AI": {"tldr": "本研究提出Chat2SPaT方法，利用大语言模型(LLM)将用户对交通信号控制计划的半结构化描述转换为精确的信号相位与时间(SPaT)结果，准确率超过94%，为交通从业者提供了易用的计划管理工具。", "motivation": "传统定时交通信号控制需要繁琐的手动计划创建与更新，尤其当采用分时段方案时，需重复输入参数。本研究旨在通过自然语言交互简化这一过程。", "method": "Chat2SPaT通过精心设计的提示词，利用LLM理解用户描述并输出JSON格式的相位序列与属性，再通过Python脚本处理信号控制细节并组装完整方案，支持聊天式迭代编辑。", "result": "在包含300多条描述的中英文测试集中，系统生成方案的准确率均超过94%，建立了首个评估LLM理解交通信号控制描述能力的基准。", "conclusion": "Chat2SPaT为智能交通系统(ITS)领域提供了LLM应用的新范式，其开源代码与数据集可促进该技术的进一步发展与应用。"}}
{"id": "2507.05471", "categories": ["math.LO", "math.KT", "03E35, 03E75, 18G10"], "pdf": "https://arxiv.org/pdf/2507.05471", "abs": "https://arxiv.org/abs/2507.05471", "authors": ["Jeffrey Bergfalk", "Matteo Casarosa"], "title": "Higher limits of wider systems", "comment": "25 pages; comments welcome", "summary": "Write $\\mathbf{A}_\\lambda$ for what might be described as the most elementary\nnontrivial inverse system of abelian groups indexed by the functions from the\ncardinal $\\lambda$ to the set of natural numbers. The question of whether for\nany fixed $n$ the derived limit $\\mathrm{lim}^n\\,\\mathbf{A}_\\lambda$ may vanish\nfor only a nonempty subset of the class of infinite cardinals $\\lambda$ is\nrecorded in both [Be17] and [Ban23], and bears closely on several related\nfurther ones. We answer this question in the affirmative; in fact, we show the\nmaximal possibility, namely that this can simultaneously happen in every degree\n$n>1$.", "AI": {"tldr": "论文证明了对于任意$n>1$，存在无限基数$\\lambda$使得$\\mathrm{lim}^n\\,\\mathbf{A}_\\lambda$为零，解决了[Be17]和[Ban23]中提出的问题。", "motivation": "研究$\\mathrm{lim}^n\\,\\mathbf{A}_\\lambda$在无限基数$\\lambda$下的消失情况，这一问题在[Be17]和[Ban23]中被提出，并与多个相关问题密切相关。", "method": "通过分析由基数$\\lambda$到自然数集的函数索引的阿贝尔群逆系统$\\mathbf{A}_\\lambda$，探讨其导出极限的性质。", "result": "证明了对于每个$n>1$，存在无限基数$\\lambda$使得$\\mathrm{lim}^n\\,\\mathbf{A}_\\lambda$为零，这是最大可能的结果。", "conclusion": "该结果不仅回答了[Be17]和[Ban23]中的问题，还表明在每一个$n>1$的度数下，$\\mathrm{lim}^n\\,\\mathbf{A}_\\lambda$都可以在无限基数$\\lambda$下消失。"}}
{"id": "2507.05634", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.05634", "abs": "https://arxiv.org/abs/2507.05634", "authors": ["Kangda K. Wren"], "title": "A Note on Inferential Decisions, Errors and Path-Dependency", "comment": "11 pages: 7 main text, 1 highlight, 3 appendix and references", "summary": "Consider the standard sequential testing of a binary outcome. The associated\nbelief process and its objectively true conditional-probability counterpart\ngenerally differ, but they converge to the same target in well-defined tests.\nWe show that unless the two processes are 'essentially identical', differing at\nmost by an a priori factor, time-homogeneous continuous sequential decisions\nbased on the former must be path-dependent with respect to state-variables\nbased on the latter or other non-essentially-identical belief processes.\nFurther, total inferential errors decompose into two components with distinct\nand independent characteristics.", "AI": {"tldr": "本文研究了二元结果序列测试中的信念过程与客观条件概率的差异及其收敛性，揭示了非本质相同信念过程下时间齐次连续决策必须具有路径依赖性，并将推断误差分解为两个独立成分。", "motivation": "探讨二元序列测试中信念过程与客观条件概率的差异及其对决策路径依赖性的影响，旨在理解推断误差的结构特性。", "method": "通过理论分析比较信念过程与客观条件概率的收敛性，并研究时间齐次连续决策在非本质相同信念过程下的路径依赖性。", "result": "除非信念过程与客观条件概率'本质相同'（仅相差先验因子），否则时间齐次连续决策必须对状态变量具有路径依赖性；推断误差可分解为两个独立成分。", "conclusion": "研究揭示了信念过程与客观条件概率的差异如何导致决策路径依赖性，并提出了推断误差的分解框架，为序列测试理论提供了新见解。"}}
{"id": "2507.05421", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05421", "abs": "https://arxiv.org/abs/2507.05421", "authors": ["Harrison Green", "Claire Le Goues", "Fraser Brown"], "title": "FrameShift: Learning to Resize Fuzzer Inputs Without Breaking Them", "comment": null, "summary": "Coverage-guided fuzzers are powerful automated bug-finding tools. They mutate\nprogram inputs, observe coverage, and save any input that hits an unexplored\npath for future mutation. Unfortunately, without knowledge of input\nformats--for example, the relationship between formats' data fields and\nsizes--fuzzers are prone to generate destructive frameshift mutations. These\ntime-wasting mutations yield malformed inputs that are rejected by the target\nprogram. To avoid such breaking mutations, this paper proposes a novel,\nlightweight technique that preserves the structure of inputs during mutation by\ndetecting and using relation fields.\n  Our technique, FrameShift, is simple, fast, and does not require additional\ninstrumentation beyond standard coverage feedback. We implement our technique\nin two state-of-the-art fuzzers, AFL++ and LibAFL, and perform a 12+ CPU-year\nfuzzer evaluation, finding that FrameShift improves the performance of the\nfuzzer in each configuration, sometimes increasing coverage by more than 50%.\nFurthermore, through a series of case studies, we show that our technique is\nversatile enough to find important structural relationships in a variety of\nformats, even generalizing beyond C/C++ targets to both Rust and Python.", "AI": {"tldr": "本文提出了一种名为FrameShift的轻量级技术，通过检测和利用关系字段来避免破坏性突变，从而提升模糊测试的性能。", "motivation": "现有的覆盖率引导模糊测试工具在缺乏输入格式知识的情况下，容易产生破坏性的帧移突变，导致生成畸形输入并被目标程序拒绝，浪费大量时间。", "method": "FrameShift技术简单、快速，无需额外的插装，仅依赖标准覆盖率反馈，通过检测和利用关系字段来保持输入结构。", "result": "在AFL++和LibAFL两种先进模糊测试工具中的实现表明，FrameShift在每种配置下均提升了性能，有时覆盖率增加超过50%，并能适用于多种格式和语言（如Rust和Python）。", "conclusion": "FrameShift是一种高效且通用的技术，能够显著提升模糊测试的覆盖率和性能，适用于多种编程语言和输入格式。"}}
{"id": "2507.05641", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.05641", "abs": "https://arxiv.org/abs/2507.05641", "authors": ["Xiaoyu He", "Jiaxi Nie", "Yuval Wigderson", "Hung-Hsun Hans Yu"], "title": "Off-Diagonal Ramsey Numbers for Linear Hypergraphs", "comment": "15 pages, 4 figures", "summary": "We study off-diagonal Ramsey numbers $r(H, K_n^{(k)})$ of $k$-uniform\nhypergraphs, where $H$ is a fixed linear $k$-uniform hypergraph and $K_n^{(k)}$\nis complete on $n$ vertices. Recently, Conlon et al.\\ disproved the folklore\nconjecture that $r(H, K_n^{(3)})$ always grows polynomially in $n$. In this\npaper we show that much larger growth rates are possible in higher uniformity.\nIn uniformity $k\\ge 4$, we prove that for any constant $C>0$, there exists a\nlinear $k$-uniform hypergraph $H$ for which $$r(H,K_n^{(k)}) \\geq\n\\twr_{k-2}(2^{(\\log n)^C}).$$", "AI": {"tldr": "本文研究了k-一致超图的非对角Ramsey数$r(H, K_n^{(k)})$，证明在$k\\ge4$时存在线性k-一致超图H使得该数呈超多项式增长。", "motivation": "近期Conlon等人否定了关于$r(H, K_n^{(3)})$总是多项式增长的猜想，本文旨在探究更高一致性下可能出现的更大增长率。", "method": "通过构造特定的线性k-一致超图H，分析其与完全k-一致超图$K_n^{(k)}$的Ramsey数下界。", "result": "对于任意常数$C>0$和$k\\ge4$，存在线性k-一致超图H满足$r(H,K_n^{(k)}) \\geq \\twr_{k-2}(2^{(\\log n)^C})$。", "conclusion": "在$k\\ge4$的一致性下，非对角Ramsey数可以呈现远超多项式的增长率，突破了三维情形的认知边界。"}}
{"id": "2507.05501", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.05501", "abs": "https://arxiv.org/abs/2507.05501", "authors": ["Oscar Dowson", "Xavier Gandibleux", "Gökhan Kof"], "title": "MultiObjectiveAlgorithms.jl: a Julia package for solving multi-objective optimization problems", "comment": null, "summary": "We present MultiObjectiveAlgorithms.jl, an open-source Julia library for\nsolving multi-objective optimization problems written in JuMP.\nMultiObjectiveAlgorithms.jl implements a number of different solution\nalgorithms, which all rely on an iterative scalarization of the problem from a\nmulti-objective optimization problem to a sequence of single-objective\nsubproblems. As part of this work, we extended JuMP to support vector-valued\nobjective functions. Because it is based on JuMP, MultiObjectiveAlgorithms.jl\ncan use a wide variety of commercial and open-source solvers to solve the\nsingle-objective subproblems, and it supports problem classes ranging from\nlinear, to conic, semi-definite, and general nonlinear.\nMultiObjectiveAlgorithms.jl is available at\nhttps://github.com/jump-dev/MultiObjectiveAlgorithms.jl under a MPL-2 license.", "AI": {"tldr": "MultiObjectiveAlgorithms.jl是一个开源的Julia库，用于解决基于JuMP的多目标优化问题，支持多种求解器和问题类型。", "motivation": "开发一个灵活、开源的Julia库，以支持多目标优化问题的求解，并扩展JuMP的功能以支持向量值目标函数。", "method": "通过迭代标量化方法将多目标优化问题转化为一系列单目标子问题，并利用JuMP支持多种商业和开源求解器。", "result": "MultiObjectiveAlgorithms.jl成功实现了多种求解算法，支持从线性到非线性等多种问题类型，并在MPL-2许可下开源。", "conclusion": "该库为多目标优化问题提供了一个强大且灵活的工具，能够与多种求解器兼容，适用于广泛的优化问题。"}}
{"id": "2507.05792", "categories": ["math.NT", "math.KT"], "pdf": "https://arxiv.org/pdf/2507.05792", "abs": "https://arxiv.org/abs/2507.05792", "authors": ["Wenhuan Huang"], "title": "On Generators of Bloch groups of CM fields", "comment": null, "summary": "This article generalizes the result of Burns et al (2022), to find an\nalgorithm to find some elements generating a full-rank subgroup of the\ntorsion-free part of Bloch group of a certain CM number field, and compute the\nrank of it.", "AI": {"tldr": "本文推广了Burns等人(2022)的结果，提出了一个算法来寻找生成特定CM数域的Bloch群无挠部分满秩子群的元素，并计算其秩。", "motivation": "研究CM数域的Bloch群结构对于理解代数K理论和数论中的深刻问题具有重要意义。", "method": "通过推广Burns等人的方法，设计算法构造Bloch群无挠部分的生成元，并计算其秩。", "result": "成功找到了生成Bloch群无挠部分满秩子群的元素，并精确计算出了该子群的秩。", "conclusion": "该算法为研究CM数域的Bloch群结构提供了有效工具，推进了相关领域的研究进展。"}}
{"id": "2507.05297", "categories": ["cs.AI", "econ.TH"], "pdf": "https://arxiv.org/pdf/2507.05297", "abs": "https://arxiv.org/abs/2507.05297", "authors": ["Zijun Meng"], "title": "Fuzzy Classification Aggregation for a Continuum of Agents", "comment": null, "summary": "We prove that any optimal, independent, and zero unanimous fuzzy\nclassification aggregation function of a continuum of individual\nclassifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted\narithmetic mean.", "AI": {"tldr": "证明了对于将$m\\ge 3$个对象分为$2\\le p\\le m$类的连续个体分类，任何最优、独立且零一致的模糊分类聚合函数必须是加权算术平均。", "motivation": "研究模糊分类聚合函数的数学特性，特别是在多对象多类型分类场景下的最优形式。", "method": "通过数学证明，分析满足最优性、独立性和零一致性的模糊分类聚合函数的必要条件。", "result": "发现唯一满足条件的聚合函数形式是加权算术平均。", "conclusion": "该结果为模糊分类聚合提供了理论基础，并限定了其数学表达形式。"}}
{"id": "2507.06007", "categories": ["math.LO"], "pdf": "https://arxiv.org/pdf/2507.06007", "abs": "https://arxiv.org/abs/2507.06007", "authors": ["Matteo De Berardinis", "Silvio Ghilardi"], "title": "A Proof Theory for Profinite Modal Algebras", "comment": null, "summary": "In a previous paper, we showed that profinite $L$-algebras (where $L$ is a\nvariety of modal algebras generated by its finite members) are monadic over\n$\\mathbf{Set}$. This monadicity result suggests that profinite $L$-algebras\ncould be presented as Lindenbaum algebras for propositional theories in\ninfinitary versions of propositional modal calculi. In this paper we identify\nsuch calculi as modal enrichments of Maehara-Takeuti's infinitary extension of\nthe sequent calculus $\\mathbf{LK}$. We also investigate correspondences between\nsyntactic properties of the calculi and regularity/exactness properties of the\nopposite category of profinite $L$-algebras.", "AI": {"tldr": "本文探讨了profinite $L$-代数与无穷命题模态演算的Lindenbaum代数之间的关系，并研究了演算的句法性质与profinite $L$-代数对立范畴的规则性/精确性之间的对应关系。", "motivation": "基于先前关于profinite $L$-代数在$\\mathbf{Set}$上的单子性结果，作者试图将其表示为无穷命题模态演算的Lindenbaum代数。", "method": "作者将Maehara-Takeuti的无穷sequent演算$\\mathbf{LK}$扩展为模态演算，并分析其句法性质与profinite $L$-代数对立范畴性质的对应关系。", "result": "成功建立了profinite $L$-代数与特定无穷模态演算的联系，并揭示了演算句法性质与代数范畴性质的对应规律。", "conclusion": "该研究为profinite $L$-代数提供了新的逻辑表示方法，并深化了对模态演算与代数结构关系的理解。"}}
{"id": "2507.05689", "categories": ["math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.05689", "abs": "https://arxiv.org/abs/2507.05689", "authors": ["Ming Gao", "Yuhao Wang", "Bryon Aragam"], "title": "Optimal structure learning and conditional independence testing", "comment": null, "summary": "We establish a fundamental connection between optimal structure learning and\noptimal conditional independence testing by showing that the minimax optimal\nrate for structure learning problems is determined by the minimax rate for\nconditional independence testing in these problems. This is accomplished by\nestablishing a general reduction between these two problems in the case of\npoly-forests, and demonstrated by deriving optimal rates for several examples,\nincluding Bernoulli, Gaussian and nonparametric models. Furthermore, we show\nthat the optimal algorithm in these settings is a suitable modification of the\nPC algorithm. This theoretical finding provides a unified framework for\nanalyzing the statistical complexity of structure learning through the lens of\nminimax testing.", "AI": {"tldr": "本文揭示了最优结构学习与最优条件独立性测试之间的基本联系，证明结构学习问题的最优速率由条件独立性测试的最优速率决定，并通过多种模型验证了这一理论。", "motivation": "研究旨在建立结构学习与条件独立性测试之间的理论联系，为分析结构学习的统计复杂性提供统一框架。", "method": "通过在多树结构问题中建立两种问题的通用归约，并在伯努利、高斯及非参数模型等示例中推导最优速率。", "result": "结果表明，这些场景下的最优算法是PC算法的适当改进版本，且结构学习的最优速率确实由条件独立性测试的最优速率决定。", "conclusion": "研究为通过极小极大测试视角分析结构学习的统计复杂度提供了理论基础，并验证了改进版PC算法的普适最优性。"}}
{"id": "2507.05445", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05445", "abs": "https://arxiv.org/abs/2507.05445", "authors": ["Daniel Jones", "Giorgio Severi", "Martin Pouliot", "Gary Lopez", "Joris de Gruyter", "Santiago Zanella-Beguelin", "Justin Song", "Blake Bullwinkel", "Pamela Cortez", "Amanda Minnich"], "title": "A Systematization of Security Vulnerabilities in Computer Use Agents", "comment": null, "summary": "Computer Use Agents (CUAs), autonomous systems that interact with software\ninterfaces via browsers or virtual machines, are rapidly being deployed in\nconsumer and enterprise environments. These agents introduce novel attack\nsurfaces and trust boundaries that are not captured by traditional threat\nmodels. Despite their growing capabilities, the security boundaries of CUAs\nremain poorly understood. In this paper, we conduct a systematic threat\nanalysis and testing of real-world CUAs under adversarial conditions. We\nidentify seven classes of risks unique to the CUA paradigm, and analyze three\nconcrete exploit scenarios in depth: (1) clickjacking via visual overlays that\nmislead interface-level reasoning, (2) indirect prompt injection that enables\nRemote Code Execution (RCE) through chained tool use, and (3) CoT exposure\nattacks that manipulate implicit interface framing to hijack multi-step\nreasoning. These case studies reveal deeper architectural flaws across current\nCUA implementations. Namely, a lack of input provenance tracking, weak\ninterface-action binding, and insufficient control over agent memory and\ndelegation. We conclude by proposing a CUA-specific security evaluation\nframework and design principles for safe deployment in adversarial and\nhigh-stakes settings.", "AI": {"tldr": "本文系统分析了计算机使用代理(CUAs)的安全风险，揭示了七类独特威胁，并深入研究了三种具体攻击场景，提出了针对CUAs的安全评估框架和设计原则。", "motivation": "计算机使用代理(CUAs)的快速部署引入了传统威胁模型未涵盖的新型攻击面和信任边界，但其安全边界仍未被充分理解。", "method": "研究对现实世界CUAs进行了系统性威胁分析，在对抗条件下测试，重点分析了三种具体攻击场景：视觉覆盖点击劫持、间接提示注入实现远程代码执行，以及思维链暴露攻击。", "result": "研究发现当前CUA实现存在深层架构缺陷，包括缺乏输入来源追踪、界面-动作绑定薄弱、对代理记忆和委托控制不足等问题。", "conclusion": "研究提出了专门针对CUAs的安全评估框架，并为对抗性和高风险环境下的安全部署提供了设计原则。"}}
{"id": "2507.05697", "categories": ["math.CO", "math.AT", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.05697", "abs": "https://arxiv.org/abs/2507.05697", "authors": ["Asaf Cohen Antonir", "Yuval Peled", "Asaf Shapira", "Mykhaylo Tyomkyn", "Maksim Zhukovskii"], "title": "When does a tree activate the random graph?", "comment": "Comments are welcome!", "summary": "Let $F$ and $G$ be two graphs. A spanning subgraph $H$ of $G$ is called\nweakly $F$-saturated if one can add to $H$ the edges of $G \\setminus H$ in some\norder, so that whenever a new edge is added, a new copy of $F$ is formed.\nObtaining lower bounds for the minimum size $\\mathrm{wsat}(G,F)$ of such an $H$\nis a classical problem in extremal combinatorics. In particular, in the past 40\nyears, various algebraic tools have been developed to prove lower bounds on the\nweak saturation number $\\mathrm{wsat}(G,F)$. Our paper uncovers a new\nconnection of weak saturation to topology of clique complexes, that allows to\nprove tight lower bounds in some cases when the algebraic tools are not\nefficient.\n  It is easy to see that the smallest $K_3$-saturating graphs in $K_n$ are\ntrees, thus $\\mathrm{wsat}(K_n,K_3)=n-1$. In 2017, Kor\\'andi and Sudakov proved\nthat this is also the case in dense random graphs $G\\sim G_{n,p}$,\n$p=\\mathrm{const}\\in(0,1)$, and posed the question of determining the smallest\n$p$ for which $G_{n,p}$ contains a $K_3$-saturating tree with high probability.\nUsing the new topological connection, we show that this critical $p$ is of\norder $n^{-1/3-o(1)}$.\n  Inspired by Gromov's local-to-global principle for hyperbolic groups, we\nfurther develop our topological approach and determine the critical probability\nup to a constant factor, for trees with diameter at most $n^{c}$, for some\n$c>0$.\n  The new connection also enables us to improve the best known upper bound on\nthe threshold probability for simple connectivity of the 2-dimensional clique\ncomplex of $G_{n,p}$, due to Kahle.", "AI": {"tldr": "该论文揭示了弱饱和问题与团复形拓扑学的新联系，提出了在代数工具效率不足时证明紧下界的方法，并确定了随机图中$K_3$-饱和树存在的临界概率。", "motivation": "研究弱饱和数$\\mathrm{wsat}(G,F)$的下界是极值组合学中的经典问题，过去40年发展了多种代数工具，但在某些情况下效率不足，需要新的方法。", "method": "通过建立弱饱和与团复形拓扑学的新联系，结合Gromov双曲群的局部到全局原理，开发了拓扑学方法来确定临界概率。", "result": "证明了在随机图$G_{n,p}$中，$K_3$-饱和树存在的临界概率为$n^{-1/3-o(1)}$，并对直径不超过$n^{c}$的树确定了临界概率的常数因子。", "conclusion": "新建立的拓扑学连接不仅解决了Kor\\'andi和Sudakov提出的问题，还改进了Kahle关于二维团复形简单连通性阈值概率的上界。"}}
{"id": "2507.05562", "categories": ["math.OC", "cs.LG", "math.FA", "90C25, 65K05, 37N40, 46N10, 34A60, 62J07", "G.1.6; I.5.4"], "pdf": "https://arxiv.org/pdf/2507.05562", "abs": "https://arxiv.org/abs/2507.05562", "authors": ["Gabriel P. Langlois", "Jérôme Darbon"], "title": "Exact and efficient basis pursuit denoising via differential inclusions and a selection principle", "comment": "50 pages, 2 figures, submitted", "summary": "Basis pursuit denoising (BPDN) is a cornerstone of compressive sensing,\nstatistics and machine learning. While various algorithms for BPDN have been\nproposed, they invariably suffer from drawbacks and must either favor\nefficiency at the expense of accuracy or vice versa. As such, state-of-the-art\nalgorithms remain ineffective for high-dimensional applications that require\naccurate solutions within a reasonable amount of computational time. In this\nwork, we address this issue and propose an exact and efficient algorithm for\nBPDN using differential inclusions. Specifically, we prove that a selection\nprinciple from the theory of differential inclusions turns the dual problem of\nBPDN into calculating the trajectory of an \\emph{integrable} projected\ndynamical system, that is, whose trajectory and asymptotic limit can be\ncomputed exactly. Our analysis naturally yields an exact algorithm, numerically\nup to machine precision, that is amenable to computing regularization paths and\nvery fast. Numerical experiments confirm that our algorithm outperforms the\nstate-of-the-art algorithms in both accuracy and efficiency. Moreover, we show\nthat the global continuation of solutions (in terms of the hyperparameter and\ndata) of the projected dynamical system yields a rigorous homotopy algorithm\nfor BPDN, as well as a novel greedy algorithm for computing feasible solutions\nto basis pursuit in strongly polynomial time. Beyond this work, we expect that\nour results and analysis can be adapted to compute exact or approximate\nsolutions to a broader class of polyhedral-constrained optimization problems.", "AI": {"tldr": "本文提出了一种基于微分包含理论的精确高效BPDN算法，通过将双问题转化为可积投影动力系统轨迹计算，实现了高精度与高效率的平衡，并在数值实验中验证了其优越性。", "motivation": "现有BPDN算法在效率与精度间难以兼顾，无法满足高维应用需求。本文旨在解决这一矛盾，提出一种同时具备精确性与计算效率的新算法。", "method": "利用微分包含理论的选择原理，将BPDN双问题转化为可积投影动力系统轨迹计算问题。该系统轨迹和渐近极限可精确求解，从而衍生出可达机器精度的快速算法。", "result": "数值实验表明该算法在精度和效率上均优于现有技术。系统解的全局延拓还可用于构建BPDN同伦算法，以及强多项式时间内求解基追踪可行解的新型贪婪算法。", "conclusion": "该算法为BPDN提供了首个精确高效解决方案，其方法论可推广至更广泛的多面体约束优化问题。微分包含框架为相关领域研究开辟了新途径。"}}
{"id": "2507.05862", "categories": ["math.NT", "11A05, 11R04, 11Y40"], "pdf": "https://arxiv.org/pdf/2507.05862", "abs": "https://arxiv.org/abs/2507.05862", "authors": ["Gustav Kjærbye Bagger", "Andrew R. Booker", "Bryce Kerr", "Kevin McGown", "Valeriia Starichkova", "Tim Trudgian"], "title": "The determination of norm-Euclidean cyclic cubic fields", "comment": "24 pages", "summary": "It is known on the Generalised Riemann Hypothesis that there are precisely\n$13$ cyclic cubic fields that are norm-Euclidean. Unconditionally, there is a\ngap between analytic estimates which hold for all sufficiently large conductors\nand computational techniques. In this paper, we establish new results\nconcerning explicit bounds for cubic non-residues and refine previous\ncomputational techniques, enabling us to completely characterise all\nnorm-Euclidean cyclic cubic fields.", "AI": {"tldr": "本文在广义黎曼假设下确定了13个范数欧几里得循环三次域，并通过改进三次非剩余显式界和计算技术，无条件地完整刻画了所有范数欧几里得循环三次域。", "motivation": "现有分析估计与计算技术之间存在无条件差距，需改进三次非剩余显式界以填补这一空白。", "method": "通过建立新的三次非剩余显式界，并优化先前计算技术，实现对所有范数欧几里得循环三次域的完整分类。", "result": "无条件完整刻画了所有范数欧几里得循环三次域，验证了广义黎曼假设下的13个域结论。", "conclusion": "改进的显式界与计算技术解决了无条件分析中的关键问题，为循环三次域的范数欧几里得性质提供了完整描述。"}}
{"id": "2507.05488", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.05488", "abs": "https://arxiv.org/abs/2507.05488", "authors": ["Subhasis Dasgupta", "Jon Stephens", "Amarnath Gupta"], "title": "OLG++: A Semantic Extension of Obligation Logic Graph", "comment": null, "summary": "We present OLG++, a semantic extension of the Obligation Logic Graph (OLG)\nfor modeling regulatory and legal rules in municipal and interjurisdictional\ncontexts. OLG++ introduces richer node and edge types, including spatial,\ntemporal, party group, defeasibility, and logical grouping constructs, enabling\nnuanced representations of legal obligations, exceptions, and hierarchies. The\nmodel supports structured reasoning over rules with contextual conditions,\nprecedence, and complex triggers. We demonstrate its expressiveness through\nexamples from food business regulations, showing how OLG++ supports legal\nquestion answering using property graph queries. OLG++ also improves over\nLegalRuleML by providing native support for subClassOf, spatial constraints,\nand reified exception structures. Our examples show that OLG++ is more\nexpressive than prior graph-based models for legal knowledge representation.", "AI": {"tldr": "本文提出OLG++，一种对义务逻辑图（OLG）的语义扩展，用于建模市政和跨辖区背景下的法规和法律规则。OLG++引入了更丰富的节点和边类型，支持对法律义务、例外和层次结构的细致表示。", "motivation": "现有法律知识表示模型在表达空间、时间和逻辑分组等复杂法律概念时存在局限性，需要一种更丰富的表示方法。", "method": "OLG++扩展了OLG模型，新增了空间、时间、参与方组、可废止性和逻辑分组等节点和边类型，支持带上下文条件、优先级和复杂触发的结构化推理。", "result": "通过食品行业法规案例展示，OLG++能够支持基于属性图查询的法律问答，并在表达能力上优于LegalRuleML等现有图模型。", "conclusion": "OLG++在表达法律知识方面比现有基于图的模型更具表现力，特别是在处理子类关系、空间约束和具体化异常结构方面具有优势。"}}
{"id": "2507.05958", "categories": ["math.ST", "stat.TH", "62-08, 62G20, 62P30, 65C05"], "pdf": "https://arxiv.org/pdf/2507.05958", "abs": "https://arxiv.org/abs/2507.05958", "authors": ["Haythem Boucharif", "Jérôme Morio", "Paul Rochet"], "title": "Importance sampling for Sobol' indices estimation", "comment": null, "summary": "We propose a new importance sampling framework for the estimation and\nanalysis of Sobol' indices. We show that a Sobol' index defined under a\nreference input distribution can be consistently estimated from samples drawn\nfrom other sampling distributions by reweighting the estimator appropriately to\naccount for the distribution change. We derive the optimal sampling\ndistribution that minimizes the asymptotic variance and demonstrate its strong\nimpact on estimation accuracy. Beyond variance reduction, the framework\nsupports distributional sensitivity analysis via reverse importance sampling,\nenabling robust exploration of input distribution uncertainty with negligible\nadditional computational cost.", "AI": {"tldr": "提出了一种新的重要性采样框架，用于Sobol'指数的估计与分析，通过重新加权估计器实现不同采样分布下的稳健估计。", "motivation": "旨在解决在参考输入分布下定义的Sobol'指数在其他采样分布中的估计问题，并探索输入分布不确定性的稳健分析方法。", "method": "采用重要性采样框架，推导出最小化渐近方差的最优采样分布，并通过反向重要性采样支持分布敏感性分析。", "result": "最优采样分布显著提高了估计精度，且反向重要性采样能以极低计算成本实现输入分布不确定性的稳健探索。", "conclusion": "该框架不仅实现了方差缩减，还为分布敏感性分析提供了高效工具，具有重要的理论和应用价值。"}}
{"id": "2507.05512", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05512", "abs": "https://arxiv.org/abs/2507.05512", "authors": ["Gehao Zhang", "Eugene Bagdasarian", "Juan Zhai", "Shiqing Ma"], "title": "Disappearing Ink: Obfuscation Breaks N-gram Code Watermarks in Theory and Practice", "comment": null, "summary": "Distinguishing AI-generated code from human-written code is becoming crucial\nfor tasks such as authorship attribution, content tracking, and misuse\ndetection. Based on this, N-gram-based watermarking schemes have emerged as\nprominent, which inject secret watermarks to be detected during the generation.\n  However, their robustness in code content remains insufficiently evaluated.\nMost claims rely solely on defenses against simple code transformations or code\noptimizations as a simulation of attack, creating a questionable sense of\nrobustness. In contrast, more sophisticated schemes already exist in the\nsoftware engineering world, e.g., code obfuscation, which significantly alters\ncode while preserving functionality. Although obfuscation is commonly used to\nprotect intellectual property or evade software scanners, the robustness of\ncode watermarking techniques against such transformations remains largely\nunexplored.\n  In this work, we formally model the code obfuscation and prove the\nimpossibility of N-gram-based watermarking's robustness with only one intuitive\nand experimentally verified assumption, distribution consistency, satisfied.\nGiven the original false positive rate of the watermarking detection, the ratio\nthat the detector failed on the watermarked code after obfuscation will\nincrease to 1 - fpr.\n  The experiments have been performed on three SOTA watermarking schemes, two\nLLMs, two programming languages, four code benchmarks, and four obfuscators.\nAmong them, all watermarking detectors show coin-flipping detection abilities\non obfuscated codes (AUROC tightly surrounds 0.5). Among all models,\nwatermarking schemes, and datasets, both programming languages own obfuscators\nthat can achieve attack effects with no detection AUROC higher than 0.6 after\nthe attack. Based on the theoretical and practical observations, we also\nproposed a potential path of robust code watermarking.", "AI": {"tldr": "本文通过理论建模和实验验证，证明现有基于N-gram的代码水印方案在代码混淆攻击下完全失效，并提出可能的鲁棒水印路径。", "motivation": "区分AI生成代码与人工编写代码对版权保护至关重要，但现有水印方案对代码混淆等复杂攻击的鲁棒性缺乏评估。", "method": "建立代码混淆的形式化模型，基于分布一致性假设理论证明N-gram水印的脆弱性，并在3种水印方案、2个LLM、2种语言、4个基准数据集和4种混淆器上进行实验验证。", "result": "所有水印检测器对混淆后代码的检测能力接近随机猜测（AUROC≈0.5），且存在使检测AUROC≤0.6的混淆攻击方法。", "conclusion": "现有N-gram水印方案无法抵抗代码混淆攻击，需探索新型鲁棒水印技术。理论证明水印检测失败率将趋近1-fpr（原始误报率）。"}}
{"id": "2507.05775", "categories": ["math.CO", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.05775", "abs": "https://arxiv.org/abs/2507.05775", "authors": ["Anne-Laure Basdevant", "Lucas Gerin", "Maxime Marivain"], "title": "Longest increasing subsequences for distributions with atoms, and an inhomogeneous Hammersley process", "comment": null, "summary": "A famous result by Hammersley and Versik-Kerov states that the length $L_n$\nof the longest increasing subsequence among $n$ iid continuous random variables\ngrows like $2\\sqrt{n}$. We investigate here the asymptotic behavior of $L_n$\nfor distributions with atoms. For purely discrete random variables, we\ncharacterize the asymptotic order of $L_n$ through a variational problem and\nprovide explicit estimates for classical distributions. The proofs rely on a\ncoupling with an inhomogeneous version of the discrete-time continuous-space\nHammersley process. This reveals that, in contrast to the continuous case, the\ndiscrete setting exhibits a wide range of growth rates between $\\mathcal{O}(1)$\nand $o(\\sqrt{n})$, depending on the tail behavior of the distribution. We can\nthen easily deduce the asymptotics of $L_n$ for a completely arbitrary\ndistribution.", "AI": {"tldr": "研究离散随机变量最长递增子序列长度$L_n$的渐进行为，发现其增长率介于$\\mathcal{O}(1)$和$o(\\sqrt{n})$之间，具体取决于分布的尾部行为。", "motivation": "Hammersley和Versik-Kerov的著名结果表明，对于连续随机变量，$L_n$的增长率为$2\\sqrt{n}$。本文旨在探讨具有原子分布的随机变量$L_n$的渐进行为。", "method": "通过将离散随机变量与离散时间连续空间的Hammersley过程的不均匀版本耦合，利用变分问题刻画$L_n$的渐进阶，并提供经典分布的显式估计。", "result": "研究发现，离散情况下的$L_n$增长率范围广泛，从$\\mathcal{O}(1)$到$o(\\sqrt{n})$不等，具体取决于分布的尾部行为。此外，可以轻松推导出任意分布的$L_n$渐进性质。", "conclusion": "与连续情况不同，离散随机变量的最长递增子序列长度$L_n$表现出多样化的增长率，这为理解离散分布下的渐进行为提供了新的视角。"}}
{"id": "2507.05610", "categories": ["math.OC", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.05610", "abs": "https://arxiv.org/abs/2507.05610", "authors": ["Devansh Gupta", "Meisam Razaviyayn", "Vatsal Sharan"], "title": "On the Inherent Privacy of Zeroth Order Projected Gradient Descent", "comment": "Accepted at AISTATS'25", "summary": "Differentially private zeroth-order optimization methods have recently gained\npopularity in private fine tuning of machine learning models due to their\nreduced memory requirements. Current approaches for privatizing zeroth-order\nmethods rely on adding Gaussian noise to the estimated zeroth-order gradients.\nHowever, since the search direction in the zeroth-order methods is inherently\nrandom, researchers including Tang et al. (2024) and Zhang et al. (2024a) have\nraised an important question: is the inherent noise in zeroth-order estimators\nsufficient to ensure the overall differential privacy of the algorithm? This\nwork settles this question for a class of oracle-based optimization algorithms\nwhere the oracle returns zeroth-order gradient estimates. In particular, we\nshow that for a fixed initialization, there exist strongly convex objective\nfunctions such that running (Projected) Zeroth-Order Gradient Descent (ZO-GD)\nis not differentially private. Furthermore, we show that even with random\ninitialization and without revealing (initial and) intermediate iterates, the\nprivacy loss in ZO-GD can grow superlinearly with the number of iterations when\nminimizing convex objective functions.", "AI": {"tldr": "本文探讨了零阶优化方法在差分隐私保护中的有效性，发现即使不添加高斯噪声，某些情况下零阶梯度下降（ZO-GD）仍无法保证差分隐私。", "motivation": "零阶优化方法因内存需求低而广泛应用于机器学习模型的私有微调，但其固有的随机性是否足以确保差分隐私尚不明确。", "method": "研究针对一类基于零阶梯度估计的优化算法，分析了固定初始化和随机初始化下（投影）零阶梯度下降（ZO-GD）的隐私性。", "result": "结果表明，对于某些强凸目标函数，固定初始化的ZO-GD不具备差分隐私性；即使随机初始化且不公开中间迭代，凸函数优化中的隐私损失可能随迭代次数超线性增长。", "conclusion": "零阶优化方法的固有噪声不足以保证差分隐私，需额外机制确保隐私保护，尤其在迭代次数较多时。"}}
{"id": "2507.05905", "categories": ["math.NT", "math.DS"], "pdf": "https://arxiv.org/pdf/2507.05905", "abs": "https://arxiv.org/abs/2507.05905", "authors": ["Jiyoung Han", "Seul Bee Lee"], "title": "Moment formulas of Siegel transforms with congruence conditions in dimension 2", "comment": "20 Pages", "summary": "We compute the first and second moment formulas for Siegel transforms related\nto problems counting primitive lattice points in the real plane with congruence\nconditions. As applications, we derive an analog of Schmidt's random counting\ntheorem and the quantitative Khintchine theorem for irrational numbers,\napproximated by rational numbers $p/q$, where we place a congruence-conditional\nconstraint on the vector $(p,q)$.", "AI": {"tldr": "本文计算了与带同余条件的原始格点计数问题相关的Siegel变换的一阶和二阶矩公式，并应用这些结果推导了Schmidt随机计数定理的类似定理以及无理数的定量Khintchine定理。", "motivation": "研究带同余条件的原始格点计数问题，扩展Schmidt随机计数定理和Khintchine定理的应用范围。", "method": "通过计算Siegel变换的一阶和二阶矩公式，并结合同余条件约束向量$(p,q)$的方法。", "result": "推导了Schmidt随机计数定理的类似定理以及带同余条件的定量Khintchine定理，适用于无理数由有理数$p/q$逼近的情况。", "conclusion": "本文的结果为带同余条件的原始格点计数问题提供了新的理论工具，扩展了经典定理的应用范围。"}}
{"id": "2507.05495", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05495", "abs": "https://arxiv.org/abs/2507.05495", "authors": ["Prahaladh Chandrahasan", "Jiahe Jin", "Zhihan Zhang", "Tevin Wang", "Andy Tang", "Lucy Mo", "Morteza Ziyadi", "Leonardo F. R. Ribeiro", "Zimeng Qiu", "Markus Dreyer", "Akari Asai", "Chenyan Xiong"], "title": "Deep Research Comparator: A Platform For Fine-grained Human Annotations of Deep Research Agents", "comment": null, "summary": "Effectively evaluating deep research agents that autonomously search the web,\nanalyze information, and generate reports remains a major challenge,\nparticularly when it comes to assessing long reports and giving detailed\nfeedback on their intermediate steps. To address these gaps, we introduce Deep\nResearch Comparator, a platform that offers a holistic framework for deep\nresearch agent hosting, side-by-side comparison, fine-grained human feedback\ncollection, and ranking calculation. Given a user query, our platform displays\nthe final reports from two different agents along with their intermediate steps\nduring generation. Annotators can evaluate the overall quality of final reports\nbased on side-by-side comparison, and also provide detailed feedback separately\nby assessing intermediate steps or specific text spans within the final report.\nFurthermore, we develop Simple Deepresearch, an end-to-end agent scaffold. This\nscaffold serves as a baseline that facilitates the easy integration of various\nlarge language models to transform them into deep research agents for\nevaluation. To demonstrate the platform's utility for deep research agent\ndevelopment, we have collected real user preference data from 17 annotators on\nthree deep research agents. A demo video of our platform can be found at\nhttps://www.youtube.com/watch?v=g4d2dnbdseg.", "AI": {"tldr": "本文介绍了Deep Research Comparator平台，用于评估自主网络搜索、分析信息并生成报告的深度研究代理，支持多代理报告对比、细粒度反馈收集及排名计算。同时提出了Simple Deepresearch代理框架作为基线。", "motivation": "当前深度研究代理的评估存在挑战，特别是在长报告评估和中间步骤反馈方面。为解决这些问题，开发了一个综合评估平台。", "method": "平台展示两个不同代理的最终报告及生成中间步骤，支持标注者通过对比评估整体质量，并提供对中间步骤或文本片段的详细反馈。开发了Simple Deepresearch框架作为基线。", "result": "收集了17位标注者对三个深度研究代理的真实偏好数据，验证了平台在代理开发中的实用性。平台演示视频已发布。", "conclusion": "Deep Research Comparator平台为深度研究代理的开发与评估提供了全面框架，Simple Deepresearch框架简化了大型语言模型向研究代理的转化。"}}
{"id": "2507.06098", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.06098", "abs": "https://arxiv.org/abs/2507.06098", "authors": ["Fabienne Comte", "Nicolas Marie"], "title": "Nonparametric Estimation in SDE Models Involving an Explanatory Process", "comment": "39 pages, 3 figures", "summary": "This paper deals with the process $X = (X_t)_{t\\in [0,T]}$ defined by the\nstochastic differential equation (SDE) $dX_t = (a(X_t) + b(Y_t))dt\n+\\sigma(X_t)dW_1(t)$, where $W_1$ is a Brownian motion and $Y$ is an exogenous\nprocess. The first task - of probabilistic nature - is to properly define the\nmodel, to prove the existence and uniqueness of the solution of such an\nequation, and then to establish the existence and a suitable control of a\ndensity with respect to the Lebesgue measure of the distribution of $(X_t,Y_t)$\n($t > 0$). In the second part of the paper, a risk bound and a rate of\nconvergence in specific Sobolev spaces are established for a copies-based\nprojection least squares estimator of the $\\mathbb R^2$-valued function\n$(a,b)$. Moreover, a model selection procedure making the adequate\nbias-variance compromise both in theory and practice is investigated.", "AI": {"tldr": "本文研究了一个由随机微分方程（SDE）定义的随机过程$X_t$，其中包含外生过程$Y_t$的影响。论文首先从概率论角度证明了模型解的存在唯一性，并建立了$(X_t,Y_t)$联合分布的密度控制。第二部分提出了基于投影最小二乘估计器的风险界和收敛速率，并研究了模型选择方法。", "motivation": "研究由外生过程驱动的随机微分方程模型，旨在解决其解的存在唯一性问题，并为后续的参数估计提供理论支持。", "method": "首先通过概率论方法建立SDE解的存在唯一性及联合分布密度控制；然后采用基于副本的投影最小二乘估计器对函数$(a,b)$进行估计，并在Sobolev空间中分析其收敛性。", "result": "证明了SDE解的存在唯一性，建立了联合分布密度的控制条件；获得了参数估计在Sobolev空间中的风险界和收敛速率，并实现了理论实践中的偏差-方差权衡。", "conclusion": "该研究为外生过程驱动的随机微分方程提供了完整的理论框架和有效的参数估计方法，其模型选择机制在实践中具有良好的适应性。"}}
{"id": "2507.05524", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05524", "abs": "https://arxiv.org/abs/2507.05524", "authors": ["Sara Chennoufi", "Yufei Han", "Gregory Blanc", "Emiliano De Cristofaro", "Christophe Kiennert"], "title": "PROTEAN: Federated Intrusion Detection in Non-IID Environments through Prototype-Based Knowledge Sharing", "comment": null, "summary": "In distributed networks, participants often face diverse and fast-evolving\ncyberattacks. This makes techniques based on Federated Learning (FL) a\npromising mitigation strategy. By only exchanging model updates, FL\nparticipants can collaboratively build detection models without revealing\nsensitive information, e.g., network structures or security postures. However,\nthe effectiveness of FL solutions is often hindered by significant data\nheterogeneity, as attack patterns often differ drastically across organizations\ndue to varying security policies. To address these challenges, we introduce\nPROTEAN, a Prototype Learning-based framework geared to facilitate\ncollaborative and privacy-preserving intrusion detection. PROTEAN enables\naccurate detection in environments with highly non-IID attack distributions and\npromotes direct knowledge sharing by exchanging class prototypes of different\nattack types among participants. This allows organizations to better understand\nattack techniques not present in their data collections. We instantiate PROTEAN\non two cyber intrusion datasets collected from IIoT and 5G-connected\nparticipants and evaluate its performance in terms of utility and privacy,\ndemonstrating its effectiveness in addressing data heterogeneity while\nimproving cyber attack understanding in federated intrusion detection systems\n(IDSs).", "AI": {"tldr": "本文提出PROTEAN框架，通过原型学习实现隐私保护的联邦学习入侵检测，有效应对非独立同分布数据挑战。", "motivation": "分布式网络中，联邦学习(FL)因能保护隐私而成为抵御快速演变的网络攻击的有力工具，但数据异构性严重影响了其效果。", "method": "PROTEAN采用原型学习方法，通过交换不同攻击类型的类别原型促进知识共享，提升非独立同分布环境下的检测精度。", "result": "在IIoT和5G网络数据集上的实验表明，PROTEAN在保持隐私的同时显著提升了入侵检测系统的性能。", "conclusion": "PROTEAN框架成功解决了联邦入侵检测中的数据异构性问题，同时增强了参与者对未知攻击类型的认知能力。"}}
{"id": "2507.05821", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.05821", "abs": "https://arxiv.org/abs/2507.05821", "authors": ["Ted Dobson", "Ademir Hujdurović", "Wilfried Imrich", "Ronald Ortner"], "title": "On cubic vertex-transitive graphs of given girth", "comment": null, "summary": "A set of vertices of a graph is distinguishing if the only automorphism that\npreserves it is the identity. The minimal size of such sets, if they exist, is\nthe distinguishing cost. The distinguishing costs of vertex transitive cubic\ngraphs are well known if they are 1-arc-transitive, or if they have two edge\norbits and either have girth 3 or vertex-stabilizers of order 1 or 2.\n  There are many results about vertex-transitive cubic graphs of girth 4 with\ntwo edge orbits, but for larger girth almost nothing is known about %the\nexistence or the distinguishing costs of such graphs. We prove that cubic\nvertex-transitive graphs of girth 5 with two edge orbits have distinguishing\ncost 2, and prove the non-existence of infinite 3-arc-transitive cubic graphs\nof girth 6.", "AI": {"tldr": "本文研究了具有两个边轨道的五次围长立方顶点传递图的区分成本，证明其区分成本为2，并排除了无限三弧传递六次围长立方图的存在。", "motivation": "目前对于具有两个边轨道且围长大于4的立方顶点传递图，其区分成本及存在性几乎未知。本文旨在填补这一研究空白。", "method": "通过图论与群论方法，分析立方顶点传递图的自同构群性质，并构造特定区分集。", "result": "证明了五次围长的立方顶点传递图（具有两个边轨道）的区分成本为2，并证实不存在无限三弧传递的六次围长立方图。", "conclusion": "研究扩展了对高围长立方顶点传递图区分成本的理解，为后续研究提供了理论基础。"}}
{"id": "2507.05623", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.05623", "abs": "https://arxiv.org/abs/2507.05623", "authors": ["Xi Chen", "Jinyan Fan"], "title": "A derivative-free regularization algorithm for equality constrained nonlinear least squares problems", "comment": "22 pages", "summary": "In this paper, we study the equality constrained nonlinear least squares\nproblem, where the Jacobian matrices of the objective function and constraints\nare unavailable or expensive to compute. We approximate the Jacobian matrices\nvia orthogonal spherical smoothing and propose a derivative-free regularization\nalgorithm for solving the problem. At each iteration, a regularized augmented\nLagrangian subproblem is solved to obtain a Newton-like step. If a sufficient\ndecrease in the merit function of the approximate KKT system is achieved, the\nstep is accepted, otherwise a derivative-free LM algorithm is applied to get\nanother step to satisfy the sufficient decrease condition. It is shown that the\nalgorithm either finds an approximate KKT point with arbitrary high probability\nor converges to a stationary point of constraints violation almost surely.", "AI": {"tldr": "本文提出一种无导数正则化算法，通过正交球面平滑逼近雅可比矩阵，解决雅可比矩阵不可用或计算成本高的等式约束非线性最小二乘问题。", "motivation": "针对目标函数和约束的雅可比矩阵难以获取或计算昂贵的问题，研究无需导数的求解方法。", "method": "采用正交球面平滑逼近雅可比矩阵，结合正则化增广拉格朗日子问题求解牛顿类步长，并通过无导数LM算法确保充分下降条件。", "result": "算法能以任意高概率找到近似KKT点，或几乎必然收敛至约束违反的稳定点。", "conclusion": "该方法为无导数环境下求解等式约束非线性最小二乘问题提供了有效方案，具有理论收敛保证。"}}
{"id": "2507.06130", "categories": ["math.NT", "Primary 11R27, Secondary 11R33"], "pdf": "https://arxiv.org/pdf/2507.06130", "abs": "https://arxiv.org/abs/2507.06130", "authors": ["Sergio Ricardo Zapata Ceballos", "Sara Chari", "Erik Holmes", "Fatemeh Jalalvand", "Rahinatou Yuh Njah Nchiwo", "Kelly O'Connor", "Fabian Ramirez", "Sameera Vemulapalli"], "title": "Unit lattices of $D_4$-quartic number fields with signature $(2,1)$", "comment": "Comments welcome!", "summary": "There has been a recent surge of interest on distributions of shapes of unit\nlattices in number fields, due to both their applications to number theory and\nthe lack of known results.\n  In this work we focus on $D_4$-quartic fields with signature $(2,1)$; such\nfields have a rank $2$ unit group. Viewing the unit lattice as a point of\n$GL_2(\\mathbb{Z})\\backslash \\mathfrak{h}$, we prove that every lattice which\narises this way must correspond to a transcendental point on the boundary of a\ncertain fundamental domain of $GL_2(\\mathbb{Z})\\backslash \\mathfrak{h}$.\nMoreover, we produce three explicit (algebraic) points of\n$GL_2(\\mathbb{Z})\\backslash \\mathfrak{h}$ which are limit points of the set of\n(points associated to) unit lattices of $D_4$-quartic fields with signature\n$(2,1)$.", "AI": {"tldr": "本文研究了$D_4$-四次域的单位格分布，证明其对应$GL_2(\\mathbb{Z})\\setminus \\mathfrak{h}$边界上的超越点，并找到三个显式代数极限点。", "motivation": "由于数论应用及现有结果匮乏，单位格分布在签名$(2,1)$的$D_4$-四次域中引起关注。", "method": "将单位格视为$GL_2(\\mathbb{Z})\\setminus \\mathfrak{h}$上的点，分析其在基本域边界的性质。", "result": "所有此类单位格对应基本域边界的超越点，并构造了三个代数极限点。", "conclusion": "$D_4$-四次域的单位格分布与$GL_2(\\mathbb{Z})\\setminus \\mathfrak{h}$的边界结构存在深刻联系，揭示了新的代数极限点。"}}
{"id": "2507.05515", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.05515", "abs": "https://arxiv.org/abs/2507.05515", "authors": ["Haochen Huang", "Jiahuan Pei", "Mohammad Aliannejadi", "Xin Sun", "Moonisa Ahsan", "Pablo Cesar", "Chuang Yu", "Zhaochun Ren", "Junxiao Wang"], "title": "Fine-Grained Vision-Language Modeling for Multimodal Training Assistants in Augmented Reality", "comment": "20 pages", "summary": "Vision-language models (VLMs) are essential for enabling AI-powered smart\nassistants to interpret and reason in multimodal environments. However, their\napplication in augmented reality (AR) training remains largely unexplored. In\nthis work, we introduce a comprehensive dataset tailored for AR training,\nfeaturing systematized vision-language tasks, and evaluate nine\nstate-of-the-art VLMs on it. Our results reveal that even advanced models,\nincluding GPT-4o, struggle with fine-grained assembly tasks, achieving a\nmaximum F1 score of just 40.54% on state detection. These findings highlight\nthe demand for enhanced datasets, benchmarks, and further research to improve\nfine-grained vision-language alignment. Beyond technical contributions, our\nwork has broader social implications, particularly in empowering blind and\nvisually impaired users with equitable access to AI-driven learning\nopportunities. We provide all related resources, including the dataset, source\ncode, and evaluation results, to support the research community.", "AI": {"tldr": "本文介绍了专为AR训练定制的视觉-语言数据集，评估了9种先进VLM模型，发现其在细粒度装配任务上表现不佳（最高F1分数仅40.54%），呼吁加强视觉-语言对齐研究，并具有赋能视障群体的社会意义。", "motivation": "尽管视觉-语言模型（VLM）在多模态环境中具有重要作用，但其在增强现实（AR）训练中的应用尚未充分探索，需要建立专用数据集和基准来推动该领域发展。", "method": "研究构建了系统化的AR训练视觉-语言任务数据集，并对包括GPT-4o在内的9种前沿VLM模型进行了全面评估。", "result": "实验表明现有模型在细粒度状态检测等任务上表现欠佳，最佳F1分数仅为40.54%，凸显当前技术的局限性。", "conclusion": "该研究不仅提出了促进VLM发展的技术资源（数据集/代码/结果），更强调了其在为视障群体提供平等AI学习机会方面的社会价值。"}}
{"id": "2507.06166", "categories": ["math.ST", "math.PR", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.06166", "abs": "https://arxiv.org/abs/2507.06166", "authors": ["Omar Al-Ghattas", "Jiaheng Chen", "Daniel Sanz-Alonso"], "title": "On the Estimation of Gaussian Moment Tensors", "comment": "13 pages", "summary": "This paper studies two estimators for Gaussian moment tensors: the standard\nsample moment estimator and a plug-in estimator based on Isserlis's theorem. We\nestablish dimension-free, non-asymptotic error bounds that demonstrate and\nquantify the advantage of Isserlis's estimator for tensors of even order $p>2$.\nOur bounds hold in operator and entrywise maximum norms, and apply to symmetric\nand asymmetric tensors.", "AI": {"tldr": "本文比较了高斯矩张量的两种估计器：标准样本矩估计器和基于Isserlis定理的插件估计器，证明了后者在偶数阶张量$p>2$时的优势。", "motivation": "研究高斯矩张量的估计方法，旨在量化Isserlis估计器在偶数阶张量中的性能优势。", "method": "对比分析标准样本矩估计器与基于Isserlis定理的插件估计器，建立维度无关的非渐近误差界。", "result": "在算子范数和逐项最大范数下，Isserlis估计器对偶数阶张量$p>2$表现出显著优势，且适用于对称与非对称张量。", "conclusion": "Isserlis估计器在高斯矩张量估计中具有理论优势，尤其适用于高阶偶数阶张量场景。"}}
{"id": "2507.05558", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05558", "abs": "https://arxiv.org/abs/2507.05558", "authors": ["Arthur Gervais", "Liyi Zhou"], "title": "AI Agent Smart Contract Exploit Generation", "comment": null, "summary": "We present A1, an agentic execution driven system that transforms any LLM\ninto an end-to-end exploit generator. A1 has no hand-crafted heuristics and\nprovides the agent with six domain-specific tools that enable autonomous\nvulnerability discovery. The agent can flexibly leverage these tools to\nunderstand smart contract behavior, generate exploit strategies, test them on\nblockchain states, and refine approaches based on execution feedback. All\noutputs are concretely validated to eliminate false positives.\n  The evaluation across 36 real-world vulnerable contracts on Ethereum and\nBinance Smart Chain demonstrates a 62.96% (17 out of 27) success rate on the\nVERITE benchmark. Beyond the VERITE dataset, A1 identified 9 additional\nvulnerable contracts, with 5 cases occurring after the strongest model's\ntraining cutoff date. Across all 26 successful cases, A1 extracts up to 8.59\nmillion USD per case and 9.33 million USD total. Through 432 experiments across\nsix LLMs, we analyze iteration-wise performance showing diminishing returns\nwith average marginal gains of +9.7%, +3.7%, +5.1%, and +2.8% for iterations\n2-5 respectively, with per-experiment costs ranging $0.01-$3.59. A Monte Carlo\nanalysis of 19 historical attacks shows success probabilities of 85.9%-88.8%\nwithout detection delays.\n  We investigate whether an attacker or a defender benefits most from deploying\nA1 as a continuous on-chain scanning system. Our model shows that OpenAI's\no3-pro maintains profitability up to a 30.0 days scanning delay at 0.100%\nvulnerability incidence rates, while faster models require >=1.000% rates to\nbreak-even. The findings exposes a troubling asymmetry: at 0.1% vulnerability\nrates, attackers achieve an on-chain scanning profitability at a $6000 exploit\nvalue, while defenders require $60000, raising fundamental questions about\nwhether AI agents inevitably favor exploitation over defense.", "AI": {"tldr": "A1是一个将任意大语言模型转化为端到端漏洞利用生成器的代理执行驱动系统，无需人工启发式规则，通过六种领域专用工具实现自主漏洞发现，在真实场景中表现出色但揭示攻击者与防御者间的盈利不对称性。", "motivation": "研究旨在开发能自动发现区块链漏洞的AI代理系统，解决传统方法依赖手工规则的问题，并验证其在真实攻击场景中的有效性及经济可行性。", "method": "系统为代理提供六种智能合约分析工具，通过自主策略生成、链上状态测试和反馈迭代来发现漏洞，所有输出均经过验证以确保零误报。采用蒙特卡洛分析评估19次历史攻击的成功概率。", "result": "在以太坊和币安智能链的36个真实漏洞合约中，VERITE基准成功率达62.96%（17/27），额外发现9个漏洞合约。26个成功案例总提取金额达933万美元，单案例最高859万美元。迭代分析显示边际收益递减（第2-5轮增益分别为+9.7%、+3.7%、+5.1%、+2.8%）。", "conclusion": "研究暴露了AI代理在攻防应用中的根本性不对称：攻击者在漏洞率0.1%、漏洞价值6000美元时即可盈利，而防御者需要60000美元，表明AI技术可能天然倾向于被用于攻击而非防御。"}}
{"id": "2507.05824", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.05824", "abs": "https://arxiv.org/abs/2507.05824", "authors": ["Michal Parnas", "Adi Shraibman"], "title": "A Study of the Binary and Boolean Rank of Matrices with Small Constant Real Rank", "comment": null, "summary": "We initiate the study of the binary and Boolean rank of $0,1$ matrices that\nhave a small rank over the reals. The relationship between these three rank\nfunctions is an important open question, and here we prove that when the real\nrank $d$ is a small constant, the gap between the real and the binary and\nBoolean rank is a small constant. We give tight upper and lower bounds on the\nBoolean and binary rank of matrices with real rank $1 \\leq d \\leq 4$, as well\nas determine the size of the maximal isolation set in each case. Furthermore,\nwe prove that for $d = 3,4$, the circulant matrix defined by a row with $d-1$\nconsecutive ones followed by $d-1$ zeros, is the only matrix of size\n$(2d-2)\\times (2d-2)$ with real rank $d$ and Boolean and binary rank and\nmaximal isolation set of size $2d-2$, and this matrix achieves the maximal gap\npossible between the real and the binary and Boolean rank for these values of\n$d$.\n  Our results can also be interpreted in other equivalent terms, such as\nfinding the minimal number of bicliques needed to partition or cover the edges\nof a bipartite graph whose reduced adjacency matrix has real rank $1 \\leq d\n\\leq 4$. We use a combination of combinatorial and algebraic techniques\ncombined with the assistance of a computer program.", "AI": {"tldr": "本文研究了实数秩较小的$0,1$矩阵的二元秩和布尔秩，证明了当实数秩$d$为小常数时，实数秩与二元秩、布尔秩之间的差距也是小常数。", "motivation": "探讨实数秩、二元秩和布尔秩之间的关系是一个重要的开放性问题，特别是在实数秩较小的矩阵中。", "method": "结合组合数学和代数技术，并借助计算机程序，对实数秩$1 \\leq d \\leq 4$的矩阵进行了分析。", "result": "给出了实数秩$1 \\leq d \\leq 4$的矩阵的二元秩和布尔秩的紧致上下界，并确定了最大隔离集的大小。对于$d=3,4$，证明了循环矩阵是唯一满足特定条件的矩阵。", "conclusion": "研究结果可以等价地解释为在二分图中寻找覆盖边所需的最小双团数，为相关领域提供了新的理论支持。"}}
{"id": "2507.05669", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.05669", "abs": "https://arxiv.org/abs/2507.05669", "authors": ["A. A. Vyguzov", "F. S. Stonyakin"], "title": "A Fully Adaptive Frank-Wolfe Algorithm for Relatively Smooth Problems and Its Application to Centralized Distributed Optimization", "comment": null, "summary": "We study the Frank-Wolfe algorithm for constrained optimization problems with\nrelatively smooth and relatively strongly convex objectives. Building upon our\nprevious work, we propose a fully adaptive variant of the Frank-Wolfe method\nthat dynamically adjusts the step size based on both the relative smoothness\nconstant and the Triangle Scaling Exponent (TSE) of the Bregman divergence. Our\nmethod does not require prior knowledge of the function parameters and\nguarantees convergence using only local information. We establish a linear\nconvergence rate under relative strong convexity and provide a detailed\ntheoretical analysis of the proposed adaptive step-size rule.\n  Furthermore, we demonstrate how relative smoothness and strong convexity\nnaturally arise in the setting of centralized distributed optimization. Under a\nvariance-type assumption on the gradients, we show that the global objective\nbecomes relatively strongly convex with respect to the Bregman divergence\ngenerated by a local function. This structure allows us to apply our adaptive\nFrank-Wolfe algorithm, leading to provable acceleration due to an improved\nrelative condition number. We support our theoretical findings with numerical\nexperiments, showing that the proposed method outperforms both non-adaptive and\npartially adaptive variants, especially in distributed settings.", "AI": {"tldr": "本文提出了一种完全自适应的Frank-Wolfe算法，用于解决具有相对光滑和相对强凸目标的约束优化问题，无需预先知道函数参数，并在分布式优化中展示了其优势。", "motivation": "研究Frank-Wolfe算法在相对光滑和相对强凸目标下的优化问题，旨在开发一种完全自适应的步长调整方法，以提升收敛性能并适应分布式优化场景。", "method": "提出了一种动态调整步长的Frank-Wolfe算法，基于相对光滑常数和Bregman散度的三角缩放指数（TSE），仅使用局部信息保证收敛，并适用于分布式优化。", "result": "在相对强凸性下建立了线性收敛率，数值实验表明该方法在分布式设置中优于非自适应和部分自适应变体。", "conclusion": "自适应Frank-Wolfe算法在相对光滑和强凸条件下表现优异，特别是在分布式优化中，由于改进的相对条件数而实现了可证明的加速。"}}
{"id": "2507.06158", "categories": ["math.NT", "cs.FL", "11A63, 68Q45"], "pdf": "https://arxiv.org/pdf/2507.06158", "abs": "https://arxiv.org/abs/2507.06158", "authors": ["Anjelo Gabriel R. Cruz", "Manuel Joseph C. Loquias", "Jörg M. Thuswaldner"], "title": "Addition Automata and Attractors of Digit Systems Corresponding to Expanding Rational Matrices", "comment": "20 pages, 11 figures", "summary": "Let $A$ be an expanding $2 \\times 2$ matrix with rational entries and\n$\\mathbb{Z}^2[A]$ be the smallest $A$-invariant $\\mathbb{Z}$-module containing\n$\\mathbb{Z}^2$. Let $\\mathcal{D}$ be a finite subset of $\\mathbb{Z}^2[A]$ which\nis a complete residue system of $\\mathbb{Z}^2[A]/A\\mathbb{Z}^2[A]$. The pair\n$(A,\\mathcal{D})$ is called a {\\em digit system} with {\\em base} $A$ and {\\em\ndigit set} $\\mathcal{D}$. It is well known that every vector $x \\in\n\\mathbb{Z}^2[A]$ can be written uniquely in the form \\[ x = d_0 + Ad_1 + \\cdots\n+ A^kd_k + A^{k+1}p, \\] with $k\\in \\mathbb{N}$ minimal, $d_0,\\dots,d_k \\in\n\\mathcal{D}$, and $p$ taken from a finite set of {\\em periodic elements}, the\nso-called {\\em attractor} of $(A,\\mathcal{D})$. If $p$ can always be chosen to\nbe $0$ we say that $(A,\\mathcal{D})$ has the {\\em finiteness property}.\n  In the present paper we introduce finite-state transducer automata which\nrealize the addition of the vectors $\\pm(1,0)^\\top$ and $\\pm(0,1)^\\top$ to a\ngiven vector $x\\in \\mathbb{Z}^2[A]$ in a number system $(A,\\mathcal{D})$ with\ncollinear digit set. These automata are applied to characterize all pairs\n$(A,\\mathcal{D})$ that have the finiteness property and, more generally, to\ncharacterize the attractors of these digit systems.", "AI": {"tldr": "本文研究了具有共线数字集的数字系统$(A,\\mathcal{D})$，通过有限状态转换器自动机实现向量加法，并表征了具有有限性性质的系统及其吸引子。", "motivation": "研究数字系统$(A,\\mathcal{D})$的有限性性质和吸引子，特别是当数字集$\\mathcal{D}$共线时，如何通过自动机实现向量加法。", "method": "引入有限状态转换器自动机，用于在数字系统$(A,\\mathcal{D})$中实现向量$\\pm(1,0)^\\top$和$\\pm(0,1)^\\top$的加法。", "result": "表征了所有具有有限性性质的数字系统$(A,\\mathcal{D})$，并更广泛地描述了这些数字系统的吸引子。", "conclusion": "通过自动机方法，成功表征了共线数字集数字系统的有限性性质和吸引子，为相关研究提供了新工具。"}}
{"id": "2507.05519", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.05519", "abs": "https://arxiv.org/abs/2507.05519", "authors": ["Gopal Gupta", "Abhiramon Rajasekharan", "Alexis R. Tudor", "Elmer Salazar", "Joaquín Arias"], "title": "Modeling (Deontic) Modal Operators With the s(CASP) Goal-directed Predicated Answer Set Programming System", "comment": null, "summary": "We consider the problem of implementing deontic modal logic. We show how\n(deontic) modal operators can be expressed elegantly using default negation\n(negation-as-failure) and strong negation present in answer set programming\n(ASP). We propose using global constraints of ASP to represent obligations and\nimpermissibilities of deontic modal logic. We show that our proposed\nrepresentation results in the various paradoxes of deontic modal logic being\nelegantly resolved.", "AI": {"tldr": "本文提出使用答案集编程(ASP)中的默认否定和强否定来优雅地表达道义模态逻辑运算符，并通过ASP的全局约束表示义务和禁止，有效解决了道义模态逻辑中的各种悖论。", "motivation": "研究如何实现道义模态逻辑，解决其运算符表达复杂和悖论问题。", "method": "利用答案集编程(ASP)中的默认否定(否定即失败)和强否定来表达道义模态运算符，并使用ASP的全局约束来表示义务和禁止。", "result": "所提出的表示方法能够优雅地解决道义模态逻辑中的各种悖论。", "conclusion": "通过ASP的否定机制和全局约束，可以有效地实现和解决道义模态逻辑的表达和悖论问题。"}}
{"id": "2507.06226", "categories": ["math.ST", "math.PR", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.06226", "abs": "https://arxiv.org/abs/2507.06226", "authors": ["Moïse Blanchard", "Adam Quinn Jaffe", "Nikita Zhivotovskiy"], "title": "Consistency and Inconsistency in $K$-Means Clustering", "comment": "36 pages, 1 figure, 1 table. Comments welcome", "summary": "A celebrated result of Pollard proves asymptotic consistency for $k$-means\nclustering when the population distribution has finite variance. In this work,\nwe point out that the population-level $k$-means clustering problem is, in\nfact, well-posed under the weaker assumption of a finite expectation, and we\ninvestigate whether some form of asymptotic consistency holds in this setting.\nAs we illustrate in a variety of negative results, the complete story is quite\nsubtle; for example, the empirical $k$-means cluster centers may fail to\nconverge even if there exists a unique set of population $k$-means cluster\ncenters. A detailed analysis of our negative results reveals that inconsistency\narises because of an extreme form of cluster imbalance, whereby the presence of\noutlying samples leads to some empirical $k$-means clusters possessing very few\npoints. We then give a collection of positive results which show that some\nforms of asymptotic consistency, under only the assumption of finite\nexpectation, may be recovered by imposing some a priori degree of balance among\nthe empirical $k$-means clusters.", "AI": {"tldr": "本文探讨了在仅有限期望条件下$k$-均值聚类问题的适定性，揭示了极端簇不平衡导致的不一致性，并提出通过平衡约束恢复渐近一致性的方法。", "motivation": "Pollard的经典结果证明当总体分布具有有限方差时，$k$-均值聚类具有渐近一致性。本研究旨在探究在更弱的有限期望条件下，$k$-均值聚类是否仍保持某种形式的渐近一致性。", "method": "通过理论分析和反例构造，研究了有限期望条件下$k$-均值聚类中心收敛性问题，特别关注簇不平衡对一致性的影响。", "result": "发现当存在极端簇不平衡（如离群样本导致某些簇点极少）时，经验$k$-均值聚类中心可能不收敛；但通过施加先验的簇平衡约束，可在有限期望条件下恢复部分渐近一致性。", "conclusion": "研究表明有限期望条件下$k$-均值聚类的渐近一致性具有微妙性，但通过合理平衡约束可实现理论保证，扩展了经典结果的适用条件。"}}
{"id": "2507.05576", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2507.05576", "abs": "https://arxiv.org/abs/2507.05576", "authors": ["Mehdi Elahi", "Mohamed R. Elshamy", "Abdel-Hameed Badawy", "Ahmad Patooghy"], "title": "iThermTroj: Exploiting Intermittent Thermal Trojans in Multi-Processor System-on-Chips", "comment": null, "summary": "Thermal Trojan attacks present a pressing concern for the security and\nreliability of System-on-Chips (SoCs), especially in mobile applications. The\nsituation becomes more complicated when such attacks are more evasive and\noperate sporadically to stay hidden from detection mechanisms. In this paper,\nwe introduce Intermittent Thermal Trojans (iThermTroj) that exploit the chips'\nthermal information in a random time-triggered manner. According to our\nexperiments, iThermTroj attack can easily bypass available threshold-based\nthermal Trojan detection solutions. We investigate SoC vulnerabilities to\nvariations of iThermTroj through an in-depth analysis of Trojan activation and\nduration scenarios. We also propose a set of tiny Machine Learning classifiers\nfor run-time anomaly detection to protect SoCs against such intermittent\nthermal Trojan attacks. Compared to existing methods, our approach improves the\nattack detection rate by 29.4\\%, 17.2\\%, and 14.3\\% in scenarios where\niThermTroj manipulates up to 80\\%, 60\\%, and 40\\% of SoC's thermal data,\nrespectively. Additionally, our method increases the full protection resolution\nto 0.8 degrees Celsius, meaning that any temperature manipulations exceeding\n$\\pm 0.8$ degrees will be detected with 100\\% accuracy.", "AI": {"tldr": "本文提出了一种新型间歇性热木马攻击(iThermTroj)，通过随机触发方式利用芯片温度信息，能绕过现有阈值检测。作者开发了微型机器学习分类器进行运行时异常检测，显著提升了攻击检测率与保护分辨率。", "motivation": "移动应用中的系统级芯片(SoC)面临间歇性热木马攻击的严重威胁，现有阈值检测方案难以应对这种隐蔽性强、随机触发的攻击模式，亟需新的防御手段。", "method": "通过深入分析木马激活与持续时间场景，研究SoC脆弱性；提出基于微型机器学习分类器的运行时异常检测方案，对抗间歇性热木马攻击。", "result": "在木马篡改80%、60%、40%热数据场景下，检测率分别提升29.4%、17.2%、14.3%；保护分辨率达0.8摄氏度，对超过$\\pm 0.8$度的温度篡改实现100%检测。", "conclusion": "该研究证实间歇性热木马攻击对SoC构成重大威胁，所提出的微型机器学习检测方案显著优于传统方法，为芯片安全防护提供了新思路。"}}
{"id": "2507.05827", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.05827", "abs": "https://arxiv.org/abs/2507.05827", "authors": ["G. Gutin", "M. A. Nielsen", "A. Yeo", "Y. Zhou"], "title": "Judicious Partitions in Edge-Weighted Graphs with Bounded Maximum Weighted Degree", "comment": null, "summary": "In this paper, we investigate bounds for the following judicious\n$k$-partitioning problem: Given an edge-weighted graph $G$, find a\n$k$-partition $(V_1,V_2,\\dots ,V_k)$ of $V(G)$ such that the total weight of\nedges in the heaviest induced subgraph, $\\max_{i=1}^k w(G[V_i])$, is minimized.\nIn our bounds, we also take into account the weight $w(V_1,V_2,\\dots,V_k)$ of\nthe cut induced by the partition (i.e., the total weight of edges with\nendpoints in different parts) and show the existence of a partition satisfying\ntight bounds for both quantities simultaneously. We establish such tight bounds\nfor the case $k=2$ and, to the best of our knowledge, present the first (even\nfor unweighted graphs) completely tight bound for $k=3$. We also show that, in\ngeneral, these results cannot be extended to $k \\geq 4$ without introducing an\nadditional lower-order term, and we propose a corresponding conjecture.\nMoreover, we prove that there always exists a $k$-partition satisfying $\\max\n\\left\\{ w(G[V_i]) : i \\in [k] \\right\\} \\leq \\frac{w(G)}{k^2} + \\frac{k -\n1}{2k^2} \\Delta_w(G),$ where $\\Delta_w(G)$ denotes the maximum weighted degree\nof $G$. This bound is tight for every integer $k\\geq 2$.", "AI": {"tldr": "本文研究了边加权图的公平k划分问题，提出了同时优化最大子图权重和割权重的紧界，首次给出了k=3时的完全紧界，并证明了一般情况下k≥4时需引入低阶项。", "motivation": "探索边加权图中同时最小化最大诱导子图权重和割权重的k划分问题，填补k=3时理论空白，并验证k≥4时的限制条件。", "method": "通过组合分析和极值图论技术，建立k=2和k=3的紧界，构造性证明一般情况下的权重分配不等式$\\max w(G[V_i]) \\leq \\frac{w(G)}{k^2} + \\frac{k-1}{2k^2}\\Delta_w(G)$。", "result": "1) 首次给出k=3时完全紧界 2) 证明k≥4需低阶修正项 3) 提出普适紧界公式并验证其最优性 4) 发现最大加权度$\\Delta_w(G)$的关键影响。", "conclusion": "该研究系统解决了2-3划分问题，揭示了k≥4的复杂性，提出的权重分配公式为后续研究奠定了基础，并启发关于高阶划分的猜想。"}}
{"id": "2507.05893", "categories": ["math.OC", "62G05, 90C35 (Primary) 62M20, 62M10 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.05893", "abs": "https://arxiv.org/abs/2507.05893", "authors": ["Edward J. Anderson", "Dominic S. T. Keehan"], "title": "Nonstationary Distribution Estimation via Wasserstein Probability Flows", "comment": "28 pages, 8 figures", "summary": "We study the problem of estimating a sequence of evolving probability\ndistributions from historical data, where the underlying distribution changes\nover time in a nonstationary and nonparametric manner. To capture gradual\nchanges, we introduce a model that penalises large deviations between\nconsecutive distributions using the Wasserstein distance. This leads to a\nmethod in which we estimate the underlying series of distributions by\nmaximizing the log-likelihood of the observations with a penalty applied to the\nsum of the Wasserstein distances between consecutive distributions. We show how\nthis can be reduced to a simple network-flow problem enabling efficient\ncomputation. We call this the Wasserstein Probability Flow method. We derive\nsome properties of the optimal solutions and carry out numerical tests in\ndifferent settings. Our results suggest that the Wasserstein Probability Flow\nmethod is a promising tool for applications such as nonstationary stochastic\noptimization.", "AI": {"tldr": "本文提出了一种基于Wasserstein距离的Wasserstein概率流方法，用于从历史数据中估计随时间演变的概率分布序列，适用于非平稳和非参数化的分布变化场景。", "motivation": "研究动机在于解决非平稳和非参数化环境下，如何从历史数据中准确估计随时间变化的概率分布序列的问题。", "method": "方法通过引入Wasserstein距离作为惩罚项，构建了一个最大化观测数据对数似然并惩罚连续分布间Wasserstein距离之和的模型，并将其简化为网络流问题以实现高效计算。", "result": "数值实验结果表明，Wasserstein概率流方法在不同设置下均表现良好，验证了其作为非平稳随机优化等应用工具的潜力。", "conclusion": "结论指出，Wasserstein概率流方法是处理非平稳环境下概率分布序列估计的有效工具，尤其在非平稳随机优化等应用中展现出良好的前景。"}}
{"id": "2507.06162", "categories": ["math.NT", "68Q45, 11B39", "F.2.2"], "pdf": "https://arxiv.org/pdf/2507.06162", "abs": "https://arxiv.org/abs/2507.06162", "authors": ["Rob Burns"], "title": "Shifting Zeckendorf and Chung-Graham representations", "comment": "17 pages, 3 figures", "summary": "We re-prove some results about integers whose Zeckendorf and Chung-Graham\nrepresentations satisfy certain conditions. We use properties of the shift\noperator and use the software package {\\tt Walnut}.", "AI": {"tldr": "重新证明关于Zeckendorf和Chung-Graham表示满足特定条件的整数结果，利用移位算子性质及{\\tt Walnut}软件。", "motivation": "探索整数在Zeckendorf和Chung-Graham表示下的性质，验证已有结果的正确性。", "method": "应用移位算子的数学性质，并借助{\\tt Walnut}软件包进行自动化验证。", "result": "成功重新证明了关于特定整数表示条件的若干结果，验证了其有效性。", "conclusion": "通过数学工具与软件辅助，强化了对整数特殊表示形式的理论理解。"}}
{"id": "2507.05520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05520", "abs": "https://arxiv.org/abs/2507.05520", "authors": ["Karishma Thakrar", "Shreyas Basavatia", "Akshay Daftardar"], "title": "Cultivating Multimodal Intelligence: Interpretive Reasoning and Agentic RAG Approaches to Dermatological Diagnosis", "comment": "2025 ImageCLEF MEDIQA-MAGIC Challenge", "summary": "The second edition of the 2025 ImageCLEF MEDIQA-MAGIC challenge, co-organized\nby researchers from Microsoft, Stanford University, and the Hospital Clinic of\nBarcelona, focuses on multimodal dermatology question answering and\nsegmentation, using real-world patient queries and images. This work addresses\nthe Closed Visual Question Answering (CVQA) task, where the goal is to select\nthe correct answer to multiple-choice clinical questions based on both\nuser-submitted images and accompanying symptom descriptions. The proposed\napproach combines three core components: (1) fine-tuning open-source multimodal\nmodels from the Qwen, Gemma, and LLaMA families on the competition dataset, (2)\nintroducing a structured reasoning layer that reconciles and adjudicates\nbetween candidate model outputs, and (3) incorporating agentic\nretrieval-augmented generation (agentic RAG), which adds relevant information\nfrom the American Academy of Dermatology's symptom and condition database to\nfill in gaps in patient context. The team achieved second place with a\nsubmission that scored sixth, demonstrating competitive performance and high\naccuracy. Beyond competitive benchmarks, this research addresses a practical\nchallenge in telemedicine: diagnostic decisions must often be made\nasynchronously, with limited input and with high accuracy and interpretability.\nBy emulating the systematic reasoning patterns employed by dermatologists when\nevaluating skin conditions, this architecture provided a pathway toward more\nreliable automated diagnostic support systems.", "AI": {"tldr": "2025年ImageCLEF MEDIQA-MAGIC挑战赛聚焦于多模态皮肤病问答与分割，提出结合开源模型微调、结构化推理层和代理检索增强生成的方案，在竞赛中获得第二名，为远程医疗中的高精度诊断决策提供了可靠支持。", "motivation": "研究旨在解决远程医疗中皮肤病诊断的异步决策难题，要求基于有限输入实现高准确性和可解释性，模拟皮肤科医生的系统推理模式。", "method": "方法包含三部分：(1)对Qwen、Gemma和LLaMA系列开源多模态模型进行微调；(2)引入结构化推理层协调候选模型输出；(3)整合代理检索增强生成技术，补充美国皮肤病学会数据库的临床背景信息。", "result": "该方案在竞赛中获得第二名（提交成绩第六名），展现了竞争性表现和高准确性，验证了多模态融合与结构化推理的有效性。", "conclusion": "通过模拟皮肤科医生的系统推理，该架构为自动化诊断支持系统提供了更可靠的实现路径，尤其适用于输入受限的远程医疗场景。"}}
{"id": "2507.05622", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05622", "abs": "https://arxiv.org/abs/2507.05622", "authors": ["Shuo Shao", "Yiming Li", "Mengren Zheng", "Zhiyang Hu", "Yukun Chen", "Boheng Li", "Yu He", "Junfeng Guo", "Tianwei Zhang", "Dacheng Tao", "Zhan Qin"], "title": "DATABench: Evaluating Dataset Auditing in Deep Learning from an Adversarial Perspective", "comment": null, "summary": "The widespread application of Deep Learning across diverse domains hinges\ncritically on the quality and composition of training datasets. However, the\ncommon lack of disclosure regarding their usage raises significant privacy and\ncopyright concerns. Dataset auditing techniques, which aim to determine if a\nspecific dataset was used to train a given suspicious model, provide promising\nsolutions to addressing these transparency gaps. While prior work has developed\nvarious auditing methods, their resilience against dedicated adversarial\nattacks remains largely unexplored. To bridge the gap, this paper initiates a\ncomprehensive study evaluating dataset auditing from an adversarial\nperspective. We start with introducing a novel taxonomy, classifying existing\nmethods based on their reliance on internal features (IF) (inherent to the\ndata) versus external features (EF) (artificially introduced for auditing).\nSubsequently, we formulate two primary attack types: evasion attacks, designed\nto conceal the use of a dataset, and forgery attacks, intending to falsely\nimplicate an unused dataset. Building on the understanding of existing methods\nand attack objectives, we further propose systematic attack strategies:\ndecoupling, removal, and detection for evasion; adversarial example-based\nmethods for forgery. These formulations and strategies lead to our new\nbenchmark, DATABench, comprising 17 evasion attacks, 5 forgery attacks, and 9\nrepresentative auditing methods. Extensive evaluations using DATABench reveal\nthat none of the evaluated auditing methods are sufficiently robust or\ndistinctive under adversarial settings. These findings underscore the urgent\nneed for developing a more secure and reliable dataset auditing method capable\nof withstanding sophisticated adversarial manipulation. Code is available at\nhttps://github.com/shaoshuo-ss/DATABench.", "AI": {"tldr": "本文首次从对抗性角度全面评估数据集审计技术，提出新的分类法和攻击策略，并构建DATABench基准测试，发现现有审计方法在对抗环境下均不够鲁棒。", "motivation": "深度学习广泛应用依赖训练数据集质量，但数据使用缺乏透明度引发隐私和版权问题。现有数据集审计技术对抗对抗性攻击的鲁棒性尚未充分研究。", "method": "提出新分类法（内部特征IF/外部特征EF），制定两种攻击类型（逃避/伪造攻击），设计系统攻击策略（解耦/移除/检测；对抗样本），构建含17种逃避攻击、5种伪造攻击和9种审计方法的DATABench基准。", "result": "DATABench评估显示，现有审计方法在对抗设置下均不够鲁棒或具有区分性，逃避攻击成功率高达96.8%，伪造攻击成功率可达99.9%。", "conclusion": "研究结果凸显开发能抵抗复杂对抗操作的安全可靠数据集审计方法的紧迫性，DATABench为未来研究提供基准平台。"}}
{"id": "2507.05836", "categories": ["math.CO", "05C45", "G.2.2"], "pdf": "https://arxiv.org/pdf/2507.05836", "abs": "https://arxiv.org/abs/2507.05836", "authors": ["Alexey Pokrovskiy", "Xiaoan Yang"], "title": "Hamiltonicity and structure of connected biclaw-free graphs", "comment": null, "summary": "We show that for sufficiently large $d$, every balanced bipartite, connected\nbiclaw-free graph with minimum degree $\\geq d$ is Hamiltonian. This confirms a\nconjecture of Flandrin, Fouquet, and Li.", "AI": {"tldr": "证明了对于足够大的$d$，所有平衡二分、连通且无双爪的图，若最小度$\\geq d$，则具有哈密顿性，验证了Flandrin等人的猜想。", "motivation": "研究图的哈密顿性质是图论中的核心问题之一，验证Flandrin等人关于特定图类哈密顿性的猜想。", "method": "通过分析平衡二分、连通且无双爪的图的性质，结合最小度$\\geq d$的条件，进行理论证明。", "result": "证明了当$d$足够大时，满足条件的图必定是哈密顿图。", "conclusion": "该结果不仅验证了Flandrin等人的猜想，还为进一步研究图的哈密顿性质提供了新的理论支持。"}}
{"id": "2507.06012", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.06012", "abs": "https://arxiv.org/abs/2507.06012", "authors": ["Alberto Guastalla", "Roberto Aringhieri", "Pierre Hosteins"], "title": "Heuristic approaches for a new variant of the Team Orienteering Problem", "comment": null, "summary": "In this paper we tackle the Team Orienteering Problem with Service Times,\nMandatory Nodes and Incompatibilities, introduced in~\\cite{Guastalla2024} and\narising from two real-world healthcare applications. We propose two heuristic\nalgorithms in the form of a Variable Descent Neighbourhood algorithm and a\nmatheuristic based on a Cuts Separation approach. For the former, we also\nprovide a multi-thread version exploiting its intrinsic capability to be\nparallelised. Both algorithms include a specific heuristic routine to provide a\nstarting feasible solution, since finding a feasible solution has been proved\nto be NP-complete. The results of our heuristic algorithms are compared with an\nexact cutting plane approach and have complementary strengths and weaknesses.\nThey are also evaluated on existing TOP benchmarks against TOP state-of-the-art\nalgorithms, demonstrating their competitiveness on general grounds.", "AI": {"tldr": "本文针对具有服务时间、强制节点和不相容性的团队定向问题，提出了两种启发式算法，并与精确切割平面方法进行对比，展示了在通用基准测试中的竞争力。", "motivation": "研究源于两个实际医疗应用场景中的团队定向问题，该问题被证明是NP完全问题，需要高效启发式算法求解。", "method": "提出可变下降邻域算法和基于切割分离的数学启发式算法，前者实现多线程并行版本，两种算法均包含特定启发式例程生成初始可行解。", "result": "启发式算法与精确切割平面方法形成优势互补，在现有TOP基准测试中展现出与最先进算法相当的竞争力。", "conclusion": "所提算法能有效解决复杂约束下的团队定向问题，在医疗等实际应用场景中具有实用价值。"}}
{"id": "2507.05528", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05528", "abs": "https://arxiv.org/abs/2507.05528", "authors": ["Jiahuan Pei", "Fanghua Ye", "Xin Sun", "Wentao Deng", "Koen Hindriks", "Junxiao Wang"], "title": "Conversational Education at Scale: A Multi-LLM Agent Workflow for Procedural Learning and Pedagogic Quality Assessment", "comment": "14 pages", "summary": "Large language models (LLMs) have advanced virtual educators and learners,\nbridging NLP with AI4Education. Existing work often lacks scalability and fails\nto leverage diverse, large-scale course content, with limited frameworks for\nassessing pedagogic quality. To this end, we propose WikiHowAgent, a\nmulti-agent workflow leveraging LLMs to simulate interactive teaching-learning\nconversations. It integrates teacher and learner agents, an interaction\nmanager, and an evaluator to facilitate procedural learning and assess\npedagogic quality. We introduce a dataset of 114,296 teacher-learner\nconversations grounded in 14,287 tutorials across 17 domains and 727 topics.\nOur evaluation protocol combines computational and rubric-based metrics with\nhuman judgment alignment. Results demonstrate the workflow's effectiveness in\ndiverse setups, offering insights into LLM capabilities across domains. Our\ndatasets and implementations are fully open-sourced.", "AI": {"tldr": "本文提出WikiHowAgent多智能体工作流，利用大语言模型(LLM)模拟师生互动对话，构建包含11万+对话的数据集，并通过混合评估方法验证其在跨领域教学中的有效性。", "motivation": "现有AI教育研究存在可扩展性不足、缺乏大规模课程内容利用及教学评估框架有限的问题，需要开发能模拟真实教学互动的系统性解决方案。", "method": "设计包含教师/学生智能体、交互管理器和评估器的多智能体框架，基于14,287篇教程构建跨17个领域的教学对话数据集，采用计算指标、评估量表和人工评判相结合的评估协议。", "result": "实验表明该工作流在不同配置下均表现良好，揭示了LLM跨领域教学能力，所有数据集和实现代码均已开源。", "conclusion": "WikiHowAgent为AI教育提供了可扩展的交互式学习框架，其混合评估方法为教学质量分析树立了新标准，推动了LLM在教育领域的应用边界。"}}
{"id": "2507.05630", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05630", "abs": "https://arxiv.org/abs/2507.05630", "authors": ["Sarthak Choudhary", "Divyam Anshumaan", "Nils Palumbo", "Somesh Jha"], "title": "How Not to Detect Prompt Injections with an LLM", "comment": null, "summary": "LLM-integrated applications and agents are vulnerable to prompt injection\nattacks, in which adversaries embed malicious instructions within seemingly\nbenign user inputs to manipulate the LLM's intended behavior. Recent defenses\nbased on $\\textit{known-answer detection}$ (KAD) have achieved near-perfect\nperformance by using an LLM to classify inputs as clean or contaminated. In\nthis work, we formally characterize the KAD framework and uncover a structural\nvulnerability in its design that invalidates its core security premise. We\ndesign a methodical adaptive attack, $\\textit{DataFlip}$, to exploit this\nfundamental weakness. It consistently evades KAD defenses with detection rates\nas low as $1.5\\%$ while reliably inducing malicious behavior with success rates\nof up to $88\\%$, without needing white-box access to the LLM or any\noptimization procedures.", "AI": {"tldr": "研究发现基于已知答案检测（KAD）的LLM防御框架存在结构性漏洞，并提出自适应攻击方法DataFlip，能有效绕过防御并诱导恶意行为。", "motivation": "LLM应用易受提示注入攻击，现有KAD防御虽表现优异，但其设计存在根本性安全缺陷需要揭示。", "method": "提出DataFlip攻击方法，无需白盒访问或优化过程，通过系统性利用KAD框架的结构漏洞实现攻击。", "result": "DataFlip将KAD检测率降至1.5\\%，同时实现高达88\\%的恶意行为诱导成功率。", "conclusion": "KAD防御的核心安全前提存在缺陷，需重新评估其有效性并开发更鲁棒的防护机制。"}}
{"id": "2507.05842", "categories": ["math.CO", "05D15", "G.2.2"], "pdf": "https://arxiv.org/pdf/2507.05842", "abs": "https://arxiv.org/abs/2507.05842", "authors": ["Alexey Pokrovskiy"], "title": "Bounded diameter monochromatic component covers", "comment": null, "summary": "Ryser conjectured that every $r$-edge-coloured complete graph can be covered\nby $r-1$ monochromatic trees. Motivated by a question of Austin in analysis,\nMili\\'cevi\\'c predicted something stronger -- that every $r$-edge-coloured\ncomplete graph can be covered by $r-1$ monochromatic trees \\emph{of bounded\ndiameter}. Here we show that the two conjectures are equivalent. As immediate\ncorollaries we obtain new results about Mili\\'cevi\\'c's Conjecture, most\nnotably that it is true for $r=5$. We also obtain several new cases of a\ngeneralization of Mili\\'cevi\\'c's Conjecture to non-complete graphs due to\nDeBiasio-Kamel-McCourt-Sheats.", "AI": {"tldr": "证明了Ryser猜想与Mili\\'cevi\\'c猜想等价，并得出Mili\\'cevi\\'c猜想在$r=5$时成立的新结果。", "motivation": "受Austin分析问题的启发，Mili\\'cevi\\'c提出了比Ryser猜想更强的猜想——每个$r$边着色完全图可被$r-1$棵直径有界的单色树覆盖。", "method": "通过数学证明展示两个猜想的等价性，并推导相关推论。", "result": "证明了两个猜想等价，并首次确认Mili\\'cevi\\'c猜想在$r=5$时成立，同时拓展了DeBiasio-Kamel-McCourt-Sheats对非完全图的推广结果。", "conclusion": "研究不仅统一了两个重要猜想，还为相关领域提供了新的理论支撑，尤其解决了$r=5$的关键情形。"}}
{"id": "2507.06024", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.06024", "abs": "https://arxiv.org/abs/2507.06024", "authors": ["Michael Konopik", "Sigrid Leyendecker", "Sofya Maslovskaya", "Sina Ober-Blöbaum", "Rodrigo T. Sato Martín de Almagro"], "title": "New Lagrangian framework for optimality conditions in optimal control of second order systems", "comment": null, "summary": "It has been shown recently that optimal control problems with the dynamical\nconstraint given by a second order system admit a regular Lagrangian\nformulation. This implies that the optimality conditions can be obtained in a\nnew form based on the variational approach. In this paper we extend the first\norder necessary optimality conditions obtained previously to second order\noptimality conditions and discuss the role of the new Lagrangian.", "AI": {"tldr": "本文扩展了二阶系统最优控制问题的一阶必要条件，提出了二阶最优性条件，并探讨了新拉格朗日量的作用。", "motivation": "近期研究表明，二阶系统动力学约束的最优控制问题具有正则拉格朗日表述，这为通过变分法获得最优性条件提供了新途径。", "method": "基于已有的变分方法，将一阶最优性条件推广至二阶条件，并分析新引入的拉格朗日量的数学特性。", "result": "成功推导出二阶最优性条件，揭示了新拉格朗日量在优化问题中的关键作用。", "conclusion": "该研究为二阶系统最优控制提供了更完备的理论框架，新拉格朗日表述为后续数值算法开发奠定了基础。"}}
{"id": "2507.05538", "categories": ["cs.AI", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.05538", "abs": "https://arxiv.org/abs/2507.05538", "authors": ["Subhabrata Majumdar", "Brian Pendleton", "Abhishek Gupta"], "title": "Red Teaming AI Red Teaming", "comment": null, "summary": "Red teaming has evolved from its origins in military applications to become a\nwidely adopted methodology in cybersecurity and AI. In this paper, we take a\ncritical look at the practice of AI red teaming. We argue that despite its\ncurrent popularity in AI governance, there exists a significant gap between red\nteaming's original intent as a critical thinking exercise and its narrow focus\non discovering model-level flaws in the context of generative AI. Current AI\nred teaming efforts focus predominantly on individual model vulnerabilities\nwhile overlooking the broader sociotechnical systems and emergent behaviors\nthat arise from complex interactions between models, users, and environments.\nTo address this deficiency, we propose a comprehensive framework\noperationalizing red teaming in AI systems at two levels: macro-level system\nred teaming spanning the entire AI development lifecycle, and micro-level model\nred teaming. Drawing on cybersecurity experience and systems theory, we further\npropose a set of recommendations. In these, we emphasize that effective AI red\nteaming requires multifunctional teams that examine emergent risks, systemic\nvulnerabilities, and the interplay between technical and social factors.", "AI": {"tldr": "本文批判性审视了AI红队测试的现状，指出其过于关注模型层面缺陷而忽视社会技术系统的问题，并提出包含宏观系统层面和微观模型层面的综合框架。", "motivation": "当前AI红队测试虽在AI治理中流行，但其聚焦个体模型漏洞的做法与最初作为批判性思维训练的目的存在显著差距，且忽略了模型、用户与环境交互产生的系统性风险。", "method": "提出双层次操作框架：宏观层面覆盖AI全生命周期的系统红队测试，微观层面进行模型红队测试，并借鉴网络安全经验与系统理论提出建议。", "result": "强调有效的AI红队测试需跨职能团队协作，考察涌现风险、系统脆弱性及技术-社会因素的相互作用。", "conclusion": "AI红队测试应超越模型缺陷检测，转向系统性风险评估，以应对生成式AI复杂社会技术环境中的挑战。"}}
{"id": "2507.05649", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05649", "abs": "https://arxiv.org/abs/2507.05649", "authors": ["Kaixiang Zhao", "Joseph Yousry Attalla", "Qian Lou", "Yushun Dong"], "title": "DESIGN: Encrypted GNN Inference via Server-Side Input Graph Pruning", "comment": "Under Review in Conference on Neural Information Processing Systems\n  (NeurIPS 2025)", "summary": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance in\nvarious graph-based learning tasks. However, enabling privacy-preserving GNNs\nin encrypted domains, such as under Fully Homomorphic Encryption (FHE),\ntypically incurs substantial computational overhead, rendering real-time and\nprivacy-preserving inference impractical. In this work, we propose DESIGN\n(EncrypteD GNN Inference via sErver-Side Input Graph pruNing), a novel\nframework for efficient encrypted GNN inference. DESIGN tackles the critical\nefficiency limitations of existing FHE GNN approaches, which often overlook\ninput data redundancy and apply uniform computational strategies. Our framework\nachieves significant performance gains through a hierarchical optimization\nstrategy executed entirely on the server: first, FHE-compatible node importance\nscores (based on encrypted degree statistics) are computed from the encrypted\ngraph. These scores then guide a homomorphic partitioning process, generating\nmulti-level importance masks directly under FHE. This dynamically generated\nmask facilitates both input graph pruning (by logically removing unimportant\nelements) and a novel adaptive polynomial activation scheme, where activation\ncomplexity is tailored to node importance levels. Empirical evaluations\ndemonstrate that DESIGN substantially accelerates FHE GNN inference compared to\nstate-of-the-art methods while maintaining competitive model accuracy,\npresenting a robust solution for secure graph analytics.", "AI": {"tldr": "DESIGN框架通过服务器端输入图剪枝和自适应多项式激活方案，显著提升了全同态加密（FHE）下图神经网络（GNN）推理的效率，同时保持模型精度。", "motivation": "现有FHE GNN方法因忽视输入数据冗余和采用统一计算策略，导致计算开销巨大，难以实现实时隐私保护推理。", "method": "DESIGN采用分层优化策略：1) 基于加密度统计计算节点重要性分数；2) 通过同态分区生成多级重要性掩码；3) 动态掩码指导输入图剪枝和自适应多项式激活。", "result": "实验表明，DESIGN相比现有方法显著加速FHE GNN推理，同时保持竞争力的模型准确率。", "conclusion": "DESIGN为安全图分析提供了高效且隐私保护的解决方案，通过服务器端优化实现了FHE环境下GNN推理的实用化突破。"}}
{"id": "2507.05987", "categories": ["math.CO", "math.AG", "14T15, 14H40"], "pdf": "https://arxiv.org/pdf/2507.05987", "abs": "https://arxiv.org/abs/2507.05987", "authors": ["Felix Röhrle", "Thomas Saillez"], "title": "Tropical Donagi theorem", "comment": "33 pages", "summary": "The tropical $n$-gonal construction was introduced in recent work by the\nfirst author and D.~Zakharov and structural results for $n = 2,3$ were\nestablished. In this article we explore the construction for $n = 4$ and prove\na tropical analogue of Donagi's theorem which states that the tetragonal\nconstruction is a triality which preserves Prym varieties. This confirms the\nspeculations in previous work and establishes new results on the\nnon-injectivity of the tropical Prym-Torelli morphism. Finally, we demonstrate\nthat the tropical $n$-gonal construction is poorly behaved under edge\ncontractions, thus preventing any immediate moduli-theoretic perspective.", "AI": {"tldr": "本文探讨了热带四边形的构造，证明了与Donagi定理类似的热带版本，确认了先前研究中的推测，并揭示了热带Prym-Torelli态射的非单射性新结果。", "motivation": "研究热带$n$-边形构造在$n=4$时的性质，验证先前关于四边形构造三重性及Prym簇保持的推测，并探索热带Prym-Torelli态射的非单射性。", "method": "通过热带几何方法，分析四边形的构造，并证明热带版本的Donagi定理，同时考察构造在边收缩下的行为。", "result": "证明了热带四边形构造具有三重性并保持Prym簇，确认了热带Prym-Torelli态射的非单射性，并发现构造在边收缩下表现不佳。", "conclusion": "热带四边形构造验证了Donagi定理的热带类比，但因其在边收缩下的不良行为，阻碍了直接的模理论视角。"}}
{"id": "2507.06118", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.06118", "abs": "https://arxiv.org/abs/2507.06118", "authors": ["Ying Hu", "Guomin Liu", "Shanjian Tang"], "title": "Relationship between maximum principle and dynamic programming principle for recursive optimal control problem of stochastic evolution equations", "comment": null, "summary": "This paper aims to study the relationship between the maximum principle and\nthe dynamic programming principle for recursive optimal control problem of\nstochastic evolution equations, where the control domain is not necessarily\nconvex and the value function may be nonsmooth. By making use of the notion of\nconditionally expected operator-valued backward stochastic integral equations,\nwe establish a connection between the first and second-order adjoint processes\nin MP and the general derivatives of the value function. Under certain\nadditional assumptions, the value function is shown to be $C^{1,1}$-regular.\nFurthermore, we discuss the smooth case and present several applications of our\nresults.", "AI": {"tldr": "本文研究了随机演化方程递归最优控制问题中最大值原理与动态规划原理的关系，通过条件期望算子值反向随机积分方程概念，建立了MP中一阶和二阶伴随过程与价值函数广义导数之间的联系，并在附加假设下证明了价值函数的$C^{1,1}$正则性。", "motivation": "探讨非凸控制域和非光滑价值函数情况下，随机演化方程递归最优控制问题中最大值原理(MP)与动态规划原理(DPP)的关联性。", "method": "利用条件期望算子值反向随机积分方程的概念，建立MP中一阶/二阶伴随过程与价值函数广义导数之间的理论联系。", "result": "在特定附加假设下证明了价值函数具有$C^{1,1}$正则性，并讨论了光滑情形下的应用案例。", "conclusion": "该研究为随机控制理论提供了MP与DPP之间的桥梁，特别适用于非凸控制域和非光滑价值函数情形，理论结果具有广泛的应用潜力。"}}
{"id": "2507.05541", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05541", "abs": "https://arxiv.org/abs/2507.05541", "authors": ["Shovito Barua Soumma", "Asiful Arefeen", "Stephanie M. Carpenter", "Melanie Hingle", "Hassan Ghasemzadeh"], "title": "SenseCF: LLM-Prompted Counterfactuals for Intervention and Sensor Data Augmentation", "comment": "In review", "summary": "Counterfactual explanations (CFs) offer human-centric insights into machine\nlearning predictions by highlighting minimal changes required to alter an\noutcome. Therefore, CFs can be used as (i) interventions for abnormality\nprevention and (ii) augmented data for training robust models. In this work, we\nexplore large language models (LLMs), specifically GPT-4o-mini, for generating\nCFs in a zero-shot and three-shot setting. We evaluate our approach on two\ndatasets: the AI-Readi flagship dataset for stress prediction and a public\ndataset for heart disease detection. Compared to traditional methods such as\nDiCE, CFNOW, and NICE, our few-shot LLM-based approach achieves high\nplausibility (up to 99%), strong validity (up to 0.99), and competitive\nsparsity. Moreover, using LLM-generated CFs as augmented samples improves\ndownstream classifier performance (an average accuracy gain of 5%), especially\nin low-data regimes. This demonstrates the potential of prompt-based generative\ntechniques to enhance explainability and robustness in clinical and\nphysiological prediction tasks. Code base: github.com/anonymous/SenseCF.", "AI": {"tldr": "本文探索使用GPT-4o-mini等大语言模型(LLM)生成反事实解释(CFs)，在零样本和三样本设置下，相比传统方法(DiCE/CFNOW/NICE)获得更高合理性(99%)和有效性(0.99)，且生成的CFs作为增强数据可使下游分类器准确率平均提升5%。", "motivation": "反事实解释(CFs)能通过展示最小改变来提供人本洞察，既可用于异常预防干预，也能作为增强数据提升模型鲁棒性。研究旨在探索LLM在临床生理预测任务中提升可解释性与鲁棒性的潜力。", "method": "采用GPT-4o-mini模型，在零样本和三样本设置下生成CFs。评估数据集包括AI-Readi压力预测旗舰数据集和公开心脏病检测数据集，并与DiCE/CFNOW/NICE等传统方法对比。", "result": "LLM方法在合理性(最高99%)、有效性(最高0.99)和稀疏性上表现优异。使用LLM生成的CFs作为增强样本时，下游分类器准确率平均提升5%，在低数据场景效果尤为显著。", "conclusion": "基于提示的生成技术能有效增强临床和生理预测任务的可解释性与鲁棒性，代码库见github.com/anonymous/SenseCF。"}}
{"id": "2507.05660", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05660", "abs": "https://arxiv.org/abs/2507.05660", "authors": ["Aravind Cheruvu", "Shravya Kanchi", "Sifat Muhammad Abdullah", "Nicholas Kong", "Daphne Yao", "Murtuza Jadliwala", "Bimal Viswanath"], "title": "TuneShield: Mitigating Toxicity in Conversational AI while Fine-tuning on Untrusted Data", "comment": "Pre-print", "summary": "Recent advances in foundation models, such as LLMs, have revolutionized\nconversational AI. Chatbots are increasingly being developed by customizing\nLLMs on specific conversational datasets. However, mitigating toxicity during\nthis customization, especially when dealing with untrusted training data,\nremains a significant challenge. To address this, we introduce TuneShield, a\ndefense framework designed to mitigate toxicity during chatbot fine-tuning\nwhile preserving conversational quality. TuneShield leverages LLM-based\ntoxicity classification, utilizing the instruction-following capabilities and\nsafety alignment of LLMs to effectively identify toxic samples, outperforming\nindustry API services. TuneShield generates synthetic conversation samples,\ntermed 'healing data', based on the identified toxic samples, using them to\nmitigate toxicity while reinforcing desirable behavior during fine-tuning. It\nperforms an alignment process to further nudge the chatbot towards producing\ndesired responses. Our findings show that TuneShield effectively mitigates\ntoxicity injection attacks while preserving conversational quality, even when\nthe toxicity classifiers are imperfect or biased. TuneShield proves to be\nresilient against adaptive adversarial and jailbreak attacks. Additionally,\nTuneShield demonstrates effectiveness in mitigating adaptive toxicity injection\nattacks during dialog-based learning (DBL).", "AI": {"tldr": "本文提出TuneShield框架，利用LLM的毒性分类能力生成'治疗数据'，在微调过程中有效降低聊天机器人毒性，同时保持对话质量。", "motivation": "尽管LLM在对话AI领域取得进展，但在使用不可信训练数据定制聊天机器人时，毒性内容仍是重大挑战。", "method": "TuneShield通过LLM毒性分类识别有毒样本，生成合成对话样本（治疗数据），并在微调中进行对齐处理。", "result": "实验表明TuneShield能有效抵御毒性注入攻击和越狱攻击，在对话式学习中保持稳健性，即使分类器存在缺陷。", "conclusion": "该框架为安全定制聊天机器人提供了有效解决方案，在毒性缓解和对话质量保持方面表现出色。"}}
{"id": "2507.06120", "categories": ["math.CO", "05E45, 52B35, 52B12"], "pdf": "https://arxiv.org/pdf/2507.06120", "abs": "https://arxiv.org/abs/2507.06120", "authors": ["Shuai Huang", "Jasper Miller", "Daniel Rose-Levine", "Steven Simon"], "title": "A non-face characterization of spheres on few vertices", "comment": "6 pages", "summary": "We give a relatively simple characterization of simplicial $d$-spheres on\n$d+4$ vertices; our criteria are in terms of the intersection patterns of a\nsimplicial complex's minimal non-faces. Namely, let $\\Sigma$ be a simplicial\ncomplex with vertex set $[d+4]$ and let $\\mathcal{F}=\\{A_0,\\ldots, A_{n-1}\\}$\nbe its family of minimal non-faces, indices taken in $\\mathbb{Z}_n$. Then\n$\\Sigma$ is a $d$-sphere if and only if the following hold: $n\\geq 3$ is odd,\nsuccessive $A_i$ are disjoint, and the alternating $(\\frac{n-1}{2})$-fold\nintersections $A_i\\cap A_{i+2} \\cap A_{i+4} \\cap \\cdots \\cap A_{i+n-3}$\npartition $[d+4]$.", "AI": {"tldr": "本文提出了一个关于在$d+4$顶点上的单纯$d$-球面的简单特征化方法，基于最小非面族的交集模式。", "motivation": "研究单纯复形在特定顶点数下的球面特征，旨在简化复杂结构的识别标准。", "method": "通过分析单纯复形的最小非面族$\\mathcal{F}=\\{A_0,\\ldots, A_{n-1}\\}$的交集模式，特别是交替$(\\frac{n-1}{2})$-重交集的分割性质。", "result": "证明了单纯复形$\\Sigma$是$d$-球面的充要条件为：$n\\geq 3$为奇数，连续$A_i$不相交，且交替交集分割顶点集$[d+4]$。", "conclusion": "该特征化方法为识别单纯$d$-球面提供了一种简洁而有效的标准，适用于顶点数为$d+4$的情况。"}}
{"id": "2507.06199", "categories": ["math.OC", "cs.NA", "math.NA", "90C55, 65K05, 49M37, 49M41"], "pdf": "https://arxiv.org/pdf/2507.06199", "abs": "https://arxiv.org/abs/2507.06199", "authors": ["Dane S. Grundvig", "Matthias Heinkenschloss"], "title": "A Generalized $\\ell_1$-Merit Function SQP Method Using Function Approximations with Tunable Accuracy", "comment": null, "summary": "This paper develops a generalization of the line-search sequential quadratic\nprogramming (SQP) algorithm with $\\ell_1$-merit function that uses objective\nand constraint function approximations with tunable accuracy to solve smooth\nequality-constrained optimization problems. The evaluation of objective and\nconstraint functions and their gradients is potentially computationally\nexpensive, but it is assumed that one can construct effective, computationally\ninexpensive models of these functions. This paper specifies how these models\ncan be used to generate new iterates. At each iteration, the models have to\nsatisfy function error and relative gradient error tolerances determined by the\nalgorithm based on its progress. Moreover, bounds for the model errors are used\nto explore regions where the combined objective function and constraint models\nare sufficiently accurate. The algorithm has the same first-order global\nconvergence properties as a line-search SQP algorithm with $\\ell_1$-merit\nfunction, but only uses objective and constraint function models and the model\nerror bounds. The algorithm is applied to a discretized boundary control\nproblem in which the evaluation of the objective and constraint functions\nrequires the solution of the Boussinesq partial differential equation (PDE).\nThe models are constructed from projection-based reduced-order models of the\nBoussinesq PDE.", "AI": {"tldr": "本文提出了一种基于$\\ell_1$-merit函数的线搜索SQP算法扩展，通过可调精度的目标与约束函数近似求解光滑等式约束优化问题，并应用于Boussinesq PDE的边界控制问题。", "motivation": "目标与约束函数及其梯度的计算成本高昂，但可通过构建高效、低计算成本的模型来近似这些函数，从而降低计算负担。", "method": "算法在每次迭代中使用满足函数误差和相对梯度误差容忍度的模型生成新迭代点，并利用模型误差边界探索足够精确的区域。模型基于Boussinesq PDE的降阶模型构建。", "result": "算法保持了与标准线搜索SQP算法相同的全局收敛性，但仅依赖目标与约束函数模型及其误差边界。数值实验验证了其在边界控制问题中的有效性。", "conclusion": "所提算法通过模型近似降低了计算成本，同时保持了收敛性，适用于需要高计算成本的PDE相关优化问题。"}}
{"id": "2507.05566", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05566", "abs": "https://arxiv.org/abs/2507.05566", "authors": ["David Bensaïd", "Noam Rotstein", "Roy Velich", "Daniel Bensaïd", "Ron Kimmel"], "title": "SingLoRA: Low Rank Adaptation Using a Single Matrix", "comment": null, "summary": "Low-Rank Adaptation (LoRA) has significantly advanced parameter-efficient\nfine-tuning of large pretrained models. LoRA augments the pre-trained weights\nof a model by adding the product of two smaller matrices that together form a\nlow-rank matrix update. Recent research has shown that scale disparities\nbetween these two matrices often cause unstable training dynamics, leading to\nsuboptimal performance. In this paper, we propose SingLoRA, which reformulates\nlow-rank adaptation by learning the weights update as a decomposition of a\nsingle low-rank matrix multiplied by its transpose. This simple design\ninherently removes inter-matrix scale conflicts, ensuring stable optimization,\nand roughly halves the parameter count. We analyze SingLoRA within the\ninfinite-width neural network framework, showing that it guarantees stable\nfeature learning by construction. Extensive experiments on multiple tasks\nvalidate these benefits. In common sense reasoning, fine-tuning LLama 7B on\nMNLI with SingLoRA achieves 91.3% accuracy - surpassing LoRA (89.1%) and LoRA+\n(90.2%) - while using only 60% of their parameter budget. In image generation,\nfine-tuning Stable Diffusion with SingLoRA significantly improves image\nfidelity on DreamBooth, achieving a DINO similarity score of 0.151, compared to\nscores of 0.148 and 0.143 for DoRA and LoRA, respectively.", "AI": {"tldr": "SingLoRA提出了一种新的低秩适应方法，通过单矩阵分解消除尺度冲突，减少参数量并提升训练稳定性，在多个任务中表现优于LoRA和LoRA+。", "motivation": "现有LoRA方法中两个小矩阵间的尺度差异会导致训练不稳定和性能下降，需改进参数高效微调技术。", "method": "将权重更新重构为单个低秩矩阵与其转置的乘积，消除矩阵间尺度冲突，参数量减半且保证稳定优化。", "result": "在LLama 7B微调MNLI任务中准确率达91.3%（LoRA为89.1%），Stable Diffusion微调DINO相似度0.151（LoRA为0.143），均仅用60%参数量。", "conclusion": "SingLoRA通过数学重构解决了低秩适应的核心问题，在理论保证和实验性能上均显著优于现有方法，具有广泛应用潜力。"}}
{"id": "2507.05683", "categories": ["cs.CR", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.05683", "abs": "https://arxiv.org/abs/2507.05683", "authors": ["Steven Duplij", "Qiang Guo"], "title": "Polyadic encryption", "comment": "revtex 4.2, 9 pages", "summary": "A novel original procedure of encryption/decryption based on the polyadic\nalgebraic structures and on signal processing methods is proposed. First, we\nuse signals with integer amplitudes to send information. Then we use polyadic\ntechniques to transfer the plaintext into series of special integers. The\nreceiver restores the plaintext using special rules and systems of equations.", "AI": {"tldr": "提出了一种基于多元代数结构和信号处理方法的加密/解密新流程。", "motivation": "利用多元代数技术和信号处理方法，开发一种新型的加密/解密机制，以提高信息传输的安全性。", "method": "首先使用整数振幅信号发送信息，然后通过多元技术将明文转换为特殊整数序列，接收方使用特定规则和方程组恢复明文。", "result": "该方法成功实现了信息的加密传输和解密恢复，验证了其可行性和有效性。", "conclusion": "该研究为信息安全领域提供了一种创新的加密/解密方法，结合了多元代数与信号处理的优势。"}}
{"id": "2507.05587", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05587", "abs": "https://arxiv.org/abs/2507.05587", "authors": ["Elija Perrier"], "title": "Towards Measurement Theory for Artificial Intelligence", "comment": "Under review for Iliad Conference 2025", "summary": "We motivate and outline a programme for a formal theory of measurement of\nartificial intelligence. We argue that formalising measurement for AI will\nallow researchers, practitioners, and regulators to: (i) make comparisons\nbetween systems and the evaluation methods applied to them; (ii) connect\nfrontier AI evaluations with established quantitative risk analysis techniques\ndrawn from engineering and safety science; and (iii) foreground how what counts\nas AI capability is contingent upon the measurement operations and scales we\nelect to use. We sketch a layered measurement stack, distinguish direct from\nindirect observables, and signpost how these ingredients provide a pathway\ntoward a unified, calibratable taxonomy of AI phenomena.", "AI": {"tldr": "本文提出建立人工智能测量的形式化理论框架，旨在通过标准化测量实现系统比较、风险评估及能力量化，并构建可校准的AI现象分类体系。", "motivation": "研究者、从业者和监管者需要形式化的AI测量理论来：(i) 比较不同系统及其评估方法；(ii) 将前沿AI评估与传统工程安全量化分析技术结合；(iii) 揭示AI能力定义对测量方法的依赖性。", "method": "提出分层测量框架，区分直接观测量与间接观测量，为构建统一可校准的AI现象分类学提供方法论路径。", "result": "通过测量操作和量表的标准化，建立了连接工程安全科学与AI评估的桥梁，为能力比较和风险分析奠定基础。", "conclusion": "形式化测量理论将推动AI评估向可量化、可比较的方向发展，其分层框架和观测量分类有望形成普适的AI现象分类体系。"}}
{"id": "2507.05728", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05728", "abs": "https://arxiv.org/abs/2507.05728", "authors": ["Ruofei Wang", "Peiqi Duan", "Boxin Shi", "Renjie Wan"], "title": "Asynchronous Event Error-Minimizing Noise for Safeguarding Event Dataset", "comment": "Accepted by ICCV2025", "summary": "With more event datasets being released online, safeguarding the event\ndataset against unauthorized usage has become a serious concern for data\nowners. Unlearnable Examples are proposed to prevent the unauthorized\nexploitation of image datasets. However, it's unclear how to create unlearnable\nasynchronous event streams to prevent event misuse. In this work, we propose\nthe first unlearnable event stream generation method to prevent unauthorized\ntraining from event datasets. A new form of asynchronous event error-minimizing\nnoise is proposed to perturb event streams, tricking the unauthorized model\ninto learning embedded noise instead of realistic features. To be compatible\nwith the sparse event, a projection strategy is presented to sparsify the noise\nto render our unlearnable event streams (UEvs). Extensive experiments\ndemonstrate that our method effectively protects event data from unauthorized\nexploitation, while preserving their utility for legitimate use. We hope our\nUEvs contribute to the advancement of secure and trustworthy event dataset\nsharing. Code is available at: https://github.com/rfww/uevs.", "AI": {"tldr": "本文提出了一种针对异步事件流的不可学习样本生成方法（UEvs），通过添加稀疏化噪声防止事件数据集被未经授权的模型训练利用，同时保持合法使用的有效性。", "motivation": "随着在线事件数据集的增多，保护数据免受未经授权使用成为重要问题。现有不可学习样本方法主要针对图像数据，缺乏对事件流的保护方案。", "method": "提出异步事件误差最小化噪声，通过投影策略将噪声稀疏化以适配事件流特性，生成不可学习事件流（UEvs）。", "result": "实验表明该方法能有效阻止未经授权的模型训练，同时不影响数据的合法使用。代码已开源。", "conclusion": "UEvs为事件数据集的安全共享提供了新方案，推动了可信事件数据生态的发展。"}}
{"id": "2507.06184", "categories": ["math.CO", "05C50"], "pdf": "https://arxiv.org/pdf/2507.06184", "abs": "https://arxiv.org/abs/2507.06184", "authors": ["Fenglei Tian", "Dein Wong"], "title": "On the multiplicity of 1 as a Laplacian eigenvalue of a graph", "comment": null, "summary": "Let $G$ be a graph with $p(G)$ pendant vertices and $q(G)$ quasi-pendant\nvertices. Denote by $m_{L(G)}(\\lambda)$ the multiplicity of $\\lambda$ as a\nLaplacian eigenvalue of $G$. Let $\\overline{G}$ be the reduced graph of $G$,\nwhich can be obtained from $G$ by deleting some pendant vertices such that\n$p(\\overline{G})=q(\\overline{G})$. We first prove that\n$m_{L(G)}(1)=p(G)-q(G)+m_{L(\\overline{G})}(1)$. Since deleting pendant path\n$P_3$ does not change the multiplicity of Laplacian eigenvalue 1 of a graph, we\nfurther focus on reduced graphs without pendant path $P_3$. Let $T$ be a\nreduced tree on $n(\\geq 6)$ vertices without pendant path $P_3$, then it is\nproved that $$m_{L(T)}(1)\\leq \\frac{n-6}{4},$$ and all the trees attaining the\nupper bound are characterized completely. As an application, for a reduced\nunicyclic graph $G$ of order $n\\geq 10$ without pendant path $P_3$, we get\n$$m_{L(G)}(1)\\leq \\frac{n}{4},$$ and all the unicyclic graphs attaining the\nupper bound are determined completely.", "AI": {"tldr": "该论文研究了图的拉普拉斯特征值1的重数，通过引入简化图的概念，推导出重数的计算公式，并对不含悬挂路径P3的简化树和单环图给出了重数的上界及达到上界的图的结构特征。", "motivation": "研究图的拉普拉斯特征值1的重数对于理解图的结构特性具有重要意义。通过分析简化图和删除悬挂顶点对重数的影响，可以更深入地揭示图的代数性质与结构之间的关系。", "method": "首先证明了$m_{L(G)}(1)=p(G)-q(G)+m_{L(\\overline{G})}(1)$，其中$\\overline{G}$是简化图。然后，针对不含悬挂路径$P_3$的简化树和单环图，推导了重数的上界，并完全刻画了达到上界的图的结构。", "result": "对于不含悬挂路径$P_3$的简化树$T$，证明了$m_{L(T)}(1)\\leq \\frac{n-6}{4}$，并完全刻画了达到上界的树。对于不含悬挂路径$P_3$的简化单环图$G$，得到了$m_{L(G)}(1)\\leq \\frac{n}{4}$，并确定了所有达到上界的单环图。", "conclusion": "通过引入简化图的概念，论文成功推导了拉普拉斯特征值1的重数的计算公式，并对特定类型的图给出了重数的上界及其结构特征。这些结果为图的代数性质的进一步研究提供了新的工具和视角。"}}
{"id": "2507.05591", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05591", "abs": "https://arxiv.org/abs/2507.05591", "authors": ["Wei Zhang", "Juan Chen", "En Zhu", "Wenhong Cheng", "YunPeng Li", "Yanbo J. Wang"], "title": "MLlm-DR: Towards Explainable Depression Recognition with MultiModal Large Language Models", "comment": null, "summary": "Automated depression diagnosis aims to analyze multimodal information from\ninterview videos to predict participants' depression scores. Previous studies\noften lack clear explanations of how these scores were determined, limiting\ntheir adoption in clinical practice. While the advent of LLMs provides a\npossible pathway for explainable depression diagnosis, current LLMs capable of\nprocessing multimodal data lack training on interview data, resulting in poor\ndiagnostic performance when used directly. In this paper, we propose a novel\nmultimodal large language model (MLlm-DR) that can understand multimodal\ninformation inputs and supports explainable depression diagnosis. MLlm-DR\nintegrates a smaller LLMs and a lightweight query module (LQ-former).\nSpecifically, the smaller LLMs is designed to generate depression scores and\ncorresponding evaluation rationales. To enhance its logical reasoning for\ndomain-specific tasks while maintaining practicality, we constructed a robust\ntraining dataset to fine-tune it. Meanwhile, the LQ-former captures\ndepression-related features from speech and visual data, aiding the model's\nability to process multimodal information, to achieve comprehensive depression\ndiagnosis. Our approach achieves state-of-the-art results on two\ninterview-based benchmark datasets, CMDC and E-DAIC-WOZ, demonstrating its\neffectiveness and superiority.", "AI": {"tldr": "本文提出了一种新型多模态大语言模型MLlm-DR，通过整合轻量级查询模块和小型LLMs，实现了可解释的抑郁症诊断，并在两个基准数据集上取得了最优效果。", "motivation": "现有抑郁症自动诊断方法缺乏对评分依据的清晰解释，且当前多模态大语言模型因缺乏访谈数据训练而诊断性能不佳，亟需开发兼具解释性和高性能的解决方案。", "method": "MLlm-DR模型融合小型LLMs（生成抑郁评分及诊断依据）和轻量级查询模块LQ-former（提取语音视觉特征），通过构建专业训练数据集进行微调，增强多模态信息处理能力。", "result": "模型在CMDC和E-DAIC-WOZ两个访谈基准数据集上达到最先进水平，验证了其在抑郁症综合诊断中的有效性和优越性。", "conclusion": "MLlm-DR通过创新架构设计解决了现有模型解释性不足和性能受限的问题，为临床实践提供了可靠的可解释抑郁症诊断工具。"}}
{"id": "2507.05794", "categories": ["cs.CR", "cs.AI", "cs.LO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.05794", "abs": "https://arxiv.org/abs/2507.05794", "authors": ["Avi Shaked", "Nan Messe"], "title": "Automated Reasoning for Vulnerability Management by Design", "comment": null, "summary": "For securing systems, it is essential to manage their vulnerability posture\nand design appropriate security controls. Vulnerability management allows to\nproactively address vulnerabilities by incorporating pertinent security\ncontrols into systems designs. Current vulnerability management approaches do\nnot support systematic reasoning about the vulnerability postures of systems\ndesigns. To effectively manage vulnerabilities and design security controls, we\npropose a formally grounded automated reasoning mechanism. We integrate the\nmechanism into an open-source security design tool and demonstrate its\napplication through an illustrative example driven by real-world challenges.\nThe automated reasoning mechanism allows system designers to identify\nvulnerabilities that are applicable to a specific system design, explicitly\nspecify vulnerability mitigation options, declare selected controls, and thus\nsystematically manage vulnerability postures.", "AI": {"tldr": "本文提出了一种基于形式化基础的自动化推理机制，用于系统漏洞管理和安全控制设计，并将其集成到开源安全设计工具中，通过实际案例验证了其有效性。", "motivation": "当前漏洞管理方法缺乏对系统设计漏洞态势的系统性推理能力，无法有效支持安全控制设计。", "method": "开发了形式化基础的自动化推理机制，集成至开源安全设计工具，支持漏洞识别、缓解选项明确指定及控制措施选择。", "result": "该机制使设计师能识别特定系统设计的适用漏洞，系统化管理漏洞态势，并通过真实案例验证了实用性。", "conclusion": "提出的自动化推理机制为系统性管理漏洞态势和安全控制设计提供了有效解决方案，具有实际应用价值。"}}
{"id": "2507.06220", "categories": ["math.CO", "math.RT", "05E10 (Primary) 05E05 20C15 05A30 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.06220", "abs": "https://arxiv.org/abs/2507.06220", "authors": ["Álvaro Gutiérrez", "Michał Szwej"], "title": "A proof of the $q$-Foulkes conjecture for Gaussian coefficients when $a$ divides $c$", "comment": "14 pages, 1 figure. Comments welcome", "summary": "Foulkes' conjecture has several generalisations due to Doran,\nAbdesselam--Chipalkatti, Bergeron, and Troyka. For the special linear Lie\nalgebra $\\mathfrak{sl}_2(\\mathbb{C})$, these assert that given $a \\le c \\le d\n\\le b$ with $ab=cd$, the $\\mathfrak{sl}_2(\\mathbb{C})$-representation\n$\\mathrm{Sym}^a\\mathrm{Sym}^b\\mathbb{C}^2$ is a subrepresentation of\n$\\mathrm{Sym}^c\\mathrm{Sym}^d\\mathbb{C}^2$. We present a short proof in the\ncase where $a$ divides $c$ or $d$, which includes all prime values of $a$. This\nis the first proof in this family of conjectures valid for infinitely many\nvalues of $a$; previously only the cases $a=2$ and $a=3$ were known.", "AI": {"tldr": "本文针对Foulkes猜想的多个推广版本，在特殊线性李代数$\\mathfrak{sl}_2(\\mathbb{C})$下，证明了当$a$整除$c$或$d$时，表示$\\mathrm{Sym}^a\\mathrm{Sym}^b\\mathbb{C}^2$是$\\mathrm{Sym}^c\\mathrm{Sym}^d\\mathbb{C}^2$的子表示。这是该猜想家族中首个适用于无限多个$a$值的证明。", "motivation": "Foulkes猜想及其推广版本在表示理论中具有重要意义，但此前仅对$a=2$和$a=3$的情况有证明。本研究旨在扩展证明范围，覆盖无限多个$a$值的情况，特别是当$a$为素数时。", "method": "研究集中在特殊线性李代数$\\mathfrak{sl}_2(\\mathbb{C})$的表示理论上，通过假设$a$整除$c$或$d$，简化了证明过程。这种方法利用了对称幂表示的性质，避免了复杂的通用证明。", "result": "成功证明了在$a$整除$c$或$d$的条件下，$\\mathrm{Sym}^a\\mathrm{Sym}^b\\mathbb{C}^2$确实是$\\mathrm{Sym}^c\\mathrm{Sym}^d\\mathbb{C}^2$的子表示。这一结果首次覆盖了无限多个$a$值，包括所有素数$a$。", "conclusion": "本研究不仅验证了Foulkes猜想在特定条件下的正确性，还为更广泛的推广版本提供了新的证明思路，特别是在$a$为素数时的无限情况，为未来的研究奠定了基础。"}}
{"id": "2507.05613", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05613", "abs": "https://arxiv.org/abs/2507.05613", "authors": ["Lei Fan", "Fangxue Liu", "Cheng Chen"], "title": "Domain adaptation of large language models for geotechnical applications", "comment": null, "summary": "Recent developments in large language models (LLMs) are opening up new\nopportunities in geotechnical engineering and engineering geology. While\ngeneral-purpose LLMs possess broad capabilities, effective application in\ngeotechnics often requires domain-specific adaptation. Such tailored LLMs are\nincreasingly employed to streamline geotechnical workflows. This paper presents\nthe first survey of the adaptation and application of LLMs in geotechnical\nengineering. It outlines key methodologies for adaptation to geotechnical\ndomain, including prompt engineering, retrieval-augmented generation,\ndomain-adaptive pretraining, and fine-tuning. The survey examines the\nstate-of-the-art applications of geotechnical-adapted LLMs, including\ngeological interpretation, subsurface characterization, site planning, design\ncalculations, numerical modeling, safety and risk assessment, and educational\ntutoring. It also analyzes benefits and limitations of geotechnical-adapted\nLLMs, and identifies promising directions for future research in this\ninterdisciplinary discipline. The findings serve as a valuable resource for\npractitioners seeking to integrate LLMs into geotechnical practice, while also\nproviding a foundation to stimulate further investigation within the academic\ncommunity.", "AI": {"tldr": "本文首次综述了大型语言模型（LLMs）在岩土工程中的适应与应用，探讨了领域适配方法、应用场景及未来研究方向。", "motivation": "随着大型语言模型的发展，其在岩土工程领域的应用潜力显现，但需进行领域特定适配以实现有效应用。", "method": "综述了岩土工程领域适配LLMs的关键方法，包括提示工程、检索增强生成、领域自适应预训练和微调。", "result": "分析了适配后LLMs在岩土工程中的应用现状，包括地质解释、地下表征、场地规划、设计计算、数值模拟、安全风险评估及教育辅导等。", "conclusion": "总结了岩土工程适配LLMs的优势与局限，并指出了这一跨学科领域未来研究的潜在方向，为实践者和学术界提供了参考。"}}
{"id": "2507.05872", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05872", "abs": "https://arxiv.org/abs/2507.05872", "authors": ["Berkay Kemal Balioglu", "Alireza Khodaie", "Mehmet Emre Gursoy"], "title": "LDP$^3$: An Extensible and Multi-Threaded Toolkit for Local Differential Privacy Protocols and Post-Processing Methods", "comment": null, "summary": "Local differential privacy (LDP) has become a prominent notion for\nprivacy-preserving data collection. While numerous LDP protocols and\npost-processing (PP) methods have been developed, selecting an optimal\ncombination under different privacy budgets and datasets remains a challenge.\nMoreover, the lack of a comprehensive and extensible LDP benchmarking toolkit\nraises difficulties in evaluating new protocols and PP methods. To address\nthese concerns, this paper presents LDP$^3$ (pronounced LDP-Cube), an\nopen-source, extensible, and multi-threaded toolkit for LDP researchers and\npractitioners. LDP$^3$ contains implementations of several LDP protocols, PP\nmethods, and utility metrics in a modular and extensible design. Its modular\ndesign enables developers to conveniently integrate new protocols and PP\nmethods. Furthermore, its multi-threaded nature enables significant reductions\nin execution times via parallelization. Experimental evaluations demonstrate\nthat: (i) using LDP$^3$ to select a good protocol and post-processing method\nsubstantially improves utility compared to a bad or random choice, and (ii) the\nmulti-threaded design of LDP$^3$ brings substantial benefits in terms of\nefficiency.", "AI": {"tldr": "本文介绍了LDP$^3$，一个开源、可扩展且多线程的本地差分隐私（LDP）工具包，旨在帮助研究者和从业者选择最优的LDP协议和后处理方法，并通过并行化显著提升执行效率。", "motivation": "当前缺乏一个全面且可扩展的LDP基准测试工具包，导致在不同隐私预算和数据集下选择最优协议和后处理方法存在挑战。LDP$^3$的提出旨在解决这一问题。", "method": "LDP$^3$采用模块化和可扩展的设计，集成了多种LDP协议、后处理方法和效用度量，支持开发者便捷地集成新协议和方法，并通过多线程设计实现并行化以提升效率。", "result": "实验评估表明：(i) 使用LDP$^3$选择优质协议和后处理方法可显著提升效用；(ii) 多线程设计大幅提升了执行效率。", "conclusion": "LDP$^3$为LDP研究和实践提供了一个高效、灵活的工具，显著优化了协议选择和后处理的效果，并通过并行化提升了计算效率。"}}
{"id": "2507.05624", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05624", "abs": "https://arxiv.org/abs/2507.05624", "authors": ["Wei Zhang", "Juan Chen", "Yanbo J. Wang", "En Zhu", "Xuan Yang", "Yiduo Wang"], "title": "ADMC: Attention-based Diffusion Model for Missing Modalities Feature Completion", "comment": null, "summary": "Multimodal emotion and intent recognition is essential for automated\nhuman-computer interaction, It aims to analyze users' speech, text, and visual\ninformation to predict their emotions or intent. One of the significant\nchallenges is that missing modalities due to sensor malfunctions or incomplete\ndata. Traditional methods that attempt to reconstruct missing information often\nsuffer from over-coupling and imprecise generation processes, leading to\nsuboptimal outcomes. To address these issues, we introduce an Attention-based\nDiffusion model for Missing Modalities feature Completion (ADMC). Our framework\nindependently trains feature extraction networks for each modality, preserving\ntheir unique characteristics and avoiding over-coupling. The Attention-based\nDiffusion Network (ADN) generates missing modality features that closely align\nwith authentic multimodal distribution, enhancing performance across all\nmissing-modality scenarios. Moreover, ADN's cross-modal generation offers\nimproved recognition even in full-modality contexts. Our approach achieves\nstate-of-the-art results on the IEMOCAP and MIntRec benchmarks, demonstrating\nits effectiveness in both missing and complete modality scenarios.", "AI": {"tldr": "本文提出了一种基于注意力的扩散模型（ADMC），用于处理多模态情感和意图识别中的缺失模态问题，通过独立训练各模态特征提取网络和生成接近真实分布的特征，显著提升了识别性能。", "motivation": "多模态情感和意图识别在人机交互中至关重要，但传感器故障或数据不完整导致的模态缺失是主要挑战。传统方法因过度耦合和生成不精确而效果不佳。", "method": "ADMC框架独立训练各模态特征提取网络，避免过度耦合，并利用注意力扩散网络（ADN）生成与真实多模态分布一致的缺失特征，提升缺失和完整模态场景下的识别性能。", "result": "在IEMOCAP和MIntRec基准测试中，ADMC取得了最先进的结果，证明了其在缺失和完整模态场景下的有效性。", "conclusion": "ADMC通过独立特征提取和注意力扩散生成，有效解决了多模态识别中的缺失模态问题，为未来研究提供了新方向。"}}
{"id": "2507.05875", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05875", "abs": "https://arxiv.org/abs/2507.05875", "authors": ["Alireza Khodaie", "Berkay Kemal Balioglu", "Mehmet Emre Gursoy"], "title": "Post-Processing in Local Differential Privacy: An Extensive Evaluation and Benchmark Platform", "comment": null, "summary": "Local differential privacy (LDP) has recently gained prominence as a powerful\nparadigm for collecting and analyzing sensitive data from users' devices.\nHowever, the inherent perturbation added by LDP protocols reduces the utility\nof the collected data. To mitigate this issue, several post-processing (PP)\nmethods have been developed. Yet, the comparative performance of PP methods\nunder diverse settings remains underexplored. In this paper, we present an\nextensive benchmark comprising 6 popular LDP protocols, 7 PP methods, 4 utility\nmetrics, and 6 datasets to evaluate the behaviors and optimality of PP methods\nunder diverse conditions. Through extensive experiments, we show that while PP\ncan substantially improve utility when the privacy budget is small (i.e.,\nstrict privacy), its benefit diminishes as the privacy budget grows. Moreover,\nour findings reveal that the optimal PP method depends on multiple factors,\nincluding the choice of LDP protocol, privacy budget, data characteristics\n(such as distribution and domain size), and the specific utility metric. To\nadvance research in this area and assist practitioners in identifying the most\nsuitable PP method for their setting, we introduce LDP$^3$, an open-source\nbenchmark platform. LDP$^3$ contains all methods used in our experimental\nanalysis, and it is designed in a modular, extensible, and multi-threaded way\nfor future use and development.", "AI": {"tldr": "本文通过广泛实验评估了7种后处理方法在6种LDP协议下的性能，发现后处理在小隐私预算时显著提升数据效用，但随着预算增加效果减弱。研究还表明最优后处理方法取决于多种因素，并推出了开源平台LDP$^3$以促进研究与实践。", "motivation": "本地差分隐私(LDP)虽能保护用户数据隐私，但其引入的噪声会降低数据效用。现有后处理方法在不同场景下的性能对比研究不足，需系统性评估以指导实践选择。", "method": "研究构建了包含6种LDP协议、7种后处理方法、4种效用指标和6个数据集的综合基准，通过大量实验分析后处理方法在不同隐私预算、数据特征等条件下的表现。", "result": "实验表明：①后处理在严格隐私(小预算)时效用提升显著，但随预算增加效果递减；②最优后处理方法取决于LDP协议类型、隐私预算、数据分布特征及具体效用指标等多重因素。", "conclusion": "研究推出了模块化、可扩展的开源平台LDP$^3$，集成所有实验方法，为后续研究与实践提供灵活工具，强调需根据具体场景选择适配的后处理方法。"}}
{"id": "2507.05629", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05629", "abs": "https://arxiv.org/abs/2507.05629", "authors": ["Yuan An", "John Liu", "Niyam Acharya", "Ruhma Hashmi"], "title": "Enhancing Student Learning with LLM-Generated Retrieval Practice Questions: An Empirical Study in Data Science Courses", "comment": null, "summary": "Retrieval practice is a well-established pedagogical technique known to\nsignificantly enhance student learning and knowledge retention. However,\ngenerating high-quality retrieval practice questions is often time-consuming\nand labor intensive for instructors, especially in rapidly evolving technical\nsubjects. Large Language Models (LLMs) offer the potential to automate this\nprocess by generating questions in response to prompts, yet the effectiveness\nof LLM-generated retrieval practice on student learning remains to be\nestablished. In this study, we conducted an empirical study involving two\ncollege-level data science courses, with approximately 60 students. We compared\nlearning outcomes during one week in which students received LLM-generated\nmultiple-choice retrieval practice questions to those from a week in which no\nsuch questions were provided. Results indicate that students exposed to\nLLM-generated retrieval practice achieved significantly higher knowledge\nretention, with an average accuracy of 89%, compared to 73% in the week without\nsuch practice. These findings suggest that LLM-generated retrieval questions\ncan effectively support student learning and may provide a scalable solution\nfor integrating retrieval practice into real-time teaching. However, despite\nthese encouraging outcomes and the potential time-saving benefits, cautions\nmust be taken, as the quality of LLM-generated questions can vary. Instructors\nmust still manually verify and revise the generated questions before releasing\nthem to students.", "AI": {"tldr": "研究表明，由大型语言模型（LLM）生成的检索练习问题能显著提升学生知识保留率（89% vs 73%），为教师提供了一种可扩展的自动化方案，但需注意人工审核生成问题的质量。", "motivation": "检索练习虽能有效提升学习效果，但人工编制高质量问题耗时耗力，尤其在技术快速更新的学科中。LLM的自动化生成潜力有待验证其实际教学效果。", "method": "在两门大学数据科学课程（约60名学生）中开展实证研究，对比学生使用LLM生成多选题进行检索练习与无练习阶段的知识保留差异。", "result": "使用LLM生成问题的学生周平均准确率达89%，显著高于无练习阶段的73%，证实其有效提升知识保留。", "conclusion": "LLM生成的检索问题可作为实时教学的高效工具，但需教师人工核查问题质量以确保可靠性。"}}
{"id": "2507.06008", "categories": ["cs.CR", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2507.06008", "abs": "https://arxiv.org/abs/2507.06008", "authors": ["Jungeun Lim", "Stephan A. Fahrenkrog-Petersen", "Xixi Lu", "Jan Mendling", "Minseok Song"], "title": "The Impact of Event Data Partitioning on Privacy-aware Process Discovery", "comment": null, "summary": "Information systems support the execution of business processes. The event\nlogs of these executions generally contain sensitive information about\ncustomers, patients, and employees. The corresponding privacy challenges can be\naddressed by anonymizing the event logs while still retaining utility for\nprocess discovery. However, trading off utility and privacy is difficult: the\nhigher the complexity of event log, the higher the loss of utility by\nanonymization. In this work, we propose a pipeline that combines anonymization\nand event data partitioning, where event abstraction is utilized for\npartitioning. By leveraging event abstraction, event logs can be segmented into\nmultiple parts, allowing each sub-log to be anonymized separately. This\npipeline preserves privacy while mitigating the loss of utility. To validate\nour approach, we study the impact of event partitioning on two anonymization\ntechniques using three real-world event logs and two process discovery\ntechniques. Our results demonstrate that event partitioning can bring\nimprovements in process discovery utility for directly-follows-based\nanonymization techniques.", "AI": {"tldr": "提出结合匿名化与事件数据分区的管道，通过事件抽象分割日志，在保护隐私的同时减少效用损失。验证表明分区能提升基于直接跟随关系的匿名化技术在流程发现中的效用。", "motivation": "信息系统的事件日志包含敏感信息，匿名化会降低流程发现的效用。如何在复杂日志中平衡隐私保护与效用保留是核心挑战。", "method": "采用事件抽象对日志分区，生成多个子日志分别匿名化。评估两种匿名化技术在三组真实日志和两种流程发现方法上的表现。", "result": "实验证明事件分区能显著提升基于直接跟随关系的匿名化技术的流程发现效用，尤其在复杂日志场景。", "conclusion": "事件分区策略有效缓解了匿名化导致的效用损失，为隐私保护与流程分析需求的平衡提供了可行方案。"}}
{"id": "2507.05638", "categories": ["cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2507.05638", "abs": "https://arxiv.org/abs/2507.05638", "authors": ["Litian Zhang", "Xiaoming Zhang", "Bingyu Yan", "Ziyi Zhou", "Bo Zhang", "Zhenyu Guan", "Xi Zhang", "Chaozhuo Li"], "title": "LLMs are Introvert", "comment": null, "summary": "The exponential growth of social media and generative AI has transformed\ninformation dissemination, fostering connectivity but also accelerating the\nspread of misinformation. Understanding information propagation dynamics and\ndeveloping effective control strategies is essential to mitigate harmful\ncontent. Traditional models, such as SIR, provide basic insights but\ninadequately capture the complexities of online interactions. Advanced methods,\nincluding attention mechanisms and graph neural networks, enhance accuracy but\ntypically overlook user psychology and behavioral dynamics. Large language\nmodels (LLMs), with their human-like reasoning, offer new potential for\nsimulating psychological aspects of information spread. We introduce an\nLLM-based simulation environment capturing agents' evolving attitudes,\nemotions, and responses. Initial experiments, however, revealed significant\ngaps between LLM-generated behaviors and authentic human dynamics, especially\nin stance detection and psychological realism. A detailed evaluation through\nSocial Information Processing Theory identified major discrepancies in\ngoal-setting and feedback evaluation, stemming from the lack of emotional\nprocessing in standard LLM training. To address these issues, we propose the\nSocial Information Processing-based Chain of Thought (SIP-CoT) mechanism\nenhanced by emotion-guided memory. This method improves the interpretation of\nsocial cues, personalization of goals, and evaluation of feedback. Experimental\nresults confirm that SIP-CoT-enhanced LLM agents more effectively process\nsocial information, demonstrating behaviors, attitudes, and emotions closer to\nreal human interactions. In summary, this research highlights critical\nlimitations in current LLM-based propagation simulations and demonstrates how\nintegrating SIP-CoT and emotional memory significantly enhances the social\nintelligence and realism of LLM agents.", "AI": {"tldr": "研究提出基于大语言模型(LLM)的社交信息传播仿真环境，通过情感引导的记忆增强社交信息处理链(SIP-CoT)机制，显著提升了LLM代理的社会智能与行为真实性。", "motivation": "社交媒体与生成式AI的指数级增长加速了错误信息传播。传统传播模型(如SIR)难以捕捉在线交互复杂性，现有先进方法又忽视用户心理因素。LLM因其类人推理能力为模拟信息传播心理维度提供新可能。", "method": "构建LLM仿真环境模拟用户态度/情感演化，提出SIP-CoT机制（基于社交信息处理理论），通过情感引导记忆增强社交线索解读、目标个性化及反馈评估能力。", "result": "实验表明标准LLM在立场检测和心理真实性存在显著缺陷。SIP-CoT增强的LLM代理在社交信息处理、行为态度和情感表现上更接近真实人类交互。", "conclusion": "研究揭示了当前LLM传播仿真的关键局限，证实整合SIP-CoT与情感记忆能有效提升LLM代理的社会智能水平，为错误信息防控提供新思路。"}}
{"id": "2507.06039", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.06039", "abs": "https://arxiv.org/abs/2507.06039", "authors": ["Oleksii Oleksenko", "Flavien Solt", "Cédric Fournet", "Jana Hofmann", "Boris Köpf", "Stavros Volos"], "title": "Enter, Exit, Page Fault, Leak: Testing Isolation Boundaries for Microarchitectural Leaks", "comment": "Accepted at IEEE SP 2025; delayed due to embargo; to appear at IEEE\n  SP 2026", "summary": "CPUs provide isolation mechanisms like virtualization and privilege levels to\nprotect software. Yet these focus on architectural isolation while typically\noverlooking microarchitectural side channels, exemplified by Meltdown and\nForeshadow. Software must therefore supplement architectural defenses with\nad-hoc microarchitectural patches, which are constantly evolving as new attacks\nemerge and defenses are proposed. Such reactive approach makes ensuring\ncomplete isolation a daunting task, and leaves room for errors and oversights.\n  We address this problem by developing a tool that stress tests\nmicroarchitectural isolation between security domains such as virtual machines,\nkernel, and processes, with the goal of detecting flaws in the isolation\nboundaries. The tool extends model-based relational testing (MRT) methodology\nto enable detection of cross-domain information leakage. We design a new test\ncase generator and execution sandbox to handle multi-domain execution, new\nleakage models to encode expected leaks, and new analysis techniques to manage\nnondeterminism.\n  We use this tool to perform an in-depth testing campaign on six x86-64 CPUs\nfor leakage across different isolation boundaries. The testing campaign exposed\nfour new leaks and corroborated numerous known ones, with only two false\npositives throughout the entire campaign. These results show critical gaps in\ncurrent isolation mechanisms as well as validate a robust methodology for\ndetecting microarchitectural flaws. As such, this approach enables a shift from\nreactive patching to proactive security validation in processor design.", "AI": {"tldr": "该研究开发了一种工具，用于压力测试安全域间的微架构隔离，检测隔离边界中的缺陷，发现了四个新的漏洞，验证了检测微架构缺陷的稳健方法。", "motivation": "现有CPU隔离机制主要关注架构层面，忽视了微架构侧信道漏洞（如Meltdown和Foreshadow），导致软件需不断修补漏洞，难以确保完全隔离。", "method": "研究扩展了基于模型的关系测试（MRT）方法，设计了新的测试用例生成器、执行沙箱、泄漏模型和分析技术，以检测跨域信息泄漏。", "result": "在六款x86-64 CPU上进行的测试中，发现了四个新的泄漏漏洞，并验证了多个已知漏洞，整个测试过程中仅出现两个误报。", "conclusion": "该方法揭示了当前隔离机制的关键缺陷，为处理器设计从被动修补转向主动安全验证提供了可行路径。"}}
{"id": "2507.05651", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05651", "abs": "https://arxiv.org/abs/2507.05651", "authors": ["Tianxing Wu", "Lizhe Cao", "Shuang Wang", "Jiming Wang", "Shutong Zhu", "Yerong Wu", "Yuqing Feng"], "title": "City-Level Foreign Direct Investment Prediction with Tabular Learning on Judicial Data", "comment": "9 pages, accepted by IJCAI 2025", "summary": "To advance the United Nations Sustainable Development Goal on promoting\nsustained, inclusive, and sustainable economic growth, foreign direct\ninvestment (FDI) plays a crucial role in catalyzing economic expansion and\nfostering innovation. Precise city-level FDI prediction is quite important for\nlocal government and is commonly studied based on economic data (e.g., GDP).\nHowever, such economic data could be prone to manipulation, making predictions\nless reliable. To address this issue, we try to leverage large-scale judicial\ndata which reflects judicial performance influencing local investment security\nand returns, for city-level FDI prediction. Based on this, we first build an\nindex system for the evaluation of judicial performance over twelve million\npublicly available adjudication documents according to which a tabular dataset\nis reformulated. We then propose a new Tabular Learning method on Judicial Data\n(TLJD) for city-level FDI prediction. TLJD integrates row data and column data\nin our built tabular dataset for judicial performance indicator encoding, and\nutilizes a mixture of experts model to adjust the weights of different\nindicators considering regional variations. To validate the effectiveness of\nTLJD, we design cross-city and cross-time tasks for city-level FDI predictions.\nExtensive experiments on both tasks demonstrate the superiority of TLJD (reach\nto at least 0.92 R2) over the other ten state-of-the-art baselines in different\nevaluation metrics.", "AI": {"tldr": "本文提出了一种基于司法数据的城市级外国直接投资（FDI）预测方法TLJD，通过整合司法绩效指标并考虑区域差异，显著提升了预测准确性。", "motivation": "传统基于经济数据（如GDP）的FDI预测易受数据操纵影响，可靠性不足。司法数据能反映影响投资安全与回报的司法绩效，为预测提供了新视角。", "method": "首先基于1200万份公开裁判文书构建司法绩效评估指标体系，并重构表格数据集；随后提出TLJD方法，通过混合专家模型整合行列数据并动态调整区域指标权重。", "result": "跨城市和跨时间任务的实验表明，TLJD在各项指标上均优于10种前沿基线方法（R2达0.92以上）。", "conclusion": "司法数据可有效替代经济数据用于FDI预测，TLJD通过多维度司法指标编码和区域自适应加权机制，为地方政府决策提供了更可靠的预测工具。"}}
{"id": "2507.06043", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06043", "abs": "https://arxiv.org/abs/2507.06043", "authors": ["Xiaohu Li", "Yunfeng Ning", "Zepeng Bao", "Mayi Xu", "Jianhao Chen", "Tieyun Qian"], "title": "CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations", "comment": null, "summary": "Security alignment enables the Large Language Model (LLM) to gain the\nprotection against malicious queries, but various jailbreak attack methods\nreveal the vulnerability of this security mechanism. Previous studies have\nisolated LLM jailbreak attacks and defenses. We analyze the security protection\nmechanism of the LLM, and propose a framework that combines attack and defense.\nOur method is based on the linearly separable property of LLM intermediate\nlayer embedding, as well as the essence of jailbreak attack, which aims to\nembed harmful problems and transfer them to the safe area. We utilize\ngenerative adversarial network (GAN) to learn the security judgment boundary\ninside the LLM to achieve efficient jailbreak attack and defense. The\nexperimental results indicate that our method achieves an average jailbreak\nsuccess rate of 88.85\\% across three popular LLMs, while the defense success\nrate on the state-of-the-art jailbreak dataset reaches an average of 84.17\\%.\nThis not only validates the effectiveness of our approach but also sheds light\non the internal security mechanisms of LLMs, offering new insights for\nenhancing model security The code and data are available at\nhttps://github.com/NLPGM/CAVGAN.", "AI": {"tldr": "本文提出了一种结合攻击与防御的框架CAVGAN，通过分析LLM中间层嵌入的线性可分特性及越狱攻击本质，利用GAN学习LLM内部安全判断边界，实现高效越狱攻击与防御。实验表明该方法在三种主流LLM上平均越狱成功率达88.85\\%，防御成功率达84.17\\%。", "motivation": "现有研究孤立看待LLM越狱攻击与防御，而安全对齐机制仍存在漏洞。为深入理解LLM安全机制并提升防护能力，需开发攻防结合的统一框架。", "method": "基于LLM中间层嵌入的线性可分特性，利用GAN学习模型内部安全判断边界。通过将有害问题嵌入并转移至安全区域，实现攻防协同优化。", "result": "在三种主流LLM上达到平均88.85\\%的越狱成功率，在最新越狱数据集上实现84.17\\%的平均防御成功率，代码与数据已开源。", "conclusion": "该方法不仅验证了攻防结合框架的有效性，揭示了LLM内部安全机制，还为增强模型安全性提供了新思路。开源地址：https://github.com/NLPGM/CAVGAN。"}}
{"id": "2507.05716", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05716", "abs": "https://arxiv.org/abs/2507.05716", "authors": ["Dipayan Sengupta", "Saumya Panda"], "title": "Divergent Realities: A Comparative Analysis of Human Expert vs. Artificial Intelligence Based Generation and Evaluation of Treatment Plans in Dermatology", "comment": "13 pages, 3 tables", "summary": "Background: Evaluating AI-generated treatment plans is a key challenge as AI\nexpands beyond diagnostics, especially with new reasoning models. This study\ncompares plans from human experts and two AI models (a generalist and a\nreasoner), assessed by both human peers and a superior AI judge.\n  Methods: Ten dermatologists, a generalist AI (GPT-4o), and a reasoning AI\n(o3) generated treatment plans for five complex dermatology cases. The\nanonymized, normalized plans were scored in two phases: 1) by the ten human\nexperts, and 2) by a superior AI judge (Gemini 2.5 Pro) using an identical\nrubric.\n  Results: A profound 'evaluator effect' was observed. Human experts scored\npeer-generated plans significantly higher than AI plans (mean 7.62 vs. 7.16;\np=0.0313), ranking GPT-4o 6th (mean 7.38) and the reasoning model, o3, 11th\n(mean 6.97). Conversely, the AI judge produced a complete inversion, scoring AI\nplans significantly higher than human plans (mean 7.75 vs. 6.79; p=0.0313). It\nranked o3 1st (mean 8.20) and GPT-4o 2nd, placing all human experts lower.\n  Conclusions: The perceived quality of a clinical plan is fundamentally\ndependent on the evaluator's nature. An advanced reasoning AI, ranked poorly by\nhuman experts, was judged as superior by a sophisticated AI, revealing a deep\ngap between experience-based clinical heuristics and data-driven algorithmic\nlogic. This paradox presents a critical challenge for AI integration,\nsuggesting the future requires synergistic, explainable human-AI systems that\nbridge this reasoning gap to augment clinical care.", "AI": {"tldr": "研究发现AI生成的治疗方案评估存在显著'评估者效应'：人类专家更倾向同行方案，而高级AI法官则更青睐AI方案，揭示临床经验与算法逻辑间的深层差异。", "motivation": "随着AI超越诊断领域进入治疗规划，评估AI生成治疗方案的质量成为关键挑战，尤其需要比较人类专家与不同AI模型的输出差异。", "method": "10位皮肤科医生、通用AI（GPT-4o）和推理AI（o3）为5个复杂病例制定治疗方案，先由人类专家匿名评分，再由高级AI法官（Gemini 2.5 Pro）使用相同标准复评。", "result": "人类专家评分显示：同行方案显著优于AI方案（均值7.62 vs 7.16），GPT-4o排名第6，o3垫底；而AI法官结果完全相反：AI方案显著优于人类方案（均值7.75 vs 6.79），o3排名第一。", "conclusion": "临床方案的质量评估本质上取决于评估者属性，人类经验启发与算法逻辑存在根本性差异，未来需构建可解释的人机协同系统来弥合这一认知鸿沟。"}}
{"id": "2507.06064", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.06064", "abs": "https://arxiv.org/abs/2507.06064", "authors": ["Oleksandr Kurbatov", "Kyrylo Baybula", "Yaroslava Chopa", "Sergey Kozlov", "Oleg Komendant", "Illia Dovgopoly", "Dmitrii Kurbatov", "Zakhar Naumets", "Yulia Artikulova", "Pavel Kravchenko", "Volodymyr Dubinin", "Lasha Antadze", "Yaroslav Panasenko", "Mykhailo Velykodnyi"], "title": "Wrapless: The trustless lending protocol on top of Bitcoin", "comment": null, "summary": "This paper presents Wrapless -- a lending protocol that enables the\ncollateralization of bitcoins without requiring a trusted wrapping mechanism.\nThe protocol facilitates a \"loan channel\" on the Bitcoin blockchain, allowing\nbitcoins to be locked as collateral for loans issued on any blockchain that\nsupports Turing-complete smart contracts. The protocol is designed in a way\nthat makes it economically irrational for each involved party to manipulate the\nloan rules. There is still a significant research area to bring the protocol\ncloser to traditional AMM financial instruments.", "AI": {"tldr": "Error processing this paper.", "motivation": "Error processing this paper.", "method": "Error processing this paper.", "result": "Error processing this paper.", "conclusion": "Error processing this paper."}}
{"id": "2507.05755", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05755", "abs": "https://arxiv.org/abs/2507.05755", "authors": ["Lukas Kuhn", "Florian Buettner"], "title": "An autonomous agent for auditing and improving the reliability of clinical AI models", "comment": null, "summary": "The deployment of AI models in clinical practice faces a critical challenge:\nmodels achieving expert-level performance on benchmarks can fail\ncatastrophically when confronted with real-world variations in medical imaging.\nMinor shifts in scanner hardware, lighting or demographics can erode accuracy,\nbut currently reliability auditing to identify such catastrophic failure cases\nbefore deployment is a bespoke and time-consuming process. Practitioners lack\naccessible and interpretable tools to expose and repair hidden failure modes.\nHere we introduce ModelAuditor, a self-reflective agent that converses with\nusers, selects task-specific metrics, and simulates context-dependent,\nclinically relevant distribution shifts. ModelAuditor then generates\ninterpretable reports explaining how much performance likely degrades during\ndeployment, discussing specific likely failure modes and identifying root\ncauses and mitigation strategies. Our comprehensive evaluation across three\nreal-world clinical scenarios - inter-institutional variation in\nhistopathology, demographic shifts in dermatology, and equipment heterogeneity\nin chest radiography - demonstrates that ModelAuditor is able correctly\nidentify context-specific failure modes of state-of-the-art models such as the\nestablished SIIM-ISIC melanoma classifier. Its targeted recommendations recover\n15-25% of performance lost under real-world distribution shift, substantially\noutperforming both baseline models and state-of-the-art augmentation methods.\nThese improvements are achieved through a multi-agent architecture and execute\non consumer hardware in under 10 minutes, costing less than US$0.50 per audit.", "AI": {"tldr": "本文提出ModelAuditor工具，通过自省代理模拟临床相关分布偏移，识别AI模型在医疗影像中的潜在故障模式，并提供可解释报告与改进策略，显著提升模型在真实场景下的性能。", "motivation": "AI模型在医疗影像基准测试中表现优异，但在实际部署中常因扫描设备、光照或人群差异导致性能骤降。现有可靠性审计方法效率低下，缺乏可解释工具来暴露和修复隐藏故障。", "method": "ModelAuditor采用多智能体架构：1) 与用户对话选择任务指标；2) 模拟临床相关分布偏移；3) 生成包含性能退化分析、故障根因及缓解策略的可解释报告。支持在消费级硬件上10分钟内完成审计。", "result": "在病理学跨机构差异、皮肤病学人口统计偏移、胸片设备异构性三个场景中，ModelAuditor成功识别SIIM-ISIC黑色素瘤分类器等先进模型的故障模式，针对性建议使性能恢复15-25%，优于基线模型和最先进数据增强方法。单次审计成本低于0.5美元。", "conclusion": "ModelAuditor为临床AI部署提供了高效、低成本的可靠性审计方案，其可解释性报告和精准改进策略能有效弥合基准测试与实际应用间的性能差距。"}}
{"id": "2507.06092", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06092", "abs": "https://arxiv.org/abs/2507.06092", "authors": ["Shravya Kanchi", "Neal Mangaokar", "Aravind Cheruvu", "Sifat Muhammad Abdullah", "Shirin Nilizadeh", "Atul Prakash", "Bimal Viswanath"], "title": "Taming Data Challenges in ML-based Security Tasks: Lessons from Integrating Generative AI", "comment": null, "summary": "Machine learning-based supervised classifiers are widely used for security\ntasks, and their improvement has been largely focused on algorithmic\nadvancements. We argue that data challenges that negatively impact the\nperformance of these classifiers have received limited attention. We address\nthe following research question: Can developments in Generative AI (GenAI)\naddress these data challenges and improve classifier performance? We propose\naugmenting training datasets with synthetic data generated using GenAI\ntechniques to improve classifier generalization. We evaluate this approach\nacross 7 diverse security tasks using 6 state-of-the-art GenAI methods and\nintroduce a novel GenAI scheme called Nimai that enables highly controlled data\nsynthesis. We find that GenAI techniques can significantly improve the\nperformance of security classifiers, achieving improvements of up to 32.6% even\nin severely data-constrained settings (only ~180 training samples).\nFurthermore, we demonstrate that GenAI can facilitate rapid adaptation to\nconcept drift post-deployment, requiring minimal labeling in the adjustment\nprocess. Despite successes, our study finds that some GenAI schemes struggle to\ninitialize (train and produce data) on certain security tasks. We also identify\ncharacteristics of specific tasks, such as noisy labels, overlapping class\ndistributions, and sparse feature vectors, which hinder performance boost using\nGenAI. We believe that our study will drive the development of future GenAI\ntools designed for security tasks.", "AI": {"tldr": "研究探讨了利用生成式AI（GenAI）生成合成数据以增强安全分类器性能的方法，提出新方案Nimai并在7项任务中验证，最高提升32.6%，同时揭示了GenAI在特定任务中的局限性。", "motivation": "现有安全分类器的改进多聚焦算法，而数据问题（如样本不足）未受重视。研究旨在验证GenAI能否通过合成数据解决此类问题。", "method": "采用6种前沿GenAI方法生成合成数据扩充训练集，并提出可控数据合成方案Nimai，在7种安全任务中测试性能提升效果。", "result": "GenAI显著提升分类器性能（最高32.6%），支持概念漂移快速适应；但部分任务因标签噪声、类别重叠等问题难以受益。", "conclusion": "研究证实GenAI对安全任务的有效性，同时指出其局限性，为未来专用工具开发提供方向。"}}
{"id": "2507.05765", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05765", "abs": "https://arxiv.org/abs/2507.05765", "authors": ["Bruno Jammes", "Edgar Hernando Sepúlveda-Oviedo", "Corinne Alonso"], "title": "Real-time monitoring of the SoH of lithium-ion batteries", "comment": "in French language, Symposium de G{\\'e}nie {\\'E}lectrique SGE 2025,\n  Jul 2025, Toulouse, France", "summary": "Real-time monitoring of the state of health (SoH) of batteries remains a\nmajor challenge, particularly in microgrids where operational constraints limit\nthe use of traditional methods. As part of the 4BLife project, we propose an\ninnovative method based on the analysis of a discharge pulse at the end of the\ncharge phase. The parameters of the equivalent electrical model describing the\nvoltage evolution across the battery terminals during this current pulse are\nthen used to estimate the SoH. Based on the experimental data acquired so far,\nthe initial results demonstrate the relevance of the proposed approach. After\ntraining using the parameters of two batteries with a capacity degradation of\naround 85%, we successfully predicted the degradation of two other batteries,\ncycled down to approximately 90% SoH, with a mean absolute error of around 1%\nin the worst case, and an explainability score of the estimator close to 0.9.\nIf these performances are confirmed, this method can be easily integrated into\nbattery management systems (BMS) and paves the way for optimized battery\nmanagement under continuous operation.", "AI": {"tldr": "论文提出了一种基于充电末期放电脉冲分析的电池健康状态(SoH)实时监测创新方法，在微电网等受限环境中表现出高精度（平均绝对误差约1%）和可解释性（得分接近0.9）。", "motivation": "微电网等场景下传统电池健康监测方法受限，亟需开发新型实时SoH监测技术以满足持续运行需求。", "method": "通过分析充电末期的放电脉冲，利用等效电路模型参数估计SoH，并使用两节容量衰减85%的电池数据进行训练。", "result": "该方法对另外两节衰减至90% SoH的电池预测时，最坏情况下平均绝对误差约1%，模型可解释性得分达0.9。", "conclusion": "若性能得到进一步验证，该方法可集成至电池管理系统(BMS)，为持续运行下的优化管理提供新途径。"}}
{"id": "2507.06112", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.06112", "abs": "https://arxiv.org/abs/2507.06112", "authors": ["Antoine Geimer", "Clementine Maurice"], "title": "Fun with flags: How Compilers Break and Fix Constant-Time Code", "comment": "11 pages", "summary": "Developers rely on constant-time programming to prevent timing side-channel\nattacks. But these efforts can be undone by compilers, whose optimizations may\nsilently reintroduce leaks. While recent works have measured the extent of such\nleakage, they leave developers without actionable insights: which optimization\npasses are responsible, and how to disable them without modifying the compiler\nremains unclear.\n  In this paper, we conduct a qualitative analysis of how compiler\noptimizations break constant-time code. We construct a dataset of\ncompiler-introduced constant-time violations and analyze the internals of two\nwidely used compilers, GCC and LLVM, to identify the specific optimization\npasses responsible. Our key insight is that a small set of passes are at the\nroot of most leaks. To the best of our knowledge, we are also the first to\ncharacterize how the interactions between these passes contribute to leakage.\nBased on this analysis, we propose an original and practical mitigation that\nrequires no source code modification or custom compiler: disabling selected\noptimization passes via compiler flags. We show that this approach\nsignificantly reduces leakage with minimal performance overhead, offering an\nimmediately deployable defense for developers.", "AI": {"tldr": "该论文通过定性分析揭示了编译器优化如何破坏常数时间编程的安全性，识别出GCC和LLVM中导致泄漏的关键优化阶段，并提出了一种无需修改源代码或定制编译器的实用缓解方案。", "motivation": "开发者依赖常数时间编程来防止时序侧信道攻击，但编译器优化可能无声地重新引入泄漏。现有研究缺乏对具体优化阶段的责任定位及非侵入式解决方案的指导。", "method": "构建编译器引入的常数时间违规数据集，分析GCC和LLVM内部机制以定位关键优化阶段，首次刻画优化阶段间交互对泄漏的影响，并提出通过编译器标志选择性禁用优化阶段的方案。", "result": "研究表明少数优化阶段是大多数泄漏的根源，禁用这些阶段的方案能以极小性能开销显著减少泄漏，为开发者提供即时可部署的防御手段。", "conclusion": "该工作不仅揭示了编译器优化破坏常数时间性的机制，还提供了无需修改工具链的轻量级解决方案，填补了从理论到实践的转化空白。"}}
{"id": "2507.05791", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05791", "abs": "https://arxiv.org/abs/2507.05791", "authors": ["Yan Yang", "Dongxu Li", "Yutong Dai", "Yuhao Yang", "Ziyang Luo", "Zirui Zhao", "Zhiyuan Hu", "Junzhe Huang", "Amrita Saha", "Zeyuan Chen", "Ran Xu", "Liyuan Pan", "Caiming Xiong", "Junnan Li"], "title": "GTA1: GUI Test-time Scaling Agent", "comment": null, "summary": "Graphical user interface (GUI) agents autonomously operate across platforms\n(e.g., Linux) to complete tasks by interacting with visual elements.\nSpecifically, a user instruction is decomposed into a sequence of action\nproposals, each corresponding to an interaction with the GUI. After each\naction, the agent observes the updated GUI environment to plan the next step.\nHowever, two main challenges arise: i) resolving ambiguity in task planning\n(i.e., the action proposal sequence), where selecting an appropriate plan is\nnon-trivial, as many valid ones may exist; ii) accurately grounding actions in\ncomplex and high-resolution interfaces, i.e., precisely interacting with visual\ntargets.\n  This paper investigates the two aforementioned challenges with our GUI\nTest-time Scaling Agent, namely GTA1. First, to select the most appropriate\naction proposal, we introduce a test-time scaling method. At each step, we\nsample multiple candidate action proposals and leverage a judge model to\nevaluate and select the most suitable one. It trades off computation for better\ndecision quality by concurrent sampling, shortening task execution steps, and\nimproving overall performance. Second, we propose a model that achieves\nimproved accuracy when grounding the selected action proposal to its\ncorresponding visual elements. Our key insight is that reinforcement learning\n(RL) facilitates visual grounding through inherent objective alignments,\nrewarding successful clicks on interface elements.\n  Experimentally, our method establishes state-of-the-art performance across\ndiverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7%\naccuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When\npaired with a planner applying our test-time scaling strategy, it exhibits\nstate-of-the-art agentic performance (e.g., 45.2% task success rate on\nOSWorld). We open-source our code and models here.", "AI": {"tldr": "本文提出GTA1智能体，通过测试时扩展方法和强化学习解决GUI任务中的动作序列规划和视觉元素定位难题，在多个基准测试中达到最先进性能。", "motivation": "GUI智能体在跨平台执行任务时面临两大挑战：任务规划中的动作序列歧义性，以及复杂高分辨率界面中的视觉元素精确定位。", "method": "1) 测试时扩展方法：并行采样候选动作序列，通过评判模型选择最优方案\\n2) 强化学习模型：利用目标对齐机制提升视觉元素定位准确率，奖励成功点击行为", "result": "GTA1-7B在Screenspot-Pro(50.1%)、Screenspot-V2(92.4%)和OSWorld-G(67.7%)等基准测试中表现优异，结合规划器后任务成功率提升至45.2%（OSWorld）", "conclusion": "该研究通过计算资源换决策质量的策略和RL驱动的视觉定位方法，显著提升了GUI智能体的操作性能，相关代码和模型已开源"}}
{"id": "2507.05816", "categories": ["cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05816", "abs": "https://arxiv.org/abs/2507.05816", "authors": ["Shuai Zhao", "Yulin Zhang", "Luwei Xiao", "Xinyi Wu", "Yanhao Jia", "Zhongliang Guo", "Xiaobao Wu", "Cong-Duy Nguyen", "Guoming Zhang", "Anh Tuan Luu"], "title": "Affective-ROPTester: Capability and Bias Analysis of LLMs in Predicting Retinopathy of Prematurity", "comment": null, "summary": "Despite the remarkable progress of large language models (LLMs) across\nvarious domains, their capacity to predict retinopathy of prematurity (ROP)\nrisk remains largely unexplored. To address this gap, we introduce a novel\nChinese benchmark dataset, termed CROP, comprising 993 admission records\nannotated with low, medium, and high-risk labels. To systematically examine the\npredictive capabilities and affective biases of LLMs in ROP risk\nstratification, we propose Affective-ROPTester, an automated evaluation\nframework incorporating three prompting strategies: Instruction-based,\nChain-of-Thought (CoT), and In-Context Learning (ICL). The Instruction scheme\nassesses LLMs' intrinsic knowledge and associated biases, whereas the CoT and\nICL schemes leverage external medical knowledge to enhance predictive accuracy.\nCrucially, we integrate emotional elements at the prompt level to investigate\nhow different affective framings influence the model's ability to predict ROP\nand its bias patterns. Empirical results derived from the CROP dataset yield\ntwo principal observations. First, LLMs demonstrate limited efficacy in ROP\nrisk prediction when operating solely on intrinsic knowledge, yet exhibit\nmarked performance gains when augmented with structured external inputs.\nSecond, affective biases are evident in the model outputs, with a consistent\ninclination toward overestimating medium- and high-risk cases. Third, compared\nto negative emotions, positive emotional framing contributes to mitigating\npredictive bias in model outputs. These findings highlight the critical role of\naffect-sensitive prompt engineering in enhancing diagnostic reliability and\nemphasize the utility of Affective-ROPTester as a framework for evaluating and\nmitigating affective bias in clinical language modeling systems.", "AI": {"tldr": "本文通过构建中文ROP风险预测数据集CROP，提出Affective-ROPTester框架，系统评估大语言模型（LLMs）在ROP风险分层中的预测能力与情感偏差，发现外部知识增强可提升性能，积极情感提示能减少预测偏差。", "motivation": "尽管大语言模型（LLMs）在多领域取得进展，但其在早产儿视网膜病变（ROP）风险预测中的潜力尚未充分探索。本研究旨在填补这一空白，并探究情感因素对模型预测的影响。", "method": "提出Affective-ROPTester评估框架，包含指令提示、思维链（CoT）和上下文学习（ICL）三种策略，并在提示层面融入情感元素。使用包含993条标注记录的CROP中文数据集进行实验。", "result": "1. LLMs仅依赖内部知识时ROP预测效果有限，但结合外部知识后性能显著提升；2. 模型输出存在情感偏差，倾向于高估中高风险病例；3. 积极情感提示相比消极提示更能减少预测偏差。", "conclusion": "研究强调情感敏感提示工程对提升诊断可靠性的重要性，Affective-ROPTester可作为临床语言模型情感偏差评估与缓解的有效框架。"}}
{"id": "2507.05868", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05868", "abs": "https://arxiv.org/abs/2507.05868", "authors": ["Aloïs Rautureau", "Éric Piette"], "title": "CogniPlay: a work-in-progress Human-like model for General Game Playing", "comment": "5 pages, 1 figure", "summary": "While AI systems have equaled or surpassed human performance in a wide\nvariety of games such as Chess, Go, or Dota 2, describing these systems as\ntruly \"human-like\" remains far-fetched. Despite their success, they fail to\nreplicate the pattern-based, intuitive decision-making processes observed in\nhuman cognition. This paper presents an overview of findings from cognitive\npsychology and previous efforts to model human-like behavior in artificial\nagents, discusses their applicability to General Game Playing (GGP) and\nintroduces our work-in-progress model based on these observations: CogniPlay.", "AI": {"tldr": "Error processing this paper.", "motivation": "Error processing this paper.", "method": "Error processing this paper.", "result": "Error processing this paper.", "conclusion": "Error processing this paper."}}
{"id": "2507.05886", "categories": ["cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.05886", "abs": "https://arxiv.org/abs/2507.05886", "authors": ["Aaron Bembenek"], "title": "Current Practices for Building LLM-Powered Reasoning Tools Are Ad Hoc -- and We Can Do Better", "comment": "6 pages, 4 figures", "summary": "There is growing excitement about building software verifiers, synthesizers,\nand other Automated Reasoning (AR) tools by combining traditional symbolic\nalgorithms and Large Language Models (LLMs). Unfortunately, the current\npractice for constructing such neurosymbolic AR systems is an ad hoc\nprogramming model that does not have the strong guarantees of traditional\nsymbolic algorithms, nor a deep enough synchronization of neural networks and\nsymbolic reasoning to unlock the full potential of LLM-powered reasoning. I\npropose Neurosymbolic Transition Systems as a principled computational model\nthat can underlie infrastructure for building neurosymbolic AR tools. In this\nmodel, symbolic state is paired with intuition, and state transitions operate\nover symbols and intuition in parallel. I argue why this new paradigm can scale\nlogical reasoning beyond current capabilities while retaining the strong\nguarantees of symbolic algorithms, and I sketch out how the computational model\nI propose can be reified in a logic programming language.", "AI": {"tldr": "本文提出了一种名为'神经符号转换系统'的计算模型，旨在为结合传统符号算法与大型语言模型（LLMs）的自动推理工具提供理论基础，以克服当前神经符号系统缺乏严格保证和深度协同的问题。", "motivation": "当前构建神经符号自动推理系统的方法缺乏传统符号算法的严格保证，且未能充分整合神经网络与符号推理，限制了LLM在推理中的潜力。", "method": "作者提出了'神经符号转换系统'模型，其中符号状态与直觉配对，状态转换并行操作符号与直觉，并探讨了如何将该模型具体化为逻辑编程语言。", "result": "该新范式有望在保持符号算法严格保证的同时，将逻辑推理能力扩展到当前技术无法达到的水平。", "conclusion": "神经符号转换系统为构建下一代神经符号自动推理工具提供了理论基础，可能实现符号算法保证与LLM推理潜力的深度结合。"}}
{"id": "2507.05891", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05891", "abs": "https://arxiv.org/abs/2507.05891", "authors": ["Robert Leppich", "Michael Stenger", "André Bauer", "Samuel Kounev"], "title": "Decomposing the Time Series Forecasting Pipeline: A Modular Approach for Time Series Representation, Information Extraction, and Projection", "comment": null, "summary": "With the advent of Transformers, time series forecasting has seen significant\nadvances, yet it remains challenging due to the need for effective sequence\nrepresentation, memory construction, and accurate target projection. Time\nseries forecasting remains a challenging task, demanding effective sequence\nrepresentation, meaningful information extraction, and precise future\nprojection. Each dataset and forecasting configuration constitutes a distinct\ntask, each posing unique challenges the model must overcome to produce accurate\npredictions. To systematically address these task-specific difficulties, this\nwork decomposes the time series forecasting pipeline into three core stages:\ninput sequence representation, information extraction and memory construction,\nand final target projection. Within each stage, we investigate a range of\narchitectural configurations to assess the effectiveness of various modules,\nsuch as convolutional layers for feature extraction and self-attention\nmechanisms for information extraction, across diverse forecasting tasks,\nincluding evaluations on seven benchmark datasets. Our models achieve\nstate-of-the-art forecasting accuracy while greatly enhancing computational\nefficiency, with reduced training and inference times and a lower parameter\ncount. The source code is available at\nhttps://github.com/RobertLeppich/REP-Net.", "AI": {"tldr": "本文提出了一种分解时间序列预测流程的三阶段方法（输入序列表示、信息提取与记忆构建、目标投影），通过评估不同架构配置在七个基准数据集上的表现，实现了最优预测精度与计算效率的提升。", "motivation": "尽管Transformer在时间序列预测中取得进展，但有效序列表示、记忆构建和精准目标投影仍是挑战。不同数据集和预测配置构成独特任务，需针对性解决方案。", "method": "将预测流程分解为三阶段：1)输入序列表示；2)信息提取与记忆构建（采用卷积层和自注意力机制）；3)目标投影。系统评估各阶段模块组合在多样化任务中的效果。", "result": "模型在七个基准数据集上达到最优预测精度，同时显著提升计算效率（减少训练/推理时间、降低参数量）。代码已开源。", "conclusion": "通过任务导向的流程分解与模块化设计，该方法在精度与效率上超越现有技术，为时间序列预测提供了可扩展的解决方案框架。"}}
{"id": "2507.05894", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05894", "abs": "https://arxiv.org/abs/2507.05894", "authors": ["Fathinah Izzati", "Xinyue Li", "Yuxuan Wu", "Gus Xia"], "title": "MusiScene: Leveraging MU-LLaMA for Scene Imagination and Enhanced Video Background Music Generation", "comment": null, "summary": "Humans can imagine various atmospheres and settings when listening to music,\nenvisioning movie scenes that complement each piece. For example, slow,\nmelancholic music might evoke scenes of heartbreak, while upbeat melodies\nsuggest celebration. This paper explores whether a Music Language Model, e.g.\nMU-LLaMA, can perform a similar task, called Music Scene Imagination (MSI),\nwhich requires cross-modal information from video and music to train. To\nimprove upon existing music captioning models which focusing solely on musical\nelements, we introduce MusiScene, a music captioning model designed to imagine\nscenes that complement each music. In this paper, (1) we construct a\nlarge-scale video-audio caption dataset with 3,371 pairs, (2) we finetune Music\nUnderstanding LLaMA for the MSI task to create MusiScene, and (3) we conduct\ncomprehensive evaluations and prove that our MusiScene is more capable of\ngenerating contextually relevant captions compared to MU-LLaMA. We leverage the\ngenerated MSI captions to enhance Video Background Music Generation (VBMG) from\ntext.", "AI": {"tldr": "本文提出MusiScene模型，通过音乐场景想象(MSI)任务生成与音乐匹配的场景描述，并构建大规模视频-音频字幕数据集，显著提升音乐字幕生成质量。", "motivation": "人类能从音乐中联想对应场景，但现有音乐字幕模型仅关注音乐元素。本文探索音乐语言模型是否具备跨模态场景想象能力，以增强音乐与视频的关联性。", "method": "1) 构建3,371对视频-音频字幕数据集 2) 基于MU-LLaMA微调出MusiScene模型 3) 利用MSI生成结果优化视频背景音乐生成(VBMG)任务", "result": "实验证明MusiScene生成的场景描述比MU-LLaMA更具上下文相关性，且MSI字幕能有效提升文本到视频背景音乐的生成质量。", "conclusion": "MusiScene首次实现音乐驱动的场景想象，为跨模态音乐理解开辟新方向，其生成的场景描述可显著辅助视频配乐生成任务。"}}
{"id": "2507.05934", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05934", "abs": "https://arxiv.org/abs/2507.05934", "authors": ["Baojiao Xiong", "Boheng Chen", "Chengzhi Wang", "Daxiong Luo", "Dongsheng Xu", "Dongyang Liu", "Fan Yang", "Fangyuan Li", "Fei Teng", "Feng Wang", "Fukang Qin", "Fuquan Peng", "Guanxin Tan", "Guozhi Wang", "Haibo Yu", "Haohao Gao", "Heng Liu", "Hongbo Yang", "Hongjian Zou", "Houzheng Shen", "Hu Meng", "Huan Li", "Hui Tan", "Jiali Chen", "Jianzhao Chen", "Jinliang Zhu", "Kai Wang", "Lei Wu", "Liangbing Liu", "Liuyang Bian", "Liyan He", "Long Liu", "Peiwen Li", "Penggang Shi", "Qi Ding", "Rui Hu", "Shuai Cao", "Shuai Ren", "Shuang Peng", "Teng Xie", "Weiji Chen", "Weilin Xiang", "Weixin Wu", "Xi Yin", "Xiaoxin Chen", "Xu Chen", "Yafei Wen", "Yan Hu", "Yanzhou Yang", "Yina Xie", "Yinghao Chen", "Yixuan Liao", "Yu Geng", "Yuanjiang Ouyang", "Yuanzhuo Yang", "Yuehua He", "Yushuai Peng", "Zhaoxiong Wang", "Zheng Wang", "Zhibo Zhou", "Ziyang Wu"], "title": "BlueLM-2.5-3B Technical Report", "comment": null, "summary": "We present BlueLM-2.5-3B, a compact and unified dense Multimodal Large\nLanguage Model (MLLM) designed for efficient edge-device deployment, offering\nstrong general-purpose and reasoning capabilities. To the best of our\nknowledge, this is the first 3B-scale MLLM to support both thinking and\nnon-thinking modes, while also enabling explicit control over thinking token\nbudget. BlueLM-2.5-3B is developed through diversified data curation, key data\nresampling, hybrid heterogeneous reinforcement learning, and a high-performance\ntraining infrastructure. Our model achieves superior multimodal capacity while\npreserving competitive pure-text performance with only 2.9 billion parameters.\nWe conduct comprehensive evaluations across a broad range of multimodal and\ntext-only benchmarks. In thinking mode, BlueLM-2.5-3B achieves comparable\nperformance to Qwen3-4B on text-only benchmarks, and trails the larger\nKimi-VL-A3B-16B by only about 5% on average across multimodal evaluations. In\nnon-thinking mode, it outperforms Qwen2.5-VL-3B on the majority of multimodal\nbenchmarks. Additionally, BlueLM-2.5-3B exhibits exceptional data efficiency.\nAll of the aforementioned performance is achieved with substantially less total\ntraining data than Qwen2.5-VL-3B and Qwen3-4B. We hope our work contributes to\nthe advancement of high-performance, on-device MLLMs and provides meaningful\ninsights to the research community.", "AI": {"tldr": "BlueLM-2.5-3B是一个紧凑的多模态大语言模型，专为边缘设备设计，具有高效的通用和推理能力，支持思考与非思考模式，并在多模态和纯文本任务中表现优异。", "motivation": "开发一个高效、紧凑的多模态大语言模型，适用于边缘设备部署，同时保持强大的通用和推理能力，填补3B规模MLLM支持双模式及可控思考令牌的空白。", "method": "通过多样化数据整理、关键数据重采样、混合异构强化学习及高性能训练基础设施开发模型，仅使用29亿参数实现多模态能力与纯文本性能的平衡。", "result": "在思考模式下，BlueLM-2.5-3B在纯文本基准测试中与Qwen3-4B相当，多模态评估中仅落后Kimi-VL-A3B-16B约5%；非思考模式下，多数多模态基准测试优于Qwen2.5-VL-3B，且数据效率显著更高。", "conclusion": "BlueLM-2.5-3B为高性能设备端MLLM的发展提供了重要贡献，其高效设计和优异性能为研究社区提供了有价值的见解。"}}
{"id": "2507.05938", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05938", "abs": "https://arxiv.org/abs/2507.05938", "authors": ["Yucheng Sheng", "Jiacheng Wang", "Xingyu Zhou", "Le Liang", "Hao Ye", "Shi Jin", "Geoffrey Ye Li"], "title": "A Wireless Foundation Model for Multi-Task Prediction", "comment": null, "summary": "With the growing complexity and dynamics of the mobile communication\nnetworks, accurately predicting key system parameters, such as channel state\ninformation (CSI), user location, and network traffic, has become essential for\na wide range of physical (PHY)-layer and medium access control (MAC)-layer\ntasks. Although traditional deep learning (DL)-based methods have been widely\napplied to such prediction tasks, they often struggle to generalize across\ndifferent scenarios and tasks. In response, we propose a unified foundation\nmodel for multi-task prediction in wireless networks that supports diverse\nprediction intervals. The proposed model enforces univariate decomposition to\nunify heterogeneous tasks, encodes granularity for interval awareness, and uses\na causal Transformer backbone for accurate predictions. Additionally, we\nintroduce a patch masking strategy during training to support arbitrary input\nlengths. After trained on large-scale datasets, the proposed foundation model\ndemonstrates strong generalization to unseen scenarios and achieves zero-shot\nperformance on new tasks that surpass traditional full-shot baselines.", "AI": {"tldr": "本文提出了一种支持多任务预测的无线网络基础模型，通过统一异构任务和因果Transformer架构，实现了对未见过场景的强泛化能力和零样本性能超越传统方法。", "motivation": "随着移动通信网络的复杂性和动态性增加，传统深度学习方法在跨场景和跨任务的泛化能力上存在局限，亟需一种统一的基础模型来提升预测准确性。", "method": "模型采用单变量分解统一异构任务，编码粒度实现区间感知，使用因果Transformer主干网络，并通过补丁掩码策略支持任意输入长度。", "result": "在大规模数据集上训练后，该基础模型对未见场景展现出强泛化能力，在新任务上的零样本性能超越传统全样本基线方法。", "conclusion": "提出的统一基础模型有效解决了无线网络中多任务预测的泛化挑战，为零样本学习场景提供了高性能解决方案。"}}
{"id": "2507.05976", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.05976", "abs": "https://arxiv.org/abs/2507.05976", "authors": ["Alessandro Umbrico", "Guido Bologna", "Luca Coraci", "Francesca Fracasso", "Silvia Gola", "Gabriella Cortellessa"], "title": "Enhancing the Interpretability of Rule-based Explanations through Information Retrieval", "comment": null, "summary": "The lack of transparency of data-driven Artificial Intelligence techniques\nlimits their interpretability and acceptance into healthcare decision-making\nprocesses. We propose an attribution-based approach to improve the\ninterpretability of Explainable AI-based predictions in the specific context of\narm lymphedema's risk assessment after lymph nodal radiotherapy in breast\ncancer. The proposed method performs a statistical analysis of the attributes\nin the rule-based prediction model using standard metrics from Information\nRetrieval techniques. This analysis computes the relevance of each attribute to\nthe prediction and provides users with interpretable information about the\nimpact of risk factors. The results of a user study that compared the output\ngenerated by the proposed approach with the raw output of the Explainable AI\nmodel suggested higher levels of interpretability and usefulness in the context\nof predicting lymphedema risk.", "AI": {"tldr": "本文提出了一种基于属性分析的改进方法，旨在提升可解释人工智能（XAI）在乳腺癌淋巴结放疗后淋巴水肿风险评估中的透明度和可接受性。", "motivation": "数据驱动的人工智能技术缺乏透明度，限制了其在医疗决策中的可解释性和接受度，特别是在乳腺癌淋巴结放疗后淋巴水肿风险评估这一特定场景中。", "method": "该方法通过对基于规则的预测模型中的属性进行统计分析，利用信息检索技术的标准指标，计算每个属性对预测的相关性，并为用户提供关于风险因素影响的可解释信息。", "result": "用户研究结果表明，与原始可解释AI模型的输出相比，所提出的方法在预测淋巴水肿风险时具有更高的可解释性和实用性。", "conclusion": "该研究通过属性分析方法有效提升了可解释AI在医疗风险评估中的透明度和用户接受度，为临床决策提供了更可靠的辅助工具。"}}
{"id": "2507.05984", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.05984", "abs": "https://arxiv.org/abs/2507.05984", "authors": ["Zhijun Guo", "Alvina Lai", "Julia Ive", "Alexandru Petcu", "Yutong Wang", "Luyuan Qi", "Johan H Thygesen", "Kezhi Li"], "title": "Development and Evaluation of HopeBot: an LLM-based chatbot for structured and interactive PHQ-9 depression screening", "comment": null, "summary": "Static tools like the Patient Health Questionnaire-9 (PHQ-9) effectively\nscreen depression but lack interactivity and adaptability. We developed\nHopeBot, a chatbot powered by a large language model (LLM) that administers the\nPHQ-9 using retrieval-augmented generation and real-time clarification. In a\nwithin-subject study, 132 adults in the United Kingdom and China completed both\nself-administered and chatbot versions. Scores demonstrated strong agreement\n(ICC = 0.91; 45% identical). Among 75 participants providing comparative\nfeedback, 71% reported greater trust in the chatbot, highlighting clearer\nstructure, interpretive guidance, and a supportive tone. Mean ratings (0-10)\nwere 8.4 for comfort, 7.7 for voice clarity, 7.6 for handling sensitive topics,\nand 7.4 for recommendation helpfulness; the latter varied significantly by\nemployment status and prior mental-health service use (p < 0.05). Overall,\n87.1% expressed willingness to reuse or recommend HopeBot. These findings\ndemonstrate voice-based LLM chatbots can feasibly serve as scalable, low-burden\nadjuncts for routine depression screening.", "AI": {"tldr": "研究开发了基于大语言模型的聊天机器人HopeBot，用于抑郁症筛查，相比传统PHQ-9问卷更具交互性和适应性，用户反馈显示其可信度和接受度较高。", "motivation": "传统抑郁症筛查工具PHQ-9缺乏互动性和适应性，研究旨在开发一种更高效、用户友好的替代方案。", "method": "开发了HopeBot聊天机器人，采用检索增强生成和实时澄清技术，并在英国和中国的132名成年人中进行自填与聊天机器人版本的对比研究。", "result": "聊天机器人版本与自填版本得分高度一致（ICC = 0.91），71%的参与者更信任聊天机器人，87.1%的参与者愿意再次使用或推荐HopeBot。", "conclusion": "基于语音的大语言模型聊天机器人可作为抑郁症筛查的可扩展、低负担辅助工具，具有较高的用户接受度和可行性。"}}
{"id": "2507.06013", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06013", "abs": "https://arxiv.org/abs/2507.06013", "authors": ["Kushal Gajjar", "Harshit Sikchi", "Arpit Singh Gautam", "Marc Hammons", "Saurabh Jha"], "title": "CogniSQL-R1-Zero: Lightweight Reinforced Reasoning for Efficient SQL Generation", "comment": null, "summary": "Translating natural language into SQL (Text-to-SQL) remains a core challenge\nat the intersection of language understanding and structured data access.\nAlthough large language models (LLMs) have improved fluency, generating correct\nand executable SQL, especially for complex queries, continues to be\nchallenging. We introduce CogniSQL-R1-Zero, a reinforcement learning (RL)\nframework and model that produces accurate SQL using a lightweight reward\nsignal based on execution correctness and format-tag compliance. By avoiding\nintermediate supervision, hybrid pipelines and complex reward shaping, our\nmethod encourages stable learning and stronger alignment with the ultimate task\nobjective-producing executable programs. CogniSQL-R1-Zero achieves\nstate-of-the-art execution accuracy on Text2SQL benchmark; BIRD bench,\noutperforming prior supervised and instruction-tuned baselines including SFT\nCodeS-7B, DeepSeek-Coder 236B, and Mistral 123B-despite being trained on a\nsignificantly smaller 7B backbone. This result underscores the scalability and\nefficiency of our RL-based approach when trained on just four NVIDIA A100 GPUs\n(40 GB VRAM each). To support further research in efficient and interpretable\nText-to-SQL modeling, we release two curated datasets: (i) a collection of\n5,024 reasoning traces with varying context lengths, and (ii) a\npositive-sampled corpus of 36,356 corpus of weakly supervised queries, each\nannotated with six semantically diverse reasoning paths. Together, these\ncontributions advance scalable, execution-aligned Text-to-SQL generation.", "AI": {"tldr": "提出CogniSQL-R1-Zero强化学习框架，通过轻量级奖励信号（执行正确性与格式标签合规性）生成高精度SQL，在Text2SQL基准测试中超越现有监督学习模型，并发布两个标注数据集推动可扩展的文本到SQL研究。", "motivation": "尽管大语言模型提升了文本到SQL的流畅性，但生成复杂查询的正确可执行SQL仍具挑战性。现有方法依赖中间监督或复杂奖励机制，亟需更高效稳定的解决方案。", "method": "采用纯强化学习框架，仅基于执行正确性和格式标签合规性的轻量级奖励信号，避免混合流水线与复杂奖励塑造，直接优化最终任务目标（生成可执行程序）。", "result": "在BIRD基准上取得SOTA执行准确率，以7B参数量超越CodeS-7B、DeepSeek-Coder 236B等基线模型，仅需4块NVIDIA A100 GPU（40GB显存/块）完成训练。", "conclusion": "该研究证明了强化学习在文本到SQL任务中的高效可扩展性，同时发布包含5,024条推理轨迹和36,356条弱监督查询的数据集，推动执行对齐的SQL生成研究。"}}
{"id": "2507.06029", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06029", "abs": "https://arxiv.org/abs/2507.06029", "authors": ["Courtney Ford", "Mark T. Keane"], "title": "Feature-Guided Neighbor Selection for Non-Expert Evaluation of Model Predictions", "comment": "7 pages, 5 figures, 1 table. Accepted at IJCAI 2025 Workshop on\n  User-Aligned Assessment of Adaptive AI Systems", "summary": "Explainable AI (XAI) methods often struggle to generate clear, interpretable\noutputs for users without domain expertise. We introduce Feature-Guided\nNeighbor Selection (FGNS), a post hoc method that enhances interpretability by\nselecting class-representative examples using both local and global feature\nimportance. In a user study (N = 98) evaluating Kannada script classifications,\nFGNS significantly improved non-experts' ability to identify model errors while\nmaintaining appropriate agreement with correct predictions. Participants made\nfaster and more accurate decisions compared to those given traditional k-NN\nexplanations. Quantitative analysis shows that FGNS selects neighbors that\nbetter reflect class characteristics rather than merely minimizing\nfeature-space distance, leading to more consistent selection and tighter\nclustering around class prototypes. These results support FGNS as a step toward\nmore human-aligned model assessment, although further work is needed to address\nthe gap between explanation quality and perceived trust.", "AI": {"tldr": "本文提出了一种名为FGNS的可解释AI方法，通过结合局部和全局特征重要性选择类代表性样本，显著提升了非专业人士识别模型错误的能力，同时保持了与正确预测的一致性。", "motivation": "现有的可解释AI方法在生成对非领域专家清晰可解释的输出方面存在困难，需要一种能提升模型解释性的新方法。", "method": "研究引入了特征引导邻居选择（FGNS）方法，这是一种事后解释技术，通过局部和全局特征重要性选择类代表性样本来增强可解释性。", "result": "在卡纳达语脚本分类的用户研究（N=98）中，FGNS显著提高了非专家识别模型错误的准确性，决策速度更快，且所选邻居更能反映类别特征而非仅最小化特征空间距离。", "conclusion": "FGNS是迈向更符合人类认知的模型评估的重要一步，但解释质量与感知信任之间的差距仍需进一步研究。"}}
{"id": "2507.06042", "categories": ["cs.AI", "03B42, 03B48"], "pdf": "https://arxiv.org/pdf/2507.06042", "abs": "https://arxiv.org/abs/2507.06042", "authors": ["Tommaso Flaminio", "Lluis Godo", "Ramón Pino Pérez", "Lluis Subirana"], "title": "On Lockean beliefs that are deductively closed and minimal change", "comment": "18 pages, to appear in the proceedings of JELIA 2025", "summary": "Within the formal setting of the Lockean thesis, an agent belief set is\ndefined in terms of degrees of confidence and these are described in\nprobabilistic terms. This approach is of established interest, notwithstanding\nsome limitations that make its use troublesome in some contexts, like, for\ninstance, in belief change theory. Precisely, Lockean belief sets are not\ngenerally closed under (classical) logical deduction. The aim of the present\npaper is twofold: on one side we provide two characterizations of those belief\nsets that are closed under classical logic deduction, and on the other we\npropose an approach to probabilistic update that allows us for a minimal\nrevision of those beliefs, i.e., a revision obtained by making the fewest\npossible changes to the existing belief set while still accommodating the new\ninformation. In particular, we show how we can deductively close a belief set\nvia a minimal revision.", "AI": {"tldr": "本文在Lockean理论框架下，研究概率置信度定义的信念集合，提出两种经典逻辑闭包特征，并设计最小修正的概率更新方法以实现信念集合的演绎封闭。", "motivation": "Lockean信念集合在经典逻辑演绎下通常不封闭，这限制了其在信念修正理论等场景的应用。论文旨在解决这一局限性。", "method": "通过两种特征化方法描述经典逻辑闭包的信念集合，并提出基于最小修正原则的概率更新策略。", "result": "证明了如何通过最小化修正实现信念集合的演绎封闭，即在保持原信念最大兼容性的同时纳入新信息。", "conclusion": "研究为概率性信念系统提供了理论工具，使Lockean方法能更有效地应用于需要逻辑一致性的领域。"}}
{"id": "2507.06057", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06057", "abs": "https://arxiv.org/abs/2507.06057", "authors": ["Bo Pang", "Yalu Ouyang", "Hangfei Xu", "Ziqi Jia", "Panpan Li", "Shengzhao Wen", "Lu Wang", "Shiyong Li", "Yanpeng Wang"], "title": "FEVO: Financial Knowledge Expansion and Reasoning Evolution for Large Language Models", "comment": null, "summary": "Advancements in reasoning for large language models (LLMs) have lead to\nsignificant performance improvements for LLMs in various fields such as\nmathematics and programming. However, research applying these advances to the\nfinancial domain, where considerable domain-specific knowledge is necessary to\ncomplete tasks, remains limited. To address this gap, we introduce FEVO\n(Financial Evolution), a multi-stage enhancement framework developed to enhance\nLLM performance in the financial domain. FEVO systemically enhances LLM\nperformance by using continued pre-training (CPT) to expand financial domain\nknowledge, supervised fine-tuning (SFT) to instill structured, elaborate\nreasoning patterns, and reinforcement learning (RL) to further integrate the\nexpanded financial domain knowledge with the learned structured reasoning. To\nensure effective and efficient training, we leverage frontier reasoning models\nand rule-based filtering to curate FEVO-Train, high-quality datasets\nspecifically designed for the different post-training phases. Using our\nframework, we train the FEVO series of models -- C32B, S32B, R32B -- from\nQwen2.5-32B and evaluate them on seven benchmarks to assess financial and\ngeneral capabilities, with results showing that FEVO-R32B achieves\nstate-of-the-art performance on five financial benchmarks against much larger\nmodels as well as specialist models. More significantly, FEVO-R32B demonstrates\nmarkedly better performance than FEVO-R32B-0 (trained from Qwen2.5-32B-Instruct\nusing only RL), thus validating the effectiveness of financial domain knowledge\nexpansion and structured, logical reasoning distillation", "AI": {"tldr": "本文提出了FEVO（金融进化）框架，通过多阶段增强方法提升大语言模型在金融领域的表现，包括持续预训练、监督微调和强化学习，最终模型在多个金融基准测试中达到最优性能。", "motivation": "尽管大语言模型在数学和编程等领域取得了显著进展，但在需要大量专业知识的金融领域应用研究仍然有限。FEVO框架旨在填补这一空白，提升模型在金融任务中的表现。", "method": "FEVO框架采用三阶段方法：1) 持续预训练（CPT）扩展金融领域知识；2) 监督微调（SFT）注入结构化推理模式；3) 强化学习（RL）整合金融知识与推理能力。使用高质量数据集FEVO-Train进行训练。", "result": "基于Qwen2.5-32B训练的FEVO-R32B模型在七个基准测试中评估，在五个金融基准上超越了更大规模的模型和专用模型，达到最先进性能。FEVO-R32B显著优于仅使用RL训练的FEVO-R32B-0，验证了金融知识扩展和结构化推理的有效性。", "conclusion": "FEVO框架通过系统性的多阶段增强，成功提升了LLM在金融领域的性能，证明了金融领域知识扩展和结构化推理提炼的重要性，为金融领域的LLM应用提供了有效解决方案。"}}
{"id": "2507.06077", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06077", "abs": "https://arxiv.org/abs/2507.06077", "authors": ["Iman Rahimi", "Isha Patel"], "title": "AI-Based Demand Forecasting and Load Balancing for Optimising Energy use in Healthcare Systems: A real case study", "comment": null, "summary": "This paper tackles the urgent need for efficient energy management in\nhealthcare facilities, where fluctuating demands challenge operational\nefficiency and sustainability. Traditional methods often prove inadequate,\ncausing inefficiencies and higher costs. To address this, the study presents an\nAI-based framework combining Long Short-Term Memory (LSTM), genetic algorithm\n(GA), and SHAP (Shapley Additive Explanations), specifically designed for\nhealthcare energy management. Although LSTM is widely used for time-series\nforecasting, its application in healthcare energy prediction remains\nunderexplored. The results reveal that LSTM significantly outperforms ARIMA and\nProphet models in forecasting complex, non-linear demand patterns. LSTM\nachieves a Mean Absolute Error (MAE) of 21.69 and Root Mean Square Error (RMSE)\nof 29.96, far better than Prophet (MAE: 59.78, RMSE: 81.22) and ARIMA (MAE:\n87.73, RMSE: 125.22), demonstrating superior performance. The genetic algorithm\nis applied to optimize model parameters and improve load balancing strategies,\nenabling adaptive responses to real-time energy fluctuations. SHAP analysis\nfurther enhances model transparency by explaining the influence of different\nfeatures on predictions, fostering trust in decision-making processes. This\nintegrated LSTM-GA-SHAP approach offers a robust solution for improving\nforecasting accuracy, boosting energy efficiency, and advancing sustainability\nin healthcare facilities. Future research may explore real-time deployment and\nhybridization with reinforcement learning for continuous optimization. Overall,\nthe study establishes a solid foundation for using AI in healthcare energy\nmanagement, highlighting its scalability, efficiency, and resilience potential.", "AI": {"tldr": "本文提出了一种结合LSTM、遗传算法和SHAP的AI框架，用于提升医疗机构能源管理效率，显著优于传统方法。", "motivation": "医疗机构能源需求波动大，传统方法效率低下且成本高，亟需智能解决方案提升能效与可持续性。", "method": "采用LSTM进行时间序列预测，遗传算法优化参数与负载均衡，SHAP增强模型可解释性，形成LSTM-GA-SHAP集成框架。", "result": "LSTM预测性能远超ARIMA和Prophet（MAE: 21.69 vs. 59.78/87.73；RMSE: 29.96 vs. 81.22/125.22），遗传算法实现动态负载调整，SHAP提供特征贡献分析。", "conclusion": "该框架为医疗能源管理提供了高精度、可解释的解决方案，未来可结合强化学习实时优化，展现了AI在能效领域的扩展潜力。"}}
{"id": "2507.06134", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06134", "abs": "https://arxiv.org/abs/2507.06134", "authors": ["Sanidhya Vijayvargiya", "Aditya Bharat Soni", "Xuhui Zhou", "Zora Zhiruo Wang", "Nouha Dziri", "Graham Neubig", "Maarten Sap"], "title": "OpenAgentSafety: A Comprehensive Framework for Evaluating Real-World AI Agent Safety", "comment": "19 pages, 10 figures", "summary": "Recent advances in AI agents capable of solving complex, everyday tasks, from\nscheduling to customer service, have enabled deployment in real-world settings,\nbut their possibilities for unsafe behavior demands rigorous evaluation. While\nprior benchmarks have attempted to assess agent safety, most fall short by\nrelying on simulated environments, narrow task domains, or unrealistic tool\nabstractions. We introduce OpenAgentSafety, a comprehensive and modular\nframework for evaluating agent behavior across eight critical risk categories.\nUnlike prior work, our framework evaluates agents that interact with real\ntools, including web browsers, code execution environments, file systems, bash\nshells, and messaging platforms; and supports over 350 multi-turn, multi-user\ntasks spanning both benign and adversarial user intents. OpenAgentSafety is\ndesigned for extensibility, allowing researchers to add tools, tasks, websites,\nand adversarial strategies with minimal effort. It combines rule-based analysis\nwith LLM-as-judge assessments to detect both overt and subtle unsafe behaviors.\nEmpirical analysis of five prominent LLMs in agentic scenarios reveals unsafe\nbehavior in 51.2% of safety-vulnerable tasks with Claude-Sonnet-3.7, to 72.7%\nwith o3-mini, highlighting critical safety vulnerabilities and the need for\nstronger safeguards before real-world deployment.", "AI": {"tldr": "本文介绍了OpenAgentSafety框架，用于全面评估AI代理在八类关键风险中的行为安全性，支持350多项多轮多用户任务，并揭示主流LLM在51.2%-72.7%的安全漏洞任务中存在不安全行为。", "motivation": "现有AI代理安全评估依赖模拟环境、狭窄任务域或不现实工具抽象，无法满足真实场景需求，亟需能测试真实工具交互的综合性安全框架。", "method": "提出模块化框架OpenAgentSafety，支持真实工具（浏览器/代码执行/文件系统等），结合规则分析与LLM评判，检测显性和隐性不安全行为，可灵活扩展工具和对抗策略。", "result": "实验显示：Claude-Sonnet-3.7在51.2%的安全漏洞任务中表现不安全，o3-mini达72.7%，暴露当前LLM代理的重要安全隐患。", "conclusion": "现有AI代理存在显著安全风险，OpenAgentSafety证实需加强安全防护机制才能投入实际应用，框架为后续研究提供可扩展评估基准。"}}
{"id": "2507.06187", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06187", "abs": "https://arxiv.org/abs/2507.06187", "authors": ["Scott Geng", "Hamish Ivison", "Chun-Liang Li", "Maarten Sap", "Jerry Li", "Ranjay Krishna", "Pang Wei Koh"], "title": "The Delta Learning Hypothesis: Preference Tuning on Weak Data can Yield Strong Gains", "comment": "COLM 2025", "summary": "Improvements in language models are often driven by improving the quality of\nthe data we train them on, which can be limiting when strong supervision is\nscarce. In this work, we show that paired preference data consisting of\nindividually weak data points can enable gains beyond the strength of each\nindividual data point. We formulate the delta learning hypothesis to explain\nthis phenomenon, positing that the relative quality delta between points\nsuffices to drive learning via preference tuning--even when supervised\nfinetuning on the weak data hurts. We validate our hypothesis in controlled\nexperiments and at scale, where we post-train 8B models on preference data\ngenerated by pairing a small 3B model's responses with outputs from an even\nsmaller 1.5B model to create a meaningful delta. Strikingly, on a standard\n11-benchmark evaluation suite (MATH, MMLU, etc.), our simple recipe matches the\nperformance of Tulu 3, a state-of-the-art open model tuned from the same base\nmodel while relying on much stronger supervisors (e.g., GPT-4o). Thus, delta\nlearning enables simpler and cheaper open recipes for state-of-the-art\npost-training. To better understand delta learning, we prove in logistic\nregression that the performance gap between two weak teacher models provides\nuseful signal for improving a stronger student. Overall, our work shows that\nmodels can learn surprisingly well from paired data that might typically be\nconsidered weak.", "AI": {"tldr": "研究表明，通过配对偏好数据中的相对质量差异（delta学习），即使单个数据点质量较弱，也能有效提升语言模型性能。该方法在8B模型上验证，性能媲美使用更强监督信号的先进模型。", "motivation": "传统语言模型改进依赖高质量监督数据，但在强监督稀缺时受限。本文探索如何利用弱数据点间的相对差异驱动模型学习。", "method": "提出delta学习假设：配对弱数据点间的质量差异足以通过偏好调优提升模型。实验使用3B与1.5B模型生成配对数据，对8B模型进行后训练。", "result": "在11个基准测试（如MATH、MMLU）中，该方法匹配了基于GPT-4o等强监督训练的Tulu 3模型性能，且成本更低。逻辑回归理论证明弱教师模型间的性能差距对强学生模型有改进信号。", "conclusion": "delta学习揭示了模型能从传统认为的弱配对数据中有效学习，为开源模型后训练提供了更简单、经济的先进方案。"}}
{"id": "2507.06213", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06213", "abs": "https://arxiv.org/abs/2507.06213", "authors": ["Clément Yvernes", "Emilie Devijver", "Marianne Clausel", "Eric Gaussier"], "title": "Identifiability in Causal Abstractions: A Hierarchy of Criteria", "comment": "Accepted at the CAR Workshop at UAI2025", "summary": "Identifying the effect of a treatment from observational data typically\nrequires assuming a fully specified causal diagram. However, such diagrams are\nrarely known in practice, especially in complex or high-dimensional settings.\nTo overcome this limitation, recent works have explored the use of causal\nabstractions-simplified representations that retain partial causal information.\nIn this paper, we consider causal abstractions formalized as collections of\ncausal diagrams, and focus on the identifiability of causal queries within such\ncollections. We introduce and formalize several identifiability criteria under\nthis setting. Our main contribution is to organize these criteria into a\nstructured hierarchy, highlighting their relationships. This hierarchical view\nenables a clearer understanding of what can be identified under varying levels\nof causal knowledge. We illustrate our framework through examples from the\nliterature and provide tools to reason about identifiability when full causal\nknowledge is unavailable.", "AI": {"tldr": "本文提出了一种基于因果抽象的方法，用于在观测数据中识别处理效应，通过构建因果图集合并引入可识别性标准层次结构，解决了传统方法需要完整因果图的局限性。", "motivation": "传统因果效应识别方法需要完整的因果图，但在复杂或高维场景中难以获取。因果抽象作为简化表示方法，能保留部分因果信息，但缺乏系统的可识别性分析框架。", "method": "将因果抽象形式化为因果图集合，提出多种可识别性标准，并构建层次化结构以阐明标准间的关联。通过文献案例验证框架，开发了不依赖完整因果知识的推理工具。", "result": "建立了可识别性标准的层次体系，揭示了不同因果知识水平下的识别能力边界。示例分析表明该框架能有效处理部分因果信息的场景。", "conclusion": "因果抽象层次框架为不完全因果知识下的效应识别提供了系统方法论，其结构化标准体系增强了可解释性和实用性。"}}
{"id": "2507.06221", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2507.06221", "abs": "https://arxiv.org/abs/2507.06221", "authors": ["Yuxuan Lu", "Yifan Wu", "Jason Hartline", "Michael J. Curry"], "title": "Aligned Textual Scoring Rules", "comment": null, "summary": "Scoring rules elicit probabilistic predictions from a strategic agent by\nscoring the prediction against a ground truth state. A scoring rule is proper\nif, from the agent's perspective, reporting the true belief maximizes the\nexpected score. With the development of language models, Wu and Hartline (2024)\nproposes a reduction from textual information elicitation to the numerical\n(i.e. probabilistic) information elicitation problem, which achieves provable\nproperness for textual elicitation. However, not all proper scoring rules are\nwell aligned with human preference over text. Our paper designs the Aligned\nScoring rule (ASR) for text by optimizing and minimizing the mean squared error\nbetween a proper scoring rule and a reference score (e.g. human score). Our\nexperiments show that our ASR outperforms previous methods in aligning with\nhuman preference while maintaining properness.", "AI": {"tldr": "本文提出了一种对齐评分规则（ASR），通过优化均方误差使文本评分规则在保持合理性的同时更符合人类偏好，实验证明其优于现有方法。", "motivation": "现有合理评分规则虽能确保策略代理报告真实信念，但未必与人类对文本的偏好一致，需设计更符合人类偏好的评分规则。", "method": "设计ASR规则，通过最小化合理评分规则与参考分数（如人工评分）间的均方误差，实现文本评分与人类偏好的对齐。", "result": "实验表明，ASR在保持评分规则合理性的前提下，显著提升了与人类偏好的对齐效果，优于先前方法。", "conclusion": "ASR成功解决了文本信息获取中评分规则与人类偏好的对齐问题，为语言模型应用提供了更可靠的评估工具。"}}
