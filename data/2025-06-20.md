<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 3]
- [math.OC](#math.OC) [Total: 16]
- [math.NT](#math.NT) [Total: 11]
- [math.LO](#math.LO) [Total: 4]
- [math.CO](#math.CO) [Total: 12]
- [cs.CR](#cs.CR) [Total: 24]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.DM](#cs.DM) [Total: 1]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Identifiability by common backdoor in summary causal graphs of time series](https://arxiv.org/abs/2506.14862)
*Clément Yvernes,Charles K. Assaad,Emilie Devijver,Eric Gaussier*

Main category: math.ST

TL;DR: 本文研究了时间序列中干预的可识别性问题，探讨了在仅能获得摘要因果图的情况下，如何通过共同后门集判断多干预多效应的可识别性，并提出了相应的判定算法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决干预效应的可识别性问题，即在仅能获取观测数据的情况下，如何通过无do运算公式计算干预的总效应，特别是在时间序列和摘要因果图的背景下。

Method: 研究聚焦于通过共同后门集进行识别，针对时间序列（包括时间一致性和非一致性的情况），建立了存在此类集合的条件，并设计了复杂度有限的判定算法。

Result: 研究确立了在时间序列中，无论时间是否一致，存在共同后门集的条件，并提供了可判定可识别性问题的算法。

Conclusion: 通过共同后门集的方法，可以在摘要因果图的背景下有效解决时间序列中干预效应的可识别性问题，为实际应用提供了理论支持和算法工具。

Abstract: The identifiability problem for interventions aims at assessing whether the
total effect of some given interventions can be written with a do-free formula,
and thus be computed from observational data only. We study this problem,
considering multiple interventions and multiple effects, in the context of time
series when only abstractions of the true causal graph in the form of summary
causal graphs are available. We focus in this study on identifiability by a
common backdoor set, and establish, for time series with and without
consistency throughout time, conditions under which such a set exists. We also
provide algorithms of limited complexity to decide whether the problem is
identifiable or not.

</details>


### [2] [Probabilistic closed-form formulas for pricing nonlinear payoff variance and volatility derivatives under Schwartz model with time-varying log-return volatility](https://arxiv.org/abs/2506.15386)
*Nontawat Bunchak,Udomsak Rakwongwan,Phiraphat Sutthimat*

Main category: math.ST

TL;DR: 本文提出了离散时间观测下非线性收益波动率和方差衍生品的闭式解析定价公式，基于Schwartz单因子模型，解决了时变对数收益波动率下的定价难题，并通过蒙特卡洛模拟验证了方法的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决时变对数收益波动率假设下波动率和方差衍生品的定价问题，特别是实现方差服从加权参数的非中心卡方随机变量线性组合的复杂分布情况。

Method: 采用概率密度函数解析计算实现方差平方根的期望，推导波动率互换和波动率看涨期权的定价公式，并对常数对数收益波动率情况简化公式，分析波动率敏感性（vega）。

Result: 提出了Schwartz单因子模型下波动率互换的简单闭式近似公式，蒙特卡洛模拟验证了方法的准确性，并探讨了价格波动率和交易日数量对公平执行价的影响。

Conclusion: 所提出的解析方法能高效定价非线性波动率和方差衍生品，为时变波动率市场下的风险管理提供了实用工具。

Abstract: This paper presents closed-form analytical formulas for pricing volatility
and variance derivatives with nonlinear payoffs under discrete-time
observations. The analysis is based on a probabilistic approach assuming that
the underlying asset price follows the Schwartz one-factor model, where the
volatility of log-returns is time-varying. A difficult challenge in this
pricing problem is to solve an analytical formula under the assumption of
time-varying log-return volatility, resulting in the realized variance being
distributed according to a linear combination of independent noncentral
chi-square random variables with weighted parameters. By utilizing the
probability density function, we analytically compute the expectation of the
square root of the realized variance and derive pricing formulas for volatility
swaps. Additionally, we derive analytical pricing formulas for volatility call
options. For the payoff function without the square root, we also derive
corresponding formulas for variance swaps and variance call options.
Additionally, we study the case of constant log-return volatility; simplified
pricing formulas are derived and sensitivity with respect to volatility (vega)
is analytically studied. Furthermore,we propose simple closed-form
approximations for pricing volatility swaps under the Schwartz one-factor
model. The accuracy and efficiency of the proposed methods are demonstrated
through Monte Carlo simulations, and the impact of price volatility and the
number of trading days on fair strike prices of volatility and variance swaps
is investigated across various numerical experiments.

</details>


### [3] [Density estimation via periodic scaled Korobov kernel method with exponential decay condition](https://arxiv.org/abs/2506.15419)
*Ziyang Ye,Haoyuan Tan,Xiaoqun Wang,Zhijian He*

Main category: math.ST

TL;DR: 本文提出了一种用于非参数密度估计的周期性缩放Korobov核方法（PSKK），通过模运算将目标密度转换为周期性版本，并在缩放Korobov空间中进行核岭回归，从而扩展了先前方法的应用范围，适用于无界域上的密度估计。


<details>
  <summary>Details</summary>
Motivation: 现有核方法要求密度函数具有固有周期性，限制了其在无界域上的应用。本文旨在消除这一限制，提出一种适用于更广泛非周期分布的有效估计方法。

Method: 通过模运算将目标密度包装为周期性版本，随后在缩放Korobov空间中使用核岭回归进行估计，扩展了Kazashi和Nobile（2023）提出的核方法。

Result: 理论分析表明，对于具有$\alpha$阶光滑性和指数衰减的密度，该方法实现了$\mathcal{O}(M^{-1/(1+1/(2\alpha)+\epsilon)})$的MISE收敛速率，其中$\epsilon>0$可任意小。数值实验验证了理论结果，并显示在大样本情况下优于传统核密度估计。

Conclusion: PSKK方法不仅匹配了先前核方法的收敛速率，而且适用于更广泛的非周期分布，为无界域上的密度估计提供了有效工具。

Abstract: We propose the periodic scaled Korobov kernel (PSKK) method for nonparametric
density estimation on $\mathbb{R}^d$. By first wrapping the target density into
a periodic version through modulo operation and subsequently applying kernel
ridge regression in scaled Korobov spaces, we extend the kernel approach
proposed by Kazashi and Nobile (SIAM J. Numer. Anal., 2023) and eliminate its
requirement for inherent periodicity of the density function. This key
modification enables effective estimation of densities defined on unbounded
domains. We establish rigorous mean integrated squared error (MISE) bounds,
proving that for densities with smoothness of order $\alpha$ and exponential
decay, our method achieves the $\mathcal{O}(M^{-1/(1+1/(2\alpha)+\epsilon)})$
MISE convergence rate with an arbitrarily small $\epsilon>0$. While matching
the convergence rate of the previous kernel approach, our approach applies to a
broader class of non-periodic distributions. Numerical experiments confirm the
theoretical results and demonstrate significant improvement over traditional
kernel density estimation in large-sample regimes.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [4] [On λ-Cent-Dians and Generalized-Center for Network Design: Formulations and Algorithms](https://arxiv.org/abs/2506.14839)
*Víctor Bucarey,Natividad González-Blanco,Martine Labbé,Juan A. Mesa*

Main category: math.OC

TL;DR: 本文研究了网络设计中的$\lambda$-中心问题，提出了一种在预算约束下设计子网络的算法方法，并探讨了不同$\lambda$值下的数学模型和解法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决在给定底层网络中设计子网络的问题，该子网络需在预算约束下高效服务多个起点/终点需求对，扩展了现有$\lambda$-中心问题的研究。

Method: 通过数学建模$\lambda\geq 0$的情况，讨论了$\lambda>1$时的双层结构问题，并引入最大$\lambda$-中心概念，通过混合整数线性规划求解帕累托最优集。对于$\lambda\in[0,1]$，研究了Benders分解法的实现。

Result: 提出了完整的帕累托最优集参数化方法，并通过不等式度量评估了不同解的质量，展示了Benders分解法在大规模问题中的适用性。

Conclusion: 研究为网络设计中的$\lambda$-中心问题提供了全面的算法视角和解决方案，特别是在不同$\lambda$范围内的数学模型和优化方法。

Abstract: In this paper, we study the $\lambda$-centdian problem in the domain of
Network Design. The focus is on designing a sub-network within a given
underlying network while adhering to a budget constraint. This sub-network is
intended to efficiently serve a collection of origin/destination demand pairs.
We extend the work presented in \cite{bucarey2024on}, providing an algorithmic
perspective on the generalized $\lambda$-centdian problem. In particular, we
provide a mathematical formulation for $\lambda\geq 0$ and discuss the bilevel
structure of this problem for $\lambda>1$. Furthermore, we describe a procedure
to obtain a complete parametrization of the Pareto-optimality set based on
solving two mixed integer linear formulations by introducing the concept of
maximum $\lambda$-cent-dian. We evaluate the quality of the different solution
concepts using some inequality measures. Finally, for $\lambda\in[0,1]$, we
study the implementation of a Benders decomposition method to solve it at
scale.

</details>


### [5] [An efficient co-simulation and control approach to tackle complex multi-domain energetic systems: concepts and applications of the PEGASE platform](https://arxiv.org/abs/2506.15195)
*Mathieu Vallee,Roland Baviere,Valérie Seguin,Valéry Vuillerme,Nicolas Lamaison,Michael Nikhil Descamps,Antoine Aurousseau*

Main category: math.OC

TL;DR: 本文介绍了一款名为PEGASE的新型研究软件，专为复杂多领域能源系统的先进控制策略设计、验证和部署而开发，具备高效协同仿真引擎和集成控制解决方案。


<details>
  <summary>Details</summary>
Motivation: 针对多领域大规模能源系统控制的复杂性，传统单一解决方案效率低下，PEGASE通过分而治之原则提供模块化仿真与控制能力。

Method: PEGASE基于FMI标准兼容模型集成框架和API接口，采用多线程时序器实现多步长仿真，并内置混合整数线性规划的模型预测控制(MPC)框架。

Result: 该C++实现的框架在典型应用中表现出低建模与求解耗时，通过工业协议连接硬件，成功应用于聚光太阳能热发电站和区域供热网络优化控制等四个案例。

Conclusion: 多样化的应用案例验证了PEGASE平台的鲁棒性和通用性，其模块化设计能有效应对各类能源系统的复杂控制挑战。

Abstract: In this paper, we present a novel research software, called PEGASE, suitable
for the design, validation and deployment of advanced control strategies for
complex multi-domain energy systems. PEGASE especially features a highly
efficient cosimulation engine, together with integrated solutions for defining
both rule-based control strategies and Model-Predictive Control (MPC). The main
principle behind the PEGASE platform is divide-and-conquer. Indeed, rather than
trying to solve a problem as a monolithic entity, which can be highly complex
for multi-domain large-scale systems, it is often more efficient to decompose
it into several domains or sub-problems, and to simulate them in a decoupled
way. To provide its cosimulation capabilities, we based PEGASE on two main
components. The first one is a framework for integrating simulation models,
which can be either compatible with the FMI standard or interfaced through an
Application Programming Interface (API). The second one is a multi-threaded
sequencer enabling several simulation sequences with different time steps. To
provide advanced control capabilities, we also equipped PEGASE with a framework
for MPC combining a comprehensive management of predictions data and a modeler
dedicated to the formulation of Mixed Integer Linear Programs. We implemented
this framework in C++ providing low formulation and resolution times for
typical applications. Connection to hardware is also available via standard
industry protocols thereby allowing PEGASE to control real energy systems. In
this paper, we show how these basic functionalities, combined with dedicated
modeling tools, enable setting up simulation and control applications suitable
for tackling the complexity of various kinds of energy systems. To illustrate
this, we present four application examples from our recent research work. These
examples cover several domains, from concentrated solar thermal plants to
optimal control of district heating networks. The variety of examples
demonstrates the robustness and genericity of the approach.

</details>


### [6] [Operational Control of a Multi-energy District Heating System: Comparison of Model-Predictive Control and Rule-Based Control](https://arxiv.org/abs/2506.15197)
*Michael Nikhil Descamps,Nicolas Lamaison,Mathieu Vallee,Roland Baviere*

Main category: math.OC

TL;DR: 本研究比较了区域供热网络(DHN)的两种运行控制策略：基于规则的响应式控制(RBC)和模型预测控制(MPC)。通过Modelica建模的小型供热网络和Pegase协同仿真平台验证，MPC在降低运营成本和应对能源波动方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 探索多能源区域供热网络的高效运行控制策略，比较传统RBC与先进MPC在满足用户需求、技术约束及成本优化方面的性能差异。

Method: 使用Modelica建立含热泵、燃气锅炉、太阳能集热场和储热罐的小型供热网络模型，通过Pegase平台实施RBC与MPC策略，分析不同热源配置和预测误差场景。

Result: MPC策略显著降低运营成本（尤其在电价波动和太阳能间歇性条件下），仿真显示MPC能有效协调储能与多能源，全年模拟可在20分钟内完成。

Conclusion: MPC在动态能源定价和可再生能源整合中具有显著优势，研究验证了Modelica与Pegase平台对复杂控制策略快速实现的支撑能力。

Abstract: This study focuses on operational control strategies for a multi-energy
District Heating Network (DHN). Two control strategies are investigated and
compared: (i) a reactive rule-based control (RBC) and (ii) a model predictive
control (MPC). For the purpose of the study a small scale district heating
network is modelled using Modelica. The production plant combines a heat pump,
a gas boiler and a thermal solar field on the production side with a storage
tank for flexibility purposes. On the consumption side, the virtual buildings
are aggregated into a single consumer. We use our co-simulation and control
platform, called Pegase, to implement the studied strategies. For both
strategies the goal is to meet the consumers' demand while satisfying technical
constraints. In addition MPC has the objective to minimize the operational
costs, taking into account variable electricity prices and availability of
solar thermal resource. Different scenarios are also defined and compared to
study the effect of the heat plant sizing and forecasting error. The
operational cost is reduced when switching from RBC to a MPC. As can be
expected, MPC is more efficient when dealing with variable energy costs,
intermittent solar energy and storage capabilities. This study also
demonstrates how our tools enable an easy coupling of Modelica-based simulation
with various control strategies. It especially supports the implementation and
validation of complex MPC strategies in an efficient way, and yearly
simulations are performed within 20 minutes.

</details>


### [7] [Contribution of expert aggregation to temperature prediction part II: Second order bounds with sleeping experts](https://arxiv.org/abs/2506.15216)
*Léo Pfitzner,Olivier Wintenberger,Olivier Mestre*

Main category: math.OC

TL;DR: 本文通过引入睡眠专家框架(SEF)和梯度提升回归树改进了在线专家聚合(EA)的温度预测，提高了反应性并减少了误差，同时结合BOA算法实现了最佳效果。


<details>
  <summary>Details</summary>
Motivation: 改进第一部分中在线专家聚合(EA)的温度预测，使其更具反应性，同时保持均方根误差并减少大误差数量。

Method: 采用睡眠专家框架(SEF)高效利用有偏专家，结合梯度提升回归树处理专家使用时机的不确定性，并在BOA自适应聚合算法中实现在线应用。

Result: 新方法在保持预测精度的同时提高了反应性，显著减少了大幅误差，并通过元聚合策略有效控制了SEF引入的噪声。

Conclusion: 结合SEF和梯度提升回归树的改进方法显著提升了温度预测性能，同时BOA算法的应用确保了最佳的在线聚合效果。

Abstract: In this paper we improve on the temperature predictions made with (online)
Expert Aggregation (EA) [Cesa-Bianchi and Lugosi, 2006] in Part I. In
particular, we make the aggregation more reactive, whilst maintaining at least
the same root mean squared error and reducing the number of large errors. We
have achieved this by using the Sleeping Expert Framework (SEF) [Freund et al.,
1997, Devaine et al., 2013], which allows the more efficient use of biased
experts (bad on average but which may be good at some point). To deal with the
fact that, unlike in Devaine et al. [2013], we do not know in advance when to
use these biased experts, we resorted to gradient boosted regression trees
[Chen and Guestrin, 2016] and provide regret bounds against sequences of
experts [Mourtada and Maillard, 2017] which take into account this uncertainty.
We applied this in a fully online way on BOA [Wintenberger, 2024], an adaptive
aggregation with second order regret bounds, which had the best results in Part
I. Finally, we made a meta-aggregation with the EA follow the leader. This
chooses whether or not to use the SEF in order to limit the possible noise
added by the SEF.

</details>


### [8] [On the Effectiveness of Classical Regression Methods for Optimal Switching Problems](https://arxiv.org/abs/2506.15436)
*Martin Andersson,Benny Avelin,Marcus Olofsson*

Main category: math.OC

TL;DR: 简单回归方法在1到50维的最优切换问题中展现出稳健且接近最优的性能，无需复杂调参即可超越神经网络。


<details>
  <summary>Details</summary>
Motivation: 研究旨在验证简单回归方法在高维最优切换问题中的有效性，尤其是在存在近似偏差和蒙特卡洛噪声的污染训练目标场景下。

Method: 采用Longstaff-Schwartz算法结合经典方法（如$k$-NN），测试了八种回归方法在四个基准问题上的表现，并分析了PCA对$k$-NN高维扩展的作用。

Result: 简单方法在不同问题特性下保持稳定性能，$k$-NN在跳跃扩散动力学下具有浓度边界，PCA使其适用于高维场景。

Conclusion: 对于计算密集型切换问题，简单、低调参的回归方法提供了可靠解决方案，其稳健性优于复杂替代方案（如神经网络）。

Abstract: Simple regression methods provide robust, near-optimal solutions for optimal
switching problems in dimensions ranging from 1 to 50. While the theory
requires solving intractable PDE systems, the Longstaff-Schwartz algorithm with
classical approaches like $k$-NN achieves excellent switching decisions without
extensive hyperparameter tuning. Testing eight regression approaches on four
benchmark problems, we find that simple methods maintain stable performance
across diverse problem characteristics, even after extensive neural network
optimization. The contaminated training targets inherent to backward
induction-where each target contains both approximation bias and Monte Carlo
noise-actually favor these robust approaches over more complex alternatives
such as neural networks. Further, we establish concentration bounds for $k$-NN
regression under jump-diffusion dynamics and show that PCA enables $k$-NN to
scale to high dimensions. For practitioners: simple, minimally-tuned regression
methods offer reliable performance for computationally demanding switching
problems.

</details>


### [9] [Contribution of expert aggregation to temperature prediction part I](https://arxiv.org/abs/2506.15217)
*Léo Pfitzner,Olivier Wintenberger,Olivier Mestre,Marion Riverain*

Main category: math.OC

TL;DR: 本文提出使用专家聚合（EA）策略优化数值天气预报（NWP）模型的温度预测，展示了其在线性、适应性和理论保证方面的优势，并通过比较不同EA策略验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有多种数值天气预报模型及其后处理统计方法，但如何最优整合这些预测结果仍具挑战性。专家聚合（EA）因其在线性、模型变化的适应性及理论保证等优势，成为解决这一问题的潜在方案。

Method: 采用专家聚合（EA）策略进行确定性温度预测，具体方法包括比较不同EA策略在不同场景下的表现，并分析其对后处理NWP模型预测的改进效果。

Result: 研究表明，EA策略能够有效提升温度预测的准确性，甚至优于后处理的NWP模型。不同EA策略在不同设置下表现各异，但整体显示出显著改进。

Conclusion: 专家聚合（EA）策略为整合多源天气预报模型提供了有效方法，显著提升了温度预测性能，但也存在一定局限性，需进一步研究和优化。

Abstract: Many Numerical Weather Prediction (NWP) models and their associated Model
Output Statistics (MOS) are available. Combining all of these predictions in an
optimal way is however not straightforward. This can be achieved thanks to
Expert Aggregation (EA) [Cesa-Bianchi and Lugosi, 2006, Gaillard et al., 2014,
Wintenberger, 2024] which has many advantages, such as being online, being
adaptive to model changes and having theoretical guarantees. Hence, in this
paper, we propose a method for making deterministic temperature predictions
with EA strategies and show how this can improve temperature predictions, even
those of post processed NWP models. We also compare different EA strategies in
various settings and discuss certain limitations.

</details>


### [10] [Polynomial Eigenfunctions and Matrix Lyapunov Equations from Energy Balance Integrals](https://arxiv.org/abs/2506.15288)
*Netzer Moriya*

Main category: math.OC

TL;DR: 该研究建立了一个统一理论框架，将经典正交多项式系统与矩阵Lyapunov方程通过随机动力系统中的能量耗散物理联系起来，揭示了二者的对偶性。


<details>
  <summary>Details</summary>
Motivation: 旨在构建连接经典正交多项式与矩阵Lyapunov方程的数学物理桥梁，从能量耗散角度统一两类看似不相关的理论体系。

Method: 基于希尔伯特空间中的能量平衡原理，推导出包含谱几何与协方差动力学的主积分表示，并通过无限维能量积分的有限维投影重构经典矩阵方程。

Result: 证明了Zernike、Hermite等正交多项式与Lyapunov方程具有相同的能量耗散结构，且经典微分算子添加均匀耗散后仍保持多项式本征函数特性。

Conclusion: 该框架为随机动力系统提供了物理自洽的数学基础，揭示了对称性在决定方程结构中的核心作用，统一了谱方法与矩阵分析方法。

Abstract: We establish a unified theoretical framework that connects classical
orthogonal polynomial systems to matrix Lyapunov equations through the
fundamental physics of energy dissipation in stochastic dynamical systems.
Starting from the energy balance principle in infinite-dimensional Hilbert
spaces, we derive a master integral representation that naturally encompasses
both spectral geometry and covariance dynamics. The theory reveals that
established orthogonal polynomials (Zernike, Hermite, spherical harmonics) and
matrix Lyapunov equations are dual manifestations of the same underlying energy
dissipation structure. We provide rigorous mathematical foundations showing how
finite-dimensional projections of infinite-dimensional energy integrals
reproduce classical matrix equations, with specific structure determined by the
symmetries of noise processes. The framework demonstrates that adding uniform
dissipation to classical differential operators preserves their polynomial
eigenfunction structure while ensuring the energy balance conditions required
for physical consistency.

</details>


### [11] [Proximal Operators of Sorted Nonconvex Penalties](https://arxiv.org/abs/2506.15315)
*Anne Gagneux,Mathurin Massias,Emmanuel Soubies*

Main category: math.OC

TL;DR: 本文研究了稀疏信号恢复中的变量自动分组问题，提出了一类排序非凸惩罚方法，用于广义线性模型的正则化，并通过改进的PAV算法高效计算其近端算子。


<details>
  <summary>Details</summary>
Motivation: 为了解决稀疏信号恢复中的变量自动分组问题，研究排序非光滑惩罚在广义线性模型中的应用，以促进变量聚类并减少系数收缩。

Method: 采用排序非凸惩罚（如排序MCP、SCAD和Lq范数），区分弱凸和非凸两种情况：弱凸情况下使用PAV算法精确计算近端算子；非凸情况下对PAV算法进行轻微修改以高效求解。

Result: 实验证明，改进的PAV算法能有效计算非凸惩罚的近端算子，且提出的惩罚方法在多个实验中表现出实用价值。

Conclusion: 排序非凸惩罚方法在稀疏信号恢复中具有显著优势，改进的PAV算法为非凸近端算子的计算提供了高效解决方案，具有广泛的应用潜力。

Abstract: This work studies the problem of sparse signal recovery with automatic
grouping of variables. To this end, we investigate sorted nonsmooth penalties
as a regularization approach for generalized linear models. We focus on a
family of sorted nonconvex penalties which generalizes the Sorted L1 Norm
(SLOPE). These penalties are designed to promote clustering of variables due to
their sorted nature, while the nonconvexity reduces the shrinkage of
coefficients. Our goal is to provide efficient ways to compute their proximal
operator, enabling the use of popular proximal algorithms to solve composite
optimization problems with this choice of sorted penalties. We distinguish
between two classes of problems: the weakly convex case where computing the
proximal operator remains a convex problem, and the nonconvex case where
computing the proximal operator becomes a challenging nonconvex combinatorial
problem. For the weakly convex case (e.g. sorted MCP and SCAD), we explain how
the Pool Adjacent Violators (PAV) algorithm can exactly compute the proximal
operator. For the nonconvex case (e.g. sorted Lq with q in ]0,1[), we show that
a slight modification of this algorithm turns out to be remarkably efficient to
tackle the computation of the proximal operator. We also present new
theoretical insights on the minimizers of the nonconvex proximal problem. We
demonstrate the practical interest of using such penalties on several
experiments.

</details>


### [12] [Optimal Control of Thin-Film Flow on a Flexible Topography](https://arxiv.org/abs/2506.15340)
*S. Alrashidy,A. Kalogirou,D. Kalise,K. G. van der Zee*

Main category: math.OC

TL;DR: 本文提出了一种数学模型，用于优化控制受外力影响的柔性地形上的薄膜流动，包括薄膜破裂和气泡合并。通过非线性润滑方程和能量耗散定律，推导了最优控制条件，并采用数值方法验证了控制策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过优化外力控制柔性地形上的薄膜流动，实现薄膜轮廓的精确控制，特别是在薄膜破裂和气泡合并等复杂情况下。

Method: 建立了非线性润滑方程描述流体动力学，推导了全局能量耗散定律和最优控制条件。采用一阶隐式-显式（IMEX）时间步进方案处理非线性，并应用降梯度下降算法进行数值求解。

Result: 数值结果表明，优化控制策略能够精确控制薄膜轮廓，加速稳态收敛，减少不稳定性，稳定去湿过程，并满足预设轮廓要求。

Conclusion: 该模型和优化控制策略在薄膜流动控制中表现出高效性和稳定性，为复杂流体动力学问题提供了有效的解决方案。

Abstract: This work presents a mathematical model for the optimal control of thin-film
flows over a flexible topography influenced by an external force. Our thin-film
model allows for the rupture of films as well as the coalescence of bubbles.
The objective is to find the optimal distributed force acting on the topography
that minimises the differences between actual and desired thin-film profiles. A
nonlinear lubrication equation governing the fluid dynamics and appropriate
functional settings for this model are presented. It is also shown that this
system satisfies a global energy-dissipation law for a suitable energy
functional. Optimality conditions are derived for the solution of the
minimisation problem of a specified cost function across a time horizon. These
conditions are formulated at a continuous level as a system of coupled,
forward-backward PDEs, which are subsequently discretised for numerical
investigation. To ensure computational efficiency and stability, first-order
Implicit-Explicit (IMEX) time-stepping schemes are employed to handle the
nonlinearities in the model, and a reduced gradient descent algorithm is
applied to obtain a numerical approximation of the optimal control signal.
Numerical results illustrate that controlling the thin film, even during
rupture, achieves a precise film profile. This control strategy accelerates
convergence towards a steady state, reduces instabilities, stabilises dewetting
processes, and meets the desired profile specifications.

</details>


### [13] [Multi-Timescale Gradient Sliding for Distributed Optimization](https://arxiv.org/abs/2506.15387)
*Junhui Zhang,Patrick Jaillet*

Main category: math.OC

TL;DR: 本文提出了两种一阶方法MT-GS和AMT-GS，用于解决凸非光滑分布式优化问题，通过多时间尺度梯度滑动减少通信轮数，并实现不同代理子集以不同速率通信。


<details>
  <summary>Details</summary>
Motivation: 针对分布式优化中通信开销大的问题，旨在开发能够利用目标函数相似性、支持灵活通信速率且完全确定性的算法。

Method: 基于块可分解的原始-对偶公式和多时间尺度滑动方法，不同对偶块以不同速率更新，MT-GS和AMT-GS分别适用于Lipschitz连续和强凸目标函数。

Result: MT-GS需$O(\overline{r}A/\epsilon)$通信轮和$O(\overline{r}/\epsilon^2)$次梯度步，AMT-GS需$O(\overline{r}A/\sqrt{\epsilon\mu})$通信轮和$O(\overline{r}/(\epsilon\mu))$次梯度步，其中$\overline{r}$为对偶块平均更新率，$A$衡量局部函数相似性。

Conclusion: 所提算法在非光滑目标下实现了通信轮数对$A$的线性最优依赖，回答了Arjevani和Shamir (2015)的开放性问题。

Abstract: We propose two first-order methods for convex, non-smooth, distributed
optimization problems, hereafter called Multi-Timescale Gradient Sliding
(MT-GS) and its accelerated variant (AMT-GS). Our MT-GS and AMT-GS can take
advantage of similarities between (local) objectives to reduce the
communication rounds, are flexible so that different subsets (of agents) can
communicate at different, user-picked rates, and are fully deterministic. These
three desirable features are achieved through a block-decomposable primal-dual
formulation, and a multi-timescale variant of the sliding method introduced in
Lan et al. (2020), Lan (2016), where different dual blocks are updated at
potentially different rates.
  To find an $\epsilon$-suboptimal solution, the complexities of our algorithms
achieve optimal dependency on $\epsilon$: MT-GS needs
$O(\overline{r}A/\epsilon)$ communication rounds and
$O(\overline{r}/\epsilon^2)$ subgradient steps for Lipchitz objectives, and
AMT-GS needs $O(\overline{r}A/\sqrt{\epsilon\mu})$ communication rounds and
$O(\overline{r}/(\epsilon\mu))$ subgradient steps if the objectives are also
$\mu$-strongly convex. Here, $\overline{r}$ measures the ``average rate of
updates'' for dual blocks, and $A$ measures similarities between (subgradients
of) local functions. In addition, the linear dependency of communication rounds
on $A$ is optimal (Arjevani and Shamir 2015), thereby providing a positive
answer to the open question whether such dependency is achievable for
non-smooth objectives (Arjevani and Shamir 2015).

</details>


### [14] [Efficient Online Mirror Descent Stochastic Approximation for Multi-Stage Stochastic Programming](https://arxiv.org/abs/2506.15392)
*Junhui Zhang,Patrick Jaillet*

Main category: math.OC

TL;DR: 本文研究了多阶段随机规划问题的无约束和极小极大鞍点变体，提出了随机条件梯度预言机概念，并证明了镜像下降随机逼近算法的收敛性。通过半在线视角和异步实现，显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统多阶段随机规划中决策通过约束耦合，本文探索通过目标函数耦合的新方法，旨在降低计算复杂度并提升算法效率。

Method: 基于确定性镜像下降算法分析，引入随机条件梯度预言机；采用半在线视角延迟决策，实现异步镜像下降随机逼近算法。

Result: 算法在期望和高概率下均收敛；通过延迟决策使复杂度从阶段数的指数级降为线性级，显著提升计算效率。

Conclusion: 提出的随机条件梯度预言机和半在线方法有效解决了多阶段随机规划的计算难题，为大规模问题提供了可行解决方案。

Abstract: We study the unconstrained and the minimax saddle point variants of the
convex multi-stage stochastic programming problem, where consecutive decisions
are coupled through the objective functions, rather than through the
constraints. Based on the analysis of deterministic mirror descent algorithms
with inexact gradients, we introduce the idea of \textit{stochastic conditional
gradient oracles}, a multi-stage analog of the stochastic gradient oracles used
in (classical) stochastic programming. We show one approach to construct such
oracles and prove the convergence of the (accelerated) mirror descent
stochastic approximation, both in expectation and with high probability. To
further reduce the oracle complexity, we view the problem from a
\textit{semi-online} perspective, where the stage $t$ decision variables are
constructed $s$ stages in advance, instead of before stage $1$. We show that
the delay in decision making allows an asynchronous implementation of the
mirror descent stochastic approximation algorithms. By avoiding computing
solutions for scenarios that are inconsistent with information available during
stage $t$, the complexity is reduced from exponential to linear in the number
of stages.

</details>


### [15] [A polynomial projective algorithm for convex feasibility problems with positive-definite constraints](https://arxiv.org/abs/2506.15484)
*Sergei Chubanov*

Main category: math.OC

TL;DR: 本文研究了一类与自对偶锥相关的谱面投影变换，并提出了一种多项式时间算法来解决具有正定约束的凸可行性问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于改进现有凸可行性问题算法的复杂度，特别是在正定约束条件下，当方程数量不小于正半定锥的秩和时。

Method: 方法基于谱面的投影变换，通过迭代寻找可行解或生成有效不等式，利用势函数衡量解集与谱面中心的接近程度。

Result: 结果表明，该算法在特定条件下（方程数量≥正半定锥秩和）能够更精确地界定复杂度上界。

Conclusion: 结论指出，所提出的投影变换方法为处理正定约束的凸可行性问题提供了更高效的解决方案，优化了现有复杂度分析。

Abstract: We study a class of projective transformations of spectraplexes associated
with self-dual cones and, on this basis, propose a polynomial-time algorithm
for convex feasibility problems with positive definite constraints. At each
iteration of the algorithm, either a feasible solution is found or a suitable
valid inequality inducing a projective transformation allowing to bring the
solution set closer to the center of an associated spectraplex. The closeness
to the center is measured in terms of a potential function. The running time of
our algorithm makes the existing complexity bounds more precise for the case
when the number of equations linking the positive definite variable matrices is
not less than the sum of the ranks of the respective positive-semidefinite
cones.

</details>


### [16] [On Exact Solutions to the Linear Bellman Equation](https://arxiv.org/abs/2506.15527)
*David Ohlin,Richard Pates,Murat Arcak*

Main category: math.OC

TL;DR: 本文提出了线性算子动态系统最优控制的充分条件，可分布式求解Bellman方程，并将线性可解MDP重构为连续状态最优控制问题，扩展了半线性动态系统的应用范围。


<details>
  <summary>Details</summary>
Motivation: 研究旨在为线性算子动态系统提供显式求解Bellman方程的充分条件，并扩展线性可解MDP至连续状态空间，以处理输入非线性问题。

Method: 通过重构线性可解MDP为连续状态最优控制问题，验证其自然满足Bellman方程显式解条件，并推广至半线性动态系统。

Result: 证明了所提条件适用于线性与二次成本场景（如随机最短路径和线性二次调节器问题），并实现了Bellman方程的分布式显式解。

Conclusion: 该研究为线性及半线性动态系统提供了显式最优控制解的理论框架，扩展了现有方法在非线性输入场景的适用性。

Abstract: This paper presents sufficient conditions for optimal control of systems with
dynamics given by a linear operator, in order to obtain an explicit solution to
the Bellman equation that can be calculated in a distributed fashion. Further,
the class of Linearly Solvable MDP is reformulated as a continuous-state
optimal control problem. It is shown that this class naturally satisfies the
conditions for explicit solution of the Bellman equation, motivating the
extension of previous results to semilinear dynamics to account for input
nonlinearities. The applicability of the given conditions is illustrated in
scenarios with linear and quadratic cost, corresponding to the Stochastic
Shortest Path and Linear-Quadratic Regulator problems.

</details>


### [17] [Long run control of nonhomogeneous Markov processes](https://arxiv.org/abs/2506.15542)
*Łukasz Stettner*

Main category: math.OC

TL;DR: 论文研究了非齐次马尔可夫过程的平均奖励与风险敏感奖励泛函，证明了贝尔曼方程解的存在性、值函数对风险参数的连续性，以及控制收敛下的泛函稳定性。


<details>
  <summary>Details</summary>
Motivation: 针对非齐次马尔可夫控制过程，探索其单位时间平均奖励和风险敏感奖励泛函的理论性质，为随机控制提供数学基础。

Method: 通过构建合适的贝尔曼方程，运用泛函分析工具研究解的存在性，并分析风险参数连续性与控制收敛稳定性。

Result: 证明了贝尔曼方程解的存在性，展示了值函数对风险参数的连续性，确立了马尔可夫控制点态收敛下泛函的稳定性。

Conclusion: 该研究为非齐次马尔可夫控制系统的奖励优化问题提供了完整的理论框架，特别在风险敏感场景中具有应用价值。

Abstract: In the paper average reward per unit time and average risk sensitive reward
functionals are considered for controlled nonhomogeneous Markov processes.
Existence of solutions to suitable Bellman equations is shown. Continuity of
the value functions with respect to risk parameter is also proved. Finally
stability of functionals with respect to pointwise convergence of Markov
controls is studied.

</details>


### [18] [Primal-Dual Coordinate Descent for Nonconvex-Nonconcave Saddle Point Problems Under the Weak MVI Assumption](https://arxiv.org/abs/2506.15597)
*Iyad Walwil,Olivier Fercoq*

Main category: math.OC

TL;DR: 本文提出了两种新的原始-对偶算法（NC-PDHG和NC-SPDHG），用于解决非凸、非凹且非光滑的鞍点问题，并通过弱Minty变分不等式（MVI）条件证明其收敛性。数值实验验证了算法在逻辑回归和感知机回归等问题上的高效性。


<details>
  <summary>Details</summary>
Motivation: 设计适用于非凸非凹鞍点问题的坐标下降算法并证明其收敛性具有挑战性，这促使作者利用PEPit工具和自动化Lyapunov函数技术进行算法推导。

Method: NC-PDHG扩展了经典PDHG方法，而NC-SPDHG则结合随机外推坐标下降技术。两种算法在弱MVI参数满足温和条件时，采用自适应常数步长实现收敛。

Result: 数值实验表明，新算法在逻辑回归平方损失和感知机回归问题上具有线性收敛速度，且NC-SPDHG在凸凹最小二乘问题中与SAGA算法性能相当。

Conclusion: 该研究首次实现了非凸非凹鞍点问题的坐标下降算法，并通过计算机辅助分析工具PEPit解决了收敛性证明难题，为复杂优化问题提供了高效解决方案。

Abstract: We introduce two novel primal-dual algorithms for addressing nonconvex,
nonconcave, and nonsmooth saddle point problems characterized by the weak Minty
Variational Inequality (MVI). The first algorithm, Nonconvex-Nonconcave
Primal-Dual Hybrid Gradient (NC-PDHG), extends the well-known Primal-Dual
Hybrid Gradient (PDHG) method to this challenging problem class. The second
algorithm, Nonconvex-Nonconcave Stochastic Primal-Dual Hybrid Gradient
(NC-SPDHG), incorporates a randomly extrapolated primal-dual coordinate descent
approach, extending the Stochastic Primal-Dual Hybrid Gradient (SPDHG)
algorithm.
  To our knowledge, designing a coordinate-based algorithm to solve
nonconvex-nonconcave saddle point problems is unprecedented, and proving its
convergence posed significant difficulties. This challenge motivated us to
utilize PEPit, a Python-based tool for computer-assisted worst-case analysis of
first-order optimization methods. By integrating PEPit with automated Lyapunov
function techniques, we successfully derived the NC-SPDHG algorithm.
  Both methods are effective under a mild condition on the weak MVI parameter,
achieving convergence with constant step sizes that adapt to the structure of
the problem. Numerical experiments on logistic regression with squared loss and
perceptron-regression problems validate our theoretical findings and show their
efficiency compared to existing state-of-the-art algorithms, where linear
convergence is observed. Additionally, we conduct a convex-concave
least-squares experiment to show that NC-SPDHG performs competitively with
SAGA, a leading algorithm in the smooth convex setting.

</details>


### [19] [Heavy Ball and Nesterov Accelerations with Hessian-driven Damping for Nonconvex Optimization](https://arxiv.org/abs/2506.15632)
*N. Hadjisavvas,F. Lara,R. T. Marcavillaca,P. T. Vuong*

Main category: math.OC

TL;DR: 本文研究了针对强拟凸函数的二阶动态系统，提出了两种离散时间梯度算法（带Hessian修正的Heavy Ball方法和自适应动量Nesterov加速方法），通过抑制经典动量法的振荡现象实现了线性收敛，并通过数值实验验证了结果。


<details>
  <summary>Details</summary>
Motivation: 针对强拟凸函数优化问题，经典动量方法常出现振荡现象。研究旨在通过连续时间动态系统与离散优化算法的结合，设计更稳定的收敛算法。

Method: 基于Hessian驱动阻尼的二阶连续系统，通过时间离散化导出两种算法：1) 含曲率修正项的Heavy Ball方法；2) 含局部曲率自适应项的Nesterov型加速方法。

Result: 理论证明两种算法在迭代序列和函数值上均能线性收敛至最优解，数值实验验证了其优于经典动量方法的稳定性。

Conclusion: 该研究揭示了连续动态系统与离散算法在强拟凸优化中的深刻联系，所提算法通过Hessian阻尼有效抑制振荡，为非凸优化提供了新思路。

Abstract: In this work, we investigate a second-order dynamical system with
Hessian-driven damping tailored for a class of nonconvex functions called
strongly quasiconvex. Buil\-ding upon this continuous-time model, we derive two
discrete-time gra\-dient-based algorithms through time discretizations. The
first is a Heavy Ball method with Hessian correction, incorporating
cur\-va\-tu\-re-dependent terms that arise from discretizing the Hessian
damping component. The second is a Nesterov-type accelerated method with
adaptive momentum, fea\-tu\-ring correction terms that account for local
curvature. Both algorithms aim to enhance stability and convergence
performance, particularly by mi\-ti\-ga\-ting oscillations commonly observed in
cla\-ssi\-cal momentum me\-thods. Furthermore, in both cases we establish
li\-near convergence to the optimal solution for the iterates and functions
values. Our approach highlights the rich interplay between continuous-time
dynamics and discrete optimization algorithms in the se\-tting of strongly
quasiconvex objectives. Numerical experiments are presented to support obtained
results.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [20] [Special Cases of the Shafarevich Conjecture for Complete Intersections in Abelian Varieties](https://arxiv.org/abs/2506.14935)
*Frank Lu*

Main category: math.NT

TL;DR: 本文利用Lawrence-Venkatesh方法，证明了数域$K$上某些阿贝尔簇中超曲面完全交的Shafarevich猜想。关键创新包括计算这些完全交的欧拉示性数，以及证明其Hodge结构变体的单值群大性质。


<details>
  <summary>Details</summary>
Motivation: 研究数域上阿贝尔簇中完全交的Shafarevich猜想，旨在深化对算术几何中这类特殊代数簇的理解。

Method: 采用Lawrence-Venkatesh方法，核心是计算特定欧拉示性数，并通过将单值群问题转化为Tannaka群问题，最终归结为组合陈述进行证明。

Result: 成功证明了特定完全交的Shafarevich猜想，并建立了其Hodge结构变体的单值群大性质。

Conclusion: 该工作不仅推进了Shafarevich猜想的研究，所发展的单值群技术为相关算术几何问题提供了新工具。

Abstract: In this paper, we prove the Shafarevich conjecture for certain complete
intersections of hypersurfaces in abelian varieties defined over a number field
$K$ using the Lawrence-Venkatesh method. The main new inputs we need are
computation of certain Euler characteristics of these complete intersections
and a big monodromy statement for the variation of Hodge structure arising from
the middle cohomology of a family of such complete intersections. Following
\cite{ls25}, we prove the latter by relating this monodromy statement to a
statement about Tannaka groups, which we then convert into a combinatorial
statement.

</details>


### [21] [Triangular and tetrahedral number differences of sumset sizes in additive number theory](https://arxiv.org/abs/2506.15015)
*Melvyn B. Nathanson*

Main category: math.NT

TL;DR: 本文研究了整数有限集合的和集大小分布，发现四元集合的流行和集大小呈现与三角数和四面体数相关的意外模式。


<details>
  <summary>Details</summary>
Motivation: 以往研究主要关注极小和集（Freiman定理）或极大和集（Sidon集与$B_h$集），本文旨在探索整数有限集合和集大小的完整分布范围。

Method: 通过分析不同大小整数集合的和集分布，特别聚焦于四元集合的流行和集尺寸。

Result: 发现四元集合的流行和集大小分布呈现出与三角数及四面体数相关的数学模式。

Conclusion: 该研究揭示了整数集合和集尺寸分布中未被注意的数学规律，为组合数论提供了新的研究方向。

Abstract: The study of sums of finite sets of integers has mostly concentrated on sets
with very small sumsets (Freiman's theorem and related work) and on sets with
very large sumsets (Sidon sets and $B_h$-sets). This paper considers the full
range of sumset sizes of finite sets of integers and an unexpected pattern
(related to the triangular and tetrahedral numbers) that appears in the
distribution of popular sumset sizes of sets of size 4.

</details>


### [22] [On the Modern Structure of the Gauss-Landau Theorem](https://arxiv.org/abs/2506.15101)
*Manuel M. Aguilera*

Main category: math.NT

TL;DR: 该论文形式化了高斯-兰道定理，提出了一种统一的质因数分解方法来计算有限非零整数集的最大公约数(GCD)和最小公倍数(LCM)。


<details>
  <summary>Details</summary>
Motivation: 尽管这些定理在初等数论教学中常被用作启发式方法或技巧，但文献中尚未对其进行明确的形式化或命名。

Method: 通过质因数分解的统一框架，对GCD和LCM计算进行形式化处理。

Result: 建立了一个完整的理论体系，为高斯-兰道定理提供了严格的数学基础。

Conclusion: 该形式化工作有助于提升数学教学和研究中的理解与应用。

Abstract: We formalize the Gauss-Landau theorem, providing a unified prime
factorization approach to computing the GCD and LCM of finite nonzero integer
sets. Although commonly used as a heuristic or technique in elementary number
theory education, these theorems have not been explicitly formalized or named
in the literature. This formalization aims to enhance understanding and
facilitate adoption in mathematical instruction and research.

</details>


### [23] [Characterizing infinite torsion subgroups of the circle through arithmetic-type sequences](https://arxiv.org/abs/2506.15257)
*Ayan Ghosh,Pratulananda Das*

Main category: math.NT

TL;DR: 本文扩展了Das等人的工作，证明算术型序列对应的特征子群可数当且仅当其是挠群，且任何无限挠子群可由有界比的算术型序列表征，同时指出Eggleston定理的二分性在广义算术型序列中不成立。


<details>
  <summary>Details</summary>
Motivation: 基于Das等人对算术型序列特征子群结构的研究，进一步探索这类子群的计数性与挠性关系，并验证Eggleston定理二分性在更广泛序列类中的适用性。

Method: 通过分析算术型序列的代数特性，结合挠群的结构理论，采用反例构造法验证广义序列的二分性失效。

Result: 1. 算术型序列特征子群可数等价于其为挠群；2. 圆周的无限挠子群可由有界比算术型序列表征；3. Eggleston定理的二分性不适用于广义算术型序列。

Conclusion: 研究揭示了算术型序列特征子群的挠性与可数性之间的深刻联系，同时突破了经典二分性结论的适用范围，为后续非标准序列表征理论提供了新方向。

Abstract: In a recent work [Das et al., Bull. Sci. Math. 199 (2025), 103580], the
structure of characterized subgroups corresponding to arithmetic-type sequences
was investigated. Building upon this work, we further show that a characterized
subgroup associated with an arithmetic-type sequence is countable if and only
if it is torsion. Further we prove that any infinite torsion subgroup of the
circle can be characterized by an arithmetic-type sequence with bounded ratio.
Moreover, our findings demonstrate that the dichotomy observed in Eggleston's
theorem [Theorem 16, Eggleston, Proc. Lond. Math. Soc. 54(2) (1952), 42--93]
for arithmetic sequences does not extend, in general, to the broader class of
arithmetic-type sequences.

</details>


### [24] [Metric Poissonian pair correlationa and additive energy](https://arxiv.org/abs/2506.15274)
*Tanmoy Bera,E. Malavika*

Main category: math.NT

TL;DR: 本文证明了当自然数严格递增序列$(a_n)$的加性能量小于$N^3/(\log N)^C$（$C\geq13.155$）时，对于几乎所有实数$\alpha$，序列$(\{a_n\alpha\})$具有泊松对相关性。


<details>
  <summary>Details</summary>
Motivation: 研究严格递增自然数序列的加性能量与其对相关性的关系，为Bloom和Walker[3]建立的加性能量界中的指数$C$提供下界。

Method: 通过分析序列的加性能量，结合对数因子$C$的约束条件，证明其对相关性的影响。

Result: 当$C\geq13.155$时，序列$(\{a_n\alpha\})$对几乎所有实数$\alpha$具有泊松对相关性。

Conclusion: 该结果为加性能量界中的指数$C$提供了明确的下界，进一步揭示了序列加性能量与对相关性之间的深刻联系。

Abstract: In this article we prove that if the additive energy of a strictly increasing
sequence $(a_n)$ of natural numbers is less than $N^3/(\log N)^C$ for some
$C\geq13.155$, then $(\{a_n\alpha\})$ has Poissonian pair correlation for
almost all $\alpha\in\mathbb{R}.$ This provides a lower bound for the exponent
$C$ in the additive energy bound established by Bloom and Walker[3].

</details>


### [25] [Singular intersections on families of abelian varieties](https://arxiv.org/abs/2506.15344)
*Nicola Ottolini*

Main category: math.NT

TL;DR: 在代数几何中，证明了在阿贝尔概形中，曲线与真平坦子群概形相切的点集是有限的。


<details>
  <summary>Details</summary>
Motivation: 研究曲线在阿贝尔概形中与子群概形的切点问题，属于不可能交问题框架，是相对Pink猜想的一个变体。

Method: 通过代数几何和数论的方法，分析曲线$\mathcal{C}$在阿贝尔概形$\mathcal{A}$中的几何性质及其与子群概形的切点。

Result: 证明了曲线$\mathcal{C}$与$\mathcal{A}$的真平坦子群概形相切的点集是有限的。

Conclusion: 该结果为不可能交问题提供了新的理论支持，扩展了相对Pink猜想在阿贝尔概形中的应用。

Abstract: Let $S$ be a smooth irreducible curve defined over $\overline{\mathbb{Q}}$,
let $\mathcal{A}$ be an abelian scheme over $S$ and $\mathcal{C}$ a curve
inside $\mathcal{A}$, both defined over $\overline{\mathbb{Q}}$. In this paper
we prove that the set of points in which $\mathcal{C}$ intersects proper flat
subgroup schemes of $\mathcal{A}$ tangentially is finite. This fits in the
framework of the so-called problems of unlikely intersections, and can be seen
as a variation of the relative Pink conjecture for abelian varieties.

</details>


### [26] [A categorical formulation of the Deligne-Terasoma approach to double shuffle theory](https://arxiv.org/abs/2506.15348)
*Benjamin Enriquez,Khalef Yaddaden*

Main category: math.NT

TL;DR: 本文引入具有分解结构的双模(BFS)概念，证明其可诱导代数态射，并为双洗牌理论中的Betti与de Rham谐波余积提供几何解释。


<details>
  <summary>Details</summary>
Motivation: 旨在通过BFS结构统一理解双洗牌理论中Betti与de Rham谐波余积的几何构造。

Method: 提出具有分解结构的双模(BFS)新概念，建立其与代数态射的关联，并关联至双洗牌理论的几何框架。

Result: 证明BFS结构自然诱导代数态射，且该框架可解释文献\cite{DeT, EF1, EF2, EF3}中的几何构造。

Conclusion: BFS结构为双洗牌理论中的谐波余积提供了统一的代数-几何解释框架。

Abstract: In this paper, we introduce the notion of a bimodule with a factorization
structure (BFS) and show that such a structure gives rise to an algebra
morphism. We then prove that this framework offers an interpretation of the
geometric construction underlying both the Betti and de Rham harmonic
coproducts of the double shuffle theory developed in \cite{DeT, EF1, EF2, EF3}.

</details>


### [27] [Patterns in Growth and Distribution of Unbounded Prime Number Walks](https://arxiv.org/abs/2506.15357)
*Alberto Fraile,Daniel Fernández,Roberto Martínez,Theophanes E. Raptis*

Main category: math.NT

TL;DR: 本文证明了先前提出的素数行走（PW）覆盖面积无界的猜想，并深入探讨了PW的新性质与衍生问题。


<details>
  <summary>Details</summary>
Motivation: 基于前期工作中素数行走在方格上的数值结果，验证其覆盖面积无界的主要猜想，并进一步探索PW的数学特性。

Method: 通过理论分析与数值验证相结合的方法，研究素数行走在二维网格上的扩展行为及其几何性质。

Result: 证实了素数行走的覆盖面积无界性，并揭示了该过程中涌现的新数学问题与潜在规律。

Conclusion: 素数行走的无界性为离散动力系统研究提供了新视角，其衍生问题值得进一步理论探索。

Abstract: In our previous work, we defined a prime walk (PW) on a square grid and
presented several intriguing numerical results. Here, we demonstrate the main
conjecture presented there, namely, that the area covered by the prime walk is
unbounded. Taking this fact into account, we examine in further detail the
properties of the PW and explore new questions that arise naturally in this
analysis.

</details>


### [28] [No Nowhere Continuous Function Maps all Non-Normal Numbers to Normal Numbers](https://arxiv.org/abs/2506.15422)
*Chokri Manai*

Main category: math.NT

TL;DR: 本文证明了不存在非空开区间和非常数连续函数能将所有非正规数映射为正规数，并构造了一个将正规数映射为非正规数的康托型函数。


<details>
  <summary>Details</summary>
Motivation: 研究非正规数集$\mathcal{N}^c$的性质，探讨是否存在连续函数将其映射为正规数集$\mathcal{N}$，以揭示$\mathcal{N}^c$的丰富性。

Method: 通过反证法否定存在性，并采用康托型构造法显式构建一个非常数连续函数$\hat{C}$。

Result: 不存在满足条件的开区间和连续函数；但构造出了将正规数映射为非正规数的函数$\hat{C}$。

Conclusion: 非正规数集$\mathcal{N}^c$具有独特的不可映射性，而正规数集$\mathcal{N}$则不具备此性质，这一对比凸显了$\mathcal{N}^c$的复杂结构。

Abstract: In this work, we consider the set of non-normal numbers $\mathcal{N}^c$ and
ask if there is a non-empty open interval $I$ and a nowhere constant continuous
function $\phi: I \to \rr$ which maps all non-normal numbers to normal numbers,
i.e., $\varphi(I \cap \mathcal{N}^c) \subset \mathcal{N}.$ We answer this
question negatively. This result can be seen as a further manifestation of the
richness of the null set $\mathcal{N}^c$. Surprisingly, the "bigger" set of
normal numbers $\mathcal{N}$ does not share this property and we will give an
explicit Cantor-type construction of a nowhere constant continuous function
$\hat{C}$, which maps all normal numbers to non-normal numbers.

</details>


### [29] [Evaluation of Modular Polynomials from Supersingular Elliptic Curves](https://arxiv.org/abs/2506.15429)
*Maria Corte-Real Santos,Jonathan Komada Eriksen,Antonin Leroux,Michael Meyer,Lorenz Panny*

Main category: math.NT

TL;DR: 本文提出了两种基于CRT方法和超奇异曲线的模多项式评估新算法，具有最优内存需求，并在特定条件下达到已知最优时间复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究旨在改进模多项式评估算法的效率和内存使用，特别是在处理大参数时，以解决现有算法在内存需求上的不足。

Method: 第一种算法结合了Sutherland的混合算法和Leroux的超奇异曲线方法；第二种算法则专注于在超奇异$j$-不变量上的高效评估，实现了在$\ell$和$\log j$上的二次复杂度。

Result: 第一种算法的时间复杂度与已知最优算法相当，但内存需求最优；第二种算法首次在通用算法中实现了$\ell$的二次复杂度和最优内存需求。

Conclusion: 本文提出的算法不仅在理论上具有优势，还通过优化实现展示了实际应用潜力，同时方法可扩展至其他类型模多项式的计算。

Abstract: We present several new algorithms to evaluate modular polynomials of level
$\ell$ modulo a prime $p$ on an input $j$.
  More precisely, we introduce two new generic algorithms, sharing the
following similarities: they are based on a CRT approach; they make use of
supersingular curves and the Deuring correspondence; and, their memory
requirements are optimal.
  The first algorithm combines the ideas behind a hybrid algorithm of
Sutherland in 2013 with a recent algorithm to compute modular polynomials using
supersingular curves introduced in 2023 by Leroux. The complexity (holding
around several plausible heuristic assumptions) of the resulting algorithm
matches the $\Tilde{O}(\ell^3 \log^{3} \ell + \ell \log p)$ time complexity of
the best known algorithm by Sutherland, but has an optimal memory requirement.
  Our second algorithm is based on a sub-algorithm that can evaluate modular
polynomials efficiently on supersingular $j$-invariants defined over $\Fp$, and
achieves heuristic complexity quadratic in both $\ell$ and $\log j$, and linear
in $\log p$. In particular, it is the first generic algorithm with optimal
memory requirement to obtain a quadratic complexity in~$\ell$.
  Additionally, we show how to adapt our method to the computation of other
types of modular polynomials such as the one stemming from Weber's function.
  Finally, we provide an optimised implementation of the two algorithms
detailed in this paper, though we emphasise that various modules in our
codebase
  may find applications outside their use in this paper.

</details>


### [30] [Long strings of composite values of polynomials and a basis of order 2](https://arxiv.org/abs/2506.15641)
*Artyom Radomskii*

Main category: math.NT

TL;DR: 该论文证明了对于任意具有正首项且在$\mathbb{Q}$上不可约的多项式$f: \mathbb{Z}\to \mathbb{Z}$，当$N$足够大时，存在两个连续正整数串$I_{1}$和$I_{2}$，使得$I_{1}\cup I_{2} \subset [1, N]$，且$f(n)$在$I_{1}\cup I_{2}$上均为合数。


<details>
  <summary>Details</summary>
Motivation: 扩展了[5]中关于$f(n)=n$的结果，研究更一般的多项式$f$在连续整数区间上的合数性质。

Method: 通过构造两个长度为$m = [(\log N) (\log \log N)^{1/325525}]$的连续整数串$I_{1}$和$I_{2}$，并证明当$N$足够大时，$f(n)$在这些区间内均为合数。

Result: 证明了对于满足条件的多项式$f$，存在两个连续整数串$I_{1}$和$I_{2}$，使得$f(n)$在这些区间内均为合数，且$I_{1}\cup I_{2} \subset [1, N]$。

Conclusion: 该结果推广了[5]中的结论，为更一般的多项式在连续整数区间上的合数分布提供了理论支持。

Abstract: We show that for any polynomial $f: \mathbb{Z}\to \mathbb{Z}$ with positive
leading coefficient and irreducible over $\mathbb{Q}$, if $N$ is large enough
then there are two strings of consecutive positive integers
$I_{1}=\{n_1-m,\ldots, n_1+m\}$ and $I_{2}=\{n_2-m, \ldots, n_2+m\}$, where $m
= [(\log N) (\log \log N)^{1/325525}]$, such that $I_{1}\cup I_{2} \subset [1,
N]$, $N = n_1 + n_2$, and $f(n)$ is composite for any $n\in I_{1}\cup I_{2}$.
This extends the result in [5] which showed the same result but with $f(n)=n$.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [31] [Class of extensions of real field and their topological properties](https://arxiv.org/abs/2506.14838)
*E. V. Alexandrov*

Main category: math.LO

TL;DR: 该论文定义了实数域的适当扩展类，并研究了这些扩展的拓扑性质。这些扩展可以是连通的（此时集合对二元运算不封闭）或非连通的（此时扩展为线性有序域），未来可应用于构建能感知零勒贝格测度集的测度。


<details>
  <summary>Details</summary>
Motivation: 研究实数域扩展的拓扑性质，为构建新型测度理论奠定基础，特别是能够识别零勒贝格测度集的测度。

Method: 通过定义实数域的适当扩展类，分析其连通性与二元运算封闭性的关系，并考察线性有序域的结构特性。

Result: 发现连通扩展对加法乘法不封闭，非连通扩展形成线性有序域，为测度构造提供了新的数学工具。

Conclusion: 实数域扩展的拓扑分类揭示了运算封闭性与有序性的内在联系，未来可应用于革新测度论中对零测集的处理方式。

Abstract: Proper classes of extensions of real field was defined and topological
properties of these extensions were studied. These extensions can be connected,
in this case such set is not closed under binary operations (addition and
multiplication), and not connected, in this case this extension is linearly
ordered field. In the future these constructions can be applied to building
measure that "feels" set of zero Lebesgue measure.

</details>


### [32] [Definability of complex functions in o-minimal structures](https://arxiv.org/abs/2506.15119)
*Adele Padgett,Patrick Speissegger*

Main category: math.LO

TL;DR: 证明了$\mathbf{an}^*$和$\mathcal{G}$类函数的全纯延拓在o-极小结构$\mathbb{R}_{\mathrm{an}^*}$和$\mathbb{R}_{\mathcal{G}}$中可定义，并给出了最优复域。应用包括描述黎曼$\zeta$函数和$\Gamma$函数在相应o-极小扩张中的最优可定义域。


<details>
  <summary>Details</summary>
Motivation: 研究特定函数类在全纯延拓后的可定义性，为复分析函数在o-极小结构中的模型论性质提供理论基础。

Method: 通过构造复域并证明其最优性，结合o-极小结构理论分析函数的可定义性。

Result: 确定了$\mathbf{an}^*$和$\mathcal{G}$类函数全纯延拓的最优可定义复域，并应用于黎曼$\zeta$函数和$\Gamma$函数。

Conclusion: 该研究为复变函数在o-极小结构中的可定义性提供了具体实例和理论框架，拓展了模型论与复分析的交叉研究。

Abstract: We prove that some holomorphic continuations of functions in the classes
$\mathbf{an}^*$ and $\mathcal{G}$ are definable in the o-minimal structures
$\mathbb{R}_{\mathrm{an}^*}$ and $\mathbb{R}_{\mathcal{G}}$ respectively. More
specifically, we give complex domains on which the holomorphic continuations
are definable, and show they are optimal. As an application, we describe
optimal domains on which the Riemann $\zeta$ function is definable in o-minimal
expansions of $\mathbb{R}_{\mathrm{an}^*,\exp}$ and on which the $\Gamma$
function is definable in o-minimal expansions of
$\mathbb{R}_{\mathcal{G},\exp}$.

</details>


### [33] [$Σ^1_3$ sets in the Sacks model](https://arxiv.org/abs/2506.15308)
*Jonathan Schilhan*

Main category: math.LO

TL;DR: 在迭代Sacks模型中，证明了$\Sigma^1_3$集的Mansfield-Solovay定理成立，表明所有$\mathbf{\Sigma}^1_3$集都是Marczewski可测的，且Bernstein集的最优复杂度为$\Delta^1_4$。


<details>
  <summary>Details</summary>
Motivation: 研究迭代Sacks模型中Mansfield-Solovay定理的适用性，特别是在$\Sigma^1_3$集上的表现，以及Bernstein集的复杂度问题。

Method: 基于Kanovei的结果，在迭代Sacks模型中进行证明，并探讨了在投影层次非平凡级别上分离Mansfield-Solovay定理的方法。

Result: 在迭代Sacks模型中，$\Sigma^1_3$集的Mansfield-Solovay定理成立，所有$\mathbf{\Sigma}^1_3$集均为Marczewski可测，且Bernstein集的最优复杂度为$\Delta^1_4$。

Conclusion: 研究结果扩展了Mansfield-Solovay定理的应用范围，为投影层次中集合的复杂度和可测性提供了新的理论支持。

Abstract: We show that in the iterated Sacks model over the constructible universe the
Mansfield-Solovay Theorem holds for $\Sigma^1_3$ sets. In particular, every
$\mathbf{\Sigma}^1_3$ set is Marczewski measurable and the optimal complexity
for a Bernstein set is $\Delta^1_4$. Based on a result by Kanovei, we also
briefly show how to separate the Mansfield-Solovay Theorem at non-trivial
levels of the projective hierarchy.

</details>


### [34] [Strongly First Order Disjunctive Embedded Dependencies in Team Semantics](https://arxiv.org/abs/2506.15367)
*Pietro Galliani*

Main category: math.LO

TL;DR: 本文研究了团队语义学中一阶逻辑的扩展问题，特别关注了那些不会增加一阶团队语义表达能力的域无关析取嵌入式依赖。


<details>
  <summary>Details</summary>
Motivation: 团队语义学是一阶逻辑的推广，允许通过新型原子描述变量间的依赖关系。这些扩展中，部分能增强表达能力，部分则不能。研究旨在识别那些不增加表达能力的依赖类型。

Method: 作者聚焦于析取嵌入式依赖（DEDs），这是一类在数据库理论中广泛研究的依赖关系。通过分析这些依赖在团队语义中的表现，来区分其表达能力。

Result: 研究提供了对域无关析取嵌入式依赖的刻画，明确了哪些依赖在添加到一阶团队语义时不会增强其表达能力。

Conclusion: 该工作为团队语义学中依赖关系的表达能力提供了理论界限，有助于理解哪些依赖类型可以安全地引入而不改变逻辑的表达能力。

Abstract: First Order Team Semantics is a generalization of Tarskian Semantics in which
formulas are satisfied with respect to sets of assignments. In Team Semantics,
it is possible to extend First Order Logic via new types of atoms that describe
dependencies between variables; some of these extensions are strictly more
expressive than First Order Logic, while others are reducible to it.
  Many of the atoms studied in Team Semantics are inspired by Database Theory
and belong in particular to the class of Disjunctive Embedded Dependencies, a
very general family of dependencies that contains most of the dependencies of
practical interest in the study of databases.
  In this work, I provide a characterization for the (domain-independent)
Disjunctive Embedded Dependencies that fail to increase the expressive power of
First-Order Team Semantics when added to it.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [35] [Factorizations in Geometric Lattices](https://arxiv.org/abs/2506.14892)
*Alex Aguila,Elvis Cabrera,Jyrko Correa-Morris*

Main category: math.CO

TL;DR: 本文研究了与有限集$X$的划分格$\Pi(X)$同构的几何格中的原子分解，探讨了原子性在这些格中的作用，并提出了一个递归公式来枚举特定红色原子的秩-$j$划分。


<details>
  <summary>Details</summary>
Motivation: 研究几何格中的原子分解，特别是与划分格$\Pi(X)$同构的格，以深化对格论和组合数学中基本结构的理解。

Method: 首先分析了函数$\mathfrak{N}\colon \Pi(X) \rightarrow \mathbb{N}$的主要特性，然后考察了一组特殊的原子（红色原子$\mathcal{R}$），并推导了枚举秩-$j$划分的递归公式$\pmb{\pi}(X, j, s, \mathcal{R})$。

Result: 提出了一个递归公式$\pmb{\pi}(X, j, s, \mathcal{R})$，用于计算可由$s$个红色原子连接表示的秩-$j$划分的数量。

Conclusion: 通过研究几何格中的原子分解，特别是红色原子的作用，本文为划分格$\Pi(X)$的分解理论提供了新的工具和见解。

Abstract: This article investigates atomic decompositions in geometric lattices
isomorphic to the partition lattice $\Pi(X)$ of a finite set $X$, a fundamental
structure in lattice theory and combinatorics. We explore the role of atomicity
in these lattices, building on concepts introduced by D.D. Anderson, D.F.
Anderson, and M. Zafrullah within the context of factorization theory in
commutative algebra. As part of the study, we first examine the main
characteristics of the function $\mathfrak{N}\colon \Pi(X) \rightarrow
\mathbb{N}$, which assigns to each partition $\pi$ the number of minimal atomic
decompositions of $\pi$. We then consider a distinguished subset of atoms,
$\mathcal{R}$, referred to as the set of red atoms, and derive a recursive
formula for $\pmb{\pi}(X, j, s, \mathcal{R})$, which enumerates the rank-$j$
partitions expressible as the join of exactly $s$ red atoms.

</details>


### [36] [Hamiltonian connectivity of some base-cobase graphs](https://arxiv.org/abs/2506.15049)
*Leonardo Martínez-Sandoval,Kolja Knauer*

Main category: math.CO

TL;DR: 该研究探讨了拟阵基-对偶基图的哈密顿连通性，证明了某些特殊类别的拟阵（如格路径拟阵的串并联扩展、轮形拟阵）具有此性质，但通过正则拟阵$R_{10}$给出了Farber等人问题的反例。


<details>
  <summary>Details</summary>
Motivation: Naddef与Pulleyblank（1984）证明拟阵基图的$1$-骨架要么是超立方体，要么是哈密顿连通的。Farber等人（1985）提出是否可将此性质推广到基-对偶基图，这是本研究的核心动机。

Method: 采用多面体方法分析格路径拟阵的串并联扩展的基-对偶基图；通过构造性证明验证轮形拟阵与漩涡拟阵的哈密顿连通性；利用正则拟阵$R_{10}$作为反例工具。

Result: 1. 格路径拟阵串并联扩展的基-对偶基图具有哈密顿连通性；\n2. 轮形与漩涡拟阵的基-对偶基图同样满足该性质；\n3. 正则拟阵$R_{10}$的基-对偶基图不满足哈密顿连通性，否定了Farber等人的猜想。

Conclusion: 拟阵基-对偶基图的哈密顿连通性仅适用于特定类别（如格路径拟阵扩展、轮形拟阵），而$R_{10}$的存在表明该性质无法普遍推广，为拟阵结构理论提供了新的边界条件。

Abstract: There has been wide interest in understanding which properties of base graphs
of matroids extend to base-cobase graphs of matroids. A significant result of
Naddef and Pulleyblank (1984) shows that the $1$-skeleton of any
$(0,1)$-polytope is either a hypercube, or Hamiltonian-connected, i.e. there is
a Hamiltonian path connecting any two vertices. In particular, this is true for
base graphs of matroids. A natural question raised by Farber, Richter, and
Shank (1985) is whether this extends to base-cobase graphs.
  First, we use the polytopal approach to show Hamiltonian connectivity of
base-cobase graphs of series-parallel extensions of lattice path matroids. On
the other hand, we show that this method extends to only very special classes
related to identically self-dual matroids. Second, we show that base-cobase
graphs of wheels and whirls are Hamiltonian connected. Last, we show that the
regular matroid $R_{10}$ yields a negative answer to the question of Farber,
Richter, and Shank.

</details>


### [37] [Short monochromatic odd cycles](https://arxiv.org/abs/2506.14910)
*Oliver Janzer,Fredy Yip*

Main category: math.CO

TL;DR: 本文证明了在完全图$K_{2^k+1}$的任意$k$边着色中，存在长度至多为$O(k^{3/2}2^{k/2})$的单色奇环，显著改进了此前的最佳上界。


<details>
  <summary>Details</summary>
Motivation: 1973年Erd\H{o}s和Graham提出的公开问题：估计最小的$L(k)$使得任何$K_{2^k+1}$的$k$边着色都包含长度不超过$L(k)$的单色奇环。最近Gir\~ao和Hunter获得了首个非平凡上界$O(\frac{2^k}{k^{1-o(1)}})$。

Method: 结合代数组合学和逼近论的工具，构建新的证明方法。

Result: 证明了指数级改进的上界$L(k)=O(k^{3/2}2^{k/2})$，比此前结果优化了多项式因子。

Conclusion: 该研究通过创新方法显著推进了Erd\H{o}s-Graham问题的解决，为极值图论中的单色子结构问题提供了新视角。

Abstract: It is easy to see that every $k$-edge-colouring of the complete graph on
$2^k+1$ vertices contains a monochromatic odd cycle. In 1973, Erd\H{o}s and
Graham asked to estimate the smallest $L(k)$ such that every $k$-edge-colouring
of $K_{2^k+1}$ contains a monochromatic odd cycle of length at most $L(k)$.
Recently, Gir\~ao and Hunter obtained the first nontrivial upper bound by
showing that $L(k)=O(\frac{2^k}{k^{1-o(1)}})$, which improves the trivial bound
by a polynomial factor. We obtain an exponential improvement by proving that
$L(k)=O(k^{3/2}2^{k/2})$. Our proof combines tools from algebraic combinatorics
and approximation theory.

</details>


### [38] [Some remarks on Folkman graphs for triangles](https://arxiv.org/abs/2506.14942)
*Eion Mulrenin*

Main category: math.CO

TL;DR: 本文研究了基于Hermitian单位几何图的Folkman定理类似性质，证明了对于所有素数幂$q \geq 4$，存在一个208顶点的图具有"准Folkman"性质，并展示了随机破坏$K_4$后仍保持Ramsey性质的高概率。


<details>
  <summary>Details</summary>
Motivation: Folkman定理中$f(2,3,4)$的定量研究极为困难，当前记录为$f(2,3,4) \leq 786$。本文旨在探索有限几何图的类Folkman性质，以提供新的构造方法。

Method: 利用射影平面上Hermitian单位几何图$H_q$，分析其三角形子集$\mathcal{T}_q$的性质，并通过随机破坏$K_4$的方式验证Ramsey性质的保持。

Result: 对于所有素数幂$q \geq 4$，$H_q$存在不生成$K_4$的三角形子集$\mathcal{T}_q$，且任何二色边着色均产生$\mathcal{T}_q$中的单色三角形。$q=4$时构造出208顶点的图。

Conclusion: 几何图$H_q$提供了新的"准Folkman"图构造，随机破坏$K_4$后仍大概率保持Ramsey性质，为相关极值问题开辟了新途径。

Abstract: Folkman's theorem asserts the existence of graphs $G$ which are $K_4$-free,
but which have the property that every two-coloring of $E(G)$ contains a
monochromatic triangle. The quantitative aspects of $f(2,3,4)$, the least $n$
such that there exists an $n$-vertex graph with both properties above, are
notoriously difficult; a series of improvements over the span of two decades
witnessed the solution to two \$100 Erd\H{o}s problems, and the current record
due to Lange, Radziszowski, and Xu now stands at $f(2,3,4) \leq 786$, the proof
of which is computer-assisted.
  In this paper, we study Folkman-like properties of a sequence $H_q$ of finite
geometric graphs constructed using Hermitian unitals over projective planes
which were instrumental in the recent Mattheus-Verstra\"ete breakthrough on
off-diagonal Ramsey numbers. We show that for all prime powers $q \geq 4$,
there exists a subset $\mathcal{T}_q$ of triangles in $H_q$ such that no four
span a $K_4$ in $H_q$, but every two-coloring of $E(H_q)$ induces a
monochromatic triangle in $\mathcal{T}_q$. For $q=4$, this gives a graph on
$208$ vertices with this "quasi-Folkman" property. Moreover, we show that a
certain random alteration of $H_q$ which destroys all of its $K_4$'s will, for
large $q$, maintain the Ramsey property with high probability.

</details>


### [39] [Positive $m$-divisible non-crossing partitions and their Kreweras maps](https://arxiv.org/abs/2506.14996)
*Christian Krattenthaler,Christian Stump*

Main category: math.CO

TL;DR: 本文研究了正$m$-可分非交叉划分及其正Kreweras映射，在经典类型中给出了组合实现，并建立了与圆环/环面上伪旋转的对应关系，证明了循环筛选现象。


<details>
  <summary>Details</summary>
Motivation: 探索正$m$-可分非交叉划分的组合性质及其在正Kreweras映射下的不变性，为不同类型（包括例外型）建立统一理论框架。

Method: 在经典类型中使用非交叉集合划分的组合模型，例外型中开发新组合模型；通过伪旋转几何实现映射，并枚举映射幂次下的不变划分。

Result: 实现了正Kreweras映射的几何描述，给出了不变划分的计数公式，最终建立了多重循环筛选现象（cyclic sieving phenomena）。

Conclusion: 该研究统一了经典型与例外型的正$m$-可分非交叉划分理论，通过组合与几何方法证实了循环筛选现象的普遍性。

Abstract: We study positive $m$-divisible non-crossing partitions and their positive
Kreweras maps. In classical types, we describe their combinatorial realisations
as certain non-crossing set partitions. We also realise these positive Kreweras
maps as pseudo-rotations on a circle, respectively on an annulus. We enumerate
positive $m$-divisible non-crossing partitions in classical types that are
invariant under powers of the positive Kreweras maps with respect to several
parameters. In order to cope with the exceptional types, we develop a different
combinatorial model in general type describing positive $m$-divisible
non-crossing partitions that are invariant under powers of the positive
Kreweras maps. We finally show that altogether these results establish several
cyclic sieving phenomena.

</details>


### [40] [Matroid complexes and Orlik-Solomon algebras](https://arxiv.org/abs/2506.15048)
*Basile Coron*

Main category: math.CO

TL;DR: 本文为超可解拟阵的Orlik-Solomon代数构建了一个组合拟自由微分分次模型，推广了Kontsevich为辫子排列引入的cdga，并证明该模型具有广义余操作结构，进而用此模型新证明了超可解拟阵的Orlik-Solomon代数是Koszul代数。


<details>
  <summary>Details</summary>
Motivation: 研究目的是在拟阵理论框架下，推广Kontsevich为辫子排列引入的可容许图cdga结构，构建超可解拟阵Orlik-Solomon代数的组合模型，并探索其代数性质。

Method: 利用拟阵理论中的模性、单元素扩张和广义平行连接等概念，构造了拟自由微分分次模型；通过广义余操作结构分析模型的代数性质。

Result: 成功构建了超可解拟阵Orlik-Solomon代数的组合模型，证明其具有广义余操作结构，并由此给出了该代数是Koszul代数的新证明。

Conclusion: 该研究不仅推广了Kontsevich的可容许图cdga结构，还为超可解拟阵的Orlik-Solomon代数提供了新的组合模型和Koszul性质的证明方法，具有理论意义。

Abstract: In this article we construct a combinatorial quasi-free differential graded
model for the Orlik-Solomon algebra of supersolvable matroids, which
generalizes in a matroidal setting the cdga of admissible graphs introduced by
M. Kontsevich for the braid arrangements. Our construction draws on well-known
concepts from matroid theory, including modularity, single-element extensions,
and generalized parallel connections. We also show that this model carries a
cooperadic structure in a suitably generalized sense. As an application, we use
this model to give a new proof that the Orlik-Solomon algebras of supersolvable
matroids are Koszul.

</details>


### [41] [Higher diameters of Cayley digraphs](https://arxiv.org/abs/2506.15137)
*G. C. Magda,J. Rubin,S. Streipert,C. Watt,A. Kumar,G. P. Constantine*

Main category: math.CO

TL;DR: 本文定义并研究了凯莱有向图的高阶直径。


<details>
  <summary>Details</summary>
Motivation: 探索凯莱有向图中高阶直径的性质及其应用。

Method: 通过数学定义和理论分析，研究凯莱有向图的高阶直径。

Result: 提出了凯莱有向图高阶直径的概念，并分析了其相关性质。

Conclusion: 凯莱有向图的高阶直径是一个值得深入研究的数学概念，具有潜在的理论价值。

Abstract: Higher diameters of Cayley digraphs are defined and studied.

</details>


### [42] [Antimagic labelings of a complete graph](https://arxiv.org/abs/2506.15221)
*Dr A. N. Bhavale*

Main category: math.CO

TL;DR: 本文证明了对于$n \geq 3$的完全图$K_n$，其不仅是超反魔图，还是全反魔全图，并且存在反魔定向。


<details>
  <summary>Details</summary>
Motivation: 研究起源于Hartsfield和Ringel在1990年提出的反魔图猜想，以及Hefetz等人在2010年提出的两个关于反魔定向的问题。

Method: 利用Bhavale提出的边标号方法，对给定的无孤立顶点的图进行标号。

Result: 证明了对于$n \geq 3$的完全图$K_n$，其既是超反魔图，也是全反魔全图，并且存在反魔定向。

Conclusion: 本研究为完全图$K_n$的反魔性质提供了新的理论支持，扩展了反魔图理论的应用范围。

Abstract: In $1990$, Hartsfield and Ringel introduced antimagic graphs. Hartsfield and
Ringel conjectured that every connected graph (and in particular, a tree)
except $K_2$ is antimagic. In $2010$, Hefetz et al.\ raised two questions: Is
every orientation of any simple connected undirected graph antimagic? and Given
any undirected graph $G$, does there exist an orientation of $G$ which is
antimagic? They call such an orientation an {\it antimagic orientation} of $G$.
Recently, Bhavale provided an edge labeling for a given graph on $n$ vertices
without isolated vertices. In this paper, using the labeling of Bhavale, we
prove that a complete graph $K_n$ for $n \geq 3$ is super antimagic as well as
totally antimagic total graph. We also prove that there exists an antimagic
orientation of $K_n$ for $n \geq 3$.

</details>


### [43] [Structured and Punctured Nullstellensätze](https://arxiv.org/abs/2506.15281)
*Erhard Aichinger,John R. Schmitt,Henry Zhan*

Main category: math.CO

TL;DR: 本文综述并推广了关于多项式零点定理的若干结果，特别是Schauz和Nica的工作，并提出了一种统一框架。通过研究多元多项式除法中特定单项式的性质，作者将Alon-F\"uredi的非零计数定理推广至穿孔网格。


<details>
  <summary>Details</summary>
Motivation: 多项式零点定理（Nullstellensatz）是代数几何与组合数学的核心工具。从Hilbert的经典定理到Alon的组合版本，再到后续的多方向推广，这些成果为多项式方法提供了理论基础。本文旨在统一Schauz（2008）和Nica（2023）的推广结果，并扩展Clark对Alon-F\"uredi定理的证明。

Method: 通过分析多元多项式除法过程中特定单项式的保留性质，建立了一般性理论框架。该方法结合了Schauz对更多单项式的排除策略，以及Nica关于对称边网格的改进结果。

Result: 提出了Schauz与Nica结果的共同推广形式，并成功将Alon-F\"uredi定理的非零计数结论扩展至穿孔网格（即网格集合$X\setminus Y$）。关键发现是某些单项式在除法过程中不受影响。

Conclusion: 该研究为多项式零点定理建立了更普适的推广框架，统一了先前分散的结果。特别是通过揭示多项式除法的单项式稳定性，为组合数学中的多项式方法提供了新的工具。

Abstract: A Nullstellensatz is a theorem providing information on polynomials that
vanish on a certain set: David Hilbert's Nullstellensatz (1893) is a
cornerstone of algebraic geometry, and Noga Alon's Combinatorial
Nullstellensatz (1999) is a powerful tool in the "Polynomial Method", a
technique used in combinatorics. Alon's Theorem excludes that a polynomial
vanishing on a grid contains a monomial with certain properties. This theorem
has been generalized in several directions, two of which we will consider in
detail: Terence Tao and Van H. Vu (2006), Uwe Schauz (2008) and Micha\l{}
Laso\'n (2010) exclude more monomials, and recently, Bogdan Nica (2023)
improved the result for grids with additional symmetries in their side edges.
Simeon Ball and Oriol Serra (2009) incorporated the multiplicity of zeros and
gave Nullstellens\"atze for punctured grids, which are sets of the form $X
\setminus Y$ with both $X,Y$ grids.
  We generalize some of these results; in particular, we provide a common
generalization to the results of Schauz and Nica. To this end, we establish
that during multivariate polynomial division, certain monomials are unaffected.
This also allows us to generalize Pete L. Clark's proof of the nonzero counting
theorem by Alon and F\"uredi to punctured grids.

</details>


### [44] [Posets for Specht ideals of essential real reflection groups](https://arxiv.org/abs/2506.15335)
*Sebastian Debus,Kurt Klement Gottwald*

Main category: math.CO

TL;DR: 本文扩展了Specht理想理论至D型及二面体群，完成了所有本质实反射群无限族的组合研究。


<details>
  <summary>Details</summary>
Motivation: Specht理想是由与群表示相关的Specht多项式生成的多项式环中的对称理想，此前已在A型和B型反射群中研究了其包含关系及簇的组合结构。

Method: 将Specht理想理论推广至D型反射群及二面体群，分析其组合性质。

Result: 研究结果揭示了D型及二面体群中Specht理想的包含关系及其簇的丰富组合结构。

Conclusion: 该工作填补了所有无限族本质实反射群中Specht理想组合研究的空白，为相关领域提供了完整的理论框架。

Abstract: Specht ideals are symmetric ideals in the polynomial ring generated by Specht
polynomials associated with group representations. These ideals were previously
studied for reflection groups of types $A$ and $B$, where their inclusion
relations and their varieties reflect rich combinatorial structures. In this
paper, we extend this theory to type $D$ and the dihedral groups. Our results
complete the combinatorial study of Specht ideals across all infinite families
of essential real reflection groups.

</details>


### [45] [Inverse eigenvalue problem for discrete Schrödinger operators of a graph](https://arxiv.org/abs/2506.15430)
*Anzila Laikhuram,Jephian C. -H. Lin*

Main category: math.CO

TL;DR: 该论文研究了图的离散薛定谔算子的逆特征值问题，通过图结构的强性质建立了多个引理，并解决了顶点数不超过5的所有图的该问题。


<details>
  <summary>Details</summary>
Motivation: 离散薛定谔算子在图论中用于振动理论和Colin de Verdi\`ere参数研究，其逆特征值问题旨在刻画图的离散薛定谔算子可能的光谱。

Method: 利用图结构的强性质，建立了超图引理、解放引理和分岔引理的类似版本，并应用这些结果进行分析。

Result: 研究结果表明，与图的逆特征值问题相比，离散薛定谔算子的解受到更多限制，并成功解决了顶点数不超过5的所有图的逆特征值问题。

Conclusion: 通过建立的新引理和结构限制，论文为小规模图的离散薛定谔算子逆特征值问题提供了完整的解决方案。

Abstract: A discrete Schr\"odinger operator of a graph $G$ is a real symmetric matrix
whose $i,j$-entry, $i \neq j$, is negative if $\{i,j\}$ is an edge and zero if
it is not an edge, while diagonal entries can be any real numbers. The discrete
Schr\"odinger operators have been used to study vibration theory and the Colin
de Verdi\`ere parameter. The inverse eigenvalue problem for discrete
Schr\"odinger operators of a graph aims to characterize the possible spectra
among discrete Schr\"odinger operators of a graph. Comparing to the inverse
eigenvalue problem of a graph, the answers turn out to be more limited, and
several restrictions based on graph structure are given. Using the strong
properties, analogous versions of the supergraph lemma, the liberation lemma,
and the bifurcation lemma are established. Using these results, the inverse
eigenvalue problem for discrete Schr\"odinger operators is resolved for each
graph with at most $5$ vertices.

</details>


### [46] [Is it easy to regularize a hypergraph with easy links?](https://arxiv.org/abs/2506.15582)
*Lior Gishboliner,Asaf Shapira,Yuval Wigderson*

Main category: math.CO

TL;DR: 本文研究了超图的$\varepsilon$-同质划分问题，推翻了Terry的猜想，给出了最佳可能的单指数界，并推广到所有$k\geq 3$的一致超图。同时发现顶点链接的$\varepsilon$-正则划分不能保证整个3-图具有多项式大小的正则划分。


<details>
  <summary>Details</summary>
Motivation: 研究超图在何种条件下具有小的$\varepsilon$-正则划分，这一问题在图中已有较好理解，但在3-图中更为复杂。本文旨在探索顶点链接具有多项式大小$\varepsilon$-同质划分时，整个3-图是否也具有小的同质划分。

Method: 通过分析3-图的顶点链接的$\varepsilon$-同质划分性质，推导整个3-图的同质划分大小。进一步研究顶点链接具有多项式大小$\varepsilon$-正则划分时，整个3-图的正则划分性质。

Result: 推翻了Terry的猜想，证明了3-图具有单指数大小的$\varepsilon$-同质划分，且这一界是最优的。同时发现即使每个顶点链接具有多项式大小的$\varepsilon$-正则划分，整个3-图的正则划分大小仍可能达到塔型。

Conclusion: 本文结果表明，顶点链接的同质划分性质可以保证整个3-图具有单指数大小的同质划分，但正则划分的性质更为复杂，顶点链接的正则划分不能保证整个3-图具有多项式大小的正则划分。

Abstract: A partition of a (hyper)graph is $\varepsilon$-homogenous if the edge
densities between almost all clusters are either at most $\varepsilon$ or at
least $1-\varepsilon$. Suppose a $3$-graph has the property that the link of
every vertex has an $\varepsilon$-homogenous partition of size
$\text{poly}(1/\varepsilon)$. Does this guarantee that the $3$-graph also has a
small homogenous partition? Terry and Wolf proved that such a $3$-graph has an
$\varepsilon$-homogenous partition of size given by a wowzer-type function.
Terry recently improved this to a double exponential bound, and conjectured
that this bound is tight. Our first result in this paper disproves this
conjecture by giving an improved (single) exponential bound, which is best
possible. We further obtain an analogous result for $k$-graphs of all
uniformities $k \geq 3$.
  The above problem is part of a much broader programme which seeks to
understand the conditions under which a (hyper)graph has small
$\varepsilon$-regular partitions. While this problem is fairly well understood
for graphs, the situation is (as always) much more involved already for
$3$-graphs. For example, it is natural to ask if one can strengthen our first
result by only requiring each link to have $\varepsilon$-regular partitions of
size $\text{poly}(1/\varepsilon)$. Our second result shows that surprisingly
the answer is `no', namely, a $3$-graph might only have regular partitions of
tower-type size, even though the link of every vertex has an
$\varepsilon$-regular partition of polynomial size.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [47] [Winter Soldier: Backdooring Language Models at Pre-Training with Indirect Data Poisoning](https://arxiv.org/abs/2506.14913)
*Wassim Bouaziz,Mathurin Videau,Nicolas Usunier,El-Mahdi El-Mhamdi*

Main category: cs.CR

TL;DR: 研究提出了一种间接数据投毒方法，通过梯度优化提示调校使语言模型学习训练数据中不存在的秘密序列，实现数据集保护和使用追踪，且不影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)预训练依赖来源复杂且难以筛选的海量文本数据。现有基于记忆性的数据追踪方法（如成员推断攻击）受限于模型提供商对训练数据记忆的限制。本研究旨在探索不依赖数据记忆的间接投毒方案。

Method: 采用基于梯度优化的提示调校技术，使模型学习训练语料中不存在的'秘密提示-秘密响应'序列。验证了在从头预训练的语言模型中，仅需污染少于0.005%的token即可实现秘密植入。

Result: 实验表明该方法能以极高置信度（$p < 10^{-55}$）检测秘密序列，且具有理论可验证性。关键优势在于：1) 秘密从未出现在训练集中 2) 不影响模型基准测试性能。

Conclusion: 间接数据投毒技术为数据集保护提供了新范式，其非记忆性、高隐蔽性和无损性能的特点，为LLM训练数据溯源开辟了可行路径。

Abstract: The pre-training of large language models (LLMs) relies on massive text
datasets sourced from diverse and difficult-to-curate origins. Although
membership inference attacks and hidden canaries have been explored to trace
data usage, such methods rely on memorization of training data, which LM
providers try to limit. In this work, we demonstrate that indirect data
poisoning (where the targeted behavior is absent from training data) is not
only feasible but also allow to effectively protect a dataset and trace its
use. Using gradient-based optimization prompt-tuning, we make a model learn
arbitrary secret sequences: secret responses to secret prompts that are absent
from the training corpus. We validate our approach on language models
pre-trained from scratch and show that less than 0.005% of poisoned tokens are
sufficient to covertly make a LM learn a secret and detect it with extremely
high confidence ($p < 10^{-55}$) with a theoretically certifiable scheme.
Crucially, this occurs without performance degradation (on LM benchmarks) and
despite secrets never appearing in the training set.

</details>


### [48] [Fair Data Exchange with Constant-Time Proofs](https://arxiv.org/abs/2506.14944)
*Majid Khabbazian*

Main category: cs.CR

TL;DR: 本文提出了一种改进的公平数据交换协议，通过将文件视为Reed-Solomon编码字并扩展至低速率编码，实现了证明和验证时间的常数级开销，同时保持了完全的客户端和服务器公平性。


<details>
  <summary>Details</summary>
Motivation: 现有的公平数据交换协议虽然实现了按文件付费的原子传输和恒定大小的证明，但证明者和验证者的运行时间仍与文件长度线性相关，需要优化以降低开销。

Method: 将文件视为速率1的Reed-Solomon编码字，扩展至低速率编码并加密，仅对少量随机密文子集进行正确性证明，利用RS解码修复可能的错误符号。

Result: 协议将证明和验证成本降至接近常数级，仅增加可调的通信冗余开销，同时保持了完全的公平性。此外，通过紧凑的zk-SNARK修复了比特币实现中的椭圆曲线不匹配问题。

Conclusion: 改进后的协议在链下完成整个交换过程，仅在通道不可用时需要两次链上交易，显著提升了效率和实用性。

Abstract: The Fair Data Exchange (FDE) protocol introduced at CCS 2024 offers atomic
pay-per-file transfers with constant-size proofs, but its prover and verifier
runtimes still scale linearly with the file length n. We collapse these costs
to essentially constant by viewing the file as a rate-1 Reed-Solomon (RS)
codeword, extending it to a lower-rate RS code with constant redundancy,
encrypting this extended vector, and then proving correctness for only a small
random subset of the resulting ciphertexts; RS decoding repairs any corrupted
symbols with negligible failure probability. Our protocol preserves full
client- and server-fairness, and adds only a tunable communication redundancy
overhead.
  Finally, we patch the elliptic-curve mismatch in the Bitcoin instantiation of
FDE with a compact zk-SNARK, enabling the entire exchange to run off-chain and
falling back to just two on-chain transactions when channels are unavailable.

</details>


### [49] [Narrowing the Gap between TEEs Threat Model and Deployment Strategies](https://arxiv.org/abs/2506.14964)
*Filip Rezabek,Jonathan Passerat-Palmbach,Moe Mahhouk,Frieder Erdmann,Andrew Miller*

Main category: cs.CR

TL;DR: 保密虚拟机(CVMs)虽提供数据使用隔离，但缺乏物理层面防护和侧信道攻击防御，需依赖可信云提供商托管底层设施。现有TEE认证未绑定运营商信息，用户无法评估物理攻击风险。论文提出通过PPID等方案扩展认证机制以绑定CVM与提供商，并讨论TEE认证的强化与扩展。


<details>
  <summary>Details</summary>
Motivation: 当前CVMs的威胁模型存在错位：虽防护租户间攻击，但未提供不依赖云服务商的端到端安全保障。TEE认证未包含运营商信息，导致用户难以评估物理攻击风险，阻碍CVM的广泛应用。

Method: 提出利用受保护平台标识符(PPID)等方案将CVM与提供商绑定。分析不同TEE厂商实现差异、认证流程多样性对验证、迁移及去信任化应用构建的挑战。

Result: 指出现有TEE认证在运营商绑定方面的关键缺陷，证明依赖可信第三方的局限性。通过讨论认证强化方向，为构建端到端安全CVMs提供技术路径。

Conclusion: 必须扩展TEE认证机制以包含提供商信息，解决物理攻击风险评估难题。PPID等方案需标准化以应对厂商差异，这是推动CVM大规模采用的关键前提。

Abstract: Confidential Virtual Machines (CVMs) provide isolation guarantees for data in
use, but their threat model does not include physical level protection and
side-channel attacks. Therefore, current deployments rely on trusted cloud
providers to host the CVMs' underlying infrastructure. However, TEE
attestations do not provide information about the operator hosting a CVM.
Without knowing whether a Trusted Execution Environment (TEE) runs within a
provider's infrastructure, a user cannot accurately assess the risks of
physical attacks. We observe a misalignment in the threat model where the
workloads are protected against other tenants but do not offer end-to-end
security assurances to external users without relying on cloud providers. The
attestation should be extended to bind the CVM with the provider. A possible
solution can rely on the Protected Platform Identifier (PPID), a unique CPU
identifier. However, the implementation details of various TEE manufacturers,
attestation flows, and providers vary. This makes verification of attestations,
ease of migration, and building applications without relying on a trusted party
challenging, highlighting a key limitation that must be addressed for the
adoption of CVMs. We discuss two points focusing on hardening and extensions of
TEEs' attestation.

</details>


### [50] [Private Continual Counting of Unbounded Streams](https://arxiv.org/abs/2506.15018)
*Ben Jacobsen,Kassem Fawaz*

Main category: cs.CR

TL;DR: 本文提出了一种新颖的矩阵分解方法，用于解决无界差分隐私持续计数问题，实现了平滑误差和高效的计算性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于矩阵机制的最优算法在无界设置下无法直接应用，因其隐私保证需要预先知道输入规模$n$。使用常见的'倍增技巧'会导致次优且非平滑的误差。

Method: 通过引入基于对数扰动函数$\frac{1}{\sqrt{1-z}}$的新颖矩阵分解方法，设计了一种空间和时间高效的差分隐私算法。

Result: 算法对于任意$\alpha > 0$和$t\leq n$，能以$O(\log^{2+2\alpha}(t))$方差私有估计前$t$个数据点的和，仅需$O(t)$空间和每轮$O(\log t)$均摊时间。

Conclusion: 该算法在误差平滑性和计算效率上显著优于现有方法，实证表明其方差在$t$高达$2^{24}$时仍低于Henzinger等算法的1.5倍。

Abstract: We study the problem of differentially private continual counting in the
unbounded setting where the input size $n$ is not known in advance. Current
state-of-the-art algorithms based on optimal instantiations of the matrix
mechanism cannot be directly applied here because their privacy guarantees only
hold when key parameters are tuned to $n$. Using the common `doubling trick'
avoids knowledge of $n$ but leads to suboptimal and non-smooth error. We solve
this problem by introducing novel matrix factorizations based on logarithmic
perturbations of the function $\frac{1}{\sqrt{1-z}}$ studied in prior works,
which may be of independent interest. The resulting algorithm has smooth error,
and for any $\alpha > 0$ and $t\leq n$ it is able to privately estimate the sum
of the first $t$ data points with $O(\log^{2+2\alpha}(t))$ variance. It
requires $O(t)$ space and amortized $O(\log t)$ time per round, compared to
$O(\log(n)\log(t))$ variance, $O(n)$ space and $O(n \log n)$ pre-processing
time for the nearly-optimal bounded-input algorithm of Henzinger et al. (SODA
2023). Empirically, we find that our algorithm's performance is also comparable
to theirs in absolute terms: our variance is less than $1.5\times$ theirs for
$t$ as large as $2^{24}$.

</details>


### [51] [Systems-Theoretic and Data-Driven Security Analysis in ML-enabled Medical Devices](https://arxiv.org/abs/2506.15028)
*Gargi Mitra,Mohammadreza Hallajiyan,Inji Kim,Athish Pranav Dharmalingam,Mohammed Elnawawy,Shahrear Iqbal,Karthik Pattabiraman,Homa Alemzadeh*

Main category: cs.CR

TL;DR: AI/ML在医疗设备中的应用虽提升了诊疗能力，但也带来了严重的网络安全风险。本文强调需在上市前解决这些挑战，并提出了一套工具帮助安全分析师进行风险评估。


<details>
  <summary>Details</summary>
Motivation: AI/ML医疗设备的复杂性和互联性增加了网络安全风险，可能危及患者安全，因此需在设计阶段就确保设备安全。

Method: 通过分析设备召回、不良事件和已知漏洞的公开数据，理解威胁形势，并开发了一套工具进行上市前风险评估。

Result: 提出了一套工具和技术，帮助制造商将网络安全作为AI/ML医疗设备的核心设计原则，从而保障患者安全。

Conclusion: 在AI/ML医疗设备的上市前阶段解决网络安全问题至关重要，制造商需将安全嵌入设计核心以确保患者安全。

Abstract: The integration of AI/ML into medical devices is rapidly transforming
healthcare by enhancing diagnostic and treatment facilities. However, this
advancement also introduces serious cybersecurity risks due to the use of
complex and often opaque models, extensive interconnectivity, interoperability
with third-party peripheral devices, Internet connectivity, and vulnerabilities
in the underlying technologies. These factors contribute to a broad attack
surface and make threat prevention, detection, and mitigation challenging.
Given the highly safety-critical nature of these devices, a cyberattack on
these devices can cause the ML models to mispredict, thereby posing significant
safety risks to patients. Therefore, ensuring the security of these devices
from the time of design is essential. This paper underscores the urgency of
addressing the cybersecurity challenges in ML-enabled medical devices at the
pre-market phase. We begin by analyzing publicly available data on device
recalls and adverse events, and known vulnerabilities, to understand the threat
landscape of AI/ML-enabled medical devices and their repercussions on patient
safety. Building on this analysis, we introduce a suite of tools and techniques
designed by us to assist security analysts in conducting comprehensive
premarket risk assessments. Our work aims to empower manufacturers to embed
cybersecurity as a core design principle in AI/ML-enabled medical devices,
thereby making them safe for patients.

</details>


### [52] [MECHA: Multithreaded and Efficient Cryptographic Hardware Access](https://arxiv.org/abs/2506.15034)
*Pratama Derry,Laksmono Agus Mahardika Ari,Iqbal Muhammad,Howon Kim*

Main category: cs.CR

TL;DR: 本文提出了一种多线程高效加密硬件访问(MECHA)架构，通过UNIX域套接字消除上下文切换需求，显著提升并发加密操作速度83%，适用于从云计算到物联网的安全通信应用。


<details>
  <summary>Details</summary>
Motivation: 传统加密接口存在上下文切换开销，无法高效处理多应用并发请求，亟需一种能同时管理多请求的快速加密解决方案。

Method: 采用服务器线程、客户端线程、收发线程及发送/接收队列等核心组件，基于UNIX域套接字实现可移植架构，兼容任意通信协议。

Result: 实验表明相较传统设计，MECHA使并发加密请求处理速度提升83%，同时保持高资源利用率。

Conclusion: 该架构为云到物联网的加密请求并发处理提供了高效解决方案，在安全通信领域具有重要应用潜力。

Abstract: This paper presents a multithread and efficient cryptographic hardware access
(MECHA) for efficient and fast cryptographic operations that eliminates the
need for context switching. Utilizing a UNIX domain socket, MECHA manages
multiple requests from multiple applications simultaneously, resulting in
faster processing and improved efficiency. We comprise several key components,
including the Server thread, Client thread, Transceiver thread, and a pair of
Sender and Receiver queues. MECHA design is portable and can be used with any
communication protocol, with experimental results demonstrating a 83% increase
in the speed of concurrent cryptographic requests compared to conventional
interface design. MECHA architecture has significant potential in the field of
secure communication applications ranging from cloud computing to the IoT,
offering a faster and more efficient solution for managing multiple
cryptographic operation requests concurrently.

</details>


### [53] [Advanced Prediction of Hypersonic Missile Trajectories with CNN-LSTM-GRU Architectures](https://arxiv.org/abs/2506.15043)
*Amir Hossein Baradaran*

Main category: cs.CR

TL;DR: 本文提出了一种新型混合深度学习模型，结合CNN、LSTM和GRU网络，成功实现了高超声速导弹轨迹的高精度预测，为国防安全提供了重要技术支持。


<details>
  <summary>Details</summary>
Motivation: 高超声速导弹因其极速和机动性对国防安全构成重大威胁，准确预测其轨迹是实施有效拦截的关键。

Method: 采用卷积神经网络(CNN)、长短期记忆网络(LSTM)和门控循环单元(GRU)的混合深度学习架构，整合各模型优势进行轨迹预测。

Result: 所提方法能够高精度预测高超声速导弹的复杂轨迹，显著提升了防御系统的预测能力。

Conclusion: 研究表明，先进机器学习技术可有效增强国防系统的预测性能，为导弹拦截技术提供了创新解决方案。

Abstract: Advancements in the defense industry are paramount for ensuring the safety
and security of nations, providing robust protection against emerging threats.
Among these threats, hypersonic missiles pose a significant challenge due to
their extreme speeds and maneuverability, making accurate trajectory prediction
a critical necessity for effective countermeasures. This paper addresses this
challenge by employing a novel hybrid deep learning approach, integrating
Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM) networks,
and Gated Recurrent Units (GRUs). By leveraging the strengths of these
architectures, the proposed method successfully predicts the complex
trajectories of hypersonic missiles with high accuracy, offering a significant
contribution to defense strategies and missile interception technologies. This
research demonstrates the potential of advanced machine learning techniques in
enhancing the predictive capabilities of defense systems.

</details>


### [54] [Toward a Lightweight, Scalable, and Parallel Secure Encryption Engine](https://arxiv.org/abs/2506.15070)
*Rasha Karakchi,Rye Stahle-Smith,Nishant Chinnasami,Tiffany Yu*

Main category: cs.CR

TL;DR: 本文提出SPiME，一种轻量级、可扩展且兼容FPGA的安全内存处理器加密架构，将AES-128直接集成到内存处理框架中，显著提升边缘计算的加密效率。


<details>
  <summary>Details</summary>
Motivation: 物联网应用的指数增长加剧了对高效、高吞吐量和节能的边缘数据处理的迫切需求，传统CPU加密方法在延迟敏感和资源受限环境中存在性能瓶颈和数据移动过多的问题。

Method: SPiME采用模块化并行内存处理单元阵列设计，每个单元将AES核心与最小控制单元结合，实现分布式就地加密，并通过Verilog在AMD UltraScale和UltraScale+ FPGA上实现。

Result: 评估显示，SPiME可扩展至4000多个并行单元，在高性能设备上关键FPGA资源利用率低于5%，持续加密吞吐量超过25Gbps，且具有可预测的低延迟性能。

Conclusion: SPiME的设计具有可移植性、可配置性和资源高效性，为安全边缘计算、嵌入式加密系统和可定制硬件加速器提供了高效的解决方案。

Abstract: The exponential growth of Internet of Things (IoT) applications has
intensified the demand for efficient, high-throughput, and energy-efficient
data processing at the edge. Conventional CPU-centric encryption methods suffer
from performance bottlenecks and excessive data movement, especially in
latency-sensitive and resource-constrained environments. In this paper, we
present SPiME, a lightweight, scalable, and FPGA-compatible Secure
Processor-in-Memory Encryption architecture that integrates the Advanced
Encryption Standard (AES-128) directly into a Processing-in-Memory (PiM)
framework. SPiME is designed as a modular array of parallel PiM units, each
combining an AES core with a minimal control unit to enable distributed
in-place encryption with minimal overhead. The architecture is fully
implemented in Verilog and tested on multiple AMD UltraScale and UltraScale+
FPGAs. Evaluation results show that SPiME can scale beyond 4,000 parallel units
while maintaining less than 5\% utilization of key FPGA resources on high-end
devices. It delivers over 25~Gbps in sustained encryption throughput with
predictable, low-latency performance. The design's portability,
configurability, and resource efficiency make it a compelling solution for
secure edge computing, embedded cryptographic systems, and customizable
hardware accelerators.

</details>


### [55] [CWGAN-GP Augmented CAE for Jamming Detection in 5G-NR in Non-IID Datasets](https://arxiv.org/abs/2506.15075)
*Samhita Kuili,Mohammadreza Amini,Burak Kantarci*

Main category: cs.CR

TL;DR: 本文提出了一种基于卷积自编码器(CAE)的5G-NR无线蜂窝网络空中干扰检测方法，通过生成对抗网络增强数据平衡性，在复杂异构数据集上实现了优于基准模型的检测性能。


<details>
  <summary>Details</summary>
Motivation: 5G-NR网络中普遍存在的空中干扰攻击会严重影响接收信号质量，需要开发鲁棒的检测方法来应对异构I/Q数据集、同步信号块(SSB)特征提取及数据不平衡等挑战。

Method: 采用添加高斯白噪声(AWGN)模拟干扰环境，利用卷积自编码器(CAE)进行检测；通过Conv1D条件Wasserstein生成对抗网络(CWGAN-GP)平衡多数类和少数类SSB观测数据，并与去噪自编码器(CDAE)和稀疏自编码器(CSAE)进行对比。

Result: CAE模型在增强数据集上表现出色，平均精确率97.33%、召回率91.33%、F1分数94.08%、准确率94.35%，显著优于CDAE和CSAE基准模型。

Conclusion: 研究表明CAE模型能有效处理数据异构性，在干扰信号检测中展现出强大鲁棒性，为5G-NR网络安全提供了可靠解决方案。

Abstract: In the ever-expanding domain of 5G-NR wireless cellular networks,
over-the-air jamming attacks are prevalent as security attacks, compromising
the quality of the received signal. We simulate a jamming environment by
incorporating additive white Gaussian noise (AWGN) into the real-world In-phase
and Quadrature (I/Q) OFDM datasets. A Convolutional Autoencoder (CAE) is
exploited to implement a jamming detection over various characteristics such as
heterogenous I/Q datasets; extracting relevant information on Synchronization
Signal Blocks (SSBs), and fewer SSB observations with notable class imbalance.
Given the characteristics of datasets, balanced datasets are acquired by
employing a Conv1D conditional Wasserstein Generative Adversarial
Network-Gradient Penalty(CWGAN-GP) on both majority and minority SSB
observations. Additionally, we compare the performance and detection ability of
the proposed CAE model on augmented datasets with benchmark models:
Convolutional Denoising Autoencoder (CDAE) and Convolutional Sparse Autoencoder
(CSAE). Despite the complexity of data heterogeneity involved across all
datasets, CAE depicts the robustness in detection performance of jammed signal
by achieving average values of 97.33% precision, 91.33% recall, 94.08%
F1-score, and 94.35% accuracy over CDAE and CSAE.

</details>


### [56] [Flexible Hardware-Enabled Guarantees for AI Compute](https://arxiv.org/abs/2506.15093)
*James Petrie,Onni Aarne,Nora Ammann,David Dalrymple*

Main category: cs.CR

TL;DR: 本文提出了一种名为flexHEGs的硬件保障系统，旨在通过可审计的处理器和安全外壳解决AI发展中的国际安全与隐私保护问题，支持多样化的治理机制。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统的强大，其对国际安全的威胁日益增加，现有治理方法难以在不泄露敏感信息或国家安全的前提下有效应对这些挑战。

Method: flexHEGs系统包括一个可审计的保障处理器，用于监控加速器使用情况，以及一个提供物理防篡改保护的安全外壳。系统完全开源，具有灵活可更新的验证能力。

Result: flexHEGs能够支持多种治理机制，如隐私保护模型评估、受控部署、训练计算限制和自动安全协议执行，为前沿AI发展中的监管和国际安全挑战提供了解决方案。

Conclusion: 尽管技术上具有挑战性，flexHEGs为解决前沿AI发展中的新兴监管和国际安全问题提供了一种可行的方法。

Abstract: As artificial intelligence systems become increasingly powerful, they pose
growing risks to international security, creating urgent coordination
challenges that current governance approaches struggle to address without
compromising sensitive information or national security. We propose flexible
hardware-enabled guarantees (flexHEGs), that could be integrated with AI
accelerators to enable trustworthy, privacy-preserving verification and
enforcement of claims about AI development. FlexHEGs consist of an auditable
guarantee processor that monitors accelerator usage and a secure enclosure
providing physical tamper protection. The system would be fully open source
with flexible, updateable verification capabilities. FlexHEGs could enable
diverse governance mechanisms including privacy-preserving model evaluations,
controlled deployment, compute limits for training, and automated safety
protocol enforcement. In this first part of a three part series, we provide a
comprehensive introduction of the flexHEG system, including an overview of the
governance and security capabilities it offers, its potential development and
adoption paths, and the remaining challenges and limitations it faces. While
technically challenging, flexHEGs offer an approach to address emerging
regulatory and international security challenges in frontier AI development.

</details>


### [57] [International Security Applications of Flexible Hardware-Enabled Guarantees](https://arxiv.org/abs/2506.15100)
*Onni Aarne,James Petrie*

Main category: cs.CR

TL;DR: 本文探讨了灵活硬件保障技术（flexHEGs）如何通过标准化设计、生态系统防御和明确操作参数，为国际可信AI治理提供技术基础，以应对AI快速发展带来的安全挑战。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力快速进步，flexHEGs为解决国际安全挑战提供了新机遇，特别是在限制恶意使用、实施安全规范、管理军事AI系统风险及支持战略稳定方面。

Method: 报告分析了两种主要治理模型：基于验证的协议（支持透明合规监测）和基于规则集的协议（通过加密签名更新自动执行国际规则），并通过博弈论分析评估其稳定性。

Result: 研究表明，在合理的国家偏好和灾难性风险假设下，全面的flexHEG协议可保持稳定，同时需解决技术门槛、现有硬件管理及治理权力滥用等实施挑战。

Conclusion: 尽管需要大量国际协调，flexHEGs可为管理AI风险提供必要的技术基础，以应对国际安全和稳定面临的新兴威胁。

Abstract: As AI capabilities advance rapidly, flexible hardware-enabled guarantees
(flexHEGs) offer opportunities to address international security challenges
through comprehensive governance frameworks. This report examines how flexHEGs
could enable internationally trustworthy AI governance by establishing
standardized designs, robust ecosystem defenses, and clear operational
parameters for AI-relevant chips. We analyze four critical international
security applications: limiting proliferation to address malicious use,
implementing safety norms to prevent loss of control, managing risks from
military AI systems, and supporting strategic stability through
balance-of-power mechanisms while respecting national sovereignty. The report
explores both targeted deployments for specific high-risk facilities and
comprehensive deployments covering all AI-relevant compute. We examine two
primary governance models: verification-based agreements that enable
transparent compliance monitoring, and ruleset-based agreements that
automatically enforce international rules through cryptographically-signed
updates. Through game-theoretic analysis, we demonstrate that comprehensive
flexHEG agreements could remain stable under reasonable assumptions about state
preferences and catastrophic risks. The report addresses critical
implementation challenges including technical thresholds for AI-relevant chips,
management of existing non-flexHEG hardware, and safeguards against abuse of
governance power. While requiring significant international coordination,
flexHEGs could provide a technical foundation for managing AI risks at the
scale and speed necessary to address emerging threats to international security
and stability.

</details>


### [58] [EVA-S2PMLP: Secure and Scalable Two-Party MLP via Spatial Transformation](https://arxiv.org/abs/2506.15102)
*Shizhao Peng,Shoumo Li,Tianle Tao*

Main category: cs.CR

TL;DR: 本文提出EVA-S2PMLP框架，一种高效、可验证且准确的安全两方多层感知机方案，通过空间尺度优化提升隐私保护与性能，在金融、医疗等领域具有实用价值。


<details>
  <summary>Details</summary>
Motivation: 垂直分区场景下的隐私保护神经网络训练对跨机构安全协作建模至关重要，需兼顾计算可靠性、效率与数据保密性。

Method: 提出安全转换管道将标量输入映射至向量/矩阵空间，包含线性/非线性安全计算的原子协议模块，支持安全激活、矩阵运算及损失评估。

Result: 理论验证协议可靠性，实验显示通信开销降低12.3倍，基准数据集上模型效用与数据保密性兼得。

Conclusion: EVA-S2PMLP通过空间优化与模块化协议实现高效隐私保护训练，为跨组织AI应用提供实用解决方案。

Abstract: Privacy-preserving neural network training in vertically partitioned
scenarios is vital for secure collaborative modeling across institutions. This
paper presents \textbf{EVA-S2PMLP}, an Efficient, Verifiable, and Accurate
Secure Two-Party Multi-Layer Perceptron framework that introduces spatial-scale
optimization for enhanced privacy and performance. To enable reliable
computation under real-number domain, EVA-S2PMLP proposes a secure
transformation pipeline that maps scalar inputs to vector and matrix spaces
while preserving correctness. The framework includes a suite of atomic
protocols for linear and non-linear secure computations, with modular support
for secure activation, matrix-vector operations, and loss evaluation.
Theoretical analysis confirms the reliability, security, and asymptotic
complexity of each protocol. Extensive experiments show that EVA-S2PMLP
achieves high inference accuracy and significantly reduced communication
overhead, with up to $12.3\times$ improvement over baselines. Evaluation on
benchmark datasets demonstrates that the framework maintains model utility
while ensuring strict data confidentiality, making it a practical solution for
privacy-preserving neural network training in finance, healthcare, and
cross-organizational AI applications.

</details>


### [59] [PDLRecover: Privacy-preserving Decentralized Model Recovery with Machine Unlearning](https://arxiv.org/abs/2506.15112)
*Xiangman Li,Xiaodong Wu,Jianbing Ni,Mohamed Mahmoud,Maazen Alsabaan*

Main category: cs.CR

TL;DR: 本文提出PDLRecover方法，通过利用历史模型信息高效恢复被毒化的全局模型，同时保护隐私。该方法避免了重新训练的高成本，并通过秘密共享技术防止本地模型泄露。实验表明，恢复后的模型性能接近完全重新训练的模型，但计算和时间成本显著降低。


<details>
  <summary>Details</summary>
Motivation: 去中心化学习易受毒化攻击，现有防御方法主要检测并过滤恶意模型，但恢复已受损的全局模型仍具挑战性。直接移除恶意客户端并重新训练不仅耗时且计算成本高，还可能影响模型一致性和隐私。

Method: PDLRecover通过利用历史模型信息高效恢复全局模型，并保护隐私。方法包括客户端准备、周期性恢复更新和最终精确更新，利用近似Hessian矩阵计算的线性特性，应用秘密共享保护历史更新，防止本地模型在传输或重建过程中泄露。

Result: 实验表明，恢复后的全局模型性能与完全重新训练的模型相当，但计算和时间成本显著降低。PDLRecover有效防止了本地模型参数的泄露，确保了恢复过程的准确性和隐私性。

Conclusion: PDLRecover提供了一种高效且隐私保护的方法来恢复被毒化的全局模型，避免了重新训练的高成本，同时确保了模型的准确性和安全性。

Abstract: Decentralized learning is vulnerable to poison attacks, where malicious
clients manipulate local updates to degrade global model performance. Existing
defenses mainly detect and filter malicious models, aiming to prevent a limited
number of attackers from corrupting the global model. However, restoring an
already compromised global model remains a challenge. A direct approach is to
remove malicious clients and retrain the model using only the benign clients.
Yet, retraining is time-consuming, computationally expensive, and may
compromise model consistency and privacy.
  We propose PDLRecover, a novel method to recover a poisoned global model
efficiently by leveraging historical model information while preserving
privacy. The main challenge lies in protecting shared historical models while
enabling parameter estimation for model recovery. By exploiting the linearity
of approximate Hessian matrix computation, we apply secret sharing to protect
historical updates, ensuring local models are not leaked during transmission or
reconstruction. PDLRecover introduces client-side preparation, periodic
recovery updates, and a final exact update to ensure robustness and convergence
of the recovered model. Periodic updates maintain accurate curvature
information, and the final step ensures high-quality convergence. Experiments
show that the recovered global model achieves performance comparable to a fully
retrained model but with significantly reduced computation and time cost.
Moreover, PDLRecover effectively prevents leakage of local model parameters,
ensuring both accuracy and privacy in recovery.

</details>


### [60] [CipherMind: The Longest Codebook in the World](https://arxiv.org/abs/2506.15117)
*Ming Nie,Zhixiong Yang,Bingsheng Wei*

Main category: cs.CR

TL;DR: 本文提出CipherMind，利用大语言模型确定性微调的中间结果作为传输内容，实现通信加密。该方法利用大模型语义参数的不可解释性，适用于网关内传输等场景。


<details>
  <summary>Details</summary>
Motivation: 受大语言模型广泛应用的启发，作者探索利用其推理过程实现通信加密的可能性。大模型底层实现的模糊性和弱可解释性为加密提供了天然优势。

Method: 通过确定性微调大模型，提取推理过程中的中间结果作为加密传输内容。该方法理论上可基于任何大模型实现，特别适用于网关内通信等场景。

Result: 提出的CipherMind框架验证了利用大模型中间结果实现加密传输的可行性，其语义参数特性天然适合作为加密手段。

Conclusion: 研究表明大语言模型的推理过程可创新性地应用于通信加密领域，CipherMind为安全传输提供了新范式，具有普适性和应用潜力。

Abstract: In recent years, the widespread application of large language models has
inspired us to consider using inference for communication encryption. We
therefore propose CipherMind, which utilizes intermediate results from
deterministic fine-tuning of large model inferences as transmission content.
The semantic parameters of large models exhibit characteristics like opaque
underlying implementations and weak interpretability, thus enabling their use
as an encryption method for data transmission. This communication paradigm can
be applied in scenarios like intra-gateway transmission, and theoretically, it
can be implemented using any large model as its foundation.

</details>


### [61] [From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem](https://arxiv.org/abs/2506.15170)
*Yanxu Mao,Tiehan Cui,Peipei Liu,Datao You,Hongsong Zhu*

Main category: cs.CR

TL;DR: 本文系统综述了大型语言模型(LLM)生态系统中越狱攻击与防御机制的发展，分析了从单模态到多模态及智能代理演进中的安全挑战，提出了分类框架并指出当前研究的不足与未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLM向多模态和智能代理扩展，其安全风险日益严峻，需系统梳理越狱攻击与防御的研究现状以促进更健壮的防护策略发展。

Method: 通过追踪LLM到MLLM及代理的技术演进路线，从攻击影响/可见性维度分类越狱技术，按响应时机和技术路线整理防御策略，并批判性分析现有研究的局限性。

Result: 建立了越狱攻击的分类学框架，汇总了代表性方法/数据集/评估指标，揭示了当前对代理安全、混合攻击分类、实验细节及前沿进展覆盖的不足。

Conclusion: 研究为理解越狱机制提供了系统视角，未来需加强数据集构建、评估框架优化和策略泛化能力，以应对LLM持续进化带来的安全挑战。

Abstract: Large language models (LLMs) are rapidly evolving from single-modal systems
to multimodal LLMs and intelligent agents, significantly expanding their
capabilities while introducing increasingly severe security risks. This paper
presents a systematic survey of the growing complexity of jailbreak attacks and
corresponding defense mechanisms within the expanding LLM ecosystem. We first
trace the developmental trajectory from LLMs to MLLMs and Agents, highlighting
the core security challenges emerging at each stage. Next, we categorize
mainstream jailbreak techniques from both the attack impact and visibility
perspectives, and provide a comprehensive analysis of representative attack
methods, related datasets, and evaluation metrics. On the defense side, we
organize existing strategies based on response timing and technical approach,
offering a structured understanding of their applicability and implementation.
Furthermore, we identify key limitations in existing surveys, such as
insufficient attention to agent-specific security issues, the absence of a
clear taxonomy for hybrid jailbreak methods, a lack of detailed analysis of
experimental setups, and outdated coverage of recent advancements. To address
these limitations, we provide an updated synthesis of recent work and outline
future research directions in areas such as dataset construction, evaluation
framework optimization, and strategy generalization. Our study seeks to enhance
the understanding of jailbreak mechanisms and facilitate the advancement of
more resilient and adaptive defense strategies in the context of ever more
capable LLMs.

</details>


### [62] [LLM vs. SAST: A Technical Analysis on Detecting Coding Bugs of GPT4-Advanced Data Analysis](https://arxiv.org/abs/2506.15212)
*Madjid G. Tehrani,Eldar Sultanow,William J. Buchanan,Mahkame Houmani,Christel H. Djaha Fodja*

Main category: cs.CR

TL;DR: 本文研究了GPT-4在识别软件漏洞方面的效能，发现其准确率高达94%，优于传统静态应用安全测试(SAST)工具。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理(NLP)的快速发展，大型语言模型(LLMs)如GPT-4在安全漏洞扫描等多样化应用中受到广泛关注。本文旨在评估GPT-4与传统SAST工具在漏洞检测上的表现差异。

Method: 研究通过分析一系列安全错误，比较了GPT-4(高级数据分析版)与传统SAST工具在检测32种可被利用漏洞方面的准确性。

Result: 实验结果表明，GPT-4的漏洞检测准确率达到94%，显著优于传统SAST工具。

Conclusion: 本研究不仅证实了LLM增强型漏洞扫描的强大能力，同时强调了AI设计中必须遵循的安全原则及最佳实践。

Abstract: With the rapid advancements in Natural Language Processing (NLP), large
language models (LLMs) like GPT-4 have gained significant traction in diverse
applications, including security vulnerability scanning. This paper
investigates the efficacy of GPT-4 in identifying software vulnerabilities
compared to traditional Static Application Security Testing (SAST) tools.
Drawing from an array of security mistakes, our analysis underscores the potent
capabilities of GPT-4 in LLM-enhanced vulnerability scanning. We unveiled that
GPT-4 (Advanced Data Analysis) outperforms SAST by an accuracy of 94% in
detecting 32 types of exploitable vulnerabilities. This study also addresses
the potential security concerns surrounding LLMs, emphasising the imperative of
security by design/default and other security best practices for AI.

</details>


### [63] [RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments](https://arxiv.org/abs/2506.15253)
*Yuchuan Fu,Xiaohan Yuan,Dongxia Wang*

Main category: cs.CR

TL;DR: 本文提出了RAS-Eval安全基准测试框架，用于评估大语言模型(LLM)代理在动态环境中的安全漏洞。测试显示攻击平均降低任务完成率36.78%，揭示当前LLM代理部署存在重大安全风险。


<details>
  <summary>Details</summary>
Motivation: 由于LLM代理在医疗、金融等关键领域的快速部署，亟需建立标准化安全评估基准。当前缺乏支持动态环境的统一测试框架。

Method: 开发了RAS-Eval基准，包含80个测试案例和3,802个攻击任务，覆盖11个CWE漏洞类别。支持JSON、LangGraph和MCP三种工具格式，评估了6个前沿LLM模型。

Result: 攻击平均使代理任务完成率下降36.78%，学术环境下成功率高达85.65%。发现模型规模与安全能力正相关，大模型表现更优。

Conclusion: 研究揭示了现实场景中LLM代理部署的重大安全隐患，RAS-Eval为未来安全研究提供了基础框架。代码和数据已开源。

Abstract: The rapid deployment of Large language model (LLM) agents in critical domains
like healthcare and finance necessitates robust security frameworks. To address
the absence of standardized evaluation benchmarks for these agents in dynamic
environments, we introduce RAS-Eval, a comprehensive security benchmark
supporting both simulated and real-world tool execution. RAS-Eval comprises 80
test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration
(CWE) categories, with tools implemented in JSON, LangGraph, and Model Context
Protocol (MCP) formats. We evaluate 6 state-of-the-art LLMs across diverse
scenarios, revealing significant vulnerabilities: attacks reduced agent task
completion rates (TCR) by 36.78% on average and achieved an 85.65% success rate
in academic settings. Notably, scaling laws held for security capabilities,
with larger models outperforming smaller counterparts. Our findings expose
critical risks in real-world agent deployments and provide a foundational
framework for future security research. Code and data are available at
https://github.com/lanzer-tree/RAS-Eval.

</details>


### [64] [Facility Location Problem under Local Differential Privacy without Super-set Assumption](https://arxiv.org/abs/2506.15224)
*Kevin Pfisterer,Quentin Hillebrand,Vorapong Suppakitpaisarn*

Main category: cs.CR

TL;DR: 本文在本地差分隐私（LDP）框架下提出了一种改进的设施选址问题模型，突破了原有$\Omega(\sqrt{n})$近似比下界，提出了一种具有较小加性误差的常数近似比LDP算法，并在合成与真实数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统差分隐私设施选址算法存在$\Omega(\sqrt{n})$近似比下界，而现有研究采用的超集假设可能损害用户隐私。本文旨在探索在LDP框架下突破该下界的新方法。

Method: 通过改进设施选址问题模型，设计了一种满足LDP的算法，该算法不依赖超集假设，并实现了常数近似比与较小加性误差的结合。

Result: 理论证明新模型不受原下界限制，实验表明算法在合成和真实数据集上均显著优于直接方法，验证了其高效性与实用性。

Conclusion: 本研究证明了LDP框架下设施选址问题可突破传统下界，所提算法在保护隐私的同时实现了更优的近似性能，为隐私保护空间计算提供了新思路。

Abstract: In this paper, we introduce an adaptation of the facility location problem
and analyze it within the framework of local differential privacy (LDP). Under
this model, we ensure the privacy of client presence at specific locations.
When n is the number of points, Gupta et al. established a lower bound of
$\Omega(\sqrt{n})$ on the approximation ratio for any differentially private
algorithm applied to the original facility location problem. As a result,
subsequent works have adopted the super-set assumption, which may, however,
compromise user privacy. We show that this lower bound does not apply to our
adaptation by presenting an LDP algorithm that achieves a constant
approximation ratio with a relatively small additive factor. Additionally, we
provide experimental results demonstrating that our algorithm outperforms the
straightforward approach on both synthetically generated and real-world
datasets.

</details>


### [65] [Evaluation Pipeline for systematically searching for Anomaly Detection Systems](https://arxiv.org/abs/2506.15388)
*Florian Rokohl,Alexander Lehnert,Marc Reichenbach*

Main category: cs.CR

TL;DR: 医疗数字化带来便利的同时也面临安全威胁，研究提出基于FPGA的实时异常检测系统以应对网络入侵。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的数字化进程虽带来显著效益，但也成为攻击者的目标，网络安全防护面临严峻挑战。

Method: 采用现场可编程门阵列（FPGA）硬件平台，设计实时异常检测系统，满足实时性与低功耗需求，并通过整体系统评估优化性能。

Result: 提出的硬件方案成功实现了对恶意客户端的实时检测，同时符合严格的实时性和能效限制。

Conclusion: 基于FPGA的硬件异常检测系统为医疗数字化安全提供了高效解决方案，其整体评估方法确保了系统性能的全面优化。

Abstract: Digitalization in the medical world provides major benefits while making it a
target for attackers and thus hard to secure. To deal with network intruders we
propose an anomaly detection system on hardware to detect malicious clients in
real-time. We meet real-time and power restrictions using FPGAs. Overall system
performance is achieved via the presented holistic system evaluation.

</details>


### [66] [Detecting Hardware Trojans in Microprocessors via Hardware Error Correction Code-based Modules](https://arxiv.org/abs/2506.15417)
*Alessandro Palumbo,Ruben Salvador*

Main category: cs.CR

TL;DR: 本文提出了一种基于硬件的方法，利用RISC-V微处理器上的纠错码（ECC）检测运行时硬件木马（HT）激活，特别是针对注入恶意指令的HT。通过硬件安全检查器（HSC）和汉明单纠错（HSEC）架构，实现了100%的检测率，且无额外性能开销。


<details>
  <summary>Details</summary>
Motivation: 软件可利用的硬件木马（HT）使攻击者能够执行未授权软件或获取特权操作权限，威胁系统安全。因此，需要一种高效且低开销的检测方法。

Method: 采用基于汉明单纠错（HSEC）架构的硬件安全检查器（HSC），在RISC-V微处理器上检测运行时HT激活，重点关注恶意指令注入行为。

Result: 实验结果表明，该方法对潜在HT激活的检测率达到100%，无漏报或误报，且仅需72个LUT、24个FF和0.5个BRAM，不影响处理器原始运行频率或引入额外延迟。

Conclusion: 所提出的硬件安全检查器（HSC）是一种高效、低开销的HT检测方案，适用于RISC-V微处理器，能够有效防御恶意指令注入攻击。

Abstract: Software-exploitable Hardware Trojans (HTs) enable attackers to execute
unauthorized software or gain illicit access to privileged operations. This
manuscript introduces a hardware-based methodology for detecting runtime HT
activations using Error Correction Codes (ECCs) on a RISC-V microprocessor.
Specifically, it focuses on HTs that inject malicious instructions, disrupting
the normal execution flow by triggering unauthorized programs. To counter this
threat, the manuscript introduces a Hardware Security Checker (HSC) leveraging
Hamming Single Error Correction (HSEC) architectures for effective HT
detection. Experimental results demonstrate that the proposed solution achieves
a 100% detection rate for potential HT activations, with no false positives or
undetected attacks. The implementation incurs minimal overhead, requiring only
72 #LUTs, 24 #FFs, and 0.5 #BRAM while maintaining the microprocessor's
original operating frequency and introducing no additional time delay.

</details>


### [67] [Side-Channel Extraction of Dataflow AI Accelerator Hardware Parameters](https://arxiv.org/abs/2506.15432)
*Guillaume Lomet,Ruben Salvador,Brice Colombier,Vincent Grosso,Olivier Sentieys,Cedric Killian*

Main category: cs.CR

TL;DR: 本文提出了一种针对FINN框架生成的数据流神经网络加速器的侧信道攻击方法，通过无监督降维和轻量级分类器，高效恢复硬件配置参数，攻击时间短且准确率高。


<details>
  <summary>Details</summary>
Motivation: 数据流神经网络加速器虽简化了AI任务部署，但其便利性使其易受侧信道攻击，导致知识产权泄露。现有方法计算开销大，需更高效的攻击方案。

Method: 采用无监督降维技术降低计算开销，结合随机森林分类器从侧信道痕迹中恢复折叠和量化参数，攻击阶段仅需数百毫秒。

Result: 攻击方法在337毫秒内恢复硬件参数的准确率超过95%，421毫秒内完全恢复参数（平均4次痕迹），相比现有方法准备和攻击时间分别减少940倍和110倍。

Conclusion: 该方法在更现实的攻击场景下显著提升了效率，即使不平均痕迹也能获得更好结果，为数据流加速器的安全防护提出了新挑战。

Abstract: Dataflow neural network accelerators efficiently process AI tasks on FPGAs,
with deployment simplified by ready-to-use frameworks and pre-trained models.
However, this convenience makes them vulnerable to malicious actors seeking to
reverse engineer valuable Intellectual Property (IP) through Side-Channel
Attacks (SCA). This paper proposes a methodology to recover the hardware
configuration of dataflow accelerators generated with the FINN framework.
Through unsupervised dimensionality reduction, we reduce the computational
overhead compared to the state-of-the-art, enabling lightweight classifiers to
recover both folding and quantization parameters. We demonstrate an attack
phase requiring only 337 ms to recover the hardware parameters with an accuracy
of more than 95% and 421 ms to fully recover these parameters with an averaging
of 4 traces for a FINN-based accelerator running a CNN, both using a random
forest classifier on side-channel traces, even with the accelerator dataflow
fully loaded. This approach offers a more realistic attack scenario than
existing methods, and compared to SoA attacks based on tsfresh, our method
requires 940x and 110x less time for preparation and attack phases,
respectively, and gives better results even without averaging traces.

</details>


### [68] [An efficient construction of Raz's two-source randomness extractor with improved parameters](https://arxiv.org/abs/2506.15547)
*Cameron Foreman,Lewis Wooltorton,Kevin Milner,Florian J. Curchod*

Main category: cs.CR

TL;DR: 本文改进了Raz的双源随机性提取器，提出了一种计算时间为准线性的新版本，并降低了熵需求。同时提供了强量子安全版本及开源实现。


<details>
  <summary>Details</summary>
Motivation: Raz的原始提取器虽能在线性熵与对数熵条件下工作，但计算复杂度高达多项式四次方，难以实用。本研究旨在解决这一效率瓶颈。

Method: 通过改进Raz提取器的构造，实现准线性计算时间；提出新分析定理降低熵需求；开发开源代码实现及参数计算模块。

Result: 新提取器计算效率显著提升（准线性时间），熵需求更低；完成与现有方案的全面对比分析；衍生出强量子安全版本。

Conclusion: 本研究使Raz提取器具备实际应用价值，为密码学等领域提供了高效的弱随机源净化工具，并通过开源促进技术推广。

Abstract: Randomness extractors are algorithms that distill weak random sources into
near-perfect random numbers. Two-source extractors enable this distillation
process by combining two independent weak random sources. Raz's extractor (STOC
'05) was the first to achieve this in a setting where one source has linear
min-entropy (i.e., proportional to its length), while the other has only
logarithmic min-entropy in its length. However, Raz's original construction is
impractical due to a polynomial computation time of at least degree 4. Our work
solves this problem by presenting an improved version of Raz's extractor with
quasi-linear computation time, as well as a new analytic theorem with reduced
entropy requirements. We provide comprehensive analytical and numerical
comparisons of our construction with others in the literature, and we derive
strong and quantum-proof versions of our efficient Raz extractor. Additionally,
we offer an easy-to-use, open-source code implementation of the extractor and a
numerical parameter calculation module.

</details>


### [69] [deepSURF: Detecting Memory Safety Vulnerabilities in Rust Through Fuzzing LLM-Augmented Harnesses](https://arxiv.org/abs/2506.15648)
*Georgios Androutsopoulos,Antonio Bianchi*

Main category: cs.CR

TL;DR: 本文介绍了deepSURF工具，它结合静态分析和基于大语言模型（LLM）的模糊测试技术，有效检测Rust库中的内存安全漏洞，特别是针对不安全代码。


<details>
  <summary>Details</summary>
Motivation: 尽管Rust默认保证内存安全，但不安全代码的使用仍可能导致漏洞。现有工具在检测能力、处理Rust特有类型或自动化方面存在不足。

Method: deepSURF通过替换泛型为自定义类型并生成特质实现，使模糊器能模拟用户定义行为；同时利用LLM动态增强模糊测试工具，探索复杂API交互。

Result: 在27个真实Rust库的评估中，deepSURF成功重现了20个已知内存安全漏洞，并发现了6个新漏洞，表现优于现有工具。

Conclusion: deepSURF通过创新方法显著提升了Rust内存安全漏洞的检测能力，为不安全代码的自动化分析提供了有效解决方案。

Abstract: Although Rust ensures memory safety by default, it also permits the use of
unsafe code, which can introduce memory safety vulnerabilities if misused.
Unfortunately, existing tools for detecting memory bugs in Rust typically
exhibit limited detection capabilities, inadequately handle Rust-specific
types, or rely heavily on manual intervention.
  To address these limitations, we present deepSURF, a tool that integrates
static analysis with Large Language Model (LLM)-guided fuzzing harness
generation to effectively identify memory safety vulnerabilities in Rust
libraries, specifically targeting unsafe code. deepSURF introduces a novel
approach for handling generics by substituting them with custom types and
generating tailored implementations for the required traits, enabling the
fuzzer to simulate user-defined behaviors within the fuzzed library.
Additionally, deepSURF employs LLMs to augment fuzzing harnesses dynamically,
facilitating exploration of complex API interactions and significantly
increasing the likelihood of exposing memory safety vulnerabilities. We
evaluated deepSURF on 27 real-world Rust crates, successfully rediscovering 20
known memory safety bugs and uncovering 6 previously unknown vulnerabilities,
demonstrating clear improvements over state-of-the-art tools.

</details>


### [70] [PhishDebate: An LLM-Based Multi-Agent Framework for Phishing Website Detection](https://arxiv.org/abs/2506.15656)
*Wenhao Li,Selvakumar Manickam,Yung-wey Chong,Shankar Karuppayah*

Main category: cs.CR

TL;DR: 本文提出PhishDebate框架，通过多智能体辩论机制提升钓鱼网站检测的准确性与可解释性，显著优于单智能体方法。


<details>
  <summary>Details</summary>
Motivation: 现有钓鱼检测方法依赖单智能体分类，存在幻觉风险且缺乏可解释性，亟需更鲁棒的解决方案。

Method: 采用模块化多智能体辩论框架（4个专项分析代理+协调员+裁决员），分别解析URL结构、HTML组成、语义内容及品牌仿冒特征。

Result: 在真实钓鱼数据集上实现98.2%召回率与真阳性率，超越单智能体及思维链基线方法。

Conclusion: PhishDebate通过结构化辩论机制实现高精度检测，模块化设计支持灵活配置，具有实际部署价值。

Abstract: Phishing websites continue to pose a significant cybersecurity threat, often
leveraging deceptive structures, brand impersonation, and social engineering
tactics to evade detection. While recent advances in large language models
(LLMs) have enabled improved phishing detection through contextual
understanding, most existing approaches rely on single-agent classification
facing the risks of hallucination and lack interpretability or robustness. To
address these limitations, we propose PhishDebate, a modular multi-agent
LLM-based debate framework for phishing website detection. PhishDebate employs
four specialized agents to independently analyze different textual aspects of a
webpage--URL structure, HTML composition, semantic content, and brand
impersonation--under the coordination of a Moderator and a final Judge. Through
structured debate and divergent thinking, the framework delivers more accurate
and interpretable decisions. Extensive evaluations on commercial LLMs
demonstrate that PhishDebate achieves 98.2% recall and 98.2% True Positive Rate
(TPR) on a real-world phishing dataset, and outperforms single-agent and Chain
of Thought (CoT) baselines. Additionally, its modular design allows agent-level
configurability, enabling adaptation to varying resource and application
requirements.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [71] [CALM: Contextual Analog Logic with Multimodality](https://arxiv.org/abs/2506.14936)
*Maxwell J. Jacobson,Corey J. Maley,Yexiang Xue*

Main category: cs.AI

TL;DR: 本文提出了一种结合符号推理与神经生成的多模态上下文类比逻辑（CALM），通过神经网络计算模拟真值并约束搜索，实现了在多模态环境中的稳健推理与决策。


<details>
  <summary>Details</summary>
Motivation: 传统二值逻辑系统无法捕捉人类决策的细微差别，且在多模态环境中需要人工标注，缺乏灵活性。神经网络虽能提取多模态数据的丰富信息，但缺乏可解释的推理结构。CALM旨在弥合逻辑与神经感知之间的鸿沟。

Method: CALM使用领域树表示每个谓词，通过神经网络迭代优化其模拟真值，并结合符号推理模块确保约束满足，从而在多模态输入上进行推理。

Result: 在填空式物体放置任务中，CALM以92.2%的准确率超越经典逻辑（86.3%）和LLM基线（59.4%），并生成符合逻辑约束与人类偏好的空间热图。

Conclusion: CALM展示了在多模态环境中结合逻辑结构与偏好的潜力，为需要逻辑精确性、可解释性及神经网络多模态处理能力的下一代AI系统奠定了基础。

Abstract: In this work, we introduce Contextual Analog Logic with Multimodality (CALM).
CALM unites symbolic reasoning with neural generation, enabling systems to make
context-sensitive decisions grounded in real-world multi-modal data.
  Background: Classic bivalent logic systems cannot capture the nuance of human
decision-making. They also require human grounding in multi-modal environments,
which can be ad-hoc, rigid, and brittle. Neural networks are good at extracting
rich contextual information from multi-modal data, but lack interpretable
structures for reasoning.
  Objectives: CALM aims to bridge the gap between logic and neural perception,
creating an analog logic that can reason over multi-modal inputs. Without this
integration, AI systems remain either brittle or unstructured, unable to
generalize robustly to real-world tasks. In CALM, symbolic predicates evaluate
to analog truth values computed by neural networks and constrained search.
  Methods: CALM represents each predicate using a domain tree, which
iteratively refines its analog truth value when the contextual groundings of
its entities are determined. The iterative refinement is predicted by neural
networks capable of capturing multi-modal information and is filtered through a
symbolic reasoning module to ensure constraint satisfaction.
  Results: In fill-in-the-blank object placement tasks, CALM achieved 92.2%
accuracy, outperforming classical logic (86.3%) and LLM (59.4%) baselines. It
also demonstrated spatial heatmap generation aligned with logical constraints
and delicate human preferences, as shown by a human study.
  Conclusions: CALM demonstrates the potential to reason with logic structure
while aligning with preferences in multi-modal environments. It lays the
foundation for next-gen AI systems that require the precision and
interpretation of logic and the multimodal information processing of neural
networks.

</details>


### [72] [MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2506.14990)
*Tristan Tomilin,Luka van den Boogaard,Samuel Garcin,Bram Grooten,Meng Fang,Mykola Pechenizkiy*

Main category: cs.AI

TL;DR: 本文介绍了首个专为持续多智能体强化学习（CMARL）设计的基准测试MEAL，利用JAX实现GPU加速，解决了现有基准测试在CPU上运行导致的性能瓶颈问题，并通过实验揭示了现有方法在复杂环境中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习基准测试在持续学习（CL）与多智能体协作场景的结合方面研究不足，且CPU运行环境导致计算瓶颈，限制了任务序列的长度。

Method: 提出MEAL基准测试，采用JAX框架实现GPU加速，支持在普通台式机上快速完成100个任务的持续学习序列，并通过消融实验分析关键架构与算法特征。

Result: 实验表明，简单组合现有CL与MARL方法在简单环境中表现良好，但在需要持续协调与适应的复杂环境中失效；消融研究识别了CMARL的关键设计要素。

Conclusion: MEAL填补了CMARL基准测试的空白，其GPU加速设计显著提升了实验效率，同时揭示了当前方法在复杂多智能体持续学习中的不足与改进方向。

Abstract: Benchmarks play a crucial role in the development and analysis of
reinforcement learning (RL) algorithms, with environment availability strongly
impacting research. One particularly underexplored intersection is continual
learning (CL) in cooperative multi-agent settings. To remedy this, we introduce
MEAL (Multi-agent Environments for Adaptive Learning), the first benchmark
tailored for continual multi-agent reinforcement learning (CMARL). Existing CL
benchmarks run environments on the CPU, leading to computational bottlenecks
and limiting the length of task sequences. MEAL leverages JAX for GPU
acceleration, enabling continual learning across sequences of 100 tasks on a
standard desktop PC in a few hours. We show that naively combining popular CL
and MARL methods yields strong performance on simple environments, but fails to
scale to more complex settings requiring sustained coordination and adaptation.
Our ablation study identifies architectural and algorithmic features critical
for CMARL on MEAL.

</details>


### [73] [Truncated Proximal Policy Optimization](https://arxiv.org/abs/2506.15050)
*Tiantian Fan,Lingjun Liu,Yu Yue,Jiaze Chen,Chengyi Wang,Qiying Yu,Chi Zhang,Zhiqi Lin,Ruofei Zhu,Yufeng Yuan,Xiaochen Zuo,Bole Ma,Mofan Zhang,Gaohong Liu,Ru Zhang,Haotian Zhou,Cong Xie,Ruidong Zhu,Zhi Zhang,Xin Liu,Mingxuan Wang,Lin Yan,Yonghui Wu*

Main category: cs.AI

TL;DR: 本文提出了一种名为截断近端策略优化（T-PPO）的新方法，通过优化策略更新和限制生成长度来提高大型语言模型（LLM）的训练效率。该方法结合了扩展广义优势估计（EGAE）和计算优化机制，显著提升了训练速度，并在AIME 2024的32B基础模型上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 近端策略优化（PPO）等强化学习方法在训练大型语言模型时效率较低，尤其是生成长文本时硬件利用率不足。本文旨在解决这一问题，提出一种更高效的训练方法。

Method: 提出了截断近端策略优化（T-PPO），包括扩展广义优势估计（EGAE）以从不完整响应中估计优势，以及一种计算优化机制，通过选择性过滤提示和截断标记来减少冗余计算。

Result: 实验结果表明，T-PPO将推理型大型语言模型的训练效率提高了2.5倍，并且在AIME 2024的32B基础模型上表现优于现有竞争方法。

Conclusion: T-PPO通过优化策略更新和生成长度限制，显著提高了训练效率，同时保持了收敛性能，为大型语言模型的强化学习训练提供了一种高效解决方案。

Abstract: Recently, test-time scaling Large Language Models (LLMs) have demonstrated
exceptional reasoning capabilities across scientific and professional tasks by
generating long chains-of-thought (CoT). As a crucial component for developing
these reasoning models, reinforcement learning (RL), exemplified by Proximal
Policy Optimization (PPO) and its variants, allows models to learn through
trial and error. However, PPO can be time-consuming due to its inherent
on-policy nature, which is further exacerbated by increasing response lengths.
In this work, we propose Truncated Proximal Policy Optimization (T-PPO), a
novel extension to PPO that improves training efficiency by streamlining policy
update and length-restricted response generation. T-PPO mitigates the issue of
low hardware utilization, an inherent drawback of fully synchronized
long-generation procedures, where resources often sit idle during the waiting
periods for complete rollouts. Our contributions are two-folds. First, we
propose Extended Generalized Advantage Estimation (EGAE) for advantage
estimation derived from incomplete responses while maintaining the integrity of
policy learning. Second, we devise a computationally optimized mechanism that
allows for the independent optimization of the policy and value models. By
selectively filtering prompt and truncated tokens, this mechanism reduces
redundant computations and accelerates the training process without sacrificing
convergence performance. We demonstrate the effectiveness and efficacy of T-PPO
on AIME 2024 with a 32B base model. The experimental results show that T-PPO
improves the training efficiency of reasoning LLMs by up to 2.5x and
outperforms its existing competitors.

</details>


### [74] [HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges](https://arxiv.org/abs/2506.15196)
*Xianliang Yang,Ling Zhang,Haolong Qian,Lei Song,Jiang Bian*

Main category: cs.AI

TL;DR: HeurAgenix是一种基于大语言模型(LLM)的两阶段超启发式框架，通过演化启发式规则并动态选择最优策略，显著提升组合优化问题的求解性能。


<details>
  <summary>Details</summary>
Motivation: 传统启发式算法设计依赖人工经验且难以泛化，而现有方法在复杂组合优化问题中表现有限，亟需自动化且通用的解决方案。

Method: 1. 启发式演化阶段：利用LLM对比种子解与优质解，提取可复用的演化策略\n2. 动态选择阶段：通过LLM的感知能力实时选取最优启发式，支持轻量化微调模型\n3. 双奖励机制：联合选择偏好和状态感知信号，解决标注噪声问题。

Result: 在标准测试集上，HeurAgenix不仅超越现有LLM超启发式方法，还能媲美或优于专业求解器。

Conclusion: 该框架通过LLM驱动的自动化启发式生成与选择，为组合优化问题提供了高效、通用的解决方案，代码已开源。

Abstract: Heuristic algorithms play a vital role in solving combinatorial optimization
(CO) problems, yet traditional designs depend heavily on manual expertise and
struggle to generalize across diverse instances. We introduce
\textbf{HeurAgenix}, a two-stage hyper-heuristic framework powered by large
language models (LLMs) that first evolves heuristics and then selects among
them automatically. In the heuristic evolution phase, HeurAgenix leverages an
LLM to compare seed heuristic solutions with higher-quality solutions and
extract reusable evolution strategies. During problem solving, it dynamically
picks the most promising heuristic for each problem state, guided by the LLM's
perception ability. For flexibility, this selector can be either a
state-of-the-art LLM or a fine-tuned lightweight model with lower inference
cost. To mitigate the scarcity of reliable supervision caused by CO complexity,
we fine-tune the lightweight heuristic selector with a dual-reward mechanism
that jointly exploits singals from selection preferences and state perception,
enabling robust selection under noisy annotations. Extensive experiments on
canonical benchmarks show that HeurAgenix not only outperforms existing
LLM-based hyper-heuristics but also matches or exceeds specialized solvers.
Code is available at https://github.com/microsoft/HeurAgenix.

</details>


### [75] [Multi-Agent Reinforcement Learning for Autonomous Multi-Satellite Earth Observation: A Realistic Case Study](https://arxiv.org/abs/2506.15207)
*Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Jimmy Cao,Ryszard Kowalczyk*

Main category: cs.AI

TL;DR: 本文探讨了利用强化学习（RL）和多智能体强化学习（MARL）解决低地球轨道（LEO）卫星群在自主协调地球观测任务中的挑战，并通过仿真环境验证了多种MARL算法的有效性。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星数量的激增为地球观测任务带来了革命性变化，但多卫星系统的自主协调仍面临实时决策、资源限制和部分可观测性等挑战，传统优化方法难以应对。

Method: 研究通过单卫星操作建模扩展到多卫星星座，采用MARL框架（如PPO、IPPO、MAPPO和HAPPO），在近真实卫星仿真环境中解决能源、数据存储限制及分散协调的复杂性。

Result: 实验表明，MARL能有效平衡成像与资源管理，并解决多卫星协调中的非平稳性和奖励依赖性问题，为自主卫星操作提供了性能稳定的算法选择。

Conclusion: 本研究为分散式地球观测任务的政策学习提供了实践指导，奠定了自主卫星操作的基础，展示了MARL在动态任务中的潜力。

Abstract: The exponential growth of Low Earth Orbit (LEO) satellites has revolutionised
Earth Observation (EO) missions, addressing challenges in climate monitoring,
disaster management, and more. However, autonomous coordination in
multi-satellite systems remains a fundamental challenge. Traditional
optimisation approaches struggle to handle the real-time decision-making
demands of dynamic EO missions, necessitating the use of Reinforcement Learning
(RL) and Multi-Agent Reinforcement Learning (MARL). In this paper, we
investigate RL-based autonomous EO mission planning by modelling
single-satellite operations and extending to multi-satellite constellations
using MARL frameworks. We address key challenges, including energy and data
storage limitations, uncertainties in satellite observations, and the
complexities of decentralised coordination under partial observability. By
leveraging a near-realistic satellite simulation environment, we evaluate the
training stability and performance of state-of-the-art MARL algorithms,
including PPO, IPPO, MAPPO, and HAPPO. Our results demonstrate that MARL can
effectively balance imaging and resource management while addressing
non-stationarity and reward interdependency in multi-satellite coordination.
The insights gained from this study provide a foundation for autonomous
satellite operations, offering practical guidelines for improving policy
learning in decentralised EO missions.

</details>


### [76] [Joint Computation Offloading and Resource Allocation for Uncertain Maritime MEC via Cooperation of UAVs and Vessels](https://arxiv.org/abs/2506.15225)
*Jiahao You,Ziye Jia,Chao Dong,Qihui Wu,Zhu Han*

Main category: cs.AI

TL;DR: 本文提出了一种基于无人机和船舶协作的海事边缘计算框架，通过Lyapunov优化和异构智能体强化学习解决不确定任务下的计算卸载与资源分配问题。


<details>
  <summary>Details</summary>
Motivation: 海事物联网(MIoT)计算需求激增，但海上任务的不确定性导致传统计算卸载与资源分配效率低下，亟需新型解决方案。

Method: 1) 构建无人机-船舶协同MEC框架；2) 使用Lyapunov优化处理任务不确定性；3) 将问题转化为马尔可夫博弈；4) 提出异构智能体SAC算法求解。

Result: 仿真实验验证了所提方法在优化执行时间和动态资源分配方面的有效性，显著提升了海上计算任务处理效率。

Conclusion: 该研究为海事不确定计算场景提供了创新解决方案，通过协同边缘计算架构和智能优化算法实现了高效资源调度。

Abstract: The computation demands from the maritime Internet of Things (MIoT) increase
rapidly in recent years, and the unmanned aerial vehicles (UAVs) and vessels
based multi-access edge computing (MEC) can fulfill these MIoT requirements.
However, the uncertain maritime tasks present significant challenges of
inefficient computation offloading and resource allocation. In this paper, we
focus on the maritime computation offloading and resource allocation through
the cooperation of UAVs and vessels, with consideration of uncertain tasks.
Specifically, we propose a cooperative MEC framework for computation offloading
and resource allocation, including MIoT devices, UAVs and vessels. Then, we
formulate the optimization problem to minimize the total execution time. As for
the uncertain MIoT tasks, we leverage Lyapunov optimization to tackle the
unpredictable task arrivals and varying computational resource availability. By
converting the long-term constraints into short-term constraints, we obtain a
set of small-scale optimization problems. Further, considering the
heterogeneity of actions and resources of UAVs and vessels, we reformulate the
small-scale optimization problem into a Markov game (MG). Moreover, a
heterogeneous-agent soft actor-critic is proposed to sequentially update
various neural networks and effectively solve the MG problem. Finally,
simulations are conducted to verify the effectiveness in addressing
computational offloading and resource allocation.

</details>


### [77] [Efficient and Generalizable Environmental Understanding for Visual Navigation](https://arxiv.org/abs/2506.15377)
*Ruoyu Wang,Xinshu Li,Chen Wang,Lina Yao*

Main category: cs.AI

TL;DR: 本文提出了一种基于因果关系的导航方法（CAN），通过引入因果理解模块来增强智能体对环境序列数据的理解能力，实验表明该方法在多种任务和模拟环境中均优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉导航方法通常同时处理所有历史观测数据，忽略了数据内部的关联结构，这限制了任务性能的进一步提升。本文从因果关系的角度分析了导航任务的特性，旨在解决这一局限性。

Method: 提出了因果感知导航（CAN）框架，其中包含一个因果理解模块（Causal Understanding Module），用于增强智能体对环境的理解能力。该方法无需额外计算开销，适用于强化学习和监督学习场景。

Result: 实验评估表明，CAN方法在多种任务和模拟环境中均显著优于基线模型。消融研究进一步验证了因果理解模块的有效性，该模块在不同学习设置下均表现出良好的泛化能力。

Conclusion: 通过引入因果关系的视角，CAN方法成功提升了导航任务的性能，其因果理解模块在无需增加计算成本的情况下，显著增强了智能体的环境理解能力。

Abstract: Visual Navigation is a core task in Embodied AI, enabling agents to navigate
complex environments toward given objectives. Across diverse settings within
Navigation tasks, many necessitate the modelling of sequential data accumulated
from preceding time steps. While existing methods perform well, they typically
process all historical observations simultaneously, overlooking the internal
association structure within the data, which may limit the potential for
further improvements in task performance. We address this by examining the
unique characteristics of Navigation tasks through the lens of causality,
introducing a causal framework to highlight the limitations of conventional
sequential methods. Leveraging this insight, we propose Causality-Aware
Navigation (CAN), which incorporates a Causal Understanding Module to enhance
the agent's environmental understanding capability. Empirical evaluations show
that our approach consistently outperforms baselines across various tasks and
simulation environments. Extensive ablations studies attribute these gains to
the Causal Understanding Module, which generalizes effectively in both
Reinforcement and Supervised Learning settings without computational overhead.

</details>


### [78] [Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents](https://arxiv.org/abs/2506.15567)
*Aline Dobrovsky,Konstantin Schekotihin,Christian Burmer*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型（LLM）的规划代理（LPA），用于辅助失效分析（FA）工程师处理复杂案例，通过整合先进规划能力和外部工具实现自动化查询处理与报告生成。


<details>
  <summary>Details</summary>
Motivation: 失效分析（FA）是高度复杂且知识密集的过程，随着AI模型数量的增加，如何协调这些组件形成高效工作流成为关键挑战。

Method: 设计并实现了一种LLM驱动的规划代理（LPA），结合外部工具使用和自主规划能力，支持复杂查询处理、数据检索及生成可读响应。

Result: 评估结果表明，LPA在支持FA任务方面具有操作有效性和可靠性。

Conclusion: LPA通过整合LLM与规划能力，为FA工程师提供了高效的自动化辅助工具，显著提升了分析流程的连贯性和效率。

Abstract: Failure Analysis (FA) is a highly intricate and knowledge-intensive process.
The integration of AI components within the computational infrastructure of FA
labs has the potential to automate a variety of tasks, including the detection
of non-conformities in images, the retrieval of analogous cases from diverse
data sources, and the generation of reports from annotated images. However, as
the number of deployed AI models increases, the challenge lies in orchestrating
these components into cohesive and efficient workflows that seamlessly
integrate with the FA process.
  This paper investigates the design and implementation of a Large Language
Model (LLM)-based Planning Agent (LPA) to assist FA engineers in solving their
analysis cases. The LPA integrates LLMs with advanced planning capabilities and
external tool utilization, enabling autonomous processing of complex queries,
retrieval of relevant data from external systems, and generation of
human-readable responses. Evaluation results demonstrate the agent's
operational effectiveness and reliability in supporting FA tasks.

</details>


### [79] [The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games](https://arxiv.org/abs/2506.15624)
*Lyle Goodyear,Rachel Guo,Ramesh Johari*

Main category: cs.AI

TL;DR: 本文提出了一个统一框架，用于系统构建大语言模型（LLM）代理在重复多智能体博弈中的自然语言状态表示，并通过实验验证了不同状态表示对代理行为的影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究在LLM代理博弈中采用临时性方法编码博弈历史，这不仅模糊了状态表示对代理行为的影响，还限制了研究间的可比性。

Method: 框架从三个维度刻画状态表示方法：动作信息量（是否包含历史动作）、奖励信息量（是否描述获得奖励）以及提示风格（自然语言压缩程度）。该框架被应用于动态自私路由博弈实验。

Result: 实验发现：(1)提供历史摘要而非完整记录；(2)展示遗憾值而非原始收益；(3)限制他人动作信息的状态表示，能使LLM代理行为更接近博弈论均衡预测且稳定性更高。其他表示则可能导致显著偏离均衡或动态博弈波动加剧。

Conclusion: 自然语言状态表示的构建方式显著影响LLM代理的博弈行为，特定类型的表示能有效引导代理行为趋近理论均衡，为未来研究提供了系统性设计范式。

Abstract: Large Language Models (LLMs) have shown promise as decision-makers in dynamic
settings, but their stateless nature necessitates creating a natural language
representation of history. We present a unifying framework for systematically
constructing natural language "state" representations for prompting LLM agents
in repeated multi-agent games. Previous work on games with LLM agents has taken
an ad hoc approach to encoding game history, which not only obscures the impact
of state representation on agents' behavior, but also limits comparability
between studies. Our framework addresses these gaps by characterizing methods
of state representation along three axes: action informativeness (i.e., the
extent to which the state representation captures actions played); reward
informativeness (i.e., the extent to which the state representation describes
rewards obtained); and prompting style (or natural language compression, i.e.,
the extent to which the full text history is summarized).
  We apply this framework to a dynamic selfish routing game, chosen because it
admits a simple equilibrium both in theory and in human subject experiments
\cite{rapoport_choice_2009}. Despite the game's relative simplicity, we find
that there are key dependencies of LLM agent behavior on the natural language
state representation. In particular, we observe that representations which
provide agents with (1) summarized, rather than complete, natural language
representations of past history; (2) information about regrets, rather than raw
payoffs; and (3) limited information about others' actions lead to behavior
that more closely matches game theoretic equilibrium predictions, and with more
stable game play by the agents. By contrast, other representations can exhibit
either large deviations from equilibrium, higher variation in dynamic game play
over time, or both.

</details>


### [80] [The AI Policy Module: Developing Computer Science Student Competency in AI Ethics and Policy](https://arxiv.org/abs/2506.15639)
*James Weichert,Daniel Dunlap,Mohammed Farghally,Hoda Eldardiry*

Main category: cs.AI

TL;DR: 本文介绍了一个AI政策模块的开发与实施，旨在将AI政策讨论引入计算机科学课程，帮助学生将伦理原则转化为实践，并提升他们对AI伦理与政策的关注与参与能力。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术在个人和专业领域的广泛应用，AI伦理和政策治理的需求日益增加。然而，现有的计算机科学课程未能充分培养学生将抽象伦理原则和政策偏好转化为AI系统设计与开发的能力。

Method: 作者开发并更新了一个AI政策模块（AI Policy Module 2.0），包括一个关于“AI监管”的技术作业。通过课前课后调查，评估学生对AI伦理和政策的态度变化。

Result: 模块实施后，学生对AI技术伦理影响的关注度提高，同时对参与AI监管讨论的信心增强。AI监管作业被证明是探索AI对齐限度和强调政策在解决伦理挑战中作用的有效工具。

Conclusion: AI政策模块成功提升了学生对AI伦理与政策的理解和参与能力，为计算机科学课程中融入AI政策教育提供了可行方案。

Abstract: As artificial intelligence (AI) further embeds itself into many settings
across personal and professional contexts, increasing attention must be paid
not only to AI ethics, but also to the governance and regulation of AI
technologies through AI policy. However, the prevailing post-secondary
computing curriculum is currently ill-equipped to prepare future AI
practitioners to confront increasing demands to implement abstract ethical
principles and normative policy preferences into the design and development of
AI systems. We believe that familiarity with the 'AI policy landscape' and the
ability to translate ethical principles to practices will in the future
constitute an important responsibility for even the most technically-focused AI
engineers.
  Toward preparing current computer science (CS) students for these new
expectations, we developed an AI Policy Module to introduce discussions of AI
policy into the CS curriculum. Building on a successful pilot in fall 2024, in
this innovative practice full paper we present an updated and expanded version
of the module, including a technical assignment on "AI regulation". We present
the findings from our pilot of the AI Policy Module 2.0, evaluating student
attitudes towards AI ethics and policy through pre- and post-module surveys.
Following the module, students reported increased concern about the ethical
impacts of AI technologies while also expressing greater confidence in their
abilities to engage in discussions about AI regulation. Finally, we highlight
the AI Regulation Assignment as an effective and engaging tool for exploring
the limits of AI alignment and emphasizing the role of 'policy' in addressing
ethical challenges.

</details>


### [81] [Exploring and Exploiting the Inherent Efficiency within Large Reasoning Models for Self-Guided Efficiency Enhancement](https://arxiv.org/abs/2506.15647)
*Weixiang Zhao,Jiahe Guo,Yang Deng,Xingyu Sui,Yulin Hu,Yanyan Zhao,Wanxiang Che,Bing Qin,Tat-Seng Chua,Ting Liu*

Main category: cs.AI

TL;DR: 大型推理模型(LRMs)存在过度思考问题，导致推理效率低下。研究发现模型本身具备简洁推理能力，提出两种轻量级方法提升效率：无需训练的激活导向技术和自奖励强化学习框架。实验证明这些方法能显著缩短推理长度并保持性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型在复杂问题解决中表现出过度思考现象，生成冗余内容导致效率降低和推理成本增加。研究旨在探索这种低效性的表征和行为根源，并开发提升效率的方法。

Method: 提出两种方法：1) 效率导向(Efficiency Steering)，一种无需训练的激活导向技术，通过模型表示空间中的单一方向调节推理行为；2) 自奖励效率强化学习(Self-Rewarded Efficiency RL)，动态平衡任务准确性和简洁性的强化学习框架。

Result: 在七个大型推理模型和多个数学推理基准上的实验表明，所提方法能显著减少推理长度(平均降低30%)，同时保持或提升任务性能(准确率提高2-5%)。

Conclusion: 研究表明通过引导模型内在能力，可以以自指导方式提升推理效率。这一发现为开发更高效的大型语言模型提供了新思路，具有重要应用价值。

Abstract: Recent advancements in large reasoning models (LRMs) have significantly
enhanced language models' capabilities in complex problem-solving by emulating
human-like deliberative thinking. However, these models often exhibit
overthinking (i.e., the generation of unnecessarily verbose and redundant
content), which hinders efficiency and inflates inference cost. In this work,
we explore the representational and behavioral origins of this inefficiency,
revealing that LRMs inherently possess the capacity for more concise reasoning.
Empirical analyses show that correct reasoning paths vary significantly in
length, and the shortest correct responses often suffice, indicating untapped
efficiency potential. Exploiting these findings, we propose two lightweight
methods to enhance LRM efficiency. First, we introduce Efficiency Steering, a
training-free activation steering technique that modulates reasoning behavior
via a single direction in the model's representation space. Second, we develop
Self-Rewarded Efficiency RL, a reinforcement learning framework that
dynamically balances task accuracy and brevity by rewarding concise correct
solutions. Extensive experiments on seven LRM backbones across multiple
mathematical reasoning benchmarks demonstrate that our methods significantly
reduce reasoning length while preserving or improving task performance. Our
results highlight that reasoning efficiency can be improved by leveraging and
guiding the intrinsic capabilities of existing models in a self-guided manner.

</details>


### [82] [SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence](https://arxiv.org/abs/2506.15672)
*Yao Zhang,Chenyang Lin,Shijie Tang,Haokun Chen,Shijie Zhou,Yunpu Ma,Volker Tresp*

Main category: cs.AI

TL;DR: SwarmAgentic是一个全自动代理系统生成框架，通过语言驱动探索和群体智能优化，实现了从零开始的代理生成与协作优化，在六项开放任务中显著超越基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统生成框架缺乏全自主性，无法实现从零生成、自优化功能和协作优化，限制了适应性和可扩展性。

Method: 受粒子群优化(PSO)启发，框架维护候选系统种群，通过反馈引导更新联合优化代理功能与协作，支持系统级结构的高效搜索。

Result: 在旅行规划等六项任务中，仅需任务描述和目标函数即实现261.8%的相对性能提升，验证了全自动化框架在非结构化任务中的有效性。

Conclusion: 该框架将群体智能与全自动多代理生成相结合，为可扩展的自主代理系统设计迈出重要一步，代码已开源。

Abstract: The rapid progress of Large Language Models has advanced agentic systems in
decision-making, coordination, and task execution. Yet, existing agentic system
generation frameworks lack full autonomy, missing from-scratch agent
generation, self-optimizing agent functionality, and collaboration, limiting
adaptability and scalability. We propose SwarmAgentic, a framework for fully
automated agentic system generation that constructs agentic systems from
scratch and jointly optimizes agent functionality and collaboration as
interdependent components through language-driven exploration. To enable
efficient search over system-level structures, SwarmAgentic maintains a
population of candidate systems and evolves them via feedback-guided updates,
drawing inspiration from Particle Swarm Optimization (PSO). We evaluate our
method on six real-world, open-ended, and exploratory tasks involving
high-level planning, system-level coordination, and creative reasoning. Given
only a task description and an objective function, SwarmAgentic outperforms all
baselines, achieving a +261.8% relative improvement over ADAS on the
TravelPlanner benchmark, highlighting the effectiveness of full automation in
structurally unconstrained tasks. This framework marks a significant step
toward scalable and autonomous agentic system design, bridging swarm
intelligence with fully automated system multi-agent generation. Our code is
publicly released at https://yaoz720.github.io/SwarmAgentic/.

</details>


### [83] [Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence](https://arxiv.org/abs/2506.15677)
*Yining Hong,Rui Sun,Bingxuan Li,Xingcheng Yao,Maxine Wu,Alexander Chien,Da Yin,Ying Nian Wu,Zhecan James Wang,Kai-Wei Chang*

Main category: cs.AI

TL;DR: 本文提出了一种新型AI代理范式——具身网络代理，通过整合3D模拟环境与功能性网络接口，构建了跨物理与数字领域的统一任务平台与基准测试，揭示了当前AI系统与人类能力间的显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理在数字信息推理与物理世界交互之间存在割裂，限制了其在需要跨领域协同任务（如在线烹饪、动态导航等）中的表现，亟需开发能融合两种能力的智能体。

Method: 开发了具身网络代理任务环境平台，将真实3D室内外环境与功能性网络接口深度整合，并构建包含烹饪、导航等任务的基准测试套件，用于系统评估跨领域智能。

Result: 实验表明，当前最先进AI系统在跨物理-数字领域任务上的表现与人类能力存在显著差距，为具身认知与网络知识访问的交叉研究提供了挑战与机遇。

Conclusion: 该研究通过建立开放平台与基准测试，为开发融合具身交互与网络推理的通用智能体奠定了基础，相关资源已开源。

Abstract: AI agents today are mostly siloed - they either retrieve and reason over vast
amount of digital information and knowledge obtained online; or interact with
the physical world through embodied perception, planning and action - but
rarely both. This separation limits their ability to solve tasks that require
integrated physical and digital intelligence, such as cooking from online
recipes, navigating with dynamic map data, or interpreting real-world landmarks
using web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI
agents that fluidly bridge embodiment and web-scale reasoning. To
operationalize this concept, we first develop the Embodied Web Agents task
environments, a unified simulation platform that tightly integrates realistic
3D indoor and outdoor environments with functional web interfaces. Building
upon this platform, we construct and release the Embodied Web Agents Benchmark,
which encompasses a diverse suite of tasks including cooking, navigation,
shopping, tourism, and geolocation - all requiring coordinated reasoning across
physical and digital realms for systematic assessment of cross-domain
intelligence. Experimental results reveal significant performance gaps between
state-of-the-art AI systems and human capabilities, establishing both
challenges and opportunities at the intersection of embodied cognition and
web-scale knowledge access. All datasets, codes and websites are publicly
available at our project page https://embodied-web-agent.github.io/.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [84] [A survey of Chernoff and Hoeffding bounds](https://arxiv.org/abs/2506.15612)
*Alexandros V. Gerbessiotis*

Main category: cs.DM

TL;DR: 本文是一篇综述性论文，探讨了Chernoff和Hoeffding开创性论文中的原始界限，并涵盖了多种形式的衍生界限。


<details>
  <summary>Details</summary>
Motivation: 旨在为感兴趣的研究者提供一个参考界限的全面资源库。

Method: 论文不仅讨论了原始界限，还提供了多种衍生界限的完整证明。

Result: 通过详尽的证明和讨论，论文成功汇集了多种形式的界限，为研究者提供了丰富的参考资料。

Conclusion: 该论文作为一个参考资源库，为研究者提供了关于Chernoff和Hoeffding界限及其衍生形式的全面概述和证明。

Abstract: This is a survey paper that discusses the original bounds of the seminal
papers by Chernoff and Hoeffding. Moreover, it includes a variety of derivative
bounds in a variety of forms. Complete proofs are provided as needed. The
intent is to provide a repository of reference bounds for the interested
researcher.

</details>
