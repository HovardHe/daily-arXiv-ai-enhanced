<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 3]
- [math.OC](#math.OC) [Total: 16]
- [math.NT](#math.NT) [Total: 11]
- [math.LO](#math.LO) [Total: 4]
- [math.CO](#math.CO) [Total: 12]
- [cs.CR](#cs.CR) [Total: 24]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.DM](#cs.DM) [Total: 1]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Identifiability by common backdoor in summary causal graphs of time series](https://arxiv.org/abs/2506.14862)
*Clément Yvernes,Charles K. Assaad,Emilie Devijver,Eric Gaussier*

Main category: math.ST

TL;DR: 本文研究了时间序列中干预的可识别性问题，探讨了在仅能获得摘要因果图的情况下，如何通过共同后门集判断干预的总效应是否可从观测数据中计算。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决时间序列中多干预、多效应的可识别性问题，特别是在真实因果图仅能以摘要形式提供的情况下，评估干预总效应是否可通过无do公式从观测数据中计算。

Method: 方法包括分析时间序列（无论是否具有时间一致性）中共同后门集的存在条件，并提供了有限复杂度的算法来判断问题的可识别性。

Result: 研究结果为时间序列中干预的可识别性建立了条件，并开发了算法来判定是否存在共同后门集，从而确定问题是否可识别。

Conclusion: 结论指出，在特定条件下，时间序列中的干预效应可以通过共同后门集进行识别，且提出的算法能有效判断可识别性，为因果推断提供了实用工具。

Abstract: The identifiability problem for interventions aims at assessing whether the
total effect of some given interventions can be written with a do-free formula,
and thus be computed from observational data only. We study this problem,
considering multiple interventions and multiple effects, in the context of time
series when only abstractions of the true causal graph in the form of summary
causal graphs are available. We focus in this study on identifiability by a
common backdoor set, and establish, for time series with and without
consistency throughout time, conditions under which such a set exists. We also
provide algorithms of limited complexity to decide whether the problem is
identifiable or not.

</details>


### [2] [Probabilistic closed-form formulas for pricing nonlinear payoff variance and volatility derivatives under Schwartz model with time-varying log-return volatility](https://arxiv.org/abs/2506.15386)
*Nontawat Bunchak,Udomsak Rakwongwan,Phiraphat Sutthimat*

Main category: math.ST

TL;DR: 本文提出了离散时间观测下非线性收益波动率和方差衍生品的闭式解析定价公式，基于Schwartz单因子模型，解决了时变对数收益波动率假设下的定价难题，并通过蒙特卡洛模拟验证了方法的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决时变对数收益波动率假设下波动率和方差衍生品定价的解析难题，特别是在实现方差服从加权参数的非中心卡方随机变量线性组合的情况下。

Method: 采用概率密度函数方法，解析计算实现方差平方根的期望，推导波动率互换和波动率看涨期权的定价公式，并研究常数对数收益波动率情况下的简化公式及波动率敏感性（vega）。

Result: 提出了Schwartz单因子模型下波动率互换的简单闭式近似定价方法，并通过数值实验研究了价格波动率和交易日数量对波动率及方差互换公平执行价的影响。

Conclusion: 所提出的解析定价公式和近似方法在蒙特卡洛模拟中表现出高准确性和效率，为波动率和方差衍生品的定价提供了有效的理论工具。

Abstract: This paper presents closed-form analytical formulas for pricing volatility
and variance derivatives with nonlinear payoffs under discrete-time
observations. The analysis is based on a probabilistic approach assuming that
the underlying asset price follows the Schwartz one-factor model, where the
volatility of log-returns is time-varying. A difficult challenge in this
pricing problem is to solve an analytical formula under the assumption of
time-varying log-return volatility, resulting in the realized variance being
distributed according to a linear combination of independent noncentral
chi-square random variables with weighted parameters. By utilizing the
probability density function, we analytically compute the expectation of the
square root of the realized variance and derive pricing formulas for volatility
swaps. Additionally, we derive analytical pricing formulas for volatility call
options. For the payoff function without the square root, we also derive
corresponding formulas for variance swaps and variance call options.
Additionally, we study the case of constant log-return volatility; simplified
pricing formulas are derived and sensitivity with respect to volatility (vega)
is analytically studied. Furthermore,we propose simple closed-form
approximations for pricing volatility swaps under the Schwartz one-factor
model. The accuracy and efficiency of the proposed methods are demonstrated
through Monte Carlo simulations, and the impact of price volatility and the
number of trading days on fair strike prices of volatility and variance swaps
is investigated across various numerical experiments.

</details>


### [3] [Density estimation via periodic scaled Korobov kernel method with exponential decay condition](https://arxiv.org/abs/2506.15419)
*Ziyang Ye,Haoyuan Tan,Xiaoqun Wang,Zhijian He*

Main category: math.ST

TL;DR: 提出周期性缩放Korobov核方法（PSKK），通过模运算将目标密度函数周期化，结合核岭回归技术，有效解决了无界域上非周期性密度函数的估计问题，理论证明其收敛速率与传统方法相当但适用范围更广。


<details>
  <summary>Details</summary>
Motivation: 现有核方法要求密度函数具有周期性，限制了在无界域非周期分布上的应用。本文旨在消除这一限制，扩展核密度估计的适用场景。

Method: 采用模运算将目标密度周期化，在缩放Korobov空间中应用核岭回归，构建周期性缩放Korobov核（PSKK）估计器。关键改进在于无需密度函数本身具有周期性。

Result: 理论证明：对于光滑阶数$\alpha$且指数衰减的密度，PSKK达到$\mathcal{O}(M^{-1/(1+1/(2\alpha)+\epsilon)})$的MISE收敛速率（$\epsilon>0$任意小）。数值实验显示在大样本下显著优于传统核密度估计。

Conclusion: PSKK方法在保持与传统方法相同收敛速率的同时，成功将核密度估计推广至非周期无界域分布，为更广泛的统计建模提供了有效工具。

Abstract: We propose the periodic scaled Korobov kernel (PSKK) method for nonparametric
density estimation on $\mathbb{R}^d$. By first wrapping the target density into
a periodic version through modulo operation and subsequently applying kernel
ridge regression in scaled Korobov spaces, we extend the kernel approach
proposed by Kazashi and Nobile (SIAM J. Numer. Anal., 2023) and eliminate its
requirement for inherent periodicity of the density function. This key
modification enables effective estimation of densities defined on unbounded
domains. We establish rigorous mean integrated squared error (MISE) bounds,
proving that for densities with smoothness of order $\alpha$ and exponential
decay, our method achieves the $\mathcal{O}(M^{-1/(1+1/(2\alpha)+\epsilon)})$
MISE convergence rate with an arbitrarily small $\epsilon>0$. While matching
the convergence rate of the previous kernel approach, our approach applies to a
broader class of non-periodic distributions. Numerical experiments confirm the
theoretical results and demonstrate significant improvement over traditional
kernel density estimation in large-sample regimes.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [4] [On λ-Cent-Dians and Generalized-Center for Network Design: Formulations and Algorithms](https://arxiv.org/abs/2506.14839)
*Víctor Bucarey,Natividad González-Blanco,Martine Labbé,Juan A. Mesa*

Main category: math.OC

TL;DR: 本文研究了网络设计中的$\lambda$-中心问题，提出了在预算约束下设计子网络的算法方法，并探讨了不同$\lambda$值下的解决方案。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决在给定底层网络中设计高效子网络的问题，以满足一系列起点/终点需求对，同时遵循预算限制。

Method: 通过数学建模和双层结构分析$\lambda>1$的情况，引入最大$\lambda$-中心概念，并利用混合整数线性规划和Benders分解方法进行求解。

Result: 提出了完整的帕累托最优集参数化方法，并通过不等式度量评估了不同解决方案的质量。

Conclusion: 对于$\lambda\in[0,1]$，Benders分解方法能够有效扩展问题规模，为网络设计提供了实用的算法工具。

Abstract: In this paper, we study the $\lambda$-centdian problem in the domain of
Network Design. The focus is on designing a sub-network within a given
underlying network while adhering to a budget constraint. This sub-network is
intended to efficiently serve a collection of origin/destination demand pairs.
We extend the work presented in \cite{bucarey2024on}, providing an algorithmic
perspective on the generalized $\lambda$-centdian problem. In particular, we
provide a mathematical formulation for $\lambda\geq 0$ and discuss the bilevel
structure of this problem for $\lambda>1$. Furthermore, we describe a procedure
to obtain a complete parametrization of the Pareto-optimality set based on
solving two mixed integer linear formulations by introducing the concept of
maximum $\lambda$-cent-dian. We evaluate the quality of the different solution
concepts using some inequality measures. Finally, for $\lambda\in[0,1]$, we
study the implementation of a Benders decomposition method to solve it at
scale.

</details>


### [5] [An efficient co-simulation and control approach to tackle complex multi-domain energetic systems: concepts and applications of the PEGASE platform](https://arxiv.org/abs/2506.15195)
*Mathieu Vallee,Roland Baviere,Valérie Seguin,Valéry Vuillerme,Nicolas Lamaison,Michael Nikhil Descamps,Antoine Aurousseau*

Main category: math.OC

TL;DR: 本文介绍了一款名为PEGASE的新型研究软件，专为复杂多领域能源系统的先进控制策略设计、验证和部署而开发，具有高效的协同仿真引擎和集成控制解决方案。


<details>
  <summary>Details</summary>
Motivation: 面对多领域大规模能源系统的复杂性，传统的整体解决方案效率低下，需要一种能够分解问题并高效仿真的工具。

Method: PEGASE基于分治法，通过FMI标准兼容或API接口集成仿真模型，并采用多线程排序器实现不同时间步长的仿真序列，同时集成了模型预测控制（MPC）框架。

Result: PEGASE在C++中实现，提供了快速的模型构建和求解能力，支持通过工业标准协议连接硬件，成功应用于多种能源系统的仿真与控制。

Conclusion: 通过四个不同领域的应用示例，证明了PEGASE在应对各类能源系统复杂性方面的鲁棒性和通用性。

Abstract: In this paper, we present a novel research software, called PEGASE, suitable
for the design, validation and deployment of advanced control strategies for
complex multi-domain energy systems. PEGASE especially features a highly
efficient cosimulation engine, together with integrated solutions for defining
both rule-based control strategies and Model-Predictive Control (MPC). The main
principle behind the PEGASE platform is divide-and-conquer. Indeed, rather than
trying to solve a problem as a monolithic entity, which can be highly complex
for multi-domain large-scale systems, it is often more efficient to decompose
it into several domains or sub-problems, and to simulate them in a decoupled
way. To provide its cosimulation capabilities, we based PEGASE on two main
components. The first one is a framework for integrating simulation models,
which can be either compatible with the FMI standard or interfaced through an
Application Programming Interface (API). The second one is a multi-threaded
sequencer enabling several simulation sequences with different time steps. To
provide advanced control capabilities, we also equipped PEGASE with a framework
for MPC combining a comprehensive management of predictions data and a modeler
dedicated to the formulation of Mixed Integer Linear Programs. We implemented
this framework in C++ providing low formulation and resolution times for
typical applications. Connection to hardware is also available via standard
industry protocols thereby allowing PEGASE to control real energy systems. In
this paper, we show how these basic functionalities, combined with dedicated
modeling tools, enable setting up simulation and control applications suitable
for tackling the complexity of various kinds of energy systems. To illustrate
this, we present four application examples from our recent research work. These
examples cover several domains, from concentrated solar thermal plants to
optimal control of district heating networks. The variety of examples
demonstrates the robustness and genericity of the approach.

</details>


### [6] [Operational Control of a Multi-energy District Heating System: Comparison of Model-Predictive Control and Rule-Based Control](https://arxiv.org/abs/2506.15197)
*Michael Nikhil Descamps,Nicolas Lamaison,Mathieu Vallee,Roland Baviere*

Main category: math.OC

TL;DR: 本研究比较了区域供热网络（DHN）中的两种运行控制策略：基于规则的被动控制（RBC）和模型预测控制（MPC）。通过Modelica建模和Pegase平台实现，MPC在降低运营成本和应对能源波动方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 探讨多能源区域供热网络的高效控制策略，以应对能源价格波动和太阳能间歇性供应，同时满足用户需求和系统技术约束。

Method: 使用Modelica建立小规模区域供热网络模型，结合热泵、燃气锅炉、太阳能集热场和储热罐，通过Pegase平台实现RBC和MPC策略的仿真与验证。

Result: MPC策略显著降低了运营成本，尤其在处理可变电价、间歇性太阳能和储热能力时表现更高效。系统仿真可在20分钟内完成年度模拟。

Conclusion: MPC策略在多能源区域供热网络中具有显著优势，研究工具实现了Modelica仿真与复杂控制策略的高效耦合，为MPC的实施与验证提供了便捷途径。

Abstract: This study focuses on operational control strategies for a multi-energy
District Heating Network (DHN). Two control strategies are investigated and
compared: (i) a reactive rule-based control (RBC) and (ii) a model predictive
control (MPC). For the purpose of the study a small scale district heating
network is modelled using Modelica. The production plant combines a heat pump,
a gas boiler and a thermal solar field on the production side with a storage
tank for flexibility purposes. On the consumption side, the virtual buildings
are aggregated into a single consumer. We use our co-simulation and control
platform, called Pegase, to implement the studied strategies. For both
strategies the goal is to meet the consumers' demand while satisfying technical
constraints. In addition MPC has the objective to minimize the operational
costs, taking into account variable electricity prices and availability of
solar thermal resource. Different scenarios are also defined and compared to
study the effect of the heat plant sizing and forecasting error. The
operational cost is reduced when switching from RBC to a MPC. As can be
expected, MPC is more efficient when dealing with variable energy costs,
intermittent solar energy and storage capabilities. This study also
demonstrates how our tools enable an easy coupling of Modelica-based simulation
with various control strategies. It especially supports the implementation and
validation of complex MPC strategies in an efficient way, and yearly
simulations are performed within 20 minutes.

</details>


### [7] [Contribution of expert aggregation to temperature prediction part II: Second order bounds with sleeping experts](https://arxiv.org/abs/2506.15216)
*Léo Pfitzner,Olivier Wintenberger,Olivier Mestre*

Main category: math.OC

TL;DR: 本文通过引入睡眠专家框架(SEF)和梯度提升回归树改进了专家聚合(EA)的温度预测方法，提高了反应速度并减少了误差，同时采用BOA自适应聚合和元聚合策略优化性能。


<details>
  <summary>Details</summary>
Motivation: 改进第一部分中专家聚合(EA)的温度预测方法，使其更具反应性，同时保持或降低均方根误差并减少大误差的数量。

Method: 使用睡眠专家框架(SEF)更高效地利用有偏专家，结合梯度提升回归树处理未知使用时机的问题，并在BOA自适应聚合中实现在线应用，最后通过元聚合策略选择是否使用SEF以减少噪声。

Result: 该方法在保持或降低均方根误差的同时，提高了预测的反应速度，并有效减少了大型误差的发生。

Conclusion: 通过SEF和梯度提升回归树的结合，以及BOA和元聚合策略的应用，显著提升了温度预测的性能和稳定性。

Abstract: In this paper we improve on the temperature predictions made with (online)
Expert Aggregation (EA) [Cesa-Bianchi and Lugosi, 2006] in Part I. In
particular, we make the aggregation more reactive, whilst maintaining at least
the same root mean squared error and reducing the number of large errors. We
have achieved this by using the Sleeping Expert Framework (SEF) [Freund et al.,
1997, Devaine et al., 2013], which allows the more efficient use of biased
experts (bad on average but which may be good at some point). To deal with the
fact that, unlike in Devaine et al. [2013], we do not know in advance when to
use these biased experts, we resorted to gradient boosted regression trees
[Chen and Guestrin, 2016] and provide regret bounds against sequences of
experts [Mourtada and Maillard, 2017] which take into account this uncertainty.
We applied this in a fully online way on BOA [Wintenberger, 2024], an adaptive
aggregation with second order regret bounds, which had the best results in Part
I. Finally, we made a meta-aggregation with the EA follow the leader. This
chooses whether or not to use the SEF in order to limit the possible noise
added by the SEF.

</details>


### [8] [On the Effectiveness of Classical Regression Methods for Optimal Switching Problems](https://arxiv.org/abs/2506.15436)
*Martin Andersson,Benny Avelin,Marcus Olofsson*

Main category: math.OC

TL;DR: 简单回归方法在1至50维的最优切换问题中表现稳健且接近最优，无需复杂调参即可超越神经网络。


<details>
  <summary>Details</summary>
Motivation: 研究旨在验证简单回归方法在高维最优切换问题中的有效性，尤其是在存在近似偏差和蒙特卡洛噪声的情况下。

Method: 采用Longstaff-Schwartz算法结合经典方法（如$k$-NN），测试了八种回归方法在四个基准问题上的表现，并分析了PCA对$k$-NN的扩展性。

Result: 简单回归方法在不同问题特性下保持稳定性能，$k$-NN在跳跃扩散动力学下具有集中界限，PCA使其适用于高维问题。

Conclusion: 对于计算密集型切换问题，简单且无需复杂调参的回归方法提供了可靠性能，优于复杂替代方案（如神经网络）。

Abstract: Simple regression methods provide robust, near-optimal solutions for optimal
switching problems in dimensions ranging from 1 to 50. While the theory
requires solving intractable PDE systems, the Longstaff-Schwartz algorithm with
classical approaches like $k$-NN achieves excellent switching decisions without
extensive hyperparameter tuning. Testing eight regression approaches on four
benchmark problems, we find that simple methods maintain stable performance
across diverse problem characteristics, even after extensive neural network
optimization. The contaminated training targets inherent to backward
induction-where each target contains both approximation bias and Monte Carlo
noise-actually favor these robust approaches over more complex alternatives
such as neural networks. Further, we establish concentration bounds for $k$-NN
regression under jump-diffusion dynamics and show that PCA enables $k$-NN to
scale to high dimensions. For practitioners: simple, minimally-tuned regression
methods offer reliable performance for computationally demanding switching
problems.

</details>


### [9] [Contribution of expert aggregation to temperature prediction part I](https://arxiv.org/abs/2506.15217)
*Léo Pfitzner,Olivier Wintenberger,Olivier Mestre,Marion Riverain*

Main category: math.OC

TL;DR: 本文提出使用专家聚合(EA)策略优化数值天气预报(NWP)和模型输出统计(MOS)的温度预测，展示了EA在提升预测精度方面的优势，并比较了不同EA策略的适用性。


<details>
  <summary>Details</summary>
Motivation: 现有多种数值天气预报模型及其统计输出方法，但如何最优整合这些预测结果仍具挑战性。专家聚合方法因其在线性、模型适应性及理论保障等优势成为解决方案。

Method: 采用专家聚合(EA)策略进行确定性温度预测，通过对比不同EA策略在不同场景下的表现，验证其对后处理NWP模型的改进效果。

Result: 研究表明EA策略能有效提升温度预测精度，包括对后处理NWP模型的改进，同时揭示了不同策略的适用条件与局限性。

Conclusion: 专家聚合方法为整合多源气象预测提供了有效框架，但其性能受策略选择和应用场景影响，未来需进一步优化策略适应性。

Abstract: Many Numerical Weather Prediction (NWP) models and their associated Model
Output Statistics (MOS) are available. Combining all of these predictions in an
optimal way is however not straightforward. This can be achieved thanks to
Expert Aggregation (EA) [Cesa-Bianchi and Lugosi, 2006, Gaillard et al., 2014,
Wintenberger, 2024] which has many advantages, such as being online, being
adaptive to model changes and having theoretical guarantees. Hence, in this
paper, we propose a method for making deterministic temperature predictions
with EA strategies and show how this can improve temperature predictions, even
those of post processed NWP models. We also compare different EA strategies in
various settings and discuss certain limitations.

</details>


### [10] [Polynomial Eigenfunctions and Matrix Lyapunov Equations from Energy Balance Integrals](https://arxiv.org/abs/2506.15288)
*Netzer Moriya*

Main category: math.OC

TL;DR: 该论文建立了一个统一的理论框架，将经典正交多项式系统与矩阵Lyapunov方程通过随机动力系统中的能量耗散物理原理联系起来。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于揭示经典正交多项式（如Zernike、Hermite、球谐函数）与矩阵Lyapunov方程之间的内在联系，并探讨它们在能量耗散结构中的共同基础。

Method: 方法是从无限维Hilbert空间中的能量平衡原理出发，推导出一个主积分表示，涵盖谱几何和协方差动力学，并通过有限维投影再现经典矩阵方程。

Result: 结果表明，经典正交多项式和矩阵Lyapunov方程是同一能量耗散结构的双重表现，且添加均匀耗散可以保持多项式本征函数结构并满足物理一致性条件。

Conclusion: 结论是该框架为理解经典正交多项式与矩阵Lyapunov方程的深层联系提供了严格的数学基础，并揭示了噪声过程对称性在确定结构中的关键作用。

Abstract: We establish a unified theoretical framework that connects classical
orthogonal polynomial systems to matrix Lyapunov equations through the
fundamental physics of energy dissipation in stochastic dynamical systems.
Starting from the energy balance principle in infinite-dimensional Hilbert
spaces, we derive a master integral representation that naturally encompasses
both spectral geometry and covariance dynamics. The theory reveals that
established orthogonal polynomials (Zernike, Hermite, spherical harmonics) and
matrix Lyapunov equations are dual manifestations of the same underlying energy
dissipation structure. We provide rigorous mathematical foundations showing how
finite-dimensional projections of infinite-dimensional energy integrals
reproduce classical matrix equations, with specific structure determined by the
symmetries of noise processes. The framework demonstrates that adding uniform
dissipation to classical differential operators preserves their polynomial
eigenfunction structure while ensuring the energy balance conditions required
for physical consistency.

</details>


### [11] [Proximal Operators of Sorted Nonconvex Penalties](https://arxiv.org/abs/2506.15315)
*Anne Gagneux,Mathurin Massias,Emmanuel Soubies*

Main category: math.OC

TL;DR: 本文研究了稀疏信号恢复中的变量自动分组问题，提出了一类排序非凸惩罚方法，用于广义线性模型的正则化。该方法通过排序特性促进变量聚类，同时利用非凸性减少系数收缩。


<details>
  <summary>Details</summary>
Motivation: 稀疏信号恢复中需要自动分组变量，现有方法如SLOPE虽能排序但存在系数收缩问题。本文旨在通过非凸排序惩罚改进这一局限，同时保持计算效率。

Method: 提出两类排序非凸惩罚：弱凸情形（如排序MCP/SCAD）使用PAV算法精确计算近端算子；非凸情形（如排序Lq，q∈(0,1)）通过改进PAV算法高效求解。

Result: 理论分析揭示了非凸近端问题极小值的新性质，实验验证了排序非凸惩罚在变量聚类和减少系数收缩方面的优越性能。

Conclusion: 排序非凸惩罚结合PAV算法改进，为稀疏恢复提供高效解决方案，其理论框架和计算工具可推广至更广泛的正则化问题。

Abstract: This work studies the problem of sparse signal recovery with automatic
grouping of variables. To this end, we investigate sorted nonsmooth penalties
as a regularization approach for generalized linear models. We focus on a
family of sorted nonconvex penalties which generalizes the Sorted L1 Norm
(SLOPE). These penalties are designed to promote clustering of variables due to
their sorted nature, while the nonconvexity reduces the shrinkage of
coefficients. Our goal is to provide efficient ways to compute their proximal
operator, enabling the use of popular proximal algorithms to solve composite
optimization problems with this choice of sorted penalties. We distinguish
between two classes of problems: the weakly convex case where computing the
proximal operator remains a convex problem, and the nonconvex case where
computing the proximal operator becomes a challenging nonconvex combinatorial
problem. For the weakly convex case (e.g. sorted MCP and SCAD), we explain how
the Pool Adjacent Violators (PAV) algorithm can exactly compute the proximal
operator. For the nonconvex case (e.g. sorted Lq with q in ]0,1[), we show that
a slight modification of this algorithm turns out to be remarkably efficient to
tackle the computation of the proximal operator. We also present new
theoretical insights on the minimizers of the nonconvex proximal problem. We
demonstrate the practical interest of using such penalties on several
experiments.

</details>


### [12] [Optimal Control of Thin-Film Flow on a Flexible Topography](https://arxiv.org/abs/2506.15340)
*S. Alrashidy,A. Kalogirou,D. Kalise,K. G. van der Zee*

Main category: math.OC

TL;DR: 本文提出了一种用于优化控制柔性基底上受外力影响的薄膜流动的数学模型，旨在通过分布式力最小化实际与理想薄膜轮廓的差异，并展示了该系统的全局能量耗散定律及数值求解方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于开发一种能够精确控制薄膜流动（包括薄膜破裂和气泡合并）的数学模型，以实现对薄膜轮廓的优化调控，满足特定应用需求。

Method: 方法包括建立非线性润滑方程描述流体动力学，推导最优控制条件为耦合的前向-后向偏微分方程系统，并采用一阶隐式-显式（IMEX）时间步进方案及降维梯度下降算法进行数值求解。

Result: 数值结果表明，该控制策略能在薄膜破裂期间实现精确轮廓控制，加速稳态收敛，减少不稳定性，稳定去湿过程，并满足目标轮廓要求。

Conclusion: 结论表明，所提出的最优控制模型能有效调控薄膜流动，即使在复杂动态（如破裂）下也能实现高精度控制，为相关工程应用提供了理论支持。

Abstract: This work presents a mathematical model for the optimal control of thin-film
flows over a flexible topography influenced by an external force. Our thin-film
model allows for the rupture of films as well as the coalescence of bubbles.
The objective is to find the optimal distributed force acting on the topography
that minimises the differences between actual and desired thin-film profiles. A
nonlinear lubrication equation governing the fluid dynamics and appropriate
functional settings for this model are presented. It is also shown that this
system satisfies a global energy-dissipation law for a suitable energy
functional. Optimality conditions are derived for the solution of the
minimisation problem of a specified cost function across a time horizon. These
conditions are formulated at a continuous level as a system of coupled,
forward-backward PDEs, which are subsequently discretised for numerical
investigation. To ensure computational efficiency and stability, first-order
Implicit-Explicit (IMEX) time-stepping schemes are employed to handle the
nonlinearities in the model, and a reduced gradient descent algorithm is
applied to obtain a numerical approximation of the optimal control signal.
Numerical results illustrate that controlling the thin film, even during
rupture, achieves a precise film profile. This control strategy accelerates
convergence towards a steady state, reduces instabilities, stabilises dewetting
processes, and meets the desired profile specifications.

</details>


### [13] [Multi-Timescale Gradient Sliding for Distributed Optimization](https://arxiv.org/abs/2506.15387)
*Junhui Zhang,Patrick Jaillet*

Main category: math.OC

TL;DR: 本文提出了两种针对非光滑分布式凸优化问题的一阶方法：多时间尺度梯度滑动（MT-GS）及其加速版本（AMT-GS），通过多时间尺度策略和块分解对偶方法，实现了通信轮次减少、灵活通信速率和确定性算法三大优势。


<details>
  <summary>Details</summary>
Motivation: 现有分布式优化方法在非光滑目标下难以同时实现通信效率与计算效率的最优平衡，且缺乏对局部目标相似性的有效利用。本文旨在解决这一开放性问题，提出能自适应不同通信速率且具有最优$\epsilon$依赖性的算法。

Method: 基于块可分解的原始-对偶形式化和多时间尺度滑动技术，MT-GS和AMT-GS允许不同代理子集以用户自定义的速率更新对偶块。其中MT-GS适用于Lipschitz目标，AMT-GS进一步利用$\mu$-强凸性实现加速收敛。

Result: 理论证明：MT-GS达到$O(\overline{r}A/\epsilon)$通信轮次和$O(\overline{r}/\epsilon^2)$次梯度步数；AMT-GS在强凸条件下仅需$O(\overline{r}A/\sqrt{\epsilon\mu})$通信轮次和$O(\overline{r}/(\epsilon\mu))$次梯度步数。其中$\overline{r}$为对偶块平均更新率，$A$量化局部函数相似性，且通信轮次对$A$的线性依赖是最优的。

Conclusion: 该工作首次在非光滑目标下实现了通信轮次对相似性度量$A$的最优线性依赖，回答了Arjevani和Shamir（2015）的开放性问题，为分布式优化提供了兼具理论保证和实用灵活性的新方法。

Abstract: We propose two first-order methods for convex, non-smooth, distributed
optimization problems, hereafter called Multi-Timescale Gradient Sliding
(MT-GS) and its accelerated variant (AMT-GS). Our MT-GS and AMT-GS can take
advantage of similarities between (local) objectives to reduce the
communication rounds, are flexible so that different subsets (of agents) can
communicate at different, user-picked rates, and are fully deterministic. These
three desirable features are achieved through a block-decomposable primal-dual
formulation, and a multi-timescale variant of the sliding method introduced in
Lan et al. (2020), Lan (2016), where different dual blocks are updated at
potentially different rates.
  To find an $\epsilon$-suboptimal solution, the complexities of our algorithms
achieve optimal dependency on $\epsilon$: MT-GS needs
$O(\overline{r}A/\epsilon)$ communication rounds and
$O(\overline{r}/\epsilon^2)$ subgradient steps for Lipchitz objectives, and
AMT-GS needs $O(\overline{r}A/\sqrt{\epsilon\mu})$ communication rounds and
$O(\overline{r}/(\epsilon\mu))$ subgradient steps if the objectives are also
$\mu$-strongly convex. Here, $\overline{r}$ measures the ``average rate of
updates'' for dual blocks, and $A$ measures similarities between (subgradients
of) local functions. In addition, the linear dependency of communication rounds
on $A$ is optimal (Arjevani and Shamir 2015), thereby providing a positive
answer to the open question whether such dependency is achievable for
non-smooth objectives (Arjevani and Shamir 2015).

</details>


### [14] [Efficient Online Mirror Descent Stochastic Approximation for Multi-Stage Stochastic Programming](https://arxiv.org/abs/2506.15392)
*Junhui Zhang,Patrick Jaillet*

Main category: math.OC

TL;DR: 本文研究了多阶段随机规划问题的无约束和极小极大鞍点变体，提出了随机条件梯度预言机概念，并证明了镜像下降随机逼近算法的收敛性。通过半在线视角和异步实现，显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究多阶段随机规划问题中决策通过目标函数耦合的情况，旨在解决传统方法在约束耦合下的局限性，提出更高效的求解方法。

Method: 基于确定性镜像下降算法与不精确梯度分析，引入随机条件梯度预言机概念；采用半在线视角，通过延迟决策实现异步镜像下降算法。

Result: 证明了（加速）镜像下降随机逼近算法在期望和高概率下的收敛性；通过半在线方法将复杂度从阶段数的指数级降至线性级。

Conclusion: 随机条件梯度预言机和半在线视角为多阶段随机规划提供了高效求解框架，显著降低了计算复杂度，具有理论和实用价值。

Abstract: We study the unconstrained and the minimax saddle point variants of the
convex multi-stage stochastic programming problem, where consecutive decisions
are coupled through the objective functions, rather than through the
constraints. Based on the analysis of deterministic mirror descent algorithms
with inexact gradients, we introduce the idea of \textit{stochastic conditional
gradient oracles}, a multi-stage analog of the stochastic gradient oracles used
in (classical) stochastic programming. We show one approach to construct such
oracles and prove the convergence of the (accelerated) mirror descent
stochastic approximation, both in expectation and with high probability. To
further reduce the oracle complexity, we view the problem from a
\textit{semi-online} perspective, where the stage $t$ decision variables are
constructed $s$ stages in advance, instead of before stage $1$. We show that
the delay in decision making allows an asynchronous implementation of the
mirror descent stochastic approximation algorithms. By avoiding computing
solutions for scenarios that are inconsistent with information available during
stage $t$, the complexity is reduced from exponential to linear in the number
of stages.

</details>


### [15] [A polynomial projective algorithm for convex feasibility problems with positive-definite constraints](https://arxiv.org/abs/2506.15484)
*Sergei Chubanov*

Main category: math.OC

TL;DR: 本文研究了一类与自对偶锥相关的谱面投影变换，并提出了一种多项式时间算法来解决具有正定约束的凸可行性问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于改进现有凸可行性问题的求解效率，特别是在正定约束条件下，通过投影变换和势函数测量来优化算法性能。

Method: 方法包括在每次迭代中寻找可行解或生成有效不等式，通过投影变换将解集拉近关联谱面的中心，并使用势函数测量接近程度。

Result: 结果表明，该算法在方程数量不小于正半定锥秩和的情况下，能够更精确地改进现有的复杂度界限。

Conclusion: 结论指出，所提出的算法在处理正定约束的凸可行性问题时具有更高的效率和更精确的复杂度界限。

Abstract: We study a class of projective transformations of spectraplexes associated
with self-dual cones and, on this basis, propose a polynomial-time algorithm
for convex feasibility problems with positive definite constraints. At each
iteration of the algorithm, either a feasible solution is found or a suitable
valid inequality inducing a projective transformation allowing to bring the
solution set closer to the center of an associated spectraplex. The closeness
to the center is measured in terms of a potential function. The running time of
our algorithm makes the existing complexity bounds more precise for the case
when the number of equations linking the positive definite variable matrices is
not less than the sum of the ranks of the respective positive-semidefinite
cones.

</details>


### [16] [On Exact Solutions to the Linear Bellman Equation](https://arxiv.org/abs/2506.15527)
*David Ohlin,Richard Pates,Murat Arcak*

Main category: math.OC

TL;DR: 本文提出了线性算子动态系统最优控制的充分条件，推导出可分布式计算的贝尔曼方程显式解，并将线性可解MDP类重构为连续状态最优控制问题。


<details>
  <summary>Details</summary>
Motivation: 研究旨在扩展线性可解MDP框架至半线性动态系统，以处理输入非线性问题，并为随机最短路径和线性二次调节器问题提供适用条件。

Method: 通过建立线性算子动态系统的充分条件，将线性可解MDP类重新表述为连续状态最优控制问题，并验证其对贝尔曼方程显式解的自然满足性。

Result: 证明了该类问题天然满足贝尔曼方程显式解条件，成功将现有成果扩展至半线性动态系统，并在线性/二次成本场景中验证了适用性。

Conclusion: 所提条件适用于处理输入非线性的扩展场景，为随机最短路径和LQR问题提供了新的分布式求解框架。

Abstract: This paper presents sufficient conditions for optimal control of systems with
dynamics given by a linear operator, in order to obtain an explicit solution to
the Bellman equation that can be calculated in a distributed fashion. Further,
the class of Linearly Solvable MDP is reformulated as a continuous-state
optimal control problem. It is shown that this class naturally satisfies the
conditions for explicit solution of the Bellman equation, motivating the
extension of previous results to semilinear dynamics to account for input
nonlinearities. The applicability of the given conditions is illustrated in
scenarios with linear and quadratic cost, corresponding to the Stochastic
Shortest Path and Linear-Quadratic Regulator problems.

</details>


### [17] [Long run control of nonhomogeneous Markov processes](https://arxiv.org/abs/2506.15542)
*Łukasz Stettner*

Main category: math.OC

TL;DR: 研究了非齐次马尔可夫过程的平均奖励与风险敏感奖励泛函，证明了贝尔曼方程解的存在性、值函数对风险参数的连续性，以及控制收敛下的泛函稳定性。


<details>
  <summary>Details</summary>
Motivation: 探索非齐次马尔可夫控制过程中平均单位时间奖励和风险敏感奖励泛函的理论性质，为动态决策提供数学基础。

Method: 通过构建合适的贝尔曼方程，分析其解的存在性，并研究值函数对风险参数的连续性及控制收敛的稳定性。

Result: 证明了贝尔曼方程解的存在性，展示了值函数关于风险参数的连续性，并建立了控制点态收敛下泛函的稳定性。

Conclusion: 该研究为非齐次马尔可夫控制过程的风险敏感优化问题提供了理论支持，扩展了动态规划方法的应用范围。

Abstract: In the paper average reward per unit time and average risk sensitive reward
functionals are considered for controlled nonhomogeneous Markov processes.
Existence of solutions to suitable Bellman equations is shown. Continuity of
the value functions with respect to risk parameter is also proved. Finally
stability of functionals with respect to pointwise convergence of Markov
controls is studied.

</details>


### [18] [Primal-Dual Coordinate Descent for Nonconvex-Nonconcave Saddle Point Problems Under the Weak MVI Assumption](https://arxiv.org/abs/2506.15597)
*Iyad Walwil,Olivier Fercoq*

Main category: math.OC

TL;DR: 本文提出了两种新的原始-对偶算法（NC-PDHG和NC-SPDHG），用于解决具有弱Minty变分不等式特性的非凸、非凹、非光滑鞍点问题。通过结合PEPit工具和自动Lyapunov函数技术，成功设计了首个基于坐标的随机算法NC-SPDHG。实验验证了算法在弱MVI条件下的有效性及优于现有算法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理非凸非凹非光滑鞍点问题，特别是缺乏基于坐标的随机算法。这促使研究者利用PEPit工具进行计算机辅助分析，并开发新型算法以填补这一空白。

Method: 提出NC-PDHG（扩展经典PDHG）和NC-SPDHG（引入随机坐标下降）。后者通过PEPit工具与自动Lyapunov函数技术相结合，首次实现坐标级随机优化。两种算法在弱MVI条件下采用自适应恒定步长。

Result: 在逻辑回归平方损失和感知机回归问题上验证了理论，显示线性收敛性。NC-SPDHG在凸凹最小二乘实验中与SAGA性能相当，优于现有算法。

Conclusion: 所提算法突破了非凸非凹鞍点问题的求解限制，NC-SPDHG作为首个坐标随机方法具有里程碑意义。弱MVI条件下的理论分析和实验表现为相关领域提供了新工具和基准。

Abstract: We introduce two novel primal-dual algorithms for addressing nonconvex,
nonconcave, and nonsmooth saddle point problems characterized by the weak Minty
Variational Inequality (MVI). The first algorithm, Nonconvex-Nonconcave
Primal-Dual Hybrid Gradient (NC-PDHG), extends the well-known Primal-Dual
Hybrid Gradient (PDHG) method to this challenging problem class. The second
algorithm, Nonconvex-Nonconcave Stochastic Primal-Dual Hybrid Gradient
(NC-SPDHG), incorporates a randomly extrapolated primal-dual coordinate descent
approach, extending the Stochastic Primal-Dual Hybrid Gradient (SPDHG)
algorithm.
  To our knowledge, designing a coordinate-based algorithm to solve
nonconvex-nonconcave saddle point problems is unprecedented, and proving its
convergence posed significant difficulties. This challenge motivated us to
utilize PEPit, a Python-based tool for computer-assisted worst-case analysis of
first-order optimization methods. By integrating PEPit with automated Lyapunov
function techniques, we successfully derived the NC-SPDHG algorithm.
  Both methods are effective under a mild condition on the weak MVI parameter,
achieving convergence with constant step sizes that adapt to the structure of
the problem. Numerical experiments on logistic regression with squared loss and
perceptron-regression problems validate our theoretical findings and show their
efficiency compared to existing state-of-the-art algorithms, where linear
convergence is observed. Additionally, we conduct a convex-concave
least-squares experiment to show that NC-SPDHG performs competitively with
SAGA, a leading algorithm in the smooth convex setting.

</details>


### [19] [Heavy Ball and Nesterov Accelerations with Hessian-driven Damping for Nonconvex Optimization](https://arxiv.org/abs/2506.15632)
*N. Hadjisavvas,F. Lara,R. T. Marcavillaca,P. T. Vuong*

Main category: math.OC

TL;DR: 本文研究了一种针对强拟凸函数的二阶动态系统，并基于此提出了两种离散时间梯度算法，均实现了线性收敛。


<details>
  <summary>Details</summary>
Motivation: 旨在通过Hessian驱动阻尼增强经典动量方法的稳定性，减少振荡现象，提升强拟凸目标函数的收敛性能。

Method: 1. 提出带Hessian修正的重球法；2. 设计具有自适应动量的Nesterov型加速法，两者均通过离散化连续时间模型引入曲率相关项。

Result: 理论证明两种算法在迭代值和函数值上均能线性收敛至最优解，数值实验验证了理论结果。

Conclusion: 研究揭示了连续时间动力学与离散优化算法在强拟凸优化中的深刻联系，所提方法显著提升了收敛稳定性。

Abstract: In this work, we investigate a second-order dynamical system with
Hessian-driven damping tailored for a class of nonconvex functions called
strongly quasiconvex. Buil\-ding upon this continuous-time model, we derive two
discrete-time gra\-dient-based algorithms through time discretizations. The
first is a Heavy Ball method with Hessian correction, incorporating
cur\-va\-tu\-re-dependent terms that arise from discretizing the Hessian
damping component. The second is a Nesterov-type accelerated method with
adaptive momentum, fea\-tu\-ring correction terms that account for local
curvature. Both algorithms aim to enhance stability and convergence
performance, particularly by mi\-ti\-ga\-ting oscillations commonly observed in
cla\-ssi\-cal momentum me\-thods. Furthermore, in both cases we establish
li\-near convergence to the optimal solution for the iterates and functions
values. Our approach highlights the rich interplay between continuous-time
dynamics and discrete optimization algorithms in the se\-tting of strongly
quasiconvex objectives. Numerical experiments are presented to support obtained
results.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [20] [Special Cases of the Shafarevich Conjecture for Complete Intersections in Abelian Varieties](https://arxiv.org/abs/2506.14935)
*Frank Lu*

Main category: math.NT

TL;DR: 本文利用Lawrence-Venkatesh方法，证明了数域$K$上某些阿贝尔簇中超曲面完全交的Shafarevich猜想。


<details>
  <summary>Details</summary>
Motivation: 研究数域上阿贝尔簇中完全交的Shafarevich猜想，扩展了相关理论的应用范围。

Method: 通过计算这些完全交的欧拉示性数，以及证明由这类完全交族的中部上同调产生的Hodge结构变异的单值群大定理，结合Tannaka群和组合陈述进行论证。

Result: 成功证明了特定条件下完全交的Shafarevich猜想，为相关领域提供了新的理论支持。

Conclusion: 本研究不仅验证了Shafarevich猜想在特定情形下的成立，还展示了Lawrence-Venkatesh方法在解决类似问题中的潜力。

Abstract: In this paper, we prove the Shafarevich conjecture for certain complete
intersections of hypersurfaces in abelian varieties defined over a number field
$K$ using the Lawrence-Venkatesh method. The main new inputs we need are
computation of certain Euler characteristics of these complete intersections
and a big monodromy statement for the variation of Hodge structure arising from
the middle cohomology of a family of such complete intersections. Following
\cite{ls25}, we prove the latter by relating this monodromy statement to a
statement about Tannaka groups, which we then convert into a combinatorial
statement.

</details>


### [21] [Triangular and tetrahedral number differences of sumset sizes in additive number theory](https://arxiv.org/abs/2506.15015)
*Melvyn B. Nathanson*

Main category: math.NT

TL;DR: 本文研究了整数有限集的和集大小分布，发现四元素集的和集大小呈现出与三角数和四面体数相关的意外模式。


<details>
  <summary>Details</summary>
Motivation: 以往研究主要关注极小和集（Freiman定理）或极大和集（Sidon集与$B_h$-集），本文旨在探索整数有限集和集大小的完整分布范围。

Method: 通过分析不同大小的整数有限集的和集分布，特别聚焦于四元素集的和集规模统计规律。

Result: 研究发现四元素集的和集大小分布存在特殊模式，该模式与三角数及四面体数存在数学关联。

Conclusion: 整数有限集的和集大小分布中潜藏着未被发现的数论规律，四元素集的特殊模式为未来研究提供了新方向。

Abstract: The study of sums of finite sets of integers has mostly concentrated on sets
with very small sumsets (Freiman's theorem and related work) and on sets with
very large sumsets (Sidon sets and $B_h$-sets). This paper considers the full
range of sumset sizes of finite sets of integers and an unexpected pattern
(related to the triangular and tetrahedral numbers) that appears in the
distribution of popular sumset sizes of sets of size 4.

</details>


### [22] [On the Modern Structure of the Gauss-Landau Theorem](https://arxiv.org/abs/2506.15101)
*Manuel M. Aguilera*

Main category: math.NT

TL;DR: 本文正式提出了高斯-兰道定理，为有限非零整数集的GCD和LCM计算提供了统一的素数分解方法。


<details>
  <summary>Details</summary>
Motivation: 尽管这些定理在初等数论教学中常被用作启发式方法或技巧，但文献中尚未对其进行明确的形式化或命名。此形式化旨在加深理解并促进其在数学教学和研究中的应用。

Method: 通过统一的素数分解方法，对有限非零整数集的最大公约数（GCD）和最小公倍数（LCM）进行计算。

Result: 成功形式化了高斯-兰道定理，为GCD和LCM的计算提供了理论支持。

Conclusion: 该形式化不仅填补了文献中的空白，还为数学教学和研究提供了实用的工具和方法。

Abstract: We formalize the Gauss-Landau theorem, providing a unified prime
factorization approach to computing the GCD and LCM of finite nonzero integer
sets. Although commonly used as a heuristic or technique in elementary number
theory education, these theorems have not been explicitly formalized or named
in the literature. This formalization aims to enhance understanding and
facilitate adoption in mathematical instruction and research.

</details>


### [23] [Characterizing infinite torsion subgroups of the circle through arithmetic-type sequences](https://arxiv.org/abs/2506.15257)
*Ayan Ghosh,Pratulananda Das*

Main category: math.NT

TL;DR: 本文扩展了Das等人的工作，证明了算术型序列对应的特征子群可数当且仅当它是挠群，并证明了圆群的无限挠子群可由有界比的算术型序列表征，同时指出Eggleston定理的二象性不适用于一般算术型序列。


<details>
  <summary>Details</summary>
Motivation: 基于Das等人对算术型序列特征子群结构的研究，进一步探索这类子群的可数性与挠性关系，以及圆群挠子群的表征问题。

Method: 通过分析算术型序列的性质，结合群论与拓扑学方法，研究特征子群的结构及其与序列参数的关系。

Result: 发现算术型序列对应的特征子群可数等价于其为挠群；证明圆群的无限挠子群可由有界比算术型序列表征；指出Eggleston定理的二象性在广义算术型序列中不成立。

Conclusion: 算术型序列特征子群的可数性完全由其挠性决定，且圆群挠子群具有特定表征方式，但经典二象性结论在广义序列中失效。

Abstract: In a recent work [Das et al., Bull. Sci. Math. 199 (2025), 103580], the
structure of characterized subgroups corresponding to arithmetic-type sequences
was investigated. Building upon this work, we further show that a characterized
subgroup associated with an arithmetic-type sequence is countable if and only
if it is torsion. Further we prove that any infinite torsion subgroup of the
circle can be characterized by an arithmetic-type sequence with bounded ratio.
Moreover, our findings demonstrate that the dichotomy observed in Eggleston's
theorem [Theorem 16, Eggleston, Proc. Lond. Math. Soc. 54(2) (1952), 42--93]
for arithmetic sequences does not extend, in general, to the broader class of
arithmetic-type sequences.

</details>


### [24] [Metric Poissonian pair correlationa and additive energy](https://arxiv.org/abs/2506.15274)
*Tanmoy Bera,E. Malavika*

Main category: math.NT

TL;DR: 本文证明了当自然数严格递增序列$(a_n)$的加性能量小于$N^3/(\log N)^C$（其中$C\geq13.155$）时，对于几乎所有实数$\alpha$，序列$(\{a_n\alpha\})$具有泊松对相关性。


<details>
  <summary>Details</summary>
Motivation: 研究严格递增自然数序列的加性能量与其对相关性的关系，为Bloom和Walker[3]建立的加性能量界限中的指数$C$提供下界。

Method: 通过分析序列$(a_n)$的加性能量，并利用泊松对相关性的定义，证明了在给定条件下序列$(\{a_n\alpha\})$的性质。

Result: 当加性能量小于$N^3/(\log N)^C$且$C\geq13.155$时，序列$(\{a_n\alpha\})$对几乎所有实数$\alpha$具有泊松对相关性。

Conclusion: 该结果为加性能量界限中的指数$C$提供了明确的下界，进一步揭示了序列加性能量与对相关性之间的深刻联系。

Abstract: In this article we prove that if the additive energy of a strictly increasing
sequence $(a_n)$ of natural numbers is less than $N^3/(\log N)^C$ for some
$C\geq13.155$, then $(\{a_n\alpha\})$ has Poissonian pair correlation for
almost all $\alpha\in\mathbb{R}.$ This provides a lower bound for the exponent
$C$ in the additive energy bound established by Bloom and Walker[3].

</details>


### [25] [Singular intersections on families of abelian varieties](https://arxiv.org/abs/2506.15344)
*Nicola Ottolini*

Main category: math.NT

TL;DR: 本文证明了在代数闭域上定义的阿贝尔概形中，曲线与真平坦子群概形相切的点集是有限的。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于所谓的'不可能交'问题，旨在探索阿贝尔簇中曲线与子群结构的特殊交点性质。

Method: 通过相对Pink猜想的变体方法，分析曲线与阿贝尔概形中子群概形的切点行为。

Result: 主要结果表明，在$\overline{\mathbb{Q}}$上定义的曲线与真平坦子群概形相切的点集是有限的。

Conclusion: 该结论为阿贝尔簇的相对Pink猜想提供了新的支持，深化了对不可能交问题的理解。

Abstract: Let $S$ be a smooth irreducible curve defined over $\overline{\mathbb{Q}}$,
let $\mathcal{A}$ be an abelian scheme over $S$ and $\mathcal{C}$ a curve
inside $\mathcal{A}$, both defined over $\overline{\mathbb{Q}}$. In this paper
we prove that the set of points in which $\mathcal{C}$ intersects proper flat
subgroup schemes of $\mathcal{A}$ tangentially is finite. This fits in the
framework of the so-called problems of unlikely intersections, and can be seen
as a variation of the relative Pink conjecture for abelian varieties.

</details>


### [26] [A categorical formulation of the Deligne-Terasoma approach to double shuffle theory](https://arxiv.org/abs/2506.15348)
*Benjamin Enriquez,Khalef Yaddaden*

Main category: math.NT

TL;DR: 本文引入了具有分解结构的双模(BFS)概念，并证明该结构能产生代数态射，为双洗牌理论中的几何构造提供了解释框架。


<details>
  <summary>Details</summary>
Motivation: 研究双模分解结构的动机在于为双洗牌理论中Betti与de Rham谐波余积的几何构造建立统一解释框架。

Method: 通过定义具有分解结构的双模(BFS)，并证明其诱导的代数态射性质，关联到$\\cite{DeT, EF1, EF2, EF3}$中的理论体系。

Result: 结果表明BFS结构能自然导出代数态射，且该框架成功解释了双洗牌理论中谐波余积的几何构造机制。

Conclusion: BFS概念的提出为理解双洗牌理论的深层几何结构提供了新工具，未来可拓展至更广泛的数学物理领域。

Abstract: In this paper, we introduce the notion of a bimodule with a factorization
structure (BFS) and show that such a structure gives rise to an algebra
morphism. We then prove that this framework offers an interpretation of the
geometric construction underlying both the Betti and de Rham harmonic
coproducts of the double shuffle theory developed in \cite{DeT, EF1, EF2, EF3}.

</details>


### [27] [Patterns in Growth and Distribution of Unbounded Prime Number Walks](https://arxiv.org/abs/2506.15357)
*Alberto Fraile,Daniel Fernández,Roberto Martínez,Theophanes E. Raptis*

Main category: math.NT

TL;DR: 本文证明了素数行走（PW）覆盖的区域是无界的，并进一步探讨了其性质及由此衍生的新问题。


<details>
  <summary>Details</summary>
Motivation: 基于前期工作中定义的素数行走及其有趣的数值结果，本研究旨在验证并深化对PW特性的理解。

Method: 通过数学证明确认了PW覆盖区域的无界性，并对其性质进行了详细分析。

Result: 成功证明了PW覆盖的区域无界，并发现了新的研究问题。

Conclusion: 素数行走的无界性为后续研究开辟了新方向，值得进一步探索其数学特性。

Abstract: In our previous work, we defined a prime walk (PW) on a square grid and
presented several intriguing numerical results. Here, we demonstrate the main
conjecture presented there, namely, that the area covered by the prime walk is
unbounded. Taking this fact into account, we examine in further detail the
properties of the PW and explore new questions that arise naturally in this
analysis.

</details>


### [28] [No Nowhere Continuous Function Maps all Non-Normal Numbers to Normal Numbers](https://arxiv.org/abs/2506.15422)
*Chokri Manai*

Main category: math.NT

TL;DR: 本文研究了非正规数集合$\mathcal{N}^c$的性质，证明了不存在非空开区间$I$和非常数连续函数$\phi$将$I$内的非正规数映射为正规数。相反，正规数集合$\mathcal{N}$不具备此性质，并构造了一个将正规数映射为非正规数的康托型连续函数。


<details>
  <summary>Details</summary>
Motivation: 探讨非正规数集合$\mathcal{N}^c$的拓扑性质，验证是否存在连续函数能将局部非正规数转换为正规数，从而揭示两类数集的深层差异。

Method: 采用反证法否定第一个命题，并通过显式构造康托型连续函数$\hat{C}$证明第二个命题，结合测度论与实分析技术。

Result: 1) 不存在满足条件的$\phi$函数；2) 构造出将$\mathcal{N}$映射到$\mathcal{N}^c$的非常数连续函数$\hat{C}$，表明正规数集在该性质上与非正规数集不对称。

Conclusion: 非正规数集合$\mathcal{N}^c$的拓扑复杂性使其抵抗连续函数下的正规化映射，而正规数集$\mathcal{N}$具有可被连续函数'非正规化'的脆弱性，这凸显了$\mathcal{N}^c$作为零测集的特殊丰富性。

Abstract: In this work, we consider the set of non-normal numbers $\mathcal{N}^c$ and
ask if there is a non-empty open interval $I$ and a nowhere constant continuous
function $\phi: I \to \rr$ which maps all non-normal numbers to normal numbers,
i.e., $\varphi(I \cap \mathcal{N}^c) \subset \mathcal{N}.$ We answer this
question negatively. This result can be seen as a further manifestation of the
richness of the null set $\mathcal{N}^c$. Surprisingly, the "bigger" set of
normal numbers $\mathcal{N}$ does not share this property and we will give an
explicit Cantor-type construction of a nowhere constant continuous function
$\hat{C}$, which maps all normal numbers to non-normal numbers.

</details>


### [29] [Evaluation of Modular Polynomials from Supersingular Elliptic Curves](https://arxiv.org/abs/2506.15429)
*Maria Corte-Real Santos,Jonathan Komada Eriksen,Antonin Leroux,Michael Meyer,Lorenz Panny*

Main category: math.NT

TL;DR: 本文提出了两种新的通用算法，用于在素数$p$下评估级别$\ell$的模多项式。这些算法基于CRT方法，利用超奇异曲线和Deuring对应，且内存需求最优。第一种算法结合了Sutherland的混合算法和Leroux的超奇异曲线方法，时间复杂度与现有最优算法相当，但内存需求更优。第二种算法在超奇异$j$-不变量上高效评估模多项式，首次实现了在$\ell$上的二次复杂度且内存最优。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于改进现有模多项式评估算法的效率和内存使用，特别是在处理大参数时。通过结合CRT方法和超奇异曲线的特性，旨在开发出时间复杂度低且内存需求最优的新算法。

Method: 方法包括两种新算法：第一种结合了Sutherland的混合算法和Leroux的超奇异曲线方法；第二种基于子算法，在超奇异$j$-不变量上高效评估模多项式。两种算法均基于CRT方法，利用超奇异曲线和Deuring对应，且内存需求最优。

Result: 第一种算法的时间复杂度为$\Tilde{O}(\ell^3 \log^{3} \ell + \ell \log p)$，与现有最优算法相当，但内存需求更优。第二种算法在$\ell$和$\log j$上达到二次复杂度，在$\log p$上为线性复杂度，且内存需求最优。此外，方法还可适配其他类型的模多项式计算。

Conclusion: 本文提出的两种新算法在模多项式评估中实现了显著的时间和内存优化。第一种算法在保持时间复杂度的同时优化了内存使用，第二种算法首次实现了在$\ell$上的二次复杂度且内存最优。这些算法不仅适用于模多项式，还可扩展至其他类型。

Abstract: We present several new algorithms to evaluate modular polynomials of level
$\ell$ modulo a prime $p$ on an input $j$.
  More precisely, we introduce two new generic algorithms, sharing the
following similarities: they are based on a CRT approach; they make use of
supersingular curves and the Deuring correspondence; and, their memory
requirements are optimal.
  The first algorithm combines the ideas behind a hybrid algorithm of
Sutherland in 2013 with a recent algorithm to compute modular polynomials using
supersingular curves introduced in 2023 by Leroux. The complexity (holding
around several plausible heuristic assumptions) of the resulting algorithm
matches the $\Tilde{O}(\ell^3 \log^{3} \ell + \ell \log p)$ time complexity of
the best known algorithm by Sutherland, but has an optimal memory requirement.
  Our second algorithm is based on a sub-algorithm that can evaluate modular
polynomials efficiently on supersingular $j$-invariants defined over $\Fp$, and
achieves heuristic complexity quadratic in both $\ell$ and $\log j$, and linear
in $\log p$. In particular, it is the first generic algorithm with optimal
memory requirement to obtain a quadratic complexity in~$\ell$.
  Additionally, we show how to adapt our method to the computation of other
types of modular polynomials such as the one stemming from Weber's function.
  Finally, we provide an optimised implementation of the two algorithms
detailed in this paper, though we emphasise that various modules in our
codebase
  may find applications outside their use in this paper.

</details>


### [30] [Long strings of composite values of polynomials and a basis of order 2](https://arxiv.org/abs/2506.15641)
*Artyom Radomskii*

Main category: math.NT

TL;DR: 论文证明了对于任意在$\mathbb{Q}$上不可约且首项系数为正的多项式$f: \mathbb{Z}\to \mathbb{Z}$，当$N$足够大时，存在两个连续正整数区间$I_{1}$和$I_{2}$，使得$f(n)$在$I_{1}\cup I_{2}$上均为合数。


<details>
  <summary>Details</summary>
Motivation: 扩展了文献[5]中关于$f(n)=n$的结果，研究更一般多项式$f$在连续整数区间上的合数分布问题。

Method: 通过构造两个长度为$m = [(\log N) (\log \log N)^{1/325525}]$的连续整数区间$I_{1}$和$I_{2}$，并证明$f(n)$在这些区间内均为合数。

Result: 对于足够大的$N$，存在满足条件的区间$I_{1}$和$I_{2}$，且$I_{1}\cup I_{2} \subset [1, N]$，$N = n_1 + n_2$。

Conclusion: 该结果将多项式$f(n)=n$的合数分布结论推广到了更一般的不可约多项式，为数论中多项式值的合数分布问题提供了新的见解。

Abstract: We show that for any polynomial $f: \mathbb{Z}\to \mathbb{Z}$ with positive
leading coefficient and irreducible over $\mathbb{Q}$, if $N$ is large enough
then there are two strings of consecutive positive integers
$I_{1}=\{n_1-m,\ldots, n_1+m\}$ and $I_{2}=\{n_2-m, \ldots, n_2+m\}$, where $m
= [(\log N) (\log \log N)^{1/325525}]$, such that $I_{1}\cup I_{2} \subset [1,
N]$, $N = n_1 + n_2$, and $f(n)$ is composite for any $n\in I_{1}\cup I_{2}$.
This extends the result in [5] which showed the same result but with $f(n)=n$.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [31] [Class of extensions of real field and their topological properties](https://arxiv.org/abs/2506.14838)
*E. V. Alexandrov*

Main category: math.LO

TL;DR: 本文定义了实数域的适当扩展类，并研究了这些扩展的拓扑性质。这些扩展可以是连通的（此时集合对二元运算不封闭）或不连通的（此时构成线性有序域），未来可应用于构建能感知零测集的测度。


<details>
  <summary>Details</summary>
Motivation: 研究实数域扩展的拓扑性质，为构建能识别零勒贝格测度集的新型测度提供理论基础。

Method: 通过定义实数域的适当扩展类，分析其连通性与代数封闭性，区分连通扩展（二元运算不封闭）与不连通扩展（形成线性有序域）。

Result: 发现连通扩展对加法/乘法不封闭，不连通扩展可构成线性有序域，揭示了拓扑结构与代数性质的内在关联。

Conclusion: 该扩展理论为后续构造感知零测集的测度工具奠定了数学基础，在实分析领域具有潜在应用价值。

Abstract: Proper classes of extensions of real field was defined and topological
properties of these extensions were studied. These extensions can be connected,
in this case such set is not closed under binary operations (addition and
multiplication), and not connected, in this case this extension is linearly
ordered field. In the future these constructions can be applied to building
measure that "feels" set of zero Lebesgue measure.

</details>


### [32] [Definability of complex functions in o-minimal structures](https://arxiv.org/abs/2506.15119)
*Adele Padgett,Patrick Speissegger*

Main category: math.LO

TL;DR: 证明了$\mathbf{an}^*$和$\mathcal{G}$类函数的全纯延拓在o-极小结构$\mathbb{R}_{\mathrm{an}^*}$和$\mathbb{R}_{\mathcal{G}}$中可定义，并给出了最优复域。应用包括描述黎曼$\zeta$函数和$\Gamma$函数在相应o-极小扩张中的最优可定义域。


<details>
  <summary>Details</summary>
Motivation: 研究特定函数类在全纯延拓下的可定义性，为复分析函数在o-极小结构中的模型论性质提供理论基础。

Method: 通过构造复域证明全纯延拓的可定义性，并验证这些域的最优性。

Result: 确定了$\mathbf{an}^*$和$\mathcal{G}$类函数全纯延拓的最优可定义复域，并应用于黎曼$\zeta$函数和$\Gamma$函数。

Conclusion: 该研究为复变函数在o-极小结构中的可定义性提供了具体实例和理论框架，具有重要的模型论和复分析意义。

Abstract: We prove that some holomorphic continuations of functions in the classes
$\mathbf{an}^*$ and $\mathcal{G}$ are definable in the o-minimal structures
$\mathbb{R}_{\mathrm{an}^*}$ and $\mathbb{R}_{\mathcal{G}}$ respectively. More
specifically, we give complex domains on which the holomorphic continuations
are definable, and show they are optimal. As an application, we describe
optimal domains on which the Riemann $\zeta$ function is definable in o-minimal
expansions of $\mathbb{R}_{\mathrm{an}^*,\exp}$ and on which the $\Gamma$
function is definable in o-minimal expansions of
$\mathbb{R}_{\mathcal{G},\exp}$.

</details>


### [33] [$Σ^1_3$ sets in the Sacks model](https://arxiv.org/abs/2506.15308)
*Jonathan Schilhan*

Main category: math.LO

TL;DR: 在可构造宇宙的迭代Sacks模型中，证明了$\Sigma^1_3$集的Mansfield-Solovay定理成立，并确定了Bernstein集的最优复杂度为$\Delta^1_4$。


<details>
  <summary>Details</summary>
Motivation: 研究迭代Sacks模型中Mansfield-Solovay定理的适用范围，特别是针对$\Sigma^1_3$集的性质，并探索Bernstein集的复杂度界限。

Method: 基于Kanovei的结果，通过迭代Sacks模型的分析方法，验证$\Sigma^1_3$集的Mansfield-Solovay定理，并推导Bernstein集的复杂度。

Result: 在迭代Sacks模型中，所有$\mathbf{\Sigma}^1_3$集都是Marczewski可测的，且Bernstein集的最优复杂度为$\Delta^1_4$。

Conclusion: 该研究不仅扩展了Mansfield-Solovay定理的适用范围，还为射影层次中非平凡水平的分离提供了理论依据。

Abstract: We show that in the iterated Sacks model over the constructible universe the
Mansfield-Solovay Theorem holds for $\Sigma^1_3$ sets. In particular, every
$\mathbf{\Sigma}^1_3$ set is Marczewski measurable and the optimal complexity
for a Bernstein set is $\Delta^1_4$. Based on a result by Kanovei, we also
briefly show how to separate the Mansfield-Solovay Theorem at non-trivial
levels of the projective hierarchy.

</details>


### [34] [Strongly First Order Disjunctive Embedded Dependencies in Team Semantics](https://arxiv.org/abs/2506.15367)
*Pietro Galliani*

Main category: math.LO

TL;DR: 本文研究了团队语义中一阶逻辑的扩展表达力问题，特别关注了与数据库理论相关的析取嵌入式依赖关系。


<details>
  <summary>Details</summary>
Motivation: 团队语义是一阶逻辑的广义化，允许通过新型原子描述变量间依赖关系。某些扩展能增强表达力，而另一些则不能。本文旨在识别那些不增加一阶团队语义表达力的析取嵌入式依赖关系。

Method: 作者对析取嵌入式依赖关系进行了系统分析，特别关注其在团队语义中的表达力影响。通过理论分析，研究了这些依赖关系与一阶逻辑的等价性。

Result: 研究给出了(域独立的)析取嵌入式依赖关系的特征化描述，明确了哪些依赖关系不会增强一阶团队语义的表达力。

Conclusion: 该工作为团队语义中依赖关系的表达力影响提供了理论依据，特别识别了那些不增加一阶逻辑表达力的析取嵌入式依赖关系类。

Abstract: First Order Team Semantics is a generalization of Tarskian Semantics in which
formulas are satisfied with respect to sets of assignments. In Team Semantics,
it is possible to extend First Order Logic via new types of atoms that describe
dependencies between variables; some of these extensions are strictly more
expressive than First Order Logic, while others are reducible to it.
  Many of the atoms studied in Team Semantics are inspired by Database Theory
and belong in particular to the class of Disjunctive Embedded Dependencies, a
very general family of dependencies that contains most of the dependencies of
practical interest in the study of databases.
  In this work, I provide a characterization for the (domain-independent)
Disjunctive Embedded Dependencies that fail to increase the expressive power of
First-Order Team Semantics when added to it.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [35] [Factorizations in Geometric Lattices](https://arxiv.org/abs/2506.14892)
*Alex Aguila,Elvis Cabrera,Jyrko Correa-Morris*

Main category: math.CO

TL;DR: 本文研究了与有限集$X$的分割格$\Pi(X)$同构的几何格中的原子分解，探讨了原子性在这些格中的作用，并推导了特定原子子集$\mathcal{R}$的递归公式。


<details>
  <summary>Details</summary>
Motivation: 研究几何格中的原子分解，特别是分割格$\Pi(X)$，以深化对格论和组合数学中基本结构的理解，并借鉴交换代数中因子分解理论的概念。

Method: 首先分析函数$\mathfrak{N}\colon \Pi(X) \rightarrow \mathbb{N}$的特性，该函数计算每个分割$\pi$的最小原子分解数；然后研究特定原子子集$\mathcal{R}$，并推导枚举公式$\pmb{\pi}(X, j, s, \mathcal{R})$。

Result: 得出了一个递归公式$\pmb{\pi}(X, j, s, \mathcal{R})$，用于计算可由$s$个红色原子（$\mathcal{R}$中的原子）连接表示的秩为$j$的分割数量。

Conclusion: 通过研究分割格中的原子分解和特定原子子集，本文为格论和组合数学提供了新的理论工具和递归计算方法。

Abstract: This article investigates atomic decompositions in geometric lattices
isomorphic to the partition lattice $\Pi(X)$ of a finite set $X$, a fundamental
structure in lattice theory and combinatorics. We explore the role of atomicity
in these lattices, building on concepts introduced by D.D. Anderson, D.F.
Anderson, and M. Zafrullah within the context of factorization theory in
commutative algebra. As part of the study, we first examine the main
characteristics of the function $\mathfrak{N}\colon \Pi(X) \rightarrow
\mathbb{N}$, which assigns to each partition $\pi$ the number of minimal atomic
decompositions of $\pi$. We then consider a distinguished subset of atoms,
$\mathcal{R}$, referred to as the set of red atoms, and derive a recursive
formula for $\pmb{\pi}(X, j, s, \mathcal{R})$, which enumerates the rank-$j$
partitions expressible as the join of exactly $s$ red atoms.

</details>


### [36] [Hamiltonian connectivity of some base-cobase graphs](https://arxiv.org/abs/2506.15049)
*Leonardo Martínez-Sandoval,Kolja Knauer*

Main category: math.CO

TL;DR: 研究了拟阵基-余基图的哈密顿连通性，部分扩展了Naddef和Pulleyblank的结果，但发现R_{10}给出了反例。


<details>
  <summary>Details</summary>
Motivation: 探讨拟阵基-余基图是否继承基图的哈密顿连通性质，回应Farber等1985年提出的问题。

Method: 采用多面体方法分析串并联扩展的格路拟阵，并研究轮形拟阵、涡旋拟阵及正则拟阵R_{10}的特例。

Result: 证明串并联格路拟阵和轮形/涡旋拟阵的基-余基图具有哈密顿连通性，但R_{10}构成反例。

Conclusion: 基-余基图的哈密顿连通性仅适用于特定拟阵类，Naddef的结论无法普遍推广，R_{10}提供了否定答案。

Abstract: There has been wide interest in understanding which properties of base graphs
of matroids extend to base-cobase graphs of matroids. A significant result of
Naddef and Pulleyblank (1984) shows that the $1$-skeleton of any
$(0,1)$-polytope is either a hypercube, or Hamiltonian-connected, i.e. there is
a Hamiltonian path connecting any two vertices. In particular, this is true for
base graphs of matroids. A natural question raised by Farber, Richter, and
Shank (1985) is whether this extends to base-cobase graphs.
  First, we use the polytopal approach to show Hamiltonian connectivity of
base-cobase graphs of series-parallel extensions of lattice path matroids. On
the other hand, we show that this method extends to only very special classes
related to identically self-dual matroids. Second, we show that base-cobase
graphs of wheels and whirls are Hamiltonian connected. Last, we show that the
regular matroid $R_{10}$ yields a negative answer to the question of Farber,
Richter, and Shank.

</details>


### [37] [Short monochromatic odd cycles](https://arxiv.org/abs/2506.14910)
*Oliver Janzer,Fredy Yip*

Main category: math.CO

TL;DR: 本文证明了在完全图$K_{2^k+1}$的任意$k$边着色中，存在长度至多$O(k^{3/2}2^{k/2})$的单色奇环，显著改进了先前的结果。


<details>
  <summary>Details</summary>
Motivation: Erd\H{o}s和Graham在1973年提出估计$L(k)$的问题，即完全图$K_{2^k+1}$的任意$k$边着色中包含长度不超过$L(k)$的单色奇环的最小值。

Method: 结合代数组合数学和逼近理论的工具，改进了Gir\~ao和Hunter的先前工作。

Result: 证明了$L(k)=O(k^{3/2}2^{k/2})$，比之前的$O(\frac{2^k}{k^{1-o(1)}})$有指数级改进。

Conclusion: 通过创新方法，本文在单色奇环长度上界问题上取得了突破性进展，为相关领域提供了新的研究工具。

Abstract: It is easy to see that every $k$-edge-colouring of the complete graph on
$2^k+1$ vertices contains a monochromatic odd cycle. In 1973, Erd\H{o}s and
Graham asked to estimate the smallest $L(k)$ such that every $k$-edge-colouring
of $K_{2^k+1}$ contains a monochromatic odd cycle of length at most $L(k)$.
Recently, Gir\~ao and Hunter obtained the first nontrivial upper bound by
showing that $L(k)=O(\frac{2^k}{k^{1-o(1)}})$, which improves the trivial bound
by a polynomial factor. We obtain an exponential improvement by proving that
$L(k)=O(k^{3/2}2^{k/2})$. Our proof combines tools from algebraic combinatorics
and approximation theory.

</details>


### [38] [Some remarks on Folkman graphs for triangles](https://arxiv.org/abs/2506.14942)
*Eion Mulrenin*

Main category: math.CO

TL;DR: 本文研究了基于Hermitian单位几何图的类Folkman性质，证明了对于所有素数幂$q \geq 4$，存在一个三角形子集$\mathcal{T}_q$，使得这些图具有"准Folkman"性质，即在任何二色边着色下都包含单色三角形。


<details>
  <summary>Details</summary>
Motivation: Folkman定理指出存在不含$K_4$但在任何二色边着色下都包含单色三角形的图。研究这类图的定量性质$f(2,3,4)$非常困难，当前记录为$f(2,3,4) \leq 786$。本文旨在探索具有类似性质的几何图。

Method: 利用Hermitian单位几何图$H_q$，构造了一个三角形子集$\mathcal{T}_q$，并证明这些图在任何二色边着色下都包含$\mathcal{T}_q$中的单色三角形。此外，通过随机修改$H_q$破坏所有$K_4$，同时保持其Ramsey性质。

Result: 对于所有素数幂$q \geq 4$，存在一个208顶点的图（当$q=4$时），具有"准Folkman"性质。随机修改后的图在$q$较大时，仍能以高概率保持Ramsey性质。

Conclusion: 本文通过几何图构造和随机方法，扩展了Folkman定理的研究，为理解图的Ramsey性质提供了新的视角和工具。

Abstract: Folkman's theorem asserts the existence of graphs $G$ which are $K_4$-free,
but which have the property that every two-coloring of $E(G)$ contains a
monochromatic triangle. The quantitative aspects of $f(2,3,4)$, the least $n$
such that there exists an $n$-vertex graph with both properties above, are
notoriously difficult; a series of improvements over the span of two decades
witnessed the solution to two \$100 Erd\H{o}s problems, and the current record
due to Lange, Radziszowski, and Xu now stands at $f(2,3,4) \leq 786$, the proof
of which is computer-assisted.
  In this paper, we study Folkman-like properties of a sequence $H_q$ of finite
geometric graphs constructed using Hermitian unitals over projective planes
which were instrumental in the recent Mattheus-Verstra\"ete breakthrough on
off-diagonal Ramsey numbers. We show that for all prime powers $q \geq 4$,
there exists a subset $\mathcal{T}_q$ of triangles in $H_q$ such that no four
span a $K_4$ in $H_q$, but every two-coloring of $E(H_q)$ induces a
monochromatic triangle in $\mathcal{T}_q$. For $q=4$, this gives a graph on
$208$ vertices with this "quasi-Folkman" property. Moreover, we show that a
certain random alteration of $H_q$ which destroys all of its $K_4$'s will, for
large $q$, maintain the Ramsey property with high probability.

</details>


### [39] [Positive $m$-divisible non-crossing partitions and their Kreweras maps](https://arxiv.org/abs/2506.14996)
*Christian Krattenthaler,Christian Stump*

Main category: math.CO

TL;DR: 本文研究了正$m$-可分非交叉分划及其正Kreweras映射，在经典类型中给出了组合实现，并在例外类型中建立了新的组合模型，最终验证了循环筛选现象。


<details>
  <summary>Details</summary>
Motivation: 研究正$m$-可分非交叉分划及其正Kreweras映射的组合性质，旨在建立其在经典类型和例外类型中的统一理论框架。

Method: 在经典类型中通过非交叉集合分划和圆环/圆盘上的伪旋转实现正Kreweras映射；在例外类型中开发新的组合模型描述映射幂下的不变分划。

Result: 枚举了经典类型中正Kreweras映射幂下不变的正$m$-可分非交叉分划，并在一般类型中建立了对应的组合模型。

Conclusion: 研究结果证实了多种循环筛选现象，为正$m$-可分非交叉分划的理论提供了完整的组合解释。

Abstract: We study positive $m$-divisible non-crossing partitions and their positive
Kreweras maps. In classical types, we describe their combinatorial realisations
as certain non-crossing set partitions. We also realise these positive Kreweras
maps as pseudo-rotations on a circle, respectively on an annulus. We enumerate
positive $m$-divisible non-crossing partitions in classical types that are
invariant under powers of the positive Kreweras maps with respect to several
parameters. In order to cope with the exceptional types, we develop a different
combinatorial model in general type describing positive $m$-divisible
non-crossing partitions that are invariant under powers of the positive
Kreweras maps. We finally show that altogether these results establish several
cyclic sieving phenomena.

</details>


### [40] [Matroid complexes and Orlik-Solomon algebras](https://arxiv.org/abs/2506.15048)
*Basile Coron*

Main category: math.CO

TL;DR: 本文为超可解拟阵的Orlik-Solomon代数构建了一个组合拟自由微分分次模型，推广了Kontsevich为辫子排列引入的cdga，并证明该模型具有广义合作结构，最终用此模型新证明了超可解拟阵的Orlik-Solomon代数是Koszul的。


<details>
  <summary>Details</summary>
Motivation: 旨在将Kontsevich为辫子排列引入的可容许图cdga推广到拟阵框架中，并探索超可解拟阵Orlik-Solomon代数的Koszul性质。

Method: 利用拟阵理论中的模性、单元素扩张和广义平行连接等概念，构建组合拟自由微分分次模型，并证明其具有广义合作结构。

Result: 成功构建了超可解拟阵Orlik-Solomon代数的微分分次模型，并通过该模型给出了其Koszul性质的新证明。

Conclusion: 该研究不仅推广了Kontsevich的工作至拟阵领域，还为超可解拟阵代数性质的研究提供了新的组合工具。

Abstract: In this article we construct a combinatorial quasi-free differential graded
model for the Orlik-Solomon algebra of supersolvable matroids, which
generalizes in a matroidal setting the cdga of admissible graphs introduced by
M. Kontsevich for the braid arrangements. Our construction draws on well-known
concepts from matroid theory, including modularity, single-element extensions,
and generalized parallel connections. We also show that this model carries a
cooperadic structure in a suitably generalized sense. As an application, we use
this model to give a new proof that the Orlik-Solomon algebras of supersolvable
matroids are Koszul.

</details>


### [41] [Higher diameters of Cayley digraphs](https://arxiv.org/abs/2506.15137)
*G. C. Magda,J. Rubin,S. Streipert,C. Watt,A. Kumar,G. P. Constantine*

Main category: math.CO

TL;DR: 本文定义并研究了凯莱有向图的高阶直径。


<details>
  <summary>Details</summary>
Motivation: 探索凯莱有向图的高阶直径性质，以深化对图论中距离概念的理解。

Method: 通过数学定义和理论分析，引入并研究了凯莱有向图的高阶直径。

Result: 提出了凯莱有向图高阶直径的概念，并对其性质进行了初步探讨。

Conclusion: 该研究为凯莱有向图的高阶性质提供了新的研究方向。

Abstract: Higher diameters of Cayley digraphs are defined and studied.

</details>


### [42] [Antimagic labelings of a complete graph](https://arxiv.org/abs/2506.15221)
*Dr A. N. Bhavale*

Main category: math.CO

TL;DR: 本文证明了对于$n \geq 3$的完全图$K_n$，其不仅是超反魔图，而且是全反魔全图，并存在反魔定向。


<details>
  <summary>Details</summary>
Motivation: 研究源自Hartsfield和Ringel于1990年提出的反魔图猜想，以及Hefetz等人在2010年提出的关于简单连通无向图的反魔定向问题。

Method: 利用Bhavale提出的边标号方法，对给定无孤立顶点的图进行标号。

Result: 证明了对于$n \geq 3$的完全图$K_n$，其是超反魔图和全反魔全图，并且存在反魔定向。

Conclusion: 完全图$K_n$（$n \geq 3$）具有超反魔性和全反魔性，且存在反魔定向，这为反魔图理论提供了新的结果。

Abstract: In $1990$, Hartsfield and Ringel introduced antimagic graphs. Hartsfield and
Ringel conjectured that every connected graph (and in particular, a tree)
except $K_2$ is antimagic. In $2010$, Hefetz et al.\ raised two questions: Is
every orientation of any simple connected undirected graph antimagic? and Given
any undirected graph $G$, does there exist an orientation of $G$ which is
antimagic? They call such an orientation an {\it antimagic orientation} of $G$.
Recently, Bhavale provided an edge labeling for a given graph on $n$ vertices
without isolated vertices. In this paper, using the labeling of Bhavale, we
prove that a complete graph $K_n$ for $n \geq 3$ is super antimagic as well as
totally antimagic total graph. We also prove that there exists an antimagic
orientation of $K_n$ for $n \geq 3$.

</details>


### [43] [Structured and Punctured Nullstellensätze](https://arxiv.org/abs/2506.15281)
*Erhard Aichinger,John R. Schmitt,Henry Zhan*

Main category: math.CO

TL;DR: 本文综述并推广了关于多项式零点定理（Nullstellensatz）的若干结果，特别是Schauz和Nica的工作，并提出了一种统一框架。通过研究多元多项式除法中的特定单项式行为，作者将Alon-F\"uredi非零计数定理推广至穿孔网格。


<details>
  <summary>Details</summary>
Motivation: 多项式零点定理在代数几何和组合数学中具有核心地位。Alon的组合零点定理及其后续推广（如Schauz、Nica等人的工作）为多项式方法提供了重要工具。本文旨在统一并扩展这些结果，尤其是针对具有对称性的网格和穿孔网格。

Method: 通过分析多元多项式除法过程中特定单项式的保留特性，建立了一个通用理论框架。该方法结合了Schauz对更多单项式的排除策略和Nica对对称网格的优化结果。

Result: 1. 提出了Schauz与Nica结果的共同推广形式；2. 将Alon-F\"uredi非零计数定理扩展至穿孔网格（即形式为$X \setminus Y$的集合，其中$X,Y$均为网格）；3. 建立了多项式除法中单项式稳定性的新结论。

Conclusion: 本研究不仅统一了现有多种多项式零点定理的推广形式，还通过创新性地分析多项式除法过程，为组合数学中的多项式方法提供了更强大的理论工具。特别是对穿孔网格的应用拓展，展现了该框架的广泛适用性。

Abstract: A Nullstellensatz is a theorem providing information on polynomials that
vanish on a certain set: David Hilbert's Nullstellensatz (1893) is a
cornerstone of algebraic geometry, and Noga Alon's Combinatorial
Nullstellensatz (1999) is a powerful tool in the "Polynomial Method", a
technique used in combinatorics. Alon's Theorem excludes that a polynomial
vanishing on a grid contains a monomial with certain properties. This theorem
has been generalized in several directions, two of which we will consider in
detail: Terence Tao and Van H. Vu (2006), Uwe Schauz (2008) and Micha\l{}
Laso\'n (2010) exclude more monomials, and recently, Bogdan Nica (2023)
improved the result for grids with additional symmetries in their side edges.
Simeon Ball and Oriol Serra (2009) incorporated the multiplicity of zeros and
gave Nullstellens\"atze for punctured grids, which are sets of the form $X
\setminus Y$ with both $X,Y$ grids.
  We generalize some of these results; in particular, we provide a common
generalization to the results of Schauz and Nica. To this end, we establish
that during multivariate polynomial division, certain monomials are unaffected.
This also allows us to generalize Pete L. Clark's proof of the nonzero counting
theorem by Alon and F\"uredi to punctured grids.

</details>


### [44] [Posets for Specht ideals of essential real reflection groups](https://arxiv.org/abs/2506.15335)
*Sebastian Debus,Kurt Klement Gottwald*

Main category: math.CO

TL;DR: 本文扩展了Specht理想理论至D型反射群和二面体群，完成了所有无限族本质实反射群的组合研究。


<details>
  <summary>Details</summary>
Motivation: Specht理想是由与群表示相关的Specht多项式生成的多项式环中的对称理想，此前仅在A型和B型反射群中研究过。为了全面理解其组合结构，需要将其理论扩展至其他反射群类型。

Method: 通过将Specht理想理论推广至D型反射群和二面体群，研究其包含关系和簇结构，以揭示丰富的组合性质。

Result: 研究结果表明，D型反射群和二面体群的Specht理想同样展现出与A型和B型相似的组合结构，从而完成了所有无限族本质实反射群的Specht理想组合研究。

Conclusion: 本文成功将Specht理想理论扩展至D型反射群和二面体群，填补了该领域的研究空白，为所有无限族本质实反射群的Specht理想提供了完整的组合描述。

Abstract: Specht ideals are symmetric ideals in the polynomial ring generated by Specht
polynomials associated with group representations. These ideals were previously
studied for reflection groups of types $A$ and $B$, where their inclusion
relations and their varieties reflect rich combinatorial structures. In this
paper, we extend this theory to type $D$ and the dihedral groups. Our results
complete the combinatorial study of Specht ideals across all infinite families
of essential real reflection groups.

</details>


### [45] [Inverse eigenvalue problem for discrete Schrödinger operators of a graph](https://arxiv.org/abs/2506.15430)
*Anzila Laikhuram,Jephian C. -H. Lin*

Main category: math.CO

TL;DR: 本文研究了图的离散薛定谔算子的逆特征值问题，通过图结构的强性质解决了最多5个顶点图的问题。


<details>
  <summary>Details</summary>
Motivation: 离散薛定谔算子用于振动理论和Colin de Verdi\`ere参数研究，其逆特征值问题旨在刻画图的离散薛定谔算子可能的谱。

Method: 利用图结构的强性质，建立了超图引理、解放引理和分岔引理的类似版本。

Result: 通过上述结果，解决了最多5个顶点的图的离散薛定谔算子的逆特征值问题。

Conclusion: 研究表明，与图的逆特征值问题相比，离散薛定谔算子的解受到更多限制，并给出了基于图结构的若干限制条件。

Abstract: A discrete Schr\"odinger operator of a graph $G$ is a real symmetric matrix
whose $i,j$-entry, $i \neq j$, is negative if $\{i,j\}$ is an edge and zero if
it is not an edge, while diagonal entries can be any real numbers. The discrete
Schr\"odinger operators have been used to study vibration theory and the Colin
de Verdi\`ere parameter. The inverse eigenvalue problem for discrete
Schr\"odinger operators of a graph aims to characterize the possible spectra
among discrete Schr\"odinger operators of a graph. Comparing to the inverse
eigenvalue problem of a graph, the answers turn out to be more limited, and
several restrictions based on graph structure are given. Using the strong
properties, analogous versions of the supergraph lemma, the liberation lemma,
and the bifurcation lemma are established. Using these results, the inverse
eigenvalue problem for discrete Schr\"odinger operators is resolved for each
graph with at most $5$ vertices.

</details>


### [46] [Is it easy to regularize a hypergraph with easy links?](https://arxiv.org/abs/2506.15582)
*Lior Gishboliner,Asaf Shapira,Yuval Wigderson*

Main category: math.CO

TL;DR: 本文通过改进Terry和Wolf的结果，证明了3-图在顶点链接具有多项式大小$\varepsilon$-同质划分的条件下，其本身存在单指数大小的同质划分，且这一结果可推广至所有$k\geq3$的一致超图。同时，研究发现即使每个顶点链接具有多项式大小的$\varepsilon$-正则划分，3-图本身仍可能仅具有塔型大小的正则划分。


<details>
  <summary>Details</summary>
Motivation: 研究超图在何种条件下存在小的$\varepsilon$-同质或正则划分是广泛研究计划的一部分。虽然对于图的情况已有较好理解，但对于3-图及以上的一致超图，情况更为复杂。本文旨在探索顶点链接的划分性质如何影响整个超图的划分性质。

Method: 通过分析3-图顶点链接的$\varepsilon$-同质划分性质，改进Terry和Wolf的wowzer型函数界限，提出单指数大小的划分界限，并进一步推广至$k$-图。同时，通过构造反例，证明顶点链接的正则划分性质不能直接推广至整个3-图。

Result: 1. 对于3-图，若每个顶点链接具有多项式大小的$\varepsilon$-同质划分，则整个3-图存在单指数大小的同质划分，且这一界限是最优的。2. 即使每个顶点链接具有多项式大小的$\varepsilon$-正则划分，3-图本身仍可能仅具有塔型大小的正则划分。

Conclusion: 本文改进了Terry的猜想，证明了3-图在顶点链接具有多项式大小同质划分的条件下，其同质划分大小可优化为单指数级，且这一结果适用于所有$k\geq3$的一致超图。然而，顶点链接的正则划分性质不能保证整个3-图具有多项式大小的正则划分，揭示了超图正则性问题的复杂性。

Abstract: A partition of a (hyper)graph is $\varepsilon$-homogenous if the edge
densities between almost all clusters are either at most $\varepsilon$ or at
least $1-\varepsilon$. Suppose a $3$-graph has the property that the link of
every vertex has an $\varepsilon$-homogenous partition of size
$\text{poly}(1/\varepsilon)$. Does this guarantee that the $3$-graph also has a
small homogenous partition? Terry and Wolf proved that such a $3$-graph has an
$\varepsilon$-homogenous partition of size given by a wowzer-type function.
Terry recently improved this to a double exponential bound, and conjectured
that this bound is tight. Our first result in this paper disproves this
conjecture by giving an improved (single) exponential bound, which is best
possible. We further obtain an analogous result for $k$-graphs of all
uniformities $k \geq 3$.
  The above problem is part of a much broader programme which seeks to
understand the conditions under which a (hyper)graph has small
$\varepsilon$-regular partitions. While this problem is fairly well understood
for graphs, the situation is (as always) much more involved already for
$3$-graphs. For example, it is natural to ask if one can strengthen our first
result by only requiring each link to have $\varepsilon$-regular partitions of
size $\text{poly}(1/\varepsilon)$. Our second result shows that surprisingly
the answer is `no', namely, a $3$-graph might only have regular partitions of
tower-type size, even though the link of every vertex has an
$\varepsilon$-regular partition of polynomial size.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [47] [Winter Soldier: Backdooring Language Models at Pre-Training with Indirect Data Poisoning](https://arxiv.org/abs/2506.14913)
*Wassim Bouaziz,Mathurin Videau,Nicolas Usunier,El-Mahdi El-Mhamdi*

Main category: cs.CR

TL;DR: 本文提出了一种间接数据投毒方法，通过梯度优化的提示调校使语言模型学习训练数据中不存在的秘密序列，从而有效追踪数据使用且不影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据追踪方法依赖训练数据的记忆效应，而语言模型提供方试图限制这种效应。本研究探索无需记忆训练数据的间接数据投毒方案，以实现高效数据保护与使用追踪。

Method: 采用基于梯度优化的提示调校技术，使模型学习训练语料中不存在的'秘密提示-秘密响应'序列，投毒比例低于0.005%的token即可实现。

Result: 实验证明该方法可在不降低模型基准性能($p < 10^{-55}$)的情况下，以理论可验证的方式检测秘密序列，即使秘密从未出现在训练集中。

Conclusion: 间接数据投毒是一种可行且高效的数据保护手段，突破了传统依赖数据记忆的追踪方法限制，为语言模型数据溯源提供了新范式。

Abstract: The pre-training of large language models (LLMs) relies on massive text
datasets sourced from diverse and difficult-to-curate origins. Although
membership inference attacks and hidden canaries have been explored to trace
data usage, such methods rely on memorization of training data, which LM
providers try to limit. In this work, we demonstrate that indirect data
poisoning (where the targeted behavior is absent from training data) is not
only feasible but also allow to effectively protect a dataset and trace its
use. Using gradient-based optimization prompt-tuning, we make a model learn
arbitrary secret sequences: secret responses to secret prompts that are absent
from the training corpus. We validate our approach on language models
pre-trained from scratch and show that less than 0.005% of poisoned tokens are
sufficient to covertly make a LM learn a secret and detect it with extremely
high confidence ($p < 10^{-55}$) with a theoretically certifiable scheme.
Crucially, this occurs without performance degradation (on LM benchmarks) and
despite secrets never appearing in the training set.

</details>


### [48] [Fair Data Exchange with Constant-Time Proofs](https://arxiv.org/abs/2506.14944)
*Majid Khabbazian*

Main category: cs.CR

TL;DR: 本文提出了一种改进的公平数据交换(FDE)协议，通过将文件视为Reed-Solomon编码字并扩展至低速率编码，实现了证明和验证时间的常数级开销，同时保持完整公平性。


<details>
  <summary>Details</summary>
Motivation: 现有FDE协议的证明者和验证者运行时间仍随文件长度线性增长，需要优化以实现更高效的常数级开销。

Method: 将文件视为速率1的Reed-Solomon编码字，扩展至低速率编码并加密，仅对少量随机密文子集进行正确性证明，利用RS解码修复损坏符号。

Result: 新协议在保持客户端和服务器完全公平性的同时，仅增加可调的通信冗余开销，并将椭圆曲线不匹配问题通过zk-SNARK修补，实现链下运行。

Conclusion: 改进后的FDE协议显著降低了计算开销，同时维持了协议的安全性和公平性特征，为比特币环境下的链下交易提供了可行方案。

Abstract: The Fair Data Exchange (FDE) protocol introduced at CCS 2024 offers atomic
pay-per-file transfers with constant-size proofs, but its prover and verifier
runtimes still scale linearly with the file length n. We collapse these costs
to essentially constant by viewing the file as a rate-1 Reed-Solomon (RS)
codeword, extending it to a lower-rate RS code with constant redundancy,
encrypting this extended vector, and then proving correctness for only a small
random subset of the resulting ciphertexts; RS decoding repairs any corrupted
symbols with negligible failure probability. Our protocol preserves full
client- and server-fairness, and adds only a tunable communication redundancy
overhead.
  Finally, we patch the elliptic-curve mismatch in the Bitcoin instantiation of
FDE with a compact zk-SNARK, enabling the entire exchange to run off-chain and
falling back to just two on-chain transactions when channels are unavailable.

</details>


### [49] [Narrowing the Gap between TEEs Threat Model and Deployment Strategies](https://arxiv.org/abs/2506.14964)
*Filip Rezabek,Jonathan Passerat-Palmbach,Moe Mahhouk,Frieder Erdmann,Andrew Miller*

Main category: cs.CR

TL;DR: 保密虚拟机(CVMs)虽提供数据使用隔离，但缺乏物理层面防护与侧信道攻击防御，需依赖可信云提供商。当前TEE认证未绑定运营商信息，用户无法评估物理攻击风险。论文提出通过PPID等方案扩展认证机制以解决这一关键限制。


<details>
  <summary>Details</summary>
Motivation: 现有CVMs威胁模型未涵盖物理攻击防护，用户依赖云提供商却无法验证TEE运行环境，导致终端用户无法获得端到端安全保障，暴露了威胁模型与实际需求的错位问题。

Method: 提出扩展TEE认证机制，将CVM与云提供商绑定。探讨利用受保护平台标识符(PPID)等方案，解决不同TEE厂商实现差异带来的认证验证、迁移及去信任化应用构建挑战。

Result: 分析表明当前认证流程存在关键局限：异构TEE实现导致跨平台验证困难，用户必须信任云提供商，阻碍了CVMs的大规模应用。需标准化认证扩展方案以强化安全保障。

Conclusion: 论文强调必须通过TEE认证机制的强化与扩展（如PPID绑定）来解决CVM部署中的信任链断裂问题，这是实现真正端到端安全的关键技术路径。

Abstract: Confidential Virtual Machines (CVMs) provide isolation guarantees for data in
use, but their threat model does not include physical level protection and
side-channel attacks. Therefore, current deployments rely on trusted cloud
providers to host the CVMs' underlying infrastructure. However, TEE
attestations do not provide information about the operator hosting a CVM.
Without knowing whether a Trusted Execution Environment (TEE) runs within a
provider's infrastructure, a user cannot accurately assess the risks of
physical attacks. We observe a misalignment in the threat model where the
workloads are protected against other tenants but do not offer end-to-end
security assurances to external users without relying on cloud providers. The
attestation should be extended to bind the CVM with the provider. A possible
solution can rely on the Protected Platform Identifier (PPID), a unique CPU
identifier. However, the implementation details of various TEE manufacturers,
attestation flows, and providers vary. This makes verification of attestations,
ease of migration, and building applications without relying on a trusted party
challenging, highlighting a key limitation that must be addressed for the
adoption of CVMs. We discuss two points focusing on hardening and extensions of
TEEs' attestation.

</details>


### [50] [Private Continual Counting of Unbounded Streams](https://arxiv.org/abs/2506.15018)
*Ben Jacobsen,Kassem Fawaz*

Main category: cs.CR

TL;DR: 本文提出了一种新颖的差分隐私连续计数算法，适用于输入规模未知的无界场景，通过基于对数扰动的矩阵分解技术实现了平滑误差和高效计算。


<details>
  <summary>Details</summary>
Motivation: 现有基于矩阵机制的最优算法需要预先知道输入规模$n$，而常见的'倍增技巧'会导致非最优且不平滑的误差。本文旨在解决无界场景下的差分隐私连续计数问题。

Method: 引入基于函数$\frac{1}{\sqrt{1-z}}$对数扰动的新型矩阵分解方法，算法空间复杂度为$O(t)$，每轮摊销时间复杂度为$O(\log t)$。

Result: 对于任意$\alpha > 0$和$t\leq n$，算法能以$O(\log^{2+2\alpha}(t))$方差私有估计前$t$个数据点的和，实验显示在$t\leq 2^{24}$时方差小于Henzinger等算法的1.5倍。

Conclusion: 该算法在无界场景下实现了与有界场景最优算法相当的隐私保护效果和计算效率，其矩阵分解技术可能具有独立研究价值。

Abstract: We study the problem of differentially private continual counting in the
unbounded setting where the input size $n$ is not known in advance. Current
state-of-the-art algorithms based on optimal instantiations of the matrix
mechanism cannot be directly applied here because their privacy guarantees only
hold when key parameters are tuned to $n$. Using the common `doubling trick'
avoids knowledge of $n$ but leads to suboptimal and non-smooth error. We solve
this problem by introducing novel matrix factorizations based on logarithmic
perturbations of the function $\frac{1}{\sqrt{1-z}}$ studied in prior works,
which may be of independent interest. The resulting algorithm has smooth error,
and for any $\alpha > 0$ and $t\leq n$ it is able to privately estimate the sum
of the first $t$ data points with $O(\log^{2+2\alpha}(t))$ variance. It
requires $O(t)$ space and amortized $O(\log t)$ time per round, compared to
$O(\log(n)\log(t))$ variance, $O(n)$ space and $O(n \log n)$ pre-processing
time for the nearly-optimal bounded-input algorithm of Henzinger et al. (SODA
2023). Empirically, we find that our algorithm's performance is also comparable
to theirs in absolute terms: our variance is less than $1.5\times$ theirs for
$t$ as large as $2^{24}$.

</details>


### [51] [Systems-Theoretic and Data-Driven Security Analysis in ML-enabled Medical Devices](https://arxiv.org/abs/2506.15028)
*Gargi Mitra,Mohammadreza Hallajiyan,Inji Kim,Athish Pranav Dharmalingam,Mohammed Elnawawy,Shahrear Iqbal,Karthik Pattabiraman,Homa Alemzadeh*

Main category: cs.CR

TL;DR: AI/ML在医疗设备中的应用虽提升了诊疗能力，但也带来了严重的网络安全风险。本文强调需在上市前解决这些挑战，并提出了一套工具帮助安全分析师进行风险评估，以确保患者安全。


<details>
  <summary>Details</summary>
Motivation: AI/ML医疗设备的互联性、第三方设备互操作性及技术漏洞扩大了攻击面，可能导致模型误预测，威胁患者安全，因此需从设计阶段确保设备安全性。

Method: 通过分析公开的设备召回、不良事件及已知漏洞数据，理解AI/ML医疗设备的威胁态势，并开发了一套工具协助安全分析师进行上市前风险评估。

Result: 提出了一套工具和技术，帮助制造商将网络安全作为AI/ML医疗设备的核心设计原则，从而提升设备安全性。

Conclusion: 在AI/ML医疗设备的预上市阶段解决网络安全问题至关重要，本文的工具和方法为制造商提供了确保患者安全的有效途径。

Abstract: The integration of AI/ML into medical devices is rapidly transforming
healthcare by enhancing diagnostic and treatment facilities. However, this
advancement also introduces serious cybersecurity risks due to the use of
complex and often opaque models, extensive interconnectivity, interoperability
with third-party peripheral devices, Internet connectivity, and vulnerabilities
in the underlying technologies. These factors contribute to a broad attack
surface and make threat prevention, detection, and mitigation challenging.
Given the highly safety-critical nature of these devices, a cyberattack on
these devices can cause the ML models to mispredict, thereby posing significant
safety risks to patients. Therefore, ensuring the security of these devices
from the time of design is essential. This paper underscores the urgency of
addressing the cybersecurity challenges in ML-enabled medical devices at the
pre-market phase. We begin by analyzing publicly available data on device
recalls and adverse events, and known vulnerabilities, to understand the threat
landscape of AI/ML-enabled medical devices and their repercussions on patient
safety. Building on this analysis, we introduce a suite of tools and techniques
designed by us to assist security analysts in conducting comprehensive
premarket risk assessments. Our work aims to empower manufacturers to embed
cybersecurity as a core design principle in AI/ML-enabled medical devices,
thereby making them safe for patients.

</details>


### [52] [MECHA: Multithreaded and Efficient Cryptographic Hardware Access](https://arxiv.org/abs/2506.15034)
*Pratama Derry,Laksmono Agus Mahardika Ari,Iqbal Muhammad,Howon Kim*

Main category: cs.CR

TL;DR: 本文提出了一种多线程高效加密硬件访问架构(MECHA)，通过UNIX域套接字管理多应用请求，消除了上下文切换需求，显著提升了加密操作效率。


<details>
  <summary>Details</summary>
Motivation: 传统加密接口存在上下文切换开销，无法高效处理并发请求。MECHA旨在提供更快速的加密操作解决方案，适用于云计算和物联网等安全通信场景。

Method: 采用Server线程、Client线程、Transceiver线程及Sender/Receiver队列等核心组件，通过UNIX域套接字实现多应用请求的并行处理，支持任意通信协议。

Result: 实验表明，相比传统接口设计，MECHA可将并发加密请求处理速度提升83%，且架构具有高度可移植性。

Conclusion: MECHA架构为并发加密操作管理提供了高效解决方案，在安全通信领域具有重要应用潜力，尤其适用于需要高性能加密服务的场景。

Abstract: This paper presents a multithread and efficient cryptographic hardware access
(MECHA) for efficient and fast cryptographic operations that eliminates the
need for context switching. Utilizing a UNIX domain socket, MECHA manages
multiple requests from multiple applications simultaneously, resulting in
faster processing and improved efficiency. We comprise several key components,
including the Server thread, Client thread, Transceiver thread, and a pair of
Sender and Receiver queues. MECHA design is portable and can be used with any
communication protocol, with experimental results demonstrating a 83% increase
in the speed of concurrent cryptographic requests compared to conventional
interface design. MECHA architecture has significant potential in the field of
secure communication applications ranging from cloud computing to the IoT,
offering a faster and more efficient solution for managing multiple
cryptographic operation requests concurrently.

</details>


### [53] [Advanced Prediction of Hypersonic Missile Trajectories with CNN-LSTM-GRU Architectures](https://arxiv.org/abs/2506.15043)
*Amir Hossein Baradaran*

Main category: cs.CR

TL;DR: 本文提出了一种结合CNN、LSTM和GRU的混合深度学习模型，用于高精度预测高超音速导弹的复杂轨迹，显著提升了防御系统的预测能力。


<details>
  <summary>Details</summary>
Motivation: 高超音速导弹因其极速和高机动性对国家安全构成重大威胁，准确预测其轨迹是实施有效拦截的关键。

Method: 采用卷积神经网络（CNN）、长短期记忆网络（LSTM）和门控循环单元（GRU）相结合的混合深度学习架构，充分利用各模型的优势。

Result: 所提方法能够高精度预测高超音速导弹的复杂轨迹，为防御策略和导弹拦截技术提供了重要支持。

Conclusion: 研究表明，先进机器学习技术可显著增强防御系统的预测能力，为应对高超音速导弹威胁提供了有效解决方案。

Abstract: Advancements in the defense industry are paramount for ensuring the safety
and security of nations, providing robust protection against emerging threats.
Among these threats, hypersonic missiles pose a significant challenge due to
their extreme speeds and maneuverability, making accurate trajectory prediction
a critical necessity for effective countermeasures. This paper addresses this
challenge by employing a novel hybrid deep learning approach, integrating
Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM) networks,
and Gated Recurrent Units (GRUs). By leveraging the strengths of these
architectures, the proposed method successfully predicts the complex
trajectories of hypersonic missiles with high accuracy, offering a significant
contribution to defense strategies and missile interception technologies. This
research demonstrates the potential of advanced machine learning techniques in
enhancing the predictive capabilities of defense systems.

</details>


### [54] [Toward a Lightweight, Scalable, and Parallel Secure Encryption Engine](https://arxiv.org/abs/2506.15070)
*Rasha Karakchi,Rye Stahle-Smith,Nishant Chinnasami,Tiffany Yu*

Main category: cs.CR

TL;DR: 本文提出SPiME，一种轻量级、可扩展且兼容FPGA的安全内存处理器加密架构，通过将AES-128直接集成到内存处理框架中，显著提升了边缘计算中的数据加密效率。


<details>
  <summary>Details</summary>
Motivation: 物联网应用的指数增长加剧了对高效、高吞吐量和节能的边缘数据处理的迫切需求，传统CPU加密方法在延迟敏感和资源受限环境中存在性能瓶颈和数据移动过多的问题。

Method: SPiME架构设计为并行内存处理单元的模块化阵列，每个单元将AES核心与最小控制单元结合，实现分布式就地加密，并在Verilog中完全实现，在AMD UltraScale和UltraScale+ FPGA上进行测试。

Result: 评估结果显示，SPiME可扩展至超过4000个并行单元，同时在高性能设备上保持关键FPGA资源利用率低于5%，提供超过25 Gbps的持续加密吞吐量，并具有可预测的低延迟性能。

Conclusion: 该架构的可移植性、可配置性和资源效率使其成为安全边缘计算、嵌入式加密系统和可定制硬件加速器的理想解决方案。

Abstract: The exponential growth of Internet of Things (IoT) applications has
intensified the demand for efficient, high-throughput, and energy-efficient
data processing at the edge. Conventional CPU-centric encryption methods suffer
from performance bottlenecks and excessive data movement, especially in
latency-sensitive and resource-constrained environments. In this paper, we
present SPiME, a lightweight, scalable, and FPGA-compatible Secure
Processor-in-Memory Encryption architecture that integrates the Advanced
Encryption Standard (AES-128) directly into a Processing-in-Memory (PiM)
framework. SPiME is designed as a modular array of parallel PiM units, each
combining an AES core with a minimal control unit to enable distributed
in-place encryption with minimal overhead. The architecture is fully
implemented in Verilog and tested on multiple AMD UltraScale and UltraScale+
FPGAs. Evaluation results show that SPiME can scale beyond 4,000 parallel units
while maintaining less than 5\% utilization of key FPGA resources on high-end
devices. It delivers over 25~Gbps in sustained encryption throughput with
predictable, low-latency performance. The design's portability,
configurability, and resource efficiency make it a compelling solution for
secure edge computing, embedded cryptographic systems, and customizable
hardware accelerators.

</details>


### [55] [CWGAN-GP Augmented CAE for Jamming Detection in 5G-NR in Non-IID Datasets](https://arxiv.org/abs/2506.15075)
*Samhita Kuili,Mohammadreza Amini,Burak Kantarci*

Main category: cs.CR

TL;DR: 本文提出了一种基于卷积自编码器(CAE)的5G-NR无线网络干扰检测方法，通过生成对抗网络增强数据平衡性，在复杂异构数据集上实现了优于基准模型的检测性能。


<details>
  <summary>Details</summary>
Motivation: 5G-NR网络中空中干扰攻击普遍存在，会严重影响接收信号质量。现有方法难以应对异构I/Q数据集、同步信号块(SSB)信息提取以及显著类别不平衡等挑战。

Method: 采用添加高斯白噪声(AWGN)模拟干扰环境，利用卷积自编码器(CAE)进行干扰检测。通过Conv1D条件Wasserstein生成对抗网络梯度惩罚(CWGAN-GP)处理数据不平衡问题，并与去噪自编码器(CDAE)和稀疏自编码器(CSAE)进行对比。

Result: 在所有异构数据集中，CAE模型展现出强鲁棒性，平均精度达97.33%、召回率91.33%、F1分数94.08%、准确率94.35%，显著优于CDAE和CSAE基准模型。

Conclusion: 研究表明，CAE模型能有效检测5G-NR网络中的干扰信号，尤其在处理复杂异构数据和类别不平衡问题时表现优异，为无线网络安全提供了可靠解决方案。

Abstract: In the ever-expanding domain of 5G-NR wireless cellular networks,
over-the-air jamming attacks are prevalent as security attacks, compromising
the quality of the received signal. We simulate a jamming environment by
incorporating additive white Gaussian noise (AWGN) into the real-world In-phase
and Quadrature (I/Q) OFDM datasets. A Convolutional Autoencoder (CAE) is
exploited to implement a jamming detection over various characteristics such as
heterogenous I/Q datasets; extracting relevant information on Synchronization
Signal Blocks (SSBs), and fewer SSB observations with notable class imbalance.
Given the characteristics of datasets, balanced datasets are acquired by
employing a Conv1D conditional Wasserstein Generative Adversarial
Network-Gradient Penalty(CWGAN-GP) on both majority and minority SSB
observations. Additionally, we compare the performance and detection ability of
the proposed CAE model on augmented datasets with benchmark models:
Convolutional Denoising Autoencoder (CDAE) and Convolutional Sparse Autoencoder
(CSAE). Despite the complexity of data heterogeneity involved across all
datasets, CAE depicts the robustness in detection performance of jammed signal
by achieving average values of 97.33% precision, 91.33% recall, 94.08%
F1-score, and 94.35% accuracy over CDAE and CSAE.

</details>


### [56] [Flexible Hardware-Enabled Guarantees for AI Compute](https://arxiv.org/abs/2506.15093)
*James Petrie,Onni Aarne,Nora Ammann,David Dalrymple*

Main category: cs.CR

TL;DR: 本文提出了一种名为flexHEGs的硬件保障系统，旨在通过可审计的处理器和安全外壳解决AI发展中的国际安全与隐私保护问题，支持多样化的治理机制。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统的强大，其对国际安全的威胁日益增加，现有治理方法难以在不泄露敏感信息或国家安全的前提下有效协调。flexHEGs旨在提供一种可信、隐私保护的验证与执行方案。

Method: flexHEGs由可审计的保障处理器和安全外壳组成，监控AI加速器使用并提供物理防篡改保护。系统完全开源，具备灵活可更新的验证能力，支持隐私保护模型评估、受控部署、训练计算限制及自动安全协议执行。

Result: flexHEGs为前沿AI发展中的监管与国际安全挑战提供了一种技术解决方案，尽管存在技术难度，但其潜力在于支持多样化的治理机制。

Conclusion: flexHEGs作为一种硬件保障系统，为解决AI发展中的新兴监管和国际安全挑战提供了可行路径，但仍需克服技术挑战并推动其开发与采用。

Abstract: As artificial intelligence systems become increasingly powerful, they pose
growing risks to international security, creating urgent coordination
challenges that current governance approaches struggle to address without
compromising sensitive information or national security. We propose flexible
hardware-enabled guarantees (flexHEGs), that could be integrated with AI
accelerators to enable trustworthy, privacy-preserving verification and
enforcement of claims about AI development. FlexHEGs consist of an auditable
guarantee processor that monitors accelerator usage and a secure enclosure
providing physical tamper protection. The system would be fully open source
with flexible, updateable verification capabilities. FlexHEGs could enable
diverse governance mechanisms including privacy-preserving model evaluations,
controlled deployment, compute limits for training, and automated safety
protocol enforcement. In this first part of a three part series, we provide a
comprehensive introduction of the flexHEG system, including an overview of the
governance and security capabilities it offers, its potential development and
adoption paths, and the remaining challenges and limitations it faces. While
technically challenging, flexHEGs offer an approach to address emerging
regulatory and international security challenges in frontier AI development.

</details>


### [57] [International Security Applications of Flexible Hardware-Enabled Guarantees](https://arxiv.org/abs/2506.15100)
*Onni Aarne,James Petrie*

Main category: cs.CR

TL;DR: 该报告探讨了灵活硬件保障技术（flexHEGs）如何通过标准化设计、生态系统防御和明确操作参数，为国际可信AI治理提供技术基础，以应对恶意使用、失控风险、军事AI系统及战略稳定等安全挑战。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力快速进步，flexHEGs为解决国际安全挑战提供了新机遇，需通过全面治理框架管理AI相关芯片的风险。

Method: 分析了两种治理模式：基于验证的协议（透明合规监测）和基于规则集的协议（通过加密签名更新自动执行国际规则），并运用博弈论评估其稳定性。

Result: 研究表明，在合理假设下，全面的flexHEG协议能保持稳定，但需解决技术门槛、现有硬件管理及治理权力滥用等实施挑战。

Conclusion: 尽管需要大量国际协调，flexHEGs可为管理AI风险提供技术基础，以应对国际安全与稳定面临的新威胁。

Abstract: As AI capabilities advance rapidly, flexible hardware-enabled guarantees
(flexHEGs) offer opportunities to address international security challenges
through comprehensive governance frameworks. This report examines how flexHEGs
could enable internationally trustworthy AI governance by establishing
standardized designs, robust ecosystem defenses, and clear operational
parameters for AI-relevant chips. We analyze four critical international
security applications: limiting proliferation to address malicious use,
implementing safety norms to prevent loss of control, managing risks from
military AI systems, and supporting strategic stability through
balance-of-power mechanisms while respecting national sovereignty. The report
explores both targeted deployments for specific high-risk facilities and
comprehensive deployments covering all AI-relevant compute. We examine two
primary governance models: verification-based agreements that enable
transparent compliance monitoring, and ruleset-based agreements that
automatically enforce international rules through cryptographically-signed
updates. Through game-theoretic analysis, we demonstrate that comprehensive
flexHEG agreements could remain stable under reasonable assumptions about state
preferences and catastrophic risks. The report addresses critical
implementation challenges including technical thresholds for AI-relevant chips,
management of existing non-flexHEG hardware, and safeguards against abuse of
governance power. While requiring significant international coordination,
flexHEGs could provide a technical foundation for managing AI risks at the
scale and speed necessary to address emerging threats to international security
and stability.

</details>


### [58] [EVA-S2PMLP: Secure and Scalable Two-Party MLP via Spatial Transformation](https://arxiv.org/abs/2506.15102)
*Shizhao Peng,Shoumo Li,Tianle Tao*

Main category: cs.CR

TL;DR: 本文提出EVA-S2PMLP框架，一种高效、可验证且准确的安全两方多层感知机方案，通过空间尺度优化提升隐私保护和性能，适用于垂直分区场景下的隐私保护神经网络训练。


<details>
  <summary>Details</summary>
Motivation: 垂直分区场景下的隐私保护神经网络训练对跨机构安全协作建模至关重要，需解决实数域可靠计算与隐私保护的双重挑战。

Method: 提出安全转换流水线将标量输入映射至向量/矩阵空间，设计线性/非线性安全计算的原子协议集，模块化支持安全激活、矩阵向量运算及损失评估。

Result: 实验表明框架推理精度高且通信开销显著降低（最高提升12.3倍），基准数据集验证其在严格数据保密下保持模型效用。

Conclusion: EVA-S2PMLP为金融、医疗及跨组织AI应用中隐私保护训练提供实用解决方案，平衡模型效用与数据机密性。

Abstract: Privacy-preserving neural network training in vertically partitioned
scenarios is vital for secure collaborative modeling across institutions. This
paper presents \textbf{EVA-S2PMLP}, an Efficient, Verifiable, and Accurate
Secure Two-Party Multi-Layer Perceptron framework that introduces spatial-scale
optimization for enhanced privacy and performance. To enable reliable
computation under real-number domain, EVA-S2PMLP proposes a secure
transformation pipeline that maps scalar inputs to vector and matrix spaces
while preserving correctness. The framework includes a suite of atomic
protocols for linear and non-linear secure computations, with modular support
for secure activation, matrix-vector operations, and loss evaluation.
Theoretical analysis confirms the reliability, security, and asymptotic
complexity of each protocol. Extensive experiments show that EVA-S2PMLP
achieves high inference accuracy and significantly reduced communication
overhead, with up to $12.3\times$ improvement over baselines. Evaluation on
benchmark datasets demonstrates that the framework maintains model utility
while ensuring strict data confidentiality, making it a practical solution for
privacy-preserving neural network training in finance, healthcare, and
cross-organizational AI applications.

</details>


### [59] [PDLRecover: Privacy-preserving Decentralized Model Recovery with Machine Unlearning](https://arxiv.org/abs/2506.15112)
*Xiangman Li,Xiaodong Wu,Jianbing Ni,Mohamed Mahmoud,Maazen Alsabaan*

Main category: cs.CR

TL;DR: 本文提出PDLRecover方法，通过利用历史模型信息高效恢复被投毒攻击破坏的全局模型，同时保护隐私。该方法避免了重新训练的高成本，并通过秘密共享技术确保本地模型参数不泄露。实验表明，恢复后的模型性能接近完全重新训练的模型，但计算和时间成本显著降低。


<details>
  <summary>Details</summary>
Motivation: 去中心化学习易受投毒攻击，现有防御方法主要检测并过滤恶意模型，但难以恢复已受损的全局模型。直接移除恶意客户端并重新训练不仅耗时且计算成本高，还可能影响模型一致性和隐私。因此，需要一种高效且隐私保护的恢复方法。

Method: PDLRecover利用历史模型信息进行恢复，通过近似Hessian矩阵计算的线性特性，应用秘密共享技术保护历史更新，防止本地模型在传输或重建过程中泄露。方法包括客户端准备、周期性恢复更新和最终精确更新，以确保恢复模型的鲁棒性和收敛性。

Result: 实验表明，PDLRecover恢复的全局模型性能与完全重新训练的模型相当，但计算和时间成本显著降低。同时，该方法有效防止了本地模型参数的泄露，确保了恢复过程中的准确性和隐私。

Conclusion: PDLRecover提供了一种高效且隐私保护的全局模型恢复方法，解决了去中心化学习中投毒攻击后的恢复难题，为实际应用提供了可行的解决方案。

Abstract: Decentralized learning is vulnerable to poison attacks, where malicious
clients manipulate local updates to degrade global model performance. Existing
defenses mainly detect and filter malicious models, aiming to prevent a limited
number of attackers from corrupting the global model. However, restoring an
already compromised global model remains a challenge. A direct approach is to
remove malicious clients and retrain the model using only the benign clients.
Yet, retraining is time-consuming, computationally expensive, and may
compromise model consistency and privacy.
  We propose PDLRecover, a novel method to recover a poisoned global model
efficiently by leveraging historical model information while preserving
privacy. The main challenge lies in protecting shared historical models while
enabling parameter estimation for model recovery. By exploiting the linearity
of approximate Hessian matrix computation, we apply secret sharing to protect
historical updates, ensuring local models are not leaked during transmission or
reconstruction. PDLRecover introduces client-side preparation, periodic
recovery updates, and a final exact update to ensure robustness and convergence
of the recovered model. Periodic updates maintain accurate curvature
information, and the final step ensures high-quality convergence. Experiments
show that the recovered global model achieves performance comparable to a fully
retrained model but with significantly reduced computation and time cost.
Moreover, PDLRecover effectively prevents leakage of local model parameters,
ensuring both accuracy and privacy in recovery.

</details>


### [60] [CipherMind: The Longest Codebook in the World](https://arxiv.org/abs/2506.15117)
*Ming Nie,Zhixiong Yang,Bingsheng Wei*

Main category: cs.CR

TL;DR: 本文提出CipherMind，利用大模型推理的确定性微调中间结果作为传输内容，实现通信加密。该方法适用于网关内传输等场景，理论上可基于任何大模型实现。


<details>
  <summary>Details</summary>
Motivation: 受大语言模型广泛应用的启发，研究者探索利用其推理过程实现通信加密的可能性。大模型的语义参数具有底层实现不透明、可解释性弱的特点，适合作为加密手段。

Method: 通过确定性微调大模型推理过程，提取中间结果作为加密传输内容。该方法不依赖传统加密算法，而是利用大模型本身的特性实现数据保护。

Result: 提出的CipherMind框架证实了大模型中间结果可用于加密传输，且该通信范式具有普适性，理论上适用于各类大模型基础架构。

Conclusion: 基于大模型的加密通信新范式为数据传输安全提供了创新思路，尤其在网关内传输等场景具有应用潜力，未来可拓展更多大模型实现方案。

Abstract: In recent years, the widespread application of large language models has
inspired us to consider using inference for communication encryption. We
therefore propose CipherMind, which utilizes intermediate results from
deterministic fine-tuning of large model inferences as transmission content.
The semantic parameters of large models exhibit characteristics like opaque
underlying implementations and weak interpretability, thus enabling their use
as an encryption method for data transmission. This communication paradigm can
be applied in scenarios like intra-gateway transmission, and theoretically, it
can be implemented using any large model as its foundation.

</details>


### [61] [From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem](https://arxiv.org/abs/2506.15170)
*Yanxu Mao,Tiehan Cui,Peipei Liu,Datao You,Hongsong Zhu*

Main category: cs.CR

TL;DR: 本文系统综述了大型语言模型(LLM)向多模态和智能代理发展过程中日益严重的越狱攻击及防御机制，梳理了攻击分类、防御策略，并指出当前研究的不足与未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLM向多模态和智能代理演进，其安全风险日益严峻，亟需系统化梳理越狱攻击与防御的研究现状及挑战。

Method: 从攻击影响和可见性角度分类主流越狱技术，分析代表性方法、数据集和评估指标；按响应时机和技术路线组织防御策略，并批判性指出现有调查的四大局限性。

Result: 提出了更新的研究综合框架，明确了混合越狱方法分类缺失、代理安全问题关注不足等缺口，为数据集构建、评估框架优化等未来方向提供指导。

Conclusion: 研究深化了对越狱机制的理解，有助于在LLM能力持续扩展的背景下发展更具韧性和适应性的防御策略体系。

Abstract: Large language models (LLMs) are rapidly evolving from single-modal systems
to multimodal LLMs and intelligent agents, significantly expanding their
capabilities while introducing increasingly severe security risks. This paper
presents a systematic survey of the growing complexity of jailbreak attacks and
corresponding defense mechanisms within the expanding LLM ecosystem. We first
trace the developmental trajectory from LLMs to MLLMs and Agents, highlighting
the core security challenges emerging at each stage. Next, we categorize
mainstream jailbreak techniques from both the attack impact and visibility
perspectives, and provide a comprehensive analysis of representative attack
methods, related datasets, and evaluation metrics. On the defense side, we
organize existing strategies based on response timing and technical approach,
offering a structured understanding of their applicability and implementation.
Furthermore, we identify key limitations in existing surveys, such as
insufficient attention to agent-specific security issues, the absence of a
clear taxonomy for hybrid jailbreak methods, a lack of detailed analysis of
experimental setups, and outdated coverage of recent advancements. To address
these limitations, we provide an updated synthesis of recent work and outline
future research directions in areas such as dataset construction, evaluation
framework optimization, and strategy generalization. Our study seeks to enhance
the understanding of jailbreak mechanisms and facilitate the advancement of
more resilient and adaptive defense strategies in the context of ever more
capable LLMs.

</details>


### [62] [LLM vs. SAST: A Technical Analysis on Detecting Coding Bugs of GPT4-Advanced Data Analysis](https://arxiv.org/abs/2506.15212)
*Madjid G. Tehrani,Eldar Sultanow,William J. Buchanan,Mahkame Houmani,Christel H. Djaha Fodja*

Main category: cs.CR

TL;DR: 本文研究了GPT-4在识别软件漏洞方面的效能，发现其准确率高达94%，优于传统静态应用安全测试工具。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理技术的快速发展，大型语言模型如GPT-4在安全漏洞扫描等领域的应用潜力值得探索。

Method: 研究通过对比GPT-4与传统静态应用安全测试工具在检测32种可利用漏洞中的表现，评估其效能。

Result: GPT-4（高级数据分析版）在漏洞检测中的准确率达到94%，显著优于传统工具。

Conclusion: 研究表明GPT-4在漏洞扫描中具有显著优势，同时强调了AI设计中安全最佳实践的重要性。

Abstract: With the rapid advancements in Natural Language Processing (NLP), large
language models (LLMs) like GPT-4 have gained significant traction in diverse
applications, including security vulnerability scanning. This paper
investigates the efficacy of GPT-4 in identifying software vulnerabilities
compared to traditional Static Application Security Testing (SAST) tools.
Drawing from an array of security mistakes, our analysis underscores the potent
capabilities of GPT-4 in LLM-enhanced vulnerability scanning. We unveiled that
GPT-4 (Advanced Data Analysis) outperforms SAST by an accuracy of 94% in
detecting 32 types of exploitable vulnerabilities. This study also addresses
the potential security concerns surrounding LLMs, emphasising the imperative of
security by design/default and other security best practices for AI.

</details>


### [63] [RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments](https://arxiv.org/abs/2506.15253)
*Yuchuan Fu,Xiaohan Yuan,Dongxia Wang*

Main category: cs.CR

TL;DR: 本文提出RAS-Eval安全基准测试框架，用于评估动态环境中大型语言模型（LLM）代理的脆弱性，覆盖80个测试案例和3,802个攻击任务。实验显示攻击平均降低任务完成率36.78%，学术环境成功率高达85.65%，同时验证模型规模与安全性能的正相关性。


<details>
  <summary>Details</summary>
Motivation: 由于LLM代理在医疗、金融等关键领域的快速部署缺乏标准化安全评估标准，研究旨在建立动态环境下的系统性安全基准。

Method: 开发支持模拟/真实工具执行的RAS-Eval框架，包含11类CWE漏洞的测试用例，工具采用JSON、LangGraph和MCP格式实现，并评估6种前沿LLM模型。

Result: 攻击显著削弱代理性能：平均任务完成率下降36.78%，学术攻击成功率85.65%；大模型安全表现优于小模型，验证规模法则适用性。

Conclusion: 研究揭示了现实场景中LLM代理的重大安全风险，RAS-Eval为后续安全研究提供基础框架，代码数据已开源。

Abstract: The rapid deployment of Large language model (LLM) agents in critical domains
like healthcare and finance necessitates robust security frameworks. To address
the absence of standardized evaluation benchmarks for these agents in dynamic
environments, we introduce RAS-Eval, a comprehensive security benchmark
supporting both simulated and real-world tool execution. RAS-Eval comprises 80
test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration
(CWE) categories, with tools implemented in JSON, LangGraph, and Model Context
Protocol (MCP) formats. We evaluate 6 state-of-the-art LLMs across diverse
scenarios, revealing significant vulnerabilities: attacks reduced agent task
completion rates (TCR) by 36.78% on average and achieved an 85.65% success rate
in academic settings. Notably, scaling laws held for security capabilities,
with larger models outperforming smaller counterparts. Our findings expose
critical risks in real-world agent deployments and provide a foundational
framework for future security research. Code and data are available at
https://github.com/lanzer-tree/RAS-Eval.

</details>


### [64] [Facility Location Problem under Local Differential Privacy without Super-set Assumption](https://arxiv.org/abs/2506.15224)
*Kevin Pfisterer,Quentin Hillebrand,Vorapong Suppakitpaisarn*

Main category: cs.CR

TL;DR: 本文在局部差分隐私（LDP）框架下提出了一种设施选址问题的改进模型，通过设计新算法突破了原有$\Omega(\sqrt{n})$的下界限制，实现了常数近似比且附加误差较小，实验证明其在合成和真实数据集上均优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统差分隐私算法在设施选址问题中存在$\Omega(\sqrt{n})$近似比下限，且超集假设可能损害用户隐私。本研究旨在证明该下限不适用于改进后的LDP模型。

Method: 提出基于局部差分隐私的改进算法，通过重新建模设施选址问题，避免直接应用超集假设，同时保证用户位置隐私。

Result: 算法实现了常数近似比和较小附加误差，实验数据表明其在合成与真实数据集上的性能均显著优于传统方法。

Conclusion: 该研究突破了原有理论下限，为隐私保护的设施选址问题提供了更优解决方案，同时验证了LDP框架在此类问题中的有效性。

Abstract: In this paper, we introduce an adaptation of the facility location problem
and analyze it within the framework of local differential privacy (LDP). Under
this model, we ensure the privacy of client presence at specific locations.
When n is the number of points, Gupta et al. established a lower bound of
$\Omega(\sqrt{n})$ on the approximation ratio for any differentially private
algorithm applied to the original facility location problem. As a result,
subsequent works have adopted the super-set assumption, which may, however,
compromise user privacy. We show that this lower bound does not apply to our
adaptation by presenting an LDP algorithm that achieves a constant
approximation ratio with a relatively small additive factor. Additionally, we
provide experimental results demonstrating that our algorithm outperforms the
straightforward approach on both synthetically generated and real-world
datasets.

</details>


### [65] [Evaluation Pipeline for systematically searching for Anomaly Detection Systems](https://arxiv.org/abs/2506.15388)
*Florian Rokohl,Alexander Lehnert,Marc Reichenbach*

Main category: cs.CR

TL;DR: 医疗数字化带来便利的同时也面临网络安全威胁，研究提出基于FPGA的实时异常检测系统以识别恶意客户端。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的数字化虽带来重大益处，但也成为攻击者的目标，网络安全问题日益突出。

Method: 采用FPGA硬件实现实时异常检测系统，以满足实时性和低功耗需求，并通过整体系统评估优化性能。

Result: 提出的系统能够在实时条件下有效检测网络入侵者，同时满足严格的功耗限制。

Conclusion: 基于FPGA的硬件方案为医疗数字化安全提供了可行的实时异常检测解决方案。

Abstract: Digitalization in the medical world provides major benefits while making it a
target for attackers and thus hard to secure. To deal with network intruders we
propose an anomaly detection system on hardware to detect malicious clients in
real-time. We meet real-time and power restrictions using FPGAs. Overall system
performance is achieved via the presented holistic system evaluation.

</details>


### [66] [Detecting Hardware Trojans in Microprocessors via Hardware Error Correction Code-based Modules](https://arxiv.org/abs/2506.15417)
*Alessandro Palumbo,Ruben Salvador*

Main category: cs.CR

TL;DR: 本文提出了一种基于硬件的方法，利用RISC-V微处理器上的纠错码(ECC)检测运行时硬件木马(HT)激活，特别是针对注入恶意指令的HT。通过硬件安全检查器(HSC)和汉明单纠错(HSEC)架构，实现了100%的检测率且无额外开销。


<details>
  <summary>Details</summary>
Motivation: 软件可利用的硬件木马(HT)使攻击者能够执行未授权软件或获取特权操作权限，威胁系统安全。因此，需要一种有效的方法来检测运行时HT激活。

Method: 采用基于硬件的方法，利用汉明单纠错(HSEC)架构构建硬件安全检查器(HSC)，在RISC-V微处理器上检测HT激活，特别是针对恶意指令注入的HT。

Result: 实验结果表明，该方法对潜在HT激活的检测率达到100%，且无假阳性或未检测到的攻击。实现仅需72个LUT、24个FF和0.5个BRAM，不影响处理器原始频率且无额外延迟。

Conclusion: 所提出的硬件安全检查器(HSC)能高效检测运行时HT激活，具有高检测率和低硬件开销，为RISC-V微处理器提供了可靠的安全保障。

Abstract: Software-exploitable Hardware Trojans (HTs) enable attackers to execute
unauthorized software or gain illicit access to privileged operations. This
manuscript introduces a hardware-based methodology for detecting runtime HT
activations using Error Correction Codes (ECCs) on a RISC-V microprocessor.
Specifically, it focuses on HTs that inject malicious instructions, disrupting
the normal execution flow by triggering unauthorized programs. To counter this
threat, the manuscript introduces a Hardware Security Checker (HSC) leveraging
Hamming Single Error Correction (HSEC) architectures for effective HT
detection. Experimental results demonstrate that the proposed solution achieves
a 100% detection rate for potential HT activations, with no false positives or
undetected attacks. The implementation incurs minimal overhead, requiring only
72 #LUTs, 24 #FFs, and 0.5 #BRAM while maintaining the microprocessor's
original operating frequency and introducing no additional time delay.

</details>


### [67] [Side-Channel Extraction of Dataflow AI Accelerator Hardware Parameters](https://arxiv.org/abs/2506.15432)
*Guillaume Lomet,Ruben Salvador,Brice Colombier,Vincent Grosso,Olivier Sentieys,Cedric Killian*

Main category: cs.CR

TL;DR: 本文提出一种针对FINN框架生成的数据流神经网络加速器的侧信道攻击方法，通过无监督降维和轻量级分类器，高效恢复硬件配置参数，攻击时间短且准确率高。


<details>
  <summary>Details</summary>
Motivation: 数据流神经网络加速器虽简化了AI任务部署，但其便利性使其易受侧信道攻击，导致知识产权被逆向工程。现有方法计算开销大，需更高效的攻击方案。

Method: 采用无监督降维技术降低计算开销，结合随机森林分类器从侧信道痕迹中恢复折叠和量化参数，攻击阶段仅需数百毫秒。

Result: 攻击方法在337毫秒内恢复硬件参数的准确率超过95%，421毫秒内完全恢复参数（平均4条痕迹），相比现有方法准备和攻击时间分别减少940倍和110倍。

Conclusion: 该方法在完全加载加速器数据流的情况下仍能高效攻击，提供了比现有技术更现实的攻击场景，且无需痕迹平均即可获得更好结果。

Abstract: Dataflow neural network accelerators efficiently process AI tasks on FPGAs,
with deployment simplified by ready-to-use frameworks and pre-trained models.
However, this convenience makes them vulnerable to malicious actors seeking to
reverse engineer valuable Intellectual Property (IP) through Side-Channel
Attacks (SCA). This paper proposes a methodology to recover the hardware
configuration of dataflow accelerators generated with the FINN framework.
Through unsupervised dimensionality reduction, we reduce the computational
overhead compared to the state-of-the-art, enabling lightweight classifiers to
recover both folding and quantization parameters. We demonstrate an attack
phase requiring only 337 ms to recover the hardware parameters with an accuracy
of more than 95% and 421 ms to fully recover these parameters with an averaging
of 4 traces for a FINN-based accelerator running a CNN, both using a random
forest classifier on side-channel traces, even with the accelerator dataflow
fully loaded. This approach offers a more realistic attack scenario than
existing methods, and compared to SoA attacks based on tsfresh, our method
requires 940x and 110x less time for preparation and attack phases,
respectively, and gives better results even without averaging traces.

</details>


### [68] [An efficient construction of Raz's two-source randomness extractor with improved parameters](https://arxiv.org/abs/2506.15547)
*Cameron Foreman,Lewis Wooltorton,Kevin Milner,Florian J. Curchod*

Main category: cs.CR

TL;DR: 本文改进了Raz的随机性提取器，提出了一种计算时间为准线性的新版本，并降低了熵需求，同时提供了开源实现和数值参数计算模块。


<details>
  <summary>Details</summary>
Motivation: Raz的原始提取器虽然能在线性最小熵和对数最小熵条件下工作，但其计算时间高达多项式级别（至少四次方），导致实际应用受限。本研究旨在解决这一效率问题。

Method: 通过改进Raz提取器的构造，实现了准线性计算时间；提出新的分析定理以降低熵需求；开发了开源代码实现和参数计算工具，并与现有方案进行了全面分析和数值比较。

Result: 改进后的提取器在保持功能的同时显著提升了计算效率（准线性时间），并衍生出强抗量子版本。开源实现和参数模块为实际应用提供了便利。

Conclusion: 本研究解决了Raz提取器的效率瓶颈，为弱随机源的实用化提取提供了高效工具，并通过开源实现促进了该技术的实际部署。

Abstract: Randomness extractors are algorithms that distill weak random sources into
near-perfect random numbers. Two-source extractors enable this distillation
process by combining two independent weak random sources. Raz's extractor (STOC
'05) was the first to achieve this in a setting where one source has linear
min-entropy (i.e., proportional to its length), while the other has only
logarithmic min-entropy in its length. However, Raz's original construction is
impractical due to a polynomial computation time of at least degree 4. Our work
solves this problem by presenting an improved version of Raz's extractor with
quasi-linear computation time, as well as a new analytic theorem with reduced
entropy requirements. We provide comprehensive analytical and numerical
comparisons of our construction with others in the literature, and we derive
strong and quantum-proof versions of our efficient Raz extractor. Additionally,
we offer an easy-to-use, open-source code implementation of the extractor and a
numerical parameter calculation module.

</details>


### [69] [deepSURF: Detecting Memory Safety Vulnerabilities in Rust Through Fuzzing LLM-Augmented Harnesses](https://arxiv.org/abs/2506.15648)
*Georgios Androutsopoulos,Antonio Bianchi*

Main category: cs.CR

TL;DR: 本文介绍了deepSURF工具，它结合静态分析与LLM引导的模糊测试技术，有效检测Rust库中的内存安全漏洞，特别是在不安全代码中。通过替换泛型类型和动态增强模糊测试工具链，deepSURF在27个实际Rust包中成功复现20个已知漏洞并发现6个新漏洞。


<details>
  <summary>Details</summary>
Motivation: 尽管Rust默认保证内存安全，但不安全代码的使用仍可能引入漏洞。现有工具在检测能力、处理Rust特有类型或自动化程度上存在不足，亟需更高效的解决方案。

Method: deepSURF创新性地采用泛型替换机制（用自定义类型替代泛型并实现相关trait），并利用LLM动态生成模糊测试工具链，以模拟复杂API交互场景。该方法结合静态分析与模糊测试，专门针对不安全代码进行深度检测。

Result: 在27个真实Rust包测试中，工具成功复现20个已知内存安全漏洞，同时发现6个未知漏洞，其表现显著优于现有最先进工具。

Conclusion: deepSURF通过融合静态分析与LLM增强的模糊测试技术，显著提升了Rust内存漏洞检测效果，尤其在不安全代码和泛型处理方面展现出独特优势，为Rust生态安全提供了实用工具。

Abstract: Although Rust ensures memory safety by default, it also permits the use of
unsafe code, which can introduce memory safety vulnerabilities if misused.
Unfortunately, existing tools for detecting memory bugs in Rust typically
exhibit limited detection capabilities, inadequately handle Rust-specific
types, or rely heavily on manual intervention.
  To address these limitations, we present deepSURF, a tool that integrates
static analysis with Large Language Model (LLM)-guided fuzzing harness
generation to effectively identify memory safety vulnerabilities in Rust
libraries, specifically targeting unsafe code. deepSURF introduces a novel
approach for handling generics by substituting them with custom types and
generating tailored implementations for the required traits, enabling the
fuzzer to simulate user-defined behaviors within the fuzzed library.
Additionally, deepSURF employs LLMs to augment fuzzing harnesses dynamically,
facilitating exploration of complex API interactions and significantly
increasing the likelihood of exposing memory safety vulnerabilities. We
evaluated deepSURF on 27 real-world Rust crates, successfully rediscovering 20
known memory safety bugs and uncovering 6 previously unknown vulnerabilities,
demonstrating clear improvements over state-of-the-art tools.

</details>


### [70] [PhishDebate: An LLM-Based Multi-Agent Framework for Phishing Website Detection](https://arxiv.org/abs/2506.15656)
*Wenhao Li,Selvakumar Manickam,Yung-wey Chong,Shankar Karuppayah*

Main category: cs.CR

TL;DR: 本文提出PhishDebate框架，采用多智能体LLM辩论机制检测钓鱼网站，通过模块化设计提升检测准确率与可解释性，实验显示其性能优于单智能体及思维链基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有钓鱼网站检测方法多依赖单智能体分类，存在幻觉风险且缺乏可解释性与鲁棒性，亟需通过多智能体协作框架解决这些问题。

Method: 设计包含URL结构、HTML组成、语义内容、品牌仿冒4个专项分析智能体的辩论框架，由协调员和裁决法官主导结构化辩论流程，实现多维度网页分析。

Result: 在真实钓鱼数据集上达到98.2%召回率和真阳性率，显著优于单智能体及CoT基线方法，模块化设计支持智能体级配置以适应不同资源需求。

Conclusion: PhishDebate通过多智能体辩论机制有效提升钓鱼检测性能，其高准确率、强解释性和可配置性为网络安全领域提供新解决方案。

Abstract: Phishing websites continue to pose a significant cybersecurity threat, often
leveraging deceptive structures, brand impersonation, and social engineering
tactics to evade detection. While recent advances in large language models
(LLMs) have enabled improved phishing detection through contextual
understanding, most existing approaches rely on single-agent classification
facing the risks of hallucination and lack interpretability or robustness. To
address these limitations, we propose PhishDebate, a modular multi-agent
LLM-based debate framework for phishing website detection. PhishDebate employs
four specialized agents to independently analyze different textual aspects of a
webpage--URL structure, HTML composition, semantic content, and brand
impersonation--under the coordination of a Moderator and a final Judge. Through
structured debate and divergent thinking, the framework delivers more accurate
and interpretable decisions. Extensive evaluations on commercial LLMs
demonstrate that PhishDebate achieves 98.2% recall and 98.2% True Positive Rate
(TPR) on a real-world phishing dataset, and outperforms single-agent and Chain
of Thought (CoT) baselines. Additionally, its modular design allows agent-level
configurability, enabling adaptation to varying resource and application
requirements.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [71] [CALM: Contextual Analog Logic with Multimodality](https://arxiv.org/abs/2506.14936)
*Maxwell J. Jacobson,Corey J. Maley,Yexiang Xue*

Main category: cs.AI

TL;DR: 本文提出CALM框架，融合符号逻辑与神经生成，实现多模态环境下的上下文敏感决策，在物体摆放任务中准确率达92.2%，超越传统逻辑与LLM基线。


<details>
  <summary>Details</summary>
Motivation: 经典二值逻辑无法捕捉人类决策的细微差别，且在多模态环境中依赖人工标注，而神经网络虽擅长多模态信息提取但缺乏可解释性。CALM旨在弥合逻辑推理与神经感知的鸿沟。

Method: CALM通过领域树表示谓词，利用神经网络迭代优化模拟真值，并通过符号推理模块确保约束满足，实现多模态信息与逻辑结构的融合。

Result: 在填空式物体摆放任务中，CALM以92.2%准确率显著优于传统逻辑（86.3%）和LLM（59.4%），生成的空间热图同时满足逻辑约束与人类偏好。

Conclusion: CALM展示了在多模态环境中结合逻辑结构与神经处理的潜力，为需要精确推理与多模态信息处理的下一代AI系统奠定基础。

Abstract: In this work, we introduce Contextual Analog Logic with Multimodality (CALM).
CALM unites symbolic reasoning with neural generation, enabling systems to make
context-sensitive decisions grounded in real-world multi-modal data.
  Background: Classic bivalent logic systems cannot capture the nuance of human
decision-making. They also require human grounding in multi-modal environments,
which can be ad-hoc, rigid, and brittle. Neural networks are good at extracting
rich contextual information from multi-modal data, but lack interpretable
structures for reasoning.
  Objectives: CALM aims to bridge the gap between logic and neural perception,
creating an analog logic that can reason over multi-modal inputs. Without this
integration, AI systems remain either brittle or unstructured, unable to
generalize robustly to real-world tasks. In CALM, symbolic predicates evaluate
to analog truth values computed by neural networks and constrained search.
  Methods: CALM represents each predicate using a domain tree, which
iteratively refines its analog truth value when the contextual groundings of
its entities are determined. The iterative refinement is predicted by neural
networks capable of capturing multi-modal information and is filtered through a
symbolic reasoning module to ensure constraint satisfaction.
  Results: In fill-in-the-blank object placement tasks, CALM achieved 92.2%
accuracy, outperforming classical logic (86.3%) and LLM (59.4%) baselines. It
also demonstrated spatial heatmap generation aligned with logical constraints
and delicate human preferences, as shown by a human study.
  Conclusions: CALM demonstrates the potential to reason with logic structure
while aligning with preferences in multi-modal environments. It lays the
foundation for next-gen AI systems that require the precision and
interpretation of logic and the multimodal information processing of neural
networks.

</details>


### [72] [MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2506.14990)
*Tristan Tomilin,Luka van den Boogaard,Samuel Garcin,Bram Grooten,Meng Fang,Mykola Pechenizkiy*

Main category: cs.AI

TL;DR: 本文介绍了首个专为持续多智能体强化学习（CMARL）设计的基准测试MEAL，通过JAX实现GPU加速，解决了现有基准测试在CPU上运行导致的性能瓶颈问题。实验表明，简单结合现有CL和MARL方法在复杂场景中表现不佳，研究还识别了CMARL关键架构与算法特征。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习研究中，持续学习（CL）与多智能体协作的交叉领域缺乏专用基准测试，现有基准因CPU运行导致计算瓶颈，限制了任务序列长度。MEAL旨在填补这一空白并提升实验效率。

Method: 提出MEAL基准测试，利用JAX框架实现GPU加速，支持在普通台式机上数小时内完成100个任务的持续学习序列。通过系统实验对比现有CL与MARL方法的组合效果，并进行消融研究。

Result: 实验显示：1) 简单结合流行CL和MARL方法在简单环境中表现良好；2) 该方法在需要持续协调与适应的复杂场景中失效；3) 消融研究明确了CMARL的关键架构与算法要素。

Conclusion: MEAL作为首个CMARL专用基准，通过GPU加速显著提升实验效率。研究表明现有方法在复杂多智能体持续学习中的局限性，并为未来CMARL算法设计提供了关键洞见。

Abstract: Benchmarks play a crucial role in the development and analysis of
reinforcement learning (RL) algorithms, with environment availability strongly
impacting research. One particularly underexplored intersection is continual
learning (CL) in cooperative multi-agent settings. To remedy this, we introduce
MEAL (Multi-agent Environments for Adaptive Learning), the first benchmark
tailored for continual multi-agent reinforcement learning (CMARL). Existing CL
benchmarks run environments on the CPU, leading to computational bottlenecks
and limiting the length of task sequences. MEAL leverages JAX for GPU
acceleration, enabling continual learning across sequences of 100 tasks on a
standard desktop PC in a few hours. We show that naively combining popular CL
and MARL methods yields strong performance on simple environments, but fails to
scale to more complex settings requiring sustained coordination and adaptation.
Our ablation study identifies architectural and algorithmic features critical
for CMARL on MEAL.

</details>


### [73] [Truncated Proximal Policy Optimization](https://arxiv.org/abs/2506.15050)
*Tiantian Fan,Lingjun Liu,Yu Yue,Jiaze Chen,Chengyi Wang,Qiying Yu,Chi Zhang,Zhiqi Lin,Ruofei Zhu,Yufeng Yuan,Xiaochen Zuo,Bole Ma,Mofan Zhang,Gaohong Liu,Ru Zhang,Haotian Zhou,Cong Xie,Ruidong Zhu,Zhi Zhang,Xin Liu,Mingxuan Wang,Lin Yan,Yonghui Wu*

Main category: cs.AI

TL;DR: 本文提出了一种名为截断近端策略优化（T-PPO）的新方法，旨在提升大型语言模型（LLM）在推理任务中的训练效率。通过优化策略更新和限制生成长度，T-PPO显著减少了训练时间，同时保持了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的近端策略优化（PPO）方法在训练大型语言模型时效率低下，尤其是在生成长文本时，硬件利用率低且等待时间较长。这促使研究者开发更高效的训练方法。

Method: T-PPO通过引入扩展广义优势估计（EGAE）从不完整响应中估计优势，并设计了一种计算优化机制，允许策略模型和价值模型独立优化，从而减少冗余计算。

Result: 实验结果表明，T-PPO在AIME 2024任务中，使用32B基础模型将训练效率提升了2.5倍，且性能优于现有方法。

Conclusion: T-PPO通过优化策略更新和生成长度限制，显著提升了大型语言模型的训练效率，同时保持了其推理能力，为未来的模型训练提供了新的解决方案。

Abstract: Recently, test-time scaling Large Language Models (LLMs) have demonstrated
exceptional reasoning capabilities across scientific and professional tasks by
generating long chains-of-thought (CoT). As a crucial component for developing
these reasoning models, reinforcement learning (RL), exemplified by Proximal
Policy Optimization (PPO) and its variants, allows models to learn through
trial and error. However, PPO can be time-consuming due to its inherent
on-policy nature, which is further exacerbated by increasing response lengths.
In this work, we propose Truncated Proximal Policy Optimization (T-PPO), a
novel extension to PPO that improves training efficiency by streamlining policy
update and length-restricted response generation. T-PPO mitigates the issue of
low hardware utilization, an inherent drawback of fully synchronized
long-generation procedures, where resources often sit idle during the waiting
periods for complete rollouts. Our contributions are two-folds. First, we
propose Extended Generalized Advantage Estimation (EGAE) for advantage
estimation derived from incomplete responses while maintaining the integrity of
policy learning. Second, we devise a computationally optimized mechanism that
allows for the independent optimization of the policy and value models. By
selectively filtering prompt and truncated tokens, this mechanism reduces
redundant computations and accelerates the training process without sacrificing
convergence performance. We demonstrate the effectiveness and efficacy of T-PPO
on AIME 2024 with a 32B base model. The experimental results show that T-PPO
improves the training efficiency of reasoning LLMs by up to 2.5x and
outperforms its existing competitors.

</details>


### [74] [HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges](https://arxiv.org/abs/2506.15196)
*Xianliang Yang,Ling Zhang,Haolong Qian,Lei Song,Jiang Bian*

Main category: cs.AI

TL;DR: 本文提出HeurAgenix框架，利用大语言模型（LLM）实现两阶段超启发式算法设计，通过演化策略和动态选择机制解决组合优化问题，性能超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统启发式算法设计依赖人工经验且难以泛化，HeurAgenix旨在通过LLM的感知能力自动生成和选择启发式策略，提升组合优化问题的求解效率。

Method: 1) 启发式演化阶段：LLM对比种子解与高质量解，提取可重用策略；2) 动态选择阶段：基于LLM感知能力或轻量级模型实时选择最优启发式；3) 双奖励机制微调选择器，缓解标注噪声问题。

Result: 在标准测试集上，HeurAgenix不仅优于现有LLM超启发式方法，且达到或超越专业求解器的性能。代码已开源。

Conclusion: HeurAgenix证明了LLM在自动化设计启发式算法中的潜力，其两阶段框架与动态选择机制为组合优化提供了新范式。

Abstract: Heuristic algorithms play a vital role in solving combinatorial optimization
(CO) problems, yet traditional designs depend heavily on manual expertise and
struggle to generalize across diverse instances. We introduce
\textbf{HeurAgenix}, a two-stage hyper-heuristic framework powered by large
language models (LLMs) that first evolves heuristics and then selects among
them automatically. In the heuristic evolution phase, HeurAgenix leverages an
LLM to compare seed heuristic solutions with higher-quality solutions and
extract reusable evolution strategies. During problem solving, it dynamically
picks the most promising heuristic for each problem state, guided by the LLM's
perception ability. For flexibility, this selector can be either a
state-of-the-art LLM or a fine-tuned lightweight model with lower inference
cost. To mitigate the scarcity of reliable supervision caused by CO complexity,
we fine-tune the lightweight heuristic selector with a dual-reward mechanism
that jointly exploits singals from selection preferences and state perception,
enabling robust selection under noisy annotations. Extensive experiments on
canonical benchmarks show that HeurAgenix not only outperforms existing
LLM-based hyper-heuristics but also matches or exceeds specialized solvers.
Code is available at https://github.com/microsoft/HeurAgenix.

</details>


### [75] [Multi-Agent Reinforcement Learning for Autonomous Multi-Satellite Earth Observation: A Realistic Case Study](https://arxiv.org/abs/2506.15207)
*Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Jimmy Cao,Ryszard Kowalczyk*

Main category: cs.AI

TL;DR: 本文探讨了利用强化学习（RL）和多智能体强化学习（MARL）解决低地球轨道（LEO）卫星群在自主地球观测任务中的协调问题，通过模拟环境验证了多种MARL算法的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道卫星数量的激增，地球观测任务面临实时决策和多卫星协调的挑战，传统优化方法难以应对，因此需要引入RL和MARL技术。

Method: 研究通过建立单卫星操作模型并扩展至多卫星星座，利用MARL框架（如PPO、IPPO、MAPPO和HAPPO）解决能源、数据存储限制及部分可观测性下的分散协调问题。

Result: 实验结果表明，MARL能有效平衡成像与资源管理，并解决多卫星协调中的非平稳性和奖励依赖性问题。

Conclusion: 本研究为自主卫星操作提供了理论基础，并为分散式地球观测任务中的策略学习改进提供了实用指南。

Abstract: The exponential growth of Low Earth Orbit (LEO) satellites has revolutionised
Earth Observation (EO) missions, addressing challenges in climate monitoring,
disaster management, and more. However, autonomous coordination in
multi-satellite systems remains a fundamental challenge. Traditional
optimisation approaches struggle to handle the real-time decision-making
demands of dynamic EO missions, necessitating the use of Reinforcement Learning
(RL) and Multi-Agent Reinforcement Learning (MARL). In this paper, we
investigate RL-based autonomous EO mission planning by modelling
single-satellite operations and extending to multi-satellite constellations
using MARL frameworks. We address key challenges, including energy and data
storage limitations, uncertainties in satellite observations, and the
complexities of decentralised coordination under partial observability. By
leveraging a near-realistic satellite simulation environment, we evaluate the
training stability and performance of state-of-the-art MARL algorithms,
including PPO, IPPO, MAPPO, and HAPPO. Our results demonstrate that MARL can
effectively balance imaging and resource management while addressing
non-stationarity and reward interdependency in multi-satellite coordination.
The insights gained from this study provide a foundation for autonomous
satellite operations, offering practical guidelines for improving policy
learning in decentralised EO missions.

</details>


### [76] [Joint Computation Offloading and Resource Allocation for Uncertain Maritime MEC via Cooperation of UAVs and Vessels](https://arxiv.org/abs/2506.15225)
*Jiahao You,Ziye Jia,Chao Dong,Qihui Wu,Zhu Han*

Main category: cs.AI

TL;DR: 本文提出了一种基于无人机和船舶协作的海事边缘计算框架，用于解决海事物联网中不确定任务的计算卸载和资源分配问题，并通过异构智能体软演员-评论家算法优化执行时间。


<details>
  <summary>Details</summary>
Motivation: 海事物联网(MIoT)的计算需求快速增长，但不确定任务导致计算卸载和资源分配效率低下，需通过无人机(UAV)和船舶协作的多接入边缘计算(MEC)框架来解决。

Method: 提出协作MEC框架，利用Lyapunov优化处理任务不确定性和资源变化，将长期约束转化为短期约束，并通过马尔可夫博弈建模异构资源问题，设计异构智能体软演员-评论家算法求解。

Result: 仿真实验验证了所提框架在优化计算卸载和资源分配方面的有效性，显著降低了总执行时间。

Conclusion: 该研究为海事物联网中的不确定任务提供了高效的计算卸载和资源分配解决方案，无人机与船舶的协作框架具有实际应用潜力。

Abstract: The computation demands from the maritime Internet of Things (MIoT) increase
rapidly in recent years, and the unmanned aerial vehicles (UAVs) and vessels
based multi-access edge computing (MEC) can fulfill these MIoT requirements.
However, the uncertain maritime tasks present significant challenges of
inefficient computation offloading and resource allocation. In this paper, we
focus on the maritime computation offloading and resource allocation through
the cooperation of UAVs and vessels, with consideration of uncertain tasks.
Specifically, we propose a cooperative MEC framework for computation offloading
and resource allocation, including MIoT devices, UAVs and vessels. Then, we
formulate the optimization problem to minimize the total execution time. As for
the uncertain MIoT tasks, we leverage Lyapunov optimization to tackle the
unpredictable task arrivals and varying computational resource availability. By
converting the long-term constraints into short-term constraints, we obtain a
set of small-scale optimization problems. Further, considering the
heterogeneity of actions and resources of UAVs and vessels, we reformulate the
small-scale optimization problem into a Markov game (MG). Moreover, a
heterogeneous-agent soft actor-critic is proposed to sequentially update
various neural networks and effectively solve the MG problem. Finally,
simulations are conducted to verify the effectiveness in addressing
computational offloading and resource allocation.

</details>


### [77] [Efficient and Generalizable Environmental Understanding for Visual Navigation](https://arxiv.org/abs/2506.15377)
*Ruoyu Wang,Xinshu Li,Chen Wang,Lina Yao*

Main category: cs.AI

TL;DR: 本文提出了一种基于因果关系的视觉导航方法（CAN），通过引入因果理解模块提升智能体对环境的结构化理解能力，实验证明该方法在多种任务和仿真环境中均优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉导航方法通常同时处理所有历史观测数据，忽略了数据内部的关联结构，可能限制任务性能的进一步提升。本文从因果关系的角度分析了导航任务的特性，旨在解决这一局限性。

Method: 提出Causality-Aware Navigation（CAN）框架，包含一个因果理解模块（Causal Understanding Module），用于增强智能体对环境的结构化理解能力。该方法无需额外计算开销，可适用于强化学习和监督学习场景。

Result: 实验表明，CAN在多种任务和仿真环境中均显著优于基线方法。消融研究证实，性能提升主要归功于因果理解模块的有效性。

Conclusion: 通过引入因果关系的视角，CAN框架成功提升了视觉导航任务的性能，其因果理解模块具有通用性，可广泛应用于不同学习范式。

Abstract: Visual Navigation is a core task in Embodied AI, enabling agents to navigate
complex environments toward given objectives. Across diverse settings within
Navigation tasks, many necessitate the modelling of sequential data accumulated
from preceding time steps. While existing methods perform well, they typically
process all historical observations simultaneously, overlooking the internal
association structure within the data, which may limit the potential for
further improvements in task performance. We address this by examining the
unique characteristics of Navigation tasks through the lens of causality,
introducing a causal framework to highlight the limitations of conventional
sequential methods. Leveraging this insight, we propose Causality-Aware
Navigation (CAN), which incorporates a Causal Understanding Module to enhance
the agent's environmental understanding capability. Empirical evaluations show
that our approach consistently outperforms baselines across various tasks and
simulation environments. Extensive ablations studies attribute these gains to
the Causal Understanding Module, which generalizes effectively in both
Reinforcement and Supervised Learning settings without computational overhead.

</details>


### [78] [Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents](https://arxiv.org/abs/2506.15567)
*Aline Dobrovsky,Konstantin Schekotihin,Christian Burmer*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型（LLM）的规划代理（LPA），用于辅助故障分析工程师处理复杂案例，通过整合LLM与外部工具实现自动化查询处理和报告生成。


<details>
  <summary>Details</summary>
Motivation: 故障分析（FA）过程复杂且知识密集，现有AI模型虽能自动化部分任务，但缺乏有效协同机制。研究旨在开发智能代理以整合多模型功能，提升FA流程效率。

Method: 设计LPA代理，结合大语言模型的规划能力和外部工具调用，实现自主处理复杂查询、检索外部数据及生成可读响应。

Result: 评估表明LPA在支持FA任务时具备操作有效性和可靠性，能无缝集成于现有分析流程。

Conclusion: LPA为FA实验室提供了可扩展的AI协同解决方案，未来可进一步优化多模型工作流编排。

Abstract: Failure Analysis (FA) is a highly intricate and knowledge-intensive process.
The integration of AI components within the computational infrastructure of FA
labs has the potential to automate a variety of tasks, including the detection
of non-conformities in images, the retrieval of analogous cases from diverse
data sources, and the generation of reports from annotated images. However, as
the number of deployed AI models increases, the challenge lies in orchestrating
these components into cohesive and efficient workflows that seamlessly
integrate with the FA process.
  This paper investigates the design and implementation of a Large Language
Model (LLM)-based Planning Agent (LPA) to assist FA engineers in solving their
analysis cases. The LPA integrates LLMs with advanced planning capabilities and
external tool utilization, enabling autonomous processing of complex queries,
retrieval of relevant data from external systems, and generation of
human-readable responses. Evaluation results demonstrate the agent's
operational effectiveness and reliability in supporting FA tasks.

</details>


### [79] [The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games](https://arxiv.org/abs/2506.15624)
*Lyle Goodyear,Rachel Guo,Ramesh Johari*

Main category: cs.AI

TL;DR: 本文提出了一个统一框架，用于在重复多智能体游戏中系统构建大语言模型（LLM）智能体的自然语言状态表示，并通过自私路由游戏验证了状态表示对智能体行为的关键影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLM智能体在游戏中的历史编码采用临时方法，这不仅掩盖了状态表示对行为的影响，还限制了研究间的可比性。本文旨在填补这些空白。

Method: 框架从三个维度描述状态表示方法：动作信息量（捕捉已执行动作的程度）、奖励信息量（描述获得奖励的程度）和提示风格（自然语言压缩程度）。将该框架应用于动态自私路由游戏进行验证。

Result: 研究发现：（1）提供历史摘要而非完整记录；（2）提供遗憾信息而非原始收益；（3）限制他人动作信息的状态表示，能使LLM智能体行为更接近博弈论均衡预测且游戏过程更稳定。

Conclusion: 自然语言状态表示的构建方式显著影响LLM智能体的博弈行为，特定类型的表示能有效提升与理论预测的一致性及游戏稳定性，为未来研究提供了系统性指导。

Abstract: Large Language Models (LLMs) have shown promise as decision-makers in dynamic
settings, but their stateless nature necessitates creating a natural language
representation of history. We present a unifying framework for systematically
constructing natural language "state" representations for prompting LLM agents
in repeated multi-agent games. Previous work on games with LLM agents has taken
an ad hoc approach to encoding game history, which not only obscures the impact
of state representation on agents' behavior, but also limits comparability
between studies. Our framework addresses these gaps by characterizing methods
of state representation along three axes: action informativeness (i.e., the
extent to which the state representation captures actions played); reward
informativeness (i.e., the extent to which the state representation describes
rewards obtained); and prompting style (or natural language compression, i.e.,
the extent to which the full text history is summarized).
  We apply this framework to a dynamic selfish routing game, chosen because it
admits a simple equilibrium both in theory and in human subject experiments
\cite{rapoport_choice_2009}. Despite the game's relative simplicity, we find
that there are key dependencies of LLM agent behavior on the natural language
state representation. In particular, we observe that representations which
provide agents with (1) summarized, rather than complete, natural language
representations of past history; (2) information about regrets, rather than raw
payoffs; and (3) limited information about others' actions lead to behavior
that more closely matches game theoretic equilibrium predictions, and with more
stable game play by the agents. By contrast, other representations can exhibit
either large deviations from equilibrium, higher variation in dynamic game play
over time, or both.

</details>


### [80] [The AI Policy Module: Developing Computer Science Student Competency in AI Ethics and Policy](https://arxiv.org/abs/2506.15639)
*James Weichert,Daniel Dunlap,Mohammed Farghally,Hoda Eldardiry*

Main category: cs.AI

TL;DR: 随着人工智能（AI）在个人和职业场景中的深入应用，AI伦理及政策治理日益重要。研究团队开发了AI政策模块，将其引入计算机科学课程，以培养学生将伦理原则转化为实践的能力。通过试点评估，学生表现出对AI伦理影响的关注增加，并对参与AI监管讨论更有信心。


<details>
  <summary>Details</summary>
Motivation: 当前高等教育计算机课程未能充分培养学生将抽象伦理原则和规范政策融入AI系统设计与开发的能力。研究认为，熟悉AI政策环境及伦理实践转化能力将成为AI工程师的重要职责。

Method: 研究团队开发了AI政策模块2.0，并在计算机科学课程中试点。通过课前课后问卷调查，评估学生对AI伦理和政策的态度变化，并设计了“AI监管”技术作业作为探索工具。

Result: 试点结果显示，学生在完成模块后对AI技术伦理影响的关注度提升，同时对自己参与AI监管讨论的能力信心增强。AI监管作业被证明是探索AI对齐限制及政策在解决伦理挑战中作用的有效工具。

Conclusion: AI政策模块成功提升了学生对AI伦理与政策的认知与实践能力，证明了将政策讨论纳入计算机科学课程的必要性和有效性。未来需进一步推广此类模块，以培养更具社会责任感的AI工程师。

Abstract: As artificial intelligence (AI) further embeds itself into many settings
across personal and professional contexts, increasing attention must be paid
not only to AI ethics, but also to the governance and regulation of AI
technologies through AI policy. However, the prevailing post-secondary
computing curriculum is currently ill-equipped to prepare future AI
practitioners to confront increasing demands to implement abstract ethical
principles and normative policy preferences into the design and development of
AI systems. We believe that familiarity with the 'AI policy landscape' and the
ability to translate ethical principles to practices will in the future
constitute an important responsibility for even the most technically-focused AI
engineers.
  Toward preparing current computer science (CS) students for these new
expectations, we developed an AI Policy Module to introduce discussions of AI
policy into the CS curriculum. Building on a successful pilot in fall 2024, in
this innovative practice full paper we present an updated and expanded version
of the module, including a technical assignment on "AI regulation". We present
the findings from our pilot of the AI Policy Module 2.0, evaluating student
attitudes towards AI ethics and policy through pre- and post-module surveys.
Following the module, students reported increased concern about the ethical
impacts of AI technologies while also expressing greater confidence in their
abilities to engage in discussions about AI regulation. Finally, we highlight
the AI Regulation Assignment as an effective and engaging tool for exploring
the limits of AI alignment and emphasizing the role of 'policy' in addressing
ethical challenges.

</details>


### [81] [Exploring and Exploiting the Inherent Efficiency within Large Reasoning Models for Self-Guided Efficiency Enhancement](https://arxiv.org/abs/2506.15647)
*Weixiang Zhao,Jiahe Guo,Yang Deng,Xingyu Sui,Yulin Hu,Yanyan Zhao,Wanxiang Che,Bing Qin,Tat-Seng Chua,Ting Liu*

Main category: cs.AI

TL;DR: 大型推理模型（LRMs）在复杂问题解决中表现出过度思考现象，导致效率低下。研究发现模型本身具备简洁推理能力，并提出两种轻量级方法提升效率：效率导向技术和自奖励效率强化学习框架，实验证明这些方法显著减少推理长度同时保持或提升任务性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型（LRMs）通过模拟人类审慎思维增强了复杂问题解决能力，但其过度思考（生成冗余内容）导致效率降低和推理成本增加。研究旨在探索这种低效的表征和行为根源，并开发方法提升模型效率。

Method: 提出两种轻量级方法：1）效率导向技术（Efficiency Steering），一种无需训练的激活导向技术，通过模型表示空间中的单一方向调节推理行为；2）自奖励效率强化学习（Self-Rewarded Efficiency RL），通过奖励简洁正确的解决方案动态平衡任务准确性和简洁性。

Result: 在多个数学推理基准测试中对七种LRM主干模型的实验表明，所提方法显著减少了推理长度，同时保持或改进了任务性能，验证了通过引导模型内在能力可提升推理效率。

Conclusion: 研究表明，通过利用和引导现有模型的固有能力，可以以自引导方式提高推理效率，为未来高效LRM设计提供了重要启示。

Abstract: Recent advancements in large reasoning models (LRMs) have significantly
enhanced language models' capabilities in complex problem-solving by emulating
human-like deliberative thinking. However, these models often exhibit
overthinking (i.e., the generation of unnecessarily verbose and redundant
content), which hinders efficiency and inflates inference cost. In this work,
we explore the representational and behavioral origins of this inefficiency,
revealing that LRMs inherently possess the capacity for more concise reasoning.
Empirical analyses show that correct reasoning paths vary significantly in
length, and the shortest correct responses often suffice, indicating untapped
efficiency potential. Exploiting these findings, we propose two lightweight
methods to enhance LRM efficiency. First, we introduce Efficiency Steering, a
training-free activation steering technique that modulates reasoning behavior
via a single direction in the model's representation space. Second, we develop
Self-Rewarded Efficiency RL, a reinforcement learning framework that
dynamically balances task accuracy and brevity by rewarding concise correct
solutions. Extensive experiments on seven LRM backbones across multiple
mathematical reasoning benchmarks demonstrate that our methods significantly
reduce reasoning length while preserving or improving task performance. Our
results highlight that reasoning efficiency can be improved by leveraging and
guiding the intrinsic capabilities of existing models in a self-guided manner.

</details>


### [82] [SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence](https://arxiv.org/abs/2506.15672)
*Yao Zhang,Chenyang Lin,Shijie Tang,Haokun Chen,Shijie Zhou,Yunpu Ma,Volker Tresp*

Main category: cs.AI

TL;DR: 本文提出SwarmAgentic框架，实现全自动代理系统生成，通过语言驱动探索联合优化代理功能与协作，在六项现实任务中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统生成框架缺乏完全自主性，无法实现从零生成、自我优化及协作，限制了适应性与可扩展性。

Method: 受粒子群优化(PSO)启发，框架维护候选系统种群并通过反馈引导更新进行演化，将代理功能与协作作为相互依赖组件进行联合优化。

Result: 在仅给定任务描述和目标函数条件下，SwarmAgentic相对ADAS基准在TravelPlanner任务上取得+261.8%的性能提升。

Conclusion: 该框架将群体智能与全自动多代理生成相结合，为可扩展自主代理系统设计迈出重要一步，代码已开源。

Abstract: The rapid progress of Large Language Models has advanced agentic systems in
decision-making, coordination, and task execution. Yet, existing agentic system
generation frameworks lack full autonomy, missing from-scratch agent
generation, self-optimizing agent functionality, and collaboration, limiting
adaptability and scalability. We propose SwarmAgentic, a framework for fully
automated agentic system generation that constructs agentic systems from
scratch and jointly optimizes agent functionality and collaboration as
interdependent components through language-driven exploration. To enable
efficient search over system-level structures, SwarmAgentic maintains a
population of candidate systems and evolves them via feedback-guided updates,
drawing inspiration from Particle Swarm Optimization (PSO). We evaluate our
method on six real-world, open-ended, and exploratory tasks involving
high-level planning, system-level coordination, and creative reasoning. Given
only a task description and an objective function, SwarmAgentic outperforms all
baselines, achieving a +261.8% relative improvement over ADAS on the
TravelPlanner benchmark, highlighting the effectiveness of full automation in
structurally unconstrained tasks. This framework marks a significant step
toward scalable and autonomous agentic system design, bridging swarm
intelligence with fully automated system multi-agent generation. Our code is
publicly released at https://yaoz720.github.io/SwarmAgentic/.

</details>


### [83] [Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence](https://arxiv.org/abs/2506.15677)
*Yining Hong,Rui Sun,Bingxuan Li,Xingcheng Yao,Maxine Wu,Alexander Chien,Da Yin,Ying Nian Wu,Zhecan James Wang,Kai-Wei Chang*

Main category: cs.AI

TL;DR: 本文提出‘具身网络智能体’新范式，通过整合3D仿真环境与网络接口构建统一平台，并发布多领域跨物理-数字协同推理基准测试，揭示了当前AI系统与人类能力的显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有AI智能体在物理交互与网络推理间存在割裂，无法完成需跨领域协同的任务（如在线食谱烹饪、动态地图导航）。研究旨在弥合这一鸿沟。

Method: 开发‘具身网络智能体任务环境’仿真平台，整合真实3D场景与功能化网络接口；构建包含烹饪/导航/购物等任务的基准测试体系。

Result: 实验表明顶尖AI系统在跨领域任务中表现显著落后于人类，平台代码及数据已开源（https://embodied-web-agent.github.io/）。

Conclusion: 该研究为具身认知与网络知识的交叉领域设立评估标准，同时揭示了该方向的技术挑战与发展机遇。

Abstract: AI agents today are mostly siloed - they either retrieve and reason over vast
amount of digital information and knowledge obtained online; or interact with
the physical world through embodied perception, planning and action - but
rarely both. This separation limits their ability to solve tasks that require
integrated physical and digital intelligence, such as cooking from online
recipes, navigating with dynamic map data, or interpreting real-world landmarks
using web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI
agents that fluidly bridge embodiment and web-scale reasoning. To
operationalize this concept, we first develop the Embodied Web Agents task
environments, a unified simulation platform that tightly integrates realistic
3D indoor and outdoor environments with functional web interfaces. Building
upon this platform, we construct and release the Embodied Web Agents Benchmark,
which encompasses a diverse suite of tasks including cooking, navigation,
shopping, tourism, and geolocation - all requiring coordinated reasoning across
physical and digital realms for systematic assessment of cross-domain
intelligence. Experimental results reveal significant performance gaps between
state-of-the-art AI systems and human capabilities, establishing both
challenges and opportunities at the intersection of embodied cognition and
web-scale knowledge access. All datasets, codes and websites are publicly
available at our project page https://embodied-web-agent.github.io/.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [84] [A survey of Chernoff and Hoeffding bounds](https://arxiv.org/abs/2506.15612)
*Alexandros V. Gerbessiotis*

Main category: cs.DM

TL;DR: 本文是一篇综述性论文，讨论了Chernoff和Hoeffding开创性论文中的原始界限，并涵盖了多种形式的衍生界限。


<details>
  <summary>Details</summary>
Motivation: 旨在为感兴趣的研究者提供一个参考界限的全面资源库。

Method: 论文通过提供完整的证明，系统地整理和分析了各种界限及其衍生形式。

Result: 论文汇总了多种形式的界限，包括原始界限及其衍生形式，为研究者提供了丰富的参考资料。

Conclusion: 该综述为概率论和统计学领域的研究者提供了一个全面的界限参考库，有助于进一步的理论和应用研究。

Abstract: This is a survey paper that discusses the original bounds of the seminal
papers by Chernoff and Hoeffding. Moreover, it includes a variety of derivative
bounds in a variety of forms. Complete proofs are provided as needed. The
intent is to provide a repository of reference bounds for the interested
researcher.

</details>
