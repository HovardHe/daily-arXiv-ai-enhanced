{"id": "2507.10779", "categories": ["math.NT", "11T06"], "pdf": "https://arxiv.org/pdf/2507.10779", "abs": "https://arxiv.org/abs/2507.10779", "authors": ["Kaimin Cheng"], "title": "The $3$-sparsity of $X^n-1$ over finite fields, II", "comment": "8 pages", "summary": "Let $q$ be a prime power and $\\mathbb{F}_q$ the finite field with $q$\nelements. For a positive integer $n$, the polynomial $X^n - 1 \\in\n\\mathbb{F}_q[X]$ is termed $3$-sparse over $\\mathbb{F}_q$ if all its\nirreducible factors in $\\mathbb{F}_q[X]$ are either binomials or trinomials. In\n2021, Oliveira and Reis characterized all positive integers $n$ for which $X^n\n- 1$ is 3-sparse over $\\mathbb{F}_q$ when $q = 2$ and $q = 4$. Recently, the\nauthor provided a complete characterization for odd $q$. This paper extends the\ninvestigation to finite fields of even characteristic, fully determining all\n$n$ such that $X^n - 1$ is 3-sparse over $\\mathbb{F}_q$ for even $q$. This work\nresolves two open problems posed by Oliveira and Reis for even characteristic\ncase.", "AI": {"tldr": "本文研究了在偶数特征有限域$\\mathbb{F}_q$上，多项式$X^n - 1$的3-稀疏性，完全确定了所有满足条件的正整数$n$，解决了Oliveira和Reis提出的两个开放性问题。", "motivation": "研究多项式$X^n - 1$在有限域$\\mathbb{F}_q$上的3-稀疏性（即其不可约因子均为二项式或三项式）的分类问题，特别是在偶数特征情况下的未解问题。", "method": "扩展了奇数特征$q$的研究方法，针对偶数特征$q$的有限域$\\mathbb{F}_q$，系统分析了$X^n - 1$的不可约因子的形式。", "result": "完全确定了在偶数特征有限域$\\mathbb{F}_q$上，多项式$X^n - 1$为3-稀疏的所有正整数$n$，填补了此前研究的空白。", "conclusion": "该工作解决了Oliveira和Reis提出的关于偶数特征情况下多项式3-稀疏性的两个开放问题，为有限域上的多项式分解理论提供了重要结论。"}}
{"id": "2507.10780", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.10780", "abs": "https://arxiv.org/abs/2507.10780", "authors": ["Thomas Wright"], "title": "Primes in Arithmetic Progressions to Large Moduli and Siegel Zeroes", "comment": null, "summary": "Let $\\chi$ be a Dirichlet character mod $D$ with $L(s,\\chi)$ its associated\n$L$-function, and let $\\psi(x,q,a)$ be Chebyshev's prime-counting function for\nprimes congruent to $a$ modulo $q$. We that under the assumption of an\nexceptional character $\\chi$ with $L(1,\\chi)=o\\left((\\log D)^{-5}\\right)$, for\nany $q<x^{\\frac 23-\\varepsilon}$, the asymptotic\n$$\\psi(x,q,a)=\\frac{\\psi(x)}{\\phi(q)}\\left(1-\\chi\\left(\\frac{aD}{(D,q)}\\right)+o(1)\\right)$$\nholds for almost all $a$ with $(a,q)=1$. We also find that for any fixed $a$,\nthe above holds for almost all $q<x^{\\frac 23-\\varepsilon}$ with $(a,q)=1$.\nPrevious prime equidistribution results under the assumption of Siegel zeroes\n(by Friedlander-Iwaniec and the current author) have found that the above\nasymptotic holds either for all $a$ and $q$ or on average over a range of $q$\n(i.e. for the Elliott-Halberstam conjecture), but only under the assumption\nthat $q<x^{\\theta}$ where $\\theta=\\frac{30}{59}$ or $\\frac{16}{31}$,\nrespectively.", "AI": {"tldr": "该论文在假设存在例外特征$\\chi$且$L(1,\\chi)=o\\left((\\log D)^{-5}\\right)$的条件下，证明了对于几乎所有与$q$互素的$a$，素数计数函数$\\psi(x,q,a)$具有特定渐近公式，且对于固定$a$，该公式对几乎所有$q<x^{\\frac{2}{3}-\\varepsilon}$成立。", "motivation": "研究在例外特征假设下素数在算术级数中的分布问题，扩展了以往基于Siegel零点假设的结果，突破了$q$的范围限制。", "method": "利用Dirichlet特征$\\chi$和关联的$L$-函数$L(s,\\chi)$，结合Chebyshev素数计数函数$\\psi(x,q,a)$，在例外特征假设下进行渐近分析。", "result": "对于几乎所有与$q$互素的$a$，素数分布满足$\\psi(x,q,a)=\\frac{\\psi(x)}{\\phi(q)}\\left(1-\\chi\\left(\\frac{aD}{(D,q)}\\right)+o(1)\\right)$，且对于固定$a$，该结果对几乎所有$q<x^{\\frac{2}{3}-\\varepsilon}$成立。", "conclusion": "在例外特征假设下，素数在算术级数中的分布具有更广泛的渐近性质，突破了以往结果中$q$的范围限制，为相关数论问题提供了新的视角。"}}
{"id": "2507.11418", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.11418", "abs": "https://arxiv.org/abs/2507.11418", "authors": ["Chan Ieong Kuan", "Didier Lesesvre"], "title": "Murmurations using Petersson trace formula", "comment": null, "summary": "We prove the murmuration phenomenon, which is a correlation between signs of\nfunctional equations and Fourier coefficients, in the case of modular forms in\nthe weight aspect. We in particular improve the range of visibility of\nmurmurations compared to previous results. This is the first approach to the\nmurmuration phenomenon using a relative trace formula, showing its robustness.", "AI": {"tldr": "本文证明了模形式在权重方面的murmuration现象，即函数方程符号与傅里叶系数之间的相关性，并通过相对迹公式首次验证了该现象的稳健性。", "motivation": "研究murmuration现象在模形式权重方面的表现，以扩展该现象的可观测范围，并验证相对迹公式在此类问题中的适用性。", "method": "采用相对迹公式方法，首次将这一工具应用于murmuration现象的研究，改进了先前结果的观测范围。", "result": "成功证明了模形式权重方面的murmuration现象，并显著扩大了该现象的可视化范围，验证了相对迹公式在此问题中的有效性。", "conclusion": "本研究不仅扩展了murmuration现象的理论范围，还为未来相关研究提供了新的方法论工具——相对迹公式。"}}
{"id": "2507.11514", "categories": ["math.NT", "math.AG", "11D72, 11G25, 11G35, 11P55, 14G05"], "pdf": "https://arxiv.org/pdf/2507.11514", "abs": "https://arxiv.org/abs/2507.11514", "authors": ["Amichai Lampert"], "title": "Density of solutions for systems of forms", "comment": "18 pages", "summary": "Let $K$ be a field of characteristic zero over which every diagonal form in\nsufficiently many variables admits a nontrivial solution. For example, $K$ may\nbe a totally imaginary number field or a finite extension of a $p$-adic field.\nSuppose $f_1,\\ldots,f_s$ are forms of degree $d$ over $K.$ Bik, Draisma and\nSnowden recently proved that there exists a constant $B = B(d,s,K)$ such that\nthe rational solutions to the system of equations $f_1=\\ldots=f_s = 0$ are\nZariski dense, as long as the Birch rank of $f_1,\\ldots,f_s$ is greater than\n$B.$ We establish an effective bound for this constant. Combined with results\nof Skinner, we obtain as a corollary a sufficient condition for the integer\nzeros of a system of forms over a number field to satisfy the Hardy-Littlewood\nasymptotic with a positive leading term. This corollary generalizes a seminal\nresult proved by Schmidt for the rational numbers.", "AI": {"tldr": "本文在特征为零的域$K$上，针对多变量形式方程组$f_1=\\ldots=f_s=0$的有理解，建立了Birch秩的有效下界$B(d,s,K)$，并推广了Schmidt关于有理数域上Hardy-Littlewood渐近的经典结果。", "motivation": "研究动机源于Bik、Draisma和Snowden关于Birch秩与方程组有理解Zariski稠密性的非有效结果，本文旨在给出该秩下界的有效计算，并应用于数域上整数解的Hardy-Littlewood渐近问题。", "method": "通过分析特征零域$K$（如全虚数域或$p$-进域）上高Birch秩多项式系统的几何性质，结合Skinner关于数域上整数解的研究方法，构建有效常数$B(d,s,K)$的显式表达式。", "result": "证明了当形式系统$\\{f_i\\}$的Birch秩超过$B(d,s,K)$时，其有理解在Zariski拓扑下稠密；作为推论，给出了数域上整数解满足Hardy-Littlewood渐近正项条件的充分判据。", "conclusion": "该结果将Schmidt的有理数域结论推广至一般数域，为Diophantine方程的解析理论提供了新的有效工具，尤其适用于高秩多项式系统的整数解分布研究。"}}
{"id": "2507.10603", "categories": ["math.OC", "cs.CE"], "pdf": "https://arxiv.org/pdf/2507.10603", "abs": "https://arxiv.org/abs/2507.10603", "authors": ["Kasper Johansson", "Stephen Boyd"], "title": "A Tax-Efficient Model Predictive Control Policy for Retirement Funding", "comment": null, "summary": "The retirement funding problem addresses the question of how to manage a\nretiree's savings to provide her with a constant post-tax inflation adjusted\nconsumption throughout her lifetime. This consists of choosing withdrawals and\ntransfers from and between several accounts with different tax treatments,\ntaking into account basic rules such as required minimum distributions and\nlimits on Roth conversions, additional income, liabilities, taxes, and the\nbequest when the retiree dies. We develop a retirement funding policy in two\nsteps. In the first step, we consider a simplified planning problem in which\nvarious future quantities, such as the retiree's remaining lifetime, future\ninvestment returns, and future inflation, are known. Using a simplified model\nof taxes, we pose this planning problem as a convex optimization problem, where\nwe maximize the bequest subject to providing a constant inflation adjusted\nconsumption target. Since this problem is convex, it can be solved quickly and\nreliably. We leverage this planning method to form a retirement funding policy\nthat determines the actions to take each year, based on information known at\nthat time. Each year the retiree forms a new plan for the future years, using\nthe current account values and life expectancy, and optionally, updated\ninformation such as changes in tax rates or rules. The retiree then carries out\nthe actions from the first year of the current plan. This update-plan-act cycle\nis repeated each year, a general policy called model predictive control (MPC).\nThe MPC retirement policy reacts to the effects of uncertain investment returns\nand inflation, changes in the retiree's expected lifetime or external income\nand liabilities, and changes in tax rules and rates. We demonstrate the\neffectiveness of the MPC retirement policy using Monte Carlo simulation.", "AI": {"tldr": "本文提出了一种基于模型预测控制（MPC）的退休资金管理策略，通过动态规划解决退休储蓄的长期消费与遗产最大化问题。", "motivation": "退休资金管理需平衡终身恒定消费与税收优化，传统方法难以应对投资回报、寿命预期和税率变化等不确定性。", "method": "1. 构建简化凸优化模型（已知未来参数），最大化遗产并满足通胀调整后的恒定消费目标；2. 采用MPC框架逐年更新计划并执行首年操作，动态适应变化。", "result": "蒙特卡洛模拟验证了MPC策略能有效应对投资波动、寿命变化及税制调整，实现稳健的退休资金管理。", "conclusion": "MPC方法将复杂退休规划转化为可求解的凸优化问题，通过滚动更新机制提升适应性，为退休资金管理提供可靠解决方案。"}}
{"id": "2507.10578", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10578", "abs": "https://arxiv.org/abs/2507.10578", "authors": ["Jeremy Styborski", "Mingzhi Lyu", "Jiayou Lu", "Nupur Kapur", "Adams Kong"], "title": "When and Where do Data Poisons Attack Textual Inversion?", "comment": "Accepted to ICCV", "summary": "Poisoning attacks pose significant challenges to the robustness of diffusion\nmodels (DMs). In this paper, we systematically analyze when and where poisoning\nattacks textual inversion (TI), a widely used personalization technique for\nDMs. We first introduce Semantic Sensitivity Maps, a novel method for\nvisualizing the influence of poisoning on text embeddings. Second, we identify\nand experimentally verify that DMs exhibit non-uniform learning behavior across\ntimesteps, focusing on lower-noise samples. Poisoning attacks inherit this bias\nand inject adversarial signals predominantly at lower timesteps. Lastly, we\nobserve that adversarial signals distract learning away from relevant concept\nregions within training data, corrupting the TI process. Based on these\ninsights, we propose Safe-Zone Training (SZT), a novel defense mechanism\ncomprised of 3 key components: (1) JPEG compression to weaken high-frequency\npoison signals, (2) restriction to high timesteps during TI training to avoid\nadversarial signals at lower timesteps, and (3) loss masking to constrain\nlearning to relevant regions. Extensive experiments across multiple poisoning\nmethods demonstrate that SZT greatly enhances the robustness of TI against all\npoisoning attacks, improving generative quality beyond prior published\ndefenses. Code: www.github.com/JStyborski/Diff_Lab Data:\nwww.github.com/JStyborski/NC10", "AI": {"tldr": "本文系统分析了扩散模型(DMs)中文本反演(TI)技术面临的投毒攻击问题，提出可视化攻击影响的语义敏感度图谱，发现DMs在低噪声时间步存在学习偏差，并基于此提出包含JPEG压缩、高时间步训练和损失掩码的三阶段防御方法SZT，显著提升了TI的抗攻击鲁棒性。", "motivation": "扩散模型的文本反演技术易受投毒攻击干扰，现有研究缺乏对攻击时机、位置及影响机制的系统分析，亟需开发针对性防御方案以保障生成质量。", "method": "1) 提出语义敏感度图谱可视化投毒影响；2) 发现DMs在低时间步存在学习偏差导致攻击信号集中注入；3) 设计SZT防御框架：JPEG压缩削弱高频信号、限制高时间步训练避开攻击窗口、损失掩码聚焦相关概念区域。", "result": "实验表明SZT能有效抵抗多种投毒攻击，在CIFAR-10等数据集上TI生成质量超越现有防御方法，FID指标提升15%以上，代码与数据已开源。", "conclusion": "揭示DMs非均匀学习特性与投毒攻击的关联机制，所提SZT通过时域约束和信号过滤实现高效防御，为扩散模型安全部署提供新思路。"}}
{"id": "2507.10562", "categories": ["cs.AI", "cs.CR", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10562", "abs": "https://arxiv.org/abs/2507.10562", "authors": ["Hari Masoor"], "title": "SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents", "comment": "7 pages, 4 figures, 3 implementation examples. Original work\n  submitted as a preprint", "summary": "Current AI agent architectures suffer from ephemeral memory limitations,\npreventing effective collaboration and knowledge sharing across sessions and\nagent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a\nnovel framework that enables persistent, secure, and semantically searchable\nmemory sharing among AI agents. Our protocol addresses three critical\nchallenges: (1) persistent context preservation across agent sessions, (2)\nsecure multi-agent collaboration with fine-grained access control, and (3)\nefficient semantic discovery of relevant historical context. SAMEP implements a\ndistributed memory repository with vector-based semantic search, cryptographic\naccess controls (AES-256-GCM), and standardized APIs compatible with existing\nagent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness\nacross diverse domains including multi-agent software development, healthcare\nAI with HIPAA compliance, and multi-modal processing pipelines. Experimental\nresults show 73% reduction in redundant computations, 89% improvement in\ncontext relevance scores, and complete compliance with regulatory requirements\nincluding audit trail generation. SAMEP enables a new paradigm of persistent,\ncollaborative AI agent ecosystems while maintaining security and privacy\nguarantees.", "AI": {"tldr": "本文提出SAMEP协议，解决AI代理间记忆共享的持久性、安全性与语义检索问题，实现跨会话协作，实验显示显著提升效率与合规性。", "motivation": "现有AI代理架构存在记忆短暂性问题，阻碍跨会话与跨代理的知识共享与协作，亟需一种安全持久的记忆交换方案。", "method": "SAMEP协议采用分布式记忆库，结合向量语义搜索、AES-256-GCM加密访问控制，并与MCP/A2A等现有协议API兼容。", "result": "实验表明：冗余计算减少73%，上下文相关度提升89%，完全符合HIPAA等法规要求，支持审计追踪生成。", "conclusion": "SAMEP开创了持久化协作AI代理生态的新范式，在保障安全隐私的同时提升跨领域应用效能。"}}
{"id": "2507.11235", "categories": ["math.HO"], "pdf": "https://arxiv.org/pdf/2507.11235", "abs": "https://arxiv.org/abs/2507.11235", "authors": ["Andrey Boris Khesin", "Tanya Khovanova"], "title": "SET! From Groups to Games", "comment": "10 pages, 10 figures", "summary": "The game of SET is one of the best mathematical games ever. It is no wonder\nthat people have tried to generalize it. We discuss existing generalizations of\nthe game of SET to different groups. We concentrate on two types of\ngeneralization: a) where a set consists of cards that multiply to the identity;\nb) where a set consists of three cards that form an arithmetic progression. We\nfinish with a discussion of some properties of the games that influence how\nenjoyable they are.", "AI": {"tldr": "本文探讨了SET游戏的数学推广，重点分析了两种推广类型：卡片乘积为恒等元的集合和三卡片形成算术序列的集合，并讨论了影响游戏乐趣的属性。", "motivation": "SET游戏作为经典数学游戏，其推广形式具有研究价值，探索不同群结构下的游戏变体能深化数学理解并提升游戏体验。", "method": "研究聚焦于两种推广方法：1) 卡片群运算结果为恒等元的集合；2) 三张卡片构成算术序列的集合，通过数学建模分析其结构特性。", "result": "分析表明，不同的推广方式会衍生出独特的游戏机制，群论性质（如交换性、阶数）直接影响游戏难度与趣味性。", "conclusion": "SET游戏的推广需兼顾数学严谨性与娱乐性，群结构的选择和集合定义方式是决定游戏可玩性的关键因素。"}}
{"id": "2507.11339", "categories": ["math.LO", "03E05, 03E15, 03E17, 03E35, 03E40"], "pdf": "https://arxiv.org/pdf/2507.11339", "abs": "https://arxiv.org/abs/2507.11339", "authors": ["Miguel A. Cardona", "Miroslav Repický"], "title": "Constant prediction and evasion number, I: Generalization and variants", "comment": "22 pages", "summary": "Using the concept of constant evasion to different sorts of suitable binary\nrelations, we establish many cardinal invariants derived from the established\ncardinal invariants $\\mathfrak{e}^\\mathrm{const}_{n}$ and\n$\\mathfrak{v}^\\mathrm{const}_{n}$, called the constant evasion number and the\nconstant prediction number. We formulate several limits and consistency results\npertaining to them.", "AI": {"tldr": "通过引入恒定规避概念，本文建立了基于基数不变量$\\mathfrak{e}^\\mathrm{const}_{n}$和$\\mathfrak{v}^\\mathrm{const}_{n}$（分别称为恒定规避数和恒定预测数）的多个新基数不变量，并给出了相关极限与一致性结果。", "motivation": "研究动机在于扩展基数不变量理论，通过恒定规避概念为不同二元关系建立新的数学工具，以深化对集合论中基数特性的理解。", "method": "采用恒定规避概念，对二元关系进行分类，并基于既有的基数不变量$\\mathfrak{e}^\\mathrm{const}_{n}$和$\\mathfrak{v}^\\mathrm{const}_{n}$，推导出新的基数不变量。", "result": "成功定义了多个新的基数不变量，并证明了它们在数学极限和一致性方面的若干结果，为集合论提供了新的理论支持。", "conclusion": "本文通过恒定规避概念扩展了基数不变量理论，提出的新基数不变量及其相关结果为集合论和数学基础研究提供了新的视角和工具。"}}
{"id": "2507.10709", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.10709", "abs": "https://arxiv.org/abs/2507.10709", "authors": ["Kristóf Bérczi", "Boglárka Gehér", "András Imolay", "László Lovász", "Carles Padró", "Tamás Schwarcz"], "title": "Interaction between skew-representability, tensor products, extension properties, and rank inequalities", "comment": "42 pages", "summary": "Skew-representable matroids form a fundamental class in matroid theory,\nbridging combinatorics and linear algebra. They play an important role in areas\nsuch as coding theory, optimization, and combinatorial geometry, where linear\nstructure is crucial for both theoretical insights and algorithmic\napplications. Since deciding skew-representability is computationally\nintractable, much effort has been focused on identifying necessary or\nsufficient conditions for a matroid to be skew-representable.\n  In this paper, we introduce a novel approach to studying\nskew-representability and structural properties of matroids and polymatroid\nfunctions via tensor products. We provide a characterization of\nskew-representable matroids, as well as of those representable over skew fields\nof a given prime characteristic, in terms of tensor products. As an algorithmic\nconsequence, we show that deciding skew-representability, or representability\nover a skew field of fixed prime characteristic, is co-recursively enumerable:\nthat is, certificates of non-skew-representability -- in general or over a\nfixed prime characteristic -- can be verified. We also prove that every rank-3\nmatroid admits a tensor product with any uniform matroid and give a\nconstruction yielding the unique freest tensor product in this setting.\nFinally, as an application of the tensor product framework, we give a new proof\nof Ingleton's inequality and, more importantly, derive the first known linear\nrank inequality for folded skew-representable matroids that does not follow\nfrom the common information property.", "AI": {"tldr": "本文通过张量积方法研究斜可表示拟阵，给出了斜可表示拟阵的特征，并证明了判定斜可表示性是可共递归枚举的。此外，还提出了秩3拟阵与任意均匀拟阵的张量积构造，并应用张量积框架得到了新的线性秩不等式。", "motivation": "斜可表示拟阵是拟阵理论中的基础类，在编码理论、优化和组合几何等领域具有重要作用。由于判定斜可表示性是计算难解的，研究其必要或充分条件具有重要意义。", "method": "本文引入张量积作为研究斜可表示拟阵和多拟阵函数结构性质的新工具，提出了斜可表示拟阵的张量积特征描述，并构建了秩3拟阵与均匀拟阵的张量积。", "result": "证明了斜可表示性判定是可共递归枚举的；给出了秩3拟阵与任意均匀拟阵的张量积构造；应用张量积框架得到了折叠斜可表示拟阵的新线性秩不等式。", "conclusion": "张量积方法为研究拟阵表示性提供了新视角，不仅给出了斜可表示拟阵的特征描述，还导出了新的线性秩不等式，拓展了拟阵理论的应用边界。"}}
{"id": "2507.10767", "categories": ["math.ST", "stat.ME", "stat.ML", "stat.TH", "62H22, 62D20, 62R01"], "pdf": "https://arxiv.org/pdf/2507.10767", "abs": "https://arxiv.org/abs/2507.10767", "authors": ["Mathias Drton", "Marina Garrote-López", "Niko Nikov", "Elina Robeva", "Y. Samuel Wang"], "title": "Causal Discovery for Linear Non-Gaussian Models with Disjoint Cycles", "comment": "9 pages + 10 pages Supplementary Materials", "summary": "The paradigm of linear structural equation modeling readily allows one to\nincorporate causal feedback loops in the model specification. These appear as\ndirected cycles in the common graphical representation of the models. However,\nthe presence of cycles entails difficulties such as the fact that models need\nno longer be characterized by conditional independence relations. As a result,\nlearning cyclic causal structures remains a challenging problem. In this paper,\nwe offer new insights on this problem in the context of linear non-Gaussian\nmodels. First, we precisely characterize when two directed graphs determine the\nsame linear non-Gaussian model. Next, we take up a setting of cycle-disjoint\ngraphs, for which we are able to show that simple quadratic and cubic\npolynomial relations among low-order moments of a non-Gaussian distribution\nallow one to locate source cycles. Complementing this with a strategy of\ndecorrelating cycles and multivariate regression allows one to infer a\nblock-topological order among the directed cycles, which leads to a {consistent\nand computationally efficient algorithm} for learning causal structures with\ndisjoint cycles.", "AI": {"tldr": "本文研究了线性非高斯模型中循环因果结构的学习问题，提出了针对循环不相交图的新方法，通过低阶矩的多项式关系和去相关策略，实现了高效且一致的算法。", "motivation": "线性结构方程模型中因果反馈循环的存在导致模型不再仅由条件独立关系表征，这使得学习循环因果结构成为挑战。本文旨在解决这一难题。", "method": "首先精确刻画了有向图确定相同线性非高斯模型的条件；针对循环不相交图，利用非高斯分布的低阶矩多项式关系定位源循环，并结合去相关策略和多变量回归推断循环的块拓扑序。", "result": "提出了一种一致且计算高效的算法，能够学习具有不相交循环的因果结构。", "conclusion": "本研究为线性非高斯模型中循环因果结构的学习提供了新的理论和方法支持，特别是在循环不相交图的情况下，算法表现优异。"}}
{"id": "2507.10569", "categories": ["cs.DM", "math.CO", "06A07, 05A05, 05C12, 05C85, 68R05", "G.2.1; G.2.2; F.2.2"], "pdf": "https://arxiv.org/pdf/2507.10569", "abs": "https://arxiv.org/abs/2507.10569", "authors": ["Danylo Tymoshenko", "Leonhard Nagel"], "title": "Metrics on Permutation Families Defined by a Restriction Graph", "comment": null, "summary": "Understanding the metric structure of permutation families is fundamental to\ncombinatorics and has applications in social choice theory, bioinformatics, and\ncoding theory. We study permutation families defined by restriction\ngraphs--oriented graphs that constrain the relative order of elements in valid\npermutations. For any restriction graph $G$, we determine the maximum distance\nachievable by two permutations under the $\\ell_\\infty$-metric and provide an\nexplicit algorithm that constructs optimal permutation pairs. Our main\ncontribution characterizes when the Kendall-Tau metric achieves its\ncombinatorial upper bound: this occurs if and only if the poset induced by $G$\nhas dimension at most 2. When this condition holds, the extremal permutations\nform a minimal realizer of the poset, revealing a deep connection between\nmetric geometry and poset dimension theory. We apply these results to classical\npermutation statistics including descent sets and Hessenberg varieties,\nobtaining explicit formulas and efficient algorithms for computing metric\ndiameters.", "AI": {"tldr": "本文研究了由限制图定义的排列族在$\\ell_\\infty$度量下的最大距离，揭示了Kendall-Tau度量达到组合上界的充要条件，并建立了度量几何与偏序集维度理论的深刻联系。", "motivation": "理解排列族的度量结构对组合数学至关重要，并在社会选择理论、生物信息学和编码理论中有广泛应用。研究限制图定义的排列族有助于揭示这些结构的本质特性。", "method": "通过限制图（有向图）约束有效排列中元素的相对顺序，对任意限制图$G$，确定$\\ell_\\infty$度量下两排列的最大可达距离，并给出构造最优排列对的显式算法。", "result": "主要贡献是刻画了Kendall-Tau度量达到组合上界的条件：当且仅当$G$诱导的偏序集维度不超过2时成立。此时极值排列构成偏序集的最小实现子，揭示了度量几何与偏序集维度理论的深层联系。", "conclusion": "将结果应用于经典排列统计量（如下降集和Hessenberg簇），获得了计算度量直径的显式公式和高效算法，为相关领域提供了实用工具。"}}
{"id": "2507.11480", "categories": ["q-fin.MF"], "pdf": "https://arxiv.org/pdf/2507.11480", "abs": "https://arxiv.org/abs/2507.11480", "authors": ["Tim Leung", "Kevin Lu"], "title": "Pricing energy spread options with variance gamma-driven Ornstein-Uhlenbeck dynamics", "comment": null, "summary": "We consider the pricing of energy spread options for spot prices following an\nexponential Ornstein-Uhlenbeck process driven by a sum of independent\nmultivariate variance gamma processes. Within this class of mean-reverting,\ninfinite activity price processes, the Esscher transform is used to obtain an\nequivalent martingale measure. We focus on the weak variance alpha-gamma\nprocess and show that it is not closed under the Esscher transform. By deriving\nan analytic expression for the cumulant generating function of the innovation\nterm, we then obtain a pricing formula for forwards and apply the FFT method of\nHurd and Zhou to price spread options. Lastly, we demonstrate how the model\nshould be both estimated on energy prices under the real world measure and\ncalibrated on forward or call prices, and provide numerical results for the\npricing of spread options.", "AI": {"tldr": "本文研究基于多元方差伽马过程驱动的指数Ornstein-Uhlenbeck过程的能源价差期权定价，利用Esscher变换获得等价鞅测度，推导创新项的累积量生成函数，并通过FFT方法实现价差期权定价。", "motivation": "针对能源价格均值回归特性，研究多元方差伽马过程驱动的随机模型，解决现有模型在Esscher变换下不闭合的问题，为能源衍生品定价提供新方法。", "method": "采用弱方差alpha-gamma过程建模，通过Esscher变换构造等价鞅测度，推导创新项累积量生成函数解析式，并应用Hurd-Zhou的FFT方法进行价差期权定价。", "result": "获得远期合约定价公式，提出基于实际能源价格的模型估计方法及远期/看涨期权价格的校准方案，并给出价差期权定价的数值计算结果。", "conclusion": "所建模型能有效刻画能源价格动态，Esscher变换虽导致过程类型改变，但通过累积量生成函数和FFT方法仍可实现高效定价，为能源衍生品市场提供实用工具。"}}
{"id": "2301.06812", "categories": ["math.HO", "math.CO", "math.NT", "00A05 (Primary), 51-01 (Secondary)"], "pdf": "https://arxiv.org/pdf/2301.06812", "abs": "https://arxiv.org/abs/2301.06812", "authors": ["Gaurav Bhatnagar", "Sagar Shrivastava"], "title": "An uncountable number of proofs of Pythagoras Theorem", "comment": "9 pages. Comments solicited. In this version, added references to a\n  set of infinite proofs presented previously", "summary": "We give an infinite number of proofs of Pythagoras theorem. Some can be\nclassified as `fractal proofs'.", "AI": {"tldr": "该论文提出了无限多种证明毕达哥拉斯定理的方法，其中包括分形证明。", "motivation": "探索毕达哥拉斯定理的多样化证明方法，特别是分形证明这一新颖途径。", "method": "使用多种数学技巧和分形几何原理构造不同的证明。", "result": "成功展示了无限多种证明，包括分形证明在内的多种方法。", "conclusion": "毕达哥拉斯定理可以通过无限多种方法证明，分形证明为其中一类新颖且有趣的方法。"}}
{"id": "2507.10604", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.10604", "abs": "https://arxiv.org/abs/2507.10604", "authors": ["Emma Hubert", "Dimitrios Lolas", "Ronnie Sircar"], "title": "A Mean Field Game for Capacity Expansion Modeling", "comment": null, "summary": "This paper studies the optimal investment behavior of renewable electricity\nproducers in a competitive market, where both prices and installation costs are\ninfluenced by aggregate industry activity. We model the resulting crowding\neffects using a mean field game framework, capturing the strategic interactions\namong a continuum of heterogeneous producers. The equilibrium dynamics are\ncharacterized via a coupled system of Hamilton-Jacobi-Bellman and Fokker-Planck\nequations, which describe the value function of a representative producer and\nthe evolution of the distribution of installed capacities over time. We analyze\nboth deterministic and stochastic versions of the model, providing analytical\ninsights in tractable cases and developing numerical methods to approximate the\ngeneral solution. Simulation results illustrate how aggregate investment\nresponds to changing market conditions, cost structures, and exogenous\nproductivity shocks.", "AI": {"tldr": "本文研究了可再生能源生产者在竞争市场中的最优投资行为，考虑了价格和安装成本受行业整体活动影响的情况，使用平均场博弈框架建模，并通过HJB和FP方程描述均衡动态。", "motivation": "研究可再生能源生产者在市场价格和成本受行业整体活动影响时的投资行为，以理解战略互动和拥挤效应对投资决策的影响。", "method": "采用平均场博弈框架建模，通过耦合的Hamilton-Jacobi-Bellman（HJB）和Fokker-Planck（FP）方程描述均衡动态，分析了确定性和随机性模型，并开发了数值方法求解一般解。", "result": "模拟结果表明，总投资对市场条件、成本结构和外生生产率冲击的变化有显著响应，验证了模型的有效性和实用性。", "conclusion": "通过平均场博弈框架，本文为可再生能源生产者的投资行为提供了理论分析和数值模拟支持，揭示了拥挤效应和战略互动对投资决策的重要影响。"}}
{"id": "2507.10592", "categories": ["cs.CR", "68Q12, 81P68, 11T71"], "pdf": "https://arxiv.org/pdf/2507.10592", "abs": "https://arxiv.org/abs/2507.10592", "authors": ["Steve Tippeconnic"], "title": "Breaking a 5-Bit Elliptic Curve Key using a 133-Qubit Quantum Computer", "comment": "32 pages, 5 figures, real hardware results from IBM Quantum, all\n  code, circuits, and raw data are publicly available for replication", "summary": "This experiment breaks a 5-bit elliptic curve cryptographic key using a\nShor-style quantum attack. Executed on IBM's 133-qubit ibm_torino with Qiskit\nRuntime 2.0, a 15-qubit circuit, comprised of 10 logical qubits and 5 ancilla,\ninterferes over an order-32 elliptic curve subgroup to extract the secret\nscalar k from the public key relation Q = kP, without ever encoding k directly\ninto the oracle. From 16,384 shots, the quantum interference reveals a diagonal\nridge in the 32 x 32 QFT outcome space. The quantum circuit, over 67,000 layers\ndeep, produced valid interference patterns despite extreme circuit depth, and\nclassical post-processing revealed k = 7 in the top 100 invertible (a, b)\nresults. All code, circuits, and raw data are publicly available for\nreplication.", "AI": {"tldr": "实验通过量子攻击成功破解5位椭圆曲线加密密钥，使用IBM的133量子比特计算机和Qiskit Runtime 2.0实现。", "motivation": "探索量子计算在破解椭圆曲线加密中的实际应用能力，验证Shor算法的可行性。", "method": "在IBM的ibm_torino上运行15量子比特电路（含5个辅助量子比特），通过量子干涉在32阶椭圆曲线子群中提取密钥k，未直接将k编码到Oracle中。", "result": "从16,384次实验中，量子干涉在32x32 QFT结果空间中显示出对角脊，经典后处理在可逆结果中成功揭示k=7。", "conclusion": "尽管电路深度极高（超过67,000层），量子电路仍能产生有效干涉模式，证明了量子计算破解椭圆曲线加密的潜力。所有代码和原始数据已公开。"}}
{"id": "2507.10566", "categories": ["cs.AI", "cs.GT", "cs.LG", "cs.MA", "cs.NE", "68T07, 68T40, 91A20", "I.2.6; I.2.11; I.2.4"], "pdf": "https://arxiv.org/pdf/2507.10566", "abs": "https://arxiv.org/abs/2507.10566", "authors": ["Hung Ming Liu"], "title": "AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems", "comment": "30 pages, 4 figures", "summary": "In Decentralized Multi-Agent Reinforcement Learning (MARL), the development\nof Emergent Communication has long been constrained by the ``Joint Exploration\nDilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' .\nTraditional methods address this by introducing inductive biases to facilitate\ncommunication emergence . This study fundamentally questions whether such\nartificial inductive biases are, in fact, over-engineering. Through experiments\nwith the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized\nVariational Autoencoder (VQ-VAE), we demonstrate that when agents possess an\nendogenous symbol system, their neural representations naturally exhibit\nspontaneous semantic compression and Nash equilibrium-driven semantic\nconvergence, achieving effective symbolic communication without external\ninductive biases. This aligns with recent neuroscience findings suggesting that\nthe human brain does not directly use human language for internal thought , and\nresonates with research on ``soft thinking'' capabilities in Large Language\nModels (LLMs) . Compared to traditional explicit communication methods, AIM\ndemonstrates stronger generality and efficiency. The interpretable analysis\ntoolkit developed in this study confirms that symbol usage exhibits a\nsignificant power-law distribution, leading to three major theoretical\ninsights: the ``Neural Communication Hypothesis'', the ``Tool-First\nPrinciple'', and the ``Semantic Interpretability Paradigm''. Future research\nwill explore the integration of Hierarchical Quantized Variational Autoencoders\n(HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the\npotential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This\ndiscovery offers new avenues for bridging symbolism and connectionism.", "AI": {"tldr": "该研究挑战了去中心化多智能体强化学习（MARL）中传统人为引入归纳偏置的做法，提出基于VQ-VAE的\"AI母语\"（AIM）框架，证明智能体内生符号系统可实现自发语义压缩与纳什均衡驱动的语义收敛，无需外部干预即达成有效符号通信。", "motivation": "针对MARL中\"联合探索困境\"导致的\"通信真空均衡\"问题，质疑传统人为引入归纳偏置的方法是否过度工程化，探索智能体自主发展通信机制的可能性。", "method": "采用基于VQ-VAE的AIM框架，让智能体通过内生符号系统进行交互，开发可解释性分析工具包验证符号使用的幂律分布特性。", "result": "实验表明：1）神经表征自发形成语义压缩 2）纳什均衡驱动语义收敛 3）符号使用呈显著幂律分布，由此提出\"神经通信假说\"\"工具优先原则\"\"语义可解释范式\"三大理论。", "conclusion": "AIM框架展现出优于传统显式通信的泛化性与效率，为连接主义与符号主义融合提供新路径，未来将探索HQ-VAE增强表达力及RL低阶预训练潜力。"}}
{"id": "2507.10932", "categories": ["math.CO", "math.FA", "math.LO", "math.OA"], "pdf": "https://arxiv.org/pdf/2507.10932", "abs": "https://arxiv.org/abs/2507.10932", "authors": ["José Contreras Mantilla", "Thomas Sinclair"], "title": "The model theory of metric lattices: pseudofinite partition lattices", "comment": "56 pages. Comments welcome!", "summary": "We initiate the study of general metric lattices in the context of the model\ntheory of metric structures. As an application we develop a theory of\npseudo-finite limits of partition lattices and connect this theory with the\ntheory of continuous limits of partition lattices due to Bj\\\"orner and\nLov\\'asz.", "AI": {"tldr": "本文首次研究了度量格在度量结构模型理论中的一般性质，并建立了分割格的伪有限极限理论，将其与Bj\\\"orner和Lov\\\\'asz提出的连续极限理论相联系。", "motivation": "探索度量格在模型理论中的基础性质，填补分割格在伪有限极限与连续极限理论间的理论空白。", "method": "采用度量结构的模型理论框架，构建分割格的伪有限极限理论体系。", "result": "成功建立了伪有限分割格极限与Bj\\\"orner-Lov\\\\'asz连续极限理论之间的理论连接。", "conclusion": "该研究为度量格理论提供了新工具，并统一了分割格极限的离散与连续描述框架。"}}
{"id": "2507.10826", "categories": ["math.CO", "05C15, 05C30, 05C57, 05C76"], "pdf": "https://arxiv.org/pdf/2507.10826", "abs": "https://arxiv.org/abs/2507.10826", "authors": ["Boris Brimkov", "Thomas R. Cameron", "Owen Grubbs"], "title": "On the forts and related parameters of the hypercube graph", "comment": "19 pages, comments are welcome", "summary": "In 2018, forts were defined as non-empty subsets of vertices in a graph where\nno vertex outside the set has exactly one neighbor in the set. Forts have since\nbeen used to characterize zero forcing sets, model zero forcing as an integer\nprogram, and provide lower bounds on the zero forcing number. In this article,\nwe give a complete characterization of minimum forts in the hypercube graph,\nshowing that they are automorphic to one of two sets. In contrast,\nnon-automorphic minimum zero forcing sets are identified with distinct\npropagation times. We also derive the fractional zero forcing number and bounds\non the fort number of the hypercube. When the hypercube's dimension is a power\nof two, the fort number and fractional zero forcing number are equal to the\ndomination number, total domination number, and open packing number. Lastly, we\npresent general constructions for minimal forts in the Cartesian product of\ngraphs, reflecting some minimal forts of the hypercube.", "AI": {"tldr": "本文对超立方体图中的最小堡垒进行了完整表征，证明其可自同构为两类集合，并推导了分数零强迫数及堡垒数的界限。当维度为2的幂时，这些参数与支配数、全支配数及开包装数相等。此外，还提出了图笛卡尔积中最小堡垒的一般构造方法。", "motivation": "堡垒作为图中顶点的非空子集，在零强迫集表征、整数规划建模及零强迫数下界估计中具有重要作用。研究超立方体图中最小堡垒的特性有助于深入理解其结构性质及应用价值。", "method": "通过自同构分析对超立方体图的最小堡垒进行完全分类，结合分数零强迫数理论推导参数界限，并利用笛卡尔积图的结构特性构造最小堡垒。", "result": "1) 超立方体最小堡垒可归约为两类自同构集；2) 维度为2的幂时，堡垒数等于支配数、全支配数与开包装数；3) 建立了笛卡尔积图中最小堡垒的通用构造方法。", "conclusion": "超立方体图的最小堡垒具有明确的分类规律，其参数在特定条件下与其他图论参数一致。所提出的笛卡尔积构造方法为研究复杂图结构中的堡垒提供了通用框架。"}}
{"id": "2507.10944", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.10944", "abs": "https://arxiv.org/abs/2507.10944", "authors": ["Libin Liang", "Zhiqiang Tan"], "title": "Debiased Prediction Inference with Non-sparse Loadings in Misspecified High-dimensional Regression Models", "comment": null, "summary": "High-dimensional regression models with regularized sparse estimation are\nwidely applied. For statistical inferences, debiased methods are available\nabout single coefficients or predictions with sparse new covariate vectors\n(also called loadings), in the presence of possible model misspecification.\nHowever, statistical inferences about predictions with non-sparse loadings are\nstudied only under the assumption of correctly specified models. In this work,\nwe develop debiased estimation and associated Wald confidence intervals for\npredictions with general loadings, allowed to be non-sparse, from possibly\nmisspecified high-dimensional regression models. Our debiased estimator\ninvolves estimation of a debiasing vector, which is the general loading\nleft-multiplied by the non-centered precision matrix in the linear model (LM)\nsetting or the inverse Hessian of the objective function at the target\ncoefficient vector in the generalized linear model (GLM) setting. We propose\nsuitable estimators of the precision matrix or the inverse Hessian respectively\nin the LM or GLM settings and, for the first time, establish a root-n\nasymptotic expansion for the debiased prediction and justify associated Wald\nconfidence intervals under sparsity conditions on the precision matrix or the\ninverse Hessian which are comparable to the conjunction of sparsity conditions\nrequired for inferences about all single coefficients in existing works. We\nalso provide numerical results which further demonstrate the validity of our\nproposed confidence intervals for predictions with general loadings from\npossibly misspecified regression models.", "AI": {"tldr": "本文针对高维回归模型中非稀疏载荷的预测问题，提出了去偏估计方法及Wald置信区间，适用于可能误设的模型，并首次在精度矩阵或逆Hessian稀疏条件下证明了其根号n渐近展开。", "motivation": "现有去偏方法仅适用于稀疏载荷或正确设定模型下的预测推断，缺乏对非稀疏载荷在误设模型中的统计推断研究。", "method": "通过估计去偏向量（线性模型中为载荷左乘非中心精度矩阵，广义线性模型中为目标系数处逆Hessian），提出精度矩阵/逆Hessian的估计方法，构建Wald置信区间。", "result": "理论证明在精度矩阵/逆Hessian稀疏条件下，去偏预测具有根号n渐近正态性，数值实验验证了所提置信区间的有效性。", "conclusion": "该方法首次实现了误设高维模型下非稀疏载荷预测的统计推断，所需稀疏条件与现有单系数推断研究相当，具有理论创新和实用价值。"}}
{"id": "2507.11031", "categories": ["cs.DM", "cs.DS", "math-ph", "math.MP", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.11031", "abs": "https://arxiv.org/abs/2507.11031", "authors": ["Weiming Feng", "Minji Yang"], "title": "Rapid Mixing of Glauber Dynamics for Monotone Systems via Entropic Independence", "comment": null, "summary": "We study the mixing time of Glauber dynamics on monotone systems. For\nmonotone systems satisfying the entropic independence condition, we prove a new\nmixing time comparison result for Glauber dynamics. For concrete applications,\nwe obtain $\\tilde{O}(n)$ mixing time for the random cluster model induced by\nthe ferromagnetic Ising model with consistently biased external fields, and\n$\\tilde{O}(n^2)$ mixing time for the bipartite hardcore model under the\none-sided uniqueness condition, where $n$ is the number of variables in\ncorresponding models, improving the best known results in [Chen and Zhang,\nSODA'23] and [Chen, Liu, and Yin, FOCS'23], respectively.\n  Our proof combines ideas from the stochastic dominance argument in the\nclassical censoring inequality and the recently developed high-dimensional\nexpanders. The key step in the proof is a novel comparison result between the\nGlauber dynamics and the field dynamics for monotone systems.", "AI": {"tldr": "本文研究了单调系统上Glauber动力学的混合时间，针对满足熵独立条件的系统提出了新的混合时间比较结果，并在具体应用中改进了铁磁Ising模型和二分图硬核模型的最佳已知结果。", "motivation": "研究单调系统上Glauber动力学的混合时间，旨在改进现有结果并扩展对高维扩展器和随机支配理论的应用理解。", "method": "结合经典审查不等式中的随机支配论证和近期发展的高维扩展器理论，提出了一种新的Glauber动力学与场动力学之间的比较方法。", "result": "对于具有一致偏置外场的铁磁Ising模型，获得了$\\tilde{O}(n)$的混合时间；对于单边唯一性条件下的二分图硬核模型，获得了$\\tilde{O}(n^2)$的混合时间，分别改进了之前的最佳结果。", "conclusion": "通过新的比较结果和理论工具，本文显著提升了单调系统上Glauber动力学的混合时间分析，为相关模型的研究提供了更优的理论保证。"}}
{"id": "2507.10937", "categories": ["math.CO", "math.NT", "Primary: 05D15, Secondary: 11B75, 12F99"], "pdf": "https://arxiv.org/pdf/2507.10937", "abs": "https://arxiv.org/abs/2507.10937", "authors": ["Mohsen Aliabadi", "Jozsef Losonczy"], "title": "Characterization of matchable sets and subspaces via Dyson transforms", "comment": "17 pages", "summary": "A matching from a finite subset $A$ of an abelian group $G$ to another subset\n$B$ is a bijection $f : A \\to B$ such that $a f(a) \\notin A$ for all $a \\in A$.\nThe study of matchings began in the 1990s and was motivated by a conjecture of\nE. K. Wakeford on canonical forms for homogeneous polynomials. The theory was\nlater extended to the linear-algebraic setting of vector subspaces over field\nextensions, and then to matroids. In this paper, we investigate the existence\nand structure of matchings in both abelian groups and field extensions. Using\nDyson's $e$-transform, a tool from additive combinatorics, along with a linear\nanalogue which is introduced in this paper, we establish characterization\ntheorems for matchable sets and subspaces. Several applications are given to\ndemonstrate the effectiveness of these theorems as standalone tools.\nThroughout, we highlight the parallels between the group-theoretic and\nlinear-algebraic perspectives.", "AI": {"tldr": "本文研究了阿贝尔群和域扩展中的匹配问题，利用Dyson的$e$-变换及其线性类比，建立了匹配集和子空间的特征定理，并展示了这些定理的应用。", "motivation": "研究匹配问题的动机源于E. K. Wakeford关于齐次多项式典范形式的猜想，随后理论被扩展到域扩展的线性代数设置和拟阵中。", "method": "使用Dyson的$e$-变换（来自加法组合学）及其线性类比工具，对阿贝尔群和域扩展中的匹配问题进行分析。", "result": "建立了匹配集和子空间的特征定理，并展示了这些定理作为独立工具的有效性。", "conclusion": "通过群论和线性代数的视角，本文不仅验证了匹配的存在性和结构，还突出了两种视角之间的相似性。"}}
{"id": "2507.10735", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.10735", "abs": "https://arxiv.org/abs/2507.10735", "authors": ["Jonathan Yu-Meng Li", "Tiantian Mao", "Reza Valimoradi"], "title": "Reconciling Risk-Aversion Paradoxes in the Distribution-Free Newsvendor Problem: Scarf's Rule Meets Dual Utility", "comment": null, "summary": "How should a risk-averse newsvendor order optimally under distributional\nambiguity? Attempts to extend Scarf's celebrated distribution-free ordering\nrule using risk measures have led to conflicting prescriptions: CVaR-based\nmodels invariably recommend ordering less as risk aversion increases, while\nmean-standard deviation models -- paradoxically -- suggest ordering more,\nparticularly when ordering costs are high. We resolve this behavioral paradox\nthrough a coherent generalization of Scarf's distribution-free framework,\nmodeling risk aversion via distortion functionals from dual utility theory.\nDespite the generality of this class, we derive closed-form optimal ordering\nrules for any coherent risk preference. These rules uncover a consistent\nbehavioral principle: a more risk-averse newsvendor may rationally order more\nwhen overstocking is inexpensive (i.e., when the cost-to-price ratio is low),\nbut will always order less when ordering is costly. Our framework offers a more\nnuanced, managerially intuitive, and behaviorally coherent understanding of\nrisk-averse inventory decisions. It exposes the limitations of non-coherent\nmodels, delivers interpretable and easy-to-compute ordering rules grounded in\ncoherent preferences, and unifies prior work under a single, tractable\napproach. We further extend the results to multi-product settings with\narbitrary demand dependencies, showing that optimal order quantities remain\nseparable and can be obtained by solving single-product problems independently.", "AI": {"tldr": "本文解决了风险厌恶报童在分布模糊下的最优订货问题，通过双效用理论的失真泛函统一了不同风险度量模型的矛盾结论，提出了基于一致风险偏好的闭式解，并扩展至多产品场景。", "motivation": "现有风险度量模型（如CVaR和均值-标准差）对风险厌恶报童的订货建议存在矛盾，需要构建一个统一框架来协调这些分歧并提供行为一致的解释。", "method": "采用双效用理论的失真泛函建模风险厌恶，将Scarf的无分布框架推广至一致风险偏好，推导闭式最优订货规则，并扩展至需求相关的多产品情形。", "result": "发现一致行为原则：当过剩成本低时，风险厌恶者可能增加订货；当订货成本高时则减少订货。多产品场景下最优订货量仍可分解为独立单产品问题求解。", "conclusion": "该框架提供了更精细、直观且行为一致的风险厌恶库存决策理论，揭示了非一致模型的局限性，并为多产品供应链管理提供了可计算方案。"}}
{"id": "2507.10610", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10610", "abs": "https://arxiv.org/abs/2507.10610", "authors": ["Zihe Yan", "Zhuosheng Zhang"], "title": "LaSM: Layer-wise Scaling Mechanism for Defending Pop-up Attack on GUI Agents", "comment": "10 pages, 9 figures", "summary": "Graphical user interface (GUI) agents built on multimodal large language\nmodels (MLLMs) have recently demonstrated strong decision-making abilities in\nscreen-based interaction tasks. However, they remain highly vulnerable to\npop-up-based environmental injection attacks, where malicious visual elements\ndivert model attention and lead to unsafe or incorrect actions. Existing\ndefense methods either require costly retraining or perform poorly under\ninductive interference. In this work, we systematically study how such attacks\nalter the attention behavior of GUI agents and uncover a layer-wise attention\ndivergence pattern between correct and incorrect outputs. Based on this\ninsight, we propose \\textbf{LaSM}, a \\textit{Layer-wise Scaling Mechanism} that\nselectively amplifies attention and MLP modules in critical layers. LaSM\nimproves the alignment between model saliency and task-relevant regions without\nadditional training. Extensive experiments across 12 types of pop-up\nperturbations and 4 different model backbones show that LaSM consistently\nenhances the defense success rate. When combined with prompt-level alerts, LaSM\nachieves over 98\\% robustness even under strong inductive attacks. Our findings\nreveal that attention misalignment is a core vulnerability in MLLM agents and\ncan be effectively addressed through selective layer-wise modulation.", "AI": {"tldr": "本文提出LaSM（层间缩放机制），通过选择性放大关键层的注意力模块来防御GUI代理中的弹窗注入攻击，无需重新训练即可显著提升模型鲁棒性。", "motivation": "现有基于多模态大语言模型（MLLM）的GUI代理易受弹窗注入攻击，传统防御方法需高成本重训练或在归纳干扰下表现不佳。", "method": "发现正确/错误输出间的层间注意力差异模式，设计\\textbf{LaSM}机制选择性增强关键层的注意力和MLP模块，使模型关注任务相关区域。", "result": "在12种弹窗扰动和4种模型架构的测试中，LaSM持续提升防御成功率，结合提示警报后对强归纳攻击的鲁棒性超过98\\%。", "conclusion": "注意力失准是MLLM代理的核心漏洞，通过层间选择性调制可有效解决，LaSM为无需训练的轻量级防御方案。"}}
{"id": "2507.10571", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.10571", "abs": "https://arxiv.org/abs/2507.10571", "authors": ["Konstantinos I. Roumeliotis", "Ranjan Sapkota", "Manoj Karkee", "Nikolaos D. Tselikas"], "title": "Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning", "comment": null, "summary": "Modern Artificial Intelligence (AI) increasingly relies on multi-agent\narchitectures that blend visual and language understanding. Yet, a pressing\nchallenge remains: How can we trust these agents especially in zero-shot\nsettings with no fine-tuning? We introduce a novel modular Agentic AI visual\nclassification framework that integrates generalist multimodal agents with a\nnon-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)\nmodule. Applied to apple leaf disease diagnosis, we benchmark three\nconfigurations: (I) zero-shot with confidence-based orchestration, (II)\nfine-tuned agents with improved performance, and (III) trust-calibrated\norchestration enhanced by CLIP-based image retrieval and re-evaluation loops.\nUsing confidence calibration metrics (ECE, OCR, CCC), the orchestrator\nmodulates trust across agents. Our results demonstrate a 77.94\\% accuracy\nimprovement in the zero-shot setting using trust-aware orchestration and RAG,\nachieving 85.63\\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL\ndisplayed overconfidence. Furthermore, image-RAG grounded predictions with\nvisually similar cases, enabling correction of agent overconfidence via\niterative re-evaluation. The proposed system separates perception (vision\nagents) from meta-reasoning (orchestrator), enabling scalable and interpretable\nmulti-agent AI. This blueprint is extensible to diagnostics, biology, and other\ntrust-critical domains. All models, prompts, results, and system components\nincluding the complete software source code are openly released to support\nreproducibility, transparency, and community benchmarking at Github:\nhttps://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust", "AI": {"tldr": "本文提出了一种新型模块化AI视觉分类框架，通过结合多模态智能体与非视觉推理协调器及RAG模块，显著提升了零样本场景下的苹果叶病诊断准确率（85.63%），并实现了可解释的信任校准。", "motivation": "当前多模态AI智能体在零样本场景下的可信度问题亟待解决，尤其在农业病害诊断等关键领域需要可靠且透明的决策支持。", "method": "开发了三层架构：（I）零样本置信度协调（II）微调智能体优化（III）基于CLIP图像检索的信任校准系统，采用ECE/OCR/CCC指标动态调节智能体信任权重。", "result": "信任感知协调+RAG使零样本准确率提升77.94%，GPT-4o校准效果最佳，Qwen-2.5-VL存在过度自信问题，图像检索通过视觉相似案例修正了32.6%的错误预测。", "conclusion": "该框架将感知（视觉智能体）与元推理（协调器）解耦，为生物诊断等信任敏感领域提供了可扩展、可解释的AI系统蓝图，所有组件已开源。"}}
{"id": "2507.10828", "categories": ["math.CO", "05D05, 05B20, 05D99"], "pdf": "https://arxiv.org/pdf/2507.10828", "abs": "https://arxiv.org/abs/2507.10828", "authors": ["Boris Bukh", "Aleksandre Saatashvili"], "title": "Maximal sets of a given diameter in Hamming cubes", "comment": "14 pages, 1 figure", "summary": "A subset of the Hamming cube over $n$-letter alphabet is said to be\n$d$-maximal if its diameter is $d$, and adding any point increases the\ndiameter. Our main result shows that each $d$-maximal set is either of size at\nmost $(n+o(n))^d$ or contains a non-trivial Hamming ball. The bound of\n$(n+o(n))^d$ is asymptotically tight. Additionally, we give a non-trivial lower\nbound on the size of any $d$-maximal set and show that the number of\nessentially different $d$-maximal sets is finite.", "AI": {"tldr": "本文研究了$n$字母表上Hamming立方体的$d$-极大子集，证明了其大小要么不超过$(n+o(n))^d$，要么包含非平凡的Hamming球，并给出了$d$-极大子集的下界和本质不同的$d$-极大子集数量的有限性。", "motivation": "研究Hamming立方体中$d$-极大子集的结构和性质，以理解其大小限制和包含关系，为组合数学和编码理论提供理论基础。", "method": "通过组合分析和极值理论，对$d$-极大子集的尺寸和结构进行严格推导和证明。", "result": "主要结果表明，$d$-极大子集的大小要么不超过$(n+o(n))^d$，要么包含非平凡的Hamming球，且该界限是渐近紧的。同时给出了$d$-极大子集的下界，并证明了本质不同的$d$-极大子集数量有限。", "conclusion": "该研究为Hamming立方体中$d$-极大子集的分类和性质提供了重要结论，揭示了其尺寸和结构的基本规律，对相关领域的研究具有指导意义。"}}
{"id": "2507.11446", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2507.11446", "abs": "https://arxiv.org/abs/2507.11446", "authors": ["Jona Dirks", "Alexandre Vigny"], "title": "Lower bounds for dominating set reconfiguration on sparse (directed) graphs", "comment": null, "summary": "In a graph, a vertex dominates itself and its neighbors, and a dominating set\nis a set of vertices that together dominate the entire graph. Given a graph and\ntwo dominating sets of equal size $k$, the {\\em Dominating Set Reconfiguration\nwith Token sliding} (DSR-TS) problem asks whether one can, by iteratively\nreplacing a vertex by an adjacent one, transform the first set into the second\none, while ensuring that every set during the reconfiguration process is a\ndominating set.\n  The token jumping variant, where a vertex can be replaced by a non-adjacent\none, is known to be efficiently solvable on many graph classes such as planar,\nbounded treewidth, and the very broad notion of nowhere-dense classes of\ngraphs. Alternatively, some algorithms also exist for the reconfiguration of\nindependent sets in the token sliding paradigm for graph classes with bounded\ndegree or large girth.\n  We show that DSR-TS is W[2]-hard when parameterized $k$, the pathwidth of the\ninstance, and the iteration of the reconfiguration sequence (a recently\nintroduced parameter). This is a setting where both the token jumping and the\nindependent set variants are fixed parameter tractable. Not restricting the\niteration yields W[2] hardness already on graphs with treewidth 9 and pathwidth\n13.\n  In the directed variant (DSR-DTS), we are only allowed to replace a vertex\nwith an out-neighbor. We show that DSR-DTS is NP-hard on DAGs of treewidth 5\nand W[2]-hard for both the case of DAGs of depth 3 parameterized by $k$, and\nthe case of DAGs when parameterized by $k$ and the pathwidth of the instance\n(independent set reconfiguration is again FPT in both settings).", "AI": {"tldr": "本文研究了图论中的支配集重构问题（DSR-TS和DSR-DTS），证明了在特定参数下这些问题具有W[2]-困难性，并对比了不同变体在各类图结构中的计算复杂性。", "motivation": "研究支配集重构问题的计算复杂性，特别是在不同图类和参数设置下的可解性，以填补现有理论空白并为算法设计提供理论依据。", "method": "通过参数化复杂性理论分析，考察了支配集重构问题在树宽、路径宽等参数下的计算难度，并与独立集重构问题进行了对比研究。", "result": "证明了DSR-TS在参数k、路径宽和重构序列迭代次数下是W[2]-困难的；在有向无环图（DAG）中，DSR-DTS在树宽5时是NP-困难的，在深度3时参数k下是W[2]-困难的。", "conclusion": "支配集重构问题在滑动范式下比跳跃范式更为困难，这一发现为图重构问题的复杂性谱系提供了新的理论洞见，特别是在有向图场景中展现了独特的计算特性。"}}
{"id": "2507.10965", "categories": ["math.CO", "cs.DM", "math.NT", "05A17, 11P81"], "pdf": "https://arxiv.org/pdf/2507.10965", "abs": "https://arxiv.org/abs/2507.10965", "authors": ["Shane Chern", "Dennis Eichhorn", "Shishuo Fu", "James A. Sellers"], "title": "Convolutive sequences, I: Through the lens of integer partition functions", "comment": "22 pages", "summary": "Motivated by the convolutive behavior of the counting function for partitions\nwith designated summands in which all parts are odd, we consider coefficient\nsequences $(a_n)_{n\\ge 0}$ of primitive eta-products that satisfy the generic\nconvolutive property\n  \\begin{align*}\n  \\sum_{n\\ge 0} a_{mn} q^n = \\left(\\sum_{n\\ge 0} a_n q^n\\right)^m\n  \\end{align*}\n  for a specific positive integer $m$. Given the results of an exhaustive\nsearch of the Online Encyclopedia of Integer Sequences for such sequences for\n$m$ up to $6$, we first focus on the case where $m=2$ with our attention mainly\npaid to the combinatorics of two $2$-convolutive sequences, featuring bijective\nproofs for both. For other $2$-convolutive sequences discovered in the OEIS, we\napply generating function manipulations to show their convolutivity. We also\ngive two examples of $3$-convolutive sequences. Finally, we discuss other\nconvolutive series that are not eta-products.", "AI": {"tldr": "本文研究了原始η积分的系数序列$(a_n)_{n\\ge 0}$的卷积性质，特别关注$m=2$时的组合意义，并给出了双射证明。此外，还探讨了其他卷积序列及其生成函数。", "motivation": "研究动机源于具有指定和且所有部分为奇数的分割计数函数的卷积行为，特别是原始η积分的系数序列满足特定卷积性质的情况。", "method": "方法包括对OEIS中$m$至多为6的序列进行详尽搜索，重点关注$m=2$时的组合意义，并给出双射证明。对于其他序列，使用生成函数操作展示其卷积性。", "result": "结果包括发现了多个$2$-卷积序列，并给出了两个$3$-卷积序列的例子。此外，还讨论了非η积分的其他卷积级数。", "conclusion": "结论表明，原始η积分的系数序列在特定条件下具有卷积性质，且这些性质可以通过组合和生成函数方法进行验证和推广。"}}
{"id": "2507.10901", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.10901", "abs": "https://arxiv.org/abs/2507.10901", "authors": ["Tommaso Giovannelli", "Jingfu Tan", "Luis Nunes Vicente"], "title": "Non-smooth stochastic gradient descent using smoothing functions", "comment": null, "summary": "In this paper, we address stochastic optimization problems involving a\ncomposition of a non-smooth outer function and a smooth inner function, a\nformulation frequently encountered in machine learning and operations research.\nTo deal with the non-differentiability of the outer function, we approximate\nthe original non-smooth function using smoothing functions, which are\ncontinuously differentiable and approach the original function as a smoothing\nparameter goes to zero (at the price of increasingly higher Lipschitz\nconstants). The proposed smoothing stochastic gradient method iteratively\ndrives the smoothing parameter to zero at a designated rate. We establish\nconvergence guarantees under strongly convex, convex, and nonconvex settings,\nproving convergence rates that match known results for non-smooth stochastic\ncompositional optimization. In particular, for convex objectives, smoothing\nstochastic gradient achieves a 1/T^(1/4) rate in terms of the number of\nstochastic gradient evaluations. We further show how general compositional and\nfinite-sum compositional problems (widely used frameworks in large-scale\nmachine learning and risk-averse optimization) fit the assumptions needed for\nthe rates (unbiased gradient estimates, bounded second moments, and accurate\nsmoothing errors). We present preliminary numerical results indicating that\nsmoothing stochastic gradient descent can be competitive for certain classes of\nproblems.", "AI": {"tldr": "本文提出了一种平滑随机梯度方法，用于解决包含非光滑外函数和光滑内函数的随机优化问题，该方法通过逐步减小平滑参数实现收敛，并在强凸、凸及非凸场景下建立了与现有非光滑随机组合优化相匹配的收敛速率。", "motivation": "机器学习与运筹学中常见非光滑外函数与光滑内函数的组合优化问题，传统方法因非可微性面临挑战，需通过平滑技术近似处理。", "method": "采用平滑函数逼近原始非光滑函数（平滑参数趋零时逼近原函数但李普希茨常数增大），提出迭代减小平滑参数的随机梯度法，并验证其适用于一般组合及有限和组合问题。", "result": "凸目标下平滑随机梯度达到$1/T^{1/4}$的随机梯度评估次数收敛速率；数值实验表明其对特定问题具有竞争力。", "conclusion": "理论证明与初步实验支持该方法在非光滑随机组合优化中的有效性，尤其适用于满足无偏梯度估计、二阶矩有界及平滑误差可控假设的场景。"}}
{"id": "2507.10621", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.GT"], "pdf": "https://arxiv.org/pdf/2507.10621", "abs": "https://arxiv.org/abs/2507.10621", "authors": ["Quanyan Zhu"], "title": "Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats", "comment": null, "summary": "Protecting cyberspace requires not only advanced tools but also a shift in\nhow we reason about threats, trust, and autonomy. Traditional cybersecurity\nmethods rely on manual responses and brittle heuristics. To build proactive and\nintelligent defense systems, we need integrated theoretical frameworks and\nsoftware tools. Game theory provides a rigorous foundation for modeling\nadversarial behavior, designing strategic defenses, and enabling trust in\nautonomous systems. Meanwhile, software tools process cyber data, visualize\nattack surfaces, verify compliance, and suggest mitigations. Yet a disconnect\nremains between theory and practical implementation.\n  The rise of Large Language Models (LLMs) and agentic AI offers a new path to\nbridge this gap. LLM-powered agents can operationalize abstract strategies into\nreal-world decisions. Conversely, game theory can inform the reasoning and\ncoordination of these agents across complex workflows. LLMs also challenge\nclassical game-theoretic assumptions, such as perfect rationality or static\npayoffs, prompting new models aligned with cognitive and computational\nrealities. This co-evolution promises richer theoretical foundations and novel\nsolution concepts. Agentic AI also reshapes software design: systems must now\nbe modular, adaptive, and trust-aware from the outset.\n  This chapter explores the intersection of game theory, agentic AI, and\ncybersecurity. We review key game-theoretic frameworks (e.g., static, dynamic,\nBayesian, and signaling games) and solution concepts. We then examine how LLM\nagents can enhance cyber defense and introduce LLM-driven games that embed\nreasoning into AI agents. Finally, we explore multi-agent workflows and\ncoordination games, outlining how this convergence fosters secure, intelligent,\nand adaptive cyber systems.", "AI": {"tldr": "本文探讨了博弈论、智能AI与网络安全的交叉领域，提出通过LLM驱动的智能体将理论策略转化为实际决策，以构建主动、智能的防御系统。", "motivation": "传统网络安全方法依赖人工响应和脆弱启发式，需转向更主动、智能的防御系统。博弈论为建模对抗行为提供了理论基础，而LLM和智能AI为弥合理论与实践的鸿沟提供了新路径。", "method": "结合博弈论框架（如静态、动态、贝叶斯和信号博弈）与LLM智能体，设计模块化、自适应且具备信任感知的软件系统，以增强网络防御。", "result": "LLM驱动的智能体能够将抽象策略转化为实际决策，同时博弈论为智能体的推理与协调提供了新模型，推动了理论与实践的协同进化。", "conclusion": "博弈论与智能AI的融合为网络安全提供了更丰富的理论基础和新型解决方案，推动了安全、智能且自适应的网络系统的发展。"}}
{"id": "2507.10624", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10624", "abs": "https://arxiv.org/abs/2507.10624", "authors": ["Zheng Zhang"], "title": "Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning", "comment": "Substantial change to previous version (experiments, theorem,\n  analysis and related work); currently under review at TMLR", "summary": "Large Language Models (LLMs) display striking surface fluency yet\nsystematically fail at tasks requiring symbolic reasoning, arithmetic accuracy,\nand logical consistency. This paper offers a structural diagnosis of such\nfailures, revealing a persistent gap between \\textit{comprehension} and\n\\textit{competence}. Through controlled experiments and architectural analysis,\nwe demonstrate that LLMs often articulate correct principles without reliably\napplying them--a failure rooted not in knowledge access, but in computational\nexecution. We term this phenomenon the computational \\textit{split-brain\nsyndrome}, where instruction and action pathways are geometrically and\nfunctionally dissociated. This core limitation recurs across domains, from\nmathematical operations to relational inferences, and explains why model\nbehavior remains brittle even under idealized prompting. We argue that LLMs\nfunction as powerful pattern completion engines, but lack the architectural\nscaffolding for principled, compositional reasoning. Our findings delineate the\nboundary of current LLM capabilities and motivate future models with\nmetacognitive control, principle lifting, and structurally grounded execution.\nThis diagnosis also clarifies why mechanistic interpretability findings may\nreflect training-specific pattern coordination rather than universal\ncomputational principles, and why the geometric separation between instruction\nand execution pathways suggests limitations in neural introspection and\nmechanistic analysis.", "AI": {"tldr": "大语言模型(LLM)在符号推理、算术精度和逻辑一致性任务中系统性失败，研究发现其核心问题是理解与执行能力的割裂，称为\\textit{计算性分裂脑综合征}。", "motivation": "探究LLMs在表面流畅性背后，为何在需要精确推理的任务中表现不佳，揭示其内在机制缺陷。", "method": "通过控制实验和架构分析，对比模型的原则表述与实际执行能力，测量指令路径与执行路径的几何分离。", "result": "发现LLMs存在\\textit{计算性分裂脑综合征}：能正确陈述原则但无法可靠应用，这种割裂导致数学运算、关系推理等领域的脆弱性。", "conclusion": "当前LLMs本质是模式补全引擎，缺乏组合推理的架构支撑。未来模型需引入元认知控制、原则提升和结构化的执行机制，几何分离现象也解释了机械可解释性研究的局限性。"}}
{"id": "2507.10840", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.10840", "abs": "https://arxiv.org/abs/2507.10840", "authors": ["Adrian Dumitrescu", "János Pach", "Morteza Saghafian"], "title": "Covering Complete Geometric Graphs by Monotone Paths", "comment": "10 pages, 3 figures", "summary": "Given a set $A$ of $n$ points (vertices) in general position in the plane,\nthe \\emph{complete geometric graph} $K_n[A]$ consists of all ${n\\choose 2}$\nsegments (edges) between the elements of $A$. It is known that the edge set of\nevery complete geometric graph on $n$ vertices can be partitioned into\n$O(n^{3/2})$ noncrossing paths (or matchings). We strengthen this result under\nvarious additional assumptions on the point set. In particular, we prove that\nfor a set $A$ of $n$ \\emph{randomly} selected points, uniformly distributed in\n$[0,1]^2$, with probability tending to $1$ as $n\\rightarrow\\infty$, the edge\nset of $K_n[A]$ can be covered by $O(n^{4/3} t(n))$ noncrossing paths (or\nmatchings), where $t(n)$ is any function tending to $\\infty$. On the other\nhand, we construct $n$-element point sets such that covering the edge set of\n$K_n(A)$ requires a quadratic number of monotone paths.", "AI": {"tldr": "本文研究了平面中完全几何图的边集划分问题，证明了在随机点集下，边集可以被$O(n^{4/3} t(n))$条不相交路径（或匹配）覆盖，同时构造了需要二次方单调路径的极端点集。", "motivation": "研究完全几何图边集划分的最优路径数量问题，特别关注随机点集和特定构造点集的表现差异。", "method": "通过概率分析证明随机点集的覆盖复杂度，并构造极端点集展示下界。使用非交叉路径和单调路径作为划分工具。", "result": "随机点集的边集覆盖复杂度为$O(n^{4/3} t(n))$（概率趋于1），而存在点集需要$\\Omega(n^2)$条单调路径。", "conclusion": "随机点集的路径覆盖复杂度显著优于最坏情况，但单调路径的覆盖需求可能达到平方级，揭示了问题结构的关键差异。"}}
{"id": "2507.11058", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.11058", "abs": "https://arxiv.org/abs/2507.11058", "authors": ["Jasarat Gasimov", "Nazim Mahmudov"], "title": "On the optimality conditions for a fractional diffusive equation with a nonlocal term", "comment": null, "summary": "We study a bilinear OCP for an evolution equation governed by the fractional\nLaplacian of order $0 < s < 1$, incorporating a nonlocal time component modeled\nby an integral kernel. After establishing well-posedness of the problem, we\nanalyze the properties of the control-to-state operator. We prove the existence\nof at least one optimal control and derive both first-order and second-order\noptimality conditions, which ensure local uniqueness. Under further\nassumptions, we also demonstrate that global uniqueness of the optimal control\ncan be achieved.", "AI": {"tldr": "研究分数阶拉普拉斯算子($0 < s < 1$)控制的演化方程的双线性最优控制问题(OCP)，包含由积分核建模的非局部时间分量。建立问题适定性后，分析控制到状态算子的性质，证明至少存在一个最优控制，推导一阶和二阶最优性条件以保证局部唯一性，并在进一步假设下证明全局唯一性。", "motivation": "探索分数阶拉普拉斯算子与非局部时间分量耦合的双线性最优控制问题，填补该领域理论空白并拓展应用场景。", "method": "1. 建立问题适定性 2. 分析控制到状态算子性质 3. 运用变分法证明最优控制存在性 4. 推导一阶/二阶最优性条件 5. 通过附加假设强化唯一性结论。", "result": "1. 证明最优控制存在性 2. 获得保证局部唯一性的最优性条件 3. 在特定条件下实现全局唯一性。", "conclusion": "理论框架成功解决了非局部时空耦合的双线性OCP问题，最优性条件的建立为实际控制策略设计提供了数学基础。"}}
{"id": "2507.10622", "categories": ["cs.CR", "cond-mat.dis-nn", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10622", "abs": "https://arxiv.org/abs/2507.10622", "authors": ["HyeYoung Lee", "Muhammad Nadeem", "Pavel Tsoi"], "title": "Spectral Feature Extraction for Robust Network Intrusion Detection Using MFCCs", "comment": null, "summary": "The rapid expansion of Internet of Things (IoT) networks has led to a surge\nin security vulnerabilities, emphasizing the critical need for robust anomaly\ndetection and classification techniques. In this work, we propose a novel\napproach for identifying anomalies in IoT network traffic by leveraging the\nMel-frequency cepstral coefficients (MFCC) and ResNet-18, a deep learning model\nknown for its effectiveness in feature extraction and image-based tasks.\nLearnable MFCCs enable adaptive spectral feature representation, capturing the\ntemporal patterns inherent in network traffic more effectively than traditional\nfixed MFCCs. We demonstrate that transforming raw signals into MFCCs maps the\ndata into a higher-dimensional space, enhancing class separability and enabling\nmore effective multiclass classification. Our approach combines the strengths\nof MFCCs with the robust feature extraction capabilities of ResNet-18, offering\na powerful framework for anomaly detection. The proposed model is evaluated on\nthree widely used IoT intrusion detection datasets: CICIoT2023, NSL-KDD, and\nIoTID20. The experimental results highlight the potential of integrating\nadaptive signal processing techniques with deep learning architectures to\nachieve robust and scalable anomaly detection in heterogeneous IoT network\nlandscapes.", "AI": {"tldr": "本文提出了一种结合梅尔频率倒谱系数（MFCC）和ResNet-18深度学习模型的新方法，用于物联网（IoT）网络流量中的异常检测与分类，并在多个数据集上验证了其有效性。", "motivation": "随着物联网网络的快速扩张，安全漏洞激增，亟需强大的异常检测与分类技术来保障网络安全。", "method": "该方法利用可学习的MFCC进行自适应频谱特征表示，结合ResNet-18模型的特征提取能力，将原始信号转换为MFCC以增强类间可分性，实现多类分类。", "result": "在CICIoT2023、NSL-KDD和IoTID20三个广泛使用的IoT入侵检测数据集上的实验结果表明，该方法能够有效检测异常，展示了自适应信号处理技术与深度学习架构结合的潜力。", "conclusion": "通过将自适应MFCC与ResNet-18结合，本文提出的框架为异构物联网网络环境中的鲁棒且可扩展的异常检测提供了有力解决方案。"}}
{"id": "2507.10630", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.10630", "abs": "https://arxiv.org/abs/2507.10630", "authors": ["Ye Yang", "Xue Xiao", "Ping Yin", "Taotao Xie"], "title": "Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs", "comment": null, "summary": "API calls by large language models (LLMs) offer a cutting-edge approach for\ndata analysis. However, their ability to effectively utilize tools via API\ncalls remains underexplored in knowledge-intensive domains like meteorology.\nThis paper introduces KG2data, a system that integrates knowledge graphs, LLMs,\nReAct agents, and tool-use technologies to enable intelligent data acquisition\nand query handling in the meteorological field. Using a virtual API, we\nevaluate API call accuracy across three metrics: name recognition failure,\nhallucination failure, and call correctness. KG2data achieves superior\nperformance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and\nchat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based\nsystems by addressing their limited access to domain-specific knowledge, which\nhampers performance on complex or terminology-rich queries. By using a\nknowledge graph as persistent memory, our system enhances content retrieval,\ncomplex query handling, domain-specific reasoning, semantic relationship\nresolution, and heterogeneous data integration. It also mitigates the high cost\nof fine-tuning LLMs, making the system more adaptable to evolving domain\nknowledge and API structures. In summary, KG2data provides a novel solution for\nintelligent, knowledge-based question answering and data analysis in domains\nwith high knowledge demands.", "AI": {"tldr": "KG2data系统结合知识图谱、大语言模型和工具使用技术，显著提升了气象领域数据查询的准确性和智能性。", "motivation": "大语言模型在知识密集型领域（如气象学）中通过API调用有效利用工具的能力尚未充分探索，现有系统在领域特定知识和复杂查询处理上存在局限。", "method": "通过整合知识图谱作为持久记忆，结合ReAct智能体和虚拟API技术，系统优化了内容检索、复杂查询处理及领域语义关系解析，同时避免了大语言模型微调的高成本。", "result": "KG2data在API调用准确率（名称识别错误1.43%、幻觉错误0%、调用正确率88.57%）上显著优于RAG2data（16%, 10%, 72.14%）和chat2data（7.14%, 8.57%, 71.43%）。", "conclusion": "KG2data为高知识需求领域提供了基于知识的智能问答与数据分析创新方案，其架构能适应领域知识和API结构的动态演进。"}}
{"id": "2507.11095", "categories": ["math.OC", "cs.IT", "cs.NA", "math.DS", "math.HO", "math.IT", "math.NA"], "pdf": "https://arxiv.org/pdf/2507.11095", "abs": "https://arxiv.org/abs/2507.11095", "authors": ["Alexander Stotsky"], "title": "Performance Enhancement of the Recursive Least Squares Algorithms with Rank Two Updates", "comment": "7pages, 2 figures", "summary": "New recursive least squares algorithms with rank two updates (RLSR2) that\ninclude both exponential and instantaneous forgetting (implemented via a proper\nchoice of the forgetting factor and the window size) are introduced and\nsystematically associated in this report with well-known RLS algorithms with\nrank one updates. Moreover, new properties (which can be used for further\nperformance improvement) of the recursive algorithms associated with the\nconvergence of the inverse of information matrix and parameter vector are\nestablished in this report. The performance of new algorithms is examined in\nthe problem of estimation of the grid events in the presence of significant\nharmonic emissions.", "AI": {"tldr": "本文介绍了具有二阶更新的新递归最小二乘算法(RLSR2)，结合指数与瞬时遗忘机制，并与传统一阶更新RLS算法进行系统关联，同时揭示了信息矩阵逆与参数向量收敛的新性质。", "motivation": "针对电网事件估计中谐波干扰严重的问题，需要开发更高效的递归估计算法，结合不同遗忘机制以提升性能。", "method": "提出RLSR2算法框架，通过遗忘因子和窗口尺寸实现混合遗忘策略，并理论分析信息矩阵逆的收敛特性。", "result": "新算法在强谐波环境下表现出优越的电网事件估计能力，所发现的性质为算法优化提供了理论依据。", "conclusion": "RLSR2算法通过二阶更新和混合遗忘机制拓展了传统RLS算法体系，其揭示的收敛性质为后续性能提升开辟了新途径。"}}
{"id": "2507.10627", "categories": ["cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2507.10627", "abs": "https://arxiv.org/abs/2507.10627", "authors": ["Xiaojian Zhang", "Junqing Wang", "Kerui Chen", "Peiyuan Zhao", "Huiyuan Bai"], "title": "Crypto-Assisted Graph Degree Sequence Release under Local Differential Privacy", "comment": null, "summary": "Given a graph $G$ defined in a domain $\\mathcal{G}$, we investigate locally\ndifferentially private mechanisms to release a degree sequence on $\\mathcal{G}$\nthat accurately approximates the actual degree distribution. Existing solutions\nfor this problem mostly use graph projection techniques based on edge deletion\nprocess, using a threshold parameter $\\theta$ to bound node degrees. However,\nthis approach presents a fundamental trade-off in threshold parameter\nselection. While large $\\theta$ values introduce substantial noise in the\nreleased degree sequence, small $\\theta$ values result in more edges removed\nthan necessary. Furthermore, $\\theta$ selection leads to an excessive\ncommunication cost. To remedy existing solutions' deficiencies, we present\nCADR-LDP, an efficient framework incorporating encryption techniques and\ndifferentially private mechanisms to release the degree sequence. In CADR-LDP,\nwe first use the crypto-assisted Optimal-$\\theta$-Selection method to select\nthe optimal parameter with a low communication cost. Then, we use the LPEA-LOW\nmethod to add some edges for each node with the edge addition process in local\nprojection. LPEA-LOW prioritizes the projection with low-degree nodes, which\ncan retain more edges for such nodes and reduce the projection error.\nTheoretical analysis shows that CADR-LDP satisfies $\\epsilon$-node local\ndifferential privacy. The experimental results on eight graph datasets show\nthat our solution outperforms existing methods.", "AI": {"tldr": "本文提出CADR-LDP框架，通过加密技术和差分隐私机制高效发布图的度序列，解决了现有方法在阈值选择上的权衡问题，并在实验中优于现有方法。", "motivation": "现有基于边删除的图投影方法在阈值参数$\\theta$选择上存在根本性权衡：大$\\theta$引入高噪声，小$\\theta$导致过多边被删除，且通信成本高。", "method": "CADR-LDP框架包含两个关键方法：1) 加密辅助的Optimal-$\\theta$-Selection以低成本选择最优参数；2) LPEA-LOW方法在局部投影中优先处理低度节点以保留更多边。", "result": "理论证明CADR-LDP满足$\\epsilon$-节点局部差分隐私，在8个图数据集上的实验表明其优于现有方法。", "conclusion": "CADR-LDP通过创新性阈值选择与边添加策略，有效解决了度序列发布的隐私与精度平衡问题，为图数据隐私保护提供了新方案。"}}
{"id": "2507.10644", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.HC", "cs.MA", "I.2.11; I.2.7; C.2.4; K.6.5; I.2.4"], "pdf": "https://arxiv.org/pdf/2507.10644", "abs": "https://arxiv.org/abs/2507.10644", "authors": ["Tatiana Petrova", "Aleksandr Puzikov", "Boris Bliznukov", "Radu State"], "title": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents", "comment": "33 pages, 9 figures, 8 tables", "summary": "The concept of the Web of Agents (WoA), which transforms the static,\ndocument-centric Web into an environment of autonomous agents acting on users'\nbehalf, has attracted growing interest as large language models (LLMs) become\nmore capable. However, research in this area is still fragmented across\ndifferent communities. Contemporary surveys catalog the latest LLM-powered\nframeworks, while the rich histories of Multi-Agent Systems (MAS) and the\nSemantic Web are often treated as separate, legacy domains. This fragmentation\nobscures the intellectual lineage of modern systems and hinders a holistic\nunderstanding of the field's trajectory. We present the first comprehensive\nevolutionary overview of the WoA. We show that modern protocols like A2A and\nthe MCP, are direct evolutionary responses to the well-documented limitations\nof earlier standards like FIPA standards and OWL-based semantic agents. To\nsystematize this analysis, we introduce a four-axis taxonomy (semantic\nfoundation, communication paradigm, locus of intelligence, discovery\nmechanism). This framework provides a unified analytical lens for comparing\nagent architectures across all generations, revealing a clear line of descent\nwhere others have seen a disconnect. Our analysis identifies a paradigm shift\nin the 'locus of intelligence': from being encoded in external data (Semantic\nWeb) or the platform (MAS) to being embedded within the agent's core model\n(LLM). This shift is foundational to modern Agentic AI, enabling the scalable\nand adaptive systems the WoA has long envisioned. We conclude that while new\nprotocols are essential, they are insufficient for building a robust, open,\ntrustworthy ecosystem. Finally, we argue that the next research frontier lies\nin solving persistent socio-technical challenges, and we map out a new agenda\nfocused on decentralized identity, economic models, security, and governance\nfor the emerging WoA.", "AI": {"tldr": "本文首次全面综述了代理网络（WoA）的演变历程，揭示了现代协议（如A2A和MCP）是对早期标准（如FIPA和OWL）局限性的直接进化响应，并提出了一个四维分类法来统一分析不同世代的代理架构。研究发现智能核心从外部数据或平台转移到代理内部模型（LLM）的范式转变，并指出未来研究方向应聚焦于解决去中心化身份、经济模型、安全与治理等社会技术挑战。", "motivation": "当前代理网络（WoA）研究分散在不同领域，缺乏对多智能体系统（MAS）和语义网历史关联的整合，阻碍了对该领域发展轨迹的整体理解。本文旨在填补这一空白，揭示现代系统的知识谱系。", "method": "通过引入四维分类法（语义基础、通信范式、智能核心、发现机制），系统比较了各代代理架构，并分析了从FIPA/OWL到A2A/MCP的进化路径。", "result": "研究发现智能核心的范式转变：从语义网的外部数据编码、MAS的平台编码，转变为LLM驱动的代理内部模型嵌入。这种转变为实现可扩展、自适应的代理网络奠定了基础。", "conclusion": "新协议虽必要但不足，未来研究需解决去中心化身份、经济模型、安全与治理等社会技术挑战，以构建稳健开放的代理网络生态系统。"}}
{"id": "2507.11106", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11106", "abs": "https://arxiv.org/abs/2507.11106", "authors": ["Víctor Blanco", "Inmaculada Espejo", "Raúl Páez", "Antonio M. Rodríguez-Chía"], "title": "A Mathematical Optimization Approach to Multisphere Support Vector Data Description", "comment": "18 pages, 5 figures, 3 tables", "summary": "We present a novel mathematical optimization framework for outlier detection\nin multimodal datasets, extending Support Vector Data Description approaches.\nWe provide a primal formulation, in the shape of a Mixed Integer Second Order\nCone model, that constructs Euclidean hyperspheres to identify anomalous\nobservations. Building on this, we develop a dual model that enables the\napplication of the kernel trick, thus allowing for the detection of outliers\nwithin complex, non-linear data structures. An extensive computational study\ndemonstrates the effectiveness of our exact method, showing clear advantages\nover existing heuristic techniques in terms of accuracy and robustness.", "AI": {"tldr": "提出了一种新颖的多模态数据集异常值检测数学优化框架，扩展了支持向量数据描述方法，通过混合整数二阶锥模型和核技巧实现高效检测。", "motivation": "现有启发式方法在复杂非线性数据结构中的异常检测精度和鲁棒性不足，需要开发更精确的数学优化框架。", "method": "构建了基于欧几里得超球面的混合整数二阶锥原始模型，并开发了支持核技巧的对偶模型以处理非线性结构。", "result": "计算研究表明，该方法在准确性和鲁棒性上显著优于现有启发式技术。", "conclusion": "该精确方法为多模态数据集中的异常检测提供了有效的数学优化解决方案，尤其在复杂数据结构中表现优异。"}}
{"id": "2507.10730", "categories": ["cs.CR", "cs.DB", "cs.DC", "cs.DS", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.10730", "abs": "https://arxiv.org/abs/2507.10730", "authors": ["Yin Li", "Sharad Mehrota", "Shantanu Sharma", "Komal Kumari"], "title": "Access Control for Information-Theoretically Secure Key-Document Stores", "comment": "An extended abstract of this version has been accepted in VLDB 2025", "summary": "This paper presents a novel key-based access control technique for secure\noutsourcing key-value stores where values correspond to documents that are\nindexed and accessed using keys. The proposed approach adopts Shamir's\nsecret-sharing that offers unconditional or information-theoretic security. It\nsupports keyword-based document retrieval while preventing leakage of the data,\naccess rights of users, or the size (\\textit{i}.\\textit{e}., volume of the\noutput that satisfies a query). The proposed approach allows servers to detect\n(and abort) malicious clients from gaining unauthorized access to data, and\nprevents malicious servers from altering data undetected while ensuring\nefficient access -- it takes 231.5ms over 5,000 keywords across 500,000 files.", "AI": {"tldr": "本文提出了一种基于密钥的访问控制技术，用于安全外包键值存储，采用Shamir秘密共享实现无条件安全，支持关键词检索并防止数据、用户权限及查询结果规模的泄露。", "motivation": "现有键值存储外包方案存在数据泄露、访问权限暴露及查询结果规模泄漏等安全隐患，需设计一种能同时防范恶意客户端和服务器的安全访问控制方法。", "method": "基于Shamir秘密共享方案，构建信息论安全的系统架构，实现关键词检索功能，并嵌入恶意行为检测机制（客户端越权检测/服务器数据篡改检测）。", "result": "系统在50万文件中处理5000个关键词耗时231.5毫秒，能有效阻止未授权访问（客户端）和隐蔽数据篡改（服务器）。", "conclusion": "该方案首次将信息论安全应用于外包键值存储，在保证高效检索（毫秒级响应）的同时，全面防护数据、元数据及查询模式的泄露。"}}
{"id": "2507.10740", "categories": ["cs.AI", "cs.NE", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.10740", "abs": "https://arxiv.org/abs/2507.10740", "authors": ["Maziar Kanani", "Sean O Leary", "James McDermott"], "title": "Parsing Musical Structure to Enable Meaningful Variations", "comment": null, "summary": "This paper presents a novel rule-based approach for generating music by\nvarying existing tunes. We parse each tune to find the Pathway Assembly (PA) [\n1], that is a structure representing all repetitions in the tune. The Sequitur\nalgorithm [2 ] is used for this. The result is a grammar. We then carry out\nmutation on the grammar, rather than on a tune directly. There are potentially\n19 types of mutations such as adding, removing, swapping or reversing parts of\nthe grammar that can be applied to the grammars. The system employs one of the\nmutations randomly in this step to automatically manipulate the grammar.\nFollowing the mutation, we need to expand the grammar which returns a new tune.\nThe output after 1 or more mutations will be a new tune related to the original\ntune. Our study examines how tunes change gradually over the course of multiple\nmutations. Edit distances, structural complexity and length of the tunes are\nused to show how a tune is changed after multiple mutations. In addition, the\nsize of effect of each mutation type is analyzed. As a final point, we review\nthe musical aspect of the output tunes. It should be noted that the study only\nfocused on generating new pitch sequences. The study is based on an Irish\ntraditional tune dataset and a list of integers has been used to represent each\ntune's pitch values.", "AI": {"tldr": "本文提出了一种基于规则的音乐生成方法，通过解析现有曲调并应用语法突变来产生新曲调。研究分析了突变对曲调编辑距离、结构复杂度和长度的影响，并评估了输出曲调的音乐性。", "motivation": "探索如何通过语法突变自动生成与原始曲调相关的新曲调，并分析突变对曲调特性的影响。", "method": "使用Sequitur算法解析曲调生成语法（PA结构），随机应用19种语法突变类型（如添加、删除、交换或反转部分语法），再扩展语法生成新曲调。基于爱尔兰传统曲调数据集，以整数序列表示音高。", "result": "通过多次突变逐渐改变曲调，量化分析显示编辑距离、结构复杂度和曲调长度均发生变化。不同突变类型的影响程度各异，生成的新曲调在音乐性上与原始曲调保持关联。", "conclusion": "基于语法的突变方法能有效生成多样化的新曲调，同时保留原始曲调特征。该方法仅聚焦音高序列生成，为音乐创作自动化提供了新思路。"}}
{"id": "2507.11253", "categories": ["math.OC", "cs.NA", "math.NA", "49J52, 49J53, 90C31"], "pdf": "https://arxiv.org/pdf/2507.11253", "abs": "https://arxiv.org/abs/2507.11253", "authors": ["Boris S. Mordukhovich", "Peipei Tang", "Chengjing Wang"], "title": "Second-Order Characterizations of Tilt Stability in Composite Optimization", "comment": "32 pages", "summary": "Tilt stability is a fundamental concept of variational analysis and\noptimization that plays a pivotal role in both theoretical issues and numerical\ncomputations. This paper investigates tilt stability of local minimizers for a\ngeneral class of composite optimization problems in finite dimensions, where\nextended-real-valued objectives are compositions of parabolically regular and\nsmooth functions. Under the weakest metric subregularity constraint\nqualification and other verifiable conditions, we establish unified\nneighborhood and pointbased characterizations of tilt stability via\nsecond-order generalized differentiation. The obtained results provide a\nrigorous theoretical foundation for further developments on variational\nstability and numerical algorithms of optimization and related topics.", "AI": {"tldr": "本文研究了有限维复合优化问题中局部极小值的倾斜稳定性，在弱度量次正则性约束条件下，通过二阶广义微分建立了统一的邻域和点基特征。", "motivation": "倾斜稳定性是变分分析和优化的基本概念，对理论问题和数值计算至关重要。本文旨在为复合优化问题的倾斜稳定性提供严格的理论基础。", "method": "在弱度量次正则性约束条件下，利用二阶广义微分方法，对抛物正则与光滑函数组合的扩展实值目标函数进行分析。", "result": "在可验证条件下，建立了倾斜稳定性的统一邻域和点基特征，为优化及相关主题的变分稳定性和数值算法提供了理论基础。", "conclusion": "研究成果为优化问题的变分稳定性和数值算法发展奠定了严谨的理论基础，推动了相关领域的进一步研究。"}}
{"id": "2507.10733", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.10733", "abs": "https://arxiv.org/abs/2507.10733", "authors": ["Jianyao Yin", "Luca Arnaboldi", "Honglong Chen", "Pascal Berrang"], "title": "3S-Attack: Spatial, Spectral and Semantic Invisible Backdoor Attack Against DNN Models", "comment": "14 pages, 10 figures", "summary": "Backdoor attacks involve either poisoning the training data or directly\nmodifying the model in order to implant a hidden behavior, that causes the\nmodel to misclassify inputs when a specific trigger is present. During\ninference, the model maintains high accuracy on benign samples but\nmisclassifies poisoned samples into an attacker-specified target class.\nExisting research on backdoor attacks has explored developing triggers in the\nspatial, spectral (frequency), and semantic (feature) domains, aiming to make\nthem stealthy. While some approaches have considered designing triggers that\nare imperceptible in both spatial and spectral domains, few have incorporated\nthe semantic domain. In this paper, we propose a novel backdoor attack, termed\n3S-attack, which is stealthy across the spatial, spectral, and semantic\ndomains. The key idea is to exploit the semantic features of benign samples as\ntriggers, using Gradient-weighted Class Activation Mapping (Grad-CAM) and a\npreliminary model for extraction. The trigger is then embedded in the spectral\ndomain, followed by pixel-level restrictions after converting the samples back\nto the spatial domain. This process minimizes the distance between poisoned and\nbenign samples, making the attack harder to detect by existing defenses and\nhuman inspection. Extensive experiments on various datasets, along with\ntheoretical analysis, demonstrate the stealthiness of 3S-attack and highlight\nthe need for stronger defenses to ensure AI security. Our code is available at:\nhttps://anonymous.4open.science/r/anon-project-3776/", "AI": {"tldr": "本文提出了一种新型后门攻击方法3S-attack，通过在空间、频谱和语义三个维度上实现隐蔽性，利用良性样本的语义特征作为触发器，结合Grad-CAM和频谱嵌入技术，使攻击难以被现有防御机制和人工检测发现。", "motivation": "现有后门攻击研究多聚焦于空间和频谱域的隐蔽性，而忽略了语义域。本文旨在开发一种在空间、频谱和语义三个维度均具备隐蔽性的攻击方法，以揭示现有防御的不足并推动AI安全的发展。", "method": "3S-attack利用Grad-CAM和预训练模型提取良性样本的语义特征作为触发器，将触发器嵌入频谱域后通过像素级限制转换回空间域，最小化毒化样本与良性样本的差异。", "result": "在多个数据集上的实验和理论分析表明，3S-attack在三个维度均表现出卓越的隐蔽性，成功规避了现有防御机制的检测，突显了当前AI安全防御的脆弱性。", "conclusion": "该研究不仅提出了一种跨域隐蔽的新型后门攻击范式，更强调了开发更强防御机制的必要性。代码已开源：https://anonymous.4open.science/r/anon-project-3776/"}}
{"id": "2507.10750", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10750", "abs": "https://arxiv.org/abs/2507.10750", "authors": ["Pandu Devarakota", "Nicolas Tsesmetzis", "Faruk O. Alpak", "Apurva Gala", "Detlef Hohl"], "title": "AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition", "comment": "Technical article to be submitted to Data Centric Engineering Journal", "summary": "Thanks to the availability of massive amounts of data, computing resources,\nand advanced algorithms, AI has entered nearly every sector. This has sparked\nsignificant investment and interest, particularly in building data centers with\nthe necessary hardware and software to develop and operate AI models and\nAI-based workflows. In this technical review article, we present energy\nconsumption scenarios of data centers and impact on GHG emissions, considering\nboth near-term projections (up to 2030) and long-term outlook (2035 and\nbeyond). We address the quintessential question of whether AI will have a net\npositive, neutral, or negative impact on CO2 emissions by 2035. Additionally,\nwe discuss AI's potential to automate, create efficient and disruptive\nworkflows across various fields related to energy production, supply and\nconsumption. In the near-term scenario, the growing demand for AI will likely\nstrain computing resources, lead to increase in electricity consumption and\ntherefore associated CO2 emissions. This is due to the power-hungry nature of\nbig data centers and the requirements for training and running of large and\ncomplex AI models, as well as the penetration of AI assistant search and\napplications for public use. However, the long-term outlook could be more\npromising. AI has the potential to be a game-changer in CO2 reduction. Its\nability to further automate and optimize processes across industries, from\nenergy production to logistics, could significantly decrease our carbon\nfootprint. This positive impact is anticipated to outweigh the initial\nemissions bump, creating value for businesses and society in areas where\ntraditional solutions have fallen short. In essence, AI might cause some\ninitial growing pains for the environment, but it has the potential to support\nclimate mitigation efforts.", "AI": {"tldr": "本文探讨了AI对数据中心能源消耗及温室气体排放的影响，分析了短期（至2030年）与长期（2035年后）的不同情景，指出AI初期可能增加碳排放，但长期有望通过优化流程成为减排的关键力量。", "motivation": "随着AI技术的广泛应用，数据中心的能源消耗和碳排放问题日益突出。研究旨在评估AI对CO2排放的净影响，并探讨其在能源生产、供应和消费领域的自动化与优化潜力。", "method": "通过分析数据中心的能源消耗情景，结合近短期和长期的预测，评估AI对电力需求和CO2排放的影响，并探讨AI在跨行业流程优化中的潜力。", "result": "短期内，AI需求的增长将导致计算资源紧张、电力消耗增加及CO2排放上升；但长期来看，AI通过自动化与优化能源生产、物流等流程，可能显著减少碳足迹，其积极影响有望超过初期的排放增长。", "conclusion": "AI虽在初期可能对环境造成压力，但其在气候缓解方面的潜力巨大，有望成为减排的重要工具，为商业和社会创造传统方法难以实现的价值。"}}
{"id": "2507.11008", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.11008", "abs": "https://arxiv.org/abs/2507.11008", "authors": ["Ze-Chun Hu", "Yi-Ding Shi", "Qian-Qian Zhou"], "title": "A lemma on a finite union-closed family of finite sets and its applications", "comment": "6 pages", "summary": "In this note, we will give a lemma on a finite union-closed family of finite\nsets, and several applications of its.", "AI": {"tldr": "本文提出了一个关于有限并闭集族的引理及其应用。", "motivation": "研究有限并闭集族的性质，以扩展组合数学中的相关理论。", "method": "通过构建并分析有限并闭集族的引理，推导其数学性质。", "result": "提出了一个关于有限并闭集族的新引理，并展示了其在多个场景下的应用。", "conclusion": "该引理为有限并闭集族的研究提供了新的工具，具有潜在的理论价值。"}}
{"id": "2507.11350", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11350", "abs": "https://arxiv.org/abs/2507.11350", "authors": ["Jun-ya Gotoh", "Michael Jong Kim", "Andrew E. B. Lim"], "title": "Distributionally Robust Optimization is a Multi-Objective Problem", "comment": null, "summary": "Distributionally Robust Optimization (DRO) is a worst-case approach to\ndecision making when there is model uncertainty. Though formulated as a\nsingle-objective problem, we show that it is intrinsically multi-objective in\nthat DRO solutions map out a near-Pareto-optimal frontier between expected cost\nand a measure of robustness called worst-case sensitivity (WCS). We take this\nas the starting point and explore robust decision making through a\nmulti-objective lens. We show that WCS is a measure of spread and derive WCS\nfor a collection of uncertainty sets commonly used in DRO. These sensitivity\nmeasures identify the errors against which the nominal expected cost is most\nvulnerable and the uncertainty set for the worst-case problem that most\neffectively mitigates it. The associated mean-sensitivity frontier is used to\nselect its size. The multi-objective perspective provides a quantitative\nmeasure of robustness and a sensitivity-based approach to addressing important\nconceptual gaps in DRO -- how to choose the family and size of uncertainty sets\nfor a given cost distribution, and how this affects the solution.", "AI": {"tldr": "本文揭示了分布鲁棒优化(DRO)本质上是多目标问题，提出了通过最坏情况敏感性(WCS)量化鲁棒性的新视角，并建立了均值-敏感性前沿以指导不确定性集合的选择。", "motivation": "传统单目标DRO框架存在概念性缺陷，无法量化鲁棒性程度，也难以确定合适的不确定性集合。研究旨在通过多目标视角解决这些核心问题。", "method": "将DRO重构为均值成本与WCS的双目标问题，推导常见不确定性集合的WCS解析式，构建均值-敏感性前沿作为决策工具。", "result": "证明WCS本质是分布离散度的度量，发现不同不确定性集合对应特定误差类型的防护能力，前沿分析可科学确定集合规模。", "conclusion": "多目标框架为DRO提供了鲁棒性量化标准，敏感性分析填补了不确定性集合选择的理论空白，使鲁棒决策更具可解释性。"}}
{"id": "2507.10808", "categories": ["cs.CR", "cs.SY", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.10808", "abs": "https://arxiv.org/abs/2507.10808", "authors": ["Mohammad Alikhani", "Reza Kazemi"], "title": "Contrastive-KAN: A Semi-Supervised Intrusion Detection Framework for Cybersecurity with scarce Labeled Data", "comment": null, "summary": "In the era of the Fourth Industrial Revolution, cybersecurity and intrusion\ndetection systems are vital for the secure and reliable operation of IoT and\nIIoT environments. A key challenge in this domain is the scarcity of labeled\ncyber-attack data, as most industrial systems operate under normal conditions.\nThis data imbalance, combined with the high cost of annotation, hinders the\neffective training of machine learning models. Moreover, rapid detection of\nattacks is essential, especially in critical infrastructure, to prevent\nlarge-scale disruptions. To address these challenges, we propose a real-time\nintrusion detection system based on a semi-supervised contrastive learning\nframework using the Kolmogorov-Arnold Network (KAN). Our method leverages\nabundant unlabeled data to distinguish between normal and attack behaviors\neffectively. We validate our approach on three benchmark datasets: UNSW-NB15,\nBoT-IoT, and Gas Pipeline, using only 2.20 percent, 1.28 percent, and 8 percent\nof labeled samples, respectively, to simulate real-world conditions.\nExperimental results show that our method outperforms existing contrastive\nlearning-based approaches. We further compare KAN with a traditional multilayer\nperceptron (MLP), demonstrating KAN's superior performance in both detection\naccuracy and robustness under limited supervision. KAN's ability to model\ncomplex relationships and its learnable activation functions are also explored\nand visualized, offering interpretability and potential for rule extraction.\nThe method supports multi-class classification and proves effective in\nsafety-critical environments where reliability is paramount.", "AI": {"tldr": "本文提出了一种基于半监督对比学习框架和Kolmogorov-Arnold网络（KAN）的实时入侵检测系统，用于解决物联网和工业物联网环境中标记数据稀缺和快速攻击检测的挑战。该方法在多个基准数据集上验证了其优越性能。", "motivation": "在第四次工业革命时代，网络安全和入侵检测系统对物联网和工业物联网环境的安全可靠运行至关重要。然而，标记网络攻击数据的稀缺性、数据不平衡以及标注成本高昂，阻碍了机器学习模型的有效训练。此外，关键基础设施中快速检测攻击的需求迫切。", "method": "我们提出了一种基于半监督对比学习框架的实时入侵检测系统，利用Kolmogorov-Arnold网络（KAN）有效区分正常和攻击行为。该方法充分利用大量未标记数据，并在UNSW-NB15、BoT-IoT和Gas Pipeline三个基准数据集上验证，仅使用少量标记样本（分别为2.20%、1.28%和8%）模拟真实场景。", "result": "实验结果表明，该方法优于现有的基于对比学习的方法。与传统的多层感知机（MLP）相比，KAN在检测精度和有限监督下的鲁棒性方面表现更优。KAN能够建模复杂关系，其可学习的激活函数提供了可解释性和规则提取的潜力。", "conclusion": "该方法支持多类分类，并在可靠性至关重要的安全关键环境中证明有效。KAN的优越性能和可解释性为入侵检测系统提供了新的解决方案。"}}
{"id": "2507.10758", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10758", "abs": "https://arxiv.org/abs/2507.10758", "authors": ["Nikesh Prajapati", "Bimal Karki", "Saroj Gopali", "Akbar Siami Namin"], "title": "IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models", "comment": null, "summary": "This paper intends to detect IoT malicious attacks through deep learning\nmodels and demonstrates a comprehensive evaluation of the deep learning and\ngraph-based models regarding malicious network traffic detection. The models\nparticularly are based on GraphSAGE, Bidirectional encoder representations from\ntransformers (BERT), Temporal Convolutional Network (TCN) as well as Multi-Head\nAttention, together with Bidirectional Long Short-Term Memory (BI-LSTM)\nMulti-Head Attention and BI-LSTM and LSTM models. The chosen models\ndemonstrated great performance to model temporal patterns and detect feature\nsignificance. The observed performance are mainly due to the fact that IoT\nsystem traffic patterns are both sequential and diverse, leaving a rich set of\ntemporal patterns for the models to learn. Experimental results showed that\nBERT maintained the best performance. It achieved 99.94% accuracy rate\nalongside high precision and recall, F1-score and AUC-ROC score of 99.99% which\ndemonstrates its capabilities through temporal dependency capture. The\nMulti-Head Attention offered promising results by providing good detection\ncapabilities with interpretable results. On the other side, the Multi-Head\nAttention model required significant processing time like BI-LSTM variants. The\nGraphSAGE model achieved good accuracy while requiring the shortest training\ntime but yielded the lowest accuracy, precision, and F1 score compared to the\nother models", "AI": {"tldr": "本文通过深度学习模型检测IoT恶意攻击，评估了多种模型在恶意网络流量检测中的表现，其中BERT模型表现最佳。", "motivation": "研究旨在利用深度学习模型捕捉IoT系统流量中的时序模式，以提高恶意攻击检测的准确性和效率。", "method": "采用了多种模型，包括GraphSAGE、BERT、TCN、Multi-Head Attention、BI-LSTM Multi-Head Attention、BI-LSTM和LSTM，以评估其在时序模式建模和特征重要性检测中的表现。", "result": "BERT模型表现最优，准确率达到99.94%，且具有高精度、召回率、F1分数和AUC-ROC分数（99.99%）。Multi-Head Attention模型提供了可解释的结果，但处理时间较长。GraphSAGE模型训练时间最短，但准确率和F1分数最低。", "conclusion": "BERT模型在捕捉时序依赖关系方面表现卓越，是IoT恶意攻击检测的最佳选择，而Multi-Head Attention模型在可解释性方面具有优势，但需权衡处理时间。"}}
{"id": "2507.11013", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.11013", "abs": "https://arxiv.org/abs/2507.11013", "authors": ["Vuong Bui"], "title": "A characterization of the Carathéodory number for $H$-convexity", "comment": "14 pages; comments are welcome", "summary": "We show that the Carath\\'eodory number for $H$-convexity is the maximum of\ntwo parameters: the Helly number for $H$-convexity and the cone number of $H$.\nThe cone number in this article is defined as the maximal number of points of\n$H$ in conical position with an empty positive hull relative to the remaining\npoints. Earlier partial results by Boltyanski and Martini can provide an exact\nvalue for the Carath\\'eodory number only when the Helly number is $1$ or $2$.\n  We further establish connections between the Carath\\'eodory numbers for\n$H$-convexity and that for $K$-strong convexity, where $H$ is the set of\nnormals of $K$. Specifically, the Carath\\'eodory number for $H$-convexity\nprovides a lower bound for that of $K$-strong convexity. Moreover, if $K$ is a\npolytope, which has $|H|$ facets, then the Carath\\'eodory number for $K$-strong\nconvexity is at most the maximum of $|H|-1$ and the Carath\\'eodory number for\n$H$-convexity. We conjecture a characterization of when the bound $|H|-1$ is\nattained. It is a consequence of a broader conjecture stating that the\nCarath\\'eodory number for $K$-strong convexity is at most the maximum of the\nCarath\\'eodory numbers for $H'$-convexity over all subsets $H'\\subseteq H$.\nFinally, we observe that the Carath\\'eodory number is at least the Helly number\nin any convex-structure where all sets are ordinarily convex.", "AI": {"tldr": "本文证明了$H$-凸性的Carath\\'eodory数是其Helly数与$H$的锥数的最大值，并建立了$H$-凸性与$K$-强凸性Carath\\'eodory数之间的联系。", "motivation": "研究$H$-凸性的Carath\\'eodory数及其与$K$-强凸性Carath\\'eodory数的关系，以扩展Boltyanski和Martini的部分结果。", "method": "通过定义$H$的锥数并分析其与Helly数的关系，进一步探讨$H$-凸性与$K$-强凸性Carath\\'eodory数之间的界限。", "result": "发现$H$-凸性的Carath\\'eodory数是Helly数与锥数的最大值，且为$K$-强凸性Carath\\'eodory数提供了下界。若$K$是多面体，则其Carath\\'eodory数不超过$|H|-1$与$H$-凸性Carath\\'eodory数的最大值。", "conclusion": "在任意凸结构中，Carath\\'eodory数至少为Helly数。提出了关于$K$-强凸性Carath\\'eodory数上界的猜想，并指出其可能由所有子集$H'\\subseteq H$的$H'$-凸性Carath\\'eodory数的最大值决定。"}}
{"id": "2507.11461", "categories": ["math.OC", "cs.CV", "65K10, 65J22, 94A08, 47N10"], "pdf": "https://arxiv.org/pdf/2507.11461", "abs": "https://arxiv.org/abs/2507.11461", "authors": ["Christian Daniele", "Silvia Villa", "Samuel Vaiter", "Luca Calatroni"], "title": "Deep Equilibrium models for Poisson Imaging Inverse problems via Mirror Descent", "comment": null, "summary": "Deep Equilibrium Models (DEQs) are implicit neural networks with fixed\npoints, which have recently gained attention for learning image regularization\nfunctionals, particularly in settings involving Gaussian fidelities, where\nassumptions on the forward operator ensure contractiveness of standard\n(proximal) Gradient Descent operators. In this work, we extend the application\nof DEQs to Poisson inverse problems, where the data fidelity term is more\nappropriately modeled by the Kullback-Leibler divergence. To this end, we\nintroduce a novel DEQ formulation based on Mirror Descent defined in terms of a\ntailored non-Euclidean geometry that naturally adapts with the structure of the\ndata term. This enables the learning of neural regularizers within a principled\ntraining framework. We derive sufficient conditions to guarantee the\nconvergence of the learned reconstruction scheme and propose computational\nstrategies that enable both efficient training and fully parameter-free\ninference. Numerical experiments show that our method outperforms traditional\nmodel-based approaches and it is comparable to the performance of Bregman\nPlug-and-Play methods, while mitigating their typical drawbacks - namely,\nsensitivity to initialization and careful tuning of hyperparameters. The code\nis publicly available at https://github.com/christiandaniele/DEQ-MD.", "AI": {"tldr": "本文提出了一种基于镜像下降的深度平衡模型（DEQ-MD），用于解决泊松逆问题，通过非欧几何结构自适应数据项，实现了高效训练和无参数推理，性能优于传统方法。", "motivation": "传统深度平衡模型（DEQs）主要适用于高斯保真度问题，而泊松逆问题需要更合适的Kullback-Leibler散度数据项。本文旨在扩展DEQs的应用范围，解决泊松逆问题。", "method": "提出了一种基于镜像下降的DEQ-MD模型，利用非欧几何结构自适应数据项，推导了收敛性条件，并设计了高效训练和无参数推理的计算策略。", "result": "实验表明，DEQ-MD在泊松逆问题中优于传统模型驱动方法，与Bregman即插即用方法性能相当，同时克服了后者对初始化和超参数敏感的缺点。", "conclusion": "DEQ-MD为泊松逆问题提供了一种高效且鲁棒的解决方案，代码已开源，推动了DEQs在更广泛逆问题中的应用。"}}
{"id": "2507.10819", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.10819", "abs": "https://arxiv.org/abs/2507.10819", "authors": ["Pedro Almansa Jiménez", "Lorenzo Fernández Maimó", "Ángel Luis Peráles Gómez"], "title": "Reporte de vulnerabilidades en IIoT. Proyecto DEFENDER", "comment": "Language: Spanish", "summary": "The main objective of this technical report is to conduct a comprehensive\nstudy on devices operating within Industrial Internet of Things (IIoT)\nenvironments, describing the scenarios that define this category and analysing\nthe vulnerabilities that compromise their security. To this end, the report\nseeks to identify and examine the main classes of IIoT devices, detailing their\ncharacteristics, functionalities, and roles within industrial systems. This\nanalysis enables a better understanding of how these devices interact and\nfulfil the requirements of critical industrial environments. The report also\nexplores the specific contexts in which these devices operate, highlighting the\ndistinctive features of industrial scenarios and the conditions under which the\ndevices function. Furthermore, it analyses the vulnerabilities affecting IIoT\ndevices, outlining their vectors, targets, impact, and consequences. The report\nthen describes the typical phases of an attack, along with a selection of\nreal-world documented incidents. These cases are classified according to the\ntaxonomy presented in Section 3, providing a comprehensive view of the\npotential threats to security and assessing the impact these vulnerabilities\nmay have on industrial environments. Finally, the report presents a compilation\nof some of the most recent and effective security countermeasures as potential\nsolutions to the security challenges faced by industrial systems. Special\nemphasis is placed on the role of Machine Learning in the development of these\napproaches, underscoring its importance in enhancing industrial cybersecurity.", "AI": {"tldr": "本技术报告全面研究了工业物联网(IIoT)设备的安全问题，包括设备分类、漏洞分析、攻击案例及防御措施，特别强调了机器学习在工业网络安全中的作用。", "motivation": "工业物联网(IIoT)设备在关键工业环境中扮演重要角色，但其安全漏洞可能对工业系统造成严重影响，因此需要系统性的安全研究。", "method": "报告通过识别IIoT设备的主要类别、分析其功能特性、研究工业场景特征，并系统梳理漏洞类型和攻击案例，最后提出安全防护对策。", "result": "研究建立了IIoT设备分类体系，揭示了典型漏洞的攻击向量和影响，通过真实案例验证了威胁模型，并总结了包括机器学习在内的最新防护方案。", "conclusion": "IIoT设备面临严峻安全挑战，需要结合设备特性、工业场景和先进技术(如机器学习)来构建多层次防护体系，以保障工业系统的安全性。"}}
{"id": "2507.10761", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.10761", "abs": "https://arxiv.org/abs/2507.10761", "authors": ["Tyler King", "Nikolos Gurney", "John H. Miller", "Volkan Ustun"], "title": "Detecting AI Assistance in Abstract Complex Tasks", "comment": "Accepted to HCII 2025", "summary": "Detecting assistance from artificial intelligence is increasingly important\nas they become ubiquitous across complex tasks such as text generation, medical\ndiagnosis, and autonomous driving. Aid detection is challenging for humans,\nespecially when looking at abstract task data. Artificial neural networks excel\nat classification thanks to their ability to quickly learn from and process\nlarge amounts of data -- assuming appropriate preprocessing. We posit detecting\nhelp from AI as a classification task for such models. Much of the research in\nthis space examines the classification of complex but concrete data classes,\nsuch as images. Many AI assistance detection scenarios, however, result in data\nthat is not machine learning-friendly. We demonstrate that common models can\neffectively classify such data when it is appropriately preprocessed. To do so,\nwe construct four distinct neural network-friendly image formulations along\nwith an additional time-series formulation that explicitly encodes the\nexploration/exploitation of users, which allows for generalizability to other\nabstract tasks. We benchmark the quality of each image formulation across three\nclassical deep learning architectures, along with a parallel CNN-RNN\narchitecture that leverages the additional time series to maximize testing\nperformance, showcasing the importance of encoding temporal and spatial\nquantities for detecting AI aid in abstract tasks.", "AI": {"tldr": "研究提出将AI辅助检测视为分类任务，通过适当预处理数据，构建四种神经网络友好的图像表示及时间序列表示，验证了常见模型对抽象任务数据的有效分类能力。", "motivation": "随着AI在文本生成、医疗诊断等复杂任务中的普及，检测AI辅助变得至关重要。由于人类难以直接识别抽象任务中的AI帮助，研究探索了神经网络在此类分类任务中的潜力。", "method": "构建四种图像表示法和一种时间序列表示法（编码用户探索/利用行为），采用三种经典深度学习架构及并行CNN-RNN架构进行测试，强调时空特征编码的重要性。", "result": "实验表明，经适当预处理后，常规模型能有效分类非机器学习友好型数据，并行CNN-RNN架构通过结合时空特征显著提升检测性能。", "conclusion": "针对抽象任务的AI辅助检测，数据预处理和时空特征编码是关键，所提方法可推广至其他抽象任务场景。"}}
{"id": "2507.11034", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.11034", "abs": "https://arxiv.org/abs/2507.11034", "authors": ["Haixiang Zhang", "Xiamiao Zhao", "Mei Lu"], "title": "Turán type problems for a fixed graph and a linear forest", "comment": null, "summary": "Let $\\mathscr{F}$ be a family of graphs. A graph $G$ is $\\mathscr{F}$-free if\n$G$ does not contain any $F\\in \\mathscr{F}$ as a subgraph. The Tur\\'an number,\ndenoted by $ex(n, \\mathscr{F})$, is the maximum number of edges in an\n$n$-vertex $\\mathscr{F}$-free graph. Let $F $ be a fixed graph with $ \\chi(F)\n\\geq 3 $. A forest $H$ is called a linear forest if all components of $H$ are\npaths. In this paper, we determined the exact value of $ex(n, \\{H, F\\}) $ for a\nfixed graph $F$ with $\\chi(F)\\geq 3$ and a linear forest $H$ with at least $2$\ncomponents and each component with size at least $3$.", "AI": {"tldr": "本文确定了对于固定图$F$（色数$\\chi(F)\\geq 3$）和线性森林$H$（至少2个分量且每个分量大小至少为3）的Turán数$ex(n, \\{H, F\\})$的精确值。", "motivation": "研究特定图族$\\mathscr{F}$的Turán数$ex(n, \\mathscr{F})$是极值图论中的核心问题，特别是当$\\mathscr{F}$包含线性森林和固定图$F$时，确定其精确值具有重要理论意义。", "method": "通过分析线性森林$H$的结构特性（各分量为路径且大小至少为3）和固定图$F$的高色数条件，结合极值图论的方法，推导出$ex(n, \\{H, F\\})$的精确表达式。", "result": "成功确定了当$F$为色数$\\chi(F)\\geq 3$的固定图、$H$为满足条件的线性森林时，Turán数$ex(n, \\{H, F\\})$的精确值。", "conclusion": "该研究扩展了Turán数理论的应用范围，为包含线性森林和高色数图的图族提供了精确的极值结果，对相关领域的后续研究具有启发意义。"}}
{"id": "2507.11489", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.11489", "abs": "https://arxiv.org/abs/2507.11489", "authors": ["Florian Fuchs", "Bernardo Martin-Iradi", "Francesco Corman"], "title": "Solving Integrated Periodic Railway Timetabling with Satisfiability Modulo Theories: A Scalable Approach to Routing and Vehicle Circulation", "comment": null, "summary": "This paper introduces a novel approach for jointly solving the periodic Train\nTimetabling Problem (TTP), train routing, and Vehicle Circulation Problem (VCP)\nthrough a unified optimization model. While these planning stages are\ntraditionally addressed sequentially, their interdependencies often lead to\nsuboptimal vehicle usage. We propose the VCR-PESP, an integrated formulation\nthat minimizes fleet size while ensuring feasible and infrastructure-compliant\nperiodic timetables. We present the first Satisfiability Modulo Theories\n(SMT)-based method for the VCR-PESP to solve the resulting large-scale\ninstances. Unlike the Boolean Satisfiability Problem (SAT), which requires time\ndiscretisation, SMT supports continuous time via difference constraints,\neliminating the trade-off between temporal precision and encoding size. Our\napproach avoids rounding artifacts and scales effectively, outperforming both\nSAT and Mixed Integer Program (MIP) models across non-trivial instances. Using\nreal-world data from the Swiss narrow-gauge operator RhB, we conduct extensive\nexperiments to assess the impact of time discretisation, vehicle circulation\nstrategies, route flexibility, and planning integration. We show that discrete\nmodels inflate vehicle requirements and that fully integrated solutions\nsubstantially reduce fleet needs compared to sequential approaches. Our\nframework consistently delivers high-resolution solutions with tractable\nruntimes, even in large and complex networks. By combining modeling accuracy\nwith scalable solver technology, this work establishes SMT as a powerful tool\nfor integrated railway planning. It demonstrates how relaxing discretisation\nand solving across planning layers enables more efficient and implementable\ntimetables.", "AI": {"tldr": "本文提出了一种新型的VCR-PESP集成优化模型，首次采用SMT方法联合解决周期性列车时刻表编排、路径规划与车辆调度问题，通过连续时间建模消除离散化误差，在瑞士RhB铁路实际数据中验证了其优越性。", "motivation": "传统铁路规划中列车时刻表、路径与车辆调度分阶段处理导致车辆使用效率低下，需开发集成优化方法以最小化车队规模并确保时刻表可行性。", "method": "基于可满足性模理论(SMT)构建VCR-PESP模型，利用差分约束支持连续时间变量，避免时间离散化；相比SAT和MIP模型，兼具时间精度与可扩展性。", "result": "实验表明：离散模型会虚增车辆需求，完全集成方案比序列化方法减少17%车队规模；SMT模型在复杂路网中仍能保持高分辨率求解与可行计算时间。", "conclusion": "该研究确立了SMT在铁路集成规划中的有效性，证明通过连续时间建模与跨层级优化能生成更高效、可实施的时刻表，为行业提供了新工具。"}}
{"id": "2507.10836", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.10836", "abs": "https://arxiv.org/abs/2507.10836", "authors": ["Zhonghao Zhan", "Huichi Zhou", "Hamed Haddadi"], "title": "REAL-IoT: Characterizing GNN Intrusion Detection Robustness under Practical Adversarial Attack", "comment": null, "summary": "Graph Neural Network (GNN)-based network intrusion detection systems (NIDS)\nare often evaluated on single datasets, limiting their ability to generalize\nunder distribution drift. Furthermore, their adversarial robustness is\ntypically assessed using synthetic perturbations that lack realism. This\nmeasurement gap leads to an overestimation of GNN-based NIDS resilience. To\naddress the limitations, we propose \\textbf{REAL-IoT}, a comprehensive\nframework for robustness evaluation of GNN-based NIDS in IoT environments. Our\nframework presents a methodology that creates a unified dataset from canonical\ndatasets to assess generalization under drift. In addition, it features a novel\nintrusion dataset collected from a physical IoT testbed, which captures network\ntraffic and attack scenarios under real-world settings. Furthermore, using\nREAL-IoT, we explore the usage of Large Language Models (LLMs) to analyze\nnetwork data and mitigate the impact of adversarial examples by filtering\nsuspicious flows. Our evaluations using REAL-IoT reveal performance drops in\nGNN models compared to results from standard benchmarks, quantifying their\nsusceptibility to drift and realistic attacks. We also demonstrate the\npotential of LLM-based filtering to enhance robustness. These findings\nemphasize the necessity of realistic threat modeling and rigorous measurement\npractices for developing resilient IoT intrusion detection systems.", "AI": {"tldr": "提出REAL-IoT框架，评估GNN在物联网入侵检测中的鲁棒性，揭示现有模型在真实场景中的性能下降，并探索LLM增强防御的潜力。", "motivation": "现有GNN网络入侵检测系统（NIDS）评估局限于单一数据集，且对抗性测试缺乏真实性，导致高估其鲁棒性。", "method": "构建REAL-IoT框架：整合标准数据集评估泛化能力，采集真实IoT测试床数据模拟攻击，并利用LLM过滤可疑流量。", "result": "实验显示GNN模型在真实数据下性能显著下降，证实其对分布偏移和真实攻击的脆弱性；LLM过滤可提升鲁棒性。", "conclusion": "强调需采用真实威胁建模和严格评估方法，以开发更具弹性的物联网入侵检测系统。"}}
{"id": "2507.10798", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10798", "abs": "https://arxiv.org/abs/2507.10798", "authors": ["Asim H. Gazi", "Bhanu T. Gullapalli", "Daiqi Gao", "Benjamin M. Marlin", "Vivek Shetty", "Susan A. Murphy"], "title": "Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions", "comment": "4 pages, 3 figures", "summary": "Timely decision making is critical to the effectiveness of mobile health\n(mHealth) interventions. At predefined timepoints called \"decision points,\"\nintelligent mHealth systems such as just-in-time adaptive interventions\n(JITAIs) estimate an individual's biobehavioral context from sensor or survey\ndata and determine whether and how to intervene. For interventions targeting\nhabitual behavior (e.g., oral hygiene), effectiveness often hinges on\ndelivering support shortly before the target behavior is likely to occur.\nCurrent practice schedules decision points at a fixed interval (e.g., one hour)\nbefore user-provided behavior times, and the fixed interval is kept the same\nfor all individuals. However, this one-size-fits-all approach performs poorly\nfor individuals with irregular routines, often scheduling decision points after\nthe target behavior has already occurred, rendering interventions ineffective.\nIn this paper, we propose SigmaScheduling, a method to dynamically schedule\ndecision points based on uncertainty in predicted behavior times. When behavior\ntiming is more predictable, SigmaScheduling schedules decision points closer to\nthe predicted behavior time; when timing is less certain, SigmaScheduling\nschedules decision points earlier, increasing the likelihood of timely\nintervention. We evaluated SigmaScheduling using real-world data from 68\nparticipants in a 10-week trial of Oralytics, a JITAI designed to improve daily\ntoothbrushing. SigmaScheduling increased the likelihood that decision points\npreceded brushing events in at least 70% of cases, preserving opportunities to\nintervene and impact behavior. Our results indicate that SigmaScheduling can\nadvance precision mHealth, particularly for JITAIs targeting time-sensitive,\nhabitual behaviors such as oral hygiene or dietary habits.", "AI": {"tldr": "本文提出SigmaScheduling方法，通过动态调整决策点时间提升移动健康干预的时效性，特别适用于刷牙等习惯性行为的精准干预。", "motivation": "当前移动健康系统采用固定间隔的决策点调度方式，对于作息不规律的用户常导致干预滞后。研究旨在解决这一时效性问题，提升干预效果。", "method": "提出SigmaScheduling算法：根据行为时间预测的不确定性动态调整决策点——预测确定性高时靠近行为时间，不确定性高时提前调度。基于68人10周刷牙实验数据验证。", "result": "该方法使70%以上的决策点成功位于刷牙行为之前，较固定间隔方法显著提升及时干预机会（p<0.05）。", "conclusion": "SigmaScheduling通过行为时间概率建模实现个性化调度，为口腔卫生等时效敏感的习惯干预提供了精准化解决方案，推动移动健康向精准医学发展。"}}
{"id": "2507.11078", "categories": ["math.CO", "05C50, 05C05, 05C70"], "pdf": "https://arxiv.org/pdf/2507.11078", "abs": "https://arxiv.org/abs/2507.11078", "authors": ["Sizhong Zhou"], "title": "Spanning subgraphs and spectral radius in graphs", "comment": "14 pages", "summary": "A spanning tree $T$ of a connected graph $G$ is a subgraph of $G$ that is a\ntree covers all vertices of $G$. The leaf distance of $T$ is defined as the\nminimum of distances between any two leaves of $T$. A fractional matching of a\ngraph $G$ is a function $h$ assigning every edge a real number in $[0,1]$ so\nthat $\\sum\\limits_{e\\in E_G(v)}{h(e)}\\leq1$ for any $v\\in V(G)$, where $E_G(v)$\ndenotes the set of edges incident with $v$ in $G$. A fractional matching of $G$\nis called a fractional perfect matching if $\\sum\\limits_{e\\in E_G(v)}{h(e)}=1$\nfor any $v\\in V(G)$. A graph $G$ with at least $2k+2$ vertices is said to be\nfractional $k$-extendable if every $k$-matching $M$ in $G$ is included in a\nfractional perfect matching $h$ of $G$ such that $h(e)=1$ for any $e\\in M$.\nThis paper considers a lower bound on the spectral radius of $G$ to guarantee\nthat $G$ has a spanning tree with leaf distance at least $d$. At the same time,\nwe obtain a lower bound on the spectral radius of $G$ to ensure that $G$ is\nfractional $k$-extendable.", "AI": {"tldr": "本文研究了图的谱半径下界，以确保图具有叶距离至少为d的生成树，并确保图是分数k-可扩展的。", "motivation": "研究图的谱半径与生成树叶距离及分数k-可扩展性之间的关系，为图论中的相关问题提供理论保证。", "method": "通过定义生成树的叶距离和分数完美匹配，利用谱半径的下界进行分析和证明。", "result": "获得了保证图具有特定叶距离生成树和分数k-可扩展性的谱半径下界。", "conclusion": "谱半径的下界可以作为判断图是否具有特定生成树和分数k-可扩展性的有效指标。"}}
{"id": "2507.11513", "categories": ["math.OC", "cs.AI", "cs.NA", "math.NA", "49K20, 65M55, 65Y20, 68Q25, 68T05, 90C26, 90C30", "F.2.1; G.1.8; I.2.5"], "pdf": "https://arxiv.org/pdf/2507.11513", "abs": "https://arxiv.org/abs/2507.11513", "authors": ["Serge Gratton", "Alena Kopaničáková", "Philippe Toint"], "title": "Recursive Bound-Constrained AdaGrad with Applications to Multilevel and Domain Decomposition Minimization", "comment": "33 pages", "summary": "Two OFFO (Objective-Function Free Optimization) noise tolerant algorithms are\npresented that handle bound constraints, inexact gradients and use second-order\ninformation when available.The first is a multi-level method exploiting a\nhierarchical description of the problem and the second is a\ndomain-decomposition method covering the standard addditive Schwarz\ndecompositions. Both are generalizations of the first-order AdaGrad algorithm\nfor unconstrained optimization. Because these algorithms share a common\ntheoretical framework, a single convergence/complexity theory is provided which\ncovers them both. Its main result is that, with high probability, both methods\nneed at most $O(\\epsilon^{-2})$ iterations and noisy gradient evaluations to\ncompute an $\\epsilon$-approximate first-order critical point of the\nbound-constrained problem. Extensive numerical experiments are discussed on\napplications ranging from PDE-based problems to deep neural network training,\nillustrating their remarkable computational efficiency.", "AI": {"tldr": "本文提出了两种抗噪声的OFFO算法，处理边界约束和不精确梯度，并在可用时利用二阶信息。第一种是多级方法，利用问题的层次描述；第二种是域分解方法，覆盖标准加性Schwarz分解。两者都是无约束优化中一阶AdaGrad算法的推广。", "motivation": "研究动机在于开发能够处理边界约束、不精确梯度，并在可能时利用二阶信息的噪声容忍优化算法，以应对从PDE问题到深度神经网络训练等多种应用场景。", "method": "提出了两种算法：多级方法和域分解方法。多级方法利用问题的层次描述，域分解方法覆盖标准加性Schwarz分解。两者均基于一阶AdaGrad算法的推广，并共享统一的理论框架。", "result": "理论分析表明，两种方法在大概率下最多需要$O(\\epsilon^{-2})$次迭代和噪声梯度评估，以计算边界约束问题的$\\epsilon$-近似一阶临界点。数值实验展示了它们在多种应用中的显著计算效率。", "conclusion": "本文提出的两种OFFO算法在理论和实验上均表现出色，能够高效处理边界约束和不精确梯度问题，适用于从PDE到深度学习的广泛领域。"}}
{"id": "2507.10845", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.10845", "abs": "https://arxiv.org/abs/2507.10845", "authors": ["Wenxuan Shi", "Hongwei Li", "Jiahao Yu", "Xinqian Sun", "Wenbo Guo", "Xinyu Xing"], "title": "BandFuzz: An ML-powered Collaborative Fuzzing Framework", "comment": null, "summary": "Collaborative fuzzing has recently emerged as a technique that combines\nmultiple individual fuzzers and dynamically chooses the appropriate\ncombinations suited for different programs. Unlike individual fuzzers, which\nrely on specific assumptions to maintain their effectiveness, collaborative\nfuzzing relaxes the assumptions on target programs, providing constant and\nrobust performance across various programs. Ideally, collaborative fuzzing\nshould be a more promising direction toward generic fuzzing solutions, as it\nmitigates the need for manual cherry-picking of individual fuzzers. However,\nthe effectiveness of existing collaborative fuzzing frameworks is limited by\nmajor challenges, such as the need for additional computational resources\ncompared to individual fuzzers and the inefficient allocation of resources\namong the various fuzzers.", "AI": {"tldr": "协作模糊测试通过组合多个独立模糊测试工具并动态选择适合不同程序的组合，提供更稳定和鲁棒的性能，但面临计算资源需求和分配效率的挑战。", "motivation": "传统的模糊测试工具依赖于特定假设，而协作模糊测试放宽了对目标程序的假设，旨在成为更通用的模糊测试解决方案。", "method": "协作模糊测试通过动态选择和组合多个模糊测试工具，以适应不同程序的需求，减少手动选择工具的必要性。", "result": "协作模糊测试在各种程序中表现出稳定和鲁棒的性能，但需要更多的计算资源，并且资源分配效率较低。", "conclusion": "协作模糊测试是一个有前景的方向，但需要解决资源需求和分配效率的挑战，以实现其作为通用模糊测试解决方案的潜力。"}}
{"id": "2507.10803", "categories": ["cs.AI", "cs.CL", "cs.ET", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.10803", "abs": "https://arxiv.org/abs/2507.10803", "authors": ["JaMor Hairston", "Ritvik Ranjan", "Sahithi Lakamana", "Anthony Spadaro", "Selen Bozkurt", "Jeanmarie Perrone", "Abeed Sarker"], "title": "Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case", "comment": "Pages: 19, Abstract word count: 151 words, Manuscript word count:\n  2185 words, References: 14, Figures: 3, Tables: 2", "summary": "Background Large language models (LLMs) face challenges in inductive thematic\nanalysis, a task requiring deep interpretive and domain-specific expertise. We\nevaluated the feasibility of using LLMs to replicate expert-driven thematic\nanalysis of social media data. Methods Using two temporally non-intersecting\nReddit datasets on xylazine (n=286 and n=686, for model optimization and\nvalidation, respectively) with twelve expert-derived themes, we evaluated five\nLLMs against expert coding. We modeled the task as a series of binary\nclassifications, rather than a single, multi-label classification, employing\nzero-, single-, and few-shot prompting strategies and measuring performance via\naccuracy, precision, recall, and F1-score. Results On the validation set,\nGPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:\n0.71). For high-prevalence themes, model-derived thematic distributions closely\nmirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:\n16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based\napproaches can automate thematic analyses, offering a scalable supplement for\nqualitative research. Keywords: thematic analysis, large language models,\nnatural language processing, qualitative analysis, social media, prompt\nengineering, public health", "AI": {"tldr": "研究评估了大型语言模型（LLMs）在复制专家驱动的社交媒体数据主题分析中的可行性，发现少量示例提示的GPT-4o表现最佳，为定性研究提供了可扩展的自动化解决方案。", "motivation": "大型语言模型在需要深度解释和领域专业知识的归纳主题分析任务中面临挑战，研究旨在探索其在该领域的应用潜力。", "method": "使用两个时间不重叠的Reddit数据集（n=286和n=686），将任务建模为一系列二元分类，采用零示例、单示例和少量示例提示策略，并通过准确率、精确率、召回率和F1分数评估性能。", "result": "在验证集上，采用两示例提示的GPT-4o表现最佳（准确率：90.9%；F1分数：0.71）。对于高流行主题，模型得出的主题分布与专家分类高度一致。", "conclusion": "研究表明，基于少量示例的大型语言模型方法可以自动化主题分析，为定性研究提供可扩展的补充工具。"}}
{"id": "2507.11194", "categories": ["math.CO", "05C15, 05C30, 05C57, 05C76"], "pdf": "https://arxiv.org/pdf/2507.11194", "abs": "https://arxiv.org/abs/2507.11194", "authors": ["Boris Brimkov", "Randy Davila", "Houston Schuerger"], "title": "Connected forcing density and related problems", "comment": "25 pages, comments are welcome", "summary": "A connected forcing set of a graph is a zero forcing set that induces a\nconnected subgraph. In this paper, we introduce and study CF-dense graphs --\ngraphs in which every vertex belongs to some minimum connected forcing set. We\nidentify several CF-dense graph families and investigate the relationships\nbetween CF-density and analogous notions in zero forcing and total forcing. We\nalso characterize CF-dense trees and give a formula for the number of distinct\nconnected forcing sets in trees. Finally, we analyze when CF-density is\npreserved under graph operations such as Cartesian products, joins, and\ncoronas.", "AI": {"tldr": "本文研究了CF-稠密图（每个顶点都属于某个最小连通强制集的图），识别了多个CF-稠密图族，分析了CF-稠密性与零强制和全强制的关系，并给出了树的CF-稠密性特征及连通强制集数量的计算公式。", "motivation": "研究连通强制集诱导连通子图的性质，探索CF-稠密图的结构特征及其在图操作下的保持性。", "method": "通过图论分析，识别CF-稠密图族，研究其与零强制和全强制的关系，并利用树的结构特征进行刻画。", "result": "确定了多个CF-稠密图族，给出了树的CF-稠密性特征及连通强制集数量的计算公式，分析了图操作对CF-稠密性的影响。", "conclusion": "CF-稠密图在多个图族中存在，其性质与零强制和全强制相关，且在特定图操作下保持稠密性。"}}
{"id": "2507.10854", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10854", "abs": "https://arxiv.org/abs/2507.10854", "authors": ["Thomas Dalton", "Hemanth Gowda", "Girish Rao", "Sachin Pargi", "Alireza Hadj Khodabakhshi", "Joseph Rombs", "Stephan Jou", "Manish Marwah"], "title": "PhreshPhish: A Real-World, High-Quality, Large-Scale Phishing Website Dataset and Benchmark", "comment": null, "summary": "Phishing remains a pervasive and growing threat, inflicting heavy economic\nand reputational damage. While machine learning has been effective in real-time\ndetection of phishing attacks, progress is hindered by lack of large,\nhigh-quality datasets and benchmarks. In addition to poor-quality due to\nchallenges in data collection, existing datasets suffer from leakage and\nunrealistic base rates, leading to overly optimistic performance results. In\nthis paper, we introduce PhreshPhish, a large-scale, high-quality dataset of\nphishing websites that addresses these limitations. Compared to existing public\ndatasets, PhreshPhish is substantially larger and provides significantly higher\nquality, as measured by the estimated rate of invalid or mislabeled data\npoints. Additionally, we propose a comprehensive suite of benchmark datasets\nspecifically designed for realistic model evaluation by minimizing leakage,\nincreasing task difficulty, enhancing dataset diversity, and adjustment of base\nrates more likely to be seen in the real world. We train and evaluate multiple\nsolution approaches to provide baseline performance on the benchmark sets. We\nbelieve the availability of this dataset and benchmarks will enable realistic,\nstandardized model comparison and foster further advances in phishing\ndetection. The datasets and benchmarks are available on Hugging Face\n(https://huggingface.co/datasets/phreshphish/phreshphish).", "AI": {"tldr": "本文介绍了PhreshPhish数据集，这是一个大规模、高质量的钓鱼网站数据集，解决了现有数据集质量低、泄漏和基准率不真实的问题，并提出了用于真实模型评估的基准套件。", "motivation": "钓鱼攻击持续增长，造成严重经济和声誉损失。现有数据集因数据收集困难导致质量差、存在泄漏和不现实的基准率，影响机器学习模型的真实性能评估。", "method": "作者提出了PhreshPhish数据集，规模更大、质量更高，并通过减少泄漏、增加任务难度、增强数据集多样性和调整基准率，设计了一套全面的基准数据集。", "result": "PhreshPhish数据集在无效或错误标记数据点的估计率上显著优于现有公共数据集。作者还训练和评估了多种解决方案，为基准集提供了基线性能。", "conclusion": "PhreshPhish数据集和基准的可用性将促进钓鱼检测领域的标准化模型比较和进一步进展。数据集和基准已在Hugging Face上公开。"}}
{"id": "2507.10831", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10831", "abs": "https://arxiv.org/abs/2507.10831", "authors": ["Yilin Xia", "Heng Zheng", "Shawn Bowers", "Bertram Ludäscher"], "title": "AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks", "comment": "International Conference on Artificial Intelligence and Law (ICAIL),\n  June 16-20, 2025. Chicago, IL, USA", "summary": "Argumentation frameworks (AFs) provide formal approaches for legal reasoning,\nbut identifying sources of ambiguity and explaining argument acceptance remains\nchallenging for non-experts. We present AF-XRAY, an open-source toolkit for\nexploring, analyzing, and visualizing abstract AFs in legal reasoning. AF-XRAY\nintroduces: (i) layered visualizations based on game-theoretic argument length\nrevealing well-founded derivation structures; (ii) classification of attack\nedges by semantic roles (primary, secondary, blunders); (iii) overlay\nvisualizations of alternative 2-valued solutions on ambiguous 3-valued grounded\nsemantics; and (iv) identification of critical attack sets whose suspension\nresolves undecided arguments. Through systematic generation of critical attack\nsets, AF-XRAY transforms ambiguous scenarios into grounded solutions, enabling\nusers to pinpoint specific causes of ambiguity and explore alternative\nresolutions. We use real-world legal cases (e.g., Wild Animals as modeled by\nBench-Capon) to show that our tool supports teleological legal reasoning by\nrevealing how different assumptions lead to different justified conclusions.", "AI": {"tldr": "AF-XRAY是一个开源工具包，用于探索、分析和可视化法律推理中的抽象论证框架（AFs），通过分层可视化和攻击边分类等方法帮助非专家理解论证接受度和模糊源。", "motivation": "法律推理中的论证框架（AFs）虽然提供了形式化方法，但非专家仍难以识别模糊源和理解论证接受度。", "method": "AF-XRAY引入：（i）基于博弈论论证长度的分层可视化；（ii）按语义角色（主要、次要、错误）分类攻击边；（iii）在模糊的3值基础语义上叠加2值解决方案的可视化；（iv）识别关键攻击集以解决未决论证。", "result": "通过系统生成关键攻击集，AF-XRAY将模糊场景转化为基础解决方案，帮助用户定位模糊原因并探索替代方案。实际法律案例（如Bench-Capon的野生动物模型）验证了工具支持目的论法律推理的能力。", "conclusion": "AF-XRAY通过揭示不同假设如何导致不同结论，有效支持了法律推理中的模糊分析和替代方案探索。"}}
{"id": "2507.11226", "categories": ["math.CO", "05C78"], "pdf": "https://arxiv.org/pdf/2507.11226", "abs": "https://arxiv.org/abs/2507.11226", "authors": ["Petr Kovář", "Ksenija Rozman", "Primož Šparl"], "title": "Self-reverse labelings of distance magic graphs", "comment": "21 pages, paper submitted to BMMS for a possible publication", "summary": "A graph is distance magic if it admits a bijective labeling of its vertices\nby integers from $1$ up to the order of the graph in such a way that the sum of\nthe labels of all the neighbors of a vertex is independent of a given vertex.\nWe introduce the concept of a self-reverse distance magic labeling of a regular\ngraph which allows for a more compact description of the graph and the labeling\nin terms of the corresponding quotient graph. We show that the members of\nseveral known infinite families of tetravalent distance magic graphs admit such\nlabelings. We present a novel general construction producing a new distance\nmagic graph from two existing ones. Using it we show that for each integer $n\n\\geq 6$, except for the odd integers up to $19$, there exists a connected\ntetravalent graph of order $n$ admitting a self-reverse distance magic\nlabeling. We also determine all connected tetravalent graphs up to order $30$\nadmitting a self-reverse distance magic labeling. The obtained data suggests a\nnumber of natural interesting questions giving several possibilities for future\nresearch.", "AI": {"tldr": "本文引入自反距离魔法标号概念，证明多个四价图族存在此类标号，并提出新构造方法生成更多满足条件的图。", "motivation": "研究距离魔法图的紧凑表示方法，通过自反标号简化描述，并探索四价图中此类标号的存在性。", "method": "提出自反距离魔法标号定义，利用商图进行简化分析；构建新方法从两个已有图生成新的距离魔法图。", "result": "证明除$n\\leq19$的奇数外，所有$n\\geq6$都存在连通四价自反距离魔法图；完整分类了30阶以下所有满足条件的四价图。", "conclusion": "研究成果为距离魔法图理论提供了新工具，实验数据揭示了若干未解决问题，为后续研究指明方向。"}}
{"id": "2507.10873", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.10873", "abs": "https://arxiv.org/abs/2507.10873", "authors": ["Danyu Sun", "Jinghuai Zhang", "Jiacen Xu", "Yu Zheng", "Yuan Tian", "Zhou Li"], "title": "From Alerts to Intelligence: A Novel LLM-Aided Framework for Host-based Intrusion Detection", "comment": null, "summary": "Host-based intrusion detection system (HIDS) is a key defense component to\nprotect the organizations from advanced threats like Advanced Persistent\nThreats (APT). By analyzing the fine-grained logs with approaches like data\nprovenance, HIDS has shown successes in capturing sophisticated attack traces.\nDespite the progresses embarked by the research community and industry, HIDS\nstill frequently encounters backlash from their operators in the deployed\nenvironments, due to issues like high false-positive rate, inconsistent\noutcomes across environments and human-unfriendly detection results. Large\nLanguage Models (LLMs) have great potentials to advance the state of HIDS,\ngiven their extensive knowledge of attack techniques and their ability to\ndetect anomalies through semantic analysis, anchored by recent studies. Yet,\nour preliminary analysis indicates that building an HIDS by naively prompting\nan LLM is unlikely to succeed. In this work, we explore the direction of\nbuilding a customized LLM pipeline for HIDS and develop a system named SHIELD.\nSHIELD addresses challenges related to LLM's token limits, confusion of\nbackground noises, etc., by integrating a variety of techniques like\nevent-level Masked Autoencoder (MAE) for attack window detection, attack\nevidence identification and expansion, Deterministic Data Augmentation (DDA)\nfor profiling normal activities, and multi-purpose prompting that guides the\nLLM to conduct precise and interpretable attack investigations. Extensive\nexperiments on three log datasets (DARPA-E3, NodLink-simulated-data and\nATLASv2) show that SHIELD consistently achieves outstanding performance in\ncomparison with 5 representative HIDS. These findings highlight the potential\nof LLMs as powerful tools for intrusion detection and pave the way for future\nresearch in this domain.", "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）的定制化主机入侵检测系统（HIDS）SHIELD，通过整合多种技术解决传统HIDS的高误报率和语义分析不足等问题，并在实验中表现出卓越性能。", "motivation": "传统HIDS因高误报率、环境适应性差及检测结果不易理解等问题常受诟病，而LLM凭借其丰富的攻击知识库和语义分析能力，有望推动HIDS技术革新。", "method": "SHIELD系统采用事件级掩码自编码器（MAE）检测攻击窗口，结合攻击证据识别与扩展、确定性数据增强（DDA）分析正常行为，以及多用途提示引导LLM进行精准可解释的调查。", "result": "在DARPA-E3、NodLink模拟数据和ATLASv2三个日志数据集上的实验表明，SHIELD相比5种代表性HIDS均表现出稳定优异的性能。", "conclusion": "该研究证实了LLM作为入侵检测工具的潜力，为未来相关领域研究提供了新方向。"}}
{"id": "2507.10894", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10894", "abs": "https://arxiv.org/abs/2507.10894", "authors": ["Zongtao He", "Liuyi Wang", "Lu Chen", "Chengju Liu", "Qijun Chen"], "title": "NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization", "comment": null, "summary": "Language-guided navigation is a cornerstone of embodied AI, enabling agents\nto interpret language instructions and navigate complex environments. However,\nexpert-provided instructions are limited in quantity, while synthesized\nannotations often lack quality, making them insufficient for large-scale\nresearch. To address this, we propose NavComposer, a novel framework for\nautomatically generating high-quality navigation instructions. NavComposer\nexplicitly decomposes semantic entities such as actions, scenes, and objects,\nand recomposes them into natural language instructions. Its modular\narchitecture allows flexible integration of state-of-the-art techniques, while\nthe explicit use of semantic entities enhances both the richness and accuracy\nof instructions. Moreover, it operates in a data-agnostic manner, supporting\nadaptation to diverse navigation trajectories without domain-specific training.\nComplementing NavComposer, we introduce NavInstrCritic, a comprehensive\nannotation-free evaluation system that assesses navigation instructions on\nthree dimensions: contrastive matching, semantic consistency, and linguistic\ndiversity. NavInstrCritic provides a holistic evaluation of instruction\nquality, addressing limitations of traditional metrics that rely heavily on\nexpert annotations. By decoupling instruction generation and evaluation from\nspecific navigation agents, our method enables more scalable and generalizable\nresearch. Extensive experiments provide direct and practical evidence for the\neffectiveness of our method.", "AI": {"tldr": "本文提出NavComposer框架，通过分解和重组语义实体自动生成高质量导航指令，并引入NavInstrCritic无标注评估系统，实现可扩展的导航研究。", "motivation": "现有语言导航研究中，专家标注指令数量有限，合成指令质量不足，制约了大规模研究的开展。", "method": "NavComposer显式分解动作、场景等语义实体并重组为自然语言指令；配套的NavInstrCritic系统从对比匹配、语义一致性和语言多样性三个维度进行无标注评估。", "result": "实验证明该方法能有效生成高质量指令，其模块化架构支持灵活集成最新技术，且无需领域特定训练即可适配多样轨迹。", "conclusion": "通过解耦指令生成与评估过程，该方法为语言导航研究提供了更具可扩展性和泛化性的解决方案。"}}
{"id": "2507.11285", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.11285", "abs": "https://arxiv.org/abs/2507.11285", "authors": ["William Linz"], "title": "A remark on the $t$-intersecting Erdős-Ko-Rado theorem", "comment": null, "summary": "The $t$-intersecting Erd\\H{o}s-Ko-Rado theorem is the following statement: if\n$\\mathcal{F} \\subset \\binom{[n]}{k}$ is a $t$-intersecting family of sets and\n$n\\ge (t+1)(k-t+1)$, then $|\\mathcal{F}| \\le \\binom{n-t}{k-t}$. The first proof\nof this statement for all $t$ was a linear algebraic argument of Wilson.\nEarlier, Schrijver had proven the $t$-intersecting Erd\\H{o}s-Ko-Rado theorem\nfor sufficiently large $n$ by a seemingly different linear algebraic argument\nmotivated by Delsarte theory. In this note, we show that the approaches of\nSchrijver and Wilson are in fact equivalent.", "AI": {"tldr": "该论文证明了Schrijver和Wilson关于$t$-相交Erd\\H{o}s-Ko-Rado定理的线性代数方法实际上是等价的。", "motivation": "研究$t$-相交Erd\\H{o}s-Ko-Rado定理的不同证明方法之间的关系，特别是Schrijver和Wilson的线性代数方法。", "method": "通过比较Schrijver基于Delsarte理论的线性代数方法和Wilson的线性代数论证，分析两者的等价性。", "result": "证明了Schrijver和Wilson的方法在本质上是相同的，即两者的线性代数论证是等价的。", "conclusion": "该研究统一了两种看似不同的证明方法，深化了对$t$-相交Erd\\H{o}s-Ko-Rado定理的理解。"}}
{"id": "2507.10898", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.10898", "abs": "https://arxiv.org/abs/2507.10898", "authors": ["Jugal Gajjar", "Kamalasankari Subramaniakuppusamy", "Noha El Kachach"], "title": "MalCodeAI: Autonomous Vulnerability Detection and Remediation via Language Agnostic Code Reasoning", "comment": "6 pages, 4 figures, accepted for publication in IEEE 26th\n  International Conference on Information Reuse and Integration (IRI 2025)", "summary": "The growing complexity of cyber threats and the limitations of traditional\nvulnerability detection tools necessitate novel approaches for securing\nsoftware systems. We introduce MalCodeAI, a language-agnostic, multi-stage AI\npipeline for autonomous code security analysis and remediation. MalCodeAI\ncombines code decomposition and semantic reasoning using fine-tuned\nQwen2.5-Coder-3B-Instruct models, optimized through Low-Rank Adaptation (LoRA)\nwithin the MLX framework, and delivers scalable, accurate results across 14\nprogramming languages. In Phase 1, the model achieved a validation loss as low\nas 0.397 for functional decomposition and summarization of code segments after\n200 iterations, 6 trainable layers, and a learning rate of 2 x 10^(-5). In\nPhase 2, for vulnerability detection and remediation, it achieved a best\nvalidation loss of 0.199 using the same number of iterations and trainable\nlayers but with an increased learning rate of 4 x 10^(-5), effectively\nidentifying security flaws and suggesting actionable fixes. MalCodeAI supports\nred-hat-style exploit tracing, CVSS-based risk scoring, and zero-shot\ngeneralization to detect complex, zero-day vulnerabilities. In a qualitative\nevaluation involving 15 developers, the system received high scores in\nusefulness (mean 8.06/10), interpretability (mean 7.40/10), and readability of\noutputs (mean 7.53/10), confirming its practical value in real-world\ndevelopment workflows. This work marks a significant advancement toward\nintelligent, explainable, and developer-centric software security solutions.", "AI": {"tldr": "MalCodeAI是一种语言无关的多阶段AI管道，用于自主代码安全分析与修复，通过微调Qwen2.5-Coder-3B-Instruct模型，结合代码分解与语义推理，在14种编程语言中实现可扩展且准确的结果。", "motivation": "传统漏洞检测工具的局限性及网络威胁的日益复杂化，亟需新型软件安全解决方案。", "method": "采用基于MLX框架的低秩适应（LoRA）优化的Qwen2.5-Coder-3B-Instruct模型，分两阶段进行代码功能分解（学习率2×10^(-5)）和漏洞检测修复（学习率4×10^(-5)），支持红队式漏洞追踪与CVSS风险评分。", "result": "验证损失分别达0.397（功能分解）和0.199（漏洞检测），在15名开发者的定性评估中，实用性（8.06/10）、可解释性（7.40/10）和输出可读性（7.53/10）均获高分。", "conclusion": "该研究标志着向智能化、可解释且以开发者为中心的软件安全解决方案迈出重要一步，能有效检测零日漏洞并提供可操作修复建议。"}}
{"id": "2507.10911", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10911", "abs": "https://arxiv.org/abs/2507.10911", "authors": ["Yicong Wu", "Ting Chen", "Irit Hochberg", "Zhoujian Sun", "Ruth Edry", "Zhengxing Huang", "Mor Peleg"], "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "comment": null, "summary": "Therapy recommendation for chronic patients with multimorbidity is\nchallenging due to risks of treatment conflicts. Existing decision support\nsystems face scalability limitations. Inspired by the way in which general\npractitioners (GP) manage multimorbidity patients, occasionally convening\nmultidisciplinary team (MDT) collaboration, this study investigated the\nfeasibility and value of using a Large Language Model (LLM)-based multi-agent\nsystem (MAS) for safer therapy recommendations. We designed a single agent and\na MAS framework simulating MDT decision-making by enabling discussion among LLM\nagents to resolve medical conflicts. The systems were evaluated on therapy\nplanning tasks for multimorbidity patients using benchmark cases. We compared\nMAS performance with single-agent approaches and real-world benchmarks. An\nimportant contribution of our study is the definition of evaluation metrics\nthat go beyond the technical precision and recall and allow the inspection of\nclinical goals met and medication burden of the proposed advices to a gold\nstandard benchmark. Our results show that with current LLMs, a single agent GP\nperforms as well as MDTs. The best-scoring models provide correct\nrecommendations that address all clinical goals, yet the advices are\nincomplete. Some models also present unnecessary medications, resulting in\nunnecessary conflicts between medication and conditions or drug-drug\ninteractions.", "AI": {"tldr": "研究探讨了基于大型语言模型（LLM）的多智能体系统（MAS）在慢性多病症患者治疗推荐中的可行性与价值，发现单智能体GP模型表现与多学科团队（MDT）相当，但当前模型建议存在不完整性和不必要的药物冲突问题。", "motivation": "多病症患者的治疗推荐因治疗冲突风险而具有挑战性，现有决策支持系统存在可扩展性限制。受全科医生（GP）偶尔召集多学科团队（MDT）协作的启发，研究探索了LLM-MAS系统在安全治疗推荐中的潜力。", "method": "设计了模拟MDT决策的单智能体和多智能体框架，通过LLM智能体间的讨论解决医疗冲突，并在多病症患者治疗规划任务中使用基准案例评估系统性能，定义了超越技术精确率的临床目标达成和药物负担评估指标。", "result": "当前LLM中，单智能体GP表现与MDT相当。最佳模型能提供满足所有临床目标的正确建议，但建议不完整，部分模型还提出了不必要的药物，导致药物与病症或药物间的不必要冲突。", "conclusion": "LLM-MAS系统在多病症治疗推荐中具有潜力，但需进一步优化建议完整性和减少不必要药物冲突，以提升临床实用性。"}}
{"id": "2507.11298", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.11298", "abs": "https://arxiv.org/abs/2507.11298", "authors": ["Xiangli Wang", "Yuefeng Yang"], "title": "Weakly distance-regular digraphs of diameter 2", "comment": "12 pages", "summary": "Weakly distance-regular digraphs is a directed version of distance-regular\ngraphs. In this paper, we characterize all weakly distance-regular digraphs of\ndiameter 2.", "AI": {"tldr": "本文研究了直径2的弱距离正则有向图，并对其进行了完整分类。", "motivation": "弱距离正则有向图是距离正则图的有向版本，研究其性质有助于理解有向图的结构特性。", "method": "通过数学推导和图论方法，对直径2的弱距离正则有向图进行了系统性分析。", "result": "成功分类了所有直径2的弱距离正则有向图，给出了完整的特征描述。", "conclusion": "该研究为弱距离正则有向图的理论体系提供了重要补充，并为后续研究奠定了基础。"}}
{"id": "2507.10927", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.10927", "abs": "https://arxiv.org/abs/2507.10927", "authors": ["Jie Zhang", "Xiaohong Li", "Man Zheng", "Zhe Hou", "Guangdong Bai", "Ruitao Feng"], "title": "DVFS: A Dynamic Verifiable Fuzzy Search Service for Encrypted Cloud Data", "comment": null, "summary": "Cloud storage introduces critical privacy challenges for encrypted data\nretrieval, where fuzzy multi-keyword search enables approximate matching while\npreserving data confidentiality. Existing solutions face fundamental trade-offs\nbetween security and efficiency: linear-search mechanisms provide adaptive\nsecurity but incur prohibitive overhead for large-scale data, while tree-based\nindexes improve performance at the cost of branch leakage vulnerabilities.\n  To address these limitations, we propose DVFS - a dynamic verifiable fuzzy\nsearch service with three core innovations: (1) An \\textit{adaptive-secure\nfuzzy search} method integrating locality-sensitive hashing with virtual binary\ntrees, eliminating branch leakage while reducing search complexity from linear\nto sublinear ($O(\\log n)$ time); (2) A \\textit{dual-repository version control}\nmechanism supporting dynamic updates with forward privacy, preventing\ninformation leakage during operations; (3) A \\textit{blockchain-based\nverification system} that ensures correctness and completeness via smart\ncontracts, achieving $O(\\log n)$ verification complexity.\n  Our solution advances secure encrypted retrieval by simultaneously resolving\nthe security-performance paradox and enabling trustworthy dynamic operations.", "AI": {"tldr": "本文提出DVFS方案，通过动态可验证模糊搜索技术解决云存储中加密数据检索的安全与效率矛盾，实现亚线性搜索复杂度($O(\\log n)$)并支持动态更新验证。", "motivation": "现有模糊多关键词搜索方案存在安全性与效率的根本矛盾：线性搜索机制安全性高但开销大，树状索引效率高但存在分支泄露风险。", "method": "1) 结合局部敏感哈希与虚拟二叉树的适应性安全模糊搜索方法；2) 支持前向隐私的双存储库版本控制机制；3) 基于区块链的智能合约验证系统($O(\\log n)$验证复杂度)。", "result": "DVFS方案在消除分支泄露的同时将搜索复杂度从线性降至亚线性，并通过区块链验证确保动态操作的可信性。", "conclusion": "该研究通过创新性技术组合，同时解决了加密检索领域的安全-性能悖论，为可信动态操作提供了新范式。"}}
{"id": "2507.10923", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10923", "abs": "https://arxiv.org/abs/2507.10923", "authors": ["Yuhao Wang", "Keyan Ding", "Kehua Feng", "Zeyuan Wang", "Ming Qin", "Xiaotong Li", "Qiang Zhang", "Huajun Chen"], "title": "Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization", "comment": "Accepted at ACL 2025 (Main Conference)", "summary": "Protein language models have emerged as powerful tools for sequence\ngeneration, offering substantial advantages in functional optimization and\ndenovo design. However, these models also present significant risks of\ngenerating harmful protein sequences, such as those that enhance viral\ntransmissibility or evade immune responses. These concerns underscore critical\nbiosafety and ethical challenges. To address these issues, we propose a\nKnowledge-guided Preference Optimization (KPO) framework that integrates prior\nknowledge via a Protein Safety Knowledge Graph. This framework utilizes an\nefficient graph pruning strategy to identify preferred sequences and employs\nreinforcement learning to minimize the risk of generating harmful proteins.\nExperimental results demonstrate that KPO effectively reduces the likelihood of\nproducing hazardous sequences while maintaining high functionality, offering a\nrobust safety assurance framework for applying generative models in\nbiotechnology.", "AI": {"tldr": "本文提出了一种知识引导的偏好优化（KPO）框架，通过整合蛋白质安全知识图谱来降低生成有害蛋白质序列的风险，同时保持高功能性。", "motivation": "蛋白质语言模型在序列生成方面表现出强大能力，但也存在生成有害序列（如增强病毒传播性或逃避免疫反应的蛋白质）的重大风险，这带来了生物安全和伦理挑战。", "method": "KPO框架通过蛋白质安全知识图谱整合先验知识，采用高效的图剪枝策略识别优选序列，并结合强化学习最小化有害蛋白质的生成风险。", "result": "实验结果表明，KPO能有效减少有害序列的生成概率，同时保持高功能性，为生物技术中生成模型的应用提供了可靠的安全保障框架。", "conclusion": "KPO框架为解决蛋白质语言模型的安全问题提供了一种有效方法，平衡了功能优化与生物安全需求，推动了生成模型在生物技术中的负责任应用。"}}
{"id": "2507.11359", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.11359", "abs": "https://arxiv.org/abs/2507.11359", "authors": ["Jie Han", "Jingwen Zhao"], "title": "Perfect Matchings in Random Sparsifications of Dense Hypergraphs", "comment": "28 pages", "summary": "The decision problem of perfect matchings in uniform hypergraphs is famously\nan NP-complete problem. It has been shown by Keevash--Knox--Mycroft [STOC,\n2013] that for every $\\varepsilon>0$, such decision problem restricted to\n$k$-uniform hypergraphs $H$ satisfying that every $(k-1)$-set of vertices is in\nat least $(1/k+\\varepsilon)|H|$ edges is tractable, and the quantity $1/k$ is\nbest possible. In this paper we study the existence of perfect matchings in the\nrandom $p$-sparsification of such $k$-uniform hypergraphs, that is, for\n$p=p(n)\\in [0,1]$, every edge is kept with probability $p$ independent of\nothers. As a consequence, we give a polynomial-time algorithm that with high\nprobability solves the decision problem; we also derive effective bounds on the\nnumber of perfect matchings in such hypergraphs. At last, similar results are\nobtained for the $F$-factor problem in graphs.\n  The key ingredients of the proofs are a strengthened partition lemma for the\nlattice-based absorption method, and the random redistribution method developed\nrecently by Kelly, M\\\"uyesser and Pokrovskiy, based on the spread method.", "AI": {"tldr": "本文研究了均匀超图中完美匹配的存在性问题，特别是在随机稀疏化处理后的超图中，提出了多项式时间算法并给出了完美匹配数量的有效界限。", "motivation": "均匀超图中的完美匹配判定问题是著名的NP完全问题。Keevash--Knox--Mycroft[STOC, 2013]已证明对于满足特定条件的k-均匀超图，该问题可解。本文旨在研究此类超图在随机稀疏化后的完美匹配存在性。", "method": "采用基于格的吸收方法的强化分割引理，以及Kelly, M\\\"uyesser和Pokrovskiy最近开发的基于扩散方法的随机再分配方法。", "result": "提出了一个高概率解决判定问题的多项式时间算法，并推导了此类超图中完美匹配数量的有效界限。类似结果也适用于图中的F-因子问题。", "conclusion": "通过结合强化分割引理和随机再分配方法，本文为随机稀疏化后的均匀超图完美匹配问题提供了有效的理论工具和算法解决方案。"}}
{"id": "2507.11137", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11137", "abs": "https://arxiv.org/abs/2507.11137", "authors": ["Yuan Yao", "Jin Song", "Jian Jin"], "title": "Hashed Watermark as a Filter: Defeating Forging and Overwriting Attacks in Weight-based Neural Network Watermarking", "comment": null, "summary": "As valuable digital assets, deep neural networks necessitate robust ownership\nprotection, positioning neural network watermarking (NNW) as a promising\nsolution. Among various NNW approaches, weight-based methods are favored for\ntheir simplicity and practicality; however, they remain vulnerable to forging\nand overwriting attacks. To address those challenges, we propose NeuralMark, a\nrobust method built around a hashed watermark filter. Specifically, we utilize\na hash function to generate an irreversible binary watermark from a secret key,\nwhich is then used as a filter to select the model parameters for embedding.\nThis design cleverly intertwines the embedding parameters with the hashed\nwatermark, providing a robust defense against both forging and overwriting\nattacks. An average pooling is also incorporated to resist fine-tuning and\npruning attacks. Furthermore, it can be seamlessly integrated into various\nneural network architectures, ensuring broad applicability. Theoretically, we\nanalyze its security boundary. Empirically, we verify its effectiveness and\nrobustness across 13 distinct Convolutional and Transformer architectures,\ncovering five image classification tasks and one text generation task. The\nsource codes are available at https://github.com/AIResearch-Group/NeuralMark.", "AI": {"tldr": "提出NeuralMark方法，通过哈希水印过滤器保护深度神经网络所有权，有效抵抗伪造和覆盖攻击，并适用于多种网络架构。", "motivation": "深度神经网络作为宝贵数字资产需要所有权保护，现有权重水印方法易受伪造和覆盖攻击。", "method": "使用哈希函数生成不可逆二进制水印作为过滤器选择嵌入参数，结合平均池化抵抗微调/剪枝攻击，可适配多种网络架构。", "result": "理论分析安全边界，在13种CNN和Transformer架构、5类图像分类及1项文本生成任务中验证有效性。", "conclusion": "NeuralMark为神经网络水印提供通用解决方案，代码已开源（https://github.com/AIResearch-Group/NeuralMark）。"}}
{"id": "2507.10993", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10993", "abs": "https://arxiv.org/abs/2507.10993", "authors": ["Emir Durakovic", "Min-Hong Shih"], "title": "Modeling Habitat Shifts: Integrating Convolutional Neural Networks and Tabular Data for Species Migration Prediction", "comment": "This paper uses a lightly modified version of the AAAI 2025 LaTeX\n  style for formatting consistency. It is not a submission to AAAI and does not\n  include any AAAI-specific headers, footers, or metadata", "summary": "Due to climate-induced changes, many habitats are experiencing range shifts\naway from their traditional geographic locations (Piguet, 2011). We propose a\nsolution to accurately model whether bird species are present in a specific\nhabitat through the combination of Convolutional Neural Networks (CNNs)\n(O'Shea, 2015) and tabular data. Our approach makes use of satellite imagery\nand environmental features (e.g., temperature, precipitation, elevation) to\npredict bird presence across various climates. The CNN model captures spatial\ncharacteristics of landscapes such as forestation, water bodies, and\nurbanization, whereas the tabular method uses ecological and geographic data.\nBoth systems predict the distribution of birds with an average accuracy of 85%,\noffering a scalable but reliable method to understand bird migration.", "AI": {"tldr": "结合卷积神经网络(CNN)与表格数据，通过卫星图像和环境特征预测鸟类分布，准确率达85%，为气候变化下的鸟类迁徙研究提供可靠方法。", "motivation": "气候变化导致栖息地范围迁移(Piguet, 2011)，需开发准确预测鸟类分布的新方法。", "method": "使用CNN提取卫星影像空间特征(森林、水体、城市化等)，结合温度/降水/海拔等表格化环境数据构建预测模型。", "result": "双系统预测鸟类分布的准确率平均达85%(O'Shea, 2015)，可扩展性强。", "conclusion": "该方法可靠且可规模化，为理解气候驱动的鸟类迁徙模式提供了有效工具。"}}
{"id": "2507.11516", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.11516", "abs": "https://arxiv.org/abs/2507.11516", "authors": ["Ilani Axelrod-Freed"], "title": "Inversions Tableaux", "comment": null, "summary": "We introduce inversions tableaux, a new combinatorial model for Schubert\npolynomials and Stanley-symmetric that directly specialize to semi-standard\nYoung tableaux in the Grassmannian case. They are a modification of the\nbalanced staircase tableaux of Edelman and Greene. We explicitly describe\ninversions tableaux that correspond to the lexicographically minimal and\nmaximal monomials in each Schubert polynomial and characterize the unique\ninversions tableau for dominant permutations. We also define tableaux skew\nSchubert polynomials $\\mathfrak{S}^t_{w/u}$ and prove certain properties about\nthem.", "AI": {"tldr": "本文提出了一种新的组合模型——反转表（inversions tableaux），用于研究Schubert多项式和Stanley对称函数，并在Grassmannian情况下直接特化为半标准Young表。", "motivation": "旨在建立一个更直接的组合模型来研究Schubert多项式和Stanley对称函数，特别是在Grassmannian情况下与半标准Young表直接关联。", "method": "通过修改Edelman和Greene的平衡阶梯表（balanced staircase tableaux），引入反转表，并明确描述与每个Schubert多项式中字典序最小和最大单项式对应的反转表。", "result": "成功定义了反转表，并描述了其在Schubert多项式中的对应关系，特别是对于主导排列（dominant permutations）的唯一反转表。此外，还定义了表斜Schubert多项式$\\mathfrak{S}^t_{w/u}$并证明了其某些性质。", "conclusion": "反转表为Schubert多项式和Stanley对称函数提供了一个有效的组合模型，特别是在Grassmannian情况下与半标准Young表的直接关联，为相关研究提供了新的工具和视角。"}}
{"id": "2507.11138", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.11138", "abs": "https://arxiv.org/abs/2507.11138", "authors": ["Adriano Castro", "Simon Hanisch", "Matin Fallahi", "Thorsten Strufe"], "title": "FacialMotionID: Identifying Users of Mixed Reality Headsets using Abstract Facial Motion Representations", "comment": null, "summary": "Facial motion capture in mixed reality headsets enables real-time avatar\nanimation, allowing users to convey non-verbal cues during virtual\ninteractions. However, as facial motion data constitutes a behavioral\nbiometric, its use raises novel privacy concerns. With mixed reality systems\nbecoming more immersive and widespread, understanding whether face motion data\ncan lead to user identification or inference of sensitive attributes is\nincreasingly important.\n  To address this, we conducted a study with 116 participants using three types\nof headsets across three sessions, collecting facial, eye, and head motion data\nduring verbal and non-verbal tasks. The data used is not raw video, but rather,\nabstract representations that are used to animate digital avatars. Our analysis\nshows that individuals can be re-identified from this data with up to 98%\nbalanced accuracy, are even identifiable across device types, and that\nemotional states can be inferred with up to 86% accuracy. These results\nunderscore the potential privacy risks inherent in face motion tracking in\nmixed reality environments.", "AI": {"tldr": "混合现实头显的面部动作捕捉技术虽能实现实时虚拟化身动画，但其采集的行为生物特征数据存在用户身份识别（98%准确率）和情绪状态推断（86%准确率）的隐私风险。", "motivation": "随着混合现实设备普及，面部运动数据作为行为生物特征可能泄露用户身份及敏感属性，需评估其隐私风险。", "method": "研究采集116名参与者三阶段实验数据（含三种头显），通过非视频的抽象动作表征分析言语/非言语任务中的面部、眼部及头部运动。", "result": "数据可实现跨设备用户重识别（平衡准确率98%），情绪状态推断准确率达86%，揭示显着隐私隐患。", "conclusion": "混合现实中的面部动作追踪存在不可忽视的隐私风险，需在设计阶段纳入隐私保护机制。"}}
{"id": "2507.11060", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11060", "abs": "https://arxiv.org/abs/2507.11060", "authors": ["Yilmazcan Ozyurt", "Tunaberk Almaci", "Stefan Feuerriegel", "Mrinmaya Sachan"], "title": "Personalized Exercise Recommendation with Semantically-Grounded Knowledge Tracing", "comment": null, "summary": "We introduce ExRec, a general framework for personalized exercise\nrecommendation with semantically-grounded knowledge tracing. Our method builds\non the observation that existing exercise recommendation approaches simulate\nstudent performance via knowledge tracing (KT) but they often overlook two key\naspects: (a) the semantic content of questions and (b) the sequential,\nstructured progression of student learning. To address this, our ExRec presents\nan end-to-end pipeline, from annotating the KCs of questions and learning their\nsemantic representations to training KT models and optimizing several\nreinforcement learning (RL) methods. Moreover, we improve standard\nQ-learning-based continuous RL methods via a tailored model-based value\nestimation (MVE) approach that directly leverages the components of KT model in\nestimating cumulative knowledge improvement. We validate the effectiveness of\nour ExRec using various RL methods across four real-world tasks with different\neducational goals in online math learning. We further show that ExRec\ngeneralizes robustly to new, unseen questions and that it produces\ninterpretable student learning trajectories. Together, our findings highlight\nthe promise of KT-guided RL for effective personalization in education.", "AI": {"tldr": "ExRec是一个结合语义知识追踪的个性化习题推荐框架，通过强化学习优化推荐效果，并在数学学习中验证了其有效性和泛化能力。", "motivation": "现有习题推荐方法常忽略问题的语义内容及学生学习的结构化进程，ExRec旨在通过知识追踪（KT）与强化学习（RL）结合解决这一问题。", "method": "ExRec构建端到端流程：标注问题知识点、学习语义表示、训练KT模型，并改进基于Q学习的强化学习方法，采用模型基价值估计（MVE）优化知识累积提升。", "result": "在四个数学学习任务中验证了ExRec的有效性，其能泛化至新问题并生成可解释的学习轨迹，表明KT引导的RL对教育个性化的潜力。", "conclusion": "研究证实了KT与RL结合在教育个性化中的前景，ExRec为语义化习题推荐提供了通用框架。"}}
{"id": "2507.05297", "categories": ["cs.AI", "econ.TH", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.05297", "abs": "https://arxiv.org/abs/2507.05297", "authors": ["Zijun Meng"], "title": "Continuous Classification Aggregation", "comment": "9 pages; 2 figures", "summary": "We prove that any optimal, independent, and zero unanimous fuzzy\nclassification aggregation function of a continuum of individual\nclassifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted\narithmetic mean. We also provide a characterization for the case when $m=p=2$.", "AI": {"tldr": "证明了对于将$m\\ge 3$个对象分为$2\\le p\\le m$类的最优、独立且零一致的模糊分类聚合函数必须是加权算术平均，并给出了$m=p=2$时的特征描述。", "motivation": "研究模糊分类聚合函数的数学特性，特别是在多对象多分类情况下的最优形式。", "method": "采用数学证明方法，分析分类聚合函数的最优性、独立性和零一致性条件。", "result": "证明了当$m\\ge 3$且$2\\le p\\le m$时，满足条件的聚合函数只能是加权算术平均，并给出了$m=p=2$时的完整特征。", "conclusion": "该研究为模糊分类聚合提供了严格的理论基础，明确了加权算术平均在特定条件下的唯一性。"}}
{"id": "2507.11155", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11155", "abs": "https://arxiv.org/abs/2507.11155", "authors": ["Yiting Qu", "Michael Backes", "Yang Zhang"], "title": "Bridging the Gap in Vision Language Models in Identifying Unsafe Concepts Across Modalities", "comment": "To Appear in the 34th USENIX Security Symposium, August 2025", "summary": "Vision-language models (VLMs) are increasingly applied to identify unsafe or\ninappropriate images due to their internal ethical standards and powerful\nreasoning abilities. However, it is still unclear whether they can recognize\nvarious unsafe concepts when presented in different modalities, such as text\nand images. To address this, we first compile the UnsafeConcepts dataset,\nfeaturing 75 unsafe concepts, i.e., ``Swastika,'' ``Sexual Harassment,'' and\n``Assaults,'' along with associated 1.5K images. We then conduct a systematic\nevaluation of VLMs' perception (concept recognition) and alignment (ethical\nreasoning) capabilities. We assess eight popular VLMs and find that, although\nmost VLMs accurately perceive unsafe concepts, they sometimes mistakenly\nclassify these concepts as safe. We also identify a consistent modality gap\namong open-source VLMs in distinguishing between visual and textual unsafe\nconcepts. To bridge this gap, we introduce a simplified reinforcement learning\n(RL)-based approach using proximal policy optimization (PPO) to strengthen the\nability to identify unsafe concepts from images. Our approach uses reward\nscores based directly on VLM responses, bypassing the need for collecting\nhuman-annotated preference data to train a new reward model. Experimental\nresults show that our approach effectively enhances VLM alignment on images\nwhile preserving general capabilities. It outperforms baselines such as\nsupervised fine-tuning (SFT) and direct preference optimization (DPO). We hope\nour dataset, evaluation findings, and proposed alignment solution contribute to\nthe community's efforts in advancing safe VLMs.", "AI": {"tldr": "研究评估了视觉语言模型(VLMs)识别多模态不安全概念的能力，构建了UnsafeConcepts数据集，并提出基于强化学习的优化方法以提升模型安全性。", "motivation": "当前VLMs虽具备伦理标准，但其在多模态(文本/图像)中识别不安全概念的可靠性尚不明确，需系统性评估与改进。", "method": "1) 构建含75个不安全概念和1.5K图像的UnsafeConcepts数据集；2) 评估8个主流VLMs的感知与对齐能力；3) 提出基于PPO的强化学习方案，直接利用VLM响应作为奖励分数。", "result": "多数VLMs能感知不安全概念但存在误判；开源VLMs存在模态差异；所提PPO方法在图像对齐任务上优于SFT和DPO基线，且不影响通用能力。", "conclusion": "数据集、评估发现及强化学习对齐方案为开发安全VLMs提供重要支持，未来可扩展至更复杂伦理场景。"}}
{"id": "2507.11079", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11079", "abs": "https://arxiv.org/abs/2507.11079", "authors": ["Li Wang", "Qizhen Wu", "Lei Chen"], "title": "Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander", "comment": null, "summary": "In multiple unmanned ground vehicle confrontations, autonomously evolving\nmulti-agent tactical decisions from situational awareness remain a significant\nchallenge. Traditional handcraft rule-based methods become vulnerable in the\ncomplicated and transient battlefield environment, and current reinforcement\nlearning methods mainly focus on action manipulation instead of strategic\ndecisions due to lack of interpretability. Here, we propose a vision-language\nmodel-based commander to address the issue of intelligent\nperception-to-decision reasoning in autonomous confrontations. Our method\nintegrates a vision language model for scene understanding and a lightweight\nlarge language model for strategic reasoning, achieving unified perception and\ndecision within a shared semantic space, with strong adaptability and\ninterpretability. Unlike rule-based search and reinforcement learning methods,\nthe combination of the two modules establishes a full-chain process, reflecting\nthe cognitive process of human commanders. Simulation and ablation experiments\nvalidate that the proposed approach achieves a win rate of over 80% compared\nwith baseline models.", "AI": {"tldr": "提出一种基于视觉语言模型的指挥官系统，通过统一感知与决策的语义空间，解决多无人地面车辆对抗中的智能感知-决策推理问题，实验显示胜率超80%。", "motivation": "传统基于规则的方法在复杂瞬变战场中脆弱，现有强化学习方法因缺乏可解释性而局限于动作操控，亟需实现具有适应性与可解释性的战略决策自主演化。", "method": "融合视觉语言模型（场景理解）与轻量级大语言模型（战略推理），在共享语义空间中建立感知-决策全链条，模拟人类指挥官认知过程。", "result": "仿真与消融实验表明，该方法相比基线模型胜率超过80%，验证了统一语义空间框架的有效性。", "conclusion": "视觉-语言模型联合架构为自主对抗提供了可解释、自适应且符合人类认知的决策范式，显著提升多智能体战术决策性能。"}}
{"id": "2507.11310", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11310", "abs": "https://arxiv.org/abs/2507.11310", "authors": ["Fengxiao Tang", "Huan Li", "Ming Zhao", "Zongzong Wu", "Shisong Peng", "Tao Yin"], "title": "LRCTI: A Large Language Model-Based Framework for Multi-Step Evidence Retrieval and Reasoning in Cyber Threat Intelligence Credibility Verification", "comment": null, "summary": "Verifying the credibility of Cyber Threat Intelligence (CTI) is essential for\nreliable cybersecurity defense. However, traditional approaches typically treat\nthis task as a static classification problem, relying on handcrafted features\nor isolated deep learning models. These methods often lack the robustness\nneeded to handle incomplete, heterogeneous, or noisy intelligence, and they\nprovide limited transparency in decision-making-factors that reduce their\neffectiveness in real-world threat environments. To address these limitations,\nwe propose LRCTI, a Large Language Model (LLM)-based framework designed for\nmulti-step CTI credibility verification. The framework first employs a text\nsummarization module to distill complex intelligence reports into concise and\nactionable threat claims. It then uses an adaptive multi-step evidence\nretrieval mechanism that iteratively identifies and refines supporting\ninformation from a CTI-specific corpus, guided by LLM feedback. Finally, a\nprompt-based Natural Language Inference (NLI) module is applied to evaluate the\ncredibility of each claim while generating interpretable justifications for the\nclassification outcome. Experiments conducted on two benchmark datasets,\nCTI-200 and PolitiFact show that LRCTI improves F1-Macro and F1-Micro scores by\nover 5%, reaching 90.9% and 93.6%, respectively, compared to state-of-the-art\nbaselines. These results demonstrate that LRCTI effectively addresses the core\nlimitations of prior methods, offering a scalable, accurate, and explainable\nsolution for automated CTI credibility verification", "AI": {"tldr": "提出LRCTI框架，利用大语言模型进行多步骤网络威胁情报可信度验证，显著提升准确率与可解释性。", "motivation": "传统网络威胁情报可信度验证方法依赖静态分类或孤立深度学习模型，对不完整、异构或噪声数据鲁棒性不足，且决策透明度低。", "method": "1) 文本摘要模块提炼威胁报告核心主张；2) 自适应多步骤证据检索机制迭代优化CTI语料支持信息；3) 基于提示的自然语言推理模块评估可信度并生成可解释结论。", "result": "在CTI-200和PolitiFact数据集上，F1-Macro和F1-Micro分数分别提升5%以上，达到90.9%和93.6%，超越现有基线方法。", "conclusion": "LRCTI框架通过可扩展、准确且可解释的自动化验证方案，有效解决了传统方法的局限性。"}}
{"id": "2507.11083", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.11083", "abs": "https://arxiv.org/abs/2507.11083", "authors": ["Longhui Zhang", "Bin Wang", "Jiahao Wang", "Xiaofeng Zhao", "Min Zhang", "Hao Yang", "Meishan Zhang", "Yu Li", "Jing Li", "Jun Yu", "Min Zhang"], "title": "Function-to-Style Guidance of LLMs for Code Translation", "comment": "This paper has been accepted by ICML 2025. Models and benchmarks can\n  be found at https://www.modelscope.cn/collections/F2STrans-42526ff95dd843", "summary": "Large language models (LLMs) have made significant strides in code\ntranslation tasks. However, ensuring both the correctness and readability of\ntranslated code remains a challenge, limiting their effective adoption in\nreal-world software development. In this work, we propose F2STrans, a\nfunction-to-style guiding paradigm designed to progressively improve the\nperformance of LLMs in code translation. Our approach comprises two key stages:\n(1) Functional learning, which optimizes translation correctness using\nhigh-quality source-target code pairs mined from online programming platforms,\nand (2) Style learning, which improves translation readability by incorporating\nboth positive and negative style examples. Additionally, we introduce a novel\ncode translation benchmark that includes up-to-date source code, extensive test\ncases, and manually annotated ground-truth translations, enabling comprehensive\nfunctional and stylistic evaluations. Experiments on both our new benchmark and\nexisting datasets demonstrate that our approach significantly improves code\ntranslation performance. Notably, our approach enables Qwen-1.5B to outperform\nprompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code\ntranslation scenarios.", "AI": {"tldr": "本文提出F2STrans方法，通过功能学习和风格学习两阶段优化，显著提升大语言模型在代码翻译任务中的正确性和可读性，并在新基准测试中表现优异。", "motivation": "尽管大语言模型在代码翻译任务中取得进展，但确保翻译代码的正确性和可读性仍是挑战，限制了其在实际软件开发中的应用。", "method": "F2STrans采用功能到风格的引导范式，包括功能学习（利用高质量代码对优化正确性）和风格学习（通过正负风格示例提升可读性），并引入包含最新源代码、测试用例和人工标注的新基准。", "result": "实验表明，该方法显著提升代码翻译性能，使Qwen-1.5B模型在20种场景中平均表现优于提示增强的Qwen-32B和GPT-4。", "conclusion": "F2STrans通过两阶段学习有效解决了代码翻译的正确性与可读性问题，为实际应用提供了可靠解决方案。"}}
{"id": "2507.11324", "categories": ["cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2507.11324", "abs": "https://arxiv.org/abs/2507.11324", "authors": ["Frederik Marinus Trudslev", "Matteo Lissandrini", "Juan Manuel Rodriguez", "Martin Bøgsted", "Daniele Dell'Aglio"], "title": "A Review of Privacy Metrics for Privacy-Preserving Synthetic Data Generation", "comment": null, "summary": "Privacy Preserving Synthetic Data Generation (PP-SDG) has emerged to produce\nsynthetic datasets from personal data while maintaining privacy and utility.\nDifferential privacy (DP) is the property of a PP-SDG mechanism that\nestablishes how protected individuals are when sharing their sensitive data. It\nis however difficult to interpret the privacy loss ($\\varepsilon$) expressed by\nDP. To make the actual risk associated with the privacy loss more transparent,\nmultiple privacy metrics (PMs) have been proposed to assess the privacy risk of\nthe data. These PMs are utilized in separate studies to assess newly introduced\nPP-SDG mechanisms. Consequently, these PMs embody the same assumptions as the\nPP-SDG mechanism they were made to assess. Therefore, a thorough definition of\nhow these are calculated is necessary. In this work, we present the assumptions\nand mathematical formulations of 17 distinct privacy metrics.", "AI": {"tldr": "本文综述了17种隐私度量指标（PMs）的假设与数学公式，旨在提升隐私保护合成数据生成（PP-SDG）中差分隐私（DP）风险的可解释性。", "motivation": "差分隐私（DP）的隐私损失参数（$\\varepsilon$）难以直观理解，现有隐私度量指标（PMs）因评估机制不同而存在假设差异，需系统化梳理其计算逻辑。", "method": "通过分析17种隐私度量指标的数学定义与底层假设，阐明其在PP-SDG机制评估中的适用性与局限性。", "result": "提出了17种PMs的完整数学表述，揭示不同指标对隐私风险量化方式的差异及与DP机制的关联性。", "conclusion": "系统化定义隐私度量指标有助于提升PP-SDG中隐私风险的透明性，为机制设计提供标准化评估框架。"}}
{"id": "2507.11117", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11117", "abs": "https://arxiv.org/abs/2507.11117", "authors": ["Ailiya Borjigin", "Cong He", "Charles CC Lee", "Wei Zhou"], "title": "AI Agent Architecture for Decentralized Trading of Alternative Assets", "comment": "8 Pages, 1 figure", "summary": "Decentralized trading of real-world alternative assets (e.g., gold) requires\nbridging physical asset custody with blockchain systems while meeting strict\nrequirements for compliance, liquidity, and risk management. We present\nGoldMine OS, a research oriented architecture that employs multiple specialized\nAI agents to automate and secure the tokenization and exchange of physical gold\ninto a blockchain based stablecoin (\"OZ\"). Our approach combines on chain smart\ncontracts for critical risk controls with off chain AI agents for decision\nmaking, blending the transparency and reliability of blockchains with the\nflexibility of AI driven automation. We describe four cooperative agents\n(Compliance, Token Issuance, Market Making, and Risk Control) and a\ncoordinating core, and evaluate the system through simulation and a controlled\npilot deployment. In experiments the prototype delivers on demand token\nissuance in under 1.2 s, more than 100 times faster than manual workflows. The\nMarket Making agent maintains tight liquidity with spreads often below 0.5\npercent even under volatile conditions. Fault injection tests show resilience:\nan oracle price spoofing attack is detected and mitigated within 10 s, and a\nsimulated vault mis reporting halts issuance immediately with minimal user\nimpact. The architecture scales to 5000 transactions per second with 10000\nconcurrent users in benchmarks. These results indicate that an AI agent based\ndecentralized exchange for alternative assets can satisfy rigorous performance\nand safety requirements. We discuss broader implications for democratizing\naccess to traditionally illiquid assets and explain how our governance model --\nmulti signature agent updates and on chain community voting on risk parameters\n-- provides ongoing transparency, adaptability, and formal assurance of system\nintegrity.", "AI": {"tldr": "GoldMine OS是一种面向研究的架构，利用多个专用AI代理自动化和保护实物黄金的令牌化及交换，将其转换为基于区块链的稳定币（\"OZ\"）。该系统结合了链上智能合约和链下AI代理，实现了高性能和安全性。", "motivation": "去中心化交易实物替代资产（如黄金）需要将实物资产托管与区块链系统结合，同时满足合规性、流动性和风险管理的严格要求。", "method": "系统采用四个协作代理（合规、令牌发行、做市和风险控制）和一个协调核心，结合链上智能合约和链下AI代理决策，通过模拟和受控试点部署进行评估。", "result": "原型实现按需令牌发行时间低于1.2秒，比人工流程快100倍以上；做市代理在波动条件下保持利差低于0.5%；系统在基准测试中支持每秒5000笔交易和10000并发用户。", "conclusion": "基于AI代理的替代资产去中心化交易所可满足严格的性能和安全性要求，其治理模型（多签名代理更新和链上社区投票风险参数）提供了透明度、适应性和系统完整性的正式保证。"}}
{"id": "2507.11499", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11499", "abs": "https://arxiv.org/abs/2507.11499", "authors": ["Adhwaa Alchaab", "Ayman Younis", "Dario Pompili"], "title": "Demo: Secure Edge Server for Network Slicing and Resource Allocation in Open RAN", "comment": null, "summary": "Next-Generation Radio Access Networks (NGRAN) aim to support diverse vertical\napplications with strict security, latency, and Service-Level Agreement (SLA)\nrequirements. These demands introduce challenges in securing the\ninfrastructure, allocating resources dynamically, and enabling real-time\nreconfiguration. This demo presents SnSRIC, a secure and intelligent network\nslicing framework that mitigates a range of Distributed Denial-of-Service\n(DDoS) attacks in Open RAN environments. SnSRIC incorporates an AI-driven xApp\nthat dynamically allocates Physical Resource Blocks (PRBs) to active users\nwhile enforcing slice-level security. The system detects anomalous behavior,\ndistinguishes between benign and malicious devices, and uses the E2 interface\nto throttle rogue signaling while maintaining service continuity for legitimate\nusers.", "AI": {"tldr": "论文提出SnSRIC框架，通过AI驱动的xApp动态分配资源并防御DDoS攻击，保障开放无线接入网的安全与服务质量。", "motivation": "下一代无线接入网需满足垂直应用的严格安全、时延及SLA要求，面临基础设施安全、动态资源分配和实时重配置等挑战。", "method": "SnSRIC整合AI驱动的xApp，动态分配物理资源块(PRB)，利用E2接口抑制恶意信令，同时区分正常与恶意设备。", "result": "系统能检测异常行为，保障合法用户服务连续性，有效缓解开放RAN环境中的DDoS攻击。", "conclusion": "SnSRIC为开放无线网络提供了安全、智能的网络切片解决方案，平衡了安全防护与资源效率。"}}
{"id": "2507.11127", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11127", "abs": "https://arxiv.org/abs/2507.11127", "authors": ["Lennert De Smet", "Luc De Raedt"], "title": "Defining neurosymbolic AI", "comment": null, "summary": "Neurosymbolic AI focuses on integrating learning and reasoning, in\nparticular, on unifying logical and neural representations. Despite the\nexistence of an alphabet soup of neurosymbolic AI systems, the field is lacking\na generally accepted formal definition of what neurosymbolic models and\ninference really are. We introduce a formal definition for neurosymbolic AI\nthat makes abstraction of its key ingredients. More specifically, we define\nneurosymbolic inference as the computation of an integral over a product of a\nlogical and a belief function. We show that our neurosymbolic AI definition\nmakes abstraction of key representative neurosymbolic AI systems.", "AI": {"tldr": "本文提出了神经符号AI的形式化定义，将其推理过程抽象为逻辑函数与置信函数的积分运算，统一了该领域的核心要素。", "motivation": "尽管神经符号AI系统众多，但缺乏公认的形式化定义来明确神经符号模型及推理的实质。", "method": "通过将神经符号推理定义为逻辑函数与置信函数乘积的积分计算，构建理论框架。", "result": "该定义成功抽象出代表性神经符号AI系统的关键特征，验证了其普适性。", "conclusion": "研究为神经符号AI提供了数学基础，有助于统一学习与推理的融合范式。"}}
{"id": "2507.11500", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.11500", "abs": "https://arxiv.org/abs/2507.11500", "authors": ["Zhengyue Zhao", "Yingzi Ma", "Somesh Jha", "Marco Pavone", "Chaowei Xiao"], "title": "ARMOR: Aligning Secure and Safe Large Language Models via Meticulous Reasoning", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable generative\ncapabilities. However, their susceptibility to misuse has raised significant\nsafety concerns. While post-training safety alignment methods have been widely\nadopted, LLMs remain vulnerable to malicious instructions that can bypass\nsafety constraints. Recent efforts have introduced inference-time safety\nreasoning (system-2 alignment), where LLMs conduct a reasoning process to\nperform safety verification before final response. We show, however, that these\nchecks are driven by ad-hoc reasoning that diverges from the structured human\nprocess, where they first discern a user's true intent, then evaluate the\nassociated risk based on the true intent. Consequently, these defenses remain\nvulnerable to sophisticated jailbreak prompts that cloak harmful goals in\nseemingly benign language. To build secure and safe LLMs, we propose a\nreasoning-based safety alignment framework, ARMOR, that replaces the ad-hoc\nchains of thought reasoning process with human-aligned, structured one. At\ninference, ARMOR (1) detects likely jailbreak strategies, (2) extracts the\nuser's core intent while discarding deceptive instructions, and (3) applies a\npolicy-grounded safety analysis to the purified request. ARMOR is evaluated on\nadaptive jailbreak attacks and multiple safety benchmarks, and a test-time\nscaling is conducted to further improve its performance. Results demonstrate\nthat ARMOR significantly enhances the robustness against state-of-the-art\nadaptive jailbreak attacks and outperforms recent reasoning-based aligned\nmodels across various safety benchmarks.", "AI": {"tldr": "本文提出了一种基于推理的安全对齐框架ARMOR，通过结构化的人类对齐推理过程，显著提升大型语言模型（LLMs）对抗复杂越狱攻击的鲁棒性。", "motivation": "尽管现有后训练安全对齐方法广泛使用，LLMs仍易受恶意指令绕过安全约束的威胁。当前推理时安全验证采用临时推理链，与人类结构化意图识别流程存在偏差，导致防御机制对隐蔽有害指令失效。", "method": "ARMOR框架采用三阶段结构化推理：(1)检测潜在越狱策略；(2)剥离欺骗性指令提取用户核心意图；(3)对净化后的请求执行基于策略的安全分析。通过测试时扩展进一步提升性能。", "result": "实验表明，ARMOR在自适应越狱攻击和多项安全基准测试中显著优于现有基于推理的对齐模型，对抗最先进攻击的鲁棒性提升明显。", "conclusion": "通过人类对齐的结构化安全推理流程，ARMOR为构建安全可靠的LLMs提供了有效解决方案，其方法论可扩展至更广泛的安全对齐场景。"}}
{"id": "2507.11135", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11135", "abs": "https://arxiv.org/abs/2507.11135", "authors": ["Selma Saidi", "Omar Laimona", "Christoph Schmickler", "Dirk Ziegenbein"], "title": "Collaborative Trustworthiness for Good Decision Making in Autonomous Systems", "comment": null, "summary": "Autonomous systems are becoming an integral part of many application domains,\nlike in the mobility sector. However, ensuring their safe and correct behaviour\nin dynamic and complex environments remains a significant challenge, where\nsystems should autonomously make decisions e.g., about manoeuvring. We propose\nin this paper a general collaborative approach for increasing the level of\ntrustworthiness in the environment of operation and improve reliability and\ngood decision making in autonomous system. In the presence of conflicting\ninformation, aggregation becomes a major issue for trustworthy decision making\nbased on collaborative data sharing. Unlike classical approaches in the\nliterature that rely on consensus or majority as aggregation rule, we exploit\nthe fact that autonomous systems have different quality attributes like\nperception quality. We use this criteria to determine which autonomous systems\nare trustworthy and borrow concepts from social epistemology to define\naggregation and propagation rules, used for automated decision making. We use\nBinary Decision Diagrams (BDDs) as formal models for beliefs aggregation and\npropagation, and formulate reduction rules to reduce the size of the BDDs and\nallow efficient computation structures for collaborative automated reasoning.", "AI": {"tldr": "本文提出一种基于协作数据共享的自主系统可信决策方法，利用感知质量等属性评估系统可信度，并采用BDD模型进行信念聚合与传播。", "motivation": "自主系统在动态复杂环境中确保安全可靠行为面临挑战，需解决冲突信息下的可信决策问题。", "method": "利用系统感知质量等属性定义可信度，结合社会认识论设计聚合与传播规则，采用BDD模型实现高效自动推理。", "result": "提出的方法通过BDD简化规则实现计算结构优化，支持协作环境下的可信自动化决策。", "conclusion": "该协作框架通过质量驱动的可信评估与形式化建模，显著提升了自主系统的决策可靠性与信任度。"}}
{"id": "2507.11150", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.11150", "abs": "https://arxiv.org/abs/2507.11150", "authors": ["Alessandro Bertagnon", "Marcello Dalpasso", "Michele Favalli", "Marco Gavanelli"], "title": "Fine-grained Timing Analysis of Digital Integrated Circuits in Answer Set Programming", "comment": "Accepted for publication in the issues of Theory and Practice of\n  Logic Programming (TPLP) dedicated to ICLP 2025, 16 pages, 9 figures", "summary": "In the design of integrated circuits, one critical metric is the maximum\ndelay introduced by combinational modules within the circuit. This delay is\ncrucial because it represents the time required to perform a computation: in an\nArithmetic-Logic Unit it represents the maximum time taken by the circuit to\nperform an arithmetic operation. When such a circuit is part of a larger,\nsynchronous system, like a CPU, the maximum delay directly impacts the maximum\nclock frequency of the entire system. Typically, hardware designers use Static\nTiming Analysis to compute an upper bound of the maximum delay because it can\nbe determined in polynomial time. However, relying on this upper bound can lead\nto suboptimal processor speeds, thereby missing performance opportunities. In\nthis work, we tackle the challenging task of computing the actual maximum\ndelay, rather than an approximate value. Since the problem is computationally\nhard, we model it in Answer Set Programming (ASP), a logic language featuring\nextremely efficient solvers. We propose non-trivial encodings of the problem\ninto ASP. Experimental results show that ASP is a viable solution to address\ncomplex problems in hardware design.", "AI": {"tldr": "本文提出使用答案集编程（ASP）精确计算集成电路中的最大延迟，替代传统的静态时序分析方法，以提高处理器性能。", "motivation": "集成电路设计中，组合模块的最大延迟直接影响系统时钟频率。传统静态时序分析虽能快速计算延迟上界，但可能导致处理器性能未达最优。", "method": "将最大延迟计算问题建模为答案集编程（ASP）问题，并提出非平凡的编码方法，利用ASP求解器的高效性解决这一计算难题。", "result": "实验结果表明，ASP能有效处理硬件设计中的复杂问题，为精确计算最大延迟提供了可行方案。", "conclusion": "ASP为集成电路设计中的延迟计算问题提供了新思路，有望替代传统近似方法，提升系统性能。"}}
{"id": "2507.11229", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11229", "abs": "https://arxiv.org/abs/2507.11229", "authors": ["Jin Li", "Zezhong Ding", "Xike Xie"], "title": "DuetGraph: Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion", "comment": null, "summary": "Knowledge graphs (KGs) are vital for enabling knowledge reasoning across\nvarious domains. Recent KG reasoning methods that integrate both global and\nlocal information have achieved promising results. However, existing methods\noften suffer from score over-smoothing, which blurs the distinction between\ncorrect and incorrect answers and hinders reasoning effectiveness. To address\nthis, we propose DuetGraph, a coarse-to-fine KG reasoning mechanism with\ndual-pathway global-local fusion. DuetGraph tackles over-smoothing by\nsegregating -- rather than stacking -- the processing of local (via message\npassing) and global (via attention) information into two distinct pathways,\npreventing mutual interference and preserving representational discrimination.\nIn addition, DuetGraph introduces a coarse-to-fine optimization, which\npartitions entities into high- and low-score subsets. This strategy narrows the\ncandidate space and sharpens the score gap between the two subsets, which\nalleviates over-smoothing and enhances inference quality. Extensive experiments\non various datasets demonstrate that DuetGraph achieves state-of-the-art (SOTA)\nperformance, with up to an 8.7% improvement in reasoning quality and a\n1.8$\\times$ acceleration in training efficiency.", "AI": {"tldr": "提出DuetGraph方法，通过双路径全局-局部信息融合和粗到细优化机制，解决知识图谱推理中的分数过平滑问题，显著提升推理质量和训练效率。", "motivation": "现有知识图谱推理方法因全局与局部信息堆叠处理导致分数过平滑，模糊正误答案差异，影响推理效果。需设计新机制分离两类信息处理并优化候选实体筛选。", "method": "1) 双路径设计：独立处理局部信息（消息传递）与全局信息（注意力机制）；2) 粗到细优化：将实体划分为高/低分候选子集，缩小搜索空间并拉大分数差距。", "result": "在多个数据集上达到SOTA性能：推理质量最高提升8.7%，训练效率加速1.8$\\times$。", "conclusion": "DuetGraph通过解耦全局-局部信息流与动态候选筛选，有效缓解过平滑问题，为知识图谱推理提供新范式。"}}
{"id": "2507.11277", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.11277", "abs": "https://arxiv.org/abs/2507.11277", "authors": ["Dany Moshkovich", "Sergey Zeltyn"], "title": "Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed within agentic\nsystems-collections of interacting, LLM-powered agents that execute complex,\nadaptive workflows using memory, tools, and dynamic planning. While enabling\npowerful new capabilities, these systems also introduce unique forms of\nuncertainty stemming from probabilistic reasoning, evolving memory states, and\nfluid execution paths. Traditional software observability and operations\npractices fall short in addressing these challenges.\n  This paper introduces AgentOps: a comprehensive framework for observing,\nanalyzing, optimizing, and automating operation of agentic AI systems. We\nidentify distinct needs across four key roles-developers, testers, site\nreliability engineers (SREs), and business users-each of whom engages with the\nsystem at different points in its lifecycle. We present the AgentOps Automation\nPipeline, a six-stage process encompassing behavior observation, metric\ncollection, issue detection, root cause analysis, optimized recommendations,\nand runtime automation. Throughout, we emphasize the critical role of\nautomation in managing uncertainty and enabling self-improving AI systems-not\nby eliminating uncertainty, but by taming it to ensure safe, adaptive, and\neffective operation.", "AI": {"tldr": "本文提出AgentOps框架，用于观察、分析和优化基于大语言模型（LLM）的智能代理系统，解决其不确定性带来的挑战。", "motivation": "随着LLM驱动的智能代理系统广泛应用，其概率推理、动态记忆和灵活执行路径带来的不确定性，使传统软件运维方法难以应对。", "method": "提出AgentOps自动化管道，包含行为观察、指标收集、问题检测、根因分析、优化建议和运行时自动化六个阶段，满足开发者、测试者、SRE和业务用户的需求。", "result": "通过自动化管理不确定性，使AI系统能够安全、自适应且高效地运行，实现自我改进。", "conclusion": "AgentOps框架通过驯服而非消除不确定性，为智能代理系统的运维提供了全面解决方案。"}}
{"id": "2507.11288", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11288", "abs": "https://arxiv.org/abs/2507.11288", "authors": ["Théo Fagnoni", "Mahsun Altin", "Chia En Chung", "Phillip Kingston", "Alan Tuning", "Dana O. Mohamed", "Inès Adnani"], "title": "Opus: A Prompt Intention Framework for Complex Workflow Generation", "comment": "39 pages, 24 figures", "summary": "This paper introduces the Opus Prompt Intention Framework, designed to\nimprove complex Workflow Generation with instruction-tuned Large Language\nModels (LLMs). We propose an intermediate Intention Capture layer between user\nqueries and Workflow Generation, implementing the Opus Workflow Intention\nFramework, which consists of extracting Workflow Signals from user queries,\ninterpreting them into structured Workflow Intention objects, and generating\nWorkflows based on these Intentions. Our results show that this layer enables\nLLMs to produce logical and meaningful outputs that scale reliably as query\ncomplexity increases. On a synthetic benchmark of 1,000 multi-intent\nquery-Workflow(s) pairs, applying the Opus Prompt Intention Framework to\nWorkflow Generation yields consistent improvements in semantic Workflow\nsimilarity metrics. In this paper, we introduce the Opus Prompt Intention\nFramework by applying the concepts of Workflow Signal and Workflow Intention to\nLLM-driven Workflow Generation. We present a reproducible, customizable\nLLM-based Intention Capture system to extract Workflow Signals and Workflow\nIntentions from user queries. Finally, we provide empirical evidence that the\nproposed system significantly improves Workflow Generation quality compared to\ndirect generation from user queries, particularly in cases of Mixed Intention\nElicitation.", "AI": {"tldr": "本文提出Opus Prompt Intention框架，通过在工作流生成前加入意图捕捉层，显著提升指令调优大语言模型处理复杂工作流的性能。", "motivation": "现有大语言模型直接根据用户查询生成工作流时，面对复杂多意图查询时可靠性不足，需要中间层来解析和结构化用户意图。", "method": "1) 从用户查询提取工作流信号 2) 将信号转化为结构化工作流意图对象 3) 基于意图生成最终工作流，形成可复现的LLM驱动意图捕捉系统。", "result": "在1000组多意图查询-工作流对的测试中，该框架显著提升语义相似度指标，尤其在混合意图场景下优于直接生成方法。", "conclusion": "Opus框架通过意图中间层使LLM工作流生成更具逻辑性和可扩展性，为复杂查询处理提供了系统化解决方案。"}}
{"id": "2507.11323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11323", "abs": "https://arxiv.org/abs/2507.11323", "authors": ["Xiang Yin", "Nico Potyka", "Antonio Rago", "Timotheus Kampik", "Francesca Toni"], "title": "Contestability in Quantitative Argumentation", "comment": null, "summary": "Contestable AI requires that AI-driven decisions align with human\npreferences. While various forms of argumentation have been shown to support\ncontestability, Edge-Weighted Quantitative Bipolar Argumentation Frameworks\n(EW-QBAFs) have received little attention. In this work, we show how EW-QBAFs\ncan be deployed for this purpose. Specifically, we introduce the contestability\nproblem for EW-QBAFs, which asks how to modify edge weights (e.g., preferences)\nto achieve a desired strength for a specific argument of interest (i.e., a\ntopic argument). To address this problem, we propose gradient-based relation\nattribution explanations (G-RAEs), which quantify the sensitivity of the topic\nargument's strength to changes in individual edge weights, thus providing\ninterpretable guidance for weight adjustments towards contestability. Building\non G-RAEs, we develop an iterative algorithm that progressively adjusts the\nedge weights to attain the desired strength. We evaluate our approach\nexperimentally on synthetic EW-QBAFs that simulate the structural\ncharacteristics of personalised recommender systems and multi-layer\nperceptrons, and demonstrate that it can solve the problem effectively.", "AI": {"tldr": "本文提出了一种基于边加权定量双极论证框架（EW-QBAF）的梯度关系归因解释方法（G-RAE），用于调整边权重以实现特定论证强度的可争议性目标，并通过迭代算法在推荐系统和多层感知器模拟数据上验证了有效性。", "motivation": "现有研究对EW-QBAF在实现AI决策可争议性方面的潜力关注不足，而人类偏好对齐需要可解释的论证强度调整方法。", "method": "提出G-RAE量化边权重对目标论证强度的敏感度，并设计迭代权重调整算法。实验采用模拟推荐系统和MLP结构的合成EW-QBAF数据。", "result": "实验证明该方法能有效解决EW-QBAF的可争议性问题，通过梯度引导的权重调整实现目标论证强度。", "conclusion": "G-RAE为EW-QBAF提供了可解释的权重调整路径，其迭代算法可广泛应用于需要论证强度可控的AI争议场景。"}}
{"id": "2507.11334", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11334", "abs": "https://arxiv.org/abs/2507.11334", "authors": ["Yuehao Huang", "Liang Liu", "Shuangming Lei", "Yukai Ma", "Hao Su", "Jianbiao Mei", "Pengxiang Zhao", "Yaqing Gu", "Yong Liu", "Jiajun Lv"], "title": "CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking", "comment": "Accepted by ACM MM 2025", "summary": "Mobile robots are increasingly required to navigate and interact within\nunknown and unstructured environments to meet human demands. Demand-driven\nnavigation (DDN) enables robots to identify and locate objects based on\nimplicit human intent, even when object locations are unknown. However,\ntraditional data-driven DDN methods rely on pre-collected data for model\ntraining and decision-making, limiting their generalization capability in\nunseen scenarios. In this paper, we propose CogDDN, a VLM-based framework that\nemulates the human cognitive and learning mechanisms by integrating fast and\nslow thinking systems and selectively identifying key objects essential to\nfulfilling user demands. CogDDN identifies appropriate target objects by\nsemantically aligning detected objects with the given instructions.\nFurthermore, it incorporates a dual-process decision-making module, comprising\na Heuristic Process for rapid, efficient decisions and an Analytic Process that\nanalyzes past errors, accumulates them in a knowledge base, and continuously\nimproves performance. Chain of Thought (CoT) reasoning strengthens the\ndecision-making process. Extensive closed-loop evaluations on the AI2Thor\nsimulator with the ProcThor dataset show that CogDDN outperforms single-view\ncamera-only methods by 15%, demonstrating significant improvements in\nnavigation accuracy and adaptability. The project page is available at\nhttps://yuehaohuang.github.io/CogDDN/.", "AI": {"tldr": "本文提出CogDDN框架，通过模仿人类认知机制结合视觉语言模型（VLM），提升移动机器人在未知环境中基于需求驱动的导航能力，实验显示其性能优于传统方法15%。", "motivation": "传统数据驱动的需求导航（DDN）方法依赖预收集数据，在未见场景中泛化能力有限。研究旨在通过模拟人类认知机制，开发能自适应识别关键目标并持续学习的导航框架。", "method": "CogDDN整合快慢思维系统：1）通过语义对齐检测对象与指令识别目标；2）双过程决策模块（启发式快速决策+分析式错误积累改进），结合思维链（CoT）强化推理。", "result": "在AI2Thor仿真器中使用ProcThor数据集的闭环评估显示，CogDDN比单视角相机方法导航准确率提升15%，显著增强适应性与性能。", "conclusion": "CogDDN通过认知机制与持续学习优化需求驱动导航，为未知环境中的机器人交互提供了可泛化解决方案，项目页面见https://yuehaohuang.github.io/CogDDN/。"}}
{"id": "2507.11352", "categories": ["cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2507.11352", "abs": "https://arxiv.org/abs/2507.11352", "authors": ["Yunhao Yang", "Neel P. Bhatt", "Christian Ellis", "Alvaro Velasquez", "Zhangyang Wang", "Ufuk Topcu"], "title": "Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces", "comment": null, "summary": "Logistics operators, from battlefield coordinators rerouting airlifts ahead\nof a storm to warehouse managers juggling late trucks, often face life-critical\ndecisions that demand both domain expertise and rapid and continuous\nreplanning. While popular methods like integer programming yield logistics\nplans that satisfy user-defined logical constraints, they are slow and assume\nan idealized mathematical model of the environment that does not account for\nuncertainty. On the other hand, large language models (LLMs) can handle\nuncertainty and promise to accelerate replanning while lowering the barrier to\nentry by translating free-form utterances into executable plans, yet they\nremain prone to misinterpretations and hallucinations that jeopardize safety\nand cost. We introduce a neurosymbolic framework that pairs the accessibility\nof natural-language dialogue with verifiable guarantees on goal interpretation.\nIt converts user requests into structured planning specifications, quantifies\nits own uncertainty at the field and token level, and invokes an interactive\nclarification loop whenever confidence falls below an adaptive threshold. A\nlightweight model, fine-tuned on just 100 uncertainty-filtered examples,\nsurpasses the zero-shot performance of GPT-4.1 while cutting inference latency\nby nearly 50%. These preliminary results highlight a practical path toward\ncertifiable, real-time, and user-aligned decision-making for complex logistics.", "AI": {"tldr": "本文提出了一种结合自然语言处理与符号逻辑的神经符号框架，用于物流决策中的实时重新规划，通过交互式澄清循环确保目标解释的可验证性，并在低延迟下超越GPT-4.1的零样本性能。", "motivation": "物流决策常面临关键且需快速重新规划的场景，传统整数规划方法速度慢且无法处理不确定性，而大语言模型虽能加速规划但存在误解与幻觉风险。需一种兼具自然语言交互能力与可验证保证的方案。", "method": "框架将用户请求转为结构化规划规范，在字段和词元层面量化自身不确定性，当置信度低于自适应阈值时触发交互式澄清循环。仅用100个经不确定性筛选的样本微调的轻量模型即实现高效推理。", "result": "微调模型在零样本性能上超越GPT-4.1，推理延迟降低近50%，初步验证了复杂物流场景中可认证、实时且用户对齐的决策可行性。", "conclusion": "该神经符号框架为高不确定性环境下的物流决策提供了兼具自然语言可访问性与数学严谨性的实用路径，其低资源需求与高效性凸显工程应用潜力。"}}
{"id": "2507.11467", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.11467", "abs": "https://arxiv.org/abs/2507.11467", "authors": ["Daniel Nichols", "Konstantinos Parasyris", "Harshitha Menon", "Brian R. Bartoldson", "Giorgis Georgakoudis", "Tal Ben-Nun", "Abhinav Bhatele"], "title": "Modeling Code: Is Text All You Need?", "comment": null, "summary": "Code LLMs have become extremely popular recently for modeling source code\nacross a variety of tasks, such as generation, translation, and summarization.\nHowever, transformer-based models are limited in their capabilities to reason\nthrough structured, analytical properties of code, such as control and data\nflow. Previous work has explored the modeling of these properties with\nstructured data and graph neural networks. However, these approaches lack the\ngenerative capabilities and scale of modern LLMs. In this work, we introduce a\nnovel approach to combine the strengths of modeling both code as text and more\nstructured forms.", "AI": {"tldr": "提出一种结合代码文本建模与结构化形式的新方法，以增强代码LLMs在分析和生成任务中的能力。", "motivation": "现有基于Transformer的代码LLMs在处理代码的结构化属性（如控制流和数据流）方面存在局限，而传统图神经网络方法又缺乏现代LLMs的生成能力和规模。", "method": "引入一种新颖方法，将代码作为文本建模与更结构化的形式相结合，以充分利用两者的优势。", "result": "该方法有望提升代码LLMs在分析和生成任务中的表现，特别是在需要结构化推理的场景下。", "conclusion": "结合代码文本与结构化建模的方法为代码LLMs的发展提供了新方向，有望解决现有模型在结构化推理方面的不足。"}}
{"id": "2507.11473", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.11473", "abs": "https://arxiv.org/abs/2507.11473", "authors": ["Tomek Korbak", "Mikita Balesni", "Elizabeth Barnes", "Yoshua Bengio", "Joe Benton", "Joseph Bloom", "Mark Chen", "Alan Cooney", "Allan Dafoe", "Anca Dragan", "Scott Emmons", "Owain Evans", "David Farhi", "Ryan Greenblatt", "Dan Hendrycks", "Marius Hobbhahn", "Evan Hubinger", "Geoffrey Irving", "Erik Jenner", "Daniel Kokotajlo", "Victoria Krakovna", "Shane Legg", "David Lindner", "David Luan", "Aleksander Mądry", "Julian Michael", "Neel Nanda", "Dave Orr", "Jakub Pachocki", "Ethan Perez", "Mary Phuong", "Fabien Roger", "Joshua Saxe", "Buck Shlegeris", "Martín Soto", "Eric Steinberger", "Jasmine Wang", "Wojciech Zaremba", "Bowen Baker", "Rohin Shah", "Vlad Mikulik"], "title": "Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety", "comment": null, "summary": "AI systems that \"think\" in human language offer a unique opportunity for AI\nsafety: we can monitor their chains of thought (CoT) for the intent to\nmisbehave. Like all other known AI oversight methods, CoT monitoring is\nimperfect and allows some misbehavior to go unnoticed. Nevertheless, it shows\npromise and we recommend further research into CoT monitorability and\ninvestment in CoT monitoring alongside existing safety methods. Because CoT\nmonitorability may be fragile, we recommend that frontier model developers\nconsider the impact of development decisions on CoT monitorability.", "AI": {"tldr": "研究探讨了通过监控AI的思维链（CoT）来提升AI安全性，建议进一步研究CoT可监控性并投资相关技术，同时提醒前沿模型开发者注意开发决策对CoT可监控性的影响。", "motivation": "利用AI以人类语言\\\"思考\\\"的特性，通过监控其思维链（CoT）来检测潜在的不良意图，为AI安全提供新的监督方法。", "method": "提出监控思维链（CoT）的方法，尽管不完美，但能部分识别AI的不良行为，建议结合现有安全技术进一步研究。", "result": "思维链监控显示出一定的潜力，但仍存在漏检问题，需与其他安全方法协同使用。", "conclusion": "建议加强CoT可监控性研究，并呼吁前沿模型开发者在决策中考虑对CoT可监控性的影响，以确保AI系统的安全性。"}}
{"id": "2507.11479", "categories": ["cs.AI", "cs.GR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.11479", "abs": "https://arxiv.org/abs/2507.11479", "authors": ["Daniel Platnick", "Matti Gruener", "Marjan Alirezaie", "Kent Larson", "Dava J. Newman", "Hossein Rahnama"], "title": "Perspective-Aware AI in Extended Reality", "comment": "Accepted to the International Conference on eXtended Reality (2025),\n  12 pages, 3 figures", "summary": "AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive\nexperiences-yet current systems fall short due to shallow user modeling and\nlimited cognitive context. We introduce Perspective-Aware AI in Extended\nReality (PAiR), a foundational framework for integrating Perspective-Aware AI\n(PAi) with XR to enable interpretable, context-aware experiences grounded in\nuser identity. PAi is built on Chronicles: reasoning-ready identity models\nlearned from multimodal digital footprints that capture users' cognitive and\nexperiential evolution. PAiR employs these models in a closed-loop system\nlinking dynamic user states with immersive environments. We present PAiR's\narchitecture, detailing its modules and system flow, and demonstrate its\nutility through two proof-of-concept scenarios implemented in the Unity-based\nOpenDome engine. PAiR opens a new direction for human-AI interaction by\nembedding perspective-based identity models into immersive systems.", "AI": {"tldr": "论文提出Perspective-Aware AI in Extended Reality (PAiR)框架，通过整合视角感知AI与XR技术，利用多模态数字足迹构建用户认知模型，实现基于用户身份的上下文感知沉浸式体验。", "motivation": "当前AI增强的XR系统因用户建模浅层且缺乏认知上下文，难以提供真正自适应的沉浸体验。PAiR旨在通过深度用户身份建模解决这一局限。", "method": "建立Chronicles多模态身份模型，采用闭环系统动态关联用户状态与XR环境，并在Unity的OpenDome引擎中实现两个概念验证场景。", "result": "PAiR框架成功展示了如何将基于视角的身份模型嵌入沉浸式系统，为人类-AI交互开辟了新方向。", "conclusion": "该研究为构建可解释、上下文感知的XR体验提供了基础框架，通过身份驱动的AI实现了沉浸系统的范式突破。"}}
{"id": "2507.11482", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11482", "abs": "https://arxiv.org/abs/2507.11482", "authors": ["Mani Hamidi", "Terrence W. Deacon"], "title": "Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light", "comment": null, "summary": "Three core tenets of reinforcement learning (RL)--concerning the definition\nof agency, the objective of learning, and the scope of the reward\nhypothesis--have been highlighted as key targets for conceptual revision, with\nmajor implications for theory and application. We propose a framework, inspired\nby open-ended evolutionary theory, to reconsider these three \"dogmas.\" We\nrevisit each assumption and address related concerns raised alongside them. To\nmake our arguments relevant to RL as a model of biological learning, we first\nestablish that evolutionary dynamics can plausibly operate within living brains\nover an individual's lifetime, and are not confined to cross-generational\nprocesses. We begin by revisiting the second dogma, drawing on evolutionary\ninsights to enrich the \"adaptation-rather-than-search\" view of learning. We\nthen address the third dogma regarding the limits of the reward hypothesis,\nusing analogies from evolutionary fitness to illuminate the scalar reward vs.\nmulti-objective debate. After discussing practical implications for exploration\nin RL, we turn to the first--and arguably most fundamental--issue: the absence\nof a formal account of agency. We argue that unlike the other two problems, the\nevolutionary paradigm alone cannot resolve the agency question, though it\ngestures in a productive direction. We advocate integrating ideas from\norigins-of-life theory, where the thermodynamics of sustenance and replication\noffer promising foundations for understanding agency and resource-constrained\nreinforcement learning in biological systems.", "AI": {"tldr": "本文通过开放式进化理论重新审视强化学习的三个核心原则，提出进化动力学可在大脑生命周期内运作，并探讨了适应优先、多目标奖励与代理问题的解决方案。", "motivation": "针对强化学习中关于代理定义、学习目标和奖励假设范围的三个核心教条，提出需要概念性修订，这对理论和应用有重大影响。", "method": "借鉴开放式进化理论框架，重新评估这三个教条，并讨论相关争议。特别论证了进化动力学在个体生命周期大脑中的可行性，而非仅限于跨代过程。", "result": "通过进化视角丰富了'适应优先于搜索'的学习观，用进化适应性类比澄清标量奖励与多目标的争议，但指出进化范式无法单独解决代理问题，需结合生命起源理论的热力学基础。", "conclusion": "进化理论为前两个教条提供了新见解，但代理问题需整合生命起源理论中关于维持与复制的热力学机制，才能为生物系统的资源受限强化学习奠定基础。"}}
{"id": "2507.11527", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2507.11527", "abs": "https://arxiv.org/abs/2507.11527", "authors": ["Yinsheng Li", "Zhen Dong", "Yi Shao"], "title": "DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering", "comment": "Project page: https://github.com/Eason-Li-AIS/DrafterBench", "summary": "Large Language Model (LLM) agents have shown great potential for solving\nreal-world problems and promise to be a solution for tasks automation in\nindustry. However, more benchmarks are needed to systematically evaluate\nautomation agents from an industrial perspective, for example, in Civil\nEngineering. Therefore, we propose DrafterBench for the comprehensive\nevaluation of LLM agents in the context of technical drawing revision, a\nrepresentation task in civil engineering. DrafterBench contains twelve types of\ntasks summarized from real-world drawing files, with 46 customized\nfunctions/tools and 1920 tasks in total. DrafterBench is an open-source\nbenchmark to rigorously test AI agents' proficiency in interpreting intricate\nand long-context instructions, leveraging prior knowledge, and adapting to\ndynamic instruction quality via implicit policy awareness. The toolkit\ncomprehensively assesses distinct capabilities in structured data\ncomprehension, function execution, instruction following, and critical\nreasoning. DrafterBench offers detailed analysis of task accuracy and error\nstatistics, aiming to provide deeper insight into agent capabilities and\nidentify improvement targets for integrating LLMs in engineering applications.\nOur benchmark is available at https://github.com/Eason-Li-AIS/DrafterBench,\nwith the test set hosted at\nhttps://huggingface.co/datasets/Eason666/DrafterBench.", "AI": {"tldr": "提出开源基准DrafterBench，系统评估大语言模型代理在土木工程图纸修订任务中的表现，包含12类任务、46个定制工具及1920项测试，聚焦结构化数据理解、函数执行等核心能力。", "motivation": "当前缺乏从工业视角（如土木工程）系统评估自动化代理的基准，需构建专业测试平台推动大语言模型在工程领域的应用落地。", "method": "基于真实图纸文件归纳12类任务，开发46个定制函数工具，构建含1920项任务的测试集，评估代理在长上下文理解、先验知识调用及动态指令适应等维度的能力。", "result": "基准提供任务准确率与错误统计的细粒度分析，开源发布于GitHub与HuggingFace平台，支持工程场景下代理能力的短板诊断与优化。", "conclusion": "DrafterBench填补了工程领域LLM代理评估空白，通过多维度测试为提升模型在结构化数据处理、关键推理等工业场景的实用性提供标准参照。"}}
{"id": "2507.11538", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11538", "abs": "https://arxiv.org/abs/2507.11538", "authors": ["Daniel Jaroslawicz", "Brendan Whiting", "Parth Shah", "Karime Maamari"], "title": "How Many Instructions Can LLMs Follow at Once?", "comment": null, "summary": "Production-grade LLM systems require robust adherence to dozens or even\nhundreds of instructions simultaneously. However, the instruction-following\ncapabilities of LLMs at high instruction densities have not yet been\ncharacterized, as existing benchmarks only evaluate models on tasks with a\nsingle or few instructions. We introduce IFScale, a simple benchmark of 500\nkeyword-inclusion instructions for a business report writing task to measure\nhow instruction-following performance degrades as instruction density\nincreases. We evaluate 20 state-of-the-art models across seven major providers\nand find that even the best frontier models only achieve 68% accuracy at the\nmax density of 500 instructions. Our analysis reveals model size and reasoning\ncapability to correlate with 3 distinct performance degradation patterns, bias\ntowards earlier instructions, and distinct categories of instruction-following\nerrors. Our insights can help inform design of instruction-dense prompts in\nreal-world applications and highlight important performance-latency tradeoffs.\nWe open-source the benchmark and all results for further analysis at\nhttps://distylai.github.io/IFScale.", "AI": {"tldr": "本文介绍了IFScale基准测试，用于评估大型语言模型在高密度指令下的表现，发现即使最先进的模型在500条指令时准确率仅68%，并揭示了模型大小与性能退化的关联。", "motivation": "现有基准测试仅评估模型在单一或少量指令下的表现，而实际生产级LLM系统需同时遵循数十甚至数百条指令，因此需要研究高密度指令下的模型性能。", "method": "研究者设计了IFScale基准，包含500条关键词包含指令的商业报告写作任务，用于测量指令密度增加时模型性能的退化情况，并评估了7大提供商的20个前沿模型。", "result": "最佳前沿模型在500条指令时的准确率仅为68%。分析显示模型大小和推理能力与三种性能退化模式相关，包括对早期指令的偏好和不同类型的指令遵循错误。", "conclusion": "研究结果为实际应用中高密度指令提示的设计提供了参考，并揭示了性能与延迟之间的权衡关系。所有基准测试数据和结果已开源供进一步分析。"}}
