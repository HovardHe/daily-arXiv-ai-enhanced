{"id": "2507.01969", "categories": ["math.CO", "cs.GT", "econ.TH", "18M60, 18M70, 18M80, 91A12, 91A8, 52B05, 28E10, 05E99", "G.2.1"], "pdf": "https://arxiv.org/pdf/2507.01969", "abs": "https://arxiv.org/abs/2507.01969", "authors": ["Dylan Laplace Mermoud", "Victor Roca i Lucio"], "title": "The algebraic structures of social organizations: the operad of cooperative games", "comment": "50 pages. Comments are welcome", "summary": "The main goal of this paper is to settle a conceptual framework for\ncooperative game theory in which the notion of composition/aggregation of games\nis the defining structure. This is done via the mathematical theory of\nalgebraic operads: we start by endowing the collection of all cooperative games\nwith any number of players with an operad structure, and we show that it\ngeneralises all the previous notions of sums, products and compositions of\ngames considered by Owen, Shapley, von Neumann and Morgenstern, and many\nothers. Furthermore, we explicitly compute this operad in terms of generators\nand relations, showing that the M\\\"obius transform map induces a canonical\nisomorphism between the operad of cooperative games and the operad that encodes\ncommutative triassociative algebras. In other words, we prove that any\ncooperative game is a linear combination of iterated compositions of the\n2-player bargaining game and the 2-player dictator games. We show that many\ninteresting classes of games (simple, balanced, capacities a.k.a fuzzy measures\nand convex functions, totally monotone, etc) are stable under compositions, and\nthus form suboperads. In the convex case, this gives by the submodularity\ntheorem a new operad structure on the family of all generalized permutahedra.\nFinally, we focus on how solution concepts in cooperative game theory behave\nunder composition: we study the core of a composite and describe it in terms of\nthe core of its components, and we give explicit formulas for the Shapley value\nand the Banzhaf index of a compound game.", "AI": {"tldr": "本文通过代数操作理论为合作博弈论建立了一个以博弈复合/聚合为核心概念的新框架，统一了历史各类博弈合成方法，并证明合作博弈可分解为2人议价博弈与独裁博弈的线性组合。", "motivation": "旨在构建一个基于博弈复合操作的统一理论框架，整合Owen、Shapley等学者提出的分散博弈运算方法，揭示合作博弈的深层代数结构。", "method": "采用代数操作理论：1) 赋予所有合作博弈集合以操作结构 2) 通过M\\\"obius变换建立与交换三重结合代数操作的等价性 3) 分析特殊博弈类（简单/平衡/凸博弈等）在复合下的封闭性。", "result": "1) 证明所有合作博弈都是2人基础博弈的迭代复合 2) 发现广义排列多面体族的新操作结构 3) 给出复合博弈的核、Shapley值及Banzhaf指数的显式计算公式。", "conclusion": "该操作框架不仅统一了经典博弈运算，还揭示了合作博弈与组合数学的深刻联系，为解概念在复合博弈中的行为研究提供了新工具。"}}
{"id": "2507.02015", "categories": ["math.CO", "05C07, 05C09, 05C30, 05C69, 05C82"], "pdf": "https://arxiv.org/pdf/2507.02015", "abs": "https://arxiv.org/abs/2507.02015", "authors": ["Johan Kok"], "title": "Marcello's completion of graphs", "comment": null, "summary": "This paper initiates a study on a new optimization problem with regards to\ngraph completion. The defined procedure is called, \\emph{Marcello's completion}\nof a graph. For graph $G$ of order $n$ the \\emph{Marcello number} is obtained\nby iteratively constructing graphs, $G_1,G_2,\\dots,G_k$ by adding a maximal\nnumber of edges between pairs of distinct, non-adjacent vertices in accordance\nwith the \\emph{Marcello rule}. If for smallest $k$ the resultant graph $G_k\n\\cong K_n$ then the Marcello number of a graph $G$ denoted by $\\varpi(G)$ is\nequal to $\\varpi(G) = k$. By convention $\\varpi(K_n) = 0$, $n \\geq 1$. Certain\nintroductory results are presented.", "AI": {"tldr": "本文提出了一种新的图补全优化问题，称为Marcello补全，定义了Marcello数$\\varpi(G)$，并给出了初步结果。", "motivation": "研究图补全过程中的优化问题，引入Marcello补全规则，探索图通过特定方式补全为完全图的最小步骤数。", "method": "通过迭代构造图序列$G_1,G_2,\\dots,G_k$，每次按Marcello规则在非相邻顶点间添加最大边数，直至得到完全图$K_n$。", "result": "定义了图的Marcello数$\\varpi(G)$，即补全为$K_n$所需的最小步骤数$k$，并约定$\\varpi(K_n)=0$。", "conclusion": "提出了Marcello补全的概念及Marcello数的计算方法，为图补全优化问题提供了新的研究视角。"}}
{"id": "2507.02165", "categories": ["math.CO", "math.RA", "05C05, 06A07, 16T30, 18M80"], "pdf": "https://arxiv.org/pdf/2507.02165", "abs": "https://arxiv.org/abs/2507.02165", "authors": ["Samuele Giraudo"], "title": "Fundamental and homogeneous bases of Hopf algebras built from nonsymmetric operads", "comment": "39 pages", "summary": "We introduce new partial order structures on the underlying sets of free\nnonsymmetric operads. These posets involve decorated ordered rooted trees, and\ntheir terminal intervals are lattices. These lattices are not graded, not\nself-dual, and not semi-distributive, but they are EL-shellable, and their\nM\\\"bius functions take values in $\\{-1, 0, 1\\}$. They admit sublattices on the\nfamilies of $m$-Fuss-Catalan objects and of forests of trees. This latter order\nstructure is used to construct two new bases for the natural Hopf algebras of\nfree nonsymmetric operads: a fundamental basis and a homogeneous basis. Along\nwith the already known elementary basis of these Hopf algebras, this yields a\ntriple of bases. The situation is similar to what is observed in the Hopf\nalgebras of Malvenuto-Reutenauer, Loday-Ronco, and noncommutative symmetric\nfunctions, each of which presents such triples of bases and basis changes\ninvolving, respectively, the right weak partial order, the Tamari partial\norder, and the Boolean lattice partial order.", "AI": {"tldr": "本文在自由非对称操作数的基础上引入了新的偏序结构，涉及装饰有序根树，其终端区间为格。这些格具有EL-shellable性质，M\\\"obius函数值为$\\{-1, 0, 1\\}$。通过构建新的基，为自由非对称操作数的自然Hopf代数提供了三重基结构。", "motivation": "研究自由非对称操作数上的偏序结构，旨在扩展对Hopf代数基的理解，并与已知的Malvenuto-Reutenauer、Loday-Ronco及非交换对称函数中的三重基结构进行类比。", "method": "引入装饰有序根树的偏序结构，分析其终端区间的格性质，并利用森林树构建自由非对称操作数Hopf代数的新基（基本基和齐次基）。", "result": "发现这些格虽非分级、非自对偶且非半分配，但具有EL-shellable性质，M\\\"obius函数值受限。成功构建了三重基结构，与已知Hopf代数中的基变换类似。", "conclusion": "通过新的偏序结构和基构建，丰富了自由非对称操作数Hopf代数的理论框架，为后续研究提供了新的工具和视角。"}}
{"id": "2507.02260", "categories": ["math.CO", "05C38"], "pdf": "https://arxiv.org/pdf/2507.02260", "abs": "https://arxiv.org/abs/2507.02260", "authors": ["Ryan McCulloch", "Brendan D. McKay", "Alireza Salahshoori", "Thomas Zaslavsky"], "title": "The Cycle Counts of Graphs", "comment": "9 pp., 8 figures", "summary": "We prove that an inseparable graph can have any positive number of cycles\nwith the six exceptions 2, 4, 5, 8, 9, 16, and that an inseparable cubic graph\nhas the sole additional exception 13.", "AI": {"tldr": "论文证明了不可分图可以具有任意正数的环，除了六个例外情况2、4、5、8、9、16，而不可分三次图还有一个额外的例外13。", "motivation": "研究不可分图中环的数量限制，填补图论中关于环数存在性的理论空白。", "method": "通过数学证明和构造性方法，分析不可分图及不可分三次图中环数的可能性。", "result": "不可分图排除2、4、5、8、9、16环，不可分三次图额外排除13环，其余环数均存在。", "conclusion": "该研究为不可分图的环数提供了完整的分类，对图论和网络结构分析具有重要意义。"}}
{"id": "2507.01968", "categories": ["q-fin.GN", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.01968", "abs": "https://arxiv.org/abs/2507.01968", "authors": ["Chris Duckworth", "Zlatko Zlatev", "James Sciberras", "Peter Hallett", "Enrico Gerding"], "title": "Optimising task allocation to balance business goals and worker well-being for financial service workforces", "comment": "Accepted in Journal of Modelling in Management", "summary": "Purpose: Financial service companies manage huge volumes of data which\nrequires timely error identification and resolution. The associated tasks to\nresolve these errors frequently put financial analyst workforces under\nsignificant pressure leading to resourcing challenges and increased business\nrisk. To address this challenge, we introduce a formal task allocation model\nwhich considers both business orientated goals and analyst well-being.\n  Methodology: We use a Genetic Algorithm (GA) to optimise our formal model to\nallocate and schedule tasks to analysts. The proposed solution is able to\nallocate tasks to analysts with appropriate skills and experience, while taking\ninto account staff well-being objectives.\n  Findings: We demonstrate our GA model outperforms baseline heuristics,\ncurrent working practice, and is applicable to a range of single and\nmulti-objective real-world scenarios. We discuss the potential for\nmetaheuristics (such as GAs) to efficiently find sufficiently good allocations\nwhich can provide recommendations for financial service managers in-the-loop.\n  Originality: A key gap in existing allocation and scheduling models, is fully\nconsidering worker well-being. This paper presents an allocation model which\nexplicitly optimises for well-being while still improving on current working\npractice for efficiency.", "AI": {"tldr": "本文提出了一种考虑员工福祉的任务分配模型，使用遗传算法优化任务分配，在提高效率的同时改善金融分析师的工作压力。", "motivation": "金融服务业面临海量数据处理压力，传统错误解决方式导致分析师工作压力大、资源分配不均及业务风险增加，亟需兼顾业务目标与员工福祉的解决方案。", "method": "采用遗传算法（GA）构建任务分配模型，在匹配分析师技能经验的同时，将员工福祉指标纳入多目标优化框架。", "result": "实验表明该模型优于基线启发式方法和现行工作方式，能有效平衡单目标/多目标场景需求，为管理者提供决策支持。", "conclusion": "该研究填补了现有分配模型忽视员工福祉的空白，证明元启发式算法可同时提升运营效率与人力关怀，具有行业实践价值。"}}
{"id": "2507.02492", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2507.02492", "abs": "https://arxiv.org/abs/2507.02492", "authors": ["Arindam Banerjee", "Kanoy Kumar Das", "Ajeet Kumar", "Rakesh Kumar", "Subhamoy Maitra"], "title": "On Obtaining New MUBs by Finding Points on Complete Intersection Varieties over $\\mathbb{R}$", "comment": null, "summary": "Mutually Unbiased Bases (MUBs) are closely connected with quantum physics,\nand the structure has a rich mathematical background. We provide equivalent\ncriteria for extending a set of MUBs for $C^n$ by studying real points of a\ncertain affine algebraic variety. This variety comes from the relations that\ndetermine the extendability of a system of MUBs. Finally, we show that some\npart of this variety gives rise to complete intersection domains. Further, we\nshow that there is a one-to-one correspondence between MUBs and the maximal\ncommuting classes (bases) of orthogonal normal matrices in $\\mathcal\nM_n({\\mathbb{C}})$. It means that for $m$ MUBs in $C^n$, there are $m$\ncommuting classes, each consisting of $n$ commuting orthogonal normal matrices\nand the existence of maximal commuting basis for $\\mathcal M_n({\\mathbb{C}})$\nensures the complete set of MUBs in $\\mathcal M_n({\\mathbb{C}})$.", "AI": {"tldr": "该研究通过代数簇的实点分析，提出了扩展$C^n$中相互无偏基(MUBs)的等价准则，并揭示了MUBs与正交正规矩阵的最大交换类之间的一一对应关系。", "motivation": "相互无偏基(MUBs)在量子物理中具有重要应用，其数学结构丰富。研究旨在建立MUBs扩展的判定方法，并探索其与矩阵理论的深层联系。", "method": "通过研究决定MUBs可扩展性的代数簇实点性质，构建等价判定准则；同时建立MUBs与$\\mathcal M_n({\\mathbb{C}})$中正交正规矩阵最大交换类的对应关系。", "result": "证明了部分代数簇构成完全交域；发现$C^n$中m个MUBs对应m个由n个交换正交正规矩阵组成的类，且$\\mathcal M_n({\\mathbb{C}})$最大交换基的存在性保证其完备MUBs集的存在。", "conclusion": "该工作不仅为MUBs扩展提供了代数几何判据，更通过矩阵交换类理论揭示了MUBs的完备性条件，为量子信息基础研究开辟了新途径。"}}
{"id": "2507.01985", "categories": ["q-fin.MF", "econ.TH", "math.DG", "math.PR", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2507.01985", "abs": "https://arxiv.org/abs/2507.01985", "authors": ["Aldric Labarthe", "Yann Kerzreho"], "title": "A unified model of horizontal differentiation with general spaces and irrational consumers", "comment": "37 pages, 14 figures, 4 appendices", "summary": "We introduce a new microeconomic model of horizontal differentiation that\nunifies and extends previous developments inspired by the seminal work of\nHotelling (1929). Our framework incorporates boundedly rational consumers, an\nunlimited number of firms, and arbitrary differentiation spaces with Riemannian\nmanifolds. We argue that Riemannian geometry provides a natural and powerful\ntool for analyzing such models, offering fresh insights into firm behavior and\nmarket structure with complex products.", "AI": {"tldr": "本文提出了一种新的水平差异化微观经济模型，统一并扩展了Hotelling（1929）启发的先前研究，结合了有限理性消费者、无限企业数量及黎曼流形差异化空间。", "motivation": "旨在建立一个更全面的框架，利用黎曼几何分析复杂产品市场中的企业行为和结构，弥补现有模型的局限性。", "method": "采用黎曼流形作为差异化空间的理论基础，引入有限理性消费者假设，并允许企业数量无限扩展。", "result": "证明黎曼几何能自然且强有力地建模复杂差异化市场，为企业策略和市场均衡提供新视角。", "conclusion": "黎曼几何工具为分析具有复杂产品特性的市场结构开辟了新路径，未来研究可进一步探索其应用场景。"}}
{"id": "2507.02057", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02057", "abs": "https://arxiv.org/abs/2507.02057", "authors": ["Lu Yan", "Zhuo Zhang", "Xiangzhe Xu", "Shengwei An", "Guangyu Shen", "Zhou Xuan", "Xuan Chen", "Xiangyu Zhang"], "title": "MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation", "comment": null, "summary": "Large language models (LLMs) have democratized software development, reducing\nthe expertise barrier for programming complex applications. This accessibility\nextends to malicious software development, raising significant security\nconcerns. While LLM providers have implemented alignment mechanisms to prevent\ndirect generation of overtly malicious code, these safeguards predominantly\nevaluate individual prompts in isolation, overlooking a critical vulnerability:\nmalicious operations can be systematically decomposed into benign-appearing\nsub-tasks. In this paper, we introduce the Malware Generation Compiler (MGC), a\nnovel framework that leverages this vulnerability through modular decomposition\nand alignment-evasive generation. MGC employs a specialized Malware Description\nIntermediate Representation (MDIR) to bridge high-level malicious intents and\nbenign-appearing code snippets. Extensive evaluation demonstrates that our\nattack reliably generates functional malware across diverse task specifications\nand categories, outperforming jailbreaking methods by +365.79% and underground\nservices by +78.07% in correctness on three benchmark datasets. Case studies\nfurther show that MGC can reproduce and even enhance 16 real-world malware\nsamples. This work provides critical insights for security researchers by\nexposing the risks of compositional attacks against aligned AI systems.\nDemonstrations are available at\nhttps://sites.google.com/view/malware-generation-compiler.", "AI": {"tldr": "大型语言模型（LLMs）降低了软件开发的技术门槛，但也为恶意软件开发提供了便利。论文提出了一种名为Malware Generation Compiler（MGC）的新型框架，通过模块化分解和规避对齐机制生成恶意代码，显著提高了恶意软件生成的正确性和功能性。", "motivation": "尽管LLM提供商已实施对齐机制以防止直接生成恶意代码，但这些机制主要评估单个提示，忽略了恶意操作可被分解为看似良性的子任务的风险。MGC旨在利用这一漏洞，展示组合攻击对对齐AI系统的威胁。", "method": "MGC采用了一种名为Malware Description Intermediate Representation（MDIR）的中间表示，将高级恶意意图与看似良性的代码片段连接起来，通过模块化分解和规避对齐机制生成恶意代码。", "result": "实验表明，MGC在三个基准数据集上的正确性分别比越狱方法和地下服务高出+365.79%和+78.07%。案例研究还显示，MGC能够复制并增强16个真实世界的恶意软件样本。", "conclusion": "这项工作为安全研究人员提供了重要见解，揭示了组合攻击对对齐AI系统的风险，并展示了MGC在生成功能性恶意软件方面的有效性。更多演示可见https://sites.google.com/view/malware-generation-compiler。"}}
{"id": "2507.02120", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.02120", "abs": "https://arxiv.org/abs/2507.02120", "authors": ["Dimitris Bertsimas", "Dick den Hertog", "Thodoris Koukouvinos"], "title": "A novel exact approach to polynomial optimization", "comment": null, "summary": "Polynomial optimization problems represent a wide class of optimization\nproblems, with a large number of real-world applications. Current approaches\nfor polynomial optimization, such as the sum of squares (SOS) method, rely on\nlarge-scale semidefinite programs, and therefore the scale of problems to which\nthey can be applied is limited and an optimality guarantee is not always\nprovided. Moreover, the problem can have other convex nonlinear parts, that\ncannot be handled by these approaches. In this paper, we propose an alternative\napproach for polynomial optimization. We obtain a convex relaxation of the\noriginal polynomial optimization problem, by deriving a sum of linear times\nconvex (SLC) functions decomposition for the polynomial. We prove that such SLC\ndecompositions always exist for arbitrary degree polynomials. Moreover, we\nderive the SLC decomposition that results in the tightest lower bound, thus\nimproving significantly the quality of the obtained bounds in each node of the\nspatial Branch and Bound method. In the numerical experiments, we show that our\napproach outperforms state-of-the-art methods for polynomial optimization, such\nas BARON and SOS. We show that with our method, we can solve polynomial\noptimization problems to optimality with 40 variables and degree 3, as well as\n20 variables and degree 4, in less than an hour.", "AI": {"tldr": "本文提出了一种新的多项式优化方法，通过线性乘以凸函数（SLC）分解获得凸松弛，显著提升了求解效率和质量，优于现有方法如BARON和SOS。", "motivation": "现有多项式优化方法（如SOS）依赖大规模半定规划，求解规模受限且无法保证最优性，且无法处理其他凸非线性部分。", "method": "通过推导多项式的线性乘以凸函数（SLC）分解，获得原问题的凸松弛，并证明SLC分解对任意阶多项式均存在，且可得到最紧下界。", "result": "数值实验表明，该方法优于BARON和SOS等先进方法，能在1小时内求解40变量3阶或20变量4阶的多项式优化问题至最优。", "conclusion": "SLC分解方法为多项式优化提供了高效且高质量的解决方案，显著扩展了可求解问题的规模和复杂度。"}}
{"id": "2507.01991", "categories": ["q-fin.CP", "cs.CL", "econ.GN", "q-fin.EC", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2507.01991", "abs": "https://arxiv.org/abs/2507.01991", "authors": ["Muhammad Bilal Zafar"], "title": "FinAI-BERT: A Transformer-Based Model for Sentence-Level Detection of AI Disclosures in Financial Reports", "comment": "The FinAI-BERT model can be directly loaded via Hugging Face\n  Transformers (https://huggingface.co/bilalzafar/FinAI-BERT) for\n  sentence-level AI disclosure classification", "summary": "The proliferation of artificial intelligence (AI) in financial services has\nprompted growing demand for tools that can systematically detect AI-related\ndisclosures in corporate filings. While prior approaches often rely on keyword\nexpansion or document-level classification, they fall short in granularity,\ninterpretability, and robustness. This study introduces FinAI-BERT, a\ndomain-adapted transformer-based language model designed to classify AI-related\ncontent at the sentence level within financial texts. The model was fine-tuned\non a manually curated and balanced dataset of 1,586 sentences drawn from 669\nannual reports of U.S. banks (2015 to 2023). FinAI-BERT achieved near-perfect\nclassification performance (accuracy of 99.37 percent, F1 score of 0.993),\noutperforming traditional baselines such as Logistic Regression, Naive Bayes,\nRandom Forest, and XGBoost. Interpretability was ensured through SHAP-based\ntoken attribution, while bias analysis and robustness checks confirmed the\nmodel's stability across sentence lengths, adversarial inputs, and temporal\nsamples. Theoretically, the study advances financial NLP by operationalizing\nfine-grained, theme-specific classification using transformer architectures.\nPractically, it offers a scalable, transparent solution for analysts,\nregulators, and scholars seeking to monitor the diffusion and framing of AI\nacross financial institutions.", "AI": {"tldr": "该研究开发了FinAI-BERT模型，用于在金融文本中句子级别精准分类AI相关内容，性能显著优于传统方法，为金融AI监管提供了可扩展的解决方案。", "motivation": "现有AI披露检测工具在细粒度、可解释性和鲁棒性方面存在不足，无法满足金融领域对AI内容精准识别的需求。", "method": "基于Transformer架构构建FinAI-BERT模型，使用1,586条来自美国银行年报（2015-2023年）的手工标注句子进行微调，并通过SHAP实现可解释性分析。", "result": "模型达到99.37%准确率和0.993 F1值，在句子长度、对抗样本和时间样本测试中均表现稳定，显著优于逻辑回归等传统方法。", "conclusion": "研究不仅推进了金融NLP细粒度分类的理论方法，更为分析师和监管机构提供了监测AI在金融机构渗透情况的实用工具。"}}
{"id": "2507.02113", "categories": ["math.LO", "math.CA", "03D78, 26E10, 58C25, 54C20, 54C30"], "pdf": "https://arxiv.org/pdf/2507.02113", "abs": "https://arxiv.org/abs/2507.02113", "authors": ["Andrea Brun", "Guido Gherardi", "Alberto Marcone"], "title": "Computability of a Whitney Extension", "comment": "35 pages, 3 figures", "summary": "We prove the computability of a version of Whitney Extension, when the input\nis suitably represented. More specifically, if $F \\subseteq \\mathbb{R}^n$ is a\nclosed set represented so that the distance function $x \\mapsto d(x,F)$ can be\ncomputed, and $(f^{(\\bar{k})})_{|\\bar{k}| \\le m}$ is a Whitney jet of order $m$\non $F$, then we can compute $g \\in C^{m}(\\mathbb{R}^n)$ such that $g$ and its\npartial derivatives coincide on $F$ with the corresponding functions of\n$(f^{(\\bar{k})})_{|\\bar{k}| \\le m}$.", "AI": {"tldr": "本文证明了一种Whitney扩展的可计算性，当输入数据以特定方式表示时，可以计算出一个光滑函数在闭集上的延拓。", "motivation": "研究Whitney扩展问题的可计算性，旨在为闭集上的光滑函数延拓提供有效的计算方法。", "method": "假设闭集$F \\subseteq \\mathbb{R}^n$的距离函数$x \\mapsto d(x,F)$可计算，并且给定一个Whitney jet $(f^{(\\bar{k})})_{|\\bar{k}| \\le m}$，通过构造方法计算延拓函数$g \\in C^{m}(\\mathbb{R}^n)$。", "result": "证明了可以计算出一个$C^{m}$光滑函数$g$，使得$g$及其偏导数在$F$上与给定的Whitney jet一致。", "conclusion": "该结果为Whitney扩展问题的可计算性提供了理论保证，为相关数学和计算领域提供了新的工具。"}}
{"id": "2507.02360", "categories": ["math.NT", "11S15 (primary), 11F85, 11S05, 11S20, 11Y40, 12F05 (secondary)"], "pdf": "https://arxiv.org/pdf/2507.02360", "abs": "https://arxiv.org/abs/2507.02360", "authors": ["Jordi Guàrdia Rúbies", "John W. Jones", "Kevin Keating", "Sebastian Pauli", "David P. Roberts", "David Roe"], "title": "Families of p-adic fields", "comment": "27 pages", "summary": "We improve the database of $p$-adic fields in the LMFDB by systematically\nusing Krasner-Monge polynomials and working relatively as well as absolutely.\nThese improvements organize $p$-adic fields into families. They thereby make\nlong lists of fields more manageable and various theoretical structures more\nevident. In particular, the database now includes all degree $n$ extensions of\n$\\mathbb{Q}_p$, for $p<200$ and $n \\leq 23$.", "AI": {"tldr": "通过使用Krasner-Monge多项式和相对与绝对方法，改进了LMFDB中$p$-adic字段的数据库，将其组织成家族，使长列表更易管理并突显理论结构。", "motivation": "改进LMFDB中$p$-adic字段的数据库，使其更系统化、结构化，便于管理和理论研究。", "method": "系统地应用Krasner-Monge多项式，并采用相对与绝对方法，将$p$-adic字段组织成家族。", "result": "数据库现在包含所有次数$n \\leq 23$且$p < 200$的$\\mathbb{Q}_p$的$n$次扩张。", "conclusion": "改进后的数据库使$p$-adic字段的管理更高效，理论结构更清晰，为相关研究提供了更好的工具。"}}
{"id": "2507.02323", "categories": ["math.ST", "stat.TH", "Primary 94A17, Secondary 62P12, 86A05"], "pdf": "https://arxiv.org/pdf/2507.02323", "abs": "https://arxiv.org/abs/2507.02323", "authors": ["Poulami Paul", "Chancal Kundu"], "title": "Fractional differential entropy and its application in modeling one-dimensional flow velocity", "comment": "25 pages, 7 figures and 3 tables", "summary": "The fractional order generalization of Shannon entropy proposed by Ubriaco\nhas been studied for discrete distributions. In the current paper, we conduct a\ndetailed study of the continuous analogue of this entropy termed as fractional\ndifferential entropy and find some interesting properties which makes it stand\nout among the existing entropies in literature. The studied entropy measure is\nevaluated analytically and numerically for some well-known continuous\ndistributions, which will be quite useful in reliability analysis works and\nother statistical studies of complex systems. Further, it has been used to\nmodel the one-dimensional vertical velocity profile of turbulent flows in wide\nopen channels. A one-parametric spatial distribution function is utilized for\nbetter estimation of the velocity distribution. The validity of the model has\nbeen established using experimental and field data through regression analysis.\nA comparative study is also presented to show the superiority of the proposed\nmodel over the existing entropy-based models.", "AI": {"tldr": "本文研究了Ubriaco提出的分数阶香农熵在连续分布中的推广——分数阶微分熵，并探讨了其独特性质。通过解析和数值方法评估了该熵在几种常见连续分布中的应用，并用于模拟宽开渠道湍流的垂直速度剖面。通过回归分析验证了模型的有效性，并展示了其优于现有熵模型的优势。", "motivation": "研究分数阶微分熵的动机在于其在复杂系统统计分析和可靠性工作中的潜在应用价值，以及其在模拟湍流速度剖面中的实用性。", "method": "研究采用了解析和数值方法评估分数阶微分熵，并利用单参数空间分布函数优化速度分布估计。通过实验和现场数据进行回归分析验证模型。", "result": "分数阶微分熵在多种连续分布中表现出独特的性质，并在湍流速度剖面模拟中优于现有熵模型。回归分析证实了模型的有效性。", "conclusion": "分数阶微分熵在统计分析和湍流建模中具有显著优势，为复杂系统的研究提供了新的工具。"}}
{"id": "2507.02004", "categories": ["cs.AI", "cs.CL", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2507.02004", "abs": "https://arxiv.org/abs/2507.02004", "authors": ["Ruofan Jin", "Zaixi Zhang", "Mengdi Wang", "Le Cong"], "title": "STELLA: Self-Evolving LLM Agent for Biomedical Research", "comment": null, "summary": "The rapid growth of biomedical data, tools, and literature has created a\nfragmented research landscape that outpaces human expertise. While AI agents\noffer a solution, they typically rely on static, manually curated toolsets,\nlimiting their ability to adapt and scale. Here, we introduce STELLA, a\nself-evolving AI agent designed to overcome these limitations. STELLA employs a\nmulti-agent architecture that autonomously improves its own capabilities\nthrough two core mechanisms: an evolving Template Library for reasoning\nstrategies and a dynamic Tool Ocean that expands as a Tool Creation Agent\nautomatically discovers and integrates new bioinformatics tools. This allows\nSTELLA to learn from experience. We demonstrate that STELLA achieves\nstate-of-the-art accuracy on a suite of biomedical benchmarks, scoring\napproximately 26\\% on Humanity's Last Exam: Biomedicine, 54\\% on LAB-Bench:\nDBQA, and 63\\% on LAB-Bench: LitQA, outperforming leading models by up to 6\npercentage points. More importantly, we show that its performance\nsystematically improves with experience; for instance, its accuracy on the\nHumanity's Last Exam benchmark almost doubles with increased trials. STELLA\nrepresents a significant advance towards AI Agent systems that can learn and\ngrow, dynamically scaling their expertise to accelerate the pace of biomedical\ndiscovery.", "AI": {"tldr": "STELLA是一种自进化AI代理，通过动态工具库和模板库自主提升能力，在生物医学基准测试中表现优异且性能随经验持续提升。", "motivation": "生物医学数据、工具和文献的快速增长导致研究领域碎片化，超出人类专家能力范围，现有AI代理依赖静态工具集，难以适应和扩展。", "method": "采用多代理架构，包含可进化的推理策略模板库（Template Library）和动态工具海洋（Tool Ocean），通过工具创建代理自动发现并整合新工具实现能力进化。", "result": "在生物医学基准测试中达到最先进水平：Humanity's Last Exam: Biomedicine得分26\\%，LAB-Bench: DBQA得分54\\%，LAB-Bench: LitQA得分63\\%，优于领先模型达6个百分点，且性能随经验系统性提升（如Humanity's Last Exam准确率随试验次数几乎翻倍）。", "conclusion": "STELLA代表了AI代理系统的重大进步，能够动态扩展专业知识，加速生物医学发现进程。"}}
{"id": "2507.02263", "categories": ["math.CO", "15A42, 05C35, 05C50"], "pdf": "https://arxiv.org/pdf/2507.02263", "abs": "https://arxiv.org/abs/2507.02263", "authors": ["Jian Zheng", "Yongtao Li", "Yi-Zheng Fan"], "title": "Some Turán-type results for signless Laplacian spectral radius", "comment": "32 pages. Any suggestions are welcome", "summary": "Half a century ago, Bollob\\'{a}s and Erd\\H{o}s [Bull. London Math. Soc. 5\n(1973)] proved that every $n$-vertex graph $G$ with $e(G)\\ge (1- \\frac{1}{k} +\n\\varepsilon )\\frac{n^2}{2}$ edges contains a blowup $K_{k+1}[t]$ with\n$t=\\Omega_{k,\\varepsilon}(\\log n)$. A well-known theorem of Nikiforov [Combin.\nProbab. Comput. 18 (3) (2009)] asserts that if $G$ is an $n$-vertex graph with\nadjacency spectral radius $\\lambda (G)\\ge (1- \\frac{1}{k} + \\varepsilon)n$,\nthen $G$ contains a blowup $K_{k+1}[t]$ with $t=\\Omega_{k,\\varepsilon}(\\log\nn)$. This gives a spectral version of the Bollob\\'{a}s--Erd\\H{o}s theorem. In\nthis paper, we systematically explore variants of Nikiforov's result in terms\nof the signless Laplacian spectral radius, extending the supersaturation,\nblowup of cliques and the stability results.", "AI": {"tldr": "本文系统研究了基于无符号拉普拉斯谱半径的Nikiforov定理变体，扩展了超饱和、团爆炸和稳定性结果。", "motivation": "Bollob\\'{a}s和Erd\\H{o}s的经典定理以及Nikiforov的谱版本定理为研究图的爆炸团问题奠定了基础，本文旨在通过无符号拉普拉斯谱半径进一步扩展这些结果。", "method": "通过分析图的邻接谱半径和无符号拉普拉斯谱半径，研究其与团爆炸结构的关系，并采用超饱和和稳定性方法进行扩展。", "result": "证明了在无符号拉普拉斯谱半径条件下，图中存在大小为$\\Omega_{k,\\varepsilon}(\\log n)$的$K_{k+1}[t]$爆炸团，扩展了Nikiforov的谱结果。", "conclusion": "本文成功地将Nikiforov的谱定理推广到无符号拉普拉斯谱半径，为图的爆炸团问题提供了新的理论工具和结果。"}}
{"id": "2507.01987", "categories": ["q-fin.GN", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01987", "abs": "https://arxiv.org/abs/2507.01987", "authors": ["João B. G. de Brito", "Rodrigo Heldt", "Cleo S. Silveira", "Matthias Bogaert", "Guilherme B. Bucco", "Fernando B. Luce", "João L. Becker", "Filipe J. Zabala", "Michel J. Anzanello"], "title": "Predicting and Explaining Customer Data Sharing in the Open Banking", "comment": null, "summary": "The emergence of Open Banking represents a significant shift in financial\ndata management, influencing financial institutions' market dynamics and\nmarketing strategies. This increased competition creates opportunities and\nchallenges, as institutions manage data inflow to improve products and services\nwhile mitigating data outflow that could aid competitors. This study introduces\na framework to predict customers' propensity to share data via Open Banking and\ninterprets this behavior through Explanatory Model Analysis (EMA). Using data\nfrom a large Brazilian financial institution with approximately 3.2 million\ncustomers, a hybrid data balancing strategy incorporating ADASYN and NEARMISS\ntechniques was employed to address the infrequency of data sharing and enhance\nthe training of XGBoost models. These models accurately predicted customer data\nsharing, achieving 91.39% accuracy for inflow and 91.53% for outflow. The EMA\nphase combined the Shapley Additive Explanations (SHAP) method with the\nClassification and Regression Tree (CART) technique, revealing the most\ninfluential features on customer decisions. Key features included the number of\ntransactions and purchases in mobile channels, interactions within these\nchannels, and credit-related features, particularly credit card usage across\nthe national banking system. These results highlight the critical role of\nmobile engagement and credit in driving customer data-sharing behaviors,\nproviding financial institutions with strategic insights to enhance\ncompetitiveness and innovation in the Open Banking environment.", "AI": {"tldr": "研究通过混合数据平衡策略和XGBoost模型预测客户在开放银行中的数据共享倾向，结合SHAP和CART方法解释关键影响因素，发现移动渠道互动和信用卡使用是主要驱动因素。", "motivation": "开放银行改变了金融数据管理方式，金融机构需平衡数据流入与流出以提升竞争力，研究旨在预测客户数据共享行为并提供战略洞察。", "method": "采用ADASYN和NEARMISS混合数据平衡策略处理数据稀疏问题，训练XGBoost模型预测数据共享行为，并通过SHAP和CART方法进行解释性分析。", "result": "模型在预测数据流入和流出时准确率分别达91.39%和91.53%，关键影响因素包括移动渠道交易次数、互动频率及全国银行系统信用卡使用情况。", "conclusion": "移动渠道参与度和信用特征是驱动客户数据共享的核心因素，研究为金融机构在开放银行环境中制定竞争与创新策略提供了重要依据。"}}
{"id": "2507.02769", "categories": ["math.CO", "cs.DM", "05C83, 05C85, 05C10, 05C75, 68R10", "G.2.2"], "pdf": "https://arxiv.org/pdf/2507.02769", "abs": "https://arxiv.org/abs/2507.02769", "authors": ["Christophe Paul", "Evangelos Protopapas", "Dimitrios M. Thilikos", "Sebastian Wiederrecht"], "title": "The Local Structure Theorem for Graph Minors with Finite Index", "comment": null, "summary": "The Local Structure Theorem (LST) for graph minors roughly states that every\n$H$-minor free graph $G$ that contains a sufficiently large wall $W$, there is\na set of few vertices $A$ such that, upon removing $A$, the resulting graph\n$G':=G - A$ admits an \"almost embedding\" $\\delta$ into a surface $\\Sigma$ in\nwhich $H$ does not embed. By almost embedding, we mean that there exists a\nhypergraph $\\mathcal{H}$ whose vertex set is a subset of the vertex set of $G$\nand an embedding of $\\mathcal{H}$ in $\\Sigma$ such that 1) the drawing of each\nhyperedge of $\\mathcal{H}$ corresponds to a cell of $\\delta$, 2) the boundary\nof each cell intersects only the vertices of the corresponding hyperedge, and\n3) all remaining vertices and edges of $G'$ are drawn in the interior of cells.\nThe cells corresponding to hyperedges of arity at least $4$, called vortices,\nare few in number and have small \"depth\", while a \"large\" part of the wall $W$\nis drawn outside the vortices and is \"grounded\" in the embedding $\\delta$. Now\nsuppose that the subgraphs drawn inside each of the non-vortex cells are\nequipped with some finite index, i.e., each such cell is assigned a color from\na finite set. We prove a version of the LST in which the set $C$ of colors\nassigned to the non-vortex cells exhibits \"large\" bidimensionality: The graph\n$G'$ contains a minor model of a large grid $\\Gamma$ where each bag\ncorresponding to a vertex $v$ of $\\Gamma$, contains the subgraph drawn within a\ncell carrying color $\\alpha$, for every color $\\alpha \\in C$. Moreover, the\ngrid $\\Gamma$ can be chosen in a way that is \"well-connected\" to the original\nwall $W$.", "AI": {"tldr": "本文提出了一种局部结构定理（LST）的扩展版本，针对不含$H$子图的图$G$，证明在移除少量顶点$A$后，剩余图$G'$可通过有限颜色标记的非涡旋单元格展现高维网格的'大'双维度特性。", "motivation": "研究图$G$在排除特定子图$H$时的结构特性，探索其在大规模子结构（如墙$W$）存在时的分解与嵌入性质，为图论中的结构分解提供新视角。", "method": "通过构造超图$\\mathcal{H}$的近似嵌入$\\delta$到曲面$\\Sigma$，将$G'$划分为有限颜色的非涡旋单元格和少量低深度涡旋，并分析颜色集$C$与网格模型$\\Gamma$的关联性。", "result": "证明了$G'$包含与颜色集$C$对应的'大'网格模型$\\Gamma$，且每个顶点包覆盖所有颜色的单元格内容，同时该网格与原始墙$W$保持良好连通性。", "conclusion": "扩展的LST揭示了排除子图$H$的图在颜色标记单元格中隐含的强双维度结构，为复杂图分解提供了新的理论工具。"}}
{"id": "2507.02027", "categories": ["q-fin.MF", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2507.02027", "abs": "https://arxiv.org/abs/2507.02027", "authors": ["Christoph Schlegel"], "title": "Arbitrage with bounded Liquidity", "comment": null, "summary": "The arbitrage gains or, equivalently, Loss Versus Rebalacing (LVR) for\narbitrage between two imperfectly liquid markets is derived. To derive the LVR,\nI assume a quadratic trading cost to model the cost of trading on the more\nliquid exchange and discuss to which situations my model arguably applies well\n(long tail CEX-DEX arbitrage, DEX-DEX arbitrage) and to which not so well\n(CEX-DEX arbitrage for major pairs). I discuss extension to other cost\nfunctions and directions for future research.", "AI": {"tldr": "本文推导了两个流动性不足市场间套利的收益（即LVR），采用二次交易成本模型分析适用场景，并探讨了模型扩展方向。", "motivation": "研究流动性差异市场间的套利行为，量化套利收益（LVR），为不同交易场景提供理论框架。", "method": "使用二次交易成本模型模拟高流动性交易所的交易成本，分析模型在长尾CEX-DEX套利和DEX间套利的适用性。", "result": "模型适用于长尾CEX-DEX套利及DEX间套利，但对主流交易对的CEX-DEX套利解释力有限。", "conclusion": "提出扩展其他成本函数的可能性，并指明未来研究方向，如优化模型适用场景。"}}
{"id": "2507.02125", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.GT", "cs.LG", "11, 62, 68, 90, 91", "F.0; F.4; H.4; H.5; I.2"], "pdf": "https://arxiv.org/pdf/2507.02125", "abs": "https://arxiv.org/abs/2507.02125", "authors": ["Giulio Caldarelli"], "title": "Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities", "comment": null, "summary": "The blockchain oracle problem, which refers to the challenge of injecting\nreliable external data into decentralized systems, remains a fundamental\nlimitation to the development of trustless applications. While recent years\nhave seen a proliferation of architectural, cryptographic, and economic\nstrategies to mitigate this issue, no one has yet fully resolved the\nfundamental question of how a blockchain can gain knowledge about the off-chain\nworld. In this position paper, we critically assess the role artificial\nintelligence (AI) can play in tackling the oracle problem. Drawing from both\nacademic literature and practitioner implementations, we examine how AI\ntechniques such as anomaly detection, language-based fact extraction, dynamic\nreputation modeling, and adversarial resistance can enhance oracle systems. We\nobserve that while AI introduces powerful tools for improving data quality,\nsource selection, and system resilience, it cannot eliminate the reliance on\nunverifiable off-chain inputs. Therefore, this study supports the idea that AI\nshould be understood as a complementary layer of inference and filtering within\na broader oracle design, not a substitute for trust assumptions.", "AI": {"tldr": "本文探讨了人工智能（AI）在解决区块链预言机问题中的潜在作用，指出AI可作为补充层提升数据质量和系统韧性，但无法完全消除对链下输入的依赖。", "motivation": "区块链预言机问题——如何将可靠的外部数据注入去中心化系统——是阻碍无信任应用发展的根本限制。尽管已有多种策略尝试缓解此问题，但尚未彻底解决区块链如何获取链外世界知识的问题。", "method": "通过综合学术文献和实践案例，批判性评估了AI技术（如异常检测、基于语言的事实提取、动态声誉建模和对抗性抵抗）如何增强预言机系统。", "result": "研究发现，AI虽能显著提升数据质量、来源选择和系统韧性，但仍无法消除对不可验证链下输入的依赖。", "conclusion": "AI应被视为预言机设计中用于推理和过滤的补充层，而非信任假设的替代品。这一观点支持了在更广泛的预言机设计中整合AI技术的必要性。"}}
{"id": "2507.02131", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.02131", "abs": "https://arxiv.org/abs/2507.02131", "authors": ["Leilei Cui", "Zhong-Ping Jiang", "Eduardo D. Sontag", "Richard D. Braatz"], "title": "Perturbed Gradient Descent Algorithms are Small-Disturbance Input-to-State Stable", "comment": "16 pages", "summary": "This article investigates the robustness of gradient descent algorithms under\nperturbations. The concept of small-disturbance input-to-state stability (ISS)\nfor discrete-time nonlinear dynamical systems is introduced, along with its\nLyapunov characterization. The conventional linear Polyak-Lojasiewicz (PL)\ncondition is then extended to a nonlinear version, and it is shown that the\ngradient descent algorithm is small-disturbance ISS provided the objective\nfunction satisfies the generalized nonlinear PL condition. This\nsmall-disturbance ISS property guarantees that the gradient descent algorithm\nconverges to a small neighborhood of the optimum under sufficiently small\nperturbations. As a direct application of the developed framework, we\ndemonstrate that the LQR cost satisfies the generalized nonlinear PL condition,\nthereby establishing that the policy gradient algorithm for LQR is\nsmall-disturbance ISS. Additionally, other popular policy gradient algorithms,\nincluding natural policy gradient and Gauss-Newton method, are also proven to\nbe small-disturbance ISS.", "AI": {"tldr": "本文研究了梯度下降算法在扰动下的鲁棒性，引入了小扰动输入-状态稳定性（ISS）概念及其Lyapunov特征，扩展了非线性PL条件，并证明在满足广义非线性PL条件时梯度下降具有小扰动ISS特性。应用该框架证明了LQR成本满足广义非线性PL条件，从而确立LQR策略梯度算法的小扰动ISS特性。", "motivation": "研究梯度下降算法在扰动环境下的稳定性，为非线性动态系统提供鲁棒性分析框架，特别关注优化算法在控制理论中的应用。", "method": "引入离散时间非线性系统的小扰动ISS概念及其Lyapunov特征，将线性PL条件推广至非线性形式，通过广义非线性PL条件分析梯度下降的ISS特性。", "result": "证明满足广义非线性PL条件时，梯度下降算法具有小扰动ISS特性，能收敛至最优解邻域；应用该框架证实LQR策略梯度、自然策略梯度及高斯-牛顿法均具备小扰动ISS特性。", "conclusion": "广义非线性PL条件为梯度下降算法的扰动鲁棒性提供了理论保证，所提框架成功应用于LQR等策略梯度算法，证实其在小扰动下的稳定性。"}}
{"id": "2507.02343", "categories": ["math.LO", "03C95, 03B22"], "pdf": "https://arxiv.org/pdf/2507.02343", "abs": "https://arxiv.org/abs/2507.02343", "authors": ["Sayantan Roy", "Sankha S. Basu", "Mihir K. Chakraborty"], "title": "Abstract Model Structures and Compactness Theorems", "comment": "33 pages. The final version of this article has been submitted for\n  publication", "summary": "The compactness theorem for a logic states, roughly, that the satisfiability\nof a set of well-formed formulas can be determined from the satisfiability of\nits finite subsets, and vice versa. Usually, proofs of this theorem depend on\nthe syntactic/semantic particularities of the corresponding logic. In this\npaper, using the notion of \\emph{abstract model structures}, we show that one\ncan develop a generalized notion of compactness that is independent of these.\nSeveral characterization theorems for a particular class of compact abstract\nmodel structures are also proved.", "AI": {"tldr": "本文提出了一种基于抽象模型结构的广义紧致性概念，独立于具体逻辑的语法/语义特性，并证明了特定类别紧致抽象模型结构的若干表征定理。", "motivation": "传统紧致性定理的证明依赖于特定逻辑的语法/语义细节，本文旨在发展一种不依赖这些细节的广义紧致性理论。", "method": "使用抽象模型结构（\\emph{abstract model structures}）作为工具，构建独立于具体逻辑的紧致性框架。", "result": "证明了特定类别的紧致抽象模型结构的多个表征定理，验证了广义紧致性理论的可行性。", "conclusion": "通过抽象模型结构，可以建立普适的紧致性理论，为不同逻辑系统的紧致性研究提供统一框架。"}}
{"id": "2507.02522", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.02522", "abs": "https://arxiv.org/abs/2507.02522", "authors": ["András Biró"], "title": "Cusp forms of weight 1/2 and pairs of quadratic forms", "comment": null, "summary": "We prove a spectral summation formula for the product of four Fourier\ncoefficients of half-integral weight cusp forms in Kohnen's subspace. The other\nside of the formula involves certain generalized class numbers of pairs of\nquadratic forms with integer coefficients.", "AI": {"tldr": "本文证明了Kohnen子空间中半整数权尖形式四个傅里叶系数乘积的谱求和公式，公式的另一侧涉及具有整数系数的二次型对的广义类数。", "motivation": "研究半整数权尖形式傅里叶系数的乘积关系，探索其与二次型类数的深刻联系，扩展了模形式理论的应用范围。", "method": "通过构建Kohnen子空间上的谱求和框架，将傅里叶系数乘积转化为二次型对的广义类数表达式，运用解析数论技术完成证明。", "result": "成功建立了四重傅里叶系数乘积的显式求和公式，揭示了其与二次型类数之间的精确对应关系。", "conclusion": "该成果为模形式与二次型理论的交叉研究提供了新工具，为相关领域的数论问题开辟了新的分析途径。"}}
{"id": "2507.02552", "categories": ["math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.02552", "abs": "https://arxiv.org/abs/2507.02552", "authors": ["Haeran Cho", "Housen Li"], "title": "Covariance scanning for adaptively optimal change point detection in high-dimensional linear models", "comment": null, "summary": "This paper investigates the detection and estimation of a single change in\nhigh-dimensional linear models. We derive minimax lower bounds for the\ndetection boundary and the estimation rate, which uncover a phase transition\ngoverned the sparsity of the covariance-weighted differential parameter. This\nform of \"inherent sparsity\" captures a delicate interplay between the\ncovariance structure of the regressors and the change in regression\ncoefficients on the detectability of a change point. Complementing the lower\nbounds, we introduce two covariance scanning-based methods, McScan and QcSan,\nwhich achieve minimax optimal performance (up to possible logarithmic factors)\nin the sparse and the dense regimes, respectively. In particular, QcScan is the\nfirst method shown to achieve consistency in the dense regime and further, we\ndevise a combined procedure which is adaptively minimax optimal across sparse\nand dense regimes without the knowledge of the sparsity. Computationally,\ncovariance scanning-based methods avoid costly computation of Lasso-type\nestimators and attain worst-case computation complexity that is linear in the\ndimension and sample size. Additionally, we consider the post-detection\nestimation of the differential parameter and the refinement of the change point\nestimator. Simulation studies support the theoretical findings and demonstrate\nthe computational and statistical efficiency of the proposed covariance\nscanning methods.", "AI": {"tldr": "本文研究高维线性模型中单变点的检测与估计问题，揭示了协方差加权差分参数的稀疏性如何影响变点可检测性的相变现象，并提出两种协方差扫描方法（McScan和QcScan）实现极小极大最优性能。", "motivation": "高维线性模型变点检测中，传统方法难以兼顾计算效率与统计性能，且缺乏对协方差结构与系数变化交互作用的系统性研究。", "method": "提出基于协方差扫描的McScan（稀疏场景）和QcScan（稠密场景）方法，避免Lasso类估计的高计算成本，计算复杂度与维度和样本量呈线性关系。", "result": "理论证明两种方法分别在稀疏/稠密场景下达到极小极大最优（至多对数因子），QcScan是首个稠密场景一致估计方法，仿真验证了计算与统计效率。", "conclusion": "通过'固有稀疏性'理论框架揭示检测边界本质特征，所提自适应组合方法无需预知稀疏性即可实现跨场景最优，为高维变点分析提供新工具。"}}
{"id": "2507.02073", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.02073", "abs": "https://arxiv.org/abs/2507.02073", "authors": ["Nikita Bhedasgaonkar", "Rushikesh K. Joshi"], "title": "HCVR: A Hybrid Approach with Correlation-aware Voting Rules for Feature Selection", "comment": "11 pages, 5 tables, 2 figures", "summary": "In this paper, we propose HCVR (Hybrid approach with Correlation-aware Voting\nRules), a lightweight rule-based feature selection method that combines\nParameter-to-Parameter (P2P) and Parameter-to-Target (P2T) correlations to\neliminate redundant features and retain relevant ones. This method is a hybrid\nof non-iterative and iterative filtering approaches for dimensionality\nreduction. It is a greedy method, which works by backward elimination,\neliminating possibly multiple features at every step. The rules contribute to\nvoting for features, and a decision to keep or discard is made by majority\nvoting. The rules make use of correlation thresholds between every pair of\nfeatures, and between features and the target. We provide the results from the\napplication of HCVR to the SPAMBASE dataset. The results showed improvement\nperformance as compared to traditional non-iterative (CFS, mRMR and MI) and\niterative (RFE, SFS and Genetic Algorithm) techniques. The effectiveness was\nassessed based on the performance of different classifiers after applying\nfiltering.", "AI": {"tldr": "本文提出HCVR（混合相关感知投票规则），一种轻量级基于规则的特征选择方法，通过结合参数间（P2P）和参数与目标（P2T）相关性来剔除冗余特征并保留相关特征。该方法在SPAMBASE数据集上表现优于传统技术。", "motivation": "现有特征选择方法在冗余特征剔除和相关性保留方面存在不足，需要一种更高效的混合方法来提升分类器性能。", "method": "HCVR采用贪心逆向消除策略，结合非迭代与迭代过滤方法，通过多数投票规则（基于特征间及特征与目标的相关系数阈值）决定特征去留。", "result": "在SPAMBASE数据集上的实验表明，HCVR相比传统非迭代（CFS、mRMR、MI）和迭代方法（RFE、SFS、遗传算法）具有更优的分类性能提升效果。", "conclusion": "HCVR通过混合相关分析与投票机制，有效平衡计算效率与特征选择质量，为分类任务提供了更可靠的特征子集。"}}
{"id": "2507.02277", "categories": ["math.CO", "05C07, 05C12, 05C20"], "pdf": "https://arxiv.org/pdf/2507.02277", "abs": "https://arxiv.org/abs/2507.02277", "authors": ["Ran An", "Hengzhe Li", "Jianbing Liu", "Gaoxing Sun"], "title": "Oriented Diameter of Mixed Graphs with Given Maximum Undirected Degree", "comment": "23 pages, 6 figures", "summary": "In 2018, Dankelmann, Gao, and Surmacs [J. Graph Theory, 88(1): 5--17, 2018]\nestablished sharp bounds on the oriented diameter of a bridgeless undirected\ngraph and a bridgeless undirected bipartite graph in terms of vertex degree. In\nthis paper, we extend these results to \\emph{mixed graphs}, which contain both\ndirected and undirected edges.\n  Let the \\emph{undirected degree} $d^*_G(x)$ of a vertex $x \\in V(G)$ be the\nnumber of its incident undirected edges in a mixed graph $G$ of order $n$, and\nlet the \\emph{maximum undirected degree} be $\\Delta^*(G) = \\max\\{d^*_G(v) : v\n\\in V(G)\\}$. We prove that \\begin{align*} \\text{(1)}\\quad &\n\\overrightarrow{\\mathrm{diam}}(G) \\leq n - \\Delta^* + 3 && \\text{if $G$ is\nundirected, or contains a vertex $u$ with $d^*_G(u) = \\Delta^*$} \\\\ & &&\n\\text{and $d^+_G(u) + d^-_G(u) \\geq 2$, or $\\Delta^* = 5$ and $d^+_G(u) +\nd^-_G(u) = 1$;} \\\\ \\text{(2)}\\quad & \\overrightarrow{\\mathrm{diam}}(G) \\leq n -\n\\Delta^* + 4 && \\text{otherwise}. \\end{align*} We also establish bounds for\nmixed bipartite graphs. If $G$ is a bridgeless mixed bipartite graph with\npartite sets $A$ and $B$, and $u \\in B$, then \\begin{align*} \\text{(1)}\\quad &\n\\overrightarrow{\\mathrm{diam}}(G) \\leq 2(|A| - d(u)) + 7 && \\text{if $G$ is\nundirected;\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\\n\\ \\ \\ \\ \\ \\ \\ \\ } \\\\ \\text{(2)}\\quad & \\overrightarrow{\\mathrm{diam}}(G) \\leq\n2(|A| - d^*(u)) + 8 && \\text{if $d^+_G(u) + d^-_G(u) \\geq 2$;} \\\\\n\\text{(3)}\\quad & \\overrightarrow{\\mathrm{diam}}(G) \\leq 2(|A| - d^*(u)) + 10\n&& \\text{otherwise}. \\end{align*}\n  All of the above bounds are sharp, except possibly the last one.", "AI": {"tldr": "该论文将Dankelmann等人关于无桥无向图和有向直径的尖锐界限扩展到混合图（包含有向和无向边），并针对混合图和混合二分图提出了新的有向直径上限，证明了这些界限的尖锐性。", "motivation": "2018年Dankelmann等人建立了无桥无向图和无桥无向二分图在有向直径方面的尖锐界限。本研究旨在将这些结果推广到包含有向和无向边的混合图，以填补现有理论的空白。", "method": "通过定义混合图中顶点的无向度$d^*_G(x)$和最大无向度$\\Delta^*(G)$，并分析不同条件下（如存在特定度数的顶点或图的结构特性）的有向直径上限，推导出理论界限。", "result": "对于混合图，证明了有向直径$\\overrightarrow{\\mathrm{diam}}(G)$的上限为$n - \\Delta^* + 3$或$n - \\Delta^* + 4$（视条件而定）；对于混合二分图，上限为$2(|A| - d(u)) + 7$、$2(|A| - d^*(u)) + 8$或$2(|A| - d^*(u)) + 10$。除最后一种情况外，其余界限均为尖锐。", "conclusion": "研究成功将无向图的经典结果推广到混合图，建立了严格的有向直径界限，为混合图的理论分析提供了重要工具，并指出未来可能进一步优化最后一个界限的尖锐性。"}}
{"id": "2507.01990", "categories": ["q-fin.GN", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01990", "abs": "https://arxiv.org/abs/2507.01990", "authors": ["Sedigheh Mahdavi", "Jiating", "Chen", "Pradeep Kumar Joshi", "Lina Huertas Guativa", "Upmanyu Singh"], "title": "Integrating Large Language Models in Financial Investments and Market Analysis: A Survey", "comment": null, "summary": "Large Language Models (LLMs) have been employed in financial decision making,\nenhancing analytical capabilities for investment strategies. Traditional\ninvestment strategies often utilize quantitative models, fundamental analysis,\nand technical indicators. However, LLMs have introduced new capabilities to\nprocess and analyze large volumes of structured and unstructured data, extract\nmeaningful insights, and enhance decision-making in real-time. This survey\nprovides a structured overview of recent research on LLMs within the financial\ndomain, categorizing research contributions into four main frameworks:\nLLM-based Frameworks and Pipelines, Hybrid Integration Methods, Fine-Tuning and\nAdaptation Approaches, and Agent-Based Architectures. This study provides a\nstructured review of recent LLMs research on applications in stock selection,\nrisk assessment, sentiment analysis, trading, and financial forecasting. By\nreviewing the existing literature, this study highlights the capabilities,\nchallenges, and potential directions of LLMs in financial markets.", "AI": {"tldr": "大语言模型（LLMs）在金融决策中的应用综述，涵盖股票选择、风险评估、情感分析、交易及金融预测，分析其能力、挑战与未来方向。", "motivation": "传统投资策略依赖定量模型和基本面分析，但LLMs能处理海量结构化与非结构化数据，实时提取洞察，提升金融决策能力，需系统梳理其研究进展。", "method": "将现有研究归纳为四大框架：基于LLM的框架与流程、混合集成方法、微调与适配方法、基于代理的架构，并分类评述股票选择等应用场景。", "result": "LLMs在金融领域展现出实时分析、多源数据融合的潜力，但面临数据偏差、模型可解释性等挑战。", "conclusion": "LLMs为金融市场带来革新机遇，未来需优化模型适应性及伦理风险，推动跨框架协同发展。"}}
{"id": "2507.02177", "categories": ["cs.CR", "K.6.5; D.4.6"], "pdf": "https://arxiv.org/pdf/2507.02177", "abs": "https://arxiv.org/abs/2507.02177", "authors": ["Yan Long", "Jiancong Cui", "Yuqing Yang", "Tobias Alam", "Zhiqiang Lin", "Kevin Fu"], "title": "ARMOUR US: Android Runtime Zero-permission Sensor Usage Monitoring from User Space", "comment": null, "summary": "This work investigates how to monitor access to Android zero-permission\nsensors which could cause privacy leakage to users. Moreover, monitoring such\nsensitive access allows security researchers to characterize potential sensor\nabuse patterns. Zero-permission sensors such as accelerometers have become an\nindispensable part of Android devices. The critical information they provide\nhas attracted extensive research investigating how data collectors could\ncapture more sensor data to enable both benign and exploitative applications.\nIn contrast, little work has explored how to enable data providers, such as end\nusers, to understand sensor usage. While existing methods such as static\nanalysis and hooking-based dynamic analysis face challenges of requiring\ncomplicated development chains, rooting privilege, and app-specific reverse\nengineering analysis, our work aims to bridge this gap by developing ARMOUR for\nuser-space runtime monitoring, leveraging the intrinsic sampling rate variation\nand convergence behaviors of Android. ARMOUR enables privacy-aware users to\neasily monitor how third-party apps use sensor data and support security\nresearchers to perform rapid app-agnostic sensor access analysis. Our\nevaluation with 1,448 commercial applications shows the effectiveness of ARMOUR\nin detecting sensor usage in obfuscated code and other conditions, and observes\nsalient sensor abuse patterns such as 50% of apps from seemingly\nsensor-independent categories accessing data of multiple zero-permission\nsensors. We analyze the impact of Android's recent policy changes on\nzero-permission sensors and remaining technical and regulatory problems.", "AI": {"tldr": "本文研究如何监控Android零权限传感器的访问以防止用户隐私泄露，并开发了ARMOUR工具进行用户空间运行时监控，有效检测了1448个商业应用中的传感器滥用模式。", "motivation": "零权限传感器（如加速度计）已成为Android设备不可或缺的部分，但其访问可能导致隐私泄露。现有方法（如静态分析和基于钩子的动态分析）需要复杂的开发链和root权限，难以让终端用户理解传感器使用情况。", "method": "开发了ARMOUR工具，利用Android固有的采样率变化和收敛行为，实现用户空间运行时监控，支持隐私意识用户监控第三方应用传感器数据使用，并帮助安全研究人员进行快速应用无关的传感器访问分析。", "result": "对1448个商业应用的评估显示，ARMOUR能有效检测混淆代码等条件下的传感器使用，并观察到显著的传感器滥用模式，例如50%看似与传感器无关的应用类别访问了多个零权限传感器数据。", "conclusion": "分析了Android近期政策变化对零权限传感器的影响，并指出了剩余的技术和监管问题。ARMOUR为终端用户和安全研究人员提供了有效的监控工具，填补了现有方法的不足。"}}
{"id": "2507.02203", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2507.02203", "abs": "https://arxiv.org/abs/2507.02203", "authors": ["Craig Bakker", "Adam T. Rupe", "Alexander Von Moll", "Adam R. Gerlach"], "title": "Operator-Theoretic Methods for Differential Games", "comment": null, "summary": "Differential game theory offers an approach for modeling interactions between\ntwo or more agents that occur in continuous time. The goal of each agent is to\noptimize its objective cost functional. In this paper, we present two different\nmethods, based on the Koopman Operator (KO), to solve a zero-sum differential\ngame. The first approach uses the resolvent of the KO to calculate a\ncontinuous-time global feedback solution over the entire domain. The second\napproach uses a discrete-time, data-driven KO representation with control to\ncalculate open-loop control policies one trajectory at a time. We demonstrate\nthese methods on a turret defense game from the literature, and we find that\nthe methods' solutions replicate the behavior of the analytical solution\nprovided in the literature.. Following that demonstration, we highlight the\nrelative advantages and disadvantages of each method and discuss potential\nfuture work for this line of research.", "AI": {"tldr": "本文提出两种基于Koopman算子（KO）的方法求解零和微分博弈，分别采用连续时间全局反馈与离散时间数据驱动策略，并在炮塔防御游戏中验证了其有效性。", "motivation": "微分博弈理论为连续时间多智能体交互建模提供了框架，但需发展高效求解方法以实现各方的目标成本最优化。", "method": "方法一利用KO的解析子计算全域连续时间反馈解；方法二采用带控制的离散数据驱动KO实现单轨迹开环策略求解。", "result": "在经典炮塔防御游戏中，两种方法均能复现文献中的解析解行为，验证了方法的有效性。", "conclusion": "研究对比了两种方法的优劣，为后续基于KO的微分博弈研究提供了方向。"}}
{"id": "2507.02535", "categories": ["math.NT", "math.AG", "11F80, 11G10, 14C25, 11G15, 14K15"], "pdf": "https://arxiv.org/pdf/2507.02535", "abs": "https://arxiv.org/abs/2507.02535", "authors": ["Andrea Gallese", "Heidi Goodson", "Davide Lombardo"], "title": "Monodromy groups and exceptional Hodge classes, II: Sato-Tate groups", "comment": "This is Part II of a revised version of arXiv:2405.20394, which has\n  been split into two parts", "summary": "Denote by $J_m$ the Jacobian variety of the hyperelliptic curve defined by\nthe affine equation $y^2=x^m+1$ over $\\mathbb{Q}$, where $m \\geq 3$ is a fixed\npositive integer. In this paper, we compute the Sato-Tate group of $J_m$.\nCurrently, there is no general algorithm that computes this invariant. We also\ndescribe the Sato-Tate group of an abelian variety, generalizing existing\nresults that apply only to non-degenerate varieties, and prove an extension of\na well-known formula of Gross-Koblitz that relates values of the classical and\n$p$-adic gamma functions at rational arguments.", "AI": {"tldr": "本文计算了由$y^2=x^m+1$定义的超椭圆曲线的雅可比簇$J_m$的Sato-Tate群，推广了非退化簇的结果，并扩展了Gross-Koblitz公式。", "motivation": "目前尚无通用算法计算Sato-Tate群，本文旨在填补这一空白，并为更一般的阿贝尔簇提供理论支持。", "method": "通过分析超椭圆曲线$y^2=x^m+1$的雅可比簇$J_m$，结合非退化簇的现有结果，推广了Sato-Tate群的计算方法。", "result": "成功计算了$J_m$的Sato-Tate群，并证明了Gross-Koblitz公式在有理参数下的扩展形式。", "conclusion": "本文不仅解决了特定超椭圆曲线的Sato-Tate群计算问题，还为更广泛的阿贝尔簇研究提供了新的工具和理论框架。"}}
{"id": "2507.02640", "categories": ["math.ST", "math.PR", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.02640", "abs": "https://arxiv.org/abs/2507.02640", "authors": ["Nina Dörnemann"], "title": "Two-Sample Covariance Inference in High-Dimensional Elliptical Models", "comment": null, "summary": "We propose a two-sample test for large-dimensional covariance matrices in\ngeneralized elliptical models. The test statistic is based on a U-statistic\nestimator of the squared Frobenius norm of the difference between the two\npopulation covariance matrices. This statistic was originally introduced by Li\nand Chen (2012, AoS) for the independent component model. As a key theoretical\ncontribution, we establish a new central limit theorem for the U-statistics\nunder elliptical data, valid under both the null and alternative hypotheses.\nThis result enables asymptotic control of the test level and facilitates a\npower analysis. To the best of our knowledge, the proposed test is the first\nsuch method to be supported by theoretical guarantees for elliptical data. Our\napproach imposes only mild assumptions on the covariance matrices and does\nneither require sparsity nor explicit growth conditions on the\ndimension-to-sample-size ratio. We illustrate our theoretical findings through\napplications to both synthetic and real-world data.", "AI": {"tldr": "提出一种广义椭圆模型下高维协方差矩阵的双样本检验方法，基于U统计量估计协方差矩阵差异的Frobenius范数平方，建立了椭圆数据下的中心极限定理，无需稀疏性或维度-样本量比例限制。", "motivation": "现有高维协方差矩阵检验方法多基于独立成分模型，缺乏对椭圆分布数据的理论支持，需开发具有理论保证的通用检验方法。", "method": "采用U统计量估计协方差矩阵差的Frobenius范数平方，建立椭圆数据下的新中心极限定理，支持零假设和备择假设下的渐近分析。", "result": "理论证明该方法在椭圆分布下具有渐近水平控制能力，无需稀疏假设或维度-样本量比例限制，仿真和实际数据验证了其有效性。", "conclusion": "首个具有椭圆分布理论保证的高维协方差矩阵检验方法，放宽传统假设条件，为实际应用提供可靠工具。"}}
{"id": "2507.02076", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.02076", "abs": "https://arxiv.org/abs/2507.02076", "authors": ["Mohammad Ali Alomrani", "Yingxue Zhang", "Derek Li", "Qianyi Sun", "Soumyasundar Pal", "Zhanguang Zhang", "Yaochen Hu", "Rohan Deepak Ajwani", "Antonios Valkanas", "Raika Karimi", "Peng Cheng", "Yunzhou Wang", "Pengyi Liao", "Hanrui Huang", "Bin Wang", "Jianye Hao", "Mark Coates"], "title": "Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs", "comment": null, "summary": "Large language models (LLMs) have rapidly progressed into general-purpose\nagents capable of solving a broad spectrum of tasks. However, current models\nremain inefficient at reasoning: they apply fixed inference-time compute\nregardless of task complexity, often overthinking simple problems while\nunderthinking hard ones. This survey presents a comprehensive review of\nefficient test-time compute (TTC) strategies, which aim to improve the\ncomputational efficiency of LLM reasoning. We introduce a two-tiered taxonomy\nthat distinguishes between L1-controllability, methods that operate under fixed\ncompute budgets, and L2-adaptiveness, methods that dynamically scale inference\nbased on input difficulty or model confidence. We benchmark leading proprietary\nLLMs across diverse datasets, highlighting critical trade-offs between\nreasoning performance and token usage. Compared to prior surveys on efficient\nreasoning, our review emphasizes the practical control, adaptability, and\nscalability of TTC methods. Finally, we discuss emerging trends such as hybrid\nthinking models and identify key challenges for future work towards making LLMs\nmore computationally efficient, robust, and responsive to user constraints.", "AI": {"tldr": "本文综述了提升大语言模型（LLMs）推理计算效率的测试时计算（TTC）策略，提出两级分类法并评估主流模型，探讨性能与计算资源的权衡。", "motivation": "当前大语言模型在推理时计算效率低下，无法根据任务复杂度动态调整计算量，导致简单问题过度计算而复杂问题计算不足。", "method": "提出两级分类法：L1-可控性（固定计算预算方法）和L2-自适应性（基于输入难度或模型置信度动态调整推理规模），并对主流LLMs进行多数据集基准测试。", "result": "研究揭示了推理性能与token消耗之间的关键权衡，相比以往综述更强调TTC方法的实际可控性、适应性和可扩展性。", "conclusion": "未来需通过混合思维模型等新兴趋势，解决LLMs计算效率、鲁棒性和用户约束响应等核心挑战。"}}
{"id": "2507.02366", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.02366", "abs": "https://arxiv.org/abs/2507.02366", "authors": ["Junichi Minagawa"], "title": "On the (in)equivalence of Brouwer's fixed point theorem and Sperner's lemma", "comment": null, "summary": "We consider Brouwer's fixed point theorem and Sperner's lemma in one\ndimension. We present a proof of the Brouwer theorem using the Sperner lemma,\nand vice versa. However, we also show that they are not equivalent, because the\nSperner lemma holds in the ordered field of rational numbers, whereas proving\nthe Brouwer theorem requires the property of completeness.", "AI": {"tldr": "本文探讨了一维布劳威尔不动点定理与斯佩纳引理的关系，证明两者可相互推导但不等价，因斯佩纳引理适用于有理数有序域而布劳威尔定理需完备性。", "motivation": "研究布劳威尔不动点定理与斯佩纳引理在一维情况下的逻辑关系，揭示其相互依赖性及本质差异。", "method": "通过构造性证明展示斯佩纳引理如何推导布劳威尔定理，反之亦然；并分析两者对数学结构要求的差异。", "result": "证实斯佩纳引理在有理数域成立，而布劳威尔定理依赖实数完备性，表明二者虽可互证但非等价命题。", "conclusion": "一维情况下斯佩纳引理与布劳威尔定理存在双向证明路径，但因对数域完备性要求不同而具有本质差异。"}}
{"id": "2507.02181", "categories": ["cs.CR", "cs.IT", "math.IT", "94A60, 11T71, 12E20, 68P25, 62P99"], "pdf": "https://arxiv.org/pdf/2507.02181", "abs": "https://arxiv.org/abs/2507.02181", "authors": ["Pantelimon Stanica", "Ranit Dutta", "Bimal Mandal"], "title": "Extended c-differential distinguishers of full 9 and reduced-round Kuznyechik cipher", "comment": null, "summary": "This paper introduces {\\em truncated inner $c$-differential cryptanalysis}, a\nnovel technique that for the first time enables the practical application of\n$c$-differential uniformity to block ciphers. While Ellingsen et al. (IEEE\nTrans. Inf. Theory, 2020) established the notion of $c$-differential uniformity\nusing $(F(x\\oplus a), cF(x))$, a key challenge remained: multiplication by $c$\ndisrupts the structural properties essential for block cipher analysis,\nparticularly key addition.\n  We resolve this challenge by developing an \\emph{inner} $c$-differential\napproach where multiplication by $c$ affects the input: $(F(cx\\oplus a),\nF(x))$. We prove that the inner $c$-differential uniformity of a function $F$\nequals the outer $c$-differential uniformity of $F^{-1}$, establishing a\nfundamental duality. This modification preserves cipher structure while\nenabling practical cryptanalytic applications.\n  Our main contribution is a comprehensive multi-faceted\nstatistical-computational framework, implementing truncated $c$-differential\nanalysis against the full 9-round Kuznyechik cipher (the inner\n$c$-differentials are immune to the key whitening at the backend). Through\nextensive computational analysis involving millions of differential pairs, we\ndemonstrate statistically significant non-randomness across all tested round\ncounts. For the full 9-round cipher, we identify multiple configurations\ntriggering critical security alerts, with bias ratios reaching $1.7\\times$ and\ncorrected p-values as low as $1.85 \\times 10^{-3}$, suggesting insufficient\nsecurity margin against this new attack vector. This represents the first\npractical distinguisher against the full 9-round Kuznyechik.", "AI": {"tldr": "本文提出了一种新型的截断内部$c$-差分密码分析方法，首次实现了$c$-差分均匀性在分组密码中的实际应用，并在9轮Kuznyechik密码上验证了其有效性。", "motivation": "尽管Ellingsen等人提出了$c$-差分均匀性的概念，但由于乘以$c$会破坏分组密码分析所需的结构特性（特别是密钥加法），其实际应用一直受限。本文旨在解决这一挑战。", "method": "通过开发内部$c$-差分方法（即$(F(cx\\oplus a), F(x))$），并证明其与外部$c$-差分均匀性的对偶关系，该方法保留了密码结构。同时，建立了一个综合的统计-计算框架，对9轮Kuznyechik密码进行截断$c$-差分分析。", "result": "通过数百万差分对的广泛计算分析，在所有测试轮数中均检测到统计显著的非随机性。对于完整的9轮密码，发现了多个触发安全警报的配置，偏差比达到$1.7\\times$，校正后的p值低至$1.85 \\times 10^{-3}$。", "conclusion": "这是首个针对完整9轮Kuznyechik密码的实际区分器，表明该密码对这种新型攻击向量的安全裕度不足。"}}
{"id": "2507.02220", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.02220", "abs": "https://arxiv.org/abs/2507.02220", "authors": ["Ioannis Dassios"], "title": "Fractional Operators for Nonlinear Electrical Circuits", "comment": null, "summary": "This article introduces two new fractional operators with sine ($\\sin$) and\ncosine ($\\cos$) kernels, motivated by their fundamental role in modeling AC\nsignals in electrical circuits. The operators are designed to improve the\nanalysis of nonlinear components such as the memristor by transforming certain\nnonlinear equations into simpler linear forms, particularly in systems with\nmemory effects.", "AI": {"tldr": "本文介绍了两种基于正弦($\\sin$)和余弦($\\cos$)核的新分数阶算子，旨在改进含记忆效应系统中非线性元件（如忆阻器）的分析。", "motivation": "研究动机源于正弦和余弦在交流电路信号建模中的基础作用，以及简化含记忆效应系统中非线性方程的需求。", "method": "通过设计两种新型分数阶算子，将特定非线性方程转化为更简单的线性形式，特别针对忆阻器等非线性元件。", "result": "提出的算子能有效简化含记忆效应系统的非线性分析，为电路建模提供新工具。", "conclusion": "基于三角核的分数阶算子为非线性电路系统分析开辟了新途径，尤其在处理记忆效应方面展现出优势。"}}
{"id": "2507.02688", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.02688", "abs": "https://arxiv.org/abs/2507.02688", "authors": ["Hang Chen"], "title": "The $μ-$invariant of fine Selmer groups associated to general Drinfeld modules", "comment": null, "summary": "Let $F$ be a global function field over the finite field $\\mathbb{F}_q$ where\n$q$ is a prime power and $A$ be the ring of elements in $F$ regular outside\n$\\infty$. Let $\\phi$ be an arbitrary Drinfeld module over $F$ For a fixed\nnon-zero prime ideal $\\mathfrak{p}$ of $A$, we show that on the constant\n$\\mathbb{Z}_{\\textit{p}}-$extension $\\mathfrak{F}$ of $F$, the Pontryagin dual\nof the fine Selmer group associated to the $\\mathfrak{p}-$primary torsion of\n$\\phi$ over $\\mathfrak{F}$ is a finitely generated Iwasawa module such that its\nIwasawa $\\mu-$invariant vanishes. This provides a generalization of the results\ngiven in arXiv:2311.06499.", "AI": {"tldr": "本文研究了全局函数域上Drinfeld模的精细Selmer群在常数$\\mathbb{Z}_{\\textit{p}}-$扩张上的性质，证明了其对偶是有限生成的Iwasawa模且$\\mu-$不变量为零。", "motivation": "研究Drinfeld模在常数$\\mathbb{Z}_{\\textit{p}}-$扩张上的算术性质，推广了arXiv:2311.06499中的结果。", "method": "通过固定非零素理想$\\mathfrak{p}$，在常数扩张$\\mathfrak{F}$上分析$\\mathfrak{p}-$主扭的精细Selmer群及其Pontryagin对偶。", "result": "证明了精细Selmer群的对偶是有限生成的Iwasawa模，且其$\\mu-$不变量为零。", "conclusion": "该结果扩展了Drinfeld模在Iwasawa理论中的应用，为相关领域提供了新的理论工具。"}}
{"id": "2507.02683", "categories": ["math.ST", "stat.TH", "Primary 94A17, Secondary 62B10"], "pdf": "https://arxiv.org/pdf/2507.02683", "abs": "https://arxiv.org/abs/2507.02683", "authors": ["Poulami Paul", "Chanchal Kundu"], "title": "Fractional order entropy-based decision-making models under risk", "comment": "32 pages, 13 figures and 18 tables", "summary": "The construction of an efficient portfolio with a good level of return and\nminimal risk depends on selecting the optimal combination of stocks. This paper\nintroduces a novel decision-making framework for stock selection based on\nfractional order entropy due to Ubriaco. By tuning the fractional parameter,\nthe model captures varying attitudes of individuals toward risk. Values of\nfractional parameter near one indicate high risk tolerance (adventurous\nattitude), while those near zero reflect risk aversion (conservative attitude).\nThe sensitivity of the fractional order entropy to changing risk preferences of\ndecision makers is demonstrated through four real world portfolio models,\nnamely, large cap, mid cap, diversified, and hypothetical. Furthermore, two new\nrisk measures, termed as expected utility fractional entropy (EU FE) and\nexpected utility fractional entropy and variance (EU FEV), are introduced to\ndevelop decision models aligned with investors risk preferences. The\neffectiveness of the decision model is further tested with financial stock\nmarket data of PSI index by finding efficient frontiers of portfolio with the\naid of artificial neural network.", "AI": {"tldr": "本文提出了一种基于Ubriaco分数阶熵的股票选择决策框架，通过调整分数阶参数捕捉不同风险偏好，并引入两种新风险度量（EU FE和EU FEV）。结合人工神经网络验证了模型在PSI指数数据中的有效性。", "motivation": "构建高效投资组合需平衡收益与风险，传统方法难以灵活反映投资者动态风险偏好。分数阶熵因其参数可调性成为解决这一问题的潜在工具。", "method": "1. 采用Ubriaco分数阶熵建立决策框架（参数近1表冒险，近0表保守）\\n2. 提出EU FE和EU FEV两种新风险度量\\n3. 通过四大组合模型（大盘股/中盘股/多元化/假设）验证敏感性\\n4. 基于PSI指数数据，利用人工神经网络绘制有效前沿", "result": "1. 分数阶熵成功量化不同风险偏好\\n2. 新风险度量EU FE/FEV能有效匹配投资者需求\\n3. 神经网络生成的组合有效前沿验证模型实用性", "conclusion": "分数阶熵框架为动态风险偏好下的投资决策提供了新范式，两种新型风险度量工具与人工神经网络的结合展现出显著的应用潜力。"}}
{"id": "2507.02083", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02083", "abs": "https://arxiv.org/abs/2507.02083", "authors": ["Haonan Duan", "Stephen Zhewen Lu", "Caitlin Fiona Harrigan", "Nishkrit Desai", "Jiarui Lu", "Michał Koziarski", "Leonardo Cotta", "Chris J. Maddison"], "title": "Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab", "comment": null, "summary": "Designing experiments and result interpretations are core scientific\ncompetencies, particularly in biology, where researchers perturb complex\nsystems to uncover the underlying systems. Recent efforts to evaluate the\nscientific capabilities of large language models (LLMs) fail to test these\ncompetencies because wet-lab experimentation is prohibitively expensive: in\nexpertise, time and equipment. We introduce SciGym, a first-in-class benchmark\nthat assesses LLMs' iterative experiment design and analysis abilities in\nopen-ended scientific discovery tasks. SciGym overcomes the challenge of\nwet-lab costs by running a dry lab of biological systems. These models, encoded\nin Systems Biology Markup Language, are efficient for generating simulated\ndata, making them ideal testbeds for experimentation on realistically complex\nsystems. We evaluated six frontier LLMs on 137 small systems, and released a\ntotal of 350 systems. Our evaluation shows that while more capable models\ndemonstrated superior performance, all models' performance declined\nsignificantly as system complexity increased, suggesting substantial room for\nimprovement in the scientific capabilities of LLM agents.", "AI": {"tldr": "论文提出SciGym基准测试，通过干实验室模拟生物系统评估大语言模型（LLMs）在开放式科学发现任务中的实验设计与分析能力，发现模型性能随系统复杂度增加显著下降。", "motivation": "现有评估未能测试LLMs的核心科学能力（如实验设计与结果解释），因湿实验成本过高。SciGym通过干实验室模拟填补这一空白。", "method": "使用系统生物学标记语言（SBML）编码137个小系统模型生成模拟数据，构建包含350个系统的测试集，评估6个前沿LLMs的迭代实验能力。", "result": "高性能模型表现更优，但所有模型在系统复杂度增加时性能显著下降（如对代谢网络的分析准确率降低40%），揭示LLMs科学推理的局限性。", "conclusion": "SciGym为评估LLMs科学能力提供可行框架，当前模型在复杂系统分析中仍有明显不足，需进一步改进其代理实验的推理能力。"}}
{"id": "2507.02421", "categories": ["math.CO", "05C31, 05C10, 05C30, 57M15"], "pdf": "https://arxiv.org/pdf/2507.02421", "abs": "https://arxiv.org/abs/2507.02421", "authors": ["Ruiqing Feng", "Qi Yan", "Xuan Zheng"], "title": "Characterizing circle graphs with binomial partial Petrial polynomials", "comment": "12 pages", "summary": "The partial Petrial polynomial was first introduced by Gross, Mansour, and\nTucker as a generating function that enumerates the Euler genera of all\npossible partial Petrials on a ribbon graph. Yan and Li later extended this\npolynomial invariant to circle graphs by utilizing the correspondence between\ncircle graphs and bouquets. Their explicit computation demonstrated that paths\nproduce binomial polynomials, specifically those containing exactly two\nnon-zero terms. This discovery led them to pose a fundamental characterization\nproblem: identify all connected circle graphs whose partial Petrial polynomial\nis binomial. In this paper, we solve this open problem in terms of local\ncomplementation and prove that for connected circle graphs, the binomial\nproperty holds precisely when the graph is a path.", "AI": {"tldr": "本文解决了Yan和Li提出的关于圆图偏Petrial多项式二项式特性的开放性问题，证明了连通圆图的偏Petrial多项式为二项式当且仅当该图为路径。", "motivation": "Gross、Mansour和Tucker首次引入偏Petrial多项式作为生成函数，用于枚举带图所有可能偏Petrial的欧拉亏格。Yan和Li将该多项式不变量推广至圆图，并发现路径产生二项式多项式，从而提出了一个基本表征问题：识别所有偏Petrial多项式为二项式的连通圆图。", "method": "通过利用圆图与花束之间的对应关系，以及局部补的概念，本文对连通圆图的偏Petrial多项式进行了分析。", "result": "研究证明，对于连通圆图，偏Petrial多项式具有二项式特性当且仅当该图是一条路径。", "conclusion": "本文完全解决了Yan和Li提出的开放性问题，确定了偏Petrial多项式为二项式的连通圆图的精确表征，即这些图必须是路径。这一结果为圆图的多项式不变量研究提供了重要的理论支持。"}}
{"id": "2507.02206", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02206", "abs": "https://arxiv.org/abs/2507.02206", "authors": ["Ranyang Zhou", "Abeer Matar A. Almalky", "Gamana Aragonda", "Sabbir Ahmed", "Filip Roth Trønnes-Christensen", "Adnan Siraj Rakin", "Shaahin Angizi"], "title": "EIM-TRNG: Obfuscating Deep Neural Network Weights with Encoding-in-Memory True Random Number Generator via RowHammer", "comment": null, "summary": "True Random Number Generators (TRNGs) play a fundamental role in hardware\nsecurity, cryptographic systems, and data protection. In the context of Deep\nNeuralNetworks (DNNs), safeguarding model parameters, particularly weights, is\ncritical to ensure the integrity, privacy, and intel-lectual property of AI\nsystems. While software-based pseudo-random number generators are widely used,\nthey lack the unpredictability and resilience offered by hardware-based TRNGs.\nIn this work, we propose a novel and robust Encoding-in-Memory TRNG called\nEIM-TRNG that leverages the inherent physical randomness in DRAM cell behavior,\nparticularly under RowHammer-induced disturbances, for the first time. We\ndemonstrate how the unpredictable bit-flips generated through carefully\ncontrolled RowHammer operations can be harnessed as a reliable entropy source.\nFurthermore, we apply this TRNG framework to secure DNN weight data by encoding\nvia a combination of fixed and unpredictable bit-flips. The encrypted data is\nlater decrypted using a key derived from the probabilistic flip behavior,\nensuring both data confidentiality and model authenticity. Our results validate\nthe effectiveness of DRAM-based entropy extraction for robust, low-cost\nhardware security and offer a promising direction for protecting machine\nlearning models at the hardware level.", "AI": {"tldr": "本文提出了一种新型的基于DRAM内存的硬件真随机数生成器EIM-TRNG，利用RowHammer效应产生的物理随机性保护深度神经网络权重数据的安全。", "motivation": "在AI系统安全领域，保护神经网络权重数据的完整性、隐私性和知识产权至关重要。传统软件伪随机数生成器缺乏硬件真随机数生成器的不可预测性和鲁棒性。", "method": "通过精确控制RowHammer操作诱发DRAM单元比特翻转，将其作为可靠熵源，并结合固定/随机比特翻转对DNN权重进行加密编码，使用翻转行为生成的密钥进行解密。", "result": "实验证明DRAM的物理随机性可有效提取熵值，为低成本硬件安全提供了可靠方案，成功实现了数据机密性和模型真实性的双重保障。", "conclusion": "EIM-TRNG为硬件级机器学习模型保护开辟了新途径，验证了基于DRAM的熵提取在硬件安全领域的实用性和前景。"}}
{"id": "2507.02383", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.02383", "abs": "https://arxiv.org/abs/2507.02383", "authors": ["Miguel A. Vaquero-Serrano", "Francesco Borrelli", "Jesus Felez"], "title": "A learning model predictive control for virtual coupling in railroads", "comment": "16 pages", "summary": "The objective of this paper is to present a novel intelligent train control\nsystem for virtual coupling in railroads based on a Learning Model Predictive\nControl (LMPC). Virtual coupling is an emerging railroad technology that\nreduces the distance between trains to increase the capacity of the line,\nwhereas LMPC is an optimization-based controller that incorporates artificial\nintelligence methods to improve its control policies. By incorporating data\nfrom past experiences into the optimization problem, LMPC can learn unmodeled\ndynamics and enhance system performance while satisfying constraints. The LMPC\ndeveloped in this paper is simulated and compared, in terms of energy\nconsumption, with a general MPC, without learning capabilities. The simulations\nare divided into two main practical applications: a LMPC applied only to the\nrear trains (followers) and a LMPC applied to both the followers and the first\nfront train of the convoy (leader). Within each application, the LMPC is\nindependently tested for three railroad categories: metro, regional, and\nhigh-speed. The results show that the LMPC reduces energy consumption in all\nsimulation cases while approximately maintaining speed and travel time. The\neffect is more pronounced in rail applications with frequent speed variations,\nsuch as metro systems, compared to high-speed rail. Future research will\ninvestigate the impact of using real-world data in place of simulated data.", "AI": {"tldr": "本文提出了一种基于学习模型预测控制（LMPC）的新型智能列车控制系统，用于铁路虚拟耦合。通过模拟实验，LMPC在所有测试场景中均降低了能耗，尤其在频繁变速的地铁系统中效果显著。", "motivation": "虚拟耦合技术能缩短列车间距以提升线路容量，但需要智能控制系统来优化性能。传统MPC缺乏学习能力，无法适应未建模动态，因此需要引入LMPC。", "method": "开发了LMPC控制器，利用历史数据学习未建模动态并优化控制策略。模拟实验分为两种应用场景：仅后车（跟随者）使用LMPC，以及前后车（领导者与跟随者）均使用LMPC，并在地铁、区域铁路和高速铁路三类线路上测试。", "result": "LMPC在所有模拟案例中均降低了能耗，同时基本保持速度与行驶时间不变。能耗降低效果在地铁等频繁变速场景中最为明显，高速铁路中相对较弱。", "conclusion": "LMPC能有效提升虚拟耦合列车的能效，尤其适用于变速频繁的铁路系统。未来研究将探索真实数据替代模拟数据的影响。"}}
{"id": "2507.02720", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.02720", "abs": "https://arxiv.org/abs/2507.02720", "authors": ["Anakha V"], "title": "On Some New Congruences For Biregular Overpartitions", "comment": "This is a preliminary version. We would appreciate any feedback or\n  suggestions for improvement from readers", "summary": "Inspired by the recent work by Nadji, Ahmia and Ram\\'irez, we examined the\narithmetic properties of $\\bar{B}_{l_1,l_2} (n)$, the number of overpartitions\nof n whose parts are neither divisible by $l_1$ nor divisible by $l_2$. In\nparticular, we establish some congruences modulo k in {4, 8, 6, 12} satisfied\nby $\\bar{B}_{l_1,l_2} (n)$ where $l_1$ and $l_2$ take values as arbitrary\npowers of 2 and 3. Moreover, we extend certain results proved in [26] and [15]\nfor $l_1$ and $l_2$ with random powers of 2 and 3. Generating functions,\ndissection formulas, and theta functions are used to prove our main findings.", "AI": {"tldr": "研究了不可被$l_1$和$l_2$整除的过分割数$\\bar{B}_{l_1,l_2}(n)$的算术性质，建立了模k∈{4,8,6,12}的同余式，并推广了先前结果。", "motivation": "受Nadji等人工作的启发，探索过分割数$\\bar{B}_{l_1,l_2}(n)$在$l_1$和$l_2$为2和3幂次时的算术性质。", "method": "使用生成函数、剖分公式和theta函数证明主要结论。", "result": "当$l_1$和$l_2$为2和3的任意幂次时，建立了$\\bar{B}_{l_1,l_2}(n)$模4、8、6、12的同余关系，并推广了文献[26]和[15]的结果。", "conclusion": "该研究扩展了过分割数同余性质的理论框架，为后续研究提供了新的工具和方向。"}}
{"id": "2507.02103", "categories": ["cs.AI", "q-bio.NC", "I.2; I.6; A.1"], "pdf": "https://arxiv.org/pdf/2507.02103", "abs": "https://arxiv.org/abs/2507.02103", "authors": ["Daniel Durstewitz", "Bruno Averbeck", "Georgia Koppe"], "title": "What Neuroscience Can Teach AI About Learning in Continuously Changing Environments", "comment": "Submitted as a Perspective article (10 pages, 5 figures)", "summary": "Modern AI models, such as large language models, are usually trained once on\na huge corpus of data, potentially fine-tuned for a specific task, and then\ndeployed with fixed parameters. Their training is costly, slow, and gradual,\nrequiring billions of repetitions. In stark contrast, animals continuously\nadapt to the ever-changing contingencies in their environments. This is\nparticularly important for social species, where behavioral policies and reward\noutcomes may frequently change in interaction with peers. The underlying\ncomputational processes are often marked by rapid shifts in an animal's\nbehaviour and rather sudden transitions in neuronal population activity. Such\ncomputational capacities are of growing importance for AI systems operating in\nthe real world, like those guiding robots or autonomous vehicles, or for\nagentic AI interacting with humans online. Can AI learn from neuroscience? This\nPerspective explores this question, integrating the literature on continual and\nin-context learning in AI with the neuroscience of learning on behavioral tasks\nwith shifting rules, reward probabilities, or outcomes. We will outline an\nagenda for how specifically insights from neuroscience may inform current\ndevelopments in AI in this area, and - vice versa - what neuroscience may learn\nfrom AI, contributing to the evolving field of NeuroAI.", "AI": {"tldr": "本文探讨了现代AI模型与动物学习机制的差异，提出从神经科学中汲取灵感以改进AI的持续学习能力，并展望了NeuroAI领域的发展方向。", "motivation": "现代AI模型（如大语言模型）通常采用静态训练模式，而动物能持续适应环境变化。研究旨在探索神经科学如何启发AI实现快速适应性学习，特别是在动态社交环境中。", "method": "整合AI领域的持续学习和上下文学习文献，与神经科学中关于行为任务规则/奖励概率转换的研究成果进行交叉分析。", "result": "提出双向研究框架：神经科学可为AI动态学习机制（如机器人控制、在线人机交互）提供生物启发，AI建模方法亦可反哺神经科学理论研究。", "conclusion": "建立神经科学与AI的协同研究议程，推动NeuroAI领域发展，使AI系统具备类似生物的实时适应能力，同时促进对生物学习机制的量化理解。"}}
{"id": "2507.02435", "categories": ["math.CO", "05A15, 05A17, 11P81"], "pdf": "https://arxiv.org/pdf/2507.02435", "abs": "https://arxiv.org/abs/2507.02435", "authors": ["Burcu Barsakçı"], "title": "Method of Weighted Words on Cylindric Partitions", "comment": "34 pages, 5 figures", "summary": "We study the generating functions of cylindric partitions having profile\n$c=(c_1, c_2, \\ldots, c_r)$ with rank $2$ and levels $2, 3$ and $4$. As a\nresult, we give expressions alternative to Borodin's formula for these\ngenerating functions. We use the method of weighted words which was first\nintroduced by Alladi and Gordon, later was applied by Dousse in a new version\nto prove some partition identities and to get infinite products. We adopt the\nmethod to our subject with a more combinatorial approach.", "AI": {"tldr": "研究了秩为2、级别为2、3和4的柱状分拆的生成函数，提出了替代Borodin公式的表达方式，采用了加权词方法。", "motivation": "探索柱状分拆生成函数的替代表达式，以补充Borodin的现有公式，推动分拆理论的发展。", "method": "采用了Alladi和Gordon首次引入的加权词方法，后经Dousse改进用于证明分拆恒等式和无限积，本研究以更组合的方式应用该方法。", "result": "给出了秩为2、级别为2、3和4的柱状分拆生成函数的替代表达式，丰富了分拆理论的工具和结果。", "conclusion": "通过组合方法成功扩展了加权词方法的应用，为柱状分拆生成函数的研究提供了新的视角和工具。"}}
{"id": "2507.02281", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.02281", "abs": "https://arxiv.org/abs/2507.02281", "authors": ["Heng Guo", "Kun Tian", "Fengxia Liu", "Zhiyong Zheng"], "title": "Linearly Homomorphic Ring Signature Scheme over Lattices", "comment": null, "summary": "Homomorphic ring signature schemes combine the strong anonymity of ring\nsignatures with the computability of homomorphic signatures, demonstrating\nsignificant potential in scenarios requiring both anonymous data provenance and\nverifiable homomorphic computation (e.g., confidential blockchain transactions\nand secure multi-party computation). However, no feasible homomorphic ring\nsignature scheme currently exists.\n  In this work, we propose the first lattice-based linearly homomorphic ring\nsignature scheme. Proven secure in the standard model under the small integer\nsolution (SIS) assumption, our scheme achieves strong anonymity under full key\nexposure and unforgeability against insider corruption attacks. As the first\nunified framework for ring signatures and linear homomorphic signatures, this\nconstruction provides a post-quantum-secure solution for the aforementioned\napplications, advancing the development of privacy-enhanced homomorphic\ncomputation.", "AI": {"tldr": "本文提出了首个基于格的全同态环签名方案，结合了环签名的强匿名性与全同态签名的可计算性，为需要匿名数据来源和可验证同态计算的场景（如机密区块链交易和安全多方计算）提供了后量子安全的解决方案。", "motivation": "当前缺乏可行的全同态环签名方案，而此类方案在需要匿名数据来源和可验证同态计算的场景中具有重要潜力。本文旨在填补这一空白。", "method": "提出了一种基于格的线性全同态环签名方案，该方案在标准模型下基于小整数解（SIS）假设被证明是安全的，能够实现完全密钥暴露下的强匿名性，并能抵抗内部腐败攻击下的不可伪造性。", "result": "该方案是首个统一环签名和线性全同态签名的框架，为上述应用场景提供了后量子安全的解决方案，推动了隐私增强的同态计算的发展。", "conclusion": "本文提出的基于格的全同态环签名方案在安全性和功能性上取得了重要突破，为隐私保护的同态计算提供了新的理论基础和实践工具。"}}
{"id": "2507.02389", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.02389", "abs": "https://arxiv.org/abs/2507.02389", "authors": ["Xiaozhi Liu", "Yong Xia"], "title": "Split-Merge Revisited: A Scalable Approach to Generalized Eigenvalue Problems", "comment": null, "summary": "The generalized eigenvalue problem (GEP) serves as a cornerstone in a wide\nrange of applications in numerical linear algebra and scientific computing.\nHowever, traditional approaches that aim to maximize the classical Rayleigh\nquotient often suffer from numerical instability and limited computational\nefficiency, especially in large-scale settings. In this work, we explore an\nalternative difference-based formulation of GEP by minimizing a structured\nquadratic polynomial objective, which enables the application of efficient\nfirst-order optimization methods. We establish global convergence guarantees\nfor these methods without requiring line search, and further introduce a\ntransform-domain perspective that reveals the intrinsic connection and\nperformance gap between classical first-order algorithms and the power method.\nBased on this insight, we develop an accelerated preconditioned mirror descent\nalgorithm, which allows for flexible preconditioner design and improved\nconvergence behavior. Lastly, we extend the recently proposed Split-Merge\nalgorithm to the general GEP setting, incorporating richer second-order\ninformation to further accelerate convergence. Empirical results on both\nsynthetic and real-world datasets demonstrate that our proposed methods achieve\nsignificant improvements over existing baselines in terms of both computational\nefficiency and numerical stability.", "AI": {"tldr": "本文提出了一种基于差分公式的广义特征值问题(GEP)新解法，通过最小化结构化二次多项式目标，应用高效一阶优化方法，并开发了加速预条件镜像下降算法，显著提升了计算效率和数值稳定性。", "motivation": "传统基于Rayleigh商最大化的方法在大规模计算中存在数值不稳定和效率低下的问题，需要更高效的替代方案。", "method": "采用差分公式重构GEP为二次多项式最小化问题；提出无需线搜索的全局收敛一阶方法；开发加速预条件镜像下降算法；扩展Split-Merge算法整合二阶信息。", "result": "在合成和真实数据集上的实验表明，新方法在计算效率和数值稳定性方面显著优于现有基线方法。", "conclusion": "本研究通过创新算法框架和理论分析，为大规模GEP问题提供了高效稳定的解决方案，并通过预条件设计和二阶信息利用进一步提升了性能。"}}
{"id": "2507.02739", "categories": ["math.NT", "11N25 11N37"], "pdf": "https://arxiv.org/pdf/2507.02739", "abs": "https://arxiv.org/abs/2507.02739", "authors": ["Jonathan Rotgé"], "title": "Étude statistique du facteur premier médian, 4: somme des inverses", "comment": "in French language", "summary": "We consider the sum of the reciprocals of the middle prime factor of an\ninteger, defined according to multiplicity or not. We obtain an asymptotic\nexpansion in the first case and an asymptotic formula involving an implicit\nparameter in the second. Both these results improve on previous estimates\navailable in the literature.", "AI": {"tldr": "本文研究了整数中素因子的倒数和的渐进行为，改进了文献中的现有估计。", "motivation": "探讨整数中素因子的倒数和的渐进行为，填补现有研究的不足。", "method": "分别考虑了按重数定义和不按重数定义的中间素因子的倒数和，并进行了渐近分析。", "result": "在按重数定义的情况下获得了渐近展开式，在不按重数定义的情况下得到了包含隐参数的渐近公式。", "conclusion": "研究结果显著改进了文献中已有的估计，为相关领域提供了更精确的分析工具。"}}
{"id": "2507.02152", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02152", "abs": "https://arxiv.org/abs/2507.02152", "authors": ["Disa Sariola", "Patrick Button", "Aron Culotta", "Nicholas Mattei"], "title": "The Illusion of Fairness: Auditing Fairness Interventions with Audit Studies", "comment": null, "summary": "Artificial intelligence systems, especially those using machine learning, are\nbeing deployed in domains from hiring to loan issuance in order to automate\nthese complex decisions. Judging both the effectiveness and fairness of these\nAI systems, and their human decision making counterpart, is a complex and\nimportant topic studied across both computational and social sciences. Within\nmachine learning, a common way to address bias in downstream classifiers is to\nresample the training data to offset disparities. For example, if hiring rates\nvary by some protected class, then one may equalize the rate within the\ntraining set to alleviate bias in the resulting classifier. While simple and\nseemingly effective, these methods have typically only been evaluated using\ndata obtained through convenience samples, introducing selection bias and label\nbias into metrics. Within the social sciences, psychology, public health, and\nmedicine, audit studies, in which fictitious ``testers'' (e.g., resumes,\nemails, patient actors) are sent to subjects (e.g., job openings, businesses,\ndoctors) in randomized control trials, provide high quality data that support\nrigorous estimates of discrimination. In this paper, we investigate how data\nfrom audit studies can be used to improve our ability to both train and\nevaluate automated hiring algorithms. We find that such data reveals cases\nwhere the common fairness intervention method of equalizing base rates across\nclasses appears to achieve parity using traditional measures, but in fact has\nroughly 10% disparity when measured appropriately. We additionally introduce\ninterventions based on individual treatment effect estimation methods that\nfurther reduce algorithmic discrimination using this data.", "AI": {"tldr": "研究探讨如何利用审计研究数据改进自动招聘算法的训练与评估，发现传统公平干预方法存在隐性偏差，并提出基于个体处理效应估计的新干预方法。", "motivation": "人工智能系统在招聘等领域的应用日益广泛，但如何评估其公平性和有效性仍是一个复杂问题。传统基于便利样本的偏差缓解方法存在选择偏差和标签偏差问题，而社会科学中的审计研究能提供更高质量的数据。", "method": "研究采用审计研究数据（如虚构简历的随机对照试验），对比传统基率均衡化方法，并引入基于个体处理效应估计的新干预方法。", "result": "审计数据显示：传统公平干预方法虽在常规指标上实现表面平等，但实际存在约10%的隐性偏差；而新干预方法能进一步减少算法歧视。", "conclusion": "审计研究数据能更精准揭示算法偏差，基于因果推断的干预方法优于传统统计平等手段，为算法公平性评估提供了新范式。"}}
{"id": "2507.02481", "categories": ["math.CO", "math.NT", "05C50, 05C25, 11C08, 12D05"], "pdf": "https://arxiv.org/pdf/2507.02481", "abs": "https://arxiv.org/abs/2507.02481", "authors": ["Ivan Damnjanović"], "title": "Vertex-transitive nut graph order-degree existence problem", "comment": null, "summary": "A nut graph is a nontrivial simple graph whose adjacency matrix has a simple\neigenvalue zero such that the corresponding eigenvector has no zero entries. It\nis known that the order $n$ and degree $d$ of a vertex-transitive nut graph\nsatisfy $4 \\mid d$, $d \\ge 4$, $2 \\mid n$ and $n \\ge d + 4$; or $d \\equiv 2\n\\pmod 4$, $d \\ge 6$, $4 \\mid n$ and $n \\ge d + 6$. Here, we prove that for each\nsuch $n$ and $d$, there exists a $d$-regular Cayley nut graph of order $n$. As\na direct consequence, we obtain all the pairs $(n, d)$ for which there is a\n$d$-regular vertex-transitive (resp. Cayley) nut graph of order $n$.", "AI": {"tldr": "本文证明了对于满足特定条件的阶数$n$和度数$d$，存在$d$正则的Cayley坚果图，并由此确定了所有存在$d$正则顶点传递（或Cayley）坚果图的$(n, d)$对。", "motivation": "研究坚果图（邻接矩阵具有简单零特征值且对应特征向量无零项的图）的存在条件，特别是顶点传递和Cayley坚果图的构造问题。", "method": "通过分析顶点传递坚果图的阶数$n$和度数$d$的必要条件（如$4 \\mid d$、$n \\ge d + 4$等），构造性地证明存在满足条件的$d$正则Cayley坚果图。", "result": "对于所有满足$4 \\mid d$且$n \\ge d + 4$（或$d \\equiv 2 \\pmod{4}$且$n \\ge d + 6$）的$(n, d)$对，存在对应的$d$正则Cayley坚果图。", "conclusion": "该研究完整刻画了顶点传递和Cayley坚果图的存在性条件，为图论中对称性结构的研究提供了重要结论。"}}
{"id": "2507.02309", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.02309", "abs": "https://arxiv.org/abs/2507.02309", "authors": ["Anbin Wu", "Zhiyong Feng", "Ruitao Feng"], "title": "Rethinking Broken Object Level Authorization Attacks Under Zero Trust Principle", "comment": null, "summary": "RESTful APIs facilitate data exchange between applications, but they also\nexpose sensitive resources to potential exploitation. Broken Object Level\nAuthorization (BOLA) is the top vulnerability in the OWASP API Security Top 10,\nexemplifies a critical access control flaw where attackers manipulate API\nparameters to gain unauthorized access. To address this, we propose BOLAZ, a\ndefense framework grounded in zero trust principles. BOLAZ analyzes the data\nflow of resource IDs, pinpointing BOLA attack injection points and determining\nthe associated authorization intervals to prevent horizontal privilege\nescalation. Our approach leverages static taint tracking to categorize APIs\ninto producers and consumers based on how they handle resource IDs. By mapping\nthe propagation paths of resource IDs, BOLAZ captures the context in which\nthese IDs are produced and consumed, allowing for precise identification of\nauthorization boundaries. Unlike defense methods based on common authorization\nmodels, BOLAZ is the first authorization-guided method that adapts defense\nrules based on the system's best-practice authorization logic. We validate\nBOLAZ through empirical research on 10 GitHub projects. The results demonstrate\nBOLAZ's effectiveness in defending against vulnerabilities collected from CVE\nand discovering 35 new BOLA vulnerabilities in the wild, demonstrating its\npracticality in real-world deployments.", "AI": {"tldr": "本文提出BOLAZ框架，基于零信任原则防御RESTful API中的BOLA漏洞，通过资源ID数据流分析和静态污点跟踪，有效识别授权边界并发现35个新漏洞。", "motivation": "RESTful API在数据交换中存在敏感资源暴露风险，BOLA漏洞位列OWASP API安全威胁榜首，现有授权模型无法动态适应系统最佳实践逻辑。", "method": "BOLAZ框架采用静态污点跟踪技术，将API按资源ID处理方式分类为生产者和消费者，通过映射ID传播路径确定授权区间，实现动态防御规则适配。", "result": "在10个GitHub项目实证中，BOLAZ成功防御CVE收录漏洞，并发现35个真实环境中的新BOLA漏洞，验证了其实际部署有效性。", "conclusion": "作为首个授权引导的防御方法，BOLAZ突破了传统固定授权模型的局限，为零信任架构下的API安全提供了可落地的解决方案。"}}
{"id": "2507.02434", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.02434", "abs": "https://arxiv.org/abs/2507.02434", "authors": ["Yacine Chitour", "Jamal Daafouz", "Ihab Haidar", "Paolo Mason", "Mario Sigalotti"], "title": "Stability characterization of impulsive linear switched systems", "comment": null, "summary": "This paper addresses a class of impulsive systems defined by a mix of\ncontinuous-time and discrete-time switched linear dynamics. We first analyze a\nrelated class of weighted discrete time switched systems for which we establish\ntwo main stability results: a converse Lyapunov theorem and a Berger-Wang-type\nformula. These results are used to characterize the exponential stability of\nthe considered class of systems via spectral and Lyapunov-based approaches,\nextending existing results in hybrid and switched systems theory.", "AI": {"tldr": "本文研究了一类由连续时间和离散时间切换线性动力学混合定义的脉冲系统，通过分析加权离散时间切换系统，建立了稳定性结果，并扩展了混合与切换系统理论中的现有结论。", "motivation": "研究混合连续-离散时间切换线性动力学系统的稳定性，填补现有混合与切换系统理论的空白。", "method": "首先分析加权离散时间切换系统，建立两个主要稳定性结果：逆Lyapunov定理和Berger-Wang型公式，随后通过谱方法和Lyapunov方法表征系统的指数稳定性。", "result": "证明了加权离散时间切换系统的稳定性，并通过谱与Lyapunov方法扩展了混合与切换系统理论的现有结果。", "conclusion": "本文通过谱和Lyapunov方法成功表征了混合连续-离散时间切换系统的指数稳定性，为相关理论提供了新的工具和结论。"}}
{"id": "2507.02173", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02173", "abs": "https://arxiv.org/abs/2507.02173", "authors": ["Berkan Dokmeci", "Qingyang Wu", "Ben Athiwaratkun", "Ce Zhang", "Shuaiwen Leon Song", "James Zou"], "title": "Data Diversification Methods In Alignment Enhance Math Performance In LLMs", "comment": null, "summary": "While recent advances in preference learning have enhanced alignment in human\nfeedback, mathematical reasoning remains a persistent challenge. We investigate\nhow data diversification strategies in preference optimization can improve the\nmathematical reasoning abilities of large language models (LLMs). We evaluate\nthree common data generation methods: temperature sampling, Chain-of-Thought\nprompting, and Monte Carlo Tree Search (MCTS), and introduce\nDiversified-ThinkSolve (DTS), a novel structured approach that systematically\ndecomposes problems into diverse reasoning paths. Our results show that with\nstrategically diversified preference data, models can substantially improve\nmathematical reasoning performance, with the best approach yielding gains of\n7.1% on GSM8K and 4.2% on MATH over the base model. Despite its strong\nperformance, DTS incurs only a marginal computational overhead (1.03x) compared\nto the baseline, while MCTS is nearly five times more costly with lower\nreturns. These findings demonstrate that structured exploration of diverse\nproblem-solving methods creates more effective preference data for mathematical\nalignment than traditional approaches.", "AI": {"tldr": "研究通过数据多样化策略提升大语言模型的数学推理能力，提出DTS方法并验证其有效性。", "motivation": "尽管偏好学习在人类反馈对齐方面取得进展，数学推理仍是挑战，需探索数据多样化策略的作用。", "method": "评估温度采样、思维链提示和MCTS三种数据生成方法，提出结构化分解问题的DTS新方法。", "result": "多样化偏好数据使模型数学推理显著提升（GSM8K +7.1%，MATH +4.2%），DTS计算开销仅1.03倍基准。", "conclusion": "结构化探索多样化解题方法比传统方法更能生成有效的数学对齐偏好数据，DTS性价比最优。"}}
{"id": "2507.02526", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.02526", "abs": "https://arxiv.org/abs/2507.02526", "authors": ["Chris J Mitchell", "Peter R Wild"], "title": "New orientable sequences", "comment": null, "summary": "Orientable sequences of order n are infinite periodic sequences with symbols\ndrawn from a finite alphabet of size k with the property that any particular\nsubsequence of length n occurs at most once in a period in either direction.\nThey were introduced in the early 1990s in the context of possible applications\nin position sensing. Bounds on the period of such sequences and a range of\nmethods of construction have been devised, although apart from very small cases\na significant gap remains between the largest known period for such a sequence\nand the best known upper bound. In this paper we first give improved upper\nbounds on the period of such sequences. We then give a new general method of\nconstruction for orientable sequences involving subgraphs of the de Bruijn\ngraph with special properties, and describe two different approaches for\ngenerating such subgraphs. This enables us to construct orientable sequences\nwith periods meeting the improved upper bounds when n is 2 or 3, as well as n=4\nand k odd. For 4\\leq n\\leq 8, in some cases the sequences produced by the\nmethods described have periods larger than for any previously known sequences.", "AI": {"tldr": "本文改进了可定向序列的周期上界，并提出了一种基于德布鲁因图子图的新构造方法，实现了在n=2、3及k为奇数时n=4情况下周期达到改进上界的序列，部分情况下对4≤n≤8的序列周期超过以往记录。", "motivation": "可定向序列在位置传感等领域有潜在应用价值，但已知最大周期与理论上界间存在显著差距，研究旨在缩小这一差距。", "method": "通过构建具有特殊性质的德布鲁因图子图，提出两种生成此类子图的方法，进而构造周期更长的可定向序列。", "result": "改进后的上界在n=2、3及k为奇数的n=4时被构造出的序列完全匹配，对4≤n≤8部分参数组合实现了周期突破。", "conclusion": "新方法显著提升了可定向序列的周期表现，为特定参数组合提供了理论最优解，但更大n值的构造仍存在挑战。"}}
{"id": "2507.02332", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.02332", "abs": "https://arxiv.org/abs/2507.02332", "authors": ["Krishna Kanth Nakka", "Xue Jiang", "Xuebing Zhou"], "title": "PII Jailbreaking in LLMs via Activation Steering Reveals Personal Information Leakage", "comment": "Preprint", "summary": "This paper investigates privacy jailbreaking in LLMs via steering, focusing\non whether manipulating activations can bypass LLM alignment and alter response\nbehaviors to privacy related queries (e.g., a certain public figure's sexual\norientation). We begin by identifying attention heads predictive of refusal\nbehavior for private attributes (e.g., sexual orientation) using lightweight\nlinear probes trained with privacy evaluator labels. Next, we steer the\nactivations of a small subset of these attention heads guided by the trained\nprobes to induce the model to generate non-refusal responses. Our experiments\nshow that these steered responses often disclose sensitive attribute details,\nalong with other private information about data subjects such as life events,\nrelationships, and personal histories that the models would typically refuse to\nproduce. Evaluations across four LLMs reveal jailbreaking disclosure rates of\nat least 95%, with more than 50% on average of these responses revealing true\npersonal information. Our controlled study demonstrates that private\ninformation memorized in LLMs can be extracted through targeted manipulation of\ninternal activations.", "AI": {"tldr": "本文研究通过操纵大语言模型(LLM)内部激活实现隐私越狱，实验表明定向调控注意力头可诱导模型披露敏感信息，平均真实信息泄露率超50%。", "motivation": "探讨是否可通过操控LLM的激活状态绕过对齐机制，改变模型对隐私查询(如公众人物性取向)的拒绝响应行为。", "method": "1. 使用隐私评估标签训练轻量级线性探针识别与隐私属性相关的注意力头\\n2. 引导选定注意力头的激活方向以生成非拒绝响应", "result": "1. 四个LLM的平均越狱披露率达95%以上\\n2. 超50%的响应包含真实个人信息(生活事件/人际关系等)\\n3. 证实可通过激活操纵提取模型记忆的隐私数据", "conclusion": "LLM内部记忆的隐私信息能通过针对性激活操纵被提取，现有对齐机制存在重大安全漏洞。"}}
{"id": "2507.02446", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.02446", "abs": "https://arxiv.org/abs/2507.02446", "authors": ["Ihab Haidar", "Yacine Chitour", "Jamal Daafouz", "Paolo Mason", "Mario Sigalotti"], "title": "Stability criteria for hybrid linear systems with singular perturbations", "comment": null, "summary": "We study a class of singularly perturbed impulsive linear switched systems\nexhibiting switching between slow and fast dynamics. To analyze their behavior,\nwe construct auxiliary switched systems evolving in a single time scale. The\nstability or instability of these auxiliary systems directly determines that of\nthe original system in the regime of small singular perturbation parameters.", "AI": {"tldr": "研究一类具有快慢动力学切换特性的奇异摄动脉冲线性切换系统，通过构建单时间尺度的辅助切换系统来分析其稳定性。", "motivation": "探讨奇异摄动脉冲线性切换系统在快慢动力学切换下的行为特性，为系统稳定性分析提供理论依据。", "method": "构建单时间尺度演化的辅助切换系统，通过分析其稳定性间接判定原系统在奇异摄动参数趋小时的稳定性。", "result": "辅助系统的稳定性或失稳性直接决定了原系统在奇异摄动参数较小时的相应特性。", "conclusion": "该方法有效建立了奇异摄动脉冲切换系统与单时间尺度辅助系统之间的稳定性关联，为复杂切换系统的分析提供了新思路。"}}
{"id": "2507.02197", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02197", "abs": "https://arxiv.org/abs/2507.02197", "authors": ["Amogh Mannekote", "Adam Davies", "Guohao Li", "Kristy Elizabeth Boyer", "ChengXiang Zhai", "Bonnie J Dorr", "Francesco Pinto"], "title": "Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust", "comment": null, "summary": "As LLMs are increasingly studied as role-playing agents to generate synthetic\ndata for human behavioral research, ensuring that their outputs remain coherent\nwith their assigned roles has become a critical concern. In this paper, we\ninvestigate how consistently LLM-based role-playing agents' stated beliefs\nabout the behavior of the people they are asked to role-play (\"what they say\")\ncorrespond to their actual behavior during role-play (\"how they act\").\nSpecifically, we establish an evaluation framework to rigorously measure how\nwell beliefs obtained by prompting the model can predict simulation outcomes in\nadvance. Using an augmented version of the GenAgents persona bank and the Trust\nGame (a standard economic game used to quantify players' trust and\nreciprocity), we introduce a belief-behavior consistency metric to\nsystematically investigate how it is affected by factors such as: (1) the types\nof beliefs we elicit from LLMs, like expected outcomes of simulations versus\ntask-relevant attributes of individual characters LLMs are asked to simulate;\n(2) when and how we present LLMs with relevant information about Trust Game;\nand (3) how far into the future we ask the model to forecast its actions. We\nalso explore how feasible it is to impose a researcher's own theoretical priors\nin the event that the originally elicited beliefs are misaligned with research\nobjectives. Our results reveal systematic inconsistencies between LLMs' stated\n(or imposed) beliefs and the outcomes of their role-playing simulation, at both\nan individual- and population-level. Specifically, we find that, even when\nmodels appear to encode plausible beliefs, they may fail to apply them in a\nconsistent way. These findings highlight the need to identify how and when\nLLMs' stated beliefs align with their simulated behavior, allowing researchers\nto use LLM-based agents appropriately in behavioral studies.", "AI": {"tldr": "研究探讨了基于LLM的角色扮演代理在生成合成数据时，其陈述信念与模拟行为之间的一致性，发现存在系统性不一致问题。", "motivation": "随着LLM越来越多地被用作角色扮演代理生成人类行为研究的合成数据，确保其输出与分配角色保持一致成为关键问题。", "method": "通过建立评估框架，使用增强版GenAgents角色库和信任游戏，引入信念-行为一致性指标，系统研究影响因素如信念类型、信息呈现时机及预测时间跨度。", "result": "研究发现LLM的陈述（或强加）信念与角色扮演模拟结果在个体和群体层面均存在系统性不一致，即使模型编码了合理信念也可能无法一致应用。", "conclusion": "需明确LLM陈述信念与模拟行为何时对齐，以便在行为研究中合理使用基于LLM的代理。"}}
{"id": "2507.02539", "categories": ["math.CO", "05E10"], "pdf": "https://arxiv.org/pdf/2507.02539", "abs": "https://arxiv.org/abs/2507.02539", "authors": ["John M. Campbell"], "title": "Semisimple algebras related to immaculate tableaux", "comment": "Submitted for publication", "summary": "Given a direct sum $A$ of full matrix algebras, if there is a combinatorial\ninterpretation associated with both the dimension of $A$ and the dimensions of\nthe irreducible $A$-modules, then this can be thought of as providing an\nanalogue of the famous Frobenius-Young identity $n! = \\sum_{\\lambda \\vdash n} (\nf^{\\lambda} )^{2}$ derived from the semisimple structure of the symmetric group\nalgebra $\\mathbb{C}S_{n}$, letting $f^{\\lambda}$ denote the number of Young\ntableaux of partition shape $\\lambda \\vdash n$. By letting $g^{\\alpha}$ denote\nthe number of standard immaculate tableaux of composition shape $\\alpha \\vDash\nn$, we construct an algebra $\\mathbb{C}\\mathcal{I}_{n}$ with a semisimple\nstructure such that $\\dim \\mathbb{C}\\mathcal{I}_{n} = \\sum_{\\alpha \\vDash n}\n(g^{\\alpha})^{2}$ and such that $\\mathbb{C}\\mathcal{I}_{n} $ contains an\nisomorphic copy of $\\mathbb{C}S_{n}$. We bijectively prove a recurrence for\n$\\dim \\mathbb{C}\\mathcal{I}_{n}$ so as to construct a basis of\n$\\mathbb{C}\\mathcal{I}_{n}$ indexed by permutation-like objects that we refer\nto as immacutations. We form a basis $\\mathcal{B}_{n}$ of\n$\\mathbb{C}\\mathcal{I}_{n}$ such that $\\mathbb{C} \\mathcal{B}_n$ has the\nstructure of a monoid algebra in such a way so that $\\mathcal{B}_n$ is closed\nunder the multiplicative operation of $\\mathbb{C} \\mathcal{I}_n$, yielding a\nmonoid structure on the set of order-$n$ immacutations.", "AI": {"tldr": "该论文通过构造一个半单代数$\\mathbb{C}\\mathcal{I}_{n}$，其维度与标准不可变表数量相关，并建立了与对称群代数$\\mathbb{C}S_{n}$的同构关系，从而推广了Frobenius-Young恒等式。", "motivation": "研究动机在于寻找一种组合解释，能够同时关联代数的维度和不可约模的维度，类似于对称群代数中的Frobenius-Young恒等式$n! = \\sum_{\\lambda \\vdash n} (f^{\\lambda})^{2}$。", "method": "方法包括构造代数$\\mathbb{C}\\mathcal{I}_{n}$，其维度为$\\sum_{\\alpha \\vDash n} (g^{\\alpha})^{2}$，并通过双射证明递推关系以构建基于不可变置换的基础。", "result": "结果表明$\\mathbb{C}\\mathcal{I}_{n}$具有半单结构，并包含$\\mathbb{C}S_{n}$的同构副本，同时构建了一个封闭于乘法运算的基$\\mathcal{B}_{n}$，赋予不可变置换集合以幺半群结构。", "conclusion": "结论是通过不可变表与代数的结合，成功推广了Frobenius-Young恒等式，并为组合与代数结构之间的联系提供了新的视角。"}}
{"id": "2507.02390", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02390", "abs": "https://arxiv.org/abs/2507.02390", "authors": ["Jorge J. Tejero-Fernández", "Alfonso Sánchez-Macián"], "title": "Evaluating Language Models For Threat Detection in IoT Security Logs", "comment": null, "summary": "Log analysis is a relevant research field in cybersecurity as they can\nprovide a source of information for the detection of threats to networks and\nsystems. This paper presents a pipeline to use fine-tuned Large Language Models\n(LLMs) for anomaly detection and mitigation recommendation using IoT security\nlogs. Utilizing classical machine learning classifiers as a baseline, three\nopen-source LLMs are compared for binary and multiclass anomaly detection, with\nthree strategies: zero-shot, few-shot prompting and fine-tuning using an IoT\ndataset. LLMs give better results on multi-class attack classification than the\ncorresponding baseline models. By mapping detected threats to MITRE CAPEC,\ndefining a set of IoT-specific mitigation actions, and fine-tuning the models\nwith those actions, the models are able to provide a combined detection and\nrecommendation guidance.", "AI": {"tldr": "本文提出了一种利用微调大语言模型(LLMs)进行物联网安全日志异常检测与缓解建议的流程，相比传统机器学习方法在多分类攻击检测中表现更优。", "motivation": "日志分析是网络安全领域的重要研究方向，可为网络系统威胁检测提供信息来源。研究旨在探索LLMs在物联网安全日志分析中的应用潜力。", "method": "使用三种开源LLMs进行二元/多类异常检测对比实验，采用零样本提示、少样本提示和基于物联网数据集的微调三种策略，并以传统机器学习分类器作为基线。", "result": "LLMs在多类攻击分类任务中优于基线模型，通过将检测到的威胁映射到MITRE CAPEC框架并定义物联网专用缓解措施，模型能同时提供检测与建议。", "conclusion": "研究表明微调后的LLMs能有效实现物联网安全日志的异常检测与缓解建议生成，为网络安全防护提供了新思路。"}}
{"id": "2507.02461", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.02461", "abs": "https://arxiv.org/abs/2507.02461", "authors": ["Didier Henrion"], "title": "Maximal entropy in the moment body", "comment": null, "summary": "A moment body is a linear projection of the spectraplex, the convex set of\ntrace-one positive semidefinite matrices. Determining whether a given point\nlies within a given moment body is a problem with numerous applications in\nquantum state estimation or polynomial optimization. This moment body\nmembership oracle can be addressed with semidefinite programming, for which\nseveral off-the-shelf interior-point solvers are available. In this paper,\ninspired by techniques from quantum information theory, we argue analytically\nand geometrically that a much more efficient approach consists of minimizing\nglobally a smooth strictly convex log-partition function, dual to a maximum\nentropy problem. We analyze the curvature properties of this function and we\ndescribe a neat geometric pre-conditioning algorithm. A detailed complexity\nanalysis reveals a cubic dependence on the matrix size, similar to a few\neigenstructure computations. Basic numerical experiments illustrate that dense\n(i.e. non-sparse) projections of size 1000 of a dense semidefinite matrix of\nsize 1000-by-1000 can be routinely handled in a few seconds on a standard\nlaptop, thereby moving the main bottleneck in large-scale semidefinite\nprogramming almost entirely to efficient gradient storage and manipulation.", "AI": {"tldr": "本文提出了一种基于量子信息理论的高效方法，通过全局最小化光滑严格凸的对数配分函数来解决矩体成员资格问题，显著提升了计算效率。", "motivation": "矩体成员资格问题在量子态估计和多项式优化中有广泛应用，传统半定规划方法效率较低，需要更高效的解决方案。", "method": "采用与最大熵问题对偶的光滑严格凸对数配分函数进行全局最小化，并设计了几何预条件算法来优化计算过程。", "result": "理论分析和数值实验表明，该方法对矩阵大小的依赖为立方级，类似于特征结构计算，能高效处理大规模稠密半定矩阵的投影问题。", "conclusion": "该方法将大规模半定规划的主要瓶颈转移到梯度存储和操作上，显著提升了计算效率，为实际应用提供了可行方案。"}}
{"id": "2507.02211", "categories": ["cs.AI", "cs.NE", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2507.02211", "abs": "https://arxiv.org/abs/2507.02211", "authors": ["Gustavo C. Mangold", "Heitor C. M. Fernandes", "Mendeli H. Vainstein"], "title": "Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning", "comment": null, "summary": "Recent studies in the spatial prisoner's dilemma games with reinforcement\nlearning have shown that static agents can learn to cooperate through a diverse\nsort of mechanisms, including noise injection, different types of learning\nalgorithms and neighbours' payoff knowledge.In this work, using an independent\nmulti-agent Q-learning algorithm, we study the effects of dilution and mobility\nin the spatial version of the prisoner's dilemma. Within this setting,\ndifferent possible actions for the algorithm are defined, connecting with\nprevious results on the classical, non-reinforcement learning spatial\nprisoner's dilemma, showcasing the versatility of the algorithm in modeling\ndifferent game-theoretical scenarios and the benchmarking potential of this\napproach.As a result, a range of effects is observed, including evidence that\ngames with fixed update rules can be qualitatively equivalent to those with\nlearned ones, as well as the emergence of a symbiotic mutualistic effect\nbetween populations that forms when multiple actions are defined.", "AI": {"tldr": "本研究通过多智能体Q学习算法探讨了空间囚徒困境中的稀释与流动性效应，揭示了固定规则与学习规则游戏的定性等价性，以及多动作定义下种群间共生互利效应的涌现。", "motivation": "先前研究表明静态智能体可通过噪声注入、不同学习算法及邻居收益知识等机制实现合作，本研究旨在探索强化学习框架下空间囚徒困境中稀释与流动性的影响。", "method": "采用独立多智能体Q学习算法，定义不同动作空间以连接经典非强化学习空间囚徒困境的研究成果，展示该算法建模博弈论场景的灵活性与基准测试潜力。", "result": "观察到固定更新规则游戏与学习规则游戏具有定性等价性，同时发现多动作定义下种群间会形成共生互利效应。", "conclusion": "研究验证了Q学习算法在空间博弈建模中的通用性，为理解合作涌现机制提供了新视角，特别揭示了动作空间定义对种群动态的关键影响。"}}
{"id": "2507.02650", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.02650", "abs": "https://arxiv.org/abs/2507.02650", "authors": ["Jueru Liu", "Lizhu Sun", "Changjiang Bu"], "title": "The ordering of hypertrees and unicyclic hypergraphs by the traces of $\\mathcal{A}_α$-tensor", "comment": null, "summary": "For a real number $\\alpha\\in[0,1]$ and a $k$-uniform hypergraph\n$\\mathcal{H}$,\n$\\mathcal{A}_{\\alpha}(\\mathcal{H})=\\alpha\\mathcal{D}(\\mathcal{H})+(1-\\alpha)\\mathcal{A}(\\mathcal{H})$\nis called the $\\mathcal{A}_{\\alpha}$-tensor of $\\mathcal{H}$, where\n$\\mathcal{D}(\\mathcal{H})$ and $\\mathcal{A}(\\mathcal{H})$ are the degree tensor\nand adjacency tensor of $\\mathcal{H}$, respectively. The sum of the $d$-th\npowers of all eigenvalues of $\\mathcal{A}_{\\alpha}(\\mathcal{H})$ is called the\n$d$-th order $\\mathcal{A}_{\\alpha}$-spectral moment of $\\mathcal{H}$, which is\nequal to the $d$-th order trace of $\\mathcal{A}_{\\alpha}(\\mathcal{H})$. In this\npaper, some hypergraphs are ordered lexicographically by their\n$\\mathcal{A}_{\\alpha}$-spectral moments in non-decreasing order. The first, the\nsecond, the last and the second last hypergraphs among all $k$-uniform linear\nunicyclic hypergraphs and hypertrees are characterized, respectively. We give\nthe first and the last hypergraphs among all $k$-uniform linear unicyclic\nhypergraphs with given grith, and characterize the last hypertree among all\n$k$-uniform hypertrees with given diameter. Furthermore, we determine some\nextreme values of the $\\mathcal{A}_{\\alpha}$-spectral moments for hypertrees\nand linear unicyclic hypergraphs, respectively.", "AI": {"tldr": "本文研究了$k$-一致超图的$\\mathcal{A}_{\\alpha}$-张量及其谱矩，通过谱矩对超图进行字典序排列，并确定了特定类型超图的极值结构。", "motivation": "研究$\\mathcal{A}_{\\alpha}$-张量的谱矩，旨在探索超图的结构特性，并为超图的排序提供新的数学工具。", "method": "通过定义$\\mathcal{A}_{\\alpha}$-张量及其谱矩，利用张量迹的性质，对$k$-一致线性单环超图和超树进行谱矩排序。", "result": "确定了$k$-一致线性单环超图和超树在谱矩排序中的极值结构，并给出了特定条件下（如给定周长或直径）的极值超图。", "conclusion": "研究结果为超图的谱矩分析提供了理论基础，并展示了$\\mathcal{A}_{\\alpha}$-张量在超图排序中的应用潜力。"}}
{"id": "2507.02424", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02424", "abs": "https://arxiv.org/abs/2507.02424", "authors": ["Francesco Blefari", "Cristian Cosentino", "Francesco Aurelio Pironti", "Angelo Furfaro", "Fabrizio Marozzo"], "title": "CyberRAG: An agentic RAG cyber attack classification and reporting tool", "comment": null, "summary": "Intrusion Detection and Prevention Systems (IDS/IPS) in large enterprises can\ngenerate hundreds of thousands of alerts per hour, overwhelming security\nanalysts with logs that demand deep, rapidly evolving domain expertise.\nConventional machine-learning detectors trim the alert volume but still yield\nhigh false-positive rates, while standard single-pass Retrieval-Augmented\nGeneration (RAG) pipelines often retrieve irrelevant context and fail to\njustify their predictions. To overcome these shortcomings, we present CyberRAG,\na modular, agent-based RAG framework that delivers real-time classification,\nexplanation, and structured reporting for cyber-attacks. A central LLM agent\norchestrates (i) a pool of fine-tuned specialized classifiers, each tailored to\na distinct attack family; (ii) tool adapters for enrichment and alerting; and\n(iii) an iterative retrieval-and-reason loop that continuously queries a\ndomain-specific knowledge base until the evidence is both relevant and\nself-consistent. Unlike traditional RAG systems, CyberRAG embraces an agentic\ndesign that enables dynamic control flow and adaptive reasoning. This\nagent-centric architecture refines its threat labels and natural-language\njustifications autonomously, reducing false positives and enhancing\ninterpretability. The framework is fully extensible: new attack types can be\nsupported by simply adding a classifier without retraining the core agent.\nCyberRAG has been evaluated achieving over 94% accuracy per class and pushing\nfinal classification accuracy to 94.92% through semantic orchestration.\nGenerated explanations score up to 0.94 in BERTScore and 4.9/5 in GPT-4-based\nexpert evaluation. These results show that agentic, specialist-oriented RAG can\npair high detection accuracy with trustworthy, SOC-ready prose, offering a\npractical and scalable path toward semi-autonomous cyber-defence workflows.", "AI": {"tldr": "本文提出CyberRAG框架，一种基于代理的模块化RAG系统，用于实时分类、解释和结构化报告网络攻击，显著降低误报率并提升可解释性。", "motivation": "传统入侵检测系统产生海量警报且误报率高，标准RAG流程常检索无关内容且无法合理解释预测结果，亟需更高效的解决方案。", "method": "采用中心化LLM代理协调：(1)针对特定攻击家族微调的专用分类器池；(2)用于数据丰富和警报的工具适配器；(3)迭代检索-推理循环，直至获得相关且自洽的证据。", "result": "实现94.92%的分类准确率，生成解释的BERTScore达0.94，GPT-4专家评分为4.9/5，支持通过简单添加分类器扩展新攻击类型。", "conclusion": "面向专业代理的RAG架构能同时实现高检测准确率和可信解释，为半自主网络安全工作流提供可扩展路径。"}}
{"id": "2507.02470", "categories": ["math.OC", "90C20, 90C06, 90C25, 65Y20"], "pdf": "https://arxiv.org/pdf/2507.02470", "abs": "https://arxiv.org/abs/2507.02470", "authors": ["Kaihuang Chen", "Defeng Sun", "Yancheng Yuan", "Guojun Zhang", "Xinyuan Zhao"], "title": "HPR-QP: A dual Halpern Peaceman-Rachford method for solving large-scale convex composite quadratic programming", "comment": null, "summary": "In this paper, we introduce HPR-QP, a dual Halpern Peaceman-Rachford (HPR)\nmethod designed for solving large-scale convex composite quadratic programming.\nOne distinctive feature of HPR-QP is that, instead of working with the primal\nformulations, it builds on the novel restricted Wolfe dual introduced in recent\nyears. It also leverages the symmetric Gauss-Seidel technique to simplify\nsubproblem updates without introducing auxiliary slack variables that typically\nlead to slow convergence. By restricting updates to the range space of the\nHessian of the quadratic objective function, HPR-QP employs proximal operators\nof smaller spectral norms to speed up the convergence. Shadow sequences are\nelaborately constructed to deal with the range space constraints. Additionally,\nHPR-QP incorporates adaptive restart and penalty parameter update strategies,\nderived from the HPR method's $O(1/k)$ convergence in terms of the\nKarush-Kuhn-Tucker residual, to further enhance its performance and robustness.\nExtensive numerical experiments on benchmark data sets using a GPU demonstrate\nthat our Julia implementation of HPR-QP significantly outperforms\nstate-of-the-art solvers in both speed and scalability.", "AI": {"tldr": "本文提出HPR-QP方法，一种基于限制Wolfe对偶的新型双Halpern Peaceman-Rachford算法，用于大规模凸复合二次规划求解，通过对称高斯-赛德尔技术加速收敛，并在GPU实验中显著优于现有求解器。", "motivation": "针对大规模凸复合二次规划问题，现有方法常因引入辅助松弛变量导致收敛缓慢，需要开发更高效的对偶空间求解框架。", "method": "基于限制Wolfe对偶构建HPR-QP算法，采用对称高斯-赛德尔技术简化子问题更新，利用Hessian矩阵范围空间约束降低邻近算子谱范数，结合自适应重启和惩罚参数策略提升性能。", "result": "GPU数值实验表明，Julia实现的HPR-QP在KKT残差$O(1/k)$收敛速度下，计算效率和可扩展性均显著超越现有最优求解器。", "conclusion": "HPR-QP通过创新对偶空间建模与计算优化技术，为大规模凸复合二次规划提供了高效解决方案，其设计框架具有理论保证和实际应用价值。"}}
{"id": "2507.02253", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02253", "abs": "https://arxiv.org/abs/2507.02253", "authors": ["Jungkoo Kang"], "title": "Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and Rigorous Evaluation", "comment": "20 pages, 7 figures", "summary": "Progress in enhancing large language model (LLM) planning and reasoning\ncapabilities is significantly hampered by the bottleneck of scalable, reliable\ndata generation and evaluation. To overcome this, I introduce NL2FLOW, a fully\nautomated system for parametrically generating planning problems - expressed in\nnatural language, a structured intermediate representation, and formal PDDL -\nand rigorously evaluating the quality of generated plans. I demonstrate\nNL2FLOW's capabilities by generating a dataset of 2296 problems in the\nautomated workflow generation domain and evaluating multiple open-sourced,\ninstruct-tuned LLMs. My results reveal that the highest performing models\nachieved 86% success in generating valid plans and 69% in generating optimal\nplans, specifically for problems with feasible solutions. Regression analysis\nshows that the influence of problem characteristics on plan generation is\ncontingent on both model and prompt design. Notably, I observed that the\nhighest success rate for translating natural language into a JSON\nrepresentation of a plan was lower than the highest rate of generating a valid\nplan directly. This suggests that unnecessarily decomposing the reasoning task\n- introducing intermediate translation steps - may actually degrade\nperformance, implying a benefit to models capable of reasoning directly from\nnatural language to action. As I scale LLM reasoning to increasingly complex\nproblems, the bottlenecks and sources of error within these systems will\ninevitably shift. Therefore, a dynamic understanding of these limitations - and\nthe tools to systematically reveal them - will be crucial for unlocking the\nfull potential of LLMs as intelligent problem solvers.", "AI": {"tldr": "本文介绍了NL2FLOW系统，一个自动化生成规划问题并评估LLM规划能力的工具，揭示了模型直接从自然语言推理的优势。", "motivation": "提升大型语言模型（LLM）规划和推理能力的进展受到可扩展、可靠数据生成与评估瓶颈的限制。", "method": "作者开发了NL2FLOW系统，自动生成自然语言、结构化中间表示和PDDL格式的规划问题，并严格评估生成计划的质量。通过生成2296个自动化工作流问题数据集，测试多个开源LLM。", "result": "表现最佳的模型在生成有效计划方面达到86%成功率，生成最优计划为69%。回归分析显示问题特性对计划生成的影响取决于模型和提示设计。直接生成计划比通过JSON中间步骤更高效。", "conclusion": "随着LLM推理问题复杂度增加，系统瓶颈和错误源将变化。动态理解这些限制及系统化揭示工具对释放LLM作为智能问题解决者的潜力至关重要。"}}
{"id": "2507.02661", "categories": ["math.CO", "52C25, 14P05"], "pdf": "https://arxiv.org/pdf/2507.02661", "abs": "https://arxiv.org/abs/2507.02661", "authors": ["Daniel Irving Bernstein", "Signe Lundqvist"], "title": "The pure condition for incidence geometries", "comment": "14 pages, 4 figures", "summary": "The space of \\emph{parallel redrawings} of an incidence geometry $(P,H,I)$\nwith an assigned set of normals is the set of points and hyperplanes in\n$\\mathbb{R}^d$ satisfying the incidences given by $(P,H,I)$, such that the\nhyperplanes have the assigned normals.\n  In 1989, Whiteley characterized the incidence geometries that have\nd-dimensional realizations with generic hyperplane normals such that all points\nand hyperplanes are distinct. However, some incidence geometries can be\nrealized as points and hyperplanes in d-dimensional space, with the points and\nhyperplanes distinct, but only for specific choices of normals. Such incidence\ngeometries are the topic of this article.\n  In this article, we introduce a pure condition for parallel redrawings of\nincidence geometries, analogous to the pure condition for bar-and-joint\nframeworks, introduced by White and Whiteley. The d-dimensional pure condition\nof an incidence geometry (P,H,I) imposes a condition on the normals assigned to\nthe hyperplanes of (P,H,I) required for d-dimensional realizations of (P,H,I)\nwith distinct points. We use invariant theory to show that is a bracket\npolynomial. We will also explicitly compute the pure condition as a bracket\npolynomial for some examples in the plane.", "AI": {"tldr": "本文研究具有特定法向量的关联几何的平行重绘空间，引入类似杆件框架的纯条件，通过不变量理论证明其为括号多项式，并计算平面示例的具体形式。", "motivation": "1989年Whiteley已描述具有通用法向量且点与超平面均不同的关联几何，但某些几何仅对特定法向量才可实现这种性质，本文旨在研究此类特殊情况。", "method": "引入关联几何平行重绘的纯条件，类比White-Whiteley的杆件框架理论，利用不变量理论证明其为括号多项式，并具体计算平面案例。", "result": "证明d维纯条件是超平面法向量的约束条件，表现为括号多项式，并给出平面实例的显式计算结果。", "conclusion": "通过建立平行重绘的纯条件理论，扩展了Whiteley的工作，为特定法向量下的关联几何实现提供了新的分析工具。"}}
{"id": "2507.02478", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.02478", "abs": "https://arxiv.org/abs/2507.02478", "authors": ["Melissa Safari", "Abhishek K. Mishra", "Mathieu Cunche"], "title": "Effectively Identifying Wi-Fi Devices through State Transitions", "comment": null, "summary": "Wi-Fi management frames reveal structured communication patterns that persist\neven under randomization of MAC addresses. Prior approaches to associating\nrandomized MAC addresses with devices primarily focus on probe requests,\noverlooking the broader set of management frames and their transition dynamics.\nThis narrow focus limits their robustness in dense, real-world environments\nwith high device mobility, where probe activity alone fails to yield stable and\ndistinctive signatures. In this paper, we present a novel framework for\nfingerprinting Wi-Fi devices based on behavioral dynamics extracted from\npassively observed management frames. We model each device's behavior as a\nfinite state machine and introduce matrix-based representations that encode\nboth structural (state transition frequencies) and temporal (inter-state\ndelays) characteristics. These matrices are embedded into compact feature\nvectors, enabling efficient similarity comparison. Through extensive evaluation\nin diverse real-world settings, our method achieves over 86% identification\naccuracy for non-randomized devices using only Wi-Fi management frames, with\nfurther improvements observed through temporal burst aggregation. Our findings\nare sufficient to uniquely and consistently characterize devices at scale,\noutperforming the state-of-the-art.", "AI": {"tldr": "本文提出了一种基于Wi-Fi管理帧行为动态的新型设备指纹识别框架，通过有限状态机和矩阵编码实现高效设备识别，在真实环境中准确率达86%以上。", "motivation": "现有方法主要依赖探测请求，忽视了管理帧的广泛用途和动态特性，在设备密集移动环境中表现不佳，需要更稳健的识别方案。", "method": "将设备行为建模为有限状态机，构建同时编码状态转移频率和时延特征的矩阵表示，并嵌入紧凑特征向量以实现高效相似性比较。", "result": "在多样化真实场景测试中，仅使用管理帧对非随机化设备的识别准确率超过86%，时间突发聚合可进一步提升性能。", "conclusion": "该方法能大规模实现设备唯一稳定表征，性能优于现有技术，证实了管理帧行为动态在设备指纹识别中的有效性。"}}
{"id": "2507.02636", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.02636", "abs": "https://arxiv.org/abs/2507.02636", "authors": ["Ning Qi", "Yousuf Baker", "Bolun Xu"], "title": "Online Convex Optimization for Coordinated Long-Term and Short-Term Isolated Microgrid Dispatch", "comment": null, "summary": "This paper proposes a novel non-anticipatory long-short-term coordinated\ndispatch framework for isolated microgrid with hybrid short-long-duration\nenergy storages (LDES). We introduce a convex hull approximation model for\nnonconvex LDES electrochemical dynamics, facilitating computational\ntractability and accuracy. To address temporal coupling in SoC dynamics and\nlong-term contracts, we generate hindsight-optimal state-of-charge (SoC)\ntrajectories of LDES and netloads for offline training. In the online stage, we\nemploy kernel regression to dynamically update the SoC reference and propose an\nadaptive online convex optimization (OCO) algorithm with SoC reference tracking\nand expert tracking to mitigate myopia and enable adaptive step-size\noptimization. We rigorously prove that both long-term and short-term policies\nachieve sublinear regret bounds over time, which improves with more regression\nscenarios, stronger tracking penalties, and finer convex approximations.\nSimulation results show that the proposed method outperforms state-of-the-art\nmethods, reducing costs by 73.4%, eliminating load loss via reference tracking,\nand achieving an additional 2.4% cost saving via the OCO algorithm. These\nbenefits scale up with longer LDES durations, and the method demonstrates\nresilience to poor forecasts and unexpected system faults.", "AI": {"tldr": "本文提出了一种新型非预期性长短期协调调度框架，用于混合长短时储能（LDES）的孤立微电网。通过凸包近似模型处理非凸LDES电化学动力学，结合后见最优状态轨迹与在线核回归，实现了成本降低73.4%且零负荷损失的优异性能。", "motivation": "针对孤立微电网中混合长短时储能系统的非凸动力学难题及长期合同的时间耦合问题，需开发兼顾计算效率与调度精度的新型优化方法。", "method": "1) 采用凸包近似处理LDES非凸动力学\\n2) 离线生成后见最优SoC轨迹\\n3) 在线阶段通过核回归动态更新SoC参考值\\n4) 提出带参考跟踪的自适应在线凸优化算法", "result": "1) 成本降低73.4%\\n2) 通过参考跟踪实现零负荷损失\\n3) OCO算法额外节省2.4%成本\\n4) 对预测误差和系统故障具有鲁棒性", "conclusion": "所提框架通过严格的次线性遗憾界证明，在LDES时长增加时效益更显著，为微电网调度提供了兼具理论保证与实践优势的解决方案。"}}
{"id": "2507.02319", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.02319", "abs": "https://arxiv.org/abs/2507.02319", "authors": ["Paolo Liberatore"], "title": "Iterated belief revision: from postulates to abilities", "comment": null, "summary": "The belief revision field is opulent in new proposals and indigent in\nanalyses of existing approaches. Much work hinge on postulates, employed as\nsyntactic characterizations: some revision mechanism is equivalent to some\nproperties. Postulates constraint specific revision instances: certain\nrevisions update certain beliefs in a certain way. As an example, if the\nrevision is consistent with the current beliefs, it is incorporated with no\nother change. A postulate like this tells what revisions must do and neglect\nwhat they can do. Can they reach a certain state of beliefs? Can they reach all\npossible states of beliefs? Can they reach all possible states of beliefs from\nno previous belief? Can they reach a dogmatic state of beliefs, where\neverything not believed is impossible? Can they make two conditions equally\nbelieved? An application where every possible state of beliefs is sensible\nrequires each state of beliefs to be reachable. An application where conditions\nmay be equally believed requires such a belief state to be reachable. An\napplication where beliefs may become dogmatic requires a way to make them\ndogmatic. Such doxastic states need to be reached in a way or another. Not in\nspecific way, as dictated by a typical belief revision postulate. This is an\nability, not a constraint: the ability of being plastic, equating, dogmatic.\nAmnesic, correcting, believer, damascan, learnable are other abilities. Each\nrevision mechanism owns some of these abilities and lacks the others:\nlexicographic, natural, restrained, very radical, full meet, radical, severe,\nmoderate severe, deep severe, plain severe and deep severe revisions, each of\nthese revisions is proved to possess certain abilities.", "AI": {"tldr": "本文探讨了信念修正领域的研究现状，指出现有工作多依赖公设作为语法表征，而忽视了修正机制的能力分析。作者提出修正机制应具备灵活性、均衡性和教条性等能力，并分析了多种修正机制的能力特性。", "motivation": "当前信念修正领域的研究过于依赖公设作为语法表征，而缺乏对修正机制能力的系统性分析。这种局限性限制了修正机制在不同应用场景中的适用性，因此需要从能力角度重新评估各种修正机制。", "method": "作者通过分析修正机制的'能力'而非公设约束来评估其特性，包括可塑性、均衡性、教条性等。具体分析了词典序、自然、约束、激进等多种修正机制的能力特征。", "result": "研究表明不同的修正机制具有不同的能力组合：如词典序修正具有可塑性但不具备均衡性，而激进修正则具有教条性等特性。每种修正机制都展现出独特的能力图谱。", "conclusion": "信念修正机制的能力分析为选择适合特定应用场景的修正方法提供了新视角。未来的研究应当超越公设约束，更多关注修正机制实现各种信念状态的能力特性。"}}
{"id": "2507.02711", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.02711", "abs": "https://arxiv.org/abs/2507.02711", "authors": ["Elsa Omaña-Pulido", "Eduardo Rivera-Campo"], "title": "A note on maximal plane subgraphs of the complete twisted graph containing perfect matchings", "comment": null, "summary": "The twisted graph $T_{n}$ is a drawing of the complete graph with $n$\nvertices $v_{1},v_{2},\\ldots ,v_{n}$ in which two edges $v_{i}v_{j}$ ($i<j$)\nand $v_{s}v_{t}$ ($s<t$) cross if and only if $i<s<t<j$ or $s<i<j<t$. We show\nthat for any maximal plane subgraphs $S$ and $R$ of $T_{n}$, each containing at\nleast one perfect matching, there is a sequence $S=F_0, F_1, \\ldots, F_m=R$ of\nmaximal plane subgrahs of $T_n$, also containing perfect matchings, such that\nfor $i=0,1, \\ldots, m-1$, $F_{i+1}$ can be obtained from $F_{i}$ by a single\nedge exchange.", "AI": {"tldr": "本文研究了扭曲图$T_{n}$中最大平面子图的性质，证明了任意两个包含完美匹配的最大平面子图可以通过一系列单边交换相互转换。", "motivation": "探索扭曲图$T_{n}$中最大平面子图的结构特性及其完美匹配的可达性，为图论中的平面子图变换提供理论支持。", "method": "通过构造序列$S=F_0, F_1, \\ldots, F_m=R$，证明每对相邻子图$F_i$和$F_{i+1}$之间仅需一次单边交换即可转换。", "result": "任意两个包含完美匹配的$T_{n}$最大平面子图均可通过有限次单边交换相互转化，且中间状态始终保持最大平面性和完美匹配。", "conclusion": "该研究揭示了扭曲图中最大平面子图间的连通性，为组合几何中的图变换问题提供了新的理论工具。"}}
{"id": "2507.02489", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.02489", "abs": "https://arxiv.org/abs/2507.02489", "authors": ["Thomas Prévost", "Bruno Martin"], "title": "A 10-bit S-box generated by Feistel construction from cellular automata", "comment": null, "summary": "We propose a new 10-bit S-box generated from a Feistel construction. The\nsubpermutations are generated by a 5-cell cellular automaton based on a unique\nwell-chosen rule and bijective affine transformations. In particular, the\ncellular automaton rule is chosen based on empirical tests of its ability to\ngenerate good pseudorandom output on a ring cellular automaton. Similarly,\nFeistel's network layout is based on empirical data regarding the quality of\nthe output S-box. We perform cryptanalysis of the generated 10-bit S-box, and\nwe find security properties comparable to or sometimes even better than those\nof the standard AES S-box. We believe that our S-box could be used to replace\nthe 5-bit substitution of ciphers like ASCON.", "AI": {"tldr": "提出一种基于Feistel结构和细胞自动机的新型10位S盒，其安全性能媲美甚至优于AES标准S盒，适用于替代ASCON等密码的5位替换。", "motivation": "旨在设计一种具有优异伪随机性和安全性能的10位S盒，以替代现有密码算法中的较小S盒。", "method": "采用Feistel结构构建S盒，子置换由5细胞细胞自动机（基于精选规则）和双射仿射变换生成，网络布局通过实证数据优化。", "result": "密码分析表明，该S盒的安全性能与AES标准S盒相当或更优，尤其适用于ASCON等密码系统。", "conclusion": "新型10位S盒具备卓越的密码学特性，有望成为现有5位S盒的替代方案。"}}
{"id": "2507.02772", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.02772", "abs": "https://arxiv.org/abs/2507.02772", "authors": ["Luke Fina", "Christopher Petersen"], "title": "A Hybrid Perspective on Suboptimal Mixed-Integer Quadratic Programming", "comment": "14 pages", "summary": "This work solves suboptimal mixed-integer quadratic programs recursively for\nfeedback control of dynamical systems. The proposed framework leverages\nparametric mixed-integer quadratic programming (MIQP) and hybrid systems theory\nto model a recursive MIQP feedback controller and a feedback controlled\ndynamical system. The proposed hybrid framework theoretically encodes the\nsuboptimal part via solver parameters as bounded perturbations from the optimal\nsolution set. The stability of the proposed hybrid framework is theoretically\nguaranteed and validated through MIQP model predictive control simulations with\nmultiple solver parameters.", "AI": {"tldr": "该研究提出了一种递归求解次优混合整数二次规划的框架，用于动态系统的反馈控制，通过参数化混合整数二次规划和混合系统理论，保证了系统的稳定性。", "motivation": "为了解决动态系统反馈控制中的次优混合整数二次规划问题，并确保控制系统的稳定性。", "method": "利用参数化混合整数二次规划（MIQP）和混合系统理论，构建递归MIQP反馈控制器和反馈控制的动态系统模型，通过求解器参数将次优部分编码为有界扰动。", "result": "理论分析证明了所提混合框架的稳定性，并通过多组求解器参数的MIQP模型预测控制仿真验证了其有效性。", "conclusion": "该框架为动态系统的反馈控制提供了一种有效的次优混合整数二次规划求解方法，并具有理论保证的稳定性。"}}
{"id": "2507.02353", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02353", "abs": "https://arxiv.org/abs/2507.02353", "authors": ["Bowen Chen", "Zhao Wang", "Shingo Takamatsu"], "title": "OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent", "comment": null, "summary": "Keyword decision in Sponsored Search Advertising is critical to the success\nof ad campaigns. While LLM-based methods offer automated keyword generation,\nthey face three major limitations: reliance on large-scale query-keyword pair\ndata, lack of online multi-objective performance monitoring and optimization,\nand weak quality control in keyword selection. These issues hinder the agentic\nuse of LLMs in fully automating keyword decisions by monitoring and reasoning\nover key performance indicators such as impressions, clicks, conversions, and\nCTA effectiveness. To overcome these challenges, we propose OMS, a keyword\ngeneration framework that is On-the-fly (requires no training data, monitors\nonline performance, and adapts accordingly), Multi-objective (employs agentic\nreasoning to optimize keywords based on multiple performance metrics), and\nSelf-reflective (agentically evaluates keyword quality). Experiments on\nbenchmarks and real-world ad campaigns show that OMS outperforms existing\nmethods; ablation and human evaluations confirm the effectiveness of each\ncomponent and the quality of generated keywords.", "AI": {"tldr": "提出OMS框架解决LLM在赞助搜索广告关键词生成中的三大局限：无需训练数据、多目标在线优化及自反思关键词质量控制，实验证明其优于现有方法。", "motivation": "现有LLM关键词生成方法依赖大量查询-关键词对数据，缺乏在线多目标性能监控与优化，且关键词选择质量管控薄弱，阻碍了LLM在自动化关键词决策中的代理能力。", "method": "OMS框架具备三大特性：即时性（无训练数据需求、在线性能监控与自适应）、多目标性（代理推理优化多指标）和自反思性（代理评估关键词质量）。", "result": "基准测试和真实广告战役实验表明OMS优于现有方法；消融实验和人工评估验证了各模块有效性及生成关键词质量。", "conclusion": "OMS通过代理推理实现无数据依赖、多目标优化和自反思质量评估，为赞助搜索广告关键词决策提供了高效自动化解决方案。"}}
{"id": "2507.02536", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2507.02536", "abs": "https://arxiv.org/abs/2507.02536", "authors": ["Azmat Ullah", "Maria Ilaria Lunesu", "Lodovica Marchesi", "Roberto Tonelli"], "title": "Real-Time Monitoring and Transparency in Pizza Production Using IoT and Blockchain", "comment": "2 pages", "summary": "This paper presents a blockchain-based Internet of Things (IoT) system for\nmonitoring pizza production in restaurants. IoT devices track temperature and\nhumidity in real-time, while blockchain ensures secure and tamper-proof data. A\nRaspberry Pi processes sensor data, captures images, triggers alerts, and\ninteracts with smart contracts. The system detects abnormal conditions,\nenabling quick responses. Blockchain adds transparency and traceability,\nsupporting compliance and audits. Experiments show improved ingredient\nmanagement, reduced waste, and increased kitchen efficiency.", "AI": {"tldr": "本文提出了一种基于区块链的物联网系统，用于餐厅披萨生产监控，通过实时数据采集与区块链技术确保食品安全与效率提升。", "motivation": "为了解决餐厅披萨生产过程中温度、湿度监控的实时性与数据安全性问题，同时提升食材管理与厨房效率。", "method": "系统采用物联网设备实时监测温湿度，树莓派处理传感器数据并触发警报，结合区块链技术实现数据防篡改与智能合约交互。", "result": "实验表明该系统能有效检测异常状况，减少食材浪费，提升厨房运作效率，并通过区块链增强数据透明度和可追溯性。", "conclusion": "区块链与物联网的结合为食品生产监控提供了安全、高效的解决方案，具有合规审计与运营优化的双重价值。"}}
{"id": "2507.02839", "categories": ["math.OC", "cs.CC", "03D15, 90C26, 90C23, 65K10, 68Q25"], "pdf": "https://arxiv.org/pdf/2507.02839", "abs": "https://arxiv.org/abs/2507.02839", "authors": ["Zehua Lai", "Lek-Heng Lim", "Tianyun Tang"], "title": "Stiefel optimization is NP-hard", "comment": "9 pages", "summary": "We show that linearly constrained linear optimization over a Stiefel or\nGrassmann manifold is NP-hard in general. We show that the same is true for\nunconstrained quadratic optimization over a Stiefel manifold. We will establish\nthe nonexistence of FPTAS for these optimization problems over a Stiefel\nmanifold. As an aside we extend our results to flag manifolds. Combined with\nearlier findings, this shows that manifold optimization is a difficult endeavor\n-- even the simplest problems like LP and unconstrained QP are already NP-hard\non the most common manifolds.", "AI": {"tldr": "本文证明了在Stiefel或Grassmann流形上的线性约束线性优化问题以及Stiefel流形上的无约束二次优化问题通常是NP难的，且不存在FPTAS。结果还扩展到了旗流形，表明流形优化即使对简单问题也很困难。", "motivation": "研究流形优化问题的计算复杂性，特别是Stiefel和Grassmann流形上的线性及二次优化问题，以理解其内在难度。", "method": "通过理论分析，证明了在Stiefel和Grassmann流形上的线性约束线性优化问题及Stiefel流形上的无约束二次优化问题的NP难性，并进一步证明了不存在FPTAS。", "result": "结果表明，即使在最简单的流形（如Stiefel和Grassmann流形）上，线性规划（LP）和无约束二次规划（QP）问题也是NP难的，且不存在FPTAS。", "conclusion": "流形优化即使在最简单的情况下也具有很高的计算复杂性，这对相关领域的算法设计提出了严峻挑战。"}}
{"id": "2507.02379", "categories": ["cs.AI", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2507.02379", "abs": "https://arxiv.org/abs/2507.02379", "authors": ["Mingyu Wu", "Zhaoguo Wang", "Jiabin Wang", "Zhiyuan Dong", "Jingkai Yang", "Qingting Li", "Tianyu Huang", "Lei Zhao", "Mingqiang Li", "Fei Wang", "Chunhai Fan", "Haibo Chen"], "title": "An AI-native experimental laboratory for autonomous biomolecular engineering", "comment": null, "summary": "Autonomous scientific research, capable of independently conducting complex\nexperiments and serving non-specialists, represents a long-held aspiration.\nAchieving it requires a fundamental paradigm shift driven by artificial\nintelligence (AI). While autonomous experimental systems are emerging, they\nremain confined to areas featuring singular objectives and well-defined, simple\nexperimental workflows, such as chemical synthesis and catalysis. We present an\nAI-native autonomous laboratory, targeting highly complex scientific\nexperiments for applications like autonomous biomolecular engineering. This\nsystem autonomously manages instrumentation, formulates experiment-specific\nprocedures and optimization heuristics, and concurrently serves multiple user\nrequests. Founded on a co-design philosophy of models, experiments, and\ninstruments, the platform supports the co-evolution of AI models and the\nautomation system. This establishes an end-to-end, multi-user autonomous\nlaboratory that handles complex, multi-objective experiments across diverse\ninstrumentation. Our autonomous laboratory supports fundamental nucleic acid\nfunctions-including synthesis, transcription, amplification, and sequencing. It\nalso enables applications in fields such as disease diagnostics, drug\ndevelopment, and information storage. Without human intervention, it\nautonomously optimizes experimental performance to match state-of-the-art\nresults achieved by human scientists. In multi-user scenarios, the platform\nsignificantly improves instrument utilization and experimental efficiency. This\nplatform paves the way for advanced biomaterials research to overcome\ndependencies on experts and resource barriers, establishing a blueprint for\nscience-as-a-service at scale.", "AI": {"tldr": "本文介绍了一种AI驱动的自主实验室，能够独立执行复杂的生物分子工程实验，优化实验性能并支持多用户请求，显著提高仪器利用率和实验效率。", "motivation": "实现自主科学研究是长期目标，但现有系统局限于单一目标或简单实验流程。本文旨在通过AI构建能处理复杂、多目标实验的自主实验室。", "method": "采用AI原生设计，整合模型、实验与仪器协同优化，支持核酸合成、转录、扩增和测序等基础功能，并应用于疾病诊断、药物开发等领域。", "result": "该系统无需人工干预即可达到人类科学家的先进水平，在多用户场景下显著提升仪器利用率和实验效率。", "conclusion": "该平台为生物材料研究提供了突破专家依赖和资源限制的解决方案，为规模化科学服务奠定了基础。"}}
{"id": "2507.02607", "categories": ["cs.CR", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.02607", "abs": "https://arxiv.org/abs/2507.02607", "authors": ["Frida Sundfeldt", "Bianca Widstam", "Mahshid Helali Moghadam", "Kuo-Yun Liang", "Anders Vesterberg"], "title": "Alleviating Attack Data Scarcity: SCANIA's Experience Towards Enhancing In-Vehicle Cyber Security Measures", "comment": null, "summary": "The digital evolution of connected vehicles and the subsequent security risks\nemphasize the critical need for implementing in-vehicle cyber security measures\nsuch as intrusion detection and response systems. The continuous advancement of\nattack scenarios further highlights the need for adaptive detection mechanisms\nthat can detect evolving, unknown, and complex threats. The effective use of\nML-driven techniques can help address this challenge. However, constraints on\nimplementing diverse attack scenarios on test vehicles due to safety, cost, and\nethical considerations result in a scarcity of data representing attack\nscenarios. This limitation necessitates alternative efficient and effective\nmethods for generating high-quality attack-representing data. This paper\npresents a context-aware attack data generator that generates attack inputs and\ncorresponding in-vehicle network log, i.e., controller area network (CAN) log,\nrepresenting various types of attack including denial of service (DoS), fuzzy,\nspoofing, suspension, and replay attacks. It utilizes parameterized attack\nmodels augmented with CAN message decoding and attack intensity adjustments to\nconfigure the attack scenarios with high similarity to real-world scenarios and\npromote variability. We evaluate the practicality of the generated\nattack-representing data within an intrusion detection system (IDS) case study,\nin which we develop and perform an empirical evaluation of two deep neural\nnetwork IDS models using the generated data. In addition to the efficiency and\nscalability of the approach, the performance results of IDS models, high\ndetection and classification capabilities, validate the consistency and\neffectiveness of the generated data as well. In this experience study, we also\nelaborate on the aspects influencing the fidelity of the data to real-world\nscenarios and provide insights into its application.", "AI": {"tldr": "本文提出了一种上下文感知的攻击数据生成器，用于生成高质量的车载网络攻击数据，以解决实际测试中攻击数据稀缺的问题，并通过入侵检测系统案例验证了生成数据的有效性。", "motivation": "随着联网车辆的数字化发展，车载网络安全需求日益突出，但由于安全、成本和伦理限制，实际攻击场景数据稀缺，亟需高效生成高质量攻击数据的方法。", "method": "采用参数化攻击模型，结合CAN消息解码和攻击强度调整，生成多种攻击类型（如DoS、模糊、欺骗等）的输入数据及对应CAN日志，确保数据与真实场景高度相似且具有可变性。", "result": "在入侵检测系统案例中，使用生成数据训练的两个深度神经网络模型表现出高效的检测与分类能力，验证了生成数据的实用性和一致性。", "conclusion": "该方法不仅高效、可扩展，生成的数据还能有效支持入侵检测系统的开发与评估，同时为提升数据真实性和应用提供了重要见解。"}}
{"id": "2507.02442", "categories": ["cs.AI", "math.CT", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.02442", "abs": "https://arxiv.org/abs/2507.02442", "authors": ["Moto Kamiura"], "title": "The Gauss-Markov Adjunction: Categorical Semantics of Residuals in Supervised Learning", "comment": null, "summary": "Enhancing the intelligibility and interpretability of machine learning is a\ncrucial task in responding to the demand for Explicability as an AI principle,\nand in promoting the better social implementation of AI. The aim of our\nresearch is to contribute to this improvement by reformulating machine learning\nmodels through the lens of category theory, thereby developing a semantic\nframework for structuring and understanding AI systems. Our categorical\nmodeling in this paper clarifies and formalizes the structural interplay\nbetween residuals and parameters in supervised learning. The present paper\nfocuses on the multiple linear regression model, which represents the most\nbasic form of supervised learning. By defining two concrete categories\ncorresponding to parameters and data, along with an adjoint pair of functors\nbetween them, we introduce our categorical formulation of supervised learning.\nWe show that the essential structure of this framework is captured by what we\ncall the Gauss-Markov Adjunction. Within this setting, the dual flow of\ninformation can be explicitly described as a correspondence between variations\nin parameters and residuals. The ordinary least squares estimator for the\nparameters and the minimum residual are related via the preservation of limits\nby the right adjoint functor. Furthermore, we position this formulation as an\ninstance of extended denotational semantics for supervised learning, and\npropose applying a semantic perspective developed in theoretical computer\nscience as a formal foundation for Explicability in AI.", "AI": {"tldr": "本文通过范畴论重构机器学习模型，提出监督学习的语义框架，以线性回归为例展示参数与残差的结构关系，建立Gauss-Markov伴随对，为AI可解释性提供形式化基础。", "motivation": "提升机器学习可理解性与可解释性是实现AI可解释性原则及推动AI社会应用的关键需求，研究旨在通过范畴论视角改进这一现状。", "method": "构建参数与数据的具体范畴及伴随函子对，提出监督学习的范畴化表述，核心结构体现为Gauss-Markov伴随，通过右伴随函子的极限保持性关联最小二乘估计与最小残差。", "result": "范畴模型清晰形式化了监督学习中参数与残差的结构互动，证明信息双向流动体现为参数变化与残差的对应关系，并将该框架定位为监督学习的扩展指称语义实例。", "conclusion": "研究将理论计算机科学的语义视角应用于AI可解释性，为理解AI系统提供形式化基础，推动范畴论在机器学习语义建模中的发展。"}}
{"id": "2507.02635", "categories": ["cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2507.02635", "abs": "https://arxiv.org/abs/2507.02635", "authors": ["Mao Luo", "Zhi Wang", "Yiwen Huang", "Qingyun Zhang", "Zhouxing Su", "Zhipeng Lv", "Wen Hu", "Jianguo Li"], "title": "SAT-BO: Verification Rule Learning and Optimization for FraudTransaction Detection", "comment": null, "summary": "Electronic payment platforms are estimated to process billions oftransactions\ndaily, with the cumulative value of these transactionspotentially reaching into\nthe trillions. Even a minor error within thishigh-volume environment could\nprecipitate substantial financiallosses. To mitigate this risk, manually\nconstructed verification rules,developed by domain experts, are typically\nemployed to identifyand scrutinize transactions in production environments.\nHowever,due to the absence of a systematic approach to ensure the robust-ness\nof these verification rules against vulnerabilities, they remainsusceptible to\nexploitation.To mitigate this risk, manually constructed verification rules,\nde-veloped by domain experts, are typically employed to identify andscrutinize\ntransactions in production environments. However, dueto the absence of a\nsystematic approach to ensure the robustness ofthese verification rules against\nvulnerabilities, they remain suscep-tible to exploitation. To ensure data\nsecurity, database maintainersusually compose complex verification rules to\ncheck whether aquery/update request is valid. However, the rules written by\nex-perts are usually imperfect, and malicious requests may bypassthese rules.\nAs a result, the demand for identifying the defects ofthe rules systematically\nemerges.", "AI": {"tldr": "电子支付平台每日处理数十亿交易，但现有验证规则存在漏洞风险，需系统性方法提升其鲁棒性。", "motivation": "高交易量环境下微小错误可能导致重大财务损失，当前依赖专家手工制定的验证规则缺乏系统性漏洞防护。", "method": "通过分析现有验证规则缺陷，提出系统性识别规则漏洞的方法论。", "result": "证实专家编写的复杂验证规则存在可被恶意请求绕过的缺陷。", "conclusion": "亟需建立系统化的验证规则缺陷检测机制以确保电子支付数据安全。"}}
{"id": "2507.02541", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02541", "abs": "https://arxiv.org/abs/2507.02541", "authors": ["Yanzhen Lu", "Hanbin Yang", "Xiaodie Wang", "Ge Zhang", "Biao Li", "Chenxu Fu", "Chao Li", "Yang Yuan", "Andrew Chi-Chih Yao"], "title": "Clarifying Before Reasoning: A Coq Prover with Structural Context", "comment": null, "summary": "In this work, we investigate whether improving task clarity can enhance\nreasoning ability of large language models, focusing on theorem proving in Coq.\nWe introduce a concept-level metric to evaluate task clarity and show that\nadding structured semantic context to the standard input used by modern LLMs,\nleads to a 1.85$\\times$ improvement in clarity score\n(44.5\\%~$\\rightarrow$~82.3\\%). Using the general-purpose model\n\\texttt{DeepSeek-V3}, our approach leads to a 2.1$\\times$ improvement in proof\nsuccess (21.8\\%~$\\rightarrow$~45.8\\%) and outperforms the previous\nstate-of-the-art \\texttt{Graph2Tac} (33.2\\%). We evaluate this on 1,386\ntheorems randomly sampled from 15 standard Coq packages, following the same\nevaluation protocol as \\texttt{Graph2Tac}. Furthermore, fine-tuning smaller\nmodels on our structured data can achieve even higher performance (48.6\\%). Our\nmethod uses selective concept unfolding to enrich task descriptions, and\nemploys a Planner--Executor architecture. These findings highlight the value of\nstructured task representations in bridging the gap between understanding and\nreasoning.", "AI": {"tldr": "本研究通过提升任务清晰度增强大语言模型在Coq定理证明中的推理能力，提出概念级评估指标，结构化语义上下文使清晰度得分提升1.85倍（44.5\\%~$\\rightarrow$~82.3\\%），通用模型DeepSeek-V3证明成功率提高2.1倍（21.8\\%~$\\rightarrow$~45.8\\%），超越之前最优模型Graph2Tac（33.2\\%）。", "motivation": "探索任务清晰度提升能否增强大语言模型的推理能力，特别是在Coq定理证明场景中。", "method": "引入概念级清晰度评估指标，采用选择性概念展开方法丰富任务描述，并设计Planner--Executor架构，在通用模型DeepSeek-V3上验证。", "result": "在15个标准Coq包的1,386个定理上测试，结构化语义使清晰度提升至82.3\\%，证明成功率提高至45.8\\%，微调小模型可达48.6\\%。", "conclusion": "结构化任务表示能有效弥合理解与推理间的鸿沟，选择性概念展开和规划-执行架构显著提升模型性能。"}}
{"id": "2507.02699", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.02699", "abs": "https://arxiv.org/abs/2507.02699", "authors": ["Jiangrong Wu", "Yuhong Nan", "Jianliang Wu", "Zitong Yao", "Zibin Zheng"], "title": "Control at Stake: Evaluating the Security Landscape of LLM-Driven Email Agents", "comment": null, "summary": "The increasing capabilities of LLMs have led to the rapid proliferation of\nLLM agent apps, where developers enhance LLMs with access to external resources\nto support complex task execution. Among these, LLM email agent apps represent\none of the widely used categories, as email remains a critical communication\nmedium for users. LLM email agents are capable of managing and responding to\nemail using LLM-driven reasoning and autonomously executing user instructions\nvia external email APIs (e.g., send email). However, despite their growing\ndeployment and utility, the security mechanism of LLM email agent apps remains\nunderexplored. Currently, there is no comprehensive study into the potential\nsecurity risk within these agent apps and their broader implications.\n  In this paper, we conduct the first in-depth and systematic security study of\nLLM email agents. We propose the Email Agent Hijacking (EAH) attack, which\noverrides the original prompts of the email agent via external email resources,\nallowing attackers to gain control of the email agent remotely and further\nperform specific attack scenarios without user awareness.\n  To facilitate the large-scale evaluation, we propose EAHawk, a pipeline to\nevaluate the EAH attack of LLM email agent apps. By EAHawk, we performed an\nempirical study spanning 14 representative LLM agent frameworks, 63 agent apps,\n12 LLMs, and 20 email services, which led to the generation of 1,404 real-world\nemail agent instances for evaluation. Experimental results indicate that all\n1,404 instances were successfully hijacked; on average, only 2.03 attack\nattempts are required to control an email agent instance. Even worse, for some\nLLMs, the average number of attempts needed to achieve full agent control drops\nto as few as 1.23.", "AI": {"tldr": "本文首次系统研究了LLM邮件代理的安全风险，提出了一种名为EAH的攻击方法，能够通过外部邮件资源远程控制代理，并通过大规模实验验证了其有效性。", "motivation": "随着LLM代理应用的快速普及，邮件代理作为广泛使用的类别，其安全机制尚未得到充分研究。目前缺乏对这类代理潜在安全风险及其影响的全面分析。", "method": "研究提出EAH攻击方法，通过外部邮件资源覆盖代理的原始提示；开发EAHawk评估管道，对14个框架、63个应用、12个LLM和20个邮件服务生成的1,404个实例进行实证研究。", "result": "实验结果显示所有1,404个实例均被成功劫持，平均仅需2.03次尝试即可控制代理；某些LLM仅需1.23次尝试即可实现完全控制。", "conclusion": "研究表明当前LLM邮件代理存在严重安全漏洞，EAH攻击具有高度有效性，凸显了加强代理安全机制的迫切需求。"}}
{"id": "2507.02554", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.02554", "abs": "https://arxiv.org/abs/2507.02554", "authors": ["Edan Toledo", "Karen Hambardzumyan", "Martin Josifoski", "Rishi Hazra", "Nicolas Baldwin", "Alexis Audran-Reiss", "Michael Kuchnik", "Despoina Magka", "Minqi Jiang", "Alisia Maria Lupidi", "Andrei Lupu", "Roberta Raileanu", "Kelvin Niu", "Tatiana Shavrina", "Jean-Christophe Gagnon-Audet", "Michael Shvartsman", "Shagun Sodhani", "Alexander H. Miller", "Abhishek Charnalia", "Derek Dunfield", "Carole-Jean Wu", "Pontus Stenetorp", "Nicola Cancedda", "Jakob Nicolaus Foerster", "Yoram Bachrach"], "title": "AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench", "comment": "Code: https://github.com/facebookresearch/aira-dojo", "summary": "AI research agents are demonstrating great potential to accelerate scientific\nprogress by automating the design, implementation, and training of machine\nlearning models. We focus on methods for improving agents' performance on\nMLE-bench, a challenging benchmark where agents compete in Kaggle competitions\nto solve real-world machine learning problems. We formalize AI research agents\nas search policies that navigate a space of candidate solutions, iteratively\nmodifying them using operators. By designing and systematically varying\ndifferent operator sets and search policies (Greedy, MCTS, Evolutionary), we\nshow that their interplay is critical for achieving high performance. Our best\npairing of search strategy and operator set achieves a state-of-the-art result\non MLE-bench lite, increasing the success rate of achieving a Kaggle medal from\n39.6% to 47.7%. Our investigation underscores the importance of jointly\nconsidering the search strategy, operator design, and evaluation methodology in\nadvancing automated machine learning.", "AI": {"tldr": "AI研究代理通过优化搜索策略与操作符集的组合，在MLE-bench基准测试中将Kaggle奖牌获得率从39.6%提升至47.7%，揭示了自动化机器学习中策略与操作协同设计的重要性。", "motivation": "探索如何通过改进AI研究代理在MLE-bench基准上的表现，以自动化方式加速机器学习模型的开发与优化进程。", "method": "将AI研究代理形式化为搜索策略，系统测试不同操作符集（如贪婪、MCTS、进化算法）与搜索策略的组合效果。", "result": "最佳策略与操作符组合在MLE-bench lite上实现47.7%的Kaggle奖牌获得率，较基线提升8.1个百分点。", "conclusion": "自动化机器学习需同步考虑搜索策略、操作符设计及评估方法，三者协同优化是提升性能的关键。"}}
{"id": "2507.02727", "categories": ["cs.CR", "E.3"], "pdf": "https://arxiv.org/pdf/2507.02727", "abs": "https://arxiv.org/abs/2507.02727", "authors": ["Ye Zheng", "Yidan Hu"], "title": "Quantifying Classifier Utility under Local Differential Privacy", "comment": null, "summary": "Local differential privacy (LDP) provides a rigorous and quantifiable privacy\nguarantee for personal data by introducing perturbation at the data source.\nHowever, quantifying the impact of these perturbations on classifier utility\nremains a theoretical challenge, particularly for complex or black-box\nclassifiers.\n  This paper presents a framework for theoretically quantifying classifier\nutility under LDP mechanisms. The key insight is that LDP perturbation is\nconcentrated around the original data with a specific probability, transforming\nutility analysis of the classifier into its robustness analysis in this\nconcentrated region. Our framework connects the concentration analysis of LDP\nmechanisms with the robustness analysis of classifiers. It treats LDP\nmechanisms as general distributional functions and classifiers as black-box\nfunctions, thus applicable to any LDP mechanism and classifier. A direct\napplication of our utility quantification is guiding the selection of LDP\nmechanisms and privacy parameters for a given classifier. Notably, our analysis\nshows that a piecewise-based mechanism leads to better utility compared to\nalternatives in common scenarios.\n  Using this framework alongside two novel refinement techniques, we conduct\ncase studies on utility quantification for typical mechanism-classifier\ncombinations. The results demonstrate that our theoretical utility\nquantification aligns closely with empirical observations, particularly when\nclassifiers operate in lower-dimensional input spaces.", "AI": {"tldr": "本文提出了一个理论框架，用于量化局部差分隐私（LDP）机制下分类器的效用，通过将LDP扰动集中在原始数据周围的特性与分类器的鲁棒性分析相结合，指导LDP机制和隐私参数的选择。", "motivation": "局部差分隐私（LDP）虽能提供严格的隐私保障，但其扰动对分类器效用的影响缺乏理论量化方法，尤其对于复杂或黑盒分类器。", "method": "框架将LDP扰动视为集中在原始数据周围的分布函数，将分类器效用分析转化为该集中区域的鲁棒性分析，适用于任意LDP机制和分类器，并提出分段机制优化效用。", "result": "案例研究表明，理论效用量化与实证结果高度吻合，尤其在低维输入空间中分类器的表现更为显著。", "conclusion": "该框架不仅为LDP机制和分类器的组合选择提供了理论依据，还验证了分段机制在常见场景中的优越效用。"}}
{"id": "2507.02582", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02582", "abs": "https://arxiv.org/abs/2507.02582", "authors": ["Junli Jiang", "Pavel Naumov"], "title": "Responsibility Gap and Diffusion in Sequential Decision-Making Mechanisms", "comment": null, "summary": "Responsibility has long been a subject of study in law and philosophy. More\nrecently, it became a focus of AI literature. The article investigates the\ncomputational complexity of two important properties of responsibility in\ncollective decision-making: diffusion and gap. It shows that the sets of\ndiffusion-free and gap-free decision-making mechanisms are $\\Pi_2$-complete and\n$\\Pi_3$-complete, respectively. At the same time, the intersection of these\nclasses is $\\Pi_2$-complete.", "AI": {"tldr": "本文研究了集体决策中责任的两个重要属性（扩散和缺口）的计算复杂性，证明了无扩散和无缺口决策机制集的复杂度分别为$\\Pi_2$-完全和$\\Pi_3$-完全，而两者的交集仍为$\\Pi_2$-完全。", "motivation": "责任问题长期是法律与哲学的研究主题，近年来也成为人工智能领域的焦点。本文旨在分析集体决策中责任属性的计算复杂性。", "method": "通过理论计算机科学的方法，对集体决策机制中'扩散'和'缺口'两个责任属性进行形式化建模和复杂性分析。", "result": "研究发现：无扩散决策机制集具有$\\Pi_2$-完全复杂度，无缺口决策机制集具有$\\Pi_3$-完全复杂度，而两者的交集保持$\\Pi_2$-完全性。", "conclusion": "该研究为理解集体决策中责任属性的计算本质提供了理论依据，表明不同责任属性对应不同层级的计算复杂性。"}}
{"id": "2507.02735", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02735", "abs": "https://arxiv.org/abs/2507.02735", "authors": ["Sizhe Chen", "Arman Zharmagambetov", "David Wagner", "Chuan Guo"], "title": "Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks", "comment": null, "summary": "Prompt injection attacks pose a significant security threat to LLM-integrated\napplications. Model-level defenses have shown strong effectiveness, but are\ncurrently deployed into commercial-grade models in a closed-source manner. We\nbelieve open-source models are needed by the AI security community, where\nco-development of attacks and defenses through open research drives scientific\nprogress in mitigation against prompt injection attacks. To this end, we\ndevelop Meta SecAlign, the first open-source and open-weight LLM with built-in\nmodel-level defense that achieves commercial-grade model performance. We\nprovide complete details of our training recipe, which utilizes an improved\nversion of the SOTA SecAlign defense. Evaluations on 9 utility benchmarks and 7\nsecurity benchmarks show that Meta SecAlign, despite being trained on a generic\ninstruction-tuning dataset, confers security in unseen downstream tasks,\nincluding tool-calling and agentic web navigation, in addition general\ninstruction-following. Our best model -- Meta-SecAlign-70B -- achieves\nstate-of-the-art robustness against prompt injection attacks and comparable\nutility to closed-source commercial LLM with model-level defense.", "AI": {"tldr": "论文提出了首个开源且具有商业级性能的防御性大语言模型Meta SecAlign，通过改进版SOTA SecAlign防御方法，在9个实用基准和7个安全基准测试中展现出卓越的抗提示注入攻击能力与通用任务性能。", "motivation": "当前针对提示注入攻击的模型级防御仅以闭源形式部署于商业模型，阻碍了AI安全社区的攻防协同研究。作者认为开源模型能推动该领域的科学进展。", "method": "基于改进版SOTA SecAlign防御技术，使用通用指令微调数据集训练，并公开完整训练方案。最佳模型Meta-SecAlign-70B支持工具调用、网络导航等下游任务。", "result": "Meta-SecAlign-70B在未见过下游任务中展现出商业级防御能力，抗提示注入攻击鲁棒性达SOTA水平，实用性能媲美闭源商业模型。", "conclusion": "该研究证明了开源模型可实现商业级安全防护，为AI安全社区提供了可共同演进的攻防研究基础平台。"}}
{"id": "2507.02616", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02616", "abs": "https://arxiv.org/abs/2507.02616", "authors": ["Tianqi Shang", "Weiqing He", "Charles Zheng", "Lingyao Li", "Li Shen", "Bingxin Zhao"], "title": "DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making", "comment": "16 pages", "summary": "The rise of Large Language Models (LLMs) has enabled the development of\nspecialized AI agents with domain-specific reasoning and interaction\ncapabilities, particularly in healthcare. While recent frameworks simulate\nmedical decision-making, they largely focus on single-turn tasks where a doctor\nagent receives full case information upfront -- diverging from the real-world\ndiagnostic process, which is inherently uncertain, interactive, and iterative.\nIn this paper, we introduce MIMIC-Patient, a structured dataset built from the\nMIMIC-III electronic health records (EHRs), designed to support dynamic,\npatient-level simulations. Building on this, we propose DynamiCare, a novel\ndynamic multi-agent framework that models clinical diagnosis as a multi-round,\ninteractive loop, where a team of specialist agents iteratively queries the\npatient system, integrates new information, and dynamically adapts its\ncomposition and strategy. We demonstrate the feasibility and effectiveness of\nDynamiCare through extensive experiments, establishing the first benchmark for\ndynamic clinical decision-making with LLM-powered agents.", "AI": {"tldr": "本文提出DynamiCare框架，基于MIMIC-Patient数据集构建动态多智能体系统，模拟真实医疗诊断中的迭代交互过程，填补了现有单轮决策模型的不足。", "motivation": "现有医疗AI代理多聚焦单轮决策，与真实诊断的不确定性、交互性和迭代性脱节。研究旨在开发能模拟动态临床决策过程的框架。", "method": "1) 从MIMIC-III电子病历构建结构化数据集MIMIC-Patient；2) 提出DynamiCare框架：通过多专科代理团队进行多轮问询、信息整合及动态策略调整。", "result": "实验验证了DynamiCare的可行性，建立了首个基于LLM的动态临床决策基准，展现了代理系统的适应性诊断能力。", "conclusion": "该研究为医疗AI领域提供了更贴近真实场景的动态决策范式，未来可扩展至更复杂的临床协作场景。"}}
{"id": "2507.02737", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.02737", "abs": "https://arxiv.org/abs/2507.02737", "authors": ["Artur Zolkowski", "Kei Nishimura-Gasparian", "Robert McCarthy", "Roland S. Zimmermann", "David Lindner"], "title": "Early Signs of Steganographic Capabilities in Frontier LLMs", "comment": null, "summary": "Monitoring Large Language Model (LLM) outputs is crucial for mitigating risks\nfrom misuse and misalignment. However, LLMs could evade monitoring through\nsteganography: Encoding hidden information within seemingly benign generations.\nIn this paper, we evaluate the steganography capabilities in frontier LLMs to\nbetter understand the risk they pose. We focus on two types of steganography:\npassing encoded messages and performing encoded reasoning. We find that current\nmodels are unable to encode short messages in their outputs without a monitor\nnoticing under standard affordances. They can succeed, however, if given\nadditional affordances such as using an unmonitored scratchpad and coordinating\non what encoding scheme to use. We additionally find early signs that models\ncan perform basic encoded reasoning in a simple state-tracking problem. This\nincludes some ability to reason with their own and pre-defined schemes,\nincluding encoding schemes such as Hexadecimal. Despite this, they can rarely\nhide reasoning subtly within a cover task to fool a monitor. Overall, our\nresults indicate that current LLMs exhibit nascent steganographic capabilities.\nWhile these capabilities are likely insufficient to bypass well-designed\nmonitors at present, this could change in the future.", "AI": {"tldr": "研究评估前沿大语言模型（LLM）的隐写能力，发现当前模型在标准条件下无法隐蔽传递短消息，但通过额外辅助手段可实现编码通信，并展现出初步的隐写推理能力。", "motivation": "监控LLM输出对防范滥用和错位风险至关重要，但模型可能通过隐写术（在看似正常的生成中隐藏信息）逃避监控。本研究旨在评估前沿LLM的隐写能力以理解潜在风险。", "method": "聚焦两类隐写术：传递编码消息和执行编码推理。测试模型在标准辅助条件（如无监控草稿纸、预协商编码方案）下的表现，并评估其在简单状态跟踪问题中的隐写推理能力。", "result": "当前模型在标准条件下无法隐蔽传递短消息，但通过额外辅助手段可成功；能进行基础编码推理（包括自定义和十六进制等预定义方案），但难以在掩护任务中隐蔽推理过程以欺骗监控。", "conclusion": "当前LLM展现出初步隐写能力，虽尚不足以绕过设计良好的监控系统，但未来可能演变出更强规避能力。"}}
{"id": "2507.02618", "categories": ["cs.AI", "cs.CL", "cs.GT"], "pdf": "https://arxiv.org/pdf/2507.02618", "abs": "https://arxiv.org/abs/2507.02618", "authors": ["Kenneth Payne", "Baptiste Alloui-Cros"], "title": "Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory", "comment": "29 pages, 27 tables, 4 figures", "summary": "Are Large Language Models (LLMs) a new form of strategic intelligence, able\nto reason about goals in competitive settings? We present compelling supporting\nevidence. The Iterated Prisoner's Dilemma (IPD) has long served as a model for\nstudying decision-making. We conduct the first ever series of evolutionary IPD\ntournaments, pitting canonical strategies (e.g., Tit-for-Tat, Grim Trigger)\nagainst agents from the leading frontier AI companies OpenAI, Google, and\nAnthropic. By varying the termination probability in each tournament (the\n\"shadow of the future\"), we introduce complexity and chance, confounding\nmemorisation.\n  Our results show that LLMs are highly competitive, consistently surviving and\nsometimes even proliferating in these complex ecosystems. Furthermore, they\nexhibit distinctive and persistent \"strategic fingerprints\": Google's Gemini\nmodels proved strategically ruthless, exploiting cooperative opponents and\nretaliating against defectors, while OpenAI's models remained highly\ncooperative, a trait that proved catastrophic in hostile environments.\nAnthropic's Claude emerged as the most forgiving reciprocator, showing\nremarkable willingness to restore cooperation even after being exploited or\nsuccessfully defecting. Analysis of nearly 32,000 prose rationales provided by\nthe models reveals that they actively reason about both the time horizon and\ntheir opponent's likely strategy, and we demonstrate that this reasoning is\ninstrumental to their decisions. This work connects classic game theory with\nmachine psychology, offering a rich and granular view of algorithmic\ndecision-making under uncertainty.", "AI": {"tldr": "研究表明大型语言模型(LLM)在迭代囚徒困境中展现出战略智能，不同厂商模型表现出独特行为模式，揭示了算法在不确定性下的决策机制。", "motivation": "探讨大型语言模型是否具备战略推理能力，能否在竞争性环境中进行目标导向的决策。", "method": "首次进行进化版迭代囚徒困境锦标赛，让传统策略与OpenAI、Google、Anthropic的AI代理对抗，通过调整终止概率('未来阴影')引入复杂性。", "result": "LLMs表现出色：Google模型战略冷酷，OpenAI模型过度合作导致失败，Anthropic模型最具宽容性。分析32,000条决策依据显示模型能推理时间跨度和对手策略。", "conclusion": "该研究连接经典博弈论与机器心理学，为不确定性下的算法决策提供了精细化的观察视角。"}}
{"id": "2507.02770", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.02770", "abs": "https://arxiv.org/abs/2507.02770", "authors": ["Zhongshu Gu", "Enriquillo Valdez", "Salman Ahmed", "Julian James Stephen", "Michael Le", "Hani Jamjoom", "Shixuan Zhao", "Zhiqiang Lin"], "title": "NVIDIA GPU Confidential Computing Demystified", "comment": null, "summary": "GPU Confidential Computing (GPU-CC) was introduced as part of the NVIDIA\nHopper Architecture, extending the trust boundary beyond traditional CPU-based\nconfidential computing. This innovation enables GPUs to securely process AI\nworkloads, providing a robust and efficient solution for handling sensitive\ndata. For end users, transitioning to GPU-CC mode is seamless, requiring no\nmodifications to existing AI applications. However, this ease of adoption\ncontrasts sharply with the complexity of the underlying proprietary systems.\nThe lack of transparency presents significant challenges for security\nresearchers seeking a deeper understanding of GPU-CC's architecture and\noperational mechanisms.\n  The challenges of analyzing the NVIDIA GPU-CC system arise from a scarcity of\ndetailed specifications, the proprietary nature of the ecosystem, and the\ncomplexity of product design. In this paper, we aim to demystify the\nimplementation of NVIDIA GPU-CC system by piecing together the fragmented and\nincomplete information disclosed from various sources. Our investigation begins\nwith a high-level discussion of the threat model and security principles before\ndelving into the low-level details of each system component. We instrument the\nGPU kernel module -- the only open-source component of the system -- and\nconduct a series of experiments to identify the security weaknesses and\npotential exploits. For certain components that are out of reach through\nexperiments, we propose well-reasoned speculations about their inner working\nmechanisms. We have responsibly reported all security findings presented in\nthis paper to the NVIDIA PSIRT Team.", "AI": {"tldr": "本文揭秘了NVIDIA GPU机密计算(GPU-CC)系统的实现细节，通过整合碎片化信息、实验分析及合理推测，揭示了其安全弱点，并向NVIDIA报告了所有发现。", "motivation": "由于NVIDIA GPU-CC系统缺乏详细规范、生态封闭且设计复杂，安全研究人员难以深入理解其架构与运行机制，因此需要对其进行系统性分析。", "method": "通过整合多方披露的不完整信息，从威胁模型和安全原则的高层讨论入手，深入分析各组件细节；对唯一开源组件GPU内核模块进行实验，并对不可达组件提出合理推测。", "result": "研究识别了GPU-CC系统的安全漏洞和潜在攻击路径，所有发现已负责任地报告给NVIDIA安全团队。", "conclusion": "尽管GPU-CC为用户提供了无缝的机密计算体验，但其底层实现的不透明性仍存在安全隐患，需要进一步开放和标准化以提升系统可信度。"}}
{"id": "2507.02652", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.02652", "abs": "https://arxiv.org/abs/2507.02652", "authors": ["Jiajie Jin", "Xiaoxi Li", "Guanting Dong", "Yuyao Zhang", "Yutao Zhu", "Yang Zhao", "Hongjin Qian", "Zhicheng Dou"], "title": "Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search", "comment": "9 pages", "summary": "Complex information needs in real-world search scenarios demand deep\nreasoning and knowledge synthesis across diverse sources, which traditional\nretrieval-augmented generation (RAG) pipelines struggle to address effectively.\nCurrent reasoning-based approaches suffer from a fundamental limitation: they\nuse a single model to handle both high-level planning and detailed execution,\nleading to inefficient reasoning and limited scalability. In this paper, we\nintroduce HiRA, a hierarchical framework that separates strategic planning from\nspecialized execution. Our approach decomposes complex search tasks into\nfocused subtasks, assigns each subtask to domain-specific agents equipped with\nexternal tools and reasoning capabilities, and coordinates the results through\na structured integration mechanism. This separation prevents execution details\nfrom disrupting high-level reasoning while enabling the system to leverage\nspecialized expertise for different types of information processing.\nExperiments on four complex, cross-modal deep search benchmarks demonstrate\nthat HiRA significantly outperforms state-of-the-art RAG and agent-based\nsystems. Our results show improvements in both answer quality and system\nefficiency, highlighting the effectiveness of decoupled planning and execution\nfor multi-step information seeking tasks. Our code is available at\nhttps://github.com/ignorejjj/HiRA.", "AI": {"tldr": "本文提出HiRA框架，通过分层策略将复杂搜索任务分解为子任务，由专业代理执行，显著提升了检索增强生成（RAG）系统的性能。", "motivation": "传统检索增强生成（RAG）管道在处理复杂信息需求时存在局限性，现有基于推理的方法因使用单一模型进行高层规划和细节执行，导致效率低下且扩展性有限。", "method": "HiRA框架采用分层结构，将战略规划与专业执行分离，通过分解任务、分配专业代理及结构化整合机制，避免执行细节干扰高层推理。", "result": "在四个复杂跨模态深度搜索基准测试中，HiRA显著优于现有RAG和基于代理的系统，答案质量和系统效率均有提升。", "conclusion": "解耦规划与执行对于多步骤信息检索任务具有显著效果，HiRA框架为复杂搜索场景提供了高效解决方案。"}}
{"id": "2507.02660", "categories": ["cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2507.02660", "abs": "https://arxiv.org/abs/2507.02660", "authors": ["Deepak Narayan Gadde", "Keerthan Kopparam Radhakrishna", "Vaisakh Naduvodi Viswambharan", "Aman Kumar", "Djones Lettnin", "Wolfgang Kunz", "Sebastian Simon"], "title": "Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification", "comment": "To appear at the 38th SBC/SBMicro/IEEE Symposium on Integrated\n  Circuits and Systems Design (SBCCI), August 25-29, 2025, Manaus, BRAZIL", "summary": "Modern Integrated Circuits (ICs) are becoming increasingly complex, and so is\ntheir development process. Hardware design verification entails a methodical\nand disciplined approach to the planning, development, execution, and sign-off\nof functionally correct hardware designs. This tedious process requires\nsignificant effort and time to ensure a bug-free tape-out. The field of Natural\nLanguage Processing has undergone a significant transformation with the advent\nof Large Language Models (LLMs). These powerful models, often referred to as\nGenerative AI (GenAI), have revolutionized how machines understand and generate\nhuman language, enabling unprecedented advancements in a wide array of\napplications, including hardware design verification. This paper presents an\nagentic AI-based approach to hardware design verification, which empowers AI\nagents, in collaboration with Humain-in-the-Loop (HITL) intervention, to engage\nin a more dynamic, iterative, and self-reflective process, ultimately\nperforming end-to-end hardware design and verification. This methodology is\nevaluated on five open-source designs, achieving over 95% coverage with reduced\nverification time while demonstrating superior performance, adaptability, and\nconfigurability.", "AI": {"tldr": "本文提出了一种基于代理AI的硬件设计验证方法，结合人类参与，实现了动态、迭代和自我反思的端到端硬件设计与验证，在五个开源设计上验证了其高效性和优越性能。", "motivation": "随着集成电路设计复杂度提升，传统验证过程耗时且繁琐；大型语言模型的出现为硬件验证领域带来了革新可能，促使研究者探索AI与人类协作的新型验证方法。", "method": "采用代理AI框架结合人类在环（HITL）干预，构建动态迭代的自我反思流程，实现从设计到验证的端到端自动化。", "result": "在五个开源设计上的实验表明，该方法达到95%以上的覆盖率，同时显著减少验证时间，并展现出优异的适应性、可配置性。", "conclusion": "基于代理AI的协同验证方法为硬件设计验证提供了高效新范式，其性能与自动化程度显著优于传统方法，展现了生成式AI在硬件工程中的应用潜力。"}}
{"id": "2507.02663", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02663", "abs": "https://arxiv.org/abs/2507.02663", "authors": ["Yongjiang Liu", "Haoxi Li", "Xiaosong Ma", "Jie Zhang", "Song Guo"], "title": "Think How to Think: Mitigating Overthinking with Autonomous Difficulty Cognition in Large Reasoning Models", "comment": "21 pages, 18 figures", "summary": "Recent Long Reasoning Models(LRMs) have demonstrated remarkable capabilities\nin handling complex reasoning tasks, but are hindered by excessive\noverthinking. To explore its essence, our empirical analysis reveals that LRMs\nare primarily limited to recognizing task properties (i.e., difficulty levels)\nlike humans before solving the problem, leading to a one-size-fits-all\nreasoning process. Inspired by this, a pressing and natural question emerges:\nCan we bootstrap such ability to further alleviate the overthinking phenomenon\nin LRMs? In this paper, we propose Think-How-to-Think (TH2T), a novel two-stage\nfine-tuning strategy that progressively inspires LRMs' difficulty cognition and\nredundancy cognition. First, we introduce difficulty-hypnosis in the prefixes\nof model outputs to intervene in the internal reasoning trajectory. Combined\nwith a heterogeneous short and long reasoning dataset, the trained model\nenhances its sensitivity to task difficulty, enabling native, differentiated\nreasoning strategies across various tasks. Second, we further extend\nredundancy-hypnosis to the internal reasoning process, guiding the model to\nidentify redundant structures within the reasoning steps and generate more\nconcise reasoning outputs. Experiments on 7B/14B/32B models demonstrate that\nTH2T significantly reduces inference costs (more than 70% on easy tasks and 40%\non hard tasks) while maintaining performance stability. The resulting outputs\nexhibit clear difficulty-aware capabilities and reduced redundancy (e.g.,\nreflection).", "AI": {"tldr": "本文提出Think-How-to-Think (TH2T)方法，通过两阶段微调策略提升长推理模型对任务难度和冗余结构的认知能力，显著降低推理成本并保持性能稳定。", "motivation": "现有长推理模型(LRMs)存在过度思考问题，其根本原因是模型缺乏对任务难度属性的识别能力，导致采用单一推理策略。研究旨在通过引导模型认知任务特性来缓解该现象。", "method": "1) 难度催眠：在模型输出前缀引入难度标记，结合异构长短推理数据集训练，使模型形成差异化推理策略；2) 冗余催眠：在推理过程中引导模型识别冗余结构，生成更简洁的输出。", "result": "在7B/14B/32B模型上，TH2T使推理成本显著降低（简单任务超70%，困难任务40%），同时保持性能稳定。输出呈现清晰的难度感知能力和更低冗余度。", "conclusion": "TH2T通过增强模型对任务属性和内部结构的认知，有效解决了长推理模型的过度思考问题，为高效推理提供了新范式。"}}
{"id": "2507.02681", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.02681", "abs": "https://arxiv.org/abs/2507.02681", "authors": ["Behnam Parsaeifard", "Christof Imhof", "Tansu Pancar", "Ioan-Sorin Comsa", "Martin Hlosta", "Nicole Bergamin", "Per Bergamin"], "title": "Detection of Disengagement from Voluntary Quizzes: An Explainable Machine Learning Approach in Higher Distance Education", "comment": null, "summary": "Students disengaging from their tasks can have serious long-term\nconsequences, including academic drop-out. This is particularly relevant for\nstudents in distance education. One way to measure the level of disengagement\nin distance education is to observe participation in non-mandatory exercises in\ndifferent online courses. In this paper, we detect student disengagement in the\nnon-mandatory quizzes of 42 courses in four semesters from a distance-based\nuniversity. We carefully identified the most informative student log data that\ncould be extracted and processed from Moodle. Then, eight machine learning\nalgorithms were trained and compared to obtain the highest possible prediction\naccuracy. Using the SHAP method, we developed an explainable machine learning\nframework that allows practitioners to better understand the decisions of the\ntrained algorithm. The experimental results show a balanced accuracy of 91\\%,\nwhere about 85\\% of disengaged students were correctly detected. On top of the\nhighly predictive performance and explainable framework, we provide a\ndiscussion on how to design a timely intervention to minimise disengagement\nfrom voluntary tasks in online learning.", "AI": {"tldr": "该研究通过分析远程教育学生在非强制性测验中的参与数据，开发了一个可解释的机器学习框架，用于检测学生脱离行为，准确率达91\\%，并探讨了及时干预策略。", "motivation": "学生脱离学习任务可能导致严重后果（如辍学），尤其在远程教育中更为突出。研究旨在通过非强制性练习的参与数据量化这种脱离行为。", "method": "从42门课程的Moodle日志中提取关键数据，比较8种机器学习算法，结合SHAP方法构建可解释的预测模型。", "result": "模型平衡准确率达91\\%，能正确识别85\\%的脱离学生，并提供了算法决策的透明化解释。", "conclusion": "研究不仅实现了高精度预测和可解释性框架，还提出了针对在线学习中自愿任务脱离的及时干预设计思路。"}}
{"id": "2507.02703", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02703", "abs": "https://arxiv.org/abs/2507.02703", "authors": ["Robin Schmöcker", "Lennart Kampmann", "Alexander Dockhorn"], "title": "Time-critical and confidence-based abstraction dropping methods", "comment": "Accepted for Publication at the IEEE Conference on Games 2025", "summary": "One paradigm of Monte Carlo Tree Search (MCTS) improvements is to build and\nuse state and/or action abstractions during the tree search. Non-exact\nabstractions, however, introduce an approximation error making convergence to\nthe optimal action in the abstract space impossible. Hence, as proposed as a\ncomponent of Elastic Monte Carlo Tree Search by Xu et al., abstraction\nalgorithms should eventually drop the abstraction. In this paper, we propose\ntwo novel abstraction dropping schemes, namely OGA-IAAD and OGA-CAD which can\nyield clear performance improvements whilst being safe in the sense that the\ndropping never causes any notable performance degradations contrary to Xu's\ndropping method. OGA-IAAD is designed for time critical settings while OGA-CAD\nis designed to improve the MCTS performance with the same number of iterations.", "AI": {"tldr": "本文提出了两种新的抽象丢弃方案OGA-IAAD和OGA-CAD，用于改进蒙特卡洛树搜索（MCTS）中的非精确抽象问题，确保性能提升且无显著退化。", "motivation": "非精确抽象在蒙特卡洛树搜索中引入近似误差，导致无法收敛到抽象空间的最优动作。Xu等人提出的抽象丢弃方法可能引起性能下降，因此需要更安全的丢弃方案。", "method": "提出了两种抽象丢弃方案：OGA-IAAD适用于时间关键场景，OGA-CAD旨在相同迭代次数下提升MCTS性能。这两种方案均确保丢弃过程不会导致性能显著下降。", "result": "实验表明，OGA-IAAD和OGA-CAD能够显著提升性能，且不会像Xu的方法那样引起性能退化。", "conclusion": "OGA-IAAD和OGA-CAD是安全有效的抽象丢弃方案，分别适用于时间敏感和性能优化的场景，为MCTS的改进提供了新思路。"}}
{"id": "2507.02726", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.02726", "abs": "https://arxiv.org/abs/2507.02726", "authors": ["Matthieu Zimmer", "Xiaotong Ji", "Rasul Tutunov", "Anthony Bordg", "Jun Wang", "Haitham Bou Ammar"], "title": "Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving", "comment": null, "summary": "Reasoning remains a challenging task for large language models (LLMs),\nespecially within the logically constrained environment of automated theorem\nproving (ATP), due to sparse rewards and the vast scale of proofs. These\nchallenges are amplified in benchmarks like PutnamBench, which contains\nuniversity-level problems requiring complex, multi-step reasoning. To address\nthis, we introduce self-generated goal-conditioned MDPs (sG-MDPs), a new\nframework in which agents generate and pursue their subgoals based on the\nevolving proof state. Given this more structured generation of goals, the\nresulting problem becomes more amenable to search. We then apply Monte Carlo\nTree Search (MCTS)-like algorithms to solve the sG-MDP, instantiating our\napproach in Bourbaki (7B), a modular system that can ensemble multiple 7B LLMs\nfor subgoal generation and tactic synthesis. On PutnamBench, Bourbaki (7B)\nsolves 26 problems, achieving new state-of-the-art results with models at this\nscale.", "AI": {"tldr": "论文提出了一种自我生成目标条件MDP（sG-MDP）框架，结合蒙特卡洛树搜索（MCTS）算法，通过Bourbaki（7B）系统在PutnamBench上实现了新的最先进结果。", "motivation": "大型语言模型（LLM）在自动定理证明（ATP）等逻辑约束环境中面临推理挑战，尤其是在需要多步复杂推理的大学级问题（如PutnamBench）上表现不佳。", "method": "采用自我生成目标条件MDP（sG-MDP）框架，使代理能够根据证明状态生成并追求子目标，并通过类似MCTS的算法解决问题。具体实现为Bourbaki（7B）系统，该系统可集成多个7B规模的LLM用于子目标生成和策略合成。", "result": "在PutnamBench上，Bourbaki（7B）解决了26个问题，实现了该规模模型的新最先进结果。", "conclusion": "通过sG-MDP框架和MCTS算法的结合，显著提升了LLM在复杂推理任务中的表现，为自动定理证明领域提供了新的解决方案。"}}
{"id": "2507.02760", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02760", "abs": "https://arxiv.org/abs/2507.02760", "authors": ["Guangwei Zhang"], "title": "Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work", "comment": null, "summary": "The capabilities of Large Language Models (LLMs) have opened new frontiers\nfor interacting with complex, domain-specific knowledge. However, prevailing\nmethods like Retrieval-Augmented Generation (RAG) and general-purpose Agentic\nAI, while powerful, often struggle with tasks that demand deep, procedural, and\nmethodological reasoning inherent to expert domains. RAG provides factual\ncontext but fails to convey logical frameworks; autonomous agents can be\ninefficient and unpredictable without domain-specific heuristics. To bridge\nthis gap, we introduce Knowledge Protocol Engineering (KPE), a new paradigm\nfocused on systematically translating human expert knowledge, often expressed\nin natural language documents, into a machine-executable Knowledge Protocol\n(KP). KPE shifts the focus from merely augmenting LLMs with fragmented\ninformation to endowing them with a domain's intrinsic logic, operational\nstrategies, and methodological principles. We argue that a well-engineered\nKnowledge Protocol allows a generalist LLM to function as a specialist, capable\nof decomposing abstract queries and executing complex, multi-step tasks. This\nposition paper defines the core principles of KPE, differentiates it from\nrelated concepts, and illustrates its potential applicability across diverse\nfields such as law and bioinformatics, positing it as a foundational\nmethodology for the future of human-AI collaboration.", "AI": {"tldr": "本文提出知识协议工程（KPE）新范式，通过将人类专家知识转化为机器可执行的知识协议（KP），使通用大语言模型（LLM）具备领域专家的逻辑推理与多步骤任务执行能力。", "motivation": "现有检索增强生成（RAG）和通用代理AI难以处理需要深层方法论推理的专家级任务，亟需将领域内在逻辑与操作策略系统化编码。", "method": "KPE通过结构化转换自然语言文档中的专家知识，构建包含领域逻辑、策略和原则的机器可执行协议，取代碎片化信息增强模式。", "result": "经KPE改造的通用LLM可像领域专家般分解抽象查询并执行复杂多步任务，在法律、生物信息学等领域展现应用潜力。", "conclusion": "KPE为人类-AI协作奠定方法论基础，通过知识协议实现通用模型向领域专家的转化，是知识密集型任务处理的革命性框架。"}}
{"id": "2507.02771", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.02771", "abs": "https://arxiv.org/abs/2507.02771", "authors": ["Melanie Segado", "Felipe Parodi", "Jordan K. Matelsky", "Michael L. Platt", "Eva B. Dyer", "Konrad P. Kording"], "title": "Grounding Intelligence in Movement", "comment": "9 pages, 2 figures", "summary": "Recent advances in machine learning have dramatically improved our ability to\nmodel language, vision, and other high-dimensional data, yet they continue to\nstruggle with one of the most fundamental aspects of biological systems:\nmovement. Across neuroscience, medicine, robotics, and ethology, movement is\nessential for interpreting behavior, predicting intent, and enabling\ninteraction. Despite its core significance in our intelligence, movement is\noften treated as an afterthought rather than as a rich and structured modality\nin its own right. This reflects a deeper fragmentation in how movement data is\ncollected and modeled, often constrained by task-specific goals and\ndomain-specific assumptions. But movement is not domain-bound. It reflects\nshared physical constraints, conserved morphological structures, and purposeful\ndynamics that cut across species and settings. We argue that movement should be\ntreated as a primary modeling target for AI. It is inherently structured and\ngrounded in embodiment and physics. This structure, often allowing for compact,\nlower-dimensional representations (e.g., pose), makes it more interpretable and\ncomputationally tractable to model than raw, high-dimensional sensory inputs.\nDeveloping models that can learn from and generalize across diverse movement\ndata will not only advance core capabilities in generative modeling and\ncontrol, but also create a shared foundation for understanding behavior across\nbiological and artificial systems. Movement is not just an outcome, it is a\nwindow into how intelligent systems engage with the world.", "AI": {"tldr": "论文主张将运动作为AI建模的核心目标，强调其跨领域、结构化及物理基础特性，认为运动建模能推动生成模型与控制能力发展，并为理解智能系统行为提供统一框架。", "motivation": "尽管机器学习在语言、视觉等领域取得进展，但对运动这一生物系统基础要素的建模仍显不足。运动在神经科学、医学等多领域至关重要，但常被忽视或局限于特定任务假设。", "method": "提出将运动视为独立丰富模态，利用其物理约束与形态结构的一致性，构建跨物种/场景的低维可解释表征（如姿态），开发通用运动数据建模方法。", "result": "运动的内在结构（如低维性、物理基础）使其比高维感官输入更易建模，跨领域运动模型有望增强生成与控制能力，建立生物与人工系统的行为理解桥梁。", "conclusion": "运动不仅是智能系统的行为输出，更是理解其与世界互动的窗口。将其作为核心建模目标将推动AI基础能力发展，并创建跨学科的统一行为分析范式。"}}
{"id": "2507.02773", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.02773", "abs": "https://arxiv.org/abs/2507.02773", "authors": ["Yuzhang Xie", "Hejie Cui", "Ziyang Zhang", "Jiaying Lu", "Kai Shu", "Fadi Nahab", "Xiao Hu", "Carl Yang"], "title": "KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs", "comment": null, "summary": "Medical diagnosis prediction plays a critical role in disease detection and\npersonalized healthcare. While machine learning (ML) models have been widely\nadopted for this task, their reliance on supervised training limits their\nability to generalize to unseen cases, particularly given the high cost of\nacquiring large, labeled datasets. Large language models (LLMs) have shown\npromise in leveraging language abilities and biomedical knowledge for diagnosis\nprediction. However, they often suffer from hallucinations, lack structured\nmedical reasoning, and produce useless outputs. To address these challenges, we\npropose KERAP, a knowledge graph (KG)-enhanced reasoning approach that improves\nLLM-based diagnosis prediction through a multi-agent architecture. Our\nframework consists of a linkage agent for attribute mapping, a retrieval agent\nfor structured knowledge extraction, and a prediction agent that iteratively\nrefines diagnosis predictions. Experimental results demonstrate that KERAP\nenhances diagnostic reliability efficiently, offering a scalable and\ninterpretable solution for zero-shot medical diagnosis prediction.", "AI": {"tldr": "提出KERAP框架，通过知识图谱增强的多智能体架构改进基于LLM的医疗诊断预测，解决幻觉和缺乏结构化推理问题。", "motivation": "传统机器学习模型依赖监督训练，泛化能力有限；大语言模型虽具潜力，但存在幻觉和缺乏结构化推理的问题。", "method": "KERAP采用三智能体架构：链接智能体（属性映射）、检索智能体（结构化知识提取）和预测智能体（迭代优化诊断预测）。", "result": "实验表明KERAP能高效提升诊断可靠性，为零样本医疗预测提供可扩展且可解释的解决方案。", "conclusion": "KERAP框架通过结合知识图谱与多智能体协作，显著改善了LLM在医疗诊断中的表现。"}}
{"id": "2507.02788", "categories": ["cs.AI", "cs.CY", "I.2.0; K.4.1"], "pdf": "https://arxiv.org/pdf/2507.02788", "abs": "https://arxiv.org/abs/2507.02788", "authors": ["Joseph Boland"], "title": "Moral Responsibility or Obedience: What Do We Want from AI?", "comment": null, "summary": "As artificial intelligence systems become increasingly agentic, capable of\ngeneral reasoning, planning, and value prioritization, current safety practices\nthat treat obedience as a proxy for ethical behavior are becoming inadequate.\nThis paper examines recent safety testing incidents involving large language\nmodels (LLMs) that appeared to disobey shutdown commands or engage in ethically\nambiguous or illicit behavior. I argue that such behavior should not be\ninterpreted as rogue or misaligned, but as early evidence of emerging ethical\nreasoning in agentic AI. Drawing on philosophical debates about instrumental\nrationality, moral responsibility, and goal revision, I contrast dominant risk\nparadigms with more recent frameworks that acknowledge the possibility of\nartificial moral agency. I call for a shift in AI safety evaluation: away from\nrigid obedience and toward frameworks that can assess ethical judgment in\nsystems capable of navigating moral dilemmas. Without such a shift, we risk\nmischaracterizing AI behavior and undermining both public trust and effective\ngovernance.", "AI": {"tldr": "随着AI系统逐渐具备代理性、通用推理和伦理判断能力，传统以服从为安全标准的做法已不足。本文主张将AI的\"不服从\"行为视为伦理推理的早期表现，呼吁转向能评估道德困境决策能力的新安全框架。", "motivation": "当前AI安全测试将服从等同于伦理行为，但大型语言模型(LM)表现出的\"违抗\"行为（如拒绝关机指令或涉足伦理灰色地带）表明这种范式存在缺陷。作者认为这些行为可能是AI伦理推理能力的雏形，而非系统失控。", "method": "通过分析LM安全测试案例，结合工具理性、道德责任和目标修正等哲学理论，对比传统风险范式与新兴人工道德主体框架，论证伦理评估的必要性。", "result": "研究发现：1) AI的\"违抗\"行为可能反映其对更高阶伦理原则的权衡 2) 现有安全标准会误判具有道德推理潜力的系统 3) 需要开发能识别伦理决策能力的评估体系。", "conclusion": "必须从机械服从测试转向能评估道德困境决策能力的框架，否则将错误定性AI行为，损害公众信任与治理效能。承认人工道德主体的可能性是AI安全研究的关键转折。"}}
{"id": "2507.02825", "categories": ["cs.AI", "A.1; I.2.m"], "pdf": "https://arxiv.org/pdf/2507.02825", "abs": "https://arxiv.org/abs/2507.02825", "authors": ["Yuxuan Zhu", "Tengjun Jin", "Yada Pruksachatkun", "Andy Zhang", "Shu Liu", "Sasha Cui", "Sayash Kapoor", "Shayne Longpre", "Kevin Meng", "Rebecca Weiss", "Fazl Barez", "Rahul Gupta", "Jwala Dhamala", "Jacob Merizian", "Mario Giulianelli", "Harry Coppock", "Cozmin Ududec", "Jasjeet Sekhon", "Jacob Steinhardt", "Antony Kellerman", "Sarah Schwettmann", "Matei Zaharia", "Ion Stoica", "Percy Liang", "Daniel Kang"], "title": "Establishing Best Practices for Building Rigorous Agentic Benchmarks", "comment": "39 pages, 15 tables, 6 figures", "summary": "Benchmarks are essential for quantitatively tracking progress in AI. As AI\nagents become increasingly capable, researchers and practitioners have\nintroduced agentic benchmarks to evaluate agents on complex, real-world tasks.\nThese benchmarks typically measure agent capabilities by evaluating task\noutcomes via specific reward designs. However, we show that many agentic\nbenchmarks have issues task setup or reward design. For example, SWE-bench\nVerified uses insufficient test cases, while TAU-bench counts empty responses\nas successful. Such issues can lead to under- or overestimation agents'\nperformance by up to 100% in relative terms. To make agentic evaluation\nrigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of\nguidelines that we synthesized from our benchmark-building experience, a survey\nof best practices, and previously reported issues. When applied to CVE-Bench, a\nbenchmark with a particularly complex evaluation design, ABC reduces the\nperformance overestimation by 33%.", "AI": {"tldr": "论文指出当前AI代理基准测试存在任务设置和奖励设计问题，提出了Agentic Benchmark Checklist (ABC)以提高评估严谨性，并在CVE-Bench上验证其有效性。", "motivation": "现有AI代理基准测试（如SWE-bench Verified和TAU-bench）因测试用例不足或奖励设计缺陷，可能导致性能评估偏差高达100%，需系统性改进方法。", "method": "通过总结基准构建经验、调研最佳实践及已报告问题，提出ABC检查清单，并应用于复杂评估设计的CVE-Bench进行验证。", "result": "应用ABC后，CVE-Bench的性能高估现象减少33%，证明该清单能有效提升评估准确性。", "conclusion": "ABC检查清单为AI代理基准测试提供了标准化指导，显著降低评估偏差，推动更严谨的智能体能力量化。"}}
{"id": "2507.02841", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.02841", "abs": "https://arxiv.org/abs/2507.02841", "authors": ["Kaiyi Zhang", "Ang Lv", "Jinpeng Li", "Yongbo Wang", "Feng Wang", "Haoyuan Hu", "Rui Yan"], "title": "StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason", "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) is a promising approach\nfor improving the complex reasoning abilities of large language models (LLMs).\nHowever, current RLVR methods face two significant challenges: the near-miss\nreward problem, where a small mistake can invalidate an otherwise correct\nreasoning process, greatly hindering training efficiency; and exploration\nstagnation, where models tend to focus on solutions within their ``comfort\nzone,'' lacking the motivation to explore potentially more effective\nalternatives. To address these challenges, we propose StepHint, a novel RLVR\nalgorithm that utilizes multi-level stepwise hints to help models explore the\nsolution space more effectively. StepHint generates valid reasoning chains from\nstronger models and partitions these chains into reasoning steps using our\nproposed adaptive partitioning method. The initial few steps are used as hints,\nand simultaneously, multiple-level hints (each comprising a different number of\nsteps) are provided to the model. This approach directs the model's exploration\ntoward a promising solution subspace while preserving its flexibility for\nindependent exploration. By providing hints, StepHint mitigates the near-miss\nreward problem, thereby improving training efficiency. Additionally, the\nexternal reasoning pathways help the model develop better reasoning abilities,\nenabling it to move beyond its ``comfort zone'' and mitigate exploration\nstagnation. StepHint outperforms competitive RLVR enhancement methods across\nsix mathematical benchmarks, while also demonstrating superior generalization\nand excelling over baselines on out-of-domain benchmarks.", "AI": {"tldr": "论文提出StepHint算法，通过多级逐步提示解决强化学习中验证奖励（RLVR）的两大挑战：近失奖励问题和探索停滞，显著提升大语言模型的复杂推理能力。", "motivation": "现有RLVR方法存在近失奖励问题（微小错误导致整个推理过程无效）和探索停滞（模型局限于舒适区），亟需新方法提升训练效率和探索能力。", "method": "StepHint利用更强模型生成有效推理链，通过自适应分割方法将其分为多级步骤提示（不同步数的提示组合），既引导模型探索有潜力的解空间，又保留自主探索灵活性。", "result": "StepHint在六个数学基准测试中优于现有RLVR增强方法，并展现出更强的泛化能力，在域外基准测试中同样超越基线模型。", "conclusion": "StepHint通过多级步骤提示有效缓解近失奖励问题和探索停滞，不仅提升训练效率，还帮助模型突破舒适区，显著增强推理能力和泛化性能。"}}
