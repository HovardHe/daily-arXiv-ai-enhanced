{"id": "2506.19115", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2506.19115", "abs": "https://arxiv.org/abs/2506.19115", "authors": ["Sebastian Angermund"], "title": "A Two-Operator Calculus for Arithmetic-Progression Paths in the Collatz Graph", "comment": null, "summary": "A recast of the standard residue-class analysis of the 3x+1 (Collatz) map in\nterms of two elementary operators on arithmetic progressions. The resulting\ncalculus (i) splits any progression into its even and odd subsequences in a\nsingle step, (ii) gives a closed formula for every set of seeds that realises a\nprescribed parity word, (iii) yields a one line affine invariant that forbids\ntrajectories consisting of infinitely many odd moves, and (iv) reduces the\nnon-trivial-cycle problem to a pair of linear congruences."}
{"id": "2506.19173", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2506.19173", "abs": "https://arxiv.org/abs/2506.19173", "authors": ["Jamal Agbanwa"], "title": "A Closed-Form Symbolic Generator: $A^n + B^n = C^n + D^n$, for $n = 2,3$", "comment": "13 pages", "summary": "We present a unified framework for constructing integer solutions to $A^{n} +\nB^{n} = C^{n} + D^{n}$ for $n=2,3$. For $n=2$, we derive explicit formulas for\nany solutions via differences of squares. For $n=3$, we introduce general\nformulas that include the Hardy-Ramanujan number 1729 for instance, we also\nconstruct a symbolic generator that produces infinitely many integer solutions\nto the Diophantine equation A^3 + B^3 = C^3 + D^3 . While the resulting\nformulas for $A,B,C,D$ from the symbolic generator developed do not span every\nsingle number expressible as a sum of two positive cubes in at least two\ndistinct ways, our method provides a closed-form, algebraic parametrization in\nterms of a single variable, expressing each term as a radical-exponential\nfunction of an integer parameter $c_1$. The generator leverages nested radicals\nand exponents of algebraic numbers, $\\alpha, \\beta$ derived from the recurrence\nstructure of the Diophantine constraint. This work represents the first\nsymbolic, recursive generator of its kind and offers a pathway toward\napproaching higher powers of this problem from a different lens. These methods\nexploit structural links between binomial expansions and Diophantine\nconstraints, offering a foundation for extensions to higher powers."}
{"id": "2506.18933", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.18933", "abs": "https://arxiv.org/abs/2506.18933", "authors": ["Sebastian Fuchs"], "title": "An Analytic Prime Indicator Based on the Fejer Kernel", "comment": "9 pages, 4 figures", "summary": "This note introduces an analytic prime indicator, constructed by smoothing a\ntrigonometric analogue of trial division. First, a function P: R -> R of class\nC1 is presented, whose zeros for x > 2 correspond precisely to the odd primes.\nIts second derivative exhibits jump discontinuities at integer squares.\nSubsequently, it is shown how this construction can be modified via an infinite\nseries to yield a globally smooth function, P_phi, of class C-inf that\npreserves this prime-zero property. As a primary application, it is\ndemonstrated how this indicator can be used to construct an analytic\napproximation for the prime-counting function pi(x) with a provably controlled\nerror."}
{"id": "2506.19052", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19052", "abs": "https://arxiv.org/abs/2506.19052", "authors": ["Shuangbao Paul Wang", "Paul Mullin"], "title": "Trustworthy Artificial Intelligence for Cyber Threat Analysis", "comment": null, "summary": "Artificial Intelligence brings innovations into the society. However, bias\nand unethical exist in many algorithms that make the applications less\ntrustworthy. Threats hunting algorithms based on machine learning have shown\ngreat advantage over classical methods. Reinforcement learning models are\ngetting more accurate for identifying not only signature-based but also\nbehavior-based threats. Quantum mechanics brings a new dimension in improving\nclassification speed with exponential advantage. In this research, we developed\na machine learning based cyber threat detection and assessment tool. It uses\ntwo stage, unsupervised and supervised learning, analyzing method on log data\nrecorded from a web server on AWS cloud. The results show the algorithm has the\nability to identify cyber threats with high confidence."}
{"id": "2506.19075", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19075", "abs": "https://arxiv.org/abs/2506.19075", "authors": ["Dan Garber"], "title": "First-Order Sparse Convex Optimization: Better Rates with Sparse Updates", "comment": null, "summary": "In was recently established that for convex optimization problems with a\nsparse optimal solution (may it be entry-wise sparsity or matrix rank-wise\nsparsity) it is possible to have linear convergence rates which depend on an\nimproved mixed-norm condition number of the form $\\frac{\\beta_1{}s}{\\alpha_2}$,\nwhere $\\beta_1$ is the $\\ell_1$-Lipchitz continuity constant of the gradient,\n$\\alpha_2$ is the $\\ell_2$-quadratic growth constant, and $s$ is the sparsity\nof the optimal solution. However, beyond the improved convergence rate, these\nmethods are unable to leverage the sparsity of optimal solutions towards\nimproving also the runtime of each iteration, which may still be prohibitively\nhigh for high-dimensional problems. In this work, we establish that linear\nconvergence rates which depend on this improved condition number can be\nobtained using only sparse updates, which may result in overall significantly\nimproved running times. Moreover, our methods are considerably easier to\nimplement."}
{"id": "2506.19025", "categories": ["math.ST", "cs.AI", "cs.LG", "stat.ME", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.19025", "abs": "https://arxiv.org/abs/2506.19025", "authors": ["Sivaraman Balakrishnan", "Tudor Manole", "Larry Wasserman"], "title": "Statistical Inference for Optimal Transport Maps: Recent Advances and Perspectives", "comment": "36 pages, 1 figure", "summary": "In many applications of optimal transport (OT), the object of primary\ninterest is the optimal transport map. This map rearranges mass from one\nprobability distribution to another in the most efficient way possible by\nminimizing a specified cost. In this paper we review recent advances in\nestimating and developing limit theorems for the OT map, using samples from the\nunderlying distributions. We also review parallel lines of work that establish\nsimilar results for special cases and variants of the basic OT setup. We\nconclude with a discussion of key directions for future research with the goal\nof providing practitioners with reliable inferential tools."}
{"id": "2506.18920", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.NE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2506.18920", "abs": "https://arxiv.org/abs/2506.18920", "authors": ["Michael Williams"], "title": "Signal Use and Emergent Cooperation", "comment": "167 pages, 19 figures, PhD dissertation, UCLA, 2006", "summary": "In this work, we investigate how autonomous agents, organized into tribes,\nlearn to use communication signals to coordinate their activities and enhance\ntheir collective efficiency. Using the NEC-DAC (Neurally Encoded Culture -\nDistributed Autonomous Communicators) system, where each agent is equipped with\nits own neural network for decision-making, we demonstrate how these agents\ndevelop a shared behavioral system -- akin to a culture -- through learning and\nsignalling. Our research focuses on the self-organization of culture within\nthese tribes of agents and how varying communication strategies impact their\nfitness and cooperation. By analyzing different social structures, such as\nauthority hierarchies, we show that the culture of cooperation significantly\ninfluences the tribe's performance. Furthermore, we explore how signals not\nonly facilitate the emergence of culture but also enable its transmission\nacross generations of agents. Additionally, we examine the benefits of\ncoordinating behavior and signaling within individual agents' neural networks."}
{"id": "2506.19147", "categories": ["math.LO", "03C45"], "pdf": "https://arxiv.org/pdf/2506.19147", "abs": "https://arxiv.org/abs/2506.19147", "authors": ["James E. Hanson"], "title": "Indiscernible extraction at small large cardinals from a higher-arity stability notion", "comment": "16 pages, 2 figures", "summary": "We introduce a higher-arity stability notion defined in terms of\n$k$-splitting, a higher-arity generalization of splitting. We show that\ntheories with bounded $k$-splitting have improved indiscernible extraction at\n$k$-ineffable cardinals, and we give a non-trivial example of a theory with\nbounded $k$-splitting but unbounded $(k-1)$-splitting for each odd $k > 1$. We\nalso show that bounded $k$-splitting implies $\\mathrm{NFOP}_k$, a higher arity\nstability notion introduced by Terry and Wolf. We then use our indiscernible\nextraction result together with a construction of Kaplan and Shelah to give a\nstrong counterexample to the converse: an $\\mathrm{NIP}$ theory with unbounded\n$k$-splitting for every $k$. Finally, as a thematically related but technically\nindependent result, we show that treelessness implies $\\mathrm{NFOP}_2$,\nsharpening a result of Kaplan, Ramsey, and Simon."}
{"id": "2506.19050", "categories": ["math.CO", "cs.FL", "68R15"], "pdf": "https://arxiv.org/pdf/2506.19050", "abs": "https://arxiv.org/abs/2506.19050", "authors": ["Narad Rampersad", "James Currie"], "title": "Low complexity binary words avoiding $(5/2)^+$-powers", "comment": "7 pages", "summary": "Rote words are infinite words that contain $2n$ factors of length $n$ for\nevery $n \\geq 1$. Shallit and Shur, as well as Ollinger and Shallit, showed\nthat there are Rote words that avoid $(5/2)^+$-powers and that this is best\npossible. In this note we give a structure theorem for the Rote words that\navoid $(5/2)^+$-powers, confirming a conjecture of Ollinger and Shallit."}
{"id": "2506.19284", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.19284", "abs": "https://arxiv.org/abs/2506.19284", "authors": ["Mohammad Hadi Shekarriz", "Dhananjay Thiruvady", "Asef Nazari", "Wilfried Imrich"], "title": "Local Search Improvements for Soft Happy Colouring", "comment": "33 pages, 17 figures, 2 tables", "summary": "For $0\\leq \\rho\\leq 1$ and a coloured graph $G$, a vertex $v$ is $\\rho$-happy\nif at least $\\rho \\deg(v)$ of its neighbours have the same colour as $v$. Soft\nhappy colouring of a partially coloured graph $G$ is the problem of finding a\nvertex colouring $\\sigma$ that preserves the precolouring and has the maximum\nnumber of $\\rho$-happy vertices. It is already known that this problem is\nNP-hard and directly relates to the community structure of the graphs; under a\ncertain condition on the proportion of happiness $\\rho$ and for graphs with\ncommunity structures, the induced colouring by communities can make all the\nvertices $\\rho$-happy. We show that when $0\\leq \\rho_1<\\rho_2\\leq 1$, a\ncomplete $\\rho_2$-happy colouring has a higher accuracy of community detection\nthan a complete $\\rho_1$-happy colouring. Moreover, when $\\rho$ is greater than\na threshold, it is unlikely for an algorithm to find a complete $\\rho$-happy\ncolouring with colour classes of almost equal sizes. Three local search\nalgorithms for soft happy colouring are proposed, and their performances are\ncompared with one another and other known algorithms. Among them, the\nlinear-time local search is shown to be not only very fast, but also a reliable\nalgorithm that can dramatically improve the number of $\\rho$-happy vertices."}
{"id": "2506.19060", "categories": ["math.NT", "11J20"], "pdf": "https://arxiv.org/pdf/2506.19060", "abs": "https://arxiv.org/abs/2506.19060", "authors": ["Lior Fishman", "David Lambert", "Keith Merrill", "David Simmons"], "title": "Diophantine approximation on abelian varieties; a conjecture of M. Waldschmidt", "comment": "11 pages", "summary": "Following the work of Waldschmidt, we investigate problems in Diophantine\napproximation on abelian varieties. First we show that a conjecture of\nWaldschmidt for a given simple abelian variety is equivalent to a well-known\nDiophantine condition holding for a certain matrix related to that variety. We\nthen posit a related but weaker conjecture, and establish the upper bound\ndirection of that conjecture in full generality. For rank 1 elliptic curves\ndefined over a number field $K \\subset \\mathbb{R}$, we then obtain a weak-type\nDirichlet theorem in this setting, establish the optimality of this statement,\nand prove our conjecture in this case."}
{"id": "2506.19054", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19054", "abs": "https://arxiv.org/abs/2506.19054", "authors": ["Mintong Kang", "Zhaorun Chen", "Chejian Xu", "Jiawei Zhang", "Chengquan Guo", "Minzhou Pan", "Ivan Revilla", "Yu Sun", "Bo Li"], "title": "PolyGuard: Massive Multi-Domain Safety Policy-Grounded Guardrail Dataset", "comment": null, "summary": "As LLMs become widespread across diverse applications, concerns about the\nsecurity and safety of LLM interactions have intensified. Numerous guardrail\nmodels and benchmarks have been developed to ensure LLM content safety.\nHowever, existing guardrail benchmarks are often built upon ad hoc risk\ntaxonomies that lack a principled grounding in standardized safety policies,\nlimiting their alignment with real-world operational requirements. Moreover,\nthey tend to overlook domain-specific risks, while the same risk category can\ncarry different implications across different domains. To bridge these gaps, we\nintroduce PolyGuard, the first massive multi-domain safety policy-grounded\nguardrail dataset. PolyGuard offers: (1) broad domain coverage across eight\nsafety-critical domains, such as finance, law, and codeGen; (2) policy-grounded\nrisk construction based on authentic, domain-specific safety guidelines; (3)\ndiverse interaction formats, encompassing declarative statements, questions,\ninstructions, and multi-turn conversations; (4) advanced benign data curation\nvia detoxification prompting to challenge over-refusal behaviors; and (5)\n\\textbf{attack-enhanced instances} that simulate adversarial inputs designed to\nbypass guardrails. Based on PolyGuard, we benchmark 19 advanced guardrail\nmodels and uncover a series of findings, such as: (1) All models achieve varied\nF1 scores, with many demonstrating high variance across risk categories,\nhighlighting their limited domain coverage and insufficient handling of\ndomain-specific safety concerns; (2) As models evolve, their coverage of safety\nrisks broadens, but performance on common risk categories may decrease; (3) All\nmodels remain vulnerable to optimized adversarial attacks. We believe that\n\\dataset and the unique insights derived from our evaluations will advance the\ndevelopment of policy-aligned and resilient guardrail systems."}
{"id": "2506.19129", "categories": ["math.OC", "math.AP", "math.PR", "35R35, 49N60, 60G40, 91A05, 91A15, 93E20"], "pdf": "https://arxiv.org/pdf/2506.19129", "abs": "https://arxiv.org/abs/2506.19129", "authors": ["Andrea Bovo", "Alessandro Milazzo"], "title": "Global regularity of the value function in a stopper vs. singular-controller game", "comment": "25 pages", "summary": "We study a class of zero-sum stochastic games between a stopper and a\nsingular-controller, previously considered in [Bovo and De Angelis (2025)]. The\nunderlying singularly-controlled dynamics takes values in\n$\\mathcal{O}\\subseteq\\mathbb{R}$. The problem is set on a finite time-horizon\nand is connected to a parabolic variational inequality of min-max type with\nspatial-derivative and obstacle constraints.\n  We show that the value function of the problem is of class $C^1$ in the whole\ndomain $[0,T)\\times\\mathcal{O}$ and that the second-order spatial derivative\nand the second-order mixed derivative are continuous everywhere except for a\n(potential) jump across a non-decreasing curve (the stopping boundary of the\ngame). The latter discontinuity is a natural consequence of the partial\ndifferential equation associated to the problem. Beyond its intrinsic\nanalytical value, such a regularity for the value function is a stepping stone\nfor further exploring the structure and properties of the free-boundaries of\nthe stochastic game, which in turn determine the optimal strategies of the\nplayers."}
{"id": "2506.19559", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.19559", "abs": "https://arxiv.org/abs/2506.19559", "authors": ["Arthur Stéphanovitch"], "title": "Regularity of the score function in generative models", "comment": null, "summary": "We study the regularity of the score function in score-based generative\nmodels and show that it naturally adapts to the smoothness of the data\ndistribution. Under minimal assumptions, we establish Lipschitz estimates that\ndirectly support convergence and stability analyses in both diffusion and\nODE-based generative models. In addition, we derive higher-order regularity\nbounds, which simplify existing arguments for optimally approximating the score\nfunction using neural networks."}
{"id": "2506.18928", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18928", "abs": "https://arxiv.org/abs/2506.18928", "authors": ["Lingyu Yang"], "title": "Do LLMs Know When to Flip a Coin? Strategic Randomization through Reasoning and Experience", "comment": null, "summary": "Strategic randomization is a key principle in game theory, yet it remains\nunderexplored in large language models (LLMs). Prior work often conflates the\ncognitive decision to randomize with the mechanical generation of randomness,\nleading to incomplete evaluations. To address this, we propose a novel zero-sum\ngame inspired by the Tian Ji Horse Race, where the Nash equilibrium corresponds\nto a maximal entropy strategy. The game's complexity masks this property from\nuntrained humans and underdeveloped LLMs. We evaluate five LLMs across prompt\nstyles -- framed, neutral, and hinted -- using competitive multi-tournament\ngameplay with system-provided random choices, isolating the decision to\nrandomize. Results show that weaker models remain deterministic regardless of\nprompts, while stronger models exhibit increased randomization under explicit\nhints. When facing weaker models, strong LLMs adopt deterministic strategies to\nexploit biases, but converge toward equilibrium play when facing peers. Through\nwin/loss outcomes and Bayes factor analysis, we demonstrate meaningful\nvariation in LLMs' strategic reasoning capabilities, highlighting opportunities\nfor improvement in abstract reasoning and adaptive learning. We make our\nimplementation publicly available at\nhttps://github.com/ocelopus/llm-when-to-throw-coin to ensure full\nreproducibility."}
{"id": "2506.19489", "categories": ["math.LO", "16W99, 12H05, 03C60, 03C45"], "pdf": "https://arxiv.org/pdf/2506.19489", "abs": "https://arxiv.org/abs/2506.19489", "authors": ["Jan Dobrowolski", "Omar Leon Sanchez"], "title": "Fields with Lie-commuting and iterative operators", "comment": null, "summary": "We introduce a general framework for studying fields equipped with operators,\ngiven as co-ordinate functions of homomorphisms into a local algebra\n$\\mathcal{D}$, satisfying various compatibility conditions that we denote by\n$\\Gamma$ and call such structures $\\mathcal{D}^{\\Gamma}$-fields. These include\nLie-commutativity of derivations and $\\mathfrak g$-iterativity of (truncated)\nHasse-Schmidt derivations. Our main result is about the existence of principal\nrealisations of $\\mathcal{D}^{\\Gamma}$-kernels. As an application, we prove\ncompanionability of the theory of $\\mathcal{D}^{\\Gamma}$-fields and denote the\ncompanion by $\\mathcal{D}^{\\Gamma}$-CF. In characteristic zero, we prove that\n$\\mathcal{D}^{\\Gamma}$-CF is a stable theory that satisfies the CBP and\nZilber's dichotomy for finite-dimensional types. We also prove that there is a\nuniform companion for model-complete theories of large\n$\\mathcal{D}^{\\Gamma}$-fields, which leads to the notion of\n$\\mathcal{D}^{\\Gamma}$-large fields and we further use this to show that PAC\nsubstructures of $\\mathcal{D}^{\\Gamma}$-DCF are elementary."}
{"id": "2506.19061", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.19061", "abs": "https://arxiv.org/abs/2506.19061", "authors": ["Sean English", "Sam Spiro"], "title": "Rational Exponents for General Graphs", "comment": null, "summary": "A rational number $r$ is a \\textbf{realizable exponent} for a graph $H$ if\nthere exists a finite family of graphs $\\mathcal{F}$ such that\n$\\mathrm{ex}(n,H,\\mathcal{F})=\\Theta(n^r)$, where\n$\\mathrm{ex}(n,H,\\mathcal{F})$ denotes the maximum number of copies of $H$ that\nan $n$-vertex $\\mathcal{F}$-free graph can have. Results for realizable\nexponents are currently known only when $H$ is either a star or a clique, with\nthe full resolution of the $H=K_2$ case being a major breakthrough of Bukh and\nConlon.\n  In this paper, we establish the first set of results for realizable exponents\nwhich hold for arbitrary graphs $H$ by showing that for any graph $H$ with\nmaximum degree $\\Delta \\ge 1$, every rational in the interval\n$\\left[v(H)-\\frac{e(H)}{2\\Delta^2},\\ v(H)\\right]$ is realizable for $H$. We\nalso prove a ``stability'' result for generalized Tur\\'an numbers of trees\nwhich implies that if $T\\ne K_2$ is a tree with $\\ell$ leaves, then $T$ has no\nrealizable exponents in $[0,\\ell]\\setminus \\mathbb{Z}$. Our proof of this\nlatter result uses a new variant of the classical Helly theorem for trees,\nwhich may be of independent interest."}
{"id": "2506.19529", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.19529", "abs": "https://arxiv.org/abs/2506.19529", "authors": ["Hande Tuncel Golpek", "Zeliha Kartal Yildiz", "Aysun Aytac"], "title": "Paired Disjunctive Domination Number of Middle Graphs", "comment": "12 pages, 0 figures", "summary": "The concept of domination in graphs plays a central role in understanding\nstructural properties and applications in network theory. In this study, we\nfocus on the paired disjunctive domination number in the context of middle\ngraphs, a transformation that captures both adjacency and incidence relations\nof the original graph. We begin by investigating this parameter for middle\ngraphs of several special graph classes, including path graphs, cycle graphs,\nwheel graphs, complete graphs, complete bipartite graphs, star graphs,\nfriendship graphs, and double star graphs. We then present general results by\nestablishing lower and upper bounds for the paired disjunctive domination\nnumber in middle graphs of arbitrary graphs, with particular emphasis on trees.\nAdditionally, we determine the exact value of the parameter for middle graphs\nobtained through the join operation. These findings contribute to the broader\nunderstanding of domination-type parameters in transformed graph structures and\noffer new insights into their combinatorial behavior."}
{"id": "2506.19319", "categories": ["math.NT", "11R42"], "pdf": "https://arxiv.org/pdf/2506.19319", "abs": "https://arxiv.org/abs/2506.19319", "authors": ["Sourabhashis Das", "Swati Gaba", "Ethan Simpson Lee", "Aditi Savalia", "Peng-Jie Wong"], "title": "New zero-free regions for Dedekind zeta-functions at small and large ordinates", "comment": null, "summary": "Given a number field $L\\neq \\mathbb{Q}$, we obtain new and explicit zero-free\nregions for Dedekind zeta-functions of $L$, which refine the previous works of\nAhn--Kwon, Kadiri, and Lee. In particular, for low-lying zeros, we extend\nKadiri's result to all number fields while improving the main constant."}
{"id": "2506.19109", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19109", "abs": "https://arxiv.org/abs/2506.19109", "authors": ["Valerii Gakh", "Hayretdin Bahsi"], "title": "Enhancing Security in LLM Applications: A Performance Evaluation of Early Detection Systems", "comment": "18 pages, 8 tables, 7 figures", "summary": "Prompt injection threatens novel applications that emerge from adapting LLMs\nfor various user tasks. The newly developed LLM-based software applications\nbecome more ubiquitous and diverse. However, the threat of prompt injection\nattacks undermines the security of these systems as the mitigation and defenses\nagainst them, proposed so far, are insufficient. We investigated the\ncapabilities of early prompt injection detection systems, focusing specifically\non the detection performance of techniques implemented in various open-source\nsolutions. These solutions are supposed to detect certain types of prompt\ninjection attacks, including the prompt leak. In prompt leakage attacks, an\nattacker maliciously manipulates the LLM into outputting its system\ninstructions, violating the system's confidentiality. Our study presents\nanalyzes of distinct prompt leakage detection techniques, and a comparative\nanalysis of several detection solutions, which implement those techniques. We\nidentify the strengths and weaknesses of these techniques and elaborate on\ntheir optimal configuration and usage in high-stake deployments. In one of the\nfirst studies on existing prompt leak detection solutions, we compared the\nperformances of LLM Guard, Vigil, and Rebuff. We concluded that the\nimplementations of canary word checks in Vigil and Rebuff were not effective at\ndetecting prompt leak attacks, and we proposed improvements for them. We also\nfound an evasion weakness in Rebuff's secondary model-based technique and\nproposed a mitigation. Then, the result of the comparison of LLM Guard, Vigil,\nand Rebuff at their peak performance revealed that Vigil is optimal for cases\nwhen minimal false positive rate is required, and Rebuff is the most optimal\nfor average needs."}
{"id": "2506.19155", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.19155", "abs": "https://arxiv.org/abs/2506.19155", "authors": ["Jasone Ramírez-Ayerbe", "Emma Frejinger"], "title": "Relative Explanations for Contextual Problems with Endogenous Uncertainty: An Application to Competitive Facility Location", "comment": null, "summary": "In this paper, we consider contextual stochastic optimization problems\nsubject to endogenous uncertainty, where the decisions affect the underlying\ndistributions. To implement such decisions in practice, it is crucial to ensure\nthat their outcomes are interpretable and trustworthy. To this end, we compute\nrelative counterfactual explanations, providing practitioners with concrete\nchanges in the contextual covariates required for a solution to satisfy\nspecific constraints. Whereas relative explanations have been introduced in\nprior literature, to the best of our knowledge, this is the first work focused\non problems with binary decision variables and subject to endogenous\nuncertainty. We propose a methodology that uses Wasserstein distance as\nregularization and to compute a lower bound. It leads to a drastic reduction in\ncomputation times, compared to the unregularized counterpart. We illustrate the\nmethod using a choice-based competitive facility location problem, and present\nnumerical experiments that demonstrate its ability to efficiently compute\nsparse and interpretable explanations."}
{"id": "2506.19587", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.19587", "abs": "https://arxiv.org/abs/2506.19587", "authors": ["Arthur Stéphanovitch"], "title": "Generative model for optimal density estimation on unknown manifold", "comment": null, "summary": "We propose a generative model that achieves minimax-optimal convergence rates\nfor estimating probability distributions supported on unknown low-dimensional\nmanifolds. Building on Fefferman's solution to the geometric Whitney problem,\nour estimator is itself supported on a submanifold that matches the regularity\nof the data's support. This geometric adaptation enables the estimator to be\nsimultaneously minimax-optimal for all \\( \\gamma \\)-H\\\"older Integral\nProbability Metrics (IPMs) with \\( \\gamma \\geq 1 \\). We validate our approach\nthrough experiments on synthetic and real datasets, demonstrating competitive\nor superior performance compared to Wasserstein GAN and score-based generative\nmodels."}
{"id": "2506.18957", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.18957", "abs": "https://arxiv.org/abs/2506.18957", "authors": ["Sheraz Khan", "Subha Madhavan", "Kannan Natarajan"], "title": "A Comment On \"The Illusion of Thinking\": Reframing the Reasoning Cliff as an Agentic Gap", "comment": "10 pages, 2 figures, Comment on \"The Illusion of Thinking:\n  Understanding the Strengths and Limitations of Reasoning Models via the Lens\n  of Problem Complexity\" (arXiv:2506.06941v1)", "summary": "The recent work by Shojaee et al. (2025), titled The Illusion of Thinking:\nUnderstanding the Strengths and Limitations of Reasoning Models via the Lens of\nProblem Complexity, presents a compelling empirical finding, a reasoning cliff,\nwhere the performance of Large Reasoning Models (LRMs) collapses beyond a\nspecific complexity threshold, which the authors posit as an intrinsic scaling\nlimitation of Chain-of-Thought (CoT) reasoning. This commentary, while\nacknowledging the study's methodological rigor, contends that this conclusion\nis confounded by experimental artifacts. We argue that the observed failure is\nnot evidence of a fundamental cognitive boundary, but rather a predictable\noutcome of system-level constraints in the static, text-only evaluation\nparadigm, including tool use restrictions, context window recall issues, the\nabsence of crucial cognitive baselines, inadequate statistical reporting, and\noutput generation limits. We reframe this performance collapse through the lens\nof an agentic gap, asserting that the models are not failing at reasoning, but\nat execution within a profoundly restrictive interface. We empirically\nsubstantiate this critique by demonstrating a striking reversal. A model,\ninitially declaring a puzzle impossible when confined to text-only generation,\nnow employs agentic tools to not only solve it but also master variations of\ncomplexity far beyond the reasoning cliff it previously failed to surmount.\nAdditionally, our empirical analysis of tool-enabled models like o4-mini and\nGPT-4o reveals a hierarchy of agentic reasoning, from simple procedural\nexecution to complex meta-cognitive self-correction, which has significant\nimplications for how we define and measure machine intelligence. The illusion\nof thinking attributed to LRMs is less a reasoning deficit and more a\nconsequence of an otherwise capable mind lacking the tools for action."}
{"id": "2506.19191", "categories": ["cs.AI", "cs.CL", "cs.GT", "math.LO", "68T05, 68Q87, 03E20", "I.2.6; I.2.3; F.1.1"], "pdf": "https://arxiv.org/pdf/2506.19191", "abs": "https://arxiv.org/abs/2506.19191", "authors": ["Craig Steven Wright"], "title": "Bayesian Evolutionary Swarm Architecture: A Formal Epistemic System Grounded in Truth-Based Competition", "comment": "83 pages, 14 sections, 92 formal results, no prior conference\n  publication", "summary": "We introduce a mathematically rigorous framework for an artificial\nintelligence system composed of probabilistic agents evolving through\nstructured competition and belief revision. The architecture, grounded in\nBayesian inference, measure theory, and population dynamics, defines agent\nfitness as a function of alignment with a fixed external oracle representing\nground truth. Agents compete in a discrete-time environment, adjusting\nposterior beliefs through observed outcomes, with higher-rated agents\nreproducing and lower-rated agents undergoing extinction. Ratings are updated\nvia pairwise truth-aligned utility comparisons, and belief updates preserve\nmeasurable consistency and stochastic convergence. We introduce hash-based\ncryptographic identity commitments to ensure traceability, alongside causal\ninference operators using do-calculus. Formal theorems on convergence,\nrobustness, and evolutionary stability are provided. The system establishes\ntruth as an evolutionary attractor, demonstrating that verifiable knowledge\narises from adversarial epistemic pressure within a computable, self-regulating\nswarm."}
{"id": "2506.19100", "categories": ["math.CO", "05C15, 05C38"], "pdf": "https://arxiv.org/pdf/2506.19100", "abs": "https://arxiv.org/abs/2506.19100", "authors": ["Ben Cameron", "Alexander Clow"], "title": "On Gyárfás' Path-Colour Problem", "comment": "30 pages, 5 figures", "summary": "In their 1997 paper titled ``Fruit Salad\", Gy\\'{a}rf\\'{a}s posed the\nfollowing conjecture: there exists a constant $k$ such that if each path of a\ngraph spans a $3$-colourable subgraph, then the graph is $k$-colourable. It is\nnoted that $k=4$ might suffice. Let $r(G)$ be the maximum chromatic number of\nany subgraph $H$ of $G$ where $H$ is spanned by a path. The only progress on\nthis conjecture comes from Randerath and Schiermeyer in 2002, who proved that\nif $G$ is an $n$ vertex graph, then $\\chi(G) \\leq r(G)\\log_{\\frac{8}{7}}(n)$.\n  We prove that for all natural numbers $r$, there exists a graph $G$ with\n$r(G)\\leq r$ and $\\chi(G)\\geq \\lfloor\\frac{3r}{2}\\rfloor -1$. Hence, for all\nconstants $k$ there exists a graph with $\\chi - r > k$. Our proof is\nconstructive.\n  We also study this problem in graphs with a forbidden induced subgraph. We\nshow that if $G$ is $K_{1,t}$-free, for $t\\geq 4$, then $\\chi(G) \\leq\n(t-1)(r(G)+\\binom{t-1}{2}-3)$. If $G$ is claw-free, then we prove $\\chi(G) \\leq\n2r(G)$. Additionally, the graphs $G$ where every induced subgraph $G'$ of $G$\nsatisfy $\\chi(G') = r(G')$ are considered. We call such graphs path-perfect, as\nthis class generalizes perfect graphs. We prove that if $H$ is a forest with at\nmost $4$ vertices other than the claw, then every $H$-free graph $G$ has\n$\\chi(G) \\leq r(G)+1$. We also prove that if $H$ is additionally not isomorphic\nto $2K_2$ or $K_2+2K_1$, then all $H$-free graphs are path-perfect."}
{"id": "2506.19149", "categories": ["math.CO", "cs.DM", "05C35, 05C38, 05C69"], "pdf": "https://arxiv.org/pdf/2506.19149", "abs": "https://arxiv.org/abs/2506.19149", "authors": ["Karl Bartolo", "Peter Borg", "Dayle Scicluna"], "title": "Solution to a problem on isolation of $3$-vertex paths", "comment": "12 pages", "summary": "The $3$-path isolation number of a connected $n$-vertex graph $G$, denoted by\n$\\iota(G,P_3)$, is the size of a smallest subset $D$ of the vertex set of $G$\nsuch that the closed neighbourhood $N[D]$ of $D$ in $G$ intersects each\n$3$-vertex path of $G$, meaning that no two edges of $G-N[D]$ intersect. Zhang\nand Wu proved that $\\iota(G,P_3) \\leq 2n/7$ unless $G$ is a $3$-path or a\n$3$-cycle or a $6$-cycle. The bound is attained by infinitely many graphs\nhaving induced $6$-cycles. Huang, Zhang and Jin proved that if $G$ has no\n$6$-cycles, or $G$ has no induced $5$-cycles and no induced $6$-cycles, then\n$\\iota(G, P_3) \\leq n/4$ unless $G$ is a $3$-path or a $3$-cycle or a $7$-cycle\nor an $11$-cycle. They asked if the bound still holds asymptotically for\nconnected graphs having no induced $6$-cycles. More precisely, taking $f(n)$ to\nbe the maximum value of $\\iota(G,P_3)$ over all connected $n$-vertex graphs $G$\nhaving no induced $6$-cycles, their question is whether $\\limsup_{n\n\\to\\infty}\\frac{f(n)}{n} = \\frac{1}{4}$. We verify this by proving that $f(n) =\n\\left \\lfloor (n+1)/4 \\right \\rfloor$. The proof hinges on further proving that\nif $G$ is such a graph and $\\iota(G, P_3) = (n+1)/4$, then $\\iota(G-v, P_3) <\n\\iota(G, P_3)$ for each vertex $v$ of $G$. This new idea promises to be of\nfurther use. We also prove that if the maximum degree of such a graph $G$ is at\nleast $5$, then $\\iota(G,P_3) \\leq n/4$."}
{"id": "2506.19411", "categories": ["math.NT", "math.LO"], "pdf": "https://arxiv.org/pdf/2506.19411", "abs": "https://arxiv.org/abs/2506.19411", "authors": ["Floris Vermeulen"], "title": "Counting rational points on transcendental curves in valued fields", "comment": "9 pages", "summary": "We prove upper bounds on the number of rational points on transcendental\ncurves in arbitrary $1$-h-minimal fields, similar to the Pila--Wilkie counting\ntheorem in the o-minimal setting. These results extend results due to\nCluckers--Comte--Loeser from $p$-adic fields to arbitrary valued fields of\nmixed characteristic. Our methods rely on parametrizations, where we avoid the\nusage of $r$-th power maps, combined with the determinant method."}
{"id": "2506.19260", "categories": ["cs.CR", "cs.DC", "cs.LG", "I.2.6; C.2.4; K.6.5"], "pdf": "https://arxiv.org/pdf/2506.19260", "abs": "https://arxiv.org/abs/2506.19260", "authors": ["Murtaza Rangwala", "Richard O. Sinnott", "Rajkumar Buyya"], "title": "Network Structures as an Attack Surface: Topology-Based Privacy Leakage in Federated Learning", "comment": "13 pages, 7 figures, 5 tables. Data from the experiments and source\n  code can be found here: https://doi.org/10.5281/zenodo.15622123", "summary": "Federated learning systems increasingly rely on diverse network topologies to\naddress scalability and organizational constraints. While existing privacy\nresearch focuses on gradient-based attacks, the privacy implications of network\ntopology knowledge remain critically understudied. We conduct the first\ncomprehensive analysis of topology-based privacy leakage across realistic\nadversarial knowledge scenarios, demonstrating that adversaries with varying\ndegrees of structural knowledge can infer sensitive data distribution patterns\neven under strong differential privacy guarantees. Through systematic\nevaluation of 4,720 attack instances, we analyze six distinct adversarial\nknowledge scenarios: complete topology knowledge and five partial knowledge\nconfigurations reflecting real-world deployment constraints. We propose three\ncomplementary attack vectors: communication pattern analysis, parameter\nmagnitude profiling, and structural position correlation, achieving success\nrates of 84.1%, 65.0%, and 47.2% under complete knowledge conditions.\nCritically, we find that 80% of realistic partial knowledge scenarios maintain\nattack effectiveness above security thresholds, with certain partial knowledge\nconfigurations achieving performance superior to the baseline complete\nknowledge scenario. To address these vulnerabilities, we propose and\nempirically validate structural noise injection as a complementary defense\nmechanism across 808 configurations, demonstrating up to 51.4% additional\nattack reduction when properly layered with existing privacy techniques. These\nresults establish that network topology represents a fundamental privacy\nvulnerability in federated learning systems while providing practical pathways\nfor mitigation through topology-aware defense mechanisms."}
{"id": "2506.19294", "categories": ["math.OC", "math.PR", "q-fin.PM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.19294", "abs": "https://arxiv.org/abs/2506.19294", "authors": ["Jose Blanchet", "Jiayi Cheng", "Hao Liu", "Yang Liu"], "title": "Duality and Policy Evaluation in Distributionally Robust Bayesian Diffusion Control", "comment": null, "summary": "We consider a Bayesian diffusion control problem of expected terminal utility\nmaximization. The controller imposes a prior distribution on the unknown drift\nof an underlying diffusion. The Bayesian optimal control, tracking the\nposterior distribution of the unknown drift, can be characterized explicitly.\nHowever, in practice, the prior will generally be incorrectly specified, and\nthe degree of model misspecification can have a significant impact on policy\nperformance. To mitigate this and reduce overpessimism, we introduce a\ndistributionally robust Bayesian control (DRBC) formulation in which the\ncontroller plays a game against an adversary who selects a prior in divergence\nneighborhood of a baseline prior. The adversarial approach has been studied in\neconomics and efficient algorithms have been proposed in static optimization\nsettings. We develop a strong duality result for our DRBC formulation.\nCombining these results together with tools from stochastic analysis, we are\nable to derive a loss that can be efficiently trained (as we demonstrate in our\nnumerical experiments) using a suitable neural network architecture. As a\nresult, we obtain an effective algorithm for computing the DRBC optimal\nstrategy. The methodology for computing the DRBC optimal strategy is greatly\nsimplified, as we show, in the important case in which the adversary chooses a\nprior from a Kullback-Leibler distributional uncertainty set."}
{"id": "2506.19748", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.19748", "abs": "https://arxiv.org/abs/2506.19748", "authors": ["Aman Pandey", "Chanchal Kundu"], "title": "Copula-Based Modeling of Fractional Inaccuracy: A Unified Framework", "comment": "4 Figures", "summary": "We introduce novel information-theoretic measures termed the multivariate\ncumulative copula fractional inaccuracy measure and the multivariate survival\ncopula fractional inaccuracy measure, constructed respectively from\nmultivariate copulas and multivariate survival copulas. These measures\ngeneralize the concept of fractional inaccuracy to multivariate settings by\nincorporating dependence structures through copulas. We establish bounds for\nthese measures using the Frechet-Hoeffding bounds and investigate their\nbehavior under lower and upper orthant stochastic orderings to facilitate\ncomparative analysis. Furthermore, we define the multivariate co-copula\nfractional inaccuracy measure and the multivariate dual copula fractional\ninaccuracy measure, derived from the multivariate co-copula and dual copula,\nrespectively, and examine several analogous properties for these extended\nforms."}
{"id": "2506.19046", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19046", "abs": "https://arxiv.org/abs/2506.19046", "authors": ["Filip Sabo", "Michele Meroni", "Maria Piles", "Martin Claverie", "Fanie Ferreira", "Elna Van Den Berg", "Francesco Collivignarelli", "Felix Rembold"], "title": "From Rows to Yields: How Foundation Models for Tabular Data Simplify Crop Yield Prediction", "comment": null, "summary": "We present an application of a foundation model for small- to medium-sized\ntabular data (TabPFN), to sub-national yield forecasting task in South Africa.\nTabPFN has recently demonstrated superior performance compared to traditional\nmachine learning (ML) models in various regression and classification tasks. We\nused the dekadal (10-days) time series of Earth Observation (EO; FAPAR and soil\nmoisture) and gridded weather data (air temperature, precipitation and\nradiation) to forecast the yield of summer crops at the sub-national level. The\ncrop yield data was available for 23 years and for up to 8 provinces. Covariate\nvariables for TabPFN (i.e., EO and weather) were extracted by region and\naggregated at a monthly scale. We benchmarked the results of the TabPFN against\nsix ML models and three baseline models. Leave-one-year-out cross-validation\nexperiment setting was used in order to ensure the assessment of the models\ncapacity to forecast an unseen year. Results showed that TabPFN and ML models\nexhibit comparable accuracy, outperforming the baselines. Nonetheless, TabPFN\ndemonstrated superior practical utility due to its significantly faster tuning\ntime and reduced requirement for feature engineering. This renders TabPFN a\nmore viable option for real-world operation yield forecasting applications,\nwhere efficiency and ease of implementation are paramount."}
{"id": "2506.19411", "categories": ["math.NT", "math.LO"], "pdf": "https://arxiv.org/pdf/2506.19411", "abs": "https://arxiv.org/abs/2506.19411", "authors": ["Floris Vermeulen"], "title": "Counting rational points on transcendental curves in valued fields", "comment": "9 pages", "summary": "We prove upper bounds on the number of rational points on transcendental\ncurves in arbitrary $1$-h-minimal fields, similar to the Pila--Wilkie counting\ntheorem in the o-minimal setting. These results extend results due to\nCluckers--Comte--Loeser from $p$-adic fields to arbitrary valued fields of\nmixed characteristic. Our methods rely on parametrizations, where we avoid the\nusage of $r$-th power maps, combined with the determinant method."}
{"id": "2506.19126", "categories": ["math.CO", "05C15"], "pdf": "https://arxiv.org/pdf/2506.19126", "abs": "https://arxiv.org/abs/2506.19126", "authors": ["Aaron Abrams"], "title": "Upper Chromatic Numbers: An Update", "comment": "This is a survey written in 2000 about upper chromatic numbers", "summary": "This is a survey written in 2000 about upper chromatic numbers"}
{"id": "2506.19768", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2506.19768", "abs": "https://arxiv.org/abs/2506.19768", "authors": ["Valentin Dusollier", "Sébastien Bonte", "Gauvain Devillez", "Alain Hertz", "Hadrien Mélot", "David Schindl"], "title": "Complete polyhedral description of chemical graphs of maximum degree at most 3", "comment": "30 pages", "summary": "Chemical graphs are simple undirected connected graphs, where vertices\nrepresent atoms in a molecule and edges represent chemical bonds. A\ndegree-based topological index is a molecular descriptor used to study specific\nphysicochemical properties of molecules. Such an index is computed from the sum\nof the weights of the edges of a chemical graph, each edge having a weight\ndefined by a formula that depends only on the degrees of its endpoints. Given\nany degree-based topological index and given two integers $n$ and $m$, we are\ninterested in determining chemical graphs of order $n$ and size $m$ that\nmaximize or minimize the index. Focusing on chemical graphs with maximum degree\nat most 3, we show that this reduces to determining the extreme points of a\npolytope that contains at most 10 facets. We also show that the number of\nextreme points is at most 16, which means that for any given $n$ and $m$, there\nare very few different classes of extremal graphs, independently of the chosen\ndegree-based topological index."}
{"id": "2506.19423", "categories": ["math.NT", "math.AG"], "pdf": "https://arxiv.org/pdf/2506.19423", "abs": "https://arxiv.org/abs/2506.19423", "authors": ["Remke Kloosterman"], "title": "Determining explicitly the Mordell-Weil group of certain rational elliptic surfaces", "comment": null, "summary": "Let $A,B$ be nonzero rational numbers. Consider the elliptic curve\n$E_{A,B}/\\mathbb{Q}(t)$ with Weierstrass equation $y^2=x^3+At^6+B$.\n  An algorithm to determine $\\mathrm{rank } E_{A,B}(\\mathbb{Q}(t))$ as a\nfunction of $(A,B)$ was presented in a recent paper by Desjardins and\nNaskrecki. We will give a different and shorter proof for the correctness of\nthat algorithm, using a more geometric approach and discuss for which classes\nof examples this approach might be useful."}
{"id": "2506.19356", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19356", "abs": "https://arxiv.org/abs/2506.19356", "authors": ["Ye Tian", "Zhang Yumin", "Yifan Jia", "Jianguo Sun", "Yanbin Wang"], "title": "WebGuard++:Interpretable Malicious URL Detection via Bidirectional Fusion of HTML Subgraphs and Multi-Scale Convolutional BERT", "comment": null, "summary": "URL+HTML feature fusion shows promise for robust malicious URL detection,\nsince attacker artifacts persist in DOM structures. However, prior work suffers\nfrom four critical shortcomings: (1) incomplete URL modeling, failing to\njointly capture lexical patterns and semantic context; (2) HTML graph sparsity,\nwhere threat-indicative nodes (e.g., obfuscated scripts) are isolated amid\nbenign content, causing signal dilution during graph aggregation; (3)\nunidirectional analysis, ignoring URL-HTML feature bidirectional interaction;\nand (4) opaque decisions, lacking attribution to malicious DOM components. To\naddress these challenges, we present WebGuard++, a detection framework with 4\nnovel components: 1) Cross-scale URL Encoder: Hierarchically learns\nlocal-to-global and coarse to fine URL features based on Transformer network\nwith dynamic convolution. 2) Subgraph-aware HTML Encoder: Decomposes DOM graphs\ninto interpretable substructures, amplifying sparse threat signals via\nHierarchical feature fusion. 3) Bidirectional Coupling Module: Aligns URL and\nHTML embeddings through cross-modal contrastive learning, optimizing\ninter-modal consistency and intra-modal specificity. 4) Voting Module:\nLocalizes malicious regions through consensus voting on malicious subgraph\npredictions. Experiments show WebGuard++ achieves significant improvements over\nstate-of-the-art baselines, achieving 1.1x-7.9x higher TPR at fixed FPR of\n0.001 and 0.0001 across both datasets."}
{"id": "2506.19426", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.19426", "abs": "https://arxiv.org/abs/2506.19426", "authors": ["Andrea Spinelli", "Dario Bezzi", "Ola Jabali", "Francesca Maggioni"], "title": "A Stochastic Electric Vehicle Routing Problem under Uncertain Energy Consumption", "comment": null, "summary": "The increasing adoption of Electric Vehicles (EVs) for service and goods\ndistribution operations has led to the emergence of Electric Vehicle Routing\nProblems (EVRPs), a class of vehicle routing problems addressing the unique\nchallenges posed by the limited driving range and recharging needs of EVs.\nWhile the majority of EVRP variants have considered deterministic energy\nconsumption, this paper focuses on the Stochastic Electric Vehicle Routing\nProblem with a Threshold recourse policy (SEVRP-T), where the uncertainty in\nenergy consumption is considered, and a recourse policy is employed to ensure\nthat EVs recharge at Charging Stations (CSs) whenever their State of Charge\n(SoC) falls below a specified threshold. We formulate the SEVRP-T as a\ntwo-stage stochastic mixed-integer second-order cone model, where the first\nstage determines the sequences of customers to be visited, and the second stage\nincorporates charging activities. The objective is to minimize the expected\ntotal duration of the routes, composed by travel times and recharging\noperations. To cope with the computational complexity of the model, we propose\na heuristic based on an Iterated Local Search (ILS) procedure coupled with a\nSet Partitioning problem. To further speed up the heuristic, we develop two\nlower bounds on the corresponding first-stage customer sequences. Furthermore,\nto handle a large number of energy consumption scenarios, we employ a scenario\nreduction technique. Extensive computational experiments are conducted to\nvalidate the effectiveness of the proposed solution strategy and to assess the\nimportance of considering the stochastic nature of the energy consumption. The\nresearch presented in this paper contributes to the growing body of literature\non EVRP and provides insights into managing the operational deployment of EVs\nin logistics activities under uncertainty."}
{"id": "2506.19095", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19095", "abs": "https://arxiv.org/abs/2506.19095", "authors": ["Fien van Wetten", "Aske Plaat", "Max van Duijn"], "title": "Baba is LLM: Reasoning in a Game with Dynamic Rules", "comment": null, "summary": "Large language models (LLMs) are known to perform well on language tasks, but\nstruggle with reasoning tasks. This paper explores the ability of LLMs to play\nthe 2D puzzle game Baba is You, in which players manipulate rules by\nrearranging text blocks that define object properties. Given that this\nrule-manipulation relies on language abilities and reasoning, it is a\ncompelling challenge for LLMs. Six LLMs are evaluated using different prompt\ntypes, including (1) simple, (2) rule-extended and (3) action-extended prompts.\nIn addition, two models (Mistral, OLMo) are finetuned using textual and\nstructural data from the game. Results show that while larger models\n(particularly GPT-4o) perform better in reasoning and puzzle solving, smaller\nunadapted models struggle to recognize game mechanics or apply rule changes.\nFinetuning improves the ability to analyze the game levels, but does not\nsignificantly improve solution formulation. We conclude that even for\nstate-of-the-art and finetuned LLMs, reasoning about dynamic rule changes is\ndifficult (specifically, understanding the use-mention distinction). The\nresults provide insights into the applicability of LLMs to complex\nproblem-solving tasks and highlight the suitability of games with dynamically\nchanging rules for testing reasoning and reflection by LLMs."}
{"id": "2506.19149", "categories": ["math.CO", "cs.DM", "05C35, 05C38, 05C69"], "pdf": "https://arxiv.org/pdf/2506.19149", "abs": "https://arxiv.org/abs/2506.19149", "authors": ["Karl Bartolo", "Peter Borg", "Dayle Scicluna"], "title": "Solution to a problem on isolation of $3$-vertex paths", "comment": "12 pages", "summary": "The $3$-path isolation number of a connected $n$-vertex graph $G$, denoted by\n$\\iota(G,P_3)$, is the size of a smallest subset $D$ of the vertex set of $G$\nsuch that the closed neighbourhood $N[D]$ of $D$ in $G$ intersects each\n$3$-vertex path of $G$, meaning that no two edges of $G-N[D]$ intersect. Zhang\nand Wu proved that $\\iota(G,P_3) \\leq 2n/7$ unless $G$ is a $3$-path or a\n$3$-cycle or a $6$-cycle. The bound is attained by infinitely many graphs\nhaving induced $6$-cycles. Huang, Zhang and Jin proved that if $G$ has no\n$6$-cycles, or $G$ has no induced $5$-cycles and no induced $6$-cycles, then\n$\\iota(G, P_3) \\leq n/4$ unless $G$ is a $3$-path or a $3$-cycle or a $7$-cycle\nor an $11$-cycle. They asked if the bound still holds asymptotically for\nconnected graphs having no induced $6$-cycles. More precisely, taking $f(n)$ to\nbe the maximum value of $\\iota(G,P_3)$ over all connected $n$-vertex graphs $G$\nhaving no induced $6$-cycles, their question is whether $\\limsup_{n\n\\to\\infty}\\frac{f(n)}{n} = \\frac{1}{4}$. We verify this by proving that $f(n) =\n\\left \\lfloor (n+1)/4 \\right \\rfloor$. The proof hinges on further proving that\nif $G$ is such a graph and $\\iota(G, P_3) = (n+1)/4$, then $\\iota(G-v, P_3) <\n\\iota(G, P_3)$ for each vertex $v$ of $G$. This new idea promises to be of\nfurther use. We also prove that if the maximum degree of such a graph $G$ is at\nleast $5$, then $\\iota(G,P_3) \\leq n/4$."}
{"id": "2506.19560", "categories": ["math.NT", "14G35, 11G05"], "pdf": "https://arxiv.org/pdf/2506.19560", "abs": "https://arxiv.org/abs/2506.19560", "authors": ["Abbey Bourdon", "Özlem Ejder"], "title": "Rational isolated $j$-invariants from $X_1(\\ell^n)$ and $X_0(\\ell^n)$", "comment": "Comments welcome", "summary": "Let $\\ell$ and $n$ be positive integers with $\\ell$ prime. The modular curves\n$X_1(\\ell^n)$ and $X_0(\\ell^n)$ are algebraic curves over $\\mathbb{Q}$ whose\nnon-cuspidal points parameterize elliptic curves with a distinguished point of\norder $\\ell^n$ or a distinguished cyclic subgroup of order $\\ell^n$,\nrespectively. We wish to understand isolated points on these curves, which are\nroughly those not belonging to an infinite parameterized family of points\nhaving the same degree. Our first main result is that there are precisely 15\n$j$-invariants in $\\mathbb{Q}$ which arise as the image of an isolated point\n$x\\in X_1(\\ell^n)$ under the natural map $j:X_1(\\ell^n) \\rightarrow X_1(1)$.\nThis completes a prior partial classification of Ejder. We also identify the 19\nrational $j$-invariants which correspond to isolated points on $X_0(\\ell^n)$."}
{"id": "2506.19360", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.19360", "abs": "https://arxiv.org/abs/2506.19360", "authors": ["Yunsung Chung", "Yunbei Zhang", "Nassir Marrouche", "Jihun Hamm"], "title": "SoK: Can Synthetic Images Replace Real Data? A Survey of Utility and Privacy of Synthetic Image Generation", "comment": "Accepted at the 34th USENIX Security Symposium (USENIX Security '25).\n  21 pages, plus a 6-page appendix", "summary": "Advances in generative models have transformed the field of synthetic image\ngeneration for privacy-preserving data synthesis (PPDS). However, the field\nlacks a comprehensive survey and comparison of synthetic image generation\nmethods across diverse settings. In particular, when we generate synthetic\nimages for the purpose of training a classifier, there is a pipeline of\ngeneration-sampling-classification which takes private training as input and\noutputs the final classifier of interest. In this survey, we systematically\ncategorize existing image synthesis methods, privacy attacks, and mitigations\nalong this generation-sampling-classification pipeline. To empirically compare\ndiverse synthesis approaches, we provide a benchmark with representative\ngenerative methods and use model-agnostic membership inference attacks (MIAs)\nas a measure of privacy risk. Through this study, we seek to answer critical\nquestions in PPDS: Can synthetic data effectively replace real data? Which\nrelease strategy balances utility and privacy? Do mitigations improve the\nutility-privacy tradeoff? Which generative models perform best across different\nscenarios? With a systematic evaluation of diverse methods, our study provides\nactionable insights into the utility-privacy tradeoffs of synthetic data\ngeneration methods and guides the decision on optimal data releasing strategies\nfor real-world applications."}
{"id": "2506.19545", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.19545", "abs": "https://arxiv.org/abs/2506.19545", "authors": ["Hong-lu Li", "Xin He", "Yi-bin Xiao"], "title": "Fast convergence of a primal-dual dynamical system with implicit Hessian damping and Tikhonov regularization", "comment": "29 pages, 9 figures", "summary": "This paper proposes two primal-dual dynamical systems for solving linear\nequality constrained convex optimization problems: one with implicit Hessian\ndamping only, and the other further incorporating Tikhonov regularization. We\nanalyze the fast convergence properties of both dynamical systems and show that\nthey achieve the same convergence rates. To the best of our knowledge, this\nwork provides the first theoretical analysis establishing a convergence rate\n$o(\\frac{1}{t^2})$ for the primal-dual gap and a convergence rate\n$o(\\frac{1}{t})$ for the velocity $\\dot{x}(t)$, without imposing additional\nassumptions on the objective function beyond convexity and L-smoothness.\nMoreover, we show that the trajectory generated by the dynamical system with\nTikhonov regularization converges strongly to the minimum-norm solution of the\nunderlying problem. Finally, numerical experiments are conducted to validate\nthe theoretical findings. Interestingly, the trajectories exhibit smooth\nbehavior even when the objective function is only continuously differentiable."}
{"id": "2506.19185", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19185", "abs": "https://arxiv.org/abs/2506.19185", "authors": ["Janak Kapuriya", "Aman Singh", "Jainendra Shukla", "Rajiv Ratn Shah"], "title": "Spiritual-LLM : Gita Inspired Mental Health Therapy In the Era of LLMs", "comment": null, "summary": "Traditional mental health support systems often generate responses based\nsolely on the user's current emotion and situations, resulting in superficial\ninterventions that fail to address deeper emotional needs. This study\nintroduces a novel framework by integrating spiritual wisdom from the Bhagavad\nGita with advanced large language model GPT-4o to enhance emotional well-being.\nWe present the GITes (Gita Integrated Therapy for Emotional Support) dataset,\nwhich enhances the existing ExTES mental health dataset by including 10,729\nspiritually guided responses generated by GPT-4o and evaluated by domain\nexperts. We benchmark GITes against 12 state-of-the-art LLMs, including both\nmental health specific and general purpose models. To evaluate spiritual\nrelevance in generated responses beyond what conventional n-gram based metrics\ncapture, we propose a novel Spiritual Insight metric and automate assessment\nvia an LLM as jury framework using chain-of-thought prompting. Integrating\nspiritual guidance into AI driven support enhances both NLP and spiritual\nmetrics for the best performing LLM Phi3-Mini 3.2B Instruct, achieving\nimprovements of 122.71% in ROUGE, 126.53% in METEOR, 8.15% in BERT score,\n15.92% in Spiritual Insight, 18.61% in Sufficiency and 13.22% in Relevance\ncompared to its zero-shot counterpart. While these results reflect substantial\nimprovements across automated empathy and spirituality metrics, further\nvalidation in real world patient populations remains a necessary step. Our\nfindings indicate a strong potential for AI systems enriched with spiritual\nguidance to enhance user satisfaction and perceived support outcomes. The code\nand dataset will be publicly available to advance further research in this\nemerging area."}
{"id": "2506.19151", "categories": ["math.CO", "05C15"], "pdf": "https://arxiv.org/pdf/2506.19151", "abs": "https://arxiv.org/abs/2506.19151", "authors": ["Aaron Abrams", "Peter Johnson"], "title": "Yet Another Species of Forbidden-distances Chromatic Number", "comment": "This 2001 paper introduces a new type of chromatic number for point\n  sets", "summary": "This 2001 paper introduces a new type of chromatic number for point sets."}
{"id": "2506.19673", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.19673", "abs": "https://arxiv.org/abs/2506.19673", "authors": ["David Loeffler", "Arshay Sheth"], "title": "The Asai--Flach Euler system in $p$-adic families", "comment": "Comments welcome!", "summary": "We show that the Euler system for the Asai representation corresponding to a\nHilbert modular eigenform over a real quadratic field, constructed by Lei,\nLoeffler and Zerbes (2018), can be interpolated $p$-adically as the Hilbert\nmodular form varies in a Hida family. This work is used as an important input\nin recent work of Grossi, Loeffler and Zerbes (2025) on the proof of the\nBloch--Kato conjecture in analytic rank zero for the Asai representation."}
{"id": "2506.19368", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19368", "abs": "https://arxiv.org/abs/2506.19368", "authors": ["Xiang Liu", "Zhanpeng Guo", "Liangxi Liu", "Mengyao Zheng", "Yiming Qiu", "Linshan Jiang"], "title": "Yotta: A Large-Scale Trustless Data Trading Scheme for Blockchain System", "comment": "9 pages, 2 figures, Exploratory Paper", "summary": "Data trading is one of the key focuses of Web 3.0. However, all the current\nmethods that rely on blockchain-based smart contracts for data exchange cannot\nsupport large-scale data trading while ensuring data security, which falls\nshort of fulfilling the spirit of Web 3.0. Even worse, there is currently a\nlack of discussion on the essential properties that large-scale data trading\nshould satisfy. In this work, we are the first to formalize the property\nrequirements for enabling data trading in Web 3.0. Based on these requirements,\nwe are the first to propose Yotta, a complete batch data trading scheme for\nblockchain, which features a data trading design that leverages our innovative\ncryptographic workflow with IPFS and zk-SNARK. Our simulation results\ndemonstrate that Yotta outperforms baseline approaches up to 130 times and\nexhibits excellent scalability to satisfy all the properties."}
{"id": "2506.19722", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.19722", "abs": "https://arxiv.org/abs/2506.19722", "authors": ["Antonio Coppola", "Gerhard Hiermann", "Dario Paccagnan", "Michel Gendreau", "Maximilian Schiffer"], "title": "Integrated Balanced and Staggered Routing in Autonomous Mobility-on-Demand Systems", "comment": null, "summary": "Autonomous mobility-on-demand (AMoD) systems, centrally coordinated fleets of\nself-driving vehicles, offer a promising alternative to traditional\nride-hailing by improving traffic flow and reducing operating costs.\nCentralized control in AMoD systems enables two complementary routing\nstrategies: balanced routing, which distributes traffic across alternative\nroutes to ease congestion, and staggered routing, which delays departures to\nsmooth peak demand over time. In this work, we introduce a unified framework\nthat jointly optimizes both route choices and departure times to minimize\nsystem travel times. We formulate the problem as an optimization model and show\nthat our congestion model yields an unbiased estimate of travel times derived\nfrom a discretized version of Vickrey's bottleneck model. To solve large-scale\ninstances, we develop a custom metaheuristic based on a large neighborhood\nsearch framework. We assess our method through a case study on the Manhattan\nstreet network using real-world taxi data. In a setting with exclusively\ncentrally controlled AMoD vehicles, our approach reduces total traffic delay by\nup to 25 percent and mitigates network congestion by up to 35 percent compared\nto selfish routing. We also consider mixed-traffic settings with both AMoD and\nconventional vehicles, comparing a welfare-oriented operator that minimizes\ntotal system travel time with a profit-oriented one that optimizes only the\nfleet's travel time. Independent of the operator's objective, the analysis\nreveals a win-win outcome: across all control levels, both autonomous and\nnon-autonomous traffic benefit from the implementation of balancing and\nstaggering strategies."}
{"id": "2506.19191", "categories": ["cs.AI", "cs.CL", "cs.GT", "math.LO", "68T05, 68Q87, 03E20", "I.2.6; I.2.3; F.1.1"], "pdf": "https://arxiv.org/pdf/2506.19191", "abs": "https://arxiv.org/abs/2506.19191", "authors": ["Craig Steven Wright"], "title": "Bayesian Evolutionary Swarm Architecture: A Formal Epistemic System Grounded in Truth-Based Competition", "comment": "83 pages, 14 sections, 92 formal results, no prior conference\n  publication", "summary": "We introduce a mathematically rigorous framework for an artificial\nintelligence system composed of probabilistic agents evolving through\nstructured competition and belief revision. The architecture, grounded in\nBayesian inference, measure theory, and population dynamics, defines agent\nfitness as a function of alignment with a fixed external oracle representing\nground truth. Agents compete in a discrete-time environment, adjusting\nposterior beliefs through observed outcomes, with higher-rated agents\nreproducing and lower-rated agents undergoing extinction. Ratings are updated\nvia pairwise truth-aligned utility comparisons, and belief updates preserve\nmeasurable consistency and stochastic convergence. We introduce hash-based\ncryptographic identity commitments to ensure traceability, alongside causal\ninference operators using do-calculus. Formal theorems on convergence,\nrobustness, and evolutionary stability are provided. The system establishes\ntruth as an evolutionary attractor, demonstrating that verifiable knowledge\narises from adversarial epistemic pressure within a computable, self-regulating\nswarm."}
{"id": "2506.19221", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.19221", "abs": "https://arxiv.org/abs/2506.19221", "authors": ["Li-Quan Feng", "Qing-Hu Hou"], "title": "Finding congruences with the WZ method", "comment": null, "summary": "We utilize the Wilf-Zeilberger (WZ) method to establish congruences related\nto truncated Ramanujan-type series. By constructing hypergeometric terms $f(k,\na, b, \\ldots)$ with Gosper-summable differences and selecting appropriate\nparameters, we derive several congruences modulo $p$ and $p^2$ for primes $p >\n2$. For instance, we prove that for any prime $p > 2$, \\[ \\sum_{n=0}^{p-1}\n\\frac{10n+3}{2^{3n}}\\binom{3n}{n}\\binom{2n}{n}^2 \\equiv 0 \\pmod{p},\\] and \\[\n\\sum_{n=0}^{p-1} \\frac{(-1)^n(20n^2+8n+1)}{2^{12n}}\\binom{2n}{n}^5 \\equiv 0\n\\pmod{p^2}. \\] These results partially confirm conjectures by Sun and provide\nsome novel congruences."}
{"id": "2506.19812", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2506.19812", "abs": "https://arxiv.org/abs/2506.19812", "authors": ["Thang Pang Ern", "Malcolm Tan Jun Xi"], "title": "On the Asymptotic Density of a GCD-based Map", "comment": null, "summary": "We show that the symmetry of\n\\[f\\left(a,b\\right)=\\frac{\\operatorname{gcd}\\left(ab,a+b\\right)}{\\operatorname{gcd}\\left(a,b\\right)}\\]\nstems from an $\\operatorname{SL}_2\\left(\\mathbb{Z}\\right)$ action on primitive\npairs and that all solutions to $f\\left(a,b\\right)=n$ admit a uniform\nthree-parameter description -- recovering arithmetic-progression families via\nthe Chinese remainder theorem when $n$ is squarefree. It shows that the density\nof pairs with $f\\left(a,b\\right)=1$ tends to\n$\\prod_p\\left(1-p^{-2}(p+1)^{-1}\\right)\\approx0.88151$, and that its\nhigher-order analogue $f_r$ has a limiting density $6/\\pi^2$ for $r\\ge2$."}
{"id": "2506.19393", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19393", "abs": "https://arxiv.org/abs/2506.19393", "authors": ["Daniel Reijsbergen", "Eyasu Getahun Chekole", "Howard Halim", "Jianying Zhou"], "title": "ZK-SERIES: Privacy-Preserving Authentication using Temporal Biometric Data", "comment": null, "summary": "Biometric authentication relies on physiological or behavioral traits that\nare inherent to a user, making them difficult to lose, forge or forget.\nBiometric data with a temporal component enable the following authentication\nprotocol: recent readings of the underlying biometrics are encoded as time\nseries and compared to a set of base readings. If the distance between the new\nreadings and the base readings falls within an acceptable threshold, then the\nuser is successfully authenticated. Various methods exist for comparing time\nseries data, such as Dynamic Time Warping (DTW) and the Time Warp Edit Distance\n(TWED), each offering advantages and drawbacks depending on the context.\nMoreover, many of these techniques do not inherently preserve privacy, which is\na critical consideration in biometric authentication due to the complexity of\nresetting biometric credentials.\n  In this work, we propose ZK-SERIES to provide privacy and efficiency to a\nbroad spectrum of time series-based authentication protocols. ZK-SERIES uses\nthe same building blocks, i.e., zero-knowledge multiplication proofs and\nefficiently batched range proofs, to ensure consistency across all protocols.\nFurthermore, it is optimized for compatibility with low-capacity devices such\nas smartphones. To assess the effectiveness of our proposed technique, we\nprimarily focus on two case studies for biometric authentication: shake-based\nand blow-based authentication. To demonstrate ZK-SERIES's practical\napplicability even in older and less powerful smartphones, we conduct\nexperiments on a 5-year-old low-spec smartphone using real data for two case\nstudies alongside scalability assessments using artificial data. Our\nexperimental results indicate that the privacy-preserving authentication\nprotocol can be completed within 1.3 seconds on older devices."}
{"id": "2506.19723", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2506.19723", "abs": "https://arxiv.org/abs/2506.19723", "authors": ["Warren Hare", "Scholar Sun"], "title": "On the computation of the cosine measure in high dimensions", "comment": null, "summary": "In derivative-free optimization, the cosine measure is a value that often\narises in the convergence analysis of direct search methods. Given the\nincreasing interest in high-dimensional derivative-free optimization problems,\nit is valuable to compute the cosine measure in this setting; however, it has\nrecently been shown to be NP-hard. We propose a new formulation of the problem\nand heuristic to tackle this problem in higher dimensions and compare it with\nexisting algorithms in the literature. In addition, new results are presented\nto facilitate the construction of sets with specific cosine measures, allowing\nfor the creation of a test-set to benchmark the algorithms with."}
{"id": "2506.19224", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19224", "abs": "https://arxiv.org/abs/2506.19224", "authors": ["Shuyin Xia", "Guan Wang", "Gaojie Xu", "Sen Zhao", "Guoyin Wang"], "title": "GBGC: Efficient and Adaptive Graph Coarsening via Granular-ball Computing", "comment": null, "summary": "The objective of graph coarsening is to generate smaller, more manageable\ngraphs while preserving key information of the original graph. Previous work\nwere mainly based on the perspective of spectrum-preserving, using some\npredefined coarsening rules to make the eigenvalues of the Laplacian matrix of\nthe original graph and the coarsened graph match as much as possible. However,\nthey largely overlooked the fact that the original graph is composed of\nsubregions at different levels of granularity, where highly connected and\nsimilar nodes should be more inclined to be aggregated together as nodes in the\ncoarsened graph. By combining the multi-granularity characteristics of the\ngraph structure, we can generate coarsened graph at the optimal granularity. To\nthis end, inspired by the application of granular-ball computing in\nmulti-granularity, we propose a new multi-granularity, efficient, and adaptive\ncoarsening method via granular-ball (GBGC), which significantly improves the\ncoarsening results and efficiency. Specifically, GBGC introduces an adaptive\ngranular-ball graph refinement mechanism, which adaptively splits the original\ngraph from coarse to fine into granular-balls of different sizes and optimal\ngranularity, and constructs the coarsened graph using these granular-balls as\nsupernodes. In addition, compared with other state-of-the-art graph coarsening\nmethods, the processing speed of this method can be increased by tens to\nhundreds of times and has lower time complexity. The accuracy of GBGC is almost\nalways higher than that of the original graph due to the good robustness and\ngeneralization of the granular-ball computing, so it has the potential to\nbecome a standard graph data preprocessing method."}
{"id": "2506.19292", "categories": ["math.CO", "math.NT"], "pdf": "https://arxiv.org/pdf/2506.19292", "abs": "https://arxiv.org/abs/2506.19292", "authors": ["Zhongjie Li"], "title": "Inequalities related to the coefficients of the $j$-function", "comment": null, "summary": "In recent years, the log-concavity or log-convexity of combinatorial\nsequences and their root sequences, higher order Tur{\\'a}n inequalities, and\nLaguerre inequalities of order two have been widely studied. However, the\nresearch of the Fourier coefficient $c(n)$ of the $j$-function is limited to\nits asymptotic form. In this paper, we give the appropriate upper and lower\nbounds of $c(n)$ to establish the inequalities associated with it."}
{"id": "2506.19292", "categories": ["math.CO", "math.NT"], "pdf": "https://arxiv.org/pdf/2506.19292", "abs": "https://arxiv.org/abs/2506.19292", "authors": ["Zhongjie Li"], "title": "Inequalities related to the coefficients of the $j$-function", "comment": null, "summary": "In recent years, the log-concavity or log-convexity of combinatorial\nsequences and their root sequences, higher order Tur{\\'a}n inequalities, and\nLaguerre inequalities of order two have been widely studied. However, the\nresearch of the Fourier coefficient $c(n)$ of the $j$-function is limited to\nits asymptotic form. In this paper, we give the appropriate upper and lower\nbounds of $c(n)$ to establish the inequalities associated with it."}
{"id": "2506.19409", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19409", "abs": "https://arxiv.org/abs/2506.19409", "authors": ["Thomas Prévost", "Bruno Martin", "Olivier Alibart"], "title": "An ETSI GS QKD compliant TLS implementation", "comment": null, "summary": "A modification of the TLS protocol is presented, using our implementation of\nthe Quantum Key Distribution (QKD) standard ETSI GS QKD 014 v1.1.1. We rely on\nthe Rustls library for this. The TLS protocol is modified while maintaining\nbackward compatibility on the client and server side. We thus wish to\nparticipate in the effort to generalize the use of QKD on the Internet. We used\nour protocol for a video conference call encrypted by QKD. Finally, we analyze\nthe performance of our protocol, comparing the time needed to establish a\nhandshake to that of TLS 1.3."}
{"id": "2506.19740", "categories": ["math.OC", "quant-ph", "81Q93, 93B05"], "pdf": "https://arxiv.org/pdf/2506.19740", "abs": "https://arxiv.org/abs/2506.19740", "authors": ["Ruikang Liang", "Gong Cheng"], "title": "An approach to control design for two-level quantum ensemble systems", "comment": "Submitted to 64th IEEE Conference on Decision and Control", "summary": "Quantum ensemble systems arise in a variety of applications, including NMR\nspectroscopy and robust quantum control. While their theoretical properties\nhave been extensively studied, relatively little attention has been given to\nthe explicit construction of control inputs. In this paper, we address this gap\nby presenting a fully implementable control strategy for a one-parameter family\nof driftless two-level quantum systems. The proposed method is supported by\nrigorous analysis that guarantees accurate approximation of target\ndistributions on SU(2). Convergence properties are established analytically,\nand numerical simulations are provided to demonstrate the effectiveness of the\napproach."}
{"id": "2506.19235", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19235", "abs": "https://arxiv.org/abs/2506.19235", "authors": ["Yu Xie", "Xingkai Ren", "Ying Qi", "Yao Hu", "Lianlei Shan"], "title": "RecLLM-R1: A Two-Stage Training Paradigm with Reinforcement Learning and Chain-of-Thought v1", "comment": null, "summary": "Traditional recommendation systems often grapple with \"filter bubbles\",\nunderutilization of external knowledge, and a disconnect between model\noptimization and business policy iteration. To address these limitations, this\npaper introduces RecLLM-R1, a novel recommendation framework leveraging Large\nLanguage Models (LLMs) and drawing inspiration from the DeepSeek R1\nmethodology. The framework initiates by transforming user profiles, historical\ninteractions, and multi-faceted item attributes into LLM-interpretable natural\nlanguage prompts through a carefully engineered data construction process.\nSubsequently, a two-stage training paradigm is employed: the initial stage\ninvolves Supervised Fine-Tuning (SFT) to imbue the LLM with fundamental\nrecommendation capabilities. The subsequent stage utilizes Group Relative\nPolicy Optimization (GRPO), a reinforcement learning technique, augmented with\na Chain-of-Thought (CoT) mechanism. This stage guides the model through\nmulti-step reasoning and holistic decision-making via a flexibly defined reward\nfunction, aiming to concurrently optimize recommendation accuracy, diversity,\nand other bespoke business objectives. Empirical evaluations on a real-world\nuser behavior dataset from a large-scale social media platform demonstrate that\nRecLLM-R1 significantly surpasses existing baseline methods across a spectrum\nof evaluation metrics, including accuracy, diversity, and novelty. It\neffectively mitigates the filter bubble effect and presents a promising avenue\nfor the integrated optimization of recommendation models and policies under\nintricate business goals."}
{"id": "2506.19295", "categories": ["math.CO", "cs.CG", "math.MG"], "pdf": "https://arxiv.org/pdf/2506.19295", "abs": "https://arxiv.org/abs/2506.19295", "authors": ["Chao Yang", "Zhujun Zhang"], "title": "Undecidability of Translational Tiling of the Plane with Four Tiles", "comment": "14 pages, 13 figures", "summary": "The translational tiling problem, dated back to Wang's domino problem in the\n1960s, is one of the most representative undecidable problems in the field of\ndiscrete geometry and combinatorics. Ollinger initiated the study of the\nundecidability of translational tiling with a fixed number of tiles in 2009,\nand proved that translational tiling of the plane with a set of $11$\npolyominoes is undecidable. The number of polyominoes needed to obtain\nundecidability was reduced from $11$ to $7$ by Yang and Zhang, and then to $5$\nby Kim. We show that translational tiling of the plane with a set of $4$\n(disconnected) polyominoes is undecidable in this paper."}
{"id": "2506.19362", "categories": ["math.CO", "math.DS", "math.MG", "math.NT", "05B45, 68R15, 52C23, 37B52"], "pdf": "https://arxiv.org/pdf/2506.19362", "abs": "https://arxiv.org/abs/2506.19362", "authors": ["Shigeki Akiyama", "Tadahisa Hamada", "Katsuki Ito"], "title": "Sturmian lattices and Aperiodic tile sets", "comment": "Welcome comments and references", "summary": "We give aperiodic tile sets based on Sturmian words of quadratic slopes. The\nmethod works for any quadratic irrational slope and we can produce infinitely\nmany aperiodic tile sets whose underlying scaling constant is a unit of any\nreal quadratic field. There are two key ingredients in our construction. The\nfirst one is ``Sturmian lattices'', an interesting grid structure generated by\nSturmian words that emerged in an aperiodic monotile called Smith Turtle.The\nsecond is the bounded displacement equivalence of Delone sets, which plays a\ncentral role in this construction."}
{"id": "2506.19453", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19453", "abs": "https://arxiv.org/abs/2506.19453", "authors": ["Sajal Halder", "Muhammad Ejaz Ahmed", "Seyit Camtepe"], "title": "FuncVul: An Effective Function Level Vulnerability Detection Model using LLM and Code Chunk", "comment": "In The 30th European Symposium on Research in Computer Security\n  (ESORICS), 22 Sep - 26 Sep, 2025, Toulouse, France", "summary": "Software supply chain vulnerabilities arise when attackers exploit weaknesses\nby injecting vulnerable code into widely used packages or libraries within\nsoftware repositories. While most existing approaches focus on identifying\nvulnerable packages or libraries, they often overlook the specific functions\nresponsible for these vulnerabilities. Pinpointing vulnerable functions within\npackages or libraries is critical, as it can significantly reduce the risks\nassociated with using open-source software. Identifying vulnerable patches is\nchallenging because developers often submit code changes that are unrelated to\nvulnerability fixes. To address this issue, this paper introduces FuncVul, an\ninnovative code chunk-based model for function-level vulnerability detection in\nC/C++ and Python, designed to identify multiple vulnerabilities within a\nfunction by focusing on smaller, critical code segments. To assess the model's\neffectiveness, we construct six code and generic code chunk based datasets\nusing two approaches: (1) integrating patch information with large language\nmodels to label vulnerable samples and (2) leveraging large language models\nalone to detect vulnerabilities in function-level code. To design FuncVul\nvulnerability model, we utilise GraphCodeBERT fine tune model that captures\nboth the syntactic and semantic aspects of code. Experimental results show that\nFuncVul outperforms existing state-of-the-art models, achieving an average\naccuracy of 87-92% and an F1 score of 86-92% across all datasets. Furthermore,\nwe have demonstrated that our code-chunk-based FuncVul model improves 53.9%\naccuracy and 42.0% F1-score than the full function-based vulnerability\nprediction. The FuncVul code and datasets are publicly available on GitHub at\nhttps://github.com/sajalhalder/FuncVul."}
{"id": "2506.19821", "categories": ["math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.19821", "abs": "https://arxiv.org/abs/2506.19821", "authors": ["Víctor Blanco", "Alfredo Marín", "Justo Puerto"], "title": "Exact Matrix Seriation through Mathematical Optimization: Stress and Effectiveness-Based Models", "comment": "30 pages, 20 figures, 8 tables. Codes and datasets available at:\n  https://github.com/vblancoOR/seriation_mathopt", "summary": "Matrix seriation, the problem of permuting the rows and columns of a matrix\nto uncover latent structure, is a fundamental technique in data science,\nparticularly in the visualization and analysis of relational data. Applications\nspan clustering, anomaly detection, and beyond. In this work, we present a\nunified framework grounded in mathematical optimization to address matrix\nseriation from a rigorous, model-based perspective. Our approach leverages\ncombinatorial and mixed-integer optimization to represent seriation objectives\nand constraints with high fidelity, bridging the gap between traditional\nheuristic methods and exact solution techniques.\n  We introduce new mathematical programming models for neighborhood-based\nstress criteria, including nonlinear formulations and their linearized\ncounterparts. For structured settings such as Moore and von Neumann\nneighborhoods, we develop a novel Hamiltonian path-based reformulation that\nenables effective control over spatial arrangement and interpretability in the\nreordered matrix.\n  To assess the practical impact of our models, we carry out an extensive set\nof experiments on synthetic and real-world datasets, as well as on a newly\ncurated benchmark based on a coauthorship network from the matrix seriation\nliterature. Our results show that these optimization-based formulations not\nonly enhance solution quality and interpretability but also provide a versatile\nfoundation for extending matrix seriation to new domains in data science."}
{"id": "2506.19280", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19280", "abs": "https://arxiv.org/abs/2506.19280", "authors": ["Feiting Yang", "Antoine Moevus", "Steve Lévesque"], "title": "Emotion Detection on User Front-Facing App Interfaces for Enhanced Schedule Optimization: A Machine Learning Approach", "comment": null, "summary": "Human-Computer Interaction (HCI) has evolved significantly to incorporate\nemotion recognition capabilities, creating unprecedented opportunities for\nadaptive and personalized user experiences. This paper explores the integration\nof emotion detection into calendar applications, enabling user interfaces to\ndynamically respond to users' emotional states and stress levels, thereby\nenhancing both productivity and engagement. We present and evaluate two\ncomplementary approaches to emotion detection: a biometric-based method\nutilizing heart rate (HR) data extracted from electrocardiogram (ECG) signals\nprocessed through Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU)\nneural networks to predict the emotional dimensions of Valence, Arousal, and\nDominance; and a behavioral method analyzing computer activity through multiple\nmachine learning models to classify emotions based on fine-grained user\ninteractions such as mouse movements, clicks, and keystroke patterns. Our\ncomparative analysis, from real-world datasets, reveals that while both\napproaches demonstrate effectiveness, the computer activity-based method\ndelivers superior consistency and accuracy, particularly for mouse-related\ninteractions, which achieved approximately 90\\% accuracy. Furthermore, GRU\nnetworks outperformed LSTM models in the biometric approach, with Valence\nprediction reaching 84.38\\% accuracy."}
{"id": "2506.19322", "categories": ["math.CO", "Primary 52B20, Secondary 05A15, 68Q25"], "pdf": "https://arxiv.org/pdf/2506.19322", "abs": "https://arxiv.org/abs/2506.19322", "authors": ["Sihao Tao", "Guoce Xin", "Zihao Zhang"], "title": "Closed-Form Decomposition for Simplicial Cones and PDBarv Algorithm for Lattice Point Counting", "comment": null, "summary": "Counting lattice points within a rational polytope is a foundational problem\nwith applications across mathematics and computer science. A key approach is\nBarvinok's algorithm, which decomposes the lattice point generating function of\ncones to that of unimodular cones. However, standard implementations face\ndifficulties: the original primal method struggles with points on cone\nboundaries, while the alternative dual method can be slow for certain cone\ntypes.\n  This paper introduces two main contributions. First, We derive a closed-form\nexpression for these generating functions using arbitrary lattice point\ndecompositions, enabling more effective primal space decomposition. Second, by\ndecomposing both the cone and its dual cone starting from the side with a\nsmaller index, we develop a novel algorithm called \\textup{PDBarv}. This hybrid\napproach integrates the primal and dual Barvinok algorithms with a novel\nacceleration strategy, achieving an average computational performance\nimprovement of over 20\\% in dimension 5 and even better in higher dimensions."}
{"id": "2506.19480", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19480", "abs": "https://arxiv.org/abs/2506.19480", "authors": ["Pasquale De Rosa", "Simon Queyrut", "Yérom-David Bromberg", "Pascal Felber", "Valerio Schiavoni"], "title": "PhishingHook: Catching Phishing Ethereum Smart Contracts leveraging EVM Opcodes", "comment": null, "summary": "The Ethereum Virtual Machine (EVM) is a decentralized computing engine. It\nenables the Ethereum blockchain to execute smart contracts and decentralized\napplications (dApps). The increasing adoption of Ethereum sparked the rise of\nphishing activities. Phishing attacks often target users through deceptive\nmeans, e.g., fake websites, wallet scams, or malicious smart contracts, aiming\nto steal sensitive information or funds. A timely detection of phishing\nactivities in the EVM is therefore crucial to preserve the user trust and\nnetwork integrity. Some state-of-the art approaches to phishing detection in\nsmart contracts rely on the online analysis of transactions and their traces.\nHowever, replaying transactions often exposes sensitive user data and\ninteractions, with several security concerns. In this work, we present\nPhishingHook, a framework that applies machine learning techniques to detect\nphishing activities in smart contracts by directly analyzing the contract's\nbytecode and its constituent opcodes. We evaluate the efficacy of such\ntechniques in identifying malicious patterns, suspicious function calls, or\nanomalous behaviors within the contract's code itself before it is deployed or\ninteracted with. We experimentally compare 16 techniques, belonging to four\nmain categories (Histogram Similarity Classifiers, Vision Models, Language\nModels and Vulnerability Detection Models), using 7,000 real-world malware\nsmart contracts. Our results demonstrate the efficiency of PhishingHook in\nperforming phishing classification systems, with about 90% average accuracy\namong all the models. We support experimental reproducibility, and we release\nour code and datasets to the research community."}
{"id": "2506.19698", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2506.19698", "abs": "https://arxiv.org/abs/2506.19698", "authors": ["Zhuojun Xie", "Adam Abdin", "Yiping Fang"], "title": "Toward Decision-Oriented Prognostics: An Integrated Estimate-Optimize Framework for Predictive Maintenance", "comment": "22 pages, 5 figures, 4 tables", "summary": "Recent research increasingly integrates machine learning (ML) into predictive\nmaintenance (PdM) to reduce operational and maintenance costs in data-rich\noperational settings. However, uncertainty due to model misspecification\ncontinues to limit widespread industrial adoption. This paper proposes a PdM\nframework in which sensor-driven prognostics inform decision-making under\neconomic trade-offs within a finite decision space. We investigate two key\nquestions: (1) Does higher predictive accuracy necessarily lead to better\nmaintenance decisions? (2) If not, how can the impact of prediction errors on\ndownstream maintenance decisions be mitigated? We first demonstrate that in the\ntraditional estimate-then-optimize (ETO) framework, errors in probabilistic\nprediction can result in inconsistent and suboptimal maintenance decisions. To\naddress this, we propose an integrated estimate-optimize (IEO) framework that\njointly tunes predictive models while directly optimizing for maintenance\noutcomes. We establish theoretical finite-sample guarantees on decision\nconsistency under standard assumptions. Specifically, we develop a stochastic\nperturbation gradient descent algorithm suitable for small run-to-failure\ndatasets. Empirical evaluations on a turbofan maintenance case study show that\nthe IEO framework reduces average maintenance regret up to 22% compared to ETO.\nThis study provides a principled approach to managing prediction errors in\ndata-driven PdM. By aligning prognostic model training with maintenance\nobjectives, the IEO framework improves robustness under model misspecification\nand improves decision quality. The improvement is particularly pronounced when\nthe decision-making policy is misaligned with the decision-maker's target.\nThese findings support more reliable maintenance planning in uncertain\noperational environments."}
{"id": "2506.19290", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.19290", "abs": "https://arxiv.org/abs/2506.19290", "authors": ["Liang Zeng", "Yongcong Li", "Yuzhen Xiao", "Changshi Li", "Chris Yuhao Liu", "Rui Yan", "Tianwen Wei", "Jujie He", "Xuchen Song", "Yang Liu", "Yahui Zhou"], "title": "Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs", "comment": null, "summary": "Software engineering (SWE) has recently emerged as a crucial testbed for\nnext-generation LLM agents, demanding inherent capabilities in two critical\ndimensions: sustained iterative problem-solving (e.g., >50 interaction rounds)\nand long-context dependency resolution (e.g., >32k tokens). However, the data\ncuration process in SWE remains notoriously time-consuming, as it heavily\nrelies on manual annotation for code file filtering and the setup of dedicated\nruntime environments to execute and validate unit tests. Consequently, most\nexisting datasets are limited to only a few thousand GitHub-sourced instances.\nTo this end, we propose an incremental, automated data-curation pipeline that\nsystematically scales both the volume and diversity of SWE datasets. Our\ndataset comprises 10,169 real-world Python task instances from 2,531 distinct\nGitHub repositories, each accompanied by a task specified in natural language\nand a dedicated runtime-environment image for automated unit-test validation.\nWe have carefully curated over 8,000 successfully runtime-validated training\ntrajectories from our proposed SWE dataset. When fine-tuning the Skywork-SWE\nmodel on these trajectories, we uncover a striking data scaling phenomenon: the\ntrained model's performance for software engineering capabilities in LLMs\ncontinues to improve as the data size increases, showing no signs of\nsaturation. Notably, our Skywork-SWE model achieves 38.0% pass@1 accuracy on\nthe SWE-bench Verified benchmark without using verifiers or multiple rollouts,\nestablishing a new state-of-the-art (SOTA) among the Qwen2.5-Coder-32B-based\nLLMs built on the OpenHands agent framework. Furthermore, with the\nincorporation of test-time scaling techniques, the performance further improves\nto 47.0% accuracy, surpassing the previous SOTA results for sub-32B parameter\nmodels. We release the Skywork-SWE-32B model checkpoint to accelerate future\nresearch."}
{"id": "2506.19334", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.19334", "abs": "https://arxiv.org/abs/2506.19334", "authors": ["Gabe Cunningham", "Isabel Hubard"], "title": "Polytopality criteria for the mix of polytopes and maniplexes", "comment": null, "summary": "The mix of two maniplexes is the minimal maniplex that covers both. This\nconstruction has many important applications, such as finding the smallest\nregular cover of a maniplex. If one of the maniplexes is an abstract polytope,\na natural question to ask is whether the mix is also a polytope. We describe\nhere a general criterion for the polytopality of the mix which generalizes\nseveral previously-known polytopality criteria."}
{"id": "2506.19563", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19563", "abs": "https://arxiv.org/abs/2506.19563", "authors": ["Jinwen He", "Yiyang Lu", "Zijin Lin", "Kai Chen", "Yue Zhao"], "title": "PrivacyXray: Detecting Privacy Breaches in LLMs through Semantic Consistency and Probability Certainty", "comment": null, "summary": "Large Language Models (LLMs) are widely used in sensitive domains, including\nhealthcare, finance, and legal services, raising concerns about potential\nprivate information leaks during inference. Privacy extraction attacks, such as\njailbreaking, expose vulnerabilities in LLMs by crafting inputs that force the\nmodels to output sensitive information. However, these attacks cannot verify\nwhether the extracted private information is accurate, as no public datasets\nexist for cross-validation, leaving a critical gap in private information\ndetection during inference. To address this, we propose PrivacyXray, a novel\nframework detecting privacy breaches by analyzing LLM inner states. Our\nanalysis reveals that LLMs exhibit higher semantic coherence and probabilistic\ncertainty when generating correct private outputs. Based on this, PrivacyXray\ndetects privacy breaches using four metrics: intra-layer and inter-layer\nsemantic similarity, token-level and sentence-level probability distributions.\nPrivacyXray addresses critical challenges in private information detection by\novercoming the lack of open-source private datasets and eliminating reliance on\nexternal data for validation. It achieves this through the synthesis of\nrealistic private data and a detection mechanism based on the inner states of\nLLMs. Experiments show that PrivacyXray achieves consistent performance, with\nan average accuracy of 92.69% across five LLMs. Compared to state-of-the-art\nmethods, PrivacyXray achieves significant improvements, with an average\naccuracy increase of 20.06%, highlighting its stability and practical utility\nin real-world applications."}
{"id": "2506.19325", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19325", "abs": "https://arxiv.org/abs/2506.19325", "authors": ["Hyein Seo", "Taewook Hwang", "Yohan Lee", "sangkeun Jung"], "title": "FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring", "comment": "ACL 2025 (Short)", "summary": "In English education tutoring, teacher feedback is essential for guiding\nstudents. Recently, AI-based tutoring systems have emerged to assist teachers;\nhowever, these systems require high-quality and large-scale teacher feedback\ndata, which is both time-consuming and costly to generate manually. In this\nstudy, we propose FEAT, a cost-effective framework for generating teacher\nfeedback, and have constructed three complementary datasets: (1) DIRECT-Manual\n(DM), where both humans and large language models (LLMs) collaboratively\ngenerate high-quality teacher feedback, albeit at a higher cost; (2)\nDIRECT-Generated (DG), an LLM-only generated, cost-effective dataset with lower\nquality;, and (3) DIRECT-Augmented (DA), primarily based on DG with a small\nportion of DM added to enhance quality while maintaining cost-efficiency.\nExperimental results showed that incorporating a small portion of DM (5-10%)\ninto DG leads to superior performance compared to using 100% DM alone."}
{"id": "2506.19362", "categories": ["math.CO", "math.DS", "math.MG", "math.NT", "05B45, 68R15, 52C23, 37B52"], "pdf": "https://arxiv.org/pdf/2506.19362", "abs": "https://arxiv.org/abs/2506.19362", "authors": ["Shigeki Akiyama", "Tadahisa Hamada", "Katsuki Ito"], "title": "Sturmian lattices and Aperiodic tile sets", "comment": "Welcome comments and references", "summary": "We give aperiodic tile sets based on Sturmian words of quadratic slopes. The\nmethod works for any quadratic irrational slope and we can produce infinitely\nmany aperiodic tile sets whose underlying scaling constant is a unit of any\nreal quadratic field. There are two key ingredients in our construction. The\nfirst one is ``Sturmian lattices'', an interesting grid structure generated by\nSturmian words that emerged in an aperiodic monotile called Smith Turtle.The\nsecond is the bounded displacement equivalence of Delone sets, which plays a\ncentral role in this construction."}
{"id": "2506.19624", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19624", "abs": "https://arxiv.org/abs/2506.19624", "authors": ["Isaac David", "Liyi Zhou", "Dawn Song", "Arthur Gervais", "Kaihua Qin"], "title": "Decompiling Smart Contracts with a Large Language Model", "comment": null, "summary": "The widespread lack of broad source code verification on blockchain explorers\nsuch as Etherscan, where despite 78,047,845 smart contracts deployed on\nEthereum (as of May 26, 2025), a mere 767,520 (< 1%) are open source, presents\na severe impediment to blockchain security. This opacity necessitates the\nautomated semantic analysis of on-chain smart contract bytecode, a fundamental\nresearch challenge with direct implications for identifying vulnerabilities and\nunderstanding malicious behavior. Prevailing decompilers struggle to reverse\nbytecode in a readable manner, often yielding convoluted code that critically\nhampers vulnerability analysis and thwarts efforts to dissect contract\nfunctionalities for security auditing.\n  This paper addresses this challenge by introducing a pioneering decompilation\npipeline that, for the first time, successfully leverages Large Language Models\n(LLMs) to transform Ethereum Virtual Machine (EVM) bytecode into human-readable\nand semantically faithful Solidity code. Our novel methodology first employs\nrigorous static program analysis to convert bytecode into a structured\nthree-address code (TAC) representation. This intermediate representation then\nguides a Llama-3.2-3B model, specifically fine-tuned on a comprehensive dataset\nof 238,446 TAC-to-Solidity function pairs, to generate high-quality Solidity.\nThis approach uniquely recovers meaningful variable names, intricate control\nflow, and precise function signatures. Our extensive empirical evaluation\ndemonstrates a significant leap beyond traditional decompilers, achieving an\naverage semantic similarity of 0.82 with original source and markedly superior\nreadability. The practical viability and effectiveness of our research are\ndemonstrated through its implementation in a publicly accessible system,\navailable at https://evmdecompiler.com."}
{"id": "2506.19359", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19359", "abs": "https://arxiv.org/abs/2506.19359", "authors": ["Debosmita Bhaumik", "Julian Togelius", "Georgios N. Yannakakis", "Ahmed Khalifa"], "title": "Evolutionary Level Repair", "comment": null, "summary": "We address the problem of game level repair, which consists of taking a\ndesigned but non-functional game level and making it functional. This might\nconsist of ensuring the completeness of the level, reachability of objects, or\nother performance characteristics. The repair problem may also be constrained\nin that it can only make a small number of changes to the level. We investigate\nsearch-based solutions to the level repair problem, particularly using\nevolutionary and quality-diversity algorithms, with good results. This level\nrepair method is applied to levels generated using a machine learning-based\nprocedural content generation (PCGML) method that generates stylistically\nappropriate but frequently broken levels. This combination of PCGML for\ngeneration and search-based methods for repair shows great promise as a hybrid\nprocedural content generation (PCG) method."}
{"id": "2506.19443", "categories": ["math.CO", "math.QA", "52B11, 52B40, 05E10, 14M15, 13F60"], "pdf": "https://arxiv.org/pdf/2506.19443", "abs": "https://arxiv.org/abs/2506.19443", "authors": ["Jian-Rong Li", "Ayush Kumar Tewari"], "title": "From dual canonical bases to positroidal subdivisions", "comment": null, "summary": "The Grassmannian cluster algebra $\\mathbb{C}[\\text{Gr}(k, n)]$ admits a\ndistinguished basis known as the dual canonical basis, whose elements\ncorrespond to rectangular semi-standard Young tableaux with $k$ rows and with\nentries in $[n]$. We establish that each such tableau induces a positroidal\nsubdivision of the hypersimplex $\\Delta(k,n)$ via a map introduced by Speyer\nand Williams. For $\\text{Gr}(2,n)$, we prove that non-frozen prime tableaux\ncorrespond precisely to the coarsest positroidal subdivisions of $\\Delta(2,n)$.\nFurthermore, we present computational evidence extending these results to\n$k>2$. In the process, we formulate a conjectural formula for the number of\nsplit positroidal subdivisions of $\\Delta(k,n)$ for any $k \\ge 2$ and explore\nthe deep connections between the polyhedral combinatorics of $\\Delta(k,n)$ and\nthe dual canonical basis of $\\mathbb{C}[\\text{Gr}(k, n)]$."}
{"id": "2506.19676", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.19676", "abs": "https://arxiv.org/abs/2506.19676", "authors": ["Dezhang Kong", "Shi Lin", "Zhenhua Xu", "Zhebo Wang", "Minghao Li", "Yufeng Li", "Yilun Zhang", "Zeyang Sha", "Yuyuan Li", "Changting Lin", "Xun Wang", "Xuan Liu", "Muhammad Khurram Khan", "Ningyu Zhang", "Chaochao Chen", "Meng Han"], "title": "A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures", "comment": null, "summary": "In recent years, Large-Language-Model-driven AI agents have exhibited\nunprecedented intelligence, flexibility, and adaptability, and are rapidly\nchanging human production and lifestyle. Nowadays, agents are undergoing a new\nround of evolution. They no longer act as an isolated island like LLMs.\nInstead, they start to communicate with diverse external entities, such as\nother agents and tools, to collectively perform more complex tasks. Under this\ntrend, agent communication is regarded as a foundational pillar of the future\nAI ecosystem, and many organizations intensively begin to design related\ncommunication protocols (e.g., Anthropic's MCP and Google's A2A) within the\nrecent few months. However, this new field exposes significant security hazard,\nwhich can cause severe damage to real-world scenarios. To help researchers to\nquickly figure out this promising topic and benefit the future agent\ncommunication development, this paper presents a comprehensive survey of agent\ncommunication security. More precisely, we first present a clear definition of\nagent communication and categorize the entire lifecyle of agent communication\ninto three stages: user-agent interaction, agent-agent communication, and\nagent-environment communication. Next, for each communication phase, we dissect\nrelated protocols and analyze its security risks according to the communication\ncharacteristics. Then, we summarize and outlook on the possible defense\ncountermeasures for each risk. Finally, we discuss open issues and future\ndirections in this promising research field."}
{"id": "2506.19385", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19385", "abs": "https://arxiv.org/abs/2506.19385", "authors": ["Ziqi Zhu", "Tao Hu", "Honglong Zhang", "Dan Yang", "HanGeng Chen", "Mengran Zhang", "Xilun Chen"], "title": "Conversational Intent-Driven GraphRAG: Enhancing Multi-Turn Dialogue Systems through Adaptive Dual-Retrieval of Flow Patterns and Context Semantics", "comment": null, "summary": "We present CID-GraphRAG (Conversational Intent-Driven Graph Retrieval\nAugmented Generation), a novel framework that addresses the limitations of\nexisting dialogue systems in maintaining both contextual coherence and\ngoal-oriented progression in multi-turn customer service conversations. Unlike\ntraditional RAG systems that rely solely on semantic similarity (Conversation\nRAG) or standard knowledge graphs (GraphRAG), CID-GraphRAG constructs dynamic\nintent transition graphs from goal achieved historical dialogues and implements\na dual-retrieval mechanism that adaptively balances intent-based graph\ntraversal with semantic search. This approach enables the system to\nsimultaneously leverage both conversional intent flow patterns and contextual\nsemantics, significantly improving retrieval quality and response quality. In\nextensive experiments on real-world customer service dialogues, we employ both\nautomatic metrics and LLM-as-judge assessments, demonstrating that CID-GraphRAG\nsignificantly outperforms both semantic-based Conversation RAG and intent-based\nGraphRAG baselines across all evaluation criteria. Quantitatively, CID-GraphRAG\ndemonstrates substantial improvements over Conversation RAG across automatic\nmetrics, with relative gains of 11% in BLEU, 5% in ROUGE-L, 6% in METEOR, and\nmost notably, a 58% improvement in response quality according to LLM-as-judge\nevaluations. These results demonstrate that the integration of intent\ntransition structures with semantic retrieval creates a synergistic effect that\nneither approach achieves independently, establishing CID-GraphRAG as an\neffective framework for addressing the challenges of maintaining contextual\ncoherence and goal-oriented progression in knowledge-intensive multi-turn\ndialogues."}
{"id": "2506.19448", "categories": ["math.CO", "math.AT", "05C82, 55U10, 55U05"], "pdf": "https://arxiv.org/pdf/2506.19448", "abs": "https://arxiv.org/abs/2506.19448", "authors": ["Udit Raj", "Slobodan Maletić", "Sudeepto Bhattacharya"], "title": "Study of higher-order interactions in unweighted, undirected networks using persistent homology", "comment": null, "summary": "Persistent homology has been studied to better understand the structural\nproperties and topology features of weighted networks. It can reveal hidden\nlayers of information about the higher-order structures formed by non-pairwise\ninteractions in a network. Studying of higher-order interactions (HoIs) of a\nsystem provides a more comprehensive understanding of the complex system;\nmoreover, it is a more precise depiction of the system as many complex systems,\nsuch as ecological systems and biological systems, etc., demonstrate HoIs. In\nthis study, the weighted simplicial adjacency matrix has been constructed using\nthe concept of adjacency strength of simplices in a clique complex obtained\nfrom an unweighted, undirected network. This weighted simplicial adjacency\nmatrix is thus used to calculate the global measure, which is called\ngeneralised weighted betweenness centrality, which further helps us in\ncalculating the persistent homology on the given simplicial complex by\nconstructing a filtration on it. Moreover, a local measure called maximal\ngeneralised degree centrality has also been established for better\nunderstanding of the network topology of the studied simplicial complex. All\nthe generalizations given in this work can be reduced to the graph-theoretic\ncase. i.e., for a simplicial complex of dimension 1. Three different filtration\nschemes for constructing the sequence of simplicial complexes have been given\nwith the help of both global and local measures, and by using these measures,\nthe topology of higher-order structures of the studied network due to the\ninteractions of their vertices has been compared. Further, the illustration of\nestablished definitions has been given using a real-life network by calculating\nBetti numbers up to dimension two."}
{"id": "2506.19802", "categories": ["cs.CR", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.19802", "abs": "https://arxiv.org/abs/2506.19802", "authors": ["Xin Fan Guo", "Albert Merono Penuela", "Sergio Maffeis", "Fabio Pierazzi"], "title": "KnowML: Improving Generalization of ML-NIDS with Attack Knowledge Graphs", "comment": null, "summary": "Despite extensive research on Machine Learning-based Network Intrusion\nDetection Systems (ML-NIDS), their capability to detect diverse attack variants\nremains uncertain. Prior studies have largely relied on homogeneous datasets,\nwhich artificially inflate performance scores and offer a false sense of\nsecurity. Designing systems that can effectively detect a wide range of attack\nvariants remains a significant challenge. The progress of ML-NIDS continues to\ndepend heavily on human expertise, which can embed subjective judgments of\nsystem designers into the model, potentially hindering its ability to\ngeneralize across diverse attack types.\n  To address this gap, we propose KnowML, a framework for knowledge-guided\nmachine learning that integrates attack knowledge into ML-NIDS. KnowML\nsystematically explores the threat landscape by leveraging Large Language\nModels (LLMs) to perform automated analysis of attack implementations. It\nconstructs a unified Knowledge Graph (KG) of attack strategies, on which it\napplies symbolic reasoning to generate KG-Augmented Input, embedding domain\nknowledge directly into the design process of ML-NIDS.\n  We evaluate KnowML on 28 realistic attack variants, of which 10 are newly\ncollected for this study. Our findings reveal that baseline ML-NIDS models fail\nto detect several variants entirely, achieving F1 scores as low as 0 %. In\ncontrast, our knowledge-guided approach achieves up to 99 % F1 score while\nmaintaining a False Positive Rate below 0.1 %."}
{"id": "2506.19408", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.19408", "abs": "https://arxiv.org/abs/2506.19408", "authors": ["Alexandre Chapin", "Emmanuel Dellandrea", "Liming Chen"], "title": "Is an object-centric representation beneficial for robotic manipulation ?", "comment": null, "summary": "Object-centric representation (OCR) has recently become a subject of interest\nin the computer vision community for learning a structured representation of\nimages and videos. It has been several times presented as a potential way to\nimprove data-efficiency and generalization capabilities to learn an agent on\ndownstream tasks. However, most existing work only evaluates such models on\nscene decomposition, without any notion of reasoning over the learned\nrepresentation. Robotic manipulation tasks generally involve multi-object\nenvironments with potential inter-object interaction. We thus argue that they\nare a very interesting playground to really evaluate the potential of existing\nobject-centric work. To do so, we create several robotic manipulation tasks in\nsimulated environments involving multiple objects (several distractors, the\nrobot, etc.) and a high-level of randomization (object positions, colors,\nshapes, background, initial positions, etc.). We then evaluate one classical\nobject-centric method across several generalization scenarios and compare its\nresults against several state-of-the-art hollistic representations. Our results\nexhibit that existing methods are prone to failure in difficult scenarios\ninvolving complex scene structures, whereas object-centric methods help\novercome these challenges."}
{"id": "2506.19493", "categories": ["math.CO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2506.19493", "abs": "https://arxiv.org/abs/2506.19493", "authors": ["Philipp Böll", "Pamela Fleischmann", "Annika Huch", "Jana Kreiß", "Tim Löck", "Kajus Park", "Max Wiedenhöft"], "title": "Word-Representable Graphs and Locality of Words", "comment": null, "summary": "In this work, we investigate the relationship between $k$-repre\\-sentable\ngraphs and graphs representable by $k$-local words. In particular, we show that\nevery graph representable by a $k$-local word is $(k+1)$-representable. A\nprevious result about graphs represented by $1$-local words is revisited with\nnew insights. Moreover, we investigate both classes of graphs w.r.t. hereditary\nand in particular the speed as a measure. We prove that the latter ones belong\nto the factorial layer and that the graphs in this classes have bounded\nclique-width."}
{"id": "2506.19836", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19836", "abs": "https://arxiv.org/abs/2506.19836", "authors": ["Saeed Mahloujifar", "Chuan Guo", "G. Edward Suh", "Kamalika Chaudhuri"], "title": "Machine Learning with Privacy for Protected Attributes", "comment": null, "summary": "Differential privacy (DP) has become the standard for private data analysis.\nCertain machine learning applications only require privacy protection for\nspecific protected attributes. Using naive variants of differential privacy in\nsuch use cases can result in unnecessary degradation of utility. In this work,\nwe refine the definition of DP to create a more general and flexible framework\nthat we call feature differential privacy (FDP). Our definition is\nsimulation-based and allows for both addition/removal and replacement variants\nof privacy, and can handle arbitrary and adaptive separation of protected and\nnon-protected features. We prove the properties of FDP, such as adaptive\ncomposition, and demonstrate its implications for limiting attribute inference\nattacks. We also propose a modification of the standard DP-SGD algorithm that\nsatisfies FDP while leveraging desirable properties such as amplification via\nsub-sampling. We apply our framework to various machine learning tasks and show\nthat it can significantly improve the utility of DP-trained models when public\nfeatures are available. For example, we train diffusion models on the AFHQ\ndataset of animal faces and observe a drastic improvement in FID compared to\nDP, from 286.7 to 101.9 at $\\epsilon=8$, assuming that the blurred version of a\ntraining image is available as a public feature. Overall, our work provides a\nnew approach to private data analysis that can help reduce the utility cost of\nDP while still providing strong privacy guarantees."}
{"id": "2506.19410", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19410", "abs": "https://arxiv.org/abs/2506.19410", "authors": ["Anas Hattay", "Mayara Ayat", "Fred Ngole Mboula"], "title": "Unsupervised Dataset Dictionary Learning for domain shift robust clustering: application to sitting posture identification", "comment": null, "summary": "This paper introduces a novel approach, Unsupervised Dataset Dictionary\nLearning (U-DaDiL), for totally unsupervised robust clustering applied to\nsitting posture identification. Traditional methods often lack adaptability to\ndiverse datasets and suffer from domain shift issues. U-DaDiL addresses these\nchallenges by aligning distributions from different datasets using Wasserstein\nbarycenter based representation. Experimental evaluations on the Office31\ndataset demonstrate significant improvements in cluster alignment accuracy.\nThis work also presents a promising step for addressing domain shift and robust\nclustering for unsupervised sitting posture identification"}
{"id": "2506.19580", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.19580", "abs": "https://arxiv.org/abs/2506.19580", "authors": ["Ran Chen", "Baogang Xu", "Yian Xu"], "title": "The optimal binding function for (cap, even hole)-free graphs", "comment": null, "summary": "A {\\em hole} is an induced cycle of length at least 4, an {\\em even hole} is\na hole of even length, and a {\\em cap} is a graph obtained from a hole by\nadding an additional vertex which is adjacent exactly to two adjacent vertices\nof the hole. A graph $G$ obtained from a graph $H$ by blowing up all the\nvertices into cliques is said to be a clique blowup of $H$. Let $p, q$ be two\npositive integers with $p>2q$, let $F$ be a triangle-free graph, and let $G'$\nbe a clique blowup of $F$ with $\\omega(G')\\leq\\max\\{\\frac{2q(p-q-2)}{p-2q},\n2q\\}$. In this paper, we prove that for any clique blowup $G$ of $F$,\n$\\chi(G)\\leq\\lceil\\frac{p}{2q}\\omega(G)\\rceil$ if and only if\n$\\chi(G')\\leq\\lceil\\frac{p}{2q}\\omega(G')\\rceil$. As its consequences, we show\nthat every (cap, even hole)-free graph $G$ satisfies\n$\\chi(G)\\leq\\lceil\\frac{5}{4}\\omega(G)\\rceil$, which affirmatively answers a\nquestion of Cameron {\\em et al.} \\cite{CdHV2018}, we also show that every (cap,\neven hole, 5-hole)-free graph $G$ satisfies\n$\\chi(G)\\leq\\lceil\\frac{7}{6}\\omega(G)\\rceil$, and the bound is reachable."}
{"id": "2506.19420", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19420", "abs": "https://arxiv.org/abs/2506.19420", "authors": ["Yazhou Zhang", "Chunwang Zou", "Bo Wang", "Jing Qin"], "title": "Commander-GPT: Dividing and Routing for Multimodal Sarcasm Detection", "comment": null, "summary": "Multimodal sarcasm understanding is a high-order cognitive task. Although\nlarge language models (LLMs) have shown impressive performance on many\ndownstream NLP tasks, growing evidence suggests that they struggle with sarcasm\nunderstanding. In this paper, we propose Commander-GPT, a modular decision\nrouting framework inspired by military command theory. Rather than relying on a\nsingle LLM's capability, Commander-GPT orchestrates a team of specialized LLM\nagents where each agent will be selectively assigned to a focused sub-task such\nas context modeling, sentiment analysis, etc. Their outputs are then routed\nback to the commander, which integrates the information and performs the final\nsarcasm judgment. To coordinate these agents, we introduce three types of\ncentralized commanders: (1) a trained lightweight encoder-based commander\n(e.g., multi-modal BERT); (2) four small autoregressive language models,\nserving as moderately capable commanders (e.g., DeepSeek-VL); (3) two large\nLLM-based commander (Gemini Pro and GPT-4o) that performs task routing, output\naggregation, and sarcasm decision-making in a zero-shot fashion. We evaluate\nCommander-GPT on the MMSD and MMSD 2.0 benchmarks, comparing five prompting\nstrategies. Experimental results show that our framework achieves 4.4% and\n11.7% improvement in F1 score over state-of-the-art (SoTA) baselines on\naverage, demonstrating its effectiveness."}
{"id": "2506.19605", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.19605", "abs": "https://arxiv.org/abs/2506.19605", "authors": ["Ming Hsuan Kang", "Yu Hsuan Hsieh"], "title": "De Bruijn Tori Without Zeros: A Field-Theoretic Perspective", "comment": null, "summary": "We present an algebraic construction of trace-based De Bruijn tori over\nfinite fields, focusing on the nonzero variant that omits the all-zero pattern.\nThe construction arranges nonzero field elements on a toroidal grid using two\nmultiplicatively independent generators, with values obtained by applying a\nfixed linear map, typically the field trace.\n  We characterize sampling patterns as subsets whose associated field elements\nform an \\( \\mathbb{F}_p \\)-basis, and show that column structures correspond to\ncyclic shifts of De Bruijn sequences determined by irreducible polynomials over\nsubfields. Recursive update rules based on multiplicative translations enable\nefficient computation."}
{"id": "2506.19466", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19466", "abs": "https://arxiv.org/abs/2506.19466", "authors": ["Cheng Li", "Jiexiong Liu", "Yixuan Chen", "Qihang Zhou", "KunLun Meta"], "title": "KunLunBaizeRAG: Reinforcement Learning Driven Inference Performance Leap for Large Language Models", "comment": null, "summary": "This paper introduces KunLunBaizeRAG, a reinforcement learning-driven\nreasoning framework designed to enhance the reasoning capabilities of large\nlanguage models (LLMs) in complex multi-hop question-answering tasks. The\nframework addresses key limitations of traditional RAG, such as retrieval\ndrift, information redundancy, and strategy rigidity. Key innovations include\nthe RAG-driven Reasoning Alignment (RDRA) mechanism, the Search-Think Iterative\nEnhancement (STIE) mechanism, the Network-Local Intelligent Routing (NLR)\nmechanism, and a progressive hybrid training strategy. Experimental results\ndemonstrate significant improvements in exact match (EM) and LLM-judged score\n(LJ) across four benchmarks, highlighting the framework's robustness and\neffectiveness in complex reasoning scenarios."}
{"id": "2506.19638", "categories": ["math.CO", "math.AT", "52C35, 14N20"], "pdf": "https://arxiv.org/pdf/2506.19638", "abs": "https://arxiv.org/abs/2506.19638", "authors": ["Luca Moci", "Roberto Pagaria", "Maddalena Pismataro", "Alejandro Vargas"], "title": "Elliptic arrangements of complex multiplication type", "comment": "25 pages", "summary": "We provide a natural definition of an elliptic arrangement, extending the\nclassical framework to an elliptic curve E with complex multiplication. We\nanalyse the intersections of elements of the arrangement and their connected\ncomponents as End(E)-modules. Furthermore, we prove that the combinatorial data\nof elliptic arrangements define both an arithmetic matroid and a matroid over\nthe ring End(E). In this way, we obtain a class of arithmetic matroids that is\ndifferent from the class of arithmetic matroids realizable via toric\narrangements. Finally, we show that the Euler characteristic of the complement\nis an evaluation of the arithmetic Tutte polynomial."}
{"id": "2506.19500", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19500", "abs": "https://arxiv.org/abs/2506.19500", "authors": ["Yan Jiang", "Hao Zhou", "LiZhong GU", "Ai Han", "TianLong Li"], "title": "NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function Calling", "comment": null, "summary": "LLMs' reliance on static knowledge and fragile tool invocation severely\nhinders the orchestration of complex, heterogeneous toolchains, particularly at\nlarge scales. Existing methods typically use rigid single-path execution,\nresulting in poor error recovery and exponentially growing search spaces. We\nintroduce NaviAgent, a graph-navigated bilevel planning architecture for robust\nfunction calling, comprising a Multi-Path Decider and Graph-Encoded Navigator.\nAs an LLM-powered agent, the Multi-Path Decider defines a four-dimensional\ndecision space and continuously perceives environmental states, dynamically\nselecting the optimal action to fully cover all tool invocation scenarios. The\nGraph-Encoded Navigator constructs a Tool Dependency Heterogeneous Graph\n(TDHG), where node embeddings explicitly fuse API schema structure with\nhistorical invocation behavior. It also integrates a novel heuristic search\nstrategy that guides the Decider toward efficient and highly successful\ntoolchains, even for unseen tool combinations. Experiments show that NaviAgent\nconsistently achieves the highest task success rate (TSR) across all foundation\nmodels and task complexities, outperforming the average baselines (ReAct,\nToolLLM, {\\alpha}-UMI) by 13.5%, 16.4%, and 19.0% on Qwen2.5-14B, Qwen2.5-32B,\nand Deepseek-V3, respectively. Its execution steps are typically within one\nstep of the most efficient baseline, ensuring a strong balance between quality\nand efficiency. Notably, a fine-tuned Qwen2.5-14B model achieves a TSR of\n49.5%, surpassing the much larger 32B model (44.9%) under our architecture.\nIncorporating the Graph-Encoded Navigator further boosts TSR by an average of\n2.4 points, with gains up over 9 points on complex tasks for larger models\n(Deepseek-V3 and GPT-4o), highlighting its essential role in toolchain\norchestration."}
{"id": "2506.19667", "categories": ["math.CO", "math.DS", "05D10 (Primary) 11B13, 37A15 (Secondary)"], "pdf": "https://arxiv.org/pdf/2506.19667", "abs": "https://arxiv.org/abs/2506.19667", "authors": ["Ethan Ackelsberg"], "title": "Infinite polynomial patterns in large subsets of the rational numbers", "comment": "51 pages", "summary": "Inspired by a question of Kra, Moreira, Richter, and Robertson, we prove two\nnew results about infinite polynomial configurations in large subsets of the\nrational numbers. First, given a finite coloring of $\\mathbb{Q}$, we show that\nthere exists an infinite set $B = \\{b_n : n \\in \\mathbb{N}\\} \\subseteq\n\\mathbb{Q}$ such that $\\{b_i, b_i^2 + b_j : i < j\\}$ is monochromatic. Second,\nwe prove that every subset of positive density in the rational numbers contains\na translate of such an infinite configuration.\n  The proofs build upon methods developed in a series of papers by Kra,\nMoreira, Richter, and Robertson to translate from combinatorics into dynamics,\nwhere the core of the argument reduces to understanding the behavior of certain\npolynomial ergodic averages. The new dynamical tools required for this analysis\nare a Wiener--Wintner theorem for polynomially-twisted ergodic averages in\n$\\mathbb{Q}$-systems and a structure theorem for Abramov $\\mathbb{Q}$-systems.\n  The end of the paper includes a discussion of related problems in the\nintegers."}
{"id": "2506.19530", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19530", "abs": "https://arxiv.org/abs/2506.19530", "authors": ["Carlo Romeo", "Andrew D. Bagdanov"], "title": "NTRL: Encounter Generation via Reinforcement Learning for Dynamic Difficulty Adjustment in Dungeons and Dragons", "comment": null, "summary": "Balancing combat encounters in Dungeons & Dragons (D&D) is a complex task\nthat requires Dungeon Masters (DM) to manually assess party strength, enemy\ncomposition, and dynamic player interactions while avoiding interruption of the\nnarrative flow. In this paper, we propose Encounter Generation via\nReinforcement Learning (NTRL), a novel approach that automates Dynamic\nDifficulty Adjustment (DDA) in D&D via combat encounter design. By framing the\nproblem as a contextual bandit, NTRL generates encounters based on real-time\nparty members attributes. In comparison with classic DM heuristics, NTRL\niteratively optimizes encounters to extend combat longevity (+200%), increases\ndamage dealt to party members, reducing post-combat hit points (-16.67%), and\nraises the number of player deaths while maintaining low total party kills\n(TPK). The intensification of combat forces players to act wisely and engage in\ntactical maneuvers, even though the generated encounters guarantee high win\nrates (70%). Even in comparison with encounters designed by human Dungeon\nMasters, NTRL demonstrates superior performance by enhancing the strategic\ndepth of combat while increasing difficulty in a manner that preserves overall\ngame fairness."}
{"id": "2506.19700", "categories": ["math.CO", "cs.CG", "05C90, 68U05"], "pdf": "https://arxiv.org/pdf/2506.19700", "abs": "https://arxiv.org/abs/2506.19700", "authors": ["Lumi Christensen", "Thomas C. Hull", "Emma O'Neil", "Valentina Pappano", "Natalya Ter-Saakov", "Kacey Yang"], "title": "The Origami flip graph of the $2\\times n$ Miura-ori", "comment": null, "summary": "Given an origami crease pattern $C=(V,E)$, a straight-line planar graph\nembedded in a region of $\\mathbb{R}^2$, we assign each crease to be either a\nmountain crease (which bends convexly) or a valley crease (which bends\nconcavely), creating a mountain-valley (MV) assignment $\\mu:E\\to\\{-1,1\\}$. An\nMV assignment $\\mu$ is locally valid if the faces around each vertex in $C$ can\nbe folded flat under $\\mu$. In this paper, we investigate locally valid MV\nassignments of the Miura-ori, $M_{m,n}$, an $m\\times n$ parallelogram\ntessellation used in numerous engineering applications. The origami flip graph\n$OFG(C)$ of $C$ is a graph whose vertices are locally valid MV assignments of\n$C$, and two vertices are adjacent if they differ by a face flip, an operation\nthat swaps the MV-parity of every crease bordering a given face of $C$. We\nenumerate the number of vertices and edges in $OFG(M_{2,n})$ and prove several\nfacts about the degrees of vertices in $OFG(M_{2,n})$. By finding recurrence\nrelations, we show that the number of vertices of degree $d$ and $2n-a$ (for\n$0\\leq a$) are both described by polynomials of particular degrees. We then\nprove that the diameter of $OFG(M_{2,n})$ is $\\lceil \\frac{n^2}{2}\\rceil$ using\ntechniques from 3-coloring reconfiguration graphs."}
{"id": "2506.19573", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19573", "abs": "https://arxiv.org/abs/2506.19573", "authors": ["Sanne Wielinga", "Jesse Heyninck"], "title": "Interpretable Hybrid Machine Learning Models Using FOLD-R++ and Answer Set Programming", "comment": "accepted for publication as a Technical Communication at ICLP 2025", "summary": "Machine learning (ML) techniques play a pivotal role in high-stakes domains\nsuch as healthcare, where accurate predictions can greatly enhance\ndecision-making. However, most high-performing methods such as neural networks\nand ensemble methods are often opaque, limiting trust and broader adoption. In\nparallel, symbolic methods like Answer Set Programming (ASP) offer the\npossibility of interpretable logical rules but do not always match the\npredictive power of ML models. This paper proposes a hybrid approach that\nintegrates ASP-derived rules from the FOLD-R++ algorithm with black-box ML\nclassifiers to selectively correct uncertain predictions and provide\nhuman-readable explanations. Experiments on five medical datasets reveal\nstatistically significant performance gains in accuracy and F1 score. This\nstudy underscores the potential of combining symbolic reasoning with\nconventional ML to achieve high interpretability without sacrificing accuracy."}
{"id": "2506.19731", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2506.19731", "abs": "https://arxiv.org/abs/2506.19731", "authors": ["Dan Hefetz", "Michael Krivelevich"], "title": "The Hamilton cycle space of random graphs", "comment": null, "summary": "The cycle space of a graph $G$, denoted $C(G)$, is a vector space over\n${\\mathbb F}_2$, spanned by all incidence vectors of edge-sets of cycles of\n$G$. If $G$ has $n$ vertices, then $C_n(G)$ denotes the subspace of $C(G)$,\nspanned by the incidence vectors of Hamilton cycles of $G$. A classical result\nin the theory of random graphs asserts that for $G \\sim \\mathbb{G}(n,p)$,\nasymptotically almost surely the necessary condition $\\delta(G) \\geq 2$ is also\nsufficient to ensure Hamiltonicity. Resolving a problem of Christoph, Nenadov,\nand Petrova, we augment this result by proving that for $G \\sim\n\\mathbb{G}(n,p)$, with $n$ being odd, asymptotically almost surely the\ncondition $\\delta(G) \\geq 3$ (observed to be necessary by Heinig) is also\nsufficient for ensuring $C_n(G) = C(G)$. That is, not only does $G$ typically\nhave a Hamilton cycle, but its Hamilton cycles are typically rich enough to\nspan its cycle space."}
{"id": "2506.19592", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.19592", "abs": "https://arxiv.org/abs/2506.19592", "authors": ["Harisankar Babu", "Philipp Schillinger", "Tamim Asfour"], "title": "Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning", "comment": null, "summary": "We introduce TAPAS (Task-based Adaptation and Planning using AgentS), a\nmulti-agent framework that integrates Large Language Models (LLMs) with\nsymbolic planning to solve complex tasks without the need for manually defined\nenvironment models. TAPAS employs specialized LLM-based agents that\ncollaboratively generate and adapt domain models, initial states, and goal\nspecifications as needed using structured tool-calling mechanisms. Through this\ntool-based interaction, downstream agents can request modifications from\nupstream agents, enabling adaptation to novel attributes and constraints\nwithout manual domain redefinition. A ReAct (Reason+Act)-style execution agent,\ncoupled with natural language plan translation, bridges the gap between\ndynamically generated plans and real-world robot capabilities. TAPAS\ndemonstrates strong performance in benchmark planning domains and in the\nVirtualHome simulated real-world environment."}
{"id": "2506.19768", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2506.19768", "abs": "https://arxiv.org/abs/2506.19768", "authors": ["Valentin Dusollier", "Sébastien Bonte", "Gauvain Devillez", "Alain Hertz", "Hadrien Mélot", "David Schindl"], "title": "Complete polyhedral description of chemical graphs of maximum degree at most 3", "comment": "30 pages", "summary": "Chemical graphs are simple undirected connected graphs, where vertices\nrepresent atoms in a molecule and edges represent chemical bonds. A\ndegree-based topological index is a molecular descriptor used to study specific\nphysicochemical properties of molecules. Such an index is computed from the sum\nof the weights of the edges of a chemical graph, each edge having a weight\ndefined by a formula that depends only on the degrees of its endpoints. Given\nany degree-based topological index and given two integers $n$ and $m$, we are\ninterested in determining chemical graphs of order $n$ and size $m$ that\nmaximize or minimize the index. Focusing on chemical graphs with maximum degree\nat most 3, we show that this reduces to determining the extreme points of a\npolytope that contains at most 10 facets. We also show that the number of\nextreme points is at most 16, which means that for any given $n$ and $m$, there\nare very few different classes of extremal graphs, independently of the chosen\ndegree-based topological index."}
{"id": "2506.19608", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19608", "abs": "https://arxiv.org/abs/2506.19608", "authors": ["Zhiyuan Wang", "Bokui Chen"], "title": "ChordPrompt: Orchestrating Cross-Modal Prompt Synergy for Multi-Domain Incremental Learning in CLIP", "comment": "Accept by ECML-PKDD 2025", "summary": "Continual learning (CL) empowers pre-trained vision-language models to adapt\neffectively to novel or previously underrepresented data distributions without\ncomprehensive retraining, enhancing their adaptability and efficiency. While\nvision-language models like CLIP show great promise, they struggle to maintain\nperformance across domains in incremental learning scenarios. Existing prompt\nlearning methods face two main limitations: 1) they primarily focus on\nclass-incremental learning scenarios, lacking specific strategies for\nmulti-domain task incremental learning; 2) most current approaches employ\nsingle-modal prompts, neglecting the potential benefits of cross-modal\ninformation exchange. To address these challenges, we propose the \\ChordPrompt\nframework, which facilitates a harmonious interplay between visual and textual\nprompts. \\ChordPrompt introduces cross-modal prompts to leverage interactions\nbetween visual and textual information. Our approach also employs\ndomain-adaptive text prompts to select appropriate prompts for continual\nadaptation across multiple domains. Comprehensive experiments on multi-domain\nincremental learning benchmarks demonstrate that \\ChordPrompt outperforms\nstate-of-the-art methods in zero-shot generalization and downstream task\nperformance."}
{"id": "2506.19284", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.19284", "abs": "https://arxiv.org/abs/2506.19284", "authors": ["Mohammad Hadi Shekarriz", "Dhananjay Thiruvady", "Asef Nazari", "Wilfried Imrich"], "title": "Local Search Improvements for Soft Happy Colouring", "comment": "33 pages, 17 figures, 2 tables", "summary": "For $0\\leq \\rho\\leq 1$ and a coloured graph $G$, a vertex $v$ is $\\rho$-happy\nif at least $\\rho \\deg(v)$ of its neighbours have the same colour as $v$. Soft\nhappy colouring of a partially coloured graph $G$ is the problem of finding a\nvertex colouring $\\sigma$ that preserves the precolouring and has the maximum\nnumber of $\\rho$-happy vertices. It is already known that this problem is\nNP-hard and directly relates to the community structure of the graphs; under a\ncertain condition on the proportion of happiness $\\rho$ and for graphs with\ncommunity structures, the induced colouring by communities can make all the\nvertices $\\rho$-happy. We show that when $0\\leq \\rho_1<\\rho_2\\leq 1$, a\ncomplete $\\rho_2$-happy colouring has a higher accuracy of community detection\nthan a complete $\\rho_1$-happy colouring. Moreover, when $\\rho$ is greater than\na threshold, it is unlikely for an algorithm to find a complete $\\rho$-happy\ncolouring with colour classes of almost equal sizes. Three local search\nalgorithms for soft happy colouring are proposed, and their performances are\ncompared with one another and other known algorithms. Among them, the\nlinear-time local search is shown to be not only very fast, but also a reliable\nalgorithm that can dramatically improve the number of $\\rho$-happy vertices."}
{"id": "2506.19613", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19613", "abs": "https://arxiv.org/abs/2506.19613", "authors": ["Sha Zhang", "Suorong Yang", "Tong Xie", "Xiangyuan Xue", "Zixuan Hu", "Rui Li", "Wenxi Qu", "Zhenfei Yin", "Tianfan Fu", "Di Hu", "Andres M Bran", "Nian Ran", "Bram Hoex", "Wangmeng Zuo", "Philippe Schwaller", "Wanli Ouyang", "Lei Bai", "Yanyong Zhang", "Lingyu Duan", "Shixiang Tang", "Dongzhan Zhou"], "title": "Position: Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI", "comment": null, "summary": "Scientific discovery has long been constrained by human limitations in\nexpertise, physical capability, and sleep cycles. The recent rise of AI\nscientists and automated laboratories has accelerated both the cognitive and\noperational aspects of research. However, key limitations persist: AI systems\nare often confined to virtual environments, while automated laboratories lack\nthe flexibility and autonomy to adaptively test new hypotheses in the physical\nworld. Recent advances in embodied AI, such as generalist robot foundation\nmodels, diffusion-based action policies, fine-grained manipulation learning,\nand sim-to-real transfer, highlight the promise of integrating cognitive and\nembodied intelligence. This convergence opens the door to closed-loop systems\nthat support iterative, autonomous experimentation and the possibility of\nserendipitous discovery. In this position paper, we propose the paradigm of\nIntelligent Science Laboratories (ISLs): a multi-layered, closed-loop framework\nthat deeply integrates cognitive and embodied intelligence. ISLs unify\nfoundation models for scientific reasoning, agent-based workflow orchestration,\nand embodied agents for robust physical experimentation. We argue that such\nsystems are essential for overcoming the current limitations of scientific\ndiscovery and for realizing the full transformative potential of AI-driven\nscience."}
{"id": "2506.19529", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.19529", "abs": "https://arxiv.org/abs/2506.19529", "authors": ["Hande Tuncel Golpek", "Zeliha Kartal Yildiz", "Aysun Aytac"], "title": "Paired Disjunctive Domination Number of Middle Graphs", "comment": "12 pages, 0 figures", "summary": "The concept of domination in graphs plays a central role in understanding\nstructural properties and applications in network theory. In this study, we\nfocus on the paired disjunctive domination number in the context of middle\ngraphs, a transformation that captures both adjacency and incidence relations\nof the original graph. We begin by investigating this parameter for middle\ngraphs of several special graph classes, including path graphs, cycle graphs,\nwheel graphs, complete graphs, complete bipartite graphs, star graphs,\nfriendship graphs, and double star graphs. We then present general results by\nestablishing lower and upper bounds for the paired disjunctive domination\nnumber in middle graphs of arbitrary graphs, with particular emphasis on trees.\nAdditionally, we determine the exact value of the parameter for middle graphs\nobtained through the join operation. These findings contribute to the broader\nunderstanding of domination-type parameters in transformed graph structures and\noffer new insights into their combinatorial behavior."}
{"id": "2506.19635", "categories": ["cs.CR", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2506.19635", "abs": "https://arxiv.org/abs/2506.19635", "authors": ["Rocco De Nicola", "Marinella Petrocchi", "Manuel Pratelli"], "title": "On the efficacy of old features for the detection of new bots", "comment": "pre-print version", "summary": "For more than a decade now, academicians and online platform administrators\nhave been studying solutions to the problem of bot detection. Bots are computer\nalgorithms whose use is far from being benign: malicious bots are purposely\ncreated to distribute spam, sponsor public characters and, ultimately, induce a\nbias within the public opinion. To fight the bot invasion on our online\necosystem, several approaches have been implemented, mostly based on\n(supervised and unsupervised) classifiers, which adopt the most varied account\nfeatures, from the simplest to the most expensive ones to be extracted from the\nraw data obtainable through the Twitter public APIs. In this exploratory study,\nusing Twitter as a benchmark, we compare the performances of four state-of-art\nfeature sets in detecting novel bots: one of the output scores of the popular\nbot detector Botometer, which considers more than 1,000 features of an account\nto take a decision; two feature sets based on the account profile and timeline;\nand the information about the Twitter client from which the user tweets. The\nresults of our analysis, conducted on six recently released datasets of Twitter\naccounts, hint at the possible use of general-purpose classifiers and\ncheap-to-compute account features for the detection of evolved bots."}
{"id": "2506.19650", "categories": ["cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2506.19650", "abs": "https://arxiv.org/abs/2506.19650", "authors": ["Simon Ferreira", "Charles K. Assaad"], "title": "Identifying Macro Causal Effects in C-DMGs over DMGs", "comment": "Accepted to the UAI2025 workshop on Causal Abstractions and\n  Representations. arXiv admin note: substantial text overlap with\n  arXiv:2504.01551", "summary": "The do-calculus is a sound and complete tool for identifying causal effects\nin acyclic directed mixed graphs (ADMGs) induced by structural causal models\n(SCMs). However, in many real-world applications, especially in\nhigh-dimensional setting, constructing a fully specified ADMG is often\ninfeasible. This limitation has led to growing interest in partially specified\ncausal representations, particularly through cluster-directed mixed graphs\n(C-DMGs), which group variables into clusters and offer a more abstract yet\npractical view of causal dependencies. While these representations can include\ncycles, recent work has shown that the do-calculus remains sound and complete\nfor identifying macro-level causal effects in C-DMGs over ADMGs under the\nassumption that all clusters size are greater than 1. Nevertheless, real-world\nsystems often exhibit cyclic causal dynamics at the structural level. To\naccount for this, input-output structural causal models (ioSCMs) have been\nintroduced as a generalization of SCMs that allow for cycles. ioSCMs induce\nanother type of graph structure known as a directed mixed graph (DMG).\nAnalogous to the ADMG setting, one can define C-DMGs over DMGs as high-level\nrepresentations of causal relations among clusters of variables. In this paper,\nwe prove that, unlike in the ADMG setting, the do-calculus is unconditionally\nsound and complete for identifying macro causal effects in C-DMGs over DMGs.\nFurthermore, we show that the graphical criteria for non-identifiability of\nmacro causal effects previously established C-DMGs over ADMGs naturally extends\nto a subset of C-DMGs over DMGs."}
{"id": "2506.19686", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19686", "abs": "https://arxiv.org/abs/2506.19686", "authors": ["Ching Fang", "Kanaka Rajan"], "title": "From memories to maps: Mechanisms of in context reinforcement learning in transformers", "comment": null, "summary": "Humans and animals show remarkable learning efficiency, adapting to new\nenvironments with minimal experience. This capability is not well captured by\nstandard reinforcement learning algorithms that rely on incremental value\nupdates. Rapid adaptation likely depends on episodic memory -- the ability to\nretrieve specific past experiences to guide decisions in novel contexts.\nTransformers provide a useful setting for studying these questions because of\ntheir ability to learn rapidly in-context and because their key-value\narchitecture resembles episodic memory systems in the brain. We train a\ntransformer to in-context reinforcement learn in a distribution of planning\ntasks inspired by rodent behavior. We then characterize the learning algorithms\nthat emerge in the model. We first find that representation learning is\nsupported by in-context structure learning and cross-context alignment, where\nrepresentations are aligned across environments with different sensory stimuli.\nWe next demonstrate that the reinforcement learning strategies developed by the\nmodel are not interpretable as standard model-free or model-based planning.\nInstead, we show that in-context reinforcement learning is supported by caching\nintermediate computations within the model's memory tokens, which are then\naccessed at decision time. Overall, we find that memory may serve as a\ncomputational resource, storing both raw experience and cached computations to\nsupport flexible behavior. Furthermore, the representations developed in the\nmodel resemble computations associated with the hippocampal-entorhinal system\nin the brain, suggesting that our findings may be relevant for natural\ncognition. Taken together, our work offers a mechanistic hypothesis for the\nrapid adaptation that underlies in-context learning in artificial and natural\nsettings."}
{"id": "2506.19698", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2506.19698", "abs": "https://arxiv.org/abs/2506.19698", "authors": ["Zhuojun Xie", "Adam Abdin", "Yiping Fang"], "title": "Toward Decision-Oriented Prognostics: An Integrated Estimate-Optimize Framework for Predictive Maintenance", "comment": "22 pages, 5 figures, 4 tables", "summary": "Recent research increasingly integrates machine learning (ML) into predictive\nmaintenance (PdM) to reduce operational and maintenance costs in data-rich\noperational settings. However, uncertainty due to model misspecification\ncontinues to limit widespread industrial adoption. This paper proposes a PdM\nframework in which sensor-driven prognostics inform decision-making under\neconomic trade-offs within a finite decision space. We investigate two key\nquestions: (1) Does higher predictive accuracy necessarily lead to better\nmaintenance decisions? (2) If not, how can the impact of prediction errors on\ndownstream maintenance decisions be mitigated? We first demonstrate that in the\ntraditional estimate-then-optimize (ETO) framework, errors in probabilistic\nprediction can result in inconsistent and suboptimal maintenance decisions. To\naddress this, we propose an integrated estimate-optimize (IEO) framework that\njointly tunes predictive models while directly optimizing for maintenance\noutcomes. We establish theoretical finite-sample guarantees on decision\nconsistency under standard assumptions. Specifically, we develop a stochastic\nperturbation gradient descent algorithm suitable for small run-to-failure\ndatasets. Empirical evaluations on a turbofan maintenance case study show that\nthe IEO framework reduces average maintenance regret up to 22% compared to ETO.\nThis study provides a principled approach to managing prediction errors in\ndata-driven PdM. By aligning prognostic model training with maintenance\nobjectives, the IEO framework improves robustness under model misspecification\nand improves decision quality. The improvement is particularly pronounced when\nthe decision-making policy is misaligned with the decision-maker's target.\nThese findings support more reliable maintenance planning in uncertain\noperational environments."}
{"id": "2506.19702", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19702", "abs": "https://arxiv.org/abs/2506.19702", "authors": ["Lei Kang", "Xuanshuo Fu", "Oriol Ramos Terrades", "Javier Vazquez-Corral", "Ernest Valveny", "Dimosthenis Karatzas"], "title": "LLM-Driven Medical Document Analysis: Enhancing Trustworthy Pathology and Differential Diagnosis", "comment": "Accepted at ICDAR 2025", "summary": "Medical document analysis plays a crucial role in extracting essential\nclinical insights from unstructured healthcare records, supporting critical\ntasks such as differential diagnosis. Determining the most probable condition\namong overlapping symptoms requires precise evaluation and deep medical\nexpertise. While recent advancements in large language models (LLMs) have\nsignificantly enhanced performance in medical document analysis, privacy\nconcerns related to sensitive patient data limit the use of online LLMs\nservices in clinical settings. To address these challenges, we propose a\ntrustworthy medical document analysis platform that fine-tunes a LLaMA-v3 using\nlow-rank adaptation, specifically optimized for differential diagnosis tasks.\nOur approach utilizes DDXPlus, the largest benchmark dataset for differential\ndiagnosis, and demonstrates superior performance in pathology prediction and\nvariable-length differential diagnosis compared to existing methods. The\ndeveloped web-based platform allows users to submit their own unstructured\nmedical documents and receive accurate, explainable diagnostic results. By\nincorporating advanced explainability techniques, the system ensures\ntransparent and reliable predictions, fostering user trust and confidence.\nExtensive evaluations confirm that the proposed method surpasses current\nstate-of-the-art models in predictive accuracy while offering practical utility\nin clinical settings. This work addresses the urgent need for reliable,\nexplainable, and privacy-preserving artificial intelligence solutions,\nrepresenting a significant advancement in intelligent medical document analysis\nfor real-world healthcare applications. The code can be found at\n\\href{https://github.com/leitro/Differential-Diagnosis-LoRA}{https://github.com/leitro/Differential-Diagnosis-LoRA}."}
{"id": "2506.19724", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19724", "abs": "https://arxiv.org/abs/2506.19724", "authors": ["Gyeongwon James Kim", "Alex Wilf", "Louis-Philippe Morency", "Daniel Fried"], "title": "From Reproduction to Replication: Evaluating Research Agents with Progressive Code Masking", "comment": null, "summary": "Recent progress in autonomous code generation has fueled excitement around AI\nagents capable of accelerating scientific discovery by running experiments.\nHowever, there is currently no benchmark that evaluates whether such agents can\nimplement scientific ideas when given varied amounts of code as a starting\npoint, interpolating between reproduction (running code) and from-scratch\nreplication (fully re-implementing and running code). We introduce\nAutoExperiment, a benchmark that evaluates AI agents' ability to implement and\nrun machine learning experiments based on natural language descriptions in\nresearch papers. In each task, agents are given a research paper, a codebase\nwith key functions masked out, and a command to run the experiment. The goal is\nto generate the missing code, execute the experiment in a sandboxed\nenvironment, and reproduce the results. AutoExperiment scales in difficulty by\nvarying the number of missing functions $n$, ranging from partial reproduction\nto full replication. We evaluate state-of-the-art agents and find that\nperformance degrades rapidly as $n$ increases. Agents that can dynamically\ninteract with the environment (e.g. to debug their code) can outperform agents\nin fixed \"agentless\" harnesses, and there exists a significant gap between\nsingle-shot and multi-trial success rates (Pass@1 vs. Pass@5), motivating\nverifier approaches to our benchmark. Our findings highlight critical\nchallenges in long-horizon code generation, context retrieval, and autonomous\nexperiment execution, establishing AutoExperiment as a new benchmark for\nevaluating progress in AI-driven scientific experimentation. Our data and code\nare open-sourced at https://github.com/j1mk1m/AutoExperiment ."}
{"id": "2506.19773", "categories": ["cs.AI", "I.2.7; I.2.4"], "pdf": "https://arxiv.org/pdf/2506.19773", "abs": "https://arxiv.org/abs/2506.19773", "authors": ["Nandana Mihindukulasooriya", "Niharika S. D'Souza", "Faisal Chowdhury", "Horst Samulowitz"], "title": "Automatic Prompt Optimization for Knowledge Graph Construction: Insights from an Empirical Study", "comment": null, "summary": "A KG represents a network of entities and illustrates relationships between\nthem. KGs are used for various applications, including semantic search and\ndiscovery, reasoning, decision-making, natural language processing, machine\nlearning, and recommendation systems. Triple (subject-relation-object)\nextraction from text is the fundamental building block of KG construction and\nhas been widely studied, for example, in early benchmarks such as ACE 2002 to\nmore recent ones, such as WebNLG 2020, REBEL and SynthIE. While the use of LLMs\nis explored for KG construction, handcrafting reasonable task-specific prompts\nfor LLMs is a labour-intensive exercise and can be brittle due to subtle\nchanges in the LLM models employed. Recent work in NLP tasks (e.g. autonomy\ngeneration) uses automatic prompt optimization/engineering to address this\nchallenge by generating optimal or near-optimal task-specific prompts given\ninput-output examples.\n  This empirical study explores the application of automatic prompt\noptimization for the triple extraction task using experimental benchmarking. We\nevaluate different settings by changing (a) the prompting strategy, (b) the LLM\nbeing used for prompt optimization and task execution, (c) the number of\ncanonical relations in the schema (schema complexity), (d) the length and\ndiversity of input text, (e) the metric used to drive the prompt optimization,\nand (f) the dataset being used for training and testing. We evaluate three\ndifferent automatic prompt optimizers, namely, DSPy, APE, and TextGrad and use\ntwo different triple extraction datasets, SynthIE and REBEL. Through rigorous\nempirical evaluation, our main contribution highlights that automatic prompt\noptimization techniques can generate reasonable prompts similar to humans for\ntriple extraction. In turn, these optimized prompts achieve improved results,\nparticularly with increasing schema complexity and text size."}
{"id": "2506.19783", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19783", "abs": "https://arxiv.org/abs/2506.19783", "authors": ["Teng Wang", "Hailei Gong", "Changwang Zhang", "Jun Wang"], "title": "SAGE: Strategy-Adaptive Generation Engine for Query Rewriting", "comment": null, "summary": "Query rewriting is pivotal for enhancing dense retrieval, yet current methods\ndemand large-scale supervised data or suffer from inefficient reinforcement\nlearning (RL) exploration. In this work, we first establish that guiding Large\nLanguage Models (LLMs) with a concise set of expert-crafted strategies, such as\nsemantic expansion and entity disambiguation, substantially improves retrieval\neffectiveness on challenging benchmarks, including HotpotQA, FEVER, NFCorpus,\nand SciFact. Building on this insight, we introduce the Strategy-Adaptive\nGeneration Engine (SAGE), which operationalizes these strategies in an RL\nframework. SAGE introduces two novel reward shaping mechanisms-Strategic Credit\nShaping (SCS) and Contrastive Reward Shaping (CRS)-to deliver more informative\nlearning signals. This strategy-guided approach not only achieves new\nstate-of-the-art NDCG@10 results, but also uncovers a compelling emergent\nbehavior: the agent learns to select optimal strategies, reduces unnecessary\nexploration, and generates concise rewrites, lowering inference cost without\nsacrificing performance. Our findings demonstrate that strategy-guided RL,\nenhanced with nuanced reward shaping, offers a scalable, efficient, and more\ninterpretable paradigm for developing the next generation of robust information\nretrieval systems."}
{"id": "2506.19785", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19785", "abs": "https://arxiv.org/abs/2506.19785", "authors": ["Menglong Zhang", "Fuyuan Qian"], "title": "Learning Task Belief Similarity with Latent Dynamics for Meta-Reinforcement Learning", "comment": "ICLR2025 https://openreview.net/forum?id=5YbuOTUFQ4", "summary": "Meta-reinforcement learning requires utilizing prior task distribution\ninformation obtained during exploration to rapidly adapt to unknown tasks. The\nefficiency of an agent's exploration hinges on accurately identifying the\ncurrent task. Recent Bayes-Adaptive Deep RL approaches often rely on\nreconstructing the environment's reward signal, which is challenging in sparse\nreward settings, leading to suboptimal exploitation. Inspired by bisimulation\nmetrics, which robustly extracts behavioral similarity in continuous MDPs, we\npropose SimBelief-a novel meta-RL framework via measuring similarity of task\nbelief in Bayes-Adaptive MDP (BAMDP). SimBelief effectively extracts common\nfeatures of similar task distributions, enabling efficient task identification\nand exploration in sparse reward environments. We introduce latent task belief\nmetric to learn the common structure of similar tasks and incorporate it into\nthe specific task belief. By learning the latent dynamics across task\ndistributions, we connect shared latent task belief features with specific task\nfeatures, facilitating rapid task identification and adaptation. Our method\noutperforms state-of-the-art baselines on sparse reward MuJoCo and panda-gym\ntasks."}
{"id": "2506.19807", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.19807", "abs": "https://arxiv.org/abs/2506.19807", "authors": ["Baochang Ren", "Shuofei Qiao", "Wenhao Yu", "Huajun Chen", "Ningyu Zhang"], "title": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality", "comment": "Work in progress", "summary": "Large Language Models (LLMs), particularly slow-thinking models, often\nexhibit severe hallucination, outputting incorrect content due to an inability\nto accurately recognize knowledge boundaries during reasoning. While\nReinforcement Learning (RL) can enhance complex reasoning abilities, its\noutcome-oriented reward mechanism often lacks factual supervision over the\nthinking process, further exacerbating the hallucination problem. To address\nthe high hallucination in slow-thinking models, we propose Knowledge-enhanced\nRL, KnowRL. KnowRL guides models to perform fact-based slow thinking by\nintegrating a factuality reward, based on knowledge verification, into the RL\ntraining process, helping them recognize their knowledge boundaries. KnowRL\nguides models to perform fact-based slow thinking by integrating a factuality\nreward, based on knowledge verification, into the RL training process, helping\nthem recognize their knowledge boundaries. This targeted factual input during\nRL training enables the model to learn and internalize fact-based reasoning\nstrategies. By directly rewarding adherence to facts within the reasoning\nsteps, KnowRL fosters a more reliable thinking process. Experimental results on\nthree hallucination evaluation datasets and two reasoning evaluation datasets\ndemonstrate that KnowRL effectively mitigates hallucinations in slow-thinking\nmodels while maintaining their original strong reasoning capabilities. Our code\nis available at https://github.com/zjunlp/KnowRL."}
{"id": "2506.19825", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.19825", "abs": "https://arxiv.org/abs/2506.19825", "authors": ["Johannes Rückert", "Louise Bloch", "Christoph M. Friedrich"], "title": "Evaluating Compliance with Visualization Guidelines in Diagrams for Scientific Publications Using Large Vision Language Models", "comment": "Accepted at ICDAR 2025", "summary": "Diagrams are widely used to visualize data in publications. The research\nfield of data visualization deals with defining principles and guidelines for\nthe creation and use of these diagrams, which are often not known or adhered to\nby researchers, leading to misinformation caused by providing inaccurate or\nincomplete information.\n  In this work, large Vision Language Models (VLMs) are used to analyze\ndiagrams in order to identify potential problems in regards to selected data\nvisualization principles and guidelines. To determine the suitability of VLMs\nfor these tasks, five open source VLMs and five prompting strategies are\ncompared using a set of questions derived from selected data visualization\nguidelines.\n  The results show that the employed VLMs work well to accurately analyze\ndiagram types (F1-score 82.49 %), 3D effects (F1-score 98.55 %), axes labels\n(F1-score 76.74 %), lines (RMSE 1.16), colors (RMSE 1.60) and legends (F1-score\n96.64 %, RMSE 0.70), while they cannot reliably provide feedback about the\nimage quality (F1-score 0.74 %) and tick marks/labels (F1-score 46.13 %). Among\nthe employed VLMs, Qwen2.5VL performs best, and the summarizing prompting\nstrategy performs best for most of the experimental questions.\n  It is shown that VLMs can be used to automatically identify a number of\npotential issues in diagrams, such as missing axes labels, missing legends, and\nunnecessary 3D effects. The approach laid out in this work can be extended for\nfurther aspects of data visualization."}
{"id": "2506.19843", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19843", "abs": "https://arxiv.org/abs/2506.19843", "authors": ["Guo Li", "Zixiang Xu", "Wei Zhang", "Yikuan Hu", "Xinyu Yang", "Nikolay Aristov", "Mingjie Tang", "Elenna R Dugundji"], "title": "Temporal-IRL: Modeling Port Congestion and Berth Scheduling with Inverse Reinforcement Learning", "comment": "TRB2025", "summary": "Predicting port congestion is crucial for maintaining reliable global supply\nchains. Accurate forecasts enableimprovedshipment planning, reducedelaysand\ncosts, and optimizeinventoryanddistributionstrategies, thereby ensuring timely\ndeliveries and enhancing supply chain resilience. To achieve accurate\npredictions, analyzing vessel behavior and their stay times at specific port\nterminals is essential, focusing particularly on berth scheduling under various\nconditions. Crucially, the model must capture and learn the underlying\npriorities and patterns of berth scheduling. Berth scheduling and planning are\ninfluenced by a range of factors, including incoming vessel size, waiting\ntimes, and the status of vessels within the port terminal. By observing\nhistorical Automatic Identification System (AIS) positions of vessels, we\nreconstruct berth schedules, which are subsequently utilized to determine the\nreward function via Inverse Reinforcement Learning (IRL). For this purpose, we\nmodeled a specific terminal at the Port of New York/New Jersey and developed\nTemporal-IRL. This Temporal-IRL model learns berth scheduling to predict vessel\nsequencing at the terminal and estimate vessel port stay, encompassing both\nwaiting and berthing times, to forecast port congestion. Utilizing data from\nMaher Terminal spanning January 2015 to September 2023, we trained and tested\nthe model, achieving demonstrably excellent results."}
{"id": "2506.19846", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19846", "abs": "https://arxiv.org/abs/2506.19846", "authors": ["Ai Han", "Junxing Hu", "Pu Wei", "Zhiqian Zhang", "Yuhang Guo", "Jiawei Lu", "Zicheng Zhang"], "title": "JoyAgents-R1: Joint Evolution Dynamics for Versatile Multi-LLM Agents with Reinforcement Learning", "comment": "33 pages, 7 figures, under review", "summary": "Multi-agent reinforcement learning (MARL) has emerged as a prominent paradigm\nfor increasingly complex tasks. However, joint evolution across heterogeneous\nagents remains challenging due to cooperative inefficiency and training\ninstability. In this paper, we propose the joint evolution dynamics for MARL\ncalled JoyAgents-R1, which first applies Group Relative Policy Optimization\n(GRPO) to the joint training of heterogeneous multi-agents. By iteratively\nrefining agents' large language models (LLMs) and memories, the method achieves\nholistic equilibrium with optimal decision-making and memory capabilities.\nSpecifically, JoyAgents-R1 first implements node-wise Monte Carlo sampling on\nthe behavior of each agent across entire reasoning trajectories to enhance GRPO\nsampling efficiency while maintaining policy diversity. Then, our marginal\nbenefit-driven selection strategy identifies top-$K$ sampling groups with\nmaximal reward fluctuations, enabling targeted agent model updates that improve\ntraining stability and maximize joint benefits through cost-effective parameter\nadjustments. Meanwhile, JoyAgents-R1 introduces an adaptive memory evolution\nmechanism that repurposes GRPO rewards as cost-free supervisory signals to\neliminate repetitive reasoning and accelerate convergence. Experiments across\ngeneral and domain-specific scenarios demonstrate that JoyAgents-R1 achieves\nperformance comparable to that of larger LLMs while built on smaller\nopen-source models."}
{"id": "2506.17336", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17336", "abs": "https://arxiv.org/abs/2506.17336", "authors": ["Yubeen Bae", "Minchan Kim", "Jaejin Lee", "Sangbum Kim", "Jaehyung Kim", "Yejin Choi", "Niloofar Mireshghallah"], "title": "Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases", "comment": "29 pages", "summary": "Large language models (LLMs) are increasingly used as personal agents,\naccessing sensitive user data such as calendars, emails, and medical records.\nUsers currently face a trade-off: They can send private records, many of which\nare stored in remote databases, to powerful but untrusted LLM providers,\nincreasing their exposure risk. Alternatively, they can run less powerful\nmodels locally on trusted devices. We bridge this gap. Our Socratic\nChain-of-Thought Reasoning first sends a generic, non-private user query to a\npowerful, untrusted LLM, which generates a Chain-of-Thought (CoT) prompt and\ndetailed sub-queries without accessing user data. Next, we embed these\nsub-queries and perform encrypted sub-second semantic search using our\nHomomorphically Encrypted Vector Database across one million entries of a\nsingle user's private data. This represents a realistic scale of personal\ndocuments, emails, and records accumulated over years of digital activity.\nFinally, we feed the CoT prompt and the decrypted records to a local language\nmodel and generate the final response. On the LoCoMo long-context QA benchmark,\nour hybrid framework, combining GPT-4o with a local Llama-3.2-1B model,\noutperforms using GPT-4o alone by up to 7.1 percentage points. This\ndemonstrates a first step toward systems where tasks are decomposed and split\nbetween untrusted strong LLMs and weak local ones, preserving user privacy."}
{"id": "2506.19025", "categories": ["math.ST", "cs.AI", "cs.LG", "stat.ME", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2506.19025", "abs": "https://arxiv.org/abs/2506.19025", "authors": ["Sivaraman Balakrishnan", "Tudor Manole", "Larry Wasserman"], "title": "Statistical Inference for Optimal Transport Maps: Recent Advances and Perspectives", "comment": "36 pages, 1 figure", "summary": "In many applications of optimal transport (OT), the object of primary\ninterest is the optimal transport map. This map rearranges mass from one\nprobability distribution to another in the most efficient way possible by\nminimizing a specified cost. In this paper we review recent advances in\nestimating and developing limit theorems for the OT map, using samples from the\nunderlying distributions. We also review parallel lines of work that establish\nsimilar results for special cases and variants of the basic OT setup. We\nconclude with a discussion of key directions for future research with the goal\nof providing practitioners with reliable inferential tools."}
{"id": "2506.19109", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19109", "abs": "https://arxiv.org/abs/2506.19109", "authors": ["Valerii Gakh", "Hayretdin Bahsi"], "title": "Enhancing Security in LLM Applications: A Performance Evaluation of Early Detection Systems", "comment": "18 pages, 8 tables, 7 figures", "summary": "Prompt injection threatens novel applications that emerge from adapting LLMs\nfor various user tasks. The newly developed LLM-based software applications\nbecome more ubiquitous and diverse. However, the threat of prompt injection\nattacks undermines the security of these systems as the mitigation and defenses\nagainst them, proposed so far, are insufficient. We investigated the\ncapabilities of early prompt injection detection systems, focusing specifically\non the detection performance of techniques implemented in various open-source\nsolutions. These solutions are supposed to detect certain types of prompt\ninjection attacks, including the prompt leak. In prompt leakage attacks, an\nattacker maliciously manipulates the LLM into outputting its system\ninstructions, violating the system's confidentiality. Our study presents\nanalyzes of distinct prompt leakage detection techniques, and a comparative\nanalysis of several detection solutions, which implement those techniques. We\nidentify the strengths and weaknesses of these techniques and elaborate on\ntheir optimal configuration and usage in high-stake deployments. In one of the\nfirst studies on existing prompt leak detection solutions, we compared the\nperformances of LLM Guard, Vigil, and Rebuff. We concluded that the\nimplementations of canary word checks in Vigil and Rebuff were not effective at\ndetecting prompt leak attacks, and we proposed improvements for them. We also\nfound an evasion weakness in Rebuff's secondary model-based technique and\nproposed a mitigation. Then, the result of the comparison of LLM Guard, Vigil,\nand Rebuff at their peak performance revealed that Vigil is optimal for cases\nwhen minimal false positive rate is required, and Rebuff is the most optimal\nfor average needs."}
{"id": "2506.19563", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19563", "abs": "https://arxiv.org/abs/2506.19563", "authors": ["Jinwen He", "Yiyang Lu", "Zijin Lin", "Kai Chen", "Yue Zhao"], "title": "PrivacyXray: Detecting Privacy Breaches in LLMs through Semantic Consistency and Probability Certainty", "comment": null, "summary": "Large Language Models (LLMs) are widely used in sensitive domains, including\nhealthcare, finance, and legal services, raising concerns about potential\nprivate information leaks during inference. Privacy extraction attacks, such as\njailbreaking, expose vulnerabilities in LLMs by crafting inputs that force the\nmodels to output sensitive information. However, these attacks cannot verify\nwhether the extracted private information is accurate, as no public datasets\nexist for cross-validation, leaving a critical gap in private information\ndetection during inference. To address this, we propose PrivacyXray, a novel\nframework detecting privacy breaches by analyzing LLM inner states. Our\nanalysis reveals that LLMs exhibit higher semantic coherence and probabilistic\ncertainty when generating correct private outputs. Based on this, PrivacyXray\ndetects privacy breaches using four metrics: intra-layer and inter-layer\nsemantic similarity, token-level and sentence-level probability distributions.\nPrivacyXray addresses critical challenges in private information detection by\novercoming the lack of open-source private datasets and eliminating reliance on\nexternal data for validation. It achieves this through the synthesis of\nrealistic private data and a detection mechanism based on the inner states of\nLLMs. Experiments show that PrivacyXray achieves consistent performance, with\nan average accuracy of 92.69% across five LLMs. Compared to state-of-the-art\nmethods, PrivacyXray achieves significant improvements, with an average\naccuracy increase of 20.06%, highlighting its stability and practical utility\nin real-world applications."}
