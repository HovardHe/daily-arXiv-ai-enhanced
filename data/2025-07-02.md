<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 1]
- [math.OC](#math.OC) [Total: 11]
- [math.NT](#math.NT) [Total: 12]
- [math.LO](#math.LO) [Total: 1]
- [math.GM](#math.GM) [Total: 8]
- [math.CO](#math.CO) [Total: 16]
- [cs.CR](#cs.CR) [Total: 14]
- [cs.AI](#cs.AI) [Total: 19]
- [cs.DM](#cs.DM) [Total: 5]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Phase Transition in Nonparametric Minimax Rates for Covariate Shifts on Approximate Manifolds](https://arxiv.org/abs/2507.00889)
*Yuyao Wang,Nabarun Deb,Debarghya Mukherjee*

Main category: math.ST

TL;DR: 本文研究了协变量偏移下结构化数据的非参数回归问题，提出了利用源数据集规模和目标数据结构化特性的新方法，并建立了新的极小极大速率。


<details>
  <summary>Details</summary>
Motivation: 现实场景中，目标域协变量常位于源域支持集的低维流形附近（如个性化手写数字在大规模图像库中）。由于密度比可能不存在，标准迁移学习方法无法有效利用这种结构，因此需要开发新方法。

Method: 我们提出局部多项式回归估计器，在相变边界两侧均能达到最优速率，并构建了完全自适应程序以调整未知平滑度和内在维度。

Result: 发现由流形距离、样本量、函数平滑度及维度差异决定的相变现象，所提方法在流形近似假设下实现了H\"older类回归函数的最优估计速率。

Conclusion: 研究成果统一并拓展了协变量偏移、流形学习和自适应非参数推断领域的关键理论，为结构化数据迁移学习提供了新范式。

Abstract: We study nonparametric regression under covariate shift with structured data,
where a small amount of labeled target data is supplemented by a large labeled
source dataset. In many real-world settings, the covariates in the target
domain lie near a low-dimensional manifold within the support of the source,
e.g., personalized handwritten digits (target) within a large, high-dimensional
image repository (source). Since density ratios may not exist in these
settings, standard transfer learning techniques often fail to leverage such
structure. This necessitates the development of methods that exploit both the
size of the source dataset and the structured nature of the target.
  Motivated by this, we establish new minimax rates under covariate shift for
estimating a regression function in a general H\"older class, assuming the
target distribution lies near -- but not exactly on -- a smooth submanifold of
the source. General smoothness helps reduce the curse of dimensionality when
the target function is highly regular, while approximate manifolds capture
realistic, noisy data. We identify a phase transition in the minimax rate of
estimation governed by the distance to the manifold, source and target sample
sizes, function smoothness, and intrinsic versus ambient dimensions. We propose
a local polynomial regression estimator that achieves optimal rates on either
side of the phase transition boundary. Additionally, we construct a fully
adaptive procedure that adjusts to unknown smoothness and intrinsic dimension,
and attains nearly optimal rates. Our results unify and extend key threads in
covariate shift, manifold learning, and adaptive nonparametric inference.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [2] [Control of Power Grids With Switching Equilibria: $Ω$-Limit Sets and Input-to-State Stability](https://arxiv.org/abs/2507.00240)
*Mahmoud Abdelgalil,Vishal Shenoy,Guido Cavraro,Emiliano Dall'Anese,Jorge I. Poveda*

Main category: math.OC

TL;DR: 本文研究了一种由传统发电机和分布式能源资产共同提供频率控制的电力传输系统，分析了动态负载条件下的系统稳定性，并提出了相应的稳定性分析方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于电力系统中动态负载（如数据中心）和保护方案激活等导致的动态运行条件，这些条件可能引发系统模式切换，进而影响系统稳定性。

Method: 方法上，利用混合动态包含工具和$\Omega$-极限集概念，分析了切换系统的稳定性；针对负载变化速率，采用多Lyapunov函数水平集论证方法，建立了输入到状态稳定性。

Result: 结果表明，在切换频率和负载变化速率足够慢的条件下，系统具有半全局实际渐近稳定性；对于任意快速变化的负载，系统对负载变化速率具有输入到状态稳定性。

Conclusion: 结论指出，通过IEEE 39总线测试系统的数值仿真验证了理论结果，为动态负载条件下的电力系统稳定性分析提供了有效工具。

Abstract: This paper studies a power transmission system with both conventional
generators (CGs) and distributed energy assets (DEAs) providing frequency
control. We consider an operating condition with demand aggregating two dynamic
components: one that switches between different values on a finite set, and one
that varies smoothly over time. Such dynamic operating conditions may result
from protection scheme activations, external cyber-attacks, or due to the
integration of dynamic loads, such as data centers. Mathematically, the
dynamics of the resulting system are captured by a system that switches between
a finite number of vector fields -- or modes--, with each mode having a
distinct equilibrium point induced by the demand aggregation. To analyze the
stability properties of the resulting switching system, we leverage tools from
hybrid dynamic inclusions and the concept of $\Omega$-limit sets from sets.
Specifically, we characterize a compact set that is semi-globally practically
asymptotically stable under the assumption that the switching frequency and
load variation rate are sufficiently slow. For arbitrarily fast variations of
the load, we use a level-set argument with multiple Lyapunov functions to
establish input-to-state stability of a larger set and with respect to the rate
of change of the loads. The theoretical results are illustrated via numerical
simulations on the IEEE 39-bus test system.

</details>


### [3] [Explicit formulas for extremals in sub-Lorentzian and Finsler problems on 2- and 3-dimensional Lie groups](https://arxiv.org/abs/2507.00250)
*E. A. Ladeishchikov,L. V. Lokutsievskiy,N. V. Prilepin*

Main category: math.OC

TL;DR: 本文研究了具有次洛伦兹和芬斯勒结构的左不变问题中的测地线寻找问题，提出了新的凸三角函数并获得了极值曲线的显式公式。


<details>
  <summary>Details</summary>
Motivation: 探索在次洛伦兹和芬斯勒结构下的左不变问题中寻找测地线的方法，扩展经典双曲函数的应用范围。

Method: 开发新的凸三角函数$\cosh_\Omega$和$\sinh_\Omega$，用于无界凸集$\Omega\subset\mathbb{R}^2$的情况，并基于这些函数获得极值曲线的显式公式。

Result: 在次洛伦兹结构中，新开发的三角函数$\cosh_\Omega$和$\sinh_\Omega$被证明特别有效，成功推广了经典的$\cosh$和$\sinh$函数。

Conclusion: 通过引入新的凸三角函数，本文为具有特定几何结构的左不变问题中的测地线寻找提供了有效的解析工具。

Abstract: In this paper, we consider the problem of finding geodesics in a series of
left-invariant problems endowed with sub-Lorentzian and Finsler structures.
Explicit formulas for extremals are obtained in terms of convex trigonometric
functions. In the sub-Lorentzian setting, the new trigonometric functions
$\cosh_\Omega$ and $\sinh_\Omega$, developed here, prove especially useful;
they generalize the classical $\cosh$ and $\sinh$ to the case of an unbounded
convex set $\Omega\subset\mathbb{R}^2$.

</details>


### [4] [Affine-Invariant Global Non-Asymptotic Convergence Analysis of BFGS under Self-Concordance](https://arxiv.org/abs/2507.00361)
*Qiujiang Jin,Aryan Mokhtari*

Main category: math.OC

TL;DR: 本文为BFGS拟牛顿法建立了全局非渐近收敛保证，无需强凸性或梯度/Hessian的Lipschitz连续性，仅需目标函数严格凸且强自协调。证明了在弱Wolfe线搜索条件下，BFGS具有全局线性和超线性收敛性，且所有保证均具有仿射不变性。


<details>
  <summary>Details</summary>
Motivation: 传统BFGS收敛理论依赖强凸性或Lipschitz连续性等强假设，本文旨在放宽这些条件，基于强自协调性建立更通用的全局收敛框架，并揭示BFGS方法固有的仿射不变性质。

Method: 采用严格凸且强自协调的目标函数假设，结合满足弱Wolfe条件的线搜索步长策略，分析任意初始点与正定Hessian近似下BFGS的迭代行为。理论证明依赖仿射不变的分析框架。

Result: 首次证明BFGS在强自协调条件下具有全局线性/超线性收敛率，且收敛速度仅取决于初始误差与自协调常数。所有收敛保证均保持仿射不变性，与BFGS算法本质特性一致。

Conclusion: 该研究突破了传统BFGS收敛理论的限制条件，建立了基于自协调性的新型分析框架，其仿射不变性质为实际应用提供了更稳健的理论基础。

Abstract: In this paper, we establish global non-asymptotic convergence guarantees for
the BFGS quasi-Newton method without requiring strong convexity or the
Lipschitz continuity of the gradient or Hessian. Instead, we consider the
setting where the objective function is strictly convex and strongly
self-concordant. For an arbitrary initial point and any arbitrary
positive-definite initial Hessian approximation, we prove global linear and
superlinear convergence guarantees for BFGS when the step size is determined
using a line search scheme satisfying the weak Wolfe conditions. Moreover, all
our global guarantees are affine-invariant, with the convergence rates
depending solely on the initial error and the strongly self-concordant
constant. Our results extend the global non-asymptotic convergence theory of
BFGS beyond traditional assumptions and, for the first time, establish
affine-invariant convergence guarantees aligning with the inherent affine
invariance of the BFGS method.

</details>


### [5] [Convex Submodular Minimization with Indicator Variables](https://arxiv.org/abs/2507.00442)
*Andres Gomez,Shaoning Han*

Main category: math.OC

TL;DR: 该论文研究了一类带有指示变量的凸次模优化问题，提出将其转化为二元次模最小化问题，并开发了高效的参数化求解方法。


<details>
  <summary>Details</summary>
Motivation: 许多应用（如推断具有稀疏性或鲁棒性先验的马尔可夫随机场）可自然建模为此类问题，因此需要高效的求解方法。

Method: 通过问题重构将原问题转化为二元次模最小化问题，并在特定平滑条件下开发了计算极端基的参数化方法。

Result: 证明此类问题具有强多项式时间解，并通过数值实验验证了所提方法的效率。

Conclusion: 该研究为凸次模优化问题提供了通用求解框架，特别适用于具有结构先验的统计推断问题。

Abstract: We study a general class of convex submodular optimization problems with
indicator variables. Many applications such as the problem of inferring Markov
random fields (MRFs) with a sparsity or robustness prior can be naturally
modeled in this form. We show that these problems can be reduced to binary
submodular minimization problems, possibly after a suitable reformulation, and
thus are strongly polynomially solvable. %We also discuss the implication of
our results in the case of quadratic objectives. Furthermore, we develop a
parametric approach for computing the associated extreme bases under certain
smoothness conditions. This leads to a fast solution method, whose efficiency
is demonstrated through numerical experiments.

</details>


### [6] [Stochastic Graphon Games with Interventions](https://arxiv.org/abs/2507.00561)
*Eyal Neuman,Sturmius Tuschmann*

Main category: math.OC

TL;DR: 本文研究动态网络和图博弈中的目标干预问题，证明纳什均衡的存在唯一性及收敛性，并提出一种最优干预框架。


<details>
  <summary>Details</summary>
Motivation: 研究动态网络中异构玩家的交互行为，通过目标干预优化整体福利，为大规模网络中的决策提供理论支持。

Method: 结合固定点理论和谱分解方法，分析有限与无限玩家博弈的均衡收敛性，并设计动态干预策略。

Result: 证明了图博弈中纳什均衡的唯一性及收敛速率，推导了线性二次目标下的半显式最优干预解。

Conclusion: 谱方法为动态环境中的干预设计提供了关键见解，理论框架适用于大规模网络的实际应用。

Abstract: We consider a class of targeted intervention problems in dynamic network and
graphon games. First, we study a general dynamic network game in which players
interact over a graph and maximize their heterogeneous, concave goal
functionals, which depend on both their own actions and their interactions with
their neighbors. We establish the existence and uniqueness of the Nash
equilibrium in both the finite-player network game and the corresponding
infinite-player graphon game. We also prove the convergence of the Nash
equilibrium in the network game to the one in the graphon game, providing
explicit bounds on the convergence rate. Using this framework, we introduce a
central planner who implements a dynamic targeted intervention. Given a fixed
budget, the planner maximizes the average welfare at equilibrium by perturbing
the players' heterogeneous objectives, thereby influencing the resulting Nash
equilibrium. Using a novel fixed-point argument, we prove the existence and
uniqueness of an optimal intervention in the graphon setting, and show that it
achieves near-optimal performance in large finite networks, again with explicit
bounds on the convergence rate. As an application, we study the special case of
linear-quadratic objectives and exploit the spectral decomposition of the
graphon operator to derive semi-explicit solutions for the optimal
intervention. This spectral approach provides key insights into the design of
optimal interventions in dynamic environments.

</details>


### [7] [On the convergence rates of moment-SOS hierarchies approximation of truncated moment sequences](https://arxiv.org/abs/2507.00572)
*Hoang Anh Tran,Toh Kim-Chuan*

Main category: math.OC

TL;DR: 本文研究了moment-SOS层次结构在多项式优化问题中的收敛速率，通过估计Hausdorff距离，建立了收敛速率与Lojasiewicz指数L的关系，并给出了不同集合下的具体收敛速率。


<details>
  <summary>Details</summary>
Motivation: 研究moment-SOS层次结构在多项式优化中的收敛速率，以填补对复杂集合收敛速率理解的空白，并扩展对简单集合（如单位球、超立方体和标准单纯形）收敛速率的现有结果。

Method: 通过估计截断伪矩序列与Tchakaloff定理指定的截断矩序列之间的Hausdorff距离，结合Lojasiewicz指数L，分析了moment-SOS层次结构的收敛速率。

Result: 在紧致性假设下，建立了收敛速率为$O(1/r^L)$的一般结果。具体而言，多面体和满足约束限定条件的集合的收敛速率为$O(1/r)$，满足Polyak-Lojasiewicz条件或由局部强凸多项式定义的域的收敛速率为$O(1/\sqrt{r})$，球面上一般多项式的收敛速率为$O(1/r^2)$。

Conclusion: 研究结果表明，moment-SOS层次结构的收敛速率与定义域的几何性质密切相关，为多项式优化问题的求解提供了理论支持。

Abstract: The moment-SOS hierarchy is a widely applicable framework to address
polynomial optimization problems over basic semi-algebraic sets based on
positivity certificates of polynomial. Recent works show that the convergence
rate of this hierarchy over certain simple sets, namely, the unit ball,
hypercube, and standard simplex, is of the order $O(1/r^2)$, where r denotes
the level of the moment-SOS hierarchy. This paper aims to provide a
comprehensive understanding of the convergence rate of the moment-SOS hierarchy
by estimating the Hausdorff distance between the set of truncated pseudo-moment
sequences and the set of truncated moment sequences specified by Tchakaloff's
theorem. Our results provide a connection between the convergence rate of the
moment-SOS hierarchy and the Lojasiewicz exponent L of the domain under the
compactness assumption, where we establish the convergence rate of $O(1/r^L)$.
Consequently, we obtain the convergence rate of $O(1/r)$ for polytopes and sets
satisfying the constraint qualification condition, $O(1/\sqrt{r})$ for domains
that either satisfy the Polyak-Lojasiewicz condition or are defined by locally
strongly convex polynomials. We also obtain the convergence rate of $O(1/r^2)$
for general polynomials over a sphere.

</details>


### [8] [General Perturbation Resilient Dynamic String-Averaging for Inconsistent Problems with Superiorization](https://arxiv.org/abs/2507.00717)
*Kay Barshad,Yair Censor*

Main category: math.OC

TL;DR: 本文提出了一种广义动态字符串平均（GDSA）迭代方案，研究了其在算子无公共不动点（不一致情况）下的收敛性，结合动态字符串平均投影（DSAP）算法与强相干性概念，证明了方法的弱收敛与有界扰动鲁棒性，并探讨了其在优越化方法中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究动态字符串平均方法在不一致情况下的收敛性，扩展2013年DSAP算法（仅适用于一致情况）的应用范围，利用2019年提出的强相干性概念提供更通用的收敛条件。

Method: 结合动态字符串平均与强相干性算子序列，构建GDSA迭代方案，分析其在一般算子类下的收敛性；特别关注有界扰动鲁棒性，并探讨其与优越化方法的结合。

Result: 证明了GDSA方法在不一致情况下具有弱收敛性，其有界扰动鲁棒性在强弱收敛条件下均成立；通过强相干性简化了无限算子序列的收敛证明，并给出了优越化版本的行为结果。

Conclusion: GDSA方法为不一致问题提供了有效的求解框架，强相干性工具显著提升了收敛分析的普适性，与优越化方法的结合进一步扩展了其应用潜力。

Abstract: In this paper we introduce a General Dynamic String-Averaging (GDSA)
iterative scheme and investigate its convergence properties in the inconsistent
case, that is, when the input operators don't have a common fixed point. The
Dynamic String-Averaging Projection (DSAP) algorithm itself was introduced in
an 2013 paper, where its strong convergence and bounded perturbation resilience
were studied in the consistent case (that is, when the sets under consideration
had a nonempty intersection). Results involving combination of the DSAP method
with superiorization, were presented in 2015. The proof of the weak convergence
of our GDSA method is based on the notion of "strong coherence" of sequences of
operators that was introduced in 2019. This is an improvement of the property
of "coherence" of sequences of operators introduced in 2001 by Bauschke and
Combettes. Strong coherence provides a more convenient sufficient convergence
condition for methods that employ infinite sequences of operators and it turns
out to be a useful general tool when applied to proving the convergence of many
iterative methods. In this paper we combine the ideas of both dynamic
string-averaging and strong coherence, in order to analyze our GDSA method for
a general class of operators and its bounded perturbation resilience in the
inconsistent case with weak and strong convergence. We then discuss an
application of the GDSA method to the Superiorization Methodology, developing
results on the behavior of its superiorized version.

</details>


### [9] [Ranking Quantilized Mean-Field Games with an Application to Early-Stage Venture Investments](https://arxiv.org/abs/2507.00853)
*Rinel Foguen Tchuendom,Dena Firoozi,Michèle Breton*

Main category: math.OC

TL;DR: 该论文研究了一类基于分位数的均值场博弈模型，其中智能体的表现根据其终端状态相对于群体$\alpha$-分位值的排名来评估。提出了目标型和阈值型两种竞争形式，并分别给出了解析解和半显式解。最后将模型应用于早期风险投资场景，展示了数值实验结果。


<details>
  <summary>Details</summary>
Motivation: 研究分位数均值场博弈模型，旨在通过相对排名评估智能体表现，从而选择前$(1-\alpha)\%$的优秀个体。这种评估机制在资源分配（如风险投资）等场景具有实际应用价值。

Method: 提出两种竞争形式：1) 目标型要求智能体终端状态精确等于群体$\alpha$-分位值；2) 阈值型要求至少等于该分位值。前者通过前向-后向常微分方程获得解析解，后者采用半显式解并数值求解分位数均值场一致性条件。

Result: 目标型方案证明了$N$人博弈中渐进最优策略的$\epsilon$-纳什性质；阈值型方案通过数值求解实现。在风险投资案例中，目标型方案能很好近似阈值型方案的结果。

Conclusion: 分位数均值场博弈模型为排名竞争提供了有效框架，两种形式在风险投资场景中均适用。目标型方案具有解析优势，而数值实验验证其可作为阈值型方案的实用近似。

Abstract: Quantilized mean-field game models involve quantiles of the population's
distribution. We study a class of such games with a capacity for ranking games,
where the performance of each agent is evaluated based on its terminal state
relative to the population's $\alpha$-quantile value, $\alpha \in (0,1)$. This
evaluation criterion is designed to select the top $(1-\alpha)\%$ performing
agents. We provide two formulations for this competition: a target-based
formulation and a threshold-based formulation. In the former and latter
formulations, to satisfy the selection condition, each agent aims for its
terminal state to be \textit{exactly} equal and \textit{at least} equal to the
population's $\alpha$-quantile value, respectively.
  For the target-based formulation, we obtain an analytic solution and
demonstrate the $\epsilon$-Nash property for the asymptotic best-response
strategies in the $N$-player game. Specifically, the quantilized mean-field
consistency condition is expressed as a set of forward-backward ordinary
differential equations, characterizing the $\alpha$-quantile value at
equilibrium. For the threshold-based formulation, we obtain a semi-explicit
solution and numerically solve the resulting quantilized mean-field consistency
condition.
  Subsequently, we propose a new application in the context of early-stage
venture investments, where a venture capital firm financially supports a group
of start-up companies engaged in a competition over a finite time horizon, with
the goal of selecting a percentage of top-ranking ones to receive the next
round of funding at the end of the time horizon. We present the results and
interpretations of numerical experiments for both formulations discussed in
this context and show that the target-based formulation provides a very good
approximation for the threshold-based formulation.

</details>


### [10] [REAP-T: A MATLAB Toolbox for Implementing Robust-to-Early Termination Model Predictive Control](https://arxiv.org/abs/2507.00863)
*Mohsen Amiri,Mehdi Hosseinzadeh*

Main category: math.OC

TL;DR: 本文介绍了一个名为REAP-T的MATLAB工具箱，用于实现抗早期终止的模型预测控制（REAP），确保在计算资源有限时仍能提供次优可行解。


<details>
  <summary>Details</summary>
Motivation: 为解决模型预测控制（MPC）在计算资源受限时可能提前终止的问题，开发了REAP-T工具箱，以确保系统仍能获得可行的控制解。

Method: REAP-T工具箱利用MATLAB内置函数定义MPC问题，提供交互式图形界面用于参数调整和可视化，支持实时仿真，并包含实际案例指导用户使用。

Result: REAP-T工具箱是一个全面、用户友好且模块化的平台，能够帮助用户探索、分析和定制REAP的各个组件，适用于多种实际应用场景。

Conclusion: REAP-T工具箱通过其易用性和功能性，为研究人员和工程师提供了一种有效的方法，以应对计算资源受限时的MPC控制问题。

Abstract: This paper presents a MATLAB toolbox for implementing robust-to-early
termination model predictive control, abbreviated as REAP, which is designed to
ensure a sub-optimal yet feasible solution when MPC computations are
prematurely terminated due to limited computational resources. Named REAP-T,
this toolbox is a comprehensive, user-friendly, and modular platform that
enables users to explore, analyze, and customize various components of REAP for
their specific applications. Notable attributes of REAP-T are: (i) utilization
of built-in MATLAB functions for defining the MPC problem; (ii) an interactive
and intuitive graphical user interface for parameter tuning and visualization;
(iii) real-time simulation capabilities, allowing users to observe and
understand the real-time behavior of their systems; and (iv) inclusion of
real-world examples designed to guide users through its effective use.

</details>


### [11] [Swarm-based optimization with jumps: a kinetic BGK framework and convergence analysis](https://arxiv.org/abs/2507.00871)
*Giacomo Borghi,Hyesung Im,Lorenzo Pareschi*

Main category: math.OC

TL;DR: 本文提出了一种新型基于粒子的优化算法，通过随机跳跃更新速度，采用BGK型动力学建模，统一框架支持包括柯西分布在内的多种噪声分布，并在特定条件下简化为基于共识的优化（CBO）动力学。


<details>
  <summary>Details</summary>
Motivation: 元启发式算法在全局优化中表现卓越，尤其适用于非凸和非可微问题。受群体智能启发，基于粒子的优化方法因其在搜索空间中平衡探索与开发的能力而备受关注。

Method: 提出了一种新型粒子优化算法，通过随机跳跃更新速度，并采用BGK型动力学建模，构建了一个支持广义噪声分布（包括重尾分布如柯西分布）的统一框架。在特定参数缩放下，该模型可简化为CBO动力学。

Result: 在非退化高斯噪声和有界域条件下，证明了混沌传播和向极小值收敛的性质。数值实验验证了该方法的有效性，并揭示了其与CBO的联系。

Conclusion: 该算法为全局优化提供了一种有效的新方法，特别是在处理复杂噪声分布时表现出色，且与现有CBO方法具有理论关联。

Abstract: Metaheuristic algorithms are powerful tools for global optimization,
particularly for non-convex and non-differentiable problems where exact methods
are often impractical. Particle-based optimization methods, inspired by swarm
intelligence principles, have shown effectiveness due to their ability to
balance exploration and exploitation within the search space. In this work, we
introduce a novel particle-based optimization algorithm where velocities are
updated via random jumps, a strategy commonly used to enhance stochastic
exploration. We formalize this approach by describing the dynamics through a
kinetic modelling of BGK type, offering a unified framework that accommodates
general noise distributions, including heavy-tailed ones like Cauchy. Under
suitable parameter scaling, the model reduces to the Consensus-Based
Optimization (CBO) dynamics. For non-degenerate Gaussian noise in bounded
domains, we prove propagation of chaos and convergence towards minimizers.
Numerical results on benchmark problems validate the approach and highlight its
connection to CBO.

</details>


### [12] [Convergence Rate Analysis for Monotone Accelerated Proximal Gradient Method](https://arxiv.org/abs/2507.00939)
*Zepeng Wang,Juan Peypouquet*

Main category: math.OC

TL;DR: 本文分析了单调加速近端梯度法的收敛速度，证明了在目标函数的平滑部分强凸时，无需知道强凸参数即可实现线性收敛，这是目前该算法已知的最快收敛速度。


<details>
  <summary>Details</summary>
Motivation: 研究单调加速近端梯度法的收敛速度，旨在解决结构化凸复合优化问题，特别是在不知道强凸参数的情况下实现快速收敛。

Method: 采用单调加速近端梯度法，通过分析目标函数的平滑部分的强凸性质，建立线性收敛速率。

Result: 在目标函数的平滑部分强凸时，算法实现了线性收敛速率，且无需事先知道强凸参数，这是目前该算法的最快收敛速度。

Conclusion: 单调加速近端梯度法在解决结构化凸复合优化问题时具有高效的收敛性能，特别是在目标函数的平滑部分强凸时，能够实现线性收敛。

Abstract: We analyze the convergence rate of the monotone accelerated proximal gradient
method, which can be used to solve structured convex composite optimization
problems. A linear convergence rate is established when the smooth part of the
objective function is strongly convex, without knowledge of the strong
convexity parameter. This is the fastest convergence rate known for this
algorithm.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [13] [On a conjecture about prime-detecting quasimodular forms](https://arxiv.org/abs/2507.00147)
*Ben Kane,Krishnarjun Krishnamoorthy,Yuk-Kam Lau*

Main category: math.NT

TL;DR: 本文证明了Craig等人关于拟模形式检测素数的猜想，通过展示拟模尖形式的傅里叶系数存在无限多次符号变化。


<details>
  <summary>Details</summary>
Motivation: 受加权分拆在$n$为素数时消失的启发，Craig等人猜想拟模形式可检测素数，即第$n$个傅里叶系数消失当且仅当$n$为素数。

Method: 通过分析拟模尖形式的傅里叶系数性质，研究其符号变化规律。

Result: 证明了拟模尖形式的傅里叶系数存在无限多次符号变化，从而验证了Craig等人的猜想。

Conclusion: 该研究不仅解决了拟模形式检测素数的猜想，还揭示了拟模尖形式傅里叶系数的深层数论性质。

Abstract: Motivated by weighted partition of $n$ that vanish if and only if $n$ is a
prime, Craig, van Ittersum, and Ono conjecture a classification of quasimodular
forms which detect primes in the sense that the $n$-th Fourier coefficient
vanishes if and only if $n$ is a prime. In this paper, we prove this conjecture
by showing that Fourier coefficients of quasimodular cusp forms exhibit
infinitely many sign changes.

</details>


### [14] [Averaging quadratically twisted $L$-values and their derivatives](https://arxiv.org/abs/2507.00179)
*Tinghao Huang*

Main category: math.NT

TL;DR: 本文无条件建立了关于两个不同全纯尖点形式$f$和$g$的二次扭中心$L$值与其导数乘积的渐近公式。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在扩展先前关于二次扭$L$函数中心值及其导数乘积的工作，特别是对Li、Kumar等人及Zhou的成果进行推广。

Method: 通过分析二次扭中心$L$值及其导数的乘积，采用渐近方法建立公式，无需额外条件假设。

Result: 成功推导出两个不同全纯尖点形式$f$和$g$的二次扭中心$L$值与其导数乘积的渐近公式。

Conclusion: 该结果为二次扭$L$函数中心值及其导数的乘积提供了新的理论支持，扩展了相关领域的研究成果。

Abstract: In this paper, we unconditionally establish an asymptotic formula for the
product of the quadratically twisted central $L$-value associated to a
holomorphic cusp form $f$, and the quadratically twisted central $L$-derivative
to a distinct holomorphic cusp form $g$. This result may be viewed as an
extension of \cite{Li-MR4768632}, \cite{Kumar.etc-MR4765788} and
\cite{zhou2025momentderivativesquadratictwists}.

</details>


### [15] [Distribution of Farey fractions with $k$-free denominators](https://arxiv.org/abs/2507.00228)
*Bittu Chahal,Tapas Chatterjee,Sneha Chaubey*

Main category: math.NT

TL;DR: 研究了以$k$-自由分母定义的Farey分数在模$m$剩余类中的全局与局部分布，证明了其模一等分布性，建立了与广义黎曼假设（GRH）的等价形式，并给出了所有级别相关测度的显式公式。


<details>
  <summary>Details</summary>
Motivation: 探索Farey分数在特定约束（分母为$k$-自由数且满足模$m$同余）下的分布规律，以深化对数论中经典问题（如GRH）与序列分布关联的理解。

Method: 通过加权Weyl和与受限域中加权格点计数的估计，分析序列$\left(\mathscr{F}_{Q,k}^{(m)}\right)_{Q\ge 1}$的等分布性及相关测度。

Result: 证明了序列模一等分布性，建立了与GRH的等价表述；给出了局部分布中所有级别相关测度的显式公式，包括极限配对相关函数的存在性及其表达式。

Conclusion: 该研究不仅扩展了Farey分数分布的理论框架，还为GRH提供了新的等价形式，其方法（加权和与格点计数）在解析数论中具有潜在应用价值。

Abstract: We study the global and local distribution of Farey fractions with $k$-free
denominators in residue classes defined as
\[\mathscr{F}_{Q,k}^{(m)}:=\left\{\frac{a}{q}\ |\ 1\leq a\leq q\leq Q,\
\gcd(a,q)=1,\ q\ \text{is}\ k\text{-free}\ \&\ q\equiv b\pmod{m} \right\}.\] We
show that $\left(\mathscr{F}_{Q,k}^{(m)}\right)_{Q\ge 1}$ is equidistributed
modulo one, and prove analogues of the classical results of Franel, Landau, and
Niederreiter for $\left(\mathscr{F}_{Q,k}^{(m)}\right)_{Q\ge 1}$, particularly,
deriving an equivalent form of the generalized Riemann hypothesis (GRH) in
terms of the distribution of $\left(\mathscr{F}_{Q,k}^{(m)}\right)_{Q\ge 1}$.
Additionally, we study the local distribution of these sequences. We establish
formulas for all levels of correlation measure. Specifically, we show the
existence of the limiting pair correlation function and provide an explicit
expression for it. Our results are based upon the estimation of weighted Weyl
sums and weighted lattice point counting in restricted domains.

</details>


### [16] [On quantum ergodicity for higher dimensional cat maps modulo prime powers](https://arxiv.org/abs/2507.00325)
*Subham Bhakta,Igor E. Shparlinski*

Main category: math.NT

TL;DR: 本文利用线性递推序列模素数幂的指数和界，构造了量子遍历性离散模型中模数N的显式序列，改进了此前仅适用于几乎所有N的非构造性结果。


<details>
  <summary>Details</summary>
Motivation: 先前关于辛矩阵$A \in \mathrm{Sp}(2d,\mathbb{Z})$模整数$N\ge 1$生成的线性映射量子遍历性研究，仅能证明对几乎所有N成立但无法显式构造。本文旨在解决这一局限性。

Method: 基于I. E. Shparlinski (1978)关于线性递推序列模素数幂的指数和界，采用数论方法构造显式序列。

Result: 成功构造了具有幂次误差缩减的显式模数N序列，突破了原有非构造性结果的限制。

Conclusion: 该研究为量子遍历性离散模型提供了首个显式构造方案，通过数论工具实现了对模数选择的精确控制。

Abstract: A discrete model of quantum ergodicity of linear maps generated by symplectic
matrices $A \in \mathrm{Sp}(2d,\mathbb{Z})$ modulo an integer $N\ge 1$, has
been studied for $d=1$ and almost all $N$ by P. Kurlberg and Z. Rudnick (2001).
Their result has been strengthened by J. Bourgain (2005) and subsequently by A.
Ostafe, I. E. Shparlinski, and J. F. Voloch (2023). For arbitrary $d$ this has
been studied by P. Kurlberg, A. Ostafe, Z. Rudnick and I. E. Shparlinski
(2024). The corresponding equidistribution results, for certain eigenfunctions,
share the same feature: they apply to almost all moduli $N$ and are unable to
provide an explicit construction of such ``good'' values of $N$. Here, using a
bound of I. E. Shparlinski (1978) on exponential sums with linear recurrence
sequences modulo a power of a fixed prime, we construct such an explicit
sequence of $N$, with a power saving on the discrepancy.

</details>


### [17] [Polynomials associated to Lie algebras](https://arxiv.org/abs/2507.00326)
*Matías Bruna,Alex Capuñay,Eduardo Friedman*

Main category: math.NT

TL;DR: 本文为半单复李代数$\mathfrak{g}$定义了一系列多项式$P_{\ell,\mathfrak{g}}(x)$，这些多项式与$\mathfrak{g}$的同构类唯一对应，并通过Witten zeta函数的变体特殊值定义。


<details>
  <summary>Details</summary>
Motivation: 研究半单复李代数$\mathfrak{g}$的多项式表示，探索其与Witten zeta函数变体的联系，并与Komori等人2008年的工作进行比较。

Method: 通过定义Witten zeta函数的一种变体，并取其特殊值，构造与$\mathfrak{g}$同构类唯一对应的多项式序列$P_{\ell,\mathfrak{g}}(x)$。

Result: 成功定义了一组多项式$P_{\ell,\mathfrak{g}}(x)$，这些多项式在变量重新编号下唯一对应于$\mathfrak{g}$的同构类，且与Komori等人的定义不同。

Conclusion: 本文提出的多项式$P_{\ell,\mathfrak{g}}(x)$为半单复李代数的研究提供了新的工具，并丰富了Witten zeta函数变体的应用。

Abstract: We associate to a semisimple complex Lie algebra $\mathfrak{g}$ a sequence of
polynomials $P_{\ell,\mathfrak{g}}(x)\in\mathbb{Q}[x]$ in $r$ variables, where
$r$ is the rank of $\mathfrak{g}$ and $\ell=0,1,2,\ldots $. The polynomials
$P_{\ell,\mathfrak{g}}(x)$ are uniquely associated to the isomorphism class of
$\mathfrak{g}$, up to re-numbering the variables, and are defined as special
values of a variant of Witten's zeta function. Another set of polynomials
associated to $\mathfrak{g}$ were defined in 2008 by Komori, Matsumoto and
Tsumura using different special values of another variant of Witten's zeta
function.

</details>


### [18] [Applications of Faà di Bruno's formula to partition traces](https://arxiv.org/abs/2507.00404)
*Toshiki Matsusaka*

Main category: math.NT

TL;DR: 本文通过经典Fa\`{a} di Bruno公式重新审视了多个分拆理论生成函数，包括拉马努金遗失笔记本中的theta商、麦克马洪分拆函数以及分拆部分的倒数求和，为已知结果提供了统一解释并推导了新恒等式。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过Fa\`{a} di Bruno公式统一解释分拆理论中的生成函数，为已知结果提供新视角并探索新恒等式。

Method: 采用经典Fa\`{a} di Bruno公式作为分析工具，重新审视拉马努金theta商、麦克马洪分拆函数及分拆部分倒数求和等生成函数。

Result: 该方法不仅自然统一了已知结果，还系统性地推导出类似类型的新恒等式。

Conclusion: Fa\`{a} di Bruno公式为分拆理论生成函数研究提供了有效框架，既能重新诠释经典结论，又能拓展新的数学恒等式。

Abstract: We revisit several partition-theoretic generating functions, including the
theta quotients from Ramanujan's lost notebook, MacMahon's partition functions,
and reciprocal sums of parts in partitions, through the lens of the classical
Fa\`{a} di Bruno formula. This approach offers a unified and natural
reinterpretation of known results and provides a systematic framework for
deriving new identities of a similar type.

</details>


### [19] [Counting abelian number fields with restricted ramification type](https://arxiv.org/abs/2507.00448)
*Julie Tavernier*

Main category: math.NT

TL;DR: 本文研究了按任意高度函数排序的阿贝尔数域，其驯顺惰性生成元限制在给定子集内的情况，给出了主导常数的显式公式，并将结果解释为$BG$上的Batyrev-Manin猜想版本。


<details>
  <summary>Details</summary>
Motivation: 旨在理解具有特定驯顺惰性生成元限制的阿贝尔数域的分布规律，并将其与$BG$上的积分点及Batyrev-Manin猜想建立联系。

Method: 通过高度函数计数阿贝尔数域，分析驯顺惰性生成元的限制子集，并利用Galois群理论推导显式公式。

Result: 得到了主导常数的显式公式，证明了此类数域在无限多个局部条件下是等分布的，并将结果转化为$BG$上的积分点描述。

Conclusion: 该研究为阿贝尔数域的分布提供了新视角，将数论问题与几何对象$BG$相关联，扩展了Batyrev-Manin猜想的应用范围。

Abstract: We count abelian number fields ordered by arbitrary height function whose
generator of tame inertia is restricted to lie in a given subset of the Galois
group, and find an explicit formula for the leading constant. We interpret our
results as a version of the Batyrev-Manin conjecture on $BG$ and rephrase our
result on number fields with restricted ramification type in terms of integral
points on $BG$. We also prove that such number fields are equidistributed with
respect to suitable collections of infinitely many local conditions.

</details>


### [20] [On the Frobenius Problem for Some Generalized Fibonacci Subsequences -- II](https://arxiv.org/abs/2507.00495)
*Ryan Azim Shaikh,Amitabha Tripathi*

Main category: math.NT

TL;DR: 研究广义斐波那契数列子集的Frobenius数和亏格问题，探讨其不可表示整数的最大数与数量。


<details>
  <summary>Details</summary>
Motivation: 对于满足$\gcd(A)=1$的正整数集$A$，存在有限多个正整数无法表示为$A$的线性组合。研究广义斐波那契数列子集的Frobenius数和亏格，有助于理解这类集合的表示性质。

Method: 通过分析广义斐波那契数列$\{V_n\}$的递推关系，研究子集$A=\{V_n, V_{n+d}, V_{n+2d}, \ldots \}$在任意$n$和偶数$d$下的Frobenius数和亏格。

Result: 确定了广义斐波那契数列子集$A$的Frobenius数和亏格的计算方法，为这类集合的表示问题提供了理论支持。

Conclusion: 该研究为广义斐波那契数列子集的Frobenius数和亏格问题提供了解决方案，扩展了数论中关于线性组合表示的理论框架。

Abstract: For a set $A$ of positive integers with $\gcd(A)=1$, let $\langle A \rangle$
denote the set of all finite linear combinations of elements of $A$ over the
non-negative integers. Then it is well known that only finitely many positive
integers do not belong to $\langle A \rangle$. The Frobenius number and the
genus associated with the set $A$ is the largest number and the cardinality of
the set of integers non-representable by $A$. By a generalized Fibonacci
sequence $\{V_n\}_{n \ge 1}$ we mean any sequence of positive integers
satisfying the recurrence $V_n=V_{n-1}+V_{n-2}$ for $n \ge 3$. We study the
problem of determining the Frobenius number and genus for sets $A=\{V_n,
V_{n+d}, V_{n+2d}, \ldots \}$ for arbitrary $n$ and even $d$.

</details>


### [21] [Murmurations of Modular Forms and $p$-power Coefficients](https://arxiv.org/abs/2507.00738)
*Debanjana Kundu,Katharina Mueller*

Main category: math.NT

TL;DR: 将N. Zubrilina关于模形式murmuration的研究扩展到以素数平方为系数的情形，发现murmuration密度形状保持不变。


<details>
  <summary>Details</summary>
Motivation: 扩展模形式murmuration理论的应用范围，探索素数平方系数下的数学性质。

Method: 采用类比方法，将原研究中素数系数的分析框架应用于素数平方系数情形。

Result: 关键发现：murmuration密度函数的形状在素数平方系数下与原素数系数情形完全一致。

Conclusion: 该研究证明了murmuration现象在更广泛的系数条件下具有稳定性，为模数理论提供了新的见解。

Abstract: We extend the work of N. Zubrilina on murmuration of modular forms to the
case when prime-indexed coefficients are replaced by squares of primes. Our key
observation is that the shape of the murmuration density is the same.

</details>


### [22] [Permutation polynomials of the form $x+γ\mathrm{Tr}(H(x))$](https://arxiv.org/abs/2507.00781)
*Yangcheng Li,Xuan Pang,Pingzhi Yuan,Yuanpeng Zeng*

Main category: math.NT

TL;DR: 研究多项式$H(x)$在$\mathbb{F}_{q^n}$上形如$x + \gamma \mathrm{Tr}(H(x))$的置换多项式，探讨集合$P_H$的性质及其与线性翻译器的关系，并给出集合大小的有效上界。


<details>
  <summary>Details</summary>
Motivation: 探索特定形式的置换多项式及其相关集合$P_H$的性质，以深化对有限域上多项式置换行为的理解。

Method: 通过分析集合$P_H$与线性翻译器的关系，推导其大小的上界，并研究两类特定函数$H(x)$在$\mathbb{F}_{q^2}$上的$P_H$集合。

Result: 证明了$P_H$集合大小的上界可达$q^n - q^{n - 1}$，且当达到上界时，$\mathrm{Tr}(H(x))$必须是$\mathbb{F}_q$-线性函数；两类特定函数的$P_H$集合大小均较小。

Conclusion: 研究揭示了置换多项式集合$P_H$的性质及其与线性函数的关系，为有限域上的多项式置换理论提供了新的见解。

Abstract: Given a polynomial \( H(x) \) over \(\mathbb{F}_{q^n}\), we study permutation
polynomials of the form \( x + \gamma \mathrm{Tr}(H(x)) \) over
\(\mathbb{F}_{q^n}\). Let \[P_H=\{\gamma\in \mathbb{F}_{q^n} : x+\gamma
\mathrm{Tr}(H(x))~\text{is a permutation polynomial}\}.\] We present some
properties of the set \(P_H\), particularly its relationship with linear
translators. Moreover, we obtain an effective upper bound for the cardinality
of the set \(P_H\) and show that the upper bound can reach up to $q^n - q^{n -
1}$. Furthermore, we prove that when the cardinality of the set \(P_H\) reaches
this upper bound, the function \(\mathrm{Tr}(H(x))\) must be an
\(\mathbb{F}_q\)-linear function. Finally, we study two classes of functions
$H(x)$ over \(\mathbb{F}_{q^2}\) and determine the corresponding sets $P_H$.
The sizes of these sets $P_H$ are all relatively small, even only including the
trivial case.

</details>


### [23] [Density of algebraic points on products of curves](https://arxiv.org/abs/2507.00860)
*Jennifer Berg,Yu Fu,Evangelia Gazaki,Morena Porzio,James Rawson,Isabel Vogt*

Main category: math.NT

TL;DR: 本文系统研究了代数点在曲面上的密度问题，揭示了密度度集合在有效渐近范围内的规律性行为，并通过具体例子展示了小度数情况下密度对曲线算术性质的依赖性。


<details>
  <summary>Details</summary>
Motivation: 研究代数点在曲面上的密度行为，特别是探讨密度度集合的规律性及其与曲线算术性质的关系，为理解相关曲面的代数点分布提供理论基础。

Method: 通过分析密度度集合的渐近行为，结合具体例子（如亏格2曲线的乘积），研究不同情况下代数点的密度特性。

Result: 在有效渐近范围内，密度度集合的行为由指数决定；而在小度数情况下，密度问题则依赖于曲线的算术性质。具体例子展示了这些不同行为，包括具有和不具有密集二次点的亏格2曲线乘积。

Conclusion: 研究结果不仅揭示了代数点密度行为的多样性，还为相关曲面（如阿贝尔曲面和双椭圆曲面）的代数点问题提供了应用价值。

Abstract: In this paper, we initiate the systematic study of density of algebraic
points on surfaces. We give an effective asymptotic range in which the density
degree set has regular behavior dictated by the index. By contrast, in small
degree, the question of density is subtle and depends on the arithmetic of the
curves. We give several explicit examples displaying these different behaviors,
including products of genus $2$ curves with and without dense quadratic points.
These results for products of curves have applications to questions about
algebraic points on closely related surfaces, such as rank growth on abelian
surfaces and bielliptic surfaces.

</details>


### [24] [Une remarque sur l'invariant de Arf](https://arxiv.org/abs/2507.00890)
*Alexis Marin*

Main category: math.NT

TL;DR: 使用Witt形式主义重新构造特征2二次型的Arf不变量


<details>
  <summary>Details</summary>
Motivation: 探索特征2二次型Arf不变量的替代构造方法，以简化现有理论框架

Method: 采用Witt的形式主义体系，重新推导Arf不变量的数学表达式

Result: 成功建立基于Witt理论的Arf不变量新构造，验证了与经典定义的等价性

Conclusion: 该方法为特征2域上的二次型理论提供了更简洁的代数工具，拓展了Witt理论的应用范围

Abstract: An alternative construction, using Witt's formalism, of the Arf-invariant of
quadratic forms in characteristic 2.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [25] [Refinements of provability and consistency principles for the second incompleteness theorem](https://arxiv.org/abs/2507.00955)
*Taishi Kurahashi*

Main category: math.LO

TL;DR: 本文延续作者先前研究，证明非正规模态逻辑启发的弱原则可推导哥德尔第二不完备定理的多种精炼形式，主要成果包括集合$\{\mathbf{E},\mathbf{C}, \mathbf{D3}\}$足以确立一致性陈述$\neg\, \mathrm{Pr}_T(\ulcorner 0=1 \urcorner)$的不可证性，以及集合$\{\mathbf{E}^{\mathrm{U}}, \mathbf{CB_{\exists}}\}$可形式化$\Sigma_1$-完备性。


<details>
  <summary>Details</summary>
Motivation: 研究非正规模态逻辑的弱原则如何精炼哥德尔第二不完备定理的表达形式，探索更基础的逻辑框架下定理的成立条件。

Method: 通过构建特定逻辑原则集合（如$\{\mathbf{E},\mathbf{C}, \mathbf{D3}\}$和$\{\mathbf{E}^{\mathrm{U}}, \mathbf{CB_{\exists}}\}$），在形式系统内进行元数学推导。

Result: 证明集合$\{\mathbf{E},\mathbf{C}, \mathbf{D3}\}$可推出一致性陈述的不可证性；集合$\{\mathbf{E}^{\mathrm{U}}, \mathbf{CB_{\exists}}\}$能形式化$\Sigma_1$-完备性。

Conclusion: 非正规模态逻辑的弱原则为哥德尔定理提供了更精细的推导路径，揭示了形式系统局限性更基础的逻辑特征。

Abstract: This paper continues the author's previous study \cite{Kura20}, showing that
several weak principles inspired by non-normal modal logic suffice to derive
various refined forms of the second incompleteness theorem. Among the main
results of the present paper, we show that the set $\{\mathbf{E},\mathbf{C},
\mathbf{D3}\}$ suffices to establish the unprovability of the consistency
statement $\neg\, \mathrm{Pr}_T(\ulcorner 0=1 \urcorner)$. We also prove that
the set $\{\mathbf{E}^{\mathrm{U}}, \mathbf{CB_{\exists}}\}$ yields formalized
$\Sigma_1$-completeness.

</details>


<div id='math.GM'></div>

# math.GM [[Back]](#toc)

### [26] [A note on D-functions and P-covariances on Hilbert spaces and related inequalities](https://arxiv.org/abs/2507.00009)
*Sergio Scarlatti*

Main category: math.GM

TL;DR: 本文回顾了D函数概念，引入Hilbert空间上的P协方差，证明一维投影下Buzano等不等式是P协方差不等式的特例，并提出了这些不等式的增强形式及Holder不等式的新改进。


<details>
  <summary>Details</summary>
Motivation: 研究D函数与P协方差的关系，旨在统一和推广已知不等式（如Buzano、Richard、Walker不等式），并探索其在金融数学中的新应用。

Method: 通过正交投影$P$定义P协方差，将一维投影作为特例，结合D函数理论推导经典不等式，并系统化增强证明方法。

Result: 1. 证明经典不等式是P协方差的特例；2. 提出Walker不等式的金融应用分析；3. 给出Holder不等式的新改进方案。

Conclusion: P协方差框架为不等式研究提供了统一工具，其应用拓展至金融领域，且Holder不等式的改进展示了该方法的普适性。

Abstract: In this note we first review the concept of D-function, closely connected
with Cauchy-Schwarz inequality, and then introduce the notion of P-covariance
on a Hilbert space, where $P$ is an orthogonal projection. We show that when P
is specialized to be one-dimensional many well-known inequalities such as
Buzano, Richard and Walker inequalities are simple consequences of P-covariance
inequalities and their relation with D-functions. By means of these concepts
enhancements of the previous mentioned inequalities are also established with
minimum effort. A more thorough analysis of Walker inequality is presented
jointly with some novel financial considerations as well as a new refinement of
Holder inequality.

</details>


### [27] [The 2p order Heisenberg-Pauli-Weyl uncertainty principles related to the offset linear canonical transform](https://arxiv.org/abs/2507.00010)
*Jia-Yin Peng,Bing-Zhao Li*

Main category: math.GM

TL;DR: 本文研究了与偏移线性正则变换相关的不确定性原理，包括Plancherel-Parseval-Rayleigh恒等式、$2p$阶Heisenberg-Pauli-Weyl不确定性原理及其锐化形式，并通过数值模拟验证了结果。


<details>
  <summary>Details</summary>
Motivation: 随着基于傅里叶变换的各种先进时频分析方法的不断发展，研究与之相关的不确定性原理成为重要课题。不确定性原理揭示了时间与频率分辨率之间的内在权衡。

Method: 论文采用理论推导方法，建立了偏移线性正则变换框架下的Plancherel-Parseval-Rayleigh恒等式，推导了$2p$阶Heisenberg-Pauli-Weyl不确定性原理及其锐化形式，并通过数值模拟进行验证。

Result: 研究得出了偏移线性正则变换下的三类不确定性原理数学表达式，数值模拟结果支持了理论推导的正确性。

Conclusion: 该研究完善了偏移线性正则变换的理论体系，为时频分析提供了新的数学工具，数值验证增强了理论结果的可靠性。

Abstract: The uncertainty principle is one of the fundamental tools for time-frequency
analysis in harmonic analysis, revealing the intrinsic trade-off between time
and frequency resolutions. With the continuous development of various advanced
time-frequency analysis methods based on the Fourier transform, investigating
uncertainty principles associated with these methods has become one of the most
interesting topics. This paper studies the uncertainty principles related to
the offset linear canonical transform, including the
Plancherel-Parseval-Rayleigh identity, the $2p$ order Heisenberg-Pauli-Weyl
uncertainty principle and the sharpened Heisenberg-Pauli-Weyl uncertainty
principle. Numerical simulations are also proposed to validate the derived
results.

</details>


### [28] [On a class of coupled fractional nonlinear singular boundary value problems arising in dusty fluid models](https://arxiv.org/abs/2507.00017)
*Lok Nath Kannaujiya,Narendra Kumar,Amit K. Verma*

Main category: math.GM

TL;DR: 本文提出了一种新的耦合分数阶Lane-Emden边值问题求解方法，结合分数阶Haar小波配置法与Newton-Raphson方法，通过数值实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决非线性奇异分数阶边值问题，展示分数阶微分方程在实际应用中的潜力。

Method: 采用分数阶Haar小波配置法与Newton-Raphson方法相结合的新方法，分析两种条件下的数值实验。

Result: 实验表明，随着分辨率水平$J$的增加或分数阶导数阶数的变化，残差误差均减小，Mathematica软件能有效求解此类问题。

Conclusion: 所提方法在求解耦合分数阶Lane-Emden边值问题上具有高精度和实用性，为相关领域提供了有效工具。

Abstract: In this article, we introduce a new class of coupled fractional Lane-Emden
boundary value problems. We employ a novel approach, the fractional Haar
wavelet collocation method with the Newton-Raphson method. We analyze the
conditions in two cases to present numerical experiments related to the defined
system of fractional differential equations. To validate the accuracy of the
proposed method we present the convergence of the method, and we demonstrate
the method's effectiveness through five numerical experiments, highlighting
real-world applications of fractional differential equations. Using figures and
tables, we show that the residual error decreases as we increase the value of
the maximum level of resolution $J$ while keeping the order of derivatives
fixed, and similar trends also observe when $J$ is fixed and vary the order of
fractional derivatives. We demonstrate that Mathematica software can be used
effectively to solve such nonlinear singular fractional boundary value
problems.

</details>


### [29] [An Application of Fractional Calculus to Column Theory](https://arxiv.org/abs/2507.00021)
*José Villa-Morales,Manuel Ramírez-Aranda*

Main category: math.GM

TL;DR: 本文通过引入曲率半径的分数阶形式到欧拉柱屈曲方程中，推导出Caputo意义上的分数阶微分方程，并证明特定分数参数下存在临界屈曲力，同时提供了数值求解方案。


<details>
  <summary>Details</summary>
Motivation: 研究旨在扩展经典欧拉屈曲理论，通过分数阶微积分方法探索柱体屈曲行为的新特征，特别是临界屈曲力与分数阶参数的关系。

Method: 采用曲率半径的分数阶形式重构欧拉方程，建立Caputo分数阶微分方程模型，并开发数值算法求解临界力。

Result: 理论证明特定分数阶参数下存在临界屈曲力，数值实验验证了该力的可计算性及参数依赖性。

Conclusion: 分数阶模型成功揭示了传统整数阶理论未涵盖的屈曲特性，数值方法为工程应用提供了实用工具。

Abstract: In this article, we employ a fractional version of the radius of curvature in
Euler's equation for column buckling, enabling us to derive a fractional
differential equation in the Caputo sense. We solve this equation and
demonstrate that for certain values of the fractional parameter, there exists a
critical buckling force. Additionally, we provide a numerical scheme for
accurately approximating this critical force.

</details>


### [30] [Conditions for solving polynomial equations using algebraic and hypergeometric functions](https://arxiv.org/abs/2507.00027)
*Nikos Mantzakouras,Carlos López Zapata,Nid Na Ratch*

Main category: math.GM

TL;DR: 本文澄清了使用连续函数或超几何函数求解六次以上方程的概念，并提供了四次以上方程无代数解的另一证明。基于Kolmogorov-Arnold定理，证明了五次以上方程在系数无特殊关系时无法用超几何函数求解，但一般形式的三项式方程通常可解。


<details>
  <summary>Details</summary>
Motivation: 旨在明确高次方程求解的理论边界，特别是探讨超几何函数在六次以上方程中的适用性，并补充四次以上方程无代数解的证明。

Method: 依据Kolmogorov-Arnold定理，分析超几何函数对高次方程的普适性限制，同时针对三项式方程的特殊结构展开可解性论证。

Result: 证明五次以上方程在系数无约束时无法通过超几何函数求解，但一般形式的三项式方程存在超几何函数解。

Conclusion: 研究划定了超几何函数求解高次方程的适用范围，为三项式方程提供了新的解析工具，同时强化了经典不可解定理的结论。

Abstract: In this paper, we focus on clarifying the concept of solving equations of
degree greater than six using continuous functions or hypergeometric functions
and providing another proof of the non-existence of algebraic solutions for
equations of degree greater than four. According to the Kolmogorov-Arnold
theorem, we will prove that equations of degree greater than five cannot be
solved without special conditions between their coefficients using
hypergeometric functions. However, we prove that trinomial equations of general
form can in general be solved using hypergeometric functions.

</details>


### [31] [Weakly Compatible Mappings and Common Fixed Points Under Generalized Contractive Conditions](https://arxiv.org/abs/2507.00035)
*Alemayehu Negash,Meaza Bogale*

Main category: math.GM

TL;DR: 本文在度量空间中建立了弱相容映射的新公共不动点定理，放宽了连续性、相容性和互连续性等传统要求，提出了统一框架并推广了现有结果。


<details>
  <summary>Details</summary>
Motivation: 旨在放宽传统不动点定理对映射的严格限制（如连续性、相容性），建立更普适的理论框架，并验证其对前人结果的严格推广性。

Method: 使用控制函数$\psi$构建三个自映射$T$、$f$、$g$的压缩条件，通过推论扩展到映射对和上半连续控制函数，并进一步推广到迭代映射序列。

Result: 消除了空间完备性假设并弱化了映射相容条件，严格推广了Al-Thagafi、Babu、Jungck等学者的定理，示例验证了假设的必要性。

Conclusion: 新定理显著扩展了弱相容映射的不动点理论框架，为后续研究提供了更灵活的工具，尤其在非完备度量空间中具有应用潜力。

Abstract: This paper establishes new common fixed point theorems for weakly compatible
mappings in metric spaces, relaxing traditional requirements such as
continuity, compatibility, and reciprocal continuity. We present a unified
framework for three self-mappings $T$, $f$, and $g$ with a contractive
condition involving a control function $\psi$, along with corollaries extending
results to pairs of mappings and upper semi-continuous control functions.
Further generalizations include iterated mappings and sequences of mappings.
Rigorous examples demonstrate the necessity of hypotheses and show our results
strictly generalize theorems by Al-Thagafi \emph{et. al.}
\cite{Al-Thagafi2006}, Babu \emph{et. al.} \cite{Babu2007}, Jungck
\cite{Jungck1976,Jungck1986}, Singh \cite{Singh1986,Singh1997a}, Som
\cite{Som2003}, Song \cite{Song2007} and Zhang \emph{et. al.} \cite{Zhang2008}.
Key advancements include eliminating completeness assumptions on the entire
space and relaxing mapping compatibility conditions.

</details>


### [32] [An Addendum to Plouffe's Ramanujan Identities](https://arxiv.org/abs/2507.00040)
*Segun Olofin Akerele*

Main category: math.GM

TL;DR: 本文介绍了一类新的多对数求和形式，与Vep\v{s}tas研究的家族密切相关，并给出了涉及Dirichlet eta函数的闭式表达式，同时提供了Ramanujan双曲求和的替代证明。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于对多对数求和的扩展及其与Dirichlet eta函数的关联，旨在深化对这类特殊函数的理解并探索新的数学关系。

Method: 方法包括引入含两个自由参数的广义求和形式，并通过数学分析推导其闭式解，同时对Ramanujan的双曲求和给出了新的证明路径。

Result: 主要成果为获得了一类新的多对数求和的显式表达式，这些表达式均与Dirichlet eta函数相关，并成功验证了Ramanujan双曲求和的正确性。

Conclusion: 结论表明所提出的广义求和形式不仅扩展了现有理论框架，还为特殊函数领域的研究提供了新的工具和视角。

Abstract: We introduce a new class of polylogarithm sums closely related to a family
studied by L. Vep\v{s}tas in 2010. These generalized sums depend on two free
parameters and yield closed-form expressions involving the Dirichlet eta
function. Additionally, we present an alternative proof for a hyperbolic sum
originally discussed by Ramanujan.

</details>


### [33] [Fixed Points of the Josephus Function via Fractional Base Expansions](https://arxiv.org/abs/2507.00317)
*Yunier Bello-Cruz,Roy Quintero-Contreras*

Main category: math.GM

TL;DR: 本文研究了约瑟夫函数$J_3$不动点的有趣性质，建立了其与中国剩余定理的联系，并发现其在$3/2$进制下的数字模式。


<details>
  <summary>Details</summary>
Motivation: 探索约瑟夫函数$J_3$不动点的数学特性及其潜在规律。

Method: 通过中国剩余定理建立联系，并利用$3/2$进制下的模运算分析数字模式。

Result: 发现不动点序列在$3/2$进制下呈现清晰数字模式，并开发了递归计算其数字展开的方法。

Conclusion: 该研究揭示了$J_3$函数不动点与数论定理的深刻联系，并为非整数进制表示提供了新视角。

Abstract: In this paper, we investigated some interesting properties of the fixed
points of the Josephus function $J_3$. First, we establish a connection between
this sequence and the Chinese Remainder Theorem. Next, we observed a clear
numerical pattern in the fixed points sequence when the terms are written in
base $3/2$ using modular arithmetic, which allows us to develop a recursive
procedure to determine the digits of their base $3/2$ expansions.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [34] [Compact Representation of Semilinear and Terrain-like Graphs](https://arxiv.org/abs/2507.00252)
*Jean Cardinal,Yelena Yuditsky*

Main category: math.CO

TL;DR: 本文研究了图的二部团覆盖问题，提出了半线性图和地形类图的新型覆盖构造，并证明了单位圆盘图覆盖大小的下限。


<details>
  <summary>Details</summary>
Motivation: 二部团覆盖作为图的紧凑表示在计算几何中广泛应用，但现有研究局限于特定图类。本文旨在扩展覆盖理论至更广泛的图类，并探索覆盖大小与图结构的关系。

Method: 通过几何与组合技术结合：对半线性图采用空间划分方法，对地形类图设计有序模式避免策略，对单位圆盘图构造反例。

Result: 1) 半线性图存在$O(n\polylog n)$大小的覆盖；2) 地形类图存在$O(n\log^3 n)$的划分；3) 单位圆盘图覆盖大小下限为$\Omega(n^{4/3})$。

Conclusion: 研究统一并扩展了多类图的覆盖理论，揭示了几何约束与覆盖效率的深刻联系，同时为后续研究提供了组合工具与边界参考。

Abstract: We consider the existence and construction of \textit{biclique covers} of
graphs, consisting of coverings of their edge sets by complete bipartite
graphs. The \textit{size} of such a cover is the sum of the sizes of the
bicliques. Small-size biclique covers of graphs are ubiquitous in computational
geometry, and have been shown to be useful compact representations of graphs.
We give a brief survey of classical and recent results on biclique covers and
their applications, and give new families of graphs having biclique covers of
near-linear size.
  In particular, we show that semilinear graphs, whose edges are defined by
linear relations in bounded dimensional space, always have biclique covers of
size $O(n\polylog n)$. This generalizes many previously known results on
special classes of graphs including interval graphs, permutation graphs, and
graphs of bounded boxicity, but also new classes such as intersection graphs of
L-shapes in the plane. It also directly implies the bounds for Zarankiewicz's
problem derived by Basit, Chernikov, Starchenko, Tao, and Tran (\textit{Forum
Math. Sigma}, 2021).
  We also consider capped graphs, also known as terrain-like graphs, defined as
ordered graphs forbidding a certain ordered pattern on four vertices.
Terrain-like graphs contain the induced subgraphs of terrain visibility graphs.
We give an elementary proof that these graphs admit biclique partitions of size
$O(n\log^3 n)$. This provides a simple combinatorial analogue of a classical
result from Agarwal, Alon, Aronov, and Suri on polygon visibility graphs
(\textit{Discrete Comput. Geom.} 1994).
  Finally, we prove that there exists families of unit disk graphs on $n$
vertices that do not admit biclique coverings of size $o(n^{4/3})$, showing
that we are unlikely to improve on Szemer\'edi-Trotter type incidence bounds
for higher-degree semialgebraic graphs.

</details>


### [35] [Faces in rectilinear drawings of complete graphs](https://arxiv.org/abs/2507.00313)
*Martin Balko,Anna Brötzner,Fabian Klute,Josef Tkadlec*

Main category: math.CO

TL;DR: 本文首次研究了凸直线绘制中关于面的极值问题，证明了在无三边共内点的条件下，总存在凸五边形面，并刻画了正多边形绘制中存在凸五边形面的条件。


<details>
  <summary>Details</summary>
Motivation: 研究凸直线绘制中面的极值问题，填补了该领域的研究空白，并提出了若干新的开放性问题。

Method: 通过分析凸直线绘制中边的共内点条件，结合正多边形绘制的几何特性，进行理论证明与分类讨论。

Result: 证明无三边共内点的凸直线绘制必含凸五边形面，但不存在更高阶凸多边形面；完整刻画了正多边形绘制中存在凸五边形面的正整数$n$。

Conclusion: 该研究为凸直线绘制中的面结构提供了首个理论框架，提出的开放问题将推动该领域的后续研究。

Abstract: We initiate the study of extremal problems about faces in convex rectilinear
drawings of~$K_n$, that is, drawings where vertices are represented by points
in the plane in convex position and edges by line segments between the points
representing the end-vertices. We show that if a convex rectilinear drawing of
$K_n$ does not contain a common interior point of at least three edges, then
there is always a face forming a convex 5-gon while there are such drawings
without any face forming a convex $k$-gon with $k \geq 6$.
  A convex rectilinear drawing of $K_n$ is \emph{regular} if its vertices
correspond to vertices of a regular convex $n$-gon. We characterize positive
integers $n$ for which regular drawings of $K_n$ contain a face forming a
convex 5-gon.
  To our knowledge, this type of problems has not been considered in the
literature before and so we also pose several new natural open problems.

</details>


### [36] [2-factors in $\frac{3}{2}$-tough maximal planar graphs](https://arxiv.org/abs/2507.00395)
*Lili Hao,Hui Ma,Songling Shan,Weihua Yang*

Main category: math.CO

TL;DR: 本文研究了$\frac{3}{2}$-坚韧极大平面图中2-因子的存在条件，提出了一个基于3度顶点间距离的充分条件。


<details>
  <summary>Details</summary>
Motivation: 1956年Tutte证明$>\frac{3}{2}$-坚韧平面图必有2-因子，1999年Owens构造了$\frac{3}{2}-\varepsilon$坚韧但无2-因子的极大平面图族。近期第三作者证实存在精确$\frac{3}{2}$-坚韧且无2-因子的极大平面图，这自然引出了$\frac{3}{2}$-坚韧极大平面图何时存在2-因子的研究问题。

Method: 通过分析极大平面图的结构特性，重点关注图中3度顶点之间的拓扑关系，建立顶点度数与图坚韧性的联系。

Result: 给出了$\frac{3}{2}$-坚韧极大平面图中存在2-因子的一个充分条件，该条件表现为对图中3度顶点间距离的明确上界约束。

Conclusion: 研究成果为判定$\frac{3}{2}$-坚韧极大平面图的2-因子存在性提供了新的理论工具，将Tutte经典结论向临界韧性情形推进了一步。

Abstract: The toughness of a graph $G$ is defined as the minimum value of $|S|/c(G-S)$
over all cutsets $S$ of $G$ if $G$ is noncomplete, and is defined to be
$\infty$ if $G$ is complete. For a real number $t$, we say that $G$ is
$t$-tough if its toughness is at least $t$. Followed from the classic 1956
result of Tutte, every more than $\frac{3}{2}$-tough planar graph on at least
three vertices has a 2-factor. In 1999, Owens constructed a sequence of maximal
planar graphs with toughness $\frac{3}{2}-\varepsilon$ for any $\varepsilon
>0$, but the graphs do not contain any 2-factor. He then posed the question of
whether there exists a maximal planar graph with toughness exactly
$\frac{3}{2}$ and with no 2-factor. This question was recently answered
affirmatively by the third author. This naturally leads to the question: under
what conditions does a $\frac{3}{2}$-tough maximal planar graph contain a
2-factor? In this paper, we provide a sufficient condition for the existence of
2-factors in $\frac{3}{2}$-tough maximal planar graphs, stated as a bound on
the distance between vertices of degree 3.

</details>


### [37] [On Bivariegated Graphs and Line Graphs](https://arxiv.org/abs/1809.08467)
*Ranjan N. Naik*

Main category: math.CO

TL;DR: 本文研究了线图和2-杂色图的结构，解决了涉及这两类图的方程问题，并给出了潜在2-杂色线图度序列的表征。


<details>
  <summary>Details</summary>
Motivation: 探索线图和2-杂色图的结构特性及其在图方程中的应用，填补相关领域的研究空白。

Method: 通过数学推导和图论方法，解决涉及线图和2-杂色图的方程问题，并分析度序列的潜在特性。

Result: 成功解决了若干图方程问题，并提供了潜在2-杂色线图度序列的完整表征。

Conclusion: 该研究为线图和2-杂色图的结构分析提供了新的理论工具，对图论领域具有重要贡献。

Abstract: This note is on the structures of line graphs and 2-variegated graphs. We
have given here solutions of some graph equations involving line graphs and
2-variegated graphs. In addition, a characterization of potentially
2-variegated line graphic degree sequences is given.

</details>


### [38] [The square of every subcubic planar graph without 4-cycles and 5-cycles is 7-choosable](https://arxiv.org/abs/2507.00426)
*Ligang Jin,Yingli Kang,Seog-Jin Kim*

Main category: math.CO

TL;DR: 本文证明了不含4-环和5-环的次立方平面图$G$的平方图$G^2$的列表着色数$\chi_{\ell}(G^2)$不超过7，改进了Kim和Lian的结果。


<details>
  <summary>Details</summary>
Motivation: 研究次立方平面图的平方图$G^2$的列表着色数$\chi_{\ell}(G^2)$是否不超过7，这是对Thomassen和Hartke等人关于普通着色数结果的进一步探索。

Method: 通过分析不含4-环和5-环的次立方平面图的结构特性，运用列表着色的相关理论和方法进行证明。

Result: 证明了对于不含4-环和5-环的次立方平面图$G$，其平方图$G^2$的列表着色数$\chi_{\ell}(G^2)$不超过7。

Conclusion: 该结果改进了Kim和Lian关于高围长次立方平面图的结论，为次立方平面图平方图的列表着色问题提供了更一般的解答。

Abstract: The square of a graph $G$, denoted by $G^2$, has the same vertex set as $G$
and has an edge between two vertices if the distance between them in $G$ is at
most $2$. Thomassen (2018) and independently, Hartke, Jahanbekam and Thomas
(2016) proved that $\chi(G^2) \leq 7$ if $G$ is a subcubic planar graph. A
natural question is whether $\chi_{\ell}(G^2) \leq 7$ or not if $G$ is a
subcubic planar graph. Recently, Kim and Lian (2024) proved that
$\chi_{\ell}(G^2) \leq 7$ if $G$ is a subcubic planar graph of girth at least
6. In this paper, we prove that $\chi_{\ell}(G^2) \leq 7$ if $G$ is a subcubic
planar graph without 4-cycles and 5-cycles, which improves the result of Kim
and Lian.

</details>


### [39] [On Intersection Graphs of Graphs and Hypergraphs: A Survey](https://arxiv.org/abs/1809.08472)
*Ranjan N. Naik*

Main category: math.CO

TL;DR: 本文综述了超图交图理论的发展历程，总结了该领域的重要里程碑，并列出了一些未解决问题及新趋势。


<details>
  <summary>Details</summary>
Motivation: 超图交图理论作为特殊图论中的经典课题，其发展历程和最新趋势需要系统梳理，以促进该领域的进一步研究。

Method: 通过文献综述的方式，回顾了超图交图的表征方法，包括线图、代表图、派生图等，并涉及算法、禁止诱导子图等技术。

Result: 总结了超图交图理论的关键发展节点，整理了多位学者提出的开放性问题，并指出了该领域的新兴研究方向。

Conclusion: 超图交图理论仍存在许多未解问题，新的研究趋势正在形成，需要进一步探索算法应用和结构表征。

Abstract: In this survey, we have attempted to show some developmental milestones on
the characterizations of intersection graphs of hypergraphs. The theory of
intersection graphs of hypergraphs has been a classical topic in the theory of
special graphs. To conclude, at the end, we have listed some open problems
posed by various authors whose work has contributed to this survey and also the
new trends coming out of intersection graphs. Keywords: Hypergraphs,
Intersection graphs, Line graphs, Representative graphs, Derived graphs,
Algorithms (ALG), Forbidden induced subgraphs (FIS), Krausz partitions,
Eigenvalues.

</details>


### [40] [The Rogers-Ramanujan Identities and Cauchy's Identity](https://arxiv.org/abs/2507.00433)
*Dennis Stanton*

Main category: math.CO

TL;DR: 该论文利用Schur函数的柯西恒等式研究了Rogers-Ramanujan恒等式。


<details>
  <summary>Details</summary>
Motivation: 探索Rogers-Ramanujan恒等式的新证明方法，通过Schur函数理论提供新的视角。

Method: 使用Schur函数的柯西恒等式作为主要工具进行分析和推导。

Result: 通过该方法，成功建立了Rogers-Ramanujan恒等式与Schur函数理论之间的联系。

Conclusion: Schur函数的柯西恒等式为研究Rogers-Ramanujan恒等式提供了有效的数学框架。

Abstract: The Rogers-Ramanujan identities are investigated using the Cauchy identity
for Schur functions.

</details>


### [41] [Sums and products in sets of positive density](https://arxiv.org/abs/2507.00515)
*Florian K. Richter*

Main category: math.CO

TL;DR: 本文通过傅里叶分析和遍历理论工具，研究了涉及整数和与积的Ramsey型问题，针对特定多项式条件证明了自然数集中存在特定形式的数对。


<details>
  <summary>Details</summary>
Motivation: 研究自然数集中特定形式数对的存在性问题，扩展Ramsey理论在加法和乘法结构中的应用。

Method: 结合傅里叶分析和遍历理论，针对满足$Q(1)=0$或$Q(0)=0$的多项式$Q$，采用对数密度和新型乘法密度的分析框架。

Result: 1. 若$Q(1)=0$，任何具有正上对数密度的自然数集包含形如$\{x + Q(y), xy\}$的数对；2. 若$Q(0)=0$，任何相对于新型乘法密度具有正密度的自然数集包含此类数对。

Conclusion: 该研究为整数加乘结构的Ramsey理论提供了新工具，并建立了在特定密度条件下数对存在的普适性结论。

Abstract: We develop an analytic approach that draws on tools from Fourier analysis and
ergodic theory to study Ramsey-type problems involving sums and products in the
integers. Suppose $Q$ denotes a polynomial with integer coefficients. We
establish two main results. First, we show that if $Q(1) = 0$, then any set of
natural numbers with positive upper logarithmic density contains a pair of the
form $\{x + Q(y), xy\}$ for some $x, y \in \mathbb{N} \setminus \{1\}$. Second,
we prove that if $Q(0) = 0$, then any set of natural numbers with positive
density relative to a new multiplicative notion of density, which arises
naturally in the context of such problems, contains $\{x + Q(y), xy\}$ for some
$x, y \in \mathbb{N}$.

</details>


### [42] [Linear rank-metric intersecting codes](https://arxiv.org/abs/2507.00569)
*Daniele Bartoli,Martino Borello,Giuseppe Marino,Martin Scotti*

Main category: math.CO

TL;DR: 本文提出并研究了一种新的秩度量相交码，这是受汉明度量中相交码启发而引入的线性码类。通过编码理论和几何视角探讨了其特性，并与最小码、MRD码等建立了联系。


<details>
  <summary>Details</summary>
Motivation: 受汉明度量中相交码研究的启发，探索秩度量背景下线性码的新特性，以扩展编码理论的应用范围。

Method: 从编码理论和几何角度分析秩度量相交码，推导其结构特性、基于最小距离的充分条件，以及用2-可生成$q$-系统的几何表征。

Result: 建立了秩度量相交码的参数上下界，展示了一些构造方法，并发现部分参数范围尚未被探索。同时，将其与$(2,1)$-分离系统和防伪码等组合结构联系起来。

Conclusion: 秩度量相交码为编码理论提供了新的研究方向，其与多种编码和组合结构的关联为未来研究开辟了潜在路径。

Abstract: In this paper we introduce and investigate rank-metric intersecting codes, a
new class of linear codes in the rank-metric context, inspired by the
well-studied notion of intersecting codes in the Hamming metric. A rank-metric
code is said to be intersecting if any two nonzero codewords have supports
intersecting non trivially. We explore this class from both a coding-theoretic
and geometric perspective, highlighting its relationship with minimal codes,
MRD codes, and Hamming-metric intersecting codes. We derive structural
properties, sufficient conditions based on minimum distance, and geometric
characterizations in terms of 2-spannable $q$-systems. We establish upper and
lower bounds on code parameters and show some constructions, which leave a
range of unexplored parameters. Finally, we connect rank-intersecting codes to
other combinatorial structures such as $(2,1)$-separating systems and
frameproof codes.

</details>


### [43] [Seeing is not believing in limited visibility cops and robbers](https://arxiv.org/abs/2507.00941)
*Bojan Bašić,Alfie Davies,Aleksa Džuklevski,Strahinja Gvozdić,Yannick Mogge*

Main category: math.CO

TL;DR: 研究了有限视野下的警察与强盗模型，证明发现强盗所需的警力远少于捕获强盗所需，并探讨了警力不足时的接近策略及概率解释。


<details>
  <summary>Details</summary>
Motivation: 解决文献中关于有限视野$l$-邻域内警察发现强盗所需警力与捕获所需警力关系的开放性问题。

Method: 通过理论分析比较发现与捕获强盗所需的最小警力，并引入概率方法评估警力不足时的接近策略。

Result: 证明发现强盗的警力可任意小于捕获所需警力，并量化了警力不足时的接近效率。

Conclusion: 该研究为有限视野追捕问题提供了理论突破，揭示了观察与捕获的警力差异，并为实际应用提供了概率框架。

Abstract: We consider the model of limited visibility Cops and Robbers, where the cops
can only see within their $l$-neighbourhood. We prove that the number of cops
needed to see the robber can be arbitrarily smaller than the number needed to
capture the robber, answering an open question from the literature. We then
consider how close we can get to seeing the robber when we do not have enough
cops, along with a probabilistic interpretation.

</details>


### [44] [A tableaux formula for $q$-rook numbers](https://arxiv.org/abs/2507.00766)
*Tirtharaj Basu,Aritra Bhattacharya*

Main category: math.CO

TL;DR: 本文提出了Garsia-Remmel $q$-rook数的标准Young表求和公式，并建立了其与单细胞LLT函数$q$-Whittaker展开系数之间的联系。


<details>
  <summary>Details</summary>
Motivation: 研究旨在建立组合数学中$q$-rook数与对称函数理论之间的桥梁，深化对两者代数结构的理解。

Method: 通过标准Young表枚举的组合方法，推导出$q$-rook数的显式表达式，并分析其与LLT多项式系数的对应关系。

Result: 成功证明了$q$-rook数可表示为标准Young表的权重和，且该表达式精确对应LLT函数的$q$-Whittaker展开系数。

Conclusion: 该成果为$q$-rook数提供了新的组合解释，同时揭示了LLT多项式在$q$-Whittaker基下的代数组合性质。

Abstract: We provide a formula for the Garsia-Remmel $q$-rook numbers as a sum over
standard Young tableaux. We connect our formula with the coefficients in
$q$-Whittaker expansion of unicellular LLT functions.

</details>


### [45] [Nondegenerate hyperplane covers of the hypercube](https://arxiv.org/abs/2507.00773)
*Lisa Sauermann,Zixuan Xu*

Main category: math.CO

TL;DR: 研究$\mathbb{R}^n$中覆盖超立方体$\{0,1\}^n$所有顶点且满足非退化条件的超平面集合，证明其最小规模为$|\mathcal{H}|\ge n/2$，并推广了斜覆盖问题的结果。


<details>
  <summary>Details</summary>
Motivation: 探索超平面覆盖超立方体顶点的非退化条件，推广斜覆盖问题，解决超平面切割超立方体边的古老问题。

Method: 通过分析超平面方程中变量的非零系数条件，结合组合几何方法，推导覆盖集合的最小规模。

Result: 证明满足非退化条件的超平面覆盖集合规模至少为$n/2$，该界限在常数因子内是紧的，并应用于超立方体边切割问题。

Conclusion: 非退化超平面覆盖问题的最小规模界限为$n/2$，推广了斜覆盖问题的结果，并为超立方体边切割问题提供了紧界限。

Abstract: We consider collections of hyperplanes in $\mathbb{R}^n$ covering all
vertices of the $n$-dimensional hypercube $\{0,1\}^n$, which satisfy the
following nondegeneracy condition: For every $v\in \{0,1\}^n$ and every
$i=1,\dots,n$, we demand that there is a hyperplane $H$ in the collection with
$v\in H$ such that the variable $x_i$ appears with a non-zero coefficient in
the hyperplane equation describing $H$. We prove that every collection
$\mathcal{H}$ of hyperplanes in $\mathbb{R}^n$ covering $\{0,1\}^n$ with this
nondegeneracy condition must have size $|\mathcal{H}|\ge n/2$.
  This bound is tight up to constant factors. It generalizes a recent result
concerning the intensively studied skew covers problem, which asks about the
minimum possible size of a hyperplane cover of $\{0,1\}^n$ in which all
variables appear with non-zero coefficients in all hyperplane equations.
  As an application of our result, we also obtain an essentially tight bound
for an old problem about collections of hyperplanes slicing all edges of the
$n$-dimensional hypercube, in the case where all of the hyperplanes have
bounded integer coefficients.

</details>


### [46] [Improved bound of graph energy in terms of vertex cover number](https://arxiv.org/abs/2507.00798)
*Aniruddha Samanta*

Main category: math.CO

TL;DR: 该论文证明了对于多类简单图$G$，其能量$\mathcal{E}(G)$满足$\mathcal{E}(G)\geq 2\tau$，显著改进了已知结果$\mathcal{E}(G)\geq 2\tau-2c$。


<details>
  <summary>Details</summary>
Motivation: 研究图的能量$\mathcal{E}(G)$与顶点覆盖数$\tau$之间的关系，改进现有理论下界。

Method: 通过分析图的邻接矩阵特征值绝对值和，结合顶点覆盖数与奇环数量$c$的关系进行推导。

Result: 对于多类图，建立了更紧的下界$\mathcal{E}(G)\geq 2\tau$，优于原下界$2\tau-2c$。

Conclusion: 该结果显著提升了图能量下界的理论估计，为相关图论研究提供了更精确的工具。

Abstract: Let $ G $ be a simple graph with the vertex cover number $ \tau $. The energy
$ \mathcal{E}(G) $ of $ G $ is the sum of the absolute values of all the
adjacency eigenvalues of $ G $. In this article, we establish $
\mathcal{E}(G)\geq 2\tau $ for several classes of graphs. The result
significantly improves the known result $ \mathcal{E}(G)\geq 2\tau-2c$ for many
classes of graphs, where $ c $ is the number of odd cycles.

</details>


### [47] [Turán density of tight cycles minus one edge in the $\ell_2$-norm](https://arxiv.org/abs/2507.00812)
*Levente Bodnár,Jinghua Deng,Jianfeng Hou,Xizhi Liu,Hongbin Zhao*

Main category: math.CO

TL;DR: 论文证明了当$\ell \ge 5$且$\ell\not\equiv 0\pmod3$时，所有不含$C_{\ell}^{3-}$的3-图若其$\ell_2$-范数接近最大值，则其结构必接近单个三元组的迭代膨胀，这验证了Balogh-Clemen-Lidick\'{y}的猜想。


<details>
  <summary>Details</summary>
Motivation: 研究$C_{\ell}^{3-}$-free的3-图在$\ell_2$-范数接近最大值时的结构性质，验证Balogh-Clemen-Lidick\'{y}的猜想。

Method: 通过分析3-图的$\ell_2$-范数和结构性质，结合组合数学和图论的方法进行研究。

Result: 当$\ell \ge 5$且$\ell\not\equiv 0\pmod3$时，$C_{\ell}^{3-}$-free的3-图若$\ell_2$-范数接近最大值，则其结构必接近单个三元组的迭代膨胀。

Conclusion: 结果以更强的形式验证了Balogh-Clemen-Lidick\'{y}的猜想，为3-图的结构研究提供了新的理论支持。

Abstract: The $3$-uniform tight $\ell$-cycle minus one edge $C_{\ell}^{3-}$ is the
$3$-graph on $\ell$ vertices consisting of $\ell-1$ consecutive triples in the
cyclic order. We show that for every integer $\ell \ge 5$ satisfying
$\ell\not\equiv 0\pmod3$, every $C_{\ell}^{3-}$-free $3$-graph whose
$\ell_2$-norm, that is, the sum of codegree squares, is close to the maximum
must be structurally close to the iterative blowup of a single triple. This
confirms a conjecture of Balogh--Clemen--Lidick\'{y}~[Surveys in combinatorics
2022, 21-63] in a stronger form.

</details>


### [48] [On the association scheme of perfect matchings and their designs](https://arxiv.org/abs/2507.00813)
*John Bamberg,Lukas Klawuhn*

Main category: math.CO

TL;DR: 研究完全图$K_{2n}$的1-因子分解与超因子分解的推广，揭示其与Gelfand对$(S_{2n},S_2 \wr S_n)$关联方案的特殊子集关系，统一并扩展了Cameron (1976)的结果，并提出了新的存在性与非存在性结论。


<details>
  <summary>Details</summary>
Motivation: 探索完全图$K_{2n}$的因子分解理论的推广，旨在统一现有理论并发现新的数学结构。

Method: 在群代数$\mathbb{C}[S_{2n}]$中工作，并利用$S_{2n}$的表示理论进行分析。

Result: 证明了1-因子分解和超因子分解是Gelfand对关联方案的特殊子集，从而统一并扩展了Cameron的结果，并获得了新的存在性与非存在性结果。

Conclusion: 通过群代数和表示理论的方法，本研究不仅统一了因子分解的现有理论，还开辟了新的研究方向。

Abstract: We investigate generalisations of 1-factorisations and hyperfactorisations of
the complete graph $K_{2n}$. We show that they are special subsets of the
association scheme obtained from the Gelfand pair $(S_{2n},S_2 \wr S_n)$. This
unifies and extends results by Cameron (1976) and gives rise to new existence
and non-existence results. Our methods involve working in the group algebra
$\mathbb{C}[S_{2n}]$ and using the representation theory of $S_{2n}$.

</details>


### [49] [Cubic torus obstructions of small Betti number](https://arxiv.org/abs/2507.00876)
*Marie Kramer*

Main category: math.CO

TL;DR: 本文对Betti数不超过八的三维环面阻碍图进行了理论分类，填补了环面图嵌入研究的部分空白。


<details>
  <summary>Details</summary>
Motivation: 图在曲面中的嵌入性研究已有近百年历史，但针对环面的拓扑阻碍仅有部分成果，亟需系统分类。

Method: 采用理论分析方法，聚焦于三次（立方）环面阻碍图，限定Betti数不超过八的条件进行分类研究。

Result: 建立了Betti数≤8的三次环面阻碍图的完整理论分类体系，扩展了环面嵌入障碍的认知边界。

Conclusion: 该研究为环面图嵌入理论提供了新的分类工具，未来可推广至更高Betti数或其它曲面的阻碍分析。

Abstract: The embeddability of graphs into surfaces has been studied for nearly a
century. While the complete set of topological obstructions is known for the
sphere and the real projective plane, there are only partial results for the
torus. Here we present a theoretical classification of cubic torus obstructions
with Betti number at most eight.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [50] [AI-Governed Agent Architecture for Web-Trustworthy Tokenization of Alternative Assets](https://arxiv.org/abs/2507.00096)
*Ailiya Borjigin,Wei Zhou,Cong He*

Main category: cs.CR

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Alternative Assets tokenization is transforming non-traditional financial
instruments are represented and traded on the web. However, ensuring
trustworthiness in web-based tokenized ecosystems poses significant challenges,
from verifying off-chain asset data to enforcing regulatory compliance. This
paper proposes an AI-governed agent architecture that integrates intelligent
agents with blockchain to achieve web-trustworthy tokenization of alternative
assets. In the proposed architecture, autonomous agents orchestrate the
tokenization process (asset verification, valuation, compliance checking, and
lifecycle management), while an AI-driven governance layer monitors agent
behavior and enforces trust through adaptive policies and cryptoeconomic
incentives. We demonstrate that this approach enhances transparency, security,
and compliance in asset tokenization, addressing key concerns around data
authenticity and fraud. A case study on tokenizing real estate assets
illustrates how the architecture mitigates risks (e.g., fraudulent listings and
money laundering) through real-time AI anomaly detection and on-chain
enforcement. Our evaluation and analysis suggest that combining AI governance
with multi-agent systems and blockchain can significantly bolster trust in
tokenized asset ecosystems. This work offers a novel framework for trustworthy
asset tokenization on the web and provides insights for practitioners aiming to
deploy secure, compliant tokenization platforms.

</details>


### [51] [AI-Hybrid TRNG: Kernel-Based Deep Learning for Near-Uniform Entropy Harvesting from Physical Noise](https://arxiv.org/abs/2507.00145)
*Hasan Yiğit*

Main category: cs.CR

TL;DR: AI-Hybrid TRNG是一种深度学习框架，直接从物理噪声中提取近均匀熵，无需量子设备或昂贵射频接收器，适用于资源受限平台。


<details>
  <summary>Details</summary>
Motivation: 传统随机数生成器依赖专用硬件，成本高且体积大。AI-Hybrid TRNG旨在通过低成本射频前端和CPU时序抖动实现高质量随机数生成。

Method: 采用动态内外网络结合自适应自然源和重播种技术，无需量化步骤即可生成32位高熵流，模型体积小于0.5 MB。

Result: 生成的随机数通过NIST SP 800-22测试及19项定制统计测试，满足密码学标准，且无预测偏差，适用于MCU和FPGA等平台。

Conclusion: AI-Hybrid TRNG通过硬件解耦扩展了高完整性随机数生成器的应用范围，涵盖安全系统、加密协议及边缘设备等领域。

Abstract: AI-Hybrid TRNG is a deep-learning framework that extracts near-uniform
entropy directly from physical noise, eliminating the need for bulky quantum
devices or expensive laboratory-grade RF receivers. Instead, it relies on a
low-cost, thumb-sized RF front end, plus CPU-timing jitter, for training, and
then emits 32-bit high-entropy streams without any quantization step.
  Unlike deterministic or trained artificial intelligence random number
generators (RNGs), our dynamic inner-outer network couples adaptive natural
sources and reseeding, yielding truly unpredictable and autonomous sequences.
Generated numbers pass the NIST SP 800-22 battery better than a CPU-based
method. It also passes nineteen bespoke statistical tests for both bit- and
integer-level analysis. All results satisfy cryptographic standards, while
forward and backward prediction experiments reveal no exploitable biases. The
model's footprint is below 0.5 MB, making it deployable on MCUs and FPGA soft
cores, as well as suitable for other resource-constrained platforms.
  By detaching randomness quality from dedicated hardware, AI-Hybrid TRNG
broadens the reach of high-integrity random number generators across secure
systems, cryptographic protocols, embedded and edge devices, stochastic
simulations, and server applications that need randomness.

</details>


### [52] [Plug. Play. Persist. Inside a Ready-to-Go Havoc C2 Infrastructure](https://arxiv.org/abs/2507.00189)
*Alessio Di Santo*

Main category: cs.CR

TL;DR: 该分析揭示了一起利用Azure虚拟机作为攻击节点的复杂网络攻击，攻击者通过过时的Apache服务器分发恶意工具，并利用公开漏洞进行初始访问，最终部署Havoc Demon植入程序进行持久控制。


<details>
  <summary>Details</summary>
Motivation: 研究旨在剖析攻击者如何利用云服务漏洞和高级技术手段（如反射加载、内存免杀）实施网络攻击，以提升防御策略。

Method: 攻击者通过伪造Google登录通知的钓鱼页面获取凭证，随后使用PowerShell禁用AMSI并内存加载恶意代码，最终通过Havoc Demon植入程序建立持久C2通道。工具包包含Chisel、PsExec等横向移动工具。

Result: 攻击链暴露了攻击者对注册表、软件限制策略的深度操作，并利用加密DLL保护流量。开发者身份线索（tonzking123/thobt）表明其技术娴熟但忽视隐蔽性。

Conclusion: 攻击者技术高超但轻视隐蔽性，依赖Havoc的模块化及合法云服务混淆恶意流量，凸显企业需加强漏洞修复与异常流量监测。

Abstract: This analysis focuses on a single Azure-hosted Virtual Machine at
52.230.23.114 that the adversary converted into an all-in-one delivery, staging
and Command-and-Control node. The host advertises an out-of-date Apache 2.4.52
instance whose open directory exposes phishing lures, PowerShell loaders,
Reflective Shell-Code, compiled Havoc Demon implants and a toolbox of
lateral-movement binaries; the same server also answers on 8443/80 for
encrypted beacon traffic. The web tier is riddled with publicly documented
critical vulnerabilities, that would have allowed initial code-execution had
the attackers not already owned the device.
  Initial access is delivered through an HTML file that, once de-obfuscated,
perfectly mimics Google Unusual sign-in attempt notification and funnels
victims toward credential collection. A PowerShell command follows: it disables
AMSI in-memory, downloads a Base64-encoded stub, allocates RWX pages and starts
the shell-code without ever touching disk. That stub reconstructs a DLL in
memory using the Reflective-Loader technique and hands control to Havoc Demon
implant. Every Demon variant-32- and 64-bit alike-talks to the same backend,
resolves Windows APIs with hashed look-ups, and hides its activity behind
indirect syscalls.
  Runtime telemetry shows interests in registry under Image File Execution
Options, deliberate queries to Software Restriction Policy keys, and heavy use
of Crypto DLLs to protect payloads and C2 traffic. The attacker toolkit further
contains Chisel, PsExec, Doppelganger and Whisker, some of them re-compiled
under user directories that leak the developer personas tonzking123 and thobt.
Collectively the findings paint a picture of a technically adept actor who
values rapid re-tooling over deep operational security, leaning on Havoc
modularity and on legitimate cloud services to blend malicious flows into
ordinary enterprise traffic.

</details>


### [53] [Addressing malware family concept drift with triplet autoencoder](https://arxiv.org/abs/2507.00348)
*Numan Halit Guldemir,Oluwafemi Olukoya,Jesús Martínez-del-Rincón*

Main category: cs.CR

TL;DR: 本文提出了一种结合监督自编码器和三元组损失的新方法，用于有效识别新型恶意软件家族，通过DBSCAN算法增强分类准确性，并在Android和Windows恶意软件数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 机器学习在网络安全尤其是恶意软件检测中日益重要，但概念漂移（恶意软件特征随时间变化）对检测系统的持续有效性构成挑战。本文专注于解决新型恶意软件家族的识别问题。

Method: 方法结合了监督自编码器和三元组损失，利用度量学习技术和DBSCAN算法，构建清晰且鲁棒的聚类，以提高恶意软件家族分类的准确性和鲁棒性。

Result: 在Android恶意软件数据集和Windows PE恶意软件数据集上的实验表明，该方法能显著提升新型恶意软件家族的检测能力，有效应对动态变化的恶意软件威胁。

Conclusion: 该方法为持续变化的网络安全挑战提供了可靠的解决方案，显著提升了新型恶意软件家族的检测性能，展示了在动态威胁环境中的模型持续有效性。

Abstract: Machine learning is increasingly vital in cybersecurity, especially in
malware detection. However, concept drift, where the characteristics of malware
change over time, poses a challenge for maintaining the efficacy of these
detection systems. Concept drift can occur in two forms: the emergence of
entirely new malware families and the evolution of existing ones. This paper
proposes an innovative method to address the former, focusing on effectively
identifying new malware families. Our approach leverages a supervised
autoencoder combined with triplet loss to differentiate between known and new
malware families. We create clear and robust clusters that enhance the accuracy
and resilience of malware family classification by utilizing this metric
learning technique and the Density-Based Spatial Clustering of Applications
with Noise (DBSCAN) algorithm. The effectiveness of our method is validated
using an Android malware dataset and a Windows portable executable (PE) malware
dataset, showcasing its capability to sustain model performance within the
dynamic landscape of emerging malware threats. Our results demonstrate a
significant improvement in detecting new malware families, offering a reliable
solution for ongoing cybersecurity challenges.

</details>


### [54] [Find a Scapegoat: Poisoning Membership Inference Attack and Defense to Federated Learning](https://arxiv.org/abs/2507.00423)
*Wenjin Mo,Zhiyuan Li,Minghong Fang,Mingwei Fang*

Main category: cs.CR

TL;DR: 本文提出了一种针对联邦学习的新型投毒成员推理攻击FedPoisonMIA，并设计了防御机制。实验证明攻击有效，防御方法能显著降低其影响。


<details>
  <summary>Details</summary>
Motivation: 联邦学习(FL)因隐私合规性被广泛采用，但其分布式特性易受投毒攻击。现有攻击多关注模型完整性破坏，对隐私威胁研究不足。

Method: 提出FedPoisonMIA攻击：恶意客户端通过精心构造本地模型更新来推断成员信息；同时设计鲁棒防御机制对抗此类攻击。

Result: 跨多个数据集的实验表明，FedPoisonMIA攻击效果显著，而提出的防御方法能有效降低攻击成功率。

Conclusion: 该研究揭示了FL中投毒攻击对隐私的新威胁，提出的防御方案为保护系统安全提供了可行路径。

Abstract: Federated learning (FL) allows multiple clients to collaboratively train a
global machine learning model with coordination from a central server, without
needing to share their raw data. This approach is particularly appealing in the
era of privacy regulations like the GDPR, leading many prominent companies to
adopt it. However, FL's distributed nature makes it susceptible to poisoning
attacks, where malicious clients, controlled by an attacker, send harmful data
to compromise the model. Most existing poisoning attacks in FL aim to degrade
the model's integrity, such as reducing its accuracy, with limited attention to
privacy concerns from these attacks. In this study, we introduce FedPoisonMIA,
a novel poisoning membership inference attack targeting FL. FedPoisonMIA
involves malicious clients crafting local model updates to infer membership
information. Additionally, we propose a robust defense mechanism to mitigate
the impact of FedPoisonMIA attacks. Extensive experiments across various
datasets demonstrate the attack's effectiveness, while our defense approach
reduces its impact to a degree.

</details>


### [55] [Cyber Attacks Detection, Prevention, and Source Localization in Digital Substation Communication using Hybrid Statistical-Deep Learning](https://arxiv.org/abs/2507.00522)
*Nicola Cibin,Bas Mulder,Herman Carstens,Peter Palensky,Alexandru Ştefanov*

Main category: cs.CR

TL;DR: 本文提出了一种混合统计-深度学习方法，用于检测、预防和定位IEC 61850 SV注入攻击，确保数字化变电站的通信安全。


<details>
  <summary>Details</summary>
Motivation: IEC 61850标准通信协议（如SV）缺乏内置安全功能，易受恶意数据包注入攻击，可能导致故障清除延迟或断路器误操作。现有研究多集中于攻击检测，而忽视了入侵预防系统。

Method: 采用指数修正高斯分布建模通信网络延迟，结合LSTM和Elman循环神经网络检测概率分布异常变化，以最小处理开销丢弃恶意SV帧，保持对延迟变化和时间同步问题的鲁棒性。

Result: 在三个测试平台（工业级设备、硬件在环仿真、虚拟化IED/MU和高保真通信网络）上验证，该方法在非攻击场景下实现近零误报率，适合IEC 61850数字化变电站实际部署。

Conclusion: 该方法有效解决了SV注入攻击的安全隐患，兼具检测精度与实时性，为数字化变电站提供了可靠的网络安全防护方案。

Abstract: The digital transformation of power systems is accelerating the adoption of
IEC 61850 standard. However, its communication protocols, including Sampled
Values (SV), lack built-in security features such as authentication and
encryption, making them vulnerable to malicious packet injection. Such cyber
attacks can delay fault clearance or trigger unintended circuit breaker
operations. While most existing research focuses on detecting cyber attacks in
digital substations, intrusion prevention systems have been disregarded because
of the risk of potential communication network disruptions. This paper proposes
a novel method using hybrid statistical-deep learning for the detection,
prevention, and source localization of IEC 61850 SV injection attacks. The
method uses exponentially modified Gaussian distributions to model
communication network latency and long short-term memory and Elman recurrent
neural network to detect anomalous variations in the estimated probability
distributions. It effectively discards malicious SV frames with minimal
processing overhead and latency, maintains robustness against communication
network latency variation and time-synchronization issues, and guarantees a
near-zero false positive rate in non-attack scenarios. Comprehensive validation
is conducted on three testbeds involving industrial-grade devices,
hardware-in-the-loop simulations, virtualized intelligent electronic devices
and merging units, and high-fidelity emulated communication networks. Results
demonstrate the method's suitability for practical deployment in IEC
61850-compliant digital substations.

</details>


### [56] [BadViM: Backdoor Attack against Vision Mamba](https://arxiv.org/abs/2507.00577)
*Yinghao Wu,Liyan Zhang*

Main category: cs.CR

TL;DR: 本文提出针对视觉状态空间模型(ViM)的新型后门攻击框架BadViM，利用共振频率触发器(RFT)和隐藏状态对齐损失函数，在保持清洁数据准确性的同时实现高攻击成功率，并能抵抗常见防御措施。


<details>
  <summary>Details</summary>
Motivation: 视觉状态空间模型(如ViM)作为视觉Transformer的替代方案，其安全性尤其是后门攻击脆弱性尚未充分研究。本文旨在探索ViM架构的后门攻击可能性。

Method: 提出BadViM攻击框架：1) 设计共振频率触发器(RFT)利用模型频率敏感特性生成隐蔽分布式触发器；2) 提出隐藏状态对齐损失函数，通过操纵模型内部表征使后门图像与目标类隐藏状态对齐。

Result: 实验表明BadViM攻击成功率显著优于基线方法，且保持清洁数据准确性。该攻击对PatchDrop、PatchShuffle和JPEG压缩等常见防御措施具有强鲁棒性。

Conclusion: 研究首次证实ViM架构存在严重后门攻击风险，提出的BadViM框架具有高效性和隐蔽性，为视觉状态空间模型的安全研究提供了重要基准。

Abstract: Vision State Space Models (SSMs), particularly architectures like Vision
Mamba (ViM), have emerged as promising alternatives to Vision Transformers
(ViTs). However, the security implications of this novel architecture,
especially their vulnerability to backdoor attacks, remain critically
underexplored. Backdoor attacks aim to embed hidden triggers into victim
models, causing the model to misclassify inputs containing these triggers while
maintaining normal behavior on clean inputs. This paper investigates the
susceptibility of ViM to backdoor attacks by introducing BadViM, a novel
backdoor attack framework specifically designed for Vision Mamba. The proposed
BadViM leverages a Resonant Frequency Trigger (RFT) that exploits the frequency
sensitivity patterns of the victim model to create stealthy, distributed
triggers. To maximize attack efficacy, we propose a Hidden State Alignment loss
that strategically manipulates the internal representations of model by
aligning the hidden states of backdoor images with those of target classes.
Extensive experimental results demonstrate that BadViM achieves superior attack
success rates while maintaining clean data accuracy. Meanwhile, BadViM exhibits
remarkable resilience against common defensive measures, including PatchDrop,
PatchShuffle and JPEG compression, which typically neutralize normal backdoor
attacks.

</details>


### [57] [The Secrets Must Not Flow: Scaling Security Verification to Large Codebases (extended version)](https://arxiv.org/abs/2507.00595)
*Linard Arquint,Samarth Kishor,Jason R. Koenig,Joey Dodds,Daniel Kroening,Peter Müller*

Main category: cs.CR

TL;DR: 本文提出了一种名为*Diodon*的新方法，通过将代码库分为协议实现（*Core*）和其余部分（*Application*），实现了对大规模代码库的安全验证。该方法结合半自动验证技术和全自动静态分析，确保Application不会影响Core的安全属性。


<details>
  <summary>Details</summary>
Motivation: 现有的程序验证工具虽然能证明安全协议实现的高级属性，但由于需要大量手动操作，难以扩展到大型代码库。Diodon旨在解决这一挑战。

Method: Diodon将代码库分为Core和Application两部分：对Core使用半自动验证技术，对Application使用全自动静态分析，证明其I/O操作与Core的安全相关数据（如密钥）无关，并满足Core的要求。

Result: 在两个案例研究中验证了Diodon的有效性：一个实现了签名的Diffie-Hellman密钥交换，另一个是10万+行代码的Go代码库。通过验证仅占代码1%的Core，在不到三个月的时间内获得了保密性和单射协议保证。

Conclusion: Diodon通过分离Core和Application，结合手动验证和静态分析，实现了对大规模代码库的高效安全验证，并在实际案例中证明了其可行性和有效性。

Abstract: Existing program verifiers can prove advanced properties about security
protocol implementations, but are difficult to scale to large codebases because
of the manual effort required. We develop a novel methodology called *Diodon*
that addresses this challenge by splitting the codebase into the protocol
implementation (the *Core*) and the remainder (the *Application*). This split
allows us to apply powerful semi-automated verification techniques to the
security-critical Core, while fully-automatic static analyses scale the
verification to the entire codebase by ensuring that the Application cannot
invalidate the security properties proved for the Core. The static analyses
achieve that by proving *I/O independence*, i.e., that the I/O operations
within the Application are independent of the Core's security-relevant data
(such as keys), and that the Application meets the Core's requirements. We have
proved Diodon sound by first showing that we can safely allow the Application
to perform I/O independent of the security protocol, and second that manual
verification and static analyses soundly compose. We evaluate Diodon on two
case studies: an implementation of the signed Diffie-Hellman key exchange and a
large (100k+ LoC) production Go codebase implementing a key exchange protocol
for which we obtained secrecy and injective agreement guarantees by verifying a
Core of about 1% of the code with the auto-active program verifier Gobra in
less than three person months.

</details>


### [58] [Integrating Network and Attack Graphs for Service-Centric Impact Analysis](https://arxiv.org/abs/2507.00637)
*Joni Herttuainen,Vesa Kuikka,Kimmo K. Kaski*

Main category: cs.CR

TL;DR: 提出了一种新颖的网络威胁建模方法，通过概率方法分析攻击路径及其对服务的影响，支持多层次攻击分析并辅助制定防护策略。


<details>
  <summary>Details</summary>
Motivation: 理解攻击在微服务间及不同服务间的传播路径，有助于早期检测和缓解网络威胁，提升企业或基础设施网络的安全性。

Method: 采用基于概率的攻击图方法，追踪攻击在服务层、应用层及物理通信网络中的传播，结合网络影响力传播模型评估攻击场景。

Result: 该方法能有效评估多样化攻击场景，并基于用户视角的服务关键性制定防护与缓解措施，辅助安全专家做出明智决策。

Conclusion: 提出的网络影响力传播建模方法为安全专家和系统管理员提供了全面的风险缓解策略支持，增强了网络攻击的早期检测与应对能力。

Abstract: We present a novel methodology for modelling, visualising, and analysing
cyber threats, attack paths, as well as their impact on user services in
enterprise or infrastructure networks of digital devices and services they
provide. Using probabilistic methods to track the propagation of an attack
through attack graphs, via the service or application layers, and on physical
communication networks, our model enables us to analyse cyber attacks at
different levels of detail. Understanding the propagation of an attack within a
service among microservices and its spread between different services or
application servers could help detect and mitigate it early. We demonstrate
that this network-based influence spreading modelling approach enables the
evaluation of diverse attack scenarios and the development of protection and
mitigation measures, taking into account the criticality of services from the
user's perspective. This methodology could also aid security specialists and
system administrators in making well-informed decisions regarding risk
mitigation strategies.

</details>


### [59] [Safe Low Bandwidth SPV: A Formal Treatment of Simplified Payment Verification Protocols and Security Bounds](https://arxiv.org/abs/2507.00740)
*Craig S Wright*

Main category: cs.CR

TL;DR: 本文为比特币白皮书中的简化支付验证（SPV）提供了完整的形式化规范、协议描述和数学证明结构，纠正了流行实现中的误解，证明了SPV在有限对抗假设下的安全性和最优性。


<details>
  <summary>Details</summary>
Motivation: 针对当前SPV实现中的普遍误解，本文旨在从第一性原理重建SPV协议，证明其在数字现金系统中的安全性和可扩展性，并优化低带宽环境下的性能。

Method: 通过符号自动机、Merkle成员关系和证明链支配谓词建立验证模型，结合概率论和博弈论分析，在部分连接、敌对中继网络和对抗性传播延迟下验证协议的活性和安全性。

Result: 研究确定了SPV协议安全运行的经济边界，并引入了自适应轮询和压缩头同步等低带宽优化技术，同时保持正确性。

Conclusion: 本文既是安全SPV实现的蓝图，也是对非验证客户端常见误解的反驳，为数字现金系统提供了可验证交易包含的最优解决方案。

Abstract: This paper presents a complete formal specification, protocol description,
and mathematical proof structure for Simplified Payment Verification (SPV) as
originally defined in the Bitcoin whitepaper \cite{nakamoto2008}. In stark
contrast to the misrepresentations proliferated by popular implementations, we
show that SPV is not only secure under bounded adversarial assumptions but
strictly optimal for digital cash systems requiring scalable and verifiable
transaction inclusion. We reconstruct the SPV protocol from first principles,
grounding its verification model in symbolic automata, Merkle membership
relations, and chain-of-proof dominance predicates. Through rigorous
probabilistic and game-theoretic analysis, we derive the economic bounds within
which the protocol operates securely and verify its liveness and safety
properties under partial connectivity, hostile relay networks, and adversarial
propagation delay. Our specification further introduces low-bandwidth
optimisations such as adaptive polling and compressed header synchronisation
while preserving correctness. This document serves both as a blueprint for
secure SPV implementation and a rebuttal of common misconceptions surrounding
non-validating clients.

</details>


### [60] [A Technique for the Detection of PDF Tampering or Forgery](https://arxiv.org/abs/2507.00827)
*Gabriel Grobler,Sheunesu Makura,Hein Venter*

Main category: cs.CR

TL;DR: 本文提出了一种通过分析PDF文件页面对象来检测文档篡改的新技术，能够识别文本、图像及元数据的变更。


<details>
  <summary>Details</summary>
Motivation: 数字文档的篡改或伪造行为日益普遍，可能引发金融欺诈和声誉损害等严重后果。现有基于哈希或水印的技术无法检测PDF签名或元数据等非视觉元素的篡改。

Method: 该技术利用PDF文档的页面对象结构开发原型系统，通过分析文件底层结构来检测文本、图像和元数据的异常变更。

Result: 原型系统实现了对PDF文档多维度篡改（包括文本内容、图像像素及元数据）的有效检测能力。

Conclusion: 该方法突破了传统技术的局限性，为PDF文档完整性验证提供了更全面的解决方案，在防伪认证领域具有应用价值。

Abstract: Tampering or forgery of digital documents has become widespread, most
commonly through altering images without any malicious intent such as enhancing
the overall appearance of the image. However, there are occasions when
tampering of digital documents can have negative consequences, such as
financial fraud and reputational damage. Tampering can occur through altering a
digital document's text or editing an image's pixels. Many techniques have been
developed to detect whether changes have been made to a document. Most of these
techniques rely on generating hashes or watermarking the document. These
techniques, however, have limitations in that they cannot detect alterations to
portable document format (PDF) signatures or other non-visual aspects, such as
metadata. This paper presents a new technique that can be used to detect
tampering within a PDF document by utilizing the PDF document's file page
objects. The technique employs a prototype that can detect changes to a PDF
document, such as changes made to the text, images, or metadata of the said
file.

</details>


### [61] [On the Surprising Efficacy of LLMs for Penetration-Testing](https://arxiv.org/abs/2507.00829)
*Andreas Happe,Jürgen Cito*

Main category: cs.CR

TL;DR: 本文批判性分析了大型语言模型(LLM)在渗透测试中的惊人效果，探讨了其双重用途挑战及关键影响因素，并分类讨论了当前LLM辅助渗透测试的两种模式，最后指出阻碍广泛采用的安全隐患与伦理困境。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于观察到LLM在渗透测试中出人意料的卓越表现，以及该技术在安全领域引发的双重用途挑战，需系统评估其应用潜力与风险。

Method: 通过系统梳理LLM的技术演进与行业应用史，结合网络杀伤链各阶段案例，采用分类分析法将LLM辅助渗透测试分为交互式'氛围黑客'与全自主系统两类模式。

Result: 研究发现LLM的卓越表现源于：其模式匹配能力与渗透测试需求高度契合、擅长处理动态环境不确定性、以及通过供应商获取预训练模型的低成本优势。同时识别出模型可靠性、安全隐忧、生态成本等六大采纳障碍。

Conclusion: 结论强调需在AI与安全交叉领域建立可靠保障机制，为解决模型稳定性、数字主权、责任归属等伦理技术复合型问题提供未来研究方向。

Abstract: This paper presents a critical examination of the surprising efficacy of
Large Language Models (LLMs) in penetration testing. The paper thoroughly
reviews the evolution of LLMs and their rapidly expanding capabilities which
render them increasingly suitable for complex penetration testing operations.
It systematically details the historical adoption of LLMs in both academic
research and industry, showcasing their application across various offensive
security tasks and covering broader phases of the cyber kill chain. Crucially,
the analysis also extends to the observed adoption of LLMs by malicious actors,
underscoring the inherent dual-use challenge of this technology within the
security landscape.
  The unexpected effectiveness of LLMs in this context is elucidated by several
key factors: the strong alignment between penetration testing's reliance on
pattern-matching and LLMs' core strengths, their inherent capacity to manage
uncertainty in dynamic environments, and cost-effective access to competent
pre-trained models through LLM providers.
  The current landscape of LLM-aided penetration testing is categorized into
interactive 'vibe-hacking' and the emergence of fully autonomous systems. The
paper identifies and discusses significant obstacles impeding wider adoption
and safe deployment. These include critical issues concerning model reliability
and stability, paramount safety and security concerns, substantial monetary and
ecological costs, implications for privacy and digital sovereignty, complex
questions of accountability, and profound ethical dilemmas. This comprehensive
review and analysis provides a foundation for discussion on future research
directions and the development of robust safeguards at the intersection of AI
and security.

</details>


### [62] [Stealtooth: Breaking Bluetooth Security Abusing Silent Automatic Pairing](https://arxiv.org/abs/2507.00847)
*Keiichiro Kimura,Hiroki Kuzuno,Yoshiaki Shiraishi,Masakatu Morii*

Main category: cs.CR

TL;DR: 研究发现蓝牙自动配对功能存在安全漏洞，攻击者可利用此漏洞无声覆盖设备链接密钥，提出名为Stealtooth的新型攻击方式，并验证了10款商用设备的普遍脆弱性。


<details>
  <summary>Details</summary>
Motivation: 商业蓝牙设备广泛采用自动配对功能提升便利性，但其安全影响尚未被充分研究，存在未知攻击面。

Method: 通过滥用自动配对漏洞实现静默密钥覆盖（Stealtooth攻击），结合省电模式技术升级为中间人攻击（MitM Stealtooth），使用普通硬件即可实施。

Result: 测试10家主流厂商设备均存在漏洞，攻击门槛低。部分厂商已根据披露发布补丁。

Conclusion: 揭示了安全性与便利性的根本矛盾，提出设备端和协议层防御方案，呼吁制定标准化自动配对规范。

Abstract: Bluetooth is a pervasive wireless communication technology used by billions
of devices for short-range connectivity. The security of Bluetooth relies on
the pairing process, where devices establish shared long-term keys for secure
communications. However, many commercial Bluetooth devices implement automatic
pairing functions to improve user convenience, creating a previously unexplored
attack surface.
  We present Stealtooth, a novel attack that abuses unknown vulnerabilities in
the automatic pairing functions in commercial Bluetooth devices to achieve
completely silent device link key overwriting. The Stealtooth attack leverages
the fact that Bluetooth audio devices automatically transition to pairing mode
under specific conditions, enabling attackers to hijack pairing processes
without user awareness or specialized tools. We also extend the attack into the
MitM Stealtooth attack, combining automatic pairing abuse with power-saving
mode techniques to enable man-in-the-middle attacks.
  We evaluate the attacks against 10 commercial Bluetooth devices from major
manufacturers, demonstrating widespread vulnerabilities across diverse device
types and manufacturers. Our practical implementation requires only commodity
hardware and open-source software, highlighting the low barrier to entry for
attackers.
  We propose defenses both device and protocol levels, including enhanced user
notifications and standardized automatic pairing guidelines. Our findings
reveal a critical tension between security and usability, showing that current
automatic pairing implementations create systematic vulnerabilities. We
responsibly disclosed our findings to affected vendors, with several already
releasing patches.

</details>


### [63] [The Age of Sensorial Zero Trust: Why We Can No Longer Trust Our Senses](https://arxiv.org/abs/2507.00907)
*Fabio Correa Xavier*

Main category: cs.CR

TL;DR: 本文提出了一种名为'感官零信任'的新安全理念，旨在应对深度伪造和克隆语音等AI生成的威胁，强调对感官信息进行系统性质疑和严格验证。


<details>
  <summary>Details</summary>
Motivation: 随着深度伪造和克隆语音等AI技术成为复杂攻击手段，传统信任模式已无法保障安全，需建立对感官信息的系统性怀疑机制。

Method: 整合了带外验证、视觉语言模型(VLMs)作为取证工具、加密来源追溯及人员培训等概念，将零信任原则扩展到人类感官信息领域。

Result: 基于实证研究和学术成果，构建了一个框架，证明在AI生成内容时代，未经验证的感官信息不可盲目信任。

Conclusion: 呼吁领导者培养方法论怀疑文化，通过严格验证协议保护组织完整性，以应对AI生成现实带来的新型威胁。

Abstract: In a world where deepfakes and cloned voices are emerging as sophisticated
attack vectors, organizations require a new security mindset: Sensorial Zero
Trust [9]. This article presents a scientific analysis of the need to
systematically doubt information perceived through the senses, establishing
rigorous verification protocols to mitigate the risks of fraud based on
generative artificial intelligence. Key concepts, such as Out-of-Band
verification, Vision-Language Models (VLMs) as forensic collaborators,
cryptographic provenance, and human training, are integrated into a framework
that extends Zero Trust principles to human sensory information. The approach
is grounded in empirical findings and academic research, emphasizing that in an
era of AI-generated realities, even our eyes and ears can no longer be
implicitly trusted without verification. Leaders are called to foster a culture
of methodological skepticism to protect organizational integrity in this new
threat landscape.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [64] [DiMo-GUI: Advancing Test-time Scaling in GUI Grounding via Modality-Aware Visual Reasoning](https://arxiv.org/abs/2507.00008)
*Hang Wu,Hongkai Chen,Yujun Cai,Chang Liu,Qingwen Ye,Ming-Hsuan Yang,Yiwei Wang*

Main category: cs.AI

TL;DR: DiMo-GUI是一种无需训练的GUI自然语言查询定位框架，通过动态视觉定位和模态感知优化，解决了GUI中视觉元素多样性和语言歧义性问题。


<details>
  <summary>Details</summary>
Motivation: GUI中视觉元素多样、空间杂乱及语言歧义性使得自然语言查询定位面临独特挑战，需要一种无需额外训练即可精确定位的方法。

Method: 将GUI拆分为文本元素和图标元素，利用通用视觉语言模型独立处理各模态；通过动态生成候选焦点区域并逐步放大子区域来优化定位结果。

Result: 在标准GUI定位基准测试中，DiMo-GUI相比基线推理流程展现出持续改进，验证了模态分离与区域聚焦推理结合的有效性。

Conclusion: DiMo-GUI通过模态感知分层优化策略，无需训练即可在复杂GUI布局中实现精准查询定位，为跨模态推理提供了新思路。

Abstract: Grounding natural language queries in graphical user interfaces (GUIs) poses
unique challenges due to the diversity of visual elements, spatial clutter, and
the ambiguity of language. In this paper, we introduce DiMo-GUI, a
training-free framework for GUI grounding that leverages two core strategies:
dynamic visual grounding and modality-aware optimization. Instead of treating
the GUI as a monolithic image, our method splits the input into textual
elements and iconic elements, allowing the model to reason over each modality
independently using general-purpose vision-language models. When predictions
are ambiguous or incorrect, DiMo-GUI dynamically focuses attention by
generating candidate focal regions centered on the model's initial predictions
and incrementally zooms into subregions to refine the grounding result. This
hierarchical refinement process helps disambiguate visually crowded layouts
without the need for additional training or annotations. We evaluate our
approach on standard GUI grounding benchmarks and demonstrate consistent
improvements over baseline inference pipelines, highlighting the effectiveness
of combining modality separation with region-focused reasoning.

</details>


### [65] [TalentMine: LLM-Based Extraction and Question-Answering from Multimodal Talent Tables](https://arxiv.org/abs/2507.00041)
*Varun Mannam,Fang Wang,Chaochun Liu,Xin Chen*

Main category: cs.AI

TL;DR: 论文提出TalentMine框架，通过LLM增强的语义表表示解决人才管理系统中表格信息检索的语义丢失问题，实验显示其查询准确率达100%，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型难以处理人才文档中的复杂表格关系，现有表格提取方法因语义理解不足导致检索增强聊天应用性能低下，亟需解决表格语义信息丢失的关键瓶颈。

Method: 提出TalentMine框架：1) 系统分析现有表格提取流程的语义丢失问题；2) 采用LLM生成语义增强的表格表示；3) 设计多模态推理方法保留表格结构与语义；4) 实现端到端的检索增强系统集成。

Result: 在员工福利文档测试中，TalentMine实现100%查询准确率（AWS Textract为0%，其视觉Q&A为40%），Claude v3 Haiku模型表现最优。

Conclusion: 该研究通过语义增强的表格表示方法显著提升人才分析任务性能，为表格数据处理提供了LLM集成的新范式，四大贡献涵盖问题分析、方法创新、系统实现与全面评测。

Abstract: In talent management systems, critical information often resides in complex
tabular formats, presenting significant retrieval challenges for conventional
language models. These challenges are pronounced when processing Talent
documentation that requires precise interpretation of tabular relationships for
accurate information retrieval and downstream decision-making. Current table
extraction methods struggle with semantic understanding, resulting in poor
performance when integrated into retrieval-augmented chat applications. This
paper identifies a key bottleneck - while structural table information can be
extracted, the semantic relationships between tabular elements are lost,
causing downstream query failures. To address this, we introduce TalentMine, a
novel LLM-enhanced framework that transforms extracted tables into semantically
enriched representations. Unlike conventional approaches relying on CSV or text
linearization, our method employs specialized multimodal reasoning to preserve
both structural and semantic dimensions of tabular data. Experimental
evaluation across employee benefits document collections demonstrates
TalentMine's superior performance, achieving 100% accuracy in query answering
tasks compared to 0% for standard AWS Textract extraction and 40% for AWS
Textract Visual Q&A capabilities. Our comparative analysis also reveals that
the Claude v3 Haiku model achieves optimal performance for talent management
applications. The key contributions of this work include (1) a systematic
analysis of semantic information loss in current table extraction pipelines,
(2) a novel LLM-based method for semantically enriched table representation,
(3) an efficient integration framework for retrieval-augmented systems as
end-to-end systems, and (4) comprehensive benchmarks on talent analytics tasks
showing substantial improvements across multiple categories.

</details>


### [66] [A collaborative digital twin built on FAIR data and compute infrastructure](https://arxiv.org/abs/2507.00048)
*Thomas M. Deucher,Juan C. Verduzco,Michael Titus,Alejandro Strachan*

Main category: cs.AI

TL;DR: 本文提出了一种基于nanoHUB服务的分布式自驱动实验室(SDL)框架，整合FAIR数据管理与机器学习，通过共享数据库和在线工具加速科学优化任务，并以食品染料配色为案例验证其可行性。


<details>
  <summary>Details</summary>
Motivation: 传统实验优化过程效率低下，且分散的研究团队难以共享数据。通过结合FAIR数据原则与SDL技术，可构建协同实验平台，实现数据互通与智能优化。

Method: 利用nanoHUB平台构建分布式SDL系统：1) 通过Sim2L自动处理实验数据并存入FAIR数据库ResultsDB；2) 开发主动学习工作流，实时更新ML模型指导实验；3) 以食品染料配色为验证案例。

Result: 系统成功实现跨地域协作优化，研究人员可通过网页提交数据并获取动态更新的分析工具。案例表明该框架能有效整合FAIR数据、ML预测和序贯优化，且易于扩展到其他领域。

Conclusion: 基于nanoHUB的SDL框架为科学协作提供了可扩展解决方案，其FAIR数据基础设施与在线优化工具尤其适用于教育资源匮乏场景，未来可推广至更复杂的优化问题。

Abstract: The integration of machine learning with automated experimentation in
self-driving laboratories (SDL) offers a powerful approach to accelerate
discovery and optimization tasks in science and engineering applications. When
supported by findable, accessible, interoperable, and reusable (FAIR) data
infrastructure, SDLs with overlapping interests can collaborate more
effectively. This work presents a distributed SDL implementation built on
nanoHUB services for online simulation and FAIR data management. In this
framework, geographically dispersed collaborators conducting independent
optimization tasks contribute raw experimental data to a shared central
database. These researchers can then benefit from analysis tools and machine
learning models that automatically update as additional data become available.
New data points are submitted through a simple web interface and automatically
processed using a nanoHUB Sim2L, which extracts derived quantities and indexes
all inputs and outputs in a FAIR data repository called ResultsDB. A separate
nanoHUB workflow enables sequential optimization using active learning, where
researchers define the optimization objective, and machine learning models are
trained on-the-fly with all existing data, guiding the selection of future
experiments. Inspired by the concept of ``frugal twin", the optimization task
seeks to find the optimal recipe to combine food dyes to achieve the desired
target color. With easily accessible and inexpensive materials, researchers and
students can set up their own experiments, share data with collaborators, and
explore the combination of FAIR data, predictive ML models, and sequential
optimization. The tools introduced are generally applicable and can easily be
extended to other optimization problems.

</details>


### [67] [SEZ-HARN: Self-Explainable Zero-shot Human Activity Recognition Network](https://arxiv.org/abs/2507.00050)
*Devin Y. De Silva,Sandareka Wickramanayake,Dulani Meedeniya,Sanka Rasnayaka*

Main category: cs.AI

TL;DR: 本文提出了一种新型自解释零样本人体活动识别网络(SEZ-HARN)，能够识别训练中未见的活动并通过骨架视频解释决策过程，在四个基准数据集上验证了其解释性与识别准确性的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有基于IMU传感器的零样本人体活动识别(ZS-HAR)模型存在数据覆盖不足和决策不透明的问题，限制了实际应用。

Method: 开发SEZ-HARN模型，结合零样本学习与可解释性技术，通过生成骨架视频直观展示决策依据。在PAMAP2等四个数据集上与三种黑盒模型对比。

Result: SEZ-HARN在PAMAP2上的零样本识别准确率仅比最优黑盒模型低3%，在其他三个数据集保持相当性能，同时产生真实可理解的解释。

Conclusion: SEZ-HARN在保持竞争力的识别准确率前提下实现了决策透明化，为医疗保健等实际场景提供了可信赖的解决方案。

Abstract: Human Activity Recognition (HAR), which uses data from Inertial Measurement
Unit (IMU) sensors, has many practical applications in healthcare and assisted
living environments. However, its use in real-world scenarios has been limited
by the lack of comprehensive IMU-based HAR datasets that cover a wide range of
activities and the lack of transparency in existing HAR models. Zero-shot HAR
(ZS-HAR) overcomes the data limitations, but current models struggle to explain
their decisions, making them less transparent. This paper introduces a novel
IMU-based ZS-HAR model called the Self-Explainable Zero-shot Human Activity
Recognition Network (SEZ-HARN). It can recognize activities not encountered
during training and provide skeleton videos to explain its decision-making
process. We evaluate the effectiveness of the proposed SEZ-HARN on four
benchmark datasets PAMAP2, DaLiAc, HTD-MHAD and MHealth and compare its
performance against three state-of-the-art black-box ZS-HAR models. The
experiment results demonstrate that SEZ-HARN produces realistic and
understandable explanations while achieving competitive Zero-shot recognition
accuracy. SEZ-HARN achieves a Zero-shot prediction accuracy within 3\% of the
best-performing black-box model on PAMAP2 while maintaining comparable
performance on the other three datasets.

</details>


### [68] [Enhancing Reasoning Capabilities in SLMs with Reward Guided Dataset Distillation](https://arxiv.org/abs/2507.00054)
*Shreyansh Padarha*

Main category: cs.AI

TL;DR: 本文提出AdvDistill框架，通过奖励引导的数据集蒸馏方法提升小语言模型在数学和复杂推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法局限于让学生模型复制教师模型的分布内响应，导致泛化能力不足且计算成本高昂，尤其在推理任务上表现明显。

Method: AdvDistill利用教师模型对每个提示生成多个响应，并通过基于规则的验证器分配奖励，将这些呈正态分布的奖励作为训练学生模型的权重。

Result: 该方法显著提升了学生模型在数学和复杂推理任务上的表现，验证了奖励机制在数据集蒸馏过程中的有效性。

Conclusion: 研究表明，引入奖励引导机制能有效改善小语言模型的推理能力，为高效知识蒸馏提供了新方向。

Abstract: The push to compress and impart the proficiency of Large Language Models
(LLMs) into more deployable and efficient Small Language Models (SLMs) has
benefited from improvements in knowledge distillation (KD) techniques. These
techniques allow a smaller student model to learn from a more capable and
larger teacher model's responses. However, distillation often revolves around
the student model merely copying the teacher's in-distribution responses,
limiting its generalisability. This limitation is amplified on reasoning tasks
and can be computationally expensive. In this study, we propose AdvDistill, a
reward-guided dataset distillation framework. We utilise multiple generations
(responses) from a teacher for each prompt and assign rewards based on
rule-based verifiers. These varying and normally distributed rewards serve as
weights when training student models. Our methods and their subsequent
behavioural analysis demonstrate a significant improvement in student model
performance for mathematical and complex reasoning tasks, showcasing the
efficacy and benefits of incorporating a rewarding mechanism in dataset
distillation processes.

</details>


### [69] [VoyagerVision: Investigating the Role of Multi-modal Information for Open-ended Learning Systems](https://arxiv.org/abs/2507.00079)
*Ethan Smyth,Alessandro Suglia*

Main category: cs.AI

TL;DR: 本文提出VoyagerVision模型，通过视觉反馈增强大型语言模型在空间环境中的理解能力，从而扩展其开放式任务执行潜力，并在Minecraft中成功构建结构。


<details>
  <summary>Details</summary>
Motivation: 研究开放式人工智能（AGI）需要模型能自主选择任务，而大型语言模型（LLM）结合视觉输入可提升空间环境理解能力，扩展任务执行范围。

Method: 基于Voyager框架，开发多模态模型VoyagerVision，利用截图作为视觉反馈，在Minecraft中构建结构。

Result: VoyagerVision在50次系统迭代中平均构建2.75个独特结构，且在平坦世界中的构建单元测试成功率为50%，复杂结构失败较多。

Conclusion: 视觉输入显著增强了模型的空间理解与任务执行能力，VoyagerVision为开放式AGI研究提供了新方向。

Abstract: Open-endedness is an active field of research in the pursuit of capable
Artificial General Intelligence (AGI), allowing models to pursue tasks of their
own choosing. Simultaneously, recent advancements in Large Language Models
(LLMs) such as GPT-4o [9] have allowed such models to be capable of
interpreting image inputs. Implementations such as OMNI-EPIC [4] have made use
of such features, providing an LLM with pixel data of an agent's POV to parse
the environment and allow it to solve tasks. This paper proposes that providing
these visual inputs to a model gives it greater ability to interpret spatial
environments, and as such, can increase the number of tasks it can successfully
perform, extending its open-ended potential. To this aim, this paper proposes
VoyagerVision -- a multi-modal model capable of creating structures within
Minecraft using screenshots as a form of visual feedback, building on the
foundation of Voyager. VoyagerVision was capable of creating an average of 2.75
unique structures within fifty iterations of the system, as Voyager was
incapable of this, it is an extension in an entirely new direction.
Additionally, in a set of building unit tests VoyagerVision was successful in
half of all attempts in flat worlds, with most failures arising in more complex
structures. Project website is available at
https://esmyth-dev.github.io/VoyagerVision.github.io/

</details>


### [70] [Thinking About Thinking: SAGE-nano's Inverse Reasoning for Self-Aware Language Models](https://arxiv.org/abs/2507.00092)
*Basab Jha,Firoj Paudel,Ujjwal Puri,Zhang Yuting,Choi Donghyuk,Wang Junhao*

Main category: cs.AI

TL;DR: 本文提出了一种名为\textbf{逆向推理}的新范式，使大语言模型（LLMs）能够事后分解和解释自身的推理链。通过SAGE-nano模型（40亿参数）的元认知结构，该方法在推理准确性和解释质量上均达到前沿水平。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在复杂推理任务中表现出色，但其决策过程仍被视为黑箱。本文旨在通过逆向推理提升模型的可解释性，填补AI安全性、教育和科学发现中的关键空白。

Method: 采用逆向推理范式，通过元学习框架反转注意力流，使模型能够识别关键决策点并生成推理选择的解释。在AQUA-RAT、CommonsenseQA等基准上进行了全面测试。

Result: SAGE-nano在AQUA-RAT上的推理准确率达到74.6%，解释质量的人类偏好得分为92.1%，性能接近Claude-3.5 Sonnet和GPT-4o等顶级模型。

Conclusion: 逆向推理不仅提高了推理性能，还显著增强了模型的可解释性，为透明AI系统开辟了新途径，并在AI安全性、教育和科学发现领域具有重要意义。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities at
solving complex reasoning tasks with Chain-of-Thought (CoT) prompting, but
their decision-making processes remain somewhat blackbox. We introduce
textbfinverse reasoning, a novel paradigm enabling LLMs to decompose and
explain their own reasoning chains post-hoc. Our approach, used in SAGE-nano, a
4-billion-parameter reasoning model, employs a metacognitive structure that
reflects back via attention processes to identify major decision points and
generate explanations of reasoning choices. While typical CoT approaches are
directed towards forward reasoning generation, inverse reasoning provides
insight into why specific reasoning chains were selected over others. Through
thorough testing of logical reasoning puzzles, math problems and ethical
dilemmas from AQUA-RAT, CommonsenseQA, and customized benchmarks, we
demonstrate that SAGE-nano is at the cutting edge both on reasoning accuracy
(74.6% on AQUA-RAT) and explanation quality (92.1% human preference score) for
its task, and offers performance almost on par with models like Claude-3.5
Sonnet or GPT-4o. Our contributions are: (i) the first rigorous framework for
LLM self-reflection via inverse reasoning, (ii) a novel metalearning framework
to reverse the attention flow, (iii) comprehensive evaluation frameworks for
reasoning transparency, and (iv) evidence that increasing reasoning using
inverse reasoning improves interpretability along with reasoning performance.
Our work creates new avenues for transparent AI systems and closes significant
gaps in AI safety, education, and scientific discovery.

</details>


### [71] [BlackBoxToBlueprint: Extracting Interpretable Logic from Legacy Systems using Reinforcement Learning and Counterfactual Analysis](https://arxiv.org/abs/2507.00180)
*Vidhi Rathore*

Main category: cs.AI

TL;DR: 本文提出了一种基于强化学习的自动化方法，用于从黑盒遗留系统中提取可解释的决策逻辑，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 遗留系统的现代化改造因缺乏文档和难以理解原始决策逻辑而面临挑战，传统方法仅能复制输入输出行为而无法捕捉底层意图。

Method: 使用强化学习代理探索输入空间，通过奖励导致输出变化的操作来识别关键决策边界，收集并聚类这些状态转换，最后用决策树提取人类可读的规则。

Result: 在三种不同复杂度的模拟遗留系统上测试表明，强化学习代理能有效聚焦边界区域探索，提取的规则准确反映了底层系统的核心逻辑。

Conclusion: 该方法为遗留系统迁移期间生成规范和测试用例提供了可靠基础，具有显著的应用潜力。

Abstract: Modernizing legacy software systems is a critical but challenging task, often
hampered by a lack of documentation and understanding of the original system's
intricate decision logic. Traditional approaches like behavioral cloning merely
replicate input-output behavior without capturing the underlying intent. This
paper proposes a novel pipeline to automatically extract interpretable decision
logic from legacy systems treated as black boxes. The approach uses a
Reinforcement Learning (RL) agent to explore the input space and identify
critical decision boundaries by rewarding actions that cause meaningful changes
in the system's output. These counterfactual state transitions, where the
output changes, are collected and clustered using K-Means. Decision trees are
then trained on these clusters to extract human-readable rules that approximate
the system's decision logic near the identified boundaries. I demonstrated the
pipeline's effectiveness on three dummy legacy systems with varying complexity,
including threshold-based, combined-conditional, and non-linear range logic.
Results show that the RL agent successfully focuses exploration on relevant
boundary regions, and the extracted rules accurately reflect the core logic of
the underlying dummy systems, providing a promising foundation for generating
specifications and test cases during legacy migration.

</details>


### [72] [ChatGPT produces more "lazy" thinkers: Evidence of cognitive engagement decline](https://arxiv.org/abs/2507.00181)
*Georgios P. Georgiou*

Main category: cs.AI

TL;DR: 研究发现ChatGPT等生成式AI工具可能降低学生在学术写作中的认知投入，呼吁教育策略需促进对AI内容的主动反思。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在教育中的应用增加，人们担忧其可能削弱深度思考与主动学习，本研究旨在探讨生成式AI工具对学生认知投入的影响。

Method: 采用实验设计，随机分配学生至ChatGPT辅助组或对照组，通过结构化议论文写作任务及认知投入量表（CES-AI）评估心理努力、注意力等维度。

Result: ChatGPT辅助组的认知投入得分显著低于对照组，表明AI可能导致认知卸载效应。

Conclusion: 研究警示AI辅助可能损害自主学习与深度认知参与，建议教育实践中需设计策略引导学生对AI内容进行主动反思。

Abstract: Despite the increasing use of large language models (LLMs) in education,
concerns have emerged about their potential to reduce deep thinking and active
learning. This study investigates the impact of generative artificial
intelligence (AI) tools, specifically ChatGPT, on the cognitive engagement of
students during academic writing tasks. The study employed an experimental
design with participants randomly assigned to either an AI-assisted (ChatGPT)
or a non-assisted (control) condition. Participants completed a structured
argumentative writing task followed by a cognitive engagement scale (CES), the
CES-AI, developed to assess mental effort, attention, deep processing, and
strategic thinking. The results revealed significantly lower cognitive
engagement scores in the ChatGPT group compared to the control group. These
findings suggest that AI assistance may lead to cognitive offloading. The study
contributes to the growing body of literature on the psychological implications
of AI in education and raises important questions about the integration of such
tools into academic practice. It calls for pedagogical strategies that promote
active, reflective engagement with AI-generated content to avoid compromising
self-regulated learning and deep cognitive involvement of students.

</details>


### [73] [Holistic Artificial Intelligence in Medicine; improved performance and explainability](https://arxiv.org/abs/2507.00205)
*Periklis Petridis,Georgios Margaritis,Vasiliki Stoumpou,Dimitris Bertsimas*

Main category: cs.AI

TL;DR: 本文提出了xHAIM框架，通过生成式AI提升医疗AI的可解释性，将多模态数据融合与临床任务结合，显著提高了预测性能（AUC从79.9%提升至90.3%）并实现决策溯源。


<details>
  <summary>Details</summary>
Motivation: 现有HAIM框架存在任务无关数据处理和可解释性不足的问题，需开发能自动识别任务相关数据、生成患者摘要并提供临床解释的新方法。

Method: xHAIM框架包含四步：(1)跨模态自动识别任务相关患者数据，(2)生成综合患者摘要，(3)利用摘要改进预测模型，(4)通过关联预测与患者特定医学知识提供临床解释。

Result: 在HAIM-MIMIC-MM数据集测试中，xHAIM将胸部病理和手术任务的AUC平均值从79.9%提升至90.3%，并实现预测结果与患者数据的可交互溯源。

Conclusion: xHAIM将AI从黑盒预测器转化为可解释的临床决策支持系统，通过关联预测与具体医疗数据，弥合了AI进步与临床实用性之间的鸿沟。

Abstract: With the increasing interest in deploying Artificial Intelligence in
medicine, we previously introduced HAIM (Holistic AI in Medicine), a framework
that fuses multimodal data to solve downstream clinical tasks. However, HAIM
uses data in a task-agnostic manner and lacks explainability. To address these
limitations, we introduce xHAIM (Explainable HAIM), a novel framework
leveraging Generative AI to enhance both prediction and explainability through
four structured steps: (1) automatically identifying task-relevant patient data
across modalities, (2) generating comprehensive patient summaries, (3) using
these summaries for improved predictive modeling, and (4) providing clinical
explanations by linking predictions to patient-specific medical knowledge.
Evaluated on the HAIM-MIMIC-MM dataset, xHAIM improves average AUC from 79.9%
to 90.3% across chest pathology and operative tasks. Importantly, xHAIM
transforms AI from a black-box predictor into an explainable decision support
system, enabling clinicians to interactively trace predictions back to relevant
patient data, bridging AI advancements with clinical utility.

</details>


### [74] [Learning for routing: A guided review of recent developments and future directions](https://arxiv.org/abs/2507.00218)
*Fangting Zhou,Attila Lischka,Balazs Kulcsar,Jiaming Wu,Morteza Haghir Chehreghani,Gilbert Laporte*

Main category: cs.AI

TL;DR: 本文综述了机器学习在解决NP难组合优化问题（如TSP和VRP）中的应用进展，提出了一种基于ML的路由方法分类法，旨在整合传统运筹学方法与前沿ML技术。


<details>
  <summary>Details</summary>
Motivation: 由于NP难组合优化问题的固有复杂性，精确算法计算时间过长，而启发式算法无法保证最优解。近年来ML模型的成功促使研究者探索ML技术以提升这类路由问题的求解效果。

Method: 提出将ML路由方法分为构造型和改进型两类，并建立分类体系以匹配不同问题特征，整合传统运筹学与先进ML技术。

Result: 构建了结构化框架来指导未来研究，特别是针对新兴VRP变体的解决方案开发。

Conclusion: 该综述为传统方法与ML技术的融合提供了系统框架，有望推动组合优化领域的发展，并有效应对复杂路由问题的挑战。

Abstract: This paper reviews the current progress in applying machine learning (ML)
tools to solve NP-hard combinatorial optimization problems, with a focus on
routing problems such as the traveling salesman problem (TSP) and the vehicle
routing problem (VRP). Due to the inherent complexity of these problems, exact
algorithms often require excessive computational time to find optimal
solutions, while heuristics can only provide approximate solutions without
guaranteeing optimality. With the recent success of machine learning models,
there is a growing trend in proposing and implementing diverse ML techniques to
enhance the resolution of these challenging routing problems. We propose a
taxonomy categorizing ML-based routing methods into construction-based and
improvement-based approaches, highlighting their applicability to various
problem characteristics. This review aims to integrate traditional OR methods
with state-of-the-art ML techniques, providing a structured framework to guide
future research and address emerging VRP variants.

</details>


### [75] [SafeMobile: Chain-level Jailbreak Detection and Automated Evaluation for Multimodal Mobile Agents](https://arxiv.org/abs/2507.00841)
*Siyuan Liang,Tianmeng Fang,Zhe Liu,Aishan Liu,Yan Xiao,Jinyuan He,Ee-Chien Chang,Xiaochun Cao*

Main category: cs.AI

TL;DR: 本文探讨了多模态基础模型在智能代理系统中的安全风险，提出了一种结合行为序列信息的风险识别机制及基于大语言模型的自动化辅助评估方案，初步验证表明该方法能提升风险行为识别率并降低越狱概率。


<details>
  <summary>Details</summary>
Motivation: 随着多模态基础模型在智能代理系统中的广泛应用，系统面临越狱风险增加的问题，现有安全措施在复杂交互场景下存在局限性，缺乏高效一致的风险评估方法。

Method: 通过构建融合行为序列信息的风险判别机制，设计基于大语言模型的自动化辅助评估方案，并在代表性高风险任务中进行初步验证。

Result: 实验结果表明，该方法能一定程度提升风险行为识别能力，辅助降低代理被越狱的概率。

Conclusion: 本研究为多模态智能代理系统的安全风险建模与防护提供了有价值的参考，未来需进一步优化风险识别机制与评估体系。

Abstract: With the wide application of multimodal foundation models in intelligent
agent systems, scenarios such as mobile device control, intelligent assistant
interaction, and multimodal task execution are gradually relying on such large
model-driven agents. However, the related systems are also increasingly exposed
to potential jailbreak risks. Attackers may induce the agents to bypass the
original behavioral constraints through specific inputs, and then trigger
certain risky and sensitive operations, such as modifying settings, executing
unauthorized commands, or impersonating user identities, which brings new
challenges to system security. Existing security measures for intelligent
agents still have limitations when facing complex interactions, especially in
detecting potentially risky behaviors across multiple rounds of conversations
or sequences of tasks. In addition, an efficient and consistent automated
methodology to assist in assessing and determining the impact of such risks is
currently lacking. This work explores the security issues surrounding mobile
multimodal agents, attempts to construct a risk discrimination mechanism by
incorporating behavioral sequence information, and designs an automated
assisted assessment scheme based on a large language model. Through preliminary
validation in several representative high-risk tasks, the results show that the
method can improve the recognition of risky behaviors to some extent and assist
in reducing the probability of agents being jailbroken. We hope that this study
can provide some valuable references for the security risk modeling and
protection of multimodal intelligent agent systems.

</details>


### [76] [ASTRO: Teaching Language Models to Reason by Reflecting and Backtracking In-Context](https://arxiv.org/abs/2507.00417)
*Joongwon Kim,Anirudh Goyal,Liang Tan,Hannaneh Hajishirzi,Srinivasan Iyer,Tianlu Wang*

Main category: cs.AI

TL;DR: ASTRO框架通过蒙特卡洛树搜索生成的自然语言数据集训练语言模型，使其具备类似搜索算法的推理能力，显著提升了Llama 3在数学问题上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有开源推理模型依赖已具备强推理能力的基座模型，ASTRO旨在为包括Llama 3在内的非专业推理模型注入结构化搜索行为。

Method: 1. 使用蒙特卡洛树搜索生成数学问题求解轨迹的合成数据集\n2. 将搜索轨迹转化为包含成功与失败恢复的自然语言思维链\n3. 通过强化学习与可验证奖励机制进一步优化模型

Result: Llama 3模型在MATH-500（+16.0%）、AMC 2023（+26.9%）和AIME 2024（+20.0%）上取得显著提升，尤其在需要迭代修正的难题上表现突出。

Conclusion: 基于搜索启发的训练方法为开源大语言模型提供了系统化的推理能力增强路径。

Abstract: We introduce ASTRO, the "Autoregressive Search-Taught Reasoner", a framework
for training language models to reason like search algorithms, explicitly
leveraging self-reflection, backtracking, and exploration in their outputs.
Recently, training large language models (LLMs) via reinforcement learning (RL)
has led to the advent of reasoning models with greatly enhanced reasoning
capabilities. Open-source replications of reasoning models, while successful,
build upon models that already exhibit strong reasoning capabilities along with
search behavior observed even before RL. As a result, it is yet unclear how to
boost the reasoning capabilities of other non-reasoner models including Llama
3. ASTRO teaches such models to internalize structured search behavior through
a synthetic dataset derived from Monte Carlo Tree Search (MCTS) over
mathematical problem-solving trajectories. By converting search traces into
natural language chain-of-thoughts that capture both successes and recoveries
from failure, ASTRO bootstraps models with a rich prior for exploration during
RL. We finetune our models on these search-derived traces and further improve
performance via RL with verifiable rewards. We apply ASTRO to the Llama 3
family of models and achieve absolute performance gains of 16.0% on MATH-500,
26.9% on AMC 2023, and 20.0% on AIME 2024, especially improving upon
challenging problems that require iterative correction. Our results demonstrate
that search-inspired training offers a principled way to instill robust
reasoning capabilities into open LLMs.

</details>


### [77] [Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning](https://arxiv.org/abs/2507.00432)
*Maggie Huan,Yuetai Li,Tuney Zheng,Xiaoyu Xu,Seungone Kim,Minxin Du,Radha Poovendran,Graham Neubig,Xiang Yue*

Main category: cs.AI

TL;DR: 研究发现，数学推理能力强的语言模型在其他领域表现不佳，强化学习调优的模型比监督微调模型具有更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型在数学推理上的进步是否能推广到其他领域，避免狭隘的过拟合现象。

Method: 评估20多个开源推理调优模型在数学、科学问答、规划、编程等任务的表现，并对Qwen3-14B模型进行数学数据调优的对比实验。

Result: 大多数数学表现优异的模型在其他领域未能保持优势；强化学习调优的模型泛化能力更强，而监督微调会导致模型遗忘通用能力。

Conclusion: 需重新思考后训练方法，减少对监督微调蒸馏数据的依赖，以提升推理模型的广泛适用性。

Abstract: Math reasoning has become the poster child of progress in large language
models (LLMs), with new models rapidly surpassing human-level performance on
benchmarks like MATH and AIME. But as math leaderboards improve week by week,
it is worth asking: do these gains reflect broader problem-solving ability or
just narrow overfitting? To answer this question, we evaluate over 20
open-weight reasoning-tuned models across a broad suite of tasks, including
math, scientific QA, agent planning, coding, and standard
instruction-following. We surprisingly find that most models that succeed in
math fail to transfer their gains to other domains. To rigorously study this
phenomenon, we conduct controlled experiments on Qwen3-14B models using
math-only data but different tuning methods. We find that reinforcement
learning (RL)-tuned models generalize well across domains, while supervised
fine-tuning (SFT)-tuned models often forget general capabilities. Latent-space
representation and token-space distribution shift analyses reveal that SFT
induces substantial representation and output drift, while RL preserves
general-domain structure. Our results suggest a need to rethink standard
post-training recipes, particularly the reliance on SFT-distilled data for
advancing reasoning models.

</details>


### [78] [A Robust Algorithm for Non-IID Machine Learning Problems with Convergence Analysis](https://arxiv.org/abs/2507.00810)
*Qing Xu,Xiaohua Xuan*

Main category: cs.AI

TL;DR: 本文提出了一种基于非光滑优化、二次规划和迭代过程的改进数值算法，用于求解极小极大问题，并在梯度连续性和有界性等温和假设下提供了严格的收敛性证明。


<details>
  <summary>Details</summary>
Motivation: 极小极大问题在鲁棒优化和不平衡学习等多个领域具有广泛应用，但现有算法在效率和收敛性方面存在不足，因此需要开发更高效的数值解法。

Method: 结合非光滑优化技术、二次规划框架和迭代过程，构建了一种新型数值算法，并通过理论分析确保其数学严谨性。

Result: 在满足梯度连续性及有界性条件下，算法被证明具有收敛性，且适用于鲁棒优化等实际应用场景。

Conclusion: 该算法为极小极大问题提供了理论可靠且适用范围广的解决方案，未来可进一步拓展至更复杂的优化问题。

Abstract: In this paper, we propose an improved numerical algorithm for solving minimax
problems based on nonsmooth optimization, quadratic programming and iterative
process. We also provide a rigorous proof of convergence for our algorithm
under some mild assumptions, such as gradient continuity and boundedness. Such
an algorithm can be widely applied in various fields such as robust
optimization, imbalanced learning, etc.

</details>


### [79] [Advancing Local Search in SMT-NRA with MCSAT Integration](https://arxiv.org/abs/2507.00557)
*Tianyi Ding,Haokun Li,Xinpeng Ni,Bican Xia,Tianqi Zhao*

Main category: cs.AI

TL;DR: 本文提出了一种改进的局部搜索方法2d-LS，用于非线性实数算术的可满足性模理论(SMT-NRA)，结合了MCSAT框架和样本单元投影算子，提高了搜索效率。


<details>
  <summary>Details</summary>
Motivation: 为了提升SMT-NRA问题的局部搜索效率，研究者需要扩展现有的LS框架，并整合MCSAT等先进技术以优化搜索过程。

Method: 引入了二维单元跳跃(2d-cell-jump)操作，扩展了局部搜索框架2d-LS，整合了MCSAT框架和样本单元投影算子，并设计了结合MCSAT、2d-LS和OpenCAD的混合框架。

Result: 实验结果表明，所提出的方法显著提高了局部搜索的性能，验证了其有效性。

Conclusion: 通过结合2d-LS、MCSAT和OpenCAD的混合框架，本文成功提升了SMT-NRA问题的求解效率，为相关领域的研究提供了新的思路。

Abstract: In this paper, we advance local search for Satisfiability Modulo the Theory
of Nonlinear Real Arithmetic (SMT-NRA for short). First, we introduce a
two-dimensional cell-jump move, called \emph{$2d$-cell-jump}, generalizing the
key operation, cell-jump, of the local search method for SMT-NRA. Then, we
propose an extended local search framework, named \emph{$2d$-LS} (following the
local search framework, LS, for SMT-NRA), integrating the model constructing
satisfiability calculus (MCSAT) framework to improve search efficiency. To
further improve the efficiency of MCSAT, we implement a recently proposed
technique called \emph{sample-cell projection operator} for MCSAT, which is
well suited for CDCL-style search in the real domain and helps guide the search
away from conflicting states. Finally, we design a hybrid framework for SMT-NRA
combining MCSAT, $2d$-LS and OpenCAD, to improve search efficiency through
information exchange. The experimental results demonstrate improvements in
local search performance, highlighting the effectiveness of the proposed
methods.

</details>


### [80] [Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess](https://arxiv.org/abs/2507.00726)
*Dongyoon Hwang,Hojoon Lee,Jaegul Choo,Dongmin Park,Jongho Park*

Main category: cs.AI

TL;DR: 研究探索了通过强化学习（RL）提升大语言模型（LLM）在象棋中的战略推理能力，发现基于知识蒸馏的密集奖励优于稀疏奖励，但模型表现仍远低于专家水平，归因于预训练模型对象棋的内在理解不足。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在提升大语言模型的数学推理能力上显示出潜力，但其在战略推理（如象棋）中的应用尚未充分探索。本研究旨在填补这一空白。

Method: 利用经过象棋预训练的动作价值网络为LLM的输出走棋质量提供密集奖励，视为一种知识蒸馏方法，并与稀疏二元奖励进行对比实验。

Result: 实验表明，基于蒸馏的密集奖励通常优于稀疏奖励，但所有模型的表现均远未达到专家水平。进一步分析发现，预训练模型对象棋的内在理解不足是主要限制因素。

Conclusion: 强化学习虽能部分提升LLM的战略推理能力，但预训练模型的内在理解缺陷可能无法仅通过RL完全克服，暗示需结合其他方法以进一步提升性能。

Abstract: While reinforcement learning (RL) for large language models (LLMs) has shown
promise in mathematical reasoning, strategic reasoning for LLMs using RL
remains largely unexplored. We investigate whether LLMs can develop strategic
reasoning capabilities through RL in chess. To this end, we leverage a
chess-pretrained action-value network to provide dense reward on the LLM's
output move quality, which can be seen as a form of knowledge distillation. Our
experiments show that our distillation-based dense rewards often outperform
sparse binary rewards. However, surprisingly, all models plateau far below
expert levels. We provide SFT and RL ablations on chess reasoning training and
find evidence that this limitation stems from a deficit in the pretrained
models' internal understanding of chess--a deficit which RL alone may not be
able to fully overcome.

</details>


### [81] [Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact](https://arxiv.org/abs/2507.00951)
*Rizwan Qureshi,Ranjan Sapkota,Abbas Shah,Amgad Muneer,Anas Zafar,Ashmal Vayani,Maged Shoman,Abdelrahman B. M. Eldaly,Kai Zhang,Ferhat Sadak,Shaina Raza,Xinqi Fan,Ravid Shwartz-Ziv,Hong Yan,Vinjia Jain,Aman Chadha,Manoj Karkee,Jia Wu,Philip Torr,Seyedali Mirjalili*

Main category: cs.AI

TL;DR: 本文探讨了人工通用智能（AGI）的发展现状与挑战，分析了当前模型的局限性，并提出了结合多学科方法的AGI发展路径，强调模块化推理、记忆整合与多智能体协调的关键作用。


<details>
  <summary>Details</summary>
Motivation: 尽管现有AI模型（如GPT-4.5、DeepSeek等）展现出多模态流畅性和部分推理能力，但其基于令牌预测的局限性促使研究者探索更接近人类思维的AGI实现路径。

Method: 通过跨学科综合研究（AI、认知神经科学、心理学等），提出Agentic RAG框架、信息压缩、测试时适应等方法，并重新审视视觉语言模型（VLMs）在具身理解中的作用。

Result: 研究表明：真正的智能需整合记忆与推理，通过模块化、交互式组件实现自适应行为；神经符号系统与强化学习的进步正在弥合统计学习与目标导向认知的鸿沟。

Conclusion: AGI的实现需要突破科学、技术和伦理挑战，其核心在于模块化组件协同、记忆-推理整合以及压缩驱动的自适应行为，而非单纯依赖模型规模。

Abstract: Can machines truly think, reason and act in domains like humans? This
enduring question continues to shape the pursuit of Artificial General
Intelligence (AGI). Despite the growing capabilities of models such as GPT-4.5,
DeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, which exhibit multimodal
fluency and partial reasoning, these systems remain fundamentally limited by
their reliance on token-level prediction and lack of grounded agency. This
paper offers a cross-disciplinary synthesis of AGI development, spanning
artificial intelligence, cognitive neuroscience, psychology, generative models,
and agent-based systems. We analyze the architectural and cognitive foundations
of general intelligence, highlighting the role of modular reasoning, persistent
memory, and multi-agent coordination. In particular, we emphasize the rise of
Agentic RAG frameworks that combine retrieval, planning, and dynamic tool use
to enable more adaptive behavior. We discuss generalization strategies,
including information compression, test-time adaptation, and training-free
methods, as critical pathways toward flexible, domain-agnostic intelligence.
Vision-Language Models (VLMs) are reexamined not just as perception modules but
as evolving interfaces for embodied understanding and collaborative task
completion. We also argue that true intelligence arises not from scale alone
but from the integration of memory and reasoning: an orchestration of modular,
interactive, and self-improving components where compression enables adaptive
behavior. Drawing on advances in neurosymbolic systems, reinforcement learning,
and cognitive scaffolding, we explore how recent architectures begin to bridge
the gap between statistical learning and goal-directed cognition. Finally, we
identify key scientific, technical, and ethical challenges on the path to AGI.

</details>


### [82] [Enhancing LLM Agent Safety via Causal Influence Prompting](https://arxiv.org/abs/2507.00979)
*Dongyoon Hahm,Woogyeol Jin,June Suk Choi,Sungsoo Ahn,Kimin Lee*

Main category: cs.AI

TL;DR: 本文提出CIP技术，利用因果影响图(CID)提升基于大语言模型的自主代理安全性，通过结构化因果表示识别和减轻决策风险，实验证明其在代码执行和移动设备控制任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型驱动的自主代理在辅助任务中展现潜力，确保其行为安全可靠成为关键。现有方法缺乏对决策过程中因果关系的系统性分析，可能导致意外后果。

Method: 方法分为三步：(1)根据任务规范初始化CID框架决策流程，(2)基于CID指导代理与环境交互，(3)通过观察行为结果迭代优化CID结构。CID提供了因果关系的结构化表示。

Result: 实验结果表明，该方法显著提升了代码执行和移动设备控制任务的安全性，证实了CID在风险预测和安全决策中的有效性。

Conclusion: CIP技术通过因果影响图实现了自主代理决策过程的可解释风险控制，为LLM驱动的智能系统安全部署提供了新思路。

Abstract: As autonomous agents powered by large language models (LLMs) continue to
demonstrate potential across various assistive tasks, ensuring their safe and
reliable behavior is crucial for preventing unintended consequences. In this
work, we introduce CIP, a novel technique that leverages causal influence
diagrams (CIDs) to identify and mitigate risks arising from agent
decision-making. CIDs provide a structured representation of cause-and-effect
relationships, enabling agents to anticipate harmful outcomes and make safer
decisions. Our approach consists of three key steps: (1) initializing a CID
based on task specifications to outline the decision-making process, (2)
guiding agent interactions with the environment using the CID, and (3)
iteratively refining the CID based on observed behaviors and outcomes.
Experimental results demonstrate that our method effectively enhances safety in
both code execution and mobile device control tasks.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [83] [Reducing Profile-Based Matching to the Maximum Weight Matching Problem](https://arxiv.org/abs/2507.00047)
*Seongbeom Park*

Main category: cs.DM

TL;DR: 本文提出了一种基于配置文件的匹配问题解决方案，通过将问题转化为最大权重匹配问题，并采用混合基数数值系统表示效用函数，显著提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 基于配置文件的匹配问题（如排名最大化匹配、公平匹配和权重最大化匹配）虽然可以转化为最大权重匹配问题，但由于权重过大导致效率低下。本文旨在找到一种高效的权重函数表示方法。

Method: 通过将效用函数表示为基数为$(2U_i+1)$的混合基数数值系统，将配置文件匹配问题转化为最大权重匹配问题。算法复杂度为$O(m\sqrt{n}(\log{n} + \sum_{i=1}^{r}\log{U_i}))$。

Result: 证明了该权重函数能有效找到最优匹配，并给出了排名最大化/公平/权重最大化匹配的权重下界。此外，还展示了验证最大权重匹配的算法可简化为排名最大化匹配问题。

Conclusion: 基于配置文件的算法在学校抽签等实际应用中表现出高效性，为解决复杂匹配问题提供了新思路。

Abstract: The profile-based matching problem is the problem of finding a matching that
optimizes profile from an instance $(G, r, \langle u_1, \dots, u_r \rangle)$,
where $G$ is a bipartite graph $(A \cup B, E)$, $r$ is the number of utility
functions, and $u_i: E \to \{ 0, 1, \dots, U_i \}$ is utility functions for $1
\le i \le r$. A matching is optimal if the matching maximizes the sum of the
1st utility, subject to this, maximizes the sum of the 2nd utility, and so on.
The profile-based matching can express rank-maximal matching
\cite{irving2006rank}, fair matching \cite{huang2016fair}, and weight-maximal
matching \cite{huang2012weight}. These problems can be reduced to maximum
weight matching problems, but the reduction is known to be inefficient due to
the huge weights.
  This paper presents the condition for a weight function to find an optimal
matching by reducing profile-based matching to the maximum weight matching
problem. It is shown that a weight function which represents utilities as a
mixed-radix numeric system with base-$(2U_i+1)$ can be used, so the complexity
of the problem is $O(m\sqrt{n}(\log{n} + \sum_{i=1}^{r}\log{U_i}))$ for $n =
|V|$, $m = |E|$. In addition, it is demonstrated that the weight lower bound
for rank-maximal/fair/weight-maximal matching, better computational complexity
for fair/weight-maximal matching, and an algorithm to verify a maximum weight
matching can be reduced to rank-maximal matching. Finally, the effectiveness of
the profile-based algorithm is evaluated with real data for school choice
lottery.

</details>


### [84] [Verification of Hamiltonian Path Conjecture (BHR Conjecture) for Integers up to p=31](https://arxiv.org/abs/2507.00059)
*Ranjan N Naik*

Main category: cs.DM

TL;DR: 本文针对BHR猜想提出了一种基于频率划分和局部/全局调整操作的探索方法，并通过Python程序验证了p < 37时的哈密顿路径存在性，改进了Mariusz Meszka对素数p ≤ 23的结果。


<details>
  <summary>Details</summary>
Motivation: BHR猜想（2006）提出对于任意素数p和模p的(p-1)个正整数多重集L，完全图K_p中存在连续边长度由L给出的哈密顿路径。本文旨在通过计算方法推进该猜想的验证范围。

Method: 采用频率划分理论结合局部/全局调整操作与回溯算法，开发Python程序系统性地搜索有效路径。数学策略聚焦于通过结构变换满足猜想条件。

Result: 实验验证了p < 37（包括所有素数p ≤ 23）时猜想成立，计算范围超越先前Meszka的成果，程序成功构建出符合要求的哈密顿路径。

Conclusion: 频率划分与调整操作的结合有效扩展了BHR猜想的验证边界，计算方法为后续理论证明提供了数据支撑，但一般情形仍需进一步研究。

Abstract: The BHR (Buratti-Horak-Rosa) Conjecture (2006) proposes that for every p and
a multiset L of (p-1) positive integers modulo p, there exists a Hamiltonian
path in the Complete Graph Kp with consecutive edge lengths given by the
elements of L. In this article, we outline an approach to the conjecture based
on frequency partitions and local/global adjustment operations and
backtracking. We describe the mathematical strategy, experimental evidence, and
implementation in a Python Program to explore valid Hamiltonian paths p < 37.
This is a result an improvement over by Mariusz Meszka for all primes up to 23
(included) with the aid of a computer.

</details>


### [85] [$σ$-Maximal Ancestral Graphs](https://arxiv.org/abs/2507.00093)
*Binghua Yao,Joris M. Mooij*

Main category: cs.DM

TL;DR: 本文提出了一种名为$\sigma$-最大祖先图（$\sigma$-MAGs）的新型图形对象，用于表示可能含有循环因果关系的带隐变量的有向图（DGs），扩展了传统最大祖先图（MAGs）仅适用于无环有向图（DAGs）的限制。


<details>
  <summary>Details</summary>
Motivation: 传统最大祖先图（MAGs）无法表示循环因果关系，这限制了其在因果发现中的应用。本文旨在解决这一限制，提出能够表示循环因果关系的图形模型。

Method: 引入并研究了$\sigma$-最大祖先图（$\sigma$-MAGs），类比于MAGs表示DAGs的方式，展示了其如何表示带隐变量的有向图（DGs），并研究了其性质。

Result: 证明了$\sigma$-MAGs能够有效表示带隐变量的有向图（DGs），并提供了其马尔可夫等价类的特征化。

Conclusion: $\sigma$-MAGs扩展了传统MAGs的应用范围，使其能够表示循环因果关系，为因果发现提供了更强大的工具。

Abstract: Maximal Ancestral Graphs (MAGs) provide an abstract representation of
Directed Acyclic Graphs (DAGs) with latent (selection) variables. These
graphical objects encode information about ancestral relations and
d-separations of the DAGs they represent. This abstract representation has been
used amongst others to prove the soundness and completeness of the FCI
algorithm for causal discovery, and to derive a do-calculus for its output. One
significant inherent limitation of MAGs is that they rule out the possibility
of cyclic causal relationships. In this work, we address that limitation. We
introduce and study a class of graphical objects that we coin
''$\sigma$-Maximal Ancestral Graphs'' (''$\sigma$-MAGs''). We show how these
graphs provide an abstract representation of (possibly cyclic) Directed Graphs
(DGs) with latent (selection) variables, analogously to how MAGs represent
DAGs. We study the properties of these objects and provide a characterization
of their Markov equivalence classes.

</details>


### [86] [Computational complexity of covering regular trees](https://arxiv.org/abs/2507.00564)
*Jan Bok,Jiří Fiala,Nikola Jedličková,Jan Kratochvíl*

Main category: cs.DM

TL;DR: 本文研究了在包含半边的图中，计算图覆盖投影问题{\sc $H$-Cover}的复杂度，证明了对于通过向树添加半边得到的$d$-正则图（$d \geq 3$），该问题是NP完全的。


<details>
  <summary>Details</summary>
Motivation: 图覆盖投影（局部双射同态）在拓扑图论、组合数学和理论计算机科学中有广泛应用。研究其在包含多重边、环和半边的图上的计算复杂度，填补了现有研究的空白。

Method: 通过扩展已有结果，研究在树结构上添加半边构成的$d$-正则图（$d \geq 3$），分析其{\sc $H$-Cover}问题的复杂度。

Result: 证明了对于任何通过向树添加半边构成的$d$-正则图（$d \geq 3$），{\sc $H$-Cover}问题是NP完全的，且即使输入图为简单图，该结论仍成立。

Conclusion: 该结果支持了强二分猜想，表明在包含半边的正则图中，{\sc $H$-Cover}问题的NP完全性具有普遍性，为相关领域的研究提供了重要理论支持。

Abstract: A graph covering projection, also referred to as a locally bijective
homomorphism, is a mapping between the vertices and edges of two graphs that
preserves incidences and is a local bijection. This concept originates in
topological graph theory but has also found applications in combinatorics and
theoretical computer science. In this paper we consider undirected graphs in
the most general setting -- graphs may contain multiple edges, loops, and
semi-edges. This is in line with recent trends in topological graph theory and
mathematical physics.
  We advance the study of the computational complexity of the {\sc $H$-Cover}
problem, which asks whether an input graph allows a covering projection onto a
parameter graph $H$. The quest for a complete characterization started in
1990's. Several results for simple graphs or graphs without semi-edges have
been known, the role of semi-edges in the complexity setting has started to be
investigated only recently. One of the most general known NP-hardness results
states that {\sc $H$}-Cover is NP-complete for every simple connected regular
graph of valency greater than two. We complement this result by considering
regular graphs $H$ arising from connected acyclic graphs by adding semi-edges.
Namely, we prove that any graph obtained by adding semi-edges to the vertices
of a tree making it a $d$-regular graph with $d \geq 3$, defines an NP-complete
graph covering problem. In line with the so called Strong Dichotomy Conjecture,
we prove that the NP-hardness holds even for simple graphs on input.

</details>


### [87] [Temporal Orienteering with Changing Fuel Costs](https://arxiv.org/abs/2507.00728)
*Timothée Corsini,Jessica Enright,Laura Larios-Jones,Kitty Meeks*

Main category: cs.DM

TL;DR: 本文研究了一种变体的定向问题，其中边的成本取决于出发和到达时间，适用于如轨道物体间旅行等场景。提出了时间图的一般化模型，证明了问题的NP完全性，并探讨了三种限制条件下的高效算法。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于实际应用如轨道物体间旅行，其中燃料成本随出发时间和旅行时长变化。传统定向问题无法处理这种动态成本，因此需要新的模型和算法。

Method: 方法包括引入一种广义时间图模型，其中边成本和最短旅行时间随时间变化。通过限制边的使用次数、顶点间隔成员宽度类似物及访问站点数量，设计了三种高效算法。

Result: 结果表明，问题的一般形式是NP完全的。但在限制边使用次数、顶点间隔成员宽度或访问站点数量的情况下，可以设计出高效算法。

Conclusion: 结论指出，提出的广义时间图模型具有独立研究价值，且在特定限制条件下，定向问题的变体可以通过高效算法解决。

Abstract: The problem Orienteering asks whether there exists a walk which visits a
number of sites without exceeding some fuel budget. In the variant of the
problem we consider, the cost of each edge in the walk is dependent on the time
we depart one endpoint and the time we arrive at the other endpoint. This
mirrors applications such as travel between orbiting objects where fuel costs
are dependent on both the departure time and the length of time spent
travelling. In defining this problem, we introduce a natural generalisation of
the standard notion of temporal graphs: the pair consisting of the graph of the
sites and a cost function, in which costs as well as shortest travel times
between pairs of objects change over time. We believe this model is likely to
be of independent interest. The problem of deciding whether a stated goal is
feasible is easily seen to be NP-complete; we investigate three different ways
to restrict the input which lead to efficient algorithms. These include the
number of times an edge can be used, an analogue of vertex-interval-membership
width, and the number of sites to be visited.

</details>
