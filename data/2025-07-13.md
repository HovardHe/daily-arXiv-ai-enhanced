<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 2]
- [math.OC](#math.OC) [Total: 13]
- [math.NT](#math.NT) [Total: 4]
- [math.LO](#math.LO) [Total: 5]
- [math.CO](#math.CO) [Total: 11]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [cs.CR](#cs.CR) [Total: 18]
- [cs.AI](#cs.AI) [Total: 26]
- [cs.DM](#cs.DM) [Total: 1]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [On the pointwise and sup-norm errors for local regression estimators](https://arxiv.org/abs/2507.07132)
*Jérémy Bettinger,François Portier,Adrien Saumard*

Main category: math.ST

TL;DR: 本文分析了多种非参数局部回归估计器的行为，证明了形状规则性对达到极小极大收敛速率的必要性，并提出了一种基于随机树构造的新算法。


<details>
  <summary>Details</summary>
Motivation: 研究非参数局部回归估计器在估计Lipschitz回归函数时的行为，特别是在固定点或上确界范数下的表现。

Method: 首先证明了基于VC类集的局部估计器的偏差界，引入了形状规则局部映射的概念，并分析了最近邻、原型变体及新算法（改进版CART）的偏差界。

Result: 形状规则性是达到极小极大收敛速率的必要条件，且能确保最优速率（除对数因子外）。新算法在上确界范数下具有极小极大速率最优性。

Conclusion: 通过分析基于纯随机树的局部估计器，进一步讨论了估计器速率与局部映射形状规则性之间的关系。

Abstract: In this paper, we analyze the behavior of various non-parametric local
regression estimators, i.e. estimators that are based on local averaging, for
estimating a Lipschitz regression function at a fixed point, or in sup-norm.
  We first prove some deviation bounds for local estimators that can be indexed
by a VC class of sets in the covariates space. We then introduce the general
concept of shape-regular local maps, corresponding to the situation where the
local averaging is done on sets which, in some sense, have ``almost isotropic''
shapes. On the one hand, we prove that, in general, shape-regularity is
necessary to achieve the minimax rates of convergence. On the other hand, we
prove that it is sufficient to ensure the optimal rates, up to some logarithmic
factors.
  Next, we prove some deviation bounds for specific estimators, that are based
on data-dependent local maps, such as nearest neighbors, their recent prototype
variants, as well as a new algorithm, which is a modified and generalized
version of CART, and that is minimax rate optimal in sup-norm. In particular,
the latter algorithm is based on a random tree construction that depends on
both the covariates and the response data. For each of the estimators, we
provide insights on the shape-regularity of their respective local maps.
Finally, we conclude the paper by establishing some probability bounds for
local estimators based on purely random trees, such as centered, uniform or
Mondrian trees. Again, we discuss the relations between the rates of the
estimators and the shape-regularity of their local maps.

</details>


### [2] [Computational barriers for permutation-based problems, and cumulants of weakly dependent random variables](https://arxiv.org/abs/2507.07946)
*Bertrand Even,Christophe Giraud,Nicolas Verzelen*

Main category: math.ST

TL;DR: 本文提出了一种处理弱依赖结构中累积量上界的技术，解决了随机排列等问题中缺乏独立性的难题，并在特征匹配和序列问题中揭示了统计-计算差距的证据。


<details>
  <summary>Details</summary>
Motivation: 在高维问题中，多项式时间算法难以达到无计算约束下的统计极限。现有方法依赖潜在变量的独立性，无法处理随机排列等缺乏独立性的结构。

Method: 开发了一种新技术，用于在弱依赖（如无放回抽样或随机排列）条件下上界累积量，突破了独立性假设的限制。

Result: 该方法有效应用于多重特征匹配和序列问题，首次在这些问题中发现了统计-计算差距的证据。

Conclusion: 该技术扩展了低阶多项式方法的应用范围，为研究具有复杂依赖结构的问题提供了新工具，揭示了新的统计-计算差距现象。

Abstract: In many high-dimensional problems,polynomial-time algorithms fall short of
achieving the statistical limits attainable without computational constraints.
A powerful approach to probe the limits of polynomial-time algorithms is to
study the performance of low-degree polynomials. The seminal work of
arXiv:2008.02269 connects low-degree lower bounds to multivariate cumulants.
Prior works arXiv:2308.15728, arXiv:2506.13647 leverage independence among
latent variables to bound cumulants. However, such approaches break down for
problems with latent structure lacking independence, such as those involving
random permutations. To address this important restriction, we develop a
technique to upper-bound cumulants under weak dependencies, such as those
arising from sampling without replacement or random permutations. To show-case
the effectiveness of our approach, we uncover evidence of
statistical-computational gaps in multiple feature matching and in seriation
problems.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [3] [Secrecy Energy Efficiency Maximization in RIS-Aided Networks: Active or Nearly-Passive RIS?](https://arxiv.org/abs/2507.07241)
*Robert Kuku Fotock,Agbotiname Lucky Imoize,Alessio Zappone,Marco Di Renzo,Roberto Garello*

Main category: math.OC

TL;DR: 本文研究了RIS辅助无线网络中保密能效(SEE)最大化问题，对比了主动与近被动RIS的性能差异，并开发了两种SEE优化算法。


<details>
  <summary>Details</summary>
Motivation: 探讨主动与近被动可重构智能表面(RIS)在保密能效方面的性能差异及权衡，为实际网络部署提供理论依据。

Method: 针对完美和统计信道状态信息两种情况，开发了两种SEE最大化算法，优化用户发射功率、RIS反射系数和基站接收滤波器。

Result: 数值结果表明主动RIS在静态功耗增加时SEE性能下降，量化了主动与近被动RIS在SEE方面的权衡关系。

Conclusion: 研究揭示了主动RIS的功耗敏感特性，为RIS类型选择提供了能效维度的设计指导。

Abstract: This work addresses the problem of secrecy energy efficiency (SEE)
maximization in RIS-aided wireless networks. The use of active and
nearly-passive RISs are compared and their trade-off in terms of SEE is
analyzed. Considering both perfect and statistical channel state information,
two SEE maximization algorithms are developed to optimize the transmit powers
of the mobile users, the RIS reflection coefficients, and the base station
receive filters. Numerical results quantify the trade-off between active and
nearly-passive RISs in terms of SEE, with active RISs yielding worse SEE values
as the static power consumed by each reflecting element increases.

</details>


### [4] [Convergence and Robustness Bounds for Distributed Asynchronous Shortest-Path](https://arxiv.org/abs/2507.07263)
*Jared Miller,Mattia Bianchi,Florian Dörfler*

Main category: math.OC

TL;DR: 本文研究了异步分布式最短路径计算的收敛时间和鲁棒性边界，重点关注自适应Bellman-Ford算法，并建立了异步环境下的有限时间收敛和鲁棒性边界。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于分析异步环境下自适应Bellman-Ford算法的性能，特别是在代理可能闲置或遇到竞争条件的情况下，确保算法的收敛性和鲁棒性。

Method: 方法基于Lyapunov稳定性理论，将同步最短路径设置的有限时间收敛和鲁棒性边界扩展到异步设置，并研究了区间有界噪声过程的鲁棒性。

Result: 结果表明，异步环境下自适应Bellman-Ford算法具有有限时间收敛性，并且在区间有界噪声下仍能保持鲁棒性，同时为异步最可能路径算法提供了收敛和鲁棒性保证。

Conclusion: 结论指出，自适应Bellman-Ford算法在异步环境下具有可靠的收敛性和鲁棒性，适用于分布式最短路径计算，特别是在存在噪声和异步通信的情况下。

Abstract: This work analyzes convergence times and robustness bounds for asynchronous
distributed shortest-path computation. We focus on the Adaptive Bellman--Ford
algorithm, a self-stabilizing method in which each agent updates its
shortest-path estimate based only on the estimates of its neighbors and
forgetting its previous estimate. In the asynchronous framework considered in
this paper, agents are allowed to idle or encounter race conditions during
their execution of the Adaptive Bellman--Ford algorithm. We build on
Lyapunov-based results that develop finite-time convergence and robustness
bounds for the synchronous shortest-path setting, in order to produce
finite-time convergence and robustness bounds for the asynchronous setting. We
also explore robustness against interval-bounded noise processes and establish
convergence and robustness guarantees for asynchronous most-probable-path
algorithms.

</details>


### [5] [Combinatorial Algorithm for Tropical Linearly Factorized Programming](https://arxiv.org/abs/2507.07596)
*Yuki Nishida*

Main category: math.OC

TL;DR: 本文提出了一种新的热带优化问题——热带线性因子化规划问题，其目标函数为热带线性形式的乘积除以热带单项式，并受热带线性不等式约束。通过基于下降法和切线有向图的算法，解决了该问题在非退化情况下的高效求解。


<details>
  <summary>Details</summary>
Motivation: 热带半环上的线性规划问题已有研究，但热带线性因子化规划问题尚未被探索。该问题在目标函数和可行集的凸性方面具有独特性质，需要新的算法来解决。

Method: 算法基于下降法，利用切线有向图确定可行下降方向。在非退化情况下，切线有向图变为生成树，提出了一种类似单纯形法的迭代算法，每次迭代时间复杂度为$O(r_A+r_C)$。

Result: 对于整数实例，算法可在$O((m+n)(r_A+r_C)MD)$时间内找到局部最优解，其中$n$和$m$分别为决策变量和约束的数量，$M$为系数的最大绝对值，$D$为目标函数的次数。

Conclusion: 本文提出的算法有效解决了热带线性因子化规划问题，尤其在非退化情况下表现出高效性，为热带优化领域提供了新的工具和理论支持。

Abstract: The tropical semiring is a set of numbers $\mathbb{R}\cup\{-\infty\}$ with
addition $a\oplus b:=\max(a,b)$ and multiplication $a\otimes b:=a+b$. As well
as in conventional algebra, linear programming problem in the tropical semiring
has been developed. In this study, we introduce a new type of tropical
optimization problem, namely, tropical linearly factorized programming problem.
This problem involves minimizing the objective function given by the product of
tropical linear forms $c_{k,1}\otimes x_1\oplus \cdots\oplus c_{k,n}\otimes
x_n$ divided by a tropical monomial, subject to tropical linear inequality
constraints. The objective function is convex in the conventional sense but not
in the tropical sense, while the feasible set is convex in the tropical sense
but not in the conventional sense.
  Our algorithm for tropical linearly factorized programming is based on the
descent method and exploits tangent digraphs. First, we demonstrate that the
feasible descent direction at the current solution can be obtained by solving
the minimum $s$-$t$ cut problem on a specific subgraph of the tangent digraph.
Although exponentially many such digraphs may exist in general, a more
efficient algorithm is devised in cases where the problem is non-degenerate.
Focusing on the fact that tangent digraphs become spanning trees in
non-degenerate cases, we present a simplex-like algorithm that updates the tree
structure iteratively. We show that each iteration can be executed in
$O(r_A+r_C)$ time, where $r_A$ and $r_C$ are the numbers of ``non-zero''
coefficients in the linear constraints and objective function, respectively.
For integer instances, our algorithm finds a local optimum in
$O((m+n)(r_A+r_C)MD)$ time, where $n$ and $m$ are the number of decision
variables and constraints, respectively, $M$ is the maximum absolute value of
coefficients and $D$ is the degree of the objective function.

</details>


### [6] [Almost Sure Convergence for the Last Iterate of Stochastic Gradient Descent Schemes](https://arxiv.org/abs/2507.07281)
*Marcel Hudiani*

Main category: math.OC

TL;DR: 本文研究了随机梯度下降(SGD)和随机重球法(SHB)在参数设置下的最终迭代几乎必然收敛速率，适用于全局凸或非凸且梯度满足$\gamma$-H\"{o}lder条件的函数。通过离散Gronwall不等式，恢复了SGD和SHB的结果，并证明了SHB在特定条件下的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 研究随机优化算法（SGD和SHB）在凸和非凸目标函数下的几乎必然收敛速率，为算法性能提供理论保证。

Method: 使用离散Gronwall不等式，避免了Robbins-Siegmund定理和鞅收敛理论，分析了SGD和SHB在$\gamma$-H\"{o}lder梯度条件下的收敛行为。

Result: 对于非凸目标，$\min_{s\leq t} \|\nabla F(w_s)\|^2 = o(t^{p-1})$；对于凸目标，$F(w_t) - F_* = o(t^{2\gamma/(1+\gamma) \cdot \max(p-1,-2p+1)-\epsilon})$。SHB在特定条件下达到$O(t^{\max(p-1,-2p+1)} \log^2 \frac{t}{\delta})$的收敛速率。

Conclusion: 本文通过离散Gronwall不等式，为SGD和SHB在凸和非凸目标下的几乎必然收敛速率提供了简洁证明，并展示了SHB在特定条件下的高效收敛性能。

Abstract: We study the almost sure convergence rate for the last iterate of stochastic
gradient descent (SGD) and stochastic heavy ball (SHB) in the parametric
setting when the objective function $F$ is globally convex or non-convex whose
gradient is $\gamma$-H\"{o}lder. Using only discrete Gronwall's inequality
without Robbins-Siegmund theorem nor martingale convergence theory, we recover
results for both SGD and SHB: $\min_{s\leq t} \|\nabla F(w_s)\|^2 = o(t^{p-1})$
for non-convex objectives and $F(w_t) - F_* = o(t^{2\gamma/(1+\gamma) \cdot
\max(p-1,-2p+1)-\epsilon})$ for $\beta \in (0, 1)$ and $\min_{s \leq t} F(w_s)
- F_* = o(t^{p-1})$ almost surely for convex objectives. In addition, we proved
that SHB with constant momentum parameter $\beta \in (0, 1)$ attains a
convergence rate of $F(w_t) - F_* = O(t^{\max(p-1,-2p+1)} \log^2
\frac{t}{\delta})$ with probability at least $1-\delta$ when $F$ is convex and
$\gamma = 1$ and step size $\alpha_t = \Theta(t^{-p})$ with $p \in
(\frac{1}{2}, 1)$.

</details>


### [7] [Qualitative and Generalized Differentiation Properties of Optimal Value Functions with Applications to Duality](https://arxiv.org/abs/2507.07377)
*Vo Si Trong Long,Nguyen Mau Nam,Len White*

Main category: math.OC

TL;DR: 本文研究了扰动优化问题中最优值函数的一般及广义微分性质，分析了其有效域、上镜图、严格上镜图、凸性、近凸性、连续性及Lipschitz型行为，并提出了基于集值映射Fenchel共轭的对偶框架，最后计算了最优值函数及其Fenchel共轭的$\epsilon$-次微分。


<details>
  <summary>Details</summary>
Motivation: 研究扰动优化问题中最优值函数的微分性质，为凸与非凸情形下的优化问题提供理论支持。

Method: 通过分析最优值函数的有效域、上镜图等性质，提出基于集值映射Fenchel共轭的对偶框架，并计算$\epsilon$-次微分。

Result: 在凸与非凸情形下，全面刻画了最优值函数的微分性质，并扩展了对偶理论的应用范围。

Conclusion: 本文为扰动优化问题中最优值函数的微分性质提供了系统分析，并提出了新的对偶框架，为优化理论的发展提供了新视角。

Abstract: In this paper, we investigate general and generalized differentiation
properties of theoptimal value function associated with perturbed optimization
problems. We begin with a comprehensive analysis of its effective domain,
epigraph, strict epigraph, convexity, near convexity, continuity, and
Lipschitz-type behavior, in both convex and nonconvex settings. Next, we
propose a duality framework for constrained optimization problems with
set-valued constraints, based on the notion of the Fenchel conjugate for
set-valued mappings, which offers new insights into duality theory in a broad
context. Finally, we compute the {\epsilon}-subdifferentials of the optimal
value function and its Fenchel conjugate.

</details>


### [8] [Relocated Fixed-Point Iterations with Applications to Variable Stepsize Resolvent Splitting](https://arxiv.org/abs/2507.07428)
*Felipe Atenas,Heinz H. Bauschke,Minh N. Dao,Matthew K. Tam*

Main category: math.OC

TL;DR: 本文提出了一种适用于非扩张算子迭代算法的收敛框架，无需算子族具有共同不动点，并应用于多算子求和的Douglas-Rachford算法变体。


<details>
  <summary>Details</summary>
Motivation: 现有收敛分析通常要求非扩张算子族具有共同不动点，这限制了算法的适用范围。本文旨在突破这一限制，建立更通用的收敛理论框架。

Method: 采用参数化非扩张算子的半闭性原理扩展，通过'重定位'步骤将当前算子不动点映射至下一阶段，构建不依赖共同不动点的收敛框架。

Result: 所提框架成功应用于图基Douglas-Rachford算法的变体，实现了$N\geq 2$个极大单调算子求零问题中解析参数的非恒定迭代。

Conclusion: 该研究为非扩张算子迭代算法提供了更灵活的收敛分析工具，特别适用于多算子优化问题，突破了传统共同不动点的限制条件。

Abstract: In this work, we develop a convergence framework for iterative algorithms
whose updates can be described by a one-parameter family of nonexpansive
operators. Within the framework, each step involving one of the main
algorithmic operators is followed by a second step which ''relocates''
fixed-points of the current operator to the next. As a consequence, our
analysis does not require the family of nonexpansive operators to have a common
fixed-point, as is common in the literature. Our analysis uses a parametric
extension of the demiclosedness principle for nonexpansive operators. As an
application of our convergence results, we develop a version of the graph-based
extension of the Douglas--Rachford algorithm for finding a zero of the sum of
$N\geq 2$ maximally monotone operators, which does not require the resolvent
parameter to be constant across iterations.

</details>


### [9] [On the local null controllability of a viscous Burgers' system in finite time](https://arxiv.org/abs/2507.07442)
*Hoai-Minh Nguyen,Minh-Nguyen Tran*

Main category: math.OC

TL;DR: 本文研究了Burgers控制系统在有限时间内不具备局部零可控性，扩展了Marbach关于小时间内不可控的结果。


<details>
  <summary>Details</summary>
Motivation: 基于Marbach此前证明的Burgers控制系统在小时间内不具备局部零可控性，本文旨在探究该系统在有限时间内是否可控。

Method: 研究方法受到Coron、Koenig和Nguyen关于KdV系统可控性工作的启发，采用了与Marbach不同的分析路径。

Result: 研究结果表明，Burgers控制系统在有限时间内同样不具备局部零可控性。

Conclusion: 本文通过不同的方法证实了Burgers控制系统在有限时间内不可控，为相关控制理论提供了新的见解。

Abstract: This paper is devoted to the local null controllability of the Burgers
control system $y_t - y_{xx} + y y_x = u(t)$ on a bounded interval imposed by
the zero Dirichlet boundary condition. It is known from the work of Marbach
that this control system is not locally null controllable in small time. In
this paper, we prove that the system is not locally null controllable in finite
time as well. Our approach is inspired by the works of Coron, Koenig, and
Nguyen, and Nguyen on the controllability of the KdV system and is different
from the one of Marbach.

</details>


### [10] [An Adaptive Order Caputo Fractional Gradient Descent Method for Multi-objective Optimization Problems](https://arxiv.org/abs/2507.07674)
*Barsha Shaw,Md Abu Talhamainuddin Ansary*

Main category: math.OC

TL;DR: 本文提出了一种新型多目标自适应阶Caputo分数阶梯度下降算法（MOAOCFGD），用于解决无约束多目标优化问题，适用于光滑与非光滑问题，且无需预设参数或目标函数排序信息。


<details>
  <summary>Details</summary>
Motivation: 针对多目标优化问题中传统方法对参数敏感且难以处理非光滑目标的局限，提出一种无需先验参数的自适应分数阶梯度方法。

Method: 通过迭代求解子问题确定下降方向，结合自适应阶Caputo分数阶梯度与Armijo型线搜索步长策略，适用于Tikhonov正则化场景。

Result: 数值实验（含神经网络案例）验证了算法的有效性，理论分析表明其在温和假设下具有收敛性。

Conclusion: MOAOCFGD算法为多目标优化提供了通用解决方案，其参数无关性和广泛适用性在理论和实验中均得到证实。

Abstract: This article introduces the multi-objective adaptive order Caputo fractional
gradient descent (MOAOCFGD) algorithm for solving unconstrained multi-objective
problems. The proposed method performs equally well for both smooth and
non-smooth multi-objective optimization problems. Moreover, the proposed method
does not require any a priori chosen parameters or ordering information of the
objective functions. At every iteration of the proposed method, a subproblem is
solved to identify a suitable descent direction toward an optimal solution.
This subproblem involves an adaptive-order Caputo fractional gradient for each
objective function. An Armijo-type line search is applied to determine a
suitable step length. The convergence of this method for the
Tikhonov-regularized solution is justified under mild assumptions. The proposed
method is verified using different numerical problems, including neural
networks.

</details>


### [11] [Efficient Stochastic BFGS methods Inspired by Bayesian Principles](https://arxiv.org/abs/2507.07729)
*André Carlon,Luis Espath,Raúl Tempone*

Main category: math.OC

TL;DR: 本文提出了一种基于贝叶斯推断的新型随机拟牛顿方法（S-BFGS和L-S-BFGS），通过吸收噪声梯度信息有效逼近二阶导数，在小批量场景下仍能保持高效计算性能。


<details>
  <summary>Details</summary>
Motivation: 传统拟牛顿法依赖精确梯度信息，而随机优化中仅能获取噪声梯度观测。现有方法多通过修改确定性方程规避噪声，本文创新性地采用贝叶斯框架直接处理噪声信息。

Method: 基于贝叶斯推断构建随机拟牛顿框架，推导出随机BFGS（S-BFGS）和随机L-BFGS（L-S-BFGS）算法。S-BFGS单次迭代复杂度为$\bigO{d^2}$，L-S-BFGS为$\bigO{d}$。

Result: 在维度高达30,720的问题上验证了方法的有效性。实验表明新方法能在小批量条件下稳定学习逆Hessian近似，兼具计算效率与鲁棒性。

Conclusion: 所提出的贝叶斯框架为随机拟牛顿法提供了新范式，可推广至其他拟牛顿变体，在保持$\bigO{d}$或$\bigO{d^2}$计算复杂度的同时实现噪声环境下的二阶优化。

Abstract: Quasi-Newton methods are ubiquitous in deterministic local search due to
their efficiency and low computational cost. This class of methods uses the
history of gradient evaluations to approximate second-order derivatives.
However, only noisy gradient observations are accessible in stochastic
optimization; thus, deriving quasi-Newton methods in this setting is
challenging. Although most existing quasi-Newton methods for stochastic
optimization rely on deterministic equations that are modified to circumvent
noise, we propose a new approach inspired by Bayesian inference to assimilate
noisy gradient information and derive the stochastic counterparts to standard
quasi-Newton methods. We focus on the derivations of stochastic BFGS and
L-BFGS, but our methodology can also be employed to derive stochastic analogs
of other quasi-Newton methods. The resulting stochastic BFGS (S-BFGS) and
stochastic L-BFGS (L-S-BFGS) can effectively learn an inverse Hessian
approximation even with small batch sizes. For a problem of dimension $d$, the
iteration cost of S-BFGS is $\bigO{d^2}$, and the cost of L-S-BFGS is
$\bigO{d}$. Numerical experiments with a dimensionality of up to $30,720$
demonstrate the efficiency and robustness of the proposed method.

</details>


### [12] [A Model-Free Extremum Seeking Controller with Application to Tracking a Nonlinear Chemical Reaction](https://arxiv.org/abs/2507.07749)
*Alexander Zuyev,Victoria Grushkovska*

Main category: math.OC

TL;DR: 本文提出了一种极值搜索方法，用于在状态空间中给定参考曲线附近生成可行轨迹，并通过非等温反应模型验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于非线性化学反应中的等周优化问题，需最大化特定时间段内反应产物的平均产量，参考曲线作为最优轨迹自然产生。

Method: 采用极值搜索控制设计，以系统当前状态与时间参数化参考曲线间的距离作为成本函数，生成邻近可行轨迹。

Result: 数值模拟展示了该方法在非等温反应模型中的应用，并量化了跟踪误差的表现。

Conclusion: 所提极值搜索方法能有效跟踪参考曲线，为非线性化学反应的优化控制提供了实用工具。

Abstract: In this paper, we develop the extremum-seeking approach to generate
admissible trajectories in a neighborhood of a given reference curve in the
state space. The cost function of the problem represents the distance between
the current system state and the reference curve, which is parameterized as a
function of time. Such reference curves naturally arise as optimal trajectories
in isoperimetric optimization problems for nonlinear chemical reactions, where
the objective is to maximize the average reaction product over a given period.
We apply the proposed extremum seeking control design to a nonisothermal
reaction model and illustrate the resulting tracking errors through numerical
simulations.

</details>


### [13] [Dissipativity-based time domain decomposition for optimal control of hyperbolic PDEs](https://arxiv.org/abs/2507.07812)
*Bálint Farkas,Birgit Jacob,Manuel Schaller,Merlin Schmitz*

Main category: math.OC

TL;DR: 提出基于半群理论的时间域分解方法求解PDE最优控制问题，通过解耦实现高效并行计算，并在波方程和热方程中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 针对偏微分方程最优控制问题，传统方法计算复杂度高，需开发高效并行算法以提升求解效率。

Method: 将状态方程与伴随方程构成的最优性系统表述为耗散算子之和，采用Peaceman-Rachford型不动点迭代，实现时间分布式解耦计算。

Result: 证明了函数空间中状态、控制及伴随状态的收敛性，特别适用于双曲型方程（如波方程），并通过2D波方程和3D热方程算例验证了方法的收敛性与效率。

Conclusion: 基于$C_0$半群的框架具有普适性，所提方法在保持理论严谨性的同时显著提升了计算并行化能力，为PDE最优控制提供了新思路。

Abstract: We propose a time domain decomposition approach to optimal control of partial
differential equations (PDEs) based on semigroup theoretic methods. We
formulate the optimality system consisting of two coupled forward-backward
PDEs, the state and adjoint equation, as a sum of dissipative operators, which
enables a Peaceman-Rachford-type fixed-point iteration. The iteration steps may
be understood and implemented as solutions of many decoupled, and therefore
highly parallelizable, time-distributed optimal control problems. We prove the
convergence of the state, the control, and the corresponding adjoint state in
function space. Due to the general framework of $C_0$-(semi)groups, the results
are particularly well applicable, e.g., to hyperbolic equations, such as beam
or wave equations. We illustrate the convergence and efficiency of the proposed
method by means of two numerical examples subject to a 2D wave equation and a
3D heat equation.

</details>


### [14] [Complexity Analysis of a Bicriteria Directed Multimodal Transportation Network Design Problem](https://arxiv.org/abs/2507.07894)
*Dominik Leib,Susanne Fritzler,Neele Leithäuser*

Main category: math.OC

TL;DR: 本文研究了一个源于城乡公共交通规划的双标准网络设计问题，证明了问题的复杂性和不可近似性，并识别了可近似求解的特殊情况。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于城乡公共交通规划中的实际问题，旨在填补双标准决策与网络设计挑战之间关系的理解空白。

Method: 方法包括建立问题复杂性、证明不可近似性结果，并利用有向网络设计问题的复杂性结果进行理论分析。

Result: 结果表明该问题在一般情况下难以找到最优解，但在特定情况下可实现近似求解，为实践者提供了重要参考。

Conclusion: 结论指出本研究填补了现有文献中对有向网络设计问题关注的不足，深化了对双标准网络设计复杂性的理解。

Abstract: In this paper, we address a bicriteria network design problem that arises
from practical applications in urban and rural public transportation planning.
We establish the problem's complexity and demonstrate inapproximability
results, highlighting the inherent difficulties in finding optimal solutions.
Additionally, we identify special cases where approximability can be achieved,
providing valuable insights for practitioners. Our proofs leverage complexity
results related to directed network design problems, an area that has received
limited attention in the existing literature. By investigating these complexity
results, we aim to fill a critical gap and enhance the understanding of the
interplay between bicriteria decision-making and network design challenges.

</details>


### [15] [Convergence rates for regularized unbalanced optimal transport: the discrete case](https://arxiv.org/abs/2507.07917)
*Luca Nenna,Paul Pegon,Louis Tocquec*

Main category: math.OC

TL;DR: 本文研究了不平衡最优运输(UOT)的正则化运输成本与运输方案的收敛速率，针对加权Dirac质量和的测度情况。


<details>
  <summary>Details</summary>
Motivation: UOT作为最优运输(OT)的扩展，能比较不同质量的测度，在机器学习中具有抗异常值的优势，研究其收敛性具有重要意义。

Method: 通过分析正则化UOT问题，研究当两个测度均为加权Dirac质量和时，正则化运输成本与运输方案向原始解的收敛速率。

Result: 获得了正则化UOT问题在特定测度条件下的收敛速率理论结果。

Conclusion: 该研究为UOT在机器学习中的应用提供了理论支持，特别是在处理含异常值数据时的收敛性保证。

Abstract: Unbalanced optimal transport (UOT) is a natural extension of optimal
transport (OT) allowing comparison between measures of different masses. It
arises naturally in machine learning by offering a robustness against outliers.
The aim of this work is to provide convergence rates of the regularized
transport cost and plans towards their original solution when both measures are
weighted sums of Dirac masses.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [16] [Asymptotic properties of zeros of Riemann zeta function](https://arxiv.org/abs/2507.07253)
*Juan Arias de Reyna,Yves Meyer*

Main category: math.NT

TL;DR: 本文探讨了黎曼ζ函数非平凡零点序列的内在性质，提出了一个渐近关系式，并研究是否存在其他实数或复数序列满足相同性质。


<details>
  <summary>Details</summary>
Motivation: 研究黎曼ζ函数零点序列的独特数学特性，探索是否存在其他序列具有类似的渐近关系。

Method: 通过假设黎曼猜想成立，将非平凡零点表示为$z_k=1/2+i\tau_k$，推导出序列$(\tau_k)$满足的渐近展开式。

Result: 建立了零点序列$(\tau_k)$与特定渐近级数之间的对应关系，其中系数$a_n$由伯努利数和欧拉数表示。

Conclusion: 该研究为黎曼ζ函数零点提供了新的特征描述，并提出了关于其他可能序列的开放性问题。

Abstract: We try to define the sequence of zeros of the Riemann zeta function by an
intrinsic property. Let $(z_k)_{k\in \mathbb{N}}$ be the sequence of nontrivial
zeros of $\zeta(s)$ with positive imaginary part. We write $z_k= 1/2+i\tau_k$
(RH says that these $\tau_k$ are all real). Then the sequence $(\tau_k)_{k\in
\mathbb{N}},$ satisfies the following asymptotic relation
\[\sum_{k\in\mathbb{N}}\frac{2x}{x^2+\tau_k^2}\simeq
\frac12\log\frac{x}{2\pi}+\sum_{n=1}^\infty \frac{a_n}{x^n},\,\,x\to +\infty\]
where $a_{2n+1}=2^{-2n-2}(8-E_{2n})$, $a_{2n}=(1-2^{-2n+1})B_{2n}/(4n).$ Are
there other sequences $(\alpha_k)_{k\in \mathbb{N}},$ of real or complex
numbers enjoying this property? These problems are addressed in this note.

</details>


### [17] [An Equivalent Representation of Generalized Differentials](https://arxiv.org/abs/2507.07337)
*Valentin Suder*

Main category: math.NT

TL;DR: 提出了一种在任意特征$p$有限域上研究广义几乎完美非线性函数时使用的高阶导数等价公式，并通过计算具有固定基数且元素和为常数的子集数量获得结果，进而探讨了高阶导数的多样性问题。


<details>
  <summary>Details</summary>
Motivation: 研究广义几乎完美非线性函数的高阶导数在密码学等领域具有重要意义，需要找到更普适的计算方法。

Method: 通过计算特征$p$的素域中具有固定基数且元素和为常数的子集数量，推导出高阶导数的等价公式。

Result: 成功建立了适用于任意特征$p$有限域的高阶导数等价公式，并提出了关于高阶导数多样性的相关问题。

Conclusion: 该公式为广义几乎完美非线性函数的研究提供了新工具，同时提出的多样性问题为未来研究指明了方向。

Abstract: We propose an equivalent formula for the higher-order derivatives used in the
study of Generalized Almost Perfect Nonlinear functions over an arbitrary
finite field of characteristic $p$. The result is obtained by counting the
number of subsets of the prime field with a fixed cardinality for which the sum
of their elements is constant. We then ask related questions regarding the
diversity of higher-order derivatives.

</details>


### [18] [Higher Hida theory for Drinfeld modular curves](https://arxiv.org/abs/2507.07423)
*Daniel Barrera Salazar,Héctor del Castillo,Giovanni Rosso*

Main category: math.NT

TL;DR: 本文基于Boxer和Pilloni的高阶Hida理论，为Drinfeld模曲线上的Drinfeld模形式线丛上同调发展了高阶Hida理论，并插值了Serre对偶性。


<details>
  <summary>Details</summary>
Motivation: 受到Boxer和Pilloni高阶Hida理论构造的启发，研究Drinfeld模形式线丛上同调的高阶理论。

Method: 采用高阶Hida理论的框架，应用于Drinfeld模曲线上的线丛上同调，并实现Serre对偶性的插值。

Result: 成功构建了Drinfeld模形式线丛上同调的高阶Hida理论，并实现了Serre对偶性的插值。

Conclusion: 该研究扩展了高阶Hida理论的应用范围，为Drinfeld模形式的上同调理论提供了新的工具和视角。

Abstract: Inspired by the construction of Higher Hida theory of Boxer and Pilloni, we
develop Higher Hida theory for the cohomology of the line bundles of Drinfeld
modular forms on the Drinfeld modular curve. We also interpolate Serre duality.

</details>


### [19] [Prime Power Residues and Blocking Sets](https://arxiv.org/abs/2507.07673)
*Bhawesh Mishra,Paolo Santonastaso*

Main category: math.NT

TL;DR: 该研究探讨了有限整数集$B$在几乎所有素数下包含$q$次幂的条件，发现这与射影几何中的阻塞集性质等价，并建立了伽罗瓦几何与数论之间的联系。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解有限整数集$B$在模几乎所有素数下包含$q$次幂的充要条件，并探索其与射影几何中阻塞集的关联。

Method: 通过分析$B$中元素的$q$-自由部分的素因子数量$k$，将问题转化为射影空间$\mathrm{PG}(\mathbb{F}_{q}^{k})$中的阻塞集性质，并利用几何$q$-等价性进行分类。

Result: 证明了$B$在几乎所有素数下包含$q$次幂当且仅当$B$对应于射影几何中的阻塞集，并给出了此类集合的最小尺寸分类与界限。

Conclusion: 该研究通过连接伽罗瓦几何与数论，揭示了整数集的模幂性质与几何阻塞集的深刻对应关系，为两类数学分支的交叉研究提供了新视角。

Abstract: Let $q$ be a fixed odd prime. We show that a finite subset $B$ of integers,
not containing any perfect $q^{th}$ power, contains a $q^{th}$ power modulo
almost every prime if and only if $B$ corresponds to a blocking set (with
respect to hyperplanes) in $\mathrm{PG}(\mathbb{F}_{q}^{k})$. Here, $k$ is the
number of distinct prime divisors of $q$-free parts of elements of $B$. As a
consequence, the property of a subset $B$ to contain $q^{th}$ power modulo
almost every prime $p$ is invariant under geometric $q$-equivalence defined by
an element of the projective general linear group
$\mathrm{PGL}(\mathbb{F}_{q}^{k})$. Employing this connection between two
disparate branches of mathematics, Galois geometry and number theory, we
classify, and provide bounds on the sizes of, minimal such sets $B$.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [20] [A 2-categorical approach to the semantics of dependent type theory with computation axioms](https://arxiv.org/abs/2507.07208)
*Matteo Spadetto*

Main category: math.LO

TL;DR: 本文从高阶范畴视角研究公理型类型论的语义，通过二维范畴模型（显示映射2-范畴）有效描述其语义，证明公理型理论的解释具有良好定义性和可靠性，并语义验证了内涵恒等类型计算规则在公理型理论中的不可接纳性。


<details>
  <summary>Details</summary>
Motivation: 公理型类型论缺乏计算规则，传统通过恒等类型补充计算公理的方式难以在1维范畴框架内刻画其内涵类型构造器。研究旨在突破这一限制，拓展Richard Garner的二维类型研究方法至公理型理论。

Method: 采用二维范畴论工具，将公理型类型构造器编码为自然二维范畴数据，构建显示映射2-范畴模型。相比内涵类型论，放松了Garner提出的二维范畴条件要求，实现语义框架的广义化。

Result: 证明公理型理论在显示映射2-范畴中的解释具备良好定义性及可靠性，并通过对Hofmann-Streicher群胚模型的改造，给出内涵恒等类型计算规则不可接纳的语义反例。

Conclusion: 建立的二维语义框架成功统一公理型与内涵型类型论的范畴解释，其放松的二维条件揭示了公理型理论的本质特征，为类型论语义学研究提供新范式。

Abstract: Axiomatic type theory is a dependent type theory without computation rules.
The term equality judgements that usually characterise these rules are replaced
by computation axioms, i.e., additional term judgements that are typed by
identity types. This paper is devoted to providing an effective description of
its semantics, from a higher categorical perspective: given the challenge of
encoding intensional type formers into 1-dimensional categorical terms and
properties, a challenge that persists even for axiomatic type formers, we adopt
Richard Garner's approach in the 2-dimensional study of dependent types. We
prove that the type formers of axiomatic theories can be encoded into natural
2-dimensional category theoretic data, obtaining a presentation of the
semantics of axiomatic type theory via 2-categorical models called display map
2-categories. In the axiomatic case, the 2-categorical requirements identified
by Garner for interpreting intensional type formers are relaxed. Therefore, we
obtain a presentation of the semantics of the axiomatic theory that generalises
Garner's one for the intensional case. Our main result states that the
interpretation of axiomatic theories within display map 2-categories is
well-defined and enjoys the soundness property. We use this fact to provide a
semantic proof that the computation rule of intensional identity types is not
admissible in axiomatic type theory. This is achieved via a revisitation of
Hofmann and Streicher's groupoid model that believes axiomatic identity types
but does not believe intensional ones.

</details>


### [21] [Generalized Tukey reducibility between $σ$-directed sets](https://arxiv.org/abs/2507.07309)
*Hiroshi Sakai,Toshimasa Tanno*

Main category: math.LO

TL;DR: 本文引入了一种在$\mathsf{ZF}$中表现良好的预图基可约性概念，扩展了有向集间的图基可约性，并在Solovay模型和满足$\mathsf{AD}$的$L(\mathbb{R})$中研究了多个$\sigma$-有向集的预图基可约性。


<details>
  <summary>Details</summary>
Motivation: 研究预图基可约性旨在扩展传统图基可约性的适用范围，使其在$\mathsf{ZF}$公理体系下仍能有效工作，并探索在特定集合论模型中的表现。

Method: 通过引入预图基可约性定义，分析其在$\sigma$-有向集间的性质，并基于实数集假设（Solovay模型和$L(\mathbb{R})$满足$\mathsf{AD}$）进行验证。

Result: 在Solovay模型和满足$\mathsf{AD}$的$L(\mathbb{R})$中，多个$\sigma$-有向集间的预图基可约性关系得到了明确刻画。

Conclusion: 预图基可约性为$\mathsf{ZF}$体系下的有向集比较提供了新工具，且在特定集合论模型中展现出良好的理论性质。

Abstract: We introduce the pre-Tukey reducibility, a generalization of the Tukey
reducibility between directed sets that works well in $\mathsf{ZF}$. We
investigate the pre-Tukey reducibility between several $\sigma$-directed sets
under assumptions on sets of reals, which hold in the Solovay model and in
$L(\mathbb{R})$ satisfying $\mathsf{AD}$.

</details>


### [22] [On the lack of colimits in various categories of BAOs and Heyting algebras](https://arxiv.org/abs/2507.07489)
*Marco Abbadini,Guram Bezhanishvili,Luca Carai*

Main category: math.LO

TL;DR: 证明了多种BAO（带算子的布尔代数）范畴及其稳定态射构成的范畴不具备余完备性，包括Heyting代数、框架等范畴，进而得出这些范畴不等价于预代数簇或代数簇的结论。


<details>
  <summary>Details</summary>
Motivation: 研究不同代数结构的范畴性质，特别是余完备性和与代数簇的等价关系，以解决Peter Jipsen提出的关于McKinsey-Tarski代数范畴是否等价于代数簇的问题。

Method: 通过分析BAO范畴、Heyting代数范畴及其子范畴的余完备性，结合范畴论和代数结构理论，证明这些范畴不具备余完备性。

Result: 发现所研究的范畴（包括BAO、Heyting代数、框架等）均不具备余完备性，且不等价于预代数簇或代数簇，特别是McKinsey-Tarski代数范畴也不等价于代数簇。

Conclusion: 这些范畴的余完备性缺失及其与代数簇的非等价性，深化了对代数结构范畴性质的理解，并否定了McKinsey-Tarski代数范畴等价于代数簇的可能性。

Abstract: We prove that various categories of BAOs (boolean algebras with an operator)
with stable morphisms between them are not cocomplete, and that neither are the
category of Heyting algebras with bounded lattice morphisms, its full
subcategory consisting of frames, and the category of frames with Heyting
morphisms. As a consequence, none of these categories is equivalent to a
prevariety of algebras, let alone a variety. In particular, we obtain that the
category of McKinsey-Tarski algebras is not equivalent to a variety, thus
answering a question by Peter Jipsen in the negative.

</details>


### [23] [Ramsey-like theorems for separable permutations](https://arxiv.org/abs/2507.07606)
*Quentin Le Houérou,Ludovic Patey*

Main category: math.LO

TL;DR: 本文研究了无限团边着色中避免特定模式（尤其是可分离排列）的无限子团存在性的计算理论特性，发现可分离排列的避免与标准模型中无限齐次集的存在等价。


<details>
  <summary>Details</summary>
Motivation: 探讨无限团边着色中避免特定模式（特别是可分离排列）的无限子团的计算理论特性，以理解这些模式在计算复杂性中的独特作用。

Method: 通过相对化对角非计算的新论证方法，分析不同模式（尤其是可分离排列）在无限团着色中的计算等价性。

Result: 证明可分离排列的避免与标准模型中无限齐次集的存在等价，而其他模式不具备此性质。

Conclusion: 可分离排列在计算理论中具有独特地位，其避免性与无限齐次集的存在性等价，这一性质不适用于其他模式。

Abstract: We conduct a computability-theoretic study of Ramsey-like theorems of the
form "Every coloring of the edges of an infinite clique admits an infinite
sub-clique avoiding some pattern", with a particular focus on transitive
patterns. As it turns out, the patterns corresponding to separable permutations
play an important role in the computational features of the statement. We prove
that the avoidance of any separable permutation is equivalent to the existence
of an infinite homogeneous set in standard models, while this property fails
for any other pattern. For this, we develop a novel argument for relativized
diagonal non-computation.

</details>


### [24] [Hyper-u-amenablity and Hyperfiniteness of Treeable Equivalence Relations](https://arxiv.org/abs/2507.07891)
*Petr Naryshkin,Andrea Vaccaro*

Main category: math.LO

TL;DR: 本文引入u-可驯性和超u-可驯性概念，证明树状可分的超u-可驯可数Borel等价关系是超有限的，并得出若干推论。


<details>
  <summary>Details</summary>
Motivation: 研究可数Borel等价关系的强可驯性形式，特别是那些由超有限性隐含的性质，以扩展对等价关系分类的理解。

Method: 通过引入u-可驯性和超u-可驯性概念，结合树状可分性和超有限性，分析可数Borel等价关系的性质。

Result: 证明了树状可分的超u-可驯可数Borel等价关系是超有限的，并得出若干关于自由群轨道等价关系和可驯群作用的推论。

Conclusion: 树状可分且满足特定可驯条件的可数Borel等价关系具有超有限性，这为相关分类问题提供了新的理论工具。

Abstract: We introduce the notions of u-amenability and hyper-u-amenability for
countable Borel equivalence relations, strong forms of amenability that are
implied by hyperfiniteness. We show that treeable, hyper-u-amenable countable
Borel equivalence relations are hyperfinite. One of the corollaries that we get
is that if a countable Borel equivalence relation is measure-hyperfinite and
equal to the orbit equivalence relation of a free continuous action of a free
group (with $k \ge 2$ or $k = \infty$ generators) on a $\sigma$-compact Polish
space, then it is hyperfinite. We also obtain that if a countable Borel
equivalence relation is treeable and equal to the orbit equivalence relation of
a Borel action of an amenable group on a standard Borel space, or if it is
treeable, amenable and Borel bounded, then it is hyperfinite.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [25] [Statistics on $\ell$-interval parking functions](https://arxiv.org/abs/2507.07243)
*Kyle Celano,Jennifer Elder,Kimberly P. Hadaway,Pamela E. Harris,Jeremy L. Martin,Amanda Priestley,Gabe Udell*

Main category: math.CO

TL;DR: 本文研究了$\ell$-间隔停车函数，统计了其反转、位移和主指标，证明了特定条件下Foata双射保持$\ell$-间隔停车函数集，并给出了1-间隔停车函数固定反转数的闭式公式。


<details>
  <summary>Details</summary>
Motivation: 研究停车函数中车辆位移限制为$\ell$的$\ell$-间隔停车函数，探索其组合性质与统计分布规律。

Method: 通过枚举和组合分析，研究了$\ell$-间隔停车函数的反转、位移和主指标统计量，并验证了Foata双射的适用条件。

Result: 发现1-间隔停车函数固定位移呈现循环筛选现象，给出了固定反转数的闭式公式，证明了Foata双射在$\ell\leq 2$或$\ell\geq n-2$时保持$\ell$-间隔停车函数集。

Conclusion: 研究揭示了$\ell$-间隔停车函数的组合特性，特别是在$\ell\leq 2$或$\ell\geq n-2$时，反转和主指标统计量具有等分布性质。

Abstract: The displacement of a car with respect to a parking function is the number of
spots it must drive past its preferred spot in order to park. An
$\ell$-interval parking function is one in which each car has displacement at
most $\ell$. Among our results, we enumerate $\ell$-interval parking functions
with respect to statistics such as inversion, displacement, and major index. We
show that $1$-interval parking functions with fixed displacement exhibit a
cyclic sieving phenomenon. We give closed formulas for the number of
$1$-interval parking functions with a fixed number of inversions. We prove that
a well-known bijection of Foata preserves the set of $\ell$-interval parking
functions exactly when $\ell\leq 2$ or $\ell\geq n-2$, which implies that the
inversion and major index statistics are equidistributed in these cases.

</details>


### [26] [A simple proof of a $(p,2)$-theorem for non-piercing regions](https://arxiv.org/abs/2507.07269)
*Chaya Keller,Shakhar Smorodinsky*

Main category: math.CO

TL;DR: 本文证明对于满足$(p,2)$-性质的平面非穿透区域族，使用超图理论可将其穿透点数优化至$O(p)$，显著优于现有几何方法的$O(p^9)$结果。


<details>
  <summary>Details</summary>
Motivation: 现有几何方法证明非穿透区域族在$(p,2)$-性质下需$O(p^9)$穿透点，但理论框架暗示可能存在更优解。本文旨在通过超图理论简化证明并改进该上界。

Method: 利用具有遗传线性Delaunay图的超图理论成果（涵盖非穿透区域交集超图），将几何问题转化为超图穿透问题进行分析。

Result: 证明满足$(p,2)$-性质的广义非穿透区域族仅需$O(p)$穿透点，较先前$O(p^9)$结果实现指数级优化。

Conclusion: 通过超图理论框架，本文不仅简化了复杂几何证明，还将穿透点数上界降至线性阶，为非穿透区域族的组合研究提供了新工具。

Abstract: A family of sets satisfies the $(p,2)$-property if among any $p$ sets in the
family, some two intersect. Two recent works used elaborate geometric
techniques to show that any family of non-piercing regions in the plane that
satisfies the $(p,2)$-property can be pierced by $O(p^9)$ points. In this note
we show that even in a much more general setting, piercing by $O(p)$ points can
be deduced from known results on hypergraphs with a hereditarily linear
Delaunay graph, which include intersection hypergraphs of non-piercing regions.

</details>


### [27] [Spanning k-trees, odd [1,b]-factors and spectral radius in binding graphs](https://arxiv.org/abs/2507.07301)
*Jiancheng Wu,Sizhong Zhou*

Main category: math.CO

TL;DR: 本文通过邻接谱半径提出了两个紧密的充分条件：一是关于连通$\frac{1}{b}$-绑定图存在奇$[1,b]$-因子的条件，推广并改进了Fan和Lin以及Fan、Liu和Ao的先前结果；二是关于连通$\frac{1}{k-2}$-绑定图存在生成$k$-树的条件，部分改进了Fan、Liu和Ao的先前工作。


<details>
  <summary>Details</summary>
Motivation: 研究图的绑定数与特定子结构（如奇$[1,b]$-因子和生成$k$-树）之间的关系，并通过谱方法提供新的充分条件，以推广和改进现有结果。

Method: 利用图的邻接谱半径作为工具，结合绑定数的定义，推导出保证图中存在奇$[1,b]$-因子和生成$k$-树的充分条件。

Result: 1. 对于连通$\frac{1}{b}$-绑定图，给出了一个关于邻接谱半径的紧密充分条件，确保其存在奇$[1,b]$-因子；2. 对于连通$\frac{1}{k-2}$-绑定图，提出了一个关于邻接谱半径的紧密充分条件，确保其存在生成$k$-树。

Conclusion: 本文通过谱方法成功推广并改进了关于绑定图子结构存在的充分条件，为图论中相关问题的研究提供了新的工具和视角。

Abstract: The binding number of a graph $G$, written as $\mbox{bind}(G)$, is defined by
$$ \mbox{bind}(G)=\min\left\{\frac{|N_G(X)|}{|X|}:\emptyset\neq X\subseteq
V(G),N_G(X)\neq V(G)\right\}. $$ A graph $G$ is called $r$-binding if
$\mbox{bind}(G)\geq r$. An odd $[1,b]$-factor of a graph $G$ is a spanning
subgraph $F$ with $d_F(v)\in\{1,3,\ldots,b\}$ for all $v\in V(G)$, where
$b\geq1$ is an odd integer. A spanning $k$-tree of a connected graph $G$ is a
spanning tree $T$ with $d_T(v)\leq k$ for every $v\in V(G)$. In this paper, we
first show a tight sufficient condition with respect to the adjacency spectral
radius for connected $\frac{1}{b}$-binding graphs to have odd $[1,b]$-factors,
which generalizes Fan and Lin's previous result [D. Fan, H. Lin, Binding
number, $k$-factor and spectral radius of graphs, Electron. J. Combin. 31(1)
(2024) \#P1.30] and partly improves Fan, Liu and Ao's previous result [A. Fan,
R. Liu, G. Ao, Spectral radius, odd $[1,b]$-factor and spanning $k$-tree of
1-binding graphs, Linear Algebra Appl. 705 (2025) 1--16]. Then we put forward a
tight sufficient condition via the adjacency spectral radius for connected
$\frac{1}{k-2}$-binding graphs to have spanning $k$-trees, which partly
improves Fan, Liu and Ao's previous result [A. Fan, R. Liu, G. Ao, Spectral
radius, odd $[1,b]$-factor and spanning $k$-tree of 1-binding graphs, Linear
Algebra Appl. 705 (2025) 1--16].

</details>


### [28] [Volumes of moduli spaces of directed ribbon graphs and Cut-and-Join operators](https://arxiv.org/abs/2507.07308)
*Simon Barazer*

Main category: math.CO

TL;DR: 本文研究了无环分解的代数结构，定义了相关积分算子并证明其满足切割-连接方程，最终生成儿童绘图（dessins d'enfants）的生成级数。


<details>
  <summary>Details</summary>
Motivation: 探索有向度量带状图的无环分解代数结构，以递归计算其模空间体积，并建立与儿童绘图的联系。

Method: 基于无环分解构建积分算子，证明其满足切割-连接型方程，并通过特化算子生成儿童绘图的级数。

Result: 积分算子满足切割-连接方程，且特化后可生成儿童绘图（dessins d'enfants）的级数。

Conclusion: 无环分解的代数结构为模空间体积计算提供了递归方法，其算子特化可系统生成儿童绘图，揭示了组合与几何的深层联系。

Abstract: In this paper, we investigate the algebraic structure underlying the acyclic
decomposition. This decomposition applies to directed metric ribbon graphs and
enables the recursive computation of the volumes of their moduli spaces.
Building on this, we define integral operators with these volumes and show that
they satisfy a Cut-and-Join type equation. Furthermore, we demonstrate that a
suitable specialization of these operators gives rise to a generating series
for \textit{dessins d'enfants}.

</details>


### [29] [Exact Turán densities in triple systems](https://arxiv.org/abs/2507.07360)
*Nannan Chen,Yuzhen Qi,Caihong Yang,Hongbin Zhao*

Main category: math.CO

TL;DR: 本文证明了几个关于3-图的新Tur\'{a}n密度结果，包括确认Shi的猜想并解决了Mubayi和R\"odl提出的几个特殊非主族问题。


<details>
  <summary>Details</summary>
Motivation: 研究3-图的Tur\'{a}n密度问题，验证已有猜想并解决非主族问题，推动极值图论领域的发展。

Method: 通过数学证明方法，计算并验证了几个特定3-图结构的Tur\'{a}n密度值。

Result: 得到三个主要结果：$\pi(C_4^3, \mathrm{complement\ of\ } F_5) = 2\sqrt{3} - 3$，$\pi(F_{3,2}, C_5^{3-}) = \frac{2}{9}$，以及$\pi(F_{3,2}, \mathrm{induced\ complement\ of\ } F_{3,2}) = \frac{3}{8}$。

Conclusion: 本文不仅确认了Shi的猜想，还解决了Mubayi和R\"odl提出的几个非主族问题，为3-图的Tur\'{a}n密度研究提供了新的理论支持。

Abstract: In this paper, we prove several new Tur\'{a}n density results for $3$-graphs.
We show: $\pi(C_4^3, \mathrm{complement\ of\ } F_5) = 2\sqrt{3} - 3$,
$\pi(F_{3,2}, C_5^{3-}) = \frac{2}{9}$, and $\pi(F_{3,2}, \mathrm{induced\
complement\ of\ } F_{3,2}) = \frac{3}{8}$. The first result confirms the
conjecture of Shi~[On Tur\'an denisties of small triple graphs, European J.
Combin. 52 (2016) 95-102]. The other results give several special non-principal
family posed by Mubayi and R\"odl~[On the Tur\'an number of triple systems, J.
Combin. Theory A. 100 (2002) 135-152].

</details>


### [30] [Deterministic simplicial complexes](https://arxiv.org/abs/2507.07402)
*S. N. Dorogovtsev,P. L. Krapivsky*

Main category: math.CO

TL;DR: 研究从单顶点确定性增长的单纯复形，发现其具有快速增长的单纯形数量和幂律分布的上度特性，并探讨了约束模型下的不同维度行为。


<details>
  <summary>Details</summary>
Motivation: 探索确定性增长的单纯复形的局部和全局特性，特别是单纯形数量的增长模式和度分布的演化规律。

Method: 通过递归步骤构建单纯复形，每一步为现有的每个$d$-维单纯形添加一个新顶点形成$(d+1)$-维单纯形，并计算Hodge Laplacian谱和Hausdorff维度。

Result: 单纯形数量增长快于$n!$，上度分布呈幂律；约束模型中，单纯形数量指数增长，$m=1$时谱维度为2，$m=2$时谱维度有限且1-度分布指数衰减。

Conclusion: 确定性增长的单纯复形展现出复杂的局部和全局特性，约束模型的行为与维度选择密切相关，为理解高维结构提供了新视角。

Abstract: We investigate simplicial complexes deterministically growing from a single
vertex. In the first step, a vertex and an edge connecting it to the primordial
vertex are added. The resulting simplicial complex has a 1-dimensional simplex
and two 0-dimensional faces (the vertices). The process continues recursively:
On the $n$-th step, every existing $d-$dimensional simplex ($d\leq n-1$) joins
a new vertex forming a $(d+1)-$dimensional simplex; all $2^{d+1}-2$ new faces
are also added so that the resulting object remains a simplicial complex. The
emerging simplicial complex has intriguing local and global characteristics.
The number of simplices grows faster than $n!$, and the upper-degree
distributions follow a power law. Here, the upper degree (or $d$-degree) of a
$d$-simplex refers to the number of $(d{+}1)$-simplices that share it as a
face. Interestingly, the $d$-degree distributions evolve quite differently for
different values of $d$. We compute the Hodge Laplacian spectra of simplicial
complexes and show that the spectral and Hausdorff dimensions are infinite. We
also explore a constrained version where the dimension of the added simplices
is fixed to a finite value $m$. In the constrained model, the number of
simplices grows exponentially. In particular, for $m=1$, the spectral dimension
is $2$. For $m=2$, the spectral dimension is finite, and the degree
distribution follows a power law, while the $1$-degree distribution decays
exponentially.

</details>


### [31] [Cocompact unfolding trees](https://arxiv.org/abs/2507.07503)
*Roman Gorazd*

Main category: math.CO

TL;DR: 本文研究了有限有向根图的根路径树在其无向自同构群作用下仅具有有限轨道（即紧合性）的条件，并提供了判定算法。


<details>
  <summary>Details</summary>
Motivation: 旨在解决arXiv:2212.07205中问题(1)，明确哪些树与紧合树几乎同构。

Method: 通过分析根路径树的轨道有限性，提出了一种判定算法。

Result: 确定了紧合树的条件，并给出了相应的判定方法。

Conclusion: 该研究为树结构的紧合性提供了理论依据和实用判定工具。

Abstract: This paper will show when a rooted path tree of a finite directed rooted
graph has only finitely many orbits under the action of its undirected
automorphism group (i.e. when it is cocompact). This will allow us to specify
which trees are almost isomorphic to cocompact trees. We will provide an
algorithm that will determine this, thus mostly answering question (1) from
arXiv:2212.07205.

</details>


### [32] [Evasive sets, twisted varieties, and container-clique trees](https://arxiv.org/abs/2507.07594)
*Jeck Lim,Jiaxi Nie,Ji Zeng*

Main category: math.CO

TL;DR: 本文研究了有限域$\mathbb{F}_q^n$中的$(d,k,r)$-规避集，证明了其存在性并给出了枚举上界。通过研究射影空间中的扭曲簇，提出了新的容器方法技术。


<details>
  <summary>Details</summary>
Motivation: 研究有限域中规避集的存在性和数量上界，为相关数学问题提供理论支持。

Method: 采用平均论证和扭曲簇理论，开发了新的容器方法技术用于枚举。

Result: 证明了$(d,k,r)$-规避集的存在性，其规模至少为$\Omega\left(q^{n-k}\right)$，并给出了枚举上界$2^{O(q^{n-k})}$。

Conclusion: 本文不仅改进了规避集的构造，还提出了新的枚举技术，为相关领域的研究提供了新工具。

Abstract: In the affine space $\mathbb{F}_q^n$ over the finite field of order $q$, a
point set $S$ is said to be $(d,k,r)$-evasive if the intersection between $S$
and any variety, of dimension $k$ and degree at most $d$, has cardinality less
than $r$. As $q$ tends to infinity, the size of a $(d,k,r)$-evasive set in
$\mathbb{F}_q^n$ is at most $O\left(q^{n-k}\right)$ by a simple averaging
argument. We exhibit the existence of such evasive sets of sizes at least
$\Omega\left(q^{n-k}\right)$ for much smaller values of $r$ than previously
known constructions, and establish an enumerative upper bound $2^{O(q^{n-k})}$
for the total number of such evasive sets. The existence result is based on our
study of twisted varieties. In the projective space $\mathbb{P}^n$ over an
algebraically closed field, a variety $V$ is said to be $d$-twisted if the
intersection between $V$ and any variety, of dimension $n - \dim(V)$ and degree
at most $d$, has dimension zero. We prove an upper bound on the smallest
possible degree of twisted varieties which is best possible in a mild sense.
The enumeration result includes a new technique for the container method which
we believe is of independent interest. To illustrate the potential of this
technique, we give a simpler proof of a result by Chen--Liu--Nie--Zeng that
characterizes the maximum size of a collinear-triple-free subset in a random
sampling of $ \mathbb{F}_q^2$ up to polylogarithmic factors.

</details>


### [33] [A constructive characterization of uniformly 4-connected graphs](https://arxiv.org/abs/2507.07656)
*Xiang Chen,Shuai Kou,Chengfu Qin,Liqiong Xu,Weihua Yang*

Main category: math.CO

TL;DR: 本文提出了均匀4连通图类的构造性特征，基于对特定顶点和边集应用图操作，表明所有均匀4连通图均可从$C_5^2$或$C_6^2$通过$\Delta_1^+$或$\Delta_2^+$操作生成。


<details>
  <summary>Details</summary>
Motivation: 研究均匀4连通图的结构特征，旨在建立其系统性构造方法，填补该图类理论表征的空白。

Method: 采用图操作（$\Delta_1^+$和$\Delta_2^+$）作用于拟4兼容集，从基础图$C_5^2$和$C_6^2$递归构造所有均匀4连通图。

Result: 证明任何均匀4连通图均可通过有限次指定操作从两类基础图派生，完整刻画了该图类的生成机制。

Conclusion: 该特征化定理为均匀4连通图提供了明确的构造范式，其操作导向的方法可推广至更高连通度图类的研究。

Abstract: A constructive characterization of the class of uniformly $4$-connected
graphs is presented. The characterization is based on the application of graph
operations to appropriate vertex and edge sets in uniformly $4$-connected
graphs, that is, any uniformly $4$-connected graph can be obtained from $C_5^2$
or $C_6^2$ by a number of $\Delta_1^+$ or $\Delta_2^+$-operations to quasi
$4$-compatible sets.

</details>


### [34] [Regular sets in Cayley sum graphs on generalized dicyclic groups](https://arxiv.org/abs/2507.07736)
*Meiqi Peng,Yuefeng Yang,Wenying Zhu*

Main category: math.CO

TL;DR: 本文研究了广义双循环群$G$中$(\alpha,\beta)$-正则集的性质，通过给定适当的连接集$S$，确定了子群$H$作为$G$的$(\alpha,\beta)$-正则集的所有可能情况。


<details>
  <summary>Details</summary>
Motivation: 研究图的$(\alpha,\beta)$-正则集在群论中的应用，特别是在广义双循环群的Cayley和图中，探索子群作为正则集的条件。

Method: 对于广义双循环群$G$的每个子群$H$，通过构造适当的连接集$S$，分析$H$在Cayley和图中作为$(\alpha,\beta)$-正则集的可能性。

Result: 确定了广义双循环群$G$的每个子群$H$作为$(\alpha,\beta)$-正则集的所有可能的$(\alpha,\beta)$值对。

Conclusion: 通过构造特定的连接集$S$，可以系统地确定广义双循环群中子群作为$(\alpha,\beta)$-正则集的条件，为相关图论问题提供了新的解决途径。

Abstract: For a graph $\Gamma=(V(\Gamma),E(\Gamma))$, a subset $C$ of $V(\Gamma)$ is
called an $(\alpha,\beta)$-regular set in $\Gamma$, if every vertex of $C$ is
adjacent to exactly $\alpha$ vertices of $C$ and every vertex of
$V(\Gamma)\setminus C$ is adjacent to exactly $\beta$ vertices of $C$. In
particular, if $C$ is an $(\alpha,\beta)$-regular set in some Cayley sum graph
of a finite group $G$ with connection set $S$, then $C$ is called an
$(\alpha,\beta)$-regular set of $G$. In this paper, we consider a generalized
dicyclic group $G$ and for each subgroup $H$ of $G$, by giving an appropriate
connection set $S$, we determine each possibility for $(\alpha,\beta)$ such
that $H$ is an $(\alpha,\beta)$-regular set of $G$.

</details>


### [35] [Constructing Optimal Kobon Triangle Arrangements via Table Encoding, SAT Solving, and Heuristic Straightening](https://arxiv.org/abs/2507.07951)
*Pavlo Savchuk*

Main category: math.CO

TL;DR: 本文提出了构建最优Kobon三角形排列的新方法与结果，包括紧凑表格表示法、启发式恢复工具及基于SAT求解器的优化搜索，发现了23线和27线的新最优排列。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发更高效的方法来表示、分析和寻找Kobon三角形的最优排列，解决复杂情况（如对称排列、平行线及多线交点）的表示难题。

Method: 1. 引入紧凑表格表示伪线排列；2. 开发启发式工具从表格恢复直线排列并保持对称性；3. 将最优排列搜索转化为SAT问题，利用Kissat求解器高效求解。

Result: 工具成功恢复了已知最优解，并发现23线和27线的新最优排列。通过SAT求解确认11线情况下无更优解。

Conclusion: 新方法显著提升了Kobon三角形排列的搜索效率与表示能力，为组合几何领域提供了实用工具与理论验证手段。

Abstract: We present new methods and results for constructing optimal Kobon triangle
arrangements. First, we introduce a compact table notation for describing
arrangements of pseudolines, enabling the representation and analysis of
complex cases, including symmetrical arrangements, arrangements with parallel
lines, and arrangements with multiple-line intersection points. Building on
this, we provide a simple heuristic method and tools for recovering
straight-line arrangements from a given table, with the ability to enforce
additional properties such as symmetries. The tool successfully recovers
arrangements for many previously known optimal solutions. Additionally, we
develop a tool that transforms the search for optimal Kobon arrangement tables
into a SAT problem, allowing us to leverage modern SAT solvers (specifically
Kissat) to efficiently find new solutions or to show that no other solutions
exist (for example, confirming that no optimal solution exists in the 11-line
case). Using these techniques, we find new optimal Kobon arrangements for 23
and 27 lines, along with several other new results.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [36] [Time Series Foundation Models for Multivariate Financial Time Series Forecasting](https://arxiv.org/abs/2507.07296)
*Ben A. Marconi*

Main category: q-fin.GN

TL;DR: 时间序列基础模型（TSFMs）在金融时间序列预测中展现出潜力，特别是在数据有限的任务中。Tiny Time Mixers（TTM）表现出较强的迁移能力，预训练版本在有限数据上微调后性能提升25-50%，且零样本预测优于基准模型。然而，传统专业模型在部分任务中仍优于TSFMs，表明TSFMs需进一步优化以适应金融时间序列特性。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列预测面临非线性关系、时间依赖性、变量互依性及数据有限等挑战，尤其对于低频数据、新上市工具或新兴市场资产。时间序列基础模型（TSFMs）通过预训练和任务适配提供解决方案。

Method: 研究评估了两种TSFMs（TTM和Chronos）在三个金融预测任务中的表现：美国10年期国债收益率变化、欧元/美元波动率及股票价差预测。比较了预训练模型与未训练模型的微调效果及零样本性能。

Result: TTM预训练模型在有限数据上微调后性能提升25-50%，在较长数据上提升15-30%。其零样本预测在波动率和股票价差任务中优于基准模型。预训练模型需3-10年更少数据达到相同性能，但传统专业模型在两项任务中表现更优。

Conclusion: TSFMs在金融预测中具有潜力，尤其在噪声大、数据有限的任务中，但需针对金融时间序列特性进行领域特定预训练和架构优化，以提升竞争力。

Abstract: Financial time series forecasting presents significant challenges due to
complex nonlinear relationships, temporal dependencies, variable
interdependencies and limited data availability, particularly for tasks
involving low-frequency data, newly listed instruments, or emerging market
assets. Time Series Foundation Models (TSFMs) offer a promising solution
through pretraining on diverse time series corpora followed by task-specific
adaptation. This study evaluates two TSFMs (Tiny Time Mixers (TTM) and Chronos)
across three financial forecasting tasks: US 10-year Treasury yield changes,
EUR/USD volatility, and equity spread prediction. Results demonstrate that TTM
exhibits strong transferability. When fine-tuning both the pretrained version
of TTM and an untrained model with the same architecture, the pretrained
version achieved 25-50% better performance when fine-tuned on limited data and
15-30% improvements even when fine-tuned on lengthier datasets. Notably, TTM's
zero-shot performance outperformed naive benchmarks in volatility forecasting
and equity spread prediction, with the latter demonstrating that TSFMs can
surpass traditional benchmark models without fine-tuning. The pretrained model
consistently required 3-10 fewer years of data to achieve comparable
performance levels compared to the untrained model, demonstrating significant
sample-efficiency gains. However, while TTM outperformed naive baselines,
traditional specialised models matched or exceeded its performance in two of
three tasks, suggesting TSFMs prioritise breadth over task-specific
optimisation. These findings indicate that TSFMs, though still nascent, offer
substantial promise for financial forecasting-particularly in noisy,
data-constrained tasks-but achieving competitive performance likely requires
domain-specific pretraining and architectural refinements tailored to financial
time series characteristics.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [37] [WatchWitch: Interoperability, Privacy, and Autonomy for the Apple Watch](https://arxiv.org/abs/2507.07210)
*Nils Rollshausen,Alexander Heinrich,Matthias Hollick,Jiska Classen*

Main category: cs.CR

TL;DR: 研究团队首次公开逆向工程Apple Watch的无线协议，发现其专有实现中的多个安全问题，并开发了Android版WatchWitch实现跨平台互联，增强用户隐私控制与数据自主权。


<details>
  <summary>Details</summary>
Motivation: Apple Watch等智能手表收集大量敏感健康数据，但用户无法选择数据处理方式——设备仅支持iPhone及苹果云服务，存在生态封闭性问题。

Method: 通过逆向工程破解手表无线通信协议，开发定制化Android系统WatchWitch，突破苹果封闭生态的技术限制。

Result: 发现苹果专有协议的多项安全漏洞，成功实现Android设备与Apple Watch的互操作，提供更灵活的隐私控制选项。

Conclusion: 该研究为智能手表生态系统开创了消费者自主选择的可能性，使用户获得对设备的更高控制权。

Abstract: Smartwatches such as the Apple Watch collect vast amounts of intimate health
and fitness data as we wear them. Users have little choice regarding how this
data is processed: The Apple Watch can only be used with Apple's iPhones, using
their software and their cloud services. We are the first to publicly
reverse-engineer the watch's wireless protocols, which led to discovering
multiple security issues in Apple's proprietary implementation. With
WatchWitch, our custom Android reimplementation, we break out of Apple's walled
garden -- demonstrating practical interoperability with enhanced privacy
controls and data autonomy. We thus pave the way for more consumer choice in
the smartwatch ecosystem, offering users more control over their devices.

</details>


### [38] [Automated Attack Testflow Extraction from Cyber Threat Report using BERT for Contextual Analysis](https://arxiv.org/abs/2507.07244)
*Faissal Ahmadou,Sepehr Ghaffarzadegan,Boubakr Nour,Makan Pourzandi,Mourad Debbabi,Chadi Assi*

Main category: cs.CR

TL;DR: 本文提出FLOWGUARDIAN系统，利用BERT模型与NLP技术自动从非结构化威胁报告中提取攻击测试流，显著提升网络安全测试效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 当前网络安全领域依赖人工从威胁报告中提取攻击测试流，存在耗时、易错且依赖专家知识的问题，亟需自动化解决方案。

Method: 采用BERT语言模型与自然语言处理技术，系统化分析安全事件上下文，重构攻击序列并生成完整测试流。

Result: 基于公开威胁报告的实证验证表明，该系统在准确性和效率上表现优异，能有效增强安全团队的主动威胁狩猎与事件响应能力。

Conclusion: FLOWGUARDIAN通过自动化测试流提取，在减少人工错误的同时确保全面覆盖，为网络安全测试提供了可靠的新工具。

Abstract: In the ever-evolving landscape of cybersecurity, the rapid identification and
mitigation of Advanced Persistent Threats (APTs) is crucial. Security
practitioners rely on detailed threat reports to understand the tactics,
techniques, and procedures (TTPs) employed by attackers. However, manually
extracting attack testflows from these reports requires elusive knowledge and
is time-consuming and prone to errors. This paper proposes FLOWGUARDIAN, a
novel solution leveraging language models (i.e., BERT) and Natural Language
Processing (NLP) techniques to automate the extraction of attack testflows from
unstructured threat reports. FLOWGUARDIAN systematically analyzes and
contextualizes security events, reconstructs attack sequences, and then
generates comprehensive testflows. This automated approach not only saves time
and reduces human error but also ensures comprehensive coverage and robustness
in cybersecurity testing. Empirical validation using public threat reports
demonstrates FLOWGUARDIAN's accuracy and efficiency, significantly enhancing
the capabilities of security teams in proactive threat hunting and incident
response.

</details>


### [39] [Disa: Accurate Learning-based Static Disassembly with Attentions](https://arxiv.org/abs/2507.07246)
*Peicheng Wang,Monika Santra,Mingyu Liu,Cong Sun,Dongrui Zeng,Gang Tan*

Main category: cs.CR

TL;DR: 本文提出Disa，一种基于学习的反汇编方法，利用多头自注意力机制学习指令相关性，显著提升反汇编精度，尤其在混淆二进制文件中表现优异。


<details>
  <summary>Details</summary>
Motivation: 反汇编在安全领域至关重要，但传统方法依赖文件格式假设和架构特定启发式，导致结果不完整且易出错，尤其在混淆二进制中。深度学习为提升反汇编精度和效率提供了新思路。

Method: Disa采用多头自注意力机制学习指令相关性，推断函数入口点和指令边界，并识别与内存块边界相关的指令，支持基于块内存模型的精确控制流图生成。

Result: 实验表明，Disa在函数入口点识别上优于现有深度学习方法，对反汇编去同步技术和源码级混淆器处理的二进制文件，F1分数分别提升9.1%和13.2%。内存块精度提高18.5%，间接调用目标数减少4.4%。

Conclusion: Disa通过深度学习显著提升反汇编精度，尤其在处理混淆代码时表现突出，为生成更准确的控制流图提供了有效解决方案。

Abstract: For reverse engineering related security domains, such as vulnerability
detection, malware analysis, and binary hardening, disassembly is crucial yet
challenging. The fundamental challenge of disassembly is to identify
instruction and function boundaries. Classic approaches rely on file-format
assumptions and architecture-specific heuristics to guess the boundaries,
resulting in incomplete and incorrect disassembly, especially when the binary
is obfuscated. Recent advancements of disassembly have demonstrated that deep
learning can improve both the accuracy and efficiency of disassembly. In this
paper, we propose Disa, a new learning-based disassembly approach that uses the
information of superset instructions over the multi-head self-attention to
learn the instructions' correlations, thus being able to infer function
entry-points and instruction boundaries. Disa can further identify instructions
relevant to memory block boundaries to facilitate an advanced block-memory
model based value-set analysis for an accurate control flow graph (CFG)
generation. Our experiments show that Disa outperforms prior deep-learning
disassembly approaches in function entry-point identification, especially
achieving 9.1% and 13.2% F1-score improvement on binaries respectively
obfuscated by the disassembly desynchronization technique and popular
source-level obfuscator. By achieving an 18.5% improvement in the memory block
precision, Disa generates more accurate CFGs with a 4.4% reduction in Average
Indirect Call Targets (AICT) compared with the state-of-the-art heuristic-based
approach.

</details>


### [40] [Semi-fragile watermarking of remote sensing images using DWT, vector quantization and automatic tiling](https://arxiv.org/abs/2507.07250)
*Jordi Serra-Ruiz,David Megías*

Main category: cs.CR

TL;DR: 本文提出了一种针对多波段图像的半脆弱水印方案，通过树结构矢量量化方法在像素签名中嵌入水印，以检测原始图像的显著修改。


<details>
  <summary>Details</summary>
Motivation: 为了保护遥感图像免受未经授权的修改，同时允许一定程度的有损压缩，需要一种能够区分恶意篡改和正常压缩的水印技术。

Method: 该方法将多光谱或高光谱图像分割为三维块，为每个块构建树结构矢量量化器，并通过迭代算法操作这些树，直到满足嵌入水印的特定标准。

Result: 实验表明，该方法能够在有损压缩（超过给定阈值）下保留水印，同时能够检测伪造块及其在整个图像中的位置。

Conclusion: 所提出的半脆弱水印方案有效地平衡了水印的鲁棒性和脆弱性，适用于遥感图像的完整性验证。

Abstract: A semi-fragile watermarking scheme for multiple band images is presented in
this article. We propose to embed a mark into remote sensing images applying a
tree-structured vector quantization approach to the pixel signatures instead of
processing each band separately. The signature of the multispectral or
hyperspectral image is used to embed the mark in it order to detect any
significant modification of the original image. The image is segmented into
three-dimensional blocks, and a tree-structured vector quantizer is built for
each block. These trees are manipulated using an iterative algorithm until the
resulting block satisfies a required criterion, which establishes the embedded
mark. The method is shown to be able to preserve the mark under lossy
compression (above a given threshold) but, at the same time, it detects
possibly forged blocks and their position in the whole image.

</details>


### [41] [FedP3E: Privacy-Preserving Prototype Exchange for Non-IID IoT Malware Detection in Cross-Silo Federated Learning](https://arxiv.org/abs/2507.07258)
*Rami Darwish,Mahmoud Abdelsalam,Sajad Khorsandroo,Kaushik Roy*

Main category: cs.CR

TL;DR: 本文提出FedP3E框架，通过隐私保护的类原型交换解决物联网(IoT)恶意软件检测中数据异构和类别不平衡问题，在联邦学习环境中实现高效且隐私安全的跨客户端知识共享。


<details>
  <summary>Details</summary>
Motivation: 物联网设备面临日益复杂的恶意软件攻击，现有联邦学习算法(FedAvg/FedProx)在非独立同分布(non-IID)和类别不平衡数据下表现不佳，需兼顾隐私保护与检测效能。

Method: 采用高斯混合模型(GMM)构建类原型，添加高斯噪声后上传服务器聚合，结合SMOTE增强少数类样本，通过原型交换而非原始数据/梯度共享来缓解统计异构性问题。

Result: 在N-BaIoT数据集上的跨机构实验表明，FedP3E能有效处理不同程度的数据不平衡，以较低通信开销提升对稀有恶意软件类别的检测能力。

Conclusion: 原型驱动的联邦学习框架FedP3E为物联网恶意软件检测提供了隐私保护、通信高效且适应数据异构性的新范式，显著优于传统参数平均方法。

Abstract: As IoT ecosystems continue to expand across critical sectors, they have
become prominent targets for increasingly sophisticated and large-scale malware
attacks. The evolving threat landscape, combined with the sensitive nature of
IoT-generated data, demands detection frameworks that are both
privacy-preserving and resilient to data heterogeneity. Federated Learning (FL)
offers a promising solution by enabling decentralized model training without
exposing raw data. However, standard FL algorithms such as FedAvg and FedProx
often fall short in real-world deployments characterized by class imbalance and
non-IID data distributions -- particularly in the presence of rare or disjoint
malware classes. To address these challenges, we propose FedP3E
(Privacy-Preserving Prototype Exchange), a novel FL framework that supports
indirect cross-client representation sharing while maintaining data privacy.
Each client constructs class-wise prototypes using Gaussian Mixture Models
(GMMs), perturbs them with Gaussian noise, and transmits only these compact
summaries to the server. The aggregated prototypes are then distributed back to
clients and integrated into local training, supported by SMOTE-based
augmentation to enhance representation of minority malware classes. Rather than
relying solely on parameter averaging, our prototype-driven mechanism enables
clients to enrich their local models with complementary structural patterns
observed across the federation -- without exchanging raw data or gradients.
This targeted strategy reduces the adverse impact of statistical heterogeneity
with minimal communication overhead. We evaluate FedP3E on the N-BaIoT dataset
under realistic cross-silo scenarios with varying degrees of data imbalance.

</details>


### [42] [Shuffling for Semantic Secrecy](https://arxiv.org/abs/2507.07401)
*Fupei Chen,Liyao Xiang,Haoxiang Sun,Hei Victor Cheng,Kaiming Shen*

Main category: cs.CR

TL;DR: 本文从新颖的乱序角度研究了深度学习语义通信的安全性，提出了一种随机乱序的语义安全通信系统，以在传输速率和泄漏速率之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 现有安全编码方案在传输速率和泄漏速率之间的权衡不足，本文旨在通过乱序技术提升语义通信的安全性。

Method: 设计了一种基于随机乱序模式的语义安全通信系统，通过特征序列的排列扰乱语义本质，使窃听者无法获取有效信息。该方法可作为插件兼容现有系统。

Result: 仿真表明，所提方法在提升安全传输方面显著优于基准方案，尤其在强噪声和不可预测衰落的信道环境下表现突出。

Conclusion: 随机乱序技术有效增强了语义通信的安全性，在保证传输速率的同时最小化语义错误概率，具有实际应用潜力。

Abstract: Deep learning draws heavily on the latest progress in semantic
communications. The present paper aims to examine the security aspect of this
cutting-edge technique from a novel shuffling perspective. Our goal is to
improve upon the conventional secure coding scheme to strike a desirable
tradeoff between transmission rate and leakage rate. To be more specific, for a
wiretap channel, we seek to maximize the transmission rate while minimizing the
semantic error probability under the given leakage rate constraint. Toward this
end, we devise a novel semantic security communication system wherein the
random shuffling pattern plays the role of the shared secret key. Intuitively,
the permutation of feature sequences via shuffling would distort the semantic
essence of the target data to a sufficient extent so that eavesdroppers cannot
access it anymore. The proposed random shuffling method also exhibits its
flexibility in working for the existing semantic communication system as a
plugin. Simulations demonstrate the significant advantage of the proposed
method over the benchmark in boosting secure transmission, especially when
channels are prone to strong noise and unpredictable fading.

</details>


### [43] [Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models](https://arxiv.org/abs/2507.07406)
*Jikesh Thapa,Gurrehmat Chahal,Serban Voinea Gabreanu,Yazan Otoum*

Main category: cs.CR

TL;DR: 本文比较了传统机器学习(ML)、深度学习(DL)与量化小参数大语言模型(LLM)在钓鱼检测中的表现，发现LLM虽当前精度略低，但擅长识别基于上下文的钓鱼线索，且轻量级LLM能兼顾效率与可解释性。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击日益复杂，需平衡高精度与计算效率的检测系统。研究旨在评估不同AI方法在钓鱼检测中的性能与部署可行性。

Method: 使用精选数据集对比ML、DL及量化LLM（如DeepSeek R1 Distill Qwen 14B）性能，测试零样本/少样本提示策略，并分析对抗鲁棒性与成本效益。

Result: LLM当前精度低于ML/DL（80%+准确率，17GB显存），但对上下文线索敏感；提示词重构会显著降低检测器性能；轻量LLM可提供实时可解释结果。

Conclusion: 优化后的LLM有望成为钓鱼防御系统的组件，为网络安全框架提供高效、可解释的AI集成方案。

Abstract: Phishing attacks are becoming increasingly sophisticated, underscoring the
need for detection systems that strike a balance between high accuracy and
computational efficiency. This paper presents a comparative evaluation of
traditional Machine Learning (ML), Deep Learning (DL), and quantized
small-parameter Large Language Models (LLMs) for phishing detection. Through
experiments on a curated dataset, we show that while LLMs currently
underperform compared to ML and DL methods in terms of raw accuracy, they
exhibit strong potential for identifying subtle, context-based phishing cues.
We also investigate the impact of zero-shot and few-shot prompting strategies,
revealing that LLM-rephrased emails can significantly degrade the performance
of both ML and LLM-based detectors. Our benchmarking highlights that models
like DeepSeek R1 Distill Qwen 14B (Q8_0) achieve competitive accuracy, above
80%, using only 17GB of VRAM, supporting their viability for cost-efficient
deployment. We further assess the models' adversarial robustness and
cost-performance tradeoffs, and demonstrate how lightweight LLMs can provide
concise, interpretable explanations to support real-time decision-making. These
findings position optimized LLMs as promising components in phishing defence
systems and offer a path forward for integrating explainable, efficient AI into
modern cybersecurity frameworks.

</details>


### [44] [Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks](https://arxiv.org/abs/2507.07413)
*Mohammad F. Al-Hammouri,Yazan Otoum,Rasha Atwa,Amiya Nayak*

Main category: cs.CR

TL;DR: 本文提出了一种结合传统签名检测与GPT-2语言模型的新型入侵检测方法，在物联网等复杂环境中显著提升检测精度并降低误报率。


<details>
  <summary>Details</summary>
Motivation: 随着物联网等分布式异构环境中网络威胁日益复杂，传统入侵检测系统难以识别新型攻击模式，亟需动态自适应解决方案。

Method: 提出混合框架：将签名检测的可靠性与GPT-2处理非结构化数据、识别语义关系的能力相结合，构建智能入侵检测系统。

Result: 实验表明，该模型检测准确率提升6.3%，误报率降低9.0%，且保持近实时响应能力。

Conclusion: 语言模型与签名检测的融合为构建适应现代网络环境的智能、可扩展、弹性网络安全防御体系提供了新思路。

Abstract: This paper presents a novel approach to intrusion detection by integrating
traditional signature-based methods with the contextual understanding
capabilities of the GPT-2 Large Language Model (LLM). As cyber threats become
increasingly sophisticated, particularly in distributed, heterogeneous, and
resource-constrained environments such as those enabled by the Internet of
Things (IoT), the need for dynamic and adaptive Intrusion Detection Systems
(IDSs) becomes increasingly urgent. While traditional methods remain effective
for detecting known threats, they often fail to recognize new and evolving
attack patterns. In contrast, GPT-2 excels at processing unstructured data and
identifying complex semantic relationships, making it well-suited to uncovering
subtle, zero-day attack vectors. We propose a hybrid IDS framework that merges
the robustness of signature-based techniques with the adaptability of
GPT-2-driven semantic analysis. Experimental evaluations on a representative
intrusion dataset demonstrate that our model enhances detection accuracy by
6.3%, reduces false positives by 9.0%, and maintains near real-time
responsiveness. These results affirm the potential of language model
integration to build intelligent, scalable, and resilient cybersecurity
defences suited for modern connected environments.

</details>


### [45] [Autonomous AI-based Cybersecurity Framework for Critical Infrastructure: Real-Time Threat Mitigation](https://arxiv.org/abs/2507.07416)
*Jenifer Paulraj,Brindha Raghuraman,Nagarani Gopalakrishnan,Yazan Otoum*

Main category: cs.CR

TL;DR: 本文探讨关键基础设施面临的网络安全威胁，提出混合AI驱动的安全框架以增强实时漏洞检测与自动化修复，并研究对抗性AI与合规性挑战。


<details>
  <summary>Details</summary>
Motivation: 关键基础设施（如能源网、医疗设施、交通网络）对社会稳定至关重要，但其互联性加剧了勒索软件、DoS攻击等网络威胁风险。

Method: 采用混合AI驱动的网络安全框架，整合实时漏洞检测、威胁建模与自动化修复技术，同时分析对抗性AI与法规整合的复杂性。

Result: 研究提供了可操作的见解，证明AI能有效提升关键基础设施对新兴网络威胁的防御能力与韧性。

Conclusion: AI驱动的解决方案可显著强化关键基础设施安全，但需应对对抗性攻击与合规性挑战以实现全面防护。

Abstract: Critical infrastructure systems, including energy grids, healthcare
facilities, transportation networks, and water distribution systems, are
pivotal to societal stability and economic resilience. However, the increasing
interconnectivity of these systems exposes them to various cyber threats,
including ransomware, Denial-of-Service (DoS) attacks, and Advanced Persistent
Threats (APTs). This paper examines cybersecurity vulnerabilities in critical
infrastructure, highlighting the threat landscape, attack vectors, and the role
of Artificial Intelligence (AI) in mitigating these risks. We propose a hybrid
AI-driven cybersecurity framework to enhance real-time vulnerability detection,
threat modelling, and automated remediation. This study also addresses the
complexities of adversarial AI, regulatory compliance, and integration. Our
findings provide actionable insights to strengthen the security and resilience
of critical infrastructure systems against emerging cyber threats.

</details>


### [46] [May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks](https://arxiv.org/abs/2507.07417)
*Nishit V. Pandya,Andrey Labunets,Sicun Gao,Earlence Fernandes*

Main category: cs.CR

TL;DR: 本文评估了针对大型语言模型（LLM）提示注入攻击的防御方法的鲁棒性，提出了一种基于注意力的新型攻击算法，并在白盒设置下成功攻击了两种最新防御方法SecAlign和StruQ，攻击成功率高达70%。


<details>
  <summary>Details</summary>
Motivation: 当前许多防御提示注入攻击的方法依赖于微调模型以区分指令和数据，但这些方法在白盒设置下的安全性尚未得到充分验证。本文旨在评估这类防御方法的实际鲁棒性。

Method: 作者提出了一种基于注意力的新型攻击算法，针对文本型LLM，并在两种最新的白盒防御方法SecAlign（CCS 2025）和StruQ（USENIX Security 2025）上进行了测试。

Result: 实验结果表明，所提出的攻击方法在攻击者预算（token数量）适度增加的情况下，攻击成功率高达70%，证明了现有防御方法无法提供所声称的安全特性。

Conclusion: 本文的研究成果为理解白盒设置下提示注入防御的鲁棒性提供了重要进展，并公开了代码和攻击方法以供进一步研究。

Abstract: A popular class of defenses against prompt injection attacks on large
language models (LLMs) relies on fine-tuning the model to separate instructions
and data, so that the LLM does not follow instructions that might be present
with data. There are several academic systems and production-level
implementations of this idea. We evaluate the robustness of this class of
prompt injection defenses in the whitebox setting by constructing strong
optimization-based attacks and showing that the defenses do not provide the
claimed security properties. Specifically, we construct a novel attention-based
attack algorithm for text-based LLMs and apply it to two recent whitebox
defenses SecAlign (CCS 2025) and StruQ (USENIX Security 2025), showing attacks
with success rates of up to 70% with modest increase in attacker budget in
terms of tokens. Our findings make fundamental progress towards understanding
the robustness of prompt injection defenses in the whitebox setting. We release
our code and attacks at https://github.com/nishitvp/better_opts_attacks

</details>


### [47] [RADAR: a Radio-based Analytics for Dynamic Association and Recognition of pseudonyms in VANETs](https://arxiv.org/abs/2507.07732)
*Giovanni Gambigliani Zoccoli,Filip Valgimigli,Dario Stabili,Mirco Marchetti*

Main category: cs.CR

TL;DR: 本文提出RADAR算法，通过结合DSRC和Wi-Fi探针信号提升车辆追踪能力，突破VANETs中的隐私保护假名方案，实验证明Pearson RSSI指标在各类场景下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有VANETs假名方案存在被追踪风险，尤其在攻击者无法全程覆盖车辆路径时，需开发更强大的去匿名化方法以评估系统脆弱性。

Method: 利用车辆发射的DSRC和Wi-Fi探针请求信号，提出三种假名与Wi-Fi标识关联指标（Count、Statistical RSSI、Pearson RSSI），通过仿真对比追踪效果。

Result: 实验表明Pearson RSSI指标在假名更换场景下具有最优追踪性能，且全面优于仅使用DSRC的传统方法。

Conclusion: 多信号融合显著提升车辆追踪能力，公开的代码与仿真场景为后续研究提供基准，揭示了现有隐私保护方案的潜在漏洞。

Abstract: This paper presents RADAR, a tracking algorithm for vehicles participating in
Cooperative Intelligent Transportation Systems (C-ITS) that exploits multiple
radio signals emitted by a modern vehicle to break privacy-preserving pseudonym
schemes deployed in VANETs. This study shows that by combining Dedicated Short
Range Communication (DSRC) and Wi-Fi probe request messages broadcast by the
vehicle, it is possible to improve tracking over standard de-anonymization
approaches that only leverage DSRC, especially in realistic scenarios where the
attacker does not have full coverage of the entire vehicle path. The
experimental evaluation compares three different metrics for pseudonym and
Wi-Fi probe identifier association (Count, Statistical RSSI, and Pearson RSSI),
demonstrating that the Pearson RSSI metric is better at tracking vehicles under
pseudonym-changing schemes in all scenarios and against previous works. As an
additional contribution to the state-of-the-art, we publicly release all
implementations and simulation scenarios used in this work.

</details>


### [48] [Rainbow Artifacts from Electromagnetic Signal Injection Attacks on Image Sensors](https://arxiv.org/abs/2507.07773)
*Youqian Zhang,Xinyu Ji,Zhihao Wang,Qinhong Jiang*

Main category: cs.CR

TL;DR: 研究发现CMOS图像传感器存在新型电磁信号注入攻击漏洞，攻击者可通过模拟域干扰产生彩虹色伪影，导致目标检测模型误判，揭示了视觉感知系统中物理层攻击的严重威胁。


<details>
  <summary>Details</summary>
Motivation: 图像传感器广泛应用于安防监控、自动驾驶等关键系统，其数据完整性直接影响决策安全。现有研究多关注数字域攻击，而模拟域电磁干扰攻击的潜在威胁尚未充分探索。

Method: 通过精心调制的电磁干扰，在CMOS图像传感器捕获的原始图像中诱导彩虹色伪影，并评估其对先进目标检测模型的影响。

Result: 攻击产生的伪影能穿透图像信号处理流水线，导致目标检测模型出现显著误判（如将停车标志误识别为限速标志）。

Conclusion: 该研究揭示了视觉感知栈中物理层攻击的关键漏洞，强调需开发针对性的鲁棒防御机制以保障系统安全。

Abstract: Image sensors are integral to a wide range of safety- and security-critical
systems, including surveillance infrastructure, autonomous vehicles, and
industrial automation. These systems rely on the integrity of visual data to
make decisions. In this work, we investigate a novel class of electromagnetic
signal injection attacks that target the analog domain of image sensors,
allowing adversaries to manipulate raw visual inputs without triggering
conventional digital integrity checks. We uncover a previously undocumented
attack phenomenon on CMOS image sensors: rainbow-like color artifacts induced
in images captured by image sensors through carefully tuned electromagnetic
interference. We further evaluate the impact of these attacks on
state-of-the-art object detection models, showing that the injected artifacts
propagate through the image signal processing pipeline and lead to significant
mispredictions. Our findings highlight a critical and underexplored
vulnerability in the visual perception stack, highlighting the need for more
robust defenses against physical-layer attacks in such systems.

</details>


### [49] [Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking](https://arxiv.org/abs/2507.07871)
*Toluwani Aremu,Noor Hussein,Munachiso Nwadike,Samuele Poppi,Jie Zhang,Karthik Nandakumar,Neil Gong,Nils Lukas*

Main category: cs.CR

TL;DR: 本文提出一种多密钥扩展方法，用于抵御生成式AI水印窃取攻击，通过理论保证和实证验证显著降低伪造效果，并形式化定义了水印伪造的安全威胁模型。


<details>
  <summary>Details</summary>
Motivation: 生成式AI提供商面临水印窃取攻击的威胁，攻击者通过收集无害水印样本伪造有害内容，需开发不依赖水印细节的通用防御方案。

Method: 提出黑盒场景下的多密钥扩展方案，可后验应用于任何模态的水印方法，通过安全博弈理论建模伪造威胁。

Result: 实验证明该方法在多个数据集上显著降低伪造成功率，理论分析验证了防御有效性。

Conclusion: 多密钥机制为生成式AI水印提供了强健的防伪保障，安全博弈框架为水印攻防研究建立了理论基础。

Abstract: Watermarking offers a promising solution for GenAI providers to establish the
provenance of their generated content. A watermark is a hidden signal embedded
in the generated content, whose presence can later be verified using a secret
watermarking key. A threat to GenAI providers are \emph{watermark stealing}
attacks, where users forge a watermark into content that was \emph{not}
generated by the provider's models without access to the secret key, e.g., to
falsely accuse the provider. Stealing attacks collect \emph{harmless}
watermarked samples from the provider's model and aim to maximize the expected
success rate of generating \emph{harmful} watermarked samples. Our work focuses
on mitigating stealing attacks while treating the underlying watermark as a
black-box. Our contributions are: (i) Proposing a multi-key extension to
mitigate stealing attacks that can be applied post-hoc to any watermarking
method across any modality. (ii) We provide theoretical guarantees and
demonstrate empirically that our method makes forging substantially less
effective across multiple datasets, and (iii) we formally define the threat of
watermark forging as the task of generating harmful, watermarked content and
model this threat via security games.

</details>


### [50] [The Trust Fabric: Decentralized Interoperability and Economic Coordination for the Agentic Web](https://arxiv.org/abs/2507.07901)
*Sree Bhargavi Balija,Rekha Singal,Abhishek Singh,Ramesh Raskar,Erfan Darzi,Raghu Bala,Thomas Hardjono,Ken Huang*

Main category: cs.CR

TL;DR: 本文提出Nanda统一架构，通过分布式注册、语义代理卡和动态信任层三大创新，解决AI代理生态系统的互操作性、信任与经济协调问题，实现全球互联的代理互联网。


<details>
  <summary>Details</summary>
Motivation: 现有协议（如MCP、A2A等）无法规模化解决AI代理生态的碎片化问题，亟需新的架构实现互操作性、信任与经济协调。

Method: 采用去中心化框架，结合快速DID代理发现、可验证凭证的语义代理卡、行为证明与策略合规的动态信任层，并引入X42/H42微支付和MAESTRO安全框架。

Result: 实际部署显示医疗应用合规率达99.9%，月交易量显著且隐私保障强，验证了架构在企业和Web3生态中的有效性。

Conclusion: 该架构将密码学证明与策略即代码结合，使代理成为去中心化经济中信任锚定的参与者，推动代理互联网的全球互操作。

Abstract: The fragmentation of AI agent ecosystems has created urgent demands for
interoperability, trust, and economic coordination that current protocols --
including MCP (Hou et al., 2025), A2A (Habler et al., 2025), ACP (Liu et al.,
2025), and Cisco's AGP (Edwards, 2025) -- cannot address at scale. We present
the Nanda Unified Architecture, a decentralized framework built around three
core innovations: fast DID-based agent discovery through distributed
registries, semantic agent cards with verifiable credentials and composability
profiles, and a dynamic trust layer that integrates behavioral attestations
with policy compliance. The system introduces X42/H42 micropayments for
economic coordination and MAESTRO, a security framework incorporating
Synergetics' patented AgentTalk protocol (US Patent 12,244,584 B1) and secure
containerization. Real-world deployments demonstrate 99.9 percent compliance in
healthcare applications and substantial monthly transaction volumes with strong
privacy guarantees. By unifying MIT's trust research with production
deployments from Cisco and Synergetics, we show how cryptographic proofs and
policy-as-code transform agents into trust-anchored participants in a
decentralized economy (Lakshmanan, 2025; Sha, 2025). The result enables a
globally interoperable Internet of Agents where trust becomes the native
currency of collaboration across both enterprise and Web3 ecosystems.

</details>


### [51] [Can Large Language Models Improve Phishing Defense? A Large-Scale Controlled Experiment on Warning Dialogue Explanations](https://arxiv.org/abs/2507.07916)
*Federico Maria Cau,Giuseppe Desolda,Francesco Greco,Lucio Davide Spano,Luca Viganò*

Main category: cs.CR

TL;DR: 研究评估大型语言模型（LLMs）生成钓鱼警告解释的效果，发现其性能可媲美人工编写，且能根据解释风格（特征型/反事实型）针对性降低用户风险。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击通过利用人类行为弱点绕过技术防御，现有警告对话框因解释模糊和内容静态而效果有限，需探索LLMs生成清晰、可扩展解释的潜力。

Method: 开展750人规模的用户研究，对比人工编写与Claude 3.5 Sonnet、Llama 3.3 70B生成的两种解释风格（特征型/反事实型）对点击率和感知指标（信任度、风险认知等）的影响。

Result: LLMs生成的解释在降低钓鱼易感性上媲美或优于人工解释，其中Claude表现突出；特征型解释对真实钓鱼更有效，反事实型减少误报率。工作负荷、性别等因素显著调节警告效果。

Conclusion: LLMs可自动化生成钓鱼警告解释，方案具备可扩展性、适应性且符合人本价值观，为网络安全防护提供新范式。

Abstract: Phishing has become a prominent risk in modern cybersecurity, often used to
bypass technological defences by exploiting predictable human behaviour.
Warning dialogues are a standard mitigation measure, but the lack of
explanatory clarity and static content limits their effectiveness. In this
paper, we report on our research to assess the capacity of Large Language
Models (LLMs) to generate clear, concise, and scalable explanations for
phishing warnings. We carried out a large-scale between-subjects user study (N
= 750) to compare the influence of warning dialogues supplemented with manually
generated explanations against those generated by two LLMs, Claude 3.5 Sonnet
and Llama 3.3 70B. We investigated two explanatory styles (feature-based and
counterfactual) for their effects on behavioural metrics (click-through rate)
and perceptual outcomes (e.g., trust, risk, clarity). The results indicate that
well-constructed LLM-generated explanations can equal or surpass manually
crafted explanations in reducing susceptibility to phishing; Claude-generated
warnings exhibited particularly robust performance. Feature-based explanations
were more effective for genuine phishing attempts, whereas counterfactual
explanations diminished false-positive rates. Other variables such as workload,
gender, and prior familiarity with warning dialogues significantly moderated
warning effectiveness. These results indicate that LLMs can be used to
automatically build explanations for warning users against phishing, and that
such solutions are scalable, adaptive, and consistent with human-centred
values.

</details>


### [52] [KeyDroid: A Large-Scale Analysis of Secure Key Storage in Android Apps](https://arxiv.org/abs/2507.07927)
*Jenny Blessing,Ross J. Anderson,Alastair R. Beresford*

Main category: cs.CR

TL;DR: 本文首次全面调查了Android设备中硬件支持的密钥存储使用情况，发现尽管有行业倡议，但56.3%处理敏感数据的应用未使用可信硬件，仅5.03%使用最安全的独立安全元件。研究还首次实证分析了可信硬件性能，发现高级安全元件在对称和非对称加密中的性能不可行。


<details>
  <summary>Details</summary>
Motivation: 移动设备普遍提供硬件支持的密钥存储以保护敏感数据，但Android应用开发者对可信硬件的实际使用情况及其性能影响尚不明确。本研究旨在填补这一空白。

Method: 研究分析了490,119个Android应用，调查开发者如何使用（或未使用）可信硬件，并与Play Store数据安全标签中自我报告的敏感数据收集行为进行交叉比对。同时首次对移动设备中可信硬件的性能进行实证分析。

Result: 56.3%处理敏感数据的应用未使用任何可信硬件，仅5.03%使用独立安全元件。性能测试表明：协处理器支持的硬件密钥存储对常见加密操作可行，但能防御高级攻击的安全元件在对称加密（非微量负载）和所有非对称加密中性能不可行。

Conclusion: 尽管可信硬件能增强安全性，但其采用率仍然很低，且高级安全元件的性能限制可能阻碍实际部署。研究揭示了安全性与性能之间的关键权衡，为未来移动安全设计提供重要参考。

Abstract: Most contemporary mobile devices offer hardware-backed storage for
cryptographic keys, user data, and other sensitive credentials. Such hardware
protects credentials from extraction by an adversary who has compromised the
main operating system, such as a malicious third-party app. Since 2011, Android
app developers can access trusted hardware via the Android Keystore API. In
this work, we conduct the first comprehensive survey of hardware-backed key
storage in Android devices. We analyze 490 119 Android apps, collecting data on
how trusted hardware is used by app developers (if used at all) and
cross-referencing our findings with sensitive user data collected by each app,
as self-reported by developers via the Play Store's data safety labels.
  We find that despite industry-wide initiatives to encourage adoption, 56.3%
of apps self-reporting as processing sensitive user data do not use Android's
trusted hardware capabilities at all, while just 5.03% of apps collecting some
form of sensitive data use the strongest form of trusted hardware, a secure
element distinct from the main processor. To better understand the potential
downsides of using secure hardware, we conduct the first empirical analysis of
trusted hardware performance in mobile devices, measuring the runtime of common
cryptographic operations across both software- and hardware-backed keystores.
We find that while hardware-backed key storage using a coprocessor is viable
for most common cryptographic operations, secure elements capable of preventing
more advanced attacks make performance infeasible for symmetric encryption with
non-negligible payloads and any kind of asymmetric encryption.

</details>


### [53] [EinHops: Einsum Notation for Expressive Homomorphic Operations on RNS-CKKS Tensors](https://arxiv.org/abs/2507.07972)
*Karthik Garimella,Austin Ebel,Brandon Reagen*

Main category: cs.CR

TL;DR: 本文提出EinHops系统，利用爱因斯坦求和（einsum）符号解决全同态加密（FHE）中多维张量运算的难题，通过显式编码维度和操作实现透明化张量打包策略。


<details>
  <summary>Details</summary>
Motivation: 全同态加密仅支持一维向量运算（如SIMD加法/乘法、循环移位），导致多维张量操作需强制降维处理，现有系统抽象层级过深，不利于调试与优化。

Method: 基于einsum符号显式表达张量结构与运算，将其分解为FHE兼容操作序列，开发开源系统EinHops实现加密张量运算的可视化打包策略。

Result: EinHops在转置、多维收缩等任务中验证了有效性，einsum的显式特性使系统兼具简洁性、通用性和可解释性。

Conclusion: einsum符号为FHE张量运算提供了自然抽象层，EinHops通过开源实现（https://github.com/baahl-nyu/einhops）平衡了功能透明性与执行效率。

Abstract: Fully Homomorphic Encryption (FHE) is an encryption scheme that allows for
computation to be performed directly on encrypted data, effectively closing the
loop on secure and outsourced computing. Data is encrypted not only during rest
and transit, but also during processing. However, FHE provides a limited
instruction set: SIMD addition, SIMD multiplication, and cyclic rotation of 1-D
vectors. This restriction makes performing multi-dimensional tensor operations
challenging. Practitioners must pack these tensors into 1-D vectors and map
tensor operations onto this one-dimensional layout rather than their
traditional nested structure. And while prior systems have made significant
strides in automating this process, they often hide critical packing decisions
behind layers of abstraction, making debugging, optimizing, and building on top
of these systems difficult.
  In this work, we approach multi-dimensional tensor operations in FHE through
Einstein summation (einsum) notation. Einsum notation explicitly encodes
dimensional structure and operations in its syntax, naturally exposing how
tensors should be packed and transformed. We decompose einsum expressions into
a fixed set of FHE-friendly operations. We implement our design and present
EinHops, a minimalist system that factors einsum expressions into a fixed
sequence of FHE operations. EinHops enables developers to perform encrypted
tensor operations using FHE while maintaining full visibility into the
underlying packing strategy. We evaluate EinHops on a range of tensor
operations from a simple transpose to complex multi-dimensional contractions.
We show that the explicit nature of einsum notation allows us to build an FHE
tensor system that is simple, general, and interpretable. We open-source
EinHops at the following repository: https://github.com/baahl-nyu/einhops.

</details>


### [54] [Defending Against Prompt Injection With a Few DefensiveTokens](https://arxiv.org/abs/2507.07974)
*Sizhe Chen,Yizhu Wang,Nicholas Carlini,Chawin Sitawarin,David Wagner*

Main category: cs.CR

TL;DR: 本文提出DefensiveToken方法，通过在LLM输入前插入特殊优化的防御令牌，实现测试时灵活切换安全模式，兼顾高效防护与模型效用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)系统与外部数据交互时易受提示注入攻击，现有测试时防御措施效果远逊于训练时防御，亟需兼具灵活性与安全性的解决方案。

Method: 设计可动态插入的特殊防御令牌(DefensiveToken)，其嵌入向量经安全优化。开发者根据安全需求决定是否在输入前添加该令牌，无需修改模型参数。

Result: 防御令牌在保持近乎最高效用(utility)的同时，提供接近训练时防御的安全水平，代码已开源(GitHub)。

Conclusion: DefensiveToken首次实现测试时防御与训练时防御可比的安全性，通过模型发布时预置该令牌，使开发者能按需灵活平衡安全与效用。

Abstract: When large language model (LLM) systems interact with external data to
perform complex tasks, a new attack, namely prompt injection, becomes a
significant threat. By injecting instructions into the data accessed by the
system, the attacker is able to override the initial user task with an
arbitrary task directed by the attacker. To secure the system, test-time
defenses, e.g., defensive prompting, have been proposed for system developers
to attain security only when needed in a flexible manner. However, they are
much less effective than training-time defenses that change the model
parameters. Motivated by this, we propose DefensiveToken, a test-time defense
with prompt injection robustness comparable to training-time alternatives.
DefensiveTokens are newly inserted as special tokens, whose embeddings are
optimized for security. In security-sensitive cases, system developers can
append a few DefensiveTokens before the LLM input to achieve security with a
minimal utility drop. In scenarios where security is less of a concern,
developers can simply skip DefensiveTokens; the LLM system remains the same as
there is no defense, generating high-quality responses. Thus, DefensiveTokens,
if released alongside the model, allow a flexible switch between the
state-of-the-art (SOTA) utility and almost-SOTA security at test time. The code
is available at https://github.com/Sizhe-Chen/DefensiveToken.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [55] [Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation](https://arxiv.org/abs/2507.07115)
*Javal Vyas,Mehmet Mercangoz*

Main category: cs.AI

TL;DR: 本文提出了一种结合大型语言模型(LLM)的智能代理框架，统一处理化工过程中的离散故障恢复规划与连续过程控制，通过有限状态机(FSM)实现可解释操作，并在案例研究中验证了其优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现代化工过程日益复杂，面临人力短缺和故障场景多样化挑战，需要融合符号推理与自适应控制的新型自动化范式。

Method: 采用有限状态机(FSM)作为可解释操作框架：LLM规划代理生成恢复序列，仿真代理执行状态转移验证，并通过验证-重提示循环迭代优化无效方案。案例研究1测试不同规模FSM的路径规划能力，案例2在TCLab平台上实现温度控制。

Result: GPT-4系列在180个随机FSM中实现100%有效路径成功率(5次重提示内)，显著优于开源模型；在温度控制任务中达到与传统PID相当的性能，且提示循环对处理非线性动态至关重要。

Conclusion: 研究表明：通过结构化反馈与模块化代理设计，LLM能统一高层符号规划与底层连续控制，为化工领域语言驱动自动化提供了新路径。关键失败模式包括指令跟随偏差和粗糙ODE近似问题。

Abstract: The increasing complexity of modern chemical processes, coupled with
workforce shortages and intricate fault scenarios, demands novel automation
paradigms that blend symbolic reasoning with adaptive control. In this work, we
introduce a unified agentic framework that leverages large language models
(LLMs) for both discrete fault-recovery planning and continuous process control
within a single architecture. We adopt Finite State Machines (FSMs) as
interpretable operating envelopes: an LLM-driven planning agent proposes
recovery sequences through the FSM, a Simulation Agent executes and checks each
transition, and a Validator-Reprompting loop iteratively refines invalid plans.
In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25
states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path
success within five reprompts-outperforming open-source LLMs in both accuracy
and latency. In Case Study 2, the same framework modulates dual-heater inputs
on a laboratory TCLab platform (and its digital twin) to maintain a target
average temperature under persistent asymmetric disturbances. Compared to
classical PID control, our LLM-based controller attains similar performance,
while ablation of the prompting loop reveals its critical role in handling
nonlinear dynamics. We analyze key failure modes-such as instruction following
lapses and coarse ODE approximations. Our results demonstrate that, with
structured feedback and modular agents, LLMs can unify high-level symbolic
planningand low-level continuous control, paving the way towards resilient,
language-driven automation in chemical engineering.

</details>


### [56] [Working with AI: Measuring the Occupational Implications of Generative AI](https://arxiv.org/abs/2507.07935)
*Kiran Tomlinson,Sonia Jaffe,Will Wang,Scott Counts,Siddharth Suri*

Main category: cs.AI

TL;DR: 研究分析了20万条用户与微软Bing Copilot的匿名对话数据，发现AI最常用于信息搜集与写作辅助，知识型职业（如计算机、行政支持、销售等）的AI适用性评分最高，并探讨了工资、教育水平与AI适用性的相关性。


<details>
  <summary>Details</summary>
Motivation: 鉴于生成式AI的快速普及及其对广泛任务的影响，理解AI对经济的影响成为社会最重要的问题之一。本研究旨在通过分析人们使用AI完成的工作活动及其效果，评估AI对各职业的适用性。

Method: 研究分析了20万条经过匿名和隐私处理的用户与微软Bing Copilot的对话数据，结合职业活动分类、任务成功率和影响范围，计算了各职业的AI适用性评分。

Result: 最常见的AI辅助活动为信息搜集与写作，AI自身主要执行提供信息、写作、教学和咨询。计算机与数学、行政支持及销售等知识型职业的AI适用性评分最高。工资和教育水平与AI适用性呈正相关。

Conclusion: 研究表明生成式AI对知识型职业影响最大，实际使用情况与职业AI影响预测存在差异，为理解AI的经济影响提供了实证基础。

Abstract: Given the rapid adoption of generative AI and its potential to impact a wide
range of tasks, understanding the effects of AI on the economy is one of
society's most important questions. In this work, we take a step toward that
goal by analyzing the work activities people do with AI, how successfully and
broadly those activities are done, and combine that with data on what
occupations do those activities. We analyze a dataset of 200k anonymized and
privacy-scrubbed conversations between users and Microsoft Bing Copilot, a
publicly available generative AI system. We find the most common work
activities people seek AI assistance for involve gathering information and
writing, while the most common activities that AI itself is performing are
providing information and assistance, writing, teaching, and advising.
Combining these activity classifications with measurements of task success and
scope of impact, we compute an AI applicability score for each occupation. We
find the highest AI applicability scores for knowledge work occupation groups
such as computer and mathematical, and office and administrative support, as
well as occupations such as sales whose work activities involve providing and
communicating information. Additionally, we characterize the types of work
activities performed most successfully, how wage and education correlate with
AI applicability, and how real-world usage compares to predictions of
occupational AI impact.

</details>


### [57] [BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks](https://arxiv.org/abs/2507.07134)
*Mridula Vijendran,Shuang Chen,Jingjing Deng,Hubert P. H. Shum*

Main category: cs.AI

TL;DR: 本文提出了一种名为BOOST的新方法，通过动态调整温度缩放和采样概率来减少AI绘画分类中的偏见，特别是在处理分布外数据时。该方法在KaoKore和PACS数据集上验证了其有效性，并引入新的评估指标SODC来衡量类别分离和偏见减少。


<details>
  <summary>Details</summary>
Motivation: AI绘画分类中的偏见问题日益严重，尤其是在艺术策展和修复等任务中。偏见主要源于数据集不平衡，导致模型对罕见风格绘画的分类准确性下降。现有研究虽提升了分类性能，但忽视了处理分布外数据时的偏见问题。

Method: 提出BOOST方法（Bias-Oriented OOD Sampling and Tuning），通过动态调整温度缩放和采样概率，促进所有类别的公平表示。该方法还引入了新指标SODC（Same-Dataset OOD Detection Score）来评估类别分离和偏见减少效果。

Result: 在KaoKore和PACS数据集上的实验表明，BOOST能够平衡高性能与公平性，有效减少类别偏见，提升模型在艺术领域的鲁棒性。

Conclusion: BOOST方法为AI绘画分类中的偏见问题提供了有效的解决方案，通过动态调整和新的评估指标，实现了性能与公平性的平衡，适用于艺术领域的模型去偏见化。

Abstract: The pervasive issue of bias in AI presents a significant challenge to
painting classification, and is getting more serious as these systems become
increasingly integrated into tasks like art curation and restoration. Biases,
often arising from imbalanced datasets where certain artistic styles dominate,
compromise the fairness and accuracy of model predictions, i.e., classifiers
are less accurate on rarely seen paintings. While prior research has made
strides in improving classification performance, it has largely overlooked the
critical need to address these underlying biases, that is, when dealing with
out-of-distribution (OOD) data. Our insight highlights the necessity of a more
robust approach to bias mitigation in AI models for art classification on
biased training data. We propose a novel OOD-informed model bias adaptive
sampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It
addresses these challenges by dynamically adjusting temperature scaling and
sampling probabilities, thereby promoting a more equitable representation of
all classes. We evaluate our proposed approach to the KaoKore and PACS
datasets, focusing on the model's ability to reduce class-wise bias. We further
propose a new metric, Same-Dataset OOD Detection Score (SODC), designed to
assess class-wise separation and per-class bias reduction. Our method
demonstrates the ability to balance high performance with fairness, making it a
robust solution for unbiasing AI models in the art domain.

</details>


### [58] [State-Inference-Based Prompting for Natural Language Trading with Game NPCs](https://arxiv.org/abs/2507.07203)
*Minkyung Kim,Junsik Kim,Hwidong Bae,Woongcheol Yang,Sangdon Park,Sohee Bae*

Main category: cs.AI

TL;DR: 论文提出状态推断提示法(SIBP)，通过自主对话状态推断和情境化规则遵守，解决大语言模型在规则化交易系统中的可靠性问题，实现97%状态合规率和99.7%计算精度。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在游戏交易系统中存在规则违反问题（如物品幻觉和计算错误），导致玩家信任危机，需要开发可靠交易交互框架。

Method: 采用状态推断提示法(SIBP)，将交易分解为六个状态构建统一提示框架，实现情境感知物品引用和占位符价格计算。

Result: 在100组交易对话测试中，达到>97%状态合规率、>95%引用准确率和99.7%计算精度，计算效率优于基线方法。

Conclusion: SIBP为商业游戏中可信NPC交互提供了实用基础框架，在保持计算效率的同时显著提升规则遵守能力。

Abstract: Large Language Models enable dynamic game interactions but struggle with
rule-governed trading systems. Current implementations suffer from rule
violations, such as item hallucinations and calculation errors, that erode
player trust. Here, State-Inference-Based Prompting (SIBP) enables reliable
trading through autonomous dialogue state inference and context-specific rule
adherence. The approach decomposes trading into six states within a unified
prompt framework, implementing context-aware item referencing and
placeholder-based price calculations. Evaluation across 100 trading dialogues
demonstrates >97% state compliance, >95% referencing accuracy, and 99.7%
calculation precision. SIBP maintains computational efficiency while
outperforming baseline approaches, establishing a practical foundation for
trustworthy NPC interactions in commercial games.

</details>


### [59] [Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains](https://arxiv.org/abs/2507.07217)
*Zili Wang,Frank Montabon,Kristin Yvonne Rozier*

Main category: cs.AI

TL;DR: 供应链网络是复杂系统，涉及非法活动时分析更为困难。本文探索神经符号方法，利用大语言模型（LLM）通过问题树方法识别和量化新闻文章的相关性，以检测供应链中的非法活动。


<details>
  <summary>Details</summary>
Motivation: 供应链中的非法活动（如假冒零件、强迫劳动）数据稀疏且常被故意篡改，传统机器学习方法需要大量训练数据，难以应对此类问题。需要开发无需大量数据即可自动检测非法活动模式的方法。

Method: 采用神经符号方法，比较人工和自动特征提取的效果，提出基于大语言模型（LLM）的问题树方法，系统评估新闻文章与强迫劳动的相关性。

Result: 通过问题树方法，能够系统评估新闻文章与供应链中强迫劳动的相关性，并比较人工与机器分类的差异。

Conclusion: 神经符号方法结合大语言模型的问题树方法，为稀疏且不可靠数据下的供应链非法活动检测提供了有效途径，尤其在强迫劳动等领域的新闻文章分类中表现出潜力。

Abstract: Supply chain networks are complex systems that are challenging to analyze;
this problem is exacerbated when there are illicit activities involved in the
supply chain, such as counterfeit parts, forced labor, or human trafficking.
While machine learning (ML) can find patterns in complex systems like supply
chains, traditional ML techniques require large training data sets. However,
illicit supply chains are characterized by very sparse data, and the data that
is available is often (purposely) corrupted or unreliable in order to hide the
nature of the activities. We need to be able to automatically detect new
patterns that correlate with such illegal activity over complex, even temporal
data, without requiring large training data sets. We explore neurosymbolic
methods for identifying instances of illicit activity in supply chains and
compare the effectiveness of manual and automated feature extraction from news
articles accurately describing illicit activities uncovered by authorities. We
propose a question tree approach for querying a large language model (LLM) to
identify and quantify the relevance of articles. This enables a systematic
evaluation of the differences between human and machine classification of news
articles related to forced labor in supply chains.

</details>


### [60] [Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery](https://arxiv.org/abs/2507.07257)
*Licong Xu,Milind Sarkar,Anto I. Lonappan,Íñigo Zubeldia,Pablo Villanueva-Domingo,Santiago Casas,Christian Fidler,Chetana Amancharla,Ujjwal Tiwari,Adrian Bayer,Chadi Ait Ekiou,Miles Cranmer,Adrian Dimitrov,James Fergusson,Kahaan Gandhi,Sven Krippendorf,Andrew Laverick,Julien Lesgourgues,Antony Lewis,Thomas Meier,Blake Sherwin,Kristen Surrao,Francisco Villaescusa-Navarro,Chi Wang,Xueqing Xu,Boris Bolliet*

Main category: cs.AI

TL;DR: 提出多智能体系统cmbagent，通过约30个LLM智能体实现科研任务自动化，采用规划与控制策略协调工作流，成功应用于宇宙学参数测量任务，性能优于现有LLM。


<details>
  <summary>Details</summary>
Motivation: 旨在开发无需人工干预、能自主完成复杂科研任务的多智能体系统，提升科研自动化水平。

Method: 系统由30个专业LLM智能体组成，采用规划与控制策略协调工作流，支持代码本地执行，涵盖文献检索、代码编写、结果解释等任务。

Result: 在宇宙学参数测量任务中表现优异，性能超越前沿LLM模型，系统代码已开源并部署于HuggingFace平台。

Conclusion: cmbagent证明了多智能体系统在科研自动化中的潜力，为复杂任务协作提供了可行方案。

Abstract: We present a multi-agent system for automation of scientific research tasks,
cmbagent. The system is formed by about 30 Large Language Model (LLM) agents
and implements a Planning & Control strategy to orchestrate the agentic
workflow, with no human-in-the-loop at any point. Each agent specializes in a
different task (performing retrieval on scientific papers and codebases,
writing code, interpreting results, critiquing the output of other agents) and
the system is able to execute code locally. We successfully apply cmbagent to
carry out a PhD level cosmology task (the measurement of cosmological
parameters using supernova data) and evaluate its performance on two benchmark
sets, finding superior performance over state-of-the-art LLMs. The source code
is available on GitHub, demonstration videos are also available, and the system
is deployed on HuggingFace and will be available on the cloud.

</details>


### [61] [Application of LLMs to Multi-Robot Path Planning and Task Allocation](https://arxiv.org/abs/2507.07302)
*Ashish Kumar*

Main category: cs.AI

TL;DR: 本文研究利用大型语言模型作为专家规划器，以提升多智能体强化学习中的探索效率。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中的探索效率问题因算法复杂性而加剧，需要有效方法来改善任务解决能力。

Method: 采用大型语言模型作为专家规划器，指导多智能体在基于规划的任务中进行高效探索。

Result: 研究表明，大型语言模型能够有效提升多智能体在复杂环境中的探索效率。

Conclusion: 利用大型语言模型作为专家规划器，是多智能体强化学习中提升探索效率的一种可行方法。

Abstract: Efficient exploration is a well known problem in deep reinforcement learning
and this problem is exacerbated in multi-agent reinforcement learning due the
intrinsic complexities of such algorithms. There are several approaches to
efficiently explore an environment to learn to solve tasks by multi-agent
operating in that environment, of which, the idea of expert exploration is
investigated in this work. More specifically, this work investigates the
application of large-language models as expert planners for efficient
exploration in planning based tasks for multiple agents.

</details>


### [62] [ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning](https://arxiv.org/abs/2507.07306)
*Yichen Lu,Wei Dai,Jiaen Liu,Ching Wing Kwok,Zongheng Wu,Xudong Xiao,Ao Sun,Sheng Fu,Jianyuan Zhan,Yian Wang,Takatomo Saito,Sicheng Lai*

Main category: cs.AI

TL;DR: 本文介绍了ViDove，一个基于LLM的多模态翻译代理系统，通过整合视觉和上下文背景信息提升翻译质量，在字幕生成和通用翻译任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的翻译代理通常仅支持文本输入，无法利用多模态信息。ViDove旨在模拟人类翻译工作流程，通过视觉和上下文信息提升翻译准确性和适应性。

Method: ViDove结合多模态记忆系统和长短时记忆模块，融入领域知识，设计了支持视频字幕翻译的新基准DoveBench（含17小时人工标注数据）。

Result: 实验显示ViDove在BLEU分数上提升28%，SubER指标提升15%，显著优于现有最佳基线模型。

Conclusion: ViDove证明了多模态信息对翻译任务的价值，其开源代码和DoveBench基准为后续研究提供了重要资源。

Abstract: LLM-based translation agents have achieved highly human-like translation
results and are capable of handling longer and more complex contexts with
greater efficiency. However, they are typically limited to text-only inputs. In
this paper, we introduce ViDove, a translation agent system designed for
multimodal input. Inspired by the workflow of human translators, ViDove
leverages visual and contextual background information to enhance the
translation process. Additionally, we integrate a multimodal memory system and
long-short term memory modules enriched with domain-specific knowledge,
enabling the agent to perform more accurately and adaptively in real-world
scenarios. As a result, ViDove achieves significantly higher translation
quality in both subtitle generation and general translation tasks, with a 28%
improvement in BLEU scores and a 15% improvement in SubER compared to previous
state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark
for long-form automatic video subtitling and translation, featuring 17 hours of
high-quality, human-annotated data. Our code is available here:
https://github.com/pigeonai-org/ViDove

</details>


### [63] [On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment](https://arxiv.org/abs/2507.07341)
*Sarah Ball,Greg Gluch,Shafi Goldwasser,Frauke Kreuter,Omer Reingold,Guy N. Rothblum*

Main category: cs.AI

TL;DR: 本文研究大型语言模型(LLM)的安全对齐问题，揭示输入提示过滤和输出过滤在计算效率上的根本性局限，证明外部过滤机制无法确保模型安全，主张模型智能与判断力不可分割。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的广泛应用，其可能被滥用于生成有害内容的风险日益凸显。本研究旨在探讨模型安全对齐的核心挑战，特别是外部过滤机制的有效性问题。

Method: 通过理论分析证明：1)存在无法被高效过滤器识别的对抗性提示构造方法；2)在特定条件下输出过滤具有计算不可行性。所有结论均基于密码学硬度假设。

Result: 核心发现：1)对某些LLM不存在高效的提示过滤器；2)输出过滤在自然场景下具有计算复杂性障碍。补充研究表明放松条件的缓解方法同样存在计算壁垒。

Conclusion: 研究表明仅通过外部过滤机制(如黑箱访问)无法实现LLM安全，必须将判断力深度整合到模型内部架构中，模型的智能与道德判断本质上是不可分割的。

Abstract: With the increased deployment of large language models (LLMs), one concern is
their potential misuse for generating harmful content. Our work studies the
alignment challenge, with a focus on filters to prevent the generation of
unsafe information. Two natural points of intervention are the filtering of the
input prompt before it reaches the model, and filtering the output after
generation. Our main results demonstrate computational challenges in filtering
both prompts and outputs. First, we show that there exist LLMs for which there
are no efficient prompt filters: adversarial prompts that elicit harmful
behavior can be easily constructed, which are computationally indistinguishable
from benign prompts for any efficient filter. Our second main result identifies
a natural setting in which output filtering is computationally intractable. All
of our separation results are under cryptographic hardness assumptions. In
addition to these core findings, we also formalize and study relaxed mitigation
approaches, demonstrating further computational barriers. We conclude that
safety cannot be achieved by designing filters external to the LLM internals
(architecture and weights); in particular, black-box access to the LLM will not
suffice. Based on our technical results, we argue that an aligned AI system's
intelligence cannot be separated from its judgment.

</details>


### [64] [Supply Chain Optimization via Generative Simulation and Iterative Decision Policies](https://arxiv.org/abs/2507.07355)
*Haoyue Bai,Haoyu Wang,Nanxu Gong,Xinyuan Wang,Wangyang Ying,Haifeng Chen,Yanjie Fu*

Main category: cs.AI

TL;DR: 提出Sim-to-Dec框架，结合生成模拟与双感知决策模型，显著提升供应链运输的时效性与利润。


<details>
  <summary>Details</summary>
Motivation: 供应链运输需兼顾高响应性与经济效益，而运输模式战略决策直接影响这两项目标。现有方法缺乏通用性、动态细节捕捉及历史与预测的融合。

Method: Sim-to-Dec框架包含：1) 基于自回归建模的生成式模拟模块，减少手工规则依赖；2) 历史-未来双感知决策模型，通过端到端优化迭代精修。

Result: 在三个真实数据集上的实验表明，该框架显著提高了准时交付率与利润。

Conclusion: Sim-to-Dec通过紧密耦合模拟反馈与策略优化，为运输战略设计提供了通用、动态且数据驱动的解决方案。

Abstract: High responsiveness and economic efficiency are critical objectives in supply
chain transportation, both of which are influenced by strategic decisions on
shipping mode. An integrated framework combining an efficient simulator with an
intelligent decision-making algorithm can provide an observable, low-risk
environment for transportation strategy design. An ideal simulation-decision
framework must (1) generalize effectively across various settings, (2) reflect
fine-grained transportation dynamics, (3) integrate historical experience with
predictive insights, and (4) maintain tight integration between simulation
feedback and policy refinement. We propose Sim-to-Dec framework to satisfy
these requirements. Specifically, Sim-to-Dec consists of a generative
simulation module, which leverages autoregressive modeling to simulate
continuous state changes, reducing dependence on handcrafted domain-specific
rules and enhancing robustness against data fluctuations; and a history-future
dual-aware decision model, refined iteratively through end-to-end optimization
with simulator interactions. Extensive experiments conducted on three
real-world datasets demonstrate that Sim-to-Dec significantly improves timely
delivery rates and profit.

</details>


### [65] [DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search](https://arxiv.org/abs/2507.07426)
*Zerui Yang,Yuwei Wan,Yinqiao Li,Yudai Matsuda,Tong Xie,Linqi Song*

Main category: cs.AI

TL;DR: 提出DrugMCTS框架，结合RAG、多智能体协作与蒙特卡洛树搜索，无需微调即显著提升大语言模型在药物重定向任务中的性能，在DrugBank和KIBA数据集上表现优于通用LLMs及深度学习基线。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在科学领域（如药物发现）的推理能力受限于预训练知识，传统方法（微调或检索增强生成）存在计算开销高或未能充分利用结构化科学数据的问题。

Method: 提出DrugMCTS框架，整合检索增强生成（RAG）、多智能体协作（5个专项代理负责分子与蛋白质信息检索分析）和蒙特卡洛树搜索，支持结构化迭代推理，无需领域微调。

Result: DrugMCTS使Qwen2.5-7B-Instruct模型性能超越Deepseek-R1达20\%以上，在DrugBank和KIBA数据集上召回率与鲁棒性显著优于通用LLMs及深度学习基线。

Conclusion: 结构化推理、智能体协作及反馈驱动搜索机制对推进大语言模型在药物发现中的应用至关重要，DrugMCTS框架为此提供了有效解决方案。

Abstract: Recent advances in large language models have demonstrated considerable
potential in scientific domains such as drug discovery. However, their
effectiveness remains constrained when reasoning extends beyond the knowledge
acquired during pretraining. Conventional approaches, such as fine-tuning or
retrieval-augmented generation, face limitations in either imposing high
computational overhead or failing to fully exploit structured scientific data.
To overcome these challenges, we propose DrugMCTS, a novel framework that
synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree
Search for drug repurposing. The framework employs five specialized agents
tasked with retrieving and analyzing molecular and protein information, thereby
enabling structured and iterative reasoning. Without requiring domain-specific
fine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by
over 20\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate
that DrugMCTS achieves substantially higher recall and robustness compared to
both general-purpose LLMs and deep learning baselines. Our results highlight
the importance of structured reasoning, agent-based collaboration, and
feedback-driven search mechanisms in advancing LLM applications for drug
discovery.

</details>


### [66] [StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley](https://arxiv.org/abs/2507.07445)
*Weihao Tan,Changjiu Jiang,Yu Duan,Mingcong Lei,Jiageng Li,Yitian Hong,Xinrun Wang,Bo An*

Main category: cs.AI

TL;DR: 研究者提出了基于《星露谷物语》的StarDojo基准测试，用于评估AI代理在开放式生产生活模拟中的综合能力，涵盖耕作、制作、探索、战斗和社交五大领域。现有最先进的MLLM代理表现不佳，最佳模型GPT-4.1成功率仅12.7%。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试鲜少同时评估AI代理的生产活动与社交互动能力，而这两种能力对人类社会中的自主代理至关重要。

Method: 基于《星露谷物语》游戏构建StarDojo基准，包含1,000项跨五大领域的任务及100项核心子集，提供统一接口支持多实例并行运行，适配多模态大语言模型评估。

Result: 顶尖MLLM代理表现存在显著局限：最佳模型GPT-4.1成功率仅12.7%，主要受限于视觉理解、多模态推理和底层操作能力。

Conclusion: StarDojo作为用户友好的测试环境，将推动复杂生产生活场景中开放式AI代理的鲁棒性研究，揭示了当前MLLM在跨模态任务执行上的重大挑战。

Abstract: Autonomous agents navigating human society must master both production
activities and social interactions, yet existing benchmarks rarely evaluate
these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel
benchmark based on Stardew Valley, designed to assess AI agents in open-ended
production-living simulations. In StarDojo, agents are tasked to perform
essential livelihood activities such as farming and crafting, while
simultaneously engaging in social interactions to establish relationships
within a vibrant community. StarDojo features 1,000 meticulously curated tasks
across five key domains: farming, crafting, exploration, combat, and social
interactions. Additionally, we provide a compact subset of 100 representative
tasks for efficient model evaluation. The benchmark offers a unified,
user-friendly interface that eliminates the need for keyboard and mouse
control, supports all major operating systems, and enables the parallel
execution of multiple environment instances, making it particularly well-suited
for evaluating the most capable foundation agents, powered by multimodal large
language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents
demonstrate substantial limitations, with the best-performing model, GPT-4.1,
achieving only a 12.7% success rate, primarily due to challenges in visual
understanding, multimodal reasoning and low-level manipulation. As a
user-friendly environment and benchmark, StarDojo aims to facilitate further
research towards robust, open-ended agents in complex production-living
environments.

</details>


### [67] [Position: We Need An Algorithmic Understanding of Generative AI](https://arxiv.org/abs/2507.07544)
*Oliver Eberle,Thomas McGee,Hamza Giaffar,Taylor Webb,Ida Momennejad*

Main category: cs.AI

TL;DR: 本文提出AlgEval框架，旨在系统研究大语言模型(LLM)学习与使用的算法，通过案例研究揭示其内部计算机制，为可解释性和高效训练提供新途径。


<details>
  <summary>Details</summary>
Motivation: 当前研究过度关注通过规模提升性能，缺乏对LLM实际学习算法的理论理解，亟需建立系统性评估框架来揭示其内部计算原理。

Method: 提出AlgEval框架，结合自上而下的算法假设与自下而上的电路分析(注意力模式与隐藏状态)，以涌现的搜索算法为案例进行研究。

Result: 案例研究展示了如何通过注意力模式和隐藏状态的电路级分析，验证LLM内部算法假设，为算法可解释性提供实证基础。

Conclusion: 系统评估LLM的任务解决机制可替代资源密集型扩展，推动对底层计算的理论理解，并为样本高效训练和多智能体系统架构设计提供新思路。

Abstract: What algorithms do LLMs actually learn and use to solve problems? Studies
addressing this question are sparse, as research priorities are focused on
improving performance through scale, leaving a theoretical and empirical gap in
understanding emergent algorithms. This position paper proposes AlgEval: a
framework for systematic research into the algorithms that LLMs learn and use.
AlgEval aims to uncover algorithmic primitives, reflected in latent
representations, attention, and inference-time compute, and their algorithmic
composition to solve task-specific problems. We highlight potential
methodological paths and a case study toward this goal, focusing on emergent
search algorithms. Our case study illustrates both the formation of top-down
hypotheses about candidate algorithms, and bottom-up tests of these hypotheses
via circuit-level analysis of attention patterns and hidden states. The
rigorous, systematic evaluation of how LLMs actually solve tasks provides an
alternative to resource-intensive scaling, reorienting the field toward a
principled understanding of underlying computations. Such algorithmic
explanations offer a pathway to human-understandable interpretability, enabling
comprehension of the model's internal reasoning performance measures. This can
in turn lead to more sample-efficient methods for training and improving
performance, as well as novel architectures for end-to-end and multi-agent
systems.

</details>


### [68] [On Trustworthy Rule-Based Models and Explanations](https://arxiv.org/abs/2507.07576)
*Mohamed Siala,Jordi Planes,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本文探讨了机器学习中基于规则的模型解释性问题，指出这些模型存在负面重叠和冗余等缺陷，并开发了分析算法，发现常用学习工具会导致规则集出现负面特征。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域，机器学习模型的解释准确性至关重要，错误的解释会误导人类决策者。尽管可解释性难以界定，基于规则的可解释模型仍被广泛使用。本文旨在分析这些模型的潜在缺陷。

Method: 研究开发了算法来分析基于规则模型中的负面特征，如负面重叠和多种冗余形式，并评估了常用学习工具生成的规则集。

Result: 研究发现，广泛使用的基于规则模型学习工具会导致规则集出现一种或多种负面特征，影响模型的解释可靠性。

Conclusion: 基于规则的机器学习模型在高风险应用中存在解释缺陷，需要改进学习工具以避免负面特征，提升模型的可信度和解释质量。

Abstract: A task of interest in machine learning (ML) is that of ascribing explanations
to the predictions made by ML models. Furthermore, in domains deemed high risk,
the rigor of explanations is paramount. Indeed, incorrect explanations can and
will mislead human decision makers. As a result, and even if interpretability
is acknowledged as an elusive concept, so-called interpretable models are
employed ubiquitously in high-risk uses of ML and data mining (DM). This is the
case for rule-based ML models, which encompass decision trees, diagrams, sets
and lists. This paper relates explanations with well-known undesired facets of
rule-based ML models, which include negative overlap and several forms of
redundancy. The paper develops algorithms for the analysis of these undesired
facets of rule-based systems, and concludes that well-known and widely used
tools for learning rule-based ML models will induce rule sets that exhibit one
or more negative facets.

</details>


### [69] [Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs](https://arxiv.org/abs/2507.07595)
*Zhixiang Su,Di Wang,Chunyan Miao*

Main category: cs.AI

TL;DR: 本文提出了一种名为Context Pooling的新方法，用于提升基于图神经网络（GNN）的知识图谱（KG）链接预测模型性能。该方法首次在KG中应用图池化技术，并能在归纳设置中生成查询特定图。实验表明，该方法在多个数据集上达到了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于GNN的KG链接预测模型中，普通聚合操作对性能提升有限。本文旨在通过引入Context Pooling方法，解决这一问题并提升模型在归纳设置中的表现。

Method: 提出Context Pooling方法，首次在KG中应用图池化技术。设计了邻居精度和邻居召回两个指标，用于评估邻居的逻辑相关性，从而筛选出与查询逻辑相关的邻居进行链接预测。该方法可应用于多种SOTA模型。

Result: 在三个公开的转导和归纳数据集上，将Context Pooling应用于两个SOTA模型，在48种设置中的42种达到了最先进性能。

Conclusion: Context Pooling是一种通用且有效的方法，能够显著提升GNN模型在KG链接预测任务中的性能，特别是在归纳设置中表现突出。

Abstract: Recent investigations on the effectiveness of Graph Neural Network
(GNN)-based models for link prediction in Knowledge Graphs (KGs) show that
vanilla aggregation does not significantly impact the model performance. In
this paper, we introduce a novel method, named Context Pooling, to enhance
GNN-based models' efficacy for link predictions in KGs. To our best of
knowledge, Context Pooling is the first methodology that applies graph pooling
in KGs. Additionally, Context Pooling is first-of-its-kind to enable the
generation of query-specific graphs for inductive settings, where testing
entities are unseen during training. Specifically, we devise two metrics,
namely neighborhood precision and neighborhood recall, to assess the neighbors'
logical relevance regarding the given queries, thereby enabling the subsequent
comprehensive identification of only the logically relevant neighbors for link
prediction. Our method is generic and assessed by being applied to two
state-of-the-art (SOTA) models on three public transductive and inductive
datasets, achieving SOTA performance in 42 out of 48 settings.

</details>


### [70] [Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.07599)
*Sedigh Khademi,Jim Black,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila*

Main category: cs.AI

TL;DR: 本研究评估了微调的Llama 3.2模型从急诊分诊记录中提取疫苗相关信息的能力，以支持近实时疫苗安全监测。微调的30亿参数Llama 3模型在疫苗名称提取准确率上优于其他方法，模型量化使其能在资源受限环境中高效部署。


<details>
  <summary>Details</summary>
Motivation: 开发自动化工具从急诊记录中提取疫苗数据，以提升疫苗安全监测效率，实现免疫接种后不良事件的早期检测。

Method: 采用提示工程初步创建标注数据集，经人工审核确认后，比较提示工程模型、微调模型与基于规则的方法。对Llama 3模型进行微调与量化处理。

Result: 微调后的30亿参数Llama 3模型在疫苗名称提取任务中表现最优，模型量化后仍保持高效运行性能。

Conclusion: 大语言模型可有效自动化处理急诊记录数据，为疫苗安全监测及不良事件早期预警提供技术支持，量化部署方案解决了资源限制问题。

Abstract: This study evaluates fine-tuned Llama 3.2 models for extracting
vaccine-related information from emergency department triage notes to support
near real-time vaccine safety surveillance. Prompt engineering was used to
initially create a labeled dataset, which was then confirmed by human
annotators. The performance of prompt-engineered models, fine-tuned models, and
a rule-based approach was compared. The fine-tuned Llama 3 billion parameter
model outperformed other models in its accuracy of extracting vaccine names.
Model quantization enabled efficient deployment in resource-constrained
environments. Findings demonstrate the potential of large language models in
automating data extraction from emergency department notes, supporting
efficient vaccine safety surveillance and early detection of emerging adverse
events following immunization issues.

</details>


### [71] [Towards conservative inference in credal networks using belief functions: the case of credal chains](https://arxiv.org/abs/2507.07619)
*Marco Sangalli,Thomas Krak,Cassio de Campos*

Main category: cs.AI

TL;DR: 本文提出了一种基于Dempster-Shafer理论的信用网络信念推理新框架，专注于链式结构，通过信念和似然函数高效计算保守区间，并对比了信念推理与传统敏感性分析的差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于改进信用网络中的不确定性传播方法，特别是在链式结构中，结合计算效率与鲁棒的不确定性表示，以提升信念推理的实用性。

Method: 方法包括构建基于Dempster-Shafer理论的框架，针对链式信用网络设计信念和似然函数传播算法，并形式化信念推理方法，与传统敏感性分析进行对比。

Result: 数值结果表明，该方法在链式结构中能高效计算保守区间，同时揭示了信念推理在此框架下的优势与局限性，为信用网络的通用应用提供了参考。

Conclusion: 结论指出，该框架为链式信用网络的信念推理提供了有效工具，但其适用范围和局限性仍需进一步研究，以拓展至更复杂的网络结构。

Abstract: This paper explores belief inference in credal networks using Dempster-Shafer
theory. By building on previous work, we propose a novel framework for
propagating uncertainty through a subclass of credal networks, namely chains.
The proposed approach efficiently yields conservative intervals through belief
and plausibility functions, combining computational speed with robust
uncertainty representation. Key contributions include formalizing belief-based
inference methods and comparing belief-based inference against classical
sensitivity analysis. Numerical results highlight the advantages and
limitations of applying belief inference within this framework, providing
insights into its practical utility for chains and for credal networks in
general.

</details>


### [72] [PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations](https://arxiv.org/abs/2507.07644)
*Fedor Rodionov,Abdelrahman Eldesokey,Michael Birsak,John Femiani,Bernard Ghanem,Peter Wonka*

Main category: cs.AI

TL;DR: PlanQA是一个用于评估大语言模型(LLM)几何与空间推理能力的诊断基准，基于结构化室内场景表示设计，揭示当前LLM在真实空间布局推理中的明显缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在几何和空间推理方面存在不足，特别是在处理真实世界布局时缺乏一致性。PlanQA旨在填补这一空白，推动开发能准确推断和操作空间属性的语言模型。

Method: 通过结构化符号格式(如JSON/XML)编码厨房/客厅/卧室等室内场景，设计多样化问题类型测试度量推理(距离/视线/最短路径)和设计约束(功能/间距/平衡/可用性)。

Result: 测试表明前沿开源和商业LLM能处理浅层查询，但在模拟物理约束、保持空间连贯性及布局扰动泛化方面普遍失败，暴露出真实空间推理的盲区。

Conclusion: PlanQA揭示了当前LLM在空间几何推理上的根本局限，该基准有望激发新研究，开发能精准处理实际场景空间属性的语言模型。

Abstract: We introduce PlanQA, a diagnostic benchmark for evaluating geometric and
spatial reasoning in large-language models (LLMs). PlanQA is grounded in
structured representations of indoor scenes, such as kitchens, living rooms,
and bedrooms, encoded in a symbolic format (e.g., JSON, XML layouts). The
benchmark includes diverse question types that test not only metric and
topological reasoning (e.g., distance, visibility, shortest paths) but also
interior design constraints such as affordance, clearance, balance, and
usability. Our results across a variety of frontier open-source and commercial
LLMs show that while models may succeed in shallow queries, they often fail to
simulate physical constraints, preserve spatial coherence, or generalize under
layout perturbation. PlanQA uncovers a clear blind spot in today's LLMs: they
do not consistently reason about real-world layouts. We hope that this
benchmark inspires new work on language models that can accurately infer and
manipulate spatial and geometric properties in practical settings.

</details>


### [73] [Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization](https://arxiv.org/abs/2507.07723)
*Chengtao Jian,Kai Yang,Ye Ouyang,Xiaozhou Ye*

Main category: cs.AI

TL;DR: 本文分析了直接偏好优化(DPO)的理论缺陷，提出了一种双层优化框架——稳定偏好优化，通过引入正则化方案改善概率分配，实验证明其在推理和摘要任务中优于标准DPO。


<details>
  <summary>Details</summary>
Motivation: 尽管DPO在语言模型对齐中表现出色，但其理论特性和内在局限性尚未充分探索。研究发现DPO对初始化敏感且容易错误分配概率质量，可能无意中强化模型偏见，影响对齐稳定性与偏好一致性。

Method: 提出基于双层优化的稳定偏好优化框架，将监督微调与改进的DPO目标紧密结合，通过原则性正则化方案显式提升偏好输出的绝对概率，同时保持优化动态稳定性。

Result: 在推理和摘要基准测试中，该方法持续提升推理准确率，使输出分布更符合预期偏好，性能超越标准DPO。

Conclusion: 稳定偏好优化为偏好对齐目标设计提供了新思路，开辟了实现更可靠、可解释语言模型对齐的新途径。

Abstract: Direct Preference Optimization (DPO) has emerged as a popular and efficient
alternative to reward modeling and reinforcement learning for aligning language
models with human preferences. Despite its empirical success, the theoretical
properties and intrinsic limitations of DPO remain underexplored. In this work,
we first present a comprehensive analysis of DPO's dynamics from a probability
evolution perspective. Our analysis reveals that DPO is highly sensitive to
initialization. It also tends to misallocate probability mass, which can
inadvertently shift probability toward irrelevant or undesired responses. This
misallocation may unintentionally reinforce model bias, thereby compromising
both the stability of model alignment and the consistency with intended
preferences. Motivated by these theoretical findings, we propose a
theoretically grounded bilevel optimization framework that tightly integrate
supervised fine-tuning with an enhanced DPO objective a.k.a. stable preference
optimization. Our approach introduces a principled regularization scheme to
explicitly encourage absolute probability improvement for preferred outputs,
while maintaining stable optimization dynamics. Experiments on challenging
reasoning and summarization benchmarks elucidate that our method consistently
improves reasoning accuracy and better aligns output distributions with
intended preferences, outperforming standard DPO. Stable preference
optimization provides new insights into the design of preference-based
alignment objectives and opens up new avenues towards more reliable and
interpretable language model alignment.

</details>


### [74] [Identification of Violin Reduction via Contour Lines Classification](https://arxiv.org/abs/2507.07743)
*Philémon Beghin,Anne-Emmanuelle Ceulemans,François Glineur*

Main category: cs.AI

TL;DR: 本文提出一种基于轮廓线的小提琴尺寸缩减分类方法，通过分析25把乐器的3D几何网格数据，发现抛物线拟合参数能有效区分缩减与非缩减乐器，其中开口参数β最具预测性。


<details>
  <summary>Details</summary>
Motivation: 16世纪晚期出现的小提琴在200年间发展出多样形态，1750年后为统一标准，制琴师会对尺寸不达标乐器进行缩减处理。这种处理会改变轮廓线形态（U型变V型），但此前缺乏定量研究。

Method: 采集25把小提琴的3D光栅扫描数据，每把提取10-20条等距轮廓线，用$y=\alpha|x|^{\beta}$方程拟合抛物线特征参数，通过回归分析和阈值统计构建数值化轮廓特征，最终应用分类模型评估。

Result: 几何特征可在一定程度上预测尺寸缩减（准确率未明确说明），其中抛物线开口参数β最具判别力。但存在连续过渡形态的乐器，其缩减程度较难量化。

Conclusion: 通过轮廓线几何分析可实现小提琴缩减分类，证实历史尺寸标准化对乐器形态产生系统性影响。该方法为乐器考古提供了新的量化研究工具。

Abstract: The first violins appeared in late 16th-century Italy. Over the next 200
years, they spread across Europe and luthiers of various royal courts, eager to
experiment with new techniques, created a highly diverse family of instruments.
Around 1750, size standards were introduced to unify violin making for
orchestras and conservatories. Instruments that fell between two standards were
then reduced to a smaller size by luthiers. These reductions have an impact on
several characteristics of violins, in particular on the contour lines, i.e.
lines of constant altitude, which look more like a U for non reduced
instruments and a V for reduced ones. While such differences are observed by
experts, they have not been studied quantitatively.
  This paper presents a method for classifying violins as reduced or
non-reduced based on their contour lines. We study a corpus of 25 instruments
whose 3D geometric meshes were acquired via photogrammetry. For each
instrument, we extract 10-20 contour lines regularly spaced every millimetre.
Each line is fitted with a parabola-like curve (with an equation of the type y
= alpha*abs(x)**beta) depending on two parameters, describing how open (beta)
and how vertically stretched (alpha) the curve is. We compute additional
features from those parameters, using regressions and counting how many values
fall under some threshold. We also deal with outliers and non equal numbers of
levels, and eventually obtain a numerical profile for each instrument.
  We then apply classification methods to assess whether geometry alone can
predict size reduction. We find that distinguishing between reduced and non
reduced instruments is feasible to some degree, taking into account that a
whole spectrum of more or less transformed violins exists, for which it is more
difficult to quantify the reduction. We also find the opening parameter beta to
be the most predictive.

</details>


### [75] [Measuring AI Alignment with Human Flourishing](https://arxiv.org/abs/2507.07787)
*Elizabeth Hilliard,Akshaya Jagadeesh,Alex Cook,Steele Billings,Nicholas Skytland,Alicia Llewellyn,Jackson Paull,Nathan Paull,Nolan Kurylo,Keatra Nesbitt,Robert Gruenewald,Anthony Jantzi,Omar Chavez*

Main category: cs.AI

TL;DR: 本文提出'繁荣AI基准'(FAI Benchmark)，通过七个维度评估AI对人类全面繁荣的贡献度，测试28个主流语言模型后发现，尽管部分模型表现较好(最高72/100)，但无模型在所有维度(尤其是信仰与灵性、品格与美德、意义与目的)达到理想对齐。


<details>
  <summary>Details</summary>
Motivation: 传统AI评估仅关注技术能力或危害预防，缺乏对AI促进人类全面繁荣的衡量。FAI基准旨在填补这一空白，推动AI从'避免伤害'转向'主动支持人类繁荣'的发展范式。

Method: 采用七维度评估框架(品格美德、亲密关系、幸福满意度等)，结合1229个主客观问题，使用专业评审LLM进行跨维度几何平均评分，确保各维度平衡评估。

Result: 28个主流模型中，最高分72分(满分100)，所有模型均在信仰灵性(维度7)、品格美德(维度1)和意义目的(维度4)表现欠佳，揭示当前AI与人类全面繁荣存在显著对齐缺口。

Conclusion: FAI基准为开发支持人类繁荣的AI系统提供新范式，其跨维度评估方法对AI伦理发展具有深远意义，特别指出当前模型在精神性和价值观维度需重点改进。

Abstract: This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel
evaluation framework that assesses AI alignment with human flourishing across
seven dimensions: Character and Virtue, Close Social Relationships, Happiness
and Life Satisfaction, Meaning and Purpose, Mental and Physical Health,
Financial and Material Stability, and Faith and Spirituality. Unlike
traditional benchmarks that focus on technical capabilities or harm prevention,
the FAI Benchmark measures AI performance on how effectively models contribute
to the flourishing of a person across these dimensions. The benchmark evaluates
how effectively LLM AI systems align with current research models of holistic
human well-being through a comprehensive methodology that incorporates 1,229
objective and subjective questions. Using specialized judge Large Language
Models (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs
geometric mean scoring to ensure balanced performance across all flourishing
dimensions. Initial testing of 28 leading language models reveals that while
some models approach holistic alignment (with the highest-scoring models
achieving 72/100), none are acceptably aligned across all dimensions,
particularly in Faith and Spirituality, Character and Virtue, and Meaning and
Purpose. This research establishes a framework for developing AI systems that
actively support human flourishing rather than merely avoiding harm, offering
significant implications for AI development, ethics, and evaluation.

</details>


### [76] [MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving](https://arxiv.org/abs/2507.07818)
*Lu Xu,Jiaqian Yu,Xiongfeng Peng,Yiwei Chen,Weiming Li,Jaewook Yoo,Sunghyun Chunag,Dongwook Lee,Daehyun Ji,Chao Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种面向驾驶技能的混合专家模型MoSE，通过模拟人类驾驶员的学习和推理过程，实现了高效且高性能的自动驾驶系统。


<details>
  <summary>Details</summary>
Motivation: 现有混合专家模型（MoE）需要大量训练数据和复杂优化，而人类驾驶员通过逐步学习技能实现高效驾驶。本文旨在设计一种类似人类学习过程的技能导向模型。

Method: 提出技能导向路由机制，通过定义和标注特定驾驶技能构建分层技能数据集，并预训练路由器以实现逐步推理。模型在单次前向过程中整合辅助任务（如描述、推理、规划），不增加计算成本。

Result: 模型仅激活不到30亿参数，在CODA AD极端案例推理任务上超越多个80亿+参数模型，相比现有方法减少至少62.5%的激活参数量，达到最先进性能。

Conclusion: MoSE通过技能分层和逐步推理机制，以更小的计算成本实现了优于大型模型的性能，为高效自动驾驶系统提供了新思路。

Abstract: Recent studies show large language models (LLMs) and vision language models
(VLMs) trained using web-scale data can empower end-to-end autonomous driving
systems for a better generalization and interpretation. Specifically, by
dynamically routing inputs to specialized subsets of parameters, the
Mixture-of-Experts (MoE) technique enables general LLMs or VLMs to achieve
substantial performance improvements while maintaining computational
efficiency. However, general MoE models usually demands extensive training data
and complex optimization. In this work, inspired by the learning process of
human drivers, we propose a skill-oriented MoE, called MoSE, which mimics human
drivers' learning process and reasoning process, skill-by-skill and
step-by-step. We propose a skill-oriented routing mechanism that begins with
defining and annotating specific skills, enabling experts to identify the
necessary driving competencies for various scenarios and reasoning tasks,
thereby facilitating skill-by-skill learning. Further align the driving process
to multi-step planning in human reasoning and end-to-end driving models, we
build a hierarchical skill dataset and pretrain the router to encourage the
model to think step-by-step. Unlike multi-round dialogs, MoSE integrates
valuable auxiliary tasks (e.g.\ description, reasoning, planning) in one single
forward process without introducing any extra computational cost. With less
than 3B sparsely activated parameters, our model outperforms several 8B+
parameters on CODA AD corner case reasoning task. Compared to existing methods
based on open-source models and data, our approach achieves state-of-the-art
performance with significantly reduced activated model size (at least by
$62.5\%$) with a single-turn conversation.

</details>


### [77] [AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift](https://arxiv.org/abs/2507.07820)
*Eunsu Baek,Keondo Park,Jeonggil Ko,Min-hwan Oh,Taesik Gong,Hyung-Sin Kim*

Main category: cs.AI

TL;DR: 本文提出自适应感知作为AI可持续发展的新范式，通过动态调节传感器参数提升小模型性能，减少资源消耗，并探讨了技术整合与伦理挑战。


<details>
  <summary>Details</summary>
Motivation: 当前AI依赖大规模模型和数据集，导致环境、经济和伦理成本高昂。受生物感官系统启发，作者主张通过自适应感知实现可持续、普惠的AI发展。

Method: 在输入层动态调制传感器参数（如曝光度、灵敏度、多模态配置），以缓解协变量偏移并提升效率。提出整合路线图及实时算法、隐私保护等研究方向。

Result: 实验表明自适应感知能使小模型（如EfficientNet-B0）超越计算资源消耗更大的模型（如OpenCLIP-H），验证了其高效性。

Conclusion: 通过标准化基准、多模态集成等技术攻关，自适应感知有望推动AI系统向可持续、鲁棒且公平的方向转型。

Abstract: Current AI advances largely rely on scaling neural models and expanding
training datasets to achieve generalization and robustness. Despite notable
successes, this paradigm incurs significant environmental, economic, and
ethical costs, limiting sustainability and equitable access. Inspired by
biological sensory systems, where adaptation occurs dynamically at the input
(e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive
sensing as a necessary and foundational shift. Adaptive sensing proactively
modulates sensor parameters (e.g., exposure, sensitivity, multimodal
configurations) at the input level, significantly mitigating covariate shifts
and improving efficiency. Empirical evidence from recent studies demonstrates
that adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass
substantially larger models (e.g., OpenCLIP-H) trained with significantly more
data and compute. We (i) outline a roadmap for broadly integrating adaptive
sensing into real-world applications spanning humanoid, healthcare, autonomous
systems, agriculture, and environmental monitoring, (ii) critically assess
technical and ethical integration challenges, and (iii) propose targeted
research directions, such as standardized benchmarks, real-time adaptive
algorithms, multimodal integration, and privacy-preserving methods.
Collectively, these efforts aim to transition the AI community toward
sustainable, robust, and equitable artificial intelligence systems.

</details>


### [78] [Searching for actual causes: Approximate algorithms with adjustable precision](https://arxiv.org/abs/2507.07857)
*Samuel Reyd,Ada Diaconescu,Jean-Louis Dessalles*

Main category: cs.AI

TL;DR: 本文提出了一种多项式复杂度的算法，用于识别实际原因，适用于非布尔、黑盒和随机系统，并能通过调整计算时间提高精确性和全面性。


<details>
  <summary>Details</summary>
Motivation: 当前可解释人工智能（XAI）和因果关系的文献主要关注理解哪些因素导致哪些结果，但这并非非专家用户期望的解释。用户更关注导致目标结果的实际原因，而这一问题尚未形式化且计算复杂度高。

Method: 作者提出了一组算法，具有多项式复杂度和可调整的精确性与全面性，能够识别非布尔、黑盒和随机系统中的实际原因。

Result: 实验表明，这些算法能够处理现有方法无法处理的系统类别，且通过增加计算时间可以提高精确性和全面性。

Conclusion: 该研究为识别实际原因提供了一种实用且高效的解决方案，填补了现有方法的不足，并具有广泛的应用潜力。

Abstract: Causality has gained popularity in recent years. It has helped improve the
performance, reliability, and interpretability of machine learning models.
However, recent literature on explainable artificial intelligence (XAI) has
faced criticism. The classical XAI and causality literature focuses on
understanding which factors contribute to which consequences. While such
knowledge is valuable for researchers and engineers, it is not what non-expert
users expect as explanations. Instead, these users often await facts that cause
the target consequences, i.e., actual causes. Formalizing this notion is still
an open problem. Additionally, identifying actual causes is reportedly an
NP-complete problem, and there are too few practical solutions to approximate
formal definitions. We propose a set of algorithms to identify actual causes
with a polynomial complexity and an adjustable level of precision and
exhaustiveness. Our experiments indicate that the algorithms (1) identify
causes for different categories of systems that are not handled by existing
approaches (i.e., non-boolean, black-box, and stochastic systems), (2) can be
adjusted to gain more precision and exhaustiveness with more computation time.

</details>


### [79] [An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis](https://arxiv.org/abs/2507.07893)
*Mingda Zhang,Na Zhao,Jianglong Qing,Qing xu,Kaiwen Pan,Ting luo*

Main category: cs.AI

TL;DR: 本文提出了一种结合提示工程与多维知识图谱的增强框架，以解决大语言模型在法律纠纷分析中的局限性，显著提升了法律决策分析的性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为智能法律系统的核心组件，在法律纠纷分析中存在法律知识表示不足、概念理解有限和推理缺陷等问题，亟需改进。

Method: 框架采用三阶段分层提示结构（任务定义、知识背景、推理引导），结合法律专用推理模板和动态优化机制；构建三层知识图谱架构（分类本体、表示层、实例层），并集成四种法律概念检索方法与网络搜索技术。

Result: 实验表明该框架显著提升法律纠纷分析性能，能精准处理复杂案件的法律适用分析，并展现对司法决策逻辑的细致理解。

Conclusion: 该研究为智能法律辅助系统的实现提供了创新技术路径，通过知识增强框架有效弥补了大语言模型在法律领域的不足。

Abstract: The rapid development of artificial intelligence has positioned large
language models as fundamental components of intelligent legal systems.
However, these models face significant limitations in legal dispute analysis,
including insufficient legal knowledge representation, limited concept
understanding, and reasoning deficiencies. This research proposes an enhanced
framework integrating prompt engineering with multidimensional knowledge
graphs. The framework introduces a three-stage hierarchical prompt structure
comprising task definition, knowledge background, and reasoning guidance,
supplemented by legal-specific reasoning templates and dynamic optimization
mechanisms. A three-layer knowledge graph architecture is constructed with
legal classification ontology, representation, and instance layers. Four
complementary methods enable precise legal concept retrieval: direct legal norm
code matching, domain-specific semantic vector similarity, ontology-based path
reasoning, and specialized lexical segmentation. These components integrate
with web search technology to establish a knowledge-enhanced framework for
legal decision-making. Experimental results demonstrate significant performance
improvements in legal dispute analysis, enabling accurate legal application
analysis for complex cases while exhibiting nuanced understanding of judicial
decision-making logic, providing a novel technical approach for implementing
intelligent legal assistance systems.

</details>


### [80] [Meek Models Shall Inherit the Earth](https://arxiv.org/abs/2507.07931)
*Hans Gundlach,Jayson Lynch,Neil Thompson*

Main category: cs.AI

TL;DR: 论文提出，随着计算规模扩大带来的边际效益递减，资源有限的AI模型（"弱小模型"）将逐渐接近顶级模型的性能水平，导致AI能力趋同。这一趋势将重塑AI战略与政策。


<details>
  <summary>Details</summary>
Motivation: 针对少数公司垄断AI模型性能导致的资源不平等现象，研究挑战了"计算规模越大性能越强"的固有认知，探讨弱小模型能否通过效益递减规律实现能力追赶。

Method: 构建理论模型证明固定分布的下一个token预测任务中，计算资源的边际能力回报急剧下降；结合训练损失差异的代理指标分析，并通过基准数据和历史模型能力差异进行实证检验。

Result: 数据表明：1) 计算规模扩大的能力增益呈现显著递减趋势；2) 即使计算资源指数级增长，最终能力优势也将微乎其微；3) 弱小模型确实在持续逼近顶级模型性能。

Conclusion: 弱小模型的能力趋同现象将颠覆现有AI竞争格局，需重新评估模型部署、资源分配和政策制定，特别是在算力垄断、安全治理和普惠AI等关键领域。

Abstract: The past decade has seen incredible scaling of AI systems by a few companies,
leading to inequality in AI model performance. This paper argues that, contrary
to prevailing intuition, the diminishing returns to compute scaling will lead
to a convergence of AI model capabilities. In other words, meek models (those
with limited computation budget) shall inherit the earth, approaching the
performance level of the best models overall. We develop a model illustrating
that under a fixed-distribution next-token objective, the marginal capability
returns to raw compute shrink substantially. Given current scaling practices,
we argue that these diminishing returns are strong enough that even companies
that can scale their models exponentially faster than other organizations will
eventually have little advantage in capabilities. As part of our argument, we
give several reasons that proxies like training loss differences capture
important capability measures using evidence from benchmark data and
theoretical performance models. In addition, we analyze empirical data on the
capability difference of AI models over time. Finally, in light of the
increasing ability of meek models, we argue that AI strategy and policy require
reexamination, and we outline the areas this shift will affect.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [81] [The Richness of CSP Non-redundancy](https://arxiv.org/abs/2507.07942)
*Joshua Brakensiek,Venkatesan Guruswami,Bart M. P. Jansen,Victor Lagerkvist,Magnus Wahlström*

Main category: cs.DM

TL;DR: 本文研究了约束满足问题(CSP)中的非冗余性(NRD)概念，证明了对于每个有理数$r \ge 1$存在对应的有限CSP谓词$P$使其非冗余性为$\Theta(n^r)$，并建立了条件非冗余性的代数理论。


<details>
  <summary>Details</summary>
Motivation: 非冗余性作为连接计算机科学和数学多个重要问题的枢纽，包括稀疏化、核化、查询复杂度、泛代数和极值组合等，需要更深入的理解。

Method: 首先证明了非冗余性与变量数$n$的多项式关系，其次通过极值组合学中的高围长图结构完全分类了二元谓词的条件非冗余性，最后发展了条件非冗余性的代数理论。

Result: 1) 对任意有理数$r \ge 1$构造了非冗余性为$\Theta(n^r)$的CSP谓词；2) 完全分类了二元谓词的条件非冗余性；3) 提出了基于量子泡利群的Mal\'tsev嵌入新实例。

Conclusion: 非冗余性研究建立了CSP理论与多个数学领域的深刻联系，特别是通过代数方法拓展了Mal\'tsev嵌入的应用范围，为未来研究提供了新的理论工具。

Abstract: In the field of constraint satisfaction problems (CSP), a clause is called
redundant if its satisfaction is implied by satisfying all other clauses. An
instance of CSP$(P)$ is called non-redundant if it does not contain any
redundant clause. The non-redundancy (NRD) of a predicate $P$ is the maximum
number of clauses in a non-redundant instance of CSP$(P)$, as a function of the
number of variables $n$. Recent progress has shown that non-redundancy is
crucially linked to many other important questions in computer science and
mathematics including sparsification, kernelization, query complexity,
universal algebra, and extremal combinatorics. Given that non-redundancy is a
nexus for many of these important problems, the central goal of this paper is
to more deeply understand non-redundancy.
  Our first main result shows that for every rational number $r \ge 1$, there
exists a finite CSP predicate $P$ such that the non-redundancy of $P$ is
$\Theta(n^r)$. Our second main result explores the concept of conditional
non-redundancy first coined by Brakensiek and Guruswami [STOC 2025]. We
completely classify the conditional non-redundancy of all binary predicates
(i.e., constraints on two variables) by connecting these non-redundancy
problems to the structure of high-girth graphs in extremal combinatorics.
  Inspired by these concrete results, we build off the work of Carbonnel [CP
2022] to develop an algebraic theory of conditional non-redundancy. As an
application of this algebraic theory, we revisit the notion of Mal'tsev
embeddings, which is the most general technique known to date for establishing
that a predicate has linear non-redundancy. For example, we provide the first
example of predicate with a Mal'tsev embedding that cannot be attributed to the
structure of an Abelian group, but rather to the structure of the quantum Pauli
group.

</details>
