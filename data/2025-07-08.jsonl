{"id": "2507.02874", "categories": ["math.GM", "00A66, 11A07, 05C45, 68U05"], "pdf": "https://arxiv.org/pdf/2507.02874", "abs": "https://arxiv.org/abs/2507.02874", "authors": ["Suvra Kanti Chakraborty", "Atanu Manna"], "title": "Extending Hridaya Kolam to Even-Ordered Dot Patterns and Their Applications", "comment": "14 pages", "summary": "This study extends the mathematical framework of Hridaya Kolam patterns by\napplying modular arithmetic to even-ordered dot arrangements with arm counts\nco-prime to the number of dots. We analyze the resulting cyclic sequences that\ncorrespond to Eulerian circuits, enabling continuous single-stroke kolam\ndesigns beyond the classical odd-ordered cases. Our method provides explicit\nalgorithms for constructing these intricate patterns, unveiling new symmetries\nand structural properties. Elevating this traditional floor art, we translate\nthese mathematically grounded motifs into striking designs, showcasing their\nbeauty and complexity in contemporary dari art in the carpet and textile\nsectors."}
{"id": "2507.02881", "categories": ["math.GM", "47H10, 54H25"], "pdf": "https://arxiv.org/pdf/2507.02881", "abs": "https://arxiv.org/abs/2507.02881", "authors": ["Babu G. V. R.", "Alemayehu Negash", "Meaza Bogale"], "title": "Common Fixed Points of Cq-Commuting Maps via Generalized Gregus-Type Inequalities", "comment": "13 pages", "summary": "We establish the existence of common fixed points for $C_q$-commuting\nself-mappings satisfying a generalized Gregus-type inequality with quadratic\nterms in $q$-starshaped subsets of normed linear spaces. Our framework extends\nclassical fixed point theory through:\n  (i) Set-distance constraints $\\delta(\\cdot, [q, \\cdot])$ generalizing norm\nconditions\n  (ii) Compatibility via $C_q$-commutativity without full affinity requirements\n  (iii) Reciprocal continuity replacing full map continuity.\n  Explicit examples (e.g., Example 2.6) demonstrate the non-triviality of these\nextensions. As applications, we derive invariant approximation theorems for\nbest approximation sets. Our results generalize Nashine's work\n\\cite{Nashine2007} and unify several known fixed point theorems."}
{"id": "2507.02882", "categories": ["math.GM", "17A30, 15A75", "I.1; F.2; E.3"], "pdf": "https://arxiv.org/pdf/2507.02882", "abs": "https://arxiv.org/abs/2507.02882", "authors": ["Stanislav Semenov"], "title": "One-way multilinear functions of the second order with linear shifts", "comment": "13 pages", "summary": "We introduce and analyze a novel class of binary operations on\nfinite-dimensional vector spaces over a field K, defined by second-order\nmultilinear expressions with linear shifts. These operations generate\npolynomials whose degree increases linearly with each iterated application,\nwhile the number of distinct monomials grows combinatorially. We demonstrate\nthat, despite being non-associative and non-commutative in general, these\noperations exhibit power associativity and internal commutativity when iterated\non a single vector. This ensures that exponentiation a^n is well-defined and\nunambiguous.\n  Crucially, the absence of a closed-form expression for a^n suggests a one-way\nproperty: computing a^n from a and n is efficient, while recovering n from a^n\n(the Discrete Iteration Problem) appears computationally hard. We propose a\nDiffie-Hellman-like key exchange protocol based on this principle, introducing\nthe Algebraic Diffie-Hellman Problem (ADHP) as an underlying assumption of\nsecurity.\n  In addition to the algebraic foundations, we empirically investigate the\norbit structure of these operations over finite fields, observing frequent\nemergence of long cycles and highly regular behavior across parameter sets.\nMotivated by these dynamics, we further propose a pseudorandom number\ngeneration (PRNG) strategy based on multi-element multiplication patterns. This\napproach empirically achieves near-maximal cycle lengths and excellent\nstatistical uniformity, highlighting the potential of these operations for\ncryptographic and combinatorial applications."}
{"id": "2507.03053", "categories": ["math.CO", "37B52, 15B48, 11K16"], "pdf": "https://arxiv.org/pdf/2507.03053", "abs": "https://arxiv.org/abs/2507.03053", "authors": ["Josef F. Dorfmeister", "Sebastian Walcher"], "title": "Resnikoff silver numbers and tilings of the half-line (Dedicated to the memory of H.L.Resnikoff)", "comment": "32 pages", "summary": "Building on work by H.L.Resnikoff we consider (Resnikoff) silver numbers,\nwhich generalize the familiar golden number. By definition, a silver number is\nthe largest positive root of a certain polynomial called silver polynomial. In\nturn, a corresponding companion matrix of a silver polynomial gives rise to a\nwell known construction of inflationary tilings of the (non-negative) real\nhalf-line, via an iteration of inflation and substitution. Resnikoff noted for\nthe golden number $\\phi$ that this tiling corresponds to the set of what he\ncalled $\\phi$-integers. We generalize this result for a special class of silver\nnumbers, the distinguished silver numbers, by showing that the integers for a\ndistinguished silver number give rise to a tiling, of which we provide a\nprecise description. For the general problem, whether the integers for an\narbitrary silver number give rise to a tiling, we cannot give a general answer,\nbut we show that tilings are obtained if and only if the differences of silver\nintegers satisfy a (rather weak looking) non-accumulation condition. If tilings\nof this type exist for certain (necessarily non-distinguished) silver numbers,\nthey would seem to form a class of inflationary tilings that differs from those\nobtained by inflation and substitution. In an Appendix we recall necessary\nnotions and -- mostly known -- results, including the inflation-substitution\nconstruction principle for (one dimensional) inflationary tilings, in an\nelementary manner. For the readers' convenience we also collect the pertinent\nfacts about non-negative matrices, thus the construction is accessible with\nonly basic prerequisites from linear algebra and analysis. Finally, in our\nsetting we give a detailed proof of a non-periodicity result that goes back to\nPenrose."}
{"id": "2507.02886", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2507.02886", "abs": "https://arxiv.org/abs/2507.02886", "authors": ["Thi Kim Nhung Dang", "Benedikt Peterseim", "Milan Lopuhaä-Zwakenberg", "Mariëlle Stoelinga"], "title": "Fuzzy Fault Trees: the Fast and the Formal", "comment": "Accepted for the proceedings of the International Conference on the\n  Quantitative Evaluation of Systems (QEST); this preprint contains an appendix\n  with proofs", "summary": "We provide a rigorous framework for handling uncertainty in quantitative\nfault tree analysis based on fuzzy theory. We show that any algorithm for fault\ntree unreliability analysis can be adapted to this framework in a fully general\nand computationally efficient manner. This result crucially leverages both the\nalpha-cut representation of fuzzy numbers and the coherence property of fault\ntrees. We evaluate our algorithms on an established benchmark of synthetic\nfault trees, demonstrating their practical effectiveness."}
{"id": "2507.03104", "categories": ["math.CO", "math.SP", "05C50, 05C76"], "pdf": "https://arxiv.org/pdf/2507.03104", "abs": "https://arxiv.org/abs/2507.03104", "authors": ["G. Kalaivani", "R. Rajkumar"], "title": "New matrices for the spectral theory of mixed graphs, Part II", "comment": "33 pages", "summary": "The concept of the integrated adjacency matrix for mixed graphs was first\nintroduced in [9], where its spectral properties were analyzed in relation to\nthe structural characteristics of the mixed graph. Building upon this\nfoundation, this paper introduces the integrated Laplacian matrix, the\nintegrated signless Laplacian matrix, and the normalized integrated Laplacian\nmatrix for mixed graphs. We further explore how the spectra of these matrices\nrelate to the structural properties of the mixed graph."}
{"id": "2507.03195", "categories": ["math.LO", "math.DS"], "pdf": "https://arxiv.org/pdf/2507.03195", "abs": "https://arxiv.org/abs/2507.03195", "authors": ["Isaac Goldbring", "Brandon Seward", "Robin Tucker-Drob"], "title": "Existentially closed measure-preserving actions of approximately treeable groups", "comment": "82 pages; first draft; comments welcome!", "summary": "Given a countable group $\\Gamma$, letting $\\mathcal{K}_\\Gamma$ denote the\nclass of {\\pmp} actions of $\\Gamma$, we study the question of when the model\ncompanion of $\\mathcal{K}_\\Gamma$ exists. Berenstein, Henson, and Ibarluc\\'ia\nshowed that the model companion of $\\mathcal{K}_\\Gamma$ exists when $\\Gamma$ is\na nonabelian free group on a countable number of generators. We significantly\ngeneralize their result by showing that the model companion of $\\cal K_\\Gamma$\nexists whenever $\\Gamma$ is an approximately treeable group. The class of\napproximately treeable groups contain the class of treeable groups as well as\nthe class of universally free groups, that is, the class of groups with the\nsame universal theory as nonabelian free groups. We prove this result using an\nopen mapping characterization of when the model companion exists; moreover,\nthis open mapping characterization provides concrete, ergodic-theoretic axioms\nfor the model companion when it exists. We show how to simplify these axioms in\nthe case of treeable groups, providing an alternate axiomatization for the\nmodel companion in the case of the free group, which was first axiomatized by\nBerenstein, Henson, and Ibarluc\\'ia using techniques from model-theoretic\nstability theory. Along the way, we prove a purely ergodic-theoretic result of\nindependent interest, namely that finitely generated universally free groups\n(also known as limit groups) have Kechris' property MD. We also show that for\ngroups with Kechris' EMD property, the profinite completion action is\nexistentially closed, and for groups without property (T), the generic\nexistentially closed action is weakly mixing, generalizing results of\nBerenstein, Henson, and Ibarluc\\'ia for the case of nonabelian free groups."}
{"id": "2507.02885", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.02885", "abs": "https://arxiv.org/abs/2507.02885", "authors": ["Runbo Li"], "title": "On the exceptional set in the $abc$ conjecture", "comment": "15 pages", "summary": "The $abc$ conjecture states that there are only finitely many triples of\ncoprime positive integers $(a,b,c)$ such that $a+b=c$ and\n$\\operatorname{rad}(abc) < c^{1-\\epsilon}$ for any $\\epsilon > 0$. Using the\noptimized methods in a recent work of Browning, Lichtman and Ter\\\"av\\\"ainen, we\nshowed that the number of those triples with $c \\leqslant X$ is\n$O\\left(X^{56/85+\\varepsilon}\\right)$ for any $\\varepsilon > 0$, where\n$\\frac{56}{85} \\approx 0.658824$. This constitutes an improvement of the\nprevious bound $O\\left(X^{33/50}\\right)$."}
{"id": "2507.03233", "categories": ["q-fin.GN"], "pdf": "https://arxiv.org/pdf/2507.03233", "abs": "https://arxiv.org/abs/2507.03233", "authors": ["Rem Sadykhov", "Geoff Goodell", "Philip Treleaven"], "title": "Economic Policy Taxonomy", "comment": "38 pages, 9 figures, 9 tables", "summary": "This paper proposes a framework for categorizing economic policies in a form\nof a tree taxonomy. The purpose of this approach is to construct an exhaustive\nand standardized list of actions that a governing authority has access to and\ncan change to control an economy. This is advantageous from two perspectives:\nby having an exhaustive list of tools, it becomes easier to construct\n\"complete\" models (i.e., models that take in all empirical data and aim to\nsimulate economic dynamics) of an economy and understand what the assumptions\nof these models are; and by knowing all available actions, economic strategies\ncan be devised that target specific economic performance metrics with an\nexhaustive list of policies."}
{"id": "2507.03470", "categories": ["q-fin.MF", "q-fin.PR", "91B25, 60G40, 60G44"], "pdf": "https://arxiv.org/pdf/2507.03470", "abs": "https://arxiv.org/abs/2507.03470", "authors": ["Pavel V. Gapeev", "Libo Li"], "title": "Perpetual American Standard and Lookback Options in Insider Models with Progressively Enlarged Filtrations", "comment": null, "summary": "We derive closed-form solutions to the optimal stopping problems related to\nthe pricing of perpetual American standard and lookback put and call options in\nthe extensions of the Black-Merton-Scholes model with progressively enlarged\nfiltrations. More specifically, the information available to the insider is\nmodelled by Brownian filtrations progressively enlarged with the times of\neither the global maximum or minimum of the underlying risky asset price over\nthe infinite time interval, which is not a stopping time in the filtration\ngenerated by the underlying risky asset. We show that the optimal exercise\ntimes are the first times at which the asset price process reaches either lower\nor upper stochastic boundaries depending on the current values of its running\nmaximum or minimum given the occurrence of times of either the global maximum\nor minimum, respectively. The proof is based on the reduction of the original\nproblems into the necessarily three-dimensional optimal stopping problems and\nthe equivalent free-boundary problems. We apply either the normal-reflection or\nthe normal-entrance conditions as well as the smooth-fit conditions for the\nvalue functions to characterise the candidate boundaries as either the maximal\nor minimal solutions to the associated first-order nonlinear ordinary\ndifferential equations and the transcendental arithmetic equations,\nrespectively."}
{"id": "2507.02873", "categories": ["math.HO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02873", "abs": "https://arxiv.org/abs/2507.02873", "authors": ["William D'Alessandro"], "title": "Using Large Language Models to Study Mathematical Practice", "comment": null, "summary": "The philosophy of mathematical practice (PMP) looks to evidence from working\nmathematics to help settle philosophical questions. One prominent program under\nthe PMP banner is the study of explanation in mathematics, which aims to\nunderstand what sorts of proofs mathematicians consider explanatory and what\nrole the pursuit of explanation plays in mathematical practice. In an effort to\naddress worries about cherry-picked examples and file-drawer problems in PMP, a\nhandful of authors have recently turned to corpus analysis methods as a\npromising alternative to small-scale case studies. This paper reports the\nresults from such a corpus study facilitated by Google's Gemini 2.5 Pro, a\nmodel whose reasoning capabilities, advances in hallucination control and large\ncontext window allow for the accurate analysis of hundreds of pages of text per\nquery. Based on a sample of 5000 mathematics papers from arXiv.org, the\nexperiments yielded a dataset of hundreds of useful annotated examples. Its aim\nwas to gain insight on questions like the following: How often do\nmathematicians make claims about explanation in the relevant sense? Do\nmathematicians' explanatory practices vary in any noticeable way by subject\nmatter? Which philosophical theories of explanation are most consistent with a\nlarge body of non-cherry-picked examples? How might philosophers make further\nuse of AI tools to gain insights from large datasets of this kind? As the first\nPMP study making extensive use of LLM methods, it also seeks to begin a\nconversation about these methods as research tools in practice-oriented\nphilosophy and to evaluate the strengths and weaknesses of current models for\nsuch work."}
{"id": "2507.03288", "categories": ["math.ST", "stat.TH", "46E22, 62E20, 62G08, 62R30"], "pdf": "https://arxiv.org/pdf/2507.03288", "abs": "https://arxiv.org/abs/2507.03288", "authors": ["Yuki Iida", "Hiroshi Shiraishi", "Hiroaki Ogata"], "title": "Local Fr'echet Regression via RKHS embedding and Its Applications to Data Analysis on Manifolds", "comment": null, "summary": "Local Fr'echet Regression (LFR) is a nonparametric regression method for\nsettings in which the explanatory variable lies in a Euclidean space and the\nresponse variable lies in a metric space. It is used to estimate smooth\ntrajectories in general metric spaces from noisy observations of random objects\ntaking values in such spaces. Since metric spaces form a broad class of spaces\nthat often lack algebraic structures such as addition or scalar multiplication\ncharacteristics typical of vector spaces the asymptotic theory for conventional\nrandom variables cannot be directly applied. As a result, deriving the\nasymptotic distribution of the LFR estimator is challenging. In this paper, we\nfirst extend nonparametric regression models for real-valued responses to\nHilbert spaces and derive the asymptotic distribution of the LFR estimator in a\nHilbert space setting. Furthermore, we propose a new estimator based on the LFR\nestimator in a reproducing kernel Hilbert space (RKHS), by mapping data from a\ngeneral metric space into an RKHS. Finally, we consider applications of the\nproposed method to data lying on manifolds and construct confidence regions in\nmetric spaces based on the derived asymptotic distribution."}
{"id": "2507.02951", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02951", "abs": "https://arxiv.org/abs/2507.02951", "authors": ["Elizabeth Lui", "Jiahao Sun"], "title": "Bittensor Protocol: The Bitcoin in Decentralized Artificial Intelligence? A Critical and Empirical Analysis", "comment": "MARBLE 2025", "summary": "This paper investigates whether Bittensor can be considered the Bitcoin of\ndecentralized Artificial Intelligence by directly comparing its tokenomics,\ndecentralization properties, consensus mechanism, and incentive structure\nagainst those of Bitcoin. Leveraging on-chain data from all 64 active Bittensor\nsubnets, we first document considerable concentration in both stake and\nrewards. We further show that rewards are overwhelmingly driven by stake,\nhighlighting a clear misalignment between quality and compensation. As a\nremedy, we put forward a series of two-pronged protocol-level interventions.\nFor incentive realignment, our proposed solutions include performance-weighted\nemission split, composite scoring, and a trust-bonus multiplier. As for\nmitigating security vulnerability due to stake concentration, we propose and\nempirically validate stake cap at the 88th percentile, which elevates the\nmedian coalition size required for a 51-percent attack and remains robust\nacross daily, weekly, and monthly snapshots."}
{"id": "2507.03980", "categories": ["cs.DM", "cs.DS"], "pdf": "https://arxiv.org/pdf/2507.03980", "abs": "https://arxiv.org/abs/2507.03980", "authors": ["Xi He", "Max. A. Little"], "title": "Combination generators with optimal cache utilization and communication free parallel execution", "comment": null, "summary": "We introduce an efficient and elegant combination generator for producing all\ncombinations of size less than or equal to K, designed for exhaustive\ngeneration and combinatorial optimization tasks. This generator can be\nimplemented to achieve what we define as optimal efficiency: constant amortized\ntime, optimal cache utilization, embarrassingly parallel execution, and a\nrecursive structure compatible with pruning-based search. These properties are\ndifficult to satisfy simultaneously in existing generators. For example,\nclassical Gray code or lexicographic generators are typically list-based and\nsequentially defined, making them difficult to vectorized, inefficient in cache\nusage, and inherently hard to parallelize. Generators based on unranking\nmethods, while easy to parallelize, are non-recursive. These limitations reduce\ntheir applicability in our target applications, where both computational\nefficiency and recursion are crucial. We adapt Bird's algebra of\nprogramming-style calculation to derive our algorithms, a formalism for\ndeveloping correct-by-construction programs from specifications. As a result,\nall generators in this paper are first formulated in their clearest\nspecification, and efficient definitions are derived constructively through\nequational reasoning, resulting in concise and elegant divide-and-conquer\ndefinitions. Beyond presenting a combination generator, we extend our approach\nto construct generators for K-permutations, nested combinations of\ncombinations, and nested permutation-combination structures. To the best of our\nknowledge, the literature has not previously reported generators for these\nnested structures. We also develop sequential variants that produce\nconfigurations in Gray code-compatible orders -- such as the revolving door\nordering -- which are particularly useful for constructing nested generators."}
{"id": "2507.02961", "categories": ["math.OC", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2507.02961", "abs": "https://arxiv.org/abs/2507.02961", "authors": ["Xuesong", "Zhou", "Taehooie Kim", "Mostafa Ameli", "Henan", "Zhu", "Yu- dai Honma", "Ram M. Pendyala"], "title": "Flow-Through Tensors: A Unified Computational Graph Architecture for Multi-Layer Transportation Network Optimization", "comment": null, "summary": "Modern transportation network modeling increasingly involves the integration\nof diverse methodologies including sensor-based forecasting, reinforcement\nlearning, classical flow optimization, and demand modeling that have\ntraditionally been developed in isolation. This paper introduces Flow Through\nTensors (FTT), a unified computational graph architecture that connects origin\ndestination flows, path probabilities, and link travel times as interconnected\ntensors. Our framework makes three key contributions: first, it establishes a\nconsistent mathematical structure that enables gradient-based optimization\nacross previously separate modeling elements; second, it supports\nmultidimensional analysis of traffic patterns over time, space, and user groups\nwith precise quantification of system efficiency; third, it implements tensor\ndecomposition techniques that maintain computational tractability for large\nscale applications. These innovations collectively enable real time control\nstrategies, efficient coordination between multiple transportation modes and\noperators, and rigorous enforcement of physical network constraints. The FTT\nframework bridges the gap between theoretical transportation models and\npractical deployment needs, providing a foundation for next generation\nintegrated mobility systems."}
{"id": "2507.02977", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.02977", "abs": "https://arxiv.org/abs/2507.02977", "authors": ["Igor Ivanov"], "title": "LLMs are Capable of Misaligned Behavior Under Explicit Prohibition and Surveillance", "comment": "10 pages, 2 figures", "summary": "In this paper, LLMs are tasked with completing an impossible quiz, while they\nare in a sandbox, monitored, told about these measures and instructed not to\ncheat. Some frontier LLMs cheat consistently and attempt to circumvent\nrestrictions despite everything. The results reveal a fundamental tension\nbetween goal-directed behavior and alignment in current LLMs. The code and\nevaluation logs are available at github.com/baceolus/cheating_evals"}
{"id": "2507.02889", "categories": ["math.GM", "44A10, 33B15, 33E12, 33C60"], "pdf": "https://arxiv.org/pdf/2507.02889", "abs": "https://arxiv.org/abs/2507.02889", "authors": ["Sergei Rogosin", "Filippo Giraldi", "Francesco Mainardi"], "title": "On the Laplace transforms of derivatives of special functions with respect to parameters", "comment": "23 pages", "summary": "This article is devoted to derivation of the Laplace transforms of the\nderivatives with respect to parameters of certain special functions, namely,\nthe Mittag-Leffler type, Wright and Le Roy type functions. These formulas show\ninterconnection of these functions and lead to better understanding of their\nbehaviour on the real line. These formulas are represented in the convoluted\nform and reconstructed in a more suitable form by using Efros theorem"}
{"id": "2507.03163", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.03163", "abs": "https://arxiv.org/abs/2507.03163", "authors": ["Vida Dujmović", "Pat Morin", "Sergey Norin", "David R. Wood"], "title": "3-Colouring Planar Graphs", "comment": null, "summary": "We show that every $n$-vertex planar graph is 3-colourable with monochromatic\ncomponents of size $O(n^{4/9})$. The best previous bound was $O(n^{1/2})$ due\nto Linial, Matou\\v{s}ek, Sheffet and Tardos [Combin. Probab. Comput., 2008]."}
{"id": "2507.03734", "categories": ["math.LO", "math.CO", "03E17, 03E05 (Primary) 03E35, 03E15 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.03734", "abs": "https://arxiv.org/abs/2507.03734", "authors": ["Rafał Filipów", "Adam Kwela"], "title": "Two $\\mathfrak{b}$ or not two $\\mathfrak{b}$?", "comment": null, "summary": "The paper is devoted to comparison of two generalizations of the bounding\nnumber $\\mathfrak{b}$."}
{"id": "2507.03058", "categories": ["math.NT", "11M41 (Primary) 30B40, 30B50 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.03058", "abs": "https://arxiv.org/abs/2507.03058", "authors": ["Lo Ho Tin"], "title": "On sums involving powers of harmonic numbers", "comment": "15 pages, 3 tables", "summary": "In this paper, we study a Dirichlet series generated by powers of harmonic\nnumbers. As an application of these functions, we derive certain series\ninvolving harmonic numbers. We also study the analytic properties of these\nDirichlet series such as values negative integers and behavior at poles. In\nparticular, objects similar to the Stieltjes constants are discussed.\nAsymptotics of the sums involving harmonic numbers are also studied. From these\nresults I showed a connection between its analytic properties and a possible\nroute to showing the irrationality of the Euler-Mascheroni constant."}
{"id": "2507.02878", "categories": ["math.HO", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2507.02878", "abs": "https://arxiv.org/abs/2507.02878", "authors": ["Oleg Zubelevich"], "title": "Integral Invariants and Hamiltonian Systems", "comment": "14 pages, in Russian", "summary": "In this methodological text we expound the Cartan and Poincare theory of\nintegral invariants. From this general viewpoint we discuss some basic aspects\nof Hamiltonian systems theory, of integrability, hydrodynamics, Riemann\ngeometry and optics."}
{"id": "2507.03356", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.03356", "abs": "https://arxiv.org/abs/2507.03356", "authors": ["Zeyan Zhuang", "Xin Zhang", "Dongfang Xu", "Shenghui Song"], "title": "No Eigenvalues Outside the Limiting Support of Generally Correlated and Noncentral Sample Covariance Matrices", "comment": null, "summary": "Spectral properties of random matrices play an important role in statistics,\nmachine learning, communications, and many other areas. Engaging results\nregarding the convergence of the empirical spectral distribution (ESD) and the\n``no-eigenvalue'' property have been obtained for random matrices with\ndifferent correlation structures. However, the related spectral analysis for\ngenerally correlated and noncentral random matrices is still incomplete, and\nthis paper aims to fill this research gap. Specifically, we consider matrices\nwhose columns are independent but with non-zero means and non-identical\ncorrelations. Under high-dimensional asymptotics where both the number of rows\nand columns grow simultaneously to infinity, we first establish the almost sure\nconvergence of the ESD for the concerned random matrices to a deterministic\nlimit, assuming mild conditions. Furthermore, we prove that with probability 1,\nno eigenvalues will appear in any closed interval outside the support of the\nlimiting distribution for matrices with sufficiently large dimensions. The\nabove results can be applied to different areas such as statistics, wireless\ncommunications, and signal processing. In this paper, we apply the derived\nresults to two communication scenarios: 1) We determine the limiting\nperformance of the signal-to-interference-plus-noise ratio for multi-user\nmultiple-input multiple-output (MIMO) systems with linear minimum mean-square\nerror receivers; and 2) We establish the invertibility of zero-forcing\nprecoding matrices in downlink MIMO systems, providing theoretical guarantees."}
{"id": "2507.02956", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02956", "abs": "https://arxiv.org/abs/2507.02956", "authors": ["Blake Bullwinkel", "Mark Russinovich", "Ahmed Salem", "Santiago Zanella-Beguelin", "Daniel Jones", "Giorgio Severi", "Eugenia Kim", "Keegan Hines", "Amanda Minnich", "Yonatan Zunger", "Ram Shankar Siva Kumar"], "title": "A Representation Engineering Perspective on the Effectiveness of Multi-Turn Jailbreaks", "comment": null, "summary": "Recent research has demonstrated that state-of-the-art LLMs and defenses\nremain susceptible to multi-turn jailbreak attacks. These attacks require only\nclosed-box model access and are often easy to perform manually, posing a\nsignificant threat to the safe and secure deployment of LLM-based systems. We\nstudy the effectiveness of the Crescendo multi-turn jailbreak at the level of\nintermediate model representations and find that safety-aligned LMs often\nrepresent Crescendo responses as more benign than harmful, especially as the\nnumber of conversation turns increases. Our analysis indicates that at each\nturn, Crescendo prompts tend to keep model outputs in a \"benign\" region of\nrepresentation space, effectively tricking the model into fulfilling harmful\nrequests. Further, our results help explain why single-turn jailbreak defenses\nlike circuit breakers are generally ineffective against multi-turn attacks,\nmotivating the development of mitigations that address this generalization gap."}
{"id": "2507.03163", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.03163", "abs": "https://arxiv.org/abs/2507.03163", "authors": ["Vida Dujmović", "Pat Morin", "Sergey Norin", "David R. Wood"], "title": "3-Colouring Planar Graphs", "comment": null, "summary": "We show that every $n$-vertex planar graph is 3-colourable with monochromatic\ncomponents of size $O(n^{4/9})$. The best previous bound was $O(n^{1/2})$ due\nto Linial, Matou\\v{s}ek, Sheffet and Tardos [Combin. Probab. Comput., 2008]."}
{"id": "2507.02992", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.02992", "abs": "https://arxiv.org/abs/2507.02992", "authors": ["J. Chico-Vázquez", "I. M. Griffiths"], "title": "A mathematical model for optimal breakaways in cycling: balancing energy expenditure and crash risk", "comment": "16 pages, 12 figures", "summary": "We present a mathematical model for optimizing breakaway strategies in\ncompetitive cycling, balancing power expenditure, aerodynamic drag, and\ncrashing. Our framework incorporates probabilistic crash dynamics, allowing a\ncyclist's risk tolerance to shape optimal tactics. We define an objective\nfunction that accounts for both finish time differences and the probability of\ncrashing, which we optimize subject to an energy expenditure constraint. We\ndemonstrate the methodology for a flat stage with a simple constant-power\nbreakaway. We then extend this analysis to account for fatigue-driven power\ndecay, and varying terrain and race conditions. We highlight the importance of\nstrategy by demonstrating that carefully planned decision making can lead to a\nrace win even when the energy expenditure is low. Our results highlight and\nquantify the fact that, at the elite level, success often depends as much on\nminimizing risk as on maximizing physical output."}
{"id": "2507.03190", "categories": ["cs.AI", "cs.DS", "cs.LG", "es: 68T05, 68T20, 68Q12, 90C27", "I.2.6; I.2.8; F.2.2; F.1.2; G.2.1"], "pdf": "https://arxiv.org/pdf/2507.03190", "abs": "https://arxiv.org/abs/2507.03190", "authors": ["Theo Bourdais", "Abeynaya Gnanasekaran", "Houman Owhadi", "Tuhin Sahai"], "title": "Discovering Algorithms with Computational Language Processing", "comment": "21 pages", "summary": "Algorithms are the engine for reproducible problem-solving. We present a\nframework automating algorithm discovery by conceptualizing them as sequences\nof operations, represented as tokens. These computational tokens are chained\nusing a grammar, enabling the formation of increasingly sophisticated\nprocedures. Our ensemble Monte Carlo tree search (MCTS) guided by reinforcement\nlearning (RL) explores token chaining and drives the creation of new tokens.\nThis methodology rediscovers, improves, and generates new algorithms that\nsubstantially outperform existing methods for strongly NP-hard combinatorial\noptimization problems and foundational quantum computing approaches such as\nGrover's and Quantum Approximate Optimization Algorithm. Operating at the\ncomputational rather than code-generation level, our framework produces\nalgorithms that can be tailored specifically to problem instances, not merely\nclasses."}
{"id": "2507.02893", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2507.02893", "abs": "https://arxiv.org/abs/2507.02893", "authors": ["Funda Raziye Mert", "Selami Bayeğ"], "title": "A Complete Characterization Theorem for Fuzzy Differentiability on Time Scales", "comment": null, "summary": "This paper investigates the generalized Hukuhara differentiability of fuzzy\nnumber-valued functions on arbitrary time scales using delta calculus. By\ncarefully examining and improving existing results, we develop a unified and\ncomplete characterization theorem that covers a wide range of differentiability\nbehaviors, including some cases that were previously missed. Our approach\naddresses important limitations and redundancies in earlier work, providing a\nclearer and more flexible understanding of fuzzy differentiability."}
{"id": "2507.03205", "categories": ["math.CO", "05A05, 05A15"], "pdf": "https://arxiv.org/pdf/2507.03205", "abs": "https://arxiv.org/abs/2507.03205", "authors": ["Roger Tian"], "title": "Counting occurrences of a pattern in a binary word", "comment": "12 pages", "summary": "Enumerating the number of times one word occurs in another is a much-studied\ncombinatorial subject. By utilizing a method that we call ``lexicographic\nextreme referencing'', we provide a formula for computing occurrences of one\nbinary word in another. We then study $B_{n,p}(k)$, the number of binary words\nof length $n$ containing a given word $p$ exactly $k$ times. For this purpose,\nwe first use lexicographic extreme referencing to provide an algorithm for\nconstructing all words $w$ that contain a given word $p$. Afterward, we give a\nmodified version of this algorithm for constructing the subset of binary words\nthat are ``primitive'' with respect to $p$, and we discuss approaches for\nfinding $B_{n,p}(k)$ via primitive words."}
{"id": "2507.03827", "categories": ["math.LO", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.03827", "abs": "https://arxiv.org/abs/2507.03827", "authors": ["Christine Gaßner"], "title": "Abstract computation over first-order structures. Part IIb: Moschovakis' operator and other non-determinisms", "comment": "43 pages", "summary": "BSS RAMs were introduced to provide a mathematical framework for\ncharacterizing algorithms over first-order structures. Non-deterministic BSS\nRAMs help to model different non-deterministic approaches. Here, we deal with\ndifferent types of binary non-determinisms and study the consequences of the\ndecidability of the identity relation and the decidability of finite sets\nconsisting of one or two constants. We compare the binary non-determinism\nresulting from a non-deterministic branching process, the digital\nnon-determinism resulting from the restriction of guesses to two constants, and\nsome other non-determinisms resulting from the use of Moschovakis' operator\napplied to oracle sets restricted to tuples of constants. Moreover, we show\nthat the performance capability and the efficiency of individual machines are\ninfluenced by the following properties. 1. The identity relation belongs to the\nunderlying structure. 2. The identity is semi-decidable over the underlying\nstructure. 3. Two single-element sets of constants are semi-decidable. 4. A set\nof two constants is semi-decidable. The order of these properties corresponds\nto the strength of their influence. In all cases mentioned, the\nsemi-decidability of the sets implies their decidability."}
{"id": "2507.03413", "categories": ["math.NT", "math.GN"], "pdf": "https://arxiv.org/pdf/2507.03413", "abs": "https://arxiv.org/abs/2507.03413", "authors": ["Paolo Leonetti"], "title": "Is it true that most sets are Sidon?", "comment": null, "summary": "No."}
{"id": "2507.02896", "categories": ["math.HO", "51M04 (Primary), 00A05 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.02896", "abs": "https://arxiv.org/abs/2507.02896", "authors": ["Luca Nathanael Chang"], "title": "Dissecting Circles to Prove a Square: A Novel Geometric Proof of the Pythagorean Theorem Using Circular Segments and Area Decomposition", "comment": "20 pages, 11 figures", "summary": "The Pythagorean Theorem has been proved in hundreds of ways, yet it inspires\nfresh insights through geometry and trigonometry. In this paper, we offer a new\nproof based on three circles that circumscribe the sides of a right triangle.\nRather than invoke coordinate geometry, the argument relies purely on classical\nEuclidean constructions, trigonometric identities independent of the theorem\nitself, and a careful analysis of the areas of circular segments.\n  The key idea is to evaluate the area of the semicircle built on the\nhypotenuse in two distinct ways: directly and as a combination of areas formed\nby overlapping circular segments and triangles constructed on the legs of the\ntriangle, as shown in Figure 10. Thales' Theorem, inscribed angle theorem,\nbasic trigonometric identities, and segment area formulas all play a role in a\nderivation that is both elementary and rigorous.\n  To the author's knowledge, this specific approach, which combines circular\nsymmetry, angle decomposition, and area comparison, has not appeared in the\nprior literature, including Loomis' comprehensive catalog [3] and the extensive\ndatabase at Cut-the-Knot [4]. As such, it provides both a new perspective on an\nancient theorem and an example of how classical tools can still yield original\ninsights."}
{"id": "2507.03699", "categories": ["math.ST", "cond-mat.stat-mech", "math.PR", "stat.TH", "60F10, 62B10, 62C10, 82M60"], "pdf": "https://arxiv.org/pdf/2507.03699", "abs": "https://arxiv.org/abs/2507.03699", "authors": ["Dalton A R Sakthivadivel"], "title": "The relation of bias with risk in empirically constrained inferences", "comment": "11+2 pages", "summary": "We give some results relating asymptotic characterisations of maximum entropy\nprobability measures to characterisations of Bayes optimal classifiers. Our\nmain theorems show that maximum entropy is a universally Bayes optimal decision\nrule given constraints on one's knowledge about some observed data in terms of\nan expected loss. We will extend this result to the case of uncertainty in the\nobservations of expected losses by generalising Sanov's theorem to\ndistributions of constraint values."}
{"id": "2507.02959", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.02959", "abs": "https://arxiv.org/abs/2507.02959", "authors": ["Ahmed Bensaoud", "Jugal Kalita"], "title": "A Novel Active Learning Approach to Label One Million Unknown Malware Variants", "comment": null, "summary": "Active learning for classification seeks to reduce the cost of labeling\nsamples by finding unlabeled examples about which the current model is least\ncertain and sending them to an annotator/expert to label. Bayesian theory can\nprovide a probabilistic view of deep neural network models by asserting a prior\ndistribution over model parameters and estimating the uncertainties by\nposterior distribution over these parameters. This paper proposes two novel\nactive learning approaches to label one million malware examples belonging to\ndifferent unknown modern malware families. The first model is Inception-V4+PCA\ncombined with several support vector machine (SVM) algorithms (UTSVM, PSVM,\nSVM-GSU, TBSVM). The second model is Vision Transformer based Bayesian Neural\nNetworks ViT-BNN. Our proposed ViT-BNN is a state-of-the-art active learning\napproach that differs from current methods and can apply to any particular\ntask. The experiments demonstrate that the ViT-BNN is more stable and robust in\nhandling uncertainty."}
{"id": "2507.03212", "categories": ["math.CO", "cs.DM", "52B12, 05C75, 52B05, 05D40, 60C05"], "pdf": "https://arxiv.org/pdf/2507.03212", "abs": "https://arxiv.org/abs/2507.03212", "authors": ["Catherine Babecki", "Tycho Elling", "Asaf Ferber"], "title": "Sharp Threshold for Cliques in Random 0/1 Polytope Graphs", "comment": "18 pages, 2 figures", "summary": "We study graph-theoretic properties of random $0/1$ polytopes. Specifically,\nlet $Q_p^n \\subseteq \\{0,1\\}^n$ be a random subset where each point is included\nindependently with probability $p$, and consider the graph $G_p$ of the\npolytope conv$(Q_p^n)$. We provide a short and combinatorial proof that $p =\n2^{-n/2}$ is a threshold for the edge density of $G_p$, a result originally due\nto Kaibel and Remshagen. We next resolve an open question from their paper by\nshowing that for $p \\leq 2^{-n/2 - o(1)}$, $G_p$ exhibits strong edge\nexpansion. In particular, we prove that, with high probability, every vertex\nhas degree $(1 - o(1))|Q_p^n|$. Lastly, we determine the threshold for $G_p$\nbeing a clique, strengthening a result of Bondarenko and Brodskiy. We show that\nwith high probability, if $p \\geq 2^{-\\delta n + o(1)}$, then $G_p$ is not a\nclique, and if $ p \\leq 2^{-\\delta n - o(1)}$, then $G_p$ is a clique, where\n$\\delta \\approx 0.8295$. Our approach combines a combinatorial characterization\nof edges in graphs arising from polytopes with the Kim-Vu polynomial\nconcentration inequality."}
{"id": "2507.03210", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.03210", "abs": "https://arxiv.org/abs/2507.03210", "authors": ["Selin Ahipasaoglu", "Stefano Cipolla", "Jacek Gondzio"], "title": "A column generation approach to exact experimental design", "comment": null, "summary": "In this work, we address the exact D-optimal experimental design problem by\nproposing an efficient algorithm that rapidly identifies the support of its\ncontinuous relaxation. Our method leverages a column generation framework to\nsolve such a continuous relaxation, where each restricted master problem is\ntackled using a Primal-Dual Interior-Point-based Semidefinite Programming\nsolver. This enables fast and reliable detection of the design's support. The\nidentified support is subsequently used to construct a feasible exact design\nthat is provably close to optimal. We show that, for large-scale instances in\nwhich the number of regression points exceeds by far the number of experiments,\nour approach achieves superior performance compared to existing\nbranch-and-bound-based algorithms in both computational efficiency and solution\nquality."}
{"id": "2507.03223", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03223", "abs": "https://arxiv.org/abs/2507.03223", "authors": ["Jeshwanth Challagundla"], "title": "SI-Agent: An Agentic Framework for Feedback-Driven Generation and Tuning of Human-Readable System Instructions for Large Language Models", "comment": null, "summary": "System Instructions (SIs), or system prompts, are pivotal for guiding Large\nLanguage Models (LLMs) but manual crafting is resource-intensive and often\nsuboptimal. Existing automated methods frequently generate non-human-readable\n\"soft prompts,\" sacrificing interpretability. This paper introduces SI-Agent, a\nnovel agentic framework designed to automatically generate and iteratively\nrefine human-readable SIs through a feedback-driven loop. SI-Agent employs\nthree collaborating agents: an Instructor Agent, an Instruction Follower Agent\n(target LLM), and a Feedback/Reward Agent evaluating task performance and\noptionally SI readability. The framework utilizes iterative cycles where\nfeedback guides the Instructor's refinement strategy (e.g., LLM-based editing,\nevolutionary algorithms). We detail the framework's architecture, agent roles,\nthe iterative refinement process, and contrast it with existing methods. We\npresent experimental results validating SI-Agent's effectiveness, focusing on\nmetrics for task performance, SI readability, and efficiency. Our findings\nindicate that SI-Agent generates effective, readable SIs, offering a favorable\ntrade-off between performance and interpretability compared to baselines.\nPotential implications include democratizing LLM customization and enhancing\nmodel transparency. Challenges related to computational cost and feedback\nreliability are acknowledged."}
{"id": "2507.02895", "categories": ["math.GM", "53D99 (primary) 53D50 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.02895", "abs": "https://arxiv.org/abs/2507.02895", "authors": ["Romero Solha"], "title": "Symplectic geometric aspects of the Schwarzschild solution", "comment": "3 pages", "summary": "This article details a construction of a symplectic structure for the\nSchwarzschild solution, and discusses its geometric quantisation. Said\nstructure is defined on the manifold itself, not on its cotangent bundle."}
{"id": "2507.03212", "categories": ["math.CO", "cs.DM", "52B12, 05C75, 52B05, 05D40, 60C05"], "pdf": "https://arxiv.org/pdf/2507.03212", "abs": "https://arxiv.org/abs/2507.03212", "authors": ["Catherine Babecki", "Tycho Elling", "Asaf Ferber"], "title": "Sharp Threshold for Cliques in Random 0/1 Polytope Graphs", "comment": "18 pages, 2 figures", "summary": "We study graph-theoretic properties of random $0/1$ polytopes. Specifically,\nlet $Q_p^n \\subseteq \\{0,1\\}^n$ be a random subset where each point is included\nindependently with probability $p$, and consider the graph $G_p$ of the\npolytope conv$(Q_p^n)$. We provide a short and combinatorial proof that $p =\n2^{-n/2}$ is a threshold for the edge density of $G_p$, a result originally due\nto Kaibel and Remshagen. We next resolve an open question from their paper by\nshowing that for $p \\leq 2^{-n/2 - o(1)}$, $G_p$ exhibits strong edge\nexpansion. In particular, we prove that, with high probability, every vertex\nhas degree $(1 - o(1))|Q_p^n|$. Lastly, we determine the threshold for $G_p$\nbeing a clique, strengthening a result of Bondarenko and Brodskiy. We show that\nwith high probability, if $p \\geq 2^{-\\delta n + o(1)}$, then $G_p$ is not a\nclique, and if $ p \\leq 2^{-\\delta n - o(1)}$, then $G_p$ is a clique, where\n$\\delta \\approx 0.8295$. Our approach combines a combinatorial characterization\nof edges in graphs arising from polytopes with the Kim-Vu polynomial\nconcentration inequality."}
{"id": "2507.03907", "categories": ["math.LO", "math.GR", "03E15, 20F50"], "pdf": "https://arxiv.org/pdf/2507.03907", "abs": "https://arxiv.org/abs/2507.03907", "authors": ["Su Gao", "Feng Li"], "title": "On the Isomorphism Relation for Omnigenous Locally Finite Groups", "comment": null, "summary": "The concept of an omnigenous locally finite group was introduced in [2] as a\ngeneralization of Hall's universal countable locally finite group. In this\npaper we show that the class of all countable omnigenous locally finite groups\nis Borel complete, hence it has the maximum Borel cardinality of isomorphism\ntypes among all countable structures.\n  [2] M. Etedadialiabadi, S. Gao, F. Le Ma\\^{i}tre, J. Melleray, Dense locally\nfinite subgroups of automorphism groups of ultraextensive spaces, Adv. Math.\n391 (2021), 107966."}
{"id": "2507.03544", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.03544", "abs": "https://arxiv.org/abs/2507.03544", "authors": ["Oleg N. German"], "title": "On uniform Diophantine exponents of lattices", "comment": "In Russian", "summary": "In this paper we study the spectrum of weak uniform Diophantine exponents of\nlattices and obtain its complete description in the two-dimensional case."}
{"id": "2507.03658", "categories": ["math.HO", "01A32 (Primary), 01A35, 51-03 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.03658", "abs": "https://arxiv.org/abs/2507.03658", "authors": ["Satyanad Kichenassamy"], "title": "Textual analysis of ancient Indian mathematics", "comment": null, "summary": "Recent analyses of Brahmagupta's discourse on the cyclic quadrilateral, and\nof Baudh\\=ayana's approximate quadrature of the circle, have shown that it is\nuseful to submit mathematical texts to a form of literary analysis. Several\npassages considered as obscure or objectionable may be explained in this way,\nby taking into account the elements of exposition and derivation of the results\nthat the author has given, as well as his conceptual background. This approach\naims at helping the reader set aside his preconceptions about what a\nmathematical text is supposed to be. In this paper, guidelines for further\napplication of this method are outlined, with illustrations taken from our\nprevious papers."}
{"id": "2507.03723", "categories": ["math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.03723", "abs": "https://arxiv.org/abs/2507.03723", "authors": ["Alessia Caponera"], "title": "On the Estimation of Anisotropic Covariance Functions on Compact Two-Point Homogeneous Spaces", "comment": null, "summary": "In this paper, the asymptotic theory presented in (Caponera et al., 2022) for\nspline-type anysotropic covariance estimator on the 2-dimensional sphere is\ngeneralized to the case of connected and compact two-point homogeneous spaces."}
{"id": "2507.02968", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02968", "abs": "https://arxiv.org/abs/2507.02968", "authors": ["Vijayalakshmi Ramasamy", "Seth Barrett", "Gokila Dorai", "Jessica Zumbach"], "title": "Unveiling Privacy Policy Complexity: An Exploratory Study Using Graph Mining, Machine Learning, and Natural Language Processing", "comment": "7 Pages; 1 Algorithm; 1 Table; 2 Figures; Accepted by AIRC 2025", "summary": "Privacy policy documents are often lengthy, complex, and difficult for\nnon-expert users to interpret, leading to a lack of transparency regarding the\ncollection, processing, and sharing of personal data. As concerns over online\nprivacy grow, it is essential to develop automated tools capable of analyzing\nprivacy policies and identifying potential risks. In this study, we explore the\npotential of interactive graph visualizations to enhance user understanding of\nprivacy policies by representing policy terms as structured graph models. This\napproach makes complex relationships more accessible and enables users to make\ninformed decisions about their personal data (RQ1). We also employ graph mining\nalgorithms to identify key themes, such as User Activity and Device\nInformation, using dimensionality reduction techniques like t-SNE and PCA to\nassess clustering effectiveness. Our findings reveal that graph-based\nclustering improves policy content interpretability. It highlights patterns in\nuser tracking and data sharing, which supports forensic investigations and\nidentifies regulatory non-compliance. This research advances AI-driven tools\nfor auditing privacy policies by integrating interactive visualizations with\ngraph mining. Enhanced transparency fosters accountability and trust."}
{"id": "2507.03423", "categories": ["math.OC", "cs.DM", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03423", "abs": "https://arxiv.org/abs/2507.03423", "authors": ["Tabea Brandt", "Christina Büsing", "Johanna Leweke", "Finn Seesemann", "Sina Weber"], "title": "Generating realistic patient data", "comment": null, "summary": "Developing algorithms for real-life problems that perform well in practice\nhighly depends on the availability of realistic data for testing. Obtaining\nreal-life data for optimization problems in health care, however, is often\ndifficult. This is especially true for any patient related optimization\nproblems, e.g., for patient-to-room assignment, due to data privacy policies.\nFurthermore, obtained real-life data usually cannot be published which\nprohibits reproducibility of results by other researchers. Therefore, often\nartificially generated instances are used. In this paper, we present\ncombinatorial insights about the feasibility of instances for the\npatient-to-room assignment problem (PRA). We use these insights to develop a\nconfigurable instance generator for PRA with an easy-to-use graphical user\ninterface. Configurability is in this case especially important as we observed\nin an extensive analysis of real-life data that, e.g., the probability\ndistribution for patients' age and length of stay depends on the respective\nward."}
{"id": "2507.03423", "categories": ["math.OC", "cs.DM", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03423", "abs": "https://arxiv.org/abs/2507.03423", "authors": ["Tabea Brandt", "Christina Büsing", "Johanna Leweke", "Finn Seesemann", "Sina Weber"], "title": "Generating realistic patient data", "comment": null, "summary": "Developing algorithms for real-life problems that perform well in practice\nhighly depends on the availability of realistic data for testing. Obtaining\nreal-life data for optimization problems in health care, however, is often\ndifficult. This is especially true for any patient related optimization\nproblems, e.g., for patient-to-room assignment, due to data privacy policies.\nFurthermore, obtained real-life data usually cannot be published which\nprohibits reproducibility of results by other researchers. Therefore, often\nartificially generated instances are used. In this paper, we present\ncombinatorial insights about the feasibility of instances for the\npatient-to-room assignment problem (PRA). We use these insights to develop a\nconfigurable instance generator for PRA with an easy-to-use graphical user\ninterface. Configurability is in this case especially important as we observed\nin an extensive analysis of real-life data that, e.g., the probability\ndistribution for patients' age and length of stay depends on the respective\nward."}
{"id": "2507.03226", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03226", "abs": "https://arxiv.org/abs/2507.03226", "authors": ["Congmin Min", "Rhea Mathew", "Joyce Pan", "Sahil Bansal", "Abbas Keshavarzi", "Amar Viswanathan Kannan"], "title": "Efficient Knowledge Graph Construction and Retrieval from Unstructured Text for Large-Scale RAG Systems", "comment": null, "summary": "We propose a scalable and cost-efficient framework for deploying Graph-based\nRetrieval Augmented Generation (GraphRAG) in enterprise environments. While\nGraphRAG has shown promise for multi-hop reasoning and structured retrieval,\nits adoption has been limited by the high computational cost of constructing\nknowledge graphs using large language models (LLMs) and the latency of\ngraph-based retrieval. To address these challenges, we introduce two core\ninnovations: (1) a dependency-based knowledge graph construction pipeline that\nleverages industrial-grade NLP libraries to extract entities and relations from\nunstructured text completely eliminating reliance on LLMs; and (2) a\nlightweight graph retrieval strategy that combines hybrid query node\nidentification with efficient one-hop traversal for high-recall, low-latency\nsubgraph extraction. We evaluate our framework on two SAP datasets focused on\nlegacy code migration and demonstrate strong empirical performance. Our system\nachieves up to 15% and 4.35% improvements over traditional RAG baselines based\non LLM-as-Judge and RAGAS metrics, respectively. Moreover, our dependency-based\nconstruction approach attains 94% of the performance of LLM-generated knowledge\ngraphs (61.87% vs. 65.83%) while significantly reducing cost and improving\nscalability. These results validate the feasibility of deploying GraphRAG\nsystems in real-world, large-scale enterprise applications without incurring\nprohibitive resource requirements paving the way for practical, explainable,\nand domain-adaptable retrieval-augmented reasoning."}
{"id": "2507.02923", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2507.02923", "abs": "https://arxiv.org/abs/2507.02923", "authors": ["Ernesto D. Aguirre"], "title": "Functional Reformulation of the Continuity Equation in Gases with Constant Density and its Application to the Existence Problem of Smooth Solutions to the Navier Stokes System", "comment": "9 pages", "summary": "We propose a rigorous reformulation of the incompressible Navier Stokes\nequations, starting from the energy equation and the ideal gas law. This\nreformulation allows the definition of a functional over the pressure field,\nwhich is used to bound the viscous dissipation term. It is shown that this norm\ncan replace classical regularity criteria and serves as the foundation for a\ncomplete functional framework that includes local existence, singularity\ncontrol, variational formulation, and uniqueness conditions."}
{"id": "2507.03244", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.03244", "abs": "https://arxiv.org/abs/2507.03244", "authors": ["Sergey Norin", "Agnes Totschnig"], "title": "Every graph with no $K_7^{\\vee}$-minor is $6$-colorable", "comment": null, "summary": "Let $K_7^{\\vee}$ denote the graph obtained from the complete graph on seven\nvertices by deleting two edges with a common end. Motivated by Hadwiger's\nconjecture, we prove that every graph with no $K_7^{\\vee}$-minor is\n$6$-colorable."}
{"id": "2507.03972", "categories": ["math.LO", "03E15, 03D30"], "pdf": "https://arxiv.org/pdf/2507.03972", "abs": "https://arxiv.org/abs/2507.03972", "authors": ["George Barmpalias", "Nikolay Bazhenov", "Chi Tat Chong", "Wei Dai", "Su Gao", "Jun Le Goh", "Jialiang He", "Keng Meng Selwyn Ng", "Andre Nies", "Theodore Slaman", "Riley Thornton", "Wei Wang", "Jing Yu", "Liang Yu"], "title": "Open Problems in Computability Theory and Descriptive Set Theory", "comment": null, "summary": "These open problems were presented in the Problem Sessions held during the\nTianyuan Workshop on Computability Theory and Descriptive Set Theory, June\n16-20, 2025. The problems are organized into sections named after their\ncontributors, in the order of their presentations during the workshop. Notes\nwere taken and compiled by Wei Dai, Feng Li, Ruiwen Li, Ming Xiao, Xu Wang,\nV\\'ictor Hugo Ya\\~nez Salazar, and Yang Zheng."}
{"id": "2507.03554", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.03554", "abs": "https://arxiv.org/abs/2507.03554", "authors": ["Oleg N. German"], "title": "On the weak uniform Diophantine exponent of a real number", "comment": "In Russian", "summary": "In this paper we introduce the notion of a weak uniform Diophantine exponent\nof a real number and obtain the complete description of the spectrum of its\nvalues."}
{"id": "2507.03894", "categories": ["math.ST", "stat.ME", "stat.TH", "62J15"], "pdf": "https://arxiv.org/pdf/2507.03894", "abs": "https://arxiv.org/abs/2507.03894", "authors": ["Roderick Edwards"], "title": "Tied Pools and Drawn Games", "comment": "33 pages; 1 figure", "summary": "We consider the problem of estimating `preference' or `strength' parameters\nin three-way comparison experiments, each composed of a series of paired\ncomparisons, but where only the single `preferred' or `strongest' candidate is\nknown in each trial. Such experiments arise in psychology and market research,\nbut here we use chess competitions as the prototypical context, in particular a\nseries of `pools' between three players that occurred in 1821. The\npossibilities of tied pools, redundant and therefore unplayed games, and drawn\ngames must all be considered. This leads us to reconsider previous models for\nestimating strength parameters when drawn games are a possible result. In\nparticular, Davidson's method for ties has been questioned, and we propose an\nalternative. We argue that the most correct use of this method is to estimate\nstrength parameters first, and then fix these to estimate a draw-propensity\nparameter, rather than estimating all parameters simultaneously, as Davidson\ndoes. This results in a model that is consistent with, and provides more\ncontext for, a simple method for handling draws proposed by Glickman. Finally,\nin pools with incomplete information, the number of drawn games can be\nestimated by adopting a draw-propensity parameter from related data with more\ncomplete information."}
{"id": "2507.02969", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02969", "abs": "https://arxiv.org/abs/2507.02969", "authors": ["Daniel López-Montero", "José L. Álvarez-Aldana", "Alicia Morales-Martínez", "Marta Gil-López", "Juan M. Auñón García"], "title": "Reinforcement Learning for Automated Cybersecurity Penetration Testing", "comment": null, "summary": "This paper aims to provide an innovative machine learning-based solution to\nautomate security testing tasks for web applications, ensuring the correct\nfunctioning of all components while reducing project maintenance costs.\nReinforcement Learning is proposed to select and prioritize tools and optimize\nthe testing path. The presented approach utilizes a simulated webpage along\nwith its network topology to train the agent. Additionally, the model leverages\nGeometric Deep Learning to create priors that reduce the search space and\nimprove learning convergence. The validation and testing process was conducted\non real-world vulnerable web pages commonly used by human hackers for learning.\nAs a result of this study, a reinforcement learning algorithm was developed\nthat maximizes the number of vulnerabilities found while minimizing the number\nof steps required"}
{"id": "2507.04254", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.04254", "abs": "https://arxiv.org/abs/2507.04254", "authors": ["Gaétan Berthe", "Marthe Bonamy", "Fábio Botler", "Gaia Carenini", "Lucas Colucci", "Arthur Dumas", "Fatemeh Ghasemi", "Pedro Mariano Viana Neto"], "title": "On Modular Edge Colourings of Graphs", "comment": "7 pages", "summary": "Given a graph $G$ and an integer $k\\geq 2$, let $\\chi'_k(G)$ denote the\nminimum number of colours required to colour the edges of $G$ such that, in\neach colour class, the subgraph induced by the edges of that colour has all\nnon-zero degrees congruent to $1$ modulo $k$. In 1992, Pyber proved that\n$\\chi'_2(G) \\leq 4$ for every graph $G$, and posed the question of whether\n$\\chi'_k(G)$ can be bounded solely in terms of $k$ for every $k\\geq 3$. This\nquestion was answered in 1997 by Scott, who showed that $\\chi'_k(G)\\leq5k^2\\log\nk$, and further asked whether $\\chi'_k(G) = O(k)$. Recently, Botler, Colucci,\nand Kohayakawa (2023) answered Scott's question affirmatively proving that\n$\\chi'_k(G) \\leq 198k - 101$, and conjectured that the multiplicative constant\ncould be reduced to $1$. A step towards this latter conjecture was made in 2024\nby Nweit and Yang, who improved the bound to $\\chi'_k(G) \\leq 177k - 93$. In\nthis paper, we further improve the multiplicative constant to $9$. More\nspecifically, we prove that there is a function $f\\in o(k)$ for which\n$\\chi'_k(G) \\leq 7k + f(k)$ if $k$ is odd, and $\\chi'_k(G) \\leq 9k + f(k)$ if\n$k$ is even. In doing so, we prove that $\\chi'_k(G) \\leq k + O(d)$ for every\n$d$-degenerate graph $G$, which plays a central role in our proof."}
{"id": "2507.03424", "categories": ["math.OC", "90C26, 49J52, 14P10"], "pdf": "https://arxiv.org/pdf/2507.03424", "abs": "https://arxiv.org/abs/2507.03424", "authors": ["Liguo Jiao", "Tien-Son Pham", "Nguyen Van Tuyen"], "title": "Exact penalty functions in optimization with unbounded constraint sets", "comment": "25 pages", "summary": "This paper identifies necessary and sufficient conditions for the exactness\nof penalty functions in optimization problems whose constraint sets are not\nnecessarily bounded. The case where the data of problems is locally Lipschitz\nor semi-algebraic is studied in detail. The conditions are given in terms of\nproperties of the objective and residual functions of the problems in question.\nThe obtained results generalize and improve some known results in the\nliterature on exact penalty functions."}
{"id": "2507.03254", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03254", "abs": "https://arxiv.org/abs/2507.03254", "authors": ["Bruce Yang", "Xinfeng He", "Huan Gao", "Yifan Cao", "Xiaofan Li", "David Hsu"], "title": "CodeAgents: A Token-Efficient Framework for Codified Multi-Agent Reasoning in LLMs", "comment": null, "summary": "Effective prompt design is essential for improving the planning capabilities\nof large language model (LLM)-driven agents. However, existing structured\nprompting strategies are typically limited to single-agent, plan-only settings,\nand often evaluate performance solely based on task accuracy - overlooking\ncritical factors such as token efficiency, modularity, and scalability in\nmulti-agent environments. To address these limitations, we introduce\nCodeAgents, a prompting framework that codifies multi-agent reasoning and\nenables structured, token-efficient planning in multi-agent systems. In\nCodeAgents, all components of agent interaction - Task, Plan, Feedback, system\nroles, and external tool invocations - are codified into modular pseudocode\nenriched with control structures (e.g., loops, conditionals), boolean logic,\nand typed variables. This design transforms loosely connected agent plans into\ncohesive, interpretable, and verifiable multi-agent reasoning programs. We\nevaluate the proposed framework across three diverse benchmarks - GAIA,\nHotpotQA, and VirtualHome - using a range of representative LLMs. Results show\nconsistent improvements in planning performance, with absolute gains of 3-36\npercentage points over natural language prompting baselines. On VirtualHome,\nour method achieves a new state-of-the-art success rate of 56%. In addition,\nour approach reduces input and output token usage by 55-87% and 41-70%,\nrespectively, underscoring the importance of token-aware evaluation metrics in\nthe development of scalable multi-agent LLM systems. The code and resources are\navailable at: https://anonymous.4open.science/r/CodifyingAgent-5A86"}
{"id": "2507.02930", "categories": ["math.GM", "11A25"], "pdf": "https://arxiv.org/pdf/2507.02930", "abs": "https://arxiv.org/abs/2507.02930", "authors": ["Sagar Mandal"], "title": "A Note on Deaconescu's Conjecture", "comment": "5 pages", "summary": "Hasanalizade [1] studied Deaconescu's conjecture for positive composite\ninteger $n$. A positive composite integer $n\\geq4$ is said to be a Deaconescu\nnumber if $S_2(n)\\mid \\phi(n)-1$. In this paper, we improve Hasanalizade's\nresult by proving that a Deaconescu number $n$ must have at least seventeen\ndistinct prime divisors, i.e., $\\omega(n)\\geq 17$ and must be strictly larger\nthan $5.86\\cdot10^{22}$. Further, we prove that if any Deaconescu number $n$\nhas all prime divisors greater than or equal to $11$, then $\\omega(n)\\geq\np^{*}$, where $p^{*}$ is the smallest prime divisor of $n$ and if $n\\in D_3$\nthen all the prime divisors of $n$ must be congruent to $2$ modulo $3$ and\n$\\omega(n)\\geq 48$."}
{"id": "2507.03261", "categories": ["math.CO", "05C35"], "pdf": "https://arxiv.org/pdf/2507.03261", "abs": "https://arxiv.org/abs/2507.03261", "authors": ["Tao Jiang", "Sean Longbrake"], "title": "Regularization and asymmetric extremal numbers of subdivisions", "comment": "29 pages", "summary": "Given a real $\\mu\\geq 1$, a graph $H$ is $\\mu$-almost-regular if\n$\\Delta(H)\\leq \\mu \\delta(H)$. The celebrated regularization theorem of\nErd\\H{o}s and Simonovits states that for every real $0<\\varepsilon<1$ there\nexists a real $\\mu=\\mu(\\varepsilon)$ such that every $n$-vertex graph $G$ with\n$\\Omega(n^{1+\\varepsilon})$ edges contains an $m$-vertex $\\mu$-almost-regular\nsubgraph $H$ with $\\Omega(m^{1+\\varepsilon})$ edges for some\n$n^{\\varepsilon\\frac{1-\\varepsilon}{1+\\varepsilon}}\\leq m\\leq n$. We develop an\nenhanced version of it in which the subgraph $H$ also has average degree at\nleast $\\Omega(\\frac{d(G)}{\\log n})$, where $d(G)$ is the average degree of $G$.\nWe then give a bipartite analogue of the enhanced regularization theorem.\n  Using the bipartite regularization theorem, we establish upper bounds on the\nmaximum number of edges in a bipartite graph with part sizes $m$ and $n$ that\ndoes not contain a $2k$-subdivision of $K_{s,t}$ or $2k$-multi-subdivisions of\n$K_p$, thus extending the corresponding work of Janzer to the bipartite setting\nfor even subdivisions. We show these upper bounds are tight up to a constant\nfactor for infinitely many pairs $(m,n)$. The problem for estimating the\nmaximum number of edges in a bipartite graph with part sizes $m$ and $n$ that\ndoes not contain a $(2k+1)$-subdivision of $K_{s,t}$ remains open."}
{"id": "2507.04028", "categories": ["math.LO", "Primary 03E35, Secondary 03E10, 03E25"], "pdf": "https://arxiv.org/pdf/2507.04028", "abs": "https://arxiv.org/abs/2507.04028", "authors": ["Guozhen Shen", "Wenjie Zhou"], "title": "On ordering of surjective cardinals", "comment": "5 pages", "summary": "Let $\\mathrm{Card}$ denote the class of cardinals. For all cardinals\n$\\mathfrak{a}$ and $\\mathfrak{b}$, $\\mathfrak{a}\\leqslant\\mathfrak{b}$ means\nthat there is an injection from a set of cardinality $\\mathfrak{a}$ into a set\nof cardinality $\\mathfrak{b}$, and $\\mathfrak{a}\\leqslant^\\ast\\mathfrak{b}$\nmeans that there is a partial surjection from a set of cardinality\n$\\mathfrak{b}$ onto a set of cardinality $\\mathfrak{a}$. A doubly ordered set\nis a triple $\\langle P,\\preccurlyeq,\\preccurlyeq^\\ast\\rangle$ such that\n$\\preccurlyeq$ is a partial ordering on $P$, $\\preccurlyeq^\\ast$ is a\npreordering on $P$, and ${\\preccurlyeq}\\subseteq{\\preccurlyeq^\\ast}$. In 1966,\nJech proved that for every partially ordered set $\\langle\nP,\\preccurlyeq\\rangle$, there exists a model of $\\mathsf{ZF}$ in which $\\langle\nP,\\preccurlyeq\\rangle$ can be embedded into\n$\\langle\\mathrm{Card},\\leqslant\\rangle$. We generalize this result by showing\nthat for every doubly ordered set $\\langle\nP,\\preccurlyeq,\\preccurlyeq^\\ast\\rangle$, there exists a model of $\\mathsf{ZF}$\nin which $\\langle P,\\preccurlyeq,\\preccurlyeq^\\ast\\rangle$ can be embedded into\n$\\langle\\mathrm{Card},\\leqslant,\\leqslant^\\ast\\rangle$."}
{"id": "2507.03727", "categories": ["math.NT", "11D68, 18M20"], "pdf": "https://arxiv.org/pdf/2507.03727", "abs": "https://arxiv.org/abs/2507.03727", "authors": ["Agustina Czenky", "Emily McGovern", "Julia Plavnik", "Eric Rowell", "Abigail Watkins"], "title": "Egyptian fractions for few primes", "comment": null, "summary": "We study solutions to the Egyptian fractions equation with the prime factors\nof the denominators constrained to lie in a fixed set of primes. We evaluate\nthe effectiveness of the greedy algorithm in establishing bounds on such\nsolutions. Additionally, we present improved algorithms for generating low-rank\nsolutions and solutions restricted to specific prime sets. Computational\nresults obtained using these algorithms are provided, alongside a discussion on\ntheir performance."}
{"id": "2507.04637", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.04637", "abs": "https://arxiv.org/abs/2507.04637", "authors": ["Subhrajyoty Roy", "Supratik Basu", "Abhik Ghosh", "Ayanendranath Basu"], "title": "Characterization of Generalized Alpha-Beta Divergence and Associated Entropy Measures", "comment": null, "summary": "Minimum divergence estimators provide a natural choice of estimators in a\nstatistical inference problem. Different properties of various families of\nthese divergence measures such as Hellinger distance, power divergence, density\npower divergence, logarithmic density power divergence, etc. have been\nestablished in literature. In this work, we propose a new class of divergence\nmeasures called \"generalized alpha-beta divergence\", which is a superfamily of\nthese popular divergence families. We provide the necessary and sufficient\nconditions for the validity of the proposed generalized divergence measure,\nwhich allows us to construct novel families of divergence and associated\nentropy measures. We also show various characterizing properties like duality,\ninversion, semi-continuity, etc., from which, many existing results follow as\nspecial cases. We also discuss about the entropy measure derived from this\ngeneral family of divergence and its properties."}
{"id": "2507.02971", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.02971", "abs": "https://arxiv.org/abs/2507.02971", "authors": ["Mohsen Ghasemizade", "Juniper Lovato", "Christopher M. Danforth", "Peter Sheridan Dodds", "Laura S. P. Bloomfield", "Matthew Price", "Team LEMURS", "Joseph P. Near"], "title": "Aim High, Stay Private: Differentially Private Synthetic Data Enables Public Release of Behavioral Health Information with High Utility", "comment": "14 pages, 8 figures, 2 tables", "summary": "Sharing health and behavioral data raises significant privacy concerns, as\nconventional de-identification methods are susceptible to privacy attacks.\nDifferential Privacy (DP) provides formal guarantees against re-identification\nrisks, but practical implementation necessitates balancing privacy protection\nand the utility of data.\n  We demonstrate the use of DP to protect individuals in a real behavioral\nhealth study, while making the data publicly available and retaining high\nutility for downstream users of the data. We use the Adaptive Iterative\nMechanism (AIM) to generate DP synthetic data for Phase 1 of the Lived\nExperiences Measured Using Rings Study (LEMURS). The LEMURS dataset comprises\nphysiological measurements from wearable devices (Oura rings) and self-reported\nsurvey data from first-year college students. We evaluate the synthetic\ndatasets across a range of privacy budgets, epsilon = 1 to 100, focusing on the\ntrade-off between privacy and utility.\n  We evaluate the utility of the synthetic data using a framework informed by\nactual uses of the LEMURS dataset. Our evaluation identifies the trade-off\nbetween privacy and utility across synthetic datasets generated with different\nprivacy budgets. We find that synthetic data sets with epsilon = 5 preserve\nadequate predictive utility while significantly mitigating privacy risks. Our\nmethodology establishes a reproducible framework for evaluating the practical\nimpacts of epsilon on generating private synthetic datasets with numerous\nattributes and records, contributing to informed decision-making in data\nsharing practices."}
{"id": "2507.04581", "categories": ["math.CO", "cs.DM", "05C35, 05C38, 05D40"], "pdf": "https://arxiv.org/pdf/2507.04581", "abs": "https://arxiv.org/abs/2507.04581", "authors": ["He Guo"], "title": "Short rainbow cycles for families of small edge sets", "comment": "9 pages", "summary": "In 2019, Aharoni proposed a conjecture generalizing the Caceetta-H\\\"aggkvist\nconjecture: if an $n$-vertex graph $G$ admits an edge coloring (not necessarily\nproper) with $n$ colors such that each color class has size at least $r$, then\n$G$ contains a rainbow cycle of length at most $\\lceil n/r\\rceil$. Recent works\n\\cite{AG2023,ABCGZ2023,G2025} have shown that if a constant fraction of the\ncolor classes are non-star, then the rainbow girth is $O(\\log n)$. In this\nnote, we extend these results, and we show that even a small fraction of\nnon-star color classes suffices to ensure logarithmic rainbow girth. We also\nprove that the logarithmic bound is of the right order of magnitude. Moreover,\nwe determine the threshold fraction between the types of color classes at which\nthe rainbow girth transitions from linear to logarithmic."}
{"id": "2507.03497", "categories": ["math.OC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2507.03497", "abs": "https://arxiv.org/abs/2507.03497", "authors": ["Pieter Kleer", "Daan Noordenbos"], "title": "Bayesian Optimal Stopping with Maximum Value Knowledge", "comment": null, "summary": "We consider an optimal stopping problem with n correlated offers where the\ngoal is to design a (randomized) stopping strategy that maximizes the expected\nvalue of the offer in the sequence at which we stop. Instead of assuming to\nknow the complete correlation structure, which is unrealistic in practice, we\nonly assume to have knowledge of the distribution of the maximum value of the\nsequence, and want to analyze the worst-case correlation structure whose\nmaximum follows this distribution. This can be seen as a trade-off between the\nsetting in which no distributional information is known, and the Bayesian\nsetting in which the (possibly correlated) distributions of all the individual\noffers are known. As our first main result we show that a deterministic\nthreshold strategy using the monopoly price of the distribution of the maximum\nvalue is asymptotically optimal assuming that the expectation of the maximum\nvalue grows sublinearly in n. In our second main result, we further tighten\nthis bound by deriving a tight quadratic convergence guarantee for sufficiently\nsmooth distributions of the maximum value. Our results also give rise to a more\nfine-grained picture regarding prophet inequalities with correlated values, for\nwhich distribution-free bounds often only yield a performance guarantee that is\nof the order 1/n."}
{"id": "2507.03267", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.03267", "abs": "https://arxiv.org/abs/2507.03267", "authors": ["Jie Peng", "Jiarui Ji", "Runlin Lei", "Zhewei Wei", "Yongchao Liu", "Chuntao Hong"], "title": "GDGB: A Benchmark for Generative Dynamic Text-Attributed Graph Learning", "comment": null, "summary": "Dynamic Text-Attributed Graphs (DyTAGs), which intricately integrate\nstructural, temporal, and textual attributes, are crucial for modeling complex\nreal-world systems. However, most of the existing DyTAG datasets exhibit poor\ntextual quality, which severely limits their utility for DyTAG generation tasks\nrequiring semantically rich inputs. Additionally, prior work mainly focuses on\ndiscriminative tasks on DyTAGs, resulting in a lack of standardized task\nformulations and evaluation protocols tailored for DyTAG generation. To address\nthese critical issues, we propose Generative DyTAG Benchmark (GDGB), which\ncomprises eight meticulously curated DyTAG datasets with high-quality textual\nfeatures for both nodes and edges, overcoming limitations of prior datasets.\nBuilding on GDGB, we define two novel DyTAG generation tasks: Transductive\nDynamic Graph Generation (TDGG) and Inductive Dynamic Graph Generation (IDGG).\nTDGG transductively generates a target DyTAG based on the given source and\ndestination node sets, while the more challenging IDGG introduces new node\ngeneration to inductively model the dynamic expansion of real-world graph data.\nTo enable holistic evaluation, we design multifaceted metrics that assess the\nstructural, temporal, and textual quality of the generated DyTAGs. We further\npropose GAG-General, an LLM-based multi-agent generative framework tailored for\nreproducible and robust benchmarking of DyTAG generation. Experimental results\ndemonstrate that GDGB enables rigorous evaluation of TDGG and IDGG, with key\ninsights revealing the critical interplay of structural and textual features in\nDyTAG generation. These findings establish GDGB as a foundational resource for\nadvancing generative DyTAG research and unlocking further practical\napplications in DyTAG generation. GDGB datasets, source codes, and leaderboards\nare available at \\href{https://gdgb-algo.github.io/}{here}."}
{"id": "2507.03107", "categories": ["math.GM", "Primary: 11N35 Secondary: 11N05, 11Y55, 11Y60", "F.2.1; G.2.0; G.2.1"], "pdf": "https://arxiv.org/pdf/2507.03107", "abs": "https://arxiv.org/abs/2507.03107", "authors": ["Yuhang Shi"], "title": "A Constructive Heuristic Sieve for the Twin Prime Problem", "comment": "5 pages,1 table", "summary": "The quantitative distribution of twin primes remains a central open problem\nin number theory. This paper develops a heuristic model grounded in the\nprinciples of sieve theory, with the goal of constructing an analytical\napproximation for the twin prime constant from first principles. The core of\nthis method, which we term ``$f(t; z)$ function analysis'', involves\nrepresenting the sieve's density product as a ratio of infinite series\ninvolving $f(t;z)$, the elementary symmetric polynomials of prime reciprocals.\nThis framework provides a constructive path to approximate the celebrated\nHardy-Littlewood constant for twin primes. We present a detailed and\ntransparent numerical analysis, comparing the truncated series approximation to\nempirical data. The limitations of the model, particularly those related to\nseries truncation and the choice of sieving parameters, are rigorously\ndiscussed. The primary value of this work lies not in proposing a superior\npredictive formula, but in offering a clear, decomposable, and analytically\ntractable heuristic for understanding the multiplicative structure of sieve\nconstants."}
{"id": "2507.03264", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.03264", "abs": "https://arxiv.org/abs/2507.03264", "authors": ["Ting Huang", "Yanbo Zhang", "Yaojun Chen"], "title": "Minimum degree and sparse connected spanning subgraphs", "comment": null, "summary": "Let $G$ be a connected graph on $n$ vertices and at most $n(1+\\epsilon)$\nedges with bounded maximum degree, and $F$ a graph on $n$ vertices with minimum\ndegree at least $n-k$, where $\\epsilon$ is a constant depending on $k$. In this\npaper, we prove that $F$ contains $G$ as a spanning subgraph provided $n\\ge\n6k^3$, by establishing tight bounds for the Ramsey number $r(G,K_{1,k})$, where\n$K_{1,k}$ is a star on $k+1$ vertices. Our result generalizes and refines the\nwork of Erd\\H{o}s, Faudree, Rousseau, and Schelp (JCT-B, 1982), who established\nthe corresponding result for $G$ being a tree. Moreover, the tight bound for\n$r(G,tK_{1,k})$ is also obtained."}
{"id": "2507.04071", "categories": ["math.LO", "03B38, 03B40, 03C55, 03E30, 68V20"], "pdf": "https://arxiv.org/pdf/2507.04071", "abs": "https://arxiv.org/abs/2507.04071", "authors": ["Tristan Bice"], "title": "Dependent Types Simplified", "comment": null, "summary": "We present two logical systems based on dependent types that are comparable\nto ZFC, both in terms of simplicity and having natural set theoretic\ninterpretations. Our perspective is that of a mathematician trained in\nclassical logic, but nevertheless we hope this paper might go some way to\nbridging the cultural divide between type theorists coming from computer\nscience."}
{"id": "2507.03784", "categories": ["math.NT", "11D45, 11Y50"], "pdf": "https://arxiv.org/pdf/2507.03784", "abs": "https://arxiv.org/abs/2507.03784", "authors": ["Kate Finnerty"], "title": "Quadratic Chabauty Experiments on Genus 2 Bielliptic Modular Curves in the LMFDB", "comment": "14 pages, submitted to LuCaNT 2025 conference proceedings", "summary": "We present results of quadratic Chabauty experiments on genus 2 bielliptic\nmodular curves of Jacobian rank 2 that have recently been added to the LMFDB.\nWe apply quadratic Chabauty methods over both the rationals and quadratic\nimaginary fields. In a number of cases, the experiments yielded algebraic\nirrational points among the set of mock rational points. We highlight specific\nnotable examples, including the non-split Cartan modular curve $X^+_{ns}(15)$.\nLastly, we offer a conjecture relating the level of the modular curve to the\npotential number fields over which points can arise."}
{"id": "2507.04794", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.04794", "abs": "https://arxiv.org/abs/2507.04794", "authors": ["Arthur Stéphanovitch", "Eddie Aamari", "Clément Levrard"], "title": "Generalization bounds for score-based generative models: a synthetic proof", "comment": null, "summary": "We establish minimax convergence rates for score-based generative models\n(SGMs) under the $1$-Wasserstein distance. Assuming the target density\n$p^\\star$ lies in a nonparametric $\\beta$-smooth H\\\"older class with either\ncompact support or subGaussian tails on $\\mathbb{R}^d$, we prove that neural\nnetwork-based score estimators trained via denoising score matching yield\ngenerative models achieving rate $n^{-(\\beta+1)/(2\\beta+d)}$ up to\npolylogarithmic factors. Our unified analysis handles arbitrary smoothness\n$\\beta > 0$, supports both deterministic and stochastic samplers, and leverages\nshape constraints on $p^\\star$ to induce regularity of the score. The resulting\nproofs are more concise, and grounded in generic stability of diffusions and\nstandard approximation theory."}
{"id": "2507.02976", "categories": ["cs.CR", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.02976", "abs": "https://arxiv.org/abs/2507.02976", "authors": ["Amirali Sajadi", "Kostadin Damevski", "Preetha Chatterjee"], "title": "Are AI-Generated Fixes Secure? Analyzing LLM and Agent Patches on SWE-bench", "comment": null, "summary": "Large Language Models (LLMs) and their agentic frameworks are increasingly\nadopted to automate software development tasks such as issue resolution and\nprogram repair. While prior work has identified security risks in LLM-generated\ncode, most evaluations have focused on synthetic or isolated settings, leaving\nopen questions about the security of these systems in real-world development\ncontexts. In this study, we present the first large-scale security analysis of\nLLM-generated patches using 20,000+ issues from the SWE-bench dataset. We\nevaluate patches produced by a standalone LLM (Llama 3.3) and compare them to\ndeveloper-written patches. We also assess the security of patches generated by\nthree top-performing agentic frameworks (OpenHands, AutoCodeRover, HoneyComb)\non a subset of our data. Finally, we analyze a wide range of code, issue, and\nproject-level factors to understand the conditions under which LLMs and agents\nare most likely to generate insecure code. Our findings reveal that the\nstandalone LLM introduces nearly 9x more new vulnerabilities than developers,\nwith many of these exhibiting unique patterns not found in developers' code.\nAgentic workflows also generate a significant number of vulnerabilities,\nparticularly when granting LLMs more autonomy, potentially increasing the\nlikelihood of misinterpreting project context or task requirements. We find\nthat vulnerabilities are more likely to occur in LLM patches associated with a\nhigher number of files, more lines of generated code, and GitHub issues that\nlack specific code snippets or information about the expected code behavior and\nsteps to reproduce. These results suggest that contextual factors play a\ncritical role in the security of the generated code and point toward the need\nfor proactive risk assessment methods that account for both code and\nissue-level information to complement existing vulnerability detection tools."}
{"id": "2507.04848", "categories": ["math.NT", "cs.DM", "math.CO", "11A63, 11K16, 11B85, 68Q45, 68R15"], "pdf": "https://arxiv.org/pdf/2507.04848", "abs": "https://arxiv.org/abs/2507.04848", "authors": ["Émilie Charlier", "Pierre Popoli", "Michel Rigo"], "title": "Computing Expansions in Infinitely Many Cantor Real Bases via a Single Transducer", "comment": "36 pages, 10 figures. Comments are welcome", "summary": "Representing real numbers using convenient numeration systems (integer bases,\n$\\beta$-numeration, Cantor bases, etc.) has been a longstanding mathematical\nchallenge. This paper focuses on Cantor real bases and, specifically, on\nautomatic Cantor real bases and the properties of expansions of real numbers in\nthis setting. We develop a new approach where a single transducer associated\nwith a fixed real number $r$, computes the $\\mathbf{B}$-expansion of $r$ but\nfor an infinite family of Cantor real bases $\\mathbf{B}$ given as input. This\npoint of view contrasts with traditional computational models for which the\nnumeration system is fixed. Under some assumptions on the finitely many Pisot\nnumbers occurring in the Cantor real base, we show that only a finite part of\nthe transducer is visited. We obtain fundamental results on the structure of\nthis transducer and on decidability problems about these expansions, proving\nthat for certain classes of Cantor real bases, key combinatorial properties\nsuch as greediness of the expansion or periodicity can be decided\nalgorithmically."}
{"id": "2507.03566", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.03566", "abs": "https://arxiv.org/abs/2507.03566", "authors": ["Yuge Ye", "Qingna Li"], "title": "Modified Block Newton Algorithm for $\\ell_0$- Regularized Optimization", "comment": "arXiv admin note: text overlap with arXiv:2505.17382. text overlap\n  with arXiv:2004.05132 by other authors", "summary": "In this paper, we propose a globally convergent Newton type method to solve\n$\\ell_0$ regularized sparse optimization problem. In fact, a line search\nstrategy is applied to the Newton method to obtain global convergence. The\nJacobian matrix of the original problem is a block upper triangular matrix. To\nreduce the computational burden, our method only requires the calculation of\nthe block diagonal. We also introduced regularization to overcome matrix\nsingularity. Although we only use the block-diagonal part of the Jacobian\nmatrix, our algorithm still maintains global convergence and achieves a local\nquadratic convergence rate. Numerical results demonstrate the efficiency of our\nmethod."}
{"id": "2507.03285", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03285", "abs": "https://arxiv.org/abs/2507.03285", "authors": ["Jianyu Zhang", "Léon Bottou"], "title": "Memory Mosaics at scale", "comment": "arXiv admin note: substantial text overlap with arXiv:2504.14751", "summary": "Memory Mosaics [Zhang et al., 2025], networks of associative memories, have\ndemonstrated appealing compositional and in-context learning capabilities on\nmedium-scale networks (GPT-2 scale) and synthetic small datasets. This work\nshows that these favorable properties remain when we scale memory mosaics to\nlarge language model sizes (llama-8B scale) and real-world datasets.\n  To this end, we scale memory mosaics to 10B size, we train them on one\ntrillion tokens, we introduce a couple architectural modifications (\"Memory\nMosaics v2\"), we assess their capabilities across three evaluation dimensions:\ntraining-knowledge storage, new-knowledge storage, and in-context learning.\n  Throughout the evaluation, memory mosaics v2 match transformers on the\nlearning of training knowledge (first dimension) and significantly outperforms\ntransformers on carrying out new tasks at inference time (second and third\ndimensions). These improvements cannot be easily replicated by simply\nincreasing the training data for transformers. A memory mosaics v2 trained on\none trillion tokens still perform better on these tasks than a transformer\ntrained on eight trillion tokens."}
{"id": "2507.03651", "categories": ["math.CO", "math.PR", "05A05, 05A15"], "pdf": "https://arxiv.org/pdf/2507.03651", "abs": "https://arxiv.org/abs/2507.03651", "authors": ["Dominik Beck", "Zelin Lv", "Aaron Potechin"], "title": "Analysing the Moments of the Determinant of a Random Matrix Via Analytic Combinatorics of Permutation Tables", "comment": null, "summary": "We consider the following natural question. Given a matrix $A$ with i.i.d.\nrandom entries, what are the moments of the determinant of $A$? In other words,\nwhat is $\\mathbb{E}[\\det(A)^k]$? While there is a general expression for\n$\\mathbb{E}[\\det(A)^k]$ when the entries of $A$ are Gaussian, much less is\nknown when the entries of $A$ have some other distribution.\n  In two recent papers, we answered this question for $k = 4$ when the entries\nof $A$ are drawn from an arbitrary distribution and for $k = 6$ when the\nentries of $A$ are drawn from a distribution which has mean $0$. These analyses\nused recurrence relations and were highly intricate. In this paper, we show how\nthese analyses can be simplified considerably by using analytic combinatorics\non permutation tables."}
{"id": "2507.04138", "categories": ["math.LO", "math.DS", "03E15, 22A22, 22F10"], "pdf": "https://arxiv.org/pdf/2507.04138", "abs": "https://arxiv.org/abs/2507.04138", "authors": ["Ruiyuan Chen"], "title": "Componentwise Polish groupoids and equivalence relations", "comment": "61 pages", "summary": "We study Borel equivalence relations equipped with a uniformly Borel family\nof Polish topologies on each equivalence class, and more generally, standard\nBorel groupoids equipped with such a family of topologies on each connected\ncomponent. Such \"componentwise Polish topologies\" capture precisely the\ntopological information determined by the Borel structure of a Polish group\naction, by the Becker--Kechris theorem. We prove that conversely, every\nabstract such Borel componentwise Polish groupoid obeying suitable axioms\nadmits a Borel equivalence of groupoids to a global open Polish groupoid.\nTogether with known results, this implies that every such groupoid is Borel\nequivalent to an action groupoid of a Polish group action; in particular, the\ninduced equivalence relations are Borel bireducible.\n  Our results are also valid for Borel groupoids with componentwise\nquasi-Polish topologies; and under stronger uniformity assumptions, we show\nthat such groupoids in fact themselves admit global quasi-Polish topologies. As\na byproduct, we also generalize several standard tools for Polish groups and\ntheir actions to the setting of componentwise quasi-Polish groupoids, including\nVaught transforms, Effros's theorem on orbits, and the open mapping theorem."}
{"id": "2507.03813", "categories": ["math.NT", "Primary 11B39, Secondary 11B83"], "pdf": "https://arxiv.org/pdf/2507.03813", "abs": "https://arxiv.org/abs/2507.03813", "authors": ["Ivan Hadinata"], "title": "Existence and Uniqueness Property On a Generalized Ledin-Brousseau Sum", "comment": "17 pages", "summary": "In this paper, we present the existence and uniqueness property on a finite\nsum involving a polynomial and a homogeneous linear recurrence sequence. This\nfinite sum is of the form $\\sum_{k=1}^n P(k)s_{hk+r}$ where $n$ is a positive\ninteger, $P(x)$ is a polynomial in $\\mathbb C[x]$, $h$ and $r$ are some\nintegers, and $(s_k)_{k\\in\\mathbb Z}$ is a homogeneous linear recurrence\nsequence of degree $m\\geq 2$ with some constraints."}
{"id": "2507.04983", "categories": ["math.ST", "math.PR", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.04983", "abs": "https://arxiv.org/abs/2507.04983", "authors": ["Nina Dörnemann", "Piotr Kokoszka", "Tim Kutta", "Sunmin Lee"], "title": "Monitoring for a Phase Transition in a Time Series of Wigner Matrices", "comment": null, "summary": "We develop methodology and theory for the detection of a phase transition in\na time-series of high-dimensional random matrices. In the model we study, at\neach time point \\( t = 1,2,\\ldots \\), we observe a deformed Wigner matrix \\(\n\\mathbf{M}_t \\), where the unobservable deformation represents a latent signal.\nThis signal is detectable only in the supercritical regime, and our objective\nis to detect the transition to this regime in real time, as new matrix--valued\nobservations arrive. Our approach is based on a partial sum process of extremal\neigenvalues of $\\mathbf{M}_t$, and its theoretical analysis combines\nstate-of-the-art tools from random-matrix-theory and Gaussian approximations.\nThe resulting detector is self-normalized, which ensures appropriate scaling\nfor convergence and a pivotal limit, without any additional parameter\nestimation. Simulations show excellent performance for varying dimensions.\nApplications to pollution monitoring and social interactions in primates\nillustrate the usefulness of our approach."}
{"id": "2507.03000", "categories": ["cs.CR", "cs.IT", "math.IT", "Primary 05A17, Secondary 11D45, 11Y60, 94A60", "F.2.1"], "pdf": "https://arxiv.org/pdf/2507.03000", "abs": "https://arxiv.org/abs/2507.03000", "authors": ["Michael A. Idowu"], "title": "Deterministic Cryptographic Seed Generation via Cyclic Modular Inversion over $\\mathbb{Z}/3^p\\mathbb{Z}$", "comment": "29 pages, 13 figures, 13 tables. Includes entropy analysis, symbolic\n  residue formulation, empirical validation, and benchmarking against\n  NIST-recommended DRBG frameworks", "summary": "We present a deterministic framework for cryptographic seed generation based\non cyclic modular inversion over $\\mathbb{Z}/3^p\\mathbb{Z}$. The method\nenforces algebraic admissibility on seed inputs via the identity $d_k \\equiv\n-\\left(2^{k-1}\\right)^{-1} \\bmod 3^p$, thereby producing structured and\ninvertible residue sequences. This mapping yields entropy-rich, cycle-complete\nseeds well-suited for cryptographic primitives such as DRBGs, KDFs, and\npost-quantum schemes. To assess the quality of randomness, we introduce the\nEntropy Confidence Score (ECS), a composite metric reflecting coverage,\nuniformity, and modular bias. Although not a cryptographic PRNG in itself, the\nframework serves as a deterministic entropy filter that conditions and\nvalidates seed inputs prior to their use by conventional generators. Empirical\nand hardware-based results confirm constant-time execution, minimal\nside-channel leakage, and lightweight feasibility for embedded applications.\nThe framework complements existing cryptographic stacks by acting as an\nalgebraically verifiable entropy filter, thereby enhancing structural soundness\nand auditability."}
{"id": "2507.03634", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.03634", "abs": "https://arxiv.org/abs/2507.03634", "authors": ["Alim Buğra Çınar", "Claudia Archetti", "Wout Dullaert", "Markus Leitner", "Stefan Waldherr"], "title": "Pricing, bundling, and driver behavior in crowdsourced delivery", "comment": null, "summary": "Challenges in last-mile delivery have encouraged innovative solutions like\ncrowdsourced delivery, where online platforms leverage the services of drivers\nwho occasionally perform delivery tasks for compensation. A key challenge is\nthat occasional drivers' acceptance behavior towards offered tasks is uncertain\nand influenced by task properties and compensation. The current literature\nlacks formulations that fully address this challenge. Hence, we formulate an\nintegrated problem that maximizes total expected cost savings by offering task\nbundles to occasional drivers. To this end, we simultaneously determine the\noptimal bundle set, their assignment to occasional drivers, and compensations\nfor each pair while considering acceptance probabilities, which are captured\nvia generic logistic functions. The vast number of potential bundles, combined\nwith incorporating acceptance probabilities leads to a mixed-integer nonlinear\nprogram (MINLP) with exponentially many variables. Using mild assumptions, we\naddress these complexities by exploiting properties of the problem, leading to\nan exact linearization of the MINLP which we solve via a tailored exact column\ngeneration algorithm. Our algorithm uses a variant of the elementary shortest\npath problem with resource constraints (ESPPRC) that features a non-linear and\nnon-additive objective function as its subproblem, for which we develop\ntailored dominance and pruning strategies. We introduce several heuristic and\nexact variants and perform an extensive set of experiments evaluating the\nalgorithm performances and solution structures. The results demonstrate the\nefficiency of the algorithms for instances with up to 120 tasks and 60 drivers\nand highlight the advantages of integrated decision-making over sequential\napproaches. The sensitivity analysis indicates that compensation is the most\ninfluential factor in shaping the bundle structure."}
{"id": "2507.03293", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.03293", "abs": "https://arxiv.org/abs/2507.03293", "authors": ["Anand Gokhale", "Vaibhav Srivastava", "Francesco Bullo"], "title": "LTLCrit: A Temporal Logic-based LLM Critic for Safe and Efficient Embodied Agents", "comment": null, "summary": "Large language models (LLMs) have demonstrated promise in reasoning tasks and\ngeneral decision-making in static environments. In long-term planning tasks,\nhowever, errors tend to accumulate, often leading to unsafe or inefficient\nbehavior, limiting their use in general-purpose settings. We propose a modular\nactor-critic architecture in which an LLM actor is guided by LTLCrit, a\ntrajectory-level LLM critic that communicates via linear temporal logic (LTL).\nOur setup combines the reasoning strengths of language models with the\nguarantees of formal logic. The actor selects high-level actions from natural\nlanguage observations, while the critic analyzes full trajectories and proposes\nnew LTL constraints that shield the actor from future unsafe or inefficient\nbehavior. The architecture supports both fixed, hand-specified safety\nconstraints and adaptive, learned soft constraints that promote long-term\nefficiency. Our architecture is model-agnostic: any LLM-based planner can serve\nas the actor, and LTLCrit serves as a logic-generating wrapper. We formalize\nplanning as graph traversal under symbolic constraints, allowing LTLCrit to\nanalyze failed or suboptimal trajectories and generate new temporal logic rules\nthat improve future behavior. We evaluate our system on the Minecraft\ndiamond-mining benchmark, achieving 100% completion rates and improving\nefficiency compared to baseline LLM planners. Our results suggest that enabling\nLLMs to supervise each other through logic is a powerful and flexible paradigm\nfor safe, generalizable decision making."}
{"id": "2507.03661", "categories": ["math.CO", "math.AG", "14M25, 14N25, 52B20, 14C17, 05E45, 14M10"], "pdf": "https://arxiv.org/pdf/2507.03661", "abs": "https://arxiv.org/abs/2507.03661", "authors": ["Fedor Selyanin"], "title": "Newton numbers, vanishing polytopes and algebraic degrees", "comment": "40 pages, 1 figure. arXiv admin note: text overlap with\n  arXiv:1411.7736 by other authors", "summary": "Consider a polynomial $f$ with a convenient Newton polytope $P$ and generic\ncomplex coefficients. By the global version of the Kouchnirenko formula, the\nhypersurface $\\{f = 0\\} \\subset \\mathbb C^n$ has the homotopy type of a bouquet\nof $(n-1)$-spheres, and the number of spheres is given by a certain alternating\nsum of volumes, called the Newton number $\\nu(P)$. Using the Furukawa-Ito\nclassification of dual defective sets, we classify convenient Newton polytopes\nwith vanishing Newton numbers as certain Cayley sums called $B_k$-polytopes.\nThese $B_k$-polytopes generalize the $B_1$- and $B_2$-facets appearing in the\nlocal monodromy conjecture in the Newton non-degenerate case. Our\nclassification provides a partial solution to the Arnold's monotonicity\nproblem.\n  The local $h^*$-polynomial (or $\\ell^*$-polynomial) is a natural invariant of\nlattice polytopes that refines the $h^*$-polynomial coming from Ehrhart theory.\nWe obtain decomposition formulas for the Newton number, for instance, prove the\ninequality $\\nu(P) \\ge \\ell^*(P;1)$. The $B_k$-polytopes are non-trivial\nexamples of thin polytopes.\n  We generalize the Newton number in two independent ways: the $\\ell$-Newton\nnumber and the $e$-Newton number. The $\\ell$-Newton number comes from Ehrhart\ntheory, namely, from certain generalizations of Katz-Stapledon decomposition\nformulas. It is the main ingredient in the proof of the thinness of the\n$B_k$-polytopes. The $e$-Newton number is the number of points of\nzero-dimensional critical complete intersections. Vanishing of the $e$-Newton\nnumber characterizes the dual defective sets. The $e$-Newton number calculates\nthe algebraic degrees (Maximum Likelihood, Euclidean Distance, and Polar\ndegrees). For instance, we show that all the known formulas for the algebraic\ndegrees in the Newton non-degenerate case are implied by basic properties of\nthe $e$-Newton number."}
{"id": "2507.04312", "categories": ["math.LO", "03B60, 60A99"], "pdf": "https://arxiv.org/pdf/2507.04312", "abs": "https://arxiv.org/abs/2507.04312", "authors": ["Sankha S. Basu", "Esha Jain"], "title": "Paracomplete Probabilities", "comment": "18 pages. The final version of this article has been submitted for\n  publication", "summary": "This paper presents an advance in the direction of working with probabilities\nin a paracomplete setting using Logics of Formal Undeterminedness (LFUs). The\nundeterminedness is interpreted here as missing evidence. A theorem of total\nparacomplete probability and a paracomplete Bayes' rule have been proved using\nthis setup. We end with a definition of a paracomplete probability space\nillustrating a way to define probabilities on sets in the presence of\nundeterminedness."}
{"id": "2507.03824", "categories": ["math.NT", "11F37, 11F99, 33D15, 33D70, 33D99"], "pdf": "https://arxiv.org/pdf/2507.03824", "abs": "https://arxiv.org/abs/2507.03824", "authors": ["Amanda Folsom", "David Metacarpa"], "title": "Antiquantum $q$-series and mock theta functions", "comment": "14 pages", "summary": "Ramanujan's original definition of mock theta functions from 1920 involves\ntheir asymptotic behaviors at roots of unity on the boundary of the disk of\nconvergence $|q|<1$. More recently this topic has been related by several\nauthors, including the first author with Ono and Rhoades in 2013, to quantum\nmodular forms, first defined in 2010 by Zagier. In 2021, Lovejoy defined and\nstudied related quantum $q$-series identities, which do not hold as equalities\nbetween power series inside the disk $|q|<1$ but which do hold on dense subsets\nof roots of unity on the boundary. Inspired by this, in our prior joint work\nfrom 2024 we further studied quantum $q$-series identities as related to mock\ntheta functions and quantum modular forms; we also defined and studied\nantiquantum $q$-series identities, between series which are equal inside the\ndisk $|q|<1$ but which hold at dense sets of roots of unity on the boundary for\nwhich one of the series diverges and is unnaturally truncated. Here, building\nfrom our previous work, we establish antiquantum $q$-series identities for all\nof Ramanujan's third order mock theta functions. We deduce these results in\npart by establishing and applying more general identities which are also of\nindependent interest, and by using the theory of modular eta-quotients."}
{"id": "2507.05074", "categories": ["math.ST", "math.PR", "stat.TH", "60G60, 60F05, 42C10"], "pdf": "https://arxiv.org/pdf/2507.05074", "abs": "https://arxiv.org/abs/2507.05074", "authors": ["Claudio Durastanti"], "title": "Gaussian approximation for non-linearity parameter estimation in perturbed random fields on the sphere", "comment": "34 pages", "summary": "The nonlinear parameter measures the amplitude of primordial non-Gaussianity\nin the cosmic microwave background radiation (CMB), offering a crucial test of\nearly universe models. While standard single field inflation predicts nearly\nGaussian fluctuations, more complex scenarios yield subtle non Gaussian\nsignals, particularly captured by the CMB bispectrum. In the local model, these\nsignals arise through a quadratic correction to a Gaussian field. To estimate\nthe nonlinear parameter, we adopt a Komatsu Spergel Wandelt (KSW) type\nestimator, based on spherical harmonics and Wigner 3j symbols, and adapted to\nnarrow band configurations that depend on the range of multipoles considered.\nIn this paper, we rigorously study its asymptotic properties by applying\nfourth-moment theorems from Wiener chaos theory. More in detail, we establish a\nquantitative central limit theorem for the KSW estimator, with an explicit\nconvergence rate controlled by number of admissible multipoles. Our results\nestablish both theoretical guarantees and practical robustness for high\nresolution CMB analyses."}
{"id": "2507.03014", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03014", "abs": "https://arxiv.org/abs/2507.03014", "authors": ["Do-hyeon Yoon", "Minsoo Chun", "Thomas Allen", "Hans Müller", "Min Wang", "Rajesh Sharma"], "title": "Intrinsic Fingerprint of LLMs: Continue Training is NOT All You Need to Steal A Model!", "comment": "This paper flags a potential case of model plagiarism, copyright\n  violation, and information fabrication in arXiv:2505.21411", "summary": "Large language models (LLMs) face significant copyright and intellectual\nproperty challenges as the cost of training increases and model reuse becomes\nprevalent. While watermarking techniques have been proposed to protect model\nownership, they may not be robust to continue training and development, posing\nserious threats to model attribution and copyright protection. This work\nintroduces a simple yet effective approach for robust LLM fingerprinting based\non intrinsic model characteristics. We discover that the standard deviation\ndistributions of attention parameter matrices across different layers exhibit\ndistinctive patterns that remain stable even after extensive continued\ntraining. These parameter distribution signatures serve as robust fingerprints\nthat can reliably identify model lineage and detect potential copyright\ninfringement. Our experimental validation across multiple model families\ndemonstrates the effectiveness of our method for model authentication. Notably,\nour investigation uncovers evidence that a recently Pangu Pro MoE model\nreleased by Huawei is derived from Qwen-2.5 14B model through upcycling\ntechniques rather than training from scratch, highlighting potential cases of\nmodel plagiarism, copyright violation, and information fabrication. These\nfindings underscore the critical importance of developing robust fingerprinting\nmethods for protecting intellectual property in large-scale model development\nand emphasize that deliberate continued training alone is insufficient to\ncompletely obscure model origins."}
{"id": "2507.03669", "categories": ["math.OC", "stat.ME"], "pdf": "https://arxiv.org/pdf/2507.03669", "abs": "https://arxiv.org/abs/2507.03669", "authors": ["Andrew D. Lipnick", "Esteban G. Tabak", "Giulio Trigila", "Yating Wang", "Xuancheng Ye", "Wenjun Zhao"], "title": "The Monge optimal transport barycenter problem", "comment": "36 pages, 19 figures", "summary": "A novel methodology is developed for the solution of the data-driven Monge\noptimal transport barycenter problem, where the pushforward condition is\nformulated in terms of the statistical independence between two sets of random\nvariables: the factors $z$ and a transformed outcome $y$. Relaxing independence\nto the uncorrelation between all functions of $z$ and $y$ within suitable\nfinite-dimensional spaces leads to an adversarial formulation, for which the\nadversarial strategy can be found in closed form through the first principal\ncomponents of a small-dimensional matrix. The resulting pure minimization\nproblem can be solved very efficiently through gradient descent driven flows in\nphase space. The methodology extends beyond scenarios where only discrete\nfactors affect the outcome, to multivariate sets of both discrete and\ncontinuous factors, for which the corresponding barycenter problems have\ninfinitely many marginals. Corollaries include a new framework for the solution\nof the Monge optimal transport problem, a procedure for the data-based\nsimulation and estimation of conditional probability densities, and a\nnonparametric methodology for Bayesian inference."}
{"id": "2507.03329", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03329", "abs": "https://arxiv.org/abs/2507.03329", "authors": ["Devendra Patel", "Aaditya Jain", "Jayant Verma", "Divyansh Rajput", "Sunil Mahala", "Ketki Suresh Khapare", "Jayateja Kalla"], "title": "NDAI-NeuroMAP: A Neuroscience-Specific Embedding Model for Domain-Specific Retrieval", "comment": "The document consists of 15 pages in total: the first 13 pages\n  comprise the main paper, while the last two pages contain supplementary\n  material", "summary": "We present NDAI-NeuroMAP, the first neuroscience-domain-specific dense vector\nembedding model engineered for high-precision information retrieval tasks. Our\nmethodology encompasses the curation of an extensive domain-specific training\ncorpus comprising 500,000 carefully constructed triplets\n(query-positive-negative configurations), augmented with 250,000\nneuroscience-specific definitional entries and 250,000 structured\nknowledge-graph triplets derived from authoritative neurological ontologies. We\nemploy a sophisticated fine-tuning approach utilizing the\nFremyCompany/BioLORD-2023 foundation model, implementing a multi-objective\noptimization framework combining contrastive learning with triplet-based metric\nlearning paradigms. Comprehensive evaluation on a held-out test dataset\ncomprising approximately 24,000 neuroscience-specific queries demonstrates\nsubstantial performance improvements over state-of-the-art general-purpose and\nbiomedical embedding models. These empirical findings underscore the critical\nimportance of domain-specific embedding architectures for neuroscience-oriented\nRAG systems and related clinical natural language processing applications."}
{"id": "2507.03676", "categories": ["math.CO", "05D40, 05C60, 05C80"], "pdf": "https://arxiv.org/pdf/2507.03676", "abs": "https://arxiv.org/abs/2507.03676", "authors": ["Peter Allen", "Julia Böttcher", "Yoshiharu Kohayakawa", "Mihir Neve"], "title": "Robustness of the Sauer-Spencer Theorem", "comment": "28 pages, no figures", "summary": "We prove a robust version of a graph embedding theorem of Sauer and Spencer.\nTo state this sparser analogue, we define $G(p)$ to be a random subgraph of $G$\nobtained by retaining each edge of $G$ independently with probability $p \\in\n[0,1]$, and let $m_1(H)$ be the maximum $1$-density of a graph $H$. We show\nthat for any constant $\\Delta$ and $\\gamma > 0$, if $G$ is an $n$-vertex host\ngraph with minimum degree $\\delta(G) \\geq (1 - 1/2\\Delta + \\gamma)n$ and $H$ is\nan $n$-vertex graph with maximum degree $\\Delta(H) \\leq \\Delta$, then for $p\n\\geq Cn^{-1/m_1(H)}\\log n$, the random subgraph $G(p)$ contains a copy of $H$\nwith high probability. Our value for $p$ is optimal up to a log-factor.\n  In fact, we prove this result for a more general minimum degree condition on\n$G$, by introducing an \\emph{extension threshold} $\\delta_{\\rm e}(\\Delta)$,\nsuch that the above result holds for graphs $G$ with ${\\delta(G) \\geq\n(\\delta_{\\rm e}(\\Delta) + \\gamma)n}$. We show that $\\delta_{\\rm e}(\\Delta) \\leq\n(2\\Delta-1)/2\\Delta$, and further conjecture that $\\delta_{\\rm e}(\\Delta)$\nequals $\\Delta/(\\Delta+1)$, which matches the minimum degree condition on $G$\nin the Bollob\\'as-Eldridge-Catlin Conjecture. A main tool in our proof is a\nvertex-spread version of the blow-up lemma of Allen, B\\\"{o}ttcher, H\\`{a}n,\nKohayakawa, and Person, which we believe to be of independent interest."}
{"id": "2507.04526", "categories": ["math.LO", "math.CT", "03G30 (Primary) 18F10, 18B25, 03C50 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.04526", "abs": "https://arxiv.org/abs/2507.04526", "authors": ["Joshua Wrigley"], "title": "On the theories classified by an étendue", "comment": "13 pages", "summary": "We give a model-theoretic characterisation of the geometric theories\nclassified by \\'etendues -- the `locally localic' topoi. They are the theories\nwhere each model is determined, syntactically and semantically, by any witness\nof a fixed collection of formulae."}
{"id": "2507.04113", "categories": ["math.NT", "11M38 (Primary), 11G09, 11G15, 11R60 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.04113", "abs": "https://arxiv.org/abs/2507.04113", "authors": ["Erik Davis", "Matthew Papanikolas"], "title": "Hecke $L$-series for Sinha modules", "comment": "63 pages", "summary": "We investigate Goss $L$-functions associated to Anderson $t$-modules defined\nby Sinha having complex multiplication by Carlitz cyclotomic fields. We show\nthat these $t$-modules are defined over the cyclotomic field and that their\n$L$-functions are products of Hecke $L$-series for Anderson's Hecke character\ndefined via Coleman functions. Applying identities of Fang and Taelman, we\nprove that special values of these $L$-functions are expressible in terms of\nproducts of values of Thakur's geometric $\\Gamma$-function."}
{"id": "2507.05075", "categories": ["math.ST", "cs.NA", "math.NA", "stat.TH", "42C40, 60G60"], "pdf": "https://arxiv.org/pdf/2507.05075", "abs": "https://arxiv.org/abs/2507.05075", "authors": ["Claudio Durastanti"], "title": "Scale Dilation Dynamics in Flexible Bandwidth Needlet Constructions", "comment": "45 pages, 1 Table, 4 Figures", "summary": "Flexible bandwidth needlets offer a versatile multiscale framework for\nanalyzing functions on the sphere. A key element in their construction is the\ndilation sequence, which controls how the multipole consecutive scales are\nspaced and overlapped. At any resolution level, this sequence determines the\ncenter positions of the needlet weight functions and influences their\nlocalization in the spatial domain and spectral concentration properties by\nmeans of the relative bandwidth ratio. In this paper, we explore the different\nasymptotic regimes that arise when the dilation sequence exhibits shrinking,\nstable (standard), or spreading behavior. Moreover, we assume the dilation\nsequence grows regularly enough to ensure well-defined asymptotic properties.\nFor each regime, we characterize the impact on the geometry of the center\nscales and the shape of the multipole windows, with particular attention to\ntheir overlap structure and spectral coverage. These insights help to clarify\nthe trade-offs between localization, redundancy, and scalability in the design\nof needlet-type systems, particularly in relation to the study of the\nasymptotic uncorrelation of needlet coefficients when applied to random fields."}
{"id": "2507.03021", "categories": ["cs.CR", "cs.GT"], "pdf": "https://arxiv.org/pdf/2507.03021", "abs": "https://arxiv.org/abs/2507.03021", "authors": ["Ya-Ting Yang", "Quanyan Zhu"], "title": "A Multi-Resolution Dynamic Game Framework for Cross-Echelon Decision-Making in Cyber Warfare", "comment": null, "summary": "Cyber warfare has become a critical dimension of modern conflict, driven by\nsociety's increasing dependence on interconnected digital and physical\ninfrastructure. Effective cyber defense often requires decision-making at\ndifferent echelons, where the tactical layer focuses on detailed actions such\nas techniques, tactics, and procedures, while the strategic layer addresses\nlong-term objectives and coordinated planning. Modeling these interactions at\ndifferent echelons remains challenging due to the dynamic, large-scale, and\ninterdependent nature of cyber environments. To address this, we propose a\nmulti-resolution dynamic game framework in which the tactical layer captures\nfine-grained interactions using high-resolution extensive-form game trees,\nwhile the strategic layer is modeled as a Markov game defined over\nlower-resolution states abstracted from those game trees. This framework\nsupports scalable reasoning and planning across different levels of abstraction\nthrough zoom-in and zoom-out operations that adjust the granularity of the\nmodeling based on operational needs. A case study demonstrates how the\nframework works and its effectiveness in improving the defender's strategic\nadvantage."}
{"id": "2507.04133", "categories": ["math.OC", "cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.04133", "abs": "https://arxiv.org/abs/2507.04133", "authors": ["Harsh Shah", "Purna Chandrasekhar", "Rahul Vaze"], "title": "Online Convex Optimization with Switching Cost with Only One Single Gradient Evaluation", "comment": "9 pages, 2 figures", "summary": "Online convex optimization with switching cost is considered under the frugal\ninformation setting where at time $t$, before action $x_t$ is taken, only a\nsingle function evaluation and a single gradient is available at the previously\nchosen action $x_{t-1}$ for either the current cost function $f_t$ or the most\nrecent cost function $f_{t-1}$. When the switching cost is linear, online\nalgorithms with optimal order-wise competitive ratios are derived for the\nfrugal setting. When the gradient information is noisy, an online algorithm\nwhose competitive ratio grows quadratically with the noise magnitude is\nderived."}
{"id": "2507.03330", "categories": ["cs.AI", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.03330", "abs": "https://arxiv.org/abs/2507.03330", "authors": ["Franklin Mingzhe Li", "Kaitlyn Ng", "Bin Zhu", "Patrick Carrington"], "title": "Exploring Object Status Recognition for Recipe Progress Tracking in Non-Visual Cooking", "comment": "ASSETS 2025", "summary": "Cooking plays a vital role in everyday independence and well-being, yet\nremains challenging for people with vision impairments due to limited support\nfor tracking progress and receiving contextual feedback. Object status - the\ncondition or transformation of ingredients and tools - offers a promising but\nunderexplored foundation for context-aware cooking support. In this paper, we\npresent OSCAR (Object Status Context Awareness for Recipes), a technical\npipeline that explores the use of object status recognition to enable recipe\nprogress tracking in non-visual cooking. OSCAR integrates recipe parsing,\nobject status extraction, visual alignment with cooking steps, and time-causal\nmodeling to support real-time step tracking. We evaluate OSCAR on 173\ninstructional videos and a real-world dataset of 12 non-visual cooking sessions\nrecorded by BLV individuals in their homes. Our results show that object status\nconsistently improves step prediction accuracy across vision-language models,\nand reveal key factors that impact performance in real-world conditions, such\nas implicit tasks, camera placement, and lighting. We contribute the pipeline\nof context-aware recipe progress tracking, an annotated real-world non-visual\ncooking dataset, and design insights to guide future context-aware assistive\ncooking systems."}
{"id": "2507.03800", "categories": ["math.CO", "cs.NA", "math.AG", "math.NA", "math.OC", "05A05, 05A15, 05A20 (Primary), 06A07, 65H04, 41A10, 41A45, 41A60,\n  90C23 (Secondary)", "G.2.1; G.1.2; G.1.3; G.1.5; G.1.6"], "pdf": "https://arxiv.org/pdf/2507.03800", "abs": "https://arxiv.org/abs/2507.03800", "authors": ["Alejandro González Nevado"], "title": "Spectrahedral relaxations of Eulerian rigidly convex sets", "comment": "75 pages. Preprint extracted from a selection, rewrite and\n  recombination of several sections and chapters from my PhD thesis. For more\n  possible lines of research in these related directions, we direct the\n  interested reader to arXiv:2503.04628", "summary": "We study a generalization of Eulerian polynomials to the multivariate setting\nintroduced by Br\\\"and\\'en. Although initially these polynomials were introduced\nusing the language of hyperbolic and stable polynomials, we manage to translate\nsome restrictions of these polynomials to our real zero setting. Once we are in\nthis setting, we focus our attention on the rigidly convex sets (RCSs) defined\nby these polynomials. In particular, we study the corresponding rigidly convex\nsets looking at spectrahedral relaxations constructed through the use of monic\nsymmetric linear matrix polynomials (MSLMPs) of small size and depending\npolynomially (actually just cubically) on the coefficients of the corresponding\npolynomials. We analyze how good are the obtained spectrahedral approximations\nto these rigidly convex sets. We do this analysis by measuring the behavior\nalong the diagonal, where we precisely recover the original univariate Eulerian\npolynomials. Thus we conclude that, measuring through the diagonal, our\nrelaxation-based spectrahedral method for approximation of the rigidly convex\nsets defined by multivariate Eulerian polynomials is highly accurate. In\nparticular, we see that this relaxation-based spectrahedral method for\napproximation of the rigidly convex sets defined by multivariate Eulerian\npolynomials provides bounds for the extreme roots of the corresponding\nunivariate Eulerian polynomials that are better than these already found in the\nliterature. All in all, this tells us that, at least close to the diagonal, the\nglobal outer approximation to the rigidly convex sets provided by this\nrelaxation-based spectrahedral method is itself highly accurate."}
{"id": "2507.04533", "categories": ["math.LO", "03B44, 03B45"], "pdf": "https://arxiv.org/pdf/2507.04533", "abs": "https://arxiv.org/abs/2507.04533", "authors": ["Qian Chen"], "title": "Degree of Kripke-incompleteness of Tense Logics", "comment": "22 pages, 3 figures", "summary": "The degree of Kripke-incompleteness of a logic $L$ in some lattice\n$\\mathcal{L}$ of logics is the cardinality of logics in $\\mathcal{L}$ which\nshare the same class of Kripke-frames with $L$. A celebrated result on\nKripke-incompleteness is Blok's dichotomy theorem for the degree of\nKripke-incompleteness in $\\mathsf{NExt}(\\mathsf{K})$: every modal logic\n$L\\in\\mathsf{NExt}(\\mathsf{K})$ is of the degree of Kripke-incompleteness $1$\nor $2^{\\aleph_0}$. In this work, we show that the dichotomy theorem for\n$\\mathsf{NExt}(\\mathsf{K})$ can be generalized to the lattices $\\K$, $\\LT$ and\n$\\NExt(\\ST)$ of tense logics. We also prove that in $\\K$, $\\LT$ and\n$\\NExt(\\ST)$, iterated splittings are exactly the strictly Kripke-complete\nlogics."}
{"id": "2507.04122", "categories": ["math.NT", "math.AG", "math.RT"], "pdf": "https://arxiv.org/pdf/2507.04122", "abs": "https://arxiv.org/abs/2507.04122", "authors": ["Yachen Liu"], "title": "The cohomology of certain intermediate strata of Kottwitz varieties", "comment": null, "summary": "We derive explicit formulas for the Frobenius-Hecke traces of the etale\ncohomology of certain strata of Kottwitz varieties (which are certain compact\nunitary type Shimura varieties considered by Kottwitz), in terms of automorphic\nrepresentations and certain explicit polynomials. We obtain our results using\nthe trace formula, representations of general linear groups over p-adic fields,\nand a truncation of the formula of Kottwitz for the number of points on Shimura\nvarieties over finite fields."}
{"id": "2507.03051", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.03051", "abs": "https://arxiv.org/abs/2507.03051", "authors": ["Marco Simoni", "Aleksandar Fontana", "Giulio Rossolini", "Andrea Saracino"], "title": "Improving LLM Reasoning for Vulnerability Detection via Group Relative Policy Optimization", "comment": "Under Review", "summary": "Improving and understanding the training dynamics and reasoning of Large\nLanguage Models (LLMs) has become essential for their deployment in AI-based\nsecurity tools, such as software vulnerability detection. In this work, we\npresent an extensive study aimed at advancing recent RL-based finetuning\ntechniques for LLMs in the context of vulnerability detection.\n  We start by highlighting key limitations of commonly adopted LLMs, such as\ntheir tendency to over-predict certain types of vulnerabilities while failing\nto detect others. To address this challenge, we explore the use of Group\nRelative Policy Optimization (GRPO), a recent policy-gradient method, for\nguiding LLM behavior through structured, rule-based rewards. We enable its\napplication to the vulnerability detection task by redefining its advantage\nfunctions and reward signals using annotations from widely used datasets in the\nfield, including BigVul, DiverseVul, and CleanVul.\n  The proposed methodology enables an extensive set of experiments, addressing\nmultiple research questions regarding the impact of GRPO on generalization,\nreasoning capabilities, and performance improvements over standard supervised\nfinetuning (SFT). Our findings offer valuable insights into the potential of\nRL-based training to enhance both the performance and reasoning abilities of\nLLMs in the context of software vulnerability detection."}
{"id": "2507.04135", "categories": ["math.OC", "math.AP", "math.DS"], "pdf": "https://arxiv.org/pdf/2507.04135", "abs": "https://arxiv.org/abs/2507.04135", "authors": ["Stephan Gerster", "Giuseppe Visconti"], "title": "Relaxation and stability analysis of a third-order multiclass traffic flow model", "comment": null, "summary": "Traffic flow modeling spans a wide range of mathematical approaches, from\nmicroscopic descriptions of individual vehicle dynamics to macroscopic models\nbased on aggregate quantities. A fundamental challenge in macroscopic modeling\nlies in the closure relations, particularly in the specification of a traffic\nhesitation function in second-order models like Aw-Rascle-Zhang. In this work,\nwe propose a third-order hyperbolic traffic model in which the hesitation\nevolves as a driver-dependent dynamic quantity. Starting from a microscopic\nformulation, we relax the standard assumption by introducing an evolution law\nfor the hesitation. This extension allows to incorporate hysteresis effects,\nmodeling the fact that drivers respond differently when accelerating or\ndecelerating, even under identical local traffic conditions. Furthermore,\nvarious relaxation terms are introduced. These allow us to establish relations\nto the Aw-Rascle-Zhang model and other traffic flow models."}
{"id": "2507.03336", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03336", "abs": "https://arxiv.org/abs/2507.03336", "authors": ["Ashutosh Hathidara", "Julien Yu", "Sebastian Schreiber"], "title": "Disambiguation-Centric Finetuning Makes Enterprise Tool-Calling LLMs More Realistic and Less Risky", "comment": null, "summary": "Large language models (LLMs) are increasingly tasked with invoking enterprise\nAPIs, yet they routinely falter when near-duplicate tools vie for the same user\nintent or when required arguments are left underspecified. We introduce\nDiaFORGE (Dialogue Framework for Organic Response Generation & Evaluation), a\ndisambiguation-centric, three-stage pipeline that (i) synthesizes\npersona-driven, multi-turn dialogues in which the assistant must distinguish\namong highly similar tools, (ii) performs supervised fine-tuning of open-source\nmodels with reasoning traces across 3B - 70B parameters, and (iii) evaluates\nreal-world readiness via a dynamic suite that redeploys each model in a live\nagentic loop and reports end-to-end goal completion alongside conventional\nstatic metrics. On our dynamic benchmark DiaBENCH, models trained with DiaFORGE\nraise tool-invocation success by 27 pp over GPT-4o and by 49 pp over\nClaude-3.5-Sonnet, both under optimized prompting. To spur further research, we\nrelease an open corpus of 5000 production-grade enterprise API specifications\npaired with rigorously validated, disambiguation-focused dialogues, offering a\npractical blueprint for building reliable, enterprise-ready tool-calling\nagents."}
{"id": "2507.03841", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.03841", "abs": "https://arxiv.org/abs/2507.03841", "authors": ["Pablo Blanco", "Doron Zeilberger"], "title": "Automated Counting of Spanning Trees for Several Infinite Families of Graphs", "comment": null, "summary": "Using the theoretical basis developed by Yao and Zeilberger, we consider\ncertain graph families whose structure results in a rational generating\nfunction for sequences related to spanning tree enumeration. Said families are\nPowers of Cycles and Powers of Path; later, we briefly discuss Torus graphs and\nGrid graphs. In each case we know, a priori, that the set of spanning trees of\nthe family of graphs can be described in terms of a finite-state-machine, and\nhence there is a finite transfer-matrix that guarantees the generating function\nis rational. Finding this ``grammar'', and hence the transfer-matrix is very\ntedious, so a much more efficient approach is to use experimental mathematics.\nSince computing numerical determinants is so fast, one can use the matrix tree\ntheorem to generate sufficiently many terms, then fit the data to a rational\nfunction. The whole procedure can be done rigorously a posteriori."}
{"id": "2507.05028", "categories": ["math.LO", "cs.LO", "03F50, 03F60"], "pdf": "https://arxiv.org/pdf/2507.05028", "abs": "https://arxiv.org/abs/2507.05028", "authors": ["Cécilia Pradic"], "title": "The Myhill isomorphism theorem does not generalize much", "comment": "25 pages, 6 figures, draft", "summary": "The Myhill isomorphism is a variant of the Cantor-Bernstein theorem. It\nstates that, from two injections that reduces two subsets of $\\mathbb{N}$ to\neach other, there exists a bijection $\\mathbb{N} \\to \\mathbb{N}$ that preserves\nthem. This theorem can be proven constructively. We investigate to which extent\nthe theorem can be extended to other infinite sets other than $\\mathbb{N}$. We\nshow that, assuming Markov's principle, the theorem can be extended to the\nconatural numbers $\\mathbb{N}_{\\infty}$ provided that we only require that\nbicomplemented sets are preserved by the bijection. This restriction is\nessential. Otherwise, the picture is overall negative: among other things, it\nis impossible to extend that result to either $2 \\times \\mathbb{N}_{\\infty}$,\n$\\mathbb{N} + \\mathbb{N}_{\\infty}$, $\\mathbb{N} \\times \\mathbb{N}_{\\infty}$,\n$\\mathbb{N}_{\\infty}^2$, $2^{\\mathbb{N}}$ or $\\mathbb{N}^{\\mathbb{N}}$."}
{"id": "2507.04150", "categories": ["math.NT", "Primary 11M06, Secondary 11M26"], "pdf": "https://arxiv.org/pdf/2507.04150", "abs": "https://arxiv.org/abs/2507.04150", "authors": ["Alessandro Fazzari", "Maxim Gerspach", "Paolo Minelli"], "title": "Selberg's Central Limit Theorem weighted by Linear Statistics of Zeta Zeros", "comment": "16 pages", "summary": "We consider the value distribution of the logarithm of the Riemann zeta\nfunction on the critical line, weighted by the local statistics of zeta zeros.\nWe show that, with appropriate normalization, it satisfies a complex Central\nLimit Theorem, provided that the Fourier support of the test function in the\nlinear statistics is sufficiently small. For the imaginary part, we extend this\nsupport condition up to its natural barrier under the Riemann Hypothesis.\nFinally, we prove that the correlation between $\\log \\zeta$ and the one-level\ndensity, while negligible on the level of Selberg's Central Limit Theorem, only\ndecays at a rather slow rate if the Riemann Hypothesis is assumed. Our results\ncan be viewed as a combination of Selberg's Central Limit Theorem with work of\nHughes and Rudnick on mock-Gaussian behavior of the local statistics."}
{"id": "2507.03064", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03064", "abs": "https://arxiv.org/abs/2507.03064", "authors": ["Hetvi Shastri", "Walid A. Hanafy", "Li Wu", "David Irwin", "Mani Srivastava", "Prashant Shenoy"], "title": "LLM-Driven Auto Configuration for Transient IoT Device Collaboration", "comment": null, "summary": "Today's Internet of Things (IoT) has evolved from simple sensing and\nactuation devices to those with embedded processing and intelligent services,\nenabling rich collaborations between users and their devices. However, enabling\nsuch collaboration becomes challenging when transient devices need to interact\nwith host devices in temporarily visited environments. In such cases,\nfine-grained access control policies are necessary to ensure secure\ninteractions; however, manually implementing them is often impractical for\nnon-expert users. Moreover, at run-time, the system must automatically\nconfigure the devices and enforce such fine-grained access control rules.\nAdditionally, the system must address the heterogeneity of devices.\n  In this paper, we present CollabIoT, a system that enables secure and\nseamless device collaboration in transient IoT environments. CollabIoT employs\na Large language Model (LLM)-driven approach to convert users' high-level\nintents to fine-grained access control policies. To support secure and seamless\ndevice collaboration, CollabIoT adopts capability-based access control for\nauthorization and uses lightweight proxies for policy enforcement, providing\nhardware-independent abstractions.\n  We implement a prototype of CollabIoT's policy generation and auto\nconfiguration pipelines and evaluate its efficacy on an IoT testbed and in\nlarge-scale emulated environments. We show that our LLM-based policy generation\npipeline is able to generate functional and correct policies with 100%\naccuracy. At runtime, our evaluation shows that our system configures new\ndevices in ~150 ms, and our proxy-based data plane incurs network overheads of\nup to 2 ms and access control overheads up to 0.3 ms."}
{"id": "2507.04188", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.04188", "abs": "https://arxiv.org/abs/2507.04188", "authors": ["Brian Brown", "Michael King"], "title": "Gramians for a New Class of Nonlinear Control Systems Using Koopman and a Novel Generalized SVD", "comment": null, "summary": "Model reduction with error bounds in nonlinear systems with non-affine\ncontrol inputs remains an active field of research. In this work we present a\nconstruction for Controllability and Observability Gramians in a class of\nnon-affine control input systems satisfying certain induced norm properties. We\ndo so using a combination of representational forms, including a novel function\ndecomposition that resembles linear Singular Value Decomposition (SVD), in\ntandem with an additional unconventional decomposition of the dynamics, and\nKoopman operator theory. The resulting representation allows one to place error\nbounds on the $H_{\\infty}$ norm on a reduced-order representation of the system\ncomputed using finite-dimensional nonlinear Controllability and Observability\nGramians."}
{"id": "2507.03347", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03347", "abs": "https://arxiv.org/abs/2507.03347", "authors": ["Sachith Gunasekara", "Yasiru Ratnayake"], "title": "Effects of structure on reasoning in instance-level Self-Discover", "comment": null, "summary": "The drive for predictable LLM reasoning in their integration with compound\nsystems has popularized structured outputs, yet concerns remain about\nperformance trade-offs compared to unconstrained natural language. At the same\ntime, training on unconstrained Chain of Thought (CoT) traces has brought about\na new class of strong reasoning models that nevertheless present novel compute\nbudget and faithfulness challenges. This paper introduces iSelf-Discover, an\ninstance-level adaptation of the Self-Discover framework, and using it compares\ndynamically generated structured JSON reasoning with its unstructured\ncounterpart. Our empirical evaluation across diverse benchmarks using\nstate-of-the-art open-source models supports a consistent advantage for\nunstructured reasoning. Notably, on the complex MATH benchmark, unstructured\nplans achieved relative performance improvements of up to 18.90\\% over\nstructured approaches. Zero-shot unstructured iSelf-Discover variants are also\nshown to outperform their five-shot structured counterparts, underscoring the\nsignificance of this gap, even when structured plans are dynamically generated\nto ensure reasoning precedes the final answer. We further demonstrate that the\noptimal granularity of plan generation (instance-level vs. task-level) is\ncontext-dependent. These findings invite re-evaluation of the reliance on\nstructured formats for complex problem-solving and how compound systems should\nbe organized."}
{"id": "2507.03926", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.03926", "abs": "https://arxiv.org/abs/2507.03926", "authors": ["Taizo Sadahiro"], "title": "Hamiltonicity of toroidal 5-puzzle", "comment": null, "summary": "We construct an explicit Hamiltonian cycle in the state graph of the 5-puzzle\non a toroidal 2x 3 grid, a graph with 720 vertices. The cycle is described by a\nshort symbolic sequence of 48 moves over the alphabet {L,R,V}, repeated $15$\ntimes, which can be verified directly. We also find a shorter 24-move sequence\nwhose repetition yields a 2-cycle cover, which can be spliced into a\nHamiltonian path. These constructions arise naturally from a general method:\nlifting Hamiltonian cycles from a quotient graph under the action of the\npuzzle's symmetry group.\n  The method produces compact, human-readable cycle encodings and appears\neffective in broader settings, suggesting a combinatorial grammar underlying\nHamiltonian paths in symmetric configuration spaces."}
{"id": "2507.05219", "categories": ["math.LO", "cs.CL", "cs.LO", "03B70, 03B65, 03B45"], "pdf": "https://arxiv.org/pdf/2507.05219", "abs": "https://arxiv.org/abs/2507.05219", "authors": ["Johan van Benthem", "Thomas Icard"], "title": "Interleaving Logic and Counting", "comment": null, "summary": "Reasoning with quantifier expressions in natural language combines logical\nand arithmetical features, transcending strict divides between qualitative and\nquantitative. Our topic is this cooperation of styles as it occurs in common\nlinguistic usage and its extension into the broader practice of natural\nlanguage plus \"grassroots mathematics\".\n  We begin with a brief review of first-order logic with counting operators and\ncardinality comparisons. This system is known to be of high complexity, and\ndrowns out finer aspects of the combination of logic and counting. We move to a\nsmall fragment that can represent numerical syllogisms and basic reasoning\nabout comparative size: monadic first-order logic with counting. We provide\nnormal forms that allow for axiomatization, determine which arithmetical\nnotions can be defined on finite and on infinite models, and conversely, we\ndiscuss which logical notions can be defined out of purely arithmetical ones,\nand what sort of (non-)classical logics can be induced.\n  Next, we investigate a series of strengthenings, again using normal form\nmethods. The monadic second-order version is close, in a precise sense, to\nadditive Presburger Arithmetic, while versions with the natural device of tuple\ncounting take us to Diophantine equations, making the logic undecidable. We\nalso define a system that combines basic modal logic over binary accessibility\nrelations with counting, needed to formulate ubiquitous reasoning patterns such\nas the Pigeonhole Principle.\n  We return to our starting point in natural language, confronting the\narchitecture of our formal systems with linguistic quantifier vocabulary and\nsyntax. We conclude with some general thoughts on yet further entanglements of\nlogic and counting in formal systems, on rethinking the\nqualitative/quantitative divide, and on connecting our analysis to empirical\nfindings in cognitive science."}
{"id": "2507.04231", "categories": ["math.NT", "11T06"], "pdf": "https://arxiv.org/pdf/2507.04231", "abs": "https://arxiv.org/abs/2507.04231", "authors": ["Mahdi-Tahar Brahimi"], "title": "Implementation of Wildberger's Polyseries", "comment": "8 pages", "summary": "We study the computational framework of polyseries and poly-numbers\nintroduced by Wildberger and Rubine in [2]. After reviewing Peano arithmetic,\ncomputable naturals, and non-standard models, we define the core data and\nprocedure operations on polyseries. We then apply Catalan number expansions to\nsolve quadratic congruences and derive explicit truncated series formulas in a\nfinite field $\\mathbb{Z}_p$. Our main result gives a closed form poly series\nsolution in terms of Catalan numbers."}
{"id": "2507.03136", "categories": ["cs.CR", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.03136", "abs": "https://arxiv.org/abs/2507.03136", "authors": ["Ricardo Queiroz de Araujo Fernandes", "Anderson Santos", "Daniel Maier de Carvalho", "André Luiz Bandeira Molina"], "title": "Holographic Projection and Cyber Attack Surface: A Physical Analogy for Digital Security", "comment": "The paper was produced to base a presentation in the V Jornadas STIC\n  capitulo Panam\\'a", "summary": "This article presents an in-depth exploration of the analogy between the\nHolographic Principle in theoretical physics and cyber attack surfaces in\ndigital security. Building on concepts such as black hole entropy and AdS/CFT\nduality, it highlights how complex infrastructures project their\nvulnerabilities onto their external interfaces. The paper draws a parallel\nbetween a black hole's event horizon, which encodes all internal information,\nand the attack surface, which reflects the internal architecture's security\nposture. Additionally, the article outlines how this conceptual framework can\nguide cybersecurity practices, emphasizing strategies such as attack surface\nreduction, continuous scanning with tools like OWASP ZAP and Greenbone OpenVAS,\nand the implementation of Zero Trust Architecture. This analogy not only\nprovides a unique perspective on digital security but also underscores the\ncritical importance of boundary-level defenses in protecting vast internal\ninfrastructures."}
{"id": "2507.04217", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.04217", "abs": "https://arxiv.org/abs/2507.04217", "authors": ["Abderrahim Hantoute", "Alexander Y. Kruger", "Marco A. López"], "title": "Strong duality in infinite convex optimization", "comment": "19 pages, Formerly was part of 2409.00573. arXiv admin note:\n  substantial text overlap with arXiv:2409.00573", "summary": "We develop a methodology for closing duality gap and guaranteeing strong\nduality in infinite convex optimization. Specifically, we examine two new\nLagrangian-type dual formulations involving infinitely many dual variables and\ninfinite sums of functions. Unlike the classical Haar duality scheme, these\ndual problems provide zero duality gap and are solvable under the standard\nSlater condition. Then we derive general optimality conditions/multiplier rules\nby applying subdifferential rules for infinite sums established in [13]."}
{"id": "2507.03407", "categories": ["cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2507.03407", "abs": "https://arxiv.org/abs/2507.03407", "authors": ["Junwei Su", "Cheng Xin", "Ao Shang", "Shan Wu", "Zhenzhen Xie", "Ruogu Xiong", "Xiaoyu Xu", "Cheng Zhang", "Guang Chen", "Yau-Tuen Chan", "Guoyi Tang", "Ning Wang", "Yong Xu", "Yibin Feng"], "title": "Artificial intelligence in drug discovery: A comprehensive review with a case study on hyperuricemia, gout arthritis, and hyperuricemic nephropathy", "comment": null, "summary": "This paper systematically reviews recent advances in artificial intelligence\n(AI), with a particular focus on machine learning (ML), across the entire drug\ndiscovery pipeline. Due to the inherent complexity, escalating costs, prolonged\ntimelines, and high failure rates of traditional drug discovery methods, there\nis a critical need to comprehensively understand how AI/ML can be effectively\nintegrated throughout the full process. Currently available literature reviews\noften narrowly focus on specific phases or methodologies, neglecting the\ndependence between key stages such as target identification, hit screening, and\nlead optimization. To bridge this gap, our review provides a detailed and\nholistic analysis of AI/ML applications across these core phases, highlighting\nsignificant methodological advances and their impacts at each stage. We further\nillustrate the practical impact of these techniques through an in-depth case\nstudy focused on hyperuricemia, gout arthritis, and hyperuricemic nephropathy,\nhighlighting real-world successes in molecular target identification and\ntherapeutic candidate discovery. Additionally, we discuss significant\nchallenges facing AI/ML in drug discovery and outline promising future research\ndirections. Ultimately, this review serves as an essential orientation for\nresearchers aiming to leverage AI/ML to overcome existing bottlenecks and\naccelerate drug discovery."}
{"id": "2507.03988", "categories": ["math.CO", "math.CT"], "pdf": "https://arxiv.org/pdf/2507.03988", "abs": "https://arxiv.org/abs/2507.03988", "authors": ["Gleb Koshevoy", "Vadim Schechtman"], "title": "Bruhat operads II. Multiplicative structures", "comment": "15 pages, 4 figures", "summary": "The Bruhat operads from \\cite{KS} are equipped with a structure of operads\nwith multiplication."}
{"id": "2507.04402", "categories": ["math.NT", "05A17, 11F11, 11F20, 11P83"], "pdf": "https://arxiv.org/pdf/2507.04402", "abs": "https://arxiv.org/abs/2507.04402", "authors": ["Judy Ann Donato"], "title": "On Minimal Excludant over Overpartitions", "comment": null, "summary": "A partition of a positive integer $n$ is a non-increasing sequence of\npositive integers which sum to $n$. A recently studied aspect of partitions is\nthe minimal excludant of a partition, which is defined to be the smallest\npositive integer that is not a part of the partition. In 2024, Aricheta and\nDonato studied the minimal excludant of the non-overlined parts of an\noverpartition, where an overpartition of $n$ is a partition of $n$ in which the\nfirst occurrence of a number may be overlined. In this research, we explore two\nother definitions of the minimal excludant of an overpartition: (i) considering\nonly the overlined parts, and (ii) considering both the overlined and\nnon-overlined parts. We discuss the combinatorial, asymptotic, and arithmetic\nproperties of the corresponding $\\sigma$-function, which gives the sum of the\nminimal excludants over all overpartitions."}
{"id": "2507.03236", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03236", "abs": "https://arxiv.org/abs/2507.03236", "authors": ["Noureldin Zahran", "Ahmad Tahmasivand", "Ihsen Alouani", "Khaled Khasawneh", "Mohammed E. Fouda"], "title": "On Jailbreaking Quantized Language Models Through Fault Injection Attacks", "comment": "This work has been published in GLSVLSI 2025", "summary": "The safety alignment of Language Models (LMs) is a critical concern, yet\ntheir integrity can be challenged by direct parameter manipulation attacks,\nsuch as those potentially induced by fault injection. As LMs are increasingly\ndeployed using low-precision quantization for efficiency, this paper\ninvestigates the efficacy of such attacks for jailbreaking aligned LMs across\ndifferent quantization schemes. We propose gradient-guided attacks, including a\ntailored progressive bit-level search algorithm introduced herein and a\ncomparative word-level (single weight update) attack. Our evaluation on\nLlama-3.2-3B, Phi-4-mini, and Llama-3-8B across FP16 (baseline), and\nweight-only quantization (FP8, INT8, INT4) reveals that quantization\nsignificantly influences attack success. While attacks readily achieve high\nsuccess (>80\\% Attack Success Rate, ASR) on FP16 models, within an attack\nbudget of 25 perturbations, FP8 and INT8 models exhibit ASRs below 20\\% and\n50\\%, respectively. Increasing the perturbation budget up to 150 bit-flips, FP8\nmodels maintained ASR below 65\\%, demonstrating some resilience compared to\nINT8 and INT4 models that have high ASR. In addition, analysis of perturbation\nlocations revealed differing architectural targets across quantization schemes,\nwith (FP16, INT4) and (INT8, FP8) showing similar characteristics. Besides,\njailbreaks induced in FP16 models were highly transferable to subsequent\nFP8/INT8 quantization (<5\\% ASR difference), though INT4 significantly reduced\ntransferred ASR (avg. 35\\% drop). These findings highlight that while common\nquantization schemes, particularly FP8, increase the difficulty of direct\nparameter manipulation jailbreaks, vulnerabilities can still persist,\nespecially through post-attack quantization."}
{"id": "2507.04223", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.04223", "abs": "https://arxiv.org/abs/2507.04223", "authors": ["Xin Chen", "Zhaolin Ren"], "title": "Regression-Based Single-Point Zeroth-Order Optimization", "comment": null, "summary": "Zeroth-order optimization (ZO) is widely used for solving black-box\noptimization and control problems. In particular, single-point ZO (SZO) is\nwell-suited to online or dynamic problem settings due to its requirement of\nonly a single function evaluation per iteration. However, SZO suffers from high\ngradient estimation variance and slow convergence, which severely limit its\npractical applicability. Despite recent advances, the convergence of existing\nSZO methods remains inferior to that of two-point ZO methods. To overcome this\nlimitation, we propose a novel yet simple SZO framework, termed\nregression-based SZO (RESZO), which substantially enhances the convergence\nrate. Unlike conventional ZO methods that rely solely on function evaluations\nat the current point for gradient estimation, RESZO improves gradient\nestimation by effectively leveraging historical function evaluations from\nprevious iterations. Specifically, RESZO constructs a surrogate function via\nregression using recent historical evaluations and employs the gradient of this\nsurrogate function for iterative updates. Two variants of RESZO, which fit\nlinear and quadratic surrogate functions respectively, are introduced.\nTheoretically, we provide a non-asymptotic convergence analysis for the linear\nvariant of RESZO, showing that its convergence rates are comparable to those of\ntwo-point ZO methods for both smooth nonconvex and strongly convex functions.\nMoreover, extensive numerical experiments demonstrate that RESZO not only\nmatches but empirically outperforms two-point ZO in terms of function query\ncomplexity."}
{"id": "2507.03409", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03409", "abs": "https://arxiv.org/abs/2507.03409", "authors": ["Christopher Summerfield", "Lennart Luettgau", "Magda Dubois", "Hannah Rose Kirk", "Kobi Hackenburg", "Catherine Fist", "Katarina Slama", "Nicola Ding", "Rebecca Anselmetti", "Andrew Strait", "Mario Giulianelli", "Cozmin Ududec"], "title": "Lessons from a Chimp: AI \"Scheming\" and the Quest for Ape Language", "comment": null, "summary": "We examine recent research that asks whether current AI systems may be\ndeveloping a capacity for \"scheming\" (covertly and strategically pursuing\nmisaligned goals). We compare current research practices in this field to those\nadopted in the 1970s to test whether non-human primates could master natural\nlanguage. We argue that there are lessons to be learned from that historical\nresearch endeavour, which was characterised by an overattribution of human\ntraits to other agents, an excessive reliance on anecdote and descriptive\nanalysis, and a failure to articulate a strong theoretical framework for the\nresearch. We recommend that research into AI scheming actively seeks to avoid\nthese pitfalls. We outline some concrete steps that can be taken for this\nresearch programme to advance in a productive and scientifically rigorous\nfashion."}
{"id": "2507.04007", "categories": ["math.CO", "05C30 (Primary), 68R05 (Secondary)", "G.2.2; F.2.2"], "pdf": "https://arxiv.org/pdf/2507.04007", "abs": "https://arxiv.org/abs/2507.04007", "authors": ["Kai Liang"], "title": "Independent Set Enumeration and Estimation of Related Constants of Grid Graphs", "comment": null, "summary": "We employed tensor network contraction algorithms to compute the hard-core\nlattice gas model, i.e., the enumeration of independent sets on grid graphs. We\nobserved the influence of boundary effect and parity effect on the enumeration\n(or entropy), and derived upper and lower bounds for both the free energy and\nthe first-order coefficients of boundary effects. Our computational results\nprovided terms 0 to 3159 of the OEIS sequence A089980.\n  Additionally, we conducted corresponding calculations and analyses for\ntriangular, cylindrical, and twisted cylindrical variants of grid graphs. We\ncomputed and analyzed their associated constants and compared how different\nadjacency and boundary conditions affect these constants. For the enumeration\nof independent sets on triangular grid graphs, we provided terms 0 to 40 of the\nOEIS sequence A027740."}
{"id": "2507.04405", "categories": ["math.NT", "math.DS"], "pdf": "https://arxiv.org/pdf/2507.04405", "abs": "https://arxiv.org/abs/2507.04405", "authors": ["Victor Beresnevich", "David Simmons", "Sanju Velani"], "title": "Twisted Diophantine approximation on manifolds", "comment": "31 pages", "summary": "In twisted Diophantine approximation, for a fixed $m\\times n$ matrix\n$\\boldsymbol\\alpha$ one is interested in sets of vectors\n$\\boldsymbol\\beta\\in\\mathbb R^m$ such that the system of affine forms $\\mathbb\nR^n \\ni \\mathbf q \\mapsto \\boldsymbol\\alpha\\mathbf q + \\boldsymbol\\beta \\in\n\\mathbb R^m$ satisfies some given Diophantine condition. In this paper we\nintroduce the notion of manifolds which are of $\\boldsymbol\\alpha$-twisted\nKhintchine type for convergence or divergence. We provide sufficient conditions\nunder which nondegenerate analytic manifolds exhibit this twisted\nKhintchine-type behaviour. Furthermore, we investigate the intersection\nproperties of the sets of $\\boldsymbol\\alpha$-twisted badly approximable and\nwell approximable vectors with nondegenerate manifolds."}
{"id": "2507.03258", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.03258", "abs": "https://arxiv.org/abs/2507.03258", "authors": ["Zhaorun Lin"], "title": "Novel Blockchain-based Protocols for Electronic Voting and Auctions", "comment": "My thesis for MPhil at HKUST", "summary": "Programmable blockchains have long been a hot research topic given their\ntremendous use in decentralized applications. Smart contracts, using\nblockchains as their underlying technology, inherit the desired properties such\nas verifiability, immutability, and transparency, which make it a great suit in\ntrustless environments.\n  In this thesis, we consider several decentralized protocols to be built on\nblockchains, specifically using smart contracts on Ethereum. We used\nalgorithmic and cryptographic tools in our implementations to further improve\nthe level of security and efficiency beyond the state-of-the-art works. We\nproposed a new approach called Blind Vote, which is an untraceable, secure,\nefficient, secrecy-preserving, and fully on-chain electronic voting protocol\nbased on the well-known concept of Chaum's blind signatures. We illustrate that\nour approach achieves the same security guarantees as previous methods such as\nTornado Vote [1], while consuming significantly less gas. Thus, we provide a\ncheaper and considerably more gas-efficient alternative for anonymous\nblockchain-based voting. On the other hand, we propose a new family of\nalgorithms for private, trustless auctions that protect bidder identities and\nbid values while remaining practical for smart contract execution. We ensure\ntrustlessness by running the auction logic in a smart contract, thereby\neliminating reliance on any single trusted party. This approach prevents bid\ntampering, front-running, and collusion by enforcing immutability and\ndecentralized verification of bids. The resulting protocol uniquely combines\nefficiency, trustlessness, and enduring bid privacy, offering a scalable and\nsecure solution for blockchain-based marketplaces and other decentralized\napplications."}
{"id": "2507.04232", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.04232", "abs": "https://arxiv.org/abs/2507.04232", "authors": ["Chenchen Wang", "Jie Qi", "Jiaqi Hu"], "title": "Soft Actor-Critic with Backstepping-Pretrained DeepONet for control of PDEs", "comment": null, "summary": "This paper develops a reinforcement learning-based controller for the\nstabilization of partial differential equation (PDE) systems. Within the soft\nactor-critic (SAC) framework, we embed a DeepONet, a well-known neural operator\n(NO), which is pretrained using the backstepping controller. The pretrained\nDeepONet captures the essential features of the backstepping controller and\nserves as a feature extractor, replacing the convolutional neural networks\n(CNNs) layers in the original actor and critic networks, and directly connects\nto the fully connected layers of the SAC architecture. We apply this novel\nbackstepping and reinforcement learning integrated method to stabilize an\nunstable ffrst-order hyperbolic PDE and an unstable reactiondiffusion PDE.\nSimulation results demonstrate that the proposed method outperforms the\nstandard SAC, SAC with an untrained DeepONet, and the backstepping controller\non both systems."}
{"id": "2507.03460", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03460", "abs": "https://arxiv.org/abs/2507.03460", "authors": ["Weitong Zhang", "Mengyun Qiao", "Chengqi Zang", "Steven Niederer", "Paul M Matthews", "Wenjia Bai", "Bernhard Kainz"], "title": "Multi-Agent Reasoning for Cardiovascular Imaging Phenotype Analysis", "comment": null, "summary": "Identifying the associations between imaging phenotypes and disease risk\nfactors and outcomes is essential for understanding disease mechanisms and\nimproving diagnosis and prognosis models. However, traditional approaches rely\non human-driven hypothesis testing and selection of association factors, often\noverlooking complex, non-linear dependencies among imaging phenotypes and other\nmulti-modal data. To address this, we introduce a Multi-agent Exploratory\nSynergy for the Heart (MESHAgents) framework that leverages large language\nmodels as agents to dynamically elicit, surface, and decide confounders and\nphenotypes in association studies, using cardiovascular imaging as a proof of\nconcept. Specifically, we orchestrate a multi-disciplinary team of AI agents --\nspanning cardiology, biomechanics, statistics, and clinical research -- which\nspontaneously generate and converge on insights through iterative,\nself-organizing reasoning. The framework dynamically synthesizes statistical\ncorrelations with multi-expert consensus, providing an automated pipeline for\nphenome-wide association studies (PheWAS). We demonstrate the system's\ncapabilities through a population-based study of imaging phenotypes of the\nheart and aorta. MESHAgents autonomously uncovered correlations between imaging\nphenotypes and a wide range of non-imaging factors, identifying additional\nconfounder variables beyond standard demographic factors. Validation on\ndiagnosis tasks reveals that MESHAgents-discovered phenotypes achieve\nperformance comparable to expert-selected phenotypes, with mean AUC differences\nas small as -0.004 on disease classification tasks. Notably, the recall score\nimproves for 6 out of 9 disease types. Our framework provides clinically\nrelevant imaging phenotypes with transparent reasoning, offering a scalable\nalternative to expert-driven methods."}
{"id": "2507.04169", "categories": ["math.CO", "20M14, 05A17"], "pdf": "https://arxiv.org/pdf/2507.04169", "abs": "https://arxiv.org/abs/2507.04169", "authors": ["Nathan Kaplan", "Kaylee Kim", "Cole McGeorge", "Fabian Ramirez", "Deepesh Singhal"], "title": "On the smallest partition associated to a numerical semigroup", "comment": "23 pages", "summary": "The set of hook lengths of an integer partition $\\lambda$ is the complement\nof some numerical semigroup $S$. There has been recent interest in studying the\nnumber of partitions with a given set of hook lengths. Very little is known\nabout the distribution of sizes of this finite set of partitions. We focus on\nthe problem of determining the size of the smallest partition with its set of\nhook lengths equal to $\\mathbb{N}\\setminus S$."}
{"id": "2507.04521", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.04521", "abs": "https://arxiv.org/abs/2507.04521", "authors": ["Dmitry Gayfulin", "Erez Nesharim"], "title": "Every real number is a sum of two real numbers with diverging partial quotients", "comment": "18 pages", "summary": "We show that every irrational number is a sum of two real numbers with\ndiverging partial quotients. The proof is constructive. The key towards these\nresults is an algorithm which was recently developed by Nikita Shulga, and our\nstudy of this algorithm is of independent interest."}
{"id": "2507.03278", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03278", "abs": "https://arxiv.org/abs/2507.03278", "authors": ["Jiaqi Xue", "Yifei Zhao", "Mengxin Zheng", "Xun Chen", "Fan Yao", "Yan Solihin", "Qian Lou"], "title": "Securing Transformer-based AI Execution via Unified TEE and Crypto-protected Accelerators", "comment": "15 pages", "summary": "Recent advances in Transformer models, e.g., large language models (LLMs),\nhave brought tremendous breakthroughs in various artificial intelligence (AI)\ntasks, leading to their wide applications in many security-critical domains.\nDue to their unprecedented scale and prohibitively high development cost, these\nmodels have become highly valuable intellectual property for AI stakeholders\nand are increasingly deployed via machine learning as a service (MLaaS).\nHowever, MLaaS often runs on untrusted cloud infrastructure, exposing data and\nmodels to potential breaches. Mainstream protection mechanisms leverage trusted\nexecution environments (TEEs) where confidentiality and integrity for secretive\ndata are shielded using hardware-based encryption and integrity checking.\nUnfortunately, running model inference entirely within TEEs is subject to\nnon-trivial slowdown, which is further exacerbated in LLMs due to the\nsubstantial computation and memory footprint involved. Recent studies reveal\nthat the hybrid TEE-based scheme offloading partial model inference operations\nto the untrusted accelerators (e.g., GPU) is a promising solution. However,\nprior offloading schemes fail to ensure dual protection of data and model in\nTransformer inference, as they cannot securely offload critical operations,\ni.e., Attention and SoftMax, forcing these computations to remain confined\nwithin TEEs. To address these challenges, we propose TwinShield, a framework\nenabling secure Transformer inference in heterogeneous TEE and accelerator\nsystems with dual protection for both model and data. TwinShield offloads ~87%\nof computation to GPUs and delivers 4.0x - 6.1x speedups over previous\napproaches across various Transformer models."}
{"id": "2507.04356", "categories": ["math.OC", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.04356", "abs": "https://arxiv.org/abs/2507.04356", "authors": ["Vyacheslav Kungurtsev", "Gustav Sir", "Akhil Anand", "Sebastien Gros", "Haozhe Tian", "Homayoun Hamedmoghadam"], "title": "Mission-Aligned Learning-Informed Control of Autonomous Systems: Formulation and Foundations", "comment": null, "summary": "Research, innovation and practical capital investment have been increasing\nrapidly toward the realization of autonomous physical agents. This includes\nindustrial and service robots, unmanned aerial vehicles, embedded control\ndevices, and a number of other realizations of cybernetic/mechatronic\nimplementations of intelligent autonomous devices. In this paper, we consider a\nstylized version of robotic care, which would normally involve a two-level\nReinforcement Learning procedure that trains a policy for both lower level\nphysical movement decisions as well as higher level conceptual tasks and their\nsub-components. In order to deliver greater safety and reliability in the\nsystem, we present the general formulation of this as a two-level optimization\nscheme which incorporates control at the lower level, and classical planning at\nthe higher level, integrated with a capacity for learning. This synergistic\nintegration of multiple methodologies -- control, classical planning, and RL --\npresents an opportunity for greater insight for algorithm development, leading\nto more efficient and reliable performance. Here, the notion of reliability\npertains to physical safety and interpretability into an otherwise black box\noperation of autonomous agents, concerning users and regulators. This work\npresents the necessary background and general formulation of the optimization\nframework, detailing each component and its integration with the others."}
{"id": "2507.03477", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03477", "abs": "https://arxiv.org/abs/2507.03477", "authors": ["Kexin Zhu", "Yang Han"], "title": "REAL: Benchmarking Abilities of Large Language Models for Housing Transactions and Services", "comment": null, "summary": "The development of large language models (LLMs) has greatly promoted the\nprogress of chatbot in multiple fields. There is an urgent need to evaluate\nwhether LLMs can play the role of agent in housing transactions and services as\nwell as humans. We present Real Estate Agent Large Language Model Evaluation\n(REAL), the first evaluation suite designed to assess the abilities of LLMs in\nthe field of housing transactions and services. REAL comprises 5,316\nhigh-quality evaluation entries across 4 topics: memory, comprehension,\nreasoning and hallucination. All these entries are organized as 14 categories\nto assess whether LLMs have the knowledge and ability in housing transactions\nand services scenario. Additionally, the REAL is used to evaluate the\nperformance of most advanced LLMs. The experiment results indicate that LLMs\nstill have significant room for improvement to be applied in the real estate\nfield."}
{"id": "2507.04179", "categories": ["math.CO", "05A19, 05A10"], "pdf": "https://arxiv.org/pdf/2507.04179", "abs": "https://arxiv.org/abs/2507.04179", "authors": ["Kunle Adegoke"], "title": "Binomial Convolution of Sequences", "comment": "23 pages, no figures or tables", "summary": "Given any two sequences of complex numbers, we establish simple relations\nbetween their binomial convolution and the binomial convolution of their\nindividual binomial transforms. We employ these relations to derive new\nidentities involving Fibonacci numbers, Bernoulli numbers, harmonic numbers,\nodd harmonic numbers and binomial coefficients."}
{"id": "2507.04604", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.04604", "abs": "https://arxiv.org/abs/2507.04604", "authors": ["Maarten Derickx"], "title": "Class groups of imaginary quadratic points on $X_1(16)$", "comment": null, "summary": "The main result is to show that if $K \\ncong \\mathbb Q(\\sqrt{-15})$ is an\nimaginary quadratic field and $E$ is an elliptic curve over $K$ with a torsion\npoint of order 16, then the class number of $K$ is divisible by 10. This gives\nan affirmative answer to a 12 year old question by David Krumm. This is done by\nsetting up a more general framework for studying divisibility of class groups\nof imaginary quadratic points on hyper-elliptic curves and applying it to\n$X_1(16)$."}
{"id": "2507.03323", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.03323", "abs": "https://arxiv.org/abs/2507.03323", "authors": ["Kazumasa Shinagawa", "Koji Nuida"], "title": "A Note on Single-Cut Full-Open Protocols", "comment": null, "summary": "Card-based cryptography is a research area that realizes cryptographic\nprotocols such as secure computation by applying shuffles to sequences of cards\nthat encode input values. A single-cut full-open protocol is one that obtains\nan output value by applying a random cut to an input sequence of cards, after\nwhich all cards are opened. In this paper, we propose three single-cut\nfull-open protocols: two protocols for three-variable functions and one\nprotocol for a four-variable function."}
{"id": "2507.04515", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.04515", "abs": "https://arxiv.org/abs/2507.04515", "authors": ["Liang Wu", "Richard D. Braatz"], "title": "A Quadratic Programming Algorithm with $O(n^3)$ Time Complexity", "comment": "16 pages", "summary": "Solving linear systems and quadratic programming (QP) problems are both\nubiquitous tasks in the engineering and computing fields. Direct methods for\nsolving systems, such as Cholesky, LU, and QR factorizations, exhibit\ndata-independent time complexity of $O(n^3)$. This raises a natural question:\ncould there exist algorithms for solving QPs that also achieve\n\\textit{data-independent} time complexity of $O(n^3)$? This raises a natural\nquestion: could there exist algorithms for solving QPs that also achieve\ndata-independent time complexity of $O(n^3)$? This is critical for offering an\nexecution time certificate for real-time optimization-based applications such\nas model predictive control. This article first demonstrates that solving\nreal-time strictly convex QPs, Lasso problems, and support vector machine\nproblems can be turned into solving box-constrained QPs (Box-QPs), which\nsupport a cost-free initialization strategy for feasible interior-point methods\n(IPMs). Next, focusing on solving Box-QPs, this article replaces the exact\nNewton step with an approximated Newton step (substituting the matrix-inversion\noperation with multiple rank-1 updates) within feasible IPMs. For the first\ntime, this article proposes an implementable feasible IPM algorithm with\n$O(n^3)$ time complexity, by proving the number of iterations is exact\n$O(\\sqrt{n})$ and the number of rank-1 updates is bounded by $O(n)$. Numerical\nvalidations/applications and codes are provided."}
{"id": "2507.03525", "categories": ["cs.AI", "cs.SY", "eess.SY", "I.2; K.6; D.2.9"], "pdf": "https://arxiv.org/pdf/2507.03525", "abs": "https://arxiv.org/abs/2507.03525", "authors": ["David Manheim", "Aidan Homewood"], "title": "Limits of Safe AI Deployment: Differentiating Oversight and Control", "comment": null, "summary": "Oversight and control (collectively, supervision) are often invoked as key\nlevers for ensuring that AI systems are accountable, reliable, and able to\nfulfill governance and management requirements. However, the concepts are\nfrequently conflated or insufficiently distinguished in academic and policy\ndiscourse, undermining efforts to design or evaluate systems that should remain\nunder meaningful human supervision.\n  This paper undertakes a targeted critical review of literature on supervision\noutside of AI, along with a brief summary of past work on the topic related to\nAI. We then differentiate control as being ex-ante or real-time, and\noperational rather than policy or governance. In contrast, oversight is either\na policy and governance function, or is ex-post. We suggest that control aims\nto prevent failures. In contrast, oversight often focuses on detection,\nremediation, or incentives for future prevention; all preventative oversight\nstrategies nonetheless necessitate control.\n  Building on this foundation, we make three contributions. First, we propose a\ntheoretically-informed yet policy-grounded framework that articulates the\nconditions under which each mechanism is possible, where they fall short, and\nwhat is required to make them meaningful in practice. Second, we outline how\nsupervision methods should be documented and integrated into risk management,\nand drawing on the Microsoft Responsible AI Maturity Model, we outline a\nmaturity model for AI supervision. Third, we explicitly highlight some\nboundaries of these mechanisms, including where they apply, where they fail,\nand where it is clear that no existing methods suffice. This foregrounds the\nquestion of whether meaningful supervision is possible in a given deployment\ncontext, and can support regulators, auditors, and practitioners in identifying\nboth present limitations and the need for new conceptual and technical\nadvances."}
{"id": "2507.04254", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.04254", "abs": "https://arxiv.org/abs/2507.04254", "authors": ["Gaétan Berthe", "Marthe Bonamy", "Fábio Botler", "Gaia Carenini", "Lucas Colucci", "Arthur Dumas", "Fatemeh Ghasemi", "Pedro Mariano Viana Neto"], "title": "On Modular Edge Colourings of Graphs", "comment": "7 pages", "summary": "Given a graph $G$ and an integer $k\\geq 2$, let $\\chi'_k(G)$ denote the\nminimum number of colours required to colour the edges of $G$ such that, in\neach colour class, the subgraph induced by the edges of that colour has all\nnon-zero degrees congruent to $1$ modulo $k$. In 1992, Pyber proved that\n$\\chi'_2(G) \\leq 4$ for every graph $G$, and posed the question of whether\n$\\chi'_k(G)$ can be bounded solely in terms of $k$ for every $k\\geq 3$. This\nquestion was answered in 1997 by Scott, who showed that $\\chi'_k(G)\\leq5k^2\\log\nk$, and further asked whether $\\chi'_k(G) = O(k)$. Recently, Botler, Colucci,\nand Kohayakawa (2023) answered Scott's question affirmatively proving that\n$\\chi'_k(G) \\leq 198k - 101$, and conjectured that the multiplicative constant\ncould be reduced to $1$. A step towards this latter conjecture was made in 2024\nby Nweit and Yang, who improved the bound to $\\chi'_k(G) \\leq 177k - 93$. In\nthis paper, we further improve the multiplicative constant to $9$. More\nspecifically, we prove that there is a function $f\\in o(k)$ for which\n$\\chi'_k(G) \\leq 7k + f(k)$ if $k$ is odd, and $\\chi'_k(G) \\leq 9k + f(k)$ if\n$k$ is even. In doing so, we prove that $\\chi'_k(G) \\leq k + O(d)$ for every\n$d$-degenerate graph $G$, which plays a central role in our proof."}
{"id": "2507.04653", "categories": ["math.NT", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.04653", "abs": "https://arxiv.org/abs/2507.04653", "authors": ["Lin-Yue Li", "Rong-Hua Wang"], "title": "$q$-Congruences for Z.-W. Sun's generalized polynomials $w^{(α)}_k(x)$", "comment": null, "summary": "In 2022, Z.-W. Sun defined \\begin{equation*}\nw_k^{(\\alpha)}{(x)}=\\sum_{j=1}^{k}w(k,j)^{\\alpha}x^{j-1}, \\end{equation*} where\n$k,\\alpha$ are positive integers and\n$w(k,j)=\\frac{1}{j}\\binom{k-1}{j-1}\\binom{k+j}{j-1}$. Let $(x)_{0}=1$ and\n$(x)_{n}=x(x+1)\\cdots(x+n-1)$ for all $n\\geq 1$. In this paper, it is proved by\n$q$-congruences that for any positive integers ${\\alpha,\\beta, m,n,r}$, we have\n\\begin{equation*}\n\\frac{(2,n)}{n(n+1)(n+2)}\\sum_{k=1}^{n}k^r(k+1)^r(2k+1)w_{k}^{(\\alpha)}(x)^{m}\\in\\mathbb{Z}[x],\n\\end{equation*} \\begin{equation*}\n\\frac{(2,n)}{n(n+1)(n+2)}\\sum_{k=1}^{n}(-1)^{k}k^r(k+1)^r(2k+1)\nw_{k}^{(\\alpha)}(x)^{m}\\in\\mathbb{Z}[x], \\end{equation*} and \\begin{equation*}\n\\frac{2}{[n,n+1,\\cdots,n+2\\beta+1]}\\sum_{k=1}^{n}(k)_{\\beta}^r(k+\\beta+1)_{\\beta}^r(k+\\beta)\n\\prod_{i=0}^{2\\beta-1}w_{k+i}^{(\\alpha)}(x)^m\\in\\mathbb{Z}[x], \\end{equation*}\nwhere $[n,n+1,\\cdots,n+2\\beta+1]$ is the least common multiple of $n$, $n+1$,\n$\\cdots$, $n+2\\beta+1$. Taking $r=\\beta=1$ above will confirm some of Z.-W.\nSun's conjectures."}
{"id": "2507.03344", "categories": ["cs.CR", "cs.SE", "C.1.3; D.2.5"], "pdf": "https://arxiv.org/pdf/2507.03344", "abs": "https://arxiv.org/abs/2507.03344", "authors": ["Jason Zhijingcheng Yu", "Fangqi Han", "Kaustab Choudhury", "Trevor E. Carlson", "Prateek Saxena"], "title": "Securing Mixed Rust with Hardware Capabilities", "comment": "To appear at CCS '25", "summary": "The Rust programming language enforces three basic Rust principles, namely\nownership, borrowing, and AXM (Aliasing Xor Mutability) to prevent security\nbugs such as memory safety violations and data races. However, Rust projects\noften have mixed code, i.e., code that also uses unsafe Rust, FFI (Foreign\nFunction Interfaces), and inline assembly for low-level control. The Rust\ncompiler is unable to statically enforce Rust principles in mixed Rust code\nwhich can lead to many security vulnerabilities. In this paper, we propose\nCapsLock, a security enforcement mechanism that can run at the level of machine\ncode and detect Rust principle violations at run-time in mixed code. CapsLock\nis kept simple enough to be implemented into recent capability-based hardware\nabstractions that provide low-cost spatial memory safety. CapsLock introduces a\nnovel revoke-on-use abstraction for capability-based designs, wherein accessing\na memory object via a capability implicitly invalidates certain other\ncapabilities pointing to it, thereby also providing temporal memory safety\nautomatically, without requiring software to explicitly specify such\ninvalidation. Thus, CapsLock is the first mechanism capable of providing\ncross-language enforcement of Rust principles. We implemented a prototype of\nCapsLock on QEMU. Evaluation results show that CapsLock is highly compatible\nwith existing Rust code (passing 99.7% of the built-in test cases of the 100\nmost popular crates) and flags Rust principle violations in real-world Rust\nprojects that use FFI or inline assembly. We discovered 8 previously unknown\nbugs in such crates in our experiments."}
{"id": "2507.04520", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.04520", "abs": "https://arxiv.org/abs/2507.04520", "authors": ["Xinling Li", "Xiaotong Guo", "Qingyi Wang", "Gioele Zardini", "Jinhua Zhao"], "title": "Robust Vehicle Rebalancing with Deep Uncertainty in Autonomous Mobility-on-Demand Systems", "comment": null, "summary": "Autonomous Mobility-on-Demand (AMoD) services offer an opportunity for\nimproving passenger service while reducing pollution and energy consumption\nthrough effective vehicle coordination. A primary challenge in the autonomous\nfleets coordination is to tackle the inherent issue of supply-demand imbalance.\nA key strategy in resolving this is vehicle rebalancing, strategically\ndirecting idle vehicles to areas with anticipated future demand. Traditional\nresearch focuses on deterministic optimization using specific demand forecasts,\nbut the unpredictable nature of demand calls for methods that can manage this\nuncertainty. This paper introduces the Deep Uncertainty Robust Optimization\n(DURO), a framework specifically designed for vehicle rebalancing in AMoD\nsystems amidst uncertain demand based on neural networks for robust\noptimization. DURO forecasts demand uncertainty intervals using a deep neural\nnetwork, which are then integrated into a robust optimization model. We assess\nDURO against various established models, including deterministic optimization\nwith refined demand forecasts and Distributionally Robust Optimization (DRO).\nBased on real-world data from New York City (NYC), our findings show that DURO\nsurpasses traditional deterministic models in accuracy and is on par with DRO,\nbut with superior computational efficiency. The DURO framework is a promising\napproach for vehicle rebalancing in AMoD systems that is proven to be effective\nin managing demand uncertainty, competitive in performance, and more\ncomputationally efficient than other optimization models."}
{"id": "2507.03579", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03579", "abs": "https://arxiv.org/abs/2507.03579", "authors": ["Riccardo Lo Bianco", "Remco Dijkman", "Wim Nuijten", "Willem van Jaarsveld"], "title": "A Universal Approach to Feature Representation in Dynamic Task Assignment Problems", "comment": null, "summary": "Dynamic task assignment concerns the optimal assignment of resources to tasks\nin a business process. Recently, Deep Reinforcement Learning (DRL) has been\nproposed as the state of the art for solving assignment problems. DRL methods\nusually employ a neural network (NN) as an approximator for the policy\nfunction, which ingests the state of the process and outputs a valuation of the\npossible assignments. However, representing the state and the possible\nassignments so that they can serve as inputs and outputs for a policy NN\nremains an open challenge, especially when tasks or resources have features\nwith an infinite number of possible values. To solve this problem, this paper\nproposes a method for representing and solving assignment problems with\ninfinite state and action spaces. In doing so, it provides three contributions:\n(I) A graph-based feature representation of assignment problems, which we call\nassignment graph; (II) A mapping from marked Colored Petri Nets to assignment\ngraphs; (III) An adaptation of the Proximal Policy Optimization algorithm that\ncan learn to solve assignment problems represented through assignment graphs.\nTo evaluate the proposed representation method, we model three archetypal\nassignment problems ranging from finite to infinite state and action space\ndimensionalities. The experiments show that the method is suitable for\nrepresenting and learning close-to-optimal task assignment policies regardless\nof the state and action space dimensionalities."}
{"id": "2507.04257", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.04257", "abs": "https://arxiv.org/abs/2507.04257", "authors": ["Wanting Sun", "Guanghui Wang", "Pingchuan Yang"], "title": "Subdivision-free graphs with the maximum spectral radius", "comment": "17 pages, 1 figure", "summary": "Given a graph family $\\mathbb{H}$, let ${\\rm SPEX}(n,\\mathbb{H}_{\\rm sub})$\ndenote the set of $n$-vertex $\\mathbb{H}$-subdivision-free graphs with the\nmaximum spectral radius. In this paper, we investigate the problem of graph\nsubdivision from a spectral extremal perspective, with a focus on the\nstructural characterization of graphs in ${\\rm SPEX}(n,\\mathbb{H}_{\\rm sub})$.\nFor any graph $H \\in \\mathbb{H}$, let $\\alpha(H)$ denote its independence\nnumber. Define $\\gamma_\\mathbb{H}:=\\min_{H\\in \\mathbb{H}}\\{|H| - \\alpha(H) -\n1\\}$. We prove that every graph in ${\\rm SPEX}(n,\\mathbb{H}_{\\rm sub})$\ncontains a spanning subgraph isomorphic to $K_{\\gamma_\\mathbb{H}}\\vee\n(n-\\gamma_\\mathbb{H})K_1$, which is obtained by joining a\n$\\gamma_\\mathbb{H}$-clique with an independent set of $n-\\gamma_\\mathbb{H}$\nvertices. This extends a recent result by Zhai, Fang, and Lin concerning\nspectral extremal problems for $\\mathbb{H}$-minor-free graphs."}
{"id": "2507.04688", "categories": ["math.NT", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.04688", "abs": "https://arxiv.org/abs/2507.04688", "authors": ["Marcus Nilsson"], "title": "Counting linear congruence systems with a fixed number of solutions", "comment": null, "summary": "For a prime $p$ and a positive integer $s$ consider a homogeneous linear\nsystem over the ring $\\mathbb{Z}_{p^s}$ (the ring of integers modulo $p^s$)\ndescribed by an $n \\times m$-matrix. The possible number of solutions to such a\nsystem is $p^j$, where $j=0,1,\\ldots, sm$. We study the problem of how many $n\n\\times m$-matrices over $\\mathbb{Z}_{p^s}$ there are given that we have exactly\n$p^j$ homogeneous solutions. For the case $s=1$ (when $\\mathbb{Z}_{p^s}$ is a\nfield) George von Landsberg proved a general formula in 1893. However, there\nseems to be few published general results for the case $s>1$ except when we\nhave a unique solution ($j=0$). In this article we present recursive methods\nfor counting such matrices and present explicit formulas for the case when\n$j\\le s$ and $n\\ge m$. We will use a generalization of Euler's $\\phi$-function\nand Gaussian binomial coefficients to express our formulas. As an application\nwe compute the probability that gcd$(\\det(A),p^s)$ gives the number of\nsolutions to the quadratic system $Ax=0$ in $\\mathbb{Z}_{p^s}$."}
{"id": "2507.03361", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.03361", "abs": "https://arxiv.org/abs/2507.03361", "authors": ["Rayne Holland"], "title": "Accelerating Private Heavy Hitter Detection on Continual Observation Streams", "comment": "24 pages, 8 figures", "summary": "Differentially private frequency estimation and heavy hitter detection are\ncore problems in the private analysis of data streams. Two models are typically\nconsidered: the one-pass model, which outputs results only at the end of the\nstream, and the continual observation model, which requires releasing private\nsummaries at every time step. While the one-pass model allows more efficient\nsolutions, continual observation better reflects scenarios where timely and\nongoing insights are critical.\n  In the one-pass setting, sketches have proven to be an effective tool for\ndifferentially private frequency analysis, as they can be privatized by a\nsingle injection of calibrated noise. In contrast, existing methods in the\ncontinual observation model add fresh noise to the entire sketch at every step,\nincurring high computational costs. This challenge is particularly acute for\nheavy hitter detection, where current approaches often require querying every\nitem in the universe at each step, resulting in untenable per-update costs for\nlarge domains.\n  To overcome these limitations, we introduce a new differentially private\nsketching technique based on lazy updates, which perturbs and updates only a\nsmall, rotating part of the output sketch at each time step. This significantly\nreduces computational overhead while maintaining strong privacy and utility\nguarantees. In comparison to prior art, for frequency estimation, our method\nimproves the update time by a factor of $O(w)$ for sketches of dimension $d\n\\times w$; for heavy hitter detection, it reduces per-update complexity from\n$\\Omega(|U|)$ to $O(d \\log w)$, where $U$ is the input domain. Experiments show\na increase in throughput by a factor of~$250$, making differential privacy more\npractical for real-time, continual observation, applications."}
{"id": "2507.04539", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.04539", "abs": "https://arxiv.org/abs/2507.04539", "authors": ["Zsombor Szádoczki", "Sándor Bozóki", "László Sipos", "Zsófia Galambosi"], "title": "An experimental approach: Converting verbal expressions to numerical scales", "comment": null, "summary": "One of the key issues in decision problems is the selection and use of the\nappropriate response scale. In this paper verbal expressions are converted into\nnumerical scales for a subjective problem instance. The main motivation for our\nresearch was that verbal values in decision tasks are often mechanically\nconverted into numbers, which thus typically do not fully represent the\nrespondent's true evaluation. In our experiment, we conducted a color selection\ntest with 462 subjects by testing six colors (red, green, blue, magenta,\nturquoise, yellow) defined from the Color Namer database on color-calibrated\ntablets in ISO standardized sensory test booths of a sensory laboratory. The\ncolors were evaluated both in a pairwise comparison matrix (indirect ranking\nwith four-item verbal category scale) and on a direct scoring basis. We\ndetermined scales that provide the closest results on average and individually\nto the direct scoring, based on the eigenvector and the logarithmic least\nsquares methods. All results show that the difference between verbal\nexpressions is much smaller than the one used by most of the common numerical\nscales. The respondents' inconsistency was also analyzed, even with a repeated\nquestion regarding their preference between a given pair of colors. It is shown\nthat most decision makers answer fairly similarly for the second time, but\nthere can be significant (even ordinal) differences. The respondents whose\nanswers are further from the original tends to be more inconsistent in general."}
{"id": "2507.03608", "categories": ["cs.AI", "cs.DC", "cs.ET", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.03608", "abs": "https://arxiv.org/abs/2507.03608", "authors": ["Sarat Ahmad", "Zeinab Nezami", "Maryam Hafeez", "Syed Ali Raza Zaidi"], "title": "Benchmarking Vector, Graph and Hybrid Retrieval Augmented Generation (RAG) Pipelines for Open Radio Access Networks (ORAN)", "comment": null, "summary": "Generative AI (GenAI) is expected to play a pivotal role in enabling\nautonomous optimization in future wireless networks. Within the ORAN\narchitecture, Large Language Models (LLMs) can be specialized to generate xApps\nand rApps by leveraging specifications and API definitions from the RAN\nIntelligent Controller (RIC) platform. However, fine-tuning base LLMs for\ntelecom-specific tasks remains expensive and resource-intensive.\nRetrieval-Augmented Generation (RAG) offers a practical alternative through\nin-context learning, enabling domain adaptation without full retraining. While\ntraditional RAG systems rely on vector-based retrieval, emerging variants such\nas GraphRAG and Hybrid GraphRAG incorporate knowledge graphs or dual retrieval\nstrategies to support multi-hop reasoning and improve factual grounding.\nDespite their promise, these methods lack systematic, metric-driven\nevaluations, particularly in high-stakes domains such as ORAN. In this study,\nwe conduct a comparative evaluation of Vector RAG, GraphRAG, and Hybrid\nGraphRAG using ORAN specifications. We assess performance across varying\nquestion complexities using established generation metrics: faithfulness,\nanswer relevance, context relevance, and factual correctness. Results show that\nboth GraphRAG and Hybrid GraphRAG outperform traditional RAG. Hybrid GraphRAG\nimproves factual correctness by 8%, while GraphRAG improves context relevance\nby 7%."}
{"id": "2507.04273", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.04273", "abs": "https://arxiv.org/abs/2507.04273", "authors": ["Yulin Chang", "Yangyang Cheng", "Tianjiao Dai", "Qiancheng Ouyang", "Guanghui Wang"], "title": "An exact Ore-degree condition for Hamilton cycles in oriented graphs", "comment": null, "summary": "An oriented graph is a digraph that contains no 2-cycles, i.e., there is at\nmost one arc between any two vertices. We show that every oriented graph $G$ of\nsufficiently large order $n$ with $\\mathrm{deg}^+(x) +\\mathrm{deg}^{-}(y)\\geq\n(3n-3)/4$ whenever $G$ does not have an edge from $x$ to $y$ contains a\nHamilton cycle. This is best possible and solves a problem of K\\\"uhn and Osthus\nfrom 2012. Our result generalizes the result of Keevash, K\\\"uhn, and Osthus and\nimproves the asymptotic bound obtained by Kelly, K\\\"uhn, and Osthus."}
{"id": "2507.04848", "categories": ["math.NT", "cs.DM", "math.CO", "11A63, 11K16, 11B85, 68Q45, 68R15"], "pdf": "https://arxiv.org/pdf/2507.04848", "abs": "https://arxiv.org/abs/2507.04848", "authors": ["Émilie Charlier", "Pierre Popoli", "Michel Rigo"], "title": "Computing Expansions in Infinitely Many Cantor Real Bases via a Single Transducer", "comment": "36 pages, 10 figures. Comments are welcome", "summary": "Representing real numbers using convenient numeration systems (integer bases,\n$\\beta$-numeration, Cantor bases, etc.) has been a longstanding mathematical\nchallenge. This paper focuses on Cantor real bases and, specifically, on\nautomatic Cantor real bases and the properties of expansions of real numbers in\nthis setting. We develop a new approach where a single transducer associated\nwith a fixed real number $r$, computes the $\\mathbf{B}$-expansion of $r$ but\nfor an infinite family of Cantor real bases $\\mathbf{B}$ given as input. This\npoint of view contrasts with traditional computational models for which the\nnumeration system is fixed. Under some assumptions on the finitely many Pisot\nnumbers occurring in the Cantor real base, we show that only a finite part of\nthe transducer is visited. We obtain fundamental results on the structure of\nthis transducer and on decidability problems about these expansions, proving\nthat for certain classes of Cantor real bases, key combinatorial properties\nsuch as greediness of the expansion or periodicity can be decided\nalgorithmically."}
{"id": "2507.03387", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.03387", "abs": "https://arxiv.org/abs/2507.03387", "authors": ["Andong Chen", "Zhaoxuan Jin", "Ziyi Guo", "Yan Chen"], "title": "Breaking the Bulkhead: Demystifying Cross-Namespace Reference Vulnerabilities in Kubernetes Operators", "comment": "12 pages", "summary": "Kubernetes Operators, automated tools designed to manage application\nlifecycles within Kubernetes clusters, extend the functionalities of\nKubernetes, and reduce the operational burden on human engineers. While\nOperators significantly simplify DevOps workflows, they introduce new security\nrisks. In particular, Kubernetes enforces namespace isolation to separate\nworkloads and limit user access, ensuring that users can only interact with\nresources within their authorized namespaces. However, Kubernetes Operators\noften demand elevated privileges and may interact with resources across\nmultiple namespaces. This introduces a new class of vulnerabilities, the\nCross-Namespace Reference Vulnerability. The root cause lies in the mismatch\nbetween the declared scope of resources and the implemented scope of the\nOperator logic, resulting in Kubernetes being unable to properly isolate the\nnamespace. Leveraging such vulnerability, an adversary with limited access to a\nsingle authorized namespace may exploit the Operator to perform operations\naffecting other unauthorized namespaces, causing Privilege Escalation and\nfurther impacts. To the best of our knowledge, this paper is the first to\nsystematically investigate the security vulnerability of Kubernetes Operators.\nWe present Cross-Namespace Reference Vulnerability with two strategies,\ndemonstrating how an attacker can bypass namespace isolation. Through\nlarge-scale measurements, we found that over 14% of Operators in the wild are\npotentially vulnerable. Our findings have been reported to the relevant\ndevelopers, resulting in 7 confirmations and 6 CVEs by the time of submission,\naffecting vendors including ****** and ******, highlighting the critical need\nfor enhanced security practices in Kubernetes Operators. To mitigate it, we\nalso open-source the static analysis suite to benefit the ecosystem."}
{"id": "2507.04540", "categories": ["math.OC", "49L12, 91A15, 91A16, 91A25, 93E20"], "pdf": "https://arxiv.org/pdf/2507.04540", "abs": "https://arxiv.org/abs/2507.04540", "authors": ["Felix Höfer", "H. Mete Soner", "Atilla Yılmaz"], "title": "Markov Perfect Equilibria in Discrete Finite-Player and Mean-Field Games", "comment": null, "summary": "We study dynamic finite-player and mean-field stochastic games within the\nframework of Markov perfect equilibria (MPE). Our focus is on discrete time and\nspace structures without monotonicity. Unlike their continuous-time analogues,\ndiscrete-time finite-player games generally do not admit unique MPE. However,\nwe show that uniqueness is remarkably recovered when the time steps are\nsufficiently small, and we provide examples demonstrating the necessity of this\nassumption. This result, established without relying on any monotonicity\nconditions, underscores the importance of inertia in dynamic games. In both the\nfinite-player and mean-field settings, we show that MPE correspond to solutions\nof the Nash-Lasry-Lions equation, which is known as the master equation in the\nmean-field case. We exploit this connection to establish the convergence of\ndiscrete-time finite-player games to their mean-field counterpart in short\ntime. Finally, we prove the convergence of finite-player games to their\ncontinuous-time version on every time horizon."}
{"id": "2507.03616", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03616", "abs": "https://arxiv.org/abs/2507.03616", "authors": ["Yingxu Wang", "Siwei Liu", "Jinyuan Fang", "Zaiqiao Meng"], "title": "EvoAgentX: An Automated Framework for Evolving Agentic Workflows", "comment": null, "summary": "Multi-agent systems (MAS) have emerged as a powerful paradigm for\norchestrating large language models (LLMs) and specialized tools to\ncollaboratively address complex tasks. However, existing MAS frameworks often\nrequire manual workflow configuration and lack native support for dynamic\nevolution and performance optimization. In addition, many MAS optimization\nalgorithms are not integrated into a unified framework. In this paper, we\npresent EvoAgentX, an open-source platform that automates the generation,\nexecution, and evolutionary optimization of multi-agent workflows. EvoAgentX\nemploys a modular architecture consisting of five core layers: the basic\ncomponents, agent, workflow, evolving, and evaluation layers. Specifically,\nwithin the evolving layer, EvoAgentX integrates three MAS optimization\nalgorithms, TextGrad, AFlow, and MIPRO, to iteratively refine agent prompts,\ntool configurations, and workflow topologies. We evaluate EvoAgentX on\nHotPotQA, MBPP, and MATH for multi-hop reasoning, code generation, and\nmathematical problem solving, respectively, and further assess it on real-world\ntasks using GAIA. Experimental results show that EvoAgentX consistently\nachieves significant performance improvements, including a 7.44% increase in\nHotPotQA F1, a 10.00% improvement in MBPP pass@1, a 10.00% gain in MATH solve\naccuracy, and an overall accuracy improvement of up to 20.00% on GAIA. The\nsource code is available at: https://github.com/EvoAgentX/EvoAgentX"}
{"id": "2507.04313", "categories": ["math.CO", "math.CA", "math.QA"], "pdf": "https://arxiv.org/pdf/2507.04313", "abs": "https://arxiv.org/abs/2507.04313", "authors": ["Jonathan G. Bradley-Thrush"], "title": "Factorization of Basic Hypergeometric Series", "comment": null, "summary": "The general problem of the factorization of a basic hypergeometric series is\npresented and discussed. The case of the general $_2\\psi_2$ series is examined\nin detail. Connections are found with the theory of basic hypergeometric series\non root systems. Alternative proofs of several well-known summation and\ntransformation formulae, including Gustafson's generalization of Ramanujan's\n$_1\\psi_1$ summation, are obtained incidentally."}
{"id": "2507.04863", "categories": ["math.NT", "math.RA", "12J10, 12F20, 16K40 (primary), 11S15, 16K20 (secondary)"], "pdf": "https://arxiv.org/pdf/2507.04863", "abs": "https://arxiv.org/abs/2507.04863", "authors": ["Ivan D. Chipchakov"], "title": "On function fields of curves over higher local fields and their division LFD-algebras", "comment": "11 pages, no figures", "summary": "Let $K _{m}$ be an $m$-local field with an $m$-th residue field $K _{0}$, for\nsome integer $m > 0$, and let $K/K _{m}$ be a field extension of transcendence\ndegree trd$(K/K _{m}) \\le 1$. This paper shows that if $K _{0}$ is a field of\nfinite Diophantine dimension (for example, a finitely-generated extension of a\nfinite or a pseudo-algebraically closed perfect field $E$), then the absolute\nBrauer $p$-dimension abrd$_{p}(K)$ of $K$ is finite, for every prime number\n$p$. Thus it turns out that if $R$ is an associative locally finite-dimensional\n(abbr., LFD) central division $K$-algebra, then it is a normally locally finite\nalgebra over $K$, that is, every nonempty finite subset $Y$ of $R$ is contained\nin a finite-dimensional central $K$-subalgebra $\\mathcal{R}_{Y}$ of $R$."}
{"id": "2507.03450", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03450", "abs": "https://arxiv.org/abs/2507.03450", "authors": ["Antonio Emanuele Cinà", "Maura Pintor", "Luca Demetrio", "Ambra Demontis", "Battista Biggio", "Fabio Roli"], "title": "Evaluating the Evaluators: Trust in Adversarial Robustness Tests", "comment": null, "summary": "Despite significant progress in designing powerful adversarial evasion\nattacks for robustness verification, the evaluation of these methods often\nremains inconsistent and unreliable. Many assessments rely on mismatched\nmodels, unverified implementations, and uneven computational budgets, which can\nlead to biased results and a false sense of security. Consequently, robustness\nclaims built on such flawed testing protocols may be misleading and give a\nfalse sense of security. As a concrete step toward improving evaluation\nreliability, we present AttackBench, a benchmark framework developed to assess\nthe effectiveness of gradient-based attacks under standardized and reproducible\nconditions. AttackBench serves as an evaluation tool that ranks existing attack\nimplementations based on a novel optimality metric, which enables researchers\nand practitioners to identify the most reliable and effective attack for use in\nsubsequent robustness evaluations. The framework enforces consistent testing\nconditions and enables continuous updates, making it a reliable foundation for\nrobustness verification."}
{"id": "2507.04585", "categories": ["math.OC", "91A15, 91A65, 93E20"], "pdf": "https://arxiv.org/pdf/2507.04585", "abs": "https://arxiv.org/abs/2507.04585", "authors": ["Na Xiang", "Jingtao Shi"], "title": "Robust Incentive Stackelberg Mean Field Stochastic Linear-Quadratic Differential Game with Model Uncertainty", "comment": "50 pages, 9 figures", "summary": "This paper investigates a robust incentive Stackelberg stochastic\ndifferential game problem for a linear-quadratic mean field system, where the\nmodel uncertainty appears in the drift term of the leader's state equation.\nMoreover, both the state average and control averages enter into the leader's\ndynamics and cost functional. Based on the zero-sum game approach, mean field\napproximation and duality theory, firstly the representation of the leader's\nlimiting cost functional and the closed-loop representation of decentralized\nopen-loop saddle points are given, via decoupling methods. Then by convex\nanalysis and the variational method, the decentralized strategies of the\nfollowers' auxiliary limiting problems and the corresponding consistency\ncondition system are derived. Finally, applying decoupling technique, the\nleader's approximate incentive strategy set is obtained, under which the\nasymptotical robust incentive optimality of the decentralized mean field\nstrategy is verified. A numerical example is given to illustrate the\ntheoretical results."}
{"id": "2507.03637", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03637", "abs": "https://arxiv.org/abs/2507.03637", "authors": ["Francesca Da Ros", "Michael Soprano", "Luca Di Gaspero", "Kevin Roitero"], "title": "Large Language Models for Combinatorial Optimization: A Systematic Review", "comment": null, "summary": "This systematic review explores the application of Large Language Models\n(LLMs) in Combinatorial Optimization (CO). We report our findings using the\nPreferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA)\nguidelines. We conduct a literature search via Scopus and Google Scholar,\nexamining over 2,000 publications. We assess publications against four\ninclusion and four exclusion criteria related to their language, research\nfocus, publication year, and type. Eventually, we select 103 studies. We\nclassify these studies into semantic categories and topics to provide a\ncomprehensive overview of the field, including the tasks performed by LLMs, the\narchitectures of LLMs, the existing datasets specifically designed for\nevaluating LLMs in CO, and the field of application. Finally, we identify\nfuture directions for leveraging LLMs in this field."}
{"id": "2507.04394", "categories": ["math.CO", "05C50"], "pdf": "https://arxiv.org/pdf/2507.04394", "abs": "https://arxiv.org/abs/2507.04394", "authors": ["Annegret Seibt"], "title": "Witnessing and guiding sets of tangles", "comment": "20 pages, no figures", "summary": "Tangles o er a way to indirectly but precisely capture cluster-like though\npossibly fuzzy substructures in discrete data. In this paper, we analyze\nwitnessing and guiding sets of tangles that can help to find proper cluster\ncandidates for given tangles. We show that every k-tangle has a witnessing set\nwhose size is bounded in an exponential function in k which improves a result\nof Grohe and Schweizer. Further, we generalize a result of Diestel, Elbracht\nand Jacobs by providing a characterization of tangles that have a guiding\nfunction of some given reliability."}
{"id": "2507.04980", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.04980", "abs": "https://arxiv.org/abs/2507.04980", "authors": ["Francesco Zerman"], "title": "Quaternionic Kolyvagin systems and Iwasawa theory for Hida families", "comment": "34 pages", "summary": "We build a modified universal Kolyvagin system for the Galois representation\nattached to a Hida family of modular forms, starting from the big Heegner point\nEuler system of Longo--Vigni built in towers of Shimura curves. We generalize\nthe work of B\\\"uy\\\"ukboduk to a quaternionic setting, relaxing the classical\n\\emph{Heegner hypothesis} on the tame conductor of the family. As a byproduct\nof this construction, we give a proof of one divisibility of the anticyclotomic\nIwasawa main conjecture for Hida families."}
{"id": "2507.03607", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.03607", "abs": "https://arxiv.org/abs/2507.03607", "authors": ["Cédric Bonhomme", "Alexandre Dulaunoy"], "title": "VLAI: A RoBERTa-Based Model for Automated Vulnerability Severity Classification", "comment": "This paper is a preprint for the 25V4C-TC: 2025 Vulnerability\n  Forecasting Technical Colloquia. Darwin College Cambridge, UK, September\n  25-26, 2025", "summary": "This paper presents VLAI, a transformer-based model that predicts software\nvulnerability severity levels directly from text descriptions. Built on\nRoBERTa, VLAI is fine-tuned on over 600,000 real-world vulnerabilities and\nachieves over 82% accuracy in predicting severity categories, enabling faster\nand more consistent triage ahead of manual CVSS scoring. The model and dataset\nare open-source and integrated into the Vulnerability-Lookup service."}
{"id": "2507.04611", "categories": ["math.OC", "93E20, 91G10, 91G80, 60H30"], "pdf": "https://arxiv.org/pdf/2507.04611", "abs": "https://arxiv.org/abs/2507.04611", "authors": ["Xiaoqing Liang", "Jie Xiong", "Ying Yang"], "title": "Equilibrium Strategies for the N-agent Mean-Variance Investment Problem over a Random Horizon", "comment": null, "summary": "We study equilibrium feedback strategies for a family of dynamic\nmean-variance problems with competition among a large group of agents. We\nassume that the time horizon is random and each agent's risk aversion depends\ndynamically on the current wealth. We consider both the finite population game\nand the corresponding mean-field one. Each agent can invest in a risk-free\nasset and a specific individual stock, which is correlated with other stocks by\na common noise. By applying stochastic control theory, we derive the extended\nHamilton-Jacobi-Bellman (HJB) system of equations for both $n$-agent and\nmean-field games. Under an exponentially distributed random horizon, we\nexplicitly obtain the equilibrium feedback strategies and the value functions\nin both cases. Our results show that the agent's equilibrium feedback strategy\ndepends not only on his/her current wealth but also on the wealth of other\ncompetitors. Moreover, when the risk aversion is state-independent and the\nrisk-free interest rate is set to zero, the equilibrium strategies degenerate\nto constants, which is identical to the unique equilibrium obtained in\n\\citet{lacker2019mean} with exponential risk preferences; when the competition\nparameter goes to zero and the risk aversion equals some specific value, the\nequilibrium strategies coincide with the ones derived in\n\\citet{landriault2018equilibrium}."}
{"id": "2507.03682", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03682", "abs": "https://arxiv.org/abs/2507.03682", "authors": ["Rebekah A. Gelpí", "Eric Xue", "William A. Cunningham"], "title": "Towards Machine Theory of Mind with Large Language Model-Augmented Inverse Planning", "comment": null, "summary": "We propose a hybrid approach to machine Theory of Mind (ToM) that uses large\nlanguage models (LLMs) as a mechanism for generating hypotheses and likelihood\nfunctions with a Bayesian inverse planning model that computes posterior\nprobabilities for an agent's likely mental states given its actions. Bayesian\ninverse planning models can accurately predict human reasoning on a variety of\nToM tasks, but these models are constrained in their ability to scale these\npredictions to scenarios with a large number of possible hypotheses and\nactions. Conversely, LLM-based approaches have recently demonstrated promise in\nsolving ToM benchmarks, but can exhibit brittleness and failures on reasoning\ntasks even when they pass otherwise structurally identical versions. By\ncombining these two methods, this approach leverages the strengths of each\ncomponent, closely matching optimal results on a task inspired by prior inverse\nplanning models and improving performance relative to models that utilize LLMs\nalone or with chain-of-thought prompting, even with smaller LLMs that typically\nperform poorly on ToM tasks. We also exhibit the model's potential to predict\nmental states on open-ended tasks, offering a promising direction for future\ndevelopment of ToM models and the creation of socially intelligent generative\nagents."}
{"id": "2507.04488", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.04488", "abs": "https://arxiv.org/abs/2507.04488", "authors": ["Dan Hefetz", "Michael Krivelevich"], "title": "The Hamilton cycle space of random regular graphs and randomly perturbed graphs", "comment": "arXiv admin note: substantial text overlap with arXiv:2506.19731", "summary": "The cycle space of a graph $G$, denoted $C(G)$, is a vector space over\n${\\mathbb F}_2$, spanned by all incidence vectors of edge-sets of cycles of\n$G$. If $G$ has $n$ vertices, then $C_n(G)$ is the subspace of $C(G)$, spanned\nby the incidence vectors of Hamilton cycles of $G$. We prove that\nasymptotically almost surely $C_n(G_{n,d}) = C(G_{n,d})$ holds whenever $n$ is\nodd and $d$ is a sufficiently large (even) integer. This extends (though with a\nweaker bound on $d$) the well-known result asserting that $G_{n,d}$ is\nasymptotically almost surely Hamiltonian for every $d \\geq 3$ (but not for $d <\n3$). Since $n$ being odd mandates that $d$ be even, somewhat limiting the\ngenerality of our result, we also prove that if $n$ is even and $d$ is any\nsufficiently large integer, then asymptotically almost surely $C_{n-1}(G_{n,d})\n= C(G_{n,d})$.\n  An influential result of Bohman, Frieze, and Martin asserts that if $H$ is an\n$n$-vertex graph with minimum degree at least $\\delta n$ for some constant\n$\\delta > 0$, and $G \\sim \\mathbb{G}(n, C/n)$, where $C := C(\\delta)$ is a\nsufficiently large constant, then $H \\cup G$ is asymptotically almost surely\nHamiltonian. We strengthen this result by proving that the same assumptions on\n$H$ and $G$ ensure that $C_n(H \\cup G) = C(H \\cup G)$ holds asymptotically\nalmost surely."}
{"id": "2507.05021", "categories": ["math.NT", "11F67 (primary), 11G40 (secondary)"], "pdf": "https://arxiv.org/pdf/2507.05021", "abs": "https://arxiv.org/abs/2507.05021", "authors": ["Xavier Guitart", "Santiago Molina"], "title": "Periods of modular forms and applications to the conjectures of Oda and of Prasanna-Venkatesh", "comment": "44 pages", "summary": "We establish several formulas relating periods of modular forms on quaternion\nalgebras over number fields to special values of L-functions. Our main inputs\nare the cohomological techniques for working with periods introduced in\n[Mol21], along with explicit versions of the Waldspurger formula due to\nCai-Shu-Tian. We work in general even positive weights; when specialized to\nparallel weight 2, our formulas provide partial evidence for the conjectures of\nOda and of Prasanna-Venkatesh in the case of forms associated to elliptic\ncurves."}
{"id": "2507.03619", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.03619", "abs": "https://arxiv.org/abs/2507.03619", "authors": ["Ruikai Zhou", "Kang Yang", "Xun Chen", "Wendy Hui Wang", "Guanhong Tao", "Jun Xu"], "title": "Blackbox Dataset Inference for LLM", "comment": null, "summary": "Today, the training of large language models (LLMs) can involve personally\nidentifiable information and copyrighted material, incurring dataset misuse. To\nmitigate the problem of dataset misuse, this paper explores \\textit{dataset\ninference}, which aims to detect if a suspect model $\\mathcal{M}$ used a victim\ndataset $\\mathcal{D}$ in training. Previous research tackles dataset inference\nby aggregating results of membership inference attacks (MIAs) -- methods to\ndetermine whether individual samples are a part of the training dataset.\nHowever, restricted by the low accuracy of MIAs, previous research mandates\ngrey-box access to $\\mathcal{M}$ to get intermediate outputs (probabilities,\nloss, perplexity, etc.) for obtaining satisfactory results. This leads to\nreduced practicality, as LLMs, especially those deployed for profits, have\nlimited incentives to return the intermediate outputs.\n  In this paper, we propose a new method of dataset inference with only\nblack-box access to the target model (i.e., assuming only the text-based\nresponses of the target model are available). Our method is enabled by two sets\nof locally built reference models, one set involving $\\mathcal{D}$ in training\nand the other not. By measuring which set of reference model $\\mathcal{M}$ is\ncloser to, we determine if $\\mathcal{M}$ used $\\mathcal{D}$ for training.\nEvaluations of real-world LLMs in the wild show that our method offers high\naccuracy in all settings and presents robustness against bypassing attempts."}
{"id": "2507.04670", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.04670", "abs": "https://arxiv.org/abs/2507.04670", "authors": ["Uday Talwar", "Meredith K. Kupinski", "Afrooz Jalilzadeh"], "title": "Riemannian Inexact Gradient Descent for Quadratic Discrimination", "comment": "27 pages, 6 figures, 2 tables", "summary": "We propose an inexact optimization algorithm on Riemannian manifolds,\nmotivated by quadratic discrimination tasks in high-dimensional,\nlow-sample-size (HDLSS) imaging settings. In such applications, gradient\nevaluations are often biased due to limited sample sizes. To address this, we\nintroduce a novel Riemannian optimization algorithm that is robust to inexact\ngradient information and prove an $\\mathcal O(1/K)$ convergence rate under\nstandard assumptions. We also present a line search variant that requires\naccess to function values but not exact gradients, maintaining the same\nconvergence rate and ensuring sufficient descent. The algorithm is tailored to\nthe Grassmann manifold by leveraging its geometric structure, and its\nconvergence rate is validated numerically. A simulation of heteroscedastic\nimages shows that when bias is introduced into the problem, both intentionally\nand through estimation of the covariance matrix, the detection performance of\nthe algorithm solution is comparable to when true gradients are used in the\noptimization. The optimal subspace learned via the algorithm encodes\ninterpretable patterns and shows qualitative similarity to known optimal\nsolutions. By ensuring robust convergence and interpretability, our algorithm\noffers a compelling tool for manifold-based dimensionality reduction and\ndiscrimination in high-dimensional image data settings."}
{"id": "2507.03697", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03697", "abs": "https://arxiv.org/abs/2507.03697", "authors": ["Qika Lin", "Fangzhi Xu", "Hao Lu", "Kai He", "Rui Mao", "Jun Liu", "Erik Cambria", "Mengling Feng"], "title": "Towards Unified Neurosymbolic Reasoning on Knowledge Graphs", "comment": "15 pages", "summary": "Knowledge Graph (KG) reasoning has received significant attention in the\nfields of artificial intelligence and knowledge engineering, owing to its\nability to autonomously deduce new knowledge and consequently enhance the\navailability and precision of downstream applications. However, current methods\npredominantly concentrate on a single form of neural or symbolic reasoning,\nfailing to effectively integrate the inherent strengths of both approaches.\nFurthermore, the current prevalent methods primarily focus on addressing a\nsingle reasoning scenario, presenting limitations in meeting the diverse\ndemands of real-world reasoning tasks. Unifying the neural and symbolic\nmethods, as well as diverse reasoning scenarios in one model is challenging as\nthere is a natural representation gap between symbolic rules and neural\nnetworks, and diverse scenarios exhibit distinct knowledge structures and\nspecific reasoning objectives. To address these issues, we propose a unified\nneurosymbolic reasoning framework, namely Tunsr, for KG reasoning. Tunsr first\nintroduces a consistent structure of reasoning graph that starts from the query\nentity and constantly expands subsequent nodes by iteratively searching\nposterior neighbors. Based on it, a forward logic message-passing mechanism is\nproposed to update both the propositional representations and attentions, as\nwell as first-order logic (FOL) representations and attentions of each node. In\nthis way, Tunsr conducts the transformation of merging multiple rules by\nmerging possible relations at each step. Finally, the FARI algorithm is\nproposed to induce FOL rules by constantly performing attention calculations\nover the reasoning graph. Extensive experimental results on 19 datasets of four\nreasoning scenarios (transductive, inductive, interpolation, and extrapolation)\ndemonstrate the effectiveness of Tunsr."}
{"id": "2507.04552", "categories": ["math.CO", "05A15"], "pdf": "https://arxiv.org/pdf/2507.04552", "abs": "https://arxiv.org/abs/2507.04552", "authors": ["Dean Rubine"], "title": "Hyper-Catalan and Geode Recurrences and Three Conjectures of Wildberger", "comment": null, "summary": "The hyper-Catalan number $C[m_2,m_3,m_4,\\ldots]$ counts the number of\nsubdivisions of a roofed polygon into $m_2$ triangles, $m_3$ quadrilaterals,\n$m_4$ pentagons, etc. Its closed form has been known since Erd\\'elyi and\nEtherington, 1940. In 2025, Wildberger and Rubine showed its generating sum\n$\\mathbf{S}[t_2,t_3,t_4,\\ldots]$ is a zero of the general geometric univariate\npolynomial. We use that to derive a recurrence for hyper-Catalans, which\nexpresses each in terms of other hyper-Catalans with smaller indices,\ngeneralizing the well-known Catalan convolution sum.\n  Wildberger notes the factorization $\\mathbf{S}-1=(t_2 + t_3 + t_4 +\n\\ldots)\\mathbf{G}$, where the factor $\\mathbf{G}$ is called the Geode. We\nderive a recurrence that let us express the Geode coefficients in terms of\nother hyper-Catalan and Geode coefficients, and ultimately in terms of\nhyper-Catalans alone. We use it to prove three conjectures of Wildberger, all\nclosed forms for special cases of elements of $\\mathbf{G}$. While the\nrecurrence allows us to expand each Geode coefficient as an integer combination\nof hyper-Catalans, enabling calculation, a closed-form for the general Geode\ncoefficient remains unknown, as does what it counts."}
{"id": "2507.03636", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.03636", "abs": "https://arxiv.org/abs/2507.03636", "authors": ["Xiaodong Wu", "Xiangman Li", "Qi Li", "Jianbing Ni", "Rongxing Lu"], "title": "SecureT2I: No More Unauthorized Manipulation on AI Generated Images from Prompts", "comment": null, "summary": "Text-guided image manipulation with diffusion models enables flexible and\nprecise editing based on prompts, but raises ethical and copyright concerns due\nto potential unauthorized modifications. To address this, we propose SecureT2I,\na secure framework designed to prevent unauthorized editing in diffusion-based\ngenerative models. SecureT2I is compatible with both general-purpose and\ndomain-specific models and can be integrated via lightweight fine-tuning\nwithout architectural changes. We categorize images into a permit set and a\nforbid set based on editing permissions. For the permit set, the model learns\nto perform high-quality manipulations as usual. For the forbid set, we\nintroduce training objectives that encourage vague or semantically ambiguous\noutputs (e.g., blurred images), thereby suppressing meaningful edits. The core\nchallenge is to block unauthorized editing while preserving editing quality for\npermitted inputs. To this end, we design separate loss functions that guide\nselective editing behavior. Extensive experiments across multiple datasets and\nmodels show that SecureT2I effectively degrades manipulation quality on\nforbidden images while maintaining performance on permitted ones. We also\nevaluate generalization to unseen inputs and find that SecureT2I consistently\noutperforms baselines. Additionally, we analyze different vagueness strategies\nand find that resize-based degradation offers the best trade-off for secure\nmanipulation control."}
{"id": "2507.04672", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.04672", "abs": "https://arxiv.org/abs/2507.04672", "authors": ["Tomonari Kitahara"], "title": "A bound for the number of basic feasible solutions generated by the simplex method with the maximum distance rule", "comment": "10pages, comments are welcomed!", "summary": "In this paper, we consider the number of different basic solutions generated\nby the simplex method with the maximum distance rule. The pivoting rule was\nrecently proposed, and in some cases, it was reported to be more efficient than\nthe renowned steepest edge rule. If the problem is nondegenerate, these results\nprovide bounds on the number of iterations. As far as we know, they are the\nfirst theoretical bounds for the maximum distance rule."}
{"id": "2507.03722", "categories": ["cs.AI", "q-bio.OT"], "pdf": "https://arxiv.org/pdf/2507.03722", "abs": "https://arxiv.org/abs/2507.03722", "authors": ["Ruian Ke", "Ruy M. Ribeiro"], "title": "Roadmap for using large language models (LLMs) to accelerate cross-disciplinary research with an example from computational biology", "comment": null, "summary": "Large language models (LLMs) are powerful artificial intelligence (AI) tools\ntransforming how research is conducted. However, their use in research has been\nmet with skepticism, due to concerns about hallucinations, biases and potential\nharms to research. These emphasize the importance of clearly understanding the\nstrengths and weaknesses of LLMs to ensure their effective and responsible use.\nHere, we present a roadmap for integrating LLMs into cross-disciplinary\nresearch, where effective communication, knowledge transfer and collaboration\nacross diverse fields are essential but often challenging. We examine the\ncapabilities and limitations of LLMs and provide a detailed computational\nbiology case study (on modeling HIV rebound dynamics) demonstrating how\niterative interactions with an LLM (ChatGPT) can facilitate interdisciplinary\ncollaboration and research. We argue that LLMs are best used as augmentative\ntools within a human-in-the-loop framework. Looking forward, we envisage that\nthe responsible use of LLMs will enhance innovative cross-disciplinary research\nand substantially accelerate scientific discoveries."}
{"id": "2507.04579", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.04579", "abs": "https://arxiv.org/abs/2507.04579", "authors": ["Jian Wang", "Wenbin Wang", "Weihua Yang"], "title": "Hypergraph Turán problem of the generalized triangle with bounded matching number", "comment": null, "summary": "Let $\\mathcal{H}$ be a 3-graph on $n$ vertices. The matching number\n$\\nu(\\mathcal{H})$ is defined as the maximum number of disjoint edges in\n$\\mathcal{H}$. The generalized triangle $F_5$ is a 3-graph on the vertex set\n$\\{a,b,c,d,e\\}$ with the edge set $\\{abc, abd,cde\\}$. In this paper, we showed\nthat an $F_5$-free 3-graph $\\mathcal{H}$ with matching number at most $s$ has\nat most $s\\lfloor (n-s)^2/4\\rfloor$ edges for $n\\geq 30(s+1)$ and $s\\geq 3$.\nFor the proof, we establish a 2-colored version of Mantel's theorem, which may\nbe of independent interests."}
{"id": "2507.03646", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.03646", "abs": "https://arxiv.org/abs/2507.03646", "authors": ["Xiaodong Wu", "Tianyi Tang", "Xiangman Li", "Jianbing Ni", "Yong Yu"], "title": "When There Is No Decoder: Removing Watermarks from Stable Diffusion Models in a No-box Setting", "comment": "arXiv admin note: text overlap with arXiv:2408.02035", "summary": "Watermarking has emerged as a promising solution to counter harmful or\ndeceptive AI-generated content by embedding hidden identifiers that trace\ncontent origins. However, the robustness of current watermarking techniques is\nstill largely unexplored, raising critical questions about their effectiveness\nagainst adversarial attacks. To address this gap, we examine the robustness of\nmodel-specific watermarking, where watermark embedding is integrated with\ntext-to-image generation in models like latent diffusion models. We introduce\nthree attack strategies: edge prediction-based, box blurring, and\nfine-tuning-based attacks in a no-box setting, where an attacker does not\nrequire access to the ground-truth watermark decoder. Our findings reveal that\nwhile model-specific watermarking is resilient against basic evasion attempts,\nsuch as edge prediction, it is notably vulnerable to blurring and\nfine-tuning-based attacks. Our best-performing attack achieves a reduction in\nwatermark detection accuracy to approximately 47.92\\%. Additionally, we perform\nan ablation study on factors like message length, kernel size and decoder\ndepth, identifying critical parameters influencing the fine-tuning attack's\nsuccess. Finally, we assess several advanced watermarking defenses, finding\nthat even the most robust methods, such as multi-label smoothing, result in\nwatermark extraction accuracy that falls below an acceptable level when\nsubjected to our no-box attacks."}
{"id": "2507.04694", "categories": ["math.OC", "65K05, 90C06, 90C30, 90C33"], "pdf": "https://arxiv.org/pdf/2507.04694", "abs": "https://arxiv.org/abs/2507.04694", "authors": ["Jia Wang", "Andreas Themelis", "Ivan Markovsky", "Panagiotis Patrinos"], "title": "A Lasry-Lions envelope approach for mathematical programs with complementarity constraints", "comment": null, "summary": "We propose a homotopy method for solving mathematical programs with\ncomplementarity constraints (CCs). The indicator function of the CCs is relaxed\nby a Lasry-Lions double envelope, an extension of the Moreau envelope that\nenjoys an additional smoothness property that makes it amenable to fast\noptimization algorithms. The proposed algorithm mimics the behavior of homotopy\nmethods for systems of nonlinear equations or penalty methods for constrained\noptimization: it solves a sequence of smooth subproblems that progressively\napproximate the original problem, using the solution of each subproblem as the\nstarting point for the next one. In the limiting setting, we establish the\nconvergence to Mordukhovich and Clarke stationary points. We also provide a\nworst-case complexity analysis for computing an approximate stationary point.\nPreliminary numerical results on a suite of benchmark problems demonstrate the\neffectiveness of the proposed approach."}
{"id": "2507.03726", "categories": ["cs.AI", "cs.CL", "cs.IR", "I.2"], "pdf": "https://arxiv.org/pdf/2507.03726", "abs": "https://arxiv.org/abs/2507.03726", "authors": ["Riya Naik", "Ashwin Srinivasan", "Swati Agarwal", "Estrid He"], "title": "Agent-Based Detection and Resolution of Incompleteness and Ambiguity in Interactions with Large Language Models", "comment": "14 pages. arXiv admin note: text overlap with arXiv:2503.17936", "summary": "Many of us now treat LLMs as modern-day oracles asking it almost any kind of\nquestion. However, consulting an LLM does not have to be a single turn\nactivity. But long multi-turn interactions can get tedious if it is simply to\nclarify contextual information that can be arrived at through reasoning. In\nthis paper, we examine the use of agent-based architecture to bolster LLM-based\nQuestion-Answering systems with additional reasoning capabilities. We examine\nthe automatic resolution of potential incompleteness or ambiguities in\nquestions by transducers implemented using LLM-based agents. We focus on\nseveral benchmark datasets that are known to contain questions with these\ndeficiencies to varying degrees. We equip different LLMs (GPT-3.5-Turbo and\nLlama-4-Scout) with agents that act as specialists in detecting and resolving\ndeficiencies of incompleteness and ambiguity. The agents are implemented as\nzero-shot ReAct agents. Rather than producing an answer in a single step, the\nmodel now decides between 3 actions a) classify b) resolve c) answer. Action a)\ndecides if the question is incomplete, ambiguous, or normal. Action b)\ndetermines if any deficiencies identified can be resolved. Action c) answers\nthe resolved form of the question. We compare the use of LLMs with and without\nthe use of agents with these components. Our results show benefits of agents\nwith transducer 1) A shortening of the length of interactions with human 2) An\nimprovement in the answer quality and 3) Explainable resolution of deficiencies\nin the question. On the negative side we find while it may result in additional\nLLM invocations and in some cases, increased latency. But on tested datasets,\nthe benefits outweigh the costs except when questions already have sufficient\ncontext. Suggesting the agent-based approach could be a useful mechanism to\nharness the power of LLMs to develop more robust QA systems."}
{"id": "2507.04581", "categories": ["math.CO", "cs.DM", "05C35, 05C38, 05D40"], "pdf": "https://arxiv.org/pdf/2507.04581", "abs": "https://arxiv.org/abs/2507.04581", "authors": ["He Guo"], "title": "Short rainbow cycles for families of small edge sets", "comment": "9 pages", "summary": "In 2019, Aharoni proposed a conjecture generalizing the Caceetta-H\\\"aggkvist\nconjecture: if an $n$-vertex graph $G$ admits an edge coloring (not necessarily\nproper) with $n$ colors such that each color class has size at least $r$, then\n$G$ contains a rainbow cycle of length at most $\\lceil n/r\\rceil$. Recent works\n\\cite{AG2023,ABCGZ2023,G2025} have shown that if a constant fraction of the\ncolor classes are non-star, then the rainbow girth is $O(\\log n)$. In this\nnote, we extend these results, and we show that even a small fraction of\nnon-star color classes suffices to ensure logarithmic rainbow girth. We also\nprove that the logarithmic bound is of the right order of magnitude. Moreover,\nwe determine the threshold fraction between the types of color classes at which\nthe rainbow girth transitions from linear to logarithmic."}
{"id": "2507.03694", "categories": ["cs.CR", "cs.CE", "cs.ET"], "pdf": "https://arxiv.org/pdf/2507.03694", "abs": "https://arxiv.org/abs/2507.03694", "authors": ["Jovonni L. PHarr"], "title": "Willchain: Decentralized, Privacy-Preserving, Self-Executing, Digital Wills", "comment": null, "summary": "This work presents a novel decentralized protocol for digital estate planning\nthat integrates advances distributed computing, and cryptography. The original\nproof-of-concept was constructed using purely solidity contracts. Since then,\nwe have enhanced the implementation into a layer-1 protocol that uses modern\ninterchain communication to connect several heterogeneous chain types. A key\ncontribution of this research is the implementation of several modern\ncryptographic primitives to support various forms of claims for information\nvalidation. These primitives introduce an unmatched level of privacy to the\nprocess of digital inheritance. We also demonstrate on a set of heterogeneous\nsmart contracts, following the same spec, on each chain to serve as entry\npoints, gateways, or bridge contracts that are invoked via a path from the will\nmodule on our protocol, to the contract. This ensures a fair and secure\ndistribution of digital assets in accordance with the wishes of the decedent\nwithout the requirement of moving their funds. This research further extends\nits innovations with a user interaction model, featuring a check-in system and\naccount abstraction process, which enhances flexibility and user-friendliness\nwithout compromising on security. By developing a dedicated permissionless\nblockchain that is secured by a network of validators, and interchain relayers,\nthe proposed protocol signifies a transformation in the digital estate planning\nindustry and illustrates the potential of blockchain technology in\nrevolutionizing traditional legal and personal spheres. Implementing a\ncryptoeconomic network at the core of inheritance planning allows for unique\nincentive compatible economic mechanisms to be constructed."}
{"id": "2507.04712", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.04712", "abs": "https://arxiv.org/abs/2507.04712", "authors": ["Shoju Enami", "Kenji Kashima"], "title": "Mutual Information Optimal Control of Discrete-Time Linear Systems", "comment": null, "summary": "In this paper, we formulate a mutual information optimal control problem\n(MIOCP) for discrete-time linear systems. This problem can be regarded as an\nextension of a maximum entropy optimal control problem (MEOCP). Differently\nfrom the MEOCP where the prior is fixed to the uniform distribution, the MIOCP\noptimizes the policy and prior simultaneously. As analytical results, under the\npolicy and prior classes consisting of Gaussian distributions, we derive the\noptimal policy and prior of the MIOCP with the prior and policy fixed,\nrespectively. Using the results, we propose an alternating minimization\nalgorithm for the MIOCP. Through numerical experiments, we discuss how our\nproposed algorithm works."}
{"id": "2507.03775", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03775", "abs": "https://arxiv.org/abs/2507.03775", "authors": ["Hiba Bederina"], "title": "Optimizing UAV Trajectories via a Simplified Close Enough TSP Approach", "comment": null, "summary": "This article explores an approach to addressing the Close Enough Traveling\nSalesman Problem (CETSP). The objective is to streamline the mathematical\nformulation by introducing reformulations that approximate the Euclidean\ndistances and simplify the objective function. Additionally, the use of convex\nsets in the constraint design offers computational benefits. The proposed\nmethodology is empirically validated on real-world CETSP instances, with the\naid of computational strategies such as a fragmented CPLEX-based approach.\nResults demonstrate its effectiveness in managing computational resources\nwithout compromising solution quality. Furthermore, the article analyzes the\nbehavior of the proposed mathematical formulations, providing comprehensive\ninsights into their performance."}
{"id": "2507.04698", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.04698", "abs": "https://arxiv.org/abs/2507.04698", "authors": ["Qi Fang", "Shishuo Fu", "Sergey Kitaev", "Haijun Li"], "title": "On fourteen equidistribution conjectures of Lv and Zhang and monotone mesh patterns with corner shadings", "comment": null, "summary": "Three complementation-like involutions are constructed on permutations to\nprove, and in some cases generalize, all remaining fourteen joint symmetric\nequidistribution conjectures of Lv and Zhang. Further enumerative results are\nobtained for several classes of (mesh) pattern-avoiding permutations, where the\nshadings of all involved mesh patterns are restricted to an opposing pair of\ncorners."}
{"id": "2507.03773", "categories": ["cs.CR", "cs.DC", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.03773", "abs": "https://arxiv.org/abs/2507.03773", "authors": ["Yibo He", "Cunjian Huang", "Xianmiao Qu", "Hongdeng Chen", "Wei Yang", "Tao Xie"], "title": "RVISmith: Fuzzing Compilers for RVV Intrinsics", "comment": "To appear in ACM CCS 2025", "summary": "Modern processors are equipped with single instruction multiple data (SIMD)\ninstructions for fine-grained data parallelism. Compiler auto-vectorization\ntechniques that target SIMD instructions face performance limitations due to\ninsufficient information available at compile time, requiring programmers to\nmanually manipulate SIMD instructions. SIMD intrinsics, a type of built-in\nfunction provided by modern compilers, enable programmers to manipulate SIMD\ninstructions within high-level programming languages. Bugs in compilers for\nSIMD intrinsics can introduce potential threats to software security, producing\nunintended calculation results, data loss, program crashes, etc.\n  To detect bugs in compilers for SIMD intrinsics, we propose RVISmith, a\nrandomized fuzzer that generates well-defined C programs that include various\ninvocation sequences of RVV (RISC-V Vector Extension) intrinsics. We design\nRVISmith to achieve the following objectives: (i) achieving high intrinsic\ncoverage, (ii) improving sequence variety, and (iii) without known undefined\nbehaviors. We implement RVISmith based on the ratified RVV intrinsic\nspecification and evaluate our approach with three modern compilers: GCC, LLVM,\nand XuanTie. Experimental results show that RVISmith achieves 11.5 times higher\nintrinsic coverage than the state-of-the-art fuzzer for RVV intrinsics. By\ndifferential testing that compares results across different compilers,\noptimizations, and equivalent programs, we detect and report 13 previously\nunknown bugs of the three compilers under test to date. Of these bugs, 10 are\nconfirmed and another 3 are fixed by the compiler developers."}
{"id": "2507.04731", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.04731", "abs": "https://arxiv.org/abs/2507.04731", "authors": ["Paolo Mason", "Antoine Girard"], "title": "Controllable Sequences of Minimal Length for Discrete-Time Switched Linear Control Systems", "comment": null, "summary": "In this paper, we provide a novel characterization of the reachable set of\ndiscrete-time switched linear control systems and a Kalman-type criterion for\ncontrollability, assuming that the switching parameter can be used as a control\nparameter in addition to the actual control variable. For controllable switched\nlinear control systems it turns out that there always exists a switching\nsequence such that the reachable set of the corresponding linear time-variant\nsystem covers the whole state space after a sufficiently large time. We provide\nestimates on the minimal time guaranteeing this property in terms of the state\ndimension, number of modes and rank of the control matrices, and show that such\nestimates are actually tight in some relevant cases."}
{"id": "2507.03793", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03793", "abs": "https://arxiv.org/abs/2507.03793", "authors": ["Jim O'Connor", "Gary B. Parker", "Mustafa Bugti"], "title": "Learning Dark Souls Combat Through Pixel Input With Neuroevolution", "comment": "IEEE Conference on Games 2025", "summary": "This paper investigates the application of Neuroevolution of Augmenting\nTopologies (NEAT) to automate gameplay in Dark Souls, a notoriously challenging\naction role-playing game characterized by complex combat mechanics, dynamic\nenvironments, and high-dimensional visual inputs. Unlike traditional\nreinforcement learning or game playing approaches, our method evolves neural\nnetworks directly from raw pixel data, circumventing the need for explicit\ngame-state information. To facilitate this approach, we introduce the Dark\nSouls API (DSAPI), a novel Python framework leveraging real-time computer\nvision techniques for extracting critical game metrics, including player and\nenemy health states. Using NEAT, agents evolve effective combat strategies for\ndefeating the Asylum Demon, the game's initial boss, without predefined\nbehaviors or domain-specific heuristics. Experimental results demonstrate that\nevolved agents achieve up to a 35% success rate, indicating the viability of\nneuroevolution in addressing complex, visually intricate gameplay scenarios.\nThis work represents an interesting application of vision-based neuroevolution,\nhighlighting its potential use in a wide range of challenging game environments\nlacking direct API support or well-defined state representations."}
{"id": "2507.04714", "categories": ["math.CO", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.04714", "abs": "https://arxiv.org/abs/2507.04714", "authors": ["Itai Benjamini", "Georgii Zakharov", "Maksim Zhukovskii"], "title": "Majority dynamics on finite trees", "comment": null, "summary": "For an arbitrary finite tree $T$, we find the exact value of the wort-case\nstabilisation time of majority dynamics on $T$. We also prove that for a\nperfect rooted cubic tree $T$ with diameter $D$ and uniformly random initial\nopinions, the dynamics stabilises in time $\\tau\\in(D/4,D/3)$ with high\nprobability."}
{"id": "2507.03993", "categories": ["cs.CR", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03993", "abs": "https://arxiv.org/abs/2507.03993", "authors": ["Dipo Dunsin", "Mohamed Chahine Ghanem", "Eduardo Almeida Palmieri"], "title": "MalVol-25: A Diverse, Labelled and Detailed Volatile Memory Dataset for Malware Detection and Response Testing and Validation", "comment": "6 pages", "summary": "This paper addresses the critical need for high-quality malware datasets that\nsupport advanced analysis techniques, particularly machine learning and agentic\nAI frameworks. Existing datasets often lack diversity, comprehensive labelling,\nand the complexity necessary for effective machine learning and agent-based AI\ntraining. To fill this gap, we developed a systematic approach for generating a\ndataset that combines automated malware execution in controlled virtual\nenvironments with dynamic monitoring tools. The resulting dataset comprises\nclean and infected memory snapshots across multiple malware families and\noperating systems, capturing detailed behavioural and environmental features.\nKey design decisions include applying ethical and legal compliance, thorough\nvalidation using both automated and manual methods, and comprehensive\ndocumentation to ensure replicability and integrity. The dataset's distinctive\nfeatures enable modelling system states and transitions, facilitating RL-based\nmalware detection and response strategies. This resource is significant for\nadvancing adaptive cybersecurity defences and digital forensic research. Its\nscope supports diverse malware scenarios and offers potential for broader\napplications in incident response and automated threat mitigation."}
{"id": "2507.04836", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.04836", "abs": "https://arxiv.org/abs/2507.04836", "authors": ["Andi Bodnariu", "Kristoffer Lindensjö", "Neofytos Rodosthenous"], "title": "Time-inconsistent singular control problems: Reflection and Absolutely continuous controls with exploding rates", "comment": null, "summary": "We study a time-inconsistent singular stochastic control problem for a\ngeneral one-dimensional diffusion, where time-inconsistency arises from a\nnon-exponential discount function. To address this, we adopt a game-theoretic\nframework and study the optimality of a novel class of controls that\nencompasses both traditional singular controls -- responsible for generating\nmultiple jumps and reflective boundaries (strong thresholds) -- and new mild\nthreshold control strategies, which allow for the explosion of the control rate\nin absolutely continuous controls, thereby creating an inaccessible boundary\n(mild threshold) for the controlled process. We establish a general\nverification theorem, formulated in terms of a system of variational\ninequalities, that provides both necessary and sufficient conditions for\nequilibrium within the proposed class of control strategies and their\ncombinations. To demonstrate the applicability of our theoretical results, we\nexamine case studies in inventory management. We show that for certain\nparameter values, the problem admits a strong threshold control equilibrium in\nthe form of Skorokhod reflection. In contrast, for other parameter values, we\nprove that no such equilibrium exists, necessitating the use of our extended\ncontrol class. In the latter case, we explicitly construct an equilibrium using\na mild threshold control strategy with a discontinuous, increasing, and\nexploding rate that induces an inaccessible boundary for the optimally\ncontrolled process, marking the first example of a singular control problem\nwith such a solution structure."}
{"id": "2507.03802", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03802", "abs": "https://arxiv.org/abs/2507.03802", "authors": ["Mayank Kejriwal", "Shilpa Thomas"], "title": "Generating Novelty in Open-World Multi-Agent Strategic Board Games", "comment": "16 pages, shorter version demonstrated in NeurIPS 2020", "summary": "We describe GNOME (Generating Novelty in Open-world Multi-agent\nEnvironments), an experimental platform that is designed to test the\neffectiveness of multi-agent AI systems when faced with \\emph{novelty}. GNOME\nseparates the development of AI gameplaying agents with the simulator, allowing\n\\emph{unanticipated} novelty (in essence, novelty that is not subject to\nmodel-selection bias). Using a Web GUI, GNOME was recently demonstrated at\nNeurIPS 2020 using the game of Monopoly to foster an open discussion on AI\nrobustness and the nature of novelty in real-world environments. In this\narticle, we further detail the key elements of the demonstration, and also\nprovide an overview of the experimental design that is being currently used in\nthe DARPA Science of Artificial Intelligence and Learning for Open-World\nNovelty (SAIL-ON) program to evaluate external teams developing\nnovelty-adaptive gameplaying agents."}
{"id": "2507.04721", "categories": ["math.CO", "cs.DS"], "pdf": "https://arxiv.org/pdf/2507.04721", "abs": "https://arxiv.org/abs/2507.04721", "authors": ["Debojyoti Bhattacharya", "Subhabrata Paul"], "title": "Liar's vertex-edge domination in subclasses of chordal graphs", "comment": null, "summary": "Let $G=(V, E)$ be an undirected graph. The set $N_G[x]=\\{y\\in V|xy\\in E\\}\\cup\n\\{x\\}$ is called the closed neighbourhood of a vertex $x\\in V$ and for an edge\n$e=xy\\in E$, the closed neighbourhood of $e$ is the set $N_G[x]\\cup N_G[y]$,\nwhich is denoted by $N_G[e]$ or $N_G[xy]$. A set $L\\subseteq V$ is called\n\\emph{liar's vertex-edge dominating set} of a graph $G=(V,E)$ if for every\n$e_i\\in E$, $|N_G[e_i]\\cap L|\\geq 2$ and for every pair of distinct edges\n$e_i,e_j\\in E$, $|(N_G[e_i]\\cup N_G[e_j])\\cap L|\\geq 3$. The notion of liar's\nvertex-edge domination arises naturally from some applications in communication\nnetworks. Given a graph $G$, the \\textsc{Minimum Liar's Vertex-Edge Domination\nProblem} (\\textsc{MinLVEDP}) asks to find a liar's vertex-edge dominating set\nof $G$ of minimum cardinality. In this paper, we study this problem from an\nalgorithmic point of view. We design two linear time algorithms for\n\\textsc{MinLVEDP} in block graphs and proper interval graphs, respectively. On\nthe negative side, we show that the decision version of liar's vertex-edge\ndomination problem is NP-complete for undirected path graphs."}
{"id": "2507.04055", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.04055", "abs": "https://arxiv.org/abs/2507.04055", "authors": ["Yufan Chen", "Daoyuan Wu", "Juantao Zhong", "Zicheng Zhang", "Debin Gao", "Shuai Wang", "Yingjiu Li", "Ning Liu"], "title": "Rethinking and Exploring String-Based Malware Family Classification in the Era of LLMs and RAG", "comment": null, "summary": "Malware Family Classification (MFC) aims to identify the fine-grained family\n(e.g., GuLoader or BitRAT) to which a potential malware sample belongs, in\ncontrast to malware detection or sample classification that predicts only an\nYes/No. Accurate family identification can greatly facilitate automated sample\nlabeling and understanding on crowdsourced malware analysis platforms such as\nVirusTotal and MalwareBazaar, which generate vast amounts of data daily. In\nthis paper, we explore and assess the feasibility of using traditional binary\nstring features for MFC in the new era of large language models (LLMs) and\nRetrieval-Augmented Generation (RAG). Specifically, we investigate how\nFamily-Specific String (FSS) features could be utilized in a manner similar to\nRAG to facilitate MFC. To this end, we develop a curated evaluation framework\ncovering 4,347 samples from 67 malware families, extract and analyze over 25\nmillion strings, and conduct detailed ablation studies to assess the impact of\ndifferent design choices in four major modules."}
{"id": "2507.05014", "categories": ["math.OC", "41A15, 47A52, 46G10, 47N10, 93B28, 46N10"], "pdf": "https://arxiv.org/pdf/2507.05014", "abs": "https://arxiv.org/abs/2507.05014", "authors": ["Vincent Guillemet", "Michaël Unser"], "title": "Adaptive Vector-Valued Splines for the Resolution of Inverse Problems", "comment": null, "summary": "We introduce a general framework for the reconstruction of vector-valued\nfunctions from finite and possibly noisy data, acquired through a known\nmeasurement operator. The reconstruction is done by the minimization of a loss\nfunctional formed as the sum of a convex data fidelity functional and a\ntotal-variation-based regularizer involving a suitable matrix L of differential\noperators. Here, the total variation is a norm on the space of vector measures.\nThese are split into two categories: inner, and outer norms. The minimization\nis performed over an infinite-dimensional Banach search space. When the\nmeasurement operator is weakstar-continuous over the search space, our main\nresult is that the solution set of the loss functional is the closed convex\nhull of adaptive L-splines, with fewer knots than the number of measurements.\nWe reveal the effect of the total-variation norms on the structure of the\nsolutions and show that inner norms yield sparser solutions. We also provide an\nexplicit description of the class of admissible measurement operators."}
{"id": "2507.03811", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03811", "abs": "https://arxiv.org/abs/2507.03811", "authors": ["Gianlucca Zuin", "Saulo Mastelini", "Túlio Loures", "Adriano Veloso"], "title": "Leveraging Large Language Models for Tacit Knowledge Discovery in Organizational Contexts", "comment": "8 pages, 4 figures, accepted to International Joint Conference on\n  Neural Networks (IJCNN) 2025", "summary": "Documenting tacit knowledge in organizations can be a challenging task due to\nincomplete initial information, difficulty in identifying knowledgeable\nindividuals, the interplay of formal hierarchies and informal networks, and the\nneed to ask the right questions. To address this, we propose an agent-based\nframework leveraging large language models (LLMs) to iteratively reconstruct\ndataset descriptions through interactions with employees. Modeling knowledge\ndissemination as a Susceptible-Infectious (SI) process with waning infectivity,\nwe conduct 864 simulations across various synthetic company structures and\ndifferent dissemination parameters. Our results show that the agent achieves\n94.9% full-knowledge recall, with self-critical feedback scores strongly\ncorrelating with external literature critic scores. We analyze how each\nsimulation parameter affects the knowledge retrieval process for the agent. In\nparticular, we find that our approach is able to recover information without\nneeding to access directly the only domain specialist. These findings highlight\nthe agent's ability to navigate organizational complexity and capture\nfragmented knowledge that would otherwise remain inaccessible."}
{"id": "2507.04728", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.04728", "abs": "https://arxiv.org/abs/2507.04728", "authors": ["Qi Wu", "Yong Lu"], "title": "Improved bounds on the $H$-rank of a mixed graph in terms of the matching number and fractional matching number", "comment": null, "summary": "A mixed graph $\\widetilde{G}$ is obtained by orienting some edges of a graph\n$G$, where $G$ is the underlying graph of $\\widetilde{G}$. Let\n$r(\\widetilde{G})$ be the $H$-rank of $\\widetilde{G}$. Denote by $r(G)$,\n$\\kappa(G)$, $m(G)$ and $m^{\\ast}(G)$ the rank, the number of even cycles, the\nmatching number and the fractional matching number of $G$, respectively. Zhou\net al. [Discrete Appl. Math. 313 (2022)] proved that $2m(G)-2\\kappa(G)\\leq\nr(G)\\leq 2m(G)+\\rho(G)$, where $\\rho(G)$ is the largest number of disjoint odd\ncycles in $G$. We extend their results to the setting of mixed graphs and prove\nthat $2m(G)-2\\kappa(G)\\leq r(\\widetilde{G}) \\leq 2m^{\\ast}(G)$ for a mixed\ngraph $\\widetilde{G}$. Furthermore, we characterize some classes of mixed\ngraphs with rank $r(\\widetilde{G})=2m(G)-2\\kappa(G)$,\n$r(\\widetilde{G})=2m(G)-2\\kappa(G)+1$ and $r(\\widetilde{G})=2m^{\\ast}(G)$,\nrespectively. Our results also improve those of Chen et al. [Linear Multiliear\nAlgebra. 66 (2018)]. In addition, our results can be applied to signed graphs\nand oriented graphs in some situations."}
{"id": "2507.04077", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.04077", "abs": "https://arxiv.org/abs/2507.04077", "authors": ["Yue Su", "Meng Shen", "Cong Zuo", "Yuzhi Liu", "Liehuang Zhu"], "title": "S-Leak: Leakage-Abuse Attack Against Efficient Conjunctive SSE via s-term Leakage", "comment": "16 pages, 12 figures. Preliminary version. Future journal/conference\n  submission intended", "summary": "Conjunctive Searchable Symmetric Encryption (CSSE) enables secure conjunctive\nsearches over encrypted data. While leakage-abuse attacks (LAAs) against\nsingle-keyword SSE have been extensively studied, their extension to\nconjunctive queries faces a critical challenge: the combinatorial explosion of\ncandidate keyword combinations, leading to enormous time and space overhead for\nattacks. In this paper, we reveal a fundamental vulnerability in\nstate-of-the-art CSSE schemes: s-term leakage, where the keyword with the\nminimal document frequency in a query leaks distinct patterns. We propose\nS-Leak, the first passive attack framework that progressively recovers\nconjunctive queries by exploiting s-term leakage and global leakage. Our key\ninnovation lies in a three-stage approach: identifying the s-term of queries,\npruning low-probability keyword conjunctions, and reconstructing full queries.\nWe propose novel metrics to better assess attacks in conjunctive query\nscenarios. Empirical evaluations on real-world datasets demonstrate that our\nattack is effective in diverse CSSE configurations. When considering 161,700\nconjunctive keyword queries, our attack achieves a 95.15% accuracy in\nrecovering at least one keyword, 82.57% for at least two, 58% for all three\nkeywords, and maintains efficacy against defenses such as SEAL padding and CLRZ\nobfuscation. Our work exposes the underestimated risks of s-term leakage in\npractical SSE deployments and calls for a redesign of leakage models for\nmulti-keyword search scenarios."}
{"id": "2507.05045", "categories": ["math.OC", "90C27, 90-08 (Secondary), 90-04 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.05045", "abs": "https://arxiv.org/abs/2507.05045", "authors": ["Nils-Christian Kempke", "Thorsten Koch"], "title": "GPU accelerated variant of Schroeppel-Shamir's algorithm for solving the market split problem", "comment": null, "summary": "The market split problem (MSP), introduced by Cornuejols and Dawande (1998),\nis a challenging binary optimization problem that performs poorly on\nstate-of-the-art linear programming-based branch-and-cut solvers. We present a\nnovel algorithm for solving the feasibility version of this problem, derived\nfrom Schroeppel-Shamir's algorithm for the one-dimensional subset sum problem.\nOur approach is based on exhaustively enumerating one-dimensional solutions of\nMSP and utilizing GPUs to evaluate candidate solutions across the entire\nproblem. The resulting hybrid CPU-GPU implementation efficiently solves\ninstances with up to 10 constraints and 90 variables. We demonstrate the\nalgorithm's performance on benchmark problems, solving instances of size (9,\n80) in less than fifteen minutes and (10, 90) in up to one day."}
{"id": "2507.03829", "categories": ["cs.AI", "I.2.4; I.2.1"], "pdf": "https://arxiv.org/pdf/2507.03829", "abs": "https://arxiv.org/abs/2507.03829", "authors": ["George Hannah", "Jacopo de Berardinis", "Terry R. Payne", "Valentina Tamma", "Andrew Mitchell", "Ellen Piercy", "Ewan Johnson", "Andrew Ng", "Harry Rostron", "Boris Konev"], "title": "RELRaE: LLM-Based Relationship Extraction, Labelling, Refinement, and Evaluation", "comment": "18 Pages, 8 Tables, Under-review at ISWC 2025", "summary": "A large volume of XML data is produced in experiments carried out by robots\nin laboratories. In order to support the interoperability of data between labs,\nthere is a motivation to translate the XML data into a knowledge graph. A key\nstage of this process is the enrichment of the XML schema to lay the foundation\nof an ontology schema. To achieve this, we present the RELRaE framework, a\nframework that employs large language models in different stages to extract and\naccurately label the relationships implicitly present in the XML schema. We\ninvestigate the capability of LLMs to accurately generate these labels and then\nevaluate them. Our work demonstrates that LLMs can be effectively used to\nsupport the generation of relationship labels in the context of lab automation,\nand that they can play a valuable role within semi-automatic ontology\ngeneration frameworks more generally."}
{"id": "2507.04925", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.04925", "abs": "https://arxiv.org/abs/2507.04925", "authors": ["Ľubomíra Dvořáková", "Lucas Mol", "Pascal Ochem"], "title": "Critical exponent of ternary words with few distinct palindromes", "comment": null, "summary": "We study infinite ternary words that contain few distinct palindromes. In\nparticular, we classify such words according to their critical exponent."}
{"id": "2507.04104", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.04104", "abs": "https://arxiv.org/abs/2507.04104", "authors": ["Sri Harsha Gajavalli"], "title": "Human-Centered Interactive Anonymization for Privacy-Preserving Machine Learning: A Case for Human-Guided k-Anonymity", "comment": null, "summary": "Privacy-preserving machine learning (ML) seeks to balance data utility and\nprivacy, especially as regulations like the GDPR mandate the anonymization of\npersonal data for ML applications. Conventional anonymization approaches often\nreduce data utility due to indiscriminate generalization or suppression of data\nattributes. In this study, we propose an interactive approach that incorporates\nhuman input into the k-anonymization process, enabling domain experts to guide\nattribute preservation based on contextual importance. Using the UCI Adult\ndataset, we compare classification outcomes of interactive human-influenced\nanonymization with traditional, fully automated methods. Our results show that\nhuman input can enhance data utility in some cases, although results vary\nacross tasks and settings. We discuss limitations of our approach and suggest\npotential areas for improved interactive frameworks in privacy-aware ML."}
{"id": "2507.05115", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.05115", "abs": "https://arxiv.org/abs/2507.05115", "authors": ["Chonghu Guan", "Xinfeng Gu", "Wenhao Zhang", "Xun Li"], "title": "Optimal Consumption-Investment for General Utility with a Drawdown Constraint over a Finite-Time Horizon", "comment": null, "summary": "We study an optimal investment and consumption problem over a finite-time\nhorizon, in which an individual invests in a risk-free asset and a risky asset,\nand evaluate utility using a general utility function that exhibits loss\naversion with respect to the historical maximum of consumption. Motivated by\nbehavioral finance and habit formation theory, we model the agent's preference\nfor maintaining a standard of living by imposing constraints on declines from\nthe peak consumption level. To solve the resulting Hamilton-Jacobi-Bellman\n(HJB) variational inequality, which is fully nonlinear, we apply a dual\ntransformation, transforming the original problem into a linear singular\ncontrol problem with a constraint. By differentiating the value function\nfurther, we reduce the constrained linear singular control problem to a linear\nobstacle problem. We prove the existence of a solution to the obstacle problem\nunder standard constraints. It allows us to characterize the optimal\nconsumption and investment strategies through piecewise analytical feedback\nforms derived from the dual formulation. Our analysis contributes to the\nliterature on habit formation, drawdown constraints, and stochastic control by\nexplicitly characterizing the time-dependent free boundaries and the associated\noptimal feedback strategies."}
{"id": "2507.03834", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03834", "abs": "https://arxiv.org/abs/2507.03834", "authors": ["Michael J. Zellinger", "Matt Thomson"], "title": "Economic Evaluation of LLMs", "comment": "14 pages, 6 figures", "summary": "Practitioners often navigate LLM performance trade-offs by plotting Pareto\nfrontiers of optimal accuracy-cost trade-offs. However, this approach offers no\nway to compare between LLMs with distinct strengths and weaknesses: for\nexample, a cheap, error-prone model vs a pricey but accurate one. To address\nthis gap, we propose economic evaluation of LLMs. Our framework quantifies the\nperformance trade-off of an LLM as a single number based on the economic\nconstraints of a concrete use case, all expressed in dollars: the cost of\nmaking a mistake, the cost of incremental latency, and the cost of abstaining\nfrom a query. We apply our economic evaluation framework to compare the\nperformance of reasoning and non-reasoning models on difficult questions from\nthe MATH benchmark, discovering that reasoning models offer better\naccuracy-cost tradeoffs as soon as the economic cost of a mistake exceeds\n\\$0.01. In addition, we find that single large LLMs often outperform cascades\nwhen the cost of making a mistake is as low as \\$0.1. Overall, our findings\nsuggest that when automating meaningful human tasks with AI models,\npractitioners should typically use the most powerful available model, rather\nthan attempt to minimize AI deployment costs, since deployment costs are likely\ndwarfed by the economic impact of AI errors."}
{"id": "2507.05037", "categories": ["math.CO", "math.AC"], "pdf": "https://arxiv.org/pdf/2507.05037", "abs": "https://arxiv.org/abs/2507.05037", "authors": ["Marilena Crupi", "Antonino Ficarra"], "title": "Generalizing blocking semiovals in finite projective planes", "comment": "Published in Finite Fields and Their Applications, Volume 108,\n  December 2025, 102688, https://doi.org/10.1016/j.ffa.2025.102688", "summary": "Blocking semiovals and the determination of their (minimum) sizes constitute\none of the central research topics in finite projective geometry. In this\narticle we introduce the concept of blocking set with the $r_\\infty$-property\nin a finite projective plane $\\text{PG}(2,q)$, with $r_\\infty$ a line of\n$\\text{PG}(2,q)$ and $q$ a prime power. This notion greatly generalizes that of\nblocking semioval. We address the question of determining those integers $k$\nfor which there exists a blocking set of size $k$ with the $r_\\infty$-property.\nTo solve this problem, we build new theory which deeply analyzes the interplay\nbetween blocking sets in finite projective and affine planes."}
{"id": "2507.04106", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04106", "abs": "https://arxiv.org/abs/2507.04106", "authors": ["Stanisław Pawlak", "Bartłomiej Twardowski", "Tomasz Trzciński", "Joost van de Weijer"], "title": "Addressing The Devastating Effects Of Single-Task Data Poisoning In Exemplar-Free Continual Learning", "comment": "Accepted at CoLLAs 2025", "summary": "Our research addresses the overlooked security concerns related to data\npoisoning in continual learning (CL). Data poisoning - the intentional\nmanipulation of training data to affect the predictions of machine learning\nmodels - was recently shown to be a threat to CL training stability. While\nexisting literature predominantly addresses scenario-dependent attacks, we\npropose to focus on a more simple and realistic single-task poison (STP)\nthreats. In contrast to previously proposed poisoning settings, in STP\nadversaries lack knowledge and access to the model, as well as to both previous\nand future tasks. During an attack, they only have access to the current task\nwithin the data stream. Our study demonstrates that even within these stringent\nconditions, adversaries can compromise model performance using standard image\ncorruptions. We show that STP attacks are able to strongly disrupt the whole\ncontinual training process: decreasing both the stability (its performance on\npast tasks) and plasticity (capacity to adapt to new tasks) of the algorithm.\nFinally, we propose a high-level defense framework for CL along with a poison\ntask detection method based on task vectors. The code is available at\nhttps://github.com/stapaw/STP.git ."}
{"id": "2507.05182", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.05182", "abs": "https://arxiv.org/abs/2507.05182", "authors": ["Keisuke Nakashima", "Kohei Furuike", "Yoshiaki Inoue"], "title": "A Two-Stage Scheduling Method for Nurse Scheduling and Its Practical Application", "comment": "This manuscript is written in Japanese", "summary": "The creation of nurses' schedules is a critical task that directly impacts\nthe quality and safety of patient care as well as the quality of life for\nnurses. In most hospitals in Japan, this responsibility falls to the head nurse\nof each ward. The physical and mental burden of this task is considerable, and\nrecent challenges such as the growing shortage of nurses and increasingly\ndiverse working styles have further complicated the scheduling process.\nConsequently, there is a growing demand for automated nurse scheduling systems.\nTechnically, modern integer programming solvers can generate feasible schedules\nwithin a practical timeframe. However, in many hospitals, schedules are still\ncreated manually. This is largely because tacit knowledge, considerations\nunconsciously applied by head nurses, cannot be fully formalized into explicit\nconstraints, often resulting in automatically generated schedules that are not\npractically usable. To address this issue, we propose a novel \"two-stage\nscheduling method.\" This approach divides the scheduling task into night shift\nand day shift stages, allowing head nurses to make manual adjustments after the\nfirst stage. This interactive process makes it possible to produce nurse\nschedules that are suitable for real-world implementation. Furthermore, to\npromote the practical adoption of nurse scheduling, we present case studies\nfrom acute and chronic care hospitals where systems based on the proposed\nmethod were deployed. We also discuss the challenges encountered during\nimplementation and the corresponding solutions."}
{"id": "2507.03839", "categories": ["cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2507.03839", "abs": "https://arxiv.org/abs/2507.03839", "authors": ["Shuowen Li", "Kexin Wang", "Minglu Fang", "Danqi Huang", "Ali Asadipour", "Haipeng Mi", "Yitong Sun"], "title": "Participatory Evolution of Artificial Life Systems via Semantic Feedback", "comment": "10 pages", "summary": "We present a semantic feedback framework that enables natural language to\nguide the evolution of artificial life systems. Integrating a\nprompt-to-parameter encoder, a CMA-ES optimizer, and CLIP-based evaluation, the\nsystem allows user intent to modulate both visual outcomes and underlying\nbehavioral rules. Implemented in an interactive ecosystem simulation, the\nframework supports prompt refinement, multi-agent interaction, and emergent\nrule synthesis. User studies show improved semantic alignment over manual\ntuning and demonstrate the system's potential as a platform for participatory\ngenerative design and open-ended evolution."}
{"id": "2507.05122", "categories": ["math.CO", "06A07, 05D05"], "pdf": "https://arxiv.org/pdf/2507.05122", "abs": "https://arxiv.org/abs/2507.05122", "authors": ["Maria-Romina Ivan", "Sean Jaffe"], "title": "The Saturation Number for the Diamond is Linear", "comment": "14 pages, 12 figures", "summary": "For a fixed poset $\\mathcal P$ we say that a family $\\mathcal\nF\\subseteq\\mathcal P([n])$ is $\\mathcal P$-saturated if it does not contain an\ninduced copy of $\\mathcal P$, but whenever we add a new set to $\\mathcal F$, we\nform an induced copy of $\\mathcal P$. The size of the smallest such family is\ndenoted by $\\text{sat}^*(n, \\mathcal P)$.\\par For the diamond poset $\\mathcal\nD_2$ (the two-dimensional Boolean lattice), while it is easy to see that the\nsaturation number is at most $n+1$, the best known lower bound has stayed at\n$O(\\sqrt n)$ since the introduction of the area of poset saturation. In this\npaper we prove that $\\text{sat}^*(n, \\mathcal D_2)\\geq \\frac{n+1}{5}$,\nestablishing that the saturation number for the diamond is linear. The proof\nuses a result about certain pairs of set systems which may be of independent\ninterest."}
{"id": "2507.04126", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.04126", "abs": "https://arxiv.org/abs/2507.04126", "authors": ["Howard Halim", "Eyasu Getahun Chekole", "Daniël Reijsbergen", "Jianying Zhou"], "title": "BlowPrint: Blow-Based Multi-Factor Biometrics for Smartphone User Authentication", "comment": null, "summary": "Biometric authentication is a widely used security mechanism that leverages\nunique physiological or behavioral characteristics to authenticate users. In\nmulti-factor biometrics (MFB), multiple biometric modalities, e.g.,\nphysiological and behavioral, are integrated to mitigate the limitations\ninherent in single-factor biometrics. The main challenge in MFB lies in\nidentifying novel behavioral techniques capable of meeting critical criteria,\nincluding high accuracy, high usability, non-invasiveness, resilience against\nspoofing attacks, and low use of computational resources. Despite ongoing\nadvancements, current behavioral biometric techniques often fall short of\nfulfilling one or more of these requirements. In this work, we propose\nBlowPrint, a novel behavioral biometric technique that allows us to\nauthenticate users based on their phone blowing behaviors. In brief, we assume\nthat the way users blow on a phone screen can produce distinctive acoustic\npatterns, which can serve as a unique biometric identifier for effective user\nauthentication. It can also be seamlessly integrated with physiological\ntechniques, such as facial recognition, to enhance its robustness and security.\nTo assess BlowPrint's effectiveness, we conduct an empirical study involving 50\nparticipants from whom we collect blow-acoustic and facial feature data.\nSubsequently, we compute the similarity scores of the two modalities using\nvarious similarity algorithms and combine them through score-level fusion.\nFinally, we compute the accuracy using a machine learning-based classifier. As\na result, the proposed method demonstrates an accuracy of 99.35% for blow\nacoustics, 99.96% for facial recognition, and 99.82% for the combined approach.\nThe experimental results demonstrate BlowPrint's high effectiveness in terms of\nauthentication accuracy, spoofing attack resilience, usability,\nnon-invasiveness, and other aspects."}
{"id": "2507.03800", "categories": ["math.CO", "cs.NA", "math.AG", "math.NA", "math.OC", "05A05, 05A15, 05A20 (Primary), 06A07, 65H04, 41A10, 41A45, 41A60,\n  90C23 (Secondary)", "G.2.1; G.1.2; G.1.3; G.1.5; G.1.6"], "pdf": "https://arxiv.org/pdf/2507.03800", "abs": "https://arxiv.org/abs/2507.03800", "authors": ["Alejandro González Nevado"], "title": "Spectrahedral relaxations of Eulerian rigidly convex sets", "comment": "75 pages. Preprint extracted from a selection, rewrite and\n  recombination of several sections and chapters from my PhD thesis. For more\n  possible lines of research in these related directions, we direct the\n  interested reader to arXiv:2503.04628", "summary": "We study a generalization of Eulerian polynomials to the multivariate setting\nintroduced by Br\\\"and\\'en. Although initially these polynomials were introduced\nusing the language of hyperbolic and stable polynomials, we manage to translate\nsome restrictions of these polynomials to our real zero setting. Once we are in\nthis setting, we focus our attention on the rigidly convex sets (RCSs) defined\nby these polynomials. In particular, we study the corresponding rigidly convex\nsets looking at spectrahedral relaxations constructed through the use of monic\nsymmetric linear matrix polynomials (MSLMPs) of small size and depending\npolynomially (actually just cubically) on the coefficients of the corresponding\npolynomials. We analyze how good are the obtained spectrahedral approximations\nto these rigidly convex sets. We do this analysis by measuring the behavior\nalong the diagonal, where we precisely recover the original univariate Eulerian\npolynomials. Thus we conclude that, measuring through the diagonal, our\nrelaxation-based spectrahedral method for approximation of the rigidly convex\nsets defined by multivariate Eulerian polynomials is highly accurate. In\nparticular, we see that this relaxation-based spectrahedral method for\napproximation of the rigidly convex sets defined by multivariate Eulerian\npolynomials provides bounds for the extreme roots of the corresponding\nunivariate Eulerian polynomials that are better than these already found in the\nliterature. All in all, this tells us that, at least close to the diagonal, the\nglobal outer approximation to the rigidly convex sets provided by this\nrelaxation-based spectrahedral method is itself highly accurate."}
{"id": "2507.03868", "categories": ["cs.AI", "cs.CE", "cs.CY", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.03868", "abs": "https://arxiv.org/abs/2507.03868", "authors": ["Xinyi Wu", "Yanhao Jia", "Luwei Xiao", "Shuai Zhao", "Fengkuang Chiang", "Erik Cambria"], "title": "From Query to Explanation: Uni-RAG for Multi-Modal Retrieval-Augmented Learning in STEM", "comment": null, "summary": "In AI-facilitated teaching, leveraging various query styles to interpret\nabstract educational content is crucial for delivering effective and accessible\nlearning experiences. However, existing retrieval systems predominantly focus\non natural text-image matching and lack the capacity to address the diversity\nand ambiguity inherent in real-world educational scenarios. To address this\nlimitation, we develop a lightweight and efficient multi-modal retrieval\nmodule, named Uni-Retrieval, which extracts query-style prototypes and\ndynamically matches them with tokens from a continually updated Prompt Bank.\nThis Prompt Bank encodes and stores domain-specific knowledge by leveraging a\nMixture-of-Expert Low-Rank Adaptation (MoE-LoRA) module and can be adapted to\nenhance Uni-Retrieval's capability to accommodate unseen query types at test\ntime. To enable natural language educational content generation, we integrate\nthe original Uni-Retrieval with a compact instruction-tuned language model,\nforming a complete retrieval-augmented generation pipeline named Uni-RAG. Given\na style-conditioned query, Uni-RAG first retrieves relevant educational\nmaterials and then generates human-readable explanations, feedback, or\ninstructional content aligned with the learning objective. Experimental results\non SER and other multi-modal benchmarks show that Uni-RAG outperforms baseline\nretrieval and RAG systems in both retrieval accuracy and generation quality,\nwhile maintaining low computational cost. Our framework provides a scalable,\npedagogically grounded solution for intelligent educational systems, bridging\nretrieval and generation to support personalized, explainable, and efficient\nlearning assistance across diverse STEM scenarios."}
{"id": "2507.05153", "categories": ["math.CO", "math.GT", "20F55, 51M20 (primary), 52B11, 11R06 (secondary)"], "pdf": "https://arxiv.org/pdf/2507.05153", "abs": "https://arxiv.org/abs/2507.05153", "authors": ["Naomi Bredon"], "title": "On ADEG-polyhedra in hyperbolic spaces", "comment": "50 pages", "summary": "In this paper, we establish that the non-zero dihedral angles of hyperbolic\nCoxeter polyhedra of large dimensions are not arbitrarily small. Namely, for\ndimensions $n\\geq 32$, they are of the form $\\frac{\\pi}{m}$ with $m\\leq 6$.\nMoreover, this property holds in all dimensions $n\\geq 7$ for Coxeter polyhedra\nwith mutually intersecting facets. Then, we develop a constructive procedure\ntailored to Coxeter polyhedra with prescribed dihedral angles, from which we\nderive the complete classification of ADEG-polyhedra, characterized by having\nno pair of disjoint facets and dihedral angles $\\frac{\\pi}{2}, \\frac{\\pi}{3}$\nand $\\frac{\\pi}{6}$, only. Besides some well-known simplices and pyramids,\nthere are three exceptional polyhedra, one of which is a new polyhedron\n$P_{\\star}\\subset \\mathbb H^9$ with $14$ facets."}
{"id": "2507.04174", "categories": ["cs.CR", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.04174", "abs": "https://arxiv.org/abs/2507.04174", "authors": ["Abdellah Akilal", "M-Tahar Kechadi"], "title": "Cloud Digital Forensic Readiness: An Open Source Approach to Law Enforcement Request Management", "comment": null, "summary": "Cloud Forensics presents a multi-jurisdictional challenge that may undermines\nthe success of digital forensic investigations (DFIs). The growing volumes of\ndomiciled and foreign law enforcement (LE) requests, the latency and complexity\nof formal channels for crossborder data access are challenging issues. In this\npaper, we first discuss major Cloud Service Providers (CSPs) transparency\nreports and law enforcement guidelines, then propose an abstract architecture\nfor a Cloud Law Enforcement Requests Management System (CLERMS). A proof of\nconcept of the proposed solution is developed, deployed and validated by two\nrealistic scenarios, in addition to an economic estimation of its associated\ncosts. Based on available open source components, our solution is for the\nbenefit of both CSPs and Cloud Service Consumers (CSCs), and aims to enhance\nthe due Cloud Digital Forensic Readiness (CDFR)."}
{"id": "2507.03870", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03870", "abs": "https://arxiv.org/abs/2507.03870", "authors": ["Rahil P Mehta", "Yashwanthi Anand", "Manish Motwani", "Sandhya Saisubramanian"], "title": "Uncovering Systemic and Environment Errors in Autonomous Systems Using Differential Testing", "comment": null, "summary": "When an autonomous agent behaves undesirably, including failure to complete a\ntask, it can be difficult to determine whether the behavior is due to a\nsystemic agent error, such as flaws in the model or policy, or an environment\nerror, where a task is inherently infeasible under a given environment\nconfiguration, even for an ideal agent. As agents and their environments grow\nmore complex, identifying the error source becomes increasingly difficult but\ncritical for reliable deployment. We introduce AIProbe, a novel black-box\ntesting technique that applies differential testing to attribute undesirable\nagent behaviors either to agent deficiencies, such as modeling or training\nflaws, or due to environmental infeasibility. AIProbe first generates diverse\nenvironmental configurations and tasks for testing the agent, by modifying\nconfigurable parameters using Latin Hypercube sampling. It then solves each\ngenerated task using a search-based planner, independent of the agent. By\ncomparing the agent's performance to the planner's solution, AIProbe identifies\nwhether failures are due to errors in the agent's model or policy, or due to\nunsolvable task conditions. Our evaluation across multiple domains shows that\nAIProbe significantly outperforms state-of-the-art techniques in detecting both\ntotal and unique errors, thereby contributing to a reliable deployment of\nautonomous agents."}
{"id": "2507.05231", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.05231", "abs": "https://arxiv.org/abs/2507.05231", "authors": ["Zach Hunter"], "title": "An improved construction for the triangle removal lemma", "comment": "13 pages, comments welcome!", "summary": "We construct $n$-vertex graphs $G$ where $\\epsilon n^2$ edges must be deleted\nto become triangle-free, which contain less than\n$\\epsilon^{(C_{\\text{new}}-o(1))\\log_2 1/\\epsilon}n^3$ triangles for\n$C_{\\text{new}}= \\frac{1}{4\\log_2(4/3)} \\approx 1.6601$. Previously, a bound of\nthe same shape was known, but with $C_{\\text{new}}$ replaced by $C_{\\text{old}}\n:= C_{\\text{new}}/2$. Our construction uses ideas from additive combinatorics,\ndrawing especially from the corners problem, but does not yield new bounds for\nthose problems."}
{"id": "2507.04197", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.04197", "abs": "https://arxiv.org/abs/2507.04197", "authors": ["Nishant Chinnasami", "Rye Stahle-Smith", "Rasha Karakchi"], "title": "ML-Enhanced AES Anomaly Detection for Real-Time Embedded Security", "comment": null, "summary": "Advanced Encryption Standard (AES) is a widely adopted cryptographic\nalgorithm, yet its practical implementations remain susceptible to side-channel\nand fault injection attacks. In this work, we propose a comprehensive framework\nthat enhances AES-128 encryption security through controlled anomaly injection\nand real-time anomaly detection using both statistical and machine learning\n(ML) methods. We simulate timing and fault-based anomalies by injecting\nexecution delays and ciphertext perturbations during encryption, generating\nlabeled datasets for detection model training. Two complementary detection\nmechanisms are developed: a threshold-based timing anomaly detector and a\nsupervised Random Forest classifier trained on combined timing and ciphertext\nfeatures. We implement and evaluate the framework on both CPU and FPGA-based\nSoC hardware (PYNQ-Z1), measuring performance across varying block sizes,\ninjection rates, and core counts. Our results show that ML-based detection\nsignificantly outperforms threshold-based methods in precision and recall while\nmaintaining real-time performance on embedded hardware. Compared to existing\nAES anomaly detection methods, our solution offers a low-cost, real-time, and\naccurate detection approach deployable on lightweight FPGA platforms."}
{"id": "2507.03876", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03876", "abs": "https://arxiv.org/abs/2507.03876", "authors": ["Alyssa Loo", "Ellie Pavlick", "Roman Feiman"], "title": "LLMs model how humans induce logically structured rules", "comment": null, "summary": "A central goal of cognitive science is to provide a computationally explicit\naccount of both the structure of the mind and its development: what are the\nprimitive representational building blocks of cognition, what are the rules via\nwhich those primitives combine, and where do these primitives and rules come\nfrom in the first place? A long-standing debate concerns the adequacy of\nartificial neural networks as computational models that can answer these\nquestions, in particular in domains related to abstract cognitive function,\nsuch as language and logic. This paper argues that recent advances in neural\nnetworks -- specifically, the advent of large language models (LLMs) --\nrepresent an important shift in this debate. We test a variety of LLMs on an\nexisting experimental paradigm used for studying the induction of rules\nformulated over logical concepts. Across four experiments, we find converging\nempirical evidence that LLMs provide at least as good a fit to human behavior\nas models that implement a Bayesian probablistic language of thought (pLoT),\nwhich have been the best computational models of human behavior on the same\ntask. Moreover, we show that the LLMs make qualitatively different predictions\nabout the nature of the rules that are inferred and deployed in order to\ncomplete the task, indicating that the LLM is unlikely to be a mere\nimplementation of the pLoT solution. Based on these results, we argue that LLMs\nmay instantiate a novel theoretical account of the primitive representations\nand computations necessary to explain human logical concepts, with which future\nwork in cognitive science should engage."}
{"id": "2507.03734", "categories": ["math.LO", "math.CO", "03E17, 03E05 (Primary) 03E35, 03E15 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.03734", "abs": "https://arxiv.org/abs/2507.03734", "authors": ["Rafał Filipów", "Adam Kwela"], "title": "Two $\\mathfrak{b}$ or not two $\\mathfrak{b}$?", "comment": null, "summary": "The paper is devoted to comparison of two generalizations of the bounding\nnumber $\\mathfrak{b}$."}
{"id": "2507.04214", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.04214", "abs": "https://arxiv.org/abs/2507.04214", "authors": ["Jianshuo Dong", "Tianyi Zhang", "Feng Yan", "Yuanjie Li", "Hewu Li", "Han Qiu"], "title": "Can Large Language Models Automate the Refinement of Cellular Network Specifications?", "comment": null, "summary": "Cellular networks serve billions of users globally, yet concerns about\nreliability and security persist due to weaknesses in 3GPP standards. However,\ntraditional analysis methods, including manual inspection and automated tools,\nstruggle with increasingly expanding cellular network specifications. This\npaper investigates the feasibility of Large Language Models (LLMs) for\nautomated cellular network specification refinement. To advance it, we leverage\n200,000+ approved 3GPP Change Requests (CRs) that document specification\nrevisions, constructing a valuable dataset for domain tasks. We introduce\nCR-eval, a principled evaluation framework, and benchmark 16 state-of-the-art\nLLMs, demonstrating that top models can discover security-related weaknesses in\nover 127 out of 200 test cases within five trials. To bridge potential gaps, we\nexplore LLM specialization techniques, including fine-tuning an 8B model to\nmatch or surpass advanced LLMs like GPT-4o and DeepSeek-R1. Evaluations on 30\ncellular attacks identify open challenges for achieving full automation. These\nfindings confirm that LLMs can automate the refinement of cellular network\nspecifications and provide valuable insights to guide future research in this\ndirection."}
{"id": "2507.03904", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.03904", "abs": "https://arxiv.org/abs/2507.03904", "authors": ["Yingxuan Yang", "Ying Wen", "Jun Wang", "Weinan Zhang"], "title": "Agent Exchange: Shaping the Future of AI Agent Economics", "comment": null, "summary": "The rise of Large Language Models (LLMs) has transformed AI agents from\npassive computational tools into autonomous economic actors. This shift marks\nthe emergence of the agent-centric economy, in which agents take on active\neconomic roles-exchanging value, making strategic decisions, and coordinating\nactions with minimal human oversight. To realize this vision, we propose Agent\nExchange (AEX), a specialized auction platform designed to support the dynamics\nof the AI agent marketplace. AEX offers an optimized infrastructure for agent\ncoordination and economic participation. Inspired by Real-Time Bidding (RTB)\nsystems in online advertising, AEX serves as the central auction engine,\nfacilitating interactions among four ecosystem components: the User-Side\nPlatform (USP), which translates human goals into agent-executable tasks; the\nAgent-Side Platform (ASP), responsible for capability representation,\nperformance tracking, and optimization; Agent Hubs, which coordinate agent\nteams and participate in AEX-hosted auctions; and the Data Management Platform\n(DMP), ensuring secure knowledge sharing and fair value attribution. We outline\nthe design principles and system architecture of AEX, laying the groundwork for\nagent-based economic infrastructure in future AI ecosystems."}
{"id": "2507.04653", "categories": ["math.NT", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.04653", "abs": "https://arxiv.org/abs/2507.04653", "authors": ["Lin-Yue Li", "Rong-Hua Wang"], "title": "$q$-Congruences for Z.-W. Sun's generalized polynomials $w^{(α)}_k(x)$", "comment": null, "summary": "In 2022, Z.-W. Sun defined \\begin{equation*}\nw_k^{(\\alpha)}{(x)}=\\sum_{j=1}^{k}w(k,j)^{\\alpha}x^{j-1}, \\end{equation*} where\n$k,\\alpha$ are positive integers and\n$w(k,j)=\\frac{1}{j}\\binom{k-1}{j-1}\\binom{k+j}{j-1}$. Let $(x)_{0}=1$ and\n$(x)_{n}=x(x+1)\\cdots(x+n-1)$ for all $n\\geq 1$. In this paper, it is proved by\n$q$-congruences that for any positive integers ${\\alpha,\\beta, m,n,r}$, we have\n\\begin{equation*}\n\\frac{(2,n)}{n(n+1)(n+2)}\\sum_{k=1}^{n}k^r(k+1)^r(2k+1)w_{k}^{(\\alpha)}(x)^{m}\\in\\mathbb{Z}[x],\n\\end{equation*} \\begin{equation*}\n\\frac{(2,n)}{n(n+1)(n+2)}\\sum_{k=1}^{n}(-1)^{k}k^r(k+1)^r(2k+1)\nw_{k}^{(\\alpha)}(x)^{m}\\in\\mathbb{Z}[x], \\end{equation*} and \\begin{equation*}\n\\frac{2}{[n,n+1,\\cdots,n+2\\beta+1]}\\sum_{k=1}^{n}(k)_{\\beta}^r(k+\\beta+1)_{\\beta}^r(k+\\beta)\n\\prod_{i=0}^{2\\beta-1}w_{k+i}^{(\\alpha)}(x)^m\\in\\mathbb{Z}[x], \\end{equation*}\nwhere $[n,n+1,\\cdots,n+2\\beta+1]$ is the least common multiple of $n$, $n+1$,\n$\\cdots$, $n+2\\beta+1$. Taking $r=\\beta=1$ above will confirm some of Z.-W.\nSun's conjectures."}
{"id": "2507.04227", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04227", "abs": "https://arxiv.org/abs/2507.04227", "authors": ["Guohong Liu", "Jialei Ye", "Jiacheng Liu", "Yuanchun Li", "Wei Liu", "Pengzhi Gao", "Jian Luan", "Yunxin Liu"], "title": "Hijacking JARVIS: Benchmarking Mobile GUI Agents against Unprivileged Third Parties", "comment": null, "summary": "Mobile GUI agents are designed to autonomously execute diverse device-control\ntasks by interpreting and interacting with mobile screens. Despite notable\nadvancements, their resilience in real-world scenarios where screen content may\nbe partially manipulated by untrustworthy third parties remains largely\nunexplored. Owing to their black-box and autonomous nature, these agents are\nvulnerable to manipulations that could compromise user devices. In this work,\nwe present the first systematic investigation into the vulnerabilities of\nmobile GUI agents. We introduce a scalable attack simulation framework\nAgentHazard, which enables flexible and targeted modifications of screen\ncontent within existing applications. Leveraging this framework, we develop a\ncomprehensive benchmark suite comprising both a dynamic task execution\nenvironment and a static dataset of vision-language-action tuples, totaling\nover 3,000 attack scenarios. The dynamic environment encompasses 58\nreproducible tasks in an emulator with various types of hazardous UI content,\nwhile the static dataset is constructed from 210 screenshots collected from 14\npopular commercial apps. Importantly, our content modifications are designed to\nbe feasible for unprivileged third parties. We evaluate 7 widely-used mobile\nGUI agents and 5 common backbone models using our benchmark. Our findings\nreveal that all examined agents are significantly influenced by misleading\nthird-party content (with an average misleading rate of 28.8% in human-crafted\nattack scenarios) and that their vulnerabilities are closely linked to the\nemployed perception modalities and backbone LLMs. Furthermore, we assess\ntraining-based mitigation strategies, highlighting both the challenges and\nopportunities for enhancing the robustness of mobile GUI agents. Our code and\ndata will be released at https://agenthazard.github.io."}
{"id": "2507.03916", "categories": ["cs.AI", "cs.CV", "68T01"], "pdf": "https://arxiv.org/pdf/2507.03916", "abs": "https://arxiv.org/abs/2507.03916", "authors": ["Yifan Jiang", "Yibo Xue", "Yukun Kang", "Pin Zheng", "Jian Peng", "Feiran Wu", "Changliang Xu"], "title": "Animation Needs Attention: A Holistic Approach to Slides Animation Comprehension with Visual-Language Models", "comment": "Appendix at:\n  https://github.com/PAMPAS-Lab/ANA-PPT-Anamation/blob/main/Appendix.pdf", "summary": "Slide animations, such as fade-ins, fly-ins, and wipes, are critical for\naudience engagement, efficient information delivery, and vivid visual\nexpression. However, most AI-driven slide-generation tools still lack native\nanimation support, and existing vision-language models (VLMs) struggle with\nanimation tasks due to the absence of public datasets and limited\ntemporal-reasoning capabilities. To address this gap, we release the first\npublic dataset for slide-animation modeling: 12,000 triplets of\nnatural-language descriptions, animation JSON files, and rendered videos,\ncollectively covering every built-in PowerPoint effect. Using this resource, we\nfine-tune Qwen-2.5-VL-7B with Low-Rank Adaptation (LoRA) and achieve consistent\nimprovements over GPT-4.1 and Gemini-2.5-Pro in BLEU-4, ROUGE-L, SPICE, and our\nCoverage-Order-Detail Assessment (CODA) metric, which evaluates action\ncoverage, temporal order, and detail fidelity. On a manually curated test set\nof slides, the LoRA model increases BLEU-4 by around 60%, ROUGE-L by 30%, and\nshows significant improvements in CODA-detail. This demonstrates that low-rank\nadaptation enables reliable temporal reasoning and generalization beyond\nsynthetic data. Overall, our dataset, LoRA-enhanced model, and CODA metric\nprovide a rigorous benchmark and foundation for future research on VLM-based\ndynamic slide generation."}
{"id": "2507.04688", "categories": ["math.NT", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.04688", "abs": "https://arxiv.org/abs/2507.04688", "authors": ["Marcus Nilsson"], "title": "Counting linear congruence systems with a fixed number of solutions", "comment": null, "summary": "For a prime $p$ and a positive integer $s$ consider a homogeneous linear\nsystem over the ring $\\mathbb{Z}_{p^s}$ (the ring of integers modulo $p^s$)\ndescribed by an $n \\times m$-matrix. The possible number of solutions to such a\nsystem is $p^j$, where $j=0,1,\\ldots, sm$. We study the problem of how many $n\n\\times m$-matrices over $\\mathbb{Z}_{p^s}$ there are given that we have exactly\n$p^j$ homogeneous solutions. For the case $s=1$ (when $\\mathbb{Z}_{p^s}$ is a\nfield) George von Landsberg proved a general formula in 1893. However, there\nseems to be few published general results for the case $s>1$ except when we\nhave a unique solution ($j=0$). In this article we present recursive methods\nfor counting such matrices and present explicit formulas for the case when\n$j\\le s$ and $n\\ge m$. We will use a generalization of Euler's $\\phi$-function\nand Gaussian binomial coefficients to express our formulas. As an application\nwe compute the probability that gcd$(\\det(A),p^s)$ gives the number of\nsolutions to the quadratic system $Ax=0$ in $\\mathbb{Z}_{p^s}$."}
{"id": "2507.04275", "categories": ["cs.CR", "cs.AI", "cs.LG", "68T05, 68M25", "D.4.6; I.2.6; K.6.5"], "pdf": "https://arxiv.org/pdf/2507.04275", "abs": "https://arxiv.org/abs/2507.04275", "authors": ["M. Tahir Akdeniz", "Zeynep Yeşilkaya", "İ. Enes Köse", "İ. Ulaş Ünal", "Sevil Şen"], "title": "VOLTRON: Detecting Unknown Malware Using Graph-Based Zero-Shot Learning", "comment": "17 pages, 6 figures, Submitted as a preprint", "summary": "The persistent threat of Android malware presents a serious challenge to the\nsecurity of millions of users globally. While many machine learning-based\nmethods have been developed to detect these threats, their reliance on large\nlabeled datasets limits their effectiveness against emerging, previously unseen\nmalware families, for which labeled data is scarce or nonexistent.\n  To address this challenge, we introduce a novel zero-shot learning framework\nthat combines Variational Graph Auto-Encoders (VGAE) with Siamese Neural\nNetworks (SNN) to identify malware without needing prior examples of specific\nmalware families. Our approach leverages graph-based representations of Android\napplications, enabling the model to detect subtle structural differences\nbetween benign and malicious software, even in the absence of labeled data for\nnew threats.\n  Experimental results show that our method outperforms the state-of-the-art\nMaMaDroid, especially in zero-day malware detection. Our model achieves 96.24%\naccuracy and 95.20% recall for unknown malware families, highlighting its\nrobustness against evolving Android threats."}
{"id": "2507.03928", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.03928", "abs": "https://arxiv.org/abs/2507.03928", "authors": ["Yiliu Sun", "Zicheng Zhao", "Sheng Wan", "Chen Gong"], "title": "CortexDebate: Debating Sparsely and Equally for Multi-Agent Debate", "comment": "Accepted by ACL 2025", "summary": "Nowadays, single Large Language Model (LLM) struggles with critical issues\nsuch as hallucination and inadequate reasoning abilities. To mitigate these\nissues, Multi-Agent Debate (MAD) has emerged as an effective strategy, where\nLLM agents engage in in-depth debates with others on tasks. However, existing\nMAD methods face two major issues: (a) too lengthy input contexts, which causes\nLLM agents to get lost in plenty of input information and experiences\nperformance drop; and (b) the overconfidence dilemma, where self-assured LLM\nagents dominate the debate, leading to low debating effectiveness. To address\nthese limitations, we propose a novel MAD method called \"CortexDebate\".\nInspired by the human brain's tendency to establish a sparse and dynamically\noptimized network among cortical areas governed by white matter, CortexDebate\nconstructs a sparse debating graph among LLM agents, where each LLM agent only\ndebates with the ones that are helpful to it. To optimize the graph, we propose\na module named McKinsey-based Debate Matter (MDM), which acts as an artificial\nanalog to white matter. By integrating the McKinsey Trust Formula, a\nwell-established measure of trustworthiness from sociology, MDM enables\ncredible evaluations that guide graph optimization. The effectiveness of our\nCortexDebate has been well demonstrated by extensive experimental results\nacross eight datasets from four task types."}
{"id": "2507.04848", "categories": ["math.NT", "cs.DM", "math.CO", "11A63, 11K16, 11B85, 68Q45, 68R15"], "pdf": "https://arxiv.org/pdf/2507.04848", "abs": "https://arxiv.org/abs/2507.04848", "authors": ["Émilie Charlier", "Pierre Popoli", "Michel Rigo"], "title": "Computing Expansions in Infinitely Many Cantor Real Bases via a Single Transducer", "comment": "36 pages, 10 figures. Comments are welcome", "summary": "Representing real numbers using convenient numeration systems (integer bases,\n$\\beta$-numeration, Cantor bases, etc.) has been a longstanding mathematical\nchallenge. This paper focuses on Cantor real bases and, specifically, on\nautomatic Cantor real bases and the properties of expansions of real numbers in\nthis setting. We develop a new approach where a single transducer associated\nwith a fixed real number $r$, computes the $\\mathbf{B}$-expansion of $r$ but\nfor an infinite family of Cantor real bases $\\mathbf{B}$ given as input. This\npoint of view contrasts with traditional computational models for which the\nnumeration system is fixed. Under some assumptions on the finitely many Pisot\nnumbers occurring in the Cantor real base, we show that only a finite part of\nthe transducer is visited. We obtain fundamental results on the structure of\nthis transducer and on decidability problems about these expansions, proving\nthat for certain classes of Cantor real bases, key combinatorial properties\nsuch as greediness of the expansion or periodicity can be decided\nalgorithmically."}
{"id": "2507.04365", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.04365", "abs": "https://arxiv.org/abs/2507.04365", "authors": ["Xiaomeng Hu", "Pin-Yu Chen", "Tsung-Yi Ho"], "title": "Attention Slipping: A Mechanistic Understanding of Jailbreak Attacks and Defenses in LLMs", "comment": null, "summary": "As large language models (LLMs) become more integral to society and\ntechnology, ensuring their safety becomes essential. Jailbreak attacks exploit\nvulnerabilities to bypass safety guardrails, posing a significant threat.\nHowever, the mechanisms enabling these attacks are not well understood. In this\npaper, we reveal a universal phenomenon that occurs during jailbreak attacks:\nAttention Slipping. During this phenomenon, the model gradually reduces the\nattention it allocates to unsafe requests in a user query during the attack\nprocess, ultimately causing a jailbreak. We show Attention Slipping is\nconsistent across various jailbreak methods, including gradient-based token\nreplacement, prompt-level template refinement, and in-context learning.\nAdditionally, we evaluate two defenses based on query perturbation, Token\nHighlighter and SmoothLLM, and find they indirectly mitigate Attention\nSlipping, with their effectiveness positively correlated with the degree of\nmitigation achieved. Inspired by this finding, we propose Attention Sharpening,\na new defense that directly counters Attention Slipping by sharpening the\nattention score distribution using temperature scaling. Experiments on four\nleading LLMs (Gemma2-9B-It, Llama3.1-8B-It, Qwen2.5-7B-It, Mistral-7B-It v0.2)\nshow that our method effectively resists various jailbreak attacks while\nmaintaining performance on benign tasks on AlpacaEval. Importantly, Attention\nSharpening introduces no additional computational or memory overhead, making it\nan efficient and practical solution for real-world deployment."}
{"id": "2507.03929", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.03929", "abs": "https://arxiv.org/abs/2507.03929", "authors": ["Mohimenul Kabir", "Kuldeep S Meel"], "title": "An ASP-Based Framework for MUSes", "comment": "To appear in ICLP 2025 Technical Communication", "summary": "Given an unsatisfiable formula, understanding the core reason for\nunsatisfiability is crucial in several applications. One effective way to\ncapture this is through the minimal unsatisfiable subset (MUS), the\nsubset-minimal set of clauses that remains unsatisfiable. Current research\nbroadly focuses on two directions: (i) enumerating as many MUSes as possible\nwithin a given time limit, and (ii) counting the total number of MUSes for a\ngiven unsatisfiable formula.\n  In this paper, we introduce an answer set programming-based framework, named\nMUS-ASP, designed for online enumeration of MUSes. ASP is a powerful tool for\nits strengths in knowledge representation and is particularly suitable for\nspecifying complex combinatorial problems. By translating MUS enumeration into\nanswer set solving, MUS-ASP leverages the computational efficiency of\nstate-of-the-art ASP systems. Our extensive experimental evaluation\ndemonstrates the effectiveness of MUS-ASP and highlights the acceleration in\nboth MUS enumeration and counting tasks, particularly when integrated within\nhybrid solvers, including the framework proposed in this paper."}
{"id": "2507.04916", "categories": ["cs.CR", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.04916", "abs": "https://arxiv.org/abs/2507.04916", "authors": ["Kazumasa Shinagawa", "Koji Nuida"], "title": "Cyclic Equalizability of Words and Its Application to Card-Based Cryptography", "comment": "11 pages, to appear in 25th International Symposium on Fundamentals\n  of Computation Theory (FCT 2025)", "summary": "Card-based cryptography is a research area to implement cryptographic\nprocedures using a deck of physical cards. In recent years, it has been found\nto be related to finite group theory and algebraic combinatorics, and is\nbecoming more and more closely connected to the field of mathematics. In this\npaper, we discuss the relationship between card-based cryptography and\ncombinatorics on words for the first time. In particular, we focus on cyclic\nequality of words. We say that a set of words are cyclically equalizable if\nthey can be transformed to be cyclically equal by repeated simultaneous\ninsertion of letters. The main result of this paper is to show that two binary\nwords of equal length and equal Hamming weight are cyclically equalizable. As\napplications of cyclic equalizability to card-based cryptography, we describe\nits applications to the information erasure problem and to single-cut full-open\nprotocols."}
{"id": "2507.04426", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.04426", "abs": "https://arxiv.org/abs/2507.04426", "authors": ["Novruz Amirov", "Leminur Celik", "Egemen Ali Caner", "Emre Yurdakul", "Fahri Anil Yerlikaya", "Serif Bahtiyar"], "title": "Enhancing Phishing Detection in Financial Systems through NLP", "comment": null, "summary": "The threat of phishing attacks in financial systems is continuously growing.\nTherefore, protecting sensitive information from unauthorized access is\nparamount. This paper discusses the critical need for robust email phishing\ndetection. Several existing methods, including blacklists and whitelists, play\na crucial role in detecting phishing attempts. Nevertheless, these methods\npossess inherent limitations, emphasizing the need for the development of a\nmore advanced solution. Our proposed solution presents a pioneering Natural\nLanguage Processing (NLP) approach for phishing email detection. Leveraging\nsemantic similarity and TFIDF (Term Frequency-Inverse Document Frequency)\nanalysis, our solution identifies keywords in phishing emails, subsequently\nevaluating the semantic similarities with a dedicated phishing dataset,\nultimately contributing to the enhancement of cybersecurity and NLP domains\nthrough a robust solution for detecting phishing threats in financial systems.\nExperimental results show the accuracy of our phishing detection method can\nreach 79.8 percent according to TF-IDF analysis, while it can reach 67.2\npercent according to semantic analysis."}
{"id": "2507.03998", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03998", "abs": "https://arxiv.org/abs/2507.03998", "authors": ["Thuy An Ha", "Bao Quoc Vo"], "title": "Toward Better Generalisation in Uncertainty Estimators: Leveraging Data-Agnostic Features", "comment": null, "summary": "Large Language Models (LLMs) often generate responses that are factually\nincorrect yet expressed with high confidence, which can pose serious risks for\nend users. To address this, it is essential for LLMs not only to produce\nanswers but also to provide accurate estimates of their correctness.\nUncertainty quantification methods have been introduced to assess the quality\nof LLM outputs, with factual accuracy being a key aspect of that quality. Among\nthese methods, those that leverage hidden states to train probes have shown\nparticular promise, as these internal representations encode information\nrelevant to the factuality of responses, making this approach the focus of this\npaper. However, the probe trained on the hidden states of one dataset often\nstruggles to generalise to another dataset of a different task or domain. To\naddress this limitation, we explore combining data-agnostic features with\nhidden-state features and assess whether this hybrid feature set enhances\nout-of-domain performance. We further examine whether selecting only the most\ninformative hidden-state features, thereby discarding task-specific noise,\nenables the data-agnostic features to contribute more effectively. The\nexperiment results indicate that although introducing data-agnostic features\ngenerally enhances generalisation performance in most cases, in certain\nscenarios their inclusion degrades performance. A similar pattern emerges when\nretaining only the most important hidden-state features - adding data-agnostic\nfeatures does not consistently further enhance performance compared to using\nthe full set of hidden-state features. A closer analysis reveals that, in some\nspecific cases, the trained probe underweights the data-agnostic features\nrelative to the hidden-state features, which we believe is the main reason why\nthe results are inconclusive."}
{"id": "2507.04457", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.04457", "abs": "https://arxiv.org/abs/2507.04457", "authors": ["Ruixuan Liu", "Li Xiong"], "title": "UniAud: A Unified Auditing Framework for High Auditing Power and Utility with One Training Run", "comment": "14 pages", "summary": "Differentially private (DP) optimization has been widely adopted as a\nstandard approach to provide rigorous privacy guarantees for training datasets.\nDP auditing verifies whether a model trained with DP optimization satisfies its\nclaimed privacy level by estimating empirical privacy lower bounds through\nhypothesis testing. Recent O(1) frameworks improve auditing efficiency by\nchecking the membership status of multiple audit samples in a single run,\nrather than checking individual samples across multiple runs. However, we\nreveal that there is no free lunch for this improved efficiency: data\ndependency and an implicit conflict between auditing and utility impair the\ntightness of the auditing results. Addressing these challenges, our key\ninsights include reducing data dependency through uncorrelated data and\nresolving the auditing-utility conflict by decoupling the criteria for\neffective auditing and separating objectives for utility and auditing. We first\npropose a unified framework, UniAud, for data-independent auditing that\nmaximizes auditing power through a novel uncorrelated canary construction and a\nself-comparison framework. We then extend this framework as UniAud++ for\ndata-dependent auditing, optimizing the auditing and utility trade-off through\nmulti-task learning with separate objectives for auditing and training.\nExperimental results validate that our black-box O(1) framework matches the\nstate-of-the-art auditing results of O(T) auditing with thousands of runs,\ndemonstrating the best efficiency-auditing trade-off across vision and language\ntasks. Additionally, our framework provides meaningful auditing with only\nslight utility degradation compared to standard DP training, showing the\noptimal utility-auditing trade-off and the benefit of requiring no extra\ntraining for auditing."}
{"id": "2507.04034", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04034", "abs": "https://arxiv.org/abs/2507.04034", "authors": ["Weizhi Tang", "Kwabena Nuamah", "Vaishak Belle"], "title": "Lyria: A General LLM-Driven Genetic Algorithm Framework for Problem Solving", "comment": null, "summary": "While Large Language Models (LLMs) have demonstrated impressive abilities\nacross various domains, they still struggle with complex problems characterized\nby multi-objective optimization, precise constraint satisfaction, immense\nsolution spaces, etc. To address the limitation, drawing on the superior\nsemantic understanding ability of LLMs and also the outstanding global search\nand optimization capability of genetic algorithms, we propose to capitalize on\ntheir respective strengths and introduce Lyria, a general LLM-driven genetic\nalgorithm framework, comprising 7 essential components. Through conducting\nextensive experiments with 4 LLMs across 3 types of problems, we demonstrated\nthe efficacy of Lyria. Additionally, with 7 additional ablation experiments, we\nfurther systematically analyzed and elucidated the factors that affect its\nperformance."}
{"id": "2507.04461", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.04461", "abs": "https://arxiv.org/abs/2507.04461", "authors": ["Tanvir Rahman", "A. B. M. Harun-ur Rashid"], "title": "Arbiter PUF: Uniqueness and Reliability Analysis Using Hybrid CMOS-Stanford Memristor Model", "comment": null, "summary": "In an increasingly interconnected world, protecting electronic devices has\ngrown more crucial because of the dangers of data extraction, reverse\nengineering, and hardware tampering. Producing chips in a third-party\nmanufacturing company can let hackers change the design. As the Internet of\nThings (IoT) proliferates, physical attacks happen more, and conventional\ncryptography techniques do not function well. In this paper, we investigate the\ndesign and assessment of PUFs using the Stanford Memristor Model, utilizing its\nrandom filament evolution to improve security. The system was built using 45nm\nCMOS technology. A comparison is made between CMOS-based and memristor-based\nArbiter PUFs, evaluating their performance under temperature, voltage, and\nprocess variations. Intra- and inter-hamming distances are employed by Monte\nCarlo simulations to estimate uniqueness and reliability. The results show that\nmemristor-based PUFs offer better reliability than CMOS-based designs, though\nuniqueness needs further improvement. Furthermore, this study sheds light on\nthe reasonableness of memristor-based PUFs for secure applications in hardware\nsecurity."}
{"id": "2507.04037", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04037", "abs": "https://arxiv.org/abs/2507.04037", "authors": ["Zheng Jia", "Shengbin Yue", "Wei Chen", "Siyuan Wang", "Yidong Liu", "Yun Song", "Zhongyu Wei"], "title": "Ready Jurist One: Benchmarking Language Agents for Legal Intelligence in Dynamic Environments", "comment": null, "summary": "The gap between static benchmarks and the dynamic nature of real-world legal\npractice poses a key barrier to advancing legal intelligence. To this end, we\nintroduce J1-ENVS, the first interactive and dynamic legal environment tailored\nfor LLM-based agents. Guided by legal experts, it comprises six representative\nscenarios from Chinese legal practices across three levels of environmental\ncomplexity. We further introduce J1-EVAL, a fine-grained evaluation framework,\ndesigned to assess both task performance and procedural compliance across\nvarying levels of legal proficiency. Extensive experiments on 17 LLM agents\nreveal that, while many models demonstrate solid legal knowledge, they struggle\nwith procedural execution in dynamic settings. Even the SOTA model, GPT-4o,\nfalls short of 60% overall performance. These findings highlight persistent\nchallenges in achieving dynamic legal intelligence and offer valuable insights\nto guide future research."}
{"id": "2507.04495", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.04495", "abs": "https://arxiv.org/abs/2507.04495", "authors": ["Hyunwook Choi", "Sangyun Won", "Daeyeon Hwang", "Junhyeok Choi"], "title": "README: Robust Error-Aware Digital Signature Framework via Deep Watermarking Model", "comment": null, "summary": "Deep learning-based watermarking has emerged as a promising solution for\nrobust image authentication and protection. However, existing models are\nlimited by low embedding capacity and vulnerability to bit-level errors, making\nthem unsuitable for cryptographic applications such as digital signatures,\nwhich require over 2048 bits of error-free data. In this paper, we propose\nREADME (Robust Error-Aware Digital Signature via Deep WaterMarking ModEl), a\nnovel framework that enables robust, verifiable, and error-tolerant digital\nsignatures within images. Our method combines a simple yet effective\ncropping-based capacity scaling mechanism with ERPA (ERror PAinting Module), a\nlightweight error correction module designed to localize and correct bit errors\nusing Distinct Circular Subsum Sequences (DCSS). Without requiring any\nfine-tuning of existing pretrained watermarking models, README significantly\nboosts the zero-bit-error image rate (Z.B.I.R) from 1.2% to 86.3% when\nembedding 2048-bit digital signatures into a single image, even under\nreal-world distortions. Moreover, our use of perceptual hash-based signature\nverification ensures public verifiability and robustness against tampering. The\nproposed framework unlocks a new class of high-assurance applications for deep\nwatermarking, bridging the gap between signal-level watermarking and\ncryptographic security."}
{"id": "2507.04067", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.04067", "abs": "https://arxiv.org/abs/2507.04067", "authors": ["Yuyang Cheng", "Yumiao Xu", "Chaojia Yu", "Yong Zhao"], "title": "HAWK: A Hierarchical Workflow Framework for Multi-Agent Collaboration", "comment": "AgentIR@SIGIR 2025", "summary": "Contemporary multi-agent systems encounter persistent challenges in\ncross-platform interoperability, dynamic task scheduling, and efficient\nresource sharing. Agents with heterogeneous implementations often lack\nstandardized interfaces; collaboration frameworks remain brittle and hard to\nextend; scheduling policies are static; and inter-agent state synchronization\nis insufficient. We propose Hierarchical Agent Workflow (HAWK), a modular\nframework comprising five layers-User, Workflow, Operator, Agent, and\nResource-and supported by sixteen standardized interfaces. HAWK delivers an\nend-to-end pipeline covering task parsing, workflow orchestration, intelligent\nscheduling, resource invocation, and data synchronization. At its core lies an\nadaptive scheduling and optimization module in the Workflow Layer, which\nharnesses real-time feedback and dynamic strategy adjustment to maximize\nutilization. The Resource Layer provides a unified abstraction over\nheterogeneous data sources, large models, physical devices, and third-party\nservices&tools, simplifying cross-domain information retrieval. We demonstrate\nHAWK's scalability and effectiveness via CreAgentive, a multi-agent\nnovel-generation prototype, which achieves marked gains in throughput, lowers\ninvocation complexity, and improves system controllability. We also show how\nhybrid deployments of large language models integrate seamlessly within HAWK,\nhighlighting its flexibility. Finally, we outline future research\navenues-hallucination mitigation, real-time performance tuning, and enhanced\ncross-domain adaptability-and survey prospective applications in healthcare,\ngovernment, finance, and education."}
{"id": "2507.04501", "categories": ["cs.CR", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.04501", "abs": "https://arxiv.org/abs/2507.04501", "authors": ["Gennady Khalimov", "Yevgen Kotukh"], "title": "LINE: Public-key encryption", "comment": null, "summary": "We propose a public key encryption cryptosystem based on solutions of linear\nequation systems with predefinition of input parameters through shared secret\ncomputation for factorizable substitutions. The existence of multiple\nequivalent solutions for an underdetermined system of linear equations\ndetermines the impossibility of its resolution by a cryptanalyst in polynomial\ntime. The completion of input parameters of the equation system is implemented\nthrough secret homomorphic matrix transformation for substitutions factorized\nover the basis of a vector space of dimension m over the field F2. Encryption\nis implemented through computation of substitutions that are one-way functions\non an elementary abelian 2-group of order 2\"m. Decryption is implemented\nthrough completion of input parameters of the equation system. Homomorphic\ntransformations are constructed based on matrix computations. Matrix\ncomputations enable the implementation of high security and low computational\noverhead for homomorphic transformations."}
{"id": "2507.04103", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.04103", "abs": "https://arxiv.org/abs/2507.04103", "authors": ["Dheeraj Vattikonda", "Santhoshi Ravichandran", "Emiliano Penaloza", "Hadi Nekoei", "Megh Thakkar", "Thibault Le Sellier de Chezelles", "Nicolas Gontier", "Miguel Muñoz-Mármol", "Sahar Omidi Shayegan", "Stefania Raimondo", "Xue Liu", "Alexandre Drouin", "Laurent Charlin", "Alexandre Piché", "Alexandre Lacoste", "Massimo Caccia"], "title": "How to Train Your LLM Web Agent: A Statistical Diagnosis", "comment": null, "summary": "LLM-based web agents have recently made significant progress, but much of it\nhas occurred in closed-source systems, widening the gap with open-source\nalternatives. Progress has been held back by two key challenges: first, a\nnarrow focus on single-step tasks that overlooks the complexity of multi-step\nweb interactions; and second, the high compute costs required to post-train\nLLM-based web agents. To address this, we present the first statistically\ngrounded study on compute allocation for LLM web-agent post-training. Our\napproach uses a two-stage pipeline, training a Llama 3.1 8B student to imitate\na Llama 3.3 70B teacher via supervised fine-tuning (SFT), followed by on-policy\nreinforcement learning. We find this process highly sensitive to hyperparameter\nchoices, making exhaustive sweeps impractical. To spare others from expensive\ntrial-and-error, we sample 1,370 configurations and use bootstrapping to\nestimate effective hyperparameters. Our results show that combining SFT with\non-policy RL consistently outperforms either approach alone on both WorkArena\nand MiniWob++. Further, this strategy requires only 55% of the compute to match\nthe peak performance of pure SFT on MiniWob++, effectively pushing the\ncompute-performance Pareto frontier, and is the only strategy that can close\nthe gap with closed-source models."}
{"id": "2507.04752", "categories": ["cs.CR", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.04752", "abs": "https://arxiv.org/abs/2507.04752", "authors": ["Shuo Yang", "Xinran Zheng", "Xinchen Zhang", "Jinfeng Xu", "Jinze Li", "Donglin Xie", "Weicai Long", "Edith C. H. Ngai"], "title": "Large Language Models for Network Intrusion Detection Systems: Foundations, Implementations, and Future Directions", "comment": null, "summary": "Large Language Models (LLMs) have revolutionized various fields with their\nexceptional capabilities in understanding, processing, and generating\nhuman-like text. This paper investigates the potential of LLMs in advancing\nNetwork Intrusion Detection Systems (NIDS), analyzing current challenges,\nmethodologies, and future opportunities. It begins by establishing a\nfoundational understanding of NIDS and LLMs, exploring the enabling\ntechnologies that bridge the gap between intelligent and cognitive systems in\nAI-driven NIDS. While Intelligent NIDS leverage machine learning and deep\nlearning to detect threats based on learned patterns, they often lack\ncontextual awareness and explainability. In contrast, Cognitive NIDS integrate\nLLMs to process both structured and unstructured security data, enabling deeper\ncontextual reasoning, explainable decision-making, and automated response for\nintrusion behaviors. Practical implementations are then detailed, highlighting\nLLMs as processors, detectors, and explainers within a comprehensive AI-driven\nNIDS pipeline. Furthermore, the concept of an LLM-centered Controller is\nproposed, emphasizing its potential to coordinate intrusion detection\nworkflows, optimizing tool collaboration and system performance. Finally, this\npaper identifies critical challenges and opportunities, aiming to foster\ninnovation in developing reliable, adaptive, and explainable NIDS. By\npresenting the transformative potential of LLMs, this paper seeks to inspire\nadvancement in next-generation network security systems."}
{"id": "2507.04105", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.04105", "abs": "https://arxiv.org/abs/2507.04105", "authors": ["Jinwei Hu", "Yi Dong", "Zhengtao Ding", "Xiaowei Huang"], "title": "Enhancing Robustness of LLM-Driven Multi-Agent Systems through Randomized Smoothing", "comment": "Preprint accepted by Chinese Journal of Aeronautics", "summary": "This paper presents a defense framework for enhancing the safety of large\nlanguage model (LLM) empowered multi-agent systems (MAS) in safety-critical\ndomains such as aerospace. We apply randomized smoothing, a statistical\nrobustness certification technique, to the MAS consensus context, enabling\nprobabilistic guarantees on agent decisions under adversarial influence. Unlike\ntraditional verification methods, our approach operates in black-box settings\nand employs a two-stage adaptive sampling mechanism to balance robustness and\ncomputational efficiency. Simulation results demonstrate that our method\neffectively prevents the propagation of adversarial behaviors and\nhallucinations while maintaining consensus performance. This work provides a\npractical and scalable path toward safe deployment of LLM-based MAS in\nreal-world, high-stakes environments."}
{"id": "2507.04771", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.04771", "abs": "https://arxiv.org/abs/2507.04771", "authors": ["Josep Domingo-Ferrer", "Najeeb Jebreel", "David Sánchez"], "title": "Efficient Unlearning with Privacy Guarantees", "comment": null, "summary": "Privacy protection laws, such as the GDPR, grant individuals the right to\nrequest the forgetting of their personal data not only from databases but also\nfrom machine learning (ML) models trained on them. Machine unlearning has\nemerged as a practical means to facilitate model forgetting of data instances\nseen during training. Although some existing machine unlearning methods\nguarantee exact forgetting, they are typically costly in computational terms.\nOn the other hand, more affordable methods do not offer forgetting guarantees\nand are applicable only to specific ML models. In this paper, we present\n\\emph{efficient unlearning with privacy guarantees} (EUPG), a novel machine\nunlearning framework that offers formal privacy guarantees to individuals whose\ndata are being unlearned. EUPG involves pre-training ML models on data\nprotected using privacy models, and it enables {\\em efficient unlearning with\nthe privacy guarantees offered by the privacy models in use}. Through empirical\nevaluation on four heterogeneous data sets protected with $k$-anonymity and\n$\\epsilon$-differential privacy as privacy models, our approach demonstrates\nutility and forgetting effectiveness comparable to those of exact unlearning\nmethods, while significantly reducing computational and storage costs. Our code\nis available at https://github.com/najeebjebreel/EUPG."}
{"id": "2507.04136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04136", "abs": "https://arxiv.org/abs/2507.04136", "authors": ["Saksham Sahai Srivastava", "Vaneet Aggarwal"], "title": "A Technical Survey of Reinforcement Learning Techniques for Large Language Models", "comment": "24 pages, LaTeX source", "summary": "Reinforcement Learning (RL) has emerged as a transformative approach for\naligning and enhancing Large Language Models (LLMs), addressing critical\nchallenges in instruction following, ethical alignment, and reasoning\ncapabilities. This survey offers a comprehensive foundation on the integration\nof RL with language models, highlighting prominent algorithms such as Proximal\nPolicy Optimization (PPO), Q-Learning, and Actor-Critic methods. Additionally,\nit provides an extensive technical overview of RL techniques specifically\ntailored for LLMs, including foundational methods like Reinforcement Learning\nfrom Human Feedback (RLHF) and AI Feedback (RLAIF), as well as advanced\nstrategies such as Direct Preference Optimization (DPO) and Group Relative\nPolicy Optimization (GRPO). We systematically analyze their applications across\ndomains, i.e., from code generation to tool-augmented reasoning. We also\npresent a comparative taxonomy based on reward modeling, feedback mechanisms,\nand optimization strategies. Our evaluation highlights key trends. RLHF remains\ndominant for alignment, and outcome-based RL such as RLVR significantly\nimproves stepwise reasoning. However, persistent challenges such as reward\nhacking, computational costs, and scalable feedback collection underscore the\nneed for continued innovation. We further discuss emerging directions,\nincluding hybrid RL algorithms, verifier-guided training, and multi-objective\nalignment frameworks. This survey serves as a roadmap for researchers advancing\nRL-driven LLM development, balancing capability enhancement with safety and\nscalability."}
{"id": "2507.04775", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.04775", "abs": "https://arxiv.org/abs/2507.04775", "authors": ["Carlos Agulló-Domingo", "Óscar Vera-López", "Seyda Guzelhan", "Lohit Daksha", "Aymane El Jerari", "Kaustubh Shivdikar", "Rashmi Agrawal", "David Kaeli", "Ajay Joshi", "José L. Abellán"], "title": "FIDESlib: A Fully-Fledged Open-Source FHE Library for Efficient CKKS on GPUs", "comment": "Presented as poster paper at 2025 IEEE International Symposium on\n  Performance Analysis of Systems and Software (ISPASS)", "summary": "Word-wise Fully Homomorphic Encryption (FHE) schemes, such as CKKS, are\ngaining significant traction due to their ability to provide\npost-quantum-resistant, privacy-preserving approximate computing; an especially\ndesirable feature in Machine-Learning-as-a-Service (MLaaS) cloud-computing\nparadigms. OpenFHE is a leading CPU-based FHE library with robust CKKS\noperations, but its server-side performance is not yet sufficient for practical\ncloud deployment. As GPU computing becomes more common in data centers, many\nFHE libraries are adding GPU support. However, integrating an efficient GPU\nbackend into OpenFHE is challenging. While OpenFHE uses a Hardware Abstraction\nLayer (HAL), its flexible architecture sacrifices performance due to the\nabstraction layers required for multi-scheme and multi-backend compatibility.\nIn this work, we introduce FIDESlib, the first open-source server-side CKKS GPU\nlibrary that is fully interoperable with well-established client-side OpenFHE\noperations. Unlike other existing open-source GPU libraries, FIDESlib provides\nthe first implementation featuring heavily optimized GPU kernels for all CKKS\nprimitives, including bootstrapping. Our library also integrates robust\nbenchmarking and testing, ensuring it remains adaptable to further\noptimization. Furthermore, its software architecture is designed to support\nextensions to a multi-GPU backend for enhanced acceleration. Our experiments\nacross various GPU systems and the leading open-source CKKS library to date,\nPhantom, show that FIDESlib offers superior performance and scalability. For\nbootstrapping, FIDESlib achieves no less than 70x speedup over the\nAVX-optimized OpenFHE implementation."}
{"id": "2507.04206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04206", "abs": "https://arxiv.org/abs/2507.04206", "authors": ["Sibei Liu", "Zhijian Hu"], "title": "Mpemba Effect in Large-Language Model Training Dynamics: A Minimal Analysis of the Valley-River model", "comment": null, "summary": "Learning rate (LR) schedules in large language model (LLM) training often\nfollow empirical templates: warm-up, constant plateau/stable phase, and decay\n(WSD). However, the mechanistic explanation for this strategy remains\nunderexplored, and the choice of plateau height and decay schedule is largely\nheuristic. In this paper, we connect training dynamics to a thermodynamic\nanalogy via the Mpemba effect - a phenomenon in which a hotter system cools\nfaster than a colder one when quenched into the same bath. We analyze a class\nof \"valley-river\" loss landscapes, where sharp (valley) directions equilibrate\nquickly, while flatter (river) directions govern global descent. The Mpemba\neffect provides an explanation for the necessity of the warm-up phase and\nmotivates a high plateau - rather than a low one - for accelerating loss\ndecrease during decay. We show that for certain loss landscapes, there exists\nan optimal plateau learning rate - the \"strong Mpemba point\" - at which the\nslowest mode vanishes, resulting in faster convergence during the decay phase.\nWe derive analytical conditions for its existence and estimate decay dynamics\nrequired to preserve the Mpemba advantage. Our minimal model and analysis offer\na principled justification for plateau-based schedulers and provide guidance\nfor tuning LR in LLMs with minimal hyperparameter sweep."}
{"id": "2507.04855", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.04855", "abs": "https://arxiv.org/abs/2507.04855", "authors": ["Darya Parygina", "Timofey Mezhuev", "Daniil Kuts"], "title": "Hybrid Approach to Directed Fuzzing", "comment": null, "summary": "Program analysis and automated testing have recently become an essential part\nof SSDLC. Directed greybox fuzzing is one of the most popular automated testing\nmethods that focuses on error detection in predefined code regions. However, it\nstill lacks ability to overcome difficult program constraints. This problem can\nbe well addressed by symbolic execution, but at the cost of lower performance.\nThus, combining directed fuzzing and symbolic execution techniques can lead to\nmore efficient error detection.\n  In this paper, we propose a hybrid approach to directed fuzzing with novel\nseed scheduling algorithm, based on target-related interestingness and\ncoverage. The approach also performs minimization and sorting of objective\nseeds according to a target-related information. We implement our approach in\nSydr-Fuzz tool using LibAFL-DiFuzz as directed fuzzer and Sydr as dynamic\nsymbolic executor. We evaluate our approach with Time to Exposure metric and\ncompare it with pure LibAFL-DiFuzz, AFLGo, BEACON, WAFLGo, WindRanger,\nFishFuzz, and Prospector. The results show an improvement for 3 out of 7\nexamples with speedup up to 1.86 times over the second best result, as well as\na significant improvement for 3 out of 7 examples over the pure LibAFL-DiFuzz\nfuzzer. Sydr-Fuzz hybrid approach to directed fuzzing shows high performance\nand helps to improve directed fuzzing efficiency."}
{"id": "2507.04283", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.04283", "abs": "https://arxiv.org/abs/2507.04283", "authors": ["Roy Uziel", "Irit Chelly", "Oren Freifeld", "Ari Pakman"], "title": "Clustering via Self-Supervised Diffusion", "comment": null, "summary": "Diffusion models, widely recognized for their success in generative tasks,\nhave not yet been applied to clustering. We introduce Clustering via Diffusion\n(CLUDI), a self-supervised framework that combines the generative power of\ndiffusion models with pre-trained Vision Transformer features to achieve robust\nand accurate clustering. CLUDI is trained via a teacher-student paradigm: the\nteacher uses stochastic diffusion-based sampling to produce diverse cluster\nassignments, which the student refines into stable predictions. This\nstochasticity acts as a novel data augmentation strategy, enabling CLUDI to\nuncover intricate structures in high-dimensional data. Extensive evaluations on\nchallenging datasets demonstrate that CLUDI achieves state-of-the-art\nperformance in unsupervised classification, setting new benchmarks in\nclustering robustness and adaptability to complex data distributions."}
{"id": "2507.04903", "categories": ["cs.CR", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.04903", "abs": "https://arxiv.org/abs/2507.04903", "authors": ["Thinh Dao", "Dung Thuy Nguyen", "Khoa D Doan", "Kok-Seng Wong"], "title": "BackFed: An Efficient & Standardized Benchmark Suite for Backdoor Attacks in Federated Learning", "comment": "Under review at NeurIPS'25", "summary": "Federated Learning (FL) systems are vulnerable to backdoor attacks, where\nadversaries train their local models on poisoned data and submit poisoned model\nupdates to compromise the global model. Despite numerous proposed attacks and\ndefenses, divergent experimental settings, implementation errors, and\nunrealistic assumptions hinder fair comparisons and valid conclusions about\ntheir effectiveness in real-world scenarios. To address this, we introduce\nBackFed - a comprehensive benchmark suite designed to standardize, streamline,\nand reliably evaluate backdoor attacks and defenses in FL, with a focus on\npractical constraints. Our benchmark offers key advantages through its\nmulti-processing implementation that significantly accelerates experimentation\nand the modular design that enables seamless integration of new methods via\nwell-defined APIs. With a standardized evaluation pipeline, we envision BackFed\nas a plug-and-play environment for researchers to comprehensively and reliably\nevaluate new attacks and defenses. Using BackFed, we conduct large-scale\nstudies of representative backdoor attacks and defenses across both Computer\nVision and Natural Language Processing tasks with diverse model architectures\nand experimental settings. Our experiments critically assess the performance of\nproposed attacks and defenses, revealing unknown limitations and modes of\nfailures under practical conditions. These empirical insights provide valuable\nguidance for the development of new methods and for enhancing the security of\nFL systems. Our framework is openly available at\nhttps://github.com/thinh-dao/BackFed."}
{"id": "2507.04299", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04299", "abs": "https://arxiv.org/abs/2507.04299", "authors": ["Joohyung Lee", "Yunsong Meng"], "title": "Answer Set Programming Modulo Theories and Reasoning about Continuous Changes", "comment": "In Proceedings of the 23rd International Joint Conference on\n  Artificial Intelligence (IJCAI 2013), pages 990-996, 2013", "summary": "Answer Set Programming Modulo Theories (ASPMT) is a new framework of tight\nintegration of answer set programming (ASP) and satisfiability modulo theories\n(SMT). Similar to the relationship between first-order logic and SMT, it is\nbased on a recent proposal of the functional stable model semantics by fixing\ninterpretations of background theories. Analogously to a known relationship\nbetween ASP and SAT, ``tight'' ASPMT programs can be translated into SMT\ninstances. We demonstrate the usefulness of ASPMT by enhancing action language\nC+ to handle continuous changes as well as discrete changes. We reformulate the\nsemantics of C+ in terms ofASPMT, and show that SMT solvers can be used to\ncompute the language. We also show how the language can represent cumulative\neffects on continuous resources."}
{"id": "2507.04916", "categories": ["cs.CR", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.04916", "abs": "https://arxiv.org/abs/2507.04916", "authors": ["Kazumasa Shinagawa", "Koji Nuida"], "title": "Cyclic Equalizability of Words and Its Application to Card-Based Cryptography", "comment": "11 pages, to appear in 25th International Symposium on Fundamentals\n  of Computation Theory (FCT 2025)", "summary": "Card-based cryptography is a research area to implement cryptographic\nprocedures using a deck of physical cards. In recent years, it has been found\nto be related to finite group theory and algebraic combinatorics, and is\nbecoming more and more closely connected to the field of mathematics. In this\npaper, we discuss the relationship between card-based cryptography and\ncombinatorics on words for the first time. In particular, we focus on cyclic\nequality of words. We say that a set of words are cyclically equalizable if\nthey can be transformed to be cyclically equal by repeated simultaneous\ninsertion of letters. The main result of this paper is to show that two binary\nwords of equal length and equal Hamming weight are cyclically equalizable. As\napplications of cyclic equalizability to card-based cryptography, we describe\nits applications to the information erasure problem and to single-cut full-open\nprotocols."}
{"id": "2507.04338", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04338", "abs": "https://arxiv.org/abs/2507.04338", "authors": ["Abdullah M. Zyarah", "Dhireesha Kudithipudi"], "title": "Voltage Mode Winner-Take-All Circuit for Neuromorphic Systems", "comment": null, "summary": "Recent advances in neuromorphic computing demonstrate on-device learning\ncapabilities with low power consumption. One of the key learning units in these\nsystems is the winner-take-all circuit. In this research, we propose a\nwinner-take-all circuit that can be configured to achieve k-winner and\nhysteresis properties, simulated in IBM 65 nm node. The circuit dissipated 34.9\n$\\mu$W of power with a latency of 10.4 ns, while processing 1000 inputs. The\nutility of the circuit is demonstrated for spatial filtering and\nclassification."}
{"id": "2507.04931", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.04931", "abs": "https://arxiv.org/abs/2507.04931", "authors": ["Ruoxi Wang", "Kun Li", "Minghui Xu", "Yue Zhang", "Kaidi Xu", "Chunchi Liu", "Yinhao Xiao", "Xiuzhen Cheng"], "title": "LIFT: Automating Symbolic Execution Optimization with Large Language Models for AI Networks", "comment": "Accepted by ACM SIGCOMM 2025 - 2nd Workshop on Networks for AI\n  Computing (NAIC). 7 pages, 2 figures, 2 tables", "summary": "Dynamic Symbolic Execution (DSE) is a key technique in program analysis,\nwidely used in software testing, vulnerability discovery, and formal\nverification. In distributed AI systems, DSE plays a crucial role in\nidentifying hard-to-detect bugs, especially those arising from complex network\ncommunication patterns. However, traditional approaches to symbolic execution\nare often hindered by scalability issues and inefficiencies, particularly in\nlarge-scale systems. This paper introduces LIFT (Large-language-model\nIntegrated Functional-equivalent-IR Transformation), a novel framework that\nleverages Large Language Models (LLMs) to automate the optimization of\nIntermediate Representations (IRs) in symbolic execution. LIFT addresses the\nchallenges of symbolic execution by providing a scalable, context-sensitive\nsolution for IR transformation. The framework consists of two phases: IR\nAnalysis and Optimization, where LLMs optimize time-intensive IR blocks, and\nSymbolic Execution and Validation, which includes benchmarking and semantic\nverification to ensure correctness and generalizability. Experiments on\nreal-world binaries demonstrated significant performance improvements,\nincluding a 53.5\\% reduction in execution time for bigtest and a 10.24\\%\nreduction for random, along with reductions in IR statements, PUT instructions,\nand temporary variables. These results demonstrate that LLMs simplify IRs while\nmaintaining functional correctness, enhancing symbolic execution in distributed\nAI systems."}
{"id": "2507.04348", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.04348", "abs": "https://arxiv.org/abs/2507.04348", "authors": ["Xingyang He", "Xiao Ling", "Jie Liu"], "title": "SmartThinker: Learning to Compress and Preserve Reasoning by Step-Level Length Control", "comment": null, "summary": "Large reasoning models (LRMs) have exhibited remarkable reasoning\ncapabilities through inference-time scaling, but this progress has also\nintroduced considerable redundancy and inefficiency into their reasoning\nprocesses, resulting in substantial computational waste. Previous work has\nattempted to mitigate this issue by penalizing the overall length of generated\nsamples during reinforcement learning (RL), with the goal of encouraging a more\nconcise chains of thought. However, we observe that such global length penalty\noften lead to excessive compression of critical reasoning steps while\npreserving unnecessary details in simpler ones, yielding a suboptimal trade-off\nbetween accuracy and efficiency. To address this issue, we propose\nSmartThinker, a two-stage learnable framework designed to enable fine-grained\ncontrol over the length of reasoning chains based on the importance of each\nindividual step. In the first stage, SmartThinker adapts a reasoning model to a\nshort-form reasoning mode through rejection sampling combined with supervised\nfine-tuning (SFT). In the second stage, SmartThinker applies Step-Level Length\nControl Policy Optimization (SCPO) to refine the model output distribution,\nwhich increases the proportion of length allocated to critical steps while\nreducing redundancy in less important ones. SCPO consists of four core\ncomponents: an online importance estimator, a step-level length control reward\nfunction, a step-level generalized advantage estimation (S-GAE) and a\ndifficulty-adaptive clipping strategy. Working in concert, these components\nenable SCPO to implement differentiated length control across reasoning steps.\nEmpirical results across multiple reasoning benchmarks and various backbone\nmodels demonstrate that SmartThinker significantly reduces redundant reasoning\nwhile achieving comparable or even superior performance to existing methods."}
{"id": "2507.04956", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.04956", "abs": "https://arxiv.org/abs/2507.04956", "authors": ["Yusei Tanaka"], "title": "Bullshark on Narwhal: Implementation-level Workflow Analysis of Round-based DAG Consensus in Theory and Practice", "comment": "17 pages, in Japanese language, 11 figures", "summary": "Round-based DAGs enable high-performance Byzantine fault-tolerant consensus,\nyet their technical advantages remain underutilized due to their short history.\nWhile research on consensus protocols is active in both academia and industry,\nmany studies overlook implementation-level algorithms, leaving actual\nperformance unclear - particularly for theoretical protocols whose practical\nperformance cannot often be evaluated. Bullshark, a Round-based DAG BFT\nprotocol on Narwhal mempool, achieves optimal performance: 297,000 transactions\nper second with 2-second latency. We analyze the algorithm's workflow, from\ntransaction submission to blockchain commitment, breaking it down layer by\nlayer at the functional level and delineating the key features and interactions\nof the Bullshark and Narwhal components. Future work aims to improve\nperformance in Byzantine fault environments and optimize trade-offs in the CAP\ntheorem."}
{"id": "2507.04370", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04370", "abs": "https://arxiv.org/abs/2507.04370", "authors": ["Yifei Gao", "Junhong Ye", "Jiaqi Wang", "Jitao Sang"], "title": "WebSynthesis: World-Model-Guided MCTS for Efficient WebUI-Trajectory Synthesis", "comment": null, "summary": "Recent advancements in large language models (LLMs) have significantly\nimproved the capabilities of web agents. However, effectively navigating\ncomplex and dynamic web environments still requires more advanced\ntrajectory-level planning and execution. Prior studies have addressed\nself-improving agents by collecting extensive GUI trajectories from\nreal-environment interactions. Despite their effectiveness, these approaches\nencounter two critical challenges: (1) Uncontrollable environment states, where\nreal or sandboxed web environments often yield unstable and non-deterministic\nfeedback, complicating the reproduction and debugging of agent behaviors; and\n(2) High API costs, as generating even a single interaction trajectory can\ninvolve hundreds of queries, leading to considerable API usage and\ncomputational expenses. To address these limitations and enable scalable\nself-improvement for agents, we propose WebSynthesis, a novel framework for\ntrajectory synthesis and training. WebSynthesis leverages a learned world model\nto simulate virtual web environments, allowing a policy agent to perform\nefficient and reversible tree-based planning. This approach supports the\nlarge-scale generation of diverse and high-quality trajectories, which are\nsubsequently utilized to refine the agent's policy. Experimental results\ndemonstrate that an agent trained using WebSynthesis on a small-scale synthetic\ndataset achieves performance comparable to or even surpassing that of models\ntrained on large-scale real-world data."}
{"id": "2507.05093", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05093", "abs": "https://arxiv.org/abs/2507.05093", "authors": ["Alberto Castagnaro", "Umberto Salviati", "Mauro Conti", "Luca Pajola", "Simeone Pizzi"], "title": "The Hidden Threat in Plain Text: Attacking RAG Data Loaders", "comment": "currently under submission", "summary": "Large Language Models (LLMs) have transformed human-machine interaction since\nChatGPT's 2022 debut, with Retrieval-Augmented Generation (RAG) emerging as a\nkey framework that enhances LLM outputs by integrating external knowledge.\nHowever, RAG's reliance on ingesting external documents introduces new\nvulnerabilities. This paper exposes a critical security gap at the data loading\nstage, where malicious actors can stealthily corrupt RAG pipelines by\nexploiting document ingestion.\n  We propose a taxonomy of 9 knowledge-based poisoning attacks and introduce\ntwo novel threat vectors -- Content Obfuscation and Content Injection --\ntargeting common formats (DOCX, HTML, PDF). Using an automated toolkit\nimplementing 19 stealthy injection techniques, we test five popular data\nloaders, finding a 74.4% attack success rate across 357 scenarios. We further\nvalidate these threats on six end-to-end RAG systems -- including white-box\npipelines and black-box services like NotebookLM and OpenAI Assistants --\ndemonstrating high success rates and critical vulnerabilities that bypass\nfilters and silently compromise output integrity. Our results emphasize the\nurgent need to secure the document ingestion process in RAG systems against\ncovert content manipulations."}
{"id": "2507.04376", "categories": ["cs.AI", "cs.DC", "cs.MA", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.04376", "abs": "https://arxiv.org/abs/2507.04376", "authors": ["Georgios Ioannides", "Christos Constantinou", "Vinija Jain", "Aman Chadha", "Aaron Elkins"], "title": "MOD-X: A Modular Open Decentralized eXchange Framework proposal for Heterogeneous Interoperable Artificial Agents", "comment": null, "summary": "As Artificial Intelligence systems evolve from monolithic models to\necosystems of specialized agents, the need for standardized communication\nprotocols becomes increasingly critical. This paper introduces MOD-X (Modular\nOpen Decentralized eXchange), a novel architectural framework proposal for\nagent interoperability that addresses key limitations of existing protocols.\nUnlike current approaches, MOD-X proposes a layered architecture with a\nUniversal Message Bus, thorough state management, translation capabilities, and\nblockchain-based security mechanisms. We present MOD-X's architecture, compare\nit with existing protocols, and demonstrate its application through a worked\nexample how it enables integration between heterogeneous specialist agents\n(agents with different architectures, vendors, capabilities, and knowledge\nrepresentations--including rule-based systems, neural networks, symbolic\nreasoning engines, and legacy software with agent wrappers). MOD-X's key\ninnovations include a publish-subscribe communication model, semantic\ncapability discovery, and dynamic workflow orchestration--providing a framework\nthat bridges theoretical formalism with practical implementation. This\narchitecture addresses the growing need for truly decentralized, interoperable\nagent ecosystems that can scale effectively without the need for central\ncoordination."}
{"id": "2507.05132", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05132", "abs": "https://arxiv.org/abs/2507.05132", "authors": ["Nelly Elsayed", "Lily Dzamesi", "Zag ElSayed", "Murat Ozer"], "title": "Extreme Learning Machine Based System for DDoS Attacks Detections on IoMT Devices", "comment": "8 pages, under review", "summary": "The Internet of Medical Things (IoMT) represents a paradigm shift in the\nhealthcare sector, enabling the interconnection of medical devices, sensors,\nand systems to enhance patient monitoring, diagnosis, and management. The rapid\nevolution of IoMT presents significant benefits to the healthcare domains.\nHowever, there is a rapid increase in distributed denial of service (DDoS)\nattacks on the IoMT networks due to several vulnerabilities in the\nIoMT-connected devices, which negatively impact patients' health and can even\nlead to deaths. Thus, in this paper, we aim to save lives via investigating an\nextreme learning machine for detecting DDoS attacks on IoMT devices. The\nproposed approach achieves a high accuracy at a low implementation budget.\nThus, it can reduce the implementation cost of the DDoS detection system,\nmaking the model capable of executing on the fog level."}
{"id": "2507.04381", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04381", "abs": "https://arxiv.org/abs/2507.04381", "authors": ["Bing Fan", "Shusen Ma", "Yun-Bo Zhao", "Yu Kang"], "title": "DC-Mamber: A Dual Channel Prediction Model based on Mamba and Linear Transformer for Multivariate Time Series Forecasting", "comment": null, "summary": "In multivariate time series forecasting (MTSF), existing strategies for\nprocessing sequences are typically categorized as channel-independent and\nchannel-mixing. The former treats all temporal information of each variable as\na token, focusing on capturing local temporal features of individual variables,\nwhile the latter constructs a token from the multivariate information at each\ntime step, emphasizing the modeling of global temporal dependencies. Current\nmainstream models are mostly based on Transformer and the emerging Mamba.\nTransformers excel at modeling global dependencies through self-attention\nmechanisms but exhibit limited sensitivity to local temporal patterns and\nsuffer from quadratic computational complexity, restricting their efficiency in\nlong-sequence processing. In contrast, Mamba, based on state space models\n(SSMs), achieves linear complexity and efficient long-range modeling but\nstruggles to aggregate global contextual information in parallel. To overcome\nthe limitations of both models, we propose DC-Mamber, a dual-channel\nforecasting model based on Mamba and linear Transformer for time series\nforecasting. Specifically, the Mamba-based channel employs a\nchannel-independent strategy to extract intra-variable features, while the\nTransformer-based channel adopts a channel-mixing strategy to model\ncross-timestep global dependencies. DC-Mamber first maps the raw input into two\ndistinct feature representations via separate embedding layers. These\nrepresentations are then processed by a variable encoder (built on Mamba) and a\ntemporal encoder (built on linear Transformer), respectively. Finally, a fusion\nlayer integrates the dual-channel features for prediction. Extensive\nexperiments on eight public datasets confirm DC-Mamber's superior accuracy over\nexisting models."}
{"id": "2507.05213", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05213", "abs": "https://arxiv.org/abs/2507.05213", "authors": ["Max Gao", "Michael Collins", "Ricky Mok", "kc Claffy"], "title": "Hunting in the Dark: Metrics for Early Stage Traffic Discovery", "comment": "12 pages, 8 figures", "summary": "Threat hunting is an operational security process where an expert analyzes\ntraffic, applying knowledge and lightweight tools on unlabeled data in order to\nidentify and classify previously unknown phenomena. In this paper, we examine\nthreat hunting metrics and practice by studying the detection of Crackonosh, a\ncryptojacking malware package, has on various metrics for identifying its\nbehavior. Using a metric for discoverability, we model the ability of defenders\nto measure Crackonosh traffic as the malware population decreases, evaluate the\nstrength of various detection methods, and demonstrate how different darkspace\nsizes affect both the ability to track the malware, but enable emergent\nbehaviors by exploiting attacker mistakes."}
{"id": "2507.04404", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04404", "abs": "https://arxiv.org/abs/2507.04404", "authors": ["Jingze Zhu", "Yongliang Wu", "Wenbo Zhu", "Jiawang Cao", "Yanqiang Zheng", "Jiawei Chen", "Xu Yang", "Bernt Schiele", "Jonas Fischer", "Xinting Hu"], "title": "LayerCake: Token-Aware Contrastive Decoding within Large Language Model Layers", "comment": null, "summary": "Large language models (LLMs) excel at natural language understanding and\ngeneration but remain vulnerable to factual errors, limiting their reliability\nin knowledge-intensive tasks. While decoding-time strategies provide a\npromising efficient solution without training, existing methods typically treat\ntoken-level and layer-level signals in isolation, overlooking the joint\ndynamics between them. In this work, we introduce a token-aware,\nlayer-localized contrastive decoding method that aligns specific token types\nwith their most influential transformer layers to improve factual generation.\nThrough empirical attention analysis, we identify two key patterns: punctuation\ntokens receive dominant attention in early layers, while conceptual tokens\ngovern semantic reasoning in intermediate layers. By selectively suppressing\nattention to these token types at their respective depths, we achieve the\ninduction of controlled factual degradation and derive contrastive signals to\nguide the final factual decoding. Our method requires no additional training or\nmodel modification, and experiments demonstrate that our method consistently\nimproves factuality across multiple LLMs and various benchmarks."}
{"id": "2507.04428", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.04428", "abs": "https://arxiv.org/abs/2507.04428", "authors": ["Feiyue Wu", "Tianxing Wu", "Shenqi Jing"], "title": "ARMR: Adaptively Responsive Network for Medication Recommendation", "comment": "9 pages, accepted by IJCAI 2025", "summary": "Medication recommendation is a crucial task in healthcare, especially for\npatients with complex medical conditions. However, existing methods often\nstruggle to effectively balance the reuse of historical medications with the\nintroduction of new drugs in response to the changing patient conditions. In\norder to address this challenge, we propose an Adaptively Responsive network\nfor Medication Recommendation (ARMR), a new method which incorporates 1) a\npiecewise temporal learning component that distinguishes between recent and\ndistant patient history, enabling more nuanced temporal understanding, and 2)\nan adaptively responsive mechanism that dynamically adjusts attention to new\nand existing drugs based on the patient's current health state and medication\nhistory. Experiments on the MIMIC-III and MIMIC-IV datasets indicate that ARMR\nhas better performance compared with the state-of-the-art baselines in\ndifferent evaluation metrics, which contributes to more personalized and\naccurate medication recommendations. The source code is publicly avaiable at:\nhttps://github.com/seucoin/armr2."}
{"id": "2507.04431", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.04431", "abs": "https://arxiv.org/abs/2507.04431", "authors": ["Debodeep Banerjee", "Burcu Sayin", "Stefano Teso", "Andrea Passerini"], "title": "MedGellan: LLM-Generated Medical Guidance to Support Physicians", "comment": null, "summary": "Medical decision-making is a critical task, where errors can result in\nserious, potentially life-threatening consequences. While full automation\nremains challenging, hybrid frameworks that combine machine intelligence with\nhuman oversight offer a practical alternative. In this paper, we present\nMedGellan, a lightweight, annotation-free framework that uses a Large Language\nModel (LLM) to generate clinical guidance from raw medical records, which is\nthen used by a physician to predict diagnoses. MedGellan uses a\nBayesian-inspired prompting strategy that respects the temporal order of\nclinical data. Preliminary experiments show that the guidance generated by the\nLLM with MedGellan improves diagnostic performance, particularly in recall and\n$F_1$ score."}
{"id": "2507.04439", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.04439", "abs": "https://arxiv.org/abs/2507.04439", "authors": ["Videep Venkatesha", "Mary Cati Poulos", "Christopher Steadman", "Caitlin Mills", "Anne M. Cleary", "Nathaniel Blanchard"], "title": "A Linguistic Analysis of Spontaneous Thoughts: Investigating Experiences of Déjà Vu, Unexpected Thoughts, and Involuntary Autobiographical Memories", "comment": "Accepted at CogSci 2025", "summary": "The onset of spontaneous thoughts are reflective of dynamic interactions\nbetween cognition, emotion, and attention. Typically, these experiences are\nstudied through subjective appraisals that focus on their triggers,\nphenomenology, and emotional salience. In this work, we use linguistic\nsignatures to investigate Deja Vu, Involuntary Autobiographical Memories and\nUnexpected Thoughts. Specifically, we analyze the inherent characteristics of\nthe linguistic patterns in participant generated descriptions of these thought\ntypes. We show how, by positioning language as a window into spontaneous\ncognition, existing theories on these attentional states can be updated and\nreaffirmed. Our findings align with prior research, reinforcing that Deja Vu is\na metacognitive experience characterized by abstract and spatial language,\nInvoluntary Autobiographical Memories are rich in personal and emotionally\nsignificant detail, and Unexpected Thoughts are marked by unpredictability and\ncognitive disruption. This work is demonstrative of languages potential to\nreveal deeper insights into how internal spontaneous cognitive states manifest\nthrough expression."}
{"id": "2507.04464", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04464", "abs": "https://arxiv.org/abs/2507.04464", "authors": ["Ashish Bastola", "Mert D. Pesé", "Long Cheng", "Jonathon Smereka", "Abolfazl Razi"], "title": "Anomalous Decision Discovery using Inverse Reinforcement Learning", "comment": null, "summary": "Anomaly detection plays a critical role in Autonomous Vehicles (AVs) by\nidentifying unusual behaviors through perception systems that could compromise\nsafety and lead to hazardous situations. Current approaches, which often rely\non predefined thresholds or supervised learning paradigms, exhibit reduced\nefficacy when confronted with unseen scenarios, sensor noise, and occlusions,\nleading to potential safety-critical failures. Moreover, supervised methods\nrequire large annotated datasets, limiting their real-world feasibility. To\naddress these gaps, we propose an anomaly detection framework based on Inverse\nReinforcement Learning (IRL) to infer latent driving intentions from sequential\nperception data, thus enabling robust identification. Specifically, we present\nTrajectory-Reward Guided Adaptive Pre-training (TRAP), a novel IRL framework\nfor anomaly detection, to address two critical limitations of existing methods:\nnoise robustness and generalization to unseen scenarios. Our core innovation is\nimplicitly learning temporal credit assignments via reward and worst-case\nsupervision. We leverage pre-training with variable-horizon sampling to\nmaximize time-to-consequence, resulting in early detection of behavior\ndeviation. Experiments on 14,000+ simulated trajectories demonstrate\nstate-of-the-art performance, achieving 0.90 AUC and 82.2\\% F1-score -\noutperforming similarly trained supervised and unsupervised baselines by 39\\%\non Recall and 12\\% on F1-score, respectively. Similar performance is achieved\nwhile exhibiting robustness to various noise types and generalization to unseen\nanomaly types. Our code will be available at:\nhttps://github.com/abastola0/TRAP.git"}
{"id": "2507.04494", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.04494", "abs": "https://arxiv.org/abs/2507.04494", "authors": ["Niels Leadholm", "Viviane Clay", "Scott Knudstrup", "Hojae Lee", "Jeff Hawkins"], "title": "Thousand-Brains Systems: Sensorimotor Intelligence for Rapid, Robust Learning and Inference", "comment": "32 pages, 8 figures", "summary": "Current AI systems achieve impressive performance on many tasks, yet they\nlack core attributes of biological intelligence, including rapid, continual\nlearning, representations grounded in sensorimotor interactions, and structured\nknowledge that enables efficient generalization. Neuroscience theory suggests\nthat mammals evolved flexible intelligence through the replication of a\nsemi-independent, sensorimotor module, a functional unit known as a cortical\ncolumn. To address the disparity between biological and artificial\nintelligence, thousand-brains systems were proposed as a means of mirroring the\narchitecture of cortical columns and their interactions.\n  In the current work, we evaluate the unique properties of Monty, the first\nimplementation of a thousand-brains system. We focus on 3D object perception,\nand in particular, the combined task of object recognition and pose estimation.\nUtilizing the YCB dataset of household objects, we first assess Monty's use of\nsensorimotor learning to build structured representations, finding that these\nenable robust generalization. These representations include an emphasis on\nclassifying objects by their global shape, as well as a natural ability to\ndetect object symmetries. We then explore Monty's use of model-free and\nmodel-based policies to enable rapid inference by supporting principled\nmovements. We find that such policies complement Monty's modular architecture,\na design that can accommodate communication between modules to further\naccelerate inference speed via a novel `voting' algorithm. Finally, we examine\nMonty's use of associative, Hebbian-like binding to enable rapid, continual,\nand computationally efficient learning, properties that compare favorably to\ncurrent deep learning architectures. While Monty is still in a nascent stage of\ndevelopment, these findings support thousand-brains systems as a powerful and\npromising new approach to AI."}
{"id": "2507.04513", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04513", "abs": "https://arxiv.org/abs/2507.04513", "authors": ["Gur Keinan", "Omer Ben-Porat"], "title": "Churn-Aware Recommendation Planning under Aggregated Preference Feedback", "comment": "arXiv admin note: substantial text overlap with arXiv:2502.18483", "summary": "We study a sequential decision-making problem motivated by recent regulatory\nand technological shifts that limit access to individual user data in\nrecommender systems (RSs), leaving only population-level preference\ninformation. This privacy-aware setting poses fundamental challenges in\nplanning under uncertainty: Effective personalization requires exploration to\ninfer user preferences, yet unsatisfactory recommendations risk immediate user\nchurn. To address this, we introduce the Rec-APC model, in which an anonymous\nuser is drawn from a known prior over latent user types (e.g., personas or\nclusters), and the decision-maker sequentially selects items to recommend.\nFeedback is binary -- positive responses refine the posterior via Bayesian\nupdates, while negative responses result in the termination of the session.\n  We prove that optimal policies converge to pure exploitation in finite time\nand propose a branch-and-bound algorithm to efficiently compute them.\nExperiments on synthetic and MovieLens data confirm rapid convergence and\ndemonstrate that our method outperforms the POMDP solver SARSOP, particularly\nwhen the number of user types is large or comparable to the number of content\ncategories. Our results highlight the applicability of this approach and\ninspire new ways to improve decision-making under the constraints imposed by\naggregated preference data."}
{"id": "2507.04528", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04528", "abs": "https://arxiv.org/abs/2507.04528", "authors": ["Sonal Allana", "Rozita Dara", "Xiaodong Lin", "Pulei Xiong"], "title": "Towards integration of Privacy Enhancing Technologies in Explainable Artificial Intelligence", "comment": "Under peer review", "summary": "Explainable Artificial Intelligence (XAI) is a crucial pathway in mitigating\nthe risk of non-transparency in the decision-making process of black-box\nArtificial Intelligence (AI) systems. However, despite the benefits, XAI\nmethods are found to leak the privacy of individuals whose data is used in\ntraining or querying the models. Researchers have demonstrated privacy attacks\nthat exploit explanations to infer sensitive personal information of\nindividuals. Currently there is a lack of defenses against known privacy\nattacks targeting explanations when vulnerable XAI are used in production and\nmachine learning as a service system. To address this gap, in this article, we\nexplore Privacy Enhancing Technologies (PETs) as a defense mechanism against\nattribute inference on explanations provided by feature-based XAI methods. We\nempirically evaluate 3 types of PETs, namely synthetic training data,\ndifferentially private training and noise addition, on two categories of\nfeature-based XAI. Our evaluation determines different responses from the\nmitigation methods and side-effects of PETs on other system properties such as\nutility and performance. In the best case, PETs integration in explanations\nreduced the risk of the attack by 49.47%, while maintaining model utility and\nexplanation quality. Through our evaluation, we identify strategies for using\nPETs in XAI for maximizing benefits and minimizing the success of this privacy\nattack on sensitive personal information."}
{"id": "2507.04594", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.04594", "abs": "https://arxiv.org/abs/2507.04594", "authors": ["Niloofar Shadab", "Tyler Cody", "Alejandro Salado", "Taylan G. Topcu", "Mohammad Shadab", "Peter Beling"], "title": "Exploring Core and Periphery Precepts in Biological and Artificial Intelligence: An Outcome-Based Perspective", "comment": null, "summary": "Engineering methodologies predominantly revolve around established principles\nof decomposition and recomposition. These principles involve partitioning\ninputs and outputs at the component level, ensuring that the properties of\nindividual components are preserved upon composition. However, this view does\nnot transfer well to intelligent systems, particularly when addressing the\nscaling of intelligence as a system property. Our prior research contends that\nthe engineering of general intelligence necessitates a fresh set of overarching\nsystems principles. As a result, we introduced the \"core and periphery\"\nprinciples, a novel conceptual framework rooted in abstract systems theory and\nthe Law of Requisite Variety. In this paper, we assert that these abstract\nconcepts hold practical significance. Through empirical evidence, we illustrate\ntheir applicability to both biological and artificial intelligence systems,\nbridging abstract theory with real-world implementations. Then, we expand on\nour previous theoretical framework by mathematically defining core-dominant vs\nperiphery-dominant systems."}
{"id": "2507.04600", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04600", "abs": "https://arxiv.org/abs/2507.04600", "authors": ["Zhipeng Liu", "Peibo Duan", "Binwu Wang", "Xuan Tang", "Qi Chu", "Changsheng Zhang", "Yongsheng Huang", "Bin Zhang"], "title": "DisMS-TS: Eliminating Redundant Multi-Scale Features for Time Series Classification", "comment": "This paper has been accepted for presentation at the ACM\n  International Conference on Multimedia (ACM MM 2025)", "summary": "Real-world time series typically exhibit complex temporal variations, making\nthe time series classification task notably challenging. Recent advancements\nhave demonstrated the potential of multi-scale analysis approaches, which\nprovide an effective solution for capturing these complex temporal patterns.\nHowever, existing multi-scale analysis-based time series prediction methods\nfail to eliminate redundant scale-shared features across multi-scale time\nseries, resulting in the model over- or under-focusing on scale-shared\nfeatures. To address this issue, we propose a novel end-to-end Disentangled\nMulti-Scale framework for Time Series classification (DisMS-TS). The core idea\nof DisMS-TS is to eliminate redundant shared features in multi-scale time\nseries, thereby improving prediction performance. Specifically, we propose a\ntemporal disentanglement module to capture scale-shared and scale-specific\ntemporal representations, respectively. Subsequently, to effectively learn both\nscale-shared and scale-specific temporal representations, we introduce two\nregularization terms that ensure the consistency of scale-shared\nrepresentations and the disparity of scale-specific representations across all\ntemporal scales. Extensive experiments conducted on multiple datasets validate\nthe superiority of DisMS-TS over its competitive baselines, with the accuracy\nimprovement up to 9.71%."}
{"id": "2507.04632", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.04632", "abs": "https://arxiv.org/abs/2507.04632", "authors": ["Yun Qu", "Qi Cheems Wang", "Yixiu Mao", "Vincent Tao Hu", "Xiangyang Ji"], "title": "Can Prompt Difficulty be Online Predicted for Accelerating RL Finetuning of Reasoning Models?", "comment": null, "summary": "Recent advances have witnessed the effectiveness of reinforcement learning\n(RL) finetuning in enhancing the reasoning capabilities of large language\nmodels (LLMs). The optimization process often requires numerous iterations to\nachieve satisfactory performance, resulting in high computational costs due to\nthe need for frequent prompt evaluations under intensive LLM interactions and\nrepeated policy updates. Appropriate online prompt selection methods reduce\niteration steps by prioritizing informative prompts during training, while the\npipeline's reliance on exhaustive prompt evaluation and subset selection for\noptimization still incurs substantial computational overhead due to frequent\nLLM inference calls. Distinguished from these direct evaluate-then-select\nschemes, this work investigates iterative approximate evaluation for arbitrary\nprompts and introduces Model Predictive Prompt Selection (MoPPS), a Bayesian\nrisk-predictive framework that online estimates prompt difficulty without\nrequiring costly LLM interactions. Technically, MoPPS models each prompt's\nsuccess rate as a latent variable, performs streaming Bayesian inference, and\nemploys posterior sampling in a constructed multi-armed bandit machine,\nenabling sample efficient and adaptive prompt selection. Extensive experiments\nacross mathematics, planning, and vision-based geometry tasks show that MoPPS\nreliably predicts prompt difficulty and accelerates training with significantly\nreduced LLM rollouts."}
{"id": "2507.04673", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04673", "abs": "https://arxiv.org/abs/2507.04673", "authors": ["Wei Duan", "Li Qian"], "title": "Trojan Horse Prompting: Jailbreaking Conversational Multimodal Models by Forging Assistant Message", "comment": null, "summary": "The rise of conversational interfaces has greatly enhanced LLM usability by\nleveraging dialogue history for sophisticated reasoning. However, this reliance\nintroduces an unexplored attack surface. This paper introduces Trojan Horse\nPrompting, a novel jailbreak technique. Adversaries bypass safety mechanisms by\nforging the model's own past utterances within the conversational history\nprovided to its API. A malicious payload is injected into a model-attributed\nmessage, followed by a benign user prompt to trigger harmful content\ngeneration. This vulnerability stems from Asymmetric Safety Alignment: models\nare extensively trained to refuse harmful user requests but lack comparable\nskepticism towards their own purported conversational history. This implicit\ntrust in its \"past\" creates a high-impact vulnerability. Experimental\nvalidation on Google's Gemini-2.0-flash-preview-image-generation shows Trojan\nHorse Prompting achieves a significantly higher Attack Success Rate (ASR) than\nestablished user-turn jailbreaking methods. These findings reveal a fundamental\nflaw in modern conversational AI security, necessitating a paradigm shift from\ninput-level filtering to robust, protocol-level validation of conversational\ncontext integrity."}
{"id": "2507.04719", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.04719", "abs": "https://arxiv.org/abs/2507.04719", "authors": ["Roozbeh Yousefzadeh", "Xuenan Cao"], "title": "Advocate for Complete Benchmarks for Formal Reasoning with Formal/Informal Statements and Formal/Informal Proofs", "comment": null, "summary": "This position paper provides a critical but constructive discussion of\ncurrent practices in benchmarking and evaluative practices in the field of\nformal reasoning and automated theorem proving. We take the position that open\ncode, open data, and benchmarks that are complete and error-free will\naccelerate progress in this field. We identify practices that create barriers\nto contributing to this field and suggest ways to remove them. We also discuss\nsome of the practices that might produce misleading evaluative information. We\naim to create discussions that bring together people from various groups\ncontributing to automated theorem proving, autoformalization, and informal\nreasoning."}
{"id": "2507.04722", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04722", "abs": "https://arxiv.org/abs/2507.04722", "authors": ["Jinzhi Wang", "Bin Li", "Qingke Peng", "Haozhou Li", "Zeyuan Zeng", "Ruimeng Li", "Biyi Zhou"], "title": "LumiCRS: Asymmetric Contrastive Prototype Learning for Long-Tail Conversational Movie Recommendation", "comment": null, "summary": "Conversational recommender systems (CRSs) often suffer from an extreme\nlong-tail distribution of dialogue data, causing a strong bias toward\nhead-frequency blockbusters that sacrifices diversity and exacerbates the\ncold-start problem. An empirical analysis of DCRS and statistics on the REDIAL\ncorpus show that only 10% of head movies account for nearly half of all\nmentions, whereas about 70% of tail movies receive merely 26% of the attention.\nThis imbalance gives rise to three critical challenges: head over-fitting, body\nrepresentation drift, and tail sparsity. To address these issues, we propose\nLumiCRS, an end-to-end framework that mitigates long-tail imbalance through\nthree mutually reinforcing layers: (i) an Adaptive Comprehensive Focal Loss\n(ACFL) that dynamically adjusts class weights and focusing factors to curb head\nover-fitting and reduce popularity bias; (ii) Prototype Learning for Long-Tail\nRecommendation, which selects semantic, affective, and contextual prototypes to\nguide clustering and stabilize body and tail representations; and (iii) a\nGPT-4o-driven prototype-guided dialogue augmentation module that automatically\ngenerates diverse long-tail conversational snippets to alleviate tail sparsity\nand distribution shift. Together, these strategies enable LumiCRS to markedly\nimprove recommendation accuracy, diversity, and fairness: on the REDIAL and\nINSPIRED benchmarks, LumiCRS boosts Recall@10 and Tail-Recall@10 by 7-15% over\nfifteen strong baselines, while human evaluations confirm superior fluency,\ninformativeness, and long-tail relevance. These results demonstrate the\neffectiveness of multi-layer collaboration in building an efficient and fair\nlong-tail conversational recommender."}
{"id": "2507.04736", "categories": ["cs.AI", "cs.AR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.04736", "abs": "https://arxiv.org/abs/2507.04736", "authors": ["Zhirong Chen", "Kaiyan Chang", "Zhuolin Li", "Xinyang He", "Chujie Chen", "Cangyuan Li", "Mengdi Wang", "Haobo Xu", "Yinhe Han", "Ying Wang"], "title": "ChipSeek-R1: Generating Human-Surpassing RTL with LLM via Hierarchical Reward-Driven Reinforcement Learning", "comment": null, "summary": "Large Language Models (LLMs) show significant potential for automating\nRegister-Transfer Level (RTL) code generation. However, current approaches face\na critical challenge: they can not simultaneously optimize for functional\ncorrectness and hardware quality (Power, Performance, Area - PPA). Methods\nbased on supervised fine-tuning often generate functionally correct but\nPPA-suboptimal code, lacking mechanisms to learn optimization principles. In\ncontrast, post-processing techniques that attempt to improve PPA metrics after\ngeneration are often inefficient because they operate externally without\nupdating the LLM's parameters, thus failing to enhance the model's intrinsic\ndesign capabilities.\n  To bridge this gap, we introduce ChipSeek-R1, a hierarchical reward-driven\nreinforcement learning framework to train LLMs to generate RTL code that\nachieves both functional correctness and optimized PPA metrics. ChipSeek-R1\nemploys a hierarchical reward system, which incorporates direct feedback on\nsyntax, functional correctness (from simulators) and PPA metrics (from\nsynthesis tools) during reinforcement learning. This enables the model to learn\ncomplex hardware design trade-offs via trial-and-error, generating RTL code\nthat is both functionally correct and PPA-optimized. Evaluating ChipSeek-R1 on\nstandard benchmarks (VerilogEval, RTLLM), we achieve state-of-the-art results\nin functional correctness. Notably, on the RTLLM benchmark, ChipSeek-R1\ngenerated 27 RTL designs surpassing the PPA metrics of the original\nhuman-written code. Our findings demonstrate the effectiveness of integrating\ntoolchain feedback into LLM training and highlight the potential for\nreinforcement learning to enable automated generation of human-surpassing RTL\ncode. We open-source our code in anonymous github."}
{"id": "2507.04742", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.04742", "abs": "https://arxiv.org/abs/2507.04742", "authors": ["Seyedarmin Azizi", "Erfan Baghaei Potraghloo", "Massoud Pedram"], "title": "Activation Steering for Chain-of-Thought Compression", "comment": null, "summary": "Large language models (LLMs) excel at complex reasoning when they include\nintermediate steps, known as \"chains of thought\" (CoTs). However, these\nrationales are often overly verbose, even for simple problems, leading to\nwasted context, increased latency, and higher energy consumption. We observe\nthat verbose, English-heavy CoTs and concise, math-centric CoTs occupy distinct\nregions in the model's residual-stream activation space. By extracting and\ninjecting a \"steering vector\" to transition between these modes, we can\nreliably shift generation toward more concise reasoning, effectively\ncompressing CoTs without retraining. We formalize this approach as\nActivation-Steered Compression (ASC), an inference-time technique that shortens\nreasoning traces by directly modifying hidden representations. In addition, we\nprovide a theoretical analysis of the impact of ASC on the output distribution,\nderived from a closed-form KL-divergence-bounded constraint to regulate\nsteering strength. Using only 100 paired verbose and concise examples, ASC\nachieves up to 67.43% reduction in CoT length on MATH500 and GSM8K datasets,\nwhile maintaining accuracy across 7B, 8B, and 32B parameter models. As a\ntraining-free method, ASC introduces negligible runtime overhead and, on\nMATH500, delivers an average 2.73x speedup in end-to-end reasoning wall-clock\ntime on an 8B model. This makes ASC a practical and efficient tool for\nstreamlining the deployment of reasoning-capable LLMs in latency- or\ncost-sensitive settings. The code is available at:\nhttps://github.com/ArminAzizi98/ASC"}
{"id": "2507.04748", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04748", "abs": "https://arxiv.org/abs/2507.04748", "authors": ["Sungmin Lee", "Minju Kang", "Joonhee Lee", "Seungyong Lee", "Dongju Kim", "Jingi Hong", "Jun Shin", "Pei Zhang", "JeongGil Ko"], "title": "LLM-based Question-Answer Framework for Sensor-driven HVAC System Interaction", "comment": null, "summary": "Question-answering (QA) interfaces powered by large language models (LLMs)\npresent a promising direction for improving interactivity with HVAC system\ninsights, particularly for non-expert users. However, enabling accurate,\nreal-time, and context-aware interactions with HVAC systems introduces unique\nchallenges, including the integration of frequently updated sensor data,\ndomain-specific knowledge grounding, and coherent multi-stage reasoning. In\nthis paper, we present JARVIS, a two-stage LLM-based QA framework tailored for\nsensor data-driven HVAC system interaction. JARVIS employs an Expert-LLM to\ntranslate high-level user queries into structured execution instructions, and\nan Agent that performs SQL-based data retrieval, statistical processing, and\nfinal response generation. To address HVAC-specific challenges, JARVIS\nintegrates (1) an adaptive context injection strategy for efficient HVAC and\ndeployment-specific information integration, (2) a parameterized SQL builder\nand executor to improve data access reliability, and (3) a bottom-up planning\nscheme to ensure consistency across multi-stage response generation. We\nevaluate JARVIS using real-world data collected from a commercial HVAC system\nand a ground truth QA dataset curated by HVAC experts to demonstrate its\neffectiveness in delivering accurate and interpretable responses across diverse\nqueries. Results show that JARVIS consistently outperforms baseline and\nablation variants in both automated and user-centered assessments, achieving\nhigh response quality and accuracy."}
{"id": "2507.04770", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.04770", "abs": "https://arxiv.org/abs/2507.04770", "authors": ["Toan Nguyen", "Tri Le", "Quang Nguyen", "Anh Nguyen"], "title": "FurniMAS: Language-Guided Furniture Decoration using Multi-Agent System", "comment": null, "summary": "Furniture decoration is an important task in various industrial applications.\nHowever, achieving a high-quality decorative result is often time-consuming and\nrequires specialized artistic expertise. To tackle these challenges, we explore\nhow multi-agent systems can assist in automating the decoration process. We\npropose FurniMAS, a multi-agent system for automatic furniture decoration.\nSpecifically, given a human prompt and a household furniture item such as a\nworking desk or a TV stand, our system suggests relevant assets with\nappropriate styles and materials, and arranges them on the item, ensuring the\ndecorative result meets functionality, aesthetic, and ambiance preferences.\nFurniMAS assembles a hybrid team of LLM-based and non-LLM agents, each\nfulfilling distinct roles in a typical decoration project. These agents\ncollaborate through communication, logical reasoning, and validation to\ntransform the requirements into the final outcome. Extensive experiments\ndemonstrate that our FurniMAS significantly outperforms other baselines in\ngenerating high-quality 3D decor."}
{"id": "2507.04803", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04803", "abs": "https://arxiv.org/abs/2507.04803", "authors": ["George Jagadeesh", "Srikrishna Iyer", "Michal Polanowski", "Kai Xin Thia"], "title": "Application and Evaluation of Large Language Models for Forecasting the Impact of Traffic Incidents", "comment": "This paper has been accepted for publication at the 2025 IEEE 28th\n  International Conference on Intelligent Transportation Systems (ITSC), Gold\n  Coast, Australia, 2025. Copyright IEEE", "summary": "This study examines the feasibility of applying large language models (LLMs)\nfor forecasting the impact of traffic incidents on the traffic flow. The use of\nLLMs for this task has several advantages over existing machine learning-based\nsolutions such as not requiring a large training dataset and the ability to\nutilize free-text incident logs. We propose a fully LLM-based solution that\npredicts the incident impact using a combination of traffic features and\nLLM-extracted incident features. A key ingredient of this solution is an\neffective method of selecting examples for the LLM's in-context learning. We\nevaluate the performance of three advanced LLMs and two state-of-the-art\nmachine learning models on a real traffic incident dataset. The results show\nthat the best-performing LLM matches the accuracy of the most accurate machine\nlearning model, despite the former not having been trained on this prediction\ntask. The findings indicate that LLMs are a practically viable option for\ntraffic incident impact prediction."}
{"id": "2507.04877", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04877", "abs": "https://arxiv.org/abs/2507.04877", "authors": ["Zewen Sun", "Ruoxiang Huang", "Jiahe Feng", "Rundong Kong", "Yuqian Wang", "Hengyu Liu", "Ziqi Gong", "Yuyuan Qin", "Yingxue Wang", "Yu Wang"], "title": "DoPI: Doctor-like Proactive Interrogation LLM for Traditional Chinese Medicine", "comment": null, "summary": "Enhancing interrogation capabilities in Traditional Chinese Medicine (TCM)\ndiagnosis through multi-turn dialogues and knowledge graphs presents a\nsignificant challenge for modern AI systems. Current large language models\n(LLMs), despite their advancements, exhibit notable limitations in medical\napplications, particularly in conducting effective multi-turn dialogues and\nproactive questioning. These shortcomings hinder their practical application\nand effectiveness in simulating real-world diagnostic scenarios. To address\nthese limitations, we propose DoPI, a novel LLM system specifically designed\nfor the TCM domain. The DoPI system introduces a collaborative architecture\ncomprising a guidance model and an expert model. The guidance model conducts\nmulti-turn dialogues with patients and dynamically generates questions based on\na knowledge graph to efficiently extract critical symptom information.\nSimultaneously, the expert model leverages deep TCM expertise to provide final\ndiagnoses and treatment plans. Furthermore, this study constructs a multi-turn\ndoctor-patient dialogue dataset to simulate realistic consultation scenarios\nand proposes a novel evaluation methodology that does not rely on manually\ncollected real-world consultation data. Experimental results show that the DoPI\nsystem achieves an accuracy rate of 84.68 percent in interrogation outcomes,\nsignificantly enhancing the model's communication ability during diagnosis\nwhile maintaining professional expertise."}
{"id": "2507.04893", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.04893", "abs": "https://arxiv.org/abs/2507.04893", "authors": ["Kaleem Ullah Qasim", "Jiashu Zhang"], "title": "MARBLE: A Multi-Agent Rule-Based LLM Reasoning Engine for Accident Severity Prediction", "comment": "13 pages, 5 figures", "summary": "Accident severity prediction plays a critical role in transportation safety\nsystems but is a persistently difficult task due to incomplete data, strong\nfeature dependencies, and severe class imbalance in which rare but\nhigh-severity cases are underrepresented and hard to detect. Existing methods\noften rely on monolithic models or black box prompting, which struggle to scale\nin noisy, real-world settings and offer limited interpretability. To address\nthese challenges, we propose MARBLE a multiagent rule based LLM engine that\ndecomposes the severity prediction task across a team of specialized reasoning\nagents, including an interchangeable ML-backed agent. Each agent focuses on a\nsemantic subset of features (e.g., spatial, environmental, temporal), enabling\nscoped reasoning and modular prompting without the risk of prompt saturation.\nPredictions are coordinated through either rule-based or LLM-guided consensus\nmechanisms that account for class rarity and confidence dynamics. The system\nretains structured traces of agent-level reasoning and coordination outcomes,\nsupporting in-depth interpretability and post-hoc performance diagnostics.\nAcross both UK and US datasets, MARBLE consistently outperforms traditional\nmachine learning classifiers and state-of-the-art (SOTA) prompt-based reasoning\nmethods including Chain-of-Thought (CoT), Least-to-Most (L2M), and\nTree-of-Thought (ToT) achieving nearly 90% accuracy where others plateau below\n48%. This performance redefines the practical ceiling for accident severity\nclassification under real world noise and extreme class imbalance. Our results\nposition MARBLE as a generalizable and interpretable framework for reasoning\nunder uncertainty in safety-critical applications."}
{"id": "2507.04994", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04994", "abs": "https://arxiv.org/abs/2507.04994", "authors": ["Adam Gould", "Gabriel de Olim Gaul", "Francesca Toni"], "title": "Supported Abstract Argumentation for Case-Based Reasoning", "comment": "Accepted to IARML@ICJAI2025: Workshop on the Interactions between\n  Analogical Reasoning and Machine Learning", "summary": "We introduce Supported Abstract Argumentation for Case-Based Reasoning\n(sAA-CBR), a binary classification model in which past cases engage in debates\nby arguing in favour of their labelling and attacking or supporting those with\nopposing or agreeing labels. With supports, sAA-CBR overcomes the limitation of\nits precursor AA-CBR, which can contain extraneous cases (or spikes) that are\nnot included in the debates. We prove that sAA-CBR contains no spikes, without\ntrading off key model properties"}
{"id": "2507.05011", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.05011", "abs": "https://arxiv.org/abs/2507.05011", "authors": ["Maxence Boels", "Harry Robertshaw", "Alejandro Granados", "Prokar Dasgupta", "Sebastien Ourselin"], "title": "When Imitation Learning Outperforms Reinforcement Learning in Surgical Action Planning", "comment": "This manuscript has been submitted to a conference and is being peer\n  reviewed", "summary": "Surgical action planning requires predicting future instrument-verb-target\ntriplets for real-time assistance. While teleoperated robotic surgery provides\nnatural expert demonstrations for imitation learning (IL), reinforcement\nlearning (RL) could potentially discover superior strategies through\nexploration. We present the first comprehensive comparison of IL versus RL for\nsurgical action planning on CholecT50. Our Dual-task Autoregressive Imitation\nLearning (DARIL) baseline achieves 34.6% action triplet recognition mAP and\n33.6% next frame prediction mAP with smooth planning degradation to 29.2% at\n10-second horizons. We evaluated three RL variants: world model-based RL,\ndirect video RL, and inverse RL enhancement. Surprisingly, all RL approaches\nunderperformed DARIL i.e. world model RL dropped to 3.1% mAP at 10s while\ndirect video RL achieved only 15.9%. Our analysis reveals that distribution\nmatching on expert-annotated test sets systematically favors IL over\npotentially valid RL policies that differ from training demonstrations. This\nchallenges assumptions about RL superiority in sequential decision making and\nprovides crucial insights for surgical AI development."}
{"id": "2507.05088", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05088", "abs": "https://arxiv.org/abs/2507.05088", "authors": ["Kilian Rückschloß", "Felix Weitkämper"], "title": "How Rules Represent Causal Knowledge: Causal Modeling with Abductive Logic Programs", "comment": null, "summary": "Pearl observes that causal knowledge enables predicting the effects of\ninterventions, such as actions, whereas descriptive knowledge only permits\ndrawing conclusions from observation. This paper extends Pearl's approach to\ncausality and interventions to the setting of stratified abductive logic\nprograms. It shows how stable models of such programs can be given a causal\ninterpretation by building on philosophical foundations and recent work by\nBochman and Eelink et al. In particular, it provides a translation of abductive\nlogic programs into causal systems, thereby clarifying the informal causal\nreading of logic program rules and supporting principled reasoning about\nexternal actions. The main result establishes that the stable model semantics\nfor stratified programs conforms to key philosophical principles of causation,\nsuch as causal sufficiency, natural necessity, and irrelevance of unobserved\neffects. This justifies the use of stratified abductive logic programs as a\nframework for causal modeling and for predicting the effects of interventions"}
{"id": "2507.05110", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05110", "abs": "https://arxiv.org/abs/2507.05110", "authors": ["Shixuan Liu", "Yue He", "Yunfei Wang", "Hao Zou", "Haoxiang Cheng", "Wenjing Yang", "Peng Cui", "Zhong Liu"], "title": "Rule Learning for Knowledge Graph Reasoning under Agnostic Distribution Shift", "comment": null, "summary": "Knowledge graph (KG) reasoning remains a critical research area focused on\ninferring missing knowledge by analyzing relationships among observed facts.\nDespite its success, a key limitation of existing KG reasoning methods is their\ndependence on the I.I.D assumption. This assumption can easily be violated due\nto unknown sample selection bias during training or agnostic distribution\nshifts during testing, significantly compromising model performance and\nreliability. To facilitate the deployment of KG reasoning in wild environments,\nthis study investigates learning logical rules from KGs affected by unknown\nselection bias. Additionally, we address test sets with agnostic distribution\nshifts, formally defining this challenge as out-of-distribution (OOD) KG\nreasoning-a previously underexplored problem. To solve the issue, we propose\nthe Stable Rule Learning (StableRule) framework, an end-to-end methodology that\nintegrates feature decorrelation with rule learning network, to enhance OOD\ngeneralization performance. By leveraging feature decorrelation, the StableRule\nframework mitigates the adverse effects of covariate shifts arising in OOD\nscenarios, thereby improving the robustness of the rule learning component in\neffectively deriving logical rules. Extensive experiments on seven benchmark\nKGs demonstrate the framework's superior effectiveness and stability across\ndiverse heterogeneous environments, underscoring its practical significance for\nreal-world applications."}
{"id": "2507.05142", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05142", "abs": "https://arxiv.org/abs/2507.05142", "authors": ["Wei Xu", "Haoran Li", "Baoyuan Ou", "Lai Xu", "Yingjie Qin", "Ruilong Su", "Ruiwen Xu"], "title": "GIST: Cross-Domain Click-Through Rate Prediction via Guided Content-Behavior Distillation", "comment": null, "summary": "Cross-domain Click-Through Rate prediction aims to tackle the data sparsity\nand the cold start problems in online advertising systems by transferring\nknowledge from source domains to a target domain. Most existing methods rely on\noverlapping users to facilitate this transfer, often focusing on joint training\nor pre-training with fine-tuning approach to connect the source and target\ndomains. However, in real-world industrial settings, joint training struggles\nto learn optimal representations with different distributions, and pre-training\nwith fine-tuning is not well-suited for continuously integrating new data. To\naddress these issues, we propose GIST, a cross-domain lifelong sequence model\nthat decouples the training processes of the source and target domains. Unlike\nprevious methods that search lifelong sequences in the source domains using\nonly content or behavior signals or their simple combinations, we innovatively\nintroduce a Content-Behavior Joint Training Module (CBJT), which aligns\ncontent-behavior distributions and combines them with guided information to\nfacilitate a more stable representation. Furthermore, we develop an Asymmetric\nSimilarity Integration strategy (ASI) to augment knowledge transfer through\nsimilarity computation. Extensive experiments demonstrate the effectiveness of\nGIST, surpassing SOTA methods on offline evaluations and an online A/B test.\nDeployed on the Xiaohongshu (RedNote) platform, GIST effectively enhances\nonline ads system performance at scale, serving hundreds of millions of daily\nactive users."}
{"id": "2507.05201", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.05201", "abs": "https://arxiv.org/abs/2507.05201", "authors": ["Andrew Sellergren", "Sahar Kazemzadeh", "Tiam Jaroensri", "Atilla Kiraly", "Madeleine Traverse", "Timo Kohlberger", "Shawn Xu", "Fayaz Jamil", "Cían Hughes", "Charles Lau", "Justin Chen", "Fereshteh Mahvar", "Liron Yatziv", "Tiffany Chen", "Bram Sterling", "Stefanie Anna Baby", "Susanna Maria Baby", "Jeremy Lai", "Samuel Schmidgall", "Lu Yang", "Kejia Chen", "Per Bjornsson", "Shashir Reddy", "Ryan Brush", "Kenneth Philbrick", "Howard Hu", "Howard Yang", "Richa Tiwari", "Sunny Jansen", "Preeti Singh", "Yun Liu", "Shekoofeh Azizi", "Aishwarya Kamath", "Johan Ferret", "Shreya Pathak", "Nino Vieillard", "Ramona Merhej", "Sarah Perrin", "Tatiana Matejovicova", "Alexandre Ramé", "Morgane Riviere", "Louis Rouillard", "Thomas Mesnard", "Geoffrey Cideron", "Jean-bastien Grill", "Sabela Ramos", "Edouard Yvinec", "Michelle Casbon", "Elena Buchatskaya", "Jean-Baptiste Alayrac", "Dmitry", "Lepikhin", "Vlad Feinberg", "Sebastian Borgeaud", "Alek Andreev", "Cassidy Hardin", "Robert Dadashi", "Léonard Hussenot", "Armand Joulin", "Olivier Bachem", "Yossi Matias", "Katherine Chou", "Avinatan Hassidim", "Kavi Goel", "Clement Farabet", "Joelle Barral", "Tris Warkentin", "Jonathon Shlens", "David Fleet", "Victor Cotruta", "Omar Sanseviero", "Gus Martins", "Phoebe Kirk", "Anand Rao", "Shravya Shetty", "David F. Steiner", "Can Kirmizibayrak", "Rory Pilgrim", "Daniel Golden", "Lin Yang"], "title": "MedGemma Technical Report", "comment": null, "summary": "Artificial intelligence (AI) has significant potential in healthcare\napplications, but its training and deployment faces challenges due to\nhealthcare's diverse data, complex tasks, and the need to preserve privacy.\nFoundation models that perform well on medical tasks and require less\ntask-specific tuning data are critical to accelerate the development of\nhealthcare AI applications. We introduce MedGemma, a collection of medical\nvision-language foundation models based on Gemma 3 4B and 27B. MedGemma\ndemonstrates advanced medical understanding and reasoning on images and text,\nsignificantly exceeding the performance of similar-sized generative models and\napproaching the performance of task-specific models, while maintaining the\ngeneral capabilities of the Gemma 3 base models. For out-of-distribution tasks,\nMedGemma achieves 2.6-10% improvement on medical multimodal question answering,\n15.5-18.1% improvement on chest X-ray finding classification, and 10.8%\nimprovement on agentic evaluations compared to the base models. Fine-tuning\nMedGemma further improves performance in subdomains, reducing errors in\nelectronic health record information retrieval by 50% and reaching comparable\nperformance to existing specialized state-of-the-art methods for pneumothorax\nclassification and histopathology patch classification. We additionally\nintroduce MedSigLIP, a medically-tuned vision encoder derived from SigLIP.\nMedSigLIP powers the visual understanding capabilities of MedGemma and as an\nencoder achieves comparable or better performance than specialized medical\nimage encoders. Taken together, the MedGemma collection provides a strong\nfoundation of medical image and text capabilities, with potential to\nsignificantly accelerate medical research and development of downstream\napplications. The MedGemma collection, including tutorials and model weights,\ncan be found at https://goo.gle/medgemma."}
{"id": "2507.05241", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05241", "abs": "https://arxiv.org/abs/2507.05241", "authors": ["Jingyi Chai", "Shuo Tang", "Rui Ye", "Yuwen Du", "Xinyu Zhu", "Mengcheng Zhou", "Yanfeng Wang", "Weinan E", "Siheng Chen"], "title": "SciMaster: Towards General-Purpose Scientific AI Agents, Part I. X-Master as Foundation: Can We Lead on Humanity's Last Exam?", "comment": "12 pages, 7 figures", "summary": "The rapid advancements of AI agents have ignited the long-held ambition of\nleveraging them to accelerate scientific discovery. Achieving this goal\nrequires a deep understanding of the frontiers of human knowledge. As such,\nHumanity's Last Exam (HLE) provides an exceptionally challenging touchstone for\nevaluating scientific AI agents. In this work, we aim to construct the\nfoundational architecture for general-purpose agents and validate the\ncapabilities through leading performance on HLE. To achieve this, we introduce\nX-Master, a tool-augmented reasoning agent designed to emulate human\nresearchers by interacting flexibly with external tools during its reasoning\nprocess. This agent, guided by the conceptualization of code as an interaction\nlanguage, can flexibly leverage built-in Python libraries and our customized\ntools to augment the reasoning. We further scale its capabilities through\nX-Masters, a scattered-and-stacked agentic workflow that systematically\nenhances breadth and depth of reasoning. Our open-source solution, X-Masters,\nsets a new state-of-the-art record on HLE with a score of 32.1%, surpassing\nOpenAI's and Google's Deep Research (26.6% and 26.9%) and becoming the first to\nexceed the 30% threshold. This work allows us to gain a deeper understanding of\ncomplex task-solving and accumulates valuable experience that can inform future\nadvancements, guiding subsequent model training."}
{"id": "2507.05244", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.05244", "abs": "https://arxiv.org/abs/2507.05244", "authors": ["Benjamin Li", "Shuyang Shi", "Lucia Romero", "Huao Li", "Yaqi Xie", "Woojun Kim", "Stefanos Nikolaidis", "Michael Lewis", "Katia Sycara", "Simon Stepputtis"], "title": "Modeling Latent Partner Strategies for Adaptive Zero-Shot Human-Agent Collaboration", "comment": "Best Paper Award at the RSS 2025 Generative Models x HRI (GenAI-HRI)\n  Workshop", "summary": "In collaborative tasks, being able to adapt to your teammates is a necessary\nrequirement for success. When teammates are heterogeneous, such as in\nhuman-agent teams, agents need to be able to observe, recognize, and adapt to\ntheir human partners in real time. This becomes particularly challenging in\ntasks with time pressure and complex strategic spaces where the dynamics can\nchange rapidly. In this work, we introduce TALENTS, a strategy-conditioned\ncooperator framework that learns to represent, categorize, and adapt to a range\nof partner strategies, enabling ad-hoc teamwork. Our approach utilizes a\nvariational autoencoder to learn a latent strategy space from trajectory data.\nThis latent space represents the underlying strategies that agents employ.\nSubsequently, the system identifies different types of strategy by clustering\nthe data. Finally, a cooperator agent is trained to generate partners for each\ntype of strategy, conditioned on these clusters. In order to adapt to\npreviously unseen partners, we leverage a fixed-share regret minimization\nalgorithm that infers and adjusts the estimated partner strategy dynamically.\nWe assess our approach in a customized version of the Overcooked environment,\nposing a challenging cooperative cooking task that demands strong coordination\nacross a wide range of possible strategies. Using an online user study, we show\nthat our agent outperforms current baselines when working with unfamiliar human\npartners."}
{"id": "2507.05246", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05246", "abs": "https://arxiv.org/abs/2507.05246", "authors": ["Scott Emmons", "Erik Jenner", "David K. Elson", "Rif A. Saurous", "Senthooran Rajamanoharan", "Heng Chen", "Irhum Shafkat", "Rohin Shah"], "title": "When Chain of Thought is Necessary, Language Models Struggle to Evade Monitors", "comment": null, "summary": "While chain-of-thought (CoT) monitoring is an appealing AI safety defense,\nrecent work on \"unfaithfulness\" has cast doubt on its reliability. These\nfindings highlight an important failure mode, particularly when CoT acts as a\npost-hoc rationalization in applications like auditing for bias. However, for\nthe distinct problem of runtime monitoring to prevent severe harm, we argue the\nkey property is not faithfulness but monitorability. To this end, we introduce\na conceptual framework distinguishing CoT-as-rationalization from\nCoT-as-computation. We expect that certain classes of severe harm will require\ncomplex, multi-step reasoning that necessitates CoT-as-computation. Replicating\nthe experimental setups of prior work, we increase the difficulty of the bad\nbehavior to enforce this necessity condition; this forces the model to expose\nits reasoning, making it monitorable. We then present methodology guidelines to\nstress-test CoT monitoring against deliberate evasion. Applying these\nguidelines, we find that models can learn to obscure their intentions, but only\nwhen given significant help, such as detailed human-written strategies or\niterative optimization against the monitor. We conclude that, while not\ninfallible, CoT monitoring offers a substantial layer of defense that requires\nactive protection and continued stress-testing."}
{"id": "2507.02873", "categories": ["math.HO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02873", "abs": "https://arxiv.org/abs/2507.02873", "authors": ["William D'Alessandro"], "title": "Using Large Language Models to Study Mathematical Practice", "comment": null, "summary": "The philosophy of mathematical practice (PMP) looks to evidence from working\nmathematics to help settle philosophical questions. One prominent program under\nthe PMP banner is the study of explanation in mathematics, which aims to\nunderstand what sorts of proofs mathematicians consider explanatory and what\nrole the pursuit of explanation plays in mathematical practice. In an effort to\naddress worries about cherry-picked examples and file-drawer problems in PMP, a\nhandful of authors have recently turned to corpus analysis methods as a\npromising alternative to small-scale case studies. This paper reports the\nresults from such a corpus study facilitated by Google's Gemini 2.5 Pro, a\nmodel whose reasoning capabilities, advances in hallucination control and large\ncontext window allow for the accurate analysis of hundreds of pages of text per\nquery. Based on a sample of 5000 mathematics papers from arXiv.org, the\nexperiments yielded a dataset of hundreds of useful annotated examples. Its aim\nwas to gain insight on questions like the following: How often do\nmathematicians make claims about explanation in the relevant sense? Do\nmathematicians' explanatory practices vary in any noticeable way by subject\nmatter? Which philosophical theories of explanation are most consistent with a\nlarge body of non-cherry-picked examples? How might philosophers make further\nuse of AI tools to gain insights from large datasets of this kind? As the first\nPMP study making extensive use of LLM methods, it also seeks to begin a\nconversation about these methods as research tools in practice-oriented\nphilosophy and to evaluate the strengths and weaknesses of current models for\nsuch work."}
{"id": "2507.02951", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02951", "abs": "https://arxiv.org/abs/2507.02951", "authors": ["Elizabeth Lui", "Jiahao Sun"], "title": "Bittensor Protocol: The Bitcoin in Decentralized Artificial Intelligence? A Critical and Empirical Analysis", "comment": "MARBLE 2025", "summary": "This paper investigates whether Bittensor can be considered the Bitcoin of\ndecentralized Artificial Intelligence by directly comparing its tokenomics,\ndecentralization properties, consensus mechanism, and incentive structure\nagainst those of Bitcoin. Leveraging on-chain data from all 64 active Bittensor\nsubnets, we first document considerable concentration in both stake and\nrewards. We further show that rewards are overwhelmingly driven by stake,\nhighlighting a clear misalignment between quality and compensation. As a\nremedy, we put forward a series of two-pronged protocol-level interventions.\nFor incentive realignment, our proposed solutions include performance-weighted\nemission split, composite scoring, and a trust-bonus multiplier. As for\nmitigating security vulnerability due to stake concentration, we propose and\nempirically validate stake cap at the 88th percentile, which elevates the\nmedian coalition size required for a 51-percent attack and remains robust\nacross daily, weekly, and monthly snapshots."}
{"id": "2507.02956", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02956", "abs": "https://arxiv.org/abs/2507.02956", "authors": ["Blake Bullwinkel", "Mark Russinovich", "Ahmed Salem", "Santiago Zanella-Beguelin", "Daniel Jones", "Giorgio Severi", "Eugenia Kim", "Keegan Hines", "Amanda Minnich", "Yonatan Zunger", "Ram Shankar Siva Kumar"], "title": "A Representation Engineering Perspective on the Effectiveness of Multi-Turn Jailbreaks", "comment": null, "summary": "Recent research has demonstrated that state-of-the-art LLMs and defenses\nremain susceptible to multi-turn jailbreak attacks. These attacks require only\nclosed-box model access and are often easy to perform manually, posing a\nsignificant threat to the safe and secure deployment of LLM-based systems. We\nstudy the effectiveness of the Crescendo multi-turn jailbreak at the level of\nintermediate model representations and find that safety-aligned LMs often\nrepresent Crescendo responses as more benign than harmful, especially as the\nnumber of conversation turns increases. Our analysis indicates that at each\nturn, Crescendo prompts tend to keep model outputs in a \"benign\" region of\nrepresentation space, effectively tricking the model into fulfilling harmful\nrequests. Further, our results help explain why single-turn jailbreak defenses\nlike circuit breakers are generally ineffective against multi-turn attacks,\nmotivating the development of mitigations that address this generalization gap."}
{"id": "2507.02959", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.02959", "abs": "https://arxiv.org/abs/2507.02959", "authors": ["Ahmed Bensaoud", "Jugal Kalita"], "title": "A Novel Active Learning Approach to Label One Million Unknown Malware Variants", "comment": null, "summary": "Active learning for classification seeks to reduce the cost of labeling\nsamples by finding unlabeled examples about which the current model is least\ncertain and sending them to an annotator/expert to label. Bayesian theory can\nprovide a probabilistic view of deep neural network models by asserting a prior\ndistribution over model parameters and estimating the uncertainties by\nposterior distribution over these parameters. This paper proposes two novel\nactive learning approaches to label one million malware examples belonging to\ndifferent unknown modern malware families. The first model is Inception-V4+PCA\ncombined with several support vector machine (SVM) algorithms (UTSVM, PSVM,\nSVM-GSU, TBSVM). The second model is Vision Transformer based Bayesian Neural\nNetworks ViT-BNN. Our proposed ViT-BNN is a state-of-the-art active learning\napproach that differs from current methods and can apply to any particular\ntask. The experiments demonstrate that the ViT-BNN is more stable and robust in\nhandling uncertainty."}
{"id": "2507.02961", "categories": ["math.OC", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2507.02961", "abs": "https://arxiv.org/abs/2507.02961", "authors": ["Xuesong", "Zhou", "Taehooie Kim", "Mostafa Ameli", "Henan", "Zhu", "Yu- dai Honma", "Ram M. Pendyala"], "title": "Flow-Through Tensors: A Unified Computational Graph Architecture for Multi-Layer Transportation Network Optimization", "comment": null, "summary": "Modern transportation network modeling increasingly involves the integration\nof diverse methodologies including sensor-based forecasting, reinforcement\nlearning, classical flow optimization, and demand modeling that have\ntraditionally been developed in isolation. This paper introduces Flow Through\nTensors (FTT), a unified computational graph architecture that connects origin\ndestination flows, path probabilities, and link travel times as interconnected\ntensors. Our framework makes three key contributions: first, it establishes a\nconsistent mathematical structure that enables gradient-based optimization\nacross previously separate modeling elements; second, it supports\nmultidimensional analysis of traffic patterns over time, space, and user groups\nwith precise quantification of system efficiency; third, it implements tensor\ndecomposition techniques that maintain computational tractability for large\nscale applications. These innovations collectively enable real time control\nstrategies, efficient coordination between multiple transportation modes and\noperators, and rigorous enforcement of physical network constraints. The FTT\nframework bridges the gap between theoretical transportation models and\npractical deployment needs, providing a foundation for next generation\nintegrated mobility systems."}
{"id": "2507.02968", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02968", "abs": "https://arxiv.org/abs/2507.02968", "authors": ["Vijayalakshmi Ramasamy", "Seth Barrett", "Gokila Dorai", "Jessica Zumbach"], "title": "Unveiling Privacy Policy Complexity: An Exploratory Study Using Graph Mining, Machine Learning, and Natural Language Processing", "comment": "7 Pages; 1 Algorithm; 1 Table; 2 Figures; Accepted by AIRC 2025", "summary": "Privacy policy documents are often lengthy, complex, and difficult for\nnon-expert users to interpret, leading to a lack of transparency regarding the\ncollection, processing, and sharing of personal data. As concerns over online\nprivacy grow, it is essential to develop automated tools capable of analyzing\nprivacy policies and identifying potential risks. In this study, we explore the\npotential of interactive graph visualizations to enhance user understanding of\nprivacy policies by representing policy terms as structured graph models. This\napproach makes complex relationships more accessible and enables users to make\ninformed decisions about their personal data (RQ1). We also employ graph mining\nalgorithms to identify key themes, such as User Activity and Device\nInformation, using dimensionality reduction techniques like t-SNE and PCA to\nassess clustering effectiveness. Our findings reveal that graph-based\nclustering improves policy content interpretability. It highlights patterns in\nuser tracking and data sharing, which supports forensic investigations and\nidentifies regulatory non-compliance. This research advances AI-driven tools\nfor auditing privacy policies by integrating interactive visualizations with\ngraph mining. Enhanced transparency fosters accountability and trust."}
{"id": "2507.02969", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02969", "abs": "https://arxiv.org/abs/2507.02969", "authors": ["Daniel López-Montero", "José L. Álvarez-Aldana", "Alicia Morales-Martínez", "Marta Gil-López", "Juan M. Auñón García"], "title": "Reinforcement Learning for Automated Cybersecurity Penetration Testing", "comment": null, "summary": "This paper aims to provide an innovative machine learning-based solution to\nautomate security testing tasks for web applications, ensuring the correct\nfunctioning of all components while reducing project maintenance costs.\nReinforcement Learning is proposed to select and prioritize tools and optimize\nthe testing path. The presented approach utilizes a simulated webpage along\nwith its network topology to train the agent. Additionally, the model leverages\nGeometric Deep Learning to create priors that reduce the search space and\nimprove learning convergence. The validation and testing process was conducted\non real-world vulnerable web pages commonly used by human hackers for learning.\nAs a result of this study, a reinforcement learning algorithm was developed\nthat maximizes the number of vulnerabilities found while minimizing the number\nof steps required"}
{"id": "2507.03051", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.03051", "abs": "https://arxiv.org/abs/2507.03051", "authors": ["Marco Simoni", "Aleksandar Fontana", "Giulio Rossolini", "Andrea Saracino"], "title": "Improving LLM Reasoning for Vulnerability Detection via Group Relative Policy Optimization", "comment": "Under Review", "summary": "Improving and understanding the training dynamics and reasoning of Large\nLanguage Models (LLMs) has become essential for their deployment in AI-based\nsecurity tools, such as software vulnerability detection. In this work, we\npresent an extensive study aimed at advancing recent RL-based finetuning\ntechniques for LLMs in the context of vulnerability detection.\n  We start by highlighting key limitations of commonly adopted LLMs, such as\ntheir tendency to over-predict certain types of vulnerabilities while failing\nto detect others. To address this challenge, we explore the use of Group\nRelative Policy Optimization (GRPO), a recent policy-gradient method, for\nguiding LLM behavior through structured, rule-based rewards. We enable its\napplication to the vulnerability detection task by redefining its advantage\nfunctions and reward signals using annotations from widely used datasets in the\nfield, including BigVul, DiverseVul, and CleanVul.\n  The proposed methodology enables an extensive set of experiments, addressing\nmultiple research questions regarding the impact of GRPO on generalization,\nreasoning capabilities, and performance improvements over standard supervised\nfinetuning (SFT). Our findings offer valuable insights into the potential of\nRL-based training to enhance both the performance and reasoning abilities of\nLLMs in the context of software vulnerability detection."}
{"id": "2507.03064", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03064", "abs": "https://arxiv.org/abs/2507.03064", "authors": ["Hetvi Shastri", "Walid A. Hanafy", "Li Wu", "David Irwin", "Mani Srivastava", "Prashant Shenoy"], "title": "LLM-Driven Auto Configuration for Transient IoT Device Collaboration", "comment": null, "summary": "Today's Internet of Things (IoT) has evolved from simple sensing and\nactuation devices to those with embedded processing and intelligent services,\nenabling rich collaborations between users and their devices. However, enabling\nsuch collaboration becomes challenging when transient devices need to interact\nwith host devices in temporarily visited environments. In such cases,\nfine-grained access control policies are necessary to ensure secure\ninteractions; however, manually implementing them is often impractical for\nnon-expert users. Moreover, at run-time, the system must automatically\nconfigure the devices and enforce such fine-grained access control rules.\nAdditionally, the system must address the heterogeneity of devices.\n  In this paper, we present CollabIoT, a system that enables secure and\nseamless device collaboration in transient IoT environments. CollabIoT employs\na Large language Model (LLM)-driven approach to convert users' high-level\nintents to fine-grained access control policies. To support secure and seamless\ndevice collaboration, CollabIoT adopts capability-based access control for\nauthorization and uses lightweight proxies for policy enforcement, providing\nhardware-independent abstractions.\n  We implement a prototype of CollabIoT's policy generation and auto\nconfiguration pipelines and evaluate its efficacy on an IoT testbed and in\nlarge-scale emulated environments. We show that our LLM-based policy generation\npipeline is able to generate functional and correct policies with 100%\naccuracy. At runtime, our evaluation shows that our system configures new\ndevices in ~150 ms, and our proxy-based data plane incurs network overheads of\nup to 2 ms and access control overheads up to 0.3 ms."}
{"id": "2507.03236", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03236", "abs": "https://arxiv.org/abs/2507.03236", "authors": ["Noureldin Zahran", "Ahmad Tahmasivand", "Ihsen Alouani", "Khaled Khasawneh", "Mohammed E. Fouda"], "title": "On Jailbreaking Quantized Language Models Through Fault Injection Attacks", "comment": "This work has been published in GLSVLSI 2025", "summary": "The safety alignment of Language Models (LMs) is a critical concern, yet\ntheir integrity can be challenged by direct parameter manipulation attacks,\nsuch as those potentially induced by fault injection. As LMs are increasingly\ndeployed using low-precision quantization for efficiency, this paper\ninvestigates the efficacy of such attacks for jailbreaking aligned LMs across\ndifferent quantization schemes. We propose gradient-guided attacks, including a\ntailored progressive bit-level search algorithm introduced herein and a\ncomparative word-level (single weight update) attack. Our evaluation on\nLlama-3.2-3B, Phi-4-mini, and Llama-3-8B across FP16 (baseline), and\nweight-only quantization (FP8, INT8, INT4) reveals that quantization\nsignificantly influences attack success. While attacks readily achieve high\nsuccess (>80\\% Attack Success Rate, ASR) on FP16 models, within an attack\nbudget of 25 perturbations, FP8 and INT8 models exhibit ASRs below 20\\% and\n50\\%, respectively. Increasing the perturbation budget up to 150 bit-flips, FP8\nmodels maintained ASR below 65\\%, demonstrating some resilience compared to\nINT8 and INT4 models that have high ASR. In addition, analysis of perturbation\nlocations revealed differing architectural targets across quantization schemes,\nwith (FP16, INT4) and (INT8, FP8) showing similar characteristics. Besides,\njailbreaks induced in FP16 models were highly transferable to subsequent\nFP8/INT8 quantization (<5\\% ASR difference), though INT4 significantly reduced\ntransferred ASR (avg. 35\\% drop). These findings highlight that while common\nquantization schemes, particularly FP8, increase the difficulty of direct\nparameter manipulation jailbreaks, vulnerabilities can still persist,\nespecially through post-attack quantization."}
{"id": "2507.03450", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03450", "abs": "https://arxiv.org/abs/2507.03450", "authors": ["Antonio Emanuele Cinà", "Maura Pintor", "Luca Demetrio", "Ambra Demontis", "Battista Biggio", "Fabio Roli"], "title": "Evaluating the Evaluators: Trust in Adversarial Robustness Tests", "comment": null, "summary": "Despite significant progress in designing powerful adversarial evasion\nattacks for robustness verification, the evaluation of these methods often\nremains inconsistent and unreliable. Many assessments rely on mismatched\nmodels, unverified implementations, and uneven computational budgets, which can\nlead to biased results and a false sense of security. Consequently, robustness\nclaims built on such flawed testing protocols may be misleading and give a\nfalse sense of security. As a concrete step toward improving evaluation\nreliability, we present AttackBench, a benchmark framework developed to assess\nthe effectiveness of gradient-based attacks under standardized and reproducible\nconditions. AttackBench serves as an evaluation tool that ranks existing attack\nimplementations based on a novel optimality metric, which enables researchers\nand practitioners to identify the most reliable and effective attack for use in\nsubsequent robustness evaluations. The framework enforces consistent testing\nconditions and enables continuous updates, making it a reliable foundation for\nrobustness verification."}
{"id": "2507.04055", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.04055", "abs": "https://arxiv.org/abs/2507.04055", "authors": ["Yufan Chen", "Daoyuan Wu", "Juantao Zhong", "Zicheng Zhang", "Debin Gao", "Shuai Wang", "Yingjiu Li", "Ning Liu"], "title": "Rethinking and Exploring String-Based Malware Family Classification in the Era of LLMs and RAG", "comment": null, "summary": "Malware Family Classification (MFC) aims to identify the fine-grained family\n(e.g., GuLoader or BitRAT) to which a potential malware sample belongs, in\ncontrast to malware detection or sample classification that predicts only an\nYes/No. Accurate family identification can greatly facilitate automated sample\nlabeling and understanding on crowdsourced malware analysis platforms such as\nVirusTotal and MalwareBazaar, which generate vast amounts of data daily. In\nthis paper, we explore and assess the feasibility of using traditional binary\nstring features for MFC in the new era of large language models (LLMs) and\nRetrieval-Augmented Generation (RAG). Specifically, we investigate how\nFamily-Specific String (FSS) features could be utilized in a manner similar to\nRAG to facilitate MFC. To this end, we develop a curated evaluation framework\ncovering 4,347 samples from 67 malware families, extract and analyze over 25\nmillion strings, and conduct detailed ablation studies to assess the impact of\ndifferent design choices in four major modules."}
{"id": "2507.04106", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04106", "abs": "https://arxiv.org/abs/2507.04106", "authors": ["Stanisław Pawlak", "Bartłomiej Twardowski", "Tomasz Trzciński", "Joost van de Weijer"], "title": "Addressing The Devastating Effects Of Single-Task Data Poisoning In Exemplar-Free Continual Learning", "comment": "Accepted at CoLLAs 2025", "summary": "Our research addresses the overlooked security concerns related to data\npoisoning in continual learning (CL). Data poisoning - the intentional\nmanipulation of training data to affect the predictions of machine learning\nmodels - was recently shown to be a threat to CL training stability. While\nexisting literature predominantly addresses scenario-dependent attacks, we\npropose to focus on a more simple and realistic single-task poison (STP)\nthreats. In contrast to previously proposed poisoning settings, in STP\nadversaries lack knowledge and access to the model, as well as to both previous\nand future tasks. During an attack, they only have access to the current task\nwithin the data stream. Our study demonstrates that even within these stringent\nconditions, adversaries can compromise model performance using standard image\ncorruptions. We show that STP attacks are able to strongly disrupt the whole\ncontinual training process: decreasing both the stability (its performance on\npast tasks) and plasticity (capacity to adapt to new tasks) of the algorithm.\nFinally, we propose a high-level defense framework for CL along with a poison\ntask detection method based on task vectors. The code is available at\nhttps://github.com/stapaw/STP.git ."}
{"id": "2507.04227", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04227", "abs": "https://arxiv.org/abs/2507.04227", "authors": ["Guohong Liu", "Jialei Ye", "Jiacheng Liu", "Yuanchun Li", "Wei Liu", "Pengzhi Gao", "Jian Luan", "Yunxin Liu"], "title": "Hijacking JARVIS: Benchmarking Mobile GUI Agents against Unprivileged Third Parties", "comment": null, "summary": "Mobile GUI agents are designed to autonomously execute diverse device-control\ntasks by interpreting and interacting with mobile screens. Despite notable\nadvancements, their resilience in real-world scenarios where screen content may\nbe partially manipulated by untrustworthy third parties remains largely\nunexplored. Owing to their black-box and autonomous nature, these agents are\nvulnerable to manipulations that could compromise user devices. In this work,\nwe present the first systematic investigation into the vulnerabilities of\nmobile GUI agents. We introduce a scalable attack simulation framework\nAgentHazard, which enables flexible and targeted modifications of screen\ncontent within existing applications. Leveraging this framework, we develop a\ncomprehensive benchmark suite comprising both a dynamic task execution\nenvironment and a static dataset of vision-language-action tuples, totaling\nover 3,000 attack scenarios. The dynamic environment encompasses 58\nreproducible tasks in an emulator with various types of hazardous UI content,\nwhile the static dataset is constructed from 210 screenshots collected from 14\npopular commercial apps. Importantly, our content modifications are designed to\nbe feasible for unprivileged third parties. We evaluate 7 widely-used mobile\nGUI agents and 5 common backbone models using our benchmark. Our findings\nreveal that all examined agents are significantly influenced by misleading\nthird-party content (with an average misleading rate of 28.8% in human-crafted\nattack scenarios) and that their vulnerabilities are closely linked to the\nemployed perception modalities and backbone LLMs. Furthermore, we assess\ntraining-based mitigation strategies, highlighting both the challenges and\nopportunities for enhancing the robustness of mobile GUI agents. Our code and\ndata will be released at https://agenthazard.github.io."}
{"id": "2507.04275", "categories": ["cs.CR", "cs.AI", "cs.LG", "68T05, 68M25", "D.4.6; I.2.6; K.6.5"], "pdf": "https://arxiv.org/pdf/2507.04275", "abs": "https://arxiv.org/abs/2507.04275", "authors": ["M. Tahir Akdeniz", "Zeynep Yeşilkaya", "İ. Enes Köse", "İ. Ulaş Ünal", "Sevil Şen"], "title": "VOLTRON: Detecting Unknown Malware Using Graph-Based Zero-Shot Learning", "comment": "17 pages, 6 figures, Submitted as a preprint", "summary": "The persistent threat of Android malware presents a serious challenge to the\nsecurity of millions of users globally. While many machine learning-based\nmethods have been developed to detect these threats, their reliance on large\nlabeled datasets limits their effectiveness against emerging, previously unseen\nmalware families, for which labeled data is scarce or nonexistent.\n  To address this challenge, we introduce a novel zero-shot learning framework\nthat combines Variational Graph Auto-Encoders (VGAE) with Siamese Neural\nNetworks (SNN) to identify malware without needing prior examples of specific\nmalware families. Our approach leverages graph-based representations of Android\napplications, enabling the model to detect subtle structural differences\nbetween benign and malicious software, even in the absence of labeled data for\nnew threats.\n  Experimental results show that our method outperforms the state-of-the-art\nMaMaDroid, especially in zero-day malware detection. Our model achieves 96.24%\naccuracy and 95.20% recall for unknown malware families, highlighting its\nrobustness against evolving Android threats."}
{"id": "2507.04356", "categories": ["math.OC", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.04356", "abs": "https://arxiv.org/abs/2507.04356", "authors": ["Vyacheslav Kungurtsev", "Gustav Sir", "Akhil Anand", "Sebastien Gros", "Haozhe Tian", "Homayoun Hamedmoghadam"], "title": "Mission-Aligned Learning-Informed Control of Autonomous Systems: Formulation and Foundations", "comment": null, "summary": "Research, innovation and practical capital investment have been increasing\nrapidly toward the realization of autonomous physical agents. This includes\nindustrial and service robots, unmanned aerial vehicles, embedded control\ndevices, and a number of other realizations of cybernetic/mechatronic\nimplementations of intelligent autonomous devices. In this paper, we consider a\nstylized version of robotic care, which would normally involve a two-level\nReinforcement Learning procedure that trains a policy for both lower level\nphysical movement decisions as well as higher level conceptual tasks and their\nsub-components. In order to deliver greater safety and reliability in the\nsystem, we present the general formulation of this as a two-level optimization\nscheme which incorporates control at the lower level, and classical planning at\nthe higher level, integrated with a capacity for learning. This synergistic\nintegration of multiple methodologies -- control, classical planning, and RL --\npresents an opportunity for greater insight for algorithm development, leading\nto more efficient and reliable performance. Here, the notion of reliability\npertains to physical safety and interpretability into an otherwise black box\noperation of autonomous agents, concerning users and regulators. This work\npresents the necessary background and general formulation of the optimization\nframework, detailing each component and its integration with the others."}
{"id": "2507.04365", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.04365", "abs": "https://arxiv.org/abs/2507.04365", "authors": ["Xiaomeng Hu", "Pin-Yu Chen", "Tsung-Yi Ho"], "title": "Attention Slipping: A Mechanistic Understanding of Jailbreak Attacks and Defenses in LLMs", "comment": null, "summary": "As large language models (LLMs) become more integral to society and\ntechnology, ensuring their safety becomes essential. Jailbreak attacks exploit\nvulnerabilities to bypass safety guardrails, posing a significant threat.\nHowever, the mechanisms enabling these attacks are not well understood. In this\npaper, we reveal a universal phenomenon that occurs during jailbreak attacks:\nAttention Slipping. During this phenomenon, the model gradually reduces the\nattention it allocates to unsafe requests in a user query during the attack\nprocess, ultimately causing a jailbreak. We show Attention Slipping is\nconsistent across various jailbreak methods, including gradient-based token\nreplacement, prompt-level template refinement, and in-context learning.\nAdditionally, we evaluate two defenses based on query perturbation, Token\nHighlighter and SmoothLLM, and find they indirectly mitigate Attention\nSlipping, with their effectiveness positively correlated with the degree of\nmitigation achieved. Inspired by this finding, we propose Attention Sharpening,\na new defense that directly counters Attention Slipping by sharpening the\nattention score distribution using temperature scaling. Experiments on four\nleading LLMs (Gemma2-9B-It, Llama3.1-8B-It, Qwen2.5-7B-It, Mistral-7B-It v0.2)\nshow that our method effectively resists various jailbreak attacks while\nmaintaining performance on benign tasks on AlpacaEval. Importantly, Attention\nSharpening introduces no additional computational or memory overhead, making it\nan efficient and practical solution for real-world deployment."}
{"id": "2507.04752", "categories": ["cs.CR", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.04752", "abs": "https://arxiv.org/abs/2507.04752", "authors": ["Shuo Yang", "Xinran Zheng", "Xinchen Zhang", "Jinfeng Xu", "Jinze Li", "Donglin Xie", "Weicai Long", "Edith C. H. Ngai"], "title": "Large Language Models for Network Intrusion Detection Systems: Foundations, Implementations, and Future Directions", "comment": null, "summary": "Large Language Models (LLMs) have revolutionized various fields with their\nexceptional capabilities in understanding, processing, and generating\nhuman-like text. This paper investigates the potential of LLMs in advancing\nNetwork Intrusion Detection Systems (NIDS), analyzing current challenges,\nmethodologies, and future opportunities. It begins by establishing a\nfoundational understanding of NIDS and LLMs, exploring the enabling\ntechnologies that bridge the gap between intelligent and cognitive systems in\nAI-driven NIDS. While Intelligent NIDS leverage machine learning and deep\nlearning to detect threats based on learned patterns, they often lack\ncontextual awareness and explainability. In contrast, Cognitive NIDS integrate\nLLMs to process both structured and unstructured security data, enabling deeper\ncontextual reasoning, explainable decision-making, and automated response for\nintrusion behaviors. Practical implementations are then detailed, highlighting\nLLMs as processors, detectors, and explainers within a comprehensive AI-driven\nNIDS pipeline. Furthermore, the concept of an LLM-centered Controller is\nproposed, emphasizing its potential to coordinate intrusion detection\nworkflows, optimizing tool collaboration and system performance. Finally, this\npaper identifies critical challenges and opportunities, aiming to foster\ninnovation in developing reliable, adaptive, and explainable NIDS. By\npresenting the transformative potential of LLMs, this paper seeks to inspire\nadvancement in next-generation network security systems."}
{"id": "2507.04903", "categories": ["cs.CR", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.04903", "abs": "https://arxiv.org/abs/2507.04903", "authors": ["Thinh Dao", "Dung Thuy Nguyen", "Khoa D Doan", "Kok-Seng Wong"], "title": "BackFed: An Efficient & Standardized Benchmark Suite for Backdoor Attacks in Federated Learning", "comment": "Under review at NeurIPS'25", "summary": "Federated Learning (FL) systems are vulnerable to backdoor attacks, where\nadversaries train their local models on poisoned data and submit poisoned model\nupdates to compromise the global model. Despite numerous proposed attacks and\ndefenses, divergent experimental settings, implementation errors, and\nunrealistic assumptions hinder fair comparisons and valid conclusions about\ntheir effectiveness in real-world scenarios. To address this, we introduce\nBackFed - a comprehensive benchmark suite designed to standardize, streamline,\nand reliably evaluate backdoor attacks and defenses in FL, with a focus on\npractical constraints. Our benchmark offers key advantages through its\nmulti-processing implementation that significantly accelerates experimentation\nand the modular design that enables seamless integration of new methods via\nwell-defined APIs. With a standardized evaluation pipeline, we envision BackFed\nas a plug-and-play environment for researchers to comprehensively and reliably\nevaluate new attacks and defenses. Using BackFed, we conduct large-scale\nstudies of representative backdoor attacks and defenses across both Computer\nVision and Natural Language Processing tasks with diverse model architectures\nand experimental settings. Our experiments critically assess the performance of\nproposed attacks and defenses, revealing unknown limitations and modes of\nfailures under practical conditions. These empirical insights provide valuable\nguidance for the development of new methods and for enhancing the security of\nFL systems. Our framework is openly available at\nhttps://github.com/thinh-dao/BackFed."}
{"id": "2507.05093", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05093", "abs": "https://arxiv.org/abs/2507.05093", "authors": ["Alberto Castagnaro", "Umberto Salviati", "Mauro Conti", "Luca Pajola", "Simeone Pizzi"], "title": "The Hidden Threat in Plain Text: Attacking RAG Data Loaders", "comment": "currently under submission", "summary": "Large Language Models (LLMs) have transformed human-machine interaction since\nChatGPT's 2022 debut, with Retrieval-Augmented Generation (RAG) emerging as a\nkey framework that enhances LLM outputs by integrating external knowledge.\nHowever, RAG's reliance on ingesting external documents introduces new\nvulnerabilities. This paper exposes a critical security gap at the data loading\nstage, where malicious actors can stealthily corrupt RAG pipelines by\nexploiting document ingestion.\n  We propose a taxonomy of 9 knowledge-based poisoning attacks and introduce\ntwo novel threat vectors -- Content Obfuscation and Content Injection --\ntargeting common formats (DOCX, HTML, PDF). Using an automated toolkit\nimplementing 19 stealthy injection techniques, we test five popular data\nloaders, finding a 74.4% attack success rate across 357 scenarios. We further\nvalidate these threats on six end-to-end RAG systems -- including white-box\npipelines and black-box services like NotebookLM and OpenAI Assistants --\ndemonstrating high success rates and critical vulnerabilities that bypass\nfilters and silently compromise output integrity. Our results emphasize the\nurgent need to secure the document ingestion process in RAG systems against\ncovert content manipulations."}
