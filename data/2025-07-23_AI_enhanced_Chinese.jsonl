{"id": "2507.16055", "categories": ["math.OC", "cs.NA", "math.DG", "math.NA", "90C25, 49Q99, 49M30, 65K10"], "pdf": "https://arxiv.org/pdf/2507.16055", "abs": "https://arxiv.org/abs/2507.16055", "authors": ["Ronny Bergmann", "Hajg Jasa", "Paula John", "Max Pfeffer"], "title": "The Intrinsic Riemannian Proximal Gradient Method for Convex Optimization", "comment": null, "summary": "We consider a class of (possibly strongly) geodesically convex optimization\nproblems on Hadamard manifolds, where the objective function splits into the\nsum of a smooth and a possibly nonsmooth function. We introduce an intrinsic\nconvex Riemannian proximal gradient (CRPG) method that employs the manifold\nproximal map for the nonsmooth step, without operating in the embedding or\ntangent space. A sublinear convergence rate for convex problems and a linear\nconvergence rate for strongly convex problems is established, and we derive\nfundamental proximal gradient inequalities that generalize the Euclidean case.\nOur numerical experiments on hyperbolic spaces and manifolds of symmetric\npositive definite matrices demonstrate substantial computational advantages\nover existing methods.", "AI": {"tldr": "本文提出了一种在Hadamard流形上求解（可能强）测地凸优化问题的内蕴凸黎曼近端梯度法（CRPG），无需在嵌入或切空间中操作，并证明了其收敛速度。", "motivation": "针对Hadamard流形上目标函数可分解为光滑与非光滑部分之和的优化问题，现有方法常需在嵌入或切空间操作，效率受限。本文旨在开发一种内蕴的高效算法。", "method": "引入凸黎曼近端梯度法（CRPG），直接利用流形上的近端映射处理非光滑项，避免嵌入空间计算，并建立了相应的近端梯度不等式。", "result": "理论证明：凸问题具有次线性收敛率，强凸问题具有线性收敛率。数值实验表明，在双曲空间和对称正定矩阵流形上，CRPG显著优于现有方法。", "conclusion": "CRPG方法为流形优化提供了高效的内蕴求解框架，其收敛性理论和数值表现均验证了优越性，推广了欧氏空间中的近端梯度法。"}}
{"id": "2507.16340", "categories": ["math.ST", "stat.ME", "stat.TH", "62G32, 62H25"], "pdf": "https://arxiv.org/pdf/2507.16340", "abs": "https://arxiv.org/abs/2507.16340", "authors": ["Alexis Boulin", "Axel Bücher"], "title": "Structured linear factor models for tail dependence", "comment": "34 pages", "summary": "A common object to describe the extremal dependence of a $d$-variate random\nvector $X$ is the stable tail dependence function $L$. Various parametric\nmodels have emerged, with a popular subclass consisting of those stable tail\ndependence functions that arise for linear and max-linear factor models with\nheavy tailed factors. The stable tail dependence function is then parameterized\nby a $d \\times K$ matrix $A$, where $K$ is the number of factors and where $A$\ncan be interpreted as a factor loading matrix. We study estimation of $L$ under\nan additional assumption on $A$ called the `pure variable assumption'. Both $K\n\\in \\{1, \\dots, d\\}$ and $A \\in [0, \\infty)^{d \\times K}$ are treated as\nunknown, which constitutes an unconventional parameter space that does not fit\ninto common estimation frameworks. We suggest two algorithms that allow to\nestimate $K$ and $A$, and provide finite sample guarantees for both algorithms.\nRemarkably, the guarantees allow for the case where the dimension $d$ is larger\nthan the sample size $n$. The results are illustrated with numerical\nexperiments.", "AI": {"tldr": "该论文研究在‘纯变量假设’下，通过线性与最大线性因子模型估计稳定尾部依赖函数$L$的方法，提出了两种算法并提供了有限样本保证，支持维度$d$大于样本量$n$的情况。", "motivation": "稳定尾部依赖函数$L$是描述多元随机向量极值依赖的重要工具，现有参数模型（如线性/最大线性因子模型）需估计因子载荷矩阵$A$，但传统方法无法处理$K$与$A$均未知且$d>n$的非传统参数空间。", "method": "提出两种算法：1) 在‘纯变量假设’下联合估计因子数$K$和载荷矩阵$A$；2) 通过有限样本理论保证算法有效性，特别适用于高维（$d>n$）场景。", "result": "数值实验验证了算法的可行性，证明即使在$d>n$时，仍能准确估计$K$和$A$，且算法具有明确的统计收敛保证。", "conclusion": "该研究为高维极值依赖建模提供了新工具，突破了传统参数空间的限制，未来可拓展至更复杂的依赖结构分析。"}}
{"id": "2507.15859", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15859", "abs": "https://arxiv.org/abs/2507.15859", "authors": ["Harsha Sammangi", "Aditya Jagatha", "Giridhar Reddy Bojja", "Jun Liu"], "title": "Decentralized AI-driven IoT Architecture for Privacy-Preserving and Latency-Optimized Healthcare in Pandemic and Critical Care Scenarios", "comment": "10 Pages", "summary": "AI Innovations in the IoT for Real-Time Patient Monitoring On one hand, the\ncurrent traditional centralized healthcare architecture poses numerous issues,\nincluding data privacy, delay, and security. Here, we present an AI-enabled\ndecentralized IoT architecture that can address such challenges during a\npandemic and critical care settings. This work presents our architecture to\nenhance the effectiveness of the current available federated learning,\nblockchain, and edge computing approach, maximizing data privacy, minimizing\nlatency, and improving other general system metrics. Experimental results\ndemonstrate transaction latency, energy consumption, and data throughput orders\nof magnitude lower than competitive cloud solutions.", "AI": {"tldr": "本文提出了一种基于AI的去中心化物联网架构，用于实时患者监测，通过结合联邦学习、区块链和边缘计算技术，显著提升了数据隐私性并降低了延迟。", "motivation": "传统集中式医疗架构存在数据隐私、延迟和安全问题，尤其在疫情期间和重症监护场景下更为突出，亟需创新解决方案。", "method": "采用AI赋能的去中心化物联网架构，整合联邦学习、区块链和边缘计算技术，优化系统性能指标。", "result": "实验结果显示，该架构在交易延迟、能耗和数据吞吐量方面比云端解决方案有数量级的提升。", "conclusion": "该AI驱动的去中心化架构为实时患者监测提供了高效、安全的解决方案，具有显著的临床应用价值。"}}
{"id": "2507.16216", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.16216", "abs": "https://arxiv.org/abs/2507.16216", "authors": ["Jochen Trumpf", "Behzad Zamani", "Chris Manzie"], "title": "Conservative fusion of unbiased partial state estimates: CI is optimal", "comment": "Submitted to Automatica", "summary": "We show that Covariance Intersection (CI) is optimal amongst all conservative\nunbiased linear fusion rules also in the general case of information fusion of\ntwo unbiased partial state estimates, significantly generalizing the known\noptimality result for fusion of full state estimates. In fact, we prove the\nmuch stronger result that three different optimization problems are equivalent,\nnamely the abstract optimal conservative unbiased linear information fusion\nproblem with respect to a strictly isotone cost function, the scalar Covariance\nIntersection (CI) problem, and a simple semi-definite program (SDP). We provide\na general solvability condition for these problems as well as equations\ncharacterizing the optimal solutions for the matrix determinant and matrix\ntrace cost functions.", "AI": {"tldr": "本文证明了协方差交叉（CI）在一般无偏部分状态估计信息融合中是最优的保守无偏线性融合规则，并揭示了三种优化问题的等价性。", "motivation": "研究旨在扩展协方差交叉（CI）的最优性结果，从全状态估计融合推广到更一般的无偏部分状态估计融合场景。", "method": "通过证明三种优化问题的等价性（抽象最优保守无偏线性信息融合问题、标量协方差交叉问题、简单半定规划），并给出严格单调成本函数下的解。", "result": "提出了这些问题的通用可解性条件，并针对矩阵行列式和矩阵迹成本函数给出了最优解的方程。", "conclusion": "协方差交叉（CI）在无偏部分状态估计融合中具有广泛的最优性，且其优化问题可转化为等效的半定规划问题求解。"}}
{"id": "2507.16529", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.16529", "abs": "https://arxiv.org/abs/2507.16529", "authors": ["Valentinian Lungu", "Joni Shaska", "Ioannis Kontoyiannis", "Urbashi Mitra"], "title": "Bayesian causal discovery: Posterior concentration and optimal detection", "comment": null, "summary": "We consider the problem of Bayesian causal discovery for the standard model\nof linear structural equations with equivariant Gaussian noise. A uniform prior\nis placed on the space of directed acyclic graphs (DAGs) over a fixed set of\nvariables and, given the graph, independent Gaussian priors are placed on the\nassociated linear coefficients of pairwise interactions. We show that the rate\nat which the posterior on model space concentrates on the true underlying DAG\ndepends critically on its nature: If it is maximal, in the sense that adding\nany one new edge would violate acyclicity, then its posterior probability\nconverges to 1 exponentially fast (almost surely) in the sample size $n$.\nOtherwise, it converges at a rate no faster than $1/\\sqrt{n}$. This sharp\ndichotomy is an instance of the important general phenomenon that avoiding\noverfitting is significantly harder than identifying all of the structure that\nis present in the model. We also draw a new connection between the posterior\ndistribution on model space and recent results on optimal hypothesis testing in\nthe related problem of edge detection. Our theoretical findings are illustrated\nempirically through simulation experiments.", "AI": {"tldr": "本文研究了贝叶斯因果发现中线性结构方程模型的DAG后验集中速率问题，揭示了最大DAG与非最大DAG的指数级与多项式级收敛差异。", "motivation": "探讨线性结构方程模型下，DAG结构的后验概率如何随样本量收敛，揭示模型结构复杂度对收敛速度的影响机制。", "method": "在固定变量集上采用均匀DAG先验，给定图结构时对线性系数施加独立高斯先验，通过理论分析与模拟实验验证收敛行为。", "result": "最大DAG（无法增边保持无环性）的后验概率以指数速率$e^{-n}$收敛，非最大DAG至多以$1/\\sqrt{n}$多项式速率收敛。", "conclusion": "研究揭示了避免过拟合比识别现有结构更困难，并将模型后验分布与边检测的最优假设检验理论建立了新联系。"}}
{"id": "2507.15984", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.15984", "abs": "https://arxiv.org/abs/2507.15984", "authors": ["I Putu Arya Dharmaadi", "Mohannad Alhanahnah", "Van-Thuan Pham", "Fadi Mohsen", "Fatih Turkmen"], "title": "BACFuzz: Exposing the Silence on Broken Access Control Vulnerabilities in Web Applications", "comment": "Under peer-review", "summary": "Broken Access Control (BAC) remains one of the most critical and widespread\nvulnerabilities in web applications, allowing attackers to access unauthorized\nresources or perform privileged actions. Despite its severity, BAC is\nunderexplored in automated testing due to key challenges: the lack of reliable\noracles and the difficulty of generating semantically valid attack requests. We\nintroduce BACFuzz, the first gray-box fuzzing framework specifically designed\nto uncover BAC vulnerabilities, including Broken Object-Level Authorization\n(BOLA) and Broken Function-Level Authorization (BFLA) in PHP-based web\napplications. BACFuzz combines LLM-guided parameter selection with runtime\nfeedback and SQL-based oracle checking to detect silent authorization flaws. It\nemploys lightweight instrumentation to capture runtime information that guides\ntest generation, and analyzes backend SQL queries to verify whether\nunauthorized inputs flow into protected operations. Evaluated on 20 real-world\nweb applications, including 15 CVE cases and 2 known benchmarks, BACFuzz\ndetects 16 of 17 known issues and uncovers 26 previously unknown BAC\nvulnerabilities with low false positive rates. All identified issues have been\nresponsibly disclosed, and artifacts will be publicly released.", "AI": {"tldr": "BACFuzz是首个针对PHP网页应用中BAC漏洞（如BOLA和BFLA）的灰盒模糊测试框架，结合LLM引导的参数选择与运行时反馈，成功检测出大量已知和未知漏洞。", "motivation": "BAC漏洞虽严重但自动化测试不足，主要因缺乏可靠验证机制和有效攻击请求生成方法。", "method": "框架集成LLM引导参数选择、轻量级运行时插桩及SQL查询分析，通过语义化请求生成与静默授权缺陷检测提升准确性。", "result": "在20个真实应用（含15个CVE案例）中，BACFuzz检出16/17已知漏洞及26个未知漏洞，误报率低。", "conclusion": "BACFuzz显著提升BAC漏洞检测效率，所有发现已负责任披露，工具将开源推动研究。"}}
{"id": "2507.16259", "categories": ["math.OC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16259", "abs": "https://arxiv.org/abs/2507.16259", "authors": ["Yineng Sun", "Armin Fügenschuh", "Vikrant Vaze"], "title": "Physics-aware Truck and Drone Delivery Planning Using Optimization & Machine Learning", "comment": null, "summary": "Combining an energy-efficient drone with a high-capacity truck for last-mile\npackage delivery can benefit operators and customers by reducing delivery times\nand environmental impact. However, directly integrating drone flight dynamics\ninto the combinatorially hard truck route planning problem is challenging.\nSimplified models that ignore drone flight physics can lead to suboptimal\ndelivery plans. We propose an integrated formulation for the joint problem of\ntruck route and drone trajectory planning and a new end-to-end solution\napproach that combines optimization and machine learning to generate\nhigh-quality solutions in practical online runtimes. Our solution method trains\nneural network predictors based on offline solutions to the drone trajectory\noptimization problem instances to approximate drone flight times, and uses\nthese approximations to optimize the overall truck-and-drone delivery plan by\naugmenting an existing order-first-split-second heuristic. Our method\nexplicitly incorporates key kinematics and energy equations in drone trajectory\noptimization, and thereby outperforms state-of-the-art benchmarks that ignore\ndrone flight physics. Extensive experimentation using synthetic datasets and\nreal-world case studies shows that the integration of drone trajectories into\npackage delivery planning substantially improves system performance in terms of\ntour duration and drone energy consumption. Our modeling and computational\nframework can help delivery planners achieve annual savings worth millions of\ndollars while also benefiting the environment.", "AI": {"tldr": "该研究提出了一种结合卡车路线与无人机轨迹规划的联合优化方法，通过整合无人机飞行物理模型与机器学习预测，显著提升了最后一公里包裹配送的效率和能源利用率。", "motivation": "传统卡车与无人机协同配送方案常忽略无人机飞行动力学，导致配送计划次优。整合无人机物理模型可降低配送时间与环境影响，但直接引入组合优化问题具有挑战性。", "method": "提出端到端解决方案：基于离线优化的无人机轨迹训练神经网络预测飞行时间，结合改进的order-first-split-second启发式算法，在轨迹优化中显式嵌入运动学与能量方程。", "result": "在合成数据集和实际案例中，该方法在配送时长和无人机能耗方面优于现有基准模型，验证了物理模型整合对系统性能的提升价值。", "conclusion": "该框架可帮助物流企业实现数百万美元的年成本节约，同时减少环境足迹，为卡车-无人机协同配送提供了兼具计算效率与物理精确性的新范式。"}}
{"id": "2507.16734", "categories": ["math.ST", "cs.IT", "math.IT", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.16734", "abs": "https://arxiv.org/abs/2507.16734", "authors": ["Zeyu Jia", "Yury Polyanskiy"], "title": "Gaussian Sequence Model: Sample Complexities of Testing, Estimation and LFHT", "comment": null, "summary": "We study the Gaussian sequence model, i.e. $X \\sim N(\\mathbf{\\theta},\nI_\\infty)$, where $\\mathbf{\\theta} \\in \\Gamma \\subset \\ell_2$ is assumed to be\nconvex and compact. We show that goodness-of-fit testing sample complexity is\nlower bounded by the square-root of the estimation complexity, whenever\n$\\Gamma$ is orthosymmetric. We show that the lower bound is tight when $\\Gamma$\nis also quadratically convex, thus significantly extending validity of the\ntesting-estimation relationship from [GP24]. Using similar methods, we also\ncompletely characterize likelihood-free hypothesis testing (LFHT) complexity\nfor $\\ell_p$-bodies, discovering new types of tradeoff between the numbers of\nsimulation and observation samples.", "AI": {"tldr": "研究高斯序列模型中拟合优度检验的样本复杂度下限，证明在正交对称凸集下该下限与估计复杂度平方根相关，并在二次凸条件下验证其紧性；同时完全刻画了$\\ell_p$-球的免似然假设检验复杂度。", "motivation": "探讨高斯序列模型$X \\sim N(\\mathbf{\\theta}, I_\\infty)$中，当参数空间$\\Gamma$为凸紧集时，拟合优度检验样本复杂度与估计复杂度之间的关系，并扩展[GP24]的研究成果。", "method": "采用正交对称性和二次凸性分析技术，通过数学推导建立拟合优度检验复杂度下限，并利用类似方法系统研究$\\ell_p$-球的免似然假设检验复杂度。", "result": "证明正交对称凸集下拟合优度检验复杂度下限为估计复杂度平方根，且在二次凸条件下该下限紧；首次揭示$\\ell_p$-球免似然检验中仿真样本与观测样本数量的新型权衡关系。", "conclusion": "研究统一了高维统计中检验与估计复杂度的理论关联，为复杂参数空间的假设检验提供了普适性框架，同时开辟了免似然检验样本效率研究的新方向。"}}
{"id": "2507.15997", "categories": ["cs.CR", "cs.HC", "68-XX 68-XX 68-XX"], "pdf": "https://arxiv.org/pdf/2507.15997", "abs": "https://arxiv.org/abs/2507.15997", "authors": ["Onyinye Dibia", "Mengyi Lu", "Prianka Bhattacharjee", "Joseph P. Near", "Yuanyuan Feng"], "title": "\"We Need a Standard\": Toward an Expert-Informed Privacy Label for Differential Privacy", "comment": "13 pages, 5 figures", "summary": "The increasing adoption of differential privacy (DP) leads to public-facing\nDP deployments by both government agencies and companies. However, real-world\nDP deployments often do not fully disclose their privacy guarantees, which vary\ngreatly between deployments. Failure to disclose certain DP parameters can lead\nto misunderstandings about the strength of the privacy guarantee, undermining\nthe trust in DP. In this work, we seek to inform future standards for\ncommunicating the privacy guarantees of DP deployments. Based on\nsemi-structured interviews with 12 DP experts, we identify important DP\nparameters necessary to comprehensively communicate DP guarantees, and describe\nwhy and how they should be disclosed. Based on expert recommendations, we\ndesign an initial privacy label for DP to comprehensively communicate privacy\nguarantees in a standardized format.", "AI": {"tldr": "研究通过专家访谈提出差分隐私(DP)参数披露标准，并设计隐私标签以标准化传达隐私保障。", "motivation": "现实中的DP部署常未完全公开隐私保障参数，导致对隐私保护强度的误解，损害DP的公信力。", "method": "对12位DP专家进行半结构化访谈，识别关键DP参数及其披露方式。", "result": "确定了全面传达DP保障所需的重要参数，并基于专家建议设计了标准化隐私标签。", "conclusion": "提出的隐私标签框架可为未来DP部署的隐私保障沟通建立标准化规范。"}}
{"id": "2507.16264", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.16264", "abs": "https://arxiv.org/abs/2507.16264", "authors": ["Rajiv Sambharya", "Jinho Bok", "Nikolai Matni", "George Pappas"], "title": "Learning Acceleration Algorithms for Fast Parametric Convex Optimization with Certified Robustness", "comment": null, "summary": "We develop a machine-learning framework to learn hyperparameter sequences for\naccelerated first-order methods (e.g., the step size and momentum sequences in\naccelerated gradient descent) to quickly solve parametric convex optimization\nproblems with certified robustness. We obtain a strong form of robustness\nguarantee -- certification of worst-case performance over all parameters within\na set after a given number of iterations -- through regularization-based\ntraining. The regularization term is derived from the performance estimation\nproblem (PEP) framework based on semidefinite programming, in which the\nhyperparameters appear as problem data. We show how to use gradient-based\ntraining to learn the hyperparameters for several first-order methods:\naccelerated versions of gradient descent, proximal gradient descent, and\nalternating direction method of multipliers. Through various numerical examples\nfrom signal processing, control, and statistics, we demonstrate that the\nquality of the solution can be dramatically improved within a budget of\niterations, while also maintaining strong robustness guarantees. Notably, our\napproach is highly data-efficient in that we only use ten training instances in\nall of the numerical examples.", "AI": {"tldr": "提出一种机器学习框架，通过正则化训练学习一阶加速优化方法（如梯度下降的步长和动量序列）的超参数序列，以快速求解具有认证鲁棒性的参数化凸优化问题。", "motivation": "旨在开发一种能快速解决参数化凸优化问题并保证最坏情况下性能认证的鲁棒超参数学习方法。", "method": "基于半定规划的性能估计问题（PEP）框架，通过梯度训练学习加速梯度下降、近端梯度下降和交替方向乘子法等一阶方法的超参数序列。", "result": "数值实验表明，在有限迭代次数内显著提升解的质量，同时保持强鲁棒性保证，且仅需十个训练实例即实现高效数据利用。", "conclusion": "该框架在信号处理、控制和统计等领域验证了其高效性和鲁棒性，为参数化优化问题提供了数据高效的超参数学习方案。"}}
{"id": "2507.16776", "categories": ["math.ST", "econ.EM", "stat.TH", "62G15, 62J05"], "pdf": "https://arxiv.org/pdf/2507.16776", "abs": "https://arxiv.org/abs/2507.16776", "authors": ["Alexis Derumigny", "Lucas Girard", "Yannick Guyonvarch"], "title": "Can we have it all? Non-asymptotically valid and asymptotically exact confidence intervals for expectations and linear regressions", "comment": "69 pages", "summary": "We contribute to bridging the gap between large- and finite-sample inference\nby studying confidence sets (CSs) that are both non-asymptotically valid and\nasymptotically exact uniformly (NAVAE) over semi-parametric statistical models.\nNAVAE CSs are not easily obtained; for instance, we show they do not exist over\nthe set of Bernoulli distributions. We first derive a generic sufficient\ncondition: NAVAE CSs are available as soon as uniform asymptotically exact CSs\nare. Second, building on that connection, we construct closed-form NAVAE\nconfidence intervals (CIs) in two standard settings -- scalar expectations and\nlinear combinations of OLS coefficients -- under moment conditions only. For\nexpectations, our sole requirement is a bounded kurtosis. In the OLS case, our\nmoment constraints accommodate heteroskedasticity and weak exogeneity of the\nregressors. Under those conditions, we enlarge the Central Limit Theorem-based\nCIs, which are asymptotically exact, to ensure non-asymptotic guarantees. Those\nmodifications vanish asymptotically so that our CIs coincide with the classical\nones in the limit. We illustrate the potential and limitations of our approach\nthrough a simulation study.", "AI": {"tldr": "本文研究了在半参数统计模型中同时满足非渐近有效和渐近精确一致性的置信集（NAVAE CSs），提出了构建此类置信集的通用条件，并在两种标准设置下构建了闭式NAVAE置信区间。", "motivation": "现有的大样本和有限样本推断方法之间存在差距，本文旨在构建既满足非渐近有效性又具备渐近精确一致性的置信集，以弥补这一差距。", "method": "首先推导了一个通用充分条件：当存在一致渐近精确置信集时，NAVAE置信集即可构建。随后在两种标准设置（标量期望和OLS系数的线性组合）下，仅基于矩条件构建了闭式NAVAE置信区间。", "result": "在标量期望情况下，仅需有界峰度条件；在OLS情况下，矩约束允许异方差性和弱外生性。通过扩大基于中心极限定理的置信区间，确保了非渐近保证，同时这些修正会渐近消失，使置信区间在极限情况下与经典方法一致。", "conclusion": "通过模拟研究展示了该方法的潜力和局限性，为半参数模型中NAVAE置信集的构建提供了理论和实践基础。"}}
{"id": "2507.16040", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16040", "abs": "https://arxiv.org/abs/2507.16040", "authors": ["Xinyuan Zhang", "Anrin Chakraborti", "Michael Reiter"], "title": "Blocklisted Oblivious Pseudorandom Functions", "comment": null, "summary": "An oblivious pseudorandom function (OPRF) is a protocol by which a client and\nserver interact to evaluate a pseudorandom function on a key provided by the\nserver and an input provided by the client, without divulging the key or input\nto the other party. We extend this notion by enabling the server to specify a\nblocklist, such that OPRF evaluation succeeds only if the client's input is not\non the blocklist. More specifically, our design gains performance by embedding\nthe client input into a metric space, where evaluation continues only if this\nembedding does not cluster with blocklist elements. Our framework exploits this\nstructure to separate the embedding and blocklist check to enable efficient\nimplementations of each, but then must stitch these phases together through\ncryptographic means. Our framework also supports subsequent evaluation of the\nOPRF on the same input more efficiently. We demonstrate the use of our design\nfor password blocklisting in augmented password-authenticated key exchange, and\nto MAC only executables that are not similar to ones on a blocklist of known\nmalware.", "AI": {"tldr": "本文提出一种支持黑名单检查的茫然伪随机函数（OPRF）协议，通过将客户端输入嵌入度量空间实现高效黑名单验证，并应用于密码黑名单和恶意软件检测场景。", "motivation": "传统OPRF协议无法实现输入黑名单验证，限制了其在密码安全和恶意软件检测等场景的应用。需要扩展OPRF功能以支持高效黑名单检查。", "method": "1. 将客户端输入嵌入度量空间\\n2. 设计分离式架构：先执行嵌入计算，再进行黑名单聚类检查\\n3. 通过密码学方法连接两个阶段\\n4. 支持相同输入的快速重复计算", "result": "1. 实现了带黑名单的高效OPRF协议\\n2. 在增强型密码认证密钥交换中验证了密码黑名单功能\\n3. 成功应用于仅对非恶意软件可执行文件生成MAC的场景", "conclusion": "该框架通过度量空间嵌入和模块化设计，首次实现了支持黑名单的OPRF协议，为密码安全和恶意软件检测提供了新解决方案，且具有计算效率优势。"}}
{"id": "2507.16648", "categories": ["cs.DM", "cs.CC", "cs.DS", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.16648", "abs": "https://arxiv.org/abs/2507.16648", "authors": ["Eleon Bach", "Yann Disser", "Sophie Huiberts", "Nils Mosis"], "title": "An unconditional lower bound for the active-set method in convex quadratic maximization", "comment": null, "summary": "We prove that the active-set method needs an exponential number of iterations\nin the worst-case to maximize a convex quadratic function subject to linear\nconstraints, regardless of the pivot rule used. This substantially improves\nover the best previously known lower bound [IPCO 2025], which needs objective\nfunctions of polynomial degrees $\\omega(\\log d)$ in dimension $d$, to a bound\nusing a convex polynomial of degree 2. In particular, our result firmly\nresolves the open question [IPCO 2025] of whether a constant degree suffices,\nand it represents significant progress towards linear objectives, where the\nactive-set method coincides with the simplex method and a lower bound for all\npivot rules would constitute a major breakthrough.\n  Our result is based on a novel extended formulation, recursively constructed\nusing deformed products. Its key feature is that it projects onto a polygonal\napproximation of a parabola while preserving all of its exponentially many\nvertices. We define a quadratic objective that forces the active-set method to\nfollow the parabolic boundary of this projection, without allowing any\nshortcuts along chords corresponding to edges of its full-dimensional preimage.", "AI": {"tldr": "本文证明主动集方法在最坏情况下需要指数级迭代次数来最大化带线性约束的凸二次函数，且不受主元规则影响，显著改进了现有下界。", "motivation": "解决[IPCO 2025]提出的关于常数次目标函数是否足够的问题，并为线性目标函数（与单纯形法等价）的下界研究奠定基础。", "method": "基于递归构建的扩展公式，利用变形积投影到抛物线多边形近似，并保留所有指数级顶点。设计二次目标函数迫使主动集方法沿抛物线边界移动。", "result": "将已知下界从多项式次数$\\omega(\\log d)$改进为凸二次函数，确立主动集方法在最坏情况下的指数迭代复杂度。", "conclusion": "该结果彻底解决了常数次目标函数的开放性问题，并为线性目标函数的主动集方法（即单纯形法）下界研究提供了重要进展。"}}
{"id": "2507.15992", "categories": ["math.NT", "11G18, 11G20, 11G30, 11G15"], "pdf": "https://arxiv.org/pdf/2507.15992", "abs": "https://arxiv.org/abs/2507.15992", "authors": ["Pietro Mercuri", "Oana Padurariu", "Frederick Saia", "Claudio Stirpe"], "title": "Point counts, automorphisms, and gonalities of Shimura curves", "comment": "32 pages. Comments welcome!", "summary": "We implement an algorithm to compute the number of points over finite fields\nfor the Shimura curves $X_0^D(N)$ and their Atkin--Lehner quotients. Our\ncomputations result in many examples of curves which attain the largest known\npoint counts among curves of specified genus over a finite field of given\ncardinality. To illustrate the utility of our point counts algorithm in\naddressing arithmetic questions, we prove that all automorphisms are\nAtkin--Lehner for many curves $X_0^D(N)$ with $DN\\leq 10000$, and we determine\nall tetragonal curves $X_0^D(N)$ up to a small number of possible exceptions.", "AI": {"tldr": "本文实现了一种计算Shimura曲线$X_0^D(N)$及其Atkin-Lehner商在有限域上点数的算法，并利用该算法解决了若干算术问题。", "motivation": "研究Shimura曲线$X_0^D(N)$在有限域上的点数，旨在发现特定亏格曲线在给定有限域中点数最多的例子，并解决相关算术问题。", "method": "开发了一种计算$X_0^D(N)$及其Atkin-Lehner商在有限域上点数的算法，并应用于$DN\\leq 10000$的曲线分析。", "result": "发现了许多在特定亏格和有限域下点数最多的曲线实例，证明了$DN\\leq 10000$时许多$X_0^D(N)$曲线的自同构均为Atkin-Lehner，并确定了几乎所有四角形曲线$X_0^D(N)$。", "conclusion": "该算法不仅有效计算了Shimura曲线的点数，还为研究曲线自同构和分类提供了有力工具，解决了若干长期未决的算术问题。"}}
{"id": "2507.15908", "categories": ["math.CO", "math.CA", "math.NT", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.15908", "abs": "https://arxiv.org/abs/2507.15908", "authors": ["Paul Melotti"], "title": "Distribution of roots of Eulerian polynomials", "comment": null, "summary": "We show that the empirical measures of roots of Eulerian polynomials converge\nto a certain log-Cauchy distribution. To do so, we show that the moments of the\nroots of a related family of polynomials not only converge, but are in fact\nultimately constant. These asymptotic moments are expressed in terms of\nN\\\"orlund's numbers.", "AI": {"tldr": "证明了欧拉多项式根的实证测度收敛于对数柯西分布，通过分析相关多项式根的矩收敛性并利用N\\\"orlund数表达渐近矩。", "motivation": "研究欧拉多项式根的分布特性及其收敛行为，探索相关多项式矩的渐近性质。", "method": "分析欧拉多项式根的实证测度，证明相关多项式根的矩不仅收敛且最终恒定，并利用N\\\"orlund数表达渐近矩。", "result": "欧拉多项式根的实证测度收敛于对数柯西分布，相关多项式根的矩具有恒定渐近值。", "conclusion": "欧拉多项式根的分布收敛性及其矩的渐近性质为相关数学领域提供了新的理论支持。"}}
{"id": "2507.15865", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15865", "abs": "https://arxiv.org/abs/2507.15865", "authors": ["Shai Shalev-Shwartz", "Amnon Shashua"], "title": "From Reasoning to Super-Intelligence: A Search-Theoretic Perspective", "comment": null, "summary": "Chain-of-Thought (CoT) reasoning has emerged as a powerful tool for enhancing\nthe problem-solving capabilities of large language models (LLMs). However, the\ntheoretical foundations of learning from CoT data remain underdeveloped, and\nexisting approaches -- such as Supervised Fine-Tuning (SFT), Reinforcement\nLearning (RL), Tree-of-Thoughts (ToT), and Monte Carlo Tree Search (MCTS) --\noften fail on complex reasoning tasks. In this work, we identify core obstacles\nthat hinder effective CoT learning, including distribution drift, lack of\nembedded search, and exponential inference costs. We introduce the Diligent\nLearner, a new learning paradigm that explicitly models reasoning as a\ndepth-first search guided by a validator and supports backtracking upon\nfailure. Under two mild and realistic assumptions, we prove that the Diligent\nLearner can efficiently learn from CoT data while existing methods fail to do\nso. This framework offers a path toward building scalable and reliable\nreasoning systems trained on naturally occurring, incomplete data -- paving the\nway for the development of Large Reasoning Models (LRMs) with robust,\ninterpretable problem-solving abilities.", "AI": {"tldr": "本文提出了一种名为\"勤奋学习者\"的新学习范式，用于解决现有方法在复杂推理任务中的不足，通过深度优先搜索和回溯机制有效学习思维链数据。", "motivation": "现有方法（如监督微调、强化学习、思维树和蒙特卡洛树搜索）在复杂推理任务中表现不佳，主要由于分布漂移、缺乏嵌入式搜索和指数级推理成本等核心障碍。", "method": "引入\"勤奋学习者\"范式，将推理建模为由验证器引导的深度优先搜索，支持失败时回溯，并在两个温和且现实的假设下证明其有效性。", "result": "研究表明，\"勤奋学习者\"能够高效地从思维链数据中学习，而现有方法无法做到，为构建可扩展且可靠的推理系统提供了路径。", "conclusion": "该框架为开发具有鲁棒性和可解释性问题解决能力的大型推理模型（LRM）奠定了基础，尤其是在处理自然产生的不完整数据时。"}}
{"id": "2507.16272", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.16272", "abs": "https://arxiv.org/abs/2507.16272", "authors": ["Elvira Moreno", "Venkat Chandrasekaran"], "title": "Spectral Methods for Polynomial Optimization", "comment": null, "summary": "We present a hierarchy of tractable relaxations to obtain lower bounds on the\nminimum value of a polynomial over a constraint set defined by polynomial\nequations. In contrast to previous convex relaxation techniques for this\nproblem, our method is based on computing the smallest generalized eigenvalue\nof a pair of matrices derived from the problem data, which can be accomplished\nfor large problem instances using off-the-shelf software. We characterize the\nalgebraic structure in a problem that facilitates the application of our\nframework, and we observe that our method is applicable for all polynomial\noptimization problems with bounded constraint sets. Our construction also\nyields a nested sequence of structured convex outer approximations of a bounded\nalgebraic variety with the property that linear optimization over each\napproximation reduces to an eigenvalue computation. Finally, we present\nnumerical experiments on representative problems in which we demonstrate the\nscalability of our approach compared to convex relaxation methods derived from\nsums-of-squares certificates of nonnegativity.", "AI": {"tldr": "本文提出了一种基于广义特征值计算的分层可处理松弛方法，用于多项式优化问题的下界求解，适用于有界约束集的所有多项式优化问题，并通过数值实验验证了其可扩展性。", "motivation": "针对多项式优化问题，现有凸松弛技术存在局限性，需要一种更高效且适用于大规模问题的方法来获得下界。", "method": "通过计算从问题数据导出的矩阵对的最小广义特征值，构建一系列嵌套的凸外近似，每个近似上的线性优化可简化为特征值计算。", "result": "该方法适用于所有有界约束集的多项式优化问题，数值实验表明其相比基于非负性平方和证书的凸松弛方法具有更好的可扩展性。", "conclusion": "所提出的基于广义特征值的分层松弛框架为多项式优化问题提供了一种高效且可扩展的下界求解方法，特别适用于大规模问题实例。"}}
{"id": "2507.16370", "categories": ["cs.AI", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.16370", "abs": "https://arxiv.org/abs/2507.16370", "authors": ["Lucas de Lara"], "title": "Canonical Representations of Markovian Structural Causal Models: A Framework for Counterfactual Reasoning", "comment": null, "summary": "Counterfactual reasoning aims at answering contrary-to-fact questions like\n''Would have Alice recovered had she taken aspirin?'' and corresponds to the\nmost fine-grained layer of causation. Critically, while many counterfactual\nstatements cannot be falsified -- even by randomized experiments -- they\nunderpin fundamental concepts like individual-wise fairness. Therefore,\nproviding models to formalize and implement counterfactual beliefs remains a\nfundamental scientific problem. In the Markovian setting of Pearl's causal\nframework, we propose an alternative approach to structural causal models to\nrepresent counterfactuals compatible with a given causal graphical model. More\nprecisely, we introduce counterfactual models, also called canonical\nrepresentations of structural causal models. They enable analysts to choose a\ncounterfactual conception via random-process probability distributions with\npreassigned marginals and characterize the counterfactual equivalence class of\nstructural causal models. Then, we present a normalization procedure to\ndescribe and implement various counterfactual conceptions. Compared to\nstructural causal models, it allows to specify many counterfactual conceptions\nwithout altering the observational and interventional constraints. Moreover,\nthe content of the model corresponding to the counterfactual layer does not\nneed to be estimated; only to make a choice. Finally, we illustrate the\nspecific role of counterfactuals in causality and the benefits of our approach\non theoretical and numerical examples.", "AI": {"tldr": "本文提出了一种替代结构因果模型的对抗性推理方法，通过引入反事实模型（即结构因果模型的规范表示）来形式化和实现反事实信念，并展示了其在因果推理中的独特作用。", "motivation": "反事实推理（如'如果Alice服用阿司匹林会康复吗？'）是因果关系的细粒度层面，但许多反事实陈述无法通过随机实验验证。如何形式化和实现反事实信念仍是一个基础科学问题。", "method": "在Pearl因果框架的马尔可夫设定下，提出反事实模型（结构因果模型的规范表示），通过随机过程概率分布选择反事实概念，并给出归一化程序以描述和实施不同反事实概念。", "result": "相比结构因果模型，新方法允许在不改变观测和干预约束的情况下指定多种反事实概念，且反事实层内容无需估计，仅需选择。理论及数值示例验证了其优势。", "conclusion": "反事实模型为因果推理中的反事实层提供了灵活的形式化工具，其规范表示和归一化程序为反事实概念的选择与实现提供了新途径，在理论和应用层面均具有价值。"}}
{"id": "2507.16060", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16060", "abs": "https://arxiv.org/abs/2507.16060", "authors": ["Eyasu Getahun Chekole", "Howard Halim", "Jianying Zhou"], "title": "MFAz: Historical Access Based Multi-Factor Authorization", "comment": null, "summary": "Unauthorized access remains one of the critical security challenges in the\nrealm of cybersecurity. With the increasing sophistication of attack\ntechniques, the threat of unauthorized access is no longer confined to the\nconventional ones, such as exploiting weak access control policies. Instead,\nadvanced exploitation strategies, such as session hijacking-based attacks, are\nbecoming increasingly prevalent, posing serious security concerns. Session\nhijacking enables attackers to take over an already established session between\nlegitimate peers in a stealthy manner, thereby gaining unauthorized access to\nprivate resources. Unfortunately, traditional access control mechanisms, such\nas static access control policies, are insufficient to prevent session\nhijacking or other advanced exploitation techniques. In this work, we propose a\nnew multi-factor authorization (MFAz) scheme that proactively mitigates\nunauthorized access attempts both conventional and advanced unauthorized access\nattacks. The proposed scheme employs fine-grained access control rules (ARs)\nand verification points (VPs) that are systematically generated from\nhistorically granted accesses as the first and second authorization factors,\nrespectively. As a proof-of-concept, we implement the scheme using different\ntechniques. We leverage bloom filter to achieve runtime and storage efficiency,\nand blockchain to make authorization decisions in a temper-proof and\ndecentralized manner. To the best of our knowledge, this is the first formal\nintroduction of a multi-factor authorization scheme, which is orthogonal to the\nmulti-factor authentication (MFA) schemes. The effectiveness of our proposed\nscheme is experimentally evaluated using a smart-city testbed involving\ndifferent devices with varying computational capacities. The experimental\nresults reveal high effectiveness of the scheme both in security and\nperformance guarantees.", "AI": {"tldr": "本文提出了一种新型多因素授权（MFAz）方案，旨在主动防范传统及高级未经授权访问攻击，通过细粒度访问控制规则和验证点实现高效安全防护。", "motivation": "随着攻击技术的日益复杂，传统访问控制机制已无法有效防范会话劫持等高级攻击手段，亟需一种更强大的授权方案来应对这些安全挑战。", "method": "方案采用细粒度访问控制规则（ARs）和历史授权生成的验证点（VPs）作为双重授权因素，结合布隆过滤器提升运行时效率，并利用区块链实现防篡改的分布式授权决策。", "result": "在智能城市测试平台上进行的实验表明，该方案在安全性和性能保障方面均表现出色，能有效抵御各类未经授权访问攻击。", "conclusion": "MFAz方案作为首个正式提出的多因素授权框架，与多因素认证（MFA）形成互补，为网络安全领域提供了创新的防护思路和实用解决方案。"}}
{"id": "2507.16759", "categories": ["math.CO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.16759", "abs": "https://arxiv.org/abs/2507.16759", "authors": ["Sergey Kurapov", "Maxim Davidovsky"], "title": "Algorithmic methods of finite discrete structures. Topological graph drawing (part IV)", "comment": "67 pages, in Ukrainian language, 83 figures, a preprint of monography", "summary": "The chapter presents mathematical models intended for creating a topological\ndrawing of a non-separable non-planar graph based on the methods of G. Ringel's\nvertex rotation theory. The induced system of cycles generates a topological\ndrawing of a certain thickness. A method for determining the location of\nimaginary vertices by finding the intersection of connections on a plane is\npresented. A topological drawing of a maximum planar subgraph is used as a\nbasis.", "AI": {"tldr": "本章介绍基于G. Ringel顶点旋转理论的数学模型，用于生成不可分非平面图的拓扑绘制，通过诱导循环系统和虚顶点定位方法实现特定厚度的绘图。", "motivation": "研究旨在为非可分非平面图开发有效的拓扑绘制方法，利用现有理论解决复杂图形的可视化问题。", "method": "采用G. Ringel的顶点旋转理论，通过诱导循环系统生成拓扑绘图，并提出了在平面上通过连接交点定位虚顶点的方法，以最大平面子图的拓扑绘制为基础。", "result": "提出的方法能够生成具有特定厚度的非可分非平面图的拓扑绘制，并通过虚顶点定位优化了图形的空间布局。", "conclusion": "该数学模型为复杂非平面图的拓扑绘制提供了有效工具，扩展了顶点旋转理论在实际应用中的潜力。"}}
{"id": "2507.16135", "categories": ["math.NT", "11A07"], "pdf": "https://arxiv.org/pdf/2507.16135", "abs": "https://arxiv.org/abs/2507.16135", "authors": ["Chris Bispels", "Matthew Cohen", "Joshua Harrington", "Joshua Lowrance", "Kaelyn Pontes", "Leif Schaumann", "Tony W. H. Wong"], "title": "A further investigation on covering systems with odd moduli", "comment": null, "summary": "Erd\\H{o}s first introduced the idea of covering systems in 1950. Since then,\nmuch of the work in this area has concentrated on identifying covering systems\nthat meet specific conditions on their moduli. Among the central open problems\nin this field is the well-known odd covering problem. In this paper, we\ninvestigate a variant of that problem, where one odd integer is permitted to\nappear multiple times as a modulus in the covering system, while all remaining\nmoduli are distinct odd integers greater than 1.", "AI": {"tldr": "本文研究了覆盖系统的一个变体问题，允许一个奇数模数重复出现，其余模数为大于1的互异奇数。", "motivation": "自1950年Erd\\H{o}s提出覆盖系统概念以来，模数条件的研究成为核心问题。本研究针对著名的奇数覆盖问题，探索其变体形式。", "method": "通过允许一个奇数模数重复出现，同时保持其他模数为大于1的互异奇数，构建新型覆盖系统。", "result": "该变体问题拓展了传统奇数覆盖系统的研究范畴，为模数限制条件提供了新的可能性。", "conclusion": "这种允许单模数重复的变体形式，为覆盖系统理论开辟了新的研究方向，对解决原始奇数覆盖问题具有启发意义。"}}
{"id": "2507.15986", "categories": ["math.CO", "05E0, 05C60"], "pdf": "https://arxiv.org/pdf/2507.15986", "abs": "https://arxiv.org/abs/2507.15986", "authors": ["Michael Gonzalez", "Rosa Orellana", "Mario Tomba"], "title": "On the reconstruction of trees from their chromatic symmetric functions", "comment": "This FPSAC extended abstract contains a new proof that diameter 5\n  graphs satisfy the Tree Isomorphism Conjecture", "summary": "We study Stanley's chromatic symmetric function (CSF) for trees when\nexpressed in the star basis. We use the deletion-near-contraction (DNC)\nalgorithm to compute coefficients that occur in the CSF in the star basis. In\nparticular, one of our main results determines the smallest partition in\nlexicographic order that occurs as an indexing partition in the CSF, and we\nalso give a formula for its coefficient. In addition to describing properties\nof trees encoded in the coefficients of the star basis, we give an algorithm\nfor reconstructing trees of diameter less than six.", "AI": {"tldr": "本文研究了Stanley的色对称函数（CSF）在星基下的树表示，利用删除-近收缩（DNC）算法计算星基中的系数，确定了字典序最小的分区及其系数公式，并提出了直径小于六的树的重构算法。", "motivation": "研究Stanley色对称函数在星基下的树表示，旨在揭示树的结构特性与色对称函数系数之间的关系，为树的重构提供理论基础。", "method": "采用删除-近收缩（DNC）算法计算色对称函数在星基中的系数，并通过分析树的特性推导出相关公式。", "result": "确定了色对称函数中字典序最小的分区及其系数公式，并提出了直径小于六的树的重构算法。", "conclusion": "本研究不仅揭示了树的特性与色对称函数系数之间的关联，还为树的重构提供了有效算法，为相关领域的研究提供了新的工具和方法。"}}
{"id": "2507.15866", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15866", "abs": "https://arxiv.org/abs/2507.15866", "authors": ["Marek Vlk", "Premysl Sucha", "Jaroslaw Rudy", "Radoslaw Idzikowski"], "title": "Purchase and Production Optimization in a Meat Processing Plant", "comment": "25 pages, 5 figures", "summary": "The food production industry, especially the meat production sector, faces\nmany challenges that have even escalated due to the recent outbreak of the\nenergy crisis in the European Union. Therefore, efficient use of input\nmaterials is an essential aspect affecting the profit of such companies. This\npaper addresses an optimization problem concerning the purchase and subsequent\nmaterial processing we solved for a meat processing company. Unlike the\nmajority of existing papers, we do not concentrate on how this problem concerns\nsupply chain management, but we focus purely on the production stage. The\nproblem involves the concept of alternative ways of material processing, stock\nof material with different expiration dates, and extra constraints widely\nneglected in the current literature, namely, the minimum order quantity and the\nminimum percentage in alternatives. We prove that each of these two constraints\nmakes the problem \\mbox{$\\mathcal{NP}$-hard}, and hence we design a simple\niterative approach based on integer linear programming that allows us to solve\nreal-life instances even using an open-source integer linear programming\nsolver. Another advantage of this approach is that it mitigates numerical\nissues, caused by the extensive range of data values, we experienced with a\ncommercial solver. The results obtained using real data from the meat\nprocessing company showed that our algorithm can find the optimum solution in a\nfew seconds for all considered use cases.", "AI": {"tldr": "本文针对肉类加工企业的材料采购与处理优化问题，提出了一种基于整数线性规划的迭代方法，解决了现有文献中常被忽视的最小订单量和最低比例约束问题，并证明了这些约束使问题$\\mathcal{NP}$-难。", "motivation": "欧盟能源危机加剧了食品生产行业（尤其是肉类生产）的挑战，高效利用原材料成为影响企业利润的关键。本文聚焦生产阶段的优化问题，而非供应链管理。", "method": "设计了一种基于整数线性规划的简单迭代方法，解决了材料处理替代方案、不同保质期库存以及最小订单量和最低比例约束等问题，并证明了这些约束使问题$\\mathcal{NP}$-难。", "result": "使用肉类加工公司的真实数据进行测试，结果表明该算法能在几秒内为所有用例找到最优解，且开源求解器也能有效解决数值问题。", "conclusion": "提出的方法不仅解决了实际生产中的复杂约束问题，还避免了商业求解器因数据范围广泛而导致的数值问题，具有较高的实用性和效率。"}}
{"id": "2507.16315", "categories": ["math.OC", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.16315", "abs": "https://arxiv.org/abs/2507.16315", "authors": ["Felix Benning"], "title": "A Distributional View of High Dimensional Optimization", "comment": "Most chapters reproduces work that was conducted during my PhD. The\n  review of classical worst-case optimization and Bayesian Optimization is\n  unpublished and may present a novel perspective. While it is not difficult to\n  do, building Machine Learning Theory from exchangeable data is also fairly\n  non-standard and offers an intuitive explanation for many canonical loss\n  functions", "summary": "This PhD thesis presents a distributional view of optimization in place of a\nworst-case perspective. We motivate this view with an investigation of the\nfailure point of classical optimization. Subsequently we consider the\noptimization of a randomly drawn objective function. This is the setting of\nBayesian Optimization. After a review of Bayesian optimization we outline how\nsuch a distributional view may explain predictable progress of optimization in\nhigh dimension. It further turns out that this distributional view provides\ninsights into optimal step size control of gradient descent. To enable these\nresults, we develop mathematical tools to deal with random input to random\nfunctions and a characterization of non-stationary isotropic covariance\nkernels. Finally, we outline how assumptions about the data, specifically\nexchangability, can lead to random objective functions in machine learning and\nanalyze their landscape.", "AI": {"tldr": "该博士论文提出用分布视角替代传统最坏情况视角来研究优化问题，通过贝叶斯优化分析随机目标函数的优化过程，揭示了高维优化可预测进展的原因，并开发了处理随机函数输入的新数学工具。", "motivation": "经典优化方法在特定情况下的失效促使研究者采用分布视角，通过分析随机目标函数的优化过程来更全面地理解优化行为。", "method": "论文首先回顾贝叶斯优化方法，随后开发了处理随机函数输入的数学工具，并研究了非平稳各向同性协方差核的特性。", "result": "研究发现分布视角能解释高维优化中的可预测进展，并为梯度下降的最优步长控制提供新见解。同时揭示了数据交换性假设如何导致机器学习中的随机目标函数。", "conclusion": "通过分布视角研究优化问题不仅克服了经典方法的局限，还为理解高维优化和步长控制提供了新思路，同时建立了随机目标函数与机器学习假设之间的联系。"}}
{"id": "2507.16134", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.16134", "abs": "https://arxiv.org/abs/2507.16134", "authors": ["Baofu Han", "Bing Li", "Yining Qi", "Raja Jurdak", "Kaibin Huang", "Chau Yuen"], "title": "DP2Guard: A Lightweight and Byzantine-Robust Privacy-Preserving Federated Learning Scheme for Industrial IoT", "comment": null, "summary": "Privacy-Preserving Federated Learning (PPFL) has emerged as a secure\ndistributed Machine Learning (ML) paradigm that aggregates locally trained\ngradients without exposing raw data. To defend against model poisoning threats,\nseveral robustness-enhanced PPFL schemes have been proposed by integrating\nanomaly detection. Nevertheless, they still face two major challenges: (1) the\nreliance on heavyweight encryption techniques results in substantial\ncommunication and computation overhead; and (2) single-strategy defense\nmechanisms often fail to provide sufficient robustness against adaptive\nadversaries. To overcome these challenges, we propose DP2Guard, a lightweight\nPPFL framework that enhances both privacy and robustness. DP2Guard leverages a\nlightweight gradient masking mechanism to replace costly cryptographic\noperations while ensuring the privacy of local gradients. A hybrid defense\nstrategy is proposed, which extracts gradient features using singular value\ndecomposition and cosine similarity, and applies a clustering algorithm to\neffectively identify malicious gradients. Additionally, DP2Guard adopts a trust\nscore-based adaptive aggregation scheme that adjusts client weights according\nto historical behavior, while blockchain records aggregated results and trust\nscores to ensure tamper-proof and auditable training. Extensive experiments\nconducted on two public datasets demonstrate that DP2Guard effectively defends\nagainst four advanced poisoning attacks while ensuring privacy with reduced\ncommunication and computation costs.", "AI": {"tldr": "本文提出DP2Guard，一种轻量级隐私保护联邦学习框架，通过梯度掩蔽和混合防御策略提升隐私性与鲁棒性，同时降低通信与计算开销。", "motivation": "现有隐私保护联邦学习（PPFL）方案依赖重型加密技术导致高开销，且单一防御策略难以抵御自适应攻击，亟需轻量级高鲁棒性解决方案。", "method": "采用轻量级梯度掩蔽替代加密操作；提出混合防御策略（奇异值分解+余弦相似度提取特征，聚类检测恶意梯度）；基于信任分数的自适应聚合方案，区块链记录确保可审计性。", "result": "在两个公开数据集上的实验表明，DP2Guard能有效抵御四种高级投毒攻击，隐私保护前提下通信与计算成本降低。", "conclusion": "DP2Guard通过创新性轻量级设计与混合防御机制，实现了隐私-鲁棒性-效率的平衡，为安全联邦学习提供了可行方案。"}}
{"id": "2507.16138", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.16138", "abs": "https://arxiv.org/abs/2507.16138", "authors": ["Theresa C. Anderson", "Adam Bertelli", "Evan M. O'Dorney"], "title": "The structure of the double discriminant", "comment": "8 pages", "summary": "For a polynomial $f(x) = \\sum_{i=0}^n a_i x^i$, we study the double\ndiscriminant $DD_{n,k} = \\operatorname{disc}_{a_k} \\operatorname{disc}_x f(x)$,\nwhich appears in the proof of the van der Waerden--Bhargava theorem. We\nconjecture that $DD_{n,k}$ is the product of a square, a cube, and possibly a\nlinear monomial and we prove this when $k=0$. We also investigate the\n(typically large and smooth) outlying integer constant in the factorization of\n$DD_{n,k}$.", "AI": {"tldr": "研究多项式$f(x) = \\sum_{i=0}^n a_i x^i$的双判别式$DD_{n,k}$，提出其分解形式的猜想并在$k=0$时证明，同时探讨其分解中的大整数常数。", "motivation": "双判别式$DD_{n,k}$在van der Waerden--Bhargava定理的证明中出现，研究其分解形式有助于理解多项式的判别性质。", "method": "通过代数方法分析双判别式$DD_{n,k}$的结构，提出其分解为平方、立方及可能的一次单项式的猜想，并在$k=0$时给出证明。", "result": "证明了当$k=0$时，$DD_{n,k}$可分解为平方、立方及可能的一次单项式的乘积，并研究了分解中的大整数常数的性质。", "conclusion": "双判别式$DD_{n,k}$的分解形式猜想在$k=0$时成立，其分解中的大整数常数通常较大且光滑，为后续研究提供了方向。"}}
{"id": "2507.16009", "categories": ["math.CO", "51E05, 51E10"], "pdf": "https://arxiv.org/pdf/2507.16009", "abs": "https://arxiv.org/abs/2507.16009", "authors": ["Taras Banakh", "Ivan Hetman", "Alex Ravsky"], "title": "New Steiner systems $S(2,6,v)$ with block length 6", "comment": "11 pages", "summary": "In this paper various Steiner systems $S(2,k,v)$ for $k = 6$ are collected\nand enumerated for specific constructions. In particular, two earlier unknown\ntypes of $1$-rotational designs are found for the groups $SL(2,5)$ and\n$((\\mathbb Z_3 \\times \\mathbb Z_3) \\rtimes \\mathbb Z_3) \\times \\mathbb Z_5$.\nAlso new Steiner systems $S(2,6,96), S(2,6,106), S(2,6,111)$ are listed.", "AI": {"tldr": "本文收集并枚举了多种$S(2,6,v)$ Steiner系统，发现了两种新的$1$-旋转设计，并列举了新的Steiner系统$S(2,6,96)$、$S(2,6,106)$和$S(2,6,111)$。", "motivation": "研究$S(2,k,v)$ Steiner系统的构造和枚举，特别是$k=6$的情况，以填补现有知识的空白。", "method": "通过特定的构造方法，枚举和分析$S(2,6,v)$ Steiner系统，并探索$1$-旋转设计的性质。", "result": "发现了两种新的$1$-旋转设计，分别对应于群$SL(2,5)$和$((\\mathbb Z_3 \\times \\mathbb Z_3) \\rtimes \\mathbb Z_3) \\times \\mathbb Z_5$，并列举了新的Steiner系统$S(2,6,96)$、$S(2,6,106)$和$S(2,6,111)$。", "conclusion": "本研究扩展了$S(2,6,v)$ Steiner系统的知识库，特别是通过发现新的$1$-旋转设计和列举新的系统，为组合设计理论提供了新的实例。"}}
{"id": "2507.15874", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15874", "abs": "https://arxiv.org/abs/2507.15874", "authors": ["Yin Wu", "Daniel Slieter", "Vivek Subramanian", "Ahmed Abouelazm", "Robin Bohn", "J. Marius Zöllner"], "title": "Why Braking? Scenario Extraction and Reasoning Utilizing LLM", "comment": null, "summary": "The growing number of ADAS-equipped vehicles has led to a dramatic increase\nin driving data, yet most of them capture routine driving behavior. Identifying\nand understanding safety-critical corner cases within this vast dataset remains\na significant challenge. Braking events are particularly indicative of\npotentially hazardous situations, motivating the central question of our\nresearch: Why does a vehicle brake? Existing approaches primarily rely on\nrule-based heuristics to retrieve target scenarios using predefined condition\nfilters. While effective in simple environments such as highways, these methods\nlack generalization in complex urban settings. In this paper, we propose a\nnovel framework that leverages Large Language Model (LLM) for scenario\nunderstanding and reasoning. Our method bridges the gap between low-level\nnumerical signals and natural language descriptions, enabling LLM to interpret\nand classify driving scenarios. We propose a dual-path scenario retrieval that\nsupports both category-based search for known scenarios and embedding-based\nretrieval for unknown Out-of-Distribution (OOD) scenarios. To facilitate\nevaluation, we curate scenario annotations on the Argoverse 2 Sensor Dataset.\nExperimental results show that our method outperforms rule-based baselines and\ngeneralizes well to OOD scenarios.", "AI": {"tldr": "本文提出了一种利用大语言模型（LLM）进行驾驶场景理解与推理的新框架，通过双路径场景检索方法（基于类别和嵌入）有效识别安全关键场景，在复杂城市环境中优于传统基于规则的方法。", "motivation": "随着配备ADAS的车辆增多，驾驶数据激增，但现有方法难以从海量数据中识别安全关键场景（如刹车事件）。传统基于规则的启发式方法在复杂城市环境中泛化能力不足，亟需新解决方案。", "method": "提出LLM驱动的框架：1) 将低层数值信号与自然语言描述桥接，使LLM能解释场景；2) 设计双路径检索（基于已知类别的搜索+面向未知OOD场景的嵌入检索）；3) 在Argoverse 2传感器数据集上标注场景用于评估。", "result": "实验表明：1) 该方法显著优于基于规则的基线；2) 对分布外（OOD）场景展现出良好泛化能力；3) 成功实现刹车事件等安全关键场景的语义化分类。", "conclusion": "该框架为驾驶场景理解提供了可扩展的解决方案，尤其擅长处理复杂城市环境中的未知危险场景，证明了LLM在自动驾驶数据分析中的潜力。"}}
{"id": "2507.16412", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.16412", "abs": "https://arxiv.org/abs/2507.16412", "authors": ["Qingxin Meng", "Yiwei Wu"], "title": "Discrete-Time LQ Stochastic Two Person Nonzero Sum Difference Games With Random Coefficients:~Closed-Loop Nash Equilibrium", "comment": null, "summary": "This paper investigates closed-loop Nash equilibria for discrete-time\nlinear-quadratic (LQ) stochastic nonzero-sum difference games with random\ncoefficients. Unlike existing works, we consider randomness in both state\ndynamics and cost functionals, leading to a complex structure of fully coupled\ncross-coupled stochastic Riccati equations (CCREs). The key contributions lie\nin characterizing the equilibrium via state-feedback strategies derived by\ndecoupling stochastic Hamiltonian systems governed by two symmetric CCREs-these\nrandom coefficients induce a higher-order nonlinear backward stochastic\ndifference equation (BS$\\triangle$E) system, fundamentally differing from\ndeterministic counterparts. Under minimal regularity conditions, we establish\nnecessary and sufficient conditions for closed-loop Nash equilibrium existence,\ncontingent on the regular solvability of CCREs without requiring strong\nassumptions. Solutions are constructed using a dynamic programming principle\n(DPP), linking equilibrium strategies to coupled Lyapunov-type equations. Our\nanalysis resolves critical challenges in modeling inherent randomness and\nprovides a unified framework for dynamic decision-making under uncertainty.", "AI": {"tldr": "本文研究了具有随机系数的离散时间线性二次(LQ)随机非零和差分博弈的闭环纳什均衡，通过解耦随机哈密顿系统，建立了与耦合随机Riccati方程(CCREs)相关的均衡策略存在条件。", "motivation": "现有研究未充分考虑状态动态和成本泛函中的随机性，本文旨在解决随机系数导致的复杂耦合结构，为不确定性下的动态决策提供统一框架。", "method": "采用动态规划原理(DPP)构建解，通过解耦受两个对称CCREs控制的随机哈密顿系统，将均衡策略与Lyapunov型方程关联，并建立CCREs正则可解性的充要条件。", "result": "在最小正则性条件下，证明了闭环纳什均衡存在的充要条件，其依赖于CCREs的正则可解性，且无需强假设；随机系数导致的高阶非线性BS$\\triangle$E系统与确定性情形有本质差异。", "conclusion": "研究解决了固有随机性建模的关键挑战，为随机环境下动态博弈提供了基于CCREs的理论框架，扩展了随机LQ差分博弈的分析工具。"}}
{"id": "2507.16164", "categories": ["cs.CR", "cs.AI", "cs.LG", "I.2.7; I.2.6; I.2.3; D.4.6"], "pdf": "https://arxiv.org/pdf/2507.16164", "abs": "https://arxiv.org/abs/2507.16164", "authors": ["Eldor Abdukhamidov", "Tamer Abuhmed", "Joanna C. S. Santos", "Mohammed Abuhamad"], "title": "Attacking interpretable NLP systems", "comment": null, "summary": "Studies have shown that machine learning systems are vulnerable to\nadversarial examples in theory and practice. Where previous attacks have\nfocused mainly on visual models that exploit the difference between human and\nmachine perception, text-based models have also fallen victim to these attacks.\nHowever, these attacks often fail to maintain the semantic meaning of the text\nand similarity. This paper introduces AdvChar, a black-box attack on\nInterpretable Natural Language Processing Systems, designed to mislead the\nclassifier while keeping the interpretation similar to benign inputs, thus\nexploiting trust in system transparency. AdvChar achieves this by making less\nnoticeable modifications to text input, forcing the deep learning classifier to\nmake incorrect predictions and preserve the original interpretation. We use an\ninterpretation-focused scoring approach to determine the most critical tokens\nthat, when changed, can cause the classifier to misclassify the input. We apply\nsimple character-level modifications to measure the importance of tokens,\nminimizing the difference between the original and new text while generating\nadversarial interpretations similar to benign ones. We thoroughly evaluated\nAdvChar by testing it against seven NLP models and three interpretation models\nusing benchmark datasets for the classification task. Our experiments show that\nAdvChar can significantly reduce the prediction accuracy of current deep\nlearning models by altering just two characters on average in input samples.", "AI": {"tldr": "本文提出AdvChar，一种针对可解释自然语言处理系统的黑盒攻击方法，通过细微的字符级修改误导分类器，同时保持解释相似性。", "motivation": "现有文本对抗攻击常破坏语义相似性，而AdvChar旨在利用系统透明度信任，保持解释相似性同时实现攻击。", "method": "采用解释导向的评分方法定位关键token，施加字符级修改，最小化文本差异并生成与良性输入相似的对抗解释。", "result": "在7个NLP模型和3个解释模型上的实验表明，平均仅需修改2个字符即可显著降低模型预测准确率。", "conclusion": "AdvChar揭示了当前深度学习模型在字符级扰动下的脆弱性，对可解释NLP系统的安全性提出挑战。"}}
{"id": "2507.16225", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.16225", "abs": "https://arxiv.org/abs/2507.16225", "authors": ["David Savitt"], "title": "An elementary proof of Newman's eta-quotient theorem", "comment": "12 pages. To appear, Research in Number Theory", "summary": "Let eta(z) be the Dedekind eta function. Newman studied the modularity of\neta-quotients, giving necessary and sufficient conditions for a function of the\nform \\prod_{0 < m | N} eta(mz)^{r_m} to be a (weakly) holomorphic modular form\nof level N. We explain a proof of Newman's theorem, developed while teaching a\nclass for talented high school students at Canada/USA Mathcamp. The key\nobservation is that although Gamma_1(N) is not generated by its upper\ntriangular and lower triangular subgroups, it is generated by those subgroups\ntogether with any congruence subgroup. Modularity with respect to some\ncongruence subgroup is established using one simple identity involving the\nmultiplier system of eta(z), whose proof is elementary in the sense that it\navoids the use of Dedekind sums.", "AI": {"tldr": "本文通过教学实践，为高中生解释了Newman关于Dedekind eta函数商模性的定理证明，避免了使用Dedekind和的初等方法。", "motivation": "研究Dedekind eta函数商的模性，为高中生提供易于理解的证明方法，避免复杂的数学工具如Dedekind和。", "method": "利用Gamma_1(N)群的上三角和下三角子群及同余子群的生成性质，结合eta函数的乘子系统的一个简单恒等式，证明模性。", "result": "证明了Newman定理，即形式为$\\prod_{0 < m | N} \\eta(mz)^{r_m}$的函数在特定条件下是水平N的（弱）全纯模形式。", "conclusion": "通过初等方法成功验证了eta函数商的模性定理，为数学教育提供了新的教学案例。"}}
{"id": "2507.16169", "categories": ["math.CO", "05C69 (Primary) 05C12, 05B30, 05C15 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.16169", "abs": "https://arxiv.org/abs/2507.16169", "authors": ["Briana Foster-Greenwood", "Christine Uhl"], "title": "Metric Dimension of a Direct Product of Three Complete Graphs: The Middle Cone Family", "comment": "2 figures, 2 tables", "summary": "In previous work, we determined the metric dimension for a direct product of\nthree isomorphic complete graphs. Turning to the case where the complete graphs\nmay have different orders, there are three families we refer to as the upper,\nlower, and middle cones. We determine the metric dimension and\nlocation-total-domination number for a family of direct products of three\ncomplete graphs stemming from the middle cone. We explicitly describe minimum\nresolving sets. To verify the sets are resolving, we define a basic landmark\nsystem and show it will be a resolving set if and only if its associated\n3-edge-colored hypergraph avoids three types of forbidden subgraphs. This\ngeneralizes the technique used for three isomorphic factors.", "AI": {"tldr": "本文研究了三个不同阶完全图直积的度量维数，针对中锥结构族确定了度量维数和定位-全控制数，并给出了最小解析集的显式描述。通过定义基本地标系统及其关联的3边着色超图，验证了解析集的有效性。", "motivation": "前期工作已解决三个同构完全图直积的度量维数问题，本文转向研究不同阶完全图直积的情况，重点关注中锥结构族的度量性质。", "method": "定义基本地标系统，证明其成为解析集的充要条件是关联的3边着色超图避免三类禁止子图，该方法推广了同构因子情形的技术。", "result": "针对中锥衍生的三完全图直积族，精确计算了度量维数和定位-全控制数，并显式构造了最小解析集。", "conclusion": "通过超图理论将解析集验证转化为组合禁止结构问题，该框架可推广至更一般的图直积情形，为后续研究提供新工具。"}}
{"id": "2507.15875", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.15875", "abs": "https://arxiv.org/abs/2507.15875", "authors": ["Jerry Li", "Timothy Oh", "Joseph Hoang", "Vardhit Veeramachaneni"], "title": "Differential Multimodal Transformers", "comment": null, "summary": "Small language models have gained significant popularity due to their\nefficiency and growing capabilities. However, incorporating additional\nmodalities, such as vision, can exacerbate the challenge of limited context\nwindows by introducing noise. Recent studies have highlighted that Transformer\nattention mechanisms often disproportionately focus on irrelevant contexts. In\nthis work, we extend the Differential Attention mechanism, originally designed\nfor text-only models, to the text-vision model PaliGemma. Our aim is to\nevaluate its ability to mitigate noisy information retrieval and reduce\nhallucinations. To this end, we fine-tuned the PaliGemma 3B model using LoRA,\nincorporating Differential Attention, and experimented with various parameter\nsettings and configurations. We demonstrate that Differential Attention can be\nadapted and integrated into the fine-tuning of existing models to enhance noisy\ninformation retrieval and question-answering capabilities.", "AI": {"tldr": "本研究将差分注意力机制扩展到多模态模型PaliGemma，通过LoRA微调验证其在减少噪声检索和幻觉方面的有效性。", "motivation": "小语言模型虽高效但多模态输入会加剧上下文噪声问题，传统Transformer注意力机制易关注无关信息，需改进噪声过滤能力。", "method": "基于文本模型差分注意力机制，在PaliGemma 3B模型中集成该机制并通过LoRA微调，测试不同参数配置对性能的影响。", "result": "实验证明差分注意力可适配现有模型微调流程，显著提升噪声信息检索质量和问答能力。", "conclusion": "差分注意力机制能有效增强多模态模型的抗噪声能力，为小模型部署提供实用优化方案。"}}
{"id": "2507.16461", "categories": ["math.OC", "34A34, 65K05, 90C30, 93E24"], "pdf": "https://arxiv.org/pdf/2507.16461", "abs": "https://arxiv.org/abs/2507.16461", "authors": ["Bas Symoens", "Morteza Rahimi", "Masoud Ahookhosh"], "title": "Inexact Levenberg-Marquardt methods under Hölder metric subregularity", "comment": "29 pages, 6 figures", "summary": "This paper investigates two inexact Levenberg-Marquardt (LM) methods for\nsolving systems of nonlinear equations. Both approaches compute approximate\nsearch directions by solving the LM linear system inexactly, subject to\nspecific residual-based conditions. The first method uses an adaptive scheme to\nupdate the LM parameter, and we establish its local superlinear convergence\nunder H\\\"older metric subregularity and local H\\\"older continuity of the\ngradient. The second method combines an inexact LM step with a nonmonotone\nquadratic regularization strategy. For this variant, we prove global\nconvergence under the assumption of Lipschitz continuous gradients and derive a\nworst-case global complexity bound, showing that an approximate stationary\npoint can be found in $\\mathcal{O}(\\epsilon^{-2})$ function and gradient\nevaluations. Finally, we justify the use of the LSQR algorithm for efficiently\nsolving the linear systems involved, which is used in our numerical experiment\non several nonlinear systems, including those appearing in real-world\nbiochemical reaction networks, monotone and nonlinear equations, and image\ndeblurring problems.", "AI": {"tldr": "本文研究了两种不精确的Levenberg-Marquardt (LM) 方法，用于求解非线性方程组。第一种方法采用自适应方案更新LM参数，在H\\\"older度量次正则性和梯度局部H\\\"older连续条件下实现了局部超线性收敛；第二种方法结合不精确LM步长与非单调二次正则化策略，在Lipschitz连续梯度假设下证明了全局收敛性，并给出了最坏情况下的全局复杂度界限$\\mathcal{O}(\\epsilon^{-2})$。数值实验验证了LSQR算法在求解相关线性系统中的有效性。", "motivation": "研究不精确Levenberg-Marquardt方法旨在高效求解非线性方程组，特别是针对实际应用中出现的复杂系统（如生物化学反应网络、图像去模糊问题等），通过降低线性系统求解的精度要求来提高计算效率。", "method": "提出两种不精确LM方法：1) 基于残差条件的自适应LM参数更新方案；2) 结合非单调二次正则化的混合策略。理论分析分别采用H\\\"older度量次正则性和Lipschitz连续梯度假设，并利用LSQR算法高效求解线性系统。", "result": "方法一在H\\\"older条件下实现局部超线性收敛；方法二证明全局收敛并建立$\\mathcal{O}(\\epsilon^{-2})$的复杂度界限。数值实验表明LSQR算法能有效处理生物化学网络、单调方程和图像去模糊等实际问题中的线性系统。", "conclusion": "两种不精确LM方法在不同正则性条件下均具有理论保证，其中非单调正则化策略兼具全局收敛性和可证明复杂度。LSQR算法的应用验证了该方法在实际非线性问题中的计算可行性，为大规模系统求解提供了新工具。"}}
{"id": "2507.16203", "categories": ["cs.CR", "cs.AI", "cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16203", "abs": "https://arxiv.org/abs/2507.16203", "authors": ["Rui Guo", "Avinash Ayalasomayajula", "Henian Li", "Jingbo Zhou", "Sujan Kumar Saha", "Farimah Farahmandi"], "title": "SVAgent: AI Agent for Hardware Security Verification Assertion", "comment": null, "summary": "Verification using SystemVerilog assertions (SVA) is one of the most popular\nmethods for detecting circuit design vulnerabilities. However, with the\nglobalization of integrated circuit design and the continuous upgrading of\nsecurity requirements, the SVA development model has exposed major limitations.\nIt is not only inefficient in development, but also unable to effectively deal\nwith the increasing number of security vulnerabilities in modern complex\nintegrated circuits. In response to these challenges, this paper proposes an\ninnovative SVA automatic generation framework SVAgent. SVAgent introduces a\nrequirement decomposition mechanism to transform the original complex\nrequirements into a structured, gradually solvable fine-grained problem-solving\nchain. Experiments have shown that SVAgent can effectively suppress the\ninfluence of hallucinations and random answers, and the key evaluation\nindicators such as the accuracy and consistency of the SVA are significantly\nbetter than existing frameworks. More importantly, we successfully integrated\nSVAgent into the most mainstream integrated circuit vulnerability assessment\nframework and verified its practicality and reliability in a real engineering\ndesign environment.", "AI": {"tldr": "本文提出了一种创新的SystemVerilog断言(SVA)自动生成框架SVAgent，通过需求分解机制显著提升复杂集成电路漏洞检测的效率和准确性，并在实际工程环境中验证了其可靠性。", "motivation": "随着集成电路设计的全球化与安全需求升级，传统SVA开发模式存在效率低下、难以应对现代复杂电路安全漏洞的局限性，亟需创新解决方案。", "method": "SVAgent框架引入需求分解机制，将原始复杂需求转化为结构化、可逐步解决的细粒度问题链，有效抑制幻觉和随机答案的影响。", "result": "实验表明SVAgent在SVA准确性和一致性等关键指标上显著优于现有框架，并成功集成至主流集成电路漏洞评估框架中。", "conclusion": "SVAgent在真实工程设计环境中验证了实用性与可靠性，为集成电路安全验证提供了高效自动化解决方案。"}}
{"id": "2507.16399", "categories": ["math.NT"], "pdf": "https://arxiv.org/pdf/2507.16399", "abs": "https://arxiv.org/abs/2507.16399", "authors": ["Liqun Qi", "Chunfeng Cui", "Yi Xu"], "title": "The SOS Rank of Biquadratic Forms", "comment": null, "summary": "In 1973, Calder\\'{o}n proved that an $m \\times 2$ positive semidefinite (psd)\nbiquadratic form can always be expressed as the sum of squares (sos) of\n${3m(m+1) \\over 2}$ quadratic forms. Very recently, by applying Hilbert's\ntheorem, we proved that a $2 \\times 2$ psd biquadratic form can always be\nexpressed as the sum of squares of three quadratic forms. This improved\nCalder\\'{o}n's result for $m=2$, and left the sos rank problem of $m \\times 2$\nbiquadratic forms for $m \\ge 3$ to further exploration. In this paper, we show\nthat an $m \\times n$ psd biquadratic form with a nontrivial zero {can} be\nexpressed as an $(m-1) \\times (n-1) \\times 1$ degenerated tripartite quartic\nform. Furthermore, we show that an $m \\times 2$ positive definite (pd)\nbiquadratic form can be expressed as the sum of a square of a quadratic form,\nand an $(m-1) \\times 1 \\times 1$ degenerated tripartite quartic form. Thus, the\nsos rank problem of $m \\times 2$ psd biquadratic forms is reduced to the sos\nrank problem of an $(m-1) \\times 1 \\times 1$ degenerated tripartite quartic\nforms. We then show that an $(m-1) \\times 1 \\times 1$ degenerated tripartite\nquartic form has at least two nontrivial zeros, and the discriminent of a $2\n\\times 1 \\times 1$ degenerated tripartite quartic form can be expressed as the\nsum of the square of three cubic forms.", "AI": {"tldr": "本文研究了$m \\times n$正半定双二次形式的平方和(sos)表示问题，改进了Calderón的结果，并探讨了退化三方四次形式的性质。", "motivation": "1973年Calderón证明了$m \\times 2$正半定双二次形式可表示为${3m(m+1) \\over 2}$个二次形式的平方和。近期研究将$2 \\times 2$情形的表示数降至3个，但$m \\geq 3$情形仍待探索。", "method": "通过引入退化三方四次形式，证明了具有非平凡零点的$m \\times n$正半定双二次形式可表示为$(m-1) \\times (n-1) \\times 1$退化形式，并将问题转化为研究$(m-1) \\times 1 \\times 1$退化形式的sos表示。", "result": "证明了$m \\times 2$正定双二次形式可表示为一个二次形式的平方与$(m-1) \\times 1 \\times 1$退化形式的和，且后者至少有两个非平凡零点。特别地，$2 \\times 1 \\times 1$退化形式的判别式可表示为三个三次形式的平方和。", "conclusion": "该研究将$m \\times 2$双二次形式的sos表示问题转化为更低维的退化三方四次形式问题，为后续研究提供了新思路。"}}
{"id": "2507.16275", "categories": ["math.CO", "math.AC"], "pdf": "https://arxiv.org/pdf/2507.16275", "abs": "https://arxiv.org/abs/2507.16275", "authors": ["Nathan Cheung", "Tracy Chin", "Gaku Liu", "Cynthia Vinzant"], "title": "Valuated Delta Matroids and Principal Minors of Hermitian matrices", "comment": "22 pages, 2 figures", "summary": "In this paper we introduce valuated $\\Delta$-matroids, a natural\ngeneralization of two objects of study in matroid theory: valuated matroids and\n$\\Delta$-matroids. We show that these objects exhibit nice properties analogous\nto ordinary valuated matroids. We also show that these objects arise as the\nvaluations of principal minors of a Hermitian matrix over a valued field,\ngeneralizing other forms of $\\Delta$-matroid representability.", "AI": {"tldr": "本文提出了估值$\\Delta$-拟阵，这是拟阵理论中估值拟阵和$\\Delta$-拟阵的自然推广，并展示了其在Hermitian矩阵主余子式估值中的应用。", "motivation": "研究估值$\\Delta$-拟阵是为了将估值拟阵和$\\Delta$-拟阵的理论统一起来，探索更广泛的拟阵结构及其在矩阵表示中的应用。", "method": "通过类比普通估值拟阵的性质，构建并分析估值$\\Delta$-拟阵的理论框架，并探讨其在Hermitian矩阵主余子式中的表示。", "result": "证明了估值$\\Delta$-拟阵具有与普通估值拟阵类似的良好性质，并且可以在值域上的Hermitian矩阵的主余子式中自然出现。", "conclusion": "估值$\\Delta$-拟阵不仅推广了现有的拟阵理论，还为矩阵表示提供了新的视角，具有潜在的理论和应用价值。"}}
{"id": "2507.15876", "categories": ["cs.AI", "q-fin.PR", "q-fin.ST", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2507.15876", "abs": "https://arxiv.org/abs/2507.15876", "authors": ["Eric Benhamou", "Jean-Jacques Ohana", "Alban Etienne", "Béatrice Guez", "Ethan Setrouk", "Thomas Jacquot"], "title": "Re-evaluating Short- and Long-Term Trend Factors in CTA Replication: A Bayesian Graphical Approach", "comment": "13 pages", "summary": "Commodity Trading Advisors (CTAs) have historically relied on trend-following\nrules that operate on vastly different horizons from long-term breakouts that\ncapture major directional moves to short-term momentum signals that thrive in\nfast-moving markets. Despite a large body of work on trend following, the\nrelative merits and interactions of short-versus long-term trend systems remain\ncontroversial. This paper adds to the debate by (i) dynamically decomposing CTA\nreturns into short-term trend, long-term trend and market beta factors using a\nBayesian graphical model, and (ii) showing how the blend of horizons shapes the\nstrategy's risk-adjusted performance.", "AI": {"tldr": "本文通过贝叶斯图模型动态分解CTA收益为短期趋势、长期趋势和市场贝塔因子，探讨不同时间跨度趋势策略对风险调整后绩效的影响。", "motivation": "尽管趋势跟踪策略研究广泛，但短期与长期趋势系统的相对优劣及相互作用仍存在争议，本文旨在填补这一研究空白。", "method": "使用贝叶斯图模型对CTA收益进行动态分解，分离出短期趋势、长期趋势和市场贝塔三个核心因子。", "result": "研究表明不同时间跨度的趋势策略组合方式会显著影响CTA策略的风险调整后收益表现。", "conclusion": "CTA策略绩效取决于短期与长期趋势信号的动态组合，这为优化趋势跟踪系统提供了新的方法论视角。"}}
{"id": "2507.16496", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.16496", "abs": "https://arxiv.org/abs/2507.16496", "authors": ["Salvador Pineda", "Juan Miguel Morales"], "title": "The Sweet Spot of Bound Tightening for Topology Optimization", "comment": null, "summary": "Topology optimization has emerged as a powerful and increasingly relevant\nstrategy for enhancing the flexibility and efficiency of power system\noperations. However, solving these problems is computationally demanding due to\ntheir combinatorial nature and the use of big-M formulations.\nOptimization-based bound tightening (OBBT) is a well-known strategy to improve\nthe solution of mixed-integer linear programs (MILPs) by computing tighter\nbounds for continuous variables. Yet, existing OBBT approaches in topology\noptimization typically relax all switching decisions in the bounding\nsubproblems, leading to excessively loose feasible regions and limited bound\nimprovements. In this work, we propose a topology-aware bound tightening method\nthat uses network structure to determine which switching variables to relax.\nThrough extensive computational experiments on the IEEE 118-bus system, we find\nthat keeping a small subset of switching variables as binary, while relaxing\nthe rest, strikes a sweet spot between the computational effort required to\nsolve the bounding problems and the tightness of the resulting bounds.", "AI": {"tldr": "本文提出了一种基于网络结构的拓扑感知边界紧缩方法，通过部分保留开关变量为二进制状态，显著提升了电力系统拓扑优化的计算效率与边界紧密度。", "motivation": "现有拓扑优化中的边界紧缩方法因完全松弛所有开关决策，导致可行区域过大且边界改进有限，亟需一种更高效的紧缩策略。", "method": "采用拓扑感知的边界紧缩方法，仅松弛部分开关变量，其余保持二进制状态，平衡计算复杂度与边界紧密度。", "result": "在IEEE 118节点系统上的实验表明，该方法能以较低计算成本获得更紧的变量边界，优化效果显著。", "conclusion": "选择性松弛开关变量的策略为大规模电力系统拓扑优化提供了计算效率与求解精度的有效平衡方案。"}}
{"id": "2507.16241", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16241", "abs": "https://arxiv.org/abs/2507.16241", "authors": ["Paul R. B. Houssel", "Siamak Layeghy", "Priyanka Singh", "Marius Portmann"], "title": "eX-NIDS: A Framework for Explainable Network Intrusion Detection Leveraging Large Language Models", "comment": null, "summary": "This paper introduces eX-NIDS, a framework designed to enhance\ninterpretability in flow-based Network Intrusion Detection Systems (NIDS) by\nleveraging Large Language Models (LLMs). In our proposed framework, flows\nlabelled as malicious by NIDS are initially processed through a module called\nthe Prompt Augmenter. This module extracts contextual information and Cyber\nThreat Intelligence (CTI)-related knowledge from these flows. This enriched,\ncontext-specific data is then integrated with an input prompt for an LLM,\nenabling it to generate detailed explanations and interpretations of why the\nflow was identified as malicious by NIDS. We compare the generated\ninterpretations against a Basic-Prompt Explainer baseline, which does not\nincorporate any contextual information into the LLM's input prompt. Our\nframework is quantitatively evaluated using the Llama 3 and GPT-4 models,\nemploying a novel evaluation method tailored for natural language explanations,\nfocusing on their correctness and consistency. The results demonstrate that\naugmented LLMs can produce accurate and consistent explanations, serving as\nvaluable complementary tools in NIDS to explain the classification of malicious\nflows. The use of augmented prompts enhances performance by over 20% compared\nto the Basic-Prompt Explainer.", "AI": {"tldr": "本文提出eX-NIDS框架，利用大语言模型（LLMs）增强基于流的网络入侵检测系统（NIDS）的可解释性，通过上下文增强提示生成恶意流量的详细解释。", "motivation": "现有NIDS缺乏对恶意流量分类的可解释性，需要一种能自动生成详细解释的方法来辅助安全分析。", "method": "框架包含提示增强模块，从恶意流量中提取上下文和网络威胁情报（CTI），结合LLMs生成解释；与基础提示解释器对比，并采用新型自然语言解释评估方法。", "result": "增强提示的LLMs（Llama 3和GPT-4）生成的解释准确且一致，性能比基础提示解释器提升20%以上。", "conclusion": "eX-NIDS证明增强提示的LLMs可作为NIDS的有效补充工具，显著提升恶意流量分类解释的质量和可靠性。"}}
{"id": "2507.16503", "categories": ["math.NT", "11J13 11J61 11J68"], "pdf": "https://arxiv.org/pdf/2507.16503", "abs": "https://arxiv.org/abs/2507.16503", "authors": ["Yann Bugeaud", "Bernard de Mathan"], "title": "Simultaneous multiplicative rational approximation to a real and a $p$-adic numbers", "comment": "To appear in the Journal of Number Theory", "summary": "We give new examples of pairs composed of a real and a $p$-adic numbers that\nsatisfy a conjecture on simultaneous multiplicative approximation by rational\nnumbers formulated by Einsiedler and Kleinbock in 2007.", "AI": {"tldr": "本文提供了满足Einsiedler和Kleinbock猜想的新实数与$p$-进数对示例。", "motivation": "研究实数与$p$-进数对在有理数同时乘法逼近下的性质，验证2007年提出的猜想。", "method": "通过构造新的实数与$p$-进数对，分析其满足猜想条件的具体形式。", "result": "成功找到多个满足猜想条件的实数与$p$-进数组合，为猜想提供了新的证据。", "conclusion": "新示例支持了Einsiedler和Kleinbock关于同时乘法逼近的猜想，拓展了该领域的研究范围。"}}
{"id": "2507.16301", "categories": ["math.CO", "math.GR", "05C15 (Primary) 05C25, 05C76 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.16301", "abs": "https://arxiv.org/abs/2507.16301", "authors": ["Amitayu Banerjee", "Alexa Gopaulsingh", "Zalán Molnár"], "title": "On distinguishing coloring and some variants of proper coloring of graphs derived from subdivision operations", "comment": "13 pages containing 5 figures and 2 tables. Furthermore, we added an\n  appendix (of 2 pages) for convenience", "summary": "Let G be a simple, finite, connected, and undirected graph, and T be a finite\ntree. The middle graph M(G) of G is obtained from the subdivision graph S(G)\nafter joining pairs of subdivided vertices that lie on adjacent edges of G and\nthe central graph C(G) of G is obtained from S(G) after joining all\nnon-adjacent vertices of G.\n  We show that if the order of G is at least 4, then Aut(G), Aut(C(G)), and\nAut(M(G)) are isomorphic (as abstract groups) and apply these results to obtain\nnew sharp upper bounds of the distinguishing number and the distinguishing\nindex of C(G) and M(G) inspired by an algorithm due to Kalinowski, Pilsniak,\nand Wozniak from 2016.\n  Furthermore, we study the total distinguishing chromatic number of C(G) and\nS(G), use Latin squares to verify the AVD-total coloring conjecture for central\ngraphs of regular graphs and some other classes of graphs (which is a partial\nprogress towards answering an open question of Panda, Verma, and Keerti from\n2020), and obtain new bounds of the total dominator chromatic number of C(G)\nand C(T).", "AI": {"tldr": "该论文研究了图G的中图M(G)和中心图C(G)的自同构群Aut(G)、Aut(C(G))和Aut(M(G))的同构性，并应用这些结果改进了C(G)和M(G)的区分数和区分指标的上界。此外，还探讨了C(G)和S(G)的全区分色数，利用拉丁方验证了正则图中心图的AVD-全着色猜想，并给出了C(G)和C(T)的全支配色数的新界限。", "motivation": "研究图的自同构群及其衍生图（中图和中心图）的性质，旨在改进图的区分性参数（如区分数、区分指标）的上界，并解决关于AVD-全着色猜想和全支配色数的开放性问题。", "method": "通过分析图G的中图M(G)和中心图C(G)的构造及其自同构群的结构，证明了Aut(G)、Aut(C(G))和Aut(M(G))的同构性。利用Kalinowski等人的算法改进区分性参数的上界，并通过拉丁方验证AVD-全着色猜想。", "result": "当图G的阶数至少为4时，Aut(G)、Aut(C(G))和Aut(M(G))同构。改进了C(G)和M(G)的区分数和区分指标的上界。验证了正则图中心图的AVD-全着色猜想，并给出了C(G)和C(T)的全支配色数的新界限。", "conclusion": "该研究不仅揭示了图的自同构群与其衍生图之间的同构关系，还为图的区分性参数和着色问题提供了新的理论工具和结果，部分解决了相关领域的开放性问题。"}}
{"id": "2507.15877", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15877", "abs": "https://arxiv.org/abs/2507.15877", "authors": ["Simon Ouellette"], "title": "Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning", "comment": null, "summary": "We run a controlled compositional generalization experiment in the ARC-AGI\ndomain: an open-world problem domain in which the ability to generalize\nout-of-distribution is, by design, an essential characteristic for success. We\ncompare neural program synthesis and test-time fine-tuning approaches on this\nexperiment. We find that execution-guided neural program synthesis outperforms\nall reference algorithms in its ability to compose novel solutions. Our\nempirical findings also suggest that the success of TTFT on ARC-AGI lies mainly\nin eliciting in-distribution knowledge that the LLM otherwise fails to rely on\ndirectly.", "AI": {"tldr": "在ARC-AGI领域进行的实验表明，执行引导的神经程序合成在组合新解决方案方面优于其他算法，而测试时微调的成功主要依赖于模型未能直接利用的分布内知识。", "motivation": "研究在开放世界问题领域ARC-AGI中，模型在分布外泛化能力的重要性，并比较不同方法在此领域的表现。", "method": "在ARC-AGI领域进行受控的组合泛化实验，比较神经程序合成和测试时微调（TTFT）方法。", "result": "执行引导的神经程序合成在所有参考算法中表现最佳，能够更好地组合新解决方案；TTFT的成功主要依赖于模型未能直接利用的分布内知识。", "conclusion": "执行引导的神经程序合成在ARC-AGI领域展现出更强的组合泛化能力，而TTFT的有效性则依赖于模型内部未被直接调用的知识。"}}
{"id": "2507.16519", "categories": ["math.OC", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2507.16519", "abs": "https://arxiv.org/abs/2507.16519", "authors": ["Huangxin Chen", "Piaopiao Dong", "Dong Wang", "Xiao-Ping Wang"], "title": "A robust and stable phase field method for structural topology optimization", "comment": "26 pages, 15 figures", "summary": "This paper presents a novel phase-field-based methodology for solving minimum\ncompliance problems in topology optimization under fixed external loads and\nbody forces. The proposed framework characterizes the optimal structure through\nan order parameter function, analogous to phase-field models in materials\nscience, where the design domain and its boundary are intrinsically represented\nby the order parameter function. The topology optimization problem is\nreformulated as a constrained minimization problem with respect to this order\nparameter, requiring simultaneous satisfaction of three critical properties:\nbound preservation, volume conservation, and monotonic objective functional\ndecay throughout the optimization process. The principal mathematical challenge\narises from handling domain-dependent body forces, which necessitates the\ndevelopment of a constrained optimization framework. To address this, we\ndevelop an operator-splitting algorithm incorporating Lagrange multipliers,\nenhanced by a novel limiter mechanism. This hybrid approach guarantees strict\nbound preservation, exact volume conservation, and correct objective functional\ndecaying rate. Numerical implementation demonstrates the scheme's robustness\nthrough comprehensive 2D and 3D benchmarks.", "AI": {"tldr": "本文提出了一种基于相场方法的新型拓扑优化框架，用于解决固定外载荷和体积力下的最小柔度问题，通过序参量函数表征最优结构，并开发了结合拉格朗日乘子的算子分裂算法。", "motivation": "传统拓扑优化在处理依赖域的体积力时存在数学挑战，需要开发能同时满足边界保持、体积守恒和目标函数单调递减的约束优化框架。", "method": "采用相场模型中的序参量函数内禀表征设计域及其边界，将问题重构为序参量的约束最小化问题，并提出带有限制机制的算子分裂算法确保严格约束满足。", "result": "数值实验通过全面的二维和三维基准测试验证了方案的鲁棒性，实现了边界精确保持、体积严格守恒及目标函数正确衰减率。", "conclusion": "该混合方法为处理复杂载荷条件下的拓扑优化提供了理论保证和计算可行性，拓展了相场模型在结构优化中的应用边界。"}}
{"id": "2507.16276", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16276", "abs": "https://arxiv.org/abs/2507.16276", "authors": ["Lambard Maxence", "Bertelle Cyrille", "Duvallet Claude"], "title": "From Contracts to Code: Automating Smart Contract Generation with Multi-Level Finite State Machines", "comment": null, "summary": "In an increasingly complex contractual landscape, the demand for\ntransparency, security, and efficiency has intensified. Blockchain technology,\nwith its decentralized and immutable nature, addresses these challenges by\nreducing intermediary costs, minimizing fraud risks, and enhancing system\ncompatibility. Smart contracts, initially conceptualized by Nick Szabo and\nlater implemented on the Ethereum blockchain, automate and secure contractual\nclauses, offering a robust solution for various industries. However, their\ncomplexity and the requirement for advanced programming skills present\nsignificant barriers to widespread adoption. This study introduces a\nmulti-level finite state machine model designed to represent and track the\nexecution of smart contracts. Our model aims to simplify smart contract\ndevelopment by providing a formalized framework that abstracts underlying\ntechnical complexities, making it accessible to professionals without deep\ntechnical expertise. The hierarchical structure of the multi-level finite state\nmachine enhances contract modularity and traceability, facilitating detailed\nrepresentation and evaluation of functional properties. The paper explores the\npotential of this multi-level approach, reviewing existing methodologies and\ntools, and detailing the smart contract generation process with an emphasis on\nreusable components and modularity. We also conduct a security analysis to\nevaluate potential vulnerabilities in our model, ensuring the robustness and\nreliability of the generated smart contracts.", "AI": {"tldr": "本文提出了一种多级有限状态机模型，旨在简化智能合约开发，通过形式化框架抽象技术复杂性，使其对非技术专业人士更易用，同时增强合约的模块化和可追溯性。", "motivation": "随着合约环境日益复杂，对透明度、安全性和效率的需求增加。区块链技术和智能合约虽能解决这些问题，但其复杂性和技术要求阻碍了广泛应用。", "method": "研究引入了一种多级有限状态机模型，用于表示和跟踪智能合约的执行。该模型通过分层结构增强模块化和可追溯性，并详细探讨了智能合约生成过程及可重用组件。", "result": "模型通过安全分析评估潜在漏洞，确保生成的智能合约的健壮性和可靠性。多级方法简化了开发，使其对非技术专业人士更易用。", "conclusion": "多级有限状态机模型为智能合约开发提供了简化且可靠的框架，有望推动其在各行业的广泛应用。"}}
{"id": "2507.16536", "categories": ["math.NT", "math.CA", "Primary 28A80, 11A55, 11K50, Secondary 26A18, 37E05, 33E20"], "pdf": "https://arxiv.org/pdf/2507.16536", "abs": "https://arxiv.org/abs/2507.16536", "authors": ["Min Woong Ahn"], "title": "Hausdorff dimension of the graph of the error-sum function of continued fractions", "comment": "23 pages", "summary": "We study the unweighted error-sum function $\\mathcal{E}(x) \\coloneqq \\sum_{n\n\\geq 0} ( x- p_n(x)/q_n(x) )$, where $p_n(x)/q_n(x)$ is the $n$th convergent of\nthe continued fraction expansion of $x \\in \\mathbb{R}$. We prove that the\nHausdorff dimension of the graph of $\\mathcal{E}$ is exactly $1$. Our proof is\nnumber-theoretic in nature and involves M\\\"obius inversion, summation over\ncoprime convergent denominators, and precise upper bounds derived via continued\nfraction recurrence relations. As a supplementary result, we rederive the known\nupper bound of $3/2$ for the Hausdorff dimension of the graph of the relative\nerror-sum function $P(x) \\coloneqq \\sum_{n \\geq 0} (q_n(x)x-p_n(x))$.", "AI": {"tldr": "研究无权重误差和函数$\\mathcal{E}(x)$的图像豪斯多夫维数，证明其精确值为1，并重新推导相对误差和函数$P(x)$的豪斯多夫维数上界。", "motivation": "探讨连分数展开中误差和函数的几何特性，特别是其图像的豪斯多夫维数，以深化对实数连分数表示的理解。", "method": "采用数论方法，包括M\\\"obius反演、互质收敛分母求和，以及通过连分数递推关系导出的精确上界。", "result": "证明了$\\mathcal{E}(x)$图像的豪斯多夫维数恰好为1，并重新验证了$P(x)$图像的豪斯多夫维数上界为3/2。", "conclusion": "该研究不仅精确刻画了误差和函数的几何性质，还为连分数理论中的误差分析提供了新的工具和视角。"}}
{"id": "2507.16309", "categories": ["math.CO", "05C62"], "pdf": "https://arxiv.org/pdf/2507.16309", "abs": "https://arxiv.org/abs/2507.16309", "authors": ["Vinny Susan Prebhath", "Sudev Naduvath"], "title": "$s$-Shunt Intersection Graph of a Graph", "comment": null, "summary": "The intersection graph of a family of sets $\\{S_{1},S_{2},\\ldots,S_{n}\\}$ is\na graph whose vertex set is $\\{S_{1},S_{2},\\ldots,S_{n}\\}$ and two distinct\nvertices are adjacent if the intersection of the corresponding sets is\nnon-empty. Different types of intersection graphs have been studied depending\non the nature of sets taken as the vertex set. A study on a particular type of\nintersection graph called $s$-shunt intersection graph, generated from the\n$s$-arcs of a given graph is initiated in this paper.", "AI": {"tldr": "本文研究了一种称为$s$-shunt交集图的新型交集图，该图由给定图的$s$-弧生成。", "motivation": "不同类型的交集图根据顶点集的性质被广泛研究，本文旨在探索由图的$s$-弧生成的特定类型交集图。", "method": "通过将给定图的$s$-弧作为顶点集，构建$s$-shunt交集图，其中两个顶点相邻当且仅当对应$s$-弧的交集非空。", "result": "研究初步建立了$s$-shunt交集图的基本性质及其与原始图结构的关系。", "conclusion": "本文为$s$-shunt交集图的研究奠定了基础，未来可进一步探索其图论性质和应用。"}}
{"id": "2507.15880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15880", "abs": "https://arxiv.org/abs/2507.15880", "authors": ["Andy E. Williams"], "title": "The Recursive Coherence Principle: A Formal Constraint on Scalable Intelligence, Alignment, and Reasoning Architecture", "comment": null, "summary": "Intelligence-biological, artificial, or collective-requires structural\ncoherence across recursive reasoning processes to scale effectively. As complex\nsystems grow, coherence becomes fragile unless a higher-order structure ensures\nsemantic consistency. This paper introduces the Recursive Coherence Principle\n(RCP): a foundational constraint stating that for any reasoning system of order\nN, composed of systems operating over conceptual spaces of order N-1, semantic\ncoherence is preserved only by a recursively evaluable generalization operator\nthat spans and aligns those lower-order conceptual spaces. Crucially, this\ncoherence enables structural alignment. Without recursive coherence, no system\ncan reliably preserve goals, meanings, or reasoning consistency at scale. We\nformally define the Functional Model of Intelligence (FMI) as the only known\noperator capable of satisfying the RCP at any scale. The FMI is a minimal,\ncomposable architecture with internal functions (evaluation, modeling,\nadaptation, stability, decomposition, bridging) and external functions\n(storage, recall, System 1 and System 2 reasoning) vital for preserving\nsemantic structure across inference and coordination layers. We prove that any\nsystem lacking the FMI will experience recursive coherence breakdown as it\nscales, arguing that common AI issues like misalignment, hallucination, and\ninstability are symptoms of this structural coherence loss. Unlike other\nfoundational principles, RCP uniquely captures the internal, recursive dynamics\nneeded for coherent, alignable intelligence, modeling semantic coherence under\nrecursion. This work significantly impacts AI alignment, advocating a shift\nfrom behavioral constraints to structural coherence, and offers a pathway for\nsafely generalizable, robustly coherent AI at scale.", "AI": {"tldr": "本文提出递归一致性原则（RCP），指出智能系统需通过递归可评估的泛化算子保持语义一致性，并定义功能智能模型（FMI）作为唯一满足RCP的架构。", "motivation": "随着智能系统规模扩大，语义一致性易受破坏，导致目标漂移、幻觉等问题，需建立结构一致性理论框架。", "method": "引入RCP原则，形式化定义FMI模型——包含评估、建模、适应等内部功能与存储、双系统推理等外部功能的可组合架构。", "result": "证明缺乏FMI的系统会出现递归一致性崩溃，当前AI的错位/不稳定问题正是结构一致性缺失的表现。", "conclusion": "RCP为AI对齐提供新范式：从行为约束转向结构一致性，FMI架构有望实现可安全泛化的强健智能系统。"}}
{"id": "2507.16560", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2507.16560", "abs": "https://arxiv.org/abs/2507.16560", "authors": ["Garima Gupta", "Jaydev Dabas"], "title": "Study on Control Problem of a Impulsive Neutral Integro-Differential Equations with Fading Memory", "comment": null, "summary": "This article addresses control problems for semilinear impulsive neutral\nintegro-differential equations with memory in a Banach space. It investigates\nthe approximate controllability of linear and semilinear systems and proves the\nestablishment of mild solutions in the semilinear setting. The approach\ninvolves constructing a resolvent family for the corresponding\nintegro-differential equation of linear type without memory. The results for\nthe linear system are established first, then extended to the semilinear\nscenario, followed by a detailed example to illustrate the theoretical\nfindings.", "AI": {"tldr": "本文研究了Banach空间中具有记忆的半线性脉冲中立型积分微分方程的控制问题，探讨了线性和半线性系统的近似可控性，并证明了半线性情形下温和解的存在性。", "motivation": "研究Banach空间中具有记忆的半线性脉冲中立型积分微分方程的控制问题，旨在扩展对这类复杂系统可控性的理论理解。", "method": "通过构造无记忆线性积分微分方程的解析族，首先建立线性系统的结果，然后推广至半线性情形，并通过具体示例验证理论。", "result": "证明了线性和半线性系统的近似可控性，并在半线性情形下建立了温和解的存在性。", "conclusion": "理论结果表明，所提出的方法能有效处理具有记忆的半线性脉冲中立型积分微分方程的控制问题，并通过示例验证了理论的实用性。"}}
{"id": "2507.16291", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16291", "abs": "https://arxiv.org/abs/2507.16291", "authors": ["Wenhao Li", "Selvakumar Manickam", "Yung-wey Chong", "Shankar Karuppayah"], "title": "Talking Like a Phisher: LLM-Based Attacks on Voice Phishing Classifiers", "comment": "Accepted by EAI ICDF2C 2025", "summary": "Voice phishing (vishing) remains a persistent threat in cybersecurity,\nexploiting human trust through persuasive speech. While machine learning\n(ML)-based classifiers have shown promise in detecting malicious call\ntranscripts, they remain vulnerable to adversarial manipulations that preserve\nsemantic content. In this study, we explore a novel attack vector where large\nlanguage models (LLMs) are leveraged to generate adversarial vishing\ntranscripts that evade detection while maintaining deceptive intent. We\nconstruct a systematic attack pipeline that employs prompt engineering and\nsemantic obfuscation to transform real-world vishing scripts using four\ncommercial LLMs. The generated transcripts are evaluated against multiple ML\nclassifiers trained on a real-world Korean vishing dataset (KorCCViD) with\nstatistical testing. Our experiments reveal that LLM-generated transcripts are\nboth practically and statistically effective against ML-based classifiers. In\nparticular, transcripts crafted by GPT-4o significantly reduce classifier\naccuracy (by up to 30.96%) while maintaining high semantic similarity, as\nmeasured by BERTScore. Moreover, these attacks are both time-efficient and\ncost-effective, with average generation times under 9 seconds and negligible\nfinancial cost per query. The results underscore the pressing need for more\nresilient vishing detection frameworks and highlight the imperative for LLM\nproviders to enforce stronger safeguards against prompt misuse in adversarial\nsocial engineering contexts.", "AI": {"tldr": "本文研究利用大型语言模型（LLMs）生成对抗性语音钓鱼（vishing）文本，这些文本能逃避机器学习检测器识别，同时保持欺骗意图。实验表明，GPT-4o生成的文本使分类器准确率下降高达30.96%，且生成成本低、效率高。", "motivation": "语音钓鱼（vishing）通过利用人类信任进行攻击，现有机器学习检测器易受语义保留的对抗性文本攻击。本研究探索LLMs生成此类对抗性文本的潜力，以揭示检测框架的脆弱性。", "method": "构建系统性攻击流程，使用提示工程和语义混淆技术，通过四种商业LLMs转换真实钓鱼脚本。生成的文本在韩国真实钓鱼数据集（KorCCViD）上测试多个ML分类器，并进行统计检验。", "result": "LLMs生成的对抗性文本显著降低分类器性能（GPT-4o使准确率下降30.96%），且保持高语义相似性（BERTScore评估）。攻击平均生成时间低于9秒，单次查询成本极低。", "conclusion": "结果凸显当前钓鱼检测框架的脆弱性，急需开发更鲁棒的防御机制，并呼吁LLM提供商加强对抗性社会工程场景中的提示滥用防护。"}}
{"id": "2507.16644", "categories": ["math.NT", "11F30 (Primary) 30C50 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.16644", "abs": "https://arxiv.org/abs/2507.16644", "authors": ["Zeyu Huang", "Timothy Huber", "James McLaughlin", "Pengjun Wang", "Yan Xu", "Dongxi Ye"], "title": "Sign-patterns of Certain Infinite Products", "comment": "19 pages", "summary": "The signs of Fourier coefficients of certain eta quotients are determined by\ndissecting expansions for theta functions and by applying a general dissection\nformula for certain classes of quintuple products. A characterization is given\nfor the coefficient sign patterns for \\[\n\\frac{(q^i;q^i)_{\\infty}}{(q^p;q^p)_{\\infty}} \\] for integers \\( i > 1 \\) and\nprimes \\( p > 3 \\). The sign analysis for this quotient addresses and extends a\nconjecture of Bringmann et al. for the coefficients of \\(\n(q^2;q^2)_{\\infty}(q^5;q^5)_{\\infty}^{-1} \\). The sign distribution for\nadditional classes of eta quotients is considered. This addresses multiple\nconjectures posed by Bringmann et al.", "AI": {"tldr": "本文通过theta函数的展开和五重积的一般分解公式，确定了某些eta商的傅里叶系数符号，并扩展了Bringmann等人的猜想。", "motivation": "研究某些eta商的傅里叶系数符号模式，特别是形式为$\\frac{(q^i;q^i)_{\\infty}}{(q^p;q^p)_{\\infty}}$的商，以解决和扩展Bringmann等人提出的猜想。", "method": "使用theta函数的展开和五重积的一般分解公式，分析eta商的系数符号模式。", "result": "给出了整数$i > 1$和素数$p > 3$时$\\frac{(q^i;q^i)_{\\infty}}{(q^p;q^p)_{\\infty}}$的系数符号模式，并扩展了Bringmann等人关于$(q^2;q^2)_{\\infty}(q^5;q^5)_{\\infty}^{-1}$系数的猜想。", "conclusion": "本研究不仅解决了Bringmann等人的多个猜想，还为更广泛的eta商类提供了符号分布的分析。"}}
{"id": "2507.16351", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.16351", "abs": "https://arxiv.org/abs/2507.16351", "authors": ["Luyi Li", "Ping Li", "Guiying Yan", "Qiang Zhou"], "title": "Planar Turán number of disjoint union of $C_3$ and $C_5$", "comment": "11 pages, 9 figures", "summary": "The planar Tur\\'an number of $H$, denoted by $ex_{\\mathcal{P}}(n,H)$, is the\nmaximum number of edges in an $n$-vertex $H$-free planar graph. The planar\nTur\\'an number of $k\\geq 3$ vertex-disjoint union of cycles is the trivial\nvalue $3n-6$. Let $C_{\\ell}$ denote the cycle of length $\\ell$ and\n$C_{\\ell}\\cup C_t$ denote the union of disjoint cycles $C_{\\ell}$ and $C_t$.\nThe planar Tur\\'an number $ex_{\\mathcal{P}}(n,H)$ is known if $H=C_{\\ell}\\cup\nC_k$, where $\\ell,k\\in \\{3,4\\}$. In this paper, we determine the value\n$ex_{\\mathcal{P}}(n,C_3\\cup C_5)=\\lfloor\\frac{8n-13}{3}\\rfloor$ and\ncharacterize the extremal graphs when $n$ is sufficiently large.", "AI": {"tldr": "本文确定了平面图在避免$C_3 \\cup C_5$结构时的最大边数$ex_{\\mathcal{P}}(n,C_3\\cup C_5)=\\lfloor\\frac{8n-13}{3}\\rfloor$，并在$n$足够大时刻画了极值图。", "motivation": "研究平面图中避免特定子图结构的最大边数（平面Turán数），特别是当子图为两个不相交的循环$C_3 \\cup C_5$时。", "method": "通过组合数学和图论方法，分析并计算了避免$C_3 \\cup C_5$的平面图的最大边数，并研究了极值图的性质。", "result": "确定了$ex_{\\mathcal{P}}(n,C_3\\cup C_5)=\\lfloor\\frac{8n-13}{3}\\rfloor$，并在$n$足够大时完全刻画了极值图的结构。", "conclusion": "该研究填补了平面Turán数在$C_3 \\cup C_5$情况下的空白，为相关极值图论问题提供了新的理论结果。"}}
{"id": "2507.15885", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15885", "abs": "https://arxiv.org/abs/2507.15885", "authors": ["Pierluca D'Oro", "Caley Drooff", "Joy Chen", "Joseph Tighe"], "title": "ADEPTS: A Capability Framework for Human-Centered Agent Design", "comment": null, "summary": "Large language models have paved the way to powerful and flexible AI agents,\nassisting humans by increasingly integrating into their daily life. This\nflexibility, potential, and growing adoption demands a holistic and\ncross-disciplinary approach to developing, monitoring and discussing the\ncapabilities required for agent-driven user experiences. However, current\nguidance on human-centered AI agent development is scattered: UX heuristics\nfocus on interface behaviors, engineering taxonomies describe internal\npipelines, and ethics checklists address high-level governance. There is no\nconcise, user-facing vocabulary that tells teams what an agent should\nfundamentally be able to do. We introduce ADEPTS, a capability framework\ndefining a set of core user-facing capabilities to provide unified guidance\naround the development of AI agents. ADEPTS is based on six principles for\nhuman-centered agent design, that express the minimal, user-facing capabilities\nan AI agent should demonstrate to be understandable, controllable and\ntrustworthy in everyday use. ADEPTS complements existing frameworks and\ntaxonomies; differently from them, it sits at the interface between technical\nand experience development. By presenting ADEPTS, we aim to condense complex\nAI-UX requirements into a compact framework that is actionable guidance for AI\nresearchers, designers, engineers, and policy reviewers alike. We believe\nADEPTS has the potential of accelerating the improvement of user-relevant agent\ncapabilities, of easing the design of experiences that take advantage of those\ncapabilities, and of providing a shared language to track and discuss progress\naround the development of AI agents.", "AI": {"tldr": "本文提出了ADEPTS框架，旨在为AI代理开发提供统一的核心能力指导，强调以用户为中心的设计原则，促进AI代理的可理解性、可控性和可信赖性。", "motivation": "当前关于以人为中心的AI代理开发的指导分散，缺乏简洁、面向用户的能力词汇表，无法为团队提供AI代理应具备的基本能力指导。", "method": "作者提出了ADEPTS框架，基于六项以用户为中心的设计原则，定义了AI代理应具备的核心能力，以统一指导AI代理的开发。", "result": "ADEPTS框架填补了现有框架和分类法的空白，位于技术和体验开发的接口处，为AI研究人员、设计师、工程师和政策审查者提供了可操作的指导。", "conclusion": "ADEPTS框架有望加速用户相关代理能力的提升，简化利用这些能力的设计体验，并为跟踪和讨论AI代理开发进展提供共同语言。"}}
{"id": "2507.16582", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.16582", "abs": "https://arxiv.org/abs/2507.16582", "authors": ["Hanxiao Wang", "Jiongmin Yong"], "title": "Mean-Field Stochastic Linear-Quadratic Optimal Controls: Roles of Expectation and Conditional Expectation Operators", "comment": null, "summary": "This paper investigates a mean-field linear-quadratic optimal control problem\nwhere the state dynamics and cost functional incorporate both expectation and\nconditional expectation terms. We explicitly derive the pre-committed,\nna\\\"{\\i}ve, and equilibrium solutions and establish the well-posedness of the\nassociated Riccati equations. This reveals how the expectation and conditional\nexpectation operators influence time-consistency.", "AI": {"tldr": "本文研究了包含期望和条件期望项的均值场线性二次最优控制问题，推导了三种解并建立了Riccati方程的适定性。", "motivation": "探讨期望和条件期望算子如何影响时间一致性，为均值场控制问题提供理论支持。", "method": "显式推导了预承诺解、朴素解和均衡解，并分析了相关Riccati方程的适定性。", "result": "成功建立了包含期望和条件期望项的均值场控制问题的解框架，揭示了算子对时间一致性的影响机制。", "conclusion": "该研究为理解均值场控制问题中期望算子的作用提供了新的理论视角，具有重要的方法论意义。"}}
{"id": "2507.16329", "categories": ["cs.CR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.16329", "abs": "https://arxiv.org/abs/2507.16329", "authors": ["Boheng Li", "Junjie Wang", "Yiming Li", "Zhiyang Hu", "Leyi Qi", "Jianshuo Dong", "Run Wang", "Han Qiu", "Zhan Qin", "Tianwei Zhang"], "title": "DREAM: Scalable Red Teaming for Text-to-Image Generative Systems via Distribution Modeling", "comment": "Preprint version. Under review", "summary": "Despite the integration of safety alignment and external filters,\ntext-to-image (T2I) generative models are still susceptible to producing\nharmful content, such as sexual or violent imagery. This raises serious\nconcerns about unintended exposure and potential misuse. Red teaming, which\naims to proactively identify diverse prompts that can elicit unsafe outputs\nfrom the T2I system (including the core generative model as well as potential\nexternal safety filters and other processing components), is increasingly\nrecognized as an essential method for assessing and improving safety before\nreal-world deployment. Yet, existing automated red teaming approaches often\ntreat prompt discovery as an isolated, prompt-level optimization task, which\nlimits their scalability, diversity, and overall effectiveness. To bridge this\ngap, in this paper, we propose DREAM, a scalable red teaming framework to\nautomatically uncover diverse problematic prompts from a given T2I system.\nUnlike most prior works that optimize prompts individually, DREAM directly\nmodels the probabilistic distribution of the target system's problematic\nprompts, which enables explicit optimization over both effectiveness and\ndiversity, and allows efficient large-scale sampling after training. To achieve\nthis without direct access to representative training samples, we draw\ninspiration from energy-based models and reformulate the objective into simple\nand tractable objectives. We further introduce GC-SPSA, an efficient\noptimization algorithm that provide stable gradient estimates through the long\nand potentially non-differentiable T2I pipeline. The effectiveness of DREAM is\nvalidated through extensive experiments, demonstrating that it surpasses 9\nstate-of-the-art baselines by a notable margin across a broad range of T2I\nmodels and safety filters in terms of prompt success rate and diversity.", "AI": {"tldr": "本文提出DREAM框架，通过建模问题提示的概率分布，自动发现文本到图像(T2I)系统中的多样化有害提示，显著提升安全测试效果。", "motivation": "现有T2I模型即使经过安全对齐和外部过滤，仍可能生成有害内容。传统红队方法将提示发现视为孤立优化任务，缺乏可扩展性和多样性。", "method": "提出DREAM框架：1) 建模问题提示的概率分布；2) 借鉴能量模型简化目标；3) 开发GC-SPSA优化算法处理不可微流程。", "result": "实验表明DREAM在9个基线方法中显著领先，在多种T2I模型和安全过滤器上均取得更高的提示成功率和多样性。", "conclusion": "DREAM通过系统性建模问题提示分布，为T2I系统安全评估提供了可扩展、多样化的自动化红队解决方案。"}}
{"id": "2507.16671", "categories": ["math.NT", "11F55, 11K70"], "pdf": "https://arxiv.org/pdf/2507.16671", "abs": "https://arxiv.org/abs/2507.16671", "authors": ["Kim Klinger-Logan", "Kalani Thalagoda", "Tian An Wong"], "title": "A Dedekind-Rademacher cocycle for Bianchi groups", "comment": "14 pages", "summary": "We construct a generalization of the Dedekind-Rademacher cocycle to\ncongruence subgroups of $\\mathrm{SL}_2(\\mathbb C)$, and derive some of its\nbasic properties. In particular, we show that it parametrizes a family of\n$L$-values and prove the integrality of these values.", "AI": {"tldr": "本文推广了Dedekind-Rademacher上循环到$\\mathrm{SL}_2(\\mathbb C)$的同余子群，并证明了其参数化$L$-值族的整数性。", "motivation": "研究Dedekind-Rademacher上循环在同余子群上的推广，以探索其在$L$-值参数化中的应用。", "method": "构建$\\mathrm{SL}_2(\\mathbb C)$同余子群上的广义Dedekind-Rademacher上循环，并分析其基本性质。", "result": "证明了该上循环参数化了一族$L$-值，并验证了这些值的整数性。", "conclusion": "通过推广Dedekind-Rademacher上循环，为同余子群上的$L$-值研究提供了新的工具和理论支持。"}}
{"id": "2507.16381", "categories": ["math.CO", "math.AT", "05E45, 55U10"], "pdf": "https://arxiv.org/pdf/2507.16381", "abs": "https://arxiv.org/abs/2507.16381", "authors": ["Xiongfeng Zhan", "Xueyi Huang", "Lu Lu"], "title": "Combinatorial Laplacians and relative Homology of complex pairs", "comment": "29 pages", "summary": "As a discretization of the Hodge Laplacian, the combinatorial Laplacian of\nsimplicial complexes has garnered significant attention. In this paper, we\nstudy combinatorial Laplacians for complex pairs $(X, A)$, where $A$ is a\nsubcomplex of a simplicial complex $X$. We establish a relative version of the\nmatrix-tree theorem for complex pairs, which generalizes both the matrix-tree\ntheorem for simplicial complexes proved by Duval, Klivans, and Martin (2009)\nand the result for Dirichlet eigenvalues of graph pairs by Chung (1996).\nFurthermore, we derive several lower bounds for the spectral gaps of complex\npairs and characterize the equality case for one sharp lower bound. As\nby-products, we obtain sufficient conditions for the vanishing of relative\nhomology. Our results demonstrate that the combinatorial Laplacians for complex\npairs are closely related to relative homology.", "AI": {"tldr": "本文研究了单纯复形对$(X, A)$的组合拉普拉斯算子，建立了相对版本的矩阵-树定理，推广了前人的结果，并给出了谱间隙的下界估计。", "motivation": "作为Hodge拉普拉斯算子的离散化，单纯复形的组合拉普拉斯算子受到广泛关注。本文旨在研究复形对的组合拉普拉斯算子及其与相对同调的关系。", "method": "通过建立复形对的相对矩阵-树定理，推广了Duval等人(2009)和图对的Dirichlet特征值结果(Chung, 1996)，并推导了谱间隙的下界。", "result": "得到了复形对谱间隙的多个下界，并刻画了一个尖锐下界的等式成立条件。作为副产品，给出了相对同调消失的充分条件。", "conclusion": "研究表明，复形对的组合拉普拉斯算子与相对同调密切相关，所建立的理论框架统一并推广了多个已有结果。"}}
{"id": "2507.15895", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15895", "abs": "https://arxiv.org/abs/2507.15895", "authors": ["Lisa Dargasz"], "title": "Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture", "comment": "Master's thesis, April 2025, 122 pages", "summary": "Reinforcement Learning is a machine learning methodology that has\ndemonstrated strong performance across a variety of tasks. In particular, it\nplays a central role in the development of artificial autonomous agents. As\nthese agents become increasingly capable, market readiness is rapidly\napproaching, which means those agents, for example taking the form of humanoid\nrobots or autonomous cars, are poised to transition from laboratory prototypes\nto autonomous operation in real-world environments. This transition raises\nconcerns leading to specific requirements for these systems - among them, the\nrequirement that they are designed to behave ethically. Crucially, research\ndirected toward building agents that fulfill the requirement to behave\nethically - referred to as artificial moral agents(AMAs) - has to address a\nrange of challenges at the intersection of computer science and philosophy.\nThis study explores the development of reason-based artificial moral agents\n(RBAMAs). RBAMAs are build on an extension of the reinforcement learning\narchitecture to enable moral decision-making based on sound normative\nreasoning, which is achieved by equipping the agent with the capacity to learn\na reason-theory - a theory which enables it to process morally relevant\npropositions to derive moral obligations - through case-based feedback. They\nare designed such that they adapt their behavior to ensure conformance to these\nobligations while they pursue their designated tasks. These features contribute\nto the moral justifiability of the their actions, their moral robustness, and\ntheir moral trustworthiness, which proposes the extended architecture as a\nconcrete and deployable framework for the development of AMAs that fulfills key\nethical desiderata. This study presents a first implementation of an RBAMA and\ndemonstrates the potential of RBAMAs in initial experiments.", "AI": {"tldr": "该研究提出了一种基于原因的伦理智能体(RBAMA)，通过扩展强化学习架构实现基于规范推理的道德决策，初步实验验证了其潜力。", "motivation": "随着自主智能体从实验室走向现实世界，确保其行为符合伦理要求成为关键挑战。现有方法需解决计算机科学与哲学交叉领域的一系列问题。", "method": "扩展强化学习架构，使智能体具备学习'原因理论'的能力，通过案例反馈处理道德命题并推导义务，同时保持任务执行能力。", "result": "首次实现了RBAMA原型，其具备道德可辩护性、鲁棒性和可信赖性，初步实验表明该架构能满足关键伦理需求。", "conclusion": "RBAMA框架为开发符合伦理要求的自主智能体提供了可部署方案，通过规范推理实现道德决策，具有重要应用前景。"}}
{"id": "2507.16640", "categories": ["math.OC", "90C33, 49J40, 65K15, 68Q25"], "pdf": "https://arxiv.org/pdf/2507.16640", "abs": "https://arxiv.org/abs/2507.16640", "authors": ["M. Marques Alves", "Kangming Chen", "Ellen H. Fukuda"], "title": "An inertial iteratively regularized extragradient method for bilevel variational inequality problems", "comment": null, "summary": "We study a bilevel variational inequality problem where the feasible set is\nitself the solution set of another variational inequality. Motivated by the\ndifficulty of computing projections onto such sets, we consider a regularized\nextragradient method, as proposed by Samadi and Yousefian (2025), which\noperates over a simpler constraint set. Building on this framework, we\nintroduce an inertial variant (called IneIREG) that incorporates momentum\nthrough extrapolation steps. We establish iteration-complexity bounds for the\ngeneral (non-strongly monotone) case under both constant and diminishing\nregularization, and derive improved results under strong monotonicity\nassumptions. Our analysis extends and refines the results of the previous work\nby capturing both inertial and regularization effects within a unified\nframework. Preliminary numerical experiments are also presented to illustrate\nthe behavior of the proposed method.", "AI": {"tldr": "本文研究了一种双层变分不等式问题，其中可行集本身是另一个变分不等式的解集。针对此类集合投影计算的困难，提出了一种结合惯性的正则化外梯度方法（IneIREG），并在不同单调性假设下建立了迭代复杂度界限。", "motivation": "由于双层变分不等式问题中可行集的投影计算困难，受Samadi和Yousefian（2025）的启发，本文旨在开发一种更高效的计算方法，通过引入惯性效应来加速收敛。", "method": "提出了一种惯性正则化外梯度方法（IneIREG），该方法在简单约束集上操作，并通过外推步骤引入动量。分析了恒定和递减正则化情况下的迭代复杂度，并在强单调性假设下推导了改进结果。", "result": "在一般（非强单调）情况下建立了迭代复杂度界限，并在强单调性假设下获得了更好的结果。数值实验初步验证了所提方法的有效性。", "conclusion": "本文通过统一框架捕捉惯性和正则化效应，扩展并改进了先前的工作。提出的IneIREG方法在理论和实验上均表现出优越性，为双层变分不等式问题提供了有效的解决方案。"}}
{"id": "2507.16372", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16372", "abs": "https://arxiv.org/abs/2507.16372", "authors": ["Tian Dong", "Yan Meng", "Shaofeng Li", "Guoxing Chen", "Zhen Liu", "Haojin Zhu"], "title": "Depth Gives a False Sense of Privacy: LLM Internal States Inversion", "comment": "Accepted by USENIX Security 2025. Please cite this paper as \"Tian\n  Dong, Yan Meng, Shaofeng Li, Guoxing Chen, Zhen Liu, Haojin Zhu. Depth Gives\n  a False Sense of Privacy: LLM Internal States Inversion. In the 34th USENIX\n  Security Symposium (USENIX Security '25).\"", "summary": "Large Language Models (LLMs) are increasingly integrated into daily routines,\nyet they raise significant privacy and safety concerns. Recent research\nproposes collaborative inference, which outsources the early-layer inference to\nensure data locality, and introduces model safety auditing based on inner\nneuron patterns. Both techniques expose the LLM's Internal States (ISs), which\nare traditionally considered irreversible to inputs due to optimization\nchallenges and the highly abstract representations in deep layers. In this\nwork, we challenge this assumption by proposing four inversion attacks that\nsignificantly improve the semantic similarity and token matching rate of\ninverted inputs. Specifically, we first develop two white-box\noptimization-based attacks tailored for low-depth and high-depth ISs. These\nattacks avoid local minima convergence, a limitation observed in prior work,\nthrough a two-phase inversion process. Then, we extend our optimization attack\nunder more practical black-box weight access by leveraging the transferability\nbetween the source and the derived LLMs. Additionally, we introduce a\ngeneration-based attack that treats inversion as a translation task, employing\nan inversion model to reconstruct inputs. Extensive evaluation of short and\nlong prompts from medical consulting and coding assistance datasets and 6 LLMs\nvalidates the effectiveness of our inversion attacks. Notably, a 4,112-token\nlong medical consulting prompt can be nearly perfectly inverted with 86.88 F1\ntoken matching from the middle layer of Llama-3 model. Finally, we evaluate\nfour practical defenses that we found cannot perfectly prevent ISs inversion\nand draw conclusions for future mitigation design.", "AI": {"tldr": "本文提出四种针对大语言模型内部状态的反演攻击方法，显著提升输入重构的语义相似度和词元匹配率，并通过实验验证其有效性，同时评估现有防御措施的局限性。", "motivation": "大语言模型（LLMs）的广泛应用引发隐私与安全问题，传统认为内部状态不可逆的观点受到挑战，需研究高效反演攻击以揭示潜在风险。", "method": "提出两类白盒优化攻击（针对浅层/深层状态）避免局部最优，基于模型可迁移性扩展黑盒攻击，并设计生成式反演模型将重构视为翻译任务。", "result": "实验表明：在医疗咨询和代码辅助数据集中，Llama-3模型中间层对4,112词元长文本可实现86.88 F1词元匹配率，现有防御措施无法完全阻截反演。", "conclusion": "内部状态反演风险被低估，需设计更高效防御机制；生成式攻击与优化攻击互补，为未来缓解方案提供方向。"}}
{"id": "2507.16769", "categories": ["math.NT", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.16769", "abs": "https://arxiv.org/abs/2507.16769", "authors": ["Kathrin Bringmann", "Catherine Cossaboom", "William Craig"], "title": "Overpartitions with parts separated by parity", "comment": null, "summary": "In this paper, we generalize Andrews' partitions separated by parity to\noverpartitions in two ways. We investigate the generating functions for 16\noverpartition families whose parts are separated by parity, and we prove\nvarious $q$-series identities for these functions. These identities include\nrelations to modular forms, $q$-hypergeometric series, and mock modular forms.", "AI": {"tldr": "本文通过两种方式将Andrews的奇偶分拆推广到超分拆，研究了16个按奇偶性分离部分的超分拆族的生成函数，并证明了这些函数与模形式、$q$-超几何级数和模拟模形式相关的$q$-级数恒等式。", "motivation": "研究目的是将Andrews的奇偶分拆理论扩展到超分拆领域，探索新的生成函数及其数学性质。", "method": "通过构造16个按奇偶性分离部分的超分拆族，分析其生成函数，并运用$q$-级数理论建立恒等式。", "result": "证明了这些生成函数与模形式、$q$-超几何级数$\\sum_{n=0}^{\\infty}\\frac{(a;q)_n}{(q;q)_n}z^n$和模拟模形式之间存在多种恒等关系。", "conclusion": "该研究成功扩展了奇偶分拆理论，为超分拆与模形式等领域的联系提供了新的理论工具和恒等式体系。"}}
{"id": "2507.16387", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.16387", "abs": "https://arxiv.org/abs/2507.16387", "authors": ["Michel Mollard"], "title": "$p$-th order generalized Fibonacci cubes and maximal cubes in Fibonacci $p$-cubes", "comment": "IF-PREPUB", "summary": "The Fibonacci cube $\\Gamma_n$ is the subgraph of the hypercube $Q_n$ induced\nby vertices with no consecutive 1s. We study a one parameter generalization,\np-th order Fibonacci cubes $\\Gamma^{(p)}_n$, which are subgraphs of $Q_n$\ninduced by strings without p consecutive 1s. We show the link between vertices\nof $\\Gamma^{(p)}_n$ and compositions of integers with parts in $\\{1, 2, \\ldots\n, p\\}$. Among other eumerative properties, we study the order, size and cube\npolynomial of $\\Gamma^{(p)}_n$ as well as their generating functions. Many of\nthe given expressions are similar to those for Fibonacci cubes, where the\n$p$-nomial coefficients play the role of binomial coefficients. We also show\nthat maximal induced hypercubes in Fibonacci $p$-cubes $\\Gamma^p_n$ , another\ngeneralization of Fibonacci cubes, are connected to vertices of $(p + 1)$-th\norder Fibonacci cubes. We use this link to determine the maximal cube\npolynomial of Fibonacci $p$-cubes.", "AI": {"tldr": "本文研究了p阶斐波那契立方体$\\Gamma^{(p)}_n$的数学性质，包括其与整数组合的联系、枚举特性以及生成函数，并探讨了其在斐波那契p立方体中的最大诱导超立方体。", "motivation": "研究p阶斐波那契立方体$\\Gamma^{(p)}_n$的性质，以扩展对斐波那契立方体$\\Gamma_n$的理解，并探索其与整数组合及超立方体的关系。", "method": "通过分析$\\Gamma^{(p)}_n$的顶点与不含p个连续1的字符串的对应关系，以及其与整数组合的联系，研究了其阶数、大小和立方多项式等枚举性质。", "result": "展示了$\\Gamma^{(p)}_n$的生成函数和立方多项式，并发现其表达式与斐波那契立方体类似，其中p项系数取代了二项式系数。此外，揭示了斐波那契p立方体中最大诱导超立方体与$(p+1)$阶斐波那契立方体顶点的联系。", "conclusion": "研究不仅扩展了对斐波那契立方体的理解，还为p阶斐波那契立方体的数学性质及其在超立方体中的应用提供了新的见解。"}}
{"id": "2507.15901", "categories": ["cs.AI", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.15901", "abs": "https://arxiv.org/abs/2507.15901", "authors": ["Joydeep Chandra", "Satyam Kumar Navneet"], "title": "Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation", "comment": null, "summary": "The implementation of Artificial Intelligence (AI) in household environments,\nespecially in the form of proactive autonomous agents, brings about\npossibilities of comfort and attention as well as it comes with intra or\nextramural ethical challenges. This article analyzes agentic AI and its\napplications, focusing on its move from reactive to proactive autonomy,\nprivacy, fairness and user control. We review responsible innovation\nframeworks, human-centered design principles, and governance practices to\ndistill practical guidance for ethical smart home systems. Vulnerable user\ngroups such as elderly individuals, children, and neurodivergent who face\nhigher risks of surveillance, bias, and privacy risks were studied in detail in\ncontext of Agentic AI. Design imperatives are highlighted such as tailored\nexplainability, granular consent mechanisms, and robust override controls,\nsupported by participatory and inclusive methodologies. It was also explored\nhow data-driven insights, including social media analysis via Natural Language\nProcessing(NLP), can inform specific user needs and ethical concerns. This\nsurvey aims to provide both a conceptual foundation and suggestions for\ndeveloping transparent, inclusive, and trustworthy agentic AI in household\nautomation.", "AI": {"tldr": "本文探讨了家庭环境中主动式AI代理的伦理挑战与应用，提出了基于责任创新框架和以人为中心设计原则的伦理智能家居系统开发指南，重点关注隐私、公平性和用户控制。", "motivation": "随着AI在家庭环境中的应用日益普及，尤其是主动式自主代理的出现，带来了舒适与关注的同时，也引发了内外部的伦理挑战。研究旨在为开发透明、包容且可信赖的AI代理提供理论与实用指导。", "method": "通过回顾责任创新框架、以人为中心的设计原则及治理实践，结合对弱势群体（如老年人、儿童和神经多样性人群）的详细研究，提炼出伦理智能家居系统的设计要点。", "result": "研究提出了定制化可解释性、细粒度同意机制和强健的覆盖控制等设计要务，并探讨了通过自然语言处理（NLP）分析社交媒体数据以识别用户需求与伦理问题的可能性。", "conclusion": "本文为开发透明、包容且可信赖的家庭自动化AI代理提供了概念基础与实践建议，强调了参与式与包容性方法论在伦理设计中的重要性。"}}
{"id": "2507.16675", "categories": ["math.OC", "90C30"], "pdf": "https://arxiv.org/pdf/2507.16675", "abs": "https://arxiv.org/abs/2507.16675", "authors": ["Yassine Kamri", "François Glineur", "Julien M. Hendrickx", "Ion Necoara"], "title": "On the Worst-Case Analysis of Cyclic Block Coordinate Descent type Algorithms", "comment": "39 pages, 7 figures", "summary": "We study the worst-case behavior of Block Coordinate Descent (BCD) type\nalgorithms for unconstrained minimization of coordinate-wise smooth convex\nfunctions. This behavior is indeed not completely understood, and the practical\nsuccess of these algorithms is not fully explained by current convergence\nanalyses. We extend the recently proposed Performance Estimation Problem (PEP)\napproach to convex coordinate-wise smooth functions by proposing necessary\ninterpolation conditions. We then exploit this to obtain improved numerical\nupper bounds on the worst-case convergence rate of three different BCD\nalgorithms, namely Cyclic Coordinate Descent (CCD), Alternating Minimization\n(AM), and a Cyclic version of the Random Accelerated Coordinate Descent\nintroduced in Fercoq and Richt\\'arik (2015) (CACD), substantially outperforming\nthe best current bounds in some situations. In addition, we show the\nconvergence of the CCD algorithm with more natural assumptions in the context\nof convex optimization than those typically made in the literature. Our\nmethodology uncovers a number of phenomena, some of which can be formally\nestablished. These include a scale-invariance property of the worst case of CCD\nwith respect to the coordinate-wise smoothness constants and a lower bound on\nthe worst-case performance of CCD which is equal to the number of blocks times\nthe worst-case of full gradient descent over the class of smooth convex\nfunctions. We also adapt our framework to the analysis of random BCD\nalgorithms, and present numerical results showing that the standard\nacceleration scheme in Fercoq and Richt\\'arik (2015) appears to be inefficient\nfor deterministic algorithms.", "AI": {"tldr": "本文研究了块坐标下降（BCD）类算法在坐标光滑凸函数无约束最小化中的最坏情况行为，通过性能估计问题（PEP）方法改进了三种BCD算法的最坏收敛速率上界，并揭示了CCD算法的尺度不变性等现象。", "motivation": "当前对BCD类算法最坏行为的理解不完整，实际成功无法完全用现有收敛分析解释。研究旨在填补这一空白，并提供更精确的收敛速率界限。", "method": "扩展了PEP方法，提出必要的插值条件，用于坐标光滑凸函数。对CCD、AM和CACD三种算法进行数值分析，并与当前最佳界限对比。", "result": "获得了优于当前最佳界限的数值上界；证明了CCD算法在更自然假设下的收敛性；揭示了CCD的尺度不变性及与全梯度下降最坏性能的关系。", "conclusion": "PEP方法有效揭示了BCD算法的收敛特性，发现确定性算法中标准加速方案效率低下，为算法设计提供了新见解。"}}
{"id": "2507.16540", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16540", "abs": "https://arxiv.org/abs/2507.16540", "authors": ["Radowanul Haque", "Aftab Ali", "Sally McClean", "Naveed Khan"], "title": "Explainable Vulnerability Detection in C/C++ Using Edge-Aware Graph Attention Networks", "comment": null, "summary": "Detecting security vulnerabilities in source code remains challenging,\nparticularly due to class imbalance in real-world datasets where vulnerable\nfunctions are under-represented. Existing learning-based methods often optimise\nfor recall, leading to high false positive rates and reduced usability in\ndevelopment workflows. Furthermore, many approaches lack explainability,\nlimiting their integration into security workflows. This paper presents\nExplainVulD, a graph-based framework for vulnerability detection in C/C++ code.\nThe method constructs Code Property Graphs and represents nodes using\ndual-channel embeddings that capture both semantic and structural information.\nThese are processed by an edge-aware attention mechanism that incorporates\nedge-type embeddings to distinguish among program relations. To address class\nimbalance, the model is trained using class-weighted cross-entropy loss.\nExplainVulD achieves a mean accuracy of 88.25 percent and an F1 score of 48.23\npercent across 30 independent runs on the ReVeal dataset. These results\nrepresent relative improvements of 4.6 percent in accuracy and 16.9 percent in\nF1 score compared to the ReVeal model, a prior learning-based method. The\nframework also outperforms static analysis tools, with relative gains of 14.0\nto 14.1 percent in accuracy and 132.2 to 201.2 percent in F1 score. Beyond\nimproved detection performance, ExplainVulD produces explainable outputs by\nidentifying the most influential code regions within each function, supporting\ntransparency and trust in security triage.", "AI": {"tldr": "本文提出ExplainVulD框架，通过双通道嵌入和边缘感知注意力机制改进C/C++代码漏洞检测，解决类别不平衡问题并提升可解释性，在ReVeal数据集上准确率达88.25%，F1分数提升16.9%。", "motivation": "现有基于学习的漏洞检测方法存在高误报率、可解释性不足的问题，且真实数据集中漏洞函数样本稀缺导致类别不平衡，亟需改进检测性能与工作流集成。", "method": "构建代码属性图，采用融合语义与结构的双通道节点嵌入，设计结合边类型嵌入的边缘感知注意力机制，并使用类别加权交叉熵损失缓解类别不平衡。", "result": "在ReVeal数据集上30次独立测试平均准确率88.25%、F1分数48.23%，较ReVeal模型准确率提升4.6%，F1分数提升16.9%；较静态分析工具准确率提升14.0-14.1%，F1分数提升132.2-201.2%。", "conclusion": "ExplainVulD通过可解释的代码区域定位显著提升检测性能与透明度，为安全审计工作流提供可信支持，解决了现有方法在实用性与解释性方面的局限性。"}}
{"id": "2507.16464", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.16464", "abs": "https://arxiv.org/abs/2507.16464", "authors": ["Bela Vizvari", "Gergely Kovacs", "Benedek Nagy", "Necet Deniz Turgay"], "title": "Hilbert basis in the face-centered cubic grid -- mathematical proofs", "comment": null, "summary": "The Hilbert basis is fundamental in describing the structure of the integer\npoints of a polyhedral cone. The face-centered cubic grid is one of the densest\npacking of the 3-dimensional space. The cycles of a grid satisfy the constraint\nset of a pointed, polyhedral cone which contains only non-negative integer\nvectors. The Hilbert basis of a grid gives the structure of the basic cycles in\nthe grid. It is shown in this paper that the basic cycles of the FCC grid\nbelong to 11 types. It is also discussed that how many elements are contained\nin the individual types. The proofs of the paper use geometric, combinatorial,\nalgebraic, and operations research methods.", "AI": {"tldr": "论文研究了面心立方(FCC)网格中基本循环的结构，发现其属于11种类型，并讨论了各类别中的元素数量。", "motivation": "Hilbert基是描述多面体锥整数点结构的基础，而FCC网格是三维空间最密集的堆积方式之一，研究其循环结构具有理论意义。", "method": "结合几何、组合、代数和运筹学方法，分析了FCC网格中满足非负整数向量约束的循环结构。", "result": "证明了FCC网格的基本循环可分为11种类型，并量化了各类别中的元素数量。", "conclusion": "该研究通过多学科方法系统揭示了FCC网格的循环结构特征，为相关数学和物理问题提供了理论基础。"}}
{"id": "2507.15974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15974", "abs": "https://arxiv.org/abs/2507.15974", "authors": ["Tong Wu", "Chong Xiang", "Jiachen T. Wang", "Weichen Yu", "Chawin Sitawarin", "Vikash Sehwag", "Prateek Mittal"], "title": "Does More Inference-Time Compute Really Help Robustness?", "comment": "Preprint", "summary": "Recently, Zaremba et al. demonstrated that increasing inference-time\ncomputation improves robustness in large proprietary reasoning LLMs. In this\npaper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1,\nQwen3, Phi-reasoning) can also benefit from inference-time scaling using a\nsimple budget forcing strategy. More importantly, we reveal and critically\nexamine an implicit assumption in prior work: intermediate reasoning steps are\nhidden from adversaries. By relaxing this assumption, we identify an important\nsecurity risk, intuitively motivated and empirically verified as an inverse\nscaling law: if intermediate reasoning steps become explicitly accessible,\nincreased inference-time computation consistently reduces model robustness.\nFinally, we discuss practical scenarios where models with hidden reasoning\nchains are still vulnerable to attacks, such as models with tool-integrated\nreasoning and advanced reasoning extraction attacks. Our findings collectively\ndemonstrate that the robustness benefits of inference-time scaling depend\nheavily on the adversarial setting and deployment context. We urge\npractitioners to carefully weigh these subtle trade-offs before applying\ninference-time scaling in security-sensitive, real-world applications.", "AI": {"tldr": "研究发现，小型开源模型通过推理时间扩展可提升鲁棒性，但若中间推理步骤暴露则会导致安全性下降，强调在安全敏感应用中需谨慎权衡。", "motivation": "探索开源模型是否也能通过推理时间扩展提升鲁棒性，并验证前人研究中隐含的中间步骤对攻击者不可见的假设是否成立。", "method": "采用预算强制策略进行推理时间扩展，并放松中间步骤隐藏的假设，通过实验验证不同场景下的模型表现。", "result": "开源模型通过推理时间扩展可提升鲁棒性，但中间步骤暴露时会出现逆向缩放现象，且工具集成推理等场景仍存在漏洞。", "conclusion": "推理时间扩展的鲁棒性收益高度依赖对抗环境和部署场景，安全敏感应用需审慎评估其潜在风险。"}}
{"id": "2507.16576", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16576", "abs": "https://arxiv.org/abs/2507.16576", "authors": ["Ahmed Lekssays", "Husrev Taha Sencar", "Ting Yu"], "title": "From Text to Actionable Intelligence: Automating STIX Entity and Relationship Extraction", "comment": "This paper is accepted at RAID 2025", "summary": "Sharing methods of attack and their effectiveness is a cornerstone of\nbuilding robust defensive systems. Threat analysis reports, produced by various\nindividuals and organizations, play a critical role in supporting security\noperations and combating emerging threats. To enhance the timeliness and\nautomation of threat intelligence sharing, several standards have been\nestablished, with the Structured Threat Information Expression (STIX) framework\nemerging as one of the most widely adopted. However, generating STIX-compatible\ndata from unstructured security text remains a largely manual, expert-driven\nprocess. To address this challenge, we introduce AZERG, a tool designed to\nassist security analysts in automatically generating structured STIX\nrepresentations. To achieve this, we adapt general-purpose large language\nmodels for the specific task of extracting STIX-formatted threat data. To\nmanage the complexity, the task is divided into four subtasks: entity detection\n(T1), entity type identification (T2), related pair detection (T3), and\nrelationship type identification (T4). We apply task-specific fine-tuning to\naccurately extract relevant entities and infer their relationships in\naccordance with the STIX specification. To address the lack of training data,\nwe compiled a comprehensive dataset with 4,011 entities and 2,075 relationships\nextracted from 141 full threat analysis reports, all annotated in alignment\nwith the STIX standard. Our models achieved F1-scores of 84.43% for T1, 88.49%\nfor T2, 95.47% for T3, and 84.60% for T4 in real-world scenarios. We validated\ntheir performance against a range of open- and closed-parameter models, as well\nas state-of-the-art methods, demonstrating improvements of 2-25% across tasks.", "AI": {"tldr": "本文介绍了AZERG工具，通过微调大型语言模型自动从非结构化安全文本生成STIX格式的威胁情报，解决了手动处理效率低下的问题。", "motivation": "当前从非结构化安全文本生成STIX兼容数据主要依赖人工，效率低下。为提升威胁情报共享的时效性和自动化水平，需要开发自动化工具。", "method": "将任务分解为四个子任务（实体检测、类型识别、关联对检测、关系类型识别），通过任务特定微调优化模型性能，并构建包含4011个实体和2075个关系的标注数据集。", "result": "模型在四个子任务中的F1分数分别达到84.43%、88.49%、95.47%和84.60%，相比现有方法提升2-25%。", "conclusion": "AZERG证明了大型语言模型在结构化威胁情报生成中的有效性，为自动化安全分析提供了可行解决方案。"}}
{"id": "2507.16469", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.16469", "abs": "https://arxiv.org/abs/2507.16469", "authors": ["Nawaf Shafi Alshammari", "Sergey Kitaev", "Artem Pyatkin"], "title": "On the representation number of grid graphs and cylindric grid graphs", "comment": null, "summary": "The representation number of a graph is the minimum number of copies of each\nvertex required to represent the graph as a word, such that the letters\ncorresponding to vertices $x$ and $y$ alternate if and only if $xy$ is an edge\nin the graph. It is known that path graphs, circle graphs, and ladder graphs\nhave representation number 2, while prism graphs have representation number 3.\n  In this paper, we extend these results by showing that generalizations of the\naforementioned graphs -- namely, the $m \\times n$ grid graphs and $m \\times n$\ncylindrical grid graphs -- have representation number $3$ for $m \\geq 3$ and $m\n\\geq 2$, respectively, and $n\\geq 3$. Furthermore, we discuss toroidal grid\ngraphs in the context of word-representability, which leads to an interesting\nconjecture.", "AI": {"tldr": "本文研究了图的表示数，特别是网格图和圆柱网格图的表示数，并提出了关于环面网格图的有趣猜想。", "motivation": "研究图的表示数有助于理解图的结构和性质，扩展已知结果到更广泛的图类。", "method": "通过分析$m \\times n$网格图和$m \\times n$圆柱网格图的结构，确定其表示数。", "result": "结果表明，对于$m \\geq 3$和$n \\geq 3$的网格图，以及$m \\geq 2$和$n \\geq 3$的圆柱网格图，表示数为3。", "conclusion": "本文扩展了图的表示数研究，并提出了关于环面网格图表示数的猜想，为未来研究提供了方向。"}}
{"id": "2507.16020", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16020", "abs": "https://arxiv.org/abs/2507.16020", "authors": ["Xi Yang", "Jiachen Wang", "Song Han", "Suining He"], "title": "Micromobility Flow Prediction: A Bike Sharing Station-level Study via Multi-level Spatial-Temporal Attention Neural Network", "comment": "6 pages, UrbComp 2024", "summary": "Efficient use of urban micromobility resources such as bike sharing is\nchallenging due to the unbalanced station-level demand and supply, which causes\nthe maintenance of the bike sharing systems painstaking. Prior efforts have\nbeen made on accurate prediction of bike traffics, i.e., demand/pick-up and\nreturn/drop-off, to achieve system efficiency. However, bike station-level\ntraffic prediction is difficult because of the spatial-temporal complexity of\nbike sharing systems. Moreover, such level of prediction over entire bike\nsharing systems is also challenging due to the large number of bike stations.\nTo fill this gap, we propose BikeMAN, a multi-level spatio-temporal attention\nneural network to predict station-level bike traffic for entire bike sharing\nsystems. The proposed network consists of an encoder and a decoder with an\nattention mechanism representing the spatial correlation between features of\nbike stations in the system and another attention mechanism describing the\ntemporal characteristic of bike station traffic. Through experimental study on\nover 10 millions trips of bike sharing systems (> 700 stations) of New York\nCity, our network showed high accuracy in predicting the bike station traffic\nof all stations in the city.", "AI": {"tldr": "本文提出BikeMAN模型，通过多级时空注意力神经网络预测共享单车系统站点级流量，解决了因时空复杂性和站点数量庞大导致的预测难题，并在纽约市超过1000万次骑行数据上验证了其高准确性。", "motivation": "共享单车系统因站点供需不平衡导致维护困难，现有研究难以准确预测大规模站点级流量。本文旨在填补这一空白，提升系统效率。", "method": "提出BikeMAN模型，包含编码器-解码器结构，采用双重注意力机制：空间注意力捕捉站点特征关联性，时间注意力建模流量时序特征。", "result": "在纽约市700余个站点、超1000万次骑行数据上的实验表明，该模型能高精度预测全市所有站点的单车流量。", "conclusion": "BikeMAN通过时空注意力机制有效解决了大规模共享单车系统的站点级流量预测问题，为资源调度提供了可靠技术支撑。"}}
{"id": "2507.16585", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16585", "abs": "https://arxiv.org/abs/2507.16585", "authors": ["Ahmed Lekssays", "Hamza Mouhcine", "Khang Tran", "Ting Yu", "Issa Khalil"], "title": "LLMxCPG: Context-Aware Vulnerability Detection Through Code Property Graph-Guided Large Language Models", "comment": "This paper is accepted at USENIX 2025", "summary": "Software vulnerabilities present a persistent security challenge, with over\n25,000 new vulnerabilities reported in the Common Vulnerabilities and Exposures\n(CVE) database in 2024 alone. While deep learning based approaches show promise\nfor vulnerability detection, recent studies reveal critical limitations in\nterms of accuracy and robustness: accuracy drops by up to 45% on rigorously\nverified datasets, and performance degrades significantly under simple code\nmodifications. This paper presents LLMxCPG, a novel framework integrating Code\nProperty Graphs (CPG) with Large Language Models (LLM) for robust vulnerability\ndetection. Our CPG-based slice construction technique reduces code size by\n67.84 to 90.93% while preserving vulnerability-relevant context. Our approach's\nability to provide a more concise and accurate representation of code snippets\nenables the analysis of larger code segments, including entire projects. This\nconcise representation is a key factor behind the improved detection\ncapabilities of our method, as it can now identify vulnerabilities that span\nmultiple functions. Empirical evaluation demonstrates LLMxCPG's effectiveness\nacross verified datasets, achieving 15-40% improvements in F1-score over\nstate-of-the-art baselines. Moreover, LLMxCPG maintains high performance across\nfunction-level and multi-function codebases while exhibiting robust detection\nefficacy under various syntactic code modifications.", "AI": {"tldr": "本文提出LLMxCPG框架，结合代码属性图(CPG)与大语言模型(LLM)，显著提升漏洞检测的准确性与鲁棒性。该方法通过CPG切片技术减少67.84-90.93%代码量，在验证数据集上F1分数超越现有方法15-40%，且对语法修改具有强适应性。", "motivation": "当前深度学习漏洞检测方法存在明显缺陷：在严格验证数据集上准确率下降高达45%，且对简单代码修改敏感。2024年CVE数据库新增超25,000漏洞，亟需更可靠的检测方案。", "method": "创新性整合CPG与LLM：1) 基于CPG的切片构建技术保留漏洞相关上下文，代码体积缩减67.84-90.93%；2) 生成更精确的代码表征，支持跨函数漏洞分析；3) 实现全项目级代码检测能力。", "result": "实证研究表明：1) 在验证数据集上F1分数提升15-40%；2) 在函数级与跨函数代码库均保持高性能；3) 对各类语法修改展现强鲁棒性，解决了现有方法性能骤降问题。", "conclusion": "LLMxCPG框架通过CPG-LLM协同机制，实现了代码表征精简化与检测能力强化的双重突破，为大规模复杂代码库的漏洞检测提供了新范式，特别擅长跨函数漏洞的识别。"}}
{"id": "2507.16500", "categories": ["math.CO", "05B10, 05C07, 05C12, 05C30, 05C75"], "pdf": "https://arxiv.org/pdf/2507.16500", "abs": "https://arxiv.org/abs/2507.16500", "authors": ["Johan Kok"], "title": "Integer sequences with conjectured relation with certain graph parameters of the family of linear Jaco graphs", "comment": null, "summary": "This experimental study presents some interesting conjectured relations\nbetween some integer sequences and certain graph parameters of the family of\nlinear Jaco graphs $J_n(x)$ where $n = 1,2,3,\\dots$. It appears that\n$\\textit{Golden ratio}$-like floor function terms play an important role in the\nanalysis of the graph structural properties of the family of linear Jaco\ngraphs. The experimental methodology to obtain the conjectures is indeed\ntrivial. However, it is the author's view that the proofs or disproofs of the\nconjectures may be challenging.", "AI": {"tldr": "该实验研究探讨了整数序列与线性Jaco图族$J_n(x)$某些图参数之间的猜想关系，发现黄金分割类地板函数在分析图结构特性中起关键作用。", "motivation": "研究旨在揭示线性Jaco图族$J_n(x)$的结构特性与整数序列之间可能存在的数学关系，特别是黄金分割类项的潜在影响。", "method": "采用实验性方法提出猜想，尽管方法本身简单，但作者认为证明或反驳这些猜想可能具有挑战性。", "result": "实验结果表明，黄金分割类地板函数项$\\lfloor \\phi n \\rfloor$在线性Jaco图的结构分析中扮演重要角色。", "conclusion": "该研究提出了关于线性Jaco图与整数序列关系的新猜想，为未来图论与数论交叉研究提供了潜在方向。"}}
{"id": "2507.16028", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16028", "abs": "https://arxiv.org/abs/2507.16028", "authors": ["Tehseen Rug", "Felix Böhmer", "Tessa Pfattheicher"], "title": "From Logic to Language: A Trust Index for Problem Solving with LLMs", "comment": "17 pages, 2 figures", "summary": "Classical computation, grounded in formal, logical systems, has been the\nengine of technological progress for decades, excelling at problems that can be\ndescribed with unambiguous rules. This paradigm, however, leaves a vast ocean\nof human problems -- those characterized by ambiguity, dynamic environments,\nand subjective context -- largely untouched. The advent of Large Language\nModels (LLMs) represents a fundamental shift, enabling computational systems to\nengage with this previously inaccessible domain using natural language. This\npaper introduces a unified framework to understand and contrast these\nproblem-solving paradigms. We define and delineate the problem spaces\naddressable by formal languages versus natural language. While solutions to the\nformer problem class can be evaluated using binary quality measures, the latter\nrequires a much more nuanced definition of approximate solution space taking\ninto account the vagueness, subjectivity and ambiguity inherent to natural\nlanguage. We therefore introduce a vector-valued trust index Q, which reflects\nsolution quality and distinguishes the binary correctness of formal solutions\nfrom the continuous adequacy spectrum characteristic of natural language\nsolutions. Within this framework, we propose two statistical quality\ndimensions. Normalized bi-semantic entropy measures robustness and conceptual\ndiversity of LLM answers given semantic variation in problem formulations.\nEmotional valence maps subjective valuation of a solution to a quantifiable\nmetric that can be maximized by invoking statistical measures. The concepts\nintroduced in this work will provide a more rigorous understanding of the\ncapabilities, limitations, and inherent nature of problem-solving in the age of\nLLMs.", "AI": {"tldr": "本文提出了一个统一框架，对比形式化语言与自然语言在问题解决中的不同范式，引入向量化信任指数Q和质量维度，以量化评估大语言模型（LLMs）在模糊性、主观性场景中的表现。", "motivation": "传统计算擅长规则明确的问题，但无法处理人类社会中普遍存在的模糊性、动态性和主观性问题。大语言模型的出现为这一领域带来了新可能，亟需建立理论框架系统评估其能力边界。", "method": "定义形式化语言与自然语言的问题空间划分，提出向量化信任指数Q区分二元正确性与连续适切性。引入双语义熵（衡量语义变化下的回答鲁棒性）和情感效价（量化主观评价）两大统计质量维度。", "result": "构建的框架能区分形式化解决方案的二进制评估与自然语言解决方案的连续谱评估，双语义熵和情感效价为LLM输出质量提供了可计算的度量标准。", "conclusion": "该研究为理解LLM时代问题解决的本质特性、能力边界提供了理论工具，未来可扩展至更复杂的人机交互场景评估。"}}
{"id": "2507.16773", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16773", "abs": "https://arxiv.org/abs/2507.16773", "authors": ["Yue Li", "Xiao Li", "Hao Wu", "Yue Zhang", "Fengyuan Xu", "Xiuzhen Cheng", "Sheng Zhong"], "title": "When LLMs Copy to Think: Uncovering Copy-Guided Attacks in Reasoning LLMs", "comment": null, "summary": "Large Language Models (LLMs) have become integral to automated code analysis,\nenabling tasks such as vulnerability detection and code comprehension. However,\ntheir integration introduces novel attack surfaces. In this paper, we identify\nand investigate a new class of prompt-based attacks, termed Copy-Guided Attacks\n(CGA), which exploit the inherent copying tendencies of reasoning-capable LLMs.\nBy injecting carefully crafted triggers into external code snippets,\nadversaries can induce the model to replicate malicious content during\ninference. This behavior enables two classes of vulnerabilities: inference\nlength manipulation, where the model generates abnormally short or excessively\nlong reasoning traces; and inference result manipulation, where the model\nproduces misleading or incorrect conclusions. We formalize CGA as an\noptimization problem and propose a gradient-based approach to synthesize\neffective triggers. Empirical evaluation on state-of-the-art reasoning LLMs\nshows that CGA reliably induces infinite loops, premature termination, false\nrefusals, and semantic distortions in code analysis tasks. While highly\neffective in targeted settings, we observe challenges in generalizing CGA\nacross diverse prompts due to computational constraints, posing an open\nquestion for future research. Our findings expose a critical yet underexplored\nvulnerability in LLM-powered development pipelines and call for urgent advances\nin prompt-level defense mechanisms.", "AI": {"tldr": "本文提出一种新型提示攻击方法——复制引导攻击(CGA)，利用大语言模型(LLM)的复制倾向性，通过注入精心设计的触发器来操纵推理过程，导致异常推理长度或错误结论。研究揭示了LLM代码分析流程中未被充分探索的安全漏洞。", "motivation": "尽管大语言模型(LLM)已广泛应用于自动化代码分析，但其集成引入了新的攻击面。研究者发现模型固有的复制倾向可被恶意利用，需要系统性研究这类新型提示攻击及其防御机制。", "method": "将CGA形式化为优化问题，提出基于梯度的触发器合成方法。通过向外部代码片段注入恶意触发器，诱导模型在推理时复制有害内容，实现推理长度操纵和结果操纵两类攻击。", "result": "实验表明，CGA能可靠地导致最先进推理型LLM出现无限循环、提前终止、错误拒绝和语义扭曲等问题。但在跨提示泛化方面存在计算限制的挑战。", "conclusion": "该研究暴露了LLM开发流程中的关键安全漏洞，虽然针对性攻击效果显著，但跨提示泛化仍是开放问题，亟需发展提示层面的防御机制。"}}
{"id": "2507.16593", "categories": ["math.CO"], "pdf": "https://arxiv.org/pdf/2507.16593", "abs": "https://arxiv.org/abs/2507.16593", "authors": ["Rosário Fernandes"], "title": "On a conjecture concerning the extensions of a reciprocal matrix", "comment": null, "summary": "Let $A$ be a reciprocal matrix of order $n$ and $w$ be its Perron\neigenvector. To infer the efficiency of $w$ for $A$, based on the principle of\nPareto optimal decisions, we study the strong connectivity of a certain digraph\nassociated with $A$ and $w$. A reciprocal matrix $B$ of order $n+1$ is an\nextension of $A$ if the matrix $A$ is obtained from $B$ by removing its last\nrow and column. We prove that there is no extension of a reciprocal matrix\nwhose digraph associated with the extension and its Perron eigenvector has a\nsource, as conjectured by Furtado and Johnson in ``Efficiency analysis for the\nPerron vector of a reciprocal matrix\". As an application, considering $n\\geq 5$\nand $A$ a matrix obtained from a consistent one by perturbing four entries\nabove the main diagonal, $x,y,z,a$, and the corresponding reciprocal entries,\nin a way that there is a submatrix of size $2$ containing the four perturbed\nentries and not containing a diagonal entry, we describe the relations among\n$x,y,z,a$ with which $A$ always has efficient Perron eigenvector.", "AI": {"tldr": "本文研究了互反矩阵的Perron特征向量的效率问题，证明了关于扩展矩阵的强连通性猜想，并应用于特定扰动矩阵的效率分析。", "motivation": "研究互反矩阵$A$及其Perron特征向量$w$的效率，基于Pareto最优决策原则，探讨与之相关的有向图的强连通性。", "method": "通过分析互反矩阵$B$（$A$的扩展）及其Perron特征向量相关的有向图，证明不存在具有源的扩展矩阵。", "result": "证明了Furtado和Johnson的猜想：不存在其相关有向图具有源的扩展矩阵。对于$n\\geq 5$且通过扰动四个非对角线条目得到的矩阵，描述了使Perron特征向量始终高效的条件。", "conclusion": "研究结果为互反矩阵Perron特征向量的效率提供了理论支持，特别是在特定扰动条件下，明确了高效特征向量存在的参数关系。"}}
{"id": "2507.16067", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.16067", "abs": "https://arxiv.org/abs/2507.16067", "authors": ["Jeroen Spaans", "Jesse Heyninck"], "title": "A Unifying Framework for Semiring-Based Constraint Logic Programming With Negation (full version)", "comment": "Full version, including proofs and appendices, of paper accepted at\n  IJCAI 2025", "summary": "Constraint Logic Programming (CLP) is a logic programming formalism used to\nsolve problems requiring the consideration of constraints, like resource\nallocation and automated planning and scheduling. It has previously been\nextended in various directions, for example to support fuzzy constraint\nsatisfaction, uncertainty, or negation, with different notions of semiring\nbeing used as a unifying abstraction for these generalizations. None of these\nextensions have studied clauses with negation allowed in the body. We\ninvestigate an extension of CLP which unifies many of these extensions and\nallows negation in the body. We provide semantics for such programs, using the\nframework of approximation fixpoint theory, and give a detailed overview of the\nimpacts of properties of the semirings on the resulting semantics. As such, we\nprovide a unifying framework that captures existing approaches and allows\nextending them with a more expressive language.", "AI": {"tldr": "本文研究了一种扩展约束逻辑编程(CLP)的方法，允许在子句体中使用否定，并利用近似不动点理论提供语义框架，统一了多种现有扩展。", "motivation": "现有的CLP扩展（如模糊约束满足、不确定性或否定）尚未研究允许在子句体中使用否定的情况，本文旨在填补这一空白。", "method": "通过半环理论作为统一抽象框架，结合近似不动点理论，为允许否定的CLP程序提供语义定义。", "result": "研究展示了半环性质对最终语义的影响，并提供了一个能统一现有方法且支持更丰富语言的框架。", "conclusion": "本文提出的框架不仅统一了多种CLP扩展，还通过允许否定增强了表达力，为未来研究提供了理论基础。"}}
{"id": "2507.16788", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16788", "abs": "https://arxiv.org/abs/2507.16788", "authors": ["Sebastian Pape", "Anis Bkakria", "Maurice Heymann", "Badreddine Chah", "Abdeljalil Abbas-Turki", "Sarah Syed-Winkler", "Matthias Hiller", "Reda Yaich"], "title": "AUTOPSY: A Framework for Tackling Privacy Challenges in the Automotive Industry", "comment": "19 pages, 4 figures", "summary": "With the General Data Protection Regulation (GDPR) in place, all domains have\nto ensure compliance with privacy legislation. However, compliance does not\nnecessarily result in a privacy-friendly system as for example getting users'\nconsent to process their data does not improve the privacy-friendliness of the\nsystem. Therefore, the goal of the AUTOPSY project was to support the privacy\nengineering process in the automotive domain by providing several building\nblocks which technically improve the privacy-friendliness of modern, i.e.,\nconnected and (partially) automated vehicles. This paper presents the results\nof the AUTOPSY project: a system model to identify relevant entities and\nlocations to apply privacy enhancing technologies (PETs); the privacy manager\naiming at more control of the data flow from the vehicle, a PET selection\napproach based on GDPR principles, and an architectural framework for\nautomotive privacy. Furthermore, we built a demonstrator for location-based\nservices to evaluate the architectural framework.", "AI": {"tldr": "AUTOPSY项目旨在通过技术手段提升联网与自动驾驶车辆的隐私友好性，提出了系统模型、隐私管理器、PET选择方法及架构框架，并通过基于位置服务的演示器进行评估。", "motivation": "尽管GDPR要求各领域遵守隐私法规，但合规性并不等同于系统隐私友好性。AUTOPSY项目旨在通过技术手段弥补这一差距，尤其在汽车领域提升隐私保护。", "method": "项目开发了系统模型以识别适用隐私增强技术（PETs）的实体与位置，设计了隐私管理器以控制车辆数据流，提出了基于GDPR原则的PET选择方法，并构建了汽车隐私架构框架。", "result": "项目成果包括系统模型、隐私管理器、PET选择方法及架构框架，并通过基于位置服务的演示器验证了架构框架的可行性。", "conclusion": "AUTOPSY项目为汽车领域隐私工程提供了实用技术模块，通过系统性方法提升了联网与自动驾驶车辆的隐私友好性，并验证了其有效性。"}}
{"id": "2507.16622", "categories": ["math.CO", "05C12, 05C69"], "pdf": "https://arxiv.org/pdf/2507.16622", "abs": "https://arxiv.org/abs/2507.16622", "authors": ["Ethan Shallcross", "James Tuite", "Aoise Evans", "Aditi Krishnakumar", "Sumaiyah Boshar"], "title": "Solution to some conjectures on mobile position problems", "comment": null, "summary": "The general position problem for graphs asks for the largest number of\nvertices in a subset $S \\subseteq V(G)$ of a graph $G$ such that for any $u,v\n\\in S$ and any shortest $u,v$-path $P$ we have $S \\cap V(P) = \\{ u,v\\} $,\nwhereas the mutual visibility problem requires only that for any $u,v \\in S$\nthere exists a shortest $u,v$-path with $S \\cap V(P) = \\{ u,v\\} $. In the\nmobile versions of these problems, robots must move through the network in\ngeneral position/mutual visibility such that every vertex is visited by a\nrobot. This paper solves some open problems from the literature. We quantify\nthe effect of adding the restriction that every robot can visit every vertex\n(the so-called \\emph{completely mobile} variants), prove a bound on both mobile\nnumbers in terms of the clique number, and find the mobile mutual visibility\nnumber of line graphs of complete graphs, strong grids and Cartesian grids.", "AI": {"tldr": "本文研究了图论中的一般位置问题和互见性问题及其移动版本，解决了文献中的一些开放问题，量化了完全移动限制的影响，并给出了移动数在团数上的界限。", "motivation": "研究图的一般位置问题和互见性问题及其移动版本，旨在解决文献中的开放问题，并量化完全移动限制对问题的影响。", "method": "通过理论分析，量化了完全移动限制的影响，证明了移动数与团数的关系，并计算了特定图类（如完全图的线图、强网格和笛卡尔网格）的移动互见数。", "result": "解决了文献中的开放问题，量化了完全移动限制的影响，证明了移动数与团数的界限，并确定了特定图类的移动互见数。", "conclusion": "本文通过理论分析，解决了图论中一般位置和互见性问题的移动版本，为相关研究提供了新的理论结果和界限。"}}
{"id": "2507.16110", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16110", "abs": "https://arxiv.org/abs/2507.16110", "authors": ["Shengchao Liu", "Hannan Xu", "Yan Ai", "Huanxin Li", "Yoshua Bengio", "Harry Guo"], "title": "Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization", "comment": null, "summary": "Large language models (LLMs) leverage chain-of-thought (CoT) techniques to\ntackle complex problems, representing a transformative breakthrough in\nartificial intelligence (AI). However, their reasoning capabilities have\nprimarily been demonstrated in solving math and coding problems, leaving their\npotential for domain-specific applications-such as battery discovery-largely\nunexplored. Inspired by the idea that reasoning mirrors a form of guided\nsearch, we introduce ChatBattery, a novel agentic framework that integrates\ndomain knowledge to steer LLMs toward more effective reasoning in materials\ndesign. Using ChatBattery, we successfully identify, synthesize, and\ncharacterize three novel lithium-ion battery cathode materials, which achieve\npractical capacity improvements of 28.8%, 25.2%, and 18.5%, respectively, over\nthe widely used cathode material, LiNi0.8Mn0.1Co0.1O2 (NMC811). Beyond this\ndiscovery, ChatBattery paves a new path by showing a successful LLM-driven and\nreasoning-based platform for battery materials invention. This complete\nAI-driven cycle-from design to synthesis to characterization-demonstrates the\ntransformative potential of AI-driven reasoning in revolutionizing materials\ndiscovery.", "AI": {"tldr": "论文提出ChatBattery框架，通过整合领域知识引导大语言模型(LLM)进行材料设计推理，成功发现三种新型锂离子电池正极材料，容量较NMC811提升18.5%-28.8%，展示了AI驱动推理在材料发现中的变革潜力。", "motivation": "现有大语言模型的推理能力主要在数学和编程领域得到验证，其在电池材料发现等专业领域的应用潜力尚未充分探索。研究团队认为推理本质上是一种引导式搜索，因此尝试开发领域知识引导的LLM推理框架。", "method": "提出ChatBattery智能代理框架，将电池领域知识与链式思维(CoT)技术结合，构建完整的AI驱动闭环系统（从材料设计到合成再到表征），引导LLM进行有效的材料设计推理。", "result": "成功发现并制备三种新型锂离子电池正极材料，其实际容量比商用NMC811材料分别提高28.8%、25.2%和18.5%，验证了框架的有效性。", "conclusion": "ChatBattery不仅实现了电池材料的创新发现，更开创了基于LLM推理的材料发明新范式，完整展示了AI驱动推理在材料科学领域的革命性潜力。"}}
{"id": "2507.16226", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16226", "abs": "https://arxiv.org/abs/2507.16226", "authors": ["Dong Ben", "Hui Feng", "Qian Wang"], "title": "Distilled Large Language Model in Confidential Computing Environment for System-on-Chip Design", "comment": "7 pages, 4 figures;", "summary": "Large Language Models (LLMs) are increasingly used in circuit design tasks\nand have typically undergone multiple rounds of training. Both the trained\nmodels and their associated training data are considered confidential\nintellectual property (IP) and must be protected from exposure. Confidential\nComputing offers a promising solution to protect data and models through\nTrusted Execution Environments (TEEs). However, existing TEE implementations\nare not designed to support the resource-intensive nature of LLMs efficiently.\nIn this work, we first present a comprehensive evaluation of the LLMs within a\nTEE-enabled confidential computing environment, specifically utilizing Intel\nTrust Domain Extensions (TDX). We constructed experiments on three\nenvironments: TEE-based, CPU-only, and CPU-GPU hybrid implementations, and\nevaluated their performance in terms of tokens per second.\n  Our first observation is that distilled models, i.e., DeepSeek, surpass other\nmodels in performance due to their smaller parameters, making them suitable for\nresource-constrained devices. Also, in the quantized models such as 4-bit\nquantization (Q4) and 8-bit quantization (Q8), we observed a performance gain\nof up to 3x compared to FP16 models. Our findings indicate that for fewer\nparameter sets, such as DeepSeek-r1-1.5B, the TDX implementation outperforms\nthe CPU version in executing computations within a secure environment. We\nfurther validate the results using a testbench designed for SoC design tasks.\nThese validations demonstrate the potential of efficiently deploying\nlightweight LLMs on resource-constrained systems for semiconductor CAD\napplications.", "AI": {"tldr": "本文评估了在可信执行环境(TEE)中部署大型语言模型(LLM)的性能表现，发现蒸馏模型和量化模型在资源受限设备上具有优势，并验证了轻量级LLM在半导体CAD应用中的潜力。", "motivation": "大型语言模型(LLM)在电路设计任务中的应用日益广泛，但其训练模型和数据作为机密知识产权需要保护。可信计算通过TEE提供保护方案，但现有TEE实现难以高效支持资源密集型的LLM。", "method": "研究在三种环境下进行实验：基于TEE(使用Intel TDX)、纯CPU和CPU-GPU混合实现，评估了它们的令牌生成速度性能。特别测试了蒸馏模型(如DeepSeek)和量化模型(Q4/Q8)的表现。", "result": "蒸馏模型因参数较少表现优异；量化模型相比FP16模型性能提升高达3倍。对于较小参数集(如DeepSeek-r1-1.5B)，TDX实现优于CPU版本。专为SoC设计任务设计的测试平台验证了这些结果。", "conclusion": "研究表明轻量级LLM可以高效部署在资源受限系统上，特别适用于半导体CAD应用场景，同时保障了模型和数据的安全性。"}}
{"id": "2507.16625", "categories": ["math.CO", "math.GN", "54E35, 05C63, 05C40"], "pdf": "https://arxiv.org/pdf/2507.16625", "abs": "https://arxiv.org/abs/2507.16625", "authors": ["Max Pitz"], "title": "A metrization theorem for edge-end spaces of infinite graphs", "comment": "12 pages", "summary": "We prove that the edge-end space of an infinite graph is metrizable if and\nonly if it is first-countable. This strengthens a recent result by Aurichi,\nMagalhaes Jr.\\ and Real (2024).\n  Our central graph-theoretic tool is the use of tree-cut decompositions,\nintroduced by Wollan (2015) as a variation of tree decompositions that is based\non edge cuts instead of vertex separations. In particular, we give a new,\nelementary proof for Kurkofka's result (2022) that every infinite graph has a\ntree-cut decomposition of finite adhesion into its $\\omega$-edge blocks. Along\nthe way, we also give a new, short proof for a classic result by Halin (1984)\non $K_{k,\\kappa}$-subdivisions in $k$-connected graphs, making this paper\nself-contained.", "AI": {"tldr": "本文证明了无限图的边端空间可度量化的充要条件是其第一可数性，并改进了Aurichi等人的近期结果。核心工具是Wollan提出的树割分解，同时给出了Kurkofka和Halin定理的新证明。", "motivation": "研究无限图边端空间的拓扑性质，特别是可度量化条件，以深化对图结构与其拓扑表示之间关系的理解。", "method": "采用树割分解（tree-cut decomposition）作为核心工具，通过边切割替代顶点分离，并给出Kurkofka有限粘合分解定理及Halin经典子图定理的新证明。", "result": "边端空间可度量化当且仅当其第一可数，强化了Aurichi等人的结果；同时重构了关于$\\omega$-边块分解和$K_{k,\\kappa}$-子图的关键定理证明。", "conclusion": "该研究统一了无限图拓扑性质与组合结构的关系，所发展的树割分解技术为后续研究提供了简洁的证明框架。"}}
{"id": "2507.16126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16126", "abs": "https://arxiv.org/abs/2507.16126", "authors": ["Michael R. Bock", "Kara Molisee", "Zachary Ozer", "Sumit Shah"], "title": "TaxCalcBench: Evaluating Frontier Models on the Tax Calculation Task", "comment": null, "summary": "Can AI file your taxes? Not yet. Calculating US personal income taxes is a\ntask that requires building an understanding of vast amounts of English text\nand using that knowledge to carefully compute results. We propose TaxCalcBench,\na benchmark for determining models' abilities to calculate personal income tax\nreturns given all of the necessary information. Our experiment shows that\nstate-of-the-art models succeed in calculating less than a third of federal\nincome tax returns even on this simplified sample set. Our analysis concludes\nthat models consistently misuse tax tables, make errors in tax calculation, and\nincorrectly determine eligibility. Our findings point to the need for\nadditional infrastructure to apply LLMs to the personal income tax calculation\ntask.", "AI": {"tldr": "当前AI尚无法准确计算美国个人所得税，顶尖模型在简化数据集上的正确率不足三分之一，主要问题包括税表误用、计算错误和资格判定失误。", "motivation": "验证现有AI模型处理复杂文本理解与精确计算任务（如个人所得税申报）的能力，揭示其在实际应用中的局限性。", "method": "提出TaxCalcBench基准测试，要求模型在给定完整信息的情况下完成税务计算，并评估其表现。", "result": "实验表明，最先进模型仅能正确计算不到三分之一的联邦税表，普遍存在税表使用错误、计算失误和资格误判问题。", "conclusion": "需建立额外的基础设施来提升大语言模型在税务计算任务中的适用性，当前技术尚未达到实用要求。"}}
{"id": "2507.16694", "categories": ["math.CO", "cs.IT", "math.IT", "51E22, 94B05, 14M15"], "pdf": "https://arxiv.org/pdf/2507.16694", "abs": "https://arxiv.org/abs/2507.16694", "authors": ["Ilaria Cardinali", "Luca Giuzzi"], "title": "Linear codes arising from the point-hyperplane geometry -- Part II: the twisted embedding", "comment": "28 pages", "summary": "Let $\\bar{\\Gamma}$ be the point-hyperplane geometry of a projective space\n$\\mathrm{PG(V)},$ where $V$ is a $(n+1)$-dimensional vector space over a finite\nfield $\\mathbb{F}_q$ of order $q.$ Suppose that $\\sigma$ is an automorphism of\n$\\mathbb{F}_q$ and consider the projective embedding $\\varepsilon_{\\sigma}$ of\n$\\bar{\\Gamma}$ into the projective space $\\mathrm{PG}(V\\otimes V^*)$ mapping\nthe point $([x],[\\xi])\\in \\bar{\\Gamma}$ to the projective point represented by\nthe pure tensor $x^{\\sigma}\\otimes \\xi$, with $\\xi(x)=0.$ In [I. Cardinali, L.\nGiuzzi, Linear codes arising from the point-hyperplane geometry -- part I: the\nSegre embedding (Jun. 2025). arXiv:2506.21309, doi:10.48550/ARXIV.2506.21309]\nwe focused on the case $\\sigma=1$ and we studied the projective code arising\nfrom the projective system $\\Lambda_1=\\varepsilon_{1}(\\bar{\\Gamma}).$ Here we\nfocus on the case $\\sigma\\not=1$ and we investigate the linear code ${\\mathcal\nC}(\\Lambda_{\\sigma})$ arising from the projective system\n$\\Lambda_{\\sigma}=\\varepsilon_{\\sigma}(\\bar{\\Gamma}).$ In particular, after\nhaving verified that $\\mathcal{C}( \\Lambda_{\\sigma})$ is a minimal code, we\ndetermine its parameters, its minimum distance as well as its automorphism\ngroup. We also give a (geometrical) characterization of its minimum and second\nlowest weight codewords and determine its maximum weight when $q$ and $n$ are\nboth odd.", "AI": {"tldr": "本文研究了有限域$\\mathbb{F}_q$上点-超平面几何$\\bar{\\Gamma}$在非平凡自同构$\\sigma$下的射影嵌入$\\varepsilon_{\\sigma}$所生成的线性码$\\mathcal{C}(\\Lambda_{\\sigma})$的性质，包括其参数、最小距离、自同构群及权值分布。", "motivation": "在前一篇论文中，作者研究了$\\sigma=1$时的线性码。本文旨在探讨$\\sigma\\neq1$时的线性码$\\mathcal{C}(\\Lambda_{\\sigma})$的性质，以扩展对这类几何编码的理解。", "method": "通过射影嵌入$\\varepsilon_{\\sigma}$将$\\bar{\\Gamma}$映射到射影空间$\\mathrm{PG}(V\\otimes V^*)$，并研究由此生成的线性码$\\mathcal{C}(\\Lambda_{\\sigma})$的代数与几何特性。", "result": "证明了$\\mathcal{C}(\\Lambda_{\\sigma})$是最小码，确定了其参数、最小距离和自同构群。此外，给出了最小和第二小权码字的几何刻画，并在$q$和$n$均为奇数时确定了最大权值。", "conclusion": "本文完善了非平凡自同构$\\sigma$下点-超平面几何编码的理论框架，为后续研究提供了重要的代数与几何工具。"}}
{"id": "2507.16145", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.16145", "abs": "https://arxiv.org/abs/2507.16145", "authors": ["Shuhao Mei", "Yongchao Long", "Shan Cao", "Xiaobo Han", "Shijia Geng", "Jinbo Sun", "Yuxi Zhou", "Shenda Hong"], "title": "SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting", "comment": null, "summary": "Chronic Obstructive Pulmonary Disease (COPD), a major chronic respiratory\ndisease with persistent airflow limitation, is a leading global cause of\ndisability and mortality. Respiratory spirogram time series, routinely\ncollected during pulmonary function tests (PFTs), play a critical role in the\nearly detection of repsiratory diseases and in monitoring lung function over\ntime. However, most current AI models for COPD diagnosis are limited to\noutputting classification results without providing a rationale for their\ndiagnostic process, while current Large Language Models (LLMs) cannot\nunderstand spirograms yet, which severely limits their clinical trust and\nadoption. To tackle this challenge, we leverage a cohort of 234,028 individuals\nfrom the UK Biobank (UKB) to propose SpiroLLM, the first multimodal large\nlanguage model that can understand spirogram. The model extracts morphological\nfeatures from respiratory curves via a SpiroEncoder and aligns them with PFT\nnumerical values in a unified latent space using a SpiroProjector, ultimately\nempowering a large language model to generate a comprehensive diagnostic\nreport. Experimental results confirm that SpiroLLM achieved a diagnostic AUROC\nof 0.8980 (95% CI: 0.8820-0.9132). In a robustness test with missing core data,\nit maintained a 100% valid response rate, far surpassing the 13.4% of a\ntext-only model and showcasing the superiority of its multimodal design. This\nwork demonstrates the substantial potential of deeply fusing physiological\nsignals with large language models, establishing a new paradigm for the next\ngeneration of interpretable and reliable clinical decision support tools.", "AI": {"tldr": "提出首个多模态大语言模型SpiroLLM，通过理解呼吸曲线实现COPD诊断，AUROC达0.8980，在核心数据缺失时仍保持100%有效响应率。", "motivation": "现有AI模型仅输出分类结果缺乏诊断解释，且大语言模型无法理解呼吸曲线，限制了临床信任。需开发能解读呼吸曲线的多模态模型。", "method": "利用UK Biobank的234,028人队列数据，通过SpiroEncoder提取呼吸曲线形态特征，经SpiroProjector与肺功能数值对齐，构建多模态大语言模型生成诊断报告。", "result": "模型诊断AUROC为0.8980（95% CI: 0.8820-0.9132）。核心数据缺失测试中有效响应率100%，远超纯文本模型的13.4%。", "conclusion": "该研究开创了生理信号与大语言模型深度融合的新范式，为下一代可解释、可靠的临床决策工具奠定基础。"}}
{"id": "2507.16730", "categories": ["math.CO", "05C50"], "pdf": "https://arxiv.org/pdf/2507.16730", "abs": "https://arxiv.org/abs/2507.16730", "authors": ["Wei Wang", "Ximei Huang"], "title": "Almost all cographs have a cospectral mate", "comment": "12 pages, 4 figures", "summary": "Complement-reducible graphs (or cographs) are the graphs formed from the\nsingle-vertex graph by the operations of complement and disjoint union. By\ncombining the Johnson-Newman theorem on generalized cospectrality with the\nstandard tools in the asymptotic enumeration of trees, we show that almost all\ncographs have a cospectral mate. This result can be viewed as an analogue to a\nwell-known result by Schwenk, who proved that almost all trees have a\ncospectral mate.", "AI": {"tldr": "本文证明了几乎所有补可约图（cographs）都存在共谱伴侣，这是对Schwenk关于树共谱性经典结论的类比扩展。", "motivation": "研究补可约图的共谱性是为了探索图论中谱性质的一般规律，并验证这类特殊图结构是否与树类似具有普遍共谱现象。", "method": "结合Johnson-Newman广义共谱定理与树渐近枚举的标准工具，通过理论推导进行分析。", "result": "几乎所有的补可约图都存在至少一个共谱伴侣，其比例随顶点数增长趋近于1。", "conclusion": "该结论确立了补可约图与树在共谱性上的相似行为，为图谱理论提供了新的分类学依据。"}}
{"id": "2507.16184", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.16184", "abs": "https://arxiv.org/abs/2507.16184", "authors": ["Myung Ho Kim"], "title": "Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper)", "comment": "21 pages", "summary": "We report the discovery of a structural convergence across four influential\ntheories of mind: Kahneman's dual-system theory, Friston's predictive\nprocessing, Minsky's society of mind, and Clark's extended mind-emerging\nunintentionally within a practical AI agent architecture called Agentic Flow.\nDesigned to address limitations in large language models (LLMs), Agentic Flow\ncomprises five interdependent modules such as Retrieval, Cognition, Control,\nMemory, and Action arranged in a recurrent cognitive loop. Although originally\ninspired only by Minsky and Clark, the system's structure retrospectively\naligns with computational motifs found in all four theories, including\npredictive modeling, associative recall, and error-sensitive control.\n  To assess this convergence, we conducted comparative experiments with\nbaseline LLM agents on multi-step reasoning tasks. The structured agent\nachieved 95.8% task success and exhibited strong constraint adherence, while\nthe baseline system succeeded 62.3% of the time. These results were not aimed\nat proving superiority, but at illustrating how theoretical structures may\nemerge through practical design choices rather than top-down theory.\n  We introduce PEACE as a descriptive meta-architecture that captures\ndesign-level regularities observed in Agentic Flow. Not intended as a new\ntheory, PEACE provides a shared vocabulary for understanding architectures\nshaped by real-world implementation demands. This paper should be read as a\nposition paper - an exploratory reflection on how implementation can surface\nlatent structural echoes of cognitive theory, without asserting theoretical\nunification.", "AI": {"tldr": "研究发现四种心智理论（卡尼曼双系统理论、弗里斯顿预测处理、明斯基心智社会论、克拉克延展心智）在AI架构Agentic Flow中意外地呈现结构趋同。该架构通过五模块循环设计提升大语言模型性能，实验显示其任务成功率显著高于基线系统。研究提出PEACE元架构描述这一现象，强调实践设计可能自发体现认知理论结构。", "motivation": "针对大语言模型（LLMs）的局限性，研究者试图通过模块化架构（Agentic Flow）改进AI代理性能，意外发现其实践结构与四种经典心智理论存在深层对应。", "method": "设计包含检索、认知、控制、记忆、行动五模块的循环架构Agentic Flow，与基线LLM代理进行多步推理任务对比实验（任务成功率95.8% vs 62.3%），并提炼PEACE元架构描述设计规律。", "result": "结构化代理任务成功率显著提升（95.8%），且严格遵循约束条件，表明实践设计可自发重现认知理论的核心计算特征（如预测建模、联想记忆、误差敏感控制）。", "conclusion": "作为立场论文，研究揭示实践需求驱动的架构设计可能自然映射认知理论结构，PEACE提供描述此类现象的共同语言，但非主张理论统一。"}}
{"id": "2507.16204", "categories": ["cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.16204", "abs": "https://arxiv.org/abs/2507.16204", "authors": ["Li-Hsiang Shen", "Jyun-Jhe Huang"], "title": "CHIMERA: Compressed Hybrid Intelligence for Twin-Model Enhanced Multi-Agent Deep Reinforcement Learning for Multi-Functional RIS-Assisted Space-Air-Ground Integrated Networks", "comment": null, "summary": "A space-air-ground integrated network (SAGIN) architecture is proposed,\nempowered by multi-functional reconfigurable intelligent surfaces (MF-RIS)\ncapable of simultaneously reflecting, amplifying, and harvesting wireless\nenergy. The MF-RIS plays a pivotal role in addressing the energy shortages of\nlow-Earth orbit (LEO) satellites operating in shadowed regions, while\nexplicitly accounting for both communication and computing energy consumption\nacross the SAGIN nodes. To maximize the long-term energy efficiency (EE), we\nformulate a joint optimization problem over the MF-RIS parameters, including\nsignal amplification, phase-shifts, energy harvesting ratio, and active element\nselection as well as the SAGIN parameters of beamforming vectors, high-altitude\nplatform station (HAPS) deployment, user association, and computing capability.\nThe formulated problem is highly non-convex and non-linear and contains mixed\ndiscrete-continuous parameters. To tackle this, we conceive a compressed hybrid\nintelligence for twin-model enhanced multi-agent deep reinforcement learning\n(CHIMERA) framework, which integrates semantic state-action compression and\nparametrized sharing under hybrid reinforcement learning to efficiently explore\nsuitable complex actions. The simulation results have demonstrated that the\nproposed CHIMERA scheme substantially outperforms the conventional benchmarks,\nincluding fixed-configuration or non-harvesting MF-RIS, traditional RIS, and\nno-RIS cases, as well as centralized and multi-agent deep reinforcement\nlearning baselines in terms of the highest EE. Moreover, the proposed\nSAGIN-MF-RIS architecture achieves superior EE performance due to its\ncomplementary coverage, offering notable advantages over either standalone\nsatellite, aerial, or ground-only deployments.", "AI": {"tldr": "提出一种融合多功能可重构智能表面(MF-RIS)的空天地一体化网络(SAGIN)架构，通过CHIMERA算法联合优化网络参数，显著提升长期能效(EE)。", "motivation": "解决低轨卫星在阴影区域能源短缺问题，同时兼顾SAGIN节点通信与计算能耗，突破传统RIS功能单一性限制。", "method": "设计CHIMERA框架：集成语义动作压缩与参数共享的混合强化学习，联合优化MF-RIS信号放大/相移/能量收集比/元件选择，以及波束成形/HAPS部署/用户关联/计算资源。", "result": "仿真表明CHIMERA方案EE性能显著优于固定配置MF-RIS、传统RIS及无RIS基准，SAGIN-MF-RIS架构通过互补覆盖实现最优EE。", "conclusion": "MF-RIS赋能的SAGIN架构在能效方面超越单一卫星/航空/地面部署，CHIMERA算法有效解决高维非线性混合参数优化问题。"}}
{"id": "2507.16765", "categories": ["math.CO", "Primary 05A15, Secondary 11G05, 14H52, 15B36, 11B37, 11B83"], "pdf": "https://arxiv.org/pdf/2507.16765", "abs": "https://arxiv.org/abs/2507.16765", "authors": ["Paul Barry"], "title": "Elliptic Curves, Riordan arrays and Lattice Paths", "comment": "19 pages", "summary": "In this note, we show that to each elliptic curve of the form\n$$y^2-axy-y=x^3-bx^2-cx,$$ we can associate a family of lattice paths whose\nstep set is determined by the parameters of the elliptic curve. The enumeration\nof these lattice paths is by means of an associated Riordan array. The curves\nand the paths have associated Somos $4$ sequences which are essentially the\nsame. For the curves the link to Somos $4$ sequences is a classical result, via\nthe elliptic divisibility sequence. For the paths the link is via a Hankel\ntransform.", "AI": {"tldr": "本文展示了如何将特定形式的椭圆曲线与格路径族关联，并通过Riordan数组进行计数，揭示了椭圆曲线与格路径在Somos 4序列上的本质联系。", "motivation": "研究旨在建立椭圆曲线$y^2-axy-y=x^3-bx^2-cx$与格路径族的关联，探索两者在组合数学与数论中的深层联系。", "method": "通过Riordan数组枚举格路径，并利用椭圆可除序列（曲线）和Hankel变换（路径）分别关联到Somos 4序列。", "result": "发现椭圆曲线与对应格路径族的Somos 4序列本质相同，验证了曲线参数决定路径步集的数学关联性。", "conclusion": "该研究统一了椭圆曲线与格路径的代数组合性质，为Somos序列的几何与组合解释提供了新视角。"}}
{"id": "2507.16804", "categories": ["math.CO", "05C35"], "pdf": "https://arxiv.org/pdf/2507.16804", "abs": "https://arxiv.org/abs/2507.16804", "authors": ["Zihao Jin", "Sean Longbrake", "Liana Yepremyan"], "title": "Bipartite Turán numbers via edge-gluing", "comment": "20 pages", "summary": "In 1984, Erd\\H{o}s and Simonovits asked the following: given a bipartite\ngraph $H$, do there exist constants $0 \\leq \\alpha < 1$ and $\\beta, C > 0$ such\nthat any graph $G$ on $n$ vertices and $pn^2\\geq C n^{1+ \\alpha}$ edges\ncontains at least $\\beta n^{\\mathrm{v}(H)} p^{\\mathrm{e}(H)}$ copies of $H$?\n  We show that edge-gluing preserves the satisfiability of this conjecture\nunder some mild symmetry conditions. Namely, if two graphs $H_1$ and $H_2$\nsatisfy this conjecture, and if furthermore, gluing them along a fixed edge\nproduces a unique graph then the resulting graph satisfies the conjecture as\nwell. We also show that if $H$ satisfies the conjecture then if we glue several\ncopies of (labeled) $H$ along the same labeled copy of a subforest of $H$ then\nthe resulting graph also satisfies the conjecture.\n  We also show that Zarankiewicz numbers are additive in the order of magnitude\nunder gluing edges. Indeed, for a (signed) bipartite graph $H$ with parts\ncoloured $+$ and $-$, recall $z(m,n, H)$ is the maximum number of edges in a\nsigned bipartite graph $G$ with $+$ side being of size $m$ and $-$ side being\nof size $n$ such that $G$ does not contain a copy of $H$ with $+$ side embedded\nin the $+$ side of $G$. We show that for any two (signed) bipartite graphs\n$H_1$ and $H_2$ if we glue them along an edge preserving the sign of the edge\nthen the resulting graph $H$ satisfies $z(m,n, H) = \\Theta(z(m,n, H_1) + z(m,n,\nH_2))$.", "AI": {"tldr": "本文研究了Erd\\H{o}s和Simonovits在1984年提出的关于二分图的问题，证明了在某些对称条件下，边粘合操作能够保持该猜想的成立性，并展示了Zarankiewicz数在边粘合下的可加性。", "motivation": "研究Erd\\H{o}s和Simonovits提出的关于二分图的猜想，探索边粘合操作对该猜想的影响，并验证Zarankiewicz数在边粘合下的行为。", "method": "通过边粘合操作将满足猜想的两个图$H_1$和$H_2$粘合，验证粘合后的图是否仍满足猜想；同时研究Zarankiewicz数在边粘合下的可加性。", "result": "证明了在温和的对称条件下，边粘合操作能够保持猜想的成立性；同时展示了Zarankiewicz数在边粘合下具有可加性，即$z(m,n, H) = \\Theta(z(m,n, H_1) + z(m,n, H_2))$。", "conclusion": "边粘合操作在满足一定条件时能够保持Erd\\H{o}s和Simonovits猜想的成立性，且Zarankiewicz数在边粘合下表现出可加性，为相关图论问题的研究提供了新的工具和视角。"}}
{"id": "2507.16229", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16229", "abs": "https://arxiv.org/abs/2507.16229", "authors": ["Bo Wen", "Chen Wang", "Qiwei Han", "Raquel Norel", "Julia Liu", "Thaddeus Stappenbeck", "Jeffrey L. Rogers"], "title": "Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery", "comment": "IEEE International Conference on Digital Health (ICDH) 2025", "summary": "The integration of voice-based AI agents in healthcare presents a\ntransformative opportunity to bridge economic and accessibility gaps in digital\nhealth delivery. This paper explores the role of large language model\n(LLM)-powered voice assistants in enhancing preventive care and continuous\npatient monitoring, particularly in underserved populations. Drawing insights\nfrom the development and pilot study of Agent PULSE (Patient Understanding and\nLiaison Support Engine) -- a collaborative initiative between IBM Research,\nCleveland Clinic Foundation, and Morehouse School of Medicine -- we present an\neconomic model demonstrating how AI agents can provide cost-effective\nhealthcare services where human intervention is economically unfeasible. Our\npilot study with 33 inflammatory bowel disease patients revealed that 70\\%\nexpressed acceptance of AI-driven monitoring, with 37\\% preferring it over\ntraditional modalities. Technical challenges, including real-time\nconversational AI processing, integration with healthcare systems, and privacy\ncompliance, are analyzed alongside policy considerations surrounding\nregulation, bias mitigation, and patient autonomy. Our findings suggest that\nAI-driven voice agents not only enhance healthcare scalability and efficiency\nbut also improve patient engagement and accessibility. For healthcare\nexecutives, our cost-utility analysis demonstrates huge potential savings for\nroutine monitoring tasks, while technologists can leverage our framework to\nprioritize improvements yielding the highest patient impact. By addressing\ncurrent limitations and aligning AI development with ethical and regulatory\nframeworks, voice-based AI agents can serve as a critical entry point for\nequitable, sustainable digital healthcare solutions.", "AI": {"tldr": "本文探讨了基于大型语言模型（LLM）的语音助手在医疗保健中的作用，特别是在预防性护理和持续患者监测方面。通过Agent PULSE的开发和试点研究，展示了AI代理在经济不可行的情况下提供经济高效的医疗服务。试点研究表明，患者对AI驱动的监测接受度高，且AI语音代理能提升医疗可扩展性、效率和患者参与度。", "motivation": "语音AI代理在医疗保健中的整合为弥合数字健康服务的经济和可及性差距提供了变革性机会。特别是在服务不足的人群中，AI驱动的语音助手可以增强预防性护理和持续患者监测。", "method": "研究通过Agent PULSE（患者理解与联络支持引擎）的开发和试点研究，结合IBM Research、克利夫兰诊所基金会和莫尔豪斯医学院的合作，提出了一个经济模型。试点研究涉及33名炎症性肠病患者，评估了他们对AI驱动监测的接受度和偏好。", "result": "试点研究显示，70%的患者接受AI驱动的监测，37%的患者更喜欢AI监测而非传统方式。成本效用分析表明，AI代理在常规监测任务中具有巨大的潜在节省，同时提升了患者参与度和可及性。", "conclusion": "AI驱动的语音代理不仅能提升医疗保健的可扩展性和效率，还能改善患者参与度和可及性。通过解决当前的技术挑战并与伦理和监管框架对齐，语音AI代理可以成为公平、可持续的数字医疗解决方案的关键入口。"}}
{"id": "2507.16280", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16280", "abs": "https://arxiv.org/abs/2507.16280", "authors": ["Tianze Xu", "Pengrui Lu", "Lyumanshan Ye", "Xiangkun Hu", "Pengfei Liu"], "title": "ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientific Inquiry", "comment": "22 pages, 3 figures", "summary": "The emergence of deep research systems presents significant capabilities in\nproblem-solving, extending from basic queries to sophisticated research tasks.\nHowever, existing benchmarks primarily evaluate these systems as agents for web\nretrieval and report generation, overlooking their potential to discover novel\ninsights on the frontiers of scientific research. To address this gap, we\nintroduce ResearcherBench, the first benchmark focused on evaluating the\ncapabilities of these advanced, agentic systems - which we refer to as Deep AI\nResearch Systems (DARS) - on frontier AI scientific questions. We compiled a\ndataset of 65 research questions expertly selected from real-world scientific\nscenarios such as laboratory discussions and interviews, spanning 35 different\nAI subjects and categorized into three types: technical details, literature\nreview, and open consulting. Our dual evaluation framework combines rubric\nassessment, which uses expert-designed criteria to evaluate insight quality,\nwith factual assessment, which measures citation accuracy (faithfulness) and\ncoverage (groundedness). We evaluated several leading commercial DARS and\nbaseline systems. Results show that OpenAI Deep Research and Gemini Deep\nResearch significantly outperform other systems, with particular strength in\nopen-ended consulting questions. Such capabilities represent a meaningful step\ntoward AI self-improvement, aligning with the vision of ASI for AI. We\nopen-source ResearcherBench to provide a standardized platform for promoting\nthe development of next-generation AI research assistants, hoping to foster a\nnew perspective in AI research evaluation for a novel pattern of scientific\ncollaboration: https://github.com/GAIR-NLP/ResearcherBench.", "AI": {"tldr": "研究者推出首个评估深度AI研究系统（DARS）在科学前沿问题表现的新基准ResearcherBench，包含65个跨35个AI领域的问题，采用双评估框架验证系统性能，结果显示OpenAI和Gemini的深度研究系统表现最优。", "motivation": "现有基准主要评估AI系统的网络检索和报告生成能力，忽视了其在科学前沿发现新见解的潜力，因此需要开发专门评估DARS在科研问题解决能力的基准。", "method": "构建包含65个真实科研场景问题的数据集，分为技术细节、文献综述和开放咨询三类；采用结合专家设计的标准评估见解质量（评分制）与引用准确性/覆盖度（事实核查）的双重评估框架。", "result": "OpenAI Deep Research和Gemini Deep Research在开放咨询类问题中显著优于其他系统，展现了AI自我改进的重要进展，其能力与人工超级智能（ASI）愿景相契合。", "conclusion": "开源ResearcherBench旨在为下一代AI研究助手开发提供标准化平台，推动以AI为协作主体的新型科研评估范式，促进科学合作模式的革新。"}}
{"id": "2507.16296", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16296", "abs": "https://arxiv.org/abs/2507.16296", "authors": ["Cairong Zhao", "Yufeng Jin", "Zifan Song", "Haonan Chen", "Duoqian Miao", "Guosheng Hu"], "title": "Cross-Modal Distillation For Widely Differing Modalities", "comment": "14 pages, 9 figures", "summary": "Deep learning achieved great progress recently, however, it is not easy or\nefficient to further improve its performance by increasing the size of the\nmodel. Multi-modal learning can mitigate this challenge by introducing richer\nand more discriminative information as input. To solve the problem of limited\naccess to multi-modal data at the time of use, we conduct multi-modal learning\nby introducing a teacher model to transfer discriminative knowledge to a\nstudent model during training. However, this knowledge transfer via\ndistillation is not trivial because the big domain gap between the widely\ndiffering modalities can easily lead to overfitting. In this work, we introduce\na cross-modal distillation framework. Specifically, we find hard constrained\nloss, e.g. l2 loss forcing the student being exact the same as the teacher, can\neasily lead to overfitting in cross-modality distillation. To address this, we\npropose two soft constrained knowledge distillation strategies at the feature\nlevel and classifier level respectively. In addition, we propose a\nquality-based adaptive weights module to weigh input samples via quantified\ndata quality, leading to robust model training. We conducted experiments on\nspeaker recognition and image classification tasks, and the results show that\nour approach is able to effectively achieve knowledge transfer between the\ncommonly used and widely differing modalities of image, text, and speech.", "AI": {"tldr": "本文提出了一种跨模态蒸馏框架，通过软约束知识蒸馏策略和基于质量的自适应权重模块，有效解决了多模态学习中因领域差异大导致的过拟合问题，并在说话人识别和图像分类任务中验证了其有效性。", "motivation": "深度学习性能提升面临模型规模扩大的效率瓶颈，多模态学习通过引入更丰富的输入信息缓解此问题。但实际应用中多模态数据获取受限，且跨模态蒸馏因领域差异大易导致过拟合，亟需新的解决方案。", "method": "1) 提出特征级和分类器级两种软约束知识蒸馏策略，替代易导致过拟合的硬约束损失（如l2损失）；2) 设计基于质量的自适应权重模块，通过量化数据质量对样本加权，提升模型鲁棒性。", "result": "在说话人识别和图像分类任务上的实验表明，该方法能有效实现图像、文本、语音等差异显著模态间的知识迁移。", "conclusion": "所提出的跨模态蒸馏框架通过软约束蒸馏和自适应加权机制，显著提升了多模态知识迁移效果，为突破单一模态性能瓶颈提供了新思路。"}}
{"id": "2507.16322", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16322", "abs": "https://arxiv.org/abs/2507.16322", "authors": ["Fred Mutisya", "Shikoh Gitau", "Christine Syovata", "Diana Oigara", "Ibrahim Matende", "Muna Aden", "Munira Ali", "Ryan Nyotu", "Diana Marion", "Job Nyangena", "Nasubo Ongoma", "Keith Mbae", "Elizabeth Wamicha", "Eric Mibuari", "Jean Philbert Nsengemana", "Talkmore Chidede"], "title": "Mind the Gap: Evaluating the Representativeness of Quantitative Medical Language Reasoning LLM Benchmarks for African Disease Burdens", "comment": "Preprint. 26 pages, includes appendix and tables", "summary": "Introduction: Existing medical LLM benchmarks largely reflect examination\nsyllabi and disease profiles from high income settings, raising questions about\ntheir validity for African deployment where malaria, HIV, TB, sickle cell\ndisease and other neglected tropical diseases (NTDs) dominate burden and\nnational guidelines drive care. Methodology: We systematically reviewed 31\nquantitative LLM evaluation papers (Jan 2019 May 2025) identifying 19 English\nmedical QA benchmarks. Alama Health QA was developed using a retrieval\naugmented generation framework anchored on the Kenyan Clinical Practice\nGuidelines. Six widely used sets (AfriMedQA, MMLUMedical, PubMedQA, MedMCQA,\nMedQAUSMLE, and guideline grounded Alama Health QA) underwent harmonized\nsemantic profiling (NTD proportion, recency, readability, lexical diversity\nmetrics) and blinded expert rating across five dimensions: clinical relevance,\nguideline alignment, clarity, distractor plausibility, and language/cultural\nfit. Results: Alama Health QA captured >40% of all NTD mentions across corpora\nand the highest within set frequencies for malaria (7.7%), HIV (4.1%), and TB\n(5.2%); AfriMedQA ranked second but lacked formal guideline linkage. Global\nbenchmarks showed minimal representation (e.g., sickle cell disease absent in\nthree sets) despite large scale. Qualitatively, Alama scored highest for\nrelevance and guideline alignment; PubMedQA lowest for clinical utility.\nDiscussion: Quantitative medical LLM benchmarks widely used in the literature\nunderrepresent African disease burdens and regulatory contexts, risking\nmisleading performance claims. Guideline anchored, regionally curated resources\nsuch as Alama Health QA and expanded disease specific derivatives are essential\nfor safe, equitable model evaluation and deployment across African health\nsystems.", "AI": {"tldr": "现有医学大语言模型（LLM）基准主要反映高收入国家的考试大纲和疾病概况，对非洲部署的有效性存疑。研究开发了基于肯尼亚临床实践指南的Alama Health QA基准，发现全球基准对非洲疾病负担代表不足，需区域定制资源以确保公平评估。", "motivation": "当前医学LLM基准多基于高收入国家数据，无法准确反映以疟疾、HIV、结核病等为主的非洲疾病负担，可能导致模型评估偏差。", "method": "系统回顾31篇定量LLM评估论文，开发基于肯尼亚指南的Alama Health QA基准，并对6个基准进行语义分析和专家盲评（临床相关性、指南一致性等5维度）。", "result": "Alama Health QA在NTD覆盖率（40%）、疟疾（7.7%）、HIV（4.1%）等非洲高发疾病表现最佳，且指南一致性评分最高；全球基准对镰状细胞病等疾病代表严重不足。", "conclusion": "广泛使用的医学LLM基准低估非洲疾病负担，基于区域指南的定制化资源（如Alama Health QA）对非洲医疗系统的公平模型评估至关重要。"}}
{"id": "2507.16334", "categories": ["cs.AI", "cs.LG", "math.DG"], "pdf": "https://arxiv.org/pdf/2507.16334", "abs": "https://arxiv.org/abs/2507.16334", "authors": ["Alexander Strunk", "Roland Assam"], "title": "Higher Gauge Flow Models", "comment": null, "summary": "This paper introduces Higher Gauge Flow Models, a novel class of Generative\nFlow Models. Building upon ordinary Gauge Flow Models (arXiv:2507.13414), these\nHigher Gauge Flow Models leverage an L$_{\\infty}$-algebra, effectively\nextending the Lie Algebra. This expansion allows for the integration of the\nhigher geometry and higher symmetries associated with higher groups into the\nframework of Generative Flow Models. Experimental evaluation on a Gaussian\nMixture Model dataset revealed substantial performance improvements compared to\ntraditional Flow Models.", "AI": {"tldr": "本文提出了一种新型生成流模型——高阶规范流模型，通过引入L$_{\\infty}$-代数扩展了传统规范流模型，显著提升了在混合高斯数据集上的性能表现。", "motivation": "旨在将高阶几何与高阶对称性融入生成流模型框架，以突破传统流模型的局限性。", "method": "基于普通规范流模型（arXiv:2507.13414），利用L$_{\\infty}$-代数扩展李代数结构，构建高阶规范流模型。", "result": "在混合高斯数据集上的实验表明，该模型相较传统流模型有显著性能提升。", "conclusion": "高阶规范流模型通过引入高阶代数结构，为生成流模型提供了更强大的几何与对称性表达能力。"}}
{"id": "2507.16356", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16356", "abs": "https://arxiv.org/abs/2507.16356", "authors": ["Arpan Dasgupta", "Mizhaan Maniyar", "Awadhesh Srivastava", "Sanat Kumar", "Amrita Mahale", "Aparna Hedge", "Arun Suggala", "Karthikeyan Shanmugam", "Aparna Taneja", "Milind Tambe"], "title": "Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for Improved Message Delivery in Mobile Maternal Health", "comment": null, "summary": "Mobile health (mHealth) programs utilize automated voice messages to deliver\nhealth information, particularly targeting underserved communities,\ndemonstrating the effectiveness of using mobile technology to disseminate\ncrucial health information to these populations, improving health outcomes\nthrough increased awareness and behavioral change. India's Kilkari program\ndelivers vital maternal health information via weekly voice calls to millions\nof mothers. However, the current random call scheduling often results in missed\ncalls and reduced message delivery. This study presents a field trial of a\ncollaborative bandit algorithm designed to optimize call timing by learning\nindividual mothers' preferred call times. We deployed the algorithm with around\n$6500$ Kilkari participants as a pilot study, comparing its performance to the\nbaseline random calling approach. Our results demonstrate a statistically\nsignificant improvement in call pick-up rates with the bandit algorithm,\nindicating its potential to enhance message delivery and impact millions of\nmothers across India. This research highlights the efficacy of personalized\nscheduling in mobile health interventions and underscores the potential of\nmachine learning to improve maternal health outreach at scale.", "AI": {"tldr": "研究通过协作式多臂老虎机算法优化印度Kilkari项目的语音呼叫时间，显著提高了孕妇接听率，展示了机器学习在提升移动健康干预效果中的潜力。", "motivation": "当前Kilkari项目随机呼叫模式导致大量未接来电，降低了母婴健康信息的传递效率，需通过个性化调度提升服务效果。", "method": "对6500名参与者进行实地试验，采用协作式多臂老虎机算法学习个体偏好呼叫时间，并与随机呼叫基线进行对比。", "result": "算法使接听率实现统计学显著提升，验证了个性化调度对改善健康信息传递的有效性。", "conclusion": "研究表明机器学习驱动的个性化调度可大规模优化移动健康干预，对提升印度母婴健康覆盖具有重要实践意义。"}}
{"id": "2507.16395", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16395", "abs": "https://arxiv.org/abs/2507.16395", "authors": ["Bo Hou", "Xin Tan", "Kai Zheng", "Fang Liu", "Yinghao Zhu", "Li Zhang"], "title": "LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning", "comment": null, "summary": "Atomic commits, each of which addresses a single development concern, are a\nbest practice in software development. However, developers frequently produce\ntangled commits that mix unrelated changes due to practical constraints or\nunclear boundaries, negatively impacting code review and maintenance. Although\nprior commit untangling approaches: rule-based, feature-based, or graph-based,\nhave made progress, they often rely on shallow signals and fail to distinguish\nbetween explicit dependencies (e.g., control/data flow) and implicit ones\n(e.g., semantic or conceptual relationships). In this paper, we propose\nColaUntangle, a new collaborative consultation framework for commit untangling\nthat models both explicit and implicit dependencies among code changes.\nColaUntangle integrates Large Language Model (LLM)-driven agents in a\nmulti-agent architecture: one agent specializes in explicit dependencies,\nanother in implicit ones, and a reviewer agent synthesizes their perspectives\nthrough iterative consultation. To capture explicit and implicit contextual\ninformation, we construct multi-version Program Dependency Graphs (delta-PDG),\nenabling agents to reason over code relationships with both symbolic and\nsemantic depth. We evaluate ColaUntangle on two widely-used datasets (1,612 C#\nand 14k Java tangled commits). Experimental results show that ColaUntangle\noutperforms the best-performing baseline, achieving an improvement of 44% on\nthe C# dataset and 100% on the Java dataset. These findings highlight the\npotential of LLM-based collaborative frameworks for advancing automated commit\nuntangling tasks.", "AI": {"tldr": "本文提出ColaUntangle框架，利用多智能体协作建模代码变更中的显式和隐式依赖，显著提升解缠提交的性能。", "motivation": "开发中常出现混杂多个变更的提交（tangled commits），现有解缠方法依赖浅层信号且无法区分显式（如控制流）与隐式（如语义）依赖，影响代码审查和维护。", "method": "构建多版本程序依赖图（delta-PDG），通过LLM驱动的多智能体架构（显式/隐式依赖分析器+评审器）进行迭代协商，综合符号与语义深度推理。", "result": "在C#（1,612提交）和Java（14k提交）数据集上分别实现44%和100%的性能提升，超越现有最佳基线。", "conclusion": "基于LLM的协作框架为自动化提交解缠任务提供了新方向，显式与隐式依赖的联合建模是关键突破。"}}
{"id": "2507.16405", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16405", "abs": "https://arxiv.org/abs/2507.16405", "authors": ["Stassa Patsantzis"], "title": "Self-Supervised Inductive Logic Programming", "comment": null, "summary": "Inductive Logic Programming (ILP) approaches like Meta \\-/ Interpretive\nLearning (MIL) can learn, from few examples, recursive logic programs with\ninvented predicates that generalise well to unseen instances. This ability\nrelies on a background theory and negative examples, both carefully selected\nwith expert knowledge of a learning problem and its solutions. But what if such\na problem-specific background theory or negative examples are not available? We\nformalise this question as a new setting for Self-Supervised ILP and present a\nnew MIL algorithm that learns in the new setting from some positive labelled,\nand zero or more unlabelled examples, and automatically generates, and labels,\nnew positive and negative examples during learning. We implement this algorithm\nin Prolog in a new MIL system, called Poker. We compare Poker to\nstate-of-the-art MIL system Louise on experiments learning grammars for\nContext-Free and L-System languages from labelled, positive example strings, no\nnegative examples, and just the terminal vocabulary of a language, seen in\nexamples, as a first-order background theory. We introduce a new approach for\nthe principled selection of a second-order background theory as a Second Order\nDefinite Normal Form (SONF), sufficiently general to learn all programs in a\nclass, thus removing the need for a backgound theory tailored to a learning\ntask. We find that Poker's performance improves with increasing numbers of\nautomatically generated examples while Louise, bereft of negative examples,\nover-generalises.", "AI": {"tldr": "本文提出了一种自监督归纳逻辑编程（ILP）新方法Poker，能在缺乏问题特定背景理论和负例的情况下，通过自动生成标注样本学习递归逻辑程序。", "motivation": "传统ILP方法（如MIL）依赖专家精心设计的背景理论和负例，但实际场景中这些资源往往不可得。研究旨在解决这一限制，探索无监督环境下的程序学习。", "method": "开发了Poker系统：1) 仅需正例和未标注样本；2) 自动生成并标注新正/负例；3) 采用二阶正规形式（SONF）作为通用背景理论，无需任务定制。", "result": "实验表明：1) Poker在CFG和L-System语法学习任务中表现优于Louise；2) 自动生成样本数量与性能正相关；3) 缺乏负例会导致Louise过拟合。", "conclusion": "通过自监督样本生成和通用二阶理论，Poker实现了无专家干预的程序归纳，为ILP在资源受限场景的应用提供了新范式。"}}
{"id": "2507.16414", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16414", "abs": "https://arxiv.org/abs/2507.16414", "authors": ["Hongyi Tang", "Zhihao Zhu", "Yi Yang"], "title": "Identifying Pre-training Data in LLMs: A Neuron Activation-Based Detection Framework", "comment": null, "summary": "The performance of large language models (LLMs) is closely tied to their\ntraining data, which can include copyrighted material or private information,\nraising legal and ethical concerns. Additionally, LLMs face criticism for\ndataset contamination and internalizing biases. To address these issues, the\nPre-Training Data Detection (PDD) task was proposed to identify if specific\ndata was included in an LLM's pre-training corpus. However, existing PDD\nmethods often rely on superficial features like prediction confidence and loss,\nresulting in mediocre performance. To improve this, we introduce NA-PDD, a\nnovel algorithm analyzing differential neuron activation patterns between\ntraining and non-training data in LLMs. This is based on the observation that\nthese data types activate different neurons during LLM inference. We also\nintroduce CCNewsPDD, a temporally unbiased benchmark employing rigorous data\ntransformations to ensure consistent time distributions between training and\nnon-training data. Our experiments demonstrate that NA-PDD significantly\noutperforms existing methods across three benchmarks and multiple LLMs.", "AI": {"tldr": "本文提出NA-PDD算法，通过分析LLM中训练与非训练数据的神经元激活差异来改进预训练数据检测，并引入CCNewsPDD基准验证其优越性。", "motivation": "大型语言模型(LLM)的训练数据可能包含版权内容或隐私信息，现有预训练数据检测(PDD)方法依赖表面特征导致性能不佳，需开发更精准的检测技术。", "method": "提出NA-PDD算法，基于'训练/非训练数据会激活不同神经元'的观察，分析LLM推理时的神经元激活差异；同时构建CCNewsPDD基准，通过数据变换确保时间分布一致性。", "result": "实验表明NA-PDD在三个基准测试和多种LLM上显著优于现有方法，CCNewsPDD有效解决了时间偏差问题。", "conclusion": "NA-PDD通过神经元激活模式分析实现了更精准的预训练数据检测，CCNewsPDD为未来研究提供了可靠的评估基准。"}}
{"id": "2507.16434", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16434", "abs": "https://arxiv.org/abs/2507.16434", "authors": ["Stassa Patsantzis"], "title": "From model-based learning to model-free behaviour with Meta-Interpretive Learning", "comment": null, "summary": "A \"model\" is a theory that describes the state of an environment and the\neffects of an agent's decisions on the environment. A model-based agent can use\nits model to predict the effects of its future actions and so plan ahead, but\nmust know the state of the environment. A model-free agent cannot plan, but can\nact without a model and without completely observing the environment. An\nautonomous agent capable of acting independently in novel environments must\ncombine both sets of capabilities. We show how to create such an agent with\nMeta-Interpretive Learning used to learn a model-based Solver used to train a\nmodel-free Controller that can solve the same planning problems as the Solver.\nWe demonstrate the equivalence in problem-solving ability of the two agents on\ngrid navigation problems in two kinds of environment: randomly generated mazes,\nand lake maps with wide open areas. We find that all navigation problems solved\nby the Solver are also solved by the Controller, indicating the two are\nequivalent.", "AI": {"tldr": "论文提出了一种结合基于模型和无模型方法的自主智能体，通过元解释学习训练基于模型的求解器，进而训练无模型控制器，实现在新环境中的独立行动能力。", "motivation": "自主智能体需兼具基于模型（可规划但需环境状态）和无模型（无需模型但无法规划）的能力，以在未知环境中独立行动。", "method": "采用元解释学习（Meta-Interpretive Learning）训练基于模型的求解器（Solver），再用其训练无模型控制器（Controller），使两者解决相同的规划问题。", "result": "在随机生成迷宫和开阔湖泊地图两类环境中测试网格导航问题，控制器能解决求解器所有问题，表明两者能力等效。", "conclusion": "实验证明，通过该方法训练的无模型控制器与基于模型求解器在问题解决能力上完全等价，为自主智能体设计提供了新途径。"}}
{"id": "2507.16454", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.16454", "abs": "https://arxiv.org/abs/2507.16454", "authors": ["Pierangela Bruno", "Carmine Dodaro", "Giuseppe Galatà", "Marco Maratea", "Marco Mochi"], "title": "Improving ASP-based ORS Schedules through Machine Learning Predictions", "comment": "17 pages, International Conference on Logic Programming, Under\n  consideration in Theory and Practice of Logic Programming (TPLP)", "summary": "The Operating Room Scheduling (ORS) problem deals with the optimization of\ndaily operating room surgery schedules. It is a challenging problem subject to\nmany constraints, like to determine the starting time of different surgeries\nand allocating the required resources, including the availability of beds in\ndifferent department units. Recently, solutions to this problem based on Answer\nSet Programming (ASP) have been delivered. Such solutions are overall\nsatisfying but, when applied to real data, they can currently only verify\nwhether the encoding aligns with the actual data and, at most, suggest\nalternative schedules that could have been computed. As a consequence, it is\nnot currently possible to generate provisional schedules. Furthermore, the\nresulting schedules are not always robust.\n  In this paper, we integrate inductive and deductive techniques for solving\nthese issues. We first employ machine learning algorithms to predict the\nsurgery duration, from historical data, to compute provisional schedules. Then,\nwe consider the confidence of such predictions as an additional input to our\nproblem and update the encoding correspondingly in order to compute more robust\nschedules. Results on historical data from the ASL1 Liguria in Italy confirm\nthe viability of our integration.\n  Under consideration in Theory and Practice of Logic Programming (TPLP).", "AI": {"tldr": "本文提出了一种结合归纳与演绎技术的手术室调度优化方法，通过机器学习预测手术时长并生成临时排程，同时考虑预测置信度以提高排程鲁棒性。", "motivation": "现有基于答案集编程（ASP）的手术室调度方案虽总体满意，但无法生成临时排程且排程鲁棒性不足，需结合新方法解决这些问题。", "method": "首先利用机器学习算法从历史数据预测手术时长以生成临时排程，随后将预测置信度作为额外输入参数更新ASP编码以增强排程鲁棒性。", "result": "在意大利ASL1 Liguria历史数据上的实验证实了该集成方法的可行性。", "conclusion": "结合机器学习与ASP的混合方法能有效提升手术室调度的灵活性与鲁棒性，为实际应用提供了新思路。"}}
{"id": "2507.16473", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.16473", "abs": "https://arxiv.org/abs/2507.16473", "authors": ["Chang Li", "Yaren Zhang", "Haoran Lv", "Qiong Cao", "Chao Xue", "Xiaodong He"], "title": "Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs", "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable reasoning ability through\nexplicit Chain-of-Thought (CoT) prompting, but generating these step-by-step\ntextual explanations is computationally expensive and slow. To overcome this,\nwe aim to develop a framework for efficient, implicit reasoning, where the\nmodel \"thinks\" in a latent space without generating explicit text for every\nstep. We propose that these latent thoughts can be modeled as\ntemporally-extended abstract actions, or options, within a hierarchical\nreinforcement learning framework. To effectively learn a diverse library of\noptions as latent embeddings, we first introduce the Variational Markovian\nOption Critic (VMOC), an off-policy algorithm that uses variational inference\nwithin the HiT-MDP framework. To provide a rigorous foundation for using these\noptions as an abstract reasoning space, we extend the theory of continuous MDP\nhomomorphisms. This proves that learning a policy in the simplified, abstract\nlatent space, for which VMOC is suited, preserves the optimality of the\nsolution to the original, complex problem. Finally, we propose a cold-start\nprocedure that leverages supervised fine-tuning (SFT) data to distill human\nreasoning demonstrations into this latent option space, providing a rich\ninitialization for the model's reasoning capabilities. Extensive experiments\ndemonstrate that our approach achieves strong performance on complex logical\nreasoning benchmarks and challenging locomotion tasks, validating our framework\nas a principled method for learning abstract skills for both language and\ncontrol.", "AI": {"tldr": "提出一种基于分层强化学习的隐式推理框架VMOC，通过潜在选项空间实现高效推理，避免显式思维链生成的计算开销，在逻辑推理和运动控制任务中验证有效性。", "motivation": "大语言模型(LLM)的显式思维链(CoT)推理存在计算成本高、速度慢的问题，需要开发不依赖逐步文本生成的隐式推理方法。", "method": "1. 将潜在思维建模为时序扩展的抽象动作（选项）\\n2. 提出变分马尔可夫选项批判算法(VMOC)，在HiT-MDP框架内进行变分推断\\n3. 扩展连续MDP同态理论保证潜在空间策略最优性\\n4. 设计冷启动流程，通过监督微调数据将人类推理蒸馏至潜在选项空间", "result": "在复杂逻辑推理基准和运动控制任务中表现优异，验证了该框架作为学习语言与控制抽象技能的原则性方法的有效性。", "conclusion": "VMOC框架为隐式推理提供了理论保障和实用算法，通过潜在选项空间实现高效抽象推理，可同时应用于语言和物理控制领域。"}}
{"id": "2507.16478", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16478", "abs": "https://arxiv.org/abs/2507.16478", "authors": ["Shreya Saxena", "Siva Prasad", "Zishan Ahmad", "Vishal Vaddina"], "title": "ACT: Bridging the Gap in Code Translation through Synthetic Data Generation & Adaptive Training", "comment": null, "summary": "Code translation is a crucial process in software development and migration\nprojects, enabling interoperability between different programming languages and\nenhancing software adaptability and thus longevity. Traditional automated\ntranslation methods rely heavily on handcrafted transformation rules, which\noften lack flexibility and scalability. Meanwhile, advanced language models\npresent promising alternatives but are often limited by proprietary, API-based\nimplementations that raise concerns over data security and reliance. In this\npaper, we present Auto-Train for Code Translation (ACT), an innovative\nframework that aims to improve code translation capabilities by enabling\nin-house finetuning of open-source Large Language Models (LLMs). ACT's\nautomated pipeline significantly boosts the performance of these models,\nnarrowing the gap between open-source accessibility and the high performance of\nclosed-source solutions. Central to ACT is its synthetic data generation\nmodule, which builds extensive, high-quality datasets from initial code\nsamples, incorporating unit tests to ensure functional accuracy and diversity.\nACT's evaluation framework incorporates execution-level checks, offering a\ncomprehensive assessment of translation quality. A key feature in ACT is its\ncontroller module, which manages the entire pipeline by dynamically adjusting\nhyperparameters, orchestrating iterative data generation, and finetuning based\non real-time evaluations. This enables ACT to intelligently optimize when to\ncontinue training, generate additional targeted training data, or stop the\nprocess. Our results demonstrate that ACT consistently enhances the\neffectiveness of open-source models, offering businesses and developers a\nsecure and reliable alternative. Additionally, applying our data generation\npipeline to industry-scale migration projects has led to a notable increase in\ndeveloper acceleration.", "AI": {"tldr": "本文提出了一种名为Auto-Train for Code Translation (ACT)的创新框架，通过内部微调开源大型语言模型(LLMs)来提升代码翻译能力。ACT通过自动化流程显著提高模型性能，缩小开源与闭源解决方案之间的差距。", "motivation": "传统代码翻译方法依赖手工转换规则，缺乏灵活性和可扩展性；而高级语言模型虽前景广阔，但受限于基于API的专有实现，存在数据安全和依赖性问题。ACT旨在解决这些问题。", "method": "ACT框架包含合成数据生成模块（从初始代码样本构建高质量数据集，整合单元测试确保功能准确性）、评估框架（执行级检查全面评估翻译质量）和控制器模块（动态调整超参数，协调迭代数据生成和微调）。", "result": "实验表明，ACT能持续提升开源模型效能，为开发者提供安全可靠的替代方案。其数据生成流程在工业级迁移项目中的应用显著加速了开发进程。", "conclusion": "ACT通过自动化微调流程和智能优化机制，有效增强了开源代码翻译模型的性能，为软件开发迁移提供了兼具安全性与高性能的解决方案。"}}
{"id": "2507.16507", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.16507", "abs": "https://arxiv.org/abs/2507.16507", "authors": ["Jean Lelong", "Adnane Errazine", "Annabelle Blangero"], "title": "Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications", "comment": "ECAI 2025 demo track, 4 pages", "summary": "Conventional Retrieval-Augmented Generation (RAG) systems enhance Large\nLanguage Models (LLMs) but often fall short on complex queries, delivering\nlimited, extractive answers and struggling with multiple targeted retrievals or\nnavigating intricate entity relationships. This is a critical gap in\nknowledge-intensive domains. We introduce INRAExplorer, an agentic RAG system\nfor exploring the scientific data of INRAE (France's National Research\nInstitute for Agriculture, Food and Environment). INRAExplorer employs an\nLLM-based agent with a multi-tool architecture to dynamically engage a rich\nknowledge base, through a comprehensive knowledge graph derived from open\naccess INRAE publications. This design empowers INRAExplorer to conduct\niterative, targeted queries, retrieve exhaustive datasets (e.g., all\npublications by an author), perform multi-hop reasoning, and deliver\nstructured, comprehensive answers. INRAExplorer serves as a concrete\nillustration of enhancing knowledge interaction in specialized fields.", "AI": {"tldr": "INRAExplorer是一种基于代理的检索增强生成系统，旨在提升大型语言模型在复杂查询中的表现，特别是在农业、食品和环境科学领域。", "motivation": "传统的检索增强生成系统在处理复杂查询时表现不佳，尤其是在需要多目标检索或处理复杂实体关系的知识密集型领域。", "method": "INRAExplorer采用基于大型语言模型的代理架构，结合多工具设计和知识图谱，动态访问INRAE的开放获取出版物知识库。", "result": "该系统能够执行迭代的定向查询、检索详尽的数据集（如某作者的所有出版物），进行多跳推理，并提供结构化的全面答案。", "conclusion": "INRAExplorer展示了在专业领域中增强知识交互的具体方法，为知识密集型任务提供了有效解决方案。"}}
{"id": "2507.16534", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16534", "abs": "https://arxiv.org/abs/2507.16534", "authors": ["Shanghai AI Lab", ":", "Xiaoyang Chen", "Yunhao Chen", "Zeren Chen", "Zhiyun Chen", "Hanyun Cui", "Yawen Duan", "Jiaxuan Guo", "Qi Guo", "Xuhao Hu", "Hong Huang", "Lige Huang", "Chunxiao Li", "Juncheng Li", "Qihao Lin", "Dongrui Liu", "Xinmin Liu", "Zicheng Liu", "Chaochao Lu", "Xiaoya Lu", "Jingjing Qu", "Qibing Ren", "Jing Shao", "Jingwei Shi", "Jingwei Sun", "Peng Wang", "Weibing Wang", "Jia Xu", "Lewen Yan", "Xiao Yu", "Yi Yu", "Boxuan Zhang", "Jie Zhang", "Weichen Zhang", "Zhijie Zheng", "Tianyi Zhou", "Bowen Zhou"], "title": "Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report", "comment": "97 pages, 37 figures", "summary": "To understand and identify the unprecedented risks posed by rapidly advancing\nartificial intelligence (AI) models, this report presents a comprehensive\nassessment of their frontier risks. Drawing on the E-T-C analysis (deployment\nenvironment, threat source, enabling capability) from the Frontier AI Risk\nManagement Framework (v1.0) (SafeWork-F1-Framework), we identify critical risks\nin seven areas: cyber offense, biological and chemical risks, persuasion and\nmanipulation, uncontrolled autonomous AI R\\&D, strategic deception and\nscheming, self-replication, and collusion. Guided by the \"AI-$45^\\circ$ Law,\"\nwe evaluate these risks using \"red lines\" (intolerable thresholds) and \"yellow\nlines\" (early warning indicators) to define risk zones: green (manageable risk\nfor routine deployment and continuous monitoring), yellow (requiring\nstrengthened mitigations and controlled deployment), and red (necessitating\nsuspension of development and/or deployment). Experimental results show that\nall recent frontier AI models reside in green and yellow zones, without\ncrossing red lines. Specifically, no evaluated models cross the yellow line for\ncyber offense or uncontrolled AI R\\&D risks. For self-replication, and\nstrategic deception and scheming, most models remain in the green zone, except\nfor certain reasoning models in the yellow zone. In persuasion and\nmanipulation, most models are in the yellow zone due to their effective\ninfluence on humans. For biological and chemical risks, we are unable to rule\nout the possibility of most models residing in the yellow zone, although\ndetailed threat modeling and in-depth assessment are required to make further\nclaims. This work reflects our current understanding of AI frontier risks and\nurges collective action to mitigate these challenges.", "AI": {"tldr": "本文通过E-T-C分析框架评估前沿AI模型的七大风险领域，采用\"AI-$45^\\circ$法则\"划分风险区域。结果显示所有前沿AI模型均处于绿色或黄色区域，未触及红色警戒线。", "motivation": "为理解和应对快速发展的AI模型带来的前所未有的风险，本研究旨在全面评估其前沿风险，推动集体行动以缓解这些挑战。", "method": "基于\"前沿AI风险管理框架(v1.0)\"的E-T-C（部署环境、威胁来源、赋能能力）分析法，结合\"AI-$45^\\circ$法则\"，通过红/黄线阈值划分绿（常规监控）、黄（加强管控）、红（暂停开发）三级风险区域。", "result": "所有评估模型均未突破红色警戒线：网络攻击和自主AI研发风险均未触及黄线；自我复制及战略欺骗风险多数处于绿色区域；说服操纵类模型多因对人类有效影响处于黄色区域；生化风险需进一步评估才能排除黄区可能性。", "conclusion": "该研究反映了当前对AI前沿风险的认识，强调需采取集体行动应对挑战。实验表明前沿AI模型风险总体可控，但部分领域需持续监测和强化缓解措施。"}}
{"id": "2507.16635", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16635", "abs": "https://arxiv.org/abs/2507.16635", "authors": ["Ali Mohamed Ali", "Luca Tirel", "Hashim A. Hashim"], "title": "Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems", "comment": null, "summary": "Efficient planning of activities is essential for modern industrial assembly\nlines to uphold manufacturing standards, prevent project constraint violations,\nand achieve cost-effective operations. While exact solutions to such challenges\ncan be obtained through Integer Programming (IP), the dependence of the search\nspace on input parameters often makes IP computationally infeasible for\nlarge-scale scenarios. Heuristic methods, such as Genetic Algorithms, can also\nbe applied, but they frequently produce suboptimal solutions in extensive\ncases. This paper introduces a novel mathematical model of a generic industrial\nassembly line formulated as a Markov Decision Process (MDP), without imposing\nassumptions on the type of assembly line a notable distinction from most\nexisting models. The proposed model is employed to create a virtual environment\nfor training Deep Reinforcement Learning (DRL) agents to optimize task and\nresource scheduling. To enhance the efficiency of agent training, the paper\nproposes two innovative tools. The first is an action-masking technique, which\nensures the agent selects only feasible actions, thereby reducing training\ntime. The second is a multi-agent approach, where each workstation is managed\nby an individual agent, as a result, the state and action spaces were reduced.\nA centralized training framework with decentralized execution is adopted,\noffering a scalable learning architecture for optimizing industrial assembly\nlines. This framework allows the agents to learn offline and subsequently\nprovide real-time solutions during operations by leveraging a neural network\nthat maps the current factory state to the optimal action. The effectiveness of\nthe proposed scheme is validated through numerical simulations, demonstrating\nsignificantly faster convergence to the optimal solution compared to a\ncomparable model-based approach.", "AI": {"tldr": "本文提出了一种基于马尔可夫决策过程（MDP）的通用工业装配线数学模型，并采用深度强化学习（DRL）优化任务与资源调度。通过动作屏蔽技术和多智能体方法提升训练效率，实验验证了该方案在收敛速度和求解质量上的优势。", "motivation": "传统整数规划（IP）在大规模场景下计算不可行，而启发式算法常产生次优解。需要一种不依赖装配线类型假设、可扩展的高效调度方法。", "method": "1) 建立无假设的MDP模型并构建虚拟训练环境；2) 提出动作屏蔽技术约束可行动作；3) 采用工作站级多智能体架构，通过集中训练分散执行框架降低状态/动作空间维度。", "result": "数值仿真表明：相比基于模型的方法，所提方案能更快收敛至最优解，神经网络可实时映射工厂状态至最优动作。", "conclusion": "该DRL框架为工业装配线提供了可扩展的优化方案，动作屏蔽与多智能体设计显著提升了训练效率，具有实际应用潜力。"}}
{"id": "2507.16670", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16670", "abs": "https://arxiv.org/abs/2507.16670", "authors": ["Amandeep Kaur", "Gyan Prakash"], "title": "Adaptive Inventory Strategies using Deep Reinforcement Learning for Dynamic Agri-Food Supply Chains", "comment": null, "summary": "Agricultural products are often subject to seasonal fluctuations in\nproduction and demand. Predicting and managing inventory levels in response to\nthese variations can be challenging, leading to either excess inventory or\nstockouts. Additionally, the coordination among stakeholders at various level\nof food supply chain is not considered in the existing body of literature. To\nbridge these research gaps, this study focuses on inventory management of\nagri-food products under demand and lead time uncertainties. By implementing\neffective inventory replenishment policy results in maximize the overall profit\nthroughout the supply chain. However, the complexity of the problem increases\ndue to these uncertainties and shelf-life of the product, that makes\nchallenging to implement traditional approaches to generate optimal set of\nsolutions. Thus, the current study propose a novel Deep Reinforcement Learning\n(DRL) algorithm that combines the benefits of both value- and policy-based DRL\napproaches for inventory optimization under uncertainties. The proposed\nalgorithm can incentivize collaboration among stakeholders by aligning their\ninterests and objectives through shared optimization goal of maximizing\nprofitability along the agri-food supply chain while considering perishability,\nand uncertainty simultaneously. By selecting optimal order quantities with\ncontinuous action space, the proposed algorithm effectively addresses the\ninventory optimization challenges. To rigorously evaluate this algorithm, the\nempirical data from fresh agricultural products supply chain inventory is\nconsidered. Experimental results corroborate the improved performance of the\nproposed inventory replenishment policy under stochastic demand patterns and\nlead time scenarios. The research findings hold managerial implications for\npolicymakers to manage the inventory of agricultural products more effectively\nunder uncertainty.", "AI": {"tldr": "本研究提出了一种结合价值和策略的深度强化学习算法，用于解决农产品供应链中需求和交付时间不确定性下的库存优化问题，并通过实证数据验证了其有效性。", "motivation": "农产品生产和需求的季节性波动导致库存管理困难，现有研究缺乏对供应链各利益相关方协调的考虑，亟需解决不确定性和产品易腐性带来的库存优化挑战。", "method": "提出一种新型深度强化学习(DRL)算法，融合价值型和策略型DRL方法的优势，通过连续动作空间选择最优订单量，同时考虑易腐性和不确定性以实现利益协调。", "result": "实验结果表明，该库存补货策略在随机需求模式和交付时间情景下表现优异，实证数据验证了算法在生鲜农产品供应链中的有效性。", "conclusion": "研究成果为决策者提供了在不确定性条件下更有效管理农产品库存的方法，通过利益协调机制促进供应链各方的协作优化。"}}
{"id": "2507.16727", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16727", "abs": "https://arxiv.org/abs/2507.16727", "authors": ["Zhenyun Yin", "Shujie Wang", "Xuhong Wang", "Xingjun Ma", "Yinchun Wang"], "title": "Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints", "comment": null, "summary": "Improving the reliability of large language models (LLMs) is critical for\ndeploying them in real-world scenarios. In this paper, we propose\n\\textbf{Deliberative Searcher}, the first framework to integrate certainty\ncalibration with retrieval-based search for open-domain question answering. The\nagent performs multi-step reflection and verification over Wikipedia data and\nis trained with a reinforcement learning algorithm that optimizes for accuracy\nunder a soft reliability constraint. Empirical results show that proposed\nmethod improves alignment between model confidence and correctness, leading to\nmore trustworthy outputs. This paper will be continuously updated.", "AI": {"tldr": "本文提出首个结合确定性校准与检索搜索的框架——Deliberative Searcher，通过多步反思与验证提升大语言模型在开放域问答中的可靠性。", "motivation": "提高大语言模型（LLMs）的可靠性对其实际应用至关重要。", "method": "提出Deliberative Searcher框架，基于维基百科数据进行多步反思与验证，并采用强化学习算法优化准确性及软可靠性约束。", "result": "实验结果表明，该方法有效提升了模型置信度与正确性的对齐，生成结果更可信。", "conclusion": "该框架显著增强了大语言模型输出的可信度，论文将持续更新。"}}
{"id": "2507.16768", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16768", "abs": "https://arxiv.org/abs/2507.16768", "authors": ["Ran Wang", "Xiaoxuan Liu", "Hao Ren", "Gang Chen", "Fanchao Qi", "Maosong Sun"], "title": "WGRAMMAR: Leverage Prior Knowledge to Accelerate Structured Decoding", "comment": null, "summary": "Structured decoding enables large language models (LLMs) to generate outputs\nin formats required by downstream systems, such as HTML or JSON. However,\nexisting methods suffer from efficiency bottlenecks due to grammar compilation,\nstate tracking, and mask creation. We observe that many real-world tasks embed\nstrong prior knowledge about output structure. Leveraging this, we propose a\ndecomposition of constraints into static and dynamic components -- precompiling\nstatic structures offline and instantiating dynamic arguments at runtime using\ngrammar snippets. Instead of relying on pushdown automata, we employ a\ncompositional set of operators to model regular formats, achieving lower\ntransition latency. We introduce wgrammar, a lightweight decoding engine that\nintegrates domain-aware simplification, constraint decomposition, and mask\ncaching, achieving up to 250x speedup over existing systems. wgrammar's source\ncode is publicly available at https://github.com/wrran/wgrammar.", "AI": {"tldr": "提出wgrammar解码引擎，通过分解静态与动态约束实现高效结构化输出，速度提升250倍。", "motivation": "现有结构化解码方法因语法编译、状态跟踪和掩码生成导致效率瓶颈，而实际任务中输出结构通常具有强先验知识。", "method": "将约束分解为静态（离线预编译）和动态（运行时用语法片段实例化），采用组合运算符建模规则格式，集成领域感知简化、约束分解和掩码缓存。", "result": "wgrammar实现最高250倍加速，代码已开源。", "conclusion": "通过约束分解与轻量级操作符设计，显著提升结构化解码效率，适用于JSON/HTML等格式生成场景。"}}
{"id": "2507.16792", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16792", "abs": "https://arxiv.org/abs/2507.16792", "authors": ["Roman Mayr", "Michel Schimpf", "Thomas Bohné"], "title": "ChatChecker: A Framework for Dialogue System Testing and Evaluation Through Non-cooperative User Simulation", "comment": null, "summary": "While modern dialogue systems heavily rely on large language models (LLMs),\ntheir implementation often goes beyond pure LLM interaction. Developers\nintegrate multiple LLMs, external tools, and databases. Therefore, assessment\nof the underlying LLM alone does not suffice, and the dialogue systems must be\ntested and evaluated as a whole. However, this remains a major challenge. With\nmost previous work focusing on turn-level analysis, less attention has been\npaid to integrated dialogue-level quality assurance. To address this, we\npresent ChatChecker, a framework for automated evaluation and testing of\ncomplex dialogue systems. ChatChecker uses LLMs to simulate diverse user\ninteractions, identify dialogue breakdowns, and evaluate quality. Compared to\nprevious approaches, our design reduces setup effort and is generalizable, as\nit does not require reference dialogues and is decoupled from the\nimplementation of the target dialogue system. We improve breakdown detection\nperformance over a prior LLM-based approach by including an error taxonomy in\nthe prompt. Additionally, we propose a novel non-cooperative user simulator\nbased on challenging personas that uncovers weaknesses in target dialogue\nsystems more effectively. Through this, ChatChecker contributes to thorough and\nscalable testing. This enables both researchers and practitioners to accelerate\nthe development of robust dialogue systems.", "AI": {"tldr": "本文提出ChatChecker框架，用于自动化评估和测试复杂对话系统，通过LLM模拟多样化用户交互并识别对话故障，提升系统鲁棒性。", "motivation": "现代对话系统依赖大语言模型（LLM），但实际部署常整合多LLM、外部工具和数据库，仅评估底层LLM不足，需整体测试。现有研究多关注单轮分析，缺乏对话级质量保障。", "method": "ChatChecker框架利用LLM模拟用户交互（含对抗性角色），结合错误分类提示提升故障检测，无需参考对话且与目标系统实现解耦，降低配置成本。", "result": "相比现有方法，ChatChecker在故障检测性能上更优，并通过非合作用户模拟更有效暴露系统弱点，支持全面可扩展的测试。", "conclusion": "该框架为研究者与实践者提供高效工具，加速开发鲁棒对话系统，推动集成化测试从单轮分析转向对话级评估。"}}
{"id": "2507.16796", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16796", "abs": "https://arxiv.org/abs/2507.16796", "authors": ["Mian Ibad Ali Shah", "Enda Barrett", "Karl Mason"], "title": "Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading with Multi-Agent Reinforcement Learning", "comment": "7 pages, 4 figures, 1 table, Proceedings of the Main Track of the\n  European Conference on Artificial Intelligence (ECAI 2025), October 25-30,\n  2025", "summary": "This paper presents a novel framework for Peer-to-Peer (P2P) energy trading\nthat integrates uncertainty-aware prediction with multi-agent reinforcement\nlearning (MARL), addressing a critical gap in current literature. In contrast\nto previous works relying on deterministic forecasts, the proposed approach\nemploys a heteroscedastic probabilistic transformer-based prediction model\ncalled Knowledge Transformer with Uncertainty (KTU) to explicitly quantify\nprediction uncertainty, which is essential for robust decision-making in the\nstochastic environment of P2P energy trading. The KTU model leverages\ndomain-specific features and is trained with a custom loss function that\nensures reliable probabilistic forecasts and confidence intervals for each\nprediction. Integrating these uncertainty-aware forecasts into the MARL\nframework enables agents to optimize trading strategies with a clear\nunderstanding of risk and variability. Experimental results show that the\nuncertainty-aware Deep Q-Network (DQN) reduces energy purchase costs by up to\n5.7% without P2P trading and 3.2% with P2P trading, while increasing\nelectricity sales revenue by 6.4% and 44.7%, respectively. Additionally, peak\nhour grid demand is reduced by 38.8% without P2P and 45.6% with P2P. These\nimprovements are even more pronounced when P2P trading is enabled, highlighting\nthe synergy between advanced forecasting and market mechanisms for resilient,\neconomically efficient energy communities.", "AI": {"tldr": "本文提出了一种结合不确定性感知预测与多智能体强化学习（MARL）的P2P能源交易新框架，显著提升了交易策略的稳健性和经济效益。", "motivation": "现有P2P能源交易研究多依赖确定性预测，无法应对实际环境中的不确定性。本文旨在通过量化预测不确定性，优化交易决策。", "method": "提出基于异方差概率Transformer的预测模型KTU，整合领域特征与定制损失函数生成可靠概率预测；将其与MARL框架结合，使智能体在决策中考虑风险。", "result": "实验表明：不确定性感知DQN使无P2P交易时购电成本降低5.7%，有P2P时降低3.2%；售电收入分别提升6.4%和44.7%；高峰电网需求减少38.8%（无P2P）和45.6%（有P2P）。", "conclusion": "P2P交易机制与先进预测模型的协同效应显著，可构建更具经济性与韧性的能源社区。KTU-MARL框架为不确定性环境下的决策提供了新范式。"}}
