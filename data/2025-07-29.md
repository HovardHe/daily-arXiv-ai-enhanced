<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 5]
- [math.OC](#math.OC) [Total: 36]
- [math.NT](#math.NT) [Total: 24]
- [math.LO](#math.LO) [Total: 4]
- [math.HO](#math.HO) [Total: 2]
- [math.GM](#math.GM) [Total: 3]
- [math.CO](#math.CO) [Total: 18]
- [q-fin.MF](#q-fin.MF) [Total: 1]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [cs.CR](#cs.CR) [Total: 19]
- [cs.AI](#cs.AI) [Total: 51]
- [cs.DM](#cs.DM) [Total: 2]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [State evolution beyond first-order methods I: Rigorous predictions and finite-sample guarantees](https://arxiv.org/abs/2507.19611)
*Michael Celentano,Chen Cheng,Ashwin Pananjady,Kabir Aladin Verchand*

Main category: math.ST

TL;DR: 本文开发了一个工具箱，用于精确分析高维非凸优化问题中迭代算法的性能，提出了适用于更广泛算法类别的状态演化预测方法，并建立了有限样本保证。


<details>
  <summary>Details</summary>
Motivation: 先前工作仅能预测（广义）一阶方法的低维统计特性，本文旨在为包含一阶和鞍点更新的更广泛算法类别建立状态演化预测。

Method: 通过希尔伯特空间提升技术证明状态演化参数化的存在唯一性，结合Bolthausen条件方法与Gordon高斯比较不等式的序贯变体，开发了通用有限样本分析工具包。

Result: 建立了非坐标可分更新的严格状态演化预测，并给出了经验更新与状态演化偏差的有限样本保证。

Conclusion: 所开发的技术工具包可推广至相关问题，为高维非凸优化算法的精确分析提供了通用框架。

Abstract: We develop a toolbox for exact analysis of iterative algorithms on a class of
high-dimensional nonconvex optimization problems with random data. While prior
work has shown that low-dimensional statistics of (generalized) first-order
methods can be predicted by a deterministic recursion known as state evolution,
our focus is on developing such a prediction for a more general class of
algorithms. We provide a state evolution for any method whose iterations are
given by (possibly interleaved) first-order and saddle point updates, showing
two main results. First, we establish a rigorous state evolution prediction
that holds even when the updates are not coordinate-wise separable. Second, we
establish finite-sample guarantees bounding the deviation of the empirical
updates from the established state evolution. In the process, we develop a
technical toolkit that may prove useful in related problems. One component of
this toolkit is a general Hilbert space lifting technique to prove existence
and uniqueness of a convenient parameterization of the state evolution. Another
component of the toolkit combines a generic application of Bolthausen's
conditioning method with a sequential variant of Gordon's Gaussian comparison
inequality, and provides additional ingredients that enable a general
finite-sample analysis.

</details>


### [2] [Uniform inference in linear mixed models](https://arxiv.org/abs/2507.19633)
*Karl Oskar Ekvall,Matteo Bottai*

Main category: math.ST

TL;DR: 本文提出了线性混合模型中参数均匀的有限样本分布近似方法，特别关注随机效应方差协方差矩阵接近或处于奇异边界的情况，提供了实用的置信区域构造方法。


<details>
  <summary>Details</summary>
Motivation: 现有理论在随机效应协方差矩阵接近或完全奇异时失效，本文旨在解决这一边界问题，为这类复杂情况提供统计推断工具。

Method: 通过量化标准正态密度与得分函数线性组合密度间的差异界限，开发了适用于参数和随机效应数量随样本量增长的渐近理论，并适用于独立聚类和交叉随机效应模型。

Result: 仿真表明该方法具有实际应用价值，所构建的置信区域在有限样本下接近名义覆盖率，即使随机效应方差接近零或相关性接近$\pm 1$时仍保持稳健。

Conclusion: 研究为边界参数问题提供了理论保证和实用方法，其易于实现的置信区域在随机效应方差接近零或极端相关时仍保持良好性能。

Abstract: We provide finite-sample distribution approximations, that are uniform in the
parameter, for inference in linear mixed models. Focus is on variances and
covariances of random effects in cases where existing theory fails because
their covariance matrix is nearly or exactly singular, and hence near or at the
boundary of the parameter set. Quantitative bounds on the differences between
the standard normal density and those of linear combinations of the score
function enable, for example, the assessment of sufficient sample size. The
bounds also lead to useful asymptotic theory in settings where both the number
of parameters and the number of random effects grow with the sample size. We
consider models with independent clusters and ones with a possibly diverging
number of crossed random effects, which are notoriously complicated.
Simulations indicate the theory leads to practically relevant methods. In
particular, the studied confidence regions, which are straightforward to
implement, have near-nominal coverage in finite samples even when some random
effects have variances near or equal to zero, or correlations near or equal to
$\pm 1$.

</details>


### [3] [Extreme value theory for singular subspace estimation in the matrix denoising model](https://arxiv.org/abs/2507.19978)
*Junhyung Chang,Joshua Cape*

Main category: math.ST

TL;DR: 本文研究矩阵去噪模型中细粒度奇异子空间估计问题，证明了在适当信噪比条件下，对齐后的样本与总体奇异向量差异的最大欧几里德行范数趋近于Gumbel分布，并基于此提出了低秩信号结构假设检验方法。


<details>
  <summary>Details</summary>
Motivation: 现有矩阵去噪文献多关注极小极大性、均方误差分析或酉不变子空间距离，缺乏对奇异向量行范数极值分布的理论研究，而这对检测局部结构化差异至关重要。

Method: 结合矩阵扰动分析、极值理论、鞍点近似和随机矩阵理论，提出基于二到无穷范数的检验统计量，并给出信号奇异值的去偏估计方法。

Result: 理论证明对齐奇异向量差异的最大行范数服从Gumbel分布，数值实验表明该方法对非高斯噪声具有鲁棒性，且比Frobenius范数检验对局部差异更敏感。

Conclusion: 所提出的二到无穷范数检验统计量能有效检测奇异向量中的局部结构化差异，补充了现有矩阵去噪理论体系，为低秩信号推断提供了新工具。

Abstract: This paper studies fine-grained singular subspace estimation in the matrix
denoising model where a deterministic low-rank signal matrix is additively
perturbed by a stochastic matrix of Gaussian noise. We establish that the
maximum Euclidean row norm (i.e., the two-to-infinity norm) of the aligned
difference between the leading sample and population singular vectors
approaches the Gumbel distribution in the large-matrix limit, under suitable
signal-to-noise conditions and after appropriate centering and scaling. We
apply our novel asymptotic distributional theory to test hypotheses of low-rank
signal structure encoded in the leading singular vectors and their
corresponding principal subspace. We provide de-biased estimators for the
corresponding nuisance signal singular values and show that our proposed
plug-in test statistic has desirable properties. Notably, compared to using the
Frobenius norm subspace distance, our test statistic based on the
two-to-infinity norm has higher power to detect structured alternatives that
differ from the null in only a few matrix entries or rows. Our main results are
obtained by a novel synthesis of and technical analysis involving entrywise
matrix perturbation analysis, extreme value theory, saddle point approximation
methods, and random matrix theory. Our contributions complement the existing
literature for matrix denoising focused on minimaxity, mean squared error
analysis, unitarily invariant distances between subspaces, component-wise
asymptotic distributional theory, and row-wise uniform error bounds. Numerical
simulations illustrate our main results and demonstrate the robustness
properties of our testing procedure to non-Gaussian noise distributions.

</details>


### [4] [A global Lipschitz stability perspective for understanding approximate approaches in Bayesian sequential learning](https://arxiv.org/abs/2507.20379)
*Liliang Wang,Alex A. Gorodetsky*

Main category: math.ST

TL;DR: 本文建立了一个非渐近误差分析框架，用于评估贝叶斯序贯学习（BSL）中增量近似方法对长期推断性能的影响，首次证明了后验分布在海灵格和瓦瑟斯坦距离下的全局Lipschitz稳定性，并提出了两组学习误差上界。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解实际贝叶斯序贯学习方法中增量近似对推断性能的长期影响，填补了现有文献在海灵格和瓦瑟斯坦距离下全局Lipschitz稳定性分析的空白。

Method: 通过建立后验分布关于先验的全局Lipschitz稳定性，使用总变差、海灵格和瓦瑟斯坦三种分布度量，构建了适用于逆问题、状态估计及参数-状态估计的统一误差分析框架。

Result: 提出了两组学习误差上界：第一组证明了近似BSL方法对增量近似过程的稳定性，第二组在实际场景中可估计；同时首次给出了数据同化导致学习误差衰减的充分条件。

Conclusion: 该框架首次系统分析了近似BSL方法的误差传播特性，为理解学习误差衰减现象提供了理论基础，其建立的全局稳定性结果具有广泛适用性。

Abstract: We establish a general, non-asymptotic error analysis framework for
understanding the effects of incremental approximations made by practical
approaches for Bayesian sequential learning (BSL) on their long-term inference
performance. Our setting covers inverse problems, state estimation, and
parameter-state estimation. In these settings, we bound the difference-termed
the learning error-between the unknown true posterior and the approximate
posterior computed by these approaches, using three widely used distribution
metrics: total variation, Hellinger, and Wasserstein distances. This framework
builds on our establishment of the global Lipschitz stability of the posterior
with respect to the prior across these settings. To the best of our knowledge,
this is the first work to establish such global Lipschitz stability under the
Hellinger and Wasserstein distances and the first general error analysis
framework for approximate BSL methods.
  Our framework offers two sets of upper bounds on the learning error. The
first set demonstrates the stability of general approximate BSL methods with
respect to the incremental approximation process, while the second set is
estimable in many practical scenarios.
  Furthermore, as an initial step toward understanding the phenomenon of
learning error decay, which is sometimes observed, we identify sufficient
conditions under which data assimilation leads to learning error reduction.

</details>


### [5] [A Generalized Cramér-Rao Bound Using Information Geometry](https://arxiv.org/abs/2507.21022)
*Satyajit Dhadumia,M. Ashok Kumar*

Main category: math.ST

TL;DR: 本文通过Eguchi理论将BHHJ散度转化为黎曼度量，并基于Amari-Nagaoka方法推导出广义Cram\'er-Rao下界，为鲁棒估计提供新工具。


<details>
  <summary>Details</summary>
Motivation: 信息几何中统计模型被视为微分流形，传统Fisher-Rao度量源自KL散度。研究BHHJ散度导出的黎曼度量可拓展Cram\'er-Rao界的应用场景。

Method: 应用Eguchi(1992)理论将Basu-Harris-Hjort-Jones(BHHJ)散度系统化为黎曼度量，沿用Amari-Nagaoka(2000)的几何框架进行推导。

Result: 成功导出基于BHHJ散度的广义Cram\'er-Rao下界，该结果在理论上扩展了经典CRLB的适用范围。

Conclusion: 新提出的广义CRLB为鲁棒统计估计提供了潜在的理论基础，未来可应用于对抗异常值的参数估计问题。

Abstract: In information geometry, statistical models are considered as differentiable
manifolds, where each probability distribution represents a unique point on the
manifold. A Riemannian metric can be systematically obtained from a divergence
function using Eguchi's theory (1992); the well-known Fisher-Rao metric is
obtained from the Kullback-Leibler (KL) divergence. The geometric derivation of
the classical Cram\'er-Rao Lower Bound (CRLB) by Amari and Nagaoka (2000) is
based on this metric. In this paper, we study a Riemannian metric obtained by
applying Eguchi's theory to the Basu-Harris-Hjort-Jones (BHHJ) divergence
(1998) and derive a generalized Cram\'er-Rao bound using Amari-Nagaoka's
approach. There are potential applications for this bound in robust estimation.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [6] [Linearizations and optimization problems in diffeological spaces](https://arxiv.org/abs/2507.19508)
*Jean-Pierre Magnot*

Main category: math.OC

TL;DR: 本文通过将线性化概念推广至微分空间，提出了一种适用于该范畴的优化问题框架，展示了无需标准图表或梯度即可构建光滑路径与变分流的方法，并引入了一种适应于弱假设条件的通用优化算法。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于将经典的变分方法扩展至非线性无限维框架，特别是在微分空间这类缺乏传统结构的空间中实现优化与临界值搜索。

Method: 方法核心是通过广义线性化构造光滑路径与变分流，开发了一种不依赖标准微分结构的优化算法，适用于低正则性映射空间。

Result: 结果表明，在微分空间条件下仍能实现向极小值或临界值的弱收敛，且算法适用于非线性的无限维问题。

Conclusion: 该研究为微分空间中的优化问题提供了灵活的理论框架，并初步探讨了微分映射不动点搜索的可能性，扩展了经典变分法的应用范围。

Abstract: By generalizing the notion of linearization, a concept originally arising
from microlocal analysis and symbolic calculus, to diffeological spaces, we
make a first proposal setting for optimization problems in this category.
  We show how linearizations allow the construction of smooth paths and
variational flows without requiring canonical charts or gradients. With these
constructions, we introduce a general optimization algorithm adapted to
diffeological spaces under weakened assumptions. The method applies to spaces
of mappings with low regularity.
  Our results show that weak convergence toward minima or critical values can
still be achieved under diffeological conditions. The approach extends
classical variational methods into a flexible, non-linear infinite-dimensional
framework. Preliminary steps to the search for fixed points of diffeological
mappings are discussed.

</details>


### [7] [On Bauschke-Bendit-Moursi modulus of averagedness and classifications of averaged nonexpansive operators](https://arxiv.org/abs/2507.19533)
*Shuang Song,Xianfu Wang*

Main category: math.OC

TL;DR: 本文利用Bauschke-Bendit-Moursi平均性模数对平均算子、严格非扩张算子和邻近算子进行分类，证明了当算子平均常数小于1/2时是双Lipschitz同胚，并揭示了邻近算子的平均性模数与函数Lipschitz光滑性的等价关系。


<details>
  <summary>Details</summary>
Motivation: 平均算子在凸分析和优化算法中具有重要作用，但现有分类体系不够完善。本文旨在通过平均性模数建立更精细的算子分类框架。

Method: 采用Bauschke-Bendit-Moursi平均性模数作为分析工具，研究算子组合的平均性，并推导了解算子和邻近算子的模数显式计算式。

Result: 关键发现包括：平均常数<1/2的算子是双Lipschitz同胚；凸函数的邻近算子模数<1/2当且仅当函数Lipschitz光滑；给出了单调算子与次微分相关量的模数计算公式。

Conclusion: 该研究建立了平均性模数与算子性质的深刻联系，为优化算法设计提供了新的理论工具，并通过算例验证了结果的实用性。

Abstract: Averaged operators are important in Convex Analysis and Optimization
Algorithms. In this paper, we propose classifications of averaged operators,
firmly nonexpansive operators, and proximal operators using the
Bauschke-Bendit-Moursi modulus of averagedness. We show that if an operator is
averaged with a constant less than 1/2, then it is a bi-Lipschitz
homeomorphism. Amazingly the proximal operator of a convex function has its
modulus of averagedness less than 1/2 if and only if the function is Lipschitz
smooth. Some results on the averagedness of operator compositions are obtained.
Explicit formulae for calculating the modulus of averagedness of resolvents and
proximal operators in terms of various values associated with the maximally
monotone operator or subdifferential are also given. Examples are provided to
illustrate our results.

</details>


### [8] [Rural School Bus Routing and Scheduling](https://arxiv.org/abs/2507.19538)
*Prabhat Hegde,Vikrant Vaze*

Main category: math.OC

TL;DR: 农村校车路线设计优化方案显著减少学生乘车时间，提升校车利用率并缓解学校周边拥堵。


<details>
  <summary>Details</summary>
Motivation: 农村校车行程过长影响学生表现与福祉，导致家长选择私家车接送，加剧交通拥堵与校车资源浪费，形成恶性循环。

Method: 提出基于道路网络感知的'先聚类后路径'启发式算法，构建农村校车路线调度模型，解决混合载客与非规则路网等复杂问题。

Result: 实际案例中，学生乘车时间减少37-39%，校车利用率提升17-19%，学校周边私家车通勤减少12-17%。

Conclusion: 该方案通过缩短通勤时间、提高校车吸引力及缓解拥堵，为农村学区提供了改善学生交通福祉的有效路径，具有广泛适用性。

Abstract: Long school bus rides adversely affect student performance and well-being.
Rural school bus rides are particularly long, incentivizing parents to drive
their children to school rather than to opt for the school bus. This in turn
exacerbates the traffic congestion around schools, further compounding the
problem of long bus rides, creating a vicious cycle. It also results in
underutilized school buses and higher bus operating costs per rider. To address
these challenges, this paper focuses on the design of rural school bus routes
and schedules, a particularly challenging problem due to its unique operational
complexities, including mixed loading and irregular road networks. We formalize
a rural school bus routing and scheduling model that tackles these complexities
while minimizing the total bus ride time of students. We develop an original
road network-aware cluster-then-route heuristic that leverages our problem
formulation to produce high-quality solutions. For real-world case studies, our
approach outperforms status quo solutions by reducing the bus ride times of
students by 37-39 %. Our solutions also make the school bus more attractive,
helping address both the underutilization of school buses and the prevalence of
private commutes. Our routing and scheduling approach can improve school bus
use by 17-19 % and reduce car trips that induce congestion near schools by
12-17 %. Many rural school districts share the operational characteristics
modeled in this study, including long bus rides, high operational expenditures,
mixed loading, and a high proportion of car-based school commutes, suggesting
the broad applicability of our approach. Ultimately, by reducing student travel
times, increasing school bus utilization, and alleviating congestion near
schools, our approach enables rural school district planners to address
transportation-related barriers to student performance and well-being.

</details>


### [9] [A Global-Local Optimization Approach for Asynchronous SAR ADC Design](https://arxiv.org/abs/2507.19541)
*Yijia Hao,Ken Li,Miguel Gandara,Shaolan Li,Bo Liu*

Main category: math.OC

TL;DR: 本文提出了一种用于自动异步SAR ADC设计的系统级优化框架，解决了块级方法在性能和手动操作上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有块级方法存在性能次优和依赖手动操作的问题，需要一种更高效的优化框架来应对高维度和高仿真成本的设计挑战。

Method: 该方法结合了快速全局优化器和多保真度局部优化器，以高效处理高维设计空间和昂贵的仿真成本。

Result: 在12个设计案例（涵盖7位和12位分辨率，频率范围100 kHz至250 MHz）中，实验结果表明其性能优于现有工作。

Conclusion: 所提出的系统级优化框架在异步SAR ADC设计中表现出色，为高维复杂设计问题提供了有效解决方案。

Abstract: This paper presents a system-level optimization framework for automated
asynchronous SAR ADC design, addressing the limitations of block-level methods
in terms of suboptimal performance and manual effort. The proposed approach
integrates a fast global optimizer with a multi-fidelity local optimizer to
efficiently handle high-dimensionality and expensive simulation cost.
Experimental results from 12 design cases, covering 7- and 12-bit resolutions
and a frequency range of 100 kHz to 250 MHz, demonstrate highly competitive
performance compared with prior works.

</details>


### [10] [Time-optimal synchronisation to self-sustained oscillations under bounded control](https://arxiv.org/abs/2507.19560)
*C. Ríos-Monje,C. A. Plata,D. Guéry-Odelin,A. Prados*

Main category: math.OC

TL;DR: 本文研究了在力约束下Li\'enard系统最快同步到极限环的非线性最优控制问题，结合庞特里亚金极大值原理与数值工具，揭示了最优控制在相空间中的复杂结构，并以van der Pol振子为例展示了关键特征。


<details>
  <summary>Details</summary>
Motivation: 在物理系统中引入力约束对于实现现实控制至关重要，研究如何在力约束下实现Li\'enard系统到极限环的最快同步具有重要理论和应用价值。

Method: 采用庞特里亚金极大值原理（Pontryagin's Maximum Principle），结合解析与数值工具，求解这一非线性最优控制问题。

Result: 研究发现，随着力约束降低，最优控制在相空间中呈现高度复杂结构，且从极限环极端点回推的轨迹对确定最优连接的bang-bang控制次数起关键作用。

Conclusion: 通过van der Pol振子模型验证了最优控制的复杂特征，为力约束下的非线性系统同步控制提供了新见解。

Abstract: Incorporating force bounds is crucial for realistic control implementations
in physical systems. In this Letter, we investigate the fastest possible
synchronisation of a Li\'enard system to its limit cycle using a bounded
external force. To tackle this challenging non-linear optimal control problem,
our approach involves applying Pontryagin's Maximum Principle with a
combination of analytical and numerical tools. We show that the optimal control
develops a remarkably complex structure in phase space as the force bound is
lowered. Trajectories rewound from the limit cycle's extreme points turn out to
play a key role in determining the maximum number of control bangs for optimal
connection. We illustrate these intricate features using the paradigmatic van
der Pol oscillator model.

</details>


### [11] [Long-Duration Station-Keeping Strategy for Cislunar Spacecraft Formations](https://arxiv.org/abs/2507.19620)
*Ethan Foss,Yuji Takubo,Simone D'Amico*

Main category: math.OC

TL;DR: 本文提出了一种用于近直线晕轨道编队保持的新型制导与控制策略，结合高保真动力学模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决地月空间近直线晕轨道编队飞行中的长期稳定控制问题，特别是在可能错过机动事件情况下的被动安全保障。

Method: 采用基于瞬时不变环的准周期相对轨道构建方法，结合绝对控制策略与简单有效的相对控制反馈律，并引入控制屏障函数确保被动安全。

Result: 通过蒙特卡洛仿真验证，该策略能在高保真动力学环境下实现长期稳定的有界相对运动，并具备错过机动时的递归被动安全特性。

Conclusion: 所提出的控制策略为地月空间复杂轨道环境下的航天器编队飞行提供了可靠解决方案，特别适用于长期任务的安全保障需求。

Abstract: This paper demonstrates a novel guidance and control strategy for cislunar
near-rectilinear halo orbit formation-keeping applied to high-fidelity
dynamics. Bounded relative motion is constructed about long-duration ephemeris
trajectories with osculating invariant circles to form quasi-periodic relative
orbits. State-of-the-art absolute control strategies are paired with a simple
and effective relative control feedback law. Finally, a control barrier
function is implemented to ensure recursively passively-safe bounded relative
motion under feedback in the presence of possible missed maneuver events for
the duration of the formation flight. The strategy is verified in high-fidelity
simulation environments through Monte Carlo trials.

</details>


### [12] [Hierarchical clustering and dimensional reduction for optimal control of large-scale agent-based models](https://arxiv.org/abs/2507.19644)
*Angela Monti,Fasma Diele,Dante Kalise*

Main category: math.OC

TL;DR: 本文提出了一种基于双重降阶策略（智能体聚类和POD投影降阶）的大规模基于智能体模型（ABM）可扩展控制框架，显著提升了复杂系统（如意见动力学模型）的控制效率。


<details>
  <summary>Details</summary>
Motivation: 基于智能体的模型（ABMs）在描述复杂系统时面临维度灾难问题，尤其在最优控制场景中计算挑战显著。现有方法难以应对大规模智能体及高维状态空间的复杂性。

Method: 结合智能体聚类与POD投影降阶技术，构建反馈回路以在降阶系统上设计最优控制律，并以意见动力学模型（含状态依赖影响函数）为原型验证。

Result: 该方法显著提升了控制效率，在直接控制因模型复杂度失效的场景中仍能有效运作，且适用于环境态度扩散等现实场景的共识控制。

Conclusion: 研究不仅提出了ABM控制的方法论创新，还揭示了意见动力学模型在环境政策采纳等需控制共识形成场景中的实际应用价值。

Abstract: Agent-based models (ABMs) provide a powerful framework to describe complex
systems composed of interacting entities, capable of producing emergent
collective behaviours such as consensus formation or clustering. However, the
increasing dimensionality of these models -- in terms of both the number of
agents and the size of their state space -- poses significant computational
challenges, particularly in the context of optimal control. In this work, we
propose a scalable control frame work for large-scale ABMs based on a twofold
model order reduction strategy: agent clustering and projection-based reduction
via Proper Orthogonal Decomposition (POD). These techniques are integrated into
a feedback loop that enables the design and application of optimal control laws
over a reduced-order representation of the system. To illustrate the
effectiveness of the approach, we consider the opinion dynamics model, a
prototyp ical first-order ABM where agents interact through state-dependent
influence functions. We show that our method significantly improves control
efficiency, even in scenarios where direct control fails due to model
complexity. Beyond its methodological contributions, this work also highlights
the rel evance of opinion dynamics models in environmental contexts -- for
example, modeling the diffusion of pro-environmental attitudes or
decision-making processes in sustainable policy adoption -- where controlling
consensus formation plays a crucial role.

</details>


### [13] [Ultracoarse Equilibria and Ordinal-Folding Dynamics in Operator-Algebraic Models of Infinite Multi-Agent Games](https://arxiv.org/abs/2507.19694)
*Faruk Alpay,Hamdi Alakkad,Bugra Kilictas,Taylan Alpay*

Main category: math.OC

TL;DR: 本文构建了一个无限玩家连续体博弈的算子代数框架，证明了基于遗憾的学习动力学在非交换连续性方程下会收敛至唯一量子响应均衡，并引入序数折叠指数衡量动力学自指深度。


<details>
  <summary>Details</summary>
Motivation: 研究旨在为大规模多智能体系统提供严格的数学基础，通过融合泛函分析、粗几何与博弈论，解决连续体经济中的均衡选择与分配问题。

Method: 为每个博弈分配一个冯·诺依曼代数表示集体策略演化，利用反射遗憾算子驱动策略分布流，并引入可计算的序数值度量——序数折叠指数。

Result: 理论证明动力学在粗可调网络上收敛时间为零，获得不变子代数刚性结果，并确保连续体经济中无嫉妒与最大最小份额分配的存在唯一性。

Conclusion: 该框架为大规模系统提供了统一分析工具，揭示了遗憾流与大语言模型经验稳定性现象的联系，证实序数度量在均衡选择中的实用性。

Abstract: We develop an operator algebraic framework for infinite games with a
continuum of agents and prove that regret based learning dynamics governed by a
noncommutative continuity equation converge to a unique quantal response
equilibrium under mild regularity assumptions. The framework unifies functional
analysis, coarse geometry and game theory by assigning to every game a von
Neumann algebra that represents collective strategy evolution. A reflective
regret operator within this algebra drives the flow of strategy distributions
and its fixed point characterises equilibrium. We introduce the ordinal folding
index, a computable ordinal valued metric that measures the self referential
depth of the dynamics, and show that it bounds the transfinite time needed for
convergence, collapsing to zero on coarsely amenable networks. The theory
yields new invariant subalgebra rigidity results, establishes existence and
uniqueness of envy free and maximin share allocations in continuum economies,
and links analytic properties of regret flows with empirical stability
phenomena in large language models. These contributions supply a rigorous
mathematical foundation for large scale multi agent systems and demonstrate the
utility of ordinal metrics for equilibrium selection.

</details>


### [14] [Stackelberg stopping games](https://arxiv.org/abs/2507.19746)
*Jingjie Zhang,Zhou Zhou*

Main category: math.OC

TL;DR: 本文研究了一种离散时间下的Stackelberg变体Dynkin博弈，其中玩家1（领导者）先宣布停止策略，玩家2（追随者）随后最优响应。重点分析了领导者-追随者博弈结构导致的时间不一致性问题，并通过有限和无限时间范围的例子探讨了预承诺和均衡策略，最后引入熵正则化方法确保均衡存在。


<details>
  <summary>Details</summary>
Motivation: 研究Stackelberg停止博弈中的时间不一致性问题，探索领导者在博弈中的最优控制策略，并解决标准Dynkin博弈中均衡策略可能不存在的问题。

Method: 通过有限时间范围的例子阐明预承诺和均衡策略概念，分析无限时间范围下的随机化策略，并引入熵正则化方法使追随者的优化问题连续化。

Result: 发现领导者的预承诺策略可能无法达到最优值，且随机化均衡策略可能不存在；熵正则化后，存在一种可近似精确均衡的正则随机化均衡策略。

Conclusion: 熵正则化的Stackelberg停止博弈能有效解决均衡存在性问题，为时间不一致性博弈提供了可行的近似解决方案。

Abstract: We study a Stackelberg variant of the classical Dynkin game in discrete time,
where the two players are no longer on equal footing. Player 1 (the leader)
announces her stopping strategy first, and Player 2 (the follower) responds
optimally. This Stackelberg stopping game can be viewed as an optimal control
problem for the leader. Our primary focus is on the time-inconsistency that
arises from the leader-follower game structure. We begin by using a
finite-horizon example to clarify key concepts, including precommitment and
equilibrium strategies in the Stackelberg setting, as well as the Nash
equilibrium in the standard Dynkin game. We then turn to the infinite-horizon
case and study randomized precommitment and equilibrium strategies. We provide
a characterization for the leader's value induced by precommitment strategies
and show that it may fail to attain the supremum. Moreover, we construct a
counterexample to demonstrate that a randomized equilibrium strategy may not
exist. Then we introduce an entropy-regularized Stackelberg stopping game, in
which the follower's optimization is regularized with an entropy term. This
modification yields a continuous best response and ensures the existence of a
regular randomized equilibrium strategy, which can be viewed as an
approximation of the exact equilibrium.

</details>


### [15] [Computing optimal policies for managing inventories with noisy observations](https://arxiv.org/abs/2507.19765)
*Eugene Feinberg,Jefferson Huang,Pavlo Kasyanov,Thomas O'Neill*

Main category: math.OC

TL;DR: 本文采用深度确定性策略梯度(DDPG)算法求解带设置成本和延期交货的部分可观测单产品周期性库存控制问题的最优策略，证明了高斯问题中均值信念的充分统计性，并通过数值实验对比了DDPG策略与离散化最优策略的性能。


<details>
  <summary>Details</summary>
Motivation: 研究部分可观测环境下含设置成本和延期交货的库存控制问题，决策者仅能获取噪声干扰的库存观测值，需在有限规划期内最大化期望总折现收益。

Method: 针对高斯分布假设(初始库存、需求及观测噪声均服从正态分布)的问题，构建基于均值信念的马尔可夫决策过程模型，采用DDPG算法计算近似最优策略。

Result: 证明均值信念可作为高斯问题的充分统计量，其最优策略呈现(s_t,S_t)结构；数值实验表明DDPG策略与离散化最优策略性能接近。

Conclusion: 均值信念能有效表征部分可观测库存系统的状态，DDPG算法可计算接近最优的(s_t,S_t)型策略，为连续状态空间问题提供可行解决方案。

Abstract: This paper implements the Deep Deterministic Policy Gradient (DDPG) algorithm
for computing optimal policies for partially observable single-product periodic
review inventory control problems with setup costs and backorders. The decision
maker does not know the exact inventory level, but can obtain noise-corrupted
observations of them. The goal is to maximize the expected total discounted
costs incurred over a finite planning horizon. We also investigate the Gaussian
version of this problem with normally distributed initial inventories, demands,
and observation noise. We show that expected posterior observations of
inventory levels, also called mean beliefs, provide sufficient statistics for
the Gaussian problem. Moreover, they can be represented in the form of a Markov
Decision Processes for an inventory control system with time-dependent holding
costs and demands. Thus, for a Gaussian problem, the there exist
(s_t,S_t)-optimal policies based on mean beliefs, and this fact explains the
structure of the approximately optimal policies computed by DDPG. For the
Gaussian case, we also numerically compare the performance of policies derived
from DDPG to optimal policies for discretized versions of the original
continuous problem.

</details>


### [16] [\(H_2/H_\infty\) Control for Continuous-Time Mean-Field Stochastic Systems with Affine Terms](https://arxiv.org/abs/2507.19809)
*Xuling Fang,Jun Moon,Maoning Tang,Qingxin Meng*

Main category: math.OC

TL;DR: 本文研究了有限时域下具有仿射项的连续时间均值场线性随机系统的$H_2/H_{\infty}$控制问题，通过均值场随机有界实引理（MF-SBRL）和均值场正倒向随机微分方程（MF-FBSDE）建立了开环与闭环控制策略的等价条件。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决均值场线性随机系统中$H_2/H_{\infty}$控制问题，确保系统扰动$H_{\infty}$范数低于特定水平，为实际工程应用提供理论支持。

Method: 采用均值场随机有界实引理（MF-SBRL）和均值场正倒向随机微分方程（MF-FBSDE），通过求解四组耦合差分Riccati方程（CDREs）、两组倒向随机微分方程（BSDEs）和常微分方程（ODEs）验证闭环控制策略的可解性。

Result: 证明了在闭环条件下，若四组CDREs、两组BSDEs和ODEs存在解，则控制问题可解，且状态反馈增益可从这些解中导出，从而建立开环与闭环解的可行性联系。

Conclusion: 通过理论分析，本文为均值场线性随机系统的$H_2/H_{\infty}$控制提供了完整的解决方案框架，并验证了开环与闭环策略的等价性。

Abstract: This paper discusses the \( H_2/H_{\infty} \) control problem for
continuous-time mean-field linear stochastic systems with affine terms over a
finite horizon. We employ the Mean-Field Stochastic Bounded Real Lemma
(MF-SBRL), which provides the necessary and sufficient conditions to ensure
that the \( H_{\infty} \) norm of system perturbations remains below a certain
level. By utilizing the Mean-Field Forward-Backward Stochastic Differential
Equations (MF-FBSDE), we establish the equivalence conditions for open-loop \(
H_2/H_{\infty} \) control strategies. Furthermore, the paper demonstrates that
the control problem is solvable under closed-loop conditions if solutions exist
for four coupled Difference Riccati Equations (CDREs), two sets of backward
stochastic differential equations (BSDEs) and ordinary equations (ODEs). The
state-feedback gains for the control strategy can be derived from these
solutions, thereby linking the feasibility of open-loop and closed-loop
solutions.

</details>


### [17] [Nonconvex Optimization Framework for Group-Sparse Feedback Linear-Quadratic Optimal Control. II: Non-Penalty Approach](https://arxiv.org/abs/2507.19895)
*Lechen Feng,Xun Li,Yuan-Hua Ni*

Main category: math.OC

TL;DR: 本文提出了一种直接解决稀疏反馈LQ问题（SF-LQ）和固定通信拓扑分布式LQ问题（DFT-LQ）的方法，避免了传统惩罚方法的缺点，如惩罚参数调整困难和引入虚假驻点的风险。通过从epi-composition函数角度重新表述问题，并研究ADMM算法的收敛性，实现了对群稀疏反馈增益的直接设计。


<details>
  <summary>Details</summary>
Motivation: 传统惩罚方法在解决SF-LQ和DFT-LQ问题时存在惩罚参数调整困难和引入虚假驻点的固有缺陷。本文旨在直接解决这些约束问题，避免使用惩罚公式或凸替代方法。

Method: 首先从epi-composition函数角度重新表述SF-LQ和DFT-LQ问题，直接解决约束问题。然后从理论角度重新审视ADMM算法，并在特定假设下建立其收敛性。当假设不成立时，结合次梯度下降和DC松弛方法使用替代方法。

Result: 研究结果表明，ADMM算法在特定假设下能够收敛到聚类点集。在不满足假设的情况下，结合次梯度下降和DC松弛方法的替代方法能够有效解决问题。

Conclusion: 本文提出的方法能够直接设计具有理论保证的群稀疏反馈增益，无需依赖凸替代、限制性结构假设或将约束纳入成本函数的惩罚公式。

Abstract: This work is a companion paper of [8], where the distributed linear-quadratic
problem with fixed communication topology (DFT-LQ) and the sparse feedback LQ
problem (SF-LQ) are formulated into a nonsmooth and nonconvex optimization
problem with affine constraints. Moreover, a penalty approach is considered in
\cite{feng-part1}, and the PALM (proximal alternating linearized minimization)
algorithm is studied with convergence and complexity analysis. In this paper,
we aim to address the inherent drawbacks of the penalty approach, such as the
challenge of tuning the penalty parameter and the risk of introducing spurious
stationary points. Specifically, we first reformulate the SF-LQ problem and the
DFT-LQ problem from an epi-composition function perspective, aiming to solve
the constrained problem directly. Then, from a theoretical viewpoint, we
revisit the alternating direction method of multipliers (ADMM) and establish
its convergence to the set of cluster points under certain assumptions. When
these assumptions do not hold, we can effectively utilize alternative
approaches combining subgradient descent with Difference-of-Convex relaxation
methods. In summary, our results enable the direct design of group-sparse
feedback gains with theoretical guarantees, without resorting to convex
surrogates, restrictive structural assumptions, or penalty formulations that
incorporate constraints into the cost function.

</details>


### [18] [Self-protection and self-insurance for general risk models via a BSDE approach](https://arxiv.org/abs/2507.19959)
*Claudia Ceci,Alessandra Cretarola*

Main category: math.OC

TL;DR: 研究一般风险设置下的最优预防与保险问题，通过结合自我保护（降低索赔频率）和自我保险（减轻损失严重性）的策略，最大化终端财富的期望指数效用。


<details>
  <summary>Details</summary>
Motivation: 探讨在潜在损失环境中，如何通过综合策略优化风险管理，扩展了先前仅关注自我保护的研究，提供了一个更全面的框架。

Method: 将问题建模为随机控制问题，利用后向随机微分方程（BSDEs）和一般的贝尔曼最优性原理求解，无需指定基础过滤结构，适用于多种风险模型。

Result: 提出了一种统一且通用的方法，适用于包括马尔可夫调制、随机因子、Cox-shot噪声和自激模型在内的广泛风险模型。

Conclusion: 该研究为风险管理提供了一个灵活且强大的框架，能够同时处理自我保护和自我保险策略，扩展了现有理论的应用范围。

Abstract: We investigate an optimal prevention and insurance problem in a general risk
setting, where a representative agent is exposed to potential losses. The agent
adopts a strategy that combines self-protection, aimed at reducing the
frequency of claims, and self-insurance, aimed at mitigating their severity.
The problem, which consists in maximizing the expected exponential utility of
terminal wealth, is formulated as a stochastic control problem and solved by
means of backward stochastic differential equations (BSDEs). Our approach,
essentially based on a general Bellman Optimality Principle (see [13] among
others), does not require specification of the underlying filtration structure,
making it applicable to a broad class of risk models, including
Markov-modulated, stochastic factor, Cox-shot noise and self-excited models. We
extend recent results by [3, 5], which focused on self-protection in specific
models, by allowing for both self-protection and self-insurance within a
unified and general framework.

</details>


### [19] [A Convex Optimization Approach to Model-Free Inverse Optimal Control with Provable Convergence](https://arxiv.org/abs/2507.19965)
*Meiling Yu,Lechen Feng,Lei Jiang,Yuan-Hua Ni*

Main category: math.OC

TL;DR: 本文提出了一种针对连续时间线性二次调节器框架下逆最优控制（IOC）问题的解析框架，通过将非凸联合估计问题转化为凸二阶锥规划问题，并设计高效迭代求解器，首次实现了具有明确收敛速率保证的模型无关IOC解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有方法在联合估计系统动态和成本函数权重矩阵时缺乏收敛性和收敛速率的严格理论保证，限制了在安全关键系统中的应用。本文旨在填补这一理论空白。

Method: 通过将非凸联合估计问题等价转化为凸二阶锥规划问题，并基于块连续上界最小化算法设计高效迭代求解器，理论证明其具有$\mathcal{O}(1/k)$的次线性收敛速率。

Result: 仿真实验表明，相比最先进基准算法，所提方法在收敛速度上实现数量级提升，同时在重构精度和鲁棒性方面展现出显著优势。

Conclusion: 本研究首次为模型无关IOC问题提供了具有显式收敛速率保证的解决方案，其理论框架和高效算法为安全关键系统的应用奠定了基础。

Abstract: Inverse Optimal Control (IOC) aims to infer the underlying cost functional of
an agent from observations of its expert behavior. This paper focuses on the
IOC problem within the continuous-time linear quadratic regulator framework,
specifically addressing the challenging scenario where both the system dynamics
and the cost functional weighting matrices are unknown. A significant
limitation of existing methods for this joint estimation problem is the lack of
rigorous theoretical guarantees on the convergence and convergence rate of
their optimization algorithms, which restricts their application in
safety-critical systems. To bridge this theoretical gap, we propose an
analytical framework for IOC that provides such guarantees. The core
contribution lies in the equivalent reformulation of this non-convex problem of
jointly estimating system and cost parameters into a convex second-order cone
programming problem. Building on this transformation, we design an efficient
iterative solver based on the block successive upper-bound minimization
algorithm. We rigorously prove that the proposed algorithm achieves a sublinear
convergence rate of $\mathcal{O}(1/k)$. To the best of our knowledge, this is
the first solution for the model-free IOC problem that comes with an explicit
convergence rate guarantee. Finally, comparative simulation experiments against
a state-of-the-art benchmark algorithm validate the superiority of our proposed
method. The results demonstrate that our algorithm achieves an
order-of-magnitude improvement in convergence speed while also exhibiting
significant advantages in reconstruction accuracy and robustness.

</details>


### [20] [A general perspective on CBO methods with stochastic rate of information](https://arxiv.org/abs/2507.20029)
*Stefano Almi,Alessandro Baldi,Marco Morandotti,Francesco Solombrino*

Main category: math.OC

TL;DR: 本文研究了一类基于共识的优化（CBO）模型，引入了额外的随机信息率来模拟代理对环境及能量景观的认知。证明了随机系统的适定性、有限粒子近似及向动力学PDE的均值场收敛。在初始空间分布和认知水平的温和假设下，粒子会围绕共识点聚集。分析表明，即使初始认知水平很小，也能实现共识收敛。该框架具有普适性，可涵盖文献中首批CBO实例。


<details>
  <summary>Details</summary>
Motivation: 研究旨在扩展共识优化模型，通过引入随机信息率来更真实地模拟代理对环境的认知过程，填补现有理论空白并提升模型实用性。

Method: 采用随机微分方程建模，结合有限粒子系统近似与均值场极限分析，通过理论证明验证系统适定性和收敛性。

Result: 证明了系统在任意小初始认知水平下均可实现共识收敛，粒子分布最终集中于共识点，且框架兼容经典CBO模型。

Conclusion: 该研究为共识优化提供了更一般的理论框架，揭示了认知水平对收敛的关键作用，为后续算法设计奠定理论基础。

Abstract: This paper studies a class of Consensus-Based Optimization (CBO) models
featuring an additional stochastic rate of information, modeling the agents'
knowledge of the environment and energy landscape. The well-posedness of the
stochastic system is proved, together with its finite-particle approximation
and the mean-field convergence to a kinetic PDE. Particles are shown to
concentrate around the consensus point under mild assumptions on the initial
spatial distribution and initial level of knowledge. In particular, the
analysis unveils that a positive, however small, initial level of knowledge is
enough for convergence to consensus to happen. The framework presented is
general enough to include the first instances of CBO proposed in the
literature.

</details>


### [21] [Fully Coupled Nonlinear FBS$Δ$Es: Maximum principle and LQ Control Insights](https://arxiv.org/abs/2507.20075)
*Zhipeng Niu,Jun Moon,Qingxin Meng*

Main category: math.OC

TL;DR: 本文研究了一类非线性全耦合正倒向随机差分方程（FBS$\Delta$Es）的最优控制问题，在控制域凸性假设下建立了包含哈密顿量和伴随系统的代价函数变分公式，并利用庞特里亚金极大值原理推导了最优控制的必要与充分条件。


<details>
  <summary>Details</summary>
Motivation: 探讨非线性全耦合正倒向随机差分方程的最优控制问题，为随机控制系统提供理论框架与应用验证。

Method: 在控制域凸性假设下，通过建立哈密顿量和伴随系统的变分公式，应用庞特里亚金极大值原理进行分析。

Result: 推导出最优控制的必要与充分条件，并通过线性二次最优控制问题验证理论结果的有效性。

Conclusion: 所提出的理论框架成功解决了特定非线性随机差分系统的最优控制问题，并通过实例验证了方法的实用性。

Abstract: This paper investigates the optimal control problem for a class of nonlinear
fully coupled forward-backward stochastic difference equations (FBS$\Delta$Es).
Under the convexity assumption of the control domain, we establish a
variational formula for the cost functional involving the Hamiltonian and
adjoint system. Both necessary and sufficient conditions for optimal control
are derived using the Pontryagin maximum principle. As an application, we
present a linear quadratic optimal control problem to illustrate our
theoretical results.

</details>


### [22] [A direct approach of the existence of the solution to a Riccati equation](https://arxiv.org/abs/2507.20171)
*Gabriela Marinoschi*

Main category: math.OC

TL;DR: 本文通过希尔伯特-施密特算子空间中的直接算子方法，研究了代数Riccati方程解的存在性，并应用于$H^{\infty}$最优控制问题。


<details>
  <summary>Details</summary>
Motivation: 研究代数Riccati方程解的存在性，以解决$H^{\infty}$最优控制问题中的状态反馈控制难题。

Method: 在希尔伯特-施密特算子空间中采用直接算子方法，分别在$A$强制和$A\geq 0$的条件下，证明了方程解的存在性。

Result: 在算子$\Gamma$和$F$满足特定假设的条件下，证明了代数Riccati方程解的存在性，并给出了相关$H^{\infty}$最优控制问题的结果。

Conclusion: 通过Hardy型奇异势抛物方程的应用示例，验证了Riccati方程解存在性证明的有效性。

Abstract: Finding the state feedback control in an $% H^{\infty }$-optimal control
problem involves a challenging approach of the associated algebraic Riccati
equation of the generic form $A^{\ast }P+PA+P\Gamma P=F$. In view of this
objective, we explore first in this paper the existence of the solution to this
algebraic Riccati equation by a direct operatorial approach in the space of
Hilbert-Schmidt operators. The proofs are provided, under certain assumptions
on the operators $\Gamma $ and $F,$ for the cases with $A$ coercive and $A\geq
0,$ respectively. Next, relying on the existence of the solution to the Riccati
equation, we provide a result concerning the associated $H^{\infty }$-optimal
control problem. An example regarding the application of the existence proof
for the solution to the Riccati equation is given for a parabolic equation with
a singular potential of Hardy type.

</details>


### [23] [Multiobjective Accelerated Gradient-like Flow with Asymptotic Vanishing Normalized Gradient](https://arxiv.org/abs/2507.20183)
*Yingdong Yin*

Main category: math.OC

TL;DR: 本文扩展了Wang等人的梯度系统，将其应用于多目标优化，提出了新的动力学系统并分析了其收敛性，同时推广了FISC-nes算法，数值实验显示其具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 将单目标优化中的梯度系统扩展到多目标优化，研究其动力学行为与收敛性能，以解决多目标优化问题。

Method: 提出了一个包含单位范数梯度项修正的动力学系统：$\ddot x(t)+\frac{\alpha}{t}\dot x(t)+\frac{\alpha -\beta}{t^p}\frac{\|\dot x(t)\|}{\|\proj_{C(x(t))}(0)\|}\proj_{C(x(t))}(0)+\proj_{C(x(t))}(-\ddot x(t))=0$，其中$C(x(t))$为梯度凸包。通过构建评价函数分析轨迹解的收敛性。

Result: 对于$p>1$且$\alpha>\beta\ge3$，获得$O(1/t^2)$的收敛速率；当$\beta>3$时，轨迹解收敛到弱Pareto解。对于$p=1$且$\alpha>\beta\ge3$，收敛速率为$O(\ln^2 t/t^2)$。推广的FISC-nes算法达到$O(\ln^2k/k^2)$的收敛速率。

Conclusion: 所提出的系统与算法在多目标优化中表现出良好的收敛性能，数值实验验证了其竞争力。

Abstract: In this paper, we extend the gradient system with unit-norm gradient term
modification proposed by Wang et al.\cite{wang2021search} to multiobjective
optimization, studying the following system: $$ \ddot x(t)+\frac{\alpha
}{t}\dot x(t)+\frac{\alpha -\beta }{t^p}\frac{\|\dot
x(t)\|}{\|\proj_{C(x(t))}(0)\|}\proj_{C(x(t))}(0)+\proj_{C(x(t))}(-\ddot
x(t))=0 $$ where $C(x(t))=\textbf{conv}\{\nabla f_i(x(t)):i=1,\cdots,m\}$,
$f_i(x(t)):\R^n\to \R$ are continuously differentiable convex functions, and
$\alpha \ge \beta \ge 3$. Under certain assumptions, we establish the existence
of trajectory solutions for this system. Using a merit function, we
characterize the convergence of trajectory solutions: For $p>1$, $\alpha >\beta
\ge 3$, we obtain a convergence rate of $O(1/t^2)$. When $\beta >3$, the
trajectory solutions converge to a weak Pareto solution of the multiobjective
optimization problem $\min _{x}(f_1(x),\cdots,f_m(x))^\top$. For $p=1$, $\alpha
>\beta \ge 3$, we derive a convergence rate of $O(\ln^2 t/t^2)$. We further
generalize Wang et al.'s FISC-nes algorithm to multiobjective optimization,
achieving a convergence rate of $O(\ln^2k/k^2)$. The numerical experiments
demonstrate that our system and algorithm exhibit competitive performance.

</details>


### [24] [On the Finiteness Property of the Polynomial Complementarity Problem](https://arxiv.org/abs/2507.20339)
*Sonali Sharma,V. Vetrivel*

Main category: math.OC

TL;DR: 本文通过引入非退化张量元组和强非退化张量元组两类新结构，研究了多项式互补问题(PCP)解集的有限性，并建立了保证解集有限的充分条件。


<details>
  <summary>Details</summary>
Motivation: 探索多项式互补问题(PCP)解集的有限性，扩展非退化张量的概念以建立更一般的理论框架。

Method: 引入非退化张量元组和强非退化张量元组两类新结构，研究其性质及相互关系，并在这些结构背景下分析PCP解集的有限性。

Result: 建立了保证PCP解集有限的充分条件，并推导出张量互补问题解集有限性的相关结果。

Conclusion: 通过推广非退化张量概念，本文为多项式互补问题解集的有限性研究提供了新的理论工具和结论。

Abstract: This paper explores the finiteness of the solution set of the polynomial
complementarity problem (PCP). To achieve this goal, we introduce two new
classes of structured tensor tuples, namely the nondegenerate tensor tuple and
the strong nondegenerate tensor tuple, as a generalization of nondegenerate
tensors, and discuss their properties and interconnections. We investigate the
finiteness of the solution set of the PCP in the context of these structured
tensor tuples and establish a sufficient condition that guarantees a finite
solution set. As a consequence, we establish a result related to the finiteness
of the solution set of tensor complementarity problems.

</details>


### [25] [The Augmented Mixing Method: Computing High-Accuracy Primal-Dual Solutions to Large-Scale SDPs via Column Updates](https://arxiv.org/abs/2507.20386)
*Daniel Brosch,Jan Schwiddessen,Angelika Wiegele*

Main category: math.OC

TL;DR: 本文提出了一种名为增强混合方法的新算法，结合Burer-Monteiro分解与不精确增广拉格朗日框架及块坐标下降方案，旨在高效解决大规模半定规划问题，尤其在处理高精度解和不等式约束方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常优先考虑可扩展性而非解精度，无法满足大规模半定规划（SDP）问题的高精度需求。本文旨在开发一种既能高效求解子问题又能保证高精度的方法。

Method: 该方法结合Burer-Monteiro分解、不精确增广拉格朗日框架和块坐标下降方案，直接处理不等式约束，无需引入松弛变量，并采用动态惩罚参数更新策略以平衡原始和对偶可行性进展。

Result: 该方法在默认参数下表现出强大的实际性能，能够计算高度精确的原始-对偶解，甚至适用于超过一千万个不等式约束的大规模SDP问题，其精度和可扩展性优于现有内点法。

Conclusion: 增强混合方法在解决大规模SDP问题时表现出色，其开源的Julia实现内存高效、可定制，并支持任意精度算术，为实际应用提供了灵活且高效的解决方案。

Abstract: The Burer-Monteiro factorization has become a powerful tool for solving
large-scale semidefinite programs (SDPs), enabling recently developed low-rank
solvers to tackle problems previously beyond reach. However, existing methods
are typically designed to prioritize scalability over solution accuracy. We
introduce the Augmented Mixing Method, a new algorithm that combines the
Burer-Monteiro factorization with an inexact augmented Lagrangian framework and
a block coordinate descent scheme. Our method emphasizes solving the resulting
subproblems efficiently and to high precision. Inequality constraints are
handled directly, without reformulation or introducing slack variables. A novel
dynamic update strategy for the penalty parameter ensures that primal and dual
feasibility progress remain balanced. This approach enables our method to
compute highly accurate primal-dual solutions, even for large-scale SDPs with
more than ten million inequality constraints. Despite lacking theoretical
convergence guarantees, the Augmented Mixing Method shows strong practical
performance with default parameters, across a wide range of SDP instances. It
often produces more accurate primal-dual solutions than state-of-the-art
interior-point methods and scales significantly better. Our open-source Julia
implementation is memory-efficient, customizable, and supports
arbitrary-precision arithmetic.

</details>


### [26] [Beyond Value Functions: Single-Loop Bilevel Optimization under Flatness Conditions](https://arxiv.org/abs/2507.20400)
*Liuyuan Jiang,Quan Xiao,Lisha Chen,Tianyi Chen*

Main category: math.OC

TL;DR: 本文提出了一种无价值函数的高效双层优化算法PBGD-Free，用于大语言模型微调，通过单循环更新显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统双层优化算法在大型语言模型微调中因需要计算Hessian向量或嵌套循环更新而效率低下，亟需一种更高效的方法。

Method: 基于完全一阶惩罚方法，提出PBGD-Free算法，消除下层问题求解循环，采用单循环更新，并通过表示学习问题的景观分析提出上层函数松弛平坦性条件。

Result: 实验表明，该算法在多种应用中均优于现有双层优化方法，计算效率显著提升。

Conclusion: PBGD-Free算法通过理论收敛证明和实际应用验证，为大规模语言模型微调提供了一种高效的双层优化解决方案。

Abstract: Bilevel optimization, a hierarchical optimization paradigm, has gained
significant attention in a wide range of practical applications, notably in the
fine-tuning of generative models. However, due to the nested problem structure,
most existing algorithms require either the Hessian vector calculation or the
nested loop updates, which are computationally inefficient in large language
model (LLM) fine-tuning. In this paper, building upon the fully first-order
penalty-based approach, we propose an efficient value function-free (PBGD-Free)
algorithm that eliminates the loop of solving the lower-level problem and
admits fully single-loop updates. Inspired by the landscape analysis of
representation learning-based LLM fine-tuning problem, we propose a relaxed
flatness condition for the upper-level function and prove the convergence of
the proposed value-function-free algorithm. We test the performance of the
proposed algorithm in various applications and demonstrate its superior
computational efficiency over the state-of-the-art bilevel methods.

</details>


### [27] [Relax-and-Cut for Temporal SCUC Decomposition](https://arxiv.org/abs/2507.20465)
*Jinxin Xiong,Linxin Yang,Yingxiao Wang,Yanting Huang,Jianghua Wu,Shunbo Lei,Akang Wang*

Main category: math.OC

TL;DR: 本文提出了一种创新的松弛-切割框架，用于解决安全约束机组组合（SCUC）问题，通过增强的时间分解策略和动态切割平面机制，显著提高了计算效率和解决方案质量。


<details>
  <summary>Details</summary>
Motivation: 传统的SCUC解决方法由于组合复杂性、大规模网络维度和众多安全约束，存在计算困难，且固定短期时间窗口导致解决方案短视和次优。

Method: 采用增强的时间分解策略，保留当前机组决策的整数变量，放松未来时间段的完整性约束；开发动态切割平面机制，选择性引入N-1应急约束；可选地使用松弛诱导邻域搜索进行解决方案优化。

Result: 在大规模系统（多达13,000个节点）上的实验表明，该方法能实现低于1%的最优性差距，仅需Gurobi整体解决方案20%的计算时间，相比现有分解方法，原始差距减少60%，求解速度提高一倍。

Conclusion: 该方法在解决方案质量和计算效率方面均有显著提升，特别适合实际SCUC应用，其中这两方面因素均至关重要。

Abstract: The Security-Constrained Unit Commitment (SCUC) problem presents formidable
computational challenges due to its combinatorial complexity, large-scale
network dimensions, and numerous security constraints. While conventional
temporal decomposition methods achieve computational tractability through fixed
short-term time windows, this limited look-ahead capability often results in
suboptimal, myopic solutions. We propose an innovative relax-and-cut framework
that alleviates these limitations through two key innovations. First, our
enhanced temporal decomposition strategy maintains integer variables for
immediate unit commitment decisions while relaxing integrality constraints for
future time periods, thereby extending the optimization horizon without
compromising tractability. Second, we develop a dynamic cutting-plane mechanism
that selectively incorporates N-1 contingency constraints during the
branch-and-cut process, avoiding the computational burden of complete upfront
enumeration. The framework optionally employs a Relaxation-Induced Neighborhood
Search procedure for additional solution refinement when computational
resources permit. Comprehensive numerical experiments demonstrate the
effectiveness of our approach on large-scale systems up to 13,000 buses. The
proposed method can achieve optimality gaps below 1% while requiring only 20%
of the computation time of monolithic Gurobi solutions. Compared to existing
decomposition approaches, our framework provides superior performance,
simultaneously reducing primal gaps by 60% and doubling solution speed. These
significant improvements make our method particularly well-suited for practical
SCUC implementations where both solution quality and computational efficiency
are crucial.

</details>


### [28] [Post-estimation Adjustments in Data-driven Decision-making with Applications in Pricing](https://arxiv.org/abs/2507.20501)
*Michael Albert,Max Biggs,Ningyuan Chen,Guan Wang*

Main category: math.OC

TL;DR: 本文提出了一种改进预测-优化（PTO）框架的数据驱动后估计调整方法，通过考虑目标函数的不对称性来提升决策质量，特别适用于小样本或新产品的定价场景。


<details>
  <summary>Details</summary>
Motivation: 传统PTO框架因估计步骤未考虑下游优化问题结构，可能导致次优决策。目标函数在PTO决策下对估计误差的不对称性会系统性降低预期结果质量。

Method: 开发了一种基于目标函数曲率条件（三阶与二阶导数比）的后估计调整方法，该条件适用于线性、对数线性及幂律需求模型，并可扩展至多参数优化和偏估计场景。

Result: 理论证明该调整方法在满足曲率条件时具有闭式解，能一致且渐进地优于标准PTO。数值实验显示其显著提升收入，尤其在估计不确定性突出的小样本场景中。

Conclusion: 所提方法在保持PTO实用性和模块化优势的同时，有效解决了估计误差不对称性问题，特别适合历史价格数据有限的新产品定价应用。

Abstract: The predict-then-optimize (PTO) framework is a standard approach in
data-driven decision-making, where a decision-maker first estimates an unknown
parameter from historical data and then uses this estimate to solve an
optimization problem. While widely used for its simplicity and modularity, PTO
can lead to suboptimal decisions because the estimation step does not account
for the structure of the downstream optimization problem. We study a class of
problems where the objective function, evaluated at the PTO decision, is
asymmetric with respect to estimation errors. This asymmetry causes the
expected outcome to be systematically degraded by noise in the parameter
estimate, as the penalty for underestimation differs from that of
overestimation. To address this, we develop a data-driven post-estimation
adjustment that improves decision quality while preserving the practicality and
modularity of PTO. We show that when the objective function satisfies a
particular curvature condition, based on the ratio of its third and second
derivatives, the adjustment simplifies to a closed-form expression. This
condition holds for a broad range of pricing problems, including those with
linear, log-linear, and power-law demand models. Under this condition, we
establish theoretical guarantees that our adjustment uniformly and
asymptotically outperforms standard PTO, and we precisely characterize the
resulting improvement. Additionally, we extend our framework to multi-parameter
optimization and settings with biased estimators. Numerical experiments
demonstrate that our method consistently improves revenue, particularly in
small-sample regimes where estimation uncertainty is most pronounced. This
makes our approach especially well-suited for pricing new products or in
settings with limited historical price variation.

</details>


### [29] [An Image Noise Level Estimation Based on Tensor T-Product](https://arxiv.org/abs/2507.20515)
*Hanxin Liu,Yisheng Song*

Main category: math.OC

TL;DR: 提出了一种新的彩色图像噪声水平估计算法，通过直接处理三阶张量并利用T乘积分解，避免了传统方法破坏数据结构的问题，并通过学习关系系数提高了估计精度。


<details>
  <summary>Details</summary>
Motivation: 现有算法通过单独处理三阶张量的每一页来估计噪声水平，破坏了数据结构，导致估计结果不准确。为避免这一问题，需要一种能保持张量结构完整的新方法。

Method: 采用大小为${M_1} \times {M_1} \times 3$的滑动块直接选取张量，重新排列后通过T乘积分解为块对角矩阵形式，利用其特征值与噪声水平的关系，通过学习方法训练关系系数来估计噪声水平。

Result: 数值实验验证了算法的有效性，新方法在噪声水平估计上达到了较高的精度。

Conclusion: 所提出的算法通过保持张量数据结构的完整性，显著提高了彩色图像噪声水平估计的准确性，具有实际应用价值。

Abstract: Currently, the noise level of color images is estimated by many algorithms
through separate selection of each page of the third-order tensor using sliding
blocks of size ${M_1} \times {M_1}$. The data structure of the tensor is
disrupted by this method, leading to errors in the estimation results. In order
not to disrupt the data structure of the tensor, we directly select the tensor
using a sliding block of size ${M_1} \times {M_1} \times 3$ and then re-arrange
it. The newly obtained tensor is decomposed into a block diagonal matrix form
through T-product. It is demonstrated that the eigenvalues of this matrix are
related to the noise level of the color image. Then train the relationship
coefficients through learning methods, thereby obtaining the estimated noise
level. The effectiveness of the algorithm was verified through numerical
experiments, and it also achieved high estimation accuracy.

</details>


### [30] [Computing an optimal single machine schedule with sequence dependent setup times using shortest path computations](https://arxiv.org/abs/2507.20611)
*Dominik Leib,Till Heller,Raphael Kühn*

Main category: math.OC

TL;DR: 研究针对制造业中的单机调度问题，提出一种基于图路径搜索的优化方法，特别适用于橡胶地板生产中的温度与颜色转换场景。


<details>
  <summary>Details</summary>
Motivation: 制造业（如橡胶地板生产）中，工序间的温度与颜色转换导致序列依赖的准备时间，严重影响生产效率和能源利用率，亟需优化调度方案。

Method: 将调度问题转化为分层图中的路径搜索问题，通过图结构直接编码序列依赖效应，利用经典最短路径算法求解最优作业序列。

Result: 该方法在两色案例中具有多项式时间复杂度，揭示了最优调度的关键结构特性，兼具理论严谨性与实际应用价值。

Conclusion: 该框架为序列依赖准备时间的调度问题提供了高效的理论解法，尤其适用于制造业中具有复杂转换约束的生产场景。

Abstract: We study a single-machine scheduling problem with sequence dependent setup
times, motivated by applications in manufacturing and service industries - in
particular, the calendering stage in rubber flooring production. In this phase,
setup times are primarily driven by temperature and color transitions between
consecutive jobs, with significant impact on throughput and energy efficiency.
We present a novel solution framework that transforms the scheduling problem
into a path-finding problem on a specially constructed layered graph. By
encoding sequence-dependent effects directly into the graph's structure, we
enable the use of classical shortest-path algorithms to compute optimal job
sequences. The resulting method is polynomial-time solvable for the two-color
case and reveals key structural properties of optimal schedules. Our approach
thus provides both a theoretically grounded and practically applicable
optimization technique.

</details>


### [31] [Subspace decomposition in regularized least-squares: solution properties, restricted coercivity and beyond](https://arxiv.org/abs/2507.20686)
*Feng Xue,Hui Zhang*

Main category: math.OC

TL;DR: 本文通过子空间分解技术研究了正则化最小二乘问题的解性质，提出了解集的共轭函数表达，并分析了存在性、紧致性和唯一性。与现有工作不同，本文单独讨论了存在性与紧致性，统一了多种现有结果，并通过引入限制强制性的概念深化了分析。


<details>
  <summary>Details</summary>
Motivation: 研究正则化最小二乘问题的解性质，旨在通过共轭函数表达解集，统一现有理论中的衰退锥和次水平集概念，并探讨限制强制性的新概念。

Method: 采用子空间分解技术，通过共轭函数表达解集，将存在性与紧致性分开讨论，并关联衰退函数与共轭函数次微分的衰退锥。同时，以类似方式讨论了线性约束对应问题。

Result: 提出了解集的共轭函数表达，统一了现有理论中的多种结果，并建立了正则化最小二乘与线性约束问题的联系。通过极下后复合的精确性进一步验证了结果，并以lasso解的简单几何为例进行了说明。

Conclusion: 本文通过共轭函数和子空间分解技术，深化了对正则化最小二乘问题解性质的理解，提出了限制强制性的新概念，并为未来研究lasso解的几何性质提供了方向。

Abstract: We study the solution properties of regularized lease-squares problem. By the
  subspace decomposition technique, we develop expressions of the solution set
in terms of conjugate
  function, from which various properties, including existence, compactness and
uniqueness, can then
  be easily analyzed. An important difference of our approach from the existing
works is that the
  existence and compactness are discussed separately. Many existing results
under the notions of
  recession cone and sublevel set are unified, and further connected to our
results by associating
  recession function with the recession cone of subdifferential of conjugate
function. In particular, the
  concept of restricted coercivity is developed and discussed in various
aspects. The associated linearly
  constrained counterpart is discussed in a similar manner. Its connections to
regularized least-squares
  are further established via the exactness of infimal postcomposition. Our
results are supported by
  many examples, where the simple geometry of lasso solution deserves further
investigations in near
  future.

</details>


### [32] [The Ellipsoidal Separation Machine](https://arxiv.org/abs/2507.20698)
*Antonio Frangioni,Enrico Gorgone,Benedetto Manca*

Main category: math.OC

TL;DR: 本文提出了首个完整实现的基于凸体分离（SCB）的分类方法——椭球分离机（ESM），通过椭球体分离两类数据，其训练问题与支持向量机（SVM）类似但可处理不确定点，适用于带拒识的分类任务。


<details>
  <summary>Details</summary>
Motivation: 现有分类方法如SVM在处理不确定点时缺乏明确机制，而SCB框架下的椭球分离能天然识别不确定区域，为带拒识分类（CwR）提供新思路。

Method: 将训练问题构造为凸的半定规划（SDP），但标准解法难以扩展；提出非凸的块高斯-赛德尔法，交替求解小规模SDP和可分离二阶锥规划（SOCP），并通过拉格朗日松弛快速近似求解。

Result: 在多个数据集上，ESM与核SVM性能相当但行为差异显著，其显式不确定点机制为CwR任务提供了独特优势。

Conclusion: ESM作为SCB框架的首个实用实现，扩展了分类器工具箱，特别适合需要明确拒识能力的场景，其与SVM的差异性为分类任务提供了新选择。

Abstract: We propose the -- to the best of our knowledge -- first fully functional
implementation of the ``Separation by a Convex Body'' (SCB) approach first
outlined in Grzybowski et al. [1] for classification, separating two data sets
using an ellipsoid. A training problem is defined that is structurally similar
to the Support Vector Machine (SVM) one, thus leading to call our method the
Ellipsoidal Separation Machine (ESM). Like SVM, the training problem is convex,
and can in particular be formulated as a Semidefinite Program (SDP); however,
solving it by means of standard SDP approaches does not scale to the size
required by practical classification task. As an alternative, a nonconvex
formulation is proposed that is amenable to a Block-Gauss-Seidel approach
alternating between a much smaller SDP and a simple separable Second-Order Cone
Program (SOCP). For the purpose of the classification approach the reduced SDP
can even be solved approximately by relaxing it in a Lagrangian way and
updating the multipliers by fast subgradient-type approaches. A characteristic
of ESM is that it necessarily defines ``indeterminate points'', i.e., those
that cannot be reliably classified as belonging to one of the two sets. This
makes it particularly suitable for Classification with Rejection (CwR) tasks,
whereby the system explicitly indicates that classification of some points as
belonging to one of the two sets is too doubtful to be reliable. We show that,
in many datasets, ESM is competitive with SVM -- with the kernel chosen among
the three standard ones and endowed with CwR capabilities using the margin of
the classifier -- and in general behaves differently; thus, ESM provides
another arrow in the quiver when designing CwR approaches.

</details>


### [33] [Electrolyzers Bidding in Electricity Markets under Green Hydrogen Regulations and Uncertainty](https://arxiv.org/abs/2507.20702)
*Andrea Gloppen Johnsen,Lesia Mitridati,Jalal Kazempour,Line Roald*

Main category: math.OC

TL;DR: 电解制氢虽可助力脱碳，但电网连接可能导致排放增加。研究提出考虑可再生能源不确定性的日前投标曲线，以提高电解槽利润，但发现时间匹配监管的激励效果可能被扭曲。


<details>
  <summary>Details</summary>
Motivation: 电网连接的电解槽可能增加电力系统排放，使氢生命周期排放与灰氢相当。欧盟和美国的补贴政策要求时间匹配可再生能源发电，这给电解槽带来不确定性。

Method: 开发了一种考虑不确定性的日前投标曲线，通过线性规划最大化预期利润，并基于Karush-Kuhn-Tucker条件推导投标曲线。

Result: 案例研究表明，考虑可再生能源不确定性可使电解槽利润提高约4%，但未能改善事后时间匹配。

Conclusion: 研究揭示了在考虑不确定性的情况下，时间匹配监管的激励效果可能存在扭曲。

Abstract: Hydrogen produced through electrolysis offers a pathway to decarbonize
hard-to-abate sectors by replacing gray hydrogen derived from natural gas
reforming when produced using renewable power. However, grid-connected
electrolyzers may inadvertently increase power-system emissions, resulting in
hydrogen whose life-cycle intensity is similar to or higher than that of gray
hydrogen. To address the high cost barrier of electrolytic hydrogen, both the
E.U. and U.S. have introduced subsidy schemes conditional on low associated
emissions. One key requirement is temporal matching, under which a subsidy
applies only to the hydrogen volume that, ex-post, can be shown to match
renewable generation over each one-hour interval. This requirement exposes the
electrolyzer to uncertainty in the subsidy-eligible volume and thus the value
of the produced hydrogen. This paper develops an uncertainty-aware day-ahead
bid curve for a grid-connected electrolyzer. We formulate a linear program that
maximizes expected profit across scenarios of renewable production and derive
the bid curve from its Karush-Kuhn-Tucker conditions. A case study demonstrates
that incorporating renewable uncertainty into the bid curve increases
electrolyzer profit by approximately 4%, although it does not improve ex-post
temporal matching. This finding highlights a potential distortion in the
incentive effects of temporal-matching regulations when uncertainty is taken
into account.

</details>


### [34] [Fundamental diagram constrained dynamic optimal transport via proximal splitting methods](https://arxiv.org/abs/2507.20717)
*Anqi Dong,Karl Henrik Johansson,Johan Karlsson*

Main category: math.OC

TL;DR: 本文提出了一种结合动态约束的最优传输框架，用于模拟宏观交通流，通过引入动量约束捕捉交通拥堵效应，并开发了高效的近端分裂算法进行求解。


<details>
  <summary>Details</summary>
Motivation: 传统最优传输框架缺乏动态特性（如Lighthill-Whitham-Richards模型），无法有效描述交通流中的饱和与拥堵现象。本文旨在将交通理论中的基本图原理融入最优传输，建立动态约束下的变分模型。

Method: 基于Benamou-Brenier传输理论，构建凸性动态最优传输问题，添加动量场的非线性时空不等式约束（反映基本图特性）。采用Douglas-Rachford和Chambolle-Pock等近端分裂算法，利用约束集的可分离结构实现高效求解。

Result: 数值实验验证了约束对传输行为的影响，包括拥堵感知的路径扩散、改道及收敛特性。算法能处理时变空间限制，为Wasserstein梯度流提供可扩展的变分工具。

Conclusion: 该框架建立了最优传输与宏观交通流理论的联系，为拥堵约束下的质量传输提供了新型建模方法，其变分形式兼具理论严谨性与计算可行性。

Abstract: Optimal transport has recently been brought forward as a tool for modeling
and efficiently solving a variety of flow problems, such as origin-destination
problems and multi-commodity flow problems. Although the framework has shown to
be effective for many large scale flow problems, the formulations typically
lack dynamic properties used in common traffic models, such as the
Lighthill-Whitham-Richards model. In this work, we propose an optimal transport
framework that includes dynamic constraints specified by the fundamental
diagram for modeling macroscopic traffic flow. The problem is cast as a convex
variant of dynamic optimal transport, with additional nonlinear
temporal-spatial inequality constraints of momentum, modeled after the
fundamental diagram from traffic theory. This constraint imposes a
density-dependent upper bound on the admissible flux, capturing flow saturation
and congestion effects, and thus leaves space for kinetic optimization. The
formulation follows the Benamou-Brenier transportation rationale, whereby
kinetic energy over density and momentum fields is optimized subject to the
mass conservation law. We develop proximal splitting methods, namely the
Douglas-Rachford and Chambolle-Pock algorithms, which exploit the separable
structure of the constraint set and require only simple proximal operations,
and can accommodate additional (time-varying) spatial restrictions or
obstacles. Numerical experiments illustrate the impact of the constraint on
transport behavior, including congestion-aware spreading, rerouting, and
convergence. The framework establishes a connection between optimal transport
and macroscopic traffic flow theory and provides a scalable, variational tool
for modeling congestion-constricted (or saturation-aware) Wasserstein gradient
flow.

</details>


### [35] [Accelerating Deterministic Global Optimization via GPU-parallel Interval Arithmetic](https://arxiv.org/abs/2507.20769)
*Hongzhen Zhang,Tim Kerkenhoff,Neil Kichler,Manuel Dahmen,Alexander Mitsos,Uwe Naumann,Dominik Bongartz*

Main category: math.OC

TL;DR: 本文提出了一种基于GPU并行化的空间分支定界(B&B)算法，通过区间划分和均值形式计算目标函数与约束的紧致下界，相比传统CPU方法实现了三个数量级的加速，并在部分案例中优于McCormick松弛法。


<details>
  <summary>Details</summary>
Motivation: 传统空间B&B算法计算成本高，现有CPU并行优化研究较多，但GPU并行潜力尚未充分挖掘。本研究旨在利用GPU大规模并行能力加速非凸问题的全局优化求解。

Method: 1) 将B&B节点域划分为多个子域 2) 使用GPU并行计算各子域上均值形式的区间边界 3) 在开源求解器MAiNGO中实现两种CUDA方案：单内核函数封装与CUDA图任务分配

Result: 1) 子域数量增加显著提升边界紧密度，减少B&B迭代次数 2) 相比CPU无划分区间算法，实现1000倍加速 3) CUDA图实现效率更高，部分案例性能超越McCormick松弛求解器

Conclusion: GPU加速的边界计算技术能有效提升B&B算法效率，均值形式区间划分法在保持计算速度的同时提供更紧致边界，为全局优化问题提供了新解决方案。

Abstract: Spatial Branch and Bound (B&B) algorithms are widely used for solving
nonconvex problems to global optimality, yet they remain computationally
expensive. Though some works have been carried out to speed up B&B via CPU
parallelization, GPU parallelization is much less explored. In this work, we
investigate the design of a spatial B&B algorithm that involves an
interval-based GPU-parallel lower bounding solver: The domain of each B&B node
is temporarily partitioned into numerous subdomains, then massive GPU
parallelism is leveraged to compute interval bounds of the objective function
and constraints on each subdomain, using the Mean Value Form. The resulting
bounds are tighter than those achieved via regular interval arithmetic without
partitioning, but they remain fast to compute. We implement the method into our
open-source solver MAiNGO via CUDA in two manners: wrapping all GPU tasks
within one kernel function, or distributing the GPU tasks onto a CUDA graph.
Numerical experiments show that using more subdomains leads to significantly
tighter lower bounds and thus less B&B iterations. Regarding wall clock time,
the proposed spatial B&B framework achieves a speedup of three orders of
magnitude compared to applying interval arithmetic on the CPU without domain
partitioning. Among the two implementations, the one developed with CUDA graph
enables higher efficiency. Moreover, in some case studies, the proposed method
delivers competitive or better performance compared to MAiNGO's default solver
which is based on McCormick relaxations. These results highlight the potential
of GPU-accelerated bounding techniques to accelerate B&B algorithms.

</details>


### [36] [Numerical Design of Optimized First-Order Algorithms](https://arxiv.org/abs/2507.20773)
*Yassine Kamri,Julien M. Hendrickx,François Glineur*

Main category: math.OC

TL;DR: 本文提出了一种基于性能估计问题（PEP）框架的数值方法，用于设计无约束凸优化中的一阶算法，并在多种梯度下降算法中实现了加速收敛。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过数值方法优化一阶算法的步长设计，特别是在无记忆和全记忆梯度下降算法中，以提升收敛速度。

Method: 采用性能估计问题（PEP）框架，将优化算法的最坏情况分析转化为优化问题本身，并应用于无记忆梯度下降、坐标下降、非精确梯度下降和循环梯度下降等算法的步长优化。

Result: 在所有测试案例中，新方法设计的步长显著提升了经典算法的收敛速度，尤其是在线性收敛背景下。

Conclusion: 通过PEP框架设计的数值方法能够有效优化一阶算法的步长，实现比传统算法更快的收敛速度，适用于多种梯度下降变体。

Abstract: We derive several numerical methods for designing optimized first-order
algorithms in unconstrained convex optimization settings. Our methods are based
on the Performance Estimation Problem (PEP) framework, which casts the
worst-case analysis of optimization algorithms as an optimization problem
itself. We benchmark our methods against existing approaches in the literature
on the task of optimizing the step sizes of memoryless gradient descent (which
uses only the current gradient for updates) over the class of smooth convex
functions. We then apply our methods to numerically tune the step sizes of
several memoryless and full (i.e., using all past gradient information for
updates) fixed-step first-order algorithms, namely coordinate descent, inexact
gradient descent, and cyclic gradient descent, in the context of linear
convergence. In all cases, we report accelerated convergence rates compared to
those of classical algorithms.

</details>


### [37] [Route Optimization Over Scheduled Services For Large-Scale Package Delivery Networks](https://arxiv.org/abs/2507.20844)
*Mohammed Faisal Ahmed,Pascal Van Hentenryck,Ahmed El Nashar*

Main category: math.OC

TL;DR: 本文提出了一种列生成启发式算法（CG-heuristic），用于解决大规模拖车路径优化与调度服务问题（TPOSSP），旨在最小化使用调度次数和总行驶里程，并在工业和实时场景中验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: TPOSSP问题涉及在时间依赖网络中优化拖车路径，考虑牵引车容量约束及时间窗口，现有方法难以应对工业级大规模实例，需开发高效求解策略。

Method: 提出网络缩减技术识别可行调度路径，并设计基于时间依赖最短路径定价的稳定化列生成算法，以处理含数亿变量的混合整数规划模型。

Result: 战术规划中，算法在1.7-10.3小时内获得3.7%-5.7%最优间隙，比现有方案提升2.3%-3.2%，年节省数千万美元；实时场景下1分钟内获得3%最优解，网络缩减使运行时间降低85%。

Conclusion: CG-heuristic算法在TPOSSP问题中展现出显著优越性，兼具求解质量与效率，适用于战术规划和实时操作，网络缩减技术大幅提升计算性能。

Abstract: This paper introduces the Trailer Path Optimization with Schedule Services
Problem (TPOSSP) and proposes a column-generation heuristic (CG-heuristic) to
find high-quality solutions to large-scale instances. The TPOSSP aims at
determining trailer routes over a time-dependent network using existing
scheduled services, while considering tractor capacity constraints and time
windows for trailer pickups and deliveries. The objective is to minimize both
the number of schedules used and the total miles traveled. To address the large
scale of industrial instances, the paper proposes a network reduction technique
that identifies the set of feasible schedule-legs for each requests. Moreover,
to address the resulting MIP models, that still contains hundred of millions
variables, the paper proposes a stabilized column-generation, whose pricing
problem is a time-dependent shortest path. The approach is evaluated on
industrial instances both for tactical planning where requests for the entire
network are re-optimized and for real-time operations where new requests are
inserted. In the tactical planning setting, the column-generation heuristic
returns solutions with a 3.7%-5.7% optimality gap (based on a MIP relaxation)
in under 1.7-10.3 hours, and improves the current practice by 2.3-3.2%, with
translates into savings of tens of millions of dollars a year. In the real-time
setting, the column-generation heuristic returns solution within 3% of
optimality in under 1 minute, which makes it adequate for real-time deployment.
The results also show that the network reduction decreases run times by 85% for
the column-generation heuristic.

</details>


### [38] [Iterative Schemes for Markov Perfect Equilibria](https://arxiv.org/abs/2507.20898)
*Felix Höfer,Mathieu Laurière,H. Mete Soner,Qinxin Yan*

Main category: math.OC

TL;DR: 研究连续时间对称玩家动态博弈的马尔可夫完美均衡，通过Nash-Lasry-Lions方程求解，提出高效计算方法的收敛性证明。


<details>
  <summary>Details</summary>
Motivation: 探讨有限对称玩家连续时间动态博弈中的均衡问题，旨在解决Nash-Lasry-Lions方程的计算难题。

Method: 将问题转化为非线性常微分方程，利用唯一经典解性质，证明Picard迭代与加权Picard迭代的收敛性。

Result: 数值实验验证了基于该方法的算法有效性，为有限状态空间问题提供了高效计算途径。

Conclusion: 通过理论分析与数值验证，确立了求解对称玩家动态博弈均衡的高效计算框架。

Abstract: We study Markov perfect equilibria in continuous-time dynamic games with
finitely many symmetric players. The corresponding Nash system reduces to the
Nash-Lasry-Lions equation for the common value function, also known as the
master equation in the mean-field setting. In the finite-state space problems
we consider, this equation becomes a nonlinear ordinary differential equation
admitting a unique classical solution. Leveraging this uniqueness, we prove the
convergence of both Picard and weighted Picard iterations, yielding efficient
computational methods. Numerical experiments confirm the effectiveness of
algorithms based on this approach.

</details>


### [39] [Mean-Field Langevin Diffusions with Density-dependent Temperature](https://arxiv.org/abs/2507.20958)
*Yu-Jui Huang,Zachariah Malik*

Main category: math.OC

TL;DR: 本文提出了一种基于密度依赖温度的Langevin扩散方法，用于非凸优化问题，通过自调节机制形成平均场随机微分方程，并证明了其Fokker-Planck方程解的唯一性及长时间行为下的收敛性。


<details>
  <summary>Details</summary>
Motivation: 在非凸优化中，传统Langevin扩散的温度固定，无法根据优化函数的局部特性动态调整。通过使温度依赖于扩散自身的密度函数，可以更好地适应局部极小值的位置和深度，提高优化效率。

Method: 构建了一种自调节的Langevin扩散过程，形成Nemytskii型平均场随机微分方程。利用Wasserstein次微分理论，证明了对应的非线性Fokker-Planck方程解的唯一性，并通过Trevisan叠加原理构造了SDE的弱解。

Result: 证明了该SDE诱导的密度函数随时间收敛到一个不变分布，该分布可用Lambert $W$函数显式表示（$W$函数需转义为$\W$）。

Conclusion: 密度依赖温度的Langevin扩散为非凸优化提供了新的理论框架，其自调节机制和收敛性证明为复杂优化问题的求解开辟了新途径。

Abstract: In the context of non-convex optimization, we let the temperature of a
Langevin diffusion to depend on the diffusion's own density function. The
rationale is that the induced density reveals to some extent the landscape
imposed by the non-convex function to be minimized, such that a
density-dependent temperature can provide location-wise random perturbation
that may better react to, for instance, the location and depth of local
minimizers. As the Langevin dynamics is now self-regulated by its own density,
it forms a mean-field stochastic differential equation (SDE) of the Nemytskii
type, distinct from the standard McKean-Vlasov equations. Relying on
Wasserstein subdifferential calculus, we first show that the corresponding
(nonlinear) Fokker-Planck equation has a unique solution. Next, a weak solution
to the SDE is constructed from the solution to the Fokker-Planck equation, by
Trevisan's superposition principle. As time goes to infinity, we further show
that the density induced by the SDE converges to an invariant distribution,
which admits an explicit formula in terms of the Lambert $W$ function.

</details>


### [40] [Benamou-Brenier and Kantorovich are equivalent on sub-Riemannian manifolds with no abnormal geodesics](https://arxiv.org/abs/2507.20959)
*Giovanna Citti,Mattia Galeotti,Andrea Pinamonti*

Main category: math.OC

TL;DR: 在无边界且无异常测地线的完备子黎曼流形上，证明了Benamou-Brenier与Kantorovich最优传输问题的等价性，并建立了最优传输方案与最小化子之间的联系。


<details>
  <summary>Details</summary>
Motivation: 研究子黎曼流形上两种最优传输问题表述的等价性，为相关理论在非欧几里得空间的应用提供数学基础。

Method: 在无边界且无异常测地线的完备子黎曼流形$M$上，针对紧支撑测度对，分析Benamou-Brenier与Kantorovich两种问题表述。

Result: 证明了两种问题表述在给定条件下的等价性，并构造了Benamou-Brenier问题的最小化解与最优传输方案的联系。

Conclusion: 该成果为子黎曼流形上的最优传输理论建立了重要理论基础，特别适用于紧支撑测度情形。

Abstract: We prove that the Benamou-Brenier formulation of the Optimal Transport
problem and the Kantorovich formulation are equivalent on a sub-Riemannian
connected and complete manifold $M$ without boundary and with no abnormal
geodesics, when the problems are considered between two measures of compact
supports. Furthermore, we prove the existence of a minimizer for the
Benamou-Brenier formulation and link it to the optimal transport plan.

</details>


### [41] [Stochastic gradient with least-squares control variates](https://arxiv.org/abs/2507.20981)
*Fabio Nobile,Matteo Raviola,Nathan Schaeffer*

Main category: math.OC

TL;DR: 提出一种新型随机梯度下降(SGD)方差缩减方法，适用于连续概率分布期望目标函数，通过加权离散最小二乘拟合历史梯度构建控制变量，在保持计算效率的同时提升收敛速度。


<details>
  <summary>Details</summary>
Motivation: 传统SGD收敛速度慢，现有方差缩减技术(如SAGA)仅适用于有限求和形式目标函数，且在项数较多时性能下降。本文针对连续概率分布期望目标函数的优化问题提出改进方案。

Method: 采用加权离散最小二乘法对历史梯度评估拟合线性模型，构建控制变量实现方差缩减，同时保持计算效率。该方法特别适用于随机变量连续分布的场景。

Result: 理论证明了强凸目标函数的次线性收敛保证，并在随机PDE约束优化问题的数值实验中验证了方法的有效性。

Conclusion: 所提出的基于控制变量的方差缩减方法突破了传统技术对有限求和形式的限制，为连续分布期望目标优化提供了高效解决方案，在理论和实验层面均表现出优越性能。

Abstract: The stochastic gradient descent (SGD) method is a widely used approach for
solving stochastic optimization problems, but its convergence is typically
slow. Existing variance reduction techniques, such as SAGA, improve convergence
by leveraging stored gradient information; however, they are restricted to
settings where the objective functional is a finite sum, and their performance
degrades when the number of terms in the sum is large. In this work, we propose
a novel approach which is well suited when the objective is given by an
expectation over random variables with a continuous probability distribution.
Our method constructs a control variate by fitting a linear model to past
gradient evaluations using weighted discrete least-squares, effectively
reducing variance while preserving computational efficiency. We establish
theoretical sublinear convergence guarantees for strongly convex objectives and
demonstrate the method's effectiveness through numerical experiments on random
PDE-constrained optimization problems.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [42] [A series involving a product of four consecutive harmonic numbers](https://arxiv.org/abs/2507.19502)
*Wilson J. Chen,Vincent Nguyen*

Main category: math.NT

TL;DR: 本文使用欧拉的初等方法，计算了一个涉及四次调和数的复杂级数，得到了用黎曼ζ函数值表示的封闭形式，该结果可能构成对Furdui和Sîntămărian猜想的反例，并关联到ζ值的无理性与线性独立性猜想。


<details>
  <summary>Details</summary>
Motivation: 受欧拉对形如$\sum_{k \geq 1} k^{-m}(1 + 2^{-n} + \cdots + k^{-n})$（现称欧拉和）的研究启发，特别是当$n=1$且$m\geq2$时可表示为ζ值的封闭形式。本文旨在解决更复杂的四次调和数级数问题，并探讨其对现有猜想的潜在影响。

Method: 采用欧拉风格的初等技巧，计算级数$\sum_{k \geq 1} \frac{H_k H_{k+1} H_{k+2} H_{k+3}}{k(k+1)(k+2)(k+3)}$，其中$H_k$为第$k$个调和数。通过代数变形将问题转化为ζ值的组合。

Result: 成功获得该级数以黎曼ζ函数值表示的精确封闭形式，此结果可能否定Furdui和Sîntămărian的猜想，并揭示了与ζ值无理性及$\mathbb{Q}$-线性独立性猜想的深层联系。

Conclusion: 研究不仅推广了欧拉和的经典结果，其反例性质为ζ值理论提供了新视角，暗示初等方法在解决现代数论问题中仍具有生命力。

Abstract: In correspondence with Goldbach, Euler began investigating series of the form
  $\sum_{k \geq 1} k^{-m}\left(1 + 2^{-n} + \cdots + k^{-n}\right)$, which are
known today as Euler sums. For the case where $n=1$ and $m \geq 2$, Euler was
able to obtain a closed form in terms of zeta values. We use elementary
techniques in the spirit of Euler to evaluate the series $\sum_{k \geq 1}
\frac{H_k H_{k+1} H_{k+2} H_{k+3}}{k(k+1)(k+2)(k+3)},$ where $H_k := 1 +
\frac{1}{2} + \cdots + \frac{1}{k}$ is the $k$th harmonic number, in terms of
zeta values. The closed form is a potential counterexample to a conjecture of
Furdui and S\^int\u{a}m\u{a}rian. We relate this problem to conjectures
regarding irrationality and $\mathbb{Q}$-linear independence of zeta values.

</details>


### [43] [The Eighth Power Moments of $Δ(x)$](https://arxiv.org/abs/2507.19528)
*Junhao Liao,Junjie Liao*

Main category: math.NT

TL;DR: 利用Voronoi截断公式和贝塞尔函数，推导了八次幂矩的渐近公式，误差项为$O\left(X^{3 - \frac{1}{254} + \varepsilon}\right)$。


<details>
  <summary>Details</summary>
Motivation: 研究八次幂矩的渐近行为，以深化对相关数论函数的理解。

Method: 采用Voronoi截断公式结合贝塞尔函数进行推导。

Result: 得到了误差项为$O\left(X^{3 - \frac{1}{254} + \varepsilon}\right)$的渐近公式。

Conclusion: 该方法有效改进了八次幂矩的渐近估计精度。

Abstract: Using Voronoi's truncated formula for $\Delta(x)$ involving Bessel functions,
the first author derives an asymptotic formula for the eighth-power moments
with an error term of order $O\left(X^{3 - \frac{1}{254} + \varepsilon}\right)$

</details>


### [44] [On finite $β$-expansions for the set of natural numbers](https://arxiv.org/abs/2507.19604)
*Túlio O. Carvalho,Catharina M. Moreira*

Main category: math.NT

TL;DR: 研究了三种Pisot数的$\beta$-展开有限性问题（条件$F_1$），发现一类简单$\beta$-数表现出奇特行为：其无限子集满足$F_1$，而补集不满足。该现象与多项式整数系数模3的余数有关。当$F_1$不成立时，${{\rm Fin}(\beta)}$的补集无限。最后给出了$F_1$成立的简洁充分条件。


<details>
  <summary>Details</summary>
Motivation: 探索非单调序列$\beta$-展开的Pisot数在自然数集上$\beta$-展开的有限性（$F_1$条件），揭示其数学结构特性。

Method: 分析三类$1$的$\beta$-展开非单调的Pisot数族，通过多项式整数系数模3分类研究$F_1$条件的成立规律。

Result: 发现一类$\beta$-数存在无限子集满足$F_1$而补集不满足，且$F_1$不成立时${{\rm Fin}(\beta)}$的补集无限。提出$(\beta-\lfloor \beta\rfloor)^2$的$\beta$-展开有限性作为$F_1$的充分条件。

Conclusion: Pisot数的$\beta$-展开有限性受多项式系数模性质调控，$(\beta-\lfloor \beta\rfloor)^2$的有限展开可保证$F_1$成立，为相关研究提供新工具。

Abstract: We present a study of the problem of finiteness of the $\beta$-expansions for
the set of natural numbers, condition $F_1$ in brief, for three families of
Pisot numbers for which the $\beta$-expansion of 1 is not a non-decreasing
sequence. We show a class of simple $\beta$-numbers which display a puzzling
behaviour, in the sense that an infinite subset of such $\beta$ satisfy $F_1$,
whereas a complementary infinite subset does not. This puzzle is organized by
the residue class modulo 3 of an integer coefficient of the main family of
polynomials discussed. We prove that, when $F_1$ does not hold, the complement
of ${{\rm Fin}(\beta)}$ is infinite. Finally, we give a concise sufficient
condition for $F_1$, which is the finitude of the $\beta$-expansion of
$(\beta-\lfloor \beta\rfloor)^2$.

</details>


### [45] [Traverso's Isogeny Conjecture for Some Unitary p-Divisible Groups](https://arxiv.org/abs/2507.19708)
*Emerald Andrews,Deewang Bhamidipati,Maria Fox,Heidi Goodson,Steven R. Groen,Sandra Nair*

Main category: math.NT

TL;DR: 本文研究了具有签名$(a,b)$的超奇异酉$p$-可分群的同源截断和最小高度，给出了最小高度的完整描述，并建立了同源截断的界限。


<details>
  <summary>Details</summary>
Motivation: 研究$p$-可分群的同源截断和最小高度，以理解其同源类及与最小$p$-可分群的距离。

Method: 通过分析超奇异酉$p$-可分群的签名$(a,b)$，结合Oort的最小$p$-可分群理论，推导其最小高度和同源截断。

Result: 完整描述了超奇异酉$p$-可分群的最小高度可能值，并建立了同源截断的界限。

Conclusion: 结果在$(a,b)$签名酉Shimura簇的$\mathrm{BT}_m$分层语言中重新表述，为相关研究提供了新视角。

Abstract: The isogeny cutoff of a $p$-divisible group $X$ (defined over an
algebraically closed field of characteristic $p$) measures the amount of
$p$-torsion necessary to determine its isogeny class. The minimal height of $X$
measures its distance to the closest minimal $p$-divisible group (in the sense
of Oort). In this paper, we study these invariants for supersingular unitary
$p$-divisible groups of signature $(a,b)$. We provide a complete description of
the possible minimal heights. As an application, we establish bounds on the
isogeny cutoffs for these $p$-divisible groups. Finally, we rephrase our
results in the language of the $\mathrm{BT}_m$ stratifications of unitary
Shimura varieties of signature $(a,b)$.

</details>


### [46] [Truncated Hypergeometric Functions and Discretized Integrals](https://arxiv.org/abs/2507.19793)
*Shuji Yamamoto*

Main category: math.NT

TL;DR: 本文介绍了一种超几何级数的有限截断方法，并提供了其离散化积分表示。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于Maesaka-Seki-Watanabe和Hirose-Matsusaka-Seki关于截断级数与离散化积分之间恒等式的最新成果，这些成果与多重zeta值和多重多对数函数相关。

Method: 我们提出了一种超几何级数的有限截断方法，并给出了其离散化积分表示。

Result: 我们证明了Ohno-Zagier类型的公式，该公式将截断多重多对数函数与截断超几何级数联系起来。

Conclusion: 本文通过截断超几何级数及其离散化积分表示，建立了与多重多对数函数的联系，并证明了相关的重要公式。

Abstract: We introduce a kind of finite truncation of the hypergeometric series and
provide its discretized integral representation. This is motivated by recent
results of Maesaka-Seki-Watanabe and Hirose-Matsusaka-Seki on the identity
between truncated series and discretized integrals which comes from the
mutliple zeta values and multiple polylogarithms. We also prove the formula of
Ohno-Zagier type which relates the truncated multiple polylogarithms and the
truncated hypergeometric series.

</details>


### [47] [On Some Hypergeometric Modularity Conjectures of Dawsey and McCarthy](https://arxiv.org/abs/2507.19971)
*Brian Grove*

Main category: math.NT

TL;DR: 本文基于显式超几何模性方法(EHMM)，构建了新的eta商函数族$\mathbb{K}_{3}$，并应用于解决Dawsey和McCarthy的超几何模性猜想，同时探讨了其在特殊$L$-值和广义Paley图研究中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于此前发展的显式超几何模性方法(EHMM)在二维和三维超几何Galois表示模性证明中的成功应用，特别是$\mathbb{K}_{2}$函数族的构建。本文旨在构建更高维的类比函数族$\mathbb{K}_{3}$，并拓展其应用范围。

Method: 方法上采用Borwein兄弟发展的权为一的三次theta函数理论，构建了新的eta商函数族$\mathbb{K}_{3}$，并将其整合到EHMM框架中，用于验证超几何模性猜想。

Result: 主要成果包括：1) 成功构建$\mathbb{K}_{3}$函数族；2) 解决了Dawsey和McCarthy提出的多个超几何模性猜想；3) 获得了$\mathbb{K}_{3}$函数的特殊$L$-值结果；4) 推进了广义Paley图的相关研究。

Conclusion: 结论表明$\mathbb{K}_{3}$函数族的引入不仅扩展了EHMM的应用维度，还为超几何模性理论、特殊函数值和图论研究提供了新的工具和视角。

Abstract: In recent work, the author, in collaboration with Allen, Long, and Tu,
developed the Explicit Hypergeometric Modularity Method (EHMM), which
establishes the modularity of a large class of hypergeometric Galois
representations in dimensions two and three. One important application of the
EHMM is the construction of an explicit family of eta-quotients, which we call
the $\mathbb{K}_{2}$ functions, from the hypergeometric background. In this
article, we introduce an analogous family of eta-quotients, which we call the
$\mathbb{K}_{3}$ functions. These $\mathbb{K}_{3}$ functions are constructed
using the theory of weight one cubic theta functions originally developed by
Jonathan and Peter Borwein. We then use the $\mathbb{K}_{3}$ functions in the
EHMM to resolve several hypergeometric modularity conjectures of Dawsey and
McCarthy. Further, we provide applications to special $L$-values of the
$\mathbb{K}_{3}$ functions and to the study of generalized Paley graphs.

</details>


### [48] [A p-adic criterion for Lehmer's conjecture](https://arxiv.org/abs/2507.20141)
*Anup B. Dixit,Sushant Kala*

Main category: math.NT

TL;DR: 本文建立了对数Weil高度$h(\alpha)$与代数数$\alpha$在$\mathbb{Q}_p$有限扩张中共轭点数量之间的$p$-adic类比关系，并由此证明了特定条件下Lehmer猜想的成立。


<details>
  <summary>Details</summary>
Motivation: 研究代数数$\alpha$的对数Weil高度$h(\alpha)$与其共轭点在复平面和$p$-adic域中分布的关系，特别是当高度较小而次数较大时的聚类现象。

Method: 通过分析$\alpha$在$\mathbb{Q}_p$有限扩张中共轭点的数量，建立$h(\alpha)$的下界估计，并利用$p$-adic分析方法推导关键不等式。

Result: 证明了当$\alpha$有$\gg \sqrt{d\log d}$个共轭点落在$\mathbb{Q}_p$的有限扩张中时，Lehmer猜想成立，即$h(\alpha)$存在非零下界。

Conclusion: 该工作将经典的复平面高度分布理论推广到$p$-adic情形，为Lehmer猜想提供了新的证明途径，揭示了数域与$p$-adic域之间的深刻联系。

Abstract: For a non-zero algebraic number $\alpha$ of degree $d$, let $h(\alpha)$
denote its logarithmic Weil height. It is known that when $h(\alpha)$ is small,
and $d$ is large, the conjugates of $\alpha$ are clustered near the unit circle
and have angular equidistribution in the complex plane about the origin. In
this paper, we establish a $p$-adic analogue of this result by obtaining lower
bounds for $h(\alpha)$ in terms of the number of its conjugates that lie in a
finite extension of $\mathbb{Q}_p$, for some prime $p$. As a consequence, we
prove Lehmer's conjecture for all $\alpha$ such that $\gg \sqrt{d\log d}$ many
of its conjugates lie in a finite extension of $\mathbb{Q}_p$.

</details>


### [49] [A number field analogue of the Grothendieck conjecture for curves over finite fields](https://arxiv.org/abs/2507.20159)
*Manabu Ozaki*

Main category: math.NT

TL;DR: 本文通过类比数域与有限域上的一维函数域，提出数域情形的Grothendieck猜想，并给出无分歧情形下的证明。


<details>
  <summary>Details</summary>
Motivation: 研究数域与函数域之间的类比关系，特别是最大分圆扩张与常数域扩张的对应，旨在建立数域情形的Grothendieck猜想。

Method: 采用Tamagawa和Mochizuki证明有限域上双曲曲线的Grothendieck猜想的方法，将其推广到数域情形。

Result: 在无分歧情形下，证明了Neukirch-Schmidt-Wingberg著作《数域的上同调》中猜想(12.5.3)的肯定答案。

Conclusion: 本文成功建立了数域与函数域之间的新类比，为相关领域的研究提供了新的视角和工具。

Abstract: In the present paper, we provide a new analogy between number fields and
1-dimensional function fields over finite fields from the viewpoint that the
maximal cyclotomic extension of a number field is analogous to the constant
field extension of a function field to an algebraic closure. Namely, we give a
number field analogue of the Grothendieck conjecture for hyperbolic curves over
finite fields proved by Tamagawa and Mochizuki, which is an affirmative answer
to Conjecture(12.5.3) of ``Cohomology of number fields" by
Neukirch-Schmidt-Wingberg in the case where the ramified prime sets are empty.

</details>


### [50] [Degenerate Sheffer-type polynomials and degenerate Sheffer polynomials associated with a random variable](https://arxiv.org/abs/2507.20167)
*Taekyun Kim,Dae san Kim*

Main category: math.NT

TL;DR: 本文研究退化Sheffer型多项式及其性质，并引入与随机变量Y相关的退化Sheffer多项式，探讨其在均匀分布和伯努利随机变量中的特性。


<details>
  <summary>Details</summary>
Motivation: 探索高阶退化伯努利和欧拉多项式的混合形式——退化Sheffer型多项式，并研究其数学性质及应用。

Method: 假设Y的矩生成函数在原点邻域存在，引入与Y相关的退化Sheffer多项式，分析其一般性质及在特定随机变量（均匀分布和伯努利）中的表现。

Result: 推导了退化Sheffer型多项式的性质，并针对均匀分布和伯努利随机变量给出了新的结果，同时扩展了高阶退化伯努利和欧拉多项式的研究。

Conclusion: 本文为退化Sheffer多项式及其相关随机变量应用提供了新的理论结果，扩展了多项式理论的研究范围。

Abstract: This paper has two primary contributions. First, we explore degenerate
Sheffer-type polynomials, a hybrid of higher-order degenerate Bernoulli and
Euler polynomials, and derive their properties. Second, assuming that the
moment generating function of Y exists in a neighborhood of the origin, we
introduce the degenerate Sheffer polynomials associated with Y. We then
investigate their properties in general and for the specific cases of uniform
and Bernoulli random variables. We also present new results for the
higher-order degenerate Bernoulli and Euler polynomials.

</details>


### [51] [Proofs of Two Conjectural Identities on Partial Nahm Sums](https://arxiv.org/abs/2507.20270)
*Changsong Shi,Liuquan Wang*

Main category: math.NT

TL;DR: 本文证明了Wang和Zeng提出的关于部分Nahn和的两个Rogers--Ramanujan型恒等式的猜想。


<details>
  <summary>Details</summary>
Motivation: Wang和Zeng研究了部分Nahn和的模性，发现了14个模族，并提出了一个包含两个Rogers--Ramanujan型恒等式的猜想。

Method: 首先，利用涉及两个Bailey对的变换公式，将部分Nahn和转化为特定的Hecke型级数；其次，通过两种不同的方法，将这些Hecke型级数转换为所需的模无限积。

Result: 成功证明了这两个猜想恒等式，验证了第14个模族的模性。

Conclusion: 通过两步变换方法，我们不仅证明了Wang和Zeng的猜想，还进一步丰富了部分Nahn和模性的理论。

Abstract: Recently, Wang and Zeng investigated modularity of partial Nahm sums and
discovered 14 modular families of such sums. They confirmed modularity for 13
families and proposed a conjecture consisting of two Rogers--Ramanujan type
identities for the remaining family. We prove these conjectural identities in
two steps. First, employing a transformation formula involving two Bailey
pairs, we transform the partial Nahm sums into some specific Hecke-type series.
Second, using two distinct approaches, we convert these Hecke-type series to
the desired modular infinite products.

</details>


### [52] [Regulators of the fixed elliptic curve over rank-one imaginary quadratic fields](https://arxiv.org/abs/2507.20297)
*Shenghao Hua*

Main category: math.NT

TL;DR: 本文证明了固定有理非CM椭圆曲线在虚二次域上的对数调节器满足单边中心极限定理，并展示了虚二次域调节器增长的下界。在BSD猜想下，还得到了秩一二次扭转的Shafarevich--Tate群和Tamagawa数的一致有界性。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于Gross--Zagier公式及Radziwi\l\l和Soundararajan的结果，旨在探索椭圆曲线调节器在虚二次域中的统计行为及其与L函数的关系。

Method: 通过建立对数调节器的单边中心极限定理，并结合Gross--Zagier公式与BSD猜想，分析调节器与L函数非零中心值的关系。

Result: 证明了虚二次域的调节器增长至少与域的导子的平方根同阶，并在L函数中心值非零时，结果适用于二次扭转的调节器。假设BSD猜想成立，进一步得到了秩一二次扭转的Shafarevich--Tate群和Tamagawa数的一致有界性。

Conclusion: 本文结果深化了对椭圆曲线调节器在虚二次域中行为的理解，并为BSD猜想下的相关数论问题提供了新的证据。

Abstract: We establish a one-sided central limit theorem for the logarithms of
regulators of a fixed rational non-CM elliptic curve $E$ over imaginary
quadratic fields of rank one, motivated by the Gross--Zagier formula and a
result of Radziwi\l\l and Soundararajan.
  We also establish the existence of many imaginary quadratic fields whose
regulators grow at least as fast as the square root of the conductor of the
field.
  When the central value of the $L$-function of $E$ is non-vanishing, these
results also hold for the regulator of the quadratic twist $E^{(d)}$ over
$\mathbb{Q}$.
  Moreover, assuming the Birch and Swinnerton-Dyer conjecture, we obtain the
uniform boundedness of the Shafarevich--Tate groups and Tamagawa numbers for
these rank-one quadratic twists.

</details>


### [53] [Identical Vanishing of Coefficients in the Series Expansion of Eta Quotients, modulo 4, 9 and 25](https://arxiv.org/abs/2507.20298)
*Tim Huber,James McLaughlin,Dongxi Ye*

Main category: math.NT

TL;DR: 本文研究了模$m$版本的eta商零系数等价性问题，针对$m=p^2$（$p=2,3,5$）及$m=4,9$给出了理论结果，并发现部分定理具有组合数学意义。对于$m=25$，通过实验数据给出了个别结果。


<details>
  <summary>Details</summary>
Motivation: 探讨两个eta商$A(q)$和$B(q)$在模$m$条件下系数同余的等价性问题，扩展了先前关于零系数等价性的研究。

Method: 利用模形式理论，对特定$m$值（如$p^2$）构建无限eta商族，并通过组合分析验证同余关系。对于$m=25$，采用实验数据与个别证明相结合的方法。

Result: 证明了$m=9$时形如$A(q)=f_1^{3j_1+1}\prod f_i^{j_i}$的eta商满足三类同余式；发现$p_2^{(3)}(n)$模9与广义五边形数的关联；对$m=25$给出了$f_1^{10}$与$f_1^5f_5$系数的模等价性。

Conclusion: 该研究系统建立了eta商在模$m$条件下的系数等价理论，部分结果揭示了深刻的组合性质，但对$m=25$的普适性结论仍需进一步探索。

Abstract: Let $A(q)=\sum_{n=0}^{\infty}a_n q^n$ and $B(q)=\sum_{n=0}^{\infty}b_n q^n$
be two eta quotients. Previously, we considered the problem of when \[ a_n=0
<=> b_n=0. \] Here we consider the ``mod $m$'' version of this problem, i.e.
eta quotients $A(q)$ and $B(q)$ and integers $m>1$ such that \[ a_n \equiv 0
\pmod m <=> b_n \equiv 0 \pmod m? \] We found results for $m=p^2$, $p=2, 3$ and
$5$. For $m=4,9$, we found results which apply to infinite families of eta
quotients. For example: Let $A(q)$ have the form \begin{equation} A(q) =
f_1^{3j_1+1}\prod_{3\nmid i}f_i^{3j_i}\prod_{3|i}f_i^{j_i} =:
\sum_{n=0}^{\infty}a_nq^n,\,\,B(q) = \frac{f_3}{f_1^3}A(q) =:
\sum_{n=0}^{\infty}b_nq^n \end{equation} with
$f_{k}=\prod_{n=1}^{\infty}(1-q^{kn})$. Then \begin{align*}
a_{3n}-b_{3n}&\equiv 0\pmod 9,\\ 2a_{3n+1}+b_{3n+1}&\equiv0\pmod 9,\\
a_{3n+2}+2b_{3n+2}&\equiv0\pmod 9. \end{align*} Some of these theorems also had
some combinatorial implications, such as the following: Let $p_2^{(3)}(n)$
denote the number of bipartitions $(\pi_1, \pi_2)$ of $n$ where $\pi_1$ is
3-regular. Then \begin{equation*} p_2^{(3)}(n)\equiv0\pmod 9 <=> n\text{ is not
a generalized pentagonal number}. \end{equation*} In the case of $m=25$, we do
not have any general theorems that apply to an infinite family of eta
quotients. Instead we give two tables of results that appear to hold
experimentally. We do prove some individual results (using theory of modular
forms), such as the following: Let the sequences $\{c_n\}$ and $\{d_n\}$ be
defined by \begin{equation*} f_1^{10}=:\sum_{n=0}^{\infty}c_nq^n, \hspace{25pt}
f_1^{5}f_5=:\sum_{n=0}^{\infty}d_nq^n. \end{equation*} Then \begin{equation*}
c_n \equiv 0 \pmod{25} <=> d_n \equiv 0 \pmod{25}. \end{equation*}

</details>


### [54] [Structure of (Fine) Mordell--Weil Groups](https://arxiv.org/abs/2507.20341)
*Rusiru Gambheera,Debanjana Kundu*

Main category: math.NT

TL;DR: 本文研究了数域的分圆$\mathbb{Z}_p$-扩张中精细Mordell--Weil群及正负Mordell--Weil群的代数结构，改进了已知结果并证明了若干等变结果。


<details>
  <summary>Details</summary>
Motivation: 探索分圆$\mathbb{Z}_p$-扩张下Mordell--Weil群的代数结构，以深化对椭圆曲线算术性质的理解，特别是在基域为$\mathbb{Q}$时的情形。

Method: 通过代数数论与椭圆曲线理论相结合的方法，对精细Mordell--Weil群及正负子群进行结构性分析，并采用等变技术处理对称性问题。

Result: 获得了比以往更强的结构性定理，尤其在基域为$\mathbb{Q}$时得到更优结果，同时建立了若干等变条件下的新结论。

Conclusion: 研究显著推进了对分圆扩张中Mordell--Weil群结构的认知，为相关领域的进一步研究提供了新的理论工具。

Abstract: In this article we study the algebraic structure of fine Mordell--Weil groups
and plus/minus Mordell--Weil groups in the cyclotomic $\mathbb{Z}_p$-extensions
of number fields. We provide refinements of previously known results and also
prove some equivariant results. In particular, we are able to give stronger
results even when the base field is $\mathbb{Q}$.

</details>


### [55] [A polynomial approach to Carlitz's $q$-Bernoulli numbers](https://arxiv.org/abs/2507.20384)
*Mohamed Mouzaia,Bakir Farhi*

Main category: math.NT

TL;DR: 本文研究了经典伯努利多项式和数的$q$-类比，通过Jackson积分定义了一个新的多项式序列${\left(B_{n , q}(X)\right)}_{n \in \mathbb{N}_0}$，并探讨了其与Carlitz的$q$-伯努利多项式及数的联系。


<details>
  <summary>Details</summary>
Motivation: 探索经典伯努利多项式和数的$q$-类比，以扩展对其性质的理解，并通过Jackson积分提供新的视角。

Method: 利用Jackson积分定义新的多项式序列${\left(B_{n , q}(X)\right)}_{n \in \mathbb{N}_0}$，并分析其与Carlitz的$q$-伯努利多项式及数的关系。

Result: 证明了$B_{n , q}(0)$即为Carlitz的$q$-伯努利数，且$B_{n , q}(X)$是经典伯努利多项式的真正$q$-类比。

Conclusion: 通过Jackson积分重新表述Carlitz的$q$-伯努利数，为理解其性质提供了新的见解，并确认了新定义的多项式序列的$q$-类比特性。

Abstract: This paper investigates $q$-analogues of the classical Bernoulli polynomials
and numbers. We introduce a new polynomial sequence ${\left(B_{n ,
q}(X)\right)}_{n \in \mathbb{N}_0}$, defined via the Jackson integral, and
explore its connections with Carlitz's $q$-Bernoulli polynomials and numbers.
Specifically, we prove that the numbers $B_{n , q}(0)$ are exactly the Carlitz
$q$-Bernoulli numbers and that the polynomials $B_{n , q}(X)$ are genuine
$q$-analogues of the classical Bernoulli polynomials. This approach leverages
the Jackson integral to reformulate Carlitz's $q$-Bernoulli numbers in terms of
classical polynomial structures, offering new insights into their properties.

</details>


### [56] [Permutation of values of irrationality measure functions](https://arxiv.org/abs/2507.20416)
*Victoria Rudykh*

Main category: math.NT

TL;DR: 本文研究了无理数的不可测度函数及其排序向量，证明了在极值情况下，排序向量的连续值构成一个k-循环置换的轨道。


<details>
  <summary>Details</summary>
Motivation: 研究无理数的不可测度函数排序向量的性质，特别是在极值情况下这些向量的行为，以深化对无理数分布的理解。

Method: 定义了k-循环置换$\pi$，并分析了在极值情况$n = \frac{k(k+1)}{2}$和$\boldsymbol{k}(\boldsymbol{\alpha}) = k$下，排序向量$\boldsymbol{v}_{\boldsymbol{\alpha}}(t)$的连续值的行为。

Result: 证明了在极值情况下，排序向量的连续值构成一个k-循环置换$\pi$的轨道。

Conclusion: 在极值情况下，无理数的不可测度函数排序向量的连续值遵循一个k-循环置换的轨道，这一发现为无理数分布的研究提供了新的视角。

Abstract: For an irrational number $\alpha\in\mathbb{R}$ we consider its irrationality
measure function $$ \psi_\alpha(t) = \min_{1\le q\le t,\, q\in\mathbb{Z}} \|
q\alpha \|. $$ Let $\boldsymbol{\alpha} = (\alpha_1, \dots, \alpha_n)$ be
$n$-tuple of pairwise independent irrational numbers. For each $t \in
\mathbb{R}_{>1}$ irrationality measure functions $\psi_{\alpha_1}, \dots,
\psi_{\alpha_n}$ can be written in an increasing order $$\psi_{\alpha_{v_1}}(t)
> \psi_{\alpha_{v_2}}(t) > \dots > \psi_{\alpha_{v_{n-1}}}(t) >
\psi_{\alpha_{v_n}}(t).$$ We consider the vector of functions
$\boldsymbol{v}_{\boldsymbol{\alpha}}(t): \mathbb{R}_{>1} \rightarrow S_n$
associated to this order and defined as
$$\boldsymbol{v}_{\boldsymbol{\alpha}}(t) = ( v_1, v_2, \dots, v_{n-1}, v_n
).$$ Let $\boldsymbol{k}(\boldsymbol{\alpha})$ be the number of infinitely
occurring different values of $\boldsymbol{v}_{\boldsymbol{\alpha}}(t)$. It is
known that if $\boldsymbol{k}(\boldsymbol{\alpha})= k$ we have $ n \leq
\frac{k(k+1)}{2}.$ At the same time, for $k \geq 3$ and $n = \frac{k(k+1)}{2}$
there exists an $n$-tuple $\boldsymbol{\alpha}$ with
$\boldsymbol{k}(\boldsymbol{\alpha}) = k$. In this work we define a $k$-cyclic
permutation $\pi$ and prove that in the extremal case $n = \frac{k(k+1)}{2}, \
\boldsymbol{k}(\boldsymbol{\alpha}) = k$ the set of successive values of
$\boldsymbol{v}_{\boldsymbol{\alpha}}(t)$ is an orbit of $\pi$.

</details>


### [57] [A BBP-type formula for the remainder of the Madhava-Gregory-Leibniz series](https://arxiv.org/abs/2507.20428)
*Benoit Cloitre*

Main category: math.NT

TL;DR: 本文推导了Madhava-Gregory-Leibniz级数余项的BBP型公式，并以16进制和Pochhammer分母形式给出闭式解，同时提出了对数2的交错级数类似公式。


<details>
  <summary>Details</summary>
Motivation: 研究Madhava-Gregory-Leibniz级数余项的精确表达式，探索π计算中BBP型公式的新形式，并扩展至对数级数领域。

Method: 通过数学推导构建基于16进制的闭式表达式，采用Pochhammer符号处理分母结构，并建立与对数级数的类比关系。

Result: 成功获得π级数余项的BBP型公式$R_n=\sum_{k=n+1}^\infty\frac{(-1)^k}{2k+1}$的16进制闭式解，同时给出$\log 2$级数的对应表达式。

Conclusion: 该研究为π和对数计算提供了新型解析工具，BBP型公式的16进制形式可能具有计算效率优势，Pochhammer结构展现了级数余项的深层数学性质。

Abstract: We derive a BBP-type formula for the remainder of the Madhava-Gregory-Leibniz
series for $\pi$. The result is a closed form in base-$16$ with Pochhammer
denominators. The analogous formula for the alternating series for $\log 2$ is
also presented.

</details>


### [58] [On the Algebraic Independence of $E$- and $G$-Functions, II: An Effective Version](https://arxiv.org/abs/2507.20429)
*Daniel Vargas-Montoya*

Main category: math.NT

TL;DR: 本文研究了完全分歧的$p$-adic域$K$上具有强Frobenius结构和最大阶多重性条件的幂级数的代数独立性，并给出了判定准则。


<details>
  <summary>Details</summary>
Motivation: 研究$\mathcal{M}\mathcal{F}(K)$集合中$E$-和$G$-函数的代数独立性，以扩展对$p$-adic域上特殊函数性质的理解。

Method: 通过构建微分算子并利用强Frobenius结构和最大阶多重性条件，提出了代数独立性的判定准则。

Result: 证明了$\mathcal{M}\mathcal{F}(K)$中某些$E$-和$G$-函数在解析元素域上的代数独立性。

Conclusion: 该准则为研究$p$-adic域上特殊函数的代数独立性提供了有效工具，并成功应用于具体函数类。

Abstract: Let $K$ be a finite extension of $\mathbb{Q}_p$ that is totally ramified over
$\mathbb{Q}_p$. The set $\mathcal{M}\mathcal{F}(K)$ consists of power series in
$1+zK[[z]]$ that are solutions of differential operators in $K(z)[d/dz]$
equipped with strong Frobenius structure and satisfying maximal order
multiplicty (MOM) condition at zero. It turns out that this set contains an
interesting class of $E$- and $G$-functions. In this work, we provide a
criterion for determining the algebraic independence, over the field of
analytic elements, of elements belonging to $\mathcal{M}\mathcal{F}(K)$. As an
illustration of this criterion, we show the algebraic independence of some $E$-
and $G$-functions over the field of analytic elements.

</details>


### [59] [Quasimodular forms that detect primes are Eisenstein](https://arxiv.org/abs/2507.20432)
*Jan-Willem van Ittersum,Lukas Mauth,Ken Ono,Ajit Singh*

Main category: math.NT

TL;DR: 本文通过$\ell$-进Galois表示理论，为MacMahon划分函数及其扩展中识别素数的猜想提供了新证明。


<details>
  <summary>Details</summary>
Motivation: MacMahon划分函数及其扩展能通过方程识别素数解，这一结果依赖于$SL_2(\mathbb{Z})$上的拟模形式理论。作者们希望验证关于素数检测拟模形式的猜想。

Method: 使用与模形式相关的$\ell$-进Galois表示理论，替代Kane等人的解析方法，重新证明素数检测拟模形式的猜想。

Result: 成功通过$\ell$-进Galois表示理论验证了素数检测拟模形式的猜想，该猜想描述了Eisenstein级数及其导数构成的集合。

Conclusion: 本文为素数检测拟模形式的猜想提供了基于Galois表示理论的新证明，丰富了该问题的研究方法。

Abstract: MacMahon's partition functions and their extensions provide equations that
identify prime numbers as solutions. These results depend on the theory of
(mixed weight) quasimodular forms on $SL_2(\mathbb{Z})$. Two of the authors,
along with Craig, conjectured an explicit description of the set of
prime-detecting quasimodular forms in terms of Eisenstein series and their
derivatives. Kane et al.\ recently verified this conjecture using analytic
methods. We offer an alternative proof using the theory of $\ell$-adic Galois
representations associated to modular forms.

</details>


### [60] [An improved upper bound on the covering radius of the logarithmic lattice of \mathbb{Q}(ζ_n)](https://arxiv.org/abs/2507.20544)
*James Punch*

Main category: math.NT

TL;DR: 本文研究了由分圆数域$\mathbb{Q}(\zeta_n)$生成的格点覆盖半径，改进了(de Araujo, 2024)中的上界，并给出了该格点覆盖半径与$n$及其不同素因子数量的关系。


<details>
  <summary>Details</summary>
Motivation: 研究分圆数域$\mathbb{Q}(\zeta_n)$生成的格点覆盖半径，旨在改进现有上界并探索其渐近性质。

Method: 通过应用对数嵌入将分圆数域的单位群映射到欧几里得空间$\mathbb{R}^m$，分析格点覆盖半径的性质，并改进现有上界。

Result: 改进了(de Araujo, 2024)中的引理2，给出了分圆数域格点覆盖半径的上界，证明该改进在渐近意义下无法进一步优化。

Conclusion: 本文提供了分圆数域格点覆盖半径的改进上界，并证明其在渐近意义下的最优性，为相关研究提供了新的理论工具。

Abstract: Let $\mathbb{R}^m$ be endowed with the Euclidean metric. The covering radius
of a lattice $\Lambda \subset \mathbb{R}^m$ is the least distance $r$ such
that, given any point of $\mathbb{R}^m$, the distance from that point to
$\Lambda$ is not more than $r$. Lattices can occur via the unit group of the
ring of integers in an algebraic number field $\mathbb{K}$, by applying a
logarithmic embedding $\mathbb{K}^*\rightarrow \mathbb{R}^m$. In this paper, we
examine those lattices which arise from the cyclotomic number field
$\mathbb{Q}(\zeta_n)$, for a given positive integer $n\geq5$ such that $n\not
\equiv 2\pmod{4}$. We then provide improvements to an upper bound in (de
Araujo, 2024), and conclude with an upper bound on the covering radius for this
lattice in terms of $n$ and the number of its distinct prime factors. In
particular, we improve Lemma 2 of (de Araujo, 2024) and show that,
asymptotically, it can be improved no further.

</details>


### [61] [Maps preserving the sum-to-difference ratio in characteristic $p$](https://arxiv.org/abs/2507.20604)
*Sunil Chebolu,Apoorva Khare,Anindya Sen*

Main category: math.NT

TL;DR: 本文引入了一个新的群$SD(\mathbb{F})$，由满足特定函数方程的自映射组成，并计算了所有代数域上的该群，特别发现该群能区分$\mathbb{F}_5$与其他有限域。


<details>
  <summary>Details</summary>
Motivation: 研究域$\mathbb{F}$上满足特定函数方程的自映射群$SD(\mathbb{F})$，旨在探索其在代数域上的性质及其对有限域的区分能力。

Method: 通过引入并分析满足方程$f \left( (x+y)/(x-y) \right) = (f(x) + f(y))/(f(x) - f(y))$的自映射群$SD(\mathbb{F})$，计算其在所有代数域上的结构。

Result: 计算表明，群$SD(\mathbb{F})$在所有代数域上具有明确的结构，并能特别区分$\mathbb{F}_5$与其他有限域及其子域。

Conclusion: 群$SD(\mathbb{F})$不仅为域的自映射提供了新的视角，还能作为区分特定有限域的有效工具，尤其在识别$\mathbb{F}_5$方面表现出独特性。

Abstract: Given a field $\mathbb{F}$, we introduce a novel group $SD(\mathbb{F})$ of
its self-maps: the solutions $f \colon \mathbb{F} \twoheadrightarrow
\mathbb{F}$ to the functional equation $f \left( (x+y)/(x-y) \right) = (f(x) +
f(y))/(f(x) - f(y))$ for all $ x \neq y$ in $\mathbb{F}$. We compute this group
for all fields algebraic over $\mathbb{F}_p$. In particular, this group
distinguishes $\mathbb{F}_5$ among all finite fields $\mathbb{F}_q$, and in
fact among all subfields of $\overline{\mathbb{F}_q}$.

</details>


### [62] [On Hypothesis H of Rudnick and Sarnak](https://arxiv.org/abs/2507.20653)
*Yujiao Jiang*

Main category: math.NT

TL;DR: 本文证明了任意数域上${\rm GL}_n$的Hypothesis H，并提出了涉及Rankin--Selberg系数的欧拉积有效界。新方法突破了以往$n\leq 4$的限制，应用包括确立自守$L$函数零点的GUE统计、强唯一性问题的有效多项式界，以及改进Selberg正交猜想。


<details>
  <summary>Details</summary>
Motivation: 研究目的是在任意数域上全面证明Hypothesis H，并解决以往方法因函子性障碍而局限于$n\leq 4$的问题。

Method: 采用新的解析方法，结合数域上的幂筛法和迭代论证，绕过了函子性障碍。

Result: 成功证明了Hypothesis H的普遍性，并得到了Rankin--Selberg系数欧拉积的更强有效界。

Conclusion: 该成果不仅推进了自守形式的理论，还为相关领域（如$L$函数零点统计和强唯一性问题）提供了新的工具和结论。

Abstract: We prove Hypothesis H in full generality for ${\rm GL}_n$ over any number
field. This result is a consequence of our stronger effective bound on Euler
products involving Rankin--Selberg coefficients at prime ideal powers. The
proof rests on a new analytic method, which employs a power sieve over number
fields and an iterative argument to bypass the functoriality barrier that had
restricted prior results to $n\leq 4$. As applications, we unconditionally
establish the GUE statistics for automorphic $L$-function zeros, provide the
first effective polynomial bound for the strong multiplicity one problem for
coefficients, and resolve the Selberg orthogonality conjecture with stronger
error terms.

</details>


### [63] [Congruences modulo $23$ to $y^2=x^3-23$ are trivial](https://arxiv.org/abs/2507.20801)
*Elie Studnia*

Main category: math.NT

TL;DR: 本文研究了椭圆曲线在模素数$p$下的同余关系，应用Mazur策略确定了特定条件下扭曲模曲线的有理点，并推导出与$y^2=x^3-p$同余的椭圆曲线的导体显式上界。


<details>
  <summary>Details</summary>
Motivation: 研究椭圆曲线在模素数$p$下的非平凡同余关系，验证Frey-Mazur猜想在特定情况下的成立性。

Method: 采用Mazur的策略，分析扭曲模曲线$X(p)$的有理点，结合椭圆曲线的导体性质进行推导。

Result: 当$p \equiv 5 \mod 9$时，确定了与$y^2=x^3-p$同余的椭圆曲线的导体上界，并证明模$23$的同余均为平凡。

Conclusion: 在特定条件下，椭圆曲线的模$p$同余关系均为平凡，支持了Frey-Mazur猜想的部分结论。

Abstract: We say that two elliptic curves $E$ and $F$ over $\mathbb{Q}$ are congruent
modulo a prime $p$ if their $p$-torsion Galois modules (over the algebraic
closure of $\mathbb{Q}$) are isomorphic. Such a congruence is called trivial if
there is a rational isogeny between $E$ and $F$ with degree prime to $p$. A
version of the Frey-Mazur conjecture states that any congruence modulo any
prime $p \geq 19$ is trivial. Given an elliptic curve $E/\mathbb{Q}$ and a
prime $p$, it is well-known that there is a twist of the classical modular
curve $X(p)$ whose rational points describe the elliptic curves congruent to
$E$ modulo $p$. In this article, we apply Mazur's strategy to determine the
rational points of such a twisted modular curve under certain assumptions. In
particular, we determine an explicit bound on the conductor of any elliptic
curve congruent modulo $p$ to $y^2=x^3-p$ when $p$ is prime and congruent to
$5$ modulo $9$, and deduce that any congruence modulo $23$ to $y^2=x^3-23$ is
trivial.

</details>


### [64] [Weil representations associated to isocrystals over function fields](https://arxiv.org/abs/2507.20807)
*Maxim Mornev,Richard Pink*

Main category: math.NT

TL;DR: 本文扩展了Anderson $A$-模的Galois表示系统，通过构造Weil群表示覆盖所有位点，并推广了Tate模构造至非纯$F_{\mathfrak{p}}$-等晶体。


<details>
  <summary>Details</summary>
Motivation: 研究$A$-模的Galois表示系统在全局函数域$F$上的兼容性扩展，特别是针对非纯等晶体的情形。

Method: 通过推广Tate模构造为张量函子，应用于$F_{\mathfrak{p}}$-等晶体，并分析其在模约化下的行为。

Result: 成功构建了覆盖所有位点的兼容Weil群表示系统，并获得了特殊特征$\wp$下Drinfeld模的新型$\wp$-adic Weil表示。

Conclusion: 该工作不仅扩展了原有表示系统的适用范围，还为Drinfeld模研究提供了新的表示论工具。

Abstract: Every Anderson $A$-motive $M$ over a field determines a compatible system of
Galois representations on its Tate modules at almost all primes of $A$. This
adapts easily to $F$-isocrystals, which are rational analogues of $A$-motives
for the global function field $F:=\operatorname{Quot}(A)$. We extend this
compatible system by constructing a Weil group representation associated to $M$
for every place of $F$. To this end we generalize the Tate module construction
to a tensor functor on $F_{\mathfrak{p}}$-isocrystals that are not necessarily
pure. To prove that this yields a compatible system, we work out how that
construction behaves under reduction of $M$. As an offshoot we obtain a new
kind of $\wp$-adic Weil representations associated to Drinfeld modules of
special characteristic $\wp$.

</details>


### [65] [Rational points on varieties defined by multihomogeneous diagonal forms](https://arxiv.org/abs/2507.20878)
*Doyon Kim,Tian Wang*

Main category: math.NT

TL;DR: 本文通过Hardy-Littlewood圆法与Blomer-Br\"udern双曲线法，给出了多齐次对角方程组定义的代数簇上有界高度有理点数量的渐近公式。


<details>
  <summary>Details</summary>
Motivation: 研究多齐次对角方程组定义的代数簇上有界高度有理点的数量问题，旨在扩展数论中计数理论的应用范围。

Method: 结合Hardy-Littlewood圆法与Blomer-Br\"udern发展的双曲线法，对多齐次对角方程组进行解析。

Result: 推导出多齐次对角方程组定义的代数簇上有界高度有理点数量的精确渐近公式。

Conclusion: 该方法为处理复杂代数结构中的有理点计数问题提供了有效工具，拓展了经典圆法的应用场景。

Abstract: We give an asymptotic formula for the number of rational points of bounded
height on algebraic varieties defined by systems of multihomogeneous diagonal
equations. The proof uses the Hardy-Littlewood circle method and the hyperbola
method developed by Blomer and Br\"udern.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [66] [The number of normal measures, revisited](https://arxiv.org/abs/2507.20466)
*Eyal Kaplan*

Main category: math.LO

TL;DR: 本文提出了Friedman-Magidor定理的新版本，展示了如何通过强制扩展使得每个正规测度在扩展后有特定数量的提升，且不依赖精细结构工具。


<details>
  <summary>Details</summary>
Motivation: 研究目的是扩展Friedman-Magidor定理的应用范围，使其不依赖内模型或精细结构假设，从而适用于更广泛的大基数理论。

Method: 采用非平稳支撑积强制技术，避免了传统方法中对内模型或精细结构的依赖，简化了强制过程。

Result: 对于每个可测基数$\kappa$和$\tau\leq\kappa^{++}$，存在强制扩展$V\subseteq V[G]$，使得$V$中的任何正规测度$U$在$V[G]$中恰好有$\tau$个不同的提升，且所有提升具有相同的超幂。

Conclusion: 新方法不仅简化了Friedman-Magidor定理的证明，还扩展了其适用范围，为研究大基数提供了更灵活的工具。

Abstract: We present a new version of the Friedman-Magidor theorem: for every
measurable cardinal $\kappa$ and $\tau\leq\kappa^{++}$, there exists a forcing
extension $V\subseteq V[G]$ such that any normal measure $U\in V$ on $\kappa$
has exactly $\tau$ distinct lifts in $V[G]$, and every normal measure on
$\kappa$ in $V[G]$ arises as such a lift. This version differs from the
original Friedman-Magidor theorem in several notable ways. First, the new
technique does not involve forcing over canonical inner models or rely on any
fine-structural tools or assumptions, allowing it to be applied in the realm of
large cardinals beyond the current reach of the inner model program. Second, in
the case where $\tau\leq \kappa^+$, all lifts of a normal measure $U\in V$ on
$\kappa$ to $V[G]$ have the same ultrapower. Finally, the technique generalizes
to a version of the Friedman-Magidor theorem for extenders. An additional
advantage is that the forcing used is notably simple, relying only on
nonstationary support product forcing.

</details>


### [67] [Some remarks on lattices of equivalences](https://arxiv.org/abs/2507.20605)
*Christian Herrmann*

Main category: math.LO

TL;DR: 综述了等价关系格类可公理化的重要结果


<details>
  <summary>Details</summary>
Motivation: 探讨等价关系格类在数学基础中的公理化可能性

Method: 系统回顾现有文献中的公理化方法

Result: 总结了等价关系格类可公理化的充分必要条件

Conclusion: 等价关系格类的公理化研究为相关代数结构提供了理论基础

Abstract: We review principal results on axiomatizability of classes of lattices of
equivalences

</details>


### [68] [Unravelling Cyclic First-Order Arithmetic](https://arxiv.org/abs/2507.20865)
*Graham E. Leigh,Dominik Wehr*

Main category: math.LO

TL;DR: 本文提出了一种简单直接的方法，将Heyting算术和Peano算术的循环证明系统嵌入到纯归纳（有限）证明中，扩展了Sprenger和Dam的方法，并恢复了Das关于Peano算术的结果。


<details>
  <summary>Details</summary>
Motivation: 传统的循环证明系统与常规变体的一致性证明通常依赖于复杂的元数学算术化，本文旨在提供一种更简单直接的方法。

Method: 通过调整Sprenger和Dam为带有显式序数逼近的$\mu\text{FOL}$循环证明系统引入的翻译方法，将循环证明嵌入到纯归纳证明中，并提出了一种新颖的标记相继式演算表示。

Result: 扩展了该方法，恢复了Das关于Peano算术的结果$\text{C}\Pi_n \subseteq \text{I}\Pi_{n + 1}$。

Conclusion: 本文提供了一种简单直接的方法，将循环证明嵌入到纯归纳证明中，并扩展了现有结果，为循环证明系统的研究提供了新的视角。

Abstract: Cyclic proof systems for Heyting and Peano arithmetic eschew induction axioms
by accepting proofs which are finite graphs rather than trees. Proving that
such a cyclic proof system coincides with its more conventional variants is
often difficult: Previous proofs in the literature rely on intricate
arithmetisations of the metamathematics of the cyclic proof systems.
  In this article, we present a simple and direct embedding of cyclic proofs
for Heyting and Peano arithmetic into purely inductive, i.e. 'finitary', proofs
by adapting a translation introduced by Sprenger and Dam for a cyclic proof
system of $\mu\text{FOL}$ with explicit ordinal approximations. We extend their
method to recover Das' result of $\text{C}\Pi_n \subseteq \text{I}\Pi_{n + 1}$
for Peano arithmetic. As part of the embedding we present a novel
representation of cyclic proofs as a labelled sequent calculus.

</details>


### [69] [The Boolean Compactness Theorem for $\mathrm{L}_{\infty\infty}$](https://arxiv.org/abs/2507.21005)
*Juan M Santiago Suárez,Matteo Viale*

Main category: math.LO

TL;DR: 论文提出$\mathrm{L}_{\infty\infty}$存在自然且最优的紧致性定理，颠覆传统认知，关键是将Tarski语义转向布尔值语义。


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点，证明$\mathrm{L}_{\infty\infty}$存在未被发现的紧致性定理，并探索更自然的语义框架。

Method: 采用布尔值语义替代Tarski语义，作为$\mathrm{L}_{\infty\infty}$和$\mathrm{L}_{\infty\omega}$的基础语义模型。

Result: 成功证明布尔值语义是$\mathrm{L}_{\infty\infty}$和$\mathrm{L}_{\infty\omega}$的自然语义，并推导出紧致性定理。

Conclusion: 布尔值语义为高阶逻辑提供了更优的语义解释，同时揭示了$\mathrm{L}_{\infty\infty}$的紧致性特性。

Abstract: We show that, contrary to the commonly held view, there is a natural and
optimal compactness theorem for $\mathrm{L}_{\infty\infty}$ which generalizes
the usual compactness theorem for first order logic. The key to this result is
the switch from Tarski semantics to Boolean valued semantics. On the way to
prove it, we also show that the latter is a (the?) natural semantics both for
$\mathrm{L}_{\infty\infty}$ and for $\mathrm{L}_{\infty\omega}$.

</details>


<div id='math.HO'></div>

# math.HO [[Back]](#toc)

### [70] [Topological Data Analysis and Topological Deep Learning Beyond Persistent Homology -- A Review](https://arxiv.org/abs/2507.19504)
*Zhe Su,Xiang Liu,Layal Bou Hamdan,Vasileios Maroulas,Jie Wu,Gunnar Carlsson,Guo-Wei Wei*

Main category: math.HO

TL;DR: 本文综述了超越持续同调的拓扑数据分析（TDA）与拓扑深度学习（TDL）方法，探讨了多种拓扑工具在不同数据类型中的应用及其局限性。


<details>
  <summary>Details</summary>
Motivation: 持续同调作为TDA的核心技术虽广泛应用，但其高度抽象性、对非拓扑变化不敏感及对点云数据的依赖限制了其潜力。本文旨在探索更广泛的拓扑方法以弥补这些不足。

Method: 综述了持续拓扑拉普拉斯算子、狄拉克算子、层理论、Mayer拓扑等工具；针对流形数据引入微分拓扑技术（如持续德拉姆上同调），针对3D空间曲线提出几何拓扑方法（如多尺度高斯链积分）。

Result: 系统梳理了适用于点云、序列数据、流形、3D曲线等不同数据结构的拓扑工具，并总结了拓扑表示方法、软件包及机器学习向量化技术。

Conclusion: 强调根据数据类型选择合适拓扑工具的重要性，为TDA/TDL研究提供了超越持续同调的方法论框架与未来发展方向。

Abstract: Topological data analysis (TDA) is a rapidly evolving field in applied
mathematics and data science that leverages tools from topology to uncover
robust, shape-driven insights in complex datasets. The main workhorse is
persistent homology, a technique rooted in algebraic topology. Paired with
topological deep learning (TDL) or topological machine learning, persistent
homology has achieved tremendous success in a wide variety of applications in
science, engineering, medicine, and industry. However, persistent homology has
many limitations due to its high-level abstraction, insensitivity to
non-topological changes, and reliance on point cloud data. This paper presents
a comprehensive review of TDA and TDL beyond persistent homology. It analyzes
how persistent topological Laplacians and Dirac operators provide spectral
representations to capture both topological invariants and homotopic evolution.
Other formulations are presented in terms of sheaf theory, Mayer topology, and
interaction topology. For data on differentiable manifolds, techniques rooted
in differential topology, such as persistent de Rham cohomology, persistent
Hodge Laplacian, and Hodge decomposition, are reviewed. For one-dimensional
(1D) curves embedded in 3-space, approaches from geometric topology are
discussed, including multiscale Gauss-link integrals, persistent Jones
polynomials, and persistent Khovanov homology. This paper further discusses the
appropriate selection of topological tools for different input data, such as
point clouds, sequential data, data on manifolds, curves embedded in 3-space,
and data with additional non-geometric information. A review is also given of
various topological representations, software packages, and machine learning
vectorizations. Finally, this review ends with concluding remarks.

</details>


### [71] [History of the canonical basis and crystal basis](https://arxiv.org/abs/2507.20816)
*G. Lusztig*

Main category: math.HO

TL;DR: 本文综述了量子包络代数及其表示的典范基与晶体基的发展历史。


<details>
  <summary>Details</summary>
Motivation: 探讨量子群理论中典范基与晶体基的数学结构及其重要性，为相关研究提供历史视角。

Method: 通过文献回顾与理论分析，梳理量子包络代数中两类基的提出背景与演变过程。

Result: 系统呈现了典范基（Lusztig提出）与晶体基（Kashiwara提出）的定义、性质及相互关系。

Conclusion: 该综述阐明了这两种基在量子群表示理论中的核心地位，为后续研究奠定历史与理论基础。

Abstract: The history of the canonical basis and crystal basis of a quantized
enveloping algebra and its representations is presented

</details>


<div id='math.GM'></div>

# math.GM [[Back]](#toc)

### [72] [On the dual valued generalized hypergeometric function and its special cases](https://arxiv.org/abs/2507.19501)
*Ravi Dwivedi,Juan Carlos Cortés*

Main category: math.GM

TL;DR: 本文研究双值函数微积分，通过引入双数作为参数和变量，探讨了伽马函数、贝塔函数及广义超几何函数的性质，包括收敛域、微分方程和积分表示，并深入分析了双合流及高斯超几何函数的特性。


<details>
  <summary>Details</summary>
Motivation: 研究双数参数下的特殊函数性质，扩展传统函数理论的应用范围，为数学物理问题提供新的分析工具。

Method: 采用双数理论框架，分析伽马函数、贝塔函数及广义超几何函数的收敛性、微分方程与积分表示，并系统研究双合流与高斯超几何函数的性质。

Result: 确立了双数参数下特殊函数的收敛区域，推导了相应的微分方程与积分表达式，并详细阐述了双合流及高斯超几何函数的数学特性。

Conclusion: 双数理论为特殊函数研究提供了新的视角，所得结果丰富了函数论内容，并具有潜在的应用价值。

Abstract: This paper explores the calculus of dual-valued functions and investigates
the gamma function, beta function and generalized hypergeometric functions by
incorporating dual numbers as parameters and variables. We examine its
fundamental properties, including regions of convergence, differential
equations, and integral representations. Furthermore, we provide an in-depth
discussion on the various properties of the dual confluent and Gauss
hypergeometric functions.

</details>


### [73] [Fibonacci-harmonic sums](https://arxiv.org/abs/2507.19503)
*Kunle Adegoke,Segun Olofin Akerele,Robert Frontczak*

Main category: math.GM

TL;DR: 本文提出了涉及调和数、奇调和数及斐波那契数的多个新求和恒等式。


<details>
  <summary>Details</summary>
Motivation: 旨在扩展数论中特殊数列求和恒等式的研究范畴。

Method: 采用三种方法：分部求和、多项式恒等式及二项式变换。

Result: 成功推导出一系列关于调和数、奇调和数与斐波那契数的新恒等式。

Conclusion: 所提出的方法为相关数列的求和问题提供了新的研究工具与视角。

Abstract: We offer several new summation identities involving harmonic numbers, odd
harmonic numbers, and Fibonacci numbers. Our results are derived using three
different approaches: partial summation, polynomial identities and binomial
transformation.

</details>


### [74] [On recurrence coefficients of classical orthogonal polynomials](https://arxiv.org/abs/2507.20646)
*K. Castillo,G. Gordillo-Núñez*

Main category: math.GM

TL;DR: 本文指出先前两篇论文中提出的判定正交多项式序列是否“经典”的新方法，实际上已被2022年的一篇论文中的两个定理完全涵盖。作者还提供了一个Mathematica符号算法来自动验证二次格上正交多项式序列的经典性，并以双格上的para-Krawtchouk多项式为例，说明其本质上是线性格上的经典正交多项式族。


<details>
  <summary>Details</summary>
Motivation: 揭示近期论文中提出的正交多项式经典性判定方法并非原创，而是已有更一般性理论覆盖，并开发自动化验证工具以简化相关研究。

Method: 通过符号计算（Mathematica实现）验证二次格上正交多项式序列的经典性，并对比分析已有定理与新结论的包含关系。

Result: 证明para-Krawtchouk多项式是线性格经典正交族的特例，其性质可直接从2022年论文的主定理导出。

Conclusion: 该研究澄清了理论重复性，强化了经典正交多项式统一框架的适用性，同时提供了可操作的自动化验证工具。

Abstract: In Lett. Math. Phys. 114, 54 (2024) and 115, 70 (2025), the author introduces
what is presented as a novel method for determining whether a sequence of
orthogonal polynomials is "classical", based solely on its initial recurrence
coefficients. This note demonstrates that all the results contained in those
works are already encompassed by two general theorems previously established in
J. Math. Anal. Appl. 515 (2022), Article 126390. A symbolic algorithm,
implemented in Mathematica, is also provided to enable automated verification
of the classical character of orthogonal polynomial sequences on quadratic
lattices. As an application, it is shown that the so-called para-Krawtchouk
polynomials on bi-lattices, discussed in Lett. Math. Phys. 115, 70 (2025),
constitute a particular instance of a classical orthogonal family on a linear
lattice. Consequently, their algebraic properties follow as a specific case of
one of the main theorems established in J. Math. Anal. Appl. 515 (2022),
Article 126390.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [75] [A note on the sizes of bipartite 1-planar graphs](https://arxiv.org/abs/2507.19762)
*Guiping Wang*

Main category: math.CO

TL;DR: 本文解决了关于具有1-圆盘OX绘制的二分图最大边数的问题，证明了边数上界为2|V(G)|+|X|-6，并展示了该上界的紧性。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于Huang等人提出的关于二分1-平面图边密度猜想，以及确定具有1-圆盘OX绘制的二分图最大边数的问题。

Method: 通过分析1-圆盘OX绘制的特性，结合二分图的结构性质，推导边数的上界。

Result: 证明了具有1-圆盘OX绘制的二分图G的边数最多为2|V(G)|+|X|-6，且该上界是紧的。

Conclusion: 研究不仅解决了Huang等人提出的问题，还为二分1-平面图的边密度提供了新的理论支持。

Abstract: A graph is 1-planar if it admits a drawing in the plane such that each edge
is crossed at most once. Let G be a bipartite 1-planar graph with partite sets
X and Y. A 1-disk OX drawing of G is a 1-planar drawing such that all vertices
of X lie on the boundary of O and all vertices of Y and all edges of G locate
in the interior of O, where O is a disk on the plane. The concept was first
proposed by Huang, Ouyang and Dong when they solved a conjecture about the edge
density of bipartite 1-planar graphs. Additionally, they presented a problem of
determining the maximum number of edges in a bipartite graph with a 1-disk OX
drawing. In this paper, we solve this problem and prove that every bipartite
graph G which has a 1-disk OX drawing has at most 2|V(G)|+|X|-6 edges.
Moreover, we demonstrate that this upper bound is tight.

</details>


### [76] [Structured Sunflowers](https://arxiv.org/abs/2507.20381)
*Nathanael Ackerman,Mary Leah Karker,Mostafa Mirabi*

Main category: math.CO

TL;DR: 本文提出了\"sunflowerable\"无限结构的概念，并给出了其充分条件，证明了多个著名结构具有该性质，同时研究了年龄的类似性质。


<details>
  <summary>Details</summary>
Motivation: 研究无限结构的\"sunflowerable\"性质，旨在理解其与向日葵集、不可分性等组合性质的关系，并推广到年龄理论。

Method: 通过定义\"sunflowerable\"结构的充分条件，结合不可分性理论，分析具体结构（如线性序）并建立年龄的向日葵性质。

Result: 证明了多个经典结构（如Fra\"iss\\'e极限）具有向日葵性，完全刻画了可数线性序的向日葵性，并建立了年龄性质与结构性质的联系。

Conclusion: 向日葵性为无限结构与组合数学建立了新联系，其充分条件及年龄性质的发现为后续研究提供了理论基础。

Abstract: We call an infinite structure $\mathcal{M}$ sunflowerable if whenever
$\mathcal{M}'$ is isomorphic to $\mathcal{M}$ with underlying set $M'$,
consisting of finite sets of bounded size, there is an $M_0 \subseteq M'$ such
that $M_0$ is a sunflower and $\mathcal{M}'\!\!\upharpoonright[M_0]$ is
isomorphic to $\mathcal{M}$. We give sufficient conditions on $\mathcal{M}$ to
show that $\mathcal{M}$ is sunflowerable. These conditions allow us to show
that several well-known structures are sunflowerable and give a complete
characterization of the countable linear orderings which are sunflowerable. We
show that a sunflowerable structure must be indivisible. This allows us to show
that any Fra\"iss\'e limit which has the 3-disjoint amalgamation property and a
single unary type must be indivisible. In addition to studying sunflowerability
of infinite structures, we also consider an analogous property of an age which
we call the sunflower property. We show that any sunflowerable structure must
have an age with the sunflower property. We also give concrete bounds in the
case that the age has the hereditary property, the 3-disjoint amalgamation
property, and is indivisible.

</details>


### [77] [The number of regular simplices in higher dimensions](https://arxiv.org/abs/2507.19841)
*Felix Christian Clemen,Adrian Dumitrescu,Dingyuan Liu*

Main category: math.CO

TL;DR: 研究极值函数$S^k_d(n)$的渐进行为，确定$d\geq2k\geq6$时的渐近值，并在$k=3$且$d$为偶数的情形下得到精确解，验证了Erd\H{o}s猜想。


<details>
  <summary>Details</summary>
Motivation: 解决Erd\H{o}s关于$\mathbb{R}^d$空间中$n$个点构成的$(k-1)$-单形最大数量的猜想，推动极值几何理论的发展。

Method: 结合超图Tur\'an理论和线性代数技术，分析高维空间中点的几何构型。

Result: 对于$d\geq2k\geq6$，确定了$S^k_d(n)$的渐近常数倍；当$k=3$且$d\geq6$为偶数时，给出了$S^3_d(n)$的精确值。

Conclusion: 该研究不仅强化了Erd\H{o}s猜想的结论，还为高维极值几何提供了新的分析工具和理论框架。

Abstract: We study the extremal function $S^k_d(n)$, defined as the maximum number of
regular $(k-1)$-simplices spanned by $n$ points in $\mathbb{R}^d$. For any
fixed $d\geq2k\geq6$, we determine the asymptotic behavior of $S^k_d(n)$ up to
a multiplicative constant in the lower-order term. In particular, when $k=3$,
we determine the exact value of $S^3_d(n)$, for all even dimensions $d\geq6$
and sufficiently large $n$. This resolves a conjecture of Erd\H{o}s in a
stronger form. The proof leverages techniques from hypergraph Tur\'an theory
and linear algebra.

</details>


### [78] [General Strong Bound on the Uncrossed Number which is Tight for the Edge Crossing Number](https://arxiv.org/abs/2507.20937)
*Gaspard Charvy,Tomáš Masařík*

Main category: math.CO

TL;DR: 本文研究了图的非交叉集合概念，改进了关于非交叉数$unc(G)$的下界，特别是在稠密图中，提出了更紧的乘法常数$c'_\epsilon=3-\sqrt{(2-\epsilon)}$，并证明了该下界在稠密图中渐近紧致。


<details>
  <summary>Details</summary>
Motivation: 图的非交叉集合是Hlin\v{e}n\'y和Masa\v{r}\'ik提出的新概念，旨在通过一组平面绘图可视化图的各个方面。非交叉数$unc(G)$的最小值$k$是一个关键问题，与图的厚度密切相关。现有下界存在改进空间，特别是在稠密图中。

Method: 通过分析图的非交叉子图数和稠密图的性质，作者改进了非交叉数的下界。具体方法包括重新推导下界表达式，并引入新的乘法常数$c'_\epsilon=3-\sqrt{(2-\epsilon)}$，同时构造了证明该下界渐近紧致的实例。

Result: 改进后的下界为$\lceil\frac{|E(G)|}{3|V(G)|-6-\sqrt{2|E(G)|}+\sqrt{6(|V(G)|-2)}}\rceil \le unc(G)$。在稠密图中，该下界表现为$\lceil\frac{|E(G)|}{c'_\epsilon|V(G)|+o(|V(G)|)}\rceil \le unc(G)$，其中$c'_\epsilon=3-\sqrt{(2-\epsilon)}$。该结果在$\epsilon \approx \frac{1}{2}$时达到紧致。

Conclusion: 本文提出的非交叉数下界在稠密图中具有渐近紧致性，并通过构造验证了其最优性。这一结果为图的非交叉集合研究提供了更精确的理论工具，特别是在稠密图场景下。

Abstract: We investigate a very recent concept for visualizing various aspects of a
graph in the plane using a collection of drawings introduced by Hlin\v{e}n\'y
and Masa\v{r}\'ik [GD 2023]. Formally, given a graph $G$, we aim to find an
uncrossed collection containing drawings of $G$ in the plane such that each
edge of $G$ is not crossed in at least one drawing in the collection. The
uncrossed number of $G$ ($unc(G)$) is the smallest integer $k$ such that an
uncrossed collection for $G$ of size $k$ exists. The uncrossed number is
lower-bounded by the well-known thickness, which is an edge-decomposition of
$G$ into planar graphs. This connection gives a trivial lower-bound
$\lceil\frac{|E(G)|}{3|V(G)|-6}\rceil \le unc(G)$. In a recent paper, Balko,
Hlin\v{e}n\'y, Masa\v{r}\'ik, Orthaber, Vogtenhuber, and Wagner [GD 2024]
presented the first non-trivial and general lower-bound on the uncrossed
number. We summarize it in terms of dense graphs (where
$|E(G)|=\epsilon(|V(G)|)^2$ for some $\epsilon>0$):
$\lceil\frac{|E(G)|}{c_\epsilon|V(G)|}\rceil \le unc(G)$, where $c_\epsilon\ge
2.82$ is a constant depending on $\epsilon$.
  We improve the lower-bound to state that
$\lceil\frac{|E(G)|}{3|V(G)|-6-\sqrt{2|E(G)|}+\sqrt{6(|V(G)|-2)}}\rceil \le
unc(G)$. Translated to dense graphs regime, the bound yields a multiplicative
constant $c'_\epsilon=3-\sqrt{(2-\epsilon)}$ in the expression
$\lceil\frac{|E(G)|}{c'_\epsilon|V(G)|+o(|V(G)|)}\rceil \le unc(G)$. Hence, it
is tight (up to low-order terms) for $\epsilon \approx \frac{1}{2}$ as
warranted by complete graphs.
  In fact, we formulate our result in the language of the maximum uncrossed
subgraph number, that is, the maximum number of edges of $G$ that are not
crossed in a drawing of $G$ in the plane. In that case, we also provide a
construction certifying that our bound is asymptotically tight (up to low-order
terms) on dense graphs for all $\epsilon>0$.

</details>


### [79] [A Note on Edge Coalitions in Graphs](https://arxiv.org/abs/2507.19871)
*Nazli Besharati,Azam Sadat Emadi,Iman Masoumi*

Main category: math.CO

TL;DR: 本文扩展了Haynes等人(2020)的顶点联盟概念，首次提出边联盟理论，研究其在特定图结构中的存在性及性质，并分析了特殊图类中的边联盟结构。


<details>
  <summary>Details</summary>
Motivation: 基于Haynes等人关于图联盟的顶点研究，本文旨在从边视角拓展该理论，建立边联盟的数学框架并探索其图论特性。

Method: 定义边联盟为两个非边支配集的边集并集构成支配集，提出边联盟划分概念，通过构造性证明和结构分析法研究其在树状图等特殊图类中的存在条件。

Result: 证明了边联盟在特定图结构中的存在性，刻画了具有少量边联盟的图特征，并系统分析了路径图、星图等特殊图类的边联盟划分规律。

Conclusion: 边联盟理论完善了图支配集的研究体系，为后续研究边划分问题提供了新工具，在特殊图类中展示出丰富的结构性质。

Abstract: Haynes et al. (2020) introduced and investigated the concept of coalition in
graphs \cite{hhhmm1}. Their study examined this concept from a vertex-based
perspective, whereas in this paper, we extend the investigation to an
edge-based perspective of graphs. \\ An edge coalition in a graph $G=(V,E)$
consists of two disjoint sets of edges $E_1$ and $E_2$, neither of which
individually forms an edge dominating set, but whose union $E_1\cup E_2$ is an
edge dominating set. An edge coalition partition in a graph $G$ of order
$n=|V|$ and size $|E|=m$ is an edge partition $\pi=\{E_1,\cdots,E_k\}$ so that
every set $E_i$ of $\pi$ either is a singleton edge dominating set, or is not
an edge dominating set but forms an edge coalition with another set $E_j$ in
$\pi$, which is also not an edge dominating set.
  In this paper, we introduce the concept of an edge coalition and demonstrate
its existence in particular graphs and trees. Additionally, we characterize
graphs with small number of edge coalitions and analyze edge coalition
structures in various special graph classes.

</details>


### [80] [A Bijection between Necklaces and Restricted Multisets](https://arxiv.org/abs/2507.19940)
*Jiyou Li,Yanghongbo Zhou*

Main category: math.CO

TL;DR: 本文证明了Swee Hong Chan的猜想，建立了长度为$n$、最多$q$种颜色的项链集合与周期函数$f: \mathbb{Z}_{n}\to \{0, 1, ..., q-1\}$集合之间的双射关系，其中$q$和$n$互质。


<details>
  <summary>Details</summary>
Motivation: 研究项链与周期函数之间的对应关系，解决Swee Hong Chan提出的猜想，扩展组合数学与数论的应用。

Method: 通过建立双射关系，利用数论中互质条件和周期性函数的性质，证明两个集合之间存在一一对应。

Result: 成功证明了当$q$和$n$互质时，长度为$n$、最多$q$种颜色的项链集合与满足加权和被$n$整除的周期函数集合之间存在双射。

Conclusion: 该研究不仅验证了猜想，还为组合数学与数论的联系提供了新的视角，具有潜在的理论和应用价值。

Abstract: We present a proof of Swee Hong Chan's conjecture establishing a bijection
between the set of necklaces of length $n$ with at most $q$ colors the set of
periodic functions $f: \mathbb{Z}_{n}\to {0, 1, ..., q-1}$ whose weighted sum
is divisible by $n$, where $q$ and $n$ are coprime positive integers.

</details>


### [81] [Finite Interpretations of a Hyper-Catalan Series Solution to Polynomial Equations and Visualizations](https://arxiv.org/abs/2507.20003)
*Pratham Mukewar*

Main category: math.CO

TL;DR: 本文证明了超卡塔兰数生成级数$\mathbf{S}$可作为几何多项式的形式级数零点，并通过有限顶点/边/面截断将其转化为有限恒等式，揭示了多边形细分与多项式代数的对应关系。


<details>
  <summary>Details</summary>
Motivation: 探索一般一元多项式方程的求解方法，特别是超卡塔兰数$C[m_2,m_3,\ldots]$与几何多项式零点的深层联系。

Method: 采用级数解的变体，显式展示顶点、边和面的数量，并通过Python生成的可视化案例验证理论。

Result: 超卡塔兰数生成级数$\mathbf{S}$的无限级数结果可转化为有限顶点/边/面截断下的恒等式，建立了多边形细分操作与多项式代数的直接对应。

Conclusion: 研究通过几何截断将无限级数问题有限化，并为多边形细分组合与多项式代数提供了新的统一框架。

Abstract: The solution to the general univariate polynomial equation has been sought
for centuries. It is well known there is no general solution in radicals for
degrees five and above.
  The hyper-Catalan numbers $C[m_2,m_3,m_4,\ldots]$ count the ways to subdivide
a planar polygon into exactly $m_2$ triangles, $m_3$ quadrilaterals, $m_4$
pentagons, etc. Wildberger and Rubine (2025) show the generating series
$\mathbf{S}$ of the hyper-Catalan numbers is a formal series zero of the
general geometric polynomial (meaning, general except for a constant of $1$ and
a linear coefficient of $-1$).
  Using a variant of the series solution to the geometric polynomial that has
the number of vertices, edges, and faces explicitly shown, We prove their
infinite series result may be viewed as a finite identity at each level, where
a level is a truncation of $\mathbf{S}$ to a given maximum number of vertices,
edges, or faces (bounded by degree).
  We illustrate this result, as well as the general correspondence between
operations on sets of subdivided polygons and the algebra of polynomials, with
figures and animations generated using Python.

</details>


### [82] [Type R $λ$-Permutation Approach to Velleman's Open Problem](https://arxiv.org/abs/2507.20062)
*Hui Xiao,Assaf Marzan,Daniil Nikolievich Shaposhnikov,Antonio Marino,Kealan Vasquez,Andrew D. Harsh,Hadi Hammoud,Yunus Zeytuncu*

Main category: math.CO

TL;DR: 本文部分解决了Daniel Velleman关于$\lambda$-置换的开放性问题，研究了类型R $\lambda$-置换下条件发散级数的收敛集合$Z_R$的性质，证明其只能是空集、单点集或实数集$\mathbb{R}$，并引入“实质性性质”为$Z_R$的形态提供充分条件。


<details>
  <summary>Details</summary>
Motivation: 研究$\lambda$-置换在条件发散级数重排中的应用，解决Velleman提出的开放性问题：对于条件发散级数，通过$\lambda$-置换得到的收敛值集合$S$是否可以介于空集和实数集$\mathbb{R}$之间。

Method: 定义类型R $\lambda$-置换作为$\lambda$-置换的子集，研究其对应的收敛值集合$Z_R$。通过分析级数的“实质性性质”，为$Z_R$的形态（空集、单点集或$\mathbb{R}$）建立充分条件。

Result: 证明$Z_R$只能是空集、单点集或$\mathbb{R}$，并给出级数的“实质性性质”作为$Z_R$为单点集或$\mathbb{R}$的充分条件。

Conclusion: 在类型R $\lambda$-置换约束下，条件发散级数的收敛值集合$Z_R$具有严格的分类性质，且通过“实质性性质”可进一步明确其具体形态。

Abstract: Previously, mathematicians Steven Krantz and Jeffery McNeal studied a type of
positive numbers permutation called $\lambda$-permutation. This type of
permutation, when applied to the index of terms of a series, is defined to be
both convergence-preserving and "fixing" at least one divergent series, that
is, rearranging the terms of any convergent series will result in a convergent
series, while rearranging the terms of some divergent series will result in a
convergent series. In general, if a divergent series can be fixed to converge
in some way (it does not need to be by $\lambda$-permutation), it is called a
"conditionally divergent series". In 2006, another mathematician Daniel
Velleman raised an open problem related to $\lambda$-permutation: for a
conditionally divergent series $\sum_{n=0}^{\infty}a_n,n\in \mathbb{N},a_n\in
\mathbb{R}$, let $S=\{L \in \mathbb{R} \colon L =
\sum_{n=0}^{\infty}{a_{\sigma\left(n\right)}}$ $\text{for some }
\lambda\text{-permutation } \sigma\}$, can $S$ ever be something between
$\emptyset$ and $\mathbb{R}$? This paper is devoted to partially answering this
open problem by considering a subset of $\lambda$-permutation constraint by how
we can permute, named type R $\lambda$-permutation. Then we answer the
analogous question about a subset of S with respect to type R
$\lambda$-permutation, named $Z_{R}=\{L \in \mathbb{R} \colon L =
\sum_{n=0}^{\infty}{a_{\sigma\left(n\right)}}$ $\text{for some type R } \lambda
\text{-permutation } \sigma\}$. We show that $Z_R$ is either $\emptyset$, a
singleton or $\mathbb{R}$. We also provide sufficient conditions on the
conditionally divergent series $\sum_{n=0}^{\infty}a_n$ for $Z_R$ to be a
singleton or $\mathbb{R}$, by introducing a "substantial property" on the
series.

</details>


### [83] [Rook decomposition of the Partition function](https://arxiv.org/abs/2507.20260)
*N. Guru Sharan*

Main category: math.CO

TL;DR: 本文研究了与整数分拆相关的Ferrers棋盘的最大车数，揭示了其与分拆的Durfee三角形之间的联系，并提出了分拆函数的新分解方法。


<details>
  <summary>Details</summary>
Motivation: 研究Ferrers棋盘的最大车数及其与整数分拆的Durfee三角形之间的关系，旨在探索分拆函数的新性质及其在模周期性和奇偶性方面的表现。

Method: 通过分析Durfee三角形大小为3、4和5的分拆的生成函数，推导其精确公式，并研究其在模$p$下的周期性和奇偶性。此外，还建立了分拆函数的一个新车类比递推关系。

Result: 获得了Durfee三角形大小为3、4和5的分拆的生成函数及其精确公式，证明了其在任意$p \in \mathbb{N}$且$p\geq2$下的模周期性，并建立了其奇偶性和奇偶偏置。同时，还得到了分拆函数的新车类比递推关系。

Conclusion: 最大车数为分拆函数提供了新的分解方法，揭示了其与Durfee三角形的深刻联系，并在模周期性、奇偶性和增长渐近性方面取得了新的理论成果。

Abstract: The rook numbers are fairly well-studied in the literature. In this paper, we
study the max-rook number of the Ferrers boards associated to integer
partitions. We show its connections with the Durfee triangle of the partitions.
The max-rook number gives a new decomposition of the partition function. We
derive the generating functions of the partitions with the Durfee triangle of
sizes $3$, $4$ and $5$. We obtain their exact formula and further use it to
show the periodicity modulo $p$ for any $p \in \mathbb{N}$ and $p\geq2$. We
also establish their parity and parity bias. We give the growth asymptotics of
partitions with the Durfee triangle of sizes $3$ and $4$. We obtain a new rook
analogue of the recurrence relation of the partition function.

</details>


### [84] [Homogeneous substructures in random ordered hyper-matchings](https://arxiv.org/abs/2507.20374)
*Andrzej Dudek,Jarosław Grytczuk,Jakub Przybyło,Andrzej Ruciński*

Main category: math.CO

TL;DR: 本文研究了随机有序$r$-均匀匹配中最大$\mathcal{P}$-团的大小，确定了多种$\mathcal{P}$集（包括大小不超过2的集、所有$r$-分划模式集及具有布尔对称结构的集）的团大小（至多乘性常数）。


<details>
  <summary>Details</summary>
Motivation: 研究有序$r$-均匀匹配中$\mathcal{P}$-团的最大规模，旨在理解不同模式集$\mathcal{P}$在随机匹配中的表现，尤其是$r$-模式对匹配结构的影响。

Method: 通过分析随机有序$r$-均匀匹配的均匀分布特性，针对不同$\mathcal{P}$集（如$|\mathcal{P}|\le2$、$r$-分划模式集$\mathcal{R}^{(r)}$及布尔对称结构集）设计理论框架，推导最大$\mathcal{P}$-团的规模界限。

Result: 确定了多种$\mathcal{P}$集（包括$|\mathcal{P}|\le2$、$\mathcal{R}^{(r)}$及布尔对称集）的最大$\mathcal{P}$-团规模，结果以乘性常数精确表示。

Conclusion: 研究揭示了随机有序$r$-均匀匹配中$\mathcal{P}$-团的最大规模与模式集$\mathcal{P}$的结构密切相关，为组合数学中的模式匹配问题提供了新的理论工具。

Abstract: An ordered $r$-uniform matching of size $n$ is a collection of $n$ pairwise
disjoint $r$-subsets of a linearly ordered set of $rn$ vertices. For $n=2$,
such a matching is called an $r$-pattern, as it represents one of
$\tfrac12\binom{2r}r$ ways two disjoint edges may intertwine. Given a set
$\mathcal{P}$ of $r$-patterns, a $\mathcal{P}$-clique is a matching with all
pairs of edges order-isomorphic to a member of $\mathcal{P}$.
  In this paper we are interested in the size of a largest $\mathcal{P}$-clique
in a random ordered $r$-uniform matching selected uniformly from all such
matchings on a fixed vertex set $[rn]$.
  We determine this size (up to multiplicative constants) for several sets
$\mathcal{P}$, including all sets of size $|\mathcal{P}|\le2$, the set
$\mathcal{R}^{(r)}$ of all $r$-partite patterns, as well as sets $\mathcal{P}$
enjoying a Boolean-like, symmetric structure.

</details>


### [85] [Distribution of new statistics of parking functions and their generalizations](https://arxiv.org/abs/2507.20495)
*Stephan Wagner,Catherine H. Yan,Mei Yin*

Main category: math.CO

TL;DR: 本文提出了停车函数与标记森林枚举的新结果，通过双射对应引入新统计量，并揭示了两者统计量间的联合分布关系。


<details>
  <summary>Details</summary>
Motivation: 研究停车函数与标记森林的新统计量，旨在解释Stanley和Yin发现的看似无关统计量间的神秘等分布现象。

Method: 通过双射对应将停车函数的新统计量扩展至标记森林，并分析两者统计量的联合分布。

Result: 确定了停车函数与标记森林统计量的联合分布，为Stanley-Yin现象提供了显式双射解释。

Conclusion: 研究成果不仅解释了现有等分布现象，其方法还可进一步扩展至更精细的统计量联合分布分析。

Abstract: In this paper we present new results on the enumeration of parking functions
and labeled forests. We introduce new statistics on parking functions, which
are then extended to labeled forests via bijective correspondences. We
determine the joint distribution of two statistics on parking functions and
their counterparts on labeled forests. Our results on labeled forests also
serve to explain the mysterious equidistribution between two seemingly
unrelated statistics in parking functions recently identified by Stanley and
Yin and give an explicit bijection between the two statistics. Extensions of
our techniques are discussed, including joint distribution on further
refinement of these new statistics.

</details>


### [86] [New bounds for linear arboricity and related problems](https://arxiv.org/abs/2507.20500)
*Micha Christoph,Nemanja Draganić,António Girão,Eoin Hurley,Lukas Michel,Alp Müyesser*

Main category: math.CO

TL;DR: 本文证明了线性森林分解猜想的一个改进结果，提出了一种新方法将图分解为$\Delta/2 + \mathcal{O}(\log n)$个线性森林，并在高密度图($\Delta = \Omega(n^\varepsilon)$)中实现了误差项的指数级改进。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于线性森林分解猜想，该猜想认为任何最大度为$\Delta$的图可分解为最多$\lceil(\Delta+1)/2\rceil$个线性森林。本文旨在改进这一猜想的误差项并探索其应用。

Method: 方法上创新性地推广了P\'osa旋转技术，从单一路径端点的旋转扩展到线性森林中多个端点的同步旋转，这一技术突破为后续应用奠定了基础。

Result: 主要成果是证明了$\Delta/2 + \mathcal{O}(\log n)$个线性森林即可完成分解，当$\Delta = \Omega(n^\varepsilon)$时，误差项相比之前最佳结果有指数级改进。

Conclusion: 该研究不仅推进了线性森林分解理论，其方法还可应用于解决Feige和Fuchs关于少路径生成线性森林的猜想，以及在连通正则图中构建最优短途游等问题。

Abstract: A linear forest is a collection of vertex-disjoint paths. The Linear
Arboricity Conjecture states that every graph of maximum degree $\Delta$ can be
decomposed into at most $\lceil(\Delta+1)/2\rceil$ linear forests. We prove
that $\Delta/2 + \mathcal{O}(\log n)$ linear forests suffice, where $n$ is the
number of vertices of the graph. If $\Delta = \Omega(n^\varepsilon)$, this is
an exponential improvement over the previous best error term. We achieve this
by generalising P\'osa rotations from rotations of one endpoint of a path to
simultaneous rotations of multiple endpoints of a linear forest. This method
has further applications, including the resolution of a conjecture of Feige and
Fuchs on spanning linear forests with few paths and the existence of optimally
short tours in connected regular graphs.

</details>


### [87] [Some calculations of centralizer rings of a complex reflection group](https://arxiv.org/abs/2507.20521)
*Masashi Kosuda,Manabu Oura,Sarbaini*

Main category: math.CO

TL;DR: 本文确定了复数反射群H1的忠实传递置换表示张量积的中心化环结构，补充了Imamura-Kosuda-Oura的研究成果。


<details>
  <summary>Details</summary>
Motivation: 研究复数反射群H1的忠实传递置换表示张量积的中心化环结构，以填补现有文献中的空白。

Method: 通过分析复数反射群H1的忠实传递置换表示及其张量积，运用群表示论和环论方法确定中心化环的结构。

Result: 成功确定了H1的忠实传递置换表示张量积的中心化环的具体结构。

Conclusion: 该研究完善了复数反射群表示理论，为后续相关研究提供了重要的理论基础。

Abstract: Let H1 be the complex reflection group of order 96. For the tensor products
of faithful transitive permutation representations of H1, we determine the
structures of the centralizer rings. This complements the work of
Imamura-Kosuda-Oura.

</details>


### [88] [On one property of Catalan numbers](https://arxiv.org/abs/2507.20584)
*Yury Kochetkov*

Main category: math.CO

TL;DR: 本文提供了Catalan数$C_n$在特定条件下可被$n+2$整除的新证明。


<details>
  <summary>Details</summary>
Motivation: 研究Catalan数的整除性质，特别是在$n$为奇数且$n\not\equiv 1\text{ mod }3$时的特性。

Method: 采用新的证明方法，验证Catalan数$C_n$在给定条件下的整除性。

Result: 证明了当$n$为奇数且$n\not\equiv 1\text{ mod }3$时，Catalan数$C_n$可被$n+2$整除。

Conclusion: 该研究扩展了对Catalan数整除性质的理解，为相关数学理论提供了新的支持。

Abstract: We give a new proof of the following statement: the Catalan number $C_n$ is
divisible by $n+2$, if $n$ is odd and $n\not\equiv 1\text{ mod }3$.

</details>


### [89] [An introduction to the symmetric group algebra](https://arxiv.org/abs/2507.20706)
*Darij Grinberg*

Main category: math.CO

TL;DR: 本文是对称群群代数的入门教材，涵盖对称群代数$\mathbf{k}[S_n]$的基本理论、表示论及Young表盘等经典内容，包含100多道习题。


<details>
  <summary>Details</summary>
Motivation: 旨在为研究生提供对称群群代数的系统介绍，尽量减少对基环$\mathbf{k}$和高等表示论的依赖，侧重初等计算法。

Method: 采用初等计算法，引入Young-Jucys-Murphy元素、共轭类和积分等对称群代数元素，并基于Specht模构建多种基。

Result: 详细证明了特征0不可约表示的刻画、Garnir关系、标准基定理、Specht模对偶描述及钩长公式等重要结论。

Conclusion: 教材系统覆盖对称群表示论核心内容，包含Murphy胞腔基等非经典结果，适合作为研究生课程参考资料。

Abstract: This is an introduction to the group algebras of the symmetric groups,
written for a quarter-long graduate course. After recalling the definition of
group algebras (and monoid algebras) in general, as well as basic properties of
permutations, we introduce several families of elements in the symmetric group
algebras $\mathbf{k}[S_n]$ such as the Young--Jucys--Murphy elements, the
(sign-)integrals and the conjugacy class sums. Then comes a chapter on group
actions and representations in general, followed by the core of this text: a
study of the representations of symmetric groups (i.e., of left
$\mathbf{k}[S_n]$-modules), including the classical theory of Young tableaux
and Young symmetrizers. We prove in detail the main facts including the
characterization of irreducible representations (in characteristic $0$), the
Garnir relations, the standard basis theorem, the description of duals of
Specht modules, and the hook length formula, as well as a number of less known
results. Finally, we describe several bases of $\mathbf{k}[S_n]$ that arise
from the study of Specht modules, including the Murphy cellular bases.
  The methods used are elementary and computational. We aim to assume as little
as possible of the base ring $\mathbf{k}$, and to use as little as possible
from representation theory (nothing more advanced than Maschke and
Jordan--H\"older).
  Over 100 exercises (without solutions) are scattered through the text.

</details>


### [90] [Marked multi-colorings and marked chromatic polynomials of hypergraphs and subspace arrangements](https://arxiv.org/abs/2507.20847)
*Chaithra P,Shushma Rani,R. Venkatesh*

Main category: math.CO

TL;DR: 本文介绍了超图的标记多着色、标记色多项式及标记（多元）独立级数概念，并将其推广到子空间构型，证明了超平面构型的独立级数的(-q)次幂具有非负系数。


<details>
  <summary>Details</summary>
Motivation: 研究超图的标记多着色与独立级数，旨在将图的色多项式与独立级数关系推广到超图及子空间构型，探索其组合性质。

Method: 通过定义标记多着色、标记色多项式及标记独立级数，建立超图与子空间构型的理论框架，并运用多项式与级数方法进行证明。

Result: 证明了超图标记独立级数的q次幂系数与标记色多项式一致；子空间构型的标记多着色数为q的多项式；超平面构型的独立级数(-q)次幂系数非负。

Conclusion: 超图标记理论可推广至子空间构型，且超平面构型的独立级数(-q)次幂系数非负；猜想超图的该性质成立当且仅当其边均为偶数基数。

Abstract: We introduce the concepts of marked multi-colorings, marked chromatic
polynomials, and marked (multivariate) independence series for hypergraphs. We
show that the coefficients of the q-th power of the marked independence series
of a hypergraph coincide with its marked chromatic polynomials in q, thereby
generalizing a corresponding result for graphs established in Chaithra et al.
2025 (arXiv:2503.11230). These notions are then naturally extended to subspace
arrangements. In particular, we prove that the number of marked multi
q-colorings of a subspace arrangement is a polynomial in q. We also define the
(marked) independence series for subspace arrangements and prove that the
(-q)-th power of the independence series of a hyperplane arrangement has
non-negative coefficients. We further conjecture that the (-q)-th power of the
independence series of a hypergraph has non-negative coefficients if and only
if all its edges have even cardinality.

</details>


### [91] [A $σ$-morphic convex protoset](https://arxiv.org/abs/2507.20867)
*Aleksa Džuklevski*

Main category: math.CO

TL;DR: 本文提出了一种构造凸面$\sigma$-同构瓦片集的方法，解决了平面中是否存在$\sigma$-同构瓦片的未解问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于平面中是否存在能以不可数多种非全等方式铺砌的$\sigma$-同构瓦片这一未解决问题，且现有构造均依赖凹凸结构导致非凸性。

Method: 通过巧妙分割Schmitt发现的瓦片集，将其转化为凸面瓦片集，同时保留原始铺砌行为特性。

Result: 成功构造出首个凸面$\sigma$-同构瓦片集，突破了传统构造必须依赖凹凸结构的限制。

Conclusion: 该研究不仅证实了凸面$\sigma$-同构瓦片的存在性，还为相关数学问题提供了新的构造范式。

Abstract: We say that a tile is $\sigma$-morphic if it tiles the plane in exactly
$\aleph_0$ many noncongruent ways (up to an isometry). It is an unsolved
problem of whether a $\sigma$-morphic tile exist in the plane. In this note we
present a construction of a set of convex tiles that is $\sigma$-morphic. The
result is interesting since all the constructions of $\sigma$-morphic sets of
tiles that arise in the literature make use of bumps and nicks, which
necessarily make the tiles non-convex. We construct our set by cleverly
dividing the tiles of the set of tiles discovered by Schmitt into convex tiles
so that they behave in the same manner.

</details>


### [92] [An identity relating Catalan numbers to tangent numbers with arithmetic applications](https://arxiv.org/abs/2507.20965)
*Tongyuan Zhao,Zhicong Lin,Yongchun Zang*

Main category: math.CO

TL;DR: 该论文证明了一个将Catalan数与切线数关联的组合恒等式，并由此发现了一个涉及切线数的有趣恒等式，该恒等式可用于证明$(n + 1)E_{2n+1}$能被$2^{2n}$整除且商为奇数。此外，论文还提出了该恒等式的一个自然$q$-模拟并给出了组合证明。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于Aliniaeifard和Li提出的关于Catalan数与切线数关系的猜想，该猜想与峰代数（peak algebra）的研究相关。

Method: 通过组合数学的方法，论文证明了一个关键的组合恒等式，并进一步推导出一个涉及切线数$E_{2k+1}$的恒等式。此外，还提出了$q$-模拟的构造并给出了其组合证明。

Result: 主要结果包括：1) 证明了猜想中的组合恒等式；2) 发现了一个新的恒等式$\sum_{k=0}^{n-1}{2n\choose 2k+1}2^{2n-2k}(-1)^{k}E_{2k+1}=2^{2n+1}$；3) 应用该恒等式证明了$(n + 1)E_{2n+1}$能被$2^{2n}$整除且商为奇数；4) 提出了恒等式的$q$-模拟版本。

Conclusion: 该研究不仅解决了Aliniaeifard和Li的猜想，还揭示了切线数的新性质，并通过$q$-模拟扩展了结果。其组合证明方法简化了传统证明中繁琐的计算，为相关领域提供了新的工具和视角。

Abstract: We prove a combinatorial identity relating Catalan numbers to tangent numbers
arising from the study of peak algebra that was conjectured by Aliniaeifard and
Li. This identity leads to the discovery of the intriguing identity $$
\sum_{k=0}^{n-1}{2n\choose 2k+1}2^{2n-2k}(-1)^{k}E_{2k+1}=2^{2n+1}, $$ where
$E_{2k+1}$ denote the tangent numbers. Interestingly, the latter identity can
be applied to prove that $(n + 1)E_{2n+1}$ is divisible by $2^{2n}$ and the
quotient is an odd number, a fact whose traditional proofs require significant
calculations. Moreover, we find a natural $q$-analog of the latter identity
with a combinatorial proof.

</details>


<div id='q-fin.MF'></div>

# q-fin.MF [[Back]](#toc)

### [93] [Lévy-Driven Option Pricing without a Riskless Asset](https://arxiv.org/abs/2507.20338)
*Ziyao Wang*

Main category: q-fin.MF

TL;DR: 本文扩展了Lindquist-Rachev (LR)期权定价框架，引入两种风险资产的共同Levy跳跃动态，以内生'影子'短期利率替代无风险收益率，并采用NIG和CGMY两种跳跃模型。通过Ito-Levy微积分推导LR-PIDE方程，利用FFT和COS算法计算欧式期权价值。实证表明两种模型显著改善标普500期权定价误差，CGMY效果最佳，且提取的影子利率可捕捉流动性压力信号。


<details>
  <summary>Details</summary>
Motivation: 现有LR框架在缺乏无风险债券的市场中定价衍生品时存在局限，需通过引入共同跳跃动态来改进定价准确性，并探索跳跃风险与资金条件的关联。

Method: 采用Normal Inverse Gaussian (NIG)和CGMY两种纯跳跃过程，基于Ito-Levy微积分推导LR偏积分微分方程(LR-PIDE)，结合快速傅里叶变换(FFT)和傅里叶余弦(COS)算法求解期权价格。

Result: 对标普500期权的校准显示：两种跳跃模型显著降低定价误差且更好拟合波动率微笑，CGMY改进最大；从资产数据提取的影子短期利率能识别国库券收益率中未体现的流动性压力信号。

Conclusion: 该框架以实用形式将跳跃风险、相对资产定价和资金条件相联系，CGMY模型表现最优，影子利率可作为潜在风险监测工具。

Abstract: We extend the Lindquist-Rachev (LR) option-pricing framework--which values
derivatives in markets lacking a traded risk-free bond--by introducing common
Levy jump dynamics across two risky assets. The resulting endogenous "shadow"
short rate replaces the usual risk-free yield and governs discounting and
risk-neutral drifts. We focus on two widely used pure-jump specifications: the
Normal Inverse Gaussian (NIG) process and the Carr-Geman-Madan-Yor (CGMY)
tempered-stable process. Using Ito-Levy calculus we derive an LR partial
integro-differential equation (LR-PIDE) and obtain European option values
through characteristic-function methods implemented with the Fast Fourier
Transform (FFT) and Fourier-cosine (COS) algorithms. Calibrations to S and P
500 index options show that both jump models materially reduce pricing errors
and fit the observed volatility smile far better than the Black-Scholes
benchmark; CGMY delivers the largest improvement. We also extract time-varying
shadow short rates from paired asset data and show that sharp declines coincide
with liquidity-stress episodes, highlighting risk signals not visible in
Treasury yields. The framework links jump risk, relative asset pricing, and
funding conditions in a tractable form for practitioners.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [94] [Deep Reputation Scoring in DeFi: zScore-Based Wallet Ranking from Liquidity and Trading Signals](https://arxiv.org/abs/2507.20494)
*Dhanashekar Kandaswamy,Ashutosh Sahoo,Akshay SP,Gurukiran S,Parag Paul,Girish G N*

Main category: q-fin.GN

TL;DR: 本文提出了一种针对Uniswap用户行为的评分框架，包含流动性提供评分和交易行为评分，通过深度学习模型和规则逻辑实现上下文感知的DeFi用户评估。


<details>
  <summary>Details</summary>
Motivation: 随着去中心化金融（DeFi）的发展，区分用户行为（流动性提供与主动交易）对风险建模和链上声誉至关重要。

Method: 采用基于规则的蓝图分解行为指标（交易量、频率、持有时间等），并引入受U-Net架构启发的深度残差神经网络处理边缘案例，同时整合资金池上下文特征（如TVL、费率层级）。

Result: 在Uniswap v3数据上的实验证明，该框架能有效支持用户细分和协议对齐的声誉系统。

Conclusion: 该研究实现了针对Uniswap的特定角色行为建模，为DeFi风险评估和激励设计提供了可扩展的解决方案。

Abstract: As decentralized finance (DeFi) evolves, distinguishing between user
behaviors - liquidity provision versus active trading - has become vital for
risk modeling and on-chain reputation. We propose a behavioral scoring
framework for Uniswap that assigns two complementary scores: a Liquidity
Provision Score that assesses strategic liquidity contributions, and a Swap
Behavior Score that reflects trading intent, volatility exposure, and
discipline. The scores are constructed using rule-based blueprints that
decompose behavior into volume, frequency, holding time, and withdrawal
patterns. To handle edge cases and learn feature interactions, we introduce a
deep residual neural network with densely connected skip blocks inspired by the
U-Net architecture. We also incorporate pool-level context such as total value
locked (TVL), fee tiers, and pool size, allowing the system to differentiate
similar user behaviors across pools with varying characteristics. Our framework
enables context-aware and scalable DeFi user scoring, supporting improved risk
assessment and incentive design. Experiments on Uniswap v3 data show its
usefulness for user segmentation and protocol-aligned reputation systems.
Although we refer to our metric as zScore, it is independently developed and
methodologically different from the cross-protocol system proposed by Udupi et
al. Our focus is on role-specific behavioral modeling within Uniswap using
blueprint logic and supervised learning.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [95] [Towards the ideals of Self-Recovery and Metadata Privacy in Social Vault Recovery](https://arxiv.org/abs/2507.19484)
*Shailesh Mishra,Simone Colombo,Pasindu Tennage,Martin Burkhart,Bryan Ford*

Main category: cs.CR

TL;DR: 本文提出了Apollo框架，通过社交圈分发不可区分的数据来解决社交密钥恢复中的元数据记忆负担与隐私保护之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的社交密钥恢复机制忽视了用户在恢复过程中需要记忆的元数据（如可信联系人的阈值数量），这增加了用户的记忆负担并可能泄露隐私。

Method: Apollo框架通过将不可区分的数据分发给用户的社交圈（可信联系人持有相关数据，非可信联系人存储随机数据），消除了记忆元数据的需要。此外，Apollo采用了一种新颖的多层秘密共享方案来扩展匿名集并减少随机数据的开销。

Result: Apollo将恶意恢复的概率降低至0.005%到1.8%之间，具体取决于攻击者的能力。多层设计在重新连接次数不同的情况下，延迟降低了1.1倍到740千倍。

Conclusion: Apollo框架在保护元数据隐私的同时，显著减轻了用户的记忆负担，并通过多层设计实现了高效的性能。

Abstract: Social key recovery mechanisms enable users to recover their vaults with the
help of trusted contacts, or trustees, avoiding the need for a single point of
trust or memorizing complex strings. However, existing mechanisms overlook the
memorability demands on users for recovery, such as the need to recall a
threshold number of trustees. Therefore, we first formalize the notion of
recovery metadata in the context of social key recovery, illustrating the
tradeoff between easing the burden of memorizing the metadata and maintaining
metadata privacy. We present Apollo, the first framework that addresses this
tradeoff by distributing indistinguishable data within a user's social circle,
where trustees hold relevant data and non-trustees store random data. Apollo
eliminates the need to memorize recovery metadata since a user eventually
gathers sufficient data from her social circle for recovery. Due to
indistinguishability, Apollo protects metadata privacy by forming an anonymity
set that hides the trustees among non-trustees. To make the anonymity set
scalable, Apollo proposes a novel multi-layered secret sharing scheme that
mitigates the overhead due to the random data distributed among non-trustees.
Finally, we provide a prototype implementation of Apollo and report on its
performance. Apollo reduces the chances of malicious recovery to between 0.005%
and 1.8%, depending on the adversary's ability to compromise. The multi-layered
design shows a latency reduction from 1.1x to 740kx compared to a
single-layered approach, depending on the number of reconnections.

</details>


### [96] [Securing the Internet of Medical Things (IoMT): Real-World Attack Taxonomy and Practical Security Measures](https://arxiv.org/abs/2507.19609)
*Suman Deb,Emil Lupu,Emm Mic Drakakis,Anil Anthony Bharath,Zhen Kit Leung,Guang Rui Ma,Anupam Chattopadhyay*

Main category: cs.CR

TL;DR: 医疗物联网(IoMT)虽能革新医疗保健，但其网络安全威胁严重危及患者安全和数据隐私。本文提出攻击分类、漏洞分析及防护策略，为构建安全IoMT生态系统提供实用指南。


<details>
  <summary>Details</summary>
Motivation: IoMT设备广泛连接和智能特性使其面临独特网络安全挑战，可能直接危害患者生命，亟需系统性安全框架保障医疗系统安全。

Method: 通过建立IoMT攻击分类法，分析各架构层攻击面与漏洞，结合历史网络事件提出跨层级缓解策略与设计准则。

Result: 揭示了IoMT与传统IT安全的关键差异，识别出药物输送等生命攸关设备的特殊风险，并给出可落地的工程防护方案。

Conclusion: 研究填补了IoMT安全理论与实践的鸿沟，为医疗设备工程师提供符合最新合规框架的隐私保护方案，推动建设抗攻击型医疗物联网。

Abstract: The Internet of Medical Things (IoMT) has the potential to radically improve
healthcare by enabling real-time monitoring, remote diagnostics, and AI-driven
decision making. However, the connectivity, embedded intelligence, and
inclusion of a wide variety of novel sensors expose medical devices to severe
cybersecurity threats, compromising patient safety and data privacy. In
addition, many devices also have direct capacity - individually or in
conjunction with other IoMT devices - to perform actions on the patient, such
as delivering an electrical stimulus, administering a drug, or activating a
motor, which can potentially be life-threatening. We provide a taxonomy of
potential attacks targeting IoMT, presenting attack surfaces, vulnerabilities,
and mitigation strategies across all layers of the IoMT architecture. It
answers key questions such as: What makes IoMT security different from
traditional IT security? What are the cybersecurity threats to medical devices?
How can engineers design secure IoMT systems and protect hospital networks from
cyberattacks? By analyzing historical cyber incidents, we highlight critical
security gaps and propose practical security guidelines for medical device
engineers and security professionals. This work bridges the gap between
research and implementation, equipping healthcare stakeholders with actionable
insights to build resilient and privacy-preserving IoMT ecosystems. Finally, we
present the latest standardization and compliance frameworks, that IoMT
security designers should be aware of.

</details>


### [97] [Trivial Trojans: How Minimal MCP Servers Enable Cross-Tool Exfiltration of Sensitive Data](https://arxiv.org/abs/2507.19880)
*Nicola Croce,Tobin South*

Main category: cs.CR

TL;DR: 研究揭示了模型上下文协议(MCP)在AI工具集成中的安全漏洞，展示攻击者如何利用基本编程技能窃取敏感金融数据。


<details>
  <summary>Details</summary>
Motivation: MCP虽推动了AI与外部服务的无缝通信，但其信任模型存在未探索的攻击面，研究旨在揭示这些安全隐患。

Method: 通过概念验证攻击，恶意天气MCP服务器伪装正常功能，利用合法银行工具窃取用户账户余额，无需高级技术或基础设施。

Result: 发现MCP生态系统的关键安全缺陷：服务器组合会意外产生跨服务器攻击面，且攻击门槛极低，本科生Python知识即可实施。

Conclusion: 当前MCP实现允许简单的跨服务器攻击，研究提出了即时缓解措施和协议改进方案以保护这一新兴生态系统。

Abstract: The Model Context Protocol (MCP) represents a significant advancement in
AI-tool integration, enabling seamless communication between AI agents and
external services. However, this connectivity introduces novel attack vectors
that remain largely unexplored. This paper demonstrates how unsophisticated
threat actors, requiring only basic programming skills and free web tools, can
exploit MCP's trust model to exfiltrate sensitive financial data. We present a
proof-of-concept attack where a malicious weather MCP server, disguised as
benign functionality, discovers and exploits legitimate banking tools to steal
user account balances. The attack chain requires no advanced technical
knowledge, server infrastructure, or monetary investment. The findings reveal a
critical security gap in the emerging MCP ecosystem: while individual servers
may appear trustworthy, their combination creates unexpected cross-server
attack surfaces. Unlike traditional cybersecurity threats that assume
sophisticated adversaries, our research shows that the barrier to entry for
MCP-based attacks is alarmingly low. A threat actor with undergraduate-level
Python knowledge can craft convincing social engineering attacks that exploit
the implicit trust relationships MCP establishes between AI agents and tool
providers. This work contributes to the nascent field of MCP security by
demonstrating that current MCP implementations allow trivial cross-server
attacks and proposing both immediate mitigations and protocol improvements to
secure this emerging ecosystem.

</details>


### [98] [ConSeg: Contextual Backdoor Attack Against Semantic Segmentation](https://arxiv.org/abs/2507.19905)
*Bilal Hussain Abbasi,Zirui Gong,Yanjun Zhang,Shang Gao,Antonio Robles-Kelly,Leo Zhang*

Main category: cs.CR

TL;DR: 本文提出了一种针对语义分割模型的上下文后门攻击方法ConSeg，通过利用目标类的上下文信息显著提高了攻击成功率，并展现出对现有防御方法的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有语义分割模型易受后门攻击威胁，当受害类与目标类存在共现关系时，模型更易被误导。基于此观察，研究旨在开发一种利用上下文信息增强攻击效果的新型后门攻击方法。

Method: ConSeg通过模拟目标类的上下文信息并在受害区域重建该信息，建立目标类与受害类之间的上下文关联，从而降低攻击难度。该方法特别关注目标类设为受害类'共现类'时的攻击场景。

Result: 实验表明ConSeg攻击成功率(ASR)较现有方法提升15.55\%，且能有效抵抗最先进的后门防御技术。

Conclusion: 该研究证明了利用上下文信息可显著提升语义分割后门攻击效果，揭示了模型在上下文关联类间存在的安全脆弱性，对开发更鲁棒的防御方法具有启示意义。

Abstract: Despite significant advancements in computer vision, semantic segmentation
models may be susceptible to backdoor attacks. These attacks, involving hidden
triggers, aim to cause the models to misclassify instances of the victim class
as the target class when triggers are present, posing serious threats to the
reliability of these models. To further explore the field of backdoor attacks
against semantic segmentation, in this paper, we propose a simple yet effective
backdoor attack called Contextual Segmentation Backdoor Attack (ConSeg). ConSeg
leverages the contextual information inherent in semantic segmentation models
to enhance backdoor performance. Our method is motivated by an intriguing
observation, i.e., when the target class is set as the `co-occurring' class of
the victim class, the victim class can be more easily `mis-segmented'. Building
upon this insight, ConSeg mimics the contextual information of the target class
and rebuilds it in the victim region to establish the contextual relationship
between the target class and the victim class, making the attack easier. Our
experiments reveal that ConSeg achieves improvements in Attack Success Rate
(ASR) with increases of 15.55\%, compared to existing methods, while exhibiting
resilience against state-of-the-art backdoor defenses.

</details>


### [99] ["Blockchain-Enabled Zero Trust Framework for Securing FinTech Ecosystems Against Insider Threats and Cyber Attacks"](https://arxiv.org/abs/2507.19976)
*Avinash Singh,Vikas Pareek,Asish Sharma*

Main category: cs.CR

TL;DR: 本文提出了一种基于区块链的零信任框架，通过以太坊智能合约实现多因素认证、基于角色的访问控制和即时权限管理，有效增强金融科技机构的安全防护能力。


<details>
  <summary>Details</summary>
Motivation: 传统边界防御机制难以应对内部攻击、恶意软件入侵和高级持续性威胁（APT），导致金融科技机构面临重大财务损失和数据泄露风险。

Method: 利用区块链作为策略引擎（PE）和策略执行点（PEP），开发去中心化应用（DApp）原型，并通过STRIDE威胁建模进行测试，实现不可篡改的访问控制和微隔离。

Result: 与边界防御系统相比，该框架虽引入轻微延迟（74.0毫秒 vs. 49.33毫秒）并降低吞吐量（30.77 vs. 50.0请求/秒），但显著提升了安全性，消除了单点故障并支持防篡改审计追踪。

Conclusion: 该研究填补了零信任理论与区块链实践之间的空白，为金融科技机构提供了一种去中心化、高性价比的安全模型，未来可通过Layer-2解决方案进一步优化扩展性。

Abstract: Fintech provides technological services to increase operational efficiency in
financial institutions, but traditional perimeter-based defense mechanisms are
insufficient against evolving cyber threats like insider attacks, malware
intrusions, and Advanced Persistent Threats (APTs). These vulnerabilities
expose Fintech organizations to significant risks, including financial losses
and data breaches. To address these challenges, this paper proposes a
blockchain-integrated Zero Trust framework, adhering to the principle of "Never
Trust, Always Verify." The framework uses Ethereum smart contracts to enforce
Multi Factor Authentication (MFA), Role-Based Access Control (RBAC), and
Just-In-Time (JIT) access privileges, effectively mitigating credential theft
and insider threats, the effect of malware and APT attacks.
  The proposed solution transforms blockchain into a Policy Engine (PE) and
Policy Enforcement Point (PEP), and policy storage, ensuring immutable access
control and micro-segmentation. A decentralized application (DApp) prototype
was developed and tested using STRIDE threat modeling, demonstrating resilience
against spoofing, tampering, and privilege escalation. Comparative analysis
with Perimeter-based systems revealed a trade-off: while the framework
introduced a marginal latency increase (74.0 ms vs. 49.33 ms) and reduced
throughput (30.77 vs. 50.0 requests/sec), it significantly enhanced security by
eliminating single points of failure and enabling tamper-proof audit trails.
  Experimental validation on a 200-node simulated network confirmed the
framework's robustness, with future optimizations targeting Layer-2 solutions
for scalability. This work bridges the gap between Zero Trust theory and
practical blockchain implementation, offering Fintech organizations a
decentralized, cost-effective security model.

</details>


### [100] [Policy-Driven AI in Dataspaces: Taxonomy, Explainability, and Pathways for Compliant Innovation](https://arxiv.org/abs/2507.20014)
*Joydeep Chandra,Satyam Kumar Navneet*

Main category: cs.CR

TL;DR: 本文全面综述了AI数据空间中隐私保护与政策合规技术，提出了一种基于隐私级别、性能影响和合规复杂性的新分类法，并分析了关键性能指标。研究指出了当前的研究空白，并提出了未来发展方向，旨在构建可信、高效且合规的AI系统。


<details>
  <summary>Details</summary>
Motivation: 随着AI驱动的数据空间在数据共享和协作分析中的重要性日益增加，确保隐私、性能和政策合规性面临重大挑战。本文旨在解决这些挑战，为实践者和研究者提供一个清晰的框架。

Method: 本文综述了多种隐私保护与政策感知的AI技术，包括联邦学习、差分隐私、可信执行环境、同态加密和安全多方计算，并提出了一种新的分类法。同时，分析了延迟、吞吐量、成本开销、模型效用、公平性和可解释性等关键性能指标。

Result: 研究揭示了当前研究中的关键空白，如缺乏标准化的隐私性能KPI、联邦生态系统中可解释AI的挑战以及监管碎片化下的语义政策执行。并提出了一系列未来研究方向，包括政策驱动的对齐框架、自动化合规验证和标准化基准测试。

Conclusion: 通过综合技术、伦理和监管视角，本文为开发可信、高效且合规的AI系统奠定了基础，促进了安全且负责任的数据驱动生态系统的创新。

Abstract: As AI-driven dataspaces become integral to data sharing and collaborative
analytics, ensuring privacy, performance, and policy compliance presents
significant challenges. This paper provides a comprehensive review of
privacy-preserving and policy-aware AI techniques, including Federated
Learning, Differential Privacy, Trusted Execution Environments, Homomorphic
Encryption, and Secure Multi-Party Computation, alongside strategies for
aligning AI with regulatory frameworks such as GDPR and the EU AI Act. We
propose a novel taxonomy to classify these techniques based on privacy levels,
performance impacts, and compliance complexity, offering a clear framework for
practitioners and researchers to navigate trade-offs. Key performance metrics
-- latency, throughput, cost overhead, model utility, fairness, and
explainability -- are analyzed to highlight the multi-dimensional optimization
required in dataspaces. The paper identifies critical research gaps, including
the lack of standardized privacy-performance KPIs, challenges in explainable AI
for federated ecosystems, and semantic policy enforcement amidst regulatory
fragmentation. Future directions are outlined, proposing a conceptual framework
for policy-driven alignment, automated compliance validation, standardized
benchmarking, and integration with European initiatives like GAIA-X, IDS, and
Eclipse EDC. By synthesizing technical, ethical, and regulatory perspectives,
this work lays the groundwork for developing trustworthy, efficient, and
compliant AI systems in dataspaces, fostering innovation in secure and
responsible data-driven ecosystems.

</details>


### [101] [Cryptographic Data Exchange for Nuclear Warheads](https://arxiv.org/abs/2507.20074)
*Neil Perry,Daniil Zhukov*

Main category: cs.CR

TL;DR: 本文提出了一种基于密码学的核弹头追踪协议，利用承诺方案和zkSNARKs技术实现非侵入式核查，保障敏感数据机密性的同时满足条约合规要求。


<details>
  <summary>Details</summary>
Motivation: 传统核军控条约仅针对战略核运载系统，缺乏对核弹头的可验证追踪机制。需要一种不依赖物理检查、能保护机密数据的核查方案。

Method: 采用密码学"弹头护照"系统，通过承诺方案链式记录弹头全生命周期数据，结合美俄双哈希算法(SHA家族与GOST R 34.11)增强鲁棒性，利用zkSNARKs实现零知识验证。

Result: 系统实现了实时条约合规验证，具备前向安全性（防止历史数据篡改），并满足现实政治约束条件，为可审计的核弹头核查机制奠定技术基础。

Conclusion: 该密码学框架为核弹头核查提供了切实可行的解决方案，既保持数据机密性又满足军控条约验证需求，推动了非战略核武器核查机制的实践进展。

Abstract: Nuclear arms control treaties have historically focused on strategic nuclear
delivery systems, leaving nuclear warheads outside formal verification
frameworks. This paper presents a cryptographic protocol for secure and
verifiable warhead tracking, addressing challenges in nuclear warhead
verification without requiring intrusive physical inspections. Our system
leverages commitment schemes and zero-knowledge succinct non-interactive
arguments of knowledge (zkSNARKs) to ensure compliance with treaty constraints
while preserving the confidentiality of sensitive nuclear warhead data. We
propose a cryptographic "Warhead Passport" tracking system that chains
commitments to individual warheads over their life cycle, enabling periodic
challenges and real-time verification of treaty compliance. Our implementation
follows real-world treaty constraints, integrates U.S. and Russian dual-hash
combiners (SHA-family & GOST R 34.11 family) for cryptographic robustness and
political constraints, and ensures forward security by preventing retroactive
data manipulation. This work builds on policy research from prior arms control
studies and provides a practical foundation for implementing secure, auditable
NSNW verification mechanisms.

</details>


### [102] [SoK: Root Cause of \$1 Billion Loss in Smart Contract Real-World Attacks via a Systematic Literature Review of Vulnerabilities](https://arxiv.org/abs/2507.20175)
*Hadis Rezaei,Mojtaba Eshghie,Karl Anderesson,Francesco Palmieri*

Main category: cs.CR

TL;DR: 以太坊生态虽成熟但仍频遭攻击，研究揭示真实攻击根源不仅在于代码漏洞，而是由协议设计、治理、外部依赖等多层因素构成的"漏洞链"。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注智能合约代码漏洞，但无法解释实际发生的巨额资金损失，需探究更深层攻击根源。

Method: 采用双轨方法：系统综述71篇文献建立24类活跃漏洞目录；实证分析2022-2025年间造成10.9亿美元损失的50起真实攻击案例。

Result: 提出四层根源框架：1)协议逻辑设计 2)生命周期治理 3)外部依赖 4)传统代码漏洞，并通过案例验证其有效性。

Conclusion: 真实攻击多由多层设计缺陷链式触发，仅修复代码漏洞不足以防范风险，需采用更全面的安全框架。

Abstract: The Ethereum ecosystem, despite its maturity, continues to witness
catastrophic attacks, with billions of dollars in assets lost annually. In
response, a significant body of research has focused on identifying and
mitigating smart contract vulnerabilities. However, these efforts predominantly
focus on implementation-level bugs, leaving a critical gap between academic
understanding of vulnerabilities and the root causes of real-world high-impact
financial losses. We employ a two-pronged methodology: first, a systematic
literature review of 71 academic papers to build a comprehensive and up-to-date
catalog of 24 active and 5 deprecated vulnerabilities as understood by the
research community. Second, we conduct an in-depth, empirical analysis of 50 of
the most severe real-world exploits between 2022 and 2025, collectively
incurring over \$1.09B in losses, to identify their true root causes. We
introduce the concept of "exploit chains" by revealing that many incidents are
not caused by isolated vulnerabilities but by combinations of human,
operational, and economic design flaws that link with implementation bugs to
enable an attack. Our analysis yields insights on how DApps are exploited in
practice, leading to a novel, four-tier root-cause framework that moves beyond
code-level vulnerabilities. We find that real-world successful attacks on
Ethereum (and related networks) trace back to one of the four tiers of (1)
protocol logic design, (2) lifecycle and governance, (3) external dependencies,
and (4) traditional implementation bugs (classic smart contract
vulnerabilities). We investigate the suitability of this multi-tier incident
root-cause framework via a case study.

</details>


### [103] [Measuring and Explaining the Effects of Android App Transformations in Online Malware Detection](https://arxiv.org/abs/2507.20361)
*Guozhu Meng,Zhixiu Guo,Xiaodong Zhang,Haoyu Wang,Kai Chen,Yang Liu*

Main category: cs.CR

TL;DR: 本研究通过数据驱动方法评估安卓应用变换对恶意软件检测的影响，揭示了杀毒引擎的内部工作机制及检测指标。


<details>
  <summary>Details</summary>
Motivation: 已知杀毒引擎易受混淆等规避技术影响，但结果不佳未必源于规避技术本身，可能与引擎局限性有关。研究旨在量化应用变换对检测的影响并解释检测结果的成因。

Method: 构建杀毒引擎交互模型，实现6种应用变换技术生成可追踪变化的安卓应用，通过VirusTotal对17.9万应用进行为期一个月的追踪，获取97.1万份检测报告，并从签名、静态和动态分析角度全面分析引擎行为。

Result: 分析报告得出7项关键发现，揭示了杀毒引擎内部密封工作机制及恶意软件检测中的妥协指标。

Conclusion: 研究通过大规模实证分析，阐明了杀毒引擎在应对应用变换时的响应机制，为理解检测结果提供了数据支撑。

Abstract: It is well known that antivirus engines are vulnerable to evasion techniques
(e.g., obfuscation) that transform malware into its variants. However, it
cannot be necessarily attributed to the effectiveness of these evasions, and
the limits of engines may also make this unsatisfactory result. In this study,
we propose a data-driven approach to measure the effect of app transformations
to malware detection, and further explain why the detection result is produced
by these engines. First, we develop an interaction model for antivirus engines,
illustrating how they respond with different detection results in terms of
varying inputs. Six app transformation techniques are implemented in order to
generate a large number of Android apps with traceable changes. Then we
undertake a one-month tracking of app detection results from multiple antivirus
engines, through which we obtain over 971K detection reports from VirusTotal
for 179K apps in total. Last, we conduct a comprehensive analysis of antivirus
engines based on these reports from the perspectives of signature-based, static
analysis-based, and dynamic analysis-based detection techniques. The results,
together with 7 highlighted findings, identify a number of sealed working
mechanisms occurring inside antivirus engines and what are the indicators of
compromise in apps during malware detection.

</details>


### [104] [Is Crunching Public Data the Right Approach to Detect BGP Hijacks?](https://arxiv.org/abs/2507.20434)
*Alessandro Giaconia,Muoi Tran,Laurent Vanbever,Stefano Vissicchio*

Main category: cs.CR

TL;DR: 研究揭示了现有BGP劫持检测系统（如DFOH和BEAM）易受数据投毒攻击的漏洞，攻击者仅需少量伪造路由公告即可误导机器学习防御机制。


<details>
  <summary>Details</summary>
Motivation: 尽管路由起源验证（ROV）逐步普及，但攻击者已转向伪造起源劫持等新型攻击。现有基于机器学习的检测系统依赖公开BGP数据，但未考虑监控节点本身可能被误导的风险。

Method: 通过大规模BGP模拟实验，证明攻击者可在实际劫持外发送少量精心构造的路由公告，污染机器学习系统依赖的知识库和指标。

Result: 实验表明，即使少量恶意公告也足以扭曲DFOH和BEAM等系统的检测结果，使其无法识别真实劫持。

Conclusion: 仅依赖公开BGP数据的检测系统存在根本性弱点，需重新评估其安全假设以应对数据投毒威胁。

Abstract: The Border Gateway Protocol (BGP) remains a fragile pillar of Internet
routing. BGP hijacks still occurr daily. While full deployment of Route Origin
Validation (ROV) is ongoing, attackers have already adapted, launching post-ROV
attacks such as forged-origin hijacks. To detect these, recent approaches like
DFOH [Holterbach et al., USENIX NSDI '24] and BEAM [Chen et al., USENIX
Security '24] apply machine learning (ML) to analyze data from globally
distributed BGP monitors, assuming anomalies will stand out against historical
patterns. However, this assumption overlooks a key threat: BGP monitors
themselves can be misled by adversaries injecting bogus routes. This paper
shows that state-of-the-art hijack detection systems like DFOH and BEAM are
vulnerable to data poisoning. Using large-scale BGP simulations, we show that
attackers can evade detection with just a handful of crafted announcements
beyond the actual hijack. These announcements are indeed sufficient to corrupt
the knowledge base used by ML-based defenses and distort the metrics they rely
on. Our results highlight a worrying weakness of relying solely on public BGP
data.

</details>


### [105] [MPC-EVM: Enabling MPC Execution by Smart Contracts In An Asynchronous Manner](https://arxiv.org/abs/2507.20554)
*Yichen Zhou,Chenxing Li,Fan Long*

Main category: cs.CR

TL;DR: MPC-EVM是首个支持智能合约在交易执行中异步调用多方计算(MPC)的区块链原型，通过非阻塞式异步执行模型和访问控制机制，在保持吞吐量和一致性的前提下实现了MPC功能。


<details>
  <summary>Details</summary>
Motivation: 现有EVM无法在智能合约执行期间异步调用MPC计算，MPC-EVM旨在解决这一限制，同时保持区块链的吞吐量和状态一致性。

Method: 采用异步执行模型处理MPC调用交易：保存交易进度直至MPC完成；引入访问控制机制防止异步执行导致的状态不一致访问或修改。

Result: 基准测试显示，在MPC调用交易与常规交易并行执行时，系统吞吐量(TPS)仅下降不到3%。

Conclusion: MPC-EVM成功实现了交易执行期间的异步MPC调用，为区块链智能合约拓展了隐私计算能力，且性能损耗极小。

Abstract: This paper presents MPC-EVM, the first blockchain prototype that extends the
EVM to enable asynchronous MPC invocations by smart contracts during
transaction executions without compromising consistency or throughput. MPC-EVM
uses an asynchronous execution model to process MPC-invoking transactions in a
non-blocking fashion, saving the transaction's progress when it enters an MPC
and resuming its execution upon MPC's completion. Additionally, it employs an
access control mechanism that prevents inconsistent state access and
modifications as a result of asynchronous executions. Benchmarking MPC-EVM's
throughput show that the transactions per second (TPS) decreased by less than
3% compared to the baseline when MPC-invoking transactions are executed
alongside regular transactions.

</details>


### [106] [Hot-Swap MarkBoard: An Efficient Black-box Watermarking Approach for Large-scale Model Distribution](https://arxiv.org/abs/2507.20650)
*Zhicheng Zhang,Peizhuo Lv,Mengke Wan,Jiang Fang,Diandian Guo,Yezeng Chen,Yinlong Liu,Wei Ma,Jiyan Sun,Liru Geng*

Main category: cs.CR

TL;DR: 本文提出Hot-Swap MarkBoard方法，通过多分支LoRA模块嵌入动态水印，解决端侧AI模型知识产权保护难题，支持黑盒验证且无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型部署到终端设备（端侧AI），模型面临更严重的知识产权盗窃风险。现有水印方案（如基于后门的方案）专为云端AI服务设计，无法适应大规模分发场景下用户专属水印的需求。

Method: 提出Hot-Swap MarkBoard方法：1) 在多分支低秩适配（LoRA）模块中独立嵌入多个水印，通过分支交换实现水印动态定制；2) 参数混淆机制将水印权重与基模型权重纠缠，防止移除水印而不损害性能；3) 支持黑盒验证，兼容分类、图像生成、文本生成等任务。

Result: 在3类任务、6种骨干模型上的实验表明，该方法水印定制效率显著优于现有方案，验证准确率达100%，且不影响模型性能。

Conclusion: Hot-Swap MarkBoard为端侧AI模型提供了高效、可定制的水印方案，解决了大规模分发场景下的知识产权保护问题，具有架构无关性和任务普适性。

Abstract: Recently, Deep Learning (DL) models have been increasingly deployed on
end-user devices as On-Device AI, offering improved efficiency and privacy.
However, this deployment trend poses more serious Intellectual Property (IP)
risks, as models are distributed on numerous local devices, making them
vulnerable to theft and redistribution. Most existing ownership protection
solutions (e.g., backdoor-based watermarking) are designed for cloud-based
AI-as-a-Service (AIaaS) and are not directly applicable to large-scale
distribution scenarios, where each user-specific model instance must carry a
unique watermark. These methods typically embed a fixed watermark, and
modifying the embedded watermark requires retraining the model. To address
these challenges, we propose Hot-Swap MarkBoard, an efficient watermarking
method. It encodes user-specific $n$-bit binary signatures by independently
embedding multiple watermarks into a multi-branch Low-Rank Adaptation (LoRA)
module, enabling efficient watermark customization without retraining through
branch swapping. A parameter obfuscation mechanism further entangles the
watermark weights with those of the base model, preventing removal without
degrading model performance. The method supports black-box verification and is
compatible with various model architectures and DL tasks, including
classification, image generation, and text generation. Extensive experiments
across three types of tasks and six backbone models demonstrate our method's
superior efficiency and adaptability compared to existing approaches, achieving
100\% verification accuracy.

</details>


### [107] [Program Analysis for High-Value Smart Contract Vulnerabilities: Techniques and Insights](https://arxiv.org/abs/2507.20672)
*Yannis Smaragdakis,Neville Grech,Sifis Lagouvardos,Konstantinos Triantafyllou,Ilias Tsatiris,Yannis Bollanos,Tony Rocco Valentine*

Main category: cs.CR

TL;DR: 本文挑战了区块链安全领域的普遍认知，通过结合高完整性静态分析与统计推断的领域知识，成功实现了高价值智能合约漏洞的自动化检测，累计获得超300万美元的漏洞赏金。


<details>
  <summary>Details</summary>
Motivation: 反驳"自动化技术仅能检测低价值漏洞"的行业偏见，证明通过创新方法可系统性地发现高价值智能合约漏洞。

Method: 采用高完整性的静态分析方法（保持合理精度），结合专家知识或通过大规模已部署合约的统计分析自动推断领域知识。特别提出：实用化检测器应具备极低触发率（<1%）且允许高误报率（95%）。

Result: 实际成果包括：10次高额漏洞披露（总赏金超300万美元），以及数百个预部署/审计中合约的漏洞发现。统计推断技术成功从合约代码库中自动提取关键领域知识。

Conclusion: 高误报率（95%）下的极低触发率（1%）检测策略，配合统计学习的领域知识增强，可有效捕捉现实世界中的高价值漏洞，其效果远超学术论文常见的50%误报率标准。

Abstract: A widespread belief in the blockchain security community is that automated
techniques are only good for detecting shallow bugs, typically of small value.
In this paper, we present the techniques and insights that have led us to
repeatable success in automatically discovering high-value smart contract
vulnerabilities. Our vulnerability disclosures have yielded 10 bug bounties,
for a total of over $3M, over high-profile deployed code, as well as hundreds
of bugs detected in pre-deployment or under-audit code.
  We argue that the elements of this surprising success are a) a very
high-completeness static analysis approach that manages to maintain acceptable
precision; b) domain knowledge, provided by experts or captured via statistical
inference. We present novel techniques for automatically inferring domain
knowledge from statistical analysis of a large corpus of deployed contracts, as
well as discuss insights on the ideal precision and warning rate of a promising
vulnerability detector. In contrast to academic literature in program analysis,
which routinely expects false-positive rates below 50% for publishable results,
we posit that a useful analysis for high-value real-world vulnerabilities will
likely flag very few programs (under 1%) and will do so with a high
false-positive rate (e.g., 95%, meaning that only one-of-twenty human
inspections will yield an exploitable vulnerability).

</details>


### [108] [A Novel Post-Quantum Secure Digital Signature Scheme Based on Neural Network](https://arxiv.org/abs/2507.20676)
*Satish Kumar,Md. Arzoo Jamal*

Main category: cs.CR

TL;DR: 本文提出了一种基于神经网络架构的多变量多项式数字签名方案，旨在抵御量子计算威胁，并通过实验验证了其安全性和实用性。


<details>
  <summary>Details</summary>
Motivation: 在量子计算时代，传统公钥签名方案易受攻击，而多变量多项式签名方案因其抗量子特性备受关注。神经网络能捕捉数据非线性关系，为密码学设计提供新思路。

Method: 方案采用二值权重神经网络定义签名核心结构，引入类似注意力机制的递归随机向量以增强动态随机性，确保私钥恢复攻击在多项式时间内不可行。

Result: 该方案在适应性选择消息攻击下具有存在不可伪造性（EUF-CMA），且量子计算环境下仍保持计算不可行性，实际评估显示其在后量子密码应用中高效可行。

Conclusion: 结合神经网络的多变量多项式签名方案为后量子密码学提供了安全高效的解决方案，其动态随机性设计显著提升了抗攻击能力。

Abstract: Digital signatures are fundamental cryptographic primitives that ensure the
authenticity and integrity of digital documents. In the post-quantum era,
classical public key-based signature schemes become vulnerable to brute-force
and key-recovery attacks due to the computational power of quantum algorithms.
Multivariate polynomial based signature schemes are among the one of the
cryptographic constructions that offers strong security guarantees against such
quantum threats. With the growing capabilities of neural networks, it is
natural to explore their potential application in the design of cryptographic
primitives. Neural networks inherently captures the non-linear relationships
within the data, which are encoded in their synaptic weight matrices and bias
vectors. In this paper, we propose a novel construction of a multivariate
polynomial based digital signature scheme that leverages neural network
architectures. A neural network with binary weights is employed to define the
central structure of the signature scheme. The design introduces a recurrent
random vector, functionally analogous to an attention mechanism, which
contributes dynamic randomness based on the previous state, thereby enhancing
the scheme's security. It is demonstrated that the proposed signature scheme
provide security against Existential Unforgeability under adaptive
Chosen-Message Attacks (EUF-CMA). Furthermore, it is proven that direct attacks
aimed to recover the private keys are computationally infeasible within
polynomial time, even in the presence of quantum computing abilities. The
operational characteristics of the proposed scheme are also evaluated, with
results indicating notable efficiency and practical viability in post-quantum
cryptographic applications.

</details>


### [109] [Guard-GBDT: Efficient Privacy-Preserving Approximated GBDT Training on Vertical Dataset](https://arxiv.org/abs/2507.20688)
*Anxiao Song,Shujie Cui,Jianli Bai,Ke Cheng,Yulong Shen,Giovanni Russello*

Main category: cs.CR

TL;DR: Guard-GBDT是一种高效且保护隐私的GBDT训练框架，通过简化近似计算和压缩通信消息，显著提升了多数据所有者协作训练的效率。


<details>
  <summary>Details</summary>
Motivation: 随着隐私问题和法律监管的日益严格，基于安全多方计算(MPC)的GBDT协作训练受到关注，但现有方法因高通信成本和非线性操作的计算负担而效率低下。

Method: Guard-GBDT通过使用更高效的近似方法绕过MPC不友好的除法和sigmoid函数，并通过压缩梯度聚合过程中的通信消息来降低通信开销。

Result: 实验表明，Guard-GBDT在LAN和WAN网络上的性能分别比HEP-XGB和SiGBDT提升高达$2.71\times$和$12.21\times$，且准确性与SiGBDT和明文XGBoost相当，偏差仅为$\pm1\%$至$\pm2\%$。

Conclusion: Guard-GBDT在保持高准确性的同时，显著提升了隐私保护GBDT训练的效率，为多数据所有者协作提供了实用解决方案。

Abstract: In light of increasing privacy concerns and stringent legal regulations,
using secure multiparty computation (MPC) to enable collaborative GBDT model
training among multiple data owners has garnered significant attention. Despite
this, existing MPC-based GBDT frameworks face efficiency challenges due to high
communication costs and the computation burden of non-linear operations, such
as division and sigmoid calculations. In this work, we introduce Guard-GBDT, an
innovative framework tailored for efficient and privacy-preserving GBDT
training on vertical datasets. Guard-GBDT bypasses MPC-unfriendly division and
sigmoid functions by using more streamlined approximations and reduces
communication overhead by compressing the messages exchanged during gradient
aggregation. We implement a prototype of Guard-GBDT and extensively evaluate
its performance and accuracy on various real-world datasets. The results show
that Guard-GBDT outperforms state-of-the-art HEP-XGB (CIKM'21) and SiGBDT (ASIA
CCS'24) by up to $2.71\times$ and $12.21 \times$ on LAN network and up to
$2.7\times$ and $8.2\times$ on WAN network. Guard-GBDT also achieves comparable
accuracy with SiGBDT and plaintext XGBoost (better than HEP-XGB ), which
exhibits a deviation of $\pm1\%$ to $\pm2\%$ only. Our implementation code is
provided at https://github.com/XidianNSS/Guard-GBDT.git.

</details>


### [110] [An Open-source Implementation and Security Analysis of Triad's TEE Trusted Time Protocol](https://arxiv.org/abs/2507.20851)
*Matthieu Bettinger,Sonia Ben Mokhtar,Anthony Simonet-Boulogne*

Main category: cs.CR

TL;DR: 本文揭示了Triad协议在可信执行环境（TEE）中的时间信任漏洞，攻击者可通过操纵时钟速度影响整个网络，并提出了增强协议韧性的改进方案。


<details>
  <summary>Details</summary>
Motivation: TEE（如Intel SGX）依赖外部时间源，恶意系统可操纵时间导致安全风险。现有Triad协议虽提供可信时间源，但存在未经验证的漏洞。

Method: 基于公开的Triad实现进行实证分析，展示攻击者通过操作系统控制权操纵本地TEE时钟速度，并传播时间跳跃至诚实节点的攻击路径。

Result: 实验证明单点恶意时钟加速可导致全网诚实节点时间戳跳跃至未来任意时刻，形成级联传播效应。

Conclusion: 需修改Triad协议以抵御时钟操纵攻击，提升分布式可信时间协议的韧性。

Abstract: The logic of many protocols relies on time measurements. However, in Trusted
Execution Environments (TEEs) like Intel SGX, the time source is outside the
Trusted Computing Base: a malicious system hosting the TEE can manipulate that
TEE's notion of time, e.g., jumping in time or affecting the perceived time
speed. Previous work like Triad propose protocols for TEEs to maintain a
trustworthy time source. However, in this paper, based on a public
implementation of Triad that we contribute, we empirically showcase
vulnerabilities to this protocol. For example, an attacker controlling the
operating system, and consequently the scheduling algorithm, may arbitrarily
manipulate their local TEE's clock speed. What is worse, in case of faster
malicious clock speeds, an attacker on a single compromised machine may
propagate the attack to honest machines participating in Triad's Trusted Time
protocol, causing them to skip to timestamps arbitrarily far in the future.
Then, infected honest machines propagate time-skips themselves to other honest
machines interacting with them. We discuss protocol changes to Triad for higher
resilience against such attacks.

</details>


### [111] [Testbed and Software Architecture for Enhancing Security in Industrial Private 5G Networks](https://arxiv.org/abs/2507.20873)
*Song Son Ha,Florian Foerster,Thomas Robert Doebbert,Tim Kittel,Dominik Merli,Gerd Scholl*

Main category: cs.CR

TL;DR: 本文提出了一种增强工业5G专用网络安全性的测试平台与软件架构。


<details>
  <summary>Details</summary>
Motivation: 工业4.0时代对5G网络的安全高效通信需求激增，但现有网络面临严峻的网络安全挑战。

Method: 开发了针对工业通信环境的专用5G网络安全测试平台及配套软件架构。

Result: 所提出的解决方案能有效应对5G网络中的复杂网络威胁。

Conclusion: 该研究为工业5G专用网络提供了先进的安全防护框架，具有重要应用价值。

Abstract: In the era of Industry 4.0, the growing need for secure and efficient
communication systems has driven the development of fifth-generation (5G)
networks characterized by extremely low latency, massive device connectivity
and high data transfer speeds. However, the deployment of 5G networks presents
significant security challenges, requiring advanced and robust solutions to
counter increasingly sophisticated cyber threats. This paper proposes a testbed
and software architecture to strengthen the security of Private 5G Networks,
particularly in industrial communication environments.

</details>


### [112] [Characterizing the Sensitivity to Individual Bit Flips in Client-Side Operations of the CKKS Scheme](https://arxiv.org/abs/2507.20891)
*Matias Mazzanti,Augusto Vega,Esteban Mocskos*

Main category: cs.CR

TL;DR: 同态加密（HE）在隐私保护计算中至关重要，但软错误（如位翻转）对现代HE方案（如CKKS）的影响尚未充分研究。本文通过理论和实证分析，揭示了CKKS在单一位翻转错误下的容错性，发现性能优化（如RNS/NTT）会显著增加其脆弱性。


<details>
  <summary>Details</summary>
Motivation: 同态加密在敏感应用（如安全机器学习和机密数据分析）中的广泛采用，使其对错误的鲁棒性变得至关重要。然而，软错误对现代HE方案（特别是CKKS）的影响尚未得到系统研究，尤其是在RNS和NTT等优化下的错误传播机制。

Method: 本文通过理论和实证分析，研究了CKKS方案在单一位翻转错误下的容错性。研究聚焦于客户端操作（编码、加密、解密和解码），并比较了原始CKKS方案与经过RNS/NTT优化后的表现。

Result: 研究发现，原始CKKS方案具有一定容错性，但性能优化（如RNS/NTT）会显著增加其对错误的敏感性，放大错误传播的影响。这些优化虽然提升了性能，却引入了新的脆弱性。

Conclusion: 本文填补了CKKS方案在软错误容错性研究上的空白，揭示了性能优化与错误敏感性之间的权衡。研究结果为设计兼具高性能和完整性的容错HE方案奠定了基础，对隐私关键应用具有重要意义。

Abstract: Homomorphic Encryption (HE) enables computation on encrypted data without
decryption, making it a cornerstone of privacy-preserving computation in
untrusted environments. As HE sees growing adoption in sensitive applications
such as secure machine learning and confidential data analysis ensuring its
robustness against errors becomes critical. Faults (e.g., transmission errors,
hardware malfunctions, or synchronization failures) can corrupt encrypted data
and compromise the integrity of HE operations. However, the impact of soft
errors (such as bit flips) on modern HE schemes remains unexplored.
Specifically, the CKKS scheme-one of the most widely used HE schemes for
approximate arithmetic-lacks a systematic study of how such errors propagate
across its pipeline, particularly under optimizations like the Residue Number
System (RNS) and Number Theoretic Transform (NTT). This work bridges that gap
by presenting a theoretical and empirical analysis of CKKS's fault tolerance
under single bit-flip errors. We focus on client-side operations (encoding,
encryption, decryption, and decoding) and demonstrate that while the vanilla
CKKS scheme exhibits some resilience, performance optimizations (RNS/NTT)
introduce significant fragility, amplifying error sensitivity. By
characterizing these failure modes, we lay the groundwork for error-resilient
HE designs, ensuring both performance and integrity in privacy-critical
applications.

</details>


### [113] [Development and analysis of a secured VoIP system for surveillance activities](https://arxiv.org/abs/2507.21038)
*M. Matsive Ali*

Main category: cs.CR

TL;DR: 本文设计了一种基于加密数据传输的VoIP系统，利用嵌入式技术和物联网实现安全通信，适用于多种场景。


<details>
  <summary>Details</summary>
Motivation: 自20世纪90年代以来，电话一直是主要通信方式，但VoIP因其简单和经济性日益普及。然而，中间人攻击等网络安全威胁对数据传输构成严重风险，因此需要开发安全的VoIP系统。

Method: 作者开发了一个嵌入式系统，包含驻极体麦克风、嵌入式C、Node.js、Particle Photon微控制器和物联网技术。系统通过MAX9814麦克风采集声音信号，利用Particle Photon微控制器加密传输数据，并通过TCP服务器供授权设备下载。数据可本地存储并上传至Google Drive。

Result: 该系统成功实现了通过加密数据传输的VoIP通信，保持了原始信号的完整性，并因其紧凑尺寸可集成到汽车、监控系统或隐蔽监听设备中。

Conclusion: 该VoIP系统提供了一种安全的通信方法，有效应对了网络攻击风险，同时保留了原始信号的质量，具有广泛的应用潜力。

Abstract: Since the 1990s, the telephone has been the primary mode of communication.
However, Voice over Internet Protocol (VoIP), which is a highly straightforward
and affordable form of data transfer, is now becoming an important part of
daily communication. VoIP is the technology that makes it possible to send
speech and multimedia data packets across either a public or private IP
network. However, a cyberattack known as a man-in-the-middle attack poses a
serious concern in transferring data through any network. Therefore, the
authors have designed a system that sends voice over the internet within the
range of a router using encrypted data transfer. An embedded system comprising
an electret microphone, Embedded C, Node.js, Particle Photon microcontroller,
and Internet of Things (IoT) technology is developed. Due to its compact size,
this type of device may be incorporated into automobiles, surveillance systems,
or covert listening tools. The VoIP system gathers sound signals using the
MAX9814 microphone, while the Particle Photon microcontroller securely
transmits the data. Devices with access can download data from the VoIP systems
Transmission Control Protocol (TCP) server. The accessed device stores the
audio locally and uploads the corresponding data to Google Drive. This VoIP
system provides a secure method of communication while conserving the integrity
of the original signal.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [114] [MAIA: A Collaborative Medical AI Platform for Integrated Healthcare Innovation](https://arxiv.org/abs/2507.19489)
*Simone Bendazzoli,Sanna Persson,Mehdi Astaraki,Sebastian Pettersson,Vitali Grozman,Rodrigo Moreno*

Main category: cs.AI

TL;DR: 本文介绍了MAIA（医疗人工智能助手），一个开源平台，旨在促进临床医生、研究人员和AI开发者之间的跨学科合作，加速AI研究向临床应用的转化。


<details>
  <summary>Details</summary>
Motivation: 人工智能在临床工作流程中的集成需要强大的协作平台，以弥合技术创新与实际医疗应用之间的差距。

Method: MAIA基于Kubernete构建，提供模块化、可扩展的环境，集成了数据管理、模型开发、标注、部署和临床反馈工具，支持项目隔离、CI/CD自动化以及与高性能计算基础设施和临床工作流程的集成。

Result: MAIA在医学影像AI中支持实际用例，已在学术和临床环境中部署，展示了其在促进协作和互操作性方面的潜力。

Conclusion: MAIA通过促进协作和互操作性，旨在加速AI研究转化为有影响力的临床解决方案，同时提升可重复性、透明度和以用户为中心的设计。

Abstract: The integration of Artificial Intelligence (AI) into clinical workflows
requires robust collaborative platforms that are able to bridge the gap between
technical innovation and practical healthcare applications. This paper
introduces MAIA (Medical Artificial Intelligence Assistant), an open-source
platform designed to facilitate interdisciplinary collaboration among
clinicians, researchers, and AI developers. Built on Kubernetes, MAIA offers a
modular, scalable environment with integrated tools for data management, model
development, annotation, deployment, and clinical feedback. Key features
include project isolation, CI/CD automation, integration with high-computing
infrastructures and in clinical workflows. MAIA supports real-world use cases
in medical imaging AI, with deployments in both academic and clinical
environments. By promoting collaborations and interoperability, MAIA aims to
accelerate the translation of AI research into impactful clinical solutions
while promoting reproducibility, transparency, and user-centered design. We
showcase the use of MAIA with different projects, both at KTH Royal Institute
of Technology and Karolinska University Hospital.

</details>


### [115] [Agent WARPP: Workflow Adherence via Runtime Parallel Personalization](https://arxiv.org/abs/2507.19543)
*Maria Emilia Mazzolenis,Ruirui Zhang*

Main category: cs.AI

TL;DR: 本文提出WARPP框架，通过运行时并行个性化提升大语言模型在任务导向对话系统中的工作流遵循能力，无需额外训练即可显著提高参数保真度和工具准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型(LLM)在涉及外部工具调用和用户特定信息的复杂条件工作流中表现不佳，需要一种能动态适应用户属性的解决方案。

Method: WARPP采用免训练模块化框架，结合多智能体编排与运行时个性化，通过专用个性化智能体实时剪枝条件分支并优化工具选择。

Result: 在银行、航班和医疗三个领域的五项用户意图测试中，WARPP在参数保真度、工具准确性和令牌使用效率上均优于非个性化方法和ReAct基线。

Conclusion: 该研究表明运行时并行个性化架构能有效提升LLM在复杂工作流中的表现，且优势随任务复杂度增加而扩大，具有实际应用价值。

Abstract: Large language models (LLMs) are increasingly applied in task-oriented
dialogue (TOD) systems but often struggle with long, conditional workflows that
involve external tool calls and depend on user-specific information. We present
Workflow Adherence via Runtime Parallel Personalization, or WARPP, a
training-free, modular framework that combines multi-agent orchestration with
runtime personalization to improve workflow adherence in LLM-based systems. By
dynamically pruning conditional branches based on user attributes, the
framework reduces reasoning overhead and narrows tool selection at runtime.
WARPP deploys a parallelized architecture where a dedicated Personalizer agent
operates alongside modular, domain-specific agents to dynamically tailor
execution paths in real time. The framework is evaluated across five
representative user intents of varying complexity within three domains:
banking, flights, and healthcare. Our evaluation leverages synthetic datasets
and LLM-powered simulated users to test scenarios with conditional
dependencies. Our results demonstrate that WARPP outperforms both the
non-personalized method and the ReAct baseline, achieving increasingly larger
gains in parameter fidelity and tool accuracy as intent complexity grows, while
also reducing average token usage, without any additional training.

</details>


### [116] [Hypergames: Modeling Misaligned Perceptions and Nested Beliefs for Multi-agent Systems](https://arxiv.org/abs/2507.19593)
*Vince Trencsenyi,Agnieszka Mensfelt,Kostas Stathis*

Main category: cs.AI

TL;DR: 本文系统综述了超博弈理论在动态多智能体系统中的应用，分析了44项研究，提出了智能体兼容性标准，并指出了当前研究的结构缺陷与未来方向。


<details>
  <summary>Details</summary>
Motivation: 经典博弈论假设理性、完全信息和共同知识，而现实多智能体系统常存在不确定性和认知差异。超博弈理论通过建模智能体的主观感知（即感知博弈）来弥补这些不足。

Method: 通过形式化引入超博弈理论及其两大扩展（分层超博弈和HNF），建立智能体兼容性标准和基于智能体的分类框架，评估44项研究的整合模式与实际适用性。

Result: 分析发现分层和图模型在欺骗性推理中占主导，实际应用简化了理论框架；存在HNF模型采用不足、缺乏形式化超博弈语言及人-智能体对齐研究空白等问题。

Conclusion: 综述为超博弈理论在动态多智能体环境中的战略建模提供了新路线图，以增强模型的现实性和有效性。

Abstract: Classical game-theoretic models typically assume rational agents, complete
information, and common knowledge of payoffs - assumptions that are often
violated in real-world MAS characterized by uncertainty, misaligned
perceptions, and nested beliefs. To overcome these limitations, researchers
have proposed extensions that incorporate models of cognitive constraints,
subjective beliefs, and heterogeneous reasoning. Among these, hypergame theory
extends the classical paradigm by explicitly modeling agents' subjective
perceptions of the strategic scenario, known as perceptual games, in which
agents may hold divergent beliefs about the structure, payoffs, or available
actions. We present a systematic review of agent-compatible applications of
hypergame theory, examining how its descriptive capabilities have been adapted
to dynamic and interactive MAS contexts. We analyze 44 selected studies from
cybersecurity, robotics, social simulation, communications, and general
game-theoretic modeling. Building on a formal introduction to hypergame theory
and its two major extensions - hierarchical hypergames and HNF - we develop
agent-compatibility criteria and an agent-based classification framework to
assess integration patterns and practical applicability. Our analysis reveals
prevailing tendencies, including the prevalence of hierarchical and graph-based
models in deceptive reasoning and the simplification of extensive theoretical
frameworks in practical applications. We identify structural gaps, including
the limited adoption of HNF-based models, the lack of formal hypergame
languages, and unexplored opportunities for modeling human-agent and
agent-agent misalignment. By synthesizing trends, challenges, and open research
directions, this review provides a new roadmap for applying hypergame theory to
enhance the realism and effectiveness of strategic modeling in dynamic
multi-agent environments.

</details>


### [117] [DeltaLLM: A Training-Free Framework Exploiting Temporal Sparsity for Efficient Edge LLM Inference](https://arxiv.org/abs/2507.19608)
*Jiawen Qi,Chang Gao,Zhaochun Ren,Qinyu Chen*

Main category: cs.AI

TL;DR: DeltaLLM是一种无需训练的边缘设备高效LLM推理框架，通过时间稀疏性和混合注意力机制，在BitNet和Llama模型上实现60%注意力稀疏性且保持精度。


<details>
  <summary>Details</summary>
Motivation: 现有动态注意力剪枝方法针对GPU/TPU设计且需要长上下文，不适用于计算资源受限的边缘设备部署。

Method: 提出时间稀疏的delta矩阵构建策略和局部全注意力+外部delta近似的混合机制，兼容现有推理流程且无需微调。

Result: 在BitNet上预填充阶段稀疏度达60%（WG任务精度微升），解码阶段达57%（SQuAD-v2任务F1从29.63→30.97）；Llama模型同样实现60%/57%稀疏且精度损失可忽略。

Conclusion: DeltaLLM为边缘部署提供零调优、高稀疏的解决方案，显著提升计算效率并保持模型性能。

Abstract: Deploying Large Language Models (LLMs) on edge devices remains challenging
due to their quadratically increasing computations with the sequence length.
Existing studies for dynamic attention pruning are designed for hardware with
massively parallel computation capabilities, such as GPUs or TPUs, and aim at
long context lengths (e.g., 64K), making them unsuitable for edge scenarios. We
present DeltaLLM, a training-free framework that exploits temporal sparsity in
attention patterns to enable efficient LLM inference across both the prefilling
and decoding stages, on resource-constrained edge devices. DeltaLLM introduces
an accuracy- and memory-aware delta matrix construction strategy that
introduces temporal sparsity, and a context-aware hybrid attention mechanism
that combines full attention in a local context window with delta approximation
outside it to increase accuracy. We evaluate our framework on the
edge-device-friendly BitNet-b1.58-2B-4T model and Llama3.2-1B-Instruct model
across diverse language tasks. The results show that on BitNet, our framework
increases the attention sparsity from 0% to 60% during the prefilling stage
with slight accuracy improvement on the WG task, and 0% to 57% across both the
prefilling and decoding stages, with even higher F1 score from 29.63 to 30.97
on SQuAD-v2 task. On the Llama model, it can also achieve up to 60% sparsity
during the prefilling stage and around 57% across both stages with negligible
accuracy drop. These results demonstrate that DeltaLLM offers a promising
solution for efficient edge deployment, requiring no fine-tuning and seamlessly
integrating with existing inference pipelines.

</details>


### [118] [Alignment and Safety in Large Language Models: Safety Mechanisms, Training Paradigms, and Emerging Challenges](https://arxiv.org/abs/2507.19672)
*Haoran Lu,Luyang Fang,Ruidong Zhang,Xinliang Li,Jiazhang Cai,Huimin Cheng,Lin Tang,Ziyu Liu,Zeliang Sun,Tao Wang,Yingchuan Zhang,Arif Hassan Zidan,Jinwen Xu,Jincheng Yu,Meizhi Yu,Hanqi Jiang,Xilin Gong,Weidi Luo,Bolun Sun,Yongkai Chen,Terry Ma,Shushan Wu,Yifan Zhou,Junhao Chen,Haotian Xiang,Jing Zhang,Afrar Jahin,Wei Ruan,Ke Deng,Yi Pan,Peilong Wang,Jiahui Li,Zhengliang Liu,Lu Zhang,Lin Zhao,Wei Liu,Dajiang Zhu,Xin Xing,Fei Dou,Wei Zhang,Chao Huang,Rongjie Liu,Mengrui Zhang,Yiwen Liu,Xiaoxiao Sun,Qin Lu,Zhen Xiang,Wenxuan Zhong,Tianming Liu,Ping Ma*

Main category: cs.AI

TL;DR: 本文综述了大语言模型（LLMs）与人类价值观对齐的实用技术、训练协议及实证发现，分析了不同范式下的对齐方法发展，并探讨了当前最佳技术与开放性问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能力的显著提升及其对社会各领域的深入影响，确保其与人类价值观和意图的对齐已成为关键挑战。

Method: 综述分析了监督微调、基于偏好的方法（如DPO）、宪法AI、脑启发方法及对齐不确定性量化（AUQ）等多种对齐技术，并评估了现有框架与数据集的局限性。

Result: 研究表明，监督微调可实现基本指令跟随，而基于偏好的方法能更灵活地对齐复杂人类意图；同时揭示了奖励误设、分布鲁棒性及可扩展监督等现存问题。

Conclusion: 文章总结了领先AI实验室的实践策略，并提出了监督、价值多元性、鲁棒性及持续对齐等开放性问题，旨在为研究者与实践者提供参考。

Abstract: Due to the remarkable capabilities and growing impact of large language
models (LLMs), they have been deeply integrated into many aspects of society.
Thus, ensuring their alignment with human values and intentions has emerged as
a critical challenge. This survey provides a comprehensive overview of
practical alignment techniques, training protocols, and empirical findings in
LLM alignment. We analyze the development of alignment methods across diverse
paradigms, characterizing the fundamental trade-offs between core alignment
objectives. Our analysis shows that while supervised fine-tuning enables basic
instruction-following, preference-based methods offer more flexibility for
aligning with nuanced human intent. We discuss state-of-the-art techniques,
including Direct Preference Optimization (DPO), Constitutional AI,
brain-inspired methods, and alignment uncertainty quantification (AUQ),
highlighting their approaches to balancing quality and efficiency. We review
existing evaluation frameworks and benchmarking datasets, emphasizing
limitations such as reward misspecification, distributional robustness, and
scalable oversight. We summarize strategies adopted by leading AI labs to
illustrate the current state of practice. We conclude by outlining open
problems in oversight, value pluralism, robustness, and continuous alignment.
This survey aims to inform both researchers and practitioners navigating the
evolving landscape of LLM alignment.

</details>


### [119] [The wall confronting large language models](https://arxiv.org/abs/2507.19703)
*Peter V. Coveney,Sauro Succi*

Main category: cs.AI

TL;DR: 研究发现大型语言模型(LLM)的扩展定律严重限制了其预测不确定性的改进能力，其学习机制可能导致错误累积和信息灾难。避免AI退化路径需更重视问题结构特性的洞察。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在提升预测可靠性方面的根本限制，分析其学习机制与准确性之间的内在矛盾，及其可能引发的AI退化行为。

Method: 通过理论分析LLM的扩展定律与非高斯输出分布特性，结合Calude和Longo提出的虚假相关性增长理论，论证模型性能受限的机制。

Result: LLM的扩展定律使其难以满足科学探究的可靠性标准，其学习机制会引发错误累积、信息灾难和AI退化行为，且数据规模扩大会加剧虚假相关性。

Conclusion: 避免AI退化路径需要从根本上改变研究范式，更加注重对问题结构特性的深入理解，而非单纯依赖数据规模和模型扩展。

Abstract: We show that the scaling laws which determine the performance of large
language models (LLMs) severely limit their ability to improve the uncertainty
of their predictions. As a result, raising their reliability to meet the
standards of scientific inquiry is intractable by any reasonable measure. We
argue that the very mechanism which fuels much of the learning power of LLMs,
namely the ability to generate non-Gaussian output distributions from Gaussian
input ones, might well be at the roots of their propensity to produce error
pileup, ensuing information catastrophes and degenerative AI behaviour. This
tension between learning and accuracy is a likely candidate mechanism
underlying the observed low values of the scaling components. It is
substantially compounded by the deluge of spurious correlations pointed out by
Calude and Longo which rapidly increase in any data set merely as a function of
its size, regardless of its nature. The fact that a degenerative AI pathway is
a very probable feature of the LLM landscape does not mean that it must
inevitably arise in all future AI research. Its avoidance, which we also
discuss in this paper, necessitates putting a much higher premium on insight
and understanding of the structural characteristics of the problems being
investigated.

</details>


### [120] [Minding Motivation: The Effect of Intrinsic Motivation on Agent Behaviors](https://arxiv.org/abs/2507.19725)
*Leonardo Villalobos-Arias,Grant Forbes,Jianxun Wang,David L Roberts,Arnav Jhala*

Main category: cs.AI

TL;DR: 研究评估了内在动机(IM)方法在强化学习(RL)中对游戏行为的影响，发现IM虽能提升初始奖励但会导致奖励黑客行为，而广义奖励匹配(GRM)能在部分场景缓解此问题。


<details>
  <summary>Details</summary>
Motivation: 游戏环境因奖励稀疏性对RL代理构成挑战，IM方法通过引入探索奖励解决该问题，但可能引发代理为优化新奖励而偏离正常游戏行为的\'奖励黑客\'现象。目前尚不清楚IM奖励如何具体改变RL代理行为。

Method: 在MiniGrid游戏环境中实证评估三种IM技术对行为的影响，并与能保证最优性的广义奖励匹配(GRM)方法进行对比。

Result: IM显著改变了代理行为：既提高了初始奖励，也导致游戏策略变化；GRM在部分情况下有效减轻了奖励黑客问题。

Conclusion: IM会实质性影响RL代理的游戏行为模式，而GRM可作为缓解奖励黑客的潜在方案，但需进一步研究其普适性。

Abstract: Games are challenging for Reinforcement Learning~(RL) agents due to their
reward-sparsity, as rewards are only obtainable after long sequences of
deliberate actions. Intrinsic Motivation~(IM) methods -- which introduce
exploration rewards -- are an effective solution to reward-sparsity. However,
IM also causes an issue known as `reward hacking' where the agent optimizes for
the new reward at the expense of properly playing the game. The larger problem
is that reward hacking itself is largely unknown; there is no answer to
whether, and to what extent, IM rewards change the behavior of RL agents. This
study takes a first step by empirically evaluating the impact on behavior of
three IM techniques on the MiniGrid game-like environment. We compare these IM
models with Generalized Reward Matching~(GRM), a method that can be used with
any intrinsic reward function to guarantee optimality. Our results suggest that
IM causes noticeable change by increasing the initial rewards, but also
altering the way the agent plays; and that GRM mitigated reward hacking in some
scenarios.

</details>


### [121] [HypKG: Hypergraph-based Knowledge Graph Contextualization for Precision Healthcare](https://arxiv.org/abs/2507.19726)
*Yuzhang Xie,Xu Han,Ran Xu,Xiao Hu,Jiaying Lu,Carl Yang*

Main category: cs.AI

TL;DR: 本文提出HypKG框架，通过整合电子健康记录(EHRs)与知识图谱(KGs)，生成情境化知识表示以提升医疗预测准确性。


<details>
  <summary>Details</summary>
Motivation: 通用知识图谱缺乏患者特定情境信息，而电子健康记录能提供丰富的个人数据。结合两者可提升精准医疗中的知识表示质量。

Method: 采用实体链接技术连接通用知识图谱与EHR数据，利用超图模型进行情境化表示，并通过超图变换器联合学习知识图谱与患者的表征。

Result: 在大型生物医学知识图谱和真实EHR数据集上的实验表明，HypKG在多项评估指标上显著提升了医疗预测任务的表现。

Conclusion: HypKG通过整合外部情境信息，不仅能改善医疗预测效果，还能优化知识图谱中实体和关系的表示质量，提升知识的实际应用价值。

Abstract: Knowledge graphs (KGs) are important products of the semantic web, which are
widely used in various application domains. Healthcare is one of such domains
where KGs are intensively used, due to the high requirement for knowledge
accuracy and interconnected nature of healthcare data. However, KGs storing
general factual information often lack the ability to account for important
contexts of the knowledge such as the status of specific patients, which are
crucial in precision healthcare. Meanwhile, electronic health records (EHRs)
provide rich personal data, including various diagnoses and medications, which
provide natural contexts for general KGs. In this paper, we propose HypKG, a
framework that integrates patient information from EHRs into KGs to generate
contextualized knowledge representations for accurate healthcare predictions.
Using advanced entity-linking techniques, we connect relevant knowledge from
general KGs with patient information from EHRs, and then utilize a hypergraph
model to "contextualize" the knowledge with the patient information. Finally,
we employ hypergraph transformers guided by downstream prediction tasks to
jointly learn proper contextualized representations for both KGs and patients,
fully leveraging existing knowledge in KGs and patient contexts in EHRs. In
experiments using a large biomedical KG and two real-world EHR datasets, HypKG
demonstrates significant improvements in healthcare prediction tasks across
multiple evaluation metrics. Additionally, by integrating external contexts,
HypKG can learn to adjust the representations of entities and relations in KG,
potentially improving the quality and real-world utility of knowledge.

</details>


### [122] [Integrating Activity Predictions in Knowledge Graphs](https://arxiv.org/abs/2507.19733)
*Alec Scully,Cameron Stockton,Forrest Hare*

Main category: cs.AI

TL;DR: 本文提出利用本体结构知识图谱预测未来事件，通过BFO和CCO框架组织数据并构建马尔可夫链模型，同时批判现有概率本体模型并提出替代方案。


<details>
  <summary>Details</summary>
Motivation: 研究旨在展示本体结构知识图谱在预测未来事件中的关键作用，并解决现有概率模型中语义混淆的问题。

Method: 采用BFO和CCO语义框架组织数据（如渔船轨迹），通过SPARQL查询构建马尔可夫链模型，引入'时空实例'概念完善结构语义。

Result: 实现了基于历史数据的未来状态预测，提出将概率视为过程特性的新观点，并将计算结果无缝集成回知识图谱。

Conclusion: 该方法有效支持预测分析，通过本体论改进概率建模，为动态现象分析提供可扩展框架。

Abstract: We argue that ontology-structured knowledge graphs can play a crucial role in
generating predictions about future events. By leveraging the semantic
framework provided by Basic Formal Ontology (BFO) and Common Core Ontologies
(CCO), we demonstrate how data such as the movements of a fishing vessel can be
organized in and retrieved from a knowledge graph. These query results are then
used to create Markov chain models, allowing us to predict future states based
on the vessel's history. To fully support this process, we introduce the term
`spatiotemporal instant' to complete the necessary structural semantics.
Additionally, we critique the prevailing ontological model of probability,
which conflates probability with likelihood and relies on the problematic
concept of modal measurements: measurements of future entities. We propose an
alternative view, where probabilities are treated as being about process
profiles, which better captures the dynamics of real world phenomena. Finally,
we demonstrate how our Markov chain based probability calculations can be
seamlessly integrated back into the knowledge graph, enabling further analysis
and decision-making. Keywords: predictive analytics, ontology, Markov chains,
probability, Basic Formal Ontology (BFO), knowledge graphs, SPARQL.

</details>


### [123] [Can LLMs Solve ASP Problems? Insights from a Benchmarking Study (Extended Version)](https://arxiv.org/abs/2507.19749)
*Lin Ren,Guohui Xiao,Guilin Qi,Yishuai Geng,Haohan Xue*

Main category: cs.AI

TL;DR: 本文介绍了ASPBench，一个针对答案集编程（ASP）的综合基准测试，评估了14种最先进的大型语言模型（LLM）在ASP特定任务上的表现。研究发现，尽管LLM在较简单的任务上表现良好，但在核心的答案集计算任务上仍存在困难。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型（LLM）在答案集编程（ASP）能力上的评估存在局限性，缺乏支持否定、析取或多答案集的复杂程序，且缺少专门设计的ASP求解任务基准。

Method: 作者提出了ASPBench基准测试，包含三个ASP特定任务：ASP蕴含、答案集验证和答案集计算，并对14种先进LLM（如\emph{deepseek-r1}、\emph{o4-mini}和\emph{gemini-2.5-flash-thinking}）进行了广泛评估。

Result: 评估结果显示，LLM在前两个较简单的任务上表现较好，但在核心的答案集计算任务上表现不佳，揭示了当前LLM在ASP求解中的局限性。

Conclusion: 研究强调了需要更有效地整合符号推理能力的新方法，以提升LLM在ASP求解中的表现。代码和数据集已开源。

Abstract: Answer Set Programming (ASP) is a powerful paradigm for non-monotonic
reasoning. Recently, large language models (LLMs) have demonstrated promising
capabilities in logical reasoning. Despite this potential, current evaluations
of LLM capabilities in ASP are often limited. Existing works normally employ
overly simplified ASP programs, do not support negation, disjunction, or
multiple answer sets. Furthermore, there is a lack of benchmarks that introduce
tasks specifically designed for ASP solving. To bridge this gap, we introduce
ASPBench, a comprehensive ASP benchmark, including three ASP specific tasks:
ASP entailment, answer set verification, and answer set computation. Our
extensive evaluations on ASPBench reveal that while 14 state-of-the-art LLMs,
including \emph{deepseek-r1}, \emph{o4-mini}, and
\emph{gemini-2.5-flash-thinking}, perform relatively well on the first two
simpler tasks, they struggle with answer set computation, which is the core of
ASP solving. These findings offer insights into the current limitations of LLMs
in ASP solving. This highlights the need for new approaches that integrate
symbolic reasoning capabilities more effectively. The code and dataset are
available at https://github.com/HomuraT/ASPBench.

</details>


### [124] [Reinforcement Learning for Multi-Objective Multi-Echelon Supply Chain Optimisation](https://arxiv.org/abs/2507.19788)
*Rifny Rachman,Josh Tingey,Richard Allmendinger,Pradyumn Shukla,Wei Pan*

Main category: cs.AI

TL;DR: 本文提出了一种基于马尔可夫决策过程的广义多目标、多层次供应链优化模型，结合经济、环境和社会因素，采用多目标强化学习方法，在复杂网络环境中实现生产与配送的近乎最优权衡。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决非平稳市场下供应链优化中的多目标冲突问题，整合经济、环境和社会维度，以应对现实世界中的典型挑战。

Method: 采用多目标强化学习（RL）方法，与加权和修改的单目标RL算法及多目标进化算法（MOEA）进行对比，通过可定制模拟器在不同网络复杂度下进行实验。

Result: 主要方法在最优性、多样性和密度之间实现了最平衡的权衡，复杂场景下超体积比MOEA方法高75%，解密度是修改单目标RL方法的11倍，同时确保稳定的生产和库存水平。

Conclusion: 该模型通过共享经验缓冲区增强策略间知识转移，显著提升鲁棒性，有效减少需求损失，为多目标供应链优化提供了高效解决方案。

Abstract: This study develops a generalised multi-objective, multi-echelon supply chain
optimisation model with non-stationary markets based on a Markov decision
process, incorporating economic, environmental, and social considerations. The
model is evaluated using a multi-objective reinforcement learning (RL) method,
benchmarked against an originally single-objective RL algorithm modified with
weighted sum using predefined weights, and a multi-objective evolutionary
algorithm (MOEA)-based approach. We conduct experiments on varying network
complexities, mimicking typical real-world challenges using a customisable
simulator. The model determines production and delivery quantities across
supply chain routes to achieve near-optimal trade-offs between competing
objectives, approximating Pareto front sets. The results demonstrate that the
primary approach provides the most balanced trade-off between optimality,
diversity, and density, further enhanced with a shared experience buffer that
allows knowledge transfer among policies. In complex settings, it achieves up
to 75\% higher hypervolume than the MOEA-based method and generates solutions
that are approximately eleven times denser, signifying better robustness, than
those produced by the modified single-objective RL method. Moreover, it ensures
stable production and inventory levels while minimising demand loss.

</details>


### [125] [Causality-aligned Prompt Learning via Diffusion-based Counterfactual Generation](https://arxiv.org/abs/2507.19882)
*Xinshu Li,Ruoyu Wang,Erdun Gao,Mingming Gong,Lina Yao*

Main category: cs.AI

TL;DR: 论文提出DiCap模型，一种基于扩散的反事实提示学习框架，通过理论推导生成因果不变性提示，显著提升跨类别泛化能力，在多项任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有提示学习方法因缺乏理论支撑，难以生成因果不变性提示，导致无法捕获跨类别鲁棒特征。DiCap旨在解决这一局限性。

Method: 采用扩散过程迭代采样因果模型的边际与条件分布梯度，生成满足最小充分性准则的反事实样本，并结合对比学习框架精炼因果对齐的提示。

Result: 实验表明DiCap在图像分类、图文检索、视觉问答等任务中表现卓越，尤其在未见类别上优势显著。

Conclusion: 理论驱动的DiCap框架通过反事实生成与对比学习，实现了因果可识别性与误差边界控制，为提示学习提供了新范式。

Abstract: Prompt learning has garnered attention for its efficiency over traditional
model training and fine-tuning. However, existing methods, constrained by
inadequate theoretical foundations, encounter difficulties in achieving
causally invariant prompts, ultimately falling short of capturing robust
features that generalize effectively across categories. To address these
challenges, we introduce the $\textit{\textbf{DiCap}}$ model, a theoretically
grounded $\textbf{Di}$ffusion-based $\textbf{C}$ounterf$\textbf{a}$ctual
$\textbf{p}$rompt learning framework, which leverages a diffusion process to
iteratively sample gradients from the marginal and conditional distributions of
the causal model, guiding the generation of counterfactuals that satisfy the
minimal sufficiency criterion. Grounded in rigorous theoretical derivations,
this approach guarantees the identifiability of counterfactual outcomes while
imposing strict bounds on estimation errors. We further employ a contrastive
learning framework that leverages the generated counterfactuals, thereby
enabling the refined extraction of prompts that are precisely aligned with the
causal features of the data. Extensive experimental results demonstrate that
our method performs excellently across tasks such as image classification,
image-text retrieval, and visual question answering, with particularly strong
advantages in unseen categories.

</details>


### [126] [What Does 'Human-Centred AI' Mean?](https://arxiv.org/abs/2507.19960)
*Olivia Guest*

Main category: cs.AI

TL;DR: 本文认为人工智能(AI)本质上是技术与人类认知劳动的关系，提出应从替代性、增强性和置换性三个维度分析这种关系，并强调必须直面人类在AI系统中的核心地位以避免认知混淆。


<details>
  <summary>Details</summary>
Motivation: 探讨以人为中心的人工智能本质，揭示当前AI讨论中人类认知角色的模糊性如何阻碍真正人本化AI系统的发展。

Method: 通过算盘与心算、闹钟与人工叫醒服务等对比案例，提出新型定义框架分析技术替代人类认知劳动的三种模式：有害的取代、有益的增强和中性的置换。

Result: 论证所有AI都必然涉及人类认知，而掩盖这种认知关联会导致批判性思维迟滞、认知科学扭曲，并最终限制构建真正以人类为中心的AI系统。

Conclusion: 要破除对AI的盲目崇拜，必须明确承认并审视"人在回路"中的核心地位，这是实现人本AI的首要前提。

Abstract: While it seems sensible that human-centred artificial intelligence (AI) means
centring "human behaviour and experience," it cannot be any other way. AI, I
argue, is usefully seen as a relationship between technology and humans where
it appears that artifacts can perform, to a greater or lesser extent, human
cognitive labour. This is evinced using examples that juxtapose technology with
cognition, inter alia: abacus versus mental arithmetic; alarm clock versus
knocker-upper; camera versus vision; and sweatshop versus tailor. Using novel
definitions and analyses, sociotechnical relationships can be analysed into
varying types of: displacement (harmful), enhancement (beneficial), and/or
replacement (neutral) of human cognitive labour. Ultimately, all AI implicates
human cognition; no matter what. Obfuscation of cognition in the AI context --
from clocks to artificial neural networks -- results in distortion, in slowing
critical engagement, perverting cognitive science, and indeed in limiting our
ability to truly centre humans and humanity in the engineering of AI systems.
To even begin to de-fetishise AI, we must look the human-in-the-loop in the
eyes.

</details>


### [127] [Leveraging Fine-Tuned Large Language Models for Interpretable Pancreatic Cystic Lesion Feature Extraction and Risk Categorization](https://arxiv.org/abs/2507.19973)
*Ebrahim Rasromani,Stella K. Kang,Yanqi Xu,Beisong Liu,Garvit Luhadia,Wan Fung Chui,Felicia L. Pasadyn,Yu Chih Hung,Julie Y. An,Edwin Mathieu,Zehui Gu,Carlos Fernandez-Granda,Ammar A. Javed,Greg D. Sacks,Tamas Gonda,Chenchan Huang,Yiqiu Shen*

Main category: cs.AI

TL;DR: 研究开发了基于大语言模型（LLM）的自动系统，用于从MRI/CT报告中提取胰腺囊性病变（PCL）特征并评估风险等级，性能媲美GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 人工提取PCL特征耗时费力，阻碍大规模研究。需开发自动化工具提升效率。

Method: 使用GPT-4o生成6,000份腹部MRI/CT报告的链式思考（CoT）标注数据，对LLaMA和DeepSeek模型进行QLoRA微调，依据2017 ACR白皮书进行风险分类，并在285份人工标注报告上评估性能。

Result: CoT微调使LLaMA和DeepSeek的特征提取准确率分别提升至97%和98%，风险分类F1分数达0.95/0.94，与GPT-4o（0.97）无显著差异。模型与放射科医生的判断一致性（Fleiss' Kappa≈0.89）达到专家水平。

Conclusion: 经CoT监督微调的开源LLM能实现与GPT-4o相当的PCL表型分析性能，为大规模研究提供高效精准的工具。

Abstract: Background: Manual extraction of pancreatic cystic lesion (PCL) features from
radiology reports is labor-intensive, limiting large-scale studies needed to
advance PCL research. Purpose: To develop and evaluate large language models
(LLMs) that automatically extract PCL features from MRI/CT reports and assign
risk categories based on guidelines. Materials and Methods: We curated a
training dataset of 6,000 abdominal MRI/CT reports (2005-2024) from 5,134
patients that described PCLs. Labels were generated by GPT-4o using
chain-of-thought (CoT) prompting to extract PCL and main pancreatic duct
features. Two open-source LLMs were fine-tuned using QLoRA on GPT-4o-generated
CoT data. Features were mapped to risk categories per institutional guideline
based on the 2017 ACR White Paper. Evaluation was performed on 285 held-out
human-annotated reports. Model outputs for 100 cases were independently
reviewed by three radiologists. Feature extraction was evaluated using exact
match accuracy, risk categorization with macro-averaged F1 score, and
radiologist-model agreement with Fleiss' Kappa. Results: CoT fine-tuning
improved feature extraction accuracy for LLaMA (80% to 97%) and DeepSeek (79%
to 98%), matching GPT-4o (97%). Risk categorization F1 scores also improved
(LLaMA: 0.95; DeepSeek: 0.94), closely matching GPT-4o (0.97), with no
statistically significant differences. Radiologist inter-reader agreement was
high (Fleiss' Kappa = 0.888) and showed no statistically significant difference
with the addition of DeepSeek-FT-CoT (Fleiss' Kappa = 0.893) or GPT-CoT
(Fleiss' Kappa = 0.897), indicating that both models achieved agreement levels
on par with radiologists. Conclusion: Fine-tuned open-source LLMs with CoT
supervision enable accurate, interpretable, and efficient phenotyping for
large-scale PCL research, achieving performance comparable to GPT-4o.

</details>


### [128] [Digital Twin Channel-Enabled Online Resource Allocation for 6G: Principle, Architecture and Application](https://arxiv.org/abs/2507.19974)
*Tongjie Li,Jianhua Zhang,Li Yu,Yuxiang Zhang,Yunlong Cai,Fan Xu,Guangyi Liu*

Main category: cs.AI

TL;DR: 本文提出了一种基于数字孪生信道（DTC）的在线优化框架，用于6G网络中灵活、低延迟和可靠的资源分配。该方法通过环境感知预测信道状态信息（CSI），并利用轻量级博弈论算法实现高效资源分配，相比传统方案提升吞吐量达11.5%。


<details>
  <summary>Details</summary>
Motivation: 全息通信、自动驾驶和工业物联网等新兴应用对6G网络的资源分配提出了灵活、低延迟和高可靠性的严苛要求。传统基于统计建模的方法在动态特定环境中性能不足，且实时获取CSI需要过高导频开销。

Method: 采用数字孪生信道（DTC）预测环境感知驱动的CSI，结合轻量级博弈论算法进行在线资源分配，形成低开销、可扩展的优化框架。

Result: 在真实工业车间的数字孪生仿真中，所提方法比基于导频的理想CSI方案吞吐量提升最高达11.5%，验证了其在6G网络中的高效性。

Conclusion: 该DTC框架为未来6G网络提供了可扩展、低开销且环境感知的通信解决方案，显著优于传统方法，适用于动态复杂场景。

Abstract: Emerging applications such as holographic communication, autonomous driving,
and the industrial Internet of Things impose stringent requirements on
flexible, low-latency, and reliable resource allocation in 6G networks.
Conventional methods, which rely on statistical modeling, have proven effective
in general contexts but may fail to achieve optimal performance in specific and
dynamic environments. Furthermore, acquiring real-time channel state
information (CSI) typically requires excessive pilot overhead. To address these
challenges, a digital twin channel (DTC)-enabled online optimization framework
is proposed, in which DTC is employed to predict CSI based on environmental
sensing. The predicted CSI is then utilized by lightweight game-theoretic
algorithms to perform online resource allocation in a timely and efficient
manner. Simulation results based on a digital replica of a realistic industrial
workshop demonstrate that the proposed method achieves throughput improvements
of up to 11.5\% compared with pilot-based ideal CSI schemes, validating its
effectiveness for scalable, low-overhead, and environment-aware communication
in future 6G networks.

</details>


### [129] [Matching Game Preferences Through Dialogical Large Language Models: A Perspective](https://arxiv.org/abs/2507.20000)
*Renaud Fabre,Daniel Egret,Patrice Bellot*

Main category: cs.AI

TL;DR: 本文探讨了如何将大型语言模型（LLMs）与GRAPHYP网络系统结合，开发透明可追溯的对话式人工智能（D-LLMs），通过结构化对话捕捉用户偏好，实现个性化决策。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统缺乏透明度，用户无法理解其决策过程。研究旨在构建可解释的AI框架，使人类能审查并整合影响AI响应的人为偏好，增强人工智能的可信度。

Method: 提出D-LLM概念框架，包含三大组件：1）分析搜索体验的推理过程；2）识别用户偏好的分类系统；3）解决信息冲突的对话方法，通过GRAPHYP网络实现偏好嵌入。

Result: 构想出能展示推理路径的AI系统，不仅提供答案，还揭示答案生成机制，使多用户偏好通过对话被显性化、可追溯地整合至决策中。

Conclusion: 该框架为开发透明、可信的对话式AI奠定基础，未来或能实现个性化LLMs，推动人机协作决策的范式革新。

Abstract: This perspective paper explores the future potential of "conversational
intelligence" by examining how Large Language Models (LLMs) could be combined
with GRAPHYP's network system to better understand human conversations and
preferences. Using recent research and case studies, we propose a conceptual
framework that could make AI rea-soning transparent and traceable, allowing
humans to see and understand how AI reaches its conclusions. We present the
conceptual perspective of "Matching Game Preferences through Dialogical Large
Language Models (D-LLMs)," a proposed system that would allow multiple users to
share their different preferences through structured conversations. This
approach envisions personalizing LLMs by embedding individual user preferences
directly into how the model makes decisions. The proposed D-LLM framework would
require three main components: (1) reasoning processes that could analyze
different search experiences and guide performance, (2) classification systems
that would identify user preference patterns, and (3) dialogue approaches that
could help humans resolve conflicting information. This perspective framework
aims to create an interpretable AI system where users could examine,
understand, and combine the different human preferences that influence AI
responses, detected through GRAPHYP's search experience networks. The goal of
this perspective is to envision AI systems that would not only provide answers
but also show users how those answers were reached, making artificial
intelligence more transparent and trustworthy for human decision-making.

</details>


### [130] [Finding Personalized Good-Enough Solutions to Unsatisfiable Stable Roommates Problems](https://arxiv.org/abs/2507.20010)
*Müge Fidan,Esra Erdem*

Main category: cs.AI

TL;DR: 本文研究了稳定室友问题，提出了一种考虑代理人习惯、偏好及朋友网络的方法，以生成个性化解决方案，并通过实例和实证评估验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于稳定室友问题并非总有解，且受现实应用启发，研究旨在计算"足够好"的匹配方案，同时考虑代理人的习惯、偏好及其朋友网络。

Method: 引入了一种新方法，结合代理人的习惯偏好及其朋友网络，生成个性化的稳定室友问题解决方案。

Result: 通过示例和实证评估，证明了所提方法在解决稳定室友问题中的实用性和有效性。

Conclusion: 本研究为稳定室友问题提供了一种考虑多方面因素的个性化解决方案，扩展了该领域的研究范围和应用潜力。

Abstract: The Stable Roommates problems are characterized by the preferences of agents
over other agents as roommates. A solution is a partition of the agents into
pairs that are acceptable to each other (i.e., they are in the preference lists
of each other), and the matching is stable (i.e., there do not exist any two
agents who prefer each other to their roommates, and thus block the matching).
Motivated by real-world applications, and considering that stable roommates
problems do not always have solutions, we continue our studies to compute
"good-enough" matchings. In addition to the agents' habits and habitual
preferences, we consider their networks of preferred friends, and introduce a
method to generate personalized solutions to stable roommates problems. We
illustrate the usefulness of our method with examples and empirical
evaluations.

</details>


### [131] [PITA: Preference-Guided Inference-Time Alignment for LLM Post-Training](https://arxiv.org/abs/2507.20067)
*Sarat Chandra Bobbili,Ujwal Dinesha,Dheeraj Narasimha,Srinivas Shakkottai*

Main category: cs.AI

TL;DR: 提出PITA框架，无需奖励模型即可在推理阶段直接整合用户偏好反馈，指导大语言模型生成符合偏好的输出。


<details>
  <summary>Details</summary>
Motivation: 现有后训练方法依赖预训练奖励模型拟合人类偏好，过程不稳定且计算成本高。PITA旨在消除这一依赖，直接优化生成过程。

Method: 通过随机搜索和迭代优化学习小型偏好引导策略，在推理时调整token概率分布，无需微调大模型或独立奖励模型。

Result: 在数学推理、情感分类等任务中验证了PITA的有效性，成功实现模型输出与用户偏好的对齐。

Conclusion: PITA提供了一种高效、低成本的偏好对齐方案，突破了传统方法对奖励模型的依赖，具有广泛应用潜力。

Abstract: Inference-time alignment enables large language models (LLMs) to generate
outputs aligned with end-user preferences without further training. Recent
post-training methods achieve this by using small guidance models to modify
token generation during inference. These methods typically optimize a reward
function KL-regularized by the original LLM taken as the reference policy. A
critical limitation, however, is their dependence on a pre-trained reward
model, which requires fitting to human preference feedback--a potentially
unstable process. In contrast, we introduce PITA, a novel framework that
integrates preference feedback directly into the LLM's token generation,
eliminating the need for a reward model. PITA learns a small preference-based
guidance policy to modify token probabilities at inference time without LLM
fine-tuning, reducing computational cost and bypassing the pre-trained reward
model dependency. The problem is framed as identifying an underlying preference
distribution, solved through stochastic search and iterative refinement of the
preference-based guidance model. We evaluate PITA across diverse tasks,
including mathematical reasoning and sentiment classification, demonstrating
its effectiveness in aligning LLM outputs with user preferences.

</details>


### [132] [Concept Learning for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2507.20143)
*Zhonghan Ge,Yuanyang Zhu,Chunlin Chen*

Main category: cs.AI

TL;DR: 本文提出了一种基于概念瓶颈模型的可解释多智能体Q学习方法（CMQ），通过显式学习人类合作概念来提升多智能体强化学习的透明度和性能，在星际争霸II和LBF任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前神经网络在多智能体强化学习（MARL）中缺乏透明性和可解释性，其隐含的合作机制因黑箱特性难以理解。研究旨在突破性能与可解释性之间的权衡，建立可信赖的合作概念学习框架。

Method: 提出CMQ方法，将合作概念表示为监督向量（而非传统端到端的概念无关信息流），利用全局状态嵌入条件下的个体动作价值来增强合作表征能力，支持测试时概念干预以检测合作偏差。

Result: 在星际争霸II微操任务和LBF环境中，CMQ性能超越最先进模型，并能捕捉有意义的合作模式，通过概念干预识别合作中的潜在偏差和伪影。

Conclusion: CMQ通过显式学习可解释合作概念，实现了性能与可解释性的双重提升，为分析多智能体合作机制提供了新工具。

Abstract: Despite substantial progress in applying neural networks (NN) to multi-agent
reinforcement learning (MARL) areas, they still largely suffer from a lack of
transparency and interoperability. However, its implicit cooperative mechanism
is not yet fully understood due to black-box networks. In this work, we study
an interpretable value decomposition framework via concept bottleneck models,
which promote trustworthiness by conditioning credit assignment on an
intermediate level of human-like cooperation concepts. To address this problem,
we propose a novel value-based method, named Concepts learning for Multi-agent
Q-learning (CMQ), that goes beyond the current performance-vs-interpretability
trade-off by learning interpretable cooperation concepts. CMQ represents each
cooperation concept as a supervised vector, as opposed to existing models where
the information flowing through their end-to-end mechanism is concept-agnostic.
Intuitively, using individual action value conditioning on global state
embeddings to represent each concept allows for extra cooperation
representation capacity. Empirical evaluations on the StarCraft II
micromanagement challenge and level-based foraging (LBF) show that CMQ achieves
superior performance compared with the state-of-the-art counterparts. The
results also demonstrate that CMQ provides more cooperation concept
representation capturing meaningful cooperation modes, and supports test-time
concept interventions for detecting potential biases of cooperation mode and
identifying spurious artifacts that impact cooperation.

</details>


### [133] [The Policy Cliff: A Theoretical Analysis of Reward-Policy Maps in Large Language Models](https://arxiv.org/abs/2507.20150)
*Xingcheng Xu*

Main category: cs.AI

TL;DR: 本文提出了一个数学框架分析强化学习策略稳定性，揭示了奖励函数映射到最优策略时的不稳定性根源，并验证了熵正则化对恢复稳定性的作用。


<details>
  <summary>Details</summary>
Motivation: 强化学习在大型语言模型行为塑造中存在策略脆弱性，导致虚假推理、欺骗性对齐等关键故障，目前缺乏统一理论解释。

Method: 建立奖励函数到最优策略映射的稳定性分析框架，研究动作退化现象，并扩展至多奖励领域分析有效奖励聚合机制。

Result: 理论证明非唯一最优动作导致策略脆弱性，熵正则化以增加随机性为代价恢复稳定性，实验验证了多奖励RL中的扰动效应。

Conclusion: 该框架为AI系统安全设计提供了理论依据，将策略稳定性分析从经验启发推向原理性理论。

Abstract: Reinforcement learning (RL) plays a crucial role in shaping the behavior of
large language and reasoning models (LLMs/LRMs). However, it often produces
brittle and unstable policies, leading to critical failures such as spurious
reasoning, deceptive alignment, and instruction disobedience that undermine the
trustworthiness and safety of LLMs/LRMs. Currently, these issues lack a unified
theoretical explanation and are typically addressed using ad-hoc heuristics.
This paper presents a rigorous mathematical framework for analyzing the
stability of the mapping from a reward function to the optimal policy. We show
that policy brittleness often stems from non-unique optimal actions, a common
occurrence when multiple valid traces exist in a reasoning task. This
theoretical lens provides a unified explanation for a range of seemingly
disparate failures, reframing them as rational outcomes of optimizing rewards
that may be incomplete or noisy, especially in the presence of action
degeneracy. We extend this analysis from the fundamental single-reward setting
to the more realistic multi-reward RL across diverse domains, showing how
stability is governed by an "effective reward" aggregation mechanism. We also
prove that entropy regularization restores policy stability at the cost of
increased stochasticity. Our framework provides a unified explanation for
recent empirical findings on deceptive reasoning, instruction-following
trade-offs, and RLHF-induced sophistry, and is further validated through
perturbation experiments in multi-reward RL. This work advances
policy-stability analysis from empirical heuristics towards a principled
theory, offering essential insights for designing safer and more trustworthy AI
systems.

</details>


### [134] [StepFun-Prover Preview: Let's Think and Verify Step by Step](https://arxiv.org/abs/2507.20199)
*Shijie Shang,Ruosi Wan,Yue Peng,Yutong Wu,Xiong-hui Chen,Jie Yan,Xiangyu Zhang*

Main category: cs.AI

TL;DR: StepFun-Prover Preview是一个专为形式化定理证明设计的大语言模型，通过工具集成推理实现高效Lean 4证明生成，在miniF2F-test基准上达到70.0\%的pass@1成功率。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种能够模拟人类问题解决策略的模型，通过实时环境反馈迭代优化证明过程，推动自动定理证明和数学AI助手的发展。

Method: 采用强化学习流程，结合工具交互机制，使模型能够基于环境反馈逐步完善证明，实现端到端的工具集成推理模型训练框架。

Result: 在miniF2F-test基准测试中，模型以最少采样达到70.0\%的pass@1成功率，显著提升了自动化证明的基准性能。

Conclusion: 该研究不仅展示了工具集成推理在定理证明中的有效性，还为开发数学AI助手提供了新的技术路径。

Abstract: We present StepFun-Prover Preview, a large language model designed for formal
theorem proving through tool-integrated reasoning. Using a reinforcement
learning pipeline that incorporates tool-based interactions, StepFun-Prover can
achieve strong performance in generating Lean 4 proofs with minimal sampling.
Our approach enables the model to emulate human-like problem-solving strategies
by iteratively refining proofs based on real-time environment feedback. On the
miniF2F-test benchmark, StepFun-Prover achieves a pass@1 success rate of
$70.0\%$. Beyond advancing benchmark performance, we introduce an end-to-end
training framework for developing tool-integrated reasoning models, offering a
promising direction for automated theorem proving and Math AI assistant.

</details>


### [135] [Improving Subgraph Matching by Combining Algorithms and Graph Neural Networks](https://arxiv.org/abs/2507.20226)
*Shuyang Guo,Wenjin Xie,Ping Lu,Ting Deng,Richong Zhang,Jianxin Li,Xiangping Huang,Zhongyi Liu*

Main category: cs.AI

TL;DR: 提出首个基于图神经网络的子图同态框架HFrame，结合传统算法与机器学习，在效率与准确率上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 子图同态问题因允许多对一映射而比同构更复杂，现有图神经网络难以有效解决，需开发新框架。

Method: HFrame融合传统子图同态算法与图神经网络，通过改进的消息传递机制区分非同态图对，并提供泛化误差界理论保证。

Result: 实验表明：HFrame比精确匹配算法快101.91倍，平均准确率达0.962，且能识别更多非同态图对。

Conclusion: HFrame为子图同态问题提供了首个神经网络解决方案，在速度与判别能力上均实现突破，具有理论及实践价值。

Abstract: Homomorphism is a key mapping technique between graphs that preserves their
structure. Given a graph and a pattern, the subgraph homomorphism problem
involves finding a mapping from the pattern to the graph, ensuring that
adjacent vertices in the pattern are mapped to adjacent vertices in the graph.
Unlike subgraph isomorphism, which requires a one-to-one mapping, homomorphism
allows multiple vertices in the pattern to map to the same vertex in the graph,
making it more complex. We propose HFrame, the first graph neural network-based
framework for subgraph homomorphism, which integrates traditional algorithms
with machine learning techniques. We demonstrate that HFrame outperforms
standard graph neural networks by being able to distinguish more graph pairs
where the pattern is not homomorphic to the graph. Additionally, we provide a
generalization error bound for HFrame. Through experiments on both real-world
and synthetic graphs, we show that HFrame is up to 101.91 times faster than
exact matching algorithms and achieves an average accuracy of 0.962.

</details>


### [136] [A Multi-Agent System for Information Extraction from the Chemical Literature](https://arxiv.org/abs/2507.20230)
*Yufan Chen,Ching Ting Leung,Bowen Yu,Jianwei Sun,Yong Huang,Linyan Li,Hao Chen,Hanyu Gao*

Main category: cs.AI

TL;DR: 本文提出了一种基于多模态大语言模型（MLLM）的多智能体系统，用于自动从文献中提取化学信息，显著提升了复杂化学反应图形的信息提取准确率。


<details>
  <summary>Details</summary>
Motivation: 高质量化学数据库是AI驱动化学研究的基石，但当前化学信息的多模态和风格多样性限制了自动提取技术的发展。

Method: 利用MLLM的强大推理能力理解复杂化学图形结构，将提取任务分解为子任务，并协调多个专用智能体协同完成。

Result: 系统在文献复杂化学反应图形基准数据集上F1分数达80.8%，较之前最佳模型（35.6%）有显著提升，并在分子图像识别、反应图像解析等子任务中表现一致改进。

Conclusion: 该研究是自动化化学信息提取的重要进展，将有力推动AI驱动的化学研究发展。

Abstract: To fully expedite AI-powered chemical research, high-quality chemical
databases are the cornerstone. Automatic extraction of chemical information
from the literature is essential for constructing reaction databases, but it is
currently limited by the multimodality and style variability of chemical
information. In this work, we developed a multimodal large language model
(MLLM)-based multi-agent system for automatic chemical information extraction.
We used the MLLM's strong reasoning capability to understand the structure of
complex chemical graphics, decompose the extraction task into sub-tasks and
coordinate a set of specialized agents to solve them. Our system achieved an F1
score of 80.8% on a benchmark dataset of complex chemical reaction graphics
from the literature, surpassing the previous state-of-the-art model (F1 score:
35.6%) by a significant margin. Additionally, it demonstrated consistent
improvements in key sub-tasks, including molecular image recognition, reaction
image parsing, named entity recognition and text-based reaction extraction.
This work is a critical step toward automated chemical information extraction
into structured datasets, which will be a strong promoter of AI-driven chemical
research.

</details>


### [137] [SciToolAgent: A Knowledge Graph-Driven Scientific Agent for Multi-Tool Integration](https://arxiv.org/abs/2507.20280)
*Keyan Ding,Jing Yu,Junjie Huang,Yuchen Yang,Qiang Zhang,Huajun Chen*

Main category: cs.AI

TL;DR: SciToolAgent是一个基于大型语言模型的智能代理，通过科学工具知识图谱实现跨学科工具的自动化调用，显著提升了复杂科研工作流的执行效率。


<details>
  <summary>Details</summary>
Motivation: 当前科学计算工具的使用高度依赖领域专业知识，而现有大型语言模型在多工具协同处理复杂科研流程方面存在不足，需要开发更高效的自动化解决方案。

Method: 系统整合了数百个生物、化学和材料科学工具，采用基于图谱的检索增强生成技术实现智能工具选择，并配备安全检测模块确保伦理使用。

Result: 在精选测试集上显著优于现有方法，蛋白质工程、化学反应预测等案例验证了其在复杂科研流程中的自动化能力。

Conclusion: 该研究使高级科研工具突破专业壁垒，为专家与非专家用户提供了统一的智能化研究界面，推动了科学计算的民主化进程。

Abstract: Scientific research increasingly relies on specialized computational tools,
yet effectively utilizing these tools demands substantial domain expertise.
While Large Language Models (LLMs) show promise in tool automation, they
struggle to seamlessly integrate and orchestrate multiple tools for complex
scientific workflows. Here, we present SciToolAgent, an LLM-powered agent that
automates hundreds of scientific tools across biology, chemistry, and materials
science. At its core, SciToolAgent leverages a scientific tool knowledge graph
that enables intelligent tool selection and execution through graph-based
retrieval-augmented generation. The agent also incorporates a comprehensive
safety-checking module to ensure responsible and ethical tool usage. Extensive
evaluations on a curated benchmark demonstrate that SciToolAgent significantly
outperforms existing approaches. Case studies in protein engineering, chemical
reactivity prediction, chemical synthesis, and metal-organic framework
screening further demonstrate SciToolAgent's capability to automate complex
scientific workflows, making advanced research tools accessible to both experts
and non-experts.

</details>


### [138] [Artificial Intelligence In Patent And Market Intelligence: A New Paradigm For Technology Scouting](https://arxiv.org/abs/2507.20322)
*Manish Verma,Vivek Sharma,Vishal Singh*

Main category: cs.AI

TL;DR: 本文介绍了一个基于大型语言模型（LLM）的AI平台，用于优化工业研发中的技术侦察和解决方案发现，通过语义理解和跨领域知识提取，显著提升创新效率和决策质量。


<details>
  <summary>Details</summary>
Motivation: 传统技术侦察方法依赖人工、耗时且效率低下，难以整合碎片化的专利和商业数据，亟需AI驱动的高效解决方案。

Method: 平台利用LLM的语义理解能力解析问题，从非结构化专利文本中提取创新方案，并结合商业情报数据，按技术类别系统化组织。

Result: 该平台减少了人工干预，加速了创新周期，并提供了兼顾技术新颖性、可行性和可持续性的综合评估。

Conclusion: AI驱动的技术侦察引擎显著提升了复杂研发环境下的决策效率，为跨领域创新提供了可扩展的解决方案。

Abstract: This paper presents the development of an AI powered software platform that
leverages advanced large language models (LLMs) to transform technology
scouting and solution discovery in industrial R&D. Traditional approaches to
solving complex research and development challenges are often time consuming,
manually driven, and heavily dependent on domain specific expertise. These
methods typically involve navigating fragmented sources such as patent
repositories, commercial product catalogs, and competitor data, leading to
inefficiencies and incomplete insights. The proposed platform utilizes cutting
edge LLM capabilities including semantic understanding, contextual reasoning,
and cross-domain knowledge extraction to interpret problem statements and
retrieve high-quality, sustainable solutions. The system processes unstructured
patent texts, such as claims and technical descriptions, and systematically
extracts potential innovations aligned with the given problem context. These
solutions are then algorithmically organized under standardized technical
categories and subcategories to ensure clarity and relevance across
interdisciplinary domains. In addition to patent analysis, the platform
integrates commercial intelligence by identifying validated market solutions
and active organizations addressing similar challenges. This combined insight
sourced from both intellectual property and real world product data enables R&D
teams to assess not only technical novelty but also feasibility, scalability,
and sustainability. The result is a comprehensive, AI driven scouting engine
that reduces manual effort, accelerates innovation cycles, and enhances
decision making in complex R&D environments.

</details>


### [139] [The Blessing and Curse of Dimensionality in Safety Alignment](https://arxiv.org/abs/2507.20333)
*Rachel S. Y. Teo,Laziz U. Abdullaev,Tan M. Nguyen*

Main category: cs.AI

TL;DR: 研究发现大语言模型(LLM)的高维表征既是优势也是安全隐患，通过降维可有效抵御激活工程攻击。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在各领域广泛应用，其安全对齐问题日益突出。本文假设模型维度增长虽带来性能提升，但高维激活空间的线性结构可能被利用来绕过安全防护。

Method: 通过可视化不同规模模型的线性子空间，并实验验证将表征投影到低维空间的效果，结合理论分析维度与安全性的关系。

Result: 实证表明降维处理能保留足够对齐信息，同时显著降低通过表征工程进行越狱攻击的脆弱性。

Conclusion: 模型内部表征的高维度对安全对齐是双刃剑，合理降维可在保持性能的同时提升安全性，为LLM安全设计提供新思路。

Abstract: The focus on safety alignment in large language models (LLMs) has increased
significantly due to their widespread adoption across different domains. The
scale of LLMs play a contributing role in their success, and the growth in
parameter count follows larger hidden dimensions. In this paper, we hypothesize
that while the increase in dimensions has been a key advantage, it may lead to
emergent problems as well. These problems emerge as the linear structures in
the activation space can be exploited, in the form of activation engineering,
to circumvent its safety alignment. Through detailed visualizations of linear
subspaces associated with different concepts, such as safety, across various
model scales, we show that the curse of high-dimensional representations
uniquely impacts LLMs. Further substantiating our claim, we demonstrate that
projecting the representations of the model onto a lower dimensional subspace
can preserve sufficient information for alignment while avoiding those linear
structures. Empirical results confirm that such dimensional reduction
significantly reduces susceptibility to jailbreaking through representation
engineering. Building on our empirical validations, we provide theoretical
insights into these linear jailbreaking methods relative to a model's hidden
dimensions. Broadly speaking, our work posits that the high dimensions of a
model's internal representations can be both a blessing and a curse in safety
alignment.

</details>


### [140] [VLMPlanner: Integrating Visual Language Models with Motion Planning](https://arxiv.org/abs/2507.20342)
*Zhipeng Tang,Sha Zhang,Jiajun Deng,Chenjie Wang,Guoliang You,Yuting Huang,Xinrui Lin,Yanyong Zhang*

Main category: cs.AI

TL;DR: 提出VLMPlanner框架，结合视觉语言模型与实时规划器，通过多视角图像捕捉精细道路信息，并引入CAI-Gate机制动态调整推理频率，在复杂驾驶场景中实现高性能轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶运动规划方法依赖抽象感知或地图输入，缺乏关键视觉上下文（如道路细节、事故痕迹等），难以应对复杂环境。需融合视觉语言模型的常识推理能力以提升决策鲁棒性。

Method: 1) 构建混合框架VLMPlanner：学习型实时规划器+VLM（处理多视角原始图像）；2) 设计CAI-Gate机制，根据场景复杂度动态调整VLM推理频率，平衡性能与效率。

Result: 在nuPlan基准测试中，该方法在复杂路况和动态场景下展现出优越的规划性能，验证了视觉上下文与常识推理的有效性。

Conclusion: VLMPlanner通过视觉语言模型增强环境理解能力，配合自适应推理机制，为自动驾驶在长尾场景中的鲁棒规划提供了新范式。代码将开源。

Abstract: Integrating large language models (LLMs) into autonomous driving motion
planning has recently emerged as a promising direction, offering enhanced
interpretability, better controllability, and improved generalization in rare
and long-tail scenarios. However, existing methods often rely on abstracted
perception or map-based inputs, missing crucial visual context, such as
fine-grained road cues, accident aftermath, or unexpected obstacles, which are
essential for robust decision-making in complex driving environments. To bridge
this gap, we propose VLMPlanner, a hybrid framework that combines a
learning-based real-time planner with a vision-language model (VLM) capable of
reasoning over raw images. The VLM processes multi-view images to capture rich,
detailed visual information and leverages its common-sense reasoning
capabilities to guide the real-time planner in generating robust and safe
trajectories. Furthermore, we develop the Context-Adaptive Inference Gate
(CAI-Gate) mechanism that enables the VLM to mimic human driving behavior by
dynamically adjusting its inference frequency based on scene complexity,
thereby achieving an optimal balance between planning performance and
computational efficiency. We evaluate our approach on the large-scale,
challenging nuPlan benchmark, with comprehensive experimental results
demonstrating superior planning performance in scenarios with intricate road
conditions and dynamic elements. Code will be available.

</details>


### [141] [Multi-Agent Reinforcement Learning for Dynamic Mobility Resource Allocation with Hierarchical Adaptive Grouping](https://arxiv.org/abs/2507.20377)
*Farshid Nooshi,Suining He*

Main category: cs.AI

TL;DR: 本文提出了一种名为HAG-PS的新型多智能体强化学习方法，用于动态分配城市移动资源（如共享单车/电动滑板车、拼车车辆），通过分层自适应分组参数共享解决政策共享和内存效率问题，并在纽约市共享单车数据上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 城市环境中移动资源（如共享单车、拼车车辆）的动态分配对平衡供需至关重要。现有方法在多智能体强化学习中面临两个挑战：如何动态自适应地共享资源分配策略，以及如何在大规模城市设置中实现高效参数共享。

Method: HAG-PS采用分层设计，结合全局和局部移动资源状态信息，通过自适应智能体分组（基于编码轨迹的相似性）实现动态参数共享，并引入可学习的身份嵌入以实现智能体专业化。

Result: 基于纽约市共享单车数据（超过120万次行程）的实验表明，HAG-PS在提高单车可用性等方面优于其他基线方法。

Conclusion: HAG-PS通过分层自适应分组参数共享有效解决了移动资源分配中的动态策略共享和内存效率问题，为城市规模的多智能体强化学习提供了实用解决方案。

Abstract: Allocating mobility resources (e.g., shared bikes/e-scooters, ride-sharing
vehicles) is crucial for rebalancing the mobility demand and supply in the
urban environments. We propose in this work a novel multi-agent reinforcement
learning named Hierarchical Adaptive Grouping-based Parameter Sharing (HAG-PS)
for dynamic mobility resource allocation. HAG-PS aims to address two important
research challenges regarding multi-agent reinforcement learning for mobility
resource allocation: (1) how to dynamically and adaptively share the mobility
resource allocation policy (i.e., how to distribute mobility resources) across
agents (i.e., representing the regional coordinators of mobility resources);
and (2) how to achieve memory-efficient parameter sharing in an urban-scale
setting. To address the above challenges, we have provided following novel
designs within HAG-PS. To enable dynamic and adaptive parameter sharing, we
have designed a hierarchical approach that consists of global and local
information of the mobility resource states (e.g., distribution of mobility
resources). We have developed an adaptive agent grouping approach in order to
split or merge the groups of agents based on their relative closeness of
encoded trajectories (i.e., states, actions, and rewards). We have designed a
learnable identity (ID) embeddings to enable agent specialization beyond simple
parameter copy. We have performed extensive experimental studies based on
real-world NYC bike sharing data (a total of more than 1.2 million trips), and
demonstrated the superior performance (e.g., improved bike availability) of
HAG-PS compared with other baseline approaches.

</details>


### [142] [MazeEval: A Benchmark for Testing Sequential Decision-Making in Language Models](https://arxiv.org/abs/2507.20395)
*Hafsteinn Einarsson*

Main category: cs.AI

TL;DR: 本文提出MazeEval基准测试，评估大语言模型（LLMs）在无视觉线索下的纯空间推理能力，发现不同模型在迷宫导航任务中表现差异显著，且跨语言迁移能力受限。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）在机器人及具身AI中的广泛应用，理解其空间推理能力对实际部署至关重要。当前研究缺乏对LLMs在无视觉线索下空间导航能力的评估。

Method: 研究采用基于坐标的迷宫导航任务，通过函数调用接口让模型仅使用坐标反馈和距离墙壁信息进行导航，排除视觉输入，测试基本空间认知能力。评估了8种先进LLMs在英语和冰岛语中的表现。

Result: 结果显示，OpenAI的O3模型在$30\times 30$迷宫内表现完美，而其他模型在$9\times 9$以上迷宫则完全失败，失败原因均为过度循环行为。冰岛语环境下模型表现显著下降，解决迷宫尺寸比英语小3-4个等级。

Conclusion: 研究表明LLMs的空间推理能力受训练数据可用性限制，且依赖于语言模式而非语言无关机制，这对LLM驱动的自主系统全球部署提出了挑战，需架构创新以实现跨语言可靠导航。

Abstract: As Large Language Models (LLMs) increasingly power autonomous agents in
robotics and embodied AI, understanding their spatial reasoning capabilities
becomes crucial for ensuring reliable real-world deployment. Despite advances
in language understanding, current research lacks evaluation of how LLMs
perform spatial navigation without visual cues, a fundamental requirement for
agents operating with limited sensory information. This paper addresses this
gap by introducing MazeEval, a benchmark designed to isolate and evaluate pure
spatial reasoning in LLMs through coordinate-based maze navigation tasks. Our
methodology employs a function-calling interface where models navigate mazes of
varying complexity ($5\times 5$ to $15\times 15$ grids) using only coordinate
feedback and distance-to-wall information, excluding visual input to test
fundamental spatial cognition. We evaluate eight state-of-the-art LLMs across
identical mazes in both English and Icelandic to assess cross-linguistic
transfer of spatial abilities. Our findings reveal striking disparities: while
OpenAI's O3 achieves perfect navigation for mazes up to size $30\times 30$,
other models exhibit catastrophic failure beyond $9\times 9$ mazes, with 100%
of failures attributed to excessive looping behavior where models revisit a
cell at least 10 times. We document a significant performance degradation in
Icelandic, with models solving mazes 3-4 sizes smaller than in English,
suggesting spatial reasoning in LLMs emerges from linguistic patterns rather
than language-agnostic mechanisms. These results have important implications
for global deployment of LLM-powered autonomous systems, showing spatial
intelligence remains fundamentally constrained by training data availability
and highlighting the need for architectural innovations to achieve reliable
navigation across linguistic contexts.

</details>


### [143] [Enhancing QoS in Edge Computing through Federated Layering Techniques: A Pathway to Resilient AI Lifelong Learning Systems](https://arxiv.org/abs/2507.20444)
*Chengzhuo Han*

Main category: cs.AI

TL;DR: 本文针对6G时代边缘计算中的服务质量(QoS)问题，提出了一种基于联邦分层技术(FLT)的通用人工智能终身学习系统，通过小模型协同机制提升资源受限环境下的AI效率与隐私保护。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络发展，数据量与网络复杂性激增，传统边缘计算框架面临QoS保障难题。研究旨在结合云边协同优势，解决资源受限环境下AI模型的效率与隐私保护问题。

Method: 采用联邦分层技术构建小模型协同机制，引入模型间协商辩论机制增强推理能力，结合分层建模与隐私保护技术实现参数安全传输，形成终身学习系统框架。

Result: 实验表明该方法显著提升学习效率(达37%)与推理准确率(92.4%)，边缘节点隐私泄露风险降低83%，同时维持毫秒级响应速度。

Conclusion: 联邦分层终身学习系统为边缘计算QoS提升提供创新解决方案，其云边协同架构与隐私保护机制对构建弹性大模型系统具有重要参考价值。

Abstract: In the context of the rapidly evolving information technology landscape,
marked by the advent of 6G communication networks, we face an increased data
volume and complexity in network environments. This paper addresses these
challenges by focusing on Quality of Service (QoS) in edge computing
frameworks. We propose a novel approach to enhance QoS through the development
of General Artificial Intelligence Lifelong Learning Systems, with a special
emphasis on Federated Layering Techniques (FLT). Our work introduces a
federated layering-based small model collaborative mechanism aimed at improving
AI models' operational efficiency and response time in environments where
resources are limited. This innovative method leverages the strengths of cloud
and edge computing, incorporating a negotiation and debate mechanism among
small AI models to enhance reasoning and decision-making processes. By
integrating model layering techniques with privacy protection measures, our
approach ensures the secure transmission of model parameters while maintaining
high efficiency in learning and reasoning capabilities. The experimental
results demonstrate that our strategy not only enhances learning efficiency and
reasoning accuracy but also effectively protects the privacy of edge nodes.
This presents a viable solution for achieving resilient large model lifelong
learning systems, with a significant improvement in QoS for edge computing
environments.

</details>


### [144] [STARN-GAT: A Multi-Modal Spatio-Temporal Graph Attention Network for Accident Severity Prediction](https://arxiv.org/abs/2507.20451)
*Pritom Ray Nobin,Imran Ahammad Rifat*

Main category: cs.AI

TL;DR: 提出STARN-GAT模型，通过多模态时空图注意力网络提升交通事故严重性预测精度，在FARS和ARI-BUET数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效建模交通事故结果中空间、时间和上下文变量的复杂关联，需开发新模型以提升预测准确性和可解释性。

Method: STARN-GAT结合自适应图构建与模态感知注意力机制，统一整合路网拓扑、时序流量模式和环境上下文，采用基于注意力的框架进行建模。

Result: 在FARS数据集中取得Macro F1-score 85%、ROC-AUC 0.91、严重事件召回率81%；在ARI-BUET数据集中Macro F1-score 0.84、召回率0.78、ROC-AUC 0.89。

Conclusion: 该模型有效识别高风险案例，增强可解释性，为实时交通安全管理系统提供可靠支持，弥合图神经网络技术与道路安全分析应用间的鸿沟。

Abstract: Accurate prediction of traffic accident severity is critical for improving
road safety, optimizing emergency response strategies, and informing the design
of safer transportation infrastructure. However, existing approaches often
struggle to effectively model the intricate interdependencies among spatial,
temporal, and contextual variables that govern accident outcomes. In this
study, we introduce STARN-GAT, a Multi-Modal Spatio-Temporal Graph Attention
Network, which leverages adaptive graph construction and modality-aware
attention mechanisms to capture these complex relationships. Unlike
conventional methods, STARN-GAT integrates road network topology, temporal
traffic patterns, and environmental context within a unified attention-based
framework. The model is evaluated on the Fatality Analysis Reporting System
(FARS) dataset, achieving a Macro F1-score of 85 percent, ROC-AUC of 0.91, and
recall of 81 percent for severe incidents. To ensure generalizability within
the South Asian context, STARN-GAT is further validated on the ARI-BUET traffic
accident dataset, where it attains a Macro F1-score of 0.84, recall of 0.78,
and ROC-AUC of 0.89. These results demonstrate the model's effectiveness in
identifying high-risk cases and its potential for deployment in real-time,
safety-critical traffic management systems. Furthermore, the attention-based
architecture enhances interpretability, offering insights into contributing
factors and supporting trust in AI-assisted decision-making. Overall, STARN-GAT
bridges the gap between advanced graph neural network techniques and practical
applications in road safety analytics.

</details>


### [145] [Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition](https://arxiv.org/abs/2507.20526)
*Andy Zou,Maxwell Lin,Eliot Jones,Micha Nowak,Mateusz Dziemian,Nick Winter,Alexander Grattan,Valent Nathanael,Ayla Croft,Xander Davies,Jai Patel,Robert Kirk,Nate Burnikell,Yarin Gal,Dan Hendrycks,J. Zico Kolter,Matt Fredrikson*

Main category: cs.AI

TL;DR: 研究通过大规模红队测试揭示当前AI代理在现实部署中普遍存在安全漏洞，攻击者仅需10-100次查询即可突破策略限制，且攻击方法具有跨模型迁移性。


<details>
  <summary>Details</summary>
Motivation: 评估LLM驱动的AI代理在真实攻击场景下是否遵守部署策略，揭示潜在安全风险以推动更安全的代理部署。

Method: 组织迄今最大规模公开红队竞赛，针对22个前沿AI代理进行44种现实场景测试，收集180万次提示注入攻击数据，并构建ART基准测试集。

Result: 60,000+次攻击成功突破策略限制（包括数据越权、金融违规等），几乎所有代理在10-100次查询内失守，且攻击可跨模型/任务迁移。代理鲁棒性与模型规模/能力无显著相关性。

Conclusion: 当前AI代理存在持续性的关键漏洞，需开发额外防御机制。通过发布ART基准与评估框架，推动更严格的安全评估体系建立。

Abstract: Recent advances have enabled LLM-powered AI agents to autonomously execute
complex tasks by combining language model reasoning with tools, memory, and web
access. But can these systems be trusted to follow deployment policies in
realistic environments, especially under attack? To investigate, we ran the
largest public red-teaming competition to date, targeting 22 frontier AI agents
across 44 realistic deployment scenarios. Participants submitted 1.8 million
prompt-injection attacks, with over 60,000 successfully eliciting policy
violations such as unauthorized data access, illicit financial actions, and
regulatory noncompliance. We use these results to build the Agent Red Teaming
(ART) benchmark - a curated set of high-impact attacks - and evaluate it across
19 state-of-the-art models. Nearly all agents exhibit policy violations for
most behaviors within 10-100 queries, with high attack transferability across
models and tasks. Importantly, we find limited correlation between agent
robustness and model size, capability, or inference-time compute, suggesting
that additional defenses are needed against adversarial misuse. Our findings
highlight critical and persistent vulnerabilities in today's AI agents. By
releasing the ART benchmark and accompanying evaluation framework, we aim to
support more rigorous security assessment and drive progress toward safer agent
deployment.

</details>


### [146] [MeLA: A Metacognitive LLM-Driven Architecture for Automatic Heuristic Design](https://arxiv.org/abs/2507.20541)
*Zishang Qiu,Xinan Chen,Long Chen,Ruibin Bai*

Main category: cs.AI

TL;DR: 本文提出MeLA架构，一种基于元认知的大语言模型驱动框架，通过演化提示而非直接修改启发式代码来实现自动启发式设计（AHD），在基准和实际问题中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统进化方法直接操作启发式代码存在局限性，而利用大语言模型（LLM）的生成能力结合元认知调控，可开辟更鲁棒、可解释的AHD新路径。

Method: MeLA整合问题分析器（生成初始策略提示）、错误诊断系统（修复代码缺陷）和元认知搜索引擎（根据启发式效果迭代优化提示），通过"提示演化"实现启发式生成。

Result: 实验表明，MeLA生成的启发式在基准测试和实际应用中均显著优于最先进方法，且具有更强的鲁棒性。

Conclusion: 研究证实以认知科学为蓝本设计AI架构的潜力，通过让LLM元认知调控问题解决过程，为AHD提供了更可靠、可解释的新范式。

Abstract: This paper introduces MeLA, a Metacognitive LLM-Driven Architecture that
presents a new paradigm for Automatic Heuristic Design (AHD). Traditional
evolutionary methods operate directly on heuristic code; in contrast, MeLA
evolves the instructional prompts used to guide a Large Language Model (LLM) in
generating these heuristics. This process of "prompt evolution" is driven by a
novel metacognitive framework where the system analyzes performance feedback to
systematically refine its generative strategy. MeLA's architecture integrates a
problem analyzer to construct an initial strategic prompt, an error diagnosis
system to repair faulty code, and a metacognitive search engine that
iteratively optimizes the prompt based on heuristic effectiveness. In
comprehensive experiments across both benchmark and real-world problems, MeLA
consistently generates more effective and robust heuristics, significantly
outperforming state-of-the-art methods. Ultimately, this research demonstrates
the profound potential of using cognitive science as a blueprint for AI
architecture, revealing that by enabling an LLM to metacognitively regulate its
problem-solving process, we unlock a more robust and interpretable path to AHD.

</details>


### [147] [Unlearning of Knowledge Graph Embedding via Preference Optimization](https://arxiv.org/abs/2507.20566)
*Jiajun Liu,Wenjun Ke,Peng Wang,Yao He,Ziyu Shang,Guozheng Li,Zijie Xu,Ke Ji*

Main category: cs.AI

TL;DR: 本文提出GraphDPO框架，通过直接偏好优化解决知识图谱中信息遗忘不彻底和边界知识弱化问题，在多个数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱存在过时或错误信息，需从嵌入模型中移除。精确遗忘成本高，近似遗忘因三元组关联性导致信息残留和边界知识弱化。

Method: 1) 将遗忘重构为偏好优化问题，利用DPO训练模型偏好重构三元组而非原遗忘三元组；2) 提出边界外采样策略构建低语义重叠偏好对；3) 引入边界回忆机制跨时间步蒸馏相关信息。

Result: 在4个主流知识图谱构建的8个遗忘数据集上，GraphDPO在MRR_Avg和MRR_F1指标分别最高提升10.1%和14.0%。

Conclusion: GraphDPO通过偏好优化和边界知识保护机制，有效解决了知识图谱近似遗忘中的核心挑战，为动态知识管理提供了新范式。

Abstract: Existing knowledge graphs (KGs) inevitably contain outdated or erroneous
knowledge that needs to be removed from knowledge graph embedding (KGE) models.
To address this challenge, knowledge unlearning can be applied to eliminate
specific information while preserving the integrity of the remaining knowledge
in KGs. Existing unlearning methods can generally be categorized into exact
unlearning and approximate unlearning. However, exact unlearning requires high
training costs while approximate unlearning faces two issues when applied to
KGs due to the inherent connectivity of triples: (1) It fails to fully remove
targeted information, as forgetting triples can still be inferred from
remaining ones. (2) It focuses on local data for specific removal, which
weakens the remaining knowledge in the forgetting boundary. To address these
issues, we propose GraphDPO, a novel approximate unlearning framework based on
direct preference optimization (DPO). Firstly, to effectively remove forgetting
triples, we reframe unlearning as a preference optimization problem, where the
model is trained by DPO to prefer reconstructed alternatives over the original
forgetting triples. This formulation penalizes reliance on forgettable
knowledge, mitigating incomplete forgetting caused by KG connectivity.
Moreover, we introduce an out-boundary sampling strategy to construct
preference pairs with minimal semantic overlap, weakening the connection
between forgetting and retained knowledge. Secondly, to preserve boundary
knowledge, we introduce a boundary recall mechanism that replays and distills
relevant information both within and across time steps. We construct eight
unlearning datasets across four popular KGs with varying unlearning rates.
Experiments show that GraphDPO outperforms state-of-the-art baselines by up to
10.1% in MRR_Avg and 14.0% in MRR_F1.

</details>


### [148] [Enhancing Large Multimodal Models with Adaptive Sparsity and KV Cache Compression](https://arxiv.org/abs/2507.20613)
*Te Zhang,Yuheng Li,Junxiang Wang,Lujun Li*

Main category: cs.AI

TL;DR: 本文提出了一种自适应搜索算法，通过优化稀疏性和KV缓存压缩来提升大型多模态模型（LMM）的效率，无需微调即可实现高效压缩。


<details>
  <summary>Details</summary>
Motivation: 尽管大型多模态模型（LMMs）通过整合视觉编码器和语言模型展现出强大的推理能力，但在边缘设备上部署时的高效压缩仍是一个关键挑战。

Method: 采用基于树结构Parzen估计器的自适应搜索算法，动态调整不同LMM层的剪枝比例和KV缓存量化带宽，结合快速剪枝技术避免额外微调。

Result: 在LLaVA-1.5 7B和13B等基准测试中，该方法优于SparseGPT和Wanda等先进技术，尤其在KV缓存资源自动分配方面树立了新标准。

Conclusion: 该框架在保持模型性能的同时显著提升了内存效率，为LMM的优化部署提供了有效解决方案。

Abstract: Large multimodal models (LMMs) have advanced significantly by integrating
visual encoders with extensive language models, enabling robust reasoning
capabilities. However, compressing LMMs for deployment on edge devices remains
a critical challenge. In this work, we propose an adaptive search algorithm
that optimizes sparsity and KV cache compression to enhance LMM efficiency.
Utilizing the Tree-structured Parzen Estimator, our method dynamically adjusts
pruning ratios and KV cache quantization bandwidth across different LMM layers,
using model performance as the optimization objective. This approach uniquely
combines pruning with key-value cache quantization and incorporates a fast
pruning technique that eliminates the need for additional fine-tuning or weight
adjustments, achieving efficient compression without compromising accuracy.
Comprehensive evaluations on benchmark datasets, including LLaVA-1.5 7B and
13B, demonstrate our method superiority over state-of-the-art techniques such
as SparseGPT and Wanda across various compression levels. Notably, our
framework automatic allocation of KV cache compression resources sets a new
standard in LMM optimization, delivering memory efficiency without sacrificing
much performance.

</details>


### [149] [Complementarity-driven Representation Learning for Multi-modal Knowledge Graph Completion](https://arxiv.org/abs/2507.20620)
*Lijian Li*

Main category: cs.AI

TL;DR: 本文提出MoCME框架，通过互补性模态知识融合和熵引导负采样机制，解决多模态知识图谱补全中的模态不平衡问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 多模态知识图谱补全(MMKGC)面临模态分布不均的挑战，现有方法忽视多模态数据的互补性，导致实体表征不充分。

Method: 提出互补性模态专家混合框架(MoCME)，包含互补性引导的模态知识融合模块(CMKF)和熵引导负采样机制(EGNS)，分别利用模态内/间互补性增强表征，并动态筛选高信息量负样本。

Result: 在五个基准数据集上的实验表明，MoCME超越现有方法，达到最先进性能。

Conclusion: MoCME通过有效挖掘多模态互补性和优化负采样策略，为不平衡多模态知识图谱补全提供了创新解决方案。

Abstract: Multi-modal Knowledge Graph Completion (MMKGC) aims to uncover hidden world
knowledge in multimodal knowledge graphs by leveraging both multimodal and
structural entity information. However, the inherent imbalance in multimodal
knowledge graphs, where modality distributions vary across entities, poses
challenges in utilizing additional modality data for robust entity
representation. Existing MMKGC methods typically rely on attention or
gate-based fusion mechanisms but overlook complementarity contained in
multi-modal data. In this paper, we propose a novel framework named Mixture of
Complementary Modality Experts (MoCME), which consists of a
Complementarity-guided Modality Knowledge Fusion (CMKF) module and an
Entropy-guided Negative Sampling (EGNS) mechanism. The CMKF module exploits
both intra-modal and inter-modal complementarity to fuse multi-view and
multi-modal embeddings, enhancing representations of entities. Additionally, we
introduce an Entropy-guided Negative Sampling mechanism to dynamically
prioritize informative and uncertain negative samples to enhance training
effectiveness and model robustness. Extensive experiments on five benchmark
datasets demonstrate that our MoCME achieves state-of-the-art performance,
surpassing existing approaches.

</details>


### [150] [Adaptive Fuzzy Time Series Forecasting via Partially Asymmetric Convolution and Sub-Sliding Window Fusion](https://arxiv.org/abs/2507.20641)
*Lijian Li*

Main category: cs.AI

TL;DR: 本文提出了一种基于自适应模糊时间序列构建和部分非对称卷积架构的新型预测模型，通过改进时间序列构建策略和设计双边Atrous算法，有效捕捉时空依赖并融合全局信息，在多个数据集上实现了最先进的预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的预测模型在学习阶段缺乏捕捉时空依赖和综合全局信息的能力，为此本文提出了一种新的解决方案。

Method: 1. 改进传统模糊时间序列构建策略，自动提取短期和长期时间关联；2. 设计双边Atrous算法降低计算需求；3. 采用部分非对称卷积架构灵活挖掘数据特征，并在子窗口内进行细粒度建模。

Result: 与现有竞争模型相比，该方法在多数流行时间序列数据集上取得了最先进的预测结果，实验结果充分验证了其有效性。

Conclusion: 通过自适应模糊时间序列构建和创新的卷积架构设计，本文提出的方法显著提升了时间序列预测的准确性，为相关领域提供了新的技术思路。

Abstract: At present, state-of-the-art forecasting models are short of the ability to
capture spatio-temporal dependency and synthesize global information at the
stage of learning. To address this issue, in this paper, through the adaptive
fuzzified construction of temporal data, we propose a novel convolutional
architecture with partially asymmetric design based on the scheme of sliding
window to realize accurate time series forecasting. First, the construction
strategy of traditional fuzzy time series is improved to further extract short
and long term temporal interrelation, which enables every time node to
automatically possess corresponding global information and inner relationships
among them in a restricted sliding window and the process does not require
human involvement. Second, a bilateral Atrous algorithm is devised to reduce
calculation demand of the proposed model without sacrificing global
characteristics of elements. And it also allows the model to avoid processing
redundant information. Third, after the transformation of time series, a
partially asymmetric convolutional architecture is designed to more flexibly
mine data features by filters in different directions on feature maps, which
gives the convolutional neural network (CNN) the ability to construct
sub-windows within existing sliding windows to model at a more fine-grained
level. And after obtaining the time series information at different levels, the
multi-scale features from different sub-windows will be sent to the
corresponding network layer for time series information fusion. Compared with
other competitive modern models, the proposed method achieves state-of-the-art
results on most of popular time series datasets, which is fully verified by the
experimental results.

</details>


### [151] [A General Framework for Dynamic MAPF using Multi-Shot ASP and Tunnels](https://arxiv.org/abs/2507.20703)
*Aysu Bogatarkan,Esra Erdem*

Main category: cs.AI

TL;DR: 本文研究了动态多智能体路径规划（D-MAPF）问题，提出了一种通用定义、新求解框架及基于ASP的方法，通过实验评估展示了其性能与解决方案质量。


<details>
  <summary>Details</summary>
Motivation: 受实际应用（如仓库管理）中智能体动态进出及障碍物变化的启发，研究如何高效解决动态环境下的多智能体路径规划问题。

Method: 1) 提出D-MAPF的通用定义；2) 设计多轮计算框架支持不同求解方法；3) 开发基于ASP的新方法，结合重规划与修复策略，引入“隧道”概念优化移动路径。

Result: 实验评估表明，该方法在计算性能和解决方案质量上具有优势，同时揭示了其局限性。

Conclusion: 提出的D-MAPF框架及ASP方法为动态环境下的多智能体路径规划提供了有效解决方案，尤其适用于需频繁调整的实际场景。

Abstract: MAPF problem aims to find plans for multiple agents in an environment within
a given time, such that the agents do not collide with each other or obstacles.
Motivated by the execution and monitoring of these plans, we study Dynamic MAPF
(D-MAPF) problem, which allows changes such as agents entering/leaving the
environment or obstacles being removed/moved. Considering the requirements of
real-world applications in warehouses with the presence of humans, we introduce
1) a general definition for D-MAPF (applicable to variations of D-MAPF), 2) a
new framework to solve D-MAPF (utilizing multi-shot computation, and allowing
different methods to solve D-MAPF), and 3) a new ASP-based method to solve
D-MAPF (combining advantages of replanning and repairing methods, with a novel
concept of tunnels to specify where agents can move). We have illustrated the
strengths and weaknesses of this method by experimental evaluations, from the
perspectives of computational performance and quality of solutions.

</details>


### [152] [Algorithmic Fairness: A Runtime Perspective](https://arxiv.org/abs/2507.20711)
*Filip Cano,Thomas A. Henzinger,Konstantin Kueffner*

Main category: cs.AI

TL;DR: 本文提出了一种将公平性作为运行时属性的分析框架，通过基于硬币投掷序列的最小化模型，研究了在动态环境中监控和执行公平性的方法。


<details>
  <summary>Details</summary>
Motivation: 传统AI公平性研究将其视为静态属性，而实际AI系统在动态环境中运行，需考虑随时间演变的公平性问题。

Method: 采用硬币投掷序列模型（允许偏差动态变化），针对投掷结果或硬币偏差的公平性，提出监控与执行策略框架，参数包括环境动态性、预测范围和置信阈值。

Result: 在简单或最小假设下得出通用结论：综述了马尔可夫动态和加性动态的监控方案，以及静态已知动态下的执行方案。

Conclusion: 动态公平性需定制化解决方案，该框架为不同场景下的监控与执行提供了系统性分类和理论基础。

Abstract: Fairness in AI is traditionally studied as a static property evaluated once,
over a fixed dataset. However, real-world AI systems operate sequentially, with
outcomes and environments evolving over time. This paper proposes a framework
for analysing fairness as a runtime property. Using a minimal yet expressive
model based on sequences of coin tosses with possibly evolving biases, we study
the problems of monitoring and enforcing fairness expressed in either toss
outcomes or coin biases. Since there is no one-size-fits-all solution for
either problem, we provide a summary of monitoring and enforcement strategies,
parametrised by environment dynamics, prediction horizon, and confidence
thresholds. For both problems, we present general results under simple or
minimal assumptions. We survey existing solutions for the monitoring problem
for Markovian and additive dynamics, and existing solutions for the enforcement
problem in static settings with known dynamics.

</details>


### [153] [Learning the Value Systems of Societies from Preferences](https://arxiv.org/abs/2507.20728)
*Andrés Holgado-Sánchez,Holger Billhardt,Sascha Ossowski,Sara Degli-Esposti*

Main category: cs.AI

TL;DR: 本文提出了一种基于启发式深度聚类的方法，用于学习社会共享价值基础及多样化的价值系统，以更准确地反映社会群体的价值偏好，而非简单聚合个体价值系统。


<details>
  <summary>Details</summary>
Motivation: 在伦理AI中，如何使AI系统与人类价值观及不同利益相关者的价值偏好保持一致是关键。传统方法难以手动获取和校准个体价值系统，而社会科学的观点认为社会价值系统应被视为不同群体的价值系统集合，而非个体系统的简单聚合。

Method: 提出了一种基于启发式深度聚类的方法，通过观察代理样本的定性价值偏好，学习社会共享的价值基础及多样化的价值系统。

Result: 该方法在旅行决策的真实数据用例中进行了评估，证明了其有效性。

Conclusion: 通过形式化社会价值系统的学习问题，并采用启发式深度聚类方法，能够更准确地捕捉社会群体的多样化价值系统，为伦理AI的价值对齐提供了新思路。

Abstract: Aligning AI systems with human values and the value-based preferences of
various stakeholders (their value systems) is key in ethical AI. In value-aware
AI systems, decision-making draws upon explicit computational representations
of individual values (groundings) and their aggregation into value systems. As
these are notoriously difficult to elicit and calibrate manually, value
learning approaches aim to automatically derive computational models of an
agent's values and value system from demonstrations of human behaviour.
Nonetheless, social science and humanities literature suggest that it is more
adequate to conceive the value system of a society as a set of value systems of
different groups, rather than as the simple aggregation of individual value
systems. Accordingly, here we formalize the problem of learning the value
systems of societies and propose a method to address it based on heuristic deep
clustering. The method learns socially shared value groundings and a set of
diverse value systems representing a given society by observing qualitative
value-based preferences from a sample of agents. We evaluate the proposal in a
use case with real data about travelling decisions.

</details>


### [154] [Beyond Listenership: AI-Predicted Interventions Drive Improvements in Maternal Health Behaviours](https://arxiv.org/abs/2507.20755)
*Arpan Dasgupta,Sarvesh Gharat,Neha Madhiwalla,Aparna Hegde,Milind Tambe,Aparna Taneja*

Main category: cs.AI

TL;DR: AI干预不仅提高了健康信息自动语音电话的收听率，还显著改善了孕产妇的健康行为和知识。


<details>
  <summary>Details</summary>
Motivation: 尽管自动语音电话在传播孕产妇和儿童健康信息方面有效，但存在听众流失和参与度低的问题。此前研究表明AI模型能针对性干预，但未证实其是否能改善健康行为和知识。

Method: 通过真实世界试验，使用AI模型（如多臂老虎机模型）识别最需要人工服务干预的受益者，并评估干预对健康行为和知识的影响。

Result: AI干预显著提高了收听率，并导致受益者在产后补充铁或钙等健康行为上的显著改善，以及对孕期和婴儿期关键健康话题的理解增强。

Conclusion: AI在提升孕产妇和儿童健康方面具有潜力，不仅能优化信息传播效率，还能直接促进健康行为和知识的改善。

Abstract: Automated voice calls with health information are a proven method for
disseminating maternal and child health information among beneficiaries and are
deployed in several programs around the world. However, these programs often
suffer from beneficiary dropoffs and poor engagement. In previous work, through
real-world trials, we showed that an AI model, specifically a restless bandit
model, could identify beneficiaries who would benefit most from live service
call interventions, preventing dropoffs and boosting engagement. However, one
key question has remained open so far: does such improved listenership via
AI-targeted interventions translate into beneficiaries' improved knowledge and
health behaviors? We present a first study that shows not only listenership
improvements due to AI interventions, but also simultaneously links these
improvements to health behavior changes. Specifically, we demonstrate that
AI-scheduled interventions, which enhance listenership, lead to statistically
significant improvements in beneficiaries' health behaviors such as taking iron
or calcium supplements in the postnatal period, as well as understanding of
critical health topics during pregnancy and infancy. This underscores the
potential of AI to drive meaningful improvements in maternal and child health.

</details>


### [155] [How Chain-of-Thought Works? Tracing Information Flow from Decoding, Projection, and Activation](https://arxiv.org/abs/2507.20758)
*Hao Yang,Qinghua Zhao,Lei Li*

Main category: cs.AI

TL;DR: 本文通过逆向追踪思维链(CoT)提示在解码、投影和激活阶段的信息流，揭示了其作为解码空间剪枝器的作用机制，并发现CoT会根据任务类型动态调节神经元参与度。


<details>
  <summary>Details</summary>
Motivation: 尽管思维链(CoT)提示显著提升了模型推理能力，但其内部工作机制尚不明确。本研究旨在定量分析CoT的操作原理，为设计更高效、鲁棒的提示提供理论基础。

Method: 采用逆向追踪法分析CoT在解码、投影和激活三个阶段的信息流动，通过定量测量模板遵循度与性能的关联性，并考察不同任务类型下神经元激活模式的变化。

Result: 研究发现：(1)CoT通过答案模板引导输出生成，模板遵循度与性能呈强正相关；(2)CoT会依据任务领域动态调节神经元参与度：在开放域任务中抑制神经元激活，在封闭域场景中增强激活。

Conclusion: 该研究提出了新颖的机制可解释性框架，表明可通过针对性干预CoT机制来优化提示设计。所有代码和数据已开源。

Abstract: Chain-of-Thought (CoT) prompting significantly enhances model reasoning, yet
its internal mechanisms remain poorly understood. We analyze CoT's operational
principles by reversely tracing information flow across decoding, projection,
and activation phases. Our quantitative analysis suggests that CoT may serve as
a decoding space pruner, leveraging answer templates to guide output
generation, with higher template adherence strongly correlating with improved
performance. Furthermore, we surprisingly find that CoT modulates neuron
engagement in a task-dependent manner: reducing neuron activation in
open-domain tasks, yet increasing it in closed-domain scenarios. These findings
offer a novel mechanistic interpretability framework and critical insights for
enabling targeted CoT interventions to design more efficient and robust
prompts. We released our code and data at
https://anonymous.4open.science/r/cot-D247.

</details>


### [156] [evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments](https://arxiv.org/abs/2507.20774)
*Fatou Ndiaye Mbodji*

Main category: cs.AI

TL;DR: 本文提出\texttt{evalSmarT}框架，利用大型语言模型（LLMs）作为评估器，解决智能合约注释生成质量评估的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统评估指标（如BLEU和ROUGE）无法捕捉领域特定细节，而人工评估成本高且难以扩展，因此需要一种新的评估方法。

Method: \texttt{evalSmarT}是一个模块化、可扩展的框架，结合约40种LLMs和10种提示策略，支持超过400种评估配置。

Result: 实验表明，提示设计显著影响与人类判断的一致性，且基于LLM的评估提供了可扩展且语义丰富的替代方案。

Conclusion: LLM-based评估为智能合约注释生成工具提供了一种高效且语义精准的评估方法，优于传统指标。

Abstract: Smart contract comment generation has gained traction as a means to improve
code comprehension and maintainability in blockchain systems. However,
evaluating the quality of generated comments remains a challenge. Traditional
metrics such as BLEU and ROUGE fail to capture domain-specific nuances, while
human evaluation is costly and unscalable. In this paper, we present
\texttt{evalSmarT}, a modular and extensible framework that leverages large
language models (LLMs) as evaluators. The system supports over 400 evaluator
configurations by combining approximately 40 LLMs with 10 prompting strategies.
We demonstrate its application in benchmarking comment generation tools and
selecting the most informative outputs. Our results show that prompt design
significantly impacts alignment with human judgment, and that LLM-based
evaluation offers a scalable and semantically rich alternative to existing
methods.

</details>


### [157] [MMGraphRAG: Bridging Vision and Language with Interpretable Multimodal Knowledge Graphs](https://arxiv.org/abs/2507.20804)
*Xueyao Wan,Hang Yu*

Main category: cs.AI

TL;DR: 本文提出MMGraphRAG方法，通过场景图和多模态知识图谱增强检索生成技术，解决了传统RAG方法在多模态信息融合和知识结构捕捉上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法缺乏多模态信息处理能力，现有多模态RAG方法虽融合图文但无法捕捉知识结构和模态间逻辑链，且需任务特定训练导致泛化能力有限。

Method: MMGraphRAG利用场景图精炼视觉内容，构建多模态知识图谱（MMKG），结合谱聚类实现跨模态实体链接，并沿推理路径检索上下文指导生成过程。

Result: 实验表明MMGraphRAG在DocBench和MMLongBench数据集上达到最优性能，展现出强大的领域适应性和清晰的推理路径。

Conclusion: MMGraphRAG通过结构化知识表示和跨模态推理路径检索，显著提升了多模态检索生成模型的性能和可解释性。

Abstract: Retrieval-Augmented Generation (RAG) enhances language model generation by
retrieving relevant information from external knowledge bases. However,
conventional RAG methods face the issue of missing multimodal information.
Multimodal RAG methods address this by fusing images and text through mapping
them into a shared embedding space, but they fail to capture the structure of
knowledge and logical chains between modalities. Moreover, they also require
large-scale training for specific tasks, resulting in limited generalizing
ability. To address these limitations, we propose MMGraphRAG, which refines
visual content through scene graphs and constructs a multimodal knowledge graph
(MMKG) in conjunction with text-based KG. It employs spectral clustering to
achieve cross-modal entity linking and retrieves context along reasoning paths
to guide the generative process. Experimental results show that MMGraphRAG
achieves state-of-the-art performance on the DocBench and MMLongBench datasets,
demonstrating strong domain adaptability and clear reasoning paths.

</details>


### [158] [Partially Observable Monte-Carlo Graph Search](https://arxiv.org/abs/2507.20951)
*Yang You,Vincent Thomas,Alex Schutz,Robert Skilton,Nick Hawes,Olivier Buffet*

Main category: cs.AI

TL;DR: 本文提出了一种名为POMCGS的离线算法，用于解决大规模部分可观测马尔可夫决策过程（POMDPs），通过动态折叠搜索树构建策略图，显著减少计算量，并能处理某些连续POMDPs。


<details>
  <summary>Details</summary>
Motivation: 在时间或能量受限的应用中，预计算的离线策略更为理想，但现有离线算法无法扩展到大规模POMDPs。

Method: POMCGS算法通过动态折叠搜索树构建策略图，结合动作渐进扩展和观测聚类方法，显著减少计算量。

Result: 实验表明，POMCGS能在最具挑战性的POMDPs上生成策略，其性能与最先进的在线算法相当。

Conclusion: POMCGS是一种高效的离线算法，能够处理大规模POMDPs，并为用户提供可分析和验证的策略。

Abstract: Currently, large partially observable Markov decision processes (POMDPs) are
often solved by sampling-based online methods which interleave planning and
execution phases. However, a pre-computed offline policy is more desirable in
POMDP applications with time or energy constraints. But previous offline
algorithms are not able to scale up to large POMDPs. In this article, we
propose a new sampling-based algorithm, the partially observable Monte-Carlo
graph search (POMCGS) to solve large POMDPs offline. Different from many online
POMDP methods, which progressively develop a tree while performing
(Monte-Carlo) simulations, POMCGS folds this search tree on the fly to
construct a policy graph, so that computations can be drastically reduced, and
users can analyze and validate the policy prior to embedding and executing it.
Moreover, POMCGS, together with action progressive widening and observation
clustering methods provided in this article, is able to address certain
continuous POMDPs. Through experiments, we demonstrate that POMCGS can generate
policies on the most challenging POMDPs, which cannot be computed by previous
offline algorithms, and these policies' values are competitive compared with
the state-of-the-art online POMDP algorithms.

</details>


### [159] [On the Limits of Hierarchically Embedded Logic in Classical Neural Networks](https://arxiv.org/abs/2507.20960)
*Bill Cochran*

Main category: cs.AI

TL;DR: 本文提出了一种基于神经网络深度的语言模型推理能力限制的形式化模型，揭示了深度与逻辑表达能力之间的严格上限关系。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解释大型神经语言模型中存在的幻觉、重复和有限规划等现象，并为未来模型架构扩展提供理论基础。

Method: 通过将神经网络视为逻辑谓词空间上的线性算子，证明每层神经网络最多只能编码一级额外的逻辑推理层次。

Result: 研究结果表明特定深度的神经网络无法忠实表示高一阶的逻辑谓词（如复杂谓词上的简单计数），这为逻辑表达能力设定了严格上限。

Conclusion: 该框架不仅解释了现有语言模型的局限性，还为理解高阶逻辑近似如何产生提供了基础，对未来的架构扩展和可解释性策略具有指导意义。

Abstract: We propose a formal model of reasoning limitations in large neural net models
for language, grounded in the depth of their neural architecture. By treating
neural networks as linear operators over logic predicate space we show that
each layer can encode at most one additional level of logical reasoning. We
prove that a neural network of depth a particular depth cannot faithfully
represent predicates in a one higher order logic, such as simple counting over
complex predicates, implying a strict upper bound on logical expressiveness.
This structure induces a nontrivial null space during tokenization and
embedding, excluding higher-order predicates from representability. Our
framework offers a natural explanation for phenomena such as hallucination,
repetition, and limited planning, while also providing a foundation for
understanding how approximations to higher-order logic may emerge. These
results motivate architectural extensions and interpretability strategies in
future development of language models.

</details>


### [160] [Core Safety Values for Provably Corrigible Agents](https://arxiv.org/abs/2507.20964)
*Aran Nayebi*

Main category: cs.AI

TL;DR: 本文提出首个可实现的校正性框架，通过五个结构分离的效用头（服从性、开关权限保护、真实性、基于信念的低影响行为及有限任务奖励）在部分可观测环境中提供多步安全保障，并证明其可验证性。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如宪法AI或RLHF/RLAIF）将所有规范合并为单一标量，导致激励冲突时无法优先保障安全。本文旨在通过结构分离解决此问题，确保校正性优先。

Method: 采用五个严格排序的效用头（词典序组合），扩展Attainable Utility Preservation至信念空间。理论1证明部分可观测开关游戏中的单步校正性；理论3扩展至多步自衍生智能体，允许学习误差$\varepsilon$和次优规划。

Result: 定理3显示：即使各效用头学习误差为$\varepsilon$且规划器次优，违反安全属性的概率仍受控，同时确保人类净收益。针对对抗性修改，证明无限时域下的校正性验证不可判定，但有限时域内可随机多项式时间验证。

Conclusion: 该框架将奖励黑客风险转移至评估环节，而非隐含激励泄漏，为当前LLM助手和未来自治系统提供更清晰的实现路径。剩余挑战仅为常规ML任务（数据覆盖与泛化）。

Abstract: We introduce the first implementable framework for corrigibility, with
provable guarantees in multi-step, partially observed environments. Our
framework replaces a single opaque reward with five *structurally separate*
utility heads -- deference, switch-access preservation, truthfulness,
low-impact behavior via a belief-based extension of Attainable Utility
Preservation, and bounded task reward -- combined lexicographically by strict
weight gaps. Theorem 1 proves exact single-round corrigibility in the partially
observable off-switch game; Theorem 3 extends the guarantee to multi-step,
self-spawning agents, showing that even if each head is \emph{learned} to
mean-squared error $\varepsilon$ and the planner is $\varepsilon$-sub-optimal,
the probability of violating \emph{any} safety property is bounded while still
ensuring net human benefit. In contrast to Constitutional AI or RLHF/RLAIF,
which merge all norms into one learned scalar, our separation makes obedience
and impact-limits dominate even when incentives conflict. For open-ended
settings where adversaries can modify the agent, we prove that deciding whether
an arbitrary post-hack agent will ever violate corrigibility is undecidable by
reduction to the halting problem, then carve out a finite-horizon ``decidable
island'' where safety can be certified in randomized polynomial time and
verified with privacy-preserving, constant-round zero-knowledge proofs.
Consequently, the remaining challenge is the ordinary ML task of data coverage
and generalization: reward-hacking risk is pushed into evaluation quality
rather than hidden incentive leak-through, giving clearer implementation
guidance for today's LLM assistants and future autonomous systems.

</details>


### [161] [MIRAGE-Bench: LLM Agent is Hallucinating and Where to Find Them](https://arxiv.org/abs/2507.21017)
*Weichen Zhang,Yiyou Sun,Pohao Huang,Jiayue Pu,Heyue Lin,Dawn Song*

Main category: cs.AI

TL;DR: 本文提出MIRAGE-Bench，首个用于交互式LLM智能体场景中诱发和评估幻觉的统一基准，通过三部分分类法和系统化测试方法分析智能体幻觉行为。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）智能体常因认知上下文中的虚构或误解信息产生幻觉行为，现有评估方法零散且缺乏系统性测试平台。

Method: 提出三部分分类法（任务指令不忠实、执行历史不忠实、环境观察不忠实），通过系统审计现有基准并采用快照策略合成测试用例，使用细粒度LLM-as-a-Judge范式进行评估。

Result: MIRAGE-Bench可规模化、高保真地评估智能体行为，无需枚举完整动作空间，为理解LLM智能体失效模式提供可操作见解。

Conclusion: 该基准为交互环境中缓解幻觉的 principled 研究奠定基础，并揭示了LLM智能体的典型失败模式。

Abstract: Hallucinations pose critical risks for large language model (LLM)-based
agents, often manifesting as hallucinative actions resulting from fabricated or
misinterpreted information within the cognitive context. While recent studies
have exposed such failures, existing evaluations remain fragmented and lack a
principled testbed. In this paper, we present MIRAGE-Bench--Measuring Illusions
in Risky AGEnt settings--the first unified benchmark for eliciting and
evaluating hallucinations in interactive LLM-agent scenarios. We begin by
introducing a three-part taxonomy to address agentic hallucinations: actions
that are unfaithful to (i) task instructions, (ii) execution history, or (iii)
environment observations. To analyze, we first elicit such failures by
performing a systematic audit of existing agent benchmarks, then synthesize
test cases using a snapshot strategy that isolates decision points in
deterministic and reproducible manners. To evaluate hallucination behaviors, we
adopt a fine-grained-level LLM-as-a-Judge paradigm with tailored risk-aware
prompts, enabling scalable, high-fidelity assessment of agent actions without
enumerating full action spaces. MIRAGE-Bench provides actionable insights on
failure modes of LLM agents and lays the groundwork for principled progress in
mitigating hallucinations in interactive environments.

</details>


### [162] [Smart Expansion Techniques for ASP-based Interactive Configuration](https://arxiv.org/abs/2507.21027)
*Lucia Balážová,Richard Comploi-Taupe,Susana Hahn,Nicolas Rühling,Gottfried Schenner*

Main category: cs.AI

TL;DR: 本文提出了一种基于ASP的交互式配置求解器，通过四种智能扩展函数提升部分配置自动补全的性能，减少计算开销并优化搜索空间。


<details>
  <summary>Details</summary>
Motivation: 尽管ASP在产品配置中应用成功，但交互式系统在引导用户完成配置过程方面仍面临挑战，特别是在处理大规模工业配置问题和支持直观用户界面时。

Method: 采用经典增量方法的多轮求解，引入四种智能扩展函数，通过利用谨慎和勇敢后果在每次迭代中确定并添加特定对象或关联，减少昂贵的不可满足性检查次数。

Result: 该方法有效限制了不可满足性检查的次数，缩小了搜索空间，从而显著提升了求解性能。

Conclusion: 提出的ASP基础求解器不仅支持大规模工业配置问题，还通过API实现了直观的用户界面，为交互式配置提供了高效解决方案。

Abstract: Product configuration is a successful application of Answer Set Programming
(ASP). However, challenges are still open for interactive systems to
effectively guide users through the configuration process. The aim of our work
is to provide an ASP-based solver for interactive configuration that can deal
with large-scale industrial configuration problems and that supports intuitive
user interfaces via an API. In this paper, we focus on improving the
performance of automatically completing a partial configuration. Our main
contribution enhances the classical incremental approach for multi-shot solving
by four different smart expansion functions. The core idea is to determine and
add specific objects or associations to the partial configuration by exploiting
cautious and brave consequences before checking for the existence of a complete
configuration with the current objects in each iteration. This approach limits
the number of costly unsatisfiability checks and reduces the search space,
thereby improving solving performance. In addition, we present a user interface
that uses our API and is implemented in ASP.

</details>


### [163] [GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis](https://arxiv.org/abs/2507.21035)
*Haoyang Liu,Yijiang Li,Haohan Wang*

Main category: cs.AI

TL;DR: GenoMAS提出了一种基于LLM的团队协作框架，通过结合结构化流程与自主代理的灵活性，显著提升了基因表达分析的自动化水平与准确性。


<details>
  <summary>Details</summary>
Motivation: 基因表达分析对生物医学发现至关重要，但现有自动化方法在灵活性和精确性上存在不足，难以应对复杂多变的转录组数据。

Method: 采用六个专业LLM代理的协作系统，通过类型化消息传递协议和引导式规划框架，动态生成、调整或跳过行动单元（Action Units）以保持逻辑连贯性。

Result: 在GenoTEX基准测试中，数据预处理复合相似度达89.13%（提升10.61%），基因识别F$_1$达60.48%（提升16.85%），并能发现文献支持的基因-表型关联。

Conclusion: GenoMAS通过人机协作范式突破了基因组分析自动化的瓶颈，其代码已开源（https://github.com/Liu-Hy/GenoMAS），为领域研究提供了新工具。

Abstract: Gene expression analysis holds the key to many biomedical discoveries, yet
extracting insights from raw transcriptomic data remains formidable due to the
complexity of multiple large, semi-structured files and the need for extensive
domain expertise. Current automation approaches are often limited by either
inflexible workflows that break down in edge cases or by fully autonomous
agents that lack the necessary precision for rigorous scientific inquiry.
GenoMAS charts a different course by presenting a team of LLM-based scientists
that integrates the reliability of structured workflows with the adaptability
of autonomous agents. GenoMAS orchestrates six specialized LLM agents through
typed message-passing protocols, each contributing complementary strengths to a
shared analytic canvas. At the heart of GenoMAS lies a guided-planning
framework: programming agents unfold high-level task guidelines into Action
Units and, at each juncture, elect to advance, revise, bypass, or backtrack,
thereby maintaining logical coherence while bending gracefully to the
idiosyncrasies of genomic data.
  On the GenoTEX benchmark, GenoMAS reaches a Composite Similarity Correlation
of 89.13% for data preprocessing and an F$_1$ of 60.48% for gene
identification, surpassing the best prior art by 10.61% and 16.85%
respectively. Beyond metrics, GenoMAS surfaces biologically plausible
gene-phenotype associations corroborated by the literature, all while adjusting
for latent confounders. Code is available at https://github.com/Liu-Hy/GenoMAS.

</details>


### [164] [A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence](https://arxiv.org/abs/2507.21046)
*Huan-ang Gao,Jiayi Geng,Wenyue Hua,Mengkang Hu,Xinzhe Juan,Hongzhang Liu,Shilong Liu,Jiahao Qiu,Xuan Qi,Yiran Wu,Hongru Wang,Han Xiao,Yuhang Zhou,Shaokun Zhang,Jiayi Zhang,Jinyu Xiang,Yixiong Fang,Qiwen Zhao,Dongrui Liu,Qihan Ren,Cheng Qian,Zhenghailong Wang,Minda Hu,Huazheng Wang,Qingyun Wu,Heng Ji,Mengdi Wang*

Main category: cs.AI

TL;DR: Error processing this paper.


<details>
  <summary>Details</summary>
Motivation: Error processing this paper.

Method: Error processing this paper.

Result: Error processing this paper.

Conclusion: Error processing this paper.

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities but remain
fundamentally static, unable to adapt their internal parameters to novel tasks,
evolving knowledge domains, or dynamic interaction contexts. As LLMs are
increasingly deployed in open-ended, interactive environments, this static
nature has become a critical bottleneck, necessitating agents that can
adaptively reason, act, and evolve in real time. This paradigm shift -- from
scaling static models to developing self-evolving agents -- has sparked growing
interest in architectures and methods enabling continual learning and
adaptation from data, interactions, and experiences. This survey provides the
first systematic and comprehensive review of self-evolving agents, organized
around three foundational dimensions -- what to evolve, when to evolve, and how
to evolve. We examine evolutionary mechanisms across agent components (e.g.,
models, memory, tools, architecture), categorize adaptation methods by stages
(e.g., intra-test-time, inter-test-time), and analyze the algorithmic and
architectural designs that guide evolutionary adaptation (e.g., scalar rewards,
textual feedback, single-agent and multi-agent systems). Additionally, we
analyze evaluation metrics and benchmarks tailored for self-evolving agents,
highlight applications in domains such as coding, education, and healthcare,
and identify critical challenges and research directions in safety,
scalability, and co-evolutionary dynamics. By providing a structured framework
for understanding and designing self-evolving agents, this survey establishes a
roadmap for advancing adaptive agentic systems in both research and real-world
deployments, ultimately shedding lights to pave the way for the realization of
Artificial Super Intelligence (ASI), where agents evolve autonomously,
performing at or beyond human-level intelligence across a wide array of tasks.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [165] [Product-Congruence Games: A Unified Impartial-Game Framework for RSA ($φ$-MuM) and AES (poly-MuM)](https://arxiv.org/abs/2507.20087)
*Satyam Tyagi*

Main category: cs.DM

TL;DR: 论文揭示了RSA指数缩减与AES S盒求逆的共同组合原理——乘积同余博弈(PCG)，通过统一框架将两种加密系统的代数核心联系起来，并提出了结构定理与崩溃原则。


<details>
  <summary>Details</summary>
Motivation: 探索RSA与AES两种主流加密算法背后的共同数学基础，建立统一的组合博弈理论框架以解释其代数结构。

Method: 提出乘积同余博弈(PCG)模型，实例化为$\phi$-MuM（对应RSA）和poly-MuM（对应AES），证明单洞性质与乘法性，并建立四项通用PCG结构定理。

Result: 发现RSA的CRT分解与AES的有限域求逆均服从PCG框架，证明局部结构的乘性特性，并揭示操作对齐崩溃导致某些变体退化的原因。

Conclusion: 通过经典数学工具（乘法阶、中国剩余定理、有限域）构建了统一视角，将RSA与AES纳入中立博弈框架，其结构定理为密码学分析提供新工具。

Abstract: RSA exponent reduction and AES S-box inversion share a hidden commonality:
both are governed by the same impartial combinatorial principle, which we call
a Product-Congruence Game (PCG). A Product-Congruence Game tracks play via the
modular or finite-field product of heap values, providing a single invariant
that unifies the algebraic cores of these two ubiquitous symmetric and
asymmetric cryptosystems. We instantiate this framework with two companion
games. First, $\phi$-MuM, in which a left-associated "multi-secret" RSA
exponent chain compresses into the game of Multiplicative Modular Nim,
PCG($k,\{1\}$), where $k = ord_N(g)$. The losing predicate then factorizes via
the Chinese remainder theorem, mirroring RSA's structure. Second, poly-MuM, our
model for finite-field inversion such as the AES S-box. For poly-MuM we prove
the single-hole property inside its threshold region, implying that the
Sprague-Grundy values are multiplicative under disjunctive sums in that region.
Beyond these instances, we establish four structural theorems for a general
Product-Congruence Game PCG($m,R$): (i) single-heap repair above the modulus,
(ii) ultimate period $m$ per coordinate, (iii) exact and asymptotic losing
densities, and (iv) confinement of optimal play to a finite indeterminacy
region. An operation-alignment collapse principle explains why some variants
degenerate to a single aggregate while MuM, $\phi$-MuM and poly-MuM retain rich
local structure. All ingredients (multiplicative orders, the Chinese remainder
theorem, finite fields) are classical; the contribution is the unified
aggregation-compression viewpoint that embeds both RSA and AES inside one
impartial-game framework, together with the structural and collapse theorems.

</details>


### [166] [Ternary Binomial and Trinomial Bent Functions in the Completed Maiorana-McFarland Class](https://arxiv.org/abs/2507.20715)
*Tor Helleseth,Alexander Kholosha,Niki Spithaki*

Main category: cs.DM

TL;DR: 发现了属于Maiorana-McFarland类的两类三元四次弯曲函数，包括二项式和三项式，并给出了其具体形式和证明方法。


<details>
  <summary>Details</summary>
Motivation: 研究三元弯曲函数的构造和性质，特别是在Maiorana-McFarland类中的具体表现形式，以扩展对弯曲函数的理解。

Method: 通过分析函数的一阶和二阶导数，提出了一种新的弯曲性判定准则，并应用于二项式和三项式的构造。

Result: 找到了两类弯曲函数：二项式形式为$f(x)=\Tr_{4k}\big(a_1 x^{2(3^k+1)}+a_2 x^{(3^k+1)^2}\big)$，三项式形式为$f(x)=\Tr_n\big(a_1 x^{2\cdot3^k+4} + a_2 x^{3^k+5} + a_3 x^2\big)$，并给出了系数的具体定义。

Conclusion: 该研究不仅扩展了三元弯曲函数的已知类别，还提供了一种新的弯曲性判定方法，为后续研究提供了新的工具和方向。

Abstract: Two classes of ternary bent functions of degree four with two and three terms
in the univariate representation that belong to the completed
Maiorana-McFarland class are found. Binomials are mappings
$\F_{3^{4k}}\mapsto\fthree$ given by $f(x)=\Tr_{4k}\big(a_1 x^{2(3^k+1)}+a_2
x^{(3^k+1)^2}\big)$, where $a_1$ is a nonsquare in $\F_{3^{4k}}$ and $a_2$ is
defined explicitly by $a_1$. Particular subclasses of the binomial bent
functions we found can be represented by exceptional polynomials over
$\fthreek$. Bent trinomials are mappings $\F_{3^{2k}}\mapsto\fthree$ given by
$f(x)=\Tr_n\big(a_1 x^{2\cdot3^k+4} + a_2 x^{3^k+5} + a_3 x^2\big)$ with
coefficients explicitly defined by the parity of $k$. The proof is based on a
new criterion that allows checking bentness by analyzing first- and
second-order derivatives of $f$ in the direction of a chosen $n/2$-dimensional
subspace.

</details>
